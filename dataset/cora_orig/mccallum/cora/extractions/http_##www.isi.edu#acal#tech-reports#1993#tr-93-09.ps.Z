URL: http://www.isi.edu/acal/tech-reports/1993/tr-93-09.ps.Z
Refering-URL: http://www.isi.edu/acal/tech-reports/index.html
Root-URL: http://www.isi.edu
Title: ABSTRACT INTERPRETATION FOR THE COMPILE-TIME OPTIMIZATION OF LOGIC PROGRAMS  
Author: by Thomas Walter Getzinger 
Degree: A Dissertation Presented to the FACULTY OF THE GRADUATE SCHOOL  In Partial Fulfillment of the Requirements for the Degree DOCTOR OF PHILOSOPHY (Computer Science)  
Note: Copyright 1993 Thomas Walter Getzinger  
Date: December 1993  
Affiliation: UNIVERSITY OF SOUTHERN CALIFORNIA  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> F. Allen and J. Cocke. </author> <title> A Program Data Flow Analysis Procedure. </title> <journal> In Comm. of the ACM, </journal> <volume> Vol 19 #3, </volume> <pages> pp. 137-147, </pages> <month> March </month> <year> 1976. </year>
Reference-contexts: Allen and Cocke describe some early applications of data and control flow analysis <ref> [1, 2, 13] </ref>. Cousot and Cousot provided a unified view of these and other data flow analyses with a technique they called abstract interpretation [17].
Reference: [2] <author> F. Allen. </author> <title> Control Flow Analysis. </title> <journal> In ACM SIGPLAN Notices 5:7, </journal> <pages> pp. 1-19, </pages> <month> January </month> <year> 1970. </year>
Reference-contexts: Allen and Cocke describe some early applications of data and control flow analysis <ref> [1, 2, 13] </ref>. Cousot and Cousot provided a unified view of these and other data flow analyses with a technique they called abstract interpretation [17].
Reference: [3] <author> A. Aho, J. Hopcroft, and J. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley. </publisher> <month> June </month> <year> 1974. </year>
Reference-contexts: In this domain, weak coupling is captured as an undirected graph in which the arcs represent possible coupling between two variables. There are many ways to represent this graph <ref> [3] </ref>. One common representation is a set of pairs of variables (representing the arcs). This makes the abstract domain the powerset of the cross product of the set of variables with itself, ordered by subset.
Reference: [4] <author> A. Aho, R. Sethi, and J. Ullman. </author> <booktitle> Compilers, Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley. </publisher> <month> March </month> <year> 1986. </year>
Reference: [5] <author> H. At-Kaci. </author> <title> Warrens Abstract Machine: A Tutorial Reconstruction. </title> <publisher> The MIT Press. </publisher> <year> 1991. </year>
Reference: [6] <author> A. Bansal and L. Sterling. </author> <title> An Abstract Interpretation Scheme for Logic Programs based on Type Expressions. </title> <booktitle> In Proceedings of the International Conference on Fifth Generation Computer Systems, </booktitle> <pages> pp. 422-429, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: Another choice in developing a type domain is whether to capture a single type for each variable or a set of possible types (or types). 90 Early work considered types separately from modes <ref> [6, 8] </ref>. Janssens and Bruynooghe referred to these as rigid types [40]. They went on to introduce integrated types, which allow partially instantiated terms to be described with considerable precision. Since mode information is so important to compile-time optimization, we will only consider integrated types.
Reference: [7] <author> R. Barbuti and M. Martelli. </author> <title> A tool to check the non-floundering logic programs and goals. </title> <booktitle> In Lecture Notes in Computer Science, Vol. 348 (Programming Languages Implementation and Logic Programming International Workshop PLILP 99), </booktitle> <pages> pp. 58-67. </pages> <month> May </month> <year> 1988. </year>
Reference: [8] <author> M. Bruynooghe, G. Janssens, Alain Callebaut, and B. Demoen. </author> <title> Abstract Interpretation: Towards the Global Optimisation of Prolog Programs. </title> <booktitle> In 1987 IEEE Symposium on Logic Programming, </booktitle> <pages> pp. 192-204, </pages> <year> 1987. </year>
Reference-contexts: This is the most often described form of analysis <ref> [8, 10, 27, 49, 54, 59, 61, 67, 69, 78, 84] </ref>, probably because it is one of the easiest to understand and provides very useful information. As we saw previously, many optimizations depend on knowing the modes of variables. <p> Domain M 3 extends domain M 1 with the state where a variable is known to be bound (nonvar), but not necessarily ground. Domain M 4 combines the information from domains M 1 and M 2 <ref> [8, 10, 54, 27] </ref>. Domain M 5 adds all of these states [84]. Domain M 6 extends domain M 5 even further by adding the state where a variable is bound to a compound term, but all of the arguments are unbound [61]. <p> Another choice in developing a type domain is whether to capture a single type for each variable or a set of possible types (or types). 90 Early work considered types separately from modes <ref> [6, 8] </ref>. Janssens and Bruynooghe referred to these as rigid types [40]. They went on to introduce integrated types, which allow partially instantiated terms to be described with considerable precision. Since mode information is so important to compile-time optimization, we will only consider integrated types. <p> This is known as T U W X 100 strong coupling. The following sections describe some domains for detecting this type of coupling. Strong Coupling Domain SC 1 The simplest strong coupling domain captures sets of equivalent variables. This was suggested by Bruynooghe et al. in <ref> [8] </ref>. The domain is the powerset of the powerset of the set of variables, ordered by subset. <p> This extends directly to sets of equivalent variables. Equivalence Domain E 1 The first equivalence domain partitions the set of variables into sets of equivalent variables <ref> [8] </ref>. This is identical to strong coupling domain SC 1 . It is merely being used here for a different purpose. For the same reasons given previously, this is also not a very useful domain for capturing equivalence. <p> Clearly, the amount of sharing between variables depends highly on when the implementation copies information as opposed to creating pointers to shared data structures. Knowing about sharing is important in order to perform compile-time garbage collection <ref> [8, 35, 45] </ref>, that is, to reuse memory structures when they are no longer needed (they become dead). Table 29: Proposed Aliasing Domains # Reference Definition: Comments: A 1 None WC 1 This is a simple domain, provided for completeness. <p> A 4 Jones & Sondergaard [42] WC 3 L This adds linearity. This is important for predicate entry and exit. A 5 Bruynooghe et al. <ref> [8] </ref> WC 3 E 2 This drops linearity, but adds equivalence. A 6 Jannsens [40, 41] WC 3 E 2 L This adds both. It was used along with T 4 . A 7 Citrin [12] WC 2 SC 2 This improves on SDDA by adding strong coupling classes. <p> The following sections describe some domains that have been proposed for capturing sharing information. Sharing Domain S 1 Bruynooghe et al. proposed a sharing domain to be used for compile-time garbage collection <ref> [8] </ref>. The domain is the product of a possible sharing and definite sharing domain. The possible sharing domain can describe the following: X AL Y: variables X and Y may share the same memory structure. <p> This is done by determining the last access to a variable or part of its value. Bruynooghe described a domain for capturing this information in conjunction with sharing domain S 1 <ref> [8] </ref>. This liveness domain describes what values may still be needed when returning from the current predicate, through the following types of statements: LIVE X: variable X may still be needed (live) on return.
Reference: [9] <author> M. Bruynooghe and G. Janssens. </author> <title> An Instance of Abstract Interpretation Integrating Type and Mode Inferencing. </title> <booktitle> In Logic Programming: Proceedings of the 5th International Conference, </booktitle> <pages> pp. 669-683, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: The program points that are captured are clause entry and exit, and between each goal in a list of goals. It requires two abstract operations, call and return. 3.3.4 A Practical Framework Bruynooghe described what he referred to as a Practical framework <ref> [9, 10] </ref>. This framework differed in three aspects from other frameworks. First, the framework was defined based on the construction of an abstract And/Or tree rather than an extension table of results. This allows different call/return conditions to be recorded based on the caller. <p> Unlike Bruynooghes, this algorithm constructs an extension table of results. The required set of operations, however, are almost the same as those described by Janssens and Bruynooghe <ref> [9] </ref>. The only difference is that the renaming operation has been combined with restriction to form a restriction operation intended to be used specifically when abstractly calling a goal. Other operations have been renamed to make their purpose more explicit. <p> Clause_Info This is the static analysis information for the clause currently being analyzed. It is available for use in the abstract operation. Table 22: Global Information in the Analysis Algorithm Name/Type Description 85 Chapter 5: Prolog Analysis Numerous abstract domains have been proposed to capture various properties <ref> [9, 27, 36, 40, 48, 57, 61, 78, 84] </ref>. We have constructed a taxonomy, shown in Figure 30, to organize these properties. The properties have been grouped into three broad categories: implementation-independent variable analyses, implementation-dependent variable analyses, and predicate-level analyses. <p> Type Domain T 4 Type domain T4 is the most expressive of the type domains. It captures fully recursive types and type intersections by defining type graphs or type expressions. Janssens and Bruynooghe called these integrated types because they include mode information <ref> [9, 40, 41] </ref>. A type graph is a directed graph with a root node. The root node is the top of the type graph. Each node is labelled, to indicate what it represents. The arcs point to the nodes successors. <p> Aliasing analysis can restrict the scope of these changes by determining what aliasing exists between variables. In addition to improving mode and type information [65], aliasing analysis can be used in its own right for automatic parallelization of Prolog code <ref> [9] </ref> and removal of occur-check from unification (or detection of where occur-checks may be needed, since most Prolog implementation dont perform occur-checks during unification) [42]. Many aliasing domains have been proposed [11, 12, 10, 40, 42, 48].
Reference: [10] <author> M. Bruynooghe. </author> <title> A Framework for the Abstract Interpretation of Logic Programs. </title> <type> Report CW 62, </type> <institution> Dept. of Computer Science, K.U. Leuven, </institution> <month> October </month> <year> 1987. </year>
Reference-contexts: The attraction of abstract interpretation, however, was that it allowed data flow analysis to be parameterized by the abstract domain. This was used in later work to define abstract interpretation frameworks in which a number of analyses could be described <ref> [42, 10, 67, 87, 43] </ref>. There are three basic pieces that together form an abstract interpretation, as illustrated in Figure 20: An abstract domain (for example, the mode domain shown in Figure 19). A specific collection of operations defined over the values of the abstract domain. <p> The program points that are captured are clause entry and exit, and between each goal in a list of goals. It requires two abstract operations, call and return. 3.3.4 A Practical Framework Bruynooghe described what he referred to as a Practical framework <ref> [9, 10] </ref>. This framework differed in three aspects from other frameworks. First, the framework was defined based on the construction of an abstract And/Or tree rather than an extension table of results. This allows different call/return conditions to be recorded based on the caller. <p> As can be seen from the variety apparent in the frameworks described previously, the set of operations specified for this can vary significantly. Bruynooghe, for example, described Prolog execution in terms of six basic operations: restriction, renaming, initialization, backward unification, extension, and abstract interpretation of unification <ref> [10] </ref>. Bruynooghe claims these operations are simple to understand, and therefore, to define for a given domain. Jacobs and Langen take an opposite approach, defining only two operations: init and pass [36]. <p> This is the most often described form of analysis <ref> [8, 10, 27, 49, 54, 59, 61, 67, 69, 78, 84] </ref>, probably because it is one of the easiest to understand and provides very useful information. As we saw previously, many optimizations depend on knowing the modes of variables. <p> Domain M 3 extends domain M 1 with the state where a variable is known to be bound (nonvar), but not necessarily ground. Domain M 4 combines the information from domains M 1 and M 2 <ref> [8, 10, 54, 27] </ref>. Domain M 5 adds all of these states [84]. Domain M 6 extends domain M 5 even further by adding the state where a variable is bound to a compound term, but all of the arguments are unbound [61]. <p> Many aliasing domains have been proposed <ref> [11, 12, 10, 40, 42, 48] </ref>. Most are constructed as the product of simpler domains, such as weak coupling, strong coupling, linearity, and modes. Modes have already been addressed. The remaining sub-domains are described in the following sections. Some terminology related to variable aliasing is defined in Table 28.
Reference: [11] <author> J. Chang and A. Despain. </author> <title> Semi-Intelligent Backtracking of Prolog Based on A Static Data Dependency Analysis. </title> <booktitle> In Logic Programming conference, </booktitle> <month> July </month> <year> 1985. </year> <month> 150 </month>
Reference-contexts: Many aliasing domains have been proposed <ref> [11, 12, 10, 40, 42, 48] </ref>. Most are constructed as the product of simpler domains, such as weak coupling, strong coupling, linearity, and modes. Modes have already been addressed. The remaining sub-domains are described in the following sections. Some terminology related to variable aliasing is defined in Table 28. <p> For partially instantiated structures (or unbound variables), this means the variables, themselves, must match. 98 Weak Coupling Domain WC 2 Domain WC 2 was proposed by Chang to detect data dependencies in order to implement semi-intelligent backtracking <ref> [11] </ref>. This domain addresses the deficiency of the previous domain. An element of this domain is a set of sets of variables, partitioning the variables into sets of possibly coupled variables. <p> A singleton set (a set containing a single variable) indicates an independent variable. When this domain was first proposed, as part of a technique called Static Data Dependency Analysis (SDDA) <ref> [11] </ref>, it also captured groundness; any variables not appearing in the abstract description were considered to be ground. This can still be done, or groundness can be captured using mode domain M 1 . <p> This was proposed as an improvement to Changs SDDA <ref> [11] </ref>. It is interesting to note that in his domain, which was the product of SC 2 and WC 2 , each weak coupling set was further divided into multiple strong coupling sets. <p> Table 29: Proposed Aliasing Domains # Reference Definition: Comments: A 1 None WC 1 This is a simple domain, provided for completeness. A 2 Chang <ref> [11] </ref> WC 2 When combined with M 1 , this is SDDA. A 3 None WC 3 This adds non-transitive weak coupling (A and B are coupled, B and C are coupled, but A and C are not). A 4 Jones & Sondergaard [42] WC 3 L This adds linearity.
Reference: [12] <author> W. Citrin. </author> <title> Parallel Unification Scheduling in Prolog. </title> <type> Ph.D. Thesis, </type> <institution> University of California, Berkeley, </institution> <note> Report UCB/CSD #88/415, </note> <year> 1988. </year>
Reference-contexts: Many aliasing domains have been proposed <ref> [11, 12, 10, 40, 42, 48] </ref>. Most are constructed as the product of simpler domains, such as weak coupling, strong coupling, linearity, and modes. Modes have already been addressed. The remaining sub-domains are described in the following sections. Some terminology related to variable aliasing is defined in Table 28. <p> This type of equivalence happens very infrequently. Strong Coupling Domain SC 2 Citrin proposed a domain which had the same form as SC 1 , except the descriptions captured sets of strongly coupled variables (i.e., grounding of one variable in the set grounded all other variables in the set) <ref> [12] </ref>. This was proposed as an improvement to Changs SDDA [11]. It is interesting to note that in his domain, which was the product of SC 2 and WC 2 , each weak coupling set was further divided into multiple strong coupling sets. <p> This is important for predicate entry and exit. A 5 Bruynooghe et al. [8] WC 3 E 2 This drops linearity, but adds equivalence. A 6 Jannsens [40, 41] WC 3 E 2 L This adds both. It was used along with T 4 . A 7 Citrin <ref> [12] </ref> WC 2 SC 2 This improves on SDDA by adding strong coupling classes. A 8 Langen [36] CC This captures both weak and strong coupling in a single, combined representation which is more expressive than both combined.
Reference: [13] <author> J. Cocke. </author> <title> Global Common Subexpression Elimination. </title> <journal> In ACM SIG-PLAN Notices 5:7, </journal> <pages> pp. 20-24, </pages> <month> January </month> <year> 1970. </year>
Reference-contexts: Allen and Cocke describe some early applications of data and control flow analysis <ref> [1, 2, 13] </ref>. Cousot and Cousot provided a unified view of these and other data flow analyses with a technique they called abstract interpretation [17].
Reference: [14] <author> C. Codognet, P. Codognet, and M. Corsini. </author> <title> Abstract Interpretation for Concurrent Logic Languages. </title> <booktitle> In Proceedings of the North American Conference on Logic Programming '90, </booktitle> <pages> pp. 215-232, </pages> <month> October </month> <year> 1990. </year>
Reference: [15] <author> M. Codish, D. Dams, and E. Yardeni. </author> <title> Bottom-up Abstract Interpretation of Logic Programs. </title> <type> Technical Report CS90-24. </type> <institution> The Weizmann Institute of Science. </institution> <month> October </month> <year> 1990. </year>
Reference: [16] <author> A. Cortesi, G. File, and W. Winsborough. </author> <title> Comparison of Abstract Interpretations. </title> <type> Internal report 14 - 18.11.1991. </type> <institution> Departmento di Matem-atica. </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: The lattice shows the set of modes provided in a given domain, and the relationship between modes; a mode appearing above another mode, connected by solid lines, describes a larger set of concrete values approximates another <ref> [17, 16] </ref>; the higher entries on this lattice provide more detailed information. The top element is the concrete domain. The bottom element is the domain of no information (in essence, the result of performing no analysis).
Reference: [17] <author> P. Cousot and R. Cousot. </author> <title> Abstract Interpretation: A Unified Lattice Model for Static Analysis of Programs by Construction or Approximation of Fixpoints. </title> <booktitle> In 4th ACM POPL, </booktitle> <pages> pp. 238-252, </pages> <month> June </month> <year> 1977. </year>
Reference-contexts: Allen and Cocke describe some early applications of data and control flow analysis [1, 2, 13]. Cousot and Cousot provided a unified view of these and other data flow analyses with a technique they called abstract interpretation <ref> [17] </ref>. Since then, many researchers have applied this technique to the analysis of logic programs [24, 48, 61, 63, 80, 84]. 3.1.1 Overview Abstract interpretation provides a good theoretical model in which a large number of program analyses may be performed. <p> The lattice shows the set of modes provided in a given domain, and the relationship between modes; a mode appearing above another mode, connected by solid lines, describes a larger set of concrete values approximates another <ref> [17, 16] </ref>; the higher entries on this lattice provide more detailed information. The top element is the concrete domain. The bottom element is the domain of no information (in essence, the result of performing no analysis).
Reference: [18] <author> P. Cousot and R. Cousot. </author> <title> Abstract Interpretation and Application to Logic Programs. </title> <type> Research Report 92-12, </type> <institution> LIENS Laboratoire dInfor-matique de lEcole Normale Superieure, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: That is, abstract interpretation will indicate what might happen when the program executes or what is guaranteed not to happen. The closeness of the approximation to reality is referred to as its precision. Abstract interpretation replaces the standard semantics of the program being executed with a collecting semantics <ref> [18] </ref>. This semantics is used to collect information about program states reachable during the execution of the program, by replacing concrete data values with abstract descriptions. <p> Table 7 provides some intuition about these conditions. 3.1.2 Example of Abstract Interpretation The domain of signs gives a simple example of abstract interpretation <ref> [18] </ref>. The data objects are real numbers. For descriptions, we will use the lattice shown in Figure 18, which gives all possible states of sets of real numbers, based on their signs.
Reference: [19] <author> J. Crammond. </author> <title> An Execution Model for Committed-Choice Non-Deterministic Languages. </title> <booktitle> In Proceedings of the 1986 Symposium on Logic Programming, </booktitle> <pages> pp. 148-158, </pages> <month> September </month> <year> 1986. </year>
Reference: [20] <author> J. Crammond. </author> <title> Scheduling and Variable Assignment in the Parallel Parlog Implementation. </title> <booktitle> In Proceedings of the North American Conference on Logic Programming '90, </booktitle> <pages> pp. 642-657, </pages> <month> October </month> <year> 1990. </year>
Reference: [21] <author> S. Debray. </author> <title> Register Allocation in a Prolog Machine. </title> <booktitle> In Proceedings of the IEEE 1986 Symposium on Logic Programming, </booktitle> <pages> pp. 267-275, </pages> <month> September </month> <year> 1986. </year>
Reference: [22] <author> S. Debray. </author> <title> Unfold/Fold Transformations and Loop Optimization of Logic Programs. </title> <booktitle> In Proceedings of the SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pp. 297-307, </pages> <month> June </month> <year> 1988. </year> <month> 151 </month>
Reference: [23] <author> S. Debray. </author> <title> A Simple Code Improvement Scheme for Prolog. </title> <booktitle> In Logic Programming: Proceedings of the 6th International Conference, </booktitle> <pages> pp. 17-32, </pages> <month> June </month> <year> 1989. </year>
Reference: [24] <author> S. Debray. </author> <title> Flow Analysis of Dynamic Logic Programs. </title> <journal> In Journal of Logic Programming, </journal> <volume> Vol. 1989:7, </volume> <pages> pp. 149-176. </pages> <year> 1989. </year>
Reference-contexts: Cousot and Cousot provided a unified view of these and other data flow analyses with a technique they called abstract interpretation [17]. Since then, many researchers have applied this technique to the analysis of logic programs <ref> [24, 48, 61, 63, 80, 84] </ref>. 3.1.1 Overview Abstract interpretation provides a good theoretical model in which a large number of program analyses may be performed. Attempting to analyze a program by simulating its execution for all possible inputs is, in general, unsolvable.
Reference: [25] <author> S. Debray. </author> <title> The Mythical Free Lunch (Notes on the Complexity/Precision Trade-off in Dataflow Analysis of Logic Programs) (unpublished). </title> <month> March </month> <year> 1991. </year>
Reference: [26] <author> S. Debray and D. S. Warren. </author> <title> Detection and Optimization of Functional Computations in Prolog. </title> <booktitle> In Proceedings of the Third International Conference on Logic Programming, </booktitle> <pages> pp. 490-504. </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: Taylor used determinacy information to reduce variable trailing [78]. Any variable being bound which was created after the current choicepoint was created does not need to be trailed. Debray and Warren extend the idea of determinacy to the concept of functional predicates <ref> [26] </ref>. A functional predicate is one whose outputs depend, functionally, on the inputs; it may return multiple results, but the results are identical for all values that are used (e.g., an output which varies may never be accessed after returning).
Reference: [27] <author> S. Debray and D. S. Warren. </author> <title> Automatic Mode Inference for Prolog Programs. </title> <booktitle> In IEEE 1986 Symposium on Logic Programming, </booktitle> <pages> pp. 78-88, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: During analysis, this indicates portions of code that have not yet been analyzed. When the analysis is complete, it indicates portions of code that are unreachable. 3.3 Abstract Interpretation Frameworks Originally, analyzers were built for specific abstract domains <ref> [27, 61] </ref>. The attraction of abstract interpretation, however, was that it allowed data flow analysis to be parameterized by the abstract domain. This was used in later work to define abstract interpretation frameworks in which a number of analyses could be described [42, 10, 67, 87, 43]. <p> Clause_Info This is the static analysis information for the clause currently being analyzed. It is available for use in the abstract operation. Table 22: Global Information in the Analysis Algorithm Name/Type Description 85 Chapter 5: Prolog Analysis Numerous abstract domains have been proposed to capture various properties <ref> [9, 27, 36, 40, 48, 57, 61, 78, 84] </ref>. We have constructed a taxonomy, shown in Figure 30, to organize these properties. The properties have been grouped into three broad categories: implementation-independent variable analyses, implementation-dependent variable analyses, and predicate-level analyses. <p> This is the most often described form of analysis <ref> [8, 10, 27, 49, 54, 59, 61, 67, 69, 78, 84] </ref>, probably because it is one of the easiest to understand and provides very useful information. As we saw previously, many optimizations depend on knowing the modes of variables. <p> Domain M 3 extends domain M 1 with the state where a variable is known to be bound (nonvar), but not necessarily ground. Domain M 4 combines the information from domains M 1 and M 2 <ref> [8, 10, 54, 27] </ref>. Domain M 5 adds all of these states [84]. Domain M 6 extends domain M 5 even further by adding the state where a variable is bound to a compound term, but all of the arguments are unbound [61]. <p> The nodes successors are ordered and describe the arguments of the structure. 96 5.1.3 Aliasing Analysis Early mode analysis was found to be unsound since it didnt consider the effects of aliasing <ref> [27] </ref>. Consider the example program from [27], shown in Figure 35. After the call to q/2, the variables X and Y are aliased together. The call to r/1 binds both X and Y to the atom a, but without aliasing information, it may seem that Y is not affected. <p> The nodes successors are ordered and describe the arguments of the structure. 96 5.1.3 Aliasing Analysis Early mode analysis was found to be unsound since it didnt consider the effects of aliasing <ref> [27] </ref>. Consider the example program from [27], shown in Figure 35. After the call to q/2, the variables X and Y are aliased together. The call to r/1 binds both X and Y to the atom a, but without aliasing information, it may seem that Y is not affected.
Reference: [28] <author> D. De Schreye and M. Bruynooghe. </author> <title> An Application of Abstract Interpretation in Source Level Program Transformation. </title> <booktitle> In Lecture Notes in Computer Science, Vol. 348 (Programming Languages Implementation and Logic Programming International Workshop PLILP 88) pp. </booktitle> <pages> 35-57. </pages> <month> May </month> <year> 1988. </year>
Reference: [29] <author> S. Dietrich. </author> <title> Extension Tables: Memo Relations in Logic Programming. </title> <booktitle> In Proceedings of the 4th International Symposium on Logic Programming, </booktitle> <pages> pp. 264-272. </pages> <year> 1987. </year>
Reference-contexts: During the analysis, the algorithm records clause input and output conditions in an extension table <ref> [29] </ref>. When the algorithm terminates, this table covers the conditions that will be encountered at run-time. As given, the algorithm in Figure 21 is not very efficient. There are a number of things that can be done (and typically are, in an implementation of this framework) to improve the efficiency. <p> One value (which can be a structure) is gathered for each predicate and one for each clause in each predicate. The algorithm in Figure 28 shows how these values are collected for a predicate. 3. This is very similar to memoization <ref> [29] </ref>. Table 16: Arguments for prepare_head/2 Argument: Description: Head The canonical head of the predicate. This is the same term passed to abs_int_entry and abs_int_exit.
Reference: [30] <author> J. Gallagher and M. Bruynooghe. </author> <title> The Derivation of an Algorithm for Program Specialisation. </title> <booktitle> In Logic Programming: Proceedings of the 7th International Conference pp. </booktitle> <pages> 732-746. </pages> <publisher> MIT Press. </publisher> <month> June </month> <year> 1990. </year>
Reference: [31] <author> T. Hickey and S. Mudambi. </author> <title> Global Compilation of Prolog. </title> <journal> In Journal of Logic Programming, </journal> <volume> Vol. 7, </volume> <pages> pp. 193-230, </pages> <year> 1989. </year>
Reference: [32] <author> J. Hennessy and D. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufman Publishers. </publisher> <year> 1990. </year>
Reference-contexts: The resulting abstract machine is described in Appendix A. The following summarizes the main differences: We made numerous changes to simplify the instruction syntax and make instruction operations and operands more regular and orthogonal <ref> [32] </ref>. This makes the model easier to understand and to translate to target assembly code, and permits peephole optimizations not possible previously. We added a mode flag to the deref instruction (like the unify flags). This allows some optimizations for the dereference loop.
Reference: [33] <author> M. Hermenegildo. </author> <title> An Abstract Machine for Restricted AND-Parallel Execution of Logic Programs. </title> <booktitle> In Proceedings of the Third International Conference on Logic Programming, </booktitle> <pages> pp. 25-39. </pages> <month> July </month> <year> 1986. </year> <month> 152 </month>
Reference: [34] <author> B. Holmer, et al. </author> <title> Fast Prolog with an Extended General Purpose Architecture. </title> <booktitle> In The 17th Annual International Symposium on Computer Architecture Conference Proceedings, </booktitle> <pages> pp. 282-291, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: In addition, it is able to differentiate between negative and nonnegative integers, between atomic and compound values, and between lists and structures. In other words, it is able to differentiate the data tags that are used in the VLSI-BAM <ref> [34] </ref>.
Reference: [35] <author> G. Gudjonsson and W. Winsborough. </author> <title> Update in Place: Overview of the Siva Project. </title> <type> Technical Report CS-93-11, </type> <institution> Pennsylvania State University, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Clearly, the amount of sharing between variables depends highly on when the implementation copies information as opposed to creating pointers to shared data structures. Knowing about sharing is important in order to perform compile-time garbage collection <ref> [8, 35, 45] </ref>, that is, to reuse memory structures when they are no longer needed (they become dead). Table 29: Proposed Aliasing Domains # Reference Definition: Comments: A 1 None WC 1 This is a simple domain, provided for completeness. <p> Perhaps there is some optimal ordering of transformations that will make this process less dependent on the programming style. Compile-time garbage collection should be a very useful optimization. In addition to reducing dynamic memory requirements, it can reduce the time spent reading and writing memory <ref> [35] </ref>. The tools are now in place to give it the scrutiny it deserves. Recursive types are another area that deserve further study.
Reference: [36] <author> D. Jacobs and A. Langen. </author> <title> Accurate and Efficient Approximation of Variable Aliasing in Logic Programs. </title> <booktitle> In Logic Programming: Proceedings of the North American Conference 1989, </booktitle> <pages> pp. 154-165, </pages> <month> Octo-ber </month> <year> 1989. </year>
Reference-contexts: The following sections describe some of these frameworks, in order to show some of the options available when defining an abstract interpreter. 3.3.1 A Simple Framework The simplest framework, described by Jacobs <ref> [36, 69] </ref>, requires that only two operations be defined: init : Clause fi Desc pass : Term Desc Term Desc fi Desc init provides an initial description for a clause. <p> The initialization operation extends the result of renaming a description to the head variables of a predicate to include variables in a clause about to be analyzed. This is related to the init operation described by Jacobs and Langen <ref> [36] </ref>. The backward unification and extension operations, together, are similar to the return operation from other frameworks. The backward unification operation computes the result of returning information from the head arguments of a predicate, after it has been analyzed, to the call arguments. <p> Bruynooghe claims these operations are simple to understand, and therefore, to define for a given domain. Jacobs and Langen take an opposite approach, defining only two operations: init and pass <ref> [36] </ref>. <p> Clause_Info This is the static analysis information for the clause currently being analyzed. It is available for use in the abstract operation. Table 22: Global Information in the Analysis Algorithm Name/Type Description 85 Chapter 5: Prolog Analysis Numerous abstract domains have been proposed to capture various properties <ref> [9, 27, 36, 40, 48, 57, 61, 78, 84] </ref>. We have constructed a taxonomy, shown in Figure 30, to organize these properties. The properties have been grouped into three broad categories: implementation-independent variable analyses, implementation-dependent variable analyses, and predicate-level analyses. <p> A 6 Jannsens [40, 41] WC 3 E 2 L This adds both. It was used along with T 4 . A 7 Citrin [12] WC 2 SC 2 This improves on SDDA by adding strong coupling classes. A 8 Langen <ref> [36] </ref> CC This captures both weak and strong coupling in a single, combined representation which is more expressive than both combined. A 9 Langen [48] CC L This adds linearity in order to keep the information more precise (and computationally feasible). It also includes M 2 .
Reference: [37] <author> D. Jacobs. </author> <title> Constructing and Optimizing Multi-Directional Logic Programs. </title> <type> (Unpublished). </type> <month> March </month> <year> 1991. </year>
Reference: [38] <author> D. Jacobs. </author> <title> A Framework for the Abstract Interpretation of Logic Programs. </title> <type> (Unpublished). </type> <month> October </month> <year> 1991. </year>
Reference-contexts: atom A. rlist (X) tests if X is a recursive list, terminated by nil ([]). 78 4.7 The Analysis Algorithm This section presents the dataflow analysis algorithm, which makes use of the operations described in the previous sections to provide a generic abstract interpreter similar to that given by Jacobs <ref> [38] </ref> and Pabst [69]. More attention has been given to the use of this algorithm as part of a Prolog compiler, however. We dont claim that this is the most efficient algorithm.
Reference: [39] <author> D. Jacobs, T. Pabst and T. Getzinger. </author> <title> Modules and the Compile-Time Optimization of Prolog. </title> <type> (Unpublished). </type> <month> June </month> <year> 1992. </year>
Reference-contexts: The capability to compile separate modules of code would be helpful here. There are a number of interesting issues in the interaction between separate compilation and abstract interpretation. Dean Jacobs, Thomas Pabst and I explored these somewhat, integrating a module system to the Aquarius compiler <ref> [39] </ref>. Some of the issues are deciding what a user should specify about the interface (should he provide abstract information about the expected calling/return conditions or should this be derived and maintained automatically).
Reference: [40] <author> G. Janssens and M. Bruynooghe. </author> <title> Deriving descriptions of possible values of program variables by means of abstract interpretation. </title> <type> Report CW 107, </type> <institution> Department of Computer Science, K. U. Leuven. </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: It is possible that this may be needed, however. For example, Janssens implementation of type analysis stored type graph nodes in the Prolog database <ref> [40, 41] </ref>. The implementation required that certain entries be placed in the database initially, and that the database be cleaned up Table 14: Arguments for abs_int_builtin/3 Argument Description Call This is the goal used to call the predefined predicate. With the exception of unification, the arguments can be arbitrary terms. <p> Clause_Info This is the static analysis information for the clause currently being analyzed. It is available for use in the abstract operation. Table 22: Global Information in the Analysis Algorithm Name/Type Description 85 Chapter 5: Prolog Analysis Numerous abstract domains have been proposed to capture various properties <ref> [9, 27, 36, 40, 48, 57, 61, 78, 84] </ref>. We have constructed a taxonomy, shown in Figure 30, to organize these properties. The properties have been grouped into three broad categories: implementation-independent variable analyses, implementation-dependent variable analyses, and predicate-level analyses. <p> Another choice in developing a type domain is whether to capture a single type for each variable or a set of possible types (or types). 90 Early work considered types separately from modes [6, 8]. Janssens and Bruynooghe referred to these as rigid types <ref> [40] </ref>. They went on to introduce integrated types, which allow partially instantiated terms to be described with considerable precision. Since mode information is so important to compile-time optimization, we will only consider integrated types. The following sections describe a number of abstract domains used to approximate type information. <p> Type Domain T 4 Type domain T4 is the most expressive of the type domains. It captures fully recursive types and type intersections by defining type graphs or type expressions. Janssens and Bruynooghe called these integrated types because they include mode information <ref> [9, 40, 41] </ref>. A type graph is a directed graph with a root node. The root node is the top of the type graph. Each node is labelled, to indicate what it represents. The arcs point to the nodes successors. <p> Each node is labelled, to indicate what it represents. The arcs point to the nodes successors. The node labels used by Janssens are defined in Table 27. Janssens and Bruynooghe describe a number of restrictions on type graphs that are required in order to make them finite <ref> [40] </ref>. 94 Observations Flat type domains are most useful when capturing flat information, such as numbers. This can be seen in benchmarks like sendmore and tak. <p> Many aliasing domains have been proposed <ref> [11, 12, 10, 40, 42, 48] </ref>. Most are constructed as the product of simpler domains, such as weak coupling, strong coupling, linearity, and modes. Modes have already been addressed. The remaining sub-domains are described in the following sections. Some terminology related to variable aliasing is defined in Table 28. <p> Taylor included equivalence within the type descriptions, but only for unbound variables and structure arguments [80]. Janssens provided the equivalence information separately from the types by specifying sets of selectors for equivalent values <ref> [40] </ref>. These selectors allowed a variable to be selected or some part of the structure of a variable (e.g., the head of a list). In addition, these equivalence relationships could be over any values. <p> Equivalence domain E 2 is defined similar to the description used by Janssens <ref> [40] </ref>. A description is a set of equivalence sets, each of which contains a number of pairs of variables and selector lists. A (possibly empty) selector list selects parts of the term to which a variable is bound. <p> To detect this, it is necessary to know when a variables value contains multiple occurrences of some variable (as is the case with V). Langen called these variables nonlinear [48]. Jones and Sondergaard called them reocc (repeated occurrence) variables [42]. Janssens called them NUNI (for Not-UNIque) variables <ref> [40] </ref>. Knowledge of linearity is very important during predicate calling/returning. If a call argument is a variable, X, and the head argument is a term, [H|T], it would have to be assumed that the variables H and T are coupled, unless it is known that X is linear. <p> A 4 Jones & Sondergaard [42] WC 3 L This adds linearity. This is important for predicate entry and exit. A 5 Bruynooghe et al. [8] WC 3 E 2 This drops linearity, but adds equivalence. A 6 Jannsens <ref> [40, 41] </ref> WC 3 E 2 L This adds both. It was used along with T 4 . A 7 Citrin [12] WC 2 SC 2 This improves on SDDA by adding strong coupling classes. <p> Similarly, after some point certain variables no longer contribute anything (e.g., after their last occurrence in the clause). Eliminating these variables from the description will reduce analysis time by making descriptions smaller and less complex. Equivalence is captured for points in the type graphs <ref> [40] </ref>. However, weak coupling and linearity are captured for entire variables. This results in a loss of precision, which can result in expensive computation at analysis time. These properties should be captured for points in the type graph, as well.
Reference: [41] <author> G. Janssens and M. Bruynooghe. </author> <title> Deriving descriptions of possible values of program variables by means of abstract interpretation: definitions and proofs. </title> <type> Report CW 108, </type> <institution> Department of Computer Science, K. U. Leuven. </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: It is possible that this may be needed, however. For example, Janssens implementation of type analysis stored type graph nodes in the Prolog database <ref> [40, 41] </ref>. The implementation required that certain entries be placed in the database initially, and that the database be cleaned up Table 14: Arguments for abs_int_builtin/3 Argument Description Call This is the goal used to call the predefined predicate. With the exception of unification, the arguments can be arbitrary terms. <p> Type Domain T 4 Type domain T4 is the most expressive of the type domains. It captures fully recursive types and type intersections by defining type graphs or type expressions. Janssens and Bruynooghe called these integrated types because they include mode information <ref> [9, 40, 41] </ref>. A type graph is a directed graph with a root node. The root node is the top of the type graph. Each node is labelled, to indicate what it represents. The arcs point to the nodes successors. <p> A 4 Jones & Sondergaard [42] WC 3 L This adds linearity. This is important for predicate entry and exit. A 5 Bruynooghe et al. [8] WC 3 E 2 This drops linearity, but adds equivalence. A 6 Jannsens <ref> [40, 41] </ref> WC 3 E 2 L This adds both. It was used along with T 4 . A 7 Citrin [12] WC 2 SC 2 This improves on SDDA by adding strong coupling classes. <p> There are a number of reasons why this might have occurred: There may have been errors in my reimplementation of Janssens type analysis algorithms <ref> [41] </ref>. In fact, I found several. There may have been errors in Janssens type analysis algorithms or the original implementation. I found one algorithm error which caused non-termination and one implementation error which caused incorrect results. The analysis might have terminated if given more time.
Reference: [42] <author> N. Jones and H. Sndergaard. </author> <title> A Semantics-Based Framework for the Abstract Interpretation of Prolog. </title> <type> Report No. 86/14, </type> <institution> Institute of Data-logy, University of Copenhagen, </institution> <year> 1986. </year>
Reference-contexts: E P g g D P (d) g (d) --,0,+- -- -0 -+- 52 3.2 Abstract Interpretation of Prolog For Prolog, E P is typically defined to be the standard top-to-bottom, left-to-right operational semantics of Prolog, based on SLD-resolution <ref> [52, 42] </ref>. D P usually represents sets of possible substitutions for the program variables. <p> The attraction of abstract interpretation, however, was that it allowed data flow analysis to be parameterized by the abstract domain. This was used in later work to define abstract interpretation frameworks in which a number of analyses could be described <ref> [42, 10, 67, 87, 43] </ref>. There are three basic pieces that together form an abstract interpretation, as illustrated in Figure 20: An abstract domain (for example, the mode domain shown in Figure 19). A specific collection of operations defined over the values of the abstract domain. <p> It relaxes the restrictions on the abstract domain, allowing it to be a semi-lattice, instead of a complete lattice. 3.3.2 A Semantics Based Framework Jones and Sondergaard describe what they refer to as a semantics-based framework <ref> [42] </ref>. They begin by defining a standard top-down semantics and then factoring it into a core semantics and an interpretation. The core semantics corresponds to our abstract interpreter and the interpretation to our abstract operations. <p> What (if anything) is actually recorded is up to the abstract operation implementor (as specified in the newlog operation). 58 3.3.3 A Theoretical Framework Nilsson described a theoretical framework [67] which is very similar to that of Jones and Sndergaard <ref> [42] </ref>. The main difference is that the proof of correctness is more rigorous. The same groundness example that was used in [42] is used to illustrate this framework. Following are some features of this framework: It implements top-down (SLD-resolution) semantics, based on substitutions. <p> operation implementor (as specified in the newlog operation). 58 3.3.3 A Theoretical Framework Nilsson described a theoretical framework [67] which is very similar to that of Jones and Sndergaard <ref> [42] </ref>. The main difference is that the proof of correctness is more rigorous. The same groundness example that was used in [42] is used to illustrate this framework. Following are some features of this framework: It implements top-down (SLD-resolution) semantics, based on substitutions. It records, for each program point, an abstraction of the set of substitutions that occur during execution at that program point. <p> In other words, these analyses capture abstract properties describing Implementation Independent Determinacy Implementation Dependent Variable level Data Flow Analyses Predicate level Local Stack Use Trailing Reference Chains Access Aliasing Sharing Types Modes 86 the possible substitutions that occur during execution in the standard operational (SLD-resolution) semantics <ref> [42, 52] </ref>. 5.1.1 Mode Analysis Mode analysis attempts to determine the degree of instantiation of each variable. <p> In addition to improving mode and type information [65], aliasing analysis can be used in its own right for automatic parallelization of Prolog code [9] and removal of occur-check from unification (or detection of where occur-checks may be needed, since most Prolog implementation dont perform occur-checks during unification) <ref> [42] </ref>. Many aliasing domains have been proposed [11, 12, 10, 40, 42, 48]. Most are constructed as the product of simpler domains, such as weak coupling, strong coupling, linearity, and modes. Modes have already been addressed. The remaining sub-domains are described in the following sections. <p> Many aliasing domains have been proposed <ref> [11, 12, 10, 40, 42, 48] </ref>. Most are constructed as the product of simpler domains, such as weak coupling, strong coupling, linearity, and modes. Modes have already been addressed. The remaining sub-domains are described in the following sections. Some terminology related to variable aliasing is defined in Table 28. <p> Weak Coupling Domain WC 3 The most expressive domain for weak coupling, WC 3 , was proposed by Jones and Sondergaard <ref> [42] </ref>. In this domain, weak coupling is captured as an undirected graph in which the arcs represent possible coupling between two variables. There are many ways to represent this graph [3]. One common representation is a set of pairs of variables (representing the arcs). <p> To detect this, it is necessary to know when a variables value contains multiple occurrences of some variable (as is the case with V). Langen called these variables nonlinear [48]. Jones and Sondergaard called them reocc (repeated occurrence) variables <ref> [42] </ref>. Janssens called them NUNI (for Not-UNIque) variables [40]. Knowledge of linearity is very important during predicate calling/returning. <p> A 2 Chang [11] WC 2 When combined with M 1 , this is SDDA. A 3 None WC 3 This adds non-transitive weak coupling (A and B are coupled, B and C are coupled, but A and C are not). A 4 Jones & Sondergaard <ref> [42] </ref> WC 3 L This adds linearity. This is important for predicate entry and exit. A 5 Bruynooghe et al. [8] WC 3 E 2 This drops linearity, but adds equivalence. A 6 Jannsens [40, 41] WC 3 E 2 L This adds both.
Reference: [43] <author> R. Kemp and G. Ringwood. </author> <title> An Algebraic Framework for Abstract Interpretation of Definite Programs. </title> <booktitle> In Proceedings of the North American Conference on Logic Programming '90, </booktitle> <pages> pp. 516-530, </pages> <month> October </month> <year> 1990. </year> <month> 153 </month>
Reference-contexts: The attraction of abstract interpretation, however, was that it allowed data flow analysis to be parameterized by the abstract domain. This was used in later work to define abstract interpretation frameworks in which a number of analyses could be described <ref> [42, 10, 67, 87, 43] </ref>. There are three basic pieces that together form an abstract interpretation, as illustrated in Figure 20: An abstract domain (for example, the mode domain shown in Figure 19). A specific collection of operations defined over the values of the abstract domain.
Reference: [44] <author> F. Kluzniak. </author> <title> Type Synthesis for Ground Prolog. </title> <booktitle> In Logic Programming: Proceedings of the 4th International Conference, </booktitle> <pages> pp. 788-816, </pages> <month> May </month> <year> 1987. </year>
Reference: [45] <author> F. Kluzniak. </author> <title> Compile Time Garbage Collection for Ground Prolog. </title> <booktitle> In Logic Programming: Proceedings of the 5th International Conference, </booktitle> <pages> pp. 1490-1505, </pages> <year> 1988. </year>
Reference-contexts: Clearly, the amount of sharing between variables depends highly on when the implementation copies information as opposed to creating pointers to shared data structures. Knowing about sharing is important in order to perform compile-time garbage collection <ref> [8, 35, 45] </ref>, that is, to reuse memory structures when they are no longer needed (they become dead). Table 29: Proposed Aliasing Domains # Reference Definition: Comments: A 1 None WC 1 This is a simple domain, provided for completeness.
Reference: [46] <author> R. Kowalski. </author> <title> Logic for Problem Solving, </title> <publisher> Elsevier North-Holland, </publisher> <year> 1979. </year>
Reference: [47] <author> A. Krall and T. Berger. </author> <title> A Prolog Compiler based on the VAM. </title> <note> (Unpublished) 1992. </note>
Reference: [48] <author> A. Langen. </author> <title> Advanced Techniques for Approximating Variable Aliasing in Logic Programs. </title> <type> PhD Thesis. </type> <institution> University of Southern Califor-nia. </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: Cousot and Cousot provided a unified view of these and other data flow analyses with a technique they called abstract interpretation [17]. Since then, many researchers have applied this technique to the analysis of logic programs <ref> [24, 48, 61, 63, 80, 84] </ref>. 3.1.1 Overview Abstract interpretation provides a good theoretical model in which a large number of program analyses may be performed. Attempting to analyze a program by simulating its execution for all possible inputs is, in general, unsolvable. <p> Clause_Info This is the static analysis information for the clause currently being analyzed. It is available for use in the abstract operation. Table 22: Global Information in the Analysis Algorithm Name/Type Description 85 Chapter 5: Prolog Analysis Numerous abstract domains have been proposed to capture various properties <ref> [9, 27, 36, 40, 48, 57, 61, 78, 84] </ref>. We have constructed a taxonomy, shown in Figure 30, to organize these properties. The properties have been grouped into three broad categories: implementation-independent variable analyses, implementation-dependent variable analyses, and predicate-level analyses. <p> Many aliasing domains have been proposed <ref> [11, 12, 10, 40, 42, 48] </ref>. Most are constructed as the product of simpler domains, such as weak coupling, strong coupling, linearity, and modes. Modes have already been addressed. The remaining sub-domains are described in the following sections. Some terminology related to variable aliasing is defined in Table 28. <p> This domain cant be used to detect that Z covers W, X, and Y (i.e., grounding of Z grounds W, X, and Y). 5.1.3.3 Coupling Domain CC Langen proposed a domain that included both strong and weak coupling, and can address the weakness of SC 2 <ref> [48] </ref>. He called this domain sharing, but since we use 101 sharing, later, to refer to the sharing of memory words in an implementation, we call his domain combined coupling, or simply, CC. <p> If V had a value of f (D,E,F) instead, X and Y would not become aliased. To detect this, it is necessary to know when a variables value contains multiple occurrences of some variable (as is the case with V). Langen called these variables nonlinear <ref> [48] </ref>. Jones and Sondergaard called them reocc (repeated occurrence) variables [42]. Janssens called them NUNI (for Not-UNIque) variables [40]. Knowledge of linearity is very important during predicate calling/returning. <p> A 7 Citrin [12] WC 2 SC 2 This improves on SDDA by adding strong coupling classes. A 8 Langen [36] CC This captures both weak and strong coupling in a single, combined representation which is more expressive than both combined. A 9 Langen <ref> [48] </ref> CC L This adds linearity in order to keep the information more precise (and computationally feasible). It also includes M 2 . A 10 None CC L E 2 This adds equivalence.
Reference: [49] <author> B. Le Charlier and P. Van Hentenryck. </author> <title> Experimental Evaluation of a Generic Abstract Interpretation Algorithm for Prolog. </title> <type> Technical Report No. </type> <institution> CS-91-55, Brown University, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: It is parameterized by seven primitive operations, which includes an abstraction of explicit unification. 60 3.3.5 A Generic Interpreter Le Charlier and Van Hentenryck developed a generic abstract interpretation algorithm very similar to Bruynooghes <ref> [49] </ref>. Unlike Bruynooghes, this algorithm constructs an extension table of results. The required set of operations, however, are almost the same as those described by Janssens and Bruynooghe [9]. <p> The first goal in the development of the framework for compilation is to develop a generic abstract interpreter for dataflow analysis. This basic framework is similar to, for example, the generic abstract interpretation algorithm given by Le Charlier and Van Hentenryck <ref> [49] </ref>. To this, we add the functions needed by the compiler. 4.2 Basic Abstract Domain Operations The first thing that must be defined is the abstract domain. <p> This is the most often described form of analysis <ref> [8, 10, 27, 49, 54, 59, 61, 67, 69, 78, 84] </ref>, probably because it is one of the easiest to understand and provides very useful information. As we saw previously, many optimizations depend on knowing the modes of variables. <p> Rather than being a collection of modes chosen for some unknown reason, however, a more methodical approach was taken <ref> [49] </ref>. This domain begins by partitioning all possible values into a number of mutually exclusive, all covering sets: ground, unbound (var), and all others (ngv). The abstract domain is now formed by taking the powerset of the set, -ground, var, ngv-, ordered by subset.
Reference: [50] <author> B. Le Charlier, K. Musumbu, and P. Van Hentenryck. </author> <title> Efficient and Accurate Algorithms for the Abstract Interpretation of Prolog Programs. </title> <note> Research Paper No. </note> <institution> RP-90/9, University of Namur, Belgium, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: This may provide a significant speedup to the analysis phase. There are also other ways to attack the analysis time issue <ref> [50, 77] </ref>. Abstract Domains Some work remains to be done in exploring the taxonomy of abstract domains presented here. Fully recursive types (T 4 ) deserve more investigation to see if they have a substantial payback, as well as to find ways to reduce the analysis time.
Reference: [51] <author> B. Le Charlier and P. Van Hentenryck. </author> <title> Reexecution in Abstract Interpretation of Prolog. </title> <type> Technical Report No. </type> <institution> CS-92-12, Brown University. </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: More attention has been given to the use of this algorithm as part of a Prolog compiler, however. We dont claim that this is the most efficient algorithm. The techniques employed by Le Charlier and Van Hentenryck <ref> [51] </ref> and Tan and Lin [77] could be used to improve the performance of this algorithm. Global information used during the analysis is described in Table 22.
Reference: [52] <author> J. Lloyd. </author> <title> Foundations of Logic Programming, </title> <publisher> Springer-Verlag 1987. </publisher>
Reference-contexts: E P g g D P (d) g (d) --,0,+- -- -0 -+- 52 3.2 Abstract Interpretation of Prolog For Prolog, E P is typically defined to be the standard top-to-bottom, left-to-right operational semantics of Prolog, based on SLD-resolution <ref> [52, 42] </ref>. D P usually represents sets of possible substitutions for the program variables. <p> In other words, these analyses capture abstract properties describing Implementation Independent Determinacy Implementation Dependent Variable level Data Flow Analyses Predicate level Local Stack Use Trailing Reference Chains Access Aliasing Sharing Types Modes 86 the possible substitutions that occur during execution in the standard operational (SLD-resolution) semantics <ref> [42, 52] </ref>. 5.1.1 Mode Analysis Mode analysis attempts to determine the degree of instantiation of each variable.
Reference: [53] <author> A. Marien and B. Demoen. </author> <title> On the Management of Choicepoint and Environment Frames in the WAM. </title> <booktitle> In Logic Programming: Proceedings of the North American Conference 1989, </booktitle> <pages> pp. 1030-1047, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: This concept is less dependent on the use of cuts and extends easily to parallel logic languages. 117 5.3.2 Local Stack Analysis Many implementations of the WAM and the BAM place both environments and choicepoints onto a single stack, called the local stack <ref> [53] </ref>. If it is known what objects are added to the stack, there are a number of optimizations (already described) that can be applied. For example, environments and choicepoints can be reused [60].
Reference: [54] <author> A. Marien, G. Janssens, A. Mulkers, and M. Bruynooghe. </author> <title> The impact of abstract interpretation: an experiment in code generation. </title> <booktitle> In Logic Programming: Proceedings of the 6th International Conference, </booktitle> <pages> pp. 33-47, </pages> <month> June </month> <year> 1989. </year> <month> 154 </month>
Reference-contexts: This is the most often described form of analysis <ref> [8, 10, 27, 49, 54, 59, 61, 67, 69, 78, 84] </ref>, probably because it is one of the easiest to understand and provides very useful information. As we saw previously, many optimizations depend on knowing the modes of variables. <p> Domain M 3 extends domain M 1 with the state where a variable is known to be bound (nonvar), but not necessarily ground. Domain M 4 combines the information from domains M 1 and M 2 <ref> [8, 10, 54, 27] </ref>. Domain M 5 adds all of these states [84]. Domain M 6 extends domain M 5 even further by adding the state where a variable is bound to a compound term, but all of the arguments are unbound [61]. <p> Reference Chain Domain R 5 Domain R 5 , proposed by Marin et al., provides even more levels by describing a reference chain as having a minimum and maximum length <ref> [54] </ref>. For example, 1..3 would describe a reference chain that had between 1 and 3 links. <p> The minimum is limited by zero, but there is no limit on the maximum length. It is not clear, therefore, how to keep this domain finite. One partial solution, given in <ref> [54] </ref>, is to always reduce the length of a chain by the minimum before calling a predicate. Therefore, the minimum at predicate entry will always be zero.
Reference: [55] <author> K. Marriott and H. Sndergaard. </author> <title> Bottom-up Abstract Interpretation of Logic Programs. </title> <booktitle> In Logic Programming: Proceedings of the 5th International Conference and Symposium, </booktitle> <pages> pp. 733-748. </pages> <year> 1988. </year>
Reference: [56] <author> K. Marriott and H. Sndergaard. </author> <title> On Prolog and the Occur Check Problem. </title> <journal> In ACM SIGPLAN Notices 24:5, </journal> <pages> pp. 76-82, </pages> <month> May </month> <year> 1989. </year>
Reference: [57] <author> K. Marriott and H. Sndergaard. </author> <title> Analysis of Constraint Logic Programs. </title> <booktitle> In Proceedings of the North American Conference on Logic Programming '90, </booktitle> <pages> pp. 531-547, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: Clause_Info This is the static analysis information for the clause currently being analyzed. It is available for use in the abstract operation. Table 22: Global Information in the Analysis Algorithm Name/Type Description 85 Chapter 5: Prolog Analysis Numerous abstract domains have been proposed to capture various properties <ref> [9, 27, 36, 40, 48, 57, 61, 78, 84] </ref>. We have constructed a taxonomy, shown in Figure 30, to organize these properties. The properties have been grouped into three broad categories: implementation-independent variable analyses, implementation-dependent variable analyses, and predicate-level analyses. <p> There are interesting variants of and extensions to Prolog that may have new abstract domains to be discovered. Constraint logic programming is an example of this, where domains might capture definiteness and freeness of variables <ref> [57] </ref>. Another major direction should be towards automatic parallelization of Prolog and investigation into concurrent logic languages.
Reference: [58] <author> K. Marriott, H. Sondergaard, and P. </author> <title> Dart. A Characterization of Non-Floundering Logic Programs. </title> <booktitle> In Proceedings of the North American Conference on Logic Programming '90, </booktitle> <pages> pp. 661-680. </pages> <year> 1990. </year>
Reference: [59] <author> H. Mannila and E. Ukkonen. </author> <title> Flow Analysis of Prolog Programs. </title> <booktitle> In 1987 IEEE Symposium on Logic Programming, </booktitle> <pages> pp. 205-214, </pages> <year> 1987. </year>
Reference-contexts: This is the most often described form of analysis <ref> [8, 10, 27, 49, 54, 59, 61, 67, 69, 78, 84] </ref>, probably because it is one of the easiest to understand and provides very useful information. As we saw previously, many optimizations depend on knowing the modes of variables. <p> Mode Domains M 1 and M 2 Abstract domains M 1 and M 2 are the simplest of mode domains, capturing the set of variables that are definitely a given mode at some program point <ref> [59, 67, 69] </ref>. M 1 captures definitely ground variables; this is the groundness domain that was used as an example in the previous chapter. M 2 captures definitely unbound variables. These domains are good examples of domains capturing some boolean property for variables.
Reference: [60] <author> M. Meier. </author> <title> Recursion vs. Iteration in Prolog. </title> <booktitle> In Proceedings of the Eighth International Conference on Logic Programming, </booktitle> <pages> pp. 157-169, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: If it is known what objects are added to the stack, there are a number of optimizations (already described) that can be applied. For example, environments and choicepoints can be reused <ref> [60] </ref>. This is also related to the determinacy analysis just described, for determining when a predicate leaves a choicepoint on the stack. This information cannot be captured effectively at the level of Prolog; there is too much imprecision.
Reference: [61] <author> C. Mellish. </author> <title> Automatic Generation of Mode Declarations for Prolog Programs (Draft). </title> <type> DAI Research Paper 163, </type> <institution> Dept. of Artificial Intelligence, University of Edinburgh, </institution> <month> August </month> <year> 1981. </year>
Reference-contexts: Cousot and Cousot provided a unified view of these and other data flow analyses with a technique they called abstract interpretation [17]. Since then, many researchers have applied this technique to the analysis of logic programs <ref> [24, 48, 61, 63, 80, 84] </ref>. 3.1.1 Overview Abstract interpretation provides a good theoretical model in which a large number of program analyses may be performed. Attempting to analyze a program by simulating its execution for all possible inputs is, in general, unsolvable. <p> During analysis, this indicates portions of code that have not yet been analyzed. When the analysis is complete, it indicates portions of code that are unreachable. 3.3 Abstract Interpretation Frameworks Originally, analyzers were built for specific abstract domains <ref> [27, 61] </ref>. The attraction of abstract interpretation, however, was that it allowed data flow analysis to be parameterized by the abstract domain. This was used in later work to define abstract interpretation frameworks in which a number of analyses could be described [42, 10, 67, 87, 43]. <p> Clause_Info This is the static analysis information for the clause currently being analyzed. It is available for use in the abstract operation. Table 22: Global Information in the Analysis Algorithm Name/Type Description 85 Chapter 5: Prolog Analysis Numerous abstract domains have been proposed to capture various properties <ref> [9, 27, 36, 40, 48, 57, 61, 78, 84] </ref>. We have constructed a taxonomy, shown in Figure 30, to organize these properties. The properties have been grouped into three broad categories: implementation-independent variable analyses, implementation-dependent variable analyses, and predicate-level analyses. <p> This is the most often described form of analysis <ref> [8, 10, 27, 49, 54, 59, 61, 67, 69, 78, 84] </ref>, probably because it is one of the easiest to understand and provides very useful information. As we saw previously, many optimizations depend on knowing the modes of variables. <p> Domain M 5 adds all of these states [84]. Domain M 6 extends domain M 5 even further by adding the state where a variable is bound to a compound term, but all of the arguments are unbound <ref> [61] </ref>. Table 23: Mode Definitions for a variable, X Mode Description Concretization: g (X) any X could be anything. Term ground X is ground. - T | var (T) = - nonvar X is not unbound. - T | T Var - var X is unbound.
Reference: [62] <author> C. Mellish. </author> <title> Abstract Interpretation of Prolog Programs. </title> <booktitle> In Proceedings of the Third International Conference on Logic Programming, </booktitle> <pages> pp. 463-474, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: Predicate level analyses collect information about attributes of predicates. This might be a boolean flag for each predicate, or something more complex. The following sections describe a number of attributes like this. 116 Although abstract interpretation can be used to capture predicate-level information <ref> [62] </ref>, this is probably not the most efficient technique. Consider, for example, attempting to detect the set of recursive predicates. This can be done by performing a transitive closure on the call graph and then collecting the set of predicates that eventually call themselves.
Reference: [63] <author> C. Mellish. </author> <title> Some Global Optimizations for a Prolog Compiler. </title> <journal> In Journal of Logic Programming, </journal> <volume> Vol 2, </volume> <pages> pp. 43-66, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: Cousot and Cousot provided a unified view of these and other data flow analyses with a technique they called abstract interpretation [17]. Since then, many researchers have applied this technique to the analysis of logic programs <ref> [24, 48, 61, 63, 80, 84] </ref>. 3.1.1 Overview Abstract interpretation provides a good theoretical model in which a large number of program analyses may be performed. Attempting to analyze a program by simulating its execution for all possible inputs is, in general, unsolvable. <p> Abstract interpretation is still a good technique to use for proving the correctness of predicate-level analyses. 5.3.1 Determinacy Analysis Mellish defines a predicate to be determinate if it will never return more than one solution <ref> [63] </ref>. It may succeed or fail, but will never be able to return alternate solutions through backtracking. In terms of an implementation, this means that the predicate does not leave a choicepoint on the stack. <p> This will never return more than one solution, but must be backtracked to in order for the side-effects to occur. Mellish uses determinacy information to generate a different kind of call instruction, but then he had a virtual machine, named POPLOG <ref> [63] </ref>, which is very different from the WAM. Taylor used determinacy information to reduce variable trailing [78]. Any variable being bound which was created after the current choicepoint was created does not need to be trailed.
Reference: [64] <author> F. Morris. </author> <title> On a Comparison of Garbage Collection Techniques. </title> <journal> In Communications of the ACM, </journal> <volume> 22(10), </volume> <pages> page 571, </pages> <month> October </month> <year> 1979. </year>
Reference: [65] <author> K. Muthukumar and M. Hermenegildo. </author> <title> Determination of Variable Dependence Information Through Abstract Interpretation. </title> <booktitle> In Proceedings of the North American Conference on Logic Programming '89, </booktitle> <pages> pp. 166-185, </pages> <month> August </month> <year> 1989. </year> <month> 155 </month>
Reference-contexts: To correct this, it is necessary to assume that instantiations occurring to some variables may further instantiate other variables aliased with the modified variables. Aliasing analysis can restrict the scope of these changes by determining what aliasing exists between variables. In addition to improving mode and type information <ref> [65] </ref>, aliasing analysis can be used in its own right for automatic parallelization of Prolog code [9] and removal of occur-check from unification (or detection of where occur-checks may be needed, since most Prolog implementation dont perform occur-checks during unification) [42].
Reference: [66] <author> A. Mulkers, W. Winsborough, and M. Bruynooghe. </author> <title> Analysis of Shared Data Structures for Compile-Time Garbage Collection in Logic Programs. </title> <booktitle> In Logic Programming: Proceedings of the 7th International Conference, </booktitle> <pages> pp. 747-762. </pages> <publisher> MIT Press. </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: The definite sharing domain can describe the following: X PART Y: Variable X is certainly a part (not the whole) of Y. Sharing Domain S 2 Mulkers et al. provided a more elegant description for a sharing domain <ref> [66] </ref>. In addition, they describe an instrumented concrete semantics, which captures actual sharing occurring in both structure copying and structure sharing implementations. They use this semantics to prove the correctness of their abstract semantics.
Reference: [67] <author> U. Nilsson. </author> <title> Towards a Framework for the Abstract Interpretation of Logic Programs. </title> <booktitle> In Lecture Notes in Computer Science, Vol. 348 (Programming Languages Implementation and Logic Programming International Workshop '88), </booktitle> <pages> pp. 68-82, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: The attraction of abstract interpretation, however, was that it allowed data flow analysis to be parameterized by the abstract domain. This was used in later work to define abstract interpretation frameworks in which a number of analyses could be described <ref> [42, 10, 67, 87, 43] </ref>. There are three basic pieces that together form an abstract interpretation, as illustrated in Figure 20: An abstract domain (for example, the mode domain shown in Figure 19). A specific collection of operations defined over the values of the abstract domain. <p> It can record, for each clause, an abstraction of the set of substitutions with which that clause is called. What (if anything) is actually recorded is up to the abstract operation implementor (as specified in the newlog operation). 58 3.3.3 A Theoretical Framework Nilsson described a theoretical framework <ref> [67] </ref> which is very similar to that of Jones and Sndergaard [42]. The main difference is that the proof of correctness is more rigorous. The same groundness example that was used in [42] is used to illustrate this framework. <p> This is the most often described form of analysis <ref> [8, 10, 27, 49, 54, 59, 61, 67, 69, 78, 84] </ref>, probably because it is one of the easiest to understand and provides very useful information. As we saw previously, many optimizations depend on knowing the modes of variables. <p> Mode Domains M 1 and M 2 Abstract domains M 1 and M 2 are the simplest of mode domains, capturing the set of variables that are definitely a given mode at some program point <ref> [59, 67, 69] </ref>. M 1 captures definitely ground variables; this is the groundness domain that was used as an example in the previous chapter. M 2 captures definitely unbound variables. These domains are good examples of domains capturing some boolean property for variables.
Reference: [68] <author> R. OKeefe. </author> <title> Finite Fixed-Point Problems. </title> <booktitle> In Logic Programming: Proceedings of the 4th International Conference, </booktitle> <pages> pp. 729-743. </pages> <month> May </month> <year> 1987. </year>
Reference: [69] <author> T. Pabst, </author> <title> Dataflow Analysis and Modular Logic Programs. </title> <address> Diplomar-beit, TU-Berlin, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: The following sections describe some of these frameworks, in order to show some of the options available when defining an abstract interpreter. 3.3.1 A Simple Framework The simplest framework, described by Jacobs <ref> [36, 69] </ref>, requires that only two operations be defined: init : Clause fi Desc pass : Term Desc Term Desc fi Desc init provides an initial description for a clause. <p> Prolog Source Code Annotated Source Code Abstract Interpreter (implements Prolog semantics, abstractly) Abstract Operations Implementation Abstract Domain: Abstract Operations 55 pass models unification, returning the description obtained from passing information from one term to another. pass is defined formally in <ref> [69] </ref>. pass is used both to pass information from a call term into a clause and to return the result after analysis of the clause. interpretation. <p> (X) tests if X is a recursive list, terminated by nil ([]). 78 4.7 The Analysis Algorithm This section presents the dataflow analysis algorithm, which makes use of the operations described in the previous sections to provide a generic abstract interpreter similar to that given by Jacobs [38] and Pabst <ref> [69] </ref>. More attention has been given to the use of this algorithm as part of a Prolog compiler, however. We dont claim that this is the most efficient algorithm. <p> This is the most often described form of analysis <ref> [8, 10, 27, 49, 54, 59, 61, 67, 69, 78, 84] </ref>, probably because it is one of the easiest to understand and provides very useful information. As we saw previously, many optimizations depend on knowing the modes of variables. <p> Mode Domains M 1 and M 2 Abstract domains M 1 and M 2 are the simplest of mode domains, capturing the set of variables that are definitely a given mode at some program point <ref> [59, 67, 69] </ref>. M 1 captures definitely ground variables; this is the groundness domain that was used as an example in the previous chapter. M 2 captures definitely unbound variables. These domains are good examples of domains capturing some boolean property for variables.
Reference: [70] <author> D. Plaisted. </author> <title> The Occur-Check Problem in Prolog. </title> <booktitle> In Proceedings of the 1984 International Symposium on Logic Programming, </booktitle> <pages> pp. 272-280, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: They then use this framework to present three abstract interpretations: one for collecting groundness information, one for collecting variable aliasing information, and a combination of the two useful in detecting unifications that may need an occur check <ref> [70] </ref>. Their framework is interesting in that it requires two related domains, as opposed to the single abstract domain required by most others. The two domains, Csub and Asub, abstractly represent substitutions and sets of substitutions, respectively.
Reference: [71] <author> C. Ponder, P. McGeer, and A. Ng. </author> <booktitle> Are Applicative Languages Inefficient? In ACM SIGPLAN Notices 23:6, </booktitle> <pages> pp. 135-139, </pages> <month> June </month> <year> 1988. </year>
Reference: [72] <author> G. Ringwood. </author> <title> SLD: </title> <journal> A Folk Acronym? In ACM SIGPLAN Notices 24:5, </journal> <pages> pp. 71-75, </pages> <month> May </month> <year> 1989. </year>
Reference: [73] <author> P. Schnupp and L. Bernhard. </author> <title> Productive Prolog Programming. </title> <publisher> Pren-tice Hall, </publisher> <year> 1987. </year>
Reference: [74] <author> H. Seki and K. Furukawa. </author> <title> Notes on Transformation Techniques For Generate and Test Logic Programs. </title> <booktitle> In 1987 IEEE Symposium on Logic Programming, </booktitle> <pages> pp. 215-223, </pages> <year> 1987. </year>
Reference: [75] <author> Z. Somogyi. </author> <title> A system of precise modes for logic programs. </title> <booktitle> In Logic Programming: Proceedings of the 4th International Conference, </booktitle> <pages> pp. 769-787. </pages> <month> May </month> <year> 1987.. </year>
Reference-contexts: Constraint logic programming is an example of this, where domains might capture definiteness and freeness of variables [57]. Another major direction should be towards automatic parallelization of Prolog and investigation into concurrent logic languages. These languages have their own set of modes, for example Inbound, Outbound, Infree and Outfree <ref> [75] </ref>. 7.3 Summary In this research, we set out to show that a significant performance increase could be obtained in Prolog execution through a good selection of global data flow analyses driving compiler optimizations.
Reference: [76] <author> H. Tamaki and T. Sato. </author> <title> OLD Resolution with Tabulation. </title> <booktitle> In Proceedings of the 3rd International Conference on Logic Programming, </booktitle> <pages> pp. 84-98. </pages> <year> 1986. </year>
Reference: [77] <author> J. Tan and I. Lin. </author> <title> Compiling Dataflow Analysis of Logic Programs. </title> <note> (Unpublished) 1992. 156 </note>
Reference-contexts: More attention has been given to the use of this algorithm as part of a Prolog compiler, however. We dont claim that this is the most efficient algorithm. The techniques employed by Le Charlier and Van Hentenryck [51] and Tan and Lin <ref> [77] </ref> could be used to improve the performance of this algorithm. Global information used during the analysis is described in Table 22. <p> Taylor was the first to propose a type domain of this class [78, 80]; we refer to this domain as T 3a . Tan and Lin later proposed a simpler version which had fewer atomic types and limited recursive lists to nil-terminated lists <ref> [77] </ref>; we refer to this domain as T 3b . We propose a third version of this domain, which goes the other direction, adding types which improve the detection of the data tags for variables. We refer to this domain as T 3c . <p> Type domain T 3c also allows a more abstract representation for structures with the types struct and gndstr. In order to keep these domains finite, nested type specifications are depth limited. Both Taylor [80] and Tan and Lin <ref> [77] </ref> limit nested types to a depth of four. Type Domain T 4 Type domain T4 is the most expressive of the type domains. It captures fully recursive types and type intersections by defining type graphs or type expressions. <p> This may provide a significant speedup to the analysis phase. There are also other ways to attack the analysis time issue <ref> [50, 77] </ref>. Abstract Domains Some work remains to be done in exploring the taxonomy of abstract domains presented here. Fully recursive types (T 4 ) deserve more investigation to see if they have a substantial payback, as well as to find ways to reduce the analysis time. <p> This limited the number and size of benchmarks we could use and the number of experiments we could perform. Tan and Lin report a decrease in analysis time by two orders of magnitude <ref> [77] </ref>. They claim this is due to a technique called abstract compilation, in 146 which the program to be analyzed is first compiled (into a WAM-like program) and the compiled program is then used to drive the analyzer. 2 Providing the abstract operations for an abstract domain can be tedious.
Reference: [78] <author> A. Taylor. </author> <title> Removal of Dereferencing and Trailing in Prolog Compilation. </title> <booktitle> In Logic Programming: Proceedings of the 6th International Conference, </booktitle> <pages> pp. 48-60, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Clause_Info This is the static analysis information for the clause currently being analyzed. It is available for use in the abstract operation. Table 22: Global Information in the Analysis Algorithm Name/Type Description 85 Chapter 5: Prolog Analysis Numerous abstract domains have been proposed to capture various properties <ref> [9, 27, 36, 40, 48, 57, 61, 78, 84] </ref>. We have constructed a taxonomy, shown in Figure 30, to organize these properties. The properties have been grouped into three broad categories: implementation-independent variable analyses, implementation-dependent variable analyses, and predicate-level analyses. <p> This is the most often described form of analysis <ref> [8, 10, 27, 49, 54, 59, 61, 67, 69, 78, 84] </ref>, probably because it is one of the easiest to understand and provides very useful information. As we saw previously, many optimizations depend on knowing the modes of variables. <p> Taylor was the first to propose a type domain of this class <ref> [78, 80] </ref>; we refer to this domain as T 3a . Tan and Lin later proposed a simpler version which had fewer atomic types and limited recursive lists to nil-terminated lists [77]; we refer to this domain as T 3b . <p> Although this doesnt improve performance over Van Roys lattice, it does allow the same performance with a sound treatment of reference chains. Reference Chain Domain R 4 Domain R 4 , proposed by Taylor, captures more categories of chains and allows different descriptions for different arguments of compound values <ref> [78] </ref>. To support this, it needs to be combined with a type domain which allows non-flat types to be captured, for example T 3c . He categorized reference chains based on implementation issues, as seen below: 0: The reference chain is of length 0 (i.e., no reference chain). <p> Trailing analysis indicates when variables definitely do or do not need to be trailed during operations which may (or do) bind them <ref> [78] </ref>. Obviously, a variable does not need to be trailed if it is already bound. In addition, a variable does not need to be trailed if it can be shown that the variable was created after the current choicepoint. This requires predicate-level knowledge, which will be addressed later. <p> The domain is the powerset of the set of variables, ordered by subset. Each element identifies the set of variables which can safely be bound without trailing (i.e., they are newer than the latest choicepoint). Taylor proposed this domain in conjunction with his type domain (T 3a ) <ref> [78] </ref>. He allowed any possibly unbound places in the type description to be annotated with a trailing not needed flag. Trailing Domain TR 2 Trailing domain TR 1 attempts to eliminate unneeded trailing operations. <p> Mellish uses determinacy information to generate a different kind of call instruction, but then he had a virtual machine, named POPLOG [63], which is very different from the WAM. Taylor used determinacy information to reduce variable trailing <ref> [78] </ref>. Any variable being bound which was created after the current choicepoint was created does not need to be trailed. Debray and Warren extend the idea of determinacy to the concept of functional predicates [26]. <p> It may be necessary to perform abstract interpretation of the intermediate code in order to get a usable approximation of this type of information. Choicepoint Creation In order to perform precise trailing analysis, it is necessary to know when predicates can generate choicepoints <ref> [78] </ref>. Taylor does this at the Prolog level and claims to get good results. Better results could be obtained at the intermediate code level, where the choicepoint instructions actually exist. The domain for this is boolean, capturing those predicates which definitely do not create a choicepoint.
Reference: [79] <author> A. Taylor. </author> <title> LIPS on a MIPS: Results from a Prolog Compiler for a RISC. </title> <booktitle> In Logic Programming: Proceedings of the 7th International Conference, </booktitle> <month> June </month> <year> 1990. </year>
Reference: [80] <author> A. Taylor. </author> <title> High Performance Prolog Implementation. </title> <type> PhD Thesis. </type> <institution> University of Sydney, </institution> <month> June </month> <year> 1991. </year>
Reference-contexts: Cousot and Cousot provided a unified view of these and other data flow analyses with a technique they called abstract interpretation [17]. Since then, many researchers have applied this technique to the analysis of logic programs <ref> [24, 48, 61, 63, 80, 84] </ref>. 3.1.1 Overview Abstract interpretation provides a good theoretical model in which a large number of program analyses may be performed. Attempting to analyze a program by simulating its execution for all possible inputs is, in general, unsolvable. <p> Type Domain T 1 The first type domain is a flat type domain with no or types. This is similar to the mode domains, in that there are a collection of distinct types, ordered in a lattice. Taylor described such a domain <ref> [80] </ref>. The lattice for his types is shown in Figure 34. These lattice elements are described in Table 24. The similarity to domain M 5 should be noted. <p> Taylor was the first to propose a type domain of this class <ref> [78, 80] </ref>; we refer to this domain as T 3a . Tan and Lin later proposed a simpler version which had fewer atomic types and limited recursive lists to nil-terminated lists [77]; we refer to this domain as T 3b . <p> Structure types specify the functor of the structure and the types of the arguments. Type domain T 3c also allows a more abstract representation for structures with the types struct and gndstr. In order to keep these domains finite, nested type specifications are depth limited. Both Taylor <ref> [80] </ref> and Tan and Lin [77] limit nested types to a depth of four. Type Domain T 4 Type domain T4 is the most expressive of the type domains. It captures fully recursive types and type intersections by defining type graphs or type expressions. <p> This is most useful when combined with a non-flat type domain, providing some structure to variable values to which this equivalence relationship can be attached. Taylor included equivalence within the type descriptions, but only for unbound variables and structure arguments <ref> [80] </ref>. Janssens provided the equivalence information separately from the types by specifying sets of selectors for equivalent values [40]. These selectors allowed a variable to be selected or some part of the structure of a variable (e.g., the head of a list). <p> This reduces the size of the code and the trail. This occurs frequently when variables are passed to predicates which will bind them (i.e., they are output variables). Taylor achieved this by deferring initialization of variables known to be unbound and unaliased <ref> [80] </ref>. older any newer ^ 113 Van Roy took a more aggressive approach, relaxing the aliasing restriction [84]. <p> Besides, as the size of the benchmark suite grows, this reduces the number of tests we can perform. The benchmarks chosen are those used by Van Roy [86] and Taylor <ref> [80] </ref>. They are described in Table 30. See Appendix D for source code. 6.2 Evaluation Measures As with benchmark selection, there are no universally agreed upon measures to use when comparing two systems. <p> This consists of the following node labels, with the obvious meanings: nonvar, structure, ground, ground_structure, and atom. 137 6.5 Comparison with Parma In this section, we compare our results with those reported by Taylor <ref> [80] </ref>. The goal of his Parma compiler, developed about the same time as Van Roys Aquarius, was to show that high performance execution of Prolog could be obtained on a modern generalpurpose architecture (the MIPS R3000). The Parma compiler was not available for measurements. <p> The Parma compiler was not available for measurements. Therefore, the performance measures for Taylors Parma system come from his dissertation <ref> [80] </ref>. There are some problems with this: The figures may not be exact since Parmas performance figures were given relative to the performance of SICStus Prolog running on a 25 MHz R3230. Parmas performance has to be computed from these relative figures.
Reference: [81] <author> A. Thayes. </author> <title> From Standard Logic to Logic Programming. </title> <publisher> John Wiley & Sons Ltd. </publisher> <year> 1988. </year>
Reference: [82] <author> H. Touati and A. Despain. </author> <title> An empirical study of the Warren Abstract Machine. </title> <booktitle> In Proceedings of the 1987 Symposium on Logic Programming, </booktitle> <pages> pp. 114-124. </pages> <address> San Francisco 1987. </address>
Reference-contexts: We have found that nearly 93% of all dereference operations have no pointer chain to follow on the BAM. This is consistent with Touatis findings on the WAM <ref> [82] </ref>. Reference chain analysis attempts to determine at compile time, the length of the pointer chain for each variable. 107 This section describes a number of abstract domains used to approximate this information. <p> Therefore, the minimum at predicate entry will always be zero. Also, it is unlikely that this adds much performance over R 4 , since only a fraction of a percent of reference chains ever exceed a length of one <ref> [82] </ref>. 1. Marin et al. combined R 5 with T 4 , but other type domains could be used. 111 5.2.3 Trailing Analysis Another basic operation in Prolog is trailing of variables in order to restore the program state during backtracking.
Reference: [83] <author> P. Van Roy. </author> <title> A Useful Extension to Prologs Definite Clause Grammar Notation. </title> <journal> In ACM SIGPLAN Notices, </journal> <volume> Volume 24, No. 11, </volume> <pages> pp. 132-134. </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: The analysis framework is written in Prolog, as is the rest of the compiler, making use of Van Roys Extended Definite Clause Grammer (EDCG) notation to provide a form of global variables, while maintaining an applicative programming style <ref> [83] </ref>. When describing abstract operations in the following sections, the global information available to that operation is also described. The first goal in the development of the framework for compilation is to develop a generic abstract interpreter for dataflow analysis.
Reference: [84] <author> P. Van Roy. </author> <title> Can Logic Programming Execute as Fast as Imperative Programming?. </title> <type> Ph.D. Thesis, </type> <institution> University of California, Berkeley, </institution> <note> Report UCB/CSD #90/600, </note> <month> December </month> <year> 1990. </year>
Reference-contexts: Cousot and Cousot provided a unified view of these and other data flow analyses with a technique they called abstract interpretation [17]. Since then, many researchers have applied this technique to the analysis of logic programs <ref> [24, 48, 61, 63, 80, 84] </ref>. 3.1.1 Overview Abstract interpretation provides a good theoretical model in which a large number of program analyses may be performed. Attempting to analyze a program by simulating its execution for all possible inputs is, in general, unsolvable. <p> There is little value, therefore, in saving more than a single pair of entry/exit descriptions per predicate. The compiler performs certain source transformations before (e.g., transformation to Kernel Prolog <ref> [84] </ref> and clause factoring) and after (e.g., determinism extraction) global dataflow analysis. The transformations occurring before the analysis affect the assumptions that can be made by the abstract interpreter about the code it receives. <p> In addition to these, the user is allowed to describe predicates defined in source files other than the one being compiled. Externally-defined user predicates are described by providing Aquarius mode declarations <ref> [84] </ref>. These declarations describe the expected entry conditions for the predicate and the conditions that will be true when the predicate completes. These mode declarations are used to construct two descriptions: a head description (similar to those returned by abs_int_entry) and a tail description (similar to those given to abs_int_exit). <p> These operations provide support for user-specified starting points for analysis and allow the code generator to extract information from the analysis results. 4.6.1 Interpreting Mode Formulas In order to construct the tables described previously for built-in and user-described predicates, it is necessary to convert Aquarius mode formulas <ref> [84] </ref> into head and tail Table 17: Arguments for prepare_clause/5 Argument: Description: Head The canonical head of the predicate. This is the same term passed to abs_int_entry and abs_int_exit. Body The body of the clause, as a conjunction of goals, terminated with the atom true. <p> Clause_Info This is the static analysis information for the clause currently being analyzed. It is available for use in the abstract operation. Table 22: Global Information in the Analysis Algorithm Name/Type Description 85 Chapter 5: Prolog Analysis Numerous abstract domains have been proposed to capture various properties <ref> [9, 27, 36, 40, 48, 57, 61, 78, 84] </ref>. We have constructed a taxonomy, shown in Figure 30, to organize these properties. The properties have been grouped into three broad categories: implementation-independent variable analyses, implementation-dependent variable analyses, and predicate-level analyses. <p> This is the most often described form of analysis <ref> [8, 10, 27, 49, 54, 59, 61, 67, 69, 78, 84] </ref>, probably because it is one of the easiest to understand and provides very useful information. As we saw previously, many optimizations depend on knowing the modes of variables. <p> Domain M 3 extends domain M 1 with the state where a variable is known to be bound (nonvar), but not necessarily ground. Domain M 4 combines the information from domains M 1 and M 2 [8, 10, 54, 27]. Domain M 5 adds all of these states <ref> [84] </ref>. Domain M 6 extends domain M 5 even further by adding the state where a variable is bound to a compound term, but all of the arguments are unbound [61]. Table 23: Mode Definitions for a variable, X Mode Description Concretization: g (X) any X could be anything. <p> Reference Chain Domain R 1 Domain R 1 is the simplest reference chain domain. This is a boolean domain capturing those variables which are definitely dereferenced (contain no pointer chain to the top-level value). Reference Chain Domain R 2 Domain R 2 was described by Van Roy <ref> [84] </ref>. The lattice for each variable consists of the following set of values (listed in order): -any, deref, rderef-. These values have the following meaning: any: Nothing is known about the references chains for a variable, either at the top-level or for the arguments. <p> This occurs frequently when variables are passed to predicates which will bind them (i.e., they are output variables). Taylor achieved this by deferring initialization of variables known to be unbound and unaliased [80]. older any newer ^ 113 Van Roy took a more aggressive approach, relaxing the aliasing restriction <ref> [84] </ref>. He does assume, however, that the uninitialized variable will be at the end of any reference chain created during unification (if not, the variable would have to be initialized to know when the chain ended). <p> Uninit_Reg Analysis In addition to deferring initialization of variables, Van Roy attempts to defer their allocation when their first use is as an argument to a call which binds the variable, using a technique he calls uninitialized register arguments <ref> [84] </ref>. In all Prolog implementations we have seen, all arguments are passed in to a called predicate. <p> This is the case except for when comparing domains M 3 or M 4 with M 5 . At this point, the code size increases. The reason for this is that M 5 is the simplest domain for which mode enrichment <ref> [84] </ref> can be performed. This optimization reduces execution time, but does so by increasing code size. Compilation time is a little more complex since it consists of several parts: source preparation time, analysis time, code generation time, and code optimization time.
Reference: [85] <author> P. Van Roy, B. Demoen, and Y. D. Willems. </author> <title> Improving the Execution Speed of Compiled Prolog with Modes, Clause Selection, and Determinism. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> Vol. 250 (TAPSOFT '87), </volume> <pages> pp. 111-125, </pages> <month> March </month> <year> 1987. </year>
Reference: [86] <author> P. Van Roy and A. Despain. </author> <title> High-Performance Logic Programming with the Aquarius Prolog Compiler. </title> <booktitle> In Computer, </booktitle> <pages> pp. 54-68, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: Besides, as the size of the benchmark suite grows, this reduces the number of tests we can perform. The benchmarks chosen are those used by Van Roy <ref> [86] </ref> and Taylor [80]. They are described in Table 30. See Appendix D for source code. 6.2 Evaluation Measures As with benchmark selection, there are no universally agreed upon measures to use when comparing two systems. <p> This version is available by sending e-mail to listserv@acal-server.usc.edu. In addition to a number of bug fixes since Van Roys dissertation was written (in 1990), support has been added for floating point and garbage collection, features not available when he performed measurements on the SPARC <ref> [86] </ref>. Table 31 shows performance figures for the benchmarks compiled by Aquarius Prolog. The first column shows the compilation time, in seconds. The next two columns show the global analysis time, in seconds and 124 as a percentage of the compilation time.
Reference: [87] <author> A. Wrn. </author> <title> An Implementation Technique for the Abstract Interpretation of Prolog. </title> <booktitle> In Logic Programming: Proceedings of the 5th International Conference, </booktitle> <pages> pp. 700-710, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: The attraction of abstract interpretation, however, was that it allowed data flow analysis to be parameterized by the abstract domain. This was used in later work to define abstract interpretation frameworks in which a number of analyses could be described <ref> [42, 10, 67, 87, 43] </ref>. There are three basic pieces that together form an abstract interpretation, as illustrated in Figure 20: An abstract domain (for example, the mode domain shown in Figure 19). A specific collection of operations defined over the values of the abstract domain.
Reference: [88] <author> D. Warren. </author> <title> An Abstract Prolog Instruction Set. </title> <type> Technical Note 309. </type> <institution> SRI International Artificial Intelligence Center. </institution> <month> October </month> <year> 1983. </year> <month> 157 </month>
Reference: [89] <author> R. Warren, M. Hermenegildo, and S. Debray. </author> <title> On the Practicality of Global Flow Analysis. </title> <booktitle> In International Conference and Symposium on Logic Programming, </booktitle> <pages> pp. 684-699. </pages> <month> August </month> <year> 1988. </year>
Reference: [90] <author> W. Winsborough and A. Wrn. </author> <title> Transparent And-Parallelism in the Presence of Shared Free Variables. </title> <booktitle> In Logic Programming: Proceedings of the 5th International Conference, </booktitle> <pages> pp. 749-764, </pages> <month> August </month> <year> 1988. </year> <month> 158 </month>
References-found: 90

