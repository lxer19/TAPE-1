URL: http://www.cs.berkeley.edu/~nir/Papers/Fr2.ps
Refering-URL: http://www.cs.berkeley.edu/~nir/Abstracts/Fr2.html
Root-URL: http://www.cs.berkeley.edu
Email: nir@cs.berkeley.edu  
Title: The Bayesian Structural EM Algorithm  
Author: Nir Friedman 
Address: 387 Soda Hall  Berkeley, CA 94720  
Affiliation: Computer Science Division,  University of California,  
Abstract: In recent years there has been a flurry of works on learning Bayesian networks from data. One of the hard problems in this area is how to effectively learn the structure of a belief network from incomplete datathat is, in the presence of missing values or hidden variables. In a recent paper, I introduced an algorithm called Structural EM that combines the standard Expectation Maximization (EM) algorithm, which optimizes parameters, with structure search for model selection. That algorithm learns networks based on penalized likelihood scores, which include the BIC/MDL score and various approximations to the Bayesian score. In this paper, I extend Structural EM to deal directly with Bayesian model selection. I prove the convergence of the resulting algorithm and show how to apply it for learning a large class of probabilistic models, including Bayesian networks and some variants thereof.
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> M. Abramowitz and I. A. Stegun, eds. </editor> <booktitle> Handbookof Mathematical Functions. </booktitle> <year> 1964. </year>
Reference-contexts: To evaluate this integral, we can use numerical in tegration procedures, called Hermite-Gaussian quadratures, that are particularly suitable for integrals of this form and can be encoded quite efficiently <ref> [1] </ref>. In the experiments described below, I use this integration procedure with 16 evaluation points. I suspect that it would suffice to use a smaller number of control points. <p> In my imple mentation, I find this value by binary search. Using Laplace's approximation, we get that the integral is approximated by: log G (m)e 2 i ) 2 i 1 2 (log G) 00 (m) (log G) 0 (m) 1 I use standard approximations (e.g., <ref> [1] </ref>) to compute the first and second derivatives of log G (). 5 EXPERIMENTAL RESULTS 5.1 METHODS In this section, I describe results of experiments that indicate the effectiveness of the general approach and evaluate the alternative methods for computing scores discussed above. (a) 3x1+1x3+3, (b) 3x8.
Reference: [2] <author> I. Beinlich, G. Suermondt, R. Chavez, and G. Cooper. </author> <title> The ALARM monitoring system. </title> <booktitle> In Proc. 2'nd Euro. Conf. on AI and Medicine, </booktitle> <year> 1989. </year>
Reference-contexts: In this experiment, I generated artificial training data from two networks: alarma network for intensive care patient monitoring <ref> [2] </ref> that has 37 variables, and insurancea network for classifying car insurance applications [3] that has 26 variables.
Reference: [3] <author> J. Binder, D. Koller, S. Russell, and K. </author> <title> Kanazawa. Adaptive probabilistic networks with hidden variables. </title> <journal> Machine Learning, </journal> <volume> 29 </volume> <pages> 213-244, </pages> <year> 1997. </year>
Reference-contexts: We can find an approximation to these parameters using either gradient ascent methods <ref> [3] </ref> or using EM [11, 19]. Since the probability of the data given a model no longer decomposes, we need to directly estimate the integral of (2). <p> In this experiment, I generated artificial training data from two networks: alarma network for intensive care patient monitoring [2] that has 37 variables, and insurancea network for classifying car insurance applications <ref> [3] </ref> that has 26 variables. From each network I randomly sampled 5 training sets of different sizes, and then randomly removed values from each of these training sets to get training sets with varying percentage of missing values.
Reference: [4] <author> C. Boutilier, N. Friedman, M. Goldszmidt, and D. Koller. </author> <title> Context-specific independence in Bayesian networks. </title> <booktitle> In UAI '96, </booktitle> <pages> pp. 115-123. </pages> <year> 1996. </year>
Reference-contexts: Other examples of separable factored models include multinets [14], mixture models [6], decision trees [5], decision graphs, and the combination of the latter two representations with belief networks <ref> [4, 13, 8] </ref>. An example of a class of models that are factored in a non-trivial sense but are not separable are non-chordal Markov networks [22]. The probability distribution defined by such networks has a product form.
Reference: [5] <author> W. Buntine. </author> <title> Learning classification trees. </title> <editor> In D. J. Hand, ed., </editor> <booktitle> AI & Stats 3, </booktitle> <year> 1993. </year>
Reference-contexts: Other examples of separable factored models include multinets [14], mixture models [6], decision trees <ref> [5] </ref>, decision graphs, and the combination of the latter two representations with belief networks [4, 13, 8]. An example of a class of models that are factored in a non-trivial sense but are not separable are non-chordal Markov networks [22]. <p> Another example of a search procedure that exploits the same factorization properties is the standard divide and conquer approach for learning decision trees, see for example <ref> [5] </ref>. A decision tree is a factored model where each factor corresponds to a leaf of the tree. If we replace a leaf by subtree, or replace a subtree by a leaf, all of the other factors in the model remain unchanged.
Reference: [6] <author> P. Cheeseman and J. </author> <title> Stutz Bayesian classification (AutoClass): Theory and results. </title> <booktitle> In Advances in Knowledge Discovery and Data Mining, </booktitle> <pages> pp. 153-180, </pages> <year> 1995. </year>
Reference-contexts: Other examples of separable factored models include multinets [14], mixture models <ref> [6] </ref>, decision trees [5], decision graphs, and the combination of the latter two representations with belief networks [4, 13, 8]. An example of a class of models that are factored in a non-trivial sense but are not separable are non-chordal Markov networks [22]. <p> Thus, although there have been thorough investigations of the properties of various approximations to the Bayesian score, there have been few empirical reports of experiments with learning structure, except in domains where the search is restricted to a small number of candidates (e.g., <ref> [6] </ref>). 3 THE STRUCTURAL EM ALGORITHM In this section, I present the Bayesian Structural EM algorithm for structure selection. This algorithm attempts to directly optimize the Bayesian score rather than an asymptotic approximation. The presentation is in a somewhat more general settings than factored models. <p> After such a single edge change, the procedure restarts the Structural EM procedure with the new structure and runs until convergence. This is repeated where at each stage the procedure perturbs the best structure found so far. The procedure uses the Cheeseman-Stutz score <ref> [6, 7] </ref> to evaluate structures from different runs of Structural EM. (The BIC version uses the marginal BIC score.) This is repeated for up to five perturbations. <p> Although they do not provide any formal treatment of their procedure, the analysis of [12] directly applies to their approach, and shows that their procedure will converge to a local maximum. Thiesson et al. [27] aim to learn general multinets using the Cheeseman-Stutz score <ref> [6] </ref>. By examining approximations to this score they motivate a learning algorithm that, in the terminology of this paper, can be seen as an instance of Factored-Bayesian-SEM, using the linear approximation, applied to multinets.
Reference: [7] <author> D. M. Chickering and D. Heckerman. </author> <title> Efficient approximations for the marginal likelihood of Bayesian networks with hidden variables. </title> <journal> Machine Learning, </journal> <volume> 29 </volume> <pages> 181-212, </pages> <year> 1997. </year>
Reference-contexts: In general, when data is incomplete, this integral cannot be solved in closed form. Current attempts to learn from incomplete data using the Bayesian score use either stochastic simulation or Laplace's approximation to approximate this integral (see <ref> [7] </ref> and the references within). The former methods tend to be computationally expensive, and the latter methods can be imprecise. In particular, the Laplace approximation assumes that the likelihood function is unimodal, while there are cases where we know that this function has an exponential number of modes. <p> The latter approximation assumes that posterior over parameters is peaked, and use a Gaussian fit in the neighborhood of the MAP parameters to estimate the integral. We refer the reader to <ref> [7, 15] </ref> for a discussion of approximations based on this technique. The use of these approximations requires us to find the MAP parameters for each model we want to consider before we can score it. Thus, a search of model space requires an expensive evaluation of each candidate. <p> After such a single edge change, the procedure restarts the Structural EM procedure with the new structure and runs until convergence. This is repeated where at each stage the procedure perturbs the best structure found so far. The procedure uses the Cheeseman-Stutz score <ref> [6, 7] </ref> to evaluate structures from different runs of Structural EM. (The BIC version uses the marginal BIC score.) This is repeated for up to five perturbations.
Reference: [8] <author> D. M. Chickering, D. Heckerman, and C. Meek. </author> <title> A Bayesian approach to learning Bayesian networks with local structure. </title> <booktitle> In UAI '97, </booktitle> <pages> pp. 80-89, </pages> <year> 1997. </year>
Reference-contexts: Other examples of separable factored models include multinets [14], mixture models [6], decision trees [5], decision graphs, and the combination of the latter two representations with belief networks <ref> [4, 13, 8] </ref>. An example of a class of models that are factored in a non-trivial sense but are not separable are non-chordal Markov networks [22]. The probability distribution defined by such networks has a product form.
Reference: [9] <author> G. F. Cooper and E. Herskovits. </author> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 309-347, </pages> <year> 1992. </year>
Reference-contexts: Eliciting belief networks from experts can be a laborious and expensive process. Thus, in recent years there has been a growing interest in learning belief networks from data <ref> [9, 16, 17, 18] </ref>. Current methods are successful at learning both the structure and parameters from complete datathat is, when each data record describes the values of all variables in the network. Unfortunately, things are different when the data is incomplete. <p> Thus, to evaluate the score of a model, we can use a summary of the data in the form of accumulated sufficient statistics. Example 2.5: We now complete the description of the learn ing problem of multinomial belief networks. Following <ref> [9, 17] </ref> we use Dirichlet priors. <p> The score of the network is a product of terms of the form of (4), one for each multinomial factor in the model; see <ref> [9, 17] </ref>. A particular score of this form is the BDe score of [17], which we use in the experiments below. Learning factored models from data is done by searching over the space of models for a model (or models) that maximizes the score. <p> Like the Structural EM procedure, his procedure is iterative. In each iteration, it generates k joint assignments to all missing values using the best model from previous iterations. His procedure then invokes the learning procedure of Cooper and Herskovits <ref> [9] </ref> on each one of the completed datasets. Finally, Singh's procedure merges the learned networks, trains parameters for this merged network using standard EM procedure, and reiterates. This approach can be interpreted as a stochastic approximation of Structural EM.
Reference: [10] <author> M. H. </author> <title> DeGroot. Optimal Statistical Decisions, </title> <year> 1970. </year>
Reference-contexts: Thus, not every combination of parameters results in a legal probability distribution. Our next assumption involves the choice of factors in the factored models. I require that each factor is from the exponential family <ref> [10] </ref>: A factor is exponential if it can be specified in the form f (X : Q) = e t (Q)s (X) where t (Q) and s (X) are vector valued functions of the same dimension, and is the inner product. 2 Example 2.3: It is easy to verify that the <p> Other examples of exponential factors include univariate and multivariate Gaussians, and many other standard distributions (see, for example, <ref> [10] </ref>). Assumption 2. All the models in M contain only expo nential factors. 2.2 BAYESIAN LEARNING Assume that we have an input dataset D with some number of examples. We want to predict other events that were generated from the same distribution as D. <p> For more details on Dirichlet priors, see <ref> [10] </ref>. Thus, to learn multinomial Bayesian networks with Dirichlet priors, we only need to keep counts of the form N x;pa (X x ) for families we intend to evaluate.
Reference: [11] <author> A. P. Dempster, N. M. Laird, and D. B. Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> J. Royal Stat. Soc., </journal> <volume> B 39 </volume> <pages> 1-39, </pages> <year> 1977. </year>
Reference-contexts: This follows the basic intuition of the Expectation Maximization (EM) algorithm for learning parameters in a fixed parametric model <ref> [11] </ref>. Hence, I call this method Structural EM. (In [12], the name MS-EM was used.) Roughly speaking, Structural EM performs search in the joint space of (Structure fi Parameters). At each step, it can either find better parameters for the current structure, or select a new structure. <p> We can find an approximation to these parameters using either gradient ascent methods [3] or using EM <ref> [11, 19] </ref>. Since the probability of the data given a model no longer decomposes, we need to directly estimate the integral of (2). We can do so either using stochastic simulation, which is extremely expensive in terms of computation, or using large-sample approximations that are based on Laplace's approximation.
Reference: [12] <author> N. Friedman. </author> <title> Learning Bayesian networks in the presence of missing values and hidden variables. </title> <booktitle> In ML '97. </booktitle> <year> 1997. </year>
Reference-contexts: Second, learning a concise structure is crucial both for avoiding overfitting and for efficient inference in the learned model. By introducing hidden variables that do not appear explicitly in the model we can often learn simpler models. In <ref> [12] </ref>, I introduced a new method for searching over structures in the presence of incomplete data. <p> This follows the basic intuition of the Expectation Maximization (EM) algorithm for learning parameters in a fixed parametric model [11]. Hence, I call this method Structural EM. (In <ref> [12] </ref>, the name MS-EM was used.) Roughly speaking, Structural EM performs search in the joint space of (Structure fi Parameters). At each step, it can either find better parameters for the current structure, or select a new structure. <p> At each step, it can either find better parameters for the current structure, or select a new structure. The former case is a standard parametric EM step, while the later is a structural EM step. In <ref> [12] </ref>, I show that for penalized likelihood scoring functions, such as the BIC/MDL score [18], this procedure converges to a local maxima. A drawback of the algorithm of [12] is that it applies only to scoring functions that approximate the Bayesian score. <p> The former case is a standard parametric EM step, while the later is a structural EM step. In <ref> [12] </ref>, I show that for penalized likelihood scoring functions, such as the BIC/MDL score [18], this procedure converges to a local maxima. A drawback of the algorithm of [12] is that it applies only to scoring functions that approximate the Bayesian score. There are good indications, both theoretical and empirical, that the exact Bayesian score provides a better assessment of the generalization properties of a model given the data. <p> In Section 3, I describe the Bayesian Structural EM algorithm in a rather abstract settings and discuss its convergence properties. The algorithm, as presented in Section 3, cannot be directly implemented, and we need 1 It is worth noting that the Structural EM procedure, as presented in <ref> [12] </ref>, is applicable to scores that include priors over parameters. Such scores incorporate, to some extent, the prior knowledge by learning MAP parameters instead of maximum likelihood ones. to approximate some quantities. In Section 4, I discuss how to adapt the algorithm for learning factored models. <p> In addition, I also compare the resulting networks to networks learned using Structural EM with the BIC score (as described in <ref> [12] </ref>). All the variants of this procedure use the same general architecture. There is a search module that performs greedy hill climbing search over network structures. To evaluate each network, this search procedure calls another module that is aware of the metric being used and of the current completion model. <p> Both algorithms were started with the same set of initial network structure and randomized parameters. In these experiments, the procedures are initialized by a structure in which all of the hidden variables are parents of each observable variable. (See <ref> [12] </ref> for motivation for the choice of this structure). As discussed above, both the Bayesian and the BIC versions of Structural EM can converge to local structural maxima. In the case of hidden variables, this phenomena is more pronounced than in the case of missing value. <p> These details can be filled in for each class of models. There is quite a bit of related work on learning from incomplete data. The general idea of interleaving structure search with EM-like iteration appeared in several papers. The first Structural EM paper, Friedman <ref> [12] </ref> introduced the framework and established the first formal convergence results. Singh [25] had a similar insight although his procedure is somewhat different. Like the Structural EM procedure, his procedure is iterative. <p> Meila and Jordan learn multinets in which each network is a Chow tree. They exploit this restriction to collect all required statistics in one pass at each iteration. Although they do not provide any formal treatment of their procedure, the analysis of <ref> [12] </ref> directly applies to their approach, and shows that their procedure will converge to a local maximum. Thiesson et al. [27] aim to learn general multinets using the Cheeseman-Stutz score [6]. <p> Another major open question is how to decide, in an in telligent fashion, on the number of hidden variables. Right now, the approach used in this paper (and in <ref> [12, 21, 27] </ref>) is to learn models with 1 hidden variable, 2 hidden variables, etc., and then to select the network with the highest score. This is clearly a blind approach.
Reference: [13] <author> N. Friedman and M. Goldszmidt. </author> <title> Learning Bayesian networks with local structure. </title> <editor> In M. I. Jordan, ed., </editor> <title> Learning in Graphical Models, </title> <note> 1998. A preliminary version appeared in UAI '96.. </note>
Reference-contexts: Other examples of separable factored models include multinets [14], mixture models [6], decision trees [5], decision graphs, and the combination of the latter two representations with belief networks <ref> [4, 13, 8] </ref>. An example of a class of models that are factored in a non-trivial sense but are not separable are non-chordal Markov networks [22]. The probability distribution defined by such networks has a product form.
Reference: [14] <author> D. Geiger and D. Heckerman. </author> <title> Knowledge representation and inference in similarity networks and Bayesian multinets. </title> <journal> Artificial Intelligence, </journal> <volume> 82 </volume> <pages> 45-74, </pages> <year> 1996. </year>
Reference-contexts: Other examples of separable factored models include multinets <ref> [14] </ref>, mixture models [6], decision trees [5], decision graphs, and the combination of the latter two representations with belief networks [4, 13, 8]. An example of a class of models that are factored in a non-trivial sense but are not separable are non-chordal Markov networks [22].
Reference: [15] <author> D. Geiger, D. Heckerman, and C. Meek. </author> <title> Asymptotic model selection for directed graphs with hidden variables. </title> <booktitle> In UAI '96, </booktitle> <pages> pp. 283-290. </pages> <year> 1996. </year>
Reference-contexts: The latter approximation assumes that posterior over parameters is peaked, and use a Gaussian fit in the neighborhood of the MAP parameters to estimate the integral. We refer the reader to <ref> [7, 15] </ref> for a discussion of approximations based on this technique. The use of these approximations requires us to find the MAP parameters for each model we want to consider before we can score it. Thus, a search of model space requires an expensive evaluation of each candidate.
Reference: [16] <author> D. Heckerman. </author> <title> A tutorial on learning Bayesian networks. </title> <editor> In M. I. Jordan, ed., </editor> <title> Learning in Graphical Models, </title> <year> 1998. </year>
Reference-contexts: Eliciting belief networks from experts can be a laborious and expensive process. Thus, in recent years there has been a growing interest in learning belief networks from data <ref> [9, 16, 17, 18] </ref>. Current methods are successful at learning both the structure and parameters from complete datathat is, when each data record describes the values of all variables in the network. Unfortunately, things are different when the data is incomplete. <p> The inability to learn structure from incomplete data is considered as one of the main problems with current state of the art technology for several reasons. First, most real-life data contains missing values One of the cited advantages of belief networks (e.g., <ref> [16] </ref>) is that they allow for principled methods for reasoning with incomplete data. However, it is unreasonable at the same time to require complete data for training them. Second, learning a concise structure is crucial both for avoiding overfitting and for efficient inference in the learned model.
Reference: [17] <author> D. Heckerman, D. Geiger, and D. M. Chickering. </author> <title> Learning Bayesian networks: </title> <journal> The combinationof knowledgeand statistical data. MachineLearning, </journal> <volume> 20 </volume> <pages> 197-243, </pages> <year> 1995. </year>
Reference-contexts: Eliciting belief networks from experts can be a laborious and expensive process. Thus, in recent years there has been a growing interest in learning belief networks from data <ref> [9, 16, 17, 18] </ref>. Current methods are successful at learning both the structure and parameters from complete datathat is, when each data record describes the values of all variables in the network. Unfortunately, things are different when the data is incomplete. <p> We assume that a priori, the parameters for each factor are independent of the parameters of all other factors and depend only on the form of the factor. These assumptions are called parameter independence and parameter modularity by Heckerman et al. <ref> [17] </ref>. Assumption 3. For each model M 2 M with k factors the prior distribution over parameters has the form Pr (Q M k j M h ) = i Pr (Q M Assumption 4. <p> Thus, to evaluate the score of a model, we can use a summary of the data in the form of accumulated sufficient statistics. Example 2.5: We now complete the description of the learn ing problem of multinomial belief networks. Following <ref> [9, 17] </ref> we use Dirichlet priors. <p> The score of the network is a product of terms of the form of (4), one for each multinomial factor in the model; see <ref> [9, 17] </ref>. A particular score of this form is the BDe score of [17], which we use in the experiments below. Learning factored models from data is done by searching over the space of models for a model (or models) that maximizes the score. <p> The score of the network is a product of terms of the form of (4), one for each multinomial factor in the model; see [9, 17]. A particular score of this form is the BDe score of <ref> [17] </ref>, which we use in the experiments below. Learning factored models from data is done by searching over the space of models for a model (or models) that maximizes the score.
Reference: [18] <author> W. Lam and F. Bacchus. </author> <title> Learning Bayesian belief networks: An approach based on the MDL principle. </title> <journal> Computational Intelligence, </journal> <volume> 10 </volume> <pages> 269-293, </pages> <year> 1994. </year>
Reference-contexts: Eliciting belief networks from experts can be a laborious and expensive process. Thus, in recent years there has been a growing interest in learning belief networks from data <ref> [9, 16, 17, 18] </ref>. Current methods are successful at learning both the structure and parameters from complete datathat is, when each data record describes the values of all variables in the network. Unfortunately, things are different when the data is incomplete. <p> The former case is a standard parametric EM step, while the later is a structural EM step. In [12], I show that for penalized likelihood scoring functions, such as the BIC/MDL score <ref> [18] </ref>, this procedure converges to a local maxima. A drawback of the algorithm of [12] is that it applies only to scoring functions that approximate the Bayesian score.
Reference: [19] <author> S. L. Lauritzen. </author> <title> The EM algorithm for graphical association models with missing data. </title> <journal> ComputationalStatistics and Data Analysis, </journal> <volume> 19 </volume> <pages> 191-201, </pages> <year> 1995. </year>
Reference-contexts: We can find an approximation to these parameters using either gradient ascent methods [3] or using EM <ref> [11, 19] </ref>. Since the probability of the data given a model no longer decomposes, we need to directly estimate the integral of (2). We can do so either using stochastic simulation, which is extremely expensive in terms of computation, or using large-sample approximations that are based on Laplace's approximation.
Reference: [20] <author> D. J. C. MacKay. </author> <title> Ensemble learning for hidden Markovmodels. </title> <type> Unpublished manuscript, </type> <note> http://wol.ra.phy.cam.ac.uk/mackay, 1997. </note>
Reference-contexts: A possible way of improving this approximation is by considering a better approximation of the posterior, such as ensemble methods <ref> [20] </ref>. When we use the MAP approximation, we get a procedure with the following structure: Procedure Factored-Bayesian-SEM (M 0 ; o): Loop for n = 0; 1; : : : until convergence Compute the MAP parameters Q M n for M n given o.
Reference: [21] <author> M. Meila and M. I. Jordan. </author> <title> Estimating dependency structure as a hidden variable. </title> <booktitle> In NIPS 10. </booktitle> <year> 1998. </year>
Reference-contexts: This depends on the class of models we are interested in. In some classes of models, such as the class of Chow trees, there are algorithms that construct the best scoring model. (See <ref> [21] </ref> for a nice use of this idea within an approach that is similar to Structural EM.) In other cases, we must resort to a heuristic search procedure, such as the ones discussed above. <p> In this case, we know in advance that we need to evaluate all factors that involve pairwise interactions between variables. Thus, we can compute the necessary information in one pass over the training data. (Again, see <ref> [21] </ref> for a nice use of this idea.) In addition the caching strategy can use the fact that for many classes of exponential families, such as multinomials and Gaussians, we can marginalize the sufficient statistics for one factor from these of another factor. <p> However, instead of combining these estimates within a single search procedure, Singh searches for structures independently on each one of the completed datasets. This leads to various complications, such as the need to merge the learned networks. Some variants of Structural EM have been proposed by Meila and Jordan <ref> [21] </ref> and Thiesson et al. [27]. Both of these variants learn multinets in which the selector variable is hidden (these can be thought of mixtures of Bayesian networks). Meila and Jordan learn multinets in which each network is a Chow tree. <p> Another major open question is how to decide, in an in telligent fashion, on the number of hidden variables. Right now, the approach used in this paper (and in <ref> [12, 21, 27] </ref>) is to learn models with 1 hidden variable, 2 hidden variables, etc., and then to select the network with the highest score. This is clearly a blind approach.
Reference: [22] <author> J. Pearl. </author> <booktitle> Probabilistic Reasoning in Intelligent Systems, </booktitle> <year> 1988. </year>
Reference-contexts: Assumption 1. All the models M are separable factored models. This assumption by itself is not too strong, since any probability model can be represented by a single factor. Here are some examples of non-trivially factored models that are also separable. Example 2.1: A belief network <ref> [22] </ref> is an annotated directed acyclic graph that encodes a joint probability distribution over U. Formally, a belief network for U is a tuple B = hG; L; Qi. <p> An example of a class of models that are factored in a non-trivial sense but are not separable are non-chordal Markov networks <ref> [22] </ref>. The probability distribution defined by such networks has a product form. However, a change in the parameters for one factor requires changing the global normalizing constant of the model. Thus, not every combination of parameters results in a legal probability distribution.
Reference: [23] <author> D. R. Rubin. </author> <title> Inference and missing data. </title> <journal> Biometrica, </journal> <volume> 63 </volume> <pages> 581-592, </pages> <year> 1976. </year>
Reference-contexts: Learning procedures that attempt to score only the observable data, such as the one described here, ignore, in some sense, the missing values. This is justified when data is missing at random (MAR). I refer the interested reader to <ref> [23] </ref> for a detailed discussion of this issue. We can circumvent this requirement if we augment the data with indicator variables that record omissions, since the augmented data satisfies the MAR assumption.
Reference: [24] <author> L. Saul, T. Jaakkola, and M. Jordan. </author> <title> Mean field theory for sigmoid belief networks. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 4 </volume> <pages> 61-76, </pages> <year> 1996. </year>
Reference-contexts: This, however, requires a more careful analysis of the effect of the noise in the estimation on the convergence properties of the algorithm. Finally, it would be interesting to understand if it is possible to combine variational approaches (e.g., <ref> [24] </ref>) with this type of learning procedures. Another major open question is how to decide, in an in telligent fashion, on the number of hidden variables.
Reference: [25] <author> M. Singh. </author> <title> Learning Bayesian networks from incomplete data. </title> <booktitle> In AAAI '97, </booktitle> <pages> pp. 27-31. </pages> <year> 1997. </year>
Reference-contexts: There is quite a bit of related work on learning from incomplete data. The general idea of interleaving structure search with EM-like iteration appeared in several papers. The first Structural EM paper, Friedman [12] introduced the framework and established the first formal convergence results. Singh <ref> [25] </ref> had a similar insight although his procedure is somewhat different. Like the Structural EM procedure, his procedure is iterative. In each iteration, it generates k joint assignments to all missing values using the best model from previous iterations.
Reference: [26] <author> P. Spirtes, C. Glymour, and R. Scheines. </author> <title> Causation, prediction, and search, </title> <year> 1993. </year>
Reference-contexts: This is clearly a blind approach. Moreover, the qualitative model learned with a hidden variable depends on the initial structure used by the Structural EM procedure. Current research examines how to combine the Structural EM procedure with constraint-based approaches, such as these of <ref> [26] </ref> that learn constraints as to the possible positions of hidden variables, to guide the introduction of hidden variables during the search. Acknowledgments I am grateful to Danny Geiger, Moises Goldszmidt, Daphne Koller, Kevin Murphy, Ron Parr, Stuart Russell, and Zohar Yakhini for useful discussions relating to this work.
Reference: [27] <author> B. Thiesson, C. Meek, D. M. Chickering, and D. Heckerman. </author> <title> Learning mixtures of Bayesian networks. </title> <booktitle> In UAI '98, </booktitle> <year> 1998. </year>
Reference-contexts: This leads to various complications, such as the need to merge the learned networks. Some variants of Structural EM have been proposed by Meila and Jordan [21] and Thiesson et al. <ref> [27] </ref>. Both of these variants learn multinets in which the selector variable is hidden (these can be thought of mixtures of Bayesian networks). Meila and Jordan learn multinets in which each network is a Chow tree. <p> They exploit this restriction to collect all required statistics in one pass at each iteration. Although they do not provide any formal treatment of their procedure, the analysis of [12] directly applies to their approach, and shows that their procedure will converge to a local maximum. Thiesson et al. <ref> [27] </ref> aim to learn general multinets using the Cheeseman-Stutz score [6]. By examining approximations to this score they motivate a learning algorithm that, in the terminology of this paper, can be seen as an instance of Factored-Bayesian-SEM, using the linear approximation, applied to multinets. <p> Another major open question is how to decide, in an in telligent fashion, on the number of hidden variables. Right now, the approach used in this paper (and in <ref> [12, 21, 27] </ref>) is to learn models with 1 hidden variable, 2 hidden variables, etc., and then to select the network with the highest score. This is clearly a blind approach.
References-found: 27

