URL: ftp://ftp.cs.wisc.edu/computer-vision/cvpr97-seitz.ps
Refering-URL: http://www.cs.wisc.edu/computer-vision/pubs.html
Root-URL: 
Email: E-mail: fseitz,dyerg@cs.wisc.edu  
Title: Photorealistic Scene Reconstruction by Voxel Coloring  
Author: Steven M. Seitz Charles R. Dyer 
Date: 1067-1073, 1997.  
Note: In Proc. Computer Vision and Pattern Recognition Conf., pp.  
Web: WWW: http://www.cs.wisc.edu/computer-vision  
Address: Wisconsin, Madison, WI 53706  
Affiliation: Department of Computer Sciences University of  
Abstract: A novel scene reconstruction technique is presented, different from previous approaches in its ability to cope with large changes in visibility and its modeling of intrinsic scene color and texture information. The method avoids image correspondence problems by working in a discretized scene space whose voxels are traversed in a fixed visibility ordering. This strategy takes full account of occlusions and allows the input cameras to be far apart and widely distributed about the environment. The algorithm identifies a special set of invariant voxels which together form a spatial and photometric reconstruction of the scene, fully consistent with the input images. The approach is evaluated with images from both inward- and outward-facing cameras. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Tomasi and T. Kanade, </author> <title> Shape and motion from image streams under orthography: A factorization method, </title> <journal> Int. J. of Computer Vision, </journal> <volume> vol. 9, no. 2, </volume> <pages> pp. 137154, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction We consider the problem of acquiring photorealistic 3D models of real environments from widely distributed viewpoints. This problem has sparked recent interest in the computer vision community <ref> [1, 2, 3, 4, 5] </ref> as a result of new applications in telepresence, virtual walkthroughs, and other graphics-oriented problems that require realistic textured object models. <p> Photo integrity requires that the reconstruction be dense and sufficiently accurate to reproduce the original images. This criterion poses a problem for existing feature- and contour-based techniques that do not provide dense shape estimates. While these techniques can produce texture-mapped models <ref> [1, 3, 4] </ref>, accuracy is ensured only in places where features have been detected. The second criterion means that the input views may be far apart and contain significant occlusions.
Reference: [2] <author> T. Kanade, P. J. Narayanan, and P. W. Rander, </author> <title> Virtualized reality: Concepts and early results, </title> <booktitle> in Proc. IEEE Workshop on Representation of Visual Scenes, </booktitle> <pages> pp. 6976, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction We consider the problem of acquiring photorealistic 3D models of real environments from widely distributed viewpoints. This problem has sparked recent interest in the computer vision community <ref> [1, 2, 3, 4, 5] </ref> as a result of new applications in telepresence, virtual walkthroughs, and other graphics-oriented problems that require realistic textured object models.
Reference: [3] <author> S. Moezzi, A. Katkere, D. Y. Kuramura, and R. Jain, </author> <title> Reality modeling and visualization from multiple video sequences, </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> vol. 16, no. 6, </volume> <pages> pp. 5863, </pages> <year> 1996. </year>
Reference-contexts: 1 Introduction We consider the problem of acquiring photorealistic 3D models of real environments from widely distributed viewpoints. This problem has sparked recent interest in the computer vision community <ref> [1, 2, 3, 4, 5] </ref> as a result of new applications in telepresence, virtual walkthroughs, and other graphics-oriented problems that require realistic textured object models. <p> Photo integrity requires that the reconstruction be dense and sufficiently accurate to reproduce the original images. This criterion poses a problem for existing feature- and contour-based techniques that do not provide dense shape estimates. While these techniques can produce texture-mapped models <ref> [1, 3, 4] </ref>, accuracy is ensured only in places where features have been detected. The second criterion means that the input views may be far apart and contain significant occlusions.
Reference: [4] <author> P. Beardsley, P. Torr, and A. Zisserman, </author> <title> 3D model acquisition from extended image sequences, </title> <booktitle> in Proc. European Conf. on Computer Vision, </booktitle> <pages> pp. 683695, </pages> <year> 1996. </year>
Reference-contexts: 1 Introduction We consider the problem of acquiring photorealistic 3D models of real environments from widely distributed viewpoints. This problem has sparked recent interest in the computer vision community <ref> [1, 2, 3, 4, 5] </ref> as a result of new applications in telepresence, virtual walkthroughs, and other graphics-oriented problems that require realistic textured object models. <p> Photo integrity requires that the reconstruction be dense and sufficiently accurate to reproduce the original images. This criterion poses a problem for existing feature- and contour-based techniques that do not provide dense shape estimates. While these techniques can produce texture-mapped models <ref> [1, 3, 4] </ref>, accuracy is ensured only in places where features have been detected. The second criterion means that the input views may be far apart and contain significant occlusions.
Reference: [5] <author> L. Robert, </author> <title> Realistic scene models from image sequences, </title> <booktitle> in Proc. Imagina 97 Conf., (Monaco), </booktitle> <pages> pp. 813, </pages> <year> 1997. </year>
Reference-contexts: 1 Introduction We consider the problem of acquiring photorealistic 3D models of real environments from widely distributed viewpoints. This problem has sparked recent interest in the computer vision community <ref> [1, 2, 3, 4, 5] </ref> as a result of new applications in telepresence, virtual walkthroughs, and other graphics-oriented problems that require realistic textured object models.
Reference: [6] <author> Y. Nakamura, T. Matsuura, K. Satoh, and Y. Ohta, </author> <title> Occlusion detectable stereoocclusion patterns in camera matrix, </title> <booktitle> in Proc. Computer Vision and Pattern Recognition Conf., </booktitle> <pages> pp. 371378, </pages> <year> 1996. </year>
Reference-contexts: While these techniques can produce texture-mapped models [1, 3, 4], accuracy is ensured only in places where features have been detected. The second criterion means that the input views may be far apart and contain significant occlusions. While some stereo methods <ref> [6, 7] </ref> can cope with limited occlusions, handling visibility changes of greater magnitude appears to be beyond the state of the art.
Reference: [7] <author> P. N. Belhumeur and D. Mumford, </author> <title> A Bayesian treatment of the stereo correspondence problem using half-occluded regions, </title> <booktitle> in Proc. Computer Vision and Pattern Recognition Conf., </booktitle> <pages> pp. 506512, </pages> <year> 1992. </year>
Reference-contexts: While these techniques can produce texture-mapped models [1, 3, 4], accuracy is ensured only in places where features have been detected. The second criterion means that the input views may be far apart and contain significant occlusions. While some stereo methods <ref> [6, 7] </ref> can cope with limited occlusions, handling visibility changes of greater magnitude appears to be beyond the state of the art.
Reference: [8] <author> R. T. Collins, </author> <title> A space-sweep approach to true multi-image matching, </title> <booktitle> in Proc. Computer Vision and Pattern Recognition Conf., </booktitle> <pages> pp. 358363, </pages> <year> 1996. </year>
Reference-contexts: The voxel coloring algorithm presented here works by discretizing scene space into a set of voxels that is traversed and colored in a special order. In this respect, the method is similar to Collins' Space-Sweep approach <ref> [8] </ref> 1 which performs an analogous scene traversal. However, the Space-Sweep algorithm does not provide a solution to the occlusion problem, a primary contribution of this paper.
Reference: [9] <author> A. Katayama, K. Tanaka, T. Oshino, and H. Tamura, </author> <title> A viewpoint dependent stereoscopic display using interpolation of multi-viewpoint images, </title> <booktitle> in Proc. SPIE Vol. 2409A, </booktitle> <pages> pp. 2130, </pages> <year> 1995. </year>
Reference-contexts: In this respect, the method is similar to Collins' Space-Sweep approach [8] 1 which performs an analogous scene traversal. However, the Space-Sweep algorithm does not provide a solution to the occlusion problem, a primary contribution of this paper. Katayama et al. <ref> [9] </ref> described a related method in which images are matched by detecting lines through slices of an epipolar volume, noting that occlusions could be explained by labeling lines in order of increasing slope. Our voxel traversal strategy yields a similar scene-space ordering but is not restricted to linear camera paths.
Reference: [10] <author> L. McMillan and G. Bishop, </author> <booktitle> Plenoptic modeling, in Proc. SIGGRAPH 95, </booktitle> <pages> pp. 3946, </pages> <year> 1995. </year>
Reference-contexts: Our voxel traversal strategy yields a similar scene-space ordering but is not restricted to linear camera paths. However, their algorithm used a reference image, thereby ignoring points that are occluded in the reference image but visible elsewhere. Also related are recently developed panoramic stereo <ref> [10, 11] </ref> algorithms which avoid field of view problems by matching 360 ffi panoramic images directly. Panoramic reconstructions can also be achieved using our approach, but without the need to build panoramic images (see Figs. 1 (b) and 4).
Reference: [11] <author> S. B. Kang and R. Szeliski, </author> <title> 3-D scene data recovery using omnidirectional multibaseline stereo, </title> <booktitle> in Proc. Computer Vision and Pattern Recognition Conf., </booktitle> <pages> pp. 364370, </pages> <year> 1996. </year>
Reference-contexts: Our voxel traversal strategy yields a similar scene-space ordering but is not restricted to linear camera paths. However, their algorithm used a reference image, thereby ignoring points that are occluded in the reference image but visible elsewhere. Also related are recently developed panoramic stereo <ref> [10, 11] </ref> algorithms which avoid field of view problems by matching 360 ffi panoramic images directly. Panoramic reconstructions can also be achieved using our approach, but without the need to build panoramic images (see Figs. 1 (b) and 4).
Reference: [12] <author> A. Laurentini, </author> <title> How far 3D shapes can be understood from 2D silhouettes, </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 17, no. 2, </volume> <pages> pp. 188195, </pages> <year> 1995. </year>
Reference-contexts: Given a multiplicity of solutions to the color reconstruction problem, the only way to recover intrinsic scene information is through invariants properties that are satisfied by every consistent scene. For instance, consider the set of voxels that are contained in every consistent scene. Laurentini <ref> [12] </ref> described how these invariants, called hard points, could be recovered by volume intersection from binary images. Hard points are useful in that they provide absolute information about the true scene. However, such points are relatively rare; some images may yield none (see, for example, Fig. 2).
Reference: [13] <author> J. E. Freund, </author> <title> Mathematical Statistics. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: If 0 is unknown, it can be estimated by imaging a homogeneous surface and computing the standard deviation of image pixels. The consistency of a voxel can be estimated using the likelihood ratio test: V = 2 , distributed as 2 <ref> [13] </ref>. 3.1 Voxel Coloring Algorithm The algorithm is as follows: S = ; for every V 2 V d i project to I 1 ; : : : ; I m , compute V if V &lt; thresh then S = S [ fV g The threshold, thresh, corresponds to the
Reference: [14] <author> R. Szeliski, </author> <title> Rapid octree construction from image sequences, Computer Vision, Graphics, </title> <booktitle> and Image Processing: Image Understanding, </booktitle> <volume> vol. 1, no. 58, </volume> <pages> pp. 2332, </pages> <year> 1993. </year>
Reference-contexts: Our strategy for calibrating the views was similar to that in <ref> [14] </ref>. Instead of a turntable, we placed the objects on a software-controlled pan-tilt head, viewed from above by a fixed camera (see Fig. 1 (a)).
Reference: [15] <author> R. Y. Tsai, </author> <title> A versatile camera calibration technique for high-accuracy 3D machine vision metrology using off-the-shelf cameras and lenses, </title> <journal> IEEE Trans. Robotics and Automation, </journal> <volume> vol. 3, no. 4, </volume> <pages> pp. 323344, </pages> <year> 1987. </year> <month> 7 </month>
Reference-contexts: Our strategy for calibrating the views was similar to that in [14]. Instead of a turntable, we placed the objects on a software-controlled pan-tilt head, viewed from above by a fixed camera (see Fig. 1 (a)). Tsai's method <ref> [15] </ref> was used to calibrate the camera with respect to the head, by rotating a known object and manually selecting image features for three pan positions. The calibration error was approximately 3%. Fig. 3 shows the voxel colorings computed from a complete revolution of a dinosaur toy and a rose.
References-found: 15

