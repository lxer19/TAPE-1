URL: http://www.cs.berkeley.edu/~beymer/publications/aim1266.ps.Z
Refering-URL: http://www.cs.berkeley.edu/~beymer/publications.html
Root-URL: 
Title: Finding Junctions Using the Image Gradient  
Author: David J. Beymer 
Note: Copyright c Massachusetts Institute of Technology, 1991  
Date: 1266 December 1991  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY  
Pubnum: A.I. Memo No.  
Abstract: Junctions, the intersection points of three or more intensity surfaces in an image, are useful low-level features in machine vision, with applications in recognition, motion, grouping, and 3D line interpretation. The popular edge detectors in use today, however, such as the Laplacian of the Gaussian and the second directional derivative, fragment edges at junctions, leaving these important features undetected. This paper analyzes why edges are fragmented at junctions by differential edge operators and proposes a method for detecting junctions based on this analysis. The analysis of edge fragmentation focuses on the properties of the gradient and zero crossings of the Laplacian and the second directional derivative operators. Fragmentation is caused by the intrinsic pairing of zero crossings at junctions and by a destructive interference of edge gradient vectors which increases sensitivity to noise and quantization. We propose a junction detector that works by filling in gaps at junctions in edge maps. It uses the image gradient to guide extensions of disconnected edges at junctions. A new representation for the gradient, the bow tie map, is used to implement the endpoint growing rules, which include following gradient ridges and using saddle points in the gradient magnitude. We demonstrate the junction detector on real imagery. Finally, the paper discusses previous approaches to junction detection. This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for the Laboratory's Artificial Intelligence Research is provided in part by grant S1-801534-2 from Hughes Aircraft Company and by the Advanced Research Projects Agency under Office of Naval Research contract N00014-85-K-0124. The author was supported by a graduate fellowship from the Office of Naval Research while performing this research. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Dana H. Ballard and Chrisopher M. Brown. </author> <title> Computer Vision. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: will look at the zero crossings of two second derivative operators, the Laplacian, r 2 f , and the second directional derivative, @ 2 f @n 2 . (For a good introduction to these operators and their use in edge detection, see Rosenfeld and Kak [34] or Ballard and Brown <ref> [1] </ref>.) Zero crossings of the Laplacian is the scheme advocated by Marr and Hildreth [29]. The second directional derivative, defined as the second derivative of f (x; y) taken in the direction of the gradient, characterizes edge detectors such as Canny [7] and Haralick [16].
Reference: [2] <author> Fredrik Bergholm. </author> <title> Edge focusing. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intel ligence, </journal> <volume> 9(6) </volume> <pages> 726-740, </pages> <year> 1987. </year>
Reference-contexts: The darkened regions contain real edges there is one phantom edge extending upward. of inter-edge interference, such as gradient skew discussed previously. Bergholm <ref> [2] </ref> has explored a technique called edge focusing to try to reap the benefits of both a high and low . High edges are tracked as is slowly decreased, bettering edge localization and reconstructing junctions. So far our analysis has used a continuous model for junctions and differential operators. <p> He suggested using the coarser scales 32 (high ) to locate important edges and then to localize them by tracking how they move in the scale space plot as is reduced. Bergholm <ref> [2] </ref> has implemented an edge detector based on Witkin's idea of tracking edges from coarse to fine resolutions, a technique he calls "edge focusing".
Reference: [3] <author> Valdis Berzins. </author> <title> Accuracy of laplacian edge detectors. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 27 </volume> <pages> 195-210, </pages> <year> 1984. </year>
Reference-contexts: We shall focus most of our attention on trihedral junctions (n = 3), since they are the most common in imagery and are the easiest to analyze. This model is similar to the corner and trihedral junction models developed respectively by Berzins <ref> [3] </ref> and De Micheli et al. [31]. The smoothed image intensity function, f (x; y), is obtained analytically by convolving the piecewise constant surface with a 2D Gaussian with width . Overall, the relevant parameters are and r i and i for 0 i &lt; n.
Reference: [4] <author> David J. Beymer. Junctions: </author> <title> Their detection and use for grouping in images. </title> <type> Master's thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1989. </year>
Reference-contexts: Finally, grouping, roughly defined as aggregating features coming from one object, can use junctions to group edges (Lowe [26], Beymer <ref> [4] </ref>). This paper focuses on the problem of finding junctions in images. Detecting junctions is an open issue because gradient-based edge detectors, the popular edge detectors in use today, fail to detect junctions. One edge of the junction will often be detached from the junction, leaving a small gap.
Reference: [5] <author> Andrew Blake and Andrew Zisserman. </author> <title> Visual Reconstruction. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: These edge detection techniques perform well at junctions because the structure of junctions is not destroyed by a uniform smoothing process, as is the case for gradient-based detectors. 5.1.1 The Weak Membrane Model In Blake and Zisserman's weak membrane model for edge detection <ref> [5] </ref>, which is an approximation to MRF models with line processes (see Geman and Geman [12], Marroquin et al. [30]), the intensity surface of the image is reconstructed by modeling it as a weak membrane.
Reference: [6] <author> R.C. Bolles and R.A. Cain. </author> <title> Recognizing and locating partially visible objects: The local feature-focus method. </title> <journal> International Journal of Robotics Research, </journal> <volume> 1(3) </volume> <pages> 57-82, </pages> <year> 1982. </year>
Reference-contexts: Junctions are usually located in images by looking for points of intersection of three or more intensity edges. As point-based features, junctions have many useful applications in higher level computer vision. Model-based recognition (Bolles and Cain <ref> [6] </ref>, Lamdan and Wolfson [23], Huttenlocher [19], Tucker [38]) and motion (Ullman [39]) have both used point-based features to drive their matching algorithms: recognition matches model to image and motion matches features between frames in time.
Reference: [7] <author> John F. Canny. </author> <title> A computational approach to edge detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8(6) </volume> <pages> 679-698, </pages> <year> 1986. </year>
Reference-contexts: This gradient interaction is an unavoidable consequence of smoothing the image, which is introduced by camera optics and purposefully used to filter out noise. Figure 1 shows an example image and corresponding Canny <ref> [7] </ref> edges. Note the fragmentation at junctions. 1 This paper has two primary goals: to investigate why edge maps are fragmented at junctions and to propose a new method for finding junctions. <p> The second directional derivative, defined as the second derivative of f (x; y) taken in the direction of the gradient, characterizes edge detectors such as Canny <ref> [7] </ref> and Haralick [16]. Nonmaximum suppression in Canny eliminates some zero crossings of @ 2 f @n 2 , as we will discuss later with phantom edges. To analyze the properties of zero crossings near junctions, we need a model for junctions. <p> A postprocessing step to edge detection, the algorithm extends disconnected edges, using the techniques of the last section to "grow" edges from their endpoints. In keeping with our analysis of gradient-based edge detection schemes, we chose to use the Canny edge detector <ref> [7] </ref> as the preliminary edge detection step. We favored Canny edges over other gradient-based schemes because of its good localization of edges and immunity to noise. After finding Canny edges and identifying edge endpoints, the junction detection algorithm works in two phases.
Reference: [8] <author> Todd A. Cass and Daniel P. Huttenlocher. </author> <title> A massively parallel implementation of a three dimensional object recognition system. </title> <type> unpublished manuscript, </type> <year> 1988. </year>
Reference-contexts: One simple method for reconstructing broken junctions from Canny edges is to group together all of the edges incident to a junction. This can be done by applying a thresholding operation to the gradient magnitude. This method, developed by Huttenlocher and Cass <ref> [8] </ref> for a larger 3D recognition system, relies on the fact that the gradient magnitude of the points in the gap between the endpoint (s) of the disconnected edge (s) and the junction is high.
Reference: [9] <author> Indranil Chakravarty. </author> <title> A generalized line and junction labeling scheme with applications to scene analysis. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 1(2) </volume> <pages> 202-205, </pages> <year> 1979. </year>
Reference-contexts: Edge labelling schemes (Guzman [15], Huffman [18], Clowes [11], Waltz [40], Mackworth [27], Kanade [20], Chakravarty <ref> [9] </ref>, Lee, et al. [25], Malik [28]) use junctions to build a three dimensional interpretation of an edge map. Finally, grouping, roughly defined as aggregating features coming from one object, can use junctions to group edges (Lowe [26], Beymer [4]).
Reference: [10] <author> James J. Clark. </author> <title> Authenticating edges produced by zero-crossing algorithms. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11 </volume> <pages> 43-57, </pages> <year> 1989. </year>
Reference-contexts: Given that edges are grouped in pairs of two at junctions, what happens at junctions with an odd number of edges, such as our model trihedral junction? Additional edges, called phantom edges by Clark <ref> [10] </ref>, will appear to force the total number of edges at a junction to be even. Phantom edges, roughly speaking, are zero crossings in the second derivative associated with local minima, rather than local maxima, in the first derivative. <p> A similar analysis can be applied to junctions to predict the occurrence of phantom edges. A junction analogous to the 1D double step, shown in figure 6 (a), consists of regions of low, medium, 5 region (figure adapted from Clark <ref> [10] </ref>). phantom edge in r 2 , the medium intensity region. and high intensities. A phantom edge will appear in the region of middle intensity, leading to the zero crossings shown in figure 6 (b). <p> Nonmaximum suppression in Canny, for instance, will weed out phantom edges because it explicitly looks for local maxima in the first derivative. Zero crossings of r 2 f , as first proposed by Marr and Hildreth, do detect phantom edges, but Clark <ref> [10] </ref> proposed an authentication measure to distinguish authentic and phantom edges. The authentication measure, basically the third directional derivative of f (x; y), measures the concavity of the first derivative. Local maxima, corresponding to authentic edges, have a negative concavity and thus a negative authentication measure. <p> From these partial derivatives we shall compute differential operators of interest: the gradient magnitude jrf j, the laplacian r 2 f , the second directional derivative @ 2 f @n 2 , and Clark's authentication measure <ref> [10] </ref>. Recall from section 2 that our model of an n-ary junction is an intersection of n regions of constant intensity r i , i = 0; : : : ; n 1.
Reference: [11] <author> M.B. Clowes. </author> <title> On seeing things. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 79-116, </pages> <year> 1971. </year>
Reference-contexts: Model-based recognition (Bolles and Cain [6], Lamdan and Wolfson [23], Huttenlocher [19], Tucker [38]) and motion (Ullman [39]) have both used point-based features to drive their matching algorithms: recognition matches model to image and motion matches features between frames in time. Edge labelling schemes (Guzman [15], Huffman [18], Clowes <ref> [11] </ref>, Waltz [40], Mackworth [27], Kanade [20], Chakravarty [9], Lee, et al. [25], Malik [28]) use junctions to build a three dimensional interpretation of an edge map. Finally, grouping, roughly defined as aggregating features coming from one object, can use junctions to group edges (Lowe [26], Beymer [4]).
Reference: [12] <author> Stuart Geman and Don Geman. </author> <title> Stochastic relaxation, gibbs distributions, and the bayesian restoration of images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 721-741, </pages> <year> 1984. </year>
Reference-contexts: because the structure of junctions is not destroyed by a uniform smoothing process, as is the case for gradient-based detectors. 5.1.1 The Weak Membrane Model In Blake and Zisserman's weak membrane model for edge detection [5], which is an approximation to MRF models with line processes (see Geman and Geman <ref> [12] </ref>, Marroquin et al. [30]), the intensity surface of the image is reconstructed by modeling it as a weak membrane. In general, a weak membrane can bend but it cannot crease, so at discontinuities, the membrane "breaks", or tears.
Reference: [13] <author> Michael A. Gennert. </author> <title> Detecting half-edges and vertices in images. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 552-557, </pages> <year> 1986. </year>
Reference-contexts: All the incident 33 surface C. edges of a junction should be connected to the same blob. From our analysis of section 2, for junctions affected by vanishing gradients, the gradient threshold should be chosen equal to jrf j at the nearby saddle point. Gennert <ref> [13] </ref>, noting that edge detectors generally perform poorly at junctions, has explored using directionally selective operators that ignore one side of the image at the point of application, a technique that finds "half edges." Figure 25 shows an example filter for a particular orientation.
Reference: [14] <author> Gerard Giraudon and Rachid Deriche. </author> <title> On corner and vertex detection. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 650-655, </pages> <address> Lahaina, Maui, Hawaii, </address> <year> 1991. </year>
Reference-contexts: Thus, edge focusing cannot restore all junctions in full, but it is a good point for other junction restoration techniques to start from since it helps reduce gap size. Giraudon and Deriche <ref> [14] </ref> have used scale space in a different way to build a junction detector especially apt at localizing junctions. Their detector is based on how elliptic points in the image intensity function move across scales near junctions.
Reference: [15] <author> A. Guzman. </author> <title> Computer recognition of three dimensional objects in a visual scene. </title> <type> Technical Report MAC-TR-59, </type> <institution> MIT, </institution> <year> 1968. </year> <month> 43 </month>
Reference-contexts: Model-based recognition (Bolles and Cain [6], Lamdan and Wolfson [23], Huttenlocher [19], Tucker [38]) and motion (Ullman [39]) have both used point-based features to drive their matching algorithms: recognition matches model to image and motion matches features between frames in time. Edge labelling schemes (Guzman <ref> [15] </ref>, Huffman [18], Clowes [11], Waltz [40], Mackworth [27], Kanade [20], Chakravarty [9], Lee, et al. [25], Malik [28]) use junctions to build a three dimensional interpretation of an edge map.
Reference: [16] <author> Robert M. Haralick. </author> <title> Digital step edges from zero crossings of second directional derivatives. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 58-68, </pages> <year> 1984. </year>
Reference-contexts: The second directional derivative, defined as the second derivative of f (x; y) taken in the direction of the gradient, characterizes edge detectors such as Canny [7] and Haralick <ref> [16] </ref>. Nonmaximum suppression in Canny eliminates some zero crossings of @ 2 f @n 2 , as we will discuss later with phantom edges. To analyze the properties of zero crossings near junctions, we need a model for junctions.
Reference: [17] <author> Berthold K. P. Horn. </author> <title> The Binford-Horn LINE-FINDER. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 285, </pages> <institution> Artificial Intelli gence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1971. </year>
Reference-contexts: How have other researchers dealt with this problem? In this section we look at modifications and extensions to edge detectors that try to restore junctions. 5.2.1 Geometric Heuristics The Binford-Horn line finder <ref> [17] </ref> uses geometric heuristics to find vertices (junctions) in an edge map. First, edge points are located by correlating the image with ideal step, roof, and peak kernels. As one would expect from our analysis of the gradient near junctions, edges are broken up at junctions.
Reference: [18] <author> D.A. Huffman. </author> <title> Impossible objects as nonsense sentences. </title> <editor> In E. B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <volume> volume 6. </volume> <publisher> Edinburgh Univ. Press, Edinburgh, </publisher> <address> U.K., </address> <year> 1971. </year>
Reference-contexts: Model-based recognition (Bolles and Cain [6], Lamdan and Wolfson [23], Huttenlocher [19], Tucker [38]) and motion (Ullman [39]) have both used point-based features to drive their matching algorithms: recognition matches model to image and motion matches features between frames in time. Edge labelling schemes (Guzman [15], Huffman <ref> [18] </ref>, Clowes [11], Waltz [40], Mackworth [27], Kanade [20], Chakravarty [9], Lee, et al. [25], Malik [28]) use junctions to build a three dimensional interpretation of an edge map. Finally, grouping, roughly defined as aggregating features coming from one object, can use junctions to group edges (Lowe [26], Beymer [4]).
Reference: [19] <author> Daniel P. Huttenlocher. </author> <title> Three-dimensional recognition of solid objects from a two-dimensional image. </title> <type> Technical Report AI-TR 1045, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1988. </year>
Reference-contexts: Junctions are usually located in images by looking for points of intersection of three or more intensity edges. As point-based features, junctions have many useful applications in higher level computer vision. Model-based recognition (Bolles and Cain [6], Lamdan and Wolfson [23], Huttenlocher <ref> [19] </ref>, Tucker [38]) and motion (Ullman [39]) have both used point-based features to drive their matching algorithms: recognition matches model to image and motion matches features between frames in time.
Reference: [20] <author> T. Kanade. </author> <title> Recovery of the three dimensional shape of an object from a single view. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 409-461, </pages> <year> 1981. </year>
Reference-contexts: Edge labelling schemes (Guzman [15], Huffman [18], Clowes [11], Waltz [40], Mackworth [27], Kanade <ref> [20] </ref>, Chakravarty [9], Lee, et al. [25], Malik [28]) use junctions to build a three dimensional interpretation of an edge map. Finally, grouping, roughly defined as aggregating features coming from one object, can use junctions to group edges (Lowe [26], Beymer [4]).
Reference: [21] <author> Axel F. Korn. </author> <title> Toward a symbolic representation of intensity changes in images. </title> <journal> IEEE Trans actions on Pattern Analysis and Machine Intelligence, </journal> <volume> 10(5) </volume> <pages> 610-625, </pages> <year> 1988. </year>
Reference-contexts: Thus, one way to fill the gap between e d and the junction is to follow the minimum direction away from e d until e n is found. This rule is related to a similar idea by Korn <ref> [21] </ref> for filling in gaps at junctions by looking for local minima in the gradient magnitude. Another method for grouping edges must be found for junctions with no saddle points in jrf j. <p> It is cheaper than iterative methods that evolve the image over time, such as the weak membrane model or anisotropic diffusion (all the techniques referred to here will be discussed in the next section). It is more expensive than the simple gradient-based junction finders of Korn <ref> [21] </ref> and Lacroix [22], but more principled in the sense that we use an analysis of the gradient near junctions to build the junction detector. 4.3.2 Detection and False Positive Rates One characteristic of the junction detector is that it is fairly aggressive about extending disconnected edges. <p> Finally, Korn <ref> [21] </ref> has advocated generalizing the non-maximum suppression stage by looking for a maximum or minimum in the gradient in four search directions, along the x and y axes and along the diagonals.
Reference: [22] <author> Vinciane Lacroix. </author> <title> A three-module strategy for edge detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 10(6) </volume> <pages> 803-810, </pages> <year> 1988. </year>
Reference-contexts: It is cheaper than iterative methods that evolve the image over time, such as the weak membrane model or anisotropic diffusion (all the techniques referred to here will be discussed in the next section). It is more expensive than the simple gradient-based junction finders of Korn [21] and Lacroix <ref> [22] </ref>, but more principled in the sense that we use an analysis of the gradient near junctions to build the junction detector. 4.3.2 Detection and False Positive Rates One characteristic of the junction detector is that it is fairly aggressive about extending disconnected edges. <p> Unfortunately, the idea is expensive to implement because convolutional operators must be applied in many directions at each point. Also, the results that Gennert shows are disappointing in that the junctions are not restored and the edges are more noise sensitive than Canny edges. 34 Lacroix <ref> [22] </ref> has investigated a generalization of the non-maximum suppression step to avoid disconnecting junctions.
Reference: [23] <author> Yehezkel Lamdan and Haim J. Wolfson. </author> <title> Geometric hashing: A general and efficient model-based recognition scheme. </title> <type> Technical Report 368, </type> <address> New York University, </address> <year> 1988. </year>
Reference-contexts: Junctions are usually located in images by looking for points of intersection of three or more intensity edges. As point-based features, junctions have many useful applications in higher level computer vision. Model-based recognition (Bolles and Cain [6], Lamdan and Wolfson <ref> [23] </ref>, Huttenlocher [19], Tucker [38]) and motion (Ullman [39]) have both used point-based features to drive their matching algorithms: recognition matches model to image and motion matches features between frames in time.
Reference: [24] <author> James S. J. Lee, Robert M. Haralick, and Linda G. Shapiro. </author> <title> Morphologic edge detection. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 3(2) </volume> <pages> 142-156, </pages> <year> 1987. </year>
Reference-contexts: Edge operators can be built by looking at the difference between either dilation or erosion and the original image; this difference is called the dilation or erosion residue. In an example taken from Lee, Haralick, and Shapiro <ref> [24] </ref>, the erosion residue is given by G e (r; c) = f (r; c) e (r; c); where e (r; c) is the erosion. If we use D rod as the structuring element and we map it to zero, we can make the following simplification. <p> One difficulty with morphological techniques is their sensitivity to noise. When no kind of smoothing or blurring operation is built into the morphological operator, Lee, et al. report that the operator is noise sensitive <ref> [24] </ref>. When blurring is added, the signal to noise ratio improves, but then morphological techniques begin to look more and more like gradient-based edge detection techniques.
Reference: [25] <author> Shih Jong Lee, Robert M. Haralick, and Ming Chua Zhang. </author> <title> Understanding objects with curved surfaces from a single perspective view of boundaries. </title> <journal> Artificial Intelligence, </journal> <volume> 26 </volume> <pages> 145-169, </pages> <year> 1985. </year>
Reference-contexts: Edge labelling schemes (Guzman [15], Huffman [18], Clowes [11], Waltz [40], Mackworth [27], Kanade [20], Chakravarty [9], Lee, et al. <ref> [25] </ref>, Malik [28]) use junctions to build a three dimensional interpretation of an edge map. Finally, grouping, roughly defined as aggregating features coming from one object, can use junctions to group edges (Lowe [26], Beymer [4]). This paper focuses on the problem of finding junctions in images.
Reference: [26] <author> David G. Lowe. </author> <title> Perceptual Organization and Visual Recognition. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1985. </year>
Reference-contexts: Finally, grouping, roughly defined as aggregating features coming from one object, can use junctions to group edges (Lowe <ref> [26] </ref>, Beymer [4]). This paper focuses on the problem of finding junctions in images. Detecting junctions is an open issue because gradient-based edge detectors, the popular edge detectors in use today, fail to detect junctions.
Reference: [27] <author> A.K. Mackworth. </author> <title> Interpreting pictures of polyhedral scenes. </title> <journal> Artificial Intelligence, </journal> <volume> 4(2):121 137, </volume> <year> 1973. </year>
Reference-contexts: Edge labelling schemes (Guzman [15], Huffman [18], Clowes [11], Waltz [40], Mackworth <ref> [27] </ref>, Kanade [20], Chakravarty [9], Lee, et al. [25], Malik [28]) use junctions to build a three dimensional interpretation of an edge map. Finally, grouping, roughly defined as aggregating features coming from one object, can use junctions to group edges (Lowe [26], Beymer [4]).
Reference: [28] <author> Jitendra Malik. </author> <title> Interpreting Line Drawings of Curved Objects. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1986. </year>
Reference-contexts: Edge labelling schemes (Guzman [15], Huffman [18], Clowes [11], Waltz [40], Mackworth [27], Kanade [20], Chakravarty [9], Lee, et al. [25], Malik <ref> [28] </ref>) use junctions to build a three dimensional interpretation of an edge map. Finally, grouping, roughly defined as aggregating features coming from one object, can use junctions to group edges (Lowe [26], Beymer [4]). This paper focuses on the problem of finding junctions in images.
Reference: [29] <author> David Marr and Ellen Hildreth. </author> <title> Theory of edge detection. </title> <journal> Proceedings of the Royal Society of London, </journal> <volume> B(207):187-217, </volume> <year> 1980. </year>
Reference-contexts: 2 f , and the second directional derivative, @ 2 f @n 2 . (For a good introduction to these operators and their use in edge detection, see Rosenfeld and Kak [34] or Ballard and Brown [1].) Zero crossings of the Laplacian is the scheme advocated by Marr and Hildreth <ref> [29] </ref>. The second directional derivative, defined as the second derivative of f (x; y) taken in the direction of the gradient, characterizes edge detectors such as Canny [7] and Haralick [16]. <p> One can gain the advantages of both good localization and good noise suppression by examining the edge maps at several scales or resolutions, using many different values. The idea of analyzing the image at several different scales was first advocated by Rosenfeld and Thurston [35]. Later, Marr and Hildreth <ref> [29] </ref> observed that strong edges are those that are relatively stable across scales. Witkin [41] generalized this by developing the scale-space representation of a 1D signal, a plot of the zero crossing location on one axis and scale on the other.
Reference: [30] <author> J. Marroquin, S. Mitter, and Tomaso Poggio. </author> <title> Probabilistic solution of ill-posed problems in computational vision. </title> <booktitle> In Proceedings Image Understanding Workshop, </booktitle> <pages> pages 293-309, </pages> <address> Miami Beach, FL, </address> <month> December </month> <year> 1985. </year> <month> 44 </month>
Reference-contexts: junctions is not destroyed by a uniform smoothing process, as is the case for gradient-based detectors. 5.1.1 The Weak Membrane Model In Blake and Zisserman's weak membrane model for edge detection [5], which is an approximation to MRF models with line processes (see Geman and Geman [12], Marroquin et al. <ref> [30] </ref>), the intensity surface of the image is reconstructed by modeling it as a weak membrane. In general, a weak membrane can bend but it cannot crease, so at discontinuities, the membrane "breaks", or tears.
Reference: [31] <author> E. De Micheli, B. Caprile, P. Ottonello, and V. Torre. </author> <title> Localization and noise in edge detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11(10) </volume> <pages> 1106-1117, </pages> <year> 1989. </year>
Reference-contexts: We shall focus most of our attention on trihedral junctions (n = 3), since they are the most common in imagery and are the easiest to analyze. This model is similar to the corner and trihedral junction models developed respectively by Berzins [3] and De Micheli et al. <ref> [31] </ref>. The smoothed image intensity function, f (x; y), is obtained analytically by convolving the piecewise constant surface with a 2D Gaussian with width . Overall, the relevant parameters are and r i and i for 0 i &lt; n.
Reference: [32] <author> J. Alison Noble. </author> <title> Morphological feature detection. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 112-116, </pages> <month> Dec </month> <year> 1988. </year>
Reference-contexts: Since points near edges will have large difference between neighboring points, edge points are located by thresholding the erosion residue. Lee, Haralick and Shapiro show how this operator behaves and recommend further refinements that combine the erosion and dilation residues. Noble <ref> [32] </ref> analyzes how morphological operators can be used for feature detection. In her analysis, she shows how morphological operators take advantage of certain differential geometrical characteristics of the intensity surface.
Reference: [33] <author> Pietro Perona and Jitendra Malik. </author> <title> Scale-space and edge detection using anisotropic diffusion. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(7) </volume> <pages> 629-639, </pages> <year> 1990. </year>
Reference-contexts: Interestingly enough, our junction detector has a similar localization problem introduced by smoothing gradient ridges into one another. Recall that this was the motivation for the geometrically driven gap filling stage. 5.1.2 Anisotropic Diffusion Perona and Malik <ref> [33] </ref> have recently used anisotropic diffusion to perform a multiple scale analysis of an image, finding both edges and junctions. Using the initial image as a starting point, anisotropic diffusion "evolves" the image over time by smoothing intensity surfaces within regions while avoiding smoothing over edges.
Reference: [34] <editor> Azriel Rosenfeld and Avinash C. Kak. </editor> <booktitle> Digital Picture Processing, </booktitle> <volume> volume 2. </volume> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: To begin with, our analysis will look at the zero crossings of two second derivative operators, the Laplacian, r 2 f , and the second directional derivative, @ 2 f @n 2 . (For a good introduction to these operators and their use in edge detection, see Rosenfeld and Kak <ref> [34] </ref> or Ballard and Brown [1].) Zero crossings of the Laplacian is the scheme advocated by Marr and Hildreth [29]. The second directional derivative, defined as the second derivative of f (x; y) taken in the direction of the gradient, characterizes edge detectors such as Canny [7] and Haralick [16].
Reference: [35] <author> Azriel Rosenfeld and Mark Thurston. </author> <title> Edge and curve detection for visual scene analysis. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-20(5):562-569, </volume> <year> 1971. </year>
Reference-contexts: One can gain the advantages of both good localization and good noise suppression by examining the edge maps at several scales or resolutions, using many different values. The idea of analyzing the image at several different scales was first advocated by Rosenfeld and Thurston <ref> [35] </ref>. Later, Marr and Hildreth [29] observed that strong edges are those that are relatively stable across scales. Witkin [41] generalized this by developing the scale-space representation of a 1D signal, a plot of the zero crossing location on one axis and scale on the other.
Reference: [36] <author> A. Sha'ashua and S. Ullman. </author> <title> Structural saliency: The detection of globally salient structures using a locally connected network. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 321-327, </pages> <month> dec </month> <year> 1988. </year>
Reference-contexts: As we have implemented it here, edge saliency is a generalization of the technique for using a threshold on jrf j to distinguish edge points from noise. More generally, edge saliency can be used as a tool for filling in gaps and selecting important edges (see Sha'ashua and Ullman <ref> [36] </ref>). As a technique for eliminating false positives, edge saliency is not entirely satisfactory for two reasons. First, the edge saliency measure does not necessarily completely separate the real and "noise" edges; i.e. the lowest scoring real edges may not be more salient then the highest scoring noise edge.
Reference: [37] <author> Vincent Torre and Tomaso Poggio. </author> <title> On edge detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8(2), </volume> <year> 1986. </year>
Reference-contexts: Gradient-based edge detection schemes are those that define edges as being local maximum of a first derivative operator, or, equivalently, a zero crossing of a second derivative operator. 1 Since gradient-based techniques take derivatives, we also assume that the image is smoothed with a regularizing filter <ref> [37] </ref>. This smoothing step blurs the structure of junctions and causes interaction between edge gradients, derailing edge detection there. In this paper, the function f (x; y) will be the smoothed image intensity function. <p> We will use this model in two ways. First, following Poggio and Torre <ref> [37] </ref>, we can qualitatively analyze zero crossings near a junction by using transversality theory. Similarly, we can use simple reasoning about the gradient as a vector field to explore its properties. <p> The first cause we explore is that the edge operators r 2 f and @ 2 f @n 2 intrinsically pair zero crossings in twos. 2.1 The Pairing of Edges at Junctions Poggio and Torre <ref> [37] </ref> have done a detailed analysis of the geometric properties of zero crossings. Using ideas from transversality theory and Morse functions, they showed that zero crossings always form closed contours or contours that terminate at the image boundary.
Reference: [38] <author> Lewis W. Tucker, Carl R. Feynman, and Donna M. Fritzsche. </author> <title> Object recognition using the connection machine. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 871-878, </pages> <address> Ann Arbor, Michigan, </address> <year> 1988. </year>
Reference-contexts: Junctions are usually located in images by looking for points of intersection of three or more intensity edges. As point-based features, junctions have many useful applications in higher level computer vision. Model-based recognition (Bolles and Cain [6], Lamdan and Wolfson [23], Huttenlocher [19], Tucker <ref> [38] </ref>) and motion (Ullman [39]) have both used point-based features to drive their matching algorithms: recognition matches model to image and motion matches features between frames in time.
Reference: [39] <author> Shimon Ullman. </author> <title> Maximizing rigitity: The incremental recovery of 3-d structure from rigid and rubbery motion. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 721, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1983. </year>
Reference-contexts: Junctions are usually located in images by looking for points of intersection of three or more intensity edges. As point-based features, junctions have many useful applications in higher level computer vision. Model-based recognition (Bolles and Cain [6], Lamdan and Wolfson [23], Huttenlocher [19], Tucker [38]) and motion (Ullman <ref> [39] </ref>) have both used point-based features to drive their matching algorithms: recognition matches model to image and motion matches features between frames in time.
Reference: [40] <author> David L. Waltz. </author> <title> Understanding line drawings of scenes with shadows. </title> <editor> In P. Winston, editor, </editor> <booktitle> The Psychology of Computer Vision. </booktitle> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: Edge labelling schemes (Guzman [15], Huffman [18], Clowes [11], Waltz <ref> [40] </ref>, Mackworth [27], Kanade [20], Chakravarty [9], Lee, et al. [25], Malik [28]) use junctions to build a three dimensional interpretation of an edge map. Finally, grouping, roughly defined as aggregating features coming from one object, can use junctions to group edges (Lowe [26], Beymer [4]).
Reference: [41] <author> Andrew P. Witkin. </author> <title> Scale-space filtering. </title> <booktitle> In Proceedings IJCAI, </booktitle> <pages> pages 1019-1022, </pages> <year> 1983. </year> <month> 45 </month>
Reference-contexts: The idea of analyzing the image at several different scales was first advocated by Rosenfeld and Thurston [35]. Later, Marr and Hildreth [29] observed that strong edges are those that are relatively stable across scales. Witkin <ref> [41] </ref> generalized this by developing the scale-space representation of a 1D signal, a plot of the zero crossing location on one axis and scale on the other.
References-found: 41

