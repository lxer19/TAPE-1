URL: ftp://ftp.cse.cuhk.edu.hk/pub/techreports/95/tr-95-8.ps.gz
Refering-URL: ftp://ftp.cs.cuhk.hk/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email fhkmak,mhwongg@cs.cuhk.hk  
Title: An Experimental Study of Semantics-Based Concurrency Control Protocols  
Author: Hang Kwong Mak Man Hon Wong 
Address: Shatin, N.T., Hong Kong  
Affiliation: Dept. of Computer Science The Chinese University of Hong Kong  
Abstract: The read=write model, which models a database by a collection of data objects that can only be read or written by transactions, has been the traditional underlying data model for database applications. However, the limited concurrency provided by the read=write model can become a major restriction for the applications to deliver a high performance even when the applications are run on advanced hardware platforms. To address this issue, some researchers have recently proposed to enhance concurrency by exploiting the semantics of data objects. In particular, an abstract data type model is used. The concurrency control mechanisms derived from this model have been shown, theoretically, to provide more concurrency as the underlying data types and operations offer a much richer semantics than that of the read/write model [22, 21, 24, 12, 6, 23]. However, these algorithms are not being widely used in industrial applications. One of the possible reasons is that the practical performance characteristics of these algorithms have not been studied extensively. Therefore, we are motivated to build a testbed to study several semantics-based concurrency control protocols [22, 24, 25]. In this paper, we have investigated the overhead and the performance of these protocols in an attempt to understand the practical characteristics of these protocols and to define concurrency from a practical point of view. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Agrawal, A. El Abbadi, and A. K. Singh. </author> <title> Consistency and Orderability: Semantics-Based Correctness Criteria for Databases. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 18(3) </volume> <pages> 460-486, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: This protocol offers more concurrency as the set of histories accepted by this protocol is a strict superset of that accepted by either DU or U I P . A variation of this protocol is to use a relation between locks called ordered sharing <ref> [1] </ref> to execute conflicting operations concurrently. A significant advantage is that no transaction will be blocked and the set of acceptable histories is enlarged. However, this protocol involves a larger overhead as compared to the protocol in [22]. <p> Once a transaction is finished, a new transaction from the same client will be generated. When shared and ordered shared relations <ref> [1] </ref> between locks are used, p will be executed even when there is conflict but the ordered shared relations will be established between T and those transactions that issue operations conflicting with p. We maintain this dependency relationship by means of a dependency graph G, which is a directed graph.
Reference: [2] <author> R. Agrawal, M. J. Carey, and M. Linvy. </author> <title> Concurrency Control Performance Modelling : Alternatives and Implications. </title> <journal> ACM Trans. Database Syst, </journal> <volume> 12(4) </volume> <pages> 609-654, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: The number of performance studies on this model is rather limited and most of the studies are based on simulation models [3] in which the overhead of concurrency control is neglected <ref> [2] </ref>. However, a semantics-based concurrency control protocol usually provides a higher degree of concurrency in the expense of a larger concurrency control overhead. Therefore, the overhead of the concurrency control protocol must be investigated in order to justify the use of the protocol. <p> When a cycle is found in G, deadlock arises and all transactions involved in the cycle must be aborted. 3.2 Parameter Setting and Performance Metrics The values chosen for the parameters are listed in Tables 1 and 2. Some of the values are chosen similar to that in <ref> [3, 2] </ref>. The maximum number of active transactions that is allowed in the system is the multi-programming level (MPL). The length of a transaction is the number of operations executed by the transaction. <p> The motivation of building a testbed is that the number of performance studies on the abstract data type model is rather limited and most of the studies are based on simulation models [3] in which the overhead of concurrency control is neglected <ref> [2] </ref>. However, a semantics-based CC protocol usually provides a higher degree of concurrency in the expense of a larger concurrency control overhead. Therefore, the overhead of a concurrency control protocol must be investigated in order to justify the use of the protocol.
Reference: [3] <author> B. R. Badrinath and K. Ramamritham. </author> <title> Semantics-Based Concurrency Control: Beyond Commutativity. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 17(1) </volume> <pages> 163-199, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: The bottleneck is due to the competition of logical resources. The situation cannot be alleviated even when the applications are run on advanced hardware platforms. To address this issue, researchers have proposed to place more structures on data objects to exploit type specific properties <ref> [13, 3, 10, 11, 22] </ref>. In particular, the read=write model is extended to an abstract data type model in which a database is modeled as a collection of data objects. <p> The number of performance studies on this model is rather limited and most of the studies are based on simulation models <ref> [3] </ref> in which the overhead of concurrency control is neglected [2]. However, a semantics-based concurrency control protocol usually provides a higher degree of concurrency in the expense of a larger concurrency control overhead. <p> When a cycle is found in G, deadlock arises and all transactions involved in the cycle must be aborted. 3.2 Parameter Setting and Performance Metrics The values chosen for the parameters are listed in Tables 1 and 2. Some of the values are chosen similar to that in <ref> [3, 2] </ref>. The maximum number of active transactions that is allowed in the system is the multi-programming level (MPL). The length of a transaction is the number of operations executed by the transaction. <p> The motivation of building a testbed is that the number of performance studies on the abstract data type model is rather limited and most of the studies are based on simulation models <ref> [3] </ref> in which the overhead of concurrency control is neglected [2]. However, a semantics-based CC protocol usually provides a higher degree of concurrency in the expense of a larger concurrency control overhead.
Reference: [4] <author> P. A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1987. </year>
Reference-contexts: The performance of a protocol should be expressed into two measures. The first measure is the throughput of the system which is defined as the number of transactions completed per unit time. The second measure is the multi-programming level at which thrashing occurs <ref> [4] </ref>. 5 When thrashing occurs, the system is wasting time to compete for resources, either logical or physical resources. <p> This phenomenon is called thrashing <ref> [4] </ref> and the multiprogramming level at which thrashing occurs is called the thrashing point. The throughput at which thrashing occurs is called the peak throughput. <p> As the multi-programming level becomes larger, the conflict probability and deadlock rate become so large that the increase in R (M ) (see Equations 2 and 3) exceeds that of M, thus leading to the drop of the throughput. It has been shown in <ref> [4] </ref>, the effect of deadlock on the throughput before thrashing is very small. The dominant factor is the blocking of transaction. But after thrashing, deadlock becomes the major factor that causes the drop in throughput of the system.
Reference: [5] <author> P. A. Bernstein, D. W. Shipman, and W. S. Wong. </author> <title> Formal Aspects of Serializability in Database Concurrency Control. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 5(5) </volume> <pages> 203-216, </pages> <month> May </month> <year> 1979. </year>
Reference-contexts: Therefore, a database system that can provide a high degree of concurrency is of ultimate importance. The read=write model has been the traditional data model for database applications and serializability <ref> [5, 7, 15] </ref> is used to ensure the correctness of interleaved executions of transactions. The strict two phase locking protocol [7] is widely used in commercial products to enforce serializability. <p> This model has been the traditional data model for relational database applications. Serializability <ref> [5, 7, 15] </ref> is widely used to ensure the correctness of interleaved executions of transactions.
Reference: [6] <author> P. K. Chrysanthis, S. Raghuram, and K. Ramamritham. </author> <title> Extracting Concurrency from Objects: A Methodology. </title> <booktitle> In Proceedings of the 1991 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 108-117, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Each data object maintains a state and provides a set of operations that act as the sole means for transactions to access the state of the object. Many theoretical studies <ref> [22, 21, 24, 12, 6, 23] </ref> have shown that the concurrency control mechanisms based on this model can enhance concurrency in the sense that the set of acceptable histories is enlarged. <p> The concurrency control mechanisms based on this model have been shown, theoretically, to enhance concurrency as the underlying data types and operations offer a much richer semantics than that of the read=write model <ref> [22, 21, 24, 12, 6, 23] </ref>. Schwarz and Spector [19] proposed to use the commutativity relations to determine conflict relations between operations. Two commutative operations can be executed concurrently even when 3 both the operations are update operations.
Reference: [7] <author> K. P. Eswaran, J. N. Gray, R. A. Lorie, and I. L. Traiger. </author> <title> The Notions of Consistency and Predicate Locks in a Database System. </title> <journal> Communications of the ACM, </journal> 19(11) 624-633, November 1976. 
Reference-contexts: Therefore, a database system that can provide a high degree of concurrency is of ultimate importance. The read=write model has been the traditional data model for database applications and serializability <ref> [5, 7, 15] </ref> is used to ensure the correctness of interleaved executions of transactions. The strict two phase locking protocol [7] is widely used in commercial products to enforce serializability. <p> The read=write model has been the traditional data model for database applications and serializability [5, 7, 15] is used to ensure the correctness of interleaved executions of transactions. The strict two phase locking protocol <ref> [7] </ref> is widely used in commercial products to enforce serializability. However, recently this model has been found to be too restrictive for modeling advanced applications such as CAD/CAM systems and VLSI design systems, since the designs of these applications are becoming more object-oriented. <p> This model has been the traditional data model for relational database applications. Serializability <ref> [5, 7, 15] </ref> is widely used to ensure the correctness of interleaved executions of transactions. <p> We expect that a protocol which provides more "concurrency" theoretically should provide more "concurrency" practically. 2.4 Control Flow of the Strict Two Phase Locking Protocol In this section, we will describe the mechanism of the Strict 2PL <ref> [7] </ref> in an attempt to identify the factors that may affect the performance of a concurrency control protocol. 6 2.4.1 Flow of an operation p generated from a client is enqueued to the ready queue in a f irst-come-f irst-served manner.
Reference: [8] <author> Hector Garcia-Molina and Kenneth Salem. </author> <title> Main Memory Database Systems : An Overview. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 4(6) </volume> <pages> 509-516, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: The effect of concurrency control overhead becomes less prominent. * Main memory database is becoming more popular as some advanced applications such as real-time applications are gaining importance. These applications must be memory-based in order to meet their real-time constraints <ref> [8] </ref>. Therefore, it is reasonable to investigate the performance of various CC protocols in a main memory environment. 3.1.2 System Configuration We assume that the main memory is large enough to hold the whole database.
Reference: [9] <author> T. Harder and A. Reuter. </author> <title> Principles of transaction oriented database recovery. </title> <journal> ACM Computing Surveys, </journal> <volume> 15(4), </volume> <month> December </month> <year> 1983. </year> <month> 26 </month>
Reference-contexts: Weihl [22] showed that the choice of recovery strategy has a subtle impact on the conflict relations being used. When different recovery strategies <ref> [9] </ref>, namely update-in-place (UIP) and deferred update (DU), are used, different notions of commutativity, forward commutativity (F C) and right backward commutativity (RBC), are needed to derive the conflict relations between operations.
Reference: [10] <author> M. Herlihy. </author> <title> General quorum consensus: A replication method for abstract data types. </title> <type> Technical Report CMU--CS-84-164, </type> <institution> Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> December </month> <year> 1984. </year>
Reference-contexts: The bottleneck is due to the competition of logical resources. The situation cannot be alleviated even when the applications are run on advanced hardware platforms. To address this issue, researchers have proposed to place more structures on data objects to exploit type specific properties <ref> [13, 3, 10, 11, 22] </ref>. In particular, the read=write model is extended to an abstract data type model in which a database is modeled as a collection of data objects.
Reference: [11] <author> M. P. Herlihy and W. E. Weihl. </author> <title> Hybrid Concurrency Control for Abstract Data Types. </title> <booktitle> In Proceedings of the Seventh Symposium on Principles of Database Systems, </booktitle> <pages> pages 201-210, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: The bottleneck is due to the competition of logical resources. The situation cannot be alleviated even when the applications are run on advanced hardware platforms. To address this issue, researchers have proposed to place more structures on data objects to exploit type specific properties <ref> [13, 3, 10, 11, 22] </ref>. In particular, the read=write model is extended to an abstract data type model in which a database is modeled as a collection of data objects.
Reference: [12] <author> M. P. Herlihy and W. E. Weihl. </author> <title> Hybrid Concurrency Control for Abstract Data Types. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 43(1) </volume> <pages> 25-61, </pages> <month> August </month> <year> 1991. </year> <booktitle> Special issue on the 7th Annual ACM SIGACT-SIGMOD Symposium on the Principles of Database Systems, </booktitle> <month> March 21-23, </month> <year> 1988. </year>
Reference-contexts: Each data object maintains a state and provides a set of operations that act as the sole means for transactions to access the state of the object. Many theoretical studies <ref> [22, 21, 24, 12, 6, 23] </ref> have shown that the concurrency control mechanisms based on this model can enhance concurrency in the sense that the set of acceptable histories is enlarged. <p> The concurrency control mechanisms based on this model have been shown, theoretically, to enhance concurrency as the underlying data types and operations offer a much richer semantics than that of the read=write model <ref> [22, 21, 24, 12, 6, 23] </ref>. Schwarz and Spector [19] proposed to use the commutativity relations to determine conflict relations between operations. Two commutative operations can be executed concurrently even when 3 both the operations are update operations.
Reference: [13] <author> H. F. Korth. </author> <title> Locking Primitives in a Database System. </title> <journal> Journal of the ACM, </journal> <volume> 30(1) </volume> <pages> 55-79, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: The bottleneck is due to the competition of logical resources. The situation cannot be alleviated even when the applications are run on advanced hardware platforms. To address this issue, researchers have proposed to place more structures on data objects to exploit type specific properties <ref> [13, 3, 10, 11, 22] </ref>. In particular, the read=write model is extended to an abstract data type model in which a database is modeled as a collection of data objects.
Reference: [14] <author> H. F. Korth and G. D. Speegle. </author> <title> Formal model of correctness without seriallizability. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference, </booktitle> <pages> pages 379-386. </pages> <publisher> ACM, </publisher> <year> 1988. </year>
Reference: [15] <author> C. H. Papadimitriou. </author> <title> The Serializability of Concurrent Database Updates. </title> <journal> Journal of the ACM, </journal> <volume> 26(4) </volume> <pages> 631-653, </pages> <month> October </month> <year> 1979. </year>
Reference-contexts: Therefore, a database system that can provide a high degree of concurrency is of ultimate importance. The read=write model has been the traditional data model for database applications and serializability <ref> [5, 7, 15] </ref> is used to ensure the correctness of interleaved executions of transactions. The strict two phase locking protocol [7] is widely used in commercial products to enforce serializability. <p> This model has been the traditional data model for relational database applications. Serializability <ref> [5, 7, 15] </ref> is widely used to ensure the correctness of interleaved executions of transactions.
Reference: [16] <author> R. Rastogi, H. F. Korth, and A. Silberschatz. </author> <title> Strict Histories in Object-Based Database Systems. </title> <booktitle> In Proceedings of the Twelfth ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 288-299, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: If a deadlock is detected, transaction T will be aborted. When update-in-place recovery strategy is used, we need additional 11 mechanisms to cancel the effects of an aborted transaction. This can be accomplished by executing a series of inverse operations <ref> [18, 16] </ref> to neutralize the effects of the transaction. An aborted transaction will be restarted later (the transaction generator will re-submit a transaction upon receiving an abort message from the database server).
Reference: [17] <author> J. Riedl. </author> <title> Adaptable distributed transaction systems. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Purdue University, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: This is similar to Riedl's closed experiment approach <ref> [17] </ref>.
Reference: [18] <author> H. Schek, G. Weikum, and H. Ye. </author> <title> Towards a Unified Theory of Concurrency Control and Recovery. </title> <booktitle> In Proceedings of the Twelfth ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 300-311, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: If a deadlock is detected, transaction T will be aborted. When update-in-place recovery strategy is used, we need additional 11 mechanisms to cancel the effects of an aborted transaction. This can be accomplished by executing a series of inverse operations <ref> [18, 16] </ref> to neutralize the effects of the transaction. An aborted transaction will be restarted later (the transaction generator will re-submit a transaction upon receiving an abort message from the database server).
Reference: [19] <author> P. M. Schwarz and A. Z. Spector. </author> <title> Synchronizing Shared Abstract Types. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(3) </volume> <pages> 223-250, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: The concurrency control mechanisms based on this model have been shown, theoretically, to enhance concurrency as the underlying data types and operations offer a much richer semantics than that of the read=write model [22, 21, 24, 12, 6, 23]. Schwarz and Spector <ref> [19] </ref> proposed to use the commutativity relations to determine conflict relations between operations. Two commutative operations can be executed concurrently even when 3 both the operations are update operations.
Reference: [20] <author> A. Thomasian. </author> <title> Thrashing in two-phase locking revisited. </title> <booktitle> In Proceedings Eighth International Conference on Data Engineering, </booktitle> <pages> pages 518-526, </pages> <year> 1992. </year>
Reference-contexts: In this section, we try to uncover this relationship. RWs, the system starts thrashing when the blocking ratio is around 30% which matches with the the findings in <ref> [20] </ref>. This shows that our model is consistent with previous work and hence our comparison of the read=write model with the semantics-based protocols is meaningful.
Reference: [21] <author> W. E. Weihl. </author> <title> Specification and implementation of atomic data types. </title> <type> Technical Report MIT-LCS-TR-314, </type> <institution> Massachusetts Institute of Technology, Cambridge, Massachusetts, </institution> <year> 1984. </year>
Reference-contexts: Each data object maintains a state and provides a set of operations that act as the sole means for transactions to access the state of the object. Many theoretical studies <ref> [22, 21, 24, 12, 6, 23] </ref> have shown that the concurrency control mechanisms based on this model can enhance concurrency in the sense that the set of acceptable histories is enlarged. <p> The concurrency control mechanisms based on this model have been shown, theoretically, to enhance concurrency as the underlying data types and operations offer a much richer semantics than that of the read=write model <ref> [22, 21, 24, 12, 6, 23] </ref>. Schwarz and Spector [19] proposed to use the commutativity relations to determine conflict relations between operations. Two commutative operations can be executed concurrently even when 3 both the operations are update operations.
Reference: [22] <author> W. E. Weihl. </author> <title> Local Atomicity Properties: Modular Concurrency Control for Abstract Data Types. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(2) </volume> <pages> 249-283, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: The bottleneck is due to the competition of logical resources. The situation cannot be alleviated even when the applications are run on advanced hardware platforms. To address this issue, researchers have proposed to place more structures on data objects to exploit type specific properties <ref> [13, 3, 10, 11, 22] </ref>. In particular, the read=write model is extended to an abstract data type model in which a database is modeled as a collection of data objects. <p> Each data object maintains a state and provides a set of operations that act as the sole means for transactions to access the state of the object. Many theoretical studies <ref> [22, 21, 24, 12, 6, 23] </ref> have shown that the concurrency control mechanisms based on this model can enhance concurrency in the sense that the set of acceptable histories is enlarged. <p> The concurrency control mechanisms based on this model have been shown, theoretically, to enhance concurrency as the underlying data types and operations offer a much richer semantics than that of the read=write model <ref> [22, 21, 24, 12, 6, 23] </ref>. Schwarz and Spector [19] proposed to use the commutativity relations to determine conflict relations between operations. Two commutative operations can be executed concurrently even when 3 both the operations are update operations. <p> However, a deposit operation "commutes" with another deposit operation since swapping the execution order of any two deposit operations does not change the responses to the two operations and the final state of the object. Weihl <ref> [22] </ref> showed that the choice of recovery strategy has a subtle impact on the conflict relations being used. <p> A significant advantage is that no transaction will be blocked and the set of acceptable histories is enlarged. However, this protocol involves a larger overhead as compared to the protocol in <ref> [22] </ref>. The extra overhead is due to the construction and the manipulation of the "view" of each operation. <p> By using commutativity relations to capture the semantic information available in objects and operations, the conflict relations are weakened. The conflict relations can further be weakened by using f orward commutativity and right backward commutativity to cope with a particular recovery strategy <ref> [22] </ref>. Furthermore, with the use of context-specific information, conflict relations are determined dynamically and is proved to be even weaker than that derived from RBC and F C [24]. <p> Finally, another reason that makes semantics-based CC protocols superior is that all the above concurrency control protocols can ensure dynamic atomicity which is a local atomicity property <ref> [22] </ref>. If local atomicity can be enforced on each object in the system, then the global correctness criterion of serializability can be ensured. Therefore, the choice of concurrency control algorithm can be made locally for each object (or group of objects) in the system.
Reference: [23] <author> G. Weikum. </author> <title> Principles and realization strategies of multi-level transaction systems. </title> <type> technical report DVSI-1987-T1, </type> <institution> Technical University of Darmstadt, Darmstadt, West Germany, </institution> <year> 1987. </year>
Reference-contexts: Each data object maintains a state and provides a set of operations that act as the sole means for transactions to access the state of the object. Many theoretical studies <ref> [22, 21, 24, 12, 6, 23] </ref> have shown that the concurrency control mechanisms based on this model can enhance concurrency in the sense that the set of acceptable histories is enlarged. <p> The concurrency control mechanisms based on this model have been shown, theoretically, to enhance concurrency as the underlying data types and operations offer a much richer semantics than that of the read=write model <ref> [22, 21, 24, 12, 6, 23] </ref>. Schwarz and Spector [19] proposed to use the commutativity relations to determine conflict relations between operations. Two commutative operations can be executed concurrently even when 3 both the operations are update operations.
Reference: [24] <author> M. H. Wong and D. Agrawal. </author> <title> Context-Specific Synchronization for Atomic Data Types. </title> <booktitle> In Proceedings of the International Conference on Database Theory, </booktitle> <pages> pages 201-215, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Each data object maintains a state and provides a set of operations that act as the sole means for transactions to access the state of the object. Many theoretical studies <ref> [22, 21, 24, 12, 6, 23] </ref> have shown that the concurrency control mechanisms based on this model can enhance concurrency in the sense that the set of acceptable histories is enlarged. <p> The concurrency control mechanisms based on this model have been shown, theoretically, to enhance concurrency as the underlying data types and operations offer a much richer semantics than that of the read=write model <ref> [22, 21, 24, 12, 6, 23] </ref>. Schwarz and Spector [19] proposed to use the commutativity relations to determine conflict relations between operations. Two commutative operations can be executed concurrently even when 3 both the operations are update operations. <p> An operation q is said to conflict with another operation p if q does not right commute backward (forward commute) with p when U I P (DU ) is used (see Appendix A). Wong and Agrawal <ref> [24] </ref> further enhanced the concurrency by exploiting the context-specific information in an execution. When a new operation, say p, is executed on an object, the active operations in that object are divided into two partitions. One partition is called the "view". <p> Furthermore, with the use of context-specific information, conflict relations are determined dynamically and is proved to be even weaker than that derived from RBC and F C <ref> [24] </ref>. From Figure 1, we notice that the set of acceptable histories is enlarged as the extent of information exploited from the system increases. <p> However, this gain in "concurrency" is obtained in the expense of a larger overhead in manipulating extra data structure (e.g. "view" construction in <ref> [24] </ref>). Therefore, the throughput and the behavior of a protocol at different multi-programming levels cannot be judged solely by the strength of the conflict relation. Usually a protocol is chosen based on its performance rather than on the size of the set of acceptable histories. <p> However, when DU recovery strategy is used, the intention lists of the transaction is simply discarded which makes DU more desirable when abort rate is high. 4.2 Using Context-Specific Information In this section, we will investigate the context-specific protocol <ref> [24] </ref> (denoted by MIX) which derives conflict relations dynamically. Theoretically, this protocol promises a higher degree of theoretical "concurrency". However, due to the dynamic nature of conflict relation derivation, a larger overhead is involved which may have negative effect on the performance of the protocol. <p> Theoretically, a protocol P a is said to provide more concurrency than another protocol P b if the set of acceptable histories of P a is larger than that of P b <ref> [24] </ref> and P a is said to provide a higher degree of theoretical "concurrency". However, this definition is quite abstract and difficult to measure practically.
Reference: [25] <author> M. H. Wong and D. Agrawal. </author> <title> Tolerating Bounded Inconsistency for Increasing Concurrency in Database Systems. </title> <booktitle> In Proceedings of the ACM SIGMOD-SIGACT Symposium on Principles of Database Systems, </booktitle> <pages> pages 236-245, </pages> <month> June </month> <year> 1992. </year> <month> 27 </month>
References-found: 25

