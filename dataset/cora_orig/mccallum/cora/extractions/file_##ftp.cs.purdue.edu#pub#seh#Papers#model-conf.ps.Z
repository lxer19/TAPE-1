URL: file://ftp.cs.purdue.edu/pub/seh/Papers/model-conf.ps.Z
Refering-URL: http://www.cs.purdue.edu/people/seh/
Root-URL: http://www.cs.purdue.edu
Email: seh@cs.purdue.edu ashfaq@cs.purdue.edu  
Title: C 3 An architecture-independent model for coarse-grained parallel machines  
Author: Susanne E. Hambrusch Ashfaq A. Khokhar 
Address: West Lafayette, IN 47907 West Lafayette, IN 47907  
Affiliation: Department of CS School of EE and Dept. of CS Purdue University Purdue University  
Abstract: We propose an architecture-independent parallel model, the C 3 -model. The C 3 -model evaluates, for a given parallel algorithm and target architecture, the complexity of computation, the pattern of communication, and the potential congestion arising in communication operations. A metric for estimating the effect of link and processor congestion on the performance of an arbitrary communication operation is developed. We describe how the C 3 -model can serve as a platform for the development of coarse-grained algorithms sensitive to the parameters of a parallel machine. The initial validation of the C 3 -model is discussed through different implementations of communication operations on the Intel Touchstone Delta.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Bala, J. Bruck, R. Cypher, P. Elustondo, A. Ho, C.-T. Ho, S. Kipnis, and M. Snir, </author> <title> "CCL: A Portable and Tunable Collective Communication Library for Scalable Parallel Computers," </title> <booktitle> Proc. of IPPS, </booktitle> <pages> pp. 835-844, </pages> <year> 1994. </year>
Reference-contexts: The importance of being able to operate on independent submachines has been recognized. It has been incorporated into the Message Passing Interface (MPI) [6] and has been extended to arbitrary process groups <ref> [1] </ref>. In our evaluation of communication units we assume that independent routing in sub-machines is possible. We thus charge communication units based on the parameters of the associated sub-machines. 2.1 Computation Units The charging of computation units in a superstep is done as follows. <p> Our results indicate that the efficiency of a communication operation is influenced by the relationship among parameters of the parallel machine, as well as by the relationship of the parameters to the amount of data involved. This agrees with other research done on the implementation of communication operations, <ref> [1, 2, 4, 12] </ref>. In order to classify the different approaches used in our implementations, we introduce the notion of a k-level algorithm.
Reference: [2] <author> M. Barnett, R. Littlefield, D. G. Payne, and R. van de Geijn, </author> <title> "Global Combine on Meshes Architecures with Wormhole Routing," </title> <booktitle> Proc. of IPPS, </booktitle> <pages> pp. 156-162, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Our results indicate that the efficiency of a communication operation is influenced by the relationship among parameters of the parallel machine, as well as by the relationship of the parameters to the amount of data involved. This agrees with other research done on the implementation of communication operations, <ref> [1, 2, 4, 12] </ref>. In order to classify the different approaches used in our implementations, we introduce the notion of a k-level algorithm.
Reference: [3] <author> A. Bar-Noy, S. Kipnis, </author> <title> "Designing Broadcasting Algorithms in the Postal Model for Message-Passing Systems," </title> <booktitle> Proc. of SPAA, </booktitle> <pages> pp. 13-22, </pages> <year> 1992. </year>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 5, 8, 10, 11, 15, 16, 17] </ref>. In most of these models, processors are assumed to communicate using a point-to-point message router. Composing more involved communication operations by having to specify fine-scheduling details places a significant burden on application programmers.
Reference: [4] <author> S.H. Bokhari, </author> <title> "Multiphase Complete Exchange on a Circuit Switched Hypercube," </title> <booktitle> Proc. of ICPP, </booktitle> <pages> pp. 525-529, </pages> <year> 1991. </year>
Reference-contexts: Our results indicate that the efficiency of a communication operation is influenced by the relationship among parameters of the parallel machine, as well as by the relationship of the parameters to the amount of data involved. This agrees with other research done on the implementation of communication operations, <ref> [1, 2, 4, 12] </ref>. In order to classify the different approaches used in our implementations, we introduce the notion of a k-level algorithm. <p> However, in actual implementations different permutations induce different patterns of link and processor congestion and thus give a different performance. Capturing this behaviour in the model and its metric would be difficult. The approach in Algorithm logp-lev-bfly has consistently been judged as being expensive for large message sizes <ref> [4, 13] </ref>. Our metric and the observed performance on the Delta, confirms that as well.
Reference: [5] <author> D. Culler, R. Karp, D. Patterson, A. Sahay, K.E. Schauser, E. Santos, R. Subramonian, T. von Eicken, </author> <title> "LogP: Towards a Realistic Model of Parallel Computation," </title> <booktitle> Proc. of 4-th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, </booktitle> <pages> pp. 1-12, </pages> <year> 1993. </year>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 5, 8, 10, 11, 15, 16, 17] </ref>. In most of these models, processors are assumed to communicate using a point-to-point message router. Composing more involved communication operations by having to specify fine-scheduling details places a significant burden on application programmers.
Reference: [6] <author> J.J. Dongarra, R. Hempel, A.J.G. Hey, D.W. Walker. </author> <title> "A Proposal for a User-level, Message Passing Interface in a Distributed Memory Environment", </title> <type> Technical Report TM 12231, </type> <institution> Oak Ridge National Laboratory, </institution> <year> 1993. </year>
Reference-contexts: The importance of being able to operate on independent submachines has been recognized. It has been incorporated into the Message Passing Interface (MPI) <ref> [6] </ref> and has been extended to arbitrary process groups [1]. In our evaluation of communication units we assume that independent routing in sub-machines is possible.
Reference: [7] <author> C. Dwork, M. Herlihy, O. Waarts, </author> <title> "Contention in Shared Memory Algorithms", </title> <booktitle> Proc. of 25-th ACM STOC, </booktitle> <pages> pp. 174-183, </pages> <year> 1993. </year>
Reference: [8] <author> P.B. Gibbons, </author> <title> "A More Practical PRAM Model," </title> <booktitle> Proc. of 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 158-168, </pages> <year> 1989. </year>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 5, 8, 10, 11, 15, 16, 17] </ref>. In most of these models, processors are assumed to communicate using a point-to-point message router. Composing more involved communication operations by having to specify fine-scheduling details places a significant burden on application programmers.
Reference: [9] <author> S.E. Hambrusch, F. Hameed, and A. Khokhar, </author> <title> "A Study of Coarse-Grained Communication Operations on Mesh Architectures" Technical Report, </title> <institution> Purdue University, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: The number of communication units charged for each of the algorithms is almost identical to the ones charged for corresponding one-to-all algorithm. On the Delta, the best one-to-all algorithms did not correspond to the best all-to-one algorithms. For a complete discussion we refer to <ref> [9] </ref>. 4.3 All-to-all Routing The most straightforward 1-level approach for all-to-all routing is to have each processor send its p 1 messages, one by one, regardless of what other processors are doing. This approach is used in Algorithm 1-lev-dir. <p> Algorithm 2-lev-r,c consists of only 2 steps, with each step sending out a total of pL bytes in the form of p p messages. The approach used in this algorithm is tailored towards the mesh architecture. For a detailed description we refer to <ref> [9] </ref>. We have implemented the above mentioned algorithms on a 256-processor Intel Delta. The implementation results are compared to the predicted performance in Figures 6 and 7. nonblocking sends and nonblocking receives. The experimental results show that Algorithm 2-lev-c,r performs best for small message sizes ( 256 bytes).
Reference: [10] <author> T. Heywood and S. Ranka, </author> <title> "A Practical Hierarchical Model of Parallel Computation: I. The model," </title> <journal> JPDC, </journal> <volume> Vol. 16, </volume> <pages> pp. 212-232, </pages> <year> 1992. </year>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 5, 8, 10, 11, 15, 16, 17] </ref>. In most of these models, processors are assumed to communicate using a point-to-point message router. Composing more involved communication operations by having to specify fine-scheduling details places a significant burden on application programmers.
Reference: [11] <author> P. Liu, W. Aiello, S. Bhatt, </author> <title> "An Atomic Model for Message Passing," </title> <booktitle> Proc. of ACM SPAA, </booktitle> <pages> pp. 154-163, </pages> <year> 1993. </year>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 5, 8, 10, 11, 15, 16, 17] </ref>. In most of these models, processors are assumed to communicate using a point-to-point message router. Composing more involved communication operations by having to specify fine-scheduling details places a significant burden on application programmers.
Reference: [12] <author> R. Ponnusamy, A. Choudhary, G. Fox, </author> <title> "Communication Overhead on CM5: An Experimental Performance Evaluation," </title> <booktitle> Proc. of 4-th Symp. on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pp. 108-115, </pages> <year> 1992. </year>
Reference-contexts: Our results indicate that the efficiency of a communication operation is influenced by the relationship among parameters of the parallel machine, as well as by the relationship of the parameters to the amount of data involved. This agrees with other research done on the implementation of communication operations, <ref> [1, 2, 4, 12] </ref>. In order to classify the different approaches used in our implementations, we introduce the notion of a k-level algorithm. <p> Common are linear permutations and exclusive-or permutations. Implementations of these approaches on different machines have shown exclusive-or permutations to be superior to linear permutations <ref> [12, 13] </ref>. Another interesting approach for partitioning all-to-all routings into permutations has been introduced in [14]. We call this approach partitioning into balanced permutations. Balanced permutations are relevant for mesh architectures since they result in a smaller congestion over the links compared to linear and exclusive-or permutations.
Reference: [13] <author> R. Thakur, A. Choudhary, </author> <title> "All-to-all Communication on Meshes with Wormhole Routing," </title> <booktitle> to appear in Proc. of IPPS, </booktitle> <pages> pp. 561-565, </pages> <year> 1994. </year>
Reference-contexts: Common are linear permutations and exclusive-or permutations. Implementations of these approaches on different machines have shown exclusive-or permutations to be superior to linear permutations <ref> [12, 13] </ref>. Another interesting approach for partitioning all-to-all routings into permutations has been introduced in [14]. We call this approach partitioning into balanced permutations. Balanced permutations are relevant for mesh architectures since they result in a smaller congestion over the links compared to linear and exclusive-or permutations. <p> However, in actual implementations different permutations induce different patterns of link and processor congestion and thus give a different performance. Capturing this behaviour in the model and its metric would be difficult. The approach in Algorithm logp-lev-bfly has consistently been judged as being expensive for large message sizes <ref> [4, 13] </ref>. Our metric and the observed performance on the Delta, confirms that as well.
Reference: [14] <author> D.S. Scott, </author> <title> "Efficient All-to-All Communication Patterns in Hypercube and Mesh Topologies," </title> <booktitle> Proc. of 6-th Distributed Memory Computing Conference, </booktitle> <pages> pp. 398-403, </pages> <year> 1991. </year>
Reference-contexts: Common are linear permutations and exclusive-or permutations. Implementations of these approaches on different machines have shown exclusive-or permutations to be superior to linear permutations [12, 13]. Another interesting approach for partitioning all-to-all routings into permutations has been introduced in <ref> [14] </ref>. We call this approach partitioning into balanced permutations. Balanced permutations are relevant for mesh architectures since they result in a smaller congestion over the links compared to linear and exclusive-or permutations. We refer to an algorithm that performs all-to-all routing by partitioning into permutations as Algorithm 1-lev-perm.
Reference: [15] <author> P. de la Torre and C.P. Kruskal, </author> <title> "Towards a Single Model of Efficient Computation in Real Parallel Machines," </title> <journal> Future Generation Computer Systems, </journal> <volume> Vol. 8, </volume> <pages> pp. 395-408. </pages> <year> 1992. </year>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 5, 8, 10, 11, 15, 16, 17] </ref>. In most of these models, processors are assumed to communicate using a point-to-point message router. Composing more involved communication operations by having to specify fine-scheduling details places a significant burden on application programmers.
Reference: [16] <author> L.G. Valiant, </author> <title> "A Bridging Model for Parallel Computation," </title> <journal> CACM, 1990, </journal> <volume> Vol. 33, No. 8, </volume> <pages> pp. 103-111. </pages>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 5, 8, 10, 11, 15, 16, 17] </ref>. In most of these models, processors are assumed to communicate using a point-to-point message router. Composing more involved communication operations by having to specify fine-scheduling details places a significant burden on application programmers. <p> For the initial validation of the C 3 -model, communication operations have been implemented on the Intel Touchstone Delta, and performance results are discussed and compared to the predicted performance. We assume that computation is synchronized by a barrier-style synchronization mechanism similar to the one described in <ref> [16] </ref>. More precisely, an algorithm can be partitioned into a sequence of supersteps, with each superstep corresponding to local computation followed by sending and receiving messages. Synchronization occurs between supersteps. We express the performance of a superstep, and thus of an algorithm, in terms of computation units and communication units.
Reference: [17] <author> D.S. Wills and W. Dally, </author> <title> "Pi: A Parallel Architecture Interface," </title> <booktitle> Proc. of 4-th Symp. on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pp. 345-352, </pages> <year> 1992. </year>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 5, 8, 10, 11, 15, 16, 17] </ref>. In most of these models, processors are assumed to communicate using a point-to-point message router. Composing more involved communication operations by having to specify fine-scheduling details places a significant burden on application programmers.
References-found: 17

