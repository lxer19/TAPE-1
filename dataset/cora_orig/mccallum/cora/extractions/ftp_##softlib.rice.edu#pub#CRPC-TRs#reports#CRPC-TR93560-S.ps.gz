URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR93560-S.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: Cache Coherence Using Local Knowledge global communication at run-time, offer better scalability, at the cost
Author: Ervan Darnell Ken Kennedy 
Keyword: "Local knowledge" coherence strategies,  
Note: which avoid  
Address: Houston, TX 77251-1892  
Affiliation: Computer Science Department, Rice University,  
Abstract: We propose a new strategy, TS1, that requires less extra storage than TS, only one extra bit per cache line, and can produce more cache hits by exploiting sophisticated compiler analysis. TS1 handles common synchronization paradigms including DOALL, DOACROSS, and critical sections. Early results show TS1 is, worst case, slightly slower than TS. Best case, TS1's flexibility allows for significant improvements. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. A. Abramson, K. Ramamohanarao, and M. Ross. </author> <title> A scalable cache coherence mechanism using a selectively clearable cache memory. </title> <journal> The Australian Computer Journal, </journal> <volume> 21(1), </volume> <month> Feb. </month> <year> 1989. </year>
Reference-contexts: Special layouts and strides could reduce this further. This is similar to what PEI does. Other authors have proposed O (1) time invalidation implementations which work by accessing cache row and column addresses <ref> [1] </ref>. 4.3 Software support To determine what to invalidate, TS1 uses compile time analysis to determine what is written for each epoch. The compiler makes its best estimate that is sure to include every address actually written.
Reference: [2] <author> L. M. Censier and P. Feautrier. </author> <title> A new solution to coherence problems in multicache systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-27(12):1112-1118, </volume> <month> Dec. </month> <year> 1978. </year>
Reference-contexts: Directory strategies <ref> [2, 8, 11, 19] </ref>, in which a directory entry associated with each memory location (or cache line) indicates which processors have cached values for that location, seem more promising for large-scale systems. However, directories can require large amounts of additional storage and directory maintenance operations may substantially increase network traffic. <p> If this global knowledge of what is written is shared at run time, we would characterize it as a global strategy. Global strategies are usually thought of as hardware strategies, e.g. snoopy caches [16, 18] and directory based caches <ref> [2, 11, 19] </ref>. Other global strategies, e.g. OS level page strategies [17], are software strategies. Cache misses have four causes: initial loading, cache size, cache organization (e.g. associativity), and invalidation to preserve coherence between processors (sharing induced). Coherence strategies are concerned only with the last category, sharing induced misses.
Reference: [3] <author> H. Cheong. </author> <title> Life-span strategy a compiler-based approach to cache coherence. </title> <booktitle> In Proceedings of 1992 International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: With this strategy, no shared value crosses an epoch boundary in cache, ensuring that caches are coherent. The penalty is that no inter-epoch reuse is preserved for shared variables. FSI is a static strategy. 3.2 Life Span Strategy Life Span Strategy (LSS) <ref> [3] </ref> is an improvement over FSI. Instead of resetting the epoch bit after every epoch, the epoch bit for a given cache line is reset 3 after the end of the next epoch.
Reference: [4] <author> H. Cheong and A. Veidenbaum. </author> <title> Compiler-directed cache management for multiprocessors. </title> <journal> Computer, </journal> <volume> 23(6) </volume> <pages> 39-47, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: A (2) write allocated on processor 2 ENDDO DOALL I A (I+1)=... A (2) write allocated on processor 1 ENDDO DOALL I B (I)=A (I)+1 Access stale A (2) on processor 2 ENDDO coherence control 2 Definitions and framework Fork-join programs are composed of a series of epochs <ref> [4] </ref>. Each epoch consists of one or more instances which run in parallel. Each epoch is either a (fork-join) parallel loop with no internal synchronization, e.g. a Fortran DOALL, or a serial region between parallel loops. <p> If A (2) were written on p i between the second and third epochs (not shown in the figure) it would again be valid (on p i ) without coherence control. Numerous previous authors have tried to capture this notion in various analytical ways <ref> [4, 6, 9] </ref>. Here we simply note the dynamic behavior that causes stal-eness without addressing its detection at compile time. Coherence is maintained by making sure that values are communicated between caches when necessary. <p> If no global knowledge is shared at run time, then coherence must rely on locally collected knowledge plus whatever global knowledge was collected at compile time. Previous local knowledge strategies have been referred to in the literature as software <ref> [4, 6] </ref> or hardware [14] strategies depending on whether most of the work was done in software or hardware. We consider all of these strategies to be similar and refer to them collectively as local strategies. <p> Those aspects of previous strategies not directly concerned with coherence are covered in section 6.3. 3.1 Fast Selective Invalidation One of the first strategies was Fast Selective Invalidate (FSI) <ref> [4] </ref>. FSI determines at compile time which references access shared variables that might have been previously written. These are designated memory reads. For memory reads to be cache hits they must be found in the cache and have a special epoch bit set (originally called a change bit). <p> The use of an epoch bit alone would not suffice to prevent this. For PEI to achieve good results, arrays, or in the worst case, each dimension of an array, must occupy an amount of memory equal to a power of two. 3.4 Time Stamping Time stamping (TS) strategies <ref> [4, 14] </ref> are more effective at preserving reuse than any of the previously mentioned strategies. For a given quality of compiler analysis, it is impossible to achieve a better hit ratio with any other local strategy. <p> Deliberate attempts to increase loop affinity [13] will further improve the benefit of dynamic strategies. 4 One-Bit Time Stamping Even though both proposed time-stamping strategies <ref> [4, 14] </ref> are hit-rate optimal local strategies, they require substantial additional hardware. TS1 achieves the same optimal hit ratio with fewer special bits per cache line and no special bits per instruction word.
Reference: [5] <author> R. Covington, S. Dwarkadas, J. Jump, J. Sinclair, and S. Madala. </author> <title> Efficient simulation of paralle computer systems. </title> <journal> International Journal in Comuter Simulation, </journal> <volume> 1 </volume> <pages> 31-58, </pages> <year> 1991. </year> <title> overview of RPPT. </title>
Reference-contexts: For TS, invalidate calls were applied to whole arrays in an epoch for which the array appeared on the left hand side of an assignment. This has the same effect on hit rate as the suggested TS implementation. These modified programs were then run through the the RPPT <ref> [5] </ref> simulator. This simulator operates by modifying the assembly code to trap at every global memory reference which is then passed off to a particular architecture simulator. For identical runs of the test programs, we compared TS, TS1, and hardware coherence.
Reference: [6] <author> R. Cytron, S. Karlovsky, and K. McAuliffe. </author> <title> Automatic management of programmable caches. </title> <booktitle> In Proc. of the 1988 International Conference on Parallel Processing, </booktitle> <pages> pages 229-238, </pages> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: If A (2) were written on p i between the second and third epochs (not shown in the figure) it would again be valid (on p i ) without coherence control. Numerous previous authors have tried to capture this notion in various analytical ways <ref> [4, 6, 9] </ref>. Here we simply note the dynamic behavior that causes stal-eness without addressing its detection at compile time. Coherence is maintained by making sure that values are communicated between caches when necessary. <p> If no global knowledge is shared at run time, then coherence must rely on locally collected knowledge plus whatever global knowledge was collected at compile time. Previous local knowledge strategies have been referred to in the literature as software <ref> [4, 6] </ref> or hardware [14] strategies depending on whether most of the work was done in software or hardware. We consider all of these strategies to be similar and refer to them collectively as local strategies. <p> The tradeoff is that dynamic strategies require some additional hardware support to handle marking bits. Static strategies require no hardware support other than the ability to invalidate cache lines under software control. Static strategies can be used on some existing machines, such as the BBN TC2000 <ref> [6, 7] </ref>. DOALL I=1,N A (I)=... ENDDO DOALL I=1,N A (I)=A (I)+... ENDDO DOALL I=1,N B (I)=A (I)+1 ENDDO in the first epoch cannot be allowed to reach the third epoch.
Reference: [7] <author> E. Darnell, J. Mellor-Crummey, and K. Kennedy. </author> <title> Automatic software cache coherence through vectorization. </title> <booktitle> In Proceedings of 1992 International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1992. </year> <note> Also available as expanded Technical Report CRPC-TR92197, Center for Research on Parallel Computation, </note> <month> January </month> <year> 1992. </year>
Reference-contexts: The tradeoff is that dynamic strategies require some additional hardware support to handle marking bits. Static strategies require no hardware support other than the ability to invalidate cache lines under software control. Static strategies can be used on some existing machines, such as the BBN TC2000 <ref> [6, 7] </ref>. DOALL I=1,N A (I)=... ENDDO DOALL I=1,N A (I)=A (I)+... ENDDO DOALL I=1,N B (I)=A (I)+1 ENDDO in the first epoch cannot be allowed to reach the third epoch. <p> The high level invalidate would then loop over the proper range of pages and lines. Even though this would take O (jsectionj), acceptable performance could still be achieved. Previously, we examined the efficiency of this kind of invalidate for a static strategy <ref> [7] </ref>. A faster, but more complex, invalidate could work by using a bit mask to determine which addresses to invalidate. With only `=' comparators and no extra storage, a section could be invalidated in O (log (jsectionj)) time. Special layouts and strides could reduce this further.
Reference: [8] <author> D. James, A. Laundrie, S. Gjessing, and G. Sohi. </author> <title> Scalable coherent interface. </title> <journal> Computer, </journal> <volume> 23(6), </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: Directory strategies <ref> [2, 8, 11, 19] </ref>, in which a directory entry associated with each memory location (or cache line) indicates which processors have cached values for that location, seem more promising for large-scale systems. However, directories can require large amounts of additional storage and directory maintenance operations may substantially increase network traffic.
Reference: [9] <author> S. Karlovsky. </author> <title> Automatic management of programmable caches: Algorithms and experience. </title> <type> Technical Report 89-8010, </type> <institution> Center for Supercomputing Research and Development, University of Illinois, Urbana, IL, </institution> <month> July </month> <year> 1989. </year>
Reference-contexts: If A (2) were written on p i between the second and third epochs (not shown in the figure) it would again be valid (on p i ) without coherence control. Numerous previous authors have tried to capture this notion in various analytical ways <ref> [4, 6, 9] </ref>. Here we simply note the dynamic behavior that causes stal-eness without addressing its detection at compile time. Coherence is maintained by making sure that values are communicated between caches when necessary.
Reference: [10] <author> L. Lamport. </author> <title> How to make a multiprocessor that correctly executes multiprocess programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9), </volume> <month> Sept. </month> <year> 1979. </year>
Reference-contexts: 1 Introduction Data race free programs executing on a shared memory multiprocessor are expected to have the same semantics as if they were executing on a sequential processor. For this to be the case, memory must appear sequentially consistent <ref> [10] </ref>. Caches on shared memory multiprocessors must have some global knowledge about executing programs otherwise they could fail to preserve sequential consistency by retaining stale values. Most approaches to the cache coherence problem have focused on hardware mechanisms to maintain coherence.
Reference: [11] <author> D. Lenoski, J. Laudon, K. Gharachorloo, W. Weber, A. Gupta, J. Hennessy, M. Horowitz, and M. Lam. </author> <title> The Standford DASH multiprocessor. </title> <journal> Computer, </journal> <volume> 25(3) </volume> <pages> 63-79, </pages> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: Directory strategies <ref> [2, 8, 11, 19] </ref>, in which a directory entry associated with each memory location (or cache line) indicates which processors have cached values for that location, seem more promising for large-scale systems. However, directories can require large amounts of additional storage and directory maintenance operations may substantially increase network traffic. <p> If this global knowledge of what is written is shared at run time, we would characterize it as a global strategy. Global strategies are usually thought of as hardware strategies, e.g. snoopy caches [16, 18] and directory based caches <ref> [2, 11, 19] </ref>. Other global strategies, e.g. OS level page strategies [17], are software strategies. Cache misses have four causes: initial loading, cache size, cache organization (e.g. associativity), and invalidation to preserve coherence between processors (sharing induced). Coherence strategies are concerned only with the last category, sharing induced misses.
Reference: [12] <author> A. Louri and H. Sung. </author> <title> A compiler directed cache coherence scheme with fast and parallel explicit invalidation. </title> <booktitle> In Proc. of the 1992 International Conference on Parallel Processing, </booktitle> <pages> pages 2-9, </pages> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: Additional bits would not help because the values would already be evicted before the count runs out. 3.3 Parallel Explicit Invalidation Parallel Explicit Invalidation (PEI) <ref> [12] </ref> works by combining an invalidate with each write instruction. Writing an element in an array invalidates everything in the array except for the element itself.
Reference: [13] <author> E. P. Markatos and T. J. LeBlanc. </author> <title> Using processor affinity in loop scheduling on shared-memory multiprocessors. </title> <booktitle> In Proceedings of 1992 International Conference on Supercomputing, </booktitle> <pages> pages 104-113, </pages> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: In practice, this utilization of DOALL semantics can make a dramatic difference because it captures reuse when subsequent loops have the same schedule and same reference pattern, for instance a DOALL inside of a serial loop will likely meet this condition. Deliberate attempts to increase loop affinity <ref> [13] </ref> will further improve the benefit of dynamic strategies. 4 One-Bit Time Stamping Even though both proposed time-stamping strategies [4, 14] are hit-rate optimal local strategies, they require substantial additional hardware.
Reference: [14] <author> S. Min and J. Baer. </author> <title> Design and analysis of a scalable cache coherence scheme based on clocks and timestamps. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(1) </volume> <pages> 25-44, </pages> <month> Jan. </month> <year> 1992. </year>
Reference-contexts: If no global knowledge is shared at run time, then coherence must rely on locally collected knowledge plus whatever global knowledge was collected at compile time. Previous local knowledge strategies have been referred to in the literature as software [4, 6] or hardware <ref> [14] </ref> strategies depending on whether most of the work was done in software or hardware. We consider all of these strategies to be similar and refer to them collectively as local strategies. <p> The use of an epoch bit alone would not suffice to prevent this. For PEI to achieve good results, arrays, or in the worst case, each dimension of an array, must occupy an amount of memory equal to a power of two. 3.4 Time Stamping Time stamping (TS) strategies <ref> [4, 14] </ref> are more effective at preserving reuse than any of the previously mentioned strategies. For a given quality of compiler analysis, it is impossible to achieve a better hit ratio with any other local strategy. <p> Deliberate attempts to increase loop affinity [13] will further improve the benefit of dynamic strategies. 4 One-Bit Time Stamping Even though both proposed time-stamping strategies <ref> [4, 14] </ref> are hit-rate optimal local strategies, they require substantial additional hardware. TS1 achieves the same optimal hit ratio with fewer special bits per cache line and no special bits per instruction word. <p> For DOACROSS, the epoch bit in TS1 indicates that values can be reused on subsequent instances (not epochs). Since two subsequent iterations are almost certain to be scheduled to different processors, the epoch bit is useless. Of the previous strategies surveyed, only Min and Baer's TS <ref> [14] </ref> handles DOACROSS. It increments the version number for an array at the end of a DOACROSS epoch. <p> In some cases involving DOACROSS, a live value is guaranteed to be invalidated before its next reference. In this case, there is no need to allocate a cache line. Read-thru and write-thru could selectively be used to advantage. Min and Baer <ref> [14] </ref> discuss this at length. This can be done with the bits already present in their strategy.
Reference: [15] <author> S. Min, J. Baer, and H. Kim. </author> <title> An efficient caching support for critical sections in large-scale shared-memory multiprocessors. </title> <booktitle> In Proc. of the 1990 International Conference on Supercomputing/Computer Architecture News, </booktitle> <pages> pages 4-47, </pages> <month> June </month> <year> 1990. </year> <journal> Special issue of Computer Architecture News, </journal> <volume> 18(3), </volume> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: Most approaches to the cache coherence problem have focused on hardware mechanisms to maintain coherence. Unfortunately, the overhead of maintaining coherence in hardware can be high; scaling systems based on hardware coherence is a difficult problem <ref> [15] </ref>.
Reference: [16] <author> A. Osterhaug, </author> <title> editor. Guide to Parallel Programming on Sequent Computer Systems. </title> <publisher> Sequent Technical Publications, </publisher> <address> San Diego, CA, </address> <year> 1989. </year>
Reference-contexts: was supported in part by the National Science Foundation under Cooperative Agreement CCR-9120008 through its research contracts with the Center for Research on Parallel Computation at Rice University. y As published in Supercomputing '93 z corresponding author: ervan@cs.rice.edu some common bus, are now in common use for small scale systems <ref> [16, 18] </ref>; however, snoopy strategies are problematic for large-scale machines because such machines cannot be based on a single, central broadcast medium for lack of sufficient bandwidth. <p> This set of writes can be exactly the locations written or any approximating superset. If this global knowledge of what is written is shared at run time, we would characterize it as a global strategy. Global strategies are usually thought of as hardware strategies, e.g. snoopy caches <ref> [16, 18] </ref> and directory based caches [2, 11, 19]. Other global strategies, e.g. OS level page strategies [17], are software strategies. Cache misses have four causes: initial loading, cache size, cache organization (e.g. associativity), and invalidation to preserve coherence between processors (sharing induced).
Reference: [17] <author> K. Peterson and K. Li. </author> <title> Cache coherence for shared memory multiprocessors based on virtual memory support. </title> <booktitle> In Proceedings of the 7th International Parallel Processing Symposium, </booktitle> <month> Apr. </month> <year> 1993. </year>
Reference-contexts: Global strategies are usually thought of as hardware strategies, e.g. snoopy caches [16, 18] and directory based caches [2, 11, 19]. Other global strategies, e.g. OS level page strategies <ref> [17] </ref>, are software strategies. Cache misses have four causes: initial loading, cache size, cache organization (e.g. associativity), and invalidation to preserve coherence between processors (sharing induced). Coherence strategies are concerned only with the last category, sharing induced misses. No currently existing global strategy causes a logically unnecessary sharing miss.
Reference: [18] <author> D. Schanin. </author> <title> The design and development of a very high speed system bus the encore multimax nanobus. </title> <booktitle> In Proceedings of the Fall Joint Computer Conference, </booktitle> <pages> pages 410-418, </pages> <month> Nov. </month> <year> 1986. </year>
Reference-contexts: was supported in part by the National Science Foundation under Cooperative Agreement CCR-9120008 through its research contracts with the Center for Research on Parallel Computation at Rice University. y As published in Supercomputing '93 z corresponding author: ervan@cs.rice.edu some common bus, are now in common use for small scale systems <ref> [16, 18] </ref>; however, snoopy strategies are problematic for large-scale machines because such machines cannot be based on a single, central broadcast medium for lack of sufficient bandwidth. <p> This set of writes can be exactly the locations written or any approximating superset. If this global knowledge of what is written is shared at run time, we would characterize it as a global strategy. Global strategies are usually thought of as hardware strategies, e.g. snoopy caches <ref> [16, 18] </ref> and directory based caches [2, 11, 19]. Other global strategies, e.g. OS level page strategies [17], are software strategies. Cache misses have four causes: initial loading, cache size, cache organization (e.g. associativity), and invalidation to preserve coherence between processors (sharing induced).
Reference: [19] <author> J. Willis, A. Sanderson, and C. Hill. </author> <title> Cache coherence in systems with parallel communication channels & many processors. </title> <booktitle> In Supercomputing '90, </booktitle> <pages> pages 554-563, </pages> <year> 1990. </year> <month> 10 </month>
Reference-contexts: Directory strategies <ref> [2, 8, 11, 19] </ref>, in which a directory entry associated with each memory location (or cache line) indicates which processors have cached values for that location, seem more promising for large-scale systems. However, directories can require large amounts of additional storage and directory maintenance operations may substantially increase network traffic. <p> If this global knowledge of what is written is shared at run time, we would characterize it as a global strategy. Global strategies are usually thought of as hardware strategies, e.g. snoopy caches [16, 18] and directory based caches <ref> [2, 11, 19] </ref>. Other global strategies, e.g. OS level page strategies [17], are software strategies. Cache misses have four causes: initial loading, cache size, cache organization (e.g. associativity), and invalidation to preserve coherence between processors (sharing induced). Coherence strategies are concerned only with the last category, sharing induced misses.
References-found: 19

