URL: http://www.cs.berkeley.edu/~lazzaro/biblio/alsr-jssc.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~lazzaro/biblio/bib.html
Root-URL: 
Title: A Silicon Model of an Auditory Neural Representation of Spectral Shape  
Author: John Lazzaro 
Address: Pasadena, California, USA  
Affiliation: California Institute of Technology  
Abstract: The paper describes an analog integrated circuit that implements an auditory neural representation of spectral shape. The circuit contains silicon models of the cochlea, inner hair cells, spiral ganglion cells, and the neurons that compute an amplitude-invariant representation of spectral shape. The chip uses the temporal information in each silicon auditory-nerve fiber to compute this final representation. The chip was fabricated and fully tested; the paper includes data comparing the silicon auditory-nerve representation and the final representation. The 9000 transistor chip computes all outputs in real time using analog continuous-time processing. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. P. Lippmann, </author> <title> "Review of neural networks for speech recognition," </title> <journal> Neural Computation, </journal> <volume> vol 1, </volume> <pages> pp. 1-38, </pages> <month> Spring </month> <year> 1989. </year>
Reference-contexts: Sound recognition, sound localization, and active sonar are practical and interesting engineering endeavors. There is renewed interest by the engineering community in understanding biological approaches to these problems and in adapting these biological solutions to engineering systems <ref> [1] </ref>. The first task is difficult, because of the incomplete knowledge of the structure and function of auditory processing in the brain. The second task is also difficult, because of the large computational demands of neural processing.
Reference: [2] <author> C. Mead, </author> <title> Analog VLSI and Neural Systems. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1989, </year> <pages> pp. 3-9. </pages>
Reference-contexts: The second task is also difficult, because of the large computational demands of neural processing. We are exploring analog VLSI technology as a computational medium for auditory neural processing. Analog VLSI offers real-time, low-power computation of neural algorithms, and shares many of the computational properties of the biological substrate <ref> [2] </ref>. The effort began with silicon models of the hydrodynamics of the cochlea [3] and of auditory-nerve response [4]. We used these cochlear circuits as components in silicon models of auditory lateralization [5] and of pitch perception [6].
Reference: [3] <author> R. F. Lyon and C. Mead, </author> <title> "An analog electronic cochlea," </title> <journal> IEEE Trans. Acoust., Speech, Signal Processing, </journal> <volume> vol. 36, </volume> <pages> pp. 1119-1134, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: We are exploring analog VLSI technology as a computational medium for auditory neural processing. Analog VLSI offers real-time, low-power computation of neural algorithms, and shares many of the computational properties of the biological substrate [2]. The effort began with silicon models of the hydrodynamics of the cochlea <ref> [3] </ref> and of auditory-nerve response [4]. We used these cochlear circuits as components in silicon models of auditory lateralization [5] and of pitch perception [6]. We believe that sound recognition, like visual object recognition, benefits from multiple representations of sensory input. <p> We have designed, fabricated, and tested an analog VLSI chip that implements this algorithm. 3. Chip Architecture input connects to a silicon model of the mechanical processing of the cochlea <ref> [3] </ref>. The circuit is a one-dimensional physical model of the traveling-wave structure formed by the basilar membrane. In this viewpoint of cochlear function, the exponentially tapered stiffness of the basilar membrane and the motility of the outer hair cells combine to produce a pseudoresonant structure. <p> V o q C C V i V s Hysteretic Differentiator Half-Wave Rectifier V r V o V l (b) cochleas, with voltage input V i , voltage output V o , and control voltages t and q. Amplifiers are wide-range transconductance amplifiers <ref> [3] </ref>. (b) Circuit model of inner-hair-cell transduction, with voltage input V i , voltage output V o , and control voltages V y , V r , and V s . (c) Spike generation and combination circuit, with voltage input V i , previous pulse input V l , and combined <p> In addition, the correlator circuit shown in Figure 3 (b) requires non-physiological spike widths for operation, and is another candidate for more realistic models. The inner-hair-cell and spiral-ganglion-cell circuits also lack several important characteristics of their physiological counterparts [4], as does the silicon cochlea <ref> [3] </ref>. The circuit implements autocorrelation in a straightforward way, using a time-delay element and a spike correlator. A biological implementation may implement autocorrelation differently. For example, a hypothetical correlator neuron could work in the following way.
Reference: [4] <author> J. P. Lazzaro and C. Mead, </author> <title> "Circuit models of sensory transduction in the cochlea," in Analog VLSI Implementations of Neural Networks, </title> <editor> C. Mead and M. Ismail, Eds. </editor> <publisher> Norwell, </publisher> <address> MA: </address> <publisher> Kluwer Academic Publishers, </publisher> <year> 1989, </year> <pages> pp. 85-101. </pages>
Reference-contexts: Analog VLSI offers real-time, low-power computation of neural algorithms, and shares many of the computational properties of the biological substrate [2]. The effort began with silicon models of the hydrodynamics of the cochlea [3] and of auditory-nerve response <ref> [4] </ref>. We used these cochlear circuits as components in silicon models of auditory lateralization [5] and of pitch perception [6]. We believe that sound recognition, like visual object recognition, benefits from multiple representations of sensory input. <p> The symbol f j denotes the center frequency at positions along the silicon cochlea. Outputs from the silicon cochlea connect to circuit models of inner-hair-cell transduction <ref> [4] </ref>, drawn as an ellipse. This circuit connects to circuits modeling spike generation and combination, drawn as boxes marked with a pulse [20]. The signal i j (t) represent the activity of a single spiral-ganglion-neuron circuit; the signal o j (t) represent the combined response of 11 spiral-ganglion-neuron circuits. <p> The correlation circuit, drawn as a small circle, performs a Boolean AND operation on the delayed and undelayed signals. The output of each second-order section connects to a circuit that models the signal--processing operations that occur during inner-hair-cell transduction <ref> [4] </ref>; each ellipse in signal, responding to motion in only one direction. Inner hair cells primarily respond to the velocity of basilar-membrane motion, implicitly computing the time derivative of basilar-membrane displacement [9]. <p> Control voltage V w scales output pulse rate; control voltage V p sets output pulse width. sign, accentuating phase information in the signal. The output voltage of the hysteretic differentiator connects to a half-wave current rectifier <ref> [4] </ref>. In this circuit, current from positive voltage transients is shunted to ground, while current from negative voltage transients passes through the p-channel transistor whose gate is labeled V o . <p> In addition, the correlator circuit shown in Figure 3 (b) requires non-physiological spike widths for operation, and is another candidate for more realistic models. The inner-hair-cell and spiral-ganglion-cell circuits also lack several important characteristics of their physiological counterparts <ref> [4] </ref>, as does the silicon cochlea [3]. The circuit implements autocorrelation in a straightforward way, using a time-delay element and a spike correlator. A biological implementation may implement autocorrelation differently. For example, a hypothetical correlator neuron could work in the following way.
Reference: [5] <author> J. P. Lazzaro and C. Mead, </author> <title> "Silicon models of auditory localization," </title> <journal> Neural Computation, </journal> <volume> vol 1, </volume> <pages> pp. 47-57, </pages> <month> Spring </month> <year> 1989. </year>
Reference-contexts: The effort began with silicon models of the hydrodynamics of the cochlea [3] and of auditory-nerve response [4]. We used these cochlear circuits as components in silicon models of auditory lateralization <ref> [5] </ref> and of pitch perception [6]. We believe that sound recognition, like visual object recognition, benefits from multiple representations of sensory input. These representations should be dedicated to the robust 1 Present Address: Computer Science Division, EECS, University of California at Berkeley. extraction of different properties of the input.
Reference: [6] <author> J. P. Lazzaro and C. Mead, </author> <title> "Silicon models of pitch perception," </title> <journal> Proc. Natl. Acad. Sci. USA, </journal> <volume> vol 86, </volume> <pages> pp. 9597-9601, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: The effort began with silicon models of the hydrodynamics of the cochlea [3] and of auditory-nerve response [4]. We used these cochlear circuits as components in silicon models of auditory lateralization [5] and of pitch perception <ref> [6] </ref>. We believe that sound recognition, like visual object recognition, benefits from multiple representations of sensory input. These representations should be dedicated to the robust 1 Present Address: Computer Science Division, EECS, University of California at Berkeley. extraction of different properties of the input.
Reference: [7] <author> S. Greenberg, </author> <title> "The ear as a speech analyzer," </title> <journal> J. Phonetics, </journal> <volume> vol 16, </volume> <pages> pp. 139-149, </pages> <year> 1988. </year>
Reference-contexts: Several amplitude-invariant representations of spectral shape have been proposed in the auditory literature <ref> [7] </ref>; these proposals include neural algorithms for computing the new representation from the auditory-nerve input. In this paper, we report on an analog integrated circuit that implements one of these algorithms. The circuit contains 9000 transistors, and computes the representation in real time, using analog, continuous-time processing. <p> At sound pressure levels (SPL) typical of normal conversation, about 60% of the auditory-nerve fibers are saturated. This fact is paradoxical, given that psychoacoustic experiments show that speech intelligibility improves with increased SPL <ref> [7] </ref>. Because of these characteristics, many auditory theorists consider a mean rate en-coding of spectral shape insufficient for explaining auditory perception. Several theories involve the extraction of information from the fine-time structure of auditory-nerve outputs. <p> A criticism of matched filter is neurophysiological implausibility; in specific, how does a neuron that implements a matched filter know the proper f j <ref> [7] </ref>? One can imagine an adaptive neuron, that learns the correct f j by experience. Alternatively, one can imagine time delays hard-coded into the neural circuit.
Reference: [8] <author> D. O. Kim, </author> <title> "Functional roles of the inner- and outer-haircell subsystems in the cochlea and brainstem ," in Hearing Science, </title> <editor> C. I. Berlin, Eds. </editor> <address> San Diego, CA: </address> <publisher> College-Hill Press, </publisher> <year> 1984, </year> <pages> pp. 241-262. </pages>
Reference-contexts: Over much of its length, the velocity of propagation along the basilar membrane decreases exponentially with distance. The structure also contains active electromechanical elements; outer hair cells have motile properties, acting to reduce the damping of the passive basilar membrane and thus allowing weaker signals to be heard <ref> [8] </ref>. In signal processing terms, a point along the basilar membrane acts as a low-pass filter with a resonant peak and a sharp cutoff. The resonant frequency of the low-pass filter decreases exponentially at points progressively distant from the mechanical input.
Reference: [9] <author> P. Dallos, </author> <title> "Response characteristics of mammalian cochlear hair cells," </title> <journal> J. Neurosci, </journal> <volume> vol 5, </volume> <pages> pp. 1591-1608, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: The resonant frequency of the low-pass filter decreases exponentially at points progressively distant from the mechanical input. Inner hair cells, distributed at regular intervals along the basilar membrane, act as electromechanical transducers, converting basilar-membrane vibrations into graded electrical signals <ref> [9] </ref>. Synapses from spiral-ganglion neurons connect to the inner hair cells; most auditory-nerve fibers sending signals to the brain are axons from these spiral-ganglion neurons. Unlike inner hair cells, the auditory-nerve signals are not graded electrical potentials; the auditory-nerve fibers produce fixed-width, fixed-height pulses in response to inner-hair-cell electrical activity. <p> Inner hair cells primarily respond to the velocity of basilar-membrane motion, implicitly computing the time derivative of basilar-membrane displacement <ref> [9] </ref>. Inner hair cells also compress the mechanical signal nonlinearly, reducing a large range of input sound intensities to a manageable excursion of signal level. Our inner-hair-cell circuit performs these operations.
Reference: [10] <author> E. F. Evans, </author> <title> "Functional anatomy of the auditory system," in The Senses, </title> <editor> H. B. Barlow and J. D. Mollon, Eds. </editor> <address> Cambridge, England: </address> <publisher> Cambridge University Press, </publisher> <year> 1982, </year> <note> p. 251. </note>
Reference-contexts: Different auditory-nerve fibers are tuned to different frequencies, associated with the position of its inner hair cell on the basilar membrane <ref> [10] </ref>. In this way, the auditory-nerve response represents the spectral shape of the input signal. However, this representation of spectral shape is not amplitude invariant. At higher amplitudes, the nerve fiber saturates, and the low-frequency cutoff of the filter response shifts grossly downward. <p> More specifically, the probability density function for spike generation is roughly a half-wave rectified version of the electrical waveform at the inner hair cell. This phase encoding of the signal persists in fully saturated fibers <ref> [10] </ref>. Several proposed representations for spectral shape involve comparing or combining the synchrony of firing between fibers connected to different inner hair cells [11,12,13]. Other proposed representations involve extracting information from the phase encoding of fibers connected to the same inner hair cell [14, 15, 16, 17, 18].
Reference: [11] <author> S. Shamma, </author> <title> "The acoustic features of speech sounds in a model of auditory processing: vowels and voiceless fricatives," </title> <journal> J. Phonetics, </journal> <volume> vol 16, </volume> <pages> pp. 77-91, </pages> <month> March </month> <year> 1988. </year>
Reference: [12] <author> L. Deng, C. D. Geisler, S. Greenberg, </author> <title> "A composite model of the auditory periphery for the processing of speech," </title> <journal> J. Phonetics, </journal> <volume> vol 16, </volume> <pages> pp. 93-108, </pages> <year> 1988. </year>
Reference: [13] <author> O. Ghitza, </author> <title> "Temporal non-place information in the auditory-nerve firing patterns as a front end for speech recognition in a noisy environment," </title> <journal> J. Phonetics, </journal> <volume> vol 16, </volume> <pages> pp. 109-123, </pages> <year> 1988. </year>
Reference: [14] <author> S. Seneff, </author> <title> "A joint synchrony/mean-rate model of auditory speech processing," </title> <journal> J. Phonetics, </journal> <volume> vol 16, </volume> <pages> pp. 55-76, </pages> <year> 1988. </year>
Reference-contexts: Several proposed representations for spectral shape involve comparing or combining the synchrony of firing between fibers connected to different inner hair cells [11,12,13]. Other proposed representations involve extracting information from the phase encoding of fibers connected to the same inner hair cell <ref> [14, 15, 16, 17, 18] </ref>. The simplest of the latter schemes involves connecting an auditory-nerve fiber with a resonant frequency of f j to a matched filter for a spike repetition rate of 1=f j [15].
Reference: [15] <author> M. B. Sachs and E. D. Young, </author> <title> "Effects of nonlinearities on speech encoding in the auditory nerve," </title> <journal> J. Acoust. Soc. Am, </journal> <volume> vol 68, no. 3, </volume> <pages> pp. 858-875, </pages> <month> September </month> <year> 1980. </year>
Reference-contexts: Several proposed representations for spectral shape involve comparing or combining the synchrony of firing between fibers connected to different inner hair cells [11,12,13]. Other proposed representations involve extracting information from the phase encoding of fibers connected to the same inner hair cell <ref> [14, 15, 16, 17, 18] </ref>. The simplest of the latter schemes involves connecting an auditory-nerve fiber with a resonant frequency of f j to a matched filter for a spike repetition rate of 1=f j [15]. <p> The simplest of the latter schemes involves connecting an auditory-nerve fiber with a resonant frequency of f j to a matched filter for a spike repetition rate of 1=f j <ref> [15] </ref>. A simple realization of this matched filter is a correlator that receives as input the auditory-nerve fiber response delayed by a time 1=f j , and the undelayed auditory-nerve fiber response [18].
Reference: [16] <author> B. Delgutte, </author> <title> "Speech coding in the auditory nerve: II. Processing schemes for vowel-like sounds," </title> <journal> J. Acoust. Soc. Am, </journal> <volume> vol. 75, no. 3, </volume> <pages> pp. 879-886, </pages> <year> 1984. </year>
Reference-contexts: Several proposed representations for spectral shape involve comparing or combining the synchrony of firing between fibers connected to different inner hair cells [11,12,13]. Other proposed representations involve extracting information from the phase encoding of fibers connected to the same inner hair cell <ref> [14, 15, 16, 17, 18] </ref>. The simplest of the latter schemes involves connecting an auditory-nerve fiber with a resonant frequency of f j to a matched filter for a spike repetition rate of 1=f j [15].
Reference: [17] <author> R. F. Lyon, </author> <title> "Computational models of neural auditory processing," </title> <booktitle> in Proceedings, 1984 IEEE ICASSP, </booktitle> <address> San Diego, CA (Mar. 19-21, </address> <year> 1984). </year>
Reference-contexts: Several proposed representations for spectral shape involve comparing or combining the synchrony of firing between fibers connected to different inner hair cells [11,12,13]. Other proposed representations involve extracting information from the phase encoding of fibers connected to the same inner hair cell <ref> [14, 15, 16, 17, 18] </ref>. The simplest of the latter schemes involves connecting an auditory-nerve fiber with a resonant frequency of f j to a matched filter for a spike repetition rate of 1=f j [15].
Reference: [18] <author> N. Suga, </author> <title> "Auditory Neuroethology and Speech Processing: Complex-Sound Processing by Combination-Sensitive Neurons," in Auditory Function, </title> <editor> G. M. Edelman, W. E. Gall, W. M. Cowan, Eds. </editor> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1988, </year> <pages> pp. 679-720. </pages>
Reference-contexts: Several proposed representations for spectral shape involve comparing or combining the synchrony of firing between fibers connected to different inner hair cells [11,12,13]. Other proposed representations involve extracting information from the phase encoding of fibers connected to the same inner hair cell <ref> [14, 15, 16, 17, 18] </ref>. The simplest of the latter schemes involves connecting an auditory-nerve fiber with a resonant frequency of f j to a matched filter for a spike repetition rate of 1=f j [15]. <p> A simple realization of this matched filter is a correlator that receives as input the auditory-nerve fiber response delayed by a time 1=f j , and the undelayed auditory-nerve fiber response <ref> [18] </ref>. The frequency characteristic of this autocorrelator shows strong peaks at frequencies nf j , for positive integer n. The cochlear filter, however, removes all frequencies substantially above f j from the input, and the frequency response of the system shows a single peak at f j .
Reference: [19] <author> C. Mead, </author> <title> Analog VLSI and Neural Systems. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1989, </year> <pages> pp. 173-177. </pages>
Reference: [20] <author> C. Mead, </author> <title> Analog VLSI and Neural Systems. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1989, </year> <pages> pp. 193-203. </pages>
Reference-contexts: The symbol f j denotes the center frequency at positions along the silicon cochlea. Outputs from the silicon cochlea connect to circuit models of inner-hair-cell transduction [4], drawn as an ellipse. This circuit connects to circuits modeling spike generation and combination, drawn as boxes marked with a pulse <ref> [20] </ref>. The signal i j (t) represent the activity of a single spiral-ganglion-neuron circuit; the signal o j (t) represent the combined response of 11 spiral-ganglion-neuron circuits. This combined response is correlated with a time-delayed version of the combined response, to yield the final output c j (t). <p> V o . The circuit converts the input voltage into a unidirectional current, then converts this current into fixed-width, fixed-height pulses. The circuit | a slightly modified version of the neuron circuit in <ref> [20] </ref> | creates a pulse rate that is linear in input current, for sufficiently low pulse rates. Thus, the average pulse rate of the circuit reflects the average value of input, whereas the temporal placement of each pulse reflects the shape of the input current waveform. <p> Experiment identical to (a). (c) Data from a c j (t) output corresponding to the i j (t) output in (a), with the cochlear filtering enabled. Experiment identical to (a). V o . The circuit is a single stage of the axon circuit shown in <ref> [20] </ref>. The control voltage V d sets the delay time, while the control voltage V p sets the output pulse width. The voltage V d is set in the subthreshold range; as a result, the delay time is an exponential function of V d . <p> These transistors produce a current, weighted by the control voltage V w , if pulses are present on both V 1 and V 2 . This current is mirrored and presented to a neuron circuit, as in <ref> [20] </ref>. To produce uniform behavior for all c j (t) outputs, we applied voltage gradients along the cochlear dimension to several control inputs using polysilicon wires. The pulse width control voltage V p for the time-delay circuits and the spiral-ganglion-neuron circuits were connected together on such a gradient line.
References-found: 20

