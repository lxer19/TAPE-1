URL: http://www.cam.sri.com/tr/crc062/paper.ps.Z
Refering-URL: http://www.cam.sri.com/tr/ABSTRACTS.html
Root-URL: 
Phone: 3  
Title: Handling Compound Nouns in a Swedish Speech-Understanding System  
Author: David Carter Jaan Kaja Leonardo Neumeyer Manny Rayner Fuliang Weng and Mats Wiren 
Address: Suite 23, Millers Yard Cambridge CB2 1RQ, UK  S-136 80 Haninge, Sweden  333 Ravenswood Avenue Menlo Park, CA 94025, USA  
Affiliation: 1 SRI International  Processing  SRI International  
Date: 1996  
Note: of ICSLP-96;  2 Telia Research AB Spoken Language  
Web: URL: http://www.cam.sri.com/tr/crc062/paper.ps.ZProcessings  
Abstract: This paper describes and evaluates a simple and general solution to the handling of compound nouns in Swedish and other languages in which compounds can be formed by concatenation of single words. The basic idea is to split compounds into their components and treat these components as recognition units equivalent to other words in the language model. By using a principled grammar-based language-processing architecture, it is then possible to accommodate input in split-compound format. 1 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> M.-S. Agnas, H. Alshawi, I. Bretan, D.M. Carter, K. Ceder, M. Collins, R. Crouch, V. Digalakis, B. Ekholm, B. Gamback, J. Kaja, J. Karlgren, B. Lyberg, P. Price, S. Pulman, M. Rayner, C. Samuelsson, and T. Svensson. </author> <title> Spoken Language Translator: First Year Report. </title> <note> SRI technical report CRC-043 (also SICS research report R94:03), SRI International, Cam-bridge, England, 1994. Available through WWW from http://www.cam.sri.com. </note>
Reference-contexts: The original system was for English only. The Swedish version [6] was developed in a collaboration with the Swedish Institute of Computer Science. The CLE is extensively described elsewhere <ref> [1, 2, 3] </ref>, so we only give the minimum background necessary for understanding our handling of compounds. The basic functionality offered by the CLE is two-way translation between surface form and a representation in terms of a logic-based formalism called Quasi Logical Form (QLF).
Reference: 2. <author> H. Alshawi, D. Carter, R. Crouch, S. Pulman, M. Rayner, and A. Smith. CLARE: </author> <title> A Contextual Reasoning and Cooperative Response Framework for the Core Language Engine. </title> <type> SRI technical report CRC-028, </type> <institution> SRI International, </institution> <address> Cambridge, England, </address> <year> 1992. </year> <note> Available through WWW from http://www.cam.sri.com. </note>
Reference-contexts: The original system was for English only. The Swedish version [6] was developed in a collaboration with the Swedish Institute of Computer Science. The CLE is extensively described elsewhere <ref> [1, 2, 3] </ref>, so we only give the minimum background necessary for understanding our handling of compounds. The basic functionality offered by the CLE is two-way translation between surface form and a representation in terms of a logic-based formalism called Quasi Logical Form (QLF).
Reference: 3. <author> Hiyan Alshawi, </author> <title> editor. The Core Language Engine. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1992. </year>
Reference-contexts: Continuous speaker-independent speech recognition is performed by a Swedish version of the DECIPHER (TM) recognizer [9], and language processing is provided by a Swedish version of the SRI Core Language Engine <ref> [3, 6] </ref>. The rest of the paper is organized as follows: Section 2. describes the corpus material used for othe experiments. Section 3. describes experiments involving the Swedish speech recognizer alone, and Section 4. describes further experiments on the full speech translation system. Section 5. presents our conclusions. 2. <p> The original system was for English only. The Swedish version [6] was developed in a collaboration with the Swedish Institute of Computer Science. The CLE is extensively described elsewhere <ref> [1, 2, 3] </ref>, so we only give the minimum background necessary for understanding our handling of compounds. The basic functionality offered by the CLE is two-way translation between surface form and a representation in terms of a logic-based formalism called Quasi Logical Form (QLF). <p> The principled grammar-based architecture of the CLE made it simple to modify the speech-language interface [5] to accommodate input in split-compound format. Since morphology and syntax rules have the same form <ref> [3, x3.9] </ref>, all that was necessary was to change the status of compounding rules from morphology to syntax.
Reference: 4. <author> Hiyan Alshawi and David Carter. </author> <title> Training and Scaling Preference Functions for Disambiguation. </title> <journal> Computational Linguistics, </journal> <volume> 20(4), </volume> <year> 1994. </year>
Reference-contexts: The relationship between surface form and QLF is in general many-to-many. Preference modules contain data in the form of statistically learned distributional facts, based on analysis of domain corpora <ref> [4] </ref>. Using this extra information, the system can distinguish between plausible and implausible applications of the rules with a fairly high degree of accuracy. The principled grammar-based architecture of the CLE made it simple to modify the speech-language interface [5] to accommodate input in split-compound format.
Reference: 5. <author> D. Carter and M. Rayner. </author> <title> The Speech-Language Interface in the Spoken Language Translator. </title> <booktitle> In Proc. 8th Twente Workshop on Language Technology, </booktitle> <institution> University of Twente, Enschede, </institution> <address> the Netherlands, </address> <year> 1994. </year>
Reference-contexts: Using this extra information, the system can distinguish between plausible and implausible applications of the rules with a fairly high degree of accuracy. The principled grammar-based architecture of the CLE made it simple to modify the speech-language interface <ref> [5] </ref> to accommodate input in split-compound format. Since morphology and syntax rules have the same form [3, x3.9], all that was necessary was to change the status of compounding rules from morphology to syntax.
Reference: 6. <author> B. Gamback and M. Rayner. </author> <title> The Swedish Core Language Engine. </title> <booktitle> In Proc. Third Nordic Conference on Text Comprehension in Man and Machine, </booktitle> <address> Linkoping, Sweden, </address> <year> 1992. </year> <note> Also SRI Technical Report CRC-025. Available through WWW from http://www.cam.sri.com. </note>
Reference-contexts: Continuous speaker-independent speech recognition is performed by a Swedish version of the DECIPHER (TM) recognizer [9], and language processing is provided by a Swedish version of the SRI Core Language Engine <ref> [3, 6] </ref>. The rest of the paper is organized as follows: Section 2. describes the corpus material used for othe experiments. Section 3. describes experiments involving the Swedish speech recognizer alone, and Section 4. describes further experiments on the full speech translation system. Section 5. presents our conclusions. 2. <p> Language processing for split compounds Language processing in SLT is carried out by the Core Language Engine (CLE), a general language-processing system, which has been developed by SRI International in a series of projects starting in 1986. The original system was for English only. The Swedish version <ref> [6] </ref> was developed in a collaboration with the Swedish Institute of Computer Science. The CLE is extensively described elsewhere [1, 2, 3], so we only give the minimum background necessary for understanding our handling of compounds.
Reference: 7. <author> P. Geutner. </author> <title> Using Morphology Towards Better Large-Vocabulary Speech Recognition Systems. </title> <booktitle> In Proc. ICASSP 95, </booktitle> <year> 1995. </year>
Reference-contexts: Two recent papers address this issue. Spies [12] reports results on an isolated-word large-vocabulary German dictation application, in which the components of compounds, rather than the compounds themselves, were treated as units. Geutner <ref> [7] </ref> describes a more elaborate method, also implemented for German, in which full morphological decomposition of words was used. Both authors report unspectacular but encouraging initial results. 1 The work reported here was funded by Telia Research AB under the SLT-2 project.
Reference: 8. <author> L. Lamel, M. Adda-Decker, and J. L. Gauvain. </author> <title> Issues in Large Vocabulary, Multilingual Speech Recognition. </title> <booktitle> In Proc. </booktitle> <volume> Eu-rospeech '95, </volume> <pages> pages 185188, </pages> <year> 1995. </year>
Reference-contexts: However, as the vocabulary size grows, the productive nature of compounding makes this kind of approach increasingly less feasible; the most obvious indication of the problem's seriousness is the magnitude of the out-of-vocabulary (OOV) rate. For example, in an experiment on SQALE training texts <ref> [8, page 186] </ref>, using 20 000-word lexicons for both German and English resulted in a 7.5 % OOV rate for German and 2.5 % for English. <p> In the second, unsplit version, only numbers were split. In both cases, the numbers were split because it would be futile to try to list them in the lexicon; the same approach was taken in the German SQALE experiments <ref> [8, page 186] </ref>. The split and unsplit versions of the ATIS-S-1 text were used to train two different versions of the Swedish recognizer. The two versions of the recognizer differed only in terms of vocabulary and language model.
Reference: 9. <author> H. Murveit, J. Butzberger, V. Digalakis, and M. Weintraub. </author> <title> Large Vocabulary Dictation using SRI's DECIPHER(TM) Speech Recognition System: Progressive Search Techniques. </title> <booktitle> In Proc. ICASSP 93, </booktitle> <year> 1993. </year>
Reference-contexts: The system is capable of translating spoken utterances from the Air Travel Planning (ATIS) domain from Swedish into English, using a vocabulary of about 1 500 words. Continuous speaker-independent speech recognition is performed by a Swedish version of the DECIPHER (TM) recognizer <ref> [9] </ref>, and language processing is provided by a Swedish version of the SRI Core Language Engine [3, 6]. The rest of the paper is organized as follows: Section 2. describes the corpus material used for othe experiments.
Reference: 10. <author> M. Rayner, H. Alshawi, I. Bretan, D.M. Carter, V. Digalakis, B. Gamback, J. Kaja, J. Karlgren, B. Lyberg, P. Price, S. Pul-man, and C. Samuelsson. </author> <title> A Speech to Speech Translation System Built From Standard Components. </title> <booktitle> In Proc. 1st ARPA Workshop on Human Language Technology, </booktitle> <year> 1993. </year>
Reference-contexts: For this reason, we decided that full morphological decomposition a la Geutner would probably not justify the additional complexity introduced. Our approach has been fully implemented within a Swedish-to-English version of the Spoken Language Translator <ref> [10, 11] </ref>. The system is capable of translating spoken utterances from the Air Travel Planning (ATIS) domain from Swedish into English, using a vocabulary of about 1 500 words.
Reference: 11. <author> M. Rayner, I. Bretan, D. Carter, M. Collins, V. Digalakis, B. Gamback, J. Kaja, J. Karlgren, B. Lyberg, P. Price, S. Pul-man, and C. Samuelsson. </author> <title> Spoken Language Translation with Mid-90's Technology: A Case Study. </title> <booktitle> In Proc. Eurospeech '93, </booktitle> <year> 1993. </year>
Reference-contexts: For this reason, we decided that full morphological decomposition a la Geutner would probably not justify the additional complexity introduced. Our approach has been fully implemented within a Swedish-to-English version of the Spoken Language Translator <ref> [10, 11] </ref>. The system is capable of translating spoken utterances from the Air Travel Planning (ATIS) domain from Swedish into English, using a vocabulary of about 1 500 words.
Reference: 12. <author> Marcus Spies. </author> <title> A Language Model for Compound Words in Speech Recognition. </title> <booktitle> In Proc. Eurospeech '95, </booktitle> <pages> pages 1767 1770, </pages> <year> 1995. </year>
Reference-contexts: Results like those quoted above strongly suggest that treating compounds in the same way as other words is not satisfactory. Two recent papers address this issue. Spies <ref> [12] </ref> reports results on an isolated-word large-vocabulary German dictation application, in which the components of compounds, rather than the compounds themselves, were treated as units. Geutner [7] describes a more elaborate method, also implemented for German, in which full morphological decomposition of words was used.
References-found: 12

