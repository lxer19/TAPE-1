URL: ftp://ftp.cs.brown.edu/pub/techreports/93/cs93-19.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-93-19.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [1] <editor> "Super Linkage," </editor> <address> Science 251 (March 15, </address> <year> 1991), </year> <month> 1311. </month>
Reference-contexts: 1 Introduction Heterogeneous supercomputers consist of serial and parallel supercomputers coupled by high-bandwidth channels. Such machines can greatly reduce computation time for large problems. It is reported that McRae solved a chemical process resource-allocation problem "40 times faster than he could on a supercomputer alone" <ref> [1] </ref> using a CRAY Y-MP connected via a high-speed link to a CM-2 Connection Machine. Others report a factor of 5 to 10 reduction in elapsed time [12] for such architectures. <p> We use that order in this discussion. Data is transferred to front-end memory units in blocks of m words. We first examine the storage of the mp values of the first bottom subgraph. We treat these values as organized into p blocks of m words, f <ref> [1; 2; . . . ; m] </ref>; [m+1; m+2; . . .; 2m]; . . . ; [(p1)m+1; (p1)m+2; . . . ; pm]g.
Reference: [2] <author> M. J. Atallah and J. -J. Tsay, </author> <title> "On the Parallel-Decomposability of Geometric Problems," </title> <booktitle> Algorithmica 8 (1992), </booktitle> <pages> 209-231. </pages>
Reference-contexts: On the other hand, if such memories are permitted on each processor of the mesh, our bounds on performance would be very different. 1.1 Related Computational Models The Mesh SuperHet model is a generalization of two models. Atallah and Tsay <ref> [2] </ref> consider a heterogeneous computer which has a serial front end connected to a d-dimensional mesh in which the memory per mesh processor is small. <p> In this case it is possible for some problems, such as sorting for which a full speedup is not possible on the Mesh SuperHet, to show a full speedup of order p (see <ref> [2] </ref> and Section 4.3). In other cases, such as matrix multiplication, the number of channels connecting processors and memory units can be considerably less than p 11=d and a full speedup is still possible (see Section 6). <p> The front end then merges these sorted lists using a merging algorithm based on an extension of Batcher's bitonic sorter. In the next section we describe a much more complicated algorithm based on one given by Atallah and Tsay <ref> [2] </ref> for the d-dimensional case and modified to run under the Mesh SuperHet's severe restriction on data movement. <p> But this is a consequence of a straightforward application of the 0-1 principle [9], which can be extended to this case. 2 4.3 An Asymptotically Optimal Sorting Algorithm Atallah and Tsay <ref> [2] </ref> have described an algorithm for a number of sorting-based problems that gives a speedup of p 11=d log p when run on a heterogeneous supercomputer consisting of a serial machine and a p-processor, d-dimensional mesh with a small number of memory locations per processor. <p> We use that order in this discussion. Data is transferred to front-end memory units in blocks of m words. We first examine the storage of the mp values of the first bottom subgraph. We treat these values as organized into p blocks of m words, f <ref> [1; 2; . . . ; m] </ref>; [m+1; m+2; . . .; 2m]; . . . ; [(p1)m+1; (p1)m+2; . . . ; pm]g.
Reference: [3] <author> K. E. Batcher, </author> <title> "Sorting Networks and Their Applications," Procs. </title> <booktitle> AFIPS Spring Joint Computer Conference 32, </booktitle> <pages> 307-314. </pages>
Reference-contexts: In the next section we describe a much more complicated algorithm based on one given by Atallah and Tsay [2] for the d-dimensional case and modified to run under the Mesh SuperHet's severe restriction on data movement. Dehne et al. [5] have shown that Batcher's oblivious bitonic sorting algorithm <ref> [3] </ref> can be converted to a merger of sorted sublists by replacing each compare-exchange operator with a merge-split operator, an operator that takes two sorted lists of k elements, merges them, and produces two lists, each of k elements, in which all elements in the first list are less than all
Reference: [4] <author> G. Bilardi and F. P. Preparata, </author> <title> "Horizons of Parallel Computation," </title> <publisher> Springer LNCS 653 (Dec. </publisher> <year> 1992), </year> <pages> 155-173. </pages>
Reference-contexts: We assume front-end memory modules are addressable via some type of fast routing network, as is typical for a serial supercomputer. A mesh is assumed for the parallel machine because the proximity of processors supports the high-speed local communication needed for 1 many large-scale computational problems. (Bilardi and Preparata <ref> [4] </ref> argue for the mesh as the parallel architecture of choice in the limit of very fast computations.) Thus, we have chosen to study a closely coupled heterogeneous supercomputer in which the front end connects memory modules via a low-diameter network and the back end connects memory modules via a high-diameter
Reference: [5] <author> F. Dehne, A. Fabri, and A. Rau-Chaplin, </author> <title> "Scalable Parallel Geometric Algorithms for Coarse Grained Multicomputers," Procs. </title> <booktitle> ACM Symposium on Computational Geometry, </booktitle> <pages> 298-307. </pages>
Reference-contexts: They show that a speedup of p 11=d log p is possible for sorting-related problems in computational geometry. Dehne, Fabri and Rau-Chaplin <ref> [5] </ref> consider a machine consisting of a p-processor d-dimensional mesh in which the processors have enough memory to hold the data for an entire problem, equally distributed over the p memory units. <p> It is interesting to note that, as shown by Dehne et al. <ref> [5] </ref>, if all n words are uniformly distributed initially over the p processors in a 2-D mesh they can be sorted with a full speedup if m = 2 ( p p) . 4.2 An Efficient 2D-Mesh SuperHet Sorting Algorithm We now present an efficient two-dimensional sorting algorithm for the Mesh <p> In the next section we describe a much more complicated algorithm based on one given by Atallah and Tsay [2] for the d-dimensional case and modified to run under the Mesh SuperHet's severe restriction on data movement. Dehne et al. <ref> [5] </ref> have shown that Batcher's oblivious bitonic sorting algorithm [3] can be converted to a merger of sorted sublists by replacing each compare-exchange operator with a merge-split operator, an operator that takes two sorted lists of k elements, merges them, and produces two lists, each of k elements, in which all
Reference: [6] <author> P. J. Denning, </author> <title> "The Working Set Model for Program Behavior," </title> <journal> Communications of the ACM 11 (May 1968), </journal> <pages> 323-333. </pages>
Reference-contexts: The third assumption typically holds in practice to within a factor of 5-10, which does not affect our asymptotic analyses. The last assumption is not practical but can be simulated for many problems <ref> [6, 15] </ref>), including those studied here. Large simulated memories are expensive and are an important distinguishing characteristic of serial supercomputers. Parallel machines typically do not support such memories on each processor because of their cost.
Reference: [7] <author> G. N. Frederickson and D. B. Johnson, </author> <title> "The Complexity of Selection and Ranking in X+Y and Matrices with Sorted Columns ," Journal of Computer and System Sciences 24 (1982), </title> <type> 197-208. </type>
Reference-contexts: A collection of n elements is divided into q = dp 1=(d+1) e lists and sorted recursively. The mp=3th element in these sorted lists is then found using the efficient serial algorithm of Frederickson and Johnson Lspace <ref> [7] </ref> discussed below. Our goal is to use this element to find and move to the mesh for sorting the mp=3 smallest elements in these lists, a step taken in 18 the Atallah-Tsay algorithm.
Reference: [8] <author> J. JaJa, </author> <title> in An Introduction to Parallel Algorithms, </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, </address> <year> 1992. </year>
Reference-contexts: The parallel decision tree model of computation, an extension of the well-known serial decision-tree model, captures essential features of such algorithms <ref> [8, pp. 185] </ref>. As shown in then executes one of several multiway branches. The path to a vertex is associated with the results of comparisons taken to reach it.
Reference: [9] <author> D. E. Knuth, </author> <title> The Art of Computer Programming Sorting and Searching #3, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1973. </year>
Reference-contexts: Correctness of the merger follows by showing correctness of a merger obtained by replacing compare-exchange operations in odd-even transposition sort with merge-split operations. But this is a consequence of a straightforward application of the 0-1 principle <ref> [9] </ref>, which can be extended to this case. 2 4.3 An Asymptotically Optimal Sorting Algorithm Atallah and Tsay [2] have described an algorithm for a number of sorting-based problems that gives a speedup of p 11=d log p when run on a heterogeneous supercomputer consisting of a serial machine and a
Reference: [10] <author> H. T. Kung, </author> <title> "Memory Requirements for Balanced Computer Architectures," </title> <journal> Journal of Complexity 1 (1985), </journal> <pages> 147-157. </pages>
Reference-contexts: As these results demonstrate, the amount of speedup possible with the Mesh SuperHet depends both on the problems for which it is used and on the parameters of the machine, in particular, the bandwidth between serial and parallel processors and the amount of memory on each mesh processor. Kung <ref> [10] </ref> has explored conditions under which balance is obtained between computation and I/O time for matrix multiplication, Gaussian elimination, the fast Fourier transform, and sorting when executed on serial machines; he also comments on these issues for two-dimensional meshes.
Reference: [11] <author> R. E. Ladner, </author> <title> "The Circuit Value Problem is Log Space Complete for P," </title> <journal> ACM SIGACT News 7 (1975), </journal> <pages> 18-20. </pages>
Reference-contexts: This processor also dispatches messages to other processors on the mesh face when a memory access is necessary. The time for each of these dispatches is O (p 1=d ), the diameter of the mesh face, from which the result follows. 2 P-complete problems <ref> [11] </ref> are believed hard to parallelize. Such problems run in serial polynomial time but are not thought to be executable on any parallel machine in time polynomial in the logarithm of the problem input size.
Reference: [12] <author> H. Nicholas, G. Giras, V. Hartonas-Garmhausen, M. Kopko, C. Maher, and A. Ropelewski, </author> <title> "Distributing the Comparison of DNA and Protein Sequences Across Heterogeneous Supercomputers," Procs. </title> <booktitle> Supercomputing '91 (Nov. </booktitle> <pages> 18-22, </pages> <year> 1991), </year> <pages> 139-146. </pages>
Reference-contexts: It is reported that McRae solved a chemical process resource-allocation problem "40 times faster than he could on a supercomputer alone" [1] using a CRAY Y-MP connected via a high-speed link to a CM-2 Connection Machine. Others report a factor of 5 to 10 reduction in elapsed time <ref> [12] </ref> for such architectures. An explanation for this remarkable performance is that many problems exhibit both serial and parallel aspects that can be exploited by the heterogeneous supercomputer. In this paper we explore the potential of closely coupled heterogeneous supercomputers.
Reference: [13] <author> F. P. Preparata and J. E. Vuillemin, </author> <title> "Area-Time Optimal VLSI Networks for Multiplying Matrices," Inf. </title> <booktitle> Proc. Let. 11 (1980), </booktitle> <pages> 77-80. </pages>
Reference-contexts: The goal of this section is to understand the effect of fi on performance of matrix multiplication on the Mesh SuperHet. We begin by studying a 2-D systolic-based matrix multiplication algorithm <ref> [13] </ref> which we extend to an arbitrary number of dimensions. We show that if the storage capacity of the mesh is large enough relative to fi and p, a full speedup is possible on the Mesh SuperHet.
Reference: [14] <author> J. E. Savage and S. Swamy, </author> <title> "Space-Time Tradeoffs on the FFT Algorithm," </title> <journal> IEEE Trans. on Info. Th. </journal> <note> IT-24 (Sept. </note> <year> 1978), </year> <pages> 563-568. 31 </pages>
Reference-contexts: We consider computing the FFT on the Mesh SuperHet. The algorithm we develop depends in an essential way on the decomposition property of the FFT stated below. Figure 8 illustrates the decomposition spelled out below. Lemma 2 <ref> [14] </ref> For k 2 and each 1 r k 1 the FFT graph F (k) on n = 2 k inputs can be represented as the composition of 2 kr disjoint topFFT subgraphs F (r) on 2 r inputs, 0 i 2 kr 1, with 2 r disjoint FFT bottomsubgraphs F
Reference: [15] <author> J. E. Savage, </author> <title> "Space-Time Tradeoffs in Memory Hierarchies," </title> <institution> Department of Computer Science, Brown University, Report CS93-08, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: The third assumption typically holds in practice to within a factor of 5-10, which does not affect our asymptotic analyses. The last assumption is not practical but can be simulated for many problems <ref> [6, 15] </ref>), including those studied here. Large simulated memories are expensive and are an important distinguishing characteristic of serial supercomputers. Parallel machines typically do not support such memories on each processor because of their cost.
Reference: [16] <author> C. P. Schnorr and A. Shamir, </author> <title> "An Optimal Sorting Algorithm for Mesh Connected Computers," Procs. </title> <booktitle> 18th Annl. Symposium on Theory of Computing (May 28-30, </booktitle> <year> 1986), </year> <pages> 255-263. </pages>
Reference-contexts: Later we sketch a proof that the optimal mesh-sorting algorithm of Schnorr and Shamir <ref> [16] </ref> can be modified in the same way to create a mesh-merging algorithm. 13 The procedure Sort uses Batcher's bitonic sorter to organize merges of lists on the mesh using a variant of the Schnorr-Shamir algorithm.
Reference: [17] <author> C. L. Wu and T. Y. Feng, </author> <title> "The Universality of the Shu*e-Exchange Network," </title> <journal> IEEE Trans. </journal> <note> Computing C-30 (May 1981), 324-332. 32 </note>
Reference-contexts: Lemma 3 <ref> [17] </ref> A permutation network on n inputs, n = 2 k , can be constructed from three FFT graphs by connecting the outputs of one to the inputs of another and interpreting each node of the graphs as compare-exchange operations. A permutation network can be used to sort its inputs.
References-found: 17

