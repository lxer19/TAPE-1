URL: http://L2R.cs.uiuc.edu/~danr/Papers/relevanceJ.ps.gz
Refering-URL: http://L2R.cs.uiuc.edu/~danr/publications.html
Root-URL: http://www.cs.uiuc.edu
Email: roni@das.harvard.edu  danr@wisdom.weizmann.ac.il  
Title: Defaults and Relevance in Model Based Reasoning  
Author: Roni Khardon Dan Roth 
Date: May 14, 1997  
Address: Cambridge, MA 02138  Rehovot 76100, ISRAEL  
Affiliation: Aiken Computation Laboratory Harvard University  Dept. of Appl. Math. CS Weizmann Institute of Science  
Note: To appear in Artificial Intelligence Journal, special issue on Relevance.  An earlier version of the paper appears in the Proceedings of the International Joint Conference on Artificial Intelligence, IJCAI-95. Research supported by ARO under grant DAAL03-92-G-0115 and by ONR grant N00014-96-1-0550. Research supported by the Feldman Foundation. Part of this work was done while at Harvard University, supported by NSF grant CCR-92-00884, DARPA AFOSR-F4962-92-J-0466 and ONR grant N00014-96-1-0550.  
Abstract: Reasoning with model-based representations is an intuitive paradigm, which has been shown to be theoretically sound and to possess some computational advantages over reasoning with formula-based representations of knowledge. This paper studies these representations and further substantiates the claim regarding their advantages. In particular, model-based representations are shown to efficiently support reasoning in the presence of varying context information, handle efficiently fragments of Reiter's default logic and provide a useful way to integrate learning with reasoning. Furthermore, these results are closely related to the notion of relevance. The use of relevance information is best exemplified by the filtering process involved in the algorithm developed for reasoning within context. The relation of defaults to relevance is viewed through the notion of context, where the agent has to find plausible context information by using of default rules. This view yields efficient algorithms for default reasoning. Finally, it is argued that these results support an incremental view of reasoning in a natural way, and the notion of relevance to the environment, captured by the Learning to Reason framework, is discussed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon, J. Bruck, J. Naor, M. Naor, and R. Roth. </author> <title> Construction of asymptotically good low-rate error-correcting codes through pseudo-random graphs. </title> <journal> IEEE Transactions on information theory, </journal> <volume> 38(2) </volume> <pages> 509-516, </pages> <year> 1992. </year>
Reference-contexts: It is easy to see that an (n; k)-universal set includes a falsifying assignment for any clause of length k and therefore it forms a basis for the class of k-CNF formulas. It is known <ref> [16, 1] </ref> that for k = log n one can construct (n; log n)-universal sets of size O (n 3 ) and therefore jB log nCN F j = O (n 3 ).
Reference: [2] <author> N. H. Bshouty. </author> <title> Exact learning via the monotone theory. </title> <journal> Information and Computation, </journal> <volume> 123(1) </volume> <pages> 146-153, </pages> <year> 1995. </year>
Reference-contexts: Boolean functions is equivalent to the connective "subset or equal" () used for subsets of f0; 1g n . That is, f j= g if and only if f g. 3 Reasoning with Models In this section we briefly present some results from the monotone theory of Boolean functions <ref> [2] </ref> and the theory of reasoning with models [5, 9]. All the results in this section have appeared elsewhere. For a detailed discussion see [9]. Consider a propositional knowledge base W and let ff be a propositional query. <p> B is a basis for a class of functions F if it is a basis for all the functions in F . The importance of these definitions <ref> [2] </ref> is that every Boolean function has a basis B, and can be represented as follows: f = b2B ^ _ M b (z): (1) This representation yields a necessary and sufficient condition describing when x 2 f0; 1g n satisfies f : Corollary 3.1 Let B be a basis for <p> Then, f (x) = 1 if and only if for every basis element b 2 B there exists z 2 min b (f ) such that x b z. It is known <ref> [2] </ref> that for every b, the size of min b (f ) is bounded by the size of its DNF representation. Further, a set of assignments which falsify every clause in a CNF representation of f is a basis for f .
Reference: [3] <author> P. N. Johnson-Laird. </author> <title> Mental Models. </title> <publisher> Harvard University Press, </publisher> <year> 1983. </year>
Reference-contexts: When a query is presented, reasoning is performed by evaluating the query on these models. It is not hard to motivate a model-based approach to reasoning from a cognitive point of view and indeed most of the proponents of this approach have been cognitive psychologists <ref> [3, 4, 11] </ref>, who have alluded to the notion of "reasoning from examples" on a qualitative basis.
Reference: [4] <author> P. N. Johnson-Laird and R. M. J. Byrne. </author> <title> Deduction. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1991. </year>
Reference-contexts: When a query is presented, reasoning is performed by evaluating the query on these models. It is not hard to motivate a model-based approach to reasoning from a cognitive point of view and indeed most of the proponents of this approach have been cognitive psychologists <ref> [3, 4, 11] </ref>, who have alluded to the notion of "reasoning from examples" on a qualitative basis.
Reference: [5] <author> H. Kautz, M. Kearns, and B. Selman. </author> <title> Horn approximations of empirical data. </title> <journal> Artificial Intelligence, </journal> <volume> 74 </volume> <pages> 129-145, </pages> <year> 1995. </year>
Reference-contexts: The intuition is that the availability of additional context information should make the reasoning task easier, by restricting the domain one needs to reason about. As we show, if the agent performs model-based reasoning then context information can be easily used, and yields efficient reasoning. In model-based reasoning <ref> [5, 9] </ref> the knowledge base is represented as a set of models (satisfying assignments, examples) of the world rather than a logical formula describing it. When a query is presented, reasoning is performed by evaluating the query on these models. <p> But representing KB by explicitly holding all the possible models is not plausible. A model-based approach becomes feasible if KB can be replaced by a small model-based representation and still support correct deduction. The theory of model-based representations developed in [9] (generalizing the theory developed in <ref> [5] </ref> for the case of Horn expressions) characterizes the propositional languages for which model-based representations support efficient deduction and abduction. <p> That is, f j= g if and only if f g. 3 Reasoning with Models In this section we briefly present some results from the monotone theory of Boolean functions [2] and the theory of reasoning with models <ref> [5, 9] </ref>. All the results in this section have appeared elsewhere. For a detailed discussion see [9]. Consider a propositional knowledge base W and let ff be a propositional query. <p> It does however allow for an exponential gap in other cases. Namely, there are functions with an exponential size DNF and a linear size model-based representation [9]. It is also interesting to compare the size of this representation to the size of other representations for functions. Examples in <ref> [5] </ref> show that there are cases where the (Horn CNF) formula representation is small and the model-based representation is exponentially large, and vice versa. For a discussion of these issues, as well as other properties of characteristic models, see [9]. <p> Nevertheless, our results provide efficient algorithms in cases where they were not known to exist before. We present two algorithms, CD-MBR and SD-MBR, which handle the credulous and skeptical default reasoning tasks, respectively. Both algorithms are similar to the abduction algorithm 3 developed in <ref> [5] </ref> and used in [9]. 5.1 Credulous Default Reasoning We start by describing the algorithm CD-MBR, which is presented in Figure 3.
Reference: [6] <author> H. Kautz and B. Selman. </author> <title> Hard problems for simple default logics. </title> <journal> Artificial Intelligence, </journal> <volume> 49 </volume> <pages> 243-279, </pages> <year> 1991. </year>
Reference-contexts: This is true not only for the task of deduction, but also for many other forms of reasoning that have been developed. All those were shown to be even harder to compute than the original formulation [25, 23]. This holds in particular for various formalizations of default reasoning <ref> [26, 6, 17] </ref>, where the increase in complexity is clearly at odds with the intuition that reasoning with defaults should somehow reduce the complexity of reasoning. This remains true, even when we severely restrict the expressiveness of the knowledge base, the default rules and the queries allowed. <p> In the original formalization [19] a knowledge base is defined to imply a query if there is an extension in which the query holds. Following <ref> [29, 6] </ref> we call this task credulous default reasoning; the case in which all extensions are taken into consideration is called skeptical default reasoning.
Reference: [7] <author> R. Khardon and D. Roth. </author> <title> Learning to reason. </title> <booktitle> In Proc. of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 682-687, </pages> <year> 1994. </year>
Reference-contexts: This suggests the notion of relevance to the environment. Namely, the agent can incrementally construct a representation that is relevant to its environment, in the sense that it supports correct reasoning there. This intuitive idea is formalized in a more general setting in the Learning to Reason framework <ref> [7] </ref>, and is discussed also in [31, 22, 8]. We discuss two results in the Learning to Reason framework that use model-based representations in order to exploit the relevant information in the reasoning process. <p> In <ref> [7] </ref> a general framework Learning to Reason is defined, that incorporates the ideas above into the study of reasoning. <p> In this case we may call it relevance to the environment. Namely, the performance of an agent has to be measured by some criterion that depends on the world the agent functions in. Indeed, it is shown in <ref> [7] </ref> that through this interaction with the world, the agent truly gains additional reasoning power. We briefly describe two results which emphasize how, within this framework, agents can focus on relevant information and what they gain from using it. <p> This may allow us to take random samples according to the distribution D that governs the occurrences of instances in W ^ d. It can be shown <ref> [7] </ref> that a sample of m = p * ln 1 ffi random examples can answer correctly all questions of length p, which are not evasive. <p> Theory Approximation and Restricted Queries The utility of knowledge approximations for capturing information relevant to the task was discussed in Section 6. We note that the use of these approximations is advantageous for other reasons as well. In <ref> [7] </ref> it is shown that while exact learning of functions is still not within reach, one can learn the model-based representations for the least upper bound approximations of functions.
Reference: [8] <author> R. Khardon and D. Roth. </author> <title> Learning to reason with a restricted view. </title> <booktitle> In Workshop on Computational Learning Theory, </booktitle> <pages> pages 301-310, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Namely, the agent can incrementally construct a representation that is relevant to its environment, in the sense that it supports correct reasoning there. This intuitive idea is formalized in a more general setting in the Learning to Reason framework [7], and is discussed also in <ref> [31, 22, 8] </ref>. We discuss two results in the Learning to Reason framework that use model-based representations in order to exploit the relevant information in the reasoning process. To summarize, this paper studies reasoning with model-based representations, and further substantiates the claim regarding their computational advantages.
Reference: [9] <author> R. Khardon and D. Roth. </author> <title> Reasoning with models. </title> <journal> Artificial Intelligence, </journal> <volume> 87 </volume> <pages> 187-213, </pages> <year> 1996. </year>
Reference-contexts: The intuition is that the availability of additional context information should make the reasoning task easier, by restricting the domain one needs to reason about. As we show, if the agent performs model-based reasoning then context information can be easily used, and yields efficient reasoning. In model-based reasoning <ref> [5, 9] </ref> the knowledge base is represented as a set of models (satisfying assignments, examples) of the world rather than a logical formula describing it. When a query is presented, reasoning is performed by evaluating the query on these models. <p> But representing KB by explicitly holding all the possible models is not plausible. A model-based approach becomes feasible if KB can be replaced by a small model-based representation and still support correct deduction. The theory of model-based representations developed in <ref> [9] </ref> (generalizing the theory developed in [5] for the case of Horn expressions) characterizes the propositional languages for which model-based representations support efficient deduction and abduction. <p> This idea can be formalized using the notion of least upper bound approximations <ref> [27, 9] </ref>. In fact, the model-based representations used for reasoning within context and default reasoning capture such approximations, and thus use this notion of relevance as well. Here again, the model-based representations are essential since formula-based representations of these approximations do not support efficient reasoning. <p> That is, f j= g if and only if f g. 3 Reasoning with Models In this section we briefly present some results from the monotone theory of Boolean functions [2] and the theory of reasoning with models <ref> [5, 9] </ref>. All the results in this section have appeared elsewhere. For a detailed discussion see [9]. Consider a propositional knowledge base W and let ff be a propositional query. <p> All the results in this section have appeared elsewhere. For a detailed discussion see <ref> [9] </ref>. Consider a propositional knowledge base W and let ff be a propositional query. The model based strategy for the deduction problem W j= ff is to try and verify the implication relation using model evaluation. <p> It does however allow for an exponential gap in other cases. Namely, there are functions with an exponential size DNF and a linear size model-based representation <ref> [9] </ref>. It is also interesting to compare the size of this representation to the size of other representations for functions. Examples in [5] show that there are cases where the (Horn CNF) formula representation is small and the model-based representation is exponentially large, and vice versa. <p> Examples in [5] show that there are cases where the (Horn CNF) formula representation is small and the model-based representation is exponentially large, and vice versa. For a discussion of these issues, as well as other properties of characteristic models, see <ref> [9] </ref>. <p> The main difficulty which arises in the general case is that W may not be consistent with all of D. Next we present positive results on default reasoning using a model-based representation. As in the case of deductive reasoning <ref> [9] </ref>, the efficient results we present hold in cases where there is no known efficient solution when reasoning with formulas. The exact complexity relation is somewhat more subtle than in the deductive case. There, efficient solutions where presented for problems that are NP-Hard (under randomized reductions) given a formula-based representation. <p> Nevertheless, our results provide efficient algorithms in cases where they were not known to exist before. We present two algorithms, CD-MBR and SD-MBR, which handle the credulous and skeptical default reasoning tasks, respectively. Both algorithms are similar to the abduction algorithm 3 developed in [5] and used in <ref> [9] </ref>. 5.1 Credulous Default Reasoning We start by describing the algorithm CD-MBR, which is presented in Figure 3. Let = W be a model based representation of W . (The monotone basis will be defined later.) The algorithm CD-MBR receives ; D and a query q as input. <p> This can be formalized using the notion of a least upper bound representation, introduced by Kautz and Selman [27]. Intuitively, these approximations capture all the conclusions of W which belong to Q. In <ref> [9] </ref> it is shown that these approximations support exact deduction with respect queries in Q. In fact, the model-based representations that we have used earlier in the paper capture such approximations relative to the class of queries.
Reference: [10] <author> J. Kolodner. </author> <title> Case-Based Reasoning. </title> <publisher> Morgan Kaufman, </publisher> <year> 1993. </year>
Reference-contexts: In the AI community this approach can be seen as an example of Levesque's notion of "vivid" reasoning [12, 13], and is somewhat related to Minsky's frames-theory [15] and to some of the work in case-based reasoning <ref> [10] </ref>. Given a model-based representation of the knowledge base KB, and a query ff, the task of deciding whether KB implies ff (denoted KB j= ff) can be performed in a straightforward way: Evaluate ff on all the models in the representation.
Reference: [11] <author> S. M. Kosslyn. </author> <title> Image and Mind. </title> <publisher> Harvard University Press, </publisher> <year> 1983. </year>
Reference-contexts: When a query is presented, reasoning is performed by evaluating the query on these models. It is not hard to motivate a model-based approach to reasoning from a cognitive point of view and indeed most of the proponents of this approach have been cognitive psychologists <ref> [3, 4, 11] </ref>, who have alluded to the notion of "reasoning from examples" on a qualitative basis.
Reference: [12] <author> H. Levesque. </author> <title> Making believers out of computers. </title> <journal> Artificial Intelligence, </journal> <volume> 30 </volume> <pages> 81-108, </pages> <year> 1986. </year>
Reference-contexts: We incorporate the notion of relevance into the study of reasoning by introducing the task of reasoning within context. It has been argued that in real life situations, one normally completes 2 a lot of missing context information when answering queries <ref> [12] </ref>. We model this situation by augmenting the agent's knowledge about the world with context-specific information. Reasoning within context is therefore a deduction task, where some additional constraining information is added to the knowledge base. We formalize this task as the problem of reasoning within a varying context. <p> In the AI community this approach can be seen as an example of Levesque's notion of "vivid" reasoning <ref> [12, 13] </ref>, and is somewhat related to Minsky's frames-theory [15] and to some of the work in case-based reasoning [10]. <p> Test: If there is such an element which does not satisfy ff, return "No". Oth erwise, return "Yes". 4 Reasoning within Context It has been argued that in real life situations, one normally completes a lot of missing "context" information when answering queries <ref> [12] </ref>.
Reference: [13] <author> H. Levesque. </author> <title> Is reasoning too hard ? In Proceeding of the 3rd NEC research Symposium. </title> <year> 1992. </year>
Reference-contexts: In the AI community this approach can be seen as an example of Levesque's notion of "vivid" reasoning <ref> [12, 13] </ref>, and is somewhat related to Minsky's frames-theory [15] and to some of the work in case-based reasoning [10].
Reference: [14] <author> J. McCarthy and P. Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence 4. </booktitle> <publisher> Edinburgh University Press, </publisher> <year> 1969. </year>
Reference-contexts: Various knowledge representations can be used to represent the knowledge in a knowledge-based system. Different representation systems (e.g., a set of logical rules, a probabilistic network) are associated with corresponding reasoning mechanisms, each with its own merits and range of applications <ref> [14, 18] </ref>. Given a logical knowledge base, for example, reasoning can be abstracted as a deduction task: determine whether a sentence, assumed to capture the situation at hand, is logically implied by the knowledge base.
Reference: [15] <author> M. Minsky. </author> <title> A framework for representing knowledge. </title> <editor> In P. Winston, editor, </editor> <booktitle> The Psychology of Computer Vision. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1975. </year> <note> Also in R. </note> <editor> Brachman and H. Levesque, </editor> <booktitle> Readings in Knowledge Representation, </booktitle> <year> 1985. </year> <month> 21 </month>
Reference-contexts: In the AI community this approach can be seen as an example of Levesque's notion of "vivid" reasoning [12, 13], and is somewhat related to Minsky's frames-theory <ref> [15] </ref> and to some of the work in case-based reasoning [10].
Reference: [16] <author> J. Naor and M. Naor. </author> <title> Small-bias probability spaces: Efficient constructions and applications. </title> <journal> SIAM J. Comput., </journal> <volume> 22(4) </volume> <pages> 838-856, </pages> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: It is easy to see that an (n; k)-universal set includes a falsifying assignment for any clause of length k and therefore it forms a basis for the class of k-CNF formulas. It is known <ref> [16, 1] </ref> that for k = log n one can construct (n; log n)-universal sets of size O (n 3 ) and therefore jB log nCN F j = O (n 3 ).
Reference: [17] <author> C. H. Papadimitriou. </author> <title> On selecting a satisfying truth assignment. </title> <booktitle> In Proc. 32nd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1991. </year>
Reference-contexts: This is true not only for the task of deduction, but also for many other forms of reasoning that have been developed. All those were shown to be even harder to compute than the original formulation [25, 23]. This holds in particular for various formalizations of default reasoning <ref> [26, 6, 17] </ref>, where the increase in complexity is clearly at odds with the intuition that reasoning with defaults should somehow reduce the complexity of reasoning. This remains true, even when we severely restrict the expressiveness of the knowledge base, the default rules and the queries allowed.
Reference: [18] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufman, </publisher> <year> 1988. </year>
Reference-contexts: Various knowledge representations can be used to represent the knowledge in a knowledge-based system. Different representation systems (e.g., a set of logical rules, a probabilistic network) are associated with corresponding reasoning mechanisms, each with its own merits and range of applications <ref> [14, 18] </ref>. Given a logical knowledge base, for example, reasoning can be abstracted as a deduction task: determine whether a sentence, assumed to capture the situation at hand, is logically implied by the knowledge base.
Reference: [19] <author> R. Reiter. </author> <title> A logic for default reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 13(1,2), </volume> <year> 1980. </year>
Reference-contexts: Intuitively, the task of default reasoning also aims at capturing some notion of relevance in that it enforces additional constraints to weed out non-relevant cases and focus on the typical cases. In default reasoning <ref> [19] </ref> an agent is given a representation of the world, and a set of (sometimes 3 conflicting) default rules, and has to assess whether a query q can be concluded "by default", namely using the standard knowledge and the default rules. <p> We will concentrate here on a special case of Reiter's Default logic <ref> [19] </ref>, applied to propositional logic. In Reiter's default logic, default rules have the form ff : fi=fl, which should read as "if ff holds and it is consistent to assume fi then conclude fl". The case with fi = fl is called normal defaults, and ff is called a prerequisite. <p> The rule is positive if fi is any monotone function. The rule is positive simple if fi is a positive literal. Notice that the theory for diagnosis [21] and the closed world defaults <ref> [19] </ref> can be described using simple defaults. A default theory is a pair (D; W ) where D is a set of default rules, and W is a propositional expression. An extension of (D; W ) is defined using a fixed point operator [19]. <p> diagnosis [21] and the closed world defaults <ref> [19] </ref> can be described using simple defaults. A default theory is a pair (D; W ) where D is a set of default rules, and W is a propositional expression. An extension of (D; W ) is defined using a fixed point operator [19]. For our special case 11 the following theorem gives an alternative and simpler definition: (The operator T h (R) denotes the theorem closure of R.) Theorem 5.1 ([21], page 88) Let D be a set of normal defaults with empty prerequisites. <p> We denote this subset by S E . Since S E is consistent with W , we get that an extension E includes q if and only if W ^ S E j= q. In the original formalization <ref> [19] </ref> a knowledge base is defined to imply a query if there is an extension in which the query holds. Following [29, 6] we call this task credulous default reasoning; the case in which all extensions are taken into consideration is called skeptical default reasoning.
Reference: [20] <author> R. Reiter. </author> <title> Nonmonotonic reasoning. </title> <booktitle> In Annual Reviews of Computer Science, </booktitle> <pages> pages 147-188. </pages> <year> 1987. </year>
Reference-contexts: This type of reasoning is naturally non-monotonic since further evidence may force us to revise our conclusions. Several formalizations trying to capture this situation have been studied, and of particular interest to us here are theories for reasoning with "defaults" (see e.g. <ref> [20] </ref>). In this approach, the true knowledge about the world is augmented by a set of default rules that are meant to capture "typical" cases.
Reference: [21] <author> R. Reiter. </author> <title> A theory of diagnosis from first principles. </title> <journal> Artificial Intelligence, </journal> <volume> 32(1), </volume> <year> 1987. </year>
Reference-contexts: Definition 5.1 For normal defaults with empty prerequisites :fi=fi we define: A default rule is simple if fi is a single literal. The rule is positive if fi is any monotone function. The rule is positive simple if fi is a positive literal. Notice that the theory for diagnosis <ref> [21] </ref> and the closed world defaults [19] can be described using simple defaults. A default theory is a pair (D; W ) where D is a set of default rules, and W is a propositional expression. An extension of (D; W ) is defined using a fixed point operator [19]. <p> Corollary 5.9 The algorithm SD-MBR solves the skeptical default reasoning task SDEF (D; W; q) correctly, for all q 2 Q and for all (D; Q; ) in T D. 5.3 Application: Diagnosis using Models One of the useful applications of default logic is for the problem of circuit diagnosis <ref> [21] </ref>. Consider for example the circuit d a ^ b; e d _ c, composed of one and gate and one or gate. In order to diagnose possible problems in the circuit we add, for every gate, a new variable denoting that it is operating normally.
Reference: [22] <author> D. Roth. </author> <title> Learning to reason: The non-monotonic case. </title> <booktitle> In Proc. of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 1178-1184, </pages> <year> 1995. </year>
Reference-contexts: Namely, the agent can incrementally construct a representation that is relevant to its environment, in the sense that it supports correct reasoning there. This intuitive idea is formalized in a more general setting in the Learning to Reason framework [7], and is discussed also in <ref> [31, 22, 8] </ref>. We discuss two results in the Learning to Reason framework that use model-based representations in order to exploit the relevant information in the reasoning process. To summarize, this paper studies reasoning with model-based representations, and further substantiates the claim regarding their computational advantages.
Reference: [23] <author> D. Roth. </author> <title> On the hardness of approximate reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 82(1-2):273-302, </volume> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: Computational considerations, however, render this approach inadequate for commonsense reasoning. This is true not only for the task of deduction, but also for many other forms of reasoning that have been developed. All those were shown to be even harder to compute than the original formulation <ref> [25, 23] </ref>. This holds in particular for various formalizations of default reasoning [26, 6, 17], where the increase in complexity is clearly at odds with the intuition that reasoning with defaults should somehow reduce the complexity of reasoning.
Reference: [24] <author> D. Schuurmans and R. Greiner. </author> <title> Learning default concepts. </title> <booktitle> In Proceedings of the Tenth Canadian Conference on Artificial Intelligence (CSCSI-94), </booktitle> <year> 1994. </year>
Reference-contexts: In particular, within this framework it has been shown that the model based representations discussed here can be learned efficiently. This can be combined with context specific default rules that are acquired via rote learning or other learning processes <ref> [24] </ref> to work in a plausible way. These results can be viewed as providing some theoretical support for the usefulness of case-based style reasoning, where a set of "typical cases" is used as a knowledge representation.
Reference: [25] <author> B. Selman. </author> <title> Tractable Default Reasoning. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Toronto, </institution> <year> 1990. </year>
Reference-contexts: Computational considerations, however, render this approach inadequate for commonsense reasoning. This is true not only for the task of deduction, but also for many other forms of reasoning that have been developed. All those were shown to be even harder to compute than the original formulation <ref> [25, 23] </ref>. This holds in particular for various formalizations of default reasoning [26, 6, 17], where the increase in complexity is clearly at odds with the intuition that reasoning with defaults should somehow reduce the complexity of reasoning. <p> Thus, if S 1 S 2 , the Boolean function S 2 is the conjunction of more rules and therefore S 2 j= S 1 . 3 Our results were inspired by the connections between abduction and default reasoning developed in <ref> [25] </ref>. 12 Algorithm CD-MBR (; D; q): Do for all models z 2 such that q (z) = 1 Let S = fd 2 D : d (z) = 1g If C-MBR (; S; q) answers "Yes", return "Yes".
Reference: [26] <author> B. Selman and H. Kautz. </author> <title> Model-preference default theories. </title> <journal> Artificial Intelligence, </journal> <volume> 45 </volume> <pages> 287-322, </pages> <year> 1990. </year>
Reference-contexts: This is true not only for the task of deduction, but also for many other forms of reasoning that have been developed. All those were shown to be even harder to compute than the original formulation [25, 23]. This holds in particular for various formalizations of default reasoning <ref> [26, 6, 17] </ref>, where the increase in complexity is clearly at odds with the intuition that reasoning with defaults should somehow reduce the complexity of reasoning. This remains true, even when we severely restrict the expressiveness of the knowledge base, the default rules and the queries allowed. <p> This corresponds to assigning the value "true" to the attribute "here" for the purpose of answering the question. Sometimes we need a more expressive language to describe our assumptions regarding the current context and assume, say, that some rule applies <ref> [26] </ref>. For example, we may assume (in the "conference" context) that if someone has a car, then it is a rental car. Thus, reasoning within context may be viewed as a deduction task, where some additional constraining information is added to the knowledge base.
Reference: [27] <author> B. Selman and H. Kautz. </author> <title> Knowledge compilation and theory approximation. </title> <journal> Journal of the ACM, </journal> <volume> 43(2) </volume> <pages> 193-224, </pages> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: This idea can be formalized using the notion of least upper bound approximations <ref> [27, 9] </ref>. In fact, the model-based representations used for reasoning within context and default reasoning capture such approximations, and thus use this notion of relevance as well. Here again, the model-based representations are essential since formula-based representations of these approximations do not support efficient reasoning. <p> In this case, it is known that an incomplete description of the world is sufficient to support correct deduction. This can be formalized using the notion of a least upper bound representation, introduced by Kautz and Selman <ref> [27] </ref>. Intuitively, these approximations capture all the conclusions of W which belong to Q. In [9] it is shown that these approximations support exact deduction with respect queries in Q.
Reference: [28] <author> B. Selman and H. Levesque. </author> <title> Abductive and default reasoning: A computational core. </title> <booktitle> In Proc. of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 343-348, </pages> <year> 1990. </year>
Reference-contexts: The exact complexity relation is somewhat more subtle than in the deductive case. There, efficient solutions where presented for problems that are NP-Hard (under randomized reductions) given a formula-based representation. In the current case, the default reasoning task is NP-Hard <ref> [28] </ref> when the knowledge base is Horn, all the default rules are positive literals, and the query is a single positive literal. Our results provide an algorithm for this class of problems, which is polynomial in the size of the model based representation. <p> Our results provide an algorithm for this class of problems, which is polynomial in the size of the model based representation. This representation, though, may be exponential in the size of the Horn expression, as is the case, for example, for the problems used in the reduction in <ref> [28] </ref>. Thus, strictly speaking, we do not prove an advantage in this special case. Nevertheless, our results provide efficient algorithms in cases where they were not known to exist before. We present two algorithms, CD-MBR and SD-MBR, which handle the credulous and skeptical default reasoning tasks, respectively.
Reference: [29] <author> D. Touretzky, J. Horty, and R. Thomason. </author> <title> A clash of intuitions: The current state of non-monotonic multiple inheritance systems. </title> <booktitle> In Proc. of the International Joint Conference of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufman, </publisher> <year> 1987. </year>
Reference-contexts: In the original formalization [19] a knowledge base is defined to imply a query if there is an extension in which the query holds. Following <ref> [29, 6] </ref> we call this task credulous default reasoning; the case in which all extensions are taken into consideration is called skeptical default reasoning.
Reference: [30] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> Nov. </month> <year> 1984. </year>
Reference-contexts: In systems that learn, the world in which the agent performs its task is the same world that supplies the agent with the information when learning. This intuition is captured in the distribution free model of learning theory <ref> [30] </ref>. There, an agent first wanders around in the world, observing examples drawn from some unknown distribution D which governs the occurrences of instances in the world. Then, the agent has to perform its task, namely to classify instances.
Reference: [31] <author> L. G. Valiant. </author> <title> Rationality. </title> <booktitle> In Workshop on Computational Learning Theory, </booktitle> <pages> pages 3-14, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Namely, the agent can incrementally construct a representation that is relevant to its environment, in the sense that it supports correct reasoning there. This intuitive idea is formalized in a more general setting in the Learning to Reason framework [7], and is discussed also in <ref> [31, 22, 8] </ref>. We discuss two results in the Learning to Reason framework that use model-based representations in order to exploit the relevant information in the reasoning process. To summarize, this paper studies reasoning with model-based representations, and further substantiates the claim regarding their computational advantages.
References-found: 31

