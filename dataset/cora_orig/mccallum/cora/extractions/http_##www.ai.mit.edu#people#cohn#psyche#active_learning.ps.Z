URL: http://www.ai.mit.edu/people/cohn/psyche/active_learning.ps.Z
Refering-URL: http://www.ai.mit.edu/people/cohn/psyche/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Improving Generalization with Active Learning  
Author: David Cohn Les Atlas Richard Ladner 
Address: Cambridge, MA 02139  Seattle, WA 98195  Seattle, WA 98195  
Affiliation: Brain and Cognitive Sciences Massachusetts Inst. of Technology  Electrical Engineering University of Washington  Computer Science Eng. University of Washington  
Date: January 23, 1992  
Abstract: Active learning differs from passive "learning from examples" in that the learning algorithm assumes at least some control over what part of the input domain it receives information about. In some situations, active learning is provably more powerful that learning from examples alone, giving better generalization for a fixed number of training examples. In this paper, we consider the problem of learning a binary concept in the absence of noise (Valiant 1984). We describe a formalism for active concept learning called selective sampling, and show how it may be approximately implemented by a neural network. In selective sampling, a learner receives distribution information from the environment and queries an oracle on parts of the domain it considers "useful." We test our implementation, called an SG-network, on three domains, and observe significant improvement in generalization.
Abstract-found: 1
Intro-found: 1
Reference: <author> M. Aggoune, L. Atlas, D. Cohn, M. Damborg, M. El-Sharkawi and R. Marks II. </author> <title> (1989) Artificial neural networks for power system static security assessment. </title> <booktitle> In Proceedings, International Symposium on Circuits and Systems. </booktitle>
Reference-contexts: Otherwise it risks thermal overload and brown-out. Previous research <ref> (Aggoune et al., 1989) </ref> determined that this problem was amenable to neural network learning, but that random sampling of the problem domain was inefficient in terms of examples needed. The range of parameters over which the system will be run is known, so distribution information is readily available.
Reference: <author> D. Angluin. </author> <title> (1986) Learning regular sets from queries and counter-examples. </title> <type> Tech Report YALEU/DCS/TR-64, </type> <institution> Yale University. </institution>
Reference: <author> T. Ash. </author> <title> (1989) Dynamic node creation in backpropagation networks. </title> <type> ICS Report 8901, </type> <institution> Institute for Cognitive Science, University of California, </institution> <address> San Diego. </address>
Reference-contexts: The configuration of a network refers to the network parameters that do change during training: in this case, the weights given to each of the connections between the neurons. Although there are network training algorithms that involve changing a network's topology during training <ref> (e.g. Ash, 1989) </ref>, we consider here only those with fixed topologies that train by weight adjustment. The theory and methods described here should, with some modification, be equally applicable to other trainable classifiers.
Reference: <author> E. Baum and D. Haussler. </author> <title> (1989) What size net gives valid generalization? In D. </title> <editor> Touretzky, ed., </editor> <booktitle> Advances in Neural Information Processing Systems 1, </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: have to draw and classify from an arbitrary distribution P in order to find a concept c 2 C consistent with the examples such that *(c; t; P) * with confidence at least 1 ffi? This problem was formalized by Valiant (1984) and has been studied for neural networks in <ref> (Baum and Haussler, 1989) </ref> and (Haussler, 1989). concepts that are consistent with all training examples in S m and yet disagree on the classification of x.
Reference: <author> E. Baum and K. Lang. </author> <title> (1991) Constructing hidden units using examples and queries. </title> <editor> In R. Lippmann et al., eds., </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. Warmuth. </author> <title> (1989) Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> JACM 36(4) </journal> <pages> 929-965. </pages>
Reference: <author> A. Blum and R. Rivest. </author> <title> (1989) Training a 3-node neural network is NP-complete. </title> <editor> In D. Touretzky, ed., </editor> <booktitle> Advances in Neural Information Processing Systems 1, Proceedings of the Neural Information Processing Systems Conference, </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> D. Cohn, L. Atlas and R. Ladner. </author> <title> (1990) Training connectionist networks with queries and selective sampling. </title>
Reference-contexts: In order to achieve an expected position error of less than *, one would need to draw O ( 1 * ln ( 1 * )) random training examples. If fl As published in Machine Learning 15 (2):201-221, 1994. A preliminary version of this paper appears as <ref> (Cohn et al., 1990) </ref>. 1 one is allowed to sequentially make membership queries, then binary search is possible and, assuming a uniform distribution, a position error of * may be reached with O (ln ( 1 * )) queries.
Reference: <editor> In D. Touretzky, ed., </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> D. Cohn and G. Tesauro. </author> <title> (1992) How tight are the Vapnik-Chervonenkis bounds? Neural Computation 4(2) </title> <type> 249-269. </type>
Reference: <author> B. Eisenberg and R. Rivest. </author> <title> (1990) On the sample complexity of pac-learning using random and chosen examples. </title> <editor> In M. Fulk and J. Case, eds., </editor> <booktitle> ACM 3rd Annual Workshop on Computational Learning Theory, </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> A. Fernald and P. Kuhl. </author> <title> (1987) Acoustic Determinants of Infant Preference for Motherese Speech. </title> <booktitle> Infant Behavior and Development 10 </booktitle> <pages> 279-293. </pages>
Reference: <author> Y. Freund, H. S. Seung, E. Shamir and N. Tishby. </author> <title> (1993) Information, prediction, and query by committee. </title>
Reference: <editor> In S. Hanson et al., eds., </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> D. Haussler. </author> <title> (1987) Learning conjunctive concepts in structural domains. </title> <booktitle> In Proceedings, AAAI '87, </booktitle> <pages> pp. 466-470. </pages>
Reference: <author> D. Haussler. </author> <title> (1989) Generalizing the pac model for neural nets and other learning applications. </title> <type> UCSC Tech Report UCSC-CRL-89-30. </type>
Reference-contexts: have to draw and classify from an arbitrary distribution P in order to find a concept c 2 C consistent with the examples such that *(c; t; P) * with confidence at least 1 ffi? This problem was formalized by Valiant (1984) and has been studied for neural networks in <ref> (Baum and Haussler, 1989) </ref> and (Haussler, 1989). concepts that are consistent with all training examples in S m and yet disagree on the classification of x. <p> from an arbitrary distribution P in order to find a concept c 2 C consistent with the examples such that *(c; t; P) * with confidence at least 1 ffi? This problem was formalized by Valiant (1984) and has been studied for neural networks in (Baum and Haussler, 1989) and <ref> (Haussler, 1989) </ref>. concepts that are consistent with all training examples in S m and yet disagree on the classification of x.
Reference: <author> J. N. Hwang, J. Choi, S. Oh and R. Marks II. </author> <title> (1990) Query learning based on boundary search and gradient computation of trained multilayer perceptrons. </title> <booktitle> IJCNN 90, </booktitle> <address> San Diego, </address> <month> June 17-21. </month>
Reference: <author> S. Judd. </author> <title> (1988) On the complexity of loading shallow neural networks. </title> <journal> Journal of Complexity, </journal> <volume> 4 </volume> <pages> 177-192. </pages>
Reference: <author> Y. Le Cunn, J. Denker, and S. Solla. </author> <title> (1990) Optimal brain damage. </title> <editor> In D. Touretzky, ed., </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> D. MacKay. </author> <title> (1992b)Information-based objective functions for active data selection, </title> <booktitle> Neural Computation 4(4): </booktitle> <pages> 590-604. </pages>
Reference: <author> T. Mitchell. </author> <title> (1982) Generalization as search. </title> <booktitle> Artificial Intelligence 18 </booktitle> <pages> 203-226. </pages>
Reference-contexts: In Section 2, we describe the concept learning problem in detail and give a formal definition of selective sampling, describing the conditions necessary for the approach to be useful. In Section 3 we describe the SG-network, a neural network implementation of this technique inspired by version-space search <ref> (Mitchell, 1982) </ref>. Section 4 contains the results of testing this implementation on several different problem domains, and Section 5 discusses some of the limitations of the selective sampling approach. <p> Below, we will use c to denote both the concept c and the network ~c that implements it. Below, we consider a nave algorithm for selective sampling with neural networks and examine its shortcomings. We then describe the SG-net, based on the version-space paradigm <ref> (Mitchell, 1982) </ref>, that overcomes these difficulties. 3.1 A nave neural network querying algorithm The observation that a neural network implementation of a concept learner may produce a real-valued output that is thresholded suggests a nave algorithm for defining a region of uncertainty.
Reference: <author> L. Y. Pratt. </author> <title> (1993) Discriminability-based transfer between neural networks In C.L. </title> <editor> Giles et al., eds., </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> D. Rumelhart, G. Hinton and R. Williams. </author> <title> (1986) Learning internal representations by error propagation. </title>
Reference-contexts: The remainder of this paper is concerned with demonstrating how an approximation of selective sampling may be implemented using a feedforward neural network trained with error backpropagation. The backpropagation algorithm <ref> (Rumelhart et al., 1986) </ref> is a supervised neural network learning technique, in that the network is presented with a training set of input/output pairs (x; t (x)) and learns to output t (x) when given input x. <p> We define the error of the output node n as ffi n (x) = (o n (x) t (x)) 2 . This error value is propagated back through the network <ref> (see Rumelhart et al., 1986 for details) </ref>, so that each neuron j has an error term ffi j (x).
Reference: <editor> In D. Rumelhart and J. McClelland, eds., </editor> <booktitle> Parallel Distributed Processing, </booktitle> <publisher> MIT Press. 16 H. </publisher> <editor> S. Seung, M. Opper, and H. Sompolinsky. </editor> <title> (1992) Query by committee. </title> <booktitle> In Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pp. 287-294, </pages> <publisher> ACM, </publisher> <address> New York. </address>
Reference: <author> L. Valiant. </author> <title> (1984) A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27 </volume> <pages> 1134-1142. 17 </pages>
Reference-contexts: In many problems, though, we can still make use of distribution information without having to pay the full cost of drawing and classifying an example. Rather than assuming that the drawing of a classified example is an atomic operation <ref> (as in Valiant, 1984 and Blumer et al., 1988) </ref>, we may divide the operation into two steps: first, that of drawing an unclassified example from the distribution, and second, querying the classification of that point.
References-found: 25

