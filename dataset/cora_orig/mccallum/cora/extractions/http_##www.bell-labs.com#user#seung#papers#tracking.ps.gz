URL: http://www.bell-labs.com/user/seung/papers/tracking.ps.gz
Refering-URL: http://www.bell-labs.com/user/seung/papers/index.html
Root-URL: 
Email: fddlee|seungg@bell-labs.com  
Title: A Neural Network Based Head Tracking System  
Author: D. D. Lee and H. S. Seung 
Address: 700 Mountain Ave. Murray Hill, NJ 07974  
Affiliation: Bell Laboratories, Lucent Technologies  
Abstract: We have constructed an inexpensive, video-based, motorized tracking system that learns to track a head. It uses real time graphical user inputs or an auxiliary infrared detector as supervisory signals to train a convolutional neural network. The inputs to the neural network consist of normalized luminance and chrominance images and motion information from frame differences. Subsampled images are also used to provide scale invariance. During the online training phase, the neural network rapidly adjusts the input weights depending upon the reliability of the different channels in the surrounding environment. This quick adaptation allows the system to robustly track a head even when other objects are moving within a cluttered background.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Horiuchi, </author> <title> TK, Bishofberger, B & Koch, C (1994). An analog VLSI saccadic eye movement system. </title> <booktitle> Advances in Neural Information Processing Systems 6, </booktitle> <pages> 582-589. </pages>
Reference-contexts: For this task, complex neural circuits have evolved in order to control the eye movements. Some examples include the saccadic and smooth pursuit systems that allow the eyes to rapidly acquire and track moving objects <ref> [1, 2] </ref>. Similarly, an active video conferencing system also needs to determine the appropriate face or feature to follow in the video stream. Then the camera must track that person's movements over time and transmit the image to the other party.
Reference: [2] <author> Rao, RPN, Zelinsky, GJ, Hayhoe, MM & Ballard, </author> <month> DH </month> <year> (1996). </year> <title> Modeling sac-cadic targeting in visual search. </title> <booktitle> Advances in Neural Information Processing Systems 8, </booktitle> <pages> 830-836. </pages>
Reference-contexts: For this task, complex neural circuits have evolved in order to control the eye movements. Some examples include the saccadic and smooth pursuit systems that allow the eyes to rapidly acquire and track moving objects <ref> [1, 2] </ref>. Similarly, an active video conferencing system also needs to determine the appropriate face or feature to follow in the video stream. Then the camera must track that person's movements over time and transmit the image to the other party.
Reference: [3] <author> Sung, KK & Poggio, </author> <title> T (1994). Example-based learning for view-based human face detection. </title> <booktitle> Proc. 23rd Image Understanding Workshop, </booktitle> <pages> 843-850. </pages>
Reference-contexts: Then the camera must track that person's movements over time and transmit the image to the other party. In the past few years, the problem of face detection in images and video has attracted considerable attention <ref> [3, 4, 5] </ref>. Rule-based methods have concentrated on looking for generic characteristics of faces such as oval shapes or skin hue. Since these types of algorithms are fairly simple to implement, they are commonly found in real-time systems [6, 7].
Reference: [4] <author> Eleftheriadis, </author> <title> A & Jacquin, A (1995). Automatic face location detection and tracking for model-assisted coding of video teleconferencing sequences at low bit-rates. Signal Processing: </title> <type> Image Communication 7, 231. </type>
Reference-contexts: Then the camera must track that person's movements over time and transmit the image to the other party. In the past few years, the problem of face detection in images and video has attracted considerable attention <ref> [3, 4, 5] </ref>. Rule-based methods have concentrated on looking for generic characteristics of faces such as oval shapes or skin hue. Since these types of algorithms are fairly simple to implement, they are commonly found in real-time systems [6, 7].
Reference: [5] <author> Petajan, E & Graf, </author> <title> HP (1996). Robust face feature analysis for automatic speechreading and character animation. </title> <booktitle> Proc. 2nd Int. Conf. Automatic Face and Gesture Recognition, </booktitle> <pages> 357-362. </pages>
Reference-contexts: Then the camera must track that person's movements over time and transmit the image to the other party. In the past few years, the problem of face detection in images and video has attracted considerable attention <ref> [3, 4, 5] </ref>. Rule-based methods have concentrated on looking for generic characteristics of faces such as oval shapes or skin hue. Since these types of algorithms are fairly simple to implement, they are commonly found in real-time systems [6, 7].
Reference: [6] <author> Darrell, T, Maes, P, Blumberg, B, & Pentland, </author> <title> AP (1994). A novel environment for situated vision and behavior. </title> <booktitle> Proc. IEEE Workshop for Visual Behaviors, </booktitle> <pages> 68-72. </pages>
Reference-contexts: Rule-based methods have concentrated on looking for generic characteristics of faces such as oval shapes or skin hue. Since these types of algorithms are fairly simple to implement, they are commonly found in real-time systems <ref> [6, 7] </ref>. But because other objects have similar shapes and colors as faces, these systems can also be easily fooled. A potentially more robust approach is to use a convolutional neural network to learn the appropriate features of a face [8, 9].
Reference: [7] <author> Yang, J & Waibel, </author> <title> A (1996). A real-time face tracker. </title> <booktitle> Proc. 3rd IEEE Workshop on Application of Computer Vision, </booktitle> <pages> 142-147. </pages>
Reference-contexts: Rule-based methods have concentrated on looking for generic characteristics of faces such as oval shapes or skin hue. Since these types of algorithms are fairly simple to implement, they are commonly found in real-time systems <ref> [6, 7] </ref>. But because other objects have similar shapes and colors as faces, these systems can also be easily fooled. A potentially more robust approach is to use a convolutional neural network to learn the appropriate features of a face [8, 9].
Reference: [8] <author> Nowlan, SJ & Platt, </author> <title> JC (1995). A convolutional neural network hand tracker. </title> <booktitle> Advances in Neural Information Processing Systems 7, </booktitle> <pages> 901-908. </pages>
Reference-contexts: But because other objects have similar shapes and colors as faces, these systems can also be easily fooled. A potentially more robust approach is to use a convolutional neural network to learn the appropriate features of a face <ref> [8, 9] </ref>. Because most such implementations learn in batch mode, they are beset by the difficulty of constructing a large enough training set of labelled images with and without faces. In this paper, we present a video based system that uses online supervisory signals to train a convolutional neural network. <p> The gradients to Eqs. 4-5 are then backpropagated through the convolutional network <ref> [8, 10] </ref>, resulting in the following update rules: c A = e m g 0 (X m )g [ A (i m ; j m )] + e n g 0 (X n )g [ A (i n ; j n )]; (6) In typical batch learning applications of neural networks,
Reference: [9] <author> Rowley, HA, Baluja, </author> <title> S & Kanade, T (1996). Human face detection in visual scenes. </title> <booktitle> Advances in Neural Information Processing Systems 8, </booktitle> <pages> 875-881. </pages>
Reference-contexts: But because other objects have similar shapes and colors as faces, these systems can also be easily fooled. A potentially more robust approach is to use a convolutional neural network to learn the appropriate features of a face <ref> [8, 9] </ref>. Because most such implementations learn in batch mode, they are beset by the difficulty of constructing a large enough training set of labelled images with and without faces. In this paper, we present a video based system that uses online supervisory signals to train a convolutional neural network.
Reference: [10] <author> Le Cun, Y, et al. </author> <year> (1990). </year> <title> Handwritten digit recognition with a back propagation network. </title> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <pages> 396-404. </pages>
Reference-contexts: The gradients to Eqs. 4-5 are then backpropagated through the convolutional network <ref> [8, 10] </ref>, resulting in the following update rules: c A = e m g 0 (X m )g [ A (i m ; j m )] + e n g 0 (X n )g [ A (i n ; j n )]; (6) In typical batch learning applications of neural networks,
References-found: 10

