URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-94-1216/CS-TR-94-1216.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-94-1216/
Root-URL: http://www.cs.wisc.edu
Title: Estimating Mean Completion Times of a Fork-Join Barrier Synchronization  
Author: Eric Bach, Rajesh Mansharamani, and John Strikwerda 
Keyword: P n  
Address: 1210 W. Dayton St. Madison, WI 53706.  
Affiliation: Computer Sciences Department  
Email: Email: fbach, mansha, strikg@cs.wisc.edu  
Phone: Tel: (608) 262-7997  
Date: February 21, 1994  
Abstract: In simulation studies of parallel processors, it is useful to consider the following abstraction of a parallel program. A job is partitioned into n processes, whose running times are independent random variables X 1 ; : : :; X n . As a measure of performance we consider the normalized job completion time S = maxfX i g= i=1 X i . We consider a simple approximation to the expected value of S, valid asymptotically whenever the X i 's are bounded, and assess its accuracy as a function of n both theoretically and experimentally. The approximation is easy to compute and involves only the first two moments of X i . 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Z. Arov and A. A. Bobrov. </author> <title> The Extreme Terms of a Sample and Their Role in the Sum of Independent Variables. </title> <journal> Teor. Verojatnost. i Primen. </journal> <volume> 5 (1960), </volume> <pages> 377-396. </pages> <booktitle> [In Russian; English translation in Theory of Probability and Applications.] </booktitle> <pages> 12 </pages>
Reference-contexts: We validate our approximation against simulation for several job length distributions. The results of this paper extend previous work in several ways. Several authors have studied the distributions of S and 1=S under various assumptions about the parent distribution. (See <ref> [1, 2, 5, 6] </ref> and references therein.) The emphasis in these works was on asymptotic results for unbounded random variables, in part because 1=S is asymptotically normal otherwise. (Unfortunately, this doesn't tell us much about the expected value of S: when Z is normal, E [1=Z] fails to exist.) In contrast,
Reference: [2] <author> T. L. Chow and J. L. Tuegels, </author> <title> The sum and maximum of i.i.d. random variables, </title> <booktitle> Proc. Second Prague Symposium on Asymptotic Statistics, </booktitle> <year> (1979), </year> <pages> 81-92. </pages>
Reference-contexts: We validate our approximation against simulation for several job length distributions. The results of this paper extend previous work in several ways. Several authors have studied the distributions of S and 1=S under various assumptions about the parent distribution. (See <ref> [1, 2, 5, 6] </ref> and references therein.) The emphasis in these works was on asymptotic results for unbounded random variables, in part because 1=S is asymptotically normal otherwise. (Unfortunately, this doesn't tell us much about the expected value of S: when Z is normal, E [1=Z] fails to exist.) In contrast,
Reference: [3] <author> H. Cramer, </author> <title> Mathematical Methods of Statistics. </title> <publisher> Princeton Univ. Press, </publisher> <address> Princeton 1946. </address>
Reference-contexts: For sample means, we have k i=1 V i " P m m : Let k := k (V ) denote the k-th central moment of the parent distribution. Cramer <ref> [3, page 345] </ref> gives the following formulas for the i.i.d. case: 1 i=1 V i 2 i=1 V i 2 ; P m m = m 2 ; 4 i=1 V i 3 2 m 2 + 2 and observes that for fixed k, k ( P m i=1 V i
Reference: [4] <author> H. Chernoff. </author> <title> A Measure of Asymptotic Efficiency for Tests of a Hypothesis Based on the Sum of Observations. </title> <journal> Annals of Math. Stat., </journal> <volume> 23 (1952), </volume> <pages> 493-507. </pages>
Reference-contexts: In particular, it is not obvious how the constant in the above O-result depends on k. 2. Large Deviations. For a random variable ~, let ~ (t) := E [e t~ ] be its moment generating function. The following result appears in Chernoff <ref> [4] </ref>: If V 1 ; V 2 ; : : : ; V m are i.i.d. with the same distribution as ~ and a &lt; E [~], then Pr [ i=1 0 e a ~ () m We must check that the infimum is actually less than 1.
Reference: [5] <author> D. A. Darling. </author> <title> The Influence of the Maximum Term in the Addition of Independent Random Variables. </title> <journal> Trans. Amer. Math. Soc. </journal> <volume> 73 (1952), </volume> <pages> 95-107. </pages>
Reference-contexts: We validate our approximation against simulation for several job length distributions. The results of this paper extend previous work in several ways. Several authors have studied the distributions of S and 1=S under various assumptions about the parent distribution. (See <ref> [1, 2, 5, 6] </ref> and references therein.) The emphasis in these works was on asymptotic results for unbounded random variables, in part because 1=S is asymptotically normal otherwise. (Unfortunately, this doesn't tell us much about the expected value of S: when Z is normal, E [1=Z] fails to exist.) In contrast,
Reference: [6] <author> D. A. Darling. </author> <title> On a Test for Homogeneity and Extreme Values. </title> <journal> Ann. Math. Stat. </journal> <volume> 23 (1952), </volume> <pages> 450-456. </pages>
Reference-contexts: We validate our approximation against simulation for several job length distributions. The results of this paper extend previous work in several ways. Several authors have studied the distributions of S and 1=S under various assumptions about the parent distribution. (See <ref> [1, 2, 5, 6] </ref> and references therein.) The emphasis in these works was on asymptotic results for unbounded random variables, in part because 1=S is asymptotically normal otherwise. (Unfortunately, this doesn't tell us much about the expected value of S: when Z is normal, E [1=Z] fails to exist.) In contrast, <p> This distribution is often used as a model for process times; for example, the exponential distribution has k = 1. In this case, one could use the asymptotic distribution of 1=S given by Darling <ref> [6] </ref> to estimate E [S]; we discuss an alternative approach below. The remainder of this paper is organized as follows. Section 2 derives the approximation for S in terms of the first two moments of X. <p> For the uniform case (X i i.i.d. U (0; 1)), our method gives an asymptotic series for S. We observe that S has the same distribution as 1=(1 + P n1 i=1 X i ), as is easily proved by conditioning on the maximum. (Compare <ref> [6, page 451] </ref>.) Therefore, S = ^ S = n + 1 1 + 3n 2 4 On the other hand, one should not expect (15) to converge quickly for distributions with rapidly vanishing tails. Consider, as a limiting case, X i 's that are i.i.d. (k) random variables.
Reference: [7] <author> P. Erd-os and A. Renyi, </author> <title> On a Classical Problem of Probability Theory. </title> <journal> MTA Mat. Kut. Inst. Kozl. </journal> <volume> 6A (1961), </volume> <pages> 215-220. </pages>
Reference-contexts: with a known expected value. (See [10].) If this is done we obtain E maxfX i g P n log n + (k 1) log log n + C log ((k 1)!) + o (n) 7 (here C = 0:57721::: is Euler's constant), a very accurate approximation for fixed k <ref> [7] </ref>. If we approximate the gamma distribution by truncation to [0; M ] and M k, then S will be close to this. On the other hand, for any fixed n, lim E M P n1 ! by the bounded convergence theorem.
Reference: [8] <author> M. Kendall and A. Stuart. </author> <title> The Advanced Theory of Statistics. Volume 1: Distribution Theory. Second Edition, </title> <publisher> Charles Griffin & Co. Ltd., </publisher> <address> London 1963. </address>
Reference-contexts: Higher moments could be computed using a procedure outlined by Kendall and Stuart <ref> [8] </ref>, although the formulas become increasingly complex as k grows. In particular, it is not obvious how the constant in the above O-result depends on k. 2. Large Deviations. For a random variable ~, let ~ (t) := E [e t~ ] be its moment generating function. <p> We will use the Second Limit Theorem from Kendall and Stuart <ref> [8, page 115] </ref>, which states that for a sequence of distribution functions fF m (x)g that converge to the distribution function G (x), the k th central moment of F m (x), k (m), converges to the k th central moment, k , of G (x) (assuming that k (m) exists
Reference: [9] <author> S. </author> <title> Leutenegger. Issues in multiprogrammed multiprocessor scheduling. </title> <type> Ph.D. Thesis, Technical Report #954, </type> <institution> Computer Sciences Dept., Univ. of Wisconsin-Madison, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: It can also be thought of as a job completion time, normalized by demand. This ratio, assuming process times are i.i.d. samples from a uniform distribution, has been used in simulation studies of multiprogrammed parallel processor scheduling policies <ref> [9, 11] </ref>. In such studies it is useful to know the expected value of S, which is proportional to the mean completion time of a simulated y This research was partially supported by the National Science Foundation under grants DCR-9208639, DMS-9208049 and CCR-9024144 jobs.
Reference: [10] <author> G. Lewandowski, A. Condon, and E. Bach. </author> <title> Realistic analysis of parallel dynamic programming algorithms. </title> <type> Technical Report #1116, </type> <institution> Computer Sciences Dept., Univ. of Wisconsin-Madison, </institution> <month> October </month> <year> 1992. </year> <booktitle> (Abstract in Proc. 1993 SIGMETRICS, </booktitle> <pages> 268-269.) </pages>
Reference-contexts: Therefore E maxfX i g P n E (maxfX i g) E ( i=1 X i ) and we can relate the maximum to an occupancy distribution, with a known expected value. (See <ref> [10] </ref>.) If this is done we obtain E maxfX i g P n log n + (k 1) log log n + C log ((k 1)!) + o (n) 7 (here C = 0:57721::: is Euler's constant), a very accurate approximation for fixed k [7].
Reference: [11] <author> S. Majumdar, D. Eager, and R. Bunt. </author> <title> Scheduling in multiprogrammed parallel systems. </title> <booktitle> ACM SIG-METRICS Conf. and Performance Evaluation Review 16, </booktitle> <month> 1 (May </month> <year> 1988), </year> <pages> 104-113. </pages>
Reference-contexts: It can also be thought of as a job completion time, normalized by demand. This ratio, assuming process times are i.i.d. samples from a uniform distribution, has been used in simulation studies of multiprogrammed parallel processor scheduling policies <ref> [9, 11] </ref>. In such studies it is useful to know the expected value of S, which is proportional to the mean completion time of a simulated y This research was partially supported by the National Science Foundation under grants DCR-9208639, DMS-9208049 and CCR-9024144 jobs.
Reference: [12] <author> A. </author> <month> Rosengard. </month> <institution> Etude des Lois-limites Jointes et Marginales de la Moyenne et des Valeurs Extr^emes d'un Enchantillon. Publ. Inst. Statist. Univ. Paris, </institution> <month> 11 </month> <year> (1963), </year> <pages> 3-53. </pages>
Reference-contexts: Roughly speaking, then, we expect (15) to be good for distributions with significant mass near the upper bound M . Since maxfX i g and P n i=1 X i are asymptotically independent <ref> [12] </ref>, there is probably some merit in replacing (15) by E [maxfX i g] M if this is not the case. We note, however, that this heuristic correction requires knowledge of the expected maximum.
Reference: [13] <author> J. Strikwerda and R. Mansharamani. </author> <title> Evaluating the Mean Completion Time of a Fork-Join Barrier Synchronization. </title> <type> Technical Report #1153, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <month> May </month> <year> 1993. </year> <note> Submitted for publication. 13 </note>
Reference-contexts: In such studies it is useful to know the expected value of S, which is proportional to the mean completion time of a simulated y This research was partially supported by the National Science Foundation under grants DCR-9208639, DMS-9208049 and CCR-9024144 jobs. In <ref> [13] </ref> two expressions for S := E maxfT i g D (2) are given: a closed form (not usable beyond n = 50 due to cancellation) and an infinite series, which leads to an O (n 2 ) algorithm to approximate S. <p> Both of these results assume process times are uniformly distributed. In this paper we propose a simple two-moment approximation for S under more general assumptions for process service times than <ref> [13] </ref>. More specifically, we assume that the total demand D is partitioned into processes of length T j = i=1 X i where X 1 ; : : :; X n are i.i.d. bounded positive random variables, independent of D. <p> Such formulas are important because detailed distributional information is rarely available in a real situation. In the uniform case, our approximation leads to an asymptotic series for S. As this series is more accurate as n increases, this complements the methods of <ref> [13] </ref>. Although we are primarily concerned with bounded random variables, it it is worthwhile to remark that E [S] can be estimated rather precisely in the important unbounded case where X 1 ; : : : ; X n are i.i.d. samples from a (k) distribution.
Reference: [14] <author> P. Whittle. </author> <title> Bounds for the Moments of Linear and Quadratic Forms in Independent Variables. Theory of Probability and Its Applications V, </title> <booktitle> 3 (1960), </booktitle> <pages> 302-305. 14 </pages>
Reference-contexts: Clearly E [Y k m ] exists for m 1 since the V i are bounded. We need to show that E [Y k m ] A k for some A k independent of m. To do this we use the following result by Whittle <ref> [14] </ref>: Proposition. Let W m = P m i=1 b i U i , where U 1 ; : : : ; U m are i.i.d. with mean zero. Let fl i (k) = E [jU i j k ] 1=k .
References-found: 14

