URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/ijcai-91.ps
Refering-URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/
Root-URL: http://www.csc.ncsu.edu
Title: Towards a Formal Theory of Communication for Multiagent Systems  
Author: Munindar P. Singh 
Address: Austin, TX 78712-1188 USA  Austin, TX 78759 USA  
Affiliation: Dept of Computer Sciences University of Texas  and Artificial Intelligence Lab MCC  
Date: 1991  
Note: In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),  
Abstract: Agents in multiagent systems interact to a large extent by communicating. Such communication may be fruitfully studied from the point of view of speech act theory. In order for mul-tiagent systems to be formally and rigorously designed and analyzed, a semantics of speech acts that gives their objective model-theoretic conditions of satisfaction is needed. However, most research into multiagent systems that deals with communication provides only informal descriptions of the different message types used. And this problem is not addressed at all by traditional speech act theory or by AI research into discourse understanding. I provide a formal semantics for the major kinds of speech acts at a level that has not been considered before. The resulting theory applies uniformly to a wide range of multiagent systems. Some applications of this theory are outlined, and some of its theorems listed. 
Abstract-found: 1
Intro-found: 1
Reference: [ Allen and Perrault, 1980 ] <author> James F. Allen and C. Ray-mond Perrault. </author> <title> Analyzing intention in utterances. </title> <journal> Artificial Intelligence, </journal> <volume> 15 </volume> <pages> 143-178, </pages> <year> 1980. </year>
Reference-contexts: The AI literature in this area too is concerned with the linguistic or discourse-related aspects of this problem (e.g., for identifying the illocutionary force of indirect speech acts <ref> [ Allen and Perrault, 1980 ] </ref> , or defining their effects on the mutual beliefs of agents [ Cohen and Levesque, 1988 ] ). Of interest here is the orthogonal problem of formally describing the conditions of satisfaction for the different kinds of speech acts.
Reference: [ Austin, 1962 ] <author> John L. Austin. </author> <title> How to do Things with Words. </title> <publisher> Clarendon, Oxford, </publisher> <address> UK, </address> <year> 1962. </year>
Reference-contexts: In x4, I show how this theory may be used in the design of multiagent systems, and list some useful theorems. 2 Shades of Satisfaction As remarked above, communication among agents in a multiagent system can be best understood by appealing to speech act theory <ref> [ Austin, 1962; Searle, 1969 ] </ref> . In speech act theory an "illocution" (which I identify with a message) is seen to have two parts: an illocutionary force and a proposition.
Reference: [ Bach and Harnish, 1979 ] <author> Kent Bach and Robert M. Harnish. </author> <title> Linguistic Communication and Speech Acts. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1979. </year>
Reference-contexts: This, relevant satisfaction, is the strongest notion of satisfaction that I consider here. The taxonomy of speech acts of this paper is motivated by the fact that permissives, prohibitives and directives have different satisfaction conditions (cf. <ref> [ Bach and Harnish, 1979, pp. 39-54 ] </ref> and [ Searle and Vanderveken, 1985, ch. 9 ] , where permissives and prohibitives are lumped together with directives). The more convention-or culture-oriented illocutionary forces (e.g., christenings, greetings) are not considered here.
Reference: [ Cohen and Levesque, 1988 ] <author> Philip R. Cohen and Hector J. Levesque. </author> <title> Rational interaction as the basis for communication. </title> <type> Technical Report 433, </type> <institution> SRI International, </institution> <address> Menlo Park, CA, </address> <month> April </month> <year> 1988. </year>
Reference-contexts: The AI literature in this area too is concerned with the linguistic or discourse-related aspects of this problem (e.g., for identifying the illocutionary force of indirect speech acts [ Allen and Perrault, 1980 ] , or defining their effects on the mutual beliefs of agents <ref> [ Cohen and Levesque, 1988 ] </ref> ). Of interest here is the orthogonal problem of formally describing the conditions of satisfaction for the different kinds of speech acts. I take the view that communication occurs because agents need to interact effectively and to influence each others' actions.
Reference: [ Davis and Smith, 1983 ] <author> Randall Davis and Reid G. Smith. </author> <title> Negotiation as a metaphor for distributed problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 20 </volume> <pages> 63-109, </pages> <year> 1983. </year> <note> Reprinted in Readings in Distributed Artificial Intelligence, </note> <editor> A. H. Bond and L. Gasser, eds., </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: E.g., requiring that agents persist with their strategies for sufficiently long considerably simplifies generating runs that on which directives and com-misives are WSAT. Correctness must be ensured for all the message types that can occur in the system. As an example, consider the contract net <ref> [ Davis and Smith, 1983 ] </ref> . In its simplest form, a manager sends out a call for bids to all contractors|treat this as requesting the hearer to bid and to promise that it will do the task for a certain price (if it wants to bid).
Reference: [ Emerson, 1990 ] <author> E. A. Emerson. </author> <title> Temporal and modal logic. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume B. </booktitle> <publisher> North-Holland Publishing Company, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1990. </year>
Reference-contexts: Here E means "in some scenario beginning at this time"; A j :E:; pUq "q holds in the future and p holds until then"; P "at a past time up to the beginning of this scenario"; Fp j trueUp "eventually p"; and Gp j :F:p "always p" <ref> [ Emerson, 1990 ] </ref> . E evaluated at a scenario is evaluated at the first point in that scenario. 1. RSAT entails WSAT; WSAT entails ESAT. 2. For a given scenario, ESAT (comm (x; y; hi; pi)) j Fp for i 6= prohibitive. For prohibitives, it j G:p. 3.
Reference: [ Gasser and Huhns, 1989 ] <editor> Les Gasser and Michael N. Huhns, editors. </editor> <booktitle> Distributed Artificial Intelligence, Volume II. </booktitle> <publisher> Pitman/Morgan Kaufmann, </publisher> <address> London, </address> <year> 1989. </year>
Reference-contexts: This connection to other theories is reason to be reassured that this theory is not ad hoc, and will coherently fit in a bigger picture. The theory presented in this paper has ramifications in several subareas of AI, notably, multiagent planning and action, autonomous agents, and cooperative work <ref> [ Gasser and Huhns, 1989; Huhns, 1987 ] </ref> . Traditionally, speech act theory classifies communications or messages into several kinds of illocutionary acts [ Searle, 1969; Searle and Vanderveken, 1985 ] . These include assertives, directives, commisives, permissives and prohibitives.
Reference: [ Grice, 1969 ] <author> Paul Grice. </author> <title> Utterer's meaning and intentions. </title> <journal> Philosophical Review, </journal> <note> 1969. Reprinted in </note> [ ? ] . 
Reference-contexts: Research in speech act theory, on the other hand, concentrates on describing the conditions under which a particular speech act (of whatever form) may be said to have occurred <ref> [ Grice, 1969; Searle, 1975 ] </ref> .
Reference: [ Hamblin, 1987 ] <editor> C. L. Hamblin. Imperatives. </editor> <publisher> Basil Blackwell Ltd., Oxford, </publisher> <address> UK, </address> <year> 1987. </year>
Reference-contexts: Classical logic applies only to the case of assertives and considers only their truth and falsity. Therefore, it is inappropriate for other kinds of speech acts (Hamblin describes and criticizes several nonclassical logics for commands <ref> [ Hamblin, 1987, pp. 97-136 ] </ref> , so I do not consider them here). Research in speech act theory, on the other hand, concentrates on describing the conditions under which a particular speech act (of whatever form) may be said to have occurred [ Grice, 1969; Searle, 1975 ] . <p> Assertives, being claims of fact, are true or false; other speech acts call for a more complex framework in which their felicity or success can be described. In the context of imperatives, Hamblin distinguishes between what he calls extensional and whole-hearted satisfaction <ref> [ Hamblin, 1987, pp. 153-157 ] </ref> . Briefly, the former notion admits accidental success, while the latter does not. <p> This lacuna is filled by this paper. But before I come to the formalization, I must discuss the different senses of satisfaction of speech acts. The rest of this section extends the discussion in <ref> [ Hamblin, 1987, pp. 153-157 ] </ref> . Note that these different senses agree for the case of assertives. The propositional part of a message specifies the state of the world that the message is, in some sense, about. <p> Thus the satisfaction of a message depends both on its illocutionary force and its proposition. The different notions of satisfaction are motivated using directives; other speech acts are considered in x3. In the simplest sense of satisfaction, called extensional satisfaction in <ref> [ Hamblin, 1987, p. 153 ] </ref> , a message is said to be satisfied (with only minor qualifications) just if its proposition turns out to hold. E.g., a directive is satisfied when the proposition becomes true. <p> Here the same framework and technical definitions are used to give an account of the different sorts of satisfaction of several kinds of speech acts. This project has been inspired by that of C. L. Hamblin, who died while writing <ref> [ Hamblin, 1987 ] </ref> .
Reference: [ Huhns et al., 1990 ] <author> Michael N. Huhns, David Bridge-land, and Natraj Arni. </author> <title> A DAI communication aide. </title> <type> Technical Report ACT-RA-317-90, </type> <institution> Microelectronics and Computer Technology Corporation, Austin, TX, </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: Here i is an atomic symbol from the set fdirective, commisive, permissive, prohibitive, assertiveg; and p is a logical formula. This much is quite standard even in the AI literature that deals with communication among agents <ref> [ Huhns et al., 1990; Thomas et al., 1990 ] </ref> . However, none of the AI papers so far give a rigorous formal semantics for messages of different illocutionary forces. This lacuna is filled by this paper.
Reference: [ Huhns, 1987 ] <editor> Michael N. Huhns, editor. </editor> <booktitle> Distributed Artificial Intelligence. </booktitle> <publisher> Pitman/Morgan Kaufmann, </publisher> <address> Lon-don, </address> <year> 1987. </year>
Reference-contexts: This connection to other theories is reason to be reassured that this theory is not ad hoc, and will coherently fit in a bigger picture. The theory presented in this paper has ramifications in several subareas of AI, notably, multiagent planning and action, autonomous agents, and cooperative work <ref> [ Gasser and Huhns, 1989; Huhns, 1987 ] </ref> . Traditionally, speech act theory classifies communications or messages into several kinds of illocutionary acts [ Searle, 1969; Searle and Vanderveken, 1985 ] . These include assertives, directives, commisives, permissives and prohibitives.
Reference: [ Perrault, 1987 ] <author> Raymond Perrault. </author> <title> An application of default logic to speech act theory. </title> <type> Technical Report 90, </type> <institution> Center for the Study of Language and Information, Stanford, </institution> <address> CA, </address> <month> March </month> <year> 1987. </year>
Reference-contexts: A problem not addressed here concerns the effects a speech act has on the hearer. These depend on issues like the social relationship of the agents or on matters of performance|these are not easy to describe, and are connected to processes of deliberation and belief revision <ref> [ Perrault, 1987 ] </ref> , rather than to the semantics of communication per se. Perrault provides some postulates for such revision using default logic. His focus is on the pragmatics of speech acts in natural language understanding, rather than the semantics as considered here.
Reference: [ Searle and Vanderveken, 1985 ] <author> John R. Searle and Daniel Vanderveken. </author> <title> Foundations of Illocutionary Logic. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, UK, </address> <year> 1985. </year>
Reference-contexts: The theory presented in this paper has ramifications in several subareas of AI, notably, multiagent planning and action, autonomous agents, and cooperative work [ Gasser and Huhns, 1989; Huhns, 1987 ] . Traditionally, speech act theory classifies communications or messages into several kinds of illocutionary acts <ref> [ Searle, 1969; Searle and Vanderveken, 1985 ] </ref> . These include assertives, directives, commisives, permissives and prohibitives. Briefly, assertives are statements of fact; directives are commands, requests or advice; commi-sives (e.g., promises) commit the speaker to a course of action; permissives issue permissions; and prohibitives take them away. <p> This, relevant satisfaction, is the strongest notion of satisfaction that I consider here. The taxonomy of speech acts of this paper is motivated by the fact that permissives, prohibitives and directives have different satisfaction conditions (cf. [ Bach and Harnish, 1979, pp. 39-54 ] and <ref> [ Searle and Vanderveken, 1985, ch. 9 ] </ref> , where permissives and prohibitives are lumped together with directives). The more convention-or culture-oriented illocutionary forces (e.g., christenings, greetings) are not considered here.
Reference: [ Searle, 1969 ] <author> John R. Searle. </author> <title> Speech Acts. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, UK, </address> <year> 1969. </year>
Reference-contexts: The theory presented in this paper has ramifications in several subareas of AI, notably, multiagent planning and action, autonomous agents, and cooperative work [ Gasser and Huhns, 1989; Huhns, 1987 ] . Traditionally, speech act theory classifies communications or messages into several kinds of illocutionary acts <ref> [ Searle, 1969; Searle and Vanderveken, 1985 ] </ref> . These include assertives, directives, commisives, permissives and prohibitives. Briefly, assertives are statements of fact; directives are commands, requests or advice; commi-sives (e.g., promises) commit the speaker to a course of action; permissives issue permissions; and prohibitives take them away. <p> In x4, I show how this theory may be used in the design of multiagent systems, and list some useful theorems. 2 Shades of Satisfaction As remarked above, communication among agents in a multiagent system can be best understood by appealing to speech act theory <ref> [ Austin, 1962; Searle, 1969 ] </ref> . In speech act theory an "illocution" (which I identify with a message) is seen to have two parts: an illocutionary force and a proposition.
Reference: [ Searle, 1975 ] <author> John R. Searle. </author> <title> Indirect speech acts. </title> <editor> In P. Cole and J. L. Morgan, editors, </editor> <booktitle> Syntax and Semantics, </booktitle> <volume> Volume 3. </volume> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1975. </year> <note> Reprinted in </note> [ ? ] . 
Reference-contexts: Research in speech act theory, on the other hand, concentrates on describing the conditions under which a particular speech act (of whatever form) may be said to have occurred <ref> [ Grice, 1969; Searle, 1975 ] </ref> .
Reference: [ Singh, 1990a ] <author> Munindar P. Singh. </author> <title> Group intentions. </title> <booktitle> In 10th Workshop on Distributed Artificial Intelligence, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: were motivated and developed on independent grounds, albeit with a view to their final fl This research was partially supported by the Microelectronics and Computer Technology Corporation, and by the National Science Foundation (through grant # IRI-8945845 to the Center for Cognitive Science, University of Texas). application to this problem <ref> [ Singh, 1991; Singh, 1990a; S-ingh, 1990b ] </ref> . This connection to other theories is reason to be reassured that this theory is not ad hoc, and will coherently fit in a bigger picture. <p> theory of know-how and intentions, but I take this advice seriously, and try to give a semantics of several kinds of speech acts in terms of my earlier theory of intentions and know-how, where these concepts are defined in terms of the actions of agents situated in an objective model <ref> [ Singh, 1990b; Singh, 1990a; Singh, 1991 ] </ref> . I briefly describe that theory, and then turn to the formal model. 3.1 Know-how and Intentions This theory of know-how and intentions is meant to apply to both traditional plan-based architectures and modern situated ones. <p> Another important primitive is can-prevent, notated K prev . This is related to know-how and applies when the given agent is able to perform actions so as to prevent the occurrence of the given condition. For reasons of space, the technical details of <ref> [ Singh, 1991; Singh, 1990a; Singh, 1990b ] </ref> are not included here. The presentation below is self-contained, however. 3.2 The Formal Model The formal model here is based on possible worlds. Each possible world has a branching history of times.
Reference: [ Singh, 1990b ] <author> Munindar P. Singh. </author> <title> Towards a theory of situated know-how. </title> <booktitle> In 9th European Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: theory of know-how and intentions, but I take this advice seriously, and try to give a semantics of several kinds of speech acts in terms of my earlier theory of intentions and know-how, where these concepts are defined in terms of the actions of agents situated in an objective model <ref> [ Singh, 1990b; Singh, 1990a; Singh, 1991 ] </ref> . I briefly describe that theory, and then turn to the formal model. 3.1 Know-how and Intentions This theory of know-how and intentions is meant to apply to both traditional plan-based architectures and modern situated ones. <p> Another important primitive is can-prevent, notated K prev . This is related to know-how and applies when the given agent is able to perform actions so as to prevent the occurrence of the given condition. For reasons of space, the technical details of <ref> [ Singh, 1991; Singh, 1990a; Singh, 1990b ] </ref> are not included here. The presentation below is self-contained, however. 3.2 The Formal Model The formal model here is based on possible worlds. Each possible world has a branching history of times.
Reference: [ Singh, 1991 ] <author> Munindar P. Singh. </author> <title> A logic of situated know-how. </title> <booktitle> In National Conference on Artificial Intelligence (AAAI), </booktitle> <month> July </month> <year> 1991. </year>
Reference-contexts: were motivated and developed on independent grounds, albeit with a view to their final fl This research was partially supported by the Microelectronics and Computer Technology Corporation, and by the National Science Foundation (through grant # IRI-8945845 to the Center for Cognitive Science, University of Texas). application to this problem <ref> [ Singh, 1991; Singh, 1990a; S-ingh, 1990b ] </ref> . This connection to other theories is reason to be reassured that this theory is not ad hoc, and will coherently fit in a bigger picture. <p> theory of know-how and intentions, but I take this advice seriously, and try to give a semantics of several kinds of speech acts in terms of my earlier theory of intentions and know-how, where these concepts are defined in terms of the actions of agents situated in an objective model <ref> [ Singh, 1990b; Singh, 1990a; Singh, 1991 ] </ref> . I briefly describe that theory, and then turn to the formal model. 3.1 Know-how and Intentions This theory of know-how and intentions is meant to apply to both traditional plan-based architectures and modern situated ones. <p> Another important primitive is can-prevent, notated K prev . This is related to know-how and applies when the given agent is able to perform actions so as to prevent the occurrence of the given condition. For reasons of space, the technical details of <ref> [ Singh, 1991; Singh, 1990a; Singh, 1990b ] </ref> are not included here. The presentation below is self-contained, however. 3.2 The Formal Model The formal model here is based on possible worlds. Each possible world has a branching history of times.
Reference: [ Thomas et al., 1990 ] <author> Becky Thomas, Yoav Shoham, and Anton Schwartz. </author> <title> Modalities in agent-oriented programming. </title> <institution> Computer Science Department, Stanford University, </institution> <month> February </month> <year> 1990. </year>
Reference-contexts: Here i is an atomic symbol from the set fdirective, commisive, permissive, prohibitive, assertiveg; and p is a logical formula. This much is quite standard even in the AI literature that deals with communication among agents <ref> [ Huhns et al., 1990; Thomas et al., 1990 ] </ref> . However, none of the AI papers so far give a rigorous formal semantics for messages of different illocutionary forces. This lacuna is filled by this paper.
References-found: 19

