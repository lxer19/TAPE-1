URL: ftp://ftp.cs.uu.nl/pub/RUU/CS/techreps/CS-1998/1998-02.ps.gz
Refering-URL: http://www.cs.ruu.nl/docs/research/publication/TechList1.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: niels@cs.ruu.nl  
Title: Predictive Probabilistic Models for Treatment Planning in Paediatric Cardiology  
Author: Niels PEEK 
Address: P.O. Box 80.089, 3508 TB Utrecht, The Netherlands  
Affiliation: Dept. of Computer Science, Utrecht University  
Abstract: The planning of clinical treatment actions for children with congenital heart disease requires a subtle trade-off between their immediate and long-term consequences, where most of these consequences cannot be predicted with certainty. It is described how this problem can be cast as a finite-horizon, partially observable Markov decision process. The complexity of the resulting model is reduced by using a graphical representation of state space and transition probabilities; it is shown that such a representation yields a significant decrease in the number of model parameters that have to be assessed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F.J. Macartney, </author> <title> D.J. Spiegelhalter, and M.L. Rigby, "Medical management", </title> <editor> in Paediatric Cardiology, R.H. Anderson, F.J. Macartney, E.A. Shinebourne, and M. Tynan, Eds., </editor> <volume> vol. 1, </volume> <pages> pp. 421-442. </pages> <address> Churchill Livingstone, Edinburgh, </address> <year> 1987. </year>
Reference-contexts: In the management of these patients, there is always a trade-off between the benefits gained by waiting before surgical intervention in the hope that the patient's condition will improve, and the risks caused by the poor natural history of these disorders <ref> [1] </ref>. The number of factors involved in this decision-making process is large and their interplay is subtle. Therefore, it is extremely difficult for the clinician to determine which timing of medical and surgical treatment will be optimal for a given patient. <p> Using this action, the clinician can make decisions at irregular time points (by skipping intermediate points) and `fill up' the remaining time when some satisfactory state is reached. The effects of actions are described by the set P = fp ff t : C X fi C X ! <ref> [0; 1] </ref> j t 2 T; ff Ag of time- and action-dependent transition probability functions, where p ff t (c post X j c pre X ) denotes the probability of arriving at state c post X after performing action set ff A in state c pre moment t. <p> An atemporal belief network for the VSD domain has recently been constructed with aid of a domain expert [14]; a simplified version of the network is shown is Fig. 1. For X = fX 1 ; : : : ; X m g, let s = ffl i <ref> [0; 1] </ref> j i = 1; : : : ; mg be the set of synchronic probability assessment functions associated with the belief network, where s (X i ) denotes the parent set of variable X i in the synchronic dependency graph; fl i s (c X i j c s <p> Furthermore, let t = ffl i t : C s (X i ) fi C t (X i ) fi 2 A i fi C X i ! <ref> [0; 1] </ref> j i = 1; : : : ; mg be the set of transition probability assessment functions associated with the complete graphical model at time t; fl i t (c post X i j c post s (X i ) ; c pre notes the probability of X i
Reference: [2] <author> K.J. Astrom, </author> <title> "Optimal control of Markov decision processes with incomplete state estimation", </title> <journal> Journal of Mathematical Analysis and Applications, </journal> <volume> vol. 10, </volume> <pages> pp. 174-205, </pages> <year> 1965. </year>
Reference-contexts: Therefore, it is extremely difficult for the clinician to determine which timing of medical and surgical treatment will be optimal for a given patient. In general terms, this problem may be characterised as prognostic assessment and planning under uncertainty with time constraints. Partially observable Markov decision processes (POMDPs) <ref> [2] </ref>, [3] are models for sequential decision making under uncertainty, taking into account both the outcomes of current decisions and future decision-making opportunities. <p> Furthermore, the decision maker receives an immediate reward reflecting the desirability of the new system state compared to other possible states. The goal is to optimise some function of the overall reward sequence that expresses the decision maker's intertemporal trade-offs. Partially observable Markov decision processes (POMDPs) <ref> [2] </ref> are a generalisation of Markov decision processes which permit uncertainty regarding the system state and allow for state information acquisition depending on action choice. Consequently, in POMDP problems the trade-off between actions does not only concern their immediate and long-term effects, but also their information-gathering properties. <p> A more promising approach is based on transforming the (finite-state) POMDP model to an equivalent MDP model in which system states are probability distributions on the state space of the original POMDP model <ref> [2] </ref>. When the state space in the original POMDP model contains n states, then the state space in the transformed MDP model is the (n 1)-dimensional unit simplex; transition probabilities are derived through Bayes' rule.
Reference: [3] <author> W.S. Lovejoy, </author> <title> "A survey of algorithmic methods for partially observed Markov decision processes", </title> <journal> Annals of Operations Research, </journal> <volume> vol. 28, </volume> <pages> pp. 47-66, </pages> <year> 1991. </year>
Reference-contexts: Therefore, it is extremely difficult for the clinician to determine which timing of medical and surgical treatment will be optimal for a given patient. In general terms, this problem may be characterised as prognostic assessment and planning under uncertainty with time constraints. Partially observable Markov decision processes (POMDPs) [2], <ref> [3] </ref> are models for sequential decision making under uncertainty, taking into account both the outcomes of current decisions and future decision-making opportunities. <p> Dynamic programming techniques can be applied to solve problems using the transformed MDP model, but because of the continuity of its state space, algorithms are complicated and limited. Solving POMDPs with a short, finite planning horizon is nevertheless feasible <ref> [3] </ref>. 4. GRAPHICAL REPRESENTATIONS OF POMDPS It was noted above that structured POMDP state spaces offer a number of advantages over flat state spaces. One of these advantages is that we can factorise the transition probability distributions describing the effects of actions.
Reference: [4] <author> C. Boutilier, T. Dean, and S. Hanks, </author> <title> "Planning under uncertainty: structural assumptions and computational leverage", in New Directions in AI Planning, </title> <editor> M. Ghallab and A. Milani, </editor> <booktitle> Eds., </booktitle> <pages> pp. 157-171. </pages> <publisher> IOS Press, </publisher> <address> Amsterdam, </address> <year> 1996. </year>
Reference-contexts: Markov decision processes are receiving increasing attention from the AI community, and have recently been proposed as a suitable framework for decision-theoretic planning <ref> [4] </ref>. However, the generality of the framework precludes straightforward application in practice, due to the representational and computational complexity of POMDP problems of considerable size. In this paper, we investigate the applicability of POMDPs to the problem of time-critical treatment planning and prognosis in the domain of paediatric cardiology. <p> Furthermore, we consider the graphical representation of POMDP models using temporal belief networks [5], [6]. These networks have previously been suggested as an adequate representation method for biomedical processes over time [7], [8], and, more recently, as a suitable means to reduce the representational complexity of POMDP models <ref> [4] </ref>. The case study reported in this paper provides evidence to support this claim. This paper is organised as follows. In Section 2, we discuss the problem of clinical treatment planning for children with a ventricular septal defect. Section 3 reviews Markov decision process models and associated solution techniques. <p> Consequently, the state space of the POMDP equals C X = C fX 1 g fi fi C fX m g . A state space thus char-acterised by multiple stochastic variables is sometimes called structured <ref> [4] </ref>. Structured state spaces offer several advantages over flat state spaces (where there is only a single state variable), the most prominent of which is the ability to exploit conditional independencies between the variables at hand; we will elaborate on this subject in Section 4. <p> These networks are generally referred to as temporal belief networks. Temporal belief networks have been suggested as a suitable way to express the dynamics of POMDP models <ref> [4] </ref>, equally facilitating the solution methods by exploiting independencies between state variables, and by making explicit persistence of states and ramification of action effects [5]. Now, let X (t) denote the set of state variables at time point t. A two-stage temporal belief network (2TBN) [4] is a belief network with <p> the dynamics of POMDP models <ref> [4] </ref>, equally facilitating the solution methods by exploiting independencies between state variables, and by making explicit persistence of states and ramification of action effects [5]. Now, let X (t) denote the set of state variables at time point t. A two-stage temporal belief network (2TBN) [4] is a belief network with two sets of variables X (t) and X (t + 1), where each arc is drawn either a variable from X (t) to a variable from X (t + 1), between two variables both from either X (t) or X (t + 1). <p> The complexity of POMDP models is known to hamper their application in practice, and probabilistic networks have been suggested in the literature as a suitable means to reduce that complexity <ref> [4] </ref>. However, both theoretical and practical investigations supporting this claim were lacking so far. In this paper, we have demonstrated that for practical problems a significant reduction in the number of model parameters can be obtained with this representation.
Reference: [5] <author> T. Dean and K. </author> <title> Kanazawa, "A model for reasoning about persistence and causation", </title> <journal> Computational Intelligence, </journal> <volume> vol. 5, </volume> <pages> pp. 142-150, </pages> <year> 1989. </year>
Reference-contexts: In this problem domain, truthful modelling of clinical treatment practice requires some adaptations to the general form of the POMDP model. Furthermore, we consider the graphical representation of POMDP models using temporal belief networks <ref> [5] </ref>, [6]. These networks have previously been suggested as an adequate representation method for biomedical processes over time [7], [8], and, more recently, as a suitable means to reduce the representational complexity of POMDP models [4]. The case study reported in this paper provides evidence to support this claim. <p> Bayesian belief networks [13] provide for a 3 concise, graphical representation of factorised joint prob-ability distributions. More recently, the belief network framework was extended to cope with dynamic stochastic systems <ref> [5] </ref>, [6], where the joint probability distribution on the variables in the network evolves over time. These networks are generally referred to as temporal belief networks. <p> Temporal belief networks have been suggested as a suitable way to express the dynamics of POMDP models [4], equally facilitating the solution methods by exploiting independencies between state variables, and by making explicit persistence of states and ramification of action effects <ref> [5] </ref>. Now, let X (t) denote the set of state variables at time point t.
Reference: [6] <author> P. Dagum and A. Galper, </author> <title> "Forecasting sleep apnea with dynamic network models", </title> <booktitle> in Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <year> 1993, </year> <pages> pp. 64-71. </pages>
Reference-contexts: In this problem domain, truthful modelling of clinical treatment practice requires some adaptations to the general form of the POMDP model. Furthermore, we consider the graphical representation of POMDP models using temporal belief networks [5], <ref> [6] </ref>. These networks have previously been suggested as an adequate representation method for biomedical processes over time [7], [8], and, more recently, as a suitable means to reduce the representational complexity of POMDP models [4]. The case study reported in this paper provides evidence to support this claim. <p> Bayesian belief networks [13] provide for a 3 concise, graphical representation of factorised joint prob-ability distributions. More recently, the belief network framework was extended to cope with dynamic stochastic systems [5], <ref> [6] </ref>, where the joint probability distribution on the variables in the network evolves over time. These networks are generally referred to as temporal belief networks.
Reference: [7] <author> S. Andreassen, R. Hovorka, J. Benn, K.G. Olesen, and E.R. Carson, </author> <title> "A model-based approach to insulin adjustment", </title> <booktitle> in Proceedings of the Third Conference on Artificial Intelligence in Medicine, </booktitle> <editor> M. Stefanelli, A. Hasman, M. Fieschi, and J. Talmon, Eds., </editor> <address> Berlin, </address> <year> 1991, </year> <title> vol. </title> <booktitle> 44 of Lecture Notes in Medical Informatics, </booktitle> <pages> pp. 239-248, </pages> <publisher> Springer Verlag. </publisher>
Reference-contexts: Furthermore, we consider the graphical representation of POMDP models using temporal belief networks [5], [6]. These networks have previously been suggested as an adequate representation method for biomedical processes over time <ref> [7] </ref>, [8], and, more recently, as a suitable means to reduce the representational complexity of POMDP models [4]. The case study reported in this paper provides evidence to support this claim. This paper is organised as follows.
Reference: [8] <author> C. Berzuini, R. Bellazzi, and D. Spiegelhalter, </author> <title> "Bayesian networks applied to therapy monitoring", </title> <booktitle> in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <year> 1991, </year> <pages> pp. 35-43. </pages>
Reference-contexts: Furthermore, we consider the graphical representation of POMDP models using temporal belief networks [5], [6]. These networks have previously been suggested as an adequate representation method for biomedical processes over time [7], <ref> [8] </ref>, and, more recently, as a suitable means to reduce the representational complexity of POMDP models [4]. The case study reported in this paper provides evidence to support this claim. This paper is organised as follows.
Reference: [9] <author> L. Kidd, D. Driscoll, and W. Gersony, </author> <title> "Second natural history study of congenital heart defects: results of treatment of patients with ventricular septal defects", </title> <journal> Circulation, </journal> <volume> vol. 87, </volume> <pages> pp. 138-151, </pages> <year> 1993. </year>
Reference-contexts: The clinical course is favourable with small defects To be presented at the Invited Session on Intelligent Prognostic Methods in Medical Diagnosis and Treatment Planning during Computational Engineering in Systems Applications (CESA'98), Nabeul-Hammamet, Tunisia, April 1998. throughout infancy and childhood <ref> [9] </ref>. About 75 to 80% of the defects close spontaneously due to tissue growth, with the majority closing in the first two years of life.
Reference: [10] <editor> T.P. Graham and H.P. Gutgesell, "Ventricular septal defects", </editor> <title> in Heart Disease in Infants, Children, </title> <booktitle> and Adolescents, </booktitle> <pages> pp. 724-746. </pages> <editor> Williams & Wilkins, </editor> <address> Baltimore, </address> <year> 1995. </year>
Reference-contexts: Patients with large defects are more difficult to manage, because of the risks of mortality in the first year of life due to heart failure and associated pulmonary infections. Furthermore, elevated pulmonary vascular resistance may develop over time as a response to continuous pulmonary overflow and hypertension <ref> [10] </ref>; this is termed Eisenmenger's complex. As a result, the shunt size will decrease and the symptoms of heart failure will vanish. However, Eisenmenger's complex eventually leads to cyanosis due to shunt reversal, and severe, irreversible damage to the pulmonary arteries (arteriopathy).
Reference: [11] <author> R.A. Howard, </author> <title> Dynamic Programming and Markov Processes, </title> <publisher> MIT Press, </publisher> <year> 1960. </year>
Reference-contexts: In cases of doubt concerning the clinical state of the patient, cardiac catheterisation or pulmonary biopsy may be performed prior to that decision. Therapy is considered completed after closure of the defect, either spontaneously or by surgical intervention. 3. MARKOV DECISION PROCESSES Markov decision processes (MDPs) <ref> [11] </ref>, [12] are models for sequential decision making under uncertainty, which take into account both immediate and long-term consequences of decisions. Basically, the theory assumes that a person, called the decision maker, is charged with the responsibility of choosing a sequence of actions in order to influence a stochastic process.
Reference: [12] <author> M.L. Puterman, </author> <title> Markov Decision Processes: Discrete Stochastic Dynamic Programming, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: In cases of doubt concerning the clinical state of the patient, cardiac catheterisation or pulmonary biopsy may be performed prior to that decision. Therapy is considered completed after closure of the defect, either spontaneously or by surgical intervention. 3. MARKOV DECISION PROCESSES Markov decision processes (MDPs) [11], <ref> [12] </ref> are models for sequential decision making under uncertainty, which take into account both immediate and long-term consequences of decisions. Basically, the theory assumes that a person, called the decision maker, is charged with the responsibility of choosing a sequence of actions in order to influence a stochastic process. <p> Generally speaking, the complexity of finding utility-maximising policies depends on the size of the state space, the number of available actions, and the horizon length. For finite-state (fully observable) MDP problems, efficient solution methods exist, based on the principle of dynamic programming <ref> [12] </ref>. Unfortunately, this does not hold for problems involving partial observability. Solving a POMDP problem directly necessitates keeping track of entire process histories, of which the sizes grow exponentially in the size of the state space and action sets.
Reference: [13] <author> J. Pearl, </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> Palo Alto, </address> <year> 1988. </year>
Reference-contexts: Factorisation of a joint probability distribution is based on conditional independence relations induced by the distri bution, and allows for a reduction in the required number of model parameters, and for more efficient probabilistic inferences. Bayesian belief networks <ref> [13] </ref> provide for a 3 concise, graphical representation of factorised joint prob-ability distributions. More recently, the belief network framework was extended to cope with dynamic stochastic systems [5], [6], where the joint probability distribution on the variables in the network evolves over time.
Reference: [14] <author> N.B. Peek and J. Ottenkamp, </author> <title> "Developing a decision-theoretic network for a congenital heart disease", </title> <booktitle> in AIME '97: Proceedings of the Sixth Conference on Artificial Intelligence in Medicine Europe, </booktitle> <editor> E. Keravnou, C. Garbay, R. Baud, and J. Wyatt, Eds. </editor> <year> 1997, </year> <pages> pp. 157-168, </pages> <publisher> Springer Verlag. </publisher> <pages> 6 </pages>
Reference-contexts: Synchronic belief network for the VSD domain. An atemporal belief network for the VSD domain has recently been constructed with aid of a domain expert <ref> [14] </ref>; a simplified version of the network is shown is Fig. 1.
References-found: 14

