URL: http://www.cs.gatech.edu/gvu/perception/pubs/PS/basu96a.ps.Z
Refering-URL: http://www.cs.gatech.edu/~irfan/publications/
Root-URL: 
Title: Motion Regularization for Model-based Head Tracking  
Author: Sumit Basu, Irfan Essa, Alex Pentland 
Keyword: Categories: Facial Expressions, Expression Recognition, Face Processing, Facial Analysis, Systems and Applications, Motion Analysis, Pattern Analysis, Vision-based HCI.  
Address: Cambridge, MA 02139, U.S.A.  
Affiliation: The Media Laboratory, Massachusetts Institute of Technology  
Pubnum: Perceptual Computing Section,  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 362 Submitted (Jan 1996): 13th Int'l. Conference on Pattern Recognition (ICPR '96), Vienna, Austria, August 25-30, 1996. Abstract This paper describes a method for the robust tracking of rigid head motion from video. This method uses a 3D ellipsoidal model of the head and interprets the optical flow in terms of the possible rigid motions of the model. This method is robust to large angular and translational motions of the head and is not subject to the singularities of a 2D model. The method has been successfully applied to heads with a variety of shapes, hair styles, etc. This method also has the advantage of accurately capturing the 3D motion parameters of the head. This accuracy is shown through comparison with a ground truth synthetic sequence (a rendered 3D animation of a model head). In addition, the ellipsoidal model is robust to small variations in the initial fit, enabling the automation of the model initialization. Lastly, due to its consideration of the entire 3D aspect of the head, the tracking is very stable over a large number of frames. This robustness extends even to sequences with very low frame rates and noisy camera images.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Adiv. </author> <title> Determining three-dimensional motion and structure from optical flow generated by several moving objects. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 4 </volume> <pages> 384-401, </pages> <year> 1985. </year>
Reference-contexts: Our experiments (shown below) demonstrate that this method can provide very robust tracking over hundreds of image frames for a very wide range of head motions. A good amount of previous work exists on the technique of flow regularization; Adiv <ref> [1] </ref> segmented flow into patches that were consistent with a single 3D motion. He then used the resulting clusters to estimate segmentation, structure (from the deviations in the parameters), and motion.
Reference: [2] <author> A. Azarbayejani, B. Horowitz, and A. Pentland. </author> <title> Recursive estimation of structure and motion using the relative orientation constraint. </title> <booktitle> In Proceedings of the Computer Vision and Pattern Recognition Conference, </booktitle> <year> 1993. </year> <title> 6 Frame 12 Frame 56 Frame 75 Frame 111 Frame 131 (a) Original Image Sequence [300 frames]. (b) Tracking using 2D planar model. (c) Tracking using 3D ellipsoidal model. ff fi fl planar model and (c) shows our 3D model for tracking. The plots show the comparision for the six parameters between model, 2D and 3D analysis. </title>
Reference-contexts: This, of course, limits the applicability of these methods. Consequently, research in head tracking has become an increasingly important topic. Perhaps the first paper that concentrated on this problem was by Azarbeyajani and Pent-land <ref> [2] </ref>, who presenting a recursive estimation method based on tracking of small facial features like the corners of the eyes or mouth. However its use of feature tracking limited its applicability to sequences in which the same points were visible over the entire image sequence.
Reference: [3] <author> J. R Bergen, P. Anandan, K. J. Hanna, and R. Hingorani. </author> <title> Hierarchical model-based motion estimation. </title> <booktitle> In Proceedings of European Conference on Computer Vision 1992, </booktitle> <pages> pages 239-252, </pages> <year> 1992. </year>
Reference-contexts: Bergen, Anandan, et al. <ref> [3] </ref> described a method for estimating model and motion parameters for several types of motion models. They used a direct estimation technique in their computation: instead of computing the unconstrained flow and then fitting it to a model, they used a series of models to constrain the flow computation.
Reference: [4] <author> D. Beymer and T. Poggio. </author> <title> Face recognition from one example view. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 500-507. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1995. </year>
Reference-contexts: However to date most research efforts have assumed that only very small head motions are present <ref> [4, 9, 10, 11, 12, 13, 15, 22, 23] </ref>. This, of course, limits the applicability of these methods. Consequently, research in head tracking has become an increasingly important topic.
Reference: [5] <author> M. J. Black and P. Anandan. </author> <title> The robust estimation of multiple motions: Affine and piecewise-smooth flow fields. </title> <type> Technical report, </type> <note> Xerox PARC, Dec. 1993. Tech. Report P93-00104. </note>
Reference-contexts: Sawhney et al. [20] used a model-based robust estimation technique to extract dominant motions from scenes. Black and Yacoob's Method [6] is based on Black and Anandan's <ref> [5] </ref> robust regression scheme over visual motion using a planar model, constraining the flow computation by an analytic eight parameter transform. Our work differs from this in that we use a full 3D rigid model.
Reference: [6] <author> M. J. Black and Y. Yacoob. </author> <title> Tracking and recognizing rigid and non-rigid facial motions using local parametric model of image motion. </title> <booktitle> In Proceedings of the International Conference 7 on Computer Vision, </booktitle> <pages> pages 374-381. </pages> <publisher> IEEE Computer Society, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: These template-based methods have had the limitations of requiring initial training or initialization, and are also limited in the range of head motions they can track. Most recently, Black and Yacoob <ref> [6] </ref> have developed a regularized optical-flow method that has yields surprisingly good results. In their method head motion is tracked by interpretation of optical flow in terms of a planar two-dimensional patch. Using this method they have been able to show stability over extended image sequences. <p> Sawhney et al. [20] used a model-based robust estimation technique to extract dominant motions from scenes. Black and Yacoob's Method <ref> [6] </ref> is based on Black and Anandan's [5] robust regression scheme over visual motion using a planar model, constraining the flow computation by an analytic eight parameter transform. Our work differs from this in that we use a full 3D rigid model.
Reference: [7] <author> T. Darrell, B. Moghaddam, and A. Pentland. </author> <title> Active face tracking and pose estimation in an interactive room. </title> <booktitle> Submitted to Computer Vision and Pattern Recognition Conference, </booktitle> <month> Nov </month> <year> 1995. </year>
Reference-contexts: However its use of feature tracking limited its applicability to sequences in which the same points were visible over the entire image sequence. Template-based methods have also been explored, such as the work of Darrell et al. <ref> [7, 8] </ref> or Saulnier et al. [19]. These template-based methods have had the limitations of requiring initial training or initialization, and are also limited in the range of head motions they can track.
Reference: [8] <author> I. Essa, T. Darrell, and A. Pentland. </author> <title> Tracking facial motion. </title> <booktitle> In Proceedings of the Workshop on Motion of Nonrigid and Articulated Objects, </booktitle> <pages> pages 36-42. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1994. </year>
Reference-contexts: However its use of feature tracking limited its applicability to sequences in which the same points were visible over the entire image sequence. Template-based methods have also been explored, such as the work of Darrell et al. <ref> [7, 8] </ref> or Saulnier et al. [19]. These template-based methods have had the limitations of requiring initial training or initialization, and are also limited in the range of head motions they can track.
Reference: [9] <author> I. Essa and A. Pentland. </author> <title> Facial expression recognition using a dynamic model and motion energy. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 360-367. </pages> <publisher> IEEE Computer Society, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: However to date most research efforts have assumed that only very small head motions are present <ref> [4, 9, 10, 11, 12, 13, 15, 22, 23] </ref>. This, of course, limits the applicability of these methods. Consequently, research in head tracking has become an increasingly important topic.
Reference: [10] <author> A. Lantis, C. J. Taylor, and T. F. Cootes. </author> <title> A unified approach to coding and interpreting face images. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 369-373. </pages> <publisher> IEEE Computer Society, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: However to date most research efforts have assumed that only very small head motions are present <ref> [4, 9, 10, 11, 12, 13, 15, 22, 23] </ref>. This, of course, limits the applicability of these methods. Consequently, research in head tracking has become an increasingly important topic.
Reference: [11] <author> H. Li, P. Roivainen, and R. Forchheimer. </author> <title> 3-d motion estimation in model-based facial image coding. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 15(6) </volume> <pages> 545-555, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: However to date most research efforts have assumed that only very small head motions are present <ref> [4, 9, 10, 11, 12, 13, 15, 22, 23] </ref>. This, of course, limits the applicability of these methods. Consequently, research in head tracking has become an increasingly important topic.
Reference: [12] <author> K. Mase. </author> <title> Recognition of facial expressions for optical flow. </title> <journal> IEICE Transactions, Special Issue on Computer Vision and its Applications, </journal> <volume> E 74(10), </volume> <year> 1991. </year>
Reference-contexts: However to date most research efforts have assumed that only very small head motions are present <ref> [4, 9, 10, 11, 12, 13, 15, 22, 23] </ref>. This, of course, limits the applicability of these methods. Consequently, research in head tracking has become an increasingly important topic.
Reference: [13] <author> K. Matsuno, C-W. Lee, S. Kimura, and S. Tsuji. </author> <title> Automatic recognition of human facial expressions. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 352-359. </pages> <publisher> IEEE Computer Society, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: However to date most research efforts have assumed that only very small head motions are present <ref> [4, 9, 10, 11, 12, 13, 15, 22, 23] </ref>. This, of course, limits the applicability of these methods. Consequently, research in head tracking has become an increasingly important topic.
Reference: [14] <author> B. Moghaddam and A. Pentland. </author> <title> Probabistic visual learning for object detection. </title> <booktitle> In Proceedings of the International Conference on Computer Vision. IEEE Computer Society, </booktitle> <year> 1995. </year>
Reference-contexts: The current normal vectors can be similarly found with N = T R N o , where T R is the 3x3 (pure rotational) transform contained in the first three rows and columns of T. 2 (a) (b) (c) eigenspace head and feature detection system <ref> [14, 17] </ref>. The bottom row shows the coarse estimate of the ellipsoidal model on basis of this data. <p> In addition, the axes of the ellipsoid could be adjusted to obtain x r ; y r ; and z r . However, since our goals required the ability to find and track people automatically, we incorporated the modular eigenspace face and feature detection work of Moghaddam and Pentland <ref> [14, 17] </ref> in order to parameterize and fit this ellipsoid automatically. This system finds the location of the head itself and the locations of the eye, nose, and mouth within the head.
Reference: [15] <author> Y. Moses, D. Reynard, and A. Blake. </author> <title> Determining facial expressions in real time. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 296-301. </pages> <publisher> IEEE Computer Society, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: However to date most research efforts have assumed that only very small head motions are present <ref> [4, 9, 10, 11, 12, 13, 15, 22, 23] </ref>. This, of course, limits the applicability of these methods. Consequently, research in head tracking has become an increasingly important topic.
Reference: [16] <author> A. Pentland and B. Horowitz. </author> <title> Recovery of nonrigid motion and structure. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 13(7) </volume> <pages> 730-742, </pages> <month> July 1r991. </month>
Reference-contexts: The unconstrained optical flow is first computed for the entire sequence, and the rigid motion of the 3D head model that best accounts for the observed flow is interpreted as the motion of the head. This is much in the style of Horowitz and Pentland <ref> [16] </ref>. The model's 3D location and rotation is then modified by these parameters, and used as the starting point for interpreting the next frame, and so on. The details of this method will be described in the section 3 below. <p> Our work differs from this in that we use a full 3D rigid model. Several attempts at tracking of rigid and nonrigid motion using complex 3D models has proved to be quite successful <ref> [16, 21] </ref>. Our method is primarily motivated by these efforts, except that we are incorporating robust estimation techniques to extract large three-dimensional motions.
Reference: [17] <author> A. Pentland, B. Moghaddam, and T. Starner. </author> <title> View-based and modular eigenspaces for face recognition. </title> <booktitle> In Computer Vision and Pattern Recognition Conference, </booktitle> <pages> pages 84-91. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1994. </year>
Reference-contexts: The current normal vectors can be similarly found with N = T R N o , where T R is the 3x3 (pure rotational) transform contained in the first three rows and columns of T. 2 (a) (b) (c) eigenspace head and feature detection system <ref> [14, 17] </ref>. The bottom row shows the coarse estimate of the ellipsoidal model on basis of this data. <p> In addition, the axes of the ellipsoid could be adjusted to obtain x r ; y r ; and z r . However, since our goals required the ability to find and track people automatically, we incorporated the modular eigenspace face and feature detection work of Moghaddam and Pentland <ref> [14, 17] </ref> in order to parameterize and fit this ellipsoid automatically. This system finds the location of the head itself and the locations of the eye, nose, and mouth within the head.
Reference: [18] <author> William H. Press, Brian P. Flannery, Saul A. Teukoisky, and William T. Vetterling. </author> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: This minimum is found by using the simplex gradient descent technique (implemented as described by <ref> [18] </ref>) with the error function E defined above, and a starting point of a i (i.e., the current parameters). 4 Experiments & Results Tracking To demonstrate the tracking performance of this system we have presented several example sequences in the figures below.
Reference: [19] <author> A. Saulnier, M. L. Viaud, and D. Geldreich. </author> <title> Real-time facial analysis and synthesis chain. </title> <booktitle> In International Workshop on Automatic Face and Gesture Recogntion, </booktitle> <pages> pages 86-91, </pages> <address> Zurich, Switzerland, </address> <year> 1995. </year> <editor> Editor, M. </editor> <publisher> Bichsel. </publisher>
Reference-contexts: However its use of feature tracking limited its applicability to sequences in which the same points were visible over the entire image sequence. Template-based methods have also been explored, such as the work of Darrell et al. [7, 8] or Saulnier et al. <ref> [19] </ref>. These template-based methods have had the limitations of requiring initial training or initialization, and are also limited in the range of head motions they can track. Most recently, Black and Yacoob [6] have developed a regularized optical-flow method that has yields surprisingly good results.
Reference: [20] <author> H. S. Sawhney, S. Ayer, and M. Gorkani. </author> <title> Model-based 2d&3d dominant motion estimation for mosaicing and video representation. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 583-590. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1995. </year>
Reference-contexts: They used a direct estimation technique in their computation: instead of computing the unconstrained flow and then fitting it to a model, they used a series of models to constrain the flow computation. Sawhney et al. <ref> [20] </ref> used a model-based robust estimation technique to extract dominant motions from scenes. Black and Yacoob's Method [6] is based on Black and Anandan's [5] robust regression scheme over visual motion using a planar model, constraining the flow computation by an analytic eight parameter transform.
Reference: [21] <author> D. Terzopoulos and D. Metaxas. </author> <title> Dynamic 3d models with local and global deformations: Deformable superquadrics. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 13(7) </volume> <pages> 703-714, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Our work differs from this in that we use a full 3D rigid model. Several attempts at tracking of rigid and nonrigid motion using complex 3D models has proved to be quite successful <ref> [16, 21] </ref>. Our method is primarily motivated by these efforts, except that we are incorporating robust estimation techniques to extract large three-dimensional motions.
Reference: [22] <author> D. Terzopoulus and K. Waters. </author> <title> Analysis and synthesis of facial image sequences using physical and anatomical models. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 15(6) </volume> <pages> 569-579, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: However to date most research efforts have assumed that only very small head motions are present <ref> [4, 9, 10, 11, 12, 13, 15, 22, 23] </ref>. This, of course, limits the applicability of these methods. Consequently, research in head tracking has become an increasingly important topic.
Reference: [23] <author> Y. Yacoob and L. Davis. </author> <title> Computing spatio-temporal representations of human faces. </title> <booktitle> In Proceedings of the Computer Vision and Pattern Recognition Conference, </booktitle> <pages> pages 70-75. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1994. </year> <month> 8 </month>
Reference-contexts: However to date most research efforts have assumed that only very small head motions are present <ref> [4, 9, 10, 11, 12, 13, 15, 22, 23] </ref>. This, of course, limits the applicability of these methods. Consequently, research in head tracking has become an increasingly important topic.
References-found: 23

