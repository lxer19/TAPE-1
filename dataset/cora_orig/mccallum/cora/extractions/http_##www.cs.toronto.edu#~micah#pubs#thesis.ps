URL: http://www.cs.toronto.edu/~micah/pubs/thesis.ps
Refering-URL: http://www.cs.toronto.edu/~micah/
Root-URL: http://www.cs.toronto.edu
Title: Limited Bandwidth Parallel Computation  
Author: by Micah Alexei Adler 
Degree: 1990 A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Computer Science in the GRADUATE DIVISION of the UNIVERSITY of CALIFORNIA at BERKELEY Committee in charge: Professor Michael Luby, Chair Professor Richard Karp Professor Sheldon Ross  
Date: 1996  
Affiliation: B.S. Massachusetts Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [ABK95] <author> M. Adler, J. Byers and R. Karp. </author> <title> Parallel Sorting with Limited Bandwidth. </title> <booktitle> In Proceedings 7th ACM Symposium on Parallel Algorithms and Architectures: </booktitle> <pages> pp. 129 - 136, </pages> <year> 1995. </year>
Reference-contexts: The lower bounds provide convincing evidence that efficient parallel algorithms for sorting rely strongly on high communication throughput. This chapter is joint work with John Byers and Richard Karp, and appeared in a preliminary version in <ref> [ABK95] </ref>. In Chapter 3, we introduce a novel coding technique for transmitting the XOR of carefully selected patterns of bits to be communicated which greatly reduces bandwidth requirements in some settings. <p> Their algorithms run in time O ( n log n P +gp * + gn with high probability, for any positive constant * &lt; 1, and for P n 1ffi , where ffi is a small constant depending on *. After the preliminary version of this paper appeared in <ref> [ABK95] </ref>, work on this problem by Goodrich [Goo96] has tightened the bounds for sorting on the BSP, giving deterministic algorithms which run in time O ( n log n P + (L + gn P )(log n= log (n=P ))) for all values of P , coupled with a matching lower
Reference: [ACS87] <author> A. Aggarwal, A. Chandra and M. Snir. </author> <title> Hierarchical Memory with Block Transfer. </title> <booktitle> In Proceedings 28 th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 204-216, </pages> <year> 1987. </year>
Reference: [ACS89] <author> A. Aggarwal, A. Chandra and M. Snir. </author> <title> On Communication Latency in PRAM Computations. </title> <booktitle> In Proceedings 1st ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1989. </year>
Reference: [ACS90] <author> A. Aggarwal, A. Chandra, and M. Snir. </author> <title> Communication Complexity of PRAMs. </title> <booktitle> Theoretical Computer Science 71: </booktitle> <pages> pp 3-28, </pages> <year> 1990. </year>
Reference: [Adl96a] <author> M. Adler. </author> <title> Asynchronous Shared Memory Search Structures. </title> <booktitle> In Proceedings 8th ACM Symposium on Parallel Algorithms and Architectures: </booktitle> <pages> pp. 42 - 51, </pages> <year> 1996. </year>
Reference-contexts: This chapter appeared in a preliminary version in <ref> [Adl96a] </ref>. 1.4 Previous Work Although we describe previous work in context throughout this thesis, we here briefly mention some previous results that imply differences between the models described.
Reference: [Adl96b] <author> M. Adler. </author> <title> New Coding Techniques for Improved Bandwidth Utilization. </title> <booktitle> In Proceedings 37 th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. </pages> , <year> 1996. </year>
Reference-contexts: The coding technique also has broader applications. For example, we demonstrate a surprising application to a simple I/O (Input / Output) complexity problem related to finding the transpose of a matrix. This chapter appeared in a preliminary version in <ref> [Adl96b] </ref>. In Chapter 4, we study the problem of storing elements from an ordered set on an asynchronous shared memory parallel computer, represented by the asynchronous QRQW PRAM.
Reference: [AHU74] <author> A. Aho, J. Hopcroft, and J. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley: </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference-contexts: Provided that no 2-3 Tree contains more than O (log n) nodes, this can be done using O (log log n) memory accesses (see <ref> [AHU74] </ref> pp. 155-157). Before unlocking the old 2-3 Tree, a marker is added to that 2-3 Tree that indicates the range of keys that have been moved to the new 2-3 Tree.
Reference: [Ajt88] <author> A. Ajtai. </author> <title> A Lower Bound for Finding Predecessors in Yao's Cell Probe Model. </title> <type> Combinatorica 8 (3) 235 - 247, </type> <year> 1988. </year> <month> 92 </month>
Reference: [AKS83] <author> M. Ajtai, J. Komlos and E. Szemeredi. </author> <title> An O(n log n) Sorting Network. </title> <journal> Combinatorica 3: pp. </journal> <volume> 1 - 19, </volume> <year> 1983. </year>
Reference: [AV88] <author> A. Aggarwal and J. Vitter. </author> <title> The Input/Output Complexity of Sorting and Related Problems. </title> <journal> Communications of the ACM, </journal> <pages> pp 116-127, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: We start by describing an application of the new coding technique to a simplified version of Aggarwal and Vitter's external memory model <ref> [AV88] </ref>. This application serves as a simple introduction to the new coding technique, and highlights the technique's power. The external memory model represents a computer with a small internal memory, and a larger, but much slower external memory. <p> A natural assumption about the additional external memory is that it can only be used to store duplicate entries of the original matrix. For example, this assumption has been used either explicitly or implicitly for I/O complexity lower bounds in [Flo72], <ref> [AV88] </ref>, [CGG+95], and others. Using this assumption, we give the following easy lower bound for this problem. Let M (n) be the set of entries of the matrix that are stored in the additional external memory.
Reference: [Aza92] <author> Y. Azar. </author> <title> Lower Bounds for Threshold and Symmetric Functions in Parallel Computation. </title> <journal> SIAM J. of Computing, </journal> <volume> 21(2): </volume> <pages> pp. 329 - 338, </pages> <year> 1992. </year>
Reference-contexts: Some asynchronous algorithms for the QRQW have already been given in [GMR96a]. 5 shared memory cellsM processorsP N input size 1.1.2 The PRAM (m) Model The PRAM (m) model is introduced in [MNV94], and is based on a similar previous model studied in [VW85], [LY86], and <ref> [Aza92] </ref>. In this PRAM model, communication is restricted by requiring that processors communicate only through m shared memory cells.
Reference: [BC82] <author> A. Borodin and S. Cook. </author> <title> A Time-Space Tradeoff for Sorting on a General Sequential Model of Computation. </title> <journal> SIAM J. of Computing, </journal> <volume> 11(2): </volume> <pages> pp. 287 - 297, </pages> <year> 1982. </year>
Reference: [BGMZ95] <author> G. Blelloch, P. Gibbons, Y. Matias and M. Zagha. </author> <title> Accounting for Memory Bank Contention and Delay in High-Bandwidth Multiprocessors. </title> <booktitle> In Proceedings 7th ACM Symposium on Parallel Algorithms and Architectures: </booktitle> <pages> pp. 84 - 93, </pages> <year> 1995. </year>
Reference: [BS77] <author> R. Bayer and M. Schkolnick. </author> <title> Concurrency of Operations on B-Trees. </title> <journal> Acta Informatica 9 </journal> <pages> 1-22, </pages> <year> 1977. </year>
Reference-contexts: There is a large body of previous work which has focused on reducing the number of locks necessary, including <ref> [BS77] </ref>, [Ell80], [LY81], [Sag86]. The culmination of these efforts is the B-Link tree, a strongly independent search structure which allows inserts to lock no more than one node at any time, and deletes to lock only a small constant number at any step.
Reference: [CD82] <author> S. Cook, C. Dwork and R. Reischuk. </author> <title> Upper and Lower Bounds for Parallel Random Access Machines Without Simultaneous Writes. </title> <journal> SIAM J. of Computing 15: </journal> <pages> pp. 87-97, </pages> <year> 1985. </year>
Reference: [CGG+95] <author> Y. Chiang, M. Goodrich, E. Grove, R. Tamassia, D. Vengroff and J. Vitter. </author> <title> External-Memory Graph Algorithms. </title> <booktitle> In Proceedings 6th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pp. 139 - 149, </pages> <year> 1995. </year>
Reference-contexts: A natural assumption about the additional external memory is that it can only be used to store duplicate entries of the original matrix. For example, this assumption has been used either explicitly or implicitly for I/O complexity lower bounds in [Flo72], [AV88], <ref> [CGG+95] </ref>, and others. Using this assumption, we give the following easy lower bound for this problem. Let M (n) be the set of entries of the matrix that are stored in the additional external memory.
Reference: [CKP+93] <author> D. Culler, R. M. Karp, D. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subra-monian and T. von Eicken. </author> <title> LogP: Towards a Realistic Model of Parallel Computation. </title> <booktitle> In Proceedings 4th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pp. 1-12, </pages> <month> January </month> <year> 1993. </year> <note> Also in Communications of the ACM, </note> <editor> 39(11):pp. </editor> <volume> 78 - 85, </volume> <month> November </month> <year> 1996. </year> <month> 93 </month>
Reference-contexts: Since most parallel machines built today do have much less communication throughput available than the number of processors [MNV94], parallel models have evolved to more accurately reflect the construction of real machines. These new models include the BSP model [Val90a], the LogP model <ref> [CKP+93] </ref>, and one of the main tools used in this thesis, the PRAM (m) model [MNV94], where p processors communicate only through a read/write shared memory of size m, m o p. The shared memory of size m models a communication throughput of m per time step. <p> We give a brief discussion of the complexity of sorting in the LogP model <ref> [CKP+93] </ref> and the BSP model [Val90a]. 2.5.1 The LogP model In the LogP model, limited communication communication throughput in a parallel machine is enforced by requiring that each processor must wait for a gap of at least g cycles between the transmission of consecutive point-to-point messages. <p> This approach 64 was introduced in [Gib89] and has since been used in the analysis of other models, for example the LogP model <ref> [CKP+93] </ref>. We take the same approach here. Thus, to analyze performance, we assume that at every time step, every processor performs one operation. Memory accesses are queued according to the asynchronous QRQW rule.
Reference: [Col88] <author> R. Cole. </author> <title> Parallel Merge Sort. </title> <journal> SIAM Journal of Computing, </journal> <volume> 17(4): </volume> <pages> pp. 770 - 785, </pages> <year> 1988. </year>
Reference-contexts: On the other hand, the lower bound of [MNV94] for sorting on the CR PRAM (m) of ( n p mp ) can be outperformed using Cole's Parallel Mergesort <ref> [Col88] </ref> on the QRQW PRAM. Therefore, the CR PRAM (m) is incomparable to the QRQW PRAM. <p> An easy upper bound can be obtained by using a variant of Cole's parallel merge sort <ref> [Col88] </ref> for the PRAM, which uses O (n log n) bits of memory and runs in O (log n) time.
Reference: [CS92] <author> R. Cypher and J. Sanz. Cubesort: </author> <title> A Parallel Algorithm for Sorting N Data Items with S-Sorters. </title> <journal> Journal of Algorithms 13: </journal> <pages> pp. 211-234, </pages> <year> 1992. </year>
Reference-contexts: Thus, the ratio between upper and lower bounds for sorting on the ER PRAM (m) was fi ( p p m log 2 n) prior to this work. Related work on upper bounds includes <ref> [CS92] </ref>, in which Cypher and Sanz allude to a recursive version of Columnsort, and introduce Cubesort, which can be used to obtain a running time of O ( n log n m (1 fi) 2 )25 log fl nlog fl (n=m) for sorting on the PRAM (m).
Reference: [CZ89] <author> R. Cole and O. Zajicek. </author> <title> The APRAM: Incorporating Asynchrony into the PRAM Model. </title> <booktitle> In Proceedings 1 st ACM Symposium on Parallel Algorithms and Architectures pp. </booktitle> <pages> 169-178, </pages> <year> 1989. </year>
Reference-contexts: Processors behave asynchronously, and this can be modeled in several different ways: <ref> [CZ89] </ref>, [CZ90], [Nis90]. Examples of asynchronous machines that conform well to the QRQW rule are the Kendall Square KSR-1, the Tera Computer, and the Stanford DASH [GMR94a].
Reference: [CZ90] <author> R. Cole and O. Zajicek. </author> <title> The Expected Advantage of Asynchrony. </title> <booktitle> In Proceedings 2 nd ACM Symposium on Parallel Algorithms and Architectures pp. </booktitle> <pages> 85-94, </pages> <year> 1990. </year>
Reference-contexts: Processors behave asynchronously, and this can be modeled in several different ways: [CZ89], <ref> [CZ90] </ref>, [Nis90]. Examples of asynchronous machines that conform well to the QRQW rule are the Kendall Square KSR-1, the Tera Computer, and the Stanford DASH [GMR94a].
Reference: [Dus94] <author> A. Dusseau. </author> <title> Modeling Parallel Sorts with LogP on the CM-5. </title> <type> Technical Report: </type> <institution> UCB/CSD-94-829, </institution> <month> May </month> <year> 1994. </year>
Reference: [Ell80] <author> C. Ellis. </author> <title> Concurrent Search and Inserts in 2-3 Trees. </title> <journal> Acta Informatica 14(1): </journal> <pages> pp. 63-86, </pages> <year> 1980. </year>
Reference-contexts: There is a large body of previous work which has focused on reducing the number of locks necessary, including [BS77], <ref> [Ell80] </ref>, [LY81], [Sag86]. The culmination of these efforts is the B-Link tree, a strongly independent search structure which allows inserts to lock no more than one node at any time, and deletes to lock only a small constant number at any step.
Reference: [Flo72] <author> R. Floyd. </author> <title> Permuting Information in Idealized Two-Level Storage. Complexity of Computer Calculations, </title> <editor> R. Miller and J. Thatcher, ed., </editor> <publisher> Plenum, </publisher> <pages> pp. 105 - 109, </pages> <year> 1972. </year>
Reference-contexts: A natural assumption about the additional external memory is that it can only be used to store duplicate entries of the original matrix. For example, this assumption has been used either explicitly or implicitly for I/O complexity lower bounds in <ref> [Flo72] </ref>, [AV88], [CGG+95], and others. Using this assumption, we give the following easy lower bound for this problem. Let M (n) be the set of entries of the matrix that are stored in the additional external memory.
Reference: [FW78] <author> S. Fortune and J. Wyllie. </author> <title> Parallelism in Random Access Machines. </title> <booktitle> In Proceedings 10th ACM Symposium on Theory of Computing: </booktitle> <pages> pp. 114 - 118, </pages> <year> 1978. </year>
Reference-contexts: Introduction The Parallel Random Access Memory (PRAM) model is a well established and well studied model for determining the inherent parallelism of computational problems (see for example [KR90], [JaJ92], [Rei93]). The original PRAM model of Fortune and Wylie <ref> [FW78] </ref> would today be referred to as a CREW (concurrent read, exclusive write) PRAM. In this model, an unlimited number of processors can read any given shared memory location during a step of computation with no penalty.
Reference: [Gib89] <author> P. Gibbons. </author> <title> A More Practical PRAM Model. </title> <booktitle> In Proceedings 1st ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 158 - 168, </pages> <year> 1989. </year>
Reference-contexts: This approach 64 was introduced in <ref> [Gib89] </ref> and has since been used in the analysis of other models, for example the LogP model [CKP+93]. We take the same approach here. Thus, to analyze performance, we assume that at every time step, every processor performs one operation. Memory accesses are queued according to the asynchronous QRQW rule.
Reference: [Gib96] <author> P. Gibbons. </author> <title> What Good Are Shared-Memory Models? In Proceedings 1996 ICPP Workshop on Challenges for Parallel Processing, </title> <journal> pp. </journal> <pages> 103-114, </pages> <year> 1996. </year>
Reference: [GMR94a] <author> P. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> The QRQW PRAM: Accounting for Contention in Parallel Algorithms. </title> <booktitle> In Proceedings 5th ACM SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pp. 638-648, </pages> <year> 1994. </year> <note> Also to appear in SIAM Journal on Computing, 1997. 94 </note>
Reference-contexts: In other words, this is a measure of the bandwidth available between the processors and a given memory location. Results by Snir [Sni85] demonstrate that this measure has a significant impact on the power of a parallel machine. Recently, Gibbons, Matias and Ramachandran <ref> [GMR94a] </ref>, [GMR94b] have inspired a re 2 examination of the effects of concurrency on parallel computation. They point out that the EREW PRAM is too restrictive: on most real machines processors can attempt to access memory locations simultaneously, but such steps do require more time. <p> The QRQW gives us a tool for obtaining a more realistic view of the effects of concurrency. Many computational problems need to be studied in this new framework, and this effort has been started in <ref> [GMR94a] </ref> and [GMR94b]. However, none of the PRAM models described above address another measure of bandwidth: communication throughput, or the maximum sustainable aggregate number of communication bits per clock cycle that can be accessed by the processors. <p> Examples of asynchronous machines that conform well to the QRQW rule include the Kendall Square KSR-1, the Tera Computer, and the Stanford DASH <ref> [GMR94a] </ref>. The potential impact of the QRQW PRAM on our knowledge of the effect of concurrency is particularly significant in the study of asynchronous algorithms. <p> We note that both queued contention resolution strategies are analogous to those devised for the standard QRQW PRAM <ref> [GMR94a] </ref>, [GMR94b]. 7 1.2 Questions to Address In order to understand the interaction between communication throughput and concur-rency, we ask the following. <p> However, although some of these designs have been shown to perform well in simulations, none have been analyzed in any parallel machine model. 60 4.1.2 New Techniques We use the QRQW PRAM (Queued Read, Queued Write) model <ref> [GMR94a] </ref>, [GMR94b], a recent advance in the modeling of shared memory parallel computation, to develop a framework for evaluating the performance of strongly independent concurrent search structures. <p> Processors behave asynchronously, and this can be modeled in several different ways: [CZ89], [CZ90], [Nis90]. Examples of asynchronous machines that conform well to the QRQW rule are the Kendall Square KSR-1, the Tera Computer, and the Stanford DASH <ref> [GMR94a] </ref>. <p> We take the same approach here. Thus, to analyze performance, we assume that at every time step, every processor performs one operation. Memory accesses are queued according to the asynchronous QRQW rule. When more than one request arrives simultaneously to a location, the asynchronous QRQW model of <ref> [GMR94a] </ref> assumes that these ties are resolved arbitrarily: i.e. the analysis is valid no matter how ties are resolved. Our results for the continuous case all hold for this pessimistic assumption. For the fixed case, however, we need something slightly stronger.
Reference: [GMR94b] <author> P. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> Efficient Low-Contention Parallel Algorithms. </title> <booktitle> In Proceedings 6th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 236 - 247, </pages> <year> 1994. </year> <note> Also to appear in Journal of Computer and System Sciences, </note> <year> 1997. </year>
Reference-contexts: In other words, this is a measure of the bandwidth available between the processors and a given memory location. Results by Snir [Sni85] demonstrate that this measure has a significant impact on the power of a parallel machine. Recently, Gibbons, Matias and Ramachandran [GMR94a], <ref> [GMR94b] </ref> have inspired a re 2 examination of the effects of concurrency on parallel computation. They point out that the EREW PRAM is too restrictive: on most real machines processors can attempt to access memory locations simultaneously, but such steps do require more time. <p> The QRQW gives us a tool for obtaining a more realistic view of the effects of concurrency. Many computational problems need to be studied in this new framework, and this effort has been started in [GMR94a] and <ref> [GMR94b] </ref>. However, none of the PRAM models described above address another measure of bandwidth: communication throughput, or the maximum sustainable aggregate number of communication bits per clock cycle that can be accessed by the processors. <p> We note that both queued contention resolution strategies are analogous to those devised for the standard QRQW PRAM [GMR94a], <ref> [GMR94b] </ref>. 7 1.2 Questions to Address In order to understand the interaction between communication throughput and concur-rency, we ask the following. <p> When the processors do not know which subset of processors are performing searches, or when some processor may experience long delays due to the system being asynchronous, this phase can be expensive. A strongly independent search structure called the Binary Search Fat Tree is introduced in <ref> [GMR94b] </ref>. This structure performs quite well in the case where the keys that processors search 59 for are chosen independently and uniformly at random from the set of keys that are stored. <p> However, although some of these designs have been shown to perform well in simulations, none have been analyzed in any parallel machine model. 60 4.1.2 New Techniques We use the QRQW PRAM (Queued Read, Queued Write) model [GMR94a], <ref> [GMR94b] </ref>, a recent advance in the modeling of shared memory parallel computation, to develop a framework for evaluating the performance of strongly independent concurrent search structures.
Reference: [GMR96a] <author> P. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> The Queue-Read Queue-Write Asynchronous PRAM Model. </title> <booktitle> In Proceedings 2nd International Euro-Par Conference pp. </booktitle> <pages> 279-292, </pages> <year> 1996. </year>
Reference-contexts: The potential impact of the QRQW PRAM on our knowledge of the effect of concurrency is particularly significant in the study of asynchronous algorithms. As pointed out in <ref> [GMR96a] </ref>, asynchronous versions of the EREW PRAM have never been examined, since when processors behave asynchronously, a great deal of overhead is required to ensure that no two processors ever access the same location simultaneously. <p> The asynchronous version of the QRQW PRAM, on the other hand, does not have this problem, and thus opens an interesting field of study, especially in light of the fact that many real machines are in fact asynchronous. Some asynchronous algorithms for the QRQW have already been given in <ref> [GMR96a] </ref>. 5 shared memory cellsM processorsP N input size 1.1.2 The PRAM (m) Model The PRAM (m) model is introduced in [MNV94], and is based on a similar previous model studied in [VW85], [LY86], and [Aza92]. <p> Processors behave asynchronously, and this can be modeled in several different ways: [CZ89], [CZ90], [Nis90]. Examples of asynchronous machines that conform well to the QRQW rule are the Kendall Square KSR-1, the Tera Computer, and the Stanford DASH [GMR94a]. Much of the existing analysis of asynchronous QRQW algorithms <ref> [GMR96a] </ref> has taken the following approach: the algorithm must work correctly for all possible interleavings of the instructions, but when analyzing the performance of the algorithms, it is assumed that the there are no delays between the steps, i.e. that each individual processor behaves synchronously.
Reference: [GMR96a] <author> P. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> The Queueing Shared Memory Model. </title> <type> Manuscript, </type> <year> 1996. </year>
Reference-contexts: The potential impact of the QRQW PRAM on our knowledge of the effect of concurrency is particularly significant in the study of asynchronous algorithms. As pointed out in <ref> [GMR96a] </ref>, asynchronous versions of the EREW PRAM have never been examined, since when processors behave asynchronously, a great deal of overhead is required to ensure that no two processors ever access the same location simultaneously. <p> The asynchronous version of the QRQW PRAM, on the other hand, does not have this problem, and thus opens an interesting field of study, especially in light of the fact that many real machines are in fact asynchronous. Some asynchronous algorithms for the QRQW have already been given in <ref> [GMR96a] </ref>. 5 shared memory cellsM processorsP N input size 1.1.2 The PRAM (m) Model The PRAM (m) model is introduced in [MNV94], and is based on a similar previous model studied in [VW85], [LY86], and [Aza92]. <p> Processors behave asynchronously, and this can be modeled in several different ways: [CZ89], [CZ90], [Nis90]. Examples of asynchronous machines that conform well to the QRQW rule are the Kendall Square KSR-1, the Tera Computer, and the Stanford DASH [GMR94a]. Much of the existing analysis of asynchronous QRQW algorithms <ref> [GMR96a] </ref> has taken the following approach: the algorithm must work correctly for all possible interleavings of the instructions, but when analyzing the performance of the algorithms, it is assumed that the there are no delays between the steps, i.e. that each individual processor behaves synchronously.
Reference: [Goo96] <author> M. Goodrich. </author> <title> Communication-Efficient Parallel Sorting. </title> <booktitle> In Proceedings of the 28 th Annual ACM Symposium on Theory of Computing: </booktitle> <pages> pp. 247 - 256, </pages> <year> 1996. </year>
Reference-contexts: Finally, with respect to BSP algorithms for sorting, Gerbessiotis and Valiant [GV94] introduce a randomized algorithm for parallel sorting in the BSP model. Also, subsequent to an earlier version of this chapter, the upper bound for sorting in the BSP model has been improved 15 by Goodrich <ref> [Goo96] </ref>, as well as by Gerbessiotis and Siniolakis [GS96]. <p> After the preliminary version of this paper appeared in [ABK95], work on this problem by Goodrich <ref> [Goo96] </ref> has tightened the bounds for sorting on the BSP, giving deterministic algorithms which run in time O ( n log n P + (L + gn P )(log n= log (n=P ))) for all values of P , coupled with a matching lower bound.
Reference: [GS96] <author> A. Gerbessiotis and C. Siniolakis. </author> <title> Deterministic Sorting and Randomized Median Finding on the BSP Model. </title> <booktitle> In Proceedings 8th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. </pages> <year> 1996. </year>
Reference-contexts: Also, subsequent to an earlier version of this chapter, the upper bound for sorting in the BSP model has been improved 15 by Goodrich [Goo96], as well as by Gerbessiotis and Siniolakis <ref> [GS96] </ref>. <p> Other recent work by Gerbessiotis and Siniolakis <ref> [GS96] </ref> gives a deterministic algorithm for sorting on the BSP which runs in time (1 + o (1))( n log n P + L) + O ( gn for P = n 1* , 0 &lt; * &lt; 1, and uses 1-optimal local computation. 36 Chapter 3 New Coding Techniques for
Reference: [GV94] <author> A. Gerbessiotis and L. Valiant. </author> <title> Direct Bulk-Synchronous Algorithms. </title> <journal> Journal of Parallel and Distributed Computing, 22:251 -267, </journal> <year> 1994. </year>
Reference-contexts: However, this algorithm has substantial overhead and is considerably more involved than the one presented in this chapter. Finally, with respect to BSP algorithms for sorting, Gerbessiotis and Valiant <ref> [GV94] </ref> introduce a randomized algorithm for parallel sorting in the BSP model. Also, subsequent to an earlier version of this chapter, the upper bound for sorting in the BSP model has been improved 15 by Goodrich [Goo96], as well as by Gerbessiotis and Siniolakis [GS96]. <p> The running time holds provided that P = O (n fi ) for some constant fi &lt; 1, since in this case there is only a constant number of phases. This result for sorting in the BSP model compares with the previous best randomized methods of Gerbessiotis and Valiant <ref> [GV94] </ref> for the BSP model with the assumption that each packet that is transmitted consists of exactly one key.
Reference: [HLS92] <author> M. Herlihy, B. Lim and N. Shavit. </author> <title> Low Contention Load Balancing on Large Scale Multiprocessors. </title> <booktitle> In Proceedings 4th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. </pages> <address> 219 -227, </address> <year> 1992. </year>
Reference-contexts: Butterfly networks have been shown to efficiently route packets by [Ran88], [Lei92], [ST91], and many others. The idea of using butterfly graphs in shared memory has been used previously in counting networks <ref> [HLS92] </ref>.
Reference: [HW95] <author> M. Harchol-Balter and D. Wolfe. </author> <title> Bounding Delays in Packet-routing Networks. </title> <booktitle> In Proceedings 27th ACM Symposium on Theory of Computing pp. </booktitle> <pages> 248-257, </pages> <year> 1995. </year>
Reference-contexts: A queuing network has Markovian routing if any routing decision is based solely on the current location of the packet to be routed. Very little is known about the delay associated with constant service time queues in networks with non-Markovian routing. For a good summary of this, see <ref> [HW95] </ref>. The remainder of this chapter is organized as follows. In Section 4.2, we discuss the asynchronous QRQW model. In Section 4.3, we introduce the Search-Butterfly. In Sections 4.4 and 4.5, we analyze the behavior of the Search-Butterfly in the static and dynamic cases, respectively. <p> It follows that for any given sample path, N N (t) N N 0 (t): Since the actual behaviors of the queuing networks are distributions over sample paths, we have that N N (t) st N N 0 (t): 81 To prove Claim 47, we induct over time (as in <ref> [HW95] </ref>). Clearly Claim 47 is true at time 0. Assume it is true for the interval of time [0; t 0 ]. <p> Note that all routing decisions in N 0 are Markovian. This allows us to use the following theorem about Processor Sharing (PS) queues: Theorem 48 <ref> [HW95] </ref> Let R be a network with constant service time, FIFO queues and Markovian routing. Let R 0 be identical, except with PS queues.
Reference: [JaJ92] <author> J. JaJa. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1992. </year>
Reference-contexts: Introduction The Parallel Random Access Memory (PRAM) model is a well established and well studied model for determining the inherent parallelism of computational problems (see for example [KR90], <ref> [JaJ92] </ref>, [Rei93]). The original PRAM model of Fortune and Wylie [FW78] would today be referred to as a CREW (concurrent read, exclusive write) PRAM. In this model, an unlimited number of processors can read any given shared memory location during a step of computation with no penalty.
Reference: [JC94] <author> T. Johnson and A. Colbrook. </author> <title> A Distributed, Replicated, Data-Balanced Search Structure. </title> <journal> International Journal of High Speed Computing 6:4 pp. </journal> <pages> 475-500, </pages> <year> 1994. </year> <month> 95 </month>
Reference-contexts: at methods to reduce resource contention at the root of a search tree. [Par89] introduces a method of embedding DeBruijn graphs into a binary tree, provided that the keys can be represented as finite length bit strings, which allows a search to start at any node in the tree. [Wan91], <ref> [JC94] </ref> and others (the bibliography in [JC94] is extensive and thorough) have looked at methods of augmenting a B-Tree by replicating nodes close to the root. <p> at the root of a search tree. [Par89] introduces a method of embedding DeBruijn graphs into a binary tree, provided that the keys can be represented as finite length bit strings, which allows a search to start at any node in the tree. [Wan91], <ref> [JC94] </ref> and others (the bibliography in [JC94] is extensive and thorough) have looked at methods of augmenting a B-Tree by replicating nodes close to the root.
Reference: [JS93] <author> T. Johnson and D. Shasha. </author> <title> The Performance of Concurrent B-Tree Algorithms. </title> <journal> ACM Transactions on Database Systems, 18:1 pp. </journal> <pages> 51-101, </pages> <year> 1993. </year>
Reference-contexts: Also, it does not allow for an efficient means of inserting and deleting keys. Many strongly independent search structures that allow updates have been proposed, but analytical evaluation of these structures has been very limited, and has been cited as lacking, for example in <ref> [JS93] </ref> and [Wan91]. In these search structures, correctness of the data structure during updates is usually provided by adding locks to the tree: shared variables that keep some processors from reading sections of the tree that are currently being modified. <p> Since the node currently being modified needs to be locked, this is very close to optimal in terms of the maximum number of locks held by any processor. Stating the need for more analysis of search tree algorithms, <ref> [JS93] </ref> analyzes B-Link trees (and other structures that reduce the number of locks held by processors), and conclude that in B-Link tree algorithms, the limiting factor is resource contention: several processors trying to access the same shared resource. <p> Each insert and search is chosen independently from the continuous distribution U , and deletes are equally likely to be any key in the structure T . Similar assumptions have been studied in <ref> [JS93] </ref>, [Wan91], [Par89], and [Yao78].
Reference: [JS93b] <author> T. Johnson and D. Shasha. </author> <title> B-Trees with Inserts and Deletes: Why Free-at-Empty is Better than Merge-at-Half. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 47: </volume> <pages> pp. 45-76, </pages> <year> 1993. </year>
Reference: [KR90] <author> R. M. Karp and V. Ramachandran. </author> <title> Parallel Algorithms for Shared-Memory Machines. </title> <booktitle> In Handbook of Theoretical Computer Science, </booktitle> <editor> J. van Leeuwen, </editor> <publisher> Ed., </publisher> <pages> pp. 869-941. </pages> <publisher> Elsevier Science Publishers: </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1990. </year>
Reference-contexts: Introduction The Parallel Random Access Memory (PRAM) model is a well established and well studied model for determining the inherent parallelism of computational problems (see for example <ref> [KR90] </ref>, [JaJ92], [Rei93]). The original PRAM model of Fortune and Wylie [FW78] would today be referred to as a CREW (concurrent read, exclusive write) PRAM. In this model, an unlimited number of processors can read any given shared memory location during a step of computation with no penalty.
Reference: [Lei85] <author> T. Leighton. </author> <title> Tight Bounds on the Complexity of Parallel Sorting. </title> <journal> IEEE Transactions on Computers, </journal> <volume> c-34(4): </volume> <pages> pp. 344-354, </pages> <year> 1985. </year>
Reference-contexts: When m = O (n fi ), for some fi &lt; 1, we show that a version of Columnsort <ref> [Lei85] </ref> has a running time that is bounded by O m j For n AE m, the case of greatest interest, the final factor becomes a small constant and so in this setting the ratio between the upper and lower bounds is fi ( log n log m ). <p> Using Thompson's VLSI model [Tho80], Leighton, in <ref> [Lei85] </ref>, proves a lower bound of AT 2 = (n 2 log 2 n) for sorting n keys of size fi (log n), where A is the area of a VLSI chip and T is the running time of the chip. <p> By the little birdie principle, the probability that processor d responds correctly on an input chosen uniformly at random, when not given the matrix H, is also at most 3 4 . 2.4 The Upper Bound We show that a version of Leighton's Columnsort <ref> [Lei85] </ref> performs well in the ER PRAM (m).
Reference: [Lei92] <author> T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: The following simple description of Columnsort is provided in <ref> [Lei92] </ref>. In phases 1, 3, and 7, the columns are sorted into increasing order. In phase 5, odd columns are sorted into increasing order and even columns are sorted into decreasing order. <p> Processors access a butterfly graph stored in the shared memory and are "routed" by following pointers between memory locations to a 2-3 Tree that contains all the keys from a small region of the set U . Butterfly networks have been shown to efficiently route packets by [Ran88], <ref> [Lei92] </ref>, [ST91], and many others. The idea of using butterfly graphs in shared memory has been used previously in counting networks [HLS92]. <p> Note that FIFO contention resolution with up-to-present arbitrary resolution of ties 73 is non-predictive. This proof can also be extended to the case where the inputs are chosen randomly and the outputs are fixed (see <ref> [Lei92] </ref>, p. 569). Thus, the problem of "routing" the processors to the correct 2-3 Trees w.h.p. requires time O (Y + log n).
Reference: [LPV81] <author> G. Lev, N. Pippenger and L. Valiant. </author> <title> A Fast Parallel Algorithm for Routing in Permutation Networks. </title> <journal> In IEEE Transactions on Computing, C-30 pp. </journal> <volume> 93 - 100, </volume> <year> 1981. </year>
Reference-contexts: In this model, an unlimited number of processors can read any given shared memory location during a step of computation with no penalty. The EREW (exclusive read, exclusive write) PRAM, introduced by <ref> [LPV81] </ref>, models a parallel machine where steps of computation involving a large number of processors reading the same location are prohibitively expensive.
Reference: [LY81] <author> P. Lehman and S.B. Yao. </author> <title> Efficient Locking for Concurrent Operations on B-Trees. </title> <journal> In ACM Transactions on Database Systems, 6:4 pp. </journal> <pages> 650-670, </pages> <year> 1981. </year>
Reference-contexts: There is a large body of previous work which has focused on reducing the number of locks necessary, including [BS77], [Ell80], <ref> [LY81] </ref>, [Sag86]. The culmination of these efforts is the B-Link tree, a strongly independent search structure which allows inserts to lock no more than one node at any time, and deletes to lock only a small constant number at any step.
Reference: [LY86] <author> M. Li and Y. Yesha. </author> <title> New Lower Bounds for Parallel Computation. </title> <booktitle> In Proceedings of the 18 th Annual ACM Symposium on Theory of Computing: </booktitle> <pages> pp. 177-187, </pages> <year> 1986. </year>
Reference-contexts: Some asynchronous algorithms for the QRQW have already been given in [GMR96a]. 5 shared memory cellsM processorsP N input size 1.1.2 The PRAM (m) Model The PRAM (m) model is introduced in [MNV94], and is based on a similar previous model studied in [VW85], <ref> [LY86] </ref>, and [Aza92]. In this PRAM model, communication is restricted by requiring that processors communicate only through m shared memory cells.
Reference: [Mac95] <author> P. Mackenzie. </author> <title> Lower Bounds for Randomized Exclusive Write PRAMs. </title> <booktitle> In Proceedings 7th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 254-263, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Also, for the uniform distribution over all possible inputs, the running time of any Monte Carlo algorithm is at least n log m 8m . We prove this theorem using an alternate formulation of Yao's lemma, provided in <ref> [Mac95] </ref>: Lemma 15 Let P 1 be the success probability of a T step randomized algorithm solving problem B, where the success probability is taken over the random choices made by the algorithm, and minimized over all possible inputs.
Reference: [ML84] <author> U. Manber and R. Ladner. </author> <title> Concurrency Control in a Dynamic Search Structure. </title> <journal> ACM Transactions on Database Systems, 9:3 pp. </journal> <pages> 439-455, </pages> <year> 1984. </year> <month> 96 </month>
Reference: [MNV94] <author> Y. Mansour, N. Nisan and U. Vishkin. </author> <title> Trade-offs Between Communication Throughput and Parallel Time. </title> <booktitle> In Proceedings of the 26 th Annual ACM Symposium on Theory of Computing: </booktitle> <pages> pp. 372-381, </pages> <year> 1994. </year>
Reference-contexts: Algorithms designed for models such as this tend not to be efficient when implemented on machines where communication throughput is limited. Since most parallel machines built today do have much less communication throughput available than the number of processors <ref> [MNV94] </ref>, parallel models have evolved to more accurately reflect the construction of real machines. These new models include the BSP model [Val90a], the LogP model [CKP+93], and one of the main tools used in this thesis, the PRAM (m) model [MNV94], where p processors communicate only through a read/write shared memory <p> much less communication throughput available than the number of processors <ref> [MNV94] </ref>, parallel models have evolved to more accurately reflect the construction of real machines. These new models include the BSP model [Val90a], the LogP model [CKP+93], and one of the main tools used in this thesis, the PRAM (m) model [MNV94], where p processors communicate only through a read/write shared memory of size m, m o p. The shared memory of size m models a communication throughput of m per time step. The new models have emphasized the fact that communication throughput is a vital consideration in parallel algorithm design. <p> The shared memory of size m models a communication throughput of m per time step. The new models have emphasized the fact that communication throughput is a vital consideration in parallel algorithm design. For example, results of <ref> [MNV94] </ref> demonstrate that limited communication throughput is the primary bottleneck for several computational problems. <p> Some asynchronous algorithms for the QRQW have already been given in [GMR96a]. 5 shared memory cellsM processorsP N input size 1.1.2 The PRAM (m) Model The PRAM (m) model is introduced in <ref> [MNV94] </ref>, and is based on a similar previous model studied in [VW85], [LY86], and [Aza92]. In this PRAM model, communication is restricted by requiring that processors communicate only through m shared memory cells. <p> Note that in the PRAM (m) model of <ref> [MNV94] </ref>, an unlimited number of processors is allowed to read the same shared memory cell concurrently. To distinguish this from refinements described below, we call this model the CR PRAM (m), where CR stands for concurrent read. This represents a system with high concurrency and limited communication throughput. <p> This problem can be solved on the CR PRAM (m) in time O (log p n), and thus the CR PRAM (m) can solve the binary search problem more efficiently than the QRQW PRAM. On the other hand, the lower bound of <ref> [MNV94] </ref> for sorting on the CR PRAM (m) of ( n p mp ) can be outperformed using Cole's Parallel Mergesort [Col88] on the QRQW PRAM. Therefore, the CR PRAM (m) is incomparable to the QRQW PRAM. <p> An interesting question would be to determine whether we could apply our lower bound technique to this non-standard VLSI model. When introducing the PRAM (m) model in <ref> [MNV94] </ref>, Mansour, Nisan and Vishkin prove a lower bound of ( n p mp ) for several problems, including sorting, in a concurrent read version of the PRAM (m), which implies the same bound in the ER PRAM (m). <p> On the other hand, it is also interesting to note that the lower bound of Section 3.2.1 implies a lower bound for using the technique described in this chapter for sorting in the CR PRAM (M ) which is identical to that given in <ref> [MNV94] </ref>. Related to this open problem is finding the exact complexity of sorting in the CR PRAM (M ). Again, a large gap remains between upper and lower bounds.
Reference: [MR95] <author> R. Motwani and P. Raghavan. </author> <title> Randomized Algorithms, </title> <publisher> Cambridge University Press, </publisher> <year> 1995. </year>
Reference-contexts: After the locations of i 1 balls have been determined, there are still at most Y marked bins left. Thus, Pr [X i = 1 j X 0 : : : X i1 ] N i Y : 56 Equation (1) follows from a Chernoff bound (see for example <ref> [MR95] </ref>). Let X 0 i = 1 if either the i th red ball is in a marked bin or at least XY N of the first i 1 balls are in marked bins and let X 0 i = 0 otherwise .
Reference: [Nis90] <author> N. Nishimura. </author> <title> Asynchronous Shared Memory Parallel Computation. </title> <booktitle> In Proceedings 2 nd ACM Symposium on Parallel Algorithms and Architectures pp. </booktitle> <pages> 76-84, </pages> <year> 1990. </year>
Reference-contexts: Processors behave asynchronously, and this can be modeled in several different ways: [CZ89], [CZ90], <ref> [Nis90] </ref>. Examples of asynchronous machines that conform well to the QRQW rule are the Kendall Square KSR-1, the Tera Computer, and the Stanford DASH [GMR94a].
Reference: [Par89] <author> J. Parker. </author> <title> A Concurrent Search Structure. </title> <journal> Journal of Parallel and Distributed Computing 7: </journal> <pages> pp. 256-278, </pages> <year> 1989. </year>
Reference-contexts: However, the authors concede that their analysis requires some strong assumptions about both the arrival times and the service times of operations at each node of the search structure. Several authors have looked at methods to reduce resource contention at the root of a search tree. <ref> [Par89] </ref> introduces a method of embedding DeBruijn graphs into a binary tree, provided that the keys can be represented as finite length bit strings, which allows a search to start at any node in the tree. [Wan91], [JC94] and others (the bibliography in [JC94] is extensive and thorough) have looked at <p> Each insert and search is chosen independently from the continuous distribution U , and deletes are equally likely to be any key in the structure T . Similar assumptions have been studied in [JS93], [Wan91], <ref> [Par89] </ref>, and [Yao78].
Reference: [PVW83] <author> W. Paul, U. Vishkin and H. Wagner. </author> <title> Parallel Dictionaries on 2-3 Trees. </title> <booktitle> In Proceedings of the 10th International Colloquium on Automata, Languages, and Programming 1983. </booktitle>
Reference-contexts: Note that concurrent updates are allowed to affect the memory location access pattern; this is necessary when the set of keys being stored changes if we wish searches to be independent. 4.1.1 Previous Work <ref> [PVW83] </ref> provide an algorithm for the synchronous EREW PRAM that performs p concurrent operations on a 2-3 Tree containing n keys in time O (log n + log p). Their algorithm is not, however, reasonable in an asynchronous environment. <p> For example, both the method from <ref> [PVW83] </ref> and from [Ran92] require an initial phase where the keys that are being searched for are sorted. When the processors do not know which subset of processors are performing searches, or when some processor may experience long delays due to the system being asynchronous, this phase can be expensive. <p> This lower bound means that when the accesses by different processors are very localized, any strongly independent search structure must perform poorly when compared to the tightly coupled algorithms of <ref> [PVW83] </ref> and [Ran92]. To deal with this case for asynchronous shared memory machines, we need to find some middle ground between strongly independent algorithms and algorithms that require very close cooperation between processors. We believe that the upper bound techniques presented here provide a good starting point for this goal.
Reference: [Ran88] <author> A. Ranade. </author> <title> Fluent Parallel Computation. </title> <type> Ph.D. Thesis, </type> <institution> Yale University, </institution> <year> 1988. </year>
Reference-contexts: Processors access a butterfly graph stored in the shared memory and are "routed" by following pointers between memory locations to a 2-3 Tree that contains all the keys from a small region of the set U . Butterfly networks have been shown to efficiently route packets by <ref> [Ran88] </ref>, [Lei92], [ST91], and many others. The idea of using butterfly graphs in shared memory has been used previously in counting networks [HLS92]. <p> Proof: The largest number of processors that access any given output of the butterfly is Y . Since every processor accesses a randomly chosen input node of the butterfly, w.h.p., at most Y + log n processors access any input node of the butterfly. <ref> [Ran88] </ref> gives a proof that realizing a p packet per input routing problem to random destinations in a butterfly with any non-predictive contention resolution scheme requires only time O (log n + Y ). Note that FIFO contention resolution with up-to-present arbitrary resolution of ties 73 is non-predictive.
Reference: [Ran92] <author> A. Ranade. </author> <title> Maintaining Dynamic Ordered Sets on Processor Networks. </title> <booktitle> In Proceedings 4 th ACM Symposium on Parallel Algorithms and Architectures pp. </booktitle> <volume> 127 - 137, </volume> <year> 1992. </year>
Reference-contexts: Their algorithm is not, however, reasonable in an asynchronous environment. Their algorithm assumes that every access by a processor to the search structure is accompanied by simultaneous accesses by all the other processors, and during these accesses, processors cooperate to a high degree. <ref> [Ran92] </ref> studies search structures for fixed connection distributed memory machines, but again the processors do not function independently. For example, both the method from [PVW83] and from [Ran92] require an initial phase where the keys that are being searched for are sorted. <p> the search structure is accompanied by simultaneous accesses by all the other processors, and during these accesses, processors cooperate to a high degree. <ref> [Ran92] </ref> studies search structures for fixed connection distributed memory machines, but again the processors do not function independently. For example, both the method from [PVW83] and from [Ran92] require an initial phase where the keys that are being searched for are sorted. When the processors do not know which subset of processors are performing searches, or when some processor may experience long delays due to the system being asynchronous, this phase can be expensive. <p> This lower bound means that when the accesses by different processors are very localized, any strongly independent search structure must perform poorly when compared to the tightly coupled algorithms of [PVW83] and <ref> [Ran92] </ref>. To deal with this case for asynchronous shared memory machines, we need to find some middle ground between strongly independent algorithms and algorithms that require very close cooperation between processors. We believe that the upper bound techniques presented here provide a good starting point for this goal.
Reference: [Rei85] <author> R. Reischuk. </author> <title> Probabilistic Parallel Algorithms For Sorting and Selection. </title> <note> SIAM Journal on Computing 14:2 pp 396-409, </note> <year> 1985. </year>
Reference: [Rei93] <author> J. Reif, </author> <title> editor. A Synthesis of Parallel Algorithms. </title> <publisher> Morgan-Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Introduction The Parallel Random Access Memory (PRAM) model is a well established and well studied model for determining the inherent parallelism of computational problems (see for example [KR90], [JaJ92], <ref> [Rei93] </ref>). The original PRAM model of Fortune and Wylie [FW78] would today be referred to as a CREW (concurrent read, exclusive write) PRAM. In this model, an unlimited number of processors can read any given shared memory location during a step of computation with no penalty.
Reference: [Sag86] <author> Y. Sagiv. </author> <title> Concurrent Operations on B fl -Trees with Overtaking. </title> <journal> Journal of Computer and System Sciences 33: </journal> <pages> pp. 275-296, </pages> <year> 1986. </year>
Reference-contexts: There is a large body of previous work which has focused on reducing the number of locks necessary, including [BS77], [Ell80], [LY81], <ref> [Sag86] </ref>. The culmination of these efforts is the B-Link tree, a strongly independent search structure which allows inserts to lock no more than one node at any time, and deletes to lock only a small constant number at any step.
Reference: [Sni85] <author> M. Snir. </author> <title> On Parallel Searching. </title> <journal> SIAM Journal of Computing: </journal> <volume> 14: </volume> <pages> pp. 688-708, </pages> <year> 1985. </year>
Reference-contexts: In other words, this is a measure of the bandwidth available between the processors and a given memory location. Results by Snir <ref> [Sni85] </ref> demonstrate that this measure has a significant impact on the power of a parallel machine. Recently, Gibbons, Matias and Ramachandran [GMR94a], [GMR94b] have inspired a re 2 examination of the effects of concurrency on parallel computation. <p> This chapter appeared in a preliminary version in [Adl96a]. 1.4 Previous Work Although we describe previous work in context throughout this thesis, we here briefly mention some previous results that imply differences between the models described. A proof of <ref> [Sni85] </ref> can be adapted to imply a lower bound of (log n log p) for the QRQW PRAM on the parallel binary search problem. <p> Therefore, the CR PRAM (m) is incomparable to the QRQW PRAM. Again using the results of <ref> [Sni85] </ref>, we can show that parallel binary search on n keys requires time (log n) in the ER PRAM (m) model and can be performed in time O (log p n) in the CR PRAM (m). This implies a separation between the CR PRAM (m) and the ER PRAM (m).
Reference: [ST91] <author> G. Stamoulis, J. Tsitsiklis. </author> <title> The Efficiency of Greedy Routing in Hypercubes and Butterflies. </title> <booktitle> In Proceedings 3 rd ACM Symposium on Parallel Algorithms and Architectures pp. </booktitle> <pages> 248-259, </pages> <year> 1991. </year> <month> 97 </month>
Reference-contexts: Processors access a butterfly graph stored in the shared memory and are "routed" by following pointers between memory locations to a 2-3 Tree that contains all the keys from a small region of the set U . Butterfly networks have been shown to efficiently route packets by [Ran88], [Lei92], <ref> [ST91] </ref>, and many others. The idea of using butterfly graphs in shared memory has been used previously in counting networks [HLS92]. <p> The arrivals to the roots of D are partitioned randomly, and thus the arrivals at each of the root nodes are described by a Poisson process. It is easily seen that S is a leveled network with Markovian routing (see <ref> [ST91] </ref>). Thus, we only need to show that the total arrival rate to any node in the Search-Butterfly is &lt; fi n fl. <p> We show that combining this observation with the technique developed by Stamoulis and Tsitsiklis in <ref> [ST91] </ref> yields the lemma. Claim 46 [ST91] Let a = t 1 ; t 2 ; : : : and a 0 = t 0 1 ; t 0 2 ; : : : be two arrival time streams to a determin istic FIFO queue, where t 1 t 0 1 <p> We show that combining this observation with the technique developed by Stamoulis and Tsitsiklis in <ref> [ST91] </ref> yields the lemma. Claim 46 [ST91] Let a = t 1 ; t 2 ; : : : and a 0 = t 0 1 ; t 0 2 ; : : : be two arrival time streams to a determin istic FIFO queue, where t 1 t 0 1 ; t 2 t 0 2 <p> Then the two corresponding departure time streams d 1 ; d 2 ; : : :, and d 0 2 ; : : :, satisfy d 1 d 0 1 ; d 2 d 0 The proof of <ref> [ST91] </ref> extends to the case where the service time is not constant, but the service time of all arrivals in stream a is no greater than the smallest service time of any arrival in stream a 0 . We now use the technique of sample path analysis developed in [ST91]. <p> of <ref> [ST91] </ref> extends to the case where the service time is not constant, but the service time of all arrivals in stream a is no greater than the smallest service time of any arrival in stream a 0 . We now use the technique of sample path analysis developed in [ST91]. Let a sample path S consist of the set of all arrival times to the network, and all routing decisions defined as follows: the nth packet of type l to depart from queue i proceeds to queue j as a packet of type k.
Reference: [Tho80] <author> C. Thompson. </author> <title> A Complexity Theory for VLSI. </title> <type> PhD Thesis. </type> <institution> Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1980. </year>
Reference-contexts: Using Thompson's VLSI model <ref> [Tho80] </ref>, Leighton, in [Lei85], proves a lower bound of AT 2 = (n 2 log 2 n) for sorting n keys of size fi (log n), where A is the area of a VLSI chip and T is the running time of the chip.
Reference: [Val90a] <author> L. Valiant. </author> <title> A Bridging Model for Parallel Computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8): </volume> <pages> pp 103-111, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Since most parallel machines built today do have much less communication throughput available than the number of processors [MNV94], parallel models have evolved to more accurately reflect the construction of real machines. These new models include the BSP model <ref> [Val90a] </ref>, the LogP model [CKP+93], and one of the main tools used in this thesis, the PRAM (m) model [MNV94], where p processors communicate only through a read/write shared memory of size m, m o p. <p> We give a brief discussion of the complexity of sorting in the LogP model [CKP+93] and the BSP model <ref> [Val90a] </ref>. 2.5.1 The LogP model In the LogP model, limited communication communication throughput in a parallel machine is enforced by requiring that each processor must wait for a gap of at least g cycles between the transmission of consecutive point-to-point messages.
Reference: [Val90b] <author> L. Valiant. </author> <title> General Purpose Parallel Architectures. </title> <booktitle> In Handbook of Theoretical Computer Science, </booktitle> <editor> J. van Leeuwen, </editor> <publisher> Ed., </publisher> <pages> pp. 943-971. </pages> <publisher> Elsevier Science Publishers: </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1990. </year>
Reference: [VS94] <author> J. Vitter and E. Shriver. </author> <title> Algorithms for Parallel Memory I: Two-Level Memories. </title> <journal> Algorith-mica, </journal> <volume> 12(2/3): </volume> <pages> pp. 110-147, </pages> <year> 1994. </year>
Reference: [VW85] <author> U. Vishkin and A. Wigderson. </author> <title> Trade-Offs between Depth and Width in Parallel Computation. </title> <journal> SIAM Journal of Computing, </journal> <volume> 14(2): </volume> <pages> pp. 303 - 314, </pages> <year> 1985. </year>
Reference-contexts: Some asynchronous algorithms for the QRQW have already been given in [GMR96a]. 5 shared memory cellsM processorsP N input size 1.1.2 The PRAM (m) Model The PRAM (m) model is introduced in [MNV94], and is based on a similar previous model studied in <ref> [VW85] </ref>, [LY86], and [Aza92]. In this PRAM model, communication is restricted by requiring that processors communicate only through m shared memory cells.
Reference: [Wal89] <author> J. Walrand. </author> <title> Introduction to Queueing Networks. </title> <publisher> Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1989. </year>
Reference-contexts: st N N 00 (t); which in turn implies: N N (t) st N N 00 (t): Since the arrivals to N 00 are Poisson, routing in N 00 is Markovian, and all queues in N 00 are PS, we see that N 00 is product form (see for example <ref> [Wal89] </ref>). Since 8i; l, l i &lt; r i i , network N 00 is stable, and thus as t ! 1, the number of times that N N 00 (t) = 0 approaches 1.
Reference: [Wan91] <author> P. Wang. </author> <title> An In-Depth Analysis of Concurrent B-Tree Algorithms Masters Thesis. </title> <institution> Mas-sachusetts Institute of Technology, </institution> <year> 1991. </year>
Reference-contexts: Also, it does not allow for an efficient means of inserting and deleting keys. Many strongly independent search structures that allow updates have been proposed, but analytical evaluation of these structures has been very limited, and has been cited as lacking, for example in [JS93] and <ref> [Wan91] </ref>. In these search structures, correctness of the data structure during updates is usually provided by adding locks to the tree: shared variables that keep some processors from reading sections of the tree that are currently being modified. <p> looked at methods to reduce resource contention at the root of a search tree. [Par89] introduces a method of embedding DeBruijn graphs into a binary tree, provided that the keys can be represented as finite length bit strings, which allows a search to start at any node in the tree. <ref> [Wan91] </ref>, [JC94] and others (the bibliography in [JC94] is extensive and thorough) have looked at methods of augmenting a B-Tree by replicating nodes close to the root. <p> Each insert and search is chosen independently from the continuous distribution U , and deletes are equally likely to be any key in the structure T . Similar assumptions have been studied in [JS93], <ref> [Wan91] </ref>, [Par89], and [Yao78].
Reference: [Yao77] <author> A. Yao. </author> <title> Probabilistic Computations: Toward a Unified Measure of Complexity. </title> <booktitle> In Proceedings 18 th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 222-227, </pages> <year> 1977. </year>
Reference-contexts: For Las Vegas algorithms, or randomized strategies which are guaranteed to provide a correct solution with a bound only on the expected running time, we have a lower bound which follows from a direct application of Yao's lemma <ref> [Yao77] </ref>. Theorem 13 For any Las Vegas algorithm A v for the ER PRAM (m) where n p 2 , there is some input I for the sorting problem, such that A v requires expected time at least n log m 8m to solve I. <p> Also, the expected running time of any Las Vegas algorithm on an input chosen uniformly at random from the set of all inputs is at least n log m 8m . Proof: Yao's lemma <ref> [Yao77] </ref> states that a lower bound of L for the expected running time of any deterministic algorithm acting on some distribution over the inputs implies that for any randomized algorithm there exists an input for which the expected running time is at least L. 20 This combined with Theorem 12 directly
Reference: [Yao78] <author> A. Yao. </author> <title> On Random 2-3 Trees. </title> <journal> Acta Informatica 9, </journal> <pages> pp. 159-170, </pages> <year> 1978. </year>
Reference-contexts: Each insert and search is chosen independently from the continuous distribution U , and deletes are equally likely to be any key in the structure T . Similar assumptions have been studied in [JS93], [Wan91], [Par89], and <ref> [Yao78] </ref>.
Reference: [Yao81] <author> A. Yao. </author> <note> Should Tables Be Sorted? Journal of ACM 28, 3 pp. 615-628, </note> <year> 1981. </year>
Reference-contexts: We combine Yao's cell probe model <ref> [Yao81] </ref> with the asynchronous QRQW PRAM: we assume the data structure consists of O (n) memory cells, and that each cell contains only the value of a key and can service at most one probe per time step. <p> and search set S containing p keys, the expected time required to perform S on T is ( p Proof: Since the keys are arbitrarily chosen real numbers, and A is strongly independent, the expected number of probes that each of the p searches needs to perform is (log n) <ref> [Yao81] </ref>. Thus, the expected total number of cell probes is (p log n). Since A is space efficient, there are only O (n) cells to perform these probes in, and the bound follows from the fact that each location can handle only one probe per time step.
References-found: 70

