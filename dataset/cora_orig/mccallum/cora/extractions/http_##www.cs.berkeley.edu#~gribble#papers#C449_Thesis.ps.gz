URL: http://www.cs.berkeley.edu/~gribble/papers/C449_Thesis.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~gribble/papers/papers.html
Root-URL: http://www.cs.berkeley.edu
Title: The Phoenix Quest  
Author: Steven Gribble 
Degree: Supervisor Dr. Maria Klawe  
Address: Vancouver, British Columbia, V6T 1Z4  
Affiliation: Department of Computer Science, The University of British Columbia  
Date: April 16, 1995  
Note: Computer Science 449 Thesis  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> N. Chomsky. </author> <title> Aspects of the Theory of Syntax. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, USA, </address> <year> 1965. </year>
Reference-contexts: Syntactic parsers are good at analyzing the grammatical structure of a given sentence; unfortunately, they make no pretense at understanding semantics, resulting in such erroneous sentences. Various modified versions of syntactic parsers have been proposed. The most notable of such schemes is attributed to Noam Chomsky <ref> [1] </ref>, and is called a transformational grammar. A transformational grammar consists of a "base" component and a "transformational" component. The base component is simply a context-free grammar, which specifies the deep structure of a sentence.
Reference: [2] <author> A. Davey. </author> <title> Discourse Production. </title> <publisher> Edinburgh University Press, Edinburgh, </publisher> <address> U.K., </address> <year> 1979. </year>
Reference-contexts: Needless to say, the success of NLG systems to date has been relatively limited. Successful systems incorporate a highly detailed conceptual model of a somewhat limited subject area; for example, the reasonably successful PROTEUS program (Davey <ref> [2] </ref>) was able to produce convincing natural language analysis of games of tic-tac-toe. The ability to build a system with a more general area of expertise has to date proven impossible. The problem of NLG, when coupled with that of natural language understanding, is extremely difficult.
Reference: [3] <author> Ralph Grishman. </author> <title> Computational Linguistics, an Introduction. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, Great Britain, </address> <year> 1986. </year>
Reference-contexts: Figure 1 illustrates the parse tree equivalent to this parsing. Given a sentence, the job of a syntactic parser is to find all parse trees that exactly represent that sentence. Syntactic parsing is therefore the reverse process of the generation of a sentence through the application of productions. Grishman <ref> [3] </ref> presents a thorough discussion of parsing algorithms, and also provides examples of the limitations of these algorithms. It is fairly evident that the approach of using CFG's to represent languages of arbitrary complexity suffers from a number of fatal drawbacks.
Reference: [4] <author> John C. Martin. </author> <title> Introduction to Languages and the Theory of Computation. </title> <publisher> McGraw-Hill, Inc., </publisher> <address> New York, NY, USA, </address> <year> 1991. </year>
Reference-contexts: Parse trees are hierarchical schematics of the structure of sentences, and are built from simple rules embodied within a (context-free) grammar. Formally, a context-free grammar may be defined in the following way (Martin <ref> [4] </ref>): Definition 1 (Context-Free Grammar) A context-free grammar (CFG) is a 4-tuple G = (V; ; S; P ), where: * V and are finite sets with V " = ;, with V as a set of non-terminal symbols and as an alphabet of terminal symbols. * S 2 V is <p> It has been extracted from a description an implementation of a regular expression parser that is written in ANSI C. This parser been ported to the Macintosh for use in the next Penpal prototype. A formal introduction to regular expressions can be found in Martin <ref> [4] </ref>. Regular expressions describe a certain class of languages. These expressions can be translated into deterministic or non-deterministic finite automata, which in turn may be compiled in order to test a string for inclusion in the regular expressions' language class. Henry Spencer's code compiles regular expressions into non-deterministic finite automata.
Reference: [5] <author> Michael L. Mauldin. Chatterbots, tinymuds, </author> <title> and the turing test: Entering the loebner prize competition. </title> <booktitle> In AAAI-94, </booktitle> <address> Seattle, WA, USA, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: Towards this end, the simplistic pattern matching and storyline inclusion strategy of the original prototype will be augmented with a more complex control mechanism, namely an activation net. This idea is based upon the control mechanism presented in Mauldin <ref> [5] </ref>, which discusses a conversational program called `Julia' that was entered into the 1994 Loebner Prize 1 competition. 5.1 Activation Networks An activation network is composed of a series of conversational nodes and weighted, directional links between these nodes.
Reference: [6] <editor> Stuart C. Shapiro, editor. </editor> <booktitle> Encyclopedia of Artificial Intelligence Volumes I and II. </booktitle> <publisher> John Wiley and Sons, </publisher> <address> New York, NY, USA, </address> <year> 1987. </year>
Reference-contexts: Semantic parsing is therefore the process of deducing meaning behind a sentence; wherever possible, that meaning should reflect the intention of the author. There are a number of practical approaches to semantic parsing that have been devised by AI researchers; many of these are outlined in Shapiro <ref> [6] </ref>. All of these methods rely on a large database of knowledge and some underlying logic or transformational scheme to relate given sentences to the underlying knowledge base. <p> Syntactic ellipsis is often used by people to minimize effort when expressing ideas during informal conversation, while semantic ellipsis occurs when the completion of the semantic structure of a sentence is obvious or implied. Unfortunately, empirical studies suggest that people tend to use anaphora and ellipsis wherever possible. Shapiro <ref> [6] </ref> observes that this intentional terseness is independent of task, media, typing ability, or instructions to the contrary.
Reference: [7] <author> J. Weizenbaum. </author> <title> Eliza a computer program for the study of natural language communication between man and machine. </title> <journal> Communications of the ACM, </journal> <volume> 9(1) </volume> <pages> 36-45, </pages> <month> January </month> <year> 1966. </year>
Reference-contexts: Should a match be found, a 9 reply sentence can then be specified or constructed. A simple (but quite successful) example of such a pattern-matching system is the ELIZA program designed by Weizenbaum <ref> [7] </ref>. ELIZA attempts to duplicate the behaviour of a psychotherapist; single sentence inputs given to ELIZA are matched against a small set of patterns, each of which has associated with it a set of replies. <p> This is a very powerful effect if a user can be made to believe in the Penpal, then that user will actively resist the loss of this belief, which is why we have named this mode "suspended disbelief". To quote Weizenbaum <ref> [7] </ref>, What I had not realized is that extremely short exposures to a relatively simple computer program could induce powerful delusional thinking in quite normal people. Clearly every effort needs to be made to encourage users to enter and remain in this mode of interaction.
Reference: [8] <author> Marv Westrom. </author> <type> Personal correspondences, </type> <month> March </month> <year> 1994. </year>
Reference-contexts: This was done in order to increase the likelihood of a match, without mangling the overall structure or content of the sentences. This process can be formalized into a series of optional transformations that can be performed on a sentence. We define the following transformations <ref> [8] </ref>: Strip Whitespace (SW) The SW transformation removes all whitespace characters from a sentence. Whites pace characters include spaces, tabs, carriage returns, etc. Strip Punctuation (SP) If this transformation is used, all punctuation is removed from a sentence.
Reference: [9] <author> W. A. Woods. </author> <title> Procedural semantics for a question-answering machine. </title> <booktitle> AFIPS Conference Proceedings, Fall Joint Computer Conference, </booktitle> <year> 1968. </year> <month> 40 </month>
Reference-contexts: Alternatively, semantic networks can be engineered in which nodes represent 7 concepts, entities, or states, and arcs represent relationships between nodes. Procedural semantics (Woods <ref> [9] </ref>) is another paradigm in which rules are applied that translate sentences into procedure calls that act on a database; the semantic meaning behind a sentence is then related to the result of calling the sentence's procedure.
References-found: 9

