URL: http://www.cs.toronto.edu/~frey/papers/pfeffer.ps.Z
Refering-URL: http://www.cs.toronto.edu/~frey/papers/pfeffer.abs.html
Root-URL: http://www.cs.toronto.edu
Title: A Probabilistic Framework for Embedded Face and Facial Expression Recognition  
Author: Antonio J. Colmenarez Brendan J. Frey Thomas S. Huang 
Address: Urbana, IL Waterloo, ON Urbana, IL  
Affiliation: Beckman Institute Computer Science Beckman Institute University of Illinois University of Waterloo University of Illinois  
Web: www.ifp.uiuc.edu/antonio www.cs.toronto.edu/frey www.ifp.uiuc.edu  
Abstract: We present a Bayesian recognition framework in which a model of the whole face is enhanced by models of facial feature position and appearances. Face recognition and facial expression recognition are carried out using maximum likelihood decisions. The algorithm finds the model and facial expression that maximizes the likelihood of a test image. In this framework, facial appearance matching is improved by facial expression matching. Also, changes in facial features due to expressions are used together with facial deformation patterns to jointly perform expression recognition. In our current implementation, the face is divided into 9 facial features grouped in 4 regions which are detected and tracked automatically in video segments. The feature images are modeled using Gaussian distributions on a principal component sub-space. The training procedure is supervised: we use video segments of people in which the facial expressions have been segmented and labeled by hand. We report results on face and facial expression recognition using a video database of 18 people and 6 expressions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Wiskott, J. M. Fellous, N. Krger, and C. Mals-burg, </author> <title> "Face recognition and gender determination," </title> <booktitle> in International Conference on Automatic Face and Gesture Recognition, </booktitle> <year> 1995. </year>
Reference-contexts: To deal with variations due to facial expressions, several approaches have been studied. Elastic graphs (e.g. "Dynamic Link Architecture" <ref> [1, 2] </ref> ) have been used to match images while allowing for non-rigid deformation . Another interesting approach uses a parametric model to deform faces so that the comparison of their appearance is carried out after the pose and facial expression is somewhat compensated [3, 4].
Reference: [2] <author> A. Tefas, C. Kotropoulos, and I. Pitas, </author> <title> "Variants of dynamic link architecture based on mathematical morphology for frontal face authentication," </title> <booktitle> in CVPR, </booktitle> <year> 1998. </year>
Reference-contexts: To deal with variations due to facial expressions, several approaches have been studied. Elastic graphs (e.g. "Dynamic Link Architecture" <ref> [1, 2] </ref> ) have been used to match images while allowing for non-rigid deformation . Another interesting approach uses a parametric model to deform faces so that the comparison of their appearance is carried out after the pose and facial expression is somewhat compensated [3, 4].
Reference: [3] <author> A. Lanitis, C. Taylor, and T. Cootes, </author> <title> "A unified approach to coding and interpreting face images," </title> <booktitle> in Proc. IEEE Conf. Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: Another interesting approach uses a parametric model to deform faces so that the comparison of their appearance is carried out after the pose and facial expression is somewhat compensated <ref> [3, 4] </ref>. In a face recognition system based on a single frontal view, [5] uses the position of the facial features to estimate the head pose and normalize feature templates accordingly.
Reference: [4] <author> A. Lanitis, C. Taylor, and T. Cootes, </author> <title> "Automatic identification of human faces using flexible appearance models," </title> <booktitle> in Procs. Of the 5th Brithish Machine Vision Conference, </booktitle> <year> 1994. </year>
Reference-contexts: Another interesting approach uses a parametric model to deform faces so that the comparison of their appearance is carried out after the pose and facial expression is somewhat compensated <ref> [3, 4] </ref>. In a face recognition system based on a single frontal view, [5] uses the position of the facial features to estimate the head pose and normalize feature templates accordingly.
Reference: [5] <author> K.-M. Lam and H. Yam, </author> <title> "An analytic-to-holistic approach for face recognition based on a single frontal view," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 20, </volume> <pages> pp. 673-686, </pages> <month> July </month> <year> 1998. </year>
Reference-contexts: Another interesting approach uses a parametric model to deform faces so that the comparison of their appearance is carried out after the pose and facial expression is somewhat compensated [3, 4]. In a face recognition system based on a single frontal view, <ref> [5] </ref> uses the position of the facial features to estimate the head pose and normalize feature templates accordingly. In another approach for person identification based on the analysis of the spatio-temporal patterns of the lips [6], it has been found that combining shape information with intensity information improves recognition accuracy.
Reference: [6] <author> J. Luettin, N. Thacker, and S. W. Beet, </author> <title> "Learning to recognize talking faces," </title> <booktitle> in Procs. of Int. Conf. On Pattern Recognition, </booktitle> <year> 1996. </year>
Reference-contexts: In a face recognition system based on a single frontal view, [5] uses the position of the facial features to estimate the head pose and normalize feature templates accordingly. In another approach for person identification based on the analysis of the spatio-temporal patterns of the lips <ref> [6] </ref>, it has been found that combining shape information with intensity information improves recognition accuracy. Although there has been a great deal of research on the subject of facial motion analysis from image sequences, face recognition research has been focussed on still images.
Reference: [7] <author> Y. Yacoob and L. S. Davis, </author> <title> "Recognizing human facial expressions from long image sequences using optical flow," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 18, </volume> <pages> pp. 636-642, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Most research on facial expression recognition is based only on non-rigid facial deformation patterns. Appearance variations due to facial expressions that are not well described by these motion fields are ignored. For example, these techniques use optical flow <ref> [7, 8] </ref>, 2-D graphical models ("Potential Nets") [9] and local parametric models [10, 11]. In this paper, we propose a probabilistic framework in which face models jointly capture information about facial appearance and expression patterns so that recognition of faces and facial expressions are carried at the same time.
Reference: [8] <author> Y. Yacoob and L. Davis, </author> <title> "Computing spatio-temporal representations of human faces," </title> <booktitle> in IEEE International Conference on Computer Vision, </booktitle> <address> (Cambridge, MA), </address> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1995, </year> <pages> pp. 70-75. </pages>
Reference-contexts: Most research on facial expression recognition is based only on non-rigid facial deformation patterns. Appearance variations due to facial expressions that are not well described by these motion fields are ignored. For example, these techniques use optical flow <ref> [7, 8] </ref>, 2-D graphical models ("Potential Nets") [9] and local parametric models [10, 11]. In this paper, we propose a probabilistic framework in which face models jointly capture information about facial appearance and expression patterns so that recognition of faces and facial expressions are carried at the same time.
Reference: [9] <author> K. Matsuno, C.-W. Lee, S. Kimura, and S. Tsuji, </author> <title> "Automatic recognition of human facial expres 6 sions," </title> <booktitle> in IEEE International Conference on Com--puter Vision, </booktitle> <address> (Cambridge, MA), </address> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1995, </year> <pages> pp. 352-358. </pages>
Reference-contexts: Most research on facial expression recognition is based only on non-rigid facial deformation patterns. Appearance variations due to facial expressions that are not well described by these motion fields are ignored. For example, these techniques use optical flow [7, 8], 2-D graphical models ("Potential Nets") <ref> [9] </ref> and local parametric models [10, 11]. In this paper, we propose a probabilistic framework in which face models jointly capture information about facial appearance and expression patterns so that recognition of faces and facial expressions are carried at the same time.
Reference: [10] <author> M. J. Black and Y. Yacoob, </author> <title> "Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motions," </title> <institution> Xerox Palo Alto Research Center, </institution> <type> Tech. Rep. </type> <institution> CS-TR-3401, </institution> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: Appearance variations due to facial expressions that are not well described by these motion fields are ignored. For example, these techniques use optical flow [7, 8], 2-D graphical models ("Potential Nets") [9] and local parametric models <ref> [10, 11] </ref>. In this paper, we propose a probabilistic framework in which face models jointly capture information about facial appearance and expression patterns so that recognition of faces and facial expressions are carried at the same time.
Reference: [11] <author> M. Black and Y. Yacoob, </author> <title> "Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motion," </title> <booktitle> in Proc. IEEE Int. Conf. Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: Appearance variations due to facial expressions that are not well described by these motion fields are ignored. For example, these techniques use optical flow [7, 8], 2-D graphical models ("Potential Nets") [9] and local parametric models <ref> [10, 11] </ref>. In this paper, we propose a probabilistic framework in which face models jointly capture information about facial appearance and expression patterns so that recognition of faces and facial expressions are carried at the same time.
Reference: [12] <author> A. Colmenarez, B. Frey, and T. Huang, </author> <title> "A real-time system for tracking multiple faces and facial features," </title> <note> in Submitted to CVPR, </note> <year> 1998. </year>
Reference-contexts: We compressed and stored the videos in MPEG1 format, 320 fi 240 color pixels, at 30 frames per seconds at an approximate rate of 1 Mbits/sec. segments and the result of our facial feature detection and tracking system <ref> [12, 13, 14] </ref>.
Reference: [13] <author> A. J. Colmenarez and T. S. Huang, </author> <title> "Pattern detection with information-based maximum discrimination and error bootstrapping," </title> <booktitle> in Proc. </booktitle> <address> ICPR, </address> <year> 1998. </year>
Reference-contexts: We compressed and stored the videos in MPEG1 format, 320 fi 240 color pixels, at 30 frames per seconds at an approximate rate of 1 Mbits/sec. segments and the result of our facial feature detection and tracking system <ref> [12, 13, 14] </ref>.
Reference: [14] <author> A. J. Colmenarez and T. S. Huang, </author> <title> "Face detection with information-based maximum discrimination," </title> <booktitle> in Proc. </booktitle> <address> CVPR, </address> <year> 1997. </year> <month> 7 </month>
Reference-contexts: We compressed and stored the videos in MPEG1 format, 320 fi 240 color pixels, at 30 frames per seconds at an approximate rate of 1 Mbits/sec. segments and the result of our facial feature detection and tracking system <ref> [12, 13, 14] </ref>.
References-found: 14

