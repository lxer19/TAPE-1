URL: http://www.speech.sri.com/people/zev/papers/euro97.ps
Refering-URL: http://www.speech.sri.com/people/zev/publications.html
Root-URL: 
Email: fzev,sankar,harryg@speech.sri.com  
Title: HMM STATE CLUSTERING ACROSS ALLOPHONE CLASS BOUNDARIES  
Author: Ze'ev Rivlin, Ananth Sankar, and Harry Bratt 
Address: Menlo Park, California 94025 U.S.A.  
Affiliation: Speech Technology And Research Laboratory SRI International  
Abstract: We present a novel approach to hidden Markov model (HMM) state clustering based on the use of broad phone classes and an allophone class entropy measure. Most state-of-the-art large-vocabulary speech recognizers are based on context-dependent (CD) phone HMMs that use Gaussian mixture models for the state-conditioned observation densities. A common approach for robust HMM parameter estimation is to cluster HMM states where each state cluster shares a set of parameters such as the components of a Gaussian mixture model. In all the current state clustering algorithms, the HMM states are clustered only within their respective allophone classes. While this makes some intuitive sense, it prevents the clustering of states across allophone class boundaries, even when the states are acoustically similar. Our algorithm allows clustering across allophone class boundaries by defining broad phone groups within which two states from different allophone classes can be clustered together. An allophone class entropy measure is used to control the clustering of states belonging to different allophone classes. Experimental results on three test sets are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Gauvain and C.-H. Lee, </author> <title> Bayesian Learning for Hidden Markov Models with Gaussian Mixture State Observation Densities, </title> <journal> Speech Communication, </journal> <volume> vol. 11, </volume> <year> 1992. </year>
Reference-contexts: Typically, such systems contain on the order of thousands of triphone models, and thus the amount of data for certain models often becomes too small to allow robust parameter estimation. Approaches to robust estimation of the CD HMM parameters include Bayesian smoothing techniques <ref> [1] </ref>, clustering of HMM models [2], and HMM state clustering [3, 4, 5]. The idea behind HMM state clustering is to cluster acoustically similar states and then train a separate set of Gaussians for each state cluster.
Reference: [2] <author> K. F. Lee, </author> <title> Automatic Speech Recognition The Development of the SPHINX System. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1989. </year>
Reference-contexts: Typically, such systems contain on the order of thousands of triphone models, and thus the amount of data for certain models often becomes too small to allow robust parameter estimation. Approaches to robust estimation of the CD HMM parameters include Bayesian smoothing techniques [1], clustering of HMM models <ref> [2] </ref>, and HMM state clustering [3, 4, 5]. The idea behind HMM state clustering is to cluster acoustically similar states and then train a separate set of Gaussians for each state cluster.
Reference: [3] <author> M.-Y. Hwang, X. Huang, and F. Alleva, </author> <title> Predicting Unseen Triphones With Senones, </title> <booktitle> in Proceedings IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pp. </pages> <address> II311 II314, </address> <year> 1993. </year>
Reference-contexts: Approaches to robust estimation of the CD HMM parameters include Bayesian smoothing techniques [1], clustering of HMM models [2], and HMM state clustering <ref> [3, 4, 5] </ref>. The idea behind HMM state clustering is to cluster acoustically similar states and then train a separate set of Gaussians for each state cluster. <p> The idea behind HMM state clustering is to cluster acoustically similar states and then train a separate set of Gaussians for each state cluster. The states in each cluster either share the same mixture Gaussian distributions <ref> [3, 4] </ref> or only share the same Gaussians but use different mixture weights for each state [5]. Sharing of parameters across acoustically similar states reduces the number of parameters to be estimated for the same amount of training data and level of acoustic resolution. <p> We define 38 allophone classes. The HMM states within each allophone class are clustered independently of the states in other allophone classes. Therefore, the resulting HMM state clusters only contain states from the same allophone class. This is also the case in other state clustering algorithms <ref> [3, 4] </ref>. However, as pointed out in Section 1, we believe that some states in different allophone classes are acoustically similar and thus should be allowed to cluster together. <p> We interpolate the two measures of entropy to trade off consideration of acoustic similarity and allophone class mixing in making the clustering decision. In contrast to our system, the algorithms presented in <ref> [3, 4, 5] </ref> do not allow cross-allophone-class clustering. Preliminary results on a WSJ test set were promising, but these results did not generalize to other test sets with which we experimented.
Reference: [4] <author> P. Woodland, J. Odell, V. Valtchev, and S. Young, </author> <title> Large Vocabulary Continuous Speech Recognition Using HTK, </title> <booktitle> in Proceedings IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pp. </pages> <address> II125 II128, </address> <year> 1994. </year>
Reference-contexts: Approaches to robust estimation of the CD HMM parameters include Bayesian smoothing techniques [1], clustering of HMM models [2], and HMM state clustering <ref> [3, 4, 5] </ref>. The idea behind HMM state clustering is to cluster acoustically similar states and then train a separate set of Gaussians for each state cluster. <p> The idea behind HMM state clustering is to cluster acoustically similar states and then train a separate set of Gaussians for each state cluster. The states in each cluster either share the same mixture Gaussian distributions <ref> [3, 4] </ref> or only share the same Gaussians but use different mixture weights for each state [5]. Sharing of parameters across acoustically similar states reduces the number of parameters to be estimated for the same amount of training data and level of acoustic resolution. <p> We define 38 allophone classes. The HMM states within each allophone class are clustered independently of the states in other allophone classes. Therefore, the resulting HMM state clusters only contain states from the same allophone class. This is also the case in other state clustering algorithms <ref> [3, 4] </ref>. However, as pointed out in Section 1, we believe that some states in different allophone classes are acoustically similar and thus should be allowed to cluster together. <p> We interpolate the two measures of entropy to trade off consideration of acoustic similarity and allophone class mixing in making the clustering decision. In contrast to our system, the algorithms presented in <ref> [3, 4, 5] </ref> do not allow cross-allophone-class clustering. Preliminary results on a WSJ test set were promising, but these results did not generalize to other test sets with which we experimented.
Reference: [5] <author> V. Digalakis, P. Monaco, and H. Murveit, Genones: </author> <title> Generalized Mixture Tying in Continuous Hidden Markov Model-Based Speech Recognizers, </title> <journal> IEEE Transactions on Speech and Audio Processing, </journal> <volume> vol. 4, no. 4, </volume> <pages> pp. 281289, </pages> <year> 1996. </year>
Reference-contexts: Approaches to robust estimation of the CD HMM parameters include Bayesian smoothing techniques [1], clustering of HMM models [2], and HMM state clustering <ref> [3, 4, 5] </ref>. The idea behind HMM state clustering is to cluster acoustically similar states and then train a separate set of Gaussians for each state cluster. <p> The states in each cluster either share the same mixture Gaussian distributions [3, 4] or only share the same Gaussians but use different mixture weights for each state <ref> [5] </ref>. Sharing of parameters across acoustically similar states reduces the number of parameters to be estimated for the same amount of training data and level of acoustic resolution. The result is more robust parameter estimation. <p> ALGORITHM DESCRIPTION The new state clustering algorithm is implemented within the context of SRI's DECIPHER T M speech recognition system. This system currently uses a bottom-up agglomerative state clustering algorithm. The state clusters share a set of Gaussian distributions (or codebook) referred to as a Genone <ref> [5] </ref>. Each state within a cluster has a unique set of mixture weights (mixture weight distribution) for these shared Gaussians. In the current DECIPHER T M system (our baseline), state clustering is permitted only within allophone classes. We define 38 allophone classes. <p> The simplest way to allow cross-allophone-class clustering is to create a single class containing all the HMM states and then perform agglomerative state clustering as in <ref> [5] </ref>. However, since the clustering algorithm needs to compute O (N 2 ) distances, where N is the number of states, increasing the class size dramatically increases the time to compute the state clusters. <p> However, there is a potential for added confusability in recognition between allophone classes when phone states from different classes now share parameters. We address this issue below. In the 38-class and 3-class systems described above, we use the weighted-by-counts increase in Gaussian mixture weight distribution entropy as defined in <ref> [5] </ref> to determine the distance between two state clusters S a and S b for potential merging to create the combined state cluster S. <p> The distance measure is d 1 (S a ; S b ) = (1) where H 1 (S) is the entropy of the Gaussian mixture weight distribution <ref> [5] </ref>, and n a and n b are the counts from state clusters S a and S b , respectively. <p> In both cases, the states in each broad phone class were clustered using the agglomerative clustering algorithm, and separate Gaussian densities were trained for each state cluster as in <ref> [5] </ref>. All three acoustic models had roughly 2000 genones. Experiments were performed using these acoustic models on a test set derived from the Wall Street Journal (WSJ) corpus [6] and gave encouraging preliminary experimental results. <p> We interpolate the two measures of entropy to trade off consideration of acoustic similarity and allophone class mixing in making the clustering decision. In contrast to our system, the algorithms presented in <ref> [3, 4, 5] </ref> do not allow cross-allophone-class clustering. Preliminary results on a WSJ test set were promising, but these results did not generalize to other test sets with which we experimented.
Reference: [6] <author> G. Doddington, </author> <title> CSR Corpus Development, </title> <booktitle> in Proc. DARPA SLS Workshop, </booktitle> <pages> pp. 363366, </pages> <year> 1992. </year>
Reference-contexts: All three acoustic models had roughly 2000 genones. Experiments were performed using these acoustic models on a test set derived from the Wall Street Journal (WSJ) corpus <ref> [6] </ref> and gave encouraging preliminary experimental results. Further experimentation was then performed on another WSJ test set and a test set derived from the North American Business News Corpora (NABN), but improvement in recognition performance was not observed for these tests. Results are reported in Section 3. 3.
Reference: [7] <author> H. Murveit, J. Butzberger, V. Digalakis, and M. Weintraub, </author> <title> Large-Vocabulary Dictation Using SRI's DECIPHER(TM) Speech Recognition System: </title> <booktitle> Progressive-Search Techniques, in Proceedings IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pp. </pages> <address> II319II322, </address> <year> 1993. </year>
Reference-contexts: A 20,000-word bigram language model was used for this test. This test set is denoted as `WSJ-A'. We ran recognition experiments by rescoring word lattices <ref> [7] </ref> that were generated using the bigram language model and a previously trained acoustic model. The lattices were rescored to determine the best recognition hypothesis with the baseline acoustic model and the two new acoustic models.
Reference: [8] <author> D. S. Pallet, J. G. Fiscus, W. M. Fisher, J. S. Garofolo, B. A. Lund, A. Martin, and M. A. Przybocki, </author> <title> 1994 Benchmark Tests for the ARPA Spoken Language Program, </title> <booktitle> in Proceedings of the Spoken Language Systems Technology Workshop, </booktitle> <pages> pp. 536, </pages> <year> 1995. </year>
Reference-contexts: The first of these two is a 10-speaker male subset of the 1994 WSJ S0 development set <ref> [8] </ref> containing 209 sentences. A 5000-word bigram language model was used for this task. This test set is denoted `WSJS0-DEV94'. The other test set is the Sennheiser microphone portion of the 1995 HUB3 NABN development set [9] denoted `NABN-DEV95'.
Reference: [9] <author> R. Stern, </author> <title> Specification of the 1996 Hub4 Broadcast News Evaluation, </title> <booktitle> in Proceedings of the DARPA Speech Recognition Workshop, </booktitle> <address> (Chantilly, VA), </address> <year> 1997. </year>
Reference-contexts: A 5000-word bigram language model was used for this task. This test set is denoted `WSJS0-DEV94'. The other test set is the Sennheiser microphone portion of the 1995 HUB3 NABN development set <ref> [9] </ref> denoted `NABN-DEV95'. As seen in Table 1, we did not get an improved performance for either of these other two test sets. One possible reason for this is the following. Introducing the allophone class entropy can be thought of as imposing a penalty for clustering across allophone class boundaries.
References-found: 9

