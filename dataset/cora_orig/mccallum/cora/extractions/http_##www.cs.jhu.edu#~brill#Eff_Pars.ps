URL: http://www.cs.jhu.edu/~brill/Eff_Pars.ps
Refering-URL: http://www.cs.jhu.edu/~brill/acadpubs.html
Root-URL: http://www.cs.jhu.edu
Email: satta@dei.unipd.it  brill@cs.jhu.edu  
Title: Efficient Transformation-Based Parsing  
Author: Giorgio Satta Eric Brill 
Address: via Gradenigo, 6/A I-35131 Padova, Italy  Baltimore, MD 21218-2694  
Affiliation: Dipartimento di Elettronica ed Informatica Universita di Padova  Department of Computer Science Johns Hopkins University  
Abstract: In transformation-based parsing, a finite sequence of tree rewriting rules are checked for application to an input structure. Since in practice only a small percentage of rules are applied to any particular structure, the naive parsing algorithm is rather inefficient. We exploit this sparseness in rule applications to derive an algorithm two to three orders of magnitude faster than the standard parsing algorithm.
Abstract-found: 1
Intro-found: 1
Reference: <author> Aho, A. V. and M. Corasick. </author> <year> 1975. </year> <title> Efficient string matching: An aid to bibliographic search. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 18(6) </volume> <pages> 333-340. </pages>
Reference-contexts: The algorithm presented here might then be a good compromise between fast parsing and reasonable space requirements. When restricted to monadic trees, our automaton A G comes down to the finite state device used in the well-known string pattern matching algorithm of Aho and Corasick (see <ref> (Aho and Corasick, 1975) </ref>), requiring linear space only.
Reference: <author> Baeten, J., J. Bergstra, and J. Klop. </author> <year> 1987. </year> <title> Priority rewrite systems. </title> <booktitle> In Proc. Second International Conference on Rewriting Techniques and Applications, </booktitle> <volume> LNCS 256, </volume> <pages> pages 83-94, </pages> <address> Berlin, Germany. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The idea of imposing a total order on the rules of a term-rewriting system can be found in the literature, but in these cases all rules are reconsidered for application at each step in the rewriting, using their priority (see for instance the priority term-rewriting systems <ref> (Baeten, Bergstra, and Klop, 1987) </ref>). Therefore these systems allow recursion. There are cases in which a critical rule in a TTS does not give rise to order-dependency in rewriting.
Reference: <author> Brill, E. </author> <year> 1993. </year> <title> Automatic grammar induction and parsing free text: A transformation-based approach. </title> <booktitle> In Proceedings of the 31st Meeting of the Association of Computational Linguistics, </booktitle> <address> Colum-bus, Oh. </address>
Reference-contexts: In this paper we consider transformation-based parsing, introduced in <ref> (Brill, 1993) </ref>, and we improve upon the O (n) time upper bound. In transformation-based parsing, an ordered sequence of tree-rewriting rules (tree transformations) are applied to an initial parse structure for an input sentence, to derive the final parse structure. <p> We observe that in most transformation-based parsers, only a small percentage of rules are actually applied, for any particular input sentence. For example, in an application of the transformation-based parser described in <ref> (Brill, 1993) </ref>, = 300 rules were learned, to be applied at each node of the initial parse structure, but the average number of rules that are successfully applied at each node is only about one. <p> that when we restrict to monadic trees, that is trees whose nodes have degree not greater than one, the above definitions correspond to the well known formalisms of deterministic finite state automata, the associated extended transition function, and the regular languages. 2.3 Transformation-based parsing Transformation-based parsing was first introduced in <ref> (Brill, 1993) </ref>. Informally, a transformation-based parser assigns to an input sentence an initial parse structure, in some uniform way. Then the parser iteratively checks an ordered sequence of tree transformations for application to the initial parse tree, in order to derive the final parse structure.
Reference: <author> Brill, E. </author> <year> 1995. </year> <title> Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging. </title> <note> Computational Linguistics. </note>
Reference: <author> Brill, E. and P. Resnik. </author> <year> 1994. </year> <title> A transformation-based approach to prepositional phrase attachment disambiguation. </title> <booktitle> In Proceedings of the Fifteenth International Conference on Computational Linguistics (COLING-1994), </booktitle> <address> Kyoto, Japan. </address>
Reference-contexts: More recently, transformations have been applied to a diverse set of problems, including part of speech tagging, pronunciation network creation, prepositional phrase attachment disambiguation, and parsing, under the paradigm of transformation-based error-driven learning (see (Brill, 1993; Brill, 1995) and <ref> (Brill and Resnik, 1994) </ref>). In this paradigm, rules can be learned automatically from a training corpus, instead of being written by hand. Transformation-based systems are typically deterministic.
Reference: <author> Chomsky, N. </author> <year> 1965. </year> <title> Aspects of the Theory of Syntax. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: 1 Introduction The idea of using transformational rules in natural language analysis dates back at least to Chom-sky, who attempted to define a set of transformations that would apply to a word sequence to map it from deep structure to surface structure (see <ref> (Chomsky, 1965) </ref>). Transformations have also been used in much of generative phonology to capture contextual variants in pronunciation, starting with (Chomsky and Halle, 1968).
Reference: <author> Chomsky, N. and M. Halle. </author> <year> 1968. </year> <title> The Sound Pattern of English. </title> <publisher> Harper and Row. </publisher>
Reference-contexts: Transformations have also been used in much of generative phonology to capture contextual variants in pronunciation, starting with <ref> (Chomsky and Halle, 1968) </ref>. More recently, transformations have been applied to a diverse set of problems, including part of speech tagging, pronunciation network creation, prepositional phrase attachment disambiguation, and parsing, under the paradigm of transformation-based error-driven learning (see (Brill, 1993; Brill, 1995) and (Brill and Resnik, 1994)).
Reference: <author> Cormen, T. H., C. E. Leiserson, and R. L. Rivest. </author> <year> 1990. </year> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Dershowitz, N. and J. Jouannaud. </author> <year> 1990. </year> <title> Rewrite systems. </title> <editor> In J. Van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume B. </booktitle> <publisher> Else-vier and The MIT Press, </publisher> <address> Amsterdam, The Nether-lands and Cambridge, MA, chapter 6, </address> <pages> pages 243-320. </pages>
Reference-contexts: Therefore these systems allow recursion. There are cases in which a critical rule in a TTS does not give rise to order-dependency in rewriting. Methods for deciding the confluency property for a term-rewriting system with critical pairs (see <ref> (Dershowitz and Jouannaud, 1990) </ref> for definitions and an overview) can also be used to detect the above cases for TTS. As already pointed out, the translation problem investigated here is closely related with the standard tree pattern matching problem.
Reference: <author> Dubiner, M., Z. Galil, and E. Magen. </author> <year> 1994. </year> <title> Faster tree pattern matching. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 41(2) </volume> <pages> 205-213. </pages>
Reference-contexts: Polynomial space requirements can be guaranteed if one switches to top-down tree pattern matching algorithms. One such a method is reported in (Hoff-mann and O'Donnell, 1982), but in this case the running-time of Algorithm 1 cannot be maintained. Faster top-down matching algorithms have been reported in (Kosaraju, 1989) and <ref> (Dubiner, Galil, and Magen, 1994) </ref>, but these methods seems impractical, due to very large hidden constants. A tree-based extension of the very fast algorithm described in (Roche and Schabes, 1995) is in principle possible for transformation-based parsing, but is likely to result in huge space requirements and seems impractical.
Reference: <author> Hoffmann, C. M. and M. J. O'Donnell. </author> <year> 1982. </year> <title> Pattern matching in trees. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 29(1) </volume> <pages> 68-95. </pages>
Reference: <author> Janssens, D. and G. Rozenberg. </author> <year> 1982. </year> <title> Graph grammars with neighbourhood-controlled embedding. </title> <journal> Theoretical Computer Science, </journal> <volume> 21 </volume> <pages> 55-74. </pages>
Reference-contexts: There are several alternative ways in which one could see transformation-based rewriting systems. TTS's are closely related to a class of graph rewriting systems called neighbourhood-controlled embedding graph grammars (NCE grammars; see <ref> (Janssens and Rozenberg, 1982) </ref>). In fact our definition of the r;n relation and of the underlying [=] operator has been inspired by similar definitions in the NCE formalism.
Reference: <author> Kaplan, R. M. and M. Kay. </author> <year> 1994. </year> <title> Regular models of phonological rule sistems. </title> <journal> Computational Linguistics, </journal> <volume> 20(3) </volume> <pages> 331-378. </pages>
Reference-contexts: This results in a deterministic, linear time parser. In order to present our algorithm, we abstract away from the assignment of the initial parse to the input, and introduce below the notion of transformation-based tree rewriting system. The formulation we give here is inspired by <ref> (Kaplan and Kay, 1994) </ref> and (Roche and Schabes, 1995). The relationship between transformation-based tree rewriting systems and standard term-rewriting systems will be discussed in the final section.
Reference: <author> Kosaraju, S. R. </author> <year> 1989. </year> <title> Efficient tree-pattern matching. </title> <booktitle> In Proceedings of the 30 Conference on Foundations of Computer Science (FOCS), </booktitle> <pages> pages 178-183. </pages>
Reference-contexts: Polynomial space requirements can be guaranteed if one switches to top-down tree pattern matching algorithms. One such a method is reported in (Hoff-mann and O'Donnell, 1982), but in this case the running-time of Algorithm 1 cannot be maintained. Faster top-down matching algorithms have been reported in <ref> (Kosaraju, 1989) </ref> and (Dubiner, Galil, and Magen, 1994), but these methods seems impractical, due to very large hidden constants.
Reference: <author> Roche, E. and Y. Schabes. </author> <year> 1995. </year> <title> Deterministic part of speech tagging with finite state transducers. </title> <note> Computational Linguistics. </note>
Reference-contexts: While this results in fast processing, it is possible to create much faster systems. In <ref> (Roche and Schabes, 1995) </ref>, a method is described for converting a list of transformations that operates on strings into a deterministic finite state transducer, resulting in an optimal tagger in the sense that tagging requires only one state transition per word, giving a linear time tag-ger whose run-time is independent of <p> In order to present our algorithm, we abstract away from the assignment of the initial parse to the input, and introduce below the notion of transformation-based tree rewriting system. The formulation we give here is inspired by (Kaplan and Kay, 1994) and <ref> (Roche and Schabes, 1995) </ref>. The relationship between transformation-based tree rewriting systems and standard term-rewriting systems will be discussed in the final section. <p> Faster top-down matching algorithms have been reported in (Kosaraju, 1989) and (Dubiner, Galil, and Magen, 1994), but these methods seems impractical, due to very large hidden constants. A tree-based extension of the very fast algorithm described in <ref> (Roche and Schabes, 1995) </ref> is in principle possible for transformation-based parsing, but is likely to result in huge space requirements and seems impractical. The algorithm presented here might then be a good compromise between fast parsing and reasonable space requirements. <p> If space requirements are of primary importance or when the rule set is very large, our method can then be considered for string-based transformation rewriting as an alternative to the already mentioned method in <ref> (Roche and Sch-abes, 1995) </ref>, which is faster but has more onerous space requirements. Acknowledgements The present research was done while the first author was visiting the Center for Language and Speech Processing, Johns Hopkins University, Baltimore, MD.
Reference: <author> Thatcher, J. W. </author> <year> 1967. </year> <title> Characterizing derivation trees of context-free grammars through a generalization of finite automata theory. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 1 </volume> <pages> 317-322. </pages>
Reference-contexts: Note that S and S 0 have the same number of leaves. Then we have T 0 = T [S=S 0 ]. 2 2.2 Tree automata Deterministic (bottom-up) tree automata were first introduced in <ref> (Thatcher, 1967) </ref> (called FRT there). The definition we propose here is a generalization of the canonical one to trees of any degree. Note that the transition function below is computed on a number of states that is independent of the degree of the input tree.
References-found: 16

