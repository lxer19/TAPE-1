URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/thrun/papers/mitchell.EBL-ml93.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/thrun/papers/full.html
Root-URL: http://www.cs.cmu.edu
Email: Tom.Mitchell@cs.cmu.edu  Thrun@uran.informatik.uni-bonn.de  
Title: Explanation Based Learning: A Comparison of Symbolic and Neural Network Approaches  
Author: Tom M. Mitchell Sebastian B. Thrun 
Note: To appear in Machine Learning: Proceedings of the Tenth International Conference, Morgan Kauffman,  
Address: Pittsburgh, PA 15213  Romerstr. 164, D-5300 Bonn, Germany  San Mateo, CA, 1993.  
Affiliation: School of Computer Science Carnegie Mellon University  University of Bonn Institut fur Informatik III  
Abstract: Explanation based learning has typically been considered a symbolic learning method. An explanation based learning method that utilizes purely neural network representations (called EBNN) has recently been developed, and has been shown to have several desirable properties, including robustness to errors in the domain theory. This paper briefly summarizes the EBNN algorithm, then explores the correspondence between this neural network based EBL method and EBL methods based on symbolic representations.
Abstract-found: 1
Intro-found: 1
Reference: [ DeJong and Mooney, 1986 ] <author> Gerald DeJong and Raymond Mooney. </author> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2) </volume> <pages> 145-176, </pages> <year> 1986. </year>
Reference: [ Fu, 1989 ] <author> Li-Min Fu. </author> <title> Integration of neural heuristics into knowledge-based inference. </title> <journal> Connection Science, </journal> <volume> 1(3) </volume> <pages> 325-339, </pages> <year> 1989. </year>
Reference-contexts: All curves are averaged over 3 learning runs and are also locally window-averaged. ductive learning, which do not involve explaining individual training examples, and which are therefore outside the scope of this discussion. These include, for example, Shavlik's [ Shavlik and Towell, 1989 ] and Fu's <ref> [ Fu, 1989 ] </ref> ) methods for using symbolically encoded domain knowledge to initialize the topology and weights of neural networks which are then inductively refined. 3.1 The Explanation-Based Learning Problem The common problem addressed by the symbolic Prolog-EBG method and the neural network EBNN method can be characterized as follows:
Reference: [ Kedar-Cabelli and McCarty, 1987 ] <author> Smadar Kedar-Cabelli and Thorne McCarty. </author> <title> Explanation based learning as resolution theorem proving. </title> <booktitle> In Proceedings of the fourth international workshop on machine learning, </booktitle> <pages> pages 383-389, </pages> <address> Irvine, CA, 1987. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The goal of this paper is to examine the correspondence between EBL methods based on symbolic and neural network representations. To ground the comparison, we consider two specific algorithms: a prototypical pure symbolic EBL algorithm, Prolog-EBG <ref> [ Kedar-Cabelli and McCarty, 1987 ] </ref> , and explanation based neural network learning, EBNN. We first present an overview of the EBNN algorithm. Following this we define the abstract EBL problem and EBL method that is common to both symbolic and neural network approaches. <p> We then explore the specific differences between these two algorithms, and the significant impact that these algorithmic differences have on their relative capabilities. While there are many variants of symbolic EBL, for the purposes of grounding the discussion we will consider only one prototypical algorithm: Prolog-EBG, as described in <ref> [ Kedar-Cabelli and McCarty, 1987 ] </ref> . Furthermore, while both neural networks and nearest-neighbor schemes have been used to represent the target function in EBNN, in this discussion we assume the target function is rep resented by a neural network.
Reference: [ Laird et al., 1988 ] <author> John Laird, Paul Rosenbloom, and Allen Newell. </author> <title> Chunking in SOAR: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 11-46, </pages> <year> 1988. </year>
Reference-contexts: EBL was originally conceived as a symbolic learning method ( [ De-Jong and Mooney, 1986 ] , [ Mitchell et al., 1986 ] ), based on creating and analyzing explanations derived from symbolic rules. While it has been used successfully to learn control knowledge to speed up search ( <ref> [ Laird et al., 1988 ] </ref> , [ Minton, 1988 ] ), the chief limit to its usefulness lies in the requirement that its prior knowledge, or domain theory, be complete and correct.
Reference: [ Machine Learning Workshop, 1989 ] <editor> Workshop on combining empirical and explanation-based learning. In Al-berto M. Segre, editor, </editor> <booktitle> Proceedings of the sixth international workshop on machine learning, </booktitle> <pages> pages 1-93, </pages> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Recent research has produced a number of proposals for extending EBL approaches to accommodate imperfect domain theories (e.g., for several dozen, see the Workshop of Combining Inductive and Analytical Learning <ref> [ Machine Learning Workshop, 1989 ] </ref> ). Despite progress in this area, we still have not found the final answer to the question of how to best unify EBL and inductive learning. <p> Strictly speaking, Prolog-EBG is used only when the training examples are consistent with the domain theory, and it therefore produces learned rules that constitute a perfect fit to both the domain theory and observed examples. However, much current work on symbolic EBL (e.g., <ref> [ Machine Learning Workshop, 1989 ] </ref> , [ Mooney and Ourston, 1989 ] , [ Pazzani, 1989 ] ) deals with the same class of situations as EBNN: situations in which the observed training examples are not strictly entailed by the domain theory, and for which the goal is therefore to
Reference: [ Minton, 1988 ] <author> Steven Minton. </author> <title> Learning Search Control Knowledge: An Explanation-Based Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: While it has been used successfully to learn control knowledge to speed up search ( [ Laird et al., 1988 ] , <ref> [ Minton, 1988 ] </ref> ), the chief limit to its usefulness lies in the requirement that its prior knowledge, or domain theory, be complete and correct.
Reference: [ Mitchell and Thrun, 1993 ] <author> Tom M. Mitchell and Sebas-tian B. Thrun. </author> <title> Explanation-based neural network learning for robot control. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <address> San Mateo, CA, </address> <year> 1993. </year> <note> Morgan Kaufmann. (to appear). </note>
Reference-contexts: Despite progress in this area, we still have not found the final answer to the question of how to best unify EBL and inductive learning. An explanation based learning method based purely on neural network representations has recently been proposed <ref> [ Mitchell and Thrun, 1993 ] </ref> , [ Thrun and Mitchell, 1993 ] , which provides a means of combining an inductive learning component (neural network Backpropagation) with an explanation based learning component. <p> Additional details regarding the algorithm and the experimental results are available in [ Thrun and Mitchell, 1993 ] and <ref> [ Mitchell and Thrun, 1993 ] </ref> . Note this section is a summary extracted from those papers. produce the final state s n , a goal state. The domain knowledge represented by neural networks can be used to explain how the observed state-action sequence resulted in achieving the goal. <p> This results in a fairly ac curate, but still imperfect, domain theory, which was 3 We will omit the somewhat lengthy details here, since they are not essential for the understanding of EBNN. See [ Thrun and Mitchell, 1993 ] and <ref> [ Mitchell and Thrun, 1993 ] </ref> for a detailed description. then used by EBNN. The results of EBNN are shown by the thick black line in Figure 4. In contrast, the results of applying standard inductive learning (Backpropagation) are shown by the line marked "without analytical learning".
Reference: [ Mitchell et al., 1986 ] <author> Tom M. Mitchell, Rich Keller, and Smadar Kedar-Cabelli. </author> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 47-80, </pages> <year> 1986. </year>
Reference-contexts: 1 Introduction Explanation based learning (EBL) is an important paradigm for machine learning because it offers a means of using prior knowledge to generalize more correctly from fewer training examples. EBL was originally conceived as a symbolic learning method ( [ De-Jong and Mooney, 1986 ] , <ref> [ Mitchell et al., 1986 ] </ref> ), based on creating and analyzing explanations derived from symbolic rules.
Reference: [ Mooney and Ourston, 1989 ] <author> Raymond Mooney and Dirk Ourston. </author> <title> Induction over the unexplained: Integrated learning of concepts with both explainable and conventional aspects. </title> <editor> In Alberto M. Segre, editor, </editor> <booktitle> Proceedings of the sixth international workshop on machine learning, </booktitle> <pages> pages 5-7, </pages> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, much current work on symbolic EBL (e.g., [ Machine Learning Workshop, 1989 ] , <ref> [ Mooney and Ourston, 1989 ] </ref> , [ Pazzani, 1989 ] ) deals with the same class of situations as EBNN: situations in which the observed training examples are not strictly entailed by the domain theory, and for which the goal is therefore to learn a function that best fits both
Reference: [ Pazzani, 1989 ] <author> Michael J. Pazzani. </author> <title> Detecting and correcting errors of omission after explanation-based learning. </title> <booktitle> In Proceedings of IJCAI-89, </booktitle> <pages> pages 713-718, </pages> <year> 1989. </year>
Reference-contexts: However, much current work on symbolic EBL (e.g., [ Machine Learning Workshop, 1989 ] , [ Mooney and Ourston, 1989 ] , <ref> [ Pazzani, 1989 ] </ref> ) deals with the same class of situations as EBNN: situations in which the observed training examples are not strictly entailed by the domain theory, and for which the goal is therefore to learn a function that best fits both the imperfect domain theory and the observed
Reference: [ Rumelhart et al., 1986 ] <author> David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart and J. L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing. </booktitle> <volume> Vol. I + II. </volume> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: By using neural network learning algorithms such as the Backpropagation procedure <ref> [ Rumelhart et al., 1986 ] </ref> , the domain theory can be learned from scratch and does not require the availability of a priori knowledge from a human trainer. <p> Symbolic EBL procedures have been demonstrated to acquire new features analytically, as a side-effect of extracting weakest preconditions (e.g., [ Ut-goff, 1986 ] ). In contrast, Backpropagation neural net learning has been demonstrated to acquire useful new features inductively, in the hidden layer units of the network (e.g., <ref> [ Rumelhart et al., 1986 ] </ref> ). In EBNN, both analytical and inductive components have an influence on the features that are acquired in the hidden layer of the target function.
Reference: [ Shavlik and Towell, 1989 ] <author> Jude W. Shavlik and G.G. Towell. </author> <title> An approach to combining explanation-based and neural learning algorithms. </title> <journal> Connection Science, </journal> <volume> 1(3) </volume> <pages> 231-253, </pages> <year> 1989. </year>
Reference-contexts: All curves are averaged over 3 learning runs and are also locally window-averaged. ductive learning, which do not involve explaining individual training examples, and which are therefore outside the scope of this discussion. These include, for example, Shavlik's <ref> [ Shavlik and Towell, 1989 ] </ref> and Fu's [ Fu, 1989 ] ) methods for using symbolically encoded domain knowledge to initialize the topology and weights of neural networks which are then inductively refined. 3.1 The Explanation-Based Learning Problem The common problem addressed by the symbolic Prolog-EBG method and the neural
Reference: [ Simard et al., 1992 ] <author> Patrice Simard, Bernard Victorri, Yann LeCun, and John Denker. </author> <title> Tangent prop a formalism for specifying selected invariances in an adaptive network. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lipp-mann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 895-903, </pages> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We also experimented with a nearest neighbor representation of the target function. if slopes are sufficiently accurate. In the case that the target function is represented by a neural network, the Backpropagation algorithm can be extended to fit slopes as well as values, as may be found in <ref> [ Simard et al., 1992 ] </ref> .
Reference: [ Sutton, 1988 ] <author> Richard S. Sutton. </author> <title> Learning to predict by the methods of temporal differences. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <year> 1988. </year>
Reference-contexts: In order to allow exploration of the robot environment and to compensate for the necessary non-optimal action choices, we applied EBNN to Watkins' Q-Learning [ Watkins, 1989 ] together with Sutton's temporal difference learning T D () <ref> [ Sutton, 1988 ] </ref> (with = 0:7 and a reward discount fl = 0:8) 3 . Each discrete action was modeled by a separate neural network. We used neural network Backpropagation learning for learning action models.
Reference: [ Thrun and Mitchell, 1993 ] <author> Sebastian B. Thrun and Tom M. Mitchell. </author> <title> Integrating inductive neural network learning and explanation-based learning. </title> <journal> Proceedings of the IJCAI, </journal> <note> to appear, </note> <year> 1993. </year>
Reference-contexts: Despite progress in this area, we still have not found the final answer to the question of how to best unify EBL and inductive learning. An explanation based learning method based purely on neural network representations has recently been proposed [ Mitchell and Thrun, 1993 ] , <ref> [ Thrun and Mitchell, 1993 ] </ref> , which provides a means of combining an inductive learning component (neural network Backpropagation) with an explanation based learning component. <p> Additional details regarding the algorithm and the experimental results are available in <ref> [ Thrun and Mitchell, 1993 ] </ref> and [ Mitchell and Thrun, 1993 ] . Note this section is a summary extracted from those papers. produce the final state s n , a goal state. <p> This results in a fairly ac curate, but still imperfect, domain theory, which was 3 We will omit the somewhat lengthy details here, since they are not essential for the understanding of EBNN. See <ref> [ Thrun and Mitchell, 1993 ] </ref> and [ Mitchell and Thrun, 1993 ] for a detailed description. then used by EBNN. The results of EBNN are shown by the thick black line in Figure 4.
Reference: [ Utgoff, 1986 ] <author> Paul E. Utgoff. </author> <title> Machine Learning of Inductive Bias. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1986. </year>
Reference: [ Watkins, 1989 ] <author> Chris J. C. H. Watkins. </author> <title> Learning from Delayed Rewards. </title> <type> PhD thesis, </type> <institution> King's College, </institution> <address> Cambridge, England, </address> <year> 1989. </year>
Reference-contexts: Note that the world is deterministic in these experiments, and there is no sensor noise. In order to allow exploration of the robot environment and to compensate for the necessary non-optimal action choices, we applied EBNN to Watkins' Q-Learning <ref> [ Watkins, 1989 ] </ref> together with Sutton's temporal difference learning T D () [ Sutton, 1988 ] (with = 0:7 and a reward discount fl = 0:8) 3 . Each discrete action was modeled by a separate neural network. We used neural network Backpropagation learning for learning action models.
References-found: 17

