URL: http://www.cs.nmsu.edu/~jcook/papers/vjournal.ps.gz
Refering-URL: http://www.cs.nmsu.edu/~jcook/papers/
Root-URL: http://www.cs.nmsu.edu
Email: fjcook,alwg@cs.colorado.edu  
Title: Software Process Validation: Quantitatively Measuring the Correspondence of a Process to a Model Using Event-Based Data  
Author: Jonathan E. Cook and Alexander L. Wolf 
Address: Boulder, CO 80309 USA  
Affiliation: Software Engineering Research Laboratory Department of Computer Science University of Colorado  
Date: November 1, 1996 13:52  
Note: DRAFT:  This work was supported in part by the National Science Foundation under grant CCR-93-02739 and the Air Force Material Command, Rome Laboratory, and the Advanced Research Projects Agency under Contract Number F30602-94-C-0253. The content of the information does not necessarily reflect the position or the policy of the Government and no official endorsement should be inferred.  
Abstract: University of Colorado Department of Computer Science Technical Report CU-CS-8??-96 November 1996 To a great extent, the usefulness of a formal model of a software process lies in its ability to accurately predict the behavior of the executing process. Similarly, the usefulness of an executing process lies largely in its ability to fulfill the requirements embodied in a formal model of the process. When process models and process executions diverge, something significant is happening. We have developed techniques for uncovering and measuring the discrepancies between models and executions, which we call process validation. Process validation takes a process execution and a process model, and measures the level of correspondence between the two. Our metrics our tailorable and give the engineers control over determining the severity of different types of discrepancies. The metrics are also hierarchical, providing detailed information once a high-level measurement indicates the presence of a problem. We have applied our process validation methods in a real-world, industrial study, of which a small portion is highlighted in this paper. The success of our techniques lead us to view this work as a first step toward a suite of useful methods for process validation. c fl 1996 Jonathan E. Cook and Alexander L. Wolf
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.V. Aho and T.G. Peterson. </author> <title> A minimum distance error-correcting parser for context-free languages. </title> <journal> SIAM Journal on Computing, </journal> <volume> 1(4) </volume> <pages> 305-312, </pages> <month> December </month> <year> 1972. </year>
Reference-contexts: Methods that can compare a model directly with some event stream are also available, but our abstraction away from this is more generalizable. Error-correcting parsers <ref> [1] </ref>, for example, have techniques in which they add error productions to the regular grammar production rules to catch deviations from the expected grammar's syntax. This could be instrumented with measurements, but it is specific to grammar formalisms. <p> Once this symbol is found, the current parse stack is popped until that symbol can be accepted. This method assumes the language has such a set of special symbols, and it makes no attempt at a minimal recovery, only deleting symbols until it can recover. * Aho and Peterson <ref> [1] </ref> show a cubic algorithm for performing global minimum cost error correction in terms of token insertion and deletion. They augment the language grammar with error productions, and modify the parse algorithm to do corrections.
Reference: [2] <author> A. Apostolico, M.J. Atallah, L.L. Larmore, and S. McFaddin. </author> <title> Efficient parallel algorithms for string editing and related problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 19(5) </volume> <pages> 968-988, </pages> <year> 1990. </year>
Reference-contexts: Previous work in other areas using string distance measures have also found the need for per-symbol weights <ref> [2, 37] </ref>. 6.2 Usability Enhancements The simple and non-linear string distance metrics are naturally decomposable in a hierarchical fashion, to be able to give more information about the measurement than just one number for the whole process model.
Reference: [3] <author> G.S. Avrunin, U.A. Buy, J.C. Corbett, L.K. Dillon, and J.C. Wileden. </author> <title> Automated analysis of concurrent systems with the constrained expression toolset. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(11) </volume> <pages> 1204-1222, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: Using event data to characterize behavior is widely accepted in other areas of software engineering, such as program visualization [42], concurrent-system analysis <ref> [3] </ref>, and distributed debugging [10, 19]. We feel it is applicable to software process as well. 4 Model Events Collected Events Execution Events 2.1 Relating Models and Events: Event Sites For our work in process validation, we focus on behavior formalisms in process modeling languages. <p> If models do not have regularity in the state space, they admit that their techniques will not provide much leverage. Another example that more directly is concerned with matching a behavior to a model is Constrained Expressions <ref> [3, 21] </ref>. This is an elegant method that, given a model, a current simulation state of that model, and a desired event, can answer the question "Can this event be produced in the future?".
Reference: [4] <author> S. Bandinelli, A. Fuggetta, and C. Ghezzi. </author> <title> Software Process Model Evolution in the SPADE Environe-ment. </title> <journal> IEEE Transactions on Software Engineering, </journal> 19(12) 1128-1144, December 1993. 
Reference-contexts: Even if one could completely enforce a process, there still remains the issue of managing change in a process, which might lead to a discrepancy between the model and the execution. There has, in fact, been considerable recent work that addresses process evolution <ref> [4, 35] </ref>. Commensurate with the historical approach mentioned above, that work is concerned more with the problem of effecting changes to a process model used for automation, than it is with the problem of uncovering inconsistencies between the model and the execution.
Reference: [5] <author> S. Bandinelli, A. Fuggetta, C. Ghezzi, and L. Lavazza. SPADE: </author> <title> An Environment for Software Process, Analysis, Design, </title> <editor> and Enactment. In A. Finkelstein, J. Kramer, and B. Nuseibeh, editors, </editor> <booktitle> Software Process Modeling and Technology, </booktitle> <pages> pages 223-248. </pages> <publisher> Wiley, </publisher> <year> 1994. </year>
Reference-contexts: We feel it is applicable to software process as well. 4 Model Events Collected Events Execution Events 2.1 Relating Models and Events: Event Sites For our work in process validation, we focus on behavior formalisms in process modeling languages. Examples are the Petri net foundation in Slang <ref> [5] </ref>, the generic state machines, and the more specific state language Statecharts [32]. In viewing a process execution as an event stream, we are assuming that a process model has some way of producing an event stream if it was "executed".
Reference: [6] <author> S. Bandinelli, C. Ghezzi, and A. Morzenti. </author> <title> A Multi-Paradigm Petri Net Based Approach to Process Description. </title> <booktitle> In Proceedings of the 7th International Software Process Workshop, </booktitle> <pages> pages 41-43, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: These include models based on state machines (e.g., Statemate [33]), Petri nets (e.g., Slang <ref> [6] </ref> and FUNSOFT Nets [31]), and procedural languages (e.g., APPL/A [53]). 4.1 Recognition Metric The first metric is a very straightforward one that has just two values, true or false. The value is true if the event streams exactly match and is false otherwise.
Reference: [7] <author> V.R. Basili and D.M. Weiss. </author> <title> A methodology for collecting valid software engineering data. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 10(6) </volume> <pages> 728-737, </pages> <year> 1984. </year>
Reference-contexts: They applied Amadeus to automatically building classification trees that describe what properties of a source code module are likely to lead to faults in the module. However, Amadeus itself is a generic data collection and activity automation system. * Basili and Weiss <ref> [7] </ref> describe a methodology for selecting metrics and data collection techniques based on the goals that are desired of the measurement activity. Their work also focuses on using product data, such as code modifications and change classification.
Reference: [8] <author> P. Bates. </author> <title> EBBA modelling tool a.k.a. event definition language. </title> <type> Technical Report COINS-87-35, </type> <institution> University of Massachusetts at Amherst, </institution> <year> 1987. </year>
Reference-contexts: process improvement by raising confidence in the correspondence between formal models and executions of processes. 3.2 Related Event Work In using event-based data to compare an execution with a formal model, the most closely related work to ours is in the areas of distributed debugging and history checking. * Bates <ref> [8, 9, 10] </ref> uses "event-based behavioral abstraction" to characterize the behavior of programs. He then attempts to match the event data to a model based on regular expressions.
Reference: [9] <author> P. Bates. </author> <title> Shu*e automata: A formal model for behavior recognition in distributed systems. </title> <type> Technical Report COINS-87-27, </type> <institution> University of Massachusetts at Amherst, </institution> <year> 1987. </year>
Reference-contexts: process improvement by raising confidence in the correspondence between formal models and executions of processes. 3.2 Related Event Work In using event-based data to compare an execution with a formal model, the most closely related work to ours is in the areas of distributed debugging and history checking. * Bates <ref> [8, 9, 10] </ref> uses "event-based behavioral abstraction" to characterize the behavior of programs. He then attempts to match the event data to a model based on regular expressions.
Reference: [10] <author> P. Bates. </author> <title> Debugging heterogenous systems using event-based models of behavior. </title> <booktitle> In Proceedings of a Workshop on Parallel and Distributed Debugging, </booktitle> <pages> pages 11-22. </pages> <publisher> ACM Press, </publisher> <month> January </month> <year> 1989. </year>
Reference-contexts: Using event data to characterize behavior is widely accepted in other areas of software engineering, such as program visualization [42], concurrent-system analysis [3], and distributed debugging <ref> [10, 19] </ref>. We feel it is applicable to software process as well. 4 Model Events Collected Events Execution Events 2.1 Relating Models and Events: Event Sites For our work in process validation, we focus on behavior formalisms in process modeling languages. <p> process improvement by raising confidence in the correspondence between formal models and executions of processes. 3.2 Related Event Work In using event-based data to compare an execution with a formal model, the most closely related work to ours is in the areas of distributed debugging and history checking. * Bates <ref> [8, 9, 10] </ref> uses "event-based behavioral abstraction" to characterize the behavior of programs. He then attempts to match the event data to a model based on regular expressions.
Reference: [11] <author> I. Bhandari, M. Halliday, E. Tarver, D. Brown, J. Chaar, and R. Chillarege. </author> <title> A Case Study of Software Process Improvement During Development. </title> <journal> IEEE Transactions on Software Engineering, </journal> 19(12) 1157-1170, December 1993. 
Reference-contexts: Below, we summarize some of this work. 1 Numeric sequences, which are really a representation of some mathematical function (e.g., a time series of stock value), is a different topic altogether. 7 * Chmura et al. [14] and Bhandari et al. <ref> [11] </ref> try to deduce problems in the process by looking at defect data in the products. Specifically, they statistically analyzed change data and effort data to determine the behavior of the process.
Reference: [12] <author> M.G. Bradac, D.E. Perry, and L.G. Votta. </author> <title> Prototyping a process monitoring experiment. </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pages 774-784, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: centers on using a rule base and goals to derive a generalized execution flow from a specific process history. * Garg et al. [29] employ a manual process history analysis in the context of a meta-process for creating and validating domain-specific process models and software toolkits. * Bradac et al. <ref> [12] </ref> describe the beginnings of a process monitoring experiment in which their goal is to model the process as a queuing network, and use actual data about the time spent by the agents in specific tasks and states to determine the real parameters (i.e., service times and probabilities, and branch path
Reference: [13] <author> J.R. Burch, E.M. Clarke, K.L. McMillan, D.L. Dill, and L.J. Hwang. </author> <title> Symbolic model checking: 10 20 states and beyond. </title> <journal> Information and Computation, </journal> <volume> 98 </volume> <pages> 141-170, </pages> <year> 1992. </year>
Reference-contexts: In one example <ref> [13] </ref>, Burch, et.al. describe a model checker based on binary decision diagrams that is able to check models with 10 20 states, where previous work had only handled 10 8 states.
Reference: [14] <author> L.J. Chmura, A.F. Norcio, and T.J. Wicinski. </author> <title> Evaluating Software Design Processes by Analyzing Change Data Over Time. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(7) </volume> <pages> 729-739, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Below, we summarize some of this work. 1 Numeric sequences, which are really a representation of some mathematical function (e.g., a time series of stock value), is a different topic altogether. 7 * Chmura et al. <ref> [14] </ref> and Bhandari et al. [11] try to deduce problems in the process by looking at defect data in the products. Specifically, they statistically analyzed change data and effort data to determine the behavior of the process.
Reference: [15] <author> J.E. Cook and A.L. Wolf. Balboa: </author> <title> A framework for event-based process data analysis. </title> <type> Technical Report CU-CS-8??-96, </type> <institution> Department of Computer Science, University of Colorado, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: Validation is our process validation tool, built using the Balboa process data analysis framework <ref> [15] </ref>. It lets one quantitatively and qualitatively compare an execution (collected) event stream to a process model and see how many and where deviations occur between the execution stream and what the model expects. Figure 10 shows a snapshot of Validation.
Reference: [16] <author> J.E. Cook and A.L. Wolf. </author> <title> Discovering models of software processes from event-based data. </title> <type> Technical Report CU-CS-8??-96, </type> <institution> Department of Computer Science, University of Colorado, </institution> <month> November </month> <year> 1996. </year> <month> 36 </month>
Reference-contexts: These did not preclude looking at the process behavior through the use of the validation techniques. Validation was done using an existing process model derived from the (informal) process documentation, and using a model that was generated from the data itself using our process discovery methods (see <ref> [16] </ref>). In general, the process was highly variable and somewhat less than 50% of the behavior matched what the document's model predicted, and about 65% matched the discovered model.
Reference: [17] <author> J.E. Cook and A.L. Wolf. </author> <title> Process discovery and validation through event-data analysis. </title> <type> Technical Report CU-CS-817-96, </type> <institution> Department of Computer Science, University of Colorado, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: For a more detailed presentation of event data, systems that can collect event data, and using event data for analysis purposes, please see <ref> [17] </ref>. 3 Discussion and Background In our framework of process validation, we have an executing process that is producing an event stream and, on the other side, we have a model that can produce a desired or prescribed event stream.
Reference: [18] <author> J. Corbett and A. Polk. </author> <title> A tool for automatic generation of behaviors for constrained expression analysis. </title> <type> Technical report, </type> <month> February </month> <year> 1993. </year>
Reference-contexts: The ILP system produces a binary answer, and some parameters when it finds a solution. If the answer is "yes", heuristics are used along with the parameters from the ILP system to produce a plausible behavior that leads to the event <ref> [18] </ref>. This behavior constitutes the next sequence of model events. Unfortunately, if the answer is "no", Constrained Expressions do not help in determining a correction to the event stream or model state to continue the analysis of the rest of the event stream.
Reference: [19] <author> J. Cuny, G. Forman, A. Hough, J. Kundu, C. Lin, L. Snyder, and D. Stemple. </author> <title> The adriane debugger: Scalable application of event-based abstraction. </title> <booktitle> In Proceedings of the ACM/ONR Workshop on Parallel and Distributed Debugging, </booktitle> <pages> pages 85-95. </pages> <publisher> ACM Press, </publisher> <month> May </month> <year> 1993. </year>
Reference-contexts: Using event data to characterize behavior is widely accepted in other areas of software engineering, such as program visualization [42], concurrent-system analysis [3], and distributed debugging <ref> [10, 19] </ref>. We feel it is applicable to software process as well. 4 Model Events Collected Events Execution Events 2.1 Relating Models and Events: Event Sites For our work in process validation, we focus on behavior formalisms in process modeling languages. <p> He then attempts to match the event data to a model based on regular expressions. However, he only marks the points at which the data and model did not match, not attempting to provide aggregate measures of disparity. * Cuny et al. <ref> [19] </ref> builds on the work of Bates, attempting to deal with large amounts of event data by providing query mechanisms for event relationships.
Reference: [20] <author> J.L. Devore. </author> <title> Probability and Statistics for Engineering and the Sciences. </title> <address> Brooks/Cole, Pacific Grove, California, </address> <note> 3rd edition, </note> <year> 1991. </year>
Reference-contexts: Thus, one might pick the standard statistical correlation rules of thumb <ref> [20] </ref> and say that any measurement less than 0:2 is a strong correspondence, less than 0:5 is a moderate correspondence, and greater than 0:5 is a weak correspondence. (Actually, these are inversions of the standard statistical rules of thumb, but their effect is the same.) 4.3 Non-linear String Distance Metric A
Reference: [21] <author> L.K. Dillon, G.S. Avrunin, and J.C. Wileden. </author> <title> Constrained expressions: Toward broad applicability of analysis methods for distributed software systems. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 10(3) </volume> <pages> 374-402, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: If models do not have regularity in the state space, they admit that their techniques will not provide much leverage. Another example that more directly is concerned with matching a behavior to a model is Constrained Expressions <ref> [3, 21] </ref>. This is an elegant method that, given a model, a current simulation state of that model, and a desired event, can answer the question "Can this event be produced in the future?".
Reference: [22] <author> M.W. Du and S.C. Chang. </author> <title> A model and a fast algorithm for multiple errors spelling correction. </title> <journal> Acta Informatica, </journal> <volume> 29 </volume> <pages> 281-302, </pages> <year> 1992. </year>
Reference: [23] <author> Z. K. F. Eckert and G. J. Nutt. </author> <title> Trace extrapolation for parallel programs on shared memory multiprocessors. </title> <type> Technical Report TR CU-CS-804-96, </type> <institution> Department of Computer Science, University of Colorado, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: For example, points in a model where one can fix the execution stream and ignore previous behavior could help further reduce the search cost in a large model. This is similar to the concept of trace change points in <ref> [23] </ref>. * Implementing other modeling paradigms, such as Petri nets, for the metric-calculation engine. * Developing techniques for better visualizing the measurements.
Reference: [24] <author> D. Eppstein. </author> <title> Sequence comparison with mixed convex and concave costs. </title> <journal> Journal of Algorithms, </journal> <volume> 11 </volume> <pages> 85-101, </pages> <year> 1990. </year>
Reference-contexts: For simple operation and symbol weightings, equivalent to our SSD metric, their algorithms operate in O (M N ) time. However, dealing with multi-symbol blocks (or gaps), as our NSD metric requires, complicates matters significantly. In general, for both string to string comparisons <ref> [24] </ref> and string to regular expression comparisons [44], arbitrary cost functions for blocks require at least O (M N max (M; N )), or cubic time.
Reference: [25] <author> M. Felder, D. Mandrioli, and A. Morzenti. </author> <title> Proving Properties of Real-time Systems Through Logical Specifications and Petri Net Models. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 20(2) </volume> <pages> 127-141, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: They assume that there is some problem somewhere in the event stream and that one is trying to locate that problem. * Felder et al. <ref> [25, 26] </ref> describe a method and tool by which one can compare an execution history against a temporal logic specification to decide the correctness of that execution with respect to the model. Our immediate goal is to quantify discrepancies, with correctness being a subsumed issue.
Reference: [26] <author> M. Felder and A. Morzenti. </author> <title> Validating Real-time Systems by History-checking TRIO Specifications. </title> <booktitle> In Proceedings of the 14th International Conference on Software Engineering, </booktitle> <pages> pages 199-211. </pages> <publisher> IEEE Computer Society, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: They assume that there is some problem somewhere in the event stream and that one is trying to locate that problem. * Felder et al. <ref> [25, 26] </ref> describe a method and tool by which one can compare an execution history against a temporal logic specification to decide the correctness of that execution with respect to the model. Our immediate goal is to quantify discrepancies, with correctness being a subsumed issue. <p> Time-oriented met-rics, for example, would be very a useful extension to execution stream analysis. Real-time 34 systems analysis techniques could be useful here <ref> [26, 50] </ref>. Methods for measuring the effi-ciency of a process would be another useful analysis method. Both of these would help in the optimization of a process that has already been behaviorally validated.
Reference: [27] <author> C.N. Fischer and J. Mauney. </author> <title> A simple, fast, and effective LL(1) error repair algorithm. </title> <journal> Acta Informat-ica, </journal> <volume> 29 </volume> <pages> 109-120, </pages> <year> 1992. </year>
Reference-contexts: This method is based on the ideas of minimum distance corrections, but makes the assumption that one never needs to back up in the input stream to find a good correction. * Fischer and Mauney <ref> [27] </ref> describe a method for locally least cost error correction. They are also biased towards insertions, but include deletions. Their method will back up in the current parse stack, and uses a local search with a priority queue to find a locally minimum cost fix.
Reference: [28] <author> P.K. Garg and S. Bhansali. </author> <title> Process Programming by Hindsight. </title> <booktitle> In Proceedings of the 14th International Conference on Software Engineering, </booktitle> <pages> pages 280-293. </pages> <publisher> IEEE Computer Society, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: Though there is no attempt to relate this to real data, "what-if" analyses are powerful tools in their own right. Some recent efforts have begun to look at process data itself, but still not for the purpose of process validation. * Garg and Bhansali <ref> [28] </ref> describe a method that uses explanation-based learning to discover aspects and fragments of the underlying process model from process history data and rules of operations and their effects.
Reference: [29] <author> P.K. Garg, M. Jazayeri, </author> <title> and M.L. Creech. A Meta-Process for Software Reuse, Process Discovery, and Evolution. </title> <booktitle> In Proceedings of the 6th International Workshop on Software Reuse, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: This work centers on using a rule base and goals to derive a generalized execution flow from a specific process history. * Garg et al. <ref> [29] </ref> employ a manual process history analysis in the context of a meta-process for creating and validating domain-specific process models and software toolkits. * Bradac et al. [12] describe the beginnings of a process monitoring experiment in which their goal is to model the process as a queuing network, and use
Reference: [30] <author> J. Grudin. </author> <title> Groupware and Cooperative Work: Problems and Prospects. In R.M. </title> <editor> Baeker, editor, </editor> <booktitle> Groupware and Computer-Supported Cooperative Work, </booktitle> <pages> pages 97-105. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: That being the case, there is no effective way to enforce the process using this approach nor to guarantee the mutual consistency of a process model and a process execution. In addition, the workflow community has long recognized the need to allow exceptions to the prescribed process <ref> [30] </ref>; so, in reality, there is a strong need to allow for deviations from the model. Even if one could completely enforce a process, there still remains the issue of managing change in a process, which might lead to a discrepancy between the model and the execution.
Reference: [31] <author> V. Gruhn and R. Jegelka. </author> <title> An Evaluation of FUNSOFT Nets. </title> <booktitle> In Proceedings of the Second European Workshop on Software Process Technology, number 635 in Lecture Notes in Computer Science, </booktitle> <pages> pages 196-214. </pages> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1992. </year>
Reference-contexts: These include models based on state machines (e.g., Statemate [33]), Petri nets (e.g., Slang [6] and FUNSOFT Nets <ref> [31] </ref>), and procedural languages (e.g., APPL/A [53]). 4.1 Recognition Metric The first metric is a very straightforward one that has just two values, true or false. The value is true if the event streams exactly match and is false otherwise.
Reference: [32] <author> D. Harel. Statecharts: </author> <title> A Visual Formalism for Complex Systems. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 8 </volume> <pages> 231-274, </pages> <year> 1987. </year>
Reference-contexts: Examples are the Petri net foundation in Slang [5], the generic state machines, and the more specific state language Statecharts <ref> [32] </ref>. In viewing a process execution as an event stream, we are assuming that a process model has some way of producing an event stream if it was "executed".
Reference: [33] <author> D. Harel, H. Lachover, A. Naamad, A. Pnueli, M. Politi, R. Sherman, and A. Shtul-Trauring. STATE--MATE: </author> <title> A Working Environment for the Development of Complex Reactive Systems. </title> <booktitle> In Proceedings of the 10th International Conference on Software Engineering, </booktitle> <pages> pages 396-406. </pages> <publisher> IEEE Computer Society, </publisher> <month> April </month> <year> 1988. </year>
Reference-contexts: Thus, possible paths through the specification|that is, possible behaviors specified by the model|can be represented by event streams produced by a simulation. 9 Several formal models suitable for our analyses have been used to describe software processes. These include models based on state machines (e.g., Statemate <ref> [33] </ref>), Petri nets (e.g., Slang [6] and FUNSOFT Nets [31]), and procedural languages (e.g., APPL/A [53]). 4.1 Recognition Metric The first metric is a very straightforward one that has just two values, true or false. The value is true if the event streams exactly match and is false otherwise.
Reference: [34] <author> A. Hutchinson. </author> <title> Algorithmic Learning. Graduate Texts in Computer Science. </title> <publisher> Oxford University Press, </publisher> <year> 1994. </year>
Reference-contexts: This approach implies some kind of state-space search method, and implies using a heuristic-driven method to control the state explosion. AI research has provided several search methods that seem applicable; two that we describe here are best first search and A fl search <ref> [34, 46] </ref>. While the standard depth first and breadth first searches of a tree of states are exhaustive in a single dimension, best first search is a heuristic-driven search that determines its search path by following the lowest cost path in the state space.
Reference: [35] <author> M.L. Jaccheri and R. Conradi. </author> <title> Techniques for Process Model Evolution in EPOS. </title> <journal> IEEE Transactions on Software Engineering, </journal> 19(12) 1145-1156, December 1993. 
Reference-contexts: Even if one could completely enforce a process, there still remains the issue of managing change in a process, which might lead to a discrepancy between the model and the execution. There has, in fact, been considerable recent work that addresses process evolution <ref> [4, 35] </ref>. Commensurate with the historical approach mentioned above, that work is concerned more with the problem of effecting changes to a process model used for automation, than it is with the problem of uncovering inconsistencies between the model and the execution.
Reference: [36] <author> L.G. Votta J.E. Cook and A.L. Wolf. </author> <title> Does following prescribed processes lead to better products? Technical Report CU-CS-8??-96, </title> <institution> Department of Computer Science, University of Colorado, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: An in-depth presentation of this study can be found in <ref> [36] </ref>; we will just highlight the use of the validation tools here. The study focussed on a change request process for a large telecommunications software system. <p> We believe that to truly have software process improvement, analysis techniques such as the ones we have implemented are needed. While Section 10 gave a short presentation of an industrial study in which the process validation techniques were applied, this study is presented in-depth in <ref> [36] </ref>. This study shows the usefulness of these techniques in a real world setting, and that the validation metrics as proposed can in fact capture important information about how a process is behaving.
Reference: [37] <author> R.L. Kashyap and B.J. Oommen. </author> <title> The noisy substring matching problem. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 9(3) </volume> <pages> 365-370, </pages> <year> 1983. </year>
Reference-contexts: Previous work in other areas using string distance measures have also found the need for per-symbol weights <ref> [2, 37] </ref>. 6.2 Usability Enhancements The simple and non-linear string distance metrics are naturally decomposable in a hierarchical fashion, to be able to give more information about the measurement than just one number for the whole process model.
Reference: [38] <author> M.I. Kellner. </author> <title> Software Process Modeling Support for Management Planning and Control. </title> <booktitle> In Proceedings of the First International Conference on the Software Process, </booktitle> <pages> pages 8-28. </pages> <publisher> IEEE Computer Society, </publisher> <month> October </month> <year> 1991. </year>
Reference-contexts: Their work also focuses on using product data, such as code modifications and change classification. This work has become known as the GQM , or goal-question-metric, paradigm. * Kellner <ref> [38] </ref> shows the usefulness of simulation and "what-if" analyses in forecasting the schedule and outcome of a specific execution of a process. He uses deterministic and stochastic modeling, along with resource constraints, to derive schedule, work effort, and staffing estimations.
Reference: [39] <author> M.I. Kellner, P.H. Feiler, A. Finkelstein, T. Katayama, L.J. Osterweil, M.H. Penedo, and H.D. Rombach. </author> <title> Software Process Modeling Example Problem. </title> <booktitle> In Proceedings of the 6th International Software Process Workshop, </booktitle> <pages> pages 19-29, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: For the moderate cutoff value, we would use 0:5 in place of 0:2. 5 Example Use of the Metrics To illustrate the various metrics introduced above, we use the Test Unit task from the ISPW 6/7 process problem <ref> [39] </ref>.
Reference: [40] <author> J.R. Knight and E.W. Myers. </author> <title> Approximate regular expression pattern matching with concave gap penalties. </title> <journal> Algorithmica, </journal> <volume> 14 </volume> <pages> 85-121, </pages> <year> 1995. </year>
Reference-contexts: The problem is, while they leverage system transformations to gain speed and scalability, these transformations make the system inherently uninspectable and their analysis methods only produce binary results. 20 7.1.3 Regular Expression Matching In <ref> [40, 44] </ref>, Myers, Miller, and Knight describe algorithms for approximately matching a string to a regular expression, using the insert, delete, and substitute operations. These methods build on the dynamic programming techniques of the string to string comparison algorithms, and extend this to regular expressions. <p> In general, constructs used in process modeling languages are not reducible to regular expressions. More powerful, yet still restricted, constructs have been looked at. Context free languages, for example, are thought to have high-order polynomial time algorithms for solving approximate matching <ref> [40] </ref>. In general, these super-quadratic to cubic solutions, while providing optimal answers, are impractical unless one requires an optimal solution.
Reference: [41] <author> J.B. Kruskal. </author> <title> An Overview of Sequence Comparison. </title> <editor> In D. Sankoff and J.B. Kruskal, editors, </editor> <title> Time Warps, String Edits, and Macromolecules: </title> <booktitle> The Theory and Practice of Sequence Comparison, </booktitle> <pages> pages 1-44. </pages> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1983. </year>
Reference-contexts: This solution paradigm is shown in Figure 3. In describing this paradigm, we will put off discussing how to generate the model event stream until Section 7. There are several methods for doing a measurement such as this, but one that seems most widely applied is string distance metrics <ref> [41] </ref>. A string distance metric counts the number of token (symbols that make up the string) swaps, insertions, and deletions needed to transform one string into the other. By applying various mathematical transformations, this method becomes a family of metrics. <p> These methods have been used in fields as various as DNA/RNA matching ([54]), substring matching ([37, 49]), spelling correction ([22]), syntax error correction ([1, 27, 47]), and even the well-known Unix diff program. A good reference to the general area of sequence comparison is <ref> [41] </ref>. Other methods of doing this measurement do not offer the versatility that the string distance metrics do. <p> We can then apply a well-known method for calculating the distance between strings <ref> [41] </ref> and use distance as the metric of difference between the process model and process execution. String distance metrics have been used profitably as measures of correspondence in a wide variety of other domains, including parsing, DNA/RNA sequencing, and text recognition [48]. <p> Given two strings, one of length n and the other of length m, the minimal total cost of operations can be computed in O (nm) time using a well-known dynamic program <ref> [41] </ref>. 2 The operations are isomorphic, so choosing one event stream over another does not change the resulting measurement, it just reverses the senses of insertion and deletion. 10 A B C C Transform Stream C A B C A B D E E E B D C AEC Transform Stream
Reference: [42] <author> R.J. LeBlanc and A.D. Robbins. </author> <title> Event-Driven Monitoring of Distributed Programs. </title> <booktitle> In Proceedings of the Fifth International Conference on Distributed Computing Systems, </booktitle> <pages> pages 515-522. </pages> <publisher> IEEE Computer Society, </publisher> <month> May </month> <year> 1985. </year>
Reference-contexts: Using event data to characterize behavior is widely accepted in other areas of software engineering, such as program visualization <ref> [42] </ref>, concurrent-system analysis [3], and distributed debugging [10, 19]. We feel it is applicable to software process as well. 4 Model Events Collected Events Execution Events 2.1 Relating Models and Events: Event Sites For our work in process validation, we focus on behavior formalisms in process modeling languages.
Reference: [43] <author> S.Y. Lu and K.S. Fu. </author> <title> Error-correcting tree automata for syntactic pattern recognition. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-27:1040-1053, </volume> <month> November </month> <year> 1978. </year>
Reference-contexts: 2 Event 3 Event 76 Event 77 Event 78 Event Data Process Model Generation Event 1 Event 2 Event 3 Event 83 Event 84 Event 85 Event Data Comparison Measurements where symbolic sequence comparison is taking place. 1 String distance methods are also generalizable to tree and graph distance measurements <ref> [43] </ref>. Methods that can compare a model directly with some event stream are also available, but our abstraction away from this is more generalizable.
Reference: [44] <author> E.W. Myers and W. Miller. </author> <title> Approximate matching of regular expressions. </title> <journal> Bulletin of Mathematical Biology, </journal> <volume> 51(1) </volume> <pages> 5-37, </pages> <year> 1989. </year>
Reference-contexts: The problem is, while they leverage system transformations to gain speed and scalability, these transformations make the system inherently uninspectable and their analysis methods only produce binary results. 20 7.1.3 Regular Expression Matching In <ref> [40, 44] </ref>, Myers, Miller, and Knight describe algorithms for approximately matching a string to a regular expression, using the insert, delete, and substitute operations. These methods build on the dynamic programming techniques of the string to string comparison algorithms, and extend this to regular expressions. <p> However, dealing with multi-symbol blocks (or gaps), as our NSD metric requires, complicates matters significantly. In general, for both string to string comparisons [24] and string to regular expression comparisons <ref> [44] </ref>, arbitrary cost functions for blocks require at least O (M N max (M; N )), or cubic time.
Reference: [45] <author> A. Porter, H. Siy, C.A. Toman, and L.G. Votta. </author> <title> An experiment to assess the cost-benefits of code inspections in large scale software development. </title> <booktitle> In Third ACM SIGSOFT Symposium on the Foundations of Software Engineering, </booktitle> <pages> pages 92-103. </pages> <publisher> ACM Press, </publisher> <month> October </month> <year> 1995. </year>
Reference-contexts: probabilities) of the queuing network that can then be analyzed. * Wolf and Rosenblum [55] demonstrate how to collect event-based process data and use basic statistical and visual techniques to find interesting relationships among the data in order to uncover possible areas of process improvement. 8 * Porter et al. <ref> [45] </ref> use a well constructed experimental setting to assess the benefits of code inspections, in terms of group size and meeting gains.
Reference: [46] <editor> E. Rich. </editor> <booktitle> Artificial Intelligence. McGraw-Hill Series in Artificial Intelligence. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: This approach implies some kind of state-space search method, and implies using a heuristic-driven method to control the state explosion. AI research has provided several search methods that seem applicable; two that we describe here are best first search and A fl search <ref> [34, 46] </ref>. While the standard depth first and breadth first searches of a tree of states are exhaustive in a single dimension, best first search is a heuristic-driven search that determines its search path by following the lowest cost path in the state space. <p> By pruning, one cannot guarantee a lowest cost goal, but smart pruning, in some domains (such as game playing), has shown that it has negligible effects on the outcome of the search while dramatically reducing search costs <ref> [46] </ref>. Pruning can take many forms, and can use vastly different methods and heuristics. One pruning method is to throw away any newly generated state that has an estimated cost higher than some threshold relative to the current best-looking state.
Reference: [47] <author> J. Rohrich. </author> <title> Methods for the automatic construction of error correcting parsers. </title> <journal> Acta Informatica, </journal> <volume> 13 </volume> <pages> 115-139, </pages> <year> 1980. </year>
Reference-contexts: They augment the language grammar with error productions, and modify the parse algorithm to do corrections. They do not expect that their algorithm to be used, because of its high cost; they only propose it as a baseline for other methods to compare against. * Rohrich <ref> [47] </ref> describes an error correction method biased towards insertion of symbols, arguing that as little of the program text should be skipped (deleted) as possible.
Reference: [48] <author> D. Sankoff and J.B. Kruskal, </author> <title> editors. Time Warps, String Edits, and Macromolecules: The Theory and Practice of Sequence Comparison. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1983. </year> <month> 38 </month>
Reference-contexts: String distance metrics have been used profitably as measures of correspondence in a wide variety of other domains, including parsing, DNA/RNA sequencing, and text recognition <ref> [48] </ref>. The basic Levenshtein distance between two strings is measured by counting the minimal number of token insertions, deletions, and substitutions needed to transform one string into the other. between their events.
Reference: [49] <author> M. Schneider, H. Lim, and W. Schoaff. </author> <title> The utilization of fuzzy sets in the recognition of imperfect strings. </title> <journal> Fuzzy Sets and Systems, </journal> <volume> 49 </volume> <pages> 331-337, </pages> <year> 1992. </year>
Reference: [50] <author> R.L. Schwartz, P.M. Melliar-Smith, and F.H. Vogt. </author> <title> In Interval Logic for Higher-level Temporal Reasoning. </title> <booktitle> In Proceedings of the Second ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 173-186. </pages> <institution> Association for Computer Machinery, </institution> <month> August </month> <year> 1983. </year>
Reference-contexts: Time-oriented met-rics, for example, would be very a useful extension to execution stream analysis. Real-time 34 systems analysis techniques could be useful here <ref> [26, 50] </ref>. Methods for measuring the effi-ciency of a process would be another useful analysis method. Both of these would help in the optimization of a process that has already been behaviorally validated.
Reference: [51] <author> R.W. Selby, A.A. Porter, D.C. Schmidt, and J. Berney. </author> <title> Metric-Driven Analysis and Feedback Systems for Enabling Empirically Guided Software Development. </title> <booktitle> In Proceedings of the 13th International Conference on Software Engineering, </booktitle> <pages> pages 288-298. </pages> <publisher> IEEE Computer Society, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: Specifically, they statistically analyzed change data and effort data to determine the behavior of the process. For example, they saw ripple effects from interface changes, saw high percentages of fix-on-fix changes, and proposed two measures of process progress that required less data than previous measures. * Selby et al. <ref> [51] </ref> take the approach of providing automated support for empirically guided software development. Their system, Amadeus, can automatically collect measurement data (currently focused primarily on product data) that can then be used to guide development efforts.
Reference: [52] <author> S.M. Sutton, Jr. </author> <title> Accommodating Manual Activities in Automated Process Programs. </title> <booktitle> In Proceedings of the 7th International Software Process Workshop, </booktitle> <month> October </month> <year> 1991. </year>
Reference-contexts: This approach, however, suffers from a fundamental flaw. In particular, it assumes that virtually the entire process is executed within the context of the automated environment. In fact, critical aspects of the process occur off the computer and, therefore, not under the watchful eye of the environment <ref> [52, 55, 56] </ref>. That being the case, there is no effective way to enforce the process using this approach nor to guarantee the mutual consistency of a process model and a process execution.
Reference: [53] <author> S.M. Sutton, Jr., D. Heimbigner, and L.J. Osterweil. </author> <title> Language Constructs for Managing Change in Process-Centered Environments. </title> <booktitle> In SIGSOFT '90: Proceedings of the Fourth Symposium on Software Development Environments, </booktitle> <pages> pages 206-217. </pages> <booktitle> ACM SIGSOFT, </booktitle> <month> December </month> <year> 1990. </year>
Reference-contexts: These include models based on state machines (e.g., Statemate [33]), Petri nets (e.g., Slang [6] and FUNSOFT Nets [31]), and procedural languages (e.g., APPL/A <ref> [53] </ref>). 4.1 Recognition Metric The first metric is a very straightforward one that has just two values, true or false. The value is true if the event streams exactly match and is false otherwise.
Reference: [54] <author> M.S. Waterman. </author> <title> General methods of sequence comparison. </title> <journal> Bulletin of Mathematical Biology, </journal> <volume> 46 </volume> <pages> 473-501, </pages> <year> 1984. </year>
Reference: [55] <author> A.L. Wolf and D.S. Rosenblum. </author> <title> A Study in Software Process Data Capture and Analysis. </title> <booktitle> In Proceedings of the Second International Conference on the Software Process, </booktitle> <pages> pages 115-124. </pages> <publisher> IEEE Computer Society, </publisher> <month> February </month> <year> 1993. </year>
Reference-contexts: This approach, however, suffers from a fundamental flaw. In particular, it assumes that virtually the entire process is executed within the context of the automated environment. In fact, critical aspects of the process occur off the computer and, therefore, not under the watchful eye of the environment <ref> [52, 55, 56] </ref>. That being the case, there is no effective way to enforce the process using this approach nor to guarantee the mutual consistency of a process model and a process execution. <p> This does not mean that other aspects of a process are not worthy of study; it is just that the issues we have chosen to investigate are those having to do with behavior rather than structure. Following Wolf and Rosenblum <ref> [55] </ref>, we use an event-based model of process actions, where an event is used to characterize the dynamic behavior of a process in terms of identifiable, instantaneous actions, such as invoking a development tool or deciding upon the next activity to be performed. `Instantaneous' is relative to the time granularity that <p> model the process as a queuing network, and use actual data about the time spent by the agents in specific tasks and states to determine the real parameters (i.e., service times and probabilities, and branch path probabilities) of the queuing network that can then be analyzed. * Wolf and Rosenblum <ref> [55] </ref> demonstrate how to collect event-based process data and use basic statistical and visual techniques to find interesting relationships among the data in order to uncover possible areas of process improvement. 8 * Porter et al. [45] use a well constructed experimental setting to assess the benefits of code inspections, in
Reference: [56] <editor> A.L. Wolf and D.S. Rosenblum. </editor> <booktitle> Process-centered Environments (Only) Support Environment-centered Processes. In Proceedings of the 8th International Software Process Workshop, </booktitle> <pages> pages 148-149, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: This approach, however, suffers from a fundamental flaw. In particular, it assumes that virtually the entire process is executed within the context of the automated environment. In fact, critical aspects of the process occur off the computer and, therefore, not under the watchful eye of the environment <ref> [52, 55, 56] </ref>. That being the case, there is no effective way to enforce the process using this approach nor to guarantee the mutual consistency of a process model and a process execution.
References-found: 56

