URL: http://www.cs.jhu.edu/~cowen/lin-nd.ps
Refering-URL: http://www.cs.jhu.edu/~cowen/
Root-URL: http://www.cs.jhu.edu
Title: A Linear-Time Algorithm for Network Decomposition  
Author: Lenore J. Cowen 
Address: Baltimore, MD 21218  
Affiliation: Department of Mathematical Sciences The Johns Hopkins University  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Afek and M. Riklin. Sparser: </author> <title> A paradigm for running distributed algorithms. </title> <editor> J. </editor> <booktitle> of Algorithms, </booktitle> <year> 1991. </year> <note> Accepted for publication. </note>
Reference-contexts: that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation (see <ref> [5, 6, 2, 3, 1, 7] </ref>.) fl Supported in part by an NSF postdoctoral fellowship. This work was done while the author was visiting DIMACS. 1 In this note, it is shown how to modify the simple greedy construction in [6] to save a log n factor in running time.
Reference: [2] <author> B. Awerbuch, B. Berger, L. Cowen, and D. Peleg. </author> <title> Fast distributed network decomposition. </title> <booktitle> In Proc. 11th ACM Symp. on Principles of Distributed Computing, </booktitle> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation (see <ref> [5, 6, 2, 3, 1, 7] </ref>.) fl Supported in part by an NSF postdoctoral fellowship. This work was done while the author was visiting DIMACS. 1 In this note, it is shown how to modify the simple greedy construction in [6] to save a log n factor in running time.
Reference: [3] <author> B. Awerbuch, B. Berger, L. Cowen, and D. Peleg. </author> <title> Low-diamter graph decomposition is in NC. In Random Structures and Algorithms, </title> <booktitle> 5 </booktitle> <pages> 442-452, </pages> <year> 1994. </year>
Reference-contexts: that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation (see <ref> [5, 6, 2, 3, 1, 7] </ref>.) fl Supported in part by an NSF postdoctoral fellowship. This work was done while the author was visiting DIMACS. 1 In this note, it is shown how to modify the simple greedy construction in [6] to save a log n factor in running time.
Reference: [4] <author> B. Awerbuch, A. Goldberg, M. Luby, and S. Plotkin. </author> <title> Network decomposition and locality in distributed computation. </title> <booktitle> In Proc. 30th IEEE Symp. on Foundations of Computer Science, </booktitle> <month> May </month> <year> 1989. </year>
Reference-contexts: A (; d)-decomposition is said to be low-diameter if and d are both O (log n). The (; d)- decomposition problem, most commonly called network decomposition was introduced in <ref> [4] </ref> as a means of partitioning a network into local regions, though they did not achieve clusters that were low-diameter by the standards of the above definition (They produced and d both O (n * ), for * = O ( log log n= log n).) In [5, 6] a simple
Reference: [5] <author> B. Awerbuch and D. Peleg. </author> <title> Sparse partitions. </title> <booktitle> In Proc. 31st IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 503-513, </pages> <year> 1990. </year>
Reference-contexts: was introduced in [4] as a means of partitioning a network into local regions, though they did not achieve clusters that were low-diameter by the standards of the above definition (They produced and d both O (n * ), for * = O ( log log n= log n).) In <ref> [5, 6] </ref> a simple greedy algorithm was presented that produced a low-diameter network decomposi tion in O ((E+n) log n) time. (In addition, [6] proved that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) <p> that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation (see <ref> [5, 6, 2, 3, 1, 7] </ref>.) fl Supported in part by an NSF postdoctoral fellowship. This work was done while the author was visiting DIMACS. 1 In this note, it is shown how to modify the simple greedy construction in [6] to save a log n factor in running time.
Reference: [6] <author> N. Linial and M. Saks. </author> <title> Decomposing graphs into regions of small diameter. </title> <booktitle> In Proc. 2nd ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 320-330. </pages> <address> ACM/SIAM, </address> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: was introduced in [4] as a means of partitioning a network into local regions, though they did not achieve clusters that were low-diameter by the standards of the above definition (They produced and d both O (n * ), for * = O ( log log n= log n).) In <ref> [5, 6] </ref> a simple greedy algorithm was presented that produced a low-diameter network decomposi tion in O ((E+n) log n) time. (In addition, [6] proved that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) <p> by the standards of the above definition (They produced and d both O (n * ), for * = O ( log log n= log n).) In [5, 6] a simple greedy algorithm was presented that produced a low-diameter network decomposi tion in O ((E+n) log n) time. (In addition, <ref> [6] </ref> proved that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation <p> that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation (see <ref> [5, 6, 2, 3, 1, 7] </ref>.) fl Supported in part by an NSF postdoctoral fellowship. This work was done while the author was visiting DIMACS. 1 In this note, it is shown how to modify the simple greedy construction in [6] to save a log n factor in running time. <p> This work was done while the author was visiting DIMACS. 1 In this note, it is shown how to modify the simple greedy construction in <ref> [6] </ref> to save a log n factor in running time. The new algorithm runs in O (E + n) time, which is optimal. Note that the new construction will produce clusters whose diameter can be larger by a small constant factor than those in [6], so in some applications where network <p> modify the simple greedy construction in <ref> [6] </ref> to save a log n factor in running time. The new algorithm runs in O (E + n) time, which is optimal. Note that the new construction will produce clusters whose diameter can be larger by a small constant factor than those in [6], so in some applications where network decomposition is used as a data structure, the original algorithm might be preferable in practice, even though it is more costly. 2 The Algorithm The new algorithm works as follows. Pick a color. <p> the interior, (i.e. are also in the ball of radius r 1 around the center node), AND (b) at least half the edges which are adjacent to a vertex in the ball of radius r, have an endpoint within the ball of radius r 1. (This is the modification of <ref> [6] </ref>). The interior of the ball is put into the color class, and the entire ball is removed from the graph. (The border (those nodes whose distance from the center vertex is exactly r) will not be colored with the current color).
Reference: [7] <author> A. Panconesi and A. Srinivasan. </author> <title> Improved algorithms for network decompositions. </title> <booktitle> In Proc. 24th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 581-592, </pages> <year> 1992. </year> <month> 3 </month>
Reference-contexts: that the low-diameter condition was best possible: there exist families of graphs for which to minimize and d simultaneously, require ; d = O (log n).) Further work on network decomposition focused on the construction of low-diameter network decompositions, and applications, in the parallel and distributed models of computation (see <ref> [5, 6, 2, 3, 1, 7] </ref>.) fl Supported in part by an NSF postdoctoral fellowship. This work was done while the author was visiting DIMACS. 1 In this note, it is shown how to modify the simple greedy construction in [6] to save a log n factor in running time.
References-found: 7

