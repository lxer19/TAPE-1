URL: http://www.fzi.de/sim/projects/SFB_358/A2/Papers/dac.ps.gz
Refering-URL: http://www.fzi.de/sim/people/trautw/index.ok.html
Root-URL: http://www.fzi.de
Date: 20. Mai 1994, 20 04 Uhr  
Note: 1 proof print:  
Abstract: Many single algorithms have been adapted to special parallel or distributed machines. In this paper we present a solution for a whole class of algorithms, the divide-and-conquer-algorithms. The environment built by the author supports the programmer by features like virtual shared variables and a system that decides when to usa a distributed rather than a local algorithm. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Al. Geist, A. Beguelin, J. J. Dongarra, W. Jiang, R. Manchek, and V. S. Sunderam. </author> <title> PVM 3.0 Users Guide And Reference Manual. </title> <type> Technical Report ORNL/TM-12187, </type> <institution> Oak Ridge National Laboratory, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: Mai 1994, 20 04 networks are a platform where this methodology can be used. Processes use the processing power of the workstations and communicate over the network. A well known software to support this paradigm is Pvm (parallel virtual machine) that is available for a wide variety of machines <ref> [1] </ref>. It has been shown that communication consumes a large fraction of the time when no balance is maintained between communication and computation. The algorithm designer has to take this balance into account. Finding a good model for the cost of communication is a current research topic [7].
Reference: [2] <author> A. Beguelin, J. Dongarra, G. A. Geist, R. Manchek, K. Moore, R. Wade, J. Plank, V. Sunderam. </author> <title> HeNCE: A Users Guide, </title> <note> Version 1.2, </note> <month> December </month> <year> 1992. </year>
Reference-contexts: Most programming systems put the burden of finding the right granularity of the computation blocks in the hands of the implementor. He has to decide which parts of the computation have to take place on which node. The HeNCE programming environment gives a graphical support for this programming method <ref> [2] </ref>. If the data structure that has to be distributed is static (does not change its size) it may be possible for the implementor to do a good guess on how to partition it. Some problems require dynamic data structures. For these problems only little support is available.
Reference: [3] <author> Utpal Banerjee, Rudolf Eigenmann, Alexandru Nicolau, David A. Padua. </author> <title> Automatic Program Parallelization. </title> <journal> Proc. of the IEEE, </journal> <volume> Vol. 81, No. 2, </volume> <month> February </month> <year> 1993 </year>
Reference-contexts: The automatic parallelization of FORTRAN was a challenging task for the computer science community. A good overview on this work together with a long list of references can be found in <ref> [3] </ref>. More complex data and communication structures can be built on the basis of communicating sequential processes [5]. Todays computer Parallelizing divide-and-conquer-Algorithms Christoph Trautwein Wolfgang Rosenstiel Lehrstuhl fr Technische Informatik Universitt Tbingen, Germany 2 proof print: 20.
Reference: [4] <institution> High-speed computing devices, Charles Babbage Institute reprint series for the history of computing; v.4, </institution> <note> pp 265ff. ISBN 0 938228-02-1 </note>
Reference-contexts: After invention of the automatic calculation machinery the idea of parallelization was used on many levels. Very soon there was the idea of adding numbers represented as bitvectors in parallel instead of the former bit by bit addition <ref> [4] </ref>. Most of the times the data structures used were vectors. In the early days the vectors were made of bits later they were often vectors of integers or oating point numbers. Special machines were built to support this type of parallelism in hardware.
Reference: [5] <author> C.A.R. Hoare, </author> <title> Communicating Sequential Processes, </title> <journal> Comm. of the ACM, Aug. 1978, </journal> <volume> Vol 21 No 8 </volume>
Reference-contexts: The automatic parallelization of FORTRAN was a challenging task for the computer science community. A good overview on this work together with a long list of references can be found in [3]. More complex data and communication structures can be built on the basis of communicating sequential processes <ref> [5] </ref>. Todays computer Parallelizing divide-and-conquer-Algorithms Christoph Trautwein Wolfgang Rosenstiel Lehrstuhl fr Technische Informatik Universitt Tbingen, Germany 2 proof print: 20. Mai 1994, 20 04 networks are a platform where this methodology can be used. Processes use the processing power of the workstations and communicate over the network.
Reference: [6] <institution> A Software Tool for Load Balanced Adaptive Multiple Grids on Distributed Memory Computers. </institution> <note> J. </note> <author> De Keyser, D. Roose. </author> <booktitle> The Sixth Distributed Memory Computing Comference Proceedings, </booktitle> <month> May </month> <year> 1991, </year> <institution> Portland Oregon </institution>
Reference-contexts: Some problems require dynamic data structures. For these problems only little support is available. Some projects use dynamic data structures but specialize on specific algorithms <ref> [6] </ref>. 4. Definitions 4.1 Multiprocessor A multiprocessor is a set of Processors A single processor p has a processing power and a communication power . The processing power is not constant over time. is the processing power at time . The communication power of a processor is not time invariant.
Reference: [7] <author> D. Culler, R. Karp, D. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, T. v. Eicken. </author> <title> LogP: Towards a realistic Model of Parallel Computation. </title>
Reference-contexts: It has been shown that communication consumes a large fraction of the time when no balance is maintained between communication and computation. The algorithm designer has to take this balance into account. Finding a good model for the cost of communication is a current research topic <ref> [7] </ref>. Most programming systems put the burden of finding the right granularity of the computation blocks in the hands of the implementor. He has to decide which parts of the computation have to take place on which node.
References-found: 7

