URL: http://vis-www.cs.umass.edu/~piater/lc/FLAIRS98.ps.gz
Refering-URL: http://vis-www.cs.umass.edu/ITL/
Root-URL: 
Email: lastname@cs.umass.edu  
Title: Interactively Training Pixel Classifiers  
Author: Justus H. Piater and Edward M. Riseman and Paul E. Utgoff 
Address: Amherst, MA 01003  
Affiliation: Computer Science Department University of Massachusetts  
Abstract: Manual generation of training examples for supervised learning is an expensive process. One way to reduce this cost is to produce training instances that are highly informative. To this end, it would be beneficial to produce training instances interactively. Rather than provide a supervised learning algorithm with one complete set of training examples before learning commences, it would be better to produce each new training instance based on knowledge of which instances the learner would otherwise misclassify. Whenever the learner receives one or more new training examples, it should update its classifier incrementally and, in real time, provide the teacher with feedback about its current performance. The feasibility of such an approach is demonstrated on a realistic image pixel classification task. Here, the number of training instances involved in building a classifier was reduced by several orders of magnitude, at no perceivable loss of classification accuracy. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Blume, M., and Ballard, D. R. </author> <year> 1997. </year> <title> Image annotation based on learning vector quantization and localized Haar wavelet transform features. </title> <booktitle> Proc. SPIE 3077:181190. </booktitle>
Reference: <author> Breiman, L.; Friedman, J. H.; Olshen, R. A.; and Stone, C. J. </author> <year> 1984. </year> <title> Classification and regression trees. </title> <address> Pacific Grove, CA: Wadsworth&Brooks. </address>
Reference-contexts: This rules out many classifiers, e.g. neural networks which converge relatively slowly and require a large number of training example presentations. Decision trees, on the other hand, are known for their computational efficiency. An early incremental decision tree algorithm was proposed by Crawford (1989) based on CART <ref> (Breiman et al. 1984) </ref>. When a new training instance would cause a new test to be picked at a decision node, the entire subtree rooted at this node is discarded and rebuilt based on the corresponding subset of the training examples.
Reference: <author> Campbell, N. W.; Mackeown, W. P. J.; Thomas, B. T.; and Troscianko, T. </author> <year> 1997. </year> <title> Interpreting image databases by region classification. </title> <journal> Pattern Recognition 30(4):555563. </journal>
Reference: <author> Carpenter, G. A.; Gjaja, M. N.; Gopal, S.; and Woodcock, C. E. </author> <year> 1997. </year> <title> ART neural networks for remote sensing: vegetation classification from Landsat TM and terrain data. </title> <journal> IEEE Trans. Geoscience and Remote Sensing 35(2):308325. </journal>
Reference: <author> Carr, J. R. </author> <year> 1996. </year> <title> Spectral and textural classification of single and multiple band digital images. </title> <journal> Computers & Geosciences 22(8):849865. </journal>
Reference: <author> Conners, R., and Harlow, C. </author> <year> 1980. </year> <title> A theoretical comparison of texture algorithms. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell. 2(3):204222. </journal>
Reference: <author> Crawford, S. L. </author> <year> 1989. </year> <title> Extensions to the CART algorithm. </title>
Reference: <institution> Int. J. Man-Machine Studies 31:197217. </institution>
Reference: <author> Devijver, P. A., and Kittler, J. </author> <year> 1982. </year> <title> Pattern recognition: a statistical approach. </title> <address> Englewood Cliffs: </address> <publisher> Prentice-Hall. </publisher> <editor> du Buf, J.; Kardan, M.; and Spann, M. </editor> <year> 1990. </year> <title> Texture feature performance for image segmentation. </title> <journal> Pattern Recognition 23(3/4):291309. </journal>
Reference-contexts: Incremental Decision Trees This work is primarily concerned with effective selection of training instances. Another important issue in classifier construction is the selection of a feature set. It is known that increasing the size of a feature set can adversely affect classifier performance <ref> (Devijver & Kittler 1982) </ref>. Selection of an optimal feature subset from a given universe of features has been shown to be infeasible in practice (Ferri et al. 1994). Classifiers that utilize all available features (such as neural networks, nearest-neighbor clusterers, linear machines) are particularly sensitive to redundant and noisy features.
Reference: <author> Ferri, J. J.; Pudil, P.; Hatef, M.; and Kittler, J. </author> <year> 1994. </year> <title> Comparative study of techniques for large-scale feature selection. </title>
Reference-contexts: It is known that increasing the size of a feature set can adversely affect classifier performance (Devijver & Kittler 1982). Selection of an optimal feature subset from a given universe of features has been shown to be infeasible in practice <ref> (Ferri et al. 1994) </ref>. Classifiers that utilize all available features (such as neural networks, nearest-neighbor clusterers, linear machines) are particularly sensitive to redundant and noisy features. This motivates the use of a univariate decision tree classifier which consults only a single feature at each decision node.
Reference: <editor> In Gelsema, E. S., and Kanal, L. N., eds., </editor> <booktitle> Pattern Recognition in Practice IV, </booktitle> <volume> 403413. </volume> <publisher> Elsevier Science B.V. </publisher>
Reference: <author> Foley, J. D., and Sammon, Jr., J. </author> <year> 1975. </year> <title> An optimal set of discriminant vectors. </title> <journal> IEEE Trans. on Computers 24(3):281 289. </journal>
Reference-contexts: The 3D features are generated during stereo processing of a calibrated image pair (Schultz 1995) and were recently shown to be highly discriminative in this task (Wang et al. 1997). The Foley-Sammon transform <ref> (FST, Foley & Sammon 1975) </ref> was employed as a classifier. FST is a linear discriminant method mouse clicks during interactive training of a classifier. Each mouse click generated either a 3fi3 square of training pixels, or a single training pixel.
Reference: <author> Hafner, W., and Munkelt, O. </author> <year> 1997. </year> <title> Using color for detecting persons in image sequences. Pattern Recognition and Image Analysis 7(1):4752. </title>
Reference-contexts: In particular, pixel classifiers are an important component of many vision applications, e.g. texture-based segmentation (du Buf, Kardan, & Spann 1990; Blume & Ballard 1997), image understanding (Campbell et al. 1997; Jolly & Gupta 1996), object recognition <ref> (Hafner & Munkelt 1997) </ref>, obstacle detection (Langer & Jochem 1996), and geoscience (Carr 1996; Carpenter et al. 1997). Despite these abundant applications, the construction of high-performance pixel classifiers usually involves substantial cost in terms of human effort.
Reference: <author> Haralick, R.; Shanmugam, K.; and Dinstein, I. </author> <year> 1973. </year> <title> Textural features for image classification. </title> <journal> IEEE Trans. Systems, Man, and Cybernetics 3(6):610621. </journal>
Reference-contexts: Hood, Texas (Figure 5a). The goal was to build a pixel classifier to recognize the four terrain classes BARE GROUND (road, riverbed), FOLIAGE (trees, shrubs), GRASS, and SHADOW. Their most effective feature set consisted of 12 co-occurence features (angular second moment, contrast, and entropy at four angular orientations each <ref> (Haralick, Shanmugam, & Dinstein 1973) </ref>), four three-dimensional features (Wang et al. 1997), and the gray value. The co-occurence features employed have previously been claimed to be highly effective for classification (Conners & Harlow 1980; du Buf, Kardan, & Spann 1990; Ohanian & Dubes 1992; Weszka, Dyer, & Rosenfeld 1976).
Reference: <author> Jolly, M.-P. D., and Gupta, A. </author> <year> 1996. </year> <title> Color and texture fusion: application to aerial image segmentation and GIS updating. </title> <booktitle> In IEEE Workshop on Applications of Computer Vision, </booktitle> <pages> 27. </pages>
Reference: <author> Langer, D., and Jochem, T. </author> <year> 1996. </year> <title> Fusing radar and vision for detecting, classifying and avoiding roadway obstacles. </title> <booktitle> In Proc. IEEE Intelligent Vehicles Symposium, </booktitle> <pages> 333338. </pages>
Reference-contexts: In particular, pixel classifiers are an important component of many vision applications, e.g. texture-based segmentation (du Buf, Kardan, & Spann 1990; Blume & Ballard 1997), image understanding (Campbell et al. 1997; Jolly & Gupta 1996), object recognition (Hafner & Munkelt 1997), obstacle detection <ref> (Langer & Jochem 1996) </ref>, and geoscience (Carr 1996; Carpenter et al. 1997). Despite these abundant applications, the construction of high-performance pixel classifiers usually involves substantial cost in terms of human effort.
Reference: <author> Liu, K.; Cheng, Y.; and Yang, J. </author> <year> 1993. </year> <title> Algebraic feature extraction for image recognition based on an optimal discriminant criterion. </title> <journal> Pattern Recognition 26(6):903911. </journal>
Reference: <author> Lovell, B. C., and Bradley, A. P. </author> <year> 1996. </year> <title> The multiscale classifier. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell. </journal> <volume> 18(2):124 137. </volume>
Reference: <author> Ohanian, P., and Dubes, R. </author> <year> 1992. </year> <title> Performance evaluation for four classes of textural features. </title> <journal> Pattern Recognition 25(8):819833. </journal>
Reference: <author> Quinlan, J. R. </author> <year> 1993. </year> <title> Programs for machine learning. </title> <publisher> Mor-gan Kaufmann. </publisher>
Reference-contexts: It can also operate in conventional batch mode, where the full set of training instances is made available at once. The classification accuracy is statistically indistinguishable (Utgoff, Berkman, & Clouse 1997) from that of C4.5 <ref> (Quinlan 1993) </ref>, which is widely considered one of the leading decision tree algorithms. One drawback of univariate decision trees like ITI is that decision boundaries best described by functions of multiple features must be approximated by multiple univariate decisions.
Reference: <author> Salzberg, S.; Delcher, A.; Heath, D.; and Kasif, S. </author> <year> 1995. </year> <title> Best-case results for nearest-neighbor learning. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell. 17(6):599608. </journal>
Reference-contexts: Therefore, one would like to be able to provide a small number of well chosen training instances relatively quickly, at no loss of classification accuracy, or even improved performance <ref> (Salzberg et al. 1995) </ref>. There are other benefits to keeping the training set small. For example, a typical decision tree classifier will make every attempt to place training instances of different classes in separate leaf nodes, as long as they are discernible based on their feature vectors.
Reference: <author> Schlimmer, J. C., and Fisher, D. </author> <year> 1986. </year> <title> A case study of incremental concept induction. </title> <booktitle> In Proc. Fifth Nat. Conf. on Artificial Intelligence, 496501. </booktitle> <address> Philadelphia, PA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The method refines the tree incrementally, and the result is dependent on the order of the training instances. The Incremental Tree Inducer ITI (Utgoff 1994; Utgoff, Berkman, & Clouse 1997) solves this problem by storing all data relevant for restructuring a decision tree within the nodes <ref> (Schlimmer & Fisher 1986) </ref>. It can accept and incorporate training instances serially without needing to rebuild the tree repeatedly. Another desirable characteristic is that it produces the same tree for the same accumulated set of training instances, regardless of the order in which they are received.
Reference: <author> Schultz, H. </author> <year> 1995. </year> <title> Terrain reconstruction from widely separated images. </title> <booktitle> Proc. SPIE 2486:113123. </booktitle>
Reference-contexts: The co-occurence features employed have previously been claimed to be highly effective for classification (Conners & Harlow 1980; du Buf, Kardan, & Spann 1990; Ohanian & Dubes 1992; Weszka, Dyer, & Rosenfeld 1976). The 3D features are generated during stereo processing of a calibrated image pair <ref> (Schultz 1995) </ref> and were recently shown to be highly discriminative in this task (Wang et al. 1997). The Foley-Sammon transform (FST, Foley & Sammon 1975) was employed as a classifier. FST is a linear discriminant method mouse clicks during interactive training of a classifier.
Reference: <author> Utgoff, P. E.; Berkman, N. C.; and Clouse, J. A. </author> <year> 1997. </year> <title> Decision tree induction based on efficient tree restructuring. </title> <booktitle> Machine Learning 29(1):544. </booktitle>
Reference-contexts: It can also operate in conventional batch mode, where the full set of training instances is made available at once. The classification accuracy is statistically indistinguishable <ref> (Utgoff, Berkman, & Clouse 1997) </ref> from that of C4.5 (Quinlan 1993), which is widely considered one of the leading decision tree algorithms. One drawback of univariate decision trees like ITI is that decision boundaries best described by functions of multiple features must be approximated by multiple univariate decisions.
Reference: <author> Utgoff, P. E. </author> <year> 1994. </year> <title> An improved algorithm for incremental induction of decision trees. </title> <booktitle> In Machine Learning: Proc. 11th Int. Conf., </booktitle> <volume> 318325. </volume> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Wang, X.; Stolle, F.; Schultz, H.; Riseman, E. M.; and Han-son, A. R. </author> <year> 1997. </year> <title> Using three-dimensional features to improve terrain clasification. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition, </booktitle> <pages> 915920. </pages>
Reference-contexts: The image in that belong to different classes (FOLIAGE and ROOF) but are indistinguishable using the given feature set. Therefore, perfect classification is not achievable, given these features. Quantitative Results We now compare performance of our On-Line Classifier with a previously published classification result by Wang et al. <ref> (Wang et al. 1997) </ref>. We chose this example because it uses state-of-the-art techniques, the task is realistic, and their data include ground truth. Wang et al. considered a monochromatic aerial image (1,936,789 pixels) of a rural area in Ft. Hood, Texas (Figure 5a). <p> Their most effective feature set consisted of 12 co-occurence features (angular second moment, contrast, and entropy at four angular orientations each (Haralick, Shanmugam, & Dinstein 1973)), four three-dimensional features <ref> (Wang et al. 1997) </ref>, and the gray value. The co-occurence features employed have previously been claimed to be highly effective for classification (Conners & Harlow 1980; du Buf, Kardan, & Spann 1990; Ohanian & Dubes 1992; Weszka, Dyer, & Rosenfeld 1976). <p> The 3D features are generated during stereo processing of a calibrated image pair (Schultz 1995) and were recently shown to be highly discriminative in this task <ref> (Wang et al. 1997) </ref>. The Foley-Sammon transform (FST, Foley & Sammon 1975) was employed as a classifier. FST is a linear discriminant method mouse clicks during interactive training of a classifier. Each mouse click generated either a 3fi3 square of training pixels, or a single training pixel. <p> This was one of their best training sets found after extensive experimentation. The 16916 training pixels constitute less than 1% of the entire image (1,936,789 pixels). Ground truth was generated by hand. The achieved classification accuracy is 83.4% <ref> (Wang et al. 1997) </ref>. To provide a baseline of the performance of ITI with respect to FST on this task, we ran ITI in conventional batch mode on the same input data as described above, using the full training set of 16916 pixels.
Reference: <author> Weszka, J.; Dyer, C.; and Rosenfeld, A. </author> <year> 1976. </year> <title> A comparative study of texture measures for terrain classification. </title> <journal> IEEE Trans. Systems, Man, and Cybernetics 6(4):269285. </journal>
References-found: 27

