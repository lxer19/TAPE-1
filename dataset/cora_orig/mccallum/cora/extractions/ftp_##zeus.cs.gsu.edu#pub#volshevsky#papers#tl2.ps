URL: ftp://zeus.cs.gsu.edu/pub/volshevsky/papers/tl2.ps
Refering-URL: http://www.cs.gsu.edu/~matvro/new.html
Root-URL: http://www.cs.gsu.edu
Email: e-mail: volshevsky@cs.gsu.edu  
Title: Eigenvector Computation for Almost Unitary Hessenberg Matrices and Inversion of Szeg-o-Vandermonde Matrices via Discrete Transmission Lines  
Author: Vadim Olshevsky 
Keyword: Key words: Horner polynomials, Szeg-o polynomials, Vandermonde matrices, Szeg-o-Vandermonde matrices, fast algorithms, signal flow graph, discrete transmission line, lattice filter structure, Markel-Gray filter, companion matrices, confederate matrices, unitary Hessenberg matrices.  
Note: AMS subject classification: 65F05, 65L20, 15A09, 15A23  
Web: web: http://www.cs.gsu.edu/~matvro  
Address: Plaza, Atlanta, GA 30303  
Affiliation: Department of Mathematics and Computer Science Georgia State University University  
Abstract: In this paper we use a discrete transmission line model (known to geophysicists as a layered earth model) to derive several computationally efficient solutions for the following three problems. (i) As is well-known, a Hessenberg matrix capturing recurrence relations for Szeg-o polynomials differs from unitary only by its last column. Hence, the first problem is how to rapidly evaluate the eigenvectors of this almost unitary Hessenberg matrix. (ii) The second problem is to design a fast O(n 2 ) algorithm for inversion of Szeg-o-Vandermonde matrices (generalizing the well-known Traub algorithm for inversion of the usual Vandermonde matrices). (iii) Finally, the third problem is to extend the well-known Horner rule to evaluate a polynomial represented in the basis of Szeg-o polynomials. As we shall see, all three problems are closely related, and their solutions can be computed by the same family of fast algorithms. Although all the results can be derived algebraically, here we reveal a connection to system theory to deduce these algorithms via elementary operations on signal flow graphs for digital filter structures, including the celebrated Markel-Gray filter, widely used in speech processing, and certain other filter structures. This choice not only clarifies the derivation and suggests a variety of possible computational schemes, but it also makes an interesting connection to many other results related to Szeg-o polynomials which have already been interpreted via signal flow graphs for (generalized) lattice filter structures, including the formulas of the Gohberg-Semencul type for inversion of Toeplitz-like matrices, Schur-type and Levinson-type algorithms, etc. For example, this connection allows us to show that moment matrices corresponding to the Horner-Szeg-o polynomials, though not Toeplitz, are quasi-Toeplitz, i.e., they have a certain shift-invariance property. 
Abstract-found: 1
Intro-found: 1
Reference: [A65] <author> N.I.Akhiezer, </author> <title> The classical moment problem and some related problems in analysis, </title> <publisher> Hafner Publishing Co., </publisher> <address> New York, </address> <year> 1965. </year>
Reference-contexts: For example, a model of a vibrating string with n discrete masses served as a starting point for many interesting mathematical investigations, see, e.g., [K52] or Appendix in <ref> [A65] </ref>.
Reference: [ACR96] <author> G.S.Ammar, D.Calvetti and L.Reichel, </author> <title> Continuation methods for the computation of zeros of Szeg-o polynomials, Linear Algebra and Its Applications, </title> <type> 249: </type> <month> 125-155 </month> <year> (1996). </year>
Reference-contexts: In particular in <ref> [ACR96] </ref> one can find an algorithm to compute the eigenvalues of the general almost unitary Hessenberg matrices.
Reference: [AGR86] <author> G.S.Ammar, W.B.Gragg and L.Reichel, </author> <title> On the eigenproblem for orthogonal matrices, </title> <booktitle> Proc. of the 25th IEEE Conference on Decision and Control, </booktitle> <address> Athens, Greece, </address> <year> 1963-1966 (1986). </year>
Reference-contexts: The computational issues related to such almost unitary Hessenberg matrices were discussed in numerical linear algebra literature, see, e.g., [G82] for a connection to Gaussian quadrature on the unit circle, [G86] for the unitary Hessenberg QR-algorithm (and [G97] for its numerically accurate implementation), <ref> [AGR86] </ref>, [GR87], [AGR91], [BGE91] for direct and inverse unitary eigenvalue problems, [AGR87], [AGR92] for some applications. In particular in [ACR96] one can find an algorithm to compute the eigenvalues of the general almost unitary Hessenberg matrices.
Reference: [AGR87] <author> G.S.Ammar, W.B.Gragg and L.Reichel, </author> <title> Determination of Pisarenko frequency estimates as eigenvalues of orthonormal matrices, </title> <booktitle> SPIE vol. 826, Proc. of the 1987 SPIE conference on Advanced Algorithms and Architectures for Signa Processing II, </booktitle> <month> 143-145 </month> <year> (1987). </year>
Reference-contexts: to such almost unitary Hessenberg matrices were discussed in numerical linear algebra literature, see, e.g., [G82] for a connection to Gaussian quadrature on the unit circle, [G86] for the unitary Hessenberg QR-algorithm (and [G97] for its numerically accurate implementation), [AGR86], [GR87], [AGR91], [BGE91] for direct and inverse unitary eigenvalue problems, <ref> [AGR87] </ref>, [AGR92] for some applications. In particular in [ACR96] one can find an algorithm to compute the eigenvalues of the general almost unitary Hessenberg matrices.
Reference: [AGR91] <author> G.S.Ammar, W.B.Gragg and L.Reichel, </author> <title> Constructing a unitary Hessenberg matrix from spectral data, in Numerical Linear Algebra, </title> <booktitle> Digital Signal Processing and Parallel Algorithms (G.Golub and P.Van Doores, Eds.), </booktitle> <pages> 385-595, </pages> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: The computational issues related to such almost unitary Hessenberg matrices were discussed in numerical linear algebra literature, see, e.g., [G82] for a connection to Gaussian quadrature on the unit circle, [G86] for the unitary Hessenberg QR-algorithm (and [G97] for its numerically accurate implementation), [AGR86], [GR87], <ref> [AGR91] </ref>, [BGE91] for direct and inverse unitary eigenvalue problems, [AGR87], [AGR92] for some applications. In particular in [ACR96] one can find an algorithm to compute the eigenvalues of the general almost unitary Hessenberg matrices.
Reference: [AGR92] <author> G.S.Ammar, W.B.Gragg and L.Reichel, </author> <title> Downdating of Szeg-o polynomials and data-fitting applications, </title> <journal> Linear Algebra and Its Appl., </journal> <volume> 172: </volume> <month> 315-336 </month> <year> (1992). </year>
Reference-contexts: such almost unitary Hessenberg matrices were discussed in numerical linear algebra literature, see, e.g., [G82] for a connection to Gaussian quadrature on the unit circle, [G86] for the unitary Hessenberg QR-algorithm (and [G97] for its numerically accurate implementation), [AGR86], [GR87], [AGR91], [BGE91] for direct and inverse unitary eigenvalue problems, [AGR87], <ref> [AGR92] </ref> for some applications. In particular in [ACR96] one can find an algorithm to compute the eigenvalues of the general almost unitary Hessenberg matrices.
Reference: [AGR93] <author> G.S.Ammar, W.B.Gragg and L.Reichel, </author> <title> An analogue for the Szeg-o polynomials of the Clenshaw algorithm, </title> <journal> J. Computational Appl. Math., </journal> <volume> 46: </volume> <month> 211-216 </month> <year> (1993). </year>
Reference-contexts: Szeg-o polynomials appear in a number of engineering applications, so the problem of evaluating (1.8) has been considered in <ref> [AGR93] </ref>. As we shall see in Sec. 4.3, there are limitations in the range of application of their two-term algorithm. <p> Note that the above mentioned two-term evaluation algorithm of <ref> [AGR93] </ref> solves the third problem only. Here we suggest a modified two-term and a new three-term algorithms that solve all three above problems. These algorithms are based on various recursions and realizations for what we suggest to call the Horner-Szeg-o polynomials. <p> fl oe fi 1 ae 1 oe 2 ae 2 1 1 1 1 * 2 ~ OE # * 0 (z 1 ~ OE # * 1 ) (z 1 ~ OE # b 0 b 1 b 2 b 3 y (z) 4.3 The Ammar-Gragg-Reichel evaluation algorithm In <ref> [AGR93] </ref> a different recursion, ~o n = n ~o k = k b k + x (o k+1 + ae fl ae k+1 o k+1 + ~o k+1 ; H (x) = o 0 + ~o 0 ; (4.10) to evaluate H (x) in (4.1) was deduced algebraically.
Reference: [B75] <author> S.Barnett, </author> <title> A companion matrix analogue for orthogonal polynomials, </title> <journal> Linear Algebra Appl., </journal> <volume> 12: </volume> <month> 197-208 </month> <year> (1975). </year>
Reference-contexts: Further, for the important case of real orthogonal polynomials (satisfying three-term recurrence relations) the matrix C Q (H) differs from tridiagonal only by its last column, in this special case it is called a comrade matrix <ref> [B75] </ref>.
Reference: [BC92] <author> M.Bakonyi and T.Constantinescu, </author> <title> Schur's algorithm and several applications, </title> <booktitle> in Pitman Research Notes in Mathematics Series, </booktitle> <volume> vol. 61, </volume> <publisher> Longman Scientific and Technical, </publisher> <address> Harlow, </address> <year> 1992. </year>
Reference-contexts: See also [F96]. In the operator theory literature the structure in (1.6) is associated with the Naimark dilation, see, e.g., [C84], <ref> [BC92] </ref>, [FF89].
Reference: [BGE91] <author> A.Bunse-Gerstner and L.Elsner, </author> <title> Schur parameter pensils for the solution of unitary eigenprob-lem, </title> <journal> Linear Algebra and Its Appl., </journal> <pages> 154-156: </pages> <month> 741-778 </month> <year> (1991). </year>
Reference-contexts: The computational issues related to such almost unitary Hessenberg matrices were discussed in numerical linear algebra literature, see, e.g., [G82] for a connection to Gaussian quadrature on the unit circle, [G86] for the unitary Hessenberg QR-algorithm (and [G97] for its numerically accurate implementation), [AGR86], [GR87], [AGR91], <ref> [BGE91] </ref> for direct and inverse unitary eigenvalue problems, [AGR87], [AGR92] for some applications. In particular in [ACR96] one can find an algorithm to compute the eigenvalues of the general almost unitary Hessenberg matrices.
Reference: [BK86] <author> A.Bruckstein and T.Kailath, </author> <title> Some Matrix Factorization Identities for Discrete Inverse Scattering, </title> <journal> Linear Algebra Appl., </journal> <volume> 74: </volume> <month> 157-172 </month> <year> (1986). </year>
Reference-contexts: We refer to [KBM86] (see also <ref> [BK86] </ref>, [BK87a], [BK87b]) for a nice explanation of how the physical properties of a transmission line (i.e., causality, symmetry and energy conservation) can be used to provide a nice interpretation for the classical Schur and Levinson algorithms for factorization 1 This name is used in the inverse scattering context; fae k
Reference: [BK87a] <author> A.Bruckstein and T.Kailath, </author> <title> Inverse Scattering for Discrete Transmission Line Models, </title> <journal> SIAM Review, </journal> <volume> 29: </volume> <month> 359-389 </month> <year> (1987). </year>
Reference-contexts: We refer to [KBM86] (see also [BK86], <ref> [BK87a] </ref>, [BK87b]) for a nice explanation of how the physical properties of a transmission line (i.e., causality, symmetry and energy conservation) can be used to provide a nice interpretation for the classical Schur and Levinson algorithms for factorization 1 This name is used in the inverse scattering context; fae k g
Reference: [BK87b] <author> A.Bruckstein and T.Kailath, </author> <title> An Inverse Scattering Framework for Several Problems in Signal Processing, </title> <journal> IEEE ASSP Magazine, </journal> <month> January </month> <year> 1987, </year> <pages> 6-20. </pages>
Reference-contexts: We refer to [KBM86] (see also [BK86], [BK87a], <ref> [BK87b] </ref>) for a nice explanation of how the physical properties of a transmission line (i.e., causality, symmetry and energy conservation) can be used to provide a nice interpretation for the classical Schur and Levinson algorithms for factorization 1 This name is used in the inverse scattering context; fae k g are
Reference: [C55] <author> C.Clenshaw, </author> <title> A note on summation of Chebyshev series, </title> <journal> M.T.A.C., </journal> <volume> 9(51): </volume> <month> 118-120 </month> <year> (1955). </year>
Reference: [C84] <author> T.Constantinescu, </author> <title> On the structure of the Naimark dilation, </title> <journal> J. of Operator Theory, </journal> <volume> 12: </volume> <month> 159-175 </month> <year> (1984). </year>
Reference-contexts: See also [F96]. In the operator theory literature the structure in (1.6) is associated with the Naimark dilation, see, e.g., <ref> [C84] </ref>, [BC92], [FF89].
Reference: [CR93] <author> D.Calvetti and L.Reichel, </author> <title> Fast inversion of Vandermonde-like matrices involving orthogonal polynomials, </title> <journal> BIT, </journal> <volume> 33: </volume> <month> 473-484 </month> <year> (1993). </year>
Reference-contexts: This algorithm was ex tended in [HHR89], <ref> [CR93] </ref> to invert what we call three-term Vandermonde matrices V Q (x) = fi fl i.e those involving polynomials fQ k (x)g satisfying three-term recurrence relations (see [GO94a] for the formulas and algorithms for Chebyshev-Vandermonde matrices). <p> One sees that (3.15) is just a special case of (3.11). According to Proposition 3.2, this Clenshaw recursion not only evaluates H (x), but it also inverts the corresponding three-term Vandermonde matrix, thus being closely related to the algorithms for this purpose specified in [HHR89], [GO94a], <ref> [CR93] </ref>. 4 Horner-Szeg-o polynomials, inversion of Szeg-o-Vandermonde ma trices and eigenvector computation for almost unitary Hessen berg matrices 4.1 Various realizations for the Szeg-o polynomials Here we consider a representation in the basis of the Szeg-o polynomials H (z 1 ) = b n OE # # # Szeg-o polynomials #
Reference: [D82] <author> J.M.Delosme, </author> <title> Algorithms for finite shift-rank processes, </title> <institution> Ph.D.Thesis, Stanford University, </institution> <year> 1982. </year>
Reference-contexts: We also refer to <ref> [D82] </ref>, [LA83], [LAK84] for a discrete-transmission-lines approach 2 to study the more general classes of matrices with Toeplitz-like structure. 1.2 Problem formulation. <p> The association of the classical Schur algorithm with discrete transmission lines offers a variety of other possibilities to parameterize the class of quasi-Toeplitz matrices, cf., e.g., <ref> [D82] </ref> and [LA83].
Reference: [F96] <author> P.Fuhrmann, </author> <title> A polynomial approach to linear algebra, </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: We also refer to a recent monograph [R95] for a nice description of connections of C # (H) to the classical Schur and Levinson algorithms, and to lattice filter structures. See also <ref> [F96] </ref>. In the operator theory literature the structure in (1.6) is associated with the Naimark dilation, see, e.g., [C84], [BC92], [FF89]. <p> This realization is canonical, and it is called observer-type, see, e.g., [K80], <ref> [F96] </ref> because the output is read from the state variables through the taps. <p> the overall transfer function H (z). y (z) oe * 6 * oe ~p 2 (z) a 1 x 2 z 1 oe * 6 * oe 6 ~p 0 (z) oe u (z) The realization in Fig. 3 is also canonical, and it is called controller-type, see, e.g., [K80], <ref> [F96] </ref> because the input, u (z), is directly connected to each of the state variables. 2.3.3 The standard Horner polynomials Now let us examine the partial transfer function for the two above realizations.
Reference: [FF89] <author> C.Foias and A.E.Frazho, </author> <title> The Commutant Lifting Approach to Interpolation Problems, </title> <publisher> Birkhauser Verlag, </publisher> <year> 1989. </year>
Reference-contexts: See also [F96]. In the operator theory literature the structure in (1.6) is associated with the Naimark dilation, see, e.g., [C84], [BC92], <ref> [FF89] </ref>.
Reference: [FMKL79] <author> B.Friedlander, M.Morf, T.Kailath and L.Ljung, </author> <title> New inversion formulas for matrices classified in terms of their distance from Toeplitz matrices, Linear ALgebra and Its Applications, </title> <type> 27: </type> <month> 31-60 </month> <year> (1979). </year>
Reference-contexts: This, of course, will imply that it will no longer be Toeplitz, but we next show that it will nevertheless have a similar shift-invariance property. 5.4 Matrices with shift-invariant structure An n fi n matrix R is said to be Toeplitz-like <ref> [FMKL79] </ref>, [KKM79], if its displacement rank, ff = rank (R ZRZ fl ) (5.7) 19 is small compared to the size n of R. Here Z is the lower shift matrix, so that ZRZ fl is obtained from R by just shifting all the entries along the diagonals.
Reference: [G48] <author> L.Y.Geronimus, </author> <title> Polynomials orthogonal on a circle and their applications, </title> <journal> Amer. Math. </journal> <note> Trans--lations, 3 1-78 (1954) (Russian original 1948). </note>
Reference-contexts: : : : ; x n1 g one is able to parameterize the first (n + 1) Szeg-o polynomials # = fOE # k=0 by only (n + 1) parameters f 0 ; ae 1 ; : : : ; ae n g via the well-known two-term recurrence relations [GS58], <ref> [G48] </ref>, OE 0 (x) = 0 1 OE k+1 (x) = k+1 1 ae fl ae k+1 1 1 0 OE k (x) : (1.2) The auxiliary polynomials fOE k (x)g involved in (1.2) obviously have a reversal form: OE k (x) = z k [OE # ( 1 x fl <p> In the next lemma we use several recurrence relations for # to draw the signal flow graphs realizing H (z 1 ). 12 Lemma 4.1 The polynomial in (4.1) can be realized using of the recurrences listed next. 1. Two-term recurrence relations. [GS58], <ref> [G48] </ref> OE 0 (x) = 0 1 OE k+1 (x) = k+1 1 ae fl ae k+1 1 1 0 OE k (x) ; (4.2) Using (4.2), the polynomial in (4.1) can be realized as shown in Fig. 6 u (z) - * A A AU -z 1 - * A <p> Three-term recurrence relations. <ref> [G48] </ref> OE 0 (x) = 0 # 1 (x OE 0 (x) + ae 1 ae fl # where ae 0 = 1, and OE k (x) = [ k ae k 1 ] OE k1 (x) ae k1 k # Using (4.3), the polynomial in (4.1) can be realized as
Reference: [G82] <author> W.B.Gragg, </author> <title> Positive definite Toeplitz matrices, the Arnoldi process for isometric operators, and Gaussian quadrature on the unit circle (in Russian). In : E.S. Nikolaev (Ed.), Numerical methods in Linear Algebra, </title> <publisher> Moscow University Press, </publisher> <month> 16-32 </month> <year> (1982). </year> <title> English translation in : J. </title> <journal> Comput. and Appl. Math., </journal> <volume> 46: </volume> <month> 183-198 </month> <year> (1993). </year>
Reference-contexts: See also [F96]. In the operator theory literature the structure in (1.6) is associated with the Naimark dilation, see, e.g., [C84], [BC92], [FF89]. The computational issues related to such almost unitary Hessenberg matrices were discussed in numerical linear algebra literature, see, e.g., <ref> [G82] </ref> for a connection to Gaussian quadrature on the unit circle, [G86] for the unitary Hessenberg QR-algorithm (and [G97] for its numerically accurate implementation), [AGR86], [GR87], [AGR91], [BGE91] for direct and inverse unitary eigenvalue problems, [AGR87], [AGR92] for some applications. <p> Similarly, Szeg-o-Vandermonde matrices appear in the context of Gaussian quadrature on the unit circle <ref> [G82] </ref>, in the context of Remez algorithm [R57], [PM72] in the case when the underlying basis consists of Szeg-o polynomials, elsewhere.
Reference: [G86] <author> W.B.Gragg, </author> <title> The QR algorithm for unitary Hessenberg matrices, </title> <journal> J.Comput. Appl. Math., </journal> <volume> 16: </volume> <month> 1-8 </month> <year> (1986). </year>
Reference-contexts: The computational issues related to such almost unitary Hessenberg matrices were discussed in numerical linear algebra literature, see, e.g., [G82] for a connection to Gaussian quadrature on the unit circle, <ref> [G86] </ref> for the unitary Hessenberg QR-algorithm (and [G97] for its numerically accurate implementation), [AGR86], [GR87], [AGR91], [BGE91] for direct and inverse unitary eigenvalue problems, [AGR87], [AGR92] for some applications. In particular in [ACR96] one can find an algorithm to compute the eigenvalues of the general almost unitary Hessenberg matrices.
Reference: [G97] <author> W.B.Gragg, </author> <title> A stabilized UHQR algorithm, </title> <type> preprint, </type> <year> 1997. </year>
Reference-contexts: The computational issues related to such almost unitary Hessenberg matrices were discussed in numerical linear algebra literature, see, e.g., [G82] for a connection to Gaussian quadrature on the unit circle, [G86] for the unitary Hessenberg QR-algorithm (and <ref> [G97] </ref> for its numerically accurate implementation), [AGR86], [GR87], [AGR91], [BGE91] for direct and inverse unitary eigenvalue problems, [AGR87], [AGR92] for some applications. In particular in [ACR96] one can find an algorithm to compute the eigenvalues of the general almost unitary Hessenberg matrices.
Reference: [GF74] <author> I.Gohberg and I.Feldman, </author> <title> Convolution equations and projection methods for their solutions, Translations of Mathematical Monographs, 41, </title> <journal> Amer. Math. Soc., </journal> <year> 1974. </year>
Reference-contexts: be used to provide a nice interpretation for the classical Schur and Levinson algorithms for factorization 1 This name is used in the inverse scattering context; fae k g are also called parcor coefficients, or often Schur parameters 2 of Toeplitz matrices, as well as for the Gohberg-Semencul formula [GS72], <ref> [GF74] </ref> for inversion of Toeplitz matrices. We also refer to [D82], [LA83], [LAK84] for a discrete-transmission-lines approach 2 to study the more general classes of matrices with Toeplitz-like structure. 1.2 Problem formulation.
Reference: [GL83] <author> W.B.Gragg and A.Lindquist, </author> <title> On the partial realization problem, </title> <journal> Linear Algebra and Its Appl., </journal> <volume> 50: </volume> <month> 277-319 </month> <year> (1983). </year>
Reference-contexts: No possible omissions are intentional; signal flow graphs are widely used to compactly represent and interpret various recursions, see, e.g., [K79], <ref> [GL83] </ref> among others. 3 recursive nested realization algorithm was specified for the structure in (1.6), see also [K85] for the further extensions.
Reference: [GKO95] <author> I.Gohberg, T.Kailath and V.Olshevsky, </author> <title> Fast Gaussian elimination with partial pivoting for matrices with displacement structure, </title> <journal> Math. of Computation, </journal> <volume> 64: </volume> <month> 1557-1576 </month> <year> (1985). </year>
Reference-contexts: Finally note that the displacement structure approach allows us to study the more general classes of Szeg-o-Vandermonde-like matrices, and polynomial Vandermonde-like matrices, see, e.g., [KO95], [KO97a] and also [GO94b], <ref> [GKO95] </ref>. 21
Reference: [GO94a] <author> I.Gohberg and V.Olshevsky, </author> <title> Fast inversion of Chebyshev-Vandermonde matrices, </title> <journal> Numerische Mathematik, </journal> <volume> 67, No. 1: </volume> <month> 71-92 </month> <year> (1994). </year>
Reference-contexts: This algorithm was ex tended in [HHR89], [CR93] to invert what we call three-term Vandermonde matrices V Q (x) = fi fl i.e those involving polynomials fQ k (x)g satisfying three-term recurrence relations (see <ref> [GO94a] </ref> for the formulas and algorithms for Chebyshev-Vandermonde matrices). Similarly, Szeg-o-Vandermonde matrices appear in the context of Gaussian quadrature on the unit circle [G82], in the context of Remez algorithm [R57], [PM72] in the case when the underlying basis consists of Szeg-o polynomials, elsewhere. <p> One sees that (3.15) is just a special case of (3.11). According to Proposition 3.2, this Clenshaw recursion not only evaluates H (x), but it also inverts the corresponding three-term Vandermonde matrix, thus being closely related to the algorithms for this purpose specified in [HHR89], <ref> [GO94a] </ref>, [CR93]. 4 Horner-Szeg-o polynomials, inversion of Szeg-o-Vandermonde ma trices and eigenvector computation for almost unitary Hessen berg matrices 4.1 Various realizations for the Szeg-o polynomials Here we consider a representation in the basis of the Szeg-o polynomials H (z 1 ) = b n OE # # # Szeg-o polynomials
Reference: [GO94b] <author> I.Gohberg and V.Olshevsky, </author> <title> Fast state space algorithms for matrix Nehari and Nehari-Takagi interpolation problems, Integral Equations and Operator Theory, </title> <journal> 20, </journal> <volume> No. 1: </volume> <month> 44-83 </month> <year> (1994). </year>
Reference-contexts: Finally note that the displacement structure approach allows us to study the more general classes of Szeg-o-Vandermonde-like matrices, and polynomial Vandermonde-like matrices, see, e.g., [KO95], [KO97a] and also <ref> [GO94b] </ref>, [GKO95]. 21
Reference: [GO97] <author> I.Gohberg and V.Olshevsky, </author> <title> The fast generalized Parker-Traub algorithm for inversion of Van-dermonde and related matrices, </title> <journal> J.of Complexity, </journal> <volume> 13(2): </volume> <month> 208-234 </month> <year> (1997). </year>
Reference-contexts: OE 1 (x 1 ) OE n1 (x 1 ) # # # . . . . . . # # # 3 7 5 There is a fast O (n 2 ) Parker-Forney-Traub algorithm to invert usual Vandermonde matrices V P (x) = fi x i , see, e.g., <ref> [GO97] </ref> for many relevant references and some generalizations. <p> diag (c 1 ; : : : c n ); (2.12) 5 with c i = H 0 (x i ) = n k6=i : (2.13) The formula (2.12) leads to the widely known fast O (n 2 ) Parker-Forney-Traub algorithm to compute V P (x) 1 , see, e.g., <ref> [GO97] </ref> for many relevant references and connections. 2.2 Horner polynomials and eigenvectors of companion matrices Let the nodes fx 1 ; : : : ; x n g be the zeros of H (x) = b 0 + b 1 x + : : : + b n x n .
Reference: [GR87] <author> W.B.Gragg and L.Reichel, </author> <title> A divide and conquer algorithm for unitary eigenproblem, in Hypercube Multiprocessors (M.T.Heath, </title> <editor> ed.), </editor> <publisher> SIAM Publications, </publisher> <address> Philadelphia, </address> <month> 639-647 </month> <year> (1987). </year>
Reference-contexts: The computational issues related to such almost unitary Hessenberg matrices were discussed in numerical linear algebra literature, see, e.g., [G82] for a connection to Gaussian quadrature on the unit circle, [G86] for the unitary Hessenberg QR-algorithm (and [G97] for its numerically accurate implementation), [AGR86], <ref> [GR87] </ref>, [AGR91], [BGE91] for direct and inverse unitary eigenvalue problems, [AGR87], [AGR92] for some applications. In particular in [ACR96] one can find an algorithm to compute the eigenvalues of the general almost unitary Hessenberg matrices.
Reference: [GS58] <author> U.Grenader and G.Szeg-o, </author> <title> Toeplitz forms and Applications, </title> <institution> University of California Press, </institution> <year> 1958. </year>
Reference-contexts: ; : : : ; x n1 g one is able to parameterize the first (n + 1) Szeg-o polynomials # = fOE # k=0 by only (n + 1) parameters f 0 ; ae 1 ; : : : ; ae n g via the well-known two-term recurrence relations <ref> [GS58] </ref>, [G48], OE 0 (x) = 0 1 OE k+1 (x) = k+1 1 ae fl ae k+1 1 1 0 OE k (x) : (1.2) The auxiliary polynomials fOE k (x)g involved in (1.2) obviously have a reversal form: OE k (x) = z k [OE # ( 1 x <p> In the next lemma we use several recurrence relations for # to draw the signal flow graphs realizing H (z 1 ). 12 Lemma 4.1 The polynomial in (4.1) can be realized using of the recurrences listed next. 1. Two-term recurrence relations. <ref> [GS58] </ref>, [G48] OE 0 (x) = 0 1 OE k+1 (x) = k+1 1 ae fl ae k+1 1 1 0 OE k (x) ; (4.2) Using (4.2), the polynomial in (4.1) can be realized as shown in Fig. 6 u (z) - * A A AU -z 1 - *
Reference: [GS72] <author> I.Gohberg and A.Semencul, </author> <title> On the inversion of finite Toeplitz matrices and their continuous analogs (in Russian), </title> <journal> Mat. Issled., </journal> <volume> 7(2): </volume> <month> 201-233 </month> <year> (1972). </year>
Reference-contexts: can be used to provide a nice interpretation for the classical Schur and Levinson algorithms for factorization 1 This name is used in the inverse scattering context; fae k g are also called parcor coefficients, or often Schur parameters 2 of Toeplitz matrices, as well as for the Gohberg-Semencul formula <ref> [GS72] </ref>, [GF74] for inversion of Toeplitz matrices. We also refer to [D82], [LA83], [LAK84] for a discrete-transmission-lines approach 2 to study the more general classes of matrices with Toeplitz-like structure. 1.2 Problem formulation.
Reference: [HHR89] <author> G.Heinig, W.Hoppe and K.Rost, </author> <title> Structured matrices in interpolation and approximation problems, </title> <journal> Wissenschaftl. Zeitschrift der TU Karl-Marx-Stadt 31, </journal> <volume> 2: </volume> <month> 196-202 </month> <year> (1989). </year>
Reference-contexts: This algorithm was ex tended in <ref> [HHR89] </ref>, [CR93] to invert what we call three-term Vandermonde matrices V Q (x) = fi fl i.e those involving polynomials fQ k (x)g satisfying three-term recurrence relations (see [GO94a] for the formulas and algorithms for Chebyshev-Vandermonde matrices). <p> One sees that (3.15) is just a special case of (3.11). According to Proposition 3.2, this Clenshaw recursion not only evaluates H (x), but it also inverts the corresponding three-term Vandermonde matrix, thus being closely related to the algorithms for this purpose specified in <ref> [HHR89] </ref>, [GO94a], [CR93]. 4 Horner-Szeg-o polynomials, inversion of Szeg-o-Vandermonde ma trices and eigenvector computation for almost unitary Hessen berg matrices 4.1 Various realizations for the Szeg-o polynomials Here we consider a representation in the basis of the Szeg-o polynomials H (z 1 ) = b n OE # # # Szeg-o
Reference: [K52] <author> M.G.Krein, </author> <title> On a generalization of investigations of Stiltjes, </title> <journal> Doklady Akad. Nauk USSR, </journal> <volume> 87: </volume> <month> 881-884 </month> <year> (1952). </year>
Reference-contexts: 1 Introduction 1.1 A physical model 1.1.1 The Szeg-o polynomials Sometimes a physical model, even at first glance simple, can be useful for purely mathematical studies. For example, a model of a vibrating string with n discrete masses served as a starting point for many interesting mathematical investigations, see, e.g., <ref> [K52] </ref> or Appendix in [A65].
Reference: [K85] <author> H.Kimura, </author> <title> Generalized Schwartz Form and Lattice-Ladder Realizations for Digital Filters, </title> <journal> IEEE Transactions on Circuits and Systems, </journal> <volume> 32, No 11: </volume> <month> 1130-1139 </month> <year> (1985). </year>
Reference-contexts: No possible omissions are intentional; signal flow graphs are widely used to compactly represent and interpret various recursions, see, e.g., [K79], [GL83] among others. 3 recursive nested realization algorithm was specified for the structure in (1.6), see also <ref> [K85] </ref> for the further extensions. We also refer to a recent monograph [R95] for a nice description of connections of C # (H) to the classical Schur and Levinson algorithms, and to lattice filter structures. See also [F96].
Reference: [K86] <author> T.Kailath, </author> <title> A theorem of I.Schur and its impact on modern signal processing, in Operator Theory: </title> <booktitle> Advances and Applications (I.Schur methods in Operator Theory and Signal Processing), </booktitle> <volume> 18, </volume> <pages> 9-30, </pages> <publisher> Birkhauser, </publisher> <year> 1986. </year>
Reference-contexts: R ZRZ fl has only two nonzero eigenvalues: one positive and one negative. We next show that moment matrices for the Horner-Szeg-o polynomials are quasi-Toeplitz. To do so we need to recall a well-known connection of quasi-Toeplitz matrices to the celebrated Schur algorithm, see, e.g., <ref> [K86] </ref>. 5.5 The classical Schur algorithm for fast triangular factorization of quasi Toeplitz matrices It was now well-known that the celebrated classical Schur algorithm [S17] in its array form computes the Cholesky factorization for quasi-Toeplitz matrices. The procedure can be briefly described as follows.
Reference: [K79] <author> R.E.Kalman, </author> <title> On partial realizations, transfer functions, and canonical forms, </title> <booktitle> Acta Polytech. Scand., MA31 (1979), </booktitle> <pages> 9-32. </pages>
Reference-contexts: In [KP83] a 2 We listed only a few papers where purely algebraic results were deduced by using the very compact and clarifying arguments based on signal flow diagrams. No possible omissions are intentional; signal flow graphs are widely used to compactly represent and interpret various recursions, see, e.g., <ref> [K79] </ref>, [GL83] among others. 3 recursive nested realization algorithm was specified for the structure in (1.6), see also [K85] for the further extensions.
Reference: [K80] <author> T.Kailath, </author> <title> Linear Systems, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1980. </year>
Reference-contexts: (z)u (z) with a scalar transfer function of the form: H (z) = d + c (zI A) 1 b; (2.16) where A is an n fi n matrix, c is a 1 fi n row, b is an n fi 1 column, and d is a scalar, see, e.g., <ref> [K80] </ref> or [OS89] for more details. <p> This realization is canonical, and it is called observer-type, see, e.g., <ref> [K80] </ref>, [F96] because the output is read from the state variables through the taps. <p> The signal flow graph for (2.22) is given in Fig. 3, and one sees that it is obtained from the one in Fig. 2 by simply reversing the direction of the flow for each branch. A new realization obtained in this way is called transposed [OS89] or dual <ref> [K80] </ref>. <p> change the overall transfer function H (z). y (z) oe * 6 * oe ~p 2 (z) a 1 x 2 z 1 oe * 6 * oe 6 ~p 0 (z) oe u (z) The realization in Fig. 3 is also canonical, and it is called controller-type, see, e.g., <ref> [K80] </ref>, [F96] because the input, u (z), is directly connected to each of the state variables. 2.3.3 The standard Horner polynomials Now let us examine the partial transfer function for the two above realizations.
Reference: [KBM86] <author> T.Kaiath, A.Bruckstein and D.Morgan, </author> <title> Fast Matrix Factoriation via Discrete Transmission Lines, </title> <journal> Linear Algebra Appl., </journal> <volume> 75: </volume> <month> 1-25 </month> <year> (1986). </year>
Reference-contexts: We refer to <ref> [KBM86] </ref> (see also [BK86], [BK87a], [BK87b]) for a nice explanation of how the physical properties of a transmission line (i.e., causality, symmetry and energy conservation) can be used to provide a nice interpretation for the classical Schur and Levinson algorithms for factorization 1 This name is used in the inverse scattering
Reference: [KKM79] <author> T.Kailath, S.Kung and M.Morf, </author> <title> Displacement ranks of matrices and linear equations, </title> <journal> J. Math. Anal. and Appl., </journal> <volume> 68: </volume> <month> 395-407 </month> <year> (1979). </year> <month> 23 </month>
Reference-contexts: This, of course, will imply that it will no longer be Toeplitz, but we next show that it will nevertheless have a similar shift-invariance property. 5.4 Matrices with shift-invariant structure An n fi n matrix R is said to be Toeplitz-like [FMKL79], <ref> [KKM79] </ref>, if its displacement rank, ff = rank (R ZRZ fl ) (5.7) 19 is small compared to the size n of R. Here Z is the lower shift matrix, so that ZRZ fl is obtained from R by just shifting all the entries along the diagonals.
Reference: [KO95] <author> T.Kailath and V.Olshevsky, </author> <title> Displacement structure approach to Chebyshev-Vandermonde and related matrices, Integral Equations and Operator Theory, </title> <type> 22: </type> <month> 65-92 </month> <year> (1995). </year>
Reference-contexts: Finally note that the displacement structure approach allows us to study the more general classes of Szeg-o-Vandermonde-like matrices, and polynomial Vandermonde-like matrices, see, e.g., <ref> [KO95] </ref>, [KO97a] and also [GO94b], [GKO95]. 21
Reference: [KO97a] <author> T.Kailath and V.Olshevsky, </author> <title> Displacement structure approach to polynomial Vandermonde and related matrices, </title> <journal> Linear Algebra and Its Appl., </journal> <volume> 261: </volume> <month> 49-90 </month> <year> (1997). </year>
Reference-contexts: Finally note that the displacement structure approach allows us to study the more general classes of Szeg-o-Vandermonde-like matrices, and polynomial Vandermonde-like matrices, see, e.g., [KO95], <ref> [KO97a] </ref> and also [GO94b], [GKO95]. 21
Reference: [KO97b] <author> T.Kailath and V.Olshevsky, </author> <title> Symmetric and Bunch-Kaufman pivoting for partially structured Cauchy-like matrices with applications to Toeplitz-like linear systems, and to boundary rational matrix interpolation problems, </title> <journal> Linear Algebra and Its Appl., </journal> <volume> 254: </volume> <month> 251-302 </month> <year> (1997). </year>
Reference: [KP83] <author> T.Kailath and B.Porat, </author> <title> State-space generators for orthogonal polynomials, in "Prediction Theory and Harmonic Analysis", </title> <booktitle> the Pesi Masani volume (V.Mandrekar and J.Salehi, </booktitle> <editor> Eds.), </editor> <publisher> North Holland Publishing Company, </publisher> <address> Amsterdam, </address> <month> 131-163 </month> <year> (1983). </year>
Reference-contexts: It has been noted in [M77] (see also [M74]) and elaborated in [ML80], [L80] (and independently in [TKH83]) that such almost unitaryHessenberg matrices describe the state-space structure for the feed-back lattice filters. In <ref> [KP83] </ref> a 2 We listed only a few papers where purely algebraic results were deduced by using the very compact and clarifying arguments based on signal flow diagrams.
Reference: [L80] <author> D.T.Lee, </author> <title> Canonical Ladder form realizations and fast estimation algorithms, </title> <type> Ph.D. thesis, </type> <institution> Department of Electrical Engineering, Stanford University, </institution> <month> August </month> <year> 1980. </year>
Reference-contexts: For example, in signal processing literature (1.6) is known under the name the discrete-time Schwartz form [M66] because it appears in the context of discrete-time Lyapunov stability test. It has been noted in [M77] (see also [M74]) and elaborated in [ML80], <ref> [L80] </ref> (and independently in [TKH83]) that such almost unitaryHessenberg matrices describe the state-space structure for the feed-back lattice filters. In [KP83] a 2 We listed only a few papers where purely algebraic results were deduced by using the very compact and clarifying arguments based on signal flow diagrams.
Reference: [LA83] <author> H.Lev-Ari, </author> <title> Nonstationary Lattice-Filter Modeling, </title> <type> Ph.D. thesis, </type> <institution> Stanford University, </institution> <month> December </month> <year> 1983. </year>
Reference-contexts: We also refer to [D82], <ref> [LA83] </ref>, [LAK84] for a discrete-transmission-lines approach 2 to study the more general classes of matrices with Toeplitz-like structure. 1.2 Problem formulation. <p> There are several other well-known ways to parameterize quasi-Toeplitz matrices. For example, any quasi-Toeplitz matrix R is congruent to a certain Toeplitz matrix T , R = L (x)T L (x) fl ; where the congruence matrix L (x) is a lower triangular Toeplitz matrix, see, e.g., <ref> [LA83] </ref>, [LAK86]. The association of the classical Schur algorithm with discrete transmission lines offers a variety of other possibilities to parameterize the class of quasi-Toeplitz matrices, cf., e.g., [D82] and [LA83]. <p> L (x)T L (x) fl ; where the congruence matrix L (x) is a lower triangular Toeplitz matrix, see, e.g., <ref> [LA83] </ref>, [LAK86]. The association of the classical Schur algorithm with discrete transmission lines offers a variety of other possibilities to parameterize the class of quasi-Toeplitz matrices, cf., e.g., [D82] and [LA83].
Reference: [LAK84] <author> H.Lev-Ari and T.Kailath, </author> <title> Lattice filter parameterization and modeling of nonstationary processes, </title> <journal> IEEE Trans on Information Theory, </journal> <volume> 30: </volume> <month> 2-16 </month> <year> (1984). </year>
Reference-contexts: We also refer to [D82], [LA83], <ref> [LAK84] </ref> for a discrete-transmission-lines approach 2 to study the more general classes of matrices with Toeplitz-like structure. 1.2 Problem formulation.
Reference: [LAK86] <author> H.Lev-Ari and T.Kailath, </author> <title> Triangular factorization of structured Hermitian matrices, in Operator Theory : Advances and Applications (I.Gohberg. </title> <editor> ed.), </editor> <volume> vol. 18, </volume> <pages> 301-324, </pages> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1986. </year>
Reference-contexts: There are several other well-known ways to parameterize quasi-Toeplitz matrices. For example, any quasi-Toeplitz matrix R is congruent to a certain Toeplitz matrix T , R = L (x)T L (x) fl ; where the congruence matrix L (x) is a lower triangular Toeplitz matrix, see, e.g., [LA83], <ref> [LAK86] </ref>. The association of the classical Schur algorithm with discrete transmission lines offers a variety of other possibilities to parameterize the class of quasi-Toeplitz matrices, cf., e.g., [D82] and [LA83].
Reference: [M66] <author> M.Mansour, </author> <title> Stability criteria of linear systems and the second method of Lyapunov, </title> <journal> Sientia Electrica, </journal> <volume> vol. </volume> <pages> XI, </pages> <month> 87-96 </month> <year> (1966). </year>
Reference-contexts: Such almost unitary Hessenberg matrices are of interest in several applied areas. For example, in signal processing literature (1.6) is known under the name the discrete-time Schwartz form <ref> [M66] </ref> because it appears in the context of discrete-time Lyapunov stability test. It has been noted in [M77] (see also [M74]) and elaborated in [ML80], [L80] (and independently in [TKH83]) that such almost unitaryHessenberg matrices describe the state-space structure for the feed-back lattice filters.
Reference: [M74] <author> M.Morf, </author> <title> Fast algorithms for multivariable systems, </title> <type> Ph.D. thesis, </type> <institution> Department of Electrical Engineering, Stanford University, </institution> <year> 1974. </year>
Reference-contexts: Such almost unitary Hessenberg matrices are of interest in several applied areas. For example, in signal processing literature (1.6) is known under the name the discrete-time Schwartz form [M66] because it appears in the context of discrete-time Lyapunov stability test. It has been noted in [M77] (see also <ref> [M74] </ref>) and elaborated in [ML80], [L80] (and independently in [TKH83]) that such almost unitaryHessenberg matrices describe the state-space structure for the feed-back lattice filters. <p> by H (x) H (y) = OE 0 (x) ~ OE n1 (y) + OE 1 (x) ~ OE n2 (y) + + OE n1 (x) ~ OE # (y); * An examination of the structure in Fig. 6 allows one to easily identify the state space structure, see, e.g., <ref> [M74] </ref>, [ML80].
Reference: [M77] <author> M.Morf, </author> <title> Ladder forms in estimation and control, </title> <booktitle> Proc. 11 Asilomar Annual Conference on CSC, </booktitle> <month> November </month> <year> 1997, </year> <pages> 424-429. </pages>
Reference-contexts: Such almost unitary Hessenberg matrices are of interest in several applied areas. For example, in signal processing literature (1.6) is known under the name the discrete-time Schwartz form [M66] because it appears in the context of discrete-time Lyapunov stability test. It has been noted in <ref> [M77] </ref> (see also [M74]) and elaborated in [ML80], [L80] (and independently in [TKH83]) that such almost unitaryHessenberg matrices describe the state-space structure for the feed-back lattice filters.
Reference: [MB79] <author> J.Maroulas and S.Barnett, </author> <title> Polynomials with respect to a general basis. I. </title> <journal> Theory, J. of Math. Analysis and Appl., </journal> <volume> 72: </volume> <month> 177-194 </month> <year> (1979). </year>
Reference-contexts: 0 (x): (1.3) The Hessenberg matrix C Q (H) = 6 6 6 4 b n b n b n . . . . . . 0 0 a n1;n1 a n1;n b n 7 7 7 5 capturing the recurrence relations (1.3) has been called the confederate matrix in <ref> [MB79] </ref>, where one can find many its useful properties, e.g., det (I C Q (H)) = b n Of course, for the simplest monomial basis Q = f1; x; x 2 ; : : : ; x n g the confederate matrix C Q (H) reduces to the usual companion matrix,
Reference: [MG76] <author> J.D.Markel and A.H.Gray, </author> <title> Linear Prediction of Speech, </title> <booktitle> Communications and Cybernetics, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1976. </year>
Reference-contexts: i.e., polynomials orthonormal with respect to a suitable inner product on the unit circle, &lt; p (x); q (x) &gt;= 2 We use the sharp sign # to follow the usual signal processing designations, where f [OE # z fl )] fl g are called backward predictor polynomials, see, e.g., <ref> [MG76] </ref>.
Reference: [ML80] <author> M.Morf and D.T.Lee, </author> <title> State-space structure of ladder canonical forms, </title> <booktitle> Proc. 18th Conf. on Control and Design, </booktitle> <month> Dec. </month> <year> 1980, </year> <pages> 1221-1224. </pages>
Reference-contexts: For example, in signal processing literature (1.6) is known under the name the discrete-time Schwartz form [M66] because it appears in the context of discrete-time Lyapunov stability test. It has been noted in [M77] (see also [M74]) and elaborated in <ref> [ML80] </ref>, [L80] (and independently in [TKH83]) that such almost unitaryHessenberg matrices describe the state-space structure for the feed-back lattice filters. In [KP83] a 2 We listed only a few papers where purely algebraic results were deduced by using the very compact and clarifying arguments based on signal flow diagrams. <p> H (x) H (y) = OE 0 (x) ~ OE n1 (y) + OE 1 (x) ~ OE n2 (y) + + OE n1 (x) ~ OE # (y); * An examination of the structure in Fig. 6 allows one to easily identify the state space structure, see, e.g., [M74], <ref> [ML80] </ref>.
Reference: [MZ60] <author> S.H.Mason and H.A.Zimmerman, </author> <title> Electronic Circuits, Signals and Systems, </title> <address> J.Wiley, New York, </address> <year> 1960. </year>
Reference-contexts: A new realization obtained in this way is called transposed [OS89] or dual [K80]. Recall that it is an elementary fact in system theory, i.e., the Mason's rules <ref> [MZ60] </ref>, that such a reversal of the flow in a signal flow graph (passing to the transposed (dual) system) does not change the overall transfer function H (z). y (z) oe * 6 * oe ~p 2 (z) a 1 x 2 z 1 oe * 6 * oe 6 ~p
Reference: [OS89] <author> A.V.Oppenheim and R.W.Schafer, </author> <title> Discrete-time Signal Processing, </title> <publisher> Prentice Hall, </publisher> <address> Eglewood Cliffs, NJ, </address> <year> 1989. </year>
Reference-contexts: with a scalar transfer function of the form: H (z) = d + c (zI A) 1 b; (2.16) where A is an n fi n matrix, c is a 1 fi n row, b is an n fi 1 column, and d is a scalar, see, e.g., [K80] or <ref> [OS89] </ref> for more details. <p> The signal flow graph for (2.22) is given in Fig. 3, and one sees that it is obtained from the one in Fig. 2 by simply reversing the direction of the flow for each branch. A new realization obtained in this way is called transposed <ref> [OS89] </ref> or dual [K80].
Reference: [PM72] <author> T.W.Park and J.H.McClellan, </author> <title> Chebyshev approximation for the design of nonrecursive digital filters with linear phase, </title> <journal> IEEE Trans. Circuit Theory, </journal> <volume> vol. CT-19: </volume> <month> 189-194 </month> <year> (1972). </year>
Reference-contexts: Similarly, Szeg-o-Vandermonde matrices appear in the context of Gaussian quadrature on the unit circle [G82], in the context of Remez algorithm [R57], <ref> [PM72] </ref> in the case when the underlying basis consists of Szeg-o polynomials, elsewhere. So, the second problem is to extend the Parker-Forney-Traub algorithm to invert V # (x) in O (n 2 ) operations. 1.2.3 Evaluation of a polynomial represented in the basis of Szeg-o polynomials.
Reference: [R57] <author> E.Ya.Remez, </author> <title> General Computational Methods of Chebyshev Approximations, Atomic Energy Translation 4491, </title> <address> Kiev, USSR, </address> <year> 1957. </year>
Reference-contexts: Similarly, Szeg-o-Vandermonde matrices appear in the context of Gaussian quadrature on the unit circle [G82], in the context of Remez algorithm <ref> [R57] </ref>, [PM72] in the case when the underlying basis consists of Szeg-o polynomials, elsewhere. So, the second problem is to extend the Parker-Forney-Traub algorithm to invert V # (x) in O (n 2 ) operations. 1.2.3 Evaluation of a polynomial represented in the basis of Szeg-o polynomials.
Reference: [R95] <author> P.A.Regalia, </author> <title> Adaptive IIR filtering in signal processing and control, </title> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: We also refer to a recent monograph <ref> [R95] </ref> for a nice description of connections of C # (H) to the classical Schur and Levinson algorithms, and to lattice filter structures. See also [F96]. In the operator theory literature the structure in (1.6) is associated with the Naimark dilation, see, e.g., [C84], [BC92], [FF89].
Reference: [S17] <author> I.Schur, </author> <title> Uber Potenzreihen die im Inneren des Einheitskreises beschrankt sind, </title> <journal> Journal fur die Reine und Angewandte Mathematik, </journal> <volume> 147: </volume> <month> 205-232 </month> <year> (1917). </year> <title> English translation in Operator Theory : Advances and Applications (I.Gohberg. </title> <editor> ed.), </editor> <volume> vol. </volume> <pages> 18: </pages> <address> 31-88 (1986), </address> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1986. </year>
Reference-contexts: To do so we need to recall a well-known connection of quasi-Toeplitz matrices to the celebrated Schur algorithm, see, e.g., [K86]. 5.5 The classical Schur algorithm for fast triangular factorization of quasi Toeplitz matrices It was now well-known that the celebrated classical Schur algorithm <ref> [S17] </ref> in its array form computes the Cholesky factorization for quasi-Toeplitz matrices. The procedure can be briefly described as follows.
Reference: [TKH83] <author> M.Takizawa, Hisao Kishi and N.Hamada, </author> <title> Synthesis of Lattice Digital Filter by the State Space Variable Method, </title> <journal> Trans. IECE Japan, </journal> <volume> vol. J65-A: </volume> <month> 363-370 </month> <year> (1983). </year> <month> 25 </month>
Reference-contexts: For example, in signal processing literature (1.6) is known under the name the discrete-time Schwartz form [M66] because it appears in the context of discrete-time Lyapunov stability test. It has been noted in [M77] (see also [M74]) and elaborated in [ML80], [L80] (and independently in <ref> [TKH83] </ref>) that such almost unitaryHessenberg matrices describe the state-space structure for the feed-back lattice filters. In [KP83] a 2 We listed only a few papers where purely algebraic results were deduced by using the very compact and clarifying arguments based on signal flow diagrams.
References-found: 62

