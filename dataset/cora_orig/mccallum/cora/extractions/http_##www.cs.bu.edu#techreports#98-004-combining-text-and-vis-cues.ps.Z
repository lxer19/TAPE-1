URL: http://www.cs.bu.edu/techreports/98-004-combining-text-and-vis-cues.ps.Z
Refering-URL: http://cs-www.bu.edu/techreports/Home.html
Root-URL: 
Title: on Content-based Access of Image and Video Libraries, June 1998. Combining Textual and Visual Cues
Author: Marco La Cascia, Saratendu Sethi, and Stan Sclaroff 
Address: Boston, MA 02215  
Affiliation: Image and Video Computing Group Computer Science Department Boston University  
Note: BU CS TR98-004. To appear in IEEE Workshop  
Abstract: A system is proposed that combines textual and visual statistics in a single index vector for content-based search of a WWW image database. Textual statistics are captured in vector form using latent semantic indexing (LSI) based on text in the containing HTML document. Visual statistics are captured in vector form using color and orientation histograms. By using an integrated approach, it becomes possible to take advantage of possible statistical couplings between the content of the document (latent semantic content) and the contents of images (visual statistics). The combined approach allows improved performance in conducting content-based search. Search performance experiments are reported for a database containing 100,000 images collected from the WWW. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Berry and S Dumais. </author> <title> Using linear algebra for intelligent information retrieval. </title> <journal> TR UT-CS-94-270, U. </journal> <volume> Tenn., </volume> <year> 1994. </year>
Reference-contexts: The first r columns of the orthogonal matrices U and V define orthonormal eigenvectors associated with the r nonzero eigenvalues of AA T and A T A respectively. For further details about SVD and the information conveyed by the matrices, readers are directed to <ref> [1] </ref>. The SVD decomposes the original term-image relationships into a set of linearly independent vectors. The dimension of the problem is reduced by choosing k most significant dimensions from the factor space which are then used for estimating the original index vectors.
Reference: [2] <author> G. Brien. </author> <title> Information Management Tools for Updating an SVD-Encoded Indexing Scheme. </title> <journal> TR UT-CS-94-259, U. </journal> <volume> Tenn., </volume> <year> 1994. </year>
Reference-contexts: It may be pointed out that since the training set was selected so that it is representative of the documents available on the web and since the size of training set is considerable, it may not require to retrain the system. Standard techniques have been reported in <ref> [2] </ref> for updating SVD-based indexing schemes. After the training step, we indexed a set of 10,000 images disjoint with the training set and stored them in the database. A subset of 100 images in the database was selected (randomly) to be retrieved.
Reference: [3] <author> S. Deerwester, S. Dumais, T. Landauer, G. Furnas, and R. Harshman. </author> <title> Indexing by latent semantic analysis. </title> <institution> J. of the Soc. for Info. Sci., 41(6):391407, </institution> <year> 1990. </year>
Reference-contexts: In this paper, we propose an approach that allows the combination of visual statistics with textual statistics in the vector space representation commonly used in query by image content systems. Text statistics are captured in vector form using latent semantic indexing (LSI) <ref> [3] </ref>. Text documents are represented by low-dimensional vectors that can be matched against user queries in the LSI semantic space. The LSI index for an HTML document is then associated with each of the images contained therein. Visual statistics (e.g., color, orientedness) are also computed for each image.
Reference: [4] <author> S. Dumais. </author> <title> Improving the retrieval of information from external sources. Behavior Res. </title> <journal> Meth., Instruments and Comp., </journal> <volume> 23(2):229236, </volume> <year> 1991. </year>
Reference-contexts: The element a ij is expressed as the product of the local (L (i; j)) and the global weight (G (i)). Several weighting schemes have been suggested in the literature. Based on the performance reported in <ref> [4] </ref>, the log-entropy scheme was chosen. <p> The graph shows how subject's success rates improved when a higher LSI dimension was employed. The steepest improvement in performance was achieved with LSI dimension of 256. After that, performance increased more slowly with increasing LSI dimension. This is consistent with results reported in <ref> [4] </ref>, where it was observed that as LSI dimension increases the performance curve flattens out, and then actually drops off slightly (due to noise).
Reference: [5] <author> M. Flickner et al. </author> <title> Query by image and video content: </title> <booktitle> the QBIC system. IEEE Computer, </booktitle> <pages> pp. 2330, </pages> <month> Sep. </month> <year> 1995. </year>
Reference-contexts: Existing image engines allow users to search for images via an SQL keywords interface [6, 12] and/or via query by image example (QBE) [7, 11, 12]. In QBE, the system presents an initial page of representative (or randomly selected) images thumbnails to the user <ref> [5] </ref>. The user then marks one or more images as relevant to the search. The visual statistics for these images are then used in defining a query. The user's success in locating images in the database depends in great part on which images appear within this initial group of thumbnails.
Reference: [6] <author> C. Frankel, M. Swain, and V. Athitsos. Webseer: </author> <title> An image search engine for the world wide web. </title> <type> TR 96-14, </type> <institution> U. Chicago, </institution> <year> 1996. </year>
Reference-contexts: 1 Introduction The growing importance of the world wide web has led to the birth of a number of image search engines <ref> [6, 7, 11, 12] </ref>. The web's staggering scale puts severe limitations on the types of indexing algorithms that can be employed. Luckily, due to the scale and unstructured nature of the WWW, even the most basic indexing tools would be welcome. <p> Luckily, due to the scale and unstructured nature of the WWW, even the most basic indexing tools would be welcome. Existing image engines allow users to search for images via an SQL keywords interface <ref> [6, 12] </ref> and/or via query by image example (QBE) [7, 11, 12]. In QBE, the system presents an initial page of representative (or randomly selected) images thumbnails to the user [5]. The user then marks one or more images as relevant to the search. <p> We call this the page zero problem. Other WWW image engines allow the user to form a query in terms of SQL keywords <ref> [6, 12] </ref>. This alleviates the page zero problem, since the user can give text information that narrows the scope of possible images displayed on page zero. To build the image index, keywords are extracted heuristically from HTML documents containing each image, and/or from the image URL. <p> The LSI vector and visual statistics vector are then combined into a unified vector that can be used for content-based search of the resulting image database. In previous systems, visual information has been used in a form that is compatible with standard DBMS frameworks <ref> [6] </ref> or only to refine the query [12]. By using an integrated approach, we are able to take advantage of possible statistical couplings between the content of the document (latent semantic content) and the contents of images (image statistics). <p> These weight values have been fixed according to the likelihood of useful information that may be implied by the text. Weighting selectively the words appearing between various HTML tags helps in emphasizing the underlying information of that document. A different weighting scheme was used in <ref> [6] </ref>. In addition, words appearing before and after a particular image are also assigned a weight based upon their proximity to the image.
Reference: [7] <author> T. Gevers and A. Smeulders. Pictoseek: </author> <title> A content-based image search engine for the www. Proc. </title> <booktitle> Int. Conf. on Visual Info., </booktitle> <month> Dec. </month> <year> 1997. </year>
Reference-contexts: 1 Introduction The growing importance of the world wide web has led to the birth of a number of image search engines <ref> [6, 7, 11, 12] </ref>. The web's staggering scale puts severe limitations on the types of indexing algorithms that can be employed. Luckily, due to the scale and unstructured nature of the WWW, even the most basic indexing tools would be welcome. <p> Luckily, due to the scale and unstructured nature of the WWW, even the most basic indexing tools would be welcome. Existing image engines allow users to search for images via an SQL keywords interface [6, 12] and/or via query by image example (QBE) <ref> [7, 11, 12] </ref>. In QBE, the system presents an initial page of representative (or randomly selected) images thumbnails to the user [5]. The user then marks one or more images as relevant to the search. The visual statistics for these images are then used in defining a query.
Reference: [8] <author> H. Murase and S. Nayar. </author> <title> Visual Learning and Recognition of 3-D Objects from Appearance. </title> <address> IJCV, 14(1):524, </address> <year> 1995. </year>
Reference-contexts: In other cases the user will be able to find several relevant images. To gain better search accu racy, we are investigating the use of modular eigenspaces <ref> [8, 9] </ref> for modeling various LSI subject categories. In summary, the maximum improvement was achieved when both visual and textual information were used in the relevance feedback framework.
Reference: [9] <author> A. Pentland, B. Moghaddam, T. Starner, O. Oliyide, and M. Turk. </author> <title> View-based and modular eigenspaces for face recognition. </title> <booktitle> Proc. CVPR, </booktitle> <pages> pp. 8491, </pages> <year> 1994. </year>
Reference-contexts: In other cases the user will be able to find several relevant images. To gain better search accu racy, we are investigating the use of modular eigenspaces <ref> [8, 9] </ref> for modeling various LSI subject categories. In summary, the maximum improvement was achieved when both visual and textual information were used in the relevance feedback framework.
Reference: [10] <author> G. Salton and M.J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1989. </year>
Reference-contexts: We allow the user to query the system based on several examples and use the additional information coming from the multiple selection to allow relevance feedback. 5 Relevance Feedback Relevance feedback enables the user to iteratively refine a query via the specification of relevant items <ref> [10] </ref>. By including the user in the loop, better search performance can be achieved. Typically, the system returns a set of possible matches, and the user gives feedback by marking items as relevant or not relevant.
Reference: [11] <author> S. Sclaroff, L. Taycher, and M. La Cascia. ImageRover: </author> <title> A content-based image browser for the world wide web. </title> <booktitle> Proc. of IEEE Int. Workshop on Content-Based Access of Image and Video Libraries, </booktitle> <year> 1997. </year>
Reference-contexts: 1 Introduction The growing importance of the world wide web has led to the birth of a number of image search engines <ref> [6, 7, 11, 12] </ref>. The web's staggering scale puts severe limitations on the types of indexing algorithms that can be employed. Luckily, due to the scale and unstructured nature of the WWW, even the most basic indexing tools would be welcome. <p> Luckily, due to the scale and unstructured nature of the WWW, even the most basic indexing tools would be welcome. Existing image engines allow users to search for images via an SQL keywords interface [6, 12] and/or via query by image example (QBE) <ref> [7, 11, 12] </ref>. In QBE, the system presents an initial page of representative (or randomly selected) images thumbnails to the user [5]. The user then marks one or more images as relevant to the search. The visual statistics for these images are then used in defining a query. <p> k 1 The resulting LSI vector provides the context associated with an image and is combined with its computed visual feature vectors and stored in the database index. 4 Integration with Visual Statistics The visual statistics we use to describe an image are the color histogram and dominant orientation histogram <ref> [11] </ref>. Given the potential number of images to index it is of fun-damental importance that the dimension of the feature vector is as small as possible. As pointed out by White and Jain [13], the visual data has an intrinsic dimension that is significantly smaller than the original dimension. <p> The use of principal component analysis (PCA) for each subvector space (color and directionality) allows us to dramatically reduce the dimension of the visual features with a small loss of information <ref> [11] </ref>. The global feature vector, representing the content of the image, is then composite of several subvectors: a dimensionally reduced color histogram and orientation histogram for each of 6 overlapping image regions [11], the LSI descriptor as described above. <p> directionality) allows us to dramatically reduce the dimension of the visual features with a small loss of information <ref> [11] </ref>. The global feature vector, representing the content of the image, is then composite of several subvectors: a dimensionally reduced color histogram and orientation histogram for each of 6 overlapping image regions [11], the LSI descriptor as described above. As each image is described by a vector, the query by example problem can be easily formulated as a k-nearest neighbor one. Our approach is slightly different. <p> The algorithm determines the relative weightings of the individual features based on feedback images. This weighting thus varies depending upon the particular selections of the user. Due to space limitations, readers are referred to <ref> [11] </ref> for a complete description of our relevance feedback algorithm. 6 System Implementation We implemented a fully functional system to test our technique. The web robots, at point of this writing, collected a few hundred thousand documents containing more than 250,000 unique 1 and valid images 2 .
Reference: [12] <author> J. Smith and S. Chang. </author> <title> Visually searching the web for content. </title> <booktitle> IEEE Multimedia, </booktitle> <address> 4(3):1220, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: 1 Introduction The growing importance of the world wide web has led to the birth of a number of image search engines <ref> [6, 7, 11, 12] </ref>. The web's staggering scale puts severe limitations on the types of indexing algorithms that can be employed. Luckily, due to the scale and unstructured nature of the WWW, even the most basic indexing tools would be welcome. <p> Luckily, due to the scale and unstructured nature of the WWW, even the most basic indexing tools would be welcome. Existing image engines allow users to search for images via an SQL keywords interface <ref> [6, 12] </ref> and/or via query by image example (QBE) [7, 11, 12]. In QBE, the system presents an initial page of representative (or randomly selected) images thumbnails to the user [5]. The user then marks one or more images as relevant to the search. <p> Luckily, due to the scale and unstructured nature of the WWW, even the most basic indexing tools would be welcome. Existing image engines allow users to search for images via an SQL keywords interface [6, 12] and/or via query by image example (QBE) <ref> [7, 11, 12] </ref>. In QBE, the system presents an initial page of representative (or randomly selected) images thumbnails to the user [5]. The user then marks one or more images as relevant to the search. The visual statistics for these images are then used in defining a query. <p> We call this the page zero problem. Other WWW image engines allow the user to form a query in terms of SQL keywords <ref> [6, 12] </ref>. This alleviates the page zero problem, since the user can give text information that narrows the scope of possible images displayed on page zero. To build the image index, keywords are extracted heuristically from HTML documents containing each image, and/or from the image URL. <p> In previous systems, visual information has been used in a form that is compatible with standard DBMS frameworks [6] or only to refine the query <ref> [12] </ref>. By using an integrated approach, we are able to take advantage of possible statistical couplings between the content of the document (latent semantic content) and the contents of images (image statistics). Furthermore, LSI implicitly addresses problems with synonyms, word sense, lexical matching, and term omission.
Reference: [13] <author> D.A. White and R. Jain. </author> <title> Algorithms and strategies for similarity retrieval. </title> <type> TR VCL-96-101, UCSD, </type> <year> 1996. </year>
Reference-contexts: Given the potential number of images to index it is of fun-damental importance that the dimension of the feature vector is as small as possible. As pointed out by White and Jain <ref> [13] </ref>, the visual data has an intrinsic dimension that is significantly smaller than the original dimension. The use of principal component analysis (PCA) for each subvector space (color and directionality) allows us to dramatically reduce the dimension of the visual features with a small loss of information [11].
Reference: [14] <author> Hongyuan Zha. </author> <title> A subspace-based model for information retrieval with applications in latent semantic indexing. </title> <type> TR CSE-98-002, </type> <institution> Penn State, </institution> <year> 1998. </year>
Reference-contexts: We experimentally found that a 256-dimensional LSI vector leads to good results for our data set, despite the breadth of the subject matter of documents included in the LSI training. The optimal LSI dimension may also be obtained using an MDL framework <ref> [14] </ref>. Figure 2 shows that the net increase in the retrieval performance drops significantly after 256 LSI dimension. We expect that even in a very large database (with millions of images) using our technique it will be possible to retrieve specific images.
References-found: 14

