URL: http://www.cs.ucsb.edu/Courses/cs290i/papers/p4.ps
Refering-URL: http://www.cs.ucsb.edu/Courses/cs290i/papers/index.html
Root-URL: http://www.cs.ucsb.edu
Title: A Language for Conveying the Aliasing Properties of Dynamic, Pointer-Based Data Structures  
Author: Joseph Hummel Laurie J. Hendren and Alexandru Nicolau 
Abstract: High-performance architectures rely upon powerful optimizing and parallelizing compilers to maximize performance. Such compilers need accurate program analysis to enable their performance-enhancing transformations. In the domain of program analysis for parallelization, pointer analysis is a difficult and increasingly common problem. When faced with dynamic, pointer-based data structures, existing solutions are either too limited in the types of data structures they can analyze, or require too much effort on the part of the programmer. In this paper we present a powerful description language for expressing the aliasing properties of dynamic data structures. Such descriptions provide the compiler with better information during alias analysis, and require only minimal effort from the programmer. Ultimately, this enables a more accurate program analysis, and an increased application of performance-enhancing transformations. 
Abstract-found: 1
Intro-found: 1
Reference: [AHU74] <author> Alfred V. Aho, John E. Hopcroft, and Jef-frey D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: note that it can usually be assumed that pointer fields of different types cannot lead to the same node 3 ; thus there is no need to restate the obvious. 4.3 Union-Find trees Union-find trees are a data structure used to support efficient find and union operations on data elements <ref> [AHU74, Man89] </ref>. The find operation searches for the group in which an element resides, while the union operation unions two existing groups into a new group. Initially, each element resides in a group by themselves.
Reference: [App85] <author> Andrew W. Appel. </author> <title> An efficient program for many-body simulation. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 6(1) </volume> <pages> 85-103, </pages> <year> 1985. </year>
Reference-contexts: This can be attributed to the increasing use of C in the parallel processing community (also C++ and F90 to a lesser extent), along with the realization that dynamic data structures are important tools for achieving high performance. For example, octrees are important data structures in N-body simulations <ref> [App85, BH86, WS92] </ref> and computational geometry [Sam90], as are sparse matrices in circuit simulations [Kun86]. The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly.
Reference: [BH86] <author> Josh Barnes and Piet Hut. </author> <title> A hierarchical O(NlogN) force-calculation algorithm. </title> <journal> Nature, </journal> <volume> 324 </volume> <pages> 446-449, </pages> <month> 4 December </month> <year> 1986. </year> <title> The code can be obtained from Prof. </title> <institution> Barnes at the University of Hawaii, or from jhummel@ics.uci.edu. </institution>
Reference-contexts: This can be attributed to the increasing use of C in the parallel processing community (also C++ and F90 to a lesser extent), along with the realization that dynamic data structures are important tools for achieving high performance. For example, octrees are important data structures in N-body simulations <ref> [App85, BH86, WS92] </ref> and computational geometry [Sam90], as are sparse matrices in circuit simulations [Kun86]. The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly.
Reference: [CBC93] <author> J. Choi, M. Burke, and P. Carini. </author> <title> Efficient flow-sensitive interprocedural computation of pointer-induced aliases and side-effects. </title> <booktitle> In Proceedings of the ACM 20th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 232-245, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly. However, such approaches <ref> [JM81, LH88, HPR89, CWZ90, HN90, Deu92, HA92, LR92, CBC93, PKC93] </ref> are quite limited in the types of data structures they can recognize (typically one and two-way linked-lists, and trees).
Reference: [Cor91] <institution> CONVEX Computer Corporation. CONVEX C optimization guide, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: A second approach is a manual one, in which the programmer annotates their program with directives, thereby directly supplying the compiler with the necessary analysis information (e.g., see <ref> [Cor91] </ref>). Such directives are typically at a very low semantic level, and must be placed throughout a program to maximize their effect.
Reference: [CWZ90] <author> D.R. Chase, M. Wegman, and F.K. Zadek. </author> <title> Analysis of pointers and structures. </title> <booktitle> In Proceedings of the SIGPLAN `90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 296-310, </pages> <year> 1990. </year> <month> 215 </month>
Reference-contexts: The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly. However, such approaches <ref> [JM81, LH88, HPR89, CWZ90, HN90, Deu92, HA92, LR92, CBC93, PKC93] </ref> are quite limited in the types of data structures they can recognize (typically one and two-way linked-lists, and trees).
Reference: [Deu92] <author> A. Deutsch. </author> <title> A storeless model of aliasing and its abstractions using finite representations of right-regular equivalence relations. </title> <booktitle> In Proceedings of the IEEE '92 International Conference on Computer Languages, </booktitle> <month> April </month> <year> 1992. </year>
Reference-contexts: The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly. However, such approaches <ref> [JM81, LH88, HPR89, CWZ90, HN90, Deu92, HA92, LR92, CBC93, PKC93] </ref> are quite limited in the types of data structures they can recognize (typically one and two-way linked-lists, and trees).
Reference: [HA92] <author> W. Ludwell Harrison III and Z. Ammarguellat. </author> <title> A program's eye view of Miprac. </title> <editor> In D. Gel-ernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Proceedings of the 5th Workshop on Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 339-353, </pages> <month> August </month> <year> 1992. </year> <note> Available as Yale Tech Report YALEU/DCS/RR-915. </note>
Reference-contexts: The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly. However, such approaches <ref> [JM81, LH88, HPR89, CWZ90, HN90, Deu92, HA92, LR92, CBC93, PKC93] </ref> are quite limited in the types of data structures they can recognize (typically one and two-way linked-lists, and trees).
Reference: [HHN92a] <author> Laurie J. Hendren, Joseph Hummel, and Alexandru Nicolau. </author> <title> Abstractions for recursive pointer data structures: Improving the analysis and transformation of imperative programs. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 249-260, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Unhappy with either method, we recently proposed a third, compromising approach: the programmer annotates the type declarations of their data structures, and the compiler then uses this information to guide the remaining program analysis <ref> [HHN92a] </ref>. This requires only a small effort on the part of the programmer, but can result in dramatic improvements in accuracy of analysis and hence performance [HHN92b, HHN93a]. The disadvantage is that the compiler may not be able to verify the type annotations. <p> deter programming in general. 3 Related work First we will discuss the work from which ASAP grew, and then other related work. 3.1 ADDS Our work on ASAP is a generalization of our earlier work on ADDS, a data structure description language based on a notion of directions and dimensions <ref> [HHN92a] </ref>. ADDS is a simple yet powerful language for describing pointer-based data structures. However, as the complexity of a data structure grows, the accuracy of ADDS can diminish.
Reference: [HHN92b] <author> Joseph Hummel, Laurie J. Hendren, and Alexandru Nicolau. </author> <title> Applying an abstract data structure description approach to parallelizing scientific pointer programs. </title> <booktitle> Proceedings of the 21st Annual International Conference on Parallel Processing, </booktitle> <volume> Volume II, </volume> <pages> pages 100-104, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: This requires only a small effort on the part of the programmer, but can result in dramatic improvements in accuracy of analysis and hence performance <ref> [HHN92b, HHN93a] </ref>. The disadvantage is that the compiler may not be able to verify the type annotations. As with program correctness, this is currently the responsibility of the programmer. The format of this paper is as follows.
Reference: [HHN93a] <author> Joseph Hummel, Laurie J. Hendren, and Alexandru Nicolau. </author> <title> A general dependence test for dynamic, pointer-based data structures. </title> <type> Technical Report ICS 93-44, </type> <institution> UC-Irvine, </institution> <month> September </month> <year> 1993. </year> <booktitle> To appear in the 1994 ACM SIGPLAN Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: This requires only a small effort on the part of the programmer, but can result in dramatic improvements in accuracy of analysis and hence performance <ref> [HHN92b, HHN93a] </ref>. The disadvantage is that the compiler may not be able to verify the type annotations. As with program correctness, this is currently the responsibility of the programmer. The format of this paper is as follows. <p> Ultimately, this allows for a straightforward application of the axioms during dependence analysis <ref> [HHN93a] </ref>. <p> The meaning of a &lt;disj-NA&gt; axiom is defined similarly. However, a &lt;def-A&gt; axiom specifies the opposite (a definite alias): 8 nodes p in 1 Details on how access paths are collected, and how general dependence testing is then performed, can be found in <ref> [HHN93a] </ref>. 2 A node is a memory location with a non-NULL address. <p> In this case we view ASAP as a lower-level language into which ADDS or graph type descriptions can be "compiled" and the resulting axioms fed to a dependence analysis framework <ref> [HHN93a] </ref>; this separates the description language of choice from the underlying analysis algorithms. However, as this section will demonstrate, there exist important data structures for which neither ADDS nor graph types suffice.
Reference: [HHN93b] <author> Joseph Hummel, Laurie J. Hendren, and Alexandru Nicolau. </author> <title> A language for conveying the aliasing properties of dynamic, pointer-based data structures. </title> <type> Technical Report ICS 93-43, </type> <institution> UC-Irvine, </institution> <month> September </month> <year> 1993. </year> <note> To appear in the 8th International Parallel Processing Symposium, </note> <month> April </month> <year> 1994. </year>
Reference-contexts: The apparent disadvantage in using ASAP over ADDS is the lower-level nature of ASAP's axioms, making the language less intuitive. However, since an ADDS description can automatically be translated into an equivalent ASAP 210 specification <ref> [HHN93b] </ref>, a programmer can use ADDS when s/he wishes, and use ASAP only when necessary. <p> ASAP has the necessary flexibility to allow a more accurate description of a sparse matrix. Since an ADDS declaration can be automatically translated into an ASAP specification <ref> [HHN93b] </ref>, we know ASAP can do no worse than ADDS. We can however do much better. The idea is to take a bottom-up approach, beginning with simple axioms and developing more complicated ones as necessary.
Reference: [HN90] <author> Laurie J. Hendren and Alexandru Nicolau. </author> <title> Par-allelizing programs with recursive data structures. </title> <journal> IEEE Trans. on Parallel and Distributed Computing, </journal> <volume> 1(1) </volume> <pages> 35-47, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly. However, such approaches <ref> [JM81, LH88, HPR89, CWZ90, HN90, Deu92, HA92, LR92, CBC93, PKC93] </ref> are quite limited in the types of data structures they can recognize (typically one and two-way linked-lists, and trees).
Reference: [HPR89] <author> Susan Horwitz, Phil Pfeiffer, and Thomas Reps. </author> <title> Dependence analysis for pointer variables. </title> <booktitle> In Proceedings of the SIGPLAN '89 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 28-40, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly. However, such approaches <ref> [JM81, LH88, HPR89, CWZ90, HN90, Deu92, HA92, LR92, CBC93, PKC93] </ref> are quite limited in the types of data structures they can recognize (typically one and two-way linked-lists, and trees).
Reference: [JM81] <author> N. D. Jones and S. S. Muchnick. </author> <title> Program Flow Analysis, Theory and Applications, chapter 4, </title> <journal> Flow Analysis and Optimization of LISP-like Structures, </journal> <pages> pages 102-131. </pages> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly. However, such approaches <ref> [JM81, LH88, HPR89, CWZ90, HN90, Deu92, HA92, LR92, CBC93, PKC93] </ref> are quite limited in the types of data structures they can recognize (typically one and two-way linked-lists, and trees).
Reference: [Ken90] <author> K. Kennedy. </author> <title> Foreword of Supercompilers for Parallel and Vector Computers, 1990. The text is written by Hans Zima with Barbara Chap-man, </title> <note> available from the ACM Press. </note>
Reference-contexts: in Section 5 we present our conclusions. 2 Overview of language First we motivate our language and its design, then we supply its definition, and lastly we discuss the problem of verification. 2.1 Motivation One of the most critical features of optimizing and parallelizing compilers is accurate program dependence analysis <ref> [Ken90] </ref>. In the case of pointers, this requires accurate alias analysis, i.e. answering questions of the form: "At a program point S, what memory locations might be (are) pointed to by the pointer variable p?".
Reference: [KKK90] <author> David Klappholz, Apostolos D. Kallis, and Xiangyun Kang. </author> <title> Refined C: An update. </title> <editor> In David Gelernter, Alexandru Nicolau, and David Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 331-357. </pages> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Larus [Lar89] discussed a technique for describing acyclic structures in LISP; these were code annotations which conveyed the acyclicness of a data structure to the compiler. Another code annotation approach is that taken by Klappholz et al. in Refined-C <ref> [KKK90] </ref>, where explicit statements such as distinct are inserted into the program to guide analysis.
Reference: [KS93] <author> N. Klarlund and M. Schwartzbach. </author> <title> Graph types. </title> <booktitle> In Proceedings of the ACM 20th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 196-205, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: However, since an ADDS description can automatically be translated into an equivalent ASAP 210 specification [HHN93b], a programmer can use ADDS when s/he wishes, and use ASAP only when necessary. Thus, the use of ASAP does not necessarily imply a loss of intuitiveness. 3.2 Graph types Graph types <ref> [KS93] </ref> and ASAP take a similar approach to describing data structures, namely using regular-like expressions to specify the relationships between pointer fields. With graph types, pointer fields are separated into two types, tree and routing fields.
Reference: [Kun86] <author> K. Kundert. </author> <title> Sparse matrix techniques. </title> <editor> In A. Ruehli, editor, </editor> <title> Circuit Analysis, </title> <booktitle> Simulation and Design, </booktitle> <pages> pages 281-324. </pages> <publisher> Elsevier Science Publishers B.V. (North-Holland), </publisher> <pages> 186. </pages>
Reference-contexts: For example, octrees are important data structures in N-body simulations [App85, BH86, WS92] and computational geometry [Sam90], as are sparse matrices in circuit simulations <ref> [Kun86] </ref>. The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly. <p> Sparse matrices are an important data structure in scientific computing, and are commonly used e.g. in circuit simulations <ref> [Kun86] </ref>. The elements of the matrix form linked-lists by row and by column, with a header node at the front of each such list. These header nodes are in turn linked into one of two lists, depending on whether they head a row or a column.
Reference: [Lar89] <author> James R. Larus. </author> <title> Restructuring Symbolic Programs for Concurrent Execution on Multiprocessors. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1989. </year>
Reference-contexts: Unlike ASAP however, these assertions do not aid analysis since the compiler does not understand their implication; the purpose of these assertions is to ensure validity at run-time (in particular, as the structure is passed from one running program to another). Larus <ref> [Lar89] </ref> discussed a technique for describing acyclic structures in LISP; these were code annotations which conveyed the acyclicness of a data structure to the compiler.
Reference: [LG88] <author> J. M. Lucassen and D. K. Gifford. </author> <title> Polymorphic effect systems. </title> <booktitle> In Proceedings 15th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 47-57, </pages> <year> 1988. </year>
Reference-contexts: Another code annotation approach is that taken by Klappholz et al. in Refined-C [KKK90], where explicit statements such as distinct are inserted into the program to guide analysis. Finally, a very different but related language-based approach is the effect system of FX <ref> [LG88] </ref>, in which the effect of a statement must be explicitly associated with a region of memory; this enables the compiler e.g. to perform a coarse-grain alias analysis. 4 Examples When describing simple data structures such as linked-lists and trees, the programmer will likely find it easier to use ADDS or
Reference: [LH88] <author> James R. Larus and Paul N. Hilfinger. </author> <title> Detecting conflicts between structure accesses. </title> <booktitle> In Proceedings of the SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 21-34, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly. However, such approaches <ref> [JM81, LH88, HPR89, CWZ90, HN90, Deu92, HA92, LR92, CBC93, PKC93] </ref> are quite limited in the types of data structures they can recognize (typically one and two-way linked-lists, and trees).
Reference: [LR92] <author> W. Landi and B. Ryder. </author> <title> A safe approximation algorithm for interprocedural pointer aliasing. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 235-248, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly. However, such approaches <ref> [JM81, LH88, HPR89, CWZ90, HN90, Deu92, HA92, LR92, CBC93, PKC93] </ref> are quite limited in the types of data structures they can recognize (typically one and two-way linked-lists, and trees).
Reference: [Man89] <author> Udi Manber. </author> <title> Introduction to Algorithms: A Creative Approach. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: note that it can usually be assumed that pointer fields of different types cannot lead to the same node 3 ; thus there is no need to restate the obvious. 4.3 Union-Find trees Union-find trees are a data structure used to support efficient find and union operations on data elements <ref> [AHU74, Man89] </ref>. The find operation searches for the group in which an element resides, while the union operation unions two existing groups into a new group. Initially, each element resides in a group by themselves.
Reference: [PKC93] <author> J. Plevyak, V. Karamcheti, and A. Chien. </author> <title> Analysis of dynamic structures for efficient parallel execution. </title> <editor> In D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Proceedings of the 6th Annual Workshop on Languages and Compilers for Parallel Computing, </booktitle> <pages> pages c1-c20, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly. However, such approaches <ref> [JM81, LH88, HPR89, CWZ90, HN90, Deu92, HA92, LR92, CBC93, PKC93] </ref> are quite limited in the types of data structures they can recognize (typically one and two-way linked-lists, and trees).
Reference: [Pug90] <author> W. Pugh. </author> <title> Skip lists: a probabilistic alternative to balanced trees. </title> <journal> CACM, </journal> <volume> 33(6) </volume> <pages> 668-676, </pages> <month> June </month> <year> 1990. </year> <title> An implementation can be FTPed from mimsy.cs.umd.edu. </title>
Reference-contexts: However, the class of describable structures is even smaller, since a structure must also be deterministic|the relationship between a routing field and the underlying backbone must be precisely known at compile-time. For example, a skiplist <ref> [Pug90] </ref> is a data structure in which some pointers skip ahead x number of nodes in order to reduce search time. Since x cannot be predicted at compile-time, this type of structure cannot be described using a graph type.
Reference: [Sam90] <author> Hanan Samet. </author> <title> Applications of Spatial Data Structures: Computer Graphics, Image Processing, and GIS. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: For example, octrees are important data structures in N-body simulations [App85, BH86, WS92] and computational geometry <ref> [Sam90] </ref>, as are sparse matrices in circuit simulations [Kun86]. The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly.
Reference: [Sno89] <author> R. Snodgrass. </author> <title> The Interface Description Language: Definition and Use. </title> <publisher> Computer Science Press, </publisher> <year> 1989. </year>
Reference-contexts: In fact, graph types are intended for functional languages in which the compiler is responsible for correctly maintaining the routing fields. 3.3 Other related work IDL, the Interface Description Language, allows the programmer to define various properties of a data structure by way of assertions supplied in its declaration <ref> [Sno89] </ref>. Unlike ASAP however, these assertions do not aid analysis since the compiler does not understand their implication; the purpose of these assertions is to ensure validity at run-time (in particular, as the structure is passed from one running program to another).
Reference: [Sta80] <author> Thomas A. Standish. </author> <title> Data Structure Techniques. </title> <publisher> Addison-Wesley, </publisher> <year> 1980. </year>
Reference-contexts: Since x cannot be predicted at compile-time, this type of structure cannot be described using a graph type. The same is true for orthogonal lists <ref> [Sta80] </ref>, an important data structure used to implement sparse matrices; we will discuss sparse matrices further in Section 4.4. It should be noted however that there are some cases in which graph types can yield a more accurate description than ASAP. <p> Thus, an ASAP specification consisting of only two axioms describes the union-find tree more accurately than ADDS, and describes a structure which graph types cannot describe at all. 4.4 Sparse matrices Sparse matrices, an example of which is shown in Figure 5, are implemented using orthogonal lists <ref> [Sta80] </ref>. Sparse matrices are an important data structure in scientific computing, and are commonly used e.g. in circuit simulations [Kun86]. The elements of the matrix form linked-lists by row and by column, with a header node at the front of each such list.
Reference: [WS92] <author> M. Warren and J. Salmon. </author> <title> Astrophysical n-body simulations using hierarchical tree data structures. </title> <booktitle> In Proceedings of Supercomputing 1992, </booktitle> <pages> pages 570-576, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: This can be attributed to the increasing use of C in the parallel processing community (also C++ and F90 to a lesser extent), along with the realization that dynamic data structures are important tools for achieving high performance. For example, octrees are important data structures in N-body simulations <ref> [App85, BH86, WS92] </ref> and computational geometry [Sam90], as are sparse matrices in circuit simulations [Kun86]. The preferred method of analysis is an automatic one, in which the compiler deduces the properties of the data structure and transforms the program accordingly.
Reference: [ZC90] <author> Hans Zima and Barbara Chapman. </author> <title> Supercom-pilers for Parallel and Vector Computers. </title> <publisher> ACM Press, </publisher> <year> 1990. </year> <month> 216 </month>
Reference-contexts: 1 Introduction High-performance architectures rely upon powerful optimizing and parallelizing compilers to increase program performance. In turn, these compilers depend upon accurate program analysis to enable various optimizing and parallelizing transformations. A good deal of work has been done in the area of array analysis (see <ref> [ZC90] </ref> for extensive references), but much less work has been focused on pointer analysis. In par fl Dept. of Computer Science, University of California at Irvine, Irvine, CA 92717 USA.
References-found: 31

