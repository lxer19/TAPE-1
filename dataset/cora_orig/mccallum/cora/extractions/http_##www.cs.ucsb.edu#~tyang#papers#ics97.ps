URL: http://www.cs.ucsb.edu/~tyang/papers/ics97.ps
Refering-URL: http://www.cs.ucsb.edu/Research/rapid_sweb/SWEB.html
Root-URL: http://www.cs.ucsb.edu
Email: fdandrese, tyangg@cs.ucsb.edu  
Title: Multiprocessor Scheduling with Client Resources to Improve the Response Time of WWW Applications  
Author: Daniel Andresen and Tao Yang 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: WWW-based information service has grown enormously during the last few years, and major performance bottlenecks have been caused by WWW server and Internet bandwidth inadequacies. Augmenting a server with multiprocessor support and shifting computation to client-site machines can substantially improve system response times and for some applications, it may also reduce network bandwidth requirements. In this paper, we propose adaptive scheduling techniques that optimize the use of a multiprocessor server with client resources by predicting demands of requests on I/O, CPU and network capabilities. We also provide a performance analysis under simplified assumptions for understanding the impact of system loads and network bandwidth when using our scheduling strategy. Finally we report preliminary experimental results to examine the system performance and verify the usefulness of the analytic model. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Acharya, M. Ranganathan, J. Saltz, "Sumatra: </author> <title> A Language for Resource-aware Mobile Programs," </title> <note> To appear in Mobile Object Systems, </note> <editor> J. Vitek and C. Tschudin (eds), </editor> <publisher> Springer Verlag Lecture Notes in Computer Science. </publisher>
Reference-contexts: Scheduling issues in heterogeneous computing using network bandwidth and load information are addressed in [8]. The above work deals with an integration of different machines as one server and does not have the division of client and server. Recent work on mobile computing (e.g. <ref> [1] </ref>) also uses bandwidth and data locality information to dynamically migrate computation. Our current project focuses on the optimization between a server and clients and currently uses tightly coupled server nodes for a WWW server, but results could be generalized for loosely coupled server nodes.
Reference: [2] <institution> The AltaVista Main Page, </institution> <note> http://altavista.digital.com/. </note>
Reference-contexts: For example, most digital library (DL) systems [14] will be based on the WWW. The major performance bottlenecks for the advent of WWW technology are server computing capabilities and Internet bandwidth. Popular WWW sites such as Alta Vista <ref> [2] </ref> receive over twenty-eight million accesses a day, where the computational demand for each request is often less than that in many sophisticated WWW systems (e.g. DLs). In [4], a study is presented on developing multiprocessor Web servers in dealing with this bottleneck using networked workstations connected with inexpensive disks.
Reference: [3] <author> D.Andresen, L.Carver, R.Dolin, C.Fischer, J.Frew, M.Goodchild, O.Ibarra, R.Kothuri, M.Larsgaard, B.Manjunath, D.Nebert, J.Simpson, T.Smith, T.Yang, Q.Zheng, </author> <title> "The WWW Prototype of the Alexandria Digital Library", </title> <booktitle> Proc. of ISDL'95: International Symposium on Digital Libraries, </booktitle> <address> Japan, </address> <year> 1995. </year>
Reference-contexts: The scheduler must determine a proper split point as a function of bandwidth and available processing capability. Another example for multi-resolution image browsing. This application comes from the Alexandria Digital Library system (ADL) <ref> [3] </ref>. ADL has adopted a progressive multi-resolution and subregion browsing strategy to reduce Internet traffic in accessing map images.
Reference: [4] <author> D.Andresen, T.Yang, V.Holmedahl, O.Ibarra, "SWEB: </author> <title> Towards a Scalable World Wide Web Server on Multicomputers", </title> <booktitle> Proc. of 10th IEEE International Symp. on Parallel Processing (IPPS'96), </booktitle> <pages> pp. 850-856. </pages> <month> April, </month> <year> 1996. </year>
Reference-contexts: Popular WWW sites such as Alta Vista [2] receive over twenty-eight million accesses a day, where the computational demand for each request is often less than that in many sophisticated WWW systems (e.g. DLs). In <ref> [4] </ref>, a study is presented on developing multiprocessor Web servers in dealing with this bottleneck using networked workstations connected with inexpensive disks. As the WWW develops and Web browsers achieve the ability to download executable content (e.g. <p> User requests are first evenly routed to processors via DNS rotation <ref> [4, 15] </ref>. Each server node may have its local disk, which is accessible to other nodes via remote file service in the OS. 1 server. <p> We first present a cost model for predicting the response time in processing a request, then we discuss a strategy to select a server node and decide a good partitioning point. This cost model is based on our previous SWEB work <ref> [4] </ref> with extensions to incorporate the impact of client resources and network bandwidth and guide the client-server partitioning. Notice that it is not easy to model the cost associated with processing a WWW request accurately and factors such as caching and contention are not considered. <p> Our experiments show that the current cost function does reflect the impact of multiple parameters on the overall system response performance, and that the multi-node system delivers good performance based on such a heuristic. In <ref> [4] </ref>, we proposed using URL redirection to implement the request re-assignment. This approach requires a certain amount of time for reconnection. <p> Clients are located within the campus network to avoid Internet bandwidth fluctuations over multiple experiments. The overhead for monitoring and scheduling is quite small for all experiments. Analyzing a request takes about 2-4ms, and monitoring takes about 0.1% of CPU resources. These results are consistent with those in <ref> [4] </ref>. 5.1 The impact of adding multiple servers changes in processing mixed wavelet and Postscript requests. We examine how average response times decrease when p increases for a test period of 30 seconds, and at each second R requests are launched from clients (RP S = R). <p> Compared to the previous SWEB work <ref> [4] </ref>, the main contributions of this work are an adaptive scheduling model for processing requests by utilizing both client and multiprocessor server resources, and analytic results for supporting our scheduling scheme.
Reference: [5] <author> D. Andresen, T. Yang, D. Watson, A. Poulakidas, </author> <title> Dynamic Processor Scheduling with Client Resources for Fast Multi-resolution WWW Image Browsing, </title> <booktitle> in Proc. of the 11th IEEE International Parallel Processing Symposium (IPPS'97), </booktitle> <address> Geneva, </address> <month> April, </month> <year> 1997. </year>
Reference-contexts: In addition to this, the impact of available bandwidth between the server and a client needs to be incorporated. Thus dynamic scheduling strategies must be adaptive to variations of client/server resources in multiple aspects and we conducted a case study for the WWW-based image browsing application is in <ref> [5] </ref>. In this paper we propose a general scheduling model for partitioning and mapping client-server computation based on dynamically changing server and client capabilities. We present analytic results on homogeneous environments examining the impact of client and server resource availability. programmers in utilizing our model for their WWW applications.
Reference: [6] <author> D. Andresen, T. Yang, </author> <title> Adaptive Scheduling with Client Resources to Improve WWW Server Scalability, </title> <publisher> UCSB TRCS96-27. </publisher>
Reference-contexts: The complexity of this selection algorithm is O (pd) where p is the number of server nodes and d is the number of all possible 1 A simple file retrieval can also be considered as a task chain <ref> [6] </ref>. 3 split points. No requests are allowed to be re-directed more than once, to avoid the ping-pong effect. 3. Redirection and fulfillment. If the chosen server node is not x, the request is redirected appropriately. <p> Partitioning also affects the MRPS that can be reached. In this case a philosophical decision must be made regarding the goal of the server minimizing individual response times or preserving server resources for future requests. In our current research we assume the former policy. 4.2 Case studies In <ref> [6] </ref>, we have conducted case studies using the above framework for simple file fetches and wavelet-based image browsing. Here we present some results for the text extraction chain in Figure 3. <p> A verification for redirection ratios is in <ref> [6] </ref>. p=1 2 3 4 5 6 With client resources 1.5 3.0 4.5 6.0 7.5 9.0 Without 0.3 0.6 0.8 1.2 1.4 1.5 Table 3: Bursty MRPS for processing wavelets. (a) (b) Sustained MRPS bound. For Postscript and wavelet requests, we have theoretical MRPS predictions in Section 4. <p> The experimental results show that proper utilizing of server and client resources can significantly reduce application response times. Our current work is developing a software system called SWEB++ <ref> [6] </ref> which implements and supports the use of our scheduling scheme when programming WWW applications. The system contains a user interface for task specification, a module composer, and run-time performance monitor and scheduling support. Several projects are related to our work.
Reference: [7] <author> M. Arlitt, C. Williamson, </author> <title> Web Server Workload Characterization: The Search for Invariants, </title> <booktitle> Proc. SIGMETRICS Conference, </booktitle> <address> Philadelphia, PA, </address> <month> May, </month> <year> 1996. </year>
Reference-contexts: We denote this as model (r; L). Two instances of this model are considered. * (r; 1). This reflects the system performance in responding to a burst in user requests, which occurs frequently in many WWW sites <ref> [7, 11] </ref>. All requests are assumed completed in the same length of time and each server processor is dealing with the same number of requests until all finish. All task chains are partitioned uni formly at the same edge. * (r; 1).
Reference: [8] <author> F. Berman, R. Wolski, S. Figueira, J. Schopf, G. Shao, </author> <title> "Application-Level Scheduling on Distributed Heterogeneous Networks", </title> <booktitle> Proc. of Supercomputing '96. </booktitle>
Reference-contexts: Several projects are related to our work. Projects in [10, 12] are working on global computing software infrastructures. Scheduling issues in heterogeneous computing using network bandwidth and load information are addressed in <ref> [8] </ref>. The above work deals with an integration of different machines as one server and does not have the division of client and server. Recent work on mobile computing (e.g. [1]) also uses bandwidth and data locality information to dynamically migrate computation.
Reference: [9] <author> E.C.K. Chui, </author> <title> Wavelets: A Tutorial in Theory and Applications, </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: To support these features, the ADL system is using a wavelet-based hierarchical data representation for multi-resolution images <ref> [9] </ref>. Figure 4 depicts a task chain for processing a user request in accessing an image or subim-age with a higher resolution, based on an implementation in [18].
Reference: [10] <author> H. Casanova, J. Dongarra, NetSolve: </author> <title> A network server for solving computation science problems, </title> <booktitle> in Supercomputing'96, </booktitle> <address> ACM/IEEE, </address> <month> Nov </month> <year> 1996. </year>
Reference-contexts: The system contains a user interface for task specification, a module composer, and run-time performance monitor and scheduling support. Several projects are related to our work. Projects in <ref> [10, 12] </ref> are working on global computing software infrastructures. Scheduling issues in heterogeneous computing using network bandwidth and load information are addressed in [8]. The above work deals with an integration of different machines as one server and does not have the division of client and server.
Reference: [11] <author> M. Crovella, A. Bestavros, </author> <title> "Self-Similarity in World Wide Web Traffic Evidence and Possible Causes", </title> <booktitle> Proc. </booktitle> <address> SIGMETRICS96, Philadelphia, PA, </address> <month> May, </month> <year> 1996. </year>
Reference-contexts: We denote this as model (r; L). Two instances of this model are considered. * (r; 1). This reflects the system performance in responding to a burst in user requests, which occurs frequently in many WWW sites <ref> [7, 11] </ref>. All requests are assumed completed in the same length of time and each server processor is dealing with the same number of requests until all finish. All task chains are partitioned uni formly at the same edge. * (r; 1). <p> We ran experiments to determine the actual MRPS by testing for a period of 120 seconds and choosing the highest RPS such that the server response times are reasonable and no requests are dropped. We chose the period of 120 seconds based on <ref> [11, 16] </ref>, which indicates most "long" bursts on the Internet are actually relatively short. Thus the sustained RPS required in practice are for a period shorter than 1. Notice that for this experiment, the clients are simulated within the Meiko machine.
Reference: [12] <author> K. Dincer, and G. C. Fox, </author> <title> Building a world-wide virtual machine based on Web and HPCC technologies. </title> <note> To Appear in Supercomputing'96, ACM/IEEE, Nov 196. </note>
Reference-contexts: The system contains a user interface for task specification, a module composer, and run-time performance monitor and scheduling support. Several projects are related to our work. Projects in <ref> [10, 12] </ref> are working on global computing software infrastructures. Scheduling issues in heterogeneous computing using network bandwidth and load information are addressed in [8]. The above work deals with an integration of different machines as one server and does not have the division of client and server.
Reference: [13] <author> A. Fox, E. Brewer, </author> <title> "Reducing WWW Latency and Bandwidth Requirements by Real-Time Distillation", </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> Volume 28, issues 711, </volume> <editor> p. </editor> <volume> 1445. </volume> <month> May, </month> <year> 1996. </year>
Reference-contexts: Many small WWW clients, such as personal digital assistants (PDAs) or NetPCs, do not have the capability to display Postscript files. Viewing the text can be the only available option to and mapping. view the content of a Postscript document <ref> [13] </ref>. which extracts text from a subset of Postscript pages. The chain has two tasks that can be performed either at server or at client. 1) Select the pages needed. Eliminating unnecessary postscript pages reduces computation needed for Step 2. <p> Our current project focuses on the optimization between a server and clients and currently uses tightly coupled server nodes for a WWW server, but results could be generalized for loosely coupled server nodes. Addressing client configuration variation is discussed in <ref> [13] </ref> for filtering multi-media data but it does not consider the use of client resources for integrated computing. Acknowledgments This work was supported in part by NSF IRI94-11330, NSF CCR-9409695, NSF CCR-9702640, and a grant from NRaD.
Reference: [14] <author> E. Fox, Akscyn, R., Furuta, R. and Leggett, J. </author> <title> (Eds), </title> <journal> Special issue on digital libraries, CACM, </journal> <month> April </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Recently WWW-based computer technology has had an explosive growth in providing on-line access for images, files, and computing services over Internet. For example, most digital library (DL) systems <ref> [14] </ref> will be based on the WWW. The major performance bottlenecks for the advent of WWW technology are server computing capabilities and Internet bandwidth.
Reference: [15] <author> E.D. Katz, M. Butler, R. McGrath, </author> <title> A Scalable HTTP Server: the NCSA Prototype, </title> <journal> Computer Networks and ISDN Systems. </journal> <volume> vol. 27, </volume> <year> 1994, </year> <pages> pp. 155-164. </pages>
Reference-contexts: User requests are first evenly routed to processors via DNS rotation <ref> [4, 15] </ref>. Each server node may have its local disk, which is accessible to other nodes via remote file service in the OS. 1 server.
Reference: [16] <author> D. Mosedale, W. Foss, R. McCool, </author> <title> "Administering Very High Volume Internet Services", </title> <booktitle> 1995 LISA IX, </booktitle> <address> Monterey, CA, </address> <year> 1995. </year>
Reference-contexts: We ran experiments to determine the actual MRPS by testing for a period of 120 seconds and choosing the highest RPS such that the server response times are reasonable and no requests are dropped. We chose the period of 120 seconds based on <ref> [11, 16] </ref>, which indicates most "long" bursts on the Internet are actually relatively short. Thus the sustained RPS required in practice are for a period shorter than 1. Notice that for this experiment, the clients are simulated within the Meiko machine.
Reference: [17] <author> NCSA development team, </author> <title> The Common Gateway Interface, </title> <address> http://hoohoo.ncsa.uiuc.edu/cgi/, June, </address> <year> 1995. </year>
Reference-contexts: Each server node may have its local disk, which is accessible to other nodes via remote file service in the OS. 1 server. We model the interaction between client and server as a task chain that is partially executed at the server node (possibly as a CGI program <ref> [17] </ref>) and partially executed at the client site (as a Java applet if applicable). A task consists of a segment of the request fulfillment, with its associated computation and communication.
Reference: [18] <author> A. Poulakidas, A. Srinivasan, O. Egecioglu, O. Ibarra, and T. Yang, </author> <title> Experimental Studies on a Compact Storage Scheme for Wavelet-based Multiresolution Subregion Retrieval, </title> <booktitle> Proc. of NASA 1996 Combined Industry, Space and Earth Science Data Compression Workshop, </booktitle> <address> Utah, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: To support these features, the ADL system is using a wavelet-based hierarchical data representation for multi-resolution images [9]. Figure 4 depicts a task chain for processing a user request in accessing an image or subim-age with a higher resolution, based on an implementation in <ref> [18] </ref>.
Reference: [19] <author> B. A. Shirazi, A. R. Hurson, and K. M. Kavi (Eds), </author> <title> Scheduling and Load Balancing in Parallel and Distributed Systems, </title> <publisher> IEEE CS Press, </publisher> <year> 1995. </year> <month> 8 </month>
Reference-contexts: Still the overall accuracy of prediction is reasonable. It should be noted that the previous load balancing research <ref> [19] </ref> normally use simulations to verify performance analysis and it is quite difficult to predict and match actual performance in a real experimental setting. Expected Split Points.
References-found: 19

