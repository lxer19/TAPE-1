URL: http://www.cs.ucla.edu/~stott/ge/CSD-950039.ps.Z
Refering-URL: http://www.cs.ucla.edu/~stott/ge/
Root-URL: http://www.cs.ucla.edu
Email: dinh@cs.ucla.edu stott@cs.ucla.edu  
Title: Practical Recursive Block Decomposition Matrix Algorithms, and Quadtree Algorithms, via Randomization seen as impractical, since
Author: Dinh L^e D. Stott Parker 
Note: Until now, such algorithms have been  
Address: Los Angeles, CA 90095-1596  
Affiliation: UCLA Computer Science Department  
Abstract: We show how to use randomization to guarantee that submatrices meet these requirements, and to make recursive block decomposition methods practical on well-conditioned input matrices. The resulting algorithms are elegant, and we show the recursive programs can perform well for both dense and sparse matrices, although with randomization dense computations seem most practical. Essentially, by `homogenizing' the input, randomization provides a way to avoid degeneracy in numerical problems and permit simple functional programs to solve these problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ull-man. </author> <title> The Design and Analysis of Computer Algorithms. </title> <booktitle> Computer Science and Information Processing. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: CA 1 I A 0 0 I : Thus the determinant can be computed as: det A B Recursive block decomposition algorithms are often used in texts for natural presentation of basic operations like matrix sum, product, inverse, transforms like the Discrete Fourier Transform, and factorizations like Cholesky and QR <ref> [1, 9] </ref>. Our objective is to study what it would take to make these algorithms used more widely in practice. 1.2 The Quadtree Structure In this paper we are particularly concerned about the case where A, B, C, D are quadrants of the matrix (blocks of equal size). <p> Then the coresponding recurrence relations are T s (n) = 7T s (n=2) + 18 (n=2) 2 , and T t (n) = 8T t (n=2) + 4 (n=2) 2 . As explained in <ref> [1, p.231] </ref>, these yield asymptotic complexities of O (n 2:81 ) and O (n 3 ) respectively. 3.3 Matrix Inversion Faddeev & Faddeeva [8, pp.161-163] provide a recursive method of solving matrix inversion as follows: C D = A 1 A 1 BM A 1 BN where N = (D CA
Reference: [2] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Don-garra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorenson. </author> <note> LA-PACK User's Guide. Siam, second edition, </note> <year> 1995. </year>
Reference-contexts: Unfortunately, the quadtree representation raises problems for serious implementors of matrix computations. First, naive implementations of quadtree algorithms for standard computations like matrix multiplication and Gaussian elimination are far from being competitive, in terms of speed, memory requirements, usability, and scalability, with their iterative counterparts like those in LAPACK <ref> [2] </ref> and ScaLA-PACK [6] for uni- and multi-processors, respectively. Improved compilation technology is a minimum that is needed if naively-expressed quadtree algorithms are to be competitive. Also, practical implementations of quadtree algorithms can be very complicated. For instance, in [10], one of us implemented Wise's quadtree matrix inversion algorithm. <p> It has been designed to be efficient on a wide range of modern performance computers. The name LAPACK is an acronym for Linear Algebra PACKage." <ref> [2, p.3] </ref> 6 partial pivoting 2 on normally distributed random matrices are shown in Tables 1 and 2.
Reference: [3] <author> D.H. Bailey, K. Lee, and H.D. Simon. </author> <title> Using Strassen's algorithm to accelerate the solution of linear systems. </title> <journal> Journal of Supercomputing, </journal> <volume> 4(4) </volume> <pages> 357-71, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: We should stress that the quadtree/Faddeev/Strassen approach to matrix inversion is not new. For example, in <ref> [3] </ref> a general Strassen multiplication is derived to solve LU factorization on a Cray-YMP. Also, in [4], a more thorough analysis on the stability of a Strassen-type matrix inversion algorithm is described.
Reference: [4] <author> S.M. Balle and P.C. Hansen. </author> <title> A Strassen-type matrix inversion algorithm. </title> <booktitle> Advances in Parallel Algorithms. </booktitle> <address> Amsterdam, Netherlands: </address> <publisher> IOS Press, </publisher> <year> 1994. </year>
Reference-contexts: We should stress that the quadtree/Faddeev/Strassen approach to matrix inversion is not new. For example, in [3] a general Strassen multiplication is derived to solve LU factorization on a Cray-YMP. Also, in <ref> [4] </ref>, a more thorough analysis on the stability of a Strassen-type matrix inversion algorithm is described.
Reference: [5] <author> J.R. Bunch and J. Hopcroft. </author> <title> Triangular factorization and inversion by fast matrix multiplication. </title> <journal> Math. of Computation, </journal> <volume> 28 </volume> <pages> 231-236, </pages> <year> 1974. </year>
Reference-contexts: When the input matrix M is symmetric positive definite this guarantee will be met, for example. In general, of course, it is not. There are several old tricks that work in the important case where M is nonsingular but nothing specific is known about its submatrices. Bunch and Hopcroft <ref> [5] </ref> mention two: they point out that the rows of such M can always be permuted so that the nonsingularity requirement needed for Gaussian elimination is met. Unfortunately there is no way of knowing the permutation a priori other than, for example, performing Gaussian elimination.
Reference: [6] <author> J. Choi, J. Demmel, I. Dhillon, J. Dongarra, S. Os-trouchov, A. Petitet, K. Stanley, D. Walker, and R.C. Whaley. </author> <note> LAPACK Working Note 95 | ScaLAPACK: </note>
Reference-contexts: First, naive implementations of quadtree algorithms for standard computations like matrix multiplication and Gaussian elimination are far from being competitive, in terms of speed, memory requirements, usability, and scalability, with their iterative counterparts like those in LAPACK [2] and ScaLA-PACK <ref> [6] </ref> for uni- and multi-processors, respectively. Improved compilation technology is a minimum that is needed if naively-expressed quadtree algorithms are to be competitive. Also, practical implementations of quadtree algorithms can be very complicated. For instance, in [10], one of us implemented Wise's quadtree matrix inversion algorithm.
References-found: 6

