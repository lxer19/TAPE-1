URL: http://www.demo.cs.brandeis.edu/papers/perceptron.ps.gz
Refering-URL: http://www.demo.cs.brandeis.edu/papers/long.html
Root-URL: http://www.cs.brandeis.edu
Title: Book Review No Harm Intended  
Author: Marvin L. Minsky and Seymour A. Papert. Jordan B. Pollack 
Note: Perceptrons: An Introduction to Computational Geometry, Expanded Edition. Cambridge, MA: MIT Press, 1988. 292pp. Reviewed by  
Abstract: The Authors are professors at the Massachusetts Institute of Technology, Minsky in Electrical Engineering and Papert in Applied Mathematics. Minsky's major research interests are artificial intelligence (AI) and theories of computation, and Papert's are cybernetics and child development The Reviewer received his Ph.D. in Computer Science from the University of Illinois in 1987, and is currently an Assistant Professor of Computer and Information Science at the Ohio State University. His research involves the use of connectionist models in traditional AI tasks. 
Abstract-found: 1
Intro-found: 1
Reference: <author> BLOCK, H. D. </author> <year> (1970). </year> <title> A Review of Perceptrons. </title> <journal> Information and Control, </journal> <volume> 17, </volume> <pages> 501-522. </pages>
Reference: <author> BLUM, A. & RIVEST, R. L. </author> <year> (1988). </year> <title> Training a 3-Node Neural Network is NP-Complete. </title> <booktitle> In Proceedings of Institute of Electrical and Electronics Engineers conference on Neural Information Processing Systems. </booktitle> <address> Denver. </address>
Reference: <author> BROOKS, F. P. </author> <year> (1975). </year> <title> The Mythical Man-Month. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> CHANDRASEKARAN, B. </author> <year> (1987). </year> <title> Towards a functional architecture for intelligence based on generic information processing tasks. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence. Milan, </booktitle> <pages> 1183-1192. </pages>
Reference-contexts: This is quite a humorous turn of events. The psychologists offer an implemented information-processing model, which the computer scientists reject in favor of a creative hhhhhhhhhhhhhhh 3 However, there are responsible practitioners who do care about tractability <ref> (Chandrasekaran, 1987) </ref>. - 7 - psychological theory! The remainder of the epilogue is, essentially, a criticism of certain aspects of modern connectionism, such as distributed representations (Hinton, 1984), from the perspective, and in the diffuse style, of Minsky's vast theory.
Reference: <author> CHERNIAK, C. </author> <year> (1988). </year> <journal> Undebuggability and cognitive science. Communications of the Association for Computing Machinery, </journal> <volume> 31, </volume> <pages> 402-412. </pages>
Reference: <author> DREYFUS, H. L. & DREYFUS, S. E. </author> <year> (1988). </year> <title> Making a Mind versus Modeling the Brain: </title> <booktitle> Artificial Intelligence Again at the Crossroads. Daedalus, </booktitle> <pages> 117. </pages>
Reference: <author> DYER, M. G. </author> <year> (1983). </year> <title> In Depth Understanding. </title> <publisher> Cambridge: MIT Press. - 8 - HINTON, </publisher> <editor> G. E. </editor> <year> (1984). </year> <title> Distributed Representations. </title> <type> CMU-CS-84-157, </type> <institution> Pittsburgh, PA: Carnegie-Mellon University, Computer Science Department. </institution>
Reference-contexts: Meanwhile, the symbolic processing side of AI has wandered off into building systems of Brobdingnagian proportions (Lenat et al., 1986). Whether or not such large-scale software-engineering projects are even doable (Brooks, 1975; Cherniak, 1988; Parnas, 1985), AI's most ``successful'' programs, such as SHRDLU (Winograd, 1972) or BORIS <ref> (Dyer, 1983) </ref>, are so complex that nobody can repeat these experiments to confirm or deny their findings or to build on previous results. One of the hallmarks of real work in Artificial Intelligence is that theory-making must be backed up by program-building.
Reference: <author> HINTON, G. E. </author> <year> (1986). </year> <title> Learning Distributed Representations of Concepts. </title> <booktitle> In Proceedings of the Eighth Annual Conference of the Cognitive Science Society. </booktitle> <address> Amherst, MA, </address> <pages> 1-12. </pages>
Reference: <author> JUDD, S. </author> <year> (1987). </year> <title> Learning in Networks is hard. </title> <booktitle> In Proceedings of the First Institute of Electrical and Electronics Engineers Neural Network Conference. </booktitle> <address> San&gt; Diego, II-685-692. </address>
Reference: <author> KOLEN, J. F. </author> <year> (1988). </year> <title> Faster learning through a probabilistic approximation algorithm. </title> <booktitle> In Proceedings of the Second Institute of Electrical and Electronics Engineers conference on Neural Networks. </booktitle> <address> San Diego, I-449-454. </address>
Reference: <author> LENAT, D., PRAKASH, M. & SHEPARD, M. </author> <year> (1986). </year> <title> CYC: Using common sense knowldeg to overcome brittleness and knowledge engineering bottlenecs. </title> <journal> Artificial Intelligence Magazine, </journal> <volume> VI, </volume> <pages> 65-85. </pages>
Reference-contexts: Connectionists are finally meeting a scientific goal for cognitive modeling which traditional AI itself has always lacked, namely the construction of theories embodied as computer programs which are both testable and repeatable. Meanwhile, the symbolic processing side of AI has wandered off into building systems of Brobdingnagian proportions <ref> (Lenat et al., 1986) </ref>.
Reference: <author> MCCLELLAND, J. L., RUMELHART, D. E. </author> & <title> THE PDP RESEARCH GROUP (1986). Parallel Distributed Processing: Experiments in the Microstructure of Cognition. </title> <publisher> Cambridge: MIT Press. </publisher>
Reference-contexts: But they also miss the fact that such questions are not of central concern to psychologists, such as Rumelhart and McClelland, who might even use first-order systems in pursuit of a cognitive model <ref> (Rumelhart & McClelland, 1986) </ref> which is empirically testable and deniable (Pinker & Prince, 1988).
Reference: <author> MINSKY, M. </author> <year> (1986). </year> <title> The Society of Mind. </title> <address> New York: </address> <publisher> Simon & Schuster. </publisher>
Reference-contexts: In one of the most brilliant turnabouts in scientific history, Minsky and Papert admit that neural networks are workable for toy problems, and therefore fit nicely into Minsky's grand unified theory of a Society of Mind <ref> (Minsky, 1986) </ref>, a theory which purports that ``mind is made up of a large number of components or `agents,' each of which would operate on the scale of ... a toy problem'' (p. 266).
Reference: <author> MJOLSNESS, E., SHARP, D. H. & ALPERT, B. K. </author> <year> (1987). </year> <title> Recursively Generated Neural Networks. </title> <booktitle> In Institute of Electrical and Electronics Engineers First International Conference on Neural Networks. </booktitle> <address> San Diego, III-165-171. </address>
Reference: <author> NEWELL, A. </author> <year> (1969). </year> <title> A step toward the understanding of information processes. </title> <journal> Science, </journal> <volume> 165, </volume> <pages> 780-782. </pages>
Reference: <author> PAPERT, S. </author> <year> (1988). </year> <title> One Artificial Intelligence or Many. </title> <journal> Daedalus, </journal> <volume> 117, </volume> <pages> 1-14. </pages>
Reference-contexts: It [was] almost inevitable for AI to appropriate our work as proof that neural networks were universally bad. We did not think of our work as killing Snow White... <ref> (Papert, 1988 p. 7) </ref> Research on Connectionist and Neural Networks has recently awakened, and is now expecting a valuable kiss from Prince DARPA. 1 In fact, 1988 may be the year of connectionism's loss of innocence.
Reference: <author> PARNAS, D. </author> <year> (1985). </year> <title> Software aspects of strategic defense systems. </title> <journal> American Scientist, </journal> <volume> 73, </volume> <pages> 432-440. </pages>
Reference: <author> PINKER, S. & PRINCE, A. </author> <year> (1988). </year> <title> On Language and Connectionism: Analysis of a parallel distributed processing model of language inquisition.. </title> <journal> Cognition, </journal> <volume> 28, </volume> <pages> 73-193. </pages>
Reference-contexts: But they also miss the fact that such questions are not of central concern to psychologists, such as Rumelhart and McClelland, who might even use first-order systems in pursuit of a cognitive model (Rumelhart & McClelland, 1986) which is empirically testable and deniable <ref> (Pinker & Prince, 1988) </ref>.
Reference: <author> POLLACK, J. B. </author> <year> (1988). </year> <title> Recursive Auto-Associative Memory: Devising Compositional Distributed Representations. </title> <booktitle> In Proceedings of the Tenth Annual Conference of the Cognitive Science Society. Montreal, </booktitle> <pages> 33-39. </pages>
Reference: <author> POMERLEAU, D. A. </author> <year> (1988). </year> <title> ALVINN: An Autonomous Land Vehicle in a Neural Network. </title> <booktitle> In Proceedings of Institute of Electrical and Electronics Engineers conference on Neural Information Processing Systems. </booktitle> <address> Denver. </address>
Reference-contexts: While one could indeed solve the credit assignment problem for the seven weights of the exclusive-or network using exhaustive search, one could not do it for a text-to-phoneme network (Sejnowski & Rosenberg, 1987) with its 10 5 weights or an autonomous vehicle controller with 10 6 <ref> (Pomerleau, 1988) </ref>. On the other hand, we also know that for certain classes of very hard problems, there are no algorithms which scale significantly better than exhaustive search, unless they are approximations. But there are many such impractical and approximate methods which are in practical use worldwide.
Reference: <author> ROSENBLATT, F. </author> <year> (1962). </year> <title> Principles of Neurodynamics. </title> <address> New York: </address> <publisher> Spartan. </publisher>
Reference-contexts: Even though they only criticize Chapter 8, they hope that the reader will ``seize the general'' point. Finally, the authors wrap themselves in the ``flag'' of unsolvable problems (pp. 247-248). Minsky and Papert point out, rightly, that Rumelhart et al have no result, like the Perceptron Convergence Theorem <ref> (Rosenblatt, 1962) </ref>, that the generalized delta rule is guaranteed to find solutions when they exist, and that ``little has been proved about the range of problems upon which [the generalized delta rule] works both efficiently and dependably.'' (p. 260.) - 5 - Since, despite the fact that they "consider [ed] it
Reference: <author> ROSENFELD, R. & TOURETZKY, D. </author> <year> (1988). </year> <title> Four capacity models for coarse-coded symbol memories. </title> <journal> Complex Systems, </journal> <volume> 2, </volume> <pages> 463-484. </pages>
Reference: <author> RUMELHART, D. E. & MCCLELLAND, J. L. </author> <year> (1986). </year> <title> On Learning the Past Tenses of English Verbs. </title>
Reference-contexts: But they also miss the fact that such questions are not of central concern to psychologists, such as Rumelhart and McClelland, who might even use first-order systems in pursuit of a cognitive model <ref> (Rumelhart & McClelland, 1986) </ref> which is empirically testable and deniable (Pinker & Prince, 1988).
Reference: <editor> In J. L. McClelland, D. E. Rumelhart & the PDP research Group, (Eds.), </editor> <booktitle> Parallel Distributed Processing: Experiments in the Microstructure of Cognition, </booktitle> <volume> Vol. </volume> <pages> 2. </pages> <address> Cambridge: </address> <publisher> MIT Press. </publisher>
Reference: <author> RUMELHART, D. E., MCCLELLAND, J. L., </author> & <title> THE PDP RESEARCH GROUP (1986). Parallel Distributed Processing: Experiments in the Microstructure of Cognition. </title> <publisher> Cambridge: MIT Press. </publisher>
Reference-contexts: But they also miss the fact that such questions are not of central concern to psychologists, such as Rumelhart and McClelland, who might even use first-order systems in pursuit of a cognitive model <ref> (Rumelhart & McClelland, 1986) </ref> which is empirically testable and deniable (Pinker & Prince, 1988).
Reference: <author> RUMELHART, D. E., HINTON, G. & WILLIAMS, R. </author> <year> (1986). </year> <title> Learning Internal Representations through Error Propagation. </title> <editor> In D. E. Rumelhart, J. L. McClelland & the PDP research Group, (Eds.), </editor> <booktitle> Parallel Distributed Processing: Experiments in the Microstructure of Cognition, </booktitle> <volume> Vol. </volume> <pages> 1. </pages> <address> Cambridge: </address> <publisher> MIT Press. </publisher>
Reference-contexts: But they also miss the fact that such questions are not of central concern to psychologists, such as Rumelhart and McClelland, who might even use first-order systems in pursuit of a cognitive model <ref> (Rumelhart & McClelland, 1986) </ref> which is empirically testable and deniable (Pinker & Prince, 1988).
Reference: <author> RUMELHART, D. E. & ZIPSER, D. </author> <year> (1986). </year> <title> Feature Discovery by Competitive Learning. </title> <editor> In D. </editor> <publisher> E. </publisher>
Reference-contexts: But they also miss the fact that such questions are not of central concern to psychologists, such as Rumelhart and McClelland, who might even use first-order systems in pursuit of a cognitive model <ref> (Rumelhart & McClelland, 1986) </ref> which is empirically testable and deniable (Pinker & Prince, 1988).
Reference: <author> Rumelhart, J. L. </author> <title> McClelland & the PDP research Group, </title> <editor> (Eds.), </editor> <booktitle> Parallel Distributed Processing: Experiments in the Microstructure of Cognition, </booktitle> <volume> Vol. </volume> <pages> 1. </pages> <address> Cambridge: </address> <publisher> MIT Press. </publisher>
Reference: <author> SAMUEL, A. L. </author> <year> (1967). </year> <title> Some studies in machine learning using the game of checkers. II Recent Progress. </title> <journal> IBM Journal of Research & Development, </journal> <volume> 11, </volume> <pages> 601-618. </pages>
Reference: <author> SEARLE, J R. </author> <year> (1980). </year> <title> The intentionality of intention and action. </title> <journal> Cognitive Science, </journal> <volume> 4, </volume> <pages> 47-70. </pages> - <note> 9 - SEJNOWSKI, </note> <author> T. J. & ROSENBERG, C. R. </author> <year> (1987). </year> <title> Parallel Networks that Learn to Pronounce English Text. </title> <journal> Complex Systems, </journal> <volume> 1, </volume> <pages> 145-168. </pages>
Reference-contexts: So, were they responsible for killing Snow White? No, since intention and action are separable, they were no more responsible than Bill, who, intending to kill his uncle, is ``so nervous and excited [when driving] that he accidentally runs over and kills a pedestrian, who happens to be his uncle'' <ref> (Searle 1980, p. 51) </ref>. If Minsky and Papert did not intend to stifle the field of neural networks, then, perhaps, they would act in accordance with their new motto: ``We see no reason to choose sides.'' (p. xiv).
Reference: <author> TOURETZKY, D. S. </author> <year> (1986). </year> <title> BoltzCONS: Reconciling connectionism with the recursive nature of stacks and trees. </title> <booktitle> In Proceedings of the 8th Annual Conference of the Cognitive Science Society. </booktitle> <address> Amherst, MA, </address> <pages> 522-530. </pages>
Reference: <author> TOURETZKY, D. S. & GEVA, S. </author> <year> (1987). </year> <title> A distributed connectionist representation for concept structures. </title> <booktitle> In Proceedings of the Ninth Annual Conference of the Cogntive Science Scoiety. Seattle, </booktitle> <pages> 155-164. </pages>
Reference: <author> WAIBEL, A. </author> <year> (1988). </year> <title> Modularity in neural networks for speech recognition. </title> <booktitle> In Proceedings of Institute of Electrical and Electronics Engineers conference on Neural Information Processing Systems. </booktitle> <address> Denver. </address>
Reference: <author> WALTZ, D. L. & POLLACK, J. B. </author> <year> (1985). </year> <title> Massively Parallel Parsing: A strongly interactive model of Natural Language Interpretation. </title> <journal> Cognitive Science, </journal> <volume> 9, </volume> <pages> 51-74. </pages>
Reference: <author> WINOGRAD, T. </author> <year> (1972). </year> <title> Understanding natural language. </title> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference-contexts: Meanwhile, the symbolic processing side of AI has wandered off into building systems of Brobdingnagian proportions (Lenat et al., 1986). Whether or not such large-scale software-engineering projects are even doable (Brooks, 1975; Cherniak, 1988; Parnas, 1985), AI's most ``successful'' programs, such as SHRDLU <ref> (Winograd, 1972) </ref> or BORIS (Dyer, 1983), are so complex that nobody can repeat these experiments to confirm or deny their findings or to build on previous results. One of the hallmarks of real work in Artificial Intelligence is that theory-making must be backed up by program-building.
References-found: 35

