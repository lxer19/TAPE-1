URL: http://www.research.microsoft.com/~ymwang/papers/FTCS-1993.ps
Refering-URL: http://www.research.microsoft.com/~ymwang/papers/FTCS93CR.htm
Root-URL: http://www.research.microsoft.com
Title: Progressive Retry for Software Error Recovery in Distributed Systems  
Author: Yi-Min Wang Yennun Huang W. Kent Fuchs 
Address: Murray Hill, NJ 07974  Urbana, IL 61801 Urbana, IL 61801  
Affiliation: Coordinated Science Laboratory AT&T Bell Laboratories Coordinated Science Laboratory University of Illinois  University of Illinois  
Abstract: In this paper, we describe a method of execution retry for bypassing software faults based on checkpointing, rollback, message reordering and replaying. We demonstrate how rollback techniques, previously developed for transient hardware failure recovery, can also be used to recover from software errors by exploiting message reordering to bypass software faults. Our approach intentionally increases the degree of nondeterminism and the scope of rollback when a previous retry fails. Examples from our experience with telecommunications software systems illustrate the benefits of the scheme. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Bhargava and S. R. </author> <title> Lian,Independent checkpointing and concurrent rollback for recovery An optimistic approach, </title> <booktitle> in Proc. IEEE Symp. on Reliable Distr. Syst., </booktitle> <pages> pp. 3-12, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction Numerous checkpointing and rollback recovery techniques have been proposed in the literature to recover from transient hardware failures. Uncoordinated checkpointing schemes <ref> [1, 2] </ref> allow maximum process autonomy and general nondeterministic execution, but suffer from potential domino effects [3]. Coordinated checkpointing schemes [4, 5] eliminate the domino effect by sacrificing a certain degree of process autonomy and by paying the cost of extra coordination messages.
Reference: [2] <author> Y. M. Wang and W. K. Fuchs, </author> <title> Optimistic message log-ging for independent checkpointing in message-passing systems, </title> <booktitle> in Proc. IEEE Symp. on Reliable Distr. Syst., </booktitle> <pages> pp. 147-154, </pages> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Numerous checkpointing and rollback recovery techniques have been proposed in the literature to recover from transient hardware failures. Uncoordinated checkpointing schemes <ref> [1, 2] </ref> allow maximum process autonomy and general nondeterministic execution, but suffer from potential domino effects [3]. Coordinated checkpointing schemes [4, 5] eliminate the domino effect by sacrificing a certain degree of process autonomy and by paying the cost of extra coordination messages. <p> Centralized recovery line computation: the global dependency information is collected by the process which initiates the garbage collection or recovery procedure <ref> [2, 11] </ref> and is responsible for the recovery line computation 5 . 3.1 Recovery Line and Message Logs With respect to the recovery line consisting of the shaded checkpoints shown in Fig. 3, messages can be classified into four categories. 1.
Reference: [3] <author> B. Randell, </author> <title> System structure for software fault tolerance, </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol. SE-1, No. 2, </volume> <pages> pp. 220-232, </pages> <month> June </month> <year> 1975. </year>
Reference-contexts: 1 Introduction Numerous checkpointing and rollback recovery techniques have been proposed in the literature to recover from transient hardware failures. Uncoordinated checkpointing schemes [1, 2] allow maximum process autonomy and general nondeterministic execution, but suffer from potential domino effects <ref> [3] </ref>. Coordinated checkpointing schemes [4, 5] eliminate the domino effect by sacrificing a certain degree of process autonomy and by paying the cost of extra coordination messages. <p> By intentionally discarding part of the message logs, we can deterministically reconstruct the system state up to the dotted line shown in Fig. 1, and then use message reordering to introduce nondeterministic execution beyond the dotted line in order to bypass the software fault. Unlike the recovery block approach <ref> [3] </ref> and N-version programming [18] which both use different programs to execute on the same set of data, the above on-line retry approach [14, 19] uses the same program to operate on a different but consistent set of data [20] obtained through message reordering.
Reference: [4] <author> K. M. Chandy and L. Lamport, </author> <title> Distributed snapshots: Determining global states of distributed systems, </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> Vol. 3, No. 1, </volume> <pages> pp. 63-75, </pages> <month> Feb. </month> <year> 1985. </year>
Reference-contexts: 1 Introduction Numerous checkpointing and rollback recovery techniques have been proposed in the literature to recover from transient hardware failures. Uncoordinated checkpointing schemes [1, 2] allow maximum process autonomy and general nondeterministic execution, but suffer from potential domino effects [3]. Coordinated checkpointing schemes <ref> [4, 5] </ref> eliminate the domino effect by sacrificing a certain degree of process autonomy and by paying the cost of extra coordination messages.
Reference: [5] <author> K. Li, J. F. Naughton, and J. S. Plank, </author> <title> Checkpointing mul-ticomputer applications, </title> <booktitle> in Proc. IEEE Symp. on Reliable Distr. Syst., </booktitle> <pages> pp. 2-11, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Numerous checkpointing and rollback recovery techniques have been proposed in the literature to recover from transient hardware failures. Uncoordinated checkpointing schemes [1, 2] allow maximum process autonomy and general nondeterministic execution, but suffer from potential domino effects [3]. Coordinated checkpointing schemes <ref> [4, 5] </ref> eliminate the domino effect by sacrificing a certain degree of process autonomy and by paying the cost of extra coordination messages.
Reference: [6] <author> Y. M. Wang and W. K. Fuchs, </author> <title> Lazy checkpoint coordination for bounding rollback propagation. </title> <type> Tech. Rep. </type> <institution> CRHC-92-26, Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, </institution> <year> 1992. </year>
Reference-contexts: Coordinated checkpointing schemes [4, 5] eliminate the domino effect by sacrificing a certain degree of process autonomy and by paying the cost of extra coordination messages. Recently, a lazy checkpoint coordination technique <ref> [6] </ref> has been proposed as a mechanism for bounding rollback propagation and providing a flexible trade-off between run-time coordination overhead and recovery efficiency. Log-based recovery provides another way of achieving domino-free recovery. Under the piecewise deterministic model [7], the domino effect is avoided through message logging and deterministic replaying.
Reference: [7] <author> R. E. Strom, D. F. Bacon, and S. A. Yemini, </author> <title> Volatile logging in n-fault-tolerant distributed systems, </title> <booktitle> in Proc. IEEE Fault-Tolerant Computing Symposium, </booktitle> <pages> pp. 44-49, </pages> <year> 1988. </year>
Reference-contexts: Recently, a lazy checkpoint coordination technique [6] has been proposed as a mechanism for bounding rollback propagation and providing a flexible trade-off between run-time coordination overhead and recovery efficiency. Log-based recovery provides another way of achieving domino-free recovery. Under the piecewise deterministic model <ref> [7] </ref>, the domino effect is avoided through message logging and deterministic replaying. In a pessimistic logging protocol [8, 9], each message is logged upon receipt 1 To appear in FTCS-23, 1993.
Reference: [8] <author> A. Borg, J. Baumbach, and S. Glazer, </author> <title> A message system supporting fault-tolerance, </title> <booktitle> in Proc. 9th ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 90-99, </pages> <year> 1983. </year>
Reference-contexts: Log-based recovery provides another way of achieving domino-free recovery. Under the piecewise deterministic model [7], the domino effect is avoided through message logging and deterministic replaying. In a pessimistic logging protocol <ref> [8, 9] </ref>, each message is logged upon receipt 1 To appear in FTCS-23, 1993.
Reference: [9] <author> M. L. Powell and D. L. Presotto, </author> <title> Publishing: A reliable broadcast communication mechanism, </title> <booktitle> in Proc. 9th ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp. 100-109, </pages> <year> 1983. </year>
Reference-contexts: Log-based recovery provides another way of achieving domino-free recovery. Under the piecewise deterministic model [7], the domino effect is avoided through message logging and deterministic replaying. In a pessimistic logging protocol <ref> [8, 9] </ref>, each message is logged upon receipt 1 To appear in FTCS-23, 1993.
Reference: [10] <author> R. E. Strom and S. Yemini, </author> <title> Optimistic recovery in distributed systems, </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> Vol. 3, No. 3, </volume> <pages> pp. 204-226, </pages> <month> Aug. </month> <year> 1985. </year>
Reference-contexts: Instead of proposing another checkpointing and recovery protocol, this paper investigates the possibility of applying the log-based techniques to recovery from software errors <ref> [10, 13-16] </ref>. We previously proposed message reordering for changing the communication pattern at run-time in order to reduce the rollback distance for hardware failures [17]. In this paper, we demonstrate how message reordering can also provide an effective way of bypassing certain software faults. Fig. 1 illustrates the basic concept. <p> FIFO channel: messages sent along the same channel between any two processes are ordered by monotonically increasing sequence numbers. Merge component: messages from all incoming channels are merged by the merge component <ref> [10] </ref> based on a changeable merge function, and are assigned the state interval indices. <p> Direct dependency tracking [11, 25, 26]: only the dependency of the receiver's logical checkpoint on the sender's logical checkpoint resulting from each message processing is recorded, as opposed to the transitive dependency tracking which has been used in many log-based papers <ref> [10, 12] </ref>. <p> Orphan messages: Messages sent after the recovery line are orphan messages. M 0 R can not exist because otherwise the recovery line is not consistent. M R is invalidated by the rollback and should be discarded. In an optimistic logging protocol <ref> [10] </ref>, rollback propagation can result from the nondeterminism due to lost volatile message logs upon failure. <p> A distributed and asynchronous algorithm can be found in Strom and Yemini's paper <ref> [10] </ref>. orphan messages. recovery line. In contrast, our retry technique progressively increases the degree of nondeterminism and the scope of rollback by discarding more message logs as a previous retry fails. <p> Message M d in Fig. 4 is an example. Such lost messages can be detected 6 when the receiver receives another message from the same sender which indicates a discontinuity in the message sequence number <ref> [10] </ref>. The sender is then requested to resend the message if sender logging is available [10], or to regenerate the message through deterministic state reconstruction [12]. <p> Such lost messages can be detected 6 when the receiver receives another message from the same sender which indicates a discontinuity in the message sequence number <ref> [10] </ref>. The sender is then requested to resend the message if sender logging is available [10], or to regenerate the message through deterministic state reconstruction [12]. The immediate recovery of such lost messages is useful for increasing the number of messages available for reordering. p 2 now discards the message contents of M a and M b as well. <p> In the extreme case where fast output commit is the most important requirement for the system, only those state intervals beyond the last out put can be backed off for introducing nondeterminism <ref> [10] </ref>. 5 Experience and Discussion In this section, we describe two examples from telecommunications software with software boundary errors. By using the progressive retry technique (Step 1 for Case 1 and Step 3 for Case 2), these programs were able to quickly recover from the errors without service interruption.
Reference: [11] <author> D. B. Johnson and W. Zwaenepoel, </author> <title> Recovery in distributed systems using optimistic message logging and checkpoint-ing, </title> <journal> J. of Algorithms, </journal> <volume> Vol. 11, </volume> <pages> pp. 462-491, </pages> <year> 1990. </year>
Reference-contexts: This can be achieved by the piecewise deterministic model and additional message logging and replaying. The piecewise deterministic model says: process execution between two consecutive message receipts, called a state interval, is deterministic. So if p 1 has logged both the message content and the state interval index <ref> [11] </ref> (i.e., the processing order) for message M 0 (but not for M 2 ) by the time it initiates the rollback, p 1 can deterministically reconstruct the state up to immediately before the receipt of M 2 (a nondeterministic event) and therefore M 1 remains a valid message. <p> Direct dependency tracking <ref> [11, 25, 26] </ref>: only the dependency of the receiver's logical checkpoint on the sender's logical checkpoint resulting from each message processing is recorded, as opposed to the transitive dependency tracking which has been used in many log-based papers [10, 12]. <p> Centralized recovery line computation: the global dependency information is collected by the process which initiates the garbage collection or recovery procedure <ref> [2, 11] </ref> and is responsible for the recovery line computation 5 . 3.1 Recovery Line and Message Logs With respect to the recovery line consisting of the shaded checkpoints shown in Fig. 3, messages can be classified into four categories. 1.
Reference: [12] <author> A. P. Sistla and J. L. Welch, </author> <title> Efficient distributed recovery using message logging, </title> <booktitle> in Proc. 8th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 223-238, </pages> <year> 1989. </year>
Reference-contexts: Direct dependency tracking [11, 25, 26]: only the dependency of the receiver's logical checkpoint on the sender's logical checkpoint resulting from each message processing is recorded, as opposed to the transitive dependency tracking which has been used in many log-based papers <ref> [10, 12] </ref>. <p> Based on the available message logs from stable storage, the recovery line is uniquely de termined and each message must statically belong to one of the four categories depending on its position relative to the 5 A distributed and synchronizedalgorithm has been proposed by Sistla and Welch <ref> [12] </ref>. A distributed and asynchronous algorithm can be found in Strom and Yemini's paper [10]. orphan messages. recovery line. In contrast, our retry technique progressively increases the degree of nondeterminism and the scope of rollback by discarding more message logs as a previous retry fails. <p> The sender is then requested to resend the message if sender logging is available [10], or to regenerate the message through deterministic state reconstruction <ref> [12] </ref>. The immediate recovery of such lost messages is useful for increasing the number of messages available for reordering. p 2 now discards the message contents of M a and M b as well. <p> Outputs to the outside world that cannot be rolled back should only be released after the recovery line has advanced beyond the state intervals that generate these outputs. Checkpoints and message logs can only be garbage-collected after the restart line has passed their corresponding state intervals <ref> [12] </ref>. Therefore, while a larger K means more nondeterminism is available, it also results in slower output commit and less effective garbage collection, which are translated into slower response to the users and larger space overhead, respectively.
Reference: [13] <author> J. Gray, </author> <title> A census of tandem system availability between 1985 and 1990, </title> <journal> IEEE Trans. on Reliability, </journal> <volume> Vol. 39, No. 4, </volume> <pages> pp. 409-418, </pages> <month> Oct. </month> <year> 1990. </year>
Reference: [14] <author> J. Gray, </author> <title> Dependable systems. Keynote Speech, </title> <booktitle> 11th Symp. on Reliable Distr. Syst., </booktitle> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: Unlike the recovery block approach [3] and N-version programming [18] which both use different programs to execute on the same set of data, the above on-line retry approach <ref> [14, 19] </ref> uses the same program to operate on a different but consistent set of data [20] obtained through message reordering. Based on our experience with telecommunications software systems, the technique of execution retry with rollback and message replaying has demonstrated its usefulness for bypassing the so-called software boundary errors.
Reference: [15] <author> M. Sullivan and R. Chillarege, </author> <title> Software defects and their impact on system availability A study of field failures in operating systems, </title> <booktitle> in Proc. IEEE Fault-Tolerant Computing Symposium, </booktitle> <pages> pp. 2-9, </pages> <year> 1991. </year>
Reference-contexts: The boundary code is often not well tested due to the difficulty in creating such boundary conditions in a test environment <ref> [15] </ref>. It has been shown that the possibility of software errors in the boundary code, called software boundary errors, can be significantly higher than that in the main routine [15]. <p> The boundary code is often not well tested due to the difficulty in creating such boundary conditions in a test environment <ref> [15] </ref>. It has been shown that the possibility of software errors in the boundary code, called software boundary errors, can be significantly higher than that in the main routine [15]. These kinds of software boundary errors may cause a catastrophic event such as the AT&T 4ESS switching system failure in January 1990 [21].
Reference: [16] <author> D. Jewett, </author> <title> Integrity S2: A fault-tolerant UNIX platform, </title> <booktitle> in Proc. IEEE Fault-Tolerant Computing Symposium, </booktitle> <pages> pp. 512-519, </pages> <year> 1991. </year>
Reference: [17] <author> Y. M. Wang and W. K. Fuchs, </author> <title> Scheduling message processing for reducing rollback propagation, </title> <booktitle> in Proc. IEEE Fault-Tolerant Computing Symposium, </booktitle> <pages> pp. 204-211, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Instead of proposing another checkpointing and recovery protocol, this paper investigates the possibility of applying the log-based techniques to recovery from software errors [10, 13-16]. We previously proposed message reordering for changing the communication pattern at run-time in order to reduce the rollback distance for hardware failures <ref> [17] </ref>. In this paper, we demonstrate how message reordering can also provide an effective way of bypassing certain software faults. Fig. 1 illustrates the basic concept.
Reference: [18] <author> A. Avizienis, </author> <title> The N-version approach to fault-tolerant software, </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol. SE-11, No. 12, </volume> <pages> pp. 1491-1501, </pages> <month> Dec. </month> <year> 1985. </year>
Reference-contexts: Unlike the recovery block approach [3] and N-version programming <ref> [18] </ref> which both use different programs to execute on the same set of data, the above on-line retry approach [14, 19] uses the same program to operate on a different but consistent set of data [20] obtained through message reordering.
Reference: [19] <author> J. Gray and D. P. </author> <title> Siewiorek, </title> <journal> High-availability computer systems, IEEE Computer Magazine, </journal> <pages> pp. 39-48, </pages> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: Unlike the recovery block approach [3] and N-version programming [18] which both use different programs to execute on the same set of data, the above on-line retry approach <ref> [14, 19] </ref> uses the same program to operate on a different but consistent set of data [20] obtained through message reordering. Based on our experience with telecommunications software systems, the technique of execution retry with rollback and message replaying has demonstrated its usefulness for bypassing the so-called software boundary errors.
Reference: [20] <author> P. E. Ammann and J. C. Knight, </author> <title> Data diversity: An approach to software fault-tolerance, </title> <booktitle> in Proc. IEEE Fault-Tolerant Computing Symposium, </booktitle> <pages> pp. 122-126, </pages> <year> 1987. </year>
Reference-contexts: Unlike the recovery block approach [3] and N-version programming [18] which both use different programs to execute on the same set of data, the above on-line retry approach [14, 19] uses the same program to operate on a different but consistent set of data <ref> [20] </ref> obtained through message reordering. Based on our experience with telecommunications software systems, the technique of execution retry with rollback and message replaying has demonstrated its usefulness for bypassing the so-called software boundary errors.
Reference: [21] <author> M. N. Meyers, </author> <title> The AT&T telephone network outage of Jan-uary 15, </title> <booktitle> 1990. Invited Talk at IEEE Fault-Tolerant Computing Symposium, </booktitle> <year> 1990. </year>
Reference-contexts: These kinds of software boundary errors may cause a catastrophic event such as the AT&T 4ESS switching system failure in January 1990 <ref> [21] </ref>. The fact that a software boundary condition usually occurs very rarely also suggests that if a boundary error does occur, then on-line retry by replaying and/or reordering the incoming messages may be helpful in bypassing the boundary condition.
Reference: [22] <author> M. Baker and M. Sullivan, </author> <title> The recovery box: Using fast recovery to provide high availability in the UNIX environment, </title> <booktitle> in Proc. Summer '92 USENIX, </booktitle> <pages> pp. 31-43, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: This can result in nondeterministic execution in a distributed message-passing environment and this nonde-terminism may result in bypassing the boundary condition. However, it is often desirable to limit the scope of rollback, the number of involved processes as well as total rollback distance, in order to achieve faster recovery <ref> [22] </ref>. It is possible that a small-scope rollback involving only a few processes suffices for successful retry. This motivates the progressive retry concept which progressively increases the scope of rollback to intentionally introduce more nondeter-minism when a previous retry fails.
Reference: [23] <author> Y. Huang and C. Kintala, </author> <title> Software implemented fault tolerance: Technologies and experience. </title> <note> To appear in Proc. IEEE Fault-Tolerant Computing Symposium, </note> <year> 1993. </year>
Reference-contexts: The objective of this paper is to describe and formalize the concept of progressive retry with message reordering to bypass software errors and to present a framework for implementation. The technique is being built into an existing fault tolerance library <ref> [23] </ref> in order to facilitate future software development. 2 Logical Checkpoints and Recovery Lines Let N be the number of processes in the system. Suppose p 1 in Fig. 2 initiates a rollback at the point marked X. <p> For a replicated file system, we have observed that Step 1 and Step 2 were able to recover from 90% of the software errors for the past six months. The techniques described are being implemented in the fault tolerance library libft which has been developed at AT&T Bell Laboratories <ref> [23] </ref>. Libft is a C library which supports N-version programming, recovery blocks, exception handling, message logging, and checkpointing and rollback recovery, and has been used by several AT&T products.
Reference: [24] <author> R. D. Schlichting and F. B. Schneider, </author> <title> Fail-stop processors: An approach to designing fault-tolerant computing systems, </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> Vol. 1, No. 3, </volume> <pages> pp. 222-238, </pages> <month> Aug. </month> <year> 1983. </year>
Reference-contexts: In other words, although p 1 physically rolls back to checkpoint C, it logically rolls back to the above logical checkpoint and therefore does not unsend M 1 . It then becomes clear that while 2 Here we assume fail-stop <ref> [24] </ref> failures only for the purpose of introducing logical checkpoints.
Reference: [25] <author> Y. M. Wang, A. Lowry, and W. K. Fuchs, </author> <title> Consistent global checkpoints based on direct dependencytracking. </title> <type> Research Report RC 18465, </type> <institution> IBM T.J. Watson Research Center, </institution> <address> York-town Heights, New York, </address> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: A consistent global checkpoint is a global checkpoint that does not contain any two checkpoints violating the above rollback propagation rule. The recovery line is the latest available consistent global checkpoint which uniquely minimizes the total rollback distance <ref> [25] </ref>. As an illustration, suppose all the messages in Fig. 2 (a) except for M 2 are logged when p 1 initiates the rollback. Fig. 2 (b) shows the dependency graph for the available logical checkpoints. <p> Direct dependency tracking <ref> [11, 25, 26] </ref>: only the dependency of the receiver's logical checkpoint on the sender's logical checkpoint resulting from each message processing is recorded, as opposed to the transitive dependency tracking which has been used in many log-based papers [10, 12].
Reference: [26] <author> Y. M. Wang, P. Y. Chung, I. J. Lin, and W. K. Fuchs, </author> <title> Checkpoint space reclamation for independent checkpointing in message-passing systems. </title> <type> Tech. Rep. </type> <institution> CRHC-92-06, Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, </institution> <year> 1992. </year>
Reference-contexts: Direct dependency tracking <ref> [11, 25, 26] </ref>: only the dependency of the receiver's logical checkpoint on the sender's logical checkpoint resulting from each message processing is recorded, as opposed to the transitive dependency tracking which has been used in many log-based papers [10, 12].
References-found: 26

