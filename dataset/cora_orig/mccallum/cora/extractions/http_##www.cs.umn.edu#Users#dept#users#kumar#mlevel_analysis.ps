URL: http://www.cs.umn.edu/Users/dept/users/kumar/mlevel_analysis.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Title: Analysis of Multilevel Graph Partitioning  
Author: George Karypis and Vipin Kumar 
Keyword: Multilevel Partitioning Methods, Fill Reducing Ordering, Numerical Linear Algebra.  
Address: Minneapolis, MN 55455  11:11am  
Affiliation: University of Minnesota, Department of Computer Science  at  
Pubnum: Technical Report: 95-037  
Email: fkarypis, kumarg@cs.umn.edu  
Date: Last updated on January 23, 1997  
Abstract: A short version of this paper appears in Supercomputing 1995 The algorithms described in this paper are implemented by the `METIS: Unstructured Graph Partitioning and Sparse Matrix Ordering System'. METIS is available on WWW at URL: http://www.cs.umn.edu/karypis/metis/metis.html Abstract Recently, a number of researchers have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity, and provide excellent graph partitions. However, there exists little theoretical analysis that could explain the ability of multilevel algorithms to produce good partitions. In this paper we present such an analysis. We show under certain reasonable assumptions that even if no refinement is used in the uncoarsening phase, a good bisection of the coarser graph is worse than a good bisection of the finer graph by at most a small factor. We also show that the size of a good vertex-separator of the coarse graph projected to the finer graph (without performing refinement in the uncoarsening phase) is higher than the size of a good vertex-separator of the finer graph by at most a small factor. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Stephen T. Barnard and Horst D. Simon. </author> <title> A fast multilevel implementation of recursive spectral bisection for partitioning unstructured problems. </title> <booktitle> In Proceedings of the sixth SIAM conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 711-718, </pages> <year> 1993. </year>
Reference-contexts: The MSB algorithm produces partitions that are as good as those produced by the original spectral bisection, but it is one to two orders of magnitude faster as it computes the Fiedler vector of the graph using a multilevel approach <ref> [28, 1] </ref>. Geometric partition methods [10, 11, 29, 22, 21, 23] are quite fast but they often provide worse partitions than those of more expensive methods such as spectral. Furthermore, geometric methods are applicable only if coordinate information for the graph is available. <p> Initial Partitioning Phase The second phase of a multilevel algorithm is to compute a balanced bisection of the coarsest graph G k D .V k ; E k /. In [14] we evaluated four different algorithms for partitioning the coarser graph. These are (a) spectral bisection (SB) <ref> [28, 1, 13] </ref>, (b) Kernighan-Lin bisection (KL) [16, 4], (c) breadth-first region growing (GGP) [5, 7], and (d) greedy region growing (GGGP) [14]. <p> graph partitioning and sparse matrix ordering algorithm. 2.1 Comparison with Other Partitioning and Ordering Schemes Despite the simplicity of the multilevel partitioning algorithm, it has been found to produce high quality partitions that are equally good or better than those produced by more sophisticated algorithms that require much more time <ref> [28, 1] </ref>. In [14] we presented an extensive comparison between our multilevel algorithm that uses the HEM matching scheme and other widely used schemes.
Reference: [2] <author> Timothy J. Barth. </author> <title> Aspects of unstructured grids and finite-volume solvers for the euler and navier-strokes equations. In AGARD Report 787 on Unstructured Grid Methods for Advection Dominated Flows, </title> <booktitle> pages 6.1-6.60, </booktitle> <year> 1992. </year>
Reference-contexts: Nevertheless, for these type of graphs it is known that fl D 2=3 [22] and that for most finite element applications d 0 ranges between 12 and 16 <ref> [2] </ref>. However, in order to apply Equation 3, we need to know the value of fi. Unlike maximally planar graphs, for which the average degree of successive coarser graphs remains the same, the average degree of 3D finite element graphs does not always remain the same. <p> Consider a 3D finite element mesh with tetrahedron elements. Let, 8 i be the number of tetrahedrons in graph G i . The number of interior vertices, edges, and tetrahedrons are related by Euler's formula <ref> [2] </ref> as follows jE i j D j8 i j C jV i j: (6) Let i i be the average number of triangular phases incident on an edge of graph G i .
Reference: [3] <author> T. Bui and C. Jones. </author> <title> A heuristic for reducing fill in sparse matrix factorization. </title> <booktitle> In 6th SIAM Conf. Parallel Processing for Scientific Computing, </booktitle> <pages> pages 445-452, </pages> <year> 1993. </year>
Reference-contexts: Furthermore, geometric methods are applicable only if coordinate information for the graph is available. Recently, a number of researches have investigated a class of algorithms that have moderate computational complexity, and provide excellent (even better than spectral) graph partitions <ref> [3, 13, 14] </ref>. The basic idea behind these algorithms is very simple. <p> Surprisingly, our scheme substantially outperforms the multiple minimum degree algorithm [19], which is the most commonly used method for computing fill reducing orderings of a sparse matrix. From the experiments presented in Section 2.1 and those of other researchers <ref> [3, 13] </ref>, it is clear that multilevel graph partitioning algorithms are able to find high quality partitions for a variety of unstructured graphs. However, there exists little theoretical analysis that could explain the ability of multilevel algorithms to produce good partitions. In this paper we present such an analysis. <p> Here we briefly describe two such matching schemes. The quality of the bisection for these two schemes is analyzed in Section 3. The first scheme, which we called random matching (RM), computes the maximal matching by using a randomized algorithm <ref> [3, 13] </ref>. The RM scheme works as follows. The vertices of the graph are visited in random order. If a vertex u has not been matched yet, then an unmatched adjacent vertex v is randomly selected and the edge .u; v/ is included in the matching.
Reference: [4] <author> C. M. Fiduccia and R. M. Mattheyses. </author> <title> A linear time heuristic for improving network partitions. </title> <booktitle> In In Proc. 19th IEEE Design Automation Conference, </booktitle> <pages> pages 175-181, </pages> <year> 1982. </year>
Reference-contexts: In [14] we evaluated four different algorithms for partitioning the coarser graph. These are (a) spectral bisection (SB) [28, 1, 13], (b) Kernighan-Lin bisection (KL) <ref> [16, 4] </ref>, (c) breadth-first region growing (GGP) [5, 7], and (d) greedy region growing (GGGP) [14]. <p> The sets A 0 and B 0 are usually constructed incrementally, and a number of algorithms have been proposed for their construction. A class of algorithms that tend to produce very good results are those that are based on the Kernighan-Lin partition algorithm <ref> [16, 4, 13] </ref>. These algorithms associate with each vertex v a quantity called gain which is the decrease (or increase) in the edge-cut if v is moved to the other part.
Reference: [5] <author> A. George and J. W.-H. Liu. </author> <title> Computer Solution of Large Sparse Positive Definite Systems. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1981. </year>
Reference-contexts: If parallel direct methods are used to solve a sparse system of equations, then a graph partitioning algorithm can be used to compute a fill reducing ordering that lead to high degree of concurrency in the factorization phase <ref> [17, 5] </ref>. The graph partitioning problem is NP-complete. However, many algorithms have been developed that find reasonably good partitions. Spectral methods [28, 27, 13] have been shown to be quite effective for partitioning unstructured problems in a variety of applications, but have very high computational complexity. <p> In [14] we evaluated four different algorithms for partitioning the coarser graph. These are (a) spectral bisection (SB) [28, 1, 13], (b) Kernighan-Lin bisection (KL) [16, 4], (c) breadth-first region growing (GGP) <ref> [5, 7] </ref>, and (d) greedy region growing (GGGP) [14]. <p> However, another even more important advantage of MLND over MMD, is that it produces orderings that exhibit significantly more concurrency than MMD. The elimination trees produced by MMD exhibit little concurrency (long and slender), and are unbalanced so that subtree-to-subcube mappings lead to significant load imbalances <ref> [17, 5, 8] </ref>. One the other hand, orderings based on nested dissection produce elimination trees that have both more concurrency and better balance [15, 9].
Reference: [6] <author> A. George and J. W.-H. Liu. </author> <title> The evolution of the minimum degree ordering algorithm. </title> <journal> SIAM Review, </journal> <volume> 31(1) </volume> <pages> 1-19, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: The multilevel graph partitioning algorithm can be used to find a fill reducing ordering for a symmetric sparse matrix via recursive nested dissection. Figure 3 shows the quality of our multilevel nested dissection ordering algorithm (MLND) compared to the multiple minimum degree (MMD) <ref> [6, 19] </ref>, and spectral nested dissection (SND) [26]. These graphs were produced by dividing the number of operations required to factor a matrix using MLND and SND to the number of operations required by MMD.
Reference: [7] <author> T. Goehring and Y. Saad. </author> <title> Heuristic algorithms for automatic graph partitioning. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, </institution> <year> 1994. </year>
Reference-contexts: In [14] we evaluated four different algorithms for partitioning the coarser graph. These are (a) spectral bisection (SB) [28, 1, 13], (b) Kernighan-Lin bisection (KL) [16, 4], (c) breadth-first region growing (GGP) <ref> [5, 7] </ref>, and (d) greedy region growing (GGGP) [14].
Reference: [8] <author> Anshul Gupta, George Karypis, and Vipin Kumar. </author> <title> Highly scalable parallel algorithms for sparse matrix factorization. </title> <type> Technical Report 94-63, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN, </institution> <year> 1994. </year> <note> Submitted for publication in IEEE Transactions on Parallel and Distributed Computing. Available on WWW at URL http://www.cs.umn.edu/karypis/papers/sparse-cholesky.ps. 17 </note>
Reference-contexts: However, another even more important advantage of MLND over MMD, is that it produces orderings that exhibit significantly more concurrency than MMD. The elimination trees produced by MMD exhibit little concurrency (long and slender), and are unbalanced so that subtree-to-subcube mappings lead to significant load imbalances <ref> [17, 5, 8] </ref>. One the other hand, orderings based on nested dissection produce elimination trees that have both more concurrency and better balance [15, 9].
Reference: [9] <author> M. T. Heath, E. G.-Y. Ng, and Barry W. Peyton. </author> <title> Parallel algorithms for sparse linear systems. </title> <journal> SIAM Review, </journal> <volume> 33 </volume> <pages> 420-460, </pages> <year> 1991. </year> <note> Also appears in K. </note> <author> A. Gallivan et al. </author> <title> Parallel Algorithms for Matrix Computations. </title> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <year> 1990. </year>
Reference-contexts: MMD has been found to produce very good orderings and is widely used to order sparse matrices for factorization on serial computers, while SND is used to order sparse matrices for factorization on parallel computers because it produces orderings with balanced elimination trees <ref> [15, 9] </ref>. From this figure we see that compared against MMD, our algorithm produces better orderings for 10 out of the 13 matrices, and compared against SND, it produces better ordering for all 13 matrices. <p> The elimination trees produced by MMD exhibit little concurrency (long and slender), and are unbalanced so that subtree-to-subcube mappings lead to significant load imbalances [17, 5, 8]. One the other hand, orderings based on nested dissection produce elimination trees that have both more concurrency and better balance <ref> [15, 9] </ref>.
Reference: [10] <author> M. T. Heath and P. Raghavan. </author> <title> A Cartesian nested dissection algorithm. </title> <type> Technical Report UIUCDCS-R-92-1772, </type> <institution> Department of Computer Science, University of Illinois, Urbana, </institution> <address> IL 61801, </address> <year> 1992. </year> <note> To appear in SIAM Journal on Matrix Analysis and Applications, </note> <year> 1994. </year>
Reference-contexts: The MSB algorithm produces partitions that are as good as those produced by the original spectral bisection, but it is one to two orders of magnitude faster as it computes the Fiedler vector of the graph using a multilevel approach [28, 1]. Geometric partition methods <ref> [10, 11, 29, 22, 21, 23] </ref> are quite fast but they often provide worse partitions than those of more expensive methods such as spectral. Furthermore, geometric methods are applicable only if coordinate information for the graph is available.
Reference: [11] <author> M. T. Heath and Padma Raghavan. </author> <title> A Cartesian parallel nested dissection algorithm. </title> <type> Technical Report 92-1772, </type> <institution> Department of Computer Science, University of Illinois, Urbana, IL, </institution> <year> 1992. </year> <note> To appear in SIAM Journal on Matrix Analysis and Applications, </note> <year> 1994. </year>
Reference-contexts: The MSB algorithm produces partitions that are as good as those produced by the original spectral bisection, but it is one to two orders of magnitude faster as it computes the Fiedler vector of the graph using a multilevel approach [28, 1]. Geometric partition methods <ref> [10, 11, 29, 22, 21, 23] </ref> are quite fast but they often provide worse partitions than those of more expensive methods such as spectral. Furthermore, geometric methods are applicable only if coordinate information for the graph is available.
Reference: [12] <author> Bruce Hendrickson and Rober Leland. </author> <title> The chaco user's guide, version 1.0. </title> <type> Technical Report SAND93-2339, </type> <institution> Sandia National Laboratories, </institution> <year> 1993. </year>
Reference: [13] <author> Bruce Hendrickson and Rober Leland. </author> <title> A multilevel algorithm for partitioning graphs. </title> <type> Technical Report SAND93-1301, </type> <institution> Sandia National Laboratories, </institution> <year> 1993. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find reasonably good partitions. Spectral methods <ref> [28, 27, 13] </ref> have been shown to be quite effective for partitioning unstructured problems in a variety of applications, but have very high computational complexity. <p> Furthermore, geometric methods are applicable only if coordinate information for the graph is available. Recently, a number of researches have investigated a class of algorithms that have moderate computational complexity, and provide excellent (even better than spectral) graph partitions <ref> [3, 13, 14] </ref>. The basic idea behind these algorithms is very simple. <p> Surprisingly, our scheme substantially outperforms the multiple minimum degree algorithm [19], which is the most commonly used method for computing fill reducing orderings of a sparse matrix. From the experiments presented in Section 2.1 and those of other researchers <ref> [3, 13] </ref>, it is clear that multilevel graph partitioning algorithms are able to find high quality partitions for a variety of unstructured graphs. However, there exists little theoretical analysis that could explain the ability of multilevel algorithms to produce good partitions. In this paper we present such an analysis. <p> Here we briefly describe two such matching schemes. The quality of the bisection for these two schemes is analyzed in Section 3. The first scheme, which we called random matching (RM), computes the maximal matching by using a randomized algorithm <ref> [3, 13] </ref>. The RM scheme works as follows. The vertices of the graph are visited in random order. If a vertex u has not been matched yet, then an unmatched adjacent vertex v is randomly selected and the edge .u; v/ is included in the matching. <p> Initial Partitioning Phase The second phase of a multilevel algorithm is to compute a balanced bisection of the coarsest graph G k D .V k ; E k /. In [14] we evaluated four different algorithms for partitioning the coarser graph. These are (a) spectral bisection (SB) <ref> [28, 1, 13] </ref>, (b) Kernighan-Lin bisection (KL) [16, 4], (c) breadth-first region growing (GGP) [5, 7], and (d) greedy region growing (GGGP) [14]. <p> The sets A 0 and B 0 are usually constructed incrementally, and a number of algorithms have been proposed for their construction. A class of algorithms that tend to produce very good results are those that are based on the Kernighan-Lin partition algorithm <ref> [16, 4, 13] </ref>. These algorithms associate with each vertex v a quantity called gain which is the decrease (or increase) in the edge-cut if v is moved to the other part.
Reference: [14] <author> G. Karypis and V. Kumar. </author> <title> A fast and high quality multilevel scheme for partitioning irregular graphs. </title> <type> Technical Report TR 95-035, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/karypis/papers/mlevel serial.ps. A short version appears in Intl. Conf. on Parallel Processing 1995. </note>
Reference-contexts: Furthermore, geometric methods are applicable only if coordinate information for the graph is available. Recently, a number of researches have investigated a class of algorithms that have moderate computational complexity, and provide excellent (even better than spectral) graph partitions <ref> [3, 13, 14] </ref>. The basic idea behind these algorithms is very simple. <p> Since the finer graph has more degrees of freedom, such refinements usually decrease the edge-cut. This process, is graphically illustrated in Figure 1. These are called multilevel graph partitioning schemes. In particular, in <ref> [14] </ref> we have developed a multilevel graph partitioning scheme that produces high quality partitions that perform consistently better than the spectral methods, while requiring significantly less time (10 to 30 times less) than even multilevel spectral bisection. <p> We also used our multilevel graph partitioning scheme to compute fill reducing orderings for sparse matrices <ref> [14] </ref>. Surprisingly, our scheme substantially outperforms the multiple minimum degree algorithm [19], which is the most commonly used method for computing fill reducing orderings of a sparse matrix. <p> The rest of the paper is organized as follows. Section 2 briefly describes the multilevel graph bisection algorithm and summarizes experimental performance results from <ref> [14] </ref>. Section 3 analyzes the bisections and vertex-separators produced by the multilevel algorithm, and presents supporting experiments. Section 4 provides some concluding remarks. 2 Multilevel Graph Bisection In this section we briefly describe the various phases of the multilevel algorithm. The reader should refer to [14] for further details. <p> summarizes experimental performance results from <ref> [14] </ref>. Section 3 analyzes the bisections and vertex-separators produced by the multilevel algorithm, and presents supporting experiments. Section 4 provides some concluding remarks. 2 Multilevel Graph Bisection In this section we briefly describe the various phases of the multilevel algorithm. The reader should refer to [14] for further details. Coarsening Phase During the coarsening phase, a sequence of smaller graphs G i D .V i ; E i /, is constructed from the original graph G 0 D .V 0 ; E 0 / such that jV i j &gt; jV iC1 j. <p> A vertex in a graph G i is call multinode if it contains more than one vertex of G 0 . Maximal matchings can be computed in different ways <ref> [14] </ref>. The method used to compute the matching greatly affects both the quality of the bisection, and the time required during the uncoarsening phase. Here we briefly describe two such matching schemes. The quality of the bisection for these two schemes is analyzed in Section 3. <p> As a result, the HEM scheme reduces the sum of the weights of the edges in the coarser graph by a larger amount than RM. In <ref> [14] </ref>, we experimentally evaluated both the RM and HEM matching schemes, and we found that the HEM scheme produces consistently better results than RM, and the amount of time spent in refinement is less than that of RM. <p> Initial Partitioning Phase The second phase of a multilevel algorithm is to compute a balanced bisection of the coarsest graph G k D .V k ; E k /. In <ref> [14] </ref> we evaluated four different algorithms for partitioning the coarser graph. These are (a) spectral bisection (SB) [28, 1, 13], (b) Kernighan-Lin bisection (KL) [16, 4], (c) breadth-first region growing (GGP) [5, 7], and (d) greedy region growing (GGGP) [14]. <p> In <ref> [14] </ref> we evaluated four different algorithms for partitioning the coarser graph. These are (a) spectral bisection (SB) [28, 1, 13], (b) Kernighan-Lin bisection (KL) [16, 4], (c) breadth-first region growing (GGP) [5, 7], and (d) greedy region growing (GGGP) [14]. <p> These algorithms proceed by repeatedly selecting vertices with the highest gains from each part, inserting them into A 0 and B 0 , and updating the gains of the remaining vertices. In <ref> [14] </ref> we evaluated four different refinement algorithms that belong to this class and we found that some of them are both effective in reducing the edge-cut and also require very little time. <p> In <ref> [14] </ref> we presented an extensive comparison between our multilevel algorithm that uses the HEM matching scheme and other widely used schemes. In this section we briefly summarize these results for the matrices in Table 1. the edge-cut of our multilevel algorithm to the edge-cut of the MSB algorithm. <p> In some cases, 4 the improvement is as high as 70%. Furthermore, the time required by our multilevel algorithm is significantly smaller than that required by MSB. Our algorithm is usually 10 times faster for small problems, and 15 to 35 times faster for larger problems <ref> [14] </ref>. the cut-size of our multilevel algorithm to that of the MSB algorithm is plotted for 64-, 128- and 256-way partitions. Bars under the baseline indicate that the multilevel algorithm performs better. <p> The two of them, labeled RM and HEM, correspond to random matching and heavy-edge matching with no refinement during the uncoarsening phase, while the one labeled HEM-R, corresponds to heavy-edge with boundary greedy refinement <ref> [14] </ref>. From this graph, we see that at successive uncoarsening levels, the size of the separator increases by a factor smaller than 2.
Reference: [15] <author> George Karypis, Anshul Gupta, and Vipin Kumar. </author> <title> A parallel formulation of interior point algorithms. </title> <booktitle> In Supercomputing 94, </booktitle> <year> 1994. </year> <note> Available on WWW at URL http://www.cs.umn.edu/karypis/papers/interior-point.ps. </note>
Reference-contexts: MMD has been found to produce very good orderings and is widely used to order sparse matrices for factorization on serial computers, while SND is used to order sparse matrices for factorization on parallel computers because it produces orderings with balanced elimination trees <ref> [15, 9] </ref>. From this figure we see that compared against MMD, our algorithm produces better orderings for 10 out of the 13 matrices, and compared against SND, it produces better ordering for all 13 matrices. <p> The elimination trees produced by MMD exhibit little concurrency (long and slender), and are unbalanced so that subtree-to-subcube mappings lead to significant load imbalances [17, 5, 8]. One the other hand, orderings based on nested dissection produce elimination trees that have both more concurrency and better balance <ref> [15, 9] </ref>.
Reference: [16] <author> B. W. Kernighan and S. Lin. </author> <title> An efficient heuristic procedure for partitioning graphs. </title> <journal> The Bell System Technical Journal, </journal> <year> 1970. </year>
Reference-contexts: In [14] we evaluated four different algorithms for partitioning the coarser graph. These are (a) spectral bisection (SB) [28, 1, 13], (b) Kernighan-Lin bisection (KL) <ref> [16, 4] </ref>, (c) breadth-first region growing (GGP) [5, 7], and (d) greedy region growing (GGGP) [14]. <p> The sets A 0 and B 0 are usually constructed incrementally, and a number of algorithms have been proposed for their construction. A class of algorithms that tend to produce very good results are those that are based on the Kernighan-Lin partition algorithm <ref> [16, 4, 13] </ref>. These algorithms associate with each vertex v a quantity called gain which is the decrease (or increase) in the edge-cut if v is moved to the other part.
Reference: [17] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <publisher> Benjamin/Cummings Publishing Company, </publisher> <address> Redwood City, CA, </address> <year> 1994. </year>
Reference-contexts: Access to computing facilities was provided by AHPCRC, Minnesota Supercomputer Institute, Cray Research Inc, and by the Pittsburgh Supercomputing Center. Related papers are available via WWW at URL: http://www.cs.umn.edu/karypis 1 to the matrix A <ref> [17] </ref>. If parallel direct methods are used to solve a sparse system of equations, then a graph partitioning algorithm can be used to compute a fill reducing ordering that lead to high degree of concurrency in the factorization phase [17, 5]. The graph partitioning problem is NP-complete. <p> If parallel direct methods are used to solve a sparse system of equations, then a graph partitioning algorithm can be used to compute a fill reducing ordering that lead to high degree of concurrency in the factorization phase <ref> [17, 5] </ref>. The graph partitioning problem is NP-complete. However, many algorithms have been developed that find reasonably good partitions. Spectral methods [28, 27, 13] have been shown to be quite effective for partitioning unstructured problems in a variety of applications, but have very high computational complexity. <p> However, another even more important advantage of MLND over MMD, is that it produces orderings that exhibit significantly more concurrency than MMD. The elimination trees produced by MMD exhibit little concurrency (long and slender), and are unbalanced so that subtree-to-subcube mappings lead to significant load imbalances <ref> [17, 5, 8] </ref>. One the other hand, orderings based on nested dissection produce elimination trees that have both more concurrency and better balance [15, 9].
Reference: [18] <author> R. J. Lipton and R. E. Tarjan. </author> <title> A separator theorem for planar graphs. </title> <journal> SIAM Journal on Applied Mathematics, </journal> <volume> 36 </volume> <pages> 177-189, </pages> <year> 1979. </year>
Reference-contexts: In the case of graphs arising in finite element applications, the small separator assumption is true. In particular, for planar graphs fl D 0:5 <ref> [18] </ref>, and for the graphs that correspond to 3D finite element meshes, fl D 2=3 [22]. Assumption 2 follows directly from Assumption 1 and corresponds to the bisection in which the separator is the boundary of one of the two parts. <p> For the rest of this section we use this correspondence and we only concentrate on maximally planar graphs. Planar graphs have been extensively studied and a great deal of properties are known about them. In particular, for maximally planar graphs fl D 0:5 <ref> [18] </ref>, and d 0 6. Also, in [18] it was shown that edge contraction also preserves maximal planarity; thus, fi D 1. <p> Planar graphs have been extensively studied and a great deal of properties are known about them. In particular, for maximally planar graphs fl D 0:5 <ref> [18] </ref>, and d 0 6. Also, in [18] it was shown that edge contraction also preserves maximal planarity; thus, fi D 1. From Equation 3, and for RM (i.e., ffi D 1), we have that C 2DRM i1 D 1:18 i C 0 (4) Thus, the edge-cut increases only by 18% at each successive coarsening level. <p> Consider the kth level coarse graph G k D .V k ; E k /. From the small separator assumption, we know that G k has a separator S k that contains no more than ff p jV k j vertices (recall that fl D 0:5 for planar graphs <ref> [18] </ref>). Let S 0 0 be the union of the vertices of S k projected to G 0 .
Reference: [19] <author> J. W.-H. Liu. </author> <title> Modification of the minimum degree algorithm by multiple elimination. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 11 </volume> <pages> 141-153, </pages> <year> 1985. </year>
Reference-contexts: We also used our multilevel graph partitioning scheme to compute fill reducing orderings for sparse matrices [14]. Surprisingly, our scheme substantially outperforms the multiple minimum degree algorithm <ref> [19] </ref>, which is the most commonly used method for computing fill reducing orderings of a sparse matrix. <p> The multilevel graph partitioning algorithm can be used to find a fill reducing ordering for a symmetric sparse matrix via recursive nested dissection. Figure 3 shows the quality of our multilevel nested dissection ordering algorithm (MLND) compared to the multiple minimum degree (MMD) <ref> [6, 19] </ref>, and spectral nested dissection (SND) [26]. These graphs were produced by dividing the number of operations required to factor a matrix using MLND and SND to the number of operations required by MMD.
Reference: [20] <author> G. L. Miller. </author> <title> Finding small simple cycle separators for 2-connected plnar graphs. </title> <journal> Journal of Computer and system Sciences, </journal> <volume> 32(3) </volume> <pages> 265-279, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: This analysis is focused on maximal planar graphs that satisfy the assumptions in Section 3. Furthermore, it is assumed that the separator forms a simple path or cycle <ref> [20] </ref>. This analysis can be extended to the graphs that correspond to 3D finite element meshes, when the separators are simple surfaces. Consider the kth level coarse graph G k D .V k ; E k /.
Reference: [21] <author> Gary L. Miller, Shang-Hua Teng, W. Thurston, and Stephen A. Vavasis. </author> <title> Automatic mesh partitioning. </title> <editor> In A. George, John R. Gilbert, and J. W.- H. Liu, editors, </editor> <title> Sparse Matrix Computations: Graph Theory Issues and Algorithms. (An IMA Workshop Volume). </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: The MSB algorithm produces partitions that are as good as those produced by the original spectral bisection, but it is one to two orders of magnitude faster as it computes the Fiedler vector of the graph using a multilevel approach [28, 1]. Geometric partition methods <ref> [10, 11, 29, 22, 21, 23] </ref> are quite fast but they often provide worse partitions than those of more expensive methods such as spectral. Furthermore, geometric methods are applicable only if coordinate information for the graph is available.
Reference: [22] <author> Gary L. Miller, Shang-Hua Teng, and Stephen A. Vavasis. </author> <title> A unified geometric approach to graph separators. </title> <booktitle> In Proceedings of 31st Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 538-547, </pages> <year> 1991. </year>
Reference-contexts: The MSB algorithm produces partitions that are as good as those produced by the original spectral bisection, but it is one to two orders of magnitude faster as it computes the Fiedler vector of the graph using a multilevel approach [28, 1]. Geometric partition methods <ref> [10, 11, 29, 22, 21, 23] </ref> are quite fast but they often provide worse partitions than those of more expensive methods such as spectral. Furthermore, geometric methods are applicable only if coordinate information for the graph is available. <p> In the case of graphs arising in finite element applications, the small separator assumption is true. In particular, for planar graphs fl D 0:5 [18], and for the graphs that correspond to 3D finite element meshes, fl D 2=3 <ref> [22] </ref>. Assumption 2 follows directly from Assumption 1 and corresponds to the bisection in which the separator is the boundary of one of the two parts. <p> Nevertheless, for these type of graphs it is known that fl D 2=3 <ref> [22] </ref> and that for most finite element applications d 0 ranges between 12 and 16 [2]. However, in order to apply Equation 3, we need to know the value of fi.
Reference: [23] <author> B. Nour-Omid, A. Raefsky, and G. Lyzenga. </author> <title> Solving finite element equations on concurrent computers. </title> <editor> In A. K. Noor, editor, </editor> <publisher> American Soc. Mech. Eng, </publisher> <pages> pages 291-307, </pages> <year> 1986. </year>
Reference-contexts: The MSB algorithm produces partitions that are as good as those produced by the original spectral bisection, but it is one to two orders of magnitude faster as it computes the Fiedler vector of the graph using a multilevel approach [28, 1]. Geometric partition methods <ref> [10, 11, 29, 22, 21, 23] </ref> are quite fast but they often provide worse partitions than those of more expensive methods such as spectral. Furthermore, geometric methods are applicable only if coordinate information for the graph is available.
Reference: [24] <author> Christos H. Papadimitriou and Kenneth Steiglitz. </author> <title> Combinatorial Optimization. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: These graphs were produced by dividing the number of operations required to factor a matrix using MLND and SND to the number of operations required by MMD. For both MLND and SND, a vertex separator is computed from an edge separator by finding the minimum vertex cover <ref> [24, 25] </ref>. MMD has been found to produce very good orderings and is widely used to order sparse matrices for factorization on serial computers, while SND is used to order sparse matrices for factorization on parallel computers because it produces orderings with balanced elimination trees [15, 9].
Reference: [25] <author> A. Pothen and C-J. Fan. </author> <title> Computing the block triangular form of a sparse matrix. </title> <journal> ACM Transactions on Mathematical Software, </journal> <year> 1990. </year>
Reference-contexts: These graphs were produced by dividing the number of operations required to factor a matrix using MLND and SND to the number of operations required by MMD. For both MLND and SND, a vertex separator is computed from an edge separator by finding the minimum vertex cover <ref> [24, 25] </ref>. MMD has been found to produce very good orderings and is widely used to order sparse matrices for factorization on serial computers, while SND is used to order sparse matrices for factorization on parallel computers because it produces orderings with balanced elimination trees [15, 9].
Reference: [26] <author> Alex Pothen, H. D. Simon, and Lie Wang. </author> <title> Spectral nested dissection. </title> <type> Technical Report 92-01, </type> <institution> Computer Science Department, Pennsylvania State University, University Park, </institution> <address> PA, </address> <year> 1992. </year>
Reference-contexts: Figure 3 shows the quality of our multilevel nested dissection ordering algorithm (MLND) compared to the multiple minimum degree (MMD) [6, 19], and spectral nested dissection (SND) <ref> [26] </ref>. These graphs were produced by dividing the number of operations required to factor a matrix using MLND and SND to the number of operations required by MMD. For both MLND and SND, a vertex separator is computed from an edge separator by finding the minimum vertex cover [24, 25].
Reference: [27] <author> Alex Pothen, H. D. Simon, Lie Wang, and Stephen T. Bernard. </author> <title> Towards a fast implementation of spectral nested dissection. </title> <booktitle> In Supercomputing '92 Proceedings, </booktitle> <pages> pages 42-51, </pages> <year> 1992. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find reasonably good partitions. Spectral methods <ref> [28, 27, 13] </ref> have been shown to be quite effective for partitioning unstructured problems in a variety of applications, but have very high computational complexity.
Reference: [28] <author> Alex Pothen, Horst D. Simon, and Kang-Pu Liou. </author> <title> Partitioning sparse matrices with eigenvectors of graphs. </title> <journal> SIAM Journal of Matrix Analysis and Applications, </journal> <volume> 11(3) </volume> <pages> 430-452, </pages> <year> 1990. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find reasonably good partitions. Spectral methods <ref> [28, 27, 13] </ref> have been shown to be quite effective for partitioning unstructured problems in a variety of applications, but have very high computational complexity. <p> The MSB algorithm produces partitions that are as good as those produced by the original spectral bisection, but it is one to two orders of magnitude faster as it computes the Fiedler vector of the graph using a multilevel approach <ref> [28, 1] </ref>. Geometric partition methods [10, 11, 29, 22, 21, 23] are quite fast but they often provide worse partitions than those of more expensive methods such as spectral. Furthermore, geometric methods are applicable only if coordinate information for the graph is available. <p> Initial Partitioning Phase The second phase of a multilevel algorithm is to compute a balanced bisection of the coarsest graph G k D .V k ; E k /. In [14] we evaluated four different algorithms for partitioning the coarser graph. These are (a) spectral bisection (SB) <ref> [28, 1, 13] </ref>, (b) Kernighan-Lin bisection (KL) [16, 4], (c) breadth-first region growing (GGP) [5, 7], and (d) greedy region growing (GGGP) [14]. <p> graph partitioning and sparse matrix ordering algorithm. 2.1 Comparison with Other Partitioning and Ordering Schemes Despite the simplicity of the multilevel partitioning algorithm, it has been found to produce high quality partitions that are equally good or better than those produced by more sophisticated algorithms that require much more time <ref> [28, 1] </ref>. In [14] we presented an extensive comparison between our multilevel algorithm that uses the HEM matching scheme and other widely used schemes.
Reference: [29] <author> P. Raghavan. </author> <title> Line and plane separators. </title> <type> Technical Report UIUCDCS-R-93-1794, </type> <institution> Department of Computer Science, University of Illinois, Urbana, </institution> <address> IL 61801, </address> <month> February </month> <year> 1993. </year> <month> 18 </month>
Reference-contexts: The MSB algorithm produces partitions that are as good as those produced by the original spectral bisection, but it is one to two orders of magnitude faster as it computes the Fiedler vector of the graph using a multilevel approach [28, 1]. Geometric partition methods <ref> [10, 11, 29, 22, 21, 23] </ref> are quite fast but they often provide worse partitions than those of more expensive methods such as spectral. Furthermore, geometric methods are applicable only if coordinate information for the graph is available.
References-found: 29

