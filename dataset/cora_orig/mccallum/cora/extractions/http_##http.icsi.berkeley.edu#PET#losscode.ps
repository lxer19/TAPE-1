URL: http://http.icsi.berkeley.edu/PET/losscode.ps
Refering-URL: http://http.icsi.berkeley.edu/PET/nsf-index.html
Root-URL: http://http.icsi.berkeley.edu
Title: Practical Loss-Resilient Codes  
Author: Michael G. Luby Michael Mitzenmacher M. Amin Shokrollahi Daniel A. Spielman Volker Stemann 
Note: CA. A substantial portion of this research done while at the  under the National Science Foundation grant No. CCR-9505448.  Research supported by a Habilita-tionsstipendium of the Deutsche Forschungsgemeinschaft, Grant Sh 57/11. Department of Mathematics, M.I.T. Supported by an NSF mathematical sciences postdoc. A substantial portion of this research done while visiting  Research done while at the International  
Address: Palo Alto,  Berkeley.  
Affiliation: Digital Equipment Corporation, Systems Research Center,  Computer Science Department, UC Berkeley,  International Computer Science Institute Berkeley, and Institut fur In-formatik der Universitat Bonn, Germany.  U.C.  Computer Science Institute.  
Abstract: We present randomized constructions of linear-time en-codable and decodable codes that can transmit over lossy channels at rates extremely close to capacity. The encoding and decoding algorithms for these codes have fast and simple software implementations. Partial implementations of our algorithms are faster by orders of magnitude than the best software implementations of any previous algorithm for this problem. We expect these codes will be extremely useful for applications such as real-time audio and video transmission over the Internet, where lossy channels are common and fast decoding is a requirement. Despite the simplicity of the algorithms, their design and analysis are mathematically intricate. The design requires the careful choice of a random irregular bipartite graph, where the structure of the irregular graph is extremely important. We model the progress of the decoding algorithm by a set of differential equations. The solution to these equations can then be expressed as polynomials in one variable fl Digital Equipment Corporation, Systems Research Center, Palo Alto, CA, and Computer Science Division, University of California at Berkeley. A substantial portion of this research done while at the International Computer Science Institute. Research supported in part by National Science Foundation operating grant NCR-9416101, and United States-Israel Binational Science Foundation grant No. 92-00226. with coefficients determined by the graph structure. Based on these polynomials, we design a graph structure that guarantees successful decoding with high probability. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Albanese, J. Blomer, J. Edmonds, M. Luby, M. Sudan, </author> <title> Priority Encoding Transmission, </title> <journal> IEEE Transactions on Information Theory (special issue devoted to coding theory), </journal> <volume> Vol. 42, No. 6, </volume> <month> November </month> <year> 1996, </year> <pages> pp. 17371744. </pages>
Reference-contexts: Such a scheme can be used as the ba-sic building block for the more robust and general protection scheme described in <ref> [1] </ref>. To demonstrate the benefits of forward error-correction in a simplified setting, consider the Internet loss measurements performed by [14] involving a multicast by one sender to a number of geographically distributed receivers. <p> One can use the results of <ref> [1] </ref> to simultaneously protect against various levels of loss while still keeping the overall redundancy modest. and quadratic decoding time. These codes have recently been customized to compensate for Internet packet loss in real-time transmission of moderate-quality video [1]. Even this optimized implementation required the use of dedicated workstations. <p> One can use the results of <ref> [1] </ref> to simultaneously protect against various levels of loss while still keeping the overall redundancy modest. and quadratic decoding time. These codes have recently been customized to compensate for Internet packet loss in real-time transmission of moderate-quality video [1]. Even this optimized implementation required the use of dedicated workstations. Transmission of significantly higher quality video requires faster coding algorithms. In theory, it is possible to decode Reed-Solomon codes in time O (n log 2 n log log n) (see, [4, Chapter 11.7] and [9, p. 369]).
Reference: [2] <author> N. Alon, J. Edmonds, M. Luby, </author> <title> Linear Time Erasure Codes With Nearly Optimal Recovery, </title> <booktitle> Proc. of the 36 th Annual Symp. on Foundations of Computer Science, </booktitle> <year> 1995, </year> <pages> pp. 512-519. </pages>
Reference-contexts: They can also be encoded in time proportional to n ln (1=*). In Section 7, we do this for all * &gt; 0. The fastest previously known encoding and decoding algorithms <ref> [2] </ref> with such a performance guarantee have run times proportional to n ln (1=*)=*. (See also [3] for related work.) The overall structure of our codes are related to codes introduced in [13] for error-correction.
Reference: [3] <author> N. Alon, M. Luby, </author> <title> A Linear Time Erasure-Resilient Code With Nearly Optimal Recovery, </title> <journal> IEEE Transactions on Information Theory (special issue devoted to coding theory), </journal> <volume> Vol. 42, No. 6, </volume> <month> November </month> <year> 1996, </year> <pages> pp. 17321736. </pages>
Reference-contexts: They can also be encoded in time proportional to n ln (1=*). In Section 7, we do this for all * &gt; 0. The fastest previously known encoding and decoding algorithms [2] with such a performance guarantee have run times proportional to n ln (1=*)=*. (See also <ref> [3] </ref> for related work.) The overall structure of our codes are related to codes introduced in [13] for error-correction. We explain the general construction along with the encoding and decoding al gorithms in Section 2. Our encoding and decoding algorithms are almost symmetrical.
Reference: [4] <author> R. E. Blahut, </author> <title> Theory and Practice of Error Control Codes, </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1983. </year>
Reference-contexts: Even this optimized implementation required the use of dedicated workstations. Transmission of significantly higher quality video requires faster coding algorithms. In theory, it is possible to decode Reed-Solomon codes in time O (n log 2 n log log n) (see, <ref> [4, Chapter 11.7] </ref> and [9, p. 369]).
Reference: [5] <author> A. Broder, A. Frieze, E. Upfal, </author> <title> `On the Satisfiability and Maximum Satisfiability of Random 3-CNF Formulas, </title> <booktitle> Proc. of the 4 th ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <year> 1993, </year> <pages> pp. 322-330. </pages>
Reference-contexts: The following combinatorial tail argument is useful in showing that the process terminates successfully when there are no nodes on the left of degree one or two. (Such arguments are often required in similar situations; see, for example, <ref> [5] </ref>.) Lemma 3 Let B be a bipartite graph chosen at random with edge-degrees specified by (x) and ae (x), such that (x) has 1 = 2 = 0.
Reference: [6] <author> P. Elias, </author> <title> Coding for Two Noisy Channels Information Theory, </title> <booktitle> Third London Symposium, </booktitle> <address> September 1955, </address> <publisher> Butter-sworth's Scientific Publications, </publisher> <pages> pp. 61-76. </pages>
Reference-contexts: We assume that the receiver knows the position of each received symbol within the stream of all encoding symbols. This is appropriate for the Internet, where packets are indexed. We adopt as our model of losses the erasure channel, introduced by Elias <ref> [6] </ref>, in which each encoding symbol is lost with a fixed constant probability p in transit independent of all the other symbols. This assumption is not appropriate for the Internet, where losses can be highly correlated and bursty. <p> However, losses on the Internet in general are not sensitive to the actual contents of each packet, and thus if we place the encoding into the packets in a random order then the independent loss assumption is valid. Elias <ref> [6] </ref> showed that the capacity of the erasure channel is 1 p and that a random linear code can be used to transmit over the erasure channel at any rate R &lt; 1 p.
Reference: [7] <author> R. G. Gallager. </author> <title> Low Density Parity-Check Codes. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1963. </year>
Reference-contexts: (B), given all of its check bits. 3 The Graph Process and Degree Sequences We now relate the decoding process of C (B) to a process on a subgraph of B, so that hereafter we can use this 3 A good candidate for the code C is the low-density parity-check <ref> [7, 12] </ref> version of these codes: only send the messages that cause all the check bits to be zero. These codes can be decoded in linear time and encoded in quadratic time with miniscule constants.
Reference: [8] <author> T.G. Kurtz, </author> <title> Approximation of Population Processes, </title> <booktitle> CBMS-NSF Regional Conf. Series in Applied Math, </booktitle> <publisher> SIAM, </publisher> <year> 1981. </year>
Reference-contexts: Proving the process progresses almost to completion if (5) is satisfied is possible by relating the differential equations to the underlying random process (see, e.g., <ref> [8, 11] </ref>). Proving the process runs to completion can be handled with a separate combinatorial argument. In some cases, however, this requires small modifications in the graph construction. Lemma 2 Let B be a bipartite graph chosen at random with edge-degrees specified by (x) and ae (x).
Reference: [9] <author> F. J. Macwilliams and N. J. A. Sloane, </author> <title> The Theory of Error-Correcting Codes, </title> <publisher> North Holland, </publisher> <address> Amsterdam, </address> <year> 1977. </year>
Reference-contexts: Even this optimized implementation required the use of dedicated workstations. Transmission of significantly higher quality video requires faster coding algorithms. In theory, it is possible to decode Reed-Solomon codes in time O (n log 2 n log log n) (see, [4, Chapter 11.7] and <ref> [9, p. 369] </ref>).
Reference: [10] <author> V. Paxson, </author> <title> Measurements and Analysis of End-to-End Internet Dynamics, </title> <type> Ph.D. thesis, </type> <institution> UC Berkeley, </institution> <year> 1997. </year>
Reference-contexts: 1 Introduction Studies show that the Internet exhibits packet loss, and the measurements in <ref> [10] </ref> show that the situation has become worse over the past few years. A standard solution to this problem is to request retransmission of data that is not received. When some of this retransmission is lost, another request is made, and so on. In some applications, this introduces technical difficulties.
Reference: [11] <author> A. Shwartz, A. Weiss, </author> <title> Large Deviations for Performance Analysis, </title> <publisher> Chapman & Hall, </publisher> <year> 1995. </year>
Reference-contexts: Proving the process progresses almost to completion if (5) is satisfied is possible by relating the differential equations to the underlying random process (see, e.g., <ref> [8, 11] </ref>). Proving the process runs to completion can be handled with a separate combinatorial argument. In some cases, however, this requires small modifications in the graph construction. Lemma 2 Let B be a bipartite graph chosen at random with edge-degrees specified by (x) and ae (x).
Reference: [12] <author> M. Sipser and D. Spielman, </author> <title> Expander codes, </title> <journal> IEEE Transactions on Information Theory (special issue devoted to coding theory), </journal> <volume> Vol. 42, No. 6, </volume> <month> November </month> <year> 1996, </year> <pages> pp. 17101722. </pages>
Reference-contexts: (B), given all of its check bits. 3 The Graph Process and Degree Sequences We now relate the decoding process of C (B) to a process on a subgraph of B, so that hereafter we can use this 3 A good candidate for the code C is the low-density parity-check <ref> [7, 12] </ref> version of these codes: only send the messages that cause all the check bits to be zero. These codes can be decoded in linear time and encoded in quadratic time with miniscule constants. <p> Thus, we only need to show that the initial graph is a good expander on small sets. Since the degree of each node on the left is at least three, standard proofs (see <ref> [12] </ref>) suffice to show that the expansion condition holds with high probability for all sets containing at most an j fraction of the left nodes, for some j &gt; 0. Using Lemmas 2 and 3, we can show that the codes presented in Section 7 work with high probability.
Reference: [13] <author> D. </author> <title> Spielman, </title> <journal> Linear-Time Encodable and Decodable Error-Correcting Codes IEEE Transactions on Information Theory (special issue devoted to coding theory), </journal> <volume> Vol. 42, No. 6, </volume> <month> November </month> <year> 1996, </year> <pages> pp. 17231731. </pages>
Reference-contexts: The fastest previously known encoding and decoding algorithms [2] with such a performance guarantee have run times proportional to n ln (1=*)=*. (See also [3] for related work.) The overall structure of our codes are related to codes introduced in <ref> [13] </ref> for error-correction. We explain the general construction along with the encoding and decoding al gorithms in Section 2. Our encoding and decoding algorithms are almost symmetrical. Both are extremely simple, computing exactly one exclusive-or operation for each edge in a randomly chosen bipartite graph.
Reference: [14] <author> M. Yajnik, J. Kurose, D. Towsley, </author> <title> Packet Loss Correlation in the MBone Multicast Network, </title> <booktitle> IEEE Global Internet Conference, </booktitle> <address> London, </address> <month> November, </month> <year> 1996. </year>
Reference-contexts: Such a scheme can be used as the ba-sic building block for the more robust and general protection scheme described in [1]. To demonstrate the benefits of forward error-correction in a simplified setting, consider the Internet loss measurements performed by <ref> [14] </ref> involving a multicast by one sender to a number of geographically distributed receivers. In one typical transmission to eleven receivers for a period of an hour, the average packet loss rate per receiver was 9.3%, yet 46.5% of the packets were lost by at least one of the receivers.
References-found: 14

