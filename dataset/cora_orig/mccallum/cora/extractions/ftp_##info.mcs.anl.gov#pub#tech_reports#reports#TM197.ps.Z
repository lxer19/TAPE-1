URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/TM197.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/tech_memos.htm
Root-URL: http://www.mcs.anl.gov
Title: Runtime System Library for Parallel Finite Difference Models with Nesting  
Author: by John Michalakes 
Note: This work was supported by the Mathematical, Information, and Computational Sciences Division subprogram of the Office of Computational and Technology Research, U.S. Department of Energy, under Contract W-31-109-Eng-38.  
Date: March 1997  
Web: ANL/MCS-TM-197  
Address: 9700 South Cass Avenue Argonne, IL 60439  
Affiliation: ARGONNE NATIONAL LABORATORY  Mathematics and Computer Science Division  
Pubnum: Technical Memorandum No. 197  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> S. Balay, W. D. Gropp, L. C. McInnes, and B. F. Smith, </author> <title> Efficient Management of Parallelism in Object-Oriented Numerical Software Libraries, in Modern Software Tools in Scientific Computing, </title> <editor> E. Arge, A. M. Bruaset, and H. P. Langtangen, eds., </editor> <publisher> Birkhauser Press, </publisher> <year> 1997. </year> <note> To appear (Also Argonne National Laboratory Mathematics and Computer Science Division preprint P634-0197). </note>
Reference-contexts: Support for global communication in the form of parallel transpose routines is under future work. The transposes may be implemented in a code outside the RSL framework by calling MPI directly. The interested reader may also wish to consider routines in the PETSc tools package <ref> [1] </ref>. Continuing RSL development focuses on the FLIC source translation software, which is based on a full Fortran-parser front-end and application specific back-end software, to 2 generate distributed-memory code mapped transparently onto the RSL library from orig-inal model source code [7].
Reference: [2] <author> I. Foster and J. Michalakes, MPMM: </author> <title> A Massively Parallel Mesoscale Model, </title> <booktitle> in Parallel Supercomputing in Atmospheric Science, </booktitle> <editor> G.-R. Hoffmann and T. Kauranne, eds., </editor> <publisher> World Scientific, </publisher> <address> River Edge, NJ 07661, </address> <year> 1993, </year> <pages> pp. 354-363. </pages>
Reference-contexts: Ability to read and write ordinary Fortran record-blocked serial data sets, allow ing the parallel code to use native data sets. MPMM and MM90, parallel versions of the Penn State/NCAR Mesoscale Model MM5 were parallelized using RSL <ref> [2, 3, 4, 8] </ref>. At the present time, RSL is applicable only to models using explicit solvers. Support for global communication in the form of parallel transpose routines is under future work. The transposes may be implemented in a code outside the RSL framework by calling MPI directly.
Reference: [3] <author> G. A. Grell, J. Dudhia, and D. R. Stauffer, </author> <title> A Description of the Fifth-Generation Penn State/NCAR Mesoscale Model (MM5), </title> <type> Tech. Rep. </type> <institution> NCAR/TN-398+STR, National Center for Atmospheric Research, Boulder, Colorado, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: Ability to read and write ordinary Fortran record-blocked serial data sets, allow ing the parallel code to use native data sets. MPMM and MM90, parallel versions of the Penn State/NCAR Mesoscale Model MM5 were parallelized using RSL <ref> [2, 3, 4, 8] </ref>. At the present time, RSL is applicable only to models using explicit solvers. Support for global communication in the form of parallel transpose routines is under future work. The transposes may be implemented in a code outside the RSL framework by calling MPI directly. <p> For this implementation, atmospheric dynamics is nonhydrostatic and uses finite-difference approximation. Physics includes the Blackadar high-resolution planetary boundary layer scheme, the Grell cumulus scheme, explicit moisture with treatment of mixed-phase processes (ice), shallow convection, dry convective adjustment, and the Dud-hia long- and short-wave radiation scheme <ref> [3] </ref>. MM5 was first converted to column-callable form and then parallelized using the first generation of RSL. MPMM, as the parallel version is called (for Massively Parallel Mesoscale Model), was validated and benchmarked on the IBM SP1 and SP2.
Reference: [4] <author> P. L. Haagenson, J. Dudhia, G. A. Grell, and D. R. Stauffer, </author> <title> The Penn State/NCAR Mesoscale Model (MM5), Source Code Documentation, </title> <type> Tech. Rep. </type> <institution> 38 NCAR/TN-328+STR, National Center for Atmospheric Research, Boulder, Colorado, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: Ability to read and write ordinary Fortran record-blocked serial data sets, allow ing the parallel code to use native data sets. MPMM and MM90, parallel versions of the Penn State/NCAR Mesoscale Model MM5 were parallelized using RSL <ref> [2, 3, 4, 8] </ref>. At the present time, RSL is applicable only to models using explicit solvers. Support for global communication in the form of parallel transpose routines is under future work. The transposes may be implemented in a code outside the RSL framework by calling MPI directly.
Reference: [5] <author> R. Hempel and H. Ritzdorf, </author> <title> The GMD communications library for grid-oriented problems, </title> <type> Tech. Rep. </type> <institution> GMD-0589, German National Research Center for Information Technology, </institution> <year> 1991. </year>
Reference-contexts: Section 5 walks through the parallelization of a simple relaxation code using RSL. Section 6 discusses the implementation of a MM5 using RSL. Section 7 presents conclusions and directions for future work. 2 Related Work RSL is similar to efforts of a number of other groups, particularly Comlib <ref> [5] </ref>, LAPRX [6], and NNT/SMS [9], in that it provides high-level, efficient mechanisms for performing data-parallel computations over multiple interrelated grids. Like the LAPRX software abstractions, RSL is able to support dynamic load balancing, efficient intergrid communication, irregularly shaped logical domains, and irregularly shaped processor subdomains.
Reference: [6] <author> S. R. Kohn and S. B. Baden, </author> <title> A Parallel Software Infrastructure for Structured Adaptive Mesh Methods, </title> <booktitle> in Proceedings of Supercomputing '95, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1996. </year>
Reference-contexts: Section 6 discusses the implementation of a MM5 using RSL. Section 7 presents conclusions and directions for future work. 2 Related Work RSL is similar to efforts of a number of other groups, particularly Comlib [5], LAPRX <ref> [6] </ref>, and NNT/SMS [9], in that it provides high-level, efficient mechanisms for performing data-parallel computations over multiple interrelated grids. Like the LAPRX software abstractions, RSL is able to support dynamic load balancing, efficient intergrid communication, irregularly shaped logical domains, and irregularly shaped processor subdomains.
Reference: [7] <author> J. Michalakes, FLIC: </author> <title> A Translator for Same-source Parallel Implementation of Regular Grid Applications, </title> <type> Tech. Rep. </type> <institution> ANL/MCS-TM-223, Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Illinois, </institution> <month> March </month> <year> 1997. </year>
Reference-contexts: Continuing RSL development focuses on the FLIC source translation software, which is based on a full Fortran-parser front-end and application specific back-end software, to 2 generate distributed-memory code mapped transparently onto the RSL library from orig-inal model source code <ref> [7] </ref>. This approach, which is virtually directiveless, will allow full and seamless integration of MPP capability into the officially maintained weather model, eliminating the need to support separate versions of the code for different architectures.
Reference: [8] <author> J. Michalakes, T. Canfield, R. Nanjundiah, and S. Hammond, </author> <title> Parallel Implementation, Validation, and Performance of MM5, </title> <booktitle> in Coming of Age: Proceedings of the Sixth ECMWF Workshop on the Use of Parallel Procesors in Meteorology, World Scientific, </booktitle> <address> River Edge, NJ, </address> <year> 1995, </year> <pages> pp. 266-276. </pages>
Reference-contexts: Ability to read and write ordinary Fortran record-blocked serial data sets, allow ing the parallel code to use native data sets. MPMM and MM90, parallel versions of the Penn State/NCAR Mesoscale Model MM5 were parallelized using RSL <ref> [2, 3, 4, 8] </ref>. At the present time, RSL is applicable only to models using explicit solvers. Support for global communication in the form of parallel transpose routines is under future work. The transposes may be implemented in a code outside the RSL framework by calling MPI directly. <p> It has since been ported to the Intel Paragon, Cray T3D, Fujutsu AP1000, Silicon Graphics Power Challenge, and networks of workstations using MPI. Performance of 1.2 Gflops has been generated for a single domain problem running on 64 SP1 processors. Additional information regarding the parallel MM5 is available in <ref> [8] </ref> and on the World Wide Web at the location http://www.mcs.anl.gov/Projects/mpmm/index.html. Parallelizing MM5 provided a number of insights and suggested improvements that have been incorporated into the latest version of RSL. These include explicit loop constructs that 23 after 50 iterations of the main loop, plotted as 2D density plots.
Reference: [9] <author> B. Rodriguez, L. Hart, and T. Henderson, </author> <title> A Library for the Portable Parall-lelization of Operational Weather Forecast Models, </title> <booktitle> in Coming of Age: Proceedings of the Sixth ECMWF Workshop on the Use of Parallel Procesors in Meteorology, World Scientific, </booktitle> <address> River Edge, NJ, </address> <year> 1995, </year> <pages> pp. 148-161. 39 </pages>
Reference-contexts: Section 6 discusses the implementation of a MM5 using RSL. Section 7 presents conclusions and directions for future work. 2 Related Work RSL is similar to efforts of a number of other groups, particularly Comlib [5], LAPRX [6], and NNT/SMS <ref> [9] </ref>, in that it provides high-level, efficient mechanisms for performing data-parallel computations over multiple interrelated grids. Like the LAPRX software abstractions, RSL is able to support dynamic load balancing, efficient intergrid communication, irregularly shaped logical domains, and irregularly shaped processor subdomains.
References-found: 9

