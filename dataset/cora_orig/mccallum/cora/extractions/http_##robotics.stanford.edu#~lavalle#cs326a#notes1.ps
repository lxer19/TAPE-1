URL: http://robotics.stanford.edu/~lavalle/cs326a/notes1.ps
Refering-URL: http://robotics.stanford.edu/~lavalle/cs326a/
Root-URL: http://www.cs.stanford.edu
Title: Dynamic Programming and Optimal Motion Planning  
Author: Steven M. LaValle 
Date: February 11, 1997  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> N. M. Amato and Y. Wu. </author> <title> A randomized roadmap method for path and manipulation planning. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 113-120, </pages> <year> 1996. </year>
Reference-contexts: The dynamic programming formulation presented here is more similar to what appears in optimal control literature [2, 7, 15]. 2 Reformulating Motion Planning Recall that the goal of the basic motion planning problem is to compute a path t : <ref> [0; 1] </ref> ! C free such that t (0) = q init and t (1) = q goal , when such a path exists. In the case of nonholonomic systems, velocity constraints must additionally be satisfied. <p> Such results have turned motion planning efforts toward approximate techniques. For example, a polynomial-time algorithm is given in [18] for computing epsilon approximations of minimum-distance paths in a 3-D environment. Also, randomized techniques are used to compute solutions for high degree-of-freedom problems that are unapproachable by complete methods <ref> [1, 4, 10, 23] </ref>. The second motivation for considering approximate solutions is to avoid specialized analysis of particular cases, with the intent of allowing the algorithms to be adaptable to other problem classes. <p> For example, if C = &lt; 2 , the interpolation can be computed as L fl k+1 (q k+1 ) fffiL fl k+1 [i; j]+(1ff)fiL fl k+1 [i; j+1]+(1ff)(1fi)L fl in which ff; fi 2 <ref> [0; 1] </ref> are coefficients that express the normalized distance to the neighbors in the q 1 and q 2 directions, respectively. For example ff = 1, and fi = 0 when q k+1 lies at the configuration represented by index [i; j + 1].
Reference: [2] <author> B. D. Anderson and J. B. Moore. </author> <title> Optimal Control: Linear-Quadratic Methods. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990. </year>
Reference-contexts: Although there are connections between dynamic programming in this context and in graph search, its use in these notes applies to continuous spaces. The dynamic programming formulation presented here is more similar to what appears in optimal control literature <ref> [2, 7, 15] </ref>. 2 Reformulating Motion Planning Recall that the goal of the basic motion planning problem is to compute a path t : [0; 1] ! C free such that t (0) = q init and t (1) = q goal , when such a path exists. <p> In both control theory and dynamic game theory, the classic set of problems that can be solved are those with a linear transition equation and quadratic loss functional <ref> [2, 3, 7] </ref>. The algorithm description is organized into three parts. First, the general principle of optimality is described, which greatly reduces the amount of effort that is required to compute optimal strategies. The next part describes how cost-to-go functions are computed as an intermediate representation of the optimal strategy.
Reference: [3] <author> T. Ba~sar and G. J. Olsder. </author> <title> Dynamic Noncooperative Game Theory. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1982. </year>
Reference-contexts: In both control theory and dynamic game theory, the classic set of problems that can be solved are those with a linear transition equation and quadratic loss functional <ref> [2, 3, 7] </ref>. The algorithm description is organized into three parts. First, the general principle of optimality is described, which greatly reduces the amount of effort that is required to compute optimal strategies. The next part describes how cost-to-go functions are computed as an intermediate representation of the optimal strategy.
Reference: [4] <author> J. Barraquand and J.-C. Latombe. </author> <title> A Monte-Carlo algorithm for path planning with many degrees of freedom. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 1712-1717, </pages> <year> 1990. </year>
Reference-contexts: Such results have turned motion planning efforts toward approximate techniques. For example, a polynomial-time algorithm is given in [18] for computing epsilon approximations of minimum-distance paths in a 3-D environment. Also, randomized techniques are used to compute solutions for high degree-of-freedom problems that are unapproachable by complete methods <ref> [1, 4, 10, 23] </ref>. The second motivation for considering approximate solutions is to avoid specialized analysis of particular cases, with the intent of allowing the algorithms to be adaptable to other problem classes. <p> Artificial potential functions have often been constructed very efficiently in motion planning approaches; however, these approaches heuristically estimate the cost-to-go and are typically prone to have local minima <ref> [4, 12] </ref>. The first step is to construct a representation of L fl K+1 . The final term, l K+1 (q K+1 ), of the loss functional is directly used to assign values of L fl K+1 (q K+1 ) at discretized locations. <p> Note that although the approach to select the action is local (and efficient), the global information is still taken into account (it is encoded in the cost-to-go function). This concept is similar to the use of a numerical navigation function in previous motion planning literature <ref> [4, 22] </ref> (such as NF1 or NF2), and the cost-to-go is a form of progress measure, as considered in [9].
Reference: [5] <author> R. E. Bellman. </author> <title> Dynamic Programming. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1957. </year>
Reference-contexts: fl u k l k (q k ; u k ) + min ( K X l k (q i ; u i (q i )) + l K+1 (q K+1 ) : (10) The second portion of the min represents the cost-to-go function for stage k + 1, yielding <ref> [5] </ref>: L fl u k l k (q k ; u k (q k )) + L fl This final form represents a powerful constraint on the set of optimal strategies. The optimal strategy at stage k and configuration q depends only cost-to-go values at stage k + 1. <p> Other schemes, such as quadratic interpolation, can be used to improve numerical accuracy at the expense of computation time [15]. Convergence properties of the quantization and interpolation are discussed in <ref> [5, 6] </ref>. Interpolation represents an important step that overcomes the problems of measuring Manhattan distance due to quantization. Note that for some problems, however, interpolation might not be necessary. Suppose for example, that the robot is a manipulator that has independently-controlled joints.
Reference: [6] <author> D. P. Bertsekas. </author> <title> Convergence in discretization procedures in dynamic programming. </title> <journal> IEEE Trans. Autom. Control, </journal> <volume> 20(3) </volume> <pages> 415-419, </pages> <month> June </month> <year> 1975. </year>
Reference-contexts: Other schemes, such as quadratic interpolation, can be used to improve numerical accuracy at the expense of computation time [15]. Convergence properties of the quantization and interpolation are discussed in <ref> [5, 6] </ref>. Interpolation represents an important step that overcomes the problems of measuring Manhattan distance due to quantization. Note that for some problems, however, interpolation might not be necessary. Suppose for example, that the robot is a manipulator that has independently-controlled joints.
Reference: [7] <author> A. E. Bryson and Y.-C. Ho. </author> <title> Applied Optimal Control. </title> <publisher> Hemisphere Publishing Corp., </publisher> <address> New York, NY, </address> <year> 1975. </year>
Reference-contexts: Although there are connections between dynamic programming in this context and in graph search, its use in these notes applies to continuous spaces. The dynamic programming formulation presented here is more similar to what appears in optimal control literature <ref> [2, 7, 15] </ref>. 2 Reformulating Motion Planning Recall that the goal of the basic motion planning problem is to compute a path t : [0; 1] ! C free such that t (0) = q init and t (1) = q goal , when such a path exists. <p> In both control theory and dynamic game theory, the classic set of problems that can be solved are those with a linear transition equation and quadratic loss functional <ref> [2, 3, 7] </ref>. The algorithm description is organized into three parts. First, the general principle of optimality is described, which greatly reduces the amount of effort that is required to compute optimal strategies. The next part describes how cost-to-go functions are computed as an intermediate representation of the optimal strategy.
Reference: [8] <author> J. Canny and J. Reif. </author> <title> New lower bound techniques for robot motion planning problems. </title> <booktitle> In Proc. IEEE Conf. on Foundations of Computer Science, </booktitle> <pages> pages 49-60, </pages> <year> 1987. </year>
Reference-contexts: The computational hardness results have curbed many efforts to find efficient, complete algorithms to general motion planning problems. In [19] the basic motion planning problem was shown to be PSPACE-hard for polyhedral robots with n links. In <ref> [8] </ref> is was shown that computing minimum-distance paths in a 3-D workspace is NP-hard. It was also shown that the compliant motion control problem with sensing uncertainty is nondeterministic exponential time hard.
Reference: [9] <author> M. Erdmann. </author> <title> Understanding action and sensing by designing action-based sensors. </title> <journal> Int. J. Robot. Res., </journal> <volume> 14(5) </volume> <pages> 483-509, </pages> <year> 1995. </year>
Reference-contexts: This concept is similar to the use of a numerical navigation function in previous motion planning literature [4, 22] (such as NF1 or NF2), and the cost-to-go is a form of progress measure, as considered in <ref> [9] </ref>. When considering the cost-to-go as a navigation function, it is important to note that it does not contain local minima because it is constructed as a by-product of determining the optimal solution. Once the optimal action is determined, an exact next configuration is obtained (i.e., not a quantized configuration).
Reference: [10] <author> L. Kavraki and J.-C. Latombe. </author> <title> Randomized preprocessingf of configuration space for path planning. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 2138-2139, </pages> <year> 1994. </year>
Reference-contexts: Such results have turned motion planning efforts toward approximate techniques. For example, a polynomial-time algorithm is given in [18] for computing epsilon approximations of minimum-distance paths in a 3-D environment. Also, randomized techniques are used to compute solutions for high degree-of-freedom problems that are unapproachable by complete methods <ref> [1, 4, 10, 23] </ref>. The second motivation for considering approximate solutions is to avoid specialized analysis of particular cases, with the intent of allowing the algorithms to be adaptable to other problem classes.
Reference: [11] <author> L. E. Kavraki. </author> <title> Computation of configuration-space obstacles using the Fast Fourier Transform. </title> <journal> IEEE Trans. Robot. & Autom., </journal> <volume> 11(3) </volume> <pages> 408-413, </pages> <year> 1995. </year>
Reference-contexts: The constraints can be directly evaluated each time to determine whether each q k+1 lies in the free space, or a bitmap representation of the configuration space can be used for quick evaluations (an efficient algorithm for building a bitmap representation of C free is given in <ref> [11] </ref>). Note that L fl K represents the cost of the optimal one-stage strategy from each configuration q k . More generally, L fl Ki represents the cost of the optimal (i + 1)-stage strategy from each configuration q K+1 .
Reference: [12] <author> O. Khatib. </author> <title> Real-time obstacle avoidance for manipulators and mobile robots. </title> <journal> Int. J. Robot. Res., </journal> <volume> 5(1) </volume> <pages> 90-98, </pages> <year> 1986. </year>
Reference-contexts: Artificial potential functions have often been constructed very efficiently in motion planning approaches; however, these approaches heuristically estimate the cost-to-go and are typically prone to have local minima <ref> [4, 12] </ref>. The first step is to construct a representation of L fl K+1 . The final term, l K+1 (q K+1 ), of the loss functional is directly used to assign values of L fl K+1 (q K+1 ) at discretized locations.
Reference: [13] <author> P. R. Kumar and P. Varaiya. </author> <title> Stochastic Systems. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1986. </year>
Reference-contexts: In optimal control theory, the dynamic programming principle is represented as a differential equation (or difference equation in discrete time) that can be used to directly solve a problem such as the linear-quadratic Gaussian regulator <ref> [13] </ref>, or can be used for computing numerical approximations of optimal strategies [14]. In the general case, the differential equation is expressed in terms of time-dependent cost-to-go functions.
Reference: [14] <author> R. E. Larson. </author> <title> A survey of dynamic programming computational procedures. </title> <journal> IEEE Trans. Autom. Control, </journal> <volume> 12(6) </volume> <pages> 767-774, </pages> <month> December </month> <year> 1967. </year>
Reference-contexts: In optimal control theory, the dynamic programming principle is represented as a differential equation (or difference equation in discrete time) that can be used to directly solve a problem such as the linear-quadratic Gaussian regulator [13], or can be used for computing numerical approximations of optimal strategies <ref> [14] </ref>. In the general case, the differential equation is expressed in terms of time-dependent cost-to-go functions. The cost-to-go is a function on the configuration space that expresses the cost that is received under the implementation of an optimal strategy from that particular configuration and time. <p> Also, only the representation of L fl k+1 is retained while constructing L fl k ; earlier representations can be discarded to save storage space. The general advantages of these kinds of computations were noted long ago in <ref> [14] </ref>: 1) extremely general types of system equations, performance criteria, and constraints can be handled; 2) particular questions of existence and uniqueness are avoided; 3) a true feedback solution is directly generated.
Reference: [15] <author> R. E. Larson and J. L. Casti. </author> <title> Principles of Dynamic Programming, Part II. </title> <publisher> Dekker, </publisher> <address> New York, NY, </address> <year> 1982. </year>
Reference-contexts: Although there are connections between dynamic programming in this context and in graph search, its use in these notes applies to continuous spaces. The dynamic programming formulation presented here is more similar to what appears in optimal control literature <ref> [2, 7, 15] </ref>. 2 Reformulating Motion Planning Recall that the goal of the basic motion planning problem is to compute a path t : [0; 1] ! C free such that t (0) = q init and t (1) = q goal , when such a path exists. <p> For example ff = 1, and fi = 0 when q k+1 lies at the configuration represented by index [i; j + 1]. Other schemes, such as quadratic interpolation, can be used to improve numerical accuracy at the expense of computation time <ref> [15] </ref>. Convergence properties of the quantization and interpolation are discussed in [5, 6]. Interpolation represents an important step that overcomes the problems of measuring Manhattan distance due to quantization. Note that for some problems, however, interpolation might not be necessary.
Reference: [16] <author> J.-C. Latombe. </author> <title> Robot Motion Planning. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1991. </year>
Reference-contexts: This implies that we can locally move the robot in any allowable direction from its tangent space. For nonholonomic problems, one will only be allowed to move the robot through a function of the form _q = f (q (t); u (t)). For example, as described in <ref> [16] </ref>, p. 432, the equations for the nonholonomic car robot can be expressed as _x = v cos (), _y = v sin (), and _ = v L tan ().
Reference: [17] <author> S. M. LaValle. </author> <title> A Game-Theoretic Framework for Robot Motion Planning. </title> <type> PhD thesis, </type> <institution> University of Illinois, Urbana, IL, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: Variations of this algorithm, which apply to a variety of motion planning problems are discussed in detail in <ref> [17] </ref>. The quality of this approximation depends on the resolution of the representation chosen for the configuration space and action space.
Reference: [18] <author> C. H. Papadimitriou. </author> <title> An algorithm for shortest-path planning in three dimensions. </title> <journal> Information Processing Letters, </journal> <volume> 20(5) </volume> <pages> 259-263, </pages> <year> 1985. </year>
Reference-contexts: In [21], a 3-D pursuit-evasion problem is shown to be exponential time hard, even though there is perfect sensing information. Such results have turned motion planning efforts toward approximate techniques. For example, a polynomial-time algorithm is given in <ref> [18] </ref> for computing epsilon approximations of minimum-distance paths in a 3-D environment. Also, randomized techniques are used to compute solutions for high degree-of-freedom problems that are unapproachable by complete methods [1, 4, 10, 23].
Reference: [19] <author> J. H. Reif. </author> <title> Complexity of the mover's problem and generalizations. </title> <booktitle> In Proc. of IEEE Symp. on Foundat. of Comp. Sci., </booktitle> <pages> pages 421-427, </pages> <year> 1979. </year>
Reference-contexts: The computational hardness results have curbed many efforts to find efficient, complete algorithms to general motion planning problems. In <ref> [19] </ref> the basic motion planning problem was shown to be PSPACE-hard for polyhedral robots with n links. In [8] is was shown that computing minimum-distance paths in a 3-D workspace is NP-hard. It was also shown that the compliant motion control problem with sensing uncertainty is nondeterministic exponential time hard.
Reference: [20] <author> J. H. Reif and M. Sharir. </author> <title> Motion planning in the presence of moving obstacles. </title> <booktitle> In Proc. of IEEE Symp. on Foundat. of Comp. Sci., </booktitle> <pages> pages 144-154, </pages> <year> 1985. </year>
Reference-contexts: In [8] is was shown that computing minimum-distance paths in a 3-D workspace is NP-hard. It was also shown that the compliant motion control problem with sensing uncertainty is nondeterministic exponential time hard. In <ref> [20] </ref> it was shown that planning the motion of a disk in a 3-D environment with rotating obstacles is PSPACE-hard. In [21], a 3-D pursuit-evasion problem is shown to be exponential time hard, even though there is perfect sensing information. Such results have turned motion planning efforts toward approximate techniques.
Reference: [21] <author> J. H. Reif and S. R. Tate. </author> <title> Continuous alternation: The complexity of pursuit in continuous domains. </title> <journal> Algorith-mica, </journal> <volume> 10 </volume> <pages> 157-181, </pages> <year> 1993. </year>
Reference-contexts: It was also shown that the compliant motion control problem with sensing uncertainty is nondeterministic exponential time hard. In [20] it was shown that planning the motion of a disk in a 3-D environment with rotating obstacles is PSPACE-hard. In <ref> [21] </ref>, a 3-D pursuit-evasion problem is shown to be exponential time hard, even though there is perfect sensing information. Such results have turned motion planning efforts toward approximate techniques. For example, a polynomial-time algorithm is given in [18] for computing epsilon approximations of minimum-distance paths in a 3-D environment.
Reference: [22] <author> E. Rimon and D. E. Koditschek. </author> <title> Exact robot navigation using artificial potential fields. </title> <journal> IEEE Trans. Robot. & Autom., </journal> <volume> 8(5) </volume> <pages> 501-518, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Note that although the approach to select the action is local (and efficient), the global information is still taken into account (it is encoded in the cost-to-go function). This concept is similar to the use of a numerical navigation function in previous motion planning literature <ref> [4, 22] </ref> (such as NF1 or NF2), and the cost-to-go is a form of progress measure, as considered in [9].
Reference: [23] <author> P. Svestka and M. H. Overmars. </author> <title> Coordinated motion planning for multiple car-like robots using probabilistic roadmaps. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 1631-1636, </pages> <year> 1995. </year> <month> 8 </month>
Reference-contexts: Such results have turned motion planning efforts toward approximate techniques. For example, a polynomial-time algorithm is given in [18] for computing epsilon approximations of minimum-distance paths in a 3-D environment. Also, randomized techniques are used to compute solutions for high degree-of-freedom problems that are unapproachable by complete methods <ref> [1, 4, 10, 23] </ref>. The second motivation for considering approximate solutions is to avoid specialized analysis of particular cases, with the intent of allowing the algorithms to be adaptable to other problem classes.
References-found: 23

