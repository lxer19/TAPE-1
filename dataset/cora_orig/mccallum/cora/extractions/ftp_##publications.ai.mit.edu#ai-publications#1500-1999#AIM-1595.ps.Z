URL: ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1595.ps.Z
Refering-URL: http://www.ai.mit.edu/people/gideon/gideon.html
Root-URL: 
Email: gideon@ai.mit.edu  
Title: Lens Distortion Calibration Using Point Correspondences  
Author: Gideon P. Stein 
Note: This publication can be retrieved by anonymous ftp to publications.ai.mit.edu. Copyright c Massachusetts Institute of Technology, 1996  
Date: 1595 November, 1996  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY  
Pubnum: A.I. Memo No.  
Abstract: This paper describes a new method for lens distortion calibration using only point correspondences in multiple views, without the need to know either the 3D location of the points or the camera locations. The standard lens distortion model is a model of the deviations of a real camera from the ideal pinhole or projective camera model. Given multiple views of a set of corresponding points taken by ideal pinhole cameras there exist epipolar and trilinear constraints among pairs and triplets of these views. In practice, due to noise in the feature detection and due to lens distortion these constraints do not hold exactly and we get some error. The calibration is a search for the lens distortion parameters that minimize this error. Using simulation and experimental results with real images we explore the properties of this method. We describe the use of this method with the standard lens distortion model, radial and decentering, but it could also be used with any other parametric distortion models. Finally we demonstrate that lens distortion calibration improves the accuracy of 3D reconstruction. This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for this research was provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N00014-94-01-0994. Gideon P. Stein is also supported by Alphatech/ DARPA "Automatic Target Recognition" project 95009-5381 and TASC/ DARPA "MSTAR Match Module" project J-08011-S95042. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Brown, </author> <note> D.C.,"Close -range Camera Calibration" Photogrammetric Engineering 37 855-866 (1971) </note>
Reference-contexts: Projective constraints: Under perspective projection, straight lines in space project to straight lines in the image. With real lenses the lines appear instead to be slightly to moderately curved. By searching for lens distortion parameters which straighten the lines the Plumb Line method and its derivatives <ref> [1] </ref> [5] [12] [2] find the lens distortion without needing to find the external parameters or the other internal camera parameters. One or more images can be used.
Reference: [2] <author> Devernay, F. and Faugeras, O., </author> <title> "Automatic calibration and removal of distortion from scenes of (a) (c) Legend: Reconstruction using uncorrected points. ..... Reconstruction using corrected points. the best fit plane. Figures (a), (b) and (c) are the points along the lines which pass close to the center of the image, half way down and close to the bottom, respectively. 7 structured environments", </title> <booktitle> In Proceedings of SPIE Conference, </booktitle> <address> San Diego, CA, </address> <month> July </month> <year> (1995) </year>
Reference-contexts: Projective constraints: Under perspective projection, straight lines in space project to straight lines in the image. With real lenses the lines appear instead to be slightly to moderately curved. By searching for lens distortion parameters which straighten the lines the Plumb Line method and its derivatives [1] [5] [12] <ref> [2] </ref> find the lens distortion without needing to find the external parameters or the other internal camera parameters. One or more images can be used.
Reference: [3] <author> Du, F. and Brady, M., </author> <title> "Self Calibration of the Intrinsic Parameters of Cameras for Active Vision Systems" In Proceedings of CVPR 93, </title> <address> 477-482, New York, NY, </address> <month> June </month> <year> (1993) </year>
Reference-contexts: One or more images can be used. Unknown world coordinates: Stein [12], and Du and Brady <ref> [3] </ref> use corresponding points or edges in images where the camera has undergone pure rotation to find the internal camera parameters including lens distortion. The 3D location of the points is not required. 3 Mathematical background This paper uses results from projective geometry.
Reference: [4] <author> Faugeras, O., </author> <title> Three Dimensional Computer Vision: </title> <publisher> a Geometric Viewpoint , MIT Press, </publisher> <year> (1993). </year>
Reference-contexts: A very readable introduction to the subject of Projective Geometry is given in the book by Young [14]. A modern book dealing more specifically with the application of Projective Geometry to computer vision is <ref> [4] </ref>. I will use the following notation. The point in 3D projective space (P 3 ) will be represented by M i where the subscript i denotes the i'th point. The subscript i might often be dropped for clarity.
Reference: [5] <author> Fryer, J.G. and Mason, </author> <title> S.O.,"Rapid Lens Calibration of a Video Camera"Photogrammetric Engineering and Remote Sensing 55 437-442, </title> <year> (1989) </year>
Reference-contexts: Projective constraints: Under perspective projection, straight lines in space project to straight lines in the image. With real lenses the lines appear instead to be slightly to moderately curved. By searching for lens distortion parameters which straighten the lines the Plumb Line method and its derivatives [1] <ref> [5] </ref> [12] [2] find the lens distortion without needing to find the external parameters or the other internal camera parameters. One or more images can be used.
Reference: [6] <author> Hartley, </author> <title> R, "In Defense of the Eight Point Algorithm", </title> <booktitle> In Proc. of ICCV 95, </booktitle> <pages> 1064-1070, </pages> <address> Boston, MA, USA, </address> <month> June </month> <year> (1995) </year>
Reference-contexts: point in the second image must lie. (The equation of that line is given by V T F jk m i;k = 0.) Given 8 or more point correspondences the Fundamental Matrix F can be determined up to a scale factor using the eight point algorithm which is described in <ref> [6] </ref> with many important implementation details. 3.2 The Trilinear Tensor Constraint: Shashua [9] shows that given a set of 3D points there exists a set of trilinear equations between the projections of those points into any three perspective views.
Reference: [7] <institution> More, J.J., et al., "User Guide for Minpack-1" Argonne National Laboratory, Argonne, Illinois (1980) </institution>
Reference-contexts: on a standard 35mm camera or an 8mm lens on 1/3" CCD video camera. * Image capture and processing was performed on an SGI Indy workstation. 6.1.3 Nonlinear optimization code The camera parameters were found using a nonlinear optimization program based on the subroutine LMDIF from the software package MINPACK-1 <ref> [7] </ref>. This subroutine uses a modified Levenberg-Marquart algorithm. 6.2 Experiment 1: Finding the lens distortion parameters. Using all 75 points in the 3 images (figures 2a,2b,2c) I computed the trilinear tensor (see section 3) and then the reprojection error from images 2b and 2c to image 2a.
Reference: [8] <editor> Slama, C.C. ed, </editor> <title> Manual of Photogrammetry,4th edition, </title> <journal> American Society of Photogrammetry (1980). </journal>
Reference-contexts: Finally I perform Euclidean reconstruction of the points. I conclude in section (7) with a discussion of the advantages and drawbacks of this method. 2 Related work Known world coordinates: The classic method for lens distortion calibration is the bundle adjustment method <ref> [8] </ref>. It uses one or more views of a calibration object with known 3D coordinates (control points). Using iterative methods it then finds both external and internal camera parameters. The external camera parameters are the position and orientation of each camera. <p> This is a good model for long focal lengths but medium to wide angle lenses have noticeable lens distortion. The standard model for lens distortion <ref> [8] </ref> is a mapping from the distorted image coordinates, (x d ; y d ), that are observable, to the undistorted image plane coordinates, (x u ; y u ), which are not physically measurable using the equation: x u = x d + x 0 0 2 0 4 y <p> d = (x 2 d c yr ) 2 (7) It has been shown in [12] that allowing the center of radial distortion, (c xr ; c yr ) to be different from the principal point is a good approximation to adding the terms for decentering distortion as given in <ref> [8] </ref>. 4 The algorithm The step by step algorithm is as follows: 1. Find point correspondences between 3 views. 2. Make an initial guess of the distortion parameters: an appropriate guess for (Cx,Cy) is the center of the image. <p> Especially, since most of the computational machinery required for tasks such as finding the trilinear tensor or fundamental matrix probably already exists in the overall system. The Manual of Photogrammetry <ref> [8] </ref> warns us that "the strong coupling that exists between interior elements of orientation [principal point, focal length] and exterior elements can be expected to result in unacceptably large variances for these particular projective parameters when recovered on a frame-by-frame basis".
Reference: [9] <author> Shashua, A. </author> <title> "Algebraic Functions for Recognition", </title> <journal> IEEE Trans. </journal> <volume> PAMI 17, </volume> <pages> 779-789, </pages> <year> (1995) </year>
Reference-contexts: The error function is in general well behaved and the distortion parameters can easily be found by nonlinear search techniques. 1.2 The three image method: Given a set of corresponding points in three images, there exist 4 independent trilinear equations that relate location of the points in the three images <ref> [9] </ref>. These equations have 27 parameters and given at least 7 point correspondences they can be found in a linear manner. These parameters allow us to reproject corresponding points given in two of the images into the third image. <p> is given by V T F jk m i;k = 0.) Given 8 or more point correspondences the Fundamental Matrix F can be determined up to a scale factor using the eight point algorithm which is described in [6] with many important implementation details. 3.2 The Trilinear Tensor Constraint: Shashua <ref> [9] </ref> shows that given a set of 3D points there exists a set of trilinear equations between the projections of those points into any three perspective views. In total there exist 9 such equations for each point with at most 4 being independent.
Reference: [10] <author> Shashua, A. and Werman, M., </author> <title> "Trilinearity of Three Perspective Views and its Associated Tensor", </title> <booktitle> In Proceedings of ICCV 95, </booktitle> <address> 920-925 Boston, MA, USA, </address> <month> June </month> <year> (1995) </year>
Reference-contexts: There are a total of nine column vectors ff ij for a total of 27 coefficients. Seven point correspondences give 28 equations which are enough to recover the coefficients up to a scale factor. The 27 coefficients can be arranged into a 3 fi 3 fi 3 tensor <ref> [10] </ref>. Given 7 points in 3 images one can recover the tensor.
Reference: [11] <author> Shashua, A. and Navab, N., </author> <title> "Relative Affine Structure: Canonical Model for 3D from 2D Geometry and Applications." </title> <journal> IEEE Trans. PAMI (PAMI) Vol. </journal> <volume> 18(9), </volume> <pages> pp. 873-883, </pages> <year> (1996). </year>
Reference-contexts: Figure (6c) shows the RMS reprojection error using the images Fig. 2a and Fig. 2b. The minimum error is obtained near the value of K1 found using the distortion calibration. 6.4 Experiment 3: Euclidean reconstruction. Projective reconstruction from the three images was performed according to <ref> [11] </ref>. Transformation to Euclidean 3D coordinates was required 5 control points. Three points were chosen from the planar surface and two other points were chosen such that the five were in general position, no 4 points coplanar.
Reference: [12] <author> Stein, </author> <title> G.P., "Internal Camera Calibration using Rotation and Geometric Shapes" AITR-1426, </title> <type> Master's Thesis, </type> <institution> Massachussets Institute of Technology, Artificial Intelligence Laboratory (1993). </institution>
Reference-contexts: 1 Introduction: Radial lens distortion can be a significant factor in medium to wide angle lenses. These are typically the lenses used when performing image based 3D reconstruction of large objects or in a confined space. The errors can be 10-100 pixels at the edges of the image <ref> [12] </ref>. This paper describes a new method for lens distortion calibration using point correspondences in multiple views without the need to know either the 3D location of the points or the camera locations. <p> Projective constraints: Under perspective projection, straight lines in space project to straight lines in the image. With real lenses the lines appear instead to be slightly to moderately curved. By searching for lens distortion parameters which straighten the lines the Plumb Line method and its derivatives [1] [5] <ref> [12] </ref> [2] find the lens distortion without needing to find the external parameters or the other internal camera parameters. One or more images can be used. Unknown world coordinates: Stein [12], and Du and Brady [3] use corresponding points or edges in images where the camera has undergone pure rotation to <p> By searching for lens distortion parameters which straighten the lines the Plumb Line method and its derivatives [1] [5] <ref> [12] </ref> [2] find the lens distortion without needing to find the external parameters or the other internal camera parameters. One or more images can be used. Unknown world coordinates: Stein [12], and Du and Brady [3] use corresponding points or edges in images where the camera has undergone pure rotation to find the internal camera parameters including lens distortion. The 3D location of the points is not required. 3 Mathematical background This paper uses results from projective geometry. <p> y u = y d + y 0 0 2 0 4 where K 1 and K 2 are the first and second parameters of radial distortion and: r d = x d + y d = (x 2 d c yr ) 2 (7) It has been shown in <ref> [12] </ref> that allowing the center of radial distortion, (c xr ; c yr ) to be different from the principal point is a good approximation to adding the terms for decentering distortion as given in [8]. 4 The algorithm The step by step algorithm is as follows: 1.
Reference: [13] <author> Weng, J et al. </author> <title> "Camera Calibration with Distortion Models and Accuracy Evaluation" IEEE Trans. </title> <note> PAMI 14,965-980 (1992) </note>
Reference-contexts: Using iterative methods it then finds both external and internal camera parameters. The external camera parameters are the position and orientation of each camera. The internal camera parameters include the parameters of the pinhole camera model (principal point, principal distance) and the parameters of lens distortion. Weng et al. <ref> [13] </ref> also use a known calibration object and iteratively solve for the external and internal parameters including the distortion parameters. Projective constraints: Under perspective projection, straight lines in space project to straight lines in the image. With real lenses the lines appear instead to be slightly to moderately curved.
Reference: [14] <author> Young, J.W., </author> <title> Projective Geometry, </title> <journal> The Mathematical Society of America, </journal> <year> (1930) </year> <month> 8 </month>
Reference-contexts: The 3D location of the points is not required. 3 Mathematical background This paper uses results from projective geometry. A very readable introduction to the subject of Projective Geometry is given in the book by Young <ref> [14] </ref>. A modern book dealing more specifically with the application of Projective Geometry to computer vision is [4]. I will use the following notation. The point in 3D projective space (P 3 ) will be represented by M i where the subscript i denotes the i'th point.
References-found: 14

