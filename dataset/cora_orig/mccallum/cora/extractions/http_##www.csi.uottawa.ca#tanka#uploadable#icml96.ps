URL: http://www.csi.uottawa.ca/tanka/uploadable/icml96.ps
Refering-URL: http://www.csi.uottawa.ca/tanka/papers.html
Root-URL: 
Email: stan@csi.uottawa.ca trouget@csi.uottawa.ca  
Phone: tel. +1 613 562 5800 ext. 6679 fax: +1 613 562 5187  
Title: Explainable Induction with an Imperfect Qualitative Model Explainable Induction with an Imperfect Qualitative Model  
Author: Stan Matwin Thierry Rouget 
Address: Ottawa, Canada K1N 6N5  
Affiliation: Ottawa Machine Learning Group Department of Computer Science University of Ottawa  
Abstract: This paper addresses the problem of learning concept descriptions that are interpretable, or explainable. Explainability is understood as the ability to justify the learned concept in terms of the existing background knowledge. The starting point for the work was an existing system that would induce only fully explainable rules. The system performed well when the model used during induction was complete and correct. In practice, however, models are likely to be incomplete and incorrect. We report here a new approach that achieves explainability with models that are incomplete or inconsistent, or both. The basis of the system is the standard inductive search driven by an accuracy-oriented heuristic, biased towards rule explainability. The bias is abandoned when there is heuristic evidence that a significant loss of accuracy results from constraining the search to explainable rules only. The user can express their relative preference for accuracy vs. explainability. Experiments with the system indicate that, even with a partially incomplete and/or incorrect model, insisting on explainability results in only a small loss of accuracy. We also show how the new approach described can repair a faulty model using evidence derived from data during induction. 
Abstract-found: 1
Intro-found: 1
Reference: [Aha Riddle 95] <author> Aha, D., Riddle, P., </author> <title> Working Notes for Applying ML in Practice: A Workshop of the 12yh ICML, </title> <type> TR AIC 95-023, </type> <institution> Washington, DC, Naval Research Labs, </institution> <year> 1995. </year>
Reference: [Bratko 95] <author> Bratko, I., </author> <title> Machine Learning: Between Accuracy and Interpretability, in [Aha and Riddle 95], </title> <editor> p. </editor> <booktitle> vii, </booktitle> <year> 1995. </year> <title> Explainable Induction with an Imperfect Qualitative Model 14 </title>
Reference: [Bratko et al., 1989] <author> Bratko, I., Mozetic, I., and Lavrac, N. Kardio: </author> <title> A Study in Deep and Qualitative Knowledge for Expert Systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Ma. </address>
Reference: [Clark and Boswell, 1991] <author> Clark, P. and Boswell, R. </author> <title> Rule induction with CN2: Some recent improvements. </title> <editor> In Kodratoff, Y, editor, </editor> <booktitle> Machine Learning - EWSL-91, </booktitle> <address> pp151-163, Berlin. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Explainable Induction with an Imperfect Qualitative Model 5 Independently of the model, a simple numeric system written in Prolog was used to simulate the system's behavior with time and to generate data for learning. 3. Model-only Biased Search The inductive algorithm we use is the latest version of CN2 <ref> [Clark and Niblett, 1989; Clark and Boswell, 1991] </ref>. It induces an ordered list of classification rules from examples, by relying on Laplaces error estimate as its search heuristic. <p> Obviously, this evaluation has to be done only on training data. We decided to rely on Laplace expected accuracy, which estimates what the predictive accuracy of a candidate rule will be on unseen data and which is also CN2s search heuristic. <ref> [Clark and Boswell, 1991] </ref> discuss the advantages of using the Laplace expected accuracy in rule induction, instead of the information gain measure [C4.5]. During induction of a particular rule, only explainable specializations are considered at first.
Reference: [Clark and Matwin, 1993a] <author> Clark, P. and Matwin, S. </author> <title> Using qualitative models to guide inductive learning. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <address> pp49-56, Amherst, MA. </address>
Reference-contexts: We use a qualitative model to represent the system under study and to guide an inductive search toward rules which are explainable with respect to this qualitative model. Our earlier work <ref> [Clark and Matwin, 1993a, Clark and Matwin, 1993b] </ref> described the first attempt at learning explainable rules in the presence of a qualitative model.
Reference: [Clark and Matwin, 1993b] <author> Clark, P., Matwin, S., </author> <title> Learning Domain Theories Using Abstract Background Knowledge, Machine Learning: </title> <editor> ECML-93, P. Brazdil, </editor> <publisher> ed., </publisher> <pages> pp. 360-365, </pages> <year> 1995. </year>
Reference-contexts: We use a qualitative model to represent the system under study and to guide an inductive search toward rules which are explainable with respect to this qualitative model. Our earlier work <ref> [Clark and Matwin, 1993a, Clark and Matwin, 1993b] </ref> described the first attempt at learning explainable rules in the presence of a qualitative model.
Reference: [Clark and Niblett, 1989] <author> Clark, P. and Niblett, T. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning Journal, </journal> <volume> 3(4), </volume> <month> pp261-283. </month>
Reference-contexts: Explainable Induction with an Imperfect Qualitative Model 5 Independently of the model, a simple numeric system written in Prolog was used to simulate the system's behavior with time and to generate data for learning. 3. Model-only Biased Search The inductive algorithm we use is the latest version of CN2 <ref> [Clark and Niblett, 1989; Clark and Boswell, 1991] </ref>. It induces an ordered list of classification rules from examples, by relying on Laplaces error estimate as its search heuristic.
Reference: [Evans and Fisher, 1993] <author> Evans, R. R. and Fisher, D. </author> <title> Overcoming process delays with decision tree induction. </title> <journal> IEEE Expert, </journal> <volume> 9(1), </volume> <month> pp60-66. </month>
Reference: [Forbus, 1984] <author> Forbus, K. D. </author> <title> Qualitative process theory. </title> <journal> Artificial Intelligence, </journal> <volume> 24, </volume> <month> pp85-168. </month>
Reference: [JKTech Ltd., 1991] <institution> The JKSimMet Steady State Mineral Processing Simulator. JKTech, QLD, Australia. </institution> <note> [deKleer 92] deKleer, </note> <author> J., </author> <title> Qualitative Physics, in Encyclopedia of AI, </title> <editor> S. Shapiro, </editor> <publisher> ed., </publisher> <pages> pp. 1149-1158, </pages> <publisher> Wiley, </publisher> <year> 1992. </year>
Reference: [Kuipers 95] <author> Kuipers, B., </author> <title> Qualitative Reasoning, </title> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: The focus there, however, was on exploiting domain knowledge for accuracy, rather than explainability of the results of learning. We decided to work on obtaining explainable and accurate rules that classify concepts related to operations of systems for which there are qualitative models in the sense of [Forbus 84], <ref> [Kuipers 95] </ref>. We use a qualitative model to represent the system under study and to guide an inductive search toward rules which are explainable with respect to this qualitative model.
Reference: [Marchand, 1995] <author> Marchand. </author> <title> Industrial Experiences in Comprehensibility. </title> <booktitle> IJCAI95 Workshop in Machine Learning and Comprehensability, </booktitle> <address> pp125-131. </address>
Reference: [Michalski et al. 86] <author> Michalski, R., Mozetic, I. Hong., J., Lavrac, N., </author> <title> The multipurpose Incremental Learning System AQ15 and its testing application to three medical domains, Procs. </title> <booktitle> of the Fifth AAAI, </booktitle> <pages> pp. </pages> <address> a1041-1054, </address> <year> 1986. </year>
Reference-contexts: 1. Introduction Classical inductive systems [Quinlan 93], <ref> [Michalski et al. 86] </ref>, [Clark and Niblett 85] rely on data, and on data alone, to generate the learned concept description. For the last several years, however, there is a growing focus in the machine learning community on interpretability of the inductively learned rules.
Reference: [Ortega and Fisher, 1995] <author> Ortega, J. and Fisher, D. </author> <title> Flexibly exploiting prior knowledge in empirical learning. </title> <booktitle> International Joint Conferences on Artificial Intelligence 1995 (IJCAII). </booktitle>
Reference: [Quinlan, 1993] <author> Quinlan, J. R. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA. </address>
Reference: [Rouget, 1995] <author> Rouget, T. </author> <title> Learning Explainable Concepts in the Presence of a Qualitative Model. </title> <type> Masters thesis, </type> <institution> Department of Computer Science, University of Ottawa, </institution> <note> available at http://csi.uottawa.ca/~trouget/thesis </note>
References-found: 16

