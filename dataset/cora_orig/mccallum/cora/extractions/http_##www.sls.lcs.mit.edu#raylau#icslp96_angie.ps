URL: http://www.sls.lcs.mit.edu/raylau/icslp96_angie.ps
Refering-URL: http://www.sls.lcs.mit.edu/raylau/publications.html
Root-URL: 
Title: ANGIE: A NEW FRAMEWORK FOR SPEECH ANALYSIS BASED ON MORPHO-PHONOLOGICAL MODELLING 1  
Author: Stephanie Seneff, Raymond Lau, and Helen Meng 
Web: http://www.sls.lcs.mit.edu  
Address: Cambridge, MA 02139, USA  
Affiliation: Spoken Language Systems Group Laboratory for Computer Science Massachusetts Institute of Technology  
Abstract: This paper describes a new system for speech analysis, ANGIE, which characterizes word substructure in terms of a trainable grammar. ANGIE capture morpho-phonemic and phonological phenomena through a hierarchical framework. The terminal categories can be alternately letters or phone units, yielding a reversible letter-to-sound/sound-to-letter system. In conjunction with a segment network and acoustic phone models, the system can produce phonemic-to-phonetic alignments for speech waveforms. For speech recognition, ANGIE uses a one-pass bottom-up best-first search strategy. Evaluated in the ATIS domain, ANGIE achieveda phone error rate of 36%, as compared with 40% achieved with a baseline phone-bigram based recognizer under similar conditions. ANGIE potentially offers many attractive features, including dynamic vocabulary adaptation, as well as a framework for handling unknown words. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <editor> Dahl, D. et al., </editor> <title> Expanding the Scope of the ATIS Task: the ATIS-3 Corpus, </title> <booktitle> Proc. ARPA Human Language Technology Workshop, </booktitle> <pages> pp. 43-48, </pages> <address> Plainsboro, NJ, </address> <month> March, </month> <year> 1994. </year>
Reference-contexts: An example parse tree with phone terminals is shown in Figure 2. Probabilities are currently trained on some 10,000 utterances from the ATIS corpus <ref> [1, 2] </ref>, seeded on forced alignments obtained using our SUMMIT recognizer [7], and subsequently iterated. Per-phone perplexity for training/test conditions is around 5.7 and 7.0 respectively, which is substantially lower than corresponding bigram phone perplexities. 6 Brackets indicate optional and parentheses enclose alternates. 5. <p> Recognition Experiments To date, all of our recognition experiments have been conducted in the ATIS [2] domain, and we have limited our training and test data to a subset of the ATIS3 corpus <ref> [1] </ref>. Thus far, we have been conducting experiments at the level of phonetic recognition, where the lexicon is only used implicitly to train the ANGIE subword models, i.e., the ANGIE probabilities are trained on a set of phonetic sequencesas-sociated with orthographic transcriptions for ATIS sentences.
Reference: 2. <author> Glass, J. et al., </author> <title> The MIT ATIS System: December 1994 Progress Report, </title> <booktitle> Proc. ARPA Spoken Language Technology Workshop, </booktitle> <pages> pp. 252-256, </pages> <address> Austin, TX, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: An example parse tree with phone terminals is shown in Figure 2. Probabilities are currently trained on some 10,000 utterances from the ATIS corpus <ref> [1, 2] </ref>, seeded on forced alignments obtained using our SUMMIT recognizer [7], and subsequently iterated. Per-phone perplexity for training/test conditions is around 5.7 and 7.0 respectively, which is substantially lower than corresponding bigram phone perplexities. 6 Brackets indicate optional and parentheses enclose alternates. 5. <p> We may eventually decide to incorporate some sort of future estimate, although we find the idea of no look-ahead appealing. 5.1. Recognition Experiments To date, all of our recognition experiments have been conducted in the ATIS <ref> [2] </ref> domain, and we have limited our training and test data to a subset of the ATIS3 corpus [1].
Reference: 3. <author> Goddeau, D. et al, </author> <title> GALAXY: A Human Language Interface to Online Travel Information, </title> <booktitle> Proc. ICSLP-94, </booktitle> <pages> pp. 707-710, </pages> <address> Yokohama, Japan, </address> <year> 1994. </year>
Reference-contexts: We will then move on to continuous speech recognition, focusing on issues of search, computation, and memory. Ultimately, we hope to use ANGIE in a conversational system, such as our GALAXY system <ref> [3] </ref>, enabling us to tag and discard unknown words, as well as adjusting the vocabulary transparently to reflect dialogue context.
Reference: 4. <author> Hetherington, L and M. McCandless, SAPPHIRE: </author> <title> An Extensible Speech Analysis and Recognition tool base on Tcl/Tk, </title> <booktitle> These Proceedings, </booktitle> <year> 1996. </year>
Reference-contexts: Thus, for example, the ay in the word I is much more likely to be reduced than is ay in general. I'm interested. Our phone set has evolved over time, and is likely to change. The choices were made empirically by examining phonemic-to-phonetic alignments using our new SAPPHIRE tool <ref> [4] </ref>. A few context-dependent units were chosen for cases where context effects were strong and there was sufficient context-specific data to build a robust model. Thus, both alveolar stops can be realized as a $dx (flap) phone, usually within intervocalic environments.
Reference: 5. <author> Lee, K., </author> <title> Large Vocabulary Speaker-independent Continuous Speech Recognition: The Sphinx System, </title> <type> Ph.D. Thesis, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1988. </year>
Reference-contexts: The models were Gaussian mixtures averaged over left, middle and right thirds of each segment, as well as delta Gauassian mixtures over the left and right boundaries. The two systems had somewhat different phone sets, but in both cases we collapsed down to the standard 39 CMU phone set <ref> [5] </ref>. In place of ANGIE's subword language model, the baseline system used a phone bigram, derived from its own training phonetic alignments. Neither system had a lexicon, but ANGIE proposed word-ends periodically, segmenting the phones into a sequence of pseudo-words.
Reference: 6. <author> Meng, H. M., </author> <title> Phonological Parsing for Bi-directional Letter-to-Sound / Sound-to-Letter Generation, </title> <type> Ph.D. Thesis, </type> <institution> MIT Department of Electrical Engineering and Computer Science, Cambridge, Massachusetts, </institution> <year> 1995. </year>
Reference-contexts: The bottom-most layer consists of letter terminals in sound-to-letter/letter-to-sound generation, changing to phone terminals for phoneme-to-phone alignment and speech recognition. 2. LINGUISTIC MODEL ANGIE's approach is similar to that reported in <ref> [6] </ref>. A significant difference is that we have attempted to reduce the parameter space, both by decreasing the total number of layers in the hierarchy, and by restricting the context conditions for column 2 building. <p> The null terminal in <ref> [6] </ref> has been replaced with deletable units marked explicitly for their left context. Most of the remaining nonterminal categories are generic units such as UROOT and CODA, but we do include over twenty special inflexional suffixes. 3. LETTER-TO-SOUND GENERATION ANGIE's letter-to-sound generation system bears close resemblance to that described in [6]. <p> <ref> [6] </ref> has been replaced with deletable units marked explicitly for their left context. Most of the remaining nonterminal categories are generic units such as UROOT and CODA, but we do include over twenty special inflexional suffixes. 3. LETTER-TO-SOUND GENERATION ANGIE's letter-to-sound generation system bears close resemblance to that described in [6]. A probabilistic parsing algorithm is used to parse the letters of an input word, and the pronunciation is derived from the phoneme sequenceat the preterminal layer in the parse tree. <p> Such an approach is less time-consuming and more portable than would be the process of hand-selecting the appropriate training parse tree. Our experiments were conducted with the same high frequency 4 In <ref> [6] </ref> we conditioned on the entire column above the left-sibling. <p> l! iy er envelope eh+ n v! el ow+ p eh n v! el+ ah p exploited eh k s p! l oy+ t d*ed eh k s p! l ow+ ih t d*ed Table 2: Examples of pronunciation generation errors words in the Brown Corpus that were used in <ref> [6] </ref>. About 8,000 words are used for training, and a disjoint set of 872 utterances for testing. <p> The accuracy score takes into account substitutions, deletions, and insertions. None of the test-set words failed to parse, indicating that our more generalized grammar was effective. While these results appear to be somewhat inferior to those reported in <ref> [6] </ref>, it should be noted that the latter experiment used a smaller set of phonemic distinctions (55 categories as against our 75). <p> Test performance improves to 69.4% per word, 91.5% per phoneme accuracy if we add the following forgivable confusions: eh/ih (as a combined front schwa); eh/eh+, ih/ih+, er/er+, el/l, and en/n. 5 This result is slightly better than the 69.2%, 91.3% result reported in <ref> [6] </ref>, obtained with full coverage after a backoff algorithm recovered parse failures. Table 2 shows some examples of letter-to-sound errors. An incorrect stress pattern is the source of many of the errors, which perhaps calls for special treatment of the stress pattern. <p> The best scoring hypothesis was selected from the first five completed theories. Our results (53.2% per word, 89.2% per phoneme) are comparable to those reported in <ref> [6] </ref> (53.5% per word, 88.5% per letter). 4. PHONOLOGICAL RULES When the terminals are phones instead of letters, the grammar defines a set of probabilistic phonological rules. Phonological rules are written without specifying context explicitly.
Reference: 7. <author> Zue, V. et al., </author> <title> The MIT SUMMIT Speech Recognition System: Phonological Modelling and Lexical Access, </title> <booktitle> Proc. ICASSP-90, </booktitle> <pages> pp. 49-52, </pages> <address> Al-buquerque, NM, </address> <month> May, </month> <year> 1990. </year>
Reference-contexts: An example parse tree with phone terminals is shown in Figure 2. Probabilities are currently trained on some 10,000 utterances from the ATIS corpus [1, 2], seeded on forced alignments obtained using our SUMMIT recognizer <ref> [7] </ref>, and subsequently iterated. Per-phone perplexity for training/test conditions is around 5.7 and 7.0 respectively, which is substantially lower than corresponding bigram phone perplexities. 6 Brackets indicate optional and parentheses enclose alternates. 5. <p> SPEECH RECOGNITION Many current speech recognition systems handle phonological variation either by generating a pronunciation graph for each word (such as MIT's SUMMIT system) <ref> [7] </ref> or by implicitly absorbing the variations into a hidden Markov model. The former has the disadvantage of not sharing common subword structure, hence splitting training data. The latter makes it difficult to control and improve upon phonological modelling.
References-found: 7

