URL: ftp://ftp.cs.columbia.edu/reports/reports-1994/cucs-034-94.ps
Refering-URL: http://www.cs.columbia.edu/~library/1994.html
Root-URL: http://www.cs.columbia.edu
Title: Revision-Based Generation of Natural Language Summaries Providing Historical Background Corpus-Based Analysis, Design, Implementation and Evaluation  
Author: Jacques Robin 
Degree: in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the Graduate School of Arts and Sciences  
Affiliation: Columbia University  
Date: Submitted  December 1994  
Pubnum: Technical Report CUCS-034-94  
Abstract-found: 0
Intro-found: 1
Reference: [ Abella 1994 ] <author> A. Abella. </author> <title> From pictures to words: generating locative descriptions of objects in an image. </title> <booktitle> In Proceedings of the Image Understanding Workshop, Monterrey, </booktitle> <address> CA, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: The version of surge resulting from these extensions has since been used for other generation applications in addition to streak: automated documentation for the activity of telephone network planning engineers [ Kukich et al. 1994 ] , verbal descriptions of visual scenes <ref> [ Abella 1994 ] </ref> and generation of business letters. The two sets of extensions to the fuf/surge package are described in detail Appendix B. They were essentially preparatory work paving the way for development of streak as a prototype for a particular application. The present chapter describes this development itself. <p> The version of surge resulting from these extensions has since been used for other generation applications in addition to streak: automated documentation for the activity of telephone network planning engineers [ Kukich et al. 1994 ] , verbal descriptions of visual scenes <ref> [ Abella 1994 ] </ref> and generation of business letters. In what follows, I first give an overview of fuf (Functional Unification Formalism) as a programming language, including the extensions for non-monotonic processing prompted by the development of streak. <p> The extended surge-2.0 has since been used for the development of several others generation applications at Columbia University including automated documentation [ Kukich et al. 1994 ] , verbal descriptions of visual scenes <ref> [ Abella 1994 ] </ref> and business letters. The extensive coverage of adverbial complements provided by surge-2.0, proved extremely useful in these three other domains.
Reference: [ Anderson 1985 ] <author> D. Anderson. </author> <title> Contemporary sports reporting. </title> <address> Nelson-Hall, Chicago, IL, </address> <year> 1985. </year>
Reference-contexts: In this report, fine-grained statistics not available in the box-score, such as performances over a short time interval during the game, are emphasized by an italic font (historical information is, as usual, emphasized by a boldface font). Such finer grained statistics come from complete game charts <ref> [ Anderson 1985 ] </ref> . Box-scores are available on-line through newswire and sport statistic computer services, whereas game charts are not 5 . Therefore, only box-scores constitute a realistic tabular input for a report generation system.
Reference: [ Andre et al. 1993 ] <author> E. Andre, W. Finkler, T. Graf, A. Rist, A. Schauder, and W. Wahlster. WIP, </author> <title> the automatic synthesis of multimedia presentation. </title> <editor> In M. Maybury, editor, </editor> <title> Intelligent Multimedia Interfaces. </title> <publisher> AAAI Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: This decomposition parallels the division in surge between the grammar proper and the linearizer (cf. Section B.2.1 of Appendix B). LD/LP TAGs have been used in the multi-media presentation system wip <ref> [ Andre et al. 1993 ] </ref> [ Wahlster et al. 1993 ] . This system generates both graphics and natural language to provide explanations on how to operate an esspresso machine.
Reference: [ Appelt 1985 ] <author> D. Appelt. </author> <title> Planning Natural Language Utterances. </title> <booktitle> Studies in Natural Language Processing. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1985. </year>
Reference-contexts: While both generate summaries, the former is representative of the class of microcoded generators that also includes fog [ Bourbeau et al. 1990 ] , lfs [ Iordanskaja et al. 1994 ] , kamp <ref> [ Appelt 1985 ] </ref> , kalipsos [ Nogier 1990 ] , fn [ Reiter 1991 ] , epicure [ Dale 1992 ] , igen [ Rubinoff 1992 ] , comet [ McKeown et al. 1990 ] , avdisorII [ Elhadad 1993b ] and plandoc [ Kukich et al. 1994 ] while <p> for the generation of complex written sentences. 1.2.2 A corpus analysis to acquire revision rules In order to handle supplementary content opportunistically, the new generation model described above requires the acquisition of a new type of linguistic knowledge structure: revision operations specifying the 14 Much publicized in the research literature <ref> [ Appelt 1985 ] </ref> [ Danlos 1986 ] [ Meteer 1990 ] [ Rubinoff 1992 ] yet of marginal significance in most practical applications as pointed out by [ Reiter 1994 ] . 10 Complex sentence S 2 containing two floating facts: "Houston, TX Buck Johnson scored a season high 26 <p> It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (functional descriptions) to represent utterances at all levels of abstraction and all linguistic ranks [ Simonin 1985 ] [ Dale 1992 ] [ Elhadad 1993b ] . * It interleaves planning and realization <ref> [ Appelt 1985 ] </ref> [ Hovy 1988 ] . 7.1.3 Contributions to revision-based generation and incremental generation The major contribution of this thesis to revision-based generation and incremental generation is the extensive set of revision rules to incrementally incorporate quantitative and historical data in a given draft expressing related information.
Reference: [ Bateman et al. 1990 ] <author> J.A. Bateman, R.T. Kasper, J.D. Moore, and R.A. Whitney. </author> <title> A general organization of knowledge for natural language processing: the PENMAN Upper-Model. </title> <type> Technical report, ISI, </type> <institution> Marina del Rey, </institution> <address> CA, </address> <year> 1990. </year>
Reference-contexts: This identity can be captured only by a purely conceptual representation that totally abstracts from linguistic form. A linguistically motivated semantic representation such as penman's Upper-Model <ref> [ Bateman et al. 1990 ] </ref> , would view (X) as a material action and (Y) as a possessed object, two radically different semantic categories. It would thus fail to capture their identity of meaning. This contrast between conceptual and linguistic semantic representations is further discussed in Section 3.12. <p> If it is like an SSS, the domain knowledge of the generator must be encoded in terms of linguistically motivated categories. This is the approach advocated by penman's Upper-Model <ref> [ Bateman et al. 1990 ] </ref> , where the facts and entities of the domain knowledge base are viewed as instances of domain-independent categories defined in terms of linguistic ranks and thematic roles.
Reference: [ Borko 1975 ] <author> H. Borko. </author> <title> Abstracting Concepts and Methods. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1975. </year>
Reference-contexts: This sub-corpus of lead sentences was of manageable size for a systematic manual analysis and at the same time allowed focusing on the two main linguistic phenomenon of interest in this thesis: summarization and historical contextualization. In the literature about summarization (e.g., <ref> [ Borko 1975 ] </ref> ), an important distinction is made between indicative abstracts which provide meta-level information on the text itself (its goal, structure, style etc), and informative abstracts which express the content of the text in a less detailed and more compact form.
Reference: [ Bourbeau et al. 1990 ] <author> L. Bourbeau, D. Carcagno, E. Goldberg, R. Kittredge, and A. Polguere. </author> <title> Bilingual generation of weather forecasts in an operations environment. </title> <booktitle> In Proceedings of the 13th International Conference on Computational Linguistics, </booktitle> <address> Helsinki University, Finland, </address> <year> 1990. </year> <pages> COLING. </pages>
Reference-contexts: I also quantitatively evaluate the advantages of this new revision-based generation model over the one-pass model of previous generators 1 cf. fog <ref> [ Bourbeau et al. 1990 ] </ref> , see Section 6.1 for details. 2 The other system working as a real-world application is plandoc [ Kukich et al. 1994 ] [ McKeown et al. 1995 ] , which produces automated documentation for managers about the choices of telephone network planning engineers at <p> The sentences generated by such systems are thus microcoded from words conveying only one or two content units. gossip and ana (cf. table of Section 1.1.2.4) illustrate these two extremes. While both generate summaries, the former is representative of the class of microcoded generators that also includes fog <ref> [ Bourbeau et al. 1990 ] </ref> , lfs [ Iordanskaja et al. 1994 ] , kamp [ Appelt 1985 ] , kalipsos [ Nogier 1990 ] , fn [ Reiter 1991 ] , epicure [ Dale 1992 ] , igen [ Rubinoff 1992 ] , comet [ McKeown et al. 1990 <p> application (summary report generation) or approach to generation (revision-based or incremental) is directly related to those of streak. 6.1 Related work in summary report generation Prior to streak, six main systems generated natural language reports to summarize quantitative data: ana [ Kukich 1983 ] [ Kukich 1985 ] , fog <ref> [ Bourbeau et al. 1990 ] </ref> [ Polguere 1990 ] , gossip [ Carcagno and Iordanskaja 1993 ] , lfs [ Iordanskaja et al. 1994 ] , semtex [ Roesner 1987 ] , and sage [ Roth et al. 1991 ] . <p> The systems all use the Meaning-Text Theory (MTT) [ Mel'cuk and Pertsov 1987 ] as underlying linguistic model. The first of these system is fog <ref> [ Bourbeau et al. 1990 ] </ref> . It produces daily local marine weather bulletins, in both English and French, from meteorological measurements. An example English report generated by fog is given in Fig. 6.4.
Reference: [ Bresnan and Kaplan 1982 ] <author> J. Bresnan and R. Kaplan. </author> <title> Lexical Functional Grammars: a formal system for grammatical representation. </title> <editor> In J. Bresnan, editor, </editor> <title> The mental representation of grammatical relations. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1982. </year>
Reference-contexts: The use of functional unification was inspired by Functional Unification Grammars (FUGs) [ Kay 1979 ] . However, the resulting functional TAGs are even closer to Lexical Functional Grammars (LFGs) <ref> [ Bresnan and Kaplan 1982 ] </ref> , since they separate, on the one hand, dependency and precedence constraints represented by the trees, and on the other hand, the other types constraints represented by the feature structures, in very much the same way than LFGs.
Reference: [ Carcagno and Iordanskaja 1993 ] <author> D. Carcagno and L. Iordanskaja. </author> <title> Content determination and text structuring: two interrelated processes. </title> <editor> In H. Horacek and M. Zock, editors, </editor> <title> New Concepts in Natural Language Generation: Planning, Realization and Systems. </title> <publisher> Frances Pinter, </publisher> <address> London and New York, </address> <year> 1993. </year>
Reference-contexts: Grouping these ten facts in the complex lead of Fig. 1.1 allow collapsing these five occurrences in a single referring NP. The table below contrasts the complexity of two previous summary report generators 7 , gossip <ref> [ Carcagno and Iordanskaja 1993 ] </ref> and ana [ Kukich 1983 ] , with the complexity of the lead sentences in the corpus I analyzed. <p> directly related to those of streak. 6.1 Related work in summary report generation Prior to streak, six main systems generated natural language reports to summarize quantitative data: ana [ Kukich 1983 ] [ Kukich 1985 ] , fog [ Bourbeau et al. 1990 ] [ Polguere 1990 ] , gossip <ref> [ Carcagno and Iordanskaja 1993 ] </ref> , lfs [ Iordanskaja et al. 1994 ] , semtex [ Roesner 1987 ] , and sage [ Roth et al. 1991 ] . I briefly review each of these systems in the following subsections. <p> In terms of linguistic summarization, it relies on the telegraphic style peculiar to weather forecasts instead of relying on the clause combining journalistic style typical of newswires. The second of these systems is gossip <ref> [ Carcagno and Iordanskaja 1993 ] </ref> which summarizes the activity of computer users from the audit trail produced by the operating system of the machine they are logged on. Its input is intended to assist the system administrator in detecting system usage that is suspicious from a security standpoint. <p> * Instantiation of C into a fact from the input statistic database (if there is an instance of C in the input database). * Deletion of the N from the topic tree (if there is no instance of C in the input database). 3 Also in English and French. 143 <ref> [ Carcagno and Iordanskaja 1993 ] </ref> ) * Addition to the topic tree of new arcs and nodes added to the topic tree below N (these additions implements domain reasoning allowing the text planner to deduce additional facts from those present in the input). <p> The paraphrasing power implemented in gossip and lfs relies on lexical functions, but is limited to alternatives necessary to avoid repetitions within the same multi-clause sentences (cf. <ref> [ Carcagno and Iordanskaja 1993 ] </ref> p.1021). 6.2 Related work in revision-based generation In itself, the idea of revision in generation is not new.
Reference: [ Cline and Nutter 1991 ] <author> B.E. Cline and J.T. Nutter. </author> <title> Conceptual revision for natural language generation, </title> <booktitle> 1991. Student session of the 29th Annual Meeting of the ACL. </booktitle>
Reference-contexts: It has been proposed in different flavors by [ Mann 1983 ] , [ Vaughan and McDonald 1986 ] [ Meteer 1991 ] , [ Yazdani 1987 ] , [ Gabriel 1988 ] , [ Wong and Simmons 1988 ] <ref> [ Cline and Nutter 1991 ] </ref> and [ Inui et al. 1992 ] . However, only two implemented generation system emerged from these proposals: Gabriel's Yh and Inui et. al's weiveR. <p> Using spokesman levels of representation, revising to adjust the tradeoff between informativity, conciseness and readability, would require acting upon both the Text-Structure level and the Linguistic Specification level. Without being specific about the characteristics of the representation to revise, <ref> [ Cline and Nutter 1991 ] </ref> also stressed the need for a representation to reflect both content planning and surface realization decisions. [ Wong and Simmons 1988 ] advocate performing revision using a blackboard. <p> They are information-preserving revisions to make the draft more concise, clearer or more coherent. In contrast, streak performs information-adding revisions to make the draft more informative. <ref> [ Cline and Nutter 1991 ] </ref> propose performing both varieties of revisions.
Reference: [ Contant 1986 ] <author> C. Contant. </author> <title> Generation automatique de texte: application au sous-language boursier, 1986. M.A. </title> <type> thesis, </type> <institution> Universite de Montreal. </institution>
Reference-contexts: Existing systems have been developed for different domains and in the rare cases when several generators exist in the same domain, they use a different language (e.g., ana [ Kukich 1983 ] in English and frana <ref> [ Contant 1986 ] </ref> in French for the stock market domain). Different domains do not only mean different encyclopedic contexts but also different writing styles. Whereas a telegraphic style is well-suited for a weather forecast it would be completely inappropriate for a business letter. <p> As the test domain for this evaluation, I chose the stock market for two reasons: (1) large textual corpora of reports in this domain are available from newswires and (2) it has been the object of several language generation projects [ Kukich 1983 ] <ref> [ Contant 1986 ] </ref> [ Smadja 1991 ] . The test corpus consisted of reports on the American, Asian and European stock markets by UPI, AP and Reuter compiled from the newsreader. Its size was about 445,000 words.
Reference: [ Dale 1992 ] <author> R. Dale. </author> <title> Generating Referring Expressions. </title> <booktitle> ACL-MIT Press Series in Natural Language Processing, </booktitle> <address> Cambridge, Ma., </address> <year> 1992. </year>
Reference-contexts: generate summaries, the former is representative of the class of microcoded generators that also includes fog [ Bourbeau et al. 1990 ] , lfs [ Iordanskaja et al. 1994 ] , kamp [ Appelt 1985 ] , kalipsos [ Nogier 1990 ] , fn [ Reiter 1991 ] , epicure <ref> [ Dale 1992 ] </ref> , igen [ Rubinoff 1992 ] , comet [ McKeown et al. 1990 ] , avdisorII [ Elhadad 1993b ] and plandoc [ Kukich et al. 1994 ] while the latter is representative of the class of macrocoded generators that also includes Danlos' generator [ Danlos 1986 <p> What each generation subtask covers depends on the level of microcoding at which generation is performed. A macrocoded generator like ana [ Kukich 1983 ] produces sentences by assembling entire clauses and group patterns stored as a whole in its phrasal lexicon. In contrast, a microcoded generator like epicure <ref> [ Dale 1992 ] </ref> dynamically builds from a word-based lexicon 1 every sentence constituent down to the group rank. The level of microcoding is defined by the minimal linguistic rank of the entries stored in the generator's lexicon. <p> The architecture thus belongs to the stratificational tradition of computational linguistics (cf. <ref> [ Dale 1992 ] </ref> and [ Polguere 1990 ] for other generation systems using a stratificational utterance representation scheme), with multiple representation layers, each capturing a specific set of regularities. The general stratificational scheme I propose is sketched in Fig. 3.3. <p> Another use for a double semantic representation is to distinguish between implicit and explicit realization of content as already discussed in Section 3.4. <ref> [ Dale 1992 ] </ref> adopted a double semantic representation in epicure specifically for such purpose. 3.3.2 Processing components and overall control As shown in Fig. 3.13 there are six components in the new generation architecture I propose: the fact generator, the discourse planner, the phrase planner, the lexicalizer, the reviser and <p> It uses declarative knowledge sources [ Nogier 1990 ] [ Polguere 1990 ] . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (functional descriptions) to represent utterances at all levels of abstraction and all linguistic ranks [ Simonin 1985 ] <ref> [ Dale 1992 ] </ref> [ Elhadad 1993b ] . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy 1988 ] . 7.1.3 Contributions to revision-based generation and incremental generation The major contribution of this thesis to revision-based generation and incremental generation is the extensive set of revision rules
Reference: [ Danlos 1986 ] <author> L. Danlos. </author> <title> The linguistic basis of text generation. </title> <booktitle> Studies in Natural Language Processing. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1986. </year>
Reference-contexts: Other systems that generate reports that are not specifically summaries, can avoid generating very complex sentences since they are under no pressure to be concise. Two such systems, Danlos' generator <ref> [ Danlos 1986 ] </ref> and pauline [ Hovy 1988 ] , generate sentences of a complexity 6 As paradoxical as it may first sound. 7 cf. <p> , epicure [ Dale 1992 ] , igen [ Rubinoff 1992 ] , comet [ McKeown et al. 1990 ] , avdisorII [ Elhadad 1993b ] and plandoc [ Kukich et al. 1994 ] while the latter is representative of the class of macrocoded generators that also includes Danlos' generator <ref> [ Danlos 1986 ] </ref> , phred [ Jacobs 1985 ] , pauline [ Hovy 1988 ] , semtex [ Roesner 1987 ] and weiver [ Inui et al. 1992 ] . <p> complex written sentences. 1.2.2 A corpus analysis to acquire revision rules In order to handle supplementary content opportunistically, the new generation model described above requires the acquisition of a new type of linguistic knowledge structure: revision operations specifying the 14 Much publicized in the research literature [ Appelt 1985 ] <ref> [ Danlos 1986 ] </ref> [ Meteer 1990 ] [ Rubinoff 1992 ] yet of marginal significance in most practical applications as pointed out by [ Reiter 1994 ] . 10 Complex sentence S 2 containing two floating facts: "Houston, TX Buck Johnson scored a season high 26 points Thursday night and <p> I briefly review each of these systems in the following subsections. Other generation systems that produced reports are not directly relevant to the present thesis, because the reports are not specifically summaries and because they worked in qualitative domains (e.g., Danlos' generator <ref> [ Danlos 1986 ] </ref> , pauline [ Hovy 1988 ] , Kalita's system [ Kalita 1989 ] , texplan [ Maybury 1990 ] ).
Reference: [ Davey 1978 ] <author> A. Davey. </author> <title> Discourse production. </title> <publisher> Edinburgh University Press, </publisher> <year> 1978. </year>
Reference-contexts: Yh takes as input an abstract description of a lisp program playing this game and generates a paragraph describing the code. Since Yh describes the code itself and not its execution (as in <ref> [ Davey 1978 ] </ref> for example) and since Yh does not include a module performing domain reasoning ( [ Gabriel 1988 ] , p.29) the input to Yh is the same for all its runs.
Reference: [ De Smedt and Kempen 1987 ] <author> K. De Smedt and G. Kempen. </author> <title> Incremental sentence production, self-correction and coordination. </title> <editor> In Gerard Kempen, editor, </editor> <booktitle> Natural Language Generation: New Results in Artificial Intellligence, Psychology and Linguistics. </booktitle> <publisher> Martinus Ninjhoff Publishers, </publisher> <year> 1987. </year> <month> 352 </month>
Reference-contexts: The research presented in this thesis is thus best viewed as bringing insights to the problem of incremental generation that nicely complement those of TAG-centered research. 6.3.2 Incremental generation in IPF Aside from the TAG-based approaches, another line of research in incremental generation is due to <ref> [ De Smedt and Kempen 1987 ] </ref> and [ De Smedt 1990 ] . It is encapsulated in the system ipf (Incremental Parallel Formulator). ipf and streak investigate incremental generation topics that are almost entirely mutually exclusive. <p> Within the grammar, ipf separates the expression of dependency and precedence constraints and is lexically driven. It thus seems very close to the LD/LP lexicalized TAGs used in wip and discussed in the previous section. In <ref> [ De Smedt and Kempen 1987 ] </ref> , the authors distinguish between six types of incremental additions to sentence structure during speech production 26 : 1. upward expansion, where the added fragment dominates the base fragment, e.g., "John and Mary are". 2. downward expansion, where the base fragment dominates the added
Reference: [ De Smedt 1990 ] <author> K. De Smedt. IPF: </author> <title> an incremental parallel formulator. </title> <editor> In R. Dale, C.S. Mellish, and M. Zock, editors, </editor> <booktitle> Current Research in Natural Language Generation. </booktitle> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: in the next section. 6.3 Related work in incremental generation Incremental generation has been investigated from three main perspectives: the AI perspective of Yh already described in the previous section, the syntactic perspective of Tree Adjoining Grammars [ Joshi et al. 1975 ] and the cognitive modelling perspective of ipf <ref> [ De Smedt 1990 ] </ref> . <p> this thesis is thus best viewed as bringing insights to the problem of incremental generation that nicely complement those of TAG-centered research. 6.3.2 Incremental generation in IPF Aside from the TAG-based approaches, another line of research in incremental generation is due to [ De Smedt and Kempen 1987 ] and <ref> [ De Smedt 1990 ] </ref> . It is encapsulated in the system ipf (Incremental Parallel Formulator). ipf and streak investigate incremental generation topics that are almost entirely mutually exclusive.
Reference: [ Duford 1993 ] <author> D. Duford. CREP: </author> <title> a regular expression-matching textual corpus tool. </title> <type> Technical Report CUCS-005-93, </type> <institution> Columbia University, </institution> <year> 1993. </year>
Reference-contexts: This task was partially automated by approximating the source and target realization patterns of each revision rule by a regular expression of words and parts-of-speech tags. All the test corpus sentences matching a given expression were then automatically retrieved a software tool called crep (cf. Appendix D and <ref> [ Duford 1993 ] </ref> ) specifically designed for this purpose. Filtering out the incorrect matches resulting from imperfect approximations was then done by manual post-edition. <p> In our present context, this means that only substep (2a) could be automated. To address this need, I initiated and supervised the development of crep <ref> [ Duford 1993 ] </ref> a system that retrieves in a corpus all the sentences containing a lexico-syntactic pattern specified as a regular expression of words and/or part-of-speech tags. crep was implemented by Duford. A brief, self-contained presentation of this software tool is given in Appendix D. <p> This technique is discussed both in Section D.1 of Appendix D and in Section 5.3.2 of the crep manual <ref> [ Duford 1993 ] </ref> . Porting a crep expression from one domain to another did not just involve accounting for the conceptual and lexical discrepancies just presented. It also required attention to details like minor rhetorical discrepancies which can prevent crep expression from matching the desired corpus sentences. <p> This option also allows simulation of 'at most one', 'exactly one' and 'zero' (i.e.,, negation) semantics with respect to the number of input expression matches inside a sentence (the default semantics being 'at least one'). * An option to overwrite the built in sentence delimiter using declarative rules. See <ref> [ Duford 1993 ] </ref> for a detailed presentation of these operators and options with many examples. D.2 Using CREP for lexical knowledge acquisition Its flexibility and user-friendliness make crep a very useful tool at any point during the development of a corpus-based language generation application.
Reference: [ Elhadad and Robin 1992 ] <author> M. Elhadad and J. Robin. </author> <title> Controlling Content Realization with Functional Unification Grammars. </title> <editor> In R. Dale, H. Hovy, D. Roesner, and O. Stock, editors, </editor> <booktitle> Aspects of Automated Natural Language Generation, </booktitle> <pages> pages 89-104. </pages> <publisher> Springler Verlag, </publisher> <year> 1992. </year>
Reference-contexts: This 45 issue of enriching the DSS on demand during linguistic realization and the implementation of a facility for such process within the generation framework of functional unification is discussed in detail in <ref> [ Elhadad and Robin 1992 ] </ref> . During the implementation of the generator streak, I discovered that for the particular sports game summarization application of this system, this facility was not really needed and thus did not make use of it. <p> In fact, the multi-layered FD representing the draft in streak can be viewed as a blackboard (cf. <ref> [ Elhadad and Robin 1992 ] </ref> for a discussion of the special control mechanisms of fuf that render FDs blackboard-like). 14 Note that Meteer's proposal is for future work. <p> B.1 The FUF programming language fuf [ Elhadad 1993b ] [ Elhadad 1993a ] is a special-purpose programming language for developing language generation applications. It is an extension (cf. [ Elhadad 1990 ] <ref> [ Elhadad and Robin 1992 ] </ref> ) of the initial functional grammar formalism initiated by [ Kay 1979 ] . Originally, functional grammars where used to implement only two generation subtasks: morpho-syntactic grammaticalization and linearization. <p> A third meta-attribute opt (meaning OPTional) is used as an abbreviation for the simplest types of disjunctions: ((opt fd)) &lt;==&gt; ((alt (FD nil))). fuf's default systematic chronological backtracking strategy can be overwritten by placing control annotations in disjunctions allowing fuf to use a more efficient dependency-directed backtracking strategy (cf. <ref> [ Elhadad and Robin 1992 ] </ref> ). The top-level of an FG is required to be a disjunction. B.1.3.2 Constituency and recursion The meta-attribute cset (meaning Constituent SET) introduces recursion on constituents. The value of this cset attribute is a list of paths.
Reference: [ Elhadad 1990 ] <author> M. Elhadad. </author> <title> Types in Functional Unification Grammars. </title> <booktitle> In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Detroit, MI, </address> <year> 1990. </year> <booktitle> ACL. </booktitle>
Reference-contexts: This test input set illustrates by example all the new features of the extended coverage of surge-2.0. B.1 The FUF programming language fuf [ Elhadad 1993b ] [ Elhadad 1993a ] is a special-purpose programming language for developing language generation applications. It is an extension (cf. <ref> [ Elhadad 1990 ] </ref> [ Elhadad and Robin 1992 ] ) of the initial functional grammar formalism initiated by [ Kay 1979 ] . Originally, functional grammars where used to implement only two generation subtasks: morpho-syntactic grammaticalization and linearization.
Reference: [ Elhadad 1993a ] <author> M. Elhadad. FUF: </author> <title> The universal unifier user manual, version 5.2. </title> <type> Technical Report CUCS-038-91, </type> <institution> Columbia University, </institution> <year> 1993. </year>
Reference-contexts: This implementation demonstrates the operationality of both the new generation model and the new type of linguistic knowledge acquired during the corpus analysis. For this implementation, I built on a pre-existing software environment dedicated to the development of language generation systems: the fuf/surge package <ref> [ Elhadad 1993a ] </ref> [ Elhadad 1993b ] . fuf (Functional Unification Formalism) is a programming language based on functional unification [ Kay 1979 ] 16 . Both the input and the output of a fuf program are features structures called Functional Descriptions (FDs). <p> or a set of synonymous complex sentences concisely expressing all the facts in the IDSS plus as many facts from the ADSS list that could be fit in without exceeding the maximum word length or syntactic depth observed in the corpus lead sentences. streak is implemented using the fuf/surge package <ref> [ Elhadad 1993a ] </ref> , [ Elhadad 1993b ] for developing language generation application. This package is presented in detail in Appendix B. It consists of: * fuf [ Elhadad 1993b ] [ Elhadad 1993a ] , a special-purpose programming language for text generation based on functional unification. * surge, a <p> word length or syntactic depth observed in the corpus lead sentences. streak is implemented using the fuf/surge package <ref> [ Elhadad 1993a ] </ref> , [ Elhadad 1993b ] for developing language generation application. This package is presented in detail in Appendix B. It consists of: * fuf [ Elhadad 1993b ] [ Elhadad 1993a ] , a special-purpose programming language for text generation based on functional unification. * surge, a wide-coverage grammar of English implemented in fuf and usable as a portable front-end for syntactic processing. 60 fuf is the formalism part of the package, a language in which to encode the <p> It has been distributed to over 50 research sites worldwide and is currently being used for the development of 12 projects at seven of these sites, making it the most widely used dedicated package for the development of language generation applications. fuf [ Elhadad 1993b ] <ref> [ Elhadad 1993a ] </ref> is a special-purpose programming language for language generation based on functional unification. <p> Finally, I give the input set used for systematically testing these extensions. This test input set illustrates by example all the new features of the extended coverage of surge-2.0. B.1 The FUF programming language fuf [ Elhadad 1993b ] <ref> [ Elhadad 1993a ] </ref> is a special-purpose programming language for developing language generation applications. It is an extension (cf. [ Elhadad 1990 ] [ Elhadad and Robin 1992 ] ) of the initial functional grammar formalism initiated by [ Kay 1979 ] . <p> For an in-depth presentation of fuf, see <ref> [ Elhadad 1993a ] </ref> and [ Elhadad 1993b ] . B.1.1 Functional Descriptions The basic data structure used in fuf is a Functional Description (FD). An FD describes a set of entities satisfying a set of properties.
Reference: [ Elhadad 1993b ] <author> M. Elhadad. </author> <title> Using argumentation to control lexical choice: a unification-based implementation. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Columbia University, </institution> <year> 1993. </year>
Reference-contexts: 1990 ] , lfs [ Iordanskaja et al. 1994 ] , kamp [ Appelt 1985 ] , kalipsos [ Nogier 1990 ] , fn [ Reiter 1991 ] , epicure [ Dale 1992 ] , igen [ Rubinoff 1992 ] , comet [ McKeown et al. 1990 ] , avdisorII <ref> [ Elhadad 1993b ] </ref> and plandoc [ Kukich et al. 1994 ] while the latter is representative of the class of macrocoded generators that also includes Danlos' generator [ Danlos 1986 ] , phred [ Jacobs 1985 ] , pauline [ Hovy 1988 ] , semtex [ Roesner 1987 ] and <p> Choose a concept to head the sentence structure. 12 In particular, I do not discuss its relation to adjacent topics such as user-modeling [ Paris 1987 ] , conversational implicatures [ Reiter 1991 ] or argumentation <ref> [ Elhadad 1993b ] </ref> . 13 Lexical items are traditionally divided into (a) open-class lexical items (also called cognates) such as nouns, verbs, adjectives and adverbs and (b) closed-class lexical items (also called function words) such as articles, pronouns and conjunctions. <p> This implementation demonstrates the operationality of both the new generation model and the new type of linguistic knowledge acquired during the corpus analysis. For this implementation, I built on a pre-existing software environment dedicated to the development of language generation systems: the fuf/surge package [ Elhadad 1993a ] <ref> [ Elhadad 1993b ] </ref> . fuf (Functional Unification Formalism) is a programming language based on functional unification [ Kay 1979 ] 16 . Both the input and the output of a fuf program are features structures called Functional Descriptions (FDs). <p> The second assumption is that the generator does not perform low-level syntactic processing on its own, but instead relies on a stand-alone, portable syntactic grammar of the target natural language such as surge <ref> [ Elhadad 1993b ] </ref> , nigel [ Mann and Matthiessen 1983 ] or mumble [ Meteer et al. 1987 ] for English. <p> Therefore, I do not discuss its relation to issues such as user-modeling [ Paris 1987 ] , conversational implicatures [ Reiter 1991 ] or argumentation <ref> [ Elhadad 1993b ] </ref> . For application domains where these issues are crucial, the DSS could not be assumed to include all the relevant aspects of an entity to describe. Instead, it would need to consist only of a default description sufficient for the most common situations. <p> complex sentences concisely expressing all the facts in the IDSS plus as many facts from the ADSS list that could be fit in without exceeding the maximum word length or syntactic depth observed in the corpus lead sentences. streak is implemented using the fuf/surge package [ Elhadad 1993a ] , <ref> [ Elhadad 1993b ] </ref> for developing language generation application. This package is presented in detail in Appendix B. It consists of: * fuf [ Elhadad 1993b ] [ Elhadad 1993a ] , a special-purpose programming language for text generation based on functional unification. * surge, a wide-coverage grammar of English implemented <p> without exceeding the maximum word length or syntactic depth observed in the corpus lead sentences. streak is implemented using the fuf/surge package [ Elhadad 1993a ] , <ref> [ Elhadad 1993b ] </ref> for developing language generation application. This package is presented in detail in Appendix B. It consists of: * fuf [ Elhadad 1993b ] [ Elhadad 1993a ] , a special-purpose programming language for text generation based on functional unification. * surge, a wide-coverage grammar of English implemented in fuf and usable as a portable front-end for syntactic processing. 60 fuf is the formalism part of the package, a language in <p> The idea of representing flat networks as FDs by listing concepts and roles under different top-level features and indicating the link between them through paths instead of embedding is due to <ref> [ Elhadad 1993b ] </ref> . <p> Among the landmark dissertations centered around the development of a generation system, only one contains an entire chapter specifically dedicated to evaluation: Kukich's [ Kukich 1983 ] . Her system ana and Elhadad's advisor II <ref> [ Elhadad 1993b ] </ref> are the only two generation systems that have been the object of quantitative evaluation. These evaluations are described and contrasted with the evaluation work presented in this thesis in Section 6.4. <p> The initial input set was incrementally created over seven years during the development of the generation systems comet [ McKeown et al. 1990 ] [ McKeown et al. 1993 ] , cook [ Smadja and McKeown 1991 ] and advisor-II <ref> [ Elhadad 1993b ] </ref> . <p> Issues such as coverage, extensibility and portability are discussed only qualitatively and rarely in much detail. The two notable exceptions to this general trend are the dissertations of Kukich [ Kukich 1983 ] and Elhadad <ref> [ Elhadad 1993b ] </ref> . Kukich dedicates a full chapter to evaluation. She defines and estimates several quantitative parameters. These parameters compare the knowledge structures abstracted during a single round of corpus analysis with the knowlege structures actually implemented in the generator ana. <p> this new generation model is that it combines a unique set of properties whose desirability had been independently advocated in previous work: * It distinguishes between foreground content to convey obligatorily and background content to convey opportunistically [ Rubinoff 1992 ] * It realizes floating facts across different linguistic ranks <ref> [ Elhadad 1993b ] </ref> . * It can conflate the expression of several facts within a single word [ Elhadad 1993b ] 164 * It uses declarative knowledge sources [ Nogier 1990 ] [ Polguere 1990 ] . * It is stratificational and modular [ Polguere 1990 ] . * It <p> advocated in previous work: * It distinguishes between foreground content to convey obligatorily and background content to convey opportunistically [ Rubinoff 1992 ] * It realizes floating facts across different linguistic ranks <ref> [ Elhadad 1993b ] </ref> . * It can conflate the expression of several facts within a single word [ Elhadad 1993b ] 164 * It uses declarative knowledge sources [ Nogier 1990 ] [ Polguere 1990 ] . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (functional descriptions) to represent utterances at all levels of abstraction and all linguistic <p> sources [ Nogier 1990 ] [ Polguere 1990 ] . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (functional descriptions) to represent utterances at all levels of abstraction and all linguistic ranks [ Simonin 1985 ] [ Dale 1992 ] <ref> [ Elhadad 1993b ] </ref> . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy 1988 ] . 7.1.3 Contributions to revision-based generation and incremental generation The major contribution of this thesis to revision-based generation and incremental generation is the extensive set of revision rules to incrementally incorporate quantitative <p> In addition to streak, it has been used as the underlying environment for the development of a wide variety of generation applications at Columbia University including multi-media explanation [ McKeown et al. 1990 ] , stock market reports [ Smadja and McKeown 1991 ] , and interactive on-line student advising <ref> [ Elhadad 1993b ] </ref> . It has been distributed to over 50 research sites worldwide and is currently being used for the development of 12 projects at seven of these sites, making it the most widely used dedicated package for the development of language generation applications. fuf [ Elhadad 1993b ] <p> on-line student advising <ref> [ Elhadad 1993b ] </ref> . It has been distributed to over 50 research sites worldwide and is currently being used for the development of 12 projects at seven of these sites, making it the most widely used dedicated package for the development of language generation applications. fuf [ Elhadad 1993b ] [ Elhadad 1993a ] is a special-purpose programming language for language generation based on functional unification. <p> Finally, I give the input set used for systematically testing these extensions. This test input set illustrates by example all the new features of the extended coverage of surge-2.0. B.1 The FUF programming language fuf <ref> [ Elhadad 1993b ] </ref> [ Elhadad 1993a ] is a special-purpose programming language for developing language generation applications. It is an extension (cf. [ Elhadad 1990 ] [ Elhadad and Robin 1992 ] ) of the initial functional grammar formalism initiated by [ Kay 1979 ] . <p> For an in-depth presentation of fuf, see [ Elhadad 1993a ] and <ref> [ Elhadad 1993b ] </ref> . B.1.1 Functional Descriptions The basic data structure used in fuf is a Functional Description (FD). An FD describes a set of entities satisfying a set of properties. <p> I will therefore not discuss the (significant) portion of surge-1.0 that was neither the object of an extension, nor used in the particular sublanguage of streak's sports reporting domain. See <ref> [ Elhadad 1993b ] </ref> for a discussion of these aspects. In what follows, I first review the generation subtasks carried out by surge. I then discuss in some detail the treatment of the clause in general and the transitivity system in particular. <p> Since only one verb ("to help") did not correspond to any of surge's general participant sets in the target sublanguage of streak, I will not discuss surge's lexical processes here. See <ref> [ Elhadad 1993b ] </ref> . The set of circumstantials accepted in input by surge-1.0 is given is Fig. B.16. These roles can appear in the input description of a clause independently of its process type. <p> The initial input set was incrementally created over seven years during the development of the generation systems comet [ McKeown et al. 1990 ] [ McKeown et al. 1993 ] , cook [ Smadja and McKeown 1991 ] and advisor-II <ref> [ Elhadad 1993b ] </ref> . The test inputs of surge-1.0 are presented in [ Elhadad 1993b ] . In this section, I present the extension of the input set testing the extensions from from surge-1.0 to surge-2.0. <p> set was incrementally created over seven years during the development of the generation systems comet [ McKeown et al. 1990 ] [ McKeown et al. 1993 ] , cook [ Smadja and McKeown 1991 ] and advisor-II <ref> [ Elhadad 1993b ] </ref> . The test inputs of surge-1.0 are presented in [ Elhadad 1993b ] . In this section, I present the extension of the input set testing the extensions from from surge-1.0 to surge-2.0. This additional test input set provides a detailed account of the extended coverage of surge-2.0.
Reference: [ Fawcett 1987 ] <author> R.P. Fawcett. </author> <title> The semantics of clause and verb for relational processes in English. In M.A.K. Halliday and R.P. Fawcett, editors, New developments in systemic linguistics. </title> <publisher> Frances Pinter, </publisher> <address> London and New York, </address> <year> 1987. </year>
Reference-contexts: The reason for the DGS to be structured in terms of thematic roles at the clause level is that the two most widely used portable syntactic grammars in generation research, today surge and nigel, are both based on the systemic linguistic framework [ Halliday 1985 ] , <ref> [ Fawcett 1987 ] </ref> which include a semantic analysis of the clause in terms of a set of thematic roles. The advantage of such high level input to a syntactic grammar is to maximize the number of generation subtasks performed by this re-usable component. <p> Milwaukee Bucks snapped a losing streak at five games with A 95-93 VICTORY OVER THE DETROIT PISTONS" 23 Some corpus sentences are even flatly ungrammatical. 24 The set of semantic roles used for this analysis are those one used in surge, which are themselves derived from various systemic linguistic sources <ref> [ Fawcett 1987 ] </ref> [ Halliday 1985 ] [ Winograd 1983 ] . 137 * Location, where "the Denver Nuggets rolled to A 124 110 VICTORY OVER THE UTAH JAZZ" becomes "the Denver Nuggets ended their three game losing streak with A 124 110 VICTORY OVER THE UTAH JAZZ" In the <p> His main sources of inspiration were <ref> [ Fawcett 1987 ] </ref> and [ Lyons 1977 ] for the semantic aspects of the transitivity system, [ Mel'cuk and Pertsov 1987 ] for its lexical aspects, [ Halliday 1985 ] and [ Winograd 1983 ] for the other clause systems, the nominal systems and the overall organization of the grammar, <p> This meaning superposition is possible because of an underlying cause-effect relationship between the event and relation components of the clause. This compositional and unifying view based on <ref> [ Fawcett 1987 ] </ref> , allows the analysis of explicitly causative clauses (e.g, "Mary made him a good man") together with the other types of clauses with three participants (e.g., "Mary gave John a book", "Mary put the book on the table". ). <p> The hierarchy of general process types defining the deep argument structure of a clause (and the semantic class of its main verb) in the current implementation is a synthesis from [ Halliday 1985 ] , <ref> [ Fawcett 1987 ] </ref> and [ Lyons 1977 ] . This hierarchy is compact and able to cover many clause structures. Yet the argument structure and/or semantics of many English verbs do not fit neatly in any element of this hierarchy.
Reference: [ Fensch 1988 ] <author> T. Fensch. </author> <title> The sports writing handbook. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1988. </year>
Reference-contexts: The reports of the corpus I analyzed summarize basketball games. In each of these reports, the lead sentence itself summarizes the rest of the report [ Mencher 1984 ] <ref> [ Fensch 1988 ] </ref> . 1.1.2.1 Floating concepts While some concepts consistently appear in fixed locations across reports (e.g., the final score of a ballgame is always conveyed in the second half of the lead sentence), others float, appearing potentially anywhere in the report structure. <p> I then distinguished between different types of information conveyed in the corpus to choose a semantic focus. 2.2.1 Report structure and discursive focus Journalism textbooks define a variety of standard report structures. The corpus reports are organized following the so-called inverted pyramid structure with summary lead <ref> [ Fensch 1988 ] </ref> , meaning that crucial information is packed in the lead followed by facts of decreasing importance towards the end of the report. Summary type leads, often consisting of a single sentence in the corpus reports, are thus self-contained mini-reports containing the basic facts.
Reference: [ Fries 1970 ] <author> P. Fries. </author> <title> Tagmeme sequences in the English noun phrase. </title> <booktitle> Number 36 in Summer institute of linguistics publications in linguistics and related fields. </booktitle> <publisher> Benjamin F. Elson for The Church Press Inc., </publisher> <address> Glendale, CA, </address> <year> 1970. </year>
Reference-contexts: B.4.5 Nominals The most urgent improvement of the nominal system is to extend it to cover reflexive pronouns. Another improvement would consist of refining the set of nominal functions currently available, namely determiner, describer, classifier, head and qualifier. In particular, <ref> [ Fries 1970 ] </ref> proposes a more complete set of functions. It also includes detailed constraints on co-occurrence of several elements filling the same function (with different semantics) in a given NP.
Reference: [ Gabriel 1988 ] <editor> R. Gabriel. Deliberate writing. In D.D. McDonald and Bolc L., editors, </editor> <booktitle> Natural Language Generation Systems. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1988. </year>
Reference-contexts: It has been proposed in different flavors by [ Mann 1983 ] , [ Vaughan and McDonald 1986 ] [ Meteer 1991 ] , [ Yazdani 1987 ] , <ref> [ Gabriel 1988 ] </ref> , [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] and [ Inui et al. 1992 ] . However, only two implemented generation system emerged from these proposals: Gabriel's Yh and Inui et. al's weiveR. <p> I compare revision in streak with previous proposals along these two dimensions in turn. 6.2.1 Yh Yh <ref> [ Gabriel 1988 ] </ref> explores a number of interesting language generation issues on the toy domain of the Dutch national flag game. Yh takes as input an abstract description of a lisp program playing this game and generates a paragraph describing the code. <p> Since Yh describes the code itself and not its execution (as in [ Davey 1978 ] for example) and since Yh does not include a module performing domain reasoning ( <ref> [ Gabriel 1988 ] </ref> , p.29) the input to Yh is the same for all its runs. Different outputs are obtained by playing with the value of adjustable parameters defining stylistic heuristics used during content organization and realization. Yh is implemented in an object-oriented fashion. <p> SPOKESMAN does not perform revision. 15 In that sense, the hill-climbing phase of KDS [ Mann and Moore 1981 ] is not revision but local backtracking. 151 6.2.4 Revising to satisfy what goals? The revision goals considered by [ Meteer 1991 ] , <ref> [ Gabriel 1988 ] </ref> , [ Wong and Simmons 1988 ] and [ Inui et al. 1992 ] are purely stylistic. They are information-preserving revisions to make the draft more concise, clearer or more coherent.
Reference: [ Gopen and Swan 1990 ] <author> G.D. Gopen and J.A. Swan. </author> <title> The science of scientific writing. </title> <journal> American Scientist, </journal> <volume> 78 </volume> <pages> 550-558, </pages> <year> 1990. </year>
Reference-contexts: For example, support verbs were pervasive in the corpus and the subject head noun was often separated from the verb by lengthy relative clauses or appositions. These two expressive forms are strongly objected by <ref> [ Gopen and Swan 1990 ] </ref> for scientific writing. This discrepancy in style can be explained by a discrepancy in goals. In a science article the main goal is to introduce the reader to new, complex concepts.
Reference: [ Gross 1984 ] <author> M. Gross. </author> <title> Lexicon-Grammar and the syntactic analysis of French. </title> <booktitle> In Proceedings of the 10th International Conference on Computational Linguistics, </booktitle> <pages> pages 275-282. COLING, </pages> <year> 1984. </year>
Reference-contexts: For example, Adjunctization applies only to clausal base patterns headed by a support verb V s . Following Gross <ref> [ Gross 1984 ] </ref> , I call support verb any verb that does not realize any semantic element. Appearing only because each clause syntactically requires a verb in English, its sole function is to support one of its meaning-bearing arguments.
Reference: [ Halliday 1985 ] <author> M.A.K. Halliday. </author> <title> An introduction to functional grammar. </title> <publisher> Edward Arnold, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: In the first structure they are in parataxis while in the second they are in hypotaxis, with the main statistic as head. In this paper, I use the notions of parataxis and hypotaxis defined in <ref> [ Halliday 1985 ] </ref> , because they are general relations between syntactic constituents occurring at all linguistic ranks (sentence, clause, group). Two constituents are in parataxis if they are both at the same structural level. Parataxis is thus a general symmetric relation covering both coordination and apposition. <p> The reason for the DGS to be structured in terms of thematic roles at the clause level is that the two most widely used portable syntactic grammars in generation research, today surge and nigel, are both based on the systemic linguistic framework <ref> [ Halliday 1985 ] </ref> , [ Fawcett 1987 ] which include a semantic analysis of the clause in terms of a set of thematic roles. The advantage of such high level input to a syntactic grammar is to maximize the number of generation subtasks performed by this re-usable component. <p> losing streak at five games with A 95-93 VICTORY OVER THE DETROIT PISTONS" 23 Some corpus sentences are even flatly ungrammatical. 24 The set of semantic roles used for this analysis are those one used in surge, which are themselves derived from various systemic linguistic sources [ Fawcett 1987 ] <ref> [ Halliday 1985 ] </ref> [ Winograd 1983 ] . 137 * Location, where "the Denver Nuggets rolled to A 124 110 VICTORY OVER THE UTAH JAZZ" becomes "the Denver Nuggets ended their three game losing streak with A 124 110 VICTORY OVER THE UTAH JAZZ" In the stock market domain, only <p> His main sources of inspiration were [ Fawcett 1987 ] and [ Lyons 1977 ] for the semantic aspects of the transitivity system, [ Mel'cuk and Pertsov 1987 ] for its lexical aspects, <ref> [ Halliday 1985 ] </ref> and [ Winograd 1983 ] for the other clause systems, the nominal systems and the overall organization of the grammar, [ Pollard and Sag 1987 ] for the treatment of long-distance dependencies and, last but not least, [ Quirk et al. 1985 ] for the many linguistic <p> The set of circumstantials accepted in input by surge-1.0 is given is Fig. B.16. These roles can appear in the input description of a clause independently of its process type. The Reason, Purpose, Instrument, Manner and Accompaniment circumstantials are based on [ Winograd 1983 ] while Behalf comes from <ref> [ Halliday 1985 ] </ref> . The locative and temporal circumstantials are somewhat ad-hoc. For most of these circumstantials, surge-1.0 can generate only prepositional realizations. In Fig. B.16, NP is indicated in parenthesis next to PP, because these prepositional circumstantials are specified in the input as NPs. <p> The sub-corpus of human-written summaries whose in-depth analysis was presented in section 2. * The comprehensive lists of adverbial classes independently presented from different angles in Chapters 8, 9, 14 and 15 of [ Quirk et al. 1985 ] . * The more limited lists of adverbial classes presented in <ref> [ Halliday 1985 ] </ref> , [ Thompson and Longacre 1985 ] and [ Talmy 1985 ] . In general, I considered only forms that occurred independently in two of these sources, considering each chapter of [ Quirk et al. 1985 ] as an independent source. <p> The hierarchy of general process types defining the deep argument structure of a clause (and the semantic class of its main verb) in the current implementation is a synthesis from <ref> [ Halliday 1985 ] </ref> , [ Fawcett 1987 ] and [ Lyons 1977 ] . This hierarchy is compact and able to cover many clause structures. Yet the argument structure and/or semantics of many English verbs do not fit neatly in any element of this hierarchy.
Reference: [ Harbusch 1994 ] <author> K. </author> <title> Harbusch. Towards an Integrated Generation Approach with Tree-Adjoining Grammars. </title> <journal> Computational Intelligence, </journal> <volume> 10(4) </volume> <pages> 579-590, </pages> <year> 1994. </year>
Reference-contexts: Considering this last remark it comes as no surprise that all subsequent proposals to adapt TAGs to the specific needs of generation used lexicalized TAGs as their starting point. Within this line of research, three main efforts have been: * LD/LP TAGs <ref> [ Harbusch 1994 ] </ref> * Synchronous TAGs [ Shieber and Shabes 1991 ] . * Systemic TAGs [ Yang et al. 1991 ] [ McCoy et al. 1992 ] .
Reference: [ Hatzivassiloglou and McKeown 1993 ] <author> Vasileios Hatzivassiloglou and Kathleen McKeown. </author> <title> Towards the Automatic Identification of Adjectival Scales: Clustering Adjectives According to Meaning. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the ACL, </booktitle> <pages> pages 172-182, </pages> <address> Columbus, Ohio, </address> <month> June </month> <year> 1993. </year> <institution> Association for Computational Linguistics. </institution>
Reference-contexts: This type of evaluation relying on one or several human judges is commonly used in statistical NLP. For example, it has been used to evaluate systems which compile collocations [ Smadja 1991 ] or form groups of semantically related adjectives <ref> [ Hatzivassiloglou and McKeown 1993 ] </ref> . However, in the context of language generation this type of approach would not yield very interesting results.
Reference: [ Herskovits 1986 ] <author> A. Herskovits. </author> <title> Language and spatial cognition: an interdisciplinary study of the prepositions of English. </title> <booktitle> Studies in Natural Language Processing. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1986. </year>
Reference-contexts: Open-classes are large and seemingly ever growing while closed-classes are small and stable. Distinguishing elements in an open-class requires semantics while in a closed-class it can be done on syntactic grounds only. In that sense, prepositions, which are few but cannot be distinguished on purely syntactic grounds (cf. <ref> [ Herskovits 1986 ] </ref> ) are neither really an open nor a closed class of words but a little bit of both. 7 8 2. Choose a verb lexicalizing this head concept. 3. Choose which other concepts to map onto each argument of this verb. 4. <p> For example, the right side of Fig. 3.9 shows dgs22, an alternative lexicalization of sss2 by the phrase: "The Magic's homecourt win against the Raptors" 7 Prepositions are the exception. Even though a closed class they cannot be chosen on purely syntactic grounds as shown by <ref> [ Herskovits 1986 ] </ref> . I thus assume that the syntactic grammar can only provide a default choice which need to be overwritten in the DGS of utterances for which this default is not appropriate on semantic grounds. 49 50 In general, a DGS represents more than one phrase. <p> Characterizing locative thematic roles by spatial prepositions is problematic for two reasons: * Most locative meaning have alternative, non-prepositional realizations. * There are many spatial prepositions in English and their respective meanings overlap in a complex, context sensitive ways <ref> [ Herskovits 1986 ] </ref> . 244 semantic syntactic Example # class role feature category Temporal Co-Event habit+ finite S Whenever you hurt, call me. 1 Causative habit- -ing S With his knees hampering him, Bo's defense is sloppy. 2 Blend ed S Injured against the Giants, Bo didn't play. 3 verbless
Reference: [ Hirschman and Cuomo 1994 ] <author> L. Hirschman and D. Cuomo. </author> <title> Report from the ARPA Workshop on Evaluation of Human Computer Interfaces. </title> <type> Technical Report MP 94B0000259, </type> <institution> Mitre, Bedford, </institution> <address> Ma., </address> <year> 1994. </year>
Reference-contexts: For such applications, a set of target responses have to be initially hand-coded and then incrementally adjusted through user feedback and determining the quality of the generated response requires determining how well it meet the user needs. Proposed evaluations <ref> [ Hirschman and Cuomo 1994 ] </ref> often center around time to task completion, where the user is given a task that requires use of the system to solve.
Reference: [ Hovy 1988 ] <author> E. Hovy. </author> <title> Generating natural language under pragmatic constraints. </title> <editor> L. </editor> <publisher> Erlbaum Associates, </publisher> <address> Hillsdale, N.J., </address> <year> 1988. </year>
Reference-contexts: Other systems that generate reports that are not specifically summaries, can avoid generating very complex sentences since they are under no pressure to be concise. Two such systems, Danlos' generator [ Danlos 1986 ] and pauline <ref> [ Hovy 1988 ] </ref> , generate sentences of a complexity 6 As paradoxical as it may first sound. 7 cf. <p> , comet [ McKeown et al. 1990 ] , avdisorII [ Elhadad 1993b ] and plandoc [ Kukich et al. 1994 ] while the latter is representative of the class of macrocoded generators that also includes Danlos' generator [ Danlos 1986 ] , phred [ Jacobs 1985 ] , pauline <ref> [ Hovy 1988 ] </ref> , semtex [ Roesner 1987 ] and weiver [ Inui et al. 1992 ] . The fact that ana generates more complex sentences than gossip generalizes to the respective classes of generators to which they belong. <p> Although in many cases an underlying application provides the generator with all the potential content, in other cases the generator's input is but one part of that content. The rest of the content has to be produced by the generator itself. This is what Hovy calls interpretation in generation <ref> [ Hovy 1988 ] </ref> : the generator needs to enrich its input with more content. In the extreme case the input consists only of communicative goals and it is the generator's task to produce all content from the knowledge sources it can access. <p> I briefly review each of these systems in the following subsections. Other generation systems that produced reports are not directly relevant to the present thesis, because the reports are not specifically summaries and because they worked in qualitative domains (e.g., Danlos' generator [ Danlos 1986 ] , pauline <ref> [ Hovy 1988 ] </ref> , Kalita's system [ Kalita 1989 ] , texplan [ Maybury 1990 ] ). <p> Without the operation of substitution that allows the derivation of syntactic structures from individual words, using TAGs for generation would require the use of a phrasal lexicon such as those of ana [ Kukich 1983 ] , phred [ Jacobs 1985 ] or pauline <ref> [ Hovy 1988 ] </ref> , with the limitations of this approach with respect to scalability discussed in section 6.1.4 20 . Considering this last remark it comes as no surprise that all subsequent proposals to adapt TAGs to the specific needs of generation used lexicalized TAGs as their starting point. <p> modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (functional descriptions) to represent utterances at all levels of abstraction and all linguistic ranks [ Simonin 1985 ] [ Dale 1992 ] [ Elhadad 1993b ] . * It interleaves planning and realization [ Appelt 1985 ] <ref> [ Hovy 1988 ] </ref> . 7.1.3 Contributions to revision-based generation and incremental generation The major contribution of this thesis to revision-based generation and incremental generation is the extensive set of revision rules to incrementally incorporate quantitative and historical data in a given draft expressing related information.
Reference: [ Hovy 1990 ] <author> E. Hovy. </author> <title> Unresolved issues in paragraph planning. </title> <editor> In R. Dale, C.S. Mellish, and M. Zock, editors, </editor> <booktitle> Current Research in Natural Language Generation. </booktitle> <publisher> Academic Press, </publisher> <year> 1990. </year> <month> 353 </month>
Reference-contexts: Auxiliary trees have the special property of containing a leaf node whose category matches that of their root. This distinguished leaf node is called the foot node of 16 Or in Hovy's term, expanding growth-points <ref> [ Hovy 1990 ] </ref> . 152 the auxiliary tree. Ajoining A to I consists of excising the subtree I x rooted at the node X of I, replacing it by A and then inserting I x at the foot node of A.
Reference: [ Hovy 1991 ] <author> E. Hovy. </author> <title> Approaches to the planning of coherent text. </title> <editor> In C. Paris, W. Swartout, and Mann. W.C., editors, </editor> <booktitle> Natutal Language Generation in Artificial Intelligence and Computational Linguistics. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: Planning a maximally complex sentence such as those observed in newswire summaries can only be done under surface form constraints. The standard content planning techniques devised for paragraphs such as textual schemas [ McKeown 1985 ] and Rhetorical Structure Theory <ref> [ Hovy 1991 ] </ref> cannot be used for the complex sentences of summaries precisely because they operate purely at the conceptual level. 1.1.2.5 Paraphrasing power Conveying floating facts concisely requires attaching them opportunistically where the surrounding text allows.
Reference: [ Inui et al. 1992 ] <author> K. Inui, T. Tokunaga, and H. Tanaka. </author> <title> Text revision: a model and its implementation. </title> <editor> In R. Dale, E. Hovy, D. Roesner, and O. Stock, editors, </editor> <booktitle> Aspects of Automated Natural Language Generation, </booktitle> <pages> pages 215-230. </pages> <address> Springler-Verlag, </address> <year> 1992. </year>
Reference-contexts: 1993b ] and plandoc [ Kukich et al. 1994 ] while the latter is representative of the class of macrocoded generators that also includes Danlos' generator [ Danlos 1986 ] , phred [ Jacobs 1985 ] , pauline [ Hovy 1988 ] , semtex [ Roesner 1987 ] and weiver <ref> [ Inui et al. 1992 ] </ref> . The fact that ana generates more complex sentences than gossip generalizes to the respective classes of generators to which they belong. Thus, existing generators either microcode simpler sentences or macrocode more complex sentences. <p> It has been proposed in different flavors by [ Mann 1983 ] , [ Vaughan and McDonald 1986 ] [ Meteer 1991 ] , [ Yazdani 1987 ] , [ Gabriel 1988 ] , [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] and <ref> [ Inui et al. 1992 ] </ref> . However, only two implemented generation system emerged from these proposals: Gabriel's Yh and Inui et. al's weiveR. In what follows, I first briefly describe these two systems and compare the type of revisions they perform to those implemented in streak. <p> This expensive search is avoided in Yh by relying on knowledge extremely specific to the tiny domain of the Dutch National Flag program. It could not be avoided in a more complex domain. 6.2.2 weiveR weiveR <ref> [ Inui et al. 1992 ] </ref> generates paragraphs that provide information for library users, such as the library's schedule or the location of a particular book. <p> 15 In that sense, the hill-climbing phase of KDS [ Mann and Moore 1981 ] is not revision but local backtracking. 151 6.2.4 Revising to satisfy what goals? The revision goals considered by [ Meteer 1991 ] , [ Gabriel 1988 ] , [ Wong and Simmons 1988 ] and <ref> [ Inui et al. 1992 ] </ref> are purely stylistic. They are information-preserving revisions to make the draft more concise, clearer or more coherent. In contrast, streak performs information-adding revisions to make the draft more informative. [ Cline and Nutter 1991 ] propose performing both varieties of revisions.
Reference: [ Iordanskaja et al. 1994 ] <author> L. Iordanskaja, M. Kim, R. Kittredge, B. Lavoie, and A. Polguere. </author> <title> Generation of extended bilingual statistical reports. </title> <booktitle> In Proceedings of the 15th International Conference on Computational Linguistics. COLING, </booktitle> <year> 1994. </year>
Reference-contexts: While both generate summaries, the former is representative of the class of microcoded generators that also includes fog [ Bourbeau et al. 1990 ] , lfs <ref> [ Iordanskaja et al. 1994 ] </ref> , kamp [ Appelt 1985 ] , kalipsos [ Nogier 1990 ] , fn [ Reiter 1991 ] , epicure [ Dale 1992 ] , igen [ Rubinoff 1992 ] , comet [ McKeown et al. 1990 ] , avdisorII [ Elhadad 1993b ] and <p> work in summary report generation Prior to streak, six main systems generated natural language reports to summarize quantitative data: ana [ Kukich 1983 ] [ Kukich 1985 ] , fog [ Bourbeau et al. 1990 ] [ Polguere 1990 ] , gossip [ Carcagno and Iordanskaja 1993 ] , lfs <ref> [ Iordanskaja et al. 1994 ] </ref> , semtex [ Roesner 1987 ] , and sage [ Roth et al. 1991 ] . I briefly review each of these systems in the following subsections.
Reference: [ Jacobs 1985 ] <author> P. Jacobs. </author> <title> PHRED: a generator for natural language interfaces. </title> <journal> Computational Linguistics, </journal> <volume> 11(4) </volume> <pages> 219-242, </pages> <year> 1985. </year>
Reference-contexts: , igen [ Rubinoff 1992 ] , comet [ McKeown et al. 1990 ] , avdisorII [ Elhadad 1993b ] and plandoc [ Kukich et al. 1994 ] while the latter is representative of the class of macrocoded generators that also includes Danlos' generator [ Danlos 1986 ] , phred <ref> [ Jacobs 1985 ] </ref> , pauline [ Hovy 1988 ] , semtex [ Roesner 1987 ] and weiver [ Inui et al. 1992 ] . The fact that ana generates more complex sentences than gossip generalizes to the respective classes of generators to which they belong. <p> To perform this mapping, weiveR relies on the sentence level content organization heuristics described in [ Scott and Souza 1990 ] and a phrasal lexicon similar to the one described in <ref> [ Jacobs 1985 ] </ref> . The final draft representation consists of a hybrid tree, whose top-levels are structured in terms of rhetorical relations and whose bottom-levels are structured in terms of syntactic dependencies. <p> Without the operation of substitution that allows the derivation of syntactic structures from individual words, using TAGs for generation would require the use of a phrasal lexicon such as those of ana [ Kukich 1983 ] , phred <ref> [ Jacobs 1985 ] </ref> or pauline [ Hovy 1988 ] , with the limitations of this approach with respect to scalability discussed in section 6.1.4 20 .
Reference: [ Joshi et al. 1975 ] <author> A.K. Joshi, L.S. Levy, and M. Takahashi. </author> <title> Tree Adjunct Grammars. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 10(1) </volume> <pages> 136-163, </pages> <year> 1975. </year>
Reference-contexts: view brings together revision-based generation with another line of research, incremental generation, reviewed in the next section. 6.3 Related work in incremental generation Incremental generation has been investigated from three main perspectives: the AI perspective of Yh already described in the previous section, the syntactic perspective of Tree Adjoining Grammars <ref> [ Joshi et al. 1975 ] </ref> and the cognitive modelling perspective of ipf [ De Smedt 1990 ] . <p> I then contrast the various TAG-based approaches to incremental generation with the approach presented in this thesis and implemented in the system streak. 6.3.1.1 Tree Adjoining Grammars Introduced by Joshi, TAGs <ref> [ Joshi et al. 1975 ] </ref> originated in the field of formal language theory, as an alternative to the various string rewrite formalisms, such as Context Free Grammars (CFGs) and Context Sensitive Grammars (CSGs), that had been put forward to study the computational complexity of both artificial and natural languages.
Reference: [ Joshi 1987 ] <author> A.K. Joshi. </author> <title> The relevance of Tree-Adjoining Grammar to generation. </title> <editor> In Gerard Kempen, editor, </editor> <booktitle> Natural Language Generation: New Results in Artificial Intellligence, Psychology and Linguistics. </booktitle> <publisher> Martinus Ninjhoff Publishers, </publisher> <year> 1987. </year>
Reference-contexts: Such comparisons bring much needed insights revealing fundamental and previously obscured differences and similarities among these formalisms. The first notable extension to pure TAGs was the introduction of Multi-Component TAGs <ref> [ Joshi 1987 ] </ref> that allow the simultaneous adjoining to the same tree of sets of auxiliary trees with co-referring nodes across several members of the set. <p> The interest of TAGs for generation continued with a paper by <ref> [ Joshi 1987 ] </ref> comparing TAGs and CFGs and arguing that two properties of TAGs, extended domain of locality and flexible word-ordering specification, make TAGs more suitable to generation than CFGs. <p> is that for applications such as question/answering systems or interlingual machine translation where both a parser and a generator are needed, a reversible grammar would avoid duplicating the effort of writing the grammar rules twice (once for each module) 19 . * As pointed out in the paper itself ( <ref> [ Joshi 1987 ] </ref> , p.243), the extended domain of locality of TAGs is also a property of FUGs.
Reference: [ Kalita 1989 ] <author> J. Kalita. </author> <title> Automatically generating natural language reports. </title> <journal> International Journal of Man-Machine Studies, </journal> (30):399-423, 1989. 
Reference-contexts: Other generation systems that produced reports are not directly relevant to the present thesis, because the reports are not specifically summaries and because they worked in qualitative domains (e.g., Danlos' generator [ Danlos 1986 ] , pauline [ Hovy 1988 ] , Kalita's system <ref> [ Kalita 1989 ] </ref> , texplan [ Maybury 1990 ] ).
Reference: [ Kay 1979 ] <author> M. Kay. </author> <title> Functional Grammar. </title> <booktitle> In Proceedings of the 5th Annual Meeting of the Berkeley Linguistic Society, </booktitle> <year> 1979. </year>
Reference-contexts: For this implementation, I built on a pre-existing software environment dedicated to the development of language generation systems: the fuf/surge package [ Elhadad 1993a ] [ Elhadad 1993b ] . fuf (Functional Unification Formalism) is a programming language based on functional unification <ref> [ Kay 1979 ] </ref> 16 . Both the input and the output of a fuf program are features structures called Functional Descriptions (FDs). The program itself, called a Functional Grammar (FG), is also a feature structure, but one which contains disjunctions and control annotations. <p> An auxiliary tree A can be adjoined (or substituted) to a node X of a tree T , only when the feature structure at the root of A unifies with the feature structure at X. The use of functional unification was inspired by Functional Unification Grammars (FUGs) <ref> [ Kay 1979 ] </ref> . <p> B.1 The FUF programming language fuf [ Elhadad 1993b ] [ Elhadad 1993a ] is a special-purpose programming language for developing language generation applications. It is an extension (cf. [ Elhadad 1990 ] [ Elhadad and Robin 1992 ] ) of the initial functional grammar formalism initiated by <ref> [ Kay 1979 ] </ref> . Originally, functional grammars where used to implement only two generation subtasks: morpho-syntactic grammaticalization and linearization. This was the case for example in the systems text [ McKeown 1985 ] and tailor [ Paris 1987 ] .
Reference: [ Kukich et al. 1994 ] <author> K. Kukich, K. McKeown, J. Shaw, J. Robin, N. Morgan, and J. Phillips. </author> <title> User-needs analysis and design methodology for an automated document generator. </title> <editor> In A. Zampolli, N. Calzolari, and M. Palmer, editors, </editor> <booktitle> Current Issues in Computational Linguistics: In Honour of Don Walker. </booktitle> <publisher> Kluwer Academic Press, </publisher> <address> Boston, </address> <year> 1994. </year>
Reference-contexts: I also quantitatively evaluate the advantages of this new revision-based generation model over the one-pass model of previous generators 1 cf. fog [ Bourbeau et al. 1990 ] , see Section 6.1 for details. 2 The other system working as a real-world application is plandoc <ref> [ Kukich et al. 1994 ] </ref> [ McKeown et al. 1995 ] , which produces automated documentation for managers about the choices of telephone network planning engineers at Bellcore. 3 Surface Text Reviser Expressing Additional Knowledge. 1 in terms of same-domain robustness and cross-domain portability. <p> et al. 1994 ] , kamp [ Appelt 1985 ] , kalipsos [ Nogier 1990 ] , fn [ Reiter 1991 ] , epicure [ Dale 1992 ] , igen [ Rubinoff 1992 ] , comet [ McKeown et al. 1990 ] , avdisorII [ Elhadad 1993b ] and plandoc <ref> [ Kukich et al. 1994 ] </ref> while the latter is representative of the class of macrocoded generators that also includes Danlos' generator [ Danlos 1986 ] , phred [ Jacobs 1985 ] , pauline [ Hovy 1988 ] , semtex [ Roesner 1987 ] and weiver [ Inui et al. 1992 <p> The version of surge resulting from these extensions has since been used for other generation applications in addition to streak: automated documentation for the activity of telephone network planning engineers <ref> [ Kukich et al. 1994 ] </ref> , verbal descriptions of visual scenes [ Abella 1994 ] and generation of business letters. The two sets of extensions to the fuf/surge package are described in detail Appendix B. <p> It is thus also performing final content selection. In constrast, the text generator of ana has no such option. It must convey all the element in its input message list. 2 In fact, probably even all others except plandoc <ref> [ Kukich et al. 1994 ] </ref> . 141 Example of fact: (make fact ^fact-name half-hour-stat ^indicator-name Dow-Jones-industrial-average ^indicator-type composite ^date 04/21 ^time 11:30am ^current-level 1192.82 ^direction down ^degree 2.03 ^cumulative-direction up ^cumulative-degree 1.35 ^high-or-low-mark nil) Example of message: (make message ^date 6/24 ^topic Dow-Jones-industrial-average ^subtopic Dow-Jones-industrial-average-status ^subject-class Dow-Jones-industrial-average ^direction down ^degree <p> The version of surge resulting from these extensions has since been used for other generation applications in addition to streak: automated documentation for the activity of telephone network planning engineers <ref> [ Kukich et al. 1994 ] </ref> , verbal descriptions of visual scenes [ Abella 1994 ] and generation of business letters. In what follows, I first give an overview of fuf (Functional Unification Formalism) as a programming language, including the extensions for non-monotonic processing prompted by the development of streak. <p> The extended surge-2.0 has since been used for the development of several others generation applications at Columbia University including automated documentation <ref> [ Kukich et al. 1994 ] </ref> , verbal descriptions of visual scenes [ Abella 1994 ] and business letters. The extensive coverage of adverbial complements provided by surge-2.0, proved extremely useful in these three other domains.
Reference: [ Kukich 1983 ] <author> K. Kukich. </author> <title> Knowledge-based report generation: a knowledge engineering approach to natural language report generation. </title> <type> PhD thesis, </type> <institution> University of Pittsburgh, </institution> <year> 1983. </year>
Reference-contexts: Grouping these ten facts in the complex lead of Fig. 1.1 allow collapsing these five occurrences in a single referring NP. The table below contrasts the complexity of two previous summary report generators 7 , gossip [ Carcagno and Iordanskaja 1993 ] and ana <ref> [ Kukich 1983 ] </ref> , with the complexity of the lead sentences in the corpus I analyzed. Its rows indicate the number of facts, represented in logical form as in Fig. 1.3, parse tree depth and number of words 8 of a sentence. <p> This task of content production subtly differs from content selection which consists of deciding which part of the produced content is to be included in the generated text. What each generation subtask covers depends on the level of microcoding at which generation is performed. A macrocoded generator like ana <ref> [ Kukich 1983 ] </ref> produces sentences by assembling entire clauses and group patterns stored as a whole in its phrasal lexicon. In contrast, a microcoded generator like epicure [ Dale 1992 ] dynamically builds from a word-based lexicon 1 every sentence constituent down to the group rank. <p> Among the landmark dissertations centered around the development of a generation system, only one contains an entire chapter specifically dedicated to evaluation: Kukich's <ref> [ Kukich 1983 ] </ref> . Her system ana and Elhadad's advisor II [ Elhadad 1993b ] are the only two generation systems that have been the object of quantitative evaluation. These evaluations are described and contrasted with the evaluation work presented in this thesis in Section 6.4. <p> Existing systems have been developed for different domains and in the rare cases when several generators exist in the same domain, they use a different language (e.g., ana <ref> [ Kukich 1983 ] </ref> in English and frana [ Contant 1986 ] in French for the stock market domain). Different domains do not only mean different encyclopedic contexts but also different writing styles. <p> The opportunity created by corpus data For generation applications where human generated text corpora are available as model output sets, setting up an evaluation is much easier. One reason why ana <ref> [ Kukich 1983 ] </ref> could be quantitively evaluated was that both its input (number tables) and target output (newspaper articles) were available in a systematic way. <p> These percentages do not, however, evaluates the solution that streak offers to these issues. In evaluating a solution, it is also important to distinguish between evaluating the underlying generation model of the system and its particular implementation. For example in <ref> [ Kukich 1983 ] </ref> , Kukich quantitatively evaluates the coverage of the generator ana, which is a particular implementation of the general one-pass macrocoded generation model that she proposes. The model in itself is not quantitatively evaluated in its abstract generality. <p> Evaluation methods can be either: * Qualitative or quantitative. * Absolute or comparative. 103 * Based on human judgments or on corpus data. * Manual or automatic. An example of qualitative vs. quantitative evaluations in the context of language generation can be found in <ref> [ Kukich 1983 ] </ref> , p.137-138. A qualitative evaluation of the syntactic coverage of ana is first given, listing all syntactic forms observed in a corpus of stock market reports and specifying which forms are encoded in the generator (e.g., participial clauses) and which are not (e.g., infinitive clauses). <p> In Section 5.2 of the present thesis, I present a comparative evaluation which contrasts the respective robustness of the two-pass microcoded generation model on which streak is based with the one-pass macrocoded generation model on which previous report generators such as ana <ref> [ Kukich 1983 ] </ref> are based. All the evaluations mentioned until now are based on corpus data. <p> It is this feature that sets this evaluation apart from previous evaluation work and make its 104 results of considerably wider relevance. As noted in section 6.4, <ref> [ Kukich 1983 ] </ref> evaluates the coverage, of the system ana, a particular implementation of the one-pass macrocoded generation model that she proposes. <p> As the test domain for this evaluation, I chose the stock market for two reasons: (1) large textual corpora of reports in this domain are available from newswires and (2) it has been the object of several language generation projects <ref> [ Kukich 1983 ] </ref> [ Contant 1986 ] [ Smadja 1991 ] . The test corpus consisted of reports on the American, Asian and European stock markets by UPI, AP and Reuter compiled from the newsreader. Its size was about 445,000 words. <p> section, I mention architecture issues only for systems either whose application (summary report generation) or approach to generation (revision-based or incremental) is directly related to those of streak. 6.1 Related work in summary report generation Prior to streak, six main systems generated natural language reports to summarize quantitative data: ana <ref> [ Kukich 1983 ] </ref> [ Kukich 1985 ] , fog [ Bourbeau et al. 1990 ] [ Polguere 1990 ] , gossip [ Carcagno and Iordanskaja 1993 ] , lfs [ Iordanskaja et al. 1994 ] , semtex [ Roesner 1987 ] , and sage [ Roth et al. 1991 ] <p> Her system ana <ref> [ Kukich 1983 ] </ref> summarizes the daily fluctuations of several stock market indexes from half-hourly updates of their values. A report generated by ana is given in Fig. 6.1. <p> Among previous systems, only ana focused on paraphrasing power. streak improves over ana in this respect in two different ways. First, by covering syntactic constructions not covered in ana such as infinitive clauses, relative clauses, appositions and nominalizations (cf. <ref> [ Kukich 1983 ] </ref> p.137). Second and more importantly, it is able to convey the same fact at a variety of linguistic ranks, including below the clause rank. <p> Without the operation of substitution that allows the derivation of syntactic structures from individual words, using TAGs for generation would require the use of a phrasal lexicon such as those of ana <ref> [ Kukich 1983 ] </ref> , phred [ Jacobs 1985 ] or pauline [ Hovy 1988 ] , with the limitations of this approach with respect to scalability discussed in section 6.1.4 20 . <p> Issues such as coverage, extensibility and portability are discussed only qualitatively and rarely in much detail. The two notable exceptions to this general trend are the dissertations of Kukich <ref> [ Kukich 1983 ] </ref> and Elhadad [ Elhadad 1993b ] . Kukich dedicates a full chapter to evaluation. She defines and estimates several quantitative parameters. These parameters compare the knowledge structures abstracted during a single round of corpus analysis with the knowlege structures actually implemented in the generator ana.
Reference: [ Kukich 1985 ] <author> K. Kukich. </author> <title> The feasibility of automatic natural language generation report. </title> <booktitle> In Proceedings of the 18th Hawaii international conference on system sciences, </booktitle> <year> 1985. </year>
Reference-contexts: issues only for systems either whose application (summary report generation) or approach to generation (revision-based or incremental) is directly related to those of streak. 6.1 Related work in summary report generation Prior to streak, six main systems generated natural language reports to summarize quantitative data: ana [ Kukich 1983 ] <ref> [ Kukich 1985 ] </ref> , fog [ Bourbeau et al. 1990 ] [ Polguere 1990 ] , gossip [ Carcagno and Iordanskaja 1993 ] , lfs [ Iordanskaja et al. 1994 ] , semtex [ Roesner 1987 ] , and sage [ Roth et al. 1991 ] .
Reference: [ Lenat and Guha 1989 ] <author> D.B. Lenat and R.V Guha. </author> <title> Building large knowledge base systems: representation and inference in the Cyc project. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: The problem arises with overusing linguistic criteria and in particular linguistic rank and thematic roles for defining these general concepts. The temptation for such overuse is great because there are not many non-linguistic criteria to fall back on for defining an Upper-Model (see <ref> [ Lenat and Guha 1989 ] </ref> for an attempt to build a non-linguistically motivated general ontology). However, semantic linguistic categories are best viewed as constituting a "surface perspective" model rather than an "upper" model for the domain.
Reference: [ Levi 1978 ] <author> J. Levi. </author> <title> The syntax and semantics of complex nominals. </title> <publisher> Academic Press, </publisher> <year> 1978. </year>
Reference-contexts: Some interesting investigations in that direction have been carried out by some authors such as [ Vendler 1968 ] or <ref> [ Levi 1978 ] </ref> but each discuss only a narrow range of nominal meanings and more studies focusing on other ranges are needed before the synthetic integration of these independent efforts within a unifying framework can even be contemplated. <p> In particular, [ Fries 1970 ] proposes a more complete set of functions. It also includes detailed constraints on co-occurrence of several elements filling the same function (with different semantics) in a given NP. Finally, the work of [ Vendler 1968 ] and <ref> [ Levi 1978 ] </ref> on nominalizations and non-predicative adjectives could serve as a good though quite limited in scope - starting point, towards the development of a set of thematic roles for a semantic input specification of nominals paralleling the set of thematic roles already used for the semantic input specification
Reference: [ Levin 1993 ] <author> B. Levin. </author> <title> English verb classes and alternations: a preliminary investigation. </title> <publisher> University of Chicago Press, </publisher> <year> 1993. </year>
Reference-contexts: It would require both refining and extending the current hierarchy of general process types. An excellent starting point for carrying out this task is the comprehensive taxonomy of English verbs proposed by <ref> [ Levin 1993 ] </ref> . B.4.2 Adverbials The coverage of the adverbial system in the current implementation is limited in two ways. First, among the four types of syntactic functions that adverbial constituents can fill in a clause adjuncts, disjuncts, conjuncts and subjuncts only the first two are covered.
Reference: [ Lyons 1977 ] <author> J. Lyons. </author> <title> Semantics. </title> <publisher> Cambridge University Press, </publisher> <year> 1977. </year>
Reference-contexts: His main sources of inspiration were [ Fawcett 1987 ] and <ref> [ Lyons 1977 ] </ref> for the semantic aspects of the transitivity system, [ Mel'cuk and Pertsov 1987 ] for its lexical aspects, [ Halliday 1985 ] and [ Winograd 1983 ] for the other clause systems, the nominal systems and the overall organization of the grammar, [ Pollard and Sag 1987 <p> The remaining types of relations are called ascriptive and they include copulative clauses. Note that this distinction among ascriptive, possessive and locative relations is orthogonal to the distinction among attributive and equative relations. Following a localist approach (cf. <ref> [ Lyons 1977 ] </ref> pp.718-724), surge views existential clauses as expressing a locative relation lacking a location participant. <p> The hierarchy of general process types defining the deep argument structure of a clause (and the semantic class of its main verb) in the current implementation is a synthesis from [ Halliday 1985 ] , [ Fawcett 1987 ] and <ref> [ Lyons 1977 ] </ref> . This hierarchy is compact and able to cover many clause structures. Yet the argument structure and/or semantics of many English verbs do not fit neatly in any element of this hierarchy.
Reference: [ Mann and Matthiessen 1983 ] <author> W.C. Mann and C.M. Matthiessen. NIGEL: </author> <title> a systemic grammar for text generation. </title> <type> Technical Report ISI/RR-83-105, ISI, </type> <institution> Marina del Rey, </institution> <address> CA, </address> <year> 1983. </year>
Reference-contexts: The second assumption is that the generator does not perform low-level syntactic processing on its own, but instead relies on a stand-alone, portable syntactic grammar of the target natural language such as surge [ Elhadad 1993b ] , nigel <ref> [ Mann and Matthiessen 1983 ] </ref> or mumble [ Meteer et al. 1987 ] for English. <p> Like surge used in this thesis and nigel <ref> [ Mann and Matthiessen 1983 ] </ref> , developped at ISI, mumble is a portable syntactic processing front-end for the development of generation applications. It accepts as input a skeletal lexico-syntactic tree (called a linguistic specfication) and incorporates a fairly extensive portion of the English grammar. <p> The networks of systemic TAGs are thus exactly similar to those of nigel <ref> [ Mann and Matthiessen 1983 ] </ref> , a portable syntactic front-end for generation applications based solely on systemic grammars. The difference between the two lies in the way they build the syntactic structures satisfying the contraints accumulated during the systemic network traversal.
Reference: [ Mann and Moore 1981 ] <author> W.C. Mann and J.A. Moore. </author> <title> Computer Generation of Multiparagraph English Text. </title> <journal> Computational Linguistics, </journal> <volume> 7(1) </volume> <pages> 17-29, </pages> <year> 1981. </year>
Reference-contexts: SPOKESMAN does not perform revision. 15 In that sense, the hill-climbing phase of KDS <ref> [ Mann and Moore 1981 ] </ref> is not revision but local backtracking. 151 6.2.4 Revising to satisfy what goals? The revision goals considered by [ Meteer 1991 ] , [ Gabriel 1988 ] , [ Wong and Simmons 1988 ] and [ Inui et al. 1992 ] are purely stylistic.
Reference: [ Mann 1983 ] <author> W.C. Mann. </author> <title> An overview of the PENMAN text generation system. </title> <type> Technical Report ISI/RR-83-114, ISI, </type> <institution> Marina del Rey, </institution> <address> CA, </address> <year> 1983. </year>
Reference-contexts: It has been proposed in different flavors by <ref> [ Mann 1983 ] </ref> , [ Vaughan and McDonald 1986 ] [ Meteer 1991 ] , [ Yazdani 1987 ] , [ Gabriel 1988 ] , [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] and [ Inui et al. 1992 ] .
Reference: [ Maybury 1990 ] <author> M.T. </author> <title> Maybury. Using discourse focus, temporal focus and spatial focus to generate mul-tisentential text. </title> <booktitle> In Proceedings of the 5th International Workshop on Natural Language Generation, </booktitle> <address> Pittsburgh, PA, </address> <year> 1990. </year> <month> 354 </month>
Reference-contexts: Other generation systems that produced reports are not directly relevant to the present thesis, because the reports are not specifically summaries and because they worked in qualitative domains (e.g., Danlos' generator [ Danlos 1986 ] , pauline [ Hovy 1988 ] , Kalita's system [ Kalita 1989 ] , texplan <ref> [ Maybury 1990 ] </ref> ).
Reference: [ McCoy et al. 1992 ] <author> K. McCoy, K. Vijay-Shanker, and G. Yang. </author> <title> A functional approach to generation with TAG. </title> <booktitle> In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics. ACL, </booktitle> <year> 1992. </year>
Reference-contexts: Within this line of research, three main efforts have been: * LD/LP TAGs [ Harbusch 1994 ] * Synchronous TAGs [ Shieber and Shabes 1991 ] . * Systemic TAGs [ Yang et al. 1991 ] <ref> [ McCoy et al. 1992 ] </ref> . LD/LP TAGs (Local Dependence / Linear Precedence Tree Adjoining Grammars) depart from the regular lexicalized TAGs used for parsing in that they separate the expression of dependency constraints among constituents from the expression of precedence constraints among these constituents.
Reference: [ McDonald and Pustejovsky 1985 ] <author> D. McDonald and J.D. Pustejovsky. </author> <title> TAGs as a formalism for generation. </title> <booktitle> In Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics. ACL, </booktitle> <year> 1985. </year>
Reference-contexts: A second series of extensions resulted from several attempts to adapt the formalism for the needs of implementing grammars for generation. This trend of work again originated from a paper by <ref> [ McDonald and Pustejovsky 1985 ] </ref> in which they point out the similarity between the adjoining operation of TAGs and the attachement operation used in their system mumble [ Meteer et al. 1987 ] .
Reference: [ McKeown and Swartout 1987 ] <author> K.R. McKeown and W.R. Swartout. </author> <title> Language generation and explanation. </title> <booktitle> The Annual Review of Computer Science, </booktitle> (2):401-449, 1987. 
Reference-contexts: This second reformatting task involves deducing the redundant information needed in the DSS for the generator to be able to perform cross-ranking paraphrasing. The need for such additional information for language generation (a pervasive problem in generation, cf. <ref> [ McKeown and Swartout 1987 ] </ref> ) was explained in the previous section. For example in dss1 in Fig. 3.6 of the previous section, the relations r-loser and r-beat can be deduced from records for the relations r-winner, r-host and r-visitor.
Reference: [ McKeown et al. 1990 ] <author> K. R. McKeown, M. Elhadad, Y. Fukumoto, J.G. Lim, C. Lombardi, J. Robin, and F.A. Smadja. </author> <title> Text generation in COMET. </title> <editor> In R. Dale, C.S. Mellish, and M. Zock, editors, </editor> <booktitle> Current Research in Natural Language Generation. </booktitle> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: that also includes fog [ Bourbeau et al. 1990 ] , lfs [ Iordanskaja et al. 1994 ] , kamp [ Appelt 1985 ] , kalipsos [ Nogier 1990 ] , fn [ Reiter 1991 ] , epicure [ Dale 1992 ] , igen [ Rubinoff 1992 ] , comet <ref> [ McKeown et al. 1990 ] </ref> , avdisorII [ Elhadad 1993b ] and plandoc [ Kukich et al. 1994 ] while the latter is representative of the class of macrocoded generators that also includes Danlos' generator [ Danlos 1986 ] , phred [ Jacobs 1985 ] , pauline [ Hovy 1988 <p> This input test set systematically probes each branch of the grammar and many combinations of features from different branches. The initial input set was incrementally created over seven years during the development of the generation systems comet <ref> [ McKeown et al. 1990 ] </ref> [ McKeown et al. 1993 ] , cook [ Smadja and McKeown 1991 ] and advisor-II [ Elhadad 1993b ] . <p> The natural language generator is essentially used to produce locative sentences such as: "The on/off switch is located in the upper left corner of the picture". In the comparable system comet <ref> [ McKeown et al. 1990 ] </ref> which generates coordinated textual 20 For the example sentence of Fig. 6.8 above, the two phrasal patterns S 1 = "How many ships S Iraq attacked" and S 2 = "Iraq had said S" (where the S in each pattern indicating the node where adjoining <p> In addition to streak, it has been used as the underlying environment for the development of a wide variety of generation applications at Columbia University including multi-media explanation <ref> [ McKeown et al. 1990 ] </ref> , stock market reports [ Smadja and McKeown 1991 ] , and interactive on-line student advising [ Elhadad 1993b ] . <p> This input text set systematically probes each branch of the grammar and many combinations of features from different branches. The initial input set was incrementally created over seven years during the development of the generation systems comet <ref> [ McKeown et al. 1990 ] </ref> [ McKeown et al. 1993 ] , cook [ Smadja and McKeown 1991 ] and advisor-II [ Elhadad 1993b ] . The test inputs of surge-1.0 are presented in [ Elhadad 1993b ] .
Reference: [ McKeown et al. 1993 ] <author> K. R. McKeown, J. Robin, and M. Tanenblatt. </author> <title> Tailoring lexical choice to the user's vocabulary in multimedia explanation generation. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics. ACL, </booktitle> <year> 1993. </year>
Reference-contexts: This input test set systematically probes each branch of the grammar and many combinations of features from different branches. The initial input set was incrementally created over seven years during the development of the generation systems comet [ McKeown et al. 1990 ] <ref> [ McKeown et al. 1993 ] </ref> , cook [ Smadja and McKeown 1991 ] and advisor-II [ Elhadad 1993b ] . <p> This input text set systematically probes each branch of the grammar and many combinations of features from different branches. The initial input set was incrementally created over seven years during the development of the generation systems comet [ McKeown et al. 1990 ] <ref> [ McKeown et al. 1993 ] </ref> , cook [ Smadja and McKeown 1991 ] and advisor-II [ Elhadad 1993b ] . The test inputs of surge-1.0 are presented in [ Elhadad 1993b ] .
Reference: [ McKeown et al. 1995 ] <author> K. McKeown, J. Robin, and K. Kukich. </author> <title> Generating concise natural language summaries. </title> <booktitle> Information Processing and Management, </booktitle> <year> 1995. </year> <note> (To appear in "Special Issue on Summarization"). </note>
Reference-contexts: also quantitatively evaluate the advantages of this new revision-based generation model over the one-pass model of previous generators 1 cf. fog [ Bourbeau et al. 1990 ] , see Section 6.1 for details. 2 The other system working as a real-world application is plandoc [ Kukich et al. 1994 ] <ref> [ McKeown et al. 1995 ] </ref> , which produces automated documentation for managers about the choices of telephone network planning engineers at Bellcore. 3 Surface Text Reviser Expressing Additional Knowledge. 1 in terms of same-domain robustness and cross-domain portability. <p> The side transformation Ellipsis presented here is thus a distinct and less general concept than the ellipsis traditionally discussed in the linguistic literature (see the system plandoc <ref> [ McKeown et al. 1995 ] </ref> for the generation of this more general type of ellipsis). In particular, it is applicable only to cases where the new constituent shares more than one semantic elements with the draft coordination to which it is appended.
Reference: [ McKeown 1985 ] <author> K. R. McKeown. </author> <title> Using Discourse Strategies and Focus Constraints to Generate Natural Language Text. </title> <booktitle> Studies in Natural Language Processing. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1985. </year>
Reference-contexts: Planning a maximally complex sentence such as those observed in newswire summaries can only be done under surface form constraints. The standard content planning techniques devised for paragraphs such as textual schemas <ref> [ McKeown 1985 ] </ref> and Rhetorical Structure Theory [ Hovy 1991 ] cannot be used for the complex sentences of summaries precisely because they operate purely at the conceptual level. 1.1.2.5 Paraphrasing power Conveying floating facts concisely requires attaching them opportunistically where the surrounding text allows. <p> The instances of all the other classes consistently appeared in the same cluster. This concept clustering phenomenon is illustrated in Fig. 2.5. It shows where additional instances of each concept gets attached. These semantic constraints on concept clustering can be viewed as schemata <ref> [ McKeown 1985 ] </ref> for sentence-rank planning. * The top-level relation between the two clusters, either parataxis or hypotaxis with the statistic cluster as head. * The internal structure of its statistic cluster * The internal structure of its result cluster These corpus observations show that any complex sentence can indeed <p> This illustrates that such paraphrasing power is not only needed for the sake of variety (always using the same linguistic form immediately betrays the artificial nature of a generated text) but also to satisfy discourse constraints, such as focus shift rules <ref> [ McKeown 1985 ] </ref> insuring that the sentence coherently inserts itself in the overall generated text. <p> The output of the fact generator is passed to the discourse planner. The discourse planner traverses a textual schema <ref> [ McKeown 1985 ] </ref> encoding, for each sentential slot in the report, which type of fixed facts it must contain. Recall from Section 2.4 that fixed facts are those present in every report and in the same sentence over the human-written model report corpus. <p> The text planner is based on the notion of topic tree. A topic tree represents a stereotypical textual organization pattern followed by the reports in a given application domain. It is comparable to one particular traversal of a textual schema <ref> [ McKeown 1985 ] </ref> . The nodes of a topic tree are domain concepts and its arcs are very general relations which can hold between concepts in many domains (e.g., object, aspect, subaction, attribute, element). Each node in the topic tree is represented as an prolog "object". <p> In itself, the implementation of such a discourse planner should not pose any fundamental difficulty. Since within the architecture proposed in this thesis, the discourse planner needs to handle only the organization of fixed facts floating facts being handled by the reviser the standard technique of textual schemas 173 <ref> [ McKeown 1985 ] </ref> would be very appropriate. The limitation of this technique is precisely its difficulty to cope with floating facts. <p> Originally, functional grammars where used to implement only two generation subtasks: morpho-syntactic grammaticalization and linearization. This was the case for example in the systems text <ref> [ McKeown 1985 ] </ref> and tailor [ Paris 1987 ] .
Reference: [ Mel'cuk and Pertsov 1987 ] <author> I.A. Mel'cuk and N.V. Pertsov. </author> <title> Surface-syntax of English, a formal model in the Meaning-Text Theory. </title> <publisher> Benjamins, </publisher> <address> Amsterdam/Philadelphia, </address> <year> 1987. </year>
Reference-contexts: The systems all use the Meaning-Text Theory (MTT) <ref> [ Mel'cuk and Pertsov 1987 ] </ref> as underlying linguistic model. The first of these system is fog [ Bourbeau et al. 1990 ] . It produces daily local marine weather bulletins, in both English and French, from meteorological measurements. <p> An example CCR together with the corresponding English DSemR is given in Fig. 6.6. The task of the linguistic component is to generate a natural language sentence expressing the content encoded in the DSemR. The linguistic component is an implementation of the Meaning-Text Theory (MTT) <ref> [ Mel'cuk and Pertsov 1987 ] </ref> . <p> This lexicalist import to TAGs seems very close in spirit to the surface syntax representation of the Meaning-Text Theory 154 <ref> [ Mel'cuk and Pertsov 1987 ] </ref> . As a result of these two extensions, TAGs could now be used to compositionally derive most syntactic structures observed in natural languages. <p> His main sources of inspiration were [ Fawcett 1987 ] and [ Lyons 1977 ] for the semantic aspects of the transitivity system, <ref> [ Mel'cuk and Pertsov 1987 ] </ref> for its lexical aspects, [ Halliday 1985 ] and [ Winograd 1983 ] for the other clause systems, the nominal systems and the overall organization of the grammar, [ Pollard and Sag 1987 ] for the treatment of long-distance dependencies and, last but not least,
Reference: [ Mel'cuk and Polguere 1987 ] <author> I.A. Mel'cuk and A. Polguere. </author> <title> A formal lexicon in the Meaning-Text Theory. </title> <booktitle> Computational Linguistics, </booktitle> <address> 13(3-4):261-275, </address> <year> 1987. </year>
Reference-contexts: No matter how comprehensive, compositional and well-defined such a general set may be, it is always possible to come up with a particular verb whose argument structure does not neatly fits into it. The immense semantic variety of verbal arguments led to lexicalist approaches (e.g., <ref> [ Mel'cuk and Polguere 1987 ] </ref> ) where no attempt is made to make any generalization across verbs. Each verb is treated as idiosyncratic, with participants not semantically labeled and instead given an arbitrary number.
Reference: [ Mencher 1984 ] <author> M. Mencher. </author> <title> News reporting and writing. Wm. </title> <address> C. </address> <publisher> Brown Publishers, </publisher> <address> Dubuque, Iowa, </address> <year> 1984. </year>
Reference-contexts: These issues include (1) floating concepts, (2) historical background, (3) conciseness, (4) sentence complexity, (5) paraphrasing, (6) granularity and (7) implicit content. The reports of the corpus I analyzed summarize basketball games. In each of these reports, the lead sentence itself summarizes the rest of the report <ref> [ Mencher 1984 ] </ref> [ Fensch 1988 ] . 1.1.2.1 Floating concepts While some concepts consistently appear in fixed locations across reports (e.g., the final score of a ballgame is always conveyed in the second half of the lead sentence), others float, appearing potentially anywhere in the report structure. <p> Summary type leads, often consisting of a single sentence in the corpus reports, are thus self-contained mini-reports containing the basic facts. This type of report structure is not particular to sports reporting but is pervasive in newswire articles <ref> [ Mencher 1984 ] </ref> . It is preferred because newswire reports are essentially used as draft material to be edited by client newspapers under heavy time-pressure and stringent space constraints. An inverted pyramid structure with a summary lead makes a report instantly editable by cutting its tail.
Reference: [ Meteer et al. 1987 ] <author> M.W. Meteer, D.D. McDonald, S.D. Anderson, D. Forster, L.S. Gay, A.K. Huettner, and P. Sibun. Mumble-86: </author> <title> Design and implementation. </title> <type> Technical Report COINS 87-87, </type> <institution> University of Massachussets at Amherst, </institution> <address> Ahmerst, Ma., </address> <year> 1987. </year>
Reference-contexts: The second assumption is that the generator does not perform low-level syntactic processing on its own, but instead relies on a stand-alone, portable syntactic grammar of the target natural language such as surge [ Elhadad 1993b ] , nigel [ Mann and Matthiessen 1983 ] or mumble <ref> [ Meteer et al. 1987 ] </ref> for English. The three layers define a pipeline of internal representations that bridge the gap from the application program interface that performs domain-specific, language-independent, conceptual processing, to the syntactic grammar component that performs domain-independent, language-specific, linguistic processing. <p> Although grammatical constituency is already decided at that level, many grammatical features and open-class lexical items with different stylistic impacts are not yet specified. The level of representation that unequivocally determines a natural language utterance in spokesman is the Linguistic Specification input to mumble-86 <ref> [ Meteer et al. 1987 ] </ref> . Using spokesman levels of representation, revising to adjust the tradeoff between informativity, conciseness and readability, would require acting upon both the Text-Structure level and the Linguistic Specification level. <p> This trend of work again originated from a paper by [ McDonald and Pustejovsky 1985 ] in which they point out the similarity between the adjoining operation of TAGs and the attachement operation used in their system mumble <ref> [ Meteer et al. 1987 ] </ref> . Like surge used in this thesis and nigel [ Mann and Matthiessen 1983 ] , developped at ISI, mumble is a portable syntactic processing front-end for the development of generation applications.
Reference: [ Meteer 1990 ] <author> M.W. Meteer. </author> <title> The generation gap: the problem of expressibility in text planning. </title> <type> PhD thesis, </type> <institution> University of Massachussets at Ahmerst, </institution> <year> 1990. </year> <note> Also available as BBN technical report No. 7347. </note>
Reference-contexts: A corpus analysis to acquire revision rules In order to handle supplementary content opportunistically, the new generation model described above requires the acquisition of a new type of linguistic knowledge structure: revision operations specifying the 14 Much publicized in the research literature [ Appelt 1985 ] [ Danlos 1986 ] <ref> [ Meteer 1990 ] </ref> [ Rubinoff 1992 ] yet of marginal significance in most practical applications as pointed out by [ Reiter 1994 ] . 10 Complex sentence S 2 containing two floating facts: "Houston, TX Buck Johnson scored a season high 26 points Thursday night and the Houston Rockets routed <p> The need for a representation that bridges the gap between conceptual and syntactic processing has been advocated in detail by <ref> [ Meteer 1990 ] </ref> . For alternative schemes using a single semantic representation, there are two possibilities: either the single semantic layer is like a DSS or it is like an SSS. <p> This is why the other authors proposed, as I do, to perform revision directly on some representation of the draft internal to the generator. This is also perhaps why in her thesis <ref> [ Meteer 1990 ] </ref> , after having dismissed revision of an internal representation as mere "optimization" claiming "true revision" requires analyzing an actual natural language output, Meteer then proposes to perform revision on the Text-Structure, a level of representation internal to her spokesman generation system 14 .
Reference: [ Meteer 1991 ] <author> M. Meteer. </author> <title> The implications of revisions for natural language generation. </title> <editor> In C. Paris, W. Swartout, and W.C. Mann, editors, </editor> <booktitle> Natutal Language Generation in Artificial Intelligence and Computational Linguistics. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: It has been proposed in different flavors by [ Mann 1983 ] , [ Vaughan and McDonald 1986 ] <ref> [ Meteer 1991 ] </ref> , [ Yazdani 1987 ] , [ Gabriel 1988 ] , [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] and [ Inui et al. 1992 ] . <p> SPOKESMAN does not perform revision. 15 In that sense, the hill-climbing phase of KDS [ Mann and Moore 1981 ] is not revision but local backtracking. 151 6.2.4 Revising to satisfy what goals? The revision goals considered by <ref> [ Meteer 1991 ] </ref> , [ Gabriel 1988 ] , [ Wong and Simmons 1988 ] and [ Inui et al. 1992 ] are purely stylistic. They are information-preserving revisions to make the draft more concise, clearer or more coherent.
Reference: [ MUC-4 1992 ] <editor> Proceedings of the Fourth Message Understanding Conference. </editor> <booktitle> In Proceedings of the Fourth Message Understanding Conference. DARPA Software and Intelligent Systems Technology Office, </booktitle> <year> 1992. </year>
Reference-contexts: Influence of related fields The vogue of comparative and quantitative evaluations is also spreading from their popularity in fields close to generation, namely language understanding and statistical NLP. Events entirely dedicated to quantitative evaluations such as the Message Understanding Conference <ref> [ MUC-4 1992 ] </ref> have now been held for several years in natural language understanding, a field that is older than generation and beneficiates from a larger workforce.
Reference: [ Nogier 1990 ] <author> J.F. Nogier. </author> <title> Un systeme de production de language fonde sur le modele des graphes conceptuels. </title> <type> PhD thesis, </type> <institution> Universite de Paris VII, </institution> <year> 1990. </year>
Reference-contexts: While both generate summaries, the former is representative of the class of microcoded generators that also includes fog [ Bourbeau et al. 1990 ] , lfs [ Iordanskaja et al. 1994 ] , kamp [ Appelt 1985 ] , kalipsos <ref> [ Nogier 1990 ] </ref> , fn [ Reiter 1991 ] , epicure [ Dale 1992 ] , igen [ Rubinoff 1992 ] , comet [ McKeown et al. 1990 ] , avdisorII [ Elhadad 1993b ] and plandoc [ Kukich et al. 1994 ] while the latter is representative of the <p> convey obligatorily and background content to convey opportunistically [ Rubinoff 1992 ] * It realizes floating facts across different linguistic ranks [ Elhadad 1993b ] . * It can conflate the expression of several facts within a single word [ Elhadad 1993b ] 164 * It uses declarative knowledge sources <ref> [ Nogier 1990 ] </ref> [ Polguere 1990 ] . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (functional descriptions) to represent utterances at all levels of abstraction and all linguistic ranks [ Simonin 1985 ] [ Dale 1992 ] [ Elhadad
Reference: [ Paris 1987 ] <author> C. L. Paris. </author> <title> The use of explicit user models in text generation: tailoring to a user's level of expertise. </title> <type> PhD thesis, </type> <institution> Columbia University, </institution> <year> 1987. </year> <note> Also available as technical report CUCS-309-87. </note>
Reference-contexts: The lexicalizer generally builds the syntactic structure in top-down recursive fashion following the algorithm below: 1. Choose a concept to head the sentence structure. 12 In particular, I do not discuss its relation to adjacent topics such as user-modeling <ref> [ Paris 1987 ] </ref> , conversational implicatures [ Reiter 1991 ] or argumentation [ Elhadad 1993b ] . 13 Lexical items are traditionally divided into (a) open-class lexical items (also called cognates) such as nouns, verbs, adjectives and adverbs and (b) closed-class lexical items (also called function words) such as articles, <p> In this thesis, I consider it only from the perspective of generating paraphrases in the context of written report production for restricted quantitative domains where the readership is assumed uniform. Therefore, I do not discuss its relation to issues such as user-modeling <ref> [ Paris 1987 ] </ref> , conversational implicatures [ Reiter 1991 ] or argumentation [ Elhadad 1993b ] . For application domains where these issues are crucial, the DSS could not be assumed to include all the relevant aspects of an entity to describe. <p> Originally, functional grammars where used to implement only two generation subtasks: morpho-syntactic grammaticalization and linearization. This was the case for example in the systems text [ McKeown 1985 ] and tailor <ref> [ Paris 1987 ] </ref> .
Reference: [ Pavard 1985 ] <editor> B. Pavard. La conception de systemes de traitement de texte. Intellectica, </editor> <volume> 1(1) </volume> <pages> 37-67, </pages> <year> 1985. </year>
Reference-contexts: But this revision-based, opportunistic approach to generation is not only preferable from a system engineering standpoint. An experiment by <ref> [ Pavard 1985 ] </ref> described in Section 3.2.2 suggests that it is also a more cognitively plausible model for the generation of complex written sentences. 1.2.2 A corpus analysis to acquire revision rules In order to handle supplementary content opportunistically, the new generation model described above requires the acquisition of a <p> From an engineering perspective, I have also suggested that the need to produce very complex sentences through microcoding calls for a two-pass draft and revision generation model. The cognitive research literature also supports the hypothesis that to generate very complex sentences conveying many facts revision is needed. <ref> [ Pavard 1985 ] </ref> describes an experiment providing psychological evidence supporting the revision model for the generation of very complex sentences. In this experiment, human subjects were asked to write a single sentence paraphrasing a text of three sentences which together conveyed eight facts in 42 words.
Reference: [ Polguere 1990 ] <author> A. </author> <month> Polguere. </month> <institution> Structuration et mise en jeu procedurale d'un modele linguistique declaratif dans un cadre de generation de texte. </institution> <type> PhD thesis, </type> <institution> Universite de Montreal, </institution> <address> Quebec, Canada, </address> <year> 1990. </year>
Reference-contexts: The architecture thus belongs to the stratificational tradition of computational linguistics (cf. [ Dale 1992 ] and <ref> [ Polguere 1990 ] </ref> for other generation systems using a stratificational utterance representation scheme), with multiple representation layers, each capturing a specific set of regularities. The general stratificational scheme I propose is sketched in Fig. 3.3. It is based on two assumptions concerning the generation system. <p> to generation (revision-based or incremental) is directly related to those of streak. 6.1 Related work in summary report generation Prior to streak, six main systems generated natural language reports to summarize quantitative data: ana [ Kukich 1983 ] [ Kukich 1985 ] , fog [ Bourbeau et al. 1990 ] <ref> [ Polguere 1990 ] </ref> , gossip [ Carcagno and Iordanskaja 1993 ] , lfs [ Iordanskaja et al. 1994 ] , semtex [ Roesner 1987 ] , and sage [ Roth et al. 1991 ] . I briefly review each of these systems in the following subsections. <p> There are three array markers, L, M, and R, standing for left, middle and right, respectively. L and M are initialized to 0. R is initialized to n -1. pattern per concept combinations in the target meteorological sublanguage of fog (cf. <ref> [ Polguere 1990 ] </ref> p.14-16), no paraphrasing power is implemented for that system. <p> content to convey opportunistically [ Rubinoff 1992 ] * It realizes floating facts across different linguistic ranks [ Elhadad 1993b ] . * It can conflate the expression of several facts within a single word [ Elhadad 1993b ] 164 * It uses declarative knowledge sources [ Nogier 1990 ] <ref> [ Polguere 1990 ] </ref> . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (functional descriptions) to represent utterances at all levels of abstraction and all linguistic ranks [ Simonin 1985 ] [ Dale 1992 ] [ Elhadad 1993b ] . * <p> floating facts across different linguistic ranks [ Elhadad 1993b ] . * It can conflate the expression of several facts within a single word [ Elhadad 1993b ] 164 * It uses declarative knowledge sources [ Nogier 1990 ] <ref> [ Polguere 1990 ] </ref> . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (functional descriptions) to represent utterances at all levels of abstraction and all linguistic ranks [ Simonin 1985 ] [ Dale 1992 ] [ Elhadad 1993b ] . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy
Reference: [ Pollard and Sag 1987 ] <author> C. Pollard and I.A. Sag. </author> <title> Information-based Syntax and Semantics Volume 1, </title> <booktitle> volume 13 of CSLI Lecture Notes. </booktitle> <publisher> University of Chicago Press, </publisher> <address> Chicago, Il, </address> <year> 1987. </year> <month> 355 </month>
Reference-contexts: Fawcett 1987 ] and [ Lyons 1977 ] for the semantic aspects of the transitivity system, [ Mel'cuk and Pertsov 1987 ] for its lexical aspects, [ Halliday 1985 ] and [ Winograd 1983 ] for the other clause systems, the nominal systems and the overall organization of the grammar, <ref> [ Pollard and Sag 1987 ] </ref> for the treatment of long-distance dependencies and, last but not least, [ Quirk et al. 1985 ] for the many linguistic phenomena not mentioned in other works, yet encountered in many generation application domains.
Reference: [ Quirk et al. 1985 ] <author> R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik. </author> <title> A comprehensive grammar of the English language. </title> <publisher> Longman, </publisher> <year> 1985. </year>
Reference-contexts: The version of surge available when I started the implementation of streak had a wide-coverage at the simple clause and determiner ranks but not at the complex sentence and nominal ranks. Drawing both on a variety of non-computational descriptive linguistic works such as <ref> [ Quirk et al. 1985 ] </ref> and on the syntactic data compiled during the corpus analysis, I extended surge at these two ranks. At the complex sentence rank, the coverage of the resulting surge-2.0 version of the grammar goes way beyond the specific sports sublanguage needed for streak. <p> Mel'cuk and Pertsov 1987 ] for its lexical aspects, [ Halliday 1985 ] and [ Winograd 1983 ] for the other clause systems, the nominal systems and the overall organization of the grammar, [ Pollard and Sag 1987 ] for the treatment of long-distance dependencies and, last but not least, <ref> [ Quirk et al. 1985 ] </ref> for the many linguistic phenomena not mentioned in other works, yet encountered in many generation application domains. In its incomparable comprehensiveness, attention to detail and wealth of examples, [ Quirk et al. 1985 ] exemplifies the all too rare type of linguistic work that constitutes <p> Pollard and Sag 1987 ] for the treatment of long-distance dependencies and, last but not least, <ref> [ Quirk et al. 1985 ] </ref> for the many linguistic phenomena not mentioned in other works, yet encountered in many generation application domains. In its incomparable comprehensiveness, attention to detail and wealth of examples, [ Quirk et al. 1985 ] exemplifies the all too rare type of linguistic work that constitutes a genuine treasure-house for the NLP practitioner. In addition, by being largely neutral with respect to formalism and yet semantically and functionally oriented, it is especially well-suited to a generation perspective. <p> There were several sources for candidate adverbial complement classes to cover in surge-2.0: * The sub-corpus of human-written summaries whose in-depth analysis was presented in section 2. * The comprehensive lists of adverbial classes independently presented from different angles in Chapters 8, 9, 14 and 15 of <ref> [ Quirk et al. 1985 ] </ref> . * The more limited lists of adverbial classes presented in [ Halliday 1985 ] , [ Thompson and Longacre 1985 ] and [ Talmy 1985 ] . <p> In general, I considered only forms that occurred independently in two of these sources, considering each chapter of <ref> [ Quirk et al. 1985 ] </ref> as an independent source. In what follows, I do not present the painstaking derivation and cross-examination process that this study involved. I instead presents the end result from the perspective of a surge user switching from the 1.0 to the 2.0 version. <p> So for example, the top-level pattern for the sentence "Orlando defeated Toronto yesterday" where "yesterday" is a Time circumstantial is: (pattern (dots -synt-roles subject- dots -synt-roles verb- dots -synt-roles direct-object- dots -circum time-)) This approach assumes that there is no syntactic distinction among the various circumstantials. However, <ref> [ Quirk et al. 1985 ] </ref> distinguish between several classes of circumstantials (that they call adverbials), each characterized by a distinct syntactic behavior. First, they distinguish among adjuncts, disjuncts, subjuncts and conjuncts. Then, they further distinguish between predicate adjuncts and sentence adjuncts. B.3.2.1.1 Adjuncts vs. <p> They are thus beyond the scope of the present extensions and are were not implemented in surge-2.0. In contrast, surge-2.0 incorporates the distinction between adjuncts and disjuncts. <ref> [ Quirk et al. 1985 ] </ref> give four tests to distinguish adjuncts from disjuncts 21 . <p> Similarly, (2) above can be equally well interpreted as synonymous to the temporal (2a) and the causative 22 Called "contingency" clauses in <ref> [ Quirk et al. 1985 ] </ref> , pp:1086. 23 Called "absolutive" clauses by [ Thompson and Longacre 1985 ] pp:200-201 and "suppletive" clauses by [ Quirk et al. 1985 ] , pp:1120-27. (2b). <p> Similarly, (2) above can be equally well interpreted as synonymous to the temporal (2a) and the causative 22 Called "contingency" clauses in <ref> [ Quirk et al. 1985 ] </ref> , pp:1086. 23 Called "absolutive" clauses by [ Thompson and Longacre 1985 ] pp:200-201 and "suppletive" clauses by [ Quirk et al. 1985 ] , pp:1120-27. (2b). Their versatility and conciseness make Co-Event clauses a construct of choice in the corpora of human--written summaries I analyzed. B.3.2.2.5 Conditional adverbials There are three conditional adverbials in surge-2.0: Condition, Concessive-Condition and Concession, and they can surface only as disjuncts.
Reference: [ Rau 1987 ] <author> L.F. Rau. </author> <title> Information retrieval in never ending stories. </title> <booktitle> In Proceedings of the 6th National Conference on Artificial Intelligence, </booktitle> <pages> pages 317-322, </pages> <address> Washington, </address> <year> 1987. </year>
Reference-contexts: While there are systems that attempt to summarize textual input such as newswire articles by selecting representative sentences in the text (e.g., <ref> [ Rau 1987 ] </ref> ), they are not directly relevant either because they involve no generation. 6.1.1 Ana The field of summary report generation was pioneered by Kukich. Her system ana [ Kukich 1983 ] summarizes the daily fluctuations of several stock market indexes from half-hourly updates of their values.
Reference: [ Reiter 1991 ] <author> E.B. Reiter. </author> <title> A New Model for Lexical Choice for Open-Class Words. </title> <journal> Computational Intelligence, </journal> <volume> (7), </volume> <month> December </month> <year> 1991. </year>
Reference-contexts: While both generate summaries, the former is representative of the class of microcoded generators that also includes fog [ Bourbeau et al. 1990 ] , lfs [ Iordanskaja et al. 1994 ] , kamp [ Appelt 1985 ] , kalipsos [ Nogier 1990 ] , fn <ref> [ Reiter 1991 ] </ref> , epicure [ Dale 1992 ] , igen [ Rubinoff 1992 ] , comet [ McKeown et al. 1990 ] , avdisorII [ Elhadad 1993b ] and plandoc [ Kukich et al. 1994 ] while the latter is representative of the class of macrocoded generators that also <p> The lexicalizer generally builds the syntactic structure in top-down recursive fashion following the algorithm below: 1. Choose a concept to head the sentence structure. 12 In particular, I do not discuss its relation to adjacent topics such as user-modeling [ Paris 1987 ] , conversational implicatures <ref> [ Reiter 1991 ] </ref> or argumentation [ Elhadad 1993b ] . 13 Lexical items are traditionally divided into (a) open-class lexical items (also called cognates) such as nouns, verbs, adjectives and adverbs and (b) closed-class lexical items (also called function words) such as articles, pronouns and conjunctions. <p> In this thesis, I consider it only from the perspective of generating paraphrases in the context of written report production for restricted quantitative domains where the readership is assumed uniform. Therefore, I do not discuss its relation to issues such as user-modeling [ Paris 1987 ] , conversational implicatures <ref> [ Reiter 1991 ] </ref> or argumentation [ Elhadad 1993b ] . For application domains where these issues are crucial, the DSS could not be assumed to include all the relevant aspects of an entity to describe.
Reference: [ Reiter 1994 ] <author> E.B. Reiter. </author> <booktitle> Has a consensus natural language generation architecture appeared and is it psycholinguistically plausible? In Proceedings of the 7th International Workshop on Natural Language Generation, </booktitle> <pages> pages 163-170, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: How the overall generation process can be decomposed into modules is still a matter of open debate among researchers in the field. However, the design of most generators built for practical applications essentially varies on a common theme (cf. <ref> [ Reiter 1994 ] </ref> ). Temporarily ignoring the multi-sentential aspect of some generators to focus on sentence generation (I revisit in detail the design issues introduced here within the larger framework of full text generation in Section 3.3.2), this common theme is outlined in Fig. 1.6. <p> requires the acquisition of a new type of linguistic knowledge structure: revision operations specifying the 14 Much publicized in the research literature [ Appelt 1985 ] [ Danlos 1986 ] [ Meteer 1990 ] [ Rubinoff 1992 ] yet of marginal significance in most practical applications as pointed out by <ref> [ Reiter 1994 ] </ref> . 10 Complex sentence S 2 containing two floating facts: "Houston, TX Buck Johnson scored a season high 26 points Thursday night and the Houston Rockets routed the Orlando Magic 119 95 for their sixth straight win".
Reference: [ Robin 1990 ] <author> J. Robin. </author> <title> Lexical Choice in Natural Language Generation. </title> <type> Technical Report CUCS-040-90, </type> <institution> Columbia University, </institution> <year> 1990. </year>
Reference-contexts: For such a review with a special focus on the relation between architecture and lexical choice, see <ref> [ Robin 1990 ] </ref> .
Reference: [ Roesner 1987 ] <author> D. Roesner. SEMTEX: </author> <title> a text generator for German. </title> <editor> In Gerard Kempen, editor, </editor> <booktitle> Natural Language Generation: New Results in Artificial Intellligence, Psychology and Linguistics. </booktitle> <publisher> Martinus Ninjhoff Publishers, </publisher> <year> 1987. </year>
Reference-contexts: 1990 ] , avdisorII [ Elhadad 1993b ] and plandoc [ Kukich et al. 1994 ] while the latter is representative of the class of macrocoded generators that also includes Danlos' generator [ Danlos 1986 ] , phred [ Jacobs 1985 ] , pauline [ Hovy 1988 ] , semtex <ref> [ Roesner 1987 ] </ref> and weiver [ Inui et al. 1992 ] . The fact that ana generates more complex sentences than gossip generalizes to the respective classes of generators to which they belong. Thus, existing generators either microcode simpler sentences or macrocode more complex sentences. <p> six main systems generated natural language reports to summarize quantitative data: ana [ Kukich 1983 ] [ Kukich 1985 ] , fog [ Bourbeau et al. 1990 ] [ Polguere 1990 ] , gossip [ Carcagno and Iordanskaja 1993 ] , lfs [ Iordanskaja et al. 1994 ] , semtex <ref> [ Roesner 1987 ] </ref> , and sage [ Roth et al. 1991 ] . I briefly review each of these systems in the following subsections. <p> It thus seems that the lexicalist flavor of the MTT is more motivated by its origin in lexicographical work than by its particular suitability to sentence generation. 6.1.3 Other summary report generators Another system implemented for the domain of labor market statistics, this time in German, is semtex <ref> [ Roesner 1987 ] </ref> . It produces summaries of similar content and style to those generated by lfs. It is also implemented in an object-oriented fashion (it uses flavors, a lisp-based object system whereas lfs uses a prolog-based object system.).
Reference: [ Roth et al. 1991 ] <author> S. Roth, J. Mattis, and X. Mesnard. </author> <title> Graphics and natural language as component of automatic explanation. </title> <editor> In J.W. Sullivan and S.W. Tyler, editors, </editor> <booktitle> Intelligent user-interfaces, </booktitle> <publisher> ACM press frontier. Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: to summarize quantitative data: ana [ Kukich 1983 ] [ Kukich 1985 ] , fog [ Bourbeau et al. 1990 ] [ Polguere 1990 ] , gossip [ Carcagno and Iordanskaja 1993 ] , lfs [ Iordanskaja et al. 1994 ] , semtex [ Roesner 1987 ] , and sage <ref> [ Roth et al. 1991 ] </ref> . I briefly review each of these systems in the following subsections. <p> The sage system <ref> [ Roth et al. 1991 ] </ref> generates a combination of text and charts summarizing the current status of a large engineering project that help managers quickly respond to unforeseen difficulties or missed deadlines and keep the project on track. <p> This system suggests the great potential for office-automation applications of summary report generation. However, while focusing on the issue of coordinating textual and graphical media, sage relies on ad-hoc techniques for text generation (cf. <ref> [ Roth et al. 1991 ] </ref> , p.216). 6.1.4 Comparison with STREAK An important first difference between previous summary report generation systems and streak is that they perform two tasks that are not implemented in the current version of the streak prototype: conceptual summarization and combination of multiple sentences in a
Reference: [ Rubinoff 1992 ] <author> R. Rubinoff. </author> <title> Negotiation, feedback and perspective within natural language generation. </title> <type> PhD thesis, </type> <institution> Computer Science Department, University of Pennsylvania, </institution> <year> 1992. </year>
Reference-contexts: of the class of microcoded generators that also includes fog [ Bourbeau et al. 1990 ] , lfs [ Iordanskaja et al. 1994 ] , kamp [ Appelt 1985 ] , kalipsos [ Nogier 1990 ] , fn [ Reiter 1991 ] , epicure [ Dale 1992 ] , igen <ref> [ Rubinoff 1992 ] </ref> , comet [ McKeown et al. 1990 ] , avdisorII [ Elhadad 1993b ] and plandoc [ Kukich et al. 1994 ] while the latter is representative of the class of macrocoded generators that also includes Danlos' generator [ Danlos 1986 ] , phred [ Jacobs 1985 <p> acquire revision rules In order to handle supplementary content opportunistically, the new generation model described above requires the acquisition of a new type of linguistic knowledge structure: revision operations specifying the 14 Much publicized in the research literature [ Appelt 1985 ] [ Danlos 1986 ] [ Meteer 1990 ] <ref> [ Rubinoff 1992 ] </ref> yet of marginal significance in most practical applications as pointed out by [ Reiter 1994 ] . 10 Complex sentence S 2 containing two floating facts: "Houston, TX Buck Johnson scored a season high 26 points Thursday night and the Houston Rockets routed the Orlando Magic 119 <p> Another interesting aspect of this new generation model is that it combines a unique set of properties whose desirability had been independently advocated in previous work: * It distinguishes between foreground content to convey obligatorily and background content to convey opportunistically <ref> [ Rubinoff 1992 ] </ref> * It realizes floating facts across different linguistic ranks [ Elhadad 1993b ] . * It can conflate the expression of several facts within a single word [ Elhadad 1993b ] 164 * It uses declarative knowledge sources [ Nogier 1990 ] [ Polguere 1990 ] .
Reference: [ Scott and Souza 1990 ] <author> D.R. Scott and C.S. Souza. </author> <title> Getting the message across in RST-based text generation. </title> <editor> In R. Dale, C.S. Mellish, and M. Zock, editors, </editor> <booktitle> Current Research in Natural Language Generation. </booktitle> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: To build a first draft, weiveR traverses this semantic tree top-down, progressively replacing semantic subtrees by corresponding fully lexicalized syntactic trees. To perform this mapping, weiveR relies on the sentence level content organization heuristics described in <ref> [ Scott and Souza 1990 ] </ref> and a phrasal lexicon similar to the one described in [ Jacobs 1985 ] . The final draft representation consists of a hybrid tree, whose top-levels are structured in terms of rhetorical relations and whose bottom-levels are structured in terms of syntactic dependencies.
Reference: [ Shabes et al. 1988 ] <author> Y. Shabes, A. Abeille, and A.K. Joshi. </author> <title> Parsing strategies with `lexicalized' grammars: application to tree adjoining grammars. </title> <booktitle> In Proceedings of the 12th International Conference on Computational Linguistics, </booktitle> <institution> Karl Marx University of Economics, </institution> <address> Budapest, </address> <year> 1988. </year> <pages> COLING. </pages>
Reference-contexts: The second and most dramatic extension of the formalism was the introduction of Lexicalized TAGs <ref> [ Shabes et al. 1988 ] </ref> .
Reference: [ Shieber and Shabes 1991 ] <author> S.M. Shieber and Y. Shabes. </author> <title> Generation and synchronous tree-adhoining grammars. </title> <journal> Computational Intelligence, </journal> <volume> 7(4) </volume> <pages> 220-228, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: Considering this last remark it comes as no surprise that all subsequent proposals to adapt TAGs to the specific needs of generation used lexicalized TAGs as their starting point. Within this line of research, three main efforts have been: * LD/LP TAGs [ Harbusch 1994 ] * Synchronous TAGs <ref> [ Shieber and Shabes 1991 ] </ref> . * Systemic TAGs [ Yang et al. 1991 ] [ McCoy et al. 1992 ] . <p> But a full-fledged generation system must start processing from an input that is a semantic as possible. The latest two extensions of TAGs attacked this deficiency of the formalism for generation. In <ref> [ Shieber and Shabes 1991 ] </ref> the authors propose to use for generation, the formalism of synchronous TAGs that they had developed for interpretation. A generator based on this extended version of TAGs would accept as input a logical form structured as a semantic tree. <p> The present thesis extends the scope of incremental generation research to encompass work on revision-based generation. In spite of being hailed as especially suited for incremental generation, TAGs were deliberately designed to be monotonic (cf. <ref> [ Shieber and Shabes 1991 ] </ref> , p.226). They therefore do not present any advantage over other monotonic grammatical formalisms for the development of a non-monotic, opportunistic generator like streak. Implementing streak with TAGs would have required working out yet another extension of the formalism.
Reference: [ Simonin 1985 ] <author> N. Simonin. Essai de modelisation de l'expertise en redaction de textes. </author> <booktitle> In Proceedings of COGNITIVA 85. COGNITIVA, </booktitle> <year> 1985. </year>
Reference-contexts: 1993b ] 164 * It uses declarative knowledge sources [ Nogier 1990 ] [ Polguere 1990 ] . * It is stratificational and modular [ Polguere 1990 ] . * It uses a uniform underlying formalism (functional descriptions) to represent utterances at all levels of abstraction and all linguistic ranks <ref> [ Simonin 1985 ] </ref> [ Dale 1992 ] [ Elhadad 1993b ] . * It interleaves planning and realization [ Appelt 1985 ] [ Hovy 1988 ] . 7.1.3 Contributions to revision-based generation and incremental generation The major contribution of this thesis to revision-based generation and incremental generation is the extensive
Reference: [ Skaliar 1994 ] <author> D. Skaliar. </author> <title> A FUF interpreter based on graph representations. </title> <type> Technical report, </type> <institution> Ben Gurion University of the Negev, Beer Sheva, Israel, </institution> <year> 1994. </year>
Reference-contexts: In example run 1, 58% of the overall run time is spent in relocations called for canonization purposes and 24% in relocations called for the purpose of cutting sub-FDs. Skaliar <ref> [ Skaliar 1994 ] </ref> describes an on-going effort to implement a new version of fuf which internally represents FDs directly as quotient sets as opposed to lists as in the current version.
Reference: [ Smadja and McKeown 1991 ] <author> F.A. Smadja and K.R. McKeown. </author> <title> Using collocations for language generation. </title> <journal> Computational Intelligence, </journal> <volume> 7(4) </volume> <pages> 229-239, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: The initial input set was incrementally created over seven years during the development of the generation systems comet [ McKeown et al. 1990 ] [ McKeown et al. 1993 ] , cook <ref> [ Smadja and McKeown 1991 ] </ref> and advisor-II [ Elhadad 1993b ] . <p> In addition to streak, it has been used as the underlying environment for the development of a wide variety of generation applications at Columbia University including multi-media explanation [ McKeown et al. 1990 ] , stock market reports <ref> [ Smadja and McKeown 1991 ] </ref> , and interactive on-line student advising [ Elhadad 1993b ] . <p> The initial input set was incrementally created over seven years during the development of the generation systems comet [ McKeown et al. 1990 ] [ McKeown et al. 1993 ] , cook <ref> [ Smadja and McKeown 1991 ] </ref> and advisor-II [ Elhadad 1993b ] . The test inputs of surge-1.0 are presented in [ Elhadad 1993b ] . In this section, I present the extension of the input set testing the extensions from from surge-1.0 to surge-2.0.
Reference: [ Smadja 1991 ] <author> F. Smadja. </author> <title> Retrieving Collocational Knowledge from Textual Corpora. An Application: Language Generation. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Columbia University, </institution> <year> 1991. </year>
Reference-contexts: This type of evaluation relying on one or several human judges is commonly used in statistical NLP. For example, it has been used to evaluate systems which compile collocations <ref> [ Smadja 1991 ] </ref> or form groups of semantically related adjectives [ Hatzivassiloglou and McKeown 1993 ] . However, in the context of language generation this type of approach would not yield very interesting results. <p> As the test domain for this evaluation, I chose the stock market for two reasons: (1) large textual corpora of reports in this domain are available from newswires and (2) it has been the object of several language generation projects [ Kukich 1983 ] [ Contant 1986 ] <ref> [ Smadja 1991 ] </ref> . The test corpus consisted of reports on the American, Asian and European stock markets by UPI, AP and Reuter compiled from the newsreader. Its size was about 445,000 words.
Reference: [ Strzalkowski 1994 ] <author> T. (Ed.) Strzalkowski. </author> <title> Reversible grammars in natural language processing. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1994. </year>
Reference-contexts: An exception to this general trend, may be the area of reversible grammars <ref> [ Strzalkowski 1994 ] </ref> . Researchers in this field attempt to circumscribe a minimal set of modifications and extensions allowing the computational grammars and formalisms they developed for parsing to be re-used for generation as well.
Reference: [ Talmy 1976 ] <author> L. Talmy. </author> <title> Semantic causative types. </title> <editor> In M. Shibatani, editor, </editor> <title> The grammar of causative constructions, volume 6 of Syntax and semantics. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1976. </year>
Reference-contexts: This non-isomorphism is well illustrated in Fig. 3.12 containing all three representation layers for the same phrase. Non-isomorphism between semantic and syntactic structure has been noted in many domains (cf. <ref> [ Talmy 1976 ] </ref> , [ Talmy 1983 ] , [ Zock 1988 ] ) and has multiple aspects: several semantic elements can be conflated into a single syntactic element, some syntactic elements may be present for purely grammatical reasons without corresponding to any of the semantic elements, the syntactic element
Reference: [ Talmy 1983 ] <author> L. Talmy. </author> <title> How language structures space. In H.L. Pick and L.P. Acredolo, editors, Spatial orientation: theory, research and application. </title> <publisher> Plenum Press, </publisher> <address> New York/London, </address> <year> 1983. </year> <month> 356 </month>
Reference-contexts: This non-isomorphism is well illustrated in Fig. 3.12 containing all three representation layers for the same phrase. Non-isomorphism between semantic and syntactic structure has been noted in many domains (cf. [ Talmy 1976 ] , <ref> [ Talmy 1983 ] </ref> , [ Zock 1988 ] ) and has multiple aspects: several semantic elements can be conflated into a single syntactic element, some syntactic elements may be present for purely grammatical reasons without corresponding to any of the semantic elements, the syntactic element realizing the semantic head can
Reference: [ Talmy 1985 ] <author> L. Talmy. </author> <title> Lexicalization patterns: semantic structure in lexical form. </title> <editor> In T. Shopen, edi-tor, </editor> <title> Grammatical categories and the lexicon, volume 3 of Language typology and syntactic description. </title> <publisher> Cambridge University Press, </publisher> <year> 1985. </year>
Reference-contexts: 2. * The comprehensive lists of adverbial classes independently presented from different angles in Chapters 8, 9, 14 and 15 of [ Quirk et al. 1985 ] . * The more limited lists of adverbial classes presented in [ Halliday 1985 ] , [ Thompson and Longacre 1985 ] and <ref> [ Talmy 1985 ] </ref> . In general, I considered only forms that occurred independently in two of these sources, considering each chapter of [ Quirk et al. 1985 ] as an independent source. In what follows, I do not present the painstaking derivation and cross-examination process that this study involved.
Reference: [ Thompson and Longacre 1985 ] <author> S.A. Thompson and R.E. Longacre. </author> <title> Adverbial clauses. </title> <editor> In T. Shopen, editor, </editor> <title> Complex constructions, volume 2 of Language typology and syntactic description. </title> <publisher> Cambridge University Press, </publisher> <year> 1985. </year>
Reference-contexts: whose in-depth analysis was presented in section 2. * The comprehensive lists of adverbial classes independently presented from different angles in Chapters 8, 9, 14 and 15 of [ Quirk et al. 1985 ] . * The more limited lists of adverbial classes presented in [ Halliday 1985 ] , <ref> [ Thompson and Longacre 1985 ] </ref> and [ Talmy 1985 ] . In general, I considered only forms that occurred independently in two of these sources, considering each chapter of [ Quirk et al. 1985 ] as an independent source. <p> Similarly, (2) above can be equally well interpreted as synonymous to the temporal (2a) and the causative 22 Called "contingency" clauses in [ Quirk et al. 1985 ] , pp:1086. 23 Called "absolutive" clauses by <ref> [ Thompson and Longacre 1985 ] </ref> pp:200-201 and "suppletive" clauses by [ Quirk et al. 1985 ] , pp:1120-27. (2b). Their versatility and conciseness make Co-Event clauses a construct of choice in the corpora of human--written summaries I analyzed. <p> Concession can also be realized by a PP. The polarity feature distinguishes between positive conditions, whose default subordinator is "if" and negative conditions, whose default subordinator is "unless". Further subdivisions of condition clauses, such as the predictive vs. hypothetical vs. counter-factual distinctions discussed in <ref> [ Thompson and Longacre 1985 ] </ref> interacts tightly with the modality system of the grammar and were thus left for a future round of extension. B.3.2.2.6 Process adverbials There are four "process" adverbials in surge-2.0: Manner, Means, Instrument and Comparison.
Reference: [ Vaughan and McDonald 1986 ] <author> M. Vaughan and D.D. McDonald. </author> <title> A Model of Revision in Natural Language Generation. </title> <booktitle> In Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Columbia University, New York, </address> <year> 1986. </year> <booktitle> ACL. </booktitle>
Reference-contexts: It has been proposed in different flavors by [ Mann 1983 ] , <ref> [ Vaughan and McDonald 1986 ] </ref> [ Meteer 1991 ] , [ Yazdani 1987 ] , [ Gabriel 1988 ] , [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] and [ Inui et al. 1992 ] . <p> Also weiveR does not attempt summarize the content it has to convey and is not constrained by space. Finally, weiveR relies on a phrasal lexicon whereas streak uses a word-based lexicon. 6.2.3 At what level to perform revision? Both Yazdani and Meteer (at least in her initial paper <ref> [ Vaughan and McDonald 1986 ] </ref> ) proposed performing revision from an actual natural language draft.
Reference: [ Vendler 1968 ] <author> Zeno Vendler. </author> <title> Adjectives and Nominalizations. </title> <publisher> Mouton, </publisher> <address> The Hague, Paris, </address> <year> 1968. </year>
Reference-contexts: Some interesting investigations in that direction have been carried out by some authors such as <ref> [ Vendler 1968 ] </ref> or [ Levi 1978 ] but each discuss only a narrow range of nominal meanings and more studies focusing on other ranges are needed before the synthetic integration of these independent efforts within a unifying framework can even be contemplated. <p> In particular, [ Fries 1970 ] proposes a more complete set of functions. It also includes detailed constraints on co-occurrence of several elements filling the same function (with different semantics) in a given NP. Finally, the work of <ref> [ Vendler 1968 ] </ref> and [ Levi 1978 ] on nominalizations and non-predicative adjectives could serve as a good though quite limited in scope - starting point, towards the development of a set of thematic roles for a semantic input specification of nominals paralleling the set of thematic roles already used
Reference: [ Vijay-Shanker 1992 ] <author> K. Vijay-Shanker. </author> <title> Using descriptions of trees in a tree adjoining grammar. </title> <journal> Computational Linguistics, </journal> <volume> 18(4) </volume> <pages> 483-517, </pages> <year> 1992. </year>
Reference-contexts: However, only lexical and syntactic constraints could influence the course of the derivation: the nodes of the trees were only labeled by a word and/or a syntactic category. The need to model semantic and pragmatic constraints as well, led to the introduction of Functional TAGs <ref> [ Vijay-Shanker 1992 ] </ref> , where each tree node is associated with a feature structure. The functional unification of these feature structures is used to constrain the adjoining and substitution operations.
Reference: [ Wahlster et al. 1993 ] <author> W. Wahlster, E. Andre, W. Finkler, H.J. Profitlich, and T. Rist. </author> <title> Plan-based integration of natural language and graphics generation. </title> <journal> Artificial Intelligence, </journal> (63):387-427, 1993. 
Reference-contexts: This decomposition parallels the division in surge between the grammar proper and the linearizer (cf. Section B.2.1 of Appendix B). LD/LP TAGs have been used in the multi-media presentation system wip [ Andre et al. 1993 ] <ref> [ Wahlster et al. 1993 ] </ref> . This system generates both graphics and natural language to provide explanations on how to operate an esspresso machine. In this type of application the emphasis is on the definition of the overall system architecture and on the task of coordinating the two media.
Reference: [ Winograd 1983 ] <author> T. Winograd. </author> <title> Language as a cognitive process. </title> <publisher> Addison-Wesley, </publisher> <year> 1983. </year>
Reference-contexts: games with A 95-93 VICTORY OVER THE DETROIT PISTONS" 23 Some corpus sentences are even flatly ungrammatical. 24 The set of semantic roles used for this analysis are those one used in surge, which are themselves derived from various systemic linguistic sources [ Fawcett 1987 ] [ Halliday 1985 ] <ref> [ Winograd 1983 ] </ref> . 137 * Location, where "the Denver Nuggets rolled to A 124 110 VICTORY OVER THE UTAH JAZZ" becomes "the Denver Nuggets ended their three game losing streak with A 124 110 VICTORY OVER THE UTAH JAZZ" In the stock market domain, only cases of adjunctized Range <p> His main sources of inspiration were [ Fawcett 1987 ] and [ Lyons 1977 ] for the semantic aspects of the transitivity system, [ Mel'cuk and Pertsov 1987 ] for its lexical aspects, [ Halliday 1985 ] and <ref> [ Winograd 1983 ] </ref> for the other clause systems, the nominal systems and the overall organization of the grammar, [ Pollard and Sag 1987 ] for the treatment of long-distance dependencies and, last but not least, [ Quirk et al. 1985 ] for the many linguistic phenomena not mentioned in other <p> See [ Elhadad 1993b ] . The set of circumstantials accepted in input by surge-1.0 is given is Fig. B.16. These roles can appear in the input description of a clause independently of its process type. The Reason, Purpose, Instrument, Manner and Accompaniment circumstantials are based on <ref> [ Winograd 1983 ] </ref> while Behalf comes from [ Halliday 1985 ] . The locative and temporal circumstantials are somewhat ad-hoc. For most of these circumstantials, surge-1.0 can generate only prepositional realizations. In Fig.
Reference: [ Wong and Simmons 1988 ] <author> W.K.C. Wong and R.F Simmons. </author> <title> A blackboard model for text production with revision. </title> <booktitle> In Proceedings of the AAAI workshop on text-planning and realization, </booktitle> <address> St-Paul, MN, 1988. </address> <publisher> AAAI. </publisher>
Reference-contexts: It has been proposed in different flavors by [ Mann 1983 ] , [ Vaughan and McDonald 1986 ] [ Meteer 1991 ] , [ Yazdani 1987 ] , [ Gabriel 1988 ] , <ref> [ Wong and Simmons 1988 ] </ref> [ Cline and Nutter 1991 ] and [ Inui et al. 1992 ] . However, only two implemented generation system emerged from these proposals: Gabriel's Yh and Inui et. al's weiveR. <p> Without being specific about the characteristics of the representation to revise, [ Cline and Nutter 1991 ] also stressed the need for a representation to reflect both content planning and surface realization decisions. <ref> [ Wong and Simmons 1988 ] </ref> advocate performing revision using a blackboard. Although they are not specific about what type of information is to be posted on the blackboard during revision, the inherent flexibility of such a mechanism would certainly allow manipulations to simultaneously affect several layers of decisions. <p> SPOKESMAN does not perform revision. 15 In that sense, the hill-climbing phase of KDS [ Mann and Moore 1981 ] is not revision but local backtracking. 151 6.2.4 Revising to satisfy what goals? The revision goals considered by [ Meteer 1991 ] , [ Gabriel 1988 ] , <ref> [ Wong and Simmons 1988 ] </ref> and [ Inui et al. 1992 ] are purely stylistic. They are information-preserving revisions to make the draft more concise, clearer or more coherent.
Reference: [ Yang et al. 1991 ] <author> G. Yang, K. McCoy, and K. Vijay-Shanker. </author> <title> From functional specification to syntactic structure: systemic grammar and tree adjoining grammars. </title> <journal> Computational Intelligence, </journal> <volume> 7(4), </volume> <month> December </month> <year> 1991. </year>
Reference-contexts: Within this line of research, three main efforts have been: * LD/LP TAGs [ Harbusch 1994 ] * Synchronous TAGs [ Shieber and Shabes 1991 ] . * Systemic TAGs <ref> [ Yang et al. 1991 ] </ref> [ McCoy et al. 1992 ] .
Reference: [ Yazdani 1987 ] <author> M. Yazdani. </author> <title> Reviewing as a component of the text generation process. </title> <editor> In Gerard Kempen, editor, </editor> <booktitle> Natural Language Generation: New Results in Artificial Intellligence, Psychology and Linguistics. </booktitle> <publisher> Martinus Ninjhoff Publishers, </publisher> <year> 1987. </year>
Reference-contexts: It has been proposed in different flavors by [ Mann 1983 ] , [ Vaughan and McDonald 1986 ] [ Meteer 1991 ] , <ref> [ Yazdani 1987 ] </ref> , [ Gabriel 1988 ] , [ Wong and Simmons 1988 ] [ Cline and Nutter 1991 ] and [ Inui et al. 1992 ] . However, only two implemented generation system emerged from these proposals: Gabriel's Yh and Inui et. al's weiveR.
Reference: [ Zock et al. 1992 ] <author> M. Zock, M. Kay, D. Carcagno, J.F. Nogier, M. Nossin, K. DeSmedt, and F. Namer. </author> <title> Automatic text generation, </title> <booktitle> a tool for the buisiness world? In Proceedings of the Annual Expert Systems Conference, </booktitle> <address> Avignon, France, </address> <year> 1992. </year>
Reference-contexts: In contrast, automatically producing a natural language paragraph summarizing a large amount of quantitative data - unexploitable in its original exhaustive and tabular form is possible today. In fact, in a recent roundtable on technology transfer <ref> [ Zock et al. 1992 ] </ref> , several participants singled out this particular task as the most promising industrial application of natural language generation.
Reference: [ Zock 1988 ] <author> M. Zock. </author> <title> Natural languages are flexible tools, that's what makes them hard to explain, to learn and to use. </title> <editor> In M. Zock and G. Sabah, editors, </editor> <title> Advances in Natural Language Generation: an Interdisciplinary Perspective. </title> <publisher> Pinter and Ablex, </publisher> <year> 1988. </year> <month> 357 </month>
Reference-contexts: This non-isomorphism is well illustrated in Fig. 3.12 containing all three representation layers for the same phrase. Non-isomorphism between semantic and syntactic structure has been noted in many domains (cf. [ Talmy 1976 ] , [ Talmy 1983 ] , <ref> [ Zock 1988 ] </ref> ) and has multiple aspects: several semantic elements can be conflated into a single syntactic element, some syntactic elements may be present for purely grammatical reasons without corresponding to any of the semantic elements, the syntactic element realizing the semantic head can be deeply embedded in the
References-found: 102

