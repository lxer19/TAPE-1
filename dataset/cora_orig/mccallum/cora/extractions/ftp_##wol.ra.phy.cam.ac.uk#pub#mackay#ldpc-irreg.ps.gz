URL: ftp://wol.ra.phy.cam.ac.uk/pub/mackay/ldpc-irreg.ps.gz
Refering-URL: http://131.111.48.24/mackay/README.html
Root-URL: 
Email: mackay|stw11|mcdavey@mrao.cam.ac.uk  
Title: Comparison of Constructions of Irregular Gallager Codes  
Author: David J. C. MacKay, Simon T. Wilson and Matthew C. Davey 
Note: Draft 1.2. (Paper first issued  
Date: July 16, 1998|  July 9 1998).  
Address: Cambridge, CB3 0HE, United Kingdom.  
Affiliation: Cavendish Laboratory,  
Abstract: The low density parity check codes whose performance is closest to the Shannon limit are `Gallager codes' based on irregular graphs. We compare alternative methods for constructing these graphs and present two results. First, we have found a `super-Poisson' construction which gives significantly better empirical performance than a random construction. Second, whereas Gallager codes normally take N 2 time to encode, we investigate constructions of regular and irregular Gallager codes which allow faster encoding. We find that these `fast-encoding' Gallager codes have equally good performance.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. C. Davey and D. J. C. MacKay. </author> <title> Low density parity check codes over GF(q). </title> <booktitle> In Proceedings of the 1998 IEEE Information Theory Workshop. IEEE, </booktitle> <month> June </month> <year> 1998. </year>
Reference-contexts: The best known binary Gallager codes, however, are irregular codes whose parity check matrices have nonuniform weight per column [4]. The best known Gallager codes of all are irregular Gallager codes defined over finite fields GF (q) <ref> [1] </ref>. The irregular codes of Luby, Mitzenmacher, Shokrollahi and Spielman [4] have parity check matrices with both nonuniform weight per row and nonuniform weight per column. It has not yet been established whether both of these nonuniformities are desirable.
Reference: [2] <author> R. G. Gallager. </author> <title> Low density parity check codes. </title> <journal> IRE Trans. Info. Theory, </journal> <volume> IT-8:21-28, </volume> <month> Jan </month> <year> 1962. </year>
Reference-contexts: 1 Introduction Codes defined in terms of a low density parity check matrix <ref> [2, 3] </ref> are asymptotically good, and can be practically decoded with Gallager's sum-product algorithm (also known as belief propagation) [7, 8, 5], giving near Shannon limit performance.
Reference: [3] <author> R. G. Gallager. </author> <title> Low Density Parity Check Codes. Number 21 in Research monograph series. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1963. </year>
Reference-contexts: 1 Introduction Codes defined in terms of a low density parity check matrix <ref> [2, 3] </ref> are asymptotically good, and can be practically decoded with Gallager's sum-product algorithm (also known as belief propagation) [7, 8, 5], giving near Shannon limit performance.
Reference: [4] <author> M. G. Luby, M. Mitzenmacher, M. A. Shokrollahi, and D. A. Spielman. </author> <title> Improved low-density parity-check codes using irregular graphs and belief propagation. </title> <note> Submitted to ISIT98, </note> <year> 1998. </year>
Reference-contexts: Regular Gallager codes have been found to be superior to Turbo codes for short block-length CDMA applications [9]. The best known binary Gallager codes, however, are irregular codes whose parity check matrices have nonuniform weight per column <ref> [4] </ref>. The best known Gallager codes of all are irregular Gallager codes defined over finite fields GF (q) [1]. The irregular codes of Luby, Mitzenmacher, Shokrollahi and Spielman [4] have parity check matrices with both nonuniform weight per row and nonuniform weight per column. <p> The best known binary Gallager codes, however, are irregular codes whose parity check matrices have nonuniform weight per column <ref> [4] </ref>. The best known Gallager codes of all are irregular Gallager codes defined over finite fields GF (q) [1]. The irregular codes of Luby, Mitzenmacher, Shokrollahi and Spielman [4] have parity check matrices with both nonuniform weight per row and nonuniform weight per column. It has not yet been established whether both of these nonuniformities are desirable. <p> in the matrix, with each column appearing in the list a number of times equal to its weight; and make a similar list of all the rows in the matrix, each row appearing with multiplicity equal to its weight; then map one list onto the other by a random permutation <ref> [4] </ref>.
Reference: [5] <author> D. J. C. MacKay. </author> <title> Good error correcting codes based on very sparse matrices. </title> <note> submitted to IEEE transactions on Information Theory. Available from http://wol.ra.phy.cam.ac.uk/, 1997. </note>
Reference-contexts: 1 Introduction Codes defined in terms of a low density parity check matrix [2, 3] are asymptotically good, and can be practically decoded with Gallager's sum-product algorithm (also known as belief propagation) <ref> [7, 8, 5] </ref>, giving near Shannon limit performance. The original regular Gallager codes are defined by very sparse random parity check matrices with uniform weight t per column and t r per row.
Reference: [6] <author> D. J. C. MacKay and J. </author> <title> Lafferty. </title> <booktitle> Work in progress, </booktitle> <year> 1997. </year> <month> 8 </month>
Reference-contexts: For some profiles and blocklengths, we can create bipartite graphs from Cayley graphs and use these to define a parity check matrix. These constructions are deterministic <ref> [6] </ref>. Permutations. We can build parity check matrices by superposing random permutation matrices. How convenient this method is depends on the profile. There are many ways of laying out these permutation matrices to satisfy a given profile.
Reference: [7] <author> D. J. C. MacKay and R. M. Neal. </author> <title> Good codes based on very sparse matrices. In Colin Boyd, editor, Cryptography and Coding. </title> <booktitle> 5th IMA Conference, number 1025 in Lecture Notes in Computer Science, </booktitle> <pages> pages 100-111. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference-contexts: 1 Introduction Codes defined in terms of a low density parity check matrix [2, 3] are asymptotically good, and can be practically decoded with Gallager's sum-product algorithm (also known as belief propagation) <ref> [7, 8, 5] </ref>, giving near Shannon limit performance. The original regular Gallager codes are defined by very sparse random parity check matrices with uniform weight t per column and t r per row.
Reference: [8] <author> D. J. C. MacKay and R. M. Neal. </author> <title> Near Shannon limit performance of low density parity check codes. </title> <journal> Electronics Letters, </journal> <volume> 32(18) </volume> <pages> 1645-1646, </pages> <month> August </month> <year> 1996. </year> <journal> Reprinted Electronics Letters, </journal> 33(6):457-458, March 1997. 
Reference-contexts: 1 Introduction Codes defined in terms of a low density parity check matrix [2, 3] are asymptotically good, and can be practically decoded with Gallager's sum-product algorithm (also known as belief propagation) <ref> [7, 8, 5] </ref>, giving near Shannon limit performance. The original regular Gallager codes are defined by very sparse random parity check matrices with uniform weight t per column and t r per row. <p> Poisson A: The non-zero entries are placed `at random' as in Poisson, but with the added constraint that no two columns are allowed to have an overlap greater than one. [Similar to construction 1A in <ref> [8] </ref>.] Poisson B: The non-zero entries are placed `at random' as in Poisson A, but with the added constraint that the bipartite graph defined by the matrix should have no cycles of length less than some l. [This can be quite hard to enforce if the profile includes high weight rows <p> `at random' as in Poisson A, but with the added constraint that the bipartite graph defined by the matrix should have no cycles of length less than some l. [This can be quite hard to enforce if the profile includes high weight rows or columns.] [Similar to construction 1B in <ref> [8] </ref>.] Cayley graphs. For some profiles and blocklengths, we can create bipartite graphs from Cayley graphs and use these to define a parity check matrix. These constructions are deterministic [6]. Permutations. We can build parity check matrices by superposing random permutation matrices. <p> It is also possible to modify the construction algorithm for Gallager codes such that cycles of length 4, such as the one highlighted in figure 3 (b), are forbidden (as in construction 1A of <ref> [8] </ref>). This modification is sufficient to prevent the topology shown in figure 3 (a) from occuring. We discard these two codes with error floors in the subsequent comparisons. 3.3 Comparison of constructions The six families are compared with each other in figure 2.
Reference: [9] <author> V. Sorokine, F. R. Kschischang, and S. Pasupathy. </author> <title> Gallager codes for CDMA applications ii: Implementations, complexity and system capacity. </title> <journal> IEEE Trans. Communications, </journal> <note> 1998. submitted. </note>
Reference-contexts: The original regular Gallager codes are defined by very sparse random parity check matrices with uniform weight t per column and t r per row. Regular Gallager codes have been found to be superior to Turbo codes for short block-length CDMA applications <ref> [9] </ref>. The best known binary Gallager codes, however, are irregular codes whose parity check matrices have nonuniform weight per column [4]. The best known Gallager codes of all are irregular Gallager codes defined over finite fields GF (q) [1]. <p> In the second part we look into regular and irregular constructions which lend themselves to rapid encoding. One motivation for this second study is that the only drawback of regular Gallager codes compared to Turbo codes for CDMA applications appears to be their greater encoding complexity <ref> [9] </ref>. In all our experiments we study codes with rate 1=2 and blocklength about N = 10; 000. 2 Constructions We mention the following methods.
Reference: [10] <author> D. A. Spielman. </author> <title> Linear-time encodable and decodable error-correcting codes. </title> <note> To appear in IEEE Transactions on Information Theory, 1996. 9 </note>
Reference-contexts: In the case of `93y' we see an improvement of about 0.05dB. 4 Fast-encoding Gallager codes One of the possible drawbacks of Gallager codes is that their encoding time generally scales as N 2 . Inspired by Spielman's <ref> [10] </ref> work, we have investigated constructions of Gallager codes 4 (a) (aa) (b) `93p' Poisson `93a' `93x' `93y' t = 3; 9 mix; (c) Super-poisson (construction x), t = 3; 9 mix. (d) Super-poisson (construction y), t = 3; 9 mix.
References-found: 10

