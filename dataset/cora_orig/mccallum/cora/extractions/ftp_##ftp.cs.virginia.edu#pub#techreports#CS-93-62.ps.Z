URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-93-62.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: -jwd,sj3e-@virginia.edu  
Title: Memory Access Coalescing: A Technique for Eliminating Redundant Memory Accesses  
Author: JACK W. DAVIDSON and SANJAY JINTURKAR S. A. 
Note: U.  
Address: Thornton Hall  Charlottesville, VA 22903  
Affiliation: Department of Computer Science,  University of Virginia  
Abstract: As microprocessor speeds increase, memory bandwidth is increasingly the performance bottleneck for microprocessors. This has occurred because innovation and technological improvements in processor design have outpaced advances in memory design. Most attempts at addressing this problem have involved hardware solutions. Unfortunately, these solutions do little to help the situation with respect to current microprocessors. In previous work, we developed, implemented, and evaluated an algorithm that exploited the ability of newer machines with wide-buses to load/ store multiple floating-point operands in a single memory reference. This paper describes a general code improvement algorithm that transforms code to better exploit the available memory bandwidth on existing microprocessors as well as wide-bus machines. Where possible and advantageous, the algorithm coalesces narrow memory references into wide ones. An interesting characteristic of the algorithm is that some decisions about the applicability of the transformation are made at run time. This dynamic analysis significantly increases the probability of the transformation being applied. The code improvement transformation was implemented and added to the repertoire of code improvements of an existing retargetable optimizing back end. Using three current architectures as evaluation platforms, the effectiveness of the transformation was measured on a set of compute and memory-intensive programs. Interestingly, the effectiveness of the transformation varied significantly with respect to the instruction-set architecture of the tested platform. For one of the tested architectures, improvements in execution speed ranging from 5 to 40 percent were observed. For another, the improvements in execution speed ranged from 5 to 20 percent, while for yet another, the transformation resulted in slower code for all programs. 
Abstract-found: 1
Intro-found: 1
Reference: [Alex93] <author> Alexander, M. J., Bailey, M. W., Childers, B. R., Davidson, J. W., Jinturkar, S., </author> <title> Memory Bandwidth Optimizations for Wide-Bus Machines, </title> <booktitle> Proceedings of the 26th Annual Hawaii International Conference on System Sciences, </booktitle> <address> Maui, HI, </address> <month> January </month> <year> 1993, </year> <pages> pp. 466475. </pages>
Reference-contexts: For this loop, the transformation yields code that saves one memory reference per loop iteration. For machines with wide-buses (the size of the bus is greater than the size of a single-precision floating-point value), it is possible to compact some number of floating-point loads into a single reference <ref> [Alex93] </ref>. Indeed, the work reported here is a generalization and extension of this technique applied to data of any size. We call this technique memory access coalescing.
Reference: [Aho86] <author> Aho, A. V., Sethi, R., and Ullman, J. D., </author> <booktitle> Compilers Principles, Techniques and Tools, </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference: [Beni94] <author> Benitez, M. E., and Davidson J. W., </author> <title> The Advantages of Machine-Dependent Global Optimization, </title> <booktitle> Proceedings of the International Conference on Programming Languages and System Architectures, Springer Verlag Lecture Notes in Computer Science, </booktitle> <address> Zurich, Switzerland, </address> <month> March, </month> <year> 1994, </year> <pages> pp. 105124. </pages>
Reference-contexts: The following section briefly discusses work related to reducing memory bandwidth requirements of programs. Section 2 describes the algorithm with emphasis on the analyses required to apply the transformation safely and profitably. Section 3 describes the implementation of the algorithm in an existing retargetable back end called vpo <ref> [Beni89, Beni94] </ref>. Using a C front end and vpo, the effectiveness of the transformation was evaluated on three processors: DECs Alpha [Digi92], Motorolas 88100 [Moto91], and Motorolas 68030 [Moto85].
Reference: [Beni91] <author> Benitez, M. E., and Davidson, J. W., </author> <title> Code Generation for Streaming: an Access/Execute Mechanism, </title> <booktitle> Proceedings of the Fourth International Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, CA, </address> <month> April </month> <year> 1991, </year> <pages> pp. 132 141. </pages>
Reference-contexts: Register blocking and cache blocking can be used in combination to reduce the number of memory references and cache misses. Another program transformation that reduces a programs memory bandwidth requirements is called recurrence detection and optimization <ref> [Beni91] </ref>. Knuth defines a recurrence relation as a rule that defines each element of a sequence in terms of the preceding elements [Knut73]. Recurrence relations appear in the solutions to many compute and memory-intensive problems. Interestingly, codes containing recurrences often cannot be vectorized. <p> Line 12 analyzes the memory reference of the loop and partitions them into disjoint sets for later analysis <ref> [Beni91] </ref>. The memory access coalescing is done by WideRefOptimization. After identifying candidate memory references for coalescing, DoProfitabilityAnalysisAndModify is called. The algorithm is in Figure 3. The algorithm makes a copy of the loop and performs memory coalescing on it.
Reference: [Beni89] <author> Benitez, M. E., and Davidson J. W., </author> <title> A Portable Global Optimizer and Linker, </title> <booktitle> Proceedings of SIGPLAN 88 Conference on Programming Language Design and Implementation, </booktitle> <address> Atlanta, GA, </address> <month> June, </month> <year> 1988, </year> <month> pp.329338. </month>
Reference-contexts: The following section briefly discusses work related to reducing memory bandwidth requirements of programs. Section 2 describes the algorithm with emphasis on the analyses required to apply the transformation safely and profitably. Section 3 describes the implementation of the algorithm in an existing retargetable back end called vpo <ref> [Beni89, Beni94] </ref>. Using a C front end and vpo, the effectiveness of the transformation was evaluated on three processors: DECs Alpha [Digi92], Motorolas 88100 [Moto91], and Motorolas 68030 [Moto85].
Reference: [Call91] <author> Callahan, D., Kennedy, K., and Porterfield, A., </author> <title> Software Prefetching, </title> <booktitle> Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, CA, </address> <month> April </month> <year> 1991, </year> <pages> pp. 4052. </pages>
Reference-contexts: 1 INTRODUCTION Processor speeds are increasing much faster than memory speeds. For example, microprocessor performance has increased by 50 to 100 percent in the last decade, while memory performance has increased by only 10 to 15 percent. Additional hardware support such as larger, faster caches [Joup90], software-assisted caches <ref> [Call91] </ref>, speculative loads [Roge92], stream memory controllers [McKe94], and machines with wider memory buses, helps, but the problem is serious enough that performance gains by any approach, including software, are worth pursuing.
Reference: [Call90] <author> Callahan, D. and Carr, S. and Kennedy, K. </author> <title> Improving Register Allocation for Subscripted Variables. </title> <booktitle> Proceedings of the ACM SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> White Plains, NY, </address> <month> June, </month> <year> 1990, </year> <pages> pp 5365. </pages>
Reference-contexts: Register blocking can be considered a specific application of scalar replacement of subscripted variables <ref> [Call90, Dues93] </ref> and loop unrolling. Scalar replacement identifies reuse of subscripted variables and replaces them by references to temporary scalar variables. Unrolling the loop exposes a block of these subscripted variables to which scalar replacement can be applied.
Reference: [Chow90] <author> Chow, F. C. and Hennessy, J. L. </author> <title> The Priority-Based Coloring Approach to Register Allocation. </title> <journal> ACM Transactions on Programming Languages and Systems 12(4):501536 October 1990. </journal>
Reference-contexts: By allocating the variable to a register, memory loads and stores previously necessary to access the variable are eliminated. An evaluation of the register coloring approach to register allocation showed that up to 75 percent of the scalar memory references can be removed using these techniques <ref> [Chow90] </ref>. Cache blocking and register blocking are code transformations that also reduce a programs memory bandwidth requirement. These transformations can profitably be applied to codes that process large sets of data held in arrays. For example, consider the multiplication of two large arrays.
Reference: [Digi92] <institution> Alpha Architecture Handbook, Digital Equipment Corporation, </institution> <year> 1992. </year>
Reference-contexts: Section 3 describes the implementation of the algorithm in an existing retargetable back end called vpo [Beni89, Beni94]. Using a C front end and vpo, the effectiveness of the transformation was evaluated on three processors: DECs Alpha <ref> [Digi92] </ref>, Motorolas 88100 [Moto91], and Motorolas 68030 [Moto85]. Section 4 contains a summary. 1.1 RELATED WORK Software approaches to the memory bandwidth problem focus on reducing the memory bandwidth requirements of programs.
Reference: [Dues93] <author> Duesterwald, E., Gupta, R., and Soffa, M. L., </author> <title> A Practical Data Flow Framework for Array Reference Analysis and its Use in Optimizations, </title> <booktitle> Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <address> Albuquerque, NM, </address> <month> June </month> <year> 1993, </year> <pages> pp. 6877. </pages>
Reference-contexts: Register blocking can be considered a specific application of scalar replacement of subscripted variables <ref> [Call90, Dues93] </ref> and loop unrolling. Scalar replacement identifies reuse of subscripted variables and replaces them by references to temporary scalar variables. Unrolling the loop exposes a block of these subscripted variables to which scalar replacement can be applied.
Reference: [Joup90] <author> Jouppi, N., </author> <title> Improving Direct-Mapped Cache Performance by the Addition of a Small Fully Associative Cache and Prefetch Buffers, </title> <booktitle> Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <address> Seattle, WA, </address> <month> May </month> <year> 1990, </year> <pages> pp. 364373. </pages>
Reference-contexts: 1 INTRODUCTION Processor speeds are increasing much faster than memory speeds. For example, microprocessor performance has increased by 50 to 100 percent in the last decade, while memory performance has increased by only 10 to 15 percent. Additional hardware support such as larger, faster caches <ref> [Joup90] </ref>, software-assisted caches [Call91], speculative loads [Roge92], stream memory controllers [McKe94], and machines with wider memory buses, helps, but the problem is serious enough that performance gains by any approach, including software, are worth pursuing.
Reference: [Knut73] <author> Knuth, D. E., </author> <title> Volume 1: Fundamental Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1973. </year>
Reference-contexts: Another program transformation that reduces a programs memory bandwidth requirements is called recurrence detection and optimization [Beni91]. Knuth defines a recurrence relation as a rule that defines each element of a sequence in terms of the preceding elements <ref> [Knut73] </ref>. Recurrence relations appear in the solutions to many compute and memory-intensive problems. Interestingly, codes containing recurrences often cannot be vectorized. Consider the following C code: for (i = 2; i &lt; n; i++) This is the fifth Livermore loop, which is a tri-diagonal elimination below the diagonal.
Reference: [Lam91] <author> Lam, M. and Rothberg, E. E. and Wolf, M. E., </author> <title> The Cache Performance and Optimizations of Blocked Algorithms, </title> <booktitle> Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, CA, </address> <month> April, </month> <year> 1991, </year> <pages> pp 6374. </pages>
Reference-contexts: Cache blocking, however, transforms the code so that a block of the array that will fit in the cache is read in once, used many times, and then replaced by the next block. The performance benefits from this transformation can be quite good. Lam, Rothberg, and Wolf <ref> [Lam91] </ref> show that for multiplication of large, floating-point arrays, cache blocking can easily triple the performance of a cache-based system.
Reference: [Land93] <author> Landi, W., Ryder, B. G., and Zhang, S., </author> <title> Interprocedural Modification Side Effect Analysis with Pointer Aliasing, </title> <booktitle> Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <address> Albuquerque, NM, </address> <month> June </month> <year> 1993, </year> <pages> pp. 5667. </pages>
Reference-contexts: The two key components of the safety analysis address aliasing and data alignment issues. Alias analysis, in particular, is extremely difficult when the source language contains unrestricted pointers <ref> [Land92, Land93] </ref>. The problem is further compounded because for many codes where this transformation would be beneficial, the code is structured so that aliasing and data alignment hazards cannot precisely be determined via interprocedural, compile-time analysis.
Reference: [Land92] <author> Landi, W., and Ryder, B. G., </author> <title> A Safe Approximation Algorithm for Interprocedural Pointer Aliasing, </title> <booktitle> Proceedings of the ACM SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <address> San Francisco, CA, </address> <month> June </month> <year> 1992, </year> <pages> pp. 235248. </pages>
Reference-contexts: The two key components of the safety analysis address aliasing and data alignment issues. Alias analysis, in particular, is extremely difficult when the source language contains unrestricted pointers <ref> [Land92, Land93] </ref>. The problem is further compounded because for many codes where this transformation would be beneficial, the code is structured so that aliasing and data alignment hazards cannot precisely be determined via interprocedural, compile-time analysis.
Reference: [Lind91] <author> Lindley, C. A., </author> <title> Practical Image Processing in C, </title> <publisher> John Wiley and Sons, Inc., </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: The reason is that the Motorola 88100 has efficient instructions for extracting bytes and words from a 32-bit Program Description Lines of Code Convolution Gradient Directional Edge Convolution of a 500 by 500 black and white Image <ref> [Lind91] </ref> 154 Image Add Image addition of two 500 by 500 black and white frames 48 Image xor Image addition of two 500 by 500 black and white frames 48 Translate Translate 500 by 500 black and white image image to a new position 48 Eqntott Part of the SPEC 89
Reference: [McFa91] <author> McFarling, S., </author> <title> Procedure Merging with Instruction Caches, </title> <booktitle> Proceedings of the ACM SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Ontario, </address> <month> June </month> <year> 1991, </year> <pages> pp. 7179. </pages>
Reference: [McKe94] <author> McKee, S. A., Klenke, R. H., Schwab, A. J., Wulf, W. A., Moyer, S. A., and Aylor, J. H., </author> <title> Experimental Implementation of Dynamic Access Ordering, </title> <booktitle> Proceedings of the 27th Annual Hawaii International Conference on System Sciences, </booktitle> <address> Maui, HI, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: For example, microprocessor performance has increased by 50 to 100 percent in the last decade, while memory performance has increased by only 10 to 15 percent. Additional hardware support such as larger, faster caches [Joup90], software-assisted caches [Call91], speculative loads [Roge92], stream memory controllers <ref> [McKe94] </ref>, and machines with wider memory buses, helps, but the problem is serious enough that performance gains by any approach, including software, are worth pursuing. Furthermore, even with additional hardware, processors often do not obtain anywhere near their peak performance with respect to their memory systems.
Reference: [Moto91] <author> MC88110: </author> <title> Second Generation RISC Microprocessor User's Manual. Motorola, </title> <publisher> Inc., </publisher> <address> Phoenix, AZ, </address> <year> 1991. </year>
Reference-contexts: Section 3 describes the implementation of the algorithm in an existing retargetable back end called vpo [Beni89, Beni94]. Using a C front end and vpo, the effectiveness of the transformation was evaluated on three processors: DECs Alpha [Digi92], Motorolas 88100 <ref> [Moto91] </ref>, and Motorolas 68030 [Moto85]. Section 4 contains a summary. 1.1 RELATED WORK Software approaches to the memory bandwidth problem focus on reducing the memory bandwidth requirements of programs.
Reference: [Moto85] <editor> MC68020 32-bit Microprocessor Users Manual, </editor> <publisher> Prentice-Hall, Inc. </publisher> <address> Englewood Cliffs, N. </address> <note> J. 07632. </note>
Reference-contexts: Section 3 describes the implementation of the algorithm in an existing retargetable back end called vpo [Beni89, Beni94]. Using a C front end and vpo, the effectiveness of the transformation was evaluated on three processors: DECs Alpha [Digi92], Motorolas 88100 [Moto91], and Motorolas 68030 <ref> [Moto85] </ref>. Section 4 contains a summary. 1.1 RELATED WORK Software approaches to the memory bandwidth problem focus on reducing the memory bandwidth requirements of programs. For example, there is a plethora of research describing algorithms for register allocation, a fundamental transformation for reducing a programs memory bandwidth requirements.
Reference: [Roge92] <author> Rogers, A., and Li, K., </author> <title> Software Support for Speculative Loads, </title> <booktitle> Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Boston, MA, </address> <month> October </month> <year> 1992, </year> <pages> pp. 3850. </pages>
Reference-contexts: For example, microprocessor performance has increased by 50 to 100 percent in the last decade, while memory performance has increased by only 10 to 15 percent. Additional hardware support such as larger, faster caches [Joup90], software-assisted caches [Call91], speculative loads <ref> [Roge92] </ref>, stream memory controllers [McKe94], and machines with wider memory buses, helps, but the problem is serious enough that performance gains by any approach, including software, are worth pursuing. Furthermore, even with additional hardware, processors often do not obtain anywhere near their peak performance with respect to their memory systems.
Reference: [Spec89] <institution> Systems Performance Evaluation Cooperative, c/o Waterside Associates, </institution> <address> Fremont, CA, </address> <year> 1989. </year>
References-found: 22

