URL: ftp://ftp.cs.columbia.edu/reports/reports-1996/cucs-021-96.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1996.html
Root-URL: http://www.cs.columbia.edu
Title: Strong Tractability of Weighted Tensor Products  
Author: Henryk Wo zniakowski ; 
Address: New York, NY 10027, USA,  ul. Banacha 2, 00-097, Warsaw, Poland.  
Affiliation: 1 Department of Computer Science, Columbia University,  Institute of Applied Mathematics, University of Warsaw,  Columbia University Computer Science Department  
Note: Baltzer Journals  Dedicated to Ted Rivlin on the occasion of his 70th birthday  
Pubnum: Report CUCS-021-96  
Email: E-mail: henryk@cs.columbia.edu  
Phone: 2  
Date: October 30, 1995  
Abstract: We deal with approximating linear operators S d that are defined as d weighted tensor products. We consider the worst case, average case, randomized and probabilistic settings depending on how the error of an approximation is defined. The complexity is understood as the minimal number of linear functionals which are needed to approximate S d with error at most ". Strong tractability means that there exist nonnegative K and p such that the complexity is bounded by K " p for all d and all " 1. The smallest such p is called the strong exponent. We provide necessary and sufficient conditions for weighted tensor products to be strongly tractable, and we find their strong exponent. In the worst case and randomized settings, these conditions are expressed in terms of singular values f i g of the problem for d = 1, and in terms of the weights ffi i g of the problem. Strong tractability holds iff the sequences f i g and ffi i g go to zero polynomially fast. In the average case and probabilistic settings we consider Gaussian measures for which the traces of the covariance operators are uniformly bounded in d. We prove that strong tractability holds independently of the sequences f i g and ffi i g. In particular, if fi i = 1; 8 i; we get tensor product problems which are strongly tractable. The strong exponent in the average (or probabilistic) setting is always smaller than the strong exponent in the worst case setting. However, if the problem is not strongly tractable in the worst case setting, the strong exponent in the average case setting may be large. We illustrate our analysis by the approximation of smooth periodic functions. fl The research reported here was supported in part by the National Science Foundation and the Air Force Office of Scientific Research. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. S. Bakhvalov, </author> <title> On the optimality of linear methods for operator approximations in convex classes of functions, in Russian, </title> <journal> Zh. </journal> <note> Vychisl. Mat. Mat. Fiz., 11 (1971) 1014-1018. [English transl.: </note> <institution> USSR Comput. Math. Math. Phys. </institution> <month> 11 </month> <year> (1971) </year> <month> 244-249]. </month>
Reference-contexts: = comp wor ("; d 1) + 1 X comp wor ("=(fi d i ); d 1) : (7) We are ready to check which weighted tensor products are strongly tractable, see (1). 2 It is also known that the adaptive selection of functionals L j does not help, see <ref> [1, 2, 7] </ref>. H. <p> Then the (prob abilistic) complexity is comp pro ("; d) = min fn : e pro (n; d) " g : Here, the parameter ffi 2 <ref> [0; 1] </ref> and obviously small ffi is of particular importance. To stress the dependence on ffi we write comp pro ("; d) = comp pro ("; ffi; d). For Gaussian measures, the probabilistic complexity depends very weakly on ffi through a power of ln 1=ffi, see [6]. <p> H. Wozniakowski / Strong Tractability 15 Consider the Fourier expansion of a complex valued periodic function f defined on <ref> [0; 1] </ref> d , X ^ f (h) e h (x) where e h (x) = exp (2 i (h; x)), i = p P d j=1 h j x j for integers h j .
Reference: [2] <author> S. Gal and C. A. Micchelli, </author> <title> Optimal sequential and non-sequential procedures for evaluating a functional, </title> <journal> Appl. Anal. </journal> <month> 10 </month> <year> (1980) </year> <month> 105-120. </month>
Reference-contexts: = comp wor ("; d 1) + 1 X comp wor ("=(fi d i ); d 1) : (7) We are ready to check which weighted tensor products are strongly tractable, see (1). 2 It is also known that the adaptive selection of functionals L j does not help, see <ref> [1, 2, 7] </ref>. H.
Reference: [3] <author> C. A. Micchelli and T. J. Rivlin, </author> <title> A survey of optimal recovery, in Optimal Estimation in Approximation Theory, </title> <editor> C. A. Micchelli and T. J. Rivlin eds., </editor> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> (1977) </year> <month> 1-54. </month>
Reference-contexts: Let e (n; d) denote the minimal (worst case) error which can be achieved by computing n continuous linear functionals, e (n; d) = inf d f 2F d ;kfk1 It is well known 2 , see <ref> [3, 6, 7] </ref>, that the L j and minimizing e (n; d) are given by U (f ) = j=1 S d ( j;d ) ; and that e (n; d) = fl n+1;d : Hence, the (worst case) complexity is given by comp wor ("; d) = min fn :
Reference: [4] <author> E. Novak, </author> <title> Optimal linear randomization methods for linear operators in Hilbert spaces, </title> <journal> J. </journal> <note> Complexity 8 (1992) 22-36. </note>
Reference-contexts: Then the weighted tensor product problem is strongly tractable in the worst case setting iff the polynomial-exponents of f i g and ffi i g are positive, and then the strong exponent is p fl = max f1=p ; 1=p fi g : It is known, see <ref> [4] </ref>, that the randomized setting for approximating linear operators by arbitrary continuous functionals is closely related to the worst case setting. In particular, strong tractabilities in both settings are equivalent and the strong exponents are the same. In the average and probabilistic settings we consider Gaussian measures. <p> Then the (ran domized) complexity is comp ran ("; d) = min fn : e ran (n; d) " g : It is proven in <ref> [4] </ref> that the randomized and worst case complexity are closely related, 1 comp wor p comp ran ("; d) comp wor ("; d): This estimate implies that strong tractability in the randomized setting is equivalent to strong tractability in the worst case setting, and the strong exponents are the same.
Reference: [5] <author> I. H. Sloan and S. Joe, </author> <title> Lattice methods for multiple integration, </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1994. </year>
Reference-contexts: and 1 ~ 1 ~ 2 &gt; 0: We define H d as the Hilbert space of such functions with the inner product hf; gi H d = h2Z d 2ff The space H d (with ~ j = 1) is often studied for lattice methods for multivariate integration, see <ref> [5] </ref>. It is known that the parameter ff indicates the smoothness of the functions from H d . <p> For example, if ff &gt; 1 is an integer then f is (ff 1) times differentiable with respect to all variables, and after such differentiations the function has bounded variation in the sense of Hardy and Krause, see <ref> [5] </ref>. We want to approximate functions from H d in the G d = L 2 ([0; 1]) d norm.
Reference: [6] <author> J. F. Traub, G. W. Wasilkowski, and H. Wozniakowski, </author> <title> Information-based complexity, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Since we consider only linear problems over Hilbert spaces, the minimal cost is proportional to the minimal number of functionals needed to compute an approximation with error at most ", see e.g., <ref> [6] </ref>. We choose this definition of the complexity to simplify the paper. H. <p> However, if the problem is not strongly tractable in the worst case than the strong exponent in the average case may be large. In the probabilistic setting, we use known relations, see <ref> [6] </ref>, with the average case setting and conclude that strong tractabilities in these two settings are equivalent, and the strong exponents are the same. We illustrate our analysis for the approximation of smooth periodic functions. <p> Let e (n; d) denote the minimal (worst case) error which can be achieved by computing n continuous linear functionals, e (n; d) = inf d f 2F d ;kfk1 It is well known 2 , see <ref> [3, 6, 7] </ref>, that the L j and minimizing e (n; d) are given by U (f ) = j=1 S d ( j;d ) ; and that e (n; d) = fl n+1;d : Hence, the (worst case) complexity is given by comp wor ("; d) = min fn : <p> Hence, the minimal (average case) error e (n; d) which can be achieved by computing n continuous linear functionals is given by e 2 (n; d) = inf d F d It is known 3 , see e.g., <ref> [6] </ref>, that L j and which minimize e (n; d) are given by U (f ) = j=1 S d (f ); fl E fl 3 It is also known that the adaptive selection of functionals L j can only help by at most one, see [8]. H. <p> To stress the dependence on ffi we write comp pro ("; d) = comp pro ("; ffi; d). For Gaussian measures, the probabilistic complexity depends very weakly on ffi through a power of ln 1=ffi, see <ref> [6] </ref>. <p> comp pro ("; ffi; d) K " p (ln 1=ffi) q ; 8 "; ffi 2 (0; 1] and d = 1; 2; : : : : It is known that the probabilistic and average case settings for Gaussian mea sures and approximations of linear operators are closely related, see <ref> [6] </ref>.
Reference: [7] <author> J. F. Traub and H. Wozniakowski, </author> <title> A general theory of optimal algorithms, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: Let e (n; d) denote the minimal (worst case) error which can be achieved by computing n continuous linear functionals, e (n; d) = inf d f 2F d ;kfk1 It is well known 2 , see <ref> [3, 6, 7] </ref>, that the L j and minimizing e (n; d) are given by U (f ) = j=1 S d ( j;d ) ; and that e (n; d) = fl n+1;d : Hence, the (worst case) complexity is given by comp wor ("; d) = min fn : <p> = comp wor ("; d 1) + 1 X comp wor ("=(fi d i ); d 1) : (7) We are ready to check which weighted tensor products are strongly tractable, see (1). 2 It is also known that the adaptive selection of functionals L j does not help, see <ref> [1, 2, 7] </ref>. H.
Reference: [8] <author> G. W. Wasilkowski, </author> <title> Information of varying cardinality, </title> <journal> J. </journal> <note> Complexity 2 (1986) 204-228. </note>
Reference-contexts: 3 , see e.g., [6], that L j and which minimize e (n; d) are given by U (f ) = j=1 S d (f ); fl E fl 3 It is also known that the adaptive selection of functionals L j can only help by at most one, see <ref> [8] </ref>. H. Wozniakowski / Strong Tractability 10 where fl j;d are the eigenvectors of the covariance operator C -d of the Gaussian measure -d = S 1 d . The eigenvectors fl j;d correspond to the n largest eigenvalues fl 2;d 0.
Reference: [9] <author> G. W. Wasilkowski and H. Wozniakowski, </author> <title> Explicit cost bounds of algorithms for multivariate tensor product problems, </title> <journal> J. </journal> <note> Complexity 11 (1995) 1-56. </note>
Reference-contexts: Strong tractability for general linear multivariate problems has been studied in [10], and for tensor product problems in <ref> [9, 11] </ref>. Strong tractability of tensor products in the worst case setting depends on the singular values f i g of the problem for d = 1.
Reference: [10] <author> H. Wozniakowski, </author> <title> Tractability and strong tractability of linear multivariate problems, </title> <journal> J. </journal> <note> of Complexity 10 (1994) 96-128. </note>
Reference-contexts: Strong tractability for general linear multivariate problems has been studied in <ref> [10] </ref>, and for tensor product problems in [9, 11]. Strong tractability of tensor products in the worst case setting depends on the singular values f i g of the problem for d = 1. <p> Hence, the power of d goes to infinity as " goes to zero. We finally add that scaling of linear multivariate problems and their strong tractability are interrelated with some surprising consequences, see <ref> [10] </ref>. To overcome the scaling problem and to still find strongly tractable problems even in the worst case setting, we study weighted tensor products in this paper. 1 Usually, the complexity denotes the minimal cost needed to compute an approximation with error at most ".
Reference: [11] <author> H. Wozniakowski, </author> <title> Tractability and strong tractability of multivariate tensor product problems, </title> <journal> J. </journal> <note> of Computing and Information 4 (1994) 1-19. </note>
Reference-contexts: Strong tractability for general linear multivariate problems has been studied in [10], and for tensor product problems in <ref> [9, 11] </ref>. Strong tractability of tensor products in the worst case setting depends on the singular values f i g of the problem for d = 1. <p> It is proven in <ref> [11] </ref>, Theorem 5.1, that the problem is strongly tractable in the average case setting iff there exist p 2 (0; 1), a positive A, and an integer k such that fl and then the strong exponent p fl = inf 2p=(1 p) for p satisfying (9).
References-found: 11

