URL: http://www.cse.ucsc.edu/~pak/mkp.ps
Refering-URL: http://www.cse.ucsc.edu/~pak/
Root-URL: http://www.cse.ucsc.edu
Title: Multi-level Spectral Hypergraph Partitioning with Arbitrary Vertex Sizes  
Author: Jason Y. Zien, Martine D. F. Schlag, Pak K. Chan 
Address: Santa Cruz, CA 95064  
Affiliation: Computer Engineering University of California at Santa Cruz  
Abstract: This paper presents a new spectral partitioning formulation which directly incorporates vertex size information. The new formulation results in a generalized eigenvalue problem, and this problem is reduced to the standard eigenvalue problem. Experimental results show that incorporating vertex sizes into the eigenvalue calculation produces results that are 50% better than the standard formulation in terms of scaled ratio-cut cost, even when a Kernighan-Lin style iterative improvement algorithm taking into account vertex sizes is applied as a post-processing step. To evaluate the new method for use in multi-level partitioning, we combine the partitioner with a multi-level bottom-up clustering algorithm and an iterative improvement algorithm for partition refinement. Experimental results show that our new spectral algorithm is more effective than the standard spectral formulation and other par-titioners in the multi-level partitioning of hypergraphs of unit-sized vertices. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. J. Alpert and A. B. Kahng. </author> <title> Multiway partitioning via geometric embeddings, orderings, and dynamic programming. </title> <journal> IEEE Trans. on CAD, </journal> <volume> 14(11) </volume> <pages> 1342-1358, </pages> <month> Nov. </month> <year> 1995. </year>
Reference-contexts: A k-way spectral partitioning algorithm and new k-way ratio-cut cost function was presented in [4]. Recent methods for spectral k-way ratio-cut partitioning are presented in <ref> [1] </ref>. Additional approaches to spectral partitioning are presented in [9, 3]. A multi-level partitioning algorithm using recursive applications of the ratio-cut metric to form clusters is presented in [12]. The first spectral multi-level algorithm was developed by [2], however, it did not include iterative refinement at successive levels. <p> We used the geometric mean of the results over all seven benchmarks for k = 2; 4; 8; and 16. In every test group, MKP gives the best answer. Table 3 lists a side-by-side comparison of the MKP partitioning results with DP-RP <ref> [1] </ref>. The results are comparable but the runtime of MKP is a lot less.
Reference: [2] <author> S. T. Barnard and H. D. Simon. </author> <title> A fast multilevel implementation of recursive spectral bisection for partitioning unstructured problems. </title> <type> Technical Report RNR-92-033, </type> <institution> NASA Ames Research Center, NAS Systems Division, Moffet Field, </institution> <address> CA, </address> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: Thus, existing standard eigenvalue computation code can be used with no modifications. We present benchmarks to quantitatively show the effectiveness of the new method. Multiple levels of bottom-up clustering reduce the problem size and tend to produce superior results. Multi-level algorithms have been developed using both spectral <ref> [2] </ref>, and iterative [9, 10] approaches. However after the application of hierarchical clustering algorithms, the resulting graph may contain vertices of different sizes. An effective spectral partitioner must take those sizes into account to produce good solutions. Our spectral partitioner, MP (Multi-level K-way Partitioner), does exactly that. <p> Recent methods for spectral k-way ratio-cut partitioning are presented in [1]. Additional approaches to spectral partitioning are presented in [9, 3]. A multi-level partitioning algorithm using recursive applications of the ratio-cut metric to form clusters is presented in [12]. The first spectral multi-level algorithm was developed by <ref> [2] </ref>, however, it did not include iterative refinement at successive levels. Hendrickson and Leland implemented a multi-level spectral algorithm with a k-way Kernighan-Lin style refinement algorithm [9].
Reference: [3] <author> E. R. Barnes. </author> <title> Partitioning the nodes of a graph. </title> <booktitle> Proceedings of Graph Theory with Applications to Algorithms and Computer Science, </booktitle> <pages> pages 57-72, </pages> <year> 1985. </year>
Reference-contexts: A k-way spectral partitioning algorithm and new k-way ratio-cut cost function was presented in [4]. Recent methods for spectral k-way ratio-cut partitioning are presented in [1]. Additional approaches to spectral partitioning are presented in <ref> [9, 3] </ref>. A multi-level partitioning algorithm using recursive applications of the ratio-cut metric to form clusters is presented in [12]. The first spectral multi-level algorithm was developed by [2], however, it did not include iterative refinement at successive levels.
Reference: [4] <author> P. K. Chan, M. D. F. Schlag, and J. Y. Zien. </author> <title> Spectral k-way ratio-cut partitioning and clustering. </title> <journal> IEEE Trans. on CAD, </journal> <volume> 13(9) </volume> <pages> 1088-1096, </pages> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: Fast bipartitioning methods were developed based on a linear ordering of the vertices using the eigenvector associated with the second smallest eigenvalue of the Laplacian of a graph in [11, 7]. A k-way spectral partitioning algorithm and new k-way ratio-cut cost function was presented in <ref> [4] </ref>. Recent methods for spectral k-way ratio-cut partitioning are presented in [1]. Additional approaches to spectral partitioning are presented in [9, 3]. A multi-level partitioning algorithm using recursive applications of the ratio-cut metric to form clusters is presented in [12]. <p> Given a partitioning, the n fi k ratioed assignment matrix, R, has as entry r ih the value y ih p jjP h jj . This definition differs slightly from the one in <ref> [4] </ref>. M is the n fi n diagonal matrix whose m ii entry is the size of vertex i. Among the many variations of the k-way partitioning problem, we focus on optimizing the k-way ratio-cut cost function [4], that is, finding a solution R such that P k E h jjP <p> This definition differs slightly from the one in <ref> [4] </ref>. M is the n fi n diagonal matrix whose m ii entry is the size of vertex i. Among the many variations of the k-way partitioning problem, we focus on optimizing the k-way ratio-cut cost function [4], that is, finding a solution R such that P k E h jjP h jj is minimized. Although it may ap pear to be the same cost function as presented in [4], there is a subtle difference: the definitions of R and jjP h jj include the actual vertex sizes <p> Among the many variations of the k-way partitioning problem, we focus on optimizing the k-way ratio-cut cost function <ref> [4] </ref>, that is, finding a solution R such that P k E h jjP h jj is minimized. Although it may ap pear to be the same cost function as presented in [4], there is a subtle difference: the definitions of R and jjP h jj include the actual vertex sizes rather than the number of vertices in a partition. As in the proof of Lemma 1 found in [4]: we can show that the h th diagonal entry of R T QR <p> it may ap pear to be the same cost function as presented in <ref> [4] </ref>, there is a subtle difference: the definitions of R and jjP h jj include the actual vertex sizes rather than the number of vertices in a partition. As in the proof of Lemma 1 found in [4]: we can show that the h th diagonal entry of R T QR satisfies: (R T QR) hh = 2 i=1 j=1 E h (1) Hence the trace of R T QR is P k E h Vertex sizes are implicitly incorporated into our problem by our new definitions of <p> Equation (3) has the same form as previous spectral partitioning formulations, except that ^ Q is no longer the Laplacian of the graph. By using the method of Lagrange multipliers or Fan's Theorem as shown in previous literature <ref> [8, 4] </ref>, Eq. (3) leads to the standard eigenvalue problem. ^ Q ^ X = ^ Xfl: (4) Theorem 1 Fan's Theorem [5] Let the eigenvalues i of a symmetric matrix Q be so arranged that 1 2 n . <p> The KP algorithm <ref> [4] </ref> forms k partitions by using the magnitude and orthogonality of the rows of the eigenvector matrix. <p> MP interfaces with the LASO library by D.S. Scott, which performs the sparse matrix eigenvalue/eigenvector computation. Figure 1 illustrates how MP integrates a k-way partitioning algorithm with contraction and iterative improvement. The k-way partitioning algorithms we implemented include 1) a reimplementation of the KP partitioning algorithm <ref> [4] </ref> which uses actual vertex sizes in forming the partitions and computing the ratio-cut cost, 2) the MKP partitioning algorithm, which amounts to our new KP modified to use the eigenvectors from the generalized eigenvalue problem, and 3) an algorithm RND5 which generates a random k-way partition. <p> Results under the heading MKP used the solution to the generalized eigenvalue while results under KP used the eigenvectors of the Laplacian. (With unit-size vertices, no contraction and no iterative improvement this is equivalent to the KP algorithm in <ref> [4] </ref>.) In order to evaluate the benefit of using the spectral information in a multilevel partitioning scheme we also used an algorithm which generates random k-way partitions. The best results out of 5 obtained from random partitions are listed under the heading RND5.

Reference: [6] <author> J. A. Frankle. </author> <title> Circuit placement methods using multiple eigenvectors and linear probe techniques. </title> <type> Technical Report UCB/ERL M87/32, </type> <institution> University of California, Berkeley, Electronics Research Laboratory, Berkeley, </institution> <address> CA, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: Hypergraphs are converted into graphs by performing a clique ex pansion on the hyperedges. Each edge of the clique formed by hyperedge, e i is given a weight of ( 2 deg (e i ) ) 2 , as proposed in <ref> [6] </ref>.
Reference: [7] <author> L. Hagen and A. Kahng. </author> <title> Fast spectral methods for ratio cut partitioning and clustering. </title> <booktitle> In Proceedings of the ICCAD, </booktitle> <pages> pages 10-12, </pages> <year> 1991. </year>
Reference-contexts: Spectral algorithms were first proposed for placement and partitioning by Hall [8]. Fast bipartitioning methods were developed based on a linear ordering of the vertices using the eigenvector associated with the second smallest eigenvalue of the Laplacian of a graph in <ref> [11, 7] </ref>. A k-way spectral partitioning algorithm and new k-way ratio-cut cost function was presented in [4]. Recent methods for spectral k-way ratio-cut partitioning are presented in [1]. Additional approaches to spectral partitioning are presented in [9, 3].
Reference: [8] <author> K. M. Hall. </author> <title> An r-dimensional quadratic placement algorithm. </title> <journal> Management Sciences, </journal> <volume> 17(3) </volume> <pages> 219-229, </pages> <month> Nov. </month> <year> 1970. </year>
Reference-contexts: An effective spectral partitioner must take those sizes into account to produce good solutions. Our spectral partitioner, MP (Multi-level K-way Partitioner), does exactly that. Spectral algorithms were first proposed for placement and partitioning by Hall <ref> [8] </ref>. Fast bipartitioning methods were developed based on a linear ordering of the vertices using the eigenvector associated with the second smallest eigenvalue of the Laplacian of a graph in [11, 7]. A k-way spectral partitioning algorithm and new k-way ratio-cut cost function was presented in [4]. <p> This problem is equivalent to the ratio-cut partitioning problem, and hence, there is no known optimal polynomial-time solution. We can, however, relax the problem by removing the R 2 D n;k constraint. The relaxed problem turns out to be a quadratic placement problem <ref> [8] </ref>, which can be solved in polynomial time. The relaxed problem is defined as: minimize trace (X T QX) subject to X T M X = I: (2) In the spectral partitioning literature, it is typical to use the constraint: X T X = I. <p> Equation (3) has the same form as previous spectral partitioning formulations, except that ^ Q is no longer the Laplacian of the graph. By using the method of Lagrange multipliers or Fan's Theorem as shown in previous literature <ref> [8, 4] </ref>, Eq. (3) leads to the standard eigenvalue problem. ^ Q ^ X = ^ Xfl: (4) Theorem 1 Fan's Theorem [5] Let the eigenvalues i of a symmetric matrix Q be so arranged that 1 2 n .
Reference: [9] <author> B. Hendrickson and R. Leland. </author> <title> A multilevel algorithm for partitioning graphs. </title> <type> Technical Report SAND93-1301 * UC-405, </type> <institution> Sandia National Laboratories, </institution> <address> Albuquerque, New Mexico, </address> <year> 1993. </year>
Reference-contexts: We present benchmarks to quantitatively show the effectiveness of the new method. Multiple levels of bottom-up clustering reduce the problem size and tend to produce superior results. Multi-level algorithms have been developed using both spectral [2], and iterative <ref> [9, 10] </ref> approaches. However after the application of hierarchical clustering algorithms, the resulting graph may contain vertices of different sizes. An effective spectral partitioner must take those sizes into account to produce good solutions. Our spectral partitioner, MP (Multi-level K-way Partitioner), does exactly that. <p> A k-way spectral partitioning algorithm and new k-way ratio-cut cost function was presented in [4]. Recent methods for spectral k-way ratio-cut partitioning are presented in [1]. Additional approaches to spectral partitioning are presented in <ref> [9, 3] </ref>. A multi-level partitioning algorithm using recursive applications of the ratio-cut metric to form clusters is presented in [12]. The first spectral multi-level algorithm was developed by [2], however, it did not include iterative refinement at successive levels. <p> The first spectral multi-level algorithm was developed by [2], however, it did not include iterative refinement at successive levels. Hendrickson and Leland implemented a multi-level spectral algorithm with a k-way Kernighan-Lin style refinement algorithm <ref> [9] </ref>. An in-depth study [10] of various multilevel contraction, initial partitioning, and refinement strategies on meshes concludes that all of the methods tested perform nearly equally as well. 2 Spectral partitioning with vertex sizes We describe a new spectral method in this section.
Reference: [10] <author> G. Karypis and V. Kumar. </author> <title> A fast and high quality multilevel scheme for partitioning irregular graphs. </title> <type> Technical Report 95-035, </type> <institution> University of Minnesota, Dept. of Computer Science, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: We present benchmarks to quantitatively show the effectiveness of the new method. Multiple levels of bottom-up clustering reduce the problem size and tend to produce superior results. Multi-level algorithms have been developed using both spectral [2], and iterative <ref> [9, 10] </ref> approaches. However after the application of hierarchical clustering algorithms, the resulting graph may contain vertices of different sizes. An effective spectral partitioner must take those sizes into account to produce good solutions. Our spectral partitioner, MP (Multi-level K-way Partitioner), does exactly that. <p> The first spectral multi-level algorithm was developed by [2], however, it did not include iterative refinement at successive levels. Hendrickson and Leland implemented a multi-level spectral algorithm with a k-way Kernighan-Lin style refinement algorithm [9]. An in-depth study <ref> [10] </ref> of various multilevel contraction, initial partitioning, and refinement strategies on meshes concludes that all of the methods tested perform nearly equally as well. 2 Spectral partitioning with vertex sizes We describe a new spectral method in this section. We present the definitions and then formulate the problem. <p> Our focus was not to find the best contraction algorithm nor the best iterative improvement algorithm, but rather to provide a framework in which to test our size-aware spectral algorithm. Other researchers have conducted more detailed studies of different contraction and improvement algorithms and their relative effects <ref> [10] </ref>. In our contraction algorithm, the edges of the hy-pergraph are clique expanded to obtain a graph. The algorithm orders the edges of the graph using a heap based on the weight of an edge.
Reference: [11] <author> A. Pothen, H. D. Simon, and K.-P. Lious. </author> <title> Partitioning sparse matrices with eigenvectors of graphs. </title> <journal> SIAM Journal Matrix Analysis Appl., </journal> <volume> 11(3) </volume> <pages> 430-452, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Spectral algorithms were first proposed for placement and partitioning by Hall [8]. Fast bipartitioning methods were developed based on a linear ordering of the vertices using the eigenvector associated with the second smallest eigenvalue of the Laplacian of a graph in <ref> [11, 7] </ref>. A k-way spectral partitioning algorithm and new k-way ratio-cut cost function was presented in [4]. Recent methods for spectral k-way ratio-cut partitioning are presented in [1]. Additional approaches to spectral partitioning are presented in [9, 3].
Reference: [12] <author> Y.-C. Wei and C.-K. Cheng. </author> <title> A two-level two-way partitioning algorithm. </title> <booktitle> In Proceedings of the IEEE ICCAD, </booktitle> <pages> pages 516-519, </pages> <year> 1990. </year>
Reference-contexts: Recent methods for spectral k-way ratio-cut partitioning are presented in [1]. Additional approaches to spectral partitioning are presented in [9, 3]. A multi-level partitioning algorithm using recursive applications of the ratio-cut metric to form clusters is presented in <ref> [12] </ref>. The first spectral multi-level algorithm was developed by [2], however, it did not include iterative refinement at successive levels. Hendrickson and Leland implemented a multi-level spectral algorithm with a k-way Kernighan-Lin style refinement algorithm [9]. <p> The n 2 edges of highest weight are removed one by one, and if either one of the two vertices of the removed edge are not already in a cluster, these vertices are merged. Our iterative improvement algorithm is modeled after the two-way ratio-cut algorithm <ref> [12] </ref>. We have extended it to perform k-way partitioning in the following way. In turn, we select each of the k partitions as the SINK (resp. SOURCE) partition, and the remaining partitions together form the SOURCE (resp. SINK).
Reference: [13] <author> J. Y. Zien, M. Schlag, and P. K. Chan. </author> <title> Multilevel spectral hypergraph partitioning with arbitrary vertex sizes. </title> <type> Technical Report UCSC-CRL-96-15, </type> <institution> Board of Studies in Computer Engineering, University of California at Santa Cruz, </institution> <month> July </month> <year> 1996. </year>
Reference-contexts: Let D n;k be the set of n fi k matrices which have a single non-zero entry in every row and for each column exactly one non-zero value among its non-zero entries. It is derived in <ref> [13] </ref> that: R is a ratioed partition matrix if and only if R 2 D n;k and R T M R = I. 3 Relaxed Problem Formulation Our objective is to find the matrix which minimizes R T QR subject to the constraint R T M R = I and R <p> In every test group, MKP gives the best answer. Table 3 lists a side-by-side comparison of the MKP partitioning results with DP-RP [1]. The results are comparable but the runtime of MKP is a lot less. Much more detailed presentation of the results are available in a technical report <ref> [13] </ref>. 6 Conclusions In this paper we have presented a modified eigenvalue formulation to account for vertex sizes, and studied its use on circuits with varying vertex sizes and within a multi-level spectral partitioning scheme. The technique is general and can be applied to any eigenvector-based partitioning algorithm.
References-found: 12

