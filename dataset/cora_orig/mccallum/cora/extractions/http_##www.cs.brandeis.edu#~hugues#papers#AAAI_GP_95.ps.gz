URL: http://www.cs.brandeis.edu/~hugues/papers/AAAI_GP_95.ps.gz
Refering-URL: http://www.cs.brandeis.edu/~hugues/publications.html
Root-URL: http://www.cs.brandeis.edu
Email: &lt;fhugues, pollackg@cs.brandeis.edu&gt;  
Title: Parallel Genetic Programming on Fine-Grained SIMD Architectures  
Author: Hugues Juille and Jordan B. Pollack 
Address: Waltham, MA 02254-9110  
Affiliation: Computer Science Department Volen Center for Complex Systems Brandeis University  
Abstract: As the field of Genetic Programming (GP) matures and its breadth of application increases, the need for parallel implementations becomes absolutely necessary. The transputer-based system recently presented by Koza ( [ 8 ] ) is one of the rare such parallel implementations. Until today, no implementation has been proposed for parallel GP using a SIMD architecture, except for a data-parallel approach ( [ 16 ] ), although others have exploited workstation farms and pipelined supercomputers. One reason is certainly the apparent difficulty of dealing with the parallel evaluation of different S-expressions when only a single instruction can be executed at the same time on every processor. The aim of this paper is to present such an implementation of parallel GP on a SIMD system, where each processor can efficiently evaluate a different S-expression. We have implemented this approach on a MasPar MP-2 computer, and will present some timing results. To the extent that SIMD machines, like the MasPar are available to offer cost-effective cycles for scien tific experimentation, this is a useful approach.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> David H. Ackley and Michael L. Littman. </author> <title> A Case for Lamarckian Evolution. </title> <booktitle> In Artificial Life III, </booktitle> <editor> Ed. Christopher G. Langton, </editor> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: 30.48 sec.) (average: 32.31 sec.) Average execution 1.75 sec. 5.75 sec. time for 1 generation 3.3 Population Evolution with Local Interactions The idea of this implementation is to study a model of sub-populations that interact locally one with each other, similar to the model presented by Ackley and Littman in <ref> [ 1 ] </ref> and [ 2 ] . This model has also been tested with the Tic-Tac-Toe problem. In our experiments, each processor manages a sub-population of 16 individuals.
Reference: [2] <author> David H. Ackley and Michael L. Littman. </author> <title> Altruism in the Evolution of Communication. </title> <booktitle> In Artificial Life IV, </booktitle> <editor> Brooks and Maes, Eds. </editor> <publisher> MIT Press, </publisher> <year> 1994, </year> <pages> pp. 40-48. </pages>
Reference-contexts: sec.) Average execution 1.75 sec. 5.75 sec. time for 1 generation 3.3 Population Evolution with Local Interactions The idea of this implementation is to study a model of sub-populations that interact locally one with each other, similar to the model presented by Ackley and Littman in [ 1 ] and <ref> [ 2 ] </ref> . This model has also been tested with the Tic-Tac-Toe problem. In our experiments, each processor manages a sub-population of 16 individuals. A table in which is stored the result of the competition between all possible pairs of individuals in the sub-population is maintained by each processor.
Reference: [3] <author> Peter J. Angeline and Jordan B. Pollack. </author> <title> The Evolutionary Induction of Subroutines. </title> <booktitle> In The Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <address> Bloomington Indiana, </address> <year> 1992. </year>
Reference-contexts: We have also seen that while expression evaluation involves a lot of overhead, reproduction and crossover have effective massively parallel models ( [ 6; 7; 15 ] ). This technique has also a few drawbacks: In particular, implementation of high-level features like modular subprograms ( <ref> [ 3; 9 ] </ref> ) may require a great deal of effort. Although, it is possible that a simple trick like a CALL instruction and a return stack would also work.
Reference: [4] <author> Peter J. Angeline and Jordan B. Pollack. </author> <title> Competitive Environments Evolve Better Solutions for Complex Tasks. </title> <booktitle> In The Fifth International Conference on Genetic Algorithms, </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1993, </year> <pages> pp. 264-270. </pages>
Reference-contexts: This model has been tested on 2 problems from [ 8 ] . Results are presented in section 4. 3.2 Fitness Evaluation with Tournament The aim of this implementation is to reproduce some experiments of Angeline and Pollack ( <ref> [ 4 ] </ref> ). We have not yet implemented modular subroutines. In their experiments, a population of Tic-Tac-Toe (TTT) players co-evolved. <p> To evaluate the fitness of each individual in the population, a tournament has been organized in the following way: * First, we did not use single-elimination as in <ref> [ 4 ] </ref> because this is not an effective use of SIMD. <p> We were able to achieve the evaluation of about 2; 350 S-expressions in 1 second (on average) for the discovery of trigonometric identities and the evaluation of about 710 S-expressions in 1 second (on average) for the symbolic integration problem. We also reproduced experiments presented in <ref> [ 4 ] </ref> with this same population size, using the model of "global tournament" presented in section 3.2, or with a population size of 64K, using the model of sub-populations interacting locally described in section 3.3.
Reference: [5] <author> W. Daniel Hillis and Guy L. Steele Jr. </author> <title> Data Parallel Algorithms. </title> <journal> In IEEE Computers, </journal> <volume> 29, pp.1170-1183, </volume> <year> 1986. </year>
Reference-contexts: 1 Introduction The idea of simulating a MIMD machine using a SIMD architecture is not new ( [ 11 ] ). One of the original ideas for the Connection Machine ( <ref> [ 5 ] </ref> ) was that it could simulate other parallel architectures. Indeed, in the extreme, each processor on a SIMD architecture can simulate a universal Turing machine (TM).
Reference: [6] <author> W. Daniel Hillis. </author> <title> Co-Evolving Parasites Improve Simulated Evolution as an Optimization Procedure. </title> <booktitle> In Artificial Life II, </booktitle> <editor> Langton, et al, Eds. </editor> <publisher> Addison Wesley, </publisher> <year> 1992, </year> <pages> pp. 313-324. </pages>
Reference-contexts: We have also seen that while expression evaluation involves a lot of overhead, reproduction and crossover have effective massively parallel models ( <ref> [ 6; 7; 15 ] </ref> ). This technique has also a few drawbacks: In particular, implementation of high-level features like modular subprograms ( [ 3; 9 ] ) may require a great deal of effort.
Reference: [7] <author> David Jefferson, Robert Collins, Claus Cooper, Michael Dyer, Margot Flowers, Richard Korf, Charles Taylor, and Alan Wang. </author> <title> Evolution as a Theme in Artificial Life: </title> <booktitle> The Genesys/Tracker System. In Artificial Life II, </booktitle> <editor> Langton, et al, Eds. Addi-son Wesley, </editor> <year> 1992, </year> <pages> pp. 549-578. </pages>
Reference-contexts: We have also seen that while expression evaluation involves a lot of overhead, reproduction and crossover have effective massively parallel models ( <ref> [ 6; 7; 15 ] </ref> ). This technique has also a few drawbacks: In particular, implementation of high-level features like modular subprograms ( [ 3; 9 ] ) may require a great deal of effort.
Reference: [8] <author> John R. Koza. </author> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: In our implementation, since the postfix program is the precompilation of a S-expression, it is always correct and one doesn't have to deal with stack underflow. Moreover, the stack is protected from overflow by restricting the depth of S-expressions resulting from recombination, as described in <ref> [ 8 ] </ref> . 2.2 Parallel Precompilator and Interpreter For many GP problems the fitness of an expression is computed by evaluating it across a variety of inputs. <p> Then, we will describe an example of co-evolution where individuals fitness is the result of a tournament. Finally, an example of an implementation involving local interactions between sub-populations will be presented. 3.1 Implementation of Canonical GP Taking fitness definition from <ref> [ 8 ] </ref> , the raw fitness, the standardized fitness and the adjusted fitness can be computed independently by each processor. <p> The sexual reproduction, or crossover operation for GP, described in detail in <ref> [ 8 ] </ref> , which involves cutting and splicing between two S-expressions, is performed in the following way in our implementation: * the 80% of individuals which have not been asexually replaced select two individuals in their local neighborhood (including self), according to fitness-proportionate probability (the same rule as for asex <p> The crossover operation is performed on a string representation of the S-expressions in parallel using another variant of our stack machine. This model has been tested on 2 problems from <ref> [ 8 ] </ref> . Results are presented in section 4. 3.2 Fitness Evaluation with Tournament The aim of this implementation is to reproduce some experiments of Angeline and Pollack ( [ 4 ] ). We have not yet implemented modular subroutines. <p> At the end of the tournament, it is straightforward to collect total score (or fitness) for each individual. Some results of our experiments are presented in section 4. Table 1: Results and time performance. Problems: Discovery of Trigonometric Symbolic Integration Identities (section 10.5 from <ref> [ 8 ] </ref> ) (section 10.1 from [ 8 ] ) Objective function cos (2x) cosx + 2x + 1 Number of runs 10 10 Number of 5 to 29 gen. 4 to 7 gen. <p> Some results of our experiments are presented in section 4. Table 1: Results and time performance. Problems: Discovery of Trigonometric Symbolic Integration Identities (section 10.5 from <ref> [ 8 ] </ref> ) (section 10.1 from [ 8 ] ) Objective function cos (2x) cosx + 2x + 1 Number of runs 10 10 Number of 5 to 29 gen. 4 to 7 gen. <p> Therefore, only the results of matches against the 2 new individuals have to be updated in the table. 4 Results and Performance We performed our first experiments with a population of 4096 individuals. Table 1 presents results and performance on two problems from <ref> [ 8 ] </ref> , using the same specifications (except for the population size).
Reference: [9] <author> John R. Koza. </author> <title> Genetic Programming II: Automatic Discovery of Reusable Programs. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: We have also seen that while expression evaluation involves a lot of overhead, reproduction and crossover have effective massively parallel models ( [ 6; 7; 15 ] ). This technique has also a few drawbacks: In particular, implementation of high-level features like modular subprograms ( <ref> [ 3; 9 ] </ref> ) may require a great deal of effort. Although, it is possible that a simple trick like a CALL instruction and a return stack would also work.
Reference: [10] <author> John R. Koza and David Andre. </author> <title> Parallel Genetic Programming on a Network of Transputers. </title> <type> Technical report. </type> <institution> Stanford University. </institution> <year> 1995. </year>
Reference: [11] <author> Michael S. Littman and Christopher D. Metcalf. </author> <title> An Exploration of Asynchronous Data-Parallelism. </title> <type> Personal communication. </type> <year> 1990. </year>
Reference-contexts: 1 Introduction The idea of simulating a MIMD machine using a SIMD architecture is not new ( <ref> [ 11 ] </ref> ). One of the original ideas for the Connection Machine ( [ 5 ] ) was that it could simulate other parallel architectures. Indeed, in the extreme, each processor on a SIMD architecture can simulate a universal Turing machine (TM).
Reference: [12] <author> Timothy Perkis. </author> <title> Stack-Based Genetic Programming. </title> <booktitle> In Proceedings of the 1994 IEEE World Congress on Computational Intelligence. </booktitle> <publisher> IEEE Press. </publisher>
Reference-contexts: Once a STOP instruction is executed for a processor, that processor becomes idle, leaving the result of its evaluation on the top of the stack. When all processors have reached their STOP instruction, the parallel evaluation of the entire population is complete. Perkis ( <ref> [ 12 ] </ref> ) has already shown that the stack-based approach for Genetic Programming can be very efficient.
Reference: [13] <author> Christopher D. Rosin and Richard K. Belew. </author> <title> Methods for Competitive Co-evolution: Finding Opponents Worth Beating. </title> <booktitle> In Proceedings of the Sixth International Conference on Genetic Algorithms, </booktitle> <year> 1995, </year> <pages> pp. 373-380. </pages>
Reference-contexts: Ultimately, one could expect the emergence of a perfect player (a player that could only win or draw). Such a result has been achieved by Rosin and Belew ( <ref> [ 13 ] </ref> ), where TTT strategies were represented as a table lookup. However, the representation of strategies as a S-expression is more general and attractive.Unfortunately, the emergence of a "perfect" GP player hasn't been achieved yet. <p> For a very long run (more than 3; 000 generations), the emergence of an individual that cannot lose when playing first has eventually been observed. This let us think that the emergence of a perfect player using the GP approach and coevolution should be possible. Rosin and Belew ( <ref> [ 13 ] </ref> ) managed to evolve a perfect strategy for Tic-Tac-Toe after a simulated coevolution for which about 3 million games were played. However, their genotype representation is such that only legal moves can be considered.
Reference: [14] <author> Karl Sims. </author> <title> Evolving 3D Morphology and Behavior by Competition. </title> <booktitle> In Artificial Life IV, </booktitle> <editor> Brooks and Maes, Eds. </editor> <publisher> MIT Press, </publisher> <year> 1994, </year> <pages> pp. 28-39. </pages>
Reference-contexts: For the second source, variance in program size, several techniques apply. The simplest method involves the management of a sub-population by each processor, with some form of load-balancing. We could also implement a cutoff ( <ref> [ 14 ] </ref> ) where the largest and slowest population members are simply expunged. Finally, we could use a "generation gap" or generational mixing, where whenever, say, 50% of the population were idle, we could apply reproduction to that subset of the population, crossed with its parents.
Reference: [15] <author> Reiko Tanese. </author> <title> Distributed Genetic Algorithms. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <year> 1989, </year> <pages> pp. 434-439. </pages>
Reference-contexts: We have also seen that while expression evaluation involves a lot of overhead, reproduction and crossover have effective massively parallel models ( <ref> [ 6; 7; 15 ] </ref> ). This technique has also a few drawbacks: In particular, implementation of high-level features like modular subprograms ( [ 3; 9 ] ) may require a great deal of effort.
Reference: [16] <author> Patrick Tufts. </author> <title> Parallel Case Evaluation for Genetic Programming. In 1993 Lectures in Complex Systems, </title> <editor> Eds. L. Nadel and D. Stein, </editor> <booktitle> SFI Studies in the Sciences of Complexity, Lec. Vol. VI, </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1995, </year> <month> pp.591-596. </month>
Reference-contexts: This leads to the idea of using a data-parallel approach where the same expression is simply evaluated with different data in parallel ( <ref> [ 16 ] </ref> ). Another approach to take advantage of this feature is to precompile S-expressions from prefix to postfix. This operation can be executed once, and then the postfix program is evaluated multiple times, amortizing the small cost of the precompilation.
References-found: 16

