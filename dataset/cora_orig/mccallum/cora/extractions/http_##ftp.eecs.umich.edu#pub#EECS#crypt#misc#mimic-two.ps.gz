URL: http://ftp.eecs.umich.edu/pub/EECS/crypt/misc/mimic-two.ps.gz
Refering-URL: http://ftp.eecs.umich.edu/pub/EECS/crypt/misc/
Root-URL: http://www.eecs.umich.edu
Title: Mimic Functions and Tractability  
Author: Peter Wayner 
Address: Ithaca, New York 14850  
Affiliation: Department of Computer Science Cornell University  
Abstract: Mimic functions are designed to hide information by transforming it into another format. They may be as simple as converting the data into a file with a particular statistical profile or as complex as giving the new file any computable structure. This paper will analyze some of the theoretical results about the security of these functions and give a practical algorithm for producing more secure mimic functions. Anyone who needs to deliver a message knows that there are two separate ways to ensure security. The first is to encrypt the message so that no one will be able to unscramble it if it is intercepted. The whole field of mathematical cryptography has evolved around this approach. The second method is to hide the message so it can't be found. The history of spies and the collection of spy novels and movies are filled with tales of microdots, hidden compartments and a number of other techniques. There have been many different foreys into hiding the existence of a message by cryptographers like the work by Simmons [Sim84] and many others. Mimic functions were introduced in [Way90] as a general technique for converting information from one form into another seemingly benign and innocent format. The paper described three different types of functions which could generate results that fall into the standard heirarchy of language complexity: the regular languages, the context-free languages and the recursively-enumerable languages. The first group of functions converted data into strings from a regular set. These sets were described in terms of compression function because if a compression algorithm like Huffman coding converted a file with uneven statistical distributions into a small, more evenly distributed file, then its inverse would convert an evenly distributed file into one that would statistically mimic the file. The internal structure has many similarities to the homophonic ciphers developed by Massey and others. [JKM90] The second type of function will convert data into strings from an unambiguous context-free language. The bits from the data file are used to choose which production of the grammar to use when producing the string. These bits can be recovered by parsing the string, finding the list of productions which generated the string and converting these productions into the bits. If a non-ambiguous method of parsing the productions was used, then data could easily be hidden in the structure of the parse tree. Encoding the data in the strings accepted by a Turing machine is the next step in the progression. In the earlier paper, this level of sophistication was described in terms of Van Wijngaarden grammars. These grammars are essentially double context-free 
Abstract-found: 1
Intro-found: 1
Reference: [AHU83] <author> A.V. Aho, J.E. Hopcroft, and J.D. Ullman. </author> <title> Data Structures and Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1983. </year>
Reference: [HU69] <author> J.E. Hopcroft and J.D. Ullman. </author> <title> Formal Languages and their Relation to Automata. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1969. </year>
Reference-contexts: These bits will be produced in the opposite order. Theoretical Bounds and Practical Questions Classical computer science borrowed many results about turing machines from the realm of logic and philosophy. <ref> [HU69] </ref> provides a good discussion of this area. The central theorem of this theory states that it is undecidable whether a turing machine will 12 accept a particular string.
Reference: [Huf51] <author> D Huffman. </author> <title> A method for the construction of minimum redundancy codes. </title> <booktitle> Proceedings of the Institute of Radio Engineers, </booktitle> <volume> 40 </volume> <pages> 1098-1101, </pages> <year> 1951. </year>
Reference-contexts: Appendix: One Way of Encoding Data in Non-determanism This is a general technique that converts data into a stream of choices that is based Huffman coding. <ref> [Huf51, Sto88] </ref>. This can be used to turn non-determanism into a technique for encoding information. Start with a set of choices, fc 1 ; : : : ; c m g. Let, p (c i ) be the probability that choice, c i , should be chosen.
Reference: [JKM90] <author> H.N. Jendal, Y. J. B. Kuhn, and J. L. Massey. </author> <title> An information-theoretic treatment of homophonic substitution. </title> <booktitle> In Advances in Cryptology-Eurocrypt `89, </booktitle> <address> New York, </address> <year> 1990. </year> <note> Springer-Verlag, Lecture Notes in Computer Science. </note>
Reference: [Kea89] <author> Michael Kearns. </author> <title> The Computational Complexity of Machine Learning. </title> <type> PhD thesis, </type> <institution> Harvard University Center for Research in Computing Technology, </institution> <month> May </month> <year> 1989. </year>
Reference: [KV89] <author> Michael Kearns and Leslie Valient. </author> <title> Cryptographic limitations on learning boolean formulae and finite automata. </title> <booktitle> In Proceedings of the Twenty-First Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 433-444, </pages> <address> Seat-tle,Washington, </address> <month> May </month> <year> 1989. </year>
Reference: [Riv91] <author> Ron Rivest. </author> <title> Cryptography and machine learning. </title> <booktitle> In Asia Crypt 91, </booktitle> <year> 1991. </year>
Reference: [RRA78] <author> Adi Shamir Ron Rivest and Len Adleman. </author> <title> A method for obtaining digital signatures and public-key cryptosystems. </title> <journal> Communications of the ACM, </journal> <volume> 21(11), </volume> <year> 1978. </year>
Reference-contexts: And these are certainly more complex for an attacker. Conclusion and Notes about Novelty Most of the best work on cryptography has tried to guarantee security by relying on the assumptions that certain problems like factoring large integers <ref> [RRA78] </ref> or solving knapsacks [?] is a difficult problem. If these problems are hard, then the cipher system may be secure. This work tries to encode information in three different theoretical models of general computation and these models are much more general than the other specific cases.
Reference: [Sim84] <author> Gus J. Simmons. </author> <title> The prisoner's problem and the subliminal channel. </title> <editor> In David Chaum, editor, </editor> <booktitle> Advances in Cryptology: Proceedings of Crypto `83, </booktitle> <pages> pages 51-67, </pages> <address> New York, 1984. </address> <publisher> Plenum. </publisher> <pages> 15 </pages>
Reference: [Sto88] <author> James Storer. </author> <title> Data Compression. </title> <publisher> Computer Science Press, </publisher> <address> Rockville, Mary--land, </address> <year> 1988. </year>
Reference-contexts: Appendix: One Way of Encoding Data in Non-determanism This is a general technique that converts data into a stream of choices that is based Huffman coding. <ref> [Huf51, Sto88] </ref>. This can be used to turn non-determanism into a technique for encoding information. Start with a set of choices, fc 1 ; : : : ; c m g. Let, p (c i ) be the probability that choice, c i , should be chosen.
Reference: [Val84] <author> Leslie G. Valient. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27 </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference: [Way90] <author> Peter Wayner. </author> <title> Mimic functions. </title> <institution> Technical Report ???, Cornell University Department of Computer Science, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: If ffi is the average length of the V i 's, then ffi i is the probability that a given string will be i tokens long. Turing Machines and Mimickry The last sections discussed using CFG's for mimickry. In <ref> [Way90] </ref>, the mimic functions that produced all recursively enumerable languages were presented as VW-grammars. This construct fitted nicely with the other items in the paper and it also allows us to apply all of the results in this paper to the larger classes of functions computable by Turing Machine.
Reference: [Way91] <author> Peter Wayner. </author> <title> If sb266 wants plaintext, give them plaintext... </title> <journal> RISKS Digest, </journal> <volume> 11(71), </volume> <month> May </month> <year> 1991. </year> <month> 16 </month>
References-found: 13

