URL: http://www.cs.columbia.edu/robotics/publications/abrams-isatp95.ps.gz
Refering-URL: http://www.cs.columbia.edu/~abrams/
Root-URL: http://www.cs.columbia.edu
Title: Swept Volumes and Their Use in Viewpoint Computation in Robot Work-Cells  
Author: Steven Abrams Peter K. Allen 
Address: New York, NY 10027  
Affiliation: Center for Research in Intelligent Systems Computer Science Department Columbia University  
Abstract: This paper discusses the automatic computation of viewpoints for monitoringobjects and features in an active robot work-cell. An important step in our algorithm for finding viewpoints is the computation of the volumes swept by polyhedral objects moving through space. A method for approximating these volumes for arbitrarily moving polyhedra is presented. Some swept volume results are presented, and methods for integrating these results into our automated Machine Vision Planning (MVP) system are discussed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Abrams and P. K. Allen. </author> <title> Computing swept volumes for sensor planning tasks. </title> <booktitle> In Proceedings DARPA 1994 Image Understanding Workshop, </booktitle> <address> Washington, DC, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: This algorithm is discussed at length in [18]. 1.2 Adding Moving Objects We have been extending MVP to function in an environment in which objects are moving <ref> [1, 2] </ref>. As an example, we may have a work-cell in which one or more robots are assembling an object. We may wish to automatically monitor this assembly task.
Reference: [2] <author> S. Abrams, P. K. Allen, and K. A. Tarabanis. </author> <title> Dynamic sensor planning. </title> <booktitle> In Proceedings 1993 IEEE International Conference on Robotics and Automation, </booktitle> <address> Atlanta, GA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: This algorithm is discussed at length in [18]. 1.2 Adding Moving Objects We have been extending MVP to function in an environment in which objects are moving <ref> [1, 2] </ref>. As an example, we may have a work-cell in which one or more robots are assembling an object. We may wish to automatically monitor this assembly task.
Reference: [3] <author> A. R. Conn, N. I. M. Gould, and Ph. L. Toint. </author> <title> LANCELOT A Fortran Package for Large-Scale Nonlinear Optimization. </title> <booktitle> Springer Series in Computational Mathematics. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Some of the constraint equations are nonlinear; some are not continuously differentiable. Optimization of such functions is a very difficult problem. The optimization systems we have used (IMSL and LANCELOT <ref> [3] </ref>), have taken anywhere from sec onds to minutes to perform the viewpoint computation and, at times, required manipulation of the weighs or starting points to produce results. This is certainly acceptable performance for one-shot off-line planning problems (such as those for which MVP is used).
Reference: [4] <author> C. K. Cowan. </author> <title> Model based synthesis of sensor locations. </title> <booktitle> In Proceedings 1988 IEEE International Conference on Robotics and Automation, </booktitle> <month> April </month> <year> 1988. </year>
Reference-contexts: Each researcher has defined the phrase satisfactory view in his own terms, but the constraints most often considered are magnification (or resolution), focus, field-of-view, and occlusion. Examples of recent work in this field are in <ref> [4, 5, 6, 12, 13] </ref>. A complete survey of sensor planning systems can be found in [14]. The majority of the work has focused on sensor planning in static environments, i.e. where all of the objects are stationary, and is typically applied to automated inspection tasks.
Reference: [5] <author> C. K. Cowan and A. Bergman. </author> <title> Determining the camera and light source location for a visual task. </title> <booktitle> In Proceedings 1989 IEEE International Conference on Robotics and Automation, </booktitle> <month> May </month> <year> 1989. </year>
Reference-contexts: Each researcher has defined the phrase satisfactory view in his own terms, but the constraints most often considered are magnification (or resolution), focus, field-of-view, and occlusion. Examples of recent work in this field are in <ref> [4, 5, 6, 12, 13] </ref>. A complete survey of sensor planning systems can be found in [14]. The majority of the work has focused on sensor planning in static environments, i.e. where all of the objects are stationary, and is typically applied to automated inspection tasks.
Reference: [6] <author> C. K. Cowan and B. Modayur. </author> <title> Edge-based placement of camera and light-source for object recognition and location. </title> <booktitle> In Proceedings 1993 IEEE International Conference on Robotics and Automation, </booktitle> <year> 1993. </year>
Reference-contexts: Each researcher has defined the phrase satisfactory view in his own terms, but the constraints most often considered are magnification (or resolution), focus, field-of-view, and occlusion. Examples of recent work in this field are in <ref> [4, 5, 6, 12, 13] </ref>. A complete survey of sensor planning systems can be found in [14]. The majority of the work has focused on sensor planning in static environments, i.e. where all of the objects are stationary, and is typically applied to automated inspection tasks.
Reference: [7] <author> H. Edelsbrunner. </author> <title> Algorithms in Combinatorial Geometry. </title> <publisher> Springer-Verlag, </publisher> <year> 1987. </year>
Reference-contexts: To compute the actual boundary of the swept volume, we can compute the arrangement of these polygons in space yielding a collection of cells (see, for example, <ref> [7] </ref>). Most of these cells will be in the swept volume, but some of these cells may be voids within the swept volume.
Reference: [8] <author> R. T. </author> <title> Farouki. </title> <type> Personal communication, </type> <month> May 23 </month> <year> 1994. </year>
Reference-contexts: z; t) ~n = 0 (where v (x; y; z; t) is the instantaneous velocity of point (x; y; z) at time t and ~n is the polygon's normal), then there will be points on the interior of the polygon which will appear on the boundary of the swept volume <ref> [8] </ref>. This corresponds to, for example, translational motion in the plane of the polygon, or rotation of a polygon about an axis which intersects the polygon. We call this class of motion sliding motion, and give an example of this type of motion in figure 2.
Reference: [9] <author> Anil Kaul. </author> <title> Computing Minkowski Sums. </title> <type> PhD thesis, </type> <institution> Department of Mechanical Engineering, Columbia University, </institution> <year> 1993. </year>
Reference-contexts: the analysis which we will be doing for sensor planning, we will be concerned with computing a boundary representation of the volume swept by M . 3 Related Sweeping Research A number of previous researchers have examined the problem of computing swept volumes, including Korein [10] (for rotating polyhedra), Kaul <ref> [9] </ref> (using Minkowski sums for translations), Wang and Wang [19] (using envelope theory), and Martin and Stephenson [11] (using envelope theory and computer algebraic techniques). Of particular interest is Weld and Leu [20] who set forth some theory for computing the volume swept by a moving polyhedron.
Reference: [10] <author> James Korein. </author> <title> A Geometric Investigation of Reach. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year>
Reference-contexts: Because of nature of the analysis which we will be doing for sensor planning, we will be concerned with computing a boundary representation of the volume swept by M . 3 Related Sweeping Research A number of previous researchers have examined the problem of computing swept volumes, including Korein <ref> [10] </ref> (for rotating polyhedra), Kaul [9] (using Minkowski sums for translations), Wang and Wang [19] (using envelope theory), and Martin and Stephenson [11] (using envelope theory and computer algebraic techniques).
Reference: [11] <author> R. R. Martin and P. C. Stephenson. </author> <title> Sweeping of three-dimensional objects. </title> <booktitle> Computer Aided Design, </booktitle> <volume> 22(4) </volume> <pages> 223-234, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: boundary representation of the volume swept by M . 3 Related Sweeping Research A number of previous researchers have examined the problem of computing swept volumes, including Korein [10] (for rotating polyhedra), Kaul [9] (using Minkowski sums for translations), Wang and Wang [19] (using envelope theory), and Martin and Stephenson <ref> [11] </ref> (using envelope theory and computer algebraic techniques). Of particular interest is Weld and Leu [20] who set forth some theory for computing the volume swept by a moving polyhedron.
Reference: [12] <author> S. Sakane, R. Niepold, T. Sato, and Y. Shirai. </author> <title> Illumination setup planning for a hand-eye system based on an environmental model. </title> <booktitle> Advanced Robotics, </booktitle> <volume> 6(4) </volume> <pages> 461-482, </pages> <year> 1992. </year>
Reference-contexts: Each researcher has defined the phrase satisfactory view in his own terms, but the constraints most often considered are magnification (or resolution), focus, field-of-view, and occlusion. Examples of recent work in this field are in <ref> [4, 5, 6, 12, 13] </ref>. A complete survey of sensor planning systems can be found in [14]. The majority of the work has focused on sensor planning in static environments, i.e. where all of the objects are stationary, and is typically applied to automated inspection tasks.
Reference: [13] <author> S. Sakane, T. Sato, and M. Kakikura. </author> <title> Model-based planning of visual sensors using a hand-eye action simulator system: HEAVEN. </title> <booktitle> In Proceedings of the 3rd International Conference on Advanced Robotics, </booktitle> <pages> pages 163-174, </pages> <address> Versailles, France, </address> <month> October </month> <year> 1987. </year>
Reference-contexts: Each researcher has defined the phrase satisfactory view in his own terms, but the constraints most often considered are magnification (or resolution), focus, field-of-view, and occlusion. Examples of recent work in this field are in <ref> [4, 5, 6, 12, 13] </ref>. A complete survey of sensor planning systems can be found in [14]. The majority of the work has focused on sensor planning in static environments, i.e. where all of the objects are stationary, and is typically applied to automated inspection tasks.
Reference: [14] <author> K. Tarabanis, P. K. Allen, and R. Y. Tsai. </author> <title> A survey of sensor planning in computer vision. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 11(1), </volume> <month> February </month> <year> 1995. </year>
Reference-contexts: Examples of recent work in this field are in [4, 5, 6, 12, 13]. A complete survey of sensor planning systems can be found in <ref> [14] </ref>. The majority of the work has focused on sensor planning in static environments, i.e. where all of the objects are stationary, and is typically applied to automated inspection tasks.
Reference: [15] <author> K. Tarabanis, R. Y. Tsai, and S. Abrams. </author> <title> Planning viewpoints that simultaneously satisfy several feature detectability constraints for robotic vision. </title> <booktitle> In Proceedings Fifth Iner-national Conference of Advanced Robotics, </booktitle> <year> 1991. </year>
Reference-contexts: robot work-cell. fl This work was supported in part by DARPA contract DACA-76-92-C-0007, NSF grants CDA-90-24735and IRI-93-11877, IBM Corporation, North American Philips Laboratories, Siemens Corporation and Rockwell International. 1.1 Previous Research: MVP Our previous research in this field has resulted in the development of the Machine Vision Planning (MVP) system <ref> [17, 18, 16, 15] </ref>. Briefly, MVP takes an optimization approach towards viewpoint computation. That is, it models each of the relevant constraints on a viewpoint (i.e. focus, resolution, field-of-view, and occlusion) as a function in the viewpoint parameter-space and optimizes a linear combination of these constraints.
Reference: [16] <author> K. Tarabanis, R. Y. Tsai, and P. K. Allen. </author> <title> Analytical characterization of the feature detectability constraints of resolution, focus and field-of-view for vision sensor planning. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 59(3), </volume> <month> May </month> <year> 1994. </year>
Reference-contexts: robot work-cell. fl This work was supported in part by DARPA contract DACA-76-92-C-0007, NSF grants CDA-90-24735and IRI-93-11877, IBM Corporation, North American Philips Laboratories, Siemens Corporation and Rockwell International. 1.1 Previous Research: MVP Our previous research in this field has resulted in the development of the Machine Vision Planning (MVP) system <ref> [17, 18, 16, 15] </ref>. Briefly, MVP takes an optimization approach towards viewpoint computation. That is, it models each of the relevant constraints on a viewpoint (i.e. focus, resolution, field-of-view, and occlusion) as a function in the viewpoint parameter-space and optimizes a linear combination of these constraints.
Reference: [17] <author> K. Tarabanis, R. Y. Tsai, and P. K. Allen. </author> <title> The MVP sensor planning system for robotic vision tasks. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 11(1), </volume> <month> February </month> <year> 1995. </year>
Reference-contexts: robot work-cell. fl This work was supported in part by DARPA contract DACA-76-92-C-0007, NSF grants CDA-90-24735and IRI-93-11877, IBM Corporation, North American Philips Laboratories, Siemens Corporation and Rockwell International. 1.1 Previous Research: MVP Our previous research in this field has resulted in the development of the Machine Vision Planning (MVP) system <ref> [17, 18, 16, 15] </ref>. Briefly, MVP takes an optimization approach towards viewpoint computation. That is, it models each of the relevant constraints on a viewpoint (i.e. focus, resolution, field-of-view, and occlusion) as a function in the viewpoint parameter-space and optimizes a linear combination of these constraints.
Reference: [18] <author> K. Tarabanis, R. Y. Tsai, and A. </author> <title> Kaul. </title> <journal> Computing occlusion-free viewpoints. IEEE Transactions Pattern Analysis and Machine Intelligence, </journal> <note> to appear 1995. </note>
Reference-contexts: robot work-cell. fl This work was supported in part by DARPA contract DACA-76-92-C-0007, NSF grants CDA-90-24735and IRI-93-11877, IBM Corporation, North American Philips Laboratories, Siemens Corporation and Rockwell International. 1.1 Previous Research: MVP Our previous research in this field has resulted in the development of the Machine Vision Planning (MVP) system <ref> [17, 18, 16, 15] </ref>. Briefly, MVP takes an optimization approach towards viewpoint computation. That is, it models each of the relevant constraints on a viewpoint (i.e. focus, resolution, field-of-view, and occlusion) as a function in the viewpoint parameter-space and optimizes a linear combination of these constraints. <p> This algorithm is discussed at length in <ref> [18] </ref>. 1.2 Adding Moving Objects We have been extending MVP to function in an environment in which objects are moving [1, 2]. As an example, we may have a work-cell in which one or more robots are assembling an object. We may wish to automatically monitor this assembly task.
Reference: [19] <author> W. P. Wang and K. K. Wang. </author> <title> Geometric modeling for swept volume of moving solids. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 6(12) </volume> <pages> 8-17, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: planning, we will be concerned with computing a boundary representation of the volume swept by M . 3 Related Sweeping Research A number of previous researchers have examined the problem of computing swept volumes, including Korein [10] (for rotating polyhedra), Kaul [9] (using Minkowski sums for translations), Wang and Wang <ref> [19] </ref> (using envelope theory), and Martin and Stephenson [11] (using envelope theory and computer algebraic techniques). Of particular interest is Weld and Leu [20] who set forth some theory for computing the volume swept by a moving polyhedron.
Reference: [20] <author> John D. Weld and Ming C. Leu. </author> <title> Geometric representation of swept volumes with application to polyhedral objects. </title> <journal> International Journal of Robotics Research, </journal> <volume> 9(5) </volume> <pages> 105-117, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: Of particular interest is Weld and Leu <ref> [20] </ref> who set forth some theory for computing the volume swept by a moving polyhedron.
References-found: 20

