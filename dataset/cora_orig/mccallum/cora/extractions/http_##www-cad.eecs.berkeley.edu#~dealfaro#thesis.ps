URL: http://www-cad.eecs.berkeley.edu/~dealfaro/thesis.ps
Refering-URL: http://www-cad.eecs.berkeley.edu/~dealfaro/abstract-thesis.html
Root-URL: 
Title: FORMAL VERIFICATION OF PROBABILISTIC SYSTEMS  
Author: Luca de Alfaro 
Degree: a dissertation submitted to the department of computer science and the committee on graduate studies of stanford university in partial fulfillment of the requirements for the degree of doctor of philosophy By  
Date: December 1997  
Abstract-found: 0
Intro-found: 1
Reference: [ABC84] <author> M. Ajmone Marsan, G. Balbo, and G. Conte. </author> <title> A class of generalized stochastic Petri nets for the performance analysis of multiprocessor systems. </title> <journal> ACM Trans. Comp. Sys., </journal> <volume> 2(2) </volume> <pages> 93-122, </pages> <month> May </month> <year> 1984. </year>
Reference: [ABC + 94] <author> M. Ajmone Marsan, G. Balbo, G. Conte, S. Donatelli, and G. Franceschinis. </author> <title> Modelling with Genralized Stochastic Petri Nets. </title> <publisher> John Wiley & Sons, </publisher> <year> 1994. </year>
Reference: [ACD90] <author> R. Alur, C. Courcoubetis, and D. Dill. </author> <title> Model-checking for real-time systems. </title> <booktitle> In Proc. 5th IEEE Symp. Logic in Comp. Sci., </booktitle> <year> 1990. </year>
Reference: [ACD91] <author> R. Alur, C. Courcoubetis, and D.L. Dill. </author> <title> Model-checking for probabilistic real-time systems. </title> <booktitle> In Proc. 18th Int. Colloq. Aut. Lang. Prog., volume 510 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 115-126. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference: [ACD92] <author> R. Alur, C. Courcoubetis, and D. Dill. </author> <title> Verifying automata specifications of probabilistic real-time systems. In Real Time: </title> <booktitle> Theory in Practice, volume 600 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 28-44. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference: [AD90] <author> R. Alur and D. Dill. </author> <title> Automata for modeling real-time systems. </title> <booktitle> In Proc. 17th Int. Colloq. Aut. Lang. Prog., volume 443 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 322-335. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference: [AFK88] <author> K.R. Apt, N. Francez, and S. Katz. </author> <title> Appraising fairness in languages for distributed programming. </title> <journal> Distributed Computing, </journal> <volume> 2 </volume> <pages> 226-241, </pages> <year> 1988. </year>
Reference-contexts: Its traditional uses include the modeling of concurrency and of un-biased arbitration; among the monographs devoted to the study of fairness, we recall Francez [Fra86] and Apt, Francez and Katz <ref> [AFK88] </ref>. Two notions of fairness are commonly considered: justice, also called weak fairness, and compassion, also called strong fairness (see Manna and Pnueli [MP91, MP95]). Informally, the meaning of justice and compassion can be described as follows.
Reference: [ASB + 95] <author> A. Aziz, V. Singhal, F. Balarin, R.K. Brayton, and A.L. Sangiovanni-Vincentelli. </author> <title> It usually works: The temporal logic of stochastic systems. </title> <booktitle> In Computer Aided Verification, volume 939 of Lect. Notes in Comp. </booktitle> <publisher> Sci. Springer-Verlag, </publisher> <year> 1995. </year>
Reference: [Bai96] <author> C. Baier. </author> <title> Polynomial time algorithms for testing probabilistic bisimulation and simulation. </title> <booktitle> In Computer Aided Verification, volume 1102 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 38-49. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> 211 212 BIBLIOGRAPHY </note>
Reference: [Bal95] <author> G. </author> <title> Balbo. On the success of stochastic Petri nets. </title> <booktitle> In Proc. 6th Int. Workshop on Petri Nets and Performance Models, </booktitle> <pages> pages 2-9, </pages> <year> 1995. </year>
Reference: [BAPM83] <author> M. Ben-Ari, A. Pnueli, and Z. Manna. </author> <title> The temporal logic of branching time. </title> <journal> Acta Informatica, </journal> <volume> 20 </volume> <pages> 207-226, </pages> <year> 1983. </year>
Reference: [BBG95] <author> M. Bernardo, N. Busi, and R. Gorrieri. </author> <title> A distributed semantics for EMPA based on stochastic contextual nets. </title> <journal> Computer J., </journal> <volume> 38(7) </volume> <pages> 492-509, </pages> <year> 1995. </year>
Reference: [BBS92] <author> J.C.M. Baeten, J.A. Bergstra, and S.A. Smolka. </author> <title> Axiomatizing probabilistic processes: ACP with generative probabilities. </title> <booktitle> In CONCUR'92: Concurrency Theory. 3rd Int. Conf., volume 630 of Lect. Notes in Comp. </booktitle> <publisher> Sci. Springer-Verlag, </publisher> <year> 1992. </year>
Reference: [BdA95] <author> A. Bianco and L. de Alfaro. </author> <title> Model checking of probabilistic and nondeterministic systems. </title> <booktitle> In Found. of Software Tech. and Theor. Comp. Sci., volume 1026 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 499-513. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: The following theorem is the analogous of Theorem 4.2, and provides an algorithm for the model checking of operator P in FPTL and FPTL*. This algorithm is very similar to the one presented in [KB96, Section 10] (which in turn is based in part on <ref> [BdA95, dA97] </ref>). The similarity of the algorithms is in spite of the fact that the definition of fairness, and other details of the system models, are different.
Reference: [BDG94a] <author> M. Bernardo, L. Donatiello, and R. Gorrieri. MPA: </author> <title> a stochastic process algebra. </title> <type> Technical Report UBLCS-94-10, </type> <institution> Laboratory for Computer Science, University of Bologna, </institution> <month> May </month> <year> 1994. </year>
Reference: [BDG94b] <author> M. Bernardo, L. Donatiello, and R. Gorrieri. </author> <title> Operational GSPN semantics of MPA. </title> <type> Technical Report UBLCS-94-12, </type> <institution> Laboratory for Computer Science, University of Bologna, </institution> <month> May </month> <year> 1994. </year>
Reference: [BDG95] <author> M. Bernardo, L. Donatiello, and R. Gorrieri. </author> <title> Giving a net semantics to Markovian process algebra. </title> <booktitle> In Proc. 6th Int. Workshop on Petri Nets and Performance Models, </booktitle> <pages> pages 169-178. </pages> <publisher> IEEE Comput. Soc. Press, </publisher> <year> 1995. </year>
Reference: [Bel57] <author> R.E. Bellman. </author> <title> Dynamic Programming. </title> <publisher> Princeton University Press, </publisher> <year> 1957. </year>
Reference: [Ber87] <author> D.P. Bertsekas. </author> <title> Dynamic Programming. </title> <publisher> Prentice-Hall, </publisher> <year> 1987. </year>
Reference-contexts: The class of instances that is most closely related to ours is the one discussed by Bertsekas <ref> [Ber87, x6.2, p. 255] </ref> and Bertsekas and Tsitsiklis [BT91], which consider the replacement of SSP Assumption 2 with both SSP Assumption 4 and the following assumption: SSP Assumption 5: There is a proper policy 0 2 P such that v 0 = inf v .
Reference: [Ber95] <author> D.P. Bertsekas. </author> <title> Dynamic Programming and Optimal Control. </title> <publisher> Athena Scientific, </publisher> <year> 1995. </year> <title> Volumes I and II. </title>
Reference-contexts: Semi-Markov decision processes have been described in Jensen [Jen53], Howard [How60, How63], De Cani [DC64], Veinott [Vei69], Ross [Ros70b, Ros70a]; we will essentially follow the presentation of Bertsekas <ref> [Ber95] </ref>. <p> In fact, the traditional analysis of semi-Markov decision problems relies on assumption (6.37), which enables the use of the uniformation technique described by Jensen [Jen53], Howard [How60], Veinott [Vei69] and [Sch71] (an account of the technique can also be found in <ref> [Ber95] </ref>). Most of the known results for semi-Markov problems depend on this technique, and thus on assumption (6.37); this includes the results presented in Ross [Ros70b, Ros70a], Puterman [Put94] and Bertsekas [Ber95]. <p> by Jensen [Jen53], Howard [How60], Veinott [Vei69] and [Sch71] (an account of the technique can also be found in <ref> [Ber95] </ref>). Most of the known results for semi-Markov problems depend on this technique, and thus on assumption (6.37); this includes the results presented in Ross [Ros70b, Ros70a], Puterman [Put94] and Bertsekas [Ber95]. Thus, while we will be able to borrow from the usual development of the subject many concepts and ideas, we will have to follow a different path to get the desired results, and we will have to provide independent proofs of our statements. <p> This theorem also indicates that if is Markovian then J + s = J s ; we will denote this common value simply as J s . We now define unichain policies, for which the above relations assume a particularly simple form (see, for example, Bertsekas <ref> [Ber95] </ref>). Definition 6.4 (unichain policies) A Markovian policy is unichain if the Markov chain defined by the state space S and the transition matrix P has a single closed recurrent class. <p> COMPUTING THE MAXIMUM AND MINIMUM VALUES OF J 133 of equations known as the Bellman equations for semi-Markov processes. This approach has been described by Howard [How60], De Cani [DC64], Veinott [Vei69] and Ross [Ros70b]; a more recent account is provided by Bertsekas <ref> [Ber95, Volume II] </ref>. <p> The standard proof of this result relies either on uniformation techniques (see Jensen [Jen53], Howard [How60] and Veinott [Vei69]) or on a connection with the stochastic shortest path problem, if all policies are unichain (see Bertsekas <ref> [Ber95, Volume II, x 5.3] </ref>). <p> We base our proof on a connection with the average reward problem. This connection is in the same spirit of the one with the shortest path problem presented in <ref> [Ber95, Volume II, x 5.3] </ref>, but it turns out to be of greater generality. Proof. <p> Then, J s = J , for all s 2 S. Proof. This proof is modeled after the one of <ref> [Ber95, Chapter 5, Proposition 3.1] </ref>; the only difference being that since W can be equal to 0, we must pay attention to the convergence (or lack thereof) of the limits of the expectations. Consider a policy 2 D , and let h fl = [h fl s ] s2S . <p> The value of J can be determined by solving a linear programming problem derived from (BEQ), as explained for example in Puterman [Put94] or Bertsekas <ref> [Ber95] </ref>. <p> As for ordinary Markov decision processes, several optimization problems can be formulated for semi-Markov decision processes; among them, the minimization or maximization of total, discounted or average reward. Ross [Ros70a] and Bertsekas <ref> [Ber95] </ref> provide an account of the subject; further references were given in Section 6.6.1. In this section we study the optimization of the average reward of SMDPs. <p> First, the size of the state space of the problem is reduced before linear programming methods are applied. Second, once the offending end components are removed, other solution methods such as policy iteration and value iteration can be used (for a description of these methods, see for example <ref> [Ber95] </ref>). The second approach consists in reducing the SSP problem directly to linear programming: since the solution of the linear programming problem corresponds to the greatest fixpoint, it corresponds to the solution of the SSP problem.
Reference: [BG96] <author> M. Bernardo and R. Gorrieri. </author> <title> Extended Markovian process algebra. </title> <booktitle> In CONCUR'96: Concurrency Theory. 7th Int. Conf., volume 1119 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 315-330. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference: [BH97] <author> C. Baier and H. Hermanns. </author> <title> Weak bisimulation for fully probabilistic processes. </title> <booktitle> In Computer Aided Verification, volume 1254 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 119-130, </pages> <month> June </month> <year> 1997. </year> <note> BIBLIOGRAPHY 213 </note>
Reference: [BK84] <author> J.A. Bergstra and J.W. Klop. </author> <title> Process algebra for synchronous communication. </title> <journal> Information and Computation, </journal> <volume> 60 </volume> <pages> 109-137, </pages> <year> 1984. </year>
Reference: [BKR + 97] <author> C. Baier, M. Kwiatkowska, M. Ryan, E. Clarke, and V.Hartonas Garmhausen. </author> <title> Symbolic model checking for probabilistic processes. </title> <booktitle> In Proc. 24th Int. Colloq. </booktitle> <address> Aut. Lang. Prog., </address> <year> 1997. </year>
Reference: [BLM97] <author> N.S. Bjtrner, U. Lerner, and Z. Manna. </author> <title> Deductive verification of parameterized fault-tolerant systems: A case study. </title> <booktitle> In Intl. Conf. on Temporal Logic. </booktitle> <publisher> Kluwer, </publisher> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: Extreme Fairness and ff-Fairness To remedy to the situation illustrated by the previous example, Pnueli [Pnu83] and Pnueli and Zuck [PZ93] introduce the notions of extreme fairness and ff-fairness. Similar concerns also led to the concept of uniform compassion in Bjtrner, Lerner and Manna <ref> [BLM97] </ref>. The notion of ff-fairness relies on the use of past temporal logic.
Reference: [BS96] <author> D. Beauquier and A. Slissenko. </author> <title> Polytime model checking for timed probabilistic computation tree logic. </title> <type> Technical Report TR-96-08, </type> <institution> Dept. of Informatics, Univ. Paris-12, </institution> <month> April </month> <year> 1996. </year>
Reference: [BT91] <author> D.P. Bertsekas and J.N. Tsitsiklis. </author> <title> An analysis of stochastic shortest path problems. </title> <journal> Math. of Op. Res., </journal> <volume> 16(3) </volume> <pages> 580-595, </pages> <year> 1991. </year>
Reference-contexts: The class of instances that is most closely related to ours is the one discussed by Bertsekas [Ber87, x6.2, p. 255] and Bertsekas and Tsitsiklis <ref> [BT91] </ref>, which consider the replacement of SSP Assumption 2 with both SSP Assumption 4 and the following assumption: SSP Assumption 5: There is a proper policy 0 2 P such that v 0 = inf v . <p> In words, SSP Assumption 5 states the existence of a policy that is at the same time proper and optimal from the point of view of expected cost. As noted also in <ref> [BT91] </ref>, there are many instances of SSP in which SSP Assumptions 1 and 4 hold, but 5 does not: one such instance is described in the following example. 150 CHAPTER 7. STOCHASTIC SHORTEST PATH AND RELATED PROBLEMS Example 7.1 Consider the instance of SSP depicted in Figure 7.1. <p> Then, s j= D ./a iff v fl for s 2 C, a 0 and ./2 f; &lt;g. Differently from Section 4.5.1, we cannot use the results of Bertsekas and Tsitsiklis <ref> [BT91] </ref> to solve this instance of SSP problem, since SSP Assumption 2 does not necessarily hold. In fact, we cannot rule out the presence of an end component (B; D) in C such that time (s; a) = 0 for all s 2 B, a 2 D (s). <p> Then, s j= D ./a iff v fl for s 2 C, a 0 and ./2 f; &gt;g. As in the preceding subsection, we cannot use the results of Bertsekas and Tsitsiklis <ref> [BT91] </ref> to solve this instance of SSP problem, since SSP Assumption 2 does not necessarily hold. Again, the 182 CHAPTER 8.
Reference: [CC91] <author> L. Christoff and I. Christoff. </author> <title> Efficient algorithms for verification of equivalences for probabilistic processes. </title> <booktitle> In Computer Aided Verification, volume 575 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 310-321. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference: [CE81] <author> E.M. Clarke and E.A. Emerson. </author> <title> Design and synthesis of synchronization skeletons using branching time temporal logic. </title> <booktitle> In Proc. Workshop on Logic of Programs, volume 131 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 52-71. </pages> <publisher> Springer-Verlag, </publisher> <year> 1981. </year>
Reference: [CFZ96] <author> E. Clarke, M. Fujita, and X. Zhao. </author> <title> Multi-Terminal Binary Decision Diagrams and Hybrid Decision Diagrams, </title> <booktitle> Representations of Discrete Functions, </booktitle> <pages> pages 93-108. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1996. </year>
Reference: [CM96] <author> K. Seidel C. Morgan, A. McIver. </author> <title> Probabilistic predicate transformers. </title> <journal> ACM Trans. Prog. Lang. Sys., </journal> <volume> 18(3) </volume> <pages> 325-353, </pages> <month> May </month> <year> 1996. </year>
Reference: [CMP92] <author> E. Chang, Z. Manna, and A. Pnueli. </author> <title> The safety-progress classification. </title> <booktitle> In Logic, Algebra, and Computation, NATO ASI Series, Subseries F: Computer and System Sciences. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1992. </year>
Reference-contexts: A Comparison with Temporal-Logic Classifications The classification of probabilistic properties described above might recall the classification of temporal properties into the safety and liveness classes proposed by Lamport [Lam77, Lam83], or the safety-progress classification of Chang, Manna and Pnueli <ref> [CMP92] </ref>. There are, nonetheless, significant differences between these classifications. Safety-progress classification. The safety-progress classification is closed under boolean operators, in the sense that boolean combinations of formulas belonging to the classification still belong 5.4. EXPRESSIVE POWER OF EXPERIMENTS 101 to the classification.
Reference: [CMT91] <author> G. Ciardo, J.K. Muppala, </author> <title> and K.S. Trivedi. On the solution of GSPN reward models. Performance Evaluation, </title> <booktitle> 12 </booktitle> <pages> 237-253, </pages> <year> 1991. </year>
Reference: [CSZ92] <author> R. Cleaveland, S.A. Smolka, and A. Zwarico. </author> <title> Testing preorders for probabilistic processes. </title> <booktitle> In Proc. 19th Int. Colloq. Aut. Lang. Prog., Lect. Notes in Comp. Sci., </booktitle> <pages> pages 708-719. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year> <note> 214 BIBLIOGRAPHY </note>
Reference: [CY88] <author> C. Courcoubetis and M. Yannakakis. </author> <title> Verifying temporal properties of finite-state probabilistic programs. </title> <booktitle> In Proc. 29th IEEE Symp. </booktitle> <institution> Found. of Comp. Sci., </institution> <year> 1988. </year>
Reference-contexts: Proof. The lower bounds are a consequence of the results of Courcoubetis and Yannakakis <ref> [CY88] </ref>; the upper bounds are derived from an analysis of the proposed model-checking algorithms. Table 8.2 summarizes the results on the complexity of the model-checking algorithms for the probabilistic logics presented in this dissertation. 184 CHAPTER 8. <p> The proof is then concluded in the same way as the previous one. 8.7.2 Model Checking of Path Quantifiers The proof of Theorem 8.4 is related to the results of Courcoubetis and Yannakakis <ref> [CY88, CY95] </ref> relative to the problem of probabilistic emptiness. The differences lie in the presence of fairness, in the concept of admissible policies, and in the use of Rabin automata and end components in the analysis of the problem. Proof of Theorem 8.4.
Reference: [CY90] <author> C. Courcoubetis and M. Yannakakis. </author> <title> Markov decision processes and regular events. </title> <booktitle> In Proc. 17th Int. Colloq. Aut. Lang. Prog., volume 443 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 336-349. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Proof. The lower bounds are a consequence of the results of Courcoubetis and Yannakakis <ref> [CY90] </ref>; the upper bounds are derived from an analysis of the proposed model-checking algorithms. 6.2 Towards the Correctness Proof: Relation Between r, w and R, W (z) The rest of this chapter, except the last section, is devoted to the correctness proof of the model-checking algorithm for GPTL and GPTL*, and <p> The method we use to go from the solution on a strongly connected SMDP to that on a general SMDP is related to the technique used to solve the optimization problem for many events in Courcoubetis and Yannakakis <ref> [CY90] </ref>. Algorithm 6.6 (computation of H s on general SMDP) Input: An SMDP = (S; A; p; R; W ) and a state s 0 2 S. Output: H Method: Perform the following steps. 146 CHAPTER 6. VERIFICATION OF LONG-RUN AVERAGE PROPERTIES 1.
Reference: [CY95] <author> C. Courcoubetis and M. Yannakakis. </author> <title> The complexity of probabilistic verification. </title> <journal> J. ACM, </journal> <volume> 42(4) </volume> <pages> 857-907, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: The proof is then concluded in the same way as the previous one. 8.7.2 Model Checking of Path Quantifiers The proof of Theorem 8.4 is related to the results of Courcoubetis and Yannakakis <ref> [CY88, CY95] </ref> relative to the problem of probabilistic emptiness. The differences lie in the presence of fairness, in the concept of admissible policies, and in the use of Rabin automata and end components in the analysis of the problem. Proof of Theorem 8.4.
Reference: [dA97] <author> L. de Alfaro. </author> <title> Temporal logics for the specification of performance and reliability. </title> <booktitle> In Proc. of Symp. on Theor. Asp. of Comp. Sci., volume 1200 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 165-176. </pages> <publisher> Springer-Verlag, </publisher> <month> February </month> <year> 1997. </year>
Reference-contexts: VERIFICATION OF LONG-RUN AVERAGE PROPERTIES 6.1 Model-Checking Algorithms for GPTL and GPTL* In this section, we present algorithms to decide whether a TPS satisfies a specification written in GPTL or GPTL*. Since these logics are obtained by extending the logics pTL and pTL* <ref> [dA97] </ref>, we need to examine only the cases corresponding to the two new operators P and D. The justification for the algorithms is somewhat involved, and will be presented in the remainder of the chapter. <p> The following theorem is the analogous of Theorem 4.2, and provides an algorithm for the model checking of operator P in FPTL and FPTL*. This algorithm is very similar to the one presented in [KB96, Section 10] (which in turn is based in part on <ref> [BdA95, dA97] </ref>). The similarity of the algorithms is in spite of the fact that the definition of fairness, and other details of the system models, are different.
Reference: [DC64] <author> J.S. De Cani. </author> <title> A dynamic programming algorithm for embedded Markov chains when the planning horizon is at infinity. </title> <institution> Management Sci., 10:710, </institution> <year> 1964. </year>
Reference-contexts: Semi-Markov decision processes have been described in Jensen [Jen53], Howard [How60, How63], De Cani <ref> [DC64] </ref>, Veinott [Vei69], Ross [Ros70b, Ros70a]; we will essentially follow the presentation of Bertsekas [Ber95]. <p> For a CPB MDP, we will show that the value of J be computed by solving a system 6.6. COMPUTING THE MAXIMUM AND MINIMUM VALUES OF J 133 of equations known as the Bellman equations for semi-Markov processes. This approach has been described by Howard [How60], De Cani <ref> [DC64] </ref>, Veinott [Vei69] and Ross [Ros70b]; a more recent account is provided by Bertsekas [Ber95, Volume II].
Reference: [Den70] <author> E.V. Denardo. </author> <title> Computing a bias-optimal policy in a discrete-time Markov decision problem. Op. </title> <journal> Res., </journal> <volume> 18 </volume> <pages> 279-289, </pages> <year> 1970. </year>
Reference-contexts: These results on the SSP problem will also lead us to new algorithms for the minimum expected total cost problem. Even though reductions to linear programming for this problem have been known since Denardo <ref> [Den70] </ref>, by combining the previous analysis with yet another application of end components, we will obtain a more direct, and possibly more efficient, reduction to linear programming for the case of non-negative costs. <p> In this section, we will describe instead a problem for which the straightforward reduction to linear programming does not work: the non-negative minimum expected total cost (non-negative METC) problem. Strauch [Str66] discusses this problem, and Denardo <ref> [Den70] </ref> proposed reductions to linear programming that finds bias-optimal policies for the METC problem without requiring the non-negativity assumption. The proposal of [Den70] requires the solution of three nested linear programming problems. <p> Strauch [Str66] discusses this problem, and Denardo <ref> [Den70] </ref> proposed reductions to linear programming that finds bias-optimal policies for the METC problem without requiring the non-negativity assumption. The proposal of [Den70] requires the solution of three nested linear programming problems. For the case of the non-negative METC problem we propose an alternative method, which requires the solution of only one linear programming problem. Our method is based on a reduction from the non-negative METC problem to the SSP problem. <p> Aside from linear programming, the reduction enables the use of value and policy iteration methods to solve non-negative METC problems. The proposed reduction relies once more on the properties of end components. In fact, there is a correspondence between the method of <ref> [Den70] </ref> and our proposal: the solution of some linear programming problems in [Den70] corresponds to the removal of end components in our approach. A discussion of the relationship between the two methods, however, is beyond the scope of this dissertation. <p> The proposed reduction relies once more on the properties of end components. In fact, there is a correspondence between the method of <ref> [Den70] </ref> and our proposal: the solution of some linear programming problems in [Den70] corresponds to the removal of end components in our approach. A discussion of the relationship between the two methods, however, is beyond the scope of this dissertation.
Reference: [Der63] <author> C. Derman. </author> <title> Stable sequential control rules and Markov chains. </title> <journal> J. of Math. Anal. and Appl., </journal> <volume> 6 </volume> <pages> 257-265, </pages> <year> 1963. </year>
Reference: [Der64] <author> C. Derman. </author> <title> On sequential control processes. </title> <journal> Ann. Math. Stat., </journal> <volume> 35 </volume> <pages> 341-349, </pages> <year> 1964. </year>
Reference-contexts: Finally, let U be the convex hull of U . Notice that U , considered in the extended real space completed with the infinity points, is a closed set, since there is only a finite number of deterministic policies. The following theorem, due to Derman <ref> [Der64] </ref> (see also [Der70, Chapter 7]), relates U to the probability distribution of v * .
Reference: [Der70] <author> C. Derman. </author> <title> Finite State Markovian Decision Processes. </title> <publisher> Acedemic Press, </publisher> <year> 1970. </year>
Reference-contexts: Finally, let U be the convex hull of U . Notice that U , considered in the extended real space completed with the infinity points, is a closed set, since there is only a finite number of deterministic policies. The following theorem, due to Derman [Der64] (see also <ref> [Der70, Chapter 7] </ref>), relates U to the probability distribution of v * . <p> Once the dependency from the initial state is eliminated, to obtain the policy (u) corresponding to u we must somehow "mix" the policies according to (6.33). This "mix" can obtained as indicated by Derman <ref> [Der70, Chapter 7, Theorem 1] </ref>; see also Derman and Strauch [DS66] and Strauch and Veinott [SV66]. Theorem 6.8 (state-action frequencies correspond to policies) For every u 2 U and t 2 S, there is a policy (u) such that u (u) Proof. <p> Derman <ref> [Der70, Chapter 7, Theorem 1] </ref>; see also Derman and Strauch [DS66] and Strauch and Veinott [SV66]. Theorem 6.8 (state-action frequencies correspond to policies) For every u 2 U and t 2 S, there is a policy (u) such that u (u) Proof. The result follows from (6.33) and from [Der70, Chapter 7, Theorem 1]. Consider now an arbitrary vector u = [x ~ 1 ; : : : ; x ~ m ]. For policy (u) and any s 2 S we can 126 CHAPTER 6. <p> From classical results about the average cost of an MDP, we know then that the Bellman equations h s = min X p st (a)h t ; s 2 S have at least one solution [h fl s ] s2S <ref> [Der70] </ref>. Substituting W (s; a) J R (s; a) for g (s; a), we see that this equation is the same as (BEQ) with = J . This indicates that (BEQ) admits at least the solution J s ] s2S .
Reference: [DNH84] <author> R. De Nicola and M. Hennessy. </author> <title> Testing equivalences for processes. </title> <journal> Theoretical Computer Science, </journal> <volume> 34 </volume> <pages> 83-133, </pages> <year> 1984. </year>
Reference: [Doo94] <author> J.L. Doob. </author> <title> Measure Theory. </title> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference: [DRH95] <author> S. Donatelli, M. Ribaudo, and J. Hillston. </author> <title> A comparison of performance evaluation process algebra and generalized Petri nets. </title> <booktitle> In Proc. 6th Int. Workshop on Petri Nets and Performance Models, </booktitle> <pages> pages 158-168. </pages> <publisher> IEEE Comput. Soc. Press, </publisher> <year> 1995. </year>
Reference: [DS66] <author> C. Derman and R. Strauch. </author> <title> A note on memoryless rules for controlling sequential control processes. </title> <journal> Ann. Math. Stat., </journal> <volume> 37 </volume> <pages> 276-278, </pages> <year> 1966. </year>
Reference-contexts: Once the dependency from the initial state is eliminated, to obtain the policy (u) corresponding to u we must somehow "mix" the policies according to (6.33). This "mix" can obtained as indicated by Derman [Der70, Chapter 7, Theorem 1]; see also Derman and Strauch <ref> [DS66] </ref> and Strauch and Veinott [SV66]. Theorem 6.8 (state-action frequencies correspond to policies) For every u 2 U and t 2 S, there is a policy (u) such that u (u) Proof. The result follows from (6.33) and from [Der70, Chapter 7, Theorem 1].
Reference: [EH85] <author> E.A. Emerson and J.Y. Halpern. </author> <title> "sometimes" and "not never" revisited: on branching versus linear time temporal logic. </title> <journal> J. ACM, </journal> <volume> 33(1) </volume> <pages> 151-178, </pages> <year> 1985. </year>
Reference: [EL85] <author> E.A. Emerson and C.L. Lei. </author> <title> Modalities for model checking: Branching time strikes back. </title> <booktitle> In Proc. 12th ACM Symp. Princ. of Prog. Lang., </booktitle> <pages> pages 84-96, </pages> <year> 1985. </year> <note> BIBLIOGRAPHY 215 </note>
Reference: [Eme90] <author> E.A. Emerson. </author> <title> Temporal and modal logic. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume B, chapter 16, </booktitle> <pages> pages 995-1072. </pages> <publisher> Elsevier Science Publishers (North-Holland), </publisher> <address> Amsterdam, </address> <year> 1990. </year>
Reference: [Fel83] <author> Y.A. Feldman. </author> <title> A decidable propositional probabilistic dynamic logic. </title> <booktitle> In Proc. 15th ACM Symp. Theory of Comp., </booktitle> <pages> pages 298-309, </pages> <year> 1983. </year>
Reference: [FH82] <author> Y.A. Feldman and D. Harel. </author> <title> A probabilistic dynamic logic. </title> <booktitle> In Proc. 14th ACM Symp. Theory of Comp., </booktitle> <pages> pages 181-195, </pages> <year> 1982. </year>
Reference: [Fra86] <author> N. Francez. </author> <title> Fairness. </title> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: Its traditional uses include the modeling of concurrency and of un-biased arbitration; among the monographs devoted to the study of fairness, we recall Francez <ref> [Fra86] </ref> and Apt, Francez and Katz [AFK88]. Two notions of fairness are commonly considered: justice, also called weak fairness, and compassion, also called strong fairness (see Manna and Pnueli [MP91, MP95]). Informally, the meaning of justice and compassion can be described as follows.
Reference: [GH94] <author> S. Gilmore and J. Hillston. </author> <title> The PEPA workbench: A tool to support a process algebra-based approach to performance modelling. </title> <booktitle> In 7th Int. Conf. on Modelling Techniques and Tools for Computer Performance Evaluation, </booktitle> <month> May </month> <year> 1994. </year>
Reference: [GHR93] <author> H.N. Gotz, U. Herzog, and M. Rettelbach. </author> <title> Multiprocessor and distributed system design: the integration of functional specification and performance analysis using stochastic process algebras. </title> <booktitle> In PERFORMANCE'93, volume 729 of Lect. Notes in Comp. </booktitle> <publisher> Sci. Springer-Verlag, </publisher> <year> 1993. </year>
Reference: [Han94] <author> H. Hansson. </author> <title> Time and Probabilities in Formal Design of Distributed Systems. Real-Time Safety Critical Systems Series. </title> <publisher> Elsevier, </publisher> <year> 1994. </year>
Reference: [Hil95] <author> J. Hillston. </author> <title> Compositional Markovian modelling using a process algebra. In Second Int. Work. on Numerical Solution of Markov Chains. </title> <publisher> Kluwer Academic Press, </publisher> <month> January </month> <year> 1995. </year> <title> Book title: Computations with Markov Chains. </title>
Reference: [Hil96] <author> J. Hillston. </author> <title> A Compositional Approach to Performance Modelling. </title> <booktitle> Distinguished Dissertations Series. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1996. </year>
Reference: [HJ89] <author> H. Hansson and B. Jonsson. </author> <title> A framework for reasoning about time and reliability. </title> <booktitle> In Proc. of Real Time Systems Symposium, </booktitle> <pages> pages 102-111. </pages> <publisher> IEEE, </publisher> <year> 1989. </year>
Reference: [HJ94] <author> H. Hansson and B. Jonsson. </author> <title> A logic for reasoning about time and probability. </title> <journal> Formal Aspects of Computing, </journal> <volume> 6(5) </volume> <pages> 512-535, </pages> <year> 1994. </year>
Reference: [HK97] <author> M. Huth and M. Kwiatkowska. </author> <title> Quantitative analysis and model checking. </title> <booktitle> In Proc. 12th IEEE Symp. Logic in Comp. Sci., </booktitle> <pages> pages 111-122, </pages> <year> 1997. </year>
Reference: [HMS96] <author> J. He, A.K. McIver, and K. Seidel. </author> <title> Probabilistic models for the guarded command language. </title> <institution> Sci. Comput. Program., </institution> <year> 1996. </year> <note> In FMTA'95 special issue. </note>
Reference: [How60] <author> H. Howard. </author> <title> Dynamic Programming and Markov Processes. </title> <publisher> MIT Press, </publisher> <year> 1960. </year> <note> 216 BIBLIOGRAPHY </note>
Reference-contexts: Semi-Markov decision processes have been described in Jensen [Jen53], Howard <ref> [How60, How63] </ref>, De Cani [DC64], Veinott [Vei69], Ross [Ros70b, Ros70a]; we will essentially follow the presentation of Bertsekas [Ber95]. <p> While Theorem 6.9 appears to be accomplishing such a reduction, the reduction is in fact incomplete. In fact, the traditional analysis of semi-Markov decision problems relies on assumption (6.37), which enables the use of the uniformation technique described by Jensen [Jen53], Howard <ref> [How60] </ref>, Veinott [Vei69] and [Sch71] (an account of the technique can also be found in [Ber95]). Most of the known results for semi-Markov problems depend on this technique, and thus on assumption (6.37); this includes the results presented in Ross [Ros70b, Ros70a], Puterman [Put94] and Bertsekas [Ber95]. <p> For a CPB MDP, we will show that the value of J be computed by solving a system 6.6. COMPUTING THE MAXIMUM AND MINIMUM VALUES OF J 133 of equations known as the Bellman equations for semi-Markov processes. This approach has been described by Howard <ref> [How60] </ref>, De Cani [DC64], Veinott [Vei69] and Ross [Ros70b]; a more recent account is provided by Bertsekas [Ber95, Volume II]. <p> Theorem 6.12 (existence of solutions to the Bellman equations) On a CPB MDP, the equations (BEQ) always have at least one solution. The standard proof of this result relies either on uniformation techniques (see Jensen [Jen53], Howard <ref> [How60] </ref> and Veinott [Vei69]) or on a connection with the stochastic shortest path problem, if all policies are unichain (see Bertsekas [Ber95, Volume II, x 5.3]).
Reference: [How63] <author> R.A. Howard. </author> <title> Semi-Markovian decision problems. </title> <note> In Intern. </note> <institution> Stat. Inst., </institution> <address> Ottawa, Canada, </address> <year> 1963. </year>
Reference-contexts: Semi-Markov decision processes have been described in Jensen [Jen53], Howard <ref> [How60, How63] </ref>, De Cani [DC64], Veinott [Vei69], Ross [Ros70b, Ros70a]; we will essentially follow the presentation of Bertsekas [Ber95].
Reference: [How71] <author> R. Howard. </author> <title> Dynamic Probabilistic Systems: Semi-Markov and Decision Systems, volume II. </title> <publisher> Wiley, </publisher> <year> 1971. </year>
Reference: [HS82] <author> D.P. Heyman and M.J. Sobel. </author> <title> Stochastic Models in Operations Research, volume I. </title> <publisher> McGraw-Hill, </publisher> <year> 1982. </year>
Reference: [HS84a] <author> S. Hart and M. Sharir. </author> <title> Probabilistic temporal logic for finite and bounded models. </title> <booktitle> In Proc. 16th ACM Symp. Theory of Comp., </booktitle> <pages> pages 1-13, </pages> <year> 1984. </year>
Reference: [HS84b] <author> D.P. Heyman and M.J. Sobel. </author> <title> Stochastic Models in Operations Research, volume II. </title> <publisher> McGraw-Hill, </publisher> <year> 1984. </year>
Reference: [HS86] <author> S. Hart and M. Sharir. </author> <title> Probabilistic propositional temporal logics. Information and Computation, </title> <address> 70(2-3):97-155, </address> <year> 1986. </year>
Reference: [HSP82] <author> S. Hart, M. Sharir, and A. Pnueli. </author> <title> Termination of probabilistic concurrent programs. </title> <booktitle> In Proc. 9th ACM Symp. Princ. of Prog. Lang., </booktitle> <pages> pages 1-6, </pages> <year> 1982. </year>
Reference-contexts: The subject of fairness in probabilistic systems has been already discussed in the literature. Pnueli [Pnu83] and Pnueli and Zuck [PZ93] introduce the notions of extreme fairness and ff-fairness to abstract from the precise values of probabilities. Hart, Sharir and Pnueli <ref> [HSP82] </ref> and Vardi [Var85] consider probabilistic systems in which the choice of actions at the states is subject to fairness requirements, and present algorithms for checking that temporal logic formulas hold with probability 1 over these systems.
Reference: [HSP83] <author> S. Hart, M. Sharir, and A. Pnueli. </author> <title> Termination of probabilistic concurrent programs. </title> <journal> ACM Trans. Prog. Lang. Sys., </journal> <volume> 5(3) </volume> <pages> 356-380, </pages> <month> July </month> <year> 1983. </year>
Reference: [HSP84] <author> S. Hart, M. Sharir, and A. Pnueli. </author> <title> Verification of probabilistic programs. </title> <journal> SIAM J. Computing, </journal> <volume> 13(2) </volume> <pages> 292-314, </pages> <month> May </month> <year> 1984. </year>
Reference: [Jen53] <author> A. Jensen. </author> <title> Markov chains as an aid to the study of Markov processes. </title> <journal> Skand. Aktuar-iedtishr., </journal> <volume> 36 </volume> <pages> 87-91, </pages> <year> 1953. </year>
Reference-contexts: Semi-Markov decision processes have been described in Jensen <ref> [Jen53] </ref>, Howard [How60, How63], De Cani [DC64], Veinott [Vei69], Ross [Ros70b, Ros70a]; we will essentially follow the presentation of Bertsekas [Ber95]. <p> While Theorem 6.9 appears to be accomplishing such a reduction, the reduction is in fact incomplete. In fact, the traditional analysis of semi-Markov decision problems relies on assumption (6.37), which enables the use of the uniformation technique described by Jensen <ref> [Jen53] </ref>, Howard [How60], Veinott [Vei69] and [Sch71] (an account of the technique can also be found in [Ber95]). Most of the known results for semi-Markov problems depend on this technique, and thus on assumption (6.37); this includes the results presented in Ross [Ros70b, Ros70a], Puterman [Put94] and Bertsekas [Ber95]. <p> Theorem 6.12 (existence of solutions to the Bellman equations) On a CPB MDP, the equations (BEQ) always have at least one solution. The standard proof of this result relies either on uniformation techniques (see Jensen <ref> [Jen53] </ref>, Howard [How60] and Veinott [Vei69]) or on a connection with the stochastic shortest path problem, if all policies are unichain (see Bertsekas [Ber95, Volume II, x 5.3]).
Reference: [JHW94] <author> B. Jonsson, C. Ho-Stuart, and Y. Wang. </author> <title> Testing and refinement for nondeterministic and probabilistic processes. </title> <booktitle> In Proc. of Symp. on Formal Techniques in Real-Time and Fault-Tolerant Systems, volume 863 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 418-430. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference: [JL91] <author> B. Jonsson and K.G. Larsen. </author> <title> Specification and refinement of probabilistic processes. </title> <booktitle> In Proc. 6th IEEE Symp. Logic in Comp. Sci., </booktitle> <pages> pages 266-277, </pages> <year> 1991. </year>
Reference: [JS90] <author> C.-C. Jou and S.A. Smolka. </author> <title> Equivalences, congruences and complete axiomatizations for probabilistic processes. </title> <booktitle> In CONCUR'90: Concurrency Theory. 1st Int. Conf., volume 458 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 367-383. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference: [JW95] <author> B. Jonsson and Y. Wang. </author> <title> Compositional testing preorders for probabilistic processes. </title> <booktitle> In Proc. 10th IEEE Symp. Logic in Comp. Sci., </booktitle> <pages> pages 431-441, </pages> <month> June </month> <year> 1995. </year> <note> BIBLIOGRAPHY 217 </note>
Reference: [KB96] <author> M. Kwiatkowska and C. Baier. </author> <title> Model checking for a probabilistic branching time logic with fairness. </title> <type> Technical Report CSR-96-12, </type> <institution> University of Birmingham, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: This chapter has been inspired by Baier and Kwiatkowska <ref> [KB96] </ref>, which consider models very similar to Markov decision processes with fairness requirements, and present algorithms to compute the probability with which temporal logic formulas hold over these systems. We return on the subject of fairness in probabilistic systems for three reasons. <p> To enforce the fairness requirements of a FMDP, we restrict our attention to fair policies in our definition of logic and system semantics. This approach is closely related to that of <ref> [KB96] </ref>, even though our definition of fair policy is different; we will later present a comparison of the two definitions. <p> To facilitate the comparison, we have reformulated all definitions in terms of Markov decision processes, instead of introducing fair transition systems, as in Manna and Pnueli [MP91], or probabilistic automata, as in Kwiatkowska and Baier <ref> [KB96] </ref>. 8.2.1 Compassion: Fair Transition Systems Approach Consider an MDP (S; A; p), and let Acts be the underlying set of actions. Adapting the definition of [MP91] to the notation of Markov decision processes, we represent FTS-compassion by a set C Acts of actions. <p> Since the definition of [MP91] is not aimed at probabilistic systems, it does not specify how the fairness of behaviors should be reflected in the set of policies that are considered. Two alternatives appear to be the most natural, and have been explored by <ref> [KB96] </ref> in a similar setting: * Only policies under which all behaviors are fair are considered. * Only policies under which behaviors are fair with probability 1 are considered. Clearly, the first alternative leads to a stronger definition of fairness than the second one. <p> on the notion of probabilistic fairness rather than ff-fairness because the definition of probabilistic fairness does not require the introduction of past temporal formulas, and because probabilistic fairness, being already stated in terms of probability, leads to a simpler analysis of the model-checking algorithms. 8.2.2 State-Based Fairness Baier and Kwiatkowska <ref> [KB96] </ref> propose a different solution to the problem illustrated in Example 8.2. According to [KB96], a behavior ! is fair if, whenever a state s appears infinitely often along !, all actions in A (s) also appear infinitely often along !. <p> fairness does not require the introduction of past temporal formulas, and because probabilistic fairness, being already stated in terms of probability, leads to a simpler analysis of the model-checking algorithms. 8.2.2 State-Based Fairness Baier and Kwiatkowska <ref> [KB96] </ref> propose a different solution to the problem illustrated in Example 8.2. According to [KB96], a behavior ! is fair if, whenever a state s appears infinitely often along !, all actions in A (s) also appear infinitely often along !. This notion of fairness has its roots in the state-fairness described in Pnueli [Pnu83] and Vardi [Var85]. As mentioned in [KB96], this definition can <p> According to <ref> [KB96] </ref>, a behavior ! is fair if, whenever a state s appears infinitely often along !, all actions in A (s) also appear infinitely often along !. This notion of fairness has its roots in the state-fairness described in Pnueli [Pnu83] and Vardi [Var85]. As mentioned in [KB96], this definition can be easily generalized to the case in which to each state s is associated a set of fair actions F (s). <p> This FMDP can be obtained by taking the product of the FMDP of Example 8.1 with an automaton over the natural numbers whose state increases by one at each transition. Since no state of this MDP appears more than once in any behavior, the fairness notion of <ref> [KB96] </ref> does not impose any constraint on the set of policies for it. This example indicates that the definition of [KB96] is not invariant with respect to the product with infinite-state systems. The notion of probabilistic fairness retains most of the properties of the proposal of [KB96] while being readily extendible <p> Since no state of this MDP appears more than once in any behavior, the fairness notion of <ref> [KB96] </ref> does not impose any constraint on the set of policies for it. This example indicates that the definition of [KB96] is not invariant with respect to the product with infinite-state systems. The notion of probabilistic fairness retains most of the properties of the proposal of [KB96] while being readily extendible to infinite-state systems. <p> the fairness notion of <ref> [KB96] </ref> does not impose any constraint on the set of policies for it. This example indicates that the definition of [KB96] is not invariant with respect to the product with infinite-state systems. The notion of probabilistic fairness retains most of the properties of the proposal of [KB96] while being readily extendible to infinite-state systems. Moreover, probabilistic fairness is suited to the representation of transitions with unknown delay distributions, as we will see in the next chapter. 170 CHAPTER 8. <p> Given a state s and a sequence formula , denote by P (s; ) = x 2 [0; 1] fi s (! j= ) = x the set of values that the probability of can assume under admissible policies. An analysis of the algorithms presented in Baier and Kwiatkowska <ref> [KB96] </ref> (which are based on a different notion of fairness) reveals that determining sup P (s; ) and inf P (s; ) can be done in time polynomial in 172 CHAPTER 8. FAIRNESS the size of the TPS. <p> MODEL-CHECKING ALGORITHMS FOR FPTL AND FPTL* 179 quantifiers. The following theorem is the analogous of Theorem 4.2, and provides an algorithm for the model checking of operator P in FPTL and FPTL*. This algorithm is very similar to the one presented in <ref> [KB96, Section 10] </ref> (which in turn is based in part on [BdA95, dA97]). The similarity of the algorithms is in spite of the fact that the definition of fairness, and other details of the system models, are different. <p> To this end, we use the notion of approximation of non-admissible policies by admissible ones. This notion has been discussed in Pnueli [Pnu83] and Kwiatkowska and Baier <ref> [KB96] </ref>. Informally, the idea is that it is sometimes possible to approximate a non-admissible policy with a series of admissible ones, such that the quantity of interest (probability, expected time) for the admissible policies can be made as close as desired to that of the non-admissible policy.
Reference: [Koz79] <author> D. Kozen. </author> <title> Semantic of probabilistic programs. </title> <booktitle> In Proc. 20th IEEE Symp. Found. of Comp. Sci., </booktitle> <pages> pages 101-114, </pages> <year> 1979. </year> <note> Also appeared in the Journal of Computer and System Sciences, vol. 22, </note> <month> 328-350 </month> <year> (1981). </year>
Reference: [Koz83] <author> D. Kozen. </author> <title> A probabilistic PDL. </title> <booktitle> In Proc. 15th ACM Symp. Theory of Comp., </booktitle> <pages> pages 291-297, </pages> <year> 1983. </year>
Reference: [KP95] <author> O. Kupferman and A. Pnueli. </author> <title> Once and for all. </title> <booktitle> In Proc. 10th IEEE Symp. Logic in Comp. Sci., </booktitle> <pages> pages 25-35, </pages> <year> 1995. </year>
Reference: [KSK66] <author> J.G. Kemeny, J.L. Snell, and A.W. Knapp. </author> <title> Denumerable Markov Chains. </title> <address> D. </address> <publisher> Van Nostrand Company, </publisher> <year> 1966. </year>
Reference-contexts: Our first result provides a model-checking algorithm for the case in which is an ergodic Markov chain (recall that an ergodic Markov chain is a chain in which all states belong to a single closed recurrent class <ref> [KSK66] </ref>). Theorem 6.1 (model checking ergodic Markov chains) Consider an MDP corresponding to an ergodic Markov chain. <p> We can interpret this "missing probability" as the probability that a behaviors ends prematurely; this is a point of view often adopted in the theory of stochastic processes and Markov chains (see, for example, Kemeny, Snell, and Knapp <ref> [KSK66] </ref>). With this interpretation, we can associate to ~ a sub-probability space defined on the infinite behaviors. <p> If is unichain, then standard results on Markov chains ensure that p ;fl us for all s; t; u 2 S (see, for example, Kemeny, Kendall, and Snell <ref> [KSK66] </ref>). This means that the long-run average fraction of time spent at a state does not depend on the initial state. We can thus define the steady state vector = [ s ] s2S by ;fl ts for all s 2 S, where t 2 S is arbitrary. <p> s and H s are not equal, showing that (6.53) is not trivial. 6.8.2 Martingale Property of H A martingale for a stochastic process is a quantity such that its current value is equal to the expectation of its future value; the precise definition can be found, for example, in <ref> [Wil91, KSK66] </ref>. By showing that H is a martingale, we will obtain a relation between the value of H at a state and at the successor states. <p> Recall that a substochastic matrix is a matrix P = [p ij ] 1i;jN such that 0 p ij 1 for all 1 i; j N and j=1 p ij 1 for all 1 i N <ref> [KSK66] </ref>. Theorem 8.11 (continuity of steady-state distributions) For a fixed N , consider a family P (x) = [p ij (x)] 1i;jN of substochastic matrices parameterized by a parameter x 2 I, where I IR is an interval of real numbers.
Reference: [KT75] <author> S. Karlin and H.M. Taylor. </author> <title> A First Course in Stochastic Processes. </title> <publisher> Academic Press, </publisher> <year> 1975. </year> <note> Second edition. </note>
Reference: [Lam77] <author> L. Lamport. </author> <title> Proving the correctness of multiprocessor programs. </title> <journal> IEEE Trans. Software Engin., </journal> <volume> 3 </volume> <pages> 125-143, </pages> <year> 1977. </year>
Reference-contexts: A Comparison with Temporal-Logic Classifications The classification of probabilistic properties described above might recall the classification of temporal properties into the safety and liveness classes proposed by Lamport <ref> [Lam77, Lam83] </ref>, or the safety-progress classification of Chang, Manna and Pnueli [CMP92]. There are, nonetheless, significant differences between these classifications. Safety-progress classification. The safety-progress classification is closed under boolean operators, in the sense that boolean combinations of formulas belonging to the classification still belong 5.4.
Reference: [Lam83] <author> L. Lamport. </author> <title> What good is temporal logic? In R.E.A. </title> <editor> Mason, editor, </editor> <booktitle> Proc. IFIP 9th World Congress, </booktitle> <pages> pages 657-668. </pages> <publisher> Elsevier Science Publishers (North-Holland), </publisher> <year> 1983. </year>
Reference-contexts: A Comparison with Temporal-Logic Classifications The classification of probabilistic properties described above might recall the classification of temporal properties into the safety and liveness classes proposed by Lamport <ref> [Lam77, Lam83] </ref>, or the safety-progress classification of Chang, Manna and Pnueli [CMP92]. There are, nonetheless, significant differences between these classifications. Safety-progress classification. The safety-progress classification is closed under boolean operators, in the sense that boolean combinations of formulas belonging to the classification still belong 5.4.
Reference: [LDPK95] <author> M.L. Littman, T.L. Dean, and L. </author> <title> Pack Kaelbling. On the complexity of solving Markov decision problems. </title> <booktitle> In Uncertainty in Artificial Intelligence. Proceedings of the 11th Conference, </booktitle> <pages> pages 394-402, </pages> <year> 1995. </year>
Reference: [LPS81] <author> D. Lehmann, A. Pnueli, and J. Stavi. Impartiality, </author> <title> justice and fairness: the ethics of concurrent termination. </title> <booktitle> In Proc. 8th Int. Colloq. Aut. Lang. Prog., volume 115 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 264-277. </pages> <publisher> Springer-Verlag, </publisher> <year> 1981. </year>
Reference-contexts: Finally, we describe the model-checking algorithm for FPTL and FPTL*, followed by its correctness proof. 8.1 An Overview of Fairness The concept of fairness in the context of formal system verification was introduced by Lehmann, Pnueli and Stavi <ref> [LPS81] </ref> for shared-variables programs, and by Queille and Sifakis [QS83] for transition systems. Its traditional uses include the modeling of concurrency and of un-biased arbitration; among the monographs devoted to the study of fairness, we recall Francez [Fra86] and Apt, Francez and Katz [AFK88].
Reference: [LR81] <author> D. Lehmann and M. Rabin. </author> <title> On the advantage of free choice: a symmetrical and fully distributed solution to the dining philosophers problem. </title> <booktitle> In Proc. 8th ACM Symp. Princ. of Prog. Lang., </booktitle> <pages> pages 133-138, </pages> <year> 1981. </year>
Reference: [LS82] <author> D. Lehman and S. Shelah. </author> <title> Reasoning with time and chance. </title> <journal> Information and Control, </journal> <volume> 53(3) </volume> <pages> 165-198, </pages> <year> 1982. </year>
Reference: [LS89] <author> K.G. Larsen and A. Skou. </author> <title> Bisimulation through probabilistic testing (preliminary report). </title> <booktitle> In Proc. 16th ACM Symp. Princ. of Prog. </booktitle> <address> Lang., </address> <year> 1989. </year>
Reference: [LS91] <author> K.G. Larsen and A. Skou. </author> <title> Bisimulation through probabilistic testing. </title> <journal> Information and Computation, </journal> <volume> 94(1) </volume> <pages> 1-28, </pages> <year> 1991. </year> <note> Preliminary report in POPL'89. 218 BIBLIOGRAPHY </note>
Reference: [LS92] <author> K.G. Larsen and A. Skou. </author> <title> Compositional verification of probabilistic processes. </title> <editor> In W.R. Cleaveland, editor, CONCUR'92: </editor> <booktitle> Concurrency Theory. 3rd Int. Conf., volume 630 of Lect. Notes in Comp. </booktitle> <publisher> Sci. Springer-Verlag, </publisher> <year> 1992. </year>
Reference: [LSS94] <author> N. Lynch, I. Saias, and R. Segala. </author> <title> Proving time bounds for randomized distributed algorithms. </title> <booktitle> In Proc. of Symp. on Principles of Distributed Computing, </booktitle> <pages> pages 314-323, </pages> <year> 1994. </year>
Reference: [LT87] <author> N.A. Lynch and M. Tuttle. </author> <title> Hierarcical correctness proofs for distributed algorithms. </title> <booktitle> In Proc. 6th ACM Symp. Princ. of Dist. Comp., </booktitle> <year> 1987. </year>
Reference: [MC94] <author> M. Melekopoglou and A. Condon. </author> <title> On the complexity of the policy improvement algorithm for Markov decision processes. </title> <journal> ORSA Journal on Computing, </journal> <volume> 6(2) </volume> <pages> 188-192, </pages> <year> 1994. </year>
Reference: [McN66] <author> R. McNaughton. </author> <title> Testing and generating infinite sequences by a finite automaton. </title> <journal> Information and Computation, </journal> <volume> 9 </volume> <pages> 521-530, </pages> <year> 1966. </year>
Reference-contexts: SPECIFICATION OF LONG-RUN AVERAGE PROPERTIES The model checking of GPTL* formula P ./a involves the construction of the product between the TPS and the deterministic Rabin automaton for or :. Deterministic Rabin automata are strictly more expressive than deterministic Buchi automata (see McNaughton <ref> [McN66] </ref> and Thomas [Tho90]). Nonetheless, for the sake of simplicity we consider an algorithm that computes the product with a deterministic Buchi automaton instead. Such an algorithm can be used for the subclass of formulas that can be encoded as deterministic Buchi automata.
Reference: [Mil83] <author> R. Milner. </author> <title> Calculi for synchrony and asynchrony. </title> <journal> Theoretical Computer Science, </journal> <volume> 25 </volume> <pages> 267-310, </pages> <year> 1983. </year>
Reference: [Mil90] <author> R. Milner. </author> <title> Operational and algebraic semantics of concurrent processes. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, </booktitle> <volume> volume B, </volume> <pages> pages 1202-1242. </pages> <publisher> Elsevier Science Publishers (North-Holland), </publisher> <address> Amsterdam, </address> <year> 1990. </year>
Reference: [MMP92] <author> O. Maler, Z. Manna, and A. Pnueli. </author> <title> From timed to hybrid systems. </title> <booktitle> In Proc. of the REX Workshop "Real-Time: Theory in Practice", volume 600 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 447-484. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference: [Mol81] <editor> M.K. </editor> <title> Molloy. On the Integration of Delay and Throughput Measure In Distributed Processing Models. </title> <type> PhD thesis, </type> <institution> UCLA, </institution> <address> Los Angeles, </address> <year> 1981. </year>
Reference: [Mol82] <editor> M.K. </editor> <title> Molloy. Performance analysis using stochastic Petri nets. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-31(9):913-917, </volume> <month> September </month> <year> 1982. </year>
Reference: [MP91] <author> Z. Manna and A. Pnueli. </author> <title> The Temporal Logic of Reactive and Concurrent Systems: Specification. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: Two notions of fairness are commonly considered: justice, also called weak fairness, and compassion, also called strong fairness (see Manna and Pnueli <ref> [MP91, MP95] </ref>). Informally, the meaning of justice and compassion can be described as follows. If t is a just or compassionate transition, then every behavior of the system must obey the following constraints: * t is just. <p> can be often substituted by the stronger requirement of compassion, and that it would be possible to extend our definitions and algorithms to encompass also the notion of justice. 8.2 Probabilistic Fairness In a fair transition system, the fairness requirements are represented by specifying which transitions are just and compassionate <ref> [MP91] </ref>. In the system model of timed probabilistic systems, the role of transitions is played by actions. <p> To facilitate the comparison, we have reformulated all definitions in terms of Markov decision processes, instead of introducing fair transition systems, as in Manna and Pnueli <ref> [MP91] </ref>, or probabilistic automata, as in Kwiatkowska and Baier [KB96]. 8.2.1 Compassion: Fair Transition Systems Approach Consider an MDP (S; A; p), and let Acts be the underlying set of actions. Adapting the definition of [MP91] to the notation of Markov decision processes, we represent FTS-compassion by a set C Acts <p> of Markov decision processes, instead of introducing fair transition systems, as in Manna and Pnueli <ref> [MP91] </ref>, or probabilistic automata, as in Kwiatkowska and Baier [KB96]. 8.2.1 Compassion: Fair Transition Systems Approach Consider an MDP (S; A; p), and let Acts be the underlying set of actions. Adapting the definition of [MP91] to the notation of Markov decision processes, we represent FTS-compassion by a set C Acts of actions. <p> Since the definition of <ref> [MP91] </ref> is not aimed at probabilistic systems, it does not specify how the fairness of behaviors should be reflected in the set of policies that are considered.
Reference: [MP93] <author> Z. Manna and A. Pnueli. </author> <title> Models for reactivity. </title> <journal> Acta Informatica, </journal> <volume> 30 </volume> <pages> 609-678, </pages> <year> 1993. </year>
Reference: [MP95] <author> Z. Manna and A. Pnueli. </author> <title> Temporal Verification of Reactive Systems: Safety. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: Two notions of fairness are commonly considered: justice, also called weak fairness, and compassion, also called strong fairness (see Manna and Pnueli <ref> [MP91, MP95] </ref>). Informally, the meaning of justice and compassion can be described as follows. If t is a just or compassionate transition, then every behavior of the system must obey the following constraints: * t is just.
Reference: [Nat80] <author> S. Natkin. </author> <title> Les Reseaux de Petri Stochastiques et leur Application a l'Evaluation des Systemes Informatiques. </title> <type> PhD thesis, </type> <institution> CNAM, Paris, </institution> <year> 1980. </year> <note> BIBLIOGRAPHY 219 </note>
Reference: [Pet ] <editor> Proc. </editor> <booktitle> of the international workshop on Petri nets and performance models, </booktitle> <address> 1987-. </address>
Reference: [Pnu83] <author> A. Pnueli. </author> <title> On the extremely fair treatment of probabilistic algorithms. </title> <booktitle> In Proc. 15th ACM Symp. Theory of Comp., </booktitle> <pages> pages 278-290, </pages> <year> 1983. </year>
Reference-contexts: The introduction of fairness in the system model requires the use of updated specification languages and model-checking algorithms, which will be described in this chapter. The subject of fairness in probabilistic systems has been already discussed in the literature. Pnueli <ref> [Pnu83] </ref> and Pnueli and Zuck [PZ93] introduce the notions of extreme fairness and ff-fairness to abstract from the precise values of probabilities. <p> Nonetheless, action a is never chosen at state t, indicating how this definition of compassion fails to capture fully the behavior of probabilistic choice. Extreme Fairness and ff-Fairness To remedy to the situation illustrated by the previous example, Pnueli <ref> [Pnu83] </ref> and Pnueli and Zuck [PZ93] introduce the notions of extreme fairness and ff-fairness. Similar concerns also led to the concept of uniform compassion in Bjtrner, Lerner and Manna [BLM97]. The notion of ff-fairness relies on the use of past temporal logic. <p> According to [KB96], a behavior ! is fair if, whenever a state s appears infinitely often along !, all actions in A (s) also appear infinitely often along !. This notion of fairness has its roots in the state-fairness described in Pnueli <ref> [Pnu83] </ref> and Vardi [Var85]. As mentioned in [KB96], this definition can be easily generalized to the case in which to each state s is associated a set of fair actions F (s). <p> To this end, we use the notion of approximation of non-admissible policies by admissible ones. This notion has been discussed in Pnueli <ref> [Pnu83] </ref> and Kwiatkowska and Baier [KB96].
Reference: [Pro ] <editor> Proc. </editor> <booktitle> of international workshop on process algebra and performance modelling, </booktitle> <address> 1993-. </address>
Reference: [PS95] <author> A. Pogosyants and R. Segala. </author> <title> Formal verification of timed properties of randomized distributed algorithms. </title> <booktitle> In Proc. of Symp. on Principles of Distributed Computing, </booktitle> <pages> pages 173-183, </pages> <year> 1995. </year>
Reference: [PT87] <author> C.H. Papadimitriou and J.N. Tsitsiklis. </author> <title> The complexity of Markov decision processes. </title> <journal> Math. of Op. Res., </journal> <volume> 12(3) </volume> <pages> 441-450, </pages> <month> August </month> <year> 1987. </year>
Reference: [Put94] <author> M.L. Puterman. </author> <title> Markov Decision Processes. </title> <publisher> John Wiley and Sons, </publisher> <year> 1994. </year>
Reference-contexts: Most of the known results for semi-Markov problems depend on this technique, and thus on assumption (6.37); this includes the results presented in Ross [Ros70b, Ros70a], Puterman <ref> [Put94] </ref> and Bertsekas [Ber95]. Thus, while we will be able to borrow from the usual development of the subject many concepts and ideas, we will have to follow a different path to get the desired results, and we will have to provide independent proofs of our statements. <p> The value of J can be determined by solving a linear programming problem derived from (BEQ), as explained for example in Puterman <ref> [Put94] </ref> or Bertsekas [Ber95]. <p> There is also a reduction from non-positive METC to SSP, albeit the reduction is more involved. We will not discuss this reduction here, since the non-positive METC problem can also be solved efficiently with the methods discussed, for example, by Puterman <ref> [Put94] </ref>. Before presenting our reduction, let us gain some intuition into why the standard approach fails. <p> As discussed in <ref> [Put94] </ref>, u fl is the least non negative fixpoint of L. The following example illustrates the presence of more than one fixpoint. Example 7.4 Consider the instance of non-negative METC depicted in Figure 7.4. <p> Vector u (2) is the least non-negative fixpoint of L, so that by the arguments discussed in <ref> [Put94] </ref> it is u (2) = u fl . 162 CHAPTER 7. STOCHASTIC SHORTEST PATH AND RELATED PROBLEMS The problem of finding the least non-negative fixpoint of L cannot be solved directly by linear programming.
Reference: [PZ86] <author> A. Pnueli and L. Zuck. </author> <title> Probabilistic verification by tableaux. </title> <booktitle> In Proc. First IEEE Symp. Logic in Comp. Sci., </booktitle> <pages> pages 322-331, </pages> <year> 1986. </year>
Reference: [PZ93] <author> A. Pnueli and L.D. Zuck. </author> <title> Probabilistic verification. </title> <journal> Information and Computation, </journal> <volume> 103 </volume> <pages> 1-29, </pages> <year> 1993. </year>
Reference-contexts: The introduction of fairness in the system model requires the use of updated specification languages and model-checking algorithms, which will be described in this chapter. The subject of fairness in probabilistic systems has been already discussed in the literature. Pnueli [Pnu83] and Pnueli and Zuck <ref> [PZ93] </ref> introduce the notions of extreme fairness and ff-fairness to abstract from the precise values of probabilities. <p> Nonetheless, action a is never chosen at state t, indicating how this definition of compassion fails to capture fully the behavior of probabilistic choice. Extreme Fairness and ff-Fairness To remedy to the situation illustrated by the previous example, Pnueli [Pnu83] and Pnueli and Zuck <ref> [PZ93] </ref> introduce the notions of extreme fairness and ff-fairness. Similar concerns also led to the concept of uniform compassion in Bjtrner, Lerner and Manna [BLM97]. The notion of ff-fairness relies on the use of past temporal logic.
Reference: [QS83] <author> J.P. Queille and J. Sifakis. </author> <title> Fairness and related properties in transition systems | A temporal logic to deal with fairness. </title> <journal> Acta Informatica, </journal> <volume> 19 </volume> <pages> 195-220, </pages> <year> 1983. </year>
Reference-contexts: Finally, we describe the model-checking algorithm for FPTL and FPTL*, followed by its correctness proof. 8.1 An Overview of Fairness The concept of fairness in the context of formal system verification was introduced by Lehmann, Pnueli and Stavi [LPS81] for shared-variables programs, and by Queille and Sifakis <ref> [QS83] </ref> for transition systems. Its traditional uses include the modeling of concurrency and of un-biased arbitration; among the monographs devoted to the study of fairness, we recall Francez [Fra86] and Apt, Francez and Katz [AFK88].
Reference: [Rab63] <author> M.O. Rabin. </author> <title> Probabilistic automata. </title> <journal> Information and Computation, </journal> <volume> 6 </volume> <pages> 230-245, </pages> <year> 1963. </year>
Reference: [Ram80] <author> L. Ramshaw. </author> <title> Formalizing the Analysis of Algorithms. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1980. </year>
Reference: [Rei80] <author> J.H. Reif. </author> <title> Logic for probabilistic programming. </title> <booktitle> In Proc. 12th ACM Symp. Theory of Comp., </booktitle> <pages> pages 8-13, </pages> <year> 1980. </year>
Reference: [Rib95] <author> M. Ribaudo. </author> <title> Stochastic Petri net semantics for stochastic process algebras. </title> <booktitle> In Proc. 6th Int. Workshop on Petri Nets and Performance Models, </booktitle> <pages> pages 148-157. </pages> <publisher> IEEE Comput. Soc. Press, </publisher> <year> 1995. </year>
Reference: [Ros70a] <author> S.M. Ross. </author> <title> Applied Probability Models with Optimization Applications. </title> <publisher> Holden-Day, </publisher> <address> San Francisco, California, </address> <year> 1970. </year>
Reference-contexts: The chapter is concluded with the proof of the equivalence of two optimization criteria for semi-Markov decision processes, and with an algorithm for computing the minimum average cost of semi-Markov processes under a very natural cost structure. These results close a long-standing open problem <ref> [Ros70b, Ros70a] </ref>. 104 CHAPTER 6. VERIFICATION OF LONG-RUN AVERAGE PROPERTIES 6.1 Model-Checking Algorithms for GPTL and GPTL* In this section, we present algorithms to decide whether a TPS satisfies a specification written in GPTL or GPTL*. <p> Semi-Markov decision processes have been described in Jensen [Jen53], Howard [How60, How63], De Cani [DC64], Veinott [Vei69], Ross <ref> [Ros70b, Ros70a] </ref>; we will essentially follow the presentation of Bertsekas [Ber95]. <p> Most of the known results for semi-Markov problems depend on this technique, and thus on assumption (6.37); this includes the results presented in Ross <ref> [Ros70b, Ros70a] </ref>, Puterman [Put94] and Bertsekas [Ber95]. Thus, while we will be able to borrow from the usual development of the subject many concepts and ideas, we will have to follow a different path to get the desired results, and we will have to provide independent proofs of our statements. <p> As for ordinary Markov decision processes, several optimization problems can be formulated for semi-Markov decision processes; among them, the minimization or maximization of total, discounted or average reward. Ross <ref> [Ros70a] </ref> and Bertsekas [Ber95] provide an account of the subject; further references were given in Section 6.6.1. In this section we study the optimization of the average reward of SMDPs. <p> AVERAGE REWARD OF SEMI-MARKOV DECISION PROCESSES 141 The second criterion, based on the sequence fH n g n0 , is semantically sound, but has so far resisted the attempts to formulate optimization methods for it. The problem stated in Ross <ref> [Ros70b, Ros70a] </ref> of proving the equivalence of these two optimization criteria has not been solved so far.
Reference: [Ros70b] <author> S.M. Ross. </author> <title> Average cost semi-Markov decision processes. </title> <journal> J. Appl. Prob., </journal> <volume> 7 </volume> <pages> 649-656, </pages> <year> 1970. </year>
Reference-contexts: The chapter is concluded with the proof of the equivalence of two optimization criteria for semi-Markov decision processes, and with an algorithm for computing the minimum average cost of semi-Markov processes under a very natural cost structure. These results close a long-standing open problem <ref> [Ros70b, Ros70a] </ref>. 104 CHAPTER 6. VERIFICATION OF LONG-RUN AVERAGE PROPERTIES 6.1 Model-Checking Algorithms for GPTL and GPTL* In this section, we present algorithms to decide whether a TPS satisfies a specification written in GPTL or GPTL*. <p> Semi-Markov decision processes have been described in Jensen [Jen53], Howard [How60, How63], De Cani [DC64], Veinott [Vei69], Ross <ref> [Ros70b, Ros70a] </ref>; we will essentially follow the presentation of Bertsekas [Ber95]. <p> Most of the known results for semi-Markov problems depend on this technique, and thus on assumption (6.37); this includes the results presented in Ross <ref> [Ros70b, Ros70a] </ref>, Puterman [Put94] and Bertsekas [Ber95]. Thus, while we will be able to borrow from the usual development of the subject many concepts and ideas, we will have to follow a different path to get the desired results, and we will have to provide independent proofs of our statements. <p> COMPUTING THE MAXIMUM AND MINIMUM VALUES OF J 133 of equations known as the Bellman equations for semi-Markov processes. This approach has been described by Howard [How60], De Cani [DC64], Veinott [Vei69] and Ross <ref> [Ros70b] </ref>; a more recent account is provided by Bertsekas [Ber95, Volume II]. <p> AVERAGE REWARD OF SEMI-MARKOV DECISION PROCESSES 141 The second criterion, based on the sequence fH n g n0 , is semantically sound, but has so far resisted the attempts to formulate optimization methods for it. The problem stated in Ross <ref> [Ros70b, Ros70a] </ref> of proving the equivalence of these two optimization criteria has not been solved so far.
Reference: [Saf88] <author> S. Safra. </author> <title> On the complexity of !-automata. </title> <booktitle> In Proc. 29th IEEE Symp. </booktitle> <institution> Found. of Comp. Sci., </institution> <year> 1988. </year> <note> 220 BIBLIOGRAPHY </note>
Reference: [Saf92] <author> S. Safra. </author> <title> Exponential determinization for !-automata with strong-fairness acceptance condition. </title> <booktitle> In Proc. ACM Symp. Theory of Comp., </booktitle> <pages> pages 275-282, </pages> <year> 1992. </year>
Reference: [Sch71] <author> P.J. Schweitzer. </author> <title> Iterative solution of the functional equations of undiscounted Markov renewal programming. </title> <journal> J. Math. Anal. Appl., </journal> <volume> 34 </volume> <pages> 495-501, </pages> <year> 1971. </year>
Reference-contexts: While Theorem 6.9 appears to be accomplishing such a reduction, the reduction is in fact incomplete. In fact, the traditional analysis of semi-Markov decision problems relies on assumption (6.37), which enables the use of the uniformation technique described by Jensen [Jen53], Howard [How60], Veinott [Vei69] and <ref> [Sch71] </ref> (an account of the technique can also be found in [Ber95]). Most of the known results for semi-Markov problems depend on this technique, and thus on assumption (6.37); this includes the results presented in Ross [Ros70b, Ros70a], Puterman [Put94] and Bertsekas [Ber95].
Reference: [Sch87] <author> A. Schrijver. </author> <title> Theory of Linear and Integer Programming. </title> <editor> J. </editor> <publisher> Wiley & Sons, </publisher> <year> 1987. </year>
Reference: [Seg95a] <author> R. Segala. </author> <title> A compositional trace-based semantics for probabilistic automata. </title> <editor> In Springer-Verlag, editor, CONCUR'95: </editor> <booktitle> Concurrency Theory. 6th Int. Conf., Lect. Notes in Comp. Sci., </booktitle> <pages> pages 234-248, </pages> <year> 1995. </year>
Reference: [Seg95b] <author> R. Segala. </author> <title> Modeling and Verification of Randomized Distributed Real-Time Systems. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <month> June </month> <year> 1995. </year> <note> Technical Report MIT/LCS/TR-676. </note>
Reference-contexts: For these reasons, we adopt in the following a more general approach, due to Segala <ref> [Seg95b] </ref>. This approach is based on the notion of time-divergent policies (called admissible in [Seg95b]): a policy is time divergent if time diverges with probability 1 under it. While the non-Zenoness requirement asks for all policies to be time divergent, the proposal of [Seg95b] is to consider the behavior of the <p> For these reasons, we adopt in the following a more general approach, due to Segala <ref> [Seg95b] </ref>. This approach is based on the notion of time-divergent policies (called admissible in [Seg95b]): a policy is time divergent if time diverges with probability 1 under it. While the non-Zenoness requirement asks for all policies to be time divergent, the proposal of [Seg95b] is to consider the behavior of the system only under time-divergent policies. <p> a more general approach, due to Segala <ref> [Seg95b] </ref>. This approach is based on the notion of time-divergent policies (called admissible in [Seg95b]): a policy is time divergent if time diverges with probability 1 under it. While the non-Zenoness requirement asks for all policies to be time divergent, the proposal of [Seg95b] is to consider the behavior of the system only under time-divergent policies. <p> However, our approach to fairness has already led us to restrict the set of policies under consideration, so that adopting the approach of <ref> [Seg95b] </ref> does not complicate excessively the semantics of the logic or the presentation of the model-checking algorithms. For this reason, in the study of fair TPSs we adopt this approach, and we define time divergent policies as follows. <p> As explained in Chapter 3, this concept provided a characterization of the set of state-action pairs that could be repeated forever along a behavior with positive probability. With the introduction of fairness in the system model and with the adoptions of the approach of <ref> [Seg95b] </ref> to time divergence, we must revise this notion, and introduce admissible end components (AECs). Admissible end components play the same role in the study of fair MDPs as end components in the study of ordinary MDPs; they are defined as follows.
Reference: [Seg96] <author> R. Segala. </author> <title> Testing probabilistic automata. </title> <booktitle> In CONCUR'96: Concurrency Theory. 7th Int. Conf., Lect. Notes in Comp. Sci., </booktitle> <pages> pages 299-314. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference: [SL94] <author> R. Segala and N.A. Lynch. </author> <title> Probabilistic simulations for probabilistic processes. </title> <booktitle> In CONCUR'94: Concurrency Theory. 5th Int. Conf., </booktitle> <volume> volume 836, </volume> <pages> pages 481-496. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference: [SL95] <author> R. Segala and N.A. Lynch. </author> <title> Probabilistic simulations for probabilistic processes. </title> <journal> Nordic Journal of Computing, </journal> <volume> 2(2) </volume> <pages> 250-273, </pages> <year> 1995. </year>
Reference: [SS71] <author> D. Scott and C. Strachey. </author> <title> Towards a mathematical semantics for computer languages. </title> <type> Technical Report PRC6, </type> <institution> Oxford Univ., </institution> <year> 1971. </year>
Reference: [Str66] <author> R.E. Strauch. </author> <title> Negative dynamic programming. </title> <journal> Annals of Math. Stat., </journal> <volume> 37(4), </volume> <year> 1966. </year>
Reference-contexts: In this section, we will describe instead a problem for which the straightforward reduction to linear programming does not work: the non-negative minimum expected total cost (non-negative METC) problem. Strauch <ref> [Str66] </ref> discusses this problem, and Denardo [Den70] proposed reductions to linear programming that finds bias-optimal policies for the METC problem without requiring the non-negativity assumption. The proposal of [Den70] requires the solution of three nested linear programming problems.
Reference: [SV66] <author> R. Strauch and A.F. Veinott. </author> <title> A Property of Sequential Control Processes. </title> <publisher> Rand McNally, </publisher> <address> Chicago, Illinois, USA, </address> <year> 1966. </year>
Reference-contexts: Once the dependency from the initial state is eliminated, to obtain the policy (u) corresponding to u we must somehow "mix" the policies according to (6.33). This "mix" can obtained as indicated by Derman [Der70, Chapter 7, Theorem 1]; see also Derman and Strauch [DS66] and Strauch and Veinott <ref> [SV66] </ref>. Theorem 6.8 (state-action frequencies correspond to policies) For every u 2 U and t 2 S, there is a policy (u) such that u (u) Proof. The result follows from (6.33) and from [Der70, Chapter 7, Theorem 1].
Reference: [Sym80] <author> F.J.W. Symons. </author> <title> Introduction to numerical Petri nets, a general graphical model for concurrent processing systems. </title> <journal> Australian Telecommunications Research, </journal> <volume> 14(1) </volume> <pages> 28-33, </pages> <month> January </month> <year> 1980. </year>
Reference: [Tho90] <author> W. Thomas. </author> <title> Automata on infinite objects. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume B, chapter 4, </booktitle> <pages> pages 135-191. </pages> <publisher> Elsevier Science Publishers (North-Holland), </publisher> <address> Amsterdam, </address> <year> 1990. </year>
Reference-contexts: SPECIFICATION OF LONG-RUN AVERAGE PROPERTIES The model checking of GPTL* formula P ./a involves the construction of the product between the TPS and the deterministic Rabin automaton for or :. Deterministic Rabin automata are strictly more expressive than deterministic Buchi automata (see McNaughton [McN66] and Thomas <ref> [Tho90] </ref>). Nonetheless, for the sake of simplicity we consider an algorithm that computes the product with a deterministic Buchi automaton instead. Such an algorithm can be used for the subclass of formulas that can be encoded as deterministic Buchi automata.
Reference: [Tij86] <author> H.C. Tijms. </author> <title> Stochastic Modelling and Analysis, a Computational Approach. </title> <publisher> Wiley, </publisher> <year> 1986. </year>
Reference: [Var85] <author> M.Y. Vardi. </author> <title> Automatic verification of probabilistic concurrent finite-state systems. </title> <booktitle> In Proc. 26th IEEE Symp. Found. of Comp. Sci., </booktitle> <pages> pages 327-338, </pages> <year> 1985. </year> <note> BIBLIOGRAPHY 221 </note>
Reference-contexts: The subject of fairness in probabilistic systems has been already discussed in the literature. Pnueli [Pnu83] and Pnueli and Zuck [PZ93] introduce the notions of extreme fairness and ff-fairness to abstract from the precise values of probabilities. Hart, Sharir and Pnueli [HSP82] and Vardi <ref> [Var85] </ref> consider probabilistic systems in which the choice of actions at the states is subject to fairness requirements, and present algorithms for checking that temporal logic formulas hold with probability 1 over these systems. <p> According to [KB96], a behavior ! is fair if, whenever a state s appears infinitely often along !, all actions in A (s) also appear infinitely often along !. This notion of fairness has its roots in the state-fairness described in Pnueli [Pnu83] and Vardi <ref> [Var85] </ref>. As mentioned in [KB96], this definition can be easily generalized to the case in which to each state s is associated a set of fair actions F (s).
Reference: [Vei69] <author> A.F. Veinott. </author> <title> On discrete dynamic programming with sensitive discount optimality criteria. </title> <journal> Ann. Math. Stat., </journal> <volume> 40 </volume> <pages> 1635-1660, </pages> <year> 1969. </year>
Reference-contexts: Semi-Markov decision processes have been described in Jensen [Jen53], Howard [How60, How63], De Cani [DC64], Veinott <ref> [Vei69] </ref>, Ross [Ros70b, Ros70a]; we will essentially follow the presentation of Bertsekas [Ber95]. <p> While Theorem 6.9 appears to be accomplishing such a reduction, the reduction is in fact incomplete. In fact, the traditional analysis of semi-Markov decision problems relies on assumption (6.37), which enables the use of the uniformation technique described by Jensen [Jen53], Howard [How60], Veinott <ref> [Vei69] </ref> and [Sch71] (an account of the technique can also be found in [Ber95]). Most of the known results for semi-Markov problems depend on this technique, and thus on assumption (6.37); this includes the results presented in Ross [Ros70b, Ros70a], Puterman [Put94] and Bertsekas [Ber95]. <p> COMPUTING THE MAXIMUM AND MINIMUM VALUES OF J 133 of equations known as the Bellman equations for semi-Markov processes. This approach has been described by Howard [How60], De Cani [DC64], Veinott <ref> [Vei69] </ref> and Ross [Ros70b]; a more recent account is provided by Bertsekas [Ber95, Volume II]. <p> Theorem 6.12 (existence of solutions to the Bellman equations) On a CPB MDP, the equations (BEQ) always have at least one solution. The standard proof of this result relies either on uniformation techniques (see Jensen [Jen53], Howard [How60] and Veinott <ref> [Vei69] </ref>) or on a connection with the stochastic shortest path problem, if all policies are unichain (see Bertsekas [Ber95, Volume II, x 5.3]).
Reference: [vGSST90] <author> R. van Glabbeek, S.A. Smolka, B. Steffen, and C.M.N. Tofts. </author> <title> Reactive, generative, and stratified models of probabilistic processes. </title> <booktitle> In Proc. 5th IEEE Symp. Logic in Comp. Sci., </booktitle> <year> 1990. </year>
Reference: [vGSST95] <author> R. van Glabbeek, S.A. Smolka, B. Steffen, and C.M.N. Tofts. </author> <title> Reactive, generative, and stratified models of probabilistic processes. </title> <journal> Information and Computation, </journal> <volume> 121(1) </volume> <pages> 59-80, </pages> <year> 1995. </year> <note> Preliminary report in LICS'90. </note>
Reference: [VW86] <author> M.Y. Vardi and P. Wolper. </author> <title> An automata-theoretic approach to automatic program verification. </title> <booktitle> In Proc. First IEEE Symp. Logic in Comp. Sci., </booktitle> <pages> pages 332-344, </pages> <year> 1986. </year>
Reference: [Wil91] <author> D. Williams. </author> <title> Probability With Martingales. </title> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: s and H s are not equal, showing that (6.53) is not trivial. 6.8.2 Martingale Property of H A martingale for a stochastic process is a quantity such that its current value is equal to the expectation of its future value; the precise definition can be found, for example, in <ref> [Wil91, KSK66] </ref>. By showing that H is a martingale, we will obtain a relation between the value of H at a state and at the successor states.
Reference: [WL92] <author> Y. Wang and K. Larsen. </author> <title> Testing probabilistic and nondeterministic processes. In Protocol Specification, Testing, and Verification XII, </title> <year> 1992. </year>
Reference: [WSS94] <author> S.-H. Wu, S.A. Smolka, </author> <title> and E.W. Stark. Composition and behaviors of probabilistic I/O automata. </title> <editor> In Springer-Verlag, editor, CONCUR'94: </editor> <booktitle> Concurrency Theory. 5th Int. Conf., Lect. Notes in Comp. Sci., </booktitle> <pages> pages 511-528, </pages> <year> 1994. </year>
Reference: [YCDS94] <author> S. Yuen, R. Cleaveland, Z. Dayar, and S.A. Smolka. </author> <title> Fully abstract characterizations of testing preorders for probabilistic processes. </title> <booktitle> In CONCUR'94: Concurrency Theory. 5th Int. Conf., Lect. Notes in Comp. Sci., </booktitle> <pages> pages 497-512. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
References-found: 144

