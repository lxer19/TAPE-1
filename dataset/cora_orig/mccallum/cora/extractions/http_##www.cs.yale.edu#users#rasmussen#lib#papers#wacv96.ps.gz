URL: http://www.cs.yale.edu/users/rasmussen/lib/papers/wacv96.ps.gz
Refering-URL: http://www.cs.yale.edu/users/rasmussen/research.html
Root-URL: http://www.cs.yale.edu
Email: rasmuss@powered.cs.yale.edu, toyama@cs.yale.edu, hager@cs.yale.edu  
Title: Tracking Objects By Color Alone  
Author: Christopher Rasmussen, Kentaro Toyama, and Gregory D. Hager 
Address: 51 Prospect Street New Haven, CT 06520-8285  
Affiliation: Department of Computer Science Yale University  
Abstract: This paper discusses a simple approach to tracking objects based solely on their color. By limiting our attention to areas of approximately uniform color on nearly Lamber-tian surfaces, we can assume that pixels corresponding to surface patches on the object form a linear, tubular distribution in color space. Performing principal component analysis on user-selected sample pixels parametrizes an ellipsoidal model of this distribution. The shape thus derived defines a static membership function that can be used to quickly and robustly track many objects through a range of orientations and scales, with varying levels of illumination, and in front of complex backgrounds. In combination with a loss recovery procedure, the basic technique has been successfully applied to tasks as diverse as head and hand tracking, following juggled and thrown balls, and constructing vision-based input devices. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Allen, A. Timcenko, B. Yoshimi, and P. Michelman. </author> <title> Automated Tracking and Grasping of a Moving Object with a Robotic Hand-Eye System. </title> <journal> In IEEE Trans. Robotics and Automation, </journal> <volume> Vol. 9, No. 2, </volume> <pages> pp. 152-165, </pages> <year> 1993. </year>
Reference-contexts: This has led to it becoming the preferred method of performing tracking in many practical applications. In the past, blob tracking was largely implemented on gray-scale images using thresholding or simple functions of gray-scale value <ref> [1, 2, 4, 11] </ref>. These techniques usually relied on a structured environment (a black backdrop) so that the target (a white ping-pong ball) was unique. With the advent of inexpensive color cameras and digitizers, it seems likely that color-based thresholding techniques will provide a practical and robust alternative.
Reference: [2] <author> R. Andersson. </author> <title> Understanding and Applying a Robot Ping-Pong Player's Expert Controller. </title> <booktitle> In ICRA, </booktitle> <pages> pp. 1284-1289, </pages> <year> 1989. </year>
Reference-contexts: This has led to it becoming the preferred method of performing tracking in many practical applications. In the past, blob tracking was largely implemented on gray-scale images using thresholding or simple functions of gray-scale value <ref> [1, 2, 4, 11] </ref>. These techniques usually relied on a structured environment (a black backdrop) so that the target (a white ping-pong ball) was unique. With the advent of inexpensive color cameras and digitizers, it seems likely that color-based thresholding techniques will provide a practical and robust alternative. <p> The juggling robot of [11] and the ping-pong playing robot of <ref> [2] </ref>, for example, require a well-illuminated white ball and a black background for accurate segmentation. This limits the robots to performing only in specially-constructed workspaces with fixed camera views that minimize distraction.
Reference: [3] <author> M. Black and A. Jepson. EigenTracking: </author> <title> Robust Matching and Tracking of Articulated Objects Using a View-Based Representation. </title> <booktitle> In ECCV, </booktitle> <pages> pp. 329-342, </pages> <year> 1996. </year>
Reference-contexts: These situations occur infrequently enough that such hybrid tracking would still be much faster than geometry alone while adding robustness. Geometry is prone to the problems (multiple object orientations and scales) that we are avoiding by using just color, of course, but some work has been done on this <ref> [3, 9] </ref>. Despite its limitations, the ellipsoidal color tracking scheme that we have presented has wide applicability. It is especially notable for its high speed and insensitivity to gross scaling, rotations, or other geometric distortions of the tracked object.
Reference: [4] <author> P. Corke. </author> <title> Visual Servoing. In Visual Control of Robot Manipulators A Review, </title> <editor> K. Hashimoto, ed., </editor> <publisher> World Scientific, </publisher> <year> 1993. </year>
Reference-contexts: This has led to it becoming the preferred method of performing tracking in many practical applications. In the past, blob tracking was largely implemented on gray-scale images using thresholding or simple functions of gray-scale value <ref> [1, 2, 4, 11] </ref>. These techniques usually relied on a structured environment (a black backdrop) so that the target (a white ping-pong ball) was unique. With the advent of inexpensive color cameras and digitizers, it seems likely that color-based thresholding techniques will provide a practical and robust alternative.
Reference: [5] <author> Y. Du and J. Crisman. </author> <title> A Color Projection for Fast Generic Target Tracking. </title> <booktitle> In IROS, </booktitle> <pages> pp. 360-365, </pages> <year> 1995. </year>
Reference-contexts: With the advent of inexpensive color cameras and digitizers, it seems likely that color-based thresholding techniques will provide a practical and robust alternative. To date, little has been published on practical color tracking algorithms. A simple color tracking technique is presented in Du and Crisman <ref> [5] </ref>. They pick a set of arbitrary "categorical" colors in RGB space and construct membership volumes for each one based on nearest neighbor calculation. Objects are characterized by their histograms over these volumes, permitting multi-colored regions to be tracked.
Reference: [6] <author> G. Hager. </author> <title> The `X-Vision' System: A General-Purpose Substrate for Vision-Based Robotics. </title> <booktitle> In Workshop on Vision for Robotics, </booktitle> <year> 1995. </year>
Reference-contexts: In this paper, we describe a general-purpose technique for color blob tracking within the XVision real-time vision software package <ref> [6] </ref>. The primary attributes of our approach are that it does not rely on a static camera, it uses an empirical sampling of the color space and a physically plausible model of color variation, and it exhibits fast performance on standard workstations.
Reference: [7] <author> R. Kahn, M. Swain, P. Prokopowicz, and R. Firby. </author> <title> Gesture Recognition Using the Perseus Architecture. </title> <note> To appear in CVPR, </note> <year> 1996. </year>
Reference-contexts: Objects are characterized by their histograms over these volumes, permitting multi-colored regions to be tracked. It is unclear what update function they use to determine where to move the tracking window, and all of their results are based only on synthetic, abstract image sequences. Pfinder [16] and Perseus <ref> [7] </ref> are specialized systems for tracking people. Pfinder uses a statistical characterization of color variation in a static image to perform color-based change detection; Perseus uses color histograms. Prior terms on flesh color assist the systems in automatically finding skin and "bootstrapping" a model whenever someone appears in the scene.
Reference: [8] <author> G. Klinker, S. Shafer, and T. Kanade. </author> <title> A Physical Approach to Color Image Understanding. </title> <journal> Int. Journal of Computer Vision, </journal> <volume> Vol. 4, </volume> <pages> pp. 7-38, </pages> <year> 1990. </year>
Reference-contexts: It is acceptable to be conservative and only classify part of the object as the object, as long as a large enough fraction is found to be distinguishable from noise. The theoretical basis for our segmentation algorithm is given by Klinker et al. <ref> [8] </ref>. They present a thorough analysis of the physics of object color properties in the context of an off-line approach to segmenting unknown colors in a scene.
Reference: [9] <author> H. Murase and S. Nayar. </author> <title> Visual Learning and Recognition of 3-D Objects from Appearance. </title> <journal> Int. Journal of Computer Vision, </journal> <volume> Vol. 14, </volume> <pages> pp. 5-24, </pages> <year> 1995. </year>
Reference-contexts: These situations occur infrequently enough that such hybrid tracking would still be much faster than geometry alone while adding robustness. Geometry is prone to the problems (multiple object orientations and scales) that we are avoiding by using just color, of course, but some work has been done on this <ref> [3, 9] </ref>. Despite its limitations, the ellipsoidal color tracking scheme that we have presented has wide applicability. It is especially notable for its high speed and insensitivity to gross scaling, rotations, or other geometric distortions of the tracked object.
Reference: [10] <author> E. Oja. </author> <title> Subspace Methods of Pattern Recognition, </title> <publisher> Research Studies Press, </publisher> <year> 1983. </year>
Reference-contexts: However, by choosing objects with minimal specularity or choosing color sample locations on them away from specularities, we have found that a single tubal cluster often captures color variation very well. We model this cluster by finding the principal components <ref> [10] </ref> of the sample color distribution's co-variance matrix. The results give the tracker a bounding ellipsoid for determining pixel membership in the object. This approach can easily be extended to handle objects composed of multiple uniform color patches.
Reference: [11] <author> A. Rizzi, L. Whitcomb, and D. Koditschek. </author> <title> Distributed Real-Time Control of a Spatial Robot Juggler. </title> <journal> IEEE Computer, </journal> <volume> Vol. 25, No. 5, </volume> <pages> pp. 12-23, </pages> <month> May, </month> <year> 1992. </year>
Reference-contexts: This has led to it becoming the preferred method of performing tracking in many practical applications. In the past, blob tracking was largely implemented on gray-scale images using thresholding or simple functions of gray-scale value <ref> [1, 2, 4, 11] </ref>. These techniques usually relied on a structured environment (a black backdrop) so that the target (a white ping-pong ball) was unique. With the advent of inexpensive color cameras and digitizers, it seems likely that color-based thresholding techniques will provide a practical and robust alternative. <p> The juggling robot of <ref> [11] </ref> and the ping-pong playing robot of [2], for example, require a well-illuminated white ball and a black background for accurate segmentation. This limits the robots to performing only in specially-constructed workspaces with fixed camera views that minimize distraction.
Reference: [12] <author> J. Shi and C. Tomasi. </author> <title> Good Features to Track. </title> <booktitle> In CVPR, </booktitle> <pages> pp. 593-600, </pages> <year> 1994. </year>
Reference-contexts: No explicit information about object scale or orientation is generated as a by-product of the update cycle, as is the case with many correlation-based methods <ref> [12] </ref>. An approximation to such information can in (a) (b) tracked as it and a blue ball are juggled.
Reference: [13] <author> D. Terzopoulos and T. Rabie. </author> <title> Animat Vision: </title> <booktitle> Active Vision in Artificial Animals. In ICCV, </booktitle> <pages> pp. 801-808, </pages> <year> 1995. </year>
Reference-contexts: When the image dimensions of an object's support shrink enough to be severely affected by aliasing resulting from subsampling, track is lost before it would be at full resolution. A fovea-like multiple resolution model <ref> [13] </ref> offers a compromise between efficient computation and accurate object localization. By decreasing sampling resolution away from the center of the tracking window, many fewer pixels can be tested for color membership per update while maintaining tracking accuracy.
Reference: [14] <author> K. Toyama and G. Hager. </author> <title> Incremental Focus of Attention for Robust Visual Tracking. </title> <note> To appear in CVPR, </note> <year> 1996. </year>
Reference-contexts: Distraction, or the mistracking of non-object pixels satisfying M, may also occur, but is not readily detectable with no other discrimination criteria. When lost from object speed or occlusion, though, a tracker can often recover by resampling the entire image at a lower resolution and performing a global search <ref> [14] </ref>. Using 8 x 8 subsampling, a global search incurs about 5 times the computation of a normal tracking cycle. Though this causes the update rate to dip, we have found this to be a rare and therefore acceptable cost.
Reference: [15] <author> J. Tsotsos, S. Culhane, W. Wai, Y. Lai, N. Davis, F. Nuflo. </author> <title> Modeling Visual-Attention Via Selective Tuning. </title> <journal> AI, </journal> <volume> Vol. 78, No. </volume> <pages> 1-2, pp. 507-545, </pages> <month> October, </month> <year> 1995. </year>
Reference-contexts: As input to higher level processes, a geometry-less color tracker is probably best suited to being an attentional mechanism <ref> [15] </ref> that suggests where to perform more sophisticated analyses.
Reference: [16] <author> C. Wren, A. Azarbayejani, T. Darrell, and A. Pentland. Pfinder: </author> <title> Real-Time Tracking of the Human Body. </title> <booktitle> In SPIE, </booktitle> <volume> Vol. 2615, </volume> <year> 1995. </year>
Reference-contexts: Objects are characterized by their histograms over these volumes, permitting multi-colored regions to be tracked. It is unclear what update function they use to determine where to move the tracking window, and all of their results are based only on synthetic, abstract image sequences. Pfinder <ref> [16] </ref> and Perseus [7] are specialized systems for tracking people. Pfinder uses a statistical characterization of color variation in a static image to perform color-based change detection; Perseus uses color histograms. <p> Those pixels which match the model are interpreted as belonging to the object and are called its support after <ref> [16] </ref>; the tracking window is repositioned to be centered on them. 3.1 Initialization Initial information about the object is supplied to the tracker through human agency. <p> his or her arm, and the puck's tendency to slide out of view briefly at the bottom of the playing area, tracking is robust and accurate. 4.3 Face Tracking Our technique also works well for tracking faces in many indoor lighting situations, both from fixed and mobile camera platforms (Pfinder <ref> [16] </ref> does not allow camera movement). We have had good results with mounting the camera on a pan-tilt unit, allowing a tracker to follow the subject's face over a wide range of positions, as shown in Figure 4. <p> It may be possible, however, to adapt the color model, or "track" the ellipsoid in color space, to maintain a best fit at all times <ref> [16] </ref>. This would be difficult because shadows can cause discontinuities in the incident light mixture. Finally, it is important to remember that although we are calling the things being tracked "objects," they are really nothing more than patches of color.
References-found: 16

