URL: http://www.cs.uoregon.edu/~mohr/vita/tr9514.ps.gz
Refering-URL: http://www.cs.uoregon.edu/~mohr/vita/vita-e.html
Root-URL: http://www.cs.uoregon.edu
Email: -kesavans,malony,mohr-@cs.uoregon.edu  
Title: Performance Extrapolation of Parallel Programs  
Author: Kesavan Shanmugam, Allen D. Malony, Bernd Mohr 
Keyword: performance prediction, extrapolation, object-parallel programming, trace driven simulation, performance debugging tools, and modeling.  
Address: OR 97403, USA  
Affiliation: Department of Computer and Information Science, University of Oregon, Eugene  
Abstract: Performance Extrapolation is the process of evaluating the performance of a parallel program in a target execution environment using performance information obtained for the same program in a different execution environment. Performance extrapolation techniques are suited for rapid performance tuning of parallel programs, particularly when the target environment is unavailable. This paper describes one such technique that was developed for data-parallel C++ programs written in the pC++ language. The technique uses high-level event tracing of a n-thread pC++ program run on a uniprocessor machine together with trace-driven simulation to predict the performance of the program run on an n-processor machine. Our results show that even with high-level events, performance extrapolation techniques are effective in isolating critical factors affecting a programs performance and for evaluating the inuence of architectural and system parameters. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. Bodin, P. Beckman, D. Gannon, S. Yang, S. Kesavan, A. Malony, B. Mohr, </author> <title> Implementing a Parallel C++ Runtime System for Scalable Parallel Systems, </title> <booktitle> Proc. Supercomputing 93, IEEE Computer Society and ACM SIGARCH, </booktitle> <pages> pages 588-597, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: The runtime system provides facilities for creating the threads, synchronizing the threads using a barrier and for accessing remote elements <ref> [1] </ref>. One of the important things to notice about pC++ is that currently it does not provide protected accesses to remote elements. Though this will change in the future, we must point out that this particular characteristic of pC++ has made our extrapolation technique simpler. <p> In particular, we notice that for Grid and Mgrid speedup levels off after four processors, a result that was different from what we have observed on several shared memory parallel platforms <ref> [1] </ref>, where speedups greater than 14 for 32 processors are achieved. This is not too surprising, given that we used a distributed memory parameter set. However, we were curious about the cause. We selected the Grid benchmark for further study; the performance results are shown in Figure 5.
Reference: [2] <author> Z. Bozkus et al., </author> <title> Compiling Distribution Directives in a Fortran 90D Compiler, </title> <type> Technical Report SCCS-388, </type> <institution> Northeast Parallel Architectures Center, </institution> <month> July </month> <year> 1992. </year>
Reference: [3] <author> E. A. Brewer, C. N. Dellarocas, A. Colbrook, W. E. Weihl, Proteus: </author> <title> A High Performance Parallel Architecture Simulator, </title> <type> Technical Report MIT/LCS/TR-516, </type> <institution> MIT Laboratory of Computer Science, </institution> <month> September </month> <year> 1991. </year>
Reference: [4] <author> E. A. Brewer, W. E. Weihl, </author> <title> Developing Parallel Applications Using High-Performance Simulation, </title> <booktitle> Proc. ACM/ONR Workshop on Parallel and Distributed Debugging, </booktitle> <pages> pages 158-168, </pages> <month> May </month> <year> 1993. </year> <title> m n 16 </title>
Reference: [5] <author> M. E. Crovella and T. J. LeBlanc, </author> <title> Parallel Performance Prediction Using Lost Cycles Analysis, </title> <booktitle> Proc. Super computing 94, IEEE Computer Society and ACM, </booktitle> <pages> pages 600-609, </pages> <month> November </month> <year> 1994. </year>
Reference: [6] <author> P. Dickens, P. Heidelberger and D. Nicol, </author> <title> Parallelized Direct Execution Simulation of Message Passing Parallel Programs, </title> <type> Technical Report ICASE/94/94-50, </type> <institution> Institute for Computer Applications in Science and Engi neering, NASA Langley, </institution> <year> 1994. </year>
Reference: [7] <author> T. Fahringer, </author> <title> Automatic Performance Prediction for Parallel Programs on Massively Parallel Computers, </title> <type> Ph.D. Thesis, </type> <institution> University of Vienna, </institution> <month> September </month> <year> 1993. </year>
Reference: [8] <author> D. Gannon, F. Bodin, S. Srinivas, N. Sundaresan and S. Narayana, Sage++, </author> <title> An Object Oriented Toolkit for Program Transformations, </title> <type> Technical Report, </type> <institution> Department of Computer Science, Indiana University, </institution> <year> 1993. </year>
Reference: [9] <author> D. Gannon and J. K. Lee, </author> <title> Object Oriented Parallelism: pC++ Ideas and Experiments, </title> <booktitle> Proc. Japan Society of Parallel Processing, </booktitle> <pages> pages 13-23, </pages> <year> 1991. </year>
Reference: [10] <author> D. C. Grunwald, </author> <title> A Users Guide to AWESIME: An Object Oriented Parallel Programming and Simulation System, </title> <type> Technical Report 552-91, </type> <institution> Department of Computer Science, University of Colorado at Boulder, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: is discussed further in Section 5. 3.2 Instrumentation and Trace Translation For the purposes of our performance extrapolation work, we modified the pC++ runtime system so that all n threads of a parallel program are executed on a single processor (in a virtual parallel manner) using a non-preemptive threads package <ref> [10] </ref>. The elements of a collection are allocated in a global space accessible by all the threads. When a thread requires access to a remote element, it gets it directly from the global space.
Reference: [11] <author> R. Helm, A. D. Malony and S. F. Fickas, </author> <title> Capturing and Automating Performance Diagnosis: The Poirot Approach, </title> <booktitle> Proc. International Parallel Processing Symposium </booktitle>
Reference-contexts: The most common motivation for developing high-performing programs is that parallel machines are expensive resources that must be utilized to their maximum potential to justify their costs. However, the process of performance debugging (the iterative application of performance diagnosis <ref> [11] </ref> and tuning) invariably requires access to the target parallel platform, since the majority of the parallel performance tools are based on the measurement and analysis of actual program execution.
Reference: [12] <author> High Performance Fortran Forum, </author> <title> High Performance Fortran Language Specification version 1.0, TR92225, Center for Research on Parallel Computation, </title> <institution> Rice University, </institution> <month> January </month> <year> 1993. </year>
Reference: [13] <author> T. T. Kwan, B. K. Totty and D. A. Reed, </author> <title> Communication and Computation Performance of the CM-5, </title> <booktitle> Proc. Supercomputing 93, IEEE Computer Society and ACM SIGARCH, </booktitle> <pages> pages 192-201, </pages> <month> November </month> <year> 1993. </year>
Reference: [14] <author> A. D. Malony, </author> <title> Event-Based Performance Perturbation: A Case Study, </title> <booktitle> Proc. ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <year> 1991. </year>
Reference-contexts: For instance, the analysis to derive a performance metric must often take into account the uncertainty in performance information and its effect on the accuracy of the metric. The work on perturbation analysis <ref> [14] </ref> is an example of how performance measurement intrusion issues can be addressed during post-mortem program trace analysis. Sometimes problems of performance information accuracy can be dealt with by deriving performance metrics in vivo of a system, as in direct execution simulation [6,18].
Reference: [15] <author> A. D. Malony, V. Mertsiotakis and A. </author> <title> Quick, Automatic Scalability Analysis of Parallel Programs Based on Modeling Techniques, Computer Performance Evaluation - Modelling Techniques and Tools, </title> <booktitle> Lecture Notes in Computer Science 794, </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pages 139-158, </pages> <year> 1994. </year>
Reference: [16] <author> A. D. Malony, B. Mohr, P. Beckman, D. Gannon, S. Yang, F. Bodin, </author> <title> Performance Analysis of pC++: A Portable Data-Parallel Programming System for Scalable Parallel Computers, </title> <booktitle> Proc. IPPS International Parallel Pro cessing Symposium, </booktitle> <pages> pages 75-85, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: The message transfer time will contribute to the barrier time. 0 - do not use actual messages for barrier synchronization. 1 BarrierMsgSize Size of a message used for barrier synchronization. 128 TABLE 1. Parameters for the Barrier Model 9 important component <ref> [16] </ref>. Second, we wanted to verify that modifying simulation parameters of interest resulted in observable and expected effects in extrapolated benchmark performance behavior.
Reference: [17] <institution> On-line information on CM-5, </institution> <type> CM-5 Technical Summary, </type> <address> http://www.think.com/Prod-Serv/Products/ cmmd.html, </address> <month> November </month> <year> 1992. </year>
Reference: [18] <author> D. K. Poulsen and P. C. Yew, </author> <title> Execution-Driven Tools for Parallel Simulation of Parallel Architectures and Applications, </title> <booktitle> Proc. Supercomputing 93, IEEE Computer Society and ACM SIGARCH, </booktitle> <pages> pages 860-869, </pages> <month> November </month> <year> 1993. </year>
Reference: [19] <author> S. K. Reinhardt, M. D. Hill, J. R. Larus, A. R. Lebeck, J. C. Lewis and D. A. Wood, </author> <title> The Wisconsin Wind Tunnel: Virtual Prototyping of Parallel Computers, </title> <booktitle> Proc. ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 48-60, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Although the work on the Proteus system [3,4] and the Wisconsin Wind Tunnel <ref> [19] </ref> has considerably advanced the efficiency and effectiveness of these dynamic techniques for architectural studies, the overheads are prohibitively high to warrant their use for rapid and interactive performance debugging.
Reference: [20] <author> K. Shanmugam, </author> <title> Performance Extrapolation of Parallel Programs, </title> <type> Masters Thesis, </type> <institution> Department of Computer and Information Science, University of Oregon, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: Aside from the operational aspects of the sub-models, the remote access performance estimates produced in the pC++ extrapolation are mostly analytical; a full description of the performance equations is given in <ref> [20] </ref>. However, modeling contention requires time-based state analysis. That is, the contention models we developed include parameters based on the intensity of concurrent use of shared system resources (e.g., the interconnection network) FIGURE 3. Remote Data Access Model Interconnect. Network Processor Model Runtime Sys. <p> The ability to extrapolate target system parameters such as processor speed and communication start-up and to see such performance effects is important when what if questions are posed, especially about systems that do not physically exist. The last experiment with the benchmarks that we report here (see <ref> [20] </ref> for more results) demonstrate ExtraPs ability to simulate different runtime system policies for servicing remote data accesses. Two policies are supported in the actual pC++ system: polling and interrupt.
Reference: [21] <author> H. Wabnig and G. Haring, </author> <title> PAPS - The Parallel Program Performance Prediction Toolset, Computer Performance Evaluation - Modelling Techniques and Tools, </title> <booktitle> Lecture Notes in Computer Science 794, Springer-Ver lag, </booktitle> <pages> pages 284-304, </pages> <year> 1994. </year>
Reference-contexts: In this manner, the environment would enable performance-driven parallel program design where algorithm choices could be considered early in the development process <ref> [21] </ref>. Two main performance evaluation directions have been pursued to approximate this ideal situation. Static performance prediction techniques use statistical performance models of a program which are evaluated analytically or through simulation.
References-found: 21

