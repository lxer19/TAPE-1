URL: ftp://ftp.cs.toronto.edu/pub/tap/plate.nips93.ps.Z
Refering-URL: http://www.cs.utoronto.ca/~tap/
Root-URL: 
Email: email: tap@ai.utoronto.ca  
Title: In  Estimating analogical similarity by dot-products of Holographic Reduced Representations.  
Author: J. D. Cowan, G. Tesauro, and J. Tony A. Plate 
Affiliation: Department of Computer Science, University of Toronto  
Date: 1994  
Address: San Mateo, CA,  Toronto, Ontario, Canada M5S 1A4  
Note: Alspector, editors, Advances in Neural Information Processing Systems 6 (NIPS*93), Morgan Kaufmann,  HRRs are discussed.  
Abstract: Models of analog retrieval require a computationally cheap method of estimating similarity between a probe and the candidates in a large pool of memory items. The vector dot-product operation would be ideal for this purpose if it were possible to encode complex structures as vector representations in such a way that the superficial similarity of vector representations reflected underlying structural similarity. This paper describes how such an encoding is provided by Holographic Reduced Representations (HRRs), which are a method for encoding nested relational structures as fixed-width distributed representations. The conditions under which structural similarity is reflected in the dot-product rankings of 
Abstract-found: 1
Intro-found: 1
Reference: <author> Falkenhainer, B., Forbus, K. D., and Gentner, D. </author> <year> (1989). </year> <title> The Structure-Mapping Engine: Algorithm and examples. </title> <journal> Artificial Intelligence, </journal> <volume> 41 </volume> <pages> 1-63. </pages>
Reference-contexts: A threshold is used to select likely analogies. It would give E1 (LS), E2 (AN cm ), and E6 (SS) equal and highest scores, i.e., (LS; AN cm ; SS) &gt; (AN; FA) The Structure Mapping Engine (SME) <ref> (Falkenhainer, Forbus and Gentner, 1989) </ref> is used as the second stage of MAC/FAC (the Few Are Chosen stage). The rules of SME are that mapped relations must match, all the arguments of mapped relations must be mapped consistently, and mapping of objects must be one-to-one.
Reference: <author> Gentner, D. and Forbus, K. D. </author> <year> (1991). </year> <title> MAC/FAC: A model of similarity-based retrieval. </title> <booktitle> In Proceedings of the Thirteenth Annual Cognitive Science Society Conference, </booktitle> <pages> pages 504-509, </pages> <address> Hillsdale, NJ. </address> <publisher> Erlbaum. </publisher>
Reference-contexts: A subject is shown a number of stories and later is shown a probe story. The task is to recall stories that are similar to the probe story (and sometimes evaluate the degree of similarity and perform analogical reasoning). MAC/FAC, a computer models of this process, has two stages <ref> (Gentner and Forbus, 1991) </ref>. The first stage selects a few likely analogs from a large number of potential analogs. The second stage searches for an optimal (or at least good) mapping between each selected story and the probe story and outputs those with the best mappings.
Reference: <author> Gentner, D. and Markman, A. B. </author> <year> (1992). </year> <title> Analogy Watershed or Waterloo? Structural alignment and the development of connectionist models of analogy. </title> <editor> In Giles, C. L., Hanson, S. J., and Cowan, J. D., editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5 (NIPS*92), </booktitle> <pages> pages 855-862, </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Gentner, D., Rattermann, M. J., and Forbus, K. D. </author> <year> (1993). </year> <title> The roles of similarity in transfer: Separating retrievability from inferential soundness. </title> <journal> Cognitive Psychology, </journal> <volume> 25 </volume> <pages> 431-467. </pages>
Reference-contexts: Cheap filtering process based on surface features Expensive selection process based on structural features ProbeLarge pool of items in memory Potential analogies Good analogies While it is indisputable that people take structural correspondences into account when evaluating and using analogies <ref> (Gentner, Rattermann and Forbus, 1993) </ref>, it is less certain whether structural similarity influences access to long term memory (i.e., the first-stage reminding process).
Reference: <author> Hummel, J. E. and Biederman, I. </author> <year> (1992). </year> <title> Dynamic binding in a neural network for shape recognition. </title> <journal> Psychological Review, </journal> <volume> 99(3) </volume> <pages> 480-517. </pages>
Reference: <author> Markman, A. B., Gentner, D., and Wisniewski, E. J. </author> <year> (1993). </year> <title> Comparison and cognition: Implications of structure-sensitive processing for connectionist models. </title> <type> Unpublished manuscript. </type>
Reference: <author> Plate, T. A. </author> <year> (1991). </year> <title> Holographic Reduced Representations: Convolution algebra for compositional distributed representations. </title> <editor> In Mylopoulos, J. and Reiter, R., editors, </editor> <booktitle> Proceedings of the 12th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 30-35, </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Plate, T. A. </author> <year> (1993). </year> <title> Estimating analogical similarity by vector dot-products of Holographic Reduced Representations. </title> <type> Unpublished manuscript. </type>
Reference: <author> Plate, T. A. </author> <year> (1994). </year> <title> Holographic reduced representations. </title> <journal> IEEE Transactions on Neural Networks. </journal> <note> To appear. </note>
Reference-contexts: The elements of the circular convolution of x and y are the sums of the outer product elements along the wrapped diagonal lines. Holographic Reduced Representations (HRRs) <ref> (Plate, 1994) </ref> use circular convolution to solve the binding problem. Circular convolution (Figure 2a) is an operation that maps two n-dimensional vectors onto one n-dimensional vector. It can be viewed as a compressed outer product, as shown in Figure 2b.
Reference: <author> Smolensky, P. </author> <year> (1990). </year> <title> Tensor product variable binding and the representation of symbolic structures in connectionist systems. </title> <journal> Artificial Intelligence, 46(1-2):159-216. </journal>
Reference-contexts: Similar items can be represented by similar vectors. (b) Items are represented in a continuous space. (c) Information is distributed and redundant. Hummel and Biederman (1992) discussed the binding problem and identified two main problems faced by conjunctive coding approaches such as Tensor Products <ref> (Smolensky, 1990) </ref>. These are exponential growth of the size of the representation with the number of associated objects (or attributes), and insensitivity to attribute structure. HRRs have much in common with conjunctive coding approaches (they can be viewed as a compressed conjunctive code), but do not suffer from these problems.
Reference: <author> Thagard, P., Holyoak, K. J., Nelson, G., and Gochfeld, D. </author> <year> (1990). </year> <title> Analog Retrieval by Constraint Satisfaction. </title> <journal> Artificial Intelligence, </journal> <volume> 46 </volume> <pages> 259-310. </pages>
Reference-contexts: To test how well the HRR dot-product works as an estimate of analogical similarity between nested relational structures I used the following set of simple episodes (see Plate (1993) for the full set). The memorized episodes are similar in different ways to the probe. These examples are adapted from <ref> (Thagard et al., 1990) </ref>. Probe: Spot bit Jane, causing Jane to flee from Spot. Episodes in long-term memory: E1 (LS) Fido bit John, causing John to flee from Fido. E2 (AN cm ) Fred bit Rover, causing Rover to flee from Fred.
Reference: <author> Wharton, C. M., Holyoak, K. J., Downing, P. E., Lange, T. E., Wickens, T. D., and Melz, E. R. </author> <year> (1994). </year> <title> Below the surface: Analogical similarity and retrieval competition in reminding. </title> <journal> Cognitive Psychology. </journal> <note> To appear. 1116 </note>
Reference-contexts: Some studies have found little effect of analogical similarity on reminding (Gentner and Forbus, 1991; Gentner, Rattermann and Forbus, 1993), while others have found some effect <ref> (Wharton et al., 1994) </ref>. 1 Surface features of stories are the features of the entities and relations involved, and structural features are the relationships among the relations and entities. 1110 In any case, surface features appear to influence the likelihood of a reminding far more than do structural features.
References-found: 12

