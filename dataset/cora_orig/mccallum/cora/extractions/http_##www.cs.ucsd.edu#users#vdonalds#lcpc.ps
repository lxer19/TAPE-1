URL: http://www.cs.ucsd.edu/users/vdonalds/lcpc.ps
Refering-URL: http://www.cs.ucsd.edu/users/vdonalds/
Root-URL: http://www.cs.ucsd.edu
Email: fvdonalds,ferranteg@cs.ucsd.edu  
Title: Determining Asynchronous Pipeline Execution Times  
Author: Val Donaldson and Jeanne Ferrante 
Date: August 1996  
Address: San Jose, CA,  La Jolla, California 92093-0114  
Affiliation: Computing,  Computer Science and Engineering Department University of California, San Diego  
Note: Proc. Ninth Workshop on Languages and Compilers for Parallel  
Abstract: Asynchronous pipelining is a form of parallelism in which processors execute different loop tasks (loop statements) as opposed to different loop iterations. An asynchronous pipeline schedule for a loop is an assignment of loop tasks to processors, plus an order on instances of tasks assigned to the same processor. This variant of pipelining is particularly relevant in distributed memory systems (since pipeline control may be distributed across processors), but may also be used in shared memory systems. Accurate estimation of the execution time of a pipeline schedule is needed to determine if pipelining is appropriate for a loop, and to compare alternative schedules. Pipeline execution of n iterations of a loop requires time at most a + bn, for some constants a and b. The coefficient b is the iteration interval of the pipeline schedule, and is the primary measure of the performance of a schedule. The startup time a is a secondary performance measure. We generalize previous work on determining if a pipeline schedule will deadlock, and generalize Reiter's well-known formula [19] for determining the iteration interval b of a deadlock-free schedule, to account for nonzero communication times (easy) and the assignment of multiple tasks to processors (nontrivial). Two key components of our generalization are the use of pipeline scheduling edges, and the notion of negative data dependence distances (in a single unnested loop). We also discuss implementation of an asynchronous pipeline schedule at runtime; derive bounds on the startup time a; and discuss evaluation of the iteration interval formula, including development of a new algorithm.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alexander Aiken and Alexandru Nicolau. </author> <title> Optimal loop parallelization. </title> <booktitle> Proc. SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <address> Atlanta, GA, </address> <month> June </month> <year> 1988, </year> <pages> pp. 308-317. </pages>
Reference-contexts: Under the broad umbrella of pipeline parallelism, there are a number of variants which make different assumptions, or focus on different aspects of the computation which is being pipelined. Examples include instruction and vector pipelining in hardware [12], and software pipelining on sequential, VLIW, or superscalar processors <ref> [1, 14] </ref>. Our focus is on a form of pipelining which we call asynchronous pipelining, where application program loops are pipelined on multiprocessors or multicomputers, and pipeline tasks are scheduled as soon as processor and data resources are available. <p> We use this sequence specification to add scheduling edges to G as follows. For each i 2 <ref> [1; k 1] </ref>, create a scheduling edge (X i ; X i+1 ), with (X i ; X i+1 ):dist = s i s i+1 .
Reference: [2] <author> Sati Banerjee, Takeo Hamada, Paul M. Chau, and Ronald D. Fellman. </author> <title> Macro pipelining based scheduling on high performance heterogeneous multiprocessor systems. </title> <journal> IEEE Transactions on Signal Processing 43:8 (June 1995), </journal> <pages> pp. 1468-1484. </pages>
Reference-contexts: This form of pipelining has been studied particularly in the context of digital signal processing algorithms <ref> [2, 10] </ref>, although it has been considered in other contexts as well [21]. Tasks may be of arbitrary size, from simple statements to complex compound statements or subroutine calls. <p> The term a is the startup time of the schedule, and is a secondary performance measure. Previous asynchronous pipeline scheduling algorithms targeting distributed memory systems <ref> [2, 10, 21] </ref> use conservative estimates of the pipeline iteration interval as their performance measure, derived in part from Reiter's well-known iteration interval formula [19]. Reiter's formula assumes that intertask communication times are zero, and each task is assigned to a distinct processor. <p> Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [19], marked directed graph [4], dataflow graph [13, 14], dependence graph [8], flow graph [10], signal flow graph <ref> [2] </ref>, iterative task graph [21], collapsed-constraint graph [3], and semisystolic network [16], among others. Alternative models such as variations of Petri nets [18] have also been analyzed. <p> Borrowing and expanding on terminology from <ref> [2] </ref>, when a processor has multiple tasks assigned to it, we say it is a shared processor, and any task assigned to a shared processor is a sharing task. <p> Task sequence specification is discussed in more detail in [7]. Pipeline scheduling algorithms from the literature specify schedules in terms specific to a particular algorithm. In our terminology, the pipeline scheduling algorithms in <ref> [2, 10] </ref> assign all tasks sharing the same processor to the same stage, which can therefore be assigned any arbitrary value (either zero or the "current" stage number are logical choices). The order in which tasks are assigned to a processor is the corresponding task order. <p> To do this, we need to 7 (a) A :1 ! B :1 <ref> [2] </ref> (c) A :1 ! B :1 [-2] dependence distances. <p> Theorem 3 (deadlock characterization) may be applied to show that a pipeline scheduling algorithm produces schedules which are free of deadlock. Theorem 4 13 (iteration interval determination) may be applied to precisely determine the iteration interval of schedules derived from existing scheduling algorithms <ref> [2, 10, 21] </ref>. We have also discussed specification of a pipeline schedule in terms of its components; execution of a schedule at runtime; algorithms for evaluating the iteration interval formula for a schedule; and bounds on the startup time of a pipeline.
Reference: [3] <author> Steven M. Burns. </author> <title> Performance analysis and optimization of asynchronous circuits. </title> <type> Ph.D. Thesis, </type> <institution> Cali-fornia Institute of Technology, Pasadena, California, </institution> <year> 1991. </year>
Reference-contexts: be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [19], marked directed graph [4], dataflow graph [13, 14], dependence graph [8], flow graph [10], signal flow graph [2], iterative task graph [21], collapsed-constraint graph <ref> [3] </ref>, and semisystolic network [16], among others. Alternative models such as variations of Petri nets [18] have also been analyzed. Although the large choice of names and model variations is perhaps confusing, it also illustrates that pipelining is useful in a variety of contexts. <p> Deadlock detection may also be added to the binary search algorithm. In addition to the binary and monotonic search algorithms, there are other algorithms which may be used to calculate the maximum cycle ratio of a DDG as required by Theorems 2 and 4. Burns <ref> [3] </ref> and Hartmann and Orlin [9] describe competitive alternative algorithms, and also provide references for additional algorithms. Some algorithms require that the DDG be a nonnegative DDG.
Reference: [4] <author> F. Commoner, A. W. Holt, S. Even, and A. Pnueli. </author> <title> Marked directed graphs. </title> <journal> Journal of Computer and System Sciences 5:5 (October 1971), </journal> <pages> pp. 511-523. </pages>
Reference-contexts: We summarize our conclusions in Section 8. 2 Loop and Pipeline Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [19], marked directed graph <ref> [4] </ref>, dataflow graph [13, 14], dependence graph [8], flow graph [10], signal flow graph [2], iterative task graph [21], collapsed-constraint graph [3], and semisystolic network [16], among others. Alternative models such as variations of Petri nets [18] have also been analyzed. <p> Some authors implicitly assume the following theorem on deadlock; explicit discussion and a proof can be found in <ref> [4] </ref> (see also [13]). <p> Further, this lower bound can be achieved, except when G:vmax (the largest task time in G) is greater than this bound. This result (Theorem 2 below) has been analyzed by a number of authors in addition to Reiter, including <ref> [4, 10, 13, 18] </ref>. Our statement of the result borrows from the discussion in several of these papers. In anticipation of our later generalization of Theorem 2, we state the theorem in terms of the following definition, which incorporates a communication term which in the immediate case is zero.
Reference: [5] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Longest paths between vertices in a graph are not well-defined if the graph contains a positive weight cycle, so general single-source longest path algorithms such as the O (ev) Bellman-Ford algorithm <ref> [5] </ref>, detect the existence of positive cycles as a necessary precondition or side-effect of the search for longest paths. (Bellman-Ford and other longest path algorithms are usually referred to as shortest path algorithms, but are equally applicable as longest path algorithms.) Therefore, any given value of b fl can be compared <p> If G b fl has one or more positive cycles, an augmented version of the Bellman-Ford algorithm can be used to find one. When longest paths are well-defined, the Bellman-Ford algorithm can explicitly enumerate the vertices in a longest path by constructing a predecessor subgraph <ref> [5] </ref>. The same technique can be used to explicitly identify a positive cycle, by following predecessor links until a cycle is found in O (v) time. <p> The ratio for this cycle can then be calculated in O (v) time, and this value can be used as the next value of b fl . As a heuristic, we can start the search for a positive cycle at the task which has the largest "relaxation delta" <ref> [5] </ref> in the cycle checking pass. Additional discussion on implementation of this algorithm can be found in [7].
Reference: [6] <author> Val Donaldson and Jeanne Ferrante. </author> <title> Determining asynchronous acyclic pipeline execution times. </title> <booktitle> Proc. 10th International Parallel Processing Symposium, </booktitle> <address> Honolulu, HI, </address> <month> April </month> <year> 1996, </year> <pages> pp. 568-572. </pages>
Reference-contexts: The algorithm in <ref> [6] </ref> assumes that the DDG is a task graph, which is a DDG in which all dependence distances are uniformly zero, and also assumes that processors are not shared. <p> With the exception of <ref> [6] </ref>, which restricts the form of a DDG and does not 12 allow processor sharing, previous work has not addressed the issue of determining a value for a, in part because the iteration interval b was not known. <p> DDG's for which a fl overestimated a by a larger multiple of b were all small granularity DDG's, with large communication to computation ratios, so that the time required to produce the first pipeline result was much larger than b. It might be possible to borrow techniques from <ref> [6] </ref> to get a more accurate value for a fl . a fl + bn is an upper bound on G:time n , the execution time of n iterations of a DDG G.
Reference: [7] <author> Val Donaldson and Jeanne Ferrante. </author> <title> Determining asynchronous pipeline execution times. </title> <type> Technical Report CS96-481, </type> <institution> Computer Science and Engineering Dept., University of California, </institution> <address> San Diego, La Jolla, CA, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: The basic idea of the proof of these generalizations is to insert new tasks on edges of a DDG which have nonzero communication times. Full proofs can be found in <ref> [7] </ref>. Accounting for the possibility that tasks may share processors is more difficult. We must first consider how a pipeline schedule may be specified when processors are shared. An asynchronous pipeline schedule for a DDG has two components. <p> This changes the range of values which the outer loop index i takes, but the sequence of values assigned to j in the inner loop will be unchanged. Task sequence specification is discussed in more detail in <ref> [7] </ref>. Pipeline scheduling algorithms from the literature specify schedules in terms specific to a particular algorithm. <p> all tasks in a scheduling cycle are executed on the same processor using the control code in Figure 4, this task sequence is unique; there is a one-to-one correspondence between scheduling cycles and task sequences generated by the code in Figure 4 (a proof of this can be found in <ref> [7] </ref>). There is one subtle point regarding deadlock which deserves mention. Based on the discussion of dependence distances in Section 5, when the total number of iterations that a DDG is executed is not larger than the absolute value of a dependence distance, the dependence edge may be ignored. <p> Theorem 3 Let G be a scheduled DDG with p scheduling cycles. Then pipeline execution of G on p processors is free of deadlock iff G satisfies the positive cycle constraint. Proof See <ref> [7] </ref>. 2 Theorem 3 may be used to determine if a given schedule for a DDG will deadlock. It may also be used to show that a scheduling algorithm always produces schedules which are free of deadlock. <p> Theorem 4 Let G be a scheduled DDG with p scheduling cycles, satisfying the positive cycle constraint. Then the iteration interval b for pipeline execution of G on p processors is the maximum cycle ratio of G. Proof See <ref> [7] </ref>. 2 Note that because Theorem 4 assumes that every task in G is contained in a scheduling cycle (from Definition 6), and the sum of dependence distances in any scheduling cycle is one, the maximum cycle ratio of G is at least as large as G:vmax , so no explicit <p> As a heuristic, we can start the search for a positive cycle at the task which has the largest "relaxation delta" [5] in the cycle checking pass. Additional discussion on implementation of this algorithm can be found in <ref> [7] </ref>. The primary question with this approach is: How many b fl trial values must be checked before b is found? To address this question, we implemented the monotonic search algorithm using the O (ev) Bellman-Ford algorithm as the longest path subalgorithm. <p> Some algorithms require that the DDG be a nonnegative DDG. A technique for transforming a general DDG into a nonnegative DDG with an equivalent maximum cycle ratio in O (ev) time is discussed in <ref> [7] </ref>. The choice of which algorithm to use depends on both the theoretical and practical characteristics of each algorithm, including computational complexity considerations and ease of implementation. <p> topics, including proofs of Theorems 3 and 4, and several additional results such as a technique for transforming an arbitrary DDG into a nonnegative DDG with the same maximum cycle ratio, and a technique for efficiently simulating execution of a pipeline schedule on a sequential processor, may be found in <ref> [7] </ref>. Several ideas that we discussed may be of interest in other contexts, such as the notion of negative dependence distances in a single unnested loop.
Reference: [8] <author> Franco Gasperoni and Uwe Schwiegelshohn. </author> <title> Scheduling loops on parallel processors: a simple algorithm with close to optimum performance. </title> <booktitle> Second Joint International Conference on Vector and Parallel Processing (Parallel Processing: CONPAR 92-VAPP V), </booktitle> <address> Lyon, France, </address> <month> September </month> <year> 1992, </year> <pages> pp. 625-636. </pages>
Reference-contexts: in Section 8. 2 Loop and Pipeline Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [19], marked directed graph [4], dataflow graph [13, 14], dependence graph <ref> [8] </ref>, flow graph [10], signal flow graph [2], iterative task graph [21], collapsed-constraint graph [3], and semisystolic network [16], among others. Alternative models such as variations of Petri nets [18] have also been analyzed. <p> The order in which tasks are assigned to a processor is the corresponding task order. The scheduling algorithm of <ref> [8] </ref> generates a noniterative task graph schedule " a " which provides a processor assignment and a task order for each processor. Stage assignments are given by the "" function. The algorithm in [21] is a generalization of the algorithm in [8]. <p> The scheduling algorithm of <ref> [8] </ref> generates a noniterative task graph schedule " a " which provides a processor assignment and a task order for each processor. Stage assignments are given by the "" function. The algorithm in [21] is a generalization of the algorithm in [8]. <p> The second question concerns search termination: How can it be determined that the current smallest b fl value such that G b fl has no positive cycles is the actual value of b? One solution is to settle for a conservative approximation of b. In <ref> [8] </ref>, the search is confined to integral values, and b is approximated as dbe. Using the Bellman-Ford algorithm as a subroutine, the resulting binary search algorithm runs in O (ev log G:vtime) time.
Reference: [9] <author> Mark Hartmann and James B. Orlin. </author> <title> Finding minimum cost to time ratio cycles with small integral transit times. </title> <booktitle> Networks 23:6 (September 1993), </booktitle> <pages> pp. 567-74. 14 </pages>
Reference-contexts: In addition to the binary and monotonic search algorithms, there are other algorithms which may be used to calculate the maximum cycle ratio of a DDG as required by Theorems 2 and 4. Burns [3] and Hartmann and Orlin <ref> [9] </ref> describe competitive alternative algorithms, and also provide references for additional algorithms. Some algorithms require that the DDG be a nonnegative DDG. A technique for transforming a general DDG into a nonnegative DDG with an equivalent maximum cycle ratio in O (ev) time is discussed in [7].
Reference: [10] <author> Phu D. Hoang and Jan M. Rabaey. </author> <title> Scheduling of DSP programs onto multiprocessors for maximum throughput. </title> <journal> IEEE Transactions on Signal Processing 41:6 (June 1993), </journal> <pages> pp. 2225-2235. </pages>
Reference-contexts: This form of pipelining has been studied particularly in the context of digital signal processing algorithms <ref> [2, 10] </ref>, although it has been considered in other contexts as well [21]. Tasks may be of arbitrary size, from simple statements to complex compound statements or subroutine calls. <p> The term a is the startup time of the schedule, and is a secondary performance measure. Previous asynchronous pipeline scheduling algorithms targeting distributed memory systems <ref> [2, 10, 21] </ref> use conservative estimates of the pipeline iteration interval as their performance measure, derived in part from Reiter's well-known iteration interval formula [19]. Reiter's formula assumes that intertask communication times are zero, and each task is assigned to a distinct processor. <p> 2 Loop and Pipeline Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [19], marked directed graph [4], dataflow graph [13, 14], dependence graph [8], flow graph <ref> [10] </ref>, signal flow graph [2], iterative task graph [21], collapsed-constraint graph [3], and semisystolic network [16], among others. Alternative models such as variations of Petri nets [18] have also been analyzed. <p> Further, this lower bound can be achieved, except when G:vmax (the largest task time in G) is greater than this bound. This result (Theorem 2 below) has been analyzed by a number of authors in addition to Reiter, including <ref> [4, 10, 13, 18] </ref>. Our statement of the result borrows from the discussion in several of these papers. In anticipation of our later generalization of Theorem 2, we state the theorem in terms of the following definition, which incorporates a communication term which in the immediate case is zero. <p> Task sequence specification is discussed in more detail in [7]. Pipeline scheduling algorithms from the literature specify schedules in terms specific to a particular algorithm. In our terminology, the pipeline scheduling algorithms in <ref> [2, 10] </ref> assign all tasks sharing the same processor to the same stage, which can therefore be assigned any arbitrary value (either zero or the "current" stage number are logical choices). The order in which tasks are assigned to a processor is the corresponding task order. <p> A natural question to ask is: If a DDG contains cycles, can the maximum cycle ratio be computed efficiently? A straightforward approach, used in <ref> [10] </ref>, is to enumerate all simple cycles, and explicitly calculate the value of the maximum cycle ratio. <p> Theorem 3 (deadlock characterization) may be applied to show that a pipeline scheduling algorithm produces schedules which are free of deadlock. Theorem 4 13 (iteration interval determination) may be applied to precisely determine the iteration interval of schedules derived from existing scheduling algorithms <ref> [2, 10, 21] </ref>. We have also discussed specification of a pipeline schedule in terms of its components; execution of a schedule at runtime; algorithms for evaluating the iteration interval formula for a schedule; and bounds on the startup time of a pipeline.
Reference: [11] <author> Donald B. Johnson. </author> <title> Finding all the elementary circuits of a directed graph. </title> <journal> SIAM Journal on Computing 4:1 (March 1975), </journal> <pages> pp. 77-84. </pages>
Reference-contexts: All jCj simple cycles in a graph can be enumerated in O (jCj (e + v)) time <ref> [11] </ref>, but there may be more than 2 v cycles in a DDG, so this technique is only feasible if it is known that the DDG has only a few cycles. 7.1 Binary Search Algorithm Lawler [15, Section 3.13] describes a technique for computing the maximum cycle ratio of a DDG
Reference: [12] <author> Peter M. Kogge. </author> <title> The Architecture of Pipelined Computers. </title> <publisher> Hemisphere Publishing, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: Under the broad umbrella of pipeline parallelism, there are a number of variants which make different assumptions, or focus on different aspects of the computation which is being pipelined. Examples include instruction and vector pipelining in hardware <ref> [12] </ref>, and software pipelining on sequential, VLIW, or superscalar processors [1, 14]. Our focus is on a form of pipelining which we call asynchronous pipelining, where application program loops are pipelined on multiprocessors or multicomputers, and pipeline tasks are scheduled as soon as processor and data resources are available.
Reference: [13] <author> S. Y. Kung, P. S. Lewis, and S. C. Lo. </author> <title> Performance analysis and optimization of VLSI dataflow arrays. </title> <journal> Journal of Parallel and Distributed Computing 4:6 (December 1987), </journal> <pages> pp. 592-618. </pages>
Reference-contexts: We summarize our conclusions in Section 8. 2 Loop and Pipeline Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [19], marked directed graph [4], dataflow graph <ref> [13, 14] </ref>, dependence graph [8], flow graph [10], signal flow graph [2], iterative task graph [21], collapsed-constraint graph [3], and semisystolic network [16], among others. Alternative models such as variations of Petri nets [18] have also been analyzed. <p> Some authors implicitly assume the following theorem on deadlock; explicit discussion and a proof can be found in [4] (see also <ref> [13] </ref>). <p> Further, this lower bound can be achieved, except when G:vmax (the largest task time in G) is greater than this bound. This result (Theorem 2 below) has been analyzed by a number of authors in addition to Reiter, including <ref> [4, 10, 13, 18] </ref>. Our statement of the result borrows from the discussion in several of these papers. In anticipation of our later generalization of Theorem 2, we state the theorem in terms of the following definition, which incorporates a communication term which in the immediate case is zero. <p> This definition could be phrased in terms of arbitrary cycles rather than simple cycles, but this is unnecessary since indexing over simple cycles is equivalent to indexing over arbitrary cycles <ref> [13] </ref>. For any cycle c in a DDG, V c is the set of tasks in c, and E c is the set of edges in c.
Reference: [14] <author> Monica Lam. </author> <title> Software pipelining: an effective scheduling technique for VLIW machines. </title> <booktitle> Proc. SIG-PLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <address> Atlanta, GA, </address> <month> June </month> <year> 1988, </year> <pages> pp. 318-328. </pages>
Reference-contexts: Under the broad umbrella of pipeline parallelism, there are a number of variants which make different assumptions, or focus on different aspects of the computation which is being pipelined. Examples include instruction and vector pipelining in hardware [12], and software pipelining on sequential, VLIW, or superscalar processors <ref> [1, 14] </ref>. Our focus is on a form of pipelining which we call asynchronous pipelining, where application program loops are pipelined on multiprocessors or multicomputers, and pipeline tasks are scheduled as soon as processor and data resources are available. <p> We summarize our conclusions in Section 8. 2 Loop and Pipeline Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [19], marked directed graph [4], dataflow graph <ref> [13, 14] </ref>, dependence graph [8], flow graph [10], signal flow graph [2], iterative task graph [21], collapsed-constraint graph [3], and semisystolic network [16], among others. Alternative models such as variations of Petri nets [18] have also been analyzed.
Reference: [15] <author> Eugene L. Lawler. </author> <title> Combinatorial Optimization: Networks and Matroids. </title> <publisher> Holt, Rinehart, and Winston, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: cycles in a graph can be enumerated in O (jCj (e + v)) time [11], but there may be more than 2 v cycles in a DDG, so this technique is only feasible if it is known that the DDG has only a few cycles. 7.1 Binary Search Algorithm Lawler <ref> [15, Section 3.13] </ref> describes a technique for computing the maximum cycle ratio of a DDG G by looking for positive cycles in a family of derivative graphs with edge weights.
Reference: [16] <author> F. Thomson Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [19], marked directed graph [4], dataflow graph [13, 14], dependence graph [8], flow graph [10], signal flow graph [2], iterative task graph [21], collapsed-constraint graph [3], and semisystolic network <ref> [16] </ref>, among others. Alternative models such as variations of Petri nets [18] have also been analyzed. Although the large choice of names and model variations is perhaps confusing, it also illustrates that pipelining is useful in a variety of contexts.
Reference: [17] <author> David A. Padua and Michael J. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> Communications of the ACM 29:12 (December 1986), </journal> <pages> pp. 1184-1201. </pages>
Reference-contexts: Pipeline parallelism exploits concurrency both within and across loop iterations, complementing other forms of parallelism. A computation which can not be parallelized using doall parallelism <ref> [17] </ref>, which assigns different loop iterations to different processors, or noniterative task (or DAG) parallelism [20, 22], may permit pipeline parallelization. Under the broad umbrella of pipeline parallelism, there are a number of variants which make different assumptions, or focus on different aspects of the computation which is being pipelined. <p> Although the large choice of names and model variations is perhaps confusing, it also illustrates that pipelining is useful in a variety of contexts. Variants of this data structure have been extensively studied in the optimizing compiler literature under the name data dependence graph <ref> [17] </ref>, which is the name we will use. Definition 1 A data dependence graph (DDG) is a weighted directed multigraph G = (V; E; f vtime ; f etime ; f dist ), where: * V is a set of vertices or tasks.
Reference: [18] <author> C. V. Ramamoorthy and Gary S. Ho. </author> <title> Performance evaluation of asynchronous concurrent systems using Petri nets. </title> <journal> IEEE Transactions on Software Engineering SE-6:5 (September 1980), </journal> <pages> pp. 440-449. </pages>
Reference-contexts: Alternative models such as variations of Petri nets <ref> [18] </ref> have also been analyzed. Although the large choice of names and model variations is perhaps confusing, it also illustrates that pipelining is useful in a variety of contexts. <p> Then the iteration interval b and startup time a for pipeline execution of G are b = lim G:time n n a = maxfG:time n bnjn 1g 2 This definition of the iteration interval b, and a proof of the existence of the limit can be found in <ref> [18] </ref> (see also [19]). The iteration interval is the average time between completion of successive iterations of the DDG, and is the primary measure of the performance of a pipeline schedule. We will show how to find b for any pipeline schedule which does not deadlock. <p> Further, this lower bound can be achieved, except when G:vmax (the largest task time in G) is greater than this bound. This result (Theorem 2 below) has been analyzed by a number of authors in addition to Reiter, including <ref> [4, 10, 13, 18] </ref>. Our statement of the result borrows from the discussion in several of these papers. In anticipation of our later generalization of Theorem 2, we state the theorem in terms of the following definition, which incorporates a communication term which in the immediate case is zero.
Reference: [19] <author> Raymond Reiter. </author> <title> Scheduling parallel computations. </title> <journal> Journal of the ACM 15:4 (October 1968), </journal> <pages> pp. 590-599. </pages>
Reference-contexts: The term a is the startup time of the schedule, and is a secondary performance measure. Previous asynchronous pipeline scheduling algorithms targeting distributed memory systems [2, 10, 21] use conservative estimates of the pipeline iteration interval as their performance measure, derived in part from Reiter's well-known iteration interval formula <ref> [19] </ref>. Reiter's formula assumes that intertask communication times are zero, and each task is assigned to a distinct processor. The primary contributions of this paper are a generalization of previous work on determining if a pipeline schedule will deadlock, and generalization of Reiter's formula for determining the iteration interval b. <p> We summarize our conclusions in Section 8. 2 Loop and Pipeline Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph <ref> [19] </ref>, marked directed graph [4], dataflow graph [13, 14], dependence graph [8], flow graph [10], signal flow graph [2], iterative task graph [21], collapsed-constraint graph [3], and semisystolic network [16], among others. Alternative models such as variations of Petri nets [18] have also been analyzed. <p> the iteration interval b and startup time a for pipeline execution of G are b = lim G:time n n a = maxfG:time n bnjn 1g 2 This definition of the iteration interval b, and a proof of the existence of the limit can be found in [18] (see also <ref> [19] </ref>). The iteration interval is the average time between completion of successive iterations of the DDG, and is the primary measure of the performance of a pipeline schedule. We will show how to find b for any pipeline schedule which does not deadlock. <p> We will show how to find b for any pipeline schedule which does not deadlock. Our definition of the startup time a, which is a secondary measure of the performance of a pipeline schedule, is based in part on results from <ref> [19] </ref>. In Section 7.3 we will show that the set in this definition is finite and therefore has a maximum, so a is well-defined. <p> The DDG has an iteration interval b = 2:5, and G:time n 0:5 + 2:5n. Beyond deadlock considerations, the primary result in determining the pipeline execution time of a DDG is Reiter's formula <ref> [19] </ref> for determining the iteration interval b of a nonnegative DDG, when all data communication times are zero, and processors are not shared. To motivate this formula, consider the DDG in Figure 2, which is a simple cycle of tasks. <p> These values are automatically found for all tasks as a side-effect of using a longest path algorithm to determine b (or given b, may be found in O (ev) time with a single longest path calculation). Reiter <ref> [19] </ref> showed that with reference to a global clock, the ith iteration of task X could legally start at time X:est + b (i 1). With asynchronous execution, this value is an upper bound on when the ith iteration of X will begin execution.
Reference: [20] <author> Vivek Sarkar. </author> <title> Partitioning and Scheduling Parallel Programs for Multiprocessors. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1989. </year>
Reference-contexts: Pipeline parallelism exploits concurrency both within and across loop iterations, complementing other forms of parallelism. A computation which can not be parallelized using doall parallelism [17], which assigns different loop iterations to different processors, or noniterative task (or DAG) parallelism <ref> [20, 22] </ref>, may permit pipeline parallelization. Under the broad umbrella of pipeline parallelism, there are a number of variants which make different assumptions, or focus on different aspects of the computation which is being pipelined. <p> Dependence distances are discussed in more detail in Section 5. Definition 2 A nonnegative DDG is a DDG in which all edges have nonnegative dependence distances. 2 Asynchronous pipeline execution is a form of macro-dataflow execution <ref> [20] </ref>. Task execution is atomic. An instance of a task may not begin execution until all input data is available. Once a task instance begins execution, it executes without interruption to completion, and any output data becomes available for communication to other tasks only when task execution is complete.
Reference: [21] <author> Tao Yang, Cong Fu, Apostolos Gerasoulis, and Vivek Sarkar. </author> <title> Mapping iterative task graphs on distributed memory machines. </title> <booktitle> Proc. 24th International Conference on Parallel Processing, </booktitle> <address> Oconomowoc, WI, </address> <month> August </month> <year> 1995, </year> <booktitle> Vol II, </booktitle> <pages> pp. 151-158. </pages>
Reference-contexts: This form of pipelining has been studied particularly in the context of digital signal processing algorithms [2, 10], although it has been considered in other contexts as well <ref> [21] </ref>. Tasks may be of arbitrary size, from simple statements to complex compound statements or subroutine calls. Task execution times may vary from iteration to iteration, although we assume that there is an expected execution time for each task. We are particularly interested in pipeline execution on distributed memory architectures. <p> The term a is the startup time of the schedule, and is a secondary performance measure. Previous asynchronous pipeline scheduling algorithms targeting distributed memory systems <ref> [2, 10, 21] </ref> use conservative estimates of the pipeline iteration interval as their performance measure, derived in part from Reiter's well-known iteration interval formula [19]. Reiter's formula assumes that intertask communication times are zero, and each task is assigned to a distinct processor. <p> and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [19], marked directed graph [4], dataflow graph [13, 14], dependence graph [8], flow graph [10], signal flow graph [2], iterative task graph <ref> [21] </ref>, collapsed-constraint graph [3], and semisystolic network [16], among others. Alternative models such as variations of Petri nets [18] have also been analyzed. Although the large choice of names and model variations is perhaps confusing, it also illustrates that pipelining is useful in a variety of contexts. <p> In Figure 1, all communication times and four dependence distances are zero. In Definition 1, we require task execution and data communication times to be fixed, invariant times, but we expect variances in component execution times to typically translate to similar magnitude variances in pipeline execution times <ref> [21] </ref>. Much of the literature on pipeline scheduling, particularly outside compiler research, uses the term "delay" as a synonym for what we refer to as dependence distance. <p> The scheduling algorithm of [8] generates a noniterative task graph schedule " a " which provides a processor assignment and a task order for each processor. Stage assignments are given by the "" function. The algorithm in <ref> [21] </ref> is a generalization of the algorithm in [8]. <p> Theorem 4 may be applied to obtain exact iteration interval values for examples from the literature. For example, the iteration interval of the schedule in <ref> [21, Figure 1d] </ref> is 80, rather than the reported conservative estimate of 90. 10 7 Iteration Interval Formula Evaluation Theorem 4 states that the iteration interval of a scheduled DDG is equal to the maximum cycle ratio of the DDG. <p> In [8], the search is confined to integral values, and b is approximated as dbe. Using the Bellman-Ford algorithm as a subroutine, the resulting binary search algorithm runs in O (ev log G:vtime) time. This same general approach is also used in <ref> [21] </ref>, but with the accuracy specified by a parameter *, i.e., b is approximated as *d b * e (0:5 is used as an example value for *). <p> Theorem 3 (deadlock characterization) may be applied to show that a pipeline scheduling algorithm produces schedules which are free of deadlock. Theorem 4 13 (iteration interval determination) may be applied to precisely determine the iteration interval of schedules derived from existing scheduling algorithms <ref> [2, 10, 21] </ref>. We have also discussed specification of a pipeline schedule in terms of its components; execution of a schedule at runtime; algorithms for evaluating the iteration interval formula for a schedule; and bounds on the startup time of a pipeline.
Reference: [22] <author> Tao Yang and Apostolos Gerasoulis. </author> <title> DSC: scheduling parallel tasks on an unbounded number of processors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems 5:9 (September 1994), </journal> <pages> pp. 951-967. 15 </pages>
Reference-contexts: Pipeline parallelism exploits concurrency both within and across loop iterations, complementing other forms of parallelism. A computation which can not be parallelized using doall parallelism [17], which assigns different loop iterations to different processors, or noniterative task (or DAG) parallelism <ref> [20, 22] </ref>, may permit pipeline parallelization. Under the broad umbrella of pipeline parallelism, there are a number of variants which make different assumptions, or focus on different aspects of the computation which is being pipelined. <p> A key component of our approach is the use of scheduling edges with potentially negative data dependence distances, which generalizes the use of scheduling edges in noniterative task graphs <ref> [22] </ref>. We also explicitly discuss the specification of an asynchronous pipeline schedule in terms of schedule subcomponents; describe a simple mechanism for implementing a pipeline schedule at runtime; derive bounds on the startup time a; and discuss evaluation of the iteration interval formula, including the design of a new algorithm. <p> Scheduling edges allow the problem of analyzing pipeline execution of a graph when processors are shared to be reduced to a problem where processors are not shared. This is a generalization of the use of scheduling edges in noniterative task graph scheduling <ref> [22] </ref>. From Section 4, a regular asynchronous pipeline schedule for a DDG G has three components: a processor assignment, and for each processor, a task order and stage assignment.
References-found: 22

