URL: http://www.cs.ucsb.edu/oocsb/self/papers/cpa.ps.Z
Refering-URL: http://www.cs.ucsb.edu/oocsb/self/papers/cpa.html
Root-URL: http://www.cs.ucsb.edu
Email: agesen@cs.stanford.edu  
Title: The Cartesian Product Algorithm Simple and Precise Type Inference of Parametric Polymorphism  
Author: Ole Agesen 
Keyword: concrete types, abstract types, type inference, polymorphism, inheritance, Self.  
Address: Stanford, CA 94305  
Affiliation: Computer Science Department, Stanford University  
Abstract: Concrete types and abstract types are different and serve different purposes. Concrete types, the focus of this paper, are essential to support compilation, application delivery, and debugging in object-oriented environments. Concrete types should not be obtained from explicit type declarations because their presence limits polymorphism unacceptably. This leaves us with type inference. Unfortunately, while polymorphism demands the use of type inference, it has also been the hardest challenge for type inference. We review previous type inference algorithms that analyze code with parametric polymorphism and then present a new one: the cartesian product algorithm. It improves precision and efficiency over previous algorithms and deals directly with inheritance, rather than relying on a preprocessor to expand it away. Last, but not least, it is conceptually simple. The cartesian product algorithm has been used in the Self system since late 1993. We present measurements to document its performance and compare it against several previous algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Agesen, O., </author> <title> Constraint-Based Type Inference and Parametric Polymorphism. </title> <booktitle> In SAS94, First International Static Analysis Symposium, p. </booktitle> <pages> 78-100, </pages> <address> Namur, Belgium, Sept. 1994. </address> <publisher> Springer-Verlag, LNCS 864. </publisher>
Reference-contexts: To illustrate this, we applied a simple inference algorithm (the basic algorithm, see Section 2.2) to the Self expression 30 factorial, where the factorial method for an integer receiver is defined by factorial = ( self&lt;=1 ifTrue: <ref> [1] </ref> False: [self * predecessor factorial] ). Rather than -smallInt, bigInt-, this very polymorphic and imprecise type was reported: -smallInt, bigInt, collector, memory, memoryState, byteVector, mutableString, immutableString, oat, link, list, primitiveFailedError, userError, time, false, true, nil, [blk 1 ], [blk 2 ], ..., [blk 13 ]-. <p> While some of this complexity is peculiar to the Self system and better results may be obtained on other systems, the example clearly demonstrates the insufficient precision of the basic algorithm when analyzing polymorphic code. To address the imprecision, more accurate algorithms were developed; see <ref> [1] </ref> for a survey. Some of these can infer the precise type -smallInt, bigInt- for the factorial example. The improved precision came at a cost, though. Type inference got less efficient and more complex to understand. <p> Templates are used both to review previous algorithms and present the new algorithm. Section 2.4 pinpoints why polymorphism is hard to analyze. Finally, Section 2.5 reviews how previous algorithms deal with polymorphism. A more detailed and complete version of this background material is found in <ref> [1] </ref>. 2.1 Definition of Type In the introduction we informally presented types as sets of classes, following Suzuki and Johnson [23, 15]. Since Self is prototype-based and has no classes we need to modify the definition of type slightly. <p> Thus, Step 3 consists in repeatedly establishing constraints and propagating, until no more can be done. To ensure soundness, a constraint must be generated for every possible data ow in the target program <ref> [1] </ref>. Different languages have different constructs that produce data ows, but some general examples can be given (more examples are found in [1, 3, 17, 18, 20]): Assignments generate data ows from the new value expressions to the assigned variables (Figure 2). <p> To ensure soundness, a constraint must be generated for every possible data ow in the target program [1]. Different languages have different constructs that produce data ows, but some general examples can be given (more examples are found in <ref> [1, 3, 17, 18, 20] </ref>): Assignments generate data ows from the new value expressions to the assigned variables (Figure 2). Variable reads generate data ows from the accessed variables to the accessing expressions. <p> Furthermore, data ows return the results of the invoked methods to the message sends. Primitive data types like integers and oats, and their operations, including built-in control structures. 2.3 Templates In <ref> [1] </ref> we introduced templates and used them to study how several previously published type inference algorithms analyze polymorphism. Templates also enable a concise exposition of our new algorithm, so we review them here. <p> Seen in this light, the p-level expansion algorithms form a family of algorithms that apply particularly simple monotonic functions to decide whether or not to share. These functions do not depend on the types being inferred, but merely on the static program text. In <ref> [1] </ref> such algorithms are called non-adaptive because they uniformly apply the same effort throughout the target program rather than focusing on the parts where the most complex polymorphism is found. <p> The iterative algorithm and CPA are adaptive because they use type information during inference to concentrate the analysis effort on the demanding parts of the target program. The hash function algorithm, described in <ref> [1, 3] </ref>, is a hybrid between the 1-level expansion and the cartesian product algorithm. It applies case analysis on receiver types, like CPA, but uses the 1-level expansion for the non-receiver arguments. The hash algorithm is adaptive because it uses receiver types during analysis. <p> The hash algorithm <ref> [1, 3] </ref> is included to show where it fits in, even though we have only touched upon it briey in this paper.
Reference: 2. <author> Agesen, O., L. Bak, C. Chambers, B.W. Chang, U. Hlzle, J. Maloney, R.B. Smith, D. Ungar, M. Wolczko. </author> <title> How to use Self 3.0 & The Self 3.0 Programmer's Reference Manual. 1993. Sun Microsystems Laboratories, </title> <type> 2550 Garcia Avenue, </type> <institution> Mountain View, </institution> <address> CA 94043, USA. </address> <note> Available by anon. ftp from self.stanford.edu or www: http://self.stanford.edu/. </note>
Reference-contexts: Finally, an appendix briey lists a number of issues that lack of space prevents us from discussing in detail. 2 Background The algorithms we describe are language independent, but we use Self as a source for examples and measurements <ref> [2, 24] </ref>. Detailed knowledge of Self is not required, although basic familiarity with Self or Small-talk syntax and programming style is helpful. This section reviews background material. Section 2.1 defines concrete types in a prototype-based context. Section 2.2 describes the basic type inference algorithm as a ow analysis.
Reference: 3. <author> Agesen, O., J. Palsberg, and M.I. Schwartzbach, </author> <title> Type Inference of Self: Analysis of Objects with Dynamic and Multiple Inheritance. </title> <booktitle> In ECOOP93, Seventh European Conference on Object-Oriented Programming, p. </booktitle> <pages> 247-267, </pages> <address> Kai-serslautern, Germany, </address> <month> July </month> <year> 1993. </year> <note> Springer-Verlag, LNCS 707. </note>
Reference-contexts: Browsing/debugging. Concrete types help a programmer understand programs by allowing a browser to track control ow (and thereby data ow) through dynamically dispatched message sends <ref> [3] </ref>. <p> Given that explicit concrete type declarations are undesirable, the considerable interest in inference algorithms is not surprising <ref> [3, 11, 17, 18, 19, 20, 25] </ref>. Ironically, while the desire to maximize polymorphism demands type inference, polymorphism is also the hardest challenge for inference algorithms. <p> To ensure soundness, a constraint must be generated for every possible data ow in the target program [1]. Different languages have different constructs that produce data ows, but some general examples can be given (more examples are found in <ref> [1, 3, 17, 18, 20] </ref>): Assignments generate data ows from the new value expressions to the assigned variables (Figure 2). Variable reads generate data ows from the accessed variables to the accessing expressions. <p> The iterative algorithm and CPA are adaptive because they use type information during inference to concentrate the analysis effort on the demanding parts of the target program. The hash function algorithm, described in <ref> [1, 3] </ref>, is a hybrid between the 1-level expansion and the cartesian product algorithm. It applies case analysis on receiver types, like CPA, but uses the 1-level expansion for the non-receiver arguments. The hash algorithm is adaptive because it uses receiver types during analysis. <p> The hash algorithm <ref> [1, 3] </ref> is included to show where it fits in, even though we have only touched upon it briey in this paper. <p> The efficiency column is informal, since it is not based on extensive measurements or theoretical complexity studies of the algorithms (the latter would require a statistical model of how typical programs use polymorphism). 2. The hash function algorithm also has this property <ref> [3] </ref>, but is restricted to singly-dispatched languages.
Reference: 4. <author> Agesen, O. and D. Ungar, </author> <title> Sifting Out the Gold: Delivering Compact Applications from an Exploratory Object-Oriented Programming Environment. </title> <booktitle> In OOPSLA94, Object-Oriented Programming Systems, Languages and Applications, p. </booktitle> <pages> 355-370, </pages> <address> Portland, Oregon, </address> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: Concrete types support important optimizations such as elimination of dynamic dispatch and method inlining [17, 21]. Extraction. Concrete types support delivery of compact applications by enabling an extractor to sift through an image of objects, selecting those that are essential to run a given application <ref> [4] </ref>. Browsing/debugging. Concrete types help a programmer understand programs by allowing a browser to track control ow (and thereby data ow) through dynamically dispatched message sends [3]. <p> They reuse and extend existing objects and data structures. For example, the factorial method is only one line of source, but it needs a bigInt implementation which comprises hundreds of lines. To obtain a more useful measure of program size, we applied the extractor described in <ref> [4] </ref>, and measured the size of the resulting self-contained source files. When counting everything, including variable definitions, blank lines, names spaces, etc., Factorial is 1300 lines, Richards 1700 lines, Deltablue 1800 lines, and Diff 5000 lines.
Reference: 5. <author> Bobrow, D.G., K. Kahn, G. Kiczales, L. Masinter, M. Stefik, and F. Zdybel, CommonLoops: </author> <title> Merging Lisp and Object-Oriented Programming. </title> <booktitle> In OOPSLA86 Object-Oriented Programming Systems, Languages and Applications, p. </booktitle> <pages> 17-29, </pages> <address> Portland, Oregon, </address> <month> Sept. </month> <year> 1986. </year>
Reference-contexts: Generality. The cartesian product handles inheritance of state, dynamic inheritance, and multiple inheritance. It even supports languages with multiple dispatch (multi-methods) <ref> [5, 6] </ref>, by a straightforward extension to the single-dispatch case: when the cartesian product is generated, each tuple is propagated to a template for the specific method that implements the operation for the combination of arguments in the tuple. 3.6 Summary Table 1 condenses the most important attributes of the algorithms
Reference: 6. <author> Chambers, C., </author> <title> Object-Oriented Multi-Methods in Cecil. </title> <booktitle> In ECOOP92, Sixth European Conference on Object-Oriented Programming, p. </booktitle> <pages> 33-56, </pages> <address> June 1992, Utrecht, The Netherlands. </address> <publisher> Springer-Verlag, LNCS 615. </publisher>
Reference-contexts: Generality. The cartesian product handles inheritance of state, dynamic inheritance, and multiple inheritance. It even supports languages with multiple dispatch (multi-methods) <ref> [5, 6] </ref>, by a straightforward extension to the single-dispatch case: when the cartesian product is generated, each tuple is propagated to a template for the specific method that implements the operation for the combination of arguments in the tuple. 3.6 Summary Table 1 condenses the most important attributes of the algorithms
Reference: 7. <author> Chambers, C., D. Ungar, </author> <title> Making Pure Object-Oriented Languages Practical. </title> <booktitle> In OOPSLA91, Sixth Annual Conference on Object-Oriented Programming Systems, Languages and Applications, p. </booktitle> <pages> 1-15, </pages> <address> Phoenix, Arizona, </address> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: We applied the six inference algorithms to four existing programs in the Self system: Factorial: invocation of the recursive factorial function shown in the introduction. Richards: an operating system simulator <ref> [7] </ref>. Deltablue: a multi-way constraint solver [22]. Diff: Mario Wolczkos Self version of the Unix diff command [12].
Reference: 8. <author> Chambers, C., D. Ungar, and E. Lee, </author> <title> An Efficient Implementation of SELF, a Dynamically-Typed Object-Oriented Language Based on Prototypes. </title> <booktitle> Lisp and Symbolic Computation 4(3), p. </booktitle> <pages> 243-281, </pages> <publisher> Kluwer Academic Publishers, </publisher> <month> June </month> <year> 1991. </year> <note> (Originally published in Proc. OOPSLA89). </note>
Reference-contexts: Propagating this type to a send that invokes display only on coloured points is imprecise: such a send should have the type -ColourPoint-. Compiler writers facing this issue found solutions such as customization <ref> [8] </ref> where the idea is to recompile a method for each class that inherits it to make the class of self known in the compiled code. Previous type inference algorithms for object-oriented languages have achieved a similar effect by using a preprocessor to eliminate inheritance [10, 11, 17, 18].
Reference: 9. <author> Cousot, P. and R. Cousot, </author> <title> Abstract Interpretation: A Unified Lattice Model for Static Analysis of Programs by Construction or Approximation of Fixpoints. </title> <booktitle> In Conference Record of the Fourth ACM Symposium on Principles of Programming Languages, p. </booktitle> <pages> 238-252, </pages> <month> Jan. </month> <year> 1977. </year>
Reference-contexts: The algorithm has deficiencies when analyzing polymorphic code, but constitutes the core of the improved algorithms, so we review it here. We take a more operational view, presenting type inference as a combined control- and data-ow analysis over the abstract domain of types. This abstract interpretation <ref> [9] </ref> perspective allows a direct correspondence between analyzing a program and executing it, making the analysis algorithms easier to understand. Referring to the program being analyzed as the target program, there are three steps in the basic algorithm. Step 1. Allocate type variables.
Reference: 10. <author> Graver, J.O., </author> <title> Type-Checking and Type-Inference for Object-Oriented Programming Languages, </title> <type> Ph.D. thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1989. </year>
Reference-contexts: It can be argued that enhancements of the iterative algorithm allow such cases to be analyzed precisely. For example, Graver and Johnson use a case analysis within methods to analyze similar structures precisely <ref> [10] </ref>. We find it preferable, though, to strive for the best precision available using our first tool, the constraints, and consider other enhancements only as they are truly needed. 3.5 Inheritance To use terminology that most readers are familiar with, we give examples from a class-based language in this section. <p> Previous type inference algorithms for object-oriented languages have achieved a similar effect by using a preprocessor to eliminate inheritance <ref> [10, 11, 17, 18] </ref>. The preprocessor copies methods down into the classes inheriting them. The result of this expansion is shown in the right hand side of Figure 8: there are now two identical methods display Point and display ColourPoint .
Reference: 11. <author> Graver, J.O. and R.E. Johnson, </author> <title> A Type System for Smalltalk. </title> <booktitle> In Conference Record of the Seventeenth Annual ACM Symposium on Principles of Programming Languages, p. </booktitle> <pages> 136-150, </pages> <address> San Francisco, California, </address> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: Given that explicit concrete type declarations are undesirable, the considerable interest in inference algorithms is not surprising <ref> [3, 11, 17, 18, 19, 20, 25] </ref>. Ironically, while the desire to maximize polymorphism demands type inference, polymorphism is also the hardest challenge for inference algorithms. <p> Previous type inference algorithms for object-oriented languages have achieved a similar effect by using a preprocessor to eliminate inheritance <ref> [10, 11, 17, 18] </ref>. The preprocessor copies methods down into the classes inheriting them. The result of this expansion is shown in the right hand side of Figure 8: there are now two identical methods display Point and display ColourPoint .
Reference: 12. <author> Hunt, J.W. and T.G. Szymanski, </author> <title> A Fast Algorithm for Computing Longest Common Subsequences, </title> <journal> Communications of the ACM, </journal> <volume> 20(5), </volume> <pages> p. 350-353, </pages> <month> May </month> <year> 1977. </year>
Reference-contexts: We applied the six inference algorithms to four existing programs in the Self system: Factorial: invocation of the recursive factorial function shown in the introduction. Richards: an operating system simulator [7]. Deltablue: a multi-way constraint solver [22]. Diff: Mario Wolczkos Self version of the Unix diff command <ref> [12] </ref>. The programs were analyzed unmodified, with one exception: we had to patch the _Mirror primitive to return nothing instead of a mirror (mirrors are a way to write reective code in Self and reection is only partially supported by the type inference implementation).
Reference: 13. <author> Hlzle, U., </author> <title> Why Static Typing is not Important for Efficiency. </title> <editor> In: J. Palsberg & M.I. Schwartzbach (eds.) </editor> <title> Types, Inheritance, and Assignment, </title> <type> Technical Report, </type> <institution> Daimi PB-357, Computer Science Department, Aarhus University, Denmark, </institution> <month> June </month> <year> 1991. </year>
Reference-contexts: For instance, knowing that an object is an instance of class Stack, is generally not sufficient to inline operations on it (the program may contain several subclasses of Stack and from the static type declaration we cannot tell which specific one occurs but concrete type inference may tell) <ref> [13] </ref>. 1.2 Polymorphism Polymorphism, the ability of a piece of code to work on several kinds of objects, is a central part of object-oriented programming. Polymorphism is desirable because it enables more code reuse. We distinguish between two kinds.
Reference: 14. <author> Hlzle, U. and D. Ungar, </author> <title> Optimizing Dynamically-Dispatched Calls with Run-time Type Feedback. </title> <booktitle> In PLDI94, Conference on Programming Language Design and Implementation, p. </booktitle> <pages> 326-336, </pages> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: The numbers in Table 2 are important beyond indicating type inference precision. A compiler based on type inference compiles fewer methods if it uses CPA than any of the other algorithms (note: the current Self compiler does not use type inference <ref> [14] </ref>). Table 3 compares CPU times of the type inference algorithms, measured on a 50 MHz SparcStation 10. To focus on the type inference algorithms per se, the time spent on grouping objects is omitted.
Reference: 15. <author> Johnson, R.E., </author> <title> Type-Checking Smalltalk. </title> <booktitle> In OOPSLA86 Object-Oriented Programming Systems, Languages and Applications, p. </booktitle> <pages> 315-321, </pages> <address> Portland, Oregon, </address> <month> Sept. </month> <year> 1986. </year>
Reference-contexts: Finally, Section 2.5 reviews how previous algorithms deal with polymorphism. A more detailed and complete version of this background material is found in [1]. 2.1 Definition of Type In the introduction we informally presented types as sets of classes, following Suzuki and Johnson <ref> [23, 15] </ref>. Since Self is prototype-based and has no classes we need to modify the definition of type slightly. A Self program is a finite set of objects (prototypes) -w 1 , w 2 , ..., w n -.
Reference: 16. <author> Milner, R., </author> <title> A Theory of Type Polymorphism in Programming. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 17, </volume> <pages> p. 348-375, </pages> <year> 1978. </year>
Reference-contexts: They may not distinguish between different implementations of the same abstract data type: both list-based and array-based stacks may have an abstract type like [push:elmTypefivoid; pop:voidfielm-Type]. Probably the best known inference algorithm for abstract types is Milners <ref> [16] </ref>. Concrete and abstract types are extremes in a spectrum of type systems.
Reference: 17. <author> Oxhj, N., J. Palsberg, and M.I. Schwartzbach, </author> <title> Making Type Inference Practical. </title> <booktitle> In ECOOP92, Sixth European Conference on Object-Oriented Programming, p. </booktitle> <pages> 329-349, </pages> <address> Utrecht, The Netherlands, June 1992, </address> <publisher> Springer-Verlag, LNCS 615. </publisher>
Reference-contexts: Concrete types are the focus of this paper. Previous publications have argued that they directly support solutions to several important problems in object-oriented programming environments: Compilation. Concrete types support important optimizations such as elimination of dynamic dispatch and method inlining <ref> [17, 21] </ref>. Extraction. Concrete types support delivery of compact applications by enabling an extractor to sift through an image of objects, selecting those that are essential to run a given application [4]. Browsing/debugging. <p> Given that explicit concrete type declarations are undesirable, the considerable interest in inference algorithms is not surprising <ref> [3, 11, 17, 18, 19, 20, 25] </ref>. Ironically, while the desire to maximize polymorphism demands type inference, polymorphism is also the hardest challenge for inference algorithms. <p> To ensure soundness, a constraint must be generated for every possible data ow in the target program [1]. Different languages have different constructs that produce data ows, but some general examples can be given (more examples are found in <ref> [1, 3, 17, 18, 20] </ref>): Assignments generate data ows from the new value expressions to the assigned variables (Figure 2). Variable reads generate data ows from the accessed variables to the accessing expressions. <p> The type of the send is determined by propagating the types of actual arguments through the template. self a self &gt; a result max: -smallInt ifTrue:False: 7 2.5.1 1-Level and p-Level Expansion Algorithms Palsberg and Schwartzbach saw the limitations of the basic algorithm and proposed the following polyvari-ant improvement <ref> [17] </ref>. 1-level expansion: always connect different sends in the target program to different templates. For example, if there are two max:-sends in the target program, two max:-templates are created, one for each send. <p> This method defeats the 2-level expansion by having a 3-deep polymorphic call chain: max:Max:fimax:fiifTrue:False:. In general, a p-level expansion algorithm is precise if polymorphic call chains are at most p calls deep, but the worst-case complexity is exponential in p since each expansion incurs a quadratic cost increase <ref> [17] </ref>. Vitek et al. [25] described this algorithm using the concept of call strings, and Phillips and Shepard [19] applied it to ParcPlace Smalltalk. 2.5.2 The Iterative Algorithm With the iterative algorithm, Plevyak and Chien [20] broke the unfavorable precision/efficiency trade-off inherent in the expansion algorithms. <p> Previous type inference algorithms for object-oriented languages have achieved a similar effect by using a preprocessor to eliminate inheritance <ref> [10, 11, 17, 18] </ref>. The preprocessor copies methods down into the classes inheriting them. The result of this expansion is shown in the right hand side of Figure 8: there are now two identical methods display Point and display ColourPoint . <p> Analogous to analyzing parametric polymorphism by copying methods, these algorithms copy classes in an attempt to keep different uses of (data) polymorphic instance variables separate. For example, Oxhj et al. proposed a 1-level class expansion <ref> [17] </ref>, Phillips and Shepard generalized this to p levels [19], and Plevyak and Chien developed an iterative algorithm [20]. While CPA itself does not address data polymorphism, neither does it conict with the existing algorithms for analyzing data polymorphism.
Reference: 18. <author> Palsberg, J. and M.I. Schwartzbach, </author> <title> Object-Oriented Type Inference. </title> <booktitle> In OOPSLA91 Object-Oriented Programming Systems, Languages and Applications, p. </booktitle> <pages> 146-161, </pages> <address> Phoenix, Arizona, </address> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Given that explicit concrete type declarations are undesirable, the considerable interest in inference algorithms is not surprising <ref> [3, 11, 17, 18, 19, 20, 25] </ref>. Ironically, while the desire to maximize polymorphism demands type inference, polymorphism is also the hardest challenge for inference algorithms. <p> The precision difference between an exponential and a linear number of types is significant. There are concrete types that the C++ programmer cannot express, yet our type inference algorithm can infer. 2.2 The Basic Type Inference Algorithm The basic type inference algorithm was presented by Palsberg and Schwartzbach <ref> [18] </ref> as a constraint-solving problem: derive a set of constraints from the program being analyzed, solve the constraints using a fix-point algorithm, and finally map the solution back onto the program to obtain the desired type information. <p> To ensure soundness, a constraint must be generated for every possible data ow in the target program [1]. Different languages have different constructs that produce data ows, but some general examples can be given (more examples are found in <ref> [1, 3, 17, 18, 20] </ref>): Assignments generate data ows from the new value expressions to the assigned variables (Figure 2). Variable reads generate data ows from the accessed variables to the accessing expressions. <p> Previous type inference algorithms for object-oriented languages have achieved a similar effect by using a preprocessor to eliminate inheritance <ref> [10, 11, 17, 18] </ref>. The preprocessor copies methods down into the classes inheriting them. The result of this expansion is shown in the right hand side of Figure 8: there are now two identical methods display Point and display ColourPoint . <p> Expanding away inheritance improves precision, because inaccuracies resulting from analyzing a single method in the context of several classes are avoided. The expansion can be expensive, though. In the worst case program size increases quadratically, even for programs using only single inheritance <ref> [18] </ref>. Care must 14 also be taken to handle overridden methods correctly, including sends to super (resends). For Self, there are additional complications: it is non-trivial to eliminate inheritance of state, not to mention dynamic inheritance, by an expansion. The cartesian product algorithm removes the need for the expansion.
Reference: 19. <author> Phillips, G. and T. Shepard, </author> <title> Static Typing Without Explicit Types. </title> <type> Technical Report, </type> <institution> Dept. of Electrical and Computer Engineering, Royal Military College of Canada, Kingston, </institution> <address> Ontario, Canada, </address> <year> 1994. </year>
Reference-contexts: Given that explicit concrete type declarations are undesirable, the considerable interest in inference algorithms is not surprising <ref> [3, 11, 17, 18, 19, 20, 25] </ref>. Ironically, while the desire to maximize polymorphism demands type inference, polymorphism is also the hardest challenge for inference algorithms. <p> The improved precision came at a cost, though. Type inference got less efficient and more complex to understand. For instance, Phillips and Shepard implemented one of the more precise algorithms and found that it took 10 hours to infer types for the expression 3+4 in ParcPlace Smalltalk <ref> [19] </ref>. 1. Slots in Self provide the functionality of instance variables, parents, formal arguments, and local variables. 3 1.3 Contributions In this paper we propose a new algorithm for analyzing parametric polymorphism. <p> Vitek et al. [25] described this algorithm using the concept of call strings, and Phillips and Shepard <ref> [19] </ref> applied it to ParcPlace Smalltalk. 2.5.2 The Iterative Algorithm With the iterative algorithm, Plevyak and Chien [20] broke the unfavorable precision/efficiency trade-off inherent in the expansion algorithms. They simultaneously improved precision and efficiency by allowing a variable amount of expansion in different parts of the program. <p> Analogous to analyzing parametric polymorphism by copying methods, these algorithms copy classes in an attempt to keep different uses of (data) polymorphic instance variables separate. For example, Oxhj et al. proposed a 1-level class expansion [17], Phillips and Shepard generalized this to p levels <ref> [19] </ref>, and Plevyak and Chien developed an iterative algorithm [20]. While CPA itself does not address data polymorphism, neither does it conict with the existing algorithms for analyzing data polymorphism. Hence, it is practical to combine CPA with any of these algorithms to obtain a comprehensive type inference system.
Reference: 20. <author> Plevyak, J. and A.A. Chien, </author> <title> Precise Concrete Type Inference for Object-Oriented Languages. </title> <booktitle> In OOPSLA94, Object-Oriented Programming Systems, Languages and Applications, p. </booktitle> <pages> 324-340, </pages> <address> Portland, Oregon, </address> <month> Oct. </month> <year> 1994. </year> <month> 19 </month>
Reference-contexts: Given that explicit concrete type declarations are undesirable, the considerable interest in inference algorithms is not surprising <ref> [3, 11, 17, 18, 19, 20, 25] </ref>. Ironically, while the desire to maximize polymorphism demands type inference, polymorphism is also the hardest challenge for inference algorithms. <p> To ensure soundness, a constraint must be generated for every possible data ow in the target program [1]. Different languages have different constructs that produce data ows, but some general examples can be given (more examples are found in <ref> [1, 3, 17, 18, 20] </ref>): Assignments generate data ows from the new value expressions to the assigned variables (Figure 2). Variable reads generate data ows from the accessed variables to the accessing expressions. <p> Vitek et al. [25] described this algorithm using the concept of call strings, and Phillips and Shepard [19] applied it to ParcPlace Smalltalk. 2.5.2 The Iterative Algorithm With the iterative algorithm, Plevyak and Chien <ref> [20] </ref> broke the unfavorable precision/efficiency trade-off inherent in the expansion algorithms. They simultaneously improved precision and efficiency by allowing a variable amount of expansion in different parts of the program. <p> Finally, it can be hard to know when to stop iterating. In principle, once pr, where r is the length of the longest polymorphic call chain, no further precision improvements are possible. In reality, the situation is more complex, due to block specialization and recursion <ref> [20] </ref> (see also the appendix). 9 3 The Cartesian Product Algorithm The previous algorithms aim to obtain precision and efficiency by partitioning sends according to the types of their actual arguments. <p> On the one hand, precision improves, enabling the analysis to stay 3. We have not implemented the iterative algorithm for Self, hence cannot include it in the following direct comparison. We have refrained from comparing with the numbers published by Plevyak <ref> [20] </ref> because his system is implemented in a different language than Self (possibly less efficient), and he analyzes different benchmarks, written in a different language. 4. The pure form of the iterative algorithm would also need the patch, since the first iteration is the basic algorithm. <p> For example, Oxhj et al. proposed a 1-level class expansion [17], Phillips and Shepard generalized this to p levels [19], and Plevyak and Chien developed an iterative algorithm <ref> [20] </ref>. While CPA itself does not address data polymorphism, neither does it conict with the existing algorithms for analyzing data polymorphism. Hence, it is practical to combine CPA with any of these algorithms to obtain a comprehensive type inference system.
Reference: 21. <author> Plevyak, J., X. Zhang, and A.A. Chien, </author> <title> Obtaining Sequential Efficiency in Concurrent Object-Oriented Programs. </title> <booktitle> In Conference Record of the 22nd Symposium on Principles of Programming Languages, p. </booktitle> <pages> 311-321, </pages> <address> San Francisco, California, </address> <month> Jan. </month> <year> 1995 </year>
Reference-contexts: Concrete types are the focus of this paper. Previous publications have argued that they directly support solutions to several important problems in object-oriented programming environments: Compilation. Concrete types support important optimizations such as elimination of dynamic dispatch and method inlining <ref> [17, 21] </ref>. Extraction. Concrete types support delivery of compact applications by enabling an extractor to sift through an image of objects, selecting those that are essential to run a given application [4]. Browsing/debugging.
Reference: 22. <author> Sanella, M., J. Maloney, B. Freeman-Benson, A. Borning, </author> <title> Multi-way versus One-way Constraints in User Interfaces: Experience with the DeltaBlue Algorithm. </title> <journal> Software - Practice and Experience, </journal> <volume> 23(5), </volume> <pages> p. 529-566, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: We applied the six inference algorithms to four existing programs in the Self system: Factorial: invocation of the recursive factorial function shown in the introduction. Richards: an operating system simulator [7]. Deltablue: a multi-way constraint solver <ref> [22] </ref>. Diff: Mario Wolczkos Self version of the Unix diff command [12].
Reference: 23. <author> Suzuki, N., </author> <title> Inferring Types in Smalltalk, </title> <booktitle> In Conference Record of the Eighth Annual ACM Symposium on Principles of Programming Languages, p. </booktitle> <pages> 187-199, </pages> <address> Williamsburg, Virginia, </address> <month> Jan. </month> <year> 1981. </year>
Reference-contexts: Finally, Section 2.5 reviews how previous algorithms deal with polymorphism. A more detailed and complete version of this background material is found in [1]. 2.1 Definition of Type In the introduction we informally presented types as sets of classes, following Suzuki and Johnson <ref> [23, 15] </ref>. Since Self is prototype-based and has no classes we need to modify the definition of type slightly. A Self program is a finite set of objects (prototypes) -w 1 , w 2 , ..., w n -.
Reference: 24. <author> Ungar, D. and R.B. Smith, </author> <title> SELF: The Power of Simplicity. </title> <journal> Lisp and Symbolic Computing, </journal> <volume> 4(3), </volume> <pages> p. 187-205, </pages> <publisher> Klu-wer Academic Publishers, </publisher> <month> June </month> <year> 1991. </year> <note> (Originally published in Proc. OOPSLA87). </note>
Reference-contexts: Finally, an appendix briey lists a number of issues that lack of space prevents us from discussing in detail. 2 Background The algorithms we describe are language independent, but we use Self as a source for examples and measurements <ref> [2, 24] </ref>. Detailed knowledge of Self is not required, although basic familiarity with Self or Small-talk syntax and programming style is helpful. This section reviews background material. Section 2.1 defines concrete types in a prototype-based context. Section 2.2 describes the basic type inference algorithm as a ow analysis.
Reference: 25. <author> Vitek, J., N. Horspool, and J.S. Uhl, </author> <title> Compile-Time Analysis of Object-Oriented Programs. </title> <booktitle> In Compiler Construction 4th International Conference, </booktitle> <address> CC92, p. 236-250, Paderborn, Germany, Oct. 1992, </address> <publisher> Springer-Verlag LNCS 641. </publisher>
Reference-contexts: Given that explicit concrete type declarations are undesirable, the considerable interest in inference algorithms is not surprising <ref> [3, 11, 17, 18, 19, 20, 25] </ref>. Ironically, while the desire to maximize polymorphism demands type inference, polymorphism is also the hardest challenge for inference algorithms. <p> In general, a p-level expansion algorithm is precise if polymorphic call chains are at most p calls deep, but the worst-case complexity is exponential in p since each expansion incurs a quadratic cost increase [17]. Vitek et al. <ref> [25] </ref> described this algorithm using the concept of call strings, and Phillips and Shepard [19] applied it to ParcPlace Smalltalk. 2.5.2 The Iterative Algorithm With the iterative algorithm, Plevyak and Chien [20] broke the unfavorable precision/efficiency trade-off inherent in the expansion algorithms.
References-found: 25

