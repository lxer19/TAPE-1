URL: http://www.cs.ucla.edu/~pazos/pub/ICATM98.ps
Refering-URL: http://www.cs.ucla.edu/~pazos/publications.html
Root-URL: http://www.cs.ucla.edu
Email: fpazos,gerlag@cs.ucla.edu giancarlo.rigolio@italtel.it  
Title: Flow Control and Bandwidth Management in Next Generation Internets  
Author: Carlos M. Pazos Mario Gerla Giancarlo Rigolio (flfl) 
Address: Los Angeles 405 Hilgard Ave., Los Angeles, CA 90024  Settimo Milanese Italy  
Affiliation: Computer Science Department University of California,  (flfl) Italtel Central R&D Labs.  
Abstract: The Internet has traditionally relied on end-to-end congestion control performed at the transport layer, where sources reduce their offered traffic only after congestion sets in. By then, network resources have been wasted and effective throughput compromised. In next generation Internets, the delay-bandwidth product is large and bandwidth is a precious resource. Hence, in this paper we present a link layer flow control for Internet backbones over ATM using the ABR service and flow control. We describe a backpressure mechanism that reduces packet losses and promotes effective utilization of allocated and unused resources along backbone links. We then show how to perform dynamic renegotiation of allocated backbone resources based on our flow control approach and on Class Based Queueing. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> ATM Forum Technical Committee. </author> <title> Traffic management specifications, </title> <note> version 4.0. </note> <month> April </month> <year> 1996. </year>
Reference-contexts: 1 Introduction There are two prevailing options for transporting Internet traffic over ATM networks: Virtual Circuit Connections (VCCs) with user selectable service category (CBR, VBR, ABR and UBR <ref> [1] </ref>) between communicating hosts; or ATM-based backbones with CBR Virtual Path Connections (VPCs). In evaluating these, and possibly other options, critical performance criteria are the efficient utilization of ATM trunks and the support of Internet guaranteed bandwidth and delay services. <p> Note that in order to avoid such loses, we need to selectively slow down the traffic flows ad and bd at the respective sources. This is clearly a hard problem to solve unless an end-to-end feedback mechanism such as the ABR flow control <ref> [1] </ref> is employed. However, the large delay-bandwidth product associated with backbone links and the large Round Trip Delays (RTDs), to which such end-to-end feedback may be subjected, compromise the efficiency of such approach. <p> All complexity is actually shifted to the ATM transport and signalling while requiring no new ATM features other than those already provided by ATM Forum standards <ref> [1] </ref>. 3 The Network Scenario In this paper we address the congestion control problem in next generation Internets and we describe a solution for the IP over ATM backbone scenario, a realistic one since it is common practice today. <p> A VS is continuously informed of the bandwidth available along its associated VPC path through Explicit Rate (ER) indications on a stream of Resource Management (RM) cells the VS injects along with the data stream to the corresponding VD, which then returns the RM cells back to the VS <ref> [1] </ref>. While ABR protects the VPC path from congestion, it does not prevent congestion at the terminating router acting as VD. For instance, if all VSs transmit at the available rate on the respective VPCs, some routers, say router 3 in Figure 4 (a), may become congested and drop packets.
Reference: [2] <author> R. Braden, D. Clark, and S. Shenker. </author> <title> Integrated services in the Internet architecture: an overview. Request for Comments 1633, </title> <month> June </month> <year> 1994. </year>
Reference-contexts: In evaluating these, and possibly other options, critical performance criteria are the efficient utilization of ATM trunks and the support of Internet guaranteed bandwidth and delay services. The latter criterion is important since the future Internet is expected to provide an Integrated Services (IS) transport <ref> [2] </ref>.
Reference: [3] <author> D. Katz, D. Piscitello, B. Cole, and J. Luciani. </author> <title> NBMA next hop resolution protocol (NHRP). </title> <type> Internet Draft, </type> <month> October </month> <year> 1997. </year>
Reference-contexts: The latter criterion is important since the future Internet is expected to provide an Integrated Services (IS) transport [2]. With VCCs between communicating hosts, three problems must be dealt with: IP to ATM address resolution <ref> [3, 4] </ref>; Internet to ATM service mapping [5]; and the support of RSVP heterogeneous receivers [6]. fl This work has been partially carried out in the framework of the PeterPan project, funded by the European Commission under the ACTS programme.
Reference: [4] <institution> ATM Forum Technical Committee. Baseline text for MPOA. </institution> <month> September </month> <year> 1996. </year>
Reference-contexts: The latter criterion is important since the future Internet is expected to provide an Integrated Services (IS) transport [2]. With VCCs between communicating hosts, three problems must be dealt with: IP to ATM address resolution <ref> [3, 4] </ref>; Internet to ATM service mapping [5]; and the support of RSVP heterogeneous receivers [6]. fl This work has been partially carried out in the framework of the PeterPan project, funded by the European Commission under the ACTS programme.
Reference: [5] <author> M. Borden, E. Crawley, B. Davie, and S. Batsell. </author> <title> Integration of real-time services in an IP-ATM network architecture. Request for Comments 1821, </title> <month> August </month> <year> 1995. </year>
Reference-contexts: The latter criterion is important since the future Internet is expected to provide an Integrated Services (IS) transport [2]. With VCCs between communicating hosts, three problems must be dealt with: IP to ATM address resolution [3, 4]; Internet to ATM service mapping <ref> [5] </ref>; and the support of RSVP heterogeneous receivers [6]. fl This work has been partially carried out in the framework of the PeterPan project, funded by the European Commission under the ACTS programme. It was also funded by GTE. y Bolsista do CNPq Braslia/Brasil.
Reference: [6] <author> E. Crawley, L. Berger, S. Berson, F. Baker, M. Borden, and J. Krawczyk. </author> <title> A framework for integrated services and RSVP over ATM. </title> <type> Internet Draft, </type> <month> November </month> <year> 1997. </year>
Reference-contexts: With VCCs between communicating hosts, three problems must be dealt with: IP to ATM address resolution [3, 4]; Internet to ATM service mapping [5]; and the support of RSVP heterogeneous receivers <ref> [6] </ref>. fl This work has been partially carried out in the framework of the PeterPan project, funded by the European Commission under the ACTS programme. It was also funded by GTE. y Bolsista do CNPq Braslia/Brasil.
Reference: [7] <author> C. M. Pazos and M. Gerla. </author> <title> ATM virtual private networks for the Internet data traffic. </title> <booktitle> In Proc. of MMNS '97, </booktitle> <address> Montreal, Canada, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: While this would not pose a major problem in an ATM LAN (the traffic is homogeneous, mostly BE), in ATM MANs/WANs the performance experienced by the Internet BE traffic will fluctuate, depending on the load of higher priority CBR and VBR traffic <ref> [7] </ref>. On the other hand, with Internet backbones, routers are connected by a VPC mesh topology and each VPC is preallocated a peak bandwidth via the CBR service category. Hence, network resources are reserved for the aggregate Internet traffic, regardless of other CBR or VBR traffic load. <p> If instead we used an ABR VPC to interconnect the two routers in Figure 2, we could apply the ABR flow control to the VPC connecting the routers as proposed in <ref> [7, 13] </ref>. With this approach, routers are notified of the bandwidth actually available along the VPC path and supported by the router at the other end of the VPC while the offered traffic load is actually bounded by this available bandwidth. <p> As a result, the use of ABR provides a more reliable link layer than GFR. In this paper we build on the approach in <ref> [7, 13] </ref> in which the ABR service category is used in backbones and the routers function as virtual sources and virtual destinations for the ABR flow control. <p> Conversely, if the BE and RT load is insufficient to fully utilize MCR on a VPC, the MCR should be reduced. In <ref> [7] </ref> we considered dynamic MCR adjustments in a single class scenario.
Reference: [8] <author> P. Newman, T. Lyon, and G. Minshall. </author> <title> Flow labeled IP: A connectionless approach to ATM. </title> <booktitle> In Proc. INFOCOM `96, </booktitle> <month> March </month> <year> 1996. </year>
Reference-contexts: Both problems can be overcome by combining switching technology and IP routing intelligence by means of label swapping in the routers <ref> [8, 9] </ref>. When label swapping is applied to routers using ATM link layer, the IP packets are segmented into ATM cells at an edge router and they are switched by most Label Swapping Routers (LSRs) directly at level 2 using the cells VPI/VCI fields as labels.
Reference: [9] <author> R. Callon, P. Doolan, N. Feldman, A. Fredette, G. Swallow, and A. Viswanathan. </author> <title> A framework for multiprotocol label switching. </title> <type> Internet Draft, </type> <month> November </month> <year> 1997. </year>
Reference-contexts: Both problems can be overcome by combining switching technology and IP routing intelligence by means of label swapping in the routers <ref> [8, 9] </ref>. When label swapping is applied to routers using ATM link layer, the IP packets are segmented into ATM cells at an edge router and they are switched by most Label Swapping Routers (LSRs) directly at level 2 using the cells VPI/VCI fields as labels.
Reference: [10] <author> S. Floyd and V. Jacobsen. </author> <title> Link-sharing and resource management models for packet networks. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 3(4), </volume> <month> August </month> <year> 1995. </year>
Reference-contexts: In this paper we address the congestion control problem in next generation Internets and we describe a framework that combines the ATM ABR service category and Class Based Queueing (CBQ) <ref> [10] </ref>. The use of ABR allows the recovery of unused bandwidth along a VPC path while providing us with some means to implement a backpressure flow control that alleviates the congestion of Figure 1. <p> Our interest is on the aggregate streams for each class because we exercise back-pressure on the aggregate traffic sent between routers. The RT traffic is given priority over the BE traffic on edge and backbone routers by a Class Based Queueing (CBQ) <ref> [10] </ref> scheduler. We also assume that RSVP and some form of flow admission control are employed to allocate the RT traffic flows appropriate bandwidth on VPs such that RT constraints can be guaranteed. <p> Each class (queue) is granted access to its allocated share of bandwidth and no class is denied access for long periods of time. This means that under no congestion the CBQ scheduler implements Weighted Fair Queueing while during congestion it enforces a link sharing policy <ref> [10] </ref>. Hence, the scheduler knows how much bandwidth has been assigned to each class and it measures how much bandwidth each class is actually using in order to enforce the link sharing policy. <p> The issue is then how to determine the ff on Figure 7 (b) such that the aggregate BE and RT traffic experience the best performance (e.g., throughput for BE traffic and QoS guarantees for RT traffic) while maximizing the utilization of ATM resources. The CBQ scheduler, as proposed in <ref> [10] </ref>, only enforces a fixed valued ff such that no class is deprived of its allocated resources for long periods of time. While this approach prevents starvation of traffic classes, other performance factors are sacrificed as a result. <p> In the following, we address the multi-class case by building on the CBQ approach to bandwidth scheduling. 5.2 Triggering Bandwidth Renegotiations As reproduced in the legend of Figure 8, CBQ classes can be characterized as overlimit, underlimit, unsatisfied and to-be-regulated. This characterization is extensively discussed in <ref> [10] </ref>, but in few words we can say that a class is allocated a given share of the available resources according to some link sharing policy, over or underlimit if it is transmitting above or below its allocated share, respectively; a class is satisfied if it has no backlog (queue in <p> However, in <ref> [10] </ref> the link class (VP class in Figure 8) can never become overlimit (a link cannot carry more traffic than that accommodated by its allocated bandwidth), which is the case if we had CBR VPCs. <p> On this figure, we consider that the VP class has two subclasses, say RT (A) and BE (B), each of which has two subclasses of their own, say video (A1) and circuit emulation (A2), and ftp (B1) and e-mail (B2), respectively. As it is pointed out in <ref> [10] </ref>, under no congestion, the CBQ scheduler behaves just like a weighted fair queueing scheduler. Under congestion (e.g., the scenarios on Cases 1 and 24 2 of Figure 8), the CBQ scheduler switches to a link sharing mode to enforce each class access to its allocated share of bandwidth. <p> In our ABR context, this means that when a VPC path is congested, the ER is restricted to the allocated MCR along 2 There are other possible scenarios that can be found in <ref> [10] </ref> and in an upcoming technical report. The ones presented here are for illustrative purposes only. the path. The presence of underlimit and unsatisfied classes forces overlimit classes to be regulated back to their allocated bandwidth limits.
Reference: [11] <author> A. Romanow and S. Floyd. </author> <title> Dynamic of TCP traffic over ATM networks. </title> <booktitle> In ACM SIGCOMM `94, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: Hence, cells (and as a result packets) may be dropped at the bottleneck switch due to GFR buffer overflow. These losses cannot be prevented and efficient packet dropping mechanisms such as Early Packet Discard have to be added to ATM switches to avoid the throughput collapse of TCP traffic <ref> [11, 12] </ref>. Hence, with GFR routers can recover the unused bandwidth and thus alleviate congestion, but excess packets can still be dropped and the GFR service category does not give us any means to address the congestion control problem at level 2.
Reference: [12] <author> F. Chiussi, Y. Xia, and V. Kumar. </author> <title> Virtual queueing techniques for ABR service: Improving ABR/VBR interaction. </title> <booktitle> In Proc. INFOCOM `97, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: Hence, cells (and as a result packets) may be dropped at the bottleneck switch due to GFR buffer overflow. These losses cannot be prevented and efficient packet dropping mechanisms such as Early Packet Discard have to be added to ATM switches to avoid the throughput collapse of TCP traffic <ref> [11, 12] </ref>. Hence, with GFR routers can recover the unused bandwidth and thus alleviate congestion, but excess packets can still be dropped and the GFR service category does not give us any means to address the congestion control problem at level 2.
Reference: [13] <author> C. M. Pazos and M. Gerla. </author> <title> Bandwidth efficiency in Internet AVPNs. </title> <booktitle> In Proc. of GLOBECOM '97, </booktitle> <month> November </month> <year> 1997. </year>
Reference-contexts: If instead we used an ABR VPC to interconnect the two routers in Figure 2, we could apply the ABR flow control to the VPC connecting the routers as proposed in <ref> [7, 13] </ref>. With this approach, routers are notified of the bandwidth actually available along the VPC path and supported by the router at the other end of the VPC while the offered traffic load is actually bounded by this available bandwidth. <p> As a result, the use of ABR provides a more reliable link layer than GFR. In this paper we build on the approach in <ref> [7, 13] </ref> in which the ABR service category is used in backbones and the routers function as virtual sources and virtual destinations for the ABR flow control.
Reference: [14] <author> V. Paxson. </author> <title> Empirically-derived analytic models of wide-area TCP connections: </title> <type> Extended report. Technical report, </type> <institution> Lawrence Berkeley Laboratory, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: On the other hand, we consider the BE traffic being mostly TCP traffic, since it is responsible for the bulk of BE traffic transported over the Internet today. TCP sessions are usually short-lived (some 90% of them transfer less than 20kB <ref> [14] </ref>) and TCP source cannot usually declare their performance and resources requirements. Since no resource is committed for such traffic, current TCP implementations test for the availability of resource by increasingly sending more packets. <p> Our main concern here is to illustrated the effectiveness of our backpressure when we have many simultaneously active TCP sessions. Furthermore, we take into account the fact that most such sessions transmitt only a few KBytes worth of data <ref> [14] </ref>, in our study they transmit 31KBytes. The typical performance problem in this scenario results from the TCP dynamics, especially during the slow start phase when the transmission window is doubled every round trip time 1 .
Reference: [15] <author> S. Floyd. </author> <title> TCP and explicit congestion notification. </title> <journal> ACM Computer Communication Review, </journal> <volume> 24(5), </volume> <month> October </month> <year> 1995. </year>
Reference-contexts: Packets must then be dropped for the transmission window to be reduced and the source rate to be controlled. The dropping of packets is very undesirable because it can lead to global synchronization and throughput collapse, and it compromises the performance of delay sensitive traffic (e.g., telnet) <ref> [15, 16] </ref>. Besides, depending on when congestion hits, the drop of packets may come too late if the source has already sent out all the data it intended to (i.e., short lived sessions).
Reference: [16] <author> R. Morris. </author> <title> TCP behavior with many flows. </title> <booktitle> In Proc. of ICNP '97, </booktitle> <month> October 97. </month>
Reference-contexts: Packets must then be dropped for the transmission window to be reduced and the source rate to be controlled. The dropping of packets is very undesirable because it can lead to global synchronization and throughput collapse, and it compromises the performance of delay sensitive traffic (e.g., telnet) <ref> [15, 16] </ref>. Besides, depending on when congestion hits, the drop of packets may come too late if the source has already sent out all the data it intended to (i.e., short lived sessions). <p> In a scenario with many sources, they experince packet losses during slow start and it has been demonstrated that some 50% of the packets are droped <ref> [16] </ref>. If sessions are short lived, they may never transition into the congestion avoidance phase. Such short-lived sessions are typical of Web transaction in which a new TCP slow-start is triggered for every new page accessed. <p> This is clearly inefficient and the works in [18, 19] discuss approaches to share the TCP state among similar concurrent sessions. The net effect is an improved response time for a user browsing the web when the network is not congested. However, when many (in the order of thousand <ref> [16] </ref>) sessions are simultaneously active, they are likely to originate from 1 The TCP packets are 1Kbyte, hence with 31Kbytes the sources can double their transmission widows only 5 times during slow start. many different hosts and these approaches do not address the performance degradation when packets are actually dropped and
Reference: [17] <author> D. Bertsekas and R. Gallager. </author> <title> Data Networks. </title> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: Obviously, if an input port does not have enough traffic to send, its allocated fair share is wasted. This problem can be solved or alleviated if the fair share computation in Eq. (1) takes into account max-min fairness <ref> [17] </ref>. Max-min fair allocation involves measuring the BE traffic contribution from each input port and allocating fair shares to input ports based on whether they have traffic to use the fair shares. Max-min fairness in this scenario will be discussed in an upcoming paper.
Reference: [18] <author> John Heidemann. </author> <title> Performance interactions between p-http and tcp implementations. </title> <journal> ACM Computer Communication Review, </journal> <month> April </month> <year> 1997. </year>
Reference-contexts: If sessions are short lived, they may never transition into the congestion avoidance phase. Such short-lived sessions are typical of Web transaction in which a new TCP slow-start is triggered for every new page accessed. This is clearly inefficient and the works in <ref> [18, 19] </ref> discuss approaches to share the TCP state among similar concurrent sessions. The net effect is an improved response time for a user browsing the web when the network is not congested.
Reference: [19] <author> J. </author> <title> Touch. TCP control block interdependence. Request for Comments 2140, </title> <month> April </month> <year> 1997. </year>
Reference-contexts: If sessions are short lived, they may never transition into the congestion avoidance phase. Such short-lived sessions are typical of Web transaction in which a new TCP slow-start is triggered for every new page accessed. This is clearly inefficient and the works in <ref> [18, 19] </ref> discuss approaches to share the TCP state among similar concurrent sessions. The net effect is an improved response time for a user browsing the web when the network is not congested.
References-found: 19

