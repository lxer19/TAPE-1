URL: http://www.cs.umr.edu/techreports/95-01.ps
Refering-URL: http://www.cs.umr.edu/techreports/
Root-URL: 
Email: e-mail: fcserban, ffg@cs.umr.edu  
Title: From Formal Security Specifications to Executable Assertions A Distributed Systems Preliminary Study  
Author: Cristina Serban and Bruce McMillin 
Address: Rolla, MO 65401, USA  
Affiliation: Department of Computer Science University of Missouri-Rolla  
Date: April 27, 1995  
Pubnum: CSC 95-01  
Abstract: A security policy for a distributed system can be checked for compliance at run-time, as the system executes, using assertions embedded in software. This paper presents the concept of run-time security assurance, according to a given security policy for a given distributed system, along with mechanisms for its usage. A model problem illustrates the implementation of executable security assertions and their run-time validation on histories (traces) of events. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Alpern and F. Schneider. </author> <title> Defining liveness. </title> <journal> Information Processing Letters, </journal> <volume> 21(4) </volume> <pages> 181-185, </pages> <year> 1985. </year>
Reference-contexts: One problem of principle arises though when considering traces for security properties evaluation: as McLean points out in [6], possibilistic security properties are not properties of traces, but properties of trace sets, and thus they are not amenable to the Alpern-Schneider framework <ref> [1] </ref>. This theoretical difficulty needs to be considered, and its solution for our approach will be exposed in section 4. 3 Problem Environment The distributed environment we consider is the most general one, composed of nodes, which are autonomous processors with local memory, connected by an interprocessor connection.
Reference: [2] <author> E. Arrowsmith and B.M. McMillin. </author> <title> How to program in CCSP. </title> <type> Technical Report CSC-94-20, </type> <institution> University of Missouri - Rolla, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: For programming we used CCSP <ref> [2] </ref>, an in-house developed tool that offers CSP-like syntax on top of a C environment.
Reference: [3] <author> C.A.R. Hoare. </author> <title> Communicating Sequential Processes. </title> <booktitle> Prentice-Hall International, </booktitle> <address> London, UK, </address> <year> 1985. </year>
Reference-contexts: Each node runs its own independent process, which is a sequential program. Interprocess communication is provided solely via message passing. Nodes and/or inter-processor connections may fail or be compromised during the operation of the system. The general programming model we adopt for this type of environment is CSP <ref> [3] </ref>, in which programs for the whole system are composed of a set of communicating sequential processes, with each single process having a local state, and the global program being seen as the parallel composition of the independent processes.
Reference: [4] <author> J. Jacob. </author> <title> Basic theorems about security. </title> <journal> Journal of Computer Security, </journal> <volume> 1(3-4):385-411, </volume> <year> 1992. </year>
Reference-contexts: The idea of treating system properties uniformly, using similar concepts and tools for each type of properties, appears in different forms in the literature (see for example 2 Jacob <ref> [4] </ref> and more recently Rushby [9]), but it is usually directed at methods for proving a system's design or implementation are correct, in a formal treatment. One of these common concepts is the use of traces; the evaluation of properties of interest is done on system traces and trace sets.
Reference: [5] <author> J. McLean. </author> <title> Proving noninterference and functional correctness using traces. </title> <journal> Journal of Computer Security, </journal> <volume> 1(1) </volume> <pages> 37-58, </pages> <year> 1992. </year>
Reference-contexts: One of these common concepts is the use of traces; the evaluation of properties of interest is done on system traces and trace sets. For security, such a method is presented, for instance, by McLean <ref> [5] </ref> for proving noninterference and functional correctness using traces, as well as a trace specification language for the software development process.
Reference: [6] <author> J. McLean. </author> <title> A general theory of composition for trace sets closed under selective interleaving functions. </title> <booktitle> In Proceedings of the IEEE Symposium on Research in Security and Privacy, </booktitle> <address> Oakland, CA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: These violations of the specifications are clearly errors. Thus, detecting such errors must be a goal for security sensitive systems' implementors. One problem of principle arises though when considering traces for security properties evaluation: as McLean points out in <ref> [6] </ref>, possibilistic security properties are not properties of traces, but properties of trace sets, and thus they are not amenable to the Alpern-Schneider framework [1]. <p> An additional, significant benefit of this approach is the narrowing of the trace space, practically eliminating the problem mentioned in section 2 about security properties being properties of trace sets, not properties of traces <ref> [6] </ref>. This problem does not actually exist if the space under consideration is not the space of all possible traces, but only its instantiation to the current execution of the system, and in this case uniform treatment can be used for security, safety, and liveness properties.
Reference: [7] <author> C. O'Halloran. </author> <title> On requirements and security in a CCIS. </title> <booktitle> In Proceedings of the Computer Security Foundations Workshop V, </booktitle> <pages> pages 121-134, </pages> <address> Franconia, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: The chosen model is based on the CCIS Boots case study, introduced by Colin O'Halloran in his doctoral thesis [8], and also as a paper <ref> [7] </ref>. <p> The audit trail must not be corrupted. 4. The window Operator must not know the audit trail. 5. The Security officer must not know the content of messages passed between users. In the original work <ref> [7, 8] </ref> these security requirements for the Boots system are formalized under the author's calculus for security and the resulting security requirements labeled SR1 through SR5 are presented now. 7 The language for this calculus consists of confidentiality statements and operations for combining them.
Reference: [8] <author> C. O'Halloran. </author> <title> Category Theory and Information Flow Applied to Computer Security. </title> <type> PhD thesis, </type> <institution> University of Oxford, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: The chosen model is based on the CCIS Boots case study, introduced by Colin O'Halloran in his doctoral thesis <ref> [8] </ref>, and also as a paper [7]. <p> The audit trail must not be corrupted. 4. The window Operator must not know the audit trail. 5. The Security officer must not know the content of messages passed between users. In the original work <ref> [7, 8] </ref> these security requirements for the Boots system are formalized under the author's calculus for security and the resulting security requirements labeled SR1 through SR5 are presented now. 7 The language for this calculus consists of confidentiality statements and operations for combining them.
Reference: [9] <author> J. Rushby. </author> <title> Critical system properties: Survey and taxonomy. Reliability Engineering and System Safety, </title> <booktitle> 43(2) </booktitle> <pages> 189-219, </pages> <year> 1994. </year>
Reference-contexts: The idea of treating system properties uniformly, using similar concepts and tools for each type of properties, appears in different forms in the literature (see for example 2 Jacob [4] and more recently Rushby <ref> [9] </ref>), but it is usually directed at methods for proving a system's design or implementation are correct, in a formal treatment. One of these common concepts is the use of traces; the evaluation of properties of interest is done on system traces and trace sets.
Reference: [10] <author> S.G. Tsai. </author> <title> Providing Assurance for Responsive Computing Systems. </title> <type> PhD thesis, </type> <institution> University of Missouri - Rolla, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: A recent development <ref> [10] </ref> provided temporal extensions for CCSP.
Reference: [11] <author> H.S. Vaccaro and G.E. Liepins. </author> <title> Detection of anomalous computer session activity. </title> <booktitle> In Proceedings of the IEEE Symposium on Research in Security and Privacy, </booktitle> <pages> pages 280-289, </pages> <address> Oakland, CA, </address> <month> May </month> <year> 1989. </year> <month> 18 </month>
Reference-contexts: Conversely, this means that any violation of the security policy is an error and the security policy, if evaluated at run time against the implemented system, provides error detection with respect to the security specifications. For example, intrusion detection <ref> [11] </ref> is formally defined as identifying those events generated by the misuse of computer systems.
References-found: 11

