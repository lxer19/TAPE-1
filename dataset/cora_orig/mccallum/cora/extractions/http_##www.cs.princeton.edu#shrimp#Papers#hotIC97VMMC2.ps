URL: http://www.cs.princeton.edu/shrimp/Papers/hotIC97VMMC2.ps
Refering-URL: http://www.cs.princeton.edu/shrimp/html/papers_stack_5.html
Root-URL: http://www.cs.princeton.edu
Email: lig@cs.princeton.edu  
Title: VMMC-2: Efficient Support for Reliable, Connection-Oriented Communication  
Author: Cezary Dubnicki, Angelos Bilas, Yuqun Chen, Stefanos Damianakis, and Kai Li 
Address: Princeton, NJ-08544 fdubnicki, bilas, yuqun, snd,  
Affiliation: Computer Science Department, Princeton University,  
Abstract: The basic virtual memory-mapped communication (VMMC) model provides protected, direct communication between the sender's and receiver's virtual address spaces, but it does not support high-level connection-oriented communication APIs well. This paper presents VMMC-2, an extension to the basic VMMC. We describe the design, implementation, and evaluate the performance of three mechanisms in VMMC-2: (1) a user-managed TLB mechanism for address translation which enables user libraries to dynamically manage the amount of pinned space and requires only driver support from many operating systems; (2) a transfer redirection mechanism which avoids copying on the receiver's side; (3) a reliable communication protocol at the data link layer which avoids copying on the sender's side. To validate our extensions we implemented stream sockets on top of the VMMC-2 running on a Myrinet network of Pentium PCs. This zero-copy sockets implementation provides a maximum bandwidth of over 84 Mbytes/s and a one-way latency of 20 s. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Alpert, C. Dubnicki, E.W. Felten, and K. Li. </author> <title> Design and Implementation of NX Message Passing Using Shrimp Virtual Memory-Mapped Communication. </title> <booktitle> In Proceedings of the 1996 International Conference on Parallel Processing, </booktitle> <pages> pages 111-119, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: The common framework is to implement a user-level data transport protocol that integrates well with the network interface. Existing high-level protocols for shared virtual memory [21] and message-passing <ref> [1, 5, 14, 32] </ref> can then be implemented efficiently. The goal is to deliver to the user communication performance close to the hardware's limit while providing the full functionality of the high-level APIs. This paper addresses three of the important issues associated with this goal. <p> On the other hand, high-level connection-oriented APIs such as stream sockets do not have destination addresses on the sending side; a sender knows only the name of the connection. As a result, zero-copy protocols typically require a scout message or a handshake in the implementation <ref> [1, 14, 32] </ref>. In this paper, we propose, implement and evaluate a mechanism called transfer redirection. We show that this mechanism naturally extends the virtual memory-mapped communication model and provides support for connection-oriented APIs to achieve zero-copy without any additional messages. <p> In this approach the receiver informs the sender about the receive buffer, after which the sender is able to transfer data directly into it. Variants of this protocol have been used by NX implementation on Paragon [31] as well as early NX implementation 3 on VMMC <ref> [1] </ref>. Active Messages (AM) [19] is a user-level communication mechanism based on fast remote execution facility. Recently, a fast sockets facility has been built with AM handlers [32]. They used a receiver-based approach called receive posting.
Reference: [2] <author> J. Asplin and S. Mehus. </author> <title> On the Design and Performance of the PARFUM Parallel Fault Tolerant Volume Renderer. </title> <type> Technical Report 97-28, </type> <institution> Univerity of Tromso, Norway, </institution> <month> Jan-uary </month> <year> 1997. </year>
Reference-contexts: We measured the bandwidth of this operation to be 25 MBytes/s, so even with infinitely fast network the bandwidth of tftp would be limited to this number. The maximum bandwidth achieved by VMMC-2 sockets is 19 MBytes/s. 7.3.2 PARFUM The PARFUM Parallel Fault Tolerant Volume Renderer <ref> [2] </ref> is a dynamically load-balanced parallel volume renderer executing in a distributed environment. PARFUM is based on a traditional ray-casting algorithm for rendering volumetric data sets.
Reference: [3] <author> A. Basu, Buch V, Vogels W, and von Eicken T. U-Net: </author> <title> A User-Level Network Interface for Parallel and Distributed Computing. </title> <booktitle> Proceedings of the 15th ACM Symposium on Operating Systems Principles (SOSP), </booktitle> <address> Copper Mountain, Colorado, </address> <pages> pages 40-53, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: During the last few years, researchers have proposed several approaches to move network protocols partially or entirely to the user level with protection in order to reduce the protocol overhead <ref> [3, 15, 18, 19, 36] </ref>. The common framework is to implement a user-level data transport protocol that integrates well with the network interface. Existing high-level protocols for shared virtual memory [21] and message-passing [1, 5, 14, 32] can then be implemented efficiently. <p> This model has been revived by Thekkath et al. [35] using fast traps. They do not deal with the issue of supporting connection-oriented high-level protocols. Druschel et al. [15] proposed the concept of application device channels which provide protected user-level access to a network interface. U-Net <ref> [3] </ref> uses a similar abstraction to support high-level protocols such as TCP/IP. Their implementation requires applications to use special, pinned buffers. Hamlyn [9] implements a sender-based communication model and uses the network interface to support user-level message passing, but it requires application programs to build headers using pinned memory.
Reference: [4] <author> Anindya Basu, Matt Welsh, and Thorst von Eicken. </author> <title> Incorporating Memory Management into User-Level Network Interfaces. </title> <note> http://www2.cs.cornell.edu/U-Net/papers/unetmm.pdf, 1996. </note>
Reference-contexts: By comparison, the UTLB mechanism can deal with a large number of small buffers and allow for buffer overlapping. A typical interrupt-driven approach is used for address translation by both U-Net/MM <ref> [4] </ref> and VMMC [18]. This approach uses a global TLB on the network interface; when a TLB miss happens, the network interface interrupts the host processor which pins or pages-in the virtual page and returns the physical address to the network interface.
Reference: [5] <author> A. Bilas and E. Felten. </author> <title> Fast RPC on the SHRIMP Virtual Memory Mapped Network Interface. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> 14:to appear, </note> <month> February </month> <year> 1997. </year>
Reference-contexts: The common framework is to implement a user-level data transport protocol that integrates well with the network interface. Existing high-level protocols for shared virtual memory [21] and message-passing <ref> [1, 5, 14, 32] </ref> can then be implemented efficiently. The goal is to deliver to the user communication performance close to the hardware's limit while providing the full functionality of the high-level APIs. This paper addresses three of the important issues associated with this goal.
Reference: [6] <author> M. Blumrich, K. Li, R. Alpert, C. Dubnicki, E. Felten, and J. Sandberg. </author> <title> A Virtual Memory Mapped Network Interface for the Shrimp Multicomputer. </title> <booktitle> In Proceedings of the 21st Annual Symposium on Computer Architecture, </booktitle> <pages> pages 142-153, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: This paper addresses three of the important issues associated with this goal. The first challenging issue is how to design and implement the low-level data transport API so that high-level APIs can be implemented with little overhead and with true zero-copy protocols. A memory-mapped communication model, such as SHRIMP <ref> [6] </ref> or DEC's Memory Channel [20], requires the least software overhead because data transfers avoid receiver's CPU intervention. However, our early experience has shown that using such a low-level API to implement a high-level connection-based API like stream sockets often requires a copy on the receiver side [14]. <p> The overhead of these design choices is high. A few low-level communication interfaces assume reliable hardware and treat each network error as a catastrophic one. Examples of such approach include Fast Messages [30] and our previous work <ref> [6, 17] </ref>.
Reference: [7] <author> Nanette J. Boden, Danny Cohen, Robert E. Felderman, Alan E. Kulawik, Charles L. Seitz, Jakov N. Seizovic, and Wen-King Su. Myrinet: </author> <title> A Gigabig-per-Second Local Area Network. </title> <journal> IEEE MICRO, </journal> <volume> 15(1) </volume> <pages> 29-36, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: A copy in the network protocol can reduce the communication bandwidth to the memory copy bandwidth which is usually substantially less than the peak hardware DMA bandwidth. For example, while the Myrinet hardware is capable of delivering bandwidth of 1.28 Gbits/s <ref> [7] </ref>, the end-user applications see little performance improvement compared to the 100 Mbits/s Ethernet [25]. The desire to build high-performance servers from a network of commodity computers has pushed researchers to explore ways to reduce the communication bottleneck for system area networks.
Reference: [8] <author> J.C. Brustoloni and P. Steenkiste. </author> <title> Effects of Buffering Semantics on I/O Performance. </title> <booktitle> In Proceedings of the Second USENIX Symposium on Operating Systems Design and Implementation (OSDI), </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: IBM's OS/360 can specify a file I/O buffer area for applications to avoid copying. Page remapping has been used to avoid copying in several past and recent projects [26, 10, 22, 16, 28]. Brus-toloni and Steenkiste proposed emulated copy <ref> [8] </ref> which combines page remapping and copying of sub-page data chunks. In this technique, total amount of data copied is not more than one page regardless of user buffer size and its alignment. Lately, several groups have proposed letting applications directly access communication interface memory [11, 13, 33].
Reference: [9] <author> Greg Buzzard, David Jacobson, Milon Mackey, Scott Marovich, and John Wilkes. </author> <title> An Implementation of the Ham-lyn Sender-Managed Interface Architecture. </title> <booktitle> In Proceedings of the Second USENIX Symposium on Operating Systems Design and Implementation (OSDI), </booktitle> <pages> pages 245-260, </pages> <month> Octo-ber </month> <year> 1996. </year>
Reference-contexts: Hamlyn <ref> [9] </ref> uses a limited number of registers to identify and keep translations of pinned user buffers. This mechanism is similar to our UTLB with two key differences: (1) it limits the number of translations to the number of registers; (2) it does not allow for buffer overlapping. <p> Druschel et al. [15] proposed the concept of application device channels which provide protected user-level access to a network interface. U-Net [3] uses a similar abstraction to support high-level protocols such as TCP/IP. Their implementation requires applications to use special, pinned buffers. Hamlyn <ref> [9] </ref> implements a sender-based communication model and uses the network interface to support user-level message passing, but it requires application programs to build headers using pinned memory. They do not address the issue of supporting connection-oriented high-level protocols.
Reference: [10] <author> D. R. Cheriton. </author> <title> The Unified Management of Memory in the V Distributed System. </title> <type> Technical Report STAN-CS-88-1192, </type> <institution> Stanford University, </institution> <month> August </month> <year> 1988. </year>
Reference-contexts: Many methods have been proposed to avoid copying between I/O devices and application memory. IBM's OS/360 can specify a file I/O buffer area for applications to avoid copying. Page remapping has been used to avoid copying in several past and recent projects <ref> [26, 10, 22, 16, 28] </ref>. Brus-toloni and Steenkiste proposed emulated copy [8] which combines page remapping and copying of sub-page data chunks. In this technique, total amount of data copied is not more than one page regardless of user buffer size and its alignment.
Reference: [11] <author> Eric Cooper, Peter Steenkiste, Robert Sansom, and Brian Zill. </author> <title> Protocol Implmentation on the Nectar Communication Processor. </title> <booktitle> In Proceedings of the ACM SIGCOMM'90 Symposium, </booktitle> <month> September </month> <year> 1990. </year>
Reference-contexts: In this technique, total amount of data copied is not more than one page regardless of user buffer size and its alignment. Lately, several groups have proposed letting applications directly access communication interface memory <ref> [11, 13, 33] </ref>. However, network interface memory is usually small and non-cacheable which limits its direct use by applications. 4 User-Managed Address Translation 4.1 Description In the VMMC-2 API, a user-level send or redirect request specifies an arbitrary user buffer with a virtual memory address and size. <p> FM does not allow multiple pro-cesses to share the network access. The FM sockets implementation [30] achieves one-way latency of about 34 s and maximum bandwidth of 11 MBytes/s between two SPARC-stations connected with Myrinet. The Nectar system <ref> [11] </ref> implements TCP on their programmable network interface (16Mhz Sparc as the communication processor). Its overhead is 45 s. 9 Conclusions This paper describes the design, implementation, and performance of three mechanisms in the VMMC-2 implementation: user-managed TLB for address translation, transfer redirection, and reliable data link.
Reference: [12] <author> D. E. Culler, L. T. Liu, R. P. Martin, and C. Yoshikawa. </author> <title> LogP Performance Assessment of Fast Network Interfaces. </title> <journal> IEEE Micro, </journal> <volume> 16(1) </volume> <pages> 35-43, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: This works well as long as network errors are really extremely rare or when the packet retransmission is handled by the hardware (like S-Connect [29]). 6 VMMC-2 Performance 6.1 The logP Model We characterize the performance of our system using the five parameters of the logP model <ref> [12] </ref>: ( RT T 2 ; L; O r ; O s ; g). RT T 2 is the one-way host to host latency for a ping-pong test. O s ; O r are the host overheads of sending and receiving a message respectively.
Reference: [13] <author> C. Dalton, G.Watson, D. Banks, C. Calamvokis, A. Ed-wards, and J. Lumley. </author> <title> Afterburner. </title> <journal> IEEE Network, </journal> <volume> 7(4) </volume> <pages> 36-43, </pages> <year> 1995. </year>
Reference-contexts: In this technique, total amount of data copied is not more than one page regardless of user buffer size and its alignment. Lately, several groups have proposed letting applications directly access communication interface memory <ref> [11, 13, 33] </ref>. However, network interface memory is usually small and non-cacheable which limits its direct use by applications. 4 User-Managed Address Translation 4.1 Description In the VMMC-2 API, a user-level send or redirect request specifies an arbitrary user buffer with a virtual memory address and size.
Reference: [14] <author> S. Damianakis, A. Bilas, C. Dubnicki, </author> <title> and E.W. Felten. Client-Server Computing on Shrimp. </title> <journal> IEEE Micro, </journal> <volume> 17(1) </volume> <pages> 8-18, </pages> <month> February </month> <year> 1997. </year>
Reference-contexts: The common framework is to implement a user-level data transport protocol that integrates well with the network interface. Existing high-level protocols for shared virtual memory [21] and message-passing <ref> [1, 5, 14, 32] </ref> can then be implemented efficiently. The goal is to deliver to the user communication performance close to the hardware's limit while providing the full functionality of the high-level APIs. This paper addresses three of the important issues associated with this goal. <p> However, our early experience has shown that using such a low-level API to implement a high-level connection-based API like stream sockets often requires a copy on the receiver side <ref> [14] </ref>. This is because the basic memory-mapped communication model requires the sender to know the destination address before it sends data. On the other hand, high-level connection-oriented APIs such as stream sockets do not have destination addresses on the sending side; a sender knows only the name of the connection. <p> On the other hand, high-level connection-oriented APIs such as stream sockets do not have destination addresses on the sending side; a sender knows only the name of the connection. As a result, zero-copy protocols typically require a scout message or a handshake in the implementation <ref> [1, 14, 32] </ref>. In this paper, we propose, implement and evaluate a mechanism called transfer redirection. We show that this mechanism naturally extends the virtual memory-mapped communication model and provides support for connection-oriented APIs to achieve zero-copy without any additional messages.
Reference: [15] <author> P. Druschel, B. S. Davie, and L. L. Peterson. </author> <title> Experiences with a High-Speed Network Adapter: A Software Perspective. </title> <booktitle> In Proceedings of SIGCOMM '94, </booktitle> <pages> pages 2-13, </pages> <month> Septem-ber </month> <year> 1994. </year>
Reference-contexts: During the last few years, researchers have proposed several approaches to move network protocols partially or entirely to the user level with protection in order to reduce the protocol overhead <ref> [3, 15, 18, 19, 36] </ref>. The common framework is to implement a user-level data transport protocol that integrates well with the network interface. Existing high-level protocols for shared virtual memory [21] and message-passing [1, 5, 14, 32] can then be implemented efficiently. <p> The implementation was programmed in a processor's microcode. This model has been revived by Thekkath et al. [35] using fast traps. They do not deal with the issue of supporting connection-oriented high-level protocols. Druschel et al. <ref> [15] </ref> proposed the concept of application device channels which provide protected user-level access to a network interface. U-Net [3] uses a similar abstraction to support high-level protocols such as TCP/IP. Their implementation requires applications to use special, pinned buffers.
Reference: [16] <author> P. Druschel and L. L. Peterson. Fbufs: </author> <title> A High-Bandwidth Cross-Domain Transfer Facility. </title> <booktitle> In Proceedings of the 14th Symposium on Operating Systems Principles, </booktitle> <pages> pages 189-202, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Many methods have been proposed to avoid copying between I/O devices and application memory. IBM's OS/360 can specify a file I/O buffer area for applications to avoid copying. Page remapping has been used to avoid copying in several past and recent projects <ref> [26, 10, 22, 16, 28] </ref>. Brus-toloni and Steenkiste proposed emulated copy [8] which combines page remapping and copying of sub-page data chunks. In this technique, total amount of data copied is not more than one page regardless of user buffer size and its alignment.
Reference: [17] <author> C. Dubnicki, A. Bilas, K. Li, and J. Philbin. </author> <title> Design and Implementation of Virtual Memory-Mapped Communication on Myrinet. </title> <booktitle> In Proceedings of the 1997 International Parallel Processing Symposium, </booktitle> <pages> pages 388-396, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: invokes a user-level handler function in the receiving process after the message has been delivered into the receiver's memory. 2.2 Lessons from VMMC Implementations The basic VMMC model has been implemented on two platforms: PCs connected by the Intel Paragon routing net work [18] and PCs connected by a Myrinet <ref> [17] </ref> network. The first platform uses a custom-designed network interface supporting virtual memory-mapped communication and the second platform uses standard Myrinet programmable network interfaces and Myrinet routing switches. Programming with VMMC directly delivers communication latency and bandwidth very close to the hardware limit. <p> The overhead of these design choices is high. A few low-level communication interfaces assume reliable hardware and treat each network error as a catastrophic one. Examples of such approach include Fast Messages [30] and our previous work <ref> [6, 17] </ref>.
Reference: [18] <author> C. Dubnicki, L. Iftode, E.W. Felten, and K. Li. </author> <title> Software Support for Virtual Memory-Mapped Communication. </title> <booktitle> In Proceedings of the 1996 International Parallel Processing Symposium, </booktitle> <pages> pages 372-381, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: During the last few years, researchers have proposed several approaches to move network protocols partially or entirely to the user level with protection in order to reduce the protocol overhead <ref> [3, 15, 18, 19, 36] </ref>. The common framework is to implement a user-level data transport protocol that integrates well with the network interface. Existing high-level protocols for shared virtual memory [21] and message-passing [1, 5, 14, 32] can then be implemented efficiently. <p> Attaching a notification to a message invokes a user-level handler function in the receiving process after the message has been delivered into the receiver's memory. 2.2 Lessons from VMMC Implementations The basic VMMC model has been implemented on two platforms: PCs connected by the Intel Paragon routing net work <ref> [18] </ref> and PCs connected by a Myrinet [17] network. The first platform uses a custom-designed network interface supporting virtual memory-mapped communication and the second platform uses standard Myrinet programmable network interfaces and Myrinet routing switches. Programming with VMMC directly delivers communication latency and bandwidth very close to the hardware limit. <p> By comparison, the UTLB mechanism can deal with a large number of small buffers and allow for buffer overlapping. A typical interrupt-driven approach is used for address translation by both U-Net/MM [4] and VMMC <ref> [18] </ref>. This approach uses a global TLB on the network interface; when a TLB miss happens, the network interface interrupts the host processor which pins or pages-in the virtual page and returns the physical address to the network interface. Pinning pages in an interrupt context is non-standard and complicated.
Reference: [19] <author> T. Eicken, D.E. Culler, S.C. Goldstein, and K.E. Schauser. </author> <title> Active Messages: A Mechanism for Integrated Communication and Computation. </title> <booktitle> In Proceedings of the 19th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 256-266, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: During the last few years, researchers have proposed several approaches to move network protocols partially or entirely to the user level with protection in order to reduce the protocol overhead <ref> [3, 15, 18, 19, 36] </ref>. The common framework is to implement a user-level data transport protocol that integrates well with the network interface. Existing high-level protocols for shared virtual memory [21] and message-passing [1, 5, 14, 32] can then be implemented efficiently. <p> Variants of this protocol have been used by NX implementation on Paragon [31] as well as early NX implementation 3 on VMMC [1]. Active Messages (AM) <ref> [19] </ref> is a user-level communication mechanism based on fast remote execution facility. Recently, a fast sockets facility has been built with AM handlers [32]. They used a receiver-based approach called receive posting.
Reference: [20] <author> R. Gillet, M. Collins, and D. Pimm. </author> <title> Overview of Network Memory Channel for PCI. </title> <booktitle> In Proceedings of the IEEE COM-PCON '96, </booktitle> <pages> pages 244-249, </pages> <year> 1996. </year>
Reference-contexts: The first challenging issue is how to design and implement the low-level data transport API so that high-level APIs can be implemented with little overhead and with true zero-copy protocols. A memory-mapped communication model, such as SHRIMP [6] or DEC's Memory Channel <ref> [20] </ref>, requires the least software overhead because data transfers avoid receiver's CPU intervention. However, our early experience has shown that using such a low-level API to implement a high-level connection-based API like stream sockets often requires a copy on the receiver side [14].
Reference: [21] <author> L. Iftode, C. Dubnicki, E.W. Felten, and K. Li. </author> <title> Improving Release-Consistent Shared Virtual Memory using Automatic Update. </title> <booktitle> In Proceedings of the Second International Symposium on High Performance Computer Architecture, </booktitle> <pages> pages 14-25, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: The common framework is to implement a user-level data transport protocol that integrates well with the network interface. Existing high-level protocols for shared virtual memory <ref> [21] </ref> and message-passing [1, 5, 14, 32] can then be implemented efficiently. The goal is to deliver to the user communication performance close to the hardware's limit while providing the full functionality of the high-level APIs. This paper addresses three of the important issues associated with this goal.
Reference: [22] <author> David Johnson and Willy Zwaenepoel. </author> <title> The Peragrine High-Performance RPC System. </title> <journal> Software Practice and Experience, </journal> <volume> 23(2) </volume> <pages> 201-221, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Many methods have been proposed to avoid copying between I/O devices and application memory. IBM's OS/360 can specify a file I/O buffer area for applications to avoid copying. Page remapping has been used to avoid copying in several past and recent projects <ref> [26, 10, 22, 16, 28] </ref>. Brus-toloni and Steenkiste proposed emulated copy [8] which combines page remapping and copying of sub-page data chunks. In this technique, total amount of data copied is not more than one page regardless of user buffer size and its alignment.
Reference: [23] <author> A.R. Karlin, M.S. Manasse, L. McGeoch, and S. Ow-icki. </author> <title> Competitive Randomized Algorithms for Non-Uniform Problems. </title> <booktitle> In 1st Annual ACM Symposium on Discrete Algorithms, </booktitle> <pages> pages 301-309, </pages> <year> 1989. </year>
Reference-contexts: During our performance tuning, we found it beneficial to add an adaptive send delay (ASD) to stream sockets. This is because transfer redirection is much faster than a memory copy. We used an adaptive delay algorithm derived from a competitive, random walk algorithm <ref> [23] </ref>. The algorithm adjusts the delay threshold using feedback from the receiver. The delay varies between 0 and the time to copy the message. The receiver gives the sender two types of feedback: 6 * redirection status: this indicates whether the receiver successfully redirected the last message.
Reference: [24] <author> J. Kay and J. Pasquale. </author> <title> The Importance of Non-Data Touching Processing Overheads in TCP/IP. </title> <booktitle> In Proceedings of the ACM Communications Architectures and Protocols Conference, </booktitle> <pages> pages 259-269, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: 1 Introduction With the arrival of fast networks such as Myrinet and ATM, the overhead of the network communication software has become a major performance bottleneck, hurting user-to-user latency and bandwidth. For example, the TCP/IP protocol overhead increases the latency by several hundreds microseconds <ref> [24] </ref> even for small messages. A copy in the network protocol can reduce the communication bandwidth to the memory copy bandwidth which is usually substantially less than the peak hardware DMA bandwidth.
Reference: [25] <author> Kimberly K. Keeton, Thomas E. Anderson, and David A. Patterson. </author> <title> LogP: The Case for Low-Overhead Local Area Networks. In Hot Interconnects III, </title> <month> August </month> <year> 1995. </year>
Reference-contexts: For example, while the Myrinet hardware is capable of delivering bandwidth of 1.28 Gbits/s [7], the end-user applications see little performance improvement compared to the 100 Mbits/s Ethernet <ref> [25] </ref>. The desire to build high-performance servers from a network of commodity computers has pushed researchers to explore ways to reduce the communication bottleneck for system area networks.
Reference: [26] <author> P.J. Leach, P.H. Levine, B.P. Douros, J.A. Hamilton, D.L. Nelson, and B.L. Stumpf. </author> <title> The Architecture of an Integrated Local Network. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> SAC-1(5), </volume> <year> 1983. </year>
Reference-contexts: Many methods have been proposed to avoid copying between I/O devices and application memory. IBM's OS/360 can specify a file I/O buffer area for applications to avoid copying. Page remapping has been used to avoid copying in several past and recent projects <ref> [26, 10, 22, 16, 28] </ref>. Brus-toloni and Steenkiste proposed emulated copy [8] which combines page remapping and copying of sub-page data chunks. In this technique, total amount of data copied is not more than one page regardless of user buffer size and its alignment.
Reference: [27] <author> S. J. Le*er, M. K. McKusick, M. J. Karels, and J. S. Quar-terman. </author> <title> The Design and Implementation of the 4.3BSD Unix Operating System. </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Our micro-benchmarks and applications show that VMMC-2 supports the socket abstraction quite well. 7.1 Implementation The sockets API is implemented as a user-level library using the VMMC-2 interface. It is compatible, and seamlessly integrated with the Unix stream sockets facility <ref> [27] </ref>. We introduce a new address family, AF VMMC, to support the new type of stream socket. To take advantage of the transfer redirection mechanism in VMMC-2 (see Figure 2), we use a circular buffer as a backup buffer for transfer redirection.
Reference: [28] <author> J. Lumley. </author> <title> A High-Throughput Network Interface for A RISC Workstation. </title> <type> Technical Report Technical Report HPL-92-7, </type> <institution> Hewlett-Packard Laboratories, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: Many methods have been proposed to avoid copying between I/O devices and application memory. IBM's OS/360 can specify a file I/O buffer area for applications to avoid copying. Page remapping has been used to avoid copying in several past and recent projects <ref> [26, 10, 22, 16, 28] </ref>. Brus-toloni and Steenkiste proposed emulated copy [8] which combines page remapping and copying of sub-page data chunks. In this technique, total amount of data copied is not more than one page regardless of user buffer size and its alignment.
Reference: [29] <author> A.G. Nowatzyk, M.C. Browne, E.J. Kelly, and M. Perkin. S-Connect: </author> <title> from Networks of Workstations to Supercomputer Performance. </title> <booktitle> In Proceedings of the 22nd Annual Symposium on Computer Architecture, </booktitle> <pages> pages 71-82, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Examples of such approach include Fast Messages [30] and our previous work [6, 17]. This works well as long as network errors are really extremely rare or when the packet retransmission is handled by the hardware (like S-Connect <ref> [29] </ref>). 6 VMMC-2 Performance 6.1 The logP Model We characterize the performance of our system using the five parameters of the logP model [12]: ( RT T 2 ; L; O r ; O s ; g).
Reference: [30] <author> S. Pakin, V. Karamcheti, and A. Chien. </author> <title> Fast Messages (FM): Efficient, Portable Communication for Workstatin Clusters and Massively-Parallel Processors. </title> <journal> IEEE Concur-rency, </journal> <year> 1997. </year>
Reference-contexts: The overhead of these design choices is high. A few low-level communication interfaces assume reliable hardware and treat each network error as a catastrophic one. Examples of such approach include Fast Messages <ref> [30] </ref> and our previous work [6, 17]. <p> They do not address the issue of supporting connection-oriented high-level protocols. FastSockets [32], built on top of Active Messages, achieves 30 s one-way latency and 33 MBytes/s maximum bandwidth between two UltraSPARC 1 connected by a Myrinet network. Fast Messages (FM) <ref> [30] </ref> is similar to AM in that each message is associated with a handler that will process the 8 message on the receive side. FM does not allow multiple pro-cesses to share the network access. The FM sockets implementation [30] achieves one-way latency of about 34 s and maximum bandwidth of <p> Fast Messages (FM) <ref> [30] </ref> is similar to AM in that each message is associated with a handler that will process the 8 message on the receive side. FM does not allow multiple pro-cesses to share the network access. The FM sockets implementation [30] achieves one-way latency of about 34 s and maximum bandwidth of 11 MBytes/s between two SPARC-stations connected with Myrinet. The Nectar system [11] implements TCP on their programmable network interface (16Mhz Sparc as the communication processor).
Reference: [31] <author> P. Pierce. </author> <title> The Paragon implementation of the NX message passing interface. </title> <booktitle> In Proceedings of 9th Conference on Hypercube Concurrent Computers and Applications, </booktitle> <year> 1994. </year>
Reference-contexts: In this approach the receiver informs the sender about the receive buffer, after which the sender is able to transfer data directly into it. Variants of this protocol have been used by NX implementation on Paragon <ref> [31] </ref> as well as early NX implementation 3 on VMMC [1]. Active Messages (AM) [19] is a user-level communication mechanism based on fast remote execution facility. Recently, a fast sockets facility has been built with AM handlers [32]. They used a receiver-based approach called receive posting.
Reference: [32] <author> Sl H. Rodrigues, T. E. Anderson, and D. E. Culler. </author> <title> High-Performance Local Area Communication With Fast Sockets. </title> <booktitle> In USENIX '97, </booktitle> <year> 1997. </year>
Reference-contexts: The common framework is to implement a user-level data transport protocol that integrates well with the network interface. Existing high-level protocols for shared virtual memory [21] and message-passing <ref> [1, 5, 14, 32] </ref> can then be implemented efficiently. The goal is to deliver to the user communication performance close to the hardware's limit while providing the full functionality of the high-level APIs. This paper addresses three of the important issues associated with this goal. <p> On the other hand, high-level connection-oriented APIs such as stream sockets do not have destination addresses on the sending side; a sender knows only the name of the connection. As a result, zero-copy protocols typically require a scout message or a handshake in the implementation <ref> [1, 14, 32] </ref>. In this paper, we propose, implement and evaluate a mechanism called transfer redirection. We show that this mechanism naturally extends the virtual memory-mapped communication model and provides support for connection-oriented APIs to achieve zero-copy without any additional messages. <p> Variants of this protocol have been used by NX implementation on Paragon [31] as well as early NX implementation 3 on VMMC [1]. Active Messages (AM) [19] is a user-level communication mechanism based on fast remote execution facility. Recently, a fast sockets facility has been built with AM handlers <ref> [32] </ref>. They used a receiver-based approach called receive posting. The arriving data is first placed in an anonymous staging area in memory and the message handler is invoked. If a receive has been posted, the handler moves the data to the final destination bypassing the socket buffer. <p> Their implementation requires applications to use special, pinned buffers. Hamlyn [9] implements a sender-based communication model and uses the network interface to support user-level message passing, but it requires application programs to build headers using pinned memory. They do not address the issue of supporting connection-oriented high-level protocols. FastSockets <ref> [32] </ref>, built on top of Active Messages, achieves 30 s one-way latency and 33 MBytes/s maximum bandwidth between two UltraSPARC 1 connected by a Myrinet network.
Reference: [33] <author> J.M. Smith and C.B.S. Traw. </author> <title> Giving Applications Access to Gb/s Networking. </title> <journal> IEEE Network, </journal> <volume> 7(4) </volume> <pages> 44-52, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: In this technique, total amount of data copied is not more than one page regardless of user buffer size and its alignment. Lately, several groups have proposed letting applications directly access communication interface memory <ref> [11, 13, 33] </ref>. However, network interface memory is usually small and non-cacheable which limits its direct use by applications. 4 User-Managed Address Translation 4.1 Description In the VMMC-2 API, a user-level send or redirect request specifies an arbitrary user buffer with a virtual memory address and size.
Reference: [34] <author> A. Z. Spector. </author> <title> Performing Remote Operations Efficiently on a Local Computer Network. </title> <journal> Communications of the ACM, </journal> <volume> 25(4) </volume> <pages> 260-273, </pages> <month> April </month> <year> 1982. </year>
Reference-contexts: Most related work is in using protected, memory-mapped communication or other user-level mechanisms to support reliable, connection-oriented high-level protocols. Spector <ref> [34] </ref> proposed a remote memory reference model to perform communication over a local area network. The implementation was programmed in a processor's microcode. This model has been revived by Thekkath et al. [35] using fast traps. They do not deal with the issue of supporting connection-oriented high-level protocols.
Reference: [35] <author> Ch. A. Thekkath and H.M. Levy. </author> <title> Hardware and Software Support for Efficient Exception Handling. </title> <booktitle> In The 6th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 110-121, </pages> <month> Oc-tober </month> <year> 1994. </year>
Reference-contexts: Spector [34] proposed a remote memory reference model to perform communication over a local area network. The implementation was programmed in a processor's microcode. This model has been revived by Thekkath et al. <ref> [35] </ref> using fast traps. They do not deal with the issue of supporting connection-oriented high-level protocols. Druschel et al. [15] proposed the concept of application device channels which provide protected user-level access to a network interface. U-Net [3] uses a similar abstraction to support high-level protocols such as TCP/IP.
Reference: [36] <author> Ch. A. Thekkath, Thu D. Nguyen, Moy E, and D. Lazowska E. </author> <title> Implementing Network Protocols at User Level. </title> <booktitle> In Proceedings of the ACM SIGCOMM'93 Symposium, </booktitle> <month> September </month> <year> 1993. </year>
Reference-contexts: During the last few years, researchers have proposed several approaches to move network protocols partially or entirely to the user level with protection in order to reduce the protocol overhead <ref> [3, 15, 18, 19, 36] </ref>. The common framework is to implement a user-level data transport protocol that integrates well with the network interface. Existing high-level protocols for shared virtual memory [21] and message-passing [1, 5, 14, 32] can then be implemented efficiently.
References-found: 36

