URL: ftp://ftp.cs.yale.edu/pub/hager/papers/invariant-tasks.ps.gz
Refering-URL: http://www.cs.yale.edu/users/hager/papers.html
Root-URL: http://www.cs.yale.edu
Email: E-mail: (gregory.hager, joao.hespanha, zachary.dodds, as.morse)@yale.edu  
Phone: Phone: (203) 432-6432  
Title: What Tasks Can Be Performed with an Uncalibrated Stereo Vision System?  
Author: J. P. Hespanha, Z. Dodds, G. D. Hager, and A. S. Morse 
Note: Submitted to IJCV special issue on vision research at Yale. This research was supported by the National Science Foundation, the Army Research Office, and the Air Force Office of Scientific Research  
Address: P.O. Box 208285  New Haven, CT, 06520  
Affiliation: Center for Computational Vision and Control c/o Computer Science Department  Yale University  
Abstract: This article studies the following question: "When is it possible to decide, on the basis of images of point features observed by an imprecisely modeled two-camera stereo vision system, whether or not a prescribed robot positioning task has been accomplished with precision?" It is shown that for a stereo vision system with known epipo-lar geometry, whether or not such a positioning task has been accomplished can be decided with available data, just in case the task function which specifies the task is a projective invariant. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W-C. Chang, J. P. Hespanha, A.S. Morse, and G.D. Hager. </author> <title> Task re-encoding in vision-based control systems. </title> <booktitle> In Proceedings, Conference on Design and Control, volume to appear, </booktitle> <address> San Diego, CA, </address> <month> December </month> <year> 1997. </year>
Reference-contexts: However, it is also clear that the method of Cartesian-based encoding is more restrictive than that of image-based encoding. The "modified" Cartesian-based encoding, introduced in <ref> [1] </ref>, is one way of extending the idea of Cartesian-based encodings to encompass a richer set of tasks.
Reference: [2] <author> Wen-Chung Chang. </author> <title> Vision-Based Control of Uncertain Systems. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> December </month> <year> 1997. </year>
Reference-contexts: The second approach, image-based control, computes feedback directly from measured image data. In this article, these two approaches and a third more recently 1 introduced idea, the modified Cartesian-based approach proposed in <ref> [2] </ref>, are discussed from the point of view of image encodings. The results described above hold for any class of two-camera models whose elements are injective functions, but nothing more. However, it is well known that two-camera systems have a rich geometric structure.
Reference: [3] <author> F. Chaumette, E. Malis, and S. Boudet. </author> <title> 2d 1/2 visual servoing with respect to a planar object. </title> <booktitle> In Proc. IROS Workshop on New Trends in Image-based Robot Servoing, </booktitle> <pages> pages 43-52, </pages> <year> 1997. </year>
Reference-contexts: Demonstrated applications of vision within a feedback loop|often referred to as visual servoing or, more generally, vision-based control|include automated driving [6], flexible manufacturing <ref> [3, 24] </ref> and teleoperation with large time delays [8] to name a few. <p> The task specified by T is the equation T (f ) = 0: (1) In case (1) holds we say that the task is accomplished at f . Examples of tasks defined in this manner, can be found in <ref> [23, 7, 4, 3, 15, 11, 22] </ref>. In order to complete the problem formulation, it is helpful to introduce the following nomenclature.
Reference: [4] <author> F. Chaumette, P. Rives, and B. Espiau. </author> <title> Classification and realization of the different vision-based tasks. </title> <editor> In K. Hashimoto, editor, </editor> <booktitle> Visual Servoing, </booktitle> <pages> pages 199-228. </pages> <publisher> World Scientific, </publisher> <year> 1994. </year>
Reference-contexts: The task specified by T is the equation T (f ) = 0: (1) In case (1) holds we say that the task is accomplished at f . Examples of tasks defined in this manner, can be found in <ref> [23, 7, 4, 3, 15, 11, 22] </ref>. In order to complete the problem formulation, it is helpful to introduce the following nomenclature.
Reference: [5] <author> P. I. Corke. </author> <title> Visual control of robot manipulators|a review. </title> <editor> In K. Hashimoto, editor, </editor> <booktitle> Visual Servoing, </booktitle> <pages> pages 1-32. </pages> <publisher> World Scientific, </publisher> <year> 1994. </year>
Reference-contexts: 1 Introduction Feedback control systems employing video cameras as sensors have been studied in the robotics community for many years (c.f. a recent tutorial on visual servoing [15] and a recent review <ref> [5] </ref>). Demonstrated applications of vision within a feedback loop|often referred to as visual servoing or, more generally, vision-based control|include automated driving [6], flexible manufacturing [3, 24] and teleoperation with large time delays [8] to name a few.
Reference: [6] <author> E.D. Dickmanns and V. Graefe. </author> <title> Applications of dynamic monocular machine vision. </title> <journal> Machine Vision and Applications, </journal> <volume> 1 </volume> <pages> 241-261, </pages> <year> 1988. </year>
Reference-contexts: Demonstrated applications of vision within a feedback loop|often referred to as visual servoing or, more generally, vision-based control|include automated driving <ref> [6] </ref>, flexible manufacturing [3, 24] and teleoperation with large time delays [8] to name a few.
Reference: [7] <author> B. Espiau, F. Chaumette, and P. Rives. </author> <title> A New Approach to Visual Servoing in Robotics. </title> <journal> IEEE Trans. Robot. Autom., </journal> <volume> 8 </volume> <pages> 313-326, </pages> <year> 1992. </year>
Reference-contexts: The task specified by T is the equation T (f ) = 0: (1) In case (1) holds we say that the task is accomplished at f . Examples of tasks defined in this manner, can be found in <ref> [23, 7, 4, 3, 15, 11, 22] </ref>. In order to complete the problem formulation, it is helpful to introduce the following nomenclature.
Reference: [8] <author> C. Fagerer, D. Dickmanns, and E. Dickmanns. </author> <title> Visual grasping with long delay time of a free floating object in orbit. </title> <booktitle> Autonomous Robots, </booktitle> <volume> 1(1), </volume> <year> 1994. </year>
Reference-contexts: Demonstrated applications of vision within a feedback loop|often referred to as visual servoing or, more generally, vision-based control|include automated driving [6], flexible manufacturing [3, 24] and teleoperation with large time delays <ref> [8] </ref> to name a few.
Reference: [9] <author> O.D. Faugeras. </author> <title> Three-Dimensional Computer Vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: In this section we specialize to the case when the two-camera models of interest are pairs of projective camera models which map subsets of P 3 containing V, into P 2 fi P 2 . Projective models of this type have been widely used in computer vision <ref> [19, 9] </ref> in part because they include as special cases, perspective, affine and orthographic camera models. <p> We note that when it is possible to write M in the form M = H Hc where H is a nonsingular 3 fi 3 matrix, and c is a vector in R 3 ; then M models a projective camera with center of projection at c <ref> [9] </ref>. In this case the kernel of M is R [ c 1 ] which justifies calling it the optical center of M. One special case occurs when H = R; where R is a 3 fi 3 rotation matrix. <p> model. 12 4.3 Weakly Calibrated Stereo Vision Systems It is well-known that, given measurements of a sufficient number of points in "general position" by a stereo camera system, it is possible to compute a one-dimensional constraint on the (stereo) projection of any point features in the two-camera field of view <ref> [18, 9] </ref>. A stereo camera system for which this information, the so-called "epipolar constraint," is known is often referred to as weakly calibrated [21]. <p> a pair of two-camera models have the same epipolar geometry if they have the same image when viewed as a function from V to Y: An equivalent definition for the 13 meaning of "same epipolar geometry" can be given in terms of the fundamental matrix of a global two-camera model <ref> [9] </ref>. One can show that C wkcal (G 0 ) contains all those two-camera models in C uncal [V] determined by global two-camera models with the same epipolar geometry as G 0 .
Reference: [10] <author> Olivier D. Faugeras. </author> <title> What can be seen in three dimensions with an uncalibrated stereo rig? In Proc., </title> <booktitle> ECCV, </booktitle> <pages> pages 563-578, </pages> <year> 1992. </year>
Reference-contexts: The results described above hold for any class of two-camera models whose elements are injective functions, but nothing more. However, it is well known that two-camera systems have a rich geometric structure. This has led to recent work in the vision literature <ref> [10] </ref> considering the following question: "What can be seen in three dimensions with an uncalibrated stereo rig?" Roughly speaking, [10] shows that, in the absence of measurement noise, using a two-camera stereo vision system that has been calibrated just using images of point features, it is possible to exactly reconstruct the <p> However, it is well known that two-camera systems have a rich geometric structure. This has led to recent work in the vision literature <ref> [10] </ref> considering the following question: "What can be seen in three dimensions with an uncalibrated stereo rig?" Roughly speaking, [10] shows that, in the absence of measurement noise, using a two-camera stereo vision system that has been calibrated just using images of point features, it is possible to exactly reconstruct the positions of point features "up to a projective transformation" on three-dimensional projective space. <p> A stereo camera system for which this information, the so-called "epipolar constraint," is known is often referred to as weakly calibrated [21]. It has been shown <ref> [10] </ref> that, with a "weakly calibrated" stereo system, it is possible to reconstruct the position of point features in the two cameras' field of view from image measurements. However, this reconstruction is only unique up to a projective transformation.
Reference: [11] <author> G. D. Hager. </author> <title> A modular system for robust hand-eye coordination. </title> <journal> IEEE Trans. Robot. Autom., </journal> <volume> 13(4) </volume> <pages> 582-595, </pages> <year> 1997. </year>
Reference-contexts: In contrast, in vision-based systems there are often many choices for defining a control error, each with different attributes. Some of the observations just made are implicit in work extending back more than 10 years [26]. Some of these issues are touched upon in <ref> [11] </ref> and in the monograph [23]. The aim of this paper is to determine conditions under which it is possible to decide, based purely on the observation of point features by an imprecisely modeled two-camera vision system, whether or not a prescribed positioning task has been accomplished. <p> The theorem also provides necessary conditions for a task to be performable in cases where the weak calibration of the two-camera system cannot be computed. The theorem thus serves to underscore the observation made in <ref> [11, 16, 14, 25] </ref> that accurate metric information is not needed for the accomplishment of many types of positioning tasks with a stereo vision system. The remainder of this article is structured as follows. The next section establishes basic nomenclature and definitions needed to formally address the task decidability problem. <p> Both the pose of the robot under consideration and the target set are determined by a list of simultaneously observed point features in V. As in <ref> [15, 11, 23] </ref>, tasks are represented mathematically as equations to be satisfied. <p> The task specified by T is the equation T (f ) = 0: (1) In case (1) holds we say that the task is accomplished at f . Examples of tasks defined in this manner, can be found in <ref> [23, 7, 4, 3, 15, 11, 22] </ref>. In order to complete the problem formulation, it is helpful to introduce the following nomenclature. <p> In other words, for any (image-based) encoding that verifies T (f ) = 0 on C, the quality of the approximate two-camera model chosen from C often affects a feedback controller's ability to accomplish the encoded task, but not the initially defined task which has been encoded <ref> [11] </ref>. 3.4 Equivalent Tasks It is sometimes desirable to reformulate a positioning task, initially defined on F V n , on a new feature space F new V m .
Reference: [12] <author> Gregory D. Hager. </author> <title> Calibration-free visual control using projective invariance. </title> <booktitle> In Proc. Int. Conf. Comput. Vis., </booktitle> <pages> pages 1009-1015, </pages> <year> 1995. </year> <month> 18 </month>
Reference-contexts: An especially interesting feature of vision-based control systems is that often both the process state (e.g., the position and orientation of the robot in its workspace) and the reference set-point (e.g., a set of desired poses) can be simultaneously observed through the same sensors (i.e., cameras). In prior work <ref> [27, 14, 13, 12, 17] </ref>, it has been observed that this unusual property of vision systems makes it possible to achieve precise positioning (in the absence of measurement noise) for certain tasks even when camera and actuator models are themselves imprecisely known.
Reference: [13] <author> Gregory D. Hager, Wen-Chung Chang, and A. Stephen Morse. </author> <title> Robot hand-eye coordi-nation based on stereo vision. </title> <journal> IEEE Control Systems Magazine, </journal> <volume> 15(1) </volume> <pages> 30-39, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: An especially interesting feature of vision-based control systems is that often both the process state (e.g., the position and orientation of the robot in its workspace) and the reference set-point (e.g., a set of desired poses) can be simultaneously observed through the same sensors (i.e., cameras). In prior work <ref> [27, 14, 13, 12, 17] </ref>, it has been observed that this unusual property of vision systems makes it possible to achieve precise positioning (in the absence of measurement noise) for certain tasks even when camera and actuator models are themselves imprecisely known.
Reference: [14] <author> N. Hollinghurst and R. Cipolla. </author> <title> Uncalibrated stereo hand eye coordination. </title> <journal> Image and Vision Computing, </journal> <volume> 12(3) </volume> <pages> 187-192, </pages> <year> 1994. </year>
Reference-contexts: An especially interesting feature of vision-based control systems is that often both the process state (e.g., the position and orientation of the robot in its workspace) and the reference set-point (e.g., a set of desired poses) can be simultaneously observed through the same sensors (i.e., cameras). In prior work <ref> [27, 14, 13, 12, 17] </ref>, it has been observed that this unusual property of vision systems makes it possible to achieve precise positioning (in the absence of measurement noise) for certain tasks even when camera and actuator models are themselves imprecisely known. <p> The theorem also provides necessary conditions for a task to be performable in cases where the weak calibration of the two-camera system cannot be computed. The theorem thus serves to underscore the observation made in <ref> [11, 16, 14, 25] </ref> that accurate metric information is not needed for the accomplishment of many types of positioning tasks with a stereo vision system. The remainder of this article is structured as follows. The next section establishes basic nomenclature and definitions needed to formally address the task decidability problem.
Reference: [15] <author> S. Hutchinson, G.D. Hager, and P. Corke. </author> <title> A tutorial introduction to visual servo control. </title> <journal> IEEE Trans. Robot. Autom., </journal> <volume> 12(5), </volume> <year> 1996. </year>
Reference-contexts: 1 Introduction Feedback control systems employing video cameras as sensors have been studied in the robotics community for many years (c.f. a recent tutorial on visual servoing <ref> [15] </ref> and a recent review [5]). Demonstrated applications of vision within a feedback loop|often referred to as visual servoing or, more generally, vision-based control|include automated driving [6], flexible manufacturing [3, 24] and teleoperation with large time delays [8] to name a few. <p> Both the pose of the robot under consideration and the target set are determined by a list of simultaneously observed point features in V. As in <ref> [15, 11, 23] </ref>, tasks are represented mathematically as equations to be satisfied. <p> The task specified by T is the equation T (f ) = 0: (1) In case (1) holds we say that the task is accomplished at f . Examples of tasks defined in this manner, can be found in <ref> [23, 7, 4, 3, 15, 11, 22] </ref>. In order to complete the problem formulation, it is helpful to introduce the following nomenclature.
Reference: [16] <author> M. Jagersand, O. Fuentes, and R. Nelson. </author> <title> Experimental evaluation of uncalibrated visual servoing for precision manipulation. </title> <booktitle> In Proc., ICRA, </booktitle> <pages> pages 2874-2880, </pages> <year> 1997. </year>
Reference-contexts: The theorem also provides necessary conditions for a task to be performable in cases where the weak calibration of the two-camera system cannot be computed. The theorem thus serves to underscore the observation made in <ref> [11, 16, 14, 25] </ref> that accurate metric information is not needed for the accomplishment of many types of positioning tasks with a stereo vision system. The remainder of this article is structured as follows. The next section establishes basic nomenclature and definitions needed to formally address the task decidability problem.
Reference: [17] <author> Rafael Kelly. </author> <title> Robust asymptotically stable visual servoing of planar robots. </title> <journal> IEEE Trans. Robot. Autom., </journal> <volume> 12(5) </volume> <pages> 759-766, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: An especially interesting feature of vision-based control systems is that often both the process state (e.g., the position and orientation of the robot in its workspace) and the reference set-point (e.g., a set of desired poses) can be simultaneously observed through the same sensors (i.e., cameras). In prior work <ref> [27, 14, 13, 12, 17] </ref>, it has been observed that this unusual property of vision systems makes it possible to achieve precise positioning (in the absence of measurement noise) for certain tasks even when camera and actuator models are themselves imprecisely known.
Reference: [18] <author> H.C. Longuet-Higgins. </author> <title> A computer algorithm for reconstructing a scene from two projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: model. 12 4.3 Weakly Calibrated Stereo Vision Systems It is well-known that, given measurements of a sufficient number of points in "general position" by a stereo camera system, it is possible to compute a one-dimensional constraint on the (stereo) projection of any point features in the two-camera field of view <ref> [18, 9] </ref>. A stereo camera system for which this information, the so-called "epipolar constraint," is known is often referred to as weakly calibrated [21].
Reference: [19] <author> J. Mundy and A. Zisserman. </author> <title> Geometric Invariance in Computer Vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1992. </year>
Reference-contexts: In this section we specialize to the case when the two-camera models of interest are pairs of projective camera models which map subsets of P 3 containing V, into P 2 fi P 2 . Projective models of this type have been widely used in computer vision <ref> [19, 9] </ref> in part because they include as special cases, perspective, affine and orthographic camera models. <p> By restricting attention to projective models, we are able to provide a complete and concise characterization of decidable tasks in terms of projective invariance <ref> [19] </ref>. 4.1 Camera Models In the sequel we are concerned with camera models whose fields of view are all the same subset V P 3 .
Reference: [20] <author> Alfred Anthony Rizzi. </author> <title> Dexterous Robot Manipulation. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: The "decidability" question is addressed by means of task encodings. The concept of a task encoding is discussed briefly in <ref> [20] </ref>, which contains further references. An encoded task is simply an equation of the form E T (y) = 0 where y is a list of observed point features and E T is a function which does not depend on knowledge of the calibration of the underlying two-camera system.
Reference: [21] <author> L. Robert and O.D. Faugeras. </author> <title> Relative 3D Positioning and 3D Convex Hull Computation from a Weakly Calibrated Stereo Pair. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 540-543, </pages> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: A two-camera system calibrated using only measured point correspondences is said to be weakly calibrated <ref> [21] </ref>. These findings clearly suggest that for a weakly calibrated two-camera model class, there ought to be a close relationship between the decidability of a given task and the invariant properties of the associated task function under projective transformations. <p> A stereo camera system for which this information, the so-called "epipolar constraint," is known is often referred to as weakly calibrated <ref> [21] </ref>. It has been shown [10] that, with a "weakly calibrated" stereo system, it is possible to reconstruct the position of point features in the two cameras' field of view from image measurements. However, this reconstruction is only unique up to a projective transformation. <p> It is common to refer to a stereo vision system whose two cameras admit a model which is known be in C [G 0 ] but is otherwise unknown as a weakly calibrated system <ref> [21] </ref>. 4.4 Projectively Invariant Tasks We now define what is meant by a "projectively invariant task".
Reference: [22] <author> L. Robert, C. Zeller, and O. Faugeras. </author> <title> Applications of non-metric vision to some visually guided robotics tasks. </title> <type> Technical Report 2584, </type> <institution> INRIA, Sophia-Antipolis, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: The task specified by T is the equation T (f ) = 0: (1) In case (1) holds we say that the task is accomplished at f . Examples of tasks defined in this manner, can be found in <ref> [23, 7, 4, 3, 15, 11, 22] </ref>. In order to complete the problem formulation, it is helpful to introduce the following nomenclature.
Reference: [23] <author> C. Samson, M. Le Borgne, and B. Espiau. </author> <title> Robot Control: The Task Function Approach. </title> <publisher> Clarendon Press, Oxford, </publisher> <address> England, </address> <year> 1992. </year>
Reference-contexts: In contrast, in vision-based systems there are often many choices for defining a control error, each with different attributes. Some of the observations just made are implicit in work extending back more than 10 years [26]. Some of these issues are touched upon in [11] and in the monograph <ref> [23] </ref>. The aim of this paper is to determine conditions under which it is possible to decide, based purely on the observation of point features by an imprecisely modeled two-camera vision system, whether or not a prescribed positioning task has been accomplished. <p> Positioning tasks are formally defined as equations of the form T (f ) = 0 where f is a list of observable point features in the workspace of a robot <ref> [23] </ref>. The "decidability" question is addressed by means of task encodings. The concept of a task encoding is discussed briefly in [20], which contains further references. <p> Both the pose of the robot under consideration and the target set are determined by a list of simultaneously observed point features in V. As in <ref> [15, 11, 23] </ref>, tasks are represented mathematically as equations to be satisfied. <p> The task specified by T is the equation T (f ) = 0: (1) In case (1) holds we say that the task is accomplished at f . Examples of tasks defined in this manner, can be found in <ref> [23, 7, 4, 3, 15, 11, 22] </ref>. In order to complete the problem formulation, it is helpful to introduce the following nomenclature.
Reference: [24] <author> M. J. Seelinger, M. Robinson, Z. Dieck, and S. B. Skaar. </author> <title> A vision-guided, semi-autonomous system applied to a robotic coating application. </title> <editor> In P. S. Schenker and G. T. McKee, editors, </editor> <booktitle> Sensor Fusion and Decentralized Control in Autonomous Robotic Systems, </booktitle> <pages> pages 133-144. SPIE, </pages> <year> 1997. </year>
Reference-contexts: Demonstrated applications of vision within a feedback loop|often referred to as visual servoing or, more generally, vision-based control|include automated driving [6], flexible manufacturing <ref> [3, 24] </ref> and teleoperation with large time delays [8] to name a few.
Reference: [25] <author> S. B. Skaar, W. H. Brockman, and W. S. Jang. </author> <title> Three-Dimensional Camera Space Manipulation. </title> <journal> Int. J. Robot. Res., </journal> <volume> 9(4) </volume> <pages> 22-39, </pages> <year> 1990. </year>
Reference-contexts: The theorem also provides necessary conditions for a task to be performable in cases where the weak calibration of the two-camera system cannot be computed. The theorem thus serves to underscore the observation made in <ref> [11, 16, 14, 25] </ref> that accurate metric information is not needed for the accomplishment of many types of positioning tasks with a stereo vision system. The remainder of this article is structured as follows. The next section establishes basic nomenclature and definitions needed to formally address the task decidability problem.
Reference: [26] <author> Lee E. Weiss, Arthur C. Sanderson, and Charles P. Neuman. </author> <title> Dynamic sensor-based control of robots with visual feedback. </title> <journal> IEEE J. Robot. Automat., </journal> <volume> RA-3(5):404-417, </volume> <month> October </month> <year> 1987. </year> <month> 19 </month>
Reference-contexts: In contrast, in vision-based systems there are often many choices for defining a control error, each with different attributes. Some of the observations just made are implicit in work extending back more than 10 years <ref> [26] </ref>. Some of these issues are touched upon in [11] and in the monograph [23].
Reference: [27] <author> S. W. Wijesoma, D. F. H. Wolfe, and R. J. Richards. </author> <title> Eye-to-hand coordination for vision-guided robot control applications. </title> <journal> Int. J. Robot. Res., </journal> <volume> 12(1) </volume> <pages> 65-78, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: An especially interesting feature of vision-based control systems is that often both the process state (e.g., the position and orientation of the robot in its workspace) and the reference set-point (e.g., a set of desired poses) can be simultaneously observed through the same sensors (i.e., cameras). In prior work <ref> [27, 14, 13, 12, 17] </ref>, it has been observed that this unusual property of vision systems makes it possible to achieve precise positioning (in the absence of measurement noise) for certain tasks even when camera and actuator models are themselves imprecisely known.
References-found: 27

