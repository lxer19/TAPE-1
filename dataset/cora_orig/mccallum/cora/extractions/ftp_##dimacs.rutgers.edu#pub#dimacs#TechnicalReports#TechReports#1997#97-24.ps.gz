URL: ftp://dimacs.rutgers.edu/pub/dimacs/TechnicalReports/TechReports/1997/97-24.ps.gz
Refering-URL: http://dimacs.rutgers.edu/TechnicalReports/1997.html
Root-URL: http://www.cs.rutgers.edu
Title: Symmetrization of Binary Random Variables 2  
Author: by Colin Mallows Larry Shepp Robert J. Vanderbei Yehuda Vardi 
Address: College Park, MD  Floram Park, NJ  New Brunswick, NJ 1  Princeton, NJ 1  New Brunswick, NJ  
Affiliation: Abram Kagan University of Maryland,  AT&T Laboratories,  Rutgers University,  Princeton University,  Rutgers University,  
Date: 1997  
Note: June  2 Research of the fourth author supported by the NSF through grant CCR-9403789 and by AFOSR through grant F49620-95-1-0351. Research of the fifth author supported by the NSA through grant DMA 96-1-0034.  
Abstract: DIMACS Technical Report 97-24 DIMACS is a partnership of Rutgers University, Princeton University, AT&T Labs, Bellcore, and Bell Labs. DIMACS is an NSF Science and Technology Center, funded under contract STC-91-19999; and also receives support from the New Jersey Commission on Science and Technology. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Yu.V. Linnik and I.V. Ostrovskii. </author> <title> Decomposition of Random Variables and Vectors. </title> <publisher> Amer. Math. Soc., </publisher> <address> Providence RI, </address> <year> 1977. </year>
Reference-contexts: is real for t 2 R:(2) Finding a minimum variance symmetrizer Y is then equivalent to finding a characteristic function g subject to (2) with minimum value of g 00 (0) + (g 0 (0)) 2 Though the arithmetic of characteristic functions is a well-developed chapter of probability (see, e.g., <ref> [1] </ref>) it seems that its methods are not fit for the problem under study and instead one needs duality theory of linear programming to obtain sharp bounds. This is seen most clearly in the example of Section 4. 2. Independent Symmetrizers In this section, we prove the following result.
Reference: [2] <author> E. Lukacs. </author> <title> Characteristic Functions. </title> <publisher> Griffin, </publisher> <address> London, 2 edition, </address> <year> 1970. </year>
Reference-contexts: An easier version of the problem would be this: find Y independent of X with minimum variance such that X + Y is Gaussian. However, the classical decomposition theorem due to Cramer (see, e.g., <ref> [2] </ref>) states that unless X is itself Gaussian no Y makes X + Y Gaussian. Rather than asking for X + Y to be Gaussian, one could stipulate that X + Y be within a certain distance of the class of Gaussian random variables and again the problem makes sense.
Reference: [3] <author> R.J. Vanderbei. </author> <title> LOQO: An interior point code for quadratic programming. </title> <type> Technical Report SOR 94-15, </type> <institution> Princeton University, </institution> <year> 1994. </year>
Reference-contexts: The answer is that we discretized an interval of the real line and thereby formulated a finite dimensional linear program as an approximation to the problem. We then used the fourth author's software, called LOQO (see <ref> [3] </ref>), to solve these discrete approximations and eventually were able to guess at the correct functional form for .
Reference: [4] <author> R.J. Vanderbei. </author> <title> Linear Programming: Foundations and Extensions. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1996. </year>
Reference-contexts: This random variable has second moment p. To prove that it minimizes the second moment, we need to show that every symmetrizer has second moment at least p. In the language of linear programming, we need to exhibit the optimal solution to the dual problem (see, e.g., <ref> [4] </ref>) and then use the weak duality theorem to derive the desired inequality. <p> Hence, we were unable to see the form of from such solutions. LOQO, on the other hand, implements an interior-point method and consequently converges to the (uniquely defined) analytic center of the set of optimal solutions (see <ref> [4] </ref> for details). From such a "regular" (smooth) solution it was fairly easy to discover the function . The reader may also feel that a simpler proof should exist given that X is assumed to take on only two values. <p> In particular, one might expect that it would be possible to restrict the search to random variables Y that only take on a finite number of values (by invoking, say, Caratheodory's theorem|see e.g. <ref> [4] </ref>). This, of course, would simplify the problem, but we were unable to justify such a restricted search. Finally, we note that as p tends to 1=2, has no limit. 3. Dependent Symmetrizers In this section, we find the minimum-variance symmetrizer when Y is allowed to depend on X.
References-found: 4

