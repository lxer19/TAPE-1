URL: ftp://cns.brown.edu/nin/papers/aistat97.ps.Z
Refering-URL: http://www.math.tau.ac.il/~nin/research.html
Root-URL: 
Title: Robust Interpretation of Neural-Network Models  
Author: Orna Intrator Nathan Intrator 
Keyword: Logistic regression; Generalized Linear Models; Model interpretability; Regularization of neural networks;  
Note: To appear: Proceedings of the VI International Workshop on Artificial Intelligence and Statistics,  
Address: Orna  
Affiliation: Hebrew University and Brown University  Tel-Aviv University and Brown University  
Email: Intrator@brown.edu  nin@cns.brown.edu  
Date: Jan, 1997.  
Abstract: Artificial Neural Network seem very promising for regression and classification, especially for large covariate spaces. These methods represent a non-linear function as a composition of low dimensional ridge functions and therefore appear to be less sensitive to the dimensionality of the covariate space. However, due to non uniqueness of a global minimum and the existence of (possibly) many local minima, the model revealed by the network is non stable. We introduce a method to interpret neural network results which uses novel robustification techniques. This results in a robust interpretation of the model employed by the network. Simulated data from known models is used to demonstrate the interpretability results and to demonstrate the effects of different regularization methods on the robustness of the model. Graphical methods are introduced to present the interpretation results. We further demonstrate how interaction between covariates can be revealed. From this study we conclude that the interpretation method works well, but that NN models may sometimes be misinterpreted, especially if the approximations to the true model are less robust. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Barron, A. R. </author> <year> (1991). </year> <title> Complexity regularization with application to artificial neural networks. </title> <editor> In Roussas, G., editor, </editor> <booktitle> Nonparametric Functional Estimation and Related Topics, </booktitle> <pages> pages 561-576. </pages> <publisher> Kluwer Academic Publishers, </publisher> <address> Dordrecht, The Netherlands. </address>
Reference-contexts: For health outcome data interpretation of model results becomes acutely important, as the intent of such studies is to gain knowledge of the underlying mechanisms. Neural networks become useful in high dimensional regression by looking for low dimensional decompositions or projections <ref> (Barron, 1991) </ref> and are thus good candidate methods for analysis of multivariate clinical data. Feed-forward neural networks with simple architecture (one or two hidden layers) can approximate any L 2 function and its derivatives with any desired accuracy (Cybenko, 1989; Hornik et al., 1990; Hornik et al., 1993).
Reference: <author> Barron, A. R. and Barron, R. L. </author> <year> (1988). </year> <title> Statistical learning networks: A unifying view. </title> <editor> In Wegman, E., editor, </editor> <booktitle> Computing Science and Statistics: Proc. 20th Symp. Interface, </booktitle> <pages> pages 192-203. </pages> <publisher> American Statistical Association, </publisher> <address> Washington, DC. </address>
Reference: <author> Baxt, W. G. </author> <year> (1990). </year> <title> Use of an artificial neural network for data analysis in clinical decision-making: the diagnosis of acute coronary occlusion. </title> <journal> Neural Computation, </journal> <volume> 2(4) </volume> <pages> 480-489. </pages>
Reference-contexts: Ripley, 1995). This has motivated the use of ANN on data that relates to health outcomes such as death or diagnosis. One such example is the use of ANN for the diagnosis of Acute Coronary Occlusion <ref> (Baxt, 1990) </ref>. In such studies, the dependent variables of interest are class label, and the set of possible explanatory predictor variables the inputs to the ANN maybe binary or continuous.
Reference: <author> Breiman, L. </author> <year> (1992). </year> <title> Stacked regression. </title> <type> Technical Report TR-367, </type> <institution> Department of Statistics, University of California, Berkeley. </institution>
Reference-contexts: Third, there is the problem of optimal network architecture selection (number of hidden layers, number of hidden units, weight constraints, etc.) The third problem can be addressed to some degree by cross validatory choice of architecture <ref> (Breiman, 1992) </ref>, or by averaging the predictors of several network with different architecture (Wolpert, 1992). The nonidentifiability of neural network solutions caused by the (possible) non uniqueness of a the global minima, and the existence of (possibly) many local minima, leads to a large prediction variance.
Reference: <author> Breiman, L. </author> <year> (1994). </year> <title> Bagging predictors. </title> <type> Technical Report TR-421, </type> <institution> Department of Statistics, University of California, Berkeley. </institution>
Reference-contexts: Breiman <ref> (Breiman, 1994) </ref> and Ripley (Ripley, 1996) show compelling empirical evidence for the importance of weight decay as a single network stabilizer. <p> These different local minima lead to somewhat independent predictors, and thus, the averaging can reduce the variance. When a larger set of independent networks is needed, but only little data is available, data reuse methods can be of help. Bootstrapping <ref> (Breiman, 1994) </ref> has been very helpful, since by resampling (with return) from the training data, the independence of the training sets is increased, and hence, the independence of the estimators, leading to improved ensemble results.
Reference: <author> Cybenko, G. </author> <year> (1989). </year> <title> Approximations by superpositions of a sigmoidal function. </title> <journal> Mathematics of Control, Signals and Systems, </journal> <volume> 2 </volume> <pages> 303-314. </pages>
Reference: <author> Davis, G. W. </author> <year> (1989). </year> <title> Sensitivity analysis in neural net solutions. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 19(5) </volume> <pages> 1078-1082. </pages>
Reference: <author> Deif, A. S. </author> <year> (1986). </year> <title> Sensitivity Analysis in Linear Systems. </title> <publisher> Springer Verlag, </publisher> <address> Berlin-Heidelberg-New York. </address>
Reference: <author> Efron, B. and Tibshirani, R. </author> <year> (1993). </year> <title> An Introduction to the Bootstrap. </title> <publisher> Chapman and Hall, </publisher> <address> New York. </address>
Reference-contexts: Bootstrapping (Breiman, 1994) has been very helpful, since by resampling (with return) from the training data, the independence of the training sets is increased, and hence, the independence of the estimators, leading to improved ensemble results. Smoothed bootstrap <ref> (Efron and Tibshirani, 1993) </ref> is potentially more useful since larger sets of independent training samples can be generated. The smoothed bootstrap approach amounts to generating larger datasets by simulating the true noise in the data.
Reference: <author> Geman, S., Bienenstock, E., and Doursat, R. </author> <year> (1992). </year> <title> Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4(1) </volume> <pages> 1-58. </pages>
Reference: <author> Hansen, L. K. and Salamon, P. </author> <year> (1990). </year> <title> Neural network ensembles. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intellignce, </journal> <volume> 12(10) </volume> <pages> 993-1001. </pages>
Reference: <author> Hornik, K., Stinchcombe, M., and White, H. </author> <year> (1990). </year> <title> Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks. </title> <booktitle> Neural Networks, </booktitle> <volume> 3 </volume> <pages> 551-560. </pages>
Reference: <author> Hornik, K., Stinchcombe, M., White, H., and Auer, P. </author> <year> (1993). </year> <title> Degree of approximation results for feedforward networks approximating unknown mappings and their derivatives. </title> <type> Discussion paper 93-15, </type> <institution> Department of Economics, UCSD. </institution>
Reference: <author> Intrator, O. and Intrator, N. </author> <year> (1993). </year> <title> Using neural networks for interpretation of nonlinear models. </title> <journal> In American Statistical Society: Proceedings of the Statistical Computing Section, </journal> <pages> pages 244-249. </pages> <publisher> American Statistical Association. </publisher>
Reference-contexts: The method allows to determine which variables have a linear effect, no effect, or nonlinear effect on the predictors. This paper extends an earlier version <ref> (Intrator and Intrator, 1993) </ref>, by using simulated data from known models is used to demonstrate the robustification and interpretability results. Useful graphical tool for examination of the prediction results are presented.
Reference: <author> Krogh, A. and Hertz, J. A. </author> <year> (1992). </year> <title> A simple weight decay can improve generalization. </title> <editor> In Moody, J., Hanson, S., and Lippmann, R., editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 4, </volume> <pages> pages 950-957. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Perrone, M. P. and Cooper, L. N. </author> <year> (1993). </year> <title> When networks disagree: Ensemble method for neural networks. </title> <editor> In Mammone, R. J., editor, </editor> <title> Neural Networks for Speech and Image processing. </title> <publisher> Chapman-Hall. [In press]. </publisher>
Reference: <author> Raviv, Y. and Intrator, N. </author> <year> (1996). </year> <title> Bootstrapping with noise: An effective regularization technique. </title> <note> To Appear: Connection Science, Special issue on Combining Estimators. </note>
Reference-contexts: It was recently shown that noise added to the input during training can be viewed as a regularizing parameter that controls, in conjunction with ensemble averaging, the capacity and the smoothness of the estimator <ref> (Raviv and Intrator, 1996) </ref>. The major role of this noise is to push different estimators to different local minima, and by that, produce a more independent set of estimators. Best performance is then achieved by averaging over the estimators.
Reference: <author> Ripley, B. D. </author> <year> (1993). </year> <title> Statistical aspects of neural networks. </title> <editor> In Barndorff-Nielsen, O., Jensen, J., and Kendall, W., editors, </editor> <title> Networks and Chaos Statistical and Probabilistic Aspects. </title> <publisher> Chapman and Hall. </publisher>
Reference: <author> Ripley, B. D. </author> <year> (1996). </year> <title> Pattern Recognition and Neural Networks. </title> <publisher> Oxford Press. </publisher>
Reference-contexts: Breiman (Breiman, 1994) and Ripley <ref> (Ripley, 1996) </ref> show compelling empirical evidence for the importance of weight decay as a single network stabilizer. <p> Each simulation contains 800 data points and uses ensembles of single layer, six hidden units single layer nets. Ripley's S-Plus `nnet' implementation of a feed-forward network was used <ref> (Ripley, 1996) </ref> together with our implementation of the generalized weights. The minimization criterion is mean squared error with weight decay. We tested weight decay parameter values between 5e-5 and 0.1. We used the skip layer connections option of Ripley's code (namely a model that includes logistic regression).
Reference: <author> Wolpert, D. H. </author> <year> (1992). </year> <title> Stacked generalization. </title> <booktitle> Neural Networks, </booktitle> <volume> 5(2) </volume> <pages> 241-260. </pages>
Reference-contexts: Third, there is the problem of optimal network architecture selection (number of hidden layers, number of hidden units, weight constraints, etc.) The third problem can be addressed to some degree by cross validatory choice of architecture (Breiman, 1992), or by averaging the predictors of several network with different architecture <ref> (Wolpert, 1992) </ref>. The nonidentifiability of neural network solutions caused by the (possible) non uniqueness of a the global minima, and the existence of (possibly) many local minima, leads to a large prediction variance.
References-found: 20

