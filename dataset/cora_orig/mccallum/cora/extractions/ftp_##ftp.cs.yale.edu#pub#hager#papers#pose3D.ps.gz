URL: ftp://ftp.cs.yale.edu/pub/hager/papers/pose3D.ps.gz
Refering-URL: http://www.cs.yale.edu/users/hager/papers.html
Root-URL: http://www.cs.yale.edu
Email: cplu@engr.sgi.com  hager@cs.yale.edu.  
Title: Fast and Globally Convergent Pose Estimation From Video Images  
Author: Chien-Ping Lu Gregory D. Hager Eric Mjolsness zx Greg Hager, Eric Mjolsness, 
Keyword: Chien-Ping Lu, Silicon Graphics  
Address: University.  
Affiliation: Department of Computer Science, Yale  
Note: Inc.  Jet Propulsion Laboratory, NASA. eric.d.mjolsness@jpl.nasa.gov The authors would like to thank Prof. R. Haralick for his useful comments and ideas on this research.  
Date: February 18, 1998  
Abstract: Determining the rigid transformation relating 2D images to known 3D geometry is a classical problem in photogrammetry and computer vision. Heretofore, the best methods for solving the problem have relied on iterative optimization methods which cannot be proven to converge and/or which do not effectively account for the orthonor-mal structure of rotation matrices. We show that the pose estimation problem can be formulated as that of minimizing an error metric based on collinearity in object (as opposed to image) space. Using object space collinearity error, we derive an iterative algorithm which directly computes orthogonal rotation matrices and which is globally convergent. Experimentally, we show that the method is computationally efficient, that it is no less accurate than the best currently employed optimization methods, and that it outperforms all tested methods in robustness to outliers. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. Wilson, </author> <title> "Visual servo control of robots using kalman filter estimates of robot pose relative to work-pieces," in Visual Servoing (K. Hashimoto, </title> <publisher> ed.), </publisher> <pages> pp. 71-104, </pages> <publisher> World Scientific, </publisher> <year> 1994. </year>
Reference-contexts: 1 Introduction Determining the rigid transformation that relates images to known geometry, the pose estimation problem, is one of the central problems in photogrammetry, robotics, computer graphics, and computer vision. In robotics, pose estimation is commonly used in hand-eye coordination systems <ref> [1] </ref>. In computer graphics, it plays a central role in tasks that combine computer-generated objects with photographic scenes | e.g. landmark tracking for determining head pose in augmented reality [2, 3, 4, 5] or interactive manipulation of objects.
Reference: [2] <author> W. E. L. Grimson et. al., </author> <title> "An automatic registration method for frameless stereotaxy, image guided surgery, and enhanced reality visualization," </title> <booktitle> in Proc. IEEE Conf. Computer Vision Pat. Rec., </booktitle> <pages> pp. 430-436, </pages> <year> 1994. </year>
Reference-contexts: In robotics, pose estimation is commonly used in hand-eye coordination systems [1]. In computer graphics, it plays a central role in tasks that combine computer-generated objects with photographic scenes | e.g. landmark tracking for determining head pose in augmented reality <ref> [2, 3, 4, 5] </ref> or interactive manipulation of objects. In computer vision, pose estimation is central to many approaches to object recognition [6].
Reference: [3] <author> A. State, G. Hirota, D. CHen, W. Garrett, and M. Livingston, </author> <title> "Superior augmented reality registration by integrating landmark tracking and magnetic tracking," </title> <booktitle> in Proc. ACM SIGGRAPH, </booktitle> <pages> pp. 429-438, </pages> <year> 1996. </year>
Reference-contexts: In robotics, pose estimation is commonly used in hand-eye coordination systems [1]. In computer graphics, it plays a central role in tasks that combine computer-generated objects with photographic scenes | e.g. landmark tracking for determining head pose in augmented reality <ref> [2, 3, 4, 5] </ref> or interactive manipulation of objects. In computer vision, pose estimation is central to many approaches to object recognition [6]. <p> When the current solution is close to the correct solution, it becomes a Gauss-Newton method. It has become a standard technique for nonlinear least squares problems, and has been widely adopted in computer vision [30, 31] and computer graphics <ref> [3] </ref>. 7 2.3 Why another iterative algorithm? Classical optimization techniques are currently the only choice when observed data is noisy and a high accuracy solution to the pose estimation problem is desired.
Reference: [4] <author> R. Azuma and G. Bishop, </author> <title> "Improving static and dynamic registration in an optical see-through HMD," </title> <booktitle> in Proc. SIGGRAPH, </booktitle> <pages> pp. 197-204, </pages> <year> 1994. </year> <month> 22 </month>
Reference-contexts: In robotics, pose estimation is commonly used in hand-eye coordination systems [1]. In computer graphics, it plays a central role in tasks that combine computer-generated objects with photographic scenes | e.g. landmark tracking for determining head pose in augmented reality <ref> [2, 3, 4, 5] </ref> or interactive manipulation of objects. In computer vision, pose estimation is central to many approaches to object recognition [6].
Reference: [5] <author> M. Bajura, H. Fuchs, and R. Ohbuchi, </author> <title> "Merging virtual objects with the real world: Seeing ultrasound imagery within the patient," </title> <booktitle> in Proc. SIGGRAPH, </booktitle> <pages> pp. 203-210, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: In robotics, pose estimation is commonly used in hand-eye coordination systems [1]. In computer graphics, it plays a central role in tasks that combine computer-generated objects with photographic scenes | e.g. landmark tracking for determining head pose in augmented reality <ref> [2, 3, 4, 5] </ref> or interactive manipulation of objects. In computer vision, pose estimation is central to many approaches to object recognition [6]. <p> The test data was generated as follows. A set of N 3D reference points were generated uniformly within a box defined by <ref> [5; 5] </ref>fi [5; 5]fi [5; 5] in the object space. A random 3D rotation was generated by selecting a random unit quaternion from a unit 4-sphere. It can be shown that the distribution of 3D rotations generated by this process is also uniform [41]. <p> The test data was generated as follows. A set of N 3D reference points were generated uniformly within a box defined by <ref> [5; 5] </ref>fi [5; 5]fi [5; 5] in the object space. A random 3D rotation was generated by selecting a random unit quaternion from a unit 4-sphere. It can be shown that the distribution of 3D rotations generated by this process is also uniform [41]. <p> The test data was generated as follows. A set of N 3D reference points were generated uniformly within a box defined by <ref> [5; 5] </ref>fi [5; 5]fi [5; 5] in the object space. A random 3D rotation was generated by selecting a random unit quaternion from a unit 4-sphere. It can be shown that the distribution of 3D rotations generated by this process is also uniform [41]. <p> A random 3D rotation was generated by selecting a random unit quaternion from a unit 4-sphere. It can be shown that the distribution of 3D rotations generated by this process is also uniform [41]. For translation, the x and y components were uniformly selected from the interval <ref> [5; 15] </ref>, and the z component was selected from the interval [20; 50]. The set of reference points were then transformed by the randomly selected rotation and translation. Following this, a fraction (= PO) of the 3D points were selected as outliers. <p> Following this, a fraction (= PO) of the 3D points were selected as outliers. Each of these points was replaced by another 3D point whose components were taken from a uniform distribution within a box <ref> [5; 5] </ref> fi [5; 5] fi [5; 5] in the object space. Finally, the resulting 3D points were projected onto the normalized image plane to produce image points. Gaussian noise was added to both coordinates of the image points to 17 generate the perturbed image points. <p> Following this, a fraction (= PO) of the 3D points were selected as outliers. Each of these points was replaced by another 3D point whose components were taken from a uniform distribution within a box <ref> [5; 5] </ref> fi [5; 5] fi [5; 5] in the object space. Finally, the resulting 3D points were projected onto the normalized image plane to produce image points. Gaussian noise was added to both coordinates of the image points to 17 generate the perturbed image points. <p> Following this, a fraction (= PO) of the 3D points were selected as outliers. Each of these points was replaced by another 3D point whose components were taken from a uniform distribution within a box <ref> [5; 5] </ref> fi [5; 5] fi [5; 5] in the object space. Finally, the resulting 3D points were projected onto the normalized image plane to produce image points. Gaussian noise was added to both coordinates of the image points to 17 generate the perturbed image points.
Reference: [6] <author> W. E. L. </author> <title> Grimson, Object Recognition by Computer. </title> <address> Cambridge, Massachusetts: </address> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: In computer vision, pose estimation is central to many approaches to object recognition <ref> [6] </ref>. The information available for solving the pose estimation problem is usually given in the form of a set of point correspondences, each composed of a 3D reference point expressed in object coordinates and its 2D projection expressed in image coordinates.
Reference: [7] <author> S. Ganapathy, </author> <title> "Decomposition of transformation matrices for robot vision," </title> <journal> Pattern Recognition Letters, </journal> <pages> pp. 401-412, </pages> <year> 1989. </year>
Reference-contexts: For three or four points, exact solutions can be computed: a fourth- or fifth-degree polynomial system can be formulated using geometrical invariants of the observed points, and the problem can be solved by finding roots of the polynomial system <ref> [7, 8, 9, 10, 11, 12] </ref>. However, the resulting methods can only be applied to a limited number of points and are thus sensitive to additive noise and possible outliers. For more than four points, closed form solutions do not exist.
Reference: [8] <author> M. Fischler and R. C. Bolles, </author> <title> "Random sample consensus: A paradigm for model fitting and automatic cartography," </title> <journal> Commun. ACM, </journal> <volume> no. 6, </volume> <pages> pp. 381-395, </pages> <year> 1981. </year>
Reference-contexts: For three or four points, exact solutions can be computed: a fourth- or fifth-degree polynomial system can be formulated using geometrical invariants of the observed points, and the problem can be solved by finding roots of the polynomial system <ref> [7, 8, 9, 10, 11, 12] </ref>. However, the resulting methods can only be applied to a limited number of points and are thus sensitive to additive noise and possible outliers. For more than four points, closed form solutions do not exist.
Reference: [9] <author> R. Horaud, B. Canio, and O. Leboullenx, </author> <title> "An analytic solution for the perspective 4-point problem," </title> <journal> Computer Vis. Graphics. Image Process, </journal> <volume> no. 1, </volume> <pages> pp. 33-44, </pages> <year> 1989. </year>
Reference-contexts: For three or four points, exact solutions can be computed: a fourth- or fifth-degree polynomial system can be formulated using geometrical invariants of the observed points, and the problem can be solved by finding roots of the polynomial system <ref> [7, 8, 9, 10, 11, 12] </ref>. However, the resulting methods can only be applied to a limited number of points and are thus sensitive to additive noise and possible outliers. For more than four points, closed form solutions do not exist.
Reference: [10] <author> R. M. Haralick, C. Lee, K. Ottenberg, and M. Nolle, </author> <title> "Analysis and solutions of the three point perspective pose estimation problem," </title> <booktitle> in Proc. IEEE Conf. Computer Vision Pat. Rec., </booktitle> <pages> pp. 592-598, </pages> <year> 1991. </year>
Reference-contexts: For three or four points, exact solutions can be computed: a fourth- or fifth-degree polynomial system can be formulated using geometrical invariants of the observed points, and the problem can be solved by finding roots of the polynomial system <ref> [7, 8, 9, 10, 11, 12] </ref>. However, the resulting methods can only be applied to a limited number of points and are thus sensitive to additive noise and possible outliers. For more than four points, closed form solutions do not exist.
Reference: [11] <author> D. DeMenthon and L. S. Davis, </author> <title> "Exact and approximate solutions of the perspective-three-point problem," </title> <journal> IEEE Trans. Pat. Anal. Machine Intell., </journal> <volume> no. 11, </volume> <pages> pp. 1100-1105, </pages> <year> 1992. </year>
Reference-contexts: For three or four points, exact solutions can be computed: a fourth- or fifth-degree polynomial system can be formulated using geometrical invariants of the observed points, and the problem can be solved by finding roots of the polynomial system <ref> [7, 8, 9, 10, 11, 12] </ref>. However, the resulting methods can only be applied to a limited number of points and are thus sensitive to additive noise and possible outliers. For more than four points, closed form solutions do not exist.
Reference: [12] <author> M. Dhome, M. Richetin, J. Lapreste, and G. Rives, </author> <title> "Determination of the attitude of 3-D objects from a single perspective view," </title> <journal> IEEE Trans. Pat. Anal. Machine Intell., </journal> <volume> no. 12, </volume> <pages> pp. 1265-1278, </pages> <year> 1989. </year>
Reference-contexts: For three or four points, exact solutions can be computed: a fourth- or fifth-degree polynomial system can be formulated using geometrical invariants of the observed points, and the problem can be solved by finding roots of the polynomial system <ref> [7, 8, 9, 10, 11, 12] </ref>. However, the resulting methods can only be applied to a limited number of points and are thus sensitive to additive noise and possible outliers. For more than four points, closed form solutions do not exist.
Reference: [13] <author> G. H. </author> <title> Rosenfield, "The problem of exterior orientation in photogrammetry," </title> <booktitle> Photogram-metric Engineering, </booktitle> <pages> pp. 536-553, </pages> <year> 1959. </year>
Reference-contexts: For more than four points, closed form solutions do not exist. The classical approach used in photogrammetry is to formulate pose estimation as a nonlinear least squares problem, and to solve it by nonlinear optimization algorithms, most typically, the Gauss-Newton method <ref> [13, 14, 15] </ref>. In the vision literature, the work by Lowe and its variants [16, 17] is an example of applying the Gauss-Newton method to the pose estimation problem. As with most nonlinear optimizations, these methods rely on a good initial guess to converge to the correct solution.
Reference: [14] <author> E. H. Tompson, </author> <title> "The projective theory of relative orientation," </title> <booktitle> Photogrammetria, </booktitle> <pages> pp. 67-75, </pages> <year> 1968. </year>
Reference-contexts: For more than four points, closed form solutions do not exist. The classical approach used in photogrammetry is to formulate pose estimation as a nonlinear least squares problem, and to solve it by nonlinear optimization algorithms, most typically, the Gauss-Newton method <ref> [13, 14, 15] </ref>. In the vision literature, the work by Lowe and its variants [16, 17] is an example of applying the Gauss-Newton method to the pose estimation problem. As with most nonlinear optimizations, these methods rely on a good initial guess to converge to the correct solution.
Reference: [15] <author> R. M. Haralick and L. G. Shapiro, </author> <title> Computer and Robot Vision. </title> <address> Reading, Massachusetts: </address> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1993. </year>
Reference-contexts: For more than four points, closed form solutions do not exist. The classical approach used in photogrammetry is to formulate pose estimation as a nonlinear least squares problem, and to solve it by nonlinear optimization algorithms, most typically, the Gauss-Newton method <ref> [13, 14, 15] </ref>. In the vision literature, the work by Lowe and its variants [16, 17] is an example of applying the Gauss-Newton method to the pose estimation problem. As with most nonlinear optimizations, these methods rely on a good initial guess to converge to the correct solution. <p> A random 3D rotation was generated by selecting a random unit quaternion from a unit 4-sphere. It can be shown that the distribution of 3D rotations generated by this process is also uniform [41]. For translation, the x and y components were uniformly selected from the interval <ref> [5; 15] </ref>, and the z component was selected from the interval [20; 50]. The set of reference points were then transformed by the randomly selected rotation and translation. Following this, a fraction (= PO) of the 3D points were selected as outliers.
Reference: [16] <author> D. G. Lowe, </author> <title> "Three-dimensional object recognition from single two-dimensional image," </title> <journal> Artificial Intelligence, </journal> <volume> vol. 31, </volume> <pages> pp. 355-395, </pages> <year> 1987. </year>
Reference-contexts: The classical approach used in photogrammetry is to formulate pose estimation as a nonlinear least squares problem, and to solve it by nonlinear optimization algorithms, most typically, the Gauss-Newton method [13, 14, 15]. In the vision literature, the work by Lowe and its variants <ref> [16, 17] </ref> is an example of applying the Gauss-Newton method to the pose estimation problem. As with most nonlinear optimizations, these methods rely on a good initial guess to converge to the correct solution.
Reference: [17] <author> H. Araujo, R. Carceroni, and C. Brown, </author> <title> "A fully projective formulation for Lowe's tracking algorithm," </title> <type> Tech. Rep. Technical Report 641, </type> <institution> University of Rochester, </institution> <year> 1996. </year>
Reference-contexts: The classical approach used in photogrammetry is to formulate pose estimation as a nonlinear least squares problem, and to solve it by nonlinear optimization algorithms, most typically, the Gauss-Newton method [13, 14, 15]. In the vision literature, the work by Lowe and its variants <ref> [16, 17] </ref> is an example of applying the Gauss-Newton method to the pose estimation problem. As with most nonlinear optimizations, these methods rely on a good initial guess to converge to the correct solution.
Reference: [18] <author> Y. I. Abdel-Aziz and H. M. Karara, </author> <title> "Direct linear transformation into object space coordinates in close-range photogrammetry," </title> <booktitle> in Symposium on Close-Range Photogram-metry (Urbana-Champaign, </booktitle> <address> IL), </address> <pages> pp. 1-18, </pages> <month> Jan </month> <year> 1971. </year>
Reference-contexts: There is no guarantee that the algorithm will eventually converge or that it will converge to the correct solution. A class of approximate methods for pose estimation have been developed by relaxing the orthogonality constraint on rotation matrices and/or by simplifying the perspective camera model <ref> [18, 19, 20, 21, 22, 23, 24, 25] </ref>. In iterative reduced perspective methods [23, 26], an approximate solution computed using a simplified camera model is iteratively refined 2 to approach a full perspective solution. <p> All the comparisons were conducted on a Silicon Graphics IRIS Indigo with a MIPS R4400 processor. 4.2.1 Results and Discussions The methods tested here are the orthogonal iteration algorithm, a linear method using full perspective camera model <ref> [18] </ref>, and a classical method using Levenberg-Marquardt minimization. An implementation of LM (called LMDIF) in MINPACK 2 is used in our experiments. 2 Visit http://www.mcs.anl.gov/summaries/minpack93/summary.html for information about the public-domain package MINPACK-2 that implements these methods. 18 Each point in the plot represents 1,000 trials.
Reference: [19] <author> Y. Yakimovsky and R. Cunningham, </author> <title> "A system for extracting three-dimensional measurements from a stereo pair of TV cameras," </title> <journal> Computer Graphics and Image Processing, </journal> <volume> vol. 7, </volume> <pages> pp. 195-210, </pages> <year> 1978. </year>
Reference-contexts: There is no guarantee that the algorithm will eventually converge or that it will converge to the correct solution. A class of approximate methods for pose estimation have been developed by relaxing the orthogonality constraint on rotation matrices and/or by simplifying the perspective camera model <ref> [18, 19, 20, 21, 22, 23, 24, 25] </ref>. In iterative reduced perspective methods [23, 26], an approximate solution computed using a simplified camera model is iteratively refined 2 to approach a full perspective solution.
Reference: [20] <author> O. D. Faugeras and G. Toscani, </author> <title> "Calibration problem for stereo," </title> <booktitle> in Proc. IEEE Conf. Computer Vision Pat. Rec., </booktitle> <pages> pp. 15-20, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: There is no guarantee that the algorithm will eventually converge or that it will converge to the correct solution. A class of approximate methods for pose estimation have been developed by relaxing the orthogonality constraint on rotation matrices and/or by simplifying the perspective camera model <ref> [18, 19, 20, 21, 22, 23, 24, 25] </ref>. In iterative reduced perspective methods [23, 26], an approximate solution computed using a simplified camera model is iteratively refined 2 to approach a full perspective solution. <p> It can be shown that the distribution of 3D rotations generated by this process is also uniform [41]. For translation, the x and y components were uniformly selected from the interval [5; 15], and the z component was selected from the interval <ref> [20; 50] </ref>. The set of reference points were then transformed by the randomly selected rotation and translation. Following this, a fraction (= PO) of the 3D points were selected as outliers.
Reference: [21] <author> R. Y. Tsai, </author> <title> "An effecient and accurate camera calibration technique for 3D machine vision," </title> <booktitle> in Proc. IEEE Conf. Computer Vision Pat. Rec., </booktitle> <pages> pp. 364-374, </pages> <year> 1986. </year>
Reference-contexts: There is no guarantee that the algorithm will eventually converge or that it will converge to the correct solution. A class of approximate methods for pose estimation have been developed by relaxing the orthogonality constraint on rotation matrices and/or by simplifying the perspective camera model <ref> [18, 19, 20, 21, 22, 23, 24, 25] </ref>. In iterative reduced perspective methods [23, 26], an approximate solution computed using a simplified camera model is iteratively refined 2 to approach a full perspective solution.
Reference: [22] <author> R. K. Lenz and R. Y. Tsai, </author> <title> "Techniques for calibration of the scale factor and image center for high accuracy 3-D machine vision metrology," </title> <journal> IEEE Trans. Pat. Anal. Machine Intell., </journal> <volume> vol. 10, no. 3, </volume> <pages> pp. 713-720, </pages> <year> 1988. </year>
Reference-contexts: There is no guarantee that the algorithm will eventually converge or that it will converge to the correct solution. A class of approximate methods for pose estimation have been developed by relaxing the orthogonality constraint on rotation matrices and/or by simplifying the perspective camera model <ref> [18, 19, 20, 21, 22, 23, 24, 25] </ref>. In iterative reduced perspective methods [23, 26], an approximate solution computed using a simplified camera model is iteratively refined 2 to approach a full perspective solution.
Reference: [23] <author> D. DeMenthon and L. Davis, </author> <title> "Model-based object pose in 25 lines of code," </title> <journal> IJCV, </journal> <volume> vol. 15, </volume> <pages> pp. 123-141, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: There is no guarantee that the algorithm will eventually converge or that it will converge to the correct solution. A class of approximate methods for pose estimation have been developed by relaxing the orthogonality constraint on rotation matrices and/or by simplifying the perspective camera model <ref> [18, 19, 20, 21, 22, 23, 24, 25] </ref>. In iterative reduced perspective methods [23, 26], an approximate solution computed using a simplified camera model is iteratively refined 2 to approach a full perspective solution. <p> A class of approximate methods for pose estimation have been developed by relaxing the orthogonality constraint on rotation matrices and/or by simplifying the perspective camera model [18, 19, 20, 21, 22, 23, 24, 25]. In iterative reduced perspective methods <ref> [23, 26] </ref>, an approximate solution computed using a simplified camera model is iteratively refined 2 to approach a full perspective solution. In these methods the rotation matrix is computed in two steps: first a linear (unconstrained) solution is computed, and then this solution is fit to the "closest" orthogonal matrix.
Reference: [24] <author> T. D. </author> <title> Alter, "3D pose from corresponding points under weak-perspective projection," </title> <type> Tech. Rep. </type> <institution> A.I. </institution> <note> Memo No. 1378, </note> <institution> MIT Artificial Intelligence Lab., </institution> <year> 1992. </year> <month> 24 </month>
Reference-contexts: There is no guarantee that the algorithm will eventually converge or that it will converge to the correct solution. A class of approximate methods for pose estimation have been developed by relaxing the orthogonality constraint on rotation matrices and/or by simplifying the perspective camera model <ref> [18, 19, 20, 21, 22, 23, 24, 25] </ref>. In iterative reduced perspective methods [23, 26], an approximate solution computed using a simplified camera model is iteratively refined 2 to approach a full perspective solution.
Reference: [25] <author> D. P. Huttenlocher and S. Ullman, </author> <title> "Recognizing solid objects by alignment with an image," </title> <journal> Intl. J. Computer Vision, </journal> <volume> vol. 5, no. 2, </volume> <pages> pp. 195-212, </pages> <year> 1990. </year>
Reference-contexts: There is no guarantee that the algorithm will eventually converge or that it will converge to the correct solution. A class of approximate methods for pose estimation have been developed by relaxing the orthogonality constraint on rotation matrices and/or by simplifying the perspective camera model <ref> [18, 19, 20, 21, 22, 23, 24, 25] </ref>. In iterative reduced perspective methods [23, 26], an approximate solution computed using a simplified camera model is iteratively refined 2 to approach a full perspective solution.
Reference: [26] <author> R. Horaud, S. Christy, and F. Dornaika, </author> <title> "Object pose: The link between weak perspective, para perspective and full perspective," </title> <type> Tech. Rep. </type> <institution> RR-2356, INRIA, </institution> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: A class of approximate methods for pose estimation have been developed by relaxing the orthogonality constraint on rotation matrices and/or by simplifying the perspective camera model [18, 19, 20, 21, 22, 23, 24, 25]. In iterative reduced perspective methods <ref> [23, 26] </ref>, an approximate solution computed using a simplified camera model is iteratively refined 2 to approach a full perspective solution. In these methods the rotation matrix is computed in two steps: first a linear (unconstrained) solution is computed, and then this solution is fit to the "closest" orthogonal matrix.
Reference: [27] <author> B. K. P. Horn, H. M. Hilden, and S. Negahdaripour, </author> <title> "Closed-form solution of absolute orientation using orthonomal matrices," </title> <journal> J. Opt. Soc. Amer., </journal> <volume> vol. A-5, </volume> <pages> pp. 1127-1135, 198. </pages>
Reference-contexts: It has been shown that this two-step approach for computing rotation is not the same as finding the best orthogonal matrix <ref> [27] </ref>. Again, with such methods there is no guarantee that they will eventually converge to the correct solution when applied iteratively. The developments in this article were originally motivated by the work of Haralick et el.[28]. <p> a solution to the following least squares problem min n X kRp i + t q i k 2 ; subject to R t R = I: (9) Such a constrained least squares problem [34] can be solved in closed form using quaternions [35, 36], or singular value decomposition (SVD) <ref> [27, 37, 35, 36] </ref>. The SVD solution proceeds as follows. <p> In this new objective function, the value of s together with R and t must be determined simultaneously. Horn presents a solution to this problem <ref> [35, 27] </ref> by considering the following modified objective function: min n X k p Rp 0 p i k 2 : (35) In this case, the solution for s is s = i=1 kp 0 P n i k 2 : (36) Furthermore, if the s is computed using (36), the
Reference: [28] <author> R. M. H. et. al., </author> <title> "Pose estimation from corresponding point data," </title> <journal> IEEE Trans. Sys. Man Cyber., </journal> <volume> vol. 19, no. 6, </volume> <pages> pp. 1426-1446, </pages> <year> 1989. </year>
Reference-contexts: What makes this algorithm attractive is that the non-linearity due to perspective is eliminated by the introduction of the depth variables. However, this algorithm has not received much attention, probably due its slow local convergence rate (hundreds of iterations) as indicated in <ref> [28] </ref> and found by ourselves. In our approach, we reformulate the pose estimation problem as that of minimizing an object-space collinearity error.
Reference: [29] <author> R. M. Haralick and L. G. Shapiro, </author> <title> Computer and Robot Vision, </title> <type> ch. 14, </type> <address> p. 132. Reading, Massachusetts: </address> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1993. </year>
Reference-contexts: If the initial approximate solution is good enough, it should converge very quickly to the correct solution. However, when the current solution is far from the correct one and/or the linear system is ill-conditioned, it may converge slowly or even fail to converge altogether. It has been empirically observed <ref> [29] </ref> that for the Gauss-Newton method to work, the initial approximate solutions have to be within 10% of scale for translation and within 15 o for each of the three rotation angles. The Levenberg-Marquardt method can be regarded as an interpolation of steepest descent and the Gauss-Newton method.
Reference: [30] <author> D. G. Lowe, </author> <title> "Fitting parametrized three-dimensional models to images," </title> <journal> IEEE Trans. Pat. Anal. Machine Intell., </journal> <volume> no. 5, </volume> <pages> pp. 441-450, </pages> <year> 1991. </year>
Reference-contexts: When the current solution is close to the correct solution, it becomes a Gauss-Newton method. It has become a standard technique for nonlinear least squares problems, and has been widely adopted in computer vision <ref> [30, 31] </ref> and computer graphics [3]. 7 2.3 Why another iterative algorithm? Classical optimization techniques are currently the only choice when observed data is noisy and a high accuracy solution to the pose estimation problem is desired. <p> An interesting extension will be to extend the formalism to include pose estimation from lines, and to compare the efficiency and accuracy with other existing pose tracking system such as demonstrated by Lowe <ref> [30] </ref>. A Uniqueness of the Optimal Solution to the Absolute Orientation Problem We show that the best rotation R to (9) is unique.
Reference: [31] <author> J. Weng, N. Ahuja, and T. S. Huang, </author> <title> "Optimal motion and structure estimation," </title> <journal> IEEE Trans. Pat. Anal. Machine Intell., </journal> <volume> vol. 15, no. 9, </volume> <pages> pp. 864-884, </pages> <year> 1993. </year>
Reference-contexts: When the current solution is close to the correct solution, it becomes a Gauss-Newton method. It has become a standard technique for nonlinear least squares problems, and has been widely adopted in computer vision <ref> [30, 31] </ref> and computer graphics [3]. 7 2.3 Why another iterative algorithm? Classical optimization techniques are currently the only choice when observed data is noisy and a high accuracy solution to the pose estimation problem is desired.
Reference: [32] <author> G. D. Hager, </author> <title> "Real-time feature tracking and projective invariance as a basis for hand-eye coordination," </title> <booktitle> in Proc. IEEE Conf. Computer Vision Pat. Rec., </booktitle> <pages> pp. 533-539, </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year>
Reference-contexts: Furthermore, the commonly used Euler angle parameterization of rotation obscures the algebraic structure of the problem. The analysis for both global and local convergence is only valid when the intermediate result is close to the solution. At the same time, recent developments in vision-based robotics <ref> [32, 33] </ref> and augmented reality demand pose estimation algorithms to be not only accurate, but also robust to corrupted data and computationally efficient.
Reference: [33] <author> S. Wijesoma, D. Wolfe, and R. Richards, </author> <title> "Eye-to-hand coordination for vision-guided robot control applications," </title> <journal> Intl. J. Rob. Res., </journal> <volume> vol. 12, no. 1, </volume> <pages> pp. 65-78, </pages> <year> 1993. </year>
Reference-contexts: Furthermore, the commonly used Euler angle parameterization of rotation obscures the algebraic structure of the problem. The analysis for both global and local convergence is only valid when the intermediate result is close to the solution. At the same time, recent developments in vision-based robotics <ref> [32, 33] </ref> and augmented reality demand pose estimation algorithms to be not only accurate, but also robust to corrupted data and computationally efficient.
Reference: [34] <author> O. Faugeras, </author> <title> Three-Dimensional Computer Vision. </title> <publisher> The MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: i : With three or more non-collinear reference points, R and t can be obtained as a solution to the following least squares problem min n X kRp i + t q i k 2 ; subject to R t R = I: (9) Such a constrained least squares problem <ref> [34] </ref> can be solved in closed form using quaternions [35, 36], or singular value decomposition (SVD) [27, 37, 35, 36]. The SVD solution proceeds as follows.
Reference: [35] <author> B. K. P. Horn, </author> <title> "Closed-form solution of absolute orientation using unit quaternion," </title> <journal> J. Opt. Soc. Amer., </journal> <volume> vol. A-4, </volume> <pages> pp. 629-642, </pages> <year> 1987. </year> <month> 25 </month>
Reference-contexts: R and t can be obtained as a solution to the following least squares problem min n X kRp i + t q i k 2 ; subject to R t R = I: (9) Such a constrained least squares problem [34] can be solved in closed form using quaternions <ref> [35, 36] </ref>, or singular value decomposition (SVD) [27, 37, 35, 36]. The SVD solution proceeds as follows. <p> a solution to the following least squares problem min n X kRp i + t q i k 2 ; subject to R t R = I: (9) Such a constrained least squares problem [34] can be solved in closed form using quaternions [35, 36], or singular value decomposition (SVD) <ref> [27, 37, 35, 36] </ref>. The SVD solution proceeds as follows. <p> In this new objective function, the value of s together with R and t must be determined simultaneously. Horn presents a solution to this problem <ref> [35, 27] </ref> by considering the following modified objective function: min n X k p Rp 0 p i k 2 : (35) In this case, the solution for s is s = i=1 kp 0 P n i k 2 : (36) Furthermore, if the s is computed using (36), the
Reference: [36] <author> M. W. Walker, L. Shao, and R. A. Volz, </author> <title> "Estimating 3-D location parameters using dual number quaternions," CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> vol. 54, no. 3, </volume> <pages> pp. 358-367, </pages> <year> 1991. </year>
Reference-contexts: R and t can be obtained as a solution to the following least squares problem min n X kRp i + t q i k 2 ; subject to R t R = I: (9) Such a constrained least squares problem [34] can be solved in closed form using quaternions <ref> [35, 36] </ref>, or singular value decomposition (SVD) [27, 37, 35, 36]. The SVD solution proceeds as follows. <p> a solution to the following least squares problem min n X kRp i + t q i k 2 ; subject to R t R = I: (9) Such a constrained least squares problem [34] can be solved in closed form using quaternions [35, 36], or singular value decomposition (SVD) <ref> [27, 37, 35, 36] </ref>. The SVD solution proceeds as follows.
Reference: [37] <author> K. S. Arun, T. S. Huang, and S. D. Blostein, </author> <title> "Least-squares fitting of two 3-D point sets," </title> <journal> IEEE Trans. Pat. Anal. Machine Intell., </journal> <volume> vol. 9, </volume> <pages> pp. 698-700, </pages> <year> 1987. </year>
Reference-contexts: a solution to the following least squares problem min n X kRp i + t q i k 2 ; subject to R t R = I: (9) Such a constrained least squares problem [34] can be solved in closed form using quaternions [35, 36], or singular value decomposition (SVD) <ref> [27, 37, 35, 36] </ref>. The SVD solution proceeds as follows.
Reference: [38] <author> D. G. Luenberger, </author> <title> Linear and Nonlinear Programming. </title> <address> Reading, Massachusetts: </address> <publisher> Addi-son Wesley, 2 ed., </publisher> <year> 1984. </year>
Reference-contexts: will satisfy R fl = arg min R i=1 11 3.3 Global Convergence We now wish to show that the orthogonal iteration algorithm will converge to an optimum of (23) for any set of observed points and any starting point R ( 0): Our proof, which follows the development in <ref> [38, Chap. 6] </ref>, first requires the following definition: Definition 3.1 A point-to-set mapping A from X to Y is said to be closed at x 2 X if the assumptions 1. x k ! x; x k 2 X imply 3. y 2 A (x) The point-to-set map A is said <p> Define OI : SO (3) ! SO (3) to be the mapping the generates R (k+1) from R (k) , that is, R (k+1) = OI (R (k) ). According to the Global Convergence Theorem <ref> [38] </ref>, to prove the global convergence of the orthogonal iteration algorithm we need to show that 1. OI is closed. 2. All fR (k) g generated by OI are contained in a compact set. 3. OI strictly decreases the objective function unless a solution is reached.
Reference: [39] <author> H. P. Moravec, </author> <title> Obstacle avoidance and navigation in the real world by a seeing robot rover. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1980. </year>
Reference-contexts: The absolute orientation problem can now be formulated as a scalar-weighted least squares n X 1 (k) k (I F i )(Rp i + t)k 2 : (40) Such weighting schemes were used in <ref> [39, 40] </ref> and can be easily incorporated into the algorithm developed above. 4 Performance Evaluation In this section, the theory and the algorithm, as well as the software implementation are evaluated using different test strategies. 4.1 Data generation protocol The protocol for generating the input data used throughout this section is
Reference: [40] <author> S. M. Kiang, R. J. Chou, and J. K. Aggarwal, </author> <title> "Triangulation errors in stereo algorithms," </title> <booktitle> in Proc. IEEE Workshop Computer Vision, </booktitle> <pages> pp. 72-78, </pages> <year> 1987. </year>
Reference-contexts: The absolute orientation problem can now be formulated as a scalar-weighted least squares n X 1 (k) k (I F i )(Rp i + t)k 2 : (40) Such weighting schemes were used in <ref> [39, 40] </ref> and can be easily incorporated into the algorithm developed above. 4 Performance Evaluation In this section, the theory and the algorithm, as well as the software implementation are evaluated using different test strategies. 4.1 Data generation protocol The protocol for generating the input data used throughout this section is
Reference: [41] <editor> D. K. Ed., </editor> <booktitle> Graphics Gems III, </booktitle> <pages> pp. 124-132. </pages> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: A random 3D rotation was generated by selecting a random unit quaternion from a unit 4-sphere. It can be shown that the distribution of 3D rotations generated by this process is also uniform <ref> [41] </ref>. For translation, the x and y components were uniformly selected from the interval [5; 15], and the z component was selected from the interval [20; 50]. The set of reference points were then transformed by the randomly selected rotation and translation.
Reference: [42] <author> P. J. Huber, </author> <title> Robust Statistics. </title> <publisher> John Wiley and Sons, </publisher> <year> 1981. </year>
Reference-contexts: For example, the method can be extended to handle uncertainty in the locations of the reference points on the object by slight modification of the objective function. The optimization could also be easily extended to perform a robust optimization step using IRLS methods <ref> [42] </ref> making it yet more robust to outliers. We are currently implementing a version of the algorithm within the XVision [43] environment for use in robotic applications, as well as augmented and virtual reality.
Reference: [43] <author> G. D. Hager and K. Toyama, "XVision: </author> <title> A portable substrate for real-time vision applications," </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <year> 1998. </year> <note> To Appean, </note> <month> Jan. </month> <year> 1998. </year>
Reference-contexts: The optimization could also be easily extended to perform a robust optimization step using IRLS methods [42] making it yet more robust to outliers. We are currently implementing a version of the algorithm within the XVision <ref> [43] </ref> environment for use in robotic applications, as well as augmented and virtual reality. An initial implementation described in [44] has shown that, by combining efficient local tracking with efficient pose estimation, it is relatively simple to construct real-time object tracking system which run on typical desktop hardware.
Reference: [44] <author> C.-P. Lu, </author> <title> Online Pose Estimation and Model Matching. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <year> 1995. </year>
Reference-contexts: We are currently implementing a version of the algorithm within the XVision [43] environment for use in robotic applications, as well as augmented and virtual reality. An initial implementation described in <ref> [44] </ref> has shown that, by combining efficient local tracking with efficient pose estimation, it is relatively simple to construct real-time object tracking system which run on typical desktop hardware.
References-found: 44

