URL: http://www.isi.edu/teamcore/tambe/papers/98/atal97fin.ps
Refering-URL: http://www.isi.edu/teamcore/tambe/agent.html
Root-URL: http://www.isi.edu
Email: galk, tambe-@isi.edu  
Title: Social Comparison for Failure Detection and Recovery  
Author: Gal A. Kaminka and Milind Tambe 
Address: 4676 Admiralty Way, Marina del Rey, CA 90292  
Affiliation: Computer Science Department and Information Sciences Institute University of Southern California  
Abstract: Plan execution monitoring in dynamic and uncertain domains is an important and difficult problem. Multi-agent environments exacerbate this problem, given that interacting and coordinated activities of multiple agents are to be monitored. Previous approaches to this problem do not detect certain classes of failures, are inflexible, and are hard to scale up. We present a novel approach, SOCFAD, to failure detection and recovery in multi-agent settings. SOCFAD is inspired by Social Comparison Theory from social psychology and includes the following key novel concepts: (a) utilizing other agents in the environment as information sources for failure detection, (b) a detection and repair method for previously undetectable failures using abductive inference based on other agents beliefs, and (c) a decision-theoretic approach to selecting the information acquisition medium. An analysis of SOCFAD is presented, showing that the new method is complementary to previous approaches in terms of classes of failures detected.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Atkins, E. M.; Durfee, E. H.; and Shin, K. G. </author> <year> 1996. </year> <title> Detecting and reacting to unplanned-for world states, </title> <booktitle> in Proceedings of the AAAI-96 Fall symposium on Plan Execution. </booktitle> <pages> pp. 1-7. </pages>
Reference: 2. <author> Bakker, P.; and Kuniyoshi, Y. </author> <year> 1996. </year> <title> Robot see, robot do: An overview of robot imitation. </title> <booktitle> AISB Workshop on Learning in Robots and Animals, </booktitle> <address> Brighton, UK. </address>
Reference-contexts: Also, while Huber and Durfee demonstrate the benefits of using plan-recognition rather than explicit communications in a dynamic domain, they do not discuss the qualities of the domain which make plan-recognition beneficial. The decision-tree provided in the previous section presents a first step towards this direction. Atkins et al. <ref> [2] </ref> attacks a similar problem of detecting states for which the agent does not have a plan ready. They offer a classification of these states, and provide planning algorithms that build tests for these states. However, their approach considers only the individual agents and not teams. <p> It also suffers from the same limitations as condition monitoring approaches in not being able to detect modeled states which have not been sensed correctly. For instance, their approach cannot detect states which were not planned-for by the planner, but are still safe <ref> [2] </ref> such as the example of the undetected landmark. Social comparison is also related to imitation [2]. In fact, imitation can be shown to be a special case of the general social comparison algorithm (Algorithm 1). <p> For instance, their approach cannot detect states which were not planned-for by the planner, but are still safe <ref> [2] </ref> such as the example of the undetected landmark. Social comparison is also related to imitation [2]. In fact, imitation can be shown to be a special case of the general social comparison algorithm (Algorithm 1). By choosing to compare itself against the observable behavior of other agents, rather than their internal goals, the social comparison approach leads to imitation.
Reference: 3. <author> Doyle R. J., Atkinson D. J., Doshi R. S., </author> <title> Generating perception requests and expectations to verify the execution of plans, </title> <booktitle> in Proceedings of AAAI-86 , Philadelphia, </booktitle> <address> PA (1986). </address>
Reference-contexts: 1 Introduction Agent behavior monitoring in complex dynamic environments is an important and well known problem, e.g., <ref> [3] </ref>, [10]. This problem is exacerbated in multi-agent environments due to the added requirements for communication and coordination. <p> To this end, an agent must have information about the ideal behavior expected of it. This ideal can be compared to the agents actual behavior to detect discrepancies indicating possible failures. Previous approaches to this problem (e.g., <ref> [3] </ref>, [10], [15]) have focused on the designer or planner supplying the agent with redundant information, either in the form of explicitly specified execution-monitoring conditions, or a model of the agent itself which may be used for comparison.
Reference: 4. <author> Festinger, L. </author> <year> 1954. </year> <title> A theory of social comparison processes. </title> <booktitle> Human Relations, </booktitle> <volume> 7, </volume> <pages> pp. 117-140. </pages>
Reference-contexts: be useful in detecting failures in the agents behavior, but as condition-monitoring approaches and activity measurement monitoring are already common techniques in failure detection, we will focus on the social comparison process in the next section. 4 Social Comparison for Failure Detection: SOCFAD SOCFAD is inspired by Social Comparison Theory <ref> [4] </ref>, a theory from social psychology, developed to explain cognitive processes in groups of humans. Newell [9] presents the first three axioms of this theory as follows (pg. 497): 1. Every agent has a drive to evaluate its opinions and abilities. 2.
Reference: 5. <author> Firby, J. </author> <year> 1987. </year> <title> An investigation into reactive planning in complex domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI-87). </booktitle>
Reference: 6. <author> Huber, M. J.; and Durfee, E. H. </author> <year> 1996. </year> <title> An Initial Assessment of Plan-Recognition-Based Coordination for Multi-Agent Teams. </title> <booktitle> In Proceedings of the Second International Conference on Multi-Agent Systems (ICMAS-96). </booktitle> <address> Kyoto, Japan. </address> <pages> pp. 126-133. </pages>
Reference-contexts: Particularly relevant are observation-based methods, which utilize agent modeling rather than communications for coordination (e.g., <ref> [6] </ref>, [14]). Work on teamwork [14] concentrates on maintaining identical joint goals to prevent miscoordination, while the focus of SOCFAD is on detecting when the goals do differ. Indeed, social comparison can be useful for recovering from failures in teamwork. <p> Indeed, social comparison can be useful for recovering from failures in teamwork. The recovery from the undetected landmark failure mentioned earlier can be construed as an example of active coordination on the part of the team. Huber and Durfee <ref> [6] </ref> do not assume joint goals but instead look at coordination as emergent from opportunistic agents, which coordinate with others when it suits their individual goals.
Reference: 7. <author> Levesque, H. J.; Cohen, P. R.; Nunes, J. </author> <year> 1990. </year> <title> On acting together, </title> <booktitle> in Proceedings of the National Conference on Artificial Intelligence (AAAI-1990) , Menlo Park, </booktitle> <address> California, </address> <publisher> AAAI Press. </publisher>
Reference-contexts: The design implements the Joint Intention Framework <ref> [7] </ref>. Following this framework, operators may be team operators (shared by the team) or individual (specific to one agent). Boxed operator names signify team operators, which achieve and maintain joint goals, while the other operators are individual. <p> The comparison process in Find-Difference therefore considers team members only. 4.1 Team Operator Differences Our agents use the Joint Intentions framework <ref> [7] </ref> as the basis for their coordination of team activities. In this framework, explicit team operators form the basis for teamwork, requiring mutual belief (MB) on the part of the team members as a condition for the establishment, and termination (based on achievement, unachieveability, or irrelevancy), of explicit team operators.
Reference: 8. <author> Mataric, M. J. </author> <year> 1993. </year> <title> Kin Recognition, Similarity, and Group Behavior. </title> <booktitle> In Proceedings of the Fifteenth Annual Cognitive Science Society Conference. </booktitle> <address> Boulder, Colorado. </address> <pages> Pp. 705-710. </pages>
Reference-contexts: Instead, with SOCFAD the agent would compare the plan that it is executing with those of its teammates, and realize that they are now executing a different plan, based on detecting a landmark which it has failed to detect. It could thus recover from such an error. Mataric <ref> [8] </ref> used socially similar agents ( next of kin ) to investigate generation of group behavior from local interactions, while the focus of SOCFAD is on failure detection.
Reference: 9. <author> Newell A., </author> <year> 1990. </year> <title> Unified Theories of Cognition. </title> <publisher> Harvard University Press. </publisher>
Reference-contexts: We propose a complementary novel approach to failure detection and recovery, which is unique to multi-agent settings. This approach, SOCFAD (Social Comparison for FAilure Detection), is inspired by ideas from Social Comparison Theory <ref> [9] </ref>. The key idea in SOCFAD is that agents use other agents as sources of information on the situation and the ideal behavior. The agents compare their own behavior, beliefs, goals, and plans to those of other agents, in order to detect failures and correct their behavior. <p> Newell <ref> [9] </ref> presents the first three axioms of this theory as follows (pg. 497): 1. Every agent has a drive to evaluate its opinions and abilities. 2. If the agent cant evaluate its opinions and abilities objectively, then it compares them against the opinions and abilities of others. 3. <p> Execute Missio n W a it at P oin t Travellin g Fly R ou te Fly Fligh t Plan Na p o f th e Earth Co ntour Lo w-Level Ju st W a it Scou t Forw ard Our agents design is based on reactive plans (operators) ([5], <ref> [9] </ref>, [11]), which form a hierarchy that controls each agent (Figure 2). The design implements the Joint Intention Framework [7]. Following this framework, operators may be team operators (shared by the team) or individual (specific to one agent). <p> This fulfills the preconditions of its own wait-at-point operator, which is now selected and allows the agent to recover gracefully from the failure. 5 Results and Evaluation Our agent, including IFDARS, is implemented completely in Soar <ref> [9] </ref>. Approximately 1200 rules are used in the implementation of the agent, which includes the military procedures, as well as the teamwork and agent-modeling capabilities. Additional 60 rules implement IFDARS, forming an add-on layer on top of the procedures making up the agent.
Reference: 10. <author> Reece, G. A.; and Tate, A. </author> <title> Synthesizing protection monitors from causal structure, </title> <booktitle> in Proceedings of AIPS-94, </booktitle> <address> Chicago, Illinois (1994). </address>
Reference-contexts: 1 Introduction Agent behavior monitoring in complex dynamic environments is an important and well known problem, e.g., [3], <ref> [10] </ref>. This problem is exacerbated in multi-agent environments due to the added requirements for communication and coordination. <p> To this end, an agent must have information about the ideal behavior expected of it. This ideal can be compared to the agents actual behavior to detect discrepancies indicating possible failures. Previous approaches to this problem (e.g., [3], <ref> [10] </ref>, [15]) have focused on the designer or planner supplying the agent with redundant information, either in the form of explicitly specified execution-monitoring conditions, or a model of the agent itself which may be used for comparison.
Reference: 11. <author> Rao, A. S.; Lucas, A.; Morley, D., Selvestrel, M.; and Murray, G. </author> <year> 1993. </year> <title> Agent-oriented architecture for air-combat simulation. </title> <type> Technical Report: Technical Note 42, </type> <institution> The Australian Artificial Intelligence Institute. </institution>
Reference-contexts: Missio n W a it at P oin t Travellin g Fly R ou te Fly Fligh t Plan Na p o f th e Earth Co ntour Lo w-Level Ju st W a it Scou t Forw ard Our agents design is based on reactive plans (operators) ([5], [9], <ref> [11] </ref>), which form a hierarchy that controls each agent (Figure 2). The design implements the Joint Intention Framework [7]. Following this framework, operators may be team operators (shared by the team) or individual (specific to one agent).
Reference: 12. <author> Tambe, M.; Johnson W. L.; Jones, R.; Koss, F.; Laird, J. E.; Rosenbloom, P. S.; and Schwamb, K. </author> <year> 1995. </year> <title> Intelligent Agents for interactive simulation environments. </title> <journal> AI Magazine, </journal> <note> 16(1) (Spring). </note>
Reference-contexts: explicit, IFDARS recovery modules can utilize different information sources and parameterized biases to reason about the differences in a general way. 2 SOCFAD and IFDARS: Motivation The motivation for our approach comes from our application domain which involves developing automated pilot agents for participation in synthetic multi-agent battlefield simulation environments <ref> [12] </ref>. The environment was commercially developed for military training, and is highly dynamic, complex, and rich in detail. In addition to the unpredictability of the environment, communications and sensors are unreliable, mission and task specifications may be incomplete, etc.
Reference: 13. <author> Tambe, M. </author> <year> 1996. </year> <title> Tracking Dynamic Team Activity, </title> <booktitle> in Proceedings of the National Conference on Artificial Intelligence (AAAI-96), </booktitle> <address> Portland, Oregon. </address>
Reference-contexts: Instead our implementation of SOCFAD relies on agent modeling (plan recognition) techniques that infer an agents beliefs, goals, and plans from its observable behavior and surrounding. We use the RESC team <ref> [13] </ref> method in modeling other agents, but different techniques may be used interchangeably, as long as they provide the needed information and representation. RESC team will be briefly described here (see [13] for more detail). <p> We use the RESC team <ref> [13] </ref> method in modeling other agents, but different techniques may be used interchangeably, as long as they provide the needed information and representation. RESC team will be briefly described here (see [13] for more detail). RESC team represents other agents plans by building additional operator hierarchies in the agents memory which correspond to the other agents inferred reactive plans currently executed.
Reference: 14. <author> Tambe, M. </author> <year> 1997. </year> <title> Agent Architectures for Flexible, Practical Teamwork, </title> <booktitle> in Proceedings of the National Conference on Artificial Intelligence , Providence, </booktitle> <address> Rhode Island (To appear). </address>
Reference-contexts: Boxed operator names signify team operators, which achieve and maintain joint goals, while the other operators are individual. Team operators require coordination with the other members of the team as part of their application ([13], <ref> [14] </ref>). Figure 2 presents a small portion of the hierarchy. The filled arrows signify the operator hierarchy currently in control, while dotted arrows point to alternative operators which may be used. <p> Particularly relevant are observation-based methods, which utilize agent modeling rather than communications for coordination (e.g., [6], <ref> [14] </ref>). Work on teamwork [14] concentrates on maintaining identical joint goals to prevent miscoordination, while the focus of SOCFAD is on detecting when the goals do differ. Indeed, social comparison can be useful for recovering from failures in teamwork. <p> Particularly relevant are observation-based methods, which utilize agent modeling rather than communications for coordination (e.g., [6], <ref> [14] </ref>). Work on teamwork [14] concentrates on maintaining identical joint goals to prevent miscoordination, while the focus of SOCFAD is on detecting when the goals do differ. Indeed, social comparison can be useful for recovering from failures in teamwork.
Reference: 15. <author> Williams, B. C.; and Nayak, P. P. </author> <year> 1996. </year> <title> A Model-Based Approach to Reactive Self-Configuring Systems. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96), </booktitle> <address> Portland, Oregon. </address>
Reference-contexts: To this end, an agent must have information about the ideal behavior expected of it. This ideal can be compared to the agents actual behavior to detect discrepancies indicating possible failures. Previous approaches to this problem (e.g., [3], [10], <ref> [15] </ref>) have focused on the designer or planner supplying the agent with redundant information, either in the form of explicitly specified execution-monitoring conditions, or a model of the agent itself which may be used for comparison.
References-found: 15

