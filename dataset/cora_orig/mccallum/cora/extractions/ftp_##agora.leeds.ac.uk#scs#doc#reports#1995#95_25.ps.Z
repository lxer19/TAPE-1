URL: ftp://agora.leeds.ac.uk/scs/doc/reports/1995/95_25.ps.Z
Refering-URL: http://www.cirl.uoregon.edu/constraints/links/pubs.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Phase Transition Behaviour of Maintaining Arc Consistency  
Author: by Stuart A. Grant and Barbara M. Smith 
Date: August 1995  
Affiliation: Division of Artificial Intelligence  
Note: The  
Abstract: University of Leeds SCHOOL OF COMPUTER STUDIES RESEARCH REPORT SERIES Report 95.25 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. B. Baker. </author> <title> Intelligent backtracking on the hardest constraint problems. </title> <type> Technical report, </type> <institution> CIRL and DCIS, University of Oregon, United States, </institution> <year> 1995. </year>
Reference-contexts: To date no complete 1 search method has been shown to be completely immune from ehps, although studies of various algorithms <ref> [40, 41, 7, 1] </ref> have shown that their incidence and magnitude varies greatly between search methods. <p> Although maintaining a higher level of consistency would very likely further reduce ehp incidence, the probable overheads involved would be prohibitively expensive. Baker <ref> [1] </ref> suggests that all exceptionally hard problems can be eliminated by a search strategy employing a sufficiently intelligent backtracker, and presents experiments using dependency-directed backtracking [18] which records nogoods during search.
Reference: [2] <author> C. Bessiere and J.-C. Regin. </author> <title> An arc consistency algorithm optimal in the number of constraint checks. </title> <editor> In M. Meyer, editor, </editor> <booktitle> Proceedings of the ECAI-94 Workshop on Constraint Processing, </booktitle> <pages> pages 9-16, </pages> <month> Aug. </month> <year> 1994. </year> <month> 42 </month>
Reference-contexts: We conducted a brief study of the effects of preprocessing using AC-3 on each of the problem classes listed in Tables 1 and 2. This study is similar in style to that of Borrett & Tsang [4], who reported the effects of preprocessing with AC-6 <ref> [2] </ref> in terms of the amount of useful work (i.e. the amount of domain pruning) performed on various CSP problem classes.
Reference: [3] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press, </publisher> <year> 1985. </year>
Reference-contexts: As we reported in [40], individual ehps are highly dependent on the algorithm being used: even a minor change in variable instantiation order may convert an ehp into a much easier problem. 2 Theoretical work on the connectivity of random graphs can be found in <ref> [3] </ref>. 6 So although individual ehps, and what makes them so difficult for a particular algorithm, should be investigated, we can also ask about ehps in relation to populations of problems and in relation to search algorithms: for instance, do ehps occur in all populations of problems, and are some search
Reference: [4] <author> J. E. Borrett and E. P. K. Tsang. </author> <title> Observations on the usefulness of arc consistency preprocessing. </title> <type> Technical Report CSM-236, </type> <institution> Department of Computer Science, University of Essex, UK, </institution> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: Theoretical work on predicting the existing level of consistency in constraint networks has been presented by van Beek [43], and empirical studies of AC preprocessing by Borrett & Tsang <ref> [4] </ref> has shown that its usefulness is restricted to problems that are over-constrained. <p> We conducted a brief study of the effects of preprocessing using AC-3 on each of the problem classes listed in Tables 1 and 2. This study is similar in style to that of Borrett & Tsang <ref> [4] </ref>, who reported the effects of preprocessing with AC-6 [2] in terms of the amount of useful work (i.e. the amount of domain pruning) performed on various CSP problem classes. <p> As we are dealing with the practical application of AC preprocessing, we also terminate the algorithm upon wipe-out of any variable domain, in which case we know that there are no solutions (the preprocessing reported in <ref> [4] </ref> was always run to completion). For each hn; m; p 1 i problem class we varied p 2 in steps of 0.01 over the interval [0:01; 1:00], generating 1000 problems at each point and preprocessing each problem with AC-3. <p> the number of arc-inconsistent values for AC-3 to find is still increasing, and hence domain wipe-outs are occurring more quickly, resulting in the earlier termination of the algorithm (if AC-3 were being run to completion, the curves would rise to a plateau at n fi m, as those shown in <ref> [4] </ref> do). When the curves fall to m, there are no arc-consistent values in any variable domain, and so the algorithm immediately removes the m values in the domain of the first variable it examines and terminates. <p> Observation of the actual positions of the pruning curves agree with the findings reported in <ref> [4] </ref>, in that AC preprocessing has very little effect (in removing values) unless the constraints are tight.
Reference: [5] <author> P. Cheeseman, B. Kanefsky, and W. Taylor. </author> <title> Where the Really Hard Problems are. </title> <booktitle> In Proceedings IJCAI-91, </booktitle> <volume> volume 1, </volume> <pages> pages 331-337, </pages> <year> 1991. </year>
Reference-contexts: Cheeseman, Kanefsky and Taylor <ref> [5] </ref> first reported the phase transition as the interface between a region where almost all problems have many solutions and are relatively easy to solve, and a region where almost all problems have no solution and their insolubility is relatively easy to prove. <p> Phase transition behaviour has been reported in an increasing number of classes of problem, including satisfiability problems [6, 14, 22, 25], Hamilto-nian paths <ref> [5] </ref>, and the travelling salesman problem [16, 17]. <p> with the number of variables if constraint density is constant, so as n is doubled with constant p 1 , fl also approximately doubles (for instance h30; m; 0:1i and h60; m; 0:05i problems would both have 6 Average degree is in fact a control parameter for graph colouring problems <ref> [5] </ref> 11 fl around 2.93, and so the latter would give a better indication of the effects of increasing problem size than would h60; m; 0:1i problems).
Reference: [6] <author> J. M. Crawford and L. D. Auton. </author> <title> Experimental Results on the Crossover Point in Satisfiability Problems. </title> <booktitle> In Proceedings of AAAI93, </booktitle> <pages> pages 21-27, </pages> <year> 1993. </year>
Reference-contexts: Smith [35, 37] has termed this region the mushy region; as problem size increases, the mushy region becomes narrower, and is instantaneous in the limit [45, 46, 47]. Phase transition behaviour has been reported in an increasing number of classes of problem, including satisfiability problems <ref> [6, 14, 22, 25] </ref>, Hamilto-nian paths [5], and the travelling salesman problem [16, 17].
Reference: [7] <author> A. Davenport and E. P. K.Tsang. </author> <title> An empirical investigation into the exceptionally hard problems. </title> <type> Technical Report CSM-239, </type> <institution> Department of Computer Science, University of Essex, U.K., </institution> <year> 1995. </year>
Reference-contexts: To date no complete 1 search method has been shown to be completely immune from ehps, although studies of various algorithms <ref> [40, 41, 7, 1] </ref> have shown that their incidence and magnitude varies greatly between search methods. <p> It is clearly important, therefore, to consider relative ehp behaviour when comparing algorithm performance. 1 To date, no exceptionally hard soluble problems have been reported in studies of incomplete local search methods, for instance those reported in <ref> [7] </ref>, [13] and [21]. 3 1.2 A history of MAC Although MAC is a popular technique employed by the constraint programming community, and is used by many constraint solving tools such as ILOG Solver [32], its application by the constraint satisfaction community has until very recently been passed over in favour
Reference: [8] <author> R. Dechter and J. Pearl. </author> <title> Network-based heuristics for constraint-satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <volume> 34 </volume> <pages> 1-38, </pages> <year> 1988. </year>
Reference-contexts: There has been a rapid move away from attempting to classify algorithms on the basis of limited testing on sets of homogenous problems, such as n-queens or the zebra problem <ref> [8] </ref>, towards attempting to classify algorithms in terms of performance on large samples of problems of varying size, topology and position in relation to the phase transition (for instance the study by Tsang, et al. [42]).
Reference: [9] <author> J. Gaschnig. </author> <title> A constraint satisfaction method for inference making. </title> <booktitle> In Proceedings of the 12th Annual Allerton Conference on Circuit and System Theory, </booktitle> <institution> University of Illinois, Urbana-Champaign, USA, </institution> <month> Oct. </month> <year> 1974. </year>
Reference-contexts: We study a version of the algorithm originally reported by Gaschnig as CS2 <ref> [9] </ref> and later as DEEB (Domain Element Elimination with Backtracking) [10]. The algorithm re-establishes arc consistency after every instantiation in the sub-problem formed by the future variables and their remaining domains, and following Sabin & Freuder [34] we have termed this algorithm MAC (Maintaining Arc Consistency).
Reference: [10] <author> J. Gaschnig. </author> <title> Performance measurement and analysis of certain search algorithms. </title> <type> Technical Report CMU-CS-79-124, </type> <institution> Carnegie-Mellon University, Pittsburgh USA, </institution> <year> 1979. </year>
Reference-contexts: We study a version of the algorithm originally reported by Gaschnig as CS2 [9] and later as DEEB (Domain Element Elimination with Backtracking) <ref> [10] </ref>. The algorithm re-establishes arc consistency after every instantiation in the sub-problem formed by the future variables and their remaining domains, and following Sabin & Freuder [34] we have termed this algorithm MAC (Maintaining Arc Consistency).
Reference: [11] <author> I. P. Gent, E. MacIntyre, P. Prosser, and T. Walsh. </author> <title> Scaling Effects in the CSP Phase Transition. </title> <editor> In U. Montanari and F. Rossi, editors, </editor> <booktitle> Proceedings CP-95, </booktitle> <pages> pages 70-87. </pages> <publisher> Springer-Verlag, </publisher> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: However, it may not reflect the varying levels of search effort required during each trial instantiation, and so is not as analogous to real time as consistency checks. 7 Recent work on scaling effects in CSPs <ref> [11] </ref> uses a control parameter t whose value is a constant times fl. 8 For example, whether a check should be counted if the variables are unconstrained: we do not do so. CPU time: the amount of cpu time elapsed during each search is measured approximately. <p> As n decreases, p 1 increases and we see the observed critical values moving slightly closer to ^p 2crit . It is worth noting that finite size scaling <ref> [11] </ref> applied to the satisfiability curves, using a rescaled order parameter, would allow the curves to line up exactly, although this would not correct the inaccuracies in predicting the critical value of the control parameter for sparsely constrained problems. 5.3 Presentation of the results We present the results of our studies <p> We have been able to show that MAC performance scales at a better rate than FC as problems become larger, but at present the rates of increase cannot be specified exactly. The application of techniques such as finite size scaling <ref> [11] </ref> may make this possible in future, and this would constitute a major advance in the development of an "empirical science of algorithms".
Reference: [12] <author> I. P. Gent and T. Walsh. </author> <title> Easy Problems are Sometimes Hard. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 335-345, </pages> <year> 1994. </year>
Reference-contexts: However, recent studies have highlighted a phenomenon that complicates the phase transition model. The existence of exceptionally hard problems ("ehps") has been reported by Hogg & Williams [21] in graph colouring, Gent & Walsh <ref> [12] </ref> in satisfiability problems, and by Smith [35] and Smith & Grant [40] in CSPs. These studies show that although there is a well-defined peak in the median cost of finding a solution in the region of the phase transition, this is often not where the hardest individual instances occur. <p> For some problem classes, we have therefore chosen to plot the median and higher percentiles, up to the maximum cost, for the sets of problems; this follows graphs shown by Hogg & Williams [21] and Gent & Walsh <ref> [12] </ref>. 7.1 General and extreme behaviour on a selection of the n = 30 problem classes, while Figure 5 shows the median and higher percentiles for three of these problem classes. <p> As expected, the median consistency checking effort increases steadily as n in 14 This is not necessarily true for other problem classes such as SAT <ref> [12] </ref>. 23 consistency checks performed. creases, and the phase transition regions are in approximately the same location, as indicated by the satisfiability curves of Figure 2.
Reference: [13] <author> I. P. Gent and T. Walsh. </author> <title> The Hardest Random SAT Problems. </title> <editor> In B. Nebel and L. Dreschler-Fischer, editors, </editor> <booktitle> Proceedings KI-94: Advances in Artificial Intelligence. !8th German Annual Conference on Artificial Intelligence, </booktitle> <pages> pages 355-366. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: It is clearly important, therefore, to consider relative ehp behaviour when comparing algorithm performance. 1 To date, no exceptionally hard soluble problems have been reported in studies of incomplete local search methods, for instance those reported in [7], <ref> [13] </ref> and [21]. 3 1.2 A history of MAC Although MAC is a popular technique employed by the constraint programming community, and is used by many constraint solving tools such as ILOG Solver [32], its application by the constraint satisfaction community has until very recently been passed over in favour of
Reference: [14] <author> I. P. Gent and T. Walsh. </author> <title> The SAT phase transition. </title> <booktitle> In Proceedings ECAI-94, </booktitle> <pages> pages 105-109, </pages> <year> 1994. </year>
Reference-contexts: Smith [35, 37] has termed this region the mushy region; as problem size increases, the mushy region becomes narrower, and is instantaneous in the limit [45, 46, 47]. Phase transition behaviour has been reported in an increasing number of classes of problem, including satisfiability problems <ref> [6, 14, 22, 25] </ref>, Hamilto-nian paths [5], and the travelling salesman problem [16, 17].
Reference: [15] <author> I. P. Gent and T. Walsh. </author> <title> The Satisfiability Constraint Gap. </title> <type> Research Paper 702, </type> <institution> Department of A.I., University of Edinburgh, </institution> <year> 1994. </year> <note> To appear in the AI Journal special issue on Phase Transitions in Problem Spaces. 43 </note>
Reference-contexts: We will investigate this belief in Section 8. The results of this study of AC preprocessing may be relevant to the notion of a "constraint gap", proposed by Gent & Walsh <ref> [15] </ref> as the conditions arising in sparsely constrained problem classes that give rise to the occurrence of ehps.
Reference: [16] <author> I. P. Gent and T. Walsh. </author> <title> Computational Phase Transitions from Real Problems. </title> <note> In Proceedings ISAI-95, Mexico (to appear), </note> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: Phase transition behaviour has been reported in an increasing number of classes of problem, including satisfiability problems [6, 14, 22, 25], Hamilto-nian paths [5], and the travelling salesman problem <ref> [16, 17] </ref>. Williams and 2 Hogg [45, 46, 47] have developed approximations to the cost of finding the first solution and to the probability that a problem is soluble, both for specific classes of constraint satisfaction problem (graph colouring, k-SAT) and for the general case.
Reference: [17] <author> I. P. Gent and T. Walsh. </author> <title> The TSP Phase Transition. </title> <type> Technical Report 178-95, </type> <institution> Department of Computer Science, University of Strathclyde, UK, </institution> <year> 1995. </year>
Reference-contexts: Phase transition behaviour has been reported in an increasing number of classes of problem, including satisfiability problems [6, 14, 22, 25], Hamilto-nian paths [5], and the travelling salesman problem <ref> [16, 17] </ref>. Williams and 2 Hogg [45, 46, 47] have developed approximations to the cost of finding the first solution and to the probability that a problem is soluble, both for specific classes of constraint satisfaction problem (graph colouring, k-SAT) and for the general case.
Reference: [18] <author> M. Ginsberg. </author> <title> Dynamic Backtracking. </title> <journal> Journal of A.I. Research, </journal> <volume> 1 </volume> <pages> 25-46, </pages> <year> 1993. </year>
Reference-contexts: Although maintaining a higher level of consistency would very likely further reduce ehp incidence, the probable overheads involved would be prohibitively expensive. Baker [1] suggests that all exceptionally hard problems can be eliminated by a search strategy employing a sufficiently intelligent backtracker, and presents experiments using dependency-directed backtracking <ref> [18] </ref> which records nogoods during search. However, Baker admits that this algorithm `has an increasing [spatial] overhead as problems get harder' which once again may be prohibitively expensive.
Reference: [19] <author> S. W. Golomb and L. D. Baumert. </author> <title> Backtrack Programming. </title> <journal> Journal of the ACM, </journal> <volume> 12 </volume> <pages> 516-524, </pages> <year> 1965. </year>
Reference-contexts: However, subsequent studies [41] have shown that densely-constrained ehps may occur with the most naive algorithms having no form of look-ahead capability, for instance plain chronological backtracking <ref> [19] </ref>. Having examined what might be termed the "macroscopic" behaviour of ehps for this algorithm, we then studied the "microscopic" behaviour of a selection of individual ehps in an attempt to understand the cause of their difficulty.
Reference: [20] <author> R. Haralick and G. Elliott. </author> <title> Increasing tree search efficiency for constraint satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <volume> 14 </volume> <pages> 263-313, </pages> <year> 1980. </year>
Reference-contexts: 1 Introduction Backtracking search algorithms which maintain some level of consistency among the uninstantiated, or future, variables during search have become established as the favoured complete methods for searching constraint satisfaction and other classes of hard problems. The most common example of such a technique is the forward checking (FC) <ref> [20] </ref> algorithm, which maintains node consistency among the future variables by removing values from their domains which are inconsistent with the current partial solution. <p> The most common example of such a technique is the forward checking (FC) [20] algorithm, which maintains node consistency among the future variables by removing values from their domains which are inconsistent with the current partial solution. It has been shown <ref> [20, 27, 29] </ref> that the additional overheads associated with making more intelligent forward search moves by forward checking are often greatly outweighed by a large reduction in the size of the search tree. 1 The benefits of achieving a greater level of "look-ahead" capability than FC by maintaining a higher level <p> These expectations are confirmed from the experiments reported by Har-alick & Elliot <ref> [20] </ref> and Nadel [27].
Reference: [21] <author> T. Hogg and C. P. Williams. </author> <title> The Hardest Constraint Problems: A Double Phase Transition. </title> <journal> Artificial Intelligence, </journal> <volume> 69 </volume> <pages> 359-377, </pages> <year> 1994. </year>
Reference-contexts: However, recent studies have highlighted a phenomenon that complicates the phase transition model. The existence of exceptionally hard problems ("ehps") has been reported by Hogg & Williams <ref> [21] </ref> in graph colouring, Gent & Walsh [12] in satisfiability problems, and by Smith [35] and Smith & Grant [40] in CSPs. <p> It is clearly important, therefore, to consider relative ehp behaviour when comparing algorithm performance. 1 To date, no exceptionally hard soluble problems have been reported in studies of incomplete local search methods, for instance those reported in [7], [13] and <ref> [21] </ref>. 3 1.2 A history of MAC Although MAC is a popular technique employed by the constraint programming community, and is used by many constraint solving tools such as ILOG Solver [32], its application by the constraint satisfaction community has until very recently been passed over in favour of the lesser <p> For some problem classes, we have therefore chosen to plot the median and higher percentiles, up to the maximum cost, for the sets of problems; this follows graphs shown by Hogg & Williams <ref> [21] </ref> and Gent & Walsh [12]. 7.1 General and extreme behaviour on a selection of the n = 30 problem classes, while Figure 5 shows the median and higher percentiles for three of these problem classes.
Reference: [22] <author> S. Kirkpatrick and B. Selman. </author> <title> Critical Behaviour in the Satisfiability of Random Boolean Expressions. </title> <journal> Science, </journal> <volume> 264 </volume> <pages> 1297-1301, </pages> <year> 1994. </year>
Reference-contexts: Smith [35, 37] has termed this region the mushy region; as problem size increases, the mushy region becomes narrower, and is instantaneous in the limit [45, 46, 47]. Phase transition behaviour has been reported in an increasing number of classes of problem, including satisfiability problems <ref> [6, 14, 22, 25] </ref>, Hamilto-nian paths [5], and the travelling salesman problem [16, 17].
Reference: [23] <author> G. Kondrak and P. van Beek. </author> <title> A Theoretical Evaluation of Selected Backtracking Algorithms. </title> <editor> In C. S. Mellish, editor, </editor> <booktitle> Proceedings IJCAI-95, </booktitle> <volume> volume 1, </volume> <pages> pages 541-547. </pages> <publisher> Morgan Kaufmann, </publisher> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Nodes visited: when a search attempts to consistently instantiate a variable by trying one or more values in its domain, until successful or forced to backtrack, each of these trial instantiations is counted as a search tree node visited. This definition of nodes visited corresponds to that given in <ref> [23] </ref>. This measure is both environment and implementation independent, and so allows direct comparison of any MAC implementation.
Reference: [24] <author> A. Mackworth. </author> <title> Consistency in networks of relations. </title> <journal> Artificial Intelligence, </journal> <volume> 8 </volume> <pages> 99-118, </pages> <year> 1977. </year>
Reference-contexts: The algorithm re-establishes arc consistency after every instantiation in the sub-problem formed by the future variables and their remaining domains, and following Sabin & Freuder [34] we have termed this algorithm MAC (Maintaining Arc Consistency). Our implementations are based on Mackworth's AC-3 arc consistency algorithm <ref> [24] </ref> whereas [34] reports an implementation based on Mohr & Henderson's AC-4 [26]. As with forward checking, MAC is a chronological backtracker, and so we also investigate the addition of conflict-directed backjumping (CBJ) [29] to MAC to produce the potentially more efficient MAC-CBJ [31]. <p> In situations such as this, the chronological backtracker will be prone to the most naive form of the pathological behaviour known as thrashing <ref> [24] </ref>. <p> We introduce the MAC and MAC-CBJ algorithms in the next section. 8 4 The MAC and MAC-CBJ algorithms The implementation of MAC and MAC-CBJ that we use is based on Mack-worth's AC-3 arc consistency algorithm <ref> [24] </ref>, and follows the descriptions given by Prosser [31]. Brief descriptions of the AC-3, MAC and MAC-CBJ algorithms are given later in this section: for a more comprehensive description and discussion refer to [31].
Reference: [25] <author> D. Mitchell, B. Selman, and H. Levesque. </author> <title> Hard and Easy Distributions of SAT Problems. </title> <booktitle> In Proceedings AAAI-92, </booktitle> <pages> pages 459-465, </pages> <year> 1992. </year>
Reference-contexts: Smith [35, 37] has termed this region the mushy region; as problem size increases, the mushy region becomes narrower, and is instantaneous in the limit [45, 46, 47]. Phase transition behaviour has been reported in an increasing number of classes of problem, including satisfiability problems <ref> [6, 14, 22, 25] </ref>, Hamilto-nian paths [5], and the travelling salesman problem [16, 17].
Reference: [26] <author> R. Mohr and T. Henderson. </author> <title> Arc and path consistency revisited. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 225-233, </pages> <year> 1986. </year>
Reference-contexts: Our implementations are based on Mackworth's AC-3 arc consistency algorithm [24] whereas [34] reports an implementation based on Mohr & Henderson's AC-4 <ref> [26] </ref>. As with forward checking, MAC is a chronological backtracker, and so we also investigate the addition of conflict-directed backjumping (CBJ) [29] to MAC to produce the potentially more efficient MAC-CBJ [31]. <p> These results established forward checking as the standard backtracking search strategy by the constraint satisfaction community. The use of MAC on CSPs covering a range of problem topologies was eventually reported by Sabin & Freuder [34], who presented an implementation based on the AC-4 <ref> [26] </ref> arc consistency algorithm. <p> The study by Sabin & Freuder of MAC [34] used an implementation based on Mohr & Henderson's AC-4 <ref> [26] </ref> 4 , which performs all consistency checking at the outset when the AC-4 support counters are initialised. During search, all the work of maintaining arc consistency is done by reference to these counters and not to the original constraints.
Reference: [27] <author> B. </author> <title> Nadel. Constraint satisfaction algorithms. </title> <journal> Comput. Intell., </journal> <volume> 5 </volume> <pages> 188-224, </pages> <year> 1989. </year>
Reference-contexts: The most common example of such a technique is the forward checking (FC) [20] algorithm, which maintains node consistency among the future variables by removing values from their domains which are inconsistent with the current partial solution. It has been shown <ref> [20, 27, 29] </ref> that the additional overheads associated with making more intelligent forward search moves by forward checking are often greatly outweighed by a large reduction in the size of the search tree. 1 The benefits of achieving a greater level of "look-ahead" capability than FC by maintaining a higher level <p> These expectations are confirmed from the experiments reported by Har-alick & Elliot [20] and Nadel <ref> [27] </ref>.
Reference: [28] <author> P. Prosser. </author> <title> An empirical study of phase transitions in binary constraint satisfaction problems. </title> <type> Technical Report AISL-49-93, </type> <institution> Department of Computer Science, University of Strathclyde, </institution> <year> 1993. </year> <note> To appear in the AI Journal special issue on Phase Transitions in Problem Spaces. </note>
Reference-contexts: Following previous experiments, variable domain size m was held at 10. The set of h30; 10; p 1 i problem classes studied is listed in Table 1 along with additional background information. The table includes the theoretical critical values of p 2 , ^p 2crit as presented in <ref> [28, 38] </ref>, at which average search effort is expected to be maximal. <p> These plots show a similar trend to that reported in <ref> [28, 38] </ref>, in that the predictions are accurate for all values of p 1 except the lowest values where problems are sparsely constrained. There, the theoretical ^p 2crit is an overestimation of the actual critical value.
Reference: [29] <author> P. Prosser. </author> <title> Hybrid Algorithms for the Constraint Satisfaction Problem. </title> <journal> Computational Intelligence, </journal> <volume> 9(3) </volume> <pages> 268-299, </pages> <year> 1993. </year> <month> 44 </month>
Reference-contexts: The most common example of such a technique is the forward checking (FC) [20] algorithm, which maintains node consistency among the future variables by removing values from their domains which are inconsistent with the current partial solution. It has been shown <ref> [20, 27, 29] </ref> that the additional overheads associated with making more intelligent forward search moves by forward checking are often greatly outweighed by a large reduction in the size of the search tree. 1 The benefits of achieving a greater level of "look-ahead" capability than FC by maintaining a higher level <p> Our implementations are based on Mackworth's AC-3 arc consistency algorithm [24] whereas [34] reports an implementation based on Mohr & Henderson's AC-4 [26]. As with forward checking, MAC is a chronological backtracker, and so we also investigate the addition of conflict-directed backjumping (CBJ) <ref> [29] </ref> to MAC to produce the potentially more efficient MAC-CBJ [31]. <p> In order to study the effects of using an increased look-ahead capability, we also compare the performance of MAC with that of FC, and of MAC-CBJ with the equivalent hybrid FC-CBJ <ref> [29] </ref>, over the same sets of problems. <p> The previous report looked at the second of these approaches, investigating the effects of adding informed backjumping capability to the FC-FF chronological backtracker (conflict-directed backjumping (CBJ) <ref> [29] </ref> was added to give FC-CBJ-FF). It was shown that although the addition of CBJ gives little improvement in general over a chronological backtracker which uses a powerful heuristic such as FF (particularly as problem density increases), it can make a huge difference to the difficulty of 7 the ehps. <p> effects of making the initial queue of (i; j) arcs consistent is done, then the algorithm reduces 5 Thus, MAC can be viewed as a natural extension of forward checking, or perhaps more correctly FC can be viewed as a degenerate form of MAC! 10 to FC-CBJ, described by Prosser <ref> [29] </ref>. <p> show exactly what the benefits of using the MAC look-ahead technique are, each set of problems was solved not only using MAC and MAC-CBJ, but also using the "underlying" basic algorithms that they can be viewed as extensions of: that is, FC and FC-CBJ 10 respectively, as described by Prosser <ref> [29] </ref> 11 . The experiments on each hn; m; p 1 i problem class take the form of generating and searching samples of problems over a range of p 2 (constraint tightness) values, varied in steps of 0:01.
Reference: [30] <author> P. Prosser. </author> <title> Binary constraint satisfaction problems: some are harder than others. </title> <editor> In A. Cohn, editor, </editor> <booktitle> Proceedings of ECAI-94, </booktitle> <pages> pages 95-99. </pages> <publisher> Wiley, </publisher> <year> 1994. </year>
Reference-contexts: In the case of binary CSPs, Prosser <ref> [30] </ref> has carried out an extensive series of experiments investigating the phase transition, and Smith [37] and Smith & Dyer [38] have discussed the extent to which it is possible to predict its location. The importance of the phase transition cannot be overstated. <p> However, it has been demonstrated <ref> [30, 34] </ref> that algorithms employing dynamic variable ordering can occasionally perform more poorly as a result of the pruning effects of constraint propagation. We conducted a brief study of the effects of preprocessing using AC-3 on each of the problem classes listed in Tables 1 and 2.
Reference: [31] <author> P. Prosser. MAC-CBJ: </author> <title> maintaining arc consistency with conflict-directed backjumping. </title> <type> Technical Report 95-177, </type> <institution> Department of Computer Science, University of Strathclyde, UK, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: As with forward checking, MAC is a chronological backtracker, and so we also investigate the addition of conflict-directed backjumping (CBJ) [29] to MAC to produce the potentially more efficient MAC-CBJ <ref> [31] </ref>. We study the behaviour of MAC and MAC-CBJ with respect to the phase transition behaviour of randomly-generated sets of binary constraint satisfaction problems (CSPs), enabling us to apply the algorithms to many problems covering a range of sizes, topologies and expected difficulties. <p> We introduce the MAC and MAC-CBJ algorithms in the next section. 8 4 The MAC and MAC-CBJ algorithms The implementation of MAC and MAC-CBJ that we use is based on Mack-worth's AC-3 arc consistency algorithm [24], and follows the descriptions given by Prosser <ref> [31] </ref>. Brief descriptions of the AC-3, MAC and MAC-CBJ algorithms are given later in this section: for a more comprehensive description and discussion refer to [31]. It should be emphasised that the decision to base our version of MAC on AC-3 is largely arbitrary. <p> The implementation of MAC and MAC-CBJ that we use is based on Mack-worth's AC-3 arc consistency algorithm [24], and follows the descriptions given by Prosser <ref> [31] </ref>. Brief descriptions of the AC-3, MAC and MAC-CBJ algorithms are given later in this section: for a more comprehensive description and discussion refer to [31]. It should be emphasised that the decision to base our version of MAC on AC-3 is largely arbitrary. Although there are arguably more efficient, if more complex, arc consistency techniques that could be used 3 , the effect of establishing arc consistency is invariant of the technique used. <p> If no more values remain to be tried for i then the search must backtrack and re-instantiate the previous variable. Prosser notes <ref> [31] </ref> that if the effects of making the initial queue of (i; j) arcs consistent are not propagated, then the algorithm becomes Haralick & Elliot's forward checking, where the search only considers the future variables that are directly affected by an instantiation 5 .
Reference: [32] <author> J.-F. Puget. </author> <title> A C++ Implementation of CLP. </title> <booktitle> In Proceedings of SPICIS94 (Singapore International Conference on Intelligent Systems), </booktitle> <year> 1994. </year>
Reference-contexts: problems have been reported in studies of incomplete local search methods, for instance those reported in [7], [13] and [21]. 3 1.2 A history of MAC Although MAC is a popular technique employed by the constraint programming community, and is used by many constraint solving tools such as ILOG Solver <ref> [32] </ref>, its application by the constraint satisfaction community has until very recently been passed over in favour of the lesser level of look-ahead provided by FC. <p> Checks are environment independent, but are highly dependent on implementation efficiency, and the definition of the circumstances under which they are taken 8 . Also note that for some implementations (e.g. ILOG Solver <ref> [32] </ref>) it may be neither possible or sensible to try and count consistency checks, because of the way the constraints are implemented.
Reference: [33] <author> F. Rossi. </author> <title> Redundant Hidden Variables in Finite Domain Constraint Problems. </title> <editor> In M. Meyer, editor, </editor> <booktitle> Proceedings of the ECAI94 Workshop on Constraint Processing, </booktitle> <pages> pages 17-25, </pages> <year> 1994. </year>
Reference-contexts: If such a constraint gap exists for CSPs, this AC data (concerning propagation of nogoods) together with data concerning the propagation of goods (such as CSP reduction operators <ref> [33] </ref>) may provide empirical evidence for it. 21 7 Macroscopic performance of MAC When analysing the performance of MAC at the population level, we are aiming firstly to gauge the general behaviour of the algorithm in isolation, particularly the extremes of population behaviour such as the occurrence of ehps, and secondly <p> Such a study would initially involve the investigation of CSP reduction operators, which have been presented by Rossi <ref> [33] </ref>, as a method of propagating definite goods in CSPs. This data could be compared with the nogood propagation of AC preprocessing to establish the location in the control parameter range of any such gaps.
Reference: [34] <author> D. Sabin and E. Freuder. </author> <title> Contradicting Conventional Wisdom in Constraint Satisfaction. </title> <editor> In A. Cohn, editor, </editor> <booktitle> Proceedings ECAI94, </booktitle> <pages> pages 125-129, </pages> <year> 1994. </year>
Reference-contexts: We study a version of the algorithm originally reported by Gaschnig as CS2 [9] and later as DEEB (Domain Element Elimination with Backtracking) [10]. The algorithm re-establishes arc consistency after every instantiation in the sub-problem formed by the future variables and their remaining domains, and following Sabin & Freuder <ref> [34] </ref> we have termed this algorithm MAC (Maintaining Arc Consistency). Our implementations are based on Mackworth's AC-3 arc consistency algorithm [24] whereas [34] reports an implementation based on Mohr & Henderson's AC-4 [26]. <p> The algorithm re-establishes arc consistency after every instantiation in the sub-problem formed by the future variables and their remaining domains, and following Sabin & Freuder <ref> [34] </ref> we have termed this algorithm MAC (Maintaining Arc Consistency). Our implementations are based on Mackworth's AC-3 arc consistency algorithm [24] whereas [34] reports an implementation based on Mohr & Henderson's AC-4 [26]. As with forward checking, MAC is a chronological backtracker, and so we also investigate the addition of conflict-directed backjumping (CBJ) [29] to MAC to produce the potentially more efficient MAC-CBJ [31]. <p> These results established forward checking as the standard backtracking search strategy by the constraint satisfaction community. The use of MAC on CSPs covering a range of problem topologies was eventually reported by Sabin & Freuder <ref> [34] </ref>, who presented an implementation based on the AC-4 [26] arc consistency algorithm. <p> The study by Sabin & Freuder of MAC <ref> [34] </ref> used an implementation based on Mohr & Henderson's AC-4 [26] 4 , which performs all consistency checking at the outset when the AC-4 support counters are initialised. During search, all the work of maintaining arc consistency is done by reference to these counters and not to the original constraints. <p> Sometimes, though, cpu time is the only measure that can be taken: the nature of the MAC implementation reported by Sabin & Freuder <ref> [34] </ref> (described in Section 4) meant that consistency checks could not be counted, and so they report cpu times. However, when presenting the results of our studies on MAC and MAC-CBJ in the following sections, we place an emphasis on nodes visited as a measure of search effort. <p> 10; p 1 i problem classes studied with constant average degree fl 4:92. are then presented, followed by a small-scale study of the effects of the new techniques on some of the individual ehps. 6 The effects of AC preprocessing Following the implementation of MAC reported by Sabin & Freuder <ref> [34] </ref>, we choose to preprocess problems with AC-3 before search by either MAC or MAC-CBJ 13 . <p> However, it has been demonstrated <ref> [30, 34] </ref> that algorithms employing dynamic variable ordering can occasionally perform more poorly as a result of the pruning effects of constraint propagation. We conducted a brief study of the effects of preprocessing using AC-3 on each of the problem classes listed in Tables 1 and 2.
Reference: [35] <author> B. M. Smith. </author> <title> In Search of Exceptionally Difficult Constraint Satisfaction Problems. </title> <editor> In M. Meyer, editor, </editor> <booktitle> Proceedings of the ECAI'94 Workshop on Constraint Processing, </booktitle> <pages> pages 79-86, </pages> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: In this intervening region, the probability of problem solubility falls from close to 1 to close to 0, and the median cost of searching these problems is highest, reaching a peak at the crossover point where 50% of problems are soluble. Smith <ref> [35, 37] </ref> has termed this region the mushy region; as problem size increases, the mushy region becomes narrower, and is instantaneous in the limit [45, 46, 47]. <p> However, recent studies have highlighted a phenomenon that complicates the phase transition model. The existence of exceptionally hard problems ("ehps") has been reported by Hogg & Williams [21] in graph colouring, Gent & Walsh [12] in satisfiability problems, and by Smith <ref> [35] </ref> and Smith & Grant [40] in CSPs. These studies show that although there is a well-defined peak in the median cost of finding a solution in the region of the phase transition, this is often not where the hardest individual instances occur.
Reference: [36] <author> B. M. Smith. </author> <title> In Search of Exceptionally Difficult Constraint Satisfaction Problems. </title> <institution> Research Report 94.2, School of Computer Studies, University of Leeds, </institution> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: As in our previous studies <ref> [36, 39] </ref>, we found no ehps in the easy-soluble regions that are insoluble problems: we continue to conjecture that in the case of CSPs such problems must be exceptionally rare 14 , even among ehps. checks, on a selection of the fl 4:92 problem classes, while Figure 7 shows the median
Reference: [37] <author> B. M. Smith. </author> <title> Phase Transition and the Mushy Region in Constraint Satisfaction Problems. </title> <editor> In A.G.Cohn, editor, </editor> <booktitle> Proceedings ECAI-94, </booktitle> <pages> pages 100-104. </pages> <publisher> Wiley, </publisher> <year> 1994. </year>
Reference-contexts: In this intervening region, the probability of problem solubility falls from close to 1 to close to 0, and the median cost of searching these problems is highest, reaching a peak at the crossover point where 50% of problems are soluble. Smith <ref> [35, 37] </ref> has termed this region the mushy region; as problem size increases, the mushy region becomes narrower, and is instantaneous in the limit [45, 46, 47]. <p> In the case of binary CSPs, Prosser [30] has carried out an extensive series of experiments investigating the phase transition, and Smith <ref> [37] </ref> and Smith & Dyer [38] have discussed the extent to which it is possible to predict its location. The importance of the phase transition cannot be overstated.
Reference: [38] <author> B. M. Smith and M. E. Dyer. </author> <title> Locating the Phase Transition in Constraint Satisfaction Problems. </title> <note> To appear in Artificial Intelligence, </note> <year> 1995. </year>
Reference-contexts: In the case of binary CSPs, Prosser [30] has carried out an extensive series of experiments investigating the phase transition, and Smith [37] and Smith & Dyer <ref> [38] </ref> have discussed the extent to which it is possible to predict its location. The importance of the phase transition cannot be overstated. <p> Where necessary, we round to the nearest integer value to give the actual number of constraints and conflicts generated. This random problem generation method corresponds to the "Model B" method used by Smith in <ref> [38] </ref>, where alternative models for random problem generation are discussed in greater detail. <p> Following previous experiments, variable domain size m was held at 10. The set of h30; 10; p 1 i problem classes studied is listed in Table 1 along with additional background information. The table includes the theoretical critical values of p 2 , ^p 2crit as presented in <ref> [28, 38] </ref>, at which average search effort is expected to be maximal. <p> These plots show a similar trend to that reported in <ref> [28, 38] </ref>, in that the predictions are accurate for all values of p 1 except the lowest values where problems are sparsely constrained. There, the theoretical ^p 2crit is an overestimation of the actual critical value.
Reference: [39] <author> B. M. Smith and S. A. Grant. </author> <title> Sparse Constraint Graphs and Exceptionally Hard Problems. </title> <institution> Research Report 94.36, School of Computer Studies, University of Leeds, </institution> <month> Dec. </month> <year> 1994. </year>
Reference-contexts: As in our previous studies <ref> [36, 39] </ref>, we found no ehps in the easy-soluble regions that are insoluble problems: we continue to conjecture that in the case of CSPs such problems must be exceptionally rare 14 , even among ehps. checks, on a selection of the fl 4:92 problem classes, while Figure 7 shows the median
Reference: [40] <author> B. M. Smith and S. A. Grant. </author> <title> Sparse Constraint Graphs and Exceptionally Hard Problems. </title> <editor> In C. S. Mellish, editor, </editor> <booktitle> Proceedings IJCAI-95, </booktitle> <volume> volume 1, </volume> <pages> pages 646-651. </pages> <publisher> Morgan Kaufmann, </publisher> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: However, recent studies have highlighted a phenomenon that complicates the phase transition model. The existence of exceptionally hard problems ("ehps") has been reported by Hogg & Williams [21] in graph colouring, Gent & Walsh [12] in satisfiability problems, and by Smith [35] and Smith & Grant <ref> [40] </ref> in CSPs. These studies show that although there is a well-defined peak in the median cost of finding a solution in the region of the phase transition, this is often not where the hardest individual instances occur. <p> To date no complete 1 search method has been shown to be completely immune from ehps, although studies of various algorithms <ref> [40, 41, 7, 1] </ref> have shown that their incidence and magnitude varies greatly between search methods. <p> However, it was the potential impact of extra look-ahead capability on the incidence of exceptionally hard problems that provided the original motivation for the study of MAC, and in this section we review the previous study of this phenomenon, reported in <ref> [40] </ref>. <p> It should be emphasised that this is intended to be a description of ehps, rather than a precise definition. As we reported in <ref> [40] </ref>, individual ehps are highly dependent on the algorithm being used: even a minor change in variable instantiation order may convert an ehp into a much easier problem. 2 Theoretical work on the connectivity of random graphs can be found in [3]. 6 So although individual ehps, and what makes them <p> Partial solutions involving most of the variables are found in the course of searching the sub-problem, resulting in a great deal of backtracking. As noted in <ref> [40] </ref>, there are, in theory, two potential ways of avoiding ehps which arise through encountering insoluble subproblems early in the search: one is to avoid getting into such subproblems in the first place, and the other is to find some search algorithm which can detect that the subproblem is insoluble more <p> In the study reported in <ref> [40] </ref> we found a good number of clear ehps for FC and FC-CBJ with the h50; 10; 0:1i problem class, which has fl = 4:92. <p> These results are similar to those reported in <ref> [40] </ref>, where the effects of adding CBJ to FC were studied. However, the difference in performance between MAC and MAC-CBJ on the non-exceptional problems is less than that between FC and FC-CBJ: in [40] we observed a noticeable improvement with FC-CBJ at the 99% level of behaviour, and at lower levels <p> These results are similar to those reported in <ref> [40] </ref>, where the effects of adding CBJ to FC were studied. However, the difference in performance between MAC and MAC-CBJ on the non-exceptional problems is less than that between FC and FC-CBJ: in [40] we observed a noticeable improvement with FC-CBJ at the 99% level of behaviour, and at lower levels in some cases, for sparsely constrained classes of problems; we see no noticeable differences in performance at the 99% level when CBJ is added to MAC for the many sparsely constrained problem classes <p> These results indicate that while MAC-CBJ, as conjectured in Section 3, shows the most stable performance in respect of the occurrence of exceptionally hard problems, a very few instances can clearly still arise in sparsely constrained problem classes. 10 A microscopic study of some ehps In <ref> [40] </ref> we studied the behaviour of two problems that forward checking found exceptionally hard, and first reported the insoluble subproblem behaviour mentioned in Section 3. We revisit these problems here, studying the be-haviour of MAC when applied to them, and also analyse a problem which MAC itself finds exceptionally hard. <p> Problem 358 at p 2 = 0:48 is an ehp for FC, and it was shown in <ref> [40] </ref> that the first four instantiations made by the algorithm are v 5 = 1 16 , v 16 = 4, v 22 = 9 and v 37 = 4. <p> Problem 898 at p 2 = 0:47 is an ehp for FC, and was also studied in <ref> [40] </ref>. It was shown that the first four instantiations also lead to an exceptionally difficult subproblem that FC takes over 190 million consistency checks and 56 million nodes visited to prove insoluble. Once again, a solution is found almost immediately once this is established.
Reference: [41] <author> B. M. Smith and S. A. Grant. </author> <title> Where the Exceptionally Hard Problems Are. </title> <booktitle> In Proceedings of the CP-95 Workshop on Studying and Solving Really Hard Problems, </booktitle> <pages> pages 172-182. </pages> <institution> Laboratoire d'Informatique de Marseille, France, </institution> <month> Sept. </month> <year> 1995. </year> <month> 45 </month>
Reference-contexts: To date no complete 1 search method has been shown to be completely immune from ehps, although studies of various algorithms <ref> [40, 41, 7, 1] </ref> have shown that their incidence and magnitude varies greatly between search methods. <p> However, subsequent studies <ref> [41] </ref> have shown that densely-constrained ehps may occur with the most naive algorithms having no form of look-ahead capability, for instance plain chronological backtracking [19]. <p> body of empirical data that now exists on these algorithms over the broad test bed of random CSP problem classes has many other potential uses: for example, the data has been used with that for some other algorithms on the same problem classes to establish an ehp "hierarchy", presented in <ref> [41] </ref>. Acknowledgments Stuart Grant is partly supported by a studentship from British Telecom plc. We are extremely grateful to Patrick Prosser and Ian Gent at the University of Strathclyde for their invaluable help and comments.
Reference: [42] <author> E. P. K. Tsang, J. Borrett, and A. C. M. Kwan. </author> <title> An attempt to map the performance of a range of algorithm and heuristic combinations. </title> <editor> In J. Hallam, editor, </editor> <booktitle> Proceedings AISB-95, </booktitle> <pages> pages 203-216. </pages> <publisher> IOS Press, </publisher> <address> Amsterdam, </address> <year> 1995. </year>
Reference-contexts: of limited testing on sets of homogenous problems, such as n-queens or the zebra problem [8], towards attempting to classify algorithms in terms of performance on large samples of problems of varying size, topology and position in relation to the phase transition (for instance the study by Tsang, et al. <ref> [42] </ref>). Knowledge of phase transitions should eventually allow problems to be analysed before any search is undertaken, and accurate predictions about solution probability, likely difficulty, and most suitable search method to be made. However, recent studies have highlighted a phenomenon that complicates the phase transition model. <p> Algorithms should clearly be chosen to suit the problem characteristics, based on the knowledge gained from empirical studies such as those presented here and those presented in <ref> [42] </ref>. An area for future study is a more detailed investigation of exactly how algorithm performance scales as problem size increases.
Reference: [43] <author> P. van Beek. </author> <title> On the Inherent Level of Local Consistency in Constraint Networks. </title> <booktitle> In Proceedings AAAI-94, </booktitle> <year> 1994. </year>
Reference-contexts: Theoretical work on predicting the existing level of consistency in constraint networks has been presented by van Beek <ref> [43] </ref>, and empirical studies of AC preprocessing by Borrett & Tsang [4] has shown that its usefulness is restricted to problems that are over-constrained.
Reference: [44] <author> R. J. Wallace. </author> <title> Why AC-3 is Almost Always Better than AC-4 for Establishing Arc Consistency in CSPs. </title> <booktitle> In Proceedings IJCAI93, </booktitle> <volume> volume 1, </volume> <pages> pages 239-245, </pages> <year> 1993. </year>
Reference-contexts: When making an entire problem arc consistent, the queue initially contains every directed arc in the constraint graph. 3 In fact, the improved efficiency of more complex AC algorithms has recently been thrown into doubt <ref> [44] </ref> 4 Prosser notes that it may be more appropriate to refer to our version of MAC as MAC3, and to Sabin & Freuder's version as MAC4, etc., but within the scope of this paper we will continue to refer simply to MAC and MAC-CBJ. 9 MAC: The basis of MAC
Reference: [45] <author> C. Williams and T. Hogg. </author> <title> Using Deep Structure to Locate Hard Problems. </title> <booktitle> In Proceedings AAAI-92, </booktitle> <pages> pages 472-477, </pages> <year> 1992. </year>
Reference-contexts: Smith [35, 37] has termed this region the mushy region; as problem size increases, the mushy region becomes narrower, and is instantaneous in the limit <ref> [45, 46, 47] </ref>. Phase transition behaviour has been reported in an increasing number of classes of problem, including satisfiability problems [6, 14, 22, 25], Hamilto-nian paths [5], and the travelling salesman problem [16, 17]. Williams and 2 Hogg [45, 46, 47] have developed approximations to the cost of finding the first <p> increases, the mushy region becomes narrower, and is instantaneous in the limit <ref> [45, 46, 47] </ref>. Phase transition behaviour has been reported in an increasing number of classes of problem, including satisfiability problems [6, 14, 22, 25], Hamilto-nian paths [5], and the travelling salesman problem [16, 17]. Williams and 2 Hogg [45, 46, 47] have developed approximations to the cost of finding the first solution and to the probability that a problem is soluble, both for specific classes of constraint satisfaction problem (graph colouring, k-SAT) and for the general case.
Reference: [46] <author> C. Williams and T. Hogg. </author> <title> Extending Deep Structure. </title> <booktitle> In Proceedings of AAAI-93, </booktitle> <pages> pages 152-158, </pages> <year> 1993. </year>
Reference-contexts: Smith [35, 37] has termed this region the mushy region; as problem size increases, the mushy region becomes narrower, and is instantaneous in the limit <ref> [45, 46, 47] </ref>. Phase transition behaviour has been reported in an increasing number of classes of problem, including satisfiability problems [6, 14, 22, 25], Hamilto-nian paths [5], and the travelling salesman problem [16, 17]. Williams and 2 Hogg [45, 46, 47] have developed approximations to the cost of finding the first <p> increases, the mushy region becomes narrower, and is instantaneous in the limit <ref> [45, 46, 47] </ref>. Phase transition behaviour has been reported in an increasing number of classes of problem, including satisfiability problems [6, 14, 22, 25], Hamilto-nian paths [5], and the travelling salesman problem [16, 17]. Williams and 2 Hogg [45, 46, 47] have developed approximations to the cost of finding the first solution and to the probability that a problem is soluble, both for specific classes of constraint satisfaction problem (graph colouring, k-SAT) and for the general case.
Reference: [47] <author> C. Williams and T. Hogg. </author> <title> Exploiting the Deep Structure of Constraint Problems. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 73-117, </pages> <year> 1994. </year> <month> 46 </month>
Reference-contexts: Smith [35, 37] has termed this region the mushy region; as problem size increases, the mushy region becomes narrower, and is instantaneous in the limit <ref> [45, 46, 47] </ref>. Phase transition behaviour has been reported in an increasing number of classes of problem, including satisfiability problems [6, 14, 22, 25], Hamilto-nian paths [5], and the travelling salesman problem [16, 17]. Williams and 2 Hogg [45, 46, 47] have developed approximations to the cost of finding the first <p> increases, the mushy region becomes narrower, and is instantaneous in the limit <ref> [45, 46, 47] </ref>. Phase transition behaviour has been reported in an increasing number of classes of problem, including satisfiability problems [6, 14, 22, 25], Hamilto-nian paths [5], and the travelling salesman problem [16, 17]. Williams and 2 Hogg [45, 46, 47] have developed approximations to the cost of finding the first solution and to the probability that a problem is soluble, both for specific classes of constraint satisfaction problem (graph colouring, k-SAT) and for the general case.
References-found: 47

