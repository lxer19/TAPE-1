URL: ftp://ftp.cs.helsinki.fi/pub/Reports/by_Project/PMDM/Efficient_Algorithms_for_Discovering_Association_Rules.ps.gz
Refering-URL: http://www.cs.helsinki.fi/~verkamo/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Efficient Algorithms for Discovering Association Rules  
Author: Heikki Mannila Hannu Toivonen A. Inkeri Verkamo 
Keyword: association rules, covering sets, algorithms, sampling.  
Address: P.O. Box 26 (Teollisuuskatu 23), FIN-00014 Helsinki, Finland  
Affiliation: University of Helsinki, Department of Computer Science  
Note: Appeared in AAAI Workshop on Knowledge Discovery in Databases, Eds. Usama M. Fayyad and Ramasamy Uthurusamy, pages 181 192, Seattle, Washington,  
Email: e-mail: fmannila, htoivone, verkamog@cs.helsinki.fi  
Date: July 1994.  
Abstract: Association rules are statements of the form "for 90 % of the rows of the relation, if the row has value 1 in the columns in set W , then it has 1 also in column B". Agrawal, Imielinski, and Swami introduced the problem of mining association rules from large collections of data, and gave a method based on successive passes over the database. We give an improved algorithm for the problem. The method is based on careful combinatorial analysis of the information obtained in previous passes; this makes it possible to eliminate unnecessary candidate rules. Experiments on a university course enrollment database indicate that the method outperforms the previous one by a factor of 5. We also show that sampling is in general a very efficient way of finding such rules. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In Proceedings of the 1993 International Conference on Management of Data (SIGMOD 93), </booktitle> <pages> pages 207 - 216, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The area can be loosely defined as finding interesting rules or exceptions from large collections of data. Recently, Agrawal, Imielinski, and Swami introduced a class of regularities, association rules, and gave an algorithm for finding such rules from a database with binary data <ref> [1] </ref>. An association rule is an expression W ) B, where W is a set of attributes and B a single attribute. <p> In this paper we study the properties of association rule discovery in relations. We give a new algorithm for the problem that outperforms the method in <ref> [1] </ref> by a factor of 5. The algorithm is based on the same basic idea of repeated passes over the database as the method in [1]. <p> We give a new algorithm for the problem that outperforms the method in <ref> [1] </ref> by a factor of 5. The algorithm is based on the same basic idea of repeated passes over the database as the method in [1]. The difference is that our algorithm makes careful use of the combinatorial information obtained from previous passes and in this way avoids considering many unnecessary sets in the process of finding the association rules. <p> The rest of this paper is organized as follows. Section 2 introduces the problem and the notations. Section 3 describes our algorithm for finding association rules. The analysis of sampling is given in Section 4. Empirical results and a comparison to the results of <ref> [1] </ref> are given in Section 5. Section 6 is a short conclusion. Appendix A contains the probabilistic analyses of random relations and the lower bound result. Appendix B gives an overview of the implementation. We refer to [1] for references about related work. 2 Problem First we introduce some basic concepts, <p> Empirical results and a comparison to the results of <ref> [1] </ref> are given in Section 5. Section 6 is a short conclusion. Appendix A contains the probabilistic analyses of random relations and the lower bound result. Appendix B gives an overview of the implementation. We refer to [1] for references about related work. 2 Problem First we introduce some basic concepts, using the formalism presented in [1]. Let R = fI 1 ; I 2 ; : : : ; I m g be a set of attributes, also called items, over the binary domain f0; 1g. <p> Appendix A contains the probabilistic analyses of random relations and the lower bound result. Appendix B gives an overview of the implementation. We refer to <ref> [1] </ref> for references about related work. 2 Problem First we introduce some basic concepts, using the formalism presented in [1]. Let R = fI 1 ; I 2 ; : : : ; I m g be a set of attributes, also called items, over the binary domain f0; 1g. <p> In the first case the rule W A ) B does not necessarily have sufficient support, and in the second case the rule W ) B does not necessarily hold with sufficient confidence. 3 Finding association rules 3.1 Basic algorithm The approach in <ref> [1] </ref> to finding association rules is to first find all covering attribute sets X, and then separately test whether the rule X n fBg ) B holds with sufficient confidence. 2 We follow this approach and concentrate on the algorithms that search for covering subsets. <p> The extreme method would be to do just one pass and check for each of the 2 m subsets of R whether they are covering or not. This is infeasible for all but the smallest values of m. 1 Agrawal et al. use the term large <ref> [1] </ref>. 2 It is easy to see that this approach is in a sense optimal: the problem of finding all covering subsets of R can be reduced to the problem of finding all association rules that hold with a given confidence. <p> Namely, if we are given a relation r, we can find the covering sets by adding an extra column B with all 1's to r and then finding the association rules that have B on the right-hand side and hold with certainty 1. 183 The method of <ref> [1] </ref> makes multiple passes over the database. During a database pass, new candidates for covering sets are generated, and support information is collected to evaluate which of the candidates actually are covering. The candidates are derived from the database tuples by extending previously found covering sets in the frontier. <p> The expected support required for this decision is derived from the frequency information of the items of the set. Originally the frontier contains only the empty set. An essential property of the method of <ref> [1] </ref> is that both candidate generation and evaluation are performed during the database pass. The method of [1] further uses two techniques to prune the candidate space during the database pass. These are briefly described in Appendix B. We take a slightly different approach. <p> Originally the frontier contains only the empty set. An essential property of the method of <ref> [1] </ref> is that both candidate generation and evaluation are performed during the database pass. The method of [1] further uses two techniques to prune the candidate space during the database pass. These are briefly described in Appendix B. We take a slightly different approach. <p> Appendix A contains an analysis of covering sets in random relations and a lower bound result for the problem of finding association rules. 5 Experiments To evaluate the efficiency of our methods, we compare the original algorithm in <ref> [1] </ref> to our algorithm. Candidate generation is performed by extending sets in L s with other sets in L s to achieve (at most) e-extensions. <p> more aggressive strategy with e = s, where the size of the candidate sets is doubled during each iteration step. (We refer to our algorithm as offline candidate determination; the variants are noted in the following as OCD 1 and OCD s .) In addition to the original algorithm of <ref> [1] </ref> (noted in the following by AIS orig ), we also implemented a minor modification of it that refrains from extending any set with an item that is not a covering set by itself (noted in the following by AIS mod ). <p> We have considered the problem of finding the association rules that hold in a given relation. Following the work of <ref> [1] </ref>, we have given an algorithm that uses all existing information between database passes to avoid checking the coverage of redundant sets. The algorithm gives clear empirical improvement when compared against the previous results, and it is simple to implement. See also [2] for similar results. <p> We have considered finding association rules from sequential data in [8]. Several problems remain open. Some of the pruning ideas in <ref> [1] </ref> are probably quite useful in certain situations; recognizing when to use such methods would help in practice. An algorithmic problem is how to find out as efficiently as possible what candidate sets occur in a given database row.
Reference: [2] <author> R. Agrawal and R. Srikant. </author> <title> Fast algorithms for mining association rules in large databases. </title> <booktitle> In VLDB '94, </booktitle> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: Our experimental data consists of two databases, namely university course enrollment data and the fault management database of a switching network. The empirical results show a good, solid performance for our method. A same type of improvement has independently been suggested in <ref> [2] </ref>. We also study the theoretical properties of the problem of finding the association rules that hold in a relation. <p> If Y 2 L s+e and e 0, then Y includes s sets from L s . This claim follows immediately from the fact that all subsets of a covering set are covering. The same observation has been made independently in <ref> [2] </ref>. Despite its triviality, this observation is powerful. <p> Following the work of [1], we have given an algorithm that uses all existing information between database passes to avoid checking the coverage of redundant sets. The algorithm gives clear empirical improvement when compared against the previous results, and it is simple to implement. See also <ref> [2] </ref> for similar results. The algorithm can be extended to handle nonbinary attributes by introducing new 189 indicator variables and using their special properties in the candidate generation process. We have also analyzed the theoretical properties of the problem of finding association rules.
Reference: [3] <author> N. Alon and J. H. Spencer. </author> <title> The Probabilistic Method. </title> <publisher> John Wiley Inc., </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Then the number of rows in the sample that contain X is a random variable x distributed according to B (h; t ), i.e., binomial distribution of h trials, each having success probability t . The Chernoff bounds <ref> [3, 6] </ref> state that for all a we have P r [x &gt; ht + a] &lt; e 2a 2 =h : 3 Results on the possible relative sizes of L s and C s+1 can be found in [4]. 185 That is, the probability that the estimated support is off
Reference: [4] <author> B. Bollobas. </author> <title> Combinatorics. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1986. </year>
Reference-contexts: The Chernoff bounds [3, 6] state that for all a we have P r [x &gt; ht + a] &lt; e 2a 2 =h : 3 Results on the possible relative sizes of L s and C s+1 can be found in <ref> [4] </ref>. 185 That is, the probability that the estimated support is off by at least ff is P r [x &gt; h (t + ff)] &lt; e 2ff 2 h 2 =h = e 2ff 2 h ; i.e., bounded by a quantity exponential in h.
Reference: [5] <author> M. Ellis and B. Stroustrup. </author> <title> The Annotated C++ Reference Manual. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference: [6] <author> T. Hagerup and C. Rub. </author> <title> A guided tour of Chernoff bounds. </title> <journal> Information Processing Letters, </journal> <volume> 33 </volume> <pages> 305-308, </pages> <year> 1989/90. </year>
Reference-contexts: Then the number of rows in the sample that contain X is a random variable x distributed according to B (h; t ), i.e., binomial distribution of h trials, each having success probability t . The Chernoff bounds <ref> [3, 6] </ref> state that for all a we have P r [x &gt; ht + a] &lt; e 2a 2 =h : 3 Results on the possible relative sizes of L s and C s+1 can be found in [4]. 185 That is, the probability that the estimated support is off
Reference: [7] <author> D. W. Loveland. </author> <title> Finding critical sets. </title> <journal> Journal of Algorithms, </journal> <volume> 8:362 - 371, </volume> <year> 1987. </year>
Reference-contexts: We also give a simple information-theoretic lower bound for finding one rule, and show that an algorithm suggested by Loveland in <ref> [7] </ref> in a different framework actually meets this lower bound. The rest of this paper is organized as follows. Section 2 introduces the problem and the notations. Section 3 describes our algorithm for finding association rules. The analysis of sampling is given in Section 4. <p> In Appendix A we give some additional theoretical results. We also give a simple lower bound for a special case of the problem, and note that an algorithm from the different framework of <ref> [7] </ref> actually matches this bound. We have considered finding association rules from sequential data in [8]. Several problems remain open. Some of the pruning ideas in [1] are probably quite useful in certain situations; recognizing when to use such methods would help in practice.
Reference: [8] <author> H. Mannila, H. Toivonen, and A. I. Verkamo. </author> <title> Association rules in sequential data. </title> <type> Manuscript, </type> <month> July </month> <year> 1994. </year> <month> 190 </month>
Reference-contexts: In Appendix A we give some additional theoretical results. We also give a simple lower bound for a special case of the problem, and note that an algorithm from the different framework of [7] actually matches this bound. We have considered finding association rules from sequential data in <ref> [8] </ref>. Several problems remain open. Some of the pruning ideas in [1] are probably quite useful in certain situations; recognizing when to use such methods would help in practice. An algorithmic problem is how to find out as efficiently as possible what candidate sets occur in a given database row.
Reference: [9] <author> K. Mehlhorn. </author> <title> Data Structures and Algorithms, Volumes 1-3. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1984. </year>
Reference: [10] <author> S. Naher. </author> <title> LEDA user manual, version 3.0. </title> <type> Technical report, </type> <institution> Max-Planck-Institut fur Informatik, Im Stadtwald, D-6600 Saarbrucken, </institution> <year> 1992. </year>
Reference: [11] <editor> G. Piatetsky-Shapiro and W. J. Frawley, editors. </editor> <title> Knowledge Discovery in Databases. </title> <publisher> AAAI Press / The MIT Press, </publisher> <address> Menlo Park, CA, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Data mining (database mining, knowledge discovery in databases) has recently been recognized as a promising new field in the intersection of databases, artificial intelligence, and machine learning (see, e.g., <ref> [11] </ref>). The area can be loosely defined as finding interesting rules or exceptions from large collections of data. Recently, Agrawal, Imielinski, and Swami introduced a class of regularities, association rules, and gave an algorithm for finding such rules from a database with binary data [1].
References-found: 11

