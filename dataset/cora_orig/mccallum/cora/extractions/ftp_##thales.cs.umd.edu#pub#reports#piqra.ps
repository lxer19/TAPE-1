URL: ftp://thales.cs.umd.edu/pub/reports/piqra.ps
Refering-URL: ftp://thales.cs.umd.edu/pub/biographical/xsoft.html
Root-URL: 
Title: A Parallel Implementation of the QR Algorithm  
Author: G. W. Stewart 
Abstract: In this paper a parallel implementation of the QR algorithm for the eigenvalues of a non-Hermitian matrix is proposed. The algorithm is designed to run efficiently on a linear array of processors that communicate by accessing their neighbors' memory. A module for building such arrays, the Maryland crab, is also described.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. H. Golub and C. Van Loan, </author> <title> Matrix Computations, </title> <publisher> Johns Hopkins, </publisher> <address> Baltimore, </address> <year> 1983. </year>
Reference-contexts: As was indicated in the introduction, the reader is assumed to be familiar with the details of the reduction (for example, see <ref> [1, pp. 222-223] </ref>). What follows is a sketch of the first step. <p> For simplicity we confine ourselves to the Parallel QR Algorithm 14 xxxxxxx xxxxxxx xxxxxx xxxxx xxxx xxx x explicitly shifted QR algorithm. It is assumed that the reader is familiar with the details of the sequential QR algorithm (see <ref> [1, pp. 220-221] </ref>). The sth step of the QR iteration goes as follows. <p> Consequently, processor k must await a signal from processor k + 1 that a [i][lcol [k+1]] is free before applying the rotation. Parallel QR Algorithm 16 for (iter=1; !converged; iter++)- if (iter &gt;= k)- if (k != 1) wait for R [lcol [k]] from P [k-1]; else generate R <ref> [1] </ref>; for (i=lcol [k]; i&lt;=rcol [k]; i++)- send R [i] to P [k+1]; applyrow R [i]; if (i != rcol [k]) generate R [i+1]; - botblk = min (iter, proc-1); for (blk = botblk; blk&gt;=1; blk--) for (i=lcol [blk]; i&lt;=rcol [blk]; i++)- wait for R [i] from P [k-1]; send R
Reference: [2] <author> D. P. O'Leary, Roger Pierson, G. W. Stewart, and Mark Weiser, </author> <title> "The Maryland Crab|A Module for Building Parallel Computers," </title> <institution> University of Maryland Computer Science Technical Report 1660, </institution> <year> 1986. </year>
Reference-contexts: In the next section we shall describe the parallel version of the reduction. In x3 we shall describe a processor module, called a crab, that is currently being designed at the University of Maryland <ref> [2] </ref>, and show how it can be used to reduce the communications overhead. Finally, in x4 we will discuss the parallelization of the QR iteration. 2 Reduction to Hessenberg Form In this section we shall discuss the parallel reduction of a nonsymmetric matrix to Hessenberg form by Householder transformations. <p> Thus the 4 This is an overestimate for small p. The last two terms are from the wave-front accumulation of x 5 The following discussion is adapted from <ref> [2] </ref> Parallel QR Algorithm 7 Sending Program 1. Request a message from the receiving program giving a pointer to the destination lo cation for the data. 2. Transmit the block of data to the locations starting at the pointer location. 3.
Reference: [3] <author> Robert van de Geign, </author> <type> Unpublished manuscript, </type> <year> 1986. </year>
Reference-contexts: In Figure 6, just before R <ref> [3] </ref> is applied to the columns, the part of the matrix around the (4; 3)-element has the form a 32 a 33 a 34 0 0 a 54 After the rotation has been applied, it has the form a 32 a 33 a 34 0 a 54 fla 54 where fl <p> matrix around the (4; 3)-element has the form a 32 a 33 a 34 0 0 a 54 After the rotation has been applied, it has the form a 32 a 33 a 34 0 a 54 fla 54 where fl and are the cosine and sine that determine R <ref> [3] </ref>. Ordinarily, the rotation R [4] would be determined from the elements a 44 and a 54 . However, if fl is zero, these elements cannot be recovered by processor k + 1. <p> Since all but the last processor are idle at some time, this should entail no additional cost. However, note that the shift s is determined from the matrix A sp+1 . An analysis in <ref> [3] </ref> for the case of a once deferred shift (p = 2), indicates that the convergence of the iteration will be slowed but remain superlinear.
References-found: 3

