URL: ftp://cse.ogi.edu/pub/chcc/oviatt/spcompaper/spcompaper.ps
Refering-URL: http://www.cse.ogi.edu/CHCC/Publications/text.html
Root-URL: http://www.cse.ogi.edu
Title: Toward Interface Design for Human Language Technology: Modality and Structure as Determinants of Linguistic Complexity  
Author: Sharon L. Oviatt, Philip R. Cohen, Michelle Wang 
Note: Michelle Wang is in the  
Date: September 20, 1995  
Affiliation: Dept. of Computer Science and Engineering Oregon Graduate Institute of Science and Technology  Department of Computer Science, Stanford University.  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> L. R. Bahl, Baker J. K., F. Jelinek, and R. L. Mercer. </author> <title> Perplexity | a measure of the difficulty of speech recognition tasks. </title> <booktitle> In Proceedings of the 94th Meeting of the Acoustical Society of America, volume 62s63, </booktitle> <address> Miami Beach, Florida, </address> <year> 1977. </year> <journal> supl. </journal> <volume> no. </volume> <pages> 1. </pages>
Reference-contexts: Both averages were analyzed in order to check for convergence of results. 2.3.5 Perplexity A bigram perplexity was calculated for each subject's spoken and written input in both the structured and unstructured conditions, based on Jelinek and colleagues' formula <ref> [1, 14] </ref>. When estimating the perplexity for each subject and condition, all of the remaining subjects' data for a given condition were used for training the word and character bigram probabilities. That is, a jackknife technique was applied as the preferred approach for calculating perplexity in small data sets.
Reference: [2] <author> E. Black, S. Abney, D. Flickinger, C. Gdaniec, R. Grishman, P. Harrison, D. Hindle, R. Ingria, F. Jelinek, J. Klavans, M. Liberman, M. Marcus, S. Roukos, B. Santorini, and T. Strzalkowski. </author> <title> A procedure for quantitatively comparing the syntactic coverage of English grammars. </title> <booktitle> In Proceedings of the DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 306-311. </pages> <publisher> Morgan Kaufmann, Inc., </publisher> <month> February </month> <year> 1991. </year> <title> Interfaces for Language Technology 23 </title>
Reference-contexts: Second, a summary also was computed of the average number of canonical parses produced by Dialogic, through a mapping of each Dialogic parse to an emerging national standard parse tree Interfaces for Language Technology 10 representation called Parseval form <ref> [2] </ref>. Since Parseval form is designed to reflect agreement among computational linguists simply on the major constituent bracketings, its syntactic structures should tend to represent the commonalities among many different systems.
Reference: [3] <author> A. Caramazza and A. E. Hillis. </author> <title> Lexical organization of nouns and verbs in the brain. </title> <journal> Nature, </journal> <volume> 349 </volume> <pages> 788-790, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: First author's current address: Department of Computer Science and Engineering, Oregon Graduate Institute of Science and Technology, P.O. Box 91000, Portland, Oregon, U.S.A. 97291 Interfaces for Language Technology 3 skills organized in modality-specific brain centers <ref> [3] </ref>. It therefore is unrealistic to expect that people will be able to adapt all aspects of their language input to suit system limitations. Instead, interfaces will be needed that can accommodate and also skillfully guide language input to optimize robust performance.
Reference: [4] <author> W. L. Chafe. </author> <title> Integration and involvement in speaking, writing, and oral literature. </title> <editor> In D. Tannen, editor, </editor> <title> Spoken and Written Language: Exploring Orality and Literacy, </title> <booktitle> chapter 3, </booktitle> <pages> pages 35-53. </pages> <publisher> Ablex Publishing Corp., </publisher> <address> Norwood, New Jersey, </address> <year> 1982. </year>
Reference-contexts: This finding qualifies previous reports of greater integration in the written modality, which were based Interfaces for Language Technology 20 on comparison of noninteractive writing versus interactive speech <ref> [4] </ref>. In terms of lexical composition, both modality and presentation structure contributed to very different vocabulary profiles. In contrast with speech, interactive writing contained fewer negatives and quantifiers. <p> In fact, the statistical underrepresentation of written verbs was offset by an overrepresentation of signs in this mode, in contrast with speech. The present finding that pronouns were selectively filtered from interactive handwriting replicates previous research <ref> [4, 31] </ref>. Perhaps the most striking alteration of lexical content during interactive writing involved the elevation of abbreviations, which accounted for over 15% of all content in this mode. The idiosyncratic class of nonstandard abbreviations, illustrated in Figure 2 (bottom), only was observed during interactive writing.
Reference: [5] <author> A. Chapanis, R. N. Parrish, R. B. Ochsman, and G. D. Weeks. </author> <title> Studies in interactive communication: II. The effects of four communication modes on the linguistic performance of teams during cooperative problem solving. </title> <booktitle> Human Factors, </booktitle> <volume> 19(2) </volume> <pages> 101-125, </pages> <year> 1977. </year>
Reference-contexts: Instead, interfaces will be needed that can accommodate and also skillfully guide language input to optimize robust performance. Although linguistic variability is a problematic issue for all communication modalities, speech is known to be particularly verbose and variable <ref> [5, 10, 24] </ref>. The constrainability of spoken input has been studied extensively by the telecommunications industry as it strives to automate operator services. <p> Textual input modes such as handwriting and keyboard tend to be briefer and more constrained than spoken input <ref> [5, 23] </ref>.
Reference: [6] <author> K. Church and R. Patil. </author> <title> Coping with syntactic ambiguity or how to put the block in the box on the table. </title> <journal> American Journal of Computational Linguistics, </journal> <volume> 8(3-4):139-149, </volume> <year> 1982. </year>
Reference-contexts: One potential advantage of using a structured format, compared to an unconstrained one, is the opportunity for reducing and prespecifying the meaning of phrasal attachments [8, 9]. For example, the number of prepositional phrase attachments has been described as forming a Catalan series <ref> [6] </ref>, defined as: Cat n = @ n A @ n 1 A According to this analysis, the sentence "Put the block in the box on the table in the corner by the door" has four prepositional phrases and would have 14 parses, not counting ambiguities arising within each phrase.
Reference: [7] <author> K. W. Church and W. A. Gale. </author> <title> A comparison of the enhanced Good-Turing and deleted estimation methods for estimating probabilities of English bigrams. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 5(1) </volume> <pages> 19-54, </pages> <year> 1991. </year>
Reference-contexts: For bigrams in the test corpus not seen during training, the probabilities were backed off to lower-order probability estimates (i.e., unigram and character probabilities) using a simplified form of Turing's method ([12], or see <ref> [7] </ref> for discussion). Since speech recognition in the structured format would be aided by having a different language model for each prompted input slot, per-slot bigram perplexities were computed for that condition by appending a unique token to the beginning of the utterance for a given prompt.
Reference: [8] <author> P. R. Cohen. </author> <title> The role of natural language in a multimodal interface. </title> <booktitle> In The 2nd FRIEND21 International Symposium on Next Generation Human Interface Technologies, </booktitle> <address> Tokyo, Japan, </address> <month> November </month> <year> 1991. </year> <title> Institute for Personalized Information Environment. </title> <booktitle> Also appears in Proceedings of UIST'92, </booktitle> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1992, </year> <pages> 143-149. </pages>
Reference-contexts: With respect to managing variability in language-oriented interfaces, presentation format is another underexplored dimension. One potential advantage of using a structured format, compared to an unconstrained one, is the opportunity for reducing and prespecifying the meaning of phrasal attachments <ref> [8, 9] </ref>.
Reference: [9] <author> P. R. Cohen, M. Dalrymple, D. B. Moran, F. C. N. Pereira, J. W. Sullivan, R. A. Gargan, J. L. Schlossberg, and S. W. Tyler. </author> <title> Synergistic use of direct manipulation and natural language. </title> <booktitle> In Human Factors in Computing Systems: CHI'89 Conference Proceedings, </booktitle> <pages> pages 227-234, </pages> <address> New York, New York, April 1989. </address> <publisher> ACM, Addison Wesley Publishing Co. </publisher>
Reference-contexts: With respect to managing variability in language-oriented interfaces, presentation format is another underexplored dimension. One potential advantage of using a structured format, compared to an unconstrained one, is the opportunity for reducing and prespecifying the meaning of phrasal attachments <ref> [8, 9] </ref>.
Reference: [10] <author> R. Cole, L. Hirschman, L. Atlas, M. Beckman, A. Bierman, M. Bush, J. Cohen, O. Garcia, B. Hanson, H. Hermansky, S. Levinson, K. McKeown, N. Morgan, D. Novick, M. Ostendorf, S. Oviatt, P. Price, H. Silverman, J. Spitz, A. Waibel, C. Weinstein, S. Zahorain, and V. Zue. </author> <title> The challenge of spoken language systems: Research directions for the nineties. </title> <journal> In IEEE Transactions on Speech and Audio Processing. </journal> <note> in press. </note>
Reference-contexts: Instead, interfaces will be needed that can accommodate and also skillfully guide language input to optimize robust performance. Although linguistic variability is a problematic issue for all communication modalities, speech is known to be particularly verbose and variable <ref> [5, 10, 24] </ref>. The constrainability of spoken input has been studied extensively by the telecommunications industry as it strives to automate operator services. <p> This significant filtering of conjunctions may have contributed further to lowering syntactic ambiguity in the structured format. Interfaces for Language Technology 21 Disfluencies are widely recognized to be a difficult source of variability for spoken language processing <ref> [10, 21, 28] </ref>. Somewhat unexpectedly, the rate of disfluencies observed in this research was as high during interactive writing as during speech, even though speech transmission was much faster.
Reference: [11] <author> H. Giles, A. Mulac, J. J. Bradac, and P. Johnson. </author> <title> Speech accommodation theory: The first decade and beyond. </title> <editor> In M. L. McLaughlin, editor, </editor> <booktitle> Communication Yearbook 10, </booktitle> <pages> pages 13-48. </pages> <publisher> Sage Publishers, </publisher> <address> Beverly Hills, California, </address> <year> 1987. </year>
Reference-contexts: One attractive feature of this approach is that it does not require imposing unnatural constraints on user behavior. Since most previous research on convergence has addressed only human-human speech (see <ref> [11] </ref> for review), more work is needed to evaluate the impact of convergence during human-computer interaction, and to clarify how best to apply interface techniques based on this principle to guide language input successfully. With respect to managing variability in language-oriented interfaces, presentation format is another underexplored dimension.
Reference: [12] <author> I. J. </author> <title> Good. The population frequencies of species and the estimation of population parameters. </title> <journal> Biometrika, </journal> <volume> 40 </volume> <pages> 237-264, </pages> <year> 1953. </year>
Reference: [13] <author> J. R. Hobbs, D. E. Appelt, J. Bear, M. Tyson, and D. Magerman. </author> <title> Robust processing of real-world natural-language texts. </title> <editor> In P. S. Jacobs, editor, </editor> <booktitle> Text-Based Intelligent Systems: Current Research and Interfaces for Language Technology 24 Practice in Information Extraction and Retrieval. </booktitle> <publisher> Lawrence Erlbaum Associates, Publishers, </publisher> <address> Hillsdale, New Jersey, </address> <year> 1992. </year>
Reference-contexts: In general, utterances were classified as belonging to the simplest appropriate category. The distribution of utterance types was summarized for each subject and condition. 2.3.4 Syntactic Ambiguity All phrasal and sentential utterances produced in each condition were parsed using two different methods. First, utterances were parsed using Dialogic <ref> [13] </ref>, a robust text processing system developed at SRI that employs a broad coverage grammar. As a pragmatic index of syntactic ambiguity, a summary was computed of the average number of parses generated per utterance.
Reference: [14] <author> F. Jelinek. </author> <title> Continuous speech recognition by statistical methods. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 64 </volume> <pages> 532-536, </pages> <month> April </month> <year> 1976. </year>
Reference-contexts: Both averages were analyzed in order to check for convergence of results. 2.3.5 Perplexity A bigram perplexity was calculated for each subject's spoken and written input in both the structured and unstructured conditions, based on Jelinek and colleagues' formula <ref> [1, 14] </ref>. When estimating the perplexity for each subject and condition, all of the remaining subjects' data for a given condition were used for training the word and character bigram probabilities. That is, a jackknife technique was applied as the preferred approach for calculating perplexity in small data sets.
Reference: [15] <author> D. Karis and K. M. Dobroth. </author> <title> Automating services with speech recognition over the public switched telephone network: Human factors considerations. </title> <journal> IEEE Journal of Selected Areas in Communications, </journal> <volume> 9(4) </volume> <pages> 574-585, </pages> <year> 1991. </year>
Reference-contexts: It also has indicated that certain spoken language phenomena are more amenable to channeling than others, and that dramatic variation can occur in the successful elicitation of target language depending on the type of system prompt <ref> [15, 29] </ref>. On the other hand, telecommunications field data typically have lacked the control needed for unambiguous interpretation.
Reference: [16] <author> G. Kurtenbach and W. Buxton. </author> <title> User learning and performance with marking menus. </title> <booktitle> In Proceedings of Conference on Human Factors in Computing Systems (CHI'94), </booktitle> <pages> pages 258-264, </pages> <address> New York, 1994. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Furthermore, research only recently has begun to focus on pen interface design <ref> [16, 34] </ref>, in spite of the fact that such work could be pivotal in boosting recognition rates to levels adequate for user acceptance of pen technology [17].
Reference: [17] <author> M. J. Lalomia. </author> <title> User acceptance of handwritten recognition accuracy. </title> <booktitle> In Proceedings of Conference on Human Factors in Computing Systems (CHI'94), </booktitle> <pages> page 107, </pages> <address> New York, 1994. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Furthermore, research only recently has begun to focus on pen interface design [16, 34], in spite of the fact that such work could be pivotal in boosting recognition rates to levels adequate for user acceptance of pen technology <ref> [17] </ref>. In particular, other than explicit training in handwriting, less obtrusive methods for guiding written input to match system capabilities have yet to be explored. <p> In this research, nonstandard abbreviations were managed very effectively by altering presentation format, with their rate dropping in the structured format to just 24% of that observed in the unconstrained one. Given the unacceptable recognition rates of current handwriting recognizers from a usability standpoint <ref> [17] </ref>, a clear advantage exists to designing structured pen interfaces for near-term systems. This study confirmed that the structured format selectively filtered out prepositions, with prepositions and parse ambiguity both reduced during structured interactions.
Reference: [18] <author> M. J. Lalomia and K. C. Cohen. </author> <title> Gesture consistency for text, spreadsheet, graphic, and form fill editing. </title> <booktitle> In Human Factors in Computing Systems: CHI'91 Conference Proceedings, </booktitle> <address> New York, New York, April 1991. </address> <publisher> ACM, Addison Wesley Publishing Company. </publisher>
Reference-contexts: However, the unique linguistic characteristics of interactive writing and marking have not been documented in any comprehensive way. 2 Compared to speech, the more difficult sources of variability in interactive writing still are poorly understood, although previous work to some extent has examined variability versus consistency in gestural marking <ref> [18, 35] </ref> and written letters [32, 33]. Furthermore, research only recently has begun to focus on pen interface design [16, 34], in spite of the fact that such work could be pivotal in boosting recognition rates to levels adequate for user acceptance of pen technology [17].
Reference: [19] <author> R. M. Leiser. </author> <title> Exploiting convergence to improve natural language understanding. </title> <journal> Interacting with Computers, </journal> <volume> 1(3) </volume> <pages> 284-298, </pages> <year> 1989. </year>
Reference-contexts: Interfaces for Language Technology 4 tic features like wordiness, lexical choice, and grammatical structure can be constrained through modeling and shaping techniques, with some system prompts more effective than others <ref> [19, 36] </ref>. One attractive feature of this approach is that it does not require imposing unnatural constraints on user behavior.
Reference: [20] <author> J. Makhoul, T. Starner, R. Schwartz, and G. Chou. </author> <title> On-line cursive handwriting recognition using hidden markov models and statistical grammars. </title> <booktitle> In Proceedings of the ARPA Human Language Technology Workshop, </booktitle> <address> Princeton, New Jersey, March 1994. </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: Collection of data from different input modalities (e.g., keyboard email as a basis for handwriting recognition [30]) or artificial tasks not involving human-computer interaction (e.g., copying Wall Street journal text as a basis for handwriting recognition <ref> [20] </ref>) risks misleading system development. That is, such data may fail to detect prevalent and difficult sources of linguistic variability that emerge clearly during higher-fidelity test Interfaces for Language Technology 22 ing.
Reference: [21] <author> C. Nakatani and J. Hirschberg. </author> <title> A speech-first model for repair detection and correction. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 46-53, </pages> <address> Columbus, Ohio, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: This significant filtering of conjunctions may have contributed further to lowering syntactic ambiguity in the structured format. Interfaces for Language Technology 21 Disfluencies are widely recognized to be a difficult source of variability for spoken language processing <ref> [10, 21, 28] </ref>. Somewhat unexpectedly, the rate of disfluencies observed in this research was as high during interactive writing as during speech, even though speech transmission was much faster.
Reference: [22] <author> S. L. Oviatt. </author> <title> Predicting and managing spoken disfluencies during human-computer interaction. </title> <booktitle> In Proceedings of the ARPA Human Language Technology Workshop, </booktitle> <address> Princeton, New Jersey, 1994, </address> <publisher> in press. Morgan Kaufmann, Publishers, </publisher> <address> Inc. </address> <note> (Also journal manuscript in submission). </note>
Reference-contexts: This general approach has been illustrated elsewhere <ref> [22] </ref>. From a scientific perspective, such research can contribute a foundation of information about expected performance tradeoffs, which then can assist in proactively guiding the design of robust human language technology. <p> A detailed report focusing on human-computer spoken disfluencies has been outlined elsewhere <ref> [22] </ref>. 3.8 Self-Reported Preferences During a post-experimental interview, people reported their preference to interact with the different presentation formats. The majority, or 67% of participants, said they preferred the more structured format. <p> Other research has demonstrated that reduction in spoken disfluencies during human-computer interaction is related to lower cognitive load, which can be influenced by interface design <ref> [22] </ref>. Furthermore, interface techniques capable of guiding speakers' utterances to be brief (i.e., 1-6 words) can eliminate over 80% of the spoken disfluencies that otherwise would have occurred in lengthy utterances (i.e., 13-18 words) [22]. <p> during human-computer interaction is related to lower cognitive load, which can be influenced by interface design <ref> [22] </ref>. Furthermore, interface techniques capable of guiding speakers' utterances to be brief (i.e., 1-6 words) can eliminate over 80% of the spoken disfluencies that otherwise would have occurred in lengthy utterances (i.e., 13-18 words) [22]. Post-experimental interviews indicated that people preferred structured interactions over unconstrained ones by a factor of 2 to 1 for these routine service-oriented tasks. In particular, the guidance and sense of completeness provided by the structured format were considered desirable.
Reference: [23] <author> S. L. Oviatt and P. R. Cohen. </author> <title> The contributing influence of speech and interaction on human discourse patterns. </title> <editor> In J. W. Sullivan and S. W. Tyler, editors, </editor> <booktitle> Intelligent User Interfaces, chapter 3, </booktitle> <pages> pages 69-83. </pages> <publisher> ACM Press Frontier Series, Addison-Wesley Publishing Co., </publisher> <address> New York, New York, </address> <year> 1991. </year>
Reference-contexts: Textual input modes such as handwriting and keyboard tend to be briefer and more constrained than spoken input <ref> [5, 23] </ref>.
Reference: [24] <author> S. L. Oviatt and P. R. Cohen. </author> <title> Discourse structure and performance efficiency in interactive and noninteractive spoken modalities. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 5(4) </volume> <pages> 297-326, </pages> <year> 1991. </year> <title> Interfaces for Language Technology 25 </title>
Reference-contexts: Instead, interfaces will be needed that can accommodate and also skillfully guide language input to optimize robust performance. Although linguistic variability is a problematic issue for all communication modalities, speech is known to be particularly verbose and variable <ref> [5, 10, 24] </ref>. The constrainability of spoken input has been studied extensively by the telecommunications industry as it strives to automate operator services.
Reference: [25] <author> S. L. Oviatt, P. R. Cohen, M. W. Fong, and M. P. Frank. </author> <title> A rapid semi-automatic simulation technique for investigating interactive speech and handwriting. </title> <editor> In J. Ohala, editor, </editor> <booktitle> Proceedings of the 1992 International Conference on Spoken Language Processing, </booktitle> <volume> vol. 2, </volume> <pages> pages 1351-1354, </pages> <institution> University of Alberta, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: Descriptions of this method have been detailed elsewhere <ref> [25] </ref>, but are summarized below. 2.1 Subjects, Tasks, and Procedure Eighteen subjects participated in the study as paid volunteers. Participants represented a broad spectrum of white-collar professionals, excluding computer scientists, and all were native speakers of English. <p> An emphasis was placed on automating the simulation in order to support accurate and rapid responding by the assistant. Technical details of the simulation technique's capabilities and performance characteristics have been outlined elsewhere <ref> [25, 26] </ref>. After the session, a post-experimental interview was conducted in which subjects were asked about their modality and format preferences, as well as evaluative questions about other aspects of the system and its features.
Reference: [26] <author> S. L. Oviatt, P. R. Cohen, M. Wang, and J. Gaston. </author> <title> A simulation-based research strategy for designing complex NL systems. </title> <booktitle> In ARPA Human Language Technology Workshop, </booktitle> <address> San Mateo, California, March 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: An emphasis was placed on automating the simulation in order to support accurate and rapid responding by the assistant. Technical details of the simulation technique's capabilities and performance characteristics have been outlined elsewhere <ref> [25, 26] </ref>. After the session, a post-experimental interview was conducted in which subjects were asked about their modality and format preferences, as well as evaluative questions about other aspects of the system and its features.
Reference: [27] <author> J. R. Rhyne and C. G. Wolf. </author> <title> Recognition-based user interfaces. </title> <editor> In H. R. Hartson and D. Hix, editors, </editor> <booktitle> Advances in Human-Computer Interaction, </booktitle> <volume> volume 4, chapter 7, </volume> <pages> pages 191-250. </pages> <publisher> Ablex Publishing Corp., </publisher> <address> Norwood, New Jersey, </address> <year> 1993. </year>
Reference-contexts: Furthermore, an emphasis was placed on delivering feedback in a rapid and clear manner, capabilities that are particularly important for Interfaces for Language Technology 7 recognition technologies <ref> [27] </ref>. In all conditions, people continued providing task-related information until a transaction receipt was completed at the bottom of their screen, correctly reflecting the propositional content of their requests. This receipt was filled out interactively as people worked.
Reference: [28] <author> E. Shriberg, J. Bear, and J. Dowding. </author> <title> Automatic detection and correction of repairs in human-computer dialog. </title> <booktitle> In Proceedings of the DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 23-26, </pages> <address> San Mateo, CA, February 1992. </address> <publisher> Morgan Kaufmann, Inc. </publisher>
Reference-contexts: This significant filtering of conjunctions may have contributed further to lowering syntactic ambiguity in the structured format. Interfaces for Language Technology 21 Disfluencies are widely recognized to be a difficult source of variability for spoken language processing <ref> [10, 21, 28] </ref>. Somewhat unexpectedly, the rate of disfluencies observed in this research was as high during interactive writing as during speech, even though speech transmission was much faster.
Reference: [29] <author> J. Spitz. </author> <title> Collection and analysis of data from real users: Implications for speech recognition/understanding systems. </title> <booktitle> In Proceedings of the 4th Darpa Workshop on Speech and Natural Language, Asilomar, </booktitle> <address> California, </address> <month> February </month> <year> 1991. </year> <institution> Defense Advanced Research Projects Agency. </institution>
Reference-contexts: The constrainability of spoken input has been studied extensively by the telecommunications industry as it strives to automate operator services. This work has emphasized the importance of collecting data with simulated or real systems, since speakers are naturally more constrained when responding to automatic prompts than to human operators <ref> [29] </ref>. It also has indicated that certain spoken language phenomena are more amenable to channeling than others, and that dramatic variation can occur in the successful elicitation of target language depending on the type of system prompt [15, 29]. <p> It also has indicated that certain spoken language phenomena are more amenable to channeling than others, and that dramatic variation can occur in the successful elicitation of target language depending on the type of system prompt <ref> [15, 29] </ref>. On the other hand, telecommunications field data typically have lacked the control needed for unambiguous interpretation.
Reference: [30] <author> R. K. Srihari. </author> <title> Use of lexical and syntactic techniques in recognizing handwritten text. </title> <booktitle> In Proceedings of the ARPA Human Language Technology Workshop, </booktitle> <address> Princeton, New Jersey, March 1994. </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: Collection of data from different input modalities (e.g., keyboard email as a basis for handwriting recognition <ref> [30] </ref>) or artificial tasks not involving human-computer interaction (e.g., copying Wall Street journal text as a basis for handwriting recognition [20]) risks misleading system development.
Reference: [31] <author> F. C. Stoll, D. G. Hoecker, G. P. Kruger, and A. Chapanis. </author> <title> The effects of four communication modes on the structure of language used during cooperative problem-solving. </title> <journal> Journal of Psychology, </journal> <volume> 94(1) </volume> <pages> 13-26, </pages> <year> 1976. </year>
Reference-contexts: In fact, the statistical underrepresentation of written verbs was offset by an overrepresentation of signs in this mode, in contrast with speech. The present finding that pronouns were selectively filtered from interactive handwriting replicates previous research <ref> [4, 31] </ref>. Perhaps the most striking alteration of lexical content during interactive writing involved the elevation of abbreviations, which accounted for over 15% of all content in this mode. The idiosyncratic class of nonstandard abbreviations, illustrated in Figure 2 (bottom), only was observed during interactive writing.
Reference: [32] <author> C. C. Tappert, C. Y. Suen, and T. Wakahara. </author> <title> The state of the art in on-line handwriting recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(8) </volume> <pages> 787-808, </pages> <year> 1990. </year>
Reference-contexts: characteristics of interactive writing and marking have not been documented in any comprehensive way. 2 Compared to speech, the more difficult sources of variability in interactive writing still are poorly understood, although previous work to some extent has examined variability versus consistency in gestural marking [18, 35] and written letters <ref> [32, 33] </ref>. Furthermore, research only recently has begun to focus on pen interface design [16, 34], in spite of the fact that such work could be pivotal in boosting recognition rates to levels adequate for user acceptance of pen technology [17].
Reference: [33] <author> J. R. Ward and T. Kuklinski. </author> <title> A model for variability effects in handprinting with implications for the design of handwriting character recognition systems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 18 </volume> <pages> 438-451, </pages> <month> May/June </month> <year> 1988. </year>
Reference-contexts: characteristics of interactive writing and marking have not been documented in any comprehensive way. 2 Compared to speech, the more difficult sources of variability in interactive writing still are poorly understood, although previous work to some extent has examined variability versus consistency in gestural marking [18, 35] and written letters <ref> [32, 33] </ref>. Furthermore, research only recently has begun to focus on pen interface design [16, 34], in spite of the fact that such work could be pivotal in boosting recognition rates to levels adequate for user acceptance of pen technology [17].
Reference: [34] <author> C. G. Wolf. </author> <title> Understanding handwriting recognition from the user's perspective. </title> <booktitle> In Proceedings of the Human Factors Society 34th Annual Meeting, </booktitle> <pages> pages 249-253, </pages> <year> 1990. </year>
Reference-contexts: Furthermore, research only recently has begun to focus on pen interface design <ref> [16, 34] </ref>, in spite of the fact that such work could be pivotal in boosting recognition rates to levels adequate for user acceptance of pen technology [17].
Reference: [35] <author> C. G. Wolf and P. Morrel-Samuels. </author> <title> The use of hand-drawn gestures for text editing. </title> <journal> International Journal of Man-machine Studies, </journal> <volume> 27(1) </volume> <pages> 91-102, </pages> <year> 1987. </year>
Reference-contexts: However, the unique linguistic characteristics of interactive writing and marking have not been documented in any comprehensive way. 2 Compared to speech, the more difficult sources of variability in interactive writing still are poorly understood, although previous work to some extent has examined variability versus consistency in gestural marking <ref> [18, 35] </ref> and written letters [32, 33]. Furthermore, research only recently has begun to focus on pen interface design [16, 34], in spite of the fact that such work could be pivotal in boosting recognition rates to levels adequate for user acceptance of pen technology [17].

References-found: 35

