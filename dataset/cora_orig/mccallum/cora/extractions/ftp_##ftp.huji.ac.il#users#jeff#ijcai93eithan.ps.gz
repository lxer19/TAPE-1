URL: ftp://ftp.huji.ac.il/users/jeff/ijcai93eithan.ps.gz
Refering-URL: http://www.cs.huji.ac.il/labs/dai/papers.html
Root-URL: 
Title: Multi-Agent Planning as a Dynamic Search for Social Consensus  
Author: Eithan Ephrati Jeffrey S. Rosenschein 
Address: Givat Ram, Jerusalem, Israel  
Affiliation: Computer Science Department Hebrew University  
Abstract: When autonomous agents attempt to coordinate action, it is often necessary that they reach some kind of consensus. Reaching consensus has traditionally been dealt with in the Distributed Artificial Intelligence literature via negotiation. Another alternative is to have agents use a voting mechanism; each agent expresses its preferences, and a group choice mechanism is used to select the result. Some choice mechanisms are better than others, and ideally we would like one that cannot be manipulated by untruthful agents. Coordination of actions by a group of agents corresponds to a group planning process. We here introduce a new multi-agent planning technique, that makes use of a dynamic, iterative search procedure. Through a process of group constraint aggregation, agents incrementally construct a plan that brings the group to a state maximizing social welfare. At each step, agents vote about the next joint action in the group plan (i.e., what the next transition state will be in the emerging plan). Using this technique agents need not fully reveal their preferences, and the set of alternative final states need not be generated in advance of a vote. With a minor variation, the entire procedure can be made resistant to untruthful agents.
Abstract-found: 1
Intro-found: 1
Reference: [ Chapman, 1987 ] <author> D. Chapman. </author> <title> Planning for conjuctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 333-377, </pages> <year> 1987. </year>
Reference-contexts: Given a semi-consistent E we define r (E) to be the set of all maximal consistent subsets of the predicates in E. * P (E) denotes the set of the cheapest "grounded" (or "complete" <ref> [ Chapman, 1987 ] </ref> ) plans that achieve the final subset of E.
Reference: [ Clark et al., 1992 ] <author> R. Clark, C. Grossner, and T. Radhakr-ishnan. ONSENSUS: </author> <title> a planning protocol for cooperating expert systems. </title> <booktitle> In Proceedings of the Eleventh International Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pages 77-94, </pages> <address> Glen Arbor, Michigan, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: The combination of local plans was done through "interaction constraints" that were pre-specified. The concept of solution that our algorithm employs (maximization of social welfare) also resembles the approach taken in CONSENSUS <ref> [ Clark et al., 1992 ] </ref> where several expert systems "elect" a plan that scores the highest rating with respect to the individual points of view. There, however, the election refers to different complete global plans that each expert generates.
Reference: [ Corkill, 1979 ] <author> D. Corkill. </author> <title> Hierarchical planning in a distributed environment. </title> <booktitle> In Proceedings of the Sixth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 168-175, </pages> <address> Tokyo, </address> <month> August </month> <year> 1979. </year>
Reference-contexts: The formation of multi-agent plans has been approached in several different ways: through the use of synchronization techniques [ Georgeff, 1984 ] , such as those used in operating systems, through the distribution of single-agent planners <ref> [ Corkill, 1979 ] </ref> , such as fl This research was partially supported by the Israeli Ministry of Science and Technology (Grant 032-8284) NOAH, and through centralized planners that ensure coordination [ Rosenschein, 1982 ] . In this paper, we present a new approach to deriving multi-agent plans.
Reference: [ Ephrati and Rosenschein, 1991 ] <author> E. Ephrati and J. S. Rosen-schein. </author> <title> The Clarke Tax as a consensus mechanism among automated agents. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 173-178, </pages> <address> Ana-heim, California, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: This is done by minor changes to the procedure of Section 4, that allow it to use a variant of the Clarke Tax mechanism (CTm). In <ref> [ Ephrati and Rosenschein, 1991 ] </ref> we proposed the CTm as a plausible group decision procedure. The basic idea of the mechanism is to make sure that each voter has only one dominant strategy, telling the truth.
Reference: [ Ephrati and Rosenschein, 1992a ] <author> E. Ephrati and J. S. Rosenschein. </author> <title> Multi-agent planning as search for a consensus that maximizes social welfare. </title> <booktitle> In Pre-Proceedings of the Fourth European Workshop on Modeling Autonomous Agents in a Multi-Agent World, </booktitle> <address> Rome, Italy, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Consensus will be reached after at most O (max A l (P (A)) steps such that P (A) results in a state that maximizes the group's social welfare. Proof. The proof of this theorem, and the one below, appear in <ref> [ Ephrati and Rosenschein, 1992a ] </ref> with slightly different notations. 4.1 Constraints There are several important aspects of, and requirements for, the procedure above to succeed, which we discuss in this section. <p> In addition, note that for many variations of the above worth functions, it will be sufficient to take the gap bound r f U to be zero (what was called a progressive worth function in <ref> [ Ephrati and Rosenschein, 1992a ] </ref> ).
Reference: [ Ephrati and Rosenschein, 1992b ] <author> E. Ephrati and J. S. Rosenschein. </author> <title> Reaching agreement through partial revelation of preferences. </title> <booktitle> In Proceedings of the Tenth European Conference on Artificial Intelligence, </booktitle> <pages> pages 229-233, </pages> <address> Vi-enna, Austria, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: by the entire group dynamically (allowing the procedure to be distributed [ Ephrati and Rosenschein, 1993 ] ); (b) utilities will be calculated and submitted only for "feasible" alternatives (utilities of infeasible alternatives need not be revealed, reducing the choice procedure's computational complexity, and also respecting agent privacy when possible <ref> [ Ephrati and Rosenschein, 1992b ] </ref> ); (c) agents are required to submit only the minimally "conflict-sufficient" information about their goals (described below), further maintaining their privacy. 3.1 Definitions * e (g i ) is the set of absolutely necessary constraints needed for any optimal plan to achieve the goal g <p> We have investigated other aspects of this problem in previous work <ref> [ Ephrati and Rosenschein, 1992b ] </ref> . Fortunately, there do exist solutions to this problem, such that the above plan choice mechanism can be used even when the agents are not necessarily benevolent and honest.
Reference: [ Ephrati and Rosenschein, 1993 ] <author> E. Ephrati and J. S. Rosen-schein. </author> <title> Distributed consensus mechanisms for self-interested heterogeneous agents. </title> <booktitle> In First International Conference on Intelligent and Cooperative Information Systems, </booktitle> <address> Rotterdam, </address> <month> May </month> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: When the search encounters a direction where social utility decreases beyond this limit, however, the search is terminated (reminiscent of hill-climbing). The procedure has the following advantages: (a) alternatives are generated by the entire group dynamically (allowing the procedure to be distributed <ref> [ Ephrati and Rosenschein, 1993 ] </ref> ); (b) utilities will be calculated and submitted only for "feasible" alternatives (utilities of infeasible alternatives need not be revealed, reducing the choice procedure's computational complexity, and also respecting agent privacy when possible [ Ephrati and Rosenschein, 1992b ] ); (c) agents are required to
Reference: [ Foulser et al., 1992 ] <author> D. E. Foulser, M. Li, and Q. Yang. </author> <title> Theory and algorithms for plan merging. </title> <journal> Artificial Intelligence, </journal> <volume> 57 </volume> <pages> 143-181, </pages> <year> 1992. </year>
Reference-contexts: Our approach does away with the need for several plans for each subgoal by using constraints instead of grounded plans (a level of abstraction that represents all possible grounded plans). In <ref> [ Foulser et al., 1992 ] </ref> it is shown how to merge grounded linear plans (as opposed to aggregating constraints) in a dynamic fashion.
Reference: [ Georgeff, 1984 ] <author> M. Georgeff. </author> <title> A theory of action for multi-agent planning. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 121-125, </pages> <address> Austin, Texas, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: Activity in multi-agent worlds often requires agreement by the agents as to how they will act, and the reaching of consensus is a major concern of DAI. The formation of multi-agent plans has been approached in several different ways: through the use of synchronization techniques <ref> [ Georgeff, 1984 ] </ref> , such as those used in operating systems, through the distribution of single-agent planners [ Corkill, 1979 ] , such as fl This research was partially supported by the Israeli Ministry of Science and Technology (Grant 032-8284) NOAH, and through centralized planners that ensure coordination [ Rosenschein,
Reference: [ Haddawy and Hanks, 1990 ] <author> P. Haddawy and S. Hanks. </author> <title> Issues in descision-theoretic planning: Symbolic goals and numeric utilities. </title> <type> Technical report, </type> <institution> University of Illinois at Urbana-Champaign, IL, </institution> <year> 1990. </year>
Reference-contexts: (op k )) associated with its success, we could use ( Q k These evaluations may be further refined by having weighted costs and/or probability of success associated with each of the constraints that needs to be achieved in order to transform the given set into the goal set (see <ref> [ Haddawy and Hanks, 1990 ] </ref> and [ Kanazawa and Dean, 1989 ] for richer probabilistic approaches). Note that instead of assigning worth to sets of constraints, it may sometimes be more natural to evaluate their induced states (s (A) instead of A).
Reference: [ Kanazawa and Dean, 1989 ] <author> K. Kanazawa and T. Dean. </author> <title> A model for projection and action. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <year> 1989. </year>
Reference-contexts: we could use ( Q k These evaluations may be further refined by having weighted costs and/or probability of success associated with each of the constraints that needs to be achieved in order to transform the given set into the goal set (see [ Haddawy and Hanks, 1990 ] and <ref> [ Kanazawa and Dean, 1989 ] </ref> for richer probabilistic approaches). Note that instead of assigning worth to sets of constraints, it may sometimes be more natural to evaluate their induced states (s (A) instead of A).
Reference: [ Korf, 1987 ] <author> R. E. Korf. </author> <title> Planning as search: A quantitative approach. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 65-88, </pages> <year> 1987. </year>
Reference-contexts: The group's social utility is therefore improved by 8. 6 Related Work There are a number of artificial intelligence researchers whose work relates to the approach we have been discussing above. Some of this work follows in the footsteps of Korf <ref> [ Korf, 1987 ] </ref> , who showed that the planning search space can be reduced if the final goal can be decomposed into several sub-goals, and the plans that achieve these sub-goals can be combined to achieve the original goal.
Reference: [ Lansky, 1990 ] <author> A. L. Lansky. </author> <title> Localized search for controlling automated reasoning. </title> <booktitle> In Proceedings of the Workshop on Innovative Approachess to Planning, Scheduling and Control, </booktitle> <pages> pages 115-125, </pages> <address> San Diego, California, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: To achieve an optimal final plan it takes that algorithm O ( Q n i=1 l (P (g i ))), while the approximation algorithm that is presented there takes polynomial time. Our approach also resembles the GEMPLAN system <ref> [ Lansky, 1990 ] </ref> . There, the search space of the global plan is divided into "regions" of activity.
Reference: [ Moehlman and Lesser, 1990 ] <author> T. Moehlman and V. Lesser. </author> <title> Cooperative planning and decentralized negotiation in Multi-Fireboss Phoenix. </title> <booktitle> In Proceedings of the Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pages 144-159, </pages> <address> San Diego, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: Since the search is guided by the vote taken at each step, it is possible to allow the agents to change their "tastes" or priorities over time (for example, due to environmental changes). As an example, in the Multi-Fireboss Phoenix system <ref> [ Moehlman and Lesser, 1990 ] </ref> planning (the actions needed to assess and contain fires) is performed by several spatially distributed agents. The system addresses, through a sophisticated negotiation protocol, the dynamic allocation of resources. Our algorithm would solve this problem in a direct manner, without negotiation.
Reference: [ Nau et al., 1990 ] <author> D. S. Nau, Q. Yang, and J. Hendler. </author> <title> Optimization of multiple-goal plans with limited interaction. </title> <booktitle> In Proceedings of the Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pages 160-165, </pages> <address> San Diego, California, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: This result suggests that the multi-agent planning algorithm presented in this paper can also serve to reduce the search space in a single-agent planning scenario if a non-optimal solution is acceptable. A similar approach is taken in <ref> [ Nau et al., 1990 ] </ref> to find an optimal plan. It is shown there how planning for multiple goals can be done by first generating several plans for each subgoal and then merging these plans.
Reference: [ Pope et al., 1992 ] <author> R. P. Pope, S. E. Conry, and R. A. Mayer. </author> <title> Distributing the planning process in a dynamic environment. </title> <booktitle> In Proceedings of the Eleventh International Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pages 317-331, </pages> <address> Glen Arbor, Michigan, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: Planning in each region is done separately, but an important part of the planning process within a region is the updating of its overlapping regions (in our terms, all individual plans are generated and aggregated simultaneously). This model served as a basis for the DCONSA system <ref> [ Pope et al., 1992 ] </ref> where agents were not assumed to have complete information about their local environments. The combination of local plans was done through "interaction constraints" that were pre-specified.
Reference: [ Rosenschein, 1982 ] <author> J. S. Rosenschein. </author> <title> Synchronization of multi-agent plans. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 115-119, </pages> <address> Pittsburgh, Pennsylvania, </address> <month> August </month> <year> 1982. </year>
Reference-contexts: techniques [ Georgeff, 1984 ] , such as those used in operating systems, through the distribution of single-agent planners [ Corkill, 1979 ] , such as fl This research was partially supported by the Israeli Ministry of Science and Technology (Grant 032-8284) NOAH, and through centralized planners that ensure coordination <ref> [ Rosenschein, 1982 ] </ref> . In this paper, we present a new approach to deriving multi-agent plans. We consider how agents could reach consensus using a voting procedure, without having to reveal full goals and preferences (unless that is actually necessary for consensus to be reached).
References-found: 17

