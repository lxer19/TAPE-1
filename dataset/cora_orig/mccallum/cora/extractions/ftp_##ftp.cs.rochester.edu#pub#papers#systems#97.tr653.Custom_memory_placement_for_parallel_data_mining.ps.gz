URL: ftp://ftp.cs.rochester.edu/pub/papers/systems/97.tr653.Custom_memory_placement_for_parallel_data_mining.ps.gz
Refering-URL: http://www.cs.indiana.edu/cstr/search/?Knowledge+discovery+MINK%3D2
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Custom Memory Placement for Parallel Data Mining  
Author: S.Parthasarathy, M. J. Zaki, and W. Li 
Keyword: Knowledge Discovery, Data Mining, Association Rules, Memory Placement, Memory Allocation, Improving Locality, Reducing False Sharing, Dynamic Data Structures, Hash Tree  
Note: supported this work. This work was supported in part by an NSF Research Initiation Award (CCR-9409120) and ARPA contract F19628-94-C-0057.  
Address: 500 Oracle Parkway, Redwood Shores, CA 94065  Rochester, New York 14627  
Affiliation: Oracle Corporation,  The University of Rochester Computer Science Department  The University of Rochester Computer Science Department  
Pubnum: Technical Report 653  
Email: fsrini, zakig@cs.rochester.edu  weili@us.oracle.com  
Date: November 1997  
Abstract: A lot of data mining tasks, such as Associations, Sequences, and Classification, use complex pointer-based data structures that typically suffer from sub-optimal locality. In the multiprocessor case shared access to these data structures may also result in false-sharing. Most of the optimization techniques for enhancing locality and reducing false sharing have been proposed in the context of numeric applications involving array-based data structures, and are not applicable for dynamic data structures due to dynamic memory allocation from the heap with arbitrary addresses. Within the context of data mining it is commonly observed that the building phase of these large recursive data structures, such as hash trees and decision trees, is random and independent from the access phase which is usually ordered and typically dominates the computation time. In such cases locality and false sharing sensitive memory placement of these structures can enhance performance significantly. We evaluate a set of placement policies over a representive data mining application (association rule discovery) and show that simple placement schemes can improve execution time by more than a factor of two. More complex schemes yield an additional 5-20% gain. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Database mining: A performance perspective. </title> <journal> In IEEE Trans. on Knowledge and Data Engg., </journal> <pages> pages 5(6) 914-925, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Data Mining is an emerging area, whose goal is to extract significant patterns or interesting rules from databases. Data mining is in fact a broad area which combines research in machine learning, statistics and databases. It can be broadly classified into these categories <ref> [1] </ref>: Classification (Clustering) finding rules that partition the database into finite, disjoint, and previously known (unknown) classes; Sequences extracting commonly occurring sequences in ordered data; and Associations (a form of summarization) finding the set of most commonly occurring groups of items.
Reference: [2] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In ACM SIGMOD Intl. Conf. Management of Data, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: We next present our experimental results in section 5. Relevant related work is discussed in section 6, and we present our conclusions in section 7. 2 Parallel Association Mining 2.1 Problem Formulation The problem of mining associations over basket data was introduced in <ref> [2] </ref>. It can be formally stated as: Let I = fi 1 ; i 2 ; ; i m g be a set of m distinct attributes, also called items. <p> We expect the benefits of reducing false sharing to be more pronounced for software distributed shared memory due to larger coherence blocks. 6 Related Work 6.1 Association Mining Sequential Algorithms Several algorithms for mining associations have been proposed in the literature <ref> [2, 22, 5, 16, 24, 17, 26, 3, 27] </ref>. The Apriori algorithm [22, 5, 3] was shown to have superior performance to earlier approaches [2, 24, 16, 17] and forms the core of almost all of the current algorithms. <p> The Apriori algorithm [22, 5, 3] was shown to have superior performance to earlier approaches <ref> [2, 24, 16, 17] </ref> and forms the core of almost all of the current algorithms. The key observation used is that all subsets of a frequent itemset must themselves be frequent. It makes multiple database scans as described in section 2.2. It may thus incur high I/O overhead.
Reference: [3] <author> R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A. Inkeri Verkamo. </author> <title> Fast discovery of association rules. </title> <editor> In U. Fayyad and et al, editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining. </booktitle> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: Discovering the frequent itemsets requires a lot of computation power, memory and I/O, which can only be provided by parallel computers. 2.2 Sequential Association Algorithm Our parallel shared-memory algorithm is built on top of the sequential Apriori association mining algorithm proposed in <ref> [3] </ref>. During iteration k of the algorithm a set of candidate k-itemsets is generated. The database is then scanned and the support for each candidate is found. Only the frequent k-itemsets are retained for future iterations, and are used to generate a candidate set for the next iteration. <p> The databases are stored on an attached 2GB disk. All processors run IRIX 5.3, and data is obtained from the disk via an NFS file server. We used different synthetic databases generated using the procedure described in <ref> [3] </ref>. These databases have been used as benchmarks for many association rules algorithms [5, 16, 24, 26, 3]. They mimic the transactions in a retailing environment. Each transaction has a unique ID followed by a list of items bought in that transaction. <p> All processors run IRIX 5.3, and data is obtained from the disk via an NFS file server. We used different synthetic databases generated using the procedure described in [3]. These databases have been used as benchmarks for many association rules algorithms <ref> [5, 16, 24, 26, 3] </ref>. They mimic the transactions in a retailing environment. Each transaction has a unique ID followed by a list of items bought in that transaction. The data-mining provides information about the set of items generally bought together. <p> In all the datasets, we set the number of maximal potentially large itemsets jLj = 2000, and the number of items N = 1000. We refer the reader to <ref> [3] </ref> for more detail on the database generation. All our experiments were performed with a minimum support values of 0.1% and 0.5%. <p> We expect the benefits of reducing false sharing to be more pronounced for software distributed shared memory due to larger coherence blocks. 6 Related Work 6.1 Association Mining Sequential Algorithms Several algorithms for mining associations have been proposed in the literature <ref> [2, 22, 5, 16, 24, 17, 26, 3, 27] </ref>. The Apriori algorithm [22, 5, 3] was shown to have superior performance to earlier approaches [2, 24, 16, 17] and forms the core of almost all of the current algorithms. <p> The Apriori algorithm <ref> [22, 5, 3] </ref> was shown to have superior performance to earlier approaches [2, 24, 16, 17] and forms the core of almost all of the current algorithms. The key observation used is that all subsets of a frequent itemset must themselves be frequent.
Reference: [4] <author> R. Agrawal and J. Shafer. </author> <title> Parallel mining of association rules. </title> <journal> In IEEE Trans. on Knowledge and Data Engg., </journal> <pages> pages 8(6) 962-969, </pages> <year> 1996. </year>
Reference-contexts: The new algorithms were shown to perform better than both Apriori and Partition. 18 Parallel Algorithms Distributed Memory Machines: There has been relatively less work in parallel mining of associations. Three different parallelizations of Apriori on a distributed-memory machine (IBM SP2) were presented in <ref> [4] </ref>. The Count Distribution algorithm is a straight-forward parallelization of Apriori. Each processor generates the partial support of all candidate item-sets from its local database partition. At the end of each iteration the global supports are generated by exchanging the partial supports among all the processors. <p> Other parallel algorithms improving upon these ideas in terms of communication efficiency, or aggregate memory utilization have also been proposed [10, 14]. The PDM algorithm [25] presents a parallelization of the DHP algorithm [24]. However, PDM performs worse than Count Distribution <ref> [4] </ref>. In recent work we presented new parallel association mining algorithms [35]. They utilize the fast sequential algorithms proposed in [31, 33] as the base algorithm.
Reference: [5] <author> R. Agrawal and R. Srikant. </author> <title> Fast algorithms for mining association rules. </title> <booktitle> In 20th VLDB Conf., </booktitle> <month> September </month> <year> 1994. </year>
Reference-contexts: The data mining task for association rules can be broken into two steps. The first step consists of finding all frequent itemsets, i.e., itemsets that occur in the database with a certain user-specified frequency, called minimum support. The second step consists of forming implication rules among the frequent itemsets <ref> [5] </ref>. The second step is relatively straightforward. Once the support of frequent itemsets is known, rules of the form XY ) Y (where Y X), are generated for all frequent itemsets X, provided the rules meet the desired confidence. <p> All processors run IRIX 5.3, and data is obtained from the disk via an NFS file server. We used different synthetic databases generated using the procedure described in [3]. These databases have been used as benchmarks for many association rules algorithms <ref> [5, 16, 24, 26, 3] </ref>. They mimic the transactions in a retailing environment. Each transaction has a unique ID followed by a list of items bought in that transaction. The data-mining provides information about the set of items generally bought together. <p> We expect the benefits of reducing false sharing to be more pronounced for software distributed shared memory due to larger coherence blocks. 6 Related Work 6.1 Association Mining Sequential Algorithms Several algorithms for mining associations have been proposed in the literature <ref> [2, 22, 5, 16, 24, 17, 26, 3, 27] </ref>. The Apriori algorithm [22, 5, 3] was shown to have superior performance to earlier approaches [2, 24, 16, 17] and forms the core of almost all of the current algorithms. <p> The Apriori algorithm <ref> [22, 5, 3] </ref> was shown to have superior performance to earlier approaches [2, 24, 16, 17] and forms the core of almost all of the current algorithms. The key observation used is that all subsets of a frequent itemset must themselves be frequent.
Reference: [6] <author> J. M. Anderson, S. P. Amarsinghe, and M. Lam. </author> <title> Data and computation transformations for multiprocessors. </title> <booktitle> ACM Symp. Principles and Practice of Parallel Programming, </booktitle> <year> 1995. </year>
Reference-contexts: Those optimizations result in a good performance improvement for the applications they considered. In our case study padding and aligning was not found to be very beneficial. Other techniques to reduce false sharing on array based programs include indirection [12], software caching [8], and data remapping <ref> [6] </ref>. Our placement policies have utilized some of these techniques. 6.4 Memory Allocation General purpose algorithms for dynamic storage have been proposed and honed for several years [19, 18, 29].
Reference: [7] <author> J. M. Anderson and M. Lam. </author> <title> Global optimizations for parallelism and locality on scalable parallel machines. </title> <booktitle> ACM Conf. Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Such structures consist of individual nodes that are allocated arbitrarily from a central heap and which are linked together by pointers. Unfortunately traditional locality optimizations found in the literature <ref> [9, 7] </ref> cannot be applied directly for such structures. These optimizations are essentially array based and rely on the fact that consecutive array elements are at consecutive addresses and therefore small strided accesses can be placed on same cache line. <p> This paper studied the locality and false sharing problems encountered in CCPD, and solutions for alleviating them. 6.2 Improving Locality Several automatic techniques like tiling, strip-mining, loop interchange, uniform transformations <ref> [9, 7, 11, 20] </ref> have been proposed on a wide range of architectures, to improve the locality of array-based programs. However these cannot directly be applied for dynamic data structures. Prefetching is also a suggested mechanism to help tolerate the latency problem.
Reference: [8] <author> Ricardo Bianchini and Thomas J. LeBlanc. </author> <title> Software caching on cache-coherent multiprocessors. </title> <booktitle> 4th Symp. Parallel Distributed Processing, </booktitle> <pages> pages 521-526, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: There are three resulting strategies: 1) Lock-region Simple Placement Policy (L-SPP), 2) Lock-region Localized Placement Policy (L-LPP), and 3) Lock-region Global Placement Policy (L-GPP). Privatize (and Reduce): Another technique for eliminating false sharing is called Software Caching <ref> [8] </ref> or Privatization. It involves making a private copy of the data that will be used locally, so that operations on that data do not cause false sharing. <p> Those optimizations result in a good performance improvement for the applications they considered. In our case study padding and aligning was not found to be very beneficial. Other techniques to reduce false sharing on array based programs include indirection [12], software caching <ref> [8] </ref>, and data remapping [6]. Our placement policies have utilized some of these techniques. 6.4 Memory Allocation General purpose algorithms for dynamic storage have been proposed and honed for several years [19, 18, 29].
Reference: [9] <author> Steve Carr, Kathryn S. McKinley, and Chau-Wen Tseng. </author> <title> Compiler optimizations for improving data locality. </title> <booktitle> 6th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 252-262, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Such structures consist of individual nodes that are allocated arbitrarily from a central heap and which are linked together by pointers. Unfortunately traditional locality optimizations found in the literature <ref> [9, 7] </ref> cannot be applied directly for such structures. These optimizations are essentially array based and rely on the fact that consecutive array elements are at consecutive addresses and therefore small strided accesses can be placed on same cache line. <p> This paper studied the locality and false sharing problems encountered in CCPD, and solutions for alleviating them. 6.2 Improving Locality Several automatic techniques like tiling, strip-mining, loop interchange, uniform transformations <ref> [9, 7, 11, 20] </ref> have been proposed on a wide range of architectures, to improve the locality of array-based programs. However these cannot directly be applied for dynamic data structures. Prefetching is also a suggested mechanism to help tolerate the latency problem.
Reference: [10] <author> D. Cheung, V. Ng, A. Fu, and Y. Fu. </author> <title> Efficient mining of association rules in distributed databases. </title> <journal> In IEEE Trans. on Knowledge and Data Engg., </journal> <pages> pages 8(6) 911-922, </pages> <year> 1996. </year>
Reference-contexts: The Candidate Distribution algorithm also partitions the candidates, but it selectively replicates the database, so that each processor proceeds independently. The local portion is scanned once during each iteration. Other parallel algorithms improving upon these ideas in terms of communication efficiency, or aggregate memory utilization have also been proposed <ref> [10, 14] </ref>. The PDM algorithm [25] presents a parallelization of the DHP algorithm [24]. However, PDM performs worse than Count Distribution [4]. In recent work we presented new parallel association mining algorithms [35]. They utilize the fast sequential algorithms proposed in [31, 33] as the base algorithm.
Reference: [11] <author> Michal Cierniak and Wei Li. </author> <title> Unifying data and control transformations for distributed shared-memory machines. </title> <booktitle> ACM Conf. Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: This paper studied the locality and false sharing problems encountered in CCPD, and solutions for alleviating them. 6.2 Improving Locality Several automatic techniques like tiling, strip-mining, loop interchange, uniform transformations <ref> [9, 7, 11, 20] </ref> have been proposed on a wide range of architectures, to improve the locality of array-based programs. However these cannot directly be applied for dynamic data structures. Prefetching is also a suggested mechanism to help tolerate the latency problem.
Reference: [12] <author> Susan J. Eggers and Tor E. Jeremiassen. </author> <title> Eliminating false sharing. </title> <booktitle> Intl. Conf. Parallel Processing, </booktitle> <pages> pages I:377-381, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Those optimizations result in a good performance improvement for the applications they considered. In our case study padding and aligning was not found to be very beneficial. Other techniques to reduce false sharing on array based programs include indirection <ref> [12] </ref>, software caching [8], and data remapping [6]. Our placement policies have utilized some of these techniques. 6.4 Memory Allocation General purpose algorithms for dynamic storage have been proposed and honed for several years [19, 18, 29].
Reference: [13] <author> D. Grunwald, B. Zorn, and R. Henderson. </author> <title> Improving the cache locality of memory allocation. </title> <booktitle> ACM Conf. Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Our placement policies have utilized some of these techniques. 6.4 Memory Allocation General purpose algorithms for dynamic storage have been proposed and honed for several years [19, 18, 29]. An evaluation of the performance of contemporary memory allocators on 5 allocation intensive C programs was presented in <ref> [13] </ref> Their measurements indicated that a custom allocator can be a very important optimization for memory subsystem performance.
Reference: [14] <author> E-H. Han, G. Karypis, and V. Kumar. </author> <title> Scalable parallel data mining for association rules. </title> <booktitle> In ACM SIGMOD Conf. Management of Data, </booktitle> <month> May </month> <year> 1997. </year> <month> 22 </month>
Reference-contexts: The Candidate Distribution algorithm also partitions the candidates, but it selectively replicates the database, so that each processor proceeds independently. The local portion is scanned once during each iteration. Other parallel algorithms improving upon these ideas in terms of communication efficiency, or aggregate memory utilization have also been proposed <ref> [10, 14] </ref>. The PDM algorithm [25] presents a parallelization of the DHP algorithm [24]. However, PDM performs worse than Count Distribution [4]. In recent work we presented new parallel association mining algorithms [35]. They utilize the fast sequential algorithms proposed in [31, 33] as the base algorithm.
Reference: [15] <author> J. Hennessey and D. Patterson. </author> <title> Computer Architecture : A Quantitative Approach. </title> <publisher> Morgan-Kaufmann Pub., </publisher> <year> 1995. </year>
Reference-contexts: If the number of processors is increased it is not easy to have one shared memory with fast access times for all processors. Therefore, most contemporary designs include private coherent caches for each processor. Due to the increasing gap between processor and memory subsystem performance in modern processors <ref> [15] </ref>, for data-intensive tasks improving the data locality (i.e. having as much of the data local to the processor cache) is extremely important to ensure that most accesses are to fast local memory. <p> the application to avoid the unnecessary locking overhead if it knows beforehand that two processors will not allocate memory from the same region simultaneously. 4 Memory Placement Policies for Association Mining Processor speeds are improving by 50-100% every year, while memory access times are improving by only 7% every year <ref> [15] </ref>. Memory latency is therefore becoming an increasingly important performance bottleneck in modern multiprocessors. While cache hierarchies alleviate this problem to an extent, application level locality optimization is crucial for improving performance.
Reference: [16] <author> M. Holsheimer, M. Kersten, H. Mannila, and H. Toivonen. </author> <title> A perspective on databases and data mining. </title> <booktitle> In 1st Intl. Conf. Knowledge Discovery and Data Mining, </booktitle> <month> August </month> <year> 1995. </year>
Reference-contexts: All processors run IRIX 5.3, and data is obtained from the disk via an NFS file server. We used different synthetic databases generated using the procedure described in [3]. These databases have been used as benchmarks for many association rules algorithms <ref> [5, 16, 24, 26, 3] </ref>. They mimic the transactions in a retailing environment. Each transaction has a unique ID followed by a list of items bought in that transaction. The data-mining provides information about the set of items generally bought together. <p> We expect the benefits of reducing false sharing to be more pronounced for software distributed shared memory due to larger coherence blocks. 6 Related Work 6.1 Association Mining Sequential Algorithms Several algorithms for mining associations have been proposed in the literature <ref> [2, 22, 5, 16, 24, 17, 26, 3, 27] </ref>. The Apriori algorithm [22, 5, 3] was shown to have superior performance to earlier approaches [2, 24, 16, 17] and forms the core of almost all of the current algorithms. <p> The Apriori algorithm [22, 5, 3] was shown to have superior performance to earlier approaches <ref> [2, 24, 16, 17] </ref> and forms the core of almost all of the current algorithms. The key observation used is that all subsets of a frequent itemset must themselves be frequent. It makes multiple database scans as described in section 2.2. It may thus incur high I/O overhead.
Reference: [17] <author> M. Houtsma and A. Swami. </author> <title> Set-oriented mining of association rules in relational databases. </title> <booktitle> In 11th Intl. Conf. Data Engineering, </booktitle> <year> 1995. </year>
Reference-contexts: We expect the benefits of reducing false sharing to be more pronounced for software distributed shared memory due to larger coherence blocks. 6 Related Work 6.1 Association Mining Sequential Algorithms Several algorithms for mining associations have been proposed in the literature <ref> [2, 22, 5, 16, 24, 17, 26, 3, 27] </ref>. The Apriori algorithm [22, 5, 3] was shown to have superior performance to earlier approaches [2, 24, 16, 17] and forms the core of almost all of the current algorithms. <p> The Apriori algorithm [22, 5, 3] was shown to have superior performance to earlier approaches <ref> [2, 24, 16, 17] </ref> and forms the core of almost all of the current algorithms. The key observation used is that all subsets of a frequent itemset must themselves be frequent. It makes multiple database scans as described in section 2.2. It may thus incur high I/O overhead.
Reference: [18] <author> C. Kingsley. </author> <title> Description of a very fast storage allocator. Documentation of 4.2 BSD Unix malloc implementation, </title> <month> February </month> <year> 1982. </year>
Reference-contexts: Other techniques to reduce false sharing on array based programs include indirection [12], software caching [8], and data remapping [6]. Our placement policies have utilized some of these techniques. 6.4 Memory Allocation General purpose algorithms for dynamic storage have been proposed and honed for several years <ref> [19, 18, 29] </ref>. An evaluation of the performance of contemporary memory allocators on 5 allocation intensive C programs was presented in [13] Their measurements indicated that a custom allocator can be a very important optimization for memory subsystem performance.
Reference: [19] <author> Donald E. Knuth. </author> <title> Fundamental Algorithms: </title> <booktitle> The Art of Computer Programming. </booktitle> <volume> Volume 1. </volume> <publisher> Addison-Wesley Pub, </publisher> <year> 1973. </year>
Reference-contexts: Other techniques to reduce false sharing on array based programs include indirection [12], software caching [8], and data remapping [6]. Our placement policies have utilized some of these techniques. 6.4 Memory Allocation General purpose algorithms for dynamic storage have been proposed and honed for several years <ref> [19, 18, 29] </ref>. An evaluation of the performance of contemporary memory allocators on 5 allocation intensive C programs was presented in [13] Their measurements indicated that a custom allocator can be a very important optimization for memory subsystem performance.
Reference: [20] <author> W. Li. </author> <title> Compiler cache optimizations for banded matrix problems. </title> <booktitle> Intl. Conf. on Supercomputing, </booktitle> <pages> pages 21-30, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: This paper studied the locality and false sharing problems encountered in CCPD, and solutions for alleviating them. 6.2 Improving Locality Several automatic techniques like tiling, strip-mining, loop interchange, uniform transformations <ref> [9, 7, 11, 20] </ref> have been proposed on a wide range of architectures, to improve the locality of array-based programs. However these cannot directly be applied for dynamic data structures. Prefetching is also a suggested mechanism to help tolerate the latency problem.
Reference: [21] <author> Chi-Keung Luk and Todd C. Mowry. </author> <title> Compiler-based prefetching for recursive data structures. </title> <booktitle> 6th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <year> 1996. </year>
Reference-contexts: However these cannot directly be applied for dynamic data structures. Prefetching is also a suggested mechanism to help tolerate the latency problem. Automatic prefetching based on locality on array based programs was suggested in work done in [23]. Building upon this work, more recently in <ref> [21] </ref>, a compiler based prefetching strategy on recursive data structures was presented. They propose a data linearization scheme, which linearizes one data class in memory to support prefetching, whereas we suggest an approach 19 where related structures are grouped together based on access patterns to further enhance locality.
Reference: [22] <author> H. Mannila, H. Toivonen, and I. Verkamo. </author> <title> Efficient algorithms for discovering association rules. </title> <note> In AAAI Wkshp. Knowledge Discovery in Databases, </note> <month> July </month> <year> 1994. </year>
Reference-contexts: We expect the benefits of reducing false sharing to be more pronounced for software distributed shared memory due to larger coherence blocks. 6 Related Work 6.1 Association Mining Sequential Algorithms Several algorithms for mining associations have been proposed in the literature <ref> [2, 22, 5, 16, 24, 17, 26, 3, 27] </ref>. The Apriori algorithm [22, 5, 3] was shown to have superior performance to earlier approaches [2, 24, 16, 17] and forms the core of almost all of the current algorithms. <p> The Apriori algorithm <ref> [22, 5, 3] </ref> was shown to have superior performance to earlier approaches [2, 24, 16, 17] and forms the core of almost all of the current algorithms. The key observation used is that all subsets of a frequent itemset must themselves be frequent.
Reference: [23] <author> T. C. Mowry, M. S. Lam, and A. Gupta. </author> <title> Design and evaluation of a compiler algorithm for prefetching. </title> <booktitle> 5th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 62-73, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: However these cannot directly be applied for dynamic data structures. Prefetching is also a suggested mechanism to help tolerate the latency problem. Automatic prefetching based on locality on array based programs was suggested in work done in <ref> [23] </ref>. Building upon this work, more recently in [21], a compiler based prefetching strategy on recursive data structures was presented.
Reference: [24] <author> J. S. Park, M. Chen, and P. S. Yu. </author> <title> An effective hash based algorithm for mining association rules. </title> <booktitle> In ACM SIGMOD Intl. Conf. Management of Data, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: All processors run IRIX 5.3, and data is obtained from the disk via an NFS file server. We used different synthetic databases generated using the procedure described in [3]. These databases have been used as benchmarks for many association rules algorithms <ref> [5, 16, 24, 26, 3] </ref>. They mimic the transactions in a retailing environment. Each transaction has a unique ID followed by a list of items bought in that transaction. The data-mining provides information about the set of items generally bought together. <p> We expect the benefits of reducing false sharing to be more pronounced for software distributed shared memory due to larger coherence blocks. 6 Related Work 6.1 Association Mining Sequential Algorithms Several algorithms for mining associations have been proposed in the literature <ref> [2, 22, 5, 16, 24, 17, 26, 3, 27] </ref>. The Apriori algorithm [22, 5, 3] was shown to have superior performance to earlier approaches [2, 24, 16, 17] and forms the core of almost all of the current algorithms. <p> The Apriori algorithm [22, 5, 3] was shown to have superior performance to earlier approaches <ref> [2, 24, 16, 17] </ref> and forms the core of almost all of the current algorithms. The key observation used is that all subsets of a frequent itemset must themselves be frequent. It makes multiple database scans as described in section 2.2. It may thus incur high I/O overhead. <p> The local portion is scanned once during each iteration. Other parallel algorithms improving upon these ideas in terms of communication efficiency, or aggregate memory utilization have also been proposed [10, 14]. The PDM algorithm [25] presents a parallelization of the DHP algorithm <ref> [24] </ref>. However, PDM performs worse than Count Distribution [4]. In recent work we presented new parallel association mining algorithms [35]. They utilize the fast sequential algorithms proposed in [31, 33] as the base algorithm.
Reference: [25] <author> J. S. Park, M. Chen, and P. S. Yu. </author> <title> Efficient parallel data mining for association rules. </title> <booktitle> In ACM Intl. Conf. Information and Knowledge Management, </booktitle> <month> November </month> <year> 1995. </year>
Reference-contexts: The local portion is scanned once during each iteration. Other parallel algorithms improving upon these ideas in terms of communication efficiency, or aggregate memory utilization have also been proposed [10, 14]. The PDM algorithm <ref> [25] </ref> presents a parallelization of the DHP algorithm [24]. However, PDM performs worse than Count Distribution [4]. In recent work we presented new parallel association mining algorithms [35]. They utilize the fast sequential algorithms proposed in [31, 33] as the base algorithm.
Reference: [26] <author> A. Savasere, E. Omiecinski, and S. Navathe. </author> <title> An efficient algorithm for mining association rules in large databases. </title> <booktitle> In 21st VLDB Conf., </booktitle> <year> 1995. </year>
Reference-contexts: All processors run IRIX 5.3, and data is obtained from the disk via an NFS file server. We used different synthetic databases generated using the procedure described in [3]. These databases have been used as benchmarks for many association rules algorithms <ref> [5, 16, 24, 26, 3] </ref>. They mimic the transactions in a retailing environment. Each transaction has a unique ID followed by a list of items bought in that transaction. The data-mining provides information about the set of items generally bought together. <p> We expect the benefits of reducing false sharing to be more pronounced for software distributed shared memory due to larger coherence blocks. 6 Related Work 6.1 Association Mining Sequential Algorithms Several algorithms for mining associations have been proposed in the literature <ref> [2, 22, 5, 16, 24, 17, 26, 3, 27] </ref>. The Apriori algorithm [22, 5, 3] was shown to have superior performance to earlier approaches [2, 24, 16, 17] and forms the core of almost all of the current algorithms. <p> The key observation used is that all subsets of a frequent itemset must themselves be frequent. It makes multiple database scans as described in section 2.2. It may thus incur high I/O overhead. The Partition algorithm <ref> [26] </ref> minimizes I/O by scanning the database 2 or 3 times. It partitions the database into small chunks which can be handled in memory.
Reference: [27] <author> H. Toivonen. </author> <title> Sampling large databases for association rules. </title> <booktitle> In 22nd VLDB Conf., </booktitle> <year> 1996. </year>
Reference-contexts: We expect the benefits of reducing false sharing to be more pronounced for software distributed shared memory due to larger coherence blocks. 6 Related Work 6.1 Association Mining Sequential Algorithms Several algorithms for mining associations have been proposed in the literature <ref> [2, 22, 5, 16, 24, 17, 26, 3, 27] </ref>. The Apriori algorithm [22, 5, 3] was shown to have superior performance to earlier approaches [2, 24, 16, 17] and forms the core of almost all of the current algorithms. <p> Another way to minimize the I/O overhead is to work with only a small random sample of the database. An analysis of the effectiveness of sampling for association mining was presented in [32], and <ref> [27] </ref> presents an exact algorithm that finds all rules using sampling. We recently proposed new association mining algorithms that usually make only 3 scans [33, 34]. They use novel itemset clustering techniques, based on equivalence classes and maximal hypergraph cliques, to approximate the set of potentially maximal frequent itemsets.
Reference: [28] <author> J. Torrellas, M. S. Lam, and J. L. Hennessy. </author> <title> Shared data placement optimizations to reduce multiprocessor cache miss rates. </title> <booktitle> Intl. Conf. Parallel Processing, </booktitle> <pages> pages II:266-270, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Our experimental results indicate increased locality gains when grouping related data structures, rather than linearizing a single class. 6.3 Reducing False Sharing Five techniques mainly directed at reducing false sharing were proposed in <ref> [28] </ref>. They include padding, aligning, and allocation of memory requested by different processors from different heap regions. Those optimizations result in a good performance improvement for the applications they considered. In our case study padding and aligning was not found to be very beneficial.
Reference: [29] <author> C. B. Weinstock and W. A. Wulf. </author> <title> An efficient algorithm for heap storage allocation. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 23(10) </volume> <pages> 141-148, </pages> <month> October </month> <year> 1988. </year> <month> 23 </month>
Reference-contexts: Other techniques to reduce false sharing on array based programs include indirection [12], software caching [8], and data remapping [6]. Our placement policies have utilized some of these techniques. 6.4 Memory Allocation General purpose algorithms for dynamic storage have been proposed and honed for several years <ref> [19, 18, 29] </ref>. An evaluation of the performance of contemporary memory allocators on 5 allocation intensive C programs was presented in [13] Their measurements indicated that a custom allocator can be a very important optimization for memory subsystem performance.
Reference: [30] <author> M. J. Zaki, M. Ogihara, S. Parthasarathy, and W. Li. </author> <title> Parallel data mining for as-sociation rules on shared-memory multi-processors. </title> <booktitle> In Supercomputing'96, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: The first two are eliminated in the pruning step, since they have a 2-subset which is not frequent, namely the 2-subsets (2; 4) and (2; 5), respectively. 2.3 Parallel Association Mining on SMP Systems We now briefly describe the Common Candidate Partitioned Database (CCPD) <ref> [30] </ref> parallel association mining algorithm on shared-memory multiprocessors. As the name suggests CCPD keeps a common candidate hash tree among all processors, but the database is logically split among them in a blocked fashion. <p> Finally, the master process selects the frequent itemsets. 5 A brief description of the two key steps of parallel candidate generation and support count-ing is given below. A more detailed study on the optimizations and parallel performance of CCPD can be found in <ref> [30] </ref>. Parallel Candidate Itemset Generation Equivalence Classes: Let F 2 = fAB, AC, AD, AE, BC, BD, BE, DEg. Then C 3 = fABC, ABD, ABE, ACD, ACE, ADE, BCD, BCE, BDEg. <p> Hash Tree Balancing: Another important factor affecting the performance is the hash function used in the internal nodes of the hash tree. A simple "mod" function on the hash table length can result in unbalanced trees with long search paths. In <ref> [30] </ref> we presented a new hash function which utilizes the equivalence classes to find out the occurrence of different items in the candidates. <p> Once all processors have finished the support counting, the master extracts those candidates that have minimum support and inserts them into F k . The support counting step typically accounts for 80% of the total computation time <ref> [30] </ref>. Our locality enhancement techniques are essentially geared towards improving the performance of this step. Optimized Candidate Search: In [30] we presented an optimization to speed up the subset counting phase. <p> The support counting step typically accounts for 80% of the total computation time <ref> [30] </ref>. Our locality enhancement techniques are essentially geared towards improving the performance of this step. Optimized Candidate Search: In [30] we presented an optimization to speed up the subset counting phase. It utilizes the fact that the subsequences of the transaction are generated in lexicographic order, to pre-empt the candidate search. <p> The algorithms minimize I/O overheads by scanning the local database portion only twice. Furthermore they have excellent locality since only simple intersection operations are used to compute the frequent itemsets. Shared Memory Machines: To the best of our knowledge the CCPD <ref> [30] </ref> algorithm is the only parallel algorithm targeting shared memory machines. In [30] we presented the parallel performance of CCPD, and also the benefits of optimizations like hash tree balancing, parallel candidate generation, and short-circuited subset checking. <p> Furthermore they have excellent locality since only simple intersection operations are used to compute the frequent itemsets. Shared Memory Machines: To the best of our knowledge the CCPD <ref> [30] </ref> algorithm is the only parallel algorithm targeting shared memory machines. In [30] we presented the parallel performance of CCPD, and also the benefits of optimizations like hash tree balancing, parallel candidate generation, and short-circuited subset checking.
Reference: [31] <author> M. J. Zaki, S. Parthasarathy, and W. Li. </author> <title> A localized algorithm for parallel association mining. </title> <booktitle> In 9th ACM Symp. Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: The PDM algorithm [25] presents a parallelization of the DHP algorithm [24]. However, PDM performs worse than Count Distribution [4]. In recent work we presented new parallel association mining algorithms [35]. They utilize the fast sequential algorithms proposed in <ref> [31, 33] </ref> as the base algorithm. The database is also selectively replicated among the processors so that the portion of the database needed for the computation of associations is local to each processor. After the initial set-up phase, the algorithms do not need any further communication or synchronization.
Reference: [32] <author> M. J. Zaki, S. Parthasarathy, W. Li, and M. Ogihara. </author> <title> Evaluation of sampling for data mining of association rules. </title> <booktitle> In 7th Intl. Wkshp. Research Issues in Data Engg, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: Another way to minimize the I/O overhead is to work with only a small random sample of the database. An analysis of the effectiveness of sampling for association mining was presented in <ref> [32] </ref>, and [27] presents an exact algorithm that finds all rules using sampling. We recently proposed new association mining algorithms that usually make only 3 scans [33, 34].
Reference: [33] <author> M. J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. </author> <title> New algorithms for fast discovery of association rules. </title> <booktitle> In 3rd Intl. Conf. on Knowledge Discovery and Data Mining, </booktitle> <month> August </month> <year> 1997. </year>
Reference-contexts: An analysis of the effectiveness of sampling for association mining was presented in [32], and [27] presents an exact algorithm that finds all rules using sampling. We recently proposed new association mining algorithms that usually make only 3 scans <ref> [33, 34] </ref>. They use novel itemset clustering techniques, based on equivalence classes and maximal hypergraph cliques, to approximate the set of potentially maximal frequent itemsets. Efficient lattice traversal techniques based on bottom-up and hybrid search, are then used to generate the frequent itemsets contained in each cluster. <p> The PDM algorithm [25] presents a parallelization of the DHP algorithm [24]. However, PDM performs worse than Count Distribution [4]. In recent work we presented new parallel association mining algorithms [35]. They utilize the fast sequential algorithms proposed in <ref> [31, 33] </ref> as the base algorithm. The database is also selectively replicated among the processors so that the portion of the database needed for the computation of associations is local to each processor. After the initial set-up phase, the algorithms do not need any further communication or synchronization.
Reference: [34] <author> M. J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. </author> <title> New algorithms for fast discovery of association rules. </title> <type> Technical Report URCS TR 651, </type> <institution> University of Rochester, </institution> <month> April </month> <year> 1997. </year>
Reference-contexts: An analysis of the effectiveness of sampling for association mining was presented in [32], and [27] presents an exact algorithm that finds all rules using sampling. We recently proposed new association mining algorithms that usually make only 3 scans <ref> [33, 34] </ref>. They use novel itemset clustering techniques, based on equivalence classes and maximal hypergraph cliques, to approximate the set of potentially maximal frequent itemsets. Efficient lattice traversal techniques based on bottom-up and hybrid search, are then used to generate the frequent itemsets contained in each cluster.
Reference: [35] <author> M. J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. </author> <title> New parallel algorithms for fast discovery of association rules. Data Mining and Knowledge Discovery: </title> <note> An International Journal, to appear, </note> <month> December </month> <year> 1997. </year> <month> 24 </month>
Reference-contexts: The PDM algorithm [25] presents a parallelization of the DHP algorithm [24]. However, PDM performs worse than Count Distribution [4]. In recent work we presented new parallel association mining algorithms <ref> [35] </ref>. They utilize the fast sequential algorithms proposed in [31, 33] as the base algorithm. The database is also selectively replicated among the processors so that the portion of the database needed for the computation of associations is local to each processor.
References-found: 35

