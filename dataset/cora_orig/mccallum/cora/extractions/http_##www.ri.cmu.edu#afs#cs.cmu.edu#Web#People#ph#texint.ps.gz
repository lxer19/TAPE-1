URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/Web/People/ph/texint.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/Web/People/ph/index.html
Root-URL: 
Title: Interpolation for Polygon Texture Mapping and Shading  
Author: Paul S. Heckbert Henry P. Moreton 
Keyword: Additional keywords: incremental, perspective, projective, affine.  
Address: Berkeley, CA 94720 USA  
Affiliation: Dept. of Electrical Engineering and Computer Sciences University of California,  
Abstract: A simple, fast method is presented for the interpolation of texture coordinates and shading parameters for polygons viewed in perspective. The method has application in scan conversion algorithms like z-buffer and painter's algorithms that perform screen space interpolation of shading parameters such as texture coordinates, colors, and normal vectors. Some previous methods perform linear interpolation in screen space, but this is rotationally variant, and in the case of texture mapping, causes a disturbing "rubber sheet" effect. To correctly compute the nonlinear, projective transformation between screen space and parameter space, we use rational linear interpolation across the polygon, performing several divisions at each pixel. We present simpler formulas for setting up these interpolation computations, reducing the setup cost per polygon to nil and reducing the cost per vertex to a handful of divisions. 
Abstract-found: 1
Intro-found: 1
Reference: [Blinn-Newell76] <author> James F. Blinn, Martin E. Newell, </author> <title> "Texture and Reflection in Computer Generated Images", </title> <journal> CACM, </journal> <volume> vol. 19, no. 10, </volume> <month> Oct. </month> <year> 1976, </year> <pages> pp. 542-547. </pages>
Reference-contexts: This set might include: texture coordinates (u; v) for texture mapping <ref> [Blinn-Newell76] </ref>, [Heckbert86], (r; g; b) for Gouraud shading, a normal vector for Phong shading, and world space position for per-pixel shading. Polygons are described by listing these parameter values along with the object space coordinates (x o ; y o ; z o ) at each vertex.
Reference: [Heckbert83] <author> Paul S. Heckbert, </author> <title> Texture Mapping Polygons in Perspective, </title> <journal> NYIT Computer Graphics Lab, </journal> <volume> TM 13, </volume> <month> Apr. </month> <year> 1983. </year>
Reference-contexts: applied a similar technique to texture mapping, showing that a divide was needed at each pixel [Smith80]. 3.1 Rational Linear Interpolation the Hard Way In previous work, the first author described incremental interpolation of texture coordinates with a per pixel cost of three additions, two divisions, and a texture access <ref> [Heckbert83] </ref>. Along each scanline, texture coordinate u has the form u (x) = (ax + b)=(cx + d), and v (x) is similar. The method employed for computing the homogeneous texture coordinates (uq; vq; q) at each vertex was quite involved, however [Heckbert89].
Reference: [Heckbert86] <author> Paul S. Heckbert, </author> <title> "Survey of Texture Mapping", </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> vol. 6, no. 11, </volume> <month> Nov. </month> <year> 1986, </year> <pages> pp. 56-67. </pages>
Reference-contexts: This set might include: texture coordinates (u; v) for texture mapping [Blinn-Newell76], <ref> [Heckbert86] </ref>, (r; g; b) for Gouraud shading, a normal vector for Phong shading, and world space position for per-pixel shading. Polygons are described by listing these parameter values along with the object space coordinates (x o ; y o ; z o ) at each vertex.
Reference: [Heckbert89] <author> Paul S. Heckbert, </author> <title> Fundamentals of Texture Mapping and Image Warping, </title> <type> Master's thesis, </type> <institution> UCB/CSD 89/516, CS Dept, UC Berkeley, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: Along each scanline, texture coordinate u has the form u (x) = (ax + b)=(cx + d), and v (x) is similar. The method employed for computing the homogeneous texture coordinates (uq; vq; q) at each vertex was quite involved, however <ref> [Heckbert89] </ref>. First, it required inference of the affine texture-to-object parameterization from the correspondence at three vertices of the polygon. This mapping was then concatenated with the object-to-screen mapping to arrive at the 3 fi 3 projective mapping matrix. <p> This generalization also allows perspective transformations to be used as modeling transformations in addition to camera transformations. The new method cannot be used when there is no 3-D information, as in image warping. In that case, warp inference techniques must be used <ref> [Heckbert89] </ref>. 3.5 New Algorithm The rational linear rendering algorithm is: (1) Associate a record containing the n parameters of interest (r 1 ; r 2 ; ; r n ) with each vertex of the polygon. (2) For each vertex, transform object space coordinates to homogeneous screen space using 4 fi
Reference: [Heckbert90] <author> Paul S. Heckbert, </author> <title> "Generic Convex Polygon Scan Conversion and Clipping", Graphics Gems, </title> <editor> Andrew Glassner, ed., </editor> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: C code for such a generic polygon clipper and scan converter is available in <ref> [Heckbert90] </ref>. 2.1 Flaws of Linear Interpolation Linear interpolation algorithms like the above are usually used for Gouraud shading, Phong shading, and often for texture mapping as well. It is wrong, however, to perform linear interpolation in screen space of parameters that are not screen-affine.
Reference: [Maxwell46] <author> E. A. Maxwell, </author> <title> The Methods of Plane Projective Geometry, Based on the Use of General Homogeneous Coordinates, </title> <publisher> Cambridge U. Press, </publisher> <address> London, </address> <year> 1946. </year>
Reference-contexts: It is related to world space by the camera parameters. Finally, 2-D screen space (or "screen space" for short) is the 2-D subspace of 3-D screen space without z. To facilitate affine and projective (perspective) transformations, we use homogeneous notation <ref> [Maxwell46] </ref> in which, for example, the 2-D real point (x; y) is represented by the 3-D homogeneous vector p = (xw; yw; w), where w is an arbitrary nonzero number. We will be cavalier about treating the case where w = 0. <p> The 3-D forms of these mappings are ubiquitous in computer graphics [Newman-Sproull76]. The 2-D projective mapping (or perspective mapping) from (u; v) to (x; y) has the general form <ref> [Maxwell46] </ref>: x = gu + hv + i du + ev + f The mapping is more simply represented in homogeneous matrix notation: ( xw yw w ) = ( uq vq q ) &gt; &gt; &gt; &gt; &gt; &gt; : b e h 9 Affine mappings include scales, rotations, translations,
Reference: [Newman-Sproull79] <author> William M. Newman, Robert F. Sproull, </author> <title> Principles of Interactive Computer Graphics (2nd ed.), </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1979. </year>
Reference: [Rogers85] <author> David F. Rogers, </author> <title> Procedural Elements for Computer Graphics, </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1985. </year> <month> 10 </month>
Reference-contexts: For example, in texture mapping, texture space is typically object-affine, but screen-projective. 2 Polygon Rendering with Linear Interpolation Scan conversion algorithms such as z-buffer, painter's, and scanline methods <ref> [Rogers85] </ref> typically use a set of interpolated shading parameters at each pixel. This set might include: texture coordinates (u; v) for texture mapping [Blinn-Newell76], [Heckbert86], (r; g; b) for Gouraud shading, a normal vector for Phong shading, and world space position for per-pixel shading.
Reference: [Smith80] <author> Alvy Ray Smith, </author> <title> "Incremental Rendering of Textures in Perspective", </title> <booktitle> SIG--GRAPH '80 Animation Graphics seminar notes, </booktitle> <month> July </month> <year> 1980. </year>
Reference-contexts: In previous work, Newman and Sproull found the rational linear formula relating a linear interpolation factor (between 0 and 1) for screen space to the interpolation factor for eye space [Newman-Sproull76 p.362]. Smith applied a similar technique to texture mapping, showing that a divide was needed at each pixel <ref> [Smith80] </ref>. 3.1 Rational Linear Interpolation the Hard Way In previous work, the first author described incremental interpolation of texture coordinates with a per pixel cost of three additions, two divisions, and a texture access [Heckbert83].
Reference: [Wolberg90] <author> George Wolberg, </author> <title> Digital Image Warping, </title> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1990. </year> <month> 11 </month>
Reference-contexts: The Silicon Graphics VGX machine currently does texture mapping this way. In figure 4 we can see how splitting a polygon into a number of smaller polygons improves the approximation. Others have approximated the nonlinear function with quadratic or cubic polynomials <ref> [Wolberg90] </ref>. But note that rational linear functions have poles (behaving like f (x) = 1=x) at the horizon of an infinite plane, near which they are not well approximated by linear functions or other polynomials. If subdivision is used, it should be adaptive.
References-found: 10

