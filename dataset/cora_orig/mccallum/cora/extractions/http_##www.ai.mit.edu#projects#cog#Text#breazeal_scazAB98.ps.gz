URL: http://www.ai.mit.edu/projects/cog/Text/breazeal_scazAB98.ps.gz
Refering-URL: http://www.ai.mit.edu/projects/cog/Text/publications.html
Root-URL: 
Email: email: ferrell@ai.mit.edu, scaz@ai.mit.edu  
Phone: (617) 253-7593  
Title: Infant-like Social Interactions between a Robot and a Human Caretaker  
Author: Cynthia Breazeal (Ferrell) Brian Scassellati 
Address: 545 Technology Square, Room 938 Cambridge, MA 02139 USA  
Affiliation: Massachusetts Institute of Technology Artificial Intelligence Laboratory  
Abstract-found: 0
Intro-found: 1
Reference: <author> Arkin, R. </author> <year> (1988), </year> <title> Homeostatic control for a mobile robot: dynamic replanning in hazardous environments, </title> <editor> in W. Wolfe, ed., </editor> <booktitle> `Mobile Robots III', SPIEThe International Society for Optical Engineering, </booktitle> <address> Bellingham, WA, </address> <pages> pp. 407413. </pages>
Reference: <author> Aslin, R. N. </author> <year> (1987), </year> <title> Visual and Auditory Development in Infancy., </title> <editor> in J. D. Osofksy, ed., </editor> <booktitle> `Handbook of infant development, 2nd Ed.', </booktitle> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: influence the behavior of the caretaker to maintain an interaction the robot can handle, learn from, and use to satisfy its drives. 5 Design of the Perceptual System Human infants discriminate readily between social stimuli (faces, voices, etc.) and salient non-social stimuli (brightly colored objects, loud noises, large motion, etc.) <ref> (Aslin 1987) </ref>. The perceptual system has been designed to discriminate a subset of both social and non-social stimuli from visual images. As a social stimulus detector, we have implemented a face detector that mimics some of the innate preferences that human infants have for face-like stimuli.
Reference: <author> Balch, R. & Arkin, R. </author> <year> (1994), </year> <title> `Communication in Reactive Multiagent Robotic Systems', </title> <booktitle> Autonomous Robots pp. </booktitle> <pages> 2752. </pages>
Reference: <author> Bates, J., Loyall, B. & Reilly, S. </author> <year> (1992), </year> <title> An architecture for action, emotion, and social behavior, </title> <type> Technical Report CMU-CS-92-144, </type> <address> CMU, Pittsburgh, PA. </address>
Reference-contexts: It is important that the caretaker find these expressive states compelling as argued in section 2. Certainly, the importance of emotions for believable interactions with artifical systems has already been argued by <ref> (Bates, Loyall & Reilly 1992, Cassell 1994, Perlin 1995) </ref>. Emotions also play an important role in learning during face-to-face exchanges with the caretaker, but we leave the details of this to another paper.
Reference: <author> Billard, A. & Dautenhahn, K. </author> <year> (1997), </year> <title> Grounding Communication in Situated, Social Robots, </title> <type> Technical Report UMCS-97-9-1, </type> <institution> University of Manchester. </institution>
Reference-contexts: 1 Introduction Social robotics has generally concentrated on the behavior of groups of robots performing behaviors such as flocking, foraging or dispersion (Mataric 1995, Balch & Arkin 1994) or on paired robot-robot interactions such as imitation <ref> (Billard & Dautenhahn 1997) </ref>. Our work focuses not on robot-robot interactions, but rather on the construction of robots that engage in meaningful social exchanges with humans.
Reference: <author> Blumberg, B. </author> <year> (1996), </year> <title> Old Tricks, New Dogs: Ethology and Interactive Creatures, </title> <type> PhD thesis, </type> <institution> MIT. </institution>
Reference-contexts: The overall system is implemented as an agent-based architecture similar to that of <ref> (Blumberg 1996, Maes 1990, Brooks 1986, Minsky 1988) </ref>. For this implementation, the basic computational process is modeled as a transducer. Each drive, emotion, behavior, percept, and facial expression is modeled as a separate transducer process specifically tailored for its role in the overall system architecture.
Reference: <author> Breazeal(Ferrell), C. </author> <year> (1998), </year> <title> A Motivational System for Regulating Human-Robot Interaction, </title> <booktitle> in `Proceedings of AAAI98'. </booktitle>
Reference: <author> Brooks, R. </author> <year> (1986), </year> <title> `A robust layered control system for a mobile robot', </title> <journal> IEEE Journal of Robotics and Automation RA-2, </journal> <volume> 253262. </volume>
Reference: <author> Brooks, R. A. </author> <year> (1991), </year> <title> Intelligence Without Reason, </title> <booktitle> in `Proceedings of the 1991 International Joint Conference on Artificial Intelligence', </booktitle> <pages> pp. 569595. </pages>
Reference-contexts: Subjects began looking directly at the camera and then rotated their head until the system failed to detect a face. Across three subjects, the average ranges were 30 degrees pitch, 30 degrees yaw, and 20 degrees roll. Quantitative analysis of behaving systems difficult, and often misleading <ref> (Brooks 1991) </ref>. Our system does not require a completely general-purpose face recognition engine. In a real-world environment, the caretaker is generally cooperative.
Reference: <author> Brooks, R. A., Ferrell, C., Irie, R., Kemp, C. C., Marjanovic, M., Scassellati, B. & Williamson, M. </author> <year> (1998), </year> <title> Alternative Essences of Intelligence, </title> <booktitle> in `Proceedings of the Fifteenth National Conference on Artificial Intelligence (AAAI-98)', </booktitle> <publisher> AAAI Press. </publisher>
Reference: <author> Bullowa, M. </author> <year> (1979), </year> <title> Before Speech: The Beginning of Interpersonal Communicaion, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, London. </address>
Reference-contexts: Specifically, the mode of social interaction is that of a caretaker-infant dyad where a human acts as the caretaker for the robot. An infant's emotions and drives play an important role in generating meaningful interactions with the caretaker <ref> (Bullowa 1979) </ref>. These interactions constitute learning episodes for new communication behaviors. In particular, the infant is strongly biased to learn communication skills that result in having the caretaker satisfy the infant's drives (Halliday 1975). <p> The mother reinforces the shared meaning of the cries by responding in consistent ways to the subtle variations. Evidence of this phenomena exists where mother-infant pairs develop communication protocols different from those of other mother-infant pairs <ref> (Bullowa 1979) </ref>. Combining these ideas one can design a robot that is biased to learn how its emotive acts influence the caretaker in order to satisfy its own drives. <p> This extreme self-regulation method allows the robot to restore all its drives by itself. A similar behavior is observed in infants; when they are in extreme distress, they may fall into a disturbed sleep <ref> (Bullowa 1979) </ref>. In the simplest case, each drive and its satiating consummatory behavior are connected as shown in figures 10, 11, and 12. Both the drive and the consummatory behavior are modeled as transducers where the output is simply the current activation energy.
Reference: <author> Carey, S. & Gelman, R. </author> <year> (1991), </year> <title> The Epigenesis of Mind, </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference-contexts: To build a believable creature, the attention system must also implement habituation effects. Infants respond strongly to novel stimuli, but soon habituate and respond less as familiarity increases <ref> (Carey & Gelman 1991) </ref>. This acts both to keep the infant from being continually fascinated with any single object and to force the caretaker to continually engage the infant with slightly new and interesting interactions. <p> Many experiments in developmental psychology have shown that infants show surprise when witnessing an unexpected or novel outcome to a familiar event <ref> (Carey & Gelman 1991) </ref>. Furthermore, parents use their infant's display of excitement or interest as cues to regulate their interaction with them (Wood et al. 1976). 7 DESIGN OF THE ATTENTION SYSTEM 16 In humans, four factors serve to elicit emotions: neurochemical, sensorimotor, motivational, and cognitive factors (Izard 1993).
Reference: <author> Cassell, J. </author> <year> (1994), </year> <title> Animated Conversation, </title> <booktitle> in `Proceedings of SIGGRAPH 94'. </booktitle>
Reference: <author> Chappell, P. & Sander, L. </author> <year> (1979), </year> <title> Mutual regulation of the neonatal-materal interactive process: context for the origins of communication, </title> <editor> in M. Bullowa, ed., </editor> <title> `Before Speech', </title> <publisher> Cambridge University Press, </publisher> <pages> pp. </pages> <year> 191206. </year>
Reference-contexts: As such, he responds to events in the world with expressive cues that his mother can read, interpret, and act upon. She interprets them as indicators of his internal state (how he feels and why), and modifies her actions to promote his well being <ref> (Tronick, Als & Adamson 1979, Chappell & Sander 1979) </ref>. For example, when he appears content she tends to maintain the current level of interaction, but when he appears disinterested she intensifies or changes the interaction to try to reengage him.
Reference: <author> Coombs, D. J. </author> <year> (1992), </year> <title> Real-Time Gaze Holding in Binocular Robot Vision, </title> <type> Technical Report TR415, </type> <institution> U. Rochester. </institution>
Reference: <author> Ekman, P. & Davidson, R. </author> <year> (1994), </year> <title> The Nature of Emotion: Fundamental Questions, </title> <publisher> Oxford University Press, </publisher> <address> New York. </address> <note> REFERENCES 26 Ekman, </note> <author> P. & Friesen, W. </author> <year> (1978), </year> <title> Facial Action Coding System: A Technique for the Measurement of Facial Movement, </title> <publisher> Consulting Psychologists Press, </publisher> <address> Palo Alto, CA. </address>
Reference-contexts: Emotions also play an important role in learning during face-to-face exchanges with the caretaker, but we leave the details of this to another paper. The organization and operation of the emotion subsystem is strongly inspired by various theories of emotions in humans <ref> (Ekman & Davidson 1994, Izard 1993) </ref>, and most closely resembles the framework presented in Velasquez (1996), as opposed to the cognitive assessment systems of Ortony, Clore & Collins (1988), Elliot (1992), or Reilly (1996). Kismet has several emotion processes.
Reference: <author> Elliot, C. D. </author> <year> (1992), </year> <title> The Affective Reasoner: A Process Model of Emotions in a Multi-Agent System, </title> <type> PhD thesis, </type> <institution> Institute for the Learning Sciences. </institution>
Reference: <author> Goldstein, E. B. </author> <year> (1989), </year> <title> Sensation and Perception, </title> <publisher> Wadsworth Publishing Company. </publisher>
Reference-contexts: However, infants have poor visual acuity which restricts their visual attention to about two feet away typically the distance to their mother's face when the infant is being held <ref> (Goldstein 1989) </ref>. 1 This choice of camera is a balance between the need for high resolution and the need for a wide low-acuity field of view. The active vision platform is attached to a parallel network of digital signal processors (Texas Instruments TMS320C40), as shown in figure 3.
Reference: <author> Halliday, M. </author> <year> (1975), </year> <title> Learning How to Mean: </title> <booktitle> Explorations in the Development of Language, </booktitle> <address> El-sevier, New York, NY. </address>
Reference-contexts: An infant's emotions and drives play an important role in generating meaningful interactions with the caretaker (Bullowa 1979). These interactions constitute learning episodes for new communication behaviors. In particular, the infant is strongly biased to learn communication skills that result in having the caretaker satisfy the infant's drives <ref> (Halliday 1975) </ref>. The infant's emotional responses provide important cues which the caretaker uses to assess how to satiate the infant's drives, and how to carefully regulate the complexity of the interaction. <p> In addition, during early interactions with his mother, an infant's motivations and emotional displays are critical in establishing the foundational context for learning episodes from which he can learn shared meanings of communicative acts <ref> (Halliday 1975) </ref>. During early face-to-face exchanges with his mother, an infant displays a wide assortment of emotive cues such as coos, smiles, waves, and kicks. At such an early age, the infant's basic needs, emotions, and emotive expressions are among the few things his mother thinks they share in common.
Reference: <author> Horn, B. K. P. </author> <year> (1986), </year> <title> Robot Vision, </title> <publisher> MIT Press. </publisher>
Reference-contexts: The filtered image is then segmented into bounding boxes of contiguous motion. The algorithm scans the filtered image, marking all locations which pass threshold with an identifying tag. Locations inherit tags from adjacent locations through a region grow-and-merge procedure <ref> (Horn 1986) </ref>. Once all locations above threshold have been tagged, the tags are sorted based on the number of image pixels that tag marks.
Reference: <author> Izard, C. </author> <year> (1993), </year> <title> Four Systems for Emotion Activation: </title> <journal> Cognitive and Noncognitive Processes, in `Psychological Review', </journal> <volume> Vol. 100, </volume> <pages> pp. 6890. </pages>
Reference-contexts: Furthermore, parents use their infant's display of excitement or interest as cues to regulate their interaction with them (Wood et al. 1976). 7 DESIGN OF THE ATTENTION SYSTEM 16 In humans, four factors serve to elicit emotions: neurochemical, sensorimotor, motivational, and cognitive factors <ref> (Izard 1993) </ref>. In this system, emphasis has been placed on how drives and other emotions contribute to a given emotion's level of activation. * Drives: Recall that each drive is partitioned into three regimes: homeostatic, overwhelmed or under-whelmed.
Reference: <author> Kaye, K. </author> <year> (1979), </year> <title> Thickening Thin Data: The Maternal Role in Developing Communication and Language, </title> <editor> in M. Bullowa, ed., </editor> <title> `Before Speech', </title> <publisher> Cambridge University Press, </publisher> <pages> pp. </pages> <year> 191206. </year>
Reference-contexts: Blumberg (1996) used motivations (called internal variables) in this way to implement operant conditioning so that human user could train an animated dog new tricks. 2.2 Regulating Interaction: An infant's motivations are vital to regulating social interactions with his mother <ref> (Kaye 1979) </ref>. Soon after birth, an infant is able to display a wide variety of facial expressions (Trevarthen 1979). As such, he responds to events in the world with expressive cues that his mother can read, interpret, and act upon.
Reference: <author> Lorenz, K. </author> <year> (1973), </year> <title> Foundations of Ethology, </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY. </address>
Reference-contexts: When an animal has a strong drive that it is trying to satisfy, it is primed to learn behaviors that directly act to satiate that drive. For this reason, it is much easier to train a hungry animal with a food reward than a satiated one <ref> (Lorenz 1973) </ref>. For a robot, an important function of the motivation system is to regulate behavior selection so that the observable behavior appears coherent, appropriately persistent, and relevant given the internal state of the robot and the external state of the environment. <p> Motivations establish the nature of a creature by defining its needs and influencing how and when it acts to satisfy them <ref> (Lorenz 1973, Tinbergen 1951) </ref>. The nature of this robot is to learn in a social environment. All drives, emotions, and behaviors are organized such that the robot is in a state of homeostatic balance when it is functioning adeptly and is in an environment that affords high learning potential. <p> Third, they provide a learning context; the robot learns skills that serve to satisfy its drives. The design of the robot's drives subsystem is heavily inspired by ethological views <ref> (Lorenz 1973, Tinbergen 1951) </ref>. One distinguishing feature of drives is their temporally cyclic behavior. That is, given no stimulation, a drive will tend to increase in intensity unless it is satiated. For instance, an animal's hunger level or need to sleep follows a cyclical pattern.
Reference: <author> Maes, P. </author> <year> (1990), </year> <title> `Learning Behavior Networks from Experience', </title> <publisher> ECAL90. </publisher>
Reference-contexts: The responsibility for this function falls largely under the drive system of the robot. Other work in autonomous agent research has used drives in a similar manner <ref> (Maes 1990, Arkin 1988, McFarland & Bosser 1993, Steels 1995) </ref>. Drives are also necessary for establishing the context for learning as well as providing a reinforcing signal.
Reference: <author> Mataric, M. </author> <year> (1995), </year> <title> `Issues and approaches in the design of collective autonomous agents', </title> <booktitle> Robotics and Autonomous Systems 16(24), </booktitle> <pages> 321331. </pages>
Reference-contexts: 1 Introduction Social robotics has generally concentrated on the behavior of groups of robots performing behaviors such as flocking, foraging or dispersion <ref> (Mataric 1995, Balch & Arkin 1994) </ref> or on paired robot-robot interactions such as imitation (Billard & Dautenhahn 1997). Our work focuses not on robot-robot interactions, but rather on the construction of robots that engage in meaningful social exchanges with humans.
Reference: <author> McFarland, D. & Bosser, T. </author> <year> (1993), </year> <title> Intelligent Behavior in Animals and Robots, </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA. </address>
Reference: <author> Milani, M. </author> <year> (1986), </year> <title> The Body Language and Emotion of Dogs, </title> <publisher> William Morrow and Company, </publisher> <address> New York, NY. </address>
Reference-contexts: The robot's facial features move analogously to how humans adjust their facial features to express different emotions (Ekman & Friesen 1978), and the robot's ears move analogously to how dogs to move theirs to express motivational state <ref> (Milani 1986) </ref>. The motor system is also responsible for implementing emotional overlays over the task based motor skills.
Reference: <author> Minsky, M. </author> <year> (1988), </year> <title> The Society of Mind, </title> <publisher> Simon & Schuster. </publisher>
Reference: <author> Newson, J. </author> <year> (1979), </year> <title> The growth of shared understandings between infant and caregiver, </title> <editor> in M. Bul-lowa, ed., </editor> <title> `Before Speech', </title> <publisher> Cambridge University Press, </publisher> <pages> pp. </pages> <year> 207222. </year>
Reference-contexts: Routine sequences of a predictable nature can be built up which serve as the basis of learning episodes <ref> (Newson 1979) </ref>. Furthermore, it provides a context of mutual expectations. For example, early cries of an infant elicit various care-giving responses from his mother depending upon how she initially interprets these cries and how the infant responds to her mothering acts.
Reference: <author> Niedenthal, P. & Kityama, S. </author> <year> (1994), </year> <title> The Heart's Eye: Emotional influences in Perception and Attention, </title> <publisher> Academic Press. </publisher>
Reference-contexts: The motivational system may bias the selection process, but does not alter the underlying raw saliency of a stimulus <ref> (Niedenthal & Kityama 1994) </ref>.
Reference: <author> Ortony, A., Clore, G. & Collins, A. </author> <year> (1988), </year> <title> The Cognitive Structure of Emotion, </title> <publisher> Cambridge University Press. </publisher>
Reference: <author> Perlin, K. </author> <year> (1995), </year> <title> `Real Time Responsive Animation with Personality', </title> <journal> IEEE Transactions on Visualization and Computer Graphics. </journal>
Reference: <author> Reilly, S. </author> <year> (1996), </year> <title> Believable Social and Emotional Agents, </title> <type> PhD thesis, </type> <institution> CMU School of Computer Science, </institution> <address> Pittsburgh, PA. </address>
Reference: <author> Rowley, H., Baluja, S. & Kanade, T. </author> <year> (1995), </year> <title> Human Face Detection in Visual Scenes, </title> <type> Technical Report CMU-CS-95-158, </type> <institution> Carnegie Mellon University. </institution> <note> REFERENCES 27 Scassellati, </note> <author> B. </author> <year> (1996), </year> <title> Mechanisms of Shared Attention for a Humanoid Robot, in `Embodied Cognition and Action: </title> <booktitle> Papers from the 1996 AAAI Fall Symposium', </booktitle> <publisher> AAAI Press. </publisher>
Reference: <author> Scassellati, B. </author> <year> (1998a), </year> <title> A Binocular, Foveated Active Vision System, </title> <type> Technical Report 1628, </type> <institution> MIT Artificial Intelligence Lab Memo. </institution>
Reference-contexts: It consists of an active stereo vision system (described in <ref> (Scassellati 1998a) </ref>) embellished with facial features for emotive expression. Currently, these facial features include eyebrows (each with two degrees-of-freedom: lift and arch), ears (each with two degrees-of-freedom: lift and rotate), eyelids (each with one degree of freedom: open/close), and a mouth (with one degree of freedom: open/close). <p> Additionally, we have implemented the hardware control for various motor skills, such as smooth pursuit tracking and saccadic eye movement <ref> (Scassellati 1998a) </ref>, but have yet to incorporate these skills into the behavior engine.
Reference: <author> Scassellati, B. </author> <year> (1998b), </year> <title> Finding Eyes and Faces with a Foveated Vision System, </title> <booktitle> in `Proceedings of the Fifteenth National Conference on Artificial Intelligence (AAAI-98)', </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: and sent to the 68332 network through the dual-ported RAM interface. 5.2 Perceiving Faces The face detection algorithm used here was initially implemented as part of a developmental program for building social skills based on detection of signals of shared attention such as eye direction, pointing gestures, and head position <ref> (Scassellati 1998b) </ref>. In that work, our choice of a face detection algorithm was based on three criteria. First, it must be a relatively simple computation that can be performed in real time. <p> By utilizing a pair of learned sensorimotor mappings, our system was capable of saccading to faces and extracting high resolution images of the eye on 94% of trials <ref> (Scassellati 1998b) </ref>. Figure 8 shows six of the faces detected from that set of trials. However, even this statistic was misleading, since the behavior of the overall system eventually corrected for trials where the first saccade missed the target.
Reference: <author> Scassellati, B. </author> <year> (1998c), </year> <title> Imitation and Mechanisms of Shared Attention: A Developmental Structure for Building Social Skills, </title> <type> Technical Report Technical Report 98-1-005, </type> <institution> University of Aizu, Aizu-Wakamatsu, </institution> <address> Japan. </address>
Reference: <author> Sharkey, P. M., Murray, D. W., Vandevelde, S., Reid, I. D. & McLauchlan, P. F. </author> <year> (1993), </year> <title> `A modular head/eye platform for real-time reactive vision', </title> <journal> Mechatronics Journal 3(4), </journal> <volume> 517535. </volume>
Reference-contexts: The robot is able to show expressions analogous to anger, fatigue, fear, disgust, excitement, happiness, interest, sadness, and surprise (shown in figure 2) which are easily interpreted by an untrained human observer. Similar to other active vision systems <ref> (Sharkey, Murray, Vandevelde, Reid & McLauchlan 1993, Coombs 1992) </ref>, there are three degrees of freedom; each eye has an independent vertical axis of rotation (pan) and the eyes share a joint horizontal axis of rotation (tilt).
Reference: <author> Sinha, P. </author> <year> (1994), </year> <title> `Object Recognition via Image Invariants: A Case Study', </title> <booktitle> Investigative Ophthalmology and Visual Science 35, </booktitle> <pages> 17351740. </pages>
Reference-contexts: Ratio templates also offer multiple levels of biological plausibility; templates can be either hand-coded or learned adaptively from qualitative image invariants <ref> (Sinha 1994) </ref>. A ratio template is composed of a number of regions and a number of relations, as shown in performed using a special set of comparison rules.
Reference: <author> Sinha, P. </author> <year> (1996), </year> <title> Perceiving and recognizing three-dimensional forms, </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology. </institution>
Reference-contexts: The ratio template algorithm was designed to detect frontal views of faces under varying lighting conditions, and is an extension of classical template approaches <ref> (Sinha 1996) </ref>.
Reference: <author> Sinha, P. </author> <year> (1997), </year> <type> Personal Communication, </type> <month> August, </month> <year> 1997. </year>
Reference: <author> Steels, L. </author> <year> (1995), </year> <title> `When are robots intelligent autonomous agents', </title> <booktitle> Robotics and Autonomous Systems 15(12), </booktitle> <pages> 39. </pages>
Reference: <author> Sung, K.-K. & Poggio, T. </author> <year> (1994), </year> <title> Example-based Learning for View-based Human Face Detection, </title> <type> Technical Report 1521, </type> <institution> MIT Artificial Intelligence Lab Memo. </institution>
Reference-contexts: The ratio template algorithm was designed to detect frontal views of faces under varying lighting conditions, and is an extension of classical template approaches (Sinha 1996). While other techniques handle rotational invariants more accurately <ref> (Sung & Poggio 1994) </ref> or provide better accuracy at the cost of greater computation (Turk & Pentland 1991, Rowley, Baluja & Kanade 1995), the simplicity of the ratio template algorithm allows us to operate in real time while detecting faces that are most likely to be engaged in social interactions.
Reference: <author> Tinbergen, N. </author> <year> (1951), </year> <title> The Study of Instinct, </title> <publisher> Oxford University Press, </publisher> <address> New York. </address>
Reference-contexts: For our purposes, we are interested in how they influence behavior selection, regulate social interactions, and promote learning in a social context. 2.1 Behavior Selection: In ethology, much of the work in motivation theory tries to explain how animals engage in appropriate behaviors at the appropriate time to promote survival <ref> (Tinbergen 1951, Lorenz 1973) </ref>. For animals, internal drives influence which behavior the animal pursues, for example, feeding, foraging, or sleeping. Furthermore, depending on the intensity of the drives, the same sensory stimulus may result in very different behavior.
Reference: <author> Trevarthen, C. </author> <year> (1979), </year> <title> Communication and cooperation in early infancy: a description of primary intersubjectivity, </title> <editor> in M. Bullowa, ed., </editor> <title> `Before Speech', </title> <publisher> Cambridge University Press, </publisher> <pages> pp. 321 348. </pages>
Reference-contexts: Soon after birth, an infant is able to display a wide variety of facial expressions <ref> (Trevarthen 1979) </ref>. As such, he responds to events in the world with expressive cues that his mother can read, interpret, and act upon.
Reference: <author> Triesman, A. </author> <year> (1986), </year> <title> `Features and Objects in Visual Processing', </title> <publisher> Scientific American 255, </publisher> <address> 114B 125. </address>
Reference: <author> Tronick, E., Als, H. & Adamson, L. </author> <year> (1979), </year> <title> Structure of early Face-to-Face Communicative Interactions, </title> <editor> in M. Bullowa, ed., </editor> <title> `Before Speech', </title> <publisher> Cambridge University Press, </publisher> <pages> pp. 349370. </pages>
Reference-contexts: As such, he responds to events in the world with expressive cues that his mother can read, interpret, and act upon. She interprets them as indicators of his internal state (how he feels and why), and modifies her actions to promote his well being <ref> (Tronick, Als & Adamson 1979, Chappell & Sander 1979) </ref>. For example, when he appears content she tends to maintain the current level of interaction, but when he appears disinterested she intensifies or changes the interaction to try to reengage him.
Reference: <author> Turk, M. & Pentland, A. </author> <year> (1991), </year> <title> `Eigenfaces for recognition', </title> <journal> Journal of Cognitive Neuroscience. </journal>
Reference-contexts: The ratio template algorithm was designed to detect frontal views of faces under varying lighting conditions, and is an extension of classical template approaches (Sinha 1996). While other techniques handle rotational invariants more accurately (Sung & Poggio 1994) or provide better accuracy at the cost of greater computation <ref> (Turk & Pentland 1991, Rowley, Baluja & Kanade 1995) </ref>, the simplicity of the ratio template algorithm allows us to operate in real time while detecting faces that are most likely to be engaged in social interactions.
Reference: <author> Velasquez, J. </author> <year> (1996), </year> <title> Cathexis, A Computational Model for the Generation of Emotions and their Influence in the Behavior of Autonomous Agents, </title> <type> Master's thesis, </type> <institution> MIT. </institution>

References-found: 49

