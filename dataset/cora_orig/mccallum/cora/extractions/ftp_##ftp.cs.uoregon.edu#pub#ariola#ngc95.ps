URL: ftp://ftp.cs.uoregon.edu/pub/ariola/ngc95.ps
Refering-URL: http://www.cs.uoregon.edu/~ariola/publications.html
Root-URL: http://www.cs.uoregon.edu
Title: Compilation of Concurrent Declarative Languages  
Author: Z. M. Ariola, B. C. Massey, M. Sami, and E. Tick 
Note: This report is an extended version of a paper appearing in the Proceedings of the ICOT/NSF Workshop on Parallel Logic Programming and its Programming Environments,  
Date: March 1994  March 1994.  
Address: CIS-TR-94-05  
Affiliation: University of Oregon  Department of Computer and Information Science University of Oregon  
Abstract: The plethora of concurrent declarative language families, each with subtly different semantics, makes the design and implementation of static analyses for these languages a demanding task. However, many of the languages share underlying structure, and if this structure can be exploited, static analysis techniques can be shared across language families. These techniques can thus provide a common kernel for the implementation of quality compilers for this entire language class. The purpose of this paper is to exploit the similarities of non-strict functional and concurrent logic languages in the design of a common intermediate language (CIL). The CIL is introduced incrementally, giving at each step the rationale for its extension. As an application, we present, in CIL form, some state-of-the-art static partitioning algorithms from the literature. This allows us to "uncover" the relative advantages and disadvantages of the analyses, and determine promising directions for improving static partitioning. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Z. M. Ariola. </author> <title> An Algebraic Approach to the Compilation and Operational Semantics of Functional Languages with I-Structures. </title> <type> PhD thesis, </type> <institution> Harvard University, </institution> <month> June </month> <year> 1992. </year>
Reference: [2] <author> Z. M. Ariola and Arvind. P-TAC: </author> <title> A Parallel Intermediate Language. </title> <booktitle> In Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 230-242. </pages> <address> London, </address> <publisher> ACM Press, </publisher> <month> September </month> <year> 1989. </year>
Reference: [3] <author> Z. M. Ariola and Arvind. </author> <title> A Syntactic Approach to Program Transformation. </title> <booktitle> In ACM SIGPLAN Symposium on Parallel Evaluation and Semantics Based Program Manipulation, </booktitle> <pages> pages 116-129, </pages> <address> New Haven, June 1991. </address> <publisher> Yale University, ACM Press. </publisher>
Reference: [4] <author> Z. M. Ariola and Arvind. </author> <title> Graph Rewriting Systems For Efficient Compilation. In Term Graph Rewriting: </title> <journal> Theory and Practice, </journal> <pages> pages 77-90. </pages> <publisher> John Wiley and Sons, </publisher> <year> 1993. </year>
Reference: [5] <author> Arvind, L. Augusston, J. Hicks, R. S. Nikhil, S. Peyton-Jones, J. Stoy, and W. Williams. pH: </author> <title> a Parallel Haskell. </title> <type> Technical report, </type> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, USA, </address> <month> September </month> <year> 1993. </year> <note> Unpublished. </note>
Reference: [6] <author> Arvind, R. S. Nikhil, and K. K. Pingali. I-Structures: </author> <title> Data Structures for Parallel Computing. In Workshop on Graph Reduction, </title> <booktitle> number 279 in Lecture Notes in Computer Science, </booktitle> <pages> pages 336-369, </pages> <address> Santa Fe, September/October 1986. </address> <publisher> Springer-Verlag. </publisher>
Reference: [7] <author> P. S. Barth, R. S. Nikhil, and Arvind. M-Structures: </author> <title> Extending a Parallel, Non-Strict, Functional Language with State. </title> <booktitle> In Conference on Functional Programming Languages and Computer Architecture, Lecture Notes in Computer Science, </booktitle> <pages> pages 538-568. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference: [8] <author> K. L. Clark and S. Gregory. </author> <title> PARLOG: Parallel Programming in Logic. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 8(1) </volume> <pages> 1-49, </pages> <month> January </month> <year> 1986. </year>
Reference: [9] <author> S. Coorg. </author> <title> Partitioning Non-strict Functional Languages, 1994. </title> <type> MIT Masters Thesis. Unpublished. </type>
Reference-contexts: The analysis we call AB analysis (after the sets A and B used in the analysis), proposed by Coorg <ref> [9] </ref>, is a modification of DD analysis which achieves better partitioning across recursive calls. <p> Thus syn-chronization is required for the input variables. In the case of liberal threads, synchronization may also be required for variables accessed inside the thread. This synchronization is achieved with a family of strict identity operators S n (after Coorg <ref> [9] </ref>). S n waits until all of its n arguments are defined, and then returns the arguments as its result. 7 4.2 DD (Demand-Dependence) Analysis The DD analysis technique proposed by Traub et al. [30] uses dependence and demand information to reduce modified forms of dataflow graphs. <p> Strictness analysis [32] deals with recursion using fixed-point iteration. The AB partitioning technique proposed by Coorg <ref> [9] </ref> attempts to alleviate this drawback of DD analysis by incorporating the recursion handling property of strictness analysis. 4.4.1 Paths The AB technique uses paths as a way of representing dependence-demand information. <p> In other words, any path corresponding to a computation which "might compute ?" is itself ?. This approximation is useful because it avoids nontermination of path analysis in recursive cases. For an algorithm to construct paths from a program, see Coorg <ref> [9] </ref>. 9 No granularity relations were assumed in this example. 18 f (A) ! f H = Select (L 0 ) + 1 ffL 0 gg x1 J = Select (I 0 ) + 2 ffI 0 gg x2 I M = g (A; H) f? 2 ; fAgg f? 2
Reference: [10] <author> I. Foster and S. Taylor. Strand: </author> <title> New Concepts in Parallel Programming. </title> <publisher> Prentice Hall, </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1989. </year>
Reference: [11] <author> J. E. Hoch, D. M. Davenport, V. G. Grafe, and K. M. Steele. </author> <title> Compile-Time Partitioning of a Non-Strict Language into Sequential Threads. </title> <booktitle> In Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 180-189. </pages> <address> Dallas, </address> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1991. </year>
Reference-contexts: logic variables, which can cause hidden cycles through aliasing. 4 Non-strict functional languages have analogous problems with hidden cycles through I-structures. 4 Aliasing occurs when two or more identifiers are simultaneously bound to the same variable 8 Several researchers have explored the problem of thread partitioning of non-strict functional languages <ref> [11, 16, 22, 23, 29] </ref>.
Reference: [12] <author> E. Horowitz and S. Sahni. </author> <title> Fundamentals of Data Structures. </title> <publisher> Computer Science Press, </publisher> <address> Woodland Hills, CA, </address> <year> 1976. </year>
Reference-contexts: Figure 16 shows the block-graph of the function f. Node 9 corresponds to the input variable A, while the other nodes correspond to the labeled terms shown in Figure 15. Some technique of converting a cyclic graph to a DAG is used, e.g., standard depth-first search <ref> [12] </ref>. For the function f, one partition of its graph contains the sets of nodes f1; 2; 4; 8; 9g and f3; 5; 6; 7g. This step, in which the call graph is transformed into two DAGs, matches the graph-coloring step of coloring analysis.
Reference: [13] <author> P. Hudak and B. Goldberg. </author> <title> Serial Combinators: Optimal Grains for Parallelism. </title> <booktitle> In Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 382-399, </pages> <address> Nancy, France, </address> <month> September </month> <year> 1985. </year> <note> Springer-Verlag. </note>
Reference-contexts: It was motivated by the serial combinator proposed as the grain for parallelism in the context of lazy graph reduction <ref> [13] </ref>, which uses both data dependence information and granularity information to build threads. In all of the analyses considered in this paper, individual clauses of a program are considered in isolation, i.e., partitions do not include more than one clause.
Reference: [14] <author> P. Hudak, S. Peyton-Jones, and P. Wadler. </author> <title> Report on Programming Language Haskell: A Non-Strict, Purely Functional Language, Version 1.2. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 27(5) </volume> <pages> 1-164, </pages> <month> May </month> <year> 1992. </year>
Reference: [15] <author> R. A. </author> <title> Iannucci. Toward a Dataflow/von Neumann Hybrid Architecture. </title> <booktitle> In International Symposium on Computer Architecture, </booktitle> <pages> pages 131-140. </pages> <address> Honolulu, </address> <publisher> IEEE Computer Society Press, </publisher> <month> May </month> <year> 1988. </year> <month> 26 </month>
Reference-contexts: By way of evaluation of our technique, and because it is important in its own right, we consider a particular static analysis example, that of partitioning or threading concurrent programs. A good partitioning strategy has to address several sometimes conflicting goals <ref> [15] </ref>. The thread length has to be maximized in order to decrease thread switches, decrease explicit synchronization, and increase pipeline utilization and locality. This however should not be at the expense of exploitable parallelism, as the objective of partitioning is to create threads containing little or no easily exploitable parallelism.
Reference: [16] <editor> R. A. Iannucci. </editor> <booktitle> Parallel Machine Languages. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: logic variables, which can cause hidden cycles through aliasing. 4 Non-strict functional languages have analogous problems with hidden cycles through I-structures. 4 Aliasing occurs when two or more identifiers are simultaneously bound to the same variable 8 Several researchers have explored the problem of thread partitioning of non-strict functional languages <ref> [11, 16, 22, 23, 29] </ref>.
Reference: [17] <author> A. King and P. Soper. </author> <title> Heuristics, Thresholding and a New Technique for Controlling the Granularity of Concurrent Logic Programs. </title> <type> Technical Report CSTR 92-08, </type> <institution> Department of Electronics and Computer Science, University of Southampton, </institution> <year> 1992. </year>
Reference-contexts: Higher granularity threads lead to lower process-creation, management, and communication overheads. However excessive sequentialization could be detrimental to performance, because useful parallelism may be lost. Unlike DD and AB analyses, coloring analysis attempts to control the granularity of the threads by performing a rather crude granularity analysis <ref> [17] </ref>. This is done by classifying terms as constant, linear, or non-linear depending upon the estimated cumulative difference between the growth of computation and communication during the execution lifespan. The constant class corresponds to terms which are builtins, or are defined in terms of constant terms. <p> In function f of the sample program, closure of dependencies create edges among nodes f1, 2, 3, 4, 7, 8g. Thus for instance &lt; 3; 4 &gt; 2 Separate f . Figure 13 illustrates Separate f . King and Soper <ref> [17] </ref> define a similar separation relation Granular c based on the granularity of terms, so that two sufficiently coarse-grained terms can be placed in different partitions. Their original analysis determined this relation by abstract interpretation over a coarse domain, and proved somewhat inaccurate.
Reference: [18] <author> A. King and P. Soper. </author> <title> Schedule Analysis: A Full Theory, A Pilot Implementation, And A Preliminary Assessment. </title> <type> Technical Report CSTR 92-06, </type> <institution> Department of Electronics and Computer Science, University of Southampton, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: Partitioning techniques have also been proposed in the context of granularity analysis for concurrent logic programming languages, most significant of which is the analysis proposed by King and Soper <ref> [18] </ref>, referred to in this paper as coloring analysis. This technique also uses global dependence information to produce partitions. Higher granularity threads lead to lower process-creation, management, and communication overheads. However excessive sequentialization could be detrimental to performance, because useful parallelism may be lost. <p> Although the CIL semantics does not guarantee sequential execution within each thread, sequential execution is acceptable. Certainly sequential code will be generated by most implementations, and the synchronization operators specify just that. 4.3 Coloring Analysis King and Soper's coloring analysis <ref> [18] </ref> is an example of a partitioning technique that was developed specifically for the family of concurrent logic programming languages. <p> Coloring analysis needs global information to infer the directionality of dataflow between variables. To obtain this information, we perform mode analysis during the translation of committed-choice logic programs to CIL programs (Section 3.1). King and Soper obtained this information by means of abstract interpretation <ref> [18] </ref>. In DD analysis, global analysis is performed during the actual partitioning step by propagating dependence information across function call boundaries.
Reference: [19] <author> A. King and P. Soper. </author> <title> Schedule Analysis of Concurrent Logic Programs. </title> <booktitle> In Joint International Conference and Symposium on Logic Programming, </booktitle> <pages> pages 478-492. </pages> <address> Washington D.C., </address> <publisher> MIT Press, </publisher> <month> November </month> <year> 1992. </year>
Reference-contexts: To turn a partition Partition c into threads, a total ordering is assigned to each Partition c;m , chosen not to contradict any data dependency in Depend c . This is done by topologically sorting each partition. This step is common to all the techniques discussed. King and Soper <ref> [19] </ref> describe a more general approach wherein a given partition can be split into subpartitions, creating more threads. They warn that if the subpartitions are split such that cycles are introduced in the data dependencies among the subpartitions, deadlock can occur.
Reference: [20] <author> G. Lindstrom. </author> <title> Functional Programming and the Logic Variable. </title> <booktitle> In SIGPLAN Symposium on Principles of Programming Languages, </booktitle> <pages> pages 266-280. </pages> <address> New Orleans, </address> <publisher> ACM Press, </publisher> <month> January </month> <year> 1985. </year>
Reference: [21] <author> R. S. Nikhil. </author> <title> Id (Version 90.0) Reference Manual. </title> <type> Technical Report CSG Memo 284-a, </type> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, USA, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: The predicate used to select a clause of a multiple-clause CIL function is encoded in the interface. A CIL program can be translated into this representation using a methodology similar to the one described by Nikhil <ref> [21] </ref>. Figure 7 shows the structured dataflow graph representation of the sample CIL program shown in Figure 6. The representation of function h is not given in Figure 7 due to space limitations. The vertices of the DAGs describing the basic blocks represent primitive operators, and edges indicate dependences.
Reference: [22] <author> R. S. Nikhil. </author> <title> A Multithreaded Implementation of Id Using P-RISC Graphs. </title> <booktitle> In Languages and Compilers for Parallel Computing. </booktitle> <address> Portland, </address> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1993. </year>
Reference-contexts: logic variables, which can cause hidden cycles through aliasing. 4 Non-strict functional languages have analogous problems with hidden cycles through I-structures. 4 Aliasing occurs when two or more identifiers are simultaneously bound to the same variable 8 Several researchers have explored the problem of thread partitioning of non-strict functional languages <ref> [11, 16, 22, 23, 29] </ref>.
Reference: [23] <author> K. E. Schauser, D. E. Culler, and T. von Eicken. </author> <title> Compiler-Controlled Multithreading for Lenient Parallel Languages. </title> <booktitle> In Conference on Functional Programming Languages and Computer Architecture, Lecture Notes in Computer Science, </booktitle> <pages> pages 50-72. </pages> <address> Cambridge MA., </address> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: logic variables, which can cause hidden cycles through aliasing. 4 Non-strict functional languages have analogous problems with hidden cycles through I-structures. 4 Aliasing occurs when two or more identifiers are simultaneously bound to the same variable 8 Several researchers have explored the problem of thread partitioning of non-strict functional languages <ref> [11, 16, 22, 23, 29] </ref>.
Reference: [24] <author> E. Y. Shapiro. </author> <title> The Family of Concurrent Logic Programming Languages. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(3) </volume> <pages> 413-510, </pages> <year> 1989. </year>
Reference: [25] <author> R. Sundararajan. </author> <title> Data Flow and Control Flow Analysis of Logic Programs. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Oregon, </institution> <year> 1994. </year> <note> Also available as Technical Report CIS-TR-94-08. </note>
Reference: [26] <author> Z. Symogyi. </author> <title> A System of Precise Modes for Logic Programs. </title> <booktitle> In International Conference on Logic Programming, </booktitle> <pages> pages 769-787. </pages> <publisher> University of Melbourne, MIT Press, </publisher> <month> May </month> <year> 1987. </year>
Reference: [27] <author> E. Tick. </author> <title> The Deevolution of Concurrent Logic Programming Languages. </title> <journal> Journal of Logic Programming, </journal> <volume> 22, </volume> <year> 1995. </year> <note> In Press. (Also available as University of Oregon Technical Report CIS-TR-94-07). </note>
Reference: [28] <author> E. Tick, B. C. Massey, F. Rakoczi, and P. Tulayathun. </author> <title> Concurrent Logic Programs a la Mode. </title> <editor> In E. Tick and G. Succi, editors, </editor> <booktitle> Implementations of Logic Programming Systems, </booktitle> <pages> pages 239-244. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference: [29] <author> K. R. Traub. </author> <title> Compilation as Partitioning: A New Approach to Compiling Non-Strict Functional Languages. </title> <booktitle> In Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 75-88, </pages> <address> London, </address> <month> September </month> <year> 1989. </year> <note> ACM Press. </note>
Reference-contexts: logic variables, which can cause hidden cycles through aliasing. 4 Non-strict functional languages have analogous problems with hidden cycles through I-structures. 4 Aliasing occurs when two or more identifiers are simultaneously bound to the same variable 8 Several researchers have explored the problem of thread partitioning of non-strict functional languages <ref> [11, 16, 22, 23, 29] </ref>.
Reference: [30] <author> K. R. Traub, D. E. Culler, and K. E. Schauser. </author> <title> Global Analysis for Partitioning Non-Strict Programs into Sequential Threads. </title> <booktitle> In Conference on Lisp and Functional Programming, </booktitle> <pages> pages 324-334, </pages> <address> San Francisco, 1992. </address> <publisher> ACM Press. </publisher> <pages> 27 </pages>
Reference-contexts: While most of the techniques produce threads within a function and in isolation from the rest of the program, the analysis of Traub et al. <ref> [30] </ref>, referred to in this paper as DD analysis, attempts to improve the thread size within a function by propagating global dependence information. <p> This synchronization is achieved with a family of strict identity operators S n (after Coorg [9]). S n waits until all of its n arguments are defined, and then returns the arguments as its result. 7 4.2 DD (Demand-Dependence) Analysis The DD analysis technique proposed by Traub et al. <ref> [30] </ref> uses dependence and demand information to reduce modified forms of dataflow graphs. Their partitioning technique is based on a greedy algorithm which attempts to make the threads as large as possible. <p> Nodes 1 and 2 of Figure 7 have been transformed in this way. Similarly, a Store command in the source CIL program is translated into an I-Store operator. Three forms of dependences are expressed in the graph representation: certain, indirect, and potential <ref> [30] </ref>. A certain dependence, indicated by a straight edge between two nodes, represents an ordering constraint due to a data dependence which holds for every invocation of the function. In represented by a squiggly edge, is a dependence completed through one or more vertices in a different basic block.
Reference: [31] <author> K. Ueda and M. Morita. </author> <title> Moded Flat GHC and Its Message-Oriented Implementation Technique. </title> <journal> New Generation Computing, </journal> <month> May </month> <year> 1994. </year>
Reference: [32] <author> P. Wadler. </author> <title> Strictness Analysis on Non-Flat Domains (by Abstract Interpretation Over Finite Domains). </title> <editor> In S. Abramsky and C. Hankin, editors, </editor> <booktitle> Abstract Interpretation of Declarative Languages, </booktitle> <pages> pages 181-198. </pages> <publisher> Ellis Horwood Ltd, </publisher> <address> Chichester, </address> <year> 1987. </year> <month> 28 </month>
Reference-contexts: However, this difference is due to the different types of threads produced by the analyses, as further discussed in Section 4.5. 4.4 AB (Above-Below) Analysis As was discussed in Section 4.2, DD partitioning technique does not handle recursion satisfactorily. Strictness analysis <ref> [32] </ref> deals with recursion using fixed-point iteration. The AB partitioning technique proposed by Coorg [9] attempts to alleviate this drawback of DD analysis by incorporating the recursion handling property of strictness analysis. 4.4.1 Paths The AB technique uses paths as a way of representing dependence-demand information.
References-found: 32

