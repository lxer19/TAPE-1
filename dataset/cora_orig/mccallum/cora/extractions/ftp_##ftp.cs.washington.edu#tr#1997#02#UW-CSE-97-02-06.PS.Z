URL: ftp://ftp.cs.washington.edu/tr/1997/02/UW-CSE-97-02-06.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-title.html
Root-URL: 
Title: A Percolating State Selector for Suffix-Tree Context Models 1 novel dynamic programming solution that does
Author: Suzanne Bunton 
Keyword: data compression, universal coding, on-line stochastic model ing, statistical inference, finite-state automata  
Web: niques.  
Note: a  tech  
Affiliation: Department of Computer Science and Engineering University of Washington  
Pubnum: Technical Report UW-CSE-97-02-06  
Abstract: This paper introduces into practice and empirically evaluates a set of techniques for performing information-theoretic state selection that have been developing in asymptotic results for over a decade. State selection, which actually implements the selection of an entire model from among a set of competing models, is performed at least trivially by all of the suffix-tree FSMs used for on-line probability estimation. The set of state-selection techniques presented here combines orthogonally with the other sets of design options covered in the companion papers, "A Generalization and Improvement to PPM's Blending," and, "An Executable Taxonomy of On-Line Modeling Algorithms," written by this author. The main results of this paper are: 1 A version of this paper appears in Proceedings of the DCC, March 1997. This report contains 
Abstract-found: 1
Intro-found: 1
Reference: [Bun96] <author> S. Bunton. </author> <title> On-Line Stochastic Processes in Data Compression. </title> <type> PhD thesis, </type> <institution> University of Washington, </institution> <month> December </month> <year> 1996. </year>
Reference-contexts: Thus, disabling update exclusion at the currently selected state is required when it is enabled globally for the modeling algorithm. The dual update mechanism introduced in <ref> [Bun96] </ref>, Chapter 5, provides this ability by maintaining both update-excluded and full-update frequencies at every state. 5 A Percolating State-Selection Mechanism 4 Here we present a dynamic-programming solution to the problem of finding the best--performing model frontier without resorting to hill-climbing or an order-bound. <p> (s) that is represented by s's children is incomplete because L (s) t:suffix (t)=s L (t) 6= fg: To complete s's context partition element, we maintain a "shadow child" of s that maintains a next-symbol frequency distribution that is conditioned by L (s) t:suffix (t)=s L (t): As explained in <ref> [Bun96] </ref>, Chapter 5, this is the same frequency distribution that is formed by the update-excluded frequency counts count [; s; 1] if maximum-order updates are globally enabled for the modeling algorithm. <p> = false): The quantity P e (a i js 0 ; update exclusion = u) equals a weighted sum of the inheritance I [a i js 0 ], and the maximum likelihood of a i given the frequencies count [b; s 0 ; u], 8b 2 A, as computed in <ref> [Bun96] </ref>, Chapter 6. 6 State Selection with Mixtures In general, an on-line modeling algorithm that uses convergent state selection will ignore the high-order descendants of a given node until the combined estimated probability distributions of those descendants have better performance, or lower entropy, than the frequency distribution at the given node. <p> The mixture-weighting formula (or escape mechanism) is D, while the inheritance evaluation time M 3 equals inherit before novel event updates. FSMX Model Topologies in f9 fl ; 64 fl g: The model is built using our suffix-tree construction algorithm <ref> [Bun96, Bun97c] </ref> (thus the fl ), to save space and time and to therefore make it possible to evaluate higher order models (i.e., orders 9 and 64) at a wide range of state selection thresholds in a reasonable time frame. <p> An unbounded-order model combined with the percolating state-election technique satisfies a primary goal of universal on-line modeling: eliminating model parameters that cannot be automatically deduced from the input sequence. 8 Conclusion Before we began the basis of this work in <ref> [Bun96] </ref>, there had been no published empirical studies of the performance of any information-theoretic state-selection technique, nor was the idea used in any published algorithm that had been implemented. <p> This paper also describes a major component of the or-thogonal sets of an executable cross-product taxonomy for on-line suffix-tree models of sequences, that we present in the companion paper [Bun97a]. We used our implementation of that cross product to present controlled experiments that conclusively demonstrate the principle hypothesis of <ref> [Bun96] </ref>: that the combination of information-theoretic state selection and mixtures is superior to either technique alone.
Reference: [Bun97a] <author> S. Bunton. </author> <title> An executable taxonomy of on-line modeling algorithms. </title> <booktitle> In Proceedings Data Compression Conference. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> March </month> <year> 1997. </year>
Reference-contexts: The set of state-selection techniques presented here combines orthogonally with the other sets of design options catalogued in the companion paper <ref> [Bun97a] </ref>. 1 Stochastic Complexity and On-Line Modeling The stochastic complexity of a string is the length of its optimal off-line encoding, that is, its Minimum Description Length, or MDL [Ris89]. <p> S 5 is top-down hill-climbing state selection. S 6 is bottom-up hill-climbing state selection. Probability Estimators in fAM 0 ; DM 3 Xg, where AM 0 denotes the degenerate mixture that produces an identical uniform prior for each state. In the language of <ref> [Bun97a] </ref>, it combines a constant uniform weighting function on the excited states (mixture-weighting formula A), and evaluates their inherited probabilities at model creation, denoted by the inheritance evaluation time M 0 . DM 3 X describes one of the better-performing mixtures from [Bun97b], combined with update exclusion (X). <p> This paper also describes a major component of the or-thogonal sets of an executable cross-product taxonomy for on-line suffix-tree models of sequences, that we present in the companion paper <ref> [Bun97a] </ref>. We used our implementation of that cross product to present controlled experiments that conclusively demonstrate the principle hypothesis of [Bun96]: that the combination of information-theoretic state selection and mixtures is superior to either technique alone.
Reference: [Bun97b] <author> S. Bunton. </author> <title> A generalization and improvement to PPM's blending. </title> <type> UW-CSE Technical Report UW-CSE-97-01-10, </type> <institution> The University of Washington, </institution> <month> January </month> <year> 1997. </year>
Reference-contexts: In the language of [Bun97a], it combines a constant uniform weighting function on the excited states (mixture-weighting formula A), and evaluates their inherited probabilities at model creation, denoted by the inheritance evaluation time M 0 . DM 3 X describes one of the better-performing mixtures from <ref> [Bun97b] </ref>, combined with update exclusion (X). The mixture-weighting formula (or escape mechanism) is D, while the inheritance evaluation time M 3 equals inherit before novel event updates.
Reference: [Bun97c] <author> S. Bunton. </author> <title> Semantically motivated improvements for PPM variants. </title> <journal> The British Computer Journal, Special Data Compression Issue, </journal> <note> 1997. (invited paper, to appear June 1997). </note>
Reference-contexts: The mixture-weighting formula (or escape mechanism) is D, while the inheritance evaluation time M 3 equals inherit before novel event updates. FSMX Model Topologies in f9 fl ; 64 fl g: The model is built using our suffix-tree construction algorithm <ref> [Bun96, Bun97c] </ref> (thus the fl ), to save space and time and to therefore make it possible to evaluate higher order models (i.e., orders 9 and 64) at a wide range of state selection thresholds in a reasonable time frame.
Reference: [CW84] <author> J. G. Cleary and I. H. Witten. </author> <title> A comparison of enumerative and adaptive codes. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 30(2) </volume> <pages> 306-315, </pages> <year> 1984. </year>
Reference-contexts: is not explicitly coded: the deterministic algorithm of the encoder is emulated by the decoder to deduce the state that was selected for coding without any side-information about the actual model. * In on-line modeling, the coding penalty is incorporated into the inaccurate probability estimates from early in the sequence <ref> [CW84] </ref>.
Reference: [Fur91] <author> G. Furlan. </author> <title> An enhancement to universal modeling algorithm `context' for real-time applications to image compression. </title> <booktitle> In IEEE Transactions on Acoustics Speech and Signal Processing, </booktitle> <pages> pages 2777-2780, </pages> <year> 1991. </year>
Reference-contexts: This means that a node must always be considered for selection along with its siblings. To select, for example, the excited state with the lowest expected codelength, or the minimum-order excited state whose expected codelength is better than that of its excited child (e.g., <ref> [Fur91] </ref>), is incorrect, not merely suboptimal. This is because the children of a state s (i.e., those nodes whose contexts correspond to minimal extensions of the state's context) may have better performance than the state s, even while the currently excited child of s has worse performance than s does.
Reference: [Ris83] <author> J. J. Rissanen. </author> <title> A universal data compression system. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 29(5) </volume> <pages> 656-664, </pages> <year> 1983. </year>
Reference-contexts: This report contains minor corrections to the DCC97 version. A Percolating State Selector for Suffix-Tree Context Models Suzanne Bunton The University of Washington This paper introduces into practice and empirically evaluates a set of techniques for information-theoretic state selection that have been developing in asymptotic results (e.g., <ref> [Ris83, Ris86, WLZ92] </ref>) for over a decade. State selection, which actually implements the selection of an entire model from among a set of competing models, is performed at least trivially by all of the suffix-tree FSMs used for on-line probability estimation. <p> Note that stochastic complexity assigns a coding penalty to each model state. The penalty is a lower bound on the number of bits required to encode that state. Most other treatments of the state-selection approach to on-line modeling (e.g., <ref> [Ris83, WLZ92] </ref>) require that a refinement (e.g., the children or deeper descendants) of a state be selected in preference to that state if the performance of that refinement improves the performance of the model frontier containing the original state by an amount exceeding the cost of encoding the states comprising the <p> Top-down, select the minimum order excited state for which no complete frontier of its subtree improves its expected codelength. 2 The first approach was introduced in <ref> [Ris83] </ref>, using entropies instead of MDLs, and then in [Ris86] using MDLs. As pointed out in [WLZ92], this technique systematically under-estimates the local order of the model; it is a hill-climbing technique that can get stuck in local minima.
Reference: [Ris86] <author> J. J. Rissanen. </author> <title> Complexity of strings in the class of Markov sources. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 32(4) </volume> <pages> 526-532, </pages> <year> 1986. </year>
Reference-contexts: This report contains minor corrections to the DCC97 version. A Percolating State Selector for Suffix-Tree Context Models Suzanne Bunton The University of Washington This paper introduces into practice and empirically evaluates a set of techniques for information-theoretic state selection that have been developing in asymptotic results (e.g., <ref> [Ris83, Ris86, WLZ92] </ref>) for over a decade. State selection, which actually implements the selection of an entire model from among a set of competing models, is performed at least trivially by all of the suffix-tree FSMs used for on-line probability estimation. <p> Top-down, select the minimum order excited state for which no complete frontier of its subtree improves its expected codelength. 2 The first approach was introduced in [Ris83], using entropies instead of MDLs, and then in <ref> [Ris86] </ref> using MDLs. As pointed out in [WLZ92], this technique systematically under-estimates the local order of the model; it is a hill-climbing technique that can get stuck in local minima. The second approach is introduced here as an obvious complement to the top-down hill-climbing approach, to complete the taxonomy.
Reference: [Ris89] <author> J. J. Rissanen. </author> <title> Stochastic Complexity in Statistical Inquiry. </title> <publisher> World Scientific Publishing, </publisher> <address> Singapore, </address> <year> 1989. </year>
Reference-contexts: The set of state-selection techniques presented here combines orthogonally with the other sets of design options catalogued in the companion paper [Bun97a]. 1 Stochastic Complexity and On-Line Modeling The stochastic complexity of a string is the length of its optimal off-line encoding, that is, its Minimum Description Length, or MDL <ref> [Ris89] </ref>. A string's MDL is the sum of the lengths of an encoding of a model plus the encoding of the string with respect to that model such that the total encoding length is minimal over all possible models within an assumed model class.
Reference: [WLZ92] <author> M. J. Weinberger, A. Lempel, and J. Ziv. </author> <title> A sequential algorithm for the universal coding of finite memory sources. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 38(3) </volume> <pages> 1002-1014, </pages> <year> 1992. </year>
Reference-contexts: This report contains minor corrections to the DCC97 version. A Percolating State Selector for Suffix-Tree Context Models Suzanne Bunton The University of Washington This paper introduces into practice and empirically evaluates a set of techniques for information-theoretic state selection that have been developing in asymptotic results (e.g., <ref> [Ris83, Ris86, WLZ92] </ref>) for over a decade. State selection, which actually implements the selection of an entire model from among a set of competing models, is performed at least trivially by all of the suffix-tree FSMs used for on-line probability estimation. <p> Note that stochastic complexity assigns a coding penalty to each model state. The penalty is a lower bound on the number of bits required to encode that state. Most other treatments of the state-selection approach to on-line modeling (e.g., <ref> [Ris83, WLZ92] </ref>) require that a refinement (e.g., the children or deeper descendants) of a state be selected in preference to that state if the performance of that refinement improves the performance of the model frontier containing the original state by an amount exceeding the cost of encoding the states comprising the <p> Top-down, select the minimum order excited state for which no complete frontier of its subtree improves its expected codelength. 2 The first approach was introduced in [Ris83], using entropies instead of MDLs, and then in [Ris86] using MDLs. As pointed out in <ref> [WLZ92] </ref>, this technique systematically under-estimates the local order of the model; it is a hill-climbing technique that can get stuck in local minima. The second approach is introduced here as an obvious complement to the top-down hill-climbing approach, to complete the taxonomy. It systematically over-estimates local order. <p> The reason that the hill-climbing approaches are suboptimal is that there may be a complete frontier below any given state's children that reduces the state's expected codelength, even though the children themselves do not. The authors of <ref> [WLZ92] </ref> present a formal, asymptotically convergent solution to the third approach that requires an order bound. In the next subsection, we describe our own solution, which requires no order bound and which allows efficient implementation.
References-found: 10

