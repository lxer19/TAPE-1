URL: http://www.daimi.aau.dk/~bromille/Papers/dich.ps
Refering-URL: http://www.daimi.aau.dk/~bromille/Papers/index.html
Root-URL: http://www.daimi.aau.dk
Email: Email Andrej.Brodnik@IMFM.Uni-Lj.SI.  Email bromille@brics.dk.  Email imunro@uwaterloo.ca.  
Phone: 3  
Title: Trans-dichotomous algorithms without multiplication some upper and lower bounds  
Author: Andrej Brodnik ? Peter Bro Miltersen ?? J. Ian Munro ??? 
Note: 2 BRICS, Centre of the Danish National Research Foundation,  
Address: Ljubljana, Slovenia and Lulea University, Lulea, Sweden.  Denmark.  Waterloo, Canada.  
Affiliation: 1 Institute of Mathematics, Physics and Mechanics,  University of Aarhus,  Department of Computer Science, University of  
Abstract: We show that on a RAM with addition, subtraction, bitwise Boolean operations and shifts, but no multiplication, there is a trans-dichotomous solution to the static dictionary problem using linear space and with query time p log n(log log n) 1+o(1) . On the way, we show that two w-bit words can be multiplied in time (log w) 1+o(1) and that time (log w) is necessary, and that fi(log log w) time is necessary and sufficient for identifying the least significant set bit of a word. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S. Albers and T. Hagerup. </author> <title> Improved parallel integer sorting without concurrent writting. </title> <booktitle> In 3 rd ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 463-472, </pages> <address> Orlando, Florida, </address> <year> 1992. </year>
Reference-contexts: Words are considered bit strings of length w. Note that when a word x is interpreted as an unsigned integer, the least significant bit is x [w] and the most significant bit is x <ref> [1] </ref>. This might be slightly confusing, but most often we view words as strings, rather than integers. If I = [i; j] = fi; i+1; : : : ; jg is an interval of bits, x [I] denotes x [i]x [i+1] : : : x [j]. <p> Proposition 2. Let m; m 0 be given, and let i 1 + i 2 + + i m = m 0 . Consider a map expand : f0; 1g m ! f0; 1g m 0 , defined by expand (x <ref> [1] </ref>x [2] : : :x [m]) = x [1] i 1 x [2] i 2 : : : x [m] i m : Then, expand (x) can be computed in time O (d (m + m 0 )=we log (m + m 0 )). Proof. <p> Let y = 1 i 1 0 i 2 1 i 3 : : : 1 i m1 0 i m . Now, compute z 1 = y and not [(y and x 0 ) + y)]; z = z 1 or z 2 Then z is x <ref> [1] </ref> i 1 x [2] i 2 : : : x [m] i m , as desired. Proposition 3. Let m 0 ; m be given. <p> Proposition 3. Let m 0 ; m be given. A monotone projection f : f0; 1g m ! f0; 1g m 0 is a map of the form f (x)[i] = ae (i), with ae (i) 2 f0; 1; x <ref> [1] </ref>; x [2]; : : :; x [m]g. Any monotone projection can be computed in time O (d (m 0 + m)=we log (m 0 +m)). Proof. Write the projection as a composition of an expansion, a permutation, and bitwise Boolean operations with masks, and use Propositions 1 and 2. <p> Simulating circuits in trans-dichotomous algorithms is not a new idea; indeed, the word merging algorithm of Albers and Hagerup <ref> [1] </ref> which is often used in trans-dichotomous algorithms is essentially a simulation of Batcher's bitonic merging network. Thorup, in his paper on sorting with the basic instruction set [21], shows a different simulation result: Theorem 7 (Thorup). Given a Boolean circuit C, mapping w bits to w bits. <p> The subroutine returns all of the m pairwise products stored in a bit string of length 2lm. Using the general circuit simulation lemma, we get Lemma 10. InterleavedMult (x; y; l; m) can be computed in time O ((log l) 3+o (1) ). a <ref> [1] </ref> b [1] z [1] a [l] b [l] z [l] a [1] b [1] z [1] where a = a fl A; b = b fl B; : : : ; z = z fl Z x = InterleavedMult (x; y; l; 26) = ... ....... ... ... ....... <p> The subroutine returns all of the m pairwise products stored in a bit string of length 2lm. Using the general circuit simulation lemma, we get Lemma 10. InterleavedMult (x; y; l; m) can be computed in time O ((log l) 3+o (1) ). a <ref> [1] </ref> b [1] z [1] a [l] b [l] z [l] a [1] b [1] z [1] where a = a fl A; b = b fl B; : : : ; z = z fl Z x = InterleavedMult (x; y; l; 26) = ... ....... ... ... ....... Fig. 1. <p> The subroutine returns all of the m pairwise products stored in a bit string of length 2lm. Using the general circuit simulation lemma, we get Lemma 10. InterleavedMult (x; y; l; m) can be computed in time O ((log l) 3+o (1) ). a <ref> [1] </ref> b [1] z [1] a [l] b [l] z [l] a [1] b [1] z [1] where a = a fl A; b = b fl B; : : : ; z = z fl Z x = InterleavedMult (x; y; l; 26) = ... ....... ... ... ....... Fig. 1. <p> Using the general circuit simulation lemma, we get Lemma 10. InterleavedMult (x; y; l; m) can be computed in time O ((log l) 3+o (1) ). a <ref> [1] </ref> b [1] z [1] a [l] b [l] z [l] a [1] b [1] z [1] where a = a fl A; b = b fl B; : : : ; z = z fl Z x = InterleavedMult (x; y; l; 26) = ... ....... ... ... ....... Fig. 1. <p> Using the general circuit simulation lemma, we get Lemma 10. InterleavedMult (x; y; l; m) can be computed in time O ((log l) 3+o (1) ). a <ref> [1] </ref> b [1] z [1] a [l] b [l] z [l] a [1] b [1] z [1] where a = a fl A; b = b fl B; : : : ; z = z fl Z x = InterleavedMult (x; y; l; 26) = ... ....... ... ... ....... Fig. 1. <p> Using the general circuit simulation lemma, we get Lemma 10. InterleavedMult (x; y; l; m) can be computed in time O ((log l) 3+o (1) ). a <ref> [1] </ref> b [1] z [1] a [l] b [l] z [l] a [1] b [1] z [1] where a = a fl A; b = b fl B; : : : ; z = z fl Z x = InterleavedMult (x; y; l; 26) = ... ....... ... ... ....... Fig. 1. <p> The lower bound for reverse follows a slightly different strategy. We consider reversing a subword of length b w; reverse (x <ref> [1] </ref>x [2] : : :x [b]) = x [b] : : : x [2]x [1]. Lemma 16. Let b w. A word circuit of size 1 10 log b correctly computes reverse on at most a 2 b 1=4 fraction of f0; 1g b . Proof. Let k = bb 1=3 c. Let a word circuit C be given.
Reference: 2. <author> A. Andersson. </author> <title> Sublogarithmic searching without multiplications. </title> <booktitle> In 36 th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 655-663, </pages> <year> 1995. </year>
Reference-contexts: However, in many architectures encountered in practice, multiplication is more expensive to perform than the basic operations mentioned above, so it seems natural to disallow it as a unit cost operation in our theoretical model. Indeed, this approach is taken in <ref> [2, 18, 21] </ref>, and we shall also take it here. Andersson et al [4] show that if only the basic instruction set is used, worst case query time ( p log n= log log n) is necessary. <p> Consider a fixed permutation on m symbols. Given a bit vector x [1]x <ref> [2] </ref> : : :x [m], we can compute its permutation perm (x) = x [(1)]x [(2)]x [(3)] : : :x [(m)] in time O (dm=we log m). Proof. Assume without loss of generality that m is a power of two. <p> Proposition 2. Let m; m 0 be given, and let i 1 + i 2 + + i m = m 0 . Consider a map expand : f0; 1g m ! f0; 1g m 0 , defined by expand (x [1]x <ref> [2] </ref> : : :x [m]) = x [1] i 1 x [2] i 2 : : : x [m] i m : Then, expand (x) can be computed in time O (d (m + m 0 )=we log (m + m 0 )). Proof. <p> Consider a map expand : f0; 1g m ! f0; 1g m 0 , defined by expand (x [1]x <ref> [2] </ref> : : :x [m]) = x [1] i 1 x [2] i 2 : : : x [m] i m : Then, expand (x) can be computed in time O (d (m + m 0 )=we log (m + m 0 )). Proof. <p> We also assume that m is even. First compute, using Proposition 1, x 0 = perm (x0 m 0 m ) = 0 i 1 1 x [1]0 i 2 1 x <ref> [2] </ref> : : : 0 i m 1 x [m] in time O (dm 0 =we log m 0 ). Let y = 1 i 1 0 i 2 1 i 3 : : : 1 i m1 0 i m . <p> Now, compute z 1 = y and not [(y and x 0 ) + y)]; z = z 1 or z 2 Then z is x [1] i 1 x <ref> [2] </ref> i 2 : : : x [m] i m , as desired. Proposition 3. Let m 0 ; m be given. <p> Proposition 3. Let m 0 ; m be given. A monotone projection f : f0; 1g m ! f0; 1g m 0 is a map of the form f (x)[i] = ae (i), with ae (i) 2 f0; 1; x [1]; x <ref> [2] </ref>; : : :; x [m]g. Any monotone projection can be computed in time O (d (m 0 + m)=we log (m 0 +m)). Proof. Write the projection as a composition of an expansion, a permutation, and bitwise Boolean operations with masks, and use Propositions 1 and 2. Lemma 4. <p> If we find the position and add r 1, we are done. 4. Make a bit string x 00 containing j = dlog se consecutive copies of x 0 . This can be done in time O (log s) = O (log log w) <ref> [2] </ref>. The bit string x 00 can be stored in 2 words, so we can operate on it with unit cost. 5. To avoid cumbersome notation, the next step is most easily explained by example. Suppose that w = 64, then s = 11 and j = 4. <p> The search time is O ((t + 1)(log log n) 1+o (1) ) p log n (log log n) 1+o (1) , as desired. In the second case, we store the reduced elements in a packed B-tree of degree D b (log n) t c, following Andersson <ref> [2] </ref>. In Andersson's paper, it was shown how to search a packed B-tree in time O (log D n) using the basic RAM instruction set. <p> Then, there is a bit string v with the following properties: - v has length 3w and will be indexed v [w] : : : v [1]v [1]v <ref> [2] </ref> : : :v [2w], so when we do a bitwise and with v and a word, only the middle part of v will matter. - v has Hamming weight at most 2 s k For any i between 0 and w k, if x varies, but the value of x <p> By Lemma 14, we find a large subset of U t for which the second argument is the same and we are done. The lower bound for reverse follows a slightly different strategy. We consider reversing a subword of length b w; reverse (x [1]x <ref> [2] </ref> : : :x [b]) = x [b] : : : x [2]x [1]. Lemma 16. Let b w. A word circuit of size 1 10 log b correctly computes reverse on at most a 2 b 1=4 fraction of f0; 1g b . Proof.
Reference: 3. <author> A. Andersson, T. Hagerup, S. Nilsson, and R. Raman. </author> <booktitle> Sorting in linear time? In 27 th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 427-436, </pages> <address> Las Vegas, Nevada, </address> <year> 1995. </year>
Reference-contexts: Remarks: Gerth Brodal (personal communication) has noted that a slight modification of the above algorithm can also be used to find the most significant set bit of a word. When multiplication is allowed, both operations can be done in constant time <ref> [13, 7, 3] </ref>. 3 The static dictionary problem We shall use the subroutine u InterleavedMult (x; y; l; m).
Reference: 4. <author> A. Andersson, P.B. Miltersen, S. Riis, and M. </author> <title> Thorup. Static dictionaries on AC 0 RAMs: Query time fi( p log n log log n) is necessary and sufficient. </title> <booktitle> In 37 th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 538-546, </pages> <address> Burlington, Ver-mont, </address> <year> 1996. </year>
Reference-contexts: Indeed, this approach is taken in [2, 18, 21], and we shall also take it here. Andersson et al <ref> [4] </ref> show that if only the basic instruction set is used, worst case query time ( p log n= log log n) is necessary. <p> This leaves only a (log log n) 1+o (1) gap to the lower bound. The technique is basically a variation of the technique of Andersson et al <ref> [4] </ref>, combining range reduction with packed B-trees. <p> As mentioned in the introduction, a lower bound for the static dictionary problem itself is shown in <ref> [4] </ref>. Note that since the problems only involve O (1) words, they can be solved in constant time if a precomputed array containing a table of the function is allowed, but this table will be very large.
Reference: 5. <author> A.M. Ben-Amram and Z. Galil. </author> <booktitle> When can we sort in o(n log n) time? In 34 th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 538-546, </pages> <address> Palo Alto, California, </address> <year> 1993. </year>
Reference-contexts: We cannot afford to compute these constants at run-time, so we assume that they have been determined and hard-wired into the algorithm at compile-time. Following the terminology of Ben-Amram and Galil <ref> [5] </ref>, such solutions are called weakly non-uniform. Fredman and Willard's fusion tree [13] is another example of a weakly non-uniform algorithm. We do not consider weak non-uniformity as a serious deficiency of the algorithms; computing useful constants at compile-time is hardly an esoteric phenomenon.
Reference: 6. <author> G.S. Brodal. </author> <title> Predecessor queries in dynamic integer sets. </title> <booktitle> In Proceedings 10 th Symposium on Theoretical Aspects of Computer Science. </booktitle> <pages> Springer-Verlag, </pages> <note> 1997 (To appear). </note>
Reference: 7. <author> A. Brodnik. </author> <title> Computation of the least significant set bit. </title> <booktitle> In Proceedings Elec-trotechnical and Computer Science Conference, </booktitle> <volume> volume B, </volume> <pages> pages 7-10, </pages> <address> Portoroz, Slovenia, </address> <year> 1993. </year>
Reference-contexts: Remarks: Gerth Brodal (personal communication) has noted that a slight modification of the above algorithm can also be used to find the most significant set bit of a word. When multiplication is allowed, both operations can be done in constant time <ref> [13, 7, 3] </ref>. 3 The static dictionary problem We shall use the subroutine u InterleavedMult (x; y; l; m).
Reference: 8. <author> A. Brodnik and J.I. Munro. </author> <title> Membership in a constant time and a minimum space. </title> <booktitle> In Proceedings 2 nd European Symposium on Algorithms, volume 855 of Lecture Notes in Computer Science, </booktitle> <pages> pages 72-81. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: It is well known that if the computational instructions also include multipli-cation, the static dictionary problem can be solved using only O (1) query time [12, 11] and even in space within an additive low order term of the information theoretic minimum <ref> [8] </ref>. However, in many architectures encountered in practice, multiplication is more expensive to perform than the basic operations mentioned above, so it seems natural to disallow it as a unit cost operation in our theoretical model. <p> We now clearly have a data structure of size n + o (n). The search time is t (log log n) 1+o (1) + O ( log ((log n) t ) q as desired. Remark: Combining the above techniques with techniques of the first and third author <ref> [8] </ref>, it is possible to improve the space bound in Theorem 13 to B + o (B) bits, where B is the information theoretic minimum log 2 w , in the case where we only want to test membership and not retrieve associated information. 4 Lower bounds In this section, we
Reference: 9. <author> A. Brodnik and J.I. Munro. </author> <title> Neighbours on a grid. </title> <booktitle> In Proceedings 5 th Scandina-vian Workshop on Algorithm Theory, volume 1097 of Lecture Notes in Computer Science, </booktitle> <pages> pages 307-320. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference: 10. <author> J.L. Carter and M.N. Wegman. </author> <title> Universal classes of hash functions. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 18(2) </volume> <pages> 143-154, </pages> <month> April </month> <year> 1979. </year>
Reference-contexts: In general, if we are given a set S of size n taken from some universe, and a family of nearly universal hash functions mapping the universe to a set of size n 2 , some member of the family will be injective on S <ref> [10] </ref>.
Reference: 11. <author> M. Dietzfelbinger, T. Hagerup, J. Katajainen, and M. Penttonen. </author> <title> A reliable randomized algorithm for the closest-pair problem. </title> <type> Technical Report 513, </type> <institution> Fachbereich Informatik, Universitat Dortmund, </institution> <address> Dortmund, Germany, </address> <year> 1993. </year>
Reference-contexts: It is well known that if the computational instructions also include multipli-cation, the static dictionary problem can be solved using only O (1) query time <ref> [12, 11] </ref> and even in space within an additive low order term of the information theoretic minimum [8]. <p> Proof. We shall use the following fact, due to Dietzfelbinger et al <ref> [11] </ref>: The class of hash functions H k;l = fh a : f0; : : :; 2 k 1g ! f0; : : :; 2 l 1gj0 &lt; a &lt; 2 k and a oddg given by h a (x) = (ax mod 2 k ) div 2 kl is nearly
Reference: 12. <author> M.L. Fredman, J. Komlos, and E. Szemeredi. </author> <title> Storing a sparse table with O(1) worst case access time. </title> <journal> Journal of the ACM, </journal> <volume> 31(3) </volume> <pages> 538-544, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: It is well known that if the computational instructions also include multipli-cation, the static dictionary problem can be solved using only O (1) query time <ref> [12, 11] </ref> and even in space within an additive low order term of the information theoretic minimum [8]. <p> In the first case, we store the reduced elements in a two level hash table, following Fredman, Komlos, and Szemeredi <ref> [12] </ref>, except that we use the hash function of Dietzfelbinger et al (the analysis of [12] goes through for any nearly universal family). The multiplicative hash function can be evaluated using lemma 6, using time (log log n) 1+o (1) . <p> In the first case, we store the reduced elements in a two level hash table, following Fredman, Komlos, and Szemeredi <ref> [12] </ref>, except that we use the hash function of Dietzfelbinger et al (the analysis of [12] goes through for any nearly universal family). The multiplicative hash function can be evaluated using lemma 6, using time (log log n) 1+o (1) . The search time is O ((t + 1)(log log n) 1+o (1) ) p log n (log log n) 1+o (1) , as desired.
Reference: 13. <author> M.L. Fredman and D.E. Willard. </author> <title> Surpassing the information theoretic bound with fusion trees. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 47 </volume> <pages> 424-436, </pages> <year> 1993. </year>
Reference-contexts: We cannot afford to compute these constants at run-time, so we assume that they have been determined and hard-wired into the algorithm at compile-time. Following the terminology of Ben-Amram and Galil [5], such solutions are called weakly non-uniform. Fredman and Willard's fusion tree <ref> [13] </ref> is another example of a weakly non-uniform algorithm. We do not consider weak non-uniformity as a serious deficiency of the algorithms; computing useful constants at compile-time is hardly an esoteric phenomenon. <p> Remarks: Gerth Brodal (personal communication) has noted that a slight modification of the above algorithm can also be used to find the most significant set bit of a word. When multiplication is allowed, both operations can be done in constant time <ref> [13, 7, 3] </ref>. 3 The static dictionary problem We shall use the subroutine u InterleavedMult (x; y; l; m). <p> The second step gathers the bits together again. We use a result of Fredman and Willard <ref> [13] </ref> that guarantees that if y is a word with set bits on equidistant positions only, then for some w constants a and b, the expression ((a fl y) and b) # w gathers these bits together on the least significant positions in a word in the same order as they
Reference: 14. <author> M.L. Fredman and D.E. Willard. </author> <title> Trans-dichotomous algorithms for minimum spanning trees and shortest paths. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 48(3) </volume> <pages> 533-551, </pages> <month> June </month> <year> 1994. </year>
Reference: 15. <author> M. Furst, J.B. Saxe, and M. Sipser. </author> <title> Parity, circuits, and the polynomial-time hierarchy. </title> <journal> Mathematical Systems Theory, </journal> <volume> 17(1) </volume> <pages> 13-27, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: This lower bound is also valid under extended computational instruction sets, as long as all instructions can be computed by AC 0 circuits (multiplication can not <ref> [15] </ref>). Andersson et al show that a matching upper bound O ( p log n= log log n) can be obtained, if various exotic AC 0 instructions (clustering functions and cluster busters) are allowed.
Reference: 16. <author> J. Hastad. </author> <title> Almost optimal lower bounds for small depth circuits. </title> <booktitle> In 18 th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 6-20, </pages> <address> Berkeley, California, </address> <year> 1986. </year>
Reference-contexts: Proof. Combine Lemma 18 and Theorem 17. It is interesting to note that the following somewhat weaker lower bound follows more or less directly from Hastad's size-depth tradeoff for unbounded fan-in circuits computing multiplication <ref> [16] </ref>: time (log w= log log w) is necessary, even if a precomputed table of size w O (1) is allowed. This is not the case for the other two lower bounds, as reverse and least significant bit are AC 0 functions.
Reference: 17. <author> P.B. Miltersen. </author> <title> Lower bounds for static dictionaries on RAMs with bit operations but no multiplication. </title> <booktitle> In Proceedings 23 rd International Colloquium on Automata, Languages and Programming, volume 1099 of Lecture Notes in Computer Science, </booktitle> <pages> pages 442-451. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: The lower bounds hold, even if a precomputed table of size O (2 w * ) for a small constant * &gt; 0 is allowed. Our lower bound technique is essentially an extension of the locality-technique of <ref> [17] </ref>. The existence of a static dictionary with sublogarithmic query time on a RAM with the basic instruction set disproves a conjecture of the second author [17]. <p> Our lower bound technique is essentially an extension of the locality-technique of <ref> [17] </ref>. The existence of a static dictionary with sublogarithmic query time on a RAM with the basic instruction set disproves a conjecture of the second author [17].
Reference: 18. <author> R. Raman. </author> <title> Priority queues: Small, monotone, </title> <booktitle> and trans-dichotomus. In Proceedings 4 th European Symposium on Algorithms, volume 1136 of Lecture Notes in Computer Science, </booktitle> <pages> pages 121-137. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: However, in many architectures encountered in practice, multiplication is more expensive to perform than the basic operations mentioned above, so it seems natural to disallow it as a unit cost operation in our theoretical model. Indeed, this approach is taken in <ref> [2, 18, 21] </ref>, and we shall also take it here. Andersson et al [4] show that if only the basic instruction set is used, worst case query time ( p log n= log log n) is necessary.
Reference: 19. <author> A. Schonhage and V. </author> <title> Strassen. </title> <journal> Schnelle Multiplikation groer Zahlen. Computing, </journal> <volume> 7 </volume> <pages> 281-292, </pages> <year> 1971. </year>
Reference-contexts: Finally, we compute a last projection. Total time is O (ds=wed log s). Corollary 5. Multiplying two w-bit words can be done in time (log w) 3+o (1) . Proof. Apply Lemma 4 to Schonhage and Strassen's multiplication circuit <ref> [19] </ref> of size w (log w)(log log w) and depth (log w)(log log w). Since multiplication is of primary importance, we want to optimize the above corollary a bit. Using the general circuit simulation algorithm is a bit of an overkill.
Reference: 20. <author> M. </author> <title> Thorup. On RAM priority queues. </title> <booktitle> In 7 th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 59-67, </pages> <address> Atlanta, Georgia, </address> <year> 1996. </year>
Reference: 21. <author> M. </author> <title> Thorup. Randomized sorting in O(n log log n) time and linear space using addition, shift, and bit-wise boolean operations. </title> <booktitle> In 8 th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 352-359, </pages> <address> New Orleans, Louisiana, </address> <year> 1997. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: However, in many architectures encountered in practice, multiplication is more expensive to perform than the basic operations mentioned above, so it seems natural to disallow it as a unit cost operation in our theoretical model. Indeed, this approach is taken in <ref> [2, 18, 21] </ref>, and we shall also take it here. Andersson et al [4] show that if only the basic instruction set is used, worst case query time ( p log n= log log n) is necessary. <p> Simulating circuits in trans-dichotomous algorithms is not a new idea; indeed, the word merging algorithm of Albers and Hagerup [1] which is often used in trans-dichotomous algorithms is essentially a simulation of Batcher's bitonic merging network. Thorup, in his paper on sorting with the basic instruction set <ref> [21] </ref>, shows a different simulation result: Theorem 7 (Thorup). Given a Boolean circuit C, mapping w bits to w bits. Suppose w instances x 1 , x 2 , : : : , x w are given. <p> However, Thorup <ref> [21] </ref> has found an application for such a BlockMult subroutine. We are now ready for the main theorem of this section. Theorem 13.
References-found: 21

