URL: http://http.cs.berkeley.edu/~soumen/vldb97.ps
Refering-URL: http://http.cs.berkeley.edu/~soumen/pub.html
Root-URL: http://www.cs.berkeley.edu
Title: Using taxonomy, discriminants, and signatures for navigating in text databases  
Author: Soumen Chakrabarti Byron Dom Rakesh Agrawal Prabhakar Raghavan 
Affiliation: IBM Almaden Research Center  
Abstract: We explore how to organize a text database hierarchically to aid better searching and browsing. We propose to exploit the natural hierarchy of topics, or taxonomy, that many corpora, such as internet directories, digital libraries, and patent databases enjoy. In our system, the user navigates through the query response not as a flat unstructured list, but embedded in the familiar taxonomy, and annotated with document signatures computed dynamically with respect to where the user is located at any time. We show how to update such databases with new documents with high speed and accuracy. We use techniques from statistical pattern recognition to efficiently separate the feature words or discriminants from the noise words at each node of the taxonomy. Using these, we build a multi-level classifier. At each node, this classifier can ignore the large number of noise words in a document. Thus the classifier has a small model size and is very fast. However, owing to the use of context-sensitive features, the classifier is very accurate. We report on experiences with the Reuters newswire benchmark, the US Patent database, and web document samples from Yahoo!.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Anick and S. Vaithyanathan. </author> <title> Exploiting clustering and phrases for context-based information retrieval. </title> <booktitle> In SIGIR, </booktitle> <year> 1997. </year>
Reference-contexts: These signatures can also be used as summaries or thumbnails; their descriptive power can often compare favorably with that of arbitrary sentences as extracted by popular search engines. They are also effective for describing a document cluster <ref> [1] </ref>. We claim that the common notion of a document abstract or signature as a function of the document 7 http://www.altavista.digital.com/av/lt/help.html alone is of limited utility.
Reference: [2] <author> C. Apte, F. Damerau, and S. M. Weiss. </author> <title> Automated learning of decision rules for text categorization. </title> <journal> ACM Transactions on Information Systems, </journal> <note> 1994. IBM Research Report RC18879. </note>
Reference-contexts: We only considered classes with at least 20 training documents. Only 30 classes were large enough, giving a 30 fi 30 confusion matrix. The best accuracy was achieved using about 8000 features. The best microav-eraged recall/precision is 0:87, which compares favorably with previous experiments <ref> [2] </ref>, although those studies used the (c; c) style classifiers. The numbers are not therefore directly comparable, although since very few documents had multiple topics, we expect similar results had the earlier experiments used only the single-topic documents. For this benchmark there is no benefit from hierarchy. <p> For such classifiers, feature sets larger than 100 are considered extremely large. Document classification may require more than 50,000. Impressive accuracy has been obtained using decision rules induction on the Reuters dataset <ref> [2] </ref>. They 10 http://www.verity.com 11 http://www.oracle.com/products/oracle7/ oracle7.3/html/context qa.html learn boolean formulas involving the presence or ab-sence of terms in documents, after pruning a static stopword set and picking the most frequent terms from each class as features.
Reference: [3] <author> J. O. Berger. </author> <title> Statistical Decision Theory and Bayesian Analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York; Berlin, </address> <year> 1985. </year> <note> ISBN: 0-387-96098-8. </note>
Reference-contexts: Data mining, machine learning, and pattern recognition. More recent work on text includes statistical modeling of documents, clustering and classification, thesaurus generation by term associations, and query expansion [31, 10, 34]. The supervised classification problem has been addressed in statistical decision theory (both classical [35] and Bayesian <ref> [3] </ref>), statistical pattern recognition [9, 12] and machine learning [36, 23, 19]. Classifier can be parametric or non-parametric. Two well-known classes of non-parametric classifiers are decision trees, such as CART [4] and C4.5 [25], and neural networks [14, 22, 15].
Reference: [4] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth & Brooks/Cole, </publisher> <year> 1984. </year> <note> ISBN: 0-534-98054-6. </note>
Reference-contexts: The supervised classification problem has been addressed in statistical decision theory (both classical [35] and Bayesian [3]), statistical pattern recognition [9, 12] and machine learning [36, 23, 19]. Classifier can be parametric or non-parametric. Two well-known classes of non-parametric classifiers are decision trees, such as CART <ref> [4] </ref> and C4.5 [25], and neural networks [14, 22, 15]. For such classifiers, feature sets larger than 100 are considered extremely large. Document classification may require more than 50,000. Impressive accuracy has been obtained using decision rules induction on the Reuters dataset [2].
Reference: [5] <author> C. Chekuri, M. Goldwasser, P. Raghavan, and E. Upfal. </author> <title> Web search using automatic classification. </title> <note> Submitted for publication, </note> <year> 1996. </year>
Reference-contexts: As we shall show, taxonomies provide a means for designing vastly enhanced searching, browsing and filtering systems. They can be used to relieve the user from the burden of sifting specific information from the large and low-quality response of most popular search engines <ref> [5, 26] </ref>. Querying with respect to a taxonomy is more reliable than depending on presence or absence of specific keywords. <p> Such queries routinely suffer from the abundance problem: there are many aspects to, and even different interpretations of the keywords typed. Most of these are unlikely to be useful. Consider the wildlife researcher asking AltaVista 6 the query jaguar speed <ref> [5] </ref>. A bewildering variety of responses emerge, spanning the car, the Atari video game, the football team, and a LAN server, in no particular order. The first page about the animal is ranked 183, and is a fable. Thwarted, we try jaguar speed -car -auto.
Reference: [6] <author> T. M. Cover and J. A. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> John Wiley and Sons, Inc., </publisher> <year> 1991. </year>
Reference-contexts: One of the best known is mutual information <ref> [6] </ref>. Closer inspection shows that its computation is more complicated and not as easily amenable to the optimizations described next. 3.4.2 Selecting a cut-off Let F be the list of terms in our lexicon sorted by decreasing Fisher index.
Reference: [7] <author> D. R. Cutting, D. R. Karger, and J. O. Pedersen. </author> <title> Constant interaction-time scatter/gather browsing of very large document collections. </title> <booktitle> In SIGIR, </booktitle> <year> 1993. </year>
Reference-contexts: We deviate from these systems in the paradigm of interactive exploration and dynamic reorganization of query response based on user context. A closely related work with respect to the user interface is Scatter-Gather <ref> [7] </ref>, which alternates between the system presenting a document cluster and a user selecting a subset from them. Topic paths in the taxonomy have some advantages: they can be precomputed and queried upon, and the path annotations (as in Yahoo!) are often more informative than "cluster digests" generated automatically.
Reference: [8] <author> S. Deerwester, S. T. Dumais, T. K. Landauer, G. W. Furnas, and R. A. Harshman. </author> <title> Indexing by latent semantic analysis. </title> <journal> Journal of the Society for Information Science, </journal> <volume> 41(6) </volume> <pages> 391-407, </pages> <year> 1990. </year>
Reference-contexts: Singular value decomposition on the term-document matrix has been found to cluster semantically related documents together even if they do not share keywords <ref> [8, 24] </ref>. We deviate from these systems in the paradigm of interactive exploration and dynamic reorganization of query response based on user context.
Reference: [9] <author> R. Duda and P. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: More recent work on text includes statistical modeling of documents, clustering and classification, thesaurus generation by term associations, and query expansion [31, 10, 34]. The supervised classification problem has been addressed in statistical decision theory (both classical [35] and Bayesian [3]), statistical pattern recognition <ref> [9, 12] </ref> and machine learning [36, 23, 19]. Classifier can be parametric or non-parametric. Two well-known classes of non-parametric classifiers are decision trees, such as CART [4] and C4.5 [25], and neural networks [14, 22, 15]. For such classifiers, feature sets larger than 100 are considered extremely large.
Reference: [10] <author> C. Falaoutsos and D. W. Oard. </author> <title> A survey of information retrieval and filtering methods. </title> <type> Technical Report CS-TR-3514, </type> <institution> University of Maryland, College Park, MD 20742, </institution> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Data mining, machine learning, and pattern recognition. More recent work on text includes statistical modeling of documents, clustering and classification, thesaurus generation by term associations, and query expansion <ref> [31, 10, 34] </ref>. The supervised classification problem has been addressed in statistical decision theory (both classical [35] and Bayesian [3]), statistical pattern recognition [9, 12] and machine learning [36, 23, 19]. Classifier can be parametric or non-parametric.
Reference: [11] <author> W. B. Frakes and R. Baeza-Yates. </author> <title> Information retrieval: Data structures and algorithms. </title> <publisher> Prentice-Hall, </publisher> <year> 1992. </year>
Reference-contexts: are also those successfully integrated into commercial text search systems such as Verity 10 , ConText 11 and AltaVista, involve processing at a relatively syntactic level; e.g., stopword filtering, tokeniz-ing, stemming, building inverted indices, computing heuristic term weights, and computing similarity measures between documents and queries in the vector-space model <ref> [33, 30, 11] </ref>. Singular value decomposition on the term-document matrix has been found to cluster semantically related documents together even if they do not share keywords [8, 24]. We deviate from these systems in the paradigm of interactive exploration and dynamic reorganization of query response based on user context.
Reference: [12] <author> K. Fukunaga. </author> <title> An Introduction to Statistical Pattern Recognition, 2nd ed. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: More recent work on text includes statistical modeling of documents, clustering and classification, thesaurus generation by term associations, and query expansion [31, 10, 34]. The supervised classification problem has been addressed in statistical decision theory (both classical [35] and Bayesian [3]), statistical pattern recognition <ref> [9, 12] </ref> and machine learning [36, 23, 19]. Classifier can be parametric or non-parametric. Two well-known classes of non-parametric classifiers are decision trees, such as CART [4] and C4.5 [25], and neural networks [14, 22, 15]. For such classifiers, feature sets larger than 100 are considered extremely large.
Reference: [13] <author> D. Harman. </author> <title> Ranking algorithms. </title> <editor> In W. B. Frakes and R. Baeza-Yates, editors, </editor> <booktitle> Information retrieval: Data structures and algorithms, chapter 14. </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1992. </year>
Reference-contexts: The similarity between two vectors is their cosine. Weighting the terms usually results in better relevance ranking. There are over 287 variants of term weighting schemes with tuned magic constants reported [29]. We pick one version recommended by Sparck-Jones <ref> [13, 16] </ref>. n max (d) = max t2d n (d; t) m = number of classes n t = c sign (n (c; t)) w (c; t) = (1 + n max (d) )(1 + lg m Score (c; d) = ~x d ~w c Class name 329 332 343 379
Reference: [14] <author> D. R. Hush and B. G. </author> <title> Horne. Progress in supervised neural networks. </title> <journal> IEEE Signal Processing Magazine, </journal> <pages> pages 8-39, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Classifier can be parametric or non-parametric. Two well-known classes of non-parametric classifiers are decision trees, such as CART [4] and C4.5 [25], and neural networks <ref> [14, 22, 15] </ref>. For such classifiers, feature sets larger than 100 are considered extremely large. Document classification may require more than 50,000. Impressive accuracy has been obtained using decision rules induction on the Reuters dataset [2].
Reference: [15] <author> A. K. Jain, J. Mao, and K. Mohiuddin. </author> <title> Artificial neural networks: A tutorial. </title> <journal> Computer, </journal> <volume> 29(3) </volume> <pages> 31-44, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: Classifier can be parametric or non-parametric. Two well-known classes of non-parametric classifiers are decision trees, such as CART [4] and C4.5 [25], and neural networks <ref> [14, 22, 15] </ref>. For such classifiers, feature sets larger than 100 are considered extremely large. Document classification may require more than 50,000. Impressive accuracy has been obtained using decision rules induction on the Reuters dataset [2].
Reference: [16] <author> K. S. Jones. </author> <title> A statistical interpretation of term specificity and its applications in retrieval. </title> <journal> Journal of Documentation, </journal> <volume> 28(1) </volume> <pages> 11-20, </pages> <year> 1972. </year>
Reference-contexts: The similarity between two vectors is their cosine. Weighting the terms usually results in better relevance ranking. There are over 287 variants of term weighting schemes with tuned magic constants reported [29]. We pick one version recommended by Sparck-Jones <ref> [13, 16] </ref>. n max (d) = max t2d n (d; t) m = number of classes n t = c sign (n (c; t)) w (c; t) = (1 + n max (d) )(1 + lg m Score (c; d) = ~x d ~w c Class name 329 332 343 379
Reference: [17] <author> D. Koller and M. Sahami. </author> <title> Toward optimal feature selection. </title> <editor> In L. Saitta, editor, </editor> <booktitle> International Conference on Machine Learning, </booktitle> <volume> volume 13. </volume> <publisher> Morgan-Kaufmann, </publisher> <year> 1996. </year>
Reference-contexts: The learning algorithm does cut down this set further, but needs computation to do so. More advanced heuristics have been proposed <ref> [17] </ref>. For virtually all of these approaches, the complexity in the number of features is supralinear (e.g., quadratic in the number of starting features and exponential in the degree of dependence between features), which makes their use difficult for large numbers of features and gigabyte-sized corpora.
Reference: [18] <author> D. Koller and M. Sahami. </author> <title> Hierarchically classifying documents using very few words. </title> <booktitle> In International Conference on Machine Learning, </booktitle> <volume> volume 14. </volume> <publisher> Morgan-Kaufmann, </publisher> <month> July </month> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: Together with feature selection, we have to pick models for each class and a classifier. Many options have been evaluated [31]. In spite of its simplicity, naive Bayesian classifiers are often almost as accurate as more sophisticated classifiers <ref> [18] </ref>. For a fixed number of features, naive Bayes is faster than more complex classifiers. However, to approach the latter in accuracy, naive Bayes typically needs many more features. Finding feature terms for each node mitigates this problem. <p> The benefit may be lost if an error is made early in the process <ref> [18] </ref>. Thus a greedy search for the best leaf may be risky. Let the path to a leaf c from the root be c 1 ; c 2 ; : : : ; c k = c. <p> As a result, these advanced methods have been typically restricted to under a thousand features and documents <ref> [18] </ref>; however, that work does add evidence that exploiting taxonomies is a valuable strategy. 6 Conclusion We have demonstrated that hierarchical views of text databases can improve search and navigation in many ways, and presented some of the tools needed to maintain and navigate in such a database.
Reference: [19] <author> P. Langley. </author> <title> Elements of Machine Learning. </title> <publisher> Morgan Kauf-mann, </publisher> <year> 1996. </year> <note> ISBN: 1-55860-301-8. </note>
Reference-contexts: More recent work on text includes statistical modeling of documents, clustering and classification, thesaurus generation by term associations, and query expansion [31, 10, 34]. The supervised classification problem has been addressed in statistical decision theory (both classical [35] and Bayesian [3]), statistical pattern recognition [9, 12] and machine learning <ref> [36, 23, 19] </ref>. Classifier can be parametric or non-parametric. Two well-known classes of non-parametric classifiers are decision trees, such as CART [4] and C4.5 [25], and neural networks [14, 22, 15]. For such classifiers, feature sets larger than 100 are considered extremely large. Document classification may require more than 50,000.
Reference: [20] <author> P.-S. </author> <title> Laplace. Philosophical Essays on Probabilities. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1995. </year> <title> Translated by A. I. Dale from the 5th French edition of 1825. </title>
Reference-contexts: tosses of a k-sided coin, i.e., the number of times each face occurred, n 1 ; : : : ; n k , the correct Bayesian estimate for the probability of face i, denoted Pr L (ijfn i g; n), is not n i =n, but n i +1 n+k <ref> [20] </ref>. This is the result of assuming that all possible associated k-component vectors of face probabilities (p 1 ; : : : ; p k ) are a priori equally likely. This is called the uniform prior assumption.
Reference: [21] <author> D. Lewis. </author> <title> Evaluating text categorization. </title> <booktitle> In Proceedings of the Speech and Natural Language Workshop, </booktitle> <pages> pages 312-318. </pages> <publisher> Morgan-Kaufmann, </publisher> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: If each document has exactly one class, this number is the same as microav-eraged recall and precision as defined by Lewis <ref> [21] </ref>. Matters are complicated by documents having multiple classes. Due to space constraint we omit our experiments with this setting. See Lewis for more details on evaluating classifiers [21]. 4.2 Evaluation of feature selection Although Reuters has provided a taxonomy for its articles, the data available does not include taxonomy codes <p> If each document has exactly one class, this number is the same as microav-eraged recall and precision as defined by Lewis <ref> [21] </ref>. Matters are complicated by documents having multiple classes. Due to space constraint we omit our experiments with this setting. See Lewis for more details on evaluating classifiers [21]. 4.2 Evaluation of feature selection Although Reuters has provided a taxonomy for its articles, the data available does not include taxonomy codes in the class header. For this subsection we will work with other corpora where such information is explicitly provided.
Reference: [22] <author> R. P. Lippmann. </author> <title> Pattern classification using neural networks. </title> <journal> IEEE Communications Magazine, </journal> <pages> pages 47-64, </pages> <month> Nov. </month> <year> 1989. </year>
Reference-contexts: Classifier can be parametric or non-parametric. Two well-known classes of non-parametric classifiers are decision trees, such as CART [4] and C4.5 [25], and neural networks <ref> [14, 22, 15] </ref>. For such classifiers, feature sets larger than 100 are considered extremely large. Document classification may require more than 50,000. Impressive accuracy has been obtained using decision rules induction on the Reuters dataset [2].
Reference: [23] <author> B. K. Natarajan. </author> <title> Machine Learning: A Theoretical Approach. </title> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: More recent work on text includes statistical modeling of documents, clustering and classification, thesaurus generation by term associations, and query expansion [31, 10, 34]. The supervised classification problem has been addressed in statistical decision theory (both classical [35] and Bayesian [3]), statistical pattern recognition [9, 12] and machine learning <ref> [36, 23, 19] </ref>. Classifier can be parametric or non-parametric. Two well-known classes of non-parametric classifiers are decision trees, such as CART [4] and C4.5 [25], and neural networks [14, 22, 15]. For such classifiers, feature sets larger than 100 are considered extremely large. Document classification may require more than 50,000.
Reference: [24] <author> C. Papadimitriou, P. Raghavan, H. Tamaki, and S. Vempala. </author> <title> Latent sematic indexing: A probabilistic analysis. </title> <note> Submitted for publication. </note>
Reference-contexts: Singular value decomposition on the term-document matrix has been found to cluster semantically related documents together even if they do not share keywords <ref> [8, 24] </ref>. We deviate from these systems in the paradigm of interactive exploration and dynamic reorganization of query response based on user context.
Reference: [25] <author> J. R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: The supervised classification problem has been addressed in statistical decision theory (both classical [35] and Bayesian [3]), statistical pattern recognition [9, 12] and machine learning [36, 23, 19]. Classifier can be parametric or non-parametric. Two well-known classes of non-parametric classifiers are decision trees, such as CART [4] and C4.5 <ref> [25] </ref>, and neural networks [14, 22, 15]. For such classifiers, feature sets larger than 100 are considered extremely large. Document classification may require more than 50,000. Impressive accuracy has been obtained using decision rules induction on the Reuters dataset [2].
Reference: [26] <author> P. Raghavan. </author> <title> Information retrieval algorithms: A survey. </title> <booktitle> In Symposium on Discrete Algorithms. ACM-SIAM, </booktitle> <year> 1997. </year> <type> Invited paper. </type>
Reference-contexts: As we shall show, taxonomies provide a means for designing vastly enhanced searching, browsing and filtering systems. They can be used to relieve the user from the burden of sifting specific information from the large and low-quality response of most popular search engines <ref> [5, 26] </ref>. Querying with respect to a taxonomy is more reliable than depending on presence or absence of specific keywords. <p> This issue looms large in searching using categories and clusters. In hierarchical categories, the importance of a search term depends on the position in the hierarchy <ref> [26] </ref>. We will later design an efficient algorithm to find, for each node in the taxonomy, the terms that are best suited for classifying documents to the next level of the taxonomy. Conversely, we detect the noise words that are of little help to distinguish the documents.
Reference: [27] <author> E. S. Ristad. </author> <title> A natural law of succession. </title> <institution> Research report CS-TR-495-95, Princeton University, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: capable of capturing the full meaning of text, hence our approach is a pragmatic one: to pick a model appro priate for the task at hand. 3.2 Rare events and laws of succession The average English speaker uses about 20,000 of the 1,000,000 or more terms in an English dictionary <ref> [27] </ref>. In that sense, many terms that occur in documents are "rare events." This means that with reasonably small sample sets, we will see zero occurrences of many, many terms, and will still be required to estimate a non-zero value of f (c; t). <p> Alternative priors have been suggested and justified. We experimented with many of these, and found that Laplace's law wins by a few percent better classification accuracy all the time. For lack of space, we refer the reader to Ristad's paper for details <ref> [27] </ref>. With these adjustment, (and returning to our earlier notation) f (c; t) is estimated as (1 + n (c; t))=(n (c) + L (c)), where L (c) is the size of the lexicon of class c. 3.3 Hierarchical classification A classifier inputs a document and outputs a class.
Reference: [28] <author> S. E. Robertson and S. Walker. </author> <title> Some simple effective approximations to the 2-Poisson model for probabilistic weighted retrieval. </title> <booktitle> In SIGIR, </booktitle> <pages> pages 232-241, </pages> <year> 1994. </year>
Reference-contexts: One of the earliest indicators of the power of simple statistical tests on term frequencies is Zipf's law [38]. The models most frequently used in the IR community are Poisson and Poisson mixtures <ref> [28, 33] </ref>. (If X is distributed Poisson with rate , denoted X ~ P (), then Pr [X = x] = e x =x! and if Y is distributed Bernoulli with n trials and mean np, denoted Y ~ B (n; p), then Pr [Y = y] = n y p
Reference: [29] <author> G. Salton and C. Buckley. </author> <title> Term-weighting approaches in automatic text retrieval. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 24(5) </volume> <pages> 513-523, </pages> <year> 1988. </year>
Reference-contexts: First we ensure that the training set is adequate. To do this, we train using different sized random samples from the training set and verify that the test performance converges. This is shown in Table 1. Next we compare the hierarchical classifier with a standard vector-space <ref> [29] </ref> based classifier. Each document is a vector in term space; each class is the sum or centroid of its document vectors. The similarity between two vectors is their cosine. Weighting the terms usually results in better relevance ranking. <p> The similarity between two vectors is their cosine. Weighting the terms usually results in better relevance ranking. There are over 287 variants of term weighting schemes with tuned magic constants reported <ref> [29] </ref>.
Reference: [30] <author> G. Salton and M. J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: are also those successfully integrated into commercial text search systems such as Verity 10 , ConText 11 and AltaVista, involve processing at a relatively syntactic level; e.g., stopword filtering, tokeniz-ing, stemming, building inverted indices, computing heuristic term weights, and computing similarity measures between documents and queries in the vector-space model <ref> [33, 30, 11] </ref>. Singular value decomposition on the term-document matrix has been found to cluster semantically related documents together even if they do not share keywords [8, 24]. We deviate from these systems in the paradigm of interactive exploration and dynamic reorganization of query response based on user context.
Reference: [31] <author> H. Schutze, D. A. Hull, and J. O. Pederson. </author> <title> A comparison of classifiers and document representations for the routing problem. </title> <booktitle> In SIGIR, </booktitle> <pages> pages 229-237, </pages> <year> 1995. </year>
Reference-contexts: For diverse top-level topics, a single-step classifier suffices. But as a document is routed deep into a taxonomy, shared jargon makes sophisticated feature selection a necessity. Together with feature selection, we have to pick models for each class and a classifier. Many options have been evaluated <ref> [31] </ref>. In spite of its simplicity, naive Bayesian classifiers are often almost as accurate as more sophisticated classifiers [18]. For a fixed number of features, naive Bayes is faster than more complex classifiers. However, to approach the latter in accuracy, naive Bayes typically needs many more features. <p> Data mining, machine learning, and pattern recognition. More recent work on text includes statistical modeling of documents, clustering and classification, thesaurus generation by term associations, and query expansion <ref> [31, 10, 34] </ref>. The supervised classification problem has been addressed in statistical decision theory (both classical [35] and Bayesian [3]), statistical pattern recognition [9, 12] and machine learning [36, 23, 19]. Classifier can be parametric or non-parametric.
Reference: [32] <author> S. Vaithyanathan. </author> <title> Document classification using principal component analysis. </title> <type> Personal communication, </type> <month> May </month> <year> 1997. </year>
Reference-contexts: To test the effect of our feature selection, we compared it with an implementation that performs singular value decomposition (SVD) on the original term-document matrix, projects documents down to a lower dimensional space, and uses a Bayesian classifier in that space assuming the Gaussian distribution <ref> [32] </ref>. Our classifier was more accurate by 10-15%, in spite of its simplicity.
Reference: [33] <editor> C. J. van Rijsbergen. </editor> <booktitle> Information Retrieval. </booktitle> <address> But-terworths, London, </address> <year> 1979. </year> <note> Also available on-line at http://www.dcs.gla.ac.uk/Keith/Preface.html. </note>
Reference-contexts: One of the earliest indicators of the power of simple statistical tests on term frequencies is Zipf's law [38]. The models most frequently used in the IR community are Poisson and Poisson mixtures <ref> [28, 33] </ref>. (If X is distributed Poisson with rate , denoted X ~ P (), then Pr [X = x] = e x =x! and if Y is distributed Bernoulli with n trials and mean np, denoted Y ~ B (n; p), then Pr [Y = y] = n y p <p> are also those successfully integrated into commercial text search systems such as Verity 10 , ConText 11 and AltaVista, involve processing at a relatively syntactic level; e.g., stopword filtering, tokeniz-ing, stemming, building inverted indices, computing heuristic term weights, and computing similarity measures between documents and queries in the vector-space model <ref> [33, 30, 11] </ref>. Singular value decomposition on the term-document matrix has been found to cluster semantically related documents together even if they do not share keywords [8, 24]. We deviate from these systems in the paradigm of interactive exploration and dynamic reorganization of query response based on user context.
Reference: [34] <author> E. M. Voorhees. </author> <title> Using WordNet to disambiguate word senses for text retrieval. </title> <booktitle> In SIGIR, </booktitle> <pages> pages 171-180, </pages> <year> 1993. </year>
Reference-contexts: Data mining, machine learning, and pattern recognition. More recent work on text includes statistical modeling of documents, clustering and classification, thesaurus generation by term associations, and query expansion <ref> [31, 10, 34] </ref>. The supervised classification problem has been addressed in statistical decision theory (both classical [35] and Bayesian [3]), statistical pattern recognition [9, 12] and machine learning [36, 23, 19]. Classifier can be parametric or non-parametric.
Reference: [35] <author> A. Wald. </author> <title> Statistical Decision Functions. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1950. </year>
Reference-contexts: Data mining, machine learning, and pattern recognition. More recent work on text includes statistical modeling of documents, clustering and classification, thesaurus generation by term associations, and query expansion [31, 10, 34]. The supervised classification problem has been addressed in statistical decision theory (both classical <ref> [35] </ref> and Bayesian [3]), statistical pattern recognition [9, 12] and machine learning [36, 23, 19]. Classifier can be parametric or non-parametric. Two well-known classes of non-parametric classifiers are decision trees, such as CART [4] and C4.5 [25], and neural networks [14, 22, 15].
Reference: [36] <author> S. M. Weiss and C. A. </author> <title> Kulikowski. Computer Systems That Learn. </title> <publisher> Morgan-Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: More recent work on text includes statistical modeling of documents, clustering and classification, thesaurus generation by term associations, and query expansion [31, 10, 34]. The supervised classification problem has been addressed in statistical decision theory (both classical [35] and Bayesian [3]), statistical pattern recognition [9, 12] and machine learning <ref> [36, 23, 19] </ref>. Classifier can be parametric or non-parametric. Two well-known classes of non-parametric classifiers are decision trees, such as CART [4] and C4.5 [25], and neural networks [14, 22, 15]. For such classifiers, feature sets larger than 100 are considered extremely large. Document classification may require more than 50,000.
Reference: [37] <author> T. Y. Young and T. W. Calvert. </author> <title> Classification, Estimation and Pattern Recognition. </title> <publisher> Elsevier, </publisher> <year> 1974. </year>
Reference-contexts: Also, when X and Y are drawn from multivariate Gaussian distributions with X = Y , this is the optimal discriminator in that thresholding on ff T q for a test point q is the minimum error classifier <ref> [37] </ref>. Computing ff involves a generalized eigenvalue problem involving the covariance matrices.
Reference: [38] <author> G. K. Zipf. </author> <title> Human Behavior and the Principle of Least Effort: An Introduction to Human Ecology. </title> <publisher> Addison-Wesley, </publisher> <year> 1949. </year>
Reference-contexts: One of the earliest indicators of the power of simple statistical tests on term frequencies is Zipf's law <ref> [38] </ref>.
References-found: 38

