URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1993/GIT-CC-93-45.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.93.html
Root-URL: 
Title: Distributed Consensus Revisited  
Author: Gil Neiger 
Note: This work was supported in part by the National Science Foundation under grants CCR-9106627 and CCR-9301454.  
Address: Atlanta, Georgia 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Date: July 26, 1993 Revised October 7, 1993  
Pubnum: GIT-CC-93/45  
Abstract: Distributed Consensus is a classical problem in distributed computing. It requires the correct processors in a distributed system to agree on a common value despite the failure of other processors. This problem is closely related to other problems, such as Byzantine Generals, Approximate Agreement, and k-Set Agreement. This paper examines a variant of Distributed Consensus that considers agreement on a value that is more than a single bit and requires that the agreed upon value be one of the correct processors' input values. It shows that, for this problem to be solved in a system with arbitrary failures, it is necessary that more processors remain correct than for solutions to Distributed Consensus and for cases where agreement is only a single bit. Specifically, the number of processors that must be correct is a function of the size of the domain of values used. Two existing consensus algorithms are modified to solve this stronger variant. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Amotz Bar-Noy and Danny Dolev. </author> <title> Consensus algorithms with one-bit messages. </title> <journal> Distributed Computing, </journal> <volume> 4 </volume> <pages> 105-110, </pages> <year> 1991. </year> <title> Distributed Consensus Revisited 11 </title>
Reference-contexts: They also showed that, as long as n &gt; 3t, solutions to the problem exist. Other solutions have been exhibited that require even more correct processors <ref> [1, 3, 5, 6, 7, 8, 10, 11, 21, 28] </ref>; these have significantly lower communication complexity than the original algorithm of Lamport et al. Only recently, has an algorithm been developed that requires only n &gt; 3t, while running in an optimal number of rounds with polynomial-time local computation [16].
Reference: [2] <author> Amotz Bar-Noy, Danny Dolev, Cynthia Dwork, and H. Raymond Strong. </author> <title> Shifting gears: Changing algorithms on the fly to expedite Byzantine agreement. </title> <journal> Information and Computation, </journal> <volume> 97(2) </volume> <pages> 205-233, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: The following subsections consider two algorithms for Distributed Consensus. The first is the original exponential-time algorithm of Lamport, Shostak, and Pease [19] as formulated by Bar-Noy et al. <ref> [2] </ref>. This algorithm uses neither Agreement Preservation nor Disagreement Detection. As a consequence, a minor modification correctly solves Strong Consensus if n &gt; maxfmt; 3tg. The second algorithm is the phase-king algorithm of Berman and Garay [3]. This algorithm makes use of Agreement Preservation. <p> Since each correct processor decides on this value, Strong Validity is satisfied and the algorithm indeed satisfies Strong Consensus. Thus, the exponential-time algorithm solves Strong Consensus if n &gt; maxfmt; 3tg. Many algorithms for Distributed Consensus are derived from the algorithm given above <ref> [2, 4, 5, 16, 21, 28] </ref>. While it is likely that many of them can be similarly modified to solve Strong Consensus, some derive their improved performance by taking advantage of the fact that D = f0; 1g.
Reference: [3] <author> Piotr Berman and Juan A. Garay. </author> <title> Asymptotically optimal consensus. </title> <booktitle> In Proceedings of the Sixteenth International Conference on Automata, Languages, and Programming, volume 372 of Lecture Notes on Computer Science, </booktitle> <pages> pages 80-94. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: They also showed that, as long as n &gt; 3t, solutions to the problem exist. Other solutions have been exhibited that require even more correct processors <ref> [1, 3, 5, 6, 7, 8, 10, 11, 21, 28] </ref>; these have significantly lower communication complexity than the original algorithm of Lamport et al. Only recently, has an algorithm been developed that requires only n &gt; 3t, while running in an optimal number of rounds with polynomial-time local computation [16]. <p> This algorithm uses neither Agreement Preservation nor Disagreement Detection. As a consequence, a minor modification correctly solves Strong Consensus if n &gt; maxfmt; 3tg. The second algorithm is the phase-king algorithm of Berman and Garay <ref> [3] </ref>. This algorithm makes use of Agreement Preservation. A small but more substantial modification correctly solves Strong Consensus if n &gt; maxf2mt; 4tg. 6 4.1 An Exponential-Time Algorithm for Strong Consensus Consider now the exponential-time algorithm of Lamport, Shostak, and Pease as presented by Bar-Noy et al. <p> A further exploration is necessary to determine which can and which cannot be modified to give algorithms for Strong Consensus. 4.2 A Phase-King Algorithm for Strong Consensus This section discusses the phase-king algorithm of Berman and Garay for Distributed Consensus <ref> [3] </ref>. An adaptation for domains of size greater than 2 is given in Figure 1. The algorithm is correct as long as n &gt; 4t.
Reference: [4] <author> Piotr Berman and Juan A. Garay. </author> <title> Efficient distributed consensus with n = (3 + *)t processors. </title> <editor> In S. Toueg, P. G. Spirakis, and L. Kirousis, editors, </editor> <booktitle> Proceedings of the Fifth International Workshop on Distributed Algorithms, volume 579 of Lecture Notes on Computer Science, </booktitle> <pages> pages 129-142. </pages> <publisher> Springer-Verlag, </publisher> <month> October </month> <year> 1991. </year>
Reference-contexts: Since each correct processor decides on this value, Strong Validity is satisfied and the algorithm indeed satisfies Strong Consensus. Thus, the exponential-time algorithm solves Strong Consensus if n &gt; maxfmt; 3tg. Many algorithms for Distributed Consensus are derived from the algorithm given above <ref> [2, 4, 5, 16, 21, 28] </ref>. While it is likely that many of them can be similarly modified to solve Strong Consensus, some derive their improved performance by taking advantage of the fact that D = f0; 1g.
Reference: [5] <author> Piotr Berman and Juan A. Garay. Cloture votes: n=4-resilient, </author> <title> polynomial time distributed consensus in t + 1 rounds. </title> <journal> Mathematical Systems Theory, </journal> <volume> 26(1) </volume> <pages> 3-20, </pages> <year> 1993. </year>
Reference-contexts: They also showed that, as long as n &gt; 3t, solutions to the problem exist. Other solutions have been exhibited that require even more correct processors <ref> [1, 3, 5, 6, 7, 8, 10, 11, 21, 28] </ref>; these have significantly lower communication complexity than the original algorithm of Lamport et al. Only recently, has an algorithm been developed that requires only n &gt; 3t, while running in an optimal number of rounds with polynomial-time local computation [16]. <p> If this is the case, then Agreement Preservation will ensure that processors retain and thus decide upon this value. Thus, Validity comes "for free." Other algorithms, especially those designed with D = f0; 1g, operate by "detecting disagreement" <ref> [5, 26, 27] </ref>. Validity requires agreement on a particular value only if there is initial unanimity for that value. As soon as a processor detects that there was some initial disagreement, it can "safely" choose some default value. This may facilitate agreement. <p> Since each correct processor decides on this value, Strong Validity is satisfied and the algorithm indeed satisfies Strong Consensus. Thus, the exponential-time algorithm solves Strong Consensus if n &gt; maxfmt; 3tg. Many algorithms for Distributed Consensus are derived from the algorithm given above <ref> [2, 4, 5, 16, 21, 28] </ref>. While it is likely that many of them can be similarly modified to solve Strong Consensus, some derive their improved performance by taking advantage of the fact that D = f0; 1g.
Reference: [6] <author> Piotr Berman, Juan A. Garay, and Kenneth J. Perry. </author> <title> Towards optimal distributed consensus. </title> <booktitle> In Proceedings of the Thirtieth Symposium on Foundations of Computer Science, </booktitle> <pages> pages 410-415. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1989. </year>
Reference-contexts: They also showed that, as long as n &gt; 3t, solutions to the problem exist. Other solutions have been exhibited that require even more correct processors <ref> [1, 3, 5, 6, 7, 8, 10, 11, 21, 28] </ref>; these have significantly lower communication complexity than the original algorithm of Lamport et al. Only recently, has an algorithm been developed that requires only n &gt; 3t, while running in an optimal number of rounds with polynomial-time local computation [16].
Reference: [7] <author> Piotr Berman, Juan A. Garay, and Kenneth J. Perry. </author> <title> Bit optimal distributed consensus. </title> <editor> In R. Yaeza-Bates and U. Manber, editors, </editor> <booktitle> Computer Science Research, </booktitle> <pages> pages 313-322. </pages> <publisher> Plenum Publishing, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: They also showed that, as long as n &gt; 3t, solutions to the problem exist. Other solutions have been exhibited that require even more correct processors <ref> [1, 3, 5, 6, 7, 8, 10, 11, 21, 28] </ref>; these have significantly lower communication complexity than the original algorithm of Lamport et al. Only recently, has an algorithm been developed that requires only n &gt; 3t, while running in an optimal number of rounds with polynomial-time local computation [16].
Reference: [8] <author> James E. Burns and Gil Neiger. </author> <title> Fast and simple Byzantine agreement. </title> <type> Technical Report 92/12, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <month> March </month> <year> 1992. </year> <note> Submitted for publication. </note>
Reference-contexts: They also showed that, as long as n &gt; 3t, solutions to the problem exist. Other solutions have been exhibited that require even more correct processors <ref> [1, 3, 5, 6, 7, 8, 10, 11, 21, 28] </ref>; these have significantly lower communication complexity than the original algorithm of Lamport et al. Only recently, has an algorithm been developed that requires only n &gt; 3t, while running in an optimal number of rounds with polynomial-time local computation [16].
Reference: [9] <author> Soma Chaudhuri. </author> <title> Agreement is harder than consensus: Set consensus problems in totally asynchronous systems. </title> <journal> Information and Computation, </journal> <volume> 103(1) </volume> <pages> 132-158, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: The most closely related forms are Byzantine Generals [19], in which only one processor (the broadcaster) has an input value, and Interactive Consistency [25], in which processors must agree on a vector of output values (one value per processor). More recently, researchers have considered further variants of this problem <ref> [9] </ref>. The complexity of solutions to these problems depends on properties of the system in which the solutions are to be executed. One important system parameter is the synchrony of message passing. <p> Strong Validity, which requires the value chosen to be an initial value, seems more natural and algorithms satisfying it will have greater applicability. In fact, Chaudhuri used this formulation of Validity in her definition of k-Set Agreement <ref> [9] </ref>; she showed that versions of this problem with weaker forms of Validity were solvable with trivial algorithms. There has been earlier work considering Distributed Consensus for domains of m &gt; 2 values.
Reference: [10] <author> Brian A. Coan. </author> <title> Efficient agreement using fault diagnosis. </title> <booktitle> In Proceedings of the Twenty-Sixth Annual Allerton Conference on Communication, Control, and Computing, </booktitle> <month> September </month> <year> 1988. </year> <note> To appear in Distributed Computing. </note>
Reference-contexts: They also showed that, as long as n &gt; 3t, solutions to the problem exist. Other solutions have been exhibited that require even more correct processors <ref> [1, 3, 5, 6, 7, 8, 10, 11, 21, 28] </ref>; these have significantly lower communication complexity than the original algorithm of Lamport et al. Only recently, has an algorithm been developed that requires only n &gt; 3t, while running in an optimal number of rounds with polynomial-time local computation [16].
Reference: [11] <author> Brian A. Coan and Jennifer L. Welch. </author> <title> Modular construction of an efficient 1-bit Byzantine agreement protocol. </title> <journal> Mathematical Systems Theory, </journal> <volume> 26(1) </volume> <pages> 131-154, </pages> <year> 1993. </year>
Reference-contexts: They also showed that, as long as n &gt; 3t, solutions to the problem exist. Other solutions have been exhibited that require even more correct processors <ref> [1, 3, 5, 6, 7, 8, 10, 11, 21, 28] </ref>; these have significantly lower communication complexity than the original algorithm of Lamport et al. Only recently, has an algorithm been developed that requires only n &gt; 3t, while running in an optimal number of rounds with polynomial-time local computation [16].
Reference: [12] <author> Danny Dolev, Michael J. Fischer, Rob Fowler, Nancy A. Lynch, and H. Raymond Strong. </author> <title> An efficient algorithm for Byzantine agreement without authentication. </title> <journal> Information and Computation, </journal> <volume> 52 </volume> <pages> 257-274, </pages> <year> 1982. </year> <month> 12 </month>
Reference-contexts: There has been earlier work considering Distributed Consensus for domains of m &gt; 2 values. Dolev et al. <ref> [12] </ref> showed how dlog 2 me binary algorithms, running in parallel could yield the bits that compose an overall value.
Reference: [13] <author> Cynthia Dwork and Yoram Moses. </author> <title> Knowledge and common knowledge in a Byzan-tine environment: Crash failures. </title> <journal> Information and Computation, </journal> <volume> 88(2) </volume> <pages> 156-186, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: An algorithm written to tolerate arbitrary failure is desirable, because it makes no assumptions regarding the behavior of faulty processors. (Other research has considered Distributed Consensus in the presence of more restricted faulty behavior <ref> [13, 17, 20, 22, 23, 24] </ref>. 1 ) If processors may fail arbitrarily, then solutions to Distributed Consensus are not possible if too many failures may occur.
Reference: [14] <author> Michael J. Fischer. </author> <title> The consensus problem in unreliable distributed systems (a brief survey). </title> <editor> In M. Karpinsky, editor, </editor> <booktitle> Foundations of Computation Theory, volume 158 of Lecture Notes on Computer Science, </booktitle> <pages> pages 127-140. </pages> <publisher> Springer-Verlag, </publisher> <year> 1983. </year>
Reference-contexts: Typically, such algorithms can tolerate only a certain number of failures. Generally, t is used to represent the fault tolerance of an algorithm; the three conditions above need hold only for executions in which at most t processors fail. Fischer <ref> [14] </ref> gives an overview of different forms of this and related problems.
Reference: [15] <author> Michael J. Fischer, Nancy A. Lynch, and Michael S. Paterson. </author> <title> Impossibility of distributed consensus with one faulty process. </title> <journal> Journal of the ACM, </journal> <volume> 32(2) </volume> <pages> 374-382, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: More recently, researchers have considered further variants of this problem [9]. The complexity of solutions to these problems depends on properties of the system in which the solutions are to be executed. One important system parameter is the synchrony of message passing. Fischer, Lynch, and Paterson <ref> [15] </ref> have shown that consensus is impossible in systems with asynchronous message passing even if only a single stopping failure can occur. For that reason, most research (including this paper) concentrates on systems with synchronous message passing.
Reference: [16] <author> Juan A. Garay and Yoram Moses. </author> <title> Fully polynomial Byzantine agreement in t + 1 rounds. </title> <booktitle> In Proceedings of the Twenty-Fifth ACM Symposium on Theory of Computing, </booktitle> <pages> pages 31-41. </pages> <publisher> ACM Press, </publisher> <month> May </month> <year> 1993. </year>
Reference-contexts: Only recently, has an algorithm been developed that requires only n &gt; 3t, while running in an optimal number of rounds with polynomial-time local computation <ref> [16] </ref>. The original specification of Distributed Consensus requires that a specific value be the decision value only when all correct processors begin with that value. (This is the Validity condition.) This is a reasonable constraint if the domain of values considered is only f0; 1g. <p> Since each correct processor decides on this value, Strong Validity is satisfied and the algorithm indeed satisfies Strong Consensus. Thus, the exponential-time algorithm solves Strong Consensus if n &gt; maxfmt; 3tg. Many algorithms for Distributed Consensus are derived from the algorithm given above <ref> [2, 4, 5, 16, 21, 28] </ref>. While it is likely that many of them can be similarly modified to solve Strong Consensus, some derive their improved performance by taking advantage of the fact that D = f0; 1g.
Reference: [17] <author> Vassos Hadzilacos. </author> <title> Byzantine agreement under restricted types of failures (not telling the truth is different from telling lies). </title> <type> Technical Report 18-83, </type> <institution> Aiken Computation Laboratory, Harvard University, </institution> <year> 1983. </year> <note> A revised version appears in Hadzilacos's Ph.D. dissertation [18]. </note>
Reference-contexts: An algorithm written to tolerate arbitrary failure is desirable, because it makes no assumptions regarding the behavior of faulty processors. (Other research has considered Distributed Consensus in the presence of more restricted faulty behavior <ref> [13, 17, 20, 22, 23, 24] </ref>. 1 ) If processors may fail arbitrarily, then solutions to Distributed Consensus are not possible if too many failures may occur.
Reference: [18] <author> Vassos Hadzilacos. </author> <title> Issues of Fault Tolerance in Concurrent Computations. </title> <type> Ph.D. dissertation, </type> <institution> Harvard University, </institution> <month> June </month> <year> 1984. </year> <type> Technical Report 11-84, </type> <institution> Aiken Computation Laboratory. </institution>
Reference: [19] <author> Leslie Lamport, Robert Shostak, and Marshall Pease. </author> <title> The Byzantine generals problem. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 4(3) </volume> <pages> 382-401, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: Generally, t is used to represent the fault tolerance of an algorithm; the three conditions above need hold only for executions in which at most t processors fail. Fischer [14] gives an overview of different forms of this and related problems. The most closely related forms are Byzantine Generals <ref> [19] </ref>, in which only one processor (the broadcaster) has an input value, and Interactive Consistency [25], in which processors must agree on a vector of output values (one value per processor). More recently, researchers have considered further variants of this problem [9]. <p> Specifically, Lamport, Shostak, and Pease <ref> [19] </ref> show that the total number of processors n must be greater than three times the number of failures to be tolerated 1 In such systems, the Validity condition is often rephrased to read "If all processors begin with the same input value, then they must end with that same value." <p> This implies that v = v 0 and Validity holds. Thus, any algorithm that solves 4 Distributed Consensus also solves Strong Consensus. The next section shows that the converse is not true. 3 The Impossibility Result Lamport, Shostak, and Pease <ref> [19] </ref> proved that Distributed Consensus can be solved only if n &gt; 3t, that is, only if fewer than one-third of the processors may fail. In addition, they exhibited an algorithm for Distributed Consensus that is correct as long as n &gt; 3t. <p> The following subsections consider two algorithms for Distributed Consensus. The first is the original exponential-time algorithm of Lamport, Shostak, and Pease <ref> [19] </ref> as formulated by Bar-Noy et al. [2]. This algorithm uses neither Agreement Preservation nor Disagreement Detection. As a consequence, a minor modification correctly solves Strong Consensus if n &gt; maxfmt; 3tg. The second algorithm is the phase-king algorithm of Berman and Garay [3].
Reference: [20] <author> Yoram Moses and Mark R. Tuttle. </author> <title> Programming simultaneous actions using common knowledge. </title> <journal> Algorithmica, </journal> <volume> 3(1) </volume> <pages> 121-169, </pages> <year> 1988. </year>
Reference-contexts: An algorithm written to tolerate arbitrary failure is desirable, because it makes no assumptions regarding the behavior of faulty processors. (Other research has considered Distributed Consensus in the presence of more restricted faulty behavior <ref> [13, 17, 20, 22, 23, 24] </ref>. 1 ) If processors may fail arbitrarily, then solutions to Distributed Consensus are not possible if too many failures may occur.
Reference: [21] <author> Yoram Moses and Orli Waarts. </author> <title> Coordinated traversal: (t + 1)-round Byzantine agreement in polynomial time. </title> <booktitle> In Proceedings of the Twenty-Ninth Symposium on Foundations of Computer Science, </booktitle> <pages> pages 246-255. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1988. </year>
Reference-contexts: They also showed that, as long as n &gt; 3t, solutions to the problem exist. Other solutions have been exhibited that require even more correct processors <ref> [1, 3, 5, 6, 7, 8, 10, 11, 21, 28] </ref>; these have significantly lower communication complexity than the original algorithm of Lamport et al. Only recently, has an algorithm been developed that requires only n &gt; 3t, while running in an optimal number of rounds with polynomial-time local computation [16]. <p> Since each correct processor decides on this value, Strong Validity is satisfied and the algorithm indeed satisfies Strong Consensus. Thus, the exponential-time algorithm solves Strong Consensus if n &gt; maxfmt; 3tg. Many algorithms for Distributed Consensus are derived from the algorithm given above <ref> [2, 4, 5, 16, 21, 28] </ref>. While it is likely that many of them can be similarly modified to solve Strong Consensus, some derive their improved performance by taking advantage of the fact that D = f0; 1g.
Reference: [22] <author> Gil Neiger and Rida Bazzi. </author> <title> Using knowledge to optimally achieve coordination in distributed systems. </title> <editor> In Yoram Moses, editor, </editor> <booktitle> Proceedings of the Fourth Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 43-59. </pages> <publisher> Morgan-Kaufmann, </publisher> <month> March </month> <year> 1992. </year>
Reference-contexts: An algorithm written to tolerate arbitrary failure is desirable, because it makes no assumptions regarding the behavior of faulty processors. (Other research has considered Distributed Consensus in the presence of more restricted faulty behavior <ref> [13, 17, 20, 22, 23, 24] </ref>. 1 ) If processors may fail arbitrarily, then solutions to Distributed Consensus are not possible if too many failures may occur.
Reference: [23] <author> Gil Neiger and Sam Toueg. </author> <title> Automatically increasing the fault-tolerance of distributed algorithms. </title> <journal> Journal of Algorithms, </journal> <volume> 11(3) </volume> <pages> 374-419, </pages> <month> September </month> <year> 1990. </year> <title> Distributed Consensus Revisited 13 </title>
Reference-contexts: An algorithm written to tolerate arbitrary failure is desirable, because it makes no assumptions regarding the behavior of faulty processors. (Other research has considered Distributed Consensus in the presence of more restricted faulty behavior <ref> [13, 17, 20, 22, 23, 24] </ref>. 1 ) If processors may fail arbitrarily, then solutions to Distributed Consensus are not possible if too many failures may occur.
Reference: [24] <author> Gil Neiger and Mark R. Tuttle. </author> <title> Common knowledge and consistent simultaneous coordination. </title> <journal> Distributed Computing, </journal> <volume> 6(3) </volume> <pages> 181-192, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: An algorithm written to tolerate arbitrary failure is desirable, because it makes no assumptions regarding the behavior of faulty processors. (Other research has considered Distributed Consensus in the presence of more restricted faulty behavior <ref> [13, 17, 20, 22, 23, 24] </ref>. 1 ) If processors may fail arbitrarily, then solutions to Distributed Consensus are not possible if too many failures may occur.
Reference: [25] <author> M. Pease, R. Shostak, and L. Lamport. </author> <title> Reaching agreement in the presence of faults. </title> <journal> Journal of the ACM, </journal> <volume> 27(2) </volume> <pages> 228-234, </pages> <month> April </month> <year> 1980. </year>
Reference-contexts: Fischer [14] gives an overview of different forms of this and related problems. The most closely related forms are Byzantine Generals [19], in which only one processor (the broadcaster) has an input value, and Interactive Consistency <ref> [25] </ref>, in which processors must agree on a vector of output values (one value per processor). More recently, researchers have considered further variants of this problem [9]. The complexity of solutions to these problems depends on properties of the system in which the solutions are to be executed.
Reference: [26] <author> Kenneth J. Perry. </author> <title> Early Stopping Protocols for Fault-Tolerant Distributed Agreement. </title> <type> Ph.D. dissertation, </type> <institution> Cornell University, </institution> <month> February </month> <year> 1985. </year> <type> Technical Report 85-662, </type> <institution> Department of Computer Science. </institution>
Reference-contexts: However, this will not guarantee Strong Validity as the bits chosen might be chosen from different values (e.g., if there are initial values 2 = 10 2 and 1 = 01 2 , the final decision could be 3 = 11 2 ). Perry <ref> [26] </ref> and Turpin and Coan [27] showed how a binary algorithm could be transformed into a multi-valued algorithm with the addition of one round of communication. However, their technique has processors agree on a "default" value (which might not be any correct processor's initial value) if initial disagreement is detected. <p> If this is the case, then Agreement Preservation will ensure that processors retain and thus decide upon this value. Thus, Validity comes "for free." Other algorithms, especially those designed with D = f0; 1g, operate by "detecting disagreement" <ref> [5, 26, 27] </ref>. Validity requires agreement on a particular value only if there is initial unanimity for that value. As soon as a processor detects that there was some initial disagreement, it can "safely" choose some default value. This may facilitate agreement.
Reference: [27] <author> Russell Turpin and Brian A. Coan. </author> <title> Extending binary Byzantine agreement to mul-tivalued Byzantine agreement. </title> <journal> Information Processing Letters, </journal> <volume> 18 </volume> <pages> 73-76, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: However, this will not guarantee Strong Validity as the bits chosen might be chosen from different values (e.g., if there are initial values 2 = 10 2 and 1 = 01 2 , the final decision could be 3 = 11 2 ). Perry [26] and Turpin and Coan <ref> [27] </ref> showed how a binary algorithm could be transformed into a multi-valued algorithm with the addition of one round of communication. However, their technique has processors agree on a "default" value (which might not be any correct processor's initial value) if initial disagreement is detected. This may violate Strong Validity. <p> If this is the case, then Agreement Preservation will ensure that processors retain and thus decide upon this value. Thus, Validity comes "for free." Other algorithms, especially those designed with D = f0; 1g, operate by "detecting disagreement" <ref> [5, 26, 27] </ref>. Validity requires agreement on a particular value only if there is initial unanimity for that value. As soon as a processor detects that there was some initial disagreement, it can "safely" choose some default value. This may facilitate agreement.
Reference: [28] <author> Arkady Zamsky, Amos Israeli, and Shlomit S. Pinter. </author> <title> Optimal time Byzantine agreement for t &lt; n=8 with linear messages. </title> <editor> In A. Segall and S. Zaks, editors, </editor> <booktitle> Proceedings of the Sixth International Workshop on Distributed Algorithms, number 647 in Lecture Notes on Computer Science, </booktitle> <pages> pages 136-152. </pages> <publisher> Springer-Verlag, </publisher> <month> November </month> <year> 1992. </year>
Reference-contexts: They also showed that, as long as n &gt; 3t, solutions to the problem exist. Other solutions have been exhibited that require even more correct processors <ref> [1, 3, 5, 6, 7, 8, 10, 11, 21, 28] </ref>; these have significantly lower communication complexity than the original algorithm of Lamport et al. Only recently, has an algorithm been developed that requires only n &gt; 3t, while running in an optimal number of rounds with polynomial-time local computation [16]. <p> Since each correct processor decides on this value, Strong Validity is satisfied and the algorithm indeed satisfies Strong Consensus. Thus, the exponential-time algorithm solves Strong Consensus if n &gt; maxfmt; 3tg. Many algorithms for Distributed Consensus are derived from the algorithm given above <ref> [2, 4, 5, 16, 21, 28] </ref>. While it is likely that many of them can be similarly modified to solve Strong Consensus, some derive their improved performance by taking advantage of the fact that D = f0; 1g.
References-found: 28

