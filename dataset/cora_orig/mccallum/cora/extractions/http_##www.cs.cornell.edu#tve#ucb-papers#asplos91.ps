URL: http://www.cs.cornell.edu/tve/ucb-papers/asplos91.ps
Refering-URL: 
Root-URL: 
Title: Fine-grain Parallelism with Minimal Hardware Support: A Compiler-Controlled Threaded Abstract Machine 1  
Author: David E. Culler, Anurag Sah, Klaus Erik Schauser Thorsten von Eicken, John Wawrzynek 
Address: Berkeley, CA 94720  
Affiliation: Computer Science Division Electrical Engineering and Computer Sciences Department University of California, Berkeley  
Abstract: In this paper, we present a relatively primitive execution model for fine-grain parallelism, in which all synchronization, scheduling, and storage management is explicit and under compiler control. This is defined by a threaded abstract machine (TAM) with a multilevel scheduling hierarchy. Considerable temporal locality of logically related threads is demonstrated, providing an avenue for effective register use under quasi-dynamic scheduling. A prototype TAM instruction set, TL0, has been developed, along with a translator to a variety of existing sequential and parallel machines. Compilation of Id, an extended functional language requiring fine-grain synchronization, under this model yields performance approaching that of conventional languages on current uniprocessors. Measurements suggest that the net cost of synchronization on conventional multiprocessors can be reduced to within a small factor of that on machines with elaborate hardware support, such as proposed dataflow architectures. This brings into question whether tolerance to latency and inexpensive synchronization require specific hardware support or merely an appropriate compilation strategy and program representation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal, B. Lim, D. Kranz, and J. Kubiatowicz. </author> <month> APRIL: </month> <title> A Processor Architecture for Multiprocessing. </title> <booktitle> In Proc. of the 17th Annual Int. Symp. on Comp. Arch., </booktitle> <pages> pages 104-114, </pages> <address> Seattle, Washington, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: I-structures [6]. On the other hand, asynchronous transfer of control (context switching) is notoriously expensive on current machines, leading many researchers to examine asynchronous parallel execution models through the study of real machines [11, 13, 15, 22, 25, 27], paper architectures <ref> [1, 5, 14, 16, 19] </ref>, and abstract machines [21]. In all of these proposals, the scheduling of threads is viewed as a property of the machine, invisible to the compiler. <p> Also, the set of enabled threads is maintained in a special hardware token queue. Several multithreaded architectures have been proposed as generalizations of conventional single-threaded machines, with registers sets (i.e., frames) multiplexed to hide memory and communication latency <ref> [1, 14, 17, 27, 29] </ref>. In most cases, only one thread of execution per frame is supported. Thus, each outstanding reference has an entire register set standing idle behind it.
Reference: [2] <author> Arvind, D. E. Culler, and G. K. Maa. </author> <title> Assessing the Benefits of Fine-Grain Parallelism in Dataflow Programs. </title> <journal> The Int. Journal of Supercomputer Applications, </journal> <volume> 2(3), </volume> <month> November </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Multithreading at the instruction level may provide the key to general purpose parallel computing [26], because it allows the processor to tolerate long, unpredictable communication latency <ref> [2, 4, 17, 24, 29] </ref>. In addition, this level of multithreading is required to support certain modern parallel programming languages [28], such as Id [20] and Multilisp [18], and extensions of more conventional languages with synchronizing data structures, e.g. I-structures [6].
Reference: [3] <author> Arvind and K. Ekanadham. </author> <title> Future Scientific Programming on Parallel Machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5(5) </volume> <pages> 460-493, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: In addition to the small programs discussed above, this includes two larger programs. Gamteb is a Monte Carlo neutron transport code. It is highly recursive with many conditionals. Simple is a hydrodynamics and heat conduction code widely used as an application benchmark, rewritten in Id <ref> [3] </ref>. The TTDA numbers were obtained using the Id-World graph interpreter, with the same suite of arithmetic operators, structure operations, and the same resource management operations as in TL0.
Reference: [4] <author> Arvind and R. A. </author> <title> Iannucci. Two Fundamental Issues in Multiprocessing. </title> <booktitle> In Proc. of DFVLR - Conf. 1987 on Par. Proc. in Science and Eng., </booktitle> <address> Bonn-Bad Godesberg, </address> <publisher> W. </publisher> <address> Germany, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: 1 Introduction Multithreading at the instruction level may provide the key to general purpose parallel computing [26], because it allows the processor to tolerate long, unpredictable communication latency <ref> [2, 4, 17, 24, 29] </ref>. In addition, this level of multithreading is required to support certain modern parallel programming languages [28], such as Id [20] and Multilisp [18], and extensions of more conventional languages with synchronizing data structures, e.g. I-structures [6]. <p> That is, the instruction that issues a fetch request does not wait for the data value to be returned, instead the response will initiate a new execution thread <ref> [4, 6] </ref>. This allows the processor to be well utilized while remote requests are outstanding.
Reference: [5] <author> Arvind and R. S. Nikhil. </author> <title> Executing a Program on the MIT Tagged-Token Dataflow Architecture. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(3) </volume> <pages> 300-318, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: I-structures [6]. On the other hand, asynchronous transfer of control (context switching) is notoriously expensive on current machines, leading many researchers to examine asynchronous parallel execution models through the study of real machines [11, 13, 15, 22, 25, 27], paper architectures <ref> [1, 5, 14, 16, 19] </ref>, and abstract machines [21]. In all of these proposals, the scheduling of threads is viewed as a property of the machine, invisible to the compiler. <p> We refer to a frame and the set of threads executed relative to the frame as an activation. The basics of this parallel call scenario are well described in the literature <ref> [5, 9, 21] </ref>. To allow greater parallelism and to support languages with non-strict function call semantics, 2 the arguments to a code-block may be delivered asynchronously; each will initiate an execution thread within the code-block. An activation is enabled if its frame contains any enabled threads. <p> we optimized these programs by hand; the Id version improves only slightly, while the other improve considerably. 3.2 Threads versus dataflow graphs To demonstrate the impact of compiling to threads, Table 2 presents dynamic instruction frequencies for Id programs compiled to TL0 and compiled to graphs for the MIT TTDA <ref> [5] </ref>. In addition to the small programs discussed above, this includes two larger programs. Gamteb is a Monte Carlo neutron transport code. It is highly recursive with many conditionals. Simple is a hydrodynamics and heat conduction code widely used as an application benchmark, rewritten in Id [3].
Reference: [6] <author> Arvind, R. S. Nikhil, and K. K. Pingali. I-Structures: </author> <title> Data Structures for Parallel Computing. </title> <type> Technical Report CSG Memo 269, </type> <institution> MIT Lab for Comp. Sci., </institution> <type> 545 Tech. </type> <institution> Square, </institution> <address> Cambridge, MA, </address> <month> February </month> <year> 1987. </year> <title> (Also in Proc. of the Graph Reduction Workshop, </title> <address> Santa Fe, NM. </address> <month> October </month> <year> 1986.). </year>
Reference-contexts: In addition, this level of multithreading is required to support certain modern parallel programming languages [28], such as Id [20] and Multilisp [18], and extensions of more conventional languages with synchronizing data structures, e.g. I-structures <ref> [6] </ref>. On the other hand, asynchronous transfer of control (context switching) is notoriously expensive on current machines, leading many researchers to examine asynchronous parallel execution models through the study of real machines [11, 13, 15, 22, 25, 27], paper architectures [1, 5, 14, 16, 19], and abstract machines [21]. <p> That is, the instruction that issues a fetch request does not wait for the data value to be returned, instead the response will initiate a new execution thread <ref> [4, 6] </ref>. This allows the processor to be well utilized while remote requests are outstanding.
Reference: [7] <author> G. Chaitin, M. Auslander, A. Chandra, J. Cocke, M. Hopkins, and P. Markstein. </author> <title> Register Allocation via Coloring. </title> <journal> Computer Languages, </journal> <volume> 6 </volume> <pages> 47-57, </pages> <year> 1981. </year>
Reference-contexts: Instructions may refer to registers and to slots in the current frame; the compiler statically determines the frame size for each code-block and is responsible for correctly using slots and registers under all possible dynamic thread orderings. (This is somewhat more complex than traditional register allocation via graph coloring <ref> [7] </ref>.) The compiler also reserves a portion of the frame as a continuation vector, used at run-time to hold pointers to enabled threads. The continuation vector must be large enough to describe the concurrently enabled threads for a code-block.
Reference: [8] <author> D. E. Culler. </author> <title> Managing Parallelism and Resources in Scientific Dataflow Programs. </title> <type> Technical Report 446, </type> <institution> MIT Lab for Comp. Sci., </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: The key observation is that the activation tree and the continuation pool are typically quite large, except on toy programs. This has been demonstrated empirically for programs in Id <ref> [8] </ref>, Sisal [23], and Multilisp [18]. Minimizing the activation tree size while exposing sufficient parallelism is an active area of research, but even with advances in this area we cannot expect the entire activation tree or the entire continuation pool to be maintained in high-speed processor storage. <p> The row labeled fork&switch includes conditional and unconditional forks in the TL0 and switch instructions in the TTDA, used to steer values into conditionals or loop bodies. The D Loop row reflects instructions that update tag fields and control unfolding in loops. The TL0 compilation uses 1-bounded loops <ref> [8] </ref> and would incur additional overhead with a more general parallel iteration strategy. Compiling to threads compensates to a large measure for the additional instructions introduced for explicit scheduling in the TAM model. The increase in overall instruction counts is modest compared to more complex dataflow models.
Reference: [9] <author> D. E. Culler and Arvind. </author> <title> Resource Requirements of Dataflow Programs. </title> <booktitle> In Proc. of the 15th Annual Int. Symp. on Comp. Arch., </booktitle> <pages> pages 141-150, </pages> <address> Hawaii, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: We refer to a frame and the set of threads executed relative to the frame as an activation. The basics of this parallel call scenario are well described in the literature <ref> [5, 9, 21] </ref>. To allow greater parallelism and to support languages with non-strict function call semantics, 2 the arguments to a code-block may be delivered asynchronously; each will initiate an execution thread within the code-block. An activation is enabled if its frame contains any enabled threads.
Reference: [10] <author> W Dally and et al. </author> <title> Architecture of a Message-Driven Processor. </title> <booktitle> In Proc. of the 14th Annual Int. Symp. on Comp. Arch., </booktitle> <pages> pages 189-196, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: However, the hybrid proposal associates presence bits with frame slots and when a thread attempts to read an empty slot it is suspended; the continuation for the thread is placed in the empty slot and 5 Inlets provide a form of message handling similar to Dally's J-machine <ref> [10] </ref>, but are more limited. The dispatch is trivial and storage required for the inlet to complete its task is pre-allocated in an activation frame. 6 rescheduled when the slot is written. Registers vanish at a point of potential suspension.
Reference: [11] <author> V. G. Grafe, G. S. Davidson, J. E. Hoch, and V. P. Holmes. </author> <title> The Epsilon Dataflow Processor. </title> <booktitle> In Proc. of the 16th Annual Int. Symp. on Comp. Arch., </booktitle> <year> 1989. </year>
Reference-contexts: I-structures [6]. On the other hand, asynchronous transfer of control (context switching) is notoriously expensive on current machines, leading many researchers to examine asynchronous parallel execution models through the study of real machines <ref> [11, 13, 15, 22, 25, 27] </ref>, paper architectures [1, 5, 14, 16, 19], and abstract machines [21]. In all of these proposals, the scheduling of threads is viewed as a property of the machine, invisible to the compiler.
Reference: [12] <author> V. G. Grafe and J. E. Hoch. </author> <title> The Epsilon-2 Hybrid Dataflow Architecture. </title> <booktitle> In Proc. of Comp-con90, </booktitle> <pages> pages 88-93, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: P-Risc, which strongly influenced TAM, uses frame slots for synchronization, rather than presence bits, and makes the synchronization operation explicit. However P-Risc does not recognize a storage hierarchy (there are no registers) or scheduling hierarchy (the next thread may come from any frame). Recent dataflow machines <ref> [12, 22, 25] </ref> allow several instructions, i.e., a thread, to be enabled by a single dataflow synchronization. Registers are used to hold values with a lifetime of a single such thread, as these values need never be placed in the frame. <p> The net reduction of synchronization events can be seen in the row labeled aborts which shows the number of unsatisfied entry count decrements, for the TL0 case, and match failures, for the TTDA, as a percentage of the total number of TTDA operations. The recent generation dataflow machines <ref> [12, 22, 25] </ref> all support some form of thread, and the graph partitioning and elimination of redundant arcs used in TL0 compilation could be employed with similar benefits.
Reference: [13] <author> J. Gurd, C.C. Kirkham, and I. Watson. </author> <title> The Manchester Prototype Dataflow Computer. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 28(1) </volume> <pages> 34-52, </pages> <month> January </month> <year> 1985. </year> <month> 17 </month>
Reference-contexts: I-structures [6]. On the other hand, asynchronous transfer of control (context switching) is notoriously expensive on current machines, leading many researchers to examine asynchronous parallel execution models through the study of real machines <ref> [11, 13, 15, 22, 25, 27] </ref>, paper architectures [1, 5, 14, 16, 19], and abstract machines [21]. In all of these proposals, the scheduling of threads is viewed as a property of the machine, invisible to the compiler.
Reference: [14] <author> R. H. Halstead, Jr. and T. Fujita. MASA: </author> <title> a Multithreaded Processor Architecture for Parallel Symbolic Computing. </title> <booktitle> In Proc. of the 15th Int. Symp. on Comp. Arch., </booktitle> <pages> pages 443-451, </pages> <year> 1988. </year>
Reference-contexts: I-structures [6]. On the other hand, asynchronous transfer of control (context switching) is notoriously expensive on current machines, leading many researchers to examine asynchronous parallel execution models through the study of real machines [11, 13, 15, 22, 25, 27], paper architectures <ref> [1, 5, 14, 16, 19] </ref>, and abstract machines [21]. In all of these proposals, the scheduling of threads is viewed as a property of the machine, invisible to the compiler. <p> Also, the set of enabled threads is maintained in a special hardware token queue. Several multithreaded architectures have been proposed as generalizations of conventional single-threaded machines, with registers sets (i.e., frames) multiplexed to hide memory and communication latency <ref> [1, 14, 17, 27, 29] </ref>. In most cases, only one thread of execution per frame is supported. Thus, each outstanding reference has an entire register set standing idle behind it. <p> In most cases, only one thread of execution per frame is supported. Thus, each outstanding reference has an entire register set standing idle behind it. With the exception of MASA <ref> [14] </ref>, the number of frames per processor is static, thus the mechanism does not directly support language models with dynamically generated parallelism. By viewing memory as split-phase transactions, TAM allows multiple outstanding references per register set and minimizes the number of register set switches.
Reference: [15] <author> K. Hiraki, K. Nishida, S. Sekiguchi, and T. Shimada. </author> <title> Maintainence Architecture and its LSI Implementation of a Dataflow Computer with a Large Number of Processors. </title> <booktitle> In Proc. of the 1986 Int. Conf. on Par. Proc., </booktitle> <pages> pages 584-591, </pages> <year> 1986. </year>
Reference-contexts: I-structures [6]. On the other hand, asynchronous transfer of control (context switching) is notoriously expensive on current machines, leading many researchers to examine asynchronous parallel execution models through the study of real machines <ref> [11, 13, 15, 22, 25, 27] </ref>, paper architectures [1, 5, 14, 16, 19], and abstract machines [21]. In all of these proposals, the scheduling of threads is viewed as a property of the machine, invisible to the compiler. <p> Under a dataflow execution model, the primary form of synchronization is matching pairs of operands. This requires one cycle on an ETS dataflow architecture [22] or multiple cycles with a hash-based matching store <ref> [15] </ref>, under the assumption that the matching store and the token queue are maintained in high-speed processor storage. 7 We see that 1.5 tokens are processed per instruction, or one synchronization event for every two instructions, on average.
Reference: [16] <author> R. A. </author> <title> Iannucci. Toward a Dataflow/von Neumann Hybrid Architecture. </title> <booktitle> In Proc. 15th Int. Symp. on Comp. Arch., </booktitle> <pages> pages 131-140, </pages> <year> 1988. </year>
Reference-contexts: I-structures [6]. On the other hand, asynchronous transfer of control (context switching) is notoriously expensive on current machines, leading many researchers to examine asynchronous parallel execution models through the study of real machines [11, 13, 15, 22, 25, 27], paper architectures <ref> [1, 5, 14, 16, 19] </ref>, and abstract machines [21]. In all of these proposals, the scheduling of threads is viewed as a property of the machine, invisible to the compiler. <p> An inlet can, however, handle messages of arbitrary length, network interface permitting. 5 2.6 Comparison with other models The basic structure of TAM is similar to several of the multithreaded architectures derived from dynamic dataflow, with some key differences. Iannucci's hybrid architecture <ref> [16] </ref> has a similar storage hierarchy; instructions may refer to processor registers or to slots in the current frame. <p> The observed thread sizes are comparable to run lengths reported for hybrid dataflow machines, where conditionals were treated as strict <ref> [16] </ref>. Partitioning eliminates more than half of the dynamic synchronization points and, by maintaining thread-local values in registers, eliminates roughly half of the frame references and reduces the frame size substantially.
Reference: [17] <author> H. F. Jordan. </author> <title> Performance Measurement on HEP | A Pipelined MIMD Computer. </title> <booktitle> In Proc. of the 10th Annual Int. Symp. on Comp. Arch., </booktitle> <address> Stockholm, Sweden, </address> <month> June </month> <year> 1983. </year>
Reference-contexts: 1 Introduction Multithreading at the instruction level may provide the key to general purpose parallel computing [26], because it allows the processor to tolerate long, unpredictable communication latency <ref> [2, 4, 17, 24, 29] </ref>. In addition, this level of multithreading is required to support certain modern parallel programming languages [28], such as Id [20] and Multilisp [18], and extensions of more conventional languages with synchronizing data structures, e.g. I-structures [6]. <p> Also, the set of enabled threads is maintained in a special hardware token queue. Several multithreaded architectures have been proposed as generalizations of conventional single-threaded machines, with registers sets (i.e., frames) multiplexed to hide memory and communication latency <ref> [1, 14, 17, 27, 29] </ref>. In most cases, only one thread of execution per frame is supported. Thus, each outstanding reference has an entire register set standing idle behind it.
Reference: [18] <author> R. H. Halstead Jr. </author> <title> Multilisp: A Language for Concurrent Symbolic Computation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(4) </volume> <pages> 501-538, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: In addition, this level of multithreading is required to support certain modern parallel programming languages [28], such as Id [20] and Multilisp <ref> [18] </ref>, and extensions of more conventional languages with synchronizing data structures, e.g. I-structures [6]. <p> The key observation is that the activation tree and the continuation pool are typically quite large, except on toy programs. This has been demonstrated empirically for programs in Id [8], Sisal [23], and Multilisp <ref> [18] </ref>. Minimizing the activation tree size while exposing sufficient parallelism is an active area of research, but even with advances in this area we cannot expect the entire activation tree or the entire continuation pool to be maintained in high-speed processor storage.
Reference: [19] <author> D. Lenoski, J. Laudon, K. Gharachorloo, A. Gupta, and J. Hennessy. </author> <title> The Directory-Based Cache Coherence Protocol for the DASH Multiprocessor. </title> <booktitle> In Proc. of the 17th Annual Int. Symp. on Comp. Arch., </booktitle> <pages> pages 148-159, </pages> <address> Sealttle, Washington, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: I-structures [6]. On the other hand, asynchronous transfer of control (context switching) is notoriously expensive on current machines, leading many researchers to examine asynchronous parallel execution models through the study of real machines [11, 13, 15, 22, 25, 27], paper architectures <ref> [1, 5, 14, 16, 19] </ref>, and abstract machines [21]. In all of these proposals, the scheduling of threads is viewed as a property of the machine, invisible to the compiler.
Reference: [20] <author> R. S. Nikhil. </author> <title> Id (Version 88.0) Reference Manual. </title> <type> Technical Report CSG Memo 284, </type> <institution> MIT Lab for Comp. Sci., </institution> <type> 545 Tech. </type> <institution> Square, </institution> <address> Cambridge, MA, </address> <month> March </month> <year> 1988. </year>
Reference-contexts: In addition, this level of multithreading is required to support certain modern parallel programming languages [28], such as Id <ref> [20] </ref> and Multilisp [18], and extensions of more conventional languages with synchronizing data structures, e.g. I-structures [6].
Reference: [21] <author> R. S. Nikhil and Arvind. </author> <title> Can Dataflow Subsume von Neumann Computing? In Proc. </title> <booktitle> of the 16th Annual Int. Symp. on Comp. Arch., </booktitle> <address> Jerusalem, Israel, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: I-structures [6]. On the other hand, asynchronous transfer of control (context switching) is notoriously expensive on current machines, leading many researchers to examine asynchronous parallel execution models through the study of real machines [11, 13, 15, 22, 25, 27], paper architectures [1, 5, 14, 16, 19], and abstract machines <ref> [21] </ref>. In all of these proposals, the scheduling of threads is viewed as a property of the machine, invisible to the compiler. <p> We refer to a frame and the set of threads executed relative to the frame as an activation. The basics of this parallel call scenario are well described in the literature <ref> [5, 9, 21] </ref>. To allow greater parallelism and to support languages with non-strict function call semantics, 2 the arguments to a code-block may be delivered asynchronously; each will initiate an execution thread within the code-block. An activation is enabled if its frame contains any enabled threads. <p> Furthermore, it remains resident and executing until no enabled threads for the activation remain. The set of threads executed during a single residency is called a quantum. Recognition of this intermediate level of scheduling is a major departure from dataflow oriented execution models, such as ETS [22] and P-Risc <ref> [21] </ref>, and is key to an efficient implementation on conventional machines. A non-resident frame may accumulate several continuations, say as arguments are supplied, and when it becomes active all of these threads are executed, as well as any that they enable. <p> Handling of such a response is usually viewed as a machine primitive. For example, in P-Risc <ref> [21] </ref> an I-structure fetch instruction issues a request to the hardware module containing the location to be read, passing the frame pointer, slot number, and thread pointer. If the location is empty, the request is stored in the memory module until the location is written.
Reference: [22] <author> G. M. Papadopoulos and D. E. Culler. Monsoon: </author> <title> an Explicit Token-Store Architecture. </title> <booktitle> In Proc. of the 17th Annual Int. Symp. on Comp. Arch., </booktitle> <year> 1990. </year>
Reference-contexts: I-structures [6]. On the other hand, asynchronous transfer of control (context switching) is notoriously expensive on current machines, leading many researchers to examine asynchronous parallel execution models through the study of real machines <ref> [11, 13, 15, 22, 25, 27] </ref>, paper architectures [1, 5, 14, 16, 19], and abstract machines [21]. In all of these proposals, the scheduling of threads is viewed as a property of the machine, invisible to the compiler. <p> Furthermore, it remains resident and executing until no enabled threads for the activation remain. The set of threads executed during a single residency is called a quantum. Recognition of this intermediate level of scheduling is a major departure from dataflow oriented execution models, such as ETS <ref> [22] </ref> and P-Risc [21], and is key to an efficient implementation on conventional machines. A non-resident frame may accumulate several continuations, say as arguments are supplied, and when it becomes active all of these threads are executed, as well as any that they enable. <p> When the location is full, the value it contains is sent back to the requesting processor, along with the frame, thread, and slot information. The hardware is expected to interpret this message, store the value in the specified slot and schedule the specified thread. On Monsoon <ref> [22] </ref>, only a frame pointer and instruction pointer need be carried with the request, since the slot number is specified by the instruction. However, this relies on presence-bits associated with each frame slot. <p> Registers vanish at a point of potential suspension. To allow multiple references to frame slots, the hardware must support lists of suspended continuations. Monsoon <ref> [22] </ref> associates presence bits with frame slots, but, when a thread attempts to read an empty slot the value carried on the token is written into the slot and further processing of the instruction is cancelled. <p> P-Risc, which strongly influenced TAM, uses frame slots for synchronization, rather than presence bits, and makes the synchronization operation explicit. However P-Risc does not recognize a storage hierarchy (there are no registers) or scheduling hierarchy (the next thread may come from any frame). Recent dataflow machines <ref> [12, 22, 25] </ref> allow several instructions, i.e., a thread, to be enabled by a single dataflow synchronization. Registers are used to hold values with a lifetime of a single such thread, as these values need never be placed in the frame. <p> The net reduction of synchronization events can be seen in the row labeled aborts which shows the number of unsatisfied entry count decrements, for the TL0 case, and match failures, for the TTDA, as a percentage of the total number of TTDA operations. The recent generation dataflow machines <ref> [12, 22, 25] </ref> all support some form of thread, and the graph partitioning and elimination of redundant arcs used in TL0 compilation could be employed with similar benefits. <p> Split-phase operations on the TTDA are limited to producing a single result, so an identity instruction is introduced to fan-out the result where needed. With the fan-out of nodes in the dataflow graph limited to two, as on Monsoon <ref> [22] </ref>, a much larger number of identities would be required for fan-out. Identity instructions are also introduced where required synchronization is not implicit in the data flow, e.g., determining when an activation is complete. <p> Under a dataflow execution model, the primary form of synchronization is matching pairs of operands. This requires one cycle on an ETS dataflow architecture <ref> [22] </ref> or multiple cycles with a hash-based matching store [15], under the assumption that the matching store and the token queue are maintained in high-speed processor storage. 7 We see that 1.5 tokens are processed per instruction, or one synchronization event for every two instructions, on average.
Reference: [23] <author> C. A. Ruggiero. </author> <title> Throttle Mechanisms for the Manchester Dataflow Machine. </title> <type> PhD thesis, </type> <institution> University of Manchester, </institution> <address> Manchester M13 9PL, England, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: The key observation is that the activation tree and the continuation pool are typically quite large, except on toy programs. This has been demonstrated empirically for programs in Id [8], Sisal <ref> [23] </ref>, and Multilisp [18]. Minimizing the activation tree size while exposing sufficient parallelism is an active area of research, but even with advances in this area we cannot expect the entire activation tree or the entire continuation pool to be maintained in high-speed processor storage.
Reference: [24] <author> R. Saavedra-Barrerra, D. E. Culler, and T. von Eicken. </author> <title> Analysis of Multithreaded Architectures for Parallel Computing. </title> <booktitle> In Proceedings of the 2nd Annual Symp. on Par. Algorithms and Arch., </booktitle> <month> July </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Multithreading at the instruction level may provide the key to general purpose parallel computing [26], because it allows the processor to tolerate long, unpredictable communication latency <ref> [2, 4, 17, 24, 29] </ref>. In addition, this level of multithreading is required to support certain modern parallel programming languages [28], such as Id [20] and Multilisp [18], and extensions of more conventional languages with synchronizing data structures, e.g. I-structures [6].
Reference: [25] <author> S. Sakai, Y. Yamaguchi, K. Hiraki, Y. Kodama, and T. Yuba. </author> <title> An Architecture of a Dataflow Single Chip Processor. </title> <booktitle> In Proc. of the 16th Annual Int. Symp. on Comp. Arch., </booktitle> <pages> pages 46-53, </pages> <address> Jerusalem, Israel, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: I-structures [6]. On the other hand, asynchronous transfer of control (context switching) is notoriously expensive on current machines, leading many researchers to examine asynchronous parallel execution models through the study of real machines <ref> [11, 13, 15, 22, 25, 27] </ref>, paper architectures [1, 5, 14, 16, 19], and abstract machines [21]. In all of these proposals, the scheduling of threads is viewed as a property of the machine, invisible to the compiler. <p> P-Risc, which strongly influenced TAM, uses frame slots for synchronization, rather than presence bits, and makes the synchronization operation explicit. However P-Risc does not recognize a storage hierarchy (there are no registers) or scheduling hierarchy (the next thread may come from any frame). Recent dataflow machines <ref> [12, 22, 25] </ref> allow several instructions, i.e., a thread, to be enabled by a single dataflow synchronization. Registers are used to hold values with a lifetime of a single such thread, as these values need never be placed in the frame. <p> The net reduction of synchronization events can be seen in the row labeled aborts which shows the number of unsatisfied entry count decrements, for the TL0 case, and match failures, for the TTDA, as a percentage of the total number of TTDA operations. The recent generation dataflow machines <ref> [12, 22, 25] </ref> all support some form of thread, and the graph partitioning and elimination of redundant arcs used in TL0 compilation could be employed with similar benefits.
Reference: [26] <author> B. Smith. </author> <title> Keynote address. </title> <booktitle> 17th Annual Int. Symp. on Comp. Arch., </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Multithreading at the instruction level may provide the key to general purpose parallel computing <ref> [26] </ref>, because it allows the processor to tolerate long, unpredictable communication latency [2, 4, 17, 24, 29].
Reference: [27] <author> M. R. Thistle and B. J. Smith. </author> <title> A Processor Architecture for Horizon. </title> <booktitle> In Proc. of Supercomputing '88, </booktitle> <pages> pages 35-41, </pages> <address> Orlando, FL, </address> <year> 1988. </year>
Reference-contexts: I-structures [6]. On the other hand, asynchronous transfer of control (context switching) is notoriously expensive on current machines, leading many researchers to examine asynchronous parallel execution models through the study of real machines <ref> [11, 13, 15, 22, 25, 27] </ref>, paper architectures [1, 5, 14, 16, 19], and abstract machines [21]. In all of these proposals, the scheduling of threads is viewed as a property of the machine, invisible to the compiler. <p> Also, the set of enabled threads is maintained in a special hardware token queue. Several multithreaded architectures have been proposed as generalizations of conventional single-threaded machines, with registers sets (i.e., frames) multiplexed to hide memory and communication latency <ref> [1, 14, 17, 27, 29] </ref>. In most cases, only one thread of execution per frame is supported. Thus, each outstanding reference has an entire register set standing idle behind it.
Reference: [28] <author> K. R. Traub. </author> <title> Sequential Implementation of Lenient Programming Languages. </title> <type> Technical Report TR-417, </type> <institution> MIT Lab for Comp. Sci., </institution> <type> 545 Tech. </type> <institution> Square, </institution> <address> Cambridge, MA, </address> <month> September </month> <year> 1988. </year> <type> (PhD Thesis, </type> <institution> Dept. of EECS, MIT). </institution>
Reference-contexts: 1 Introduction Multithreading at the instruction level may provide the key to general purpose parallel computing [26], because it allows the processor to tolerate long, unpredictable communication latency [2, 4, 17, 24, 29]. In addition, this level of multithreading is required to support certain modern parallel programming languages <ref> [28] </ref>, such as Id [20] and Multilisp [18], and extensions of more conventional languages with synchronizing data structures, e.g. I-structures [6]. <p> Thread Partitioning: Although the partitioner is primitive compared to the theoretical state-of-the-art <ref> [28] </ref>, thread sizes (I =T ) are close to typical branch distances, which provides an upper bound given that fork is the only form of control transfer. The observed thread sizes are comparable to run lengths reported for hybrid dataflow machines, where conditionals were treated as strict [16].
Reference: [29] <author> W. Weber and A. Gupta. </author> <title> Exploring the Benefits of Multiple Hardware Contexts in a Multiprocessor Architecture: Preliminary Results. </title> <booktitle> In Proc. of the 16th Int. Symp. on Comp. Arch., </booktitle> <pages> pages 273-280, </pages> <address> Jerusalem, Israel, </address> <month> May </month> <year> 1989. </year> <month> 18 </month>
Reference-contexts: 1 Introduction Multithreading at the instruction level may provide the key to general purpose parallel computing [26], because it allows the processor to tolerate long, unpredictable communication latency <ref> [2, 4, 17, 24, 29] </ref>. In addition, this level of multithreading is required to support certain modern parallel programming languages [28], such as Id [20] and Multilisp [18], and extensions of more conventional languages with synchronizing data structures, e.g. I-structures [6]. <p> Also, the set of enabled threads is maintained in a special hardware token queue. Several multithreaded architectures have been proposed as generalizations of conventional single-threaded machines, with registers sets (i.e., frames) multiplexed to hide memory and communication latency <ref> [1, 14, 17, 27, 29] </ref>. In most cases, only one thread of execution per frame is supported. Thus, each outstanding reference has an entire register set standing idle behind it.
References-found: 29

