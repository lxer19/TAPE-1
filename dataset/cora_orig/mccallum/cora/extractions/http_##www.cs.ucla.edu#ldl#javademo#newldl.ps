URL: http://www.cs.ucla.edu/ldl/javademo/newldl.ps
Refering-URL: http://www.cs.ucla.edu/ldl/ldl_intro.html
Root-URL: http://www.cs.ucla.edu
Title: An Overview of LDL A Second-Generation Deductive Database System  
Author: N. Arni, K. Ong, S. Tsur, and C. Zaniolo 
Abstract: The expanding role of intelligent information systems and a new wave of database applications are creating a strong demand for database-centered programming environments. In response to this demand, deductive database systems support complex queries and reasoning, rule-based programming and the integration of databases with knowledge bases. The LDL and LDL ++ systems are the two prototypes produced by a leading research project in this area. This paper focuses on the second system that was shaped by the experience gained with its predecessor and recent research advances in the field. The LDL ++ system features a better integration with external databases, a new execution model, and various language extensions to support non-deterministic and non-monotonic programming.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Natraj A., S. Greco and D. </author> <booktitle> Sacca "Set-Term Matching in Logic Programming" in Proc. 4th International Conference on Database Theory, </booktitle> <address> ICDT 92, Berlin, Germany, </address> <pages> pp. 436-449 </pages>
Reference-contexts: the type of node. 1 ESS, a "Extensible Services Switch" developed in the CARNOT project at MCC, supports RDA interface to several databases on a network 2 Similar to a C++ virtual function 6 Some interesting techniques used in the implementation of LDL ++ include novel implementation techniques for sets <ref> [1] </ref> and a stream-oriented execution. Because of space limitations, we will only discuss the second item. Stream-Oriented Processing LDL ++ adopts a lazy evaluation approach (pipelin-ing) as its primary execution model.
Reference: [2] <author> Bancilhon, F.D., Maier D., Sagiv, Y. and Ullman, J. </author> <title> "Magic Sets and Other Strange Ways to Implement Logic Programs," </title> <booktitle> in Proc. SIGACT-SIGMOD Principles of Database Systems Conference (PODS), </booktitle> <year> 1986. </year>
Reference-contexts: Then, for each query form, the compiler performs a bound-free analysis on the arguments of the predicates, annotating these predicates with adornments and checking the safety of the queries in the process. The compiler also performs the rewriting of recursive rules using various techniques, including the Magic Sets method <ref> [2] </ref> and specialized methods applicable to linear programs [20, 24]. These rewriting techniques result in an efficient execution plan for queries. Unification is also performed as part of this compilation process, resulting in the sharing of variables between predicates, to minimize the assignments required for execution.
Reference: [3] <editor> Chimenti, D. et al., </editor> <title> "The LDL System Prototype," </title> <journal> IEEE Journal on Data and Knowledge Engineering, </journal> <volume> vol. 2, no. 1, </volume> <pages> pp. 76-90, </pages> <month> March </month> <year> 1990. </year> <month> 10 </month>
Reference-contexts: 1 Introduction The design of the LDL ++ prototype was inspired by the experience with the LDL prototype <ref> [3] </ref>, which was completed in 1989 and tested and deployed in many applications [17, 18, 19]. This paper focuses on progress past the LDL system that has already been described in previous papers. <p> In particular, the LDL language and its semantics, along with the theory that underlies its design, are described in [9]; a detailed description of the technology and architecture for the first LDL prototype is presented in <ref> [3] </ref>. The experience with the first-generation prototype resulted in substantial feedback by users and opportunities for critical re-evaluation of design choices. In the meantime, much technical progress occurred in the deductive database area. <p> Using ESS, LDL ++ can link with additional relational databases and some SQL-like interfaces to O-O databases. 3 Compilation and Execution The approach followed by the LDL ++ compiler is similar of that followed in <ref> [3] </ref>. Thus, the compiler reads-in programs and constructs the Global Predicate Connection Graph (PCG). Then, for each query form, the compiler performs a bound-free analysis on the arguments of the predicates, annotating these predicates with adornments and checking the safety of the queries in the process. <p> Instead, we have to jump back to b1 for a new value of A. An eager approach will instead generate all B-values for this A, even they cannot satisfy b2. Some of these optimizations were already supported in LDL <ref> [3] </ref> which used pipelin-ing in some restricted situations. For recursive predicates however, LDL followed the usual seminaive fixpoint procedure, that uses the immediate consequence operator for eagerly computing all the immediate consequences [9].
Reference: [4] <author> A. Van Gelder, K.A. Ross, and J.S. Schlipf. </author> <title> The well-founded semantics for general logic programs. </title> <journal> Journal of ACM, </journal> <volume> 38(3) </volume> <pages> 620-650, </pages> <year> 1991. </year>
Reference-contexts: The problem of going beyond stratification represents in fact a difficult research challenge, with contributions and ideas coming from the areas of AI, non-monotonic logic and deductive databases. Among the most important notions, we find the concepts of well-founded models <ref> [4] </ref> and stable models [5], which provide a declarative semantics for most programs of practical interest. Formal declarative semantics, however, only represents one of the requirements that must be satisfied before non-monotonic programs can be allowed in the recursive rules of the language.
Reference: [5] <author> M. Gelfond and V. Lifschitz. </author> <title> The stable model semantics of logic programming. </title> <booktitle> In Proc. Fifth Int. Conference on Logic Programming, </booktitle> <pages> pp. 1070-1080, </pages> <year> 1988. </year>
Reference-contexts: The problem of going beyond stratification represents in fact a difficult research challenge, with contributions and ideas coming from the areas of AI, non-monotonic logic and deductive databases. Among the most important notions, we find the concepts of well-founded models [4] and stable models <ref> [5] </ref>, which provide a declarative semantics for most programs of practical interest. Formal declarative semantics, however, only represents one of the requirements that must be satisfied before non-monotonic programs can be allowed in the recursive rules of the language.
Reference: [6] <author> Giannotti, F. Pedreschi, D., Sacca, D., and C. Zaniolo. </author> <title> Non-determinism in deductive databases. </title> <booktitle> In Proc. 2nd Int. Conf. on Deductive and Object-Oriented Databases, </booktitle> <year> 1991. </year>
Reference-contexts: These problems were avoided by using instead a semantics based on the use of negation and stable models <ref> [6] </ref>.
Reference: [7] <author> Giannotti, F., S. Greco, D. Sacca and C. Zaniolo, </author> <booktitle> "Programming with Non-determinism in Deductive Databases" Annals of Artificial Intelligence and Mathematics, </booktitle> <volume> Vol. 19, No, 3/4, </volume> <month> April </month> <year> 1997. </year>
Reference-contexts: ordered d (root; root): ordered d (X; Y) ordered d ( ; X); d (Y); choice ((X); (Y)); choice ((Y); (X)): 9 Therefore using choice and stratified negation it is possible to express all algo-rithms that can be computed in time which is polynomial in the size of the database <ref> [7] </ref>.
Reference: [8] <author> R. Krishnamurthy and S. Naqvi. </author> <title> "Non-deterministic choice in Datalog," </title> <booktitle> In Proceedings of the 3rd International Conference on Data and Knowledge Bases, </booktitle> <year> 1988. </year>
Reference-contexts: The formal semantics of both constructs is based on stable models. Because of limited space, we will not discuss XY-stratification [21], and concentrate instead on the non-deterministic choice construct. The idea of choice was introduced in <ref> [8] </ref> to express non-determinism in a declarative fashion. Thus, a construct 8 such as choice ((X); (Y)) is used to denote that the functional dependency X ! Y must hold in the model defining the meaning of this program. <p> In LDL, this very powerful construct was disallowed in recursion, inasmuch as the functional-dependency based semantics proposed in <ref> [8] </ref> suffers from technical problems such as a lack of justifiability property and its unsuitability to efficient implementation due to its static nature [15]. These problems were avoided by using instead a semantics based on the use of negation and stable models [6].
Reference: [9] <author> S. A. Naqvi, S. </author> <title> Tsur "A Logical Language for Data and Knowledge Bases", </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <year> 1989. </year>
Reference-contexts: This paper focuses on progress past the LDL system that has already been described in previous papers. In particular, the LDL language and its semantics, along with the theory that underlies its design, are described in <ref> [9] </ref>; a detailed description of the technology and architecture for the first LDL prototype is presented in [3]. The experience with the first-generation prototype resulted in substantial feedback by users and opportunities for critical re-evaluation of design choices. In the meantime, much technical progress occurred in the deductive database area. <p> Some of these optimizations were already supported in LDL [3] which used pipelin-ing in some restricted situations. For recursive predicates however, LDL followed the usual seminaive fixpoint procedure, that uses the immediate consequence operator for eagerly computing all the immediate consequences <ref> [9] </ref>. LDL ++ instead supports lazy computation of fixpoints, through the consumer/producer architecture where the 7 goals calling recursive predicates act as consumers and the recursive clique acts as a producer.
Reference: [10] <author> Phipps, G., M.A., Derr and K. A. Ross, </author> <title> "Glue-Nail: a Deductive Database System," </title> <booktitle> Proc. 1991 ACM-SIGMOD Conference on Management of Data, </booktitle> <pages> pp. </pages> <month> 308-317 </month> <year> (1991). </year>
Reference-contexts: Thus only data is duplicated|rather than both code and data as in LDL. 3.1 Language Extensions A very useful new construct supported in LDL ++ is meta-level predicates, which were given a first order semantics along the lines described in <ref> [10] </ref>. Furthermore, LDL ++ supports non-stratified negation (and set-aggregates) and supports powerful non-deterministic constructs, providing novel solutions to the semantics problems connected with these concepts.
Reference: [11] <author> Ong, K., N. Arni, C. Tomlinson, Unnikrishnan, and D. Woelk, </author> <title> "A Deductive Database Solution to Intelligent Information Retrieval from Legacy Databases", </title> <booktitle> Proc. of 4th International Conference on Database Systems for Advanced Applications, </booktitle> <month> April, </month> <year> 1995. </year>
Reference-contexts: Indeed, recent progress makes it possible to have a system that integrates active database rules with deductive rules, and supports in a unified framework temporal reasoning, spatial reasoning and reasoning in the presence of uncertainty. Furthermore, important application areas are now emerging for this technology, including middleware systems <ref> [11] </ref> and knowledge discovery [16]. Ideally, this combination of application pull and technology push will soon produce a new-generation of deductive database systems that take us beyond the current LDL ++ and its second-generation technology.
Reference: [12] <author> R. Ramakrishnan. </author> <title> Applications of Logic Databases. </title> <publisher> Kluwer Academic Publisher, </publisher> <year> 1995. </year>
Reference-contexts: Furthermore, the deployment of the LDL ++ prototype in various applications has much contributed to proving the unique advantages offered by deductive databases in several domains <ref> [18, 19, 12] </ref>. Future evolution of the field could be shaped by various advances that have taken place after the completion of the LDL ++ prototype.
Reference: [13] <author> R. Ramakrisnhan, D. Srivastava, and S. Sudanshan, "CORAL-Control, </author> <title> Relations and Logic," </title> <booktitle> Proceedings of the 18th VLDB Conference, </booktitle> <year> 1992. </year>
Reference: [14] <author> Jayen Vaghani, Kotagiri Ramamohanarao, David B. Kemp, Zoltan Somogyi, Peter J. Stuckey, Tim S. Leask, James Harland, </author> <title> "The Aditi Deductive Database System," </title> <journal> VLDB Journal Vol. </journal> <volume> 3, </volume> <pages> No.2, pp. </pages> <month> 245-288 </month> <year> (1994) </year>
Reference-contexts: For instance, some deductive database prototypes include a secondary-store based record manager and internal DBMS <ref> [14] </ref>, others rely on external DBMSs as their record managers. The LDL application experience, particularly in a middle-ware role, confirmed the desirability of an architecture based on (i) an internal (fast-path) database and (ii) a transparent connection with multiple external DBMSs.
Reference: [15] <author> Sacca, D., and Zaniolo, C., </author> <title> "Stable models and non determinism in logic programs with negation", </title> <booktitle> Proc. 9th, ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <pages> pp. 205-218, </pages> <year> 1990. </year>
Reference-contexts: In LDL, this very powerful construct was disallowed in recursion, inasmuch as the functional-dependency based semantics proposed in [8] suffers from technical problems such as a lack of justifiability property and its unsuitability to efficient implementation due to its static nature <ref> [15] </ref>. These problems were avoided by using instead a semantics based on the use of negation and stable models [6].
Reference: [16] <author> Shen, W., K.Ong, B. Mitbander and C. Zaniolo, </author> <title> "Metaqueries for Data Mining," Chapter 15 of Advances in Knowledge Discovery and Data Mining, </title> <editor> U. M. Fayyad et al (eds.), </editor> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: Furthermore, important application areas are now emerging for this technology, including middleware systems [11] and knowledge discovery <ref> [16] </ref>. Ideally, this combination of application pull and technology push will soon produce a new-generation of deductive database systems that take us beyond the current LDL ++ and its second-generation technology.
Reference: [17] <author> Tryon, D. </author> <title> "Deductive Computing: </title> <booktitle> Living in the Future," Proc. of the Monterey Software Conference, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: 1 Introduction The design of the LDL ++ prototype was inspired by the experience with the LDL prototype [3], which was completed in 1989 and tested and deployed in many applications <ref> [17, 18, 19] </ref>. This paper focuses on progress past the LDL system that has already been described in previous papers.
Reference: [18] <author> Tsur, S., </author> <title> `Deductive Databases in Action,' </title> <booktitle> Proc. 10th, ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <pages> pp. 205-218, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction The design of the LDL ++ prototype was inspired by the experience with the LDL prototype [3], which was completed in 1989 and tested and deployed in many applications <ref> [17, 18, 19] </ref>. This paper focuses on progress past the LDL system that has already been described in previous papers. <p> Furthermore, the deployment of the LDL ++ prototype in various applications has much contributed to proving the unique advantages offered by deductive databases in several domains <ref> [18, 19, 12] </ref>. Future evolution of the field could be shaped by various advances that have taken place after the completion of the LDL ++ prototype.
Reference: [19] <author> Tsur, S., </author> <title> "Data Dredging," </title> <journal> Data Engineering, </journal> <volume> Vol. 13, No. 4, </volume> <publisher> IEEE Computer Society, </publisher> <month> Dec. 90. </month>
Reference-contexts: 1 Introduction The design of the LDL ++ prototype was inspired by the experience with the LDL prototype [3], which was completed in 1989 and tested and deployed in many applications <ref> [17, 18, 19] </ref>. This paper focuses on progress past the LDL system that has already been described in previous papers. <p> Furthermore, the deployment of the LDL ++ prototype in various applications has much contributed to proving the unique advantages offered by deductive databases in several domains <ref> [18, 19, 12] </ref>. Future evolution of the field could be shaped by various advances that have taken place after the completion of the LDL ++ prototype.
Reference: [20] <author> Ullman, J.D., </author> <title> "Database and Knowledge-Based Systems, Vols. I and II, </title> <publisher> Computer Science Press, </publisher> <address> Rockville, Md., </address> <year> 1989. </year>
Reference-contexts: The compiler also performs the rewriting of recursive rules using various techniques, including the Magic Sets method [2] and specialized methods applicable to linear programs <ref> [20, 24] </ref>. These rewriting techniques result in an efficient execution plan for queries. Unification is also performed as part of this compilation process, resulting in the sharing of variables between predicates, to minimize the assignments required for execution.
Reference: [21] <author> Zaniolo, C., N. Arni, and K. Ong, </author> <title> "Negation and Aggregates in Recursive Rules: the LDL ++ Approach," Procs. </title> <booktitle> Third Int. Conference on Deductive and Object-Oriented Databases, </booktitle> <month> Dec. </month> <pages> 6-8, </pages> <address> 1993, Scottsdale, Arizona. </address>
Reference-contexts: In fact, LDL ++ support the choice construct for non-deterministic programming and the concept of XY -stratification that allows for negation and set aggregates in recursive rules. The formal semantics of both constructs is based on stable models. Because of limited space, we will not discuss XY-stratification <ref> [21] </ref>, and concentrate instead on the non-deterministic choice construct. The idea of choice was introduced in [8] to express non-determinism in a declarative fashion. <p> This operational semantics is also the basis for efficient implementations of the construct. Likewise, the notion of XY-stratification <ref> [21] </ref> a combination of formal non-monotonic semantics, intuitive appeal and amenability to efficient implementations are the ingredients that allow the relaxation of the stratification requirement in LDL ++ 4 Conclusions and Future Directions The realization of the LDL ++ prototype, a second-generation system, demonstrates the significant progress recently made by deductive
Reference: [22] <author> Zaniolo, C., </author> <title> Intelligent Databases: Old Challenges and New Opportunities, </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> 1, </volume> <month> 271-292 </month> <year> (1992). </year>
Reference: [23] <author> Zaniolo, C., </author> <title> "A Unified Semantics for Active and Deductive Databases,", Procs. Workshop on Rules In Database Systems (RIDS93), </title> <publisher> Springer Ferlag 94. </publisher>
Reference: [24] <author> Zaniolo, C., S. Ceri, C. Faloutsos, R. Snodgrass, V. Subrahamanian and R. Zicari, </author> <title> "Introduction to Advanced Database Systems," </title> <publisher> Morgan Kaufmann, </publisher> <year> 1997. </year> <month> 11 </month>
Reference-contexts: The compiler also performs the rewriting of recursive rules using various techniques, including the Magic Sets method [2] and specialized methods applicable to linear programs <ref> [20, 24] </ref>. These rewriting techniques result in an efficient execution plan for queries. Unification is also performed as part of this compilation process, resulting in the sharing of variables between predicates, to minimize the assignments required for execution.
References-found: 24

