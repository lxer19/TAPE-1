URL: http://www.cs.cmu.edu/~chrislee/hmm-icra96.ps.gz
Refering-URL: http://www.cs.cmu.edu/~chrislee/publications.html
Root-URL: http://www.cs.cmu.edu
Title: Online, Interactive Learning of Gestures for Human/Robot Interfaces  
Author: Christopher Lee and Yangsheng Xu 
Address: Pittsburgh, Pennsylvania 15213, USA  
Affiliation: The Robotics Institute Carnegie Mellon University  
Abstract: We have developed a gesture recognition system, based on Hidden Markov Models, which can interactively recognize gestures and perform online learning of new gestures. In addition, it is able to update its model of a gesture iteratively with each example it recognizes. This system has demonstrated reliable recognition of 14 different gestures after only one or two examples of each. The system is currently interfaced to a Cyberglove for use in recognition of gestures from the sign language alphabet. The system is being implemented as part of an interactive interface for robot teleoperation and programming by example. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. P. Tung and A. C. Kak, </author> <title> "Automatic learning of assembly tasks using a dataglove system," </title> <booktitle> in Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems, </booktitle> <pages> pp. 1-8, </pages> <year> 1995. </year>
Reference-contexts: In this methodology, a robot learns to perform a task by observing a human teacher. Much effort is being directed toward the research of systems for gesture/observation-based programming of robot systems. Tung and Kak <ref> [1] </ref> demonstrate automatic learning of robot tasks through a DataGlove interface. Kang and Ikeuchi [2] developed a system for simple task learning by human demonstration. Voyles [3] developed a system for gesture-based programming via a multi-agent model.
Reference: [2] <author> S. B. Kang and K. </author> <title> Ikeuchi, "Robot task programming by human demonstration," </title> <booktitle> in Proceedings of the Image Understanding Workshop, </booktitle> <year> 1994. </year>
Reference-contexts: In this methodology, a robot learns to perform a task by observing a human teacher. Much effort is being directed toward the research of systems for gesture/observation-based programming of robot systems. Tung and Kak [1] demonstrate automatic learning of robot tasks through a DataGlove interface. Kang and Ikeuchi <ref> [2] </ref> developed a system for simple task learning by human demonstration. Voyles [3] developed a system for gesture-based programming via a multi-agent model. One capability which is currently lacking in systems such as these is a mechanism for online teaching of gestures with symbolic meanings.
Reference: [3] <author> R. Voyles, </author> <title> "Tactile gestures for human/robot interaction," </title> <booktitle> in Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems, </booktitle> <year> 1995. </year>
Reference-contexts: Much effort is being directed toward the research of systems for gesture/observation-based programming of robot systems. Tung and Kak [1] demonstrate automatic learning of robot tasks through a DataGlove interface. Kang and Ikeuchi [2] developed a system for simple task learning by human demonstration. Voyles <ref> [3] </ref> developed a system for gesture-based programming via a multi-agent model. One capability which is currently lacking in systems such as these is a mechanism for online teaching of gestures with symbolic meanings.
Reference: [4] <author> L. R. Rabiner and B. H. Juang, </author> <title> "An introduction to hidden markov models," </title> <journal> IEEE ASSP Magazine, </journal> <pages> pp. 4-16, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: The next time the user performs that gesture, the system should recognize it and immediately halt the motion of the robot. 4 Recognition and Learning with HMMs Hidden Markov Models <ref> [4] </ref> are commonly used for speech recognition, but have also been used for characterizing task information and human skills for transfer to robots in telerobotic applications [5, 6]. A Hidden Markov Model is a representation of a Markov process which cannot be directly observed (a "doubly stochastic" system). <p> The third component of a Hidden Markov Model is a vector indicating the distribution of probability that any given state is the initial state of the hidden Markov process. There are three problems commonly associated with Hidden Markov models <ref> [4] </ref>: (1) determining the probability with which a given sequence of observable symbols would be generated by an HMM, (2) determining the most likely sequence of internal states in a given HMM which would have given rise to a given sequence of observable symbols, and (3) generating an HMM that best
Reference: [5] <author> J. Yang, Y. Xu, and C. Chen, </author> <title> "Hidden markov model approach to skill learning and its application in telerobotics," </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> vol. 10, no. 5, </volume> <pages> pp. 621-631, </pages> <year> 1994. </year>
Reference-contexts: that gesture, the system should recognize it and immediately halt the motion of the robot. 4 Recognition and Learning with HMMs Hidden Markov Models [4] are commonly used for speech recognition, but have also been used for characterizing task information and human skills for transfer to robots in telerobotic applications <ref> [5, 6] </ref>. A Hidden Markov Model is a representation of a Markov process which cannot be directly observed (a "doubly stochastic" system). The discrete form of the HMM is represented by three matrices, = (A; B; ).
Reference: [6] <author> Y. Xu and J. Yang, </author> <title> "Towards human-robot coordination: skill modeling and transferring via hidden markov model," </title> <booktitle> in Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1906-1911, </pages> <year> 1995. </year>
Reference-contexts: that gesture, the system should recognize it and immediately halt the motion of the robot. 4 Recognition and Learning with HMMs Hidden Markov Models [4] are commonly used for speech recognition, but have also been used for characterizing task information and human skills for transfer to robots in telerobotic applications <ref> [5, 6] </ref>. A Hidden Markov Model is a representation of a Markov process which cannot be directly observed (a "doubly stochastic" system). The discrete form of the HMM is represented by three matrices, = (A; B; ).
Reference: [7] <author> A. Gersho, </author> <title> "On the structure of vector quantizers," </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. IT-28, no. 2, </volume> <pages> pp. 157-166, </pages> <year> 1982. </year>
Reference-contexts: K = argmin (c k a)). The code-book is a set of vectors which is believed to be representative of the domain of vectors to be encoded. We generate this codebook using the LBG algorithm <ref> [7] </ref> on a representative sample of gesture data. Codebook generation is an o*ine process. Because the preprocessor is coded as a data filter, a symbol is sent to the gesture-recognition system as soon as enough data has been read from the glove to generate it.
Reference: [8] <author> S. S. Fels and G. E. Hinton, "Glove-talk: </author> <title> A neural network interface between a data-glove and a speech synthesizer," </title> <journal> IEEE Transations on Neural Networks, </journal> <volume> vol. 4, </volume> <pages> pp. 2-8, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: The number of gestures we can classify this accurately is currently limited by the number of observable symbols the preprocessor generates. Thus at this time, systems which perform o*ine training now can recognize a larger gesture vocabulary. Fels and Hinton <ref> [8] </ref>, for example, use o*ine-trained neural networks to recognize 66 root words, each with up to 6 endings.
References-found: 8

