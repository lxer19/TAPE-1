URL: http://rakaposhi.eas.asu.edu/aaai-ddb-sent.ps
Refering-URL: http://rakaposhi.eas.asu.edu/yochan.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: rao@asu.edu  
Title: Formalizing Dependency Directed Backtracking and Explanation Based Learning in Refinement Search  
Author: Subbarao Kambhampati 
Address: Tempe, AZ 85287,  
Affiliation: Department of Computer Science and Engineering Arizona State University,  
Abstract: The ideas of dependency directed backtracking (DDB) and explanation based learning (EBL) have developed independently in constraint satisfaction, planning and problem solving communities. In this paper, I formalize and unify these ideas under the task-independent framework of refinement search, which can model the search strategies used in both planning and constraint satisfaction. I show that both DDB and EBL depend upon the common theory of explaining search failures, and regressing them to higher levels of the search tree. The relevant issues of importance include (a) how the failures are explained and (b) how many failure explanations are remembered. This task-independent understanding of DDB and EBL helps support cross-fertilization of ideas among Constraint Satisfaction, Planning and Explanation-Based Learning communities. 
Abstract-found: 1
Intro-found: 1
Reference: [ 1 ] <author> N. Bhatnagar and J. Mostow. </author> <title> On-line Learning From Search Failures Machine Learning, </title> <journal> Vol. </journal> <volume> 15, </volume> <pages> pp. 69-117, </pages> <year> 1994. </year>
Reference-contexts: However, there is a considerable confusion and variation regarding the various implementations of dependency directed backtracking. Complicating the picture further is the fact that many ``speedup learning'' algorithms that learn from failure (c.f. <ref> [ 10; 1; 9 ] </ref> ), do analyses that are quite close to the type of analysis done in the dependency directed backtracking algorithms.
Reference: [ 2 ] <author> L. Daniel. </author> <title> Planning: Modifying non-linear plans University Of Edinburgh, </title> <note> DAI Working Paper: 24 </note>
Reference-contexts: Intelligent backtracking techniques in planning include the ``context'' based backtracking search used in Wilkin's SIPE [ 18 ] , and the decision graphs used by Daniels et. al. to support intelligent backtracking in Nonlin <ref> [ 2 ] </ref> . The decision graphs and contexts explicitly keep track of the dependencies between the constraints in the plan, and the decisions that were taken on the plan. These structures are then used to facilitate DDB.
Reference: [ 3 ] <author> R. Dechter. </author> <title> Enhancement schemes for learning: Back-jumping, learning and cutset decomposition. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 41, </volume> <pages> pp. 273-312, </pages> <year> 1990. </year>
Reference-contexts: Lack of a coherent framework has had ramifications on the research efforts on DDB and EBL. For example, the DDB and speedup learning techniques employed in planning and problem solving on one hand [ 10 ] , and CSP on the other <ref> [ 3; 17 ] </ref> , have hither-to been incomparable. <p> Storing the failure explanations and/or search control rules learned at all interior nodes could be very expensive from the storage and matching cost points of view. CSP, and machine learning literatures took differing approaches to this problem. Researchers in CSP (e.g. <ref> [ 3; 17 ] </ref> ) concentrated on the syntactic characteristics of the nogoods, such as their size and minimality, to decide whether or not they should be stored. <p> Dechter <ref> [ 3 ] </ref> shows that computing the minimal explanations does not necessarily pay off in terms of improved performance.
Reference: [ 4 ] <author> D. Frost and R. Dechter. </author> <title> Dead-end driven learning. </title> <booktitle> In Proc. AAAI-94, </booktitle> <year> 1994. </year>
Reference: [ 5 ] <author> M. Ginsberg and D. McAllester. </author> <title> GSAT and Dynamic Backtracking. </title> <booktitle> In Proc. </booktitle> <address> KRR, </address> <year> 1994. </year>
Reference-contexts: For example, CSP approaches could benefit from the results of research on utility of EBL, and planning research could benefit from the improved backtracking algorithms being developed for CSP <ref> [ 5 ] </ref> .
Reference: [ 6 ] <author> J .Gratch and G. DeJong COMPOSER: </author> <title> A Probabilistic Solution to the Utility problem in Speed-up Learning. </title> <booktitle> In Proc. AAAI 92, </booktitle> <address> pp:235--240, </address> <year> 1992 </year>
Reference-contexts: Since in general, using failure explanations will involve matching the failure explanations (or the antecedents of the search control rules) to the current node, the match cost increases as the number of stored explanations increase. This problem has been termed the EBL Utility Problem in the Machine learning community <ref> [ 11; 6 ] </ref> . <p> in machine learning concentrated instead on approaches that use the distribution of 4 we are assuming that none of the refinement decisions are degenerate; each of the add at least one new constraint to the node. the encountered problems to dynamically modify the stored rules (e.g. by forgetting ineffective rules) <ref> [ 11; 6 ] </ref> . These differences are to some extent caused by the differences in CSP and planning problems. The nogoods learned in CSP problems have traditionally only been used in intra-problem learning, to cut down search in the other branches of the same problem.
Reference: [ 7 ] <author> S. Kambhampati, C. Knoblock and Q. Yang. </author> <title> Planning as Refinement Search: A Unified framework for evaluating design tradeoffs in partial order planning. </title> <journal> Artificial Intelligence special issue on Planning and Scheduling. </journal> <volume> Vol. 76, </volume> <pages> pp/ 167-238. </pages> <year> 1995. </year>
Reference-contexts: To this end, I consider all backtracking and learning algorithms within the context of general refinement search <ref> [ 7 ] </ref> . Refinement search involves starting with the set of all potential solutions for the problem, and repeatedly splitting the set until a solution for the problem can be extracted from one of the sets. <p> The actions are described in terms of preconditions and effects. The solution is any sequence of actions such that executing those actions from the initial state, in that sequence, will lead us to goal state. Search nodes in planning can be represented (see <ref> [ 7 ] </ref> ) as 6-tuples hS; O; B; L; E ; Ci, consisting of a set of steps, orderings, bindings, auxiliary constraints, step effects and step preconditions.
Reference: [ 8 ] <author> S. Kambhampati and B. Srivastava. </author> <title> Universal Classical Planner: An Algorithm for unifying state-space and plan-space planning. </title> <booktitle> In Proc. 3rd European Workshop on Planning Systems, </booktitle> <year> 1995. </year>
Reference-contexts: These constraint sets, called partial plans, are shorthand notations for the set of ground operator sequences that are consistent with the constraints of the partial plan. There are several types of complete refinement operators in planning <ref> [ 8 ] </ref> , including plan space, state-space, and task reduction refinements. As an example, plan-space refinement proceeds by picking a goal condition and considering different ways of making that condition true in different branches.
Reference: [ 9 ] <author> S. Kambhampati, S. Katukam and Y. Qu. </author> <title> Failure driven dynamic search control for partial order planners: An explanation-based approach. </title> <journal> Artificial Intelligence, </journal> <note> Fall 1996. (To appear). </note>
Reference-contexts: However, there is a considerable confusion and variation regarding the various implementations of dependency directed backtracking. Complicating the picture further is the fact that many ``speedup learning'' algorithms that learn from failure (c.f. <ref> [ 10; 1; 9 ] </ref> ), do analyses that are quite close to the type of analysis done in the dependency directed backtracking algorithms. <p> E 0 = d 1 (E 1 ), we can learn a rule which recommends rejection of the decision d whenever E 0 is present in the current node. 3 3 Explanation-based learning normally also involves a generalization step, where the failure explanation is generalized by replacing constants with variables <ref> [ 9 ] </ref> . Although such generalization can be very important in supporting inter-problem transfer, addition of generalization steps does not have a crucial impact on the analysis given in this paper. See [ 9 ] for a comprehensive discussion of the issues involved in explanation generalization. <p> normally also involves a generalization step, where the failure explanation is generalized by replacing constants with variables <ref> [ 9 ] </ref> . Although such generalization can be very important in supporting inter-problem transfer, addition of generalization steps does not have a crucial impact on the analysis given in this paper. See [ 9 ] for a comprehensive discussion of the issues involved in explanation generalization. Unlike DDB, whose overheads are generally negligible compared to chronological backtracking, learning failure explanations through EBL has two types of hidden costs. First, there is the storage cost. <p> We shall review various approaches to it later. 3.1 Example Let me illustrate the DDB and EBL process above with a simple CSP example shown in Figure 6 (for a planning example that follows the same formalism, see the discussion of UCPOP-EBL in <ref> [ 9 ] </ref> ). The problem contains five variables, l; x; y; u; v and w. The domains of the variables and the constraints on the variable values are shown in the figure. The figure shows a series of refinements culminating in node N5, which is a failure node.
Reference: [ 10 ] <author> S. Minton, J.G Carbonell, C.A. Knoblock, D.R. Kuokka, O. Etzioni and Y. Gil. </author> <title> Explanation-Based Learning: A Problem Solving Perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40:63-- 118, </volume> <year> 1989. </year>
Reference-contexts: However, there is a considerable confusion and variation regarding the various implementations of dependency directed backtracking. Complicating the picture further is the fact that many ``speedup learning'' algorithms that learn from failure (c.f. <ref> [ 10; 1; 9 ] </ref> ), do analyses that are quite close to the type of analysis done in the dependency directed backtracking algorithms. <p> Lack of a coherent framework has had ramifications on the research efforts on DDB and EBL. For example, the DDB and speedup learning techniques employed in planning and problem solving on one hand <ref> [ 10 ] </ref> , and CSP on the other [ 3; 17 ] , have hither-to been incomparable. <p> A variation of this approach involves learning search control rules <ref> [ 10 ] </ref> which recommend rejection of individual decisions of a refinement operator if they will lead to failure.
Reference: [ 11 ] <author> S. Minton. </author> <title> Quantitative Results Concerning the Utility of Explanation Based Learning. </title> <journal> Artificial Intelligence, </journal> <volume> 42:363-- 391, </volume> <year> 1990. </year>
Reference-contexts: Since in general, using failure explanations will involve matching the failure explanations (or the antecedents of the search control rules) to the current node, the match cost increases as the number of stored explanations increase. This problem has been termed the EBL Utility Problem in the Machine learning community <ref> [ 11; 6 ] </ref> . <p> in machine learning concentrated instead on approaches that use the distribution of 4 we are assuming that none of the refinement decisions are degenerate; each of the add at least one new constraint to the node. the encountered problems to dynamically modify the stored rules (e.g. by forgetting ineffective rules) <ref> [ 11; 6 ] </ref> . These differences are to some extent caused by the differences in CSP and planning problems. The nogoods learned in CSP problems have traditionally only been used in intra-problem learning, to cut down search in the other branches of the same problem.
Reference: [ 12 ] <author> N.J. Nilsson. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga, </publisher> <address> Palo Alto, </address> <year> 1980. </year>
Reference-contexts: that must be present in the partial plan before the decision d, such that c is present after taking the decision. 1 Regression of this type is typically studied in planning in conjunction with backward application of STRIPS-type operators (with add, delete, and precondition lists), and is quite well-understood (see <ref> [ 12 ] </ref> ).
Reference: [ 13 ] <author> J. Pearl. </author> <title> Heuristics: Intelligent Search Strategies for Computer Problem Solving. </title> <publisher> Addison-Wesley (1984). </publisher>
Reference: [ 14 ] <author> C. Petrie. </author> <title> Constrained Decision Revision. </title> <booktitle> In Proc. 10th AAAI, </booktitle> <year> 1992. </year>
Reference-contexts: These structures are then used to facilitate DDB. In a way, decision graphs attempt to solve the same problem that is solved by regression. However, the semantics of decision graphs are often problem dependent, and storing and maintaining them can be quite complex <ref> [ 14 ] </ref> . In contrast, the notion of regression and propagation is problem independent and explicates the dependencies between decisions on an as-needed basis.
Reference: [ 15 ] <author> S. Russell and P. Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference-contexts: It is no wonder then that despite the long acknowledged utility of DDB, even the more comprehensive AI textbooks such as <ref> [ 15 ] </ref> fail to provide a coherent account of dependency directed backtracking. Lack of a coherent framework has had ramifications on the research efforts on DDB and EBL.
Reference: [ 16 ] <author> R. Stallman and G. Sussman. </author> <title> Forward Reasoning and Dependency-directed Backtracking in a System for Computer Aided Circuit Analysis. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 9, </volume> <pages> pp. 135-196. </pages> <year> 1977. </year>
Reference-contexts: 1 Introduction One of the main-stays of AI literature is the idea of ``dependency directed backtracking'' as an antidote for the inefficiencies of chronological backtracking <ref> [ 16 ] </ref> . However, there is a considerable confusion and variation regarding the various implementations of dependency directed backtracking. <p> At this point E (N 4) can be remembered as a learned failure explanation (aka nogood <ref> [ 16 ] </ref> ), and used to prune nodes in other parts of the search tree. Propagation progresses upwards. The decision v D does not affect the explanation N 4, and thus we backtrack over the node N3, without refining it further. Similarly, we also backtrack over N2.
Reference: [ 17 ] <author> E. Tsang. </author> <title> Foundations of Constraint Satisfaction, </title> <publisher> (Academic Press, </publisher> <address> San Diego, California, </address> <year> 1993). </year>
Reference-contexts: Lack of a coherent framework has had ramifications on the research efforts on DDB and EBL. For example, the DDB and speedup learning techniques employed in planning and problem solving on one hand [ 10 ] , and CSP on the other <ref> [ 3; 17 ] </ref> , have hither-to been incomparable. <p> Figure 2 shows how planning and CSP problems can be modeled in terms of refinement search. The next two subsections elaborate this formulation. 2.1 Constraint Satisfaction as Refinement Search A constraint satisfaction problem (CSP) <ref> [ 17 ] </ref> is specified by a set of n variables, X 1 ; X 2 X n , their respective value domains, D 1 ; D 2 D n and a set of constraints. <p> Storing the failure explanations and/or search control rules learned at all interior nodes could be very expensive from the storage and matching cost points of view. CSP, and machine learning literatures took differing approaches to this problem. Researchers in CSP (e.g. <ref> [ 3; 17 ] </ref> ) concentrated on the syntactic characteristics of the nogoods, such as their size and minimality, to decide whether or not they should be stored. <p> This sort of direct correspondence has facilitated specialized versions of DDB algorithm that use ``constraint graphs'' and other syntactic characterizations of a CSP problem to help in deciding which decision to backtrack to <ref> [ 17 ] </ref> . Regression is however important in other refinement search scenarios including planning where there is no one-to-one correspondence between decisions and the constraints in the node. Most CSP systems do not add the flaw description to the interior node explanations.
Reference: [ 18 ] <author> D. Wilkins. </author> <title> Practical Planning. </title> <publisher> Morgan Kaufmann (1988). </publisher>
Reference-contexts: Intelligent backtracking techniques in planning include the ``context'' based backtracking search used in Wilkin's SIPE <ref> [ 18 ] </ref> , and the decision graphs used by Daniels et. al. to support intelligent backtracking in Nonlin [ 2 ] . The decision graphs and contexts explicitly keep track of the dependencies between the constraints in the plan, and the decisions that were taken on the plan.
References-found: 18

