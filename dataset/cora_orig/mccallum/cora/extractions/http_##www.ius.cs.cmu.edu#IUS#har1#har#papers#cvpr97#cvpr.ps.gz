URL: http://www.ius.cs.cmu.edu/IUS/har1/har/papers/cvpr97/cvpr.ps.gz
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/user/har/Web/research.html
Root-URL: 
Email: har@cs.cmu.edu  rehg@crl.dec.com  
Title: Analyzing Articulated Motion Using Expectation-Maximization  
Author: Henry A. Rowley James M. Rehg 
Address: 5000 Forbes Avenue Pittsburgh, PA 15213, USA  One Kendall Square, Bldg 700 Cambridge, MA 02139, USA  
Affiliation: Carnegie Mellon University  Digital Equipment Corporation  
Abstract: We present a novel application of the Expectation-Maximization algorithm to the global analysis of articulated motion. The approach utilizes a kinematic model to constrain the motion estimates, producing a segmentation of the flow field into parts with different articulated motions. Experiments with synthetic and real images are described. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Bergen, P. Anandan, K. Hanna, and R. Hingorani. </author> <title> Hierarchical model-based motion estimation. </title> <booktitle> In 2nd Europ. Conf. on Computer Vision, </booktitle> <pages> pages 237252, </pages> <address> Italy, </address> <year> 1992. </year>
Reference-contexts: The flow in each region was described by a parametric model, such as affine flow. This flow model approximates with a small number of parameters the overall flow of a rigidly-moving surface of arbitrary shape <ref> [1, 15] </ref>. Parametric flow estimates can be computed more reliably than local flow, which is often noisy and under-constrained. This in turn enables a higher quality motion-based segmentation than purely local flow can support.
Reference: [2] <author> A. Bobick and J. Davis. </author> <title> Real-time recognition of activity using temporal templates. </title> <booktitle> In 3rd Workshop on Appl. of Computer Vision, </booktitle> <pages> pages 3942, </pages> <address> Sarasota, FL, </address> <month> December </month> <year> 1996. </year>
Reference-contexts: However, their dependency on specific types of motion or viewing directions is an obstacle to general video analysis. Previous work on gesture recognition employed temporal Markov chain models to segment and detect image feature motion that is consistent with a vocabulary of human action [3, 20]. Related work in <ref> [2] </ref> introduces the concept of motion-history images for specific actions. These efforts make use of domain-specific, high-level models in an attempt to bypass the need for accurate low-level image analysis.
Reference: [3] <author> C. Bregler, S. Omohundro, et al. </author> <title> Probabilistic models of verbal and body gesture. </title> <editor> In S. Pentland and R. Cipolla, editors, </editor> <title> Computer Vision in Man-Machine Interfaces. </title> <publisher> Cam-bridge University Press, </publisher> <address> Cambridge, UK, </address> <year> 1997. </year>
Reference-contexts: However, their dependency on specific types of motion or viewing directions is an obstacle to general video analysis. Previous work on gesture recognition employed temporal Markov chain models to segment and detect image feature motion that is consistent with a vocabulary of human action <ref> [3, 20] </ref>. Related work in [2] introduces the concept of motion-history images for specific actions. These efforts make use of domain-specific, high-level models in an attempt to bypass the need for accurate low-level image analysis.
Reference: [4] <author> A. Dempster, N. Laird, and D. Rubin. </author> <title> Maximum-likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> B39:138, </volume> <year> 1977. </year>
Reference-contexts: The difficulty is that neither the correct segmentation nor the motion estimates are known prior to analysis. The EM algorithm makes it possible to overcome the interdependency between segmentation and motion estimation. It is based on a general statistical framework for estimating model parameters from incomplete, or missing, data <ref> [4] </ref>. In the case of motion analysis the missing data is the segmentation which assigns each image measurement (pixel) to a motion model. Given this segmentation information, the motion model parameters can be estimated using standard least squares techniques [8]. <p> Also note that because each model is independent of the others, their parameters can be optimized separately. Convergence results for the EM algorithm <ref> [4] </ref> guarantee that iteration of alternating E- and M-steps will cause the overall likelihood of the measured data given the parameters to increase. EM is therefore a gradient-based algorithm, and is subject to the usual pitfalls, such as convergence to local rather than global maxima.
Reference: [5] <author> M. Fleck, D. Forsyth, and C. Bregler. </author> <title> Finding naked people. </title> <booktitle> In 4th Europ. Conf. on Computer Vision, </booktitle> <pages> pages 593602, </pages> <address> Cambridge, UK, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: Few objects in the world move the way people do. An algorithm capable of detecting the presence of human motion in a sequence of images would complement existing detection schemes based on faces [17] and color and form cues <ref> [5] </ref>, and make robust person-detection possible. Such a system would have applications in user-interfaces [13], surveillance, and video indexing.
Reference: [6] <author> A. Jepson and M. Black. </author> <title> Mixture models for optical flow computation. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <pages> pages 760761, </pages> <address> New York City, NY, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: This representation is tuned to the structure inherent in human motion, and we expect it to be a useful representation for motion-based detection and classification. 2. Motion Analysis and EM The first application of Expectation-Maximization (EM) to motion analysis, in <ref> [6] </ref>, addressed the segmentation of an optical flow field into independent rigid motions. The flow field was assumed to consist of multiple regions corresponding to independently moving surfaces in the scene. The flow in each region was described by a parametric model, such as affine flow. <p> It is convenient to assume that the family of motion models takes the form of a Gaussian mixture density [11]. This means that each image measurement is drawn independently from a Gaussian distribution whose mean is a function of the motion model parameters <ref> [6, 19] </ref>. We let R m (P; x; y) denote the measurement deviation, or residual, at pixel (x; y) with respect to model m whose motion is described by parameters P. <p> In practice, however, the EM algorithm exhibits good performance on a wide variety of problems from speech recognition to medical image segmentation. In addition, it is straightforward to incorporate robust statistical techniques <ref> [6] </ref> and a spatial coherence constraint [19] into the basic EM framework. <p> However, they may be difficult to apply in a broad domain such as video indexing, where the number of possible actions is quite large. Our algorithm for articulated motion segmentation builds heavily on previous work on segmenting multiple rigid motions using EM. Following <ref> [6] </ref>, a number of authors have applied mixture models to motion analysis. For example, [19] presents a general framework for EM-based motion analysis that includes spatial coherence. We extend these approaches by demonstrating how to incorporate kinematic constraints into the EM analysis. 6.
Reference: [7] <author> I. Kakadiaris and D. Metaxas. </author> <title> 3d human body model acquisition from multiple views. </title> <booktitle> In 5th Intl. Conf. on Computer Vision, </booktitle> <pages> pages 618623, </pages> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Periodicity and a known ground plane orientation are exploited in [9] to obtain an initial segmentation of fronto-parallel walking motion, which is then refined by fitting spatiotemporal surface models. In [16], a simple articulated model is applied to previously segmented motion data, while in <ref> [7] </ref> a deformable articulated model is segmented from carefully staged figure motion. A nice property of these approaches is that they can exploit many frames of video in making a decision. However, their dependency on specific types of motion or viewing directions is an obstacle to general video analysis.
Reference: [8] <author> B. Lucas and T. Kanade. </author> <title> An iterative image registration technique with an application to stereo. </title> <booktitle> In 7th Int. Joint Conf. on Artificial Intelligence, </booktitle> <pages> pages 674679, </pages> <address> Vancouver, B.C., </address> <year> 1981. </year>
Reference-contexts: In the case of motion analysis the missing data is the segmentation which assigns each image measurement (pixel) to a motion model. Given this segmentation information, the motion model parameters can be estimated using standard least squares techniques <ref> [8] </ref>. It is convenient to assume that the family of motion models takes the form of a Gaussian mixture density [11]. This means that each image measurement is drawn independently from a Gaussian distribution whose mean is a function of the motion model parameters [6, 19].
Reference: [9] <author> S. Niyogi and E. Adelson. </author> <title> Analyzing and recognizing walking figures in XYT. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <pages> pages 469474, </pages> <address> Seattle, WA, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Such a system would have applications in user-interfaces [13], surveillance, and video indexing. Previous work on human motion detection and classification has relied on special properties of fronto-parallel walking motion <ref> [9] </ref> or on the reliable estimation of global translation prior to articulated motion analysis [10]. In contrast, our goal is to exploit the known kinematics of the body to detect moving figures under all viewing conditions and in the absence of any additional segmentation information. <p> Several authors have addressed the segmentation of repetitive human motion from video. In [10], time-frequency analysis on translation-stabilized imagery is used to detect repetitive patterns due to gait and arm swinging. Periodicity and a known ground plane orientation are exploited in <ref> [9] </ref> to obtain an initial segmentation of fronto-parallel walking motion, which is then refined by fitting spatiotemporal surface models. In [16], a simple articulated model is applied to previously segmented motion data, while in [7] a deformable articulated model is segmented from carefully staged figure motion.
Reference: [10] <author> R. Polana and R. Nelson. </author> <title> Nonparametric recognition of non-rigid motion. </title> <type> Technical Report TR 575, </type> <institution> Univ. of Rochester Dept. of Computer Science, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: Such a system would have applications in user-interfaces [13], surveillance, and video indexing. Previous work on human motion detection and classification has relied on special properties of fronto-parallel walking motion [9] or on the reliable estimation of global translation prior to articulated motion analysis <ref> [10] </ref>. In contrast, our goal is to exploit the known kinematics of the body to detect moving figures under all viewing conditions and in the absence of any additional segmentation information. <p> We will describe a representative set of previous work on human motion analysis; please refer to [14] for a more comprehensive discussion. Several authors have addressed the segmentation of repetitive human motion from video. In <ref> [10] </ref>, time-frequency analysis on translation-stabilized imagery is used to detect repetitive patterns due to gait and arm swinging. Periodicity and a known ground plane orientation are exploited in [9] to obtain an initial segmentation of fronto-parallel walking motion, which is then refined by fitting spatiotemporal surface models.
Reference: [11] <author> R. Redner and H. Walker. </author> <title> Mixture densities, maximum likelihood, and the EM algorithm. </title> <publisher> SIAM Revew, </publisher> <address> 26:195239, </address> <year> 1994. </year>
Reference-contexts: Given this segmentation information, the motion model parameters can be estimated using standard least squares techniques [8]. It is convenient to assume that the family of motion models takes the form of a Gaussian mixture density <ref> [11] </ref>. This means that each image measurement is drawn independently from a Gaussian distribution whose mean is a function of the motion model parameters [6, 19].
Reference: [12] <author> J. Rehg and T. Kanade. </author> <title> Model-based tracking of self-occluding articulated objects. </title> <booktitle> In 5th Intl. Conf. on Computer Vision, </booktitle> <pages> pages 612617, </pages> <address> Boston, MA, </address> <year> 1995. </year>
Reference-contexts: If the link appearance is modeled by a texture-mapped plane, a simple motion model can be derived which expresses pixel motion in terms of joint angles <ref> [12] </ref>. The corresponding segmentation model assigns pixels to the link in the kinematic chain where their motion originates. We will demonstrate that this model, which was originally developed for object tracking, can be incorporated directly into the framework of Equations 1 and 2. 3.1. <p> This model, first presented in <ref> [12] </ref>, assumes that pixels that are visible in one frame will remain visible throughout the sequence. It is violated by motions which take pixels across the occlusion boundary of the link, as in the case of side-to-side head rotation.
Reference: [13] <author> J. Rehg, M. Loughlin, and K. Waters. </author> <title> Vision for a smart kiosk. In Computer Vision and Pattern Recognition, </title> <address> San Juan, PR, </address> <month> June </month> <year> 1997. </year> <note> In this proceedings. </note>
Reference-contexts: An algorithm capable of detecting the presence of human motion in a sequence of images would complement existing detection schemes based on faces [17] and color and form cues [5], and make robust person-detection possible. Such a system would have applications in user-interfaces <ref> [13] </ref>, surveillance, and video indexing. Previous work on human motion detection and classification has relied on special properties of fronto-parallel walking motion [9] or on the reliable estimation of global translation prior to articulated motion analysis [10].
Reference: [14] <author> J. Rehg and H. Rowley. </author> <title> An EM algorithm for articulated motion analysis. </title> <type> Technical Report CRL 96/3, </type> <institution> Digital Equipment Corp. Cambridge Research Lab, </institution> <year> 1996. </year>
Reference-contexts: The first used synthetic data, to measure the accuracy of the algorithm, while the second used two frames from a real image sequence, to verify the algorithm's performance on real data. More details on these results are presented in <ref> [14] </ref>. The first sequence, depicted in Figures 1b and c, consisted of synthetic data. Each part of the model was textured with Gaussian white noise. The motion and segmentation maps derived for the torso and upper and lower arm are shown in Figures 2 and 3. <p> Such a representation could provide a basis for the classification and recognition of human motion. We will describe a representative set of previous work on human motion analysis; please refer to <ref> [14] </ref> for a more comprehensive discussion. Several authors have addressed the segmentation of repetitive human motion from video. In [10], time-frequency analysis on translation-stabilized imagery is used to detect repetitive patterns due to gait and arm swinging.
Reference: [15] <author> J. Rehg and A. Witkin. </author> <title> Visual tracking with deformation models. </title> <booktitle> In Proc. of Intl. Conf. on Robotics and Automation, </booktitle> <pages> pages 844850, </pages> <address> Sacramento, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The flow in each region was described by a parametric model, such as affine flow. This flow model approximates with a small number of parameters the overall flow of a rigidly-moving surface of arbitrary shape <ref> [1, 15] </ref>. Parametric flow estimates can be computed more reliably than local flow, which is often noisy and under-constrained. This in turn enables a higher quality motion-based segmentation than purely local flow can support. <p> In the previous EM formulation, the mixture model might consist of a set of affine deformations, each with six motion parameters (see <ref> [15] </ref> for details). Alternative residual measures based on fitting optical flow data are also possible, but our method has the advantage of applying motion constraints directly to the pixel data.
Reference: [16] <author> K. Rohr. </author> <title> Towards model-based recognition of human movements in image sequences. CVGIP: Image Understanding, </title> <address> 59(1):94115, </address> <year> 1994. </year>
Reference-contexts: In [10], time-frequency analysis on translation-stabilized imagery is used to detect repetitive patterns due to gait and arm swinging. Periodicity and a known ground plane orientation are exploited in [9] to obtain an initial segmentation of fronto-parallel walking motion, which is then refined by fitting spatiotemporal surface models. In <ref> [16] </ref>, a simple articulated model is applied to previously segmented motion data, while in [7] a deformable articulated model is segmented from carefully staged figure motion. A nice property of these approaches is that they can exploit many frames of video in making a decision.
Reference: [17] <author> H. Rowley, S. Baluja, and T. Kanade. </author> <title> Neural network-based face detection. In Computer Vision and Pattern Recognition, </title> <address> pages 203208, San Francisco, CA, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Few objects in the world move the way people do. An algorithm capable of detecting the presence of human motion in a sequence of images would complement existing detection schemes based on faces <ref> [17] </ref> and color and form cues [5], and make robust person-detection possible. Such a system would have applications in user-interfaces [13], surveillance, and video indexing.
Reference: [18] <author> M. Spong. </author> <title> Robot Dynamics and Control. </title> <publisher> John Wiley and Sons, </publisher> <year> 1989. </year>
Reference-contexts: An arm model, for example, might consist of an upper and lower link. The motion parameters for the deformation are the degrees of freedom of the link's kinematic chain, which are described using the Denavit-Hartenberg notation commonly employed in robotics <ref> [18] </ref>. Each link in the chain is attached either to the base or to another link. A link m has a local coordinate frame which is specified by a rigid transformation, T m , relative to its connecting link in the chain.
Reference: [19] <author> Y. Weiss and E. Adelson. </author> <title> A unified mixture framework for motion segmentation: Incorporating spatial coherence and estimating the number of models. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <pages> pages 321326, </pages> <address> San Fransisco, CA, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: It is convenient to assume that the family of motion models takes the form of a Gaussian mixture density [11]. This means that each image measurement is drawn independently from a Gaussian distribution whose mean is a function of the motion model parameters <ref> [6, 19] </ref>. We let R m (P; x; y) denote the measurement deviation, or residual, at pixel (x; y) with respect to model m whose motion is described by parameters P. <p> In practice, however, the EM algorithm exhibits good performance on a wide variety of problems from speech recognition to medical image segmentation. In addition, it is straightforward to incorporate robust statistical techniques [6] and a spatial coherence constraint <ref> [19] </ref> into the basic EM framework. <p> The difference between this equation and Equation 1 is this convolution, which smooths the segmentation maps; other techniques have been explored in <ref> [19] </ref>. The p m terms denote prior probabilities for each link m. These can be set in proportion to the expected sizes of each of the links in the images. Motion analysis, which happens in the M-step, consists of finding a set of parameters to minimize an error function. <p> Our algorithm for articulated motion segmentation builds heavily on previous work on segmenting multiple rigid motions using EM. Following [6], a number of authors have applied mixture models to motion analysis. For example, <ref> [19] </ref> presents a general framework for EM-based motion analysis that includes spatial coherence. We extend these approaches by demonstrating how to incorporate kinematic constraints into the EM analysis. 6.
Reference: [20] <author> A. Wilson and A. Bobick. </author> <title> Learning visual behavior for gesture analysis. </title> <booktitle> In Int. Symposium on Computer Vision, </booktitle> <pages> pages 229234, </pages> <address> Coral Gables, FL, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: However, their dependency on specific types of motion or viewing directions is an obstacle to general video analysis. Previous work on gesture recognition employed temporal Markov chain models to segment and detect image feature motion that is consistent with a vocabulary of human action <ref> [3, 20] </ref>. Related work in [2] introduces the concept of motion-history images for specific actions. These efforts make use of domain-specific, high-level models in an attempt to bypass the need for accurate low-level image analysis.
References-found: 20

