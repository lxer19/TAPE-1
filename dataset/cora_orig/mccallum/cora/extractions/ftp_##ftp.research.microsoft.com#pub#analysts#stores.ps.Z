URL: ftp://ftp.research.microsoft.com/pub/analysts/stores.ps.Z
Refering-URL: http://www.research.microsoft.com/analysts/vdg.html
Root-URL: http://www.research.microsoft.com
Email: rusa@research.microsoft.com  
Title: Sparse Functional Stores for Imperative Programs  
Author: Bjarne Steensgaard 
Address: One Microsoft Way Redmond, WA 98052  
Affiliation: Microsoft Research  
Abstract: In recent years, the trend in program representations for imperative programs has been to make them more functional, or to make them more sparse. However, new sparse representations have been non-functional, and new functional representations have not been sparse in the presence of pointer operations. In this paper, we present a functional representation that is sparse even in the presence of pointer operations. Conventionally, a store is represented in a functional program representation by a single object|typically a mapping from locations to values. We show how such a store object may be fragmented into several objects, each representing part of the store. The result is a sparser representation, which has not only the usual benefit of directly linking producers to consumers, but which also for static program analysis often leads to smaller domains of abstract values for store objects. Store fragmentation corresponds to assignment factored SSA form (a factorization of SSA form introduced in this paper). We report on experiments with a thorough fragmentation based on a data flow points-to analysis and an intermediate level fragmentation based on an almost linear time complexity points-to analysis by type inference. 
Abstract-found: 1
Intro-found: 1
Reference: [ASU86] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ull-man. Compilers|Principles, </author> <title> Techniques, and Tools. </title> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: The initial VDG has many advantages when performing optimizations that only require local knowledge [WCES94b]. However, for performing analyses and many global transformations that involve store operations, the initial VDG is only slightly more useful than a control flow graph (CFG) <ref> [ASU86] </ref>. Using VDGs has advantages over non-functional program representations for performing sparseness increasing transformations. <p> In this and the following section we define assignment fac tored SSA form and compare it with location factored SSA form [CCF94] and ordinary SSA form [CFR + 91]. As observed in [CCF94], SSA form factors 2 use-def edges <ref> [ASU86] </ref> over join points in the flow graph to avoid an explo sion of use-def edges at these points.
Reference: [BMO90] <author> Robert A. Ballance, Arthur B. Maccabe, and Karl J. Ottenstein. </author> <title> The program dependence web: a representation supporting control-, data-, and demand-driven interpretation of imperative languages. </title> <booktitle> In Proceedings of the SIG-PLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: 1 Introduction In recent years, the trend in program representations for imperative programs has been to make them more functional, or to make them more sparse. However, new sparse representations [CFR + 91, FOW87, PBJ + 90, SKR90, JP93] have been non-functional, and new functional representations <ref> [WCES94a, BMO90, Fie92] </ref> have not been sparse in the presence of pointer operations. In this paper, we present a functional representation that is sparse even in the presence of pointer operations. <p> We present store fragmentation in terms of the value dependence graph (VDG) [WCES94a, WCES94b], but the technique is equally useful for other program representations such as the program dependence web <ref> [BMO90] </ref> and PIM terms [Fie92]. We present a quick overview of the value dependence graph in Section 2. Section 3 contains the technical results of the paper. We first present an overview of store fragmentation. In Section 3.1, we present a small algebra for creating and manipulating store objects. <p> It has some resemblance to the demand view of the program dependence web <ref> [BMO90] </ref> and to graphical demand driven dataflow representations [PA85, PA86]. It can also be described as a graphical lambda calculus representation of imperative programs. <p> Our programming environment presently prevents us from proving this empirically. 5 Related work The demand view of the program dependence web (PDW) <ref> [BMO90] </ref> is very similar to the VDG. The PDW is not described for programs with aliases or pointer operations, but private communication with students of the authors indicated they will use explicit stores in the representation for such programs.
Reference: [CBC93] <author> Jong-Deok Choi, Michael Burke, and Paul Carini. </author> <title> Efficient flow-sensitive interprocedural computation of pointer-induced aliases and side effects. </title> <booktitle> In Proceedings of the Twentieth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 232-245. </pages> <publisher> ACM Press, </publisher> <month> January </month> <year> 1993. </year>
Reference-contexts: This optimization can easily be performed on functional, graphical, program representations, while they are impossible to represent directly in CFGs. The optimizations may be represented in, e.g., SSA form [CFR + 91], but constructing SSA form requires the results of an alias analysis <ref> [LR92, LRZ93, CBC93] </ref> or points-to analysis [EGH93, CWZ90].
Reference: [CCF94] <author> Jong-Deok Choi, Ron Cytron, and Jeanne Fer-rante. </author> <title> On the efficient engineering of ambitious program analysis. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 20(2) </volume> <pages> 105-114, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: Assignment factored SSA form is a novel factorization of dependence edges in SSA form presented in this paper. The factorization is likely to have fewer edges and nodes than both ordinary SSA form [CFR + 91] and (location) factored SSA form <ref> [CCF94] </ref>. There is a spectrum of store fragmentation configurations with different costs and benefits. At one end of the spectrum is the configuration that has only one store object, corresponding to not doing any fragmentation. It has low (no) cost, and it does not offer any benefits. <p> In this and the following section we define assignment fac tored SSA form and compare it with location factored SSA form <ref> [CCF94] </ref> and ordinary SSA form [CFR + 91]. As observed in [CCF94], SSA form factors 2 use-def edges [ASU86] over join points in the flow graph to avoid an explo sion of use-def edges at these points. <p> In this and the following section we define assignment fac tored SSA form and compare it with location factored SSA form <ref> [CCF94] </ref> and ordinary SSA form [CFR + 91]. As observed in [CCF94], SSA form factors 2 use-def edges [ASU86] over join points in the flow graph to avoid an explo sion of use-def edges at these points. In pure use-def form 2 We are using the term "factor" in the same sense as [CCF94]. be quadratic in the number of program statements <p> As observed in <ref> [CCF94] </ref>, SSA form factors 2 use-def edges [ASU86] over join points in the flow graph to avoid an explo sion of use-def edges at these points. In pure use-def form 2 We are using the term "factor" in the same sense as [CCF94]. be quadratic in the number of program statements (figure copied from [CCF94]). there will be n fi m edges across a join point for a single location, where n is the number of uses of the location after the join point, and m is the number of definitions of the <p> In pure use-def form 2 We are using the term "factor" in the same sense as <ref> [CCF94] </ref>. be quadratic in the number of program statements (figure copied from [CCF94]). there will be n fi m edges across a join point for a single location, where n is the number of uses of the location after the join point, and m is the number of definitions of the location before the join point. Figure 6 illustrates this point. <p> Figure 6 illustrates this point. In SSA form, a node is introduced at the join point, and there are n edges from the uses to the node, and m edges from the node to the definitions. Location factored SSA form (called simply factored SSA form in <ref> [CCF94] </ref>) factors SSA edges over weak updates [CWZ90] (called preserving definitions in [CCF94]). A weak update of a location is an operation that might update the location while not guaranteed to always overwrite the previous contents of the location. <p> Location factored SSA form (called simply factored SSA form in <ref> [CCF94] </ref>) factors SSA edges over weak updates [CWZ90] (called preserving definitions in [CCF94]). A weak update of a location is an operation that might update the location while not guaranteed to always overwrite the previous contents of the location. The effects of the previous update of that location cannot be ignored by analyses because the weak update might not affect the location. <p> The statements shown are statements from the original program. The bullets correspond to statements in the SSA form. A single assignment statement in the original program is represented by one SSA statement for each location possibly modified by the original statement <ref> [CCF94] </ref>. represent factored dependence edges, and the bullets represent statements in the SSA form. Note that there is only one SSA statement per statement in the original program. 3.5 Assignment factored SSA form Assignment factored SSA form factors SSA edges over the assignments in the original program.
Reference: [CF89] <author> Robert Cartwright and Matthias Felleisen. </author> <title> The semantics of program dependence. </title> <booktitle> In Proceedings of the SIGPLAN '89 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 13-27, </pages> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: The same is true for other aspects of the machine state, like I/O stream state, but for the purposes of this paper, we ignore these other values. Stores are explicit values produced by primitive computations (as in denotational semantics for imperative languages <ref> [CF89] </ref>). An assignment (that cannot be eliminated by the methods described in [WCES94b] or [Ruf95]) is represented by a primitive operation (update) that takes a store argument and produces a new store. A VDG demonstrating pointer references and updates through pointers is shown in Figure 2.
Reference: [CFR + 91] <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> Efficiently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: 1 Introduction In recent years, the trend in program representations for imperative programs has been to make them more functional, or to make them more sparse. However, new sparse representations <ref> [CFR + 91, FOW87, PBJ + 90, SKR90, JP93] </ref> have been non-functional, and new functional representations [WCES94a, BMO90, Fie92] have not been sparse in the presence of pointer operations. In this paper, we present a functional representation that is sparse even in the presence of pointer operations. <p> Store fragmentation corresponds to establishing assignment factored SSA form. Assignment factored SSA form is a novel factorization of dependence edges in SSA form presented in this paper. The factorization is likely to have fewer edges and nodes than both ordinary SSA form <ref> [CFR + 91] </ref> and (location) factored SSA form [CCF94]. There is a spectrum of store fragmentation configurations with different costs and benefits. At one end of the spectrum is the configuration that has only one store object, corresponding to not doing any fragmentation. <p> Values originally written to the location can be directed to their uses without being written to the location. This optimization can easily be performed on functional, graphical, program representations, while they are impossible to represent directly in CFGs. The optimizations may be represented in, e.g., SSA form <ref> [CFR + 91] </ref>, but constructing SSA form requires the results of an alias analysis [LR92, LRZ93, CBC93] or points-to analysis [EGH93, CWZ90]. <p> In this and the following section we define assignment fac tored SSA form and compare it with location factored SSA form [CCF94] and ordinary SSA form <ref> [CFR + 91] </ref>. As observed in [CCF94], SSA form factors 2 use-def edges [ASU86] over join points in the flow graph to avoid an explo sion of use-def edges at these points.
Reference: [CWZ90] <author> David R. Chase, Mark Wegman, and F. Ken-neth Zadeck. </author> <title> Analysis of pointers and structures. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 296-310, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: It has low (no) cost, and it does not offer any benefits. At the other end is a thorough fragmentation whose configuration varies with the program point and is based on a data flow based points-to analysis (e.g., <ref> [EGH93, CWZ90] </ref>). It has a relatively high cost to obtain, and offers maximum benefits in terms of exposing parallelism in the representation. We describe experience with both the thorough fragmentation and an intermediate level fragmentation that uses an al most linear time points-to analysis based on type inference [Ste95a]. <p> This optimization can easily be performed on functional, graphical, program representations, while they are impossible to represent directly in CFGs. The optimizations may be represented in, e.g., SSA form [CFR + 91], but constructing SSA form requires the results of an alias analysis [LR92, LRZ93, CBC93] or points-to analysis <ref> [EGH93, CWZ90] </ref>. <p> Is is based on the results of data flow based points-to analyses such as [EGH93] or <ref> [CWZ90] </ref>). The fragmentation configuration varies over the possible program points. A defining property of the thorough fragmentation is that for a given program point, different locations are put in different store fragments unless the latest possible update of either is also a possible update of the other. <p> In SSA form, a node is introduced at the join point, and there are n edges from the uses to the node, and m edges from the node to the definitions. Location factored SSA form (called simply factored SSA form in [CCF94]) factors SSA edges over weak updates <ref> [CWZ90] </ref> (called preserving definitions in [CCF94]). A weak update of a location is an operation that might update the location while not guaranteed to always overwrite the previous contents of the location.
Reference: [EGH93] <author> Maryam Emami, Rakesh Ghiya, and Lau-rie J. Hendren. </author> <title> Context-sensitive interprocedu-ral points-to analysis in the presence of function pointers. </title> <type> ACAPS Technical Memo 54, </type> <institution> McGill University, School of Computer Science, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: It has low (no) cost, and it does not offer any benefits. At the other end is a thorough fragmentation whose configuration varies with the program point and is based on a data flow based points-to analysis (e.g., <ref> [EGH93, CWZ90] </ref>). It has a relatively high cost to obtain, and offers maximum benefits in terms of exposing parallelism in the representation. We describe experience with both the thorough fragmentation and an intermediate level fragmentation that uses an al most linear time points-to analysis based on type inference [Ste95a]. <p> This optimization can easily be performed on functional, graphical, program representations, while they are impossible to represent directly in CFGs. The optimizations may be represented in, e.g., SSA form [CFR + 91], but constructing SSA form requires the results of an alias analysis [LR92, LRZ93, CBC93] or points-to analysis <ref> [EGH93, CWZ90] </ref>. <p> Is is based on the results of data flow based points-to analyses such as <ref> [EGH93] </ref> or [CWZ90]). The fragmentation configuration varies over the possible program points. A defining property of the thorough fragmentation is that for a given program point, different locations are put in different store fragments unless the latest possible update of either is also a possible update of the other.
Reference: [Fie92] <author> John Field. </author> <title> A simple rewriting semantics for realistic imperative programs and its application to program analysis (preliminary report). </title> <booktitle> In Proc. ACM SIGPLAN Workshop on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 98-107, </pages> <address> San Francisco, </address> <month> June </month> <year> 1992. </year> <note> Published as Yale University Technical Report YALEU/DCS/RR-909. </note>
Reference-contexts: 1 Introduction In recent years, the trend in program representations for imperative programs has been to make them more functional, or to make them more sparse. However, new sparse representations [CFR + 91, FOW87, PBJ + 90, SKR90, JP93] have been non-functional, and new functional representations <ref> [WCES94a, BMO90, Fie92] </ref> have not been sparse in the presence of pointer operations. In this paper, we present a functional representation that is sparse even in the presence of pointer operations. <p> We present store fragmentation in terms of the value dependence graph (VDG) [WCES94a, WCES94b], but the technique is equally useful for other program representations such as the program dependence web [BMO90] and PIM terms <ref> [Fie92] </ref>. We present a quick overview of the value dependence graph in Section 2. Section 3 contains the technical results of the paper. We first present an overview of store fragmentation. In Section 3.1, we present a small algebra for creating and manipulating store objects. <p> The PDW is not described for programs with aliases or pointer operations, but private communication with students of the authors indicated they will use explicit stores in the representation for such programs. The merge structures of PIM <ref> [Fie92] </ref> are used to represent sequences of assignment operations. Such merge structures are roughly equivalent to store objects in the VDG. The concept of store fragmentation could be easily applied to both PIM terms and the PDW.
Reference: [FOW87] <author> Jeanne Ferrante, Karl J. Ottenstein, and Joe D. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: 1 Introduction In recent years, the trend in program representations for imperative programs has been to make them more functional, or to make them more sparse. However, new sparse representations <ref> [CFR + 91, FOW87, PBJ + 90, SKR90, JP93] </ref> have been non-functional, and new functional representations [WCES94a, BMO90, Fie92] have not been sparse in the presence of pointer operations. In this paper, we present a functional representation that is sparse even in the presence of pointer operations.
Reference: [GJSO92] <author> David K. Gifford, Pierre Jouvelot, Mark A. Sheldon, and James O'Toole. </author> <title> Report on the FX-91 programming language. </title> <type> Technical Report TR-150, </type> <institution> MIT/LCS, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: Use of allocation zones is however entirely under programmer control. Partitioning the available store has been used in a couple of implementations of programming languages. An extension of the FX programming language <ref> [GJSO92] </ref> called FX/R (FX with regions) uses regions to describe the area of the store that an effect encompasses. These regions are examples of store fragments.
Reference: [Hen91] <author> Fritz Henglein. </author> <title> Efficient type inference for higher-order binding-time analysis. </title> <booktitle> In Functional Programming and Computer Architecture, </booktitle> <pages> pages 448-472, </pages> <year> 1991. </year>
Reference-contexts: The algorithm is based on type inference using fast union/find data structures (the algorithm is inspired by <ref> [Hen91] </ref>). The algorithm computes relations between equivalence classes of locations. Equivalence classes remain the same over the entire program. Equivalence classes can be treated as specifications of store fragments; all locations in an equivalence class should be in the same store fragment.
Reference: [JP93] <author> Richard Johnson and Keshav Pin-gali. </author> <title> Dependence-based program analysis. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 78-89, </pages> <address> Albuquerque, New Mexico, </address> <month> June 23-25, </month> <year> 1993. </year>
Reference-contexts: 1 Introduction In recent years, the trend in program representations for imperative programs has been to make them more functional, or to make them more sparse. However, new sparse representations <ref> [CFR + 91, FOW87, PBJ + 90, SKR90, JP93] </ref> have been non-functional, and new functional representations [WCES94a, BMO90, Fie92] have not been sparse in the presence of pointer operations. In this paper, we present a functional representation that is sparse even in the presence of pointer operations.
Reference: [LR92] <author> William Landi and Barbara G. Ryder. </author> <title> A safe approximate algorithm for interprocedural pointer aliasing. </title> <booktitle> In Proceedings of the SIG-PLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 235-248. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: This optimization can easily be performed on functional, graphical, program representations, while they are impossible to represent directly in CFGs. The optimizations may be represented in, e.g., SSA form [CFR + 91], but constructing SSA form requires the results of an alias analysis <ref> [LR92, LRZ93, CBC93] </ref> or points-to analysis [EGH93, CWZ90].
Reference: [LRZ93] <author> William A. Landi, Barbara G. Ryder, and Sean Zhang. </author> <title> Interprocedural modification side effect analysis with pointer aliasing. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 56-67. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: This optimization can easily be performed on functional, graphical, program representations, while they are impossible to represent directly in CFGs. The optimizations may be represented in, e.g., SSA form [CFR + 91], but constructing SSA form requires the results of an alias analysis <ref> [LR92, LRZ93, CBC93] </ref> or points-to analysis [EGH93, CWZ90].
Reference: [PA85] <author> Keshav Pingali and Arvind. </author> <title> Efficient demand-driven evaluation. Part 1. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(2) </volume> <pages> 311-333, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: It has some resemblance to the demand view of the program dependence web [BMO90] and to graphical demand driven dataflow representations <ref> [PA85, PA86] </ref>. It can also be described as a graphical lambda calculus representation of imperative programs. A program is in the VDG represented by a set of nodes denoting primitive computations generating values and a set of edges representing how the generated values flow to other nodes.
Reference: [PA86] <author> Keshav Pingali and Arvind. </author> <title> Efficient demand-driven evaluation. Part 2. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 8(1) </volume> <pages> 109-139, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: It has some resemblance to the demand view of the program dependence web [BMO90] and to graphical demand driven dataflow representations <ref> [PA85, PA86] </ref>. It can also be described as a graphical lambda calculus representation of imperative programs. A program is in the VDG represented by a set of nodes denoting primitive computations generating values and a set of edges representing how the generated values flow to other nodes.
Reference: [PBJ + 90] <author> Keshav Pingali, Micah Beck, Richard Johnson, Mayan Moudgill, and Paul Stodghill. </author> <title> Dependence flow graphs: An algebraic approach to program dependencies. </title> <type> Technical Report 90-1152, </type> <institution> Department of Computer Science, Cor-nell University, </institution> <address> Ithaca, NY 14853, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: 1 Introduction In recent years, the trend in program representations for imperative programs has been to make them more functional, or to make them more sparse. However, new sparse representations <ref> [CFR + 91, FOW87, PBJ + 90, SKR90, JP93] </ref> have been non-functional, and new functional representations [WCES94a, BMO90, Fie92] have not been sparse in the presence of pointer operations. In this paper, we present a functional representation that is sparse even in the presence of pointer operations.
Reference: [Ruf95] <author> Erik Ruf. </author> <title> Optimizing sparse representations for dataflow analysis. </title> <booktitle> In Proceedings of the ACM SIGPLAN Workshop on Intermediate Representations (IR'95), </booktitle> <address> San Francisco, CA, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: Stores are explicit values produced by primitive computations (as in denotational semantics for imperative languages [CF89]). An assignment (that cannot be eliminated by the methods described in [WCES94b] or <ref> [Ruf95] </ref>) is represented by a primitive operation (update) that takes a store argument and produces a new store. A VDG demonstrating pointer references and updates through pointers is shown in Figure 2. The initial VDG has many advantages when performing optimizations that only require local knowledge [WCES94b]. <p> For C programs, any location whose address is never used as a value in the program 1 is trivially 1 The location will appear as a value in the VDG, but only as an argument to lookup and update operations. removed from the store domain <ref> [Ruf95] </ref>. Values originally written to the location can be directed to their uses without being written to the location. This optimization can easily be performed on functional, graphical, program representations, while they are impossible to represent directly in CFGs. <p> Preliminary results indicate that store fragments have an average size of 1.5-3 abstract locations (the abstract locations used by our dataflow based points-to analysis). Many store fragments can be determined to contain exactly one location, and those store fragments can be eliminated entirely (cf. arity raising <ref> [Ruf95] </ref>). We are still experimenting with ways of improving the quality of the analysis results without increasing the complexity of the algorithm, thereby possibly obtaining even better results. If arity raising [Ruf95] is not performed on the program representation, the quick store fragmentation will ensure that each location that would have <p> can be determined to contain exactly one location, and those store fragments can be eliminated entirely (cf. arity raising <ref> [Ruf95] </ref>). We are still experimenting with ways of improving the quality of the analysis results without increasing the complexity of the algorithm, thereby possibly obtaining even better results. If arity raising [Ruf95] is not performed on the program representation, the quick store fragmentation will ensure that each location that would have been eliminated by ar-ity raising would have been in its own store fragment. <p> We therefore postulate that the quick store fragmentation in the absence of arity raising will lead to improvements in analysis speed and memory requirements proportional to those measured by <ref> [Ruf95] </ref>. The quick store fragmentation is however able to do global arity raising, and we have hopes that it will ensure the continuation of the improvement curve measured by [Ruf95] for large programs. <p> in the absence of arity raising will lead to improvements in analysis speed and memory requirements proportional to those measured by <ref> [Ruf95] </ref>. The quick store fragmentation is however able to do global arity raising, and we have hopes that it will ensure the continuation of the improvement curve measured by [Ruf95] for large programs. Our programming environment presently prevents us from proving this empirically. 5 Related work The demand view of the program dependence web (PDW) [BMO90] is very similar to the VDG.
Reference: [SGW94] <author> Eric Stoltz, Michael P. Gerlek, and Michael Wolfe. </author> <title> Extended SSA with factored use-def chains to support optimization and parallelism. </title> <booktitle> In Proc. of 27th Annual Hawaii International Conference on System Sciences, </booktitle> <pages> pages 43-52, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: More parallelism could be revealed if we had alias information instead, but this extra parallelism would not be possible to express in a VDG (as defined in [WCES94a, WCES94b]). The parallelism can be expressed in a functional representation by adding a functional equivalent to the nodes of <ref> [SGW94] </ref>. * fi update C store val fl loc outstore * fi lookup C loc fl store outvalue * fi build C val fl outvalue * fi merge C S 1 fl S n outstore * fi restrict C spec fl store outstore 3.3 Quick fragmentation We have developed an almost
Reference: [SKR90] <author> Bernhard Steffen, Jens Knoop, and Oliver Ruthing. </author> <title> The value flow graph: A program representation for optimal program transformation. </title> <booktitle> In 3rd European Symposium on Programming, </booktitle> <pages> pages 389-405. </pages> <publisher> Springer Verlag, </publisher> <month> May </month> <year> 1990. </year>
Reference-contexts: 1 Introduction In recent years, the trend in program representations for imperative programs has been to make them more functional, or to make them more sparse. However, new sparse representations <ref> [CFR + 91, FOW87, PBJ + 90, SKR90, JP93] </ref> have been non-functional, and new functional representations [WCES94a, BMO90, Fie92] have not been sparse in the presence of pointer operations. In this paper, we present a functional representation that is sparse even in the presence of pointer operations.
Reference: [Ste95a] <author> Bjarne Steensgaard. </author> <title> Almost linear time points-to analysis. </title> <type> Technical report, </type> <institution> Microsoft Research, </institution> <year> 1995. </year> <note> In preparation. A version of this is submitted for publication. </note>
Reference-contexts: It has a relatively high cost to obtain, and offers maximum benefits in terms of exposing parallelism in the representation. We describe experience with both the thorough fragmentation and an intermediate level fragmentation that uses an al most linear time points-to analysis based on type inference <ref> [Ste95a] </ref>. We present store fragmentation in terms of the value dependence graph (VDG) [WCES94a, WCES94b], but the technique is equally useful for other program representations such as the program dependence web [BMO90] and PIM terms [Fie92]. We present a quick overview of the value dependence graph in Section 2. <p> lookup C loc fl store outvalue * fi build C val fl outvalue * fi merge C S 1 fl S n outstore * fi restrict C spec fl store outstore 3.3 Quick fragmentation We have developed an almost linear time points-to analysis whose results simultaneously serve as fragmentation configurations <ref> [Ste95a] </ref>. The algorithm is based on type inference using fast union/find data structures (the algorithm is inspired by [Hen91]). The algorithm computes relations between equivalence classes of locations. Equivalence classes remain the same over the entire program.
Reference: [Ste95b] <author> Bjarne Steensgaard. </author> <title> Experiments in store fragmentation. </title> <type> Technical report, </type> <institution> Microsoft Research, </institution> <year> 1995. </year> <note> In preparation. </note>
Reference-contexts: The ratio of store operation to store operations sans restrict operations in the representation of a program is typically smaller than the average number of abstract locations possibly modified by an update operation <ref> [Ste95b] </ref>. In terms of factored SSA forms, this means that the number of dependence edges in assignment factored SSA form is less than the number of dependence edges in location factored SSA form. 4 Experience The thorough store fragmentation appears to be useless for most purposes.
Reference: [TT94] <author> Mads Tofte and Jean-Pierre Talpin. </author> <title> Implementation of the typed call-by-value -calculus using a stack of regions. </title> <booktitle> In Proceedings 21st SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 188-201, </pages> <address> Portland, Oregon, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: These regions are examples of store fragments. However, FX with regions does not allow program point specific divisions of the store into disjoint areas. <ref> [TT94] </ref> describes an ML implementation without the usual ubiquitous garbage collector. They use a type inference analysis to compute regions in which the results of expressions should be written to (or allocated from).
Reference: [WCES94a] <author> Daniel Weise, Roger F. Crew, Michael Ernst, and Bjarne Steensgaard. </author> <title> Value dependence graphs: Representation without taxation. </title> <booktitle> In Proceedings 21st SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 297-310, </pages> <address> Portland, OR, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: 1 Introduction In recent years, the trend in program representations for imperative programs has been to make them more functional, or to make them more sparse. However, new sparse representations [CFR + 91, FOW87, PBJ + 90, SKR90, JP93] have been non-functional, and new functional representations <ref> [WCES94a, BMO90, Fie92] </ref> have not been sparse in the presence of pointer operations. In this paper, we present a functional representation that is sparse even in the presence of pointer operations. <p> We describe experience with both the thorough fragmentation and an intermediate level fragmentation that uses an al most linear time points-to analysis based on type inference [Ste95a]. We present store fragmentation in terms of the value dependence graph (VDG) <ref> [WCES94a, WCES94b] </ref>, but the technique is equally useful for other program representations such as the program dependence web [BMO90] and PIM terms [Fie92]. We present a quick overview of the value dependence graph in Section 2. Section 3 contains the technical results of the paper. <p> In Section 4 we report on our experience with the two types of fragmentation. In Section 5 we describe related work, and in Section 6 we summarize and indicate directions for future work. 2 The value dependence graph The value dependence graph (VDG) <ref> [WCES94a, WCES94b] </ref> is a graphical, functional representation for imperative programs. It has some resemblance to the demand view of the program dependence web [BMO90] and to graphical demand driven dataflow representations [PA85, PA86]. It can also be described as a graphical lambda calculus representation of imperative programs. <p> The thorough fragmentation exposes as much parallelism in the representation as is possible given only points-to information. More parallelism could be revealed if we had alias information instead, but this extra parallelism would not be possible to express in a VDG (as defined in <ref> [WCES94a, WCES94b] </ref>).
Reference: [WCES94b] <author> Daniel Weise, Roger F. Crew, Michael Ernst, and Bjarne Steensgaard. </author> <title> Value dependence graphs: Representation without taxation. </title> <type> Technical Report MSR-TR-94-03, </type> <institution> Microsoft Research, </institution> <address> Redmond, WA, </address> <month> April 13, </month> <year> 1994. </year>
Reference-contexts: We describe experience with both the thorough fragmentation and an intermediate level fragmentation that uses an al most linear time points-to analysis based on type inference [Ste95a]. We present store fragmentation in terms of the value dependence graph (VDG) <ref> [WCES94a, WCES94b] </ref>, but the technique is equally useful for other program representations such as the program dependence web [BMO90] and PIM terms [Fie92]. We present a quick overview of the value dependence graph in Section 2. Section 3 contains the technical results of the paper. <p> In Section 4 we report on our experience with the two types of fragmentation. In Section 5 we describe related work, and in Section 6 we summarize and indicate directions for future work. 2 The value dependence graph The value dependence graph (VDG) <ref> [WCES94a, WCES94b] </ref> is a graphical, functional representation for imperative programs. It has some resemblance to the demand view of the program dependence web [BMO90] and to graphical demand driven dataflow representations [PA85, PA86]. It can also be described as a graphical lambda calculus representation of imperative programs. <p> Stores are explicit values produced by primitive computations (as in denotational semantics for imperative languages [CF89]). An assignment (that cannot be eliminated by the methods described in <ref> [WCES94b] </ref> or [Ruf95]) is represented by a primitive operation (update) that takes a store argument and produces a new store. A VDG demonstrating pointer references and updates through pointers is shown in Figure 2. The initial VDG has many advantages when performing optimizations that only require local knowledge [WCES94b]. <p> described in <ref> [WCES94b] </ref> or [Ruf95]) is represented by a primitive operation (update) that takes a store argument and produces a new store. A VDG demonstrating pointer references and updates through pointers is shown in Figure 2. The initial VDG has many advantages when performing optimizations that only require local knowledge [WCES94b]. However, for performing analyses and many global transformations that involve store operations, the initial VDG is only slightly more useful than a control flow graph (CFG) [ASU86]. Using VDGs has advantages over non-functional program representations for performing sparseness increasing transformations. <p> The thorough fragmentation exposes as much parallelism in the representation as is possible given only points-to information. More parallelism could be revealed if we had alias information instead, but this extra parallelism would not be possible to express in a VDG (as defined in <ref> [WCES94a, WCES94b] </ref>).
References-found: 26

