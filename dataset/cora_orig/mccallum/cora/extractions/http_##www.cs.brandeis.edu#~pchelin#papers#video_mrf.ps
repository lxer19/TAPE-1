URL: http://www.cs.brandeis.edu/~pchelin/papers/video_mrf.ps
Refering-URL: http://www.cs.brandeis.edu/~pchelin/papers/
Root-URL: http://www.cs.brandeis.edu
Email: email: pchelin@cs.brandeis.edu  
Title: Region-based Video Compression  
Author: Peter Pchelin, 
Affiliation: Computer Science Department Brandeis University  
Abstract: The development of better video compression techniques is imperative to satisfying the rapidly increasing demand for the transmission and storage of digital video data. These techniques will largely influence the success of the MPEG-4 standard aimed at providing an extensive set of low bit-rate multimedia services. This paper presents a region-based video compression technique inspired by the Markov random field (MRF) model. Its main features include the application of both motion and intensity segmentation for coding as well as a technique that eliminates the need to transmit the segmentation itself. Another interesting feature of the method presented here is that it can guarantee coding efficiency that is as "good" as that of a block-based method under a few realistic assumptions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Bhaskaran, K. Konstantinides. </author> <title> Image and Video Compression Standards: Algorithms and Architectures. 2nd. </title> <editor> ed. </editor> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1997. </year>
Reference-contexts: Spatial redundancies occur within a single frame because of a strong correlation between a single pixel and its neighbors. Temporal redundancies are due to the presence of coherent objects undergoing motion from one frame to the next. Motion compensation techniques are geared towards reducing the temporal redundancy between frames <ref> [1] </ref>. Since there is a great deal of redundancy on that level, the efficiency of motion compensation has a direct impact on the overall efficiency of video compression. <p> This difference is called the Displacement Frame Difference (DFD.) Current video compression standards use block-based motion compensation for constructing the motion compensated frame and discrete cosine transform (DCT) for encoding the difference between the current frame and the motion compensated frame <ref> [1] </ref>. Block-based motion compensation works by subdividing the current frame into equally sized blocks and then for each block finding its closest match in the previous frame. In its simplest case, block-based motion compensation matches blocks in the current frame to those in the previous frame.
Reference: [2] <author> C.H. Hsieh, P.C. Lu, J.S. Shyu, and E.H. Lu. </author> <title> A motion estimation algorithm using interblock correlation. </title> <journal> Electronic Letters, </journal> <volume> vol. 26, no. 5, pp.276-277, </volume> <month> Mar </month> <year> 1990. </year>
Reference-contexts: Since motion of large homogenous areas is quite common, the displacement vectors of neighboring blocks tend to be correlated and this correlation must be removed to improve the compression <ref> [2, 3] </ref>. They also fail to capture the notion of objects and their trajectories. More sophisticated region-based motion compensation methods are being developed to address these issues.
Reference: [3] <author> M. Baker and A. Maeder. </author> <title> Region-Based Motion Compensation for Video Compression using a Quadtree Approach. </title> <journal> ITG-Fachberichte, </journal> <volume> no. 143, pp.585-590, </volume> <year> 1997. </year>
Reference-contexts: Since motion of large homogenous areas is quite common, the displacement vectors of neighboring blocks tend to be correlated and this correlation must be removed to improve the compression <ref> [2, 3] </ref>. They also fail to capture the notion of objects and their trajectories. More sophisticated region-based motion compensation methods are being developed to address these issues.
Reference: [4] <author> A.M. Tekalp, Y. Altunbasak, and G. Bozdagi. </author> <title> Two Versus Three-Dimensional Object-Based Video Compression. </title> <journal> IEEE Transactions on Circuits and Systems for Video Technology, </journal> <volume> vol. 7, no. 2, pp.391-397, </volume> <month> Apr </month> <year> 1997. </year>
Reference-contexts: The major problem with block-based motion compensation methods is that they produce blocking artifacts and motion jerkiness, especially at low bit rates <ref> [4] </ref>. Since motion of large homogenous areas is quite common, the displacement vectors of neighboring blocks tend to be correlated and this correlation must be removed to improve the compression [2, 3]. They also fail to capture the notion of objects and their trajectories.
Reference: [5] <author> M. Irani, B. Rousso, S. Peleg. </author> <title> Detecting and Tracking Multiple Moving Objects Using Temporal Integration. </title> <booktitle> Europ. Conference on Computer Vision, </booktitle> <address> Santa Margherita, Italy, </address> <pages> pp. 282-287, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Object tracking has been a very active area of research with such methods as temporal integration <ref> [5] </ref> and Kalman filtering [6] emerging as the methods with both theoretical and practical merit. 2 . 1 Motion Models The simplifying assumption behind most motion models used for video compression is that the motion within a scene is rigid body motion.
Reference: [6] <author> F. Ziliani and F. Moscheni. </author> <title> Kalman Filtering Motion Prediction for Recursive Spatio-Temporal Segmentation and Object Tracking. Signal Processing Laboratory, </title> <institution> Swiss Federal Institute of Technology, CH-1015 Lausanne, Switzerland. </institution>
Reference-contexts: Object tracking has been a very active area of research with such methods as temporal integration [5] and Kalman filtering <ref> [6] </ref> emerging as the methods with both theoretical and practical merit. 2 . 1 Motion Models The simplifying assumption behind most motion models used for video compression is that the motion within a scene is rigid body motion.
Reference: [7] <author> P. Bouthemy and E. Franois. </author> <title> Motion Segmentation and Qualitative Dynamic Scene Analysis from an Image Sequence. </title> <journal> International Journal of Computer Vision, </journal> <volume> vol. 10, no. 2, pp.157-182, </volume> <month> Apr </month> <year> 1993. </year>
Reference-contexts: More complicated models with eight or more parameters can also be used, but they induce a significantly higher computational burden and produce a greater amount of overhead information. Affine model or a simplified version thereof seems to be a good tradeoff in that regard <ref> [7] </ref>. 2 . 2 Scene Segmentation Scene segmentation aims at segmenting the scene into regions characterized by coherent motion. Since motion is constrained by a motion model, this type of segmentation is defined with respect to such a model. <p> The whole process is recursively repeated for each such segment [12]. The methods in the fourth category aim at simultaneously deriving the segmentation and the motion parameters. This is accomplished by expressing the segmentation problem in the framework of Markov random field (MRF) modeling <ref> [13, 14, 7, 15] </ref> where the final segmentation is defined by a minima of an energy function obtained through relaxation. By using a Bayesian criterion [16] this approach is able to balance the prior knowledge about the segmentation and the actual data in theoretically robust fashion. <p> A special case of Bayes labeling is given by the Maximum A Posterior (MAP) solution that maximizes the posterior probability of a state given the data. In practice this is achieved by minimizing the energy function U through relaxation. In the work of Patrick Bouthemy and Edouard Franois <ref> [7] </ref> the energy function U is a sum of two energy terms: U = U 1 + U 2 . 8 The first term denotes the prior energy. It encodes the knowledge that the regions in the resulting segmentation are homogeneous and have regular boundaries. <p> All three steps are presented below in more detail. 3 . 1 Motion-based segmentation Similarly to the work of Bouthemy and Franois <ref> [7] </ref>, the proposed method relies on Markov random field model to segment the current frame. <p> Note that the second term relies on the motion parameters that have to be estimated during the segmentation process. Instead of recalculating the motion parameters each time a label is changed, the algorithm alternates between relabeling and parameter estimation. Similarly to <ref> [7] </ref>, in order to introduce new regions a special label with the following energy is considered: m (1 - d e s ,e t ) + f 2s s r . where s r 2 is a posteriori estimated variance of the second energy term [I (s, t) I (s - <p> The constant f is determined using c 2 distribution <ref> [7] </ref> which makes it approximately 10 for our purposes. 12 After one relabeling cycle, the proposed algorithm assigns new labels to the areas marked with the special label.
Reference: [8] <author> P. Salembier and M. Pardas. </author> <title> Hierarchical Morphological Segmentation for Image Sequence Coding. </title> <journal> IEEE Trans. Image Proces., </journal> <volume> vol. 3, no. 5, pp.639-651, </volume> <month> Sep </month> <year> 1994. </year>
Reference-contexts: Methods in the first category create the initial scene segmentation based on the luminance information. Mathematical morphology turns out to be wellsuited for that task since it deals with geometrical features that can be extracted with efficient algorithms <ref> [8] </ref>. The main assumption behind these methods is that the intensity boundaries correspond to the motion boundaries [9]. This assumption is violated in practice, for example when objects in the scene are composed of multiple parts or when only one part of an object is subject to motion.
Reference: [9] <author> V.N. Dang, A.R. Mansouri, and J. Konrad. </author> <title> Motion Estimation for Region-Based Video Coding. </title> <booktitle> International Conference on Image Processing ICIP '95, </booktitle> <address> Washington, DC, USA, Oct 23-26, </address> <year> 1995. </year>
Reference-contexts: Mathematical morphology turns out to be wellsuited for that task since it deals with geometrical features that can be extracted with efficient algorithms [8]. The main assumption behind these methods is that the intensity boundaries correspond to the motion boundaries <ref> [9] </ref>. This assumption is violated in practice, for example when objects in the scene are composed of multiple parts or when only one part of an object is subject to motion.
Reference: [10] <author> L. Kaufman and P.J. Rousseeuw. </author> <title> Finding Groups in Data: an Introduction to Cluster Analysis. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: The next category of methods relies on dense optical flow for segmentation and motion estimation. Frequently, motion vectors are grouped together into coherent regions via a clustering technique <ref> [10] </ref> and the motion parameters are determined using least-mean-squared (LMS) regression [11]. This method alternates between clustering and motion estimation until 5 convergence is reached.
Reference: [11] <author> J.Y.A Wang and E.H. Adelson. </author> <title> Representing moving objects with layers. </title> <journal> IEEE Trans. Image Proces., </journal> <volume> vol. 3, no. 5, </volume> <pages> pp. 625-638, </pages> <month> Sep </month> <year> 1994. </year>
Reference-contexts: The next category of methods relies on dense optical flow for segmentation and motion estimation. Frequently, motion vectors are grouped together into coherent regions via a clustering technique [10] and the motion parameters are determined using least-mean-squared (LMS) regression <ref> [11] </ref>. This method alternates between clustering and motion estimation until 5 convergence is reached. Clearly, the accuracy of this method is closely linked to the accuracy of the estimated dense optical flow and consequently it tends to be very error-prone in case of sudden motion and on the motion boundaries.
Reference: [12] <author> S. Peleg and H. </author> <title> Rom. Motion based segmentation. </title> <booktitle> IEEE Proc. Int. Conf. on Pattern Recognition, </booktitle> <address> Atlantic City, NJ, pp.109-113, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: One such method estimates the dominant motion within a (fragment of a) scene and then creates new segments that correspond to the areas that are poorly described by this motion. The whole process is recursively repeated for each such segment <ref> [12] </ref>. The methods in the fourth category aim at simultaneously deriving the segmentation and the motion parameters.
Reference: [13] <author> J. Konrad and V.-N. Dang. </author> <title> Coding-Oriented Video Segmentation Inspired by MRF Models. </title> <booktitle> IEEE International Conference on Image Processing ICIP'96, </booktitle> <address> Lausanne, Switzerland, </address> <month> Sep 16-19. 17 </month>
Reference-contexts: The whole process is recursively repeated for each such segment [12]. The methods in the fourth category aim at simultaneously deriving the segmentation and the motion parameters. This is accomplished by expressing the segmentation problem in the framework of Markov random field (MRF) modeling <ref> [13, 14, 7, 15] </ref> where the final segmentation is defined by a minima of an energy function obtained through relaxation. By using a Bayesian criterion [16] this approach is able to balance the prior knowledge about the segmentation and the actual data in theoretically robust fashion.
Reference: [14] <author> E. Franois, J.-F. Vial, and B. Chupeau. </author> <title> Coding Algorithm with Region-Based Motion Compensation. </title> <journal> IEEE Trans. on Circuits and Systems for Video Technology, </journal> <volume> vol. 7, no. 1, pp.97-108, </volume> <month> Feb </month> <year> 1997. </year>
Reference-contexts: The whole process is recursively repeated for each such segment [12]. The methods in the fourth category aim at simultaneously deriving the segmentation and the motion parameters. This is accomplished by expressing the segmentation problem in the framework of Markov random field (MRF) modeling <ref> [13, 14, 7, 15] </ref> where the final segmentation is defined by a minima of an energy function obtained through relaxation. By using a Bayesian criterion [16] this approach is able to balance the prior knowledge about the segmentation and the actual data in theoretically robust fashion.
Reference: [15] <author> C.-H. Yang and J. Konrad. </author> <title> Motion-based video segmentation using continuation method and robust cost functions. </title> <booktitle> IS&T/SPIE Symposium on Electronic Imaging Visual Communications and Image Processing, </booktitle> <address> San Jose, CA, USA, </address> <month> Jan 24-30, </month> <year> 1998. </year>
Reference-contexts: The whole process is recursively repeated for each such segment [12]. The methods in the fourth category aim at simultaneously deriving the segmentation and the motion parameters. This is accomplished by expressing the segmentation problem in the framework of Markov random field (MRF) modeling <ref> [13, 14, 7, 15] </ref> where the final segmentation is defined by a minima of an energy function obtained through relaxation. By using a Bayesian criterion [16] this approach is able to balance the prior knowledge about the segmentation and the actual data in theoretically robust fashion.
Reference: [16] <author> S.Z. Li, ed: T. L. Kunii. </author> <title> Markov Random Field Modeling in Computer Vision. </title> <publisher> Springer-Verlag, </publisher> <address> Tokyo, </address> <year> 1995. </year>
Reference-contexts: This is accomplished by expressing the segmentation problem in the framework of Markov random field (MRF) modeling [13, 14, 7, 15] where the final segmentation is defined by a minima of an energy function obtained through relaxation. By using a Bayesian criterion <ref> [16] </ref> this approach is able to balance the prior knowledge about the segmentation and the actual data in theoretically robust fashion. <p> They are used to model statistical dependencies that are context-based by defining probabilistic interactions between random variables. The following discussion draws heavily on that of S.Z. Li <ref> [16] </ref>. Let F = -F 1, ..., F m - be a set of random variables where each F i can take on a value from a set of labels L. <p> By using appropriate clique potential functions it is possible to encode a priori knowledge about interaction between labels consequently determining system's behavior. In that context the energy function determines how neighbors contribute to the probability of a certain configuration <ref> [16] </ref>. In case of vision problems, the energy function's minimum gives the "optimal" labeling of the sites (i.e. the segmentation) given the prior distribution and the likelihood function of a pattern. According to Bayes statistics the best possible labeling given these two pieces of information is Bayes labeling [16]. <p> certain configuration <ref> [16] </ref>. In case of vision problems, the energy function's minimum gives the "optimal" labeling of the sites (i.e. the segmentation) given the prior distribution and the likelihood function of a pattern. According to Bayes statistics the best possible labeling given these two pieces of information is Bayes labeling [16]. A special case of Bayes labeling is given by the Maximum A Posterior (MAP) solution that maximizes the posterior probability of a state given the data. In practice this is achieved by minimizing the energy function U through relaxation. <p> It encodes the knowledge that the regions in the resulting segmentation are homogeneous and have regular boundaries. Multilevel logistic model <ref> [16] </ref> is used by the authors in that case. <p> The minimization of this energy function is performed using ICM relaxation <ref> [16] </ref>. In spirit, ICM is similar to steepest descend since it works by considering the energy for each consecutive site and finding a label that would minimize the energy at that site.
Reference: [17] <author> A. Singh. </author> <title> Optic Flow Computation: A Uniform Perspective. </title> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1991. </year>
Reference-contexts: Higher values of m encourage the formation of more homogeneous segments while lower values of m make the segments less coherent. The second energy term determines the "closeness" of the observed and estimated data. Patrick Bouthemy and Edouard Franois base it on the image-flow constraint equation <ref> [17] </ref> which relates spatio-temporal derivatives ( I, I t ) to the velocity vector ( w ): I w + I t = 0 . <p> The first kind first computes a dense motion field using non-parametric technique and then fits the model parameters to this field. Since non-parametric motion field estimation is an ill-posed problem, it requires an additional constraint. This constraint is usually the smoothness or the local uniformity of the field <ref> [17] </ref>. This technique is indirect because it relies on the results of the non-parametric motion field estimation instead of the luminance signal itself. As such, it is very sensitive to the errors in the initial motion field. <p> Direct motion estimation techniques divide into differential methods and matching methods. Differential methods rely on a model of the luminance described by a Taylor series expansion of the luminance signal <ref> [17] </ref>.
Reference: [18] <author> B.K.P. Horn and B. Schunck. </author> <title> Determining Optical Flow. </title> <journal> Artificial Intelligence, </journal> <volume> no. 17, pp.185-203, </volume> <year> 1981. </year>
Reference-contexts: Consequently, Horn and Schunck <ref> [18] </ref> propose minimizing the following quantity: dx x I + dt t over the entire motion field. Matching techniques make no assumptions about the luminance signal and estimate the motion parameters by minimizing the normalized error between the luminance signal and the region for which the parameters are being estimated.
Reference: [19] <author> F. Moscheni, F. Dufaux, and M. Kunt. </author> <title> A new two stage global/local motion estimation based on a background/foreground segmentation. </title> <booktitle> IEEE Proc. </booktitle> <address> ICASSP'95, Detroit, MI, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: The method presented in this paper uses matching for motion estimation since matching techniques tend to be very robust <ref> [19] </ref>. 3 The Proposed Method The proposed method utilizes two previous frames (I'll call them previous and current) in order to encode the next frame. First, it segments the current frame based on the motion between it and the previous frame. It also segments the current frame based on intensity.
Reference: [20] <author> Y. Yokoyama, Y. Miyamoto, and M. Ohta. </author> <title> Very low bit rate Video Coding using Arbitrarily Shaped Region-based Motion Compensation. </title> <journal> IEEE Trans. on Circuits and Systems for Video Technology, </journal> <volume> vol. 5, no. 6, </volume> <month> Dec </month> <year> 1995. </year>
Reference-contexts: It also segments the current frame based on intensity. Second, it uses both segmentations to construct the motion-compensated version of the next frame and to compute the motion parameters. This approach is similar to that of Yokoyama, Miyamoto, and Ohta <ref> [20] </ref> since it derives the segmentation of the scene based on the previously reconstructed frame making it unnecessary to transmit the segmentation itself.
Reference: [21] <author> H.Nicloas, S. Pateux, D. Le Guen. </author> <title> Region-based Video Compression using Minimum Description Length Criteria. </title> <journal> ITG-Fachberichte, </journal> <volume> no. 143, pp.603-608, </volume> <year> 1997. </year>
Reference-contexts: For videconference-type sequences this results in significant savings because the coding of segmentation can account for more than 50% of the total coding cost for such sequences <ref> [21] </ref>. Motion-based segmentation is complemented by intensity-based segmentation because it fails to identify nonmoving objects in the scene. This turns out to be a serious handicap because many types of sequences contain objects that exhibit sudden (jerky) motion.
Reference: [22] <author> J. Benois, L. Wu, and D. Barba. </author> <title> Joint contour-based and Motion-based Image Sequences Segmentation for TV Image Coding at Low Bit-Rate. </title> <booktitle> Proc. of SPIE-the International Society for Optical Engineering, </booktitle> <volume> vol. 2308, pp.1074-1085, </volume> <year> 1994. </year>
Reference-contexts: A number of works use intensity-based segmentation to alleviate such problems. For instance, J. Benois, L. Wu, and D. Barba provide a segmentation 11 algorithm that uses joint contour and motion-based segmentation <ref> [22] </ref> while the method proposed in this paper performs each segmentation separately. The last step involves handling the uncovered and the overlapping regions within the motion-compensated frame.
Reference: [23] <author> D. Mukherjee, Y. Deng, and S. K. Mitra. </author> <title> A Region-based Video Coder Using Edge Flow Segmentation and Hierarchical Affine Region Matching. </title> <institution> Department of Electrical and Computer Engineering, University of California, Santa Barbara, </institution> <address> CA. </address>
Reference-contexts: These regions commonly occur around the object's boundaries and can be quite large in case of newly appearing objects or rapid motion. The proposed method utilizes the technique by D. Mukherjee, Y. Deng, and S. K. Mitra <ref> [23] </ref> for handling uncovered areas. These areas are segmented into smaller regions and then "filled-in" from the previous frame by backward motion compensation. Since the decoder knows what the uncovered areas look like, it can run the same segmentation procedure as the encoder to reconstruct the motion-compensated frame.
References-found: 23

