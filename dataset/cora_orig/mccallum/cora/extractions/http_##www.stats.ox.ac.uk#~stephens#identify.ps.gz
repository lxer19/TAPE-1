URL: http://www.stats.ox.ac.uk/~stephens/identify.ps.gz
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email: stephens@stats.ox.ac.uk  
Title: Dealing with the Multimodal Distributions of Mixture Model Parameters  
Author: Matthew Stephens 
Keyword: BAYESIAN METHODS, MARKOV CHAIN MONTE CARLO, MIXTURE MODELS, NON-IDENTIFIABILITY, SEM ALGORITHM, SYMMETRIC POSTERIOR  
Date: November 1996  
Address: Oxford  
Affiliation: Department of Statistics University of  
Abstract: In a Bayesian analysis of finite mixture models, the symmetry and multi-modality of the posterior distribution of the parameters makes it difficult to interpret or summarize. The common practice of making parameters identifiable by imposing artificial constraints biases parameter estimates and generally fails to solve the problem of multimodality. We suggest a solution which involves permuting samples from the parameter posterior density so as to remove as much multimodality as possible, and demonstrate its effectiveness on a simulated example. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Celeux, G., Chauveau, D. and Diebolt, J. </author> <title> (1995) On stochastic versions of the EM algorithm. </title> <type> Technical Report 2514, </type> <institution> INRIA Rhone-Alpes. </institution>
Reference: <author> Cowles, M. K. and Carlin, B. P. </author> <title> (1996) Markov Chain Monte Carlo convergence diagnostics: a comparative review. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 91, </volume> <pages> 883-904. </pages>
Reference: <author> Diebolt, J. and Robert, C. P. </author> <title> (1994) Estimation of finite mixture distributions through Bayesian sampling. </title> <journal> Journal of the Royal Statistics Society, Series B, </journal> <volume> 56(2), </volume> <pages> 363-375. </pages>
Reference: <author> Robert, C. P. </author> <title> (1994) The Bayesian Choice: a Decision-Theoretic Motivation. Springer Texts in Statistics. </title> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: for the completed sample (the sample together with the list of components from which each observation arose) are ( 1 ; 2 ; 3 ) = (0:16; 5:00; 4:79), ( 2 2 ; 2 The conjugate prior for = (; ; 2 ) in this case is of the form <ref> (Robert, 1994, page 152) </ref> p () = D (; a 1 ; : : :; a k ) i=1 i ; m i ; l i )N ( i ; u i ; 2 where D (; a) is the density of the Dirichlet distribution with parameter a = (a 1
Reference: <author> Robert, C. P. </author> <title> (1995) Convergence control methods for Markov Chain Monte Carlo algorithms. </title> <journal> Statistical Science, </journal> <volume> 10(3), </volume> <pages> 231-253. </pages>
Reference: <author> Robert, C. P. </author> <title> (1996) Mixtures of distributions: Inference and estimation. In Markov Chain Monte Carlo in Practice (Eds W. </title> <editor> R. Gilks, S. Richardson and D. J. Spiegel-halter). </editor> <publisher> London: Chapman & Hall. </publisher>
Reference: <author> Tanner, M. and Wong, W. </author> <title> (1987) The calculation of posterior distributions by data augmentation. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 82, </volume> <pages> 528-550. 7 </pages>
References-found: 7

