URL: http://www.cs.panam.edu/~meng/unix-home/TechRep/ornl.ps
Refering-URL: http://www.cs.panam.edu/~meng/unix-home/TechRep/
Root-URL: http://www.cs.panam.edu
Title: A STUDY OF APPLICATION SENSITIVITY TO VARIATION IN MESSAGE PASSING LATENCY AND BANDWIDTH  
Author: Patrick H. Worley Allen C. Robinson David R. Mackay Edward J. Barragy flfl 
Date: June, 1996  
Note: Date Published:  Research was supported by the Mathematical, Information and Computational Sciences Division of the Office of Computational and Technology Research Program, Office of Energy Research, U.S. Department of Energy Prepared by the  managed by Lockheed Martin Energy Research Corp. for the U.S. DEPARTMENT OF ENERGY under Contract No. DE-AC05-96OR22464  
Address: P. O. Box 2008, Oak Ridge, TN 37831-6367  1431, P.O. Box 5800, Albu querque, NM 87185-0819  P. O. Box 2008, Oak Ridge, TN 37831-6203  CO1-02, 15201 NW Greenbrier Pkwy, Beaver ton OR, 97006  Oak Ridge, Tennessee 37831  
Affiliation: Computer Science and Mathematics Division Mathematical Sciences Section  Oak Ridge National Laboratory, Mathematical Sciences Section,  Sandia National Laboratories, Computational Physics Research Development,  Intel Corp., Oak Ridge National Laboratory, Center for Computational Sciences,  flfl Intel Corp,  Oak Ridge National Laboratory  
Pubnum: ORNL/TM-13250  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. Brehm, L. Dowdy, M. Madhukar, and E. Smirni, </author> <title> PerPreT a performance prediction tool, in Quantitative Evaluation of Computing and Communication Systems, </title> <booktitle> Lecture Notes in Computer Science 977, </booktitle> <publisher> Springer, </publisher> <address> Heidelberg, </address> <year> 1995. </year>
Reference-contexts: Such characterizations can be used to help explain the empirically observed performance difference across parallel platforms [6], [5] or between message passing libraries [15], or used to determine rates in performance models <ref> [1] </ref>. There has been significantly less work in characterizing the communication requirements of production-level parallel application codes, and, to our knowledge, almost no research on performance sensitivity to changes in latency, bandwidth, and topology.
Reference: [2] <author> G. L. Browning, J. J. Hack, and P. N. Swarztrauber, </author> <title> A comparison of three numerical methods for solving differential equations on the sphere, </title> <journal> Mon. Wea. Rev., </journal> <volume> 117 (1989), </volume> <pages> pp. 1058-1075. </pages>
Reference-contexts: The nonlinear shallow water equations are a two-dimensional atmospheric-like fluid prediction model that exhibits many of the features of more complete models and is commonly used to investigate numerical methods <ref> [2] </ref>.
Reference: [3] <author> J. D. Dongarra and T. H. Dunigan, </author> <title> Message-passing performance of various computers, </title> <type> Tech. Report ORNL/TM-13006, </type> <institution> Oak Ridge National Laboratory, Oak Ridge, TN, </institution> <month> February </month> <year> 1996. </year>
Reference-contexts: The information in this study is useful in optimizing machine design for cost performance and for scaling to tens of thousands of processors. Performance studies of communication latency and bandwidth are most commonly used to characterize the peak or "peak achievable" performance on parallel platforms <ref> [3] </ref>. Such characterizations can be used to help explain the empirically observed performance difference across parallel platforms [6], [5] or between message passing libraries [15], or used to determine rates in performance models [1].
Reference: [4] <author> J. B. Drake, I. T. Foster, J. G. Michalakes, B. Toonen, and P. H. Worley, </author> <title> Design and performance of a scalable parallel community climate model, </title> <booktitle> Parallel Computing, 21 (1995), </booktitle> <pages> pp. 1571-1591. </pages>
Reference-contexts: transform algorithm of the code follows closely how CCM2, the Community Climate Model developed at the National Center for Atmospheric Research (NCAR), handles the dynamical part of the primitive equations [7], and the parallel algorithms implemented in PSTSWM include those currently used in PCCM2, the message-passing parallel implementation of CCM2 <ref> [4] </ref>. PSTSWM is used to evaluate the performance of parallel platforms for spectral atmospheric circulation models and to develop new parallel algorithms for use in PCCM2 [5], [6].
Reference: [5] <author> I. T. Foster, B. Toonen, and P. H. Worley, </author> <title> Performance of parallel computers for spectral atmospheric models, </title> <type> Tech. Report ORNL/TM-12986, </type> <institution> Oak Ridge National Laboratory, Oak Ridge, TN, </institution> <month> April </month> <year> 1995. </year> <note> (also, J. Atm. Oceanic Tech accepted). </note>
Reference-contexts: Performance studies of communication latency and bandwidth are most commonly used to characterize the peak or "peak achievable" performance on parallel platforms [3]. Such characterizations can be used to help explain the empirically observed performance difference across parallel platforms [6], <ref> [5] </ref> or between message passing libraries [15], or used to determine rates in performance models [1]. There has been significantly less work in characterizing the communication requirements of production-level parallel application codes, and, to our knowledge, almost no research on performance sensitivity to changes in latency, bandwidth, and topology. <p> PSTSWM is used to evaluate the performance of parallel platforms for spectral atmospheric circulation models and to develop new parallel algorithms for use in PCCM2 <ref> [5] </ref>, [6]. PSTSWM is a parallel implementation of the sequential code STSWM [8] developed at NCAR that has subsequently been modified to add vertical levels to the code, allowing the parallel algorithms to better capture the requirements and performance for three dimensional models like PCCM2.
Reference: [6] <author> I. T. Foster and P. H. Worley, </author> <title> Parallel algorithms for the spectral transform method, </title> <type> Tech. Report ORNL/TM-12507, </type> <institution> Oak Ridge National Laboratory, Oak Ridge, TN, </institution> <month> May </month> <year> 1994. </year> <note> (also, SIAM J. Sci. Comput. accepted). </note>
Reference-contexts: Performance studies of communication latency and bandwidth are most commonly used to characterize the peak or "peak achievable" performance on parallel platforms [3]. Such characterizations can be used to help explain the empirically observed performance difference across parallel platforms <ref> [6] </ref>, [5] or between message passing libraries [15], or used to determine rates in performance models [1]. There has been significantly less work in characterizing the communication requirements of production-level parallel application codes, and, to our knowledge, almost no research on performance sensitivity to changes in latency, bandwidth, and topology. <p> PSTSWM is used to evaluate the performance of parallel platforms for spectral atmospheric circulation models and to develop new parallel algorithms for use in PCCM2 [5], <ref> [6] </ref>. PSTSWM is a parallel implementation of the sequential code STSWM [8] developed at NCAR that has subsequently been modified to add vertical levels to the code, allowing the parallel algorithms to better capture the requirements and performance for three dimensional models like PCCM2.
Reference: [7] <author> J. J. Hack, B. A. Boville, B. P. Briegleb, J. T. Kiehl, P. J. Rasch, and D. L. Williamson, </author> <title> Description of the NCAR Community Climate Model (CCM2), </title> <type> NCAR Tech. </type> <institution> Note NCAR/TN-382+STR, National Center for Atmospheric Research, Boulder, Colo., </institution> <year> 1992. </year> <month> - 20 </month> - 
Reference-contexts: The spectral transform algorithm of the code follows closely how CCM2, the Community Climate Model developed at the National Center for Atmospheric Research (NCAR), handles the dynamical part of the primitive equations <ref> [7] </ref>, and the parallel algorithms implemented in PSTSWM include those currently used in PCCM2, the message-passing parallel implementation of CCM2 [4]. PSTSWM is used to evaluate the performance of parallel platforms for spectral atmospheric circulation models and to develop new parallel algorithms for use in PCCM2 [5], [6].
Reference: [8] <author> J. J. Hack and R. Jakob, </author> <title> Description of a global shallow water model based on the spectral transform method, </title> <type> NCAR Tech Note NCAR/TN-343+STR, </type> <institution> National Center for Atmospheric Research, Boulder, CO, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: PSTSWM is used to evaluate the performance of parallel platforms for spectral atmospheric circulation models and to develop new parallel algorithms for use in PCCM2 [5], [6]. PSTSWM is a parallel implementation of the sequential code STSWM <ref> [8] </ref> developed at NCAR that has subsequently been modified to add vertical levels to the code, allowing the parallel algorithms to better capture the requirements and performance for three dimensional models like PCCM2.
Reference: [9] <author> P. Heidelberger and K. S. Trivedi, </author> <title> Analytic queuing models for programs with internal concurrency, </title> <journal> IEEE Trans. Comput., </journal> <volume> c-32 (1983), </volume> <pages> pp. 73-82. </pages>
Reference-contexts: One reason for this lack is that performance modeling techniques that can accurately model network performance, like Markov models and Petri nets <ref> [9] </ref>, [19], [20], are impractical to apply to full application codes running on hundreds or thousands of processors. The alternative is to do empirical studies using representative application codes.
Reference: [10] <author> G. Lyon, R. Kacker, and A. Linz, </author> <title> A scalability test for parallel code, </title> <journal> Software: Practise and Experience, </journal> <volume> 25 (1995), </volume> <pages> pp. 1299-1314. </pages>
Reference-contexts: The alternative is to do empirical studies using representative application codes. The work closest in spirit to our research is the synthetic-perturbation technique developed at the National Institute of Standards <ref> [10] </ref>, [11] and the performance studies by Rothberg [17], [18].
Reference: [11] <author> G. Lyon, R. Snelick, and R. Kacker, </author> <title> Synthetic-perturbation tuning of MIMD programs, </title> <journal> The Journal of Supercomputing, </journal> <volume> 8 (1994), </volume> <pages> pp. 5-28. </pages>
Reference-contexts: The alternative is to do empirical studies using representative application codes. The work closest in spirit to our research is the synthetic-perturbation technique developed at the National Institute of Standards [10], <ref> [11] </ref> and the performance studies by Rothberg [17], [18]. <p> The second approach used to degrade net bandwidth is to degrade message latency by inserting spin waits in the communication routines. Various levels of degradation are achieved by varying the time spent in the spin wait, similar to the approaches used in <ref> [11] </ref>, [17], and [18]. All simulations were run on Intel Paragon systems under the SUNMOS operating system [12], [21].
Reference: [12] <author> A. B. Maccabe, K. S. McCurley, R. Riesen, and S. R. Wheat, </author> <title> SUNMOS for the Intel Paragon: A brief users guide, in Proceedings of the Intel Supercomputer Users' Group 1994, Intel Supercomputer Users' Group, </title> <booktitle> 1994, </booktitle> <pages> pp. 245-251. </pages>
Reference-contexts: Various levels of degradation are achieved by varying the time spent in the spin wait, similar to the approaches used in [11], [17], and [18]. All simulations were run on Intel Paragon systems under the SUNMOS operating system <ref> [12] </ref>, [21]. SUNMOS is used in these experiments rather than the vendor-supplied OSF node operating system because SUNMOS provides lower latency, higher bandwidth, and uses less memory, allowing more of the parameter space to be examined.
Reference: [13] <author> B. Machenhauer, </author> <title> The spectral method, in Numerical Methods Used in Atmospheric Models, vol. II of GARP Pub. </title> <journal> Ser. </journal> <volume> No. 17. </volume> <publisher> JOC, World Meteorological Organization, </publisher> <address> Geneva, Switzerland, </address> <year> 1979, </year> <journal> ch. </journal> <volume> 3, </volume> <pages> pp. 121-275. </pages>
Reference-contexts: PSTSWM PSTSWM is a parallel algorithm testbed and benchmark code developed at Oak Ridge National Laboratory and Argonne National Laboratory that solves the nonlinear shallow water equations on a rotating sphere using the spectral transform method <ref> [13] </ref>. The nonlinear shallow water equations are a two-dimensional atmospheric-like fluid prediction model that exhibits many of the features of more complete models and is commonly used to investigate numerical methods [2].
Reference: [14] <author> J. M. McGlaun, S. L. Thompson, and M. G. Elrick, </author> <title> CTH: A three dimensional shock wave physics code, </title> <journal> Int. J. of Impact Engineering, </journal> <volume> 10 (1990), </volume> <pages> pp. 351-360. </pages>
Reference-contexts: The code is a parallel version of the CTH shock physics code, a highly regarded modeling tool in the DoD and DOE modeling community, that models large-deformation material motion arising from high explosive detonation or high velocity impacts <ref> [14] </ref>. The algorithm implemented in the code solves equations modeling the conservation of mass, momentum and energy through a two stage process. The first stage models the change in physical quantities as seen in the frame of moving material.
Reference: [15] <author> J. Painter, P. McCormick, M. Krogh, C. Hansen, and G. C. de Verdi ere, </author> <title> The ACL message passing library, </title> <booktitle> EPFL Supercomputing Review, </booktitle> <month> 7 </month> <year> (1995). </year>
Reference-contexts: Performance studies of communication latency and bandwidth are most commonly used to characterize the peak or "peak achievable" performance on parallel platforms [3]. Such characterizations can be used to help explain the empirically observed performance difference across parallel platforms [6], [5] or between message passing libraries <ref> [15] </ref>, or used to determine rates in performance models [1]. There has been significantly less work in characterizing the communication requirements of production-level parallel application codes, and, to our knowledge, almost no research on performance sensitivity to changes in latency, bandwidth, and topology.
Reference: [16] <author> A. C. Robinson and C. T. Vaughan, </author> <title> Block grid application, in High Performance Computing, </title> <editor> G. Sabot, ed., </editor> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, </address> <year> 1995, </year> <note> ch. 2. </note>
Reference-contexts: Applications 2.1. PCTH PCTH was developed at Sandia National Laboratories and is a parallel three-dimensional shock wave physics code currently being used as a production simulation tool <ref> [16] </ref>. The code is a parallel version of the CTH shock physics code, a highly regarded modeling tool in the DoD and DOE modeling community, that models large-deformation material motion arising from high explosive detonation or high velocity impacts [14].
Reference: [17] <author> E. Rothberg, </author> <title> Characterization of paragon performance benchmarks. Intel Internal Correspondence Memo, </title> <month> February </month> <year> 1994. </year> <title> [18] , Communication characteristics of parallel scientific applications. Intel Internal Correspondence Memo, </title> <month> August </month> <year> 1994. </year>
Reference-contexts: The alternative is to do empirical studies using representative application codes. The work closest in spirit to our research is the synthetic-perturbation technique developed at the National Institute of Standards [10], [11] and the performance studies by Rothberg <ref> [17] </ref>, [18]. The synthetic-perturbation technique inserts idle loops into programs to determine the effect on overall performance of this type of perturbation, It was developed as a technique for identifying which routines are most important to tune when attempting to improve the performance of a parallel code. <p> The second approach used to degrade net bandwidth is to degrade message latency by inserting spin waits in the communication routines. Various levels of degradation are achieved by varying the time spent in the spin wait, similar to the approaches used in [11], <ref> [17] </ref>, and [18]. All simulations were run on Intel Paragon systems under the SUNMOS operating system [12], [21].
Reference: [19] <author> A. Thomasian and P. F. </author> <title> Bay, Analytic queuing network models for parallel processing of task systems, </title> <journal> IEEE Trans. Comput., </journal> <volume> c-35 (1986), </volume> <pages> pp. 1045-1054. </pages>
Reference-contexts: One reason for this lack is that performance modeling techniques that can accurately model network performance, like Markov models and Petri nets [9], <ref> [19] </ref>, [20], are impractical to apply to full application codes running on hundreds or thousands of processors. The alternative is to do empirical studies using representative application codes.
Reference: [20] <author> H. Wabnig and G. Haring, </author> <title> PAPS the parallel program performance prediction toolset, </title> <booktitle> in 7th International Conference on Modeling Techniques and Tools for Computer Performance Evaluation, </booktitle> <year> 1994, </year> <pages> pp. 284-304. - 21 </pages> - 
Reference-contexts: One reason for this lack is that performance modeling techniques that can accurately model network performance, like Markov models and Petri nets [9], [19], <ref> [20] </ref>, are impractical to apply to full application codes running on hundreds or thousands of processors. The alternative is to do empirical studies using representative application codes.
Reference: [21] <author> S. R. Wheat, A. B. Maccabe, R. Riesen, D. W. van Dresser, and T. M. Stall-cup, </author> <title> An operating system for massively parallel systems, </title> <booktitle> in Proceedings of the Twenty Seventh Annual Hawaii International Conference on System Sciences, </booktitle> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1994, </year> <pages> pp. 56-65. </pages>
Reference-contexts: Various levels of degradation are achieved by varying the time spent in the spin wait, similar to the approaches used in [11], [17], and [18]. All simulations were run on Intel Paragon systems under the SUNMOS operating system [12], <ref> [21] </ref>. SUNMOS is used in these experiments rather than the vendor-supplied OSF node operating system because SUNMOS provides lower latency, higher bandwidth, and uses less memory, allowing more of the parameter space to be examined.
Reference: [22] <author> D. L. Williamson, J. B. Drake, J. J. Hack, R. Jakob, and P. N. Swarztrauber, </author> <title> A standard test set for numerical approximations to the shallow water equations on the sphere, </title> <journal> J. Computational Physics, </journal> <volume> 102 (1992), </volume> <pages> pp. 211-224. </pages>
Reference-contexts: PSTSWM also has embedded 6 of the 7 test cases specified by Williamson et al. <ref> [22] </ref> to test the ability of numerical methods to simulate important flow phenomena. The spectral transform is the most complicated portion of a spectral atmospheric circulation code to parallelize, and the performance is sensitive to how it is done.
Reference: [23] <author> P. H. Worley and B. Toonen, </author> <title> A users' guide to PSTSWM, </title> <type> Tech. Report ORNL/TM-12779, </type> <institution> Oak Ridge National Laboratory, Oak Ridge, TN, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: There are also options for specifying how data is exchanged between nodes, including whether to try to overlap communication and computation, and what message-passing interface to use <ref> [23] </ref>. For the results presented in this paper, two different parallel algorithms were examined: a transpose Fourier transform/transpose Legendre transform algorithm and a transpose Fourier transform/distributed Legendre transform algorithm. Previous studies have shown these algorithms to be among the best performers across a range of platforms and problem sizes.
References-found: 22

