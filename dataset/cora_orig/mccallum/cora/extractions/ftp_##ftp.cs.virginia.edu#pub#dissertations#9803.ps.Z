URL: ftp://ftp.cs.virginia.edu/pub/dissertations/9803.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/dissertations/README.html
Root-URL: http://www.cs.virginia.edu
Title: Practical Computer Security Analysis  
Author: Darrell M. Kienzle 
Degree: A Dissertation Presented to the Faculty of the School of Engineering and Applied Science at the University of Virginia In Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy (Computer Science) by  
Date: January 1998  
Abstract-found: 0
Intro-found: 1
Reference: [ABLP93] <author> Abadi, M., M. Burrows, B. Lampson, and G. Plotkin, </author> <title> A Calculus for Access Control in Distributed Systems, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 15, No. 3, </volume> <month> September </month> <year> 1993. </year>
Reference: [AF91] <author> Alves-Foss, J., and K. Levitt, </author> <title> Verification of Secure Distributed Systems in Higher-Order Logic: A Modular Approach Using Generic Components, </title> <booktitle> Proceedings of the 1991 IEEE Computer Society Symposium on Research in Security and Privacy, Oakland, Cal., </booktitle> <pages> pp. 122-135. </pages>
Reference-contexts: A great deal of effort ahs been expended in the area of composition theory . There are many such models proposed in the security literature (e.g. <ref> [AF91, DBY94, LSW91, LR92, PWK96] </ref>). These models provide precise understanding of the results that can arise when different components are composed. This existing work is not explicitly leveraged by MOAT because it all requires that the composed parts be specified in specialized formal notations.
Reference: [AH97] <author> Archer, M.M. and Heitmeyer, C.L. </author> <title> HumanStyle Theorem Proving Using PVS, </title> <note> To be presented at TPHOLs '97, </note> <institution> Murray Hill, NJ, </institution> <month> August, </month> <year> 1997. </year>
Reference: [AL93] <author> Abadi, M. and L. Lamport, </author> <title> Composing Specifications, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 15, No. 1, </volume> <month> January </month> <year> 1993, </year> <pages> pp. 73-132. </pages>
Reference-contexts: When the use of a formal composition theory cannot be justified, it may still be possible to derive useful heuristics from the existing formal work. For example, Abadi and Lamport outlines a basic composition principle that, although stated formally, can be paraphrased informally as well <ref> [AL93] </ref>: An object built of several component parts, guarantees M under its assumed environment if: 1. The object guarantees M if every component guarantees its part of M 2. No component violates an environmental assumption of another component or of the object. 3.
Reference: [AWNL91] <author> Amoroso, E., J. Watson, T. Nguyen, P. Lapiska, J. Weiss, and T. Starr, </author> <title> Towards an Approach to Measuring Software Trust, </title> <booktitle> Proceedings of the 1991 IEEE Computer Society Symposium on Research in Security and Privacy, Oakland, Cal., </booktitle> <pages> pp. 198-218. </pages>
Reference-contexts: Depending on the nature of the mandatory policy, this might be performed through runtime enforcement, or through other techniques aimed at gauging the level of trust that can be placed in an object <ref> [AWNL91] </ref>. In addition, the non-circumventability of the protocol stack as a whole must still be demonstrated through some combination of software wrapper and hardware support. <p> For objects operating on an insecure Legion platform, mandatory security cannot be enforced at runtime. Instead, the objects must be subjected to inspection (and other techniques for assessing trust <ref> [AWNL91] </ref>) in order to make sure that they will not communicate via other means. But if an object uses non-Legion files, it may prove difficult to ensure that no other Legion object will access those files, and impossible to ensure that no other non-Legion object will.
Reference: [BB94] <author> Boehm, B. and P. Bose, </author> <title> A Collaborative Spiral Software Process Model Based on Theory W, </title> <institution> University of Southern California Technical Report USC-CSE-94-501. </institution>
Reference: [BH94] <author> Bowen, J., M. </author> <title> Hinchey, Formal Methods and Safety-Critical Standards, </title> <journal> IEEE Computer, </journal> <volume> Vol. 27, No. 8, </volume> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: As Young [You91] points out, while formal methods cannot guarantee perfection, they can increase assurance in the quality of software. Bowen and Hinchley summarize this as despite the mathematical basis of these methods, errors are still possible. However the methods have been demonstrated to reduce errors if used appropriately. <ref> [BH94] </ref>. And Wing points out that The greatest benefit in applying a formal method often comes from the process of formalizing rather than the end result [Win90]. The notion that formal methods can guarantee correctness is a dangerous one, and yet it has been hard to banish. <p> of the problems associated with those methods, such as the risk of premature formalization. 10.2 MOATs and General Problem Understanding One of the most common arguments advanced in favor of formal methods approaches is that their use results in a greater understanding of the nature of the problem under consideration <ref> [Win90, BH94] </ref>. It is impossible to quantify or rigorously explain this phenomena, but it is nonetheless observable. Similarly, the experiments demonstrated that the use of MOAT resulted in considerably increased understanding of the problem areas under consideration.
Reference: [BH95a] <author> Bowen, J., M. </author> <title> Hinchey, Seven More Myths of Formal Methods, </title> <journal> IEEE Software, </journal> <volume> Vol. 12, No. 4, </volume> <month> July </month> <year> 1995, </year> <pages> pp. 34-41. </pages>
Reference: [BH95b] <author> Bowen, J., M. </author> <title> Hinchey, Ten Commandments of Formal Methods, </title> <journal> IEEE Computer, </journal> <volume> Vol. 28, No. 4, </volume> <month> April </month> <year> 1995, </year> <pages> pp. 56-63. </pages>
Reference-contexts: It is questionable whether formal methods can be of practical utility for such systems. 2.3.2 Formal Methods Require Experts Experience with formal methods has demonstrated that having a formal methods guru on staff is a significant factor affecting the success of formal methods projects <ref> [BH95b] </ref>. There simply arent enough formal methods experts to go around. Large numbers of applications are being built with security ramifications. There are too many such systems being built to staff them all with formal methods experts.
Reference: [BK97] <author> Blakley, B., and D. Kienzle, </author> <title> Some Weaknesses of the TCB Model, </title> <booktitle> Proceedings of the 1997 IEEE Symposium on Security and Privacy, </booktitle> <address> Oakland, California, </address> <month> October </month> <year> 1997, </year> <month> pp.3-5. </month>
Reference-contexts: But there are indications that the TCB model is losing its appeal. At a recent debate at the Security and Privacy Forum, almost half of the audience agreed with Wulfs assertion that the TCB is fundamentally flawed and should no longer be used to justify security architectures <ref> [Wul95, BK97] </ref>. Even the sponsors of the rainbow books have moved away from the TCB in their endorsement of the Common Criteria [CC96]. The latter are not architecturally specific, but rather provide guidelines for the construction of architecturally specific evaluation criteria.
Reference: [Bla96] <editor> Blakley, B., </editor> <booktitle> The Emperors Old Armor, Proceedings of the New Security Paradigms Workshop, </booktitle> <address> Lake Arrowhead, California, </address> <year> 1996, </year> <pages> pp. 2-16. </pages>
Reference: [Boe88] <author> Boehm, B., </author> <title> A Spiral Model of Software Development, </title> <booktitle> IEEE Computer, </booktitle> <month> May </month> <year> 1988, </year> <pages> pp. 61-72. </pages>
Reference-contexts: As Boehm points out, such a process model is appropriate when a system is fairly well understood and the risks of changing requirements are low <ref> [Boe88] </ref>. Historically, security-critical systems may have fit that profile. But for increasingly many security-sensitive systems, rapid development and evolution are the norms. For these, the waterfall is not appropriate, since the risk of changing requirements can invalidate elaborate specifications and designs. <p> An iterative approach to development has many practical benefits. It allows user validation of key functionality early in the process, ensures that some form of working product will be available when a deadline is reached, and allows testing to be performed early in the life-cycle <ref> [Boe88, BT75, Mye96] </ref>. The waterfall is not an iterative process model. In such an environment, the waterfall may be faked [PC86], but it cannot be followed. There are many novel architectures and commercial systems for which the waterfall is not a good choice. <p> As Section 5.1 explains, MOAT can be integrated into a conventional waterfall process model. 3.1.2 The Spiral Model In 1988 Boehm, introduced the notion of a risk-driven software process model as a replacement for the waterfall <ref> [Boe88] </ref>. The Spiral Model is a more flexible approach because it permits the order of development activities to vary according to the risks 1 specific to the project. The Spiral Model is a risk 1 Note that the term risk has several different meanings. <p> As Boehm pointed out , when a systems requirements are well-understood at the outset of a project, a conventional waterfall model may represent the best possible approach <ref> [Boe88] </ref>. A complete specification can be developed and then refined through design and ultimately implementation, with little risk that changing requirements or other unanticipated events will necessitate significant backtracking. 28 There are many examples of such systems in the literature (e.g. [Cor89, Rus81, PVK90]). <p> For example, the risk of faulty logic undermining a cryptographic protocol is one that is best addressed using formal reasoning. Similarly, when it can be cost-justified, formal verification is the most thorough means of uncovering coding errors that could be exploited by an attacker. But as Boehm <ref> [Boe88] </ref> notes, there are system risks that undermine the waterfall model to which formal methods have been tied. If a system being developed is not well understood at the outset, the possibility of changing requirements can undermine the effectiveness of formal specifications. <p> But only because the user of the waterfall model implicitly relies on both foresight and experience. As Boehm <ref> [Boe88] </ref> points out, the waterfall model can either be very efficient or very inefficient depending on the risks present in the system and project. The use of a risk-driven approach does not introduce the possibility of misapplication of resources , it merely makes the consideration of this possibility explicit.
Reference: [Boe89] <editor> Boehm, B., </editor> <publisher> Software Risk Management , IEEE Computer Society Press, </publisher> <year> 1989 </year>
Reference: [Bos95] <author> Boswell, A., </author> <title> Specification and Validation of a Security Policy Model, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 21, No. 2, </volume> <month> Feb. </month> <year> 1995, </year> <pages> pp. 63-68. </pages>
Reference-contexts: In such circumstances, the waterfall represents a mature process model. The waterfall model is often paired with formal methods techniques. In many formal methods documents, the waterfall model is presented as the software process model <ref> [PST91, Inc88, Bos95] </ref>. In fact, many of the beneficial effects of using formal specification notations can be seen as addressing shortcomings of the waterfall model. The sequential nature of the waterfall tends to compound the cost of errors that are made early in the process but not discovered until late.
Reference: [Bro75] <author> Brooks, F. P., </author> <title> The Mythical Man-Month: </title> <booktitle> Essays on Software Engineering , Addison-Wesley, </booktitle> <address> Reading Massachusetts, </address> <year> 1975. </year>
Reference: [Bro87] <author> Brooks, F. P., </author> <title> No Silver Bullet: Essence and Accidents of Software Engineeri ng, </title> <journal> IEEE Computer, </journal> <volume> Vol. 20, No. 4, </volume> <month> April </month> <year> 1987, </year> <pages> pp. 10-19. </pages>
Reference: [BT75] <author> Basili, V. R., and A. J. Turner, </author> <title> Iterative Enhancement: A Practical Technique for Software 142 Development, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-1, No. 4, </volume> <month> December </month> <year> 1975, </year> <pages> pp. 390-396. </pages>
Reference-contexts: An iterative approach to development has many practical benefits. It allows user validation of key functionality early in the process, ensures that some form of working product will be available when a deadline is reached, and allows testing to be performed early in the life-cycle <ref> [Boe88, BT75, Mye96] </ref>. The waterfall is not an iterative process model. In such an environment, the waterfall may be faked [PC86], but it cannot be followed. There are many novel architectures and commercial systems for which the waterfall is not a good choice.
Reference: [CGHM81] <author> Cheheyl, M. H., M. Gasser, G. A. Huff, and J. K. Millen, </author> <title> Verifying Security, </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 13, No. 3, </volume> <month> Sept. </month> <year> 1981, </year> <pages> 279-340. </pages>
Reference: [CGR95] <author> Craigen, D., S. Gerhart, and T. Ralston, </author> <title> Formal Methods Reality Check: Industrial Usage, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 21, No. 2, </volume> <month> Feb. </month> <year> 1995, </year> <pages> pp. 90-98. </pages>
Reference-contexts: Documents such as the Rainbow Books specify formal methods as an important criterion in getting systems validated as secure. Formal methods have proven themselves to being particularly useful as isolating certain classes of errors and in gaining understanding of the problem. 3.2.1 Industrial Usage Craigen, et al <ref> [CGR95] </ref> present a survey of usage of formal methods in industry. They report on discussions with practitioners (not researchers) from twelve different projects where formal methods were employed. Of these twelve, two were security-critical systems.
Reference: [CLR90] <author> Cormen, T. H., C. E. Leiserson, and R. L. Rivest, </author> <title> Introduction to Algorithms , MIT Press, </title> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: The process views development as an ordered application of develo pment activities, each of which can be ranked in terms of costs (resources used) and effects (risks reduced). This makes it an instance of the well-understood knapsack problem <ref> [CLR90] </ref>. In that problem, the goal is to fill a knapsack with the items that have the greatest value. The basic heuristic is a greedy algorithm approach: always choose the item with the greatest value/size ratio.
Reference: [CNN96] <institution> CNN Financial News, Sun working to fix J ava bug: Flaw discovered by Princeton professor, graduate students, </institution> <month> March 26, </month> <year> 1996, </year> <note> available at http://cnnfn.com/news /9603/26/sun/index.htm. </note>
Reference-contexts: When exploitable security flaws are discovered in popular commercial software packages, the result is often significant negative coverage in the mainstream press <ref> [CNN97a, CNN97b, CNN96] </ref>. Commercial software vendors have been forced to consider security a priority but only one of many. Users have repeatedly demonstrated that they are unwilling to sacrifice functional goals in the interest of security.
Reference: [CNN97a] <editor> CNN Financial News, </editor> <title> Explorer bug discovered : Flaw is serious and could cause damage to home and office systems, </title> <address> March 4, </address> <year> 1997, </year> <note> available at http://cnnfn.com/digitaljam /9703/04/microsoft_pkg/. </note>
Reference-contexts: When exploitable security flaws are discovered in popular commercial software packages, the result is often significant negative coverage in the mainstream press <ref> [CNN97a, CNN97b, CNN96] </ref>. Commercial software vendors have been forced to consider security a priority but only one of many. Users have repeatedly demonstrated that they are unwilling to sacrifice functional goals in the interest of security.
Reference: [CNN97b] <editor> CNN Financial News, </editor> <title> Netscape bug uncovered: Danish s oftware firm finds flaw that could let sites see data stored on PCs, </title> <address> June 12, </address> <year> 1997, </year> <note> available at http://cnnfn.com/digitaljam /9706/12/netscape_pkg/. </note>
Reference-contexts: When exploitable security flaws are discovered in popular commercial software packages, the result is often significant negative coverage in the mainstream press <ref> [CNN97a, CNN97b, CNN96] </ref>. Commercial software vendors have been forced to consider security a priority but only one of many. Users have repeatedly demonstrated that they are unwilling to sacrifice functional goals in the interest of security.
Reference: [Cor89] <author> Cornwell, M., </author> <title> A Software Engineering Approach to Designing Trustworthy Software, </title> <booktitle> Proceedings of the IEEE Symposium on Security and Privacy, Oakland 1989, </booktitle> <pages> pp. 148-156. </pages>
Reference-contexts: A complete specification can be developed and then refined through design and ultimately implementation, with little risk that changing requirements or other unanticipated events will necessitate significant backtracking. 28 There are many examples of such systems in the literature (e.g. <ref> [Cor89, Rus81, PVK90] </ref>). These systems demonstrated that a waterfall process could be used to successfully build secure system software. The many documented successes might even suggest that a waterfall model is generally applicable to security-critical systems.
Reference: [CV92] <author> Calvelli, C., and V. Varadharajan, </author> <title> An Analysis of Some Delegation Protocols for Distributed Systems, </title> <booktitle> Proceedings of Computer Security Foundations Workshop V, </booktitle> <address> Franconia, NH, </address> <month> June </month> <year> 1992, </year> <pages> pp. 92-110. </pages>
Reference-contexts: for any method target executes on its behalf Method execution by the target on behalf of the RA requires an external leverage relationship Method execution by the target on behalf of the RA requires an authorizing certificate (8.5) 84 well-reasoned certificate schemes for which interesting properties have been proven (e.g. <ref> [CV92, VAB91] </ref>).
Reference: [CW87] <author> Clark, D. and D. Wilson, </author> <title> A Comparison of Commercial and Military Security Policies, </title> <booktitle> Proceedings of the 1987 IEEE Symposium on Security and Privacy, </booktitle> <pages> pp. 184-194. </pages>
Reference: [DAR97] <author> DARPA initiativ e, </author> <title> Evolutionary Design of Complex Software, </title> <note> available at http://www.sei.cmu.edu/technology/edcs/ </note>
Reference-contexts: Modern commercial systems are not built so much as grown, with multiple iterations of the product being produced as features are added [McC95, McC96]. The software engineering community is just beginning to recognize this with new paradigms such as evolutionary and rapid development approaches <ref> [DAR97, SPC97, TS95] </ref>. And the Department of Defense has instructed that large, software-dominated weapons and command and control systems should be acquired using an Evolutionary Acquisition model: Considered most broadly, EA consists of several steps. The first step defines the requirement and the general outline of the system.
Reference: [DBY94] <author> Dinolt, G. W., L. A. Benzinger, and M. G. Yatabe, </author> <title> Combining Components and Policies, </title> <booktitle> Proceedings of the IEEE Computer Security Foundations Workshop, </booktitle> <address> Franconia, N.H., </address> <year> 1994, </year> <pages> pp. 22-33. </pages>
Reference-contexts: A great deal of effort ahs been expended in the area of composition theory . There are many such models proposed in the security literature (e.g. <ref> [AF91, DBY94, LSW91, LR92, PWK96] </ref>). These models provide precise understanding of the results that can arise when different components are composed. This existing work is not explicitly leveraged by MOAT because it all requires that the composed parts be specified in specialized formal notations.
Reference: [Dea97] <author> Dean, D., </author> <title> panel discussion Ensuring Assurance in Mobile Computing, </title> <booktitle> 1997 IEEE Symposium on Security and Privacy, </booktitle> <address> Oakland, California, </address> <month> October </month> <year> 1997` </year>
Reference-contexts: The use of a pointer-free language such as Java also makes other techniques such as code inspection more effective <ref> [Dea97] </ref>. 9.13.4 Inspection Inspection involves scrutinizing existing source code to find problems that might undermine system security. Inspection provides a means for gaining trust in untrusted code.
Reference: [Den76] <author> Denning, D., </author> <title> A Lattice Model of Secure Information Flow, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 19, No. 5, </volume> <month> May </month> <year> 1976, </year> <pages> pp. 236-242. </pages>
Reference: [DFW] <author> Dean, D., E. Felton, and D. Wallach, </author> <title> Java Security: From Hotjava to Netscape and Beyond, </title> <booktitle> Proceedings of the 1996 IEEE Symposium on Security and Privacy, </booktitle> <address> Oakland, CA, </address> <month> May </month> <year> 1996, </year> <pages> pp. 190-200. </pages>
Reference: [Dij76] <author> Dijkstra, E., </author> <title> A Discipline of Programming , Prentice-Hall, </title> <year> 1976. </year>
Reference-contexts: Formal methods, when applied to security-critical systems, can make them more secure . But they cannot ensure that a system is secure in any absolute sense. Perhaps the best summary of the utility of formal methods comes from Dijkstras A Discipline of Programming <ref> [Dij76] </ref>: I have dealt with the examples in different degrees of formality. This variation is intended, as I would not like to give my readers the impressions that a certain, fixed degree of formality is the right one. <p> Using this technique, they were able to find certain circumstances in which unsafe outputs might be generated. They also found many places where additional assertions could be added to make already safe code more robust. Semantically, this approach is equivalent to Dijkstras weakest preconditions <ref> [Dij76] </ref>. It differed in that it used a graphical notation, and was used on real languages that did not exhibit the nondeterminism that Dijkstras programming language featured. The also suffered from a key problem of weakest preconditions: they are computed working backwards from the lowest level modules to the highest.
Reference: [Dil90] <author> Diller, A., </author> <title> Z: An Introduction to Formal Methods, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1990. </year>
Reference: [DLP79] <author> DeMillo, R., R. Lipton, and A. Perlis, </author> <title> Social Processes and Proofs of Theorems and 143 Programs, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 22, No. 5, </volume> <month> May </month> <year> 1979, </year> <pages> pp. 271-280. </pages>
Reference-contexts: Assertions of this sort were bound to draw criticism. The most widely-read critiques of this position are those of DeMillo, Lipton, and Perlis, and Fetzer. 3.3.1 DeMillo, Lipton, and Perlis The crux of DeMillo, Lipton, and Perliss <ref> [DLP79] </ref> argument is that the analogies between formal verification and mathematical proofs are flawed.
Reference: [DoD83] <institution> National Computer Security Center, Ft. Meade, MD, DoD 5200.28-STD, </institution> <note> Trusted Computer System Evaluation Criteria , December 1985. </note>
Reference-contexts: We divided these into two broad categories: collected experience with standard architectures and formal methods. We found both of these approaches to be unsatisfactory solutions to our problem. The collected experience approach is best exemplified by the Department of Defenses Trusted Computing System Evaluation Criteria (the rainbow books) <ref> [DoD83] </ref>. These documents represent years of experience with certain standard security architectures, all variations on the Trusted Computing Base model. But the Legion Security Model discards the notion that the operating system can be trusted, and therefore undermines the most basic assumptions underlying the TCB approach. <p> This decomposition would permit security verification to focus on only the TCB itself, and would allow users to develop application 8 software without concern that they (or other applications) might impact system security. The Trusted Computing System Evaluation Criteria <ref> [DoD83] </ref> (dubbed the rainbow books because of their many-colored covers) represent years of collected experience and expertise with various instantiations of this model. This information ranged from practical, implementation-level issues to formal models and their realization. The major risk areas were understood and well documented. <p> Similarly, a formal analysis might consider the pseudocode for an algorithm and ignore the specific program-language representation 24 The third axis, that of limiting formality to only those components that are deemed to be critical is a common technique that is documented in many of the critical software standards documents <ref> [DoD83, CC96] </ref>. The fourth involves specifying or analyzing only those properties that are deemed critical in security applications this would involve limiting formality, where possible, to security properties. The final axis involves limiting formality to certain lifecycle stages.
Reference: [DoD96] <institution> U.S. Department of Defense, Office of the Under Secretary of Defense for Acquistion and Technology, Buying Commercial and Nondevelopment Items: </institution> <note> A Handbook, Document SD-2, April 1996, available at http://www.acq.osd.mil/es/std/ndi/ndihome.html. </note>
Reference-contexts: Our ability to field affordable, state-of-the-art systems when they are needed, and to buy the millions of items needed to support our troops and fielded systems, depends on efficient use of available resources. The commercial industrial base is a vast resource capable of providing many of these items. <ref> [DoD96] </ref> It is not at all clear whether formal methods can be made to work cost-effectively for systems that are composed of COTS products. Historically, formal methods have been applied to projects built from the ground up.
Reference: [DSMC96] <institution> Defense Systems Management College, Research, Consulting & Information Division (RCID) Evolutionary Acquisition, Program Managers Notebook PM Fact Sheet 1.15, </institution> <month> May </month> <year> 1996, </year> <note> available at http://www.dsmc.dsm.mil/pubs/ </note>
Reference-contexts: The first step defines the requirement and the general outline of the system. Then the succeeding steps in the process sequentially define, fund, develop, test, field, support, and evaluate increments of the system. This process begins with a core or baseline system, which is then enhanced through incremental upgrades <ref> [DSMC96] </ref> Evolutionary development occurs both before a product is released, and continues through the release of new versions. An iterative approach to development has many practical benefits.
Reference: [ECC90] <editor> European Communities Commission, </editor> <title> Information Technology Security Evaluation Criteria (ITSEC) , Draft, </title> <type> Version 1, </type> <month> May </month> <year> 1990. </year>
Reference: [EO94] <institution> Executive Order 12931 of October 13, </institution> <year> 1994, </year> <journal> Federal Procurement Reform, Federal Register Vol. </journal> <volume> 59, No. 199, </volume> <month> October </month> <year> 1994. </year>
Reference-contexts: It is simply no longer cost-effective to build custom systems in-house. Rather, customers seek solutions that are composed of fully-functional commercial off the shelf (COTS) parts. Under President Clintons Federal Procurement Reform directive, all federal agencies are required to use COTS products wherever practicable. <ref> [EO94, GSA97] </ref>. The Department of Defense has also established its own acquisition reform initiative, the Commercial and Nondevelopment Items Program (CaNDI): The Department of Defense must learn to use commercial and nondevelopmental items (NDI) effectively.
Reference: [Fag86] <author> Fagan, M. E., </author> <title> Advances in Software Inspection, </title> <journal> IEEE Transaction on Software Engineering, </journal> <volume> Vol. SE-12, No. 7, </volume> <month> July </month> <year> 1986, </year> <pages> pp. 744-751. </pages>
Reference-contexts: Using an informal notation, the developer could conceivably fail to uncover all of the important problems. But MOAT requires the user to present the arguments for review by the other stakeholders. Experience with reviews and inspections have demonstrated that can be extremely effective <ref> [Fag86] </ref>. Even simply preparing for an inspection can result in much improved work products [Wei71]. In addition, the alternative perspectives offered as part of the review may result in additional problems being found.
Reference: [Fet88] <author> Fetzer, J., </author> <title> Program Verification: The Very Idea, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 31, No. 9, </volume> <month> Sept. </month> <year> 1988. </year>
Reference-contexts: Rather than provide a complete formal verification (down to first principles) it is meant to demonstrate that all sources of considerable risk have been identified and ameliorated. 3.3.2 Fetzer While DeMillo, et al, argue the practical limits of formal verification, Fetzer takes aim on theoretical limitations <ref> [Fet88] </ref>. He argues that the notion of absolute formal verification is fundamentally flawed. Even a complete reduction to first principles depends on the assumption that those first principles are correct.
Reference: [FKV94] <author> Fraser, M., K. Kumar, and V. Vaishnavi, </author> <title> Strategies for Incorporating Formal Specifications in Software Development, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 37, No. 10, </volume> <month> Oct. </month> <year> 1994, </year> <month> pp.74-86. </month>
Reference: [FL96] <author> Filman, R., and T. Linden, SafeBots: </author> <title> A Paradigm for Software Security Controls, </title> <booktitle> Proceedings of the New Security Paradigms Workshop, </booktitle> <address> Lake Arrowhead, California, </address> <year> 1996, </year> <pages> pp. 45-51. </pages>
Reference-contexts: Some other examples include Secure Network Objects [VABW96], the Distributed Compartment Model [Gre96], and Metaobjects [RH97]. But it is not only the research community that is moving towards distributed models of security. Industrial endeavors include Safebots <ref> [FL96] </ref>, CORBA security [OMG97], DCE security [OSF92], and the policy-neutral model used in DTOS [OFSS96], several of which are already in common use. But perhaps most significantly, the Department of Defense is also moving towards new distributed security architectures. At present, there are several DARPA initiatives in this direction.
Reference: [FM93] <author> Fenelon, P., and J. McDermid, </author> <title> An Integrated Toolset For Software Safety Analysis, </title> <journal> Journal of Systems and Software, </journal> <month> July </month> <year> 1993. </year>
Reference-contexts: Other than this, the two approaches are quite dissimilar, in spite of sharing a common graphical basis. 3.6.4 Hierarchical Fault Tree Analysis Hierarchical Fault Tree Analysis is a technique developed by Fenelon and McDermid as part of their comprehensive approach to building and assessing safety-critical software <ref> [FM93] </ref>. They use conventional AND/OR fault trees to structure a safety case (the case made that a given system is safe). The use of AND/OR trees permits large argument and their supporting evidence to be collected and presented in an organized manner. <p> And in order to be compatible with FTA, they limit themselves to negative logic approaches that analyze faults rather than desirable properties. There are substantial differences between MOAT and HFTA. Of particular interest is the use of the term life cycle as synonymous with the waterfall process model <ref> [FM93] </ref>. They recognize the need to deviate from the waterfall in order to explore alternative designs, but rather than provide guidance they encourage faking a rational process [FMNP94]. HFTA is billed as breadth-first, limiting itself to a 36 conventional formal methods approach almost identical to that described in Section 5.1.
Reference: [FMNP94] <author> Fenelon, P., J. McDermid, M. Nicholson, and D. Pumfrey, </author> <title> Towards Integrated Safety Analysis And Design, </title> <journal> ACM Applied Computing Review Vol. </journal> <volume> 2, No. 1, </volume> <month> August </month> <year> 1994, </year> <pages> pp. 21-32. </pages>
Reference-contexts: Of particular interest is the use of the term life cycle as synonymous with the waterfall process model [FM93]. They recognize the need to deviate from the waterfall in order to explore alternative designs, but rather than provide guidance they encourage faking a rational process <ref> [FMNP94] </ref>. HFTA is billed as breadth-first, limiting itself to a 36 conventional formal methods approach almost identical to that described in Section 5.1. By contrast, MOAT encourages the developer to recognize the importance of applying limited resources in the most cost-effective manner possible.
Reference: [Fri96] <author> Frincke, D., </author> <title> Developing Secure Objects, </title> <booktitle> Proceedings of the 19 th National Information Systems Security Conference, </booktitle> <address> Baltimore Maryland, </address> <month> October </month> <year> 1996, </year> <pages> pp. 410-419. </pages>
Reference-contexts: Ideally, such arguments should be written with an eye towards reusability, in order to collect the experience necessary for the next generation of standard certification criteria. The MOAT approach was designed with these goals in mind. 3.7.2 Design Patterns Frincke <ref> [Fri96] </ref> presents work that begins to explore the possibility of reusing architectural templates in tandem with proofs associated with those templates. The design patterns of Gamma et al [GHJV95] are templates that represent archetypal objectoriented design constructs.
Reference: [GG93] <author> Gilb, T., and D. Graham, </author> <title> Software Inspection , Addison-Wesley, </title> <address> Reading, Massachusetts, </address> <year> 1993, </year> <pages> pp. 14-39. </pages>
Reference: [GH86] <author> Guttag, J., J. Hornung, </author> <title> Formal Specification as a Design Tool, in Software Specification Techniques (Gehani and McGetrick, </title> <editor> eds.), </editor> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference: [GHJV95] <author> Gamma, E., R. Helm, R. Johnson, and J. Vlissides, </author> <title> Design Patterns , Addison Wesley, </title> <address> Reading Massachusetts, </address> <year> 1995. </year>
Reference-contexts: The MOAT approach was designed with these goals in mind. 3.7.2 Design Patterns Frincke [Fri96] presents work that begins to explore the possibility of reusing architectural templates in tandem with proofs associated with those templates. The design patterns of Gamma et al <ref> [GHJV95] </ref> are templates that represent archetypal objectoriented design constructs. Frincke attempts to establish general security properties for software using some of these patterns. Since the patterns represent high-level 37 relationships between user-defined components, a high-level security property will necessarily be decomposed into requirements on the individual components.
Reference: [GHW85] <author> Guttag, J., J. Hornung, J. Wing, </author> <title> The Larch Family of Specification Lan guages, </title> <journal> IEEE Software, </journal> <volume> Vol. 2, No. 5, </volume> <month> Sept. </month> <year> 1985. </year>
Reference: [Gre83] <author> Green, A., </author> <title> Safety Systems Reliability, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1983. </year> <month> 144 </month>
Reference: [Gre96] <author> Greenwald, S. J., </author> <title> A New Security Policy for Distributed Resource Management and Access Control, </title> <booktitle> Proceedings of the New Security Paradigms Workshop, </booktitle> <address> Lake Arrowhead, California, </address> <year> 1996, </year> <pages> pp. 74-86. </pages>
Reference-contexts: This environment invalidates several assumptions needed to support the TCB, The importance of distributed objectoriented systems has led to a number of different object-oriented security models, of which Legion is but one example. Some other examples include Secure Network Objects [VABW96], the Distributed Compartment Model <ref> [Gre96] </ref>, and Metaobjects [RH97]. But it is not only the research community that is moving towards distributed models of security. Industrial endeavors include Safebots [FL96], CORBA security [OMG97], DCE security [OSF92], and the policy-neutral model used in DTOS [OFSS96], several of which are already in common use.
Reference: [GSA97] <institution> General Services Administration, Federal Acquistion Regulation, </institution> <note> version FAC 97-02. Section 12: Acquisition of Commercial Items available at http://www.arnet.gov/far/, 1997. </note>
Reference-contexts: It is simply no longer cost-effective to build custom systems in-house. Rather, customers seek solutions that are composed of fully-functional commercial off the shelf (COTS) parts. Under President Clintons Federal Procurement Reform directive, all federal agencies are required to use COTS products wherever practicable. <ref> [EO94, GSA97] </ref>. The Department of Defense has also established its own acquisition reform initiative, the Commercial and Nondevelopment Items Program (CaNDI): The Department of Defense must learn to use commercial and nondevelopmental items (NDI) effectively.
Reference: [GW97] <author> Grimshaw, A., W. Wulf, </author> <title> and the Legion team, The Legion Vision of a Worldwide Virtual Computer, </title> <journal> Communications of the ACM, </journal> <month> January </month> <year> 1997. </year>
Reference-contexts: Introduction This dissertation presents Methodically Organized Argument Trees, a new approach towards achieving and providing assurance of software security goals. The MOAT approach arose as part of the development of the security model for the Legion distributed high-performance computing system <ref> [GW97] </ref>. The Legion Security Model takes a decentralized approach towards security [WWK96]. Rather than making the system responsible for enforcing some global definition of security, Legion allows users application objects to define and enforce individualized security policies.
Reference: [Hal90] <author> Hall, A., </author> <title> Seven Myths of Formal Methods, </title> <journal> IEEE Software, </journal> <volume> Vol. 7, No. 5, </volume> <month> Sept. </month> <year> 1990, </year> <pages> pp. 11-19. </pages>
Reference: [Hay85] <author> Hayes, I., </author> <title> Applying Formal Specification to Software D evelopment in Industry, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-11, No. 2, </volume> <month> Feb. </month> <year> 1985, </year> <pages> pp. 169-178. </pages>
Reference: [Hen80] <author> Heninger, K., </author> <title> Specifying Software Requirements for Complex Systems: New Techniques and their Application, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-6, No. 1, </volume> <month> Jan. </month> <year> 1980. </year>
Reference-contexts: It focuses on communication of arguments. And it permits formal technologies to be added to a development effort in a gradual manner. 3.2.2 The SCR Notation One of the most influential contributions in the area of specification capture is Parnass Software Cost Reduction notation, initially documented in <ref> [Hen80] </ref>. The specification notation, often referred to as the A-7 notation, was developed in order to specify the flight control software for the Navys A -7 aircraft. The specification of the A-7 software was a masterfully executed risk reduction exercise. Everything about the notation was aimed at reducing risks.
Reference: [HK85] <author> Henley, E. J. and H. Kumamoto, </author> <title> Designing for Reliability and Safety Control , Prentice-Hall, </title> <publisher> Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1985, </year> <pages> pp. 407 458. </pages>
Reference: [HKL97] <author> Heitmeyer, C., J. Kirby, and B. Labaw, </author> <title> Tools for Formal Specification, Verification, and Validation of Requirements, </title> <booktitle> Proceedings of the 12 th Annual Conference on Computer Assurance, </booktitle> <month> June </month> <year> 1997. </year>
Reference: [Hoa85] <author> Hoare, C. A. R., </author> <title> Programs are Predicates, In Hoare, </title> <editor> C. A. R., and C. B. Jones (ed.) </editor> <booktitle> Essays in Computing Science , Prentice-Hall, </booktitle> <address> New York, </address> <year> 1989, </year> <pages> pp. 333-350. </pages>
Reference-contexts: The formal methods literature has long been spotted with assertions that software engineering is a purely mathematical endeavor, and that we should strive for a future where all significant programs are completely formally specified, developed, and verified (e.g. <ref> [Hoa85] </ref>). Assertions of this sort were bound to draw criticism.
Reference: [ICFEM97] <editor> Call for Papers, </editor> <booktitle> First IEEE International Conference on Formal Engineering Methods, </booktitle> <month> November </month> <year> 1997, </year> <institution> Hiroshima, </institution> <address> Japan. </address>
Reference-contexts: A critical barrier is the poor understanding of how to merge academic advances in formal methods into how industry actually builds software. Practitioners also feel that existing formal methods are difficult to use and their application consumes prohibitive amounts of resources, particularly at startup. <ref> [ICFEM97] </ref> Given this admission that the software-engineering community has found formal methods to be impractical, it is not difficult to believe that our firsthand difficulties with formal methods might be representative of problems facing many others. <p> existing formal methods to overcome the critical barrier, how to apply formal methods in an engineering manner, and how to support formal methods with intelligent CASE so that they can be easily and effectively used in industry not only for safety critical systems, but also for other complex computer systems. <ref> [ICFEM97] </ref> The MOAT approach provides a possible solution to these problems. It provides a framework in which formal methods can be applied in a systematic manner based on cost-effectiveness in addressing the risks of a particular systems.
Reference: [Inc88] <author> Ince, D. C., </author> <title> An Introductions to Discrete Mathematics and Formal System Specification, </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1988. </year>
Reference-contexts: In such circumstances, the waterfall represents a mature process model. The waterfall model is often paired with formal methods techniques. In many formal methods documents, the waterfall model is presented as the software process model <ref> [PST91, Inc88, Bos95] </ref>. In fact, many of the beneficial effects of using formal specification notations can be seen as addressing shortcomings of the waterfall model. The sequential nature of the waterfall tends to compound the cost of errors that are made early in the process but not discovered until late.
Reference: [Jon94] <author> Jones, C., </author> <title> Assessment and Control of Software Risks , Yourdon Press, </title> <booktitle> Prentice-Hall International, </booktitle> <address> Englewood Cliffs, New Jersey, </address> <year> 1994, </year> <pages> 617 pp. </pages>
Reference-contexts: This definition includes both security risks and other development risks such as the risk of not completing the project within time or cost constraints. For a thorough explanation of software development risks, see <ref> [Jon94] </ref>. 20 design as well: In areas involving a high risk if the design turned out to be wrong, the design was carried down to the detailed design level In areas involving a low risk if the design was wrong, very little design elaboration was done.
Reference: [JSC94] <author> Joint Security Committee, </author> <title> Redefinin g Security: A Report to the Secretary of Defense and the Director of Central Intelligence, </title> <address> Washington D.C., </address> <month> February 28, </month> <year> 1994. </year>
Reference-contexts: Department of Defense, recognizes this as a necessity: Some inherent vulnerabilities can never be eliminated fully, nor would the cost and benefit warrant this risk avoidance approach. We can and must provide a rational, cost effective, and enduring framework using risk management as the underlying basis for security decisionmaking. <ref> [JSC94] </ref> The security community is in the midst of a paradigm shift. The old model of risk avoidance is being 9 replaced by a more realistic risk management model.
Reference: [KA94] <author> Kahn, J. J., and M. D. Abrams, </author> <title> Editorial: Why Bad Things Happen To Good Systems, and What To Do About It, </title> <booktitle> Proceedings of the 10 th Annual Computer Security Applications Conference, </booktitle> <address> Orlando, Florida, </address> <month> December, </month> <year> 1994, </year> <pages> pp. 306-307. </pages>
Reference-contexts: Software vendors are thus striving for the most security that they can be achieved at a reasonable cost. As Kahn and Abrams observe, available resources can be expected to continue to shrink. We can now only afford pragmatic risk reduction <ref> [KA94] </ref>. The commercial software community has not embraced formal methods, in part because the costs associated with them are considered unreasonable. It is not realistic to think that the addition of security goals will change the landscape overnight.
Reference: [Kem90] <author> Kemmerer, R. A., </author> <title> Integrating Formal Methods into the Development Process, </title> <journal> IEEE Software, </journal> <month> September </month> <year> 1990, </year> <pages> pp. 37-50. </pages>
Reference-contexts: There are many published examples in which systems were formally modeled and their security reasoned about (e.g. <ref> [Kem90] </ref>, [Moo90]). These published experiments with formal methods have found them to be quite effective. One might then conclude that developers who need to stray from the collected experience approach should rely on formal methods. But the bottom line is that formal methods have failed to gain widespread acceptance. <p> But because MOAT is risk-driven, it can also be applied to less conventional systems. 3.4.2 Integrated Formal Methods Kemmerer reports on an experiment in applying formal methods to the development of secure terminal software <ref> [Kem90] </ref>. He identifies three distinct manners in which formal methods can be used in such a project: After the fact . In this approach, formal methods are applied to the finished product in order to demonstrate that it meets its security requirements.
Reference: [Ker96] <author> Kerr, D., </author> <title> Barbarians at the Firewall, </title> <journal> Byte, </journal> <volume> Vol. 21, No. 9, </volume> <month> Sept. </month> <year> 1996. </year>
Reference-contexts: The TCB can define security primitives in terms of the interface it offers: such as primitive operating system calls and database functions. Modern applications have security requirements that cannot be defined in terms of TCB primitives. Examples include malicious Java applets [DFW96], and word processing macro viruses <ref> [Ker96] </ref>. Although these applications could be moved into the TCB, it would no longer be a small, verifiable subset of the system, defeating the purpose of that architectural approach.
Reference: [KK92a] <author> Knight, J., and D. Kienzle, </author> <title> Reuse of Specifications, </title> <booktitle> WISR-5, The Workshop on Software Reuse, </booktitle> <year> 1992. </year>
Reference-contexts: Historically, formal methods have been applied to projects built from the ground up. There is very little experience, practical or otherwise, with reuse of formal methods work products. That which is available generally involves very small components (e.g. <ref> [KK92a] </ref>). While there is a significant literature on the composition of formally-stated security properties, none of it has been validated through use on real systems (see section 3.5.3).
Reference: [KK92b] <author> Knight, J., and D. Kienzle, </author> <title> Preliminary Experience Using Z to Specify a Safety-C ritical System, </title> <booktitle> Proceedings of the Z User Meeting, </booktitle> <address> London England, </address> <year> 1992. </year> <month> 145 </month>
Reference-contexts: Formal methods advocates have not experimented with the use of formal methods in modern, risk-driven process models. The author has firsthand experience in attempting to apply formal methods to two experimental systems a safety-critical medical device <ref> [KK92b] </ref> and the Legion security model. In both cases, the inapplicability of the waterfall process model undermined the formal methods approach. Schaefer discusses several security-critical systems in which a formal methods approach was tried.
Reference: [KW97] <author> Kienzle, D. M., and W. A. Wulf, </author> <title> A Practical Approach to Security Assessment, </title> <booktitle> to appear in Proceedings of the 1997 New Security Paradigms Workshop, </booktitle> <address> England, </address> <month> September </month> <year> 1997. </year>
Reference: [Lan81] <author> Landwehr, C., </author> <title> Formal Models for Computer Security, </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 13, No. 3, </volume> <month> Sept. </month> <year> 1981, </year> <pages> pp. 247-278. </pages>
Reference: [Lan96] <author> Landoll, D., </author> <title> panel chair, Alternative Assurance: Theres Gotta Be a Better Way, </title> <booktitle> Proceedings of the 19 th National Information Systems Security Conference, </booktitle> <address> Baltimore Maryland, </address> <month> October </month> <year> 1996, </year> <pages> pp. 644-654. </pages>
Reference: [LBMC94] <author> Landwehr, C., A. Bull, J. McDermott, and W. Choi, </author> <title> A Taxonomy of Computer Program Security Flaws, </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 26, No. 3, </volume> <month> Sept. </month> <year> 1994, </year> <pages> pp. 211-254. </pages>
Reference: [Lev90] <author> Leveson, N. G., </author> <title> guest editorial Formal Methods in Software Engineering, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 16, No. 9, </volume> <month> Sept. </month> <year> 1990, </year> <pages> pp. 929-931. </pages>
Reference-contexts: Leveson reinforces this position, saying there is a need to determine how and where formal methods are most effective the more rigorous and costly procedures might well be reserved for those software qualities that need to be ensured with very high confidence. <ref> [Lev90] </ref> And, as noted above, Parnass work on the A-7 provides an excellent example of the utility of riskspecific application of rigor. Depending on the risks, an application of MOAT can result in varying degrees of formality along all five of these axes.
Reference: [Lev92] <author> Leveson, N. G., </author> <title> High Pressure Steam Engines and Computer Software, </title> <booktitle> Proceedings of the International Conference on Software Engineering, </booktitle> <address> Melbourne, Australia, </address> <month> May </month> <year> 1992. </year>
Reference: [LH83] <author> Leveson, N., P. Harvey, </author> <title> Analyzing Software Safety, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-9, No. 5, </volume> <month> Sept. </month> <year> 1983. </year>
Reference-contexts: These generally incorporate advances from all of the above areas. Thus, these toolsets are not directly applicable to MOAT, though they do suggest that similarly MOATspecific tools might be quite useful. 3.6.3 Levesons Software Fault Tree Analysis Leveson and Harvey <ref> [LH83] </ref> applied fault tree analysis to safety-critical software at the source code level. Their approach permitted potentially errant outputs to be traced backwards through the code to determine whether they could in fact be generated.
Reference: [LR92] <author> Landauer, J. and T. </author> <title> Redmond, A Framework for the Composition of Security Models, </title> <booktitle> Proceedings of the IEEE Computer Security Foundations Workshop, </booktitle> <address> Franconia, N.H., </address> <year> 1992, </year> <pages> pp. 157-166. </pages>
Reference-contexts: A great deal of effort ahs been expended in the area of composition theory . There are many such models proposed in the security literature (e.g. <ref> [AF91, DBY94, LSW91, LR92, PWK96] </ref>). These models provide precise understanding of the results that can arise when different components are composed. This existing work is not explicitly leveraged by MOAT because it all requires that the composed parts be specified in specialized formal notations.
Reference: [LSW91] <author> Lam, S. S., A. U. Shankar, and T. Y. C. Woo, </author> <title> Applying a Theory of Modules and Interfaces to Security Verification, </title> <booktitle> Proceedings of the 1991 IEEE Computer Society Symposium on Research in Security and Privacy, Oakland, Cal., </booktitle> <pages> pp. 136-154. </pages>
Reference-contexts: A great deal of effort ahs been expended in the area of composition theory . There are many such models proposed in the security literature (e.g. <ref> [AF91, DBY94, LSW91, LR92, PWK96] </ref>). These models provide precise understanding of the results that can arise when different components are composed. This existing work is not explicitly leveraged by MOAT because it all requires that the composed parts be specified in specialized formal notations.
Reference: [Lun96] <author> Lunt, T. F., </author> <title> panel chair, DARPA Research Panel 2: Secure Networking and Assurance Technology, </title> <booktitle> Proceedings of the 19 th National Information Systems Security Conference, </booktitle> <address> Baltimore Maryland, </address> <month> October </month> <year> 1996, </year> <pages> pp. 661-676. </pages>
Reference-contexts: But perhaps most significantly, the Department of Defense is also moving towards new distributed security architectures. At present, there are several DARPA initiatives in this direction. For example, one such initiative investigates numerous technologies for wrapping objects with security layers <ref> [Lun96] </ref>. As these approaches do not follow a standard TCB model, they cannot depend on the collected experience of the rainbow books. In fact, the very diversity of solutions suggests that an approach based solely on collected experience may not be possible in the future. <p> The assurance argument must only concern itself with making sure that the protocol stack cannot be circumvented or otherwise undermined. There are many wrapper technologies that can be used for this purpose (see <ref> [Lun96] </ref>). If the object replaces one or more elements of the reference implementation, then those elements must be shown to be in compliance with the corresponds relation of the replaced layer.
Reference: [McC81] <author> McCormick, N., </author> <title> Reliability and Risk Analysis , Academic Press, </title> <address> San Diego, California, </address> <year> 1981, </year> <pages> pp. 154-228. </pages>
Reference-contexts: A useful overview of the approach can be found in <ref> [McC81] </ref>; the authoritative reference is [NRC81]. A fault t ree is a graphical representation of Boolean logic relationships between system components, and how they combine to affect the propagation of a particular fault in the system.
Reference: [McC95] <author> McCarthy, J., </author> <title> Dynamics of Software Development , Microsoft Press, </title> <address> Redmond, Washington, </address> <year> 1995, </year> <pages> 184 pp. </pages>
Reference-contexts: Modern commercial systems are not built so much as grown, with multiple iterations of the product being produced as features are added <ref> [McC95, McC96] </ref>. The software engineering community is just beginning to recognize this with new paradigms such as evolutionary and rapid development approaches [DAR97, SPC97, TS95].
Reference: [McC96] <author> McConnell, S., </author> <title> Rapid Development: Taming Wild Software Schedules , Microsoft Press, </title> <address> Redmond, Washington, </address> <year> 1996, </year> <pages> 660 pp. </pages>
Reference-contexts: Modern commercial systems are not built so much as grown, with multiple iterations of the product being produced as features are added <ref> [McC95, McC96] </ref>. The software engineering community is just beginning to recognize this with new paradigms such as evolutionary and rapid development approaches [DAR97, SPC97, TS95].
Reference: [Mea94a] <author> Meadows, C., </author> <title> Tradeoffs in Secure System Develop ment: An Outline, </title> <booktitle> Proceedings of CSESAW '94, </booktitle> <institution> Naval Surface Warfare Center, </institution> <month> July </month> <year> 1994 </year>
Reference-contexts: In some cases it may be necessary to trade off the different requirements against each other. This is as true of security as it is of any other system requirement. <ref> [Mea94a] </ref> There are security-critical systems that are so critical as to justify the costs of formal methods. But for many other systems, like ours, formal methods are simply not cost-justifiable. <p> In this environment, formal methods were not considered unreasonable. But increasingly, security-critical systems must compete with commercial software in terms of cost, functionality, and performance. Security is but one of many competing development goals <ref> [Mea94a] </ref>. Cost and time constraints have made the application of formality harder to cost-justify.
Reference: [Mea94b] <author> Meadows, C., </author> <title> The Feasibility of Quantitative Assessment of Security, </title> <booktitle> Proceedings of DCCA4, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: But at present, the security community has no such metrics. Any numbers assigned to branches of a MOAT be extremely suspect, and would result in a composite value in which we could place no real confidence. 43 While the security community discusses the need for quantitative metrics of security <ref> [Mea94b] </ref>, there are many difficulties that need to be addressed before that can become a reality. It is not clear that security can be assigned a meaningful simple quantitative value, nor is it clear that any simple combinative functions could be applied at the leaves [CW97].
Reference: [Mea97] <author> Meadows, C., </author> <title> Three Paradigms in Comp uter Security, </title> <booktitle> to appear in Proceedings of the 1997 New Security Paradigms Workshop, </booktitle> <address> England, </address> <month> September </month> <year> 1997. </year>
Reference: [MH95] <author> McLean, J. and C. Heitmeyer, </author> <title> High Assurance Computer Systems: A Research Agenda, </title> <booktitle> America in the Age of Information, National Science and Technology Council Committee on Information and Communications Forum, </booktitle> <address> Bethesda MD, </address> <year> 1995 </year> <month> 146 </month>
Reference: [MK93] <author> Myers, E. A. and J. C. Knight, </author> <title> An Improved Software Inspection Technique And An Empirical Evaluation Of Its Effectiveness, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 36, No. 11, </volume> <month> November, </month> <year> 1993, </year> <pages> pp. 50-61. </pages>
Reference-contexts: It can consist of freeform scrutiny and discussion of source code, or it can follow a precise list of activities. Inspection can also involve tools that make the task less ad hoc and therefor more repeatable. Examples of the latter include lint and Inspec <ref> [MK93] </ref>. All of these techniques have been demonstrated to be effective, with the degree of effectiveness increasing with cost of application.
Reference: [MMM95] <author> Milli, H., F. Mili, and A. Mili, </author> <title> Reusing Software: Issues and Research Directions, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 21, No. </volume> <month> 6 : June </month> <year> 1995, </year> <pages> pp. 528-562. </pages>
Reference: [Moo90] <author> Moore, A., </author> <title> The Specification and Verified Decomposition of System Requirements Using CSP, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 16, No. 9, </volume> <month> Sept </month> <year> 1990, </year> <pages> pp. 932-948. </pages>
Reference-contexts: There are many published examples in which systems were formally modeled and their security reasoned about (e.g. [Kem90], <ref> [Moo90] </ref>). These published experiments with formal methods have found them to be quite effective. One might then conclude that developers who need to stray from the collected experience approach should rely on formal methods. But the bottom line is that formal methods have failed to gain widespread acceptance. <p> Finally, Spencers approach is essentially top-down: system requirements are decomposed into restrictions on objection interactions which are later themselves demonstrated to hold. 3.7.4 Moore A similar project lines was performed by Moore using the Communicating Sequential Processes notation <ref> [Moo90] </ref>. Previous work involving reasoning about systems specified in CSP was concerned with determining how the composition of a collection of specified object would behave. Given a collection of objects, they asked what formal semantics should be associated with the composition of those objects.
Reference: [MP94] <author> Moore, A. P. and C. N. Payne, Jr., </author> <title> The RS-232 character repeater refinement and assurance argument. </title> <note> NRL Technical Memorandum 5540-034:amcp, Naval Research Laboratory, 1994 available at: http://www.itd.navy.mil/ITD/5540/publications/CHACS/1996/newrptrTL/ newrptrTL.html </note>
Reference: [MP96] <author> Moore, A. P. and C. N. Payne Jr., </author> <title> Increasing Assurance with Literate Programming Techniques, </title> <booktitle> Proceedings of the 11 th Annual Conference on Computer Assurance, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: The MOAT approach represents a concrete instantiation of the proposed methodology and validates the conclusions of the authors of [PFN93] that the methodology represents an improvement over previous approaches. 3.5 The Presentation of Assurance Arguments 3.5.1 Literate Programming Moore and Payne <ref> [MP96] </ref> expressed dissatisfaction with a previous experience in the use of formal methods to prove that a security-critical device met its requirements. <p> The analysis of these aspects are necessarily more subjective than those aspects that are formalized. Finally, although formal methods are more precise, they can also be less intuitive than informal methods. The documentation must explain and motivate the formalisms used. <ref> [MP96] </ref> Based on a small experiment with the use of literate programming techniques to document assurance arguments, they conclude We believe that its use would have prevented many of the problems that we encountered in the certification of the network security device.
Reference: [MPM95] <author> McHugh, J., C.N. Payne and C. Martin. </author> <title> Assurance Mappings, a chapter of the Handbook for the Computer Security Certification of Trusted Systems, </title> <note> NRL Technical Memorandum 5540:081A, </note> <institution> Naval Research Laboratory, </institution> <address> Washington, DC, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: It is entirely too easy for a prose argument to slip over into hand-waving. Evaluators should and must be somewhat suspicious; they should approach these mapping arguments with a critical eye. <ref> [MPM95] </ref> This document makes clear that even in the staunchest bastions of computer security informal arguments can be acceptable they need only be sufficiently rigorous (and complete) to satisfy the critical eye of the evaluator.
Reference: [Mue94] <author> Muehrcke, C. K., </author> <title> Formal Methods for the Informal World, </title> <booktitle> Proceedings of Computer Security Foundations Workshop VII, </booktitle> <address> Franconia, NH, </address> <month> June </month> <year> 1994, </year> <pages> pp. 36-46. </pages>
Reference: [Mye96] <author> Myerson, M., </author> <title> Risk Management Process for Software Engineering Models , Artech House, </title> <address> Boston, Massachusetts, </address> <pages> 226 pp., </pages> <year> 1996. </year>
Reference-contexts: In the latter, the greatest security risks are addressed (making them less likely or less damaging) so that the system will be secure enough to resist the anticipated threats. For a thorough introduction to risk management, see <ref> [Mye96] </ref>. Finally, the rising popularity of distributed objectoriented systems has further eroded the TCB model. For one thing, it becomes difficult or impossible to rely on any degree of physical security. <p> An iterative approach to development has many practical benefits. It allows user validation of key functionality early in the process, ensures that some form of working product will be available when a deadline is reached, and allows testing to be performed early in the life-cycle <ref> [Boe88, BT75, Mye96] </ref>. The waterfall is not an iterative process model. In such an environment, the waterfall may be faked [PC86], but it cannot be followed. There are many novel architectures and commercial systems for which the waterfall is not a good choice.
Reference: [NASA95] <author> National Aeronautics and Space Administration, </author> <title> Formal Methods Specification and Verification Guidebook for Software and Computer Systems, Volume I: Planning and Technology Insertion , NASA-GB-002-95, Release 1.0, </title> <month> July </month> <year> 1995. </year>
Reference-contexts: He claims that selective application of formality is the only realistic manner in which extreme degrees of formality can be brought to bear where they are most needed. Rushby is by no means alone in his thinking. The NASA formal methods guidebook takes an almost identical position <ref> [NASA95] </ref>.
Reference: [Nel97] <author> Nelson, R., </author> <title> Integrating Formalism and Pragmatism: </title> <booktitle> Architectural Security, to appear in Proceedings of the 1997 New Security Paradigms Workshop, </booktitle> <address> England, </address> <month> September </month> <year> 1997. </year>
Reference: [Neu95] <author> Neumann, P. G., </author> <title> Architectures and Formal Representations for Secure Systems, </title> <type> Technical Report, </type> <institution> Computer Science Laboratory, SRI International, </institution> <address> Menlo Park, CA, </address> <month> October </month> <year> 1995. </year>
Reference: [NRC81] <author> U. S. </author> <title> Nuclear Regulatory Commission, Fault Tree Handbook , NUREG-0492, </title> <address> Washington, D. C. </address> <month> January </month> <year> 1991. </year>
Reference-contexts: A useful overview of the approach can be found in [McC81]; the authoritative reference is <ref> [NRC81] </ref>. A fault t ree is a graphical representation of Boolean logic relationships between system components, and how they combine to affect the propagation of a particular fault in the system.
Reference: [OFSS96] <author> Olawsky, D., T. Fine, E. Schneider, and R. Spencer, </author> <title> Developing and Using a Policy Neutral Access Control Policy, </title> <booktitle> Proceedings of the New Security Paradigms Workshop, </booktitle> <address> Lake Arrowhead, California, </address> <year> 1996, </year> <pages> pp. 60-67 </pages>
Reference-contexts: But it is not only the research community that is moving towards distributed models of security. Industrial endeavors include Safebots [FL96], CORBA security [OMG97], DCE security [OSF92], and the policy-neutral model used in DTOS <ref> [OFSS96] </ref>, several of which are already in common use. But perhaps most significantly, the Department of Defense is also moving towards new distributed security architectures. At present, there are several DARPA initiatives in this direction. For example, one such initiative investigates numerous technologies for wrapping objects with security layers [Lun96].
Reference: [OMG97] <author> Object Management Group, </author> <title> Security Service Specification in CORBAServices: Common Object Services Specification , July 1997. </title>
Reference-contexts: Some other examples include Secure Network Objects [VABW96], the Distributed Compartment Model [Gre96], and Metaobjects [RH97]. But it is not only the research community that is moving towards distributed models of security. Industrial endeavors include Safebots [FL96], CORBA security <ref> [OMG97] </ref>, DCE security [OSF92], and the policy-neutral model used in DTOS [OFSS96], several of which are already in common use. But perhaps most significantly, the Department of Defense is also moving towards new distributed security architectures. At present, there are several DARPA initiatives in this direction.
Reference: [OSF92] <author> Open Software Foundation, </author> <title> Security in a Distributed Computing Environment, </title> <type> White Paper, </type> <month> January </month> <year> 1992. </year>
Reference-contexts: Some other examples include Secure Network Objects [VABW96], the Distributed Compartment Model [Gre96], and Metaobjects [RH97]. But it is not only the research community that is moving towards distributed models of security. Industrial endeavors include Safebots [FL96], CORBA security [OMG97], DCE security <ref> [OSF92] </ref>, and the policy-neutral model used in DTOS [OFSS96], several of which are already in common use. But perhaps most significantly, the Department of Defense is also moving towards new distributed security architectures. At present, there are several DARPA initiatives in this direction.
Reference: [PC86] <author> Parnas, D., P. Clements, </author> <title> A Rational Design Process: How and Why to Fake It, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-12, No. 2, </volume> <month> Feb. </month> <year> 1986. </year> <month> 147 </month>
Reference-contexts: The waterfall is not an iterative process model. In such an environment, the waterfall may be faked <ref> [PC86] </ref>, but it cannot be followed. There are many novel architectures and commercial systems for which the waterfall is not a good choice. <p> The MOAT approach presents variably-refined argument trees representing critical software properties as an answer to this problem. 3.1.3 The Rational Process In 1986, Parnas and Clements introduced the notion of faking a rational design process <ref> [PC86] </ref>. They argued that it didnt matter what steps were taken in practice, the documentation could be arranged post facto in a way that made it appear as if a perfectly rational process had been performed.
Reference: [PCCW93] <author> Paulk, M., B. Curtis, M. Chrissis, and C. Weber, </author> <title> Capability Maturity Model, Version 1.1, </title> <journal> IEEE Software, </journal> <volume> Vol. 10, No. 4, </volume> <month> July </month> <year> 1993, </year> <pages> pp. 18-27. </pages>
Reference-contexts: Successful software can result regardless of how these activities are performed: they may be combined or separated; interspersed or performed sequentially. It is generally accepted that a systematic development process is preferable to one that occurs in a haphazard manner <ref> [PCCW93] </ref>. A software process model provides the developer with guidance in deciding in what order the development activities should be performed. The process model provides a framework in which other software engineering notations, tools, and techniques can be brought to bear.
Reference: [PFL93] <author> Payne, C. N., J. N. Froscher, and C. E. Landwehr, </author> <title> Toward a Comprehensive INFOSEC Certification Methodology, </title> <booktitle> Proceedings of the 16 th National Computer Security Conference, </booktitle> <address> Baltimore, MD, </address> <month> Sept. </month> <year> 1993, </year> <pages> pp. 165-172. </pages>
Reference-contexts: MOAT represents a refinement of this approach, accommodating more general risk profiles, balancing formality against the risks of changing requirements, focusing on clarity of communication, and facilitating tradeoffs between security and other goals. 3.4.3 A Comprehensive Certification Methodology Payne, Froscher, and Landwehr <ref> [PFL93] </ref> propose an alternative approach that recognizes the need to integrate security into a risk-driven process model. Their approach addresses the critical risk that the delivered system (including assurance arguments) will not satisfy the accreditation agency.
Reference: [PKPR97] <author> Pitts, B., T. Kumbula, M. Popovich, and D. Reed, </author> <title> The Process of Media Writing, </title> <publisher> Allyn & Bacon Books, </publisher> <address> Needham Heights, Massachusetts, </address> <year> 1997, </year> <pages> 325 pp. </pages>
Reference-contexts: It is also interesting to draw a parallel with a very different field that uses a similar heuristic. Print journalism has long relied on the inverted pyramid approach to story writing <ref> [PKPR97] </ref>. Essentially, the journalist writes the paragraphs of a story in order from most important to least. An editor can then cut the 55 story at any point and know that the column-inches provided were used to best effect.
Reference: [Pre92] <author> Pressman, R., </author> <title> Software Engineering: A Practitioners Approach , Mc Graw Hill, </title> <address> New York, </address> <year> 1992. </year>
Reference: [PST91] <author> Potter, B., J. Sinclair, D. Till, </author> <title> An Introduction to Formal Specification and Z, </title> <publisher> Prentice Hall International, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: In such circumstances, the waterfall represents a mature process model. The waterfall model is often paired with formal methods techniques. In many formal methods documents, the waterfall model is presented as the software process model <ref> [PST91, Inc88, Bos95] </ref>. In fact, many of the beneficial effects of using formal specification notations can be seen as addressing shortcomings of the waterfall model. The sequential nature of the waterfall tends to compound the cost of errors that are made early in the process but not discovered until late.
Reference: [PVK90] <author> Parnas, D., J van Schouwen, S. Kwan, </author> <title> Evaluation of Safety-Critical Software, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 33, No. 9, </volume> <month> June </month> <year> 1990, </year> <pages> pp. 636-648. </pages>
Reference-contexts: A complete specification can be developed and then refined through design and ultimately implementation, with little risk that changing requirements or other unanticipated events will necessitate significant backtracking. 28 There are many examples of such systems in the literature (e.g. <ref> [Cor89, Rus81, PVK90] </ref>). These systems demonstrated that a waterfall process could be used to successfully build secure system software. The many documented successes might even suggest that a waterfall model is generally applicable to security-critical systems.
Reference: [PWK96] <author> Peri, R. V., W. A. Wulf, and D. M. Kienzle, </author> <title> A Logic of Composition for Information Flow Predicates, </title> <booktitle> Proceedings of the IEEE Computer Security Foundations Workshop, </booktitle> <address> Ireland, </address> <year> 1996. </year>
Reference-contexts: A great deal of effort ahs been expended in the area of composition theory . There are many such models proposed in the security literature (e.g. <ref> [AF91, DBY94, LSW91, LR92, PWK96] </ref>). These models provide precise understanding of the results that can arise when different components are composed. This existing work is not explicitly leveraged by MOAT because it all requires that the composed parts be specified in specialized formal notations.
Reference: [RH97] <author> Riechmann, T. and F. Hauck, </author> <title> Meta Objects for Access Control: Extending Capability-Based Security, </title> <booktitle> to appear in Proceedings of the 1997 New Security Paradigms Workshop, </booktitle> <address> England, </address> <month> September </month> <year> 1997. </year>
Reference-contexts: This environment invalidates several assumptions needed to support the TCB, The importance of distributed objectoriented systems has led to a number of different object-oriented security models, of which Legion is but one example. Some other examples include Secure Network Objects [VABW96], the Distributed Compartment Model [Gre96], and Metaobjects <ref> [RH97] </ref>. But it is not only the research community that is moving towards distributed models of security. Industrial endeavors include Safebots [FL96], CORBA security [OMG97], DCE security [OSF92], and the policy-neutral model used in DTOS [OFSS96], several of which are already in common use.
Reference: [RM83] <author> Roland, H.E. and B. </author> <title> Moriarty, </title> <publisher> System Safety Engineering and Management , John Wiley and Sons, </publisher> <address> New York, </address> <year> 1983, </year> <pages> pp. 215-271. </pages>
Reference: [Rus81] <author> Rushby, J., </author> <title> Design and Verification of Secure Systems, </title> <journal> ACM Operating Systems Review, </journal> <volume> Vol. 15, No. 5, </volume> <month> December </month> <year> 1981, </year> <pages> pp. 12-21. </pages>
Reference-contexts: A complete specification can be developed and then refined through design and ultimately implementation, with little risk that changing requirements or other unanticipated events will necessitate significant backtracking. 28 There are many examples of such systems in the literature (e.g. <ref> [Cor89, Rus81, PVK90] </ref>). These systems demonstrated that a waterfall process could be used to successfully build secure system software. The many documented successes might even suggest that a waterfall model is generally applicable to security-critical systems.
Reference: [Rus95] <author> Rushby, J., </author> <title> Formal Methods and their Role in the Certification of Critical Systems, </title> <address> SRI-CSL-95-01, </address> <month> January </month> <year> 1995. </year> <note> http://www.csl.sri.com/csl-95-1.html </note>
Reference-contexts: Cost and time constraints have made the application of formality harder to cost-justify. Even the formal methods community is recognizing that in order to be practical, formal methods must be limited to the problem elements where they provide the greatest return on investment <ref> [Rus95] </ref>. 2.3.5 Summary In spite of their shortcomings, formal methods can be extremely useful. For example, cryptography and protocol analysis are both aspects of security that have proven quite amenable to the application of formal 15 mathematical modeling. <p> It constantly reminds the user that the pupose of a specification (formal or informal) is to reduce risks, and the most appropriate notation is the one that maximizes the ratio of risks reduced to costs incurred. 3.2.3 Selective Application Rushby <ref> [Rus95] </ref> recognizes that the complete application of formal methods to a large project is both prohibitively expensive, and of dubious value. He argues that formal methods should be applied selectively.
Reference: [SB82] <author> Swartout, W., R. Balzer, </author> <title> On the Inevitable Intertwining of Specification and Implementation, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 25, No. 7, </volume> <month> July </month> <year> 1982. </year>
Reference: [Sch89] <author> Schaefer, M., </author> <title> Symbol Security Condition Considered Harmful, </title> <booktitle> Proceedings of the 1989 IEEE Computer Society Symposium on Security and Privacy, </booktitle> <address> Oakland, California, </address> <month> May, </month> <year> 1989, </year> <pages> pp. 20-46. </pages>
Reference-contexts: Schaefer discusses several security-critical systems in which a formal methods approach was tried. He notes that although the formal documents appeared as if a waterfall had been followed, in practice, the designspecification-analysis-implementation-test process is not strictly linear. Rather, it has shown to be an iterative process. <ref> [Sch89] </ref> He notes that discoveries can be made at any point that necessitate changing 12 the earliest documents and necessitate appropriate modifications to portions of much of the modeling, specification, and analysis that has already been done. [Sch89] The risk of changing requirements is not the only reason for avoiding the <p> Rather, it has shown to be an iterative process. <ref> [Sch89] </ref> He notes that discoveries can be made at any point that necessitate changing 12 the earliest documents and necessitate appropriate modifications to portions of much of the modeling, specification, and analysis that has already been done. [Sch89] The risk of changing requirements is not the only reason for avoiding the waterfall model. Modern commercial systems are not built so much as grown, with multiple iterations of the product being produced as features are added [McC95, McC96]. <p> Furthermore, he suggests that those who do have the necessary expertise in formalisms generally lack necessary implementation skills <ref> [Sch89] </ref>. 13 Meanwhile, the security community has long relied on experience with well-understood architectures. The vast majority of security practitioners are not, and never have been, formal methods gurus.
Reference: [SPC97] <institution> Software Productivity Consortium, Rapid Evolutionary Development , SPC-97057-CMC, </institution> <month> June </month> <year> 1997, </year> <note> available at http://www.software.org/pub/darpa/erd. </note>
Reference-contexts: Modern commercial systems are not built so much as grown, with multiple iterations of the product being produced as features are added [McC95, McC96]. The software engineering community is just beginning to recognize this with new paradigms such as evolutionary and rapid development approaches <ref> [DAR97, SPC97, TS95] </ref>. And the Department of Defense has instructed that large, software-dominated weapons and command and control systems should be acquired using an Evolutionary Acquisition model: Considered most broadly, EA consists of several steps. The first step defines the requirement and the general outline of the system.
Reference: [Spe96] <author> Spencer, R., </author> <title> Deriving Security Requirements for Applications on Trusted Systems, </title> <booktitle> Proceedings of the 19 th National Information Systems Security Conference, </booktitle> <address> Baltimore Maryland, </address> <month> October </month> <year> 1996, </year> <pages> pp. 420-427. </pages>
Reference-contexts: In this manner, every MOAT analysis potentially represents a reusable pattern. Whether or not these patterns will actually be reusable will depend on how well local design decisions can be kept from permeating the tree. 3.7.3 Spencer In <ref> [Spe96] </ref>, Spencer presents an approach used to derive the requirements for applications that are to be run on a trusted system.
Reference: [Ste91] <author> Sterne, D. F., </author> <title> On the Buzzword Security Policy, </title> <booktitle> Proceedings of the 1991 IEEE Computer Society Symposium on Research in Security and Privacy, Oakland, Cal., </booktitle> <pages> pp. 219-230. </pages>
Reference: [Tie91] <author> Tierney, M., </author> <title> The Evolution of Def Stan 00-55 and 00-56: an intensification of the formal 148 methods debate in the UK, </title> <booktitle> SPRU Software Workshop on Policy Issues in Systems and Software Development, </booktitle> <address> Brighton UK, </address> <month> July </month> <year> 1991. </year>
Reference: [TS94] <author> Thomas, R. K., and R. S. Sandhu, </author> <title> Conceptual Foundations for a Model of Task-Based Authorizations, </title> <booktitle> Proceedings of Computer Security Foundations Workshop VII, </booktitle> <address> Franconia, NH, </address> <month> June </month> <year> 1994, </year> <pages> pp. 66-79. </pages>
Reference-contexts: Nevertheless, the costs incurred in performing the experiments were reduced due to reuse. Some of the more interesting observations are presented below. At the highest levels, we were able to reuse an entire analysis. In convincing a customer that Legion would be able to support Role-Based Access Control <ref> [TS94] </ref>, we built a design that was very similar to the delegation model. We were able to reason about this design by reusing the delegation analysis in entirety and relabeling the nodes.
Reference: [TS95] <author> Tilley, S. R., and D. B. Smith, </author> <title> Perspectives on Legacy System Reengineering, </title> <journal> Software Engineering Institute, </journal> <note> 1995, available at http://www.sei.cmu.edu/technology/reengineering/ pubs/lsysree/index.htm. </note>
Reference-contexts: Modern commercial systems are not built so much as grown, with multiple iterations of the product being produced as features are added [McC95, McC96]. The software engineering community is just beginning to recognize this with new paradigms such as evolutionary and rapid development approaches <ref> [DAR97, SPC97, TS95] </ref>. And the Department of Defense has instructed that large, software-dominated weapons and command and control systems should be acquired using an Evolutionary Acquisition model: Considered most broadly, EA consists of several steps. The first step defines the requirement and the general outline of the system.
Reference: [VAB91] <author> Varadharajan, V., P. Allen, and S. Black, </author> <title> An Analysis of the Proxy Problem in Distributed Systems, </title> <booktitle> Proceedings of the 1991 IEEE Computer Society Symposium on Research in Security and Privacy, </booktitle> <address> Oakland, CA, </address> <month> May </month> <year> 1991, </year> <pages> pp. </pages> <note> 255-275. </note> <author> [VABW96] van Doorn, L., M. Abadi, M. Burrows, and E. Wobber, </author> <title> Secure Network Objects, </title> <booktitle> Proceedings of the 1996 IEEE Symposium on Security and Privacy, </booktitle> <address> Oakland, CA, </address> <month> May </month> <year> 1996, </year> <pages> pp. </pages> <address> 211- 221. </address>
Reference-contexts: for any method target executes on its behalf Method execution by the target on behalf of the RA requires an external leverage relationship Method execution by the target on behalf of the RA requires an authorizing certificate (8.5) 84 well-reasoned certificate schemes for which interesting properties have been proven (e.g. <ref> [CV92, VAB91] </ref>).
Reference: [Wei71] <author> Weinberg, G. M., </author> <title> The Psychology of Computer Programming , Van Nostrand Reinhold, </title> <address> New York, </address> <year> 1971. </year>
Reference-contexts: But MOAT requires the user to present the arguments for review by the other stakeholders. Experience with reviews and inspections have demonstrated that can be extremely effective [Fag86]. Even simply preparing for an inspection can result in much improved work products <ref> [Wei71] </ref>. In addition, the alternative perspectives offered as part of the review may result in additional problems being found. So while the use of MOAT with informal arguments may not be as thorough as a formal approach, users who are uncomfortable with formal methods can still gain significant benefits.
Reference: [Win90] <author> Wing, J., </author> <title> A Specifiers Introduction to Formal Methods, </title> <journal> IEEE Computer, </journal> <volume> Vol. 23, No. 9, </volume> <month> Sept. </month> <year> 1990, </year> <pages> pp. 8-24. </pages>
Reference-contexts: However the methods have been demonstrated to reduce errors if used appropriately. [BH94]. And Wing points out that The greatest benefit in applying a formal method often comes from the process of formalizing rather than the end result <ref> [Win90] </ref>. The notion that formal methods can guarantee correctness is a dangerous one, and yet it has been hard to banish. Formal methods, when applied to security-critical systems, can make them more secure . But they cannot ensure that a system is secure in any absolute sense. <p> of the problems associated with those methods, such as the risk of premature formalization. 10.2 MOATs and General Problem Understanding One of the most common arguments advanced in favor of formal methods approaches is that their use results in a greater understanding of the nature of the problem under consideration <ref> [Win90, BH94] </ref>. It is impossible to quantify or rigorously explain this phenomena, but it is nonetheless observable. Similarly, the experiments demonstrated that the use of MOAT resulted in considerably increased understanding of the problem areas under consideration.
Reference: [WLH81] <author> Wulf, W. A., R. Levin, and S. P. Harbison, HYDRA/C.mmp: </author> <title> An Experimental Computer System , Mc-Graw-Hill, </title> <address> New York, </address> <year> 1981. </year>
Reference: [WSL95] <author> Williams, J., M. Scha efer, and D. Landoll, </author> <title> Pretty Good Assurance, Proceedings of the New Security Paradigms Workshop, Little Compton, </title> <address> Rhode Island, </address> <year> 1995, </year> <pages> pp. 82-89. </pages>
Reference-contexts: Rank and file developers need alternatives that permit them to analyze and assess the security of their systems at a reasonable cost. But it is not only the commercial world that has adopted a good enough approach to security. The security community at large is moving in that direction <ref> [WSL95] </ref>. Historically, security was viewed as a critical requirement, and customers were willing to spend tremendous amounts on it. In this environment, formal methods were not considered unreasonable. But increasingly, security-critical systems must compete with commercial software in terms of cost, functionality, and performance.
Reference: [Wul95] <author> Wulf, W. A., </author> <title> Comments made in the Javasoft Security Forum 1.1, </title> <note> available at http://java.sun.com:81/forum/securityForum.html, 1995. </note>
Reference-contexts: But there are indications that the TCB model is losing its appeal. At a recent debate at the Security and Privacy Forum, almost half of the audience agreed with Wulfs assertion that the TCB is fundamentally flawed and should no longer be used to justify security architectures <ref> [Wul95, BK97] </ref>. Even the sponsors of the rainbow books have moved away from the TCB in their endorsement of the Common Criteria [CC96]. The latter are not architecturally specific, but rather provide guidelines for the construction of architecturally specific evaluation criteria.
Reference: [WW97] <author> Wang, C., and W. Wulf, </author> <title> A Framework for Security Measurement, </title> <booktitle> Proceedings of the 20 th National Information Systems Security Conference, </booktitle> <address> Baltimore Maryland, </address> <month> October </month> <year> 1997, </year> <note> to appear. </note>
Reference: [WWK96] <author> Wulf, W. A., C. Wang, and D. M. Kienzle, </author> <title> A New Model of Security for Distributed Systems, </title> <booktitle> Proceedings of the New Security Paradigms Workshop, </booktitle> <address> Lake Arrowhead, California, </address> <year> 1996, </year> <month> pp.34-43. </month>
Reference-contexts: The MOAT approach arose as part of the development of the security model for the Legion distributed high-performance computing system [GW97]. The Legion Security Model takes a decentralized approach towards security <ref> [WWK96] </ref>. Rather than making the system responsible for enforcing some global definition of security, Legion allows users application objects to define and enforce individualized security policies. With the right to enforce an individual notion of security comes the responsibility of doing it correctly.
Reference: [You91] <author> Young, W. D., </author> <title> Formal Metho ds versus Software Engineering: Is There a Conflict ?, Proceedings of the Fourth Testing, Analysis, </title> <booktitle> and Verification Symposium, </booktitle> <address> Victoria, British Columbia, </address> <month> October, </month> <year> 1991, </year> <pages> pp. 188-189. </pages>
Reference-contexts: Ultimately, the developers and the stakeholders will have to decide how much formality is enough. 27 3.3.3 A Consensus Position Regardless of the theoretical benefits or limitations of formal methods, they have been found in practice to be beneficial. As Young <ref> [You91] </ref> points out, while formal methods cannot guarantee perfection, they can increase assurance in the quality of software. Bowen and Hinchley summarize this as despite the mathematical basis of these methods, errors are still possible. However the methods have been demonstrated to reduce errors if used appropriately. [BH94].
Reference: [You95] <author> Yourdan, E., </author> <title> When Good Enough Software is Best, Guest Editorial, </title> <journal> IEEE Software, </journal> <volume> Vol. 12, No. 3, </volume> <pages> pp 79-81. 149 </pages>
Reference-contexts: So, for example, when Yourdan makes an eloquent case for a good enough approach to software, he steers clear of controversy by saying that the old paradigm should still be applied 11 to critical systems <ref> [You95] </ref>. But the security community is becoming increasingly cognizant of the fact that security cannot be treated as the single immutable requirement.
References-found: 131

