URL: http://www.cs.uoregon.edu/~sabry/papers/thesis.ps
Refering-URL: http://www.cs.uoregon.edu/~sabry/papers/index.html
Root-URL: http://www.cs.uoregon.edu
Title: The Formal Relationship between Direct and Continuation-Passing Style Optimizing Compilers: A Synthesis of Two Paradigms  
Author: by Amr A. Sabry Keith Cooper Steve Cox 
Degree: A Thesis Submitted in Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy Approved, Thesis Committee: Matthias Felleisen, Chairman Professor of Computer Science Robert Cartwright Professor of Computer Science  Associate Professor of Computer Science  Assistant Professor of Computational and  
Date: August, 1994  
Address: Houston, Texas  
Affiliation: RICE UNIVERSITY  Applied Mathematics  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> Aho, A., Sethi, R., and Ullman, J. Compilers|Principles, </author> <title> Techniques, and Tools. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass. </address> <year> (1985). </year>
Reference-contexts: v 2 (v 3 : The expression becomes even more readable when we replace the symbol with the notation for assignment !: call f 2 ! v 1 fl v 1 3 ! v 2 return v 3 This last expression is essentially the conventional triples representation for our expression <ref> [1] </ref>. The example hints that the CPS transformation generates a sensible intermediate representation. In addition, given that the CPS transformation is a simple, well-understood, linear transformation that uniformly applies to all programming constructs, it is not surprising that it became a popular tool in compilers.
Reference: [2] <author> Allison, L. </author> <title> A Practical Introduction to Denotational Semantics. </title> <booktitle> Volume 23 of Cambridge Computer Science Texts, </booktitle> <publisher> Cambridge University Press (1986). </publisher>
Reference-contexts: The second translation relies on Allison's <ref> [2] </ref> CPS translation that keeps the local transfer of control independent of the continuation. 90 * The proof of Lemma 4.2 only uses a restricted version of v on continuations, A, and callcc: (callcc (k:C [(x:kx)])) = (callcc (k:C [k])) ( v 1 ) k 62 trap (C) (x:callcc k:xk) =
Reference: [3] <author> Appel, A. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press (1992). </publisher>
Reference-contexts: Abstract Collecting Interpreter (II) : : : : : : : : : : : 136 1 Chapter 1 Background and Motivation The continuation-passing style (CPS) transformation is ubiquitous in the area of programming language semantics: * it defines the intermediate representation of many compilers and program anal ysis tools <ref> [3, 15, 39, 55, 56, 58, 82, 92, 97] </ref>; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds <p> Indeed many state-of-the-art compilers for applicative higher-order programming languages (Scheme, ML, Lisp, etc) use a CPS intermediate representation <ref> [3, 56, 82] </ref>, and many others do not [7, 9, 12, 50, 59]. <p> for every intermediate computation and re-orders the subexpressions of a program in a way that reflects the order in which they should be evaluated [39]. * Despite its functional appearances, CPS code constitutes an (imperative) abstract assembly language whose standard reduction sequence mimics the behav ior of typical target machines <ref> [3, 4, 41, 55, 104] </ref>. * Data-flow analyzers, partial evaluators, and other tools perform better on CPS programs than on source programs [22, 33, 34, 72]. * The CPS transformation is a global transformation that affects every subex-pression in a program. <p> Chapter 3 addresses the most elementary and most obvious advantage of CPS compilers over direct compilers, namely that the equational theory for the CPS intermediate representation is richer than the equational theory for pure call-by-value languages [75]. Since equational theories are commonly used to perform simple optimizations <ref> [3] </ref>, it appears that CPS compilers can perform more simplifications on their intermediate representation than direct compilers. In order to understand and report these optimizations of CPS programs in terms of transformations on the original source programs, we formulate a precise correspondence between the equational theories for both languages. <p> The CPS intermediate language used in realistic CPS compilers <ref> [3, 56, 97] </ref> corresponds to the output of our compacting CPS transformation. <p> For example, Shivers partitions procedures and continuations in order to improve the data flow analysis of CPS programs [92, sec 3.8.3]. Also, in both Orbit [56] and Rabbit [97], the allocation strategy of a closure changes if the closure is a continuation. Similarly, Appel <ref> [3, p 114-124] </ref> describes various techniques for closure allocation that treat the continuation closure in a special way. In order to reflect these changes in the machine, we tag continuation closures with a special marker "ar" that describes them as activation records. <p> This "optimization" eliminates "some of the register shu*ing" [97, p 94] during the evaluation of the term. Appel <ref> [3] </ref> achieves the same effect without modifying the CPS transformation by letting the variables k 1 and k 2 share the same register during the procedure call. <p> from the theoretical CPS abstract machine and interpret this intermediate code on a more specialized machine: * Orbit [56] essentially ignores the operator callcc "because the runtime system ensures that any continuation which is captured by call-with-current-con tinuation will be migrated dynamically to the heap" [56, p. 227]. * SML-NJ <ref> [3] </ref> ensures that the current continuation is always accessible in a register. In the absence of control operators, the variable k in the expression (k W ) always refers to the current continuation and is therefore useless.
Reference: [4] <author> Appel, A. and Jim, T. </author> <title> Continuation-passing, closure-passing style. </title> <booktitle> In Conference Record of the 16th ACM Symposium on Principles of Programming Languages (1989) 293-302. </booktitle>
Reference-contexts: for every intermediate computation and re-orders the subexpressions of a program in a way that reflects the order in which they should be evaluated [39]. * Despite its functional appearances, CPS code constitutes an (imperative) abstract assembly language whose standard reduction sequence mimics the behav ior of typical target machines <ref> [3, 4, 41, 55, 104] </ref>. * Data-flow analyzers, partial evaluators, and other tools perform better on CPS programs than on source programs [22, 33, 34, 72]. * The CPS transformation is a global transformation that affects every subex-pression in a program.
Reference: [5] <author> Baker, H. </author> <title> CONS should not CONS its arguments, part II: </title> <booktitle> Cheney on the M.T.A. </booktitle> <month> (January </month> <year> 1994). </year> <type> Unpublished manuscript. </type>
Reference-contexts: program anal ysis tools [3, 15, 39, 55, 56, 58, 82, 92, 97]; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation <ref> [5, 37] </ref>; * it embeds classical logic into constructive logic [46, 70, 71]. <p> In summary, the explicit manipulation of the continuation enables a mathematical theory based on functions to explain both sequencing and jumps uniformly as function applications. 1 In practice however, the resulting stack must be treated like a garbage-collected heap since it is never popped during the execution of the program <ref> [5, 37] </ref>. 15 2.1.3 Continuations and Transfers of Control Although the transformations described in the two previous subsections appear to have dual effects, they are in fact identical transformations.
Reference: [6] <author> Barendregt, H. P. </author> <title> The Lambda Calculus: Its Syntax and Semantics. </title> <booktitle> Volume 103 of Studies in Logic and the Foundations of Mathematics, </booktitle> <pages> North-Holland, </pages> <note> revised edition (1984). </note>
Reference-contexts: Chapter 7 concludes this dissertation with a summary of contributions, open problems, and directions for future research. 1.2 fl: Syntax, Calculi, and Semantics The core of our source language is a typed or untyped call-by-value functional language based on the language fl of the pure lambda calculus <ref> [6] </ref>. The latter language consists of variables, -abstractions (procedures) and applications. <p> The latter language consists of variables, -abstractions (procedures) and applications. The set of terms M is generated inductively over an infinite set of variables Vars: M ::= V j (M M ) (fl) V ::= x j (x:M ) (Values ) x 2 Vars We adopt Barendregt's <ref> [6, ch 2,3] </ref> notation and terminology for this syntax. Thus, in the abstraction (x:M ), the variable x is bound in M . Variables that are not bound by a -abstraction are free; the set of free variables in a term M is F V (M ). <p> If the terms C [M ] and C [N ] are simply typed fl-programs, then the termination criterion is useless as the evaluation of any simply typed fl-program terminates <ref> [6] </ref>. Thus to compare two simply typed expressions M and N , we enrich the set of contexts C to allow recursion and basic arithmetic operations. <p> X G ` g 1 = g 2 if and only if X R ` h (g 1 ) = h (g 2 ). The above correspondence is similar to the correspondence between the -calculus and combinatory logic <ref> [6, 18] </ref>. Usually, we will be given the two languages R and G, the translation f , and the equational theory for G. Our goal will be to derive the theory for R that equationally corresponds to the theory for G. The derivation of the axioms X R is systematic. <p> Lemma 2.4 Let P and Q be in fi-normal form. If fi ` F [[M ]] !! P and fi ` F [[M ]] !! Q, then P Q. Sketch The proof is a consequence of the Church-Rosser theorem for fi <ref> [6] </ref>. We can view the function F 2 as the specification of an optimal CPS transformation that eliminates all administrative reductions. It remains to find a one-pass implementation of this CPS transformation. By Proposition 2.2, administrative reductions can be performed in any order without affecting the result. <p> Proof Assume fi ` C k [[M ]][k := x:x] !! W , then by Lemma 2.5, fi ` (F [[M ]] x:x) !! ((k:C k [[M ]]) x:x) ! C k [[M ]][k := x:x] !! W By the Postponement Lemma <ref> [6, p 15] </ref>, we also have: (F [[M]] x:x) !! fi L !! W for some term L Since M is a closed term, W cannot be a variable; it must a -abstraction. Any - expansion starting from a -abstraction will also result in a -abstraction.
Reference: [7] <author> Bartley, D. H. and Jensen, J. C. </author> <title> The implementation of PC Scheme. </title> <booktitle> In Proceedings of the ACM Conference on Lisp and Functional Programming (1986) 86-93. </booktitle>
Reference-contexts: Indeed many state-of-the-art compilers for applicative higher-order programming languages (Scheme, ML, Lisp, etc) use a CPS intermediate representation [3, 56, 82], and many others do not <ref> [7, 9, 12, 50, 59] </ref>.
Reference: [8] <author> Boehm, H.-J. </author> <title> Side effects and aliasing can have simple axiomatic descriptions. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7, </volume> <month> 4 (October </month> <year> 1985) </year> <month> 637-655. </month>
Reference-contexts: We choose the following common representation <ref> [8, 62, 73] </ref>. <p> The axiomatization of the semantics of languages with assignments has been studied extensively <ref> [8, 17, 23, 26, 29, 51, 61, 102] </ref>. Each of the previously proposed logics was designed independently, and differs from the others in subtle ways. Our approach of deriving the calculus from the store-passing axioms is more systematic and generalizes to other languages [88].
Reference: [9] <author> Boehm, H.-J. and Demers, A. </author> <title> Implementing Russel. </title> <booktitle> In Proceedings of the ACM Sigplan Symposium on Compiler Construction, Sigplan Notices, </booktitle> <volume> 21, </volume> <month> 7 </month> <year> (1986) </year> <month> 186-195. </month>
Reference-contexts: Indeed many state-of-the-art compilers for applicative higher-order programming languages (Scheme, ML, Lisp, etc) use a CPS intermediate representation [3, 56, 82], and many others do not <ref> [7, 9, 12, 50, 59] </ref>.
Reference: [10] <author> Bondorf, A. </author> <title> Improving binding times without explicit CPS-conversion. </title> <booktitle> In Proceedings of the ACM Conference on Lisp and Functional Programming (1992) 1-10. </booktitle> <pages> 149 </pages>
Reference-contexts: The literature generally supports the idea that CPS improves the precision of data flow analysis <ref> [10, 15, 33, 34, 58, 92] </ref>.
Reference: [11] <author> Clinger, W. </author> <title> The Scheme 311 compiler: An exercise in denotational semantics. </title> <booktitle> In Proceedings of the ACM Conference on Lisp and Functional Programming (1984) 356-364. </booktitle>
Reference-contexts: The partial function ffi abstracts the semantics of the primitive operations. The CEK machine provides a model for designing direct compilers <ref> [11, 31, 59] </ref>. A compiler based on the CEK machine implements an efficient representation for environments, e.g., displays, and for continuations, e.g., a stack.
Reference: [12] <author> Clinger, W. and Hansen, L. </author> <title> Lambda, the ultimate label or a simple optimizing compiler for Scheme. </title> <booktitle> In Proceedings of the ACM Conference on Lisp and Functional Programming (1994). To Appear. </booktitle>
Reference-contexts: Indeed many state-of-the-art compilers for applicative higher-order programming languages (Scheme, ML, Lisp, etc) use a CPS intermediate representation [3, 56, 82], and many others do not <ref> [7, 9, 12, 50, 59] </ref>.
Reference: [13] <editor> Clinger, W. and Rees, J. </editor> <title> Revised 4 report on the algorithmic language Scheme. Lisp Pointers, </title> <type> 4, </type> <month> 3 </month> <year> (1991) </year> <month> 1-55. </month>
Reference-contexts: Informal or incomplete arguments regarding the relative advantages and disadvantages of the 2 CPS intermediate representation with respect to other intermediate representations are also common: * The CPS transformation translates complicated control facilities in the source language, e.g., exception handlers and call-with-current-continuation <ref> [13] </ref> to simple procedures that manipulate their continuation arguments in non-standard ways [77, 101]. * The CPS intermediate representation is simple: it consists only of basic primitive operations and procedure applications, and has a well-understood semantics in terms of the -calculus [75]. * The canonical equational theory for the CPS intermediate <p> intuitive explanation of a program that implements coroutines using first-class continuations and the second subsection includes a simplification phase based on the CS axioms. 94 4.4.1 The Original Program For convenience, we use a superset of Core Scheme that includes assignments to variables via set!, and various other syntactic extensions <ref> [13] </ref>: error df (let ([x M ]) N) = ((x:N ) M ) (begin M N) df = ((d:N ) M ) where d 62 F V (N ) (x:M N) = (x:(begin M N )) (letrec ([x (y:M )]) N) df (begin (set! x (y:M )) N )) The original
Reference: [14] <author> Clinger, W., Friedman, D., and Wand, M. </author> <title> A scheme for a higher-level semantic algebra. </title> <editor> In Reynolds, J. and Nivat, M., editors, </editor> <booktitle> Algebraic Methods in Semantics, </booktitle> <address> Cambridge University Press (1985) 237-250. </address>
Reference-contexts: standard reductions, we follow the traditional route and immediately specify the translation of these values into CPS form and use this translation as the formal semantics of the language. 6 The extensions to C k (or F ) consist of two additional clauses to the function (or F v ) <ref> [14] </ref>: [[callcc]] = (k:u:((u k) d:k)) [[A]] = (k:x:x) The CPS transform of callcc is a procedure that expects a continuation k and an argument u. The non-standard manipulation of the continuation is manifest in the second argument to u, which is a procedural abstraction of the continuation.
Reference: [15] <author> Consel, C. and Danvy, O. </author> <title> For a better support of static data flow. </title> <booktitle> In Proceedings of the Conference on Functional Programming Languages and Computer Architecture (1991) 496-519. </booktitle>
Reference-contexts: Abstract Collecting Interpreter (II) : : : : : : : : : : : 136 1 Chapter 1 Background and Motivation The continuation-passing style (CPS) transformation is ubiquitous in the area of programming language semantics: * it defines the intermediate representation of many compilers and program anal ysis tools <ref> [3, 15, 39, 55, 56, 58, 82, 92, 97] </ref>; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds <p> The literature generally supports the idea that CPS improves the precision of data flow analysis <ref> [10, 15, 33, 34, 58, 92] </ref>.
Reference: [16] <author> Cousot, P. and Cousot, R. </author> <title> Abstract interpretation: A unified lattice model for static analysis of programs by construction of approximation of fixpoints. </title> <booktitle> In Conference Record of the 4th ACM Symposium on Principles of Programming Languages (1977) 238-252. </booktitle>
Reference-contexts: possible to recover x, i.e., new (x; s) = ` 62 dom (s) and x = new 1 (`). (For brevity, we will usually omit the second argument to new since it is easy to reconstruct from the context.) 122 Based on well-known ideas from the area of abstract interpretation <ref> [16, 53, 72, 92] </ref>, we derive a data flow analyzer from the previous interpreter. The first step in the derivation is to associate one location with each variable that holds the set of all values to which the variable is bound during the evaluation of the program.
Reference: [17] <author> Crank, E. and Felleisen, M. </author> <title> Parameter-passing and the lambda calculus. </title> <booktitle> In Conference Record of the 18th ACM Symposium on Principles of Programming Languages (1991) 233-244. </booktitle>
Reference-contexts: The axiomatization of the semantics of languages with assignments has been studied extensively <ref> [8, 17, 23, 26, 29, 51, 61, 102] </ref>. Each of the previously proposed logics was designed independently, and differs from the others in subtle ways. Our approach of deriving the calculus from the store-passing axioms is more systematic and generalizes to other languages [88]. <p> Our approach of deriving the calculus from the store-passing axioms is more systematic and generalizes to other languages [88]. Also, when compared to other systems, our calculus has several distinguishing features. First, in contrast with calculi derived from abstract machines for the imperative source language <ref> [17, 29, 61] </ref>, our equational theory never eliminates an expression of the form (setref! V 1 V 2 ). These expressions simply migrate from point to point within the program to allow lookup operations. In the other calculi [17, 29, 61], there is typically a distinguished position in the program text <p> contrast with calculi derived from abstract machines for the imperative source language <ref> [17, 29, 61] </ref>, our equational theory never eliminates an expression of the form (setref! V 1 V 2 ). These expressions simply migrate from point to point within the program to allow lookup operations. In the other calculi [17, 29, 61], there is typically a distinguished position in the program text that contains the most recent value associated with a particular location: setref! expressions modify this current value and lookup operations copy this current value.
Reference: [18] <author> Curry, H. B. and Feys, R. </author> <title> Combinatory Logic, Volume I. </title> <publisher> North-Holland, </publisher> <address> Amsterdam (1958). </address>
Reference-contexts: X G ` g 1 = g 2 if and only if X R ` h (g 1 ) = h (g 2 ). The above correspondence is similar to the correspondence between the -calculus and combinatory logic <ref> [6, 18] </ref>. Usually, we will be given the two languages R and G, the translation f , and the equational theory for G. Our goal will be to derive the theory for R that equationally corresponds to the theory for G. The derivation of the axioms X R is systematic.
Reference: [19] <author> Danvy, O. </author> <title> Three Steps for the CPS Transformation. </title> <type> Technical Report CIS-92-2, </type> <institution> Kansas State University (1992). </institution>
Reference-contexts: Their analysis did not however address the interactions among the CPS transformation, its inverse, reductions on call-by-value terms, and reductions on CPS terms. 57 In subsequent work, Danvy and Lawall <ref> [19, 57] </ref> recognize that the CPS transformation can be "staged" in a number of independent steps. Their staging is similar to ours; their first two stages essentially perform an A-normalization as explained in Section 3.1.
Reference: [20] <author> Danvy, O. </author> <title> Back to direct style. Science of Computer Programming (1993). To appear. Preliminary version in: </title> <booktitle> Proceedings of the 4th European Symposium on Programming, 1992. Lecture Notes in Computer Science, </booktitle> <volume> 582, </volume> <publisher> Springer Verlag. </publisher>
Reference-contexts: Some of the ideas are closely related to recent work by Danvy, Lawall, and Hatcliff. Danvy and Lawall <ref> [20, 22] </ref> studied the problem of inverting the CPS transformation and produced a "direct style" transformation similar to our transformation C 1 . Danvy and Lawall argue that the "direct style" transformation is useful in its own right and discuss applications in partial evaluation.
Reference: [21] <author> Danvy, O. and Filinski, A. </author> <title> Representing control: A study of the CPS transformation. </title> <note> Mathematical Structures in Computer Science, 2, 4 (1992) 361-391. 150 </note>
Reference-contexts: In order to minimize the size of intermediate programs, Steele improved the original CPS transformation to recognize various special cases. Although Steele's CPS transform generates terms without administrative redexes, his algorithm is complicated and includes ad-hoc optimizations. Danvy and Filinski <ref> [21] </ref> analyzed the CPS transformation in a more systematic way and defined a one-pass transformation that combines the traditional CPS transformation with the elimination of the administrative redexes. <p> In the process of transforming programs, the original algorithm increases the size of source terms considerably by introducing administrative redexes. Both Steele [97] and Danvy/Filinski <ref> [21] </ref> developed algorithms to eliminate administrative redexes but did not give any semantic significance to administrative reductions. <p> We refer to the prompt in the first case as the lazy prompt because its subexpression may not be evaluated, and refer to the other prompt as the strict prompt . The classic semantics for control delimiters <ref> [21, 24] </ref> corresponds to the strict prompt. <p> The algorithm is written in Scheme extended with a special form match, which performs pattern matching on the syntax of program terms [105]. It employs a programming technique for CPS algorithms pioneered by Danvy and Filinski <ref> [21] </ref>.
Reference: [22] <author> Danvy, O. and Lawall, J. </author> <title> Back to direct style II: First-class continuations. </title> <booktitle> In Proceedings of the ACM Conference on Lisp and Functional Programming (1992) 299-310. </booktitle>
Reference-contexts: be evaluated [39]. * Despite its functional appearances, CPS code constitutes an (imperative) abstract assembly language whose standard reduction sequence mimics the behav ior of typical target machines [3, 4, 41, 55, 104]. * Data-flow analyzers, partial evaluators, and other tools perform better on CPS programs than on source programs <ref> [22, 33, 34, 72] </ref>. * The CPS transformation is a global transformation that affects every subex-pression in a program. It re-structures programs to the extent that many of their original aspects are unrecognizable. <p> Some of the ideas are closely related to recent work by Danvy, Lawall, and Hatcliff. Danvy and Lawall <ref> [20, 22] </ref> studied the problem of inverting the CPS transformation and produced a "direct style" transformation similar to our transformation C 1 . Danvy and Lawall argue that the "direct style" transformation is useful in its own right and discuss applications in partial evaluation. <p> Second, a binding of a continuation k in the CPS language corresponds to a capture 62 of the continuation k in the source language. Finally, every continuation is explicitly invoked. The last two changes exploit an idea due to Danvy and Lawall <ref> [22] </ref>. 7 The discovery of the call-by-value axioms that correspond to fi-reductions on CPS terms proceeds in the same manner as for the pure language. The resulting axioms consist of the axioms AB for the pure language and control specific axioms. <p> Then, 1. fi ` (C k ffi C 1 )[[P ]][k 1 := (d:k 1 ); : : : ; k n := (d:k n )] = P: 7 Danvy and Lawall <ref> [22] </ref> perform a counting analysis to determine whether a continuation is used in a non-standard way and include a callcc only when necessary. This analysis is unnecessary for our purposes.
Reference: [23] <author> Demers, A. and Donahue, J. </author> <title> Making variables abstract: An equational theory for Russell. </title> <booktitle> In Conference Record of the 10th ACM Symposium on Principles of Programming Languages (1983) 59-72. </booktitle>
Reference-contexts: The axiomatization of the semantics of languages with assignments has been studied extensively <ref> [8, 17, 23, 26, 29, 51, 61, 102] </ref>. Each of the previously proposed logics was designed independently, and differs from the others in subtle ways. Our approach of deriving the calculus from the store-passing axioms is more systematic and generalizes to other languages [88].
Reference: [24] <author> Felleisen, M. </author> <title> The theory and practice of first-class prompts. </title> <booktitle> In Conference Record of the 15th ACM Symposium on Principles of Programming Languages (1988) 180-190. </booktitle>
Reference-contexts: Denotational models for languages with such control operators naturally include elements that delimit control actions [80, 95]. In addition to their theoretical importance, these delimiters present a useful programming paradigm [93, 94]. In this section, we study one traditional control delimiter: # (prompt) <ref> [24] </ref>. Intuitively, in an expression (# M ), the prompt treats its subexpression as a complete program by evaluating it in the initial continuation, forwarding the result to the current continuation. <p> We refer to the prompt in the first case as the lazy prompt because its subexpression may not be evaluated, and refer to the other prompt as the strict prompt . The classic semantics for control delimiters <ref> [21, 24] </ref> corresponds to the strict prompt.
Reference: [25] <author> Felleisen, M. -v-CS: </author> <title> An extended -calculus for Scheme. </title> <booktitle> In Proceedings of the ACM Conference on Lisp and Functional Programming (1988) 72-84. </booktitle>
Reference-contexts: For example, programmers may use the theory to evaluate programs in a symbolic manner <ref> [25] </ref>, to prove the equivalence of two programs, or to simplify a program by a series of meaning-preserving transformations [44].
Reference: [26] <author> Felleisen, M. and Friedman, </author> <title> D.P. A calculus for assignments in higher-order languages. </title> <booktitle> In Conference Record of the 14th ACM Symposium on Principles of Programming Languages (1987) 314-325. </booktitle>
Reference-contexts: The axiomatization of the semantics of languages with assignments has been studied extensively <ref> [8, 17, 23, 26, 29, 51, 61, 102] </ref>. Each of the previously proposed logics was designed independently, and differs from the others in subtle ways. Our approach of deriving the calculus from the store-passing axioms is more systematic and generalizes to other languages [88].
Reference: [27] <author> Felleisen, M. and Friedman, D. P. </author> <title> Control operators, the SECD-machine, and the -calculus. </title> <editor> In Wirsing, M., editor, </editor> <booktitle> Formal Description of Programming Concepts-III, </booktitle> <publisher> North-Holland (1986) 193-217. </publisher>
Reference-contexts: A program is a term with no free variables and, in practical languages, an answer is a member of the syntactic category of values. A common method for specifying the semantics of fl is based on the Curry-Feys standard reduction theorem <ref> [27, 75] </ref>. The standard reduction theorem defines a partial function 7! from programs to programs that corresponds to a single evaluation step of an abstract machine for fl. <p> The special contexts E are evaluation contexts and have the following definition for the call-by-value and call-by-name variants of fl respectively <ref> [27] </ref>: E v ::= [ ] j (V E v ) j (E v M ) Conceptually, the hole of an evaluation context, [ ], points to the current instruction, which must be a fi v or fi redex. <p> and only if eval n ((k:C k [[M ]]) x:x) = [[V ]]: In order to simplify the following discussions (and proofs), we use a CPS transformation that is less compacting than the one in Definition 2.4 but more suited for the remainder of our analysis. 6 Felleisen et al. <ref> [27, 29, 30] </ref> and Talcott [103] use alternative definitions that do not rely on the CPS transformation. 60 Definition 4.1 (C k with Control Operators) Let k; u i 2 Vars be vari ables that do not occur in the argument to C k . <p> The machine we use, the CEK machine <ref> [27] </ref>, has three components: a control string C that represents the current subexpression of interest, an environment E that includes bindings for all free variables in C, and a continuation K that represents the rest of the computation.
Reference: [28] <author> Felleisen, M. and Friedman, D. P. </author> <title> A syntactic theory of sequential state. </title> <journal> Theoretical Computer Science, </journal> <volume> 69, </volume> <month> 3 </month> <year> (1989) </year> <month> 243-287. </month> <title> Preliminary version in: </title> <booktitle> Conference Record of the 14th ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1987. </year>
Reference-contexts: During 95 (define Player-1-Code (let ([Board (make-board )]) (lambda (resume his-first-shot) (letrec ([loop (lambda (his-shot) (if (his-shot-is-fatal? ) (I-lost-the-game) (loop (resume Player-2 (compute-my-shot)))))]) (loop his-first-shot))))) (define Player-1 (make-coroutine Player-1-Code)) the transformation, set! is treated as a free variable. Alternatively, we could use the axioms of the v -S-calculus <ref> [28] </ref> or rewrite the code to use reference cells but this is not necessary for our purposes. (define make-coroutine (lambda (f ) (callcc (lambda (maker ) (let ([LCS 'any]) (let ([resume (lambda (dest val ) (callcc (lambda (k ) (set! LCS k ) (dest val))))]) (f resume (resume maker (lambda (v
Reference: [29] <author> Felleisen, M. and Hieb, R. </author> <title> The revised report on the syntactic theories of sequential control and state. </title> <booktitle> Theoretical Computer Science, </booktitle> <month> 102 </month> <year> (1992) </year> <month> 235-271. </month> <type> Technical Report 89-100, </type> <institution> Rice University. </institution>
Reference-contexts: and only if eval n ((k:C k [[M ]]) x:x) = [[V ]]: In order to simplify the following discussions (and proofs), we use a CPS transformation that is less compacting than the one in Definition 2.4 but more suited for the remainder of our analysis. 6 Felleisen et al. <ref> [27, 29, 30] </ref> and Talcott [103] use alternative definitions that do not rely on the CPS transformation. 60 Definition 4.1 (C k with Control Operators) Let k; u i 2 Vars be vari ables that do not occur in the argument to C k . <p> A)): where the sequencing operation M ; N abbreviates ((d:N ) M ) where d does not occur in the free variables of N . 10 Our approach to dynamic allocation has the advantage of simplicity and abstractness, but relies on the meta-operation of ff-renaming to ensure uniqueness of addresses <ref> [29] </ref>. A more "concrete" allocation mechanism could be defined in any number of ways, but would require more complicated axioms to correctly reflect its internal behavior. 77 ? denotes an unspecified value. In the term (alloc A P ) the location A is bound in P . <p> Axiom lk 2 ensures that store components not containing the looked-up address are preserved. Axiom l lift implements scope extrusion <ref> [29, 66] </ref>; it "lifts" the binding of the location A to permit the evaluation of the application (W P ). <p> (letrec ([LCS (lambda (x ) (f (lambda (dest val ) (callcc (lambda (k ) (set! LCS k ) (dest val)))) x ) (error "fell off end"))]) (lambda (v ) (LCS v ))))) 101 4.5 Related Work The axiomatization of the semantics of call-by-value control operators was originally studied by Felleisen <ref> [29, 30] </ref> and Talcott [103]. Our axioms extend Felleisen's v -C-calculus and are equivalent to Talcott's theory IOCC (when restricted to our language). <p> The axiomatization of the semantics of languages with assignments has been studied extensively <ref> [8, 17, 23, 26, 29, 51, 61, 102] </ref>. Each of the previously proposed logics was designed independently, and differs from the others in subtle ways. Our approach of deriving the calculus from the store-passing axioms is more systematic and generalizes to other languages [88]. <p> Our approach of deriving the calculus from the store-passing axioms is more systematic and generalizes to other languages [88]. Also, when compared to other systems, our calculus has several distinguishing features. First, in contrast with calculi derived from abstract machines for the imperative source language <ref> [17, 29, 61] </ref>, our equational theory never eliminates an expression of the form (setref! V 1 V 2 ). These expressions simply migrate from point to point within the program to allow lookup operations. In the other calculi [17, 29, 61], there is typically a distinguished position in the program text <p> contrast with calculi derived from abstract machines for the imperative source language <ref> [17, 29, 61] </ref>, our equational theory never eliminates an expression of the form (setref! V 1 V 2 ). These expressions simply migrate from point to point within the program to allow lookup operations. In the other calculi [17, 29, 61], there is typically a distinguished position in the program text that contains the most recent value associated with a particular location: setref! expressions modify this current value and lookup operations copy this current value.
Reference: [30] <author> Felleisen, M., Friedman, D. P., Kohlbecker, E., and Duba, B. </author> <title> A syntactic theory of sequential control. </title> <journal> Theoretical Computer Science, </journal> <volume> 52, </volume> <month> 3 </month> <year> (1987) </year> <month> 205-237. </month> <title> Preliminary version: Reasoning with Continuations, </title> <booktitle> in Proceedings of the 1st IEEE Symposium on Logic in Computer Science, </booktitle> <year> 1986. </year>
Reference-contexts: and only if eval n ((k:C k [[M ]]) x:x) = [[V ]]: In order to simplify the following discussions (and proofs), we use a CPS transformation that is less compacting than the one in Definition 2.4 but more suited for the remainder of our analysis. 6 Felleisen et al. <ref> [27, 29, 30] </ref> and Talcott [103] use alternative definitions that do not rely on the CPS transformation. 60 Definition 4.1 (C k with Control Operators) Let k; u i 2 Vars be vari ables that do not occur in the argument to C k . <p> (letrec ([LCS (lambda (x ) (f (lambda (dest val ) (callcc (lambda (k ) (set! LCS k ) (dest val)))) x ) (error "fell off end"))]) (lambda (v ) (LCS v ))))) 101 4.5 Related Work The axiomatization of the semantics of call-by-value control operators was originally studied by Felleisen <ref> [29, 30] </ref> and Talcott [103]. Our axioms extend Felleisen's v -C-calculus and are equivalent to Talcott's theory IOCC (when restricted to our language).
Reference: [31] <author> Fessenden, C., Clinger, W., Friedman, D. P., and Haynes, C. T. </author> <note> Scheme 311 Version 4 Reference Manual. Computer Science Technical Report 137, Indiana University, Bloomington, Indiana (February 1983). 151 </note>
Reference-contexts: The partial function ffi abstracts the semantics of the primitive operations. The CEK machine provides a model for designing direct compilers <ref> [11, 31, 59] </ref>. A compiler based on the CEK machine implements an efficient representation for environments, e.g., displays, and for continuations, e.g., a stack.
Reference: [32] <author> Field, J. </author> <title> A simple rewriting semantics for realistic imperative programs and its application to program analysis (preliminary report). In ACM Sigplan Workshop on Partial Evaluation and Semantics-Based Program Manipulation, </title> <type> Technical Report RR-909, </type> <institution> Yale University (1992) 98-107. </institution>
Reference-contexts: For example, we can extend the axioms for the imperative fragments to include equations that axiomatize the store data-type. This is the approach taken in the logic Pim <ref> [32] </ref>, and we consider a few similar extensions here.
Reference: [33] <author> Filho, J. Muylaert. </author> <title> Improving abstract interpretations with CPS-translation. (1993). </title> <type> Unpublished Manuscript. </type>
Reference-contexts: be evaluated [39]. * Despite its functional appearances, CPS code constitutes an (imperative) abstract assembly language whose standard reduction sequence mimics the behav ior of typical target machines [3, 4, 41, 55, 104]. * Data-flow analyzers, partial evaluators, and other tools perform better on CPS programs than on source programs <ref> [22, 33, 34, 72] </ref>. * The CPS transformation is a global transformation that affects every subex-pression in a program. It re-structures programs to the extent that many of their original aspects are unrecognizable. <p> The literature generally supports the idea that CPS improves the precision of data flow analysis <ref> [10, 15, 33, 34, 58, 92] </ref>. <p> The literature generally supports the idea that CPS improves the precision of data flow analysis [10, 15, 33, 34, 58, 92]. Although much of the evidence is informal, investigations by Nielson [72] and Burn/Filho <ref> [33, 34] </ref> support, to some degree, the idea with formal results. 16 However, their results do not pinpoint the source of increased abstract information and do not explain the observation of many people that continuation-passing confuses some conventional data flow analyses. Prompted by conversations with G.
Reference: [34] <author> Filho, J. Muylaert and Burn, G. </author> <title> Continuation passing transformation and abstract interpretation. </title> <editor> In Burn, G., Gay, S., and Ryan, M., editors, </editor> <booktitle> Proceedings of the First Imperial College, Department of Computing, Workshop on Theory and Formal Methods (1993). </booktitle>
Reference-contexts: be evaluated [39]. * Despite its functional appearances, CPS code constitutes an (imperative) abstract assembly language whose standard reduction sequence mimics the behav ior of typical target machines [3, 4, 41, 55, 104]. * Data-flow analyzers, partial evaluators, and other tools perform better on CPS programs than on source programs <ref> [22, 33, 34, 72] </ref>. * The CPS transformation is a global transformation that affects every subex-pression in a program. It re-structures programs to the extent that many of their original aspects are unrecognizable. <p> The literature generally supports the idea that CPS improves the precision of data flow analysis <ref> [10, 15, 33, 34, 58, 92] </ref>. <p> The literature generally supports the idea that CPS improves the precision of data flow analysis [10, 15, 33, 34, 58, 92]. Although much of the evidence is informal, investigations by Nielson [72] and Burn/Filho <ref> [33, 34] </ref> support, to some degree, the idea with formal results. 16 However, their results do not pinpoint the source of increased abstract information and do not explain the observation of many people that continuation-passing confuses some conventional data flow analyses. Prompted by conversations with G. <p> Nielson [72] proved that, for a small imperative language, the semantic-CPS analysis computes the MOP (meet over all paths) solution and the direct analysis computes the less precise MFP (maximum fixed point) solution; Filho and Burn <ref> [34] </ref> improved the abstract interpretations of typed call-by-name languages using the CPS transformation. Our result suggests that the gain in all cases is entirely due to the duplication of the analysis of the continuation along different execution paths.
Reference: [35] <author> Filinski, A. </author> <title> Representing monads. </title> <booktitle> In Conference Record of the 21th ACM Symposium on Principles of Programming Languages (1994) 446-457. </booktitle>
Reference-contexts: Theorem 3.15 (Correspondence (Reformulation)) The theory c equationally corresponds to the theory fi (relative to the languages fl and cps (fl), and the translations C k and C 1 ). 50 As also noted by Filinski <ref> [35, 36] </ref>, the correspondence between Moggi's computational -calculus (a generic calculus for computational effects) and the calculus fi v AB (a calculus derived from the CPS transformation) is but one aspect of a deeper correspondence between continuations and other computational effects.
Reference: [36] <author> Filinski, A. </author> <note> Representing monads (revised version). (1994). In preparation. </note>
Reference-contexts: Theorem 3.15 (Correspondence (Reformulation)) The theory c equationally corresponds to the theory fi (relative to the languages fl and cps (fl), and the translations C k and C 1 ). 50 As also noted by Filinski <ref> [35, 36] </ref>, the correspondence between Moggi's computational -calculus (a generic calculus for computational effects) and the calculus fi v AB (a calculus derived from the CPS transformation) is but one aspect of a deeper correspondence between continuations and other computational effects.
Reference: [37] <author> Fischer, M. </author> <title> Lambda calculus schemata. </title> <booktitle> In Proceedings of the ACM Conference on Proving Assertions About Programs, Sigplan Notices, </booktitle> <volume> 7, </volume> <month> 1 </month> <year> (1972) </year> <month> 104-109. </month> <note> Revised version in Lisp and Symbolic Computation, 6, 3/4, </note> <year> (1993) </year> <month> 259-287. </month>
Reference-contexts: program anal ysis tools [3, 15, 39, 55, 56, 58, 82, 92, 97]; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation <ref> [5, 37] </ref>; * it embeds classical logic into constructive logic [46, 70, 71]. <p> The first section presents our personal perspective on the discovery of the concept of CPS transformations. For a different and more extensive historical perspective, we refer the reader to Reynolds's survey [79]. In the second section, we apply the original CPS transformation (due to Fischer <ref> [37] </ref>, Morris [69], and Strachey and Wadsworth [101]) to a pure call-by-value language. We also discuss Plotkin's analysis of the properties of this transformation [75]. Finally, we include a series of CPS transformations from the literature that represent various practical and theoretical improvements of the original formulation. <p> Independently, Fischer used the same idea to implement languages with higher-order procedures such as Lisp, Scheme, and ML <ref> [37] </ref>. In such languages, a variable bound in an inner block (or procedure) may be referenced from outside. <p> end), no deletion takes place! Thus, : : : instead of g passing its result back to the caller, the caller is passed 14 to g as an additional argument. g then applies the new argument to the result it used to return, thereby avoiding the necessity of returning immediately <ref> [37, p 107] </ref>. <p> Based on this intuitive idea, Fischer proves that all programs can be mapped to a restricted subset of the original language that can be evaluated using a stack-based strategy <ref> [37] </ref>. 1 In summary, transforming program fragments so that they manipulate their continuation explicitly enables both an implementation of procedure calls as jumps and a stack-based implementation strategy of languages with higher-order procedures. 2.1.2 Goto as Procedure Call The idea of defining the semantics of programming languages mathematically was proposed by <p> In summary, the explicit manipulation of the continuation enables a mathematical theory based on functions to explain both sequencing and jumps uniformly as function applications. 1 In practice however, the resulting stack must be treated like a garbage-collected heap since it is never popped during the execution of the program <ref> [5, 37] </ref>. 15 2.1.3 Continuations and Transfers of Control Although the transformations described in the two previous subsections appear to have dual effects, they are in fact identical transformations. <p> This ability to shift perspective from a high-level functional view to a low-level machine view and vice-versa is perhaps the most appealing aspect of CPS programs. 2 2.2 The Original CPS Transformation The original formulation of the CPS transformation is due to Fischer <ref> [37] </ref>, Morris [69], and Strachey and Wadsworth [101]. We first illustrate the transformation of a pure (without constants) higher-order call-by-value language. <p> It is trivial to rewrite the CPS transformation to encode a right-to-left evaluation order: F [[M N ]] = k:(F [[N ]] (n:(F [[M ]] m:((m k) n)))): The main formal properties of the original CPS transformation were established by Fischer <ref> [37] </ref>, Reynolds [77], and Plotkin [75]. The following theorem summarizes these main properties. Theorem 2.1 (Plotkin [75]) Let M 2 fl.
Reference: [38] <author> Flanagan, C., Sabry, A., Duba, B. F., and Felleisen, M. </author> <title> The essence of compiling with continuations. </title> <booktitle> In Proceedings of the ACM Sigplan Conference on Programming Language Design and Implementation (1993) 237-247. </booktitle>
Reference-contexts: We conclude with a summary of the benefits of using A-normal form terms as an intermediate representation for compilers. Most of the results in this chapter appeared in a paper presented at the Conference on Programming Language Design and Implementation <ref> [38] </ref>. 5.1 Direct Abstract Machine For the purposes of this chapter, it is sufficient to consider a restriction of Core Scheme that excludes assignments and, for most of the time, control operators. <p> the language cps (fl): P ::= (k W ) j (let (x W ) P ) j (W W (x:P )) j (let (k x:P ) (if0 W P P )) The semantics of CPS programs is defined by M c , a specialized version of the direct interpreter M <ref> [38] </ref>. The evaluator for CPS terms (see Figure 6.5) handles procedures of two arguments and manipulates a larger set of run-time values than the direct interpreter that includes continuations of the form hco x; P; i.
Reference: [39] <author> Fradet, P. and Metayer, D. Le. </author> <title> Compilation of functional languages by program transformation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13, </volume> <month> 1 (January </month> <year> 1991) </year> <month> 21-51. </month>
Reference-contexts: Abstract Collecting Interpreter (II) : : : : : : : : : : : 136 1 Chapter 1 Background and Motivation The continuation-passing style (CPS) transformation is ubiquitous in the area of programming language semantics: * it defines the intermediate representation of many compilers and program anal ysis tools <ref> [3, 15, 39, 55, 56, 58, 82, 92, 97] </ref>; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds <p> - calculus) proves more equations, hence more optimizations, than the canonical equational theory for the call-by-value source language [75]. * The CPS transformation systematically introduces names for every intermediate computation and re-orders the subexpressions of a program in a way that reflects the order in which they should be evaluated <ref> [39] </ref>. * Despite its functional appearances, CPS code constitutes an (imperative) abstract assembly language whose standard reduction sequence mimics the behav ior of typical target machines [3, 4, 41, 55, 104]. * Data-flow analyzers, partial evaluators, and other tools perform better on CPS programs than on source programs [22, 33, 34,
Reference: [40] <author> Friedman, D. P., Haynes, C.T., and Kohlbecker, E. </author> <title> Programming with continuations. </title> <editor> In Pepper, P., editor, </editor> <title> Program Transformations and Programming Environments, </title> <publisher> Springer-Verlag (1985) 263-274. </publisher>
Reference-contexts: These operators suffice to express a wide variety of control abstractions such as error exits, jumps, backtracking, coroutines, and exception handling <ref> [40, 49] </ref>. The last two sections extend the discussion to include control delimiters as well.
Reference: [41] <author> Friedman, D. P., Wand, M., and Haynes, </author> <title> C.T. Essentials of Programming Languages. </title> <publisher> The MIT Press (1992). </publisher>
Reference-contexts: for every intermediate computation and re-orders the subexpressions of a program in a way that reflects the order in which they should be evaluated [39]. * Despite its functional appearances, CPS code constitutes an (imperative) abstract assembly language whose standard reduction sequence mimics the behav ior of typical target machines <ref> [3, 4, 41, 55, 104] </ref>. * Data-flow analyzers, partial evaluators, and other tools perform better on CPS programs than on source programs [22, 33, 34, 72]. * The CPS transformation is a global transformation that affects every subex-pression in a program. <p> C k . 4 C k : fl ! fl C k [[E [(x V )]]] = ((x K k [[E]]) [[V ]]) : Values (fl) ! fl [[x]] = x 4 The CPS transformation C k is, in spirit, similar to the CPS transformation by Friedman, Wand, and Haynes <ref> [41, ch 8] </ref>, but differs significantly in its formal part. 22 K k : EvCont (fl) ! fl K k [[[ ]]] = k K k [[E [((x:M ) [ ])]]] = (x:C k [[E [M ]]]) The transformation of a complete program M is ((k:C k [[M ]]) (a:a)).
Reference: [42] <author> Friedman, H. </author> <title> Equality between functionals. </title> <editor> In Parikh, R., editor, </editor> <booktitle> Logic Colloquium, </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin (1973) 22-37. </address> <month> 152 </month>
Reference-contexts: The result explained below follows from the soundness and completeness of the simply typed -calculus with respect to the full type structure <ref> [42] </ref>. <p> The result explained below follows from the soundness and completeness of the simply typed -calculus with respect to the full type structure [42]. In the conventional semantics for fl t <ref> [42, 47] </ref>, each type denotes a set of elements: the base type o denotes some arbitrary infinite set B, and the type t 1 ! t 2 denotes the set of functions from the denotations of t 1 to the denotations of t 2 . <p> The notation P B j= M = N means that for all environments , P [[M]] = P [[N ]]. Based on this definition, we can formulate the completeness theorem. Theorem 3.18 (Friedman <ref> [42] </ref>) Let M; N be simply typed terms in fl. Then, fi ` M = N if and only if P B j= M = N .
Reference: [43] <author> G. D. Plotkin, G.D. </author> <title> LCF considered as a programming language. </title> <booktitle> Theoretical Computer Science, </booktitle> <month> 5 </month> <year> (1977) </year> <month> 223-255. </month>
Reference-contexts: The canonical set of contexts is the set of PCF-contexts that includes numerals, an increment procedure add1, a decrement procedure sub1, conditionals, and a recursion operator <ref> [43] </ref>. Observational equivalence of call-by-name simply typed terms relative to PCF-contexts is decidable and axiomatized by the axioms fi. Theorem 1.2 (Meyer [81]) Let M and N be simply typed terms in fl, then fi ` M = N if and only if M ~ = PCF n N .
Reference: [44] <author> Galbiati, L. and Talcott, C. L. </author> <title> A simplifier for untyped lambda expressions. </title> <booktitle> In Proceedings Conditional Term Rewriting Systems, Lecture Notes in Computer Science, </booktitle> <month> 516 </month> <year> (1990) </year> <month> 342-353. </month>
Reference-contexts: For example, programmers may use the theory to evaluate programs in a symbolic manner [25], to prove the equivalence of two programs, or to simplify a program by a series of meaning-preserving transformations <ref> [44] </ref>.
Reference: [45] <author> Gateley, J. and Duba, </author> <title> B.F. Call-by-value combinatory logic and the lambda-value calculus. </title> <editor> In Brookes, S., editor, </editor> <booktitle> Proceedings of the Conference on the Mathematical Foundations of Programing Semantics, Lecture Notes in Computer Science, </booktitle> <volume> 517, </volume> <publisher> Springer Verlag (1991). </publisher>
Reference-contexts: In the next section, we will add a sound and restricted version of v that applies only to functional constants <ref> [45] </ref>. 4.3.1 The CPS Language: cps (CS ) Given our extensions to the source language, the CPS language cannot be a subset of fl unless the CPS transformation encodes all new constructs in the source language using procedures.
Reference: [46] <author> Griffin, T.G. </author> <title> A formulae-as-types notion of control. </title> <booktitle> In Conference Record of the 17th ACM Symposium on Principles of Programming Languages (1990) 47-58. </booktitle>
Reference-contexts: 82, 92, 97]; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds classical logic into constructive logic <ref> [46, 70, 71] </ref>. <p> Theorem 4.9 Let M; N 2 fl t c , then fi v ABCC # ` M = N if and only if the CPS continuous type frame satisfies M = N. 8 This theorem provides an alternative proof for Griffin's <ref> [46] </ref> weak normalization theorem for the v -C-calculus.
Reference: [47] <editor> Gunter, Carl A. </editor> <booktitle> Semantics of Programming Languages. Foundations of Computing, </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA (1992). </address>
Reference-contexts: The result explained below follows from the soundness and completeness of the simply typed -calculus with respect to the full type structure [42]. In the conventional semantics for fl t <ref> [42, 47] </ref>, each type denotes a set of elements: the base type o denotes some arbitrary infinite set B, and the type t 1 ! t 2 denotes the set of functions from the denotations of t 1 to the denotations of t 2 .
Reference: [48] <author> Hatcliff, J. and Danvy, O. </author> <title> A generic account of continuation-passing styles. </title> <booktitle> In Conference Record of the 21th ACM Symposium on Principles of Programming Languages (1994). </booktitle>
Reference-contexts: Their staging is similar to ours; their first two stages essentially perform an A-normalization as explained in Section 3.1. Finally, Danvy and Hatcliff <ref> [48] </ref> extended our correspondence theorems to languages with other evaluation strategies, e.g., call-by-name. 3.8 Summary We have identified the call-by-value reductions that can prove any equation that fi-reductions can prove on CPS terms.
Reference: [49] <author> Haynes, C.T., Friedman, D. P., and Wand, M. </author> <title> Obtaining coroutines from continuations. </title> <journal> Journal of Computer Languages (Pergamon Press), </journal> <volume> 11, </volume> <month> 3/4 </month> <year> (1986) </year> <month> 143-153. </month>
Reference-contexts: These operators suffice to express a wide variety of control abstractions such as error exits, jumps, backtracking, coroutines, and exception handling <ref> [40, 49] </ref>. The last two sections extend the discussion to include control delimiters as well. <p> = ((x:N ) M ) (begin M N) df = ((d:N ) M ) where d 62 F V (N ) (x:M N) = (x:(begin M N )) (letrec ([x (y:M )]) N) df (begin (set! x (y:M )) N )) The original definition of coroutines using first-class continuations is <ref> [49] </ref>: (define make-coroutine (lambda (f ) (callcc (lambda (maker ) (let ([LCS 'any]) (let ([resume (lambda (dest val) (callcc (lambda (k ) (set! LCS k ) (dest val ))))]) (f resume (resume maker (lambda (v ) (LCS v)))) (error "fell off end"))))))) Intuitively, the procedure make-coroutine accepts an argument that contains
Reference: [50] <author> Hieb, R., Dybvig, K., and Bruggeman, C. </author> <title> Representing control in the presence of first-class continuations. </title> <booktitle> In Proceedings of the ACM Sigplan Conference on Programming Language Design and Implementation (1990) 66-77. </booktitle>
Reference-contexts: Indeed many state-of-the-art compilers for applicative higher-order programming languages (Scheme, ML, Lisp, etc) use a CPS intermediate representation [3, 56, 82], and many others do not <ref> [7, 9, 12, 50, 59] </ref>.
Reference: [51] <author> Hoare, C., Hayes, I., Jifeng, H., Morgan, C., Roscoe, A., Sanders, J., Sorensen, I., Spivey, J., and Sufrin, B. </author> <title> Laws of programming. </title> <journal> Communications of the ACM, </journal> <volume> 30, </volume> <month> 8 </month> <year> (1987) </year> <month> 672-686. </month>
Reference-contexts: The axiomatization of the semantics of languages with assignments has been studied extensively <ref> [8, 17, 23, 26, 29, 51, 61, 102] </ref>. Each of the previously proposed logics was designed independently, and differs from the others in subtle ways. Our approach of deriving the calculus from the store-passing axioms is more systematic and generalizes to other languages [88].
Reference: [52] <author> Hofmann, M. </author> <title> Sound and complete axiomatisations of call-by-value control operators. </title> <booktitle> In Proceedings of the 5th Conference on Category Theory and Computer Science (1993). To Appear. </booktitle> <pages> 153 </pages>
Reference-contexts: Our axioms extend Felleisen's v -C-calculus and are equivalent to Talcott's theory IOCC (when restricted to our language). Our axiomatization is also the first to be shown complete with respect to the CPS semantics; it was the main technical contribution of our extended journal paper [85]. Independently, Hofmann <ref> [52] </ref> developed a complete axiomatization of the semantics of call-by-value control operators with respect to CPS semantics; his proof technique is different from ours but the resulting set of axioms is the same (modulo some syntactic differences).
Reference: [53] <author> Hudak, P. and Young, J. </author> <title> Collecting interpretations of expressions. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13, </volume> <month> 2 (April </month> <year> 1991) </year> <month> 269-290. </month>
Reference-contexts: Intuitively, the first phase of A-normalization gives every subexpression a name to which the data flow analyzer can associate information about the expression. Without A-normalization, the analyzer would typically associate a "label" with every expression and attach the information about each expression at the corresponding label <ref> [53, 72, 92] </ref>. The two treatments are identical but the elimination of a separate notion of labels simplifies the analyzers. The second phase of A-normalization re-orders the expressions to reflect the order in which the interpreters will traverse them. <p> possible to recover x, i.e., new (x; s) = ` 62 dom (s) and x = new 1 (`). (For brevity, we will usually omit the second argument to new since it is easy to reconstruct from the context.) 122 Based on well-known ideas from the area of abstract interpretation <ref> [16, 53, 72, 92] </ref>, we derive a data flow analyzer from the previous interpreter. The first step in the derivation is to associate one location with each variable that holds the set of all values to which the variable is bound during the evaluation of the program.
Reference: [54] <author> Kam, J.B. and Ullman, J. D. </author> <title> Monotone data flow analysis frameworks. </title> <journal> Acta Informatica, </journal> <month> 7 </month> <year> (1977) </year> <month> 305-317. </month>
Reference-contexts: The problem is that the lattice of collected values contains infinite chains of elements of decreasing precision, e.g., ; f0g f0; 1g f0; 1; 2g : : :. Since these infinite chains may cause divergence, we need to approximate sets of numbers to abstract numbers <ref> [54] </ref>: ; = ?; fng = n; and fn 1 ; n 2 ; : : :g = &gt; n 1 6= n 2 : At this point, the universe of abstract values consists of abstract numbers and abstract closures. <p> We organize the abstract values in a lattice that is the product of two lattices: the first is the traditional lattice N &gt; ? used for constant propagation <ref> [54] </ref>, and the second is the power set of abstract closures relative to the given program (ordered by the subset relation) used to approximate the control flow [92]. The ordering relation v, as well as the least upper bound operation t, of the lattice of abstract values are defined component-wise. <p> , A i , and n: G A i i appr A f if and only if h; A 1 i appr B 1 : : : h; A n i appr B n and A f = i=1;n When the Distributivity condition does not hold, e.g., for constant propagation <ref> [54, 60] </ref>, the semantic-CPS data flow analyzer may gain information by duplicating the continuation along every execution path as in the right hand side of the condition. Otherwise, the semantic-CPS analysis is identical to the direct analysis of the program. <p> In the semantic-CPS case, the computation of i=0;1 B i is undecidable. The proof is an adaptation of Kam and Ullman's <ref> [54] </ref> that, given an arbitrary monotone framework, it is undecidable to compute the MOP solution for each program: Given a Turing machine H, we construct the continuation such that: h; hhn; ;i; ii appr hhn 0 ; ;i; i where: * n 0 = n if n is ? or &gt;,
Reference: [55] <author> Kelsey, R. and Hudak, P. </author> <title> Realistic compilation by program transformation. </title> <booktitle> In Conference Record of the 16th ACM Symposium on Principles of Programming Languages (1989) 281-292. </booktitle>
Reference-contexts: Abstract Collecting Interpreter (II) : : : : : : : : : : : 136 1 Chapter 1 Background and Motivation The continuation-passing style (CPS) transformation is ubiquitous in the area of programming language semantics: * it defines the intermediate representation of many compilers and program anal ysis tools <ref> [3, 15, 39, 55, 56, 58, 82, 92, 97] </ref>; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds <p> for every intermediate computation and re-orders the subexpressions of a program in a way that reflects the order in which they should be evaluated [39]. * Despite its functional appearances, CPS code constitutes an (imperative) abstract assembly language whose standard reduction sequence mimics the behav ior of typical target machines <ref> [3, 4, 41, 55, 104] </ref>. * Data-flow analyzers, partial evaluators, and other tools perform better on CPS programs than on source programs [22, 33, 34, 72]. * The CPS transformation is a global transformation that affects every subex-pression in a program.
Reference: [56] <author> Kranz, D., Kelsey, R., Rees, J., Hudak, P., Philbin, J., and Adams, N. </author> <title> Orbit: An optimizing compiler for Scheme. </title> <booktitle> In Proceedings of the ACM Sigplan Symposium on Compiler Construction, Sigplan Notices, </booktitle> <volume> 21, </volume> <month> 7 </month> <year> (1986) </year> <month> 219-233. </month>
Reference-contexts: Abstract Collecting Interpreter (II) : : : : : : : : : : : 136 1 Chapter 1 Background and Motivation The continuation-passing style (CPS) transformation is ubiquitous in the area of programming language semantics: * it defines the intermediate representation of many compilers and program anal ysis tools <ref> [3, 15, 39, 55, 56, 58, 82, 92, 97] </ref>; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds <p> Indeed many state-of-the-art compilers for applicative higher-order programming languages (Scheme, ML, Lisp, etc) use a CPS intermediate representation <ref> [3, 56, 82] </ref>, and many others do not [7, 9, 12, 50, 59]. <p> The CPS intermediate language used in realistic CPS compilers <ref> [3, 56, 97] </ref> corresponds to the output of our compacting CPS transformation. <p> Yet, realistic CPS compilers "mark" the continuation closure as a special closure. For example, Shivers partitions procedures and continuations in order to improve the data flow analysis of CPS programs [92, sec 3.8.3]. Also, in both Orbit <ref> [56] </ref> and Rabbit [97], the allocation strategy of a closure changes if the closure is a continuation. Similarly, Appel [3, p 114-124] describes various techniques for closure allocation that treat the continuation closure in a special way. <p> However, realistic CPS compilers deviate from the theoretical CPS abstract machine and interpret this intermediate code on a more specialized machine: * Orbit <ref> [56] </ref> essentially ignores the operator callcc "because the runtime system ensures that any continuation which is captured by call-with-current-con tinuation will be migrated dynamically to the heap" [56, p. 227]. * SML-NJ [3] ensures that the current continuation is always accessible in a register. <p> However, realistic CPS compilers deviate from the theoretical CPS abstract machine and interpret this intermediate code on a more specialized machine: * Orbit [56] essentially ignores the operator callcc "because the runtime system ensures that any continuation which is captured by call-with-current-con tinuation will be migrated dynamically to the heap" <ref> [56, p. 227] </ref>. * SML-NJ [3] ensures that the current continuation is always accessible in a register. In the absence of control operators, the variable k in the expression (k W ) always refers to the current continuation and is therefore useless.
Reference: [57] <author> Lawall, J. and Danvy, O. </author> <title> Separating stages in the continuation-passing transform. </title> <booktitle> In Conference Record of the 20th ACM Symposium on Principles of Programming Languages (1993) 124-136. </booktitle>
Reference-contexts: Their analysis did not however address the interactions among the CPS transformation, its inverse, reductions on call-by-value terms, and reductions on CPS terms. 57 In subsequent work, Danvy and Lawall <ref> [19, 57] </ref> recognize that the CPS transformation can be "staged" in a number of independent steps. Their staging is similar to ours; their first two stages essentially perform an A-normalization as explained in Section 3.1.
Reference: [58] <author> Lawall, J. and Danvy, O. </author> <title> Continuation-based partial evaluation. </title> <booktitle> In Proceedings of the ACM Conference on Lisp and Functional Programming (1994). To Appear. </booktitle>
Reference-contexts: Abstract Collecting Interpreter (II) : : : : : : : : : : : 136 1 Chapter 1 Background and Motivation The continuation-passing style (CPS) transformation is ubiquitous in the area of programming language semantics: * it defines the intermediate representation of many compilers and program anal ysis tools <ref> [3, 15, 39, 55, 56, 58, 82, 92, 97] </ref>; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds <p> The literature generally supports the idea that CPS improves the precision of data flow analysis <ref> [10, 15, 33, 34, 58, 92] </ref>.
Reference: [59] <author> Leroy, X. </author> <title> The Zinc Experiment: An Economical Implementation of the ML Language. </title> <type> Technical Report 117, </type> <note> INRIA (1990). </note>
Reference-contexts: Indeed many state-of-the-art compilers for applicative higher-order programming languages (Scheme, ML, Lisp, etc) use a CPS intermediate representation [3, 56, 82], and many others do not <ref> [7, 9, 12, 50, 59] </ref>. <p> The partial function ffi abstracts the semantics of the primitive operations. The CEK machine provides a model for designing direct compilers <ref> [11, 31, 59] </ref>. A compiler based on the CEK machine implements an efficient representation for environments, e.g., displays, and for continuations, e.g., a stack. <p> It is therefore natural to modify such compilers to perform a complete A-normalization phase, and analyze the effects. We have conducted such an experiment with the non-optimizing, direct compiler CAML Light <ref> [59] </ref>. 15 This compiler translates ML programs into byte-code via a -calculus based intermediate language, and then interprets this byte-code.
Reference: [60] <author> Marlowe, T.J. and Ryder, B.G. </author> <title> Properties of data flow frameworks: A unified model. </title> <note> Acta Informatica (1990). </note>
Reference-contexts: , A i , and n: G A i i appr A f if and only if h; A 1 i appr B 1 : : : h; A n i appr B n and A f = i=1;n When the Distributivity condition does not hold, e.g., for constant propagation <ref> [54, 60] </ref>, the semantic-CPS data flow analyzer may gain information by duplicating the continuation along every execution path as in the right hand side of the condition. Otherwise, the semantic-CPS analysis is identical to the direct analysis of the program.
Reference: [61] <author> Mason, I. and Talcott, C. L. </author> <title> Equivalence in functional languages with effects. </title> <journal> Journal of Functional Programming, </journal> <volume> 1, </volume> <month> 3 (July </month> <year> 1991) </year> <month> 287-327. </month>
Reference-contexts: The axiomatization of the semantics of languages with assignments has been studied extensively <ref> [8, 17, 23, 26, 29, 51, 61, 102] </ref>. Each of the previously proposed logics was designed independently, and differs from the others in subtle ways. Our approach of deriving the calculus from the store-passing axioms is more systematic and generalizes to other languages [88]. <p> Our approach of deriving the calculus from the store-passing axioms is more systematic and generalizes to other languages [88]. Also, when compared to other systems, our calculus has several distinguishing features. First, in contrast with calculi derived from abstract machines for the imperative source language <ref> [17, 29, 61] </ref>, our equational theory never eliminates an expression of the form (setref! V 1 V 2 ). These expressions simply migrate from point to point within the program to allow lookup operations. In the other calculi [17, 29, 61], there is typically a distinguished position in the program text <p> contrast with calculi derived from abstract machines for the imperative source language <ref> [17, 29, 61] </ref>, our equational theory never eliminates an expression of the form (setref! V 1 V 2 ). These expressions simply migrate from point to point within the program to allow lookup operations. In the other calculi [17, 29, 61], there is typically a distinguished position in the program text that contains the most recent value associated with a particular location: setref! expressions modify this current value and lookup operations copy this current value.
Reference: [62] <author> Mason, I.A. and Talcott, C. L. </author> <title> Inferring the equivalence of functional programs that mutate data. </title> <journal> Theoretical Computer Science, </journal> <volume> 105, </volume> <month> 2 </month> <year> (1992) </year> <month> 167-215. </month> <note> Preliminary version in Proceedings of the 4th IEEE Symposium on Logic in Computer Science 1989. </note>
Reference-contexts: We choose the following common representation <ref> [8, 62, 73] </ref>.
Reference: [63] <author> Mazurkiewicz, A.W. </author> <title> Proving algorithms by tail functions. </title> <journal> Information and Control, </journal> <volume> 18 (1971) 220-226. </volume> <pages> 154 </pages>
Reference-contexts: Since continuations were conceived to explain sophisticated control operators <ref> [63, 69, 77, 101] </ref>, we begin by extending the theorems to languages with such constructs. In the next section, we axiomatize the semantics of a language with assignments using the store-passing transformation.
Reference: [64] <author> Meyer, A. and Riecke, J. </author> <title> Continuations may be unreasonable. </title> <booktitle> In Proceedings of the ACM Conference on Lisp and Functional Programming (1988) 63-71. </booktitle>
Reference-contexts: Since D includes a sub-term (k:m:(m x:x)) that ignores its continuation, there is no context C 2 fl such that C k [[C [M ]]] = D [C k [[M]]]. This result prompted Meyer and Riecke <ref> [64] </ref> to deduce that "continuations may be unreasonable." However, a restriction of D to range over contexts in the language cps (fl) results in a notion of observational equivalence that coincides with the call-by-value observational equivalence. Theorem 3.24 Let M; N 2 fl.
Reference: [65] <author> Meyer, A. R. and Wand, M. </author> <title> Continuation semantics in typed lambda-calculi. </title> <booktitle> In Proceedings Workshop Logics of Programs, Lecture Notes in Computer Science, </booktitle> <month> 193 </month> <year> (1985) </year> <month> 219-224. </month>
Reference-contexts: between the original programs and their CPS transforms specializes to a problem of independent interest, e.g., relating source programs to their intermediate representation in a CPS compiler, relating direct compilers to CPS compilers, relating classical proofs to constructive proofs, and relating denotations in direct semantics to denotations in continuation semantics <ref> [65, 78, 91, 98] </ref>. Some of the above problems have been thoroughly studied in the literature, but the precise role of the CPS transformation in the compilation process is still not completely understood. <p> which we can assign simple types as follows: M ::= x t j (M s!t N s ) t j (x s :M t ) s!t The CPS transformation on simply typed terms can be factored into a CPS transformation on types and a CPS transformation on raw (untyped) terms <ref> [65] </ref>.
Reference: [66] <author> Milner, R. </author> <title> Functions as processes. </title> <booktitle> Mathematical Structures in Computer Science, </booktitle> <month> 2 </month> <year> (1992) </year> <month> 119-141. </month>
Reference-contexts: Axiom lk 2 ensures that store components not containing the looked-up address are preserved. Axiom l lift implements scope extrusion <ref> [29, 66] </ref>; it "lifts" the binding of the location A to permit the evaluation of the application (W P ).
Reference: [67] <author> Moggi, E. </author> <title> Computational lambda-calculus and monads. </title> <note> In Proceedings of the 4th IEEE Symposium on Logic in Computer Science (1989) 14-23. Also appeared as: </note> <institution> LFCS Report ECS-LFCS-88-86, University of Edinburgh, </institution> <year> 1988. </year>
Reference-contexts: First, the calculus fi is a canonical and complete system of reasoning about functions in a call-by-name language. Second, our newly developed calculus turns out to be equivalent to Moggi's computational - calculus, which is a generic calculus for reasoning about programs with computational effects <ref> [67, 68] </ref>. Our correspondence theorem relates these two canonical calculi and hints at deeper connections between continuations and other computational effects. In the first subsection, we outline the equivalence of the calculus fi v AB and Moggi's computational -calculus. <p> Finally, we discuss the relationship of our calculus to the call-by-value observational equivalence relation. 3.6.1 Moggi's Computational Lambda Calculus Starting from a categorical semantics of computations, Moggi <ref> [67] </ref> introduced the computational -calculus as a basis for reasoning about programs, independently of any specific computational model. <p> The result follows by Proposition 3.20. 3.6.3 Observational Equivalence The interest in calculi is generally motivated by their soundness with respect to observational equivalence. Therefore, the natural question is whether our extension is sound with respect to the call-by-value observational equivalence relation. Moggi <ref> [67] </ref> proved the result in a typed setting. In a dynamically typed language, the soundness of the c -calculus with respect to the call-by-value observational equivalence relation depends on the particular language extensions. For example, the axiom v is unsound in languages like Lisp or Scheme.
Reference: [68] <author> Moggi, E. </author> <title> Notions of computation and monads. </title> <booktitle> Information and Computation, </booktitle> <month> 93 </month> <year> (1991) </year> <month> 55-92. </month>
Reference-contexts: First, the calculus fi is a canonical and complete system of reasoning about functions in a call-by-name language. Second, our newly developed calculus turns out to be equivalent to Moggi's computational - calculus, which is a generic calculus for reasoning about programs with computational effects <ref> [67, 68] </ref>. Our correspondence theorem relates these two canonical calculi and hints at deeper connections between continuations and other computational effects. In the first subsection, we outline the equivalence of the calculus fi v AB and Moggi's computational -calculus.
Reference: [69] <author> Morris, L. </author> <title> The next 700 formal language descriptions. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 6, </volume> <month> 3/4 </month> <year> (1993) </year> <month> 249-256. </month> <note> Original manuscript dated 1970. </note>
Reference-contexts: The first section presents our personal perspective on the discovery of the concept of CPS transformations. For a different and more extensive historical perspective, we refer the reader to Reynolds's survey [79]. In the second section, we apply the original CPS transformation (due to Fischer [37], Morris <ref> [69] </ref>, and Strachey and Wadsworth [101]) to a pure call-by-value language. We also discuss Plotkin's analysis of the properties of this transformation [75]. Finally, we include a series of CPS transformations from the literature that represent various practical and theoretical improvements of the original formulation. <p> This ability to shift perspective from a high-level functional view to a low-level machine view and vice-versa is perhaps the most appealing aspect of CPS programs. 2 2.2 The Original CPS Transformation The original formulation of the CPS transformation is due to Fischer [37], Morris <ref> [69] </ref>, and Strachey and Wadsworth [101]. We first illustrate the transformation of a pure (without constants) higher-order call-by-value language. <p> Since continuations were conceived to explain sophisticated control operators <ref> [63, 69, 77, 101] </ref>, we begin by extending the theorems to languages with such constructs. In the next section, we axiomatize the semantics of a language with assignments using the store-passing transformation.
Reference: [70] <author> Murthy, C. </author> <title> Extracting Constructive Content from Classical Proofs. </title> <type> PhD thesis, </type> <institution> Cornell (1990). </institution>
Reference-contexts: 82, 92, 97]; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds classical logic into constructive logic <ref> [46, 70, 71] </ref>.
Reference: [71] <author> Murthy, C. </author> <title> An evaluation semantics for classical proofs. </title> <booktitle> In Proceedings of the 6th IEEE Symposium on Logic in Computer Science (1991). </booktitle>
Reference-contexts: 82, 92, 97]; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds classical logic into constructive logic <ref> [46, 70, 71] </ref>.
Reference: [72] <author> Nielson, F. </author> <title> A denotational framework for data flow analysis. </title> <journal> Acta Informatica, </journal> <month> 18 </month> <year> (1982) </year> <month> 265-287. </month>
Reference-contexts: be evaluated [39]. * Despite its functional appearances, CPS code constitutes an (imperative) abstract assembly language whose standard reduction sequence mimics the behav ior of typical target machines [3, 4, 41, 55, 104]. * Data-flow analyzers, partial evaluators, and other tools perform better on CPS programs than on source programs <ref> [22, 33, 34, 72] </ref>. * The CPS transformation is a global transformation that affects every subex-pression in a program. It re-structures programs to the extent that many of their original aspects are unrecognizable. <p> The literature generally supports the idea that CPS improves the precision of data flow analysis [10, 15, 33, 34, 58, 92]. Although much of the evidence is informal, investigations by Nielson <ref> [72] </ref> and Burn/Filho [33, 34] support, to some degree, the idea with formal results. 16 However, their results do not pinpoint the source of increased abstract information and do not explain the observation of many people that continuation-passing confuses some conventional data flow analyses. Prompted by conversations with G. <p> Intuitively, the first phase of A-normalization gives every subexpression a name to which the data flow analyzer can associate information about the expression. Without A-normalization, the analyzer would typically associate a "label" with every expression and attach the information about each expression at the corresponding label <ref> [53, 72, 92] </ref>. The two treatments are identical but the elimination of a separate notion of labels simplifies the analyzers. The second phase of A-normalization re-orders the expressions to reflect the order in which the interpreters will traverse them. <p> possible to recover x, i.e., new (x; s) = ` 62 dom (s) and x = new 1 (`). (For brevity, we will usually omit the second argument to new since it is easy to reconstruct from the context.) 122 Based on well-known ideas from the area of abstract interpretation <ref> [16, 53, 72, 92] </ref>, we derive a data flow analyzer from the previous interpreter. The first step in the derivation is to associate one location with each variable that holds the set of all values to which the variable is bound during the evaluation of the program. <p> In contrast, the analysis of the source program and the semantic-CPS analysis do not collect continuations, but only consider the current continuation at any program point. 6.4.2 Duplication The gain of information in semantic-CPS analyzers is folklore knowledge. Nielson <ref> [72] </ref> proved that, for a small imperative language, the semantic-CPS analysis computes the MOP (meet over all paths) solution and the direct analysis computes the less precise MFP (maximum fixed point) solution; Filho and Burn [34] improved the abstract interpretations of typed call-by-name languages using the CPS transformation.
Reference: [73] <author> Odersky, M., Rabin, D., and Hudak, P. </author> <title> Call by name, assignment, and the lambda calculus. </title> <booktitle> In Conference Record of the 20th ACM Symposium on Principles of Programming Languages (January 1993) 43-56. </booktitle>
Reference-contexts: We choose the following common representation <ref> [8, 62, 73] </ref>. <p> Our calculus is closer in spirit to the theory var <ref> [73] </ref> and the Imperative Lambda Calculus (ILC) [102] but is more powerful because it accommodates first-class reference cells. Also, the theory var uses a call-by-name semantics for procedures and has an additional pure construct.
Reference: [74] <author> Okasaki, C., Lee, P., and Tarditi, D. </author> <title> Call-by-need and continuation-passing style. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 7, </volume> <month> 1 </month> <year> (1994) </year> <month> 57-81. </month>
Reference-contexts: For example, we have: F [[((x:x) y)]] = k:((k:(k k:x:((k:kx) k))) (n:((m k) n))))): 3 For other parameter-passing mechanisms, e.g., call-by-name, call-by-need, we refer the reader to the literature <ref> [74, 75] </ref>. 17 Not only is this explosion in size undesirable in practical settings, e.g., when CPS programs are used as a compiler's intermediate representation, but it also complicates the relationship between source programs and their CPS counterparts.
Reference: [75] <author> Plotkin, G.D. </author> <title> Call-by-name, call-by-value, and the -calculus. </title> <booktitle> Theoretical Computer Science, </booktitle> <month> 1 </month> <year> (1975) </year> <month> 125-159. </month>
Reference-contexts: in the source language, e.g., exception handlers and call-with-current-continuation [13] to simple procedures that manipulate their continuation arguments in non-standard ways [77, 101]. * The CPS intermediate representation is simple: it consists only of basic primitive operations and procedure applications, and has a well-understood semantics in terms of the -calculus <ref> [75] </ref>. * The canonical equational theory for the CPS intermediate representation (the - calculus) proves more equations, hence more optimizations, than the canonical equational theory for the call-by-value source language [75]. * The CPS transformation systematically introduces names for every intermediate computation and re-orders the subexpressions of a program in a <p> it consists only of basic primitive operations and procedure applications, and has a well-understood semantics in terms of the -calculus <ref> [75] </ref>. * The canonical equational theory for the CPS intermediate representation (the - calculus) proves more equations, hence more optimizations, than the canonical equational theory for the call-by-value source language [75]. * The CPS transformation systematically introduces names for every intermediate computation and re-orders the subexpressions of a program in a way that reflects the order in which they should be evaluated [39]. * Despite its functional appearances, CPS code constitutes an (imperative) abstract assembly language whose standard reduction sequence mimics <p> Chapter 3 addresses the most elementary and most obvious advantage of CPS compilers over direct compilers, namely that the equational theory for the CPS intermediate representation is richer than the equational theory for pure call-by-value languages <ref> [75] </ref>. Since equational theories are commonly used to perform simple optimizations [3], it appears that CPS compilers can perform more simplifications on their intermediate representation than direct compilers. <p> A program is a term with no free variables and, in practical languages, an answer is a member of the syntactic category of values. A common method for specifying the semantics of fl is based on the Curry-Feys standard reduction theorem <ref> [27, 75] </ref>. The standard reduction theorem defines a partial function 7! from programs to programs that corresponds to a single evaluation step of an abstract machine for fl. <p> In the second section, we apply the original CPS transformation (due to Fischer [37], Morris [69], and Strachey and Wadsworth [101]) to a pure call-by-value language. We also discuss Plotkin's analysis of the properties of this transformation <ref> [75] </ref>. Finally, we include a series of CPS transformations from the literature that represent various practical and theoretical improvements of the original formulation. <p> It is trivial to rewrite the CPS transformation to encode a right-to-left evaluation order: F [[M N ]] = k:(F [[N ]] (n:(F [[M ]] m:((m k) n)))): The main formal properties of the original CPS transformation were established by Fischer [37], Reynolds [77], and Plotkin <ref> [75] </ref>. The following theorem summarizes these main properties. Theorem 2.1 (Plotkin [75]) Let M 2 fl. <p> transformation to encode a right-to-left evaluation order: F [[M N ]] = k:(F [[N ]] (n:(F [[M ]] m:((m k) n)))): The main formal properties of the original CPS transformation were established by Fischer [37], Reynolds [77], and Plotkin <ref> [75] </ref>. The following theorem summarizes these main properties. Theorem 2.1 (Plotkin [75]) Let M 2 fl. <p> For example, we have: F [[((x:x) y)]] = k:((k:(k k:x:((k:kx) k))) (n:((m k) n))))): 3 For other parameter-passing mechanisms, e.g., call-by-name, call-by-need, we refer the reader to the literature <ref> [74, 75] </ref>. 17 Not only is this explosion in size undesirable in practical settings, e.g., when CPS programs are used as a compiler's intermediate representation, but it also complicates the relationship between source programs and their CPS counterparts. <p> Following Plotkin's terminology <ref> [75] </ref>, we call this reduction proper , and all other reductions administrative. The remainder of this chapter addresses various algorithms for the elimination of administrative redexes. Steele [97] based his compiler for Scheme on the CPS transformation. <p> It remains to find a one-pass implementation of this CPS transformation. By Proposition 2.2, administrative reductions can be performed in any order without affecting the result. Therefore, we can analyze a particular order, e.g., the standard reduction sequence. According to Plotkin <ref> [75] </ref>, the standard reduction sequence of a source program relates to the standard reduction sequence of its CPS counterpart as described in the following diagram: * N 7! v - * . . . . * * * * * * N : K 3 . . . . . . <p> Any - expansion starting from a -abstraction will also result in a -abstraction. Therefore, L is a value: (F [[M]] x:x) !! fi W 0 By the Standard Reduction theorem <ref> [75] </ref>, if a term reduces to a value, then it standard-reduces to a value. Therefore, eval n (F [[M]] x:x) is defined. <p> The two operational equivalences however do not coincide, e.g., M ~ = fl v N does not imply that C k [[M ]] ~ = fl n C k [[N]]. For example, if: M = y:x:x (y x) df then, M ~ = fl v N <ref> [75] </ref>. On the other hand, C k [[M]] = (k k:y:(k k:x:((y (x k)) x))); and the context: D = ((k:[ ]) (k:m:m (x:x))))) differentiates the two expressions.
Reference: [76] <author> Plotkin, G. D. </author> <title> Completeness for the continuous type frame. </title> <type> Unpublished Manuscript. 155 </type>
Reference-contexts: Since the latter terms are also simply typed terms, the full continuous type frame satisfies the equation C k [[M]] = C k [[N ]] <ref> [76] </ref>. The result follows because the two denotational models define the same semantics. Finally, the calculus fi v ABCC # corresponds to a restriction of the call-by-value observational equivalence that accounts for control operations.
Reference: [77] <author> Reynolds, J. C. </author> <title> Definitional interpreters for higher-order programming languages. </title> <booktitle> In Proceedings of the ACM Annual Conference (1972) 717-740. </booktitle>
Reference-contexts: it defines the intermediate representation of many compilers and program anal ysis tools [3, 15, 39, 55, 56, 58, 82, 92, 97]; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics <ref> [77] </ref>; * it converts heap allocation into stack allocation [5, 37]; * it embeds classical logic into constructive logic [46, 70, 71]. <p> regarding the relative advantages and disadvantages of the 2 CPS intermediate representation with respect to other intermediate representations are also common: * The CPS transformation translates complicated control facilities in the source language, e.g., exception handlers and call-with-current-continuation [13] to simple procedures that manipulate their continuation arguments in non-standard ways <ref> [77, 101] </ref>. * The CPS intermediate representation is simple: it consists only of basic primitive operations and procedure applications, and has a well-understood semantics in terms of the -calculus [75]. * The canonical equational theory for the CPS intermediate representation (the - calculus) proves more equations, hence more optimizations, than the <p> It is trivial to rewrite the CPS transformation to encode a right-to-left evaluation order: F [[M N ]] = k:(F [[N ]] (n:(F [[M ]] m:((m k) n)))): The main formal properties of the original CPS transformation were established by Fischer [37], Reynolds <ref> [77] </ref>, and Plotkin [75]. The following theorem summarizes these main properties. Theorem 2.1 (Plotkin [75]) Let M 2 fl. <p> Since continuations were conceived to explain sophisticated control operators <ref> [63, 69, 77, 101] </ref>, we begin by extending the theorems to languages with such constructs. In the next section, we axiomatize the semantics of a language with assignments using the store-passing transformation.
Reference: [78] <author> Reynolds, J. C. </author> <title> On the relation between direct and continuation semantics. </title> <booktitle> In Proceedings of the International Colloquium on Automata, Languages and Programming (1974) 141-156. </booktitle>
Reference-contexts: between the original programs and their CPS transforms specializes to a problem of independent interest, e.g., relating source programs to their intermediate representation in a CPS compiler, relating direct compilers to CPS compilers, relating classical proofs to constructive proofs, and relating denotations in direct semantics to denotations in continuation semantics <ref> [65, 78, 91, 98] </ref>. Some of the above problems have been thoroughly studied in the literature, but the precise role of the CPS transformation in the compilation process is still not completely understood.
Reference: [79] <author> Reynolds, J. C. </author> <title> The discoveries of continuations. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 6, </volume> <month> 3/4 </month> <year> (1993) </year> <month> 233-247. </month>
Reference-contexts: The first section presents our personal perspective on the discovery of the concept of CPS transformations. For a different and more extensive historical perspective, we refer the reader to Reynolds's survey <ref> [79] </ref>. In the second section, we apply the original CPS transformation (due to Fischer [37], Morris [69], and Strachey and Wadsworth [101]) to a pure call-by-value language. We also discuss Plotkin's analysis of the properties of this transformation [75].
Reference: [80] <author> Riecke, J. </author> <title> Delimiting the scope of effects. </title> <booktitle> In Proceedings of the Conference on Functional Programming Languages and Computer Architecture (1993) 146-155. </booktitle>
Reference-contexts: Denotational models for languages with such control operators naturally include elements that delimit control actions <ref> [80, 95] </ref>. In addition to their theoretical importance, these delimiters present a useful programming paradigm [93, 94]. In this section, we study one traditional control delimiter: # (prompt) [24].
Reference: [81] <author> Riecke, J. </author> <title> Statman's 1-section theorem. </title> <note> Information and Computation (1994). To appear. Also Technical Report MS-CIS-92-03, </note> <institution> University of Pennsylvania, </institution> <year> 1992. </year>
Reference-contexts: The canonical set of contexts is the set of PCF-contexts that includes numerals, an increment procedure add1, a decrement procedure sub1, conditionals, and a recursion operator [43]. Observational equivalence of call-by-name simply typed terms relative to PCF-contexts is decidable and axiomatized by the axioms fi. Theorem 1.2 (Meyer <ref> [81] </ref>) Let M and N be simply typed terms in fl, then fi ` M = N if and only if M ~ = PCF n N . In general, it is hard to reason directly about observational equivalence.
Reference: [82] <author> Rozas, G. </author> <title> Liar, An Algol-like Compiler for Scheme. </title> <type> Master's thesis, </type> <institution> MIT Department of Electrical Engineering and Computer Science (1984). </institution>
Reference-contexts: Abstract Collecting Interpreter (II) : : : : : : : : : : : 136 1 Chapter 1 Background and Motivation The continuation-passing style (CPS) transformation is ubiquitous in the area of programming language semantics: * it defines the intermediate representation of many compilers and program anal ysis tools <ref> [3, 15, 39, 55, 56, 58, 82, 92, 97] </ref>; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds <p> Indeed many state-of-the-art compilers for applicative higher-order programming languages (Scheme, ML, Lisp, etc) use a CPS intermediate representation <ref> [3, 56, 82] </ref>, and many others do not [7, 9, 12, 50, 59]. <p> One of the simple approximations, known as 0CFA analysis <ref> [82, 92] </ref>, is to associate one location for each variable and to collect all the values to which the variable is bound at that location.
Reference: [83] <author> Sabry, A. and Felleisen, M. </author> <title> Reasoning about programs in continuation-passing style. </title> <booktitle> In Proceedings of the ACM Conference on Lisp and Functional Programming (1992) 288-298. </booktitle> <institution> Technical Report 92-180, Rice University. </institution>
Reference-contexts: We also discuss Plotkin's analysis of the properties of this transformation [75]. Finally, we include a series of CPS transformations from the literature that represent various practical and theoretical improvements of the original formulation. The development culminates with our optimal compacting CPS transformation <ref> [83, 85] </ref>. 2.1 History and Motivation: Procedure Call versus Goto Unlike earlier languages, Algol 60 included both lexically-nested procedures (blocks) and unconditional jumps (gotos). The combination of these two constructs posed a challenge to both semanticists and implementors alike.
Reference: [84] <author> Sabry, A. and Felleisen, M. </author> <title> Reasoning about Programs in Continuation-Passing Style. </title> <type> Technical Report 92-180, </type> <institution> Rice University (1992). </institution>
Reference-contexts: Both are impossible if the input is of the form C k [[M ]] for some M 2 fl. 3.7 Related Work Most of the material in this chapter is contained in the technical report version of our 1992 Lisp and Functional Programming paper <ref> [84] </ref>. Some of the ideas are closely related to recent work by Danvy, Lawall, and Hatcliff. Danvy and Lawall [20, 22] studied the problem of inverting the CPS transformation and produced a "direct style" transformation similar to our transformation C 1 .
Reference: [85] <author> Sabry, A. and Felleisen, M. </author> <title> Reasoning about programs in continuation-passing style. </title> <booktitle> Lisp and Symbolic Computation, 6, 3/4 (1993) 289-360. Also in Proceedings of the ACM Conference on Lisp and Functional Programming, </booktitle> <year> 1992, </year> <type> and Technical Report 92-180, </type> <institution> Rice University. </institution>
Reference-contexts: We also discuss Plotkin's analysis of the properties of this transformation [75]. Finally, we include a series of CPS transformations from the literature that represent various practical and theoretical improvements of the original formulation. The development culminates with our optimal compacting CPS transformation <ref> [83, 85] </ref>. 2.1 History and Motivation: Procedure Call versus Goto Unlike earlier languages, Algol 60 included both lexically-nested procedures (blocks) and unconditional jumps (gotos). The combination of these two constructs posed a challenge to both semanticists and implementors alike. <p> A simple improvement of the Danvy/Filinski CPS transformation is possible if the order of the arguments to a procedure is switched so that the continuation becomes the first argument <ref> [85] </ref>. <p> Our axioms extend Felleisen's v -C-calculus and are equivalent to Talcott's theory IOCC (when restricted to our language). Our axiomatization is also the first to be shown complete with respect to the CPS semantics; it was the main technical contribution of our extended journal paper <ref> [85] </ref>. Independently, Hofmann [52] developed a complete axiomatization of the semantics of call-by-value control operators with respect to CPS semantics; his proof technique is different from ours but the resulting set of axioms is the same (modulo some syntactic differences). <p> The results in this chapter ap 16 We discussed and re-confirmed the informal idea that CPS improves program analysis with, among others, Charles Consel, and Olivier Danvy at LFP '92 [June 92], following the presentation of our paper on equational reasoning about programs in CPS <ref> [85] </ref>; in an email exchange with Geoffrey Burn and Juarez Filho [July 92]; in further discussions at POPL '93 with Daniel Weise; in email discussions with Kelsey [July 93] and Shivers [May 93]; and in discussions with Burn at FPCA '93 [June 93].
Reference: [86] <author> Sabry, A. and Felleisen, M. </author> <title> Is continuation-passing useful for data flow analysis? In Proceedings of the ACM Sigplan Conference on Programming Language Design and Implementation (1994). </title> <note> To appear. </note>
Reference-contexts: We suspect that many others who use the CPS transformation subscribe to the same conjecture. 120 peared in a paper presented at the Conference on Programming Language Design and Implementation <ref> [86, 87] </ref>. 6.1 Constant Propagation by Abstract Interpretation For the analysis of programs, we assume the programs to be in A-normal form, and all the bound variables to be unique, e.g., if (x 1 :M 1 ) and (x 2 :M 2 ) are two distinct procedures in a program, then
Reference: [87] <author> Sabry, A. and Felleisen, M. </author> <title> Is Continuation-Passing Useful for Data Flow Analysis? Technical Report TR94-223, </title> <institution> Rice University (1994). </institution> <month> 156 </month>
Reference-contexts: We suspect that many others who use the CPS transformation subscribe to the same conjecture. 120 peared in a paper presented at the Conference on Programming Language Design and Implementation <ref> [86, 87] </ref>. 6.1 Constant Propagation by Abstract Interpretation For the analysis of programs, we assume the programs to be in A-normal form, and all the bound variables to be unique, e.g., if (x 1 :M 1 ) and (x 2 :M 2 ) are two distinct procedures in a program, then
Reference: [88] <author> Sabry, A. and Field, J. </author> <title> Reasoning about explicit and implicit representations of state. </title> <booktitle> In ACM Sigplan Workshop on State in Programming Languages, </booktitle> <institution> Technical Report RR-968, Yale University (1993) 17-30. </institution>
Reference-contexts: Each of the previously proposed logics was designed independently, and differs from the others in subtle ways. Our approach of deriving the calculus from the store-passing axioms is more systematic and generalizes to other languages <ref> [88] </ref>. Also, when compared to other systems, our calculus has several distinguishing features. First, in contrast with calculi derived from abstract machines for the imperative source language [17, 29, 61], our equational theory never eliminates an expression of the form (setref! V 1 V 2 ).
Reference: [89] <author> Scott, D. </author> <title> Outline of a mathematical theory of computation. </title> <booktitle> In Proceedings of the Fourth Annual Princeton Conference on Information Sciences and Systems ( ) 169-176. </booktitle> <institution> Also Technical Monograph PRG-2, Oxford University Computing Laboratory, Programming Research Group, </institution> <year> 1970. </year>
Reference-contexts: The combination of these two constructs posed a challenge to both semanticists and implementors alike. On one hand, the contemporary mathematical theory of semantics <ref> [89, 90] </ref> could not accommodate imperative facilities such as gotos. On the other hand, the ability to jump outside of blocks (and hence jump to new lexical scopes) complicated the implementation of procedures and the representation of labels. <p> transforming program fragments so that they manipulate their continuation explicitly enables both an implementation of procedure calls as jumps and a stack-based implementation strategy of languages with higher-order procedures. 2.1.2 Goto as Procedure Call The idea of defining the semantics of programming languages mathematically was proposed by Scott and Strachey <ref> [89, 90, 100] </ref>. Intuitively, the goal of the approach is to use well-established mathematical concepts, e.g., functions, lattices, etc, in order to describe the semantics of programming languages.
Reference: [90] <author> Scott, D. and Strachey, C. </author> <title> Toward a mathematical semantics for computer languages. </title> <booktitle> In Proceedings of the Symposium on Computers and Automata (1971). </booktitle> <institution> Also Technical Monograph PRG-6, Oxford University, Computing Laboratory, Programming Research Group. </institution>
Reference-contexts: The combination of these two constructs posed a challenge to both semanticists and implementors alike. On one hand, the contemporary mathematical theory of semantics <ref> [89, 90] </ref> could not accommodate imperative facilities such as gotos. On the other hand, the ability to jump outside of blocks (and hence jump to new lexical scopes) complicated the implementation of procedures and the representation of labels. <p> transforming program fragments so that they manipulate their continuation explicitly enables both an implementation of procedure calls as jumps and a stack-based implementation strategy of languages with higher-order procedures. 2.1.2 Goto as Procedure Call The idea of defining the semantics of programming languages mathematically was proposed by Scott and Strachey <ref> [89, 90, 100] </ref>. Intuitively, the goal of the approach is to use well-established mathematical concepts, e.g., functions, lattices, etc, in order to describe the semantics of programming languages.
Reference: [91] <author> Sethi, R. and Tang, A. </author> <title> Constructing call-by-value continuation semantics. </title> <journal> Journal of the ACM, </journal> <volume> 27, </volume> <month> 3 </month> <year> (1980) </year> <month> 580-597. </month>
Reference-contexts: between the original programs and their CPS transforms specializes to a problem of independent interest, e.g., relating source programs to their intermediate representation in a CPS compiler, relating direct compilers to CPS compilers, relating classical proofs to constructive proofs, and relating denotations in direct semantics to denotations in continuation semantics <ref> [65, 78, 91, 98] </ref>. Some of the above problems have been thoroughly studied in the literature, but the precise role of the CPS transformation in the compilation process is still not completely understood.
Reference: [92] <author> Shivers, O. </author> <title> Control-Flow Analysis of Higher-Order Languages or Taming Lambda. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University (1991). </institution>
Reference-contexts: Abstract Collecting Interpreter (II) : : : : : : : : : : : 136 1 Chapter 1 Background and Motivation The continuation-passing style (CPS) transformation is ubiquitous in the area of programming language semantics: * it defines the intermediate representation of many compilers and program anal ysis tools <ref> [3, 15, 39, 55, 56, 58, 82, 92, 97] </ref>; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds <p> First, the nave abstract machine for CPS code represents the continuation as an ordinary closure. Yet, realistic CPS compilers "mark" the continuation closure as a special closure. For example, Shivers partitions procedures and continuations in order to improve the data flow analysis of CPS programs <ref> [92, sec 3.8.3] </ref>. Also, in both Orbit [56] and Rabbit [97], the allocation strategy of a closure changes if the closure is a continuation. Similarly, Appel [3, p 114-124] describes various techniques for closure allocation that treat the continuation closure in a special way. <p> The literature generally supports the idea that CPS improves the precision of data flow analysis <ref> [10, 15, 33, 34, 58, 92] </ref>. <p> Intuitively, the first phase of A-normalization gives every subexpression a name to which the data flow analyzer can associate information about the expression. Without A-normalization, the analyzer would typically associate a "label" with every expression and attach the information about each expression at the corresponding label <ref> [53, 72, 92] </ref>. The two treatments are identical but the elimination of a separate notion of labels simplifies the analyzers. The second phase of A-normalization re-orders the expressions to reflect the order in which the interpreters will traverse them. <p> possible to recover x, i.e., new (x; s) = ` 62 dom (s) and x = new 1 (`). (For brevity, we will usually omit the second argument to new since it is easy to reconstruct from the context.) 122 Based on well-known ideas from the area of abstract interpretation <ref> [16, 53, 72, 92] </ref>, we derive a data flow analyzer from the previous interpreter. The first step in the derivation is to associate one location with each variable that holds the set of all values to which the variable is bound during the evaluation of the program. <p> One of the simple approximations, known as 0CFA analysis <ref> [82, 92] </ref>, is to associate one location for each variable and to collect all the values to which the variable is bound at that location. <p> in a lattice that is the product of two lattices: the first is the traditional lattice N &gt; ? used for constant propagation [54], and the second is the power set of abstract closures relative to the given program (ordered by the subset relation) used to approximate the control flow <ref> [92] </ref>. The ordering relation v, as well as the least upper bound operation t, of the lattice of abstract values are defined component-wise. <p> In the remainder of this section, we discuss each of the properties of the CPS analyzers in detail. 6.4.1 False Returns In practice, many analyses do indeed confuse continuations when applied to CPS programs. For example, Shivers's 0CFA analysis of CPS programs <ref> [92] </ref> merges distinct control paths unnecessarily. Shivers did not relate the problem to CPS but his example [92, p 33] is essentially the example for Theorem 6.5. 143 Given our result, we can explain how the CPS transformation confuses some data flow analyzers that associate (approximate) information with program points. <p> For example, Shivers's 0CFA analysis of CPS programs [92] merges distinct control paths unnecessarily. Shivers did not relate the problem to CPS but his example <ref> [92, p 33] </ref> is essentially the example for Theorem 6.5. 143 Given our result, we can explain how the CPS transformation confuses some data flow analyzers that associate (approximate) information with program points.
Reference: [93] <author> Sitaram, D. </author> <title> Handling control. </title> <booktitle> In Proceedings of the ACM Sigplan Conference on Programming Language Design and Implementation (1993) 147-155. </booktitle>
Reference-contexts: Denotational models for languages with such control operators naturally include elements that delimit control actions [80, 95]. In addition to their theoretical importance, these delimiters present a useful programming paradigm <ref> [93, 94] </ref>. In this section, we study one traditional control delimiter: # (prompt) [24]. Intuitively, in an expression (# M ), the prompt treats its subexpression as a complete program by evaluating it in the initial continuation, forwarding the result to the current continuation.
Reference: [94] <author> Sitaram, D. and Felleisen, M. </author> <title> Control delimiters and their hierarchies. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 3, </volume> <month> 1 </month> <year> (1990) </year> <month> 67-100. </month>
Reference-contexts: Denotational models for languages with such control operators naturally include elements that delimit control actions [80, 95]. In addition to their theoretical importance, these delimiters present a useful programming paradigm <ref> [93, 94] </ref>. In this section, we study one traditional control delimiter: # (prompt) [24]. Intuitively, in an expression (# M ), the prompt treats its subexpression as a complete program by evaluating it in the initial continuation, forwarding the result to the current continuation.
Reference: [95] <author> Sitaram, D. and Felleisen, M. </author> <title> Reasoning with continuations II: Full abstraction for models of control. </title> <booktitle> In Proceedings of the ACM Conference on Lisp and Functional Programming (1990) 161-175. </booktitle>
Reference-contexts: Denotational models for languages with such control operators naturally include elements that delimit control actions <ref> [80, 95] </ref>. In addition to their theoretical importance, these delimiters present a useful programming paradigm [93, 94]. In this section, we study one traditional control delimiter: # (prompt) [24]. <p> In the remainder of this section, we restrict the type of answers a so that it coincides with the type o of observable objects. The set of source terms is an extension of the simply typed -calculus with the control operators and their usual types <ref> [95] </ref>: V ::= : : : j callcc ((s!t)!s)!s j A o!t j (# M o ) o Definition 4.5 (CPS t ) The full set of CPS terms is: P ::= x a j (K t!a W t ) a j (K a!a P a ) a K ::= k <p> Sketch By modifying the full abstraction proof of Sitaram and Felleisen <ref> [95] </ref>, we prove that the CPS continuous frame model satisfies M = N if only if M and N are observationally equivalent. The rest follows from Theorem 4.9. 4.2 Assignments Realistic programming languages include imperative, assignment-like constructs.
Reference: [96] <editor> Steel, T.B., editor. </editor> <booktitle> Formal Language Description Languages for Computer Programming. </booktitle> <publisher> North-Holland (1966). </publisher>
Reference-contexts: The above idea can be traced back to A. van Wijngaarden. In the discussion following the presentation of his paper at an IFIP Working Conference on Formal Language Description Languages <ref> [96] </ref>, van Wijngaarden argued that the presence of goto statements complicates the implementation of procedures and proposed a new strategy in which no procedure ever returns because it always calls for another one before it ends, and all of the ends of all the procedures will be at the end of <p> That means you can make the procedure implementation so that it does not bother to enable the procedure return : : : it's exactly the same as a goto, only called in other words <ref> [96, p 24] </ref>. Independently, Fischer used the same idea to implement languages with higher-order procedures such as Lisp, Scheme, and ML [37]. In such languages, a variable bound in an inner block (or procedure) may be referenced from outside.
Reference: [97] <author> Steele, G. L. Rabbit: </author> <title> A Compiler for Scheme. MIT AI Memo 474, </title> <institution> Mas-sachusetts Institute of Technology (1978). </institution>
Reference-contexts: Abstract Collecting Interpreter (II) : : : : : : : : : : : 136 1 Chapter 1 Background and Motivation The continuation-passing style (CPS) transformation is ubiquitous in the area of programming language semantics: * it defines the intermediate representation of many compilers and program anal ysis tools <ref> [3, 15, 39, 55, 56, 58, 82, 92, 97] </ref>; * it is essential in the construction of many denotational models of programming languages [99, 101]; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds <p> Following Plotkin's terminology [75], we call this reduction proper , and all other reductions administrative. The remainder of this chapter addresses various algorithms for the elimination of administrative redexes. Steele <ref> [97] </ref> based his compiler for Scheme on the CPS transformation. In order to minimize the size of intermediate programs, Steele improved the original CPS transformation to recognize various special cases. Although Steele's CPS transform generates terms without administrative redexes, his algorithm is complicated and includes ad-hoc optimizations. <p> In the process of transforming programs, the original algorithm increases the size of source terms considerably by introducing administrative redexes. Both Steele <ref> [97] </ref> and Danvy/Filinski [21] developed algorithms to eliminate administrative redexes but did not give any semantic significance to administrative reductions. <p> on w . 12 Alternative translations that do not cause this exponential increase in the size of the code are: C k [[E [(if V M N )]]] = ((k:(if [[V ]] C k [[M ]] C k [[N ]])) K k [[E]]) The first translation is used by compilers <ref> [97] </ref> but also duplicates the entire evaluation context once we close the language under fi-reductions. <p> The CPS intermediate language used in realistic CPS compilers <ref> [3, 56, 97] </ref> corresponds to the output of our compacting CPS transformation. <p> Yet, realistic CPS compilers "mark" the continuation closure as a special closure. For example, Shivers partitions procedures and continuations in order to improve the data flow analysis of CPS programs [92, sec 3.8.3]. Also, in both Orbit [56] and Rabbit <ref> [97] </ref>, the allocation strategy of a closure changes if the closure is a continuation. Similarly, Appel [3, p 114-124] describes various techniques for closure allocation that treat the continuation closure in a special way. <p> In order to reflect these changes in the machine, we tag continuation closures with a special marker "ar" that describes them as activation records. Second, the CPS representation of any user-defined procedure receives a continuation argument. However, Steele <ref> [97] </ref> modifies the CPS transformation with a 108 "continuation variable hack" [97, p 94] that recognizes instances of CPS terms like ((k 1 :P ) k 2 : : :) and transforms them to (( :P [k 1 := k 2 ]) : : :). <p> In order to reflect these changes in the machine, we tag continuation closures with a special marker "ar" that describes them as activation records. Second, the CPS representation of any user-defined procedure receives a continuation argument. However, Steele [97] modifies the CPS transformation with a 108 "continuation variable hack" <ref> [97, p 94] </ref> that recognizes instances of CPS terms like ((k 1 :P ) k 2 : : :) and transforms them to (( :P [k 1 := k 2 ]) : : :). This "optimization" eliminates "some of the register shu*ing" [97, p 94] during the evaluation of the term. <p> CPS transformation with a 108 "continuation variable hack" <ref> [97, p 94] </ref> that recognizes instances of CPS terms like ((k 1 :P ) k 2 : : :) and transforms them to (( :P [k 1 := k 2 ]) : : :). This "optimization" eliminates "some of the register shu*ing" [97, p 94] during the evaluation of the term. Appel [3] achieves the same effect without modifying the CPS transformation by letting the variables k 1 and k 2 share the same register during the procedure call.
Reference: [98] <author> Stoy, J. </author> <title> The congruence of two programming language definitions. </title> <booktitle> Theoretical Computer Science, </booktitle> <month> 13 </month> <year> (1981) </year> <month> 151-174. 157 </month>
Reference-contexts: between the original programs and their CPS transforms specializes to a problem of independent interest, e.g., relating source programs to their intermediate representation in a CPS compiler, relating direct compilers to CPS compilers, relating classical proofs to constructive proofs, and relating denotations in direct semantics to denotations in continuation semantics <ref> [65, 78, 91, 98] </ref>. Some of the above problems have been thoroughly studied in the literature, but the precise role of the CPS transformation in the compilation process is still not completely understood.
Reference: [99] <author> Stoy, J. </author> <title> Denotational Semantics: The Scott-Strachey Approach to Programming Languages. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Mass. </address> <year> (1981). </year>
Reference-contexts: continuation-passing style (CPS) transformation is ubiquitous in the area of programming language semantics: * it defines the intermediate representation of many compilers and program anal ysis tools [3, 15, 39, 55, 56, 58, 82, 92, 97]; * it is essential in the construction of many denotational models of programming languages <ref> [99, 101] </ref>; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds classical logic into constructive logic [46, 70, 71].
Reference: [100] <author> Strachey, C. </author> <title> Towards a formal semantics. In Steel, T.B., editor, Formal Language Description Languages for Computer Programming, </title> <publisher> North-Holland (1966) 197-220. </publisher>
Reference-contexts: transforming program fragments so that they manipulate their continuation explicitly enables both an implementation of procedure calls as jumps and a stack-based implementation strategy of languages with higher-order procedures. 2.1.2 Goto as Procedure Call The idea of defining the semantics of programming languages mathematically was proposed by Scott and Strachey <ref> [89, 90, 100] </ref>. Intuitively, the goal of the approach is to use well-established mathematical concepts, e.g., functions, lattices, etc, in order to describe the semantics of programming languages. <p> : :g Although this language is quite simple, it is sufficient to represent, e.g., pointer manipulations, call-by-reference parameter passing, ML-style reference cells, 9 and dynamic allocation and de-allocation. 10 In order to define the semantics of the source language fl + ref , we exploit an idea from denotational semantics <ref> [100] </ref>. This semantics regards the store as a primitive concept, and uses a "store-passing transformation" to translate imperative operations to explicit operations on a concrete representation of the store.
Reference: [101] <author> Strachey, C. and Wadsworth, </author> <title> C.P. Continuations: A Mathematical Semantics for Handling Full Jumps. </title> <type> Technical Monograph PRG-11, </type> <institution> Oxford University Computing Laboratory, Programming Research Group (1974). </institution>
Reference-contexts: continuation-passing style (CPS) transformation is ubiquitous in the area of programming language semantics: * it defines the intermediate representation of many compilers and program anal ysis tools [3, 15, 39, 55, 56, 58, 82, 92, 97]; * it is essential in the construction of many denotational models of programming languages <ref> [99, 101] </ref>; * it permits a simulation of call-by-value semantics using call-by-name seman tics [77]; * it converts heap allocation into stack allocation [5, 37]; * it embeds classical logic into constructive logic [46, 70, 71]. <p> regarding the relative advantages and disadvantages of the 2 CPS intermediate representation with respect to other intermediate representations are also common: * The CPS transformation translates complicated control facilities in the source language, e.g., exception handlers and call-with-current-continuation [13] to simple procedures that manipulate their continuation arguments in non-standard ways <ref> [77, 101] </ref>. * The CPS intermediate representation is simple: it consists only of basic primitive operations and procedure applications, and has a well-understood semantics in terms of the -calculus [75]. * The canonical equational theory for the CPS intermediate representation (the - calculus) proves more equations, hence more optimizations, than the <p> For a different and more extensive historical perspective, we refer the reader to Reynolds's survey [79]. In the second section, we apply the original CPS transformation (due to Fischer [37], Morris [69], and Strachey and Wadsworth <ref> [101] </ref>) to a pure call-by-value language. We also discuss Plotkin's analysis of the properties of this transformation [75]. Finally, we include a series of CPS transformations from the literature that represent various practical and theoretical improvements of the original formulation. <p> To get around this problem, Strachey and Wadsworth <ref> [101] </ref> modify the state transformers to take an additional argument that represents the (state transformation specified by the) rest of the program, i.e., the continuation. <p> This ability to shift perspective from a high-level functional view to a low-level machine view and vice-versa is perhaps the most appealing aspect of CPS programs. 2 2.2 The Original CPS Transformation The original formulation of the CPS transformation is due to Fischer [37], Morris [69], and Strachey and Wadsworth <ref> [101] </ref>. We first illustrate the transformation of a pure (without constants) higher-order call-by-value language. <p> Since continuations were conceived to explain sophisticated control operators <ref> [63, 69, 77, 101] </ref>, we begin by extending the theorems to languages with such constructs. In the next section, we axiomatize the semantics of a language with assignments using the store-passing transformation.
Reference: [102] <author> Swarup, V., Reddy, U., and Ireland, E. </author> <title> Assignments for applicative languages. </title> <booktitle> In Proceedings of the Conference on Functional Programming Languages and Computer Architecture (1991) 192-214. </booktitle>
Reference-contexts: 2 ) A 1 W 1 ) (upd (upd S A W 1 ) A W 2 ) = (upd S A W 2 ) 11 It is possible to use a type system that rejects the above program and that guarantees that the evaluation of "simply typed" programs terminates <ref> [102] </ref>. <p> The axiomatization of the semantics of languages with assignments has been studied extensively <ref> [8, 17, 23, 26, 29, 51, 61, 102] </ref>. Each of the previously proposed logics was designed independently, and differs from the others in subtle ways. Our approach of deriving the calculus from the store-passing axioms is more systematic and generalizes to other languages [88]. <p> Our calculus is closer in spirit to the theory var [73] and the Imperative Lambda Calculus (ILC) <ref> [102] </ref> but is more powerful because it accommodates first-class reference cells. Also, the theory var uses a call-by-name semantics for procedures and has an additional pure construct.
Reference: [103] <author> Talcott, C. L. </author> <title> A theory for program and data specification. </title> <booktitle> Theoretical Computer Science, 104 (1992) 129-159. Preliminary version in Proceedings of the International Symposium on Design and Implementation of Symbolic Computation Systems, (Lecture Notes in Computer Science, </booktitle> <volume> 429, </volume> <year> 1990). </year>
Reference-contexts: ((k:C k [[M ]]) x:x) = [[V ]]: In order to simplify the following discussions (and proofs), we use a CPS transformation that is less compacting than the one in Definition 2.4 but more suited for the remainder of our analysis. 6 Felleisen et al. [27, 29, 30] and Talcott <ref> [103] </ref> use alternative definitions that do not rely on the CPS transformation. 60 Definition 4.1 (C k with Control Operators) Let k; u i 2 Vars be vari ables that do not occur in the argument to C k . <p> ) (f (lambda (dest val ) (callcc (lambda (k ) (set! LCS k ) (dest val)))) x ) (error "fell off end"))]) (lambda (v ) (LCS v ))))) 101 4.5 Related Work The axiomatization of the semantics of call-by-value control operators was originally studied by Felleisen [29, 30] and Talcott <ref> [103] </ref>. Our axioms extend Felleisen's v -C-calculus and are equivalent to Talcott's theory IOCC (when restricted to our language). Our axiomatization is also the first to be shown complete with respect to the CPS semantics; it was the main technical contribution of our extended journal paper [85].
Reference: [104] <author> Wand, M. </author> <title> Correctness of procedure representations in higher-order assembly language. </title> <editor> In Brookes, S., editor, </editor> <booktitle> Proceedings of the Conference on the Mathematical Foundations of Programing Semantics, Lecture Notes in Computer Science, </booktitle> <volume> 598, </volume> <publisher> Springer Verlag (1992) 294-311. </publisher>
Reference-contexts: for every intermediate computation and re-orders the subexpressions of a program in a way that reflects the order in which they should be evaluated [39]. * Despite its functional appearances, CPS code constitutes an (imperative) abstract assembly language whose standard reduction sequence mimics the behav ior of typical target machines <ref> [3, 4, 41, 55, 104] </ref>. * Data-flow analyzers, partial evaluators, and other tools perform better on CPS programs than on source programs [22, 33, 34, 72]. * The CPS transformation is a global transformation that affects every subex-pression in a program.
Reference: [105] <author> Wright, A. and Duba, B. F. </author> <title> Pattern matching for Scheme. </title> <type> Unpublished manuscript, </type> <year> 1993. </year> <note> Available as World Wide Web URL "ftp://cs.rice.edu/public/ wright/match.ps.Z". </note>
Reference-contexts: In that case, the A-normalization phase can be performed using the linear algorithm in Figure 5.1. The algorithm is written in Scheme extended with a special form match, which performs pattern matching on the syntax of program terms <ref> [105] </ref>. It employs a programming technique for CPS algorithms pioneered by Danvy and Filinski [21].
References-found: 105

