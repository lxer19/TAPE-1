URL: ftp://speech.cse.ogi.edu/pub/docs/census_icslp94.ps.Z
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Title: A PROTOTYPE VOICE-RESPONSE QUESTIONNAIRE FOR THE U.S. CENSUS  for Spoken Language Understanding  
Author: Ronald Cole, David G. Novick, Mark Fanty, Pieter Vermeulen, Stephen Sutton, Dan Burnett and Johan Schalkwyk 
Address: 20000 N.W. Walker Road, P.O. Box 91000, Portland, OR 97291-1000, USA  
Affiliation: Center  Oregon Graduate Institute of Science and Technology  
Abstract: This paper describes a study conducted to determine the feasibility of using a spoken questionnaire to collect information for the Year 2000 Census in the USA. To refine the dialogue and to train recognizers, we collected complete protocols from over 4000 callers. For the responses labeled (about half), over 99 percent of the answers contain the desired information. The recognizers trained so far range in performance from 75 percent correct on year of birth to over 99 percent for marital status. We developed a prototype system that engages the callers in a dialogue to obtain the desired information, reviews the recognized information at the end of the call, and asks the caller to identify the response categories that are incorrect. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J.-M. Boite, H. Bourlard, B. D'hoore, and M. </author> <month> Haesen </month> <year> (1993), </year> <title> "A new approach towards keyword spotting," </title> <booktitle> Proceedings of the 3rd European Conference on Speech Communication and Technology, </booktitle> <address> Berlin, </address> <month> Sep. </month> <pages> 21-23, </pages> <year> 1993, </year> <pages> pp. 1273-1276. </pages>
Reference-contexts: SYSTEM 2.1. Recognition Signal Processing. The caller's response is transmitted over the digital phone line as a 8 kHz mu-law encoded digital signal. A seventh order Perceptual Linear Predictive (PLP) analysis <ref> [1] </ref> is performed every 6 msec using a 10 msec window. Phonetic Classification. Each 6 msec frame of the signal is classified phonetically by a three layer neural network.
Reference: 2. <author> M. Cohen, H. Franco, N. Morgan, D. Rumelhart and V. Abrash. </author> <title> "Context-dependent multiple distribution phonetic modeling with mlps," </title> <editor> in J.D. Cowan S.J. Han-son and C.L. Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 5, </volume> <pages> pages 649-657. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: The outputs of the network fall in the range (0,1) because of the sigmoid transfer function, and, ideally, approximate the a posteriori probability of that phoneme given the input <ref> [2] </ref>. These values are divided by the prior probability of the phoneme in the training set [3]. Training the Classifiers. Training the neural network required phonetically segmented data.
Reference: 3. <author> H. Bourlard and C.J. Wellekens, </author> <year> (1989), </year> <title> "Links between Markov models and multilayer perceptrons," </title> <booktitle> Advances in Neural Information Processing Systems 1, </booktitle> <publisher> (Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1989), </year> <pages> pages 502-510. </pages>
Reference-contexts: The outputs of the network fall in the range (0,1) because of the sigmoid transfer function, and, ideally, approximate the a posteriori probability of that phoneme given the input [2]. These values are divided by the prior probability of the phoneme in the training set <ref> [3] </ref>. Training the Classifiers. Training the neural network required phonetically segmented data. We used a semiautomatic procedure that involved hand transcription at the word level of about a quarter of the corpus and automatic generation of "forced" phonetic alignment of these transcriptions using a classifier trained on a different task.
Reference: 4. <author> M. Fanty, R. A. Cole and K. Roginski, </author> <year> (1992), </year> " <title> English alphabet recognition with telephone speech," </title> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992). </year>
Reference-contexts: In addition, phoneme segments which exceed expected duration limits are penalized on a frame-by-frame basis. As of this writing, all transitions in the pronunciation graphs for the regular vocabulary and grammar have "probabilities" of 1.0 and do not contribute to the score. A word-dependent N-Best search is performed <ref> [4] </ref> so that the top two hypotheses can be retrieved. Word Spotting. While the vast majority of the responses in the 4000-call corpus are succinct, there are enough responses with "extraneous" speech that it needed to be dealt with.
Reference: 5. <author> H. Hermansky, </author> <year> (1990), </year> <title> "Perceptual linear predictive PLP analysis for speech," </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> Vol. 87(4), </volume> <pages> pp. 1738-1752. </pages>
Reference-contexts: However, because the majority of responses are succinct, our initial system has a simple word spotting approach in which all words and sounds not in the target set match a single garbage model. We use the approach described in <ref> [5] </ref>, in which the output score for the garbage word is computed as the median value of the top N phoneme scores for each frame, where N varies with the task and is set empirically.
Reference: 6. <author> N. Morgan and H. </author> <title> Bourlard (1990), "Continuous speech recognition using multilayer perceptrons with hidden Markov models," </title> <booktitle> Proceedings of the 1990 International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pp. 413-416. </pages>
Reference-contexts: Only responses containing a target word were run. The data collected for this task is noisier than other corpora we have collected. It is also regionally very diverse. Name Recognition. The OGI name retrieval algorithm is designed for spelling with pauses between the letters <ref> [6] </ref>. However, callers were not asked to pause during the collection of this corpus in order to create a data set on which to develop fluent letter recognition. Other than retraining the classifier, the system architecture has not yet changed. In particular, alternate segmentations are not considered.
Reference: 7. <author> R. Schwartz and S. Austin, </author> <title> "A comparison of several approximate algorithms for finding multiple (n-best) sentence hypotheses," </title> <booktitle> Proceedings of the 1991 International Conference on Acoustics, Speech, and Signal Processing, ( IEEE, </booktitle> <year> 1991), </year> <pages> pp. </pages> <address> I1-I4. </address> <month> 4 </month>
Reference-contexts: Most remaining errors can be identified automatically using measures of confidence applied to the recognition scores. For the more difficult recognition tasks, additional work is required to achieve acceptable levels of performance. We are currently investigating two promising approaches: using context dependent phonetic networks, following <ref> [7] </ref>; and performing word-specific reclassification following the initial recognition. There is much work yet to be done to produce a robust and graceful spoken language system for this task. The prototype system described was developed as part of a feasibility study.
References-found: 7

