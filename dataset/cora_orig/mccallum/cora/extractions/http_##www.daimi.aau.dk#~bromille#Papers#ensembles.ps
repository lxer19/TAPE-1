URL: http://www.daimi.aau.dk/~bromille/Papers/ensembles.ps
Refering-URL: http://www.daimi.aau.dk/~bromille/Papers/index.html
Root-URL: http://www.daimi.aau.dk
Email: bromille@daimi.aau.dk  
Title: The Complexity of Malign Ensembles  
Author: Peter Bro Miltersen 
Address: Ny Munkegade, DK 8000 Aarhus C.  
Affiliation: Computer Science Department, Aaarhus University,  
Abstract: We analyze the concept of malignness, which is the property of probability ensembles of making the average case running time equal to the worst case running time for a class of algorithms. We derive lower and upper bounds on the complexity of malign ensembles, which are tight for exponential time algorithms, and which show that no polynomial time computable malign ensemble exists for the class of polynomial time algorithms. Furthermore, we show that for no class of superlinear algorithms a polynomial time computable malign ensemble exists, unless every language in P has an expected polynomial time constructor. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Ben-David, B. Chor, O. Goldreich and M. Luby, </author> <title> On the theory of average case complexity, </title> <booktitle> in Proc. 21st Annual ACM Symposium on Theory of Computing, </booktitle> <address> Seattle, WA, </address> <month> May </month> <year> 1989, </year> <pages> pp. 204-216. </pages>
Reference-contexts: However, since the Solomonoff-Levin measure is not even recursive, their result fits poorly with the traditional complexity theoretic view on average case complexity, founded by Levin in [3] and extended in [2] and <ref> [1] </ref>. In Levins approach to average case complexity, the distribution function of the input measure is required to be polynomial time computable. <p> Consequently, from now on we require that the measures we consider are normalized. 4 Malign ensembles Definition 4.1 A probability ensemble (or merely ensemble) is a measure : fl ! <ref> [0; 1] </ref>, with ( n ) = 1 for all n. Thus, if is an ensemble, (x) = jxj (x) for all x. Definition 4.2 An ensemble is called polynomial time computable if and only if its family of distribution functions x ! fl jxj (x) is polynomial time computable. <p> on input &lt; 1 n ; 1 i &gt; produces a string of length n, M (n; i) such that for all x 2 n jPr (M (n; i) = x) n (x)j 2 i A similar definition and a analogy to the following the orem can be found in <ref> [1] </ref>. Theorem 5.2 Every ensemble in PE is polynomial time samplable. Proof The proof is similar to the one in [1]. First, we construct a probabilistic algorithm A with no time bound, whose outputs follow the distribution n exactly. <p> for all x 2 n jPr (M (n; i) = x) n (x)j 2 i A similar definition and a analogy to the following the orem can be found in <ref> [1] </ref>. Theorem 5.2 Every ensemble in PE is polynomial time samplable. Proof The proof is similar to the one in [1]. First, we construct a probabilistic algorithm A with no time bound, whose outputs follow the distribution n exactly. Given a finite string b = b 1 b 2 : : : b j we denote by val (b) the number P j i=1 b i 2 i . <p> Given a one-way infinite tape b = b 1 b 2 : : :, we denote by val (b) the number P 1 i=1 b i 2 i . That is, val (b) is b read as the binary expansion of a real in the interval <ref> [0; 1] </ref>. Clearly, if b is a random tape, the random variable val (b) is uniformly distributed in [0; 1]. <p> That is, val (b) is b read as the binary expansion of a real in the interval <ref> [0; 1] </ref>. Clearly, if b is a random tape, the random variable val (b) is uniformly distributed in [0; 1].
Reference: [2] <author> Y. Gurevich, </author> <title> Complete and incomplete randomized NP problems, </title> <booktitle> Proc. 28th Annual Symposium on Foundations of Computer Science, </booktitle> <address> Los Angeles, CA, </address> <month> October </month> <year> 1987, </year> <pages> pp. 111-117. </pages>
Reference-contexts: However, since the Solomonoff-Levin measure is not even recursive, their result fits poorly with the traditional complexity theoretic view on average case complexity, founded by Levin in [3] and extended in <ref> [2] </ref> and [1]. In Levins approach to average case complexity, the distribution function of the input measure is required to be polynomial time computable.
Reference: [3] <author> L.A. Levin, </author> <title> Average case complete problems, </title> <note> Siam J. Comput., 15 (1986) pp. 285-286. </note>
Reference-contexts: However, since the Solomonoff-Levin measure is not even recursive, their result fits poorly with the traditional complexity theoretic view on average case complexity, founded by Levin in <ref> [3] </ref> and extended in [2] and [1]. In Levins approach to average case complexity, the distribution function of the input measure is required to be polynomial time computable.
Reference: [4] <author> M. Li, P.M.B. Vitanyi, </author> <title> A theory of learning simple concepts under simple distributions and average case complexity for the universal distribution, </title> <booktitle> in Proc. 30th Annual Symposium on Foundations of Computer Science, </booktitle> <address> Research Triangle Park, NC, </address> <month> October </month> <year> 1989, </year> <pages> pp. 34-39. </pages>
Reference-contexts: 1 Introduction The average case time complexity of specific algorithms has for a number of years been an active area of research, often showing significant improvement over the worst case complexity when specific distributions of the inputs were assumed. Recently, Li and Vitanyi <ref> [4] </ref> studied the Solomonoff-Levin measure m and found that when the inputs to any algorithm are distributed according to this measure, it holds that the algorithm's average case complexity is of the same order of magnitude as its worst case complexity. <p> Therefore, the result seems to imply that worst case strings or strings close to worst case will be easily describable. In <ref> [4] </ref>, the example of quicksort is given, where the worst case strings are the sorted or almost sorted ones. These have short descriptions, and hence high Solomonoff-Levin measure. <p> Therefore, unless we can derive some kind of time bounded version of Li and Vitanyi's result, the two subjects seem quite unrelated, although some of the consequences are similar <ref> [4] </ref>. In this paper, we analyze from a complexity-theoretic perspective the property of malignness. For this, we restate Li and Vitanyi's result and give a simple proof. It seems that the counterintuitive property of malignness is dependent upon an exponential time pattern, which makes the above interpretations less obvious. <p> We present a number of results which support this. Our results pose a limit on the results achievable in the average case direction by the time bounded versions of the Solomonoff-Levin measure, which are also discussed in <ref> [4] </ref>. <p> We give a direct proof and skip the con ceptual developments of <ref> [4] </ref>. We consider the class of Turing machines, where each machine has three tapes, * A binary input tape, infinite in one direction, with the restriction that the head can only move in this direction. <p> Actually, it is closely tied to self-delimiting Kolmogorov complexity of x, K (x), since m (x) = fi (2 K (x) ), but we do not need this result here (see <ref> [4] </ref> for a proof, and [5] and [6] for general discussions of the properties of m). <p> The following is the main result from <ref> [4] </ref> on average case complexity. Theorem 3.1 (Li and Vitanyi) The Solomonoff-Levin measure m is malign for all algorithms. Proof Consider the Turing machine M in figure 1. Assume M = M k in the above enumeration, and as Read the prefix 1 i 0, i 0 from the tape. <p> In <ref> [4] </ref>, Li and Vitanyi use quicksort as an example, where the worst case inputs are the ones already sorted - i.e. inputs with lots of pattern. Theorem 3.1 then suggests that this is a general phenomenon.
Reference: [5] <author> M. Li, P.M.B. Vitanyi, </author> <title> Inductive reasoning and Kolmogorov complexity, </title> <booktitle> in Proc. 4th Annual Structure in Complexity Theory Conference, </booktitle> <month> June </month> <year> 1989, </year> <pages> pp. 165-185. </pages>
Reference-contexts: In [4], the example of quicksort is given, where the worst case strings are the sorted or almost sorted ones. These have short descriptions, and hence high Solomonoff-Levin measure. That worst case strings in general are easily de scribable seems counterintuitive. * Li and Vitanyi argue in <ref> [5] </ref> that the Solomonoff-Levin measure should be used as the a priori probability in Bayesian reasoning, because, in a certain sense, it lies close to any r.e. measure (it dominates them multiplicatively). <p> Actually, it is closely tied to self-delimiting Kolmogorov complexity of x, K (x), since m (x) = fi (2 K (x) ), but we do not need this result here (see [4] for a proof, and <ref> [5] </ref> and [6] for general discussions of the properties of m).
Reference: [6] <author> M. Li, P.M.B. Vitanyi, </author> <title> Kolmogorov complexity and its applications, </title> <booktitle> Handbook of theoretical computer science, </booktitle> <editor> ed. Jan van Leeuwen, </editor> <publisher> Elsevier Science Publishers B.V., </publisher> <address> Amsterdam, </address> <year> 1990, </year> <pages> pp. 187-254. </pages>
Reference-contexts: Actually, it is closely tied to self-delimiting Kolmogorov complexity of x, K (x), since m (x) = fi (2 K (x) ), but we do not need this result here (see [4] for a proof, and [5] and <ref> [6] </ref> for general discussions of the properties of m). <p> By a technique similar to the above proof, we can also prove that no recursive measure is malign for the class of all algorithms. This implies that the Solomonoff-Levin measure is not recursive (of course, we could have proven this in a more direct way, see <ref> [6] </ref>). For polynomial time algorithms, we have Corollary 4.2 No ensemble 2 PE is malign for the class of polynomial time algorithms. 5 Malign ensembles for classes of fast algorithms Corollary 4.2 still leaves something to be desired.
Reference: [7] <author> J. Hartmanis, </author> <title> On sparse sets in NP - P, </title> <journal> Inform. Process. Lett., </journal> <note> 16 (1983) pp. 55-60. </note>
Reference-contexts: Hence, RE should be considered a rather small extension of E, and RE = NE, where NE = [ c0 NTIME (2 cn ) must be considered only slightly more plausible than E = NE. Actually, by a proof identical to the one used by Hartmanis in <ref> [7] </ref>, RE = NE if and only if there are no sparse languages in NP RP. Theorem 5.4 If every L 2 P has an expected polyno mial time constructor, then RE = NE.
Reference: [8] <author> L.A. Sanchis, M.A. Fulk, </author> <title> On the efficient generation of language instances, </title> <note> Siam J. Comput., 19 (1990) pp. 281-296. </note>
Reference-contexts: This is a natural generalization of the deterministic constructors defined and studied by Sanchis and Fulk in <ref> [8] </ref>. A useful equivalence is Lemma 5.1 Every L 2 P has an expected polynomial time constructor if and only if every L 2 DTIME (n) has one. Proof Suppose every L 2 DTIME (n) has a constructor. Let J be a language in P. <p> Thus, runnning M several times on input &lt; 1 n ; 1 d log c 4 e+n &gt; until an element of L is produced is a construction of such an element in expected polynomial time. 2 The following theorem (an analog to proposition 4.1 in <ref> [8] </ref>) makes expected polynomial time constructors for all languages in P unlikely.
Reference: [9] <author> A.K. Zvonkin, L.A. Levin, </author> <title> The complexity of finite objects and the development of the concepts of information and randomness by means of the theory of algorithms, </title> <journal> Russian Math. Surveys, </journal> <note> 25 (1970) pp. 83-124. </note>
Reference-contexts: The Solomonoff-Levin measure m (x) of a string x 2 n is then defined as the probability that U halts, outputting x. Since U of course has a non-zero probability of not halting, we have that X m (x) &lt; 1: The Solomonoff-Levin measure was first defined rigorously in <ref> [9] </ref>. Intuitively, it gives a large amount of measure to strings with lots of pattern, since these have short programs which have a high probability of appearing.
References-found: 9

