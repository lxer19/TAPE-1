URL: ftp://ftp.research.microsoft.com/pub/analysts/sequent.ps.Z
Refering-URL: http://www.research.microsoft.com/~rusa/papers.html
Root-URL: http://www.research.microsoft.com
Email: rusa@research.microsoft.com  
Phone: Phone: (206) 936-2435  
Title: Sequentializing Program Dependence Graphs for Irreducible Programs  
Author: Bjarne Steensgaard 
Address: One Microsoft Way Redmond, WA 98052  
Affiliation: Microsoft Research  
Abstract: Compilers using a parallel intermediate program representation like the program dependence graph must sequentialize the code as part of code generation. We have taken the final steps needed to solve the problem of converting a program dependence graph representation into a control flow graph representation for irreducible programs. We have done this without increasing the computational complexity of the fastest previously published algorithm unable to handle irreducible programs. We introduce the concepts of loop entry nodes and loop closing edges, which are generalizations of loop headers and backedges. Using these nodes, we can perform the necessary preprocessing without fixpoint iteration. 
Abstract-found: 1
Intro-found: 1
Reference: [AHU74] <author> Alfred V. Aho, John E. Hopcroft, and Jef-frey D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: Instead of a definition of nested SCRs, an algorithm for finding them and simultaneously finding the loop header nodes and loop closing edges is given. 1 3 - 6 The algorithm proceeds iteratively by first identifying ordinary SCRs for rooted graphs (e.g., using Tarjan's algorithm <ref> [AHU74] </ref>). The loop entry nodes and loop closing edges are then found for the identified loop bodies. The process is repeated by identifying SCRs and loop bodies in the graph without the already identified loop closing edges, and finding loop entry nodes and loop closing edges for those loop bodies.
Reference: [Bal93] <author> Thomas Jaudon Ball. </author> <title> The use of control-flow and control dependence in software tools. </title> <type> Technical Report 1169, </type> <institution> University of Wiscon-sin - Madison, </institution> <month> August </month> <year> 1993. </year> <type> PhD thesis. </type>
Reference-contexts: They use their algorithm in combination with a CFG-to-CDG conversion to check for conflicts in a version control system. They ignore data dependences in the PDG, so their algorithm cannot be used to generate programs. In his thesis, Ball shows how to take data dependences into account <ref> [Bal93] </ref>. 2 The Program Dependence Graph The program dependence graph (PDG) is a program representation suggested by Ferrante, Ottenstein and Warren [FOW87]. It is an incomplete representation of a sequential program, as there may be several sequential programs having the same PDG.
Reference: [BH92] <author> Thomas Ball and Susan Horwitz. </author> <title> Contructing control flow from control dependence. </title> <type> Technical Report TR No. 1091, </type> <institution> University of Wis-consin | Madison, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: Our work is an extension of this algorithm. The previous papers all describe sequentialization of 1 a PDG whose constituent CDG is as defined by Ballance and Maccabe [BM92]. Ball and Horwitz also developed an algorithm for constructing a CFG from a CDG <ref> [BH92] </ref>. Their algorithm works for CDGs as defined by Ferrante, Ottenstein and Warren [FOW87] 1 . They use their algorithm in combination with a CFG-to-CDG conversion to check for conflicts in a version control system.
Reference: [BM92] <author> Robert A. Ballance and Arthur B. Maccabe. </author> <title> Program dependence graphs for the rest of us. </title> <type> Technical Report TR 92-10, </type> <institution> Department of Computer Science, The University of New Mexico, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: Our work is an extension of this algorithm. The previous papers all describe sequentialization of 1 a PDG whose constituent CDG is as defined by Ballance and Maccabe <ref> [BM92] </ref>. Ball and Horwitz also developed an algorithm for constructing a CFG from a CDG [BH92]. Their algorithm works for CDGs as defined by Ferrante, Ottenstein and Warren [FOW87] 1 . They use their algorithm in combination with a CFG-to-CDG conversion to check for conflicts in a version control system. <p> The PDG consists of a data dependence graph (DDG) and a control dependence graph (CDG). The DDG reflects dependences between computations. The CDG reflects under what conditions computations must be executed. Some intuition about the PDG and how to translate common constructs into a CDG is given in <ref> [BM92, FOW87] </ref>. The DDG part of the PDG is not well defined. Any kind of data dependence edges may be part of the data dependence graph (e.g., def-use, anti-dependence, output-dependence, etc.). <p> The only requirement is that there must be enough information in the DDG to make the PDG executable (represent a deterministic program). The CDG part of the PDG we will sequentialize is the CDG as defined in <ref> [BM92] </ref>. In the context of sequen-tializing, the structure of the control dependence graph is very important. The following is a description of the CDG structure and the constraints imposed on it A CDG is a rooted graph. The nodes of the CDG are root, region, predicate, and statement nodes. <p> Region nodes represent a set of computations to be executed under the same conditions (the 1 The details of the differences between the definitions of the CDG in [FOW87] and <ref> [BM92] </ref> are outside the scope of this paper. same control dependence). Region nodes may have multiple children and multiple parents in the CDG. Region nodes are the only nodes that may have multiple parents. The root node is a special kind of region node that does not have any parents.
Reference: [FM85] <author> Jeanne Ferrante and Mary Mace. </author> <title> On linearizing parallel code. </title> <booktitle> In Proceedings of the Twelfth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 179-190, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: We show how to solve the necessary dataflow problems rapidly using these nodes to guide processing of the nodes in the graph. 1.1 Related Work Ferrante and Mace did the initial work on generating sequential code from a PDG <ref> [FM85] </ref>. Their algorithm only handled PDGs for some programs; due to an oversight, the subset handled correctly is even smaller than the one they claimed to handle. A follow-up paper by Ferrante, Mace, and Simons [FMS88] gives more detail about this work but does not correct the oversight. <p> else goto reg 2 reg 1 : Stmnt 1 if (P 2 ) then goto reg 2 else goto fin reg 2 : Stmnt 2 fin: Root If 1 Region 1 Stmnt 1 If 2 Region 2 Stmnt 2 ? ff AU AU ? 3 The Problem It is demonstrated <ref> [FM85] </ref> and proved [SAF90] that the problem of generating sequential code for a PDG can be phrased as a problem of ordering sibling subgraphs in the constituent CDG. Sibling subgraphs are children of the same region, entry, or root node.
Reference: [FMS88] <author> Jeanne Ferrante, Mary Mace, and Barbara Si-mons. </author> <title> Generating sequential code from parallel code. </title> <booktitle> In Proceedings of the 1988 International Conference on Supercomputing, </booktitle> <pages> pages 582-592, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: We only consider PDGs for which code duplication or insertion of extra predicates is not necessary. As the algorithm that our work is based upon the algorithm indicates where code duplication or insertion of extra predicates is needed <ref> [FMS88, SAF90, SF93] </ref>. The contribution of this paper is the extension of the previous work on sequentializing parallel program representations to handle programs with arbitrary control flow (i.e., irreducible programs). To achieve this goal, we introduce the concept of loop entry nodes and loop closing edges in rooted directed graphs. <p> Their algorithm only handled PDGs for some programs; due to an oversight, the subset handled correctly is even smaller than the one they claimed to handle. A follow-up paper by Ferrante, Mace, and Simons <ref> [FMS88] </ref> gives more detail about this work but does not correct the oversight. Simons, Alpern, and Ferrante [SAF90] take a more mathematical approach and present a correct algorithm for PDGs with acyclic CDGs.
Reference: [FOW87] <author> Jeanne Ferrante, Karl J. Ottenstein, and Joe D. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: The previous papers all describe sequentialization of 1 a PDG whose constituent CDG is as defined by Ballance and Maccabe [BM92]. Ball and Horwitz also developed an algorithm for constructing a CFG from a CDG [BH92]. Their algorithm works for CDGs as defined by Ferrante, Ottenstein and Warren <ref> [FOW87] </ref> 1 . They use their algorithm in combination with a CFG-to-CDG conversion to check for conflicts in a version control system. They ignore data dependences in the PDG, so their algorithm cannot be used to generate programs. <p> They ignore data dependences in the PDG, so their algorithm cannot be used to generate programs. In his thesis, Ball shows how to take data dependences into account [Bal93]. 2 The Program Dependence Graph The program dependence graph (PDG) is a program representation suggested by Ferrante, Ottenstein and Warren <ref> [FOW87] </ref>. It is an incomplete representation of a sequential program, as there may be several sequential programs having the same PDG. Two sequential programs with the same PDG are semantically equivalent [PS91]. The PDG consists of a data dependence graph (DDG) and a control dependence graph (CDG). <p> The PDG consists of a data dependence graph (DDG) and a control dependence graph (CDG). The DDG reflects dependences between computations. The CDG reflects under what conditions computations must be executed. Some intuition about the PDG and how to translate common constructs into a CDG is given in <ref> [BM92, FOW87] </ref>. The DDG part of the PDG is not well defined. Any kind of data dependence edges may be part of the data dependence graph (e.g., def-use, anti-dependence, output-dependence, etc.). <p> Region nodes represent a set of computations to be executed under the same conditions (the 1 The details of the differences between the definitions of the CDG in <ref> [FOW87] </ref> and [BM92] are outside the scope of this paper. same control dependence). Region nodes may have multiple children and multiple parents in the CDG. Region nodes are the only nodes that may have multiple parents.
Reference: [KU76] <author> John B. Kam and Jeffrey D. Ullman. </author> <title> Global data flow analysis and iterative algorithms. </title> <journal> Journal of the ACM, </journal> <volume> 23(1) </volume> <pages> 158-171, </pages> <month> January </month> <year> 1976. </year>
Reference-contexts: We show how to compute the same preprocessing information for CDGs with entry and close nodes and possibly with multiple entry loops. An important result of this paper is how to perform the preprocessing in a constant number of passes, regardless of the loop interconnectedness <ref> [KU76] </ref> of the graph.
Reference: [PS91] <author> Phil Pfeiffer and Rebecca Parsons Selke. </author> <title> On the adequacy of dependence-based representations for programs with heaps. </title> <booktitle> In Proceedings of the International Conference on Theoretical Aspects of Computer Software, </booktitle> <pages> pages 365-386, </pages> <year> 1991. </year>
Reference-contexts: It is an incomplete representation of a sequential program, as there may be several sequential programs having the same PDG. Two sequential programs with the same PDG are semantically equivalent <ref> [PS91] </ref>. The PDG consists of a data dependence graph (DDG) and a control dependence graph (CDG). The DDG reflects dependences between computations. The CDG reflects under what conditions computations must be executed.
Reference: [SAF90] <author> Barbara Simons, David Alpern, and Jeanne Ferrante. </author> <title> A foundation for sequentializing parallel code | extended abstract. </title> <booktitle> In Proceedings of the 2nd ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 350-359, </pages> <year> 1990. </year>
Reference-contexts: The parallel program representation considered is the program dependence graph (PDG). A PDG is a combination of a control dependence graph (CDG) and a data dependence graph (DDG). Earlier work <ref> [SAF90, SF93] </ref> gave algorithms for sequentializing PDGs without loops in the CDG. The same papers sketch how to handle CDGs with single entry loops. We extend this existing work to work for CDGs with arbitrary loops. <p> The generated CFG should ideally contain no more computation statements/nodes than the PDG does. For some PDGs code duplication or insertion of extra predicates is necessary to generate a CFG representation of the same program <ref> [SAF90] </ref>. We only consider PDGs for which code duplication or insertion of extra predicates is not necessary. As the algorithm that our work is based upon the algorithm indicates where code duplication or insertion of extra predicates is needed [FMS88, SAF90, SF93]. <p> We only consider PDGs for which code duplication or insertion of extra predicates is not necessary. As the algorithm that our work is based upon the algorithm indicates where code duplication or insertion of extra predicates is needed <ref> [FMS88, SAF90, SF93] </ref>. The contribution of this paper is the extension of the previous work on sequentializing parallel program representations to handle programs with arbitrary control flow (i.e., irreducible programs). To achieve this goal, we introduce the concept of loop entry nodes and loop closing edges in rooted directed graphs. <p> A follow-up paper by Ferrante, Mace, and Simons [FMS88] gives more detail about this work but does not correct the oversight. Simons, Alpern, and Ferrante <ref> [SAF90] </ref> take a more mathematical approach and present a correct algorithm for PDGs with acyclic CDGs. The paper contains a proof of correctness for the algorithm applied to such PDGs, for which there exists a corresponding concise CFG. <p> The no postdomi-nance rule is necessary for eliminating unnecessary control dependence. As in <ref> [SAF90, SF93] </ref>, additional restrictions are imposed on the structure of the CDG. We state these restrictions for the CDG after the transformations in Section 5.1 have been performed, as the rules are complicated to state for the CDG before the transformations. <p> 2 reg 1 : Stmnt 1 if (P 2 ) then goto reg 2 else goto fin reg 2 : Stmnt 2 fin: Root If 1 Region 1 Stmnt 1 If 2 Region 2 Stmnt 2 ? ff AU AU ? 3 The Problem It is demonstrated [FM85] and proved <ref> [SAF90] </ref> that the problem of generating sequential code for a PDG can be phrased as a problem of ordering sibling subgraphs in the constituent CDG. Sibling subgraphs are children of the same region, entry, or root node. <p> The external edge into the "If 2 " subgraph forces that subgraph to be scheduled after "Stmnt 1 ". Previous algorithms <ref> [SAF90, SF93] </ref> for ordering subgraphs according to the structure of the CDG do not work correctly for programs with multiple entry loops in the CDG. Programs with multiple entry loops in the CDG correspond to irreducible sequential programs. <p> We use the fact that sequentializing a constituent PDG amounts to ordering sibling subgraphs of the CDG if the CDG obeys the structural rules stated in Section 2 (this has been proved for acyclic graphs <ref> [SAF90] </ref>). In the presence of multiple entry loops in the CDG it is still possible to use the concept of external edges into subgraphs to order sibling subgraphs. In the previous algorithm [SF93], the CDG was acyclic and the subgraph of a node well defined. <p> The eec information for all nodes in the shown CDGs is listed in Table 2. 5.3 Computing a partial ordering of computations A subgraph represents a set of computations that can be scheduled as a unit relative to sibling subgraphs <ref> [SAF90] </ref>. Specifying an order for sibling subgraphs effectively reduces the problem of generating a CFG from the PDG to a simple traverse-and-link problem. In this section we show how to order sibling subgraphs. The ordering rules can specify a cyclic ordering of subgraphs. <p> In this section we show how to order sibling subgraphs. The ordering rules can specify a cyclic ordering of subgraphs. A cyclic ordering means that it is not possible to construct a CFG from the CDG without duplicating code or inserting extra predicates <ref> [SAF90, SF93] </ref>. The eec information is used both to determine whether there are external edges into a subgraph and to determine whether a certain subgraph is executed whenever a sibling subgraph is executed. If X 62 eec (X), then an external edge into G (X) exists.
Reference: [SF93] <author> Barbara Simons and Jeanne Ferrante. </author> <title> An efficient algorithm for constructing a control flow graph for parallel code. </title> <type> Technical Report TR 03.465, </type> <institution> IBM, Santa Teresa Laboratory, </institution> <address> San Jose, California, </address> <month> February </month> <year> 1993. </year> <pages> Page 9 </pages>
Reference-contexts: The parallel program representation considered is the program dependence graph (PDG). A PDG is a combination of a control dependence graph (CDG) and a data dependence graph (DDG). Earlier work <ref> [SAF90, SF93] </ref> gave algorithms for sequentializing PDGs without loops in the CDG. The same papers sketch how to handle CDGs with single entry loops. We extend this existing work to work for CDGs with arbitrary loops. <p> We only consider PDGs for which code duplication or insertion of extra predicates is not necessary. As the algorithm that our work is based upon the algorithm indicates where code duplication or insertion of extra predicates is needed <ref> [FMS88, SAF90, SF93] </ref>. The contribution of this paper is the extension of the previous work on sequentializing parallel program representations to handle programs with arbitrary control flow (i.e., irreducible programs). To achieve this goal, we introduce the concept of loop entry nodes and loop closing edges in rooted directed graphs. <p> The paper contains a proof of correctness for the algorithm applied to such PDGs, for which there exists a corresponding concise CFG. The paper contains a sketch of how to handle CDGs with single entry loops. Simons and Ferrante <ref> [SF93] </ref> presents an algorithm with a much better time complexity. The major contribution of [SF93] is a preprocessing mechanism that makes information about external edges into subgraphs available in every CDG node. This makes it possible to order two sibling subgraphs in constant time. <p> The paper contains a sketch of how to handle CDGs with single entry loops. Simons and Ferrante <ref> [SF93] </ref> presents an algorithm with a much better time complexity. The major contribution of [SF93] is a preprocessing mechanism that makes information about external edges into subgraphs available in every CDG node. This makes it possible to order two sibling subgraphs in constant time. <p> The no postdomi-nance rule is necessary for eliminating unnecessary control dependence. As in <ref> [SAF90, SF93] </ref>, additional restrictions are imposed on the structure of the CDG. We state these restrictions for the CDG after the transformations in Section 5.1 have been performed, as the rules are complicated to state for the CDG before the transformations. <p> The external edge into the "If 2 " subgraph forces that subgraph to be scheduled after "Stmnt 1 ". Previous algorithms <ref> [SAF90, SF93] </ref> for ordering subgraphs according to the structure of the CDG do not work correctly for programs with multiple entry loops in the CDG. Programs with multiple entry loops in the CDG correspond to irreducible sequential programs. <p> In the presence of multiple entry loops in the CDG it is still possible to use the concept of external edges into subgraphs to order sibling subgraphs. In the previous algorithm <ref> [SF93] </ref>, the CDG was acyclic and the subgraph of a node well defined. In the sketch of how to extend the algorithm for CDGs with single entry loops, backedges were ignored when computing the nodes of a subgraph. <p> This definition avoids the problems of information that has to be propagated from entry nodes to close nodes (or vice versa) during preprocessing. Page 4 The fastest previous algorithm <ref> [SF93] </ref> used a prepro-cessing mechanism to make information about external edges into subgraphs available in every CDG node. This makes it possible to order two sibling subgraphs possible in constant time. We extend this mechanism to work for CDGs with multiple entry loops. <p> If needed, a region node can be inserted between the entry node and the non-close parents. The transformations are illustrated for the example PDG in Figure 5. 5.2 Preprocessing In <ref> [SF93] </ref>, the CDG is preprocessed before the actual sequentializing phase. The preprocessing information gives information for each node about external edges into subgraphs and enables ordering of two sibling subgraphs in constant time. The cost of preprocessing is O (ne) when using bit-vector operations. <p> The method of computing the preprocessing information for region, predicate, and statement nodes is Root Stmnt 1 Stmnt 2 If 1 Entry 1 Entry 2 Stmnt 3 If 2 Stmnt 4 Close 2 Close 1 ? @ T @ ff A ff A T F ? adapted from <ref> [SF93] </ref>. So is the notation of G (X) meaning the CDG subgraph of X. The method for ordering two sibling subgraphs X and Y in constant time requires knowledge about eec (X) and eec (Y ). The name eec is adopted from [SF93]. <p> A ff A T F ? adapted from <ref> [SF93] </ref>. So is the notation of G (X) meaning the CDG subgraph of X. The method for ordering two sibling subgraphs X and Y in constant time requires knowledge about eec (X) and eec (Y ). The name eec is adopted from [SF93]. It is an acronym for "external edge condition". <p> In The computation of the eec information is performed using the region information for each node in the graph. The name and this two-step method for computing the eec information is adopted from <ref> [SF93] </ref>. Definition 5 (region) region (X) is the set of nodes n such that for all paths, , in the CDG from the root node to X, n has a region, root, or entry node on as a parent. <p> Computing region (X) We first describe how the region information was com puted in <ref> [SF93] </ref>, and then describe how the algorithm must be modified to work for CDGs with multiple entry loops. In [SF93], the region information is computed during a top-down traversal of the CDG, where each node is processed only after all its (non-close) parents have been processed (reverse postorder processing). <p> Computing region (X) We first describe how the region information was com puted in <ref> [SF93] </ref>, and then describe how the algorithm must be modified to work for CDGs with multiple entry loops. In [SF93], the region information is computed during a top-down traversal of the CDG, where each node is processed only after all its (non-close) parents have been processed (reverse postorder processing). <p> Subsequently, the region information is computed for the rest of the loop body. Table 1 lists the region infor mation for all nodes in the shown CDGs. Computing eec (X) We first describe how the eec information was computed in <ref> [SF93] </ref>, and then describe the algorithm for CDGs with multiple entry loops. In [SF93], the eec information is computed via a pos-torder processing of the graph using the region information we just computed. <p> Table 1 lists the region infor mation for all nodes in the shown CDGs. Computing eec (X) We first describe how the eec information was computed in <ref> [SF93] </ref>, and then describe the algorithm for CDGs with multiple entry loops. In [SF93], the eec information is computed via a pos-torder processing of the graph using the region information we just computed. <p> Then eec (X) = i=1 ! When sketching how to handle single entry loops in the CDG, <ref> [SF93] </ref> treats close nodes as leaf nodes. We modify this algorithm to work for CDGs with multiple entry loops. We observe that if E is an entry node, then eec (E)"G (E) fEg. <p> In this section we show how to order sibling subgraphs. The ordering rules can specify a cyclic ordering of subgraphs. A cyclic ordering means that it is not possible to construct a CFG from the CDG without duplicating code or inserting extra predicates <ref> [SAF90, SF93] </ref>. The eec information is used both to determine whether there are external edges into a subgraph and to determine whether a certain subgraph is executed whenever a sibling subgraph is executed. If X 62 eec (X), then an external edge into G (X) exists. <p> The close node in the CDG eventually become a jump in the CFG, and all other computations must be scheduled before the jump if they are to be executed at all. This rule is a refinement of the rule in <ref> [SF93] </ref> for handling subgraphs with backedges. Intuitively, headers and entry nodes become basic blocks in the generated code. Edges to headers and entry nodes become jumps to these basic blocks. The only exception is that some empty basic blocks are not really created because of fall-through. <p> The only exception is that some empty basic blocks are not really created because of fall-through. We are now ready to state the ordering rules for sibling subgraphs X and Y . All the rules except those involving entry or close nodes are similar to the rules listed in <ref> [SF93] </ref>. To make the description simpler we ignore that subgraphs may be marked as having to be scheduled last among all sibling subgraphs. Table 3 is a decision table specifying how to order sibling subgraphs.
References-found: 11

