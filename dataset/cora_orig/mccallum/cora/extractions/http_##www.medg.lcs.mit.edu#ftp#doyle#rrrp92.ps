URL: http://www.medg.lcs.mit.edu/ftp/doyle/rrrp92.ps
Refering-URL: http://www.medg.lcs.mit.edu/ftp/doyle/
Root-URL: 
Email: doyle@lcs.mit.edu  
Title: Rationality and its Roles in Reasoning  
Author: Jon Doyle 
Address: Cambridge, Massachusetts 02139, U.S.A.  
Affiliation: Massachusetts Institute of Technology, Laboratory for Computer Science  
Date: 2 (May 1992),  May 2, 1990, revised January 24, 1992.  
Note: Reset reproduction of article published in Computational Intelligence, Vol. 8, No.  pp. 376-409. Written  Reprinted July 1994. Reprinting c Copyright 1990, 1992, 1994 by Jon Doyle.  
Abstract: The economic theory of rationality promises to equal mathematical logic in its importance for the mechanization of reasoning. We survey the growing literature on how the basic notions of probability, utility, and rational choice, coupled with practical limitations on information and resources, influence the design and analysis of reasoning and representation systems.
Abstract-found: 1
Intro-found: 1
Reference: <author> Agre, P. E. and Chapman, D. </author> <year> 1987. </year> <title> Pengi: An implementation of a theory of activity. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 268-272. </pages>
Reference: <author> Arrow, K. J. </author> <year> 1963. </year> <title> Social Choice and Individual Values. </title> <institution> Yale University Press, </institution> <note> second edition. </note>
Reference: <author> Arrow, K. J. and Raynaud, H. </author> <year> 1986. </year> <title> Social Choice and Multicriterion Decision-Making. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference: <author> Baron, J. </author> <year> 1985. </year> <title> Rationality and Intelligence. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge. </address>
Reference: <author> Becker, G. S. </author> <year> 1976. </year> <title> The Economic Approach to Human Behavior. </title> <publisher> University of Chicago Press, Chicago. </publisher>
Reference: <author> Bentham, J. </author> <title> 1823. </title> <booktitle> Principles of Morals and Legislation. </booktitle> <publisher> Oxford University Press, </publisher> <address> Oxford. </address> <note> Originally published in 1789. </note>
Reference: <editor> Bernoulli, D. </editor> <volume> 1738. </volume> <editor> Specimen theoriae novae de mensura sortis. </editor> <booktitle> Commentarii academiae scientiarum imperialis Petropolitanae (for 1730 and 1731), </booktitle> <volume> 5 </volume> <pages> 175-192. </pages>
Reference: <author> Bratman, M. </author> <year> 1987. </year> <title> Intention, Plans, and Practical Reason. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Breese, J. S. </author> <year> 1987. </year> <title> Knowledge Representation and Inference in Intelligent Decision Systems. </title> <type> Research Report 2, </type> <institution> Rockwell International Science Center, </institution> <address> Palo Alto, CA. </address>
Reference: <author> Breese, J. S. and Fehling, M. R. </author> <year> 1990. </year> <title> Control of problem solving: Principles and architecture. </title> <editor> In Schacter, R. D., Levitt, T. S., et al., editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 4, volume 9 of Machine Intelligence and Pattern Recognition, </booktitle> <pages> pp. 59-68. </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference: <author> Breese, J. S. and Horvitz, E. J. </author> <year> 1990. </year> <title> Ideal reformulation of belief networks. </title> <booktitle> In Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 64-72. </pages>
Reference: <author> Brooks, R. A. </author> <year> 1986. </year> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 2(1) </volume> <pages> 14-23. </pages>
Reference: <author> Cheeseman, P. </author> <year> 1983. </year> <title> A method of computing generalized Bayesian probability values for expert systems. </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <month> 198-202. </month> <title> 32 Rationality and its Roles in Reasoning Cherniak, </title> <address> C. </address> <year> 1986. </year> <title> Minimal Rationality. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Cooper, G. F. </author> <year> 1990. </year> <title> The computational complexity of probabilistic inference using Bayesian belief networks. </title> <journal> Artificial Intelligence, </journal> <note> 42(2-3):393-405. </note> <author> de Finetti, B. </author> <year> 1937. </year> <title> La prevision: see lois logiques, ses sources subjectives. </title> <journal> Annales de l'Institut Henri Poincare, </journal> <volume> 7. </volume>
Reference-contexts: Unfortunately, it can sometimes be hard to carry out inferences in these frameworks, even though they greatly restrict what can be expressed (see <ref> (Cooper, 1990) </ref>). Wellman (1990) goes even further in this direction and provides more general qualitative descriptions of probability distributions, including qualitative probabilistic influences and qualitative synergies. Extending and improving these succinct probabilistic representations constitutes an important open problem.
Reference: <author> Dean, T. and Boddy, M. </author> <year> 1988. </year> <title> An analysis of time-dependent planning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. 49-54. </pages>
Reference: <author> Dean, T. L. and Wellman, M. P. </author> <year> 1991. </year> <title> Planning and Control. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: We will here highlight only some recent work on using techniques from decision theory and operations research in allocating effort within time limitations, which may be soft deadlines in addition to hard deadlines. See <ref> (Dean and Wellman, 1991, Chapter 8) </ref> for a more detailed survey, and (Good, 1962; Simon and Kadane, 1975) for some early discussions of rational control of search. 23 Doyle Russell and Wefald (1991) present their approach to rationally controlling A* and other search methods as a general theory of "metareasoning." In
Reference: <author> Debreu, G. </author> <year> 1959. </year> <title> Theory of Value: an axiomatic analysis of economic equilibrium. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference: <author> DeJong, G. </author> <year> 1983. </year> <title> Acquiring schemata through understanding and generalizing plans. </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 462-464. </pages>
Reference: <author> Doyle, J. </author> <year> 1979. </year> <title> A truth maintenance system. </title> <journal> Artificial Intelligence, </journal> <volume> 12(2) </volume> <pages> 231-272. </pages>
Reference: <author> Doyle, J. </author> <year> 1980. </year> <title> A Model for Deliberation, Action, and Introspection. </title> <type> AI-TR 581, </type> <institution> Mas-sachusetts Institute of Technology, Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA. </address>
Reference-contexts: Making control decisions rationally raises the problem of infinite regress, since trying to control the cost of making rational control decisions by means of additional rational control decisions creates a tower of deliberations, each one concerned with the level below (as in <ref> (Doyle, 1980) </ref>). 11 Thus striking a balance between control and reasoning computations means taking effort expended at all these levels into account.
Reference: <author> Doyle, J. </author> <year> 1983a. </year> <title> The ins and outs of reason maintenance. </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 349-351. </pages>
Reference: <author> Doyle, J. </author> <year> 1983b. </year> <title> Some Theories of Reasoned Assumptions: An Essay in Rational Psychology. </title> <type> Technical Report 83-125, </type> <institution> Computer Science Department, Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference: <author> Doyle, J. </author> <year> 1988a. </year> <title> Artificial Intelligence and Rational Self-Government. </title> <type> Technical Report CS-88-124, </type> <institution> Computer Science Department, Carnegie-Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: More generally, we may call the legal operations and states of the agent its constitution, and divide the constitution into a fixed part unchangeable by the agent and a variable part under its control (see <ref> (Doyle, 1988a) </ref>). <p> An easier task is to compare limitations along each dimension separately, for example, according to the completeness of beliefs and preferences separately, and also according to the strength of underlying inferential systems <ref> (Doyle, 1988a) </ref>. It would also be interesting to define a notion of relative rationality, in analogy with the notion of relative computability. <p> Thinking is costly, and to gain the efficiency in thought that intelligence seems to require, it seems necessary for agents to engage in some form of what one might call rational self-government <ref> (Doyle, 1988a) </ref>. As an added benefit, using the theory of rational choice to recast artificial intelligence ideas makes it easier to relate these ideas to relevant concepts in philosophy, psychology, economics, decision theory, statistics, operations research, management, political theory, sociology, and anthropology.
Reference: <author> Doyle, J. </author> <year> 1988b. </year> <title> Big problems for artificial intelligence. </title> <journal> AI Magazine, </journal> <volume> 9(1) </volume> <pages> 19-22. </pages>
Reference-contexts: and by using the same language they do, artificial intelligence may find more thorough developments of some of its informal ideas, may find some new ideas to apply to formalizing thinking, and perhaps can see more easily which of its own ideas can make a contribution to these other fields <ref> (Doyle, 1988b) </ref>. In spite of its attractions as a precise standard for reasoning and action, the theory of rational choice cannot be adopted uncritically for two reasons. First of all, it places unreasonable demands on the knowledge and inferential abilities of the reasoner.
Reference: <author> Doyle, J. </author> <year> 1989a. </year> <title> Constructive belief and rational representation. </title> <journal> Computational Intelligence, </journal> <volume> 5(1) </volume> <pages> 1-11. </pages>
Reference: <author> Doyle, J. </author> <year> 1989b. </year> <title> Mental constitutions and limited rationality. </title> <editor> In Fehling, M. and Russell, S., editors, </editor> <booktitle> Papers of the AAAI Symposium on AI and Limited Rationality, </booktitle> <pages> pp. 18-22. </pages>
Reference-contexts: This approach gives the appearance of consistency. The use of representations of inconsistent sets of beliefs has close relations with Levesque's (1984) notion of explicit belief, and more specifically, with the notions of manifest and constructive belief <ref> (Doyle, 1989b) </ref> which divide explicit beliefs into the manifest or explicitly represented beliefs and the constructive or implicitly represented beliefs derived when needed.
Reference: <author> Doyle, J. </author> <year> 1990. </year> <title> Rationality and its roles in reasoning (extended abstract). </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 1093-1100. </pages>
Reference-contexts: as rational selection of concept definitions, but it is not apparent that PAC definitions are the same as definitions of maximal expected utility, even under this identification. 5.6 Rational planning Planning involves several tasks (in addition to reasoning and search) in which rational choice may play a significant role (cf. <ref> (Doyle and Wellman, 1990) </ref>). As noted earlier, the very notion of "goal" is suspect, as goals often implicitly involve efficiency considerations. Thus one of the main roles for rational choice is comparison of alternative plans (see (Feldman and Sproull, 1977; Smith, 1988; Langlotz, 1989)). <p> We need to investigate how to integrate these theories in useful ways that recognize that meaning, possibility, utility, and probability must all be evaluated with respect to changing purposes and circumstances. 31 Doyle Acknowledgments This paper is an extended version of an invited talk <ref> (Doyle, 1990) </ref> presented at AAAI-90.
Reference: <author> Doyle, J. </author> <year> 1991a. </year> <title> Rational belief revision (preliminary report). </title> <editor> In Fikes, R. E. and Sande-wall, E., editors, </editor> <booktitle> Proceedings of the Second Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pp. 163-174. </pages> <note> 33 Doyle Doyle, J. </note> <year> 1991b. </year> <title> Reason maintenance and belief revision: Foundations vs. coherence theories. </title> <editor> In Gardenfors, P., editor, </editor> <title> Belief Revision. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge. </address> <note> To appear. </note>
Reference-contexts: In the present setting, this means that the ideal of logical rationality may be completely undercut in some economically rational reasoners, since one may always be able to find sets of preferences which make rational any set or change of beliefs (cf. <ref> (Doyle, 1991a) </ref>). In spite of these difficulties, there does seem to be reason to doubt that economic rationality is the best idealization of human behavior.
Reference: <author> Doyle, J. and Patil, R. S. </author> <year> 1991. </year> <title> Two theses of knowledge representation: Language restrictions, taxonomic classification, and the utility of representation services. </title> <journal> Artificial Intelligence, </journal> <volume> 48(3) </volume> <pages> 261-297. </pages>
Reference-contexts: On the other hand, finite sets of goals provide a focus for reasoning and action in a way that specifying utilities for the infinity of conceivable circumstances does not. To gain the advantages of both goals and preferences, one must introduce some new notion to connect the two. See <ref> (Wellman and Doyle, 1991) </ref> for an approach using multi-attribute descriptions of outcomes to define goals as conditions preferred to their opposites, holding other things equal. 2.3 Decision theory Most work in artificial intelligence that makes use of economic rationality draws on the specific theory of subjective Bayesian decision theory (Savage, 1972), <p> To reason intelligently, the reasoner must know something about the value of information and about which methods for achieving goals are more likely to work than others, and must prudently manage the use of its knowledge and skills by taking into account its own powers, limitations, and reliability (cf. <ref> (Doyle and Patil, 1991) </ref>). For example, for some questions it may be clear that no answer is possible, or that finding the answer will take too long, in which case the reasoner may conclude "I don't know" right away. <p> Different tasks will have different deadlines in different situations (for example, emergency room medical diagnosis has much shorter deadlines than diagnosis in the doctor's office), and deadlines can sometimes be postponed. More generally, the 10 In <ref> (Doyle and Wellman, 1991) </ref>, however, these multiple extensions are viewed as stemming from inconsistent preferences about belief. 13 Doyle reasoner may be able to trade other resources at its disposal for more time (for example, processor speeds might be changed if increased error rates are acceptable). <p> for investigation is how to choose a representation appropriate to the reasoner's situation (an approach which makes beliefs context-sensitive in the sense of Thomason (1986) discussed earlier.) This problem appears to have close connections with the problem of group decision making, and appears to suffer from the same metaphysical difficulties <ref> (Doyle and Wellman, 1991) </ref>. Practical approaches based on credulous representations must also involve a notion of conservatism. If the consistent representation is chosen anew for each action, different actions may be based on inconsistent subsets even if the underlying beliefs have not changed. <p> That is, to be maximally useful, systems should "put themselves in the user's place" by adopting the user's expectations and preferences and making decisions rationally with these adopted attitudes <ref> (Doyle and Patil, 1991) </ref>. 6.7 Design provably rational architectures AI has developed numerous general architectures for representation and reasoning (such as soar (Laird et al., 1987) or prodigy (Minton et al., 1989)), but we lack at present an understanding of whether any of these architectures are rational in any precise sense.
Reference: <author> Doyle, J., Shoham, Y., and Wellman, M. P. </author> <year> 1991. </year> <title> A logic of relative desire (preliminary report). </title> <editor> In Ras, Z. W. and Zemankova, M., editors, </editor> <booktitle> Methodologies for Intelligent Systems, 6, volume 542 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pp. 16-31, </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference-contexts: On the other hand, finite sets of goals provide a focus for reasoning and action in a way that specifying utilities for the infinity of conceivable circumstances does not. To gain the advantages of both goals and preferences, one must introduce some new notion to connect the two. See <ref> (Wellman and Doyle, 1991) </ref> for an approach using multi-attribute descriptions of outcomes to define goals as conditions preferred to their opposites, holding other things equal. 2.3 Decision theory Most work in artificial intelligence that makes use of economic rationality draws on the specific theory of subjective Bayesian decision theory (Savage, 1972), <p> To reason intelligently, the reasoner must know something about the value of information and about which methods for achieving goals are more likely to work than others, and must prudently manage the use of its knowledge and skills by taking into account its own powers, limitations, and reliability (cf. <ref> (Doyle and Patil, 1991) </ref>). For example, for some questions it may be clear that no answer is possible, or that finding the answer will take too long, in which case the reasoner may conclude "I don't know" right away. <p> Different tasks will have different deadlines in different situations (for example, emergency room medical diagnosis has much shorter deadlines than diagnosis in the doctor's office), and deadlines can sometimes be postponed. More generally, the 10 In <ref> (Doyle and Wellman, 1991) </ref>, however, these multiple extensions are viewed as stemming from inconsistent preferences about belief. 13 Doyle reasoner may be able to trade other resources at its disposal for more time (for example, processor speeds might be changed if increased error rates are acceptable). <p> for investigation is how to choose a representation appropriate to the reasoner's situation (an approach which makes beliefs context-sensitive in the sense of Thomason (1986) discussed earlier.) This problem appears to have close connections with the problem of group decision making, and appears to suffer from the same metaphysical difficulties <ref> (Doyle and Wellman, 1991) </ref>. Practical approaches based on credulous representations must also involve a notion of conservatism. If the consistent representation is chosen anew for each action, different actions may be based on inconsistent subsets even if the underlying beliefs have not changed. <p> That is, to be maximally useful, systems should "put themselves in the user's place" by adopting the user's expectations and preferences and making decisions rationally with these adopted attitudes <ref> (Doyle and Patil, 1991) </ref>. 6.7 Design provably rational architectures AI has developed numerous general architectures for representation and reasoning (such as soar (Laird et al., 1987) or prodigy (Minton et al., 1989)), but we lack at present an understanding of whether any of these architectures are rational in any precise sense.
Reference: <author> Doyle, J. and Wellman, M. P. </author> <year> 1990. </year> <title> Rational distributed reason maintenance for planning and replanning of large-scale activities. </title> <editor> In Sycara, K., editor, </editor> <booktitle> Proceedings of the DARPA Workshop on Planning and Scheduling, </booktitle> <pages> pp. 28-36, </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: as rational selection of concept definitions, but it is not apparent that PAC definitions are the same as definitions of maximal expected utility, even under this identification. 5.6 Rational planning Planning involves several tasks (in addition to reasoning and search) in which rational choice may play a significant role (cf. <ref> (Doyle and Wellman, 1990) </ref>). As noted earlier, the very notion of "goal" is suspect, as goals often implicitly involve efficiency considerations. Thus one of the main roles for rational choice is comparison of alternative plans (see (Feldman and Sproull, 1977; Smith, 1988; Langlotz, 1989)). <p> We need to investigate how to integrate these theories in useful ways that recognize that meaning, possibility, utility, and probability must all be evaluated with respect to changing purposes and circumstances. 31 Doyle Acknowledgments This paper is an extended version of an invited talk <ref> (Doyle, 1990) </ref> presented at AAAI-90.
Reference: <author> Doyle, J. and Wellman, M. P. </author> <year> 1991. </year> <title> Impediments to universal preference-based default theories. </title> <journal> Artificial Intelligence, 49(1-3):97-128. </journal>
Reference-contexts: On the other hand, finite sets of goals provide a focus for reasoning and action in a way that specifying utilities for the infinity of conceivable circumstances does not. To gain the advantages of both goals and preferences, one must introduce some new notion to connect the two. See <ref> (Wellman and Doyle, 1991) </ref> for an approach using multi-attribute descriptions of outcomes to define goals as conditions preferred to their opposites, holding other things equal. 2.3 Decision theory Most work in artificial intelligence that makes use of economic rationality draws on the specific theory of subjective Bayesian decision theory (Savage, 1972), <p> To reason intelligently, the reasoner must know something about the value of information and about which methods for achieving goals are more likely to work than others, and must prudently manage the use of its knowledge and skills by taking into account its own powers, limitations, and reliability (cf. <ref> (Doyle and Patil, 1991) </ref>). For example, for some questions it may be clear that no answer is possible, or that finding the answer will take too long, in which case the reasoner may conclude "I don't know" right away. <p> Different tasks will have different deadlines in different situations (for example, emergency room medical diagnosis has much shorter deadlines than diagnosis in the doctor's office), and deadlines can sometimes be postponed. More generally, the 10 In <ref> (Doyle and Wellman, 1991) </ref>, however, these multiple extensions are viewed as stemming from inconsistent preferences about belief. 13 Doyle reasoner may be able to trade other resources at its disposal for more time (for example, processor speeds might be changed if increased error rates are acceptable). <p> for investigation is how to choose a representation appropriate to the reasoner's situation (an approach which makes beliefs context-sensitive in the sense of Thomason (1986) discussed earlier.) This problem appears to have close connections with the problem of group decision making, and appears to suffer from the same metaphysical difficulties <ref> (Doyle and Wellman, 1991) </ref>. Practical approaches based on credulous representations must also involve a notion of conservatism. If the consistent representation is chosen anew for each action, different actions may be based on inconsistent subsets even if the underlying beliefs have not changed. <p> That is, to be maximally useful, systems should "put themselves in the user's place" by adopting the user's expectations and preferences and making decisions rationally with these adopted attitudes <ref> (Doyle and Patil, 1991) </ref>. 6.7 Design provably rational architectures AI has developed numerous general architectures for representation and reasoning (such as soar (Laird et al., 1987) or prodigy (Minton et al., 1989)), but we lack at present an understanding of whether any of these architectures are rational in any precise sense.
Reference: <author> Elster, J. </author> <year> 1979. </year> <title> Ulysses and the Sirens: Studies in Rationality and Irrationality. </title> <publisher> Cambridge Univerisity Press, </publisher> <address> Cambridge. </address>
Reference: <author> Etzioni, O. </author> <year> 1991. </year> <title> Embedding decision-analytic control in a learning architecture. </title> <journal> Artificial Intelligence, 49(1-3):129-159. </journal>
Reference: <author> Fagin, R. and Halpern, J. Y. </author> <year> 1985. </year> <title> Belief, awareness, and limited reasoning: Preliminary report. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 491-501. </pages>
Reference: <author> Fehling, M. R., Einav, D., and Breese, J. S. </author> <year> 1989. </year> <title> Adaptive planning and search. </title> <booktitle> In Proceedings of the AAAI Symposium on AI and Limited Rationality, </booktitle> <pages> pp. 46-54. </pages>
Reference: <author> Feldman, J. A. and Sproull, R. F. </author> <year> 1977. </year> <title> Decision Theory and Artificial Intelligence II: </title> <journal> The hungry monkey. Cognitive Science, </journal> <volume> 1 </volume> <pages> 158-192. </pages>
Reference: <author> Friedman, M. </author> <year> 1953. </year> <title> The methodology of positive economics. In Essays in Positive Economics. </title> <publisher> University of Chicago Press. </publisher>
Reference: <author> Gardenfors, P. </author> <year> 1988. </year> <title> Knowledge in Flux: Modeling the Dynamics of Epistemic States. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: for storing specific information, or if memory decay forces the reasoner to refresh its beliefs periodically. 20 Rationality and its Roles in Reasoning or set of changed beliefs (as in (Harman, 1986)), or axiomatize the logical relationships that must hold between prior beliefs, new information, and posterior beliefs (as in <ref> (Gardenfors, 1988) </ref>). But these principles do not take into account any of the reasoner's preferences among different possible revisions, which means that revisions may be less rational than necessary.
Reference: <author> Gardenfors, P. and Makinson, D. </author> <year> 1988. </year> <title> Revisions of knowledge systems using epistemic entrenchment. </title> <editor> In Vardi, M. Y., editor, </editor> <booktitle> Proceedings of the Second Conference on Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pp. 83-95. </pages>
Reference-contexts: for storing specific information, or if memory decay forces the reasoner to refresh its beliefs periodically. 20 Rationality and its Roles in Reasoning or set of changed beliefs (as in (Harman, 1986)), or axiomatize the logical relationships that must hold between prior beliefs, new information, and posterior beliefs (as in <ref> (Gardenfors, 1988) </ref>). But these principles do not take into account any of the reasoner's preferences among different possible revisions, which means that revisions may be less rational than necessary.
Reference: <author> Gardenfors, P. and Sahlin, N.-E., editors. </author> <year> 1988. </year> <title> Decision, Probability, and Utility: </title> <booktitle> Selected Readings. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge. </address>
Reference-contexts: for storing specific information, or if memory decay forces the reasoner to refresh its beliefs periodically. 20 Rationality and its Roles in Reasoning or set of changed beliefs (as in (Harman, 1986)), or axiomatize the logical relationships that must hold between prior beliefs, new information, and posterior beliefs (as in <ref> (Gardenfors, 1988) </ref>). But these principles do not take into account any of the reasoner's preferences among different possible revisions, which means that revisions may be less rational than necessary.
Reference: <author> Ginsberg, M. L. </author> <year> 1991. </year> <title> The computational value of nonmonotonic reasoning. </title> <editor> In Allen, J., Fikes, R., and Sandewall, E., editors, </editor> <booktitle> Proceedings of the Second International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pp. </pages> <month> 262-268. </month> <title> 34 Rationality and its Roles in Reasoning Good, </title> <editor> I. J. </editor> <year> 1962. </year> <title> A five-year plan for automatic chess. </title> <editor> In Dale, E. and Michie, D., editors, </editor> <booktitle> Machine Intelligence 2, </booktitle> <volume> volume 2, </volume> <pages> pp. 89-118. </pages> <publisher> Oliver and Boyd, London. </publisher>
Reference: <author> Good, I. J. </author> <year> 1971. </year> <title> The probabilistic explication of information, evidence, surprise, causality, explanation, and utility. </title> <editor> In Godambe, V. P. and Sprott, D. A., editors, </editor> <booktitle> Foundations of Statistical Inference, </booktitle> <pages> pp. 108-127. </pages> <publisher> Holt, Rinehart and Winston, Toronto. </publisher>
Reference: <author> Gorry, G. A. and Barnett, G. O. </author> <year> 1968. </year> <title> Sequential diagnosis by computer. </title> <journal> Journal of the American Medical Association, </journal> 205(12) 849-854. 
Reference: <author> Halpern, J. Y. </author> <year> 1986. </year> <title> Reasoning about knowledge: An overview. </title> <editor> In Halpern, J. Y., editor, </editor> <booktitle> Theoretical Aspects of Reasoning About Knowledge: Proceedings of the 1986 Conference, </booktitle> <pages> pp. 1-17, </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address>
Reference: <author> Hansson, O. and Mayer, A. </author> <year> 1989. </year> <title> Heuristic search as evidential reasoning. </title> <booktitle> In Proceedings of the Fifth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 152-161. </pages>
Reference: <author> Harman, G. </author> <year> 1986. </year> <title> Change in View: </title> <booktitle> Principles of Reasoning. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: storage space alone if storing items in memory slows down inference in retrieval, if fixed memory size introduces opportunity costs for storing specific information, or if memory decay forces the reasoner to refresh its beliefs periodically. 20 Rationality and its Roles in Reasoning or set of changed beliefs (as in <ref> (Harman, 1986) </ref>), or axiomatize the logical relationships that must hold between prior beliefs, new information, and posterior beliefs (as in (Gardenfors, 1988)). But these principles do not take into account any of the reasoner's preferences among different possible revisions, which means that revisions may be less rational than necessary.
Reference: <author> Harper, W. L. </author> <year> 1976. </year> <title> Rational belief change, Popper functions, and counterfactuals. </title> <editor> In Harper, W. L. and Hooker, C. A., editors, </editor> <title> Foundations of Probability Theory, Statistical Inference, </title> <journal> and Statistical Theories of Science, </journal> <volume> volume 1, </volume> <pages> pp. 73-115. </pages> <publisher> Reidel, Dordrecht. </publisher>
Reference-contexts: using a maximum entropy principle to fill in gaps in probability distributions. 4.1.2 Inertia Standard treatments of decision theory assume that the beliefs of the agent persist over time in the absence of new information and that beliefs change according to the rule of Bayesian conditionalization (or some related rule <ref> (Harper, 1976) </ref>). But perfect sensitivity to new information is usually not possible because changing beliefs takes time and effort.
Reference: <author> Haussler, D. </author> <year> 1988. </year> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <journal> Artificial Intelligence, </journal> <volume> 36(2) </volume> <pages> 177-221. </pages>
Reference: <author> Henderson, J. M. and Quandt, R. E. </author> <year> 1980. </year> <title> Microeconomic Theory: A Mathematical Approach. </title> <publisher> McGraw-Hill, </publisher> <address> New York, third edition. </address>
Reference: <author> Hirschman, A. O. </author> <year> 1982. </year> <title> Shifting Involvements: Private Interest and Public Action. </title> <publisher> Prince-ton University Press, Princeton. </publisher>
Reference: <author> Holtzman, S. </author> <year> 1989. </year> <title> Intelligent Decision Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference: <author> Horty, J. F., Thomason, R. H., and Touretzky, D. S. </author> <year> 1990. </year> <title> A skeptical theory of inheritance in nonmonotonic semantic networks. </title> <journal> Artificial Intelligence, 42(2-3):311-348. </journal>
Reference-contexts: These give the appearance of consistency by means of credulous representations, in which maximal consistent subsets represent inconsistent sets of rules, and skeptical representations, in which the intersection of all maximal consistent subsets represents the inconsistent information <ref> (Horty et al., 1990) </ref>. The skeptical approach amounts to reasoning without the conflicting information, while the credulous approach amounts to temporarily taking sides in the conflict. Skeptical approaches are preferred by some authors because they avoid the risk of taking the wrong side in the conflict.
Reference: <author> Horvitz, E. J. </author> <year> 1988. </year> <title> Reasoning under varying and uncertain resource constraints. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. 111-116. </pages>
Reference-contexts: Recent work has evidenced a convergence of method, with decision analysts adopting AI tools, and expert systems employing decision-analytic concepts (see <ref> (Horvitz et al., 1988) </ref>). While decision-analytic methodologies offer a starting point, autonomous reasoners cannot always rely on obtaining their decision formulations through external decision analysts.
Reference: <author> Horvitz, E. J., Breese, J. S., and Henrion, M. </author> <year> 1988. </year> <journal> Decision theory in expert systems and artificial intelligence. International Journal of Approximate Reasoning, </journal> <volume> 2 </volume> <pages> 247-302. </pages>
Reference-contexts: Recent work has evidenced a convergence of method, with decision analysts adopting AI tools, and expert systems employing decision-analytic concepts (see <ref> (Horvitz et al., 1988) </ref>). While decision-analytic methodologies offer a starting point, autonomous reasoners cannot always rely on obtaining their decision formulations through external decision analysts.
Reference: <author> Horvitz, E. J., Cooper, G. F., and Heckerman, D. E. </author> <year> 1989. </year> <title> Reflection and action under scarce resources: Theoretical principles and empirical study. </title> <editor> In Sridharan, N. S., editor, </editor> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <volume> volume 2, </volume> <pages> pp. 1121-1127, </pages> <address> San Mateo, CA. </address> <booktitle> International Joint Conferences on Artificial Intelligence, </booktitle> <publisher> Inc., Morgan Kaufmann. </publisher>
Reference: <author> Howard, R. A. and Matheson, J. E., editors. </author> <year> 1984. </year> <title> The Principles and Applications of Decision Analysis. Strategic Decisions Group, </title> <address> Menlo Park, CA. </address> <note> 35 Doyle Huberman, </note> <editor> B. A., editor. </editor> <year> 1988. </year> <title> The Ecology of Computation. </title> <publisher> North-Holland, Amsterdam. </publisher>
Reference: <author> James, W. </author> <title> 1897. The Will to Believe and Other Essays in Popular Philosophy. Longmans, Green, </title> <publisher> and Co., </publisher> <address> New York. </address>
Reference: <author> Jaynes, E. T. </author> <year> 1979. </year> <title> Where do we stand on maximum entropy? In Levine and Tribus, editors, The Maximum Entropy Formalism. </title> <publisher> M.I.T. Press. </publisher>
Reference: <author> Jeffrey, R. C. </author> <year> 1983. </year> <title> The Logic of Decision. </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, </address> <note> second edition. </note>
Reference-contexts: The derivation or construction of constructive belief involves rational choice, but a fully satisfactory formal definition of rational constructive belief remains to be developed, as the self-referential nature of the choice requires use of equilibrium notions like ratified decisions <ref> (Jeffrey, 1983) </ref>. 5.3 Rational approximations Imprecise knowledge is an important special case of ignorance, since reasoners often lack the details of answers to questions even when they possess the essentials of the answers.
Reference: <author> Kahneman, D., Slovic, P., and Tversky, A., editors. </author> <year> 1982. </year> <title> Judgment under Uncertainty: Heuristics and Biases. </title> <publisher> Cambridge University Press. </publisher>
Reference: <author> Kant, E. </author> <year> 1983. </year> <title> On the efficient synthesis of efficient programs. </title> <journal> Artificial Intelligence, </journal> <volume> 20(3) </volume> <pages> 253-305. </pages>
Reference: <author> Keeney, R. L. and Raiffa, H. </author> <year> 1976. </year> <title> Decisions with Multiple Objectives: Preferences and Value Tradeoffs. </title> <publisher> John Wiley and Sons, </publisher> <address> New York. </address>
Reference-contexts: The usual approach to choice when there are several different ways of comparing things is multiattribute decision theory, in which utilities are functions of vectors of attribute valuations (see <ref> (Keeney and Raiffa, 1976) </ref>). But multiattribute decision theory does not prescribe how to combine the different attributes into a utility measure.
Reference: <author> Konolige, K. </author> <year> 1986. </year> <title> What awareness isn't: a sentential view of implicit and explicit belief. </title> <editor> In Halpern, J. Y., editor, </editor> <booktitle> Proceedings of the Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pp. 241-250. </pages>
Reference: <author> Korf, R. </author> <year> 1988. </year> <title> Real-time heuristic search: New results. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. 139-144. </pages>
Reference: <author> Kydland, F. E. and Prescott, E. C. </author> <year> 1977. </year> <title> Rules rather than discretion: the inconsistency of optimal plans. </title> <journal> J. Political Economy, </journal> <volume> 85(3) </volume> <pages> 473-491. </pages>
Reference: <author> Laird, J. E., Newell, A., and Rosenbloom, P. S. </author> <year> 1987. </year> <title> SOAR: An architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 1-64. </pages>
Reference-contexts: Indeed, many reasoning systems record aspects of past episodes of reasoning indiscriminately (using, for example, reason maintenance systems or chunking <ref> (Laird et al., 1987) </ref>), and this leads to clogging memory with records of dubious value (Minton, 1990). More generally, few learning theories address the problem of how to choose when or whether to learn, and so fail to cover the deliberate learning so common in everyday life. <p> is, to be maximally useful, systems should "put themselves in the user's place" by adopting the user's expectations and preferences and making decisions rationally with these adopted attitudes (Doyle and Patil, 1991). 6.7 Design provably rational architectures AI has developed numerous general architectures for representation and reasoning (such as soar <ref> (Laird et al., 1987) </ref> or prodigy (Minton et al., 1989)), but we lack at present an understanding of whether any of these architectures are rational in any precise sense.
Reference: <author> Langlotz, C. P. </author> <year> 1989. </year> <title> A Decision-Theoretic Approach to Heuristic Planning. </title> <type> Report No. </type> <institution> STAN-CS-89-1295, Computer Science Department, Stanford University, Stanford, </institution> <address> CA. </address>
Reference: <author> Langlotz, C. P. and Shortliffe, E. H. </author> <year> 1989. </year> <title> Logical and decision-theoretic methods for planning under uncertainty. </title> <journal> AI Magazine, </journal> <volume> 10(1) </volume> <pages> 39-47. </pages>
Reference: <author> Langlotz, C. P., Shortliffe, E. H., and Fagan, L. M. </author> <year> 1986. </year> <title> Using decision theory to justify heuristics. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pp. 215-219. </pages>
Reference-contexts: In particular, the theory may be applied in AI to provide a formal analysis of informally developed techniques (e.g., <ref> (Langlotz et al., 1986) </ref>). It also permits comparison of AI theories with formal psychological theories. Normatively construed, however, logical and economic rationality provide different conceptions of how one should think, and logic has also overshadowed economic rationality as a normative theory of thinking.
Reference: <author> Levesque, H. J. </author> <year> 1984. </year> <title> A logic of implicit and explicit belief. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pp. 198-202. </pages>
Reference: <author> Levesque, H. J. and Brachman, R. J. </author> <year> 1987. </year> <title> Expressiveness and tractability in knowledge representation and reasoning. </title> <journal> Computational Intelligence, </journal> <volume> 3 </volume> <pages> 78-93. </pages>
Reference-contexts: One version of this problem is that of real-time reasoning and search, in which a fixed amount of time is available for each episode of reasoning or search (Breese and Fehling, 1990; Korf, 1988). Other work has explored obtaining predictable response time, rather than fixed response times <ref> (Levesque and Brachman, 1987) </ref>. We will here highlight only some recent work on using techniques from decision theory and operations research in allocating effort within time limitations, which may be soft deadlines in addition to hard deadlines.
Reference: <author> Lipman, B. </author> <year> 1989. </year> <title> How to decide how to decide how to : : :: Limited rationality in decisions and games. </title> <booktitle> In Working Notes of the AAAI Symposium on AI and Limited Rationality, </booktitle> <pages> pp. 77-80. </pages> <note> Rationality and its Roles in Reasoning Loui, </note> <author> R. P. </author> <year> 1986. </year> <title> Interval-based decisions for reasoning systems. </title> <editor> In Kanal, L. N. and Lemmer, J. F., editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 459-472. </pages> <publisher> North-Holland. </publisher>
Reference: <author> Loui, R. P. </author> <year> 1988. </year> <title> Computing reference classes. </title> <editor> In Lemmer, J. F. and Kanal, L. N., editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 2, </booktitle> <pages> pp. 273-289. </pages> <publisher> North-Holland. </publisher>
Reference: <author> Machina, M. J. </author> <year> 1987. </year> <title> Choice under uncertainty: Problems solved and unsolved. </title> <journal> Journal of Economic Perspectives, </journal> <volume> 1(1) </volume> <pages> 121-154. </pages>
Reference: <author> Machina, M. J. </author> <year> 1989. </year> <title> Dynamic consistency and non-expected utility models of choice under uncertainty. </title> <journal> Journal of Economic Literature, XXVII(4):1622-1668. </journal>
Reference: <author> McCarthy, J. and Hayes, P. J. </author> <year> 1969. </year> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <editor> In Meltzer, B. and Michie, D., editors, </editor> <booktitle> Machine Intelligence 4, </booktitle> <pages> pp. 463-502. </pages> <publisher> Edinburgh University Press. </publisher>
Reference-contexts: Indeed, the standard guideline in heuristic problem solving is the rule If it seems useful, do it! Similarly, the more limited notion of heuristic adequacy <ref> (McCarthy and Hayes, 1969) </ref> advanced in the logicist approach involves using heuristics to determine the most useful sound inferences.
Reference: <author> McDermott, D. </author> <year> 1987. </year> <title> A critique of pure reason. </title> <journal> Computational Intelligence, </journal> <volume> 3 </volume> <pages> 151-160. </pages>
Reference-contexts: A purely logical reasoner guided only by the logicist rule would make many worthless inferences, since sound worthwhile inferences may be of the same logical form as sound worthless inferences (cf. <ref> (McDermott, 1987) </ref>). Making worthless inferences would not matter if reasoners were not expected to arrive at conclusions and take actions within appropriate lengths of time. But most reasoning does have some temporal purpose, and the reasoner needs to distinguish worthwhile inferences from worthless ones.
Reference: <author> Milnor, J. </author> <year> 1954. </year> <title> Games against nature. </title> <editor> In Thrall, R. M., Coombs, C. H., and Davis, R. L., editors, </editor> <booktitle> Decision Processes, </booktitle> <pages> pp. 49-59. </pages> <publisher> Wiley, </publisher> <address> New York. </address>
Reference: <author> Minsky, M. </author> <year> 1975. </year> <title> A framework for representing knowledge. </title> <editor> In Winston, P. H., editor, </editor> <booktitle> The Psychology of Computer Vision, chapter 6, </booktitle> <pages> pp. 211-277. </pages> <publisher> McGraw-Hill, </publisher> <address> New York. </address>
Reference: <author> Minsky, M. </author> <year> 1986. </year> <title> The Society of Mind. </title> <publisher> Simon and Schuster, </publisher> <address> New York. </address>
Reference-contexts: To avoid this pitfall of unthinking bureaucratic behavior, subprocedures must be implemented as tools or assistants that can be ignored or discarded when necessary rather than as subroutines (as in <ref> (Minsky, 1986) </ref>).
Reference: <author> Minsky, N. H. </author> <year> 1988. </year> <title> Law-Governed Systems. </title> <type> Technical report, </type> <institution> Rutgers University, Computer Science Department, </institution> <address> New Brunswick, NJ. </address>
Reference: <author> Minton, S. </author> <year> 1990. </year> <title> Quantitative results concerning the utility of explanation-based learning. </title> <journal> Artificial Intelligence, 42(2-3):363-391. </journal>
Reference-contexts: Indeed, many reasoning systems record aspects of past episodes of reasoning indiscriminately (using, for example, reason maintenance systems or chunking (Laird et al., 1987)), and this leads to clogging memory with records of dubious value <ref> (Minton, 1990) </ref>. More generally, few learning theories address the problem of how to choose when or whether to learn, and so fail to cover the deliberate learning so common in everyday life.
Reference: <author> Minton, S., Carbonell, J. G., et al. </author> <year> 1989. </year> <title> Explanation-based learning: A problem solving perspective. </title> <journal> Artificial Intelligence, 40(1-3):63-118. </journal>
Reference-contexts: should "put themselves in the user's place" by adopting the user's expectations and preferences and making decisions rationally with these adopted attitudes (Doyle and Patil, 1991). 6.7 Design provably rational architectures AI has developed numerous general architectures for representation and reasoning (such as soar (Laird et al., 1987) or prodigy <ref> (Minton et al., 1989) </ref>), but we lack at present an understanding of whether any of these architectures are rational in any precise sense.
Reference: <author> Mitchell, T. M., Keller, R. M., and Kedar-Cabelli, S. T. </author> <year> 1986. </year> <title> Explanation-based generalization: a unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 47-80. </pages>
Reference-contexts: For example, while DeJong's (1983) original criteria for explanation-based learning concerned utility of the result, many techniques of explanation-based generalization <ref> (Mitchell et al., 1986) </ref> use only a categorical notion of operationality of concept definitions that avoids comparing the different explanations that might form the basis of learning.
Reference: <author> Mueller, D. C. </author> <year> 1989. </year> <title> Public Choice II. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <note> second edition. </note>
Reference-contexts: The most relevant general topics are microeconomics, which treats the theory of markets composed of individual rational agents (see (Henderson and Quandt, 1980; Debreu, 1959)) and social choice theory, which treats nonmarket or social decision-making schemes such as voting (see <ref> (Mueller, 1989) </ref>).
Reference: <author> Nagel, T. </author> <year> 1979. </year> <title> The fragmentation of value. In Mortal Questions, chapter 9. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge. </address>
Reference: <author> Nelson, R. R. and Winter, S. G. </author> <year> 1982. </year> <title> An Evolutionary Theory of Economic Change. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Newell, A. </author> <year> 1982. </year> <title> The knowledge level. </title> <journal> Artificial Intelligence, </journal> <volume> 18(1) </volume> <pages> 87-127. </pages>
Reference-contexts: If an agent has knowledge that one of its actions will lead to one of its goals, then the agent will select that action." <ref> (Newell, 1982, p. 102) </ref> (Cf. Cherniak's (1986) principles of "minimal rationality.") Newell calls this principle the "behavioral law that governs an agent, and permits prediction of its behavior". <p> be necessary: the theory is supposed to accurately characterize most of AI, and most AI systems ignore issues of rational choice in just the way Newell's principle suggests. 6 "Knowledge: Whatever can be ascribed to an agent, such that its behavior can be computed according to the principle of rationality." <ref> (Newell, 1982, p. 105) </ref> 8 Rationality and its Roles in Reasoning Newell's principle of rationality notwithstanding, many in artificial intelligence, including Newell, have long recognized the limitations of unguided reasoning and have advanced the notion of heuristics as central to effective problem solving.
Reference: <author> Olson, M. </author> <year> 1982. </year> <title> The Rise and Decline of Nations: Economic Growth, Stagflation, and Social Rigidities. </title> <publisher> Yale University Press, </publisher> <address> New Haven, CT. </address> <note> 37 Doyle Pareto, </note> <author> V. </author> <year> 1971. </year> <title> Manual of Political Economy. Kelley, </title> <address> New York. </address> <note> Originally published 1927. </note> <editor> Translated by A. S. Schwier, edited by A. S. Schwier and A. N. </editor> <publisher> Page. </publisher>
Reference: <author> Pascal, B. </author> <year> 1962. </year> <institution> Pensees sur la religion et sur quelques autres sujets. </institution> <address> Harvill, London. </address>
Reference: <author> Translated by M. Turnell, </author> <note> originally published 1662. </note>
Reference: <author> Pearl, J. </author> <year> 1988. </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Penrose, R. </author> <year> 1989. </year> <title> The Emperor's New Mind: Concerning Computers, Minds, and The Laws of Physics. </title> <publisher> Oxford University Press, </publisher> <address> New York. </address>
Reference: <author> Quine, W. V. and Ullian, J. S. </author> <year> 1978. </year> <title> The Web of Belief. Random House, </title> <address> New York, </address> <note> second edition. </note>
Reference: <author> Raiffa, H. </author> <year> 1968. </year> <title> Decision Analysis: Introductory Lectures on Choices Under Uncertainty. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference: <author> Ramsey, F. P. </author> <year> 1931. </year> <title> Truth and probability. </title> <editor> In Braithwaite, R. B., editor, </editor> <booktitle> The Foundations of Mathematics and Other Logical Essays, </booktitle> <pages> pp. 156-198. </pages> <publisher> Routledge and Kegan Paul, London. </publisher>
Reference: <author> Rawls, J. </author> <year> 1971. </year> <title> A Theory of Justice. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Reiter, R. </author> <year> 1980. </year> <title> A logic for default reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 13 </volume> <pages> 81-132. </pages>
Reference-contexts: The most notable examples are those theories of nonmonotonic reasoning which admit a multiplicity of possible states of belief corresponding to a single set of premises. For example, in default logic <ref> (Reiter, 1980) </ref>, the knowledge of the reasoner is expressed in a set of axioms and a set of default rules.
Reference: <author> Reiter, R. </author> <year> 1988. </year> <title> On integrity constraints. </title> <editor> In Vardi, M. Y., editor, </editor> <booktitle> Proceedings of the Second Conference on Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pp. 97-111. </pages>
Reference-contexts: For example, database integrity constraints, which state conditions that the set of database entries must satisfy, may be viewed in this way (see <ref> (Reiter, 1988) </ref>), and the same holds for the reasons or justifications of reason maintenance systems, which represent conditions on what beliefs must be or must not be believed at the same time as others (see (Doyle, 1983b; Doyle, 1988a)).
Reference: <author> Rosenschein, S. J. and Kaelbling, L. P. </author> <year> 1986. </year> <title> The synthesis of digital machines with provable epistemic properties. </title> <editor> In Halpern, J. Y., editor, </editor> <booktitle> Theoretical Aspects of Reasoning About Knowledge: Proceedings of the 1986 Conference, </booktitle> <pages> pp. 83-98. </pages>
Reference-contexts: But since the point of distributing knowledge and reasoning is to free the reasoner from having to take all possibly relevant knowledge into account at every step, it is hard to imagine how (apart from using the shared environment as a coordinating store <ref> (Rosenschein and Kaelbling, 1986) </ref>, which may not always be possible or successful) to ensure any degree of global consistency and coordination without undercutting this motivation for distributed computation. 4.2 Resource limitations The most obvious limitations on resources facing reasoners are limitations on the time and memory available.
Reference: <author> Russell, S. and Wefald, E. </author> <year> 1991. </year> <booktitle> Principles of metareasoning. Artificial Intelligence, </booktitle> <address> 49(1-3):361-395,. </address>
Reference: <author> Saraswat, V. </author> <year> 1989. </year> <title> Concurrent Constraint Programming Languages. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, Pittsburgh, Pennsylvania. </institution>
Reference: <author> Savage, L. J. </author> <year> 1972. </year> <title> The Foundations of Statistics. </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <note> second edition. </note>
Reference-contexts: See (Wellman and Doyle, 1991) for an approach using multi-attribute descriptions of outcomes to define goals as conditions preferred to their opposites, holding other things equal. 2.3 Decision theory Most work in artificial intelligence that makes use of economic rationality draws on the specific theory of subjective Bayesian decision theory <ref> (Savage, 1972) </ref>, hereafter simply called decision theory. 4 Compared with the basic theory, decision theory adds probability measures p A which indicate the likelihood of each possible outcome for each alternative A 2 A.
Reference: <author> Schelling, T. C. </author> <year> 1984a. </year> <title> The intimate contest for self-command. In Choice and Consequence: </title> <booktitle> Perspectives of an errant economist, </booktitle> <pages> pp. 57-82. </pages> <publisher> Harvard University Press, </publisher> <address> Cambridge. </address>
Reference: <author> Schelling, T. C. </author> <year> 1984b. </year> <title> The mind as a consuming organ. In Choice and Consequence: </title> <booktitle> Perspectives of an errant economist, </booktitle> <pages> pp. 328-346. </pages> <publisher> Harvard University Press, </publisher> <address> Cambridge. </address>
Reference: <author> Schumpeter, J. A. </author> <year> 1934. </year> <title> The Theory of Economic Development: An Inquiry into Profits, Capital, Credit, Interest, and the Business Cycle. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge. </address>
Reference: <author> Translated by R. Opie. </author> <title> 38 Rationality and its Roles in Reasoning Scott, </title> <editor> D. S. </editor> <year> 1982. </year> <title> Domains for denotational semantics. </title> <booktitle> In Proceedings of the International Conference on Automata, Languages, and Programming. </booktitle>
Reference: <author> Shils, E. </author> <year> 1981. </year> <title> Tradition. </title> <publisher> Chicago University Press, Chicago. </publisher>
Reference: <author> Shoham, Y. </author> <year> 1988. </year> <title> Reasoning about Change: Time and Causation from the Standpoint of Artificial Intelligence. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Simon, H. A. </author> <year> 1955. </year> <title> A behavioral model of rational choice. </title> <journal> Quarterly Journal of Economics, </journal> <volume> 69 </volume> <pages> 99-118. </pages>
Reference: <author> Simon, H. A. </author> <year> 1976. </year> <title> From substantive to procedural rationality. </title> <editor> In Latsis, S. J., editor, </editor> <booktitle> Method and Appraisal in Economics, </booktitle> <pages> pp. 129-148. </pages> <publisher> Cambridge University Press. </publisher>
Reference: <author> Simon, H. A. and Kadane, J. B. </author> <year> 1975. </year> <title> Optimal problem-solving search: All-or-none solutions. </title> <journal> Artificial Intelligence, </journal> <volume> 6 </volume> <pages> 235-247. </pages>
Reference: <author> Smith, D. E. </author> <year> 1986. </year> <title> Controlling inference. </title> <type> Technical Report STAN-CS-86-1107, </type> <institution> Department of Computer Science, Stanford University. </institution>
Reference: <author> Smith, D. E. </author> <year> 1988. </year> <title> A Decision Theoretic Approach to the Control of Planning Search. </title> <type> Technical Report LOGIC-87-11, </type> <institution> Department of Computer Science, Stanford University. </institution>
Reference: <author> Sproull, R. </author> <year> 1977. </year> <title> Strategy Construction Using a Synthesis of Heuristic and Decision-Theoretic Methods. </title> <type> PhD thesis, </type> <institution> Stanford University. </institution>
Reference: <author> Stallman, R. M. and Sussman, G. J. </author> <year> 1977. </year> <title> Forward reasoning and dependency-directed backtracking in a system for computer-aided circuit analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 9(2) </volume> <pages> 135-196. </pages>
Reference: <author> Stalnaker, R. C. </author> <year> 1984. </year> <title> Inquiry. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Stefik, M. </author> <year> 1981. </year> <title> Planning with constraints (molgen: Part 1). </title> <journal> Artificial Intelligence, </journal> <volume> 16 </volume> <pages> 111-140. </pages>
Reference: <author> Stigler, G. J. and Becker, G. S. </author> <year> 1977. </year> <title> De gustibus non est disputandum. </title> <journal> American Economic Review, </journal> <volume> 67 </volume> <pages> 76-90. </pages>
Reference-contexts: That is, it appears that for any history of behaviors one can always find a set of ordinal preferences so that every action of the history is rational (see <ref> (Stigler and Becker, 1977) </ref>). In the present setting, this means that the ideal of logical rationality may be completely undercut in some economically rational reasoners, since one may always be able to find sets of preferences which make rational any set or change of beliefs (cf. (Doyle, 1991a)).
Reference: <author> Szolovits, P. and Pauker, S. G. </author> <year> 1978. </year> <title> Categorical and probabilistic reasoning in medical diagnosis. </title> <journal> Artificial Intelligence, </journal> <volume> 11 </volume> <pages> 115-144. </pages>
Reference-contexts: In medical diagnosis problems, for example, the number of conditional probabilities needed in the worst case is exponential in the number of diseases and symptoms or tests results <ref> (Szolovits and Pauker, 1978) </ref>. This difficulty was taken for some time to indicate the impracticality of probabilistic representations of knowledge, but several methods have been developed recently for succinctly specifying large amounts of probabilistic information.
Reference: <author> Thaler, R. H. and Shefrin, H. M. </author> <year> 1981. </year> <title> An economic theory of self-control. </title> <journal> Journal of Political Economy, </journal> <volume> 89(2) </volume> <pages> 392-406. </pages>
Reference: <author> Thomason, R. H. </author> <year> 1986. </year> <title> The context-sensitivity of belief and desire. </title> <editor> In Georgeff, M. P. and Lansky, A. L., editors, </editor> <booktitle> Reasoning about Actions and Plans: Proceedings of the 1986 Workshop, </booktitle> <pages> pp. 341-360. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Tinbergen, N. </author> <year> 1951. </year> <title> The Study of Instinct. </title> <publisher> Clarendon Press, Oxford. </publisher>
Reference: <author> Valiant, L. G. </author> <year> 1984. </year> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 18(11) </volume> <pages> 1134-1142. </pages>
Reference: <author> Doyle Van Fraassen, B. C. </author> <year> 1973. </year> <title> Values and the heart's command. </title> <journal> Journal of Philosophy, LXX(1):5-19. </journal>
Reference: <author> Wellman, M. P. </author> <year> 1990. </year> <title> Formulation of Tradeoffs in Planning Under Uncertainty. </title> <publisher> Pitman and Morgan Kaufmann. </publisher>
Reference-contexts: as rational selection of concept definitions, but it is not apparent that PAC definitions are the same as definitions of maximal expected utility, even under this identification. 5.6 Rational planning Planning involves several tasks (in addition to reasoning and search) in which rational choice may play a significant role (cf. <ref> (Doyle and Wellman, 1990) </ref>). As noted earlier, the very notion of "goal" is suspect, as goals often implicitly involve efficiency considerations. Thus one of the main roles for rational choice is comparison of alternative plans (see (Feldman and Sproull, 1977; Smith, 1988; Langlotz, 1989)). <p> It may be that architectures based on explicit decision-theoretic comparisons (such as sudo-planner <ref> (Wellman, 1990) </ref>) or on other operations of demonstrated rationality may be easier to analyze.
Reference: <author> Wellman, M. P. </author> <year> 1992. </year> <title> A general equilibrium approach to distributed transportation planning. </title> <note> To appear. </note>
Reference: <author> Wellman, M. P. and Doyle, J. </author> <year> 1991. </year> <title> Preferential semantics for goals. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pp. 698-703. </pages>
Reference-contexts: On the other hand, finite sets of goals provide a focus for reasoning and action in a way that specifying utilities for the infinity of conceivable circumstances does not. To gain the advantages of both goals and preferences, one must introduce some new notion to connect the two. See <ref> (Wellman and Doyle, 1991) </ref> for an approach using multi-attribute descriptions of outcomes to define goals as conditions preferred to their opposites, holding other things equal. 2.3 Decision theory Most work in artificial intelligence that makes use of economic rationality draws on the specific theory of subjective Bayesian decision theory (Savage, 1972), <p> Different tasks will have different deadlines in different situations (for example, emergency room medical diagnosis has much shorter deadlines than diagnosis in the doctor's office), and deadlines can sometimes be postponed. More generally, the 10 In <ref> (Doyle and Wellman, 1991) </ref>, however, these multiple extensions are viewed as stemming from inconsistent preferences about belief. 13 Doyle reasoner may be able to trade other resources at its disposal for more time (for example, processor speeds might be changed if increased error rates are acceptable). <p> for investigation is how to choose a representation appropriate to the reasoner's situation (an approach which makes beliefs context-sensitive in the sense of Thomason (1986) discussed earlier.) This problem appears to have close connections with the problem of group decision making, and appears to suffer from the same metaphysical difficulties <ref> (Doyle and Wellman, 1991) </ref>. Practical approaches based on credulous representations must also involve a notion of conservatism. If the consistent representation is chosen anew for each action, different actions may be based on inconsistent subsets even if the underlying beliefs have not changed. <p> We will here highlight only some recent work on using techniques from decision theory and operations research in allocating effort within time limitations, which may be soft deadlines in addition to hard deadlines. See <ref> (Dean and Wellman, 1991, Chapter 8) </ref> for a more detailed survey, and (Good, 1962; Simon and Kadane, 1975) for some early discussions of rational control of search. 23 Doyle Russell and Wefald (1991) present their approach to rationally controlling A* and other search methods as a general theory of "metareasoning." In
Reference: <author> Wellman, M. P., Eckman, M. H., et al. </author> <year> 1989. </year> <title> Automated critiquing of medical decision trees. Medical Decision Making, </title> <booktitle> 9(4) </booktitle> <pages> 272-284. </pages> <note> 40 Rationality and its Roles in Reasoning </note>
References-found: 130

