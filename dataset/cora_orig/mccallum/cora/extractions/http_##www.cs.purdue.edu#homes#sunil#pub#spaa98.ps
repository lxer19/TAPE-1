URL: http://www.cs.purdue.edu/homes/sunil/pub/spaa98.ps
Refering-URL: http://www.cs.purdue.edu/homes/sunil/syllabi/CS690D_Fall98.html
Root-URL: http://www.cs.purdue.edu
Email: fsunilp,agrawal,amrg@cs.ucsb.edu  
Title: Efficient Disk Allocation for Fast Similarity Searching  
Author: Sunil Prabhakar Divyakant Agrawal Amr El Abbadi 
Note: Appeared in Proc. 10th ACM Symposium on Parallel Algorithms and Architectures (SPAA '98), Puerto Vallarta, Mexico  
Address: Santa Barbara CA 93106, U.S.A.  
Affiliation: Department of Computer Science University of California  
Abstract: As databases increasingly integrate non-textual information it is becoming necessary to support efficient similarity searching in addition to range searching. Recently, declustering techniques have been proposed for improving the performance of similarity searches through parallel I/O. In this paper, we propose a new scheme which provides good declus-tering for similarity searching. In particular, it does global declustering as opposed to local declustering, exploits the availability of extra disks and does not limit the partitioning of the data space. Our technique is based upon the Cyclic declustering schemes which were developed for range and partial match queries. We establish, in general, that Cyclic declustering techniques outperform previously proposed techniques. 
Abstract-found: 1
Intro-found: 1
Reference: [AE93] <author> K. A. S. Abdel-Ghaffar and A. El Abbadi. </author> <title> Optimal disk allocation for partial match queries. </title> <journal> Proc. ACM Symp. on Transactions of Database Systems, </journal> <volume> 18(1) </volume> <pages> 132-156, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: Prominent examples of such declustering schemes are HCAM [FB93], Fieldwise Exclusive or FX [KP88] and CMD [LSR92] or Disk Modulo [DS82] and error-correcting based techniques <ref> [FM89, AE93] </ref>. In [BBB + 97], a new declustering technique is developed that optimizes data allocation on multiple disks for nearest-neighbor queries. The authors argue that the existing declustering techniques do not generate adequate declustering for nearest-neighbor queries.
Reference: [AE97] <author> K. A. S. Abdel-Ghaffar and A. El Abbadi. </author> <title> Optimal allocation of two-dimensional data. </title> <booktitle> In International Conference on Database Theory, </booktitle> <pages> pages 409-418, </pages> <address> Delphi, Greece, </address> <month> January </month> <year> 1997. </year>
Reference-contexts: For this purpose, the Cost met-rics are used to compare the schemes. In each graph the lower bound that can be achieved by any allocation scheme is shown. For two-dimensional range queries, it has been shown that strictly optimal declustering can be achieved only in very rare cases <ref> [AE97] </ref>. We expect that for nearest-neighbor searching too, in general, optimal declustering will be achievable only in very few cases. The case of 2-way partitioning is discussed first. In Figures 7 and 8, the performance of the various schemes for 2-way partitioning with 15 dimensions is shown.
Reference: [AFS93] <author> R. Agrawal, C. Faloutsos, and A. Swami. </author> <title> Efficient similarity search in sequence databases. </title> <booktitle> In 4th Int. Conference on Foundations of Data Organization and Algorithms, </booktitle> <pages> pages 69-84, </pages> <year> 1993. </year>
Reference-contexts: The number of dimensions necessary for satisfactory mapping can be very large, and dimensionality reduction techniques are first employed to reduce the fl Work supported by a research grant from NSF/ARPA/NASA IRI9411330, NSF instrumentation grant CDA-9421978 and NSF grant CCR97-12108. number of dimensions to smaller values <ref> [AFS93] </ref>. A typical number of dimensions into which images are mapped is 256, followed by a reduction to 10 or 16 dimensions. Searching for similar objects therefore transforms into a problem of locating the nearest points. A nearest-neighbor query is evaluated as follows. <p> Some examples of these include the R fl -tree [BKSS90], the X-tree [BKK96], HB-tree [LS90] and GiST [HNP95]. The performance of these structures is good for few dimensions, but as the number of dimensions increases beyond 10, the performance degrades significantly <ref> [AFS93] </ref>. An effective technique for improving the performance of the index structures is to employ parallelism. The major bottleneck is the large number of disk I/O operations that need to be performed. This number typically grows rapidly as the number of dimensions increases.
Reference: [BBB + 97] <author> S. Berchtold, C. Bohm, B. Braunmuller, D. A. Keim, and H-P. Kriegel. </author> <title> Fast parallel similarity search in multimedia databases. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 1-12, </pages> <address> Arizona, U.S.A., </address> <year> 1997. </year>
Reference-contexts: Prominent examples of such declustering schemes are HCAM [FB93], Fieldwise Exclusive or FX [KP88] and CMD [LSR92] or Disk Modulo [DS82] and error-correcting based techniques [FM89, AE93]. In <ref> [BBB + 97] </ref>, a new declustering technique is developed that optimizes data allocation on multiple disks for nearest-neighbor queries. The authors argue that the existing declustering techniques do not generate adequate declustering for nearest-neighbor queries. <p> It is also shown that the performance of the HCAM approach degrades when non-square queries are considered. The performance of HCAM for the nearest-neighbor queries is also found to be poor (achieving a speed-up of only 3 with 16 disks) <ref> [BBB + 97] </ref>. The new approach developed in [BBB + 97] limits the number of divisions along each dimension to 1. Also, the availability of additional disks does not improve the performance of the declustering. The other approaches do not suffer from these limitations. <p> It is also shown that the performance of the HCAM approach degrades when non-square queries are considered. The performance of HCAM for the nearest-neighbor queries is also found to be poor (achieving a speed-up of only 3 with 16 disks) <ref> [BBB + 97] </ref>. The new approach developed in [BBB + 97] limits the number of divisions along each dimension to 1. Also, the availability of additional disks does not improve the performance of the declustering. The other approaches do not suffer from these limitations. <p> This is typically achieved by dividing each dimension into several parts. Each bucket is then identified by a set of numbers or coordinates corresponding to each dimension. We borrow and extend the definitions of direct and indirect neighbors from <ref> [BBB + 97] </ref> (the model in their paper does not allow splitting any dimension into more than two parts). Definition 2 Two buckets are direct neighbors if their coordinates differ in only one dimension. Moreover, the magnitude of the difference in the coordinates should be 1. <p> Note that these definitions hold for any number of dimensions. Similarly, buckets that differ by 1 in exactly three dimensions can be said to be doubly indirect neighbors and so on. As was established in <ref> [BBB + 97] </ref>, for d dimensions, the likelihood that data will be clustered around the (d 1)- dimensional surface that encloses the data space, increases as d becomes larger. Consequently, the need to access direct and indirect neighbors when searching for nearest-neighbors becomes greater. <p> Alternatively, all direct and indirect neighbors could be retrieved at the same time. From the example of point B, it can be seen that it may be necessary to retrieve the direct and indirect neighbors in one step. In higher dimensions, the likelihood of such access increases <ref> [BBB + 97] </ref>. 3 Related Work In this section we review some related work. <p> The x-axis gives the number of disks and the y-axis gives the ratio that reflects the performance of the query. It is clear to see that the GFIB Cyclic schemes outperforms all the other schemes for all values of M for range queries. In <ref> [BBB + 97] </ref>, an allocation scheme for declustering buckets to optimize nearest-neighbor queries is presented. This scheme requires that each dimension be divided into exactly two parts, thus the value of each coordinate is either 0 or 1. <p> They define such an allocation to be near-optimal. It is shown that DM, FX and HCAM do not achieve near-optimal declustering. Given a bucket (x 0 ; x 1 ; ; x d1 ), the <ref> [BBB + 97] </ref> scheme assigns it to disk i=0 i + 1 if x i = 1 0 otherwise ! where is the bitwise exclusive-OR operator. This allocation guarantees near-optimal declustering, assuming that there are enough disks available. <p> However, if there are more disks available then the required number, the NoD approach does not use the extra disks - thus the extra disks are wasted. Through experiments, it is shown in <ref> [BBB + 97] </ref> that the performance of 10 nearest-neighbors queries is improved by almost a linear factor in the number of disks through declus-tering using NoD. The HCAM approach is able to achieve only a two fold improvement using 16 disks. <p> We start by using a metric that measures the degree of near-optimal declustering since in <ref> [BBB + 97] </ref> achieving near-optimal declustering was the main criterion for predicting the performance of an allocation scheme. However, achieving near-optimal declustering in itself does not accurately reflect the degree of parallelism achieved. <p> The evalua tions are based upon both criteria: 1. Counts this is a measure of how far the allocation is from being a near-optimal allocation, as defined in <ref> [BBB + 97] </ref>. The count for an allocation scheme is the sum of the count for each bucket. The count for a bucket is the number of direct and indirect neighbors of the bucket that are allocated to the same disk as the bucket itself.
Reference: [BKK96] <author> S. Berchtold, D. A. Keim, and H. P. Kreigel. </author> <title> The X-tree: An index structure for high-dimensional data. </title> <booktitle> In 22nd. Conference on Very Large Databases, </booktitle> <pages> pages 28-39, </pages> <address> Bombay, India, </address> <year> 1996. </year>
Reference-contexts: Searching for the nearest points in such high-dimensional space is a very computation and I/O intensive operation. Several index structures have been proposed in the literature that significantly improve the search operation in multidimensional spaces. Some examples of these include the R fl -tree [BKSS90], the X-tree <ref> [BKK96] </ref>, HB-tree [LS90] and GiST [HNP95]. The performance of these structures is good for few dimensions, but as the number of dimensions increases beyond 10, the performance degrades significantly [AFS93]. An effective technique for improving the performance of the index structures is to employ parallelism.
Reference: [BKSS90] <author> N. Beckmann, H. Kriegel, R. Schneider, and B. Seeger. </author> <title> The R* tree: An efficient and robust access method for points and rectangl es. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 322-331, </pages> <month> May 23-25 </month> <year> 1990. </year>
Reference-contexts: Searching for the nearest points in such high-dimensional space is a very computation and I/O intensive operation. Several index structures have been proposed in the literature that significantly improve the search operation in multidimensional spaces. Some examples of these include the R fl -tree <ref> [BKSS90] </ref>, the X-tree [BKK96], HB-tree [LS90] and GiST [HNP95]. The performance of these structures is good for few dimensions, but as the number of dimensions increases beyond 10, the performance degrades significantly [AFS93]. An effective technique for improving the performance of the index structures is to employ parallelism.
Reference: [CDN + 97] <author> X. Cheng, R. Dolin, M. Neary, S. Prabhakar, K. Ravikanth, D. Wu, D. Agrawal, A. El Abbadi, M. Freeston, A. Singh, T. Smith, and J. Su. </author> <title> Scalable access within the context of digital libraries. </title> <booktitle> In IEEE International Conference on Advances in Digital Libraries, ADL, </booktitle> <pages> pages 70-81, </pages> <address> Wash-ington, D.C., </address> <year> 1997. </year>
Reference-contexts: 1 Introduction Identifying objects that are similar to each other is a challenging problem for many applications, such as multimedia repositories or digital libraries. Examples of such applications are the QBIC project [NBE + 93] and the Alexandria Digital Library <ref> [CDN + 97] </ref>. In order to automate similarity searching, it is first necessary to define a similarity measure.
Reference: [CLRS86] <author> B. Chor, C. E. Leiserson, R. L. Rivest, and J. B. Shearer. </author> <title> An application of number theory to the organization of raster-graphics memory. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 33(1) </volume> <pages> 86-104, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: One of the techniques for determining the value of H is called Generalized Fibonacci or GFIB. It is based upon Fibonacci numbers and is an extension of a declustering scheme proposed earlier <ref> [CLRS86] </ref> for improving the performance of raster graphics displays. The original scheme is restrictive because it limits the number of disks to odd order Fibonacci numbers. The GFIB scheme works as follows. Let us first assume that M is a Fibonacci number.
Reference: [DS82] <author> H. C. Du and J. S. Sobolewski. </author> <title> Disk allocation for cartesian product files on multiple-disk systems. </title> <journal> ACM Transactions of Database Systems, </journal> <volume> 7(1) </volume> <pages> 82-101, </pages> <month> March </month> <year> 1982. </year>
Reference-contexts: Prominent examples of such declustering schemes are HCAM [FB93], Fieldwise Exclusive or FX [KP88] and CMD [LSR92] or Disk Modulo <ref> [DS82] </ref> and error-correcting based techniques [FM89, AE93]. In [BBB + 97], a new declustering technique is developed that optimizes data allocation on multiple disks for nearest-neighbor queries. The authors argue that the existing declustering techniques do not generate adequate declustering for nearest-neighbor queries. <p> Also, M represents the number of disks over which the buckets are to be declustered, and d is the number of dimensions. The meaning of each symbol is summarized in Table 1. The Disk Modulo or DM approach <ref> [DS82] </ref> allocates bucket Symbol Meaning M Number of Disks d Number of Dimensions N i Number of Buckets in Dimension i x i Coordinate of Bucket in Dimension i Table 1: Meaning of symbols used (x 0 ; x 1 ; ; x d1 ) to disk ( j=0 The Fieldwise
Reference: [FB93] <author> C. Faloutsos and P. Bhagwat. </author> <title> Declustering using fractals. </title> <booktitle> In Proceedings of the 2nd International Conference on Parallel and Distributed Information Systems, </booktitle> <pages> pages 18 - 25, </pages> <address> San Diego, CA, </address> <month> Jan </month> <year> 1993. </year>
Reference-contexts: The problem of declustering a high-dimensional space across multiple disks has been well studied in the context of relational databases, where the goal has been to improve the performance of range and partial match queries. Prominent examples of such declustering schemes are HCAM <ref> [FB93] </ref>, Fieldwise Exclusive or FX [KP88] and CMD [LSR92] or Disk Modulo [DS82] and error-correcting based techniques [FM89, AE93]. In [BBB + 97], a new declustering technique is developed that optimizes data allocation on multiple disks for nearest-neighbor queries. <p> Through experimentation, it is shown that their approach gives much better performance for nearest-neighbor and 10 nearest-neighbors queries as compared to the HCAM approach, which has been shown to give superior performance for square range queries in two dimensions <ref> [FB93] </ref>. In a recent study [PAAE98], we proposed a new class of declustering algorithms called Cyclic allocation schemes for two-dimensional data. The schemes were shown to give the best declustering performance for range and partial match queries. <p> The HCAM approach <ref> [FB93] </ref>, allocates the bucket to disk hilbert order (x 0 ; x 1 ; ; x d1 ) mod M where the function hilbert order () returns the Hilbert sequence of the input coordinates. The Hilbert sequence maps a multidimensional space into a linear order.
Reference: [FM89] <author> C. Faloutsos and D. Metaxas. </author> <title> Declustering using error correcting codes. </title> <booktitle> In Proc. ACM Symp. on Principles of Database Systems, </booktitle> <pages> pages 253-258, </pages> <year> 1989. </year>
Reference-contexts: Prominent examples of such declustering schemes are HCAM [FB93], Fieldwise Exclusive or FX [KP88] and CMD [LSR92] or Disk Modulo [DS82] and error-correcting based techniques <ref> [FM89, AE93] </ref>. In [BBB + 97], a new declustering technique is developed that optimizes data allocation on multiple disks for nearest-neighbor queries. The authors argue that the existing declustering techniques do not generate adequate declustering for nearest-neighbor queries.
Reference: [GD92] <author> S. Ghandeharizadeh and D. J. DeWitt. </author> <title> A performance analysis of alternative multi-attribute declustering strategies. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 29-38, </pages> <address> San Diego, </address> <year> 1992. </year>
Reference-contexts: This number typically grows rapidly as the number of dimensions increases. Therefore the key to improving the performance is distributing the data among several I/O devices such that the data retrieved by any query is evenly spread across all the I/O devices (typically disks). Ghandeharizadeh and DeWitt <ref> [GD92] </ref> demonstrated, using simulation, that declustering data on multiple disks results in significant improvements in response time for range queries.
Reference: [GSC + 95] <author> G. A. Gibson, D. Stodolsky, F. W. Chang, W. V. Courtright, C. G. Demetriou, E. Gint-ing, M. Holland, Q. Ma, L. Neal, R. H. Pat-terson, J. Su, R. Youssef, and J. Zelenka. </author> <title> The scotch parallel storage systems. </title> <booktitle> In COMPCON '95. Technologies for the Information Superhighway, </booktitle> <pages> pages 403-10, </pages> <address> Los Alamitos, CA, </address> <year> 1995. </year>
Reference-contexts: In higher dimensions, the likelihood of such access increases [BBB + 97]. 3 Related Work In this section we review some related work. There has been a significant amount of work investigating the use of parallel techniques for improving I/O performance such as the Scotch parallel storage systems <ref> [GSC + 95] </ref> which investigate the evolution of RAID technology and parallel prefetching and caching [KTP + 96]. In particular, several approaches to decluster data for increasing parallel I/O have been proposed. We now review some of the most prominent declus-tering schemes.
Reference: [HNP95] <author> J. Hellerstein, J. Naughton, and A. Pfeffer. </author> <title> Generalized search trees for database systems. </title> <booktitle> In Proceedings of the Int. Conf. on Very Large Data Bases, </booktitle> <pages> pages 562-573, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: Several index structures have been proposed in the literature that significantly improve the search operation in multidimensional spaces. Some examples of these include the R fl -tree [BKSS90], the X-tree [BKK96], HB-tree [LS90] and GiST <ref> [HNP95] </ref>. The performance of these structures is good for few dimensions, but as the number of dimensions increases beyond 10, the performance degrades significantly [AFS93]. An effective technique for improving the performance of the index structures is to employ parallelism.
Reference: [Jag91] <author> H. V. Jagadish. </author> <title> A retrieval technique for similar shapes. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 208-217, </pages> <year> 1991. </year>
Reference-contexts: The most common approach is to map each data object into a high-dimensional space such that the distance between two such points is a measure of the similarity between the corresponding data objects the closer the points in the high-dimensional space, the more similar the data objects <ref> [MM96, Jag91] </ref>. The number of dimensions necessary for satisfactory mapping can be very large, and dimensionality reduction techniques are first employed to reduce the fl Work supported by a research grant from NSF/ARPA/NASA IRI9411330, NSF instrumentation grant CDA-9421978 and NSF grant CCR97-12108. number of dimensions to smaller values [AFS93].
Reference: [KP88] <author> M. H. Kim and S. Pramanik. </author> <title> Optimal file distribution for partial match retrieval. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 173-182, </pages> <address> Chicago, </address> <year> 1988. </year>
Reference-contexts: The problem of declustering a high-dimensional space across multiple disks has been well studied in the context of relational databases, where the goal has been to improve the performance of range and partial match queries. Prominent examples of such declustering schemes are HCAM [FB93], Fieldwise Exclusive or FX <ref> [KP88] </ref> and CMD [LSR92] or Disk Modulo [DS82] and error-correcting based techniques [FM89, AE93]. In [BBB + 97], a new declustering technique is developed that optimizes data allocation on multiple disks for nearest-neighbor queries. The authors argue that the existing declustering techniques do not generate adequate declustering for nearest-neighbor queries. <p> M Number of Disks d Number of Dimensions N i Number of Buckets in Dimension i x i Coordinate of Bucket in Dimension i Table 1: Meaning of symbols used (x 0 ; x 1 ; ; x d1 ) to disk ( j=0 The Fieldwise eXclusive or FX approach <ref> [KP88] </ref> allocates the same bucket to disk (b 0 b 1 b d1 ) mod M where b j is the binary representation of x j , represents the bitwise exclusive-OR operator and () 1 0 represents the decimal value of the resulting binary digits.
Reference: [KTP + 96] <author> T. Kimbrel, A. Tomkins, R. H. Patterson, B. Bershad, P. Cao, E. W. Felten, G. Gibson, A. Karlin, and K. Li. </author> <title> A trace-driven comparison of algorithms for parallel prefetching and caching. </title> <booktitle> In 2nd USENIX Symposium on Operating System Design and Implementation, </booktitle> <pages> pages 19-34, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: There has been a significant amount of work investigating the use of parallel techniques for improving I/O performance such as the Scotch parallel storage systems [GSC + 95] which investigate the evolution of RAID technology and parallel prefetching and caching <ref> [KTP + 96] </ref>. In particular, several approaches to decluster data for increasing parallel I/O have been proposed. We now review some of the most prominent declus-tering schemes. The first four schemes discussed have been developed for optimizing range and partial match queries.
Reference: [LS90] <author> D. B. Lomet and B. Salzberg. </author> <title> The hb-tree: A multi-attribute indexing method with good guaranteed performance. </title> <journal> Proc. ACM Symp. on Transactions of Database Systems, </journal> <volume> 15(4) </volume> <pages> 625-658, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Searching for the nearest points in such high-dimensional space is a very computation and I/O intensive operation. Several index structures have been proposed in the literature that significantly improve the search operation in multidimensional spaces. Some examples of these include the R fl -tree [BKSS90], the X-tree [BKK96], HB-tree <ref> [LS90] </ref> and GiST [HNP95]. The performance of these structures is good for few dimensions, but as the number of dimensions increases beyond 10, the performance degrades significantly [AFS93]. An effective technique for improving the performance of the index structures is to employ parallelism.
Reference: [LSR92] <author> J. Li, J. Srivastava, and D. Rotem. CMD: </author> <title> a multidimensional declustering method for parallel database systems. </title> <booktitle> In Proceedings of the Int. Conf. on Very Large Data Bases, </booktitle> <pages> pages 3-14, </pages> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Prominent examples of such declustering schemes are HCAM [FB93], Fieldwise Exclusive or FX [KP88] and CMD <ref> [LSR92] </ref> or Disk Modulo [DS82] and error-correcting based techniques [FM89, AE93]. In [BBB + 97], a new declustering technique is developed that optimizes data allocation on multiple disks for nearest-neighbor queries. The authors argue that the existing declustering techniques do not generate adequate declustering for nearest-neighbor queries.
Reference: [MM96] <author> B. S. Manjunath and W. Y. Ma. </author> <title> Texture features for browsing and retrieval of image data. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 18(8) </volume> <pages> 837-42, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: The most common approach is to map each data object into a high-dimensional space such that the distance between two such points is a measure of the similarity between the corresponding data objects the closer the points in the high-dimensional space, the more similar the data objects <ref> [MM96, Jag91] </ref>. The number of dimensions necessary for satisfactory mapping can be very large, and dimensionality reduction techniques are first employed to reduce the fl Work supported by a research grant from NSF/ARPA/NASA IRI9411330, NSF instrumentation grant CDA-9421978 and NSF grant CCR97-12108. number of dimensions to smaller values [AFS93].
Reference: [NBE + 93] <author> W. Niblack, R. Barber, W. Equitz, M. Flickner, E. Glasman, D. Petkovic, and P. Yanker. </author> <title> The QBIC project: Querying images by content using color, texture and shape. </title> <booktitle> In Proc. of the SPIE Conf. 1908 on Storage and Retrieval for Image and Video Databases, volume 1908, </booktitle> <pages> pages 173-187, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Identifying objects that are similar to each other is a challenging problem for many applications, such as multimedia repositories or digital libraries. Examples of such applications are the QBIC project <ref> [NBE + 93] </ref> and the Alexandria Digital Library [CDN + 97]. In order to automate similarity searching, it is first necessary to define a similarity measure.
Reference: [PAAE98] <author> S. Prabhakar, K. Abdel-Ghaffar, D. Agrawal, and A. El Abbadi. </author> <title> Cyclic allocation of two-dimensional data. </title> <booktitle> In International Conference on Data Engineering, </booktitle> <pages> pages 94-101, </pages> <address> Orlando, Florida, </address> <month> Feb </month> <year> 1998. </year>
Reference-contexts: Through experimentation, it is shown that their approach gives much better performance for nearest-neighbor and 10 nearest-neighbors queries as compared to the HCAM approach, which has been shown to give superior performance for square range queries in two dimensions [FB93]. In a recent study <ref> [PAAE98] </ref>, we proposed a new class of declustering algorithms called Cyclic allocation schemes for two-dimensional data. The schemes were shown to give the best declustering performance for range and partial match queries. It is also shown that the performance of the HCAM approach degrades when non-square queries are considered. <p> The order generated by the hilbert curve is also shown by the directed lines beginning at the top left corner. The Cyclic allocation schemes <ref> [PAAE98] </ref>, defined only for two dimensions, allocate bucket (x 0 ; x 1 ) to disk (x 0 + x 1 fl H) mod M where the value of H is appropriately chosen to ensure good declustering. <p> The value of H, also called the skip value, is the key factor determining the performance of the Cyclic scheme. A good choice of H depends entirely upon the value of M . Three different techniques for determining an appropriate choice of H are described in <ref> [PAAE98] </ref>. The key idea is that H should be relatively prime with respect to M and H 6= 1. One of the techniques for determining the value of H is called Generalized Fibonacci or GFIB. <p> The allocation generated by GFIB is shown in Figure 2 (d). The relative performance of the above schemes for range queries in two dimensions is studied in <ref> [PAAE98] </ref>. The effectiveness of declustering achieved by each scheme is measured as follows. For a query which retrieves A buckets, an optimal declustering would result in no more than d A M e buckets being allocated to any one of the M disks. <p> The Cyclic schemes developed in <ref> [PAAE98] </ref> were optimized for declustering two-dimensional data for range or partial match queries. The first step is extends the schemes to make them applicable to more than two dimensions. <p> In fact, its cost tracks the lower bound and reduces as the number of disks increases. Overall we observe that the Cyclic scheme gives the best performance for nearest-neighbor queries more consistently than any other scheme. Given the success of the cyclic schemes for two-dimensional range queries <ref> [PAAE98] </ref>, and the flexibility for nearest-neighbor queries, we expect that it will give good performance for systems that require both types of queries.
Reference: [PAE97] <author> S. Prabhakar, D. Agrawal, and A. El Abbadi. </author> <title> Efficient disk allocation for fast similarity searching. </title> <type> Technical Report TRCS97-17, </type> <institution> Dept. of Computer Science, Univ. of Calilfornia, Santa Barbara, </institution> <year> 1997. </year> <note> http://www.cs.ucsb.edu/TRs /TRCS97-17.ps. </note>
Reference-contexts: Note however, that in order to obtain d skip values, a minimum number of disks is required. The proof of the following theorem which establishes that for d-dimensions, 2d disks are sufficient is presented in <ref> [PAE97] </ref>. Theorem 1 For a d-dimensional space, it is possible to find d values such that no two direct or indirect neighbors are allocated to the same disk if 2d disks are available. The Cyclic approach requires a choice of skip values. The specific values chosen result in different performance. <p> These two values are chosen because they represent the case where NoD and Cyclic have very different disk requirements (15 dimensions) and the case where they have the same disk requirements (8 dimensions). The results for other cases can be found in <ref> [PAE97] </ref>. 5.1 Achieving near-optimal declustering We begin by studying how effective the various schemes are in achieving near-optimal allocations. For this purpose, we compare the performance of the various schemes under the counts metric. The performance of all the schemes for 8 dimensions is presented in Figure 6.
References-found: 23

