URL: ftp://zeus.cs.gsu.edu/pub/volshevsky/papers/geppdsams.ps
Refering-URL: http://www.cs.gsu.edu/~matvro/papers.html
Root-URL: http://www.cs.gsu.edu
Title: Fast Gaussian Elimination with Partial Pivoting for Matrices with Displacement Structure  
Author: I.Gohberg T.Kailath and V.Olshevsky 
Keyword: Key words. Gaussian elimination, partial pivoting, displacement structure, Toeplitz-like, Cauchy-like, Vandermonde-like, Toeplitz-plus-Hankel matrix, Schur algorithm, Levin-son algorithm.  
Note: AMS subject classification. 15A06, 15A09, 15A23, 15A57, 65F05, 65H10.  
Abstract: Fast O(n 2 ) implementation of Gaussian elimination with partial pivoting is designed for matrices possessing Cauchy-like displacement structure. We show how Toeplitz-like, Toeplitz-plus-Hankel-like and Vandermonde-like matrices can be transformed into Cauchy-like matrices by using Discrete Fourier, Cosine or Sine Transform matrices. In particular this allows us to propose a new fast O(n 2 ) Toeplitz solver GKO, which incorporates partial pivoting. A large set of numerical examples showed that GKO demonstrated stable numerical behavior and can be recommended for solving linear systems, especially with nonsymmetric, indefinite and ill-conditioned positive definite Toeplitz matrices. It is also useful for block Toeplitz and mosaic Toeplitz ( Toeplitz-block ) matrices. The algorithms proposed in this paper suggest an attractive alternative to look-ahead approaches, where one has to jump over ill-conditioned leading submatrices, which in the worse case requires O(n 3 ) operations. 
Abstract-found: 1
Intro-found: 1
Reference: [AG] <author> G.Ammar and P.Gader, </author> <title> New decompositions of the inverse of a Toeplitz matrix, Signal processing, Scattering and Operator Theory, and Numerical Methods, </title> <booktitle> Proc. Int. Symp. MTNS-89, </booktitle> <volume> vol. III, </volume> <pages> 421-428, </pages> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference: [B] <author> A.W.Bojanczyk, </author> <title> private communication. </title>
Reference-contexts: Observe that the analysis in [BBHS] assumes that the actually computed reflection coefficients are positive. Therefore that analysis is valid in fact only for a special subclass of positive definite Toeplitz matrices and is not applicable for this situation. In <ref> [B] </ref> it was shown that to guarantee that the reflection coefficients of a positive definite Toeplitz 16 matrix, computed via the classical Schur algorithm, will remain less than 1 in magnitude, one has to require that u k 2 (T ) be less than some constant of the order of O
Reference: [BBHG] <author> A.W.Bojanczyk, R.P.Brent, F.R. de Hoog and D.R.Sweet, </author> <title> On the stability of the Bareiss and related Toeplitz factorization algorithms, </title> <note> to appear in SIAM J. on Matrix Analysis. </note>
Reference: [BDF] <author> E.Bozzo and C.Di Fiore, </author> <title> On the use of certain Matrix algebras associated with Discrete Trigonometric Transforms in Matrix Displacement Decomposition, </title> <note> to appear in SIAM J. of Natrix Analysis. </note>
Reference-contexts: In what follows we shall use the fact that the matrices Y fl;ffi with fl; ffi 2 f1; 1g or fl = ffi = 0, can be diagonalized by Fast Trigonometric Transform matrices. In particular the following statement holds ( see for example <ref> [BDF] </ref> ). 9 Lemma 4.1 Let Y fl;ffi be defined as in (0.4).
Reference: [BGR] <author> J. Ball, I.Gohberg and L.Rodman, </author> <title> Interpolation of rational matrix functions, </title> <publisher> OT45, Birkhauser Verlag, </publisher> <address> Basel, </address> <year> 1990. </year>
Reference: [C] <author> G.Cybenko, </author> <title> The numerical stability of Levinson-Durbin algorithm for Toeplitz systems of equations, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 1 (1980), 303 - 319. </volume>
Reference-contexts: We describe the results of several numerical experiments. 6.1 Positive definite Toeplitz matrices For positive definite Toeplitz matrices with positive reflection coefficients, Cybenko showed in <ref> [C] </ref> that the Levinson algorithm guarantees the same size of residual error as the stable Cholesky factorization. He pointed out that his proof does not extend to the case where there are negative reflection coefficients. Example 1. <p> Levinson algorithm. For positive definite Toeplitz matrices with positive reflection coefficients, the Levinson algorithm is as stable in practice as GECP and GKO; results consistent with those of Cybenko <ref> [C] </ref>. For positive definite Toeplitz matrices, whose reflection coefficients do not have the same sign, the Levinson algorithm may be less accurate and can produce residual errors larger than those of stable GECP. With symmetric indefinite and nonsymmetric Toeplitz matrices, the Levinson algorithm is less accurate than GECP and GKO.
Reference: [CK1] <author> J.Chun and T.Kailath, </author> <title> Fast triangularization and orthogonalization of Hankel and Vandermonde matrices, </title> <journal> Linear Algebra Appl., </journal> <volume> 151 (1991), 199 - 228. </volume>
Reference: [CK2] <author> J.Chun and T.Kailath, </author> <title> Generalized displacement structure for block-Toeplitz, Toeplitz-block, and Toeplitz-derived matrices, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 15, No. 1 (1994), 114 - 128. </volume>
Reference-contexts: 6e-5 8e-6 8e-4 8e-5 240 9e+2 1e+2 2e+1 1e+2 3e-5 1e-6 2e-1 4e-2 2e-4 8e-6 3e-3 2e-4 6.4 Mosaic Toeplitz ( or Toeplitz-block ) matrices We also applied the algorithms GECP, GKO and TpH for solving linear systems with mosaic Toeplitz [HR] ( the designation Toeplitz-block was also used, see <ref> [CK2] </ref> ) matrices to test problems where the displacement rank of a matrix is greater than for ordinary Toeplitz matrices. In particular we checked the matrices of the form T 2n = C D where A; B; C; D are themselves Toeplitz matrices. Example 8.
Reference: [GK] <author> I.Gohberg and I.Koltracht, </author> <title> Efficient algorithm for Toeplitz plus Hankel matrices, Integral Equations and Operator Theory, </title> <booktitle> 12 (1989), </booktitle> <volume> 136 - 142. </volume>
Reference-contexts: see that the sum of any Toeplitz and Hankel matrices R = T + H = t ij 1i;jn + h i+j2 1i;jn satisfies rankr fY 00 ;Y 11 g (T + H) = Y 00 (T + H) (T + H) Y 11 4 (4.1) ( cf. with [HJR], <ref> [GK] </ref> and [SLAK] ). Indeed, let R = T + H = r ij 1i;jn , and A = r fY 00 ;Y 11 g (R) = a ij 1i;jn . Note that the matrix Y fl;ffi is essentially a combination of lower and upper shifts.
Reference: [GKX1] <author> I.Gohberg, I.Koltracht and D.Xiao, </author> <title> On the solution of Yule-Walker equations, </title> <booktitle> Proc. of SPIE conference of advanced algorithms and architectures for signal processing IV, </booktitle> <volume> 1566, </volume> <month> July </month> <year> 1991, </year> <pages> 14-22. </pages>
Reference-contexts: GECP. There is no numerical superiority of fast O (n 2 ) Toeplitz solvers over general purpose algorithm O (n 3 ) GECP. This corresponds to the results of <ref> [GKX1] </ref>, [GKX2], where it was found that there is a little difference between the structured condition number and condition number of a positive definite Toeplitz matrix. Levinson algorithm.
Reference: [GKX2] <author> I.Gohberg, I.Koltracht and D.Xiao, </author> <title> Condition and accuracy of algorithms for computing Schur coefficients of Toeplitz matrices, </title> <journal> Siam J. of Matrix Analysis, </journal> <volume> /bf 15, No. 4 (1994), 1290 - 1309. </volume>
Reference-contexts: GECP. There is no numerical superiority of fast O (n 2 ) Toeplitz solvers over general purpose algorithm O (n 3 ) GECP. This corresponds to the results of [GKX1], <ref> [GKX2] </ref>, where it was found that there is a little difference between the structured condition number and condition number of a positive definite Toeplitz matrix. Levinson algorithm.
Reference: [GL] <author> G. Golub and C, Van Loan, </author> <title> Matrix Computations, </title> <note> second edition, </note> <author> John Hopkins U. P., Baltimore, </author> <year> 1989. </year>
Reference: [GO1] <author> I.Gohberg and V.Olshevsky, Circulants, </author> <title> displacements and decompositions of matrices, Integral Equations and Operator Theory, </title> <journal> 15, </journal> <volume> No. </volume> <month> 5 </month> <year> (1992), </year> <note> 730 -743. </note>
Reference: [GO2] <author> I.Gohberg and V.Olshevsky, </author> <title> Complexity of multiplication with vectors for structured matrices, </title> <journal> Linear Algebra Appl., </journal> <volume> 202 (1994), 163 - 192. </volume> <pages> 20 </pages>
Reference-contexts: It can be easily checked that the Vandermonde matrix V (x) = x i 1i;jn satisfies the equation r fD 1 x x 1 = 1 1 x n 1 0 0 ; ( cf. with [HR], <ref> [GO2] </ref> ). By analogy with (5.1) we shall refer to any matrix R with low fD 1 ; Z T 1 g-displacement rank as a Vandermonde-like matrix. Remark that although this definition slightly deviates from the one in [HR], it describes in fact the same class of matrices.
Reference: [GO3] <author> I.Gohberg and V.Olshevsky, </author> <title> Fast algorithm for matrix Nehari problem, </title> <booktitle> Proceedings of MTNS-93, Systems and Networks: Mathematical Theory and Applications, </booktitle> <editor> v.2, Invited and Contributed Papers,edited by U. Helmke, R. Mennicken and J. Sauers, Academy Verlag,1994, p. </editor> <month> 687-690. </month>
Reference: [GO4] <author> I.Gohberg and V.Olshevsky, </author> <title> Fast state space algorithms for matrix Nehari and Nehari-Takagi interpolation problems, Integral Equations and Operator Theory, </title> <journal> 20, </journal> <volume> No. 1, </volume> <year> 1994, </year> <note> 44 - 83.. </note>
Reference: [H] <author> Heinig G. </author> <title> Inversion of generalized Cauchy matrices and other classes of structured matrices, in : Linear Algebra in Signal Processing, </title> <journal> IMA volumes in Mathematics and its Applications, </journal> <volume> vol. 69 (1994), 95 - 114. </volume>
Reference: [HJR] <author> G.Heinig, P.Jankowski and K.Rost, </author> <title> Fast inversion of Toeplitz-plus-Hankel matrices, </title> <journal> Numer.Math. </journal> <volume> 52 (1988), 665 - 682. </volume>
Reference-contexts: to see that the sum of any Toeplitz and Hankel matrices R = T + H = t ij 1i;jn + h i+j2 1i;jn satisfies rankr fY 00 ;Y 11 g (T + H) = Y 00 (T + H) (T + H) Y 11 4 (4.1) ( cf. with <ref> [HJR] </ref>, [GK] and [SLAK] ). Indeed, let R = T + H = r ij 1i;jn , and A = r fY 00 ;Y 11 g (R) = a ij 1i;jn . Note that the matrix Y fl;ffi is essentially a combination of lower and upper shifts.
Reference: [HR] <author> Heinig G., Rost K., </author> <title> Algebraic methods for Toeplitz-like matrices and operators, </title> <journal> Operator Theory, </journal> <volume> vol. 13, </volume> <publisher> Birkhauser, </publisher> <address> Basel, </address> <year> 1984. </year>
Reference-contexts: It can be easily checked that the Vandermonde matrix V (x) = x i 1i;jn satisfies the equation r fD 1 x x 1 = 1 1 x n 1 0 0 ; ( cf. with <ref> [HR] </ref>, [GO2] ). By analogy with (5.1) we shall refer to any matrix R with low fD 1 ; Z T 1 g-displacement rank as a Vandermonde-like matrix. Remark that although this definition slightly deviates from the one in [HR], it describes in fact the same class of matrices. <p> 1 1 x n 1 0 0 ; ( cf. with <ref> [HR] </ref>, [GO2] ). By analogy with (5.1) we shall refer to any matrix R with low fD 1 ; Z T 1 g-displacement rank as a Vandermonde-like matrix. Remark that although this definition slightly deviates from the one in [HR], it describes in fact the same class of matrices. <p> 200 1e+2 1e+2 1e+1 6e+1 2e-6 2e-6 9e-3 2e-3 6e-5 8e-6 8e-4 8e-5 240 9e+2 1e+2 2e+1 1e+2 3e-5 1e-6 2e-1 4e-2 2e-4 8e-6 3e-3 2e-4 6.4 Mosaic Toeplitz ( or Toeplitz-block ) matrices We also applied the algorithms GECP, GKO and TpH for solving linear systems with mosaic Toeplitz <ref> [HR] </ref> ( the designation Toeplitz-block was also used, see [CK2] ) matrices to test problems where the displacement rank of a matrix is greater than for ordinary Toeplitz matrices.
Reference: [K] <author> T.Kailath, </author> <title> Signal processing applications of some moment problems, in Moments in Mathematics (H.Landau, ed.), </title> <journal> AMS, </journal> <volume> vol. </volume> <pages> 37, </pages> <address> Providence, </address> <year> 1987, </year> <pages> 71 - 109. </pages>
Reference: [KKM] <author> T.Kailath, S.Kung and M.Morf, </author> <title> Displacement ranks of matrices and linear equations, </title> <journal> J. Math. Anal. and Appl., </journal> <volume> 68 (1979), </volume> <pages> 395-407. </pages>
Reference-contexts: By analogy with (3.1), a matrix with low fZ 1 ; Z 1 g-displacement rank is referred to as a Toeplitz-like matrix. Note, that this definition slightly deviates from the one in <ref> [KKM] </ref>, where the displacement operator of the form r fZ 0 ;Z T 0 g (T ) = T Z 0 T Z T 0 was exploited.
Reference: [KO1] <author> T.Kailath and V.Olshevsky, </author> <title> Displacement structure approach to Chebyshev-Vander-monde and related matrices, to appear in Integral Equations and Operator Theory, </title> <year> 1995. </year>
Reference: [KO2] <author> T.Kailath and V.Olshevsky, </author> <title> Displacement structure approach to polynomial Vander-monde and related matrices, </title> <type> preprint, </type> <year> 1994. </year>
Reference: [KS1] <author> T. Kailath and A.H.Sayed, </author> <title> Fast algorithms for generalized displacement structures, </title> <booktitle> in Recent advances in mathematical theory of systems, control, networks and signal processing II, Proc. of the MTNS-91 (H.Kimura, </booktitle> <editor> S.Kodama, Eds.), </editor> <publisher> Mita Press, </publisher> <address> Japan, </address> <year> 1992, </year> <pages> 27 - 32. </pages>
Reference: [KS2] <author> T. Kailath and A.H.Sayed, </author> <title> Displacement structure : theory and applications, </title> <note> SIAM Review, to appear. </note>
Reference: [LAK] <author> H. Lev-Ari and T.Kailath, </author> <title> Triangular factorization of structured Hermitian matrices, Operator Theory : Advances and Applications, </title> <journal> 18 (19986), </journal> <volume> 301 -324, </volume> <editor> (I.Gohberg, ed.), </editor> <publisher> Birkhauser, </publisher> <address> Boston. </address>
Reference: [LT] <author> P.Lancaster and M.Tismenetsky, </author> <title> Theory of matrices with applications, 2nd ed., </title> <publisher> Academic press, </publisher> <address> Orlando, </address> <year> 1985. </year>
Reference: [P] <author> V.Pan, </author> <title> On computations with dense structured matrices, </title> <journal> Math. of Computation, </journal> <volume> 55, No. 191 (1990), 179 - 190. </volume>
Reference: [PD] <author> J. Pasupathy and R.A. Damodar, </author> <title> The Gaussian Toeplitz matrix, </title> <journal> Linear Algebra and Appl., </journal> <volume> 171 (1992),133 - 147. </volume>
Reference-contexts: Thus another example is the Gaussian Toeplitz matrix T n = t ij 1n where t k = a k 2 0 &lt; a &lt; 1, with a close to 1. The background on a Gaussian Toeplitz matrix can be found in <ref> [PD] </ref>. We mention here only that this positive definite matrix arises as a discretization of Gaussian convolution and that k 2 (T n ) (1 a 2 )(1 a 4 ) (1 a 2 (n1) ) One can check that the reflection coefficients of T n also alternate in sign.
Reference: [S] <author> I.Schur, </author> <title> Uber potenzreeihen die im Inneren des Einheitskreises beschrankt sind, </title> <journal> Journal fur die Reine und Angewandte Mathematik, </journal> <volume> 147 (1917), 205 - 232. </volume> <booktitle> English translation : in Operator Theory : Advances and Applications (I.Gohberg. </booktitle> <editor> ed.), </editor> <volume> vol. 18, 31 - 88, </volume> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1986. </year>
Reference: [SLAK] <author> A.Sayed, H.Lev-Ari and T.Kailath, </author> <title> Fast triangular factorization of the sum of quasi-Toeplitz and quasi-Hankel matrices, </title> <journal> Linear Algebra and Appl., </journal> <volume> 191 (1993), 77 - 106. </volume>
Reference-contexts: the sum of any Toeplitz and Hankel matrices R = T + H = t ij 1i;jn + h i+j2 1i;jn satisfies rankr fY 00 ;Y 11 g (T + H) = Y 00 (T + H) (T + H) Y 11 4 (4.1) ( cf. with [HJR], [GK] and <ref> [SLAK] </ref> ). Indeed, let R = T + H = r ij 1i;jn , and A = r fY 00 ;Y 11 g (R) = a ij 1i;jn . Note that the matrix Y fl;ffi is essentially a combination of lower and upper shifts.
Reference: [V] <author> J.M. Varah, </author> <title> The Prolate Matri, </title> <journal> Linear Algebra and Appl., </journal> <volume> 187 (1993), 269 - 278. </volume> <pages> 22 </pages>
Reference-contexts: He pointed out that his proof does not extend to the case where there are negative reflection coefficients. Example 1. In <ref> [V] </ref> ( see also [BBHS]) it was observed that the Levinson algorithm can produce residual errors that are larger by a factor of the order of 10 3 10 5 than those of a general stable method ( Cholesky factorization ), when applied to the prolate matrix with w = 1 <p> matrix with w = 1 4 , for which reflection coefficients alternate in sign; the prolate matrix is defined by T n = t ij 1n where t k = 2! if k = 0; k otherwise; (0 ! 2 The background on the prolate matrix can be found in <ref> [V] </ref>. We mention here only that it possesses remarkable spectral and conditioning properties. For small !, its eigenvalues are clustered around 0 and 1, which makes it extremely ill-conditioned. <p> The data in Table 2 confirm the conclusion of <ref> [V] </ref> that the Levinson algorithm can give poor results. However, it turns out, very interestingly, that the classical Schur algorithm and new Toeplitz solver GKO applied to the prolate matrix remain as accurate as the stable GECP algorithm. Table 2. Prolate matrix with ! = 1 4 .
References-found: 32

