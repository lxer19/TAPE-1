URL: http://www.cs.unc.edu/~ramamurt/papers/PODC96.ps.Z
Refering-URL: http://www.cs.unc.edu/~ramamurt/papers.html
Root-URL: http://www.cs.unc.edu
Title: Real-Time Object Sharing with Minimal System Support (Extended Abstract)  
Author: Srikanth Ramamurthy, Mark Moir, and James H. Anderson 
Address: Chapel Hill  
Affiliation: Department of Computer Science, University of North Carolina at  
Abstract: We show that any object with consensus number P in Herlihy's wait-free hierarchy is universal in a hard real-time system consisting of any number of tasks on P processors. An important special case of this result is that, for hard real-time applications on uniprocessors, reads and writes are universal. Thus, Herlihy's hierarchy collapses for such applications. We also show that, by exploiting timing information already required for real-time scheduling analysis, reads and writes can be made universal for real-time applications on multiprocessors. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Multi-Object Operations", </title> <booktitle> Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing , 1995, </booktitle> <pages> pp. 184-193. </pages>
Reference-contexts: We show that such primitives can be implemented efficiently on real-time uniprocessors by considering implementations of C&S; these implementations can, in turn, be used to implement LL/SC in constant time <ref> [1] </ref>. We give two N -task implementations of C&S. The first uses only reads and writes, and has O (N ) space and time complexity. The second is based upon a memory-to-memory move instruction (Move) and has O (1) time complexity and O (N ) space complexity. <p> More practical wait-free and lock-free implementations are based on primitives such as C&S and LL/SC. To enable such implementations to be used in real-time uniprocessor systems, we present two implementations of Read and C&S. (LL/SC can be implemented using Read and C&S in constant time <ref> [1] </ref>.) These implementations use Read/Write and Move, respectively. <p> 1::2N 1 ] of 1::N ; Val : array [ 1::N ] of valtype; Rv : array [ 1::N ] of valtype [ ?; Pm : array [ 1::N ] of boolean; V : valtype initially (8k : 1 k &lt; 2N :: Buf [k] = 1) ^ V al <ref> [1] </ref> = init val ) private var i : integer; w, maj : 1::N ; current : valtype; count : array [1::N ] of 0::2N 1 procedure Read () returns valtype 1 : Pm [ p ], count := false, (0; : : : ; 0); for i := 1 to <p> The following definition states that the current value CV of the implemented shared variable is determined by the task identifier that is stored in a majority of the locations Buf <ref> [1] </ref> through Buf [2N 1]. (It can be shown that such a majority always exists and is unique.) CV (Val [p] :: p is a majority in Buf ) In order to perform a C&S operation, a task p first attempts to determine CV.
Reference: [2] <author> J. Anderson, S. Ramamurthy, and K. Jeffay, </author> <title> "Real-Time Computing with Lock-Free Shared Objects", </title> <booktitle> to appear in the Proceedings of the 16th IEEE Real-Time Systems Symposium, </booktitle> <year> 1995. </year>
Reference-contexts: On uniprocessors, Anderson, Ramamurthy, and Jeffay have shown that such overhead can be avoided altogether by using lock-free, rather than wait-free, object implementations <ref> [2] </ref>. On the surface, it is not immediately apparent that lock-free shared objects can be employed if tasks must adhere to strict timing constraints. <p> In particular, lock-free implementations permit concurrent operations to interfere with each other, and repeated interferences can cause a given operation to take an arbitrarily long time to complete. The main contribution of <ref> [2] </ref> is to show that such interferences can be bounded on uniprocessors by judicious scheduling. Another possible reason for the lack of acceptance of wait-free and lock-free object implementations among real-time practitioners is that many published implementations require strong synchronization primitives such as compare-and-swap (C&S).
Reference: [3] <author> M. Herlihy, </author> <title> "Wait-Free Synchronization", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 13, No. 1, </volume> <year> 1991, </year> <pages> pp. 124-149. </pages>
Reference-contexts: The fact that many published wait-free and lock-free object implementations are based on strong synchronization primitives is no accident. Herlihy has shown that such strong primitives are, in general, necessary for these implementations <ref> [3] </ref>. Herlihy's results are based upon a categorization of synchronization objects by "consensus number". An object has consensus number N if it can be used to solve N -process consensus, but not (N + 1)-process consensus, in a wait-free (or lock-free) manner. <p> The results mentioned above are obtained by showing how to solve wait-free consensus within our real-time task model. Although our consensus protocols can be used to implement wait-free and lock-free objects directly <ref> [3, 5] </ref>, implementations of practical interest are usually based on universal primitives such as C&S or LL/SC. We show that such primitives can be implemented efficiently on real-time uniprocessors by considering implementations of C&S; these implementations can, in turn, be used to implement LL/SC in constant time [1]. <p> Using consensus objects, any shared object can be implemented in a wait-free manner <ref> [3, 5] </ref>. However, such implementations usually entail high overhead. More practical wait-free and lock-free implementations are based on primitives such as C&S and LL/SC. <p> Thus, on most multiprocessor systems with three or more processors that do not provide universal primitives, Herlihy's results about fully-asynchronous systems imply that general object constructions are not possible <ref> [3] </ref>. In the following subsection, we show that, by making certain timing assumptions, it is indeed possible to implement wait-free universal primitives in such systems.
Reference: [4] <author> M. G. Harbour, M. H. Klein, and J. P. Lehoczky, </author> <title> "Fixed Priority Scheduling of Periodic Tasks with Varying Execution Priority", </title> <booktitle> Proceedings of the 12th IEEE Real-Time Systems Symposium, </booktitle> <year> 1991, </year> <pages> pp. 116-128. </pages>
Reference-contexts: Assumption (ii) also holds for variations of RM, DM, and EDF scheduling in which tasks are broken into phases that are allowed to have distinct priorities <ref> [4] </ref>. The only common scheduling policy that we know of that violates assumption (ii) is least-laxity-first (LLF) scheduling [8]. Under LLF scheduling, the priority of a task invocation can change during its execution.
Reference: [5] <author> P. Jayanti and S. Toueg, </author> <title> "Some Results on the Impossibility, Universality, and Decidability of Consensus", </title> <booktitle> Proceedings of the 6th International Workshop on Distributed Algorithms, </booktitle> <address> Haifa, Israel, </address> <month> Nov. </month> <year> 1992, </year> <pages> pp. 69-84. </pages>
Reference-contexts: The results mentioned above are obtained by showing how to solve wait-free consensus within our real-time task model. Although our consensus protocols can be used to implement wait-free and lock-free objects directly <ref> [3, 5] </ref>, implementations of practical interest are usually based on universal primitives such as C&S or LL/SC. We show that such primitives can be implemented efficiently on real-time uniprocessors by considering implementations of C&S; these implementations can, in turn, be used to implement LL/SC in constant time [1]. <p> Using consensus objects, any shared object can be implemented in a wait-free manner <ref> [3, 5] </ref>. However, such implementations usually entail high overhead. More practical wait-free and lock-free implementations are based on primitives such as C&S and LL/SC. <p> Results of Jayanti and Toueg imply that, given universal consensus objects, C&S can be implemented with time complexity O (N 2 ) and space complexity O (N 3 ) <ref> [5] </ref>. Their construction uses O (N 3 ) consensus objects, and performs at most O (N ) consensus object accesses per operation. Thus, combining Theorem 4 with the results of [5] yields the following corollary. <p> consensus objects, C&S can be implemented with time complexity O (N 2 ) and space complexity O (N 3 ) <ref> [5] </ref>. Their construction uses O (N 3 ) consensus objects, and performs at most O (N ) consensus object accesses per operation. Thus, combining Theorem 4 with the results of [5] yields the following corollary.
Reference: [6] <author> J.Y.T. Leung and J. Whitehead, </author> <title> "On the Complexity of Fixed-Priority Scheduling of Periodic, Real-Time Tasks", </title> <journal> Performance Evaluation, </journal> <volume> Vol. 2, No. 4, </volume> <year> 1982, </year> <pages> pp. 237-250. </pages>
Reference-contexts: However, we do relax this assumption by allowing short nonpreemptable code fragments when considering object implementations for multiprocessors. Assumption (i) is fundamental to all priority-driven scheduling policies. Assumption (ii) holds for most common policies, including rate-monotonic (RM) [7], deadline-monotonic (DM) <ref> [6] </ref>, and earliest-deadline-first (EDF) [7] scheduling. Under RM and DM scheduling, task priorities are static, i.e., do not change over system. Line segments denote operations on shared objects with time running from left to right. Each level corresponds to operations by a different task. time.
Reference: [7] <author> C. Liu and J. Layland, </author> <title> "Scheduling Algorithms for multiprogramming in a Hard Real-Time Environment", </title> <journal> Journal of the ACM , Vol 30., </journal> <month> Jan. </month> <year> 1973, </year> <pages> pp. 46-61. </pages>
Reference-contexts: However, we do relax this assumption by allowing short nonpreemptable code fragments when considering object implementations for multiprocessors. Assumption (i) is fundamental to all priority-driven scheduling policies. Assumption (ii) holds for most common policies, including rate-monotonic (RM) <ref> [7] </ref>, deadline-monotonic (DM) [6], and earliest-deadline-first (EDF) [7] scheduling. Under RM and DM scheduling, task priorities are static, i.e., do not change over system. Line segments denote operations on shared objects with time running from left to right. Each level corresponds to operations by a different task. time. <p> However, we do relax this assumption by allowing short nonpreemptable code fragments when considering object implementations for multiprocessors. Assumption (i) is fundamental to all priority-driven scheduling policies. Assumption (ii) holds for most common policies, including rate-monotonic (RM) <ref> [7] </ref>, deadline-monotonic (DM) [6], and earliest-deadline-first (EDF) [7] scheduling. Under RM and DM scheduling, task priorities are static, i.e., do not change over system. Line segments denote operations on shared objects with time running from left to right. Each level corresponds to operations by a different task. time.
Reference: [8] <author> A. Mok, </author> <title> Fundamental Design Problems of Distributed Systems for the Hard Real-Time Environ 11 ment, </title> <type> Ph.D. Thesis, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1983. </year>
Reference-contexts: Assumption (ii) also holds for variations of RM, DM, and EDF scheduling in which tasks are broken into phases that are allowed to have distinct priorities [4]. The only common scheduling policy that we know of that violates assumption (ii) is least-laxity-first (LLF) scheduling <ref> [8] </ref>. Under LLF scheduling, the priority of a task invocation can change during its execution. We leave open the question of whether it is possible to apply our results to a modified version of LLF scheduling in which task priorities do not change during object accesses.
Reference: [9] <author> Raghunathan Rajkumar, </author> <title> Synchronization In Real-Time Systems APriority Inheritance Approach, </title> <publisher> Kluwer Academic Publications, </publisher> <year> 1991. </year>
Reference-contexts: The main problem when using such protocols is that of priority inversion, i.e., the situation in which a given task waits for another task of lower priority to unlock an object. Mechanisms such as the priority ceiling protocol (PCP) <ref> [9, 10] </ref> are used to solve this problem. The PCP requires the kernel to dynamically adjust task priorities to ensure that a task within a critical section executes at a priority that is sufficiently high to bound the duration of any priority inversion.
Reference: [10] <author> L. Sha, R. Rajkumar, and J. Lehoczky, </author> <title> "Priority Inheritance Protocols: An Approach to Real-Time System Synchronization", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 39, No. 9, </volume> <year> 1990, </year> <pages> pp. 1175-1185. 12 </pages>
Reference-contexts: The main problem when using such protocols is that of priority inversion, i.e., the situation in which a given task waits for another task of lower priority to unlock an object. Mechanisms such as the priority ceiling protocol (PCP) <ref> [9, 10] </ref> are used to solve this problem. The PCP requires the kernel to dynamically adjust task priorities to ensure that a task within a critical section executes at a priority that is sufficiently high to bound the duration of any priority inversion.
References-found: 10

