URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/umsi-98-97.ps.gz
Refering-URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/
Root-URL: http://www.cs.umn.edu
Title: A deflated version of the Conjugate Gradient Algorithm  
Author: Y. Saad M. Yeung J. Erhel F. Guyomarc'h 
Keyword: Key words: Conjugate Gradient; deflation; multiple right-hand sides; Lanczos algorithm.  
Date: May 19, 1998  
Abstract: We present a deflated version of the conjugate gradient algorithm for solving linear systems. The new algorithm can be useful in cases when a small number of eigenvalues of the iteration matrix are very close to the origin. It can also be useful when solving linear systems with multiple right-hand sides, since the eigenvalue information gathered from solving one linear system can be recycled for solving the next systems and then updated.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. F. Ashby, T. A. Manteuffel and P. E. </author> <title> Saylor, A taxonomy for conjugate gradient methods, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 27 (1990), </volume> <pages> pp. 1542-1568. </pages>
Reference-contexts: Then the minimization property leads to the desired result. 2 Deflated-CG can also be viewed as a Preconditioned Conjugate Gradient (PCG) but with a singular preconditioner. Define C = HH T : We use the taxonomy defined in <ref> [1] </ref>, where two versions of PCG are denoted by Omin (A; C; A) and Odir (A; C; A). <p> Therefore Deflated-CG converges. Proof. Since ff j = (r j ; r j ), we have ff j 6= 0 except if x j is the exact solution. Hence Deflated-CG does not break down and, as shown in <ref> [1] </ref>, both versions Omin and Odir are equivalent. Now, using theorem 3.1 in [1], we infer that Deflated-CG converges. 2 To derive the convergence rate, we prove another equivalence. <p> Proof. Since ff j = (r j ; r j ), we have ff j 6= 0 except if x j is the exact solution. Hence Deflated-CG does not break down and, as shown in <ref> [1] </ref>, both versions Omin and Odir are equivalent. Now, using theorem 3.1 in [1], we infer that Deflated-CG converges. 2 To derive the convergence rate, we prove another equivalence. Theorem 4.7 Deflated-CG is equivalent to Conjugate Gradient, version Omin (A,I,A), applied to the linear system H T AH ~x = H T b.
Reference: [2] <author> A. Chapman and Y. Saad, </author> <title> Deflated and augmented Krylov subspace techniques, </title> <journal> Numer. </journal> <note> Linear Algebra Appl., to appear. </note>
Reference-contexts: It has been observed that significant improvements in convergence rates can be achieved from Krylov subspace methods by adding to these subspaces a few approximate eigenvectors associated with the eigenvalues closest to zero <ref> [2, 4, 7, 8, 13, 14] </ref>. In practice, approximations to the eigenvectors closest to zero are obtained from the use of a certain Krylov subspace, then these approximations are dynamically updated using the new Krylov subspace. <p> Results of experiments obtained from these variations indicate that the improvement in convergence over standard Krylov subspaces of the same dimension can sometimes be substantial, especially when the convergence of the original scheme is hampered by a small number of eigenvalues near zero, see e.g., <ref> [2, 8] </ref>. In this paper we consider extensions of this idea to the Conjugate Gradient algorithm for the symmetric case. Our starting point is an algorithm recently proposed by Erhel and Guyomarc'h [5]. This is an augmented subspace Conjugate Gradient method aimed at linear systems with several right-hand sides. <p> An alternative whose goal is to maintain a similar convergence 8 rate, is to adopt the idea of eigenvalue deflation, as used in the Deflated-GMRES algorithm for example, see <ref> [2, 4, 8] </ref>. Deflated GMRES injects a few approximate eigenvectors into its Krylov solution subspace. These approximate eigenvectors are usually selected to be those hampering the convergence of the original scheme. <p> After the s-th system of (22) is solved, we update the set W (s) of approximate eigenvectors to be used for the next right-hand side, yielding a new system W (s+1) . In <ref> [2] </ref>, three projection techniques are described to obtain such approximations. Here we only describe one of them suggested by Morgan [8] and referred to as harmonic projection. This approach yielded the best results in finding eigenvalues nearest zero.
Reference: [3] <author> M. O. Bristeau and J. Erhel, </author> <title> Augmented Conjugate Gradient. Application in an iterative process for the solution of scattering problems, </title> <address> http://www.irisa.fr/aladin /perso/erhel.html, </address> <year> 1998. </year>
Reference-contexts: The disadvantage of this approach is that the memory requirements could be huge when m is large <ref> [3] </ref> since it requires keeping a basis of an earlier Krylov subspace K m (A; x 0 ). An alternative whose goal is to maintain a similar convergence 8 rate, is to adopt the idea of eigenvalue deflation, as used in the Deflated-GMRES algorithm for example, see [2, 4, 8].
Reference: [4] <author> J. Erhel, K. Burrage and B. Pohl, </author> <title> Restarted GMRES preconditioned by deflation, </title> <journal> Journal of Computational and Applied Mathematics, </journal> <volume> 69 (1996), </volume> <pages> pp. 303-318. </pages>
Reference-contexts: It has been observed that significant improvements in convergence rates can be achieved from Krylov subspace methods by adding to these subspaces a few approximate eigenvectors associated with the eigenvalues closest to zero <ref> [2, 4, 7, 8, 13, 14] </ref>. In practice, approximations to the eigenvectors closest to zero are obtained from the use of a certain Krylov subspace, then these approximations are dynamically updated using the new Krylov subspace. <p> An alternative whose goal is to maintain a similar convergence 8 rate, is to adopt the idea of eigenvalue deflation, as used in the Deflated-GMRES algorithm for example, see <ref> [2, 4, 8] </ref>. Deflated GMRES injects a few approximate eigenvectors into its Krylov solution subspace. These approximate eigenvectors are usually selected to be those hampering the convergence of the original scheme.
Reference: [5] <author> J. Erhel and F. Guyomarc'h, </author> <title> An augmented subspace Conjugate Gradient, </title> <address> http://www.irisa.fr /al-adin/perso/erhel.html, </address> <year> 1997. </year>
Reference-contexts: In this paper we consider extensions of this idea to the Conjugate Gradient algorithm for the symmetric case. Our starting point is an algorithm recently proposed by Erhel and Guyomarc'h <ref> [5] </ref>. This is an augmented subspace Conjugate Gradient method aimed at linear systems with several right-hand sides. Erhel and Guyomarc'h [5] propose an algorithm which adds one specific vector obtained from a subspace related to a previous right-hand side. <p> Our starting point is an algorithm recently proposed by Erhel and Guyomarc'h <ref> [5] </ref>. This is an augmented subspace Conjugate Gradient method aimed at linear systems with several right-hand sides. Erhel and Guyomarc'h [5] propose an algorithm which adds one specific vector obtained from a subspace related to a previous right-hand side. We first extend this algorithm to one which handles an arbitrary block W of vectors. <p> This choice was used in <ref> [5, 10, 11, 15] </ref>. A preconditioned version of Deflated-CG can be derived in a straightforward way. Suppose we are solving the split-preconditioned system L 1 AL T y = L 1 b; x = L T y: Set M = LL T . <p> In addition to the matrices A and M , five vectors and three matrices of storage are required: p; Ap; r; x; z; W; AW and W T AW . 4 Theoretical Considerations We observe that Deflated-CG is a generalization of AugCG <ref> [5] </ref> to any subspace W . Since the theory developed in [5] did not use the fact that W was a Krylov subspace, the convergence behavior of Deflated-CG algorithm can be analyzed by exploiting the same theory. <p> the matrices A and M , five vectors and three matrices of storage are required: p; Ap; r; x; z; W; AW and W T AW . 4 Theoretical Considerations We observe that Deflated-CG is a generalization of AugCG <ref> [5] </ref> to any subspace W . Since the theory developed in [5] did not use the fact that W was a Krylov subspace, the convergence behavior of Deflated-CG algorithm can be analyzed by exploiting the same theory. <p> See theorems 2.4, 2.6 and 2.7 in [6] and theorem 2.2 in <ref> [5] </ref>. 2 We can now directly apply the polynomial formalism built in [5] to obtain convergence properties. Theorem 4.4 Let be the condition number of H T AH. Then kx fl x j k A 2 1 + 1 kx fl x 0 k A : (21) Proof. <p> See theorems 2.4, 2.6 and 2.7 in [6] and theorem 2.2 in <ref> [5] </ref>. 2 We can now directly apply the polynomial formalism built in [5] to obtain convergence properties. Theorem 4.4 Let be the condition number of H T AH. Then kx fl x j k A 2 1 + 1 kx fl x 0 k A : (21) Proof. See theorem 3.3 and corollary 3.1 in [5]. <p> directly apply the polynomial formalism built in <ref> [5] </ref> to obtain convergence properties. Theorem 4.4 Let be the condition number of H T AH. Then kx fl x j k A 2 1 + 1 kx fl x 0 k A : (21) Proof. See theorem 3.3 and corollary 3.1 in [5]. Theorem 3.3 proves that r j = P j (AH)r 0 where P j is a polynomial of degree j so that, using (18), we get r j = P j (H T AH)r 0 . <p> This problem has been recently considered by Erhel and Guyomarc'h <ref> [5] </ref>. The main idea in [5] is to solve the first system by CG and to recycle the Krylov subspace K m (A; x 0 ) created in the first system to accelerate the convergence in solving the subsequent systems. <p> This problem has been recently considered by Erhel and Guyomarc'h <ref> [5] </ref>. The main idea in [5] is to solve the first system by CG and to recycle the Krylov subspace K m (A; x 0 ) created in the first system to accelerate the convergence in solving the subsequent systems. <p> Also, we kept the data in the first l = 20 steps and k = 5 approximate eigenvectors associated with smallest eigenvalues were calculated via the QZ algorithm in Matlab, when we solved each system. We compared our Algorithm with Algorithm AugCG <ref> [5] </ref> with m = 30 for the second system (s = 2). All the test matrices were from the Harwell-Boeing Collection 2 . The convergence behavior of system s = 1, corresponding to the standard preconditioned CG algorithm, is plotted with a dotted line.
Reference: [6] <author> Wayne D. Joubert and Thomas A. Manteuffel, </author> <title> Iterative methods for Nonsymmetric Linear Systems, </title> <booktitle> chapter 10, </booktitle> <pages> pages 149-171. </pages> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: It is easy to see that x = W (W T AW ) 1 W T b satisfies (AW ) T x = W T b. Deflated-CG must then start with x 0 given by (16). 2 Proposition 4.2 Algorithm 3.5 is equivalent to the Balanced Projection Method <ref> [6] </ref>, defined by the solution space condition x j+1 x j 2 K k;j (A; W; r 0 ) (19) and the Petrov-Galerkin condition r 0 ? W and r j ? K k;j (A; W; r 0 ): (20) Proof. <p> See theorems 2.4, 2.6 and 2.7 in <ref> [6] </ref> and theorem 2.2 in [5]. 2 We can now directly apply the polynomial formalism built in [5] to obtain convergence properties. Theorem 4.4 Let be the condition number of H T AH.
Reference: [7] <author> S. A. Kharchenko and A. Yu. Yeremin, </author> <title> Eigenvalue translation based preconditioners for the GMRES(k) method, </title> <journal> Numer. Linear Algebra Appl., </journal> <volume> 2 (1995), </volume> <pages> pp. 51-70. </pages>
Reference-contexts: It has been observed that significant improvements in convergence rates can be achieved from Krylov subspace methods by adding to these subspaces a few approximate eigenvectors associated with the eigenvalues closest to zero <ref> [2, 4, 7, 8, 13, 14] </ref>. In practice, approximations to the eigenvectors closest to zero are obtained from the use of a certain Krylov subspace, then these approximations are dynamically updated using the new Krylov subspace.
Reference: [8] <author> R. B. Morgan, </author> <title> A restarted GMRES method augmented with eigenvectors, </title> <journal> SIAM J. Matrix Analysis and Applications, </journal> <volume> 16(4), </volume> <pages> 1154-1171, </pages> <year> 1995. </year>
Reference-contexts: It has been observed that significant improvements in convergence rates can be achieved from Krylov subspace methods by adding to these subspaces a few approximate eigenvectors associated with the eigenvalues closest to zero <ref> [2, 4, 7, 8, 13, 14] </ref>. In practice, approximations to the eigenvectors closest to zero are obtained from the use of a certain Krylov subspace, then these approximations are dynamically updated using the new Krylov subspace. <p> Results of experiments obtained from these variations indicate that the improvement in convergence over standard Krylov subspaces of the same dimension can sometimes be substantial, especially when the convergence of the original scheme is hampered by a small number of eigenvalues near zero, see e.g., <ref> [2, 8] </ref>. In this paper we consider extensions of this idea to the Conjugate Gradient algorithm for the symmetric case. Our starting point is an algorithm recently proposed by Erhel and Guyomarc'h [5]. This is an augmented subspace Conjugate Gradient method aimed at linear systems with several right-hand sides. <p> An alternative whose goal is to maintain a similar convergence 8 rate, is to adopt the idea of eigenvalue deflation, as used in the Deflated-GMRES algorithm for example, see <ref> [2, 4, 8] </ref>. Deflated GMRES injects a few approximate eigenvectors into its Krylov solution subspace. These approximate eigenvectors are usually selected to be those hampering the convergence of the original scheme. <p> In [2], three projection techniques are described to obtain such approximations. Here we only describe one of them suggested by Morgan <ref> [8] </ref> and referred to as harmonic projection. This approach yielded the best results in finding eigenvalues nearest zero.
Reference: [9] <author> R. A. Nicolaides, </author> <title> Deflation of Conjugate Gradients with Applications to Boundary Value Problems, </title> <journal> SIAM J. Numer. Anal. </journal> <volume> Vol. </volume> <month> 24(2) April </month> <year> 1987, </year> <pages> pp. 355-365. </pages>
Reference-contexts: We first extend this algorithm to one which handles an arbitrary block W of vectors. We note that introducing an arbitrary W into the Krylov subspace of CG has already been considered by Nicolaides in <ref> [9] </ref>. The algorithm introduced in this paper is mathematically equivalent with the one in [9]. Nicolaides' algorithm is directly derived from a deflated Lanczos procedure and uses the 3-term recurrence version of the conjugate gradient algorithm. <p> We first extend this algorithm to one which handles an arbitrary block W of vectors. We note that introducing an arbitrary W into the Krylov subspace of CG has already been considered by Nicolaides in <ref> [9] </ref>. The algorithm introduced in this paper is mathematically equivalent with the one in [9]. Nicolaides' algorithm is directly derived from a deflated Lanczos procedure and uses the 3-term recurrence version of the conjugate gradient algorithm. The algorithm in this paper exploits the link between the Lanczos algorithm and the standard Conjugate Gradient algorithm. <p> EndDo The deflated-CG algorithm proposed by Nicolaides <ref> [9] </ref> can be readily obtained from the above algorithm by deriving a sequence of iterates whose residual vectors are proportional to the v-vectors. 2 3 The Deflated-CG Algorithm We now turn to the linear system Ax = b; (5) where A is SPD.
Reference: [10] <author> B. Parlett, </author> <title> A new look at the Lanczos algorithm for solving symmetric systems of linear equations, Linear algebra and its applications, </title> <booktitle> 29 (1980), </booktitle> <pages> pp. 323-346. </pages>
Reference-contexts: This choice was used in <ref> [5, 10, 11, 15] </ref>. A preconditioned version of Deflated-CG can be derived in a straightforward way. Suppose we are solving the split-preconditioned system L 1 AL T y = L 1 b; x = L T y: Set M = LL T .
Reference: [11] <author> Y. Saad, </author> <title> On the Lanczos method for solving symmetric linear systems with several right-hand sides, </title> <journal> Mathematics of computation, </journal> <volume> 178 (1987), </volume> <pages> pp. </pages> <month> 651-662. </month> <title> [12] ||, Iterative methods for sparse linear systems, </title> <publisher> PWS Publishing Company, </publisher> <year> 1996. </year> <title> [13] ||, Analysis of augmented Krylov subspace methods, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> Vol. 18, No. 2, </volume> <pages> pp. 435-449, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: This choice was used in <ref> [5, 10, 11, 15] </ref>. A preconditioned version of Deflated-CG can be derived in a straightforward way. Suppose we are solving the split-preconditioned system L 1 AL T y = L 1 b; x = L T y: Set M = LL T .
Reference: [14] <author> E. de Sturler, </author> <title> Inner-outer methods with deflation for linear systems with multiple right-hand sides, Presentation in Householder Symposium XIII, </title> <year> 1996. </year>
Reference-contexts: It has been observed that significant improvements in convergence rates can be achieved from Krylov subspace methods by adding to these subspaces a few approximate eigenvectors associated with the eigenvalues closest to zero <ref> [2, 4, 7, 8, 13, 14] </ref>. In practice, approximations to the eigenvectors closest to zero are obtained from the use of a certain Krylov subspace, then these approximations are dynamically updated using the new Krylov subspace.
Reference: [15] <author> H. van der Vorst, </author> <title> An iterative method for solving f (A)x = b using Krylov subspace information obtained for the symmetric positive definite matrix A, </title> <journal> Journal of Computational and Applied Mathematics, </journal> <volume> 18 (1987), </volume> <pages> pp. 249-263. 16 </pages>
Reference-contexts: This choice was used in <ref> [5, 10, 11, 15] </ref>. A preconditioned version of Deflated-CG can be derived in a straightforward way. Suppose we are solving the split-preconditioned system L 1 AL T y = L 1 b; x = L T y: Set M = LL T .
References-found: 13

