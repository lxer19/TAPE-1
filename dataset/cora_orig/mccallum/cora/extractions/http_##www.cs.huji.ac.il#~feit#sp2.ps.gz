URL: http://www.cs.huji.ac.il/~feit/sp2.ps.gz
Refering-URL: http://www.cs.huji.ac.il/~ahumu/index5.html
Root-URL: http://www.cs.huji.ac.il
Email: ffeit,ahumug@cs.huji.ac.il  
Title: Utilization and Predictability in Scheduling the IBM SP2 with Backfilling  
Author: Dror G. Feitelson Ahuva Mu'alem Weil 
Address: 91904 Jerusalem, Israel  
Affiliation: Institute of Computer Science The Hebrew University of Jerusalem  
Abstract: Scheduling jobs on the IBM SP2 system is usually done by giving each job a partition of the machine for its exclusive use. Allocating such partitions in the order that the jobs arrive (FCFS scheduling) is fair and predictable, but suffers from severe fragmentation, leading to low utilization. This motivated Argonne National Lab, where the first large SP1 was installed, to develop the EASY scheduler. This scheduler, which has since been adopted by many other SP2 sites, uses aggressive backfilling: small jobs are moved ahead to fill in holes in the schedule, provided they do not delay the first job in the queue. We show that a more conservative approach, in which small jobs move ahead only if they do not delay any job in the queue, produces essentially the same benefits in terms of utilization. Our conservative scheme has the added advantage that queueing times can be predicted in advance, whereas in EASY the queueing time is unbounded.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Das Sharma and D. K. Pradhan, </author> <title> "Job scheduling in mesh multicomputers". </title> <booktitle> In Intl. Conf. Parallel Processing, </booktitle> <volume> vol. II, </volume> <pages> pp. 251-258, </pages> <month> Aug </month> <year> 1994. </year>
Reference-contexts: A FCFS scheduler would then reserve all the processors that are freed for this queued job, and leave them idle. A non-FCFS scheduler would schedule some other smaller jobs, that are behind the big job in the queue, rather than letting the processors idle <ref> [8, 1] </ref>. Of course, this runs the danger of starving the large job, as small jobs continue to pass it by.
Reference: [2] <author> D. G. Feitelson, </author> <title> A Survey of Scheduling in Multiprogrammed Parallel Systems. </title> <type> Research Report RC 19790 (87657), </type> <institution> IBM T. J. Watson Research Center, </institution> <month> Oct </month> <year> 1994. </year>
Reference-contexts: 1 Introduction The scheduling scheme used on most distributed-memory parallel supercomputers is variable partitioning, meaning that each job receives a partition of the machine with its desired number of processors <ref> [2] </ref>. Such partitions are allocated in a first-come first-serve (FCFS) manner to interactive jobs that are submitted directly, and to batch jobs that are submitted via a queueing system such as NQS.
Reference: [3] <author> D. G. Feitelson and M. A. Jette, </author> <title> "Improved utilization and responsiveness with gang scheduling". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 238-261, </pages> <publisher> Springer Verlag, </publisher> <year> 1997. </year> <title> Lect. </title> <journal> Notes Comput. Sci. </journal> <volume> vol. </volume> <pages> 1291. </pages>
Reference-contexts: As a result system utilization is typically in the range of 50-80% [12, 9, 4, 7]. It is well known that the best solutions for this problem are to use dynamic partitioning [11] or gang scheduling <ref> [3] </ref>. However, these schemes have practical limitations. The only 1 efficient and widely used implementation of gang scheduling was the one on the CM-5 Con--nection Machine; other implementations are too coarse-grained for real interactive support, and do not enjoy much use. <p> Different versions of backfilling balance these goals in different ways. 2.1 Conservative Backfilling Conservative backfilling is the vanilla version usually assumed in the literature (e.g. <ref> [6, 3] </ref>), although it seems not to be used. In this version, backfilling is done subject to checking that it does not delay any previous job in the queue. We call this version "conservative" backfilling to distinguish it from the more aggressive version used by EASY, as described below. <p> The second made direct use of workload traces collected from SP2 sites using EASY. 3.1 Evaluation with Workload Model The first simulation used a workload model derived from traces taken on several production systems, and used previously in <ref> [3] </ref>. Such a model allows the load on the simulated system to be modified in a controlled manner, to see how performance depends on system load. As the model does not contain user estimates of the runtime, we use the actual times as the estimate.
Reference: [4] <author> D. G. Feitelson and B. Nitzberg, </author> <title> "Job characteristics of a production parallel scientific workload on the NASA Ames iPSC/860". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 337-360, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <title> Lect. </title> <journal> Notes Comput. Sci. </journal> <volume> vol. </volume> <pages> 949. </pages>
Reference-contexts: But this approach suffers from fragmentation, where processors cannot meet the requirements of the next queued job and therefore remain idle. As a result system utilization is typically in the range of 50-80% <ref> [12, 9, 4, 7] </ref>. It is well known that the best solutions for this problem are to use dynamic partitioning [11] or gang scheduling [3]. However, these schemes have practical limitations.
Reference: [5] <author> D. G. Feitelson, L. Rudolph, U. Schwiegelshohn, K. C. Sevcik, and P. Wong, </author> <title> "Theory and practice in parallel job scheduling". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 1-34, </pages> <publisher> Springer Verlag, </publisher> <year> 1997. </year> <title> Lect. </title> <journal> Notes Comput. Sci. </journal> <volume> vol. </volume> <pages> 1291. </pages>
Reference-contexts: Dynamic partitioning has not been implemented on production machines at all. A simpler approach is to just re-order the jobs in the queue, that is, to use non-FCFS policies <ref> [5] </ref>. Consider the following scenario, where a number of jobs are running side by side, and the next queued job requires all the processors in the system. A FCFS scheduler would then reserve all the processors that are freed for this queued job, and leave them idle. <p> This should be understood as a queueing system, where load causes jobs to be delayed. Slowdown is used rather than response time to normalize all jobs to the same range. Bounded slowdown eliminates the emphasis on very short jobs <ref> [5] </ref>; a threshold of 10 seconds was used.
Reference: [6] <author> R. Gibbons, </author> <title> "A historical application profiler for use by parallel schedulers". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 58-77, </pages> <publisher> Springer Verlag, </publisher> <year> 1997. </year> <title> Lect. </title> <journal> Notes Comput. Sci. </journal> <volume> vol. </volume> <pages> 1291. </pages>
Reference-contexts: Different versions of backfilling balance these goals in different ways. 2.1 Conservative Backfilling Conservative backfilling is the vanilla version usually assumed in the literature (e.g. <ref> [6, 3] </ref>), although it seems not to be used. In this version, backfilling is done subject to checking that it does not delay any previous job in the queue. We call this version "conservative" backfilling to distinguish it from the more aggressive version used by EASY, as described below.
Reference: [7] <author> S. Hotovy, </author> <title> "Workload evolution on the Cornell Theory Center IBM SP2". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 27-40, </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <title> Lect. </title> <journal> Notes Comput. Sci. </journal> <volume> vol. </volume> <pages> 1162. </pages>
Reference-contexts: But this approach suffers from fragmentation, where processors cannot meet the requirements of the next queued job and therefore remain idle. As a result system utilization is typically in the range of 50-80% <ref> [12, 9, 4, 7] </ref>. It is well known that the best solutions for this problem are to use dynamic partitioning [11] or gang scheduling [3]. However, these schemes have practical limitations.
Reference: [8] <author> Intel Corp., </author> <title> iPSC/860 Multi-User Accounting, Control, and Scheduling Utilities Manual. Order number 312261-002, </title> <month> May </month> <year> 1992. </year>
Reference-contexts: A FCFS scheduler would then reserve all the processors that are freed for this queued job, and leave them idle. A non-FCFS scheduler would schedule some other smaller jobs, that are behind the big job in the queue, rather than letting the processors idle <ref> [8, 1] </ref>. Of course, this runs the danger of starving the large job, as small jobs continue to pass it by. <p> Backfilling improves upon this by moving short jobs ahead in the queue to utilize "holes" in the schedule. The name "backfilling" was coined by Lifka to describe the EASY scheduler for the Argonne SP1 [10], although the concept was also present in earlier systems (e.g. <ref> [8] </ref>). It is desirable that a scheduler with backfilling will support two conflicting goals: on one hand, it is desirable to move as many short jobs forward, in order to improve utilization and responsiveness.
Reference: [9] <author> P. Krueger, T-H. Lai, and V. A. Dixit-Radiya, </author> <title> "Job scheduling is more important than processor allocation for hypercube computers". </title> <journal> IEEE Trans. Parallel & Distributed Syst. </journal> <volume> 5(5), </volume> <pages> pp. 488-497, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: But this approach suffers from fragmentation, where processors cannot meet the requirements of the next queued job and therefore remain idle. As a result system utilization is typically in the range of 50-80% <ref> [12, 9, 4, 7] </ref>. It is well known that the best solutions for this problem are to use dynamic partitioning [11] or gang scheduling [3]. However, these schemes have practical limitations.
Reference: [10] <author> D. Lifka, </author> <title> "The ANL/IBM SP scheduling system". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 295-303, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <title> Lect. </title> <journal> Notes Comput. Sci. </journal> <volume> vol. </volume> <pages> 949. </pages>
Reference-contexts: This approach, which is called backfilling, was developed for the IBM SP1 parallel supercomputer installed at Argonne National Lab as part of EASY (the Extensible Argonne Scheduling sYstem) <ref> [10] </ref>, which has since been integrated with the LoadLeveler scheduler from IBM for the SP2 [13]. The EASY backfilling algorithm only checks that jobs that move ahead in the queue do not delay the first queued job. <p> Backfilling improves upon this by moving short jobs ahead in the queue to utilize "holes" in the schedule. The name "backfilling" was coined by Lifka to describe the EASY scheduler for the Argonne SP1 <ref> [10] </ref>, although the concept was also present in earlier systems (e.g. [8]). It is desirable that a scheduler with backfilling will support two conflicting goals: on one hand, it is desirable to move as many short jobs forward, in order to improve utilization and responsiveness. <p> EASY backfilling takes a more aggressive approach, and allows short jobs to skip ahead provided they do not delay the job at the head of the queue <ref> [10] </ref>. Interaction with other 8 jobs is not checked, and they may be delayed, as shown below. The objective is to improve the current utilization as much as possible, subject to some consideration of queue order.
Reference: [11] <author> C. McCann, R. Vaswani, and J. Zahorjan, </author> <title> "A dynamic processor allocation policy for multiprogrammed shared-memory multiprocessors". </title> <journal> ACM Trans. Comput. Syst. </journal> <volume> 11(2), </volume> <pages> pp. 146-178, </pages> <month> May </month> <year> 1993. </year> <month> 18 </month>
Reference-contexts: As a result system utilization is typically in the range of 50-80% [12, 9, 4, 7]. It is well known that the best solutions for this problem are to use dynamic partitioning <ref> [11] </ref> or gang scheduling [3]. However, these schemes have practical limitations. The only 1 efficient and widely used implementation of gang scheduling was the one on the CM-5 Con--nection Machine; other implementations are too coarse-grained for real interactive support, and do not enjoy much use.
Reference: [12] <author> P. Messina, </author> <title> "The Concurrent Supercomputing Consortium: </title> <booktitle> year 1". IEEE Parallel & Distributed Technology 1(1), </booktitle> <pages> pp. 9-16, </pages> <month> Feb </month> <year> 1993. </year>
Reference-contexts: But this approach suffers from fragmentation, where processors cannot meet the requirements of the next queued job and therefore remain idle. As a result system utilization is typically in the range of 50-80% <ref> [12, 9, 4, 7] </ref>. It is well known that the best solutions for this problem are to use dynamic partitioning [11] or gang scheduling [3]. However, these schemes have practical limitations.
Reference: [13] <author> J. Skovira, W. Chan, H. Zhou, and D. Lifka, </author> <title> "The EASY - LoadLeveler API project". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 41-47, </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <title> Lect. </title> <journal> Notes Comput. Sci. </journal> <volume> vol. 1162. </volume> <pages> 19 </pages>
Reference-contexts: This approach, which is called backfilling, was developed for the IBM SP1 parallel supercomputer installed at Argonne National Lab as part of EASY (the Extensible Argonne Scheduling sYstem) [10], which has since been integrated with the LoadLeveler scheduler from IBM for the SP2 <ref> [13] </ref>. The EASY backfilling algorithm only checks that jobs that move ahead in the queue do not delay the first queued job.
References-found: 13

