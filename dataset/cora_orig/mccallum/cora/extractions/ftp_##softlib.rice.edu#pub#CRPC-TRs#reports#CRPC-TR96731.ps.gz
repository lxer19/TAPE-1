URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR96731.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: A Parallel Three-dimensional Electromagnetic Particle-in-Cell Code for Non-Orthogonal Meshes  
Author: S. R. Karmesin P. C. Liewer and J. Wang 
Date: September 26, 1996  
Address: Pasadena CA 91125  Pasadena CA 91109  
Affiliation: California Institute of Technology,  Jet Propulsion Laboratory, California Institute of Technology,  
Abstract: We describe a new parallel three dimensional electromagnetic particle-in-cell code that uses body fitted curvilinear coordinates for modeling plasma and beam devices. Cells in the structure grid are deformable hexahedra in physical space and are mapped to unit cubes in logical space for particle interpolations. The algorithms conserve particle charge and current, and update the electromagnetic fields in a divergence preserving manner. The code is modular and portable, and we present numerical results of convergence rates and benchmarks on serial, vector and parallel computers for the components separately and together.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S.D. Gedney and F. </author> <title> Lansing, A generalized Yee-algorithm for the analysis of microwave circuit devices, </title> <journal> IEEE Trans. Microwave Theory and Techniques, </journal> <note> (submitted for publication, </note> <year> 1995). </year>
Reference-contexts: And because complex microwave devices can have several connected cavities and regions, we organize the grid in patches, connected by appropriate boundary conditions. The algorithm we use to update the electromagnetic field quantities E and B is due to Gedney and Lansing <ref> [1] </ref>. This algorithm is an extension to non-uniform meshes of the classical staggered mesh Finite-difference time-domain (FDTD) algorithm and is similar to that of Madsen [2]. <p> flm (fl = (1 v 2 =c 2 ) 1=2 ) in an electromagnetic field, d t flmv = q (E + (v=c) fi B) (4) d t x = v 3 Numerics Description The electromagnetic field portion of our code is based on the algorithm of Gedney and Lans-ing <ref> [1] </ref>, specialized to the case of a structured grid of hexahedral cells. This is a discrete volume generalization of the standard FDTD algorithm and reduces identically to this algorithm if the grid is Cartesian. <p> In the second step, the B dl for the line segment from face 2 to the center of the cell is obtained from the vectors associated with the four vertices of face 2. Lansing <ref> [1] </ref> specialized to the case of hexahedral cells. <p> Once these cell vertex values are found, there are many choices of how to proceed to obtain the dual edge quantity B dl. We choose to follow Gedney and Lansing <ref> [1] </ref> and this is illustrated in the second step in Figure 4.
Reference: 2. <author> N. K. Madsen, </author> <title> Divergence preserving discrete surface integral methods for Maxwell's curl equations using non-orthogonal unstructured grids, </title> <journal> J. Comput. </journal> <volume> Phys.,119, </volume> <month> 34 </month> <year> (1995). </year>
Reference-contexts: The algorithm we use to update the electromagnetic field quantities E and B is due to Gedney and Lansing [1]. This algorithm is an extension to non-uniform meshes of the classical staggered mesh Finite-difference time-domain (FDTD) algorithm and is similar to that of Madsen <ref> [2] </ref>. We also extend the method of Villasenor and Buneman [3] to non-uniform meshes in order to calculate the current J on the grid from the particles while preserving to machine precision the divergence condition on E. We present here convergence studies for these methods. <p> The discrete line integral B dl is located on edges of the E grid. possible, however, that for extremely non-orthogonal grids, the edge will not pass through the face and this should be avoided <ref> [2] </ref>. 3.2 Electromagnetic Field Update The fundamental variables that our electromagnetic simulation code calculates are B ds (on each face of B grid cells) and E ds (on each face of E cells). <p> Lansing [1] specialized to the case of hexahedral cells. This technique is similar, but not identical, to the Discrete Surface Integral method of Madsen <ref> [2] </ref>. from the B ds for that face and 4 others in the same cell. (In the figure, the quantities are labeled by cell face, not logical coordinate.) The first step in obtaining a B dl for a face is to find vertex values for B for the four vertices of
Reference: 3. <author> J. Villasenor and O. Buneman, </author> <title> Rigorous charge conservation for local electromagnetic field solves, </title> <journal> Comput. Phys. Comm. </journal> <volume> 69, </volume> <month> 306 </month> <year> (1992). </year>
Reference-contexts: This algorithm is an extension to non-uniform meshes of the classical staggered mesh Finite-difference time-domain (FDTD) algorithm and is similar to that of Madsen [2]. We also extend the method of Villasenor and Buneman <ref> [3] </ref> to non-uniform meshes in order to calculate the current J on the grid from the particles while preserving to machine precision the divergence condition on E. We present here convergence studies for these methods. <p> This is a discrete volume generalization of the standard FDTD algorithm and reduces identically to this algorithm if the grid is Cartesian. The particle update uses the current deposit formulation 3 simple tri-linear interpolation maps the logical coordinates to the physical coordinates. of Villasenor and Buneman <ref> [3] </ref> generalized to non-orthogonal meshes, and the usual electromagnetic leap frog time step described in, for example, Birdsall and Langdon [6] and Wang et. al [4]. 3.1 Code Geometry and Grid We denote by the domain on which the equations of motion of the fields and particles shall be computed. <p> Presently, the accuracy of the EMPIC code is limited by the accuracy of the EM field algorithm. 3.7 Current Deposit The last ingredient in the particle time step is a technique for depositing the current. Here, we use the method of Villasenor and Buneman <ref> [3] </ref> extended to non-orthogonal grids. The current deposit is done by calculating for each particle how much charge crosses each face of the E grid as described in [3], which we briefly summarize here. <p> Here, we use the method of Villasenor and Buneman <ref> [3] </ref> extended to non-orthogonal grids. The current deposit is done by calculating for each particle how much charge crosses each face of the E grid as described in [3], which we briefly summarize here. In our non-orthogonal grid code, exactly the same calculation is done, but it is now in logical space using the cells of the E grid. <p> In a time step, a particle will deposit current to any face which its shape function moves across. It is obvious that a particle "cube" can touch up to eight E cells at any given time. Following Villasenor and Buneman <ref> [3] </ref>, if during a time step a particle stays within the same B cell, then the same eight E cells will be occupied by the particle and the particle will deposit current to the twelve faces that separate those eight E cells.
Reference: 4. <author> J. Wang, P. Liewer, V. Decyk, </author> <title> 3D electromagnetic plasma particle simulations on a MIMD parallel computer, </title> <journal> Comput. Phys. Comm. </journal> <volume> 87, </volume> <month> 35 </month> <year> (1995). </year>
Reference-contexts: We present benchmarks and scaling studies to show that it scales efficiently from personal computers to massively parallel supercomputers. The parallel decomposition used is a domain decomposition as used in the parallel three-dimensional Cartesian grid electromagnetic PIC code of Wang et. al <ref> [4] </ref> and the reader is referred to this paper for more background on parallel 3D EMPIC codes. <p> The particle update uses the current deposit formulation 3 simple tri-linear interpolation maps the logical coordinates to the physical coordinates. of Villasenor and Buneman [3] generalized to non-orthogonal meshes, and the usual electromagnetic leap frog time step described in, for example, Birdsall and Langdon [6] and Wang et. al <ref> [4] </ref>. 3.1 Code Geometry and Grid We denote by the domain on which the equations of motion of the fields and particles shall be computed. We then break down into a set of nonoverlapping patches p such that each patch can be represented with three dimensional Cartesian curvilinear coordinates. <p> We briefly describe here the particle time step, elaborating on the parts that pertain to non-uniform geometries. The method is an extension of the scheme used in the Cartesian 3D EMPIC code of Wang et. al <ref> [4] </ref> and a more detailed treatment can be found there. In the code, the trajectory of each particle is integrated using a standard time-centering scheme discussed in Birdsall and Langdon [6] and as used in [4] with the particle position defined on integer time steps and the velocity defined on half <p> extension of the scheme used in the Cartesian 3D EMPIC code of Wang et. al <ref> [4] </ref> and a more detailed treatment can be found there. In the code, the trajectory of each particle is integrated using a standard time-centering scheme discussed in Birdsall and Langdon [6] and as used in [4] with the particle position defined on integer time steps and the velocity defined on half integer time steps. However, in our non-orthogonal grid code, the particle position is kept in logical space while the velocity is kept in physical space. <p> We distribute the particles and the grid using a domain decomposition of both grid and particles in much the same way as Liewer and Decyk [8] and as used by Wang et. al <ref> [4] </ref>. The patches of the grid described above are distributed onto the processors and the particles are distributed to be with the section of grid that they will reference.
Reference: 5. <author> J. W. Eastwood, W. Arter, N. J. Brealey, R. W. Hockney, </author> <title> Body-fitted electromagnetic PIC software for use on parallel computers, </title> <journal> Comput. Phys. Comm. </journal> <volume> 87, </volume> <month> 155 </month> <year> (1995). </year>
Reference-contexts: The parallel decomposition used is a domain decomposition as used in the parallel three-dimensional Cartesian grid electromagnetic PIC code of Wang et. al [4] and the reader is referred to this paper for more background on parallel 3D EMPIC codes. Eastwood et. al <ref> [5] </ref> have also developed a sophisticated parallel 3D EMPIC code which uses body-fitted coordinates. 2 Physics Model The electromagnetic fields satisfy Maxwell's equations with the current derived from the motion of charged particles.
Reference: 6. <author> C. K. Birdsall and A. B. Langdon, </author> <title> Plasma Physics via Computer Simulation (McGraw Hill, </title> <address> New York, </address> <year> 1985). </year>
Reference-contexts: The particle update uses the current deposit formulation 3 simple tri-linear interpolation maps the logical coordinates to the physical coordinates. of Villasenor and Buneman [3] generalized to non-orthogonal meshes, and the usual electromagnetic leap frog time step described in, for example, Birdsall and Langdon <ref> [6] </ref> and Wang et. al [4]. 3.1 Code Geometry and Grid We denote by the domain on which the equations of motion of the fields and particles shall be computed. <p> The method is an extension of the scheme used in the Cartesian 3D EMPIC code of Wang et. al [4] and a more detailed treatment can be found there. In the code, the trajectory of each particle is integrated using a standard time-centering scheme discussed in Birdsall and Langdon <ref> [6] </ref> and as used in [4] with the particle position defined on integer time steps and the velocity defined on half integer time steps. However, in our non-orthogonal grid code, the particle position is kept in logical space while the velocity is kept in physical space.
Reference: 7. <author> K. S. Yee, </author> <title> Numerical solution of initial boundary value problems involving Maxwell's equations in isotropic media, </title> <journal> IEEE Trans. Antennas Propagat. </journal> <volume> AP-14(3), </volume> <month> 302 </month> <year> (1966). </year>
Reference-contexts: When the grid is Cartesian, the edges and the face normals are colinear; in the general case, they are not colinear as illustrated in Fig. 3. These locations reduce to the familiar grid staggering of the Yee lattice for Cartesian FDTD codes <ref> [7] </ref>. To give unique labels to the various grid quantities, we label each with the logical coordinates of its center, e.g. a cell is labeled by the coordinates of its center and a B ds by the coordinates of the face center.
Reference: 8. <author> P. C. Liewer and V. K. Decyk, </author> <title> A general concurrent algorithm for plasma particle-in-cell simulations codes, </title> <journal> J. Comput. Phys. </journal> <volume> 85, </volume> <month> 302 </month> <year> (1989). </year> <month> 15 </month>
Reference-contexts: The linear relationship between the time and the number of processors on the T3D shows the code's high parallel efficiency. is minimized. We distribute the particles and the grid using a domain decomposition of both grid and particles in much the same way as Liewer and Decyk <ref> [8] </ref> and as used by Wang et. al [4]. The patches of the grid described above are distributed onto the processors and the particles are distributed to be with the section of grid that they will reference.
References-found: 8

