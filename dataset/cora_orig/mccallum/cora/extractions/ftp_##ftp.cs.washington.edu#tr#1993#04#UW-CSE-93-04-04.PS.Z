URL: ftp://ftp.cs.washington.edu/tr/1993/04/UW-CSE-93-04-04.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-title.html
Root-URL: 
Title: OS Agents: Using AI Techniques in the Operating System Environment  
Author: Oren Etzioni, Henry M. Levy, Richard B. Segal, and Chandramohan A. Thekkath 
Address: Seattle, WA 98195  
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract: Technical Report 93-04-04 April 12, 1993 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> J. Allen, J. Hendler, and A. Tate, editors. </editor> <booktitle> Readings in Planning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: While designing and implementing an agent that meets these needs may sound difficult, in fact, the base technology already exists within two major areas of Artificial Intelligence (AI) known as planning and machine learning <ref> [1, 21] </ref>. In recent years, concise algorithmic descriptions and public-domain implementations have become available, attesting to the maturity of the techniques [3, 18]. <p> As a result, information necessary for planning may be unknown to the planner (e.g., what is the protection on the file paper.ps). Space precludes a comprehensive discussion of our planning algorithm (see <ref> [1, 5] </ref>). However, we would like to emphasize that planning is well understood as a search problem.
Reference: [2] <author> B. N. Bershad and C. B. Pinkerton. Watchdogs: </author> <title> Extending the UNIX file system. </title> <booktitle> In Proceedings of the 1988 Winter USENIX Conference, </booktitle> <pages> pages 267-275, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Currently, our implementation only provides support for setting triggers on specific i-nodes; this allows us to be notified on logins, for example, by watching a specific system file modified by login. Thus, one way of viewing the current event notification facility is as a generalization of watchdogs <ref> [2] </ref>, an earlier system permitting watchpoints on files. In our implementation, the OS agent server runs as a privileged process that receives RPC requests from a remote OS agent clerk. The clerk's RPC request is blocked from proceeding until the server determines that the request is complete.
Reference: [3] <author> W. Buntine and R. Caruana. </author> <title> Introduction to IND and recursive partitioning. </title> <institution> NASA Ames Research Center, Mail Stop 269-2 Moffet Field, </institution> <address> CA 94035, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: In recent years, concise algorithmic descriptions and public-domain implementations have become available, attesting to the maturity of the techniques <ref> [3, 18] </ref>. In this work, we are demonstrating the marriage of what may seem like strange bedfellows AI and operating systems in order to add expressive power to the user's command interface. The organization of this paper follows the two different viewpoints from which this work can be seen.
Reference: [4] <author> D. J. Campbell and W. J. Heffner. </author> <title> Measurement and analysis of large operating systems during system development. </title> <booktitle> In Proceedings of the 1968 Fall Joint Computer Conference, </booktitle> <pages> pages 903-914, </pages> <month> December </month> <year> 1968. </year>
Reference-contexts: Such modification would be 9 permitted only to a trusted person, such as a system manager. Our approach has much in common with the approach used by performance monitors and debuggers <ref> [16, 4] </ref>; in fact, our mechanism could be used to support such facilities as well.
Reference: [5] <author> D. Chapman. </author> <title> Planning for conjunctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32(3) </volume> <pages> 333-377, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: As a result, information necessary for planning may be unknown to the planner (e.g., what is the protection on the file paper.ps). Space precludes a comprehensive discussion of our planning algorithm (see <ref> [1, 5] </ref>). However, we would like to emphasize that planning is well understood as a search problem.
Reference: [6] <institution> Computer Systems Research Group, Department of EECS, University of California, Berkeley, </institution> <address> CA 94720. </address> <note> CSH(1) UNIX User's Reference Manual (URM) 4.3 BSD, </note> <year> 1986. </year>
Reference-contexts: Third, the language for specifying goals to the OS agent is system independent, making evolution or even radical change of the system transparent to the user. OS agents may be viewed as a command-language extension mechanism, as are shell scripts <ref> [6] </ref>. However, to match the power of OS agents with shell scripts or conventional programs, a user or system programmer would need to create programs to accomplish every conceivable user goal or combination of goals.
Reference: [7] <author> T. G. Dietterich. </author> <title> constraint propagation techniques for theory-driven data interpretation. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1984. </year> <month> 14 </month>
Reference-contexts: The inputs to the planner are logical models of the OS commands at its disposal, and a user request. The models are currently provided by the system manager. Although not yet incorporated into our implementation, algorithms exist for automatically learning and refining classes of action models (e.g., <ref> [7, 12, 19] </ref>). Furthermore, sophisticated users can add their own models. 2 The planner's goal is based on the user's original request. Planner goals are quantified conjunctions of atomic propositions. Each atomic proposition in the goal is referred to as a subgoal. <p> In addition, the OS agent's normal operation is rife with learning opportunities. Algorithms already exist for learning 13 control heuristics by analyzing past successes and failures [9, 17], and automatically generating logical models of actions based on experiments and by observing human users <ref> [7, 12, 19] </ref>. In future work, we plan to incorporate these algorithms into the OS agent and investigate their performance in the Unix domain. We have also described the integration of the OS agent facility within Unix.
Reference: [8] <author> R. Droms. </author> <title> Access to Heterogeneous Directory Services. </title> <booktitle> In IEEE INFOCOM '90, </booktitle> <pages> pages 1054-1061, </pages> <address> San Francisco, CA, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Since planning is done dynamically, the agent is capable of responding to changes in the system's state and configuration. Our current implementation is based on Unix, but in the framework of a distributed and potentially heterogeneous environment. The agent metaphor has become popular recently <ref> [8, 13, 15, 14] </ref>, however OS agents differ sharply from this body of work in several ways. We have successfully incorporated well-understood AI planning algorithms into our agent, yielding a flexible and extensible system as discussed in Section 2.3.
Reference: [9] <author> O. Etzioni. </author> <title> STATIC: A problem-space compiler for Prodigy. </title> <booktitle> In Proceedings of AAAI-91, </booktitle> <year> 1991. </year>
Reference-contexts: The planner accepts control heuristics, specified in a high-level language, which constrain the planner's search by instructing it to ignore options, to prefer certain options over others, etc. These heuristics can be hand-coded or generated automatically via machine learning techniques <ref> [9, 17] </ref>. When the planner decides to execute a command, it sends a message to its clerk detailing the command and its arguments. <p> For example, the agent could learn that whois never finds a particular user's acquaintances, and save time by abstaining from that command. Simple, but effective, heuristics of this sort can be generated automatically using machine learning techniques <ref> [9, 17] </ref>. * To enable shell programs to utilize a new command, or a new application, the programmer would have to change all programs that might potentially use the command. In contrast, models of new command or tools can be easily added to the agent's database as they become available. <p> In addition, the OS agent's normal operation is rife with learning opportunities. Algorithms already exist for learning 13 control heuristics by analyzing past successes and failures <ref> [9, 17] </ref>, and automatically generating logical models of actions based on experiments and by observing human users [7, 12, 19]. In future work, we plan to incorporate these algorithms into the OS agent and investigate their performance in the Unix domain.
Reference: [10] <author> O. Etzioni, S. Hanks, D. Weld, D. Draper, N. Lesh, and M. Williamson. </author> <title> An Approach to Planning with Incomplete Information. </title> <booktitle> In Proceedings of KR-92, </booktitle> <month> October </month> <year> 1992. </year>
Reference-contexts: An action model can be viewed as a generalization of a Prolog inference rule to allow for multiple postconditions, universal quantification, and state change. The precise syntax and semantics of our action representation language are described in <ref> [10] </ref>, and a sample action model appears in Figure 1. Name: (WC ?file) Preconds: Postconds: (isa file.object ?file) (character.count ?file !char) (isa directory.object ?dir) (word.count ?file !word) (name ?file ?name) (line.count ?file !line) (parent.directory ?file ?dir) (protection ?file readable) count of a file. <p> We have successfully incorporated well-understood AI planning algorithms into our agent, yielding a flexible and extensible system as discussed in Section 2.3. The precise descriptions of the planning algorithm and operator representation language in <ref> [10, 18] </ref>, combined with the discussion in this paper, suffice to replicate our implementation and experimental results. In addition, the OS agent's normal operation is rife with learning opportunities.
Reference: [11] <editor> D. Ferraari, G. Serazzi, and A. Zeigner. </editor> <booktitle> Measurement and Tuning of Computer Systems. </booktitle> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1983. </year>
Reference-contexts: The operating system mechanism needed to do this is straightforward and has been used in the past to add performance probes <ref> [11] </ref> or device drivers [22] dynamically to a running kernel. To summarize, event specification by OS agents is facilitated by three mechanisms. First, we define a relatively static set of event types.
Reference: [12] <author> Y. Gil. </author> <title> Acquiring Domain Knowledge for Planning by Experimentation. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <year> 1992. </year> <note> Also appeared as Technical Report CMU-CS-92-175. </note>
Reference-contexts: The inputs to the planner are logical models of the OS commands at its disposal, and a user request. The models are currently provided by the system manager. Although not yet incorporated into our implementation, algorithms exist for automatically learning and refining classes of action models (e.g., <ref> [7, 12, 19] </ref>). Furthermore, sophisticated users can add their own models. 2 The planner's goal is based on the user's original request. Planner goals are quantified conjunctions of atomic propositions. Each atomic proposition in the goal is referred to as a subgoal. <p> In addition, the OS agent's normal operation is rife with learning opportunities. Algorithms already exist for learning 13 control heuristics by analyzing past successes and failures [9, 17], and automatically generating logical models of actions based on experiments and by observing human users <ref> [7, 12, 19] </ref>. In future work, we plan to incorporate these algorithms into the OS agent and investigate their performance in the Unix domain. We have also described the integration of the OS agent facility within Unix.
Reference: [13] <author> R. E. Kahn and V. G. Cerf. </author> <title> An open architecture for a digital library system and a plan for its development. </title> <type> Technical report, </type> <institution> Corporation for National Research Initiatives, </institution> <month> March </month> <year> 1988. </year>
Reference-contexts: Since planning is done dynamically, the agent is capable of responding to changes in the system's state and configuration. Our current implementation is based on Unix, but in the framework of a distributed and potentially heterogeneous environment. The agent metaphor has become popular recently <ref> [8, 13, 15, 14] </ref>, however OS agents differ sharply from this body of work in several ways. We have successfully incorporated well-understood AI planning algorithms into our agent, yielding a flexible and extensible system as discussed in Section 2.3.
Reference: [14] <author> B. Laurel, T. Oren, and A. Don. </author> <title> Issues in multimedia interface design: Media integration and interface agents. </title> <booktitle> In CHI '90 Conference Proceedings, </booktitle> <pages> pages 133-139, </pages> <year> 1990. </year>
Reference-contexts: Since planning is done dynamically, the agent is capable of responding to changes in the system's state and configuration. Our current implementation is based on Unix, but in the framework of a distributed and potentially heterogeneous environment. The agent metaphor has become popular recently <ref> [8, 13, 15, 14] </ref>, however OS agents differ sharply from this body of work in several ways. We have successfully incorporated well-understood AI planning algorithms into our agent, yielding a flexible and extensible system as discussed in Section 2.3.
Reference: [15] <author> P. Maes and R. Kozierok. </author> <title> Learning interface agents. </title> <booktitle> In Proceedings of INTERCHI-93, </booktitle> <year> 1993. </year>
Reference-contexts: Since planning is done dynamically, the agent is capable of responding to changes in the system's state and configuration. Our current implementation is based on Unix, but in the framework of a distributed and potentially heterogeneous environment. The agent metaphor has become popular recently <ref> [8, 13, 15, 14] </ref>, however OS agents differ sharply from this body of work in several ways. We have successfully incorporated well-understood AI planning algorithms into our agent, yielding a flexible and extensible system as discussed in Section 2.3.
Reference: [16] <author> G. Mcdaniel. </author> <title> METRIC: A kernel instrumentation system for distributed environments. </title> <booktitle> In Proceedings of the 6th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 93-99, </pages> <month> November </month> <year> 1977. </year>
Reference-contexts: Such modification would be 9 permitted only to a trusted person, such as a system manager. Our approach has much in common with the approach used by performance monitors and debuggers <ref> [16, 4] </ref>; in fact, our mechanism could be used to support such facilities as well.
Reference: [17] <author> S. Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 42(2-3), </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: The planner accepts control heuristics, specified in a high-level language, which constrain the planner's search by instructing it to ignore options, to prefer certain options over others, etc. These heuristics can be hand-coded or generated automatically via machine learning techniques <ref> [9, 17] </ref>. When the planner decides to execute a command, it sends a message to its clerk detailing the command and its arguments. <p> For example, the agent could learn that whois never finds a particular user's acquaintances, and save time by abstaining from that command. Simple, but effective, heuristics of this sort can be generated automatically using machine learning techniques <ref> [9, 17] </ref>. * To enable shell programs to utilize a new command, or a new application, the programmer would have to change all programs that might potentially use the command. In contrast, models of new command or tools can be easily added to the agent's database as they become available. <p> In addition, the OS agent's normal operation is rife with learning opportunities. Algorithms already exist for learning 13 control heuristics by analyzing past successes and failures <ref> [9, 17] </ref>, and automatically generating logical models of actions based on experiments and by observing human users [7, 12, 19]. In future work, we plan to incorporate these algorithms into the OS agent and investigate their performance in the Unix domain.
Reference: [18] <author> J. Penberthy and D. Weld. UCPOP: </author> <title> a sound, complete, partial order planner for ADL. </title> <booktitle> In Proceedings of KR-92, </booktitle> <pages> pages 103-114, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: In recent years, concise algorithmic descriptions and public-domain implementations have become available, attesting to the maturity of the techniques <ref> [3, 18] </ref>. In this work, we are demonstrating the marriage of what may seem like strange bedfellows AI and operating systems in order to add expressive power to the user's command interface. The organization of this paper follows the two different viewpoints from which this work can be seen. <p> Space precludes a comprehensive discussion of our planning algorithm (see [1, 5]). However, we would like to emphasize that planning is well understood as a search problem. Modern planning algorithms are provably (see <ref> [18] </ref>): * complete: if a plan exists, the planner will find it, and * sound: if the planner outputs a plan, that plan is guaranteed to achieve its goal. These formal guarantees do not ensure that the planner is efficient. <p> We have successfully incorporated well-understood AI planning algorithms into our agent, yielding a flexible and extensible system as discussed in Section 2.3. The precise descriptions of the planning algorithm and operator representation language in <ref> [10, 18] </ref>, combined with the discussion in this paper, suffice to replicate our implementation and experimental results. In addition, the OS agent's normal operation is rife with learning opportunities.
Reference: [19] <author> R. L. Rivest and R. E. Schapire. </author> <title> Diversity-based inference of finite automata. </title> <booktitle> In Proceedings of FOCS-87, </booktitle> <month> October </month> <year> 1987. </year>
Reference-contexts: The inputs to the planner are logical models of the OS commands at its disposal, and a user request. The models are currently provided by the system manager. Although not yet incorporated into our implementation, algorithms exist for automatically learning and refining classes of action models (e.g., <ref> [7, 12, 19] </ref>). Furthermore, sophisticated users can add their own models. 2 The planner's goal is based on the user's original request. Planner goals are quantified conjunctions of atomic propositions. Each atomic proposition in the goal is referred to as a subgoal. <p> In addition, the OS agent's normal operation is rife with learning opportunities. Algorithms already exist for learning 13 control heuristics by analyzing past successes and failures [9, 17], and automatically generating logical models of actions based on experiments and by observing human users <ref> [7, 12, 19] </ref>. In future work, we plan to incorporate these algorithms into the OS agent and investigate their performance in the Unix domain. We have also described the integration of the OS agent facility within Unix.
Reference: [20] <author> M. F. Schwartz and P. G. Tsirigotis. </author> <title> Experience with a semantically cognizant internet white pages directory tool. </title> <journal> Journal of Internetworking: Research and Experience, </journal> <volume> 2(1) </volume> <pages> 23-50, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: Recently, we discovered the netfind facility distributed by the University of Colorado <ref> [20] </ref>. We added three command models to our agent's repertoire, and it is now able to utilize netfind to locate users.
Reference: [21] <author> J. Shavlik and T. Dietterich, </author> <title> editors. </title> <booktitle> Readings in Machine Learning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: While designing and implementing an agent that meets these needs may sound difficult, in fact, the base technology already exists within two major areas of Artificial Intelligence (AI) known as planning and machine learning <ref> [1, 21] </ref>. In recent years, concise algorithmic descriptions and public-domain implementations have become available, attesting to the maturity of the techniques [3, 18].
Reference: [22] <institution> Sun Microsystems Inc., </institution> <type> 2550 Garcia Avenue, </type> <institution> Mountain View CA 94043. Writing SBus Device Drivers, </institution> <year> 1991. </year>
Reference-contexts: The operating system mechanism needed to do this is straightforward and has been used in the past to add performance probes [11] or device drivers <ref> [22] </ref> dynamically to a running kernel. To summarize, event specification by OS agents is facilitated by three mechanisms. First, we define a relatively static set of event types. Second, OS agent servers, which are considered trusted, can dynamically express an interest in specific instances of these event types.
References-found: 22

