URL: ftp://ftp.cs.berkeley.edu/ucb/sprite/papers/sprite.ps
Refering-URL: http://www.cs.berkeley.edu/projects/sprite/sprite.papers.html
Root-URL: 
Title: The Sprite Network Operating System  
Author: John K. Ousterhout Andrew R. Cherenson Frederick Douglis Michael N. Nelson Brent B. Welch 
Keyword: Operating systems, networks, file systems, process migration, remote procedure call.  
Address: Berkeley, CA 94720  
Affiliation: Computer Science Division Department of Electrical Engineering and Computer Sciences University of California  
Abstract: Sprite is a new operating system for networked uniprocessor and multiprocessor workstations with large physical memories. It implements a set of kernel calls much like those of 4.3 BSD UNIX, with extensions to allow processes on the same workstation to share memory and to allow processes to migrate between workstations. The implementation of the Sprite kernel contains several interesting features, including a remote procedure call facility for communication between kernels, the use of prefix tables to implement a single file name space and to provide flexibility in administering the network file system, and large variable-size file caches on both client and server machines, which provide high performance even for diskless workstations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Accetta, M., et al. </author> <title> ``Mach: A New Kernel Foundation for UNIX Development.'' </title> <booktitle> Proceedings of Summer USENIX, </booktitle> <month> July </month> <year> 1986, </year> <pages> pp. 93-112. </pages>
Reference-contexts: One possibility would be to access all information through the virtual memory system. To access a file, it would first be mapped into a process's virtual address space and then read or written just like virtual memory, as in Apollo's Aegis system [6] or Mach <ref> [1] </ref>. This approach would eliminate the file cache entirely; the standard page replacement - 25 - The Sprite Network Operating System November 19, 1987 mechanisms would automatically balance physical memory usage between file and program information. <p> The first difference is the way in which the virtual memory of a process is transferred between machines, and the second difference is the way in which migration is made transparent to the migrated process. The simplest approach to process migration is: <ref> [1] </ref> ``Freeze'' the process (prevent it from executing any more). [2] Transfer its state to the new machine, including registers and other execution state, virtual memory, and file access. [3] ``Unfreeze'' the process on its new machine, so that it may continue executing.
Reference: [2] <author> Birrell, A. and Nelson, B. </author> <title> ``Implementing Remote Procedure Calls.'' </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 2, No. 1, </volume> <month> February </month> <year> 1986, </year> <pages> pp. 39-59. </pages>
Reference-contexts: The mechanism we chose is a kernel-to-kernel remote procedure call (RPC) facility similar to the one described by Birrell and Nelson <ref> [2] </ref>. We chose RPC rather than a message style because RPC provides a simple programming model (remote operations appear just like local procedure calls) and because the RPC approach is particularly efficient for request-response transactions, which we expected to be the most common form of interaction between kernels. <p> The simplest approach to process migration is: [1] ``Freeze'' the process (prevent it from executing any more). <ref> [2] </ref> Transfer its state to the new machine, including registers and other execution state, virtual memory, and file access. [3] ``Unfreeze'' the process on its new machine, so that it may continue executing.
Reference: [3] <author> Douglis, F. and Ousterhout, J. </author> <title> Process Migration in the Sprite Operating System. To appear, </title> <booktitle> 7th International Conference on Distributed Computing Systems, </booktitle> <month> September </month> <year> 1987. </year> <note> Also appears as technical report UCB/CSD 87/343, </note> <month> February </month> <year> 1987. </year>
Reference-contexts: The simplest approach to process migration is: [1] ``Freeze'' the process (prevent it from executing any more). [2] Transfer its state to the new machine, including registers and other execution state, virtual memory, and file access. <ref> [3] </ref> ``Unfreeze'' the process on its new machine, so that it may continue executing. The virtual memory transfer is the dominant cost in migration, so various techniques have been applied to reduce it. <p> Table 3 shows that the costs of remote execution are acceptable (less than 5% penalty over executing at home, for a compilation benchmark) and that migration may allow a collection of jobs to be completed much more quickly than they could without migration. See <ref> [3] </ref> for more information on process migration in Sprite. iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Action Cost or Speed iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Migrate smallest possible process 190 msec Flush dirty pages 585 Kbytes/sec Demand-load pages 545 Kbytes/sec Transfer info for open files 14 msec/file Flush file cache 585 Kbytes/sec iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiic c c c c c c c
Reference: [4] <author> Hill, M., et al. </author> <title> ``Design Decisions in SPUR.'' </title> <journal> IEEE Computer, </journal> <volume> Vol. 19, No. 11, </volume> <month> November </month> <year> 1986, </year> <pages> pp. 8-22. </pages>
Reference-contexts: 1. Introduction Sprite is an experimental network operating system under development at the University of Cali-fornia at Berkeley. It is part of a larger research project called SPUR (``Symbolic Processing Using RISCs''), whose goal is to design and construct a high-performance multiprocessor workstation with special hardware support for Lisp applications <ref> [4] </ref>. Although one of Sprite's primary goals is to support applications running on SPUR workstations, we hope that the system will work well for a variety of high-performance engineering workstations. Sprite is currently being used on Sun-2 and Sun-3 workstations.
Reference: [5] <author> Howard, J., et al. </author> <title> ``Scale and Performance in a Distributed File System.'' </title> <note> To appear, ACM Transactions on Computer Systems. </note>
Reference-contexts: The LOCUS system was one of the first to make transparency an explicit goal [10]; other file systems with varying degrees of transparency are CMU-ITC's Andrew <ref> [5] </ref> and Sun's NFS [11]. Most network file systems fail to meet the transparency goal in one or more ways. <p> Basic Cache Design Each client and server workstation maintains a large cache of recently-accessed file blocks, as shown in Figure 6. The caches are organized on a block basis, rather than a whole-file basis as in the Andrew file system <ref> [5] </ref>, and are stored in main memory rather than on a local disk. Blocks are currently 4 Kbytes. Each block in the cache is identified by a token for a file and a block location within the file. <p> Andrew was written by M. Satyanarayanan <ref> [5] </ref>; it is a composite benchmark that includes directory searches, file copying, version checking, and compilation. Figure (a) shows additional time required by each diskless client to complete the benchmark, relative to a single client running with local disk and cache. Figure (b) shows server CPU utilization.
Reference: [6] <author> Leach, P., et al. </author> <title> ``The Architecture of an Integrated Local Network.'' </title> <journal> IEEE Transactions on Selected Areas in Communications, </journal> <volume> Vol. SAC-1, No. 5, </volume> <month> November </month> <year> 1983, </year> <pages> pp. 842-857. </pages>
Reference-contexts: The earliest systems (and even some later systems, such as 4.2 BSD) allowed remote file access only with a few special programs (e.g., rcp in 4.2 BSD); most application programs could only access files stored on local disks. Second-generation systems, such as Apollo's Aegis <ref> [6] </ref>, allow any application to access files on any machine in the network but special names must be used for remote files (e.g., ``file'' for a local file but ``[ivy]file'' for a file stored on the Ivy server). <p> One possibility would be to access all information through the virtual memory system. To access a file, it would first be mapped into a process's virtual address space and then read or written just like virtual memory, as in Apollo's Aegis system <ref> [6] </ref> or Mach [1]. This approach would eliminate the file cache entirely; the standard page replacement - 25 - The Sprite Network Operating System November 19, 1987 mechanisms would automatically balance physical memory usage between file and program information.
Reference: [7] <author> Nelson, M. </author> <title> Virtual Memory for the Sprite Operating System. </title> <note> Techical report UCB/CSD 86/301, </note> <month> June </month> <year> 1986. </year>
Reference-contexts: These and other aspects of the virtual memory system are described in detail in <ref> [7] </ref>. This section focusses on three aspects of the virtual memory implementation where we intentionally deviated from UNIX in order to make better use of networks and large physical memories.
Reference: [8] <author> Nelson, M., Welch, B., and Ousterhout, J. </author> <title> ``Caching in the Sprite Network File System.'' </title> <note> To appear, ACM Transactions on Computer Systems. Also appears as technical report UCB/CSD 87/345, </note> <month> March </month> <year> 1987. </year> - <title> 30 - The Sprite Network Operating System November 19, </title> <year> 1987 </year>
Reference-contexts: A file may be cached simultaneously by several active readers. There are two potential disadvantages to Sprite's cache consistency mechanism. First, it results in substantially slower file access when caching has been disabled. Fortunately, measurements and simulations in <ref> [8] </ref> and [9] show that files tend to be open only for short periods of time and are rarely write-shared, so that cache disabling will not occur often. Second, the Sprite approach depends on the fact that the server is notified whenever a file is opened or closed. <p> Second, the Sprite approach depends on the fact that the server is notified whenever a file is opened or closed. This prohibits performance optimizations (such as name caching) in which clients open files without contacting the files' servers. Our benchmark results in <ref> [8] </ref> suggest that such optimizations would only provide small additional - 19 - The Sprite Network Operating System November 19, 1987 performance improvements. It is important to distinguish between consistency and correct synchronization. Sprite's mechan ism provides consistency: each read will return the most up-to-date data. <p> Figure (b) plots network traffic, including bytes transmitted in packet headers and control packets as well as file data. See <ref> [8] </ref> for a description of the benchmarks. - 20 - The Sprite Network Operating System November 19, 1987 from the clients. Because the benchmarks do not involve file sharing, they do not measure the over heads associated with cache consistency. <p> Because the benchmarks do not involve file sharing, they do not measure the over heads associated with cache consistency. This section presents only summary results; for descriptions of the benchmarks and additional performance measurements, see <ref> [8] </ref>. mance within 1% to 12% of workstations with local disks, whereas without caches the diskless works tations typically run 10% to 40% more slowly than workstations with disks. It also shows that client caching reduces network traffic by a factor of four or more. <p> Since our NFS servers can support 10-20 clients, the NFS comparison supports our estimate of at least 50 clients per Sprite file server. See <ref> [8] </ref> for more information on the NFS comparison. 6. Virtual Memory Sprite's implementation of virtual memory is traditional in many respects.
Reference: [9] <author> Ousterhout, J., et al. </author> <title> ``A TraceDriven Analysis of the UNIX 4.2 BSD File System.'' </title> <booktitle> Proceedings of the Tenth Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1985, </year> <pages> pp. 15-24. </pages>
Reference-contexts: A file may be cached simultaneously by several active readers. There are two potential disadvantages to Sprite's cache consistency mechanism. First, it results in substantially slower file access when caching has been disabled. Fortunately, measurements and simulations in [8] and <ref> [9] </ref> show that files tend to be open only for short periods of time and are rarely write-shared, so that cache disabling will not occur often. Second, the Sprite approach depends on the fact that the server is notified whenever a file is opened or closed.
Reference: [10] <author> Popek, G. and Walker, B., eds. </author> <title> The LOCUS Distributed System Architecture. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1985. </year>
Reference-contexts: The LOCUS system was one of the first to make transparency an explicit goal <ref> [10] </ref>; other file systems with varying degrees of transparency are CMU-ITC's Andrew [5] and Sun's NFS [11]. Most network file systems fail to meet the transparency goal in one or more ways. <p> Process migration, which allows processes to be moved at any time, has been implemented in several systems (e.g., LOCUS <ref> [10] </ref>, V [12], and Accent [15]) but is still not widely available. For Sprite we decided to implement process migration. We think that the additional flexibility provided by migration is particularly important in a workstation environment. <p> Process Migration Sprite's implementation of process migration differs from other implementations such as those in the V System [12], Accent [15], or LOCUS <ref> [10] </ref> in two major ways. The first difference is the way in which the virtual memory of a process is transferred between machines, and the second difference is the way in which migration is made transparent to the migrated process.
Reference: [11] <author> Sandberg, R., et al. </author> <title> ``Design and Implementation of the Sun Network Filesystem.'' </title> <booktitle> Proceedings of the USENIX 1985 Summer Conference, </booktitle> <month> June </month> <year> 1985, </year> <pages> pp. 119-130. </pages>
Reference-contexts: The LOCUS system was one of the first to make transparency an explicit goal [10]; other file systems with varying degrees of transparency are CMU-ITC's Andrew [5] and Sun's NFS <ref> [11] </ref>. Most network file systems fail to meet the transparency goal in one or more ways.
Reference: [12] <author> Theimer, M., Lantz, K., and Cheriton, D. </author> <title> ``Preemptable Remote Execution Facilities for the V-System.'' </title> <booktitle> Proceedings of the Tenth Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1985, </year> <pages> pp. 2-12. </pages>
Reference-contexts: Process migration, which allows processes to be moved at any time, has been implemented in several systems (e.g., LOCUS [10], V <ref> [12] </ref>, and Accent [15]) but is still not widely available. For Sprite we decided to implement process migration. We think that the additional flexibility provided by migration is particularly important in a workstation environment. <p> Process Migration Sprite's implementation of process migration differs from other implementations such as those in the V System <ref> [12] </ref>, Accent [15], or LOCUS [10] in two major ways. The first difference is the way in which the virtual memory of a process is transferred between machines, and the second difference is the way in which migration is made transparent to the migrated process.
Reference: [13] <author> Welch, B. </author> <title> The Sprite Remote Procedure Call System. </title> <type> Technical report UCB/CSD 86/302, </type> <month> June </month> <year> 1986. </year>
Reference: [14] <author> Welch, B., and Ousterhout, J. </author> <title> ``Prefix Tables: A Simple Mechanism for Locating Files in a Distributed System.'' </title> <booktitle> Proceedings of the Sixth International Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1986, </year> <pages> pp. 184-189. </pages>
Reference-contexts: The client takes the new name, processes it with its prefix table, and sends it to a new server. This process repeats until the name is completely resolved (see <ref> [14] </ref> for details). The prefix approach bypasses the root domain (and its server) when looking up absolute names of files in non-root domains.
Reference: [15] <author> Zayas, E. </author> <title> ``Breaking the Process Migration Bottleneck.'' To appear, </title> <booktitle> Proceedings of the Eleventh Symposium on Operating Systems Principles, </booktitle> <month> November </month> <year> 1987. </year> <month> - 31 </month> - 
Reference-contexts: Process migration, which allows processes to be moved at any time, has been implemented in several systems (e.g., LOCUS [10], V [12], and Accent <ref> [15] </ref>) but is still not widely available. For Sprite we decided to implement process migration. We think that the additional flexibility provided by migration is particularly important in a workstation environment. <p> Process Migration Sprite's implementation of process migration differs from other implementations such as those in the V System [12], Accent <ref> [15] </ref>, or LOCUS [10] in two major ways. The first difference is the way in which the virtual memory of a process is transferred between machines, and the second difference is the way in which migration is made transparent to the migrated process.
References-found: 15

