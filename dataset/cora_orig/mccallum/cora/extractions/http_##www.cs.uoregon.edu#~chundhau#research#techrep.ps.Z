URL: http://www.cs.uoregon.edu/~chundhau/research/techrep.ps.Z
Refering-URL: http://www.cs.uoregon.edu/~chundhau/research/writings.html
Root-URL: http://www.cs.uoregon.edu
Email: chundhau-@cs.uoregon.edu, donna@dynamic.uoregon.edu  
Title: Toward Empirically-Based Software Visualization Languages  
Author: Sarah Douglas Christopher Hundhausen and Donna McKeown* douglas, 
Address: Eugene, OR 97403  
Affiliation: Computer Information Science Dept. *Psychology Dept. University of Oregon  
Abstract: Single-user software visualization (SV) systems purport to empower people without expertise in graphics programming to develop their own visualizations interactively, and within minutes. Underlying any single-user SV system is a visualization language onto which its users must map the computations they would like to visualize with the system. We hypothesize that the usability of such systems turns on their ability to provide an underlying visualization language that accords with the ways in which their users conceptualize the computations to be visualized. To explore the question of how to design visualization languages grounded in human conceptualization, we present an empirical study that made use of a research method called visualization storyboarding to investigate the human conceptualization of the bubble-sort algorithm. Using an analytical framework based on entities, attributes, and transformations, we derive a semantic-level visualization language for bubblesort, in terms of which all visualizations observed in our study can be expressed. Our empirically-based visualization language provides a framework for predicting the usability of the visualization language defined by Lens [11,12], a prototypical single-user SV system. We draw from a follow-up usability study of Lens to substantiate our predictions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Badre, M. Beranek, J.M. Morris, and J.T. Stasko. </author> <title> Assessing program visualization systems as instructional aids. </title> <type> Technical report GIT-GVU-91-23, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <address> Atlanta, GA, </address> <year> 1991. </year>
Reference: [2] <author> Brown, M. </author> <title> Algorithm Animation . Cambridge, </title> <address> MA: </address> <publisher> The MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: Early SV systems such as Balsa <ref> [2] </ref> and Tango [17] defined system user models in which different actors performed those activities.
Reference: [3] <author> K.C. Cox and G-C. Roman. </author> <title> Abstraction in algorithm animation. </title> <booktitle> In Proc. 1992 IEEE Workshop on Visual Languages (Seattle, WA), </booktitle> <pages> pp. </pages> <address> 18 -23, </address> <year> 1992. </year>
Reference-contexts: Fords analysis of the 180 visualizations resulting from the study revealed a wide range of alternative visualizations for the same code fragments; the visualizations were classified using Cox and Romans <ref> [3] </ref> abstraction classification system. In contrast to our study, Fords study considered the visualization of general imperative and objectoriented programming concepts for example, variables, pointers, loops, conditionals, arrays, and classes; visualization conceptualization was not considered at the level of algorithm semantics.
Reference: [4] <author> S.A. Douglas. </author> <title> Conversational analysis and human-computer interaction design. </title> <editor> In P. Thomas (ed.) </editor> <title> The Social and Interactional Dimensions of Human-Computer Interfaces. </title> <publisher> Cambridge: Cambridge University Press, (in press). </publisher>
Reference-contexts: To interpret participants interaction, we review the videotapes of participant sessions using conversational analysis techniques developed by Douglas <ref> [4] </ref>. 2.2 Procedure We videotaped three same-sex pairs of participants (two consisting of women, one consisting of men) during 45 to 70 minute sessions. All participants were graduate students in computer science at the University of Oregon, and all reported that they understood the bubblesort algorithm. <p> As was the case with our visualization storyboarding experiments, both sessions were videotaped and later analyzed using conversational analysis techniques developed by Douglas <ref> [4] </ref>. See [8] for a more thorough treatment of the study. zation in Lens Observations relevant to Hypothesis 1 . As hypothesized, we observed that the overall usability of the Lens language was quite good.
Reference: [5] <author> S. Douglas, D. McKeown, and C. Hundhausen. </author> <title> Exploring human visualization of algorithms. </title> <type> Technical report CIS-TR-94-27, </type> <institution> Department of Computer and Information Science, University of Oregon, Eugene, </institution> <year> 1993. </year>
Reference-contexts: See <ref> [5] </ref> for a more thorough treatment of the study. 2.1 Method: Visualization storyboarding How does one empirically study human conceptualizations of computer programs independently of computer-based technology? We see at least two requirements for the medium employed by the empirical method.
Reference: [6] <author> L. Ford. </author> <title> How programmers visualize programs. </title> <type> Research report 271, </type> <institution> Department of Computer Science, University of Exeter, Exeter, U.K., </institution> <year> 1993. </year>
Reference-contexts: Our work differs fundamentally from this work both in the research method (quantitative factors analysis versus qualitative visualization storyboarding), and in the research goal (evaluation of SV efficacy versus SV language design). 5.2 Using empirical studies to document human visualizations Ford <ref> [6] </ref> employs a research method similar to ours to document human visualizations of computer programs. In Fords study, 46 beginning computer science students, assembled into two, three-, and four-person teams, were videotaped as they sketched visualizations for C++ code fragments.
Reference: [7] <author> L. Ford and D. Tallis. </author> <title> Interacting visual abstractions of programs. </title> <booktitle> In Proc. 1993 IEEE Workshop on Visual Languages (Bergen, Norway), </booktitle> <pages> pp. </pages> <address> 93 -97, </address> <year> 1993. </year>
Reference-contexts: Further, Ford made no attempt to use the study results as a basis for an SV language. Instead, Fords interest has been in devising a set of empirically-based visual program abstractions for aiding 9 programmer comprehension of conventional text-based program views <ref> [7] </ref>. 5.3 Language design Drawing from an analysis of human pen-and-paper descriptions, Radiya and Radiya [13] introduce a model called HAL (Human approach to describing ALgorithms) for graphically describing algorithms However, whereas they were interested in using such descriptions as basis for a visual programming language, we are interested in applying
Reference: [8] <author> C.D. Hundhausen. </author> <title> Exploring the potential for conversational analysis in the evaluation of interactive algorithm visualization systems. </title> <note> Unpublished technical report available at http://www.cs.uoregon.edu/~chundhau, 1993. </note>
Reference-contexts: As was the case with our visualization storyboarding experiments, both sessions were videotaped and later analyzed using conversational analysis techniques developed by Douglas [4]. See <ref> [8] </ref> for a more thorough treatment of the study. zation in Lens Observations relevant to Hypothesis 1 . As hypothesized, we observed that the overall usability of the Lens language was quite good.
Reference: [9] <author> A.W. Lawrence, A.N. Badre, and J.T. Stasko. </author> <title> Empirically evaluating the use of animations to teach algorithms. </title> <type> Technical report GIT-GVU-94-07, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <address> Atlanta, GA, </address> <year> 1994. </year>
Reference: [10] <author> N. Miyake. </author> <title> Constructive interaction and the iterative process of understanding. </title> <journal> Cognitive Science 10 , pp. </journal> <volume> 151177, </volume> <year> 1986. </year>
Reference-contexts: The resulting storyboard of the algorithms execution a dynamic presentation consisting of animated construction paper cutouts, drawings, conversation, and gestures is videotaped, becoming the empirical data to be analyzed at a later time. Visualization storyboarding applies two qualitative research techniques constructive interaction <ref> [10] </ref> and conversational analysis [18] to the situation of software 3 visualization design. By using two participants, constructive interaction creates a situation of collaborative problem solving in which each participant must inform the other, in an explicit verbal and visual record, of problems, causes, and solutions each has encountered.
Reference: [11] <author> S. Mukherjea and J.T. </author> <title> Stasko Applying algorithm animation techniques for program tracing, debugging, </title> <booktitle> and understanding. In Proc. 15th IEEE International Conference on Software Engineering (Baltimore, MD), </booktitle> <pages> pp. 456465, </pages> <year> 1993. </year>
Reference: [12] <author> S. Mukherjea and J.T. Stasko. </author> <title> Toward visual debugging: Integrating algorithm animation capabilities within a a source-level debugger . ACM Trans. </title> <journal> on Computer-Human Interaction 1(3) , pp. </journal> <volume> 215 -244, </volume> <year> 1994. </year>
Reference-contexts: In practice, SV system designers are interested in supporting the definition of visualizations for a broad range of algorithm classes. For example, the Lens system has been used to define visualizations for sorting, searching, graph, computational geometry, and even scientific simulation algorithms <ref> [12] </ref>.
Reference: [13] <author> A. Radiya and V. Radiya. </author> <title> A model of human approach to describing algorithms using diagrams. </title> <booktitle> In Proc. 1992 IEEE Workshop on Visual Languages (Seattle, WA), </booktitle> <pages> pp. </pages> <address> 261 -263, </address> <year> 1992. </year>
Reference-contexts: Instead, Fords interest has been in devising a set of empirically-based visual program abstractions for aiding 9 programmer comprehension of conventional text-based program views [7]. 5.3 Language design Drawing from an analysis of human pen-and-paper descriptions, Radiya and Radiya <ref> [13] </ref> introduce a model called HAL (Human approach to describing ALgorithms) for graphically describing algorithms However, whereas they were interested in using such descriptions as basis for a visual programming language, we are interested in applying our research to SV languages.
Reference: [14] <author> G-C. Roman and K.C. Cox. </author> <title> A taxonomy of program visualization systems. </title> <booktitle> IEEE Computer 26(12) (December), </booktitle> <pages> pp. </pages> <address> 11 -24, </address> <year> 1993. </year> <month> 11 </month>
Reference-contexts: All of the participants in our visualization storyboarding experiment chose to visualize the bubblesort algorithm by identifying interesting events in the algorithm, and mapping those interesting events to corresponding graphical transformations. Called visualization-by-annotation in the SV literature <ref> [14] </ref>, this specification paradigm is the one most commonly supported by computer-based SV systems. It is widely known, however, that visualization-by-annotation is not the most appropriate method for ex 10 pressing all possible computation-to-visualization mappings.
Reference: [15] <author> J.T. Stasko, A. Badre, and C. Lewis. </author> <title> Do algorithm animations assist learning? An empirical study and analysis. </title> <booktitle> In Proc. INTERCHI 93 Conference on Human Factors in Computing Systems (Amsterdam, The Neth-erlands), </booktitle> <pages> pp. 6166, </pages> <year> 1993. </year>
Reference: [16] <author> J.T. Stasko. </author> <title> Animating algorithms with XTANGO. </title> <journal> SICACT News 23(2), </journal> <pages> pp. </pages> <address> 67 -71, </address> <year> 1992. </year>
Reference-contexts: To design the Lens SV language, Mukherjea and Stasko [11,12] studied visualizations of 42 algorithms drawn from several problem domains, including sorting, searching, graph theory, and graphics. Programmed by over 25 people from 4 different institutions, all of the visualizations they studied had been implemented in XTango <ref> [16] </ref>, an animation toolkit based on Staskos path-transition paradigm [17]. It should be no surprise, then, that the language they designed is a subset of the XTango language.
Reference: [17] <author> J.T. Stasko. </author> <title> Tango: A framework and system for algorithm animation. </title> <note> IEEE Computer 23 (September) pp. 27 -39, </note> <year> 1990. </year>
Reference-contexts: Early SV systems such as Balsa [2] and Tango <ref> [17] </ref> defined system user models in which different actors performed those activities. <p> Programmed by over 25 people from 4 different institutions, all of the visualizations they studied had been implemented in XTango [16], an animation toolkit based on Staskos path-transition paradigm <ref> [17] </ref>. It should be no surprise, then, that the language they designed is a subset of the XTango language.
Reference: [18] <author> L. Suchman. </author> <title> Plans and situated actions: The problem of humanmachine communication . Cambridge: </title> <publisher> Cam-bridge University Press, </publisher> <year> 1987. </year>
Reference-contexts: The resulting storyboard of the algorithms execution a dynamic presentation consisting of animated construction paper cutouts, drawings, conversation, and gestures is videotaped, becoming the empirical data to be analyzed at a later time. Visualization storyboarding applies two qualitative research techniques constructive interaction [10] and conversational analysis <ref> [18] </ref> to the situation of software 3 visualization design. By using two participants, constructive interaction creates a situation of collaborative problem solving in which each participant must inform the other, in an explicit verbal and visual record, of problems, causes, and solutions each has encountered.
References-found: 18

