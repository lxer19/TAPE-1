URL: http://www.ai.mit.edu/people/jpmellor/techreport-.ps.gz
Refering-URL: http://www.ai.mit.edu/people/jpmellor/erv.html
Root-URL: 
Email: jpmellor@ai.mit.edu  
Title: Enhanced Reality Visualization in a Surgical Environment  
Author: J.P. Mellor 
Note: This publication can be retrieved by anonymous ftp to publications.ai.mit.edu. c Massachusetts Institute of Technology 1995  
Date: 1544 January 1995  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY  
Pubnum: A.I. Technical Report No.  
Abstract: Enhanced reality visualization is the process of enhancing an image by adding to it information which is not present in the original image. A wide variety of information can be added to an image ranging from hidden lines or surfaces to textual or iconic data about a particular part of the image. Enhanced reality visualization is particularly well suited to neurosurgery. By rendering brain structures which are not visible, at the correct location in an image of a patient's head, the surgeon is essentially provided with X-ray vision. He can visualize the spatial relationship between brain structures before he performs a craniotomy and during the surgery he can see what's under the next layer before he cuts through. Given a video image of the patient and a three dimensional model of the patient's brain, the problem enhanced reality visualization faces is to render the model from the correct viewpoint and overlay it on the original image. The relationship between the coordinate frames of the patient, the patient's internal anatomy scans and the image plane of the camera observing the patient must be established. This problem is closely related to the camera calibration problem. This report presents a new approach to finding this relationship and develops a system for performing enhanced reality visualization in a surgical environment. Immediately prior to surgery a few circular fiducials are placed near the surgical site. An initial registration of video and internal data is performed using a laser scanner. Following this, our method is fully automatic, runs in nearly real-time, is accurate to within a pixel, allows both patient and camera motion, automatically corrects for changes to the internal camera parameters (focal length, focus, aperture, etc.) and requires only a single image. 
Abstract-found: 1
Intro-found: 1
Reference: [ Adams et al., 1990 ] <author> Ludwig Adams, Joachim M. Gilsbach, Dietrich Meyer-Ebrecht Werner Krybus, Ralph Mosges, and Georg Schlondorff. </author> <title> CAS a navigation support for surgery. </title> <editor> In K. H. Hohne et al., editor, </editor> <booktitle> 3D Imaging in Medicine, volume 60 of NATO ASI, F, </booktitle> <pages> pages 411-423. </pages> <address> Heidelberg, </address> <year> 1990. </year>
Reference-contexts: INTRODUCTION 1.2. WHAT IS ENHANCED REALITY VISUALIZATION? 15 1.2 What is Enhanced Reality Visualization? Computer assisted surgery is a relatively new development which attempts to provide the surgeon with a tool to assist in the planning and execution of surgical procedures <ref> [ Adams et al., 1990, Lavallee and Cinquin, 1990 ] </ref> . <p> In this chapter we will examine several different approaches. 2.1 Medical Applications 2.1.1 Aachen University of Technology A group at the Aachen University of Technology in Germany has developed a Computer Assisted Surgery module for use in ENT surgical procedures <ref> [ Adams et al., 1990 ] </ref> . A model of the patient is produced from presurgical CT scans. Radiopaque markings are attached to the patient's skull prior to the presurgical scans for use as reference points. The system is calibrated using a hand-guided electro-mechanical three dimensional coordinate digitizer.
Reference: [ Azuma and Biship, 1994 ] <author> Ronald Azuma and Gary Biship. </author> <title> Improving static and dynamic registration in an optical see-through HMD. </title> <booktitle> In Computer Graphics, </booktitle> <pages> pages 197-204. </pages> <publisher> ACM SIGGRAPH, </publisher> <address> July 1994. Orlando, Fl. </address>
Reference: [ Bajura et al., 1992 ] <author> Michael Bajura, Henry Fuchs, and Ryutarou Ohbuchi. </author> <title> Merging virtual objects with the real world: Seeing ultrasound imagery within the patient. </title> <booktitle> In Computer Graphics, </booktitle> <pages> pages 203-210. </pages> <publisher> ACM SIGGRAPH, </publisher> <month> July </month> <year> 1992. </year>
Reference-contexts: The accuracy of this method is not reported. 2.1.6 University of North Carolina A group at the University of North Carolina has developed a method for Merging Virtual Objects with the Real World <ref> [ Bajura et al., 1992 ] </ref> . This system allows the user to see ultrasound imagery overlaid on a patient in near real-time. A six degrees of freedom (DOF) Polhemus 3Space tracker is mounted on the probe used to acquire ultrasound images.
Reference: [ Bemmel et al., 1985 ] <author> Jan H. Van Bemmel, Francois Gremy, and Jana Zvarova, </author> <title> editors. Medical Decision Making: Diagnostic Strategies and Expert Systems, </title> <address> New York, </address> <month> October </month> <year> 1985. </year> <title> IFIP-IMIA, </title> <publisher> North-Holland. </publisher> <address> Prague, Czechoslo-vakia. </address>
Reference: [ Black et al., 1993 ] <author> P. Black, R. Kikinis, W. Wells, D. Altobelli, W. Lorensen, H. Cline, and F. Jolesz. </author> <title> A new virtual reality technique for tumor localization. </title> <booktitle> In Congress of Neurological Surgeons, </booktitle> <year> 1993. </year>
Reference: [ Bose and Amir, 1990 ] <author> C.B. Bose and I. Amir. </author> <title> Design of fiducials for accurate registration using machine vision. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(12) </volume> <pages> 1196-1200, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: In the vertical direction the maximum is also 0.5 pixels so the maximum distance between the calculated centroid and the actual centroid is 1= p The maximum error can be reduced significantly by using a circular shape <ref> [ Bose and Amir, 1990, Efrat and Gotsman, 1993 ] </ref> . Figure 5-7 shows a digital approximation of a circle. The improvement which results from using a circular shape is caused by the fact that the error for a given row or column is dependent 5.2.
Reference: [ Brown, 1965 ] <author> Duane C. Brown. </author> <title> Decentering distortion of lenses. </title> <journal> Photogram-metric Engineering, </journal> <volume> 32(3) </volume> <pages> 444-462, </pages> <year> 1965. </year>
Reference-contexts: The effective focal length f also varies with focus and aperture settings. Zoom lenses take this variability to an extreme, enabling large changes to f . Lens distortion also varies with changes to focus and aperture <ref> [ Brown, 1965 ] </ref> . In enhanced reality visualization we are interested in the total transformation from model to image coordinates. We do not need to separate intrinsic and extrinsic parameters to generate an enhanced reality image.
Reference: [ Brown, 1971 ] <author> Duane C. Brown. </author> <title> Close-range camera calibration. </title> <journal> Photogram-metric Engineering, </journal> <volume> 37(8) </volume> <pages> 855-866, </pages> <year> 1971. </year>
Reference-contexts: It also works well if the fiducials are near the location of the enhancement. As a preliminary step, we measured the radial distortion for our camera setup. Radial distortion was measured using the plumb-line method <ref> [ Brown, 1971, Stein, 1993 ] </ref> for a 16mm and 25mm lens. The results are summarized in Table A.1. Plots of the distortion are also shown in Figures A-1 and A-2.
Reference: [ Caudell and Mizell, 1992 ] <author> Thomas P. Caudell and David W. Mizell. </author> <title> Augmented reality: An application of heads-up display technology to manual manufacturing processes. </title> <booktitle> In Proceedings of Hawaii International Conference on System Sciences, </booktitle> <volume> Vol II, </volume> <pages> pages 659-669. </pages> <publisher> IEEE Computer Society, </publisher> <month> January </month> <year> 1992. </year> <title> Kaual HI, RR P3.20.S9. </title> <type> 97 98 BIBLIOGRAPHY </type>
Reference-contexts: This system allows for motion of both the user and the patient. The accuracy of the overlay is not reported. 24 CHAPTER 2. RELATED WORK 2.2 Other Applications 2.2.1 Boeing A group at Boeing has developed An Application of Heads-Up Display Technology to Manual Manufacturing Processes <ref> [ Caudell and Mizell, 1992 ] </ref> . The goal of this work is to overlay manufacturing instructions on images of the manufacturing process and display them to a worker using an HMD. The instructions to be overlayed are derived from a CAD model.
Reference: [ Chang, 1993 ] <author> Ifay F. Chang. </author> <title> Computerized patient record and clinical information system. </title> <type> Technical Report RC 19164, </type> <institution> IBM, </institution> <month> September </month> <year> 1993. </year>
Reference: [ Chaudhuri and Samanta, 1991 ] <author> B.B. Chaudhuri and G.P. Samanta. </author> <title> Elliptic fit of objects in two and three dimensions by moment of inertia optimization. </title> <journal> Pattern Recognition Letters, </journal> <volume> 12(1) </volume> <pages> 1-7, </pages> <month> January </month> <year> 1991. </year>
Reference: [ Chiorboli and Vecchi, 1993 ] <author> G. Chiorboli and G.P. Vecchi. </author> <title> Comments on design of fiducials for accurate registration using machine vision. </title> <journal> IEEE Transactions On Pattern Analysis And Machine Intelligence, </journal> <volume> 15(12) </volume> <pages> 1330-1332, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: The maximum error for both the centroid and radius can be further reduced by using grey scale values rather than binary values <ref> [ Chiorboli and Vecchi, 1993 ] </ref> . Grey scale values can be modeled as the sum of a number of binary sub-pixels. Figure 5-8 shows a pixel with a dynamic range of 122 and a value of 25.
Reference: [ Church, 1945 ] <author> E. Church. </author> <note> Revised geometry of the aerial photograph. Bulletin of Aerial Photogrammetry 15, </note> <institution> Syracuse University, </institution> <year> 1945. </year>
Reference-contexts: CURRENT CAMERA CALIBRATION TECHNIQUES 31 2. Methods which recover only extrinsic parameters (also known as geometric methods). These methods assume that the intrinsic camera parameters are precisely known. This is not always possible for the reasons mentioned above. Examples of these methods include <ref> [ Church, 1945, Fischler and Bolles, 1981 ] </ref> . 3. Methods which recover both intrinsic and extrinsic parameters. These methods can be further divided into two categories: (a) Nonlinear optimization methods. These methods are both nonlinear and iterative.
Reference: [ Dinstein et al., 1984 ] <author> Its'hak Dinstein, Fritz merkle, Tinwai D. Lam, and Kwan Y. Wong. </author> <title> Imaging system response linearization and shading correction. </title> <booktitle> In Conference on Robotics, </booktitle> <pages> pages 204-209. </pages> <publisher> IEEE, </publisher> <address> March 1984. Atlanta, GA. </address>
Reference-contexts: Next we will consider image formation errors. These errors include noise and nonlinearities in the image sensor <ref> [ Dinstein et al., 1984, Healey and Kon-depudy, 1994 ] </ref> . For our purposes the most significant phenomenon is the smoothing of high contrast edges. We will refer to this as bleeding.
Reference: [ Duda and Hart, 1973 ] <author> Richard Duda and Peter Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: Image points are expressed in homogeneous coordinates to allow the perspective projection to be captured using linear equations <ref> [ Duda and Hart, 1973 ] </ref> . The pixel coordinates of an image point fi are determined by the following relationships: x 0 = x=z and y 0 = y=z. These relationships are very similar to (3.3) and (3.4).
Reference: [ Efrat and Gotsman, 1993 ] <author> Alon Efrat and Craig Gotsman. </author> <title> Subpixel image registration using circular fiducials. </title> <type> Technical Report TECHNION CIS 9308, </type> <institution> Technion, Israel Institute of Technology, Center for Intelligent Systems, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: In the vertical direction the maximum is also 0.5 pixels so the maximum distance between the calculated centroid and the actual centroid is 1= p The maximum error can be reduced significantly by using a circular shape <ref> [ Bose and Amir, 1990, Efrat and Gotsman, 1993 ] </ref> . Figure 5-7 shows a digital approximation of a circle. The improvement which results from using a circular shape is caused by the fact that the error for a given row or column is dependent 5.2.
Reference: [ Faig, 1975 ] <author> W. Faig. </author> <title> Calibration of close-range photogrammetry systems: Mathematical formulation. </title> <journal> Photogrammetric Engineering and Remote Sensing, </journal> <volume> 41 </volume> <pages> 1479-1486, </pages> <year> 1975. </year> <pages> Barker. </pages>
Reference-contexts: Further they are frequently not automatic and need a good initial solution to ensure convergence. Finding an initial solution can be a difficult problem. Examples of these methods include <ref> [ Faig, 1975, Sobel, 1974 ] </ref> . (b) Linearization methods. These methods linearize the nonlinear projection equations by introducing additional constraints. The basic difference between members of this category is how the problem is linearized. If care is not taken when the equations are linearized significant bias can be introduced.
Reference: [ Faugeras and Toscani, 1987 ] <author> O. Faugeras and G. Toscani. </author> <title> Camera calibration for three dimensional computer vision. </title> <booktitle> In Proceedings of the International Workshop on Industrial Applications of Machine Vision and Machine Intelligence. Seiken Symposium, </booktitle> <month> February </month> <year> 1987. </year> <institution> Tokyo, Japan; Barker TA1632.I595. </institution>
Reference: [ Feiner et al., 1993 ] <author> Steven Feiner, Blair MacIntyre, and Doree Seligmann. </author> <title> Knowledge-based augmented reality. </title> <journal> Communications of the ACM, </journal> <volume> 36(7) </volume> <pages> 53-62, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Given the relationship between the HMD and the work site an overlay can easily be generated. The accuracy of this system is not reported. 2.2.2 Columbia University A group at Columbia University has developed a method for Knowledge-Based Augmented Reality <ref> [ Feiner et al., 1993 ] </ref> . The goal of this work is to overlay instructions for repairing a laser printer with images of the laser printer. The instructions are derived from a knowledge-based system.
Reference: [ Fischler and Bolles, 1981 ] <author> M.A. Fischler and R.C. Bolles. </author> <title> Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography. </title> <journal> Communications of the ACM, </journal> <volume> 24(6) </volume> <pages> 381-385, </pages> <month> June </month> <year> 1981. </year> <note> BIBLIOGRAPHY 99 </note>
Reference-contexts: CURRENT CAMERA CALIBRATION TECHNIQUES 31 2. Methods which recover only extrinsic parameters (also known as geometric methods). These methods assume that the intrinsic camera parameters are precisely known. This is not always possible for the reasons mentioned above. Examples of these methods include <ref> [ Church, 1945, Fischler and Bolles, 1981 ] </ref> . 3. Methods which recover both intrinsic and extrinsic parameters. These methods can be further divided into two categories: (a) Nonlinear optimization methods. These methods are both nonlinear and iterative.
Reference: [ Ganapathy, 1984 ] <author> Sundaram Ganapathy. </author> <title> Decomposition of transformation matrices for robot vision. </title> <booktitle> In Conference on Robotics, </booktitle> <pages> pages 204-209. </pages> <publisher> IEEE, </publisher> <address> March 1984. Atlanta, GA. </address>
Reference-contexts: Clearly, to recover the pose of an object it is necessary to separate the intrinsic and extrinsic parameters. Separating the parameters is difficult <ref> [ Ganapathy, 1984 ] </ref> . The problem is nonlinear and several of the parameters are closely coupled. In the presence of noise a single solution to the camera calibration problem does not exist, rather there exists a set of solutions.
Reference: [ Goshtasby, 1987 ] <author> A. Goshtasby. </author> <title> Correction of image deformation from lens distortion. </title> <type> Technical report, </type> <institution> University of Kentucky, </institution> <year> 1987. </year>
Reference: [ Gottschalk and Hughes, 1993 ] <author> Stefan Gottschalk and John F. Hughes. </author> <title> Auto-calibration for virtual environments tracking hardware. </title> <booktitle> In Computer Graphics, </booktitle> <pages> pages 65-71. </pages> <publisher> ACM SIGGRAPH, </publisher> <month> August </month> <year> 1993. </year>
Reference: [ Grimson et al., 1994 ] <author> W.E.L. Grimson, T. Lozano-P erez, G.J. Ettinger W.M. Wells III, S.J. White, and R. Kikinis. </author> <title> An automatic registration method for frameless stereotaxy, image guided surgery, and enhanced reality visualization. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <pages> pages 430-436. </pages> <publisher> IEEE, </publisher> <address> June 1994. Seattle, WA. </address>
Reference-contexts: Accuracies of ~1mm and ~1 ffi are reported. 2.1.4 Massachusetts Institute of Technology A group at MIT's Artificial Intelligence Laboratory has developed An Automatic Registration Method for Frameless Stereotaxy, Image Guided Surgery, and Enhanced Reality Visualization <ref> [ Grimson et al., 1994 ] </ref> . As in the previous work described, a model of the patient's internal anatomy is produced from presurgical imaging. A Technical Arts laser range scanner is used to collect a set of 3D data points from the patient's skin surface. <p> They do not allow for patient motion. This is because the alignment between the patient and the world coordinate system is implicitly determined during the initial calibration phase and is not monitored. It is not clear that it is possible to extend these methods to allow for motion. <ref> [ Grimson et al., 1994 ] </ref> claim that their method is extensible to cover patient motion, however it is not clear that it is practical or possible to do so using a laser scanner. <p> In cases were the model coordinates of the fiducials are not known a priori, an initial calibration must be performed. An initial alignment is performed using data from a laser scanner <ref> [ Grimson et al., 1994 ] </ref> . This initial alignment along with an image showing the fiducials is then used to lookup the model (MR or CT) coordinates of the fiducials. Figure 6-1 shows an overview of this process. <p> A single scan produces 240 three dimensional measurements with accuracies up to 0.003. Surface points on the patient's head near the surgical site are measured with the scanner. These data points are aligned with a model of the patient's head and brain obtained from previous MR and/or CT scans <ref> [ Grimson et al., 1994 ] </ref> . The registration is produced by minimizing the sum of the squared distance between the laser data and the model. The model is sampled at several resolutions to speed convergence and random perturbations are used to avoid local minima.
Reference: [ Grosky and Tamburino, 1987 ] <author> W. Grosky and L. Tamburino. </author> <title> A unified approach to the linear camera calibration problem. </title> <type> Technical report, </type> <institution> University of Michigan, </institution> <year> 1987. </year>
Reference: [ Healey and Kondepudy, 1994 ] <author> Glenn E. Healey and Raghava Kondepudy. </author> <title> Radiometric CCD camera calibration and noise estimation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 16(3) </volume> <pages> 267-276, </pages> <month> March </month> <year> 1994. </year>
Reference: [ Horn, 1986 ] <author> Berthold Klaus Paul Horn. </author> <title> Robot Vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference: [ Hussain and Kabuka, 1990 ] <author> Basit Hussain and Mansur R. Kabuka. </author> <title> Real-time system for accurate three-dimensional position determination and verification. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 6(1) </volume> <pages> 31-43, </pages> <month> February </month> <year> 1990. </year>
Reference: [ Huttenlocher, 1988 ] <author> Danial Peter Huttenlocher. </author> <title> Three-Dimensional Recognition of Solid Objects From a Two-Dimensional Image. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <month> April </month> <year> 1988. </year>
Reference-contexts: If at least some minimum number of correspondences ( 4) are maintained, then the fiducials have been successfully tracked. If correspondence is lost or no previous correspondence exists than an initial correspondence must be established. The initial correspondence is performed using a modified version of the alignment method <ref> [ Huttenlocher, 1988 ] </ref> . The alignment method is modified to use scale information as well as some orientation constraints to significantly prune the search space. The three major constraints used are listed below: * Each fiducial is visible from only one side.
Reference: [ Kamgar-Parsi and Kamgar-Parsi, 1989 ] <author> Behrooz Kamgar-Parsi and Behzad Kamgar-Parsi. </author> <title> Evaluation of quantization error in computer vision. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11(9) </volume> <pages> 929-940, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: One of the more significant sources is quantization errors <ref> [ Kamgar-Parsi and Kamgar-Parsi, 1989 ] </ref> . These errors are the result of taking a continuous signal and converting it to digital values. First, we will examine errors caused by the fact that pixel values are only available at discrete locations in a lattice.
Reference: [ Landau, 1987 ] <author> U.M. Landau. </author> <title> Estimation of a circular arc center and its radius. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 38(3) </volume> <pages> 317-326, </pages> <month> June </month> <year> 1987. </year> <note> 100 BIBLIOGRAPHY </note>
Reference: [ Lavallee and Cinquin, 1990 ] <author> Stephane Lavallee and Philippe Cinquin. </author> <title> Computer assisted medical interventions. </title> <editor> In K. H. Hohne et al., editor, </editor> <booktitle> 3D Imaging in Medicine, volume 60 of NATO ASI, F, </booktitle> <pages> pages 301-312. </pages> <address> Heidelberg, </address> <year> 1990. </year>
Reference-contexts: INTRODUCTION 1.2. WHAT IS ENHANCED REALITY VISUALIZATION? 15 1.2 What is Enhanced Reality Visualization? Computer assisted surgery is a relatively new development which attempts to provide the surgeon with a tool to assist in the planning and execution of surgical procedures <ref> [ Adams et al., 1990, Lavallee and Cinquin, 1990 ] </ref> . <p> The system must be recalibrated every time the patient moves with respect to the digitizer. The reported accuracy is better than 1mm. 2.1.2 TIMB A group at TIMB in Grenoble, France has developed a Computer Assisted Medical Intervention module <ref> [ Lavallee and Cinquin, 1990 ] </ref> . A model of the patient's internal anatomy is produced from presurgical imaging. This system 21 22 CHAPTER 2. RELATED WORK uses a surgical robot or guidance system with modes that range from passive to semi-autonomous.
Reference: [ Lemoine et al., 1991 ] <author> D. Lemoine, C. Barillot, B. Gibaud, and E. Pasqualini. </author> <title> An anatomical-based 3D registration system of multimodality and atlas data in neurosurgery. </title> <booktitle> In Information Processing in Medical Imaging, </booktitle> <pages> pages 154-164, </pages> <year> 1991. </year>
Reference: [ Lenz and Tsai, 1988 ] <author> Reimar K. Lenz and Roger Y. Tsai. </author> <title> Techniques for calibration of the scale factor and image center for high accuracy 3-D machine vision metrology. </title> <journal> IEEE Transactions On Pattern Analysis And Machine Intelligence, </journal> <volume> 10(5) </volume> <pages> 713-720, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Synchronization errors can also cause the rows to not line up. This is known as pixel jitter and in extreme cases can cause the x and y axes to appear non-orthogonal or skewed <ref> [ Lenz and Tsai, 1988 ] </ref> . Most camera models omit skew angle xy (the angle between the x and y axes minus 90 ffi ). <p> FEATURE DETECTION AND LOCALIZATION of a circle. a circle. would appear to a significant limitation. This is not the case because s x=y is easy to calibrate and it does not change <ref> [ Lenz and Tsai, 1988, Penna, 1991 ] </ref> . s x=y is a function of the aspect ratio of the image sensor and the ratio of camera and frame grabber clock frequencies. The physical properties of the image sensor cannot change and modern clocks have extremely stable frequencies.
Reference: [ Maybank and Faugeras, 1992 ] <author> Stephen J. Maybank and Olivier D. Faugeras. </author> <title> A theory of self-calibration of a moving camera. </title> <journal> International Journal of Computer Vision, </journal> <volume> 8(2) </volume> <pages> 123-151, </pages> <month> August </month> <year> 1992. </year>
Reference: [ Miller, 1990 ] <author> Randolph A. Miller, </author> <title> editor. </title> <booktitle> Symposium on Computer Applications in Medical Care. IEEE Computer Society, November 1990. </booktitle> <address> Washington, DC. </address>
Reference: [ Pelizzari et al., 1991 ] <author> C. A. Pelizzari, K. K. Tan, D. N. Levin, G. T. Y. Chen, and J. Balter. </author> <title> Interactive 3d patient-image registration. </title> <booktitle> In Information Processing in Medical Imaging, </booktitle> <pages> pages 132-141, </pages> <month> July </month> <year> 1991. </year> <note> Wye, UK. </note>
Reference-contexts: Accuracy for the instrumented probe is reported as ~5mm. Accuracies for other modes are not reported. 2.1.3 University of Chicago A group at the University of Chicago has developed a method for Interactive 3D Patient Image Registration <ref> [ Pelizzari et al., 1991 ] </ref> . The method is used to position patients for radiation therapy. Again, a model of the patient's internal anatomy is produced from presurgical imaging. The model is used to plan the geometry of radiation therapy beams.
Reference: [ Penna, 1991 ] <author> M.A. Penna. </author> <title> Camera calibration: A quick and easy way to determine the scale factor. </title> <journal> IEEE Transactions On Pattern Analysis And Machine Intelligence, </journal> <volume> 13(12) </volume> <pages> 1240-1245, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: FEATURE DETECTION AND LOCALIZATION of a circle. a circle. would appear to a significant limitation. This is not the case because s x=y is easy to calibrate and it does not change <ref> [ Lenz and Tsai, 1988, Penna, 1991 ] </ref> . s x=y is a function of the aspect ratio of the image sensor and the ratio of camera and frame grabber clock frequencies. The physical properties of the image sensor cannot change and modern clocks have extremely stable frequencies.
Reference: [ Pieper et al., 1992 ] <author> Steven Pieper, Joseph Rosen, and David Zeltzer. </author> <title> Interactive graphics for plastic surgery: A task-level analysis and implementation. </title> <booktitle> In Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 127-134. </pages> <publisher> ACM SIGGRAPH, </publisher> <address> March 1992. Cambridge, MA. </address>
Reference: [ Reggia and Tuhrim, 1985 ] <author> James A. Reggia and Stanley Tuhrim, </author> <title> editors. Computer-Assisted Medical Decision Making, volume I and II. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference: [ Safaee-Rad et al., 1992 ] <author> R. Safaee-Rad, K.C. Smith, B. Benhabib, and I. Tchoukanov. </author> <title> Application of moment and fourier descriptors to the accurate estimation of elliptical-shape parameters. </title> <journal> Pattern Recognition Letters, </journal> <volume> 13(7) </volume> <pages> 497-508, </pages> <month> July </month> <year> 1992. </year> <note> BIBLIOGRAPHY 101 </note>
Reference: [ Schweikard et al., 1994 ] <author> Achim Schweikard, Rhea Tombropoulos, Lydia Kavraki, John R. Adler, and Jean-Claude Latombe. </author> <title> Treatment planning for a radiosurgical system with general kinematics. </title> <booktitle> In Robotics and Automation, </booktitle> <pages> pages 1720-1727. </pages> <publisher> IEEE, </publisher> <address> May 1994. San Diego, CA. </address>
Reference-contexts: The calibration must be reperformed if the patient or camera move and the overlay can only be generated for a single viewpoint. The reported accuracy of this method is ~1mm. 2.1.5 Stanford A group at Stanford University has developed Treatment Planning for a Ra-diosurgical System with General Kinematics <ref> [ Schweikard et al., 1994 ] </ref> . The method is used to plan and perform radiosurgery. A model of the patient's internal anatomy is produced from presurgical imaging. The radiosurgery is planned using the model. In addition, the model is used to synthesize radiographs from different view points.
Reference: [ Slama, 1980 ] <editor> C.C. Slama, editor. </editor> <title> Manual of Photogrammetry. </title> <journal> American Society of Photogrammetry, </journal> <note> fourth edition, </note> <year> 1980. </year>
Reference-contexts: For a more complete discussion of camera calibration techniques see <ref> [ Slama, 1980, Tsai, 1987 ] </ref> . Camera calibration techniques can be divided into three different categories: 1. Methods which recover only intrinsic parameters. These methods generally require a special calibration object or stand to allow the internal parameter (s) to be measured independent of other parameters. <p> CONCLUSIONS Appendix A Effects of Radial Distortion As discussed in previous chapters, our method only models a linear approximation to radial distortion. In this appendix we will consider the consequences of this approximations. Radial distortion is typically modeled as follows <ref> [ Slama, 1980 ] </ref> : u = x 0 d + ffix (A.1) y 0 d + ffiy (A.2) ffix = d x 0 K 1 r 0 2 d (A.3) ffiy = d y 0 K 1 r 0 2 d (A.4) Where x 0 u and y 0 u
Reference: [ Smith et al., 1991 ] <author> K.R. Smith, K. Joarder, R.D. Bucholz, and K.R. Smith. </author> <title> Multimodality image analysis and display methods for improved tumor localization in stereotactic neurosurgery. In Engineering in Medicine and Biology, page 210. </title> <journal> IEEE, 1991. </journal> <volume> Volume 3. </volume>
Reference: [ Sobel, 1974 ] <author> I. Sobel. </author> <title> On calibrating computer controlled cameras for perceiving 3-d scenes. </title> <journal> Artificial Intelligence, </journal> <volume> 5 </volume> <pages> 185-198, </pages> <year> 1974. </year>
Reference-contexts: Further they are frequently not automatic and need a good initial solution to ensure convergence. Finding an initial solution can be a difficult problem. Examples of these methods include <ref> [ Faig, 1975, Sobel, 1974 ] </ref> . (b) Linearization methods. These methods linearize the nonlinear projection equations by introducing additional constraints. The basic difference between members of this category is how the problem is linearized. If care is not taken when the equations are linearized significant bias can be introduced.
Reference: [ Stein, 1993 ] <author> Gideon P. Stein. </author> <title> Internal camera calibration using rotation and geometric shapes. </title> <type> Master's thesis, </type> <institution> MIT, </institution> <month> February </month> <year> 1993. </year> <note> MIT/AI/TR 1426. </note>
Reference-contexts: It also works well if the fiducials are near the location of the enhancement. As a preliminary step, we measured the radial distortion for our camera setup. Radial distortion was measured using the plumb-line method <ref> [ Brown, 1971, Stein, 1993 ] </ref> for a 16mm and 25mm lens. The results are summarized in Table A.1. Plots of the distortion are also shown in Figures A-1 and A-2.
Reference: [ Thomas and Chan, 1989 ] <author> Samual M. Thomas and Y.T. Chan. </author> <title> A simple approach for the estimation of circular arc center and its radius. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 45(3) </volume> <pages> 362-370, </pages> <month> March </month> <year> 1989. </year>
Reference: [ Tsai, 1987 ] <author> Roger Y. Tsai. </author> <title> A versatile camera calibration technique for high-accuracy three dimensional machine vision metrology using off-the-shelf TV cameras and lenses. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-3(4):323-344, </volume> <month> August </month> <year> 1987. </year>
Reference-contexts: For a more complete discussion of camera calibration techniques see <ref> [ Slama, 1980, Tsai, 1987 ] </ref> . Camera calibration techniques can be divided into three different categories: 1. Methods which recover only intrinsic parameters. These methods generally require a special calibration object or stand to allow the internal parameter (s) to be measured independent of other parameters.
Reference: [ Verbeeck et al., 1993 ] <author> R. Verbeeck, D. Vandermeulen, J. Michiels, P. Suetens, G. Marchal, J. Gybels, and B. Nuttin. </author> <booktitle> Computer assisted stereotactic neuro-surger. Image and Vision Computing, </booktitle> <volume> 11(8) </volume> <pages> 468-485, </pages> <month> October </month> <year> 1993. </year>
Reference: [ Wang et al., 1990 ] <author> Jih-fang Wang, Vernon Chi, and Henry Fuchs. </author> <title> A real-time optical 3d tracker for head-mounted display systems. </title> <booktitle> In Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 205-215. </pages> <publisher> ACM SIGGRAPH, </publisher> <address> March 1990. Snowbird, Utah. </address>
Reference: [ Ward et al., 1992 ] <author> Mark Ward, Ronald Azumaand Robert Bennett, Stefan Gottschalk, and Henry Fuchs. </author> <title> A demonstratedd optical tracker with scalable work area for head mounted display systems. </title> <booktitle> In Computer Graphics, </booktitle> <pages> pages 43-52. </pages> <publisher> ACM SIGGRAPH, </publisher> <address> March 1992. Cambridge, MA. </address>
Reference: [ Watkins, 1991 ] <author> D. Watkins. </author> <title> Fundamentals of Matrix Computations. </title> <publisher> John Wiley and Sons, Inc., </publisher> <address> New York, </address> <year> 1991. </year> <note> 102 BIBLIOGRAPHY </note>
Reference-contexts: If correspondences have been established for more than four fiducials than an over-determined system of linear equations exists. We solve this problem in a least-squares fashion by minimizing the following error terms using Householder's QR decomposition <ref> [ Watkins, 1991 ] </ref> . kr 1 k 2 = i=1 i ( p 11 X i + p 21 Y i + p 31 Z i + p 41 ) j 2 (4.11) n X jy ? kr 3 k 2 = i=1 fi fi fi s i fi fi
Reference: [ Wells et al., 1993 ] <author> W. Wells, R. Kikinis, D. Altobelli, G. Ettinger W. Lorensen, H. Cline, P. L. Gleason, and F. Jolesz. </author> <title> Video registration using fiducials for surgical enhanced reality. </title> <booktitle> In Engineering in Medicine and Biology. IEEE, </booktitle> <year> 1993. </year>
Reference-contexts: Almost all of the current approaches ignore the information contained in the raw image opting for what is essentially a closed loop solution. Recently <ref> [ Wells et al., 1993 ] </ref> proposed a method of enhanced reality visualization using video information exclusively, however the method requires manual alignment of the model with the video image and in some cases requires markers to appear in both the MR image and video image.
Reference: [ Willson and Shafer, 1993 ] <author> Reg G. Willson and Steven A. Shafer. </author> <title> What is the center of the image? Technical Report CMU-CS-93-122, </title> <institution> Carnegie-Mellon University, Computer Science Department, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: Further, the intrinsic camera calibration parameters are not fixed. They change with the focus and aperture settings. For example, the principle point can shift by 8 pixels or more with adjustments to focus <ref> [ Willson and Shafer, 1993 ] </ref> . The effective focal length f also varies with focus and aperture settings. Zoom lenses take this variability to an extreme, enabling large changes to f . Lens distortion also varies with changes to focus and aperture [ Brown, 1965 ] .
References-found: 54

