URL: http://www.eecs.umich.edu/~qstout/pap/subcubeft.ps.Z
Refering-URL: http://www.eecs.umich.edu/~qstout/papers.html
Root-URL: http://www.eecs.umich.edu
Title: Subcube Fault-Tolerance in Hypercubes  
Author: Niall Graham ; Frank Harary Marilynn Livingston ; Quentin F. Stout 
Keyword: hypercube computer, n-cube, fault-tolerance, k-independent sets, partitions.  
Date: 16 September 1987 Revised 22 July 1988 and 12 September 1990  
Address: Las Cruces, NM 88003-0001  Ann Arbor, MI 48109-2122  
Affiliation: Computing Research Laboratory Department of Computer Science New Mexico State University  Advanced Computer Architecture Laboratory Electrical Engineering and Computer Science University of Michigan  
Note: In Information and Computation 102 (1993), pp. 280-314.  
Abstract: We consider the problem of determining the minimum number of faulty processors, (n; m), and of faulty links, (n; m), in an n-dimensional hypercube computer so that every m-dimensional subcube is faulty. Best known lower bounds for (n; m) and (n; m) are proved, several new recursive inequalities and new upper bounds are established, their asymptotic behavior for fixed m and for fixed nm are analyzed, and their exact values are determined for small n and m. Most of the methods employed show how to construct sets of faults attaining the bounds. An extensive survey of related work is also included, showing connections to resource allocation, k-independent sets, and exhaustive testing. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon. </author> <title> Explicit construction of exponential sized families of k-independent sets. </title> <journal> Discrete Math. </journal> <month> 58 </month> <year> (1986) </year> <month> 191-193. </month>
Reference-contexts: Their results give a construction of a set in S (n; m) of size O (log w n), where w can be arbitrarily close to 1. Alon <ref> [1] </ref> has given a construction of a family of k-independent subsets of a set of size r.
Reference: [2] <author> Y. Burton. </author> <title> On the probability of connectedness of a random subgraph of the n-cube. </title> <journal> Problemy pered inf. </journal> <note> 13 (Russian-English summary) (1977). </note>
Reference-contexts: They showed that if at least (n m)2 nm lg n nodes are removed from Q n , the probability that there are no remaining m-cubes approaches 1 as n tends to infinity. A variation of these questions appears in the work of Burton <ref> [2] </ref>, and Erdos and Spencer [10].
Reference: [3] <author> B. Becker and H. Simon. </author> <title> How robust is the n-cube? Info. </title> <booktitle> and Comp. </booktitle> <month> 77 </month> <year> (1988) </year> <month> 162-178. </month>
Reference-contexts: In our notation this is (n; n k). They determined (n; n 2), gave a construction for sets in S (n; n 3) of non-optimal size, and used essentially the same probabilistic argument as in [26] to obtain an upper bound for (n; n k). Becker and Simon <ref> [3] </ref>, apparently unaware of the work in [7], repeated many of these results for , and used the same methods to establish bounds on . <p> Selecting a = b (n 1 m)=2c results in the removal of levels as far from the center level (s) as possible. A straightforward term-by-term comparison shows the optimality of this value of a. 2 While many authors <ref> [3, 7, 20, 21, 22, 24] </ref> utilize the approach of the theorem just proved, most choose to express their result in the following simpler but weaker form. Corollary 4.1 For n m 1, (n; m) m + 1 Proof. <p> This means that y 2 F i for each i 2 J 1 and y 62 F i for i 2 J 2 , which allows us to conclude that F is k-independent. 2 The correspondence established in the lemma, used in <ref> [3] </ref> and [7], gives the following result. Theorem 8 ([3, 7]) Let F (r; k) denote the maximum size of a k-independent family of subsets of a set of r elements. <p> Using this result and the above theorem, one immediately obtains the following. Theorem 9 (n; n 2) is the minimum positive integer r such that r1 10 Chandra et al. [7] rediscovered this result and the following corollary, as did Becker and Simon <ref> [3] </ref>. Corollary 9.1 ([3, 7]) (n; n 2) = lg n + 1 2 lg lg n + O (1), where the O (1) term is non negative. 2 Kleitman and Spencer also obtained bounds for F (r; k). <p> Rewriting it in the following slightly weaker form, (n; n k) 2 k1 k 2 + lg e lg (n k + 3) k lg k 2 lg lg n; (5) it is easy to compare the improvement gained over the bound from <ref> [3] </ref> (n; n k) 2 k2 [lg (n k + 2) + 0:125 lg lg (n k + 2)]; which is the result of applying Theorems 2 and 9. <p> proba bilistic argument to prove that F (r; k) (1=2)(k!) 1=k (2 k =(2 k 1)) r=k : (6) When this inequality is combined with Theorem 8, it is straightforward to show that (n; n k) lg (1 2 k ) This inequality, first established in [7] and later in <ref> [3] </ref>, provides the best known upper bound for fixed k and large n; k. It will be discussed further in Section 4. <p> Becker and Simon <ref> [3] </ref> used Friedman's result to construct sets in S (n; nk) of size at most lg n (k 4 = lg k)2 2k lg k+3k . While this construction yields sets of the right order of magnitude, namely O (lg n), for small k they are impractically large. <p> Figure 1 illustrates (4; 2). We state two straightforward consequences of Theorem 15 which were also observed in <ref> [3] </ref>. Corollary 15.1 For n 3, (i) (n; n 2) (n; n 2) (n 1; n 3) + 6 2 lg lg n + O (1). 2 The labeling technique used in Theorem 3 has an analog for (n; m). <p> Kleitman and Spencer [26] used probabilistic methods to determine bounds for the maximum size of families of k-independent sets. Chandra et al. [7] used a probabilistic argument equivalent to that in [26] to prove the following bound on . Becker and Simon <ref> [3] </ref> rediscovered this result, and used similar arguments to establish an upper bound for . These bounds are stated in the following. <p> Unfortunately, finding such sets is a very difficult problem in general. Arguments in [26] and [7] show that non-deterministic methods have a high probability of success for n large and n m fixed. Probabilistic arguments similar to those in [26] were used in <ref> [3, 7] </ref> to prove that, with high probability, a randomly chosen set of (ln 2)(n m)2 nm lg n nodes of Q n is in 25 S (n; m). <p> An analogous argument shows that, with high probability, a randomly chosen set of (ln 2)(n m)2 nm ( n m ) lg n edges of Q n is in T (n; m) <ref> [3] </ref>. Levitin and Karpovsky [27] developed constructive methods for a problem equivalent to the study of (n; m). The problem involves the exhaustive testing of devices with n inputs where each output is a Boolean function of at most k binary input variables. <p> For fixed n m, this size is the same order of magnitude as a minimum set in S (n; m), but even for n m = 3, say, it is more than 3 216 lg n. As discussed in Section 2.4, Becker and Simon <ref> [3] </ref> used results of Friedman [12] to construct sets in S (n; n k) of size at most lg n (k 4 = lg k)2 2k lg k+3k . <p> On the other hand, the construction in Theorem 13 yields a set in S (20; 17) of size 19. Even the construction using level sets, Theorem 4, yields a set of size 40 in this case. When m is fixed, the constructions in [12] and <ref> [3] </ref> give sets whose sizes are far from the same order of magnitude as (n; m). In this case the best constructions for near minimum fault sets are given by the level sets in Theorems 4 and 17. <p> While the buddy system is the only allocation scheme used on hypercube computers thus far, we see it is not 26 particularly fault-tolerant. For some specific allocation schemes of interest, Livingston and Stout [29] determined (A; n; m). For arbitrary allocation scheme A, Becker and Simon <ref> [3] </ref> showed that the problem of determining (A; n; n 2) is equivalent to a graph-coloring problem. The general problem of determining (A; n; m) and (A; n; m) is open. The fault-tolerance questions considered here can be generalized to arbitrary architectures and arbitrary graph properties. <p> A related but somewhat different situation arises if we are only concerned that, with high probability, G fails to have property P . What is the expected number of copies of H that must be removed in this case? Becker and Simon <ref> [3] </ref> considered an instance of this question in which G is Q n , H is a single node, and P denotes the property of containing an m-cube.
Reference: [4] <author> B. Bollobas. </author> <title> The evolution of the cube. Combinatorial Mathematics (C. Berge, </title> <editor> et al., Eds). </editor> <publisher> North-Holland (1983) 91-97. </publisher>
Reference-contexts: p, they showed that if P 1 (Q n ; p) denotes the probability that the resulting subgraph of Q n is connected then lim P 1 (Q n ; p) = &lt; 1 if p &lt; 1=2; 0 otherwise. 27 When p is allowed to vary with n, Bollobas <ref> [4, 5] </ref> proved that if &gt; 0 and p = p (n) = 1 2 then lim P 1 (Q n ; p) = e : Suppose that instead of deleting edges from Q n we delete nodes, together with their incident edges, with fixed probability p and define P 0
Reference: [5] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press Inc. (London) Ltd. </publisher> <year> (1985) </year> <month> 336-346. </month>
Reference-contexts: p, they showed that if P 1 (Q n ; p) denotes the probability that the resulting subgraph of Q n is connected then lim P 1 (Q n ; p) = &lt; 1 if p &lt; 1=2; 0 otherwise. 27 When p is allowed to vary with n, Bollobas <ref> [4, 5] </ref> proved that if &gt; 0 and p = p (n) = 1 2 then lim P 1 (Q n ; p) = e : Suppose that instead of deleting edges from Q n we delete nodes, together with their incident edges, with fixed probability p and define P 0
Reference: [6] <author> A. Brace and D. E. Daykin. </author> <title> Sperner type theorems for finite sets. </title> <booktitle> Proc. Br. Combinatorial Conf. </booktitle> <address> Oxford (1972) 18-37. </address>
Reference-contexts: In Section 2 we show the direct relationship between k-independent sets and . The earliest published work relevant to evaluating and is apparently that of Schonheim [34], and Brace and Daykin <ref> [6] </ref>, who determined the maximum size of a 2-independent family, and Kleitman and Spencer [26], who considered the general problem of determining the maximum size of families of k-independent sets. <p> Theorem 8 ([3, 7]) Let F (r; k) denote the maximum size of a k-independent family of subsets of a set of r elements. Then (n; m) = minfr j F (r; n m) ng: 2 Schonheim [34], Brace and Daykin <ref> [6] </ref>, and Kleitman and Spencer [26] determined the maximum size of a family of 2-independent sets. Kleitman and Spencer proved that F (r; 2) = br=2c1 , observing that this maximum is attained by taking all subsets of size br=2c that contain a fixed element of X.
Reference: [7] <author> A. Chandra, L. Kou, G. Markowsky, and S. Zaks. </author> <title> On sets of boolean n-vectors with all k-projections surjective. </title> <journal> Acta Inf. </journal> <month> 20 </month> <year> (1983) </year> <month> 103-111. </month>
Reference-contexts: These results yield the value of (n; n 2) and bounds for (n; n k). Chandra, Kou, Markowsky, and Zaks <ref> [7] </ref> studied the problem of finding the minimum number of boolean n-vectors such that every k-projection of them yields all possible k-vectors. In our notation this is (n; n k). <p> They determined (n; n 2), gave a construction for sets in S (n; n 3) of non-optimal size, and used essentially the same probabilistic argument as in [26] to obtain an upper bound for (n; n k). Becker and Simon [3], apparently unaware of the work in <ref> [7] </ref>, repeated many of these results for , and used the same methods to establish bounds on . They also gave a construction, based on the work of Friedman [12], which yields an upper bound for (n; n k) that has the correct growth behavior for fixed n k. <p> Selecting a = b (n 1 m)=2c results in the removal of levels as far from the center level (s) as possible. A straightforward term-by-term comparison shows the optimality of this value of a. 2 While many authors <ref> [3, 7, 20, 21, 22, 24] </ref> utilize the approach of the theorem just proved, most choose to express their result in the following simpler but weaker form. Corollary 4.1 For n m 1, (n; m) m + 1 Proof. <p> This means that y 2 F i for each i 2 J 1 and y 62 F i for i 2 J 2 , which allows us to conclude that F is k-independent. 2 The correspondence established in the lemma, used in [3] and <ref> [7] </ref>, gives the following result. Theorem 8 ([3, 7]) Let F (r; k) denote the maximum size of a k-independent family of subsets of a set of r elements. <p> Using this result and the above theorem, one immediately obtains the following. Theorem 9 (n; n 2) is the minimum positive integer r such that r1 10 Chandra et al. <ref> [7] </ref> rediscovered this result and the following corollary, as did Becker and Simon [3]. <p> [26] used a non-constructive proba bilistic argument to prove that F (r; k) (1=2)(k!) 1=k (2 k =(2 k 1)) r=k : (6) When this inequality is combined with Theorem 8, it is straightforward to show that (n; n k) lg (1 2 k ) This inequality, first established in <ref> [7] </ref> and later in [3], provides the best known upper bound for fixed k and large n; k. It will be discussed further in Section 4. <p> Although its methods yield sets of size O ((lg n) 2 ), as pointed out earlier, when it is combined with Corollary 12.1 and Table 1, it yields superior bounds for (n; n 3) for n 1600. A similar construction was used by Chandra et al. <ref> [7] </ref> to construct sets in S (n; n k) of size O ((lg n) k1 ), but for specific n and k, their sets are somewhat larger than ours because they could not utilize the results in Table 1. 14 Theorem 13 For n 5, (n; n 3) (dn=2e; dn=2e 3) <p> intersection, then yy 0 2 T " S. 2 The proof of the above theorem can be extended to show that for all n 2h 2, (n; n h) (d n 2 e h) + i=2 2 e; d n 2 e; d n A slightly weaker result appears in <ref> [7] </ref>, where the factor (d n 2 e; d n 2 e i) 1 in the above summation is replaced by (d n 2 e; d n 15 3 The Values of Turning to the corresponding questions involving edge faults instead of node faults, we find that many of the results <p> In this section we describe the best known bounds for each of these cases and mention several open problems concerning the relative sizes of and . Kleitman and Spencer [26] used probabilistic methods to determine bounds for the maximum size of families of k-independent sets. Chandra et al. <ref> [7] </ref> used a probabilistic argument equivalent to that in [26] to prove the following bound on . Becker and Simon [3] rediscovered this result, and used similar arguments to establish an upper bound for . These bounds are stated in the following. <p> Unfortunately, finding such sets is a very difficult problem in general. Arguments in [26] and <ref> [7] </ref> show that non-deterministic methods have a high probability of success for n large and n m fixed. <p> Unfortunately, finding such sets is a very difficult problem in general. Arguments in [26] and [7] show that non-deterministic methods have a high probability of success for n large and n m fixed. Probabilistic arguments similar to those in [26] were used in <ref> [3, 7] </ref> to prove that, with high probability, a randomly chosen set of (ln 2)(n m)2 nm lg n nodes of Q n is in 25 S (n; m).
Reference: [8] <author> S. Dutt. </author> <title> Designing and Reconfiguring Fault-Tolerant Multiprocessor Systems. </title> <type> PhD thesis, </type> <institution> Univ. Michigan, </institution> <year> 1990. </year> <month> 28 </month>
Reference-contexts: Two basic graph-theoretic approaches are to provide additional edges and/or nodes, or to weaken the notion of a subcube. In the former, hardware is added so that the system still has a Q n as a subsystem after a fault occurs <ref> [8, 33, 36] </ref>. This approach must be taken at the time of hardware design, and can tolerate relatively few faults without inordinate expense.
Reference: [9] <author> P. Erdos. </author> <title> Some problems in graph theory, combinatorial analysis and combinatorial number theory. Graph Theory and Combinatorics, </title> <editor> B. Bollobas, ed., </editor> <publisher> Academic Press (1984) 1-17. </publisher>
Reference-contexts: Thus, the Johnson and Entringer result determines (n; 2). In [20, 21, 23], Johnson has considered f (n; m) and obtained bounds for the cases m = 3; 4; 5, and in [22] has evaluated g (5; 2). Responding to a related question of Erdos <ref> [9] </ref> (see Section 3.4), F. Chung (personal communication, July 1988) established an upper bound for g (n; 2), thus providing a lower bound for (n; 2). 1.2 Organization The following sections contain our new results on and as well as an extensive survey of related work. <p> By Theorems 1 and 15 (ii), at most 1 2 of the edges need be faulty to insure that every Q 2 is faulty. Some time ago, Erdos <ref> [9] </ref> conjectured that, for every * &gt; 0, there is an n * such that, for all n &gt; n * , g (n; 2) &lt; ( 1 2 + *)n2 n1 , i.e., that the edge density becomes arbitrarily close to 1 2 .
Reference: [10] <author> P. Erdos, P. Frankl, and Z. Furedi. </author> <title> Families of finite sets in which no set is covered by the union oftwo others. </title> <journal> J. Combin. </journal> <note> Theory A 33 (1982) 158-166. </note>
Reference-contexts: In Section 2 we derive several bounds for . We establish new bounds for the maximum 3 size of 3-independent families by using the non-constructive methods of Erdos, Frankl, and Furedi <ref> [10] </ref>. These bounds yield an improved upper bound for (n; n 3). We also give a construction for small sets in S (n; n 3) which yields a new recursive inequality for (n; n 3), producing the best known upper bounds for it with n of any practical size. <p> It will be discussed further in Section 4. Using the non-constructive methods of Erdos, Frankl, and Furedi <ref> [10] </ref>, we next derive a new upper bound for (n; n 3) that, for n large, is superior to any other known bounds. The best upper bound known previously, given by inequality (7) with k = 3, is (n; n 3) 15:571 lg n. <p> They showed that if at least (n m)2 nm lg n nodes are removed from Q n , the probability that there are no remaining m-cubes approaches 1 as n tends to infinity. A variation of these questions appears in the work of Burton [2], and Erdos and Spencer <ref> [10] </ref>.
Reference: [11] <author> P. Erdos and J. Spencer. </author> <title> Evolution of the n-cube. </title> <journal> Comput. Math. Appl. </journal> <month> 5 </month> <year> (1979) </year> <month> 33-39. </month>
Reference: [12] <author> J. Friedman. </author> <title> Constructing O(n log n) size monotone formulae for the k-th elementary symmetric polynomial of n Boolean variables. </title> <booktitle> 25th Symp. on Found. of Computer Science (1984) 506-515. </booktitle>
Reference-contexts: Becker and Simon [3], apparently unaware of the work in [7], repeated many of these results for , and used the same methods to establish bounds on . They also gave a construction, based on the work of Friedman <ref> [12] </ref>, which yields an upper bound for (n; n k) that has the correct growth behavior for fixed n k. <p> Friedman <ref> [12] </ref> showed how to construct, for any fixed k and n, a collection of O (lg n) partitions of f1; 2; : : :; ng such that for any subset T of f1; 2; : : :; ng of size k, there is a partition in which each of its cells <p> For fixed n m, this size is the same order of magnitude as a minimum set in S (n; m), but even for n m = 3, say, it is more than 3 216 lg n. As discussed in Section 2.4, Becker and Simon [3] used results of Friedman <ref> [12] </ref> to construct sets in S (n; n k) of size at most lg n (k 4 = lg k)2 2k lg k+3k . <p> On the other hand, the construction in Theorem 13 yields a set in S (20; 17) of size 19. Even the construction using level sets, Theorem 4, yields a set of size 40 in this case. When m is fixed, the constructions in <ref> [12] </ref> and [3] give sets whose sizes are far from the same order of magnitude as (n; m). In this case the best constructions for near minimum fault sets are given by the level sets in Theorems 4 and 17.
Reference: [13] <author> F. Harary, J. P. Hayes, and H. Wu. </author> <title> A survey of the theory of hypercube graphs. </title> <journal> Comput. Math. Appl. </journal> <month> 15 </month> <year> (1988) </year> <month> 277-289. </month>
Reference-contexts: If G is Q n , P is the property of containing an m-cube, and H is a single m-cube, then (Q m ; Q m ; Q n ) is the mispacking number mispac 0 (Q m ae Q n ) discussed in <ref> [13] </ref>.
Reference: [14] <author> J. Hastad, T. Leighton, and M. Newman. </author> <title> Reconfiguring a hypercube in the presence of faults. </title> <booktitle> Proc. 19th ACM Symp. Theory of Computing (1987) 274-284. </booktitle>
Reference-contexts: Generally, many more faults can be tolerated with this approach and it is frequently possible to provide a reconfigured subcube of the desired size in the presence of several faults <ref> [14] </ref>. This solution suffers a performance penalty, however, because each communication step in a reconfigured subcube takes longer than a communication step in the original hypercube. Neither of these approaches has yet been implemented in any commercial hypercube, and we will not pursue these methods here.
Reference: [15] <institution> Hypercube Multiprocessors 1986, </institution> <note> SIAM. </note>
Reference-contexts: Hypercube computers have been studied since 1962 [35] and have recently become the focus of intense commercial and research activity <ref> [15, 16, 17, 18, 19] </ref>. One of the attractive features of the n-cube topology is its behavior in the presence of faulty processors or links. Depending on the number and location of these faults it is possible that the network still contains large subcubes which are fault-free.
Reference: [16] <institution> Hypercube Multiprocessors 1987, </institution> <note> SIAM. </note>
Reference-contexts: Hypercube computers have been studied since 1962 [35] and have recently become the focus of intense commercial and research activity <ref> [15, 16, 17, 18, 19] </ref>. One of the attractive features of the n-cube topology is its behavior in the presence of faulty processors or links. Depending on the number and location of these faults it is possible that the network still contains large subcubes which are fault-free.
Reference: [17] <editor> Proc. </editor> <booktitle> 3rd Conf. on Hypercube Concurrent Computers and Applications, (1988) SIAM. </booktitle>
Reference-contexts: Hypercube computers have been studied since 1962 [35] and have recently become the focus of intense commercial and research activity <ref> [15, 16, 17, 18, 19] </ref>. One of the attractive features of the n-cube topology is its behavior in the presence of faulty processors or links. Depending on the number and location of these faults it is possible that the network still contains large subcubes which are fault-free.
Reference: [18] <editor> Proc. </editor> <booktitle> 4th Conf. on Hypercube Concurrent Computers and Applications, </booktitle> <year> (1989). </year>
Reference-contexts: Hypercube computers have been studied since 1962 [35] and have recently become the focus of intense commercial and research activity <ref> [15, 16, 17, 18, 19] </ref>. One of the attractive features of the n-cube topology is its behavior in the presence of faulty processors or links. Depending on the number and location of these faults it is possible that the network still contains large subcubes which are fault-free.
Reference: [19] <editor> Proc. </editor> <booktitle> 5th Distributed Memory Computer Conference, </booktitle> <year> (1990). </year>
Reference-contexts: Hypercube computers have been studied since 1962 [35] and have recently become the focus of intense commercial and research activity <ref> [15, 16, 17, 18, 19] </ref>. One of the attractive features of the n-cube topology is its behavior in the presence of faulty processors or links. Depending on the number and location of these faults it is possible that the network still contains large subcubes which are fault-free.
Reference: [20] <author> K. Johnson. </author> <title> Largest induced subgraphs of the n-cube that contain no 2k-cycle. </title> <type> PhD thesis, </type> <institution> Univ. </institution> <address> New Mexico, </address> <year> 1986. </year>
Reference-contexts: Notice that f (n; m) = 2 n (n; m) and g (n; m) = n2 n1 (n; m). Thus, the Johnson and Entringer result determines (n; 2). In <ref> [20, 21, 23] </ref>, Johnson has considered f (n; m) and obtained bounds for the cases m = 3; 4; 5, and in [22] has evaluated g (5; 2). Responding to a related question of Erdos [9] (see Section 3.4), F. <p> Selecting a = b (n 1 m)=2c results in the removal of levels as far from the center level (s) as possible. A straightforward term-by-term comparison shows the optimality of this value of a. 2 While many authors <ref> [3, 7, 20, 21, 22, 24] </ref> utilize the approach of the theorem just proved, most choose to express their result in the following simpler but weaker form. Corollary 4.1 For n m 1, (n; m) m + 1 Proof. <p> In [21, 28] it was noted that, for fixed m, C fl (n; m) satisfies a recursive equation, and this was later solved for m = 3; 4; 5 in <ref> [20, 21, 23] </ref>. These results yield upper bounds for (n; m) for m = 3; 4; 5 which are improvements over those provided by Corollary 4.1. We summarize these in the following. Theorem 6 ([20, 21, 23]) For n; m 1, (i) (n; 3) 2 n =4 2 bn=2c =2: (n;
Reference: [21] <author> K. Johnson. </author> <title> An appearance of the Fibonacci and Lucas numbers in a hypercube problem. </title> <type> Preprint, </type> <institution> University of New Mexico, </institution> <month> 11 March </month> <year> 1988. </year>
Reference-contexts: Notice that f (n; m) = 2 n (n; m) and g (n; m) = n2 n1 (n; m). Thus, the Johnson and Entringer result determines (n; 2). In <ref> [20, 21, 23] </ref>, Johnson has considered f (n; m) and obtained bounds for the cases m = 3; 4; 5, and in [22] has evaluated g (5; 2). Responding to a related question of Erdos [9] (see Section 3.4), F. <p> Selecting a = b (n 1 m)=2c results in the removal of levels as far from the center level (s) as possible. A straightforward term-by-term comparison shows the optimality of this value of a. 2 While many authors <ref> [3, 7, 20, 21, 22, 24] </ref> utilize the approach of the theorem just proved, most choose to express their result in the following simpler but weaker form. Corollary 4.1 For n m 1, (n; m) m + 1 Proof. <p> In <ref> [21, 28] </ref> it was noted that, for fixed m, C fl (n; m) satisfies a recursive equation, and this was later solved for m = 3; 4; 5 in [20, 21, 23]. <p> In [21, 28] it was noted that, for fixed m, C fl (n; m) satisfies a recursive equation, and this was later solved for m = 3; 4; 5 in <ref> [20, 21, 23] </ref>. These results yield upper bounds for (n; m) for m = 3; 4; 5 which are improvements over those provided by Corollary 4.1. We summarize these in the following. Theorem 6 ([20, 21, 23]) For n; m 1, (i) (n; 3) 2 n =4 2 bn=2c =2: (n; <p> 2 n =4 2 bn=2c =2: (n; 4) 2 n =5 (2=5)L n n odd 2 n =5 (1=5)L n+1 n even where L n , the nth Lucas number, is [(1 + p p (iii) ae 2 n =6 3 bn=2c =3 + 1=3 n even : 2 Johnson <ref> [21] </ref> suggested that the bound C fl (n; m) given by Theorem 4 may be sharp, and formally conjectured equality in the case m = 4. However, for any fixed m &gt; 2, equality between (n; m) and C fl (n; m) cannot hold for all n m.
Reference: [22] <author> K. Johnson. Buds, </author> <title> stems and fault-tolerance in hypercubes. </title> <type> Preprint, </type> <institution> University of New Mexico, </institution> <month> 6 April </month> <year> 1988. </year>
Reference-contexts: Thus, the Johnson and Entringer result determines (n; 2). In [20, 21, 23], Johnson has considered f (n; m) and obtained bounds for the cases m = 3; 4; 5, and in <ref> [22] </ref> has evaluated g (5; 2). Responding to a related question of Erdos [9] (see Section 3.4), F. <p> Selecting a = b (n 1 m)=2c results in the removal of levels as far from the center level (s) as possible. A straightforward term-by-term comparison shows the optimality of this value of a. 2 While many authors <ref> [3, 7, 20, 21, 22, 24] </ref> utilize the approach of the theorem just proved, most choose to express their result in the following simpler but weaker form. Corollary 4.1 For n m 1, (n; m) m + 1 Proof. <p> Its proof is an extension and generalization of an argument used by Johnson <ref> [22] </ref>, who proved that g (5; 2) 56.
Reference: [23] <author> K. Johnson, J. Mc Canna, and R. Grassl. </author> <title> Pascalian Rectangles Modulo m. </title> <type> Preprint, </type> <institution> University of New Mexico, </institution> <month> 30 May, </month> <year> 1989. </year>
Reference-contexts: Notice that f (n; m) = 2 n (n; m) and g (n; m) = n2 n1 (n; m). Thus, the Johnson and Entringer result determines (n; 2). In <ref> [20, 21, 23] </ref>, Johnson has considered f (n; m) and obtained bounds for the cases m = 3; 4; 5, and in [22] has evaluated g (5; 2). Responding to a related question of Erdos [9] (see Section 3.4), F. <p> In [21, 28] it was noted that, for fixed m, C fl (n; m) satisfies a recursive equation, and this was later solved for m = 3; 4; 5 in <ref> [20, 21, 23] </ref>. These results yield upper bounds for (n; m) for m = 3; 4; 5 which are improvements over those provided by Corollary 4.1. We summarize these in the following. Theorem 6 ([20, 21, 23]) For n; m 1, (i) (n; 3) 2 n =4 2 bn=2c =2: (n;
Reference: [24] <author> K. Johnson and R. Entringer. </author> <title> Largest induced subgraphs of the n-cube that contain no 4-cycles. </title> <journal> J. Combin. Theory Ser. </journal> <note> B 46 (1989) 346-355. </note>
Reference-contexts: Several persons have worked on a problem complementary to determining (n; m). Some time ago, Erdos asked for the maximum size of any set of nodes of Q n for which the induced subgraph contains no 4-cycle. Johnson and Entringer <ref> [24] </ref> found this maximum size and characterized the extremal graphs for this case. Let f (n; m) denote the maximum size of any set of nodes of Q n for which the induced subgraph contains no Q m , and g (n; m) denote the corresponding number for edges. <p> Selecting a = b (n 1 m)=2c results in the removal of levels as far from the center level (s) as possible. A straightforward term-by-term comparison shows the optimality of this value of a. 2 While many authors <ref> [3, 7, 20, 21, 22, 24] </ref> utilize the approach of the theorem just proved, most choose to express their result in the following simpler but weaker form. Corollary 4.1 For n m 1, (n; m) m + 1 Proof. <p> The desired result follows from the identity m X X k = 2 n : 2 The bound given by Theorem 4 in the case k = 2 is sharp according to the results of Johnson and Entringer <ref> [24] </ref>, who used constructive methods to determine f (n; 2), the complement of (n; 2). We state their result in terms of . Theorem 5 ([24]) For n 2, (n; 2) = b2 n =3c: 2 Before further discussion concerning the use of level sets, let us simplify notation by letting
Reference: [25] <author> D. Kleitman. </author> <title> On a problem of Yuzvinsky on separating the n-cube. </title> <journal> Discrete Math. </journal> <month> 60 </month> <year> (1986) </year> <month> 207-213. </month>
Reference-contexts: As a final example along these lines, consider the problem, described in <ref> [25] </ref>, due to Yuzvinski: How many nodes of the n-cube must be removed in order that no connected component of the rest contains an antipodal pair of nodes? Kleitman [25] solved this problem by establishing the more general result that at least n nodes must be removed from Q n if <p> As a final example along these lines, consider the problem, described in <ref> [25] </ref>, due to Yuzvinski: How many nodes of the n-cube must be removed in order that no connected component of the rest contains an antipodal pair of nodes? Kleitman [25] solved this problem by establishing the more general result that at least n nodes must be removed from Q n if no connected component of the remaining graph is to contain more than 2 n1 nodes.
Reference: [26] <author> D. Kleitman and J. Spencer. </author> <title> Families of k-independent sets. </title> <journal> Discrete Math. </journal> <month> 6 </month> <year> (1973) </year> <month> 255-262. </month>
Reference-contexts: In Section 2 we show the direct relationship between k-independent sets and . The earliest published work relevant to evaluating and is apparently that of Schonheim [34], and Brace and Daykin [6], who determined the maximum size of a 2-independent family, and Kleitman and Spencer <ref> [26] </ref>, who considered the general problem of determining the maximum size of families of k-independent sets. <p> In our notation this is (n; n k). They determined (n; n 2), gave a construction for sets in S (n; n 3) of non-optimal size, and used essentially the same probabilistic argument as in <ref> [26] </ref> to obtain an upper bound for (n; n k). Becker and Simon [3], apparently unaware of the work in [7], repeated many of these results for , and used the same methods to establish bounds on . <p> We also give a construction for small sets in S (n; n 3) which yields a new recursive inequality for (n; n 3), producing the best known upper bounds for it with n of any practical size. We make use of the results obtained by Kleitman and Spencer <ref> [26] </ref> for k-independent subsets to establish a new lower bound for (n; m). Many of the techniques of Section 2 are easily modified to give corresponding results for . <p> Theorem 8 ([3, 7]) Let F (r; k) denote the maximum size of a k-independent family of subsets of a set of r elements. Then (n; m) = minfr j F (r; n m) ng: 2 Schonheim [34], Brace and Daykin [6], and Kleitman and Spencer <ref> [26] </ref> determined the maximum size of a family of 2-independent sets. Kleitman and Spencer proved that F (r; 2) = br=2c1 , observing that this maximum is attained by taking all subsets of size br=2c that contain a fixed element of X. <p> Now, in the other direction, Kleitman and Spencer <ref> [26] </ref> used a non-constructive proba bilistic argument to prove that F (r; k) (1=2)(k!) 1=k (2 k =(2 k 1)) r=k : (6) When this inequality is combined with Theorem 8, it is straightforward to show that (n; n k) lg (1 2 k ) This inequality, first established in [7] <p> Moreover, the bounds obtained for fixed n m are not useful for fixed m, and 22 conversely. In this section we describe the best known bounds for each of these cases and mention several open problems concerning the relative sizes of and . Kleitman and Spencer <ref> [26] </ref> used probabilistic methods to determine bounds for the maximum size of families of k-independent sets. Chandra et al. [7] used a probabilistic argument equivalent to that in [26] to prove the following bound on . <p> Kleitman and Spencer <ref> [26] </ref> used probabilistic methods to determine bounds for the maximum size of families of k-independent sets. Chandra et al. [7] used a probabilistic argument equivalent to that in [26] to prove the following bound on . Becker and Simon [3] rediscovered this result, and used similar arguments to establish an upper bound for . These bounds are stated in the following. <p> Unfortunately, finding such sets is a very difficult problem in general. Arguments in <ref> [26] </ref> and [7] show that non-deterministic methods have a high probability of success for n large and n m fixed. Probabilistic arguments similar to those in [26] were used in [3, 7] to prove that, with high probability, a randomly chosen set of (ln 2)(n m)2 nm lg n nodes of <p> Unfortunately, finding such sets is a very difficult problem in general. Arguments in <ref> [26] </ref> and [7] show that non-deterministic methods have a high probability of success for n large and n m fixed. Probabilistic arguments similar to those in [26] were used in [3, 7] to prove that, with high probability, a randomly chosen set of (ln 2)(n m)2 nm lg n nodes of Q n is in 25 S (n; m). <p> In the generalized problem considered above, asking for the minimum number of copies of H whose removal from G destroys P is appropriate in an adversarial situation, in certain resource allocation problems [28], in designing efficient tests [27], or in constructing k-independent sets <ref> [26] </ref>. However, suppose each copy of H to be removed is selected uniformly and at random from the set of all copies of H in G.
Reference: [27] <author> L. Levitin and M. Karpovsky. </author> <title> Efficient exhaustive tests based on MDS codes. </title> <institution> Boston Univ. Tech. Rept. </institution> <year> (1986). </year> <month> 29 </month>
Reference-contexts: They also gave a construction, based on the work of Friedman [12], which yields an upper bound for (n; n k) that has the correct growth behavior for fixed n k. In <ref> [27] </ref>, Levitin and Karpovsky considered the problem of exhaustive testing of combinational devices with n inputs, where each output is a boolean function of at most k binary input variables. They used MDS codes to construct sets in S (n; m), although the sets were not of optimal size. <p> 3 1 Table 2: Values of (n; m) 6 Constructions The construction of fault sets that are of nearly minimum size is of interest to saboteurs, to computer architects solving resource allocation problems such as those described in [28], and to persons needing to construct k-independent sets for testing purposes <ref> [27] </ref>. Unfortunately, finding such sets is a very difficult problem in general. Arguments in [26] and [7] show that non-deterministic methods have a high probability of success for n large and n m fixed. <p> An analogous argument shows that, with high probability, a randomly chosen set of (ln 2)(n m)2 nm ( n m ) lg n edges of Q n is in T (n; m) [3]. Levitin and Karpovsky <ref> [27] </ref> developed constructive methods for a problem equivalent to the study of (n; m). The problem involves the exhaustive testing of devices with n inputs where each output is a Boolean function of at most k binary input variables. <p> In the generalized problem considered above, asking for the minimum number of copies of H whose removal from G destroys P is appropriate in an adversarial situation, in certain resource allocation problems [28], in designing efficient tests <ref> [27] </ref>, or in constructing k-independent sets [26]. However, suppose each copy of H to be removed is selected uniformly and at random from the set of all copies of H in G.
Reference: [28] <author> M. Livingston and Q. F. Stout. </author> <title> Distributing resources in hypercube computers. </title> <booktitle> Proc. Third Conf. on Hypercube Concurrent Computers and Applications (1988) 222-231. </booktitle>
Reference-contexts: The above question arises from problems in resource distribution <ref> [28] </ref> as well. <p> In <ref> [21, 28] </ref> it was noted that, for fixed m, C fl (n; m) satisfies a recursive equation, and this was later solved for m = 3; 4; 5 in [20, 21, 23]. <p> 5 80 24 8 3 1 7 448 142-160 47-62 19-20 7 3 1 Table 2: Values of (n; m) 6 Constructions The construction of fault sets that are of nearly minimum size is of interest to saboteurs, to computer architects solving resource allocation problems such as those described in <ref> [28] </ref>, and to persons needing to construct k-independent sets for testing purposes [27]. Unfortunately, finding such sets is a very difficult problem in general. Arguments in [26] and [7] show that non-deterministic methods have a high probability of success for n large and n m fixed. <p> In the generalized problem considered above, asking for the minimum number of copies of H whose removal from G destroys P is appropriate in an adversarial situation, in certain resource allocation problems <ref> [28] </ref>, in designing efficient tests [27], or in constructing k-independent sets [26]. However, suppose each copy of H to be removed is selected uniformly and at random from the set of all copies of H in G.
Reference: [29] <author> M. Livingston and Q. F. Stout. </author> <title> Fault tolerance of allocation schemes in massively parallel computers. </title> <booktitle> Proc. 2nd Symp. Massively Parallel Computation (1988) 491-494. </booktitle>
Reference-contexts: While the buddy system is the only allocation scheme used on hypercube computers thus far, we see it is not 26 particularly fault-tolerant. For some specific allocation schemes of interest, Livingston and Stout <ref> [29] </ref> determined (A; n; m). For arbitrary allocation scheme A, Becker and Simon [3] showed that the problem of determining (A; n; n 2) is equivalent to a graph-coloring problem. The general problem of determining (A; n; m) and (A; n; m) is open. <p> Some of the properties of E (n; m) and E (n; m) for arbitrary n and m, and of E (A; n; m) and E (A; n; m) for certain allocation schemes A, are studied in <ref> [29, 30] </ref>. A related but somewhat different situation arises if we are only concerned that, with high probability, G fails to have property P .
Reference: [30] <author> M. Livingston and Q. F. Stout. </author> <title> Expected fault-tolerance of hypercubes. </title> <note> (In preparation) </note>
Reference-contexts: Some of the properties of E (n; m) and E (n; m) for arbitrary n and m, and of E (A; n; m) and E (A; n; m) for certain allocation schemes A, are studied in <ref> [29, 30] </ref>. A related but somewhat different situation arises if we are only concerned that, with high probability, G fails to have property P . <p> Najjar and Gaudiot [31], investigating the reliability of the hypercube network in the presence of node faults, used Monte-Carlo simulation to estimate P 0 (Q n ; p) for small n. In <ref> [30] </ref>, an analog of the above results for P 1 (Q n ; p) is proved for P 0 (Q n ; p), namely lim P 0 (Q n ; p) = &lt; 1 if p &lt; 1=2; 0 otherwise.
Reference: [31] <author> W. Najjar and J.-L. Gaudiot. </author> <title> Reliability and performance modeling of hypercube-based multiprocessors. </title> <booktitle> 2nd Int. Wkshp. on Applied Math. and Performance/Reliability Models of Computer/Communication Systems, </booktitle> <institution> Univ. of Rome II (1987) 305-319. </institution>
Reference-contexts: Najjar and Gaudiot <ref> [31] </ref>, investigating the reliability of the hypercube network in the presence of node faults, used Monte-Carlo simulation to estimate P 0 (Q n ; p) for small n.
Reference: [32] <institution> NCUBE handbook, Version 1.0 (1986) NCUBE Corp., Beaverton, </institution> <address> OR. </address>
Reference-contexts: Most allocation schemes use some variant of the "buddy system" allocating only m-cubes of the form a 1 : : : a nm fl : : : fl <ref> [32] </ref>. Under a given allocation scheme A, let AQ n denote the set of all subcubes of Q n that are recognized by A.
Reference: [33] <author> D. A. Rennels. </author> <title> On implementing fault-tolerance in binary hypercubes. </title> <booktitle> Proc. 16th Symp. Fault-Tolerant Comp. </booktitle> <year> (1986) </year> <month> 344-349. </month>
Reference-contexts: Two basic graph-theoretic approaches are to provide additional edges and/or nodes, or to weaken the notion of a subcube. In the former, hardware is added so that the system still has a Q n as a subsystem after a fault occurs <ref> [8, 33, 36] </ref>. This approach must be taken at the time of hardware design, and can tolerate relatively few faults without inordinate expense.
Reference: [34] <author> J. Schonheim. </author> <title> A generalization of results of P. </title> <editor> Erdos, G. Katona, and D. J. </editor> <title> Kleitman concerning Sperner's theorem. </title> <journal> J. Combin. Theory Ser. </journal> <note> A 11 (1971) 111-117. </note>
Reference-contexts: In Section 2 we show the direct relationship between k-independent sets and . The earliest published work relevant to evaluating and is apparently that of Schonheim <ref> [34] </ref>, and Brace and Daykin [6], who determined the maximum size of a 2-independent family, and Kleitman and Spencer [26], who considered the general problem of determining the maximum size of families of k-independent sets. <p> Theorem 8 ([3, 7]) Let F (r; k) denote the maximum size of a k-independent family of subsets of a set of r elements. Then (n; m) = minfr j F (r; n m) ng: 2 Schonheim <ref> [34] </ref>, Brace and Daykin [6], and Kleitman and Spencer [26] determined the maximum size of a family of 2-independent sets.
Reference: [35] <author> J. S. Squire and S. M. Palais. </author> <title> Programming and design considerations for a highly parallel computer. </title> <booktitle> AFIPS Conf. Proc. </booktitle> <month> 23 </month> <year> (1963) </year> <month> 395-400. </month>
Reference-contexts: Each node of the cube is associated with a processor P while each edge (P i ; P j ) of the cube represents the direct communication link between processors P i and P j . Hypercube computers have been studied since 1962 <ref> [35] </ref> and have recently become the focus of intense commercial and research activity [15, 16, 17, 18, 19]. One of the attractive features of the n-cube topology is its behavior in the presence of faulty processors or links.
Reference: [36] <author> R. M. Yanney. </author> <title> Fault recovery in multiprocessor networks. </title> <type> PhD thesis, </type> <institution> Univ. Southern California, </institution> <year> 1982. </year> <month> 30 </month>
Reference-contexts: Two basic graph-theoretic approaches are to provide additional edges and/or nodes, or to weaken the notion of a subcube. In the former, hardware is added so that the system still has a Q n as a subsystem after a fault occurs <ref> [8, 33, 36] </ref>. This approach must be taken at the time of hardware design, and can tolerate relatively few faults without inordinate expense.
References-found: 36

