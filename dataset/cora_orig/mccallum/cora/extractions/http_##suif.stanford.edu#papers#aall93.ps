URL: http://suif.stanford.edu/papers/aall93.ps
Refering-URL: http://suif.stanford.edu/papers/papers.html
Root-URL: 
Title: An Overview of a Compiler for Scalable Parallel Machines  
Author: Saman P. Amarasinghe, Jennifer M. Anderson, Monica S. Lam and Amy W. Lim 
Address: CA 94305  
Affiliation: Computer Systems Laboratory Stanford University,  
Abstract: This paper presents an overview of a parallelizing compiler to automatically generate efficient code for large-scale parallel architectures from sequential input programs. This research focuses on loop-level parallelism in dense matrix computations. We illustrate the basic techniques the compiler uses by describing the entire compilation process for a simple example. Our compiler is organized into three major phases: analyzing array references, allocating the computation and data to the processors to optimize parallelism and locality, and generating code. An optimizing compiler for scalable parallel machines requires more sophisticated program analysis than the traditional data dependence analysis. Our compiler uses a precise data-flow analysis technique to identify the producer of the value read by each instance of a read access. In order to allocate the computation and data to the processors, the compiler first transforms the program to expose loop-level parallelism in the computation. It then finds a decomposition of the computation and data such that parallelism is exploited and the communication overhead is minimized. The compiler will trade off extra degrees of parallelism to reduce or eliminate communication. Finally, the compiler generates code to manage the multiple address spaces and to communicate data across processors.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S. P. Amarasinghe and M. S. Lam. </author> <title> Communication optimization and code gen-eration for distributed memory machines. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: We explain the steps taken in the compiler by showing how they operate on a simple example. We assume that readers are familiar with the literature on parallelizing compilers. Details and related work on individual algorithms can be found in our other papers <ref> [1, 2, 14, 18, 19] </ref>. An optimizing compiler for scalable parallel machines needs more sophisticated program analysis than the traditional data dependence analysis. Exact array data-flow analysis determines if two dynamic instances of an array access refer to the same value, and not just to the same location. <p> The compiler uses data dependence analysis to perform communication optimizations such as message aggregation. If data-flow information is available, our communication generation algorithm uses the given data decompositions only as boundary conditions for the region <ref> [1] </ref>. This allows for more flexible data decompositions within a region including data replication and data migration across different processors. Com- munication within the region is captured by all the non? contexts in the LWT generated by our data-flow analysis algorithm. <p> This structure facilitates optimizations such as message aggregation and hiding the latency of communication with communication. 4.2 Communication Code Generation We have developed a uniform mathematical framework to solve the problems of communication code generation <ref> [1] </ref>. We represent data decompositions, computation decompositions and the array access information all as systems of linear inequalities. For the ADI example from Figure 3, the earlier compiler phase decides to block the second dimension of both arrays X and Y (Section 3.3). <p> We also represent a set of communication by a system of linear inequalities. We derive the receiving and sending code for each communication set by projecting the polyhedra represented by the system of linear inequalities onto lower-dimensional spaces in different orders <ref> [1] </ref>. if p 0 and p bN=bc then for i 1 := 0 to bN=bc do X [i 1 ; i 2 ] := f (X [i 1 ; i 2 ]; X [i 1 ; i 2 1]); (a) Computation loop nest. if p s 0 and p s bN=bc <p> These optimizations include eliminating redundant messages, aggregating messages, and hiding communication latency by overlapping the communication and computation. The data-flow information enables the compiler to perform these optimizations more aggressively than would otherwise be possible using data dependence information <ref> [1] </ref>. The compiler uses the LWT information to eliminate redundant data transfers. While accessing the same location may require multiple data transfers since the value at the location may or may not have changed, each value needs to be transferred once and only once. <p> Each of these components specify the actions to be performed in a subset of the source iterations. The 16 final step is thus to merge these components together so that the operations are performed at the correct time <ref> [1] </ref>. The final SPMD program for our ADI example is given in Figure 9. 5 Conclusion In this paper, we showed how the complex problem of compiling for distributed memory machines can be divided into several well-defined subproblems: array data flow analysis, data and computation decomposition and code generation.
Reference: 2. <author> J. M. Anderson and M. S. Lam. </author> <title> Global optimizations for parallelism and locality on scalable parallel machines. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: We explain the steps taken in the compiler by showing how they operate on a simple example. We assume that readers are familiar with the literature on parallelizing compilers. Details and related work on individual algorithms can be found in our other papers <ref> [1, 2, 14, 18, 19] </ref>. An optimizing compiler for scalable parallel machines needs more sophisticated program analysis than the traditional data dependence analysis. Exact array data-flow analysis determines if two dynamic instances of an array access refer to the same value, and not just to the same location. <p> We use this observation to reduce the complexity of finding the decomposition functions. Our approach is to first solve for the data and computation that are mapped onto the same processor. A simple calculation can then be used to find an assignment of data and computation to specific processors <ref> [2] </ref>. The data decompositions ffi (a) = Da + d and computation decompositions fl (i) = Ci + c have two components. The linear transformation matrices D and 10 C describe the mapping between the axes of the array elements and loop itera-tions, and the processors. <p> Letting f xj (i) = F xj (i) + k xj , D x F xj (i) = C j (i) (2) Algorithm Overview. This section presents a brief overview of the decomposition algorithms we have developed. The details of the algorithms can be found in a related paper <ref> [2] </ref>. Each loop nest has been transformed into canonical form to expose the maximum degree of coarse-grain parallelism. The loop nests with parallelism may be nested within outer sequential loops. The outer sequential loops are considered in order from innermost to outermost. <p> If it cannot eliminate communication while still maintaining at least one degree of parallelism, then communication is necessary. Finding decompositions that minimize communication while allowing at least one degree of parallelism is NP-hard <ref> [2] </ref>. We thus use a greedy algorithm to eliminate the largest amounts of potential communication first. To model the potential communication in a program, the compiler uses a communication graph. <p> If there exist non-trivial decompositions that do not require any communication beyond the displacement level, our algorithm is optimal in that it will find the decomposition with the maximum degree of parallelism <ref> [2] </ref>. Once the algorithm finds the decompositions for a single instance of the current enclosing sequential loop, it then finds decompositions for all instances of that outer loop using the same greedy strategy. Consider the ADI example from Figure 3.
Reference: 3. <author> B. Chapman, P. Mehrotra, and H. Zima. </author> <title> Programming in Vienna Fortran. </title> <journal> Scientific Programming, </journal> <volume> 1(1) </volume> <pages> 31-50, </pages> <month> Fall </month> <year> 1992. </year>
Reference-contexts: 1 Introduction A number of compiler systems, such as SUPERB [21], AL [17], ID Noveau [15], Kali [11], Vienna FORTRAN <ref> [3] </ref>, FORTRAN D [8, 16] and HPF [7], have been developed to make effective use of scalable parallel machines. <p> That is, data dependence checks if any of the dynamic instances of two array accesses in a loop nest refers to the same location. Consider the following example: for j := 3 to N do Data dependence analysis of this program will produce the dependence vectors f <ref> [+; 3] </ref>; [0; 3]g, meaning that the read access in iteration [i r ; j r ] may be data dependent on all iterations [i w ; j w ] such that j w = j r 3 and i w i r . <p> That is, data dependence checks if any of the dynamic instances of two array accesses in a loop nest refers to the same location. Consider the following example: for j := 3 to N do Data dependence analysis of this program will produce the dependence vectors f [+; 3]; <ref> [0; 3] </ref>g, meaning that the read access in iteration [i r ; j r ] may be data dependent on all iterations [i w ; j w ] such that j w = j r 3 and i w i r .
Reference: 4. <author> P. Feautrier. </author> <title> Parametric integer programming. </title> <type> Technical Report 209, </type> <institution> Laboratoire Methodologie and Architecture Des Systemes Informatiques, </institution> <month> January </month> <year> 1988. </year>
Reference-contexts: This information is found for every dynamic read-write access pair. Thus, exact data- flow analysis does not have the inaccuracies of the traditional data dependence analysis. 3 The problem of finding exact array data-flow information was first formu-lated by Feautrier <ref> [4, 5, 6] </ref>. Feautrier proposed a parametric integer programming algorithm that can find such exact information in the domain of loop nests where the loop bounds and array indices are affine functions of loop indices.
Reference: 5. <author> Paul Feautrier. </author> <title> Array expansion. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <pages> pages 429-442, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: This information is found for every dynamic read-write access pair. Thus, exact data- flow analysis does not have the inaccuracies of the traditional data dependence analysis. 3 The problem of finding exact array data-flow information was first formu-lated by Feautrier <ref> [4, 5, 6] </ref>. Feautrier proposed a parametric integer programming algorithm that can find such exact information in the domain of loop nests where the loop bounds and array indices are affine functions of loop indices.
Reference: 6. <author> Paul Feautrier. </author> <title> Dataflow analysis of scalar and array references. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 20(1) </volume> <pages> 23-53, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: This information is found for every dynamic read-write access pair. Thus, exact data- flow analysis does not have the inaccuracies of the traditional data dependence analysis. 3 The problem of finding exact array data-flow information was first formu-lated by Feautrier <ref> [4, 5, 6] </ref>. Feautrier proposed a parametric integer programming algorithm that can find such exact information in the domain of loop nests where the loop bounds and array indices are affine functions of loop indices.
Reference: 7. <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification, </title> <month> January </month> <year> 1993. </year> <note> Draft Version 1.0. </note>
Reference-contexts: 1 Introduction A number of compiler systems, such as SUPERB [21], AL [17], ID Noveau [15], Kali [11], Vienna FORTRAN [3], FORTRAN D [8, 16] and HPF <ref> [7] </ref>, have been developed to make effective use of scalable parallel machines. <p> This two-step model is able to capture a wide range of computation and data assignments. For example, our model represents a superset of the decompositions available to HPF <ref> [7] </ref> programmers. Virtual Processor Mapping. The objective of the virtual processor mapping phase is to minimize communication while maintaining sufficient parallelism. This phase eliminates communication in two ways.
Reference: 8. <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Compiling Fortran D for MIMD distributed-memory machines. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: 1 Introduction A number of compiler systems, such as SUPERB [21], AL [17], ID Noveau [15], Kali [11], Vienna FORTRAN [3], FORTRAN D <ref> [8, 16] </ref> and HPF [7], have been developed to make effective use of scalable parallel machines.
Reference: 9. <institution> Intel Corporation, </institution> <address> Santa Clara, CA. </address> <note> iPSC/2 and iPSC/860 User's Guide, </note> <month> June </month> <year> 1990. </year>
Reference-contexts: We are currently developing a compiler to automatically translate sequential scientific programs into efficient parallel code. Our compilation techniques are applicable to all machines with non-uniform memory access times. Our target machines include both distributed address space machines such as the Intel iPSC/860 <ref> [9] </ref>, and shared address space machines such as the Stanford DASH multiprocessor [12]. Our research focuses on dense matrix computations written in sequential FORTRAN-77, though many of the techniques presented are also applicable to optimizations within and especially across FORTRAN-90 statements.
Reference: 10. <author> F. Irigoin and R. Triolet. </author> <title> Supernode partitioning. </title> <booktitle> In Proceedings of the SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 319329, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: Choices of Parallelism. Our algorithm for maximizing loop-level parallelism is based on the concept of fully permutable loop nests. A loop nest is fully permutable if any arbitrary permutation of the loops within the nest is legal <ref> [10, 19] </ref>. Fully permutable loop nests can be easily transformed to contain coarse- grain parallelism. In particular, every fully permutable loop nest of depth k has at least k 1 degrees of parallelism.
Reference: 11. <author> C. Koelbel, P. Mehrotra, and J. Van Rosendale. </author> <title> Supporting shared data struc-tures on distributed memory architectures. </title> <booktitle> In Proceedings of the Second ACM/SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 177-186, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: 1 Introduction A number of compiler systems, such as SUPERB [21], AL [17], ID Noveau [15], Kali <ref> [11] </ref>, Vienna FORTRAN [3], FORTRAN D [8, 16] and HPF [7], have been developed to make effective use of scalable parallel machines.
Reference: 12. <author> D. Lenoski, K. Gharachorloo, J. Laudon, A. Gupta, J. Hennessy, M. Horowitz, and M. Lam. </author> <title> The Stanford DASH Multiprocessor. </title> <journal> IEEE Computer, </journal> <volume> 25(3) </volume> <pages> 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Our compilation techniques are applicable to all machines with non-uniform memory access times. Our target machines include both distributed address space machines such as the Intel iPSC/860 [9], and shared address space machines such as the Stanford DASH multiprocessor <ref> [12] </ref>. Our research focuses on dense matrix computations written in sequential FORTRAN-77, though many of the techniques presented are also applicable to optimizations within and especially across FORTRAN-90 statements. Our techniques are applicable to programs with arbitrary nestings of parallel and sequential loops.
Reference: 13. <author> D. E. Maydan. </author> <title> Accurate Analysis of Array References. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> September </month> <year> 1992. </year> <note> Published as CSL-TR-92-547. </note>
Reference: 14. <author> D. E. Maydan, S. P. Amarasinghe, and M. S. Lam. </author> <title> Array data flow analysis and its use in array privatization. </title> <booktitle> In Proc. 20th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1993. </year>
Reference-contexts: We explain the steps taken in the compiler by showing how they operate on a simple example. We assume that readers are familiar with the literature on parallelizing compilers. Details and related work on individual algorithms can be found in our other papers <ref> [1, 2, 14, 18, 19] </ref>. An optimizing compiler for scalable parallel machines needs more sophisticated program analysis than the traditional data dependence analysis. Exact array data-flow analysis determines if two dynamic instances of an array access refer to the same value, and not just to the same location. <p> Fig. 2. The Last Write Tree for the read access X [i 1 1, i 2 ] with respect to the write access X [i 1 , i 2 ] in loop nest 1. We have developed an array privatization algorithm based on the LWT analysis <ref> [14] </ref>. The algorithm first parallelizes the loops by considering only the data-flow dependence constraints. If the parallelized loop carries any anti or output dependences, privatization is necessary. On machines with a shared address space, the compiler needs to create a private copy of the data for every processor.
Reference: 15. <author> A. Rogers and K. Pingali. </author> <title> Compiling for locality. </title> <booktitle> In Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <pages> pages 142-146, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: 1 Introduction A number of compiler systems, such as SUPERB [21], AL [17], ID Noveau <ref> [15] </ref>, Kali [11], Vienna FORTRAN [3], FORTRAN D [8, 16] and HPF [7], have been developed to make effective use of scalable parallel machines.
Reference: 16. <author> C.-W. Tseng. </author> <title> An Optimizing Fortran D Compiler for MIMD Distributed-Memory Machines. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> January </month> <year> 1993. </year> <note> Published as Rice COMP TR93-199. </note>
Reference-contexts: 1 Introduction A number of compiler systems, such as SUPERB [21], AL [17], ID Noveau [15], Kali [11], Vienna FORTRAN [3], FORTRAN D <ref> [8, 16] </ref> and HPF [7], have been developed to make effective use of scalable parallel machines. <p> Massive data movements between regions can be optimized by mapping them to hand-tuned collective communication routines. If data-flow information is not available, we plan to use an algorithm similar to that used in FORTRAN D to generate communication <ref> [16] </ref>. In our case, however, both the computation and data decomposition are specified by our compiler. Communication is necessary whenever the processor executing an operation does not own the data used. The compiler uses data dependence analysis to perform communication optimizations such as message aggregation.
Reference: 17. <author> P.-S. Tseng. </author> <title> A Parallelizing Compiler for Distributed Memory Parallel Computers. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1989. </year> <note> Published as CMU-CS-89-148. </note>
Reference-contexts: 1 Introduction A number of compiler systems, such as SUPERB [21], AL <ref> [17] </ref>, ID Noveau [15], Kali [11], Vienna FORTRAN [3], FORTRAN D [8, 16] and HPF [7], have been developed to make effective use of scalable parallel machines.
Reference: 18. <author> M. E. Wolf and M. S. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 30-44, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: We explain the steps taken in the compiler by showing how they operate on a simple example. We assume that readers are familiar with the literature on parallelizing compilers. Details and related work on individual algorithms can be found in our other papers <ref> [1, 2, 14, 18, 19] </ref>. An optimizing compiler for scalable parallel machines needs more sophisticated program analysis than the traditional data dependence analysis. Exact array data-flow analysis determines if two dynamic instances of an array access refer to the same value, and not just to the same location. <p> This is achieved by transforming the code to maximize the coarsest granularity of parallelism. The next step is to optimize for the memory hierarchies in a single processor, such as caches and registers. We have developed a data locality optimizing algorithm within our unified loop transformation framework <ref> [18] </ref>. We apply this uniprocessor algorithm to the subnest consisting of the distributed parallel loops and their inner loops. The original loop structure differs from this subnest by having additional sequential loops outside the parallel loops.
Reference: 19. <author> M. E. Wolf and M. S. Lam. </author> <title> A loop transformation theory and an algorithm to maximize parallelism. </title> <journal> Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4):452470, </volume> <month> October </month> <year> 1991. </year>
Reference-contexts: We explain the steps taken in the compiler by showing how they operate on a simple example. We assume that readers are familiar with the literature on parallelizing compilers. Details and related work on individual algorithms can be found in our other papers <ref> [1, 2, 14, 18, 19] </ref>. An optimizing compiler for scalable parallel machines needs more sophisticated program analysis than the traditional data dependence analysis. Exact array data-flow analysis determines if two dynamic instances of an array access refer to the same value, and not just to the same location. <p> Choices of Parallelism. Our algorithm for maximizing loop-level parallelism is based on the concept of fully permutable loop nests. A loop nest is fully permutable if any arbitrary permutation of the loops within the nest is legal <ref> [10, 19] </ref>. Fully permutable loop nests can be easily transformed to contain coarse- grain parallelism. In particular, every fully permutable loop nest of depth k has at least k 1 degrees of parallelism.
Reference: 20. <author> M. J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference: 21. <author> H. P. Zima, H.-J. Bast, and M. Gerndt. </author> <title> SUPERB: A tool for semi-automatic MIMD / SIMD parallelization. </title> <journal> Parallel Computing, </journal> <volume> 6(1) </volume> <pages> 1-18, </pages> <month> January </month> <year> 1988. </year> <title> This article was processed using the L a T E X macro package with LLNCS style 20 </title>
Reference-contexts: 1 Introduction A number of compiler systems, such as SUPERB <ref> [21] </ref>, AL [17], ID Noveau [15], Kali [11], Vienna FORTRAN [3], FORTRAN D [8, 16] and HPF [7], have been developed to make effective use of scalable parallel machines.
References-found: 21

