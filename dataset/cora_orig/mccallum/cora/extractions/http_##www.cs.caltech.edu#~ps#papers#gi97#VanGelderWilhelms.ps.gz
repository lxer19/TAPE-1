URL: http://www.cs.caltech.edu/~ps/papers/gi97/VanGelderWilhelms.ps.gz
Refering-URL: http://www.cs.caltech.edu/~ps/papers/gi97/
Root-URL: http://www.cs.caltech.edu
Email: E-mail: avg@cse.ucsc.edu, wilhelms@cse.ucsc.edu  
Title: An Interactive Fur Modeling Technique  
Author: Allen Van Gelder and Jane Wilhelms 
Keyword: Computer graphics, computer animation, modeling, natural phenomena, animals, fur, hair.  
Address: Santa Cruz, U.S.A. 95064  
Affiliation: Computer Science Department University of California,  
Abstract: A technique for modeling fur, but not long human hair, quickly using the facilities of common graphics workstations is described. The user selects a variety of parameters to achieve the desired appearance for a particular animal, such as hair density, length, stiffness, and color properties. Undercoat and overcoat may have separate specifications, and degrees of randomness may be specified, for added realism. Standard GL facilities are used for modeling, lighting, and rendering. Hair density is automatically adjusted for viewing distance to compensate for the limit of single pixel resolution, thus avoiding the tendency to melt into a surface of uniform appearance. Gravitational effects are approximated. Four drawing methods are compared: single line, polyline, nurbs curve, and nurbs surface. The polyline method is judged to offer reasonable realism at substantially faster rendering rates than previously reported hair techniques. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ando and S. Morishima. </author> <title> Expression and motion control of hair using fast collision detection. </title> <editor> In R. Chin et al., editor, </editor> <booktitle> Image Analysis Applications and Computer Graphics, </booktitle> <pages> pages 46370, </pages> <address> Hong Kong, </address> <month> December </month> <year> 1995. </year> <note> Springer-Verlag. </note>
Reference-contexts: We are able to report that rather simple techniques, using the facilities of common graphics workstations, can produce reasonably realistic fur in interactive time frames. 2 Background Two different techniques for modeling hair and fur have been described in the literature. The first technique models individual hair primitives <ref> [1, 2, 3, 6, 7, 10, 11, 12, 13, 15] </ref>. The second technique simulates the interaction of light with hair using three-dimensional textures [4, 5, 8, 9, 14]. Three-dimensional textures can generate many complex phenomena, including fur. <p> Hairs are modeled as a curved chain of straight cylinders. Their human hair style typically has 100,000 1 Method Hairs/sec. Equipment [13] 5 DEC Vax [15] 421 SGI 4D/210GTX [12] 333 unspecified SGI <ref> [1] </ref> 750 85 MIPS workstation this paper 15,000 150MHz SGI RE-II to 150,000 hairs. They also use a wisp model to reduce calculations. They use a shadow-buffer technique in ray-tracing the hair. They do not indicate how long their impressive ray-traced rendering of a synthetic actress' head takes. <p> In their model, collision detection can be performed, and hair blowing in the wind can be simulated. Ando and Morishima discuss a relatively fast method of simulating human hair, including collision detection <ref> [1] </ref>. They also use a wisp technique and model a single hair which is duplicated hundreds of times in the neighborhood. Rankin and Hall modeled long pony-tail hairs and render in software [10]. They use a polyline technique, and do not give any rendering times. <p> Those hairs allocated to a triangle are distributed over the surface at random, according to a 2D uniform distribution. To generate points according to such a distribution, barycentric coordinates are used. Let u 1 and u 2 be independent uniform random numbers on <ref> [0; 1] </ref>. The first barycentric coordinate, b 1 , is generated from a triangular distribution on [0; 1:0] with the peak at 0. The second barycentric coordinate, b 2 , is generated from a uniform distribution on [0; 1:0 b 1 ]. The third makes the sum equal 1.0.
Reference: [2] <author> Ken-ichi Anjyo, Yoshiakai Usami, and Tsuneya Kurihara. </author> <title> A simple method for extracting the natural beauty of hair. </title> <booktitle> Computer Graphics (ACM SIG-GRAPH Proceedings), </booktitle> <address> 26(2):111120, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: We are able to report that rather simple techniques, using the facilities of common graphics workstations, can produce reasonably realistic fur in interactive time frames. 2 Background Two different techniques for modeling hair and fur have been described in the literature. The first technique models individual hair primitives <ref> [1, 2, 3, 6, 7, 10, 11, 12, 13, 15] </ref>. The second technique simulates the interaction of light with hair using three-dimensional textures [4, 5, 8, 9, 14]. Three-dimensional textures can generate many complex phenomena, including fur. <p> Though results looked quite good, it was too slow for interactive purposes. Rosenblum et al. used a similarly expensive physical model of individual hairs involving mass-spring chains [11]. Anjyo et al.. model human hair as polylines representing a chain of sticks, which is bent using a cantilever beam model <ref> [2] </ref>. Watanabe and Suenaga use a chain of trigonal prisms to approximate cylinders [15]. To avoid expensive calculations on each hair, they modeled a small proportion of the hairs carefully and used a wisp model to generated more hairs from these. <p> They use a shadow-buffer technique in ray-tracing the hair. They do not indicate how long their impressive ray-traced rendering of a synthetic actress' head takes. Shih and Guo [12] model human hair using the cantilever beam model suggested by Anjyo et al. <ref> [2] </ref>. Hairs are modeled as polylines, also. They point out that a human head has between 80,000 and 120,000 strands of hair, varying in width from 0.05 mm to 0.09 mm. In their model, collision detection can be performed, and hair blowing in the wind can be simulated.
Reference: [3] <author> A. Daldegan, N. M. Thalmann, T. Kurihara, and D. Thalmann. </author> <title> An interated system for modeling, animating, </title> <booktitle> and rendering hair. In Eurographics '93, </booktitle> <pages> pages 21121, </pages> <address> Barcelona, Spain, </address> <year> 1993. </year>
Reference-contexts: We are able to report that rather simple techniques, using the facilities of common graphics workstations, can produce reasonably realistic fur in interactive time frames. 2 Background Two different techniques for modeling hair and fur have been described in the literature. The first technique models individual hair primitives <ref> [1, 2, 3, 6, 7, 10, 11, 12, 13, 15] </ref>. The second technique simulates the interaction of light with hair using three-dimensional textures [4, 5, 8, 9, 14]. Three-dimensional textures can generate many complex phenomena, including fur. <p> To avoid expensive calculations on each hair, they modeled a small proportion of the hairs carefully and used a wisp model to generated more hairs from these. Daldegan et al. model human hair, including motion and collision detection, and render it using ray tracing <ref> [3] </ref>. Hairs are modeled as a curved chain of straight cylinders. Their human hair style typically has 100,000 1 Method Hairs/sec. Equipment [13] 5 DEC Vax [15] 421 SGI 4D/210GTX [12] 333 unspecified SGI [1] 750 85 MIPS workstation this paper 15,000 150MHz SGI RE-II to 150,000 hairs.
Reference: [4] <author> J.-M. Dischler and D. Ghazanfarpour. </author> <title> A geometrical based method for highly structured texture generation. </title> <journal> Computer Graphics Forum, </journal> <volume> 14(4):20315, </volume> <month> October </month> <year> 1995. </year>
Reference-contexts: The first technique models individual hair primitives [1, 2, 3, 6, 7, 10, 11, 12, 13, 15]. The second technique simulates the interaction of light with hair using three-dimensional textures <ref> [4, 5, 8, 9, 14] </ref>. Three-dimensional textures can generate many complex phenomena, including fur. Using this technique, the Kajiya teddy bear remains one of the most realistic images of simulated fur [5].
Reference: [5] <author> James T. Kajiya. </author> <title> Rendering fur with three dimensional textures. </title> <booktitle> Computer Graphics (ACM SIG-GRAPH Proceedings), </booktitle> <address> 23(3):271280, </address> <month> July </month> <year> 1989. </year>
Reference-contexts: The first technique models individual hair primitives [1, 2, 3, 6, 7, 10, 11, 12, 13, 15]. The second technique simulates the interaction of light with hair using three-dimensional textures <ref> [4, 5, 8, 9, 14] </ref>. Three-dimensional textures can generate many complex phenomena, including fur. Using this technique, the Kajiya teddy bear remains one of the most realistic images of simulated fur [5]. <p> The second technique simulates the interaction of light with hair using three-dimensional textures [4, 5, 8, 9, 14]. Three-dimensional textures can generate many complex phenomena, including fur. Using this technique, the Kajiya teddy bear remains one of the most realistic images of simulated fur <ref> [5] </ref>. However, it is difficult to find the appropriate texture for the desired fur, and rendering is extremely slow. (Rendering times are usually given in hours.) Therefore, for our application, we use the first technique: individual hair primitives.
Reference: [6] <author> N. Magnenat-Thalmann, S. Carion, M. Courch-esne, P. Volino, et al. </author> <title> Virtual clothes, hair and skin for beautiful top models. </title> <booktitle> In Proceedings of Computer Graphics International, </booktitle> <pages> pages 132141, </pages> <address> South Korea, 1996. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: We are able to report that rather simple techniques, using the facilities of common graphics workstations, can produce reasonably realistic fur in interactive time frames. 2 Background Two different techniques for modeling hair and fur have been described in the literature. The first technique models individual hair primitives <ref> [1, 2, 3, 6, 7, 10, 11, 12, 13, 15] </ref>. The second technique simulates the interaction of light with hair using three-dimensional textures [4, 5, 8, 9, 14]. Three-dimensional textures can generate many complex phenomena, including fur.
Reference: [7] <author> Gavin Miller. </author> <title> From wire-frames to furry animals. </title> <booktitle> In Graphics Interface '88, </booktitle> <pages> pages 138145, </pages> <address> Edmon-ton, Alberta, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: We are able to report that rather simple techniques, using the facilities of common graphics workstations, can produce reasonably realistic fur in interactive time frames. 2 Background Two different techniques for modeling hair and fur have been described in the literature. The first technique models individual hair primitives <ref> [1, 2, 3, 6, 7, 10, 11, 12, 13, 15] </ref>. The second technique simulates the interaction of light with hair using three-dimensional textures [4, 5, 8, 9, 14]. Three-dimensional textures can generate many complex phenomena, including fur. <p> Gavin Miller, in one of the earliest papers on modeling fur and other anisotropic materials, used straight line segments oriented according to the skin surface normal and tangent vectors to mimic fur <ref> [7] </ref>. Robert Skinner modeled hair and fur as a sequence of cylinders following a Bezier curve [13]. He implemented a specialized anti-aliasing hair renderer to make this more efficient. Though results looked quite good, it was too slow for interactive purposes.
Reference: [8] <author> F. Neyret. </author> <title> A general and multiscale model for volumetric textures. </title> <editor> In W. Davis and P. Prusinkiewicz, editors, </editor> <booktitle> Proceedings of Graphics Interface '95, </booktitle> <pages> pages 8391, </pages> <address> Toronto, Ontario, Canada, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: The first technique models individual hair primitives [1, 2, 3, 6, 7, 10, 11, 12, 13, 15]. The second technique simulates the interaction of light with hair using three-dimensional textures <ref> [4, 5, 8, 9, 14] </ref>. Three-dimensional textures can generate many complex phenomena, including fur. Using this technique, the Kajiya teddy bear remains one of the most realistic images of simulated fur [5].
Reference: [9] <author> Ken Perlin. Hypertextures. </author> <booktitle> Computer Graphics (ACM Siggraph Proceedings), </booktitle> <address> 23(3):253262, </address> <month> July </month> <year> 1989. </year>
Reference-contexts: The first technique models individual hair primitives [1, 2, 3, 6, 7, 10, 11, 12, 13, 15]. The second technique simulates the interaction of light with hair using three-dimensional textures <ref> [4, 5, 8, 9, 14] </ref>. Three-dimensional textures can generate many complex phenomena, including fur. Using this technique, the Kajiya teddy bear remains one of the most realistic images of simulated fur [5].
Reference: [10] <author> J. Rankin and R. Hall. </author> <title> A simple naturalistic hair model. </title> <journal> Computer Graphics, </journal> <volume> 30(1):59, </volume> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: We are able to report that rather simple techniques, using the facilities of common graphics workstations, can produce reasonably realistic fur in interactive time frames. 2 Background Two different techniques for modeling hair and fur have been described in the literature. The first technique models individual hair primitives <ref> [1, 2, 3, 6, 7, 10, 11, 12, 13, 15] </ref>. The second technique simulates the interaction of light with hair using three-dimensional textures [4, 5, 8, 9, 14]. Three-dimensional textures can generate many complex phenomena, including fur. <p> Ando and Morishima discuss a relatively fast method of simulating human hair, including collision detection [1]. They also use a wisp technique and model a single hair which is duplicated hundreds of times in the neighborhood. Rankin and Hall modeled long pony-tail hairs and render in software <ref> [10] </ref>. They use a polyline technique, and do not give any rendering times. As far as we can tell, given the published information, and the variety of machines used (see Figure 1), the method we describe here is significantly faster than previous methods, even allowing for equipment differences.
Reference: [11] <author> R. E. Rosenblum, W. E. Carlson, and E. T. Tripp. </author> <title> Simulating the structure and dynamics of human hair: Modeling, rendering, and animation. </title> <journal> The Journal of Visualization and Computer Animation, </journal> <volume> 2:141148, </volume> <year> 1991. </year>
Reference-contexts: We are able to report that rather simple techniques, using the facilities of common graphics workstations, can produce reasonably realistic fur in interactive time frames. 2 Background Two different techniques for modeling hair and fur have been described in the literature. The first technique models individual hair primitives <ref> [1, 2, 3, 6, 7, 10, 11, 12, 13, 15] </ref>. The second technique simulates the interaction of light with hair using three-dimensional textures [4, 5, 8, 9, 14]. Three-dimensional textures can generate many complex phenomena, including fur. <p> He implemented a specialized anti-aliasing hair renderer to make this more efficient. Though results looked quite good, it was too slow for interactive purposes. Rosenblum et al. used a similarly expensive physical model of individual hairs involving mass-spring chains <ref> [11] </ref>. Anjyo et al.. model human hair as polylines representing a chain of sticks, which is bent using a cantilever beam model [2]. Watanabe and Suenaga use a chain of trigonal prisms to approximate cylinders [15].
Reference: [12] <author> Zen-Chung Shih and Hurng-Dar Guo. </author> <title> The modeling and animation of human hair. </title> <booktitle> In Pacific Graphics '94, </booktitle> <pages> pages 215228, </pages> <address> Beijing, China, </address> <year> 1994. </year>
Reference-contexts: We are able to report that rather simple techniques, using the facilities of common graphics workstations, can produce reasonably realistic fur in interactive time frames. 2 Background Two different techniques for modeling hair and fur have been described in the literature. The first technique models individual hair primitives <ref> [1, 2, 3, 6, 7, 10, 11, 12, 13, 15] </ref>. The second technique simulates the interaction of light with hair using three-dimensional textures [4, 5, 8, 9, 14]. Three-dimensional textures can generate many complex phenomena, including fur. <p> Daldegan et al. model human hair, including motion and collision detection, and render it using ray tracing [3]. Hairs are modeled as a curved chain of straight cylinders. Their human hair style typically has 100,000 1 Method Hairs/sec. Equipment [13] 5 DEC Vax [15] 421 SGI 4D/210GTX <ref> [12] </ref> 333 unspecified SGI [1] 750 85 MIPS workstation this paper 15,000 150MHz SGI RE-II to 150,000 hairs. They also use a wisp model to reduce calculations. They use a shadow-buffer technique in ray-tracing the hair. <p> They also use a wisp model to reduce calculations. They use a shadow-buffer technique in ray-tracing the hair. They do not indicate how long their impressive ray-traced rendering of a synthetic actress' head takes. Shih and Guo <ref> [12] </ref> model human hair using the cantilever beam model suggested by Anjyo et al. [2]. Hairs are modeled as polylines, also. They point out that a human head has between 80,000 and 120,000 strands of hair, varying in width from 0.05 mm to 0.09 mm.
Reference: [13] <author> Robert Skinner. </author> <title> Modeling hair with structured particle systems. </title> <type> Master's thesis, </type> <institution> University of California, </institution> <address> Santa Cruz, Santa Cruz, CA, </address> <month> June </month> <year> 1989. </year> <month> 6 </month>
Reference-contexts: We are able to report that rather simple techniques, using the facilities of common graphics workstations, can produce reasonably realistic fur in interactive time frames. 2 Background Two different techniques for modeling hair and fur have been described in the literature. The first technique models individual hair primitives <ref> [1, 2, 3, 6, 7, 10, 11, 12, 13, 15] </ref>. The second technique simulates the interaction of light with hair using three-dimensional textures [4, 5, 8, 9, 14]. Three-dimensional textures can generate many complex phenomena, including fur. <p> Gavin Miller, in one of the earliest papers on modeling fur and other anisotropic materials, used straight line segments oriented according to the skin surface normal and tangent vectors to mimic fur [7]. Robert Skinner modeled hair and fur as a sequence of cylinders following a Bezier curve <ref> [13] </ref>. He implemented a specialized anti-aliasing hair renderer to make this more efficient. Though results looked quite good, it was too slow for interactive purposes. Rosenblum et al. used a similarly expensive physical model of individual hairs involving mass-spring chains [11]. <p> Daldegan et al. model human hair, including motion and collision detection, and render it using ray tracing [3]. Hairs are modeled as a curved chain of straight cylinders. Their human hair style typically has 100,000 1 Method Hairs/sec. Equipment <ref> [13] </ref> 5 DEC Vax [15] 421 SGI 4D/210GTX [12] 333 unspecified SGI [1] 750 85 MIPS workstation this paper 15,000 150MHz SGI RE-II to 150,000 hairs. They also use a wisp model to reduce calculations. They use a shadow-buffer technique in ray-tracing the hair.
Reference: [14] <author> John M. Snyder. </author> <title> Generative Modeling for Com--puter Graphics. </title> <publisher> Academic Press, </publisher> <address> Boston, Mass., </address> <year> 1992. </year>
Reference-contexts: The first technique models individual hair primitives [1, 2, 3, 6, 7, 10, 11, 12, 13, 15]. The second technique simulates the interaction of light with hair using three-dimensional textures <ref> [4, 5, 8, 9, 14] </ref>. Three-dimensional textures can generate many complex phenomena, including fur. Using this technique, the Kajiya teddy bear remains one of the most realistic images of simulated fur [5].
Reference: [15] <author> Y. Watanabe and Y. Suenaga. </author> <title> A trigonal prism-based method for hair image generation. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 12(1):47 53, </volume> <month> January </month> <year> 1992. </year>
Reference-contexts: We are able to report that rather simple techniques, using the facilities of common graphics workstations, can produce reasonably realistic fur in interactive time frames. 2 Background Two different techniques for modeling hair and fur have been described in the literature. The first technique models individual hair primitives <ref> [1, 2, 3, 6, 7, 10, 11, 12, 13, 15] </ref>. The second technique simulates the interaction of light with hair using three-dimensional textures [4, 5, 8, 9, 14]. Three-dimensional textures can generate many complex phenomena, including fur. <p> Anjyo et al.. model human hair as polylines representing a chain of sticks, which is bent using a cantilever beam model [2]. Watanabe and Suenaga use a chain of trigonal prisms to approximate cylinders <ref> [15] </ref>. To avoid expensive calculations on each hair, they modeled a small proportion of the hairs carefully and used a wisp model to generated more hairs from these. Daldegan et al. model human hair, including motion and collision detection, and render it using ray tracing [3]. <p> Daldegan et al. model human hair, including motion and collision detection, and render it using ray tracing [3]. Hairs are modeled as a curved chain of straight cylinders. Their human hair style typically has 100,000 1 Method Hairs/sec. Equipment [13] 5 DEC Vax <ref> [15] </ref> 421 SGI 4D/210GTX [12] 333 unspecified SGI [1] 750 85 MIPS workstation this paper 15,000 150MHz SGI RE-II to 150,000 hairs. They also use a wisp model to reduce calculations. They use a shadow-buffer technique in ray-tracing the hair.
Reference: [16] <author> Jane Wilhelms. </author> <title> Animals with anatomy. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 17(3), </volume> <month> May </month> <year> 1997. </year>
Reference-contexts: Because we start at the beginning of the table each time the animal is redrawn, we generate the same hairs each time. Skin motion during animation uses an anatomically based method described elsewhere <ref> [16, 17] </ref>. Each vertex of the skin's triangle mesh is transformed to its present position. Although triangles shift and may change shape as a result, the hairs' locations, being retained in barycentric coordinates, can be efficiently recalculated.

References-found: 16

