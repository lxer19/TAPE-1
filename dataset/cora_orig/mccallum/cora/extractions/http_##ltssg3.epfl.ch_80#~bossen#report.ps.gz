URL: http://ltssg3.epfl.ch:80/~bossen/report.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/ph/index.html
Root-URL: 
Email: Email: bossen@cs.cmu.edu bossen@ltssg7.epfl.ch  
Title: Anisotropic Mesh Generation with Particles  
Author: Frank Bossen 
Note: This document is a revised version of the author's master's thesis (Ingenieur EPF),  
Web: WWW: http://www.cs.cmu.edu/~bossen http://ltswww.epfl.ch/~bossen  
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  Computer Science, Swiss Federal Institute of Technology (EPFL), Lausanne, Switzer  
Date: May 13, 1996  land, March 1996.  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Eric B. Becker, Graham F. Cary, and J. Tinsley Oden. </author> <title> Finite Elements: An Introduction, volume 1. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1981. </year>
Reference-contexts: Introduction Many important real-world problems require meshing, that is the approximation of a given geometry by a set of simpler elements such as triangles or quadrilaterals in two dimensions, and tetrahedra or hexahedra in three dimensions. Applications include finite element analysis <ref> [1] </ref> and computer graphics. Many engineering simulations require the solution of partial differential or integral equations. Since most of these equations cannot be solved analytically, approximations must be used. If the domain has a simple shape, one can use finite difference methods with structured grids. <p> and the cross product p det M (a fi b) (5.3) where a fi b = a 1 b 2 a 2 b 1 is the 2-dimensional cross product. 5.1.1 Computing Distances In Riemannian geometry, the length of a parametric curve (t) between points i and j, where t 2 <ref> [0; 1] </ref>, (0) = x i , and (1) = x j is defined as `() = 0 _ (t) T M ((t)) _ (t) dt (5.4) where _ = d dt . The distance between two points is the length of the shortest parametric curve .
Reference: [2] <author> Marshall Bern and David Eppstein. </author> <title> Mesh generation and optimal triangulation. </title> <type> Technical Report P92-00047, </type> <note> Xerox PARC, </note> <year> 1992. </year>
Reference-contexts: A metric tensor is introduced to quantify the stretching. The triangulation procedure is changed to generate "Delaunay" meshes in the Riemannian space defined by the metric. 1.1 Previous Work There are several surveys available on mesh generation <ref> [2, 15] </ref>. Most of present mesh generation algorithms are structured in the following way. First a mesh is build with methods such as advancing front [19, 21, 23], quadtree decomposition [35], or by greedy point insertion [3, 32].
Reference: [3] <author> M.J. Castro-Diaz, F. Hecht, and B. Mohammadi. </author> <title> New progress in anisotropic grid adaptation for inviscid and viscous flows simulations. </title> <booktitle> In 4th Annual International Meshing Roundtable, </booktitle> <year> 1995. </year>
Reference-contexts: Most of present mesh generation algorithms are structured in the following way. First a mesh is build with methods such as advancing front [19, 21, 23], quadtree decomposition [35], or by greedy point insertion <ref> [3, 32] </ref>. The quality of the mesh is further improved with the use of smoothing. The most common method is Laplacian smoothing [8]. Advancing front methods start meshing at the boundaries of the domain. A list of nodes to be expanded (referred to as the front) is maintained. <p> To obtain a triangular mesh, the squares are further divided into triangles. Greedy insertion methods localize poorly shaped, or poorly sized elements, and split them by inserting a new node on an edge <ref> [3] </ref>, at the center of a triangle [32], or at the center of the circle circumscribing a triangle [25]. Although the Delaunay criterion is the most common, other triangle quality criteria have been used [31] to determine the topology of the mesh. <p> Before that, Peraire [23] was using a similar representation to quantify the desired element size as a function of its position and orientation. Later a metric tensor was introduced <ref> [3, 31] </ref>. The tensor representation has the advantage to be directly related to the Hessian of the function (speed, pressure, etc.) to be estimated [5]. It is thus a more natural representation to create adapted meshes. Quite impressive results have been produced by Castro-Diaz, Hecht, and Mohammadi [3]. <p> The tensor representation has the advantage to be directly related to the Hessian of the function (speed, pressure, etc.) to be estimated [5]. It is thus a more natural representation to create adapted meshes. Quite impressive results have been produced by Castro-Diaz, Hecht, and Mohammadi <ref> [3] </ref>. In their method, which is of the greedy insertion type, edges that are too long are split, and edges that are too short are collapsed. When the desired number of elements is reached, the mesh is further relaxed to improve its quality. <p> Another weakness of his method is poor meshing at boundaries. Peraire et al. [23], and later Mavriplis [22] introduced stretching vectors to quantify the anisotropy, which really are eigenvectors of the metric tensor, but never formally introduced the latter. Greedy insertion algorithms have been proposed by researchers at INRIA <ref> [3, 31] </ref>. We believe that better node positioning can be achieved. This chapter is structured as follows. Section 5.1 introduces some concepts of Rieman-nian geometry. Section 5.2 exposes the changes made to the triangulation procedure due to anisotropy. <p> Otherwise the mesh elements could get arbitrary small or large. It has also been proposed <ref> [3] </ref> to align one of the eigenvectors of the metric matrix with the boundary, when close to one. 5.6.1 Example: a Gaussian function The function we approximate is f (x; y) = exp 2 of which the Hessian is H f = x 2 1 xy The eigenvalues of H f
Reference: [4] <author> L. Paul Chew. </author> <title> Constrained Delaunay triangulations. </title> <journal> Algorithmica, </journal> <volume> 4 </volume> <pages> 97-108, </pages> <year> 1989. </year>
Reference-contexts: The edge swapping algorithm for instance starts with a triangulation where all constrained edges are present, then runs as usual but a constrained edge is never swapped. There are also O (n log n) algorithms for generating constrained Delaunay triangulation such as divide-and-conquer <ref> [4] </ref>, but they are usually difficult to implement. The next section presents an asymptotically slower incremental algorithm which is easier to implement. 2.6.1 An Incremental CDT Algorithm The present algorithm for building constrained Delaunay triangulations can be split in two phases.
Reference: [5] <author> E.F. D'Azevedo. </author> <title> Optimal triangular mesh generation by coordinate transformation. </title> <journal> J. Sci. Stat. Comput., </journal> <volume> 12(4) </volume> <pages> 755-786, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Later a metric tensor was introduced [3, 31]. The tensor representation has the advantage to be directly related to the Hessian of the function (speed, pressure, etc.) to be estimated <ref> [5] </ref>. It is thus a more natural representation to create adapted meshes. Quite impressive results have been produced by Castro-Diaz, Hecht, and Mohammadi [3]. In their method, which is of the greedy insertion type, edges that are too long are split, and edges that are too short are collapsed. <p> A metric tensor is introduced to quantify the stretching of the triangles at every point in the domain. It reflects the curvature of the function that is approximated. Relatively little work has been done on anisotropic meshes. D'Azevedo <ref> [5] </ref> has proposed the use of coordinate transformations to generate optimal triangulations. Although very elegant, his method is limited to metric tensors that represent a flat space (the Riemann-Christoffel tensor [28], that is the curvature of the space represented by the metric, should be zero). <p> It has been shown by D'Azevedo <ref> [5] </ref> that it is better to Delaunay triangulate in a transformed space to minimize errors for function interpolation. Only simple cases (for example when the metric tensor is constant) allow a global map of the domain into a 2-dimensional Euclidean space by coordinate transformation.
Reference: [6] <author> L. Devroye, E.P. Mucke, and B. Zhu. </author> <title> A note on point location in Delaunay triangulations of random points. </title> <note> Submited for publication, </note> <year> 1995. </year>
Reference-contexts: However, without any additional data structure, jump-and-walk methods can be used to reach an expected time of O (n 4=3 ) <ref> [6] </ref>. 2.5 Dynamic Maintenance of a Triangulation The problem of dynamically maintaining the triangulation can be divided into two sub-problems: insertion and removal of a site.
Reference: [7] <author> H. Edelsbrunner and R. Seidel. </author> <title> Voronoi diagrams and arrangements. </title> <journal> Disc. and Comp. Geom., </journal> <volume> 8(1) </volume> <pages> 25-44, </pages> <year> 1986. </year>
Reference-contexts: There is also a nice relationship between Delaunay triangulations and 3-dimensional convex hulls. Lift each point of the input to a paraboloid by mapping the point (x; y) to (x; y; x 2 + y 2 ) 1 . It can be proved <ref> [7] </ref> that the DT of the input points is the projection of the lower convex hull onto the xy-plane. The Delaunay triangulation features other interesting properties. Indeed it maximizes of the minimum angle, minimizes the maximum circumcircle as many other measures. The outline of the chapter is as follows.
Reference: [8] <author> D.A. </author> <title> Field. Laplacian smoothing and Delaunay triangulations. </title> <journal> Comm. Appl. Num. Methods, </journal> <volume> 4 </volume> <pages> 709-712, </pages> <year> 1988. </year>
Reference-contexts: First a mesh is build with methods such as advancing front [19, 21, 23], quadtree decomposition [35], or by greedy point insertion [3, 32]. The quality of the mesh is further improved with the use of smoothing. The most common method is Laplacian smoothing <ref> [8] </ref>. Advancing front methods start meshing at the boundaries of the domain. A list of nodes to be expanded (referred to as the front) is maintained. At each iteration, the front advances by expanding a node, and inserting a new node at the desired distance from the front. <p> Other approximations of the Lennard-Jones potential function are possible, such as (Fi gure 3.6) 0 ( ij ) = (1 ( ij ) 4 ) exp (d ( ij ) 4 ) (3.20) Derivative 0 ( ij ) 3.3.4 Laplacian Smoothing Laplacian smoothing <ref> [8] </ref> is a widely used technique for improving the shape of triangles in a mesh. In particle terminology, Laplacian smoothing consists of moving a particle i to the centroid of its neighbors.
Reference: [9] <author> S. Fortune. </author> <title> A sweepline algorithm for Voronoi diagrams. </title> <journal> Algorithmica, </journal> <volume> 2 </volume> <pages> 153-174, </pages> <year> 1987. </year>
Reference-contexts: The Delaunay triangulation is computed recursively for each subset. Subsets are then merged using a sweeping circle algorithm. A complete description is given in [13]. The time complexity of the algorithm is O (n log n). The sweepline algorithm is due to Fortune <ref> [9] </ref>. In a comparison with divide-and-conquer, Leach [18] has optimized both algorithms and measured execution speed.
Reference: [10] <author> William H. Frey and David A. </author> <title> Field. Mesh relaxation: A new technique for improving triangulations. </title> <journal> International Journal for Numerical Methods in Engineering, </journal> <volume> 31 </volume> <pages> 1121-1133, </pages> <year> 1991. </year>
Reference-contexts: Furthermore the degrees of the nodes, which are often the reason of poorly shaped elements, are not affected. Relaxations methods that combine Laplacian smoothing with local topological optimization have been proposed to remedy to this problem <ref> [10, 11] </ref>. Anisotropic mesh generation has not benefited from an extensive literature. One of the major fields of application for anisotropic meshes is computational fluid dynamics (CFD), where stretched triangles oriented in the direction of the flow are desirable.
Reference: [11] <author> N.A. Golias and T.D. Tsiboukis. </author> <title> An approach to refining three-dimensional tetrahedral meshes based on delaunay transformations. </title> <journal> International Journal for Numerical Methods in Engineering, </journal> <volume> 37 </volume> <pages> 793-812, </pages> <year> 1994. </year>
Reference-contexts: Furthermore the degrees of the nodes, which are often the reason of poorly shaped elements, are not affected. Relaxations methods that combine Laplacian smoothing with local topological optimization have been proposed to remedy to this problem <ref> [10, 11] </ref>. Anisotropic mesh generation has not benefited from an extensive literature. One of the major fields of application for anisotropic meshes is computational fluid dynamics (CFD), where stretched triangles oriented in the direction of the flow are desirable.
Reference: [12] <author> James Gosling and Henry McGilton. </author> <title> The Java Language Environment: a white paper. Sun Microsystems, </title> <month> October </month> <year> 1995. </year>
Reference-contexts: The World Wide Web appears to be a good tool to familiarize those people with these concepts. And as learning is often easier when playing games, we have designed an interactive Delaunay triangulator using the Java programming language developed by Sun <ref> [12] </ref>. It allows all people using a Java enabled browser such as Netscape Navigator TM 2.0 to build a triangulation by interactively inserting and removing sites. The triangulator can be found at: http://www.cs.cmu.edu/~bossen/triangulator.html Complete user instructions are given on the web page.
Reference: [13] <author> Leonidas Guibas and Jorge Stolfi. </author> <title> Primitives for the manipulation of general subdivisions and the computation of Voronoi diagrams. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 4(2) </volume> <pages> 74-123, </pages> <month> April </month> <year> 1985. </year> <month> 57 </month>
Reference-contexts: The value of ff doesn't matter either since it neither affects the topology of the convex hull, nor its projection on the plane 13 2.1 The Quadedge Data Structure The quadedge data structure <ref> [13] </ref> was designed for representing general subdivisions of orien-table manifolds. It simultaneously represents both the subdivision and its dual. Alternatives are the double-connected-edge-list (DCEL) [24] and the winged-edge data structures, which do not hold the dual. The quadedge structure has been preferred because an implementation was readily available [20]. <p> 3 (2.4) When assuming that the subdivision is a triangulation, it is possible to simplify some of the operations: e:Dprev = e:Onext:Rot 2 :Onext e:Dnext = e:Rot:Onext 2 :Rot (2.5) The next section presents higher level operators. 2.2 Topological Operators Starting with the operator set proposed by Guibas and Stolfi <ref> [13] </ref>, we have modified it to make it more symmetrical, and also to eliminate superfluous edge navigation. The parameters of the Connect operator have been changed and its inverse operator Disconnect is introduced. The latter accommodates some operations that were previously part of DeleteEdge. <p> Each operator is described in the next paragraphs. 15 2.2.1 MakeEdge MakeEdge creates a new quadedge and initializes all of its four directed edges. It takes no argument and returns the first edge of the quadedge. The quadedge is a subdivision by itself, namely the one of a sphere <ref> [13] </ref>. The details of the procedure are described below. <p> A description is given below. begin Edge:Connect (a; b) this:Splice (a) this:Org a:Org this:Sym:Splice (b) this:Dest b:Org end This new definition of the Connect operator changes in two ways from its original <ref> [13] </ref> form: it does not create a new edge any more, and the arguments represent different edges so that they can directly be applied to both of the Splice operations. 2.2.4 Disconnect The Disconnect operator is the inverse of the Connect operator. <p> In the divide-and-conquer algorithm, the input site set is first sorted by x-coordinate and split vertically in two subsets of equal size. The Delaunay triangulation is computed recursively for each subset. Subsets are then merged using a sweeping circle algorithm. A complete description is given in <ref> [13] </ref>. The time complexity of the algorithm is O (n log n). The sweepline algorithm is due to Fortune [9]. In a comparison with divide-and-conquer, Leach [18] has optimized both algorithms and measured execution speed. <p> A fast walking method is described in the next section. The total cost of an insertion is thus dominated by the cost of the point location procedure. 2.5.2 Walking Method for Point Location Guibas and Stolfi <ref> [13] </ref> have proposed a simple walking method for point location, which Lischinski has implemented [20]. An improved version where redundant tests have been 23 removed is described by a finite state automaton in Figure 2.8. At any time the point to locate is on the left of the current edge.
Reference: [14] <author> L.J. Guibas, D.E. Knuth, and M. Sharir. </author> <title> Randomized incremental construction of Delaunay and Voronoi diagrams. </title> <type> Technical Report STAN-CS-90-1300, </type> <institution> Stanford University, </institution> <year> 1990. </year>
Reference-contexts: If it is violated the offending edge is swapped. In this case 21 two more edges become candidates for inspection. The process continues until no more candidates remain. If the order of insertion is randomized, and with use of appropriate data structures for point-in-triangle location, it can be shown <ref> [14] </ref> that the expected running time of the algorithm is O (n log n). <p> The point location cost (step 1) can be reduced to O (log n) time with appropriate O (n)- space data structures <ref> [14] </ref>. Without additional data structures a simple walking method can be used to achieve an expected O ( p n) time performance. A fast walking method is described in the next section. <p> In the latter case, Delaunay triangulation is used. To compute the metric at a given point, the triangle it lies in first has to be determined. To do so, it is possible to use data structures such as the history tree proposed in <ref> [14] </ref>. Although the cost of one location is only O (log m), where m is the number of samples defining the metric, this method is suboptimal.
Reference: [15] <author> K. Ho-Le. </author> <title> Finite element mesh generation methods: a review and classification. </title> <booktitle> Computer-Aided Design, </booktitle> <volume> 20(1) </volume> <pages> 27-38, </pages> <month> Jan/Feb </month> <year> 1988. </year>
Reference-contexts: A metric tensor is introduced to quantify the stretching. The triangulation procedure is changed to generate "Delaunay" meshes in the Riemannian space defined by the metric. 1.1 Previous Work There are several surveys available on mesh generation <ref> [2, 15] </ref>. Most of present mesh generation algorithms are structured in the following way. First a mesh is build with methods such as advancing front [19, 21, 23], quadtree decomposition [35], or by greedy point insertion [3, 32].
Reference: [16] <author> Thomas Kao and David M. Mount. </author> <title> Dynamic maintenance of Delaunay triangulations. </title> <type> Technical Report CS-TR-2585, </type> <institution> University of Maryland, </institution> <year> 1991. </year>
Reference-contexts: Although it can be simple when using appropriate data structures and removing the last inserted point <ref> [16] </ref>, the general case is more difficult to handle.
Reference: [17] <author> C. L. Lawson. </author> <title> Software for c 1 surface interpolation. </title> <editor> In John R. Rice, editor, </editor> <booktitle> Mathematical Software III, </booktitle> <pages> pages 161-194. </pages> <publisher> Academic Press, </publisher> <year> 1977. </year>
Reference-contexts: Combined with an O (n 2 ) algorithm for constructing the initial triangulation, the Delaunay triangulation of a set of points can be found in O (n 2 ) time with this method. 2.4.2 The Incremental Algorithm The incremental algorithm was first proposed by Lawson <ref> [17] </ref>. It starts with a triangle large enough to contain all the points of the input set (ideally the three vertices are at infinity). Points are added into the triangulation one by one, maintaining the invariant that the triangulation is Delaunay.
Reference: [18] <author> Geoff Leach. </author> <title> Improving worst-case optimal Delaunay triangulation algorithms. </title> <booktitle> In 4th Canadian Conference on Computational Geometry, </booktitle> <year> 1992. </year>
Reference-contexts: Subsets are then merged using a sweeping circle algorithm. A complete description is given in [13]. The time complexity of the algorithm is O (n log n). The sweepline algorithm is due to Fortune [9]. In a comparison with divide-and-conquer, Leach <ref> [18] </ref> has optimized both algorithms and measured execution speed. According to Leach, the sweepline algorithm is the fastest, but also appears to be the least robust. 2.4.1 The Edge Swapping Algorithm Given an initial triangulation, the edge swapping algorithm maintains a queue of edges that might fail the circumcircle test.
Reference: [19] <author> D.A. Lindholm. </author> <title> Automatic triangular mesh generation on surfaces of polyhedra. </title> <journal> IEEE Trans. Magnetics, </journal> <volume> 19 </volume> <pages> 2539-2542, </pages> <year> 1983. </year>
Reference-contexts: Most of present mesh generation algorithms are structured in the following way. First a mesh is build with methods such as advancing front <ref> [19, 21, 23] </ref>, quadtree decomposition [35], or by greedy point insertion [3, 32]. The quality of the mesh is further improved with the use of smoothing. The most common method is Laplacian smoothing [8]. Advancing front methods start meshing at the boundaries of the domain.
Reference: [20] <author> Dani Lischinski. </author> <title> Incremental Delaunay triangulations. </title> <editor> In Paul S. Heckbert, editor, </editor> <booktitle> Graphics Gems IV, </booktitle> <pages> pages 47-59. </pages> <publisher> Academic Press, </publisher> <year> 1994. </year>
Reference-contexts: It simultaneously represents both the subdivision and its dual. Alternatives are the double-connected-edge-list (DCEL) [24] and the winged-edge data structures, which do not hold the dual. The quadedge structure has been preferred because an implementation was readily available <ref> [20] </ref>. Each quadedge record holds four directed edges corresponding to a single undirected edge in the subdivision and to its dual edge. <p> When naively computed, this determinant requires 48 multiplications and 27 additions. A good idea is to consider that the last column is filled with ones to reduce the cost to 20 multiplications and 24 additions, as in the code proposed by Lischinski <ref> [20] </ref>. <p> The total cost of an insertion is thus dominated by the cost of the point location procedure. 2.5.2 Walking Method for Point Location Guibas and Stolfi [13] have proposed a simple walking method for point location, which Lischinski has implemented <ref> [20] </ref>. An improved version where redundant tests have been 23 removed is described by a finite state automaton in Figure 2.8. At any time the point to locate is on the left of the current edge. Figure 2.7 shows the two possible movements at each step.
Reference: [21] <author> S.H. Lo. </author> <title> A new mesh generation scheme for arbitrary planar domains. </title> <booktitle> International Jounral for Numerical Methods in Engineering, </booktitle> <volume> 21 </volume> <pages> 1403-1426, </pages> <year> 1985. </year>
Reference-contexts: Most of present mesh generation algorithms are structured in the following way. First a mesh is build with methods such as advancing front <ref> [19, 21, 23] </ref>, quadtree decomposition [35], or by greedy point insertion [3, 32]. The quality of the mesh is further improved with the use of smoothing. The most common method is Laplacian smoothing [8]. Advancing front methods start meshing at the boundaries of the domain.
Reference: [22] <author> Dimitri J. Mavriplis. </author> <title> Adaptive mesh generation for viscous flows using Delaunay triangulation. </title> <journal> Journal of Computational Physics, </journal> <volume> 90(2) </volume> <pages> 271-291, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: Anisotropic mesh generation has not benefited from an extensive literature. One of the major fields of application for anisotropic meshes is computational fluid dynamics (CFD), where stretched triangles oriented in the direction of the flow are desirable. Mavriplis <ref> [22] </ref> proposed to stretch the plane by lifting it on a surface in three dimensions. The deformation of space is represented at each point by two values: an angle giving the direction of the stretching, and a value larger than 1 quantifying the stretching. <p> Another weakness of his method is poor meshing at boundaries. Peraire et al. [23], and later Mavriplis <ref> [22] </ref> introduced stretching vectors to quantify the anisotropy, which really are eigenvectors of the metric tensor, but never formally introduced the latter. Greedy insertion algorithms have been proposed by researchers at INRIA [3, 31]. We believe that better node positioning can be achieved. This chapter is structured as follows.
Reference: [23] <author> J. Peraire, M. Vahdati, K. Morgan, </author> <title> and O.C. Zienkiewicz. Adaptive remeshing for compressible flow computations. </title> <journal> Journal of Computational Physics, </journal> <volume> 72 </volume> <pages> 449-466, </pages> <year> 1987. </year>
Reference-contexts: Most of present mesh generation algorithms are structured in the following way. First a mesh is build with methods such as advancing front <ref> [19, 21, 23] </ref>, quadtree decomposition [35], or by greedy point insertion [3, 32]. The quality of the mesh is further improved with the use of smoothing. The most common method is Laplacian smoothing [8]. Advancing front methods start meshing at the boundaries of the domain. <p> Mavriplis [22] proposed to stretch the plane by lifting it on a surface in three dimensions. The deformation of space is represented at each point by two values: an angle giving the direction of the stretching, and a value larger than 1 quantifying the stretching. Before that, Peraire <ref> [23] </ref> was using a similar representation to quantify the desired element size as a function of its position and orientation. Later a metric tensor was introduced [3, 31]. <p> Although very elegant, his method is limited to metric tensors that represent a flat space (the Riemann-Christoffel tensor [28], that is the curvature of the space represented by the metric, should be zero). Another weakness of his method is poor meshing at boundaries. Peraire et al. <ref> [23] </ref>, and later Mavriplis [22] introduced stretching vectors to quantify the anisotropy, which really are eigenvectors of the metric tensor, but never formally introduced the latter. Greedy insertion algorithms have been proposed by researchers at INRIA [3, 31]. We believe that better node positioning can be achieved.
Reference: [24] <author> Franco P. Preparata and Michael Ian Shamos. </author> <title> Computational Geometry: an Introduction. </title> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: It simultaneously represents both the subdivision and its dual. Alternatives are the double-connected-edge-list (DCEL) <ref> [24] </ref> and the winged-edge data structures, which do not hold the dual. The quadedge structure has been preferred because an implementation was readily available [20]. Each quadedge record holds four directed edges corresponding to a single undirected edge in the subdivision and to its dual edge.
Reference: [25] <author> J. Ruppert. </author> <title> A new and simple algorithm for quality 2-dimensional mesh generation. </title> <booktitle> In 4th ACM-SIAM Symp. on Disc. Algorithms, </booktitle> <pages> pages 83-92, </pages> <year> 1993. </year>
Reference-contexts: Greedy insertion methods localize poorly shaped, or poorly sized elements, and split them by inserting a new node on an edge [3], at the center of a triangle [32], or at the center of the circle circumscribing a triangle <ref> [25] </ref>. Although the Delaunay criterion is the most common, other triangle quality criteria have been used [31] to determine the topology of the mesh. Laplacian smoothing consists of moving each vertex to the centroid of its neighbors. <p> The algorithm should always converge. * Quality. The resulting mesh should locally match the desired edge length. For now we will consider this length equal to ^, which is defined by the user. In a more sophisticated scheme, the implicit geometric feature size <ref> [25] </ref> could also be considered. The chapter is structured as follows. Section 3.1 introduces the general dynamics of the interaction model. Section 3.2 defines the interaction neighborhood. Section 3.3 presents different potential functions. Section 3.4 defines a model for controlling the particle population. Section 3.5 presents some improvements regarding speed.
Reference: [26] <author> Kenji Shimada. </author> <title> Physically-Based Mesh Generation: Automated Triangulation of Surfaces and Volumes via Bubble Packing. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <year> 1993. </year>
Reference-contexts: When the desired number of elements is reached, the mesh is further relaxed to improve its quality. Mesh generation has also benefited from other kinds of approaches. The idea of using physically-based simulations for mesh generation has been investigated by Shimada <ref> [26] </ref> and 8 his bubble packing method. The bubble interaction (attraction/repulsion) model, which is inspired by the Lennard-Jones interaction model from molecular chemistry, generates triangulations that imitate Nature in her way of producing regular arrangements of points, such as in crystals.
Reference: [27] <author> Kenji Shimada and David C. Gossard. </author> <title> Computational methods for physically-based fe mesh generation. </title> <booktitle> In PROLAMAT. IFIP TC5/WG5.3, </booktitle> <year> 1992. </year>
Reference-contexts: Section 3.2 defines the interaction neighborhood. Section 3.3 presents different potential functions. Section 3.4 defines a model for controlling the particle population. Section 3.5 presents some improvements regarding speed. Finally, results are shown in Section 3.6. 3.1 Interaction Model Whereas in Nature and in some previously implemented models <ref> [27, 29] </ref>, the motion of the particles is defined by a second order differential equation (mx = P consider a simpler, first order model, as used in [34]. Although first order models are more 27 likely to get stuck in local minima, they are generally numerically more stable. <p> The differential equation associated with this model is of the form x + k _x = r x E + C 3.2 Interaction Neighborhoods In previous work <ref> [34, 27, 30, 29] </ref> the interaction neighborhood of a particle i was defined based on geometrical properties. The neighborhood was defined by a sphere with a radius equal to some constant times the desired edge length. <p> derivative is 0 ( ij ) = (1 ( ij ) 2 ) exp 2 (3.17) Potential ( ij ) Derivative 0 ( ij ) This new scheme generates regular patterns for N 1 and N 2 neighborhoods. 32 3.3.3 Lennard-Jones Potential One of the most widely used interaction model <ref> [29, 27] </ref> is based on the Lennard-Jones potential, or van der Waals force which is inspired from molecular chemistry. <p> Numerical integration can thus be disastrous. Shimada <ref> [27] </ref> has defined a potential function with a similar shape but which overcomes the singularity problem (Figure 3.5): 0 ( ij ) = 4 ij 3 19 + 8 Potential ( ij ) Derivative 0 ( ij ) Shimada used N 1:5^ , but this scheme also works with N 1
Reference: [28] <author> I.S. Sokolnikoff. </author> <title> Tensor Analysis, Theory and Applications to Geometry and Mechanics of Continua. </title> <publisher> John Wiley, </publisher> <address> New York, 2nd edition, </address> <year> 1964. </year>
Reference-contexts: Relatively little work has been done on anisotropic meshes. D'Azevedo [5] has proposed the use of coordinate transformations to generate optimal triangulations. Although very elegant, his method is limited to metric tensors that represent a flat space (the Riemann-Christoffel tensor <ref> [28] </ref>, that is the curvature of the space represented by the metric, should be zero). Another weakness of his method is poor meshing at boundaries.
Reference: [29] <author> Richard Szeliski and David Tonnesen. </author> <title> Surface modeling with oriented particle systems. </title> <booktitle> In SIGGRAPH'92 Proceedings, </booktitle> <pages> pages 185-194, </pages> <year> 1992. </year>
Reference-contexts: The main advantages of this method are good point placement, and intrinsic remeshing capabilities. Physically-based models have also been used in computer graphics for sampling surfaces <ref> [29, 30, 33, 34] </ref>. In these models, particles spread over complex surfaces to form uniform sampling patterns. Szeliski [29] used attracting and repelling, oriented particles to interactively sculpt surfaces. Turk [30] considered resampling polygonal surfaces using repelling particles. Witkin and Heckbert [34] used repelling particles to sample implicit surfaces. <p> The main advantages of this method are good point placement, and intrinsic remeshing capabilities. Physically-based models have also been used in computer graphics for sampling surfaces [29, 30, 33, 34]. In these models, particles spread over complex surfaces to form uniform sampling patterns. Szeliski <ref> [29] </ref> used attracting and repelling, oriented particles to interactively sculpt surfaces. Turk [30] considered resampling polygonal surfaces using repelling particles. Witkin and Heckbert [34] used repelling particles to sample implicit surfaces. <p> Section 3.2 defines the interaction neighborhood. Section 3.3 presents different potential functions. Section 3.4 defines a model for controlling the particle population. Section 3.5 presents some improvements regarding speed. Finally, results are shown in Section 3.6. 3.1 Interaction Model Whereas in Nature and in some previously implemented models <ref> [27, 29] </ref>, the motion of the particles is defined by a second order differential equation (mx = P consider a simpler, first order model, as used in [34]. Although first order models are more 27 likely to get stuck in local minima, they are generally numerically more stable. <p> The differential equation associated with this model is of the form x + k _x = r x E + C 3.2 Interaction Neighborhoods In previous work <ref> [34, 27, 30, 29] </ref> the interaction neighborhood of a particle i was defined based on geometrical properties. The neighborhood was defined by a sphere with a radius equal to some constant times the desired edge length. <p> For fast location of the particles within N i c^ , k d trees <ref> [29] </ref>, buckets or some other additional data structures are used. In the present case, however, a triangulation is already provided, and it is thus easy to define a neighborhood based on topology instead of geometry. <p> derivative is 0 ( ij ) = (1 ( ij ) 2 ) exp 2 (3.17) Potential ( ij ) Derivative 0 ( ij ) This new scheme generates regular patterns for N 1 and N 2 neighborhoods. 32 3.3.3 Lennard-Jones Potential One of the most widely used interaction model <ref> [29, 27] </ref> is based on the Lennard-Jones potential, or van der Waals force which is inspired from molecular chemistry.
Reference: [30] <author> Greg Turk. </author> <title> Generating textures on arbitrary surfaces using reaction-diffusion. </title> <booktitle> In SIGGRAPH'91 Proceedings, </booktitle> <pages> pages 289-298, </pages> <year> 1991. </year>
Reference-contexts: The main advantages of this method are good point placement, and intrinsic remeshing capabilities. Physically-based models have also been used in computer graphics for sampling surfaces <ref> [29, 30, 33, 34] </ref>. In these models, particles spread over complex surfaces to form uniform sampling patterns. Szeliski [29] used attracting and repelling, oriented particles to interactively sculpt surfaces. Turk [30] considered resampling polygonal surfaces using repelling particles. Witkin and Heckbert [34] used repelling particles to sample implicit surfaces. <p> Physically-based models have also been used in computer graphics for sampling surfaces [29, 30, 33, 34]. In these models, particles spread over complex surfaces to form uniform sampling patterns. Szeliski [29] used attracting and repelling, oriented particles to interactively sculpt surfaces. Turk <ref> [30] </ref> considered resampling polygonal surfaces using repelling particles. Witkin and Heckbert [34] used repelling particles to sample implicit surfaces. Although many have thought of introducing anisotropy, and defining the sampling density based on surface curvature, few have done it [30]. <p> Turk <ref> [30] </ref> considered resampling polygonal surfaces using repelling particles. Witkin and Heckbert [34] used repelling particles to sample implicit surfaces. Although many have thought of introducing anisotropy, and defining the sampling density based on surface curvature, few have done it [30]. Witkin and Heckbert [34] have noticed that such schemes can produce very regular patterns of points. Their work has been the starting point of the work presented in this document. 1.2 Approach Overview In this work, we limit ourselves to generate triangular meshes over polygonal domains in the plane. <p> The differential equation associated with this model is of the form x + k _x = r x E + C 3.2 Interaction Neighborhoods In previous work <ref> [34, 27, 30, 29] </ref> the interaction neighborhood of a particle i was defined based on geometrical properties. The neighborhood was defined by a sphere with a radius equal to some constant times the desired edge length.
Reference: [31] <author> Marie-Gabrielle Vallet. </author> <title> Generation de maillages anisotropes adaptes application a la capture de couches limites. </title> <type> Technical Report 1360, </type> <institution> INRIA, </institution> <year> 1990. </year> <month> 58 </month>
Reference-contexts: Although the Delaunay criterion is the most common, other triangle quality criteria have been used <ref> [31] </ref> to determine the topology of the mesh. Laplacian smoothing consists of moving each vertex to the centroid of its neighbors. This operation must generally be repeated several times for each node before the quality of the mesh is improved. <p> Before that, Peraire [23] was using a similar representation to quantify the desired element size as a function of its position and orientation. Later a metric tensor was introduced <ref> [3, 31] </ref>. The tensor representation has the advantage to be directly related to the Hessian of the function (speed, pressure, etc.) to be estimated [5]. It is thus a more natural representation to create adapted meshes. Quite impressive results have been produced by Castro-Diaz, Hecht, and Mohammadi [3]. <p> Another weakness of his method is poor meshing at boundaries. Peraire et al. [23], and later Mavriplis [22] introduced stretching vectors to quantify the anisotropy, which really are eigenvectors of the metric tensor, but never formally introduced the latter. Greedy insertion algorithms have been proposed by researchers at INRIA <ref> [3, 31] </ref>. We believe that better node positioning can be achieved. This chapter is structured as follows. Section 5.1 introduces some concepts of Rieman-nian geometry. Section 5.2 exposes the changes made to the triangulation procedure due to anisotropy.
Reference: [32] <author> N.P. Weatherill and O. Hassan. </author> <title> Efficient three-dimensional Delaunay triangulation with automatic point creation and imposed boundary constraints. </title> <journal> International Journal for Numerical Methods in Engineering, </journal> <volume> 37 </volume> <pages> 2005-2039, </pages> <year> 1994. </year>
Reference-contexts: Most of present mesh generation algorithms are structured in the following way. First a mesh is build with methods such as advancing front [19, 21, 23], quadtree decomposition [35], or by greedy point insertion <ref> [3, 32] </ref>. The quality of the mesh is further improved with the use of smoothing. The most common method is Laplacian smoothing [8]. Advancing front methods start meshing at the boundaries of the domain. A list of nodes to be expanded (referred to as the front) is maintained. <p> To obtain a triangular mesh, the squares are further divided into triangles. Greedy insertion methods localize poorly shaped, or poorly sized elements, and split them by inserting a new node on an edge [3], at the center of a triangle <ref> [32] </ref>, or at the center of the circle circumscribing a triangle [25]. Although the Delaunay criterion is the most common, other triangle quality criteria have been used [31] to determine the topology of the mesh. Laplacian smoothing consists of moving each vertex to the centroid of its neighbors.
Reference: [33] <author> William Welch. </author> <title> Serious Putty: Topological Design for Variational Curves and Surfaces. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1995. </year>
Reference-contexts: The main advantages of this method are good point placement, and intrinsic remeshing capabilities. Physically-based models have also been used in computer graphics for sampling surfaces <ref> [29, 30, 33, 34] </ref>. In these models, particles spread over complex surfaces to form uniform sampling patterns. Szeliski [29] used attracting and repelling, oriented particles to interactively sculpt surfaces. Turk [30] considered resampling polygonal surfaces using repelling particles. Witkin and Heckbert [34] used repelling particles to sample implicit surfaces.
Reference: [34] <author> Andrew P. Witkin and Paul S. Heckbert. </author> <title> Using particles to sample and control implicit surfaces. </title> <booktitle> In SIGGRAPH'94 Proceedings, </booktitle> <year> 1994. </year>
Reference-contexts: The main advantages of this method are good point placement, and intrinsic remeshing capabilities. Physically-based models have also been used in computer graphics for sampling surfaces <ref> [29, 30, 33, 34] </ref>. In these models, particles spread over complex surfaces to form uniform sampling patterns. Szeliski [29] used attracting and repelling, oriented particles to interactively sculpt surfaces. Turk [30] considered resampling polygonal surfaces using repelling particles. Witkin and Heckbert [34] used repelling particles to sample implicit surfaces. <p> In these models, particles spread over complex surfaces to form uniform sampling patterns. Szeliski [29] used attracting and repelling, oriented particles to interactively sculpt surfaces. Turk [30] considered resampling polygonal surfaces using repelling particles. Witkin and Heckbert <ref> [34] </ref> used repelling particles to sample implicit surfaces. Although many have thought of introducing anisotropy, and defining the sampling density based on surface curvature, few have done it [30]. Witkin and Heckbert [34] have noticed that such schemes can produce very regular patterns of points. <p> Turk [30] considered resampling polygonal surfaces using repelling particles. Witkin and Heckbert <ref> [34] </ref> used repelling particles to sample implicit surfaces. Although many have thought of introducing anisotropy, and defining the sampling density based on surface curvature, few have done it [30]. Witkin and Heckbert [34] have noticed that such schemes can produce very regular patterns of points. Their work has been the starting point of the work presented in this document. 1.2 Approach Overview In this work, we limit ourselves to generate triangular meshes over polygonal domains in the plane. <p> Finally, results are shown in Section 3.6. 3.1 Interaction Model Whereas in Nature and in some previously implemented models [27, 29], the motion of the particles is defined by a second order differential equation (mx = P consider a simpler, first order model, as used in <ref> [34] </ref>. Although first order models are more 27 likely to get stuck in local minima, they are generally numerically more stable. <p> The differential equation associated with this model is of the form x + k _x = r x E + C 3.2 Interaction Neighborhoods In previous work <ref> [34, 27, 30, 29] </ref> the interaction neighborhood of a particle i was defined based on geometrical properties. The neighborhood was defined by a sphere with a radius equal to some constant times the desired edge length. <p> A tradeoff must thus be found between quality near the boundaries and elsewhere. As the effects depend a lot on the choice of the potential energy function, we empirically search for the best solution for each function. 31 3.3.2 Gaussian Potential Witkin and Heckbert <ref> [34] </ref> used a Gaussian potential function to spread particles on implicit surfaces (Figure 3.2): ( ij ) = exp 2 ( ij ) 2 Potential ( ij ) Derivative 0 ( ij ) This model works well with N 2 neighborhoods but fails to arrange particles into the desired pattern with
Reference: [35] <author> M.A. </author> <title> Yerry and M.S. Shepard. A modified quadtree approach to finite element mesh generation. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 3 </volume> <pages> 39-46, </pages> <month> January/February </month> <year> 1983. </year>
Reference-contexts: Most of present mesh generation algorithms are structured in the following way. First a mesh is build with methods such as advancing front [19, 21, 23], quadtree decomposition <ref> [35] </ref>, or by greedy point insertion [3, 32]. The quality of the mesh is further improved with the use of smoothing. The most common method is Laplacian smoothing [8]. Advancing front methods start meshing at the boundaries of the domain.
References-found: 35

