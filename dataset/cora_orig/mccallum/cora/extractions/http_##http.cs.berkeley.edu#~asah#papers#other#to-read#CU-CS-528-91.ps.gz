URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/CU-CS-528-91.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/
Root-URL: http://www.cs.berkeley.edu
Title: The Effect of Garbage Collection on Cache Performance  
Author: Benjamin Zorn 
Address: Boulder  
Affiliation: University of Colorado at  
Date: May 1991  
Pubnum: CU-CS-528-91  
Abstract: Technical Report CU-CS-528-91 Department of Computer Science Campus Box 430 University of Colorado Boulder, Colorado 80309 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. J. </author> <title> Cheney. A nonrecursive list compacting algorithm. </title> <journal> Communications of the ACM, </journal> <volume> 13(11) </volume> <pages> 677-678, </pages> <month> November </month> <year> 1970. </year>
Reference-contexts: Stop-and-copy collection solves both of these problems. 2.2 Stop-and-copy Collection Stop-and-copy garbage collection (or copying collection) was first proposed in the late 1960's when virtual memory allowed the use of large heaps that required significant overhead to sweep <ref> [1, 3] </ref>. Copying collection divides the heap into semispaces, and copies reachable objects between semispaces during collection. Because only reachable objects are visited, the overhead of copying collection is no longer proportional to the size of memory.
Reference: [2] <author> Robert Courts. </author> <title> Improving locality of reference in a garbage-collecting memory management system. </title> <journal> Communications of the ACM, </journal> <volume> 31(9) </volume> <pages> 1128-1138, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Because stop-and-copy collection provides these two advantages (less overhead and compaction) over simple mark-and-sweep collection, it has been the preferred algorithm for more than a decade and is used in many commercial Lisp systems <ref> [10, 2, 4, 16] </ref>. 2.3 Generation Collection Generation garbage collection divides a program's heap into regions (generations) containing objects of different ages. <p> The order of traversal in a copying algorithm affects the locality of garbage collection, as discussed by Moon [10]. Courts reports that approximate depth-first traversal was shown to decrease page fault rates by 10-15% over breadth-first traversal in the TI Explorer <ref> [2] </ref>. 5.3 Performance Results: Direct-mapped Caches As with the mark-and-sweep performance results, I present the performance results for stop-and-copy collection in direct-mapped caches ranging from 128 kilobytes to 2 megabytes. The cache block size is 32 bytes and the replacement policy is LRU. <p> Furthermore, almost every paper measures the page locality for a specific memory size by providing page fault rates (e.g., see <ref> [10, 14, 2, 16, 17] </ref>). Only a few more recent papers have considered the cache locality of garbage-collected programs. There are several reasons for this dearth of research: 22 23 first, before generation collection, the locality of garbage-collected programs was so bad that cache effects were not significant.
Reference: [3] <author> Robert R. Fenichel and Jerome C. Yochelson. </author> <title> A Lisp garbage-collector for virtual memory computer systems. </title> <journal> Communications of the ACM, </journal> <volume> 12(11) </volume> <pages> 611-612, </pages> <month> November </month> <year> 1969. </year>
Reference-contexts: Stop-and-copy collection solves both of these problems. 2.2 Stop-and-copy Collection Stop-and-copy garbage collection (or copying collection) was first proposed in the late 1960's when virtual memory allowed the use of large heaps that required significant overhead to sweep <ref> [1, 3] </ref>. Copying collection divides the heap into semispaces, and copies reachable objects between semispaces during collection. Because only reachable objects are visited, the overhead of copying collection is no longer proportional to the size of memory.
Reference: [4] <author> Franz Incorporated. </author> <title> Allegro Common Lisp User Guide, Release 3.0 (beta) edition, </title> <month> April </month> <year> 1988. </year>
Reference-contexts: Because stop-and-copy collection provides these two advantages (less overhead and compaction) over simple mark-and-sweep collection, it has been the preferred algorithm for more than a decade and is used in many commercial Lisp systems <ref> [10, 2, 4, 16] </ref>. 2.3 Generation Collection Generation garbage collection divides a program's heap into regions (generations) containing objects of different ages. <p> Commercial Lisp systems, such as Allegro Common Lisp, allow the user to set the allocation threshold <ref> [4] </ref>. 3 Evaluation Methods This paper compares the data cache miss rates of different garbage collection algorithms with different cache configurations. The miss rates are calculated using the all-associativity cache simulator, tycho, written by Mark Hill [5].
Reference: [5] <author> Mark D. Hill. </author> <title> Aspects of Cache Memory and Instruction Buffer Performance. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, Berkeley, </institution> <address> CA, </address> <month> November </month> <year> 1987. </year> <note> Also appears as tech report UCB/CSD 87/381. </note>
Reference-contexts: The miss rates are calculated using the all-associativity cache simulator, tycho, written by Mark Hill <ref> [5] </ref>. The cache simulations were driven by address traces collected from four large Common Lisp programs.
Reference: [6] <author> Norman P. Jouppi. </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers. </title> <booktitle> In Proceedings of the Seventeenth Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 364-373, </pages> <address> Seattle, WA, </address> <month> March </month> <year> 1990. </year>
Reference-contexts: As processors and cache memories increase in speed, the cost of missing in the cache and retrieving data from main memory will also increase. Jouppi estimates the cost of a cache miss will increase to over 100 cycles if current trends continue <ref> [6] </ref>. Mogul and Borg evaluate the effect of context switches on a hypothetical two-level cache that requires 200 cycles to service a second-level cache miss [9]. In modern computer systems, the effect that collection algorithms have on both the cache and main memory reference locality must be considered.
Reference: [7] <author> Henry Lieberman and Carl Hewitt. </author> <title> A real-time garbage collector based on the lifetimes of objects. </title> <journal> Communications of the ACM, </journal> <volume> 26(6) </volume> <pages> 419-429, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: In the early 1980's, algorithm designers recognized the performance problems of garbage-collecting a large address space and suggested solutions. Generation techniques, described by Lieberman and Hewitt, proved to be the most effective solution <ref> [7] </ref>. By focusing collection on a small subset of the entire address space, generation methods greatly improve the virtual memory paging performance of garbage collection algorithms [10, 17]. In recent years, faster processor speeds have shifted interest in memory system performance from slower main memories to high-speed cache memories.
Reference: [8] <author> John McCarthy. </author> <title> Recursive functions of symbolic expressions and their computations by machine, part I. </title> <journal> Communications of the ACM, </journal> <volume> 3(4) </volume> <pages> 184-195, </pages> <month> April </month> <year> 1960. </year>
Reference-contexts: Mark-and-sweep and stop-and-copy collection differ in the way in which the live objects are preserved and the dead objects reclaimed. 2.1 Mark-and-sweep Collection Mark-and-sweep algorithms were the first garbage collection algorithms proposed <ref> [8] </ref>. As the name suggests, this algorithm collects garbage in two phases: the mark phase visits and marks all live objects and the sweep phase sweeps sequentially through the memory, adding unmarked objects to the free list of objects that can be reused.
Reference: [9] <author> Jeffrey C. Mogul and Anita Borg. </author> <title> The effect of context switches on cache performance. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-IV), </booktitle> <pages> pages 75-84, </pages> <address> Santa Clara, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Jouppi estimates the cost of a cache miss will increase to over 100 cycles if current trends continue [6]. Mogul and Borg evaluate the effect of context switches on a hypothetical two-level cache that requires 200 cycles to service a second-level cache miss <ref> [9] </ref>. In modern computer systems, the effect that collection algorithms have on both the cache and main memory reference locality must be considered. Because the cache locality of algorithms is a topic of relatively recent interest, little work has been done to investigate the cache locality of garbage collection algorithms.
Reference: [10] <author> David A. Moon. </author> <title> Garbage collection in a large Lisp system. </title> <booktitle> In Conference Record of the 1984 ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 235-246, </pages> <address> Austin, Texas, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: Generation techniques, described by Lieberman and Hewitt, proved to be the most effective solution [7]. By focusing collection on a small subset of the entire address space, generation methods greatly improve the virtual memory paging performance of garbage collection algorithms <ref> [10, 17] </ref>. In recent years, faster processor speeds have shifted interest in memory system performance from slower main memories to high-speed cache memories. Cache memories must be able to provide instructions and data to processors at faster and faster rates. <p> Because stop-and-copy collection provides these two advantages (less overhead and compaction) over simple mark-and-sweep collection, it has been the preferred algorithm for more than a decade and is used in many commercial Lisp systems <ref> [10, 2, 4, 16] </ref>. 2.3 Generation Collection Generation garbage collection divides a program's heap into regions (generations) containing objects of different ages. <p> If, however, newspace fits entirely in the cache, this effect will not be significant. The order of traversal in a copying algorithm affects the locality of garbage collection, as discussed by Moon <ref> [10] </ref>. <p> Furthermore, almost every paper measures the page locality for a specific memory size by providing page fault rates (e.g., see <ref> [10, 14, 2, 16, 17] </ref>). Only a few more recent papers have considered the cache locality of garbage-collected programs. There are several reasons for this dearth of research: 22 23 first, before generation collection, the locality of garbage-collected programs was so bad that cache effects were not significant.
Reference: [11] <author> C.-J. Peng and G. S. Sohi. </author> <title> Cache memory design considerations to support languages with dynamic heap allocation. </title> <type> Technical Report 860, </type> <institution> Computer Sciences Dept., Univ. of Wisconsin| Madison, </institution> <month> July </month> <year> 1989. </year>
Reference-contexts: A third reason that cache performance is of current interest is that cache sizes have only recently grown to the point that fitting the newspace in the cache was possible. Peng and Sohi considered cache modifications to enhance performance in a garbage-collected heap <ref> [11] </ref>. In their study, they outline two methods of improving the cache performance of these systems. First, they advocate the addition of a special cache operation "allocate" that tells the cache not to bother fetching the block being allocated since its contents will immediately be overwritten, avoiding unnecessary bus traffic.
Reference: [12] <author> Steven Przybylski. </author> <title> The performance impact of block sizes and fetch strategies. </title> <booktitle> In Proceedings of the Seventeenth Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 160-169, </pages> <address> Seattle, WA, </address> <month> March </month> <year> 1990. </year>
Reference-contexts: same rate as the processor, and assuming that 10% of all memory references are data references, a 1% data cache miss rate translates into a 1% increase in execution 2 Recently, the block size of 32-bytes is shown to be an excellent size for caches with a simple fetch strategy <ref> [12] </ref>. 8 time. If, however, a cache miss results in 100 wasted processor cycles (as is envisioned), the overhead of a 1% miss rate is 10%.
Reference: [13] <author> Paul Rovner. </author> <title> On adding garbage collection and runtime types to a strongly-typed, statically checked, concurrent language. </title> <type> Technical Report CSL-84-7, </type> <institution> Xerox Palo Alto Research Center, Palo Alto, California, </institution> <month> July </month> <year> 1985. </year>
Reference-contexts: Rovner estimates that developers using the Mesa language spent 40% of the development time implementing memory management procedures and finding bugs related to explicit storage reclamation <ref> [13] </ref>. As useful as it is, garbage collection also has costs: first, additional CPU overhead is required to identify and reuse "garbage" objects. Second, it is traditionally believed that memory references performed during garbage collection disrupt the reference locality of executing programs.
Reference: [14] <author> Robert A. Shaw. </author> <title> Empirical Analysis of a Lisp System. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <address> Stan-ford, CA, </address> <month> February </month> <year> 1988. </year> <note> Also appears as Computer Systems Laboratory tech report CSL-TR-88-351. </note>
Reference-contexts: Instead of collecting objects located throughout the heap, generation collection focuses the effort of garbage collection on the most recently allocated objects because empirical evidence shows they are the most likely to become garbage <ref> [14, 20] </ref>. There are two advantages to collecting only part of a program's total heap: first, the collection references are localized and garbage collection does not disrupt the reference locality of the program as much. <p> However, maintaining collection counts can be memory intensive for small objects (e.g., maintaining a 1-byte count with each 8-byte cons cell results in a memory overhead of 12%). By using techniques such as a bucket-brigade (suggested by Shaw <ref> [14] </ref>), copying algorithms can approximate maintaining per-object collection counts and promote only those objects that have survived a fixed number of collections. Unfortunately, because mark-and-sweep algorithms do not copy objects at every collection, even approximate per-object collection counts are costly to maintain. <p> Furthermore, almost every paper measures the page locality for a specific memory size by providing page fault rates (e.g., see <ref> [10, 14, 2, 16, 17] </ref>). Only a few more recent papers have considered the cache locality of garbage-collected programs. There are several reasons for this dearth of research: 22 23 first, before generation collection, the locality of garbage-collected programs was so bad that cache effects were not significant. <p> In Smalltalk, in which Ungar first proposed the idea, objects die rapidly, and little data ever needs to be copied from the creation space to the semispaces. Empirical results from Lisp systems suggest that objects survive much longer than in Smalltalk <ref> [14, 20] </ref>. Under these circumstances, the number of objects surviving the collection from the creation space will be a significant fraction of the objects allocated, reducing the locality benefits of the creation space.
Reference: [15] <author> Alan J. Smith. </author> <title> Cache memories. </title> <journal> ACM Computing Surveys, </journal> <volume> 14(3) </volume> <pages> 473-530, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: The cache simulations were driven by address traces collected from four large Common Lisp programs. The use of trace-driven simulation to measure cache miss rate in the evaluation of cache performance is a proven technique used in many performance studies (e.g., see Smith <ref> [15] </ref>). 3.1 Object-level tracing With trace-driven simulation, cache performance is measured by feeding program address references to a cache simulator. However, different garbage collection algorithms will result in different organizations of objects in memory.
Reference: [16] <author> Patrick G. Sobalvarro. </author> <title> A lifetime-based garbage collector for LISP systems on general purpose computers. </title> <type> Bachelor's thesis, </type> <institution> MIT, </institution> <year> 1988. </year>
Reference-contexts: Because stop-and-copy collection provides these two advantages (less overhead and compaction) over simple mark-and-sweep collection, it has been the preferred algorithm for more than a decade and is used in many commercial Lisp systems <ref> [10, 2, 4, 16] </ref>. 2.3 Generation Collection Generation garbage collection divides a program's heap into regions (generations) containing objects of different ages. <p> Furthermore, almost every paper measures the page locality for a specific memory size by providing page fault rates (e.g., see <ref> [10, 14, 2, 16, 17] </ref>). Only a few more recent papers have considered the cache locality of garbage-collected programs. There are several reasons for this dearth of research: 22 23 first, before generation collection, the locality of garbage-collected programs was so bad that cache effects were not significant.
Reference: [17] <author> David Ungar. </author> <title> Generation scavenging: A non-disruptive high performance storage reclamation algorithm. </title> <booktitle> In SIGSOFT/SIGPLAN Practical Programming Environments Conference, </booktitle> <pages> pages 157-167, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: Generation techniques, described by Lieberman and Hewitt, proved to be the most effective solution [7]. By focusing collection on a small subset of the entire address space, generation methods greatly improve the virtual memory paging performance of garbage collection algorithms <ref> [10, 17] </ref>. In recent years, faster processor speeds have shifted interest in memory system performance from slower main memories to high-speed cache memories. Cache memories must be able to provide instructions and data to processors at faster and faster rates. <p> Furthermore, almost every paper measures the page locality for a specific memory size by providing page fault rates (e.g., see <ref> [10, 14, 2, 16, 17] </ref>). Only a few more recent papers have considered the cache locality of garbage-collected programs. There are several reasons for this dearth of research: 22 23 first, before generation collection, the locality of garbage-collected programs was so bad that cache effects were not significant. <p> Wilson and I also investigate different copying algorithms. While my work uses a standard semispace copying algorithm, Wilson investigates the use of a separate "creation space" for object allocation as proposed by Ungar <ref> [17] </ref>. With a creation space, objects are allocated in a separate area, and then copied into the normal copying semispaces associate with newspace the first time they are collected.
Reference: [18] <author> Paul R. Wilson, Michael S. Lam, and Thomas G. Moher. </author> <title> Caching considerations for generation garbage collection: a case for large and set associative caches. </title> <type> Technical Report UIC-EECS-90-5, </type> <institution> Software Systems Lab, University of Illinois at Chicago, Chicago, IL, </institution> <month> December 90. </month>
Reference-contexts: The major reason for the difference is that non-benchmark programs use large long-lived data structures and reference system objects with higher frequency than small benchmark programs. These objects behave much differently than the short-lived objects measured by Peng and Sohi. Wilson investigates the cache locality of generation garbage-collected systems <ref> [18] </ref>. Wil-son measured a Scheme-48 compiler running in a mixed instruction and data cache ranging from 64 to 256 kilobytes.
Reference: [19] <author> Taiichi Yuasa and Masami Hagiya. </author> <title> The KCL Report. </title> <institution> Research Institute for Mathematical Sciences, University of Kyoto. </institution>
Reference-contexts: Second, the marking and sweeping techniques used in the algorithm are designed to increase memory reference locality. Third, the promotion policy used by this algorithm illustrates a difficulty of combining mark-and-sweep collection with generations. The mark-and-sweep technique described enhances the algorithm implemented in Kyoto Common Lisp (KCL) <ref> [19] </ref>. The algorithm does not perform a compaction phase, and once allocated, objects are only relocated when they are promoted. Mark-and-sweep algorithms must solve two problems: maintain per-object mark bits, and avoid fragmentation of vector objects (whose size varies from object to object).
Reference: [20] <author> Benjamin Zorn. </author> <title> Comparative Performance Evaluation of Garbage Collection Algorithms. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, Berkeley, </institution> <address> CA, </address> <month> November </month> <year> 1989. </year> <note> Also appears as tech report UCB/CSD 89/544. </note>
Reference-contexts: Instead of collecting objects located throughout the heap, generation collection focuses the effort of garbage collection on the most recently allocated objects because empirical evidence shows they are the most likely to become garbage <ref> [14, 20] </ref>. There are two advantages to collecting only part of a program's total heap: first, the collection references are localized and garbage collection does not disrupt the reference locality of the program as much. <p> This paper compares the cache performance of a generation mark-and-sweep algorithm with a generation copying algorithm. Further details about the implementation of the algorithms are provided in later sections and elsewhere <ref> [20] </ref>. The goal of this comparison is not to predict the exact cache performance metrics expected for an actual implementation of these algorithms, but to provide a fair experimental comparison of the relative performance of the two approaches. <p> After mapping abstract object references to concrete memory addresses, the garbage collection simulator passes the reference information to the cache simulator, which computes the cache miss rate. I used MARS (Memory Allocation and Reference Simulator) to collect the object-level traces used in this paper <ref> [20] </ref>. MARS is attached to a commercial Common Lisp system (Franz Allegro Common Lisp), and four large Common Lisp programs drive the algorithm simulation. These programs, which represent a variety of programming styles and application areas, are summarized in Table 1. <p> In the next section, I perform the same analysis for stop-and-copy collection. 9 10 4.1 Generation Mark-and-sweep Collection While this section provides a high-level description of the mark-and-sweep algorithm measured, a more precise description of the algorithm can be found in <ref> [20] </ref>. This algorithm was selected for several reasons: first, because it uses generation collection, it avoids some of the inherent problems of mark-and-sweep collection described earlier. Second, the marking and sweeping techniques used in the algorithm are designed to increase memory reference locality. <p> En-masse promotion is less selective than collection count promotion because it promotes younger as well as older objects, and results in significantly higher promotion rates, as shown by Zorn <ref> [20] </ref>. <p> In Smalltalk, in which Ungar first proposed the idea, objects die rapidly, and little data ever needs to be copied from the creation space to the semispaces. Empirical results from Lisp systems suggest that objects survive much longer than in Smalltalk <ref> [14, 20] </ref>. Under these circumstances, the number of objects surviving the collection from the creation space will be a significant fraction of the objects allocated, reducing the locality benefits of the creation space. <p> In work that predates the present evaluation, Zorn uses the same evaluation techniques to compare the main memory and cache performance of different garbage collection algorithms <ref> [20, 21] </ref>. Zorn's earlier measurements focus primarily on the page reference locality of garbage collection.
Reference: [21] <author> Benjamin Zorn. </author> <title> Comparing mark-and-sweep and stop-and-copy garbage collection. </title> <booktitle> In Proceedings of the 1990 ACM Conference on LISP and Functional Programming, </booktitle> <pages> pages 87-98, </pages> <address> Nice, France, </address> <month> June </month> <year> 1990. </year> <month> 31 </month>
Reference-contexts: Because the most frequent collections only collect the youngest generation, generation garbage collection has the potential to substantially improve cache performance by localizing 4 references inside the cache. Furthermore, generation garbage collection also ameliorates the two negative characteristics of mark-and-sweep collection, as outlined in a related paper by Zorn <ref> [21] </ref>. He argues that because the youngest generation (newspace) is relatively small, sweeping a small fraction of the address space does not add a significant overhead, especially if the sweeping process is seen as an extension of the allocation process. <p> In work that predates the present evaluation, Zorn uses the same evaluation techniques to compare the main memory and cache performance of different garbage collection algorithms <ref> [20, 21] </ref>. Zorn's earlier measurements focus primarily on the page reference locality of garbage collection.
References-found: 21

