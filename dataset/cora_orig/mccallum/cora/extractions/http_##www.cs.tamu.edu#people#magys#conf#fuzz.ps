URL: http://www.cs.tamu.edu/people/magys/conf/fuzz.ps
Refering-URL: http://www.cs.tamu.edu/people/magys/conf/publication.html
Root-URL: http://www.cs.tamu.edu
Title: A Fuzzy Emotional Agent for Decision-Making in a Mobile Robot  
Author: Magy Seif El-Nasr Marjorie Skubic 
Address: College Station, TX 77843-3112 Columbia, MO 65211  
Affiliation: Department of Computer Science Computer Engineering and Computer Science Dept. Texas A&M University University of Missouri-Columbia  
Abstract: Emotions have been shown to have a significant influence on the decision-making process of human beings and, thus, play an important role in intelligent behavior. As a means of providing similar intelligence, we are investigating the use of emotional agents in the decision-making process of a mobile robot. We propose a fuzzy logic model that captures the inherent uncertainty of emotions. The model is used to generate decisions based on both internal and external states and incorporates the use of sensory information to extract environmental conditions. In this way, the agent will react to a changing environment and can take an action according to a mixture of emotions generated by multiple states. As a first step towards addressing the complexity, the model deals with three negative emotions: fear, pain and anger, chosen because of their innate structure. In this paper, we discuss our fuzzy logic model and describe the implementation of an emotional agent on a small mobile robot in which sensory information is used to generate emotions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Bates. </author> <title> The Role of Emotion in Believable Agents. </title> <journal> Communications of the ACM, </journal> <volume> vol. 37, no. 7, </volume> <pages> pp. 122-125, </pages> <year> 1992. </year>
Reference: [2] <author> J. Bates, A. Bryan Loyall and W. Scott Reilly. </author> <title> An Architecture for Action, Emotion, and Social Behavior. </title> <type> Technical Report CMU-CS-92-144, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> May </month> <year> 1992. </year>
Reference: [3] <author> J. Bates, A. Bryan Loyall and W. Scott Reilly. </author> <title> Integerating Reactivity, Goals and Emotion in a Broad Agent. </title> <type> Technical Report CMU-CS-92-142, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> May </month> <year> 1992. </year>
Reference: [4] <author> R. C. Bolles and Fanselow M. S. </author> <title> A perceptual defensive recuperative model of fear and pain. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> Vol. 3, </volume> <pages> pp. 291-301, </pages> <year> 1980. </year>
Reference-contexts: Psychology, philosophy and cognitive science have been concerned with modeling the mind and its behavior for many years. Pain has been modeled by Schumacher and Velden [24] and again by Tayrer [28]. Bolles and Fanselow have proposed a model that shows the relation between fear and pain <ref> [4] </ref>. Price et al have developed a mathematical model that described emotions in terms of intensity and expectation [20]. With the interest in Artificial Intelligence (AI), several computer models have been proposed to simulate the human mind. <p> This will influence the behavior of the agent when he is E V R N E T Sensors Belief of the world Action Goals Emotion Expectation experiencing fear. In an unblocked condition, people tend to run; in a blocked condition they tend to freeze <ref> [4] </ref>. The external state physical damage is a measure of how much tissue damage the agent is experiencing. In contrast to the binary states, we determine a degree of physical damage, which influences the level of pain. These inputs are then normalized to certain degrees (e.g., a level from 1-10). <p> According to the level of tissue or physical damage, a level of pain is assigned. If the level of pain is greater than the level of fear or anger, then pain will inhibit both <ref> [4] </ref>. Pain reactions are not very interesting as Fanslow pointed out [4]. However, we describe them in terms of company. If many people are around and the pain is very high (i.e. serious ) then the agent will tend to ask for help. <p> According to the level of tissue or physical damage, a level of pain is assigned. If the level of pain is greater than the level of fear or anger, then pain will inhibit both <ref> [4] </ref>. Pain reactions are not very interesting as Fanslow pointed out [4]. However, we describe them in terms of company. If many people are around and the pain is very high (i.e. serious ) then the agent will tend to ask for help. This action also depends on whether the other agents are near or far from him. <p> A soldier wounded in an intense battle may continue to fight, even if the same wound experienced without fear would incapacitate him. A hormone called endorphins is responsible for this action. It is secreted into the system when the person feels an intense fear and thus inhibits pain <ref> [4] </ref>. The idea of one emotion inhibiting the other is based on goal priority. If a given condition threatens a high priority goal, then the agent will act on the emotion triggered by this threat. We assume that survival is one of the highest priority goals.
Reference: [5] <author> Antonio R. Damasio. </author> <title> Descartes error: emotion, reason, and the human brain. </title> <address> New York: G.P. Putnam, </address> <year> 1994. </year>
Reference-contexts: 1 Introduction Since the time of the Greeks, we have been conditioned to think that emotion is not a part of human intelligence and that it hinders our thoughts. Demasio refuted this claim with neurological evidence taken from several test cases <ref> [5] </ref>. Elliot, one of the cases under Demasios supervision, was observed to be stable and intelligent but had lost his emotional power, resulting in his inability to make basic decisions, to follow a schedule, or even to motivate himself to get dressed in the morning.
Reference: [6] <author> Michael Dyre. </author> <title> Emotions and their computations: three computer models. </title> <journal> Cognition and Emotion, </journal> <volume> Vol. 1, No. 3, </volume> <pages> pp. 323-347, </pages> <year> 1987. </year>
Reference-contexts: Many of the proposed emotional models represent significant milestones in the research on human emotions. Pfeifer offers a summary of AI emotional models from the early 1960s to the 1980s [19]. One such model was proposed by Frijda and Swagerman [8]. Dyre simulated a day dreamer <ref> [6] </ref>. An expert system was proposed as an alternative model for the emotional process in [23]. Japanese researchers have recently become interested in a system (e.g., robot) that can communicate with humans, and emotions are regarded as an important factor.
Reference: [7] <author> N. Frijda. </author> <title> The Emotions. </title> <publisher> Cambridge University Press: </publisher> <address> Cambridge, </address> <year> 1986. </year>
Reference: [8] <author> N. Frijda and J. Swagerman. </author> <title> Can Computers Feel? Theory and Design of an emotional System. </title> <journal> Cognition and Emotion, </journal> <volume> Vol. 1, </volume> <pages> pp. 235-57, </pages> <year> 1987. </year>
Reference-contexts: Many of the proposed emotional models represent significant milestones in the research on human emotions. Pfeifer offers a summary of AI emotional models from the early 1960s to the 1980s [19]. One such model was proposed by Frijda and Swagerman <ref> [8] </ref>. Dyre simulated a day dreamer [6]. An expert system was proposed as an alternative model for the emotional process in [23]. Japanese researchers have recently become interested in a system (e.g., robot) that can communicate with humans, and emotions are regarded as an important factor.
Reference: [9] <author> Daniel Goleman. </author> <title> Emotional Intelligence. </title> <publisher> Bantam Books: </publisher> <address> New York, </address> <year> 1995. </year>
Reference: [10] <author> Tim La Haye and Bob Philips. </author> <title> Anger is a choice. </title> <address> USA: </address> <publisher> Zondervan Publishing House, </publisher> <year> 1982. </year>
Reference-contexts: This was the prime reason for adding expectation to our model. Anger depends on multiple states, which Lahaye outlines as the following: memory of old experiences, temperature and body chemistry, personal desires, demands and expectations, positive and negative modeling of family origin, and finally, positive and negative relationships <ref> [10] </ref>. Normalize Inputs Brightness Level Sound Level State Alone, physical damage, blocked - Evaluate Expectations according to inputs Expectations Normalized inputs Stimulus Evaluate Stimulus according to the goals desirability Of all the above, we are modeling anger according to expectations only.
Reference: [11] <author> K. Inoue, K. Kawabata and H. Kobayashi. </author> <title> On a decision making system with emotion. </title> <booktitle> IEEE Int. Workshop on Robot and Human Communication,pp. </booktitle> <pages> 461-465, </pages> <year> 1996. </year>
Reference-contexts: An attempt was also made by Sugano and Ogata [27] to simulate the brain priority level through an electrically wired robot. A prototype of a decision-making process using emotion was developed by Inoue et al, using neural networks <ref> [11] </ref>. Stimulated by the Japanese work, U.S. researchers have also begun working in the area of emotions and believable agents [1,14]. Bates has been building a believable agent for his virtual world, the OZ project [2,3,21], using a model proposed by Ortony, Clore and Collins [18].
Reference: [12] <author> Carroll E. Izard. </author> <title> Human Emotions. </title> <publisher> Plenum Press: </publisher> <address> New York & London, </address> <year> 1977. </year>
Reference-contexts: Several inputs can trigger fear; our model uses the following: level of darkness, level of sound, and being alone or with others. The rationale is provided by Izard <ref> [12] </ref>, who suggests that we have an innate fear of darkness, being alone, and loud noises. Of course, a person can overcome these fears, but our model does not include a learning component. Rather, our model reacts as a child, experiencing innate emotions.
Reference: [13] <author> Joseph LeDoux. </author> <title> The Emotional Brain. </title> <publisher> Simon & Schuster:USA,1996. </publisher>
Reference: [14] <author> P. Maes. </author> <title> Artificial Life meets Entertainment: Lifelike Autonomous Agents. </title> <journal> Communications of the ACM. Special Issue on Novel Applications of AI, </journal> <year> 1995. </year>
Reference: [15] <author> E. Masuyama. </author> <title> A Number of Fundamental Emotions and Their Definitions. </title> <booktitle> IEEE International Workshop on Robot and Human Communication, </booktitle> <pages> pp. 156-161, </pages> <year> 1994. </year>
Reference-contexts: Japanese researchers have recently become interested in a system (e.g., robot) that can communicate with humans, and emotions are regarded as an important factor. As part of this focus, Masuyma formulated human emotions in terms of rules <ref> [15] </ref>. An attempt was also made by Sugano and Ogata [27] to simulate the brain priority level through an electrically wired robot. A prototype of a decision-making process using emotion was developed by Inoue et al, using neural networks [11].
Reference: [16] <author> Michael Mauldin. ChaterBots, TinyMuds, </author> <title> and the Turing Test Entering The Loebner Prize Competition. </title> <booktitle> Proceedings of the AAAI Conference, </booktitle> <year> 1994. </year>
Reference: [17] <author> M. Minsky. </author> <title> The Society of the Mind. </title> <institution> Simon and Schuster:New York, </institution> <year> 1986. </year>
Reference-contexts: Several psychologists have acknowledged the importance of emotions in the role of thinking and intelligent behavior. Indeed, Minsky concluded that, the question is not whether intelligent machines can have any emotions, but whether machines can be intelligent without any emotions <ref> [17] </ref>. As a means of providing such intelligence, we are investigating the use of emotional agents in the decision-making process of a mobile robot. Psychology, philosophy and cognitive science have been concerned with modeling the mind and its behavior for many years.
Reference: [18] <author> A. Ortony, G. Clore and A. Collins. </author> <title> The Cognitive Structure of Emotions. </title> <publisher> Cambridge University Press: </publisher> <address> Cambridge, </address> <year> 1988. </year>
Reference-contexts: Stimulated by the Japanese work, U.S. researchers have also begun working in the area of emotions and believable agents [1,14]. Bates has been building a believable agent for his virtual world, the OZ project [2,3,21], using a model proposed by Ortony, Clore and Collins <ref> [18] </ref>. Another model has been built by Velasquez [29]. These two models provide a reasonable starting point for building computer simulations of emotions; however, they describe only basic emotions and their reactions, not their interactions.
Reference: [19] <author> R. Pfeifer. </author> <booktitle> Artificial Intelligence Models of Emotions. Cognitive Perspectives on Emotion and Motivation. </booktitle> <pages> ,pp. 287-320, </pages> <year> 1988. </year>
Reference-contexts: With the interest in Artificial Intelligence (AI), several computer models have been proposed to simulate the human mind. Many of the proposed emotional models represent significant milestones in the research on human emotions. Pfeifer offers a summary of AI emotional models from the early 1960s to the 1980s <ref> [19] </ref>. One such model was proposed by Frijda and Swagerman [8]. Dyre simulated a day dreamer [6]. An expert system was proposed as an alternative model for the emotional process in [23].
Reference: [20] <author> Donald D. Price, James E. Barrell, and James J. Barrell. </author> <title> A Quantitative-Experiential Analysis of Human Emotions. </title> <journal> Motivation and Emotion, </journal> <volume> Vol. 9, No. 1, </volume> <year> 1985. </year>
Reference-contexts: Pain has been modeled by Schumacher and Velden [24] and again by Tayrer [28]. Bolles and Fanselow have proposed a model that shows the relation between fear and pain [4]. Price et al have developed a mathematical model that described emotions in terms of intensity and expectation <ref> [20] </ref>. With the interest in Artificial Intelligence (AI), several computer models have been proposed to simulate the human mind. Many of the proposed emotional models represent significant milestones in the research on human emotions. Pfeifer offers a summary of AI emotional models from the early 1960s to the 1980s [19].
Reference: [21] <author> W. Reilly and Joseph Bates. </author> <title> Building Emotional Agents. </title> <type> Technical Report CMU-CS-92-143, </type> <institution> Carnegie Mellon University:PA, </institution> <year> 1992. </year>
Reference: [22] <author> Stuart Russel and Peter Norvig. </author> <title> Artificial Intelligence A modern Approach. </title> <address> USA: </address> <publisher> Prentice-Hall Inc., </publisher> <year> 1995. </year>
Reference-contexts: These emotions were specifically chosen because of their innate structure and the fact that they tend to be constant through different social groups and cultures. 2.1 Framework The framework for our model is based on that of the Intelligent Agent (IA) <ref> [22] </ref>. We have expanded the IA framework to incorporate the emotional or the internal state features, as illustrated in Figure 1. The agents internal states are shown in the gray box. The solid lines represent relationships in our model, and the dashed lines represent those in the traditional model.
Reference: [23] <author> K. R. Scherer. </author> <title> Studying the emotion antecedent appraisal process: An expert system approach. </title> <journal> Cognition and Emotion, </journal> <volume> Vol. 7, </volume> <pages> pp. 325-55, </pages> <year> 1993. </year>
Reference-contexts: Pfeifer offers a summary of AI emotional models from the early 1960s to the 1980s [19]. One such model was proposed by Frijda and Swagerman [8]. Dyre simulated a day dreamer [6]. An expert system was proposed as an alternative model for the emotional process in <ref> [23] </ref>. Japanese researchers have recently become interested in a system (e.g., robot) that can communicate with humans, and emotions are regarded as an important factor. As part of this focus, Masuyma formulated human emotions in terms of rules [15].
Reference: [24] <author> R. Schumacher and M. Velden. Anxiety, </author> <title> pain experience and pain report: A signal-detection study. Perceptual and motor skills, </title> <journal> Vol. </journal> <volume> 58, </volume> <pages> pp. 339-349, </pages> <year> 1984. </year>
Reference-contexts: As a means of providing such intelligence, we are investigating the use of emotional agents in the decision-making process of a mobile robot. Psychology, philosophy and cognitive science have been concerned with modeling the mind and its behavior for many years. Pain has been modeled by Schumacher and Velden <ref> [24] </ref> and again by Tayrer [28]. Bolles and Fanselow have proposed a model that shows the relation between fear and pain [4]. Price et al have developed a mathematical model that described emotions in terms of intensity and expectation [20].
Reference: [25] <author> T. Shiida. </author> <title> An attempt to model emotions on a machine. Emotion and behavior: A system approach, </title> <journal> Vol. </journal> <volume> 2, </volume> <pages> pp. 275-287, </pages> <year> 1989. </year>
Reference: [26] <author> R. L. Solomon and J. D. Corbit. </author> <title> An opponent-process theory of motivation: I. Temporal dynamics of affect. </title> <journal> Psychological Review, </journal> <volume> Vol. 81, </volume> <pages> pp. 119-145, </pages> <year> 1974. </year>
Reference: [27] <author> Shigeki Sugano and Tesuya Ogata. </author> <title> Emergence of mind in robots for Human Interface - research methodology and robot model -. Proc. </title> <booktitle> International Conference on robotics and Automation IEEE, </booktitle> <month> April </month> <year> 1996. </year>
Reference-contexts: Japanese researchers have recently become interested in a system (e.g., robot) that can communicate with humans, and emotions are regarded as an important factor. As part of this focus, Masuyma formulated human emotions in terms of rules [15]. An attempt was also made by Sugano and Ogata <ref> [27] </ref> to simulate the brain priority level through an electrically wired robot. A prototype of a decision-making process using emotion was developed by Inoue et al, using neural networks [11]. Stimulated by the Japanese work, U.S. researchers have also begun working in the area of emotions and believable agents [1,14].
Reference: [28] <author> Stephen Tayrer (ed). </author> <title> Psychology, Psychiatry and Chronic Pain. Britain: </title> <type> Butterworth Heinemann, </type> <year> 1992. </year>
Reference-contexts: Psychology, philosophy and cognitive science have been concerned with modeling the mind and its behavior for many years. Pain has been modeled by Schumacher and Velden [24] and again by Tayrer <ref> [28] </ref>. Bolles and Fanselow have proposed a model that shows the relation between fear and pain [4]. Price et al have developed a mathematical model that described emotions in terms of intensity and expectation [20].
Reference: [29] <author> J. Velasquez. </author> <title> Modeling Emotions and Other Motivations in Synthetic Agents. </title> <booktitle> Proceedings of the AAAI Conference 1997, </booktitle> <pages> pp. 10-15, </pages> <year> 1997. </year>
Reference-contexts: Bates has been building a believable agent for his virtual world, the OZ project [2,3,21], using a model proposed by Ortony, Clore and Collins [18]. Another model has been built by Velasquez <ref> [29] </ref>. These two models provide a reasonable starting point for building computer simulations of emotions; however, they describe only basic emotions and their reactions, not their interactions. In general, the previous research discussed has not addressed the complexity of the human emotional system.
References-found: 29

