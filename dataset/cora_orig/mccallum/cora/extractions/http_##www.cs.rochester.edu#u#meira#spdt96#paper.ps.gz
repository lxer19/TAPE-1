URL: http://www.cs.rochester.edu/u/meira/spdt96/paper.ps.gz
Refering-URL: http://www.cs.rochester.edu/stats/oldmonths/1998.05/docs-name.html
Root-URL: 
Email: fmeira,leblanc,poulosg@cs.rochester.edu  
Title: Waiting Time Analysis and Performance Visualization in Carnival  
Author: Wagner Meira, Jr., Thomas J. LeBlanc, Alexandros Poulos 
Address: Rochester  
Affiliation: Department of Computer Science University of  
Abstract: Waiting time (where one processor is blocked while waiting for another) arises from a variety of sources in parallel programs, including communication, synchronization, load imbalance, and resource contention. Many tools can identify portions of the source code where waiting time arises and measure it during execution, but the programmer must infer the underlying cause of waiting time from other measurements. Carnival is a performance measurement and analysis tool that automates this inference process. Using traces of program executions, the tool identifies the differences in execution paths leading up to a synchronization point, and explains waiting time to the user in terms of those differences. It also supports several different types of performance profiles, which can be used to isolate and quantify important sources of waiting time. We present algorithms for characterizing waiting time in terms of execution paths, and describe implementations on the IBM SP2 and the SGI Challenge. We also present the Carnival user interface, and illustrate the functionality of the interface and the usefulness of waiting time analysis by identifying and explaining the sources of overhead in example applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> IBM AIX parallel environment, release 2.1. IBM Corporation, </institution> <address> Poughkeepsie, NY, </address> <year> 1994. </year>
Reference-contexts: These events are stored in a file for further processing. During execution, the instrumented executable utilizes the UTE trace facility [13] (which is implemented on top of IBM's AIX trace facility <ref> [1] </ref>) to generate a trace file containing information about the execution.
Reference: [2] <editor> Forgex 2.0 user's guide. </editor> <booktitle> Applied Parallel Research, </booktitle> <address> Placerville, CA, </address> <year> 1995. </year>
Reference-contexts: It is implemented using the Sage++ package from Indiana [9] and Tcl/Tk [12]. The implementation runs on the IBM SP2 [3] and supports parallel code generated by the Forge APR HPF compiler <ref> [2] </ref>. The compilation of HPF programs in this environment is a two-step process. Initially, the HPF code is translated by the Forge xhpf preprocessor into SPMD Fortran 77 code augmented with calls to a runtime library, which performs data exchanges and synchronization operations.
Reference: [3] <author> T. Agerwala, J. Martin, J. H. Mirza, D. Sadler, D. Dias, and M. Snir. </author> <title> Sp2 system architecture. </title> <type> Research Report RC 20012 (88066), </type> <institution> IBM Research Division, T.J. Watson Research Center, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: Our initial implementation of Carnival is targeted to data-parallel applications running on distributed memory machines using message passing for communication. It is implemented using the Sage++ package from Indiana [9] and Tcl/Tk [12]. The implementation runs on the IBM SP2 <ref> [3] </ref> and supports parallel code generated by the Forge APR HPF compiler [2]. The compilation of HPF programs in this environment is a two-step process.
Reference: [4] <author> Thomas E. Anderson and Edward D. Lazowska. Quartz: </author> <title> A tool for tuning parallel program performance. </title> <booktitle> In Proceedings ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 115-125, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Standard profiling techniques (such as gprof [11]) identify where the program spends the greatest percentage of its time, suggesting a focus for code optimizations. More recent profiling techniques designed specifically for parallel programs (such as normalized processor time profiling <ref> [4] </ref>) suggest code optimizations that have the most impact on parallel program performance. Critical path analysis [14] isolates the one execution path that dominates the running time of the program, ensuring that code optimizations along that path contribute to improved execution time.
Reference: [5] <author> Mark E. Crovella and Thomas J. LeBlanc. </author> <title> Performance debugging using parallel performance predicates. </title> <booktitle> In Proc. 3rd ACM/ONR Workshop on Parallel and Distributed Debugging, </booktitle> <pages> pages 140-150, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: There are many tools that present performance data and metrics, giving the user the flexibility to determine what data to observe and how to view the data. For example, predicate profiling <ref> [5] </ref> measures and displays categories of inefficiency that are meaningful to the user, offering a high-level view of any performance problems. Para-dyn [8] goes into greater detail, identifying individual performance bottlenecks in an execution and their location in the source code.
Reference: [6] <author> Mark E. Crovella and Thomas J. LeBlanc. </author> <title> Parallel performance prediction using lost cycles analysis. </title> <booktitle> In Proceedings of Supercomputing '94, </booktitle> <year> 1994. </year>
Reference-contexts: We are using user-defined (with compiler assistance) analytical models for steps in a characterization to build analytical models for waiting time based on lost cycles analysis <ref> [6] </ref>. These models will allow us to quantify the impact on waiting time of a change in the number of processors or problem size, and ultimately to predict accurately the running time of a program under varying conditions.
Reference: [7] <author> Helen Davis and John Hennessy. </author> <title> Characterizing the synchronization behavior of parallel programs. </title> <booktitle> In Proc. First PPEALS, </booktitle> <pages> pages 198-211, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: There are tools designed to measure the frequency of operations that produce waiting time, and other related statistics that help infer the cause of waiting time. For example, Davis and Hennessy <ref> [7] </ref> developed a tool to monitor synchronization events, including the frequency of synchronization, 1 Multiprogramming that occurs while a process is waiting is counted as waiting time. 2 1. main ()- 2. for (i=0; i&lt;100; i++) - 3. barrier (); 4. if (ProcID == 0) 5. for (k=0; k&lt;N; k++) -/*
Reference: [8] <author> Barton P. Miller et al. </author> <title> The Paradyn parallel performance measurement tool. </title> <journal> IEEE Computer, </journal> <volume> 28(11) </volume> <pages> 37-46, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: For example, predicate profiling [5] measures and displays categories of inefficiency that are meaningful to the user, offering a high-level view of any performance problems. Para-dyn <ref> [8] </ref> goes into greater detail, identifying individual performance bottlenecks in an execution and their location in the source code. The integrated Fortran D/Pablo tool [10] adds static information (e.g., data dependences, communication requirements) to the dynamic measurements, providing more context for the analysis.
Reference: [9] <author> F. Bodin et al. Sage++: </author> <title> an object-oriented toolkit and class library for building Fortran and C++ restructuring tools. </title> <booktitle> In Proc. 2nd Annual Object-Oriented Numerics Conference, </booktitle> <year> 1994. </year>
Reference-contexts: Our initial implementation of Carnival is targeted to data-parallel applications running on distributed memory machines using message passing for communication. It is implemented using the Sage++ package from Indiana <ref> [9] </ref> and Tcl/Tk [12]. The implementation runs on the IBM SP2 [3] and supports parallel code generated by the Forge APR HPF compiler [2]. The compilation of HPF programs in this environment is a two-step process.
Reference: [10] <author> Vikram S. Adve et al. </author> <title> An integrated compilation and performance analysis environment for data parallel programs. </title> <type> Technical Report CRPC-TR94513-S, </type> <institution> Rice University, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: Para-dyn [8] goes into greater detail, identifying individual performance bottlenecks in an execution and their location in the source code. The integrated Fortran D/Pablo tool <ref> [10] </ref> adds static information (e.g., data dependences, communication requirements) to the dynamic measurements, providing more context for the analysis. All of these tools assist the user in understanding performance phenomena, but do not automate the inference process linking an observation to a specific cause.
Reference: [11] <author> Susan L. Graham, P.B. Kessler, and M. Kirk McKusick. </author> <title> gprof: a call graph execution profiler. </title> <booktitle> In Proceedings SIGPLAN '82 Symp. on Compiler Construction, </booktitle> <pages> pages 120-126, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: Most performance metrics and tuning techniques are designed to assist the programmer in finding the most profitable opportunities for optimizations that reduce computation time, and only indirectly address waiting time. Standard profiling techniques (such as gprof <ref> [11] </ref>) identify where the program spends the greatest percentage of its time, suggesting a focus for code optimizations. More recent profiling techniques designed specifically for parallel programs (such as normalized processor time profiling [4]) suggest code optimizations that have the most impact on parallel program performance.
Reference: [12] <author> John K. Ousterhout. </author> <title> Tcl and Tk Toolkit. </title> <publisher> Addison Wes-ley, </publisher> <year> 1994. </year>
Reference-contexts: Our initial implementation of Carnival is targeted to data-parallel applications running on distributed memory machines using message passing for communication. It is implemented using the Sage++ package from Indiana [9] and Tcl/Tk <ref> [12] </ref>. The implementation runs on the IBM SP2 [3] and supports parallel code generated by the Forge APR HPF compiler [2]. The compilation of HPF programs in this environment is a two-step process. <p> time spent on communication operations. * barrier is the processing time associated with a barrier, excluding any waiting time. * waiting time is time spent blocked or idling due to synchronization or communication. * multiprogramming is time lost to another process due to multiprogramming. 1 The result is a Tcl/Tk <ref> [12] </ref> interface that presents both static and dynamic data. This visualization interface is discussed in more detail in Section 5. 3 Waiting Time Analysis Many of the overheads associated with parallelization ultimately manifest themselves as waiting time (WT); a processor is idle while it waits for another.
Reference: [13] <author> C. Eric Wu and Hubertus Franke. UTE: </author> <title> A unified trace environment for IBM SP systems. </title> <type> Technical Report RC 20048 (88654), </type> <institution> T. J. Watson Research Center, </institution> <address> York-town Heights, NY, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Each call to a library function generates an event that records the processor id, a scope identifier, the processing category (or processor state), and time of occurrence. These events are stored in a file for further processing. During execution, the instrumented executable utilizes the UTE trace facility <ref> [13] </ref> (which is implemented on top of IBM's AIX trace facility [1]) to generate a trace file containing information about the execution.
Reference: [14] <author> Cui-Qing Yang and Barton P. Miller. </author> <title> Critical path analysis for the execution of parallel and distributed programs. </title> <booktitle> In 8th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 366-373, </pages> <month> June </month> <year> 1988. </year> <month> 10 </month>
Reference-contexts: More recent profiling techniques designed specifically for parallel programs (such as normalized processor time profiling [4]) suggest code optimizations that have the most impact on parallel program performance. Critical path analysis <ref> [14] </ref> isolates the one execution path that dominates the running time of the program, ensuring that code optimizations along that path contribute to improved execution time.
References-found: 14

