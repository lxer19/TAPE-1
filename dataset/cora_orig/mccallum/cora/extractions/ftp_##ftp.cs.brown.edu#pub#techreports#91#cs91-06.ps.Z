URL: ftp://ftp.cs.brown.edu/pub/techreports/91/cs91-06.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-91-06.html
Root-URL: http://www.cs.brown.edu/
Title: Solving Time-Dependent Problems: A Decision-Theoretic Approach to Planning in Dynamic Environments  
Author: by Mark Boddy 
Degree: Thesis Submitted in partial fulfillment of the requirements for the Degree of Doctor of Philosophy in the  
Date: May 1991  
Affiliation: Department of Computer Science at Brown University.  
Abstract-found: 0
Intro-found: 0
Reference: [ Agogino et al., 1988 ] <author> A. M. Agogino, S. Srinivas, and K. Schneider. </author> <title> Multiple sensor expert system for diagnostic reasoning, monitoring, </title> <journal> and control of mechanical systems. Mechanical Systems and Signal Processing, </journal> <volume> 2(2) </volume> <pages> 165-185, </pages> <year> 1988. </year>
Reference-contexts: In addition, decision-theoretic deliberation scheduling frameworks have been proposed for computer vision [ Levitt et al., 1988 ] , industrial control <ref> [ Agogino et al., 1988, Ramamurthi and Agogino, 1988 ] </ref> , probabilistic inference using belief networks [ Breese and Horvitz, 1990 ] , sensor fusion [ Hager, 1988 ] , and queries in deductive databases [ Smith, 1989 ] .
Reference: [ Andersson, 1988 ] <author> Russell L. Andersson. </author> <title> A Robot Ping-Pong Player: Experiment in Real-Time Intelligent Control. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1988. </year>
Reference-contexts: That is where the work in this thesis comes in. One implemented system does deliberation scheduling for abstract reasoning in an extremely time-constrained domain: Andersson's controller for a ping-pong-playing 2 In other words, a "velocity-control" KA and a "goal-achieving" KA can be defined in the same system. 4 robot <ref> [ Andersson, 1988 ] </ref> solves special cases of exactly the kind of problems we are interested in. In particular, he deals with the issues of incremental modification of plans as more information becomes available, and computation of the best answer possible in the time available.
Reference: [ Barto et al., 1989 ] <author> Andrew G. Barto, R.S. Sutton, and C.J.C.H Watkins. </author> <title> Learning and sequential decision making. </title> <type> Technical Report 89-95, </type> <institution> University of Massachusetts at Amherst Department of Computer and Information Science, </institution> <year> 1989. </year>
Reference-contexts: An additional issue that would almost certainly have to be dealt with in doing this is the explicit allocation of deliberation time for projection. Some other possible directions for further work include designing a system that learns policies for deliberation scheduling (using an approach similar to <ref> [ Barto et al., 1989 ] </ref> ), automating the calculation of expected utility from performance profiles, as in Section 2.5.3, and extending the start we have made on providing a general framework for constructing complex anytime decision procedures from simpler ones (Section 2.4.3). 170
Reference: [ Bellman, 1957 ] <author> R.E. Bellman. </author> <title> Dynamic Programming. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1957. </year>
Reference-contexts: Many of these problems have their roots in planning for large-scale industrial operations (e.g., capital investment or inventory management). The techniques employed for solving these problems include various method methods for solving linear programming problems [ Papadimitriou and Steiglitz, 1981, Dantzig, 1963 ] , and dynamic programming <ref> [ Bellman, 1957 ] </ref> . Some of these techniques are relevant to the kinds of optimization problems we address in deliberation scheduling. <p> Time passes, events happen, and the internal state of the system changes due to the deliberation performed. Then the deliberation scheduler makes another decision, and another, and so on. There are standard methods in decision analysis for analyzing sequential decision 40 problems <ref> [ Ross, 1983, Bellman, 1957, Raiffa, 1968 ] </ref> . <p> Choosing the decision d that maximizes the value of the sequence of n states starting in s i involves finding V n (s i ) = max [R (s i ; d) + V n1 ((s i ; d))] This can be solved, at least in principle. Dynamic programming <ref> [ Bellman, 1957 ] </ref> is frequently employed for the solution of this type of problem. <p> Each such instant thus provides new information (a new state) and requires a new allocation decision. Following methods used in operations research, we might try using dynamic programming <ref> [ Bellman, 1957, Ross, 1983 ] </ref> to solve our optimization problem. 6 Dynamic programming involves caching the optimal answer to a series of subproblems of increasing size, until finally we can determine the optimal answer to the full problem.
Reference: [ Berzuini et al., 1989 ] <author> C. Berzuini, R. Bellazzi, and S. Quaglini. </author> <title> Temporal reasoning with probabilities. </title> <booktitle> In Proceedings of the Fifth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 14-21, </pages> <year> 1989. </year>
Reference: [ Boddy and Dean, 1989 ] <author> Mark Boddy and Thomas Dean. </author> <title> Solving time-dependent planning problems. </title> <booktitle> In IJCAI89, </booktitle> <year> 1989. </year>
Reference-contexts: These expectations include performance profiles that encode expectations on the effects of allocating time to specific anytime decision procedures. 1 Anytime decision procedures implement anytime algorithms <ref> [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] </ref> . 2 Using expectation-driven iterative refinement to construct solutions to time-dependent problems restricts a very general problem (deciding what to think about and when to act) to a somewhat simpler one: allocating the next increment of time to one of a <p> already mentioned several application areas in which the decision-theoretic control of reasoning has been explored, including planning [ Elkan, 1990, Drummond and Bresina, 1990 ] , game-tree search [ Russell and Wefald, 1989a, Hansson and Mayer, 1988 ] , medical decision making [ Horvitz, 1988 ] , and robot control <ref> [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] </ref> . <p> A time-dependent problem consists of: * A set of event types: T = ft 1 ; t 2 ; : : :g. 1 Anytime decision procedures implement anytime algorithms <ref> [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] </ref> . 16 * A set of action types A T defining the types of events under the system's control. * A set of histories H 2 T fi&lt; . <p> Clearly, which of these algorithms is most appropriate for a particular application depends in part on what kind of "approximate sort" is be most useful; the analogy with our case is evident. Expectations In previous work <ref> [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] </ref> , we have compiled performance profiles that tracked the expected value of (some parameter of) the answer returned by a given anytime decision procedure as a function of deliberation time.
Reference: [ Bollinger and Duffie, 1988 ] <author> John G. Bollinger and Neil A. Duffie. </author> <title> Computer Control of Machines and Processes. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1988. </year>
Reference-contexts: a somewhat different perspective (see, for example, [ Stankovic, 1988 ] ). 1.4.2 Control Theory The canonical control problem starts with a controller (system) and a plant (environment): the controller can affect the evolving state of the plant in fixed ways and has access to limited information about that state <ref> [ Dorf, 1989, Bollinger and Duffie, 1988 ] </ref> . <p> Calculating expected utility from performance profiles is not always so easy. Let us look again at the projectile-weapon controller from Section 2.4.3, and this time, let the target be mobile rather than stationary. Information on the target's trajectory is 14 This is similar to gain scheduling in control theory <ref> [ Bollinger and Duffie, 1988 ] </ref> , in which the controller can switch among a set of linear control laws, depending on which one best approximates an optimal controller, given the current state of the system. 43 Deliberation time V Elapsed time V Elapsed time a) c) gathered by a tracking
Reference: [ Breese and Fehling, 1988 ] <author> John S. Breese and Michael R. Fehling. </author> <title> Decision-theoretic control of problem solving: </title> <booktitle> Principles and architecture. In Proceedings of the Fourth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <year> 1988. </year>
Reference: [ Breese and Horvitz, 1990 ] <author> J. S. Breese and E. J. Horvitz. </author> <title> Ideal reformulation of belief networks. </title> <booktitle> In Proceedings of the Sixth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 64-72, </pages> <year> 1990. </year>
Reference-contexts: In addition, decision-theoretic deliberation scheduling frameworks have been proposed for computer vision [ Levitt et al., 1988 ] , industrial control [ Agogino et al., 1988, Ramamurthi and Agogino, 1988 ] , probabilistic inference using belief networks <ref> [ Breese and Horvitz, 1990 ] </ref> , sensor fusion [ Hager, 1988 ] , and queries in deductive databases [ Smith, 1989 ] .
Reference: [ Breese, 1990 ] <author> J. S. Breese. </author> <title> Construction of belief and decision networks. </title> <type> Technical Report 30, </type> <institution> Rockwell International Science Center, </institution> <year> 1990. </year> <month> 171 </month>
Reference-contexts: This tradeoff also suggests that there may some incentive to construct composite procedures for deliberation at run time, in that the best sequence of steps may depend on the time available. A somewhat different example of series combination from the one analyzed here has been proposed by Breese. In <ref> [ Breese, 1990 ] </ref> , he incrementally constructs influence diagrams [ Shachter, 1986 ] corresponding to partial decision models, and then solves them approximately. 11 The time allocated to both model construction and finding an approximate solution is determined using expectations on the effect of a given allocation on the expected
Reference: [ Brooks, 1985 ] <author> Rodney A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 864, </pages> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1985. </year>
Reference: [ Carraway et al., 1989 ] <author> R. L. Carraway, T. L. Morin, and H. Moskowitz. </author> <title> Generalized dynamic programming for stochastic combinatorial optimization. </title> <journal> Operations Research, </journal> <volume> 37 </volume> <pages> 819-829, </pages> <year> 1989. </year>
Reference-contexts: Dynamic programming, especially some of the more recent work on extending dynamic programming to stochastic problems (e.g., <ref> [ Ross, 1983, Carraway et al., 1989 ] </ref> ), is more generally applicable to deliberation scheduling. Deliberation scheduling is a sequential decision problem of exactly the sort that dynamic programming was formulated to address.
Reference: [ Chapman and Agre, 1987 ] <author> David Chapman and Phil Agre. </author> <title> Abstract reasoning as emergent from concrete activity. </title> <editor> In Michael P. Georgeff and Amy L. Lansky, editors, </editor> <booktitle> The 1986 Workshop on Reasoning About Actions and Plans, </booktitle> <pages> pages 411-424. </pages> <address> Morgan-Kaufman, </address> <year> 1987. </year>
Reference: [ Cohen et al., 1988 ] <author> P. R. Cohen, M. L. Greenberg, D. M. Hart, and A. E. Howe. </author> <title> Trial by fire: Understanding the design requirements for agents in complex environments. </title> <journal> AI Magazine, </journal> <volume> 9(1) </volume> <pages> 34-48, </pages> <year> 1988. </year>
Reference-contexts: Hanks and Firby accomplish this by interfacing a fairly traditional high-level planner with low-level reactive behaviors used as primitive actions [ Firby, 1987, Hanks and Firby, 1990 ] . The Phoenix project <ref> [ Cohen et al., 1988, Howe et al., 1990 ] </ref> uses an agent architecture that integrates planning and acting by implementing a two-level system: the higher-level "cognitive" component modifies the agent's behavior at irregular intervals, while a "reflexive" system provides lower-level but more timely reactions to changes in the environment.
Reference: [ Cooper, 1987 ] <author> Gregory F. Cooper. </author> <title> Probabilistic inference using belief networks is np-hard. </title> <institution> Memo KSL-87-27, Stanford Knowledge Systems Laboratory, </institution> <year> 1987. </year>
Reference-contexts: We then calculate the posterior distribution for the value of some random variable or variables. Despite recent advances in the construction and evaluation of belief nets as a method for probabilistic inference [ Pearl, 1988 ] , this problem is NP-hard <ref> [ Cooper, 1987 ] </ref> . A wide variety of methods has been developed for approximate evaluation of belief nets (i.e., providing bounds on the posterior distribution, rather than the exact distribution). <p> For a given set of deliberation allocations, a procedural-dependency graph can be viewed as a belief net [ Pearl, 1988 ] in which the arcs represent probabilistic dependencies and the corresponding distributions are given by the performance profiles. Results obtained in calculating posterior distributions from belief nets <ref> [ Cooper, 1987 ] </ref> suggest that "solving" procedural-dependency graphs in a similar way that takes undirected cycles into account is likely to be difficult. This correspondence also suggests that some of the considerable existing work on belief nets might be of use in analyzing complex procedural-dependency graphs. <p> Relaxing assumption 2 produces a situation in which the system has only uncertain information on the types and times of occurrence of conditions. One consequence of this more general formulation is that projection may be very expensive. General probabilistic reasoning is known to be intractable <ref> [ Cooper, 1987 ] </ref> .
Reference: [ Dantzig, 1963 ] <author> G. B. Dantzig. </author> <title> Linear Programming and Extensions. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1963. </year>
Reference-contexts: Many of these problems have their roots in planning for large-scale industrial operations (e.g., capital investment or inventory management). The techniques employed for solving these problems include various method methods for solving linear programming problems <ref> [ Papadimitriou and Steiglitz, 1981, Dantzig, 1963 ] </ref> , and dynamic programming [ Bellman, 1957 ] . Some of these techniques are relevant to the kinds of optimization problems we address in deliberation scheduling.
Reference: [ Dean and Boddy, 1988 ] <author> Thomas Dean and Mark Boddy. </author> <title> An analysis of time-dependent planning. </title> <booktitle> In Proceedings AAAI-88, </booktitle> <pages> pages 49-54. </pages> <publisher> AAAI, </publisher> <year> 1988. </year>
Reference-contexts: These expectations include performance profiles that encode expectations on the effects of allocating time to specific anytime decision procedures. 1 Anytime decision procedures implement anytime algorithms <ref> [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] </ref> . 2 Using expectation-driven iterative refinement to construct solutions to time-dependent problems restricts a very general problem (deciding what to think about and when to act) to a somewhat simpler one: allocating the next increment of time to one of a <p> Chapter 3, it is sometimes possible to allocate large blocks of time at once when the benefit of running one anytime decision procedure can be shown to be greater than for any other. 1.3.3 Flexible Computations An alternative approach is to assume that deliberation is performed by anytime decision procedures <ref> [ Dean and Boddy, 1988 ] </ref> (also called flexible computations in [ Horvitz, basis for resource-bounded reasoning, see [ Horvitz, 1987 ] 5 For a more detailed discussion of the work presented in this section, see [ Dean, 1989 ] . 7 1987 ] ), and that time can be allocated <p> already mentioned several application areas in which the decision-theoretic control of reasoning has been explored, including planning [ Elkan, 1990, Drummond and Bresina, 1990 ] , game-tree search [ Russell and Wefald, 1989a, Hansson and Mayer, 1988 ] , medical decision making [ Horvitz, 1988 ] , and robot control <ref> [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] </ref> . <p> A time-dependent problem consists of: * A set of event types: T = ft 1 ; t 2 ; : : :g. 1 Anytime decision procedures implement anytime algorithms <ref> [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] </ref> . 16 * A set of action types A T defining the types of events under the system's control. * A set of histories H 2 T fi&lt; . <p> Clearly, which of these algorithms is most appropriate for a particular application depends in part on what kind of "approximate sort" is be most useful; the analogy with our case is evident. Expectations In previous work <ref> [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] </ref> , we have compiled performance profiles that tracked the expected value of (some parameter of) the answer returned by a given anytime decision procedure as a function of deliberation time. <p> Unbounded step (the movie "The Seventh Sign"|Armageddon ensues if a deadline is not met.) Our original assumption in <ref> [ Dean and Boddy, 1988 ] </ref> was that combining time-cost and utility for a particular response would yield a function that had a single maximum for expected utility (e.g., Figure 2.9c).
Reference: [ Dean and Kanazawa, 1988 ] <author> Thomas Dean and Keiji Kanazawa. </author> <title> Probabilistic temporal reasoning. </title> <booktitle> In Proceedings AAAI-88, </booktitle> <pages> pages 524-528. </pages> <publisher> AAAI, </publisher> <year> 1988. </year>
Reference: [ Dean and Siegle, 1990 ] <author> T. Dean and G. Siegle. </author> <title> An approach to reasoning about continuous change for applications in planning. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 132-137, </pages> <year> 1990. </year>
Reference-contexts: We make no commitment on how these states are represented. States can include calculated quantities (the level of water in the bathtub, given when the faucet was turned on and how far) as in <ref> [ Hendrix, 1973, Dean and Siegle, 1990 ] </ref> , or propositions whose presence or absence is determined by something like strips rules [ Fikes and Nilsson, 1971 ] .
Reference: [ Dean et al., 1987 ] <author> Thomas L. Dean, R. James Firby, and David P. Miller. </author> <title> The forbin paper. </title> <type> Technical Report 576, </type> <institution> Yale University Department of Computer Science, </institution> <year> 1987. </year>
Reference-contexts: More recently, planners have been built that can take into account the passage of time as the system acts and the possibility of other events occurring, e.g., <ref> [ Wilkins, 1984, Vere, 1983, Dean et al., 1987 ] </ref> . When researchers tried using these planners on robots, they ran into problems resulting from the "top-down" nature of the resulting architecture. The kind of information available from sensors is very different from the symbolic representations the classical planners manipulate. <p> ] have constructed an architecture for planning and acting in which the upper levels iteratively modify a set of situated control rules for the lowest level to follow. [ Zweben et al., 1990 ] present an anytime algorithm for rescheduling, which is a useful planning capability in many domains (e.g., <ref> [ Dean et al., 1987, Wilkins, 1989 ] </ref> ). The enormous advantage to these proposals from our point of view is that these planning methods can be used directly in a solution of a time-dependent problem constructed using expectation-driven iterative refinement.
Reference: [ Dean, 1989 ] <author> Thomas Dean. </author> <title> Decision-theoretic control of inference for time-critical applications. </title> <type> Technical Report CS-89-44, </type> <institution> Brown University Department of Computer Science, </institution> <year> 1989. </year>
Reference-contexts: An alternative approach is to assume that deliberation is performed by anytime decision procedures [ Dean and Boddy, 1988 ] (also called flexible computations in [ Horvitz, basis for resource-bounded reasoning, see [ Horvitz, 1987 ] 5 For a more detailed discussion of the work presented in this section, see <ref> [ Dean, 1989 ] </ref> . 7 1987 ] ), and that time can be allocated in values drawn from a continuous range (this is inevitably an approximation). Our motivations for using anytime decision procedures and the consequences of that choice are discussed in detail in Chapter 2.
Reference: [ Dorf, 1989 ] <author> Richard C. Dorf. </author> <title> Modern Control Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year> <month> 172 </month>
Reference-contexts: a somewhat different perspective (see, for example, [ Stankovic, 1988 ] ). 1.4.2 Control Theory The canonical control problem starts with a controller (system) and a plant (environment): the controller can affect the evolving state of the plant in fixed ways and has access to limited information about that state <ref> [ Dorf, 1989, Bollinger and Duffie, 1988 ] </ref> .
Reference: [ Drummond and Bresina, 1990 ] <author> Mark Drummond and John Bresina. </author> <title> Anytime syn-thetic projection: Maximizing the probability of goal satisfaction. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 138-144, </pages> <year> 1990. </year>
Reference-contexts: In contrast, we have pursued a more empirical course in trying to find approximate solutions to the kind of deliberation-scheduling problems that arise in controlling robots. 1.3.4 Applications We have already mentioned several application areas in which the decision-theoretic control of reasoning has been explored, including planning <ref> [ Elkan, 1990, Drummond and Bresina, 1990 ] </ref> , game-tree search [ Russell and Wefald, 1989a, Hansson and Mayer, 1988 ] , medical decision making [ Horvitz, 1988 ] , and robot control [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] .
Reference: [ Einav, 1990 ] <author> David Einav. </author> <title> Computationally-optimal real-resource strategies for independent, uninterruptible methods. </title> <booktitle> In Proceedings of the Sixth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 73-81, </pages> <year> 1990. </year>
Reference-contexts: only on the total time spent deliberating, but does not work well for a more complicated set of deadlines (e.g., the robot and the conveyor belt). 5 One of the problems with allocating deliberation time in discrete increments is that it is easy to wind up with a combinatorial problem <ref> [ Einav, 1990 ] </ref> . This was part of our motivation in adopting the use of anytime decision procedures. If continuous behavior is a reasonable approximation, then deliberation scheduling is no longer a combinatorial problem, though it may still be computationally expensive for other reasons.
Reference: [ Elkan, 1990 ] <author> Charles Elkan. </author> <title> Incremental, approximate planning. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 145-150, </pages> <year> 1990. </year>
Reference-contexts: In contrast, we have pursued a more empirical course in trying to find approximate solutions to the kind of deliberation-scheduling problems that arise in controlling robots. 1.3.4 Applications We have already mentioned several application areas in which the decision-theoretic control of reasoning has been explored, including planning <ref> [ Elkan, 1990, Drummond and Bresina, 1990 ] </ref> , game-tree search [ Russell and Wefald, 1989a, Hansson and Mayer, 1988 ] , medical decision making [ Horvitz, 1988 ] , and robot control [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] .
Reference: [ Etzioni, 1989 ] <author> Oren Etzioni. </author> <title> Tractable decision-analytic control. </title> <booktitle> In First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 114-125. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Sproull [ 1977 ] applies this model to a system for planning travel itineraries, though he is more concerned with the use of decision theory to guide planning choices. In <ref> [ Etzioni, 1989 ] </ref> , the deliberative chunks are called "methods." Each method has a fixed cost.
Reference: [ Farmer et al., 1984 ] <author> D. Farmer, T. Toffoli, and S. Wolfram. </author> <title> Cellular Automata. </title> <publisher> North Holland, </publisher> <year> 1984. </year>
Reference-contexts: successively added to or removed from a set representing an approximate answer so as to reduce the difference between that set and a set representing the correct answer The analysis of discrete iterations is closely tied to work on connectionist models [ Hinton and Sejnowski, 1983 ] , cellular automata <ref> [ Farmer et al., 1984 ] </ref> , and VLSI system design [ Mead and Conway, 1980 ] . 2.4.2 Performance Profiles In order to allocate deliberation time effectively, we use expectations on the behavior of the anytime decision procedures available.
Reference: [ Fikes and Nilsson, 1971 ] <author> Richard Fikes and Nils J. Nilsson. </author> <title> Strips: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 189-208, </pages> <year> 1971. </year>
Reference-contexts: Many of these systems employ world models that abstract away the passage of time and the occurrence of events other than the problem-solver's own actions (e.g., the blocksworld) <ref> [ Fikes and Nilsson, 1971, Sacerdoti, 1977, Tate, 1977 ] </ref> . More recently, planners have been built that can take into account the passage of time as the system acts and the possibility of other events occurring, e.g., [ Wilkins, 1984, Vere, 1983, Dean et al., 1987 ] . <p> States can include calculated quantities (the level of water in the bathtub, given when the faucet was turned on and how far) as in [ Hendrix, 1973, Dean and Siegle, 1990 ] , or propositions whose presence or absence is determined by something like strips rules <ref> [ Fikes and Nilsson, 1971 ] </ref> . Events with uncertain outcomes can be modeled by leaving the type of the event uncertain until the event occurs, after which the type is determined (not necessarily known by the system) and in turn determines the resulting state (s).
Reference: [ Firby, 1987 ] <author> R. James Firby. </author> <title> An investigation in reactive planning in complex domains. </title> <booktitle> In Proceedings AAAI-87, </booktitle> <pages> pages 196-201. </pages> <publisher> AAAI, </publisher> <year> 1987. </year>
Reference-contexts: We are left with the problem of synchronizing the high-level reasoner with the lower levels controlling the robot. Hanks and Firby accomplish this by interfacing a fairly traditional high-level planner with low-level reactive behaviors used as primitive actions <ref> [ Firby, 1987, Hanks and Firby, 1990 ] </ref> .
Reference: [ Georgeff and Ingrand, 1989 ] <author> Michael P. Georgeff and Francois F. Ingrand. </author> <title> Decision-making in an embedded reasoning system. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 972-978. IJCAI, </pages> <year> 1989. </year>
Reference-contexts: Some of these systems are flexible enough that deliberation scheduling could be added to them. For example, we could add a deliberation-scheduling KA to a PRS system (they already have "metalevel" KAs <ref> [ Georgeff and Ingrand, 1989 ] </ref> ). But this does not answer the question of what these meta-level KAs should look like or what kinds of computation they are used to control. That is where the work in this thesis comes in.
Reference: [ Georgeff et al., 1987 ] <author> M. P. Georgeff, A. L. Lansky, and M. J. Schoppers. </author> <title> Reasoning and planning in dynamic domains: an experiment with a mobile robot. </title> <type> Technical Report 380, </type> <institution> SRI International, </institution> <year> 1987. </year>
Reference-contexts: Hayes-Roth's BB1 [ Hayes-Roth et al., 1989 ] is a blackboard architecture for systems that are responsive to environmental changes, but perform abstract reasoning when time permits. The Procedural Reasoning System (PRS) <ref> [ Georgeff et al., 1987 ] </ref> provides what amounts to a programming language for complex robot architectures.
Reference: [ Good, 1976 ] <author> I. J. </author> <title> Good. Good Thinking. </title> <publisher> University of Minnesota Press, </publisher> <year> 1976. </year>
Reference-contexts: In addition, we have only limited knowledge of the effects of allocating time to the decision procedures used for deliberation. Probability is a simple, consistent, and well-understood way to represent and reason about these uncertainties <ref> [ Pearl, 1988, Good, 1976 ] </ref> . In addition, there is a large body of standard techniques for deriving probability distributions from statistical data [ Green and Margerison, 1978 ] .
Reference: [ Green and Margerison, 1978 ] <author> J. R. Green and D. Margerison. </author> <title> Statistical Treatment of Experimental Data. </title> <publisher> Elsevier, </publisher> <address> New York, NY, </address> <year> 1978. </year>
Reference-contexts: Probability is a simple, consistent, and well-understood way to represent and reason about these uncertainties [ Pearl, 1988, Good, 1976 ] . In addition, there is a large body of standard techniques for deriving probability distributions from statistical data <ref> [ Green and Margerison, 1978 ] </ref> . Since the solutions we provide and the expectations we use are both grounded in the real world (or at the least in some simulated environment), these techniques will be useful. <p> w 0 = 1= 2 0 , w = w i&gt;0 = 1= 2 , and define the weighted means: x = 0 w i x i P n = P n w 0 +nw P n 0 w i w 0 t 0 +w 1 t i Then, following <ref> [ Green and Margerison, 1978 ] </ref> , the MSE estimator for X (t) is: ^x (t) = 0 w i x i 0 w i P n P n P n P n P n i ( 0 w i t i ) 2 =( 0 w i ) = x
Reference: [ Green, 1969 ] <author> C. C. Green. </author> <title> Application of theorem proving to problem solving. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <year> 1969. </year>
Reference-contexts: Constructing systems for abstract problem solving and planning has been an active research area in artificial intelligence (AI) for some time (e.g., <ref> [ Green, 1969 ] </ref> ). Many of these systems employ world models that abstract away the passage of time and the occurrence of events other than the problem-solver's own actions (e.g., the blocksworld) [ Fikes and Nilsson, 1971, Sacerdoti, 1977, Tate, 1977 ] .
Reference: [ Haddawy, 1990 ] <author> Peter Haddawy. </author> <title> Time, chance, and action. </title> <booktitle> In Proceedings of the Sixth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 147-154, </pages> <year> 1990. </year> <month> 173 </month>
Reference: [ Hageman and Young, 1981 ] <author> L.A. Hageman and D.M. Young. </author> <title> Applied Iterative Meth--ods. </title> <publisher> Academic Press, </publisher> <year> 1981. </year>
Reference-contexts: Such "well-behaved" anytime algorithms are ubiquitous in computer science. We discuss some examples below. Numerical Approximation The study of methods for iterative approximation is a large and active area in numerical analysis <ref> [ Tompkins and Wilson, 1969, Hageman and Young, 1981 ] </ref> . Two common techniques are Taylor series approximations (e.g., computing or e) and iterative finite-element methods.
Reference: [ Hager, 1988 ] <author> Gregory D. Hager. </author> <title> Active Reduction of Uncertainty in Multi-Sensor Systems. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <month> July </month> <year> 1988. </year>
Reference-contexts: In addition, decision-theoretic deliberation scheduling frameworks have been proposed for computer vision [ Levitt et al., 1988 ] , industrial control [ Agogino et al., 1988, Ramamurthi and Agogino, 1988 ] , probabilistic inference using belief networks [ Breese and Horvitz, 1990 ] , sensor fusion <ref> [ Hager, 1988 ] </ref> , and queries in deductive databases [ Smith, 1989 ] . <p> It is usually possible to characterize the convergence properties of these methods, including bounds on the error in the answer resulting from a given number of iterations [ Varga, 1962 ] . Finite-element methods are not confined to traditionally "mathematical" problems. Hager <ref> [ Hager, 1988 ] </ref> applies finite-element methods to calculate the most probable interpretation for uncertain sensor data, as well as to determine what new readings can best reduce the uncertainty in that interpretation. Probablistic Algorithms An algorithm can be "probabilistic" in a number of senses.
Reference: [ Hanks and Firby, 1990 ] <author> Steve Hanks and R. James Firby. </author> <title> Issues and architectures for planning and execution. </title> <booktitle> In Proceedings of the DARPA Workshop on Innovative Approaches to Planning, Scheduling, and Control. DARPA, </booktitle> <year> 1990. </year>
Reference-contexts: We are left with the problem of synchronizing the high-level reasoner with the lower levels controlling the robot. Hanks and Firby accomplish this by interfacing a fairly traditional high-level planner with low-level reactive behaviors used as primitive actions <ref> [ Firby, 1987, Hanks and Firby, 1990 ] </ref> .
Reference: [ Hanks, 1990 ] <author> Steven Hanks. </author> <title> Projecting Plans for Uncertain Worlds. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> January </month> <year> 1990. </year>
Reference-contexts: The most common responses to this fact have been either to limit the expressivity of the language [ Berzuini et al., 1989, Dean and Kanazawa, 1988, Haddawy, 1990 ] , or to use the structure of the application being addressed to constrain the inference that is performed <ref> [ Wellman, 1988, Hanks, 1990 ] </ref> . It would be interesting to extend the model analyzed in this chapter to include uncertain information, and then to see what combination of these approaches might prove to be effective. <p> The most common responses to this fact have been either to limit the expressivity of the language [ Berzuini et al., 1989, Dean and Kanazawa, 1988, Haddawy, 1990 ] or to use the structure of the application being addressed to constrain the inference performed <ref> [ Wellman, 1988, Hanks, 1990 ] </ref> . It would be interesting to extend the examples analyzed in this thesis to include uncertain information and to see what combination of these approaches might prove effective.
Reference: [ Hansson and Mayer, 1988 ] <author> Othar Hansson and Andrew Mayer. </author> <title> The optimality of sat-isficing solutions. </title> <booktitle> In Proceedings of the Fourth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <year> 1988. </year>
Reference-contexts: course in trying to find approximate solutions to the kind of deliberation-scheduling problems that arise in controlling robots. 1.3.4 Applications We have already mentioned several application areas in which the decision-theoretic control of reasoning has been explored, including planning [ Elkan, 1990, Drummond and Bresina, 1990 ] , game-tree search <ref> [ Russell and Wefald, 1989a, Hansson and Mayer, 1988 ] </ref> , medical decision making [ Horvitz, 1988 ] , and robot control [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] . <p> Using decision-analytic methods to determine how (and whether) to expand search trees is currently an active research area <ref> [ Russell and Wefald, 1989b, Hansson and Mayer, 1988 ] </ref> .
Reference: [ Harel, 1987 ] <author> David Harel. </author> <title> ALGORITHMICS: </title> <booktitle> The Spirit of Computing. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: Probablistic Algorithms An algorithm can be "probabilistic" in a number of senses. Those most directly useful as anytime algorithms are the Monte Carlo algorithms <ref> [ Harel, 1987 ] </ref> , in which some 23 parameter is estimated with increasing confidence as the result of drawing repeated samples at random from the search space. The iterative nature of the resulting algorithms is not their only advantage. <p> There are two main types of Monte Carlo methods. In the first, the algorithm provides an answer that is increasingly likely to be correct as further samples are drawn. An example of this type is primality-testing using witnesses <ref> [ Harel, 1987 ] </ref> . This algorithm exploits the fact that with probability approximately 1 2 , any of the numbers smaller than the number being tested is a witness to its being composite: finding a witness establishes that the number is not prime.
Reference: [ Hayes-Roth et al., 1989 ] <author> Barbara Hayes-Roth, Richard Washington, Rattikorn Hewett, Michael Hewett, and Adam Seiver. </author> <title> Intelligent monitoring and control. </title> <booktitle> In Proceedings IJCAI 11, </booktitle> <pages> pages 243-249. IJCAI, </pages> <year> 1989. </year>
Reference-contexts: Hayes-Roth's BB1 <ref> [ Hayes-Roth et al., 1989 ] </ref> is a blackboard architecture for systems that are responsive to environmental changes, but perform abstract reasoning when time permits. The Procedural Reasoning System (PRS) [ Georgeff et al., 1987 ] provides what amounts to a programming language for complex robot architectures.
Reference: [ Heckerman et al., 1989 ] <author> David E. Heckerman, John S. Breese, and Eric J. Horvitz. </author> <title> The compilation of decision models. </title> <booktitle> In UW89, </booktitle> <pages> pages 162-173, </pages> <year> 1989. </year>
Reference: [ Heckerman, 1985 ] <author> David Heckerman. </author> <title> Probabilistic interpretations for mycin certainty factors. </title> <booktitle> In Proceedings of the 1985 AAAI/IEEE Sponsored Workshop on Uncertainty and Probability in Artificial Intelligence, </booktitle> <year> 1985. </year>
Reference-contexts: A wide variety of methods has been developed for approximate evaluation of belief nets (i.e., providing bounds on the posterior distribution, rather than the exact distribution). Several of these methods are anytime algorithms in the sense that the bounds get smaller for additional iterations of the basic method <ref> [ Horvitz et al., 1989, Heckerman, 1985, Henrion, 1986 ] </ref> .
Reference: [ Hendrix, 1973 ] <author> Gary Hendrix. </author> <title> Modeling simultaneous actions and continuous processes. </title> <journal> Artificial Intelligence, </journal> <volume> 4 </volume> <pages> 145-180, </pages> <year> 1973. </year>
Reference-contexts: We make no commitment on how these states are represented. States can include calculated quantities (the level of water in the bathtub, given when the faucet was turned on and how far) as in <ref> [ Hendrix, 1973, Dean and Siegle, 1990 ] </ref> , or propositions whose presence or absence is determined by something like strips rules [ Fikes and Nilsson, 1971 ] .
Reference: [ Henrion, 1984 ] <author> M. Henrion. </author> <title> The Value of Knowing How Little You Know. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1984. </year>
Reference-contexts: Further work on problems in this class is likely to be application-driven. Given our demonstration that problems with this structure are amenable to solutions using expectation-driven iterative refinement, the next step appears to be for 13 Henrion has shown <ref> [ Henrion, 1984 ] </ref> that there are cases where using means rather than distributions does no damage at all (e.g., if utility is a linear function of the random variables). 136 someone to try applying it to some "real world" problem, or to let us know about the problem so that <p> foremost, what 2 This is one of the advantages of using anytime decision procedures: the resulting scheduling problems are more likely to be easy to solve. 167 kinds of simplifications can we make, and at what cost? We need to model such things as Henrion's expected value of including uncertainty <ref> [ Henrion, 1984 ] </ref> , the value of gathering additional information, and the cost of excluding some kinds of expectations from the decision model (e.g., expectations on future events).
Reference: [ Henrion, 1986 ] <author> M. Henrion. </author> <title> Propagating uncertainty by logic sampling in bayes' networks. </title> <booktitle> In Proceedings of the Second Workshop on Uncertainty in Artificial Intelligence, </booktitle> <year> 1986. </year>
Reference-contexts: A wide variety of methods has been developed for approximate evaluation of belief nets (i.e., providing bounds on the posterior distribution, rather than the exact distribution). Several of these methods are anytime algorithms in the sense that the bounds get smaller for additional iterations of the basic method <ref> [ Horvitz et al., 1989, Heckerman, 1985, Henrion, 1986 ] </ref> .
Reference: [ Hinton and Sejnowski, 1983 ] <author> G.E. Hinton and T.J. Sejnowski. </author> <title> Optimal perceptual inference. </title> <booktitle> In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 448-453, </pages> <year> 1983. </year> <month> 174 </month>
Reference-contexts: Elements are successively added to or removed from a set representing an approximate answer so as to reduce the difference between that set and a set representing the correct answer The analysis of discrete iterations is closely tied to work on connectionist models <ref> [ Hinton and Sejnowski, 1983 ] </ref> , cellular automata [ Farmer et al., 1984 ] , and VLSI system design [ Mead and Conway, 1980 ] . 2.4.2 Performance Profiles In order to allocate deliberation time effectively, we use expectations on the behavior of the anytime decision procedures available.
Reference: [ Horvitz et al., 1988 ] <author> Eric J. Horvitz, John S. Breese, </author> <title> and Max Henrion. </title> <journal> Decision the-ory in expert systems and artificial intelligence. Journal of Approximate Reasoning, </journal> <year> 1988. </year>
Reference-contexts: Breese and Fehling [ 1988 ] provide an abstract architecture for the decision-theoretic control of an autonomous agent, including reasoning about tradeoffs among planning, acting, and gathering information. <ref> [ Horvitz et al., 1988 ] </ref> provide a survey of the application of decision theory to AI more generally, and points out some areas in which further research might be most fruitful. 1.4 Related Work in Other Areas The kinds of optimization problems we address are similar to problems addressed in
Reference: [ Horvitz et al., 1989 ] <author> E. J. Horvitz, H. J. Suermondt, and G. F. Cooper. </author> <title> Bounded conditioning: Flexible inference for decisions under scarce resources. </title> <booktitle> In Proceedings of the Fifth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <year> 1989. </year>
Reference-contexts: A wide variety of methods has been developed for approximate evaluation of belief nets (i.e., providing bounds on the posterior distribution, rather than the exact distribution). Several of these methods are anytime algorithms in the sense that the bounds get smaller for additional iterations of the basic method <ref> [ Horvitz et al., 1989, Heckerman, 1985, Henrion, 1986 ] </ref> .
Reference: [ Horvitz, 1987 ] <author> Eric J. Horvitz. </author> <title> Reasoning about beliefs and actions under computational resource constraints. </title> <booktitle> In Proceedings of the Third Workshop on Uncertainty in Artificial Intelligence, </booktitle> <year> 1987. </year>
Reference-contexts: running one anytime decision procedure can be shown to be greater than for any other. 1.3.3 Flexible Computations An alternative approach is to assume that deliberation is performed by anytime decision procedures [ Dean and Boddy, 1988 ] (also called flexible computations in [ Horvitz, basis for resource-bounded reasoning, see <ref> [ Horvitz, 1987 ] </ref> 5 For a more detailed discussion of the work presented in this section, see [ Dean, 1989 ] . 7 1987 ] ), and that time can be allocated in values drawn from a continuous range (this is inevitably an approximation).
Reference: [ Horvitz, 1988 ] <author> Eric J. Horvitz. </author> <title> Reasoning under varying and uncertain resource constraints. </title> <booktitle> In Proceedings AAAI-88, </booktitle> <pages> pages 111-116. </pages> <publisher> AAAI, </publisher> <year> 1988. </year>
Reference-contexts: arise in controlling robots. 1.3.4 Applications We have already mentioned several application areas in which the decision-theoretic control of reasoning has been explored, including planning [ Elkan, 1990, Drummond and Bresina, 1990 ] , game-tree search [ Russell and Wefald, 1989a, Hansson and Mayer, 1988 ] , medical decision making <ref> [ Horvitz, 1988 ] </ref> , and robot control [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] . <p> Thus a single anytime decision procedure might have several performance profiles, each providing information on the distribution of a different parameter or for a different distribution over the possible values of its inputs. Which of these profiles is most appropriate or useful depends on the task at hand. Horvitz <ref> [ Horvitz, 1988 ] </ref> discusses various algorithms for sorting an array viewed as anytime algorithms (he calls them flexible computations). Each algorithm makes repeated changes to the array, each one bringing the array closer to being sorted. What is meant by "closer" differs for each algorithm, however. <p> Russell and Wefald's work on game-tree search [ Russell and Wefald, 1989b ] includes a time cost that is inversely related to the distance to a deadline and is independent of the action taken. In Horvitz's work on high-stakes medical decision-making <ref> [ Horvitz, 1988 ] </ref> , overall utility is the sum of an object-related or intrinsic utility that is independent of time and an inference cost. For a more comprehensive survey of related work on time-dependent problems, see Section 1.4.
Reference: [ Howe et al., 1990 ] <author> A. E. Howe, D. M. Hart, and P. R. Cohen. </author> <title> Addressing real-time constraints in the design of autonomous agents. </title> <type> Technical Report 90-06, </type> <institution> Department of Computer and Information Science, University of Massachusetts, </institution> <year> 1990. </year>
Reference-contexts: Hanks and Firby accomplish this by interfacing a fairly traditional high-level planner with low-level reactive behaviors used as primitive actions [ Firby, 1987, Hanks and Firby, 1990 ] . The Phoenix project <ref> [ Cohen et al., 1988, Howe et al., 1990 ] </ref> uses an agent architecture that integrates planning and acting by implementing a two-level system: the higher-level "cognitive" component modifies the agent's behavior at irregular intervals, while a "reflexive" system provides lower-level but more timely reactions to changes in the environment.
Reference: [ Kaelbling, 1988 ] <author> Leslie P. Kaelbling. </author> <title> Goals as parallel program specifications. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 60-65, </pages> <year> 1988. </year>
Reference: [ Kanazawa and Dean, 1989 ] <author> K. Kanazawa and T. Dean. </author> <title> A model for projection and action. </title> <booktitle> In Proceedings IJCAI 11, </booktitle> <pages> pages 985-990. IJCAI, </pages> <year> 1989. </year>
Reference: [ King and Spachis, 1980 ] <author> John R. King and Alexander S. Spachis. </author> <title> Scheduling: Bibliography and review. </title> <journal> International Journal of Physical Distribution and Materials Management, </journal> <volume> 10(3) </volume> <pages> 105-132, </pages> <year> 1980. </year>
Reference-contexts: In addition, consider what has happened in the work on scheduling: there are a myriad of separate problems, distinguished by minor differences in problem characteristics, for which the difficulty of providing a scheduler (and the best way of doing so) varies enormously <ref> [ King and Spachis, 1980 ] </ref> .
Reference: [ Korf, 1987 ] <author> Richard E. Korf. </author> <title> Real-time path planning. </title> <booktitle> In Proceedings DARPA Knowledge-Based Planning Workshop, </booktitle> <year> 1987. </year>
Reference-contexts: The procedure used to construct these paths performs a heuristic search, similar to an algorithm described in <ref> [ Korf, 1987 ] </ref> . The algorithm we use is basically A fl [ Nilsson, 1980 ] . Nodes in the search tree correspond to locations, paths to branches from the root to a leaf. We use the remaining distance to the destination as a heuristic evaluation function.
Reference: [ Korf, 1990 ] <author> Richard Korf. </author> <title> Real-time heuristic search. </title> <journal> Artificial Intelligence, </journal> <volume> 42(2) </volume> <pages> 189-212, </pages> <year> 1990. </year>
Reference-contexts: Heuristic Search Algorithms for heuristic search, in particular those employing variable lookahead and fast evaluation functions, can be cast as anytime algorithms <ref> [ Pearl, 1985, Korf, 1990 ] </ref> . 24 Each iteration expands another node or nodes in the search tree, possibly causing a change in the ranking of possible next moves or in the best known solution.
Reference: [ Kraus et al., 1990 ] <author> S. Kraus, M. Nirkhe, and D. Perlis. </author> <title> Planning and acting in deadline situations. </title> <booktitle> In Proceedings of the 1990 Workshop on Planning in Complex Domains. AAAI, </booktitle> <year> 1990. </year>
Reference-contexts: All we need to do is gather some statistics on their performance in a particular domain. In a different vein, <ref> [ Kraus et al., 1990 ] </ref> present a planning system in which the time spent planning is explicitly accounted for using step-logics in which the time required for an inference is associated with that inference.
Reference: [ Laffey et al., 1988 ] <author> T. J. Laffey, P. A. Cox, J. L. Schmidt, S. M. Kao, and Y. </author> <title> Read. Real-time knowledge-based systems. </title> <journal> AI Magazine, </journal> <volume> 9(1) </volume> <pages> 27-45, </pages> <year> 1988. </year> <month> 175 </month>
Reference-contexts: Computer systems used to control manufacturing processes, for example, are specially designed to guarantee response within some time bound. As the environments to which these systems are applied grow in complexity, interest has grown in applying artificial intelligence techniques, including expert systems [ Mok, 1989 ] , and planning <ref> [ Laffey et al., 1988 ] </ref> . This work, however, addresses only part of the problem we are interested in: guaranteeing a maximum response time is not sufficient.
Reference: [ Lawler et al., 1985 ] <author> E.L. Lawler, J.K. Lenstra, A.H.G. Rinnooy Kan, </author> <title> and D.B. Shmoys. The Travelling Salesman Problem. </title> <publisher> Wiley, </publisher> <address> New York, NY, </address> <year> 1985. </year>
Reference-contexts: It has been shown empirically that for large (100-city) tours, these algorithms average within about 8% of the optimal tour length when run to completion <ref> [ Lawler et al., 1985 ] </ref> . 4 The procedure 2-opt in Figure 4.9 exchanges pairs of edges, always making the exchange so as to maximize the decrease in tour length. Given an existing ordering, 2 opt tries all possible pairs of edges to remove.
Reference: [ Lesser and Corkill, 1983 ] <author> V.R. Lesser and D.D. Corkill. </author> <title> The distributed vehicle monitoring testbed: A tool for investigating distributed problem solving networks. </title> <journal> AI Magazine, </journal> <volume> 4 </volume> <pages> 15-33, </pages> <year> 1983. </year>
Reference-contexts: Finding the optimal allocations and executing the procedures consecutively yields a composite procedure that provides optimal answers across a wide range of available times. The procedure is not, however, a particularly good anytime decision procedure: rather, it is similar to what Lesser calls a design-to-time algorithm <ref> [ Lesser and Corkill, 1983 ] </ref> . If the composite procedure is interrupted unexpectedly, it may not have run the aiming procedure at all.
Reference: [ Lesser et al., 1988 ] <author> V.R. Lesser, J. Pavlin, and E. Durfee. </author> <title> Approximate processing in real-time problem solving. </title> <journal> AI Magazine, </journal> <volume> 9 </volume> <pages> 49-62, </pages> <year> 1988. </year>
Reference: [ Levitt et al., 1988 ] <author> Tod Levitt, Thomas Binford, Gil Ettinger, and Patrice Gelband. </author> <title> Utility-based control for computer vision. </title> <booktitle> In Proceedings of the Fourth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <year> 1988. </year>
Reference-contexts: In addition, decision-theoretic deliberation scheduling frameworks have been proposed for computer vision <ref> [ Levitt et al., 1988 ] </ref> , industrial control [ Agogino et al., 1988, Ramamurthi and Agogino, 1988 ] , probabilistic inference using belief networks [ Breese and Horvitz, 1990 ] , sensor fusion [ Hager, 1988 ] , and queries in deductive databases [ Smith, 1989 ] .
Reference: [ Lin and Kernighan, 1973 ] <author> S. Lin and B. W. Kernighan. </author> <title> An effective heuristic for the travelling salesman problem. </title> <journal> Operations Research, </journal> <volume> 21 </volume> <pages> 498-516, </pages> <year> 1973. </year>
Reference-contexts: In this section, we present and analyze an anytime decision procedure for tour improvement. Expected tour length is the parameter of the resulting tour we seek to minimize and for which we construct a performance profile. Edge-exchange algorithms <ref> [ Lin and Kernighan, 1973 ] </ref> produce tours that are progressively closer to optimal by exchanging small sets of edges (typically 2 or 3) so that the length of the overall tour decreases.
Reference: [ Locke, 1986 ] <author> C. Douglass Locke. </author> <title> Best-Effort Decision-Making for Real-Time Scheduling. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <month> May </month> <year> 1986. </year>
Reference-contexts: More recent work in the real-time-systems community has gone beyond simple guarantees in various ways, including using models for tasks similar to anytime decision procedures [ Shih et al., 1989 ] and meta-level control that modifies scheduling behavior based on the current situation <ref> [ Ramamritham et al., 1987, Locke, 1986 ] </ref> .
Reference: [ Lumelsky and Stepanov, 1987 ] <author> V. J. Lumelsky and A. A. Stepanov. </author> <title> Path planning strategies for a point mobile automaton moving amidst unknown obstacles of arbitrary shape. </title> <journal> Algorithmica, </journal> <year> 1987. </year>
Reference-contexts: as it turns out more significantly, having a planned path means not bumping into obstacles, which saves a lot of time. 1 To see this, think of blocked intersections: one must travel almost up to the intersection to discover that it is blocked. 2 This routine, based on Lumelsky's work <ref> [ Lumelsky and Stepanov, 1987 ] </ref> , uses a compass to head towards the goal, working around any obstacles encountered in a consistent direction (e.g., clockwise). 3 In a more general class of problems, some value might be attached to visiting a particular location and the robot must decide whether or
Reference: [ Manohar, 1988 ] <author> S. Manohar. </author> <title> Supercomputing with vlsi. </title> <type> Technical Report CS-88-14, </type> <institution> Brown University Department of Computer Science, </institution> <year> 1988. </year>
Reference-contexts: Two common techniques are Taylor series approximations (e.g., computing or e) and iterative finite-element methods. Finite-element methods can be used for approximating conti-nous functions [ Varga, 1962 ] , including the solutions to differential equations <ref> [ Manohar, 1988 ] </ref> . It is usually possible to characterize the convergence properties of these methods, including bounds on the error in the answer resulting from a given number of iterations [ Varga, 1962 ] . Finite-element methods are not confined to traditionally "mathematical" problems.
Reference: [ McDermott, 1982 ] <author> Drew V. McDermott. </author> <title> A temporal logic for reasoning about processes and plans. </title> <journal> Cognitive Science, </journal> <volume> 6 </volume> <pages> 101-155, </pages> <year> 1982. </year>
Reference-contexts: To represent the occurrence of processes having a finite duration, we define events corresponding to the beginning and ending of those processes. 3 Alternatively, U could be defined on the set of external states. 4 An active history set is very similar to what McDermott calls a chronset <ref> [ McDermott, 1982 ] </ref> . 17 t ^ t For a given value of ^ t , we refer to the current active histories H ^ t . We say that the history that eventually results is realized, and denote this realized history by h fl .
Reference: [ Mead and Conway, 1980 ] <author> C.A. Mead and M.A. Conway. </author> <title> Introduction to VLSI Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1980. </year>
Reference-contexts: answer so as to reduce the difference between that set and a set representing the correct answer The analysis of discrete iterations is closely tied to work on connectionist models [ Hinton and Sejnowski, 1983 ] , cellular automata [ Farmer et al., 1984 ] , and VLSI system design <ref> [ Mead and Conway, 1980 ] </ref> . 2.4.2 Performance Profiles In order to allocate deliberation time effectively, we use expectations on the behavior of the anytime decision procedures available. Ultimately, what we want to know is the expected effect of a particular allocation on the utility of the system's behavior.
Reference: [ Mok, 1989 ] <author> Aloysius P. Mok. </author> <title> Formal analysis of real-time equational rule-based systems. </title> <booktitle> In Proceedings of the Real-Time Systems Symposium. IEEE, </booktitle> <year> 1989. </year>
Reference-contexts: Computer systems used to control manufacturing processes, for example, are specially designed to guarantee response within some time bound. As the environments to which these systems are applied grow in complexity, interest has grown in applying artificial intelligence techniques, including expert systems <ref> [ Mok, 1989 ] </ref> , and planning [ Laffey et al., 1988 ] . This work, however, addresses only part of the problem we are interested in: guaranteeing a maximum response time is not sufficient.
Reference: [ Nilsson, 1980 ] <author> Nils J. Nilsson. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga Publishing Company, </publisher> <year> 1980. </year>
Reference-contexts: The procedure used to construct these paths performs a heuristic search, similar to an algorithm described in [ Korf, 1987 ] . The algorithm we use is basically A fl <ref> [ Nilsson, 1980 ] </ref> . Nodes in the search tree correspond to locations, paths to branches from the root to a leaf. We use the remaining distance to the destination as a heuristic evaluation function.
Reference: [ Papadimitriou and Steiglitz, 1981 ] <author> Christos H. Papadimitriou and Kenneth Steiglitz. </author> <title> Combinatorial Optimization. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1981. </year>
Reference-contexts: Many of these problems have their roots in planning for large-scale industrial operations (e.g., capital investment or inventory management). The techniques employed for solving these problems include various method methods for solving linear programming problems <ref> [ Papadimitriou and Steiglitz, 1981, Dantzig, 1963 ] </ref> , and dynamic programming [ Bellman, 1957 ] . Some of these techniques are relevant to the kinds of optimization problems we address in deliberation scheduling. <p> We are minimizing a linear function over a convex polytope, and thus any local minimum is also a global minimum <ref> [ Papadimitriou and Steiglitz, 1981 ] </ref> . 2 4.9.2 Proof that Sched-2 is optimal From Section 4.6.2, g (S; ffi 0 ) is the expected length of the improved tour S 0 , given ffi 0 units spent on improving tour S. ff fl g (S; ffi 0 )=k is the
Reference: [ Pearl, 1985 ] <author> Judea Pearl. </author> <title> Heuristics. </title> <publisher> Addison-Wesley, </publisher> <year> 1985. </year> <month> 176 </month>
Reference-contexts: Heuristic Search Algorithms for heuristic search, in particular those employing variable lookahead and fast evaluation functions, can be cast as anytime algorithms <ref> [ Pearl, 1985, Korf, 1990 ] </ref> . 24 Each iteration expands another node or nodes in the search tree, possibly causing a change in the ranking of possible next moves or in the best known solution.
Reference: [ Pearl, 1988 ] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <address> Morgan-Kaufman, Los Altos, California, </address> <year> 1988. </year>
Reference-contexts: In addition, we have only limited knowledge of the effects of allocating time to the decision procedures used for deliberation. Probability is a simple, consistent, and well-understood way to represent and reason about these uncertainties <ref> [ Pearl, 1988, Good, 1976 ] </ref> . In addition, there is a large body of standard techniques for deriving probability distributions from statistical data [ Green and Margerison, 1978 ] . <p> We then calculate the posterior distribution for the value of some random variable or variables. Despite recent advances in the construction and evaluation of belief nets as a method for probabilistic inference <ref> [ Pearl, 1988 ] </ref> , this problem is NP-hard [ Cooper, 1987 ] . A wide variety of methods has been developed for approximate evaluation of belief nets (i.e., providing bounds on the posterior distribution, rather than the exact distribution). <p> But the dependencies represented by undirected cycles will not taken into account. For a given set of deliberation allocations, a procedural-dependency graph can be viewed as a belief net <ref> [ Pearl, 1988 ] </ref> in which the arcs represent probabilistic dependencies and the corresponding distributions are given by the performance profiles.
Reference: [ Raiffa, 1968 ] <author> Howard Raiffa. </author> <title> Decision Analysis: Introductory Lectures on Choices Under Uncertainty. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1968. </year>
Reference-contexts: results of its decisions to allocate deliberation time. 1.3.1 Why Use Decision Theory? Much of the work on deliberation scheduling has employed decision theory. 3 Probability and decision theory are methods for dealing with uncertain information and outcomes on the basis of a small set of axioms concerning rational behavior <ref> [ Raiffa, 1968 ] </ref> . If you accept the axioms, decision theory provides a powerful set of tools for modelling and evaluating decision making under uncertainty. <p> The main point we take from decision theory is that calculating the expected utility resulting from the decisions made provides a consistent basis for evaluating decision making under uncertainty <ref> [ Raiffa, 1968, von Neumann and Morgenstern, 1947 ] </ref> . This is how we evaluate strategies for deliberation scheduling: an optimal deliberation scheduler maximizes the expected utility of its decisions, given what it knows about the environment and the effect of those allocations. 4 3 Not all of it, however. <p> Time passes, events happen, and the internal state of the system changes due to the deliberation performed. Then the deliberation scheduler makes another decision, and another, and so on. There are standard methods in decision analysis for analyzing sequential decision 40 problems <ref> [ Ross, 1983, Bellman, 1957, Raiffa, 1968 ] </ref> . <p> Suppose that you are offered instead the certainty of gaining the value v fl p. The expected values are the same. Risk-neutral behavior will find no preference between the lottery and the certain gain. Risk-averse behavior would be to prefer the certain gain <ref> [ Raiffa, 1968 ] </ref> .
Reference: [ Ramadge and Wonham, 1989 ] <author> Peter Ramadge and Murray Wonham. </author> <title> The control of discrete event systems. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 77(1) </volume> <pages> 81-98, </pages> <year> 1989. </year>
Reference-contexts: The research presented in this thesis addresses an issue that work on intelligent control will inevitably face: how to synchronize high-level, abstract computation with low-level control and changes occurring in the environment. In discrete-event control <ref> [ Ramadge and Wonham, 1989 ] </ref> , the plant is a system evolving over time through the occurrence of a sequence of events. The controller's influence over the plant is limited to restricting what events may follow certain other events.
Reference: [ Ramamritham et al., 1987 ] <author> Krithi Ramamritham, John A. Stankovic, and Wei Zhao. </author> <title> Meta-level control in distributed real-time systems. </title> <booktitle> In International Conference on Distributed Computer Systems, </booktitle> <year> 1987. </year>
Reference-contexts: More recent work in the real-time-systems community has gone beyond simple guarantees in various ways, including using models for tasks similar to anytime decision procedures [ Shih et al., 1989 ] and meta-level control that modifies scheduling behavior based on the current situation <ref> [ Ramamritham et al., 1987, Locke, 1986 ] </ref> .
Reference: [ Ramamurthi and Agogino, 1988 ] <author> K. Ramamurthi and A. M. Agogino. </author> <title> Real time expert system for fault-tolerant supervisory control. </title> <booktitle> In 1988 ASME International Computers in Engineering Conference, </booktitle> <pages> pages 333-340, </pages> <year> 1988. </year>
Reference-contexts: In addition, decision-theoretic deliberation scheduling frameworks have been proposed for computer vision [ Levitt et al., 1988 ] , industrial control <ref> [ Agogino et al., 1988, Ramamurthi and Agogino, 1988 ] </ref> , probabilistic inference using belief networks [ Breese and Horvitz, 1990 ] , sensor fusion [ Hager, 1988 ] , and queries in deductive databases [ Smith, 1989 ] .
Reference: [ Robert, 1986 ] <author> F. Robert. </author> <title> Discrete Iterations: A Metric Study. </title> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: Symbolic processing in general can be viewed as the manipulation of finite sets (of bindings, constraints, entities, etc.). The study of discrete iterations <ref> [ Robert, 1986 ] </ref> investigates the behavior of iterated functions over finite sets. Algorithms that operate over sets "converge" in terms of the membership of the set in question.
Reference: [ Rosenschein and Kaelbling, 1987 ] <author> Stan Rosenschein and Leslie Pack Kaelbling. </author> <title> The synthesis of digital machines with provable epistemic properties. </title> <editor> In Joseph Y. Halpern, editor, </editor> <booktitle> Theoretical Aspects of Reasoning About Knowledge, Proceedings of the 1986 Conference, </booktitle> <pages> pages 83-98. </pages> <address> Morgan-Kaufman, </address> <year> 1987. </year>
Reference: [ Ross, 1983 ] <author> Sheldon Ross. </author> <title> Introduction to Stochastic Dynamic Programming. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1983. </year>
Reference-contexts: Dynamic programming, especially some of the more recent work on extending dynamic programming to stochastic problems (e.g., <ref> [ Ross, 1983, Carraway et al., 1989 ] </ref> ), is more generally applicable to deliberation scheduling. Deliberation scheduling is a sequential decision problem of exactly the sort that dynamic programming was formulated to address. <p> to information available in the system's internal state (i.e., known to the system), but there is no such limitation on the information included in the decision model by which the system's performance is judged. 2.5.1 Sequential Decision Problems Constructing a deliberation-scheduling policy can be viewed as a sequential decision problem <ref> [ Ross, 1983 ] </ref> . Deliberation time is allocated in discrete increments, not necessarily of a fixed size. At the start of each increment, the deliberation scheduler provides a decision. Time passes, events happen, and the internal state of the system changes due to the deliberation performed. <p> Time passes, events happen, and the internal state of the system changes due to the deliberation performed. Then the deliberation scheduler makes another decision, and another, and so on. There are standard methods in decision analysis for analyzing sequential decision 40 problems <ref> [ Ross, 1983, Bellman, 1957, Raiffa, 1968 ] </ref> . <p> The recursive definition of the optimization problem for this case is V n (s i ) = max [R (s i ; d) + s j 2S Stochastic dynamic programming <ref> [ Ross, 1983 ] </ref> is a solution methodology for problems of this sort. Constructing a deliberation-scheduling policy using stochastic dynamic programming involves caching optimal decisions for increasingly longer sequences of states, starting in any of the states in S. <p> The basic decision to be made is made repeatedly: for each increment of time, which of the available decision procedures will be run? This is a sequential decision problem of a form commonly addressed in operations research <ref> [ Ross, 1983 ] </ref> . <p> Each such instant thus provides new information (a new state) and requires a new allocation decision. Following methods used in operations research, we might try using dynamic programming <ref> [ Bellman, 1957, Ross, 1983 ] </ref> to solve our optimization problem. 6 Dynamic programming involves caching the optimal answer to a series of subproblems of increasing size, until finally we can determine the optimal answer to the full problem.
Reference: [ Russell and Wefald, 1989a ] <author> Stuart J. Russell and Eric H. Wefald. </author> <title> On optimal game-tree search using rational meta-reasoning. </title> <booktitle> In Proceedings IJCAI 11, </booktitle> <pages> pages 334-340. IJCAI, </pages> <year> 1989. </year>
Reference-contexts: The utility of a particular inference step is defined in terms of its effect on the eventual choice of action and the state in which the action is executed. This model is applied to game-tree search, in which a deliberative "chunk" corresponds to expanding the children of a node <ref> [ Russell and Wefald, 1989a ] </ref> or just evaluating a single additional child of some node [ Russell, 1990 ] . <p> course in trying to find approximate solutions to the kind of deliberation-scheduling problems that arise in controlling robots. 1.3.4 Applications We have already mentioned several application areas in which the decision-theoretic control of reasoning has been explored, including planning [ Elkan, 1990, Drummond and Bresina, 1990 ] , game-tree search <ref> [ Russell and Wefald, 1989a, Hansson and Mayer, 1988 ] </ref> , medical decision making [ Horvitz, 1988 ] , and robot control [ Dean and Boddy, 1988, Boddy and Dean, 1989 ] .
Reference: [ Russell and Wefald, 1989b ] <author> Stuart J. Russell and Eric H. </author> <title> Wefald. </title> <booktitle> Principles of metar-easoning. In First International Conference on Principles of Knowledge Representation and Reasoning. </booktitle> <publisher> Morgan-Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Etzioni shows that problems involving multiple methods applied to a single goal can be solved inexpensively, but that allowing multiple goals makes the problem intractable. In <ref> [ Russell and Wefald, 1989b ] </ref> , the computation to be controlled is modeled as a sequence of "inference steps" leading to the performance of an action. <p> Using decision-analytic methods to determine how (and whether) to expand search trees is currently an active research area <ref> [ Russell and Wefald, 1989b, Hansson and Mayer, 1988 ] </ref> . <p> Locke [ 1986 ] is interested in constructing schedules of tasks when there is a value attached to completing a task as close as possible to an intended time. There is no notion of task utility apart from the completion time. Russell and Wefald's work on game-tree search <ref> [ Russell and Wefald, 1989b ] </ref> includes a time cost that is inversely related to the distance to a deadline and is independent of the action taken.
Reference: [ Russell, 1989 ] <author> Stuart J. Russell. </author> <title> Execution architectures and compilation. </title> <booktitle> In Proceedings IJCAI 11, </booktitle> <pages> pages 15-20. IJCAI, </pages> <year> 1989. </year>
Reference: [ Russell, 1990 ] <author> Stuart Russell. </author> <title> Fine-grained decision-theoretic search control. </title> <booktitle> In Proceedings of the Sixth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 436-442, </pages> <year> 1990. </year>
Reference-contexts: This model is applied to game-tree search, in which a deliberative "chunk" corresponds to expanding the children of a node [ Russell and Wefald, 1989a ] or just evaluating a single additional child of some node <ref> [ Russell, 1990 ] </ref> . This work assumes that the cost of inference can all be pushed into a "time cost" that is a function only of the number of inferential steps and actions taken so far.
Reference: [ Sacerdoti, 1977 ] <author> Earl Sacerdoti. </author> <title> A Structure for Plans and Behavior. </title> <publisher> American Else-vier Publishing Company, Inc., </publisher> <year> 1977. </year> <month> 177 </month>
Reference-contexts: Many of these systems employ world models that abstract away the passage of time and the occurrence of events other than the problem-solver's own actions (e.g., the blocksworld) <ref> [ Fikes and Nilsson, 1971, Sacerdoti, 1977, Tate, 1977 ] </ref> . More recently, planners have been built that can take into account the passage of time as the system acts and the possibility of other events occurring, e.g., [ Wilkins, 1984, Vere, 1983, Dean et al., 1987 ] .
Reference: [ Shachter, 1986 ] <author> Ross D. Shachter. </author> <title> Evaluating influence diagrams. </title> <journal> Operations Re--search, </journal> <volume> 34(6) </volume> <pages> 871-882, </pages> <month> November/December </month> <year> 1986. </year>
Reference-contexts: A somewhat different example of series combination from the one analyzed here has been proposed by Breese. In [ Breese, 1990 ] , he incrementally constructs influence diagrams <ref> [ Shachter, 1986 ] </ref> corresponding to partial decision models, and then solves them approximately. 11 The time allocated to both model construction and finding an approximate solution is determined using expectations on the effect of a given allocation on the expected utility of the final decision.
Reference: [ Shekhar and Dutta, 1989 ] <author> S. Shekhar and S. Dutta. </author> <title> Minimizing response times in real time planning. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 972-978. IJCAI, </pages> <year> 1989. </year>
Reference-contexts: This is how we evaluate strategies for deliberation scheduling: an optimal deliberation scheduler maximizes the expected utility of its decisions, given what it knows about the environment and the effect of those allocations. 4 3 Not all of it, however. See for example <ref> [ Shekhar and Dutta, 1989 ] </ref> . 4 For a more detailed discussion of the theoretical and practical advantages of decision theory as a 6 1.3.2 Discrete Deliberation Scheduling A line of work running back to [ Simon and Kadane, 1975 ] views deliberation time as being quantized into chunks of
Reference: [ Shih et al., 1989 ] <author> W-K. Shih, J. W. S. Liu, and J-Y. Chung. </author> <title> Fast algorithms for scheduling imprecise computations. </title> <booktitle> In Proceedings of the Real-Time Systems Symposium. IEEE, </booktitle> <year> 1989. </year>
Reference-contexts: More recent work in the real-time-systems community has gone beyond simple guarantees in various ways, including using models for tasks similar to anytime decision procedures <ref> [ Shih et al., 1989 ] </ref> and meta-level control that modifies scheduling behavior based on the current situation [ Ramamritham et al., 1987, Locke, 1986 ] .
Reference: [ Simon and Kadane, 1975 ] <author> H. A. Simon and J. B. Kadane. </author> <title> Optimal problem-solving search: All-or-none solutions. </title> <journal> Artificial Intelligence, </journal> <volume> 6 </volume> <pages> 235-247, </pages> <year> 1975. </year>
Reference-contexts: See for example [ Shekhar and Dutta, 1989 ] . 4 For a more detailed discussion of the theoretical and practical advantages of decision theory as a 6 1.3.2 Discrete Deliberation Scheduling A line of work running back to <ref> [ Simon and Kadane, 1975 ] </ref> views deliberation time as being quantized into chunks of fixed, though not necessarily constant, size. Sproull [ 1977 ] applies this model to a system for planning travel itineraries, though he is more concerned with the use of decision theory to guide planning choices.
Reference: [ Smith, 1989 ] <author> David E. Smith. </author> <title> Controlling backward inference. </title> <journal> Artificial Intelligence, </journal> <volume> 39 </volume> <pages> 145-208, </pages> <year> 1989. </year>
Reference-contexts: have been proposed for computer vision [ Levitt et al., 1988 ] , industrial control [ Agogino et al., 1988, Ramamurthi and Agogino, 1988 ] , probabilistic inference using belief networks [ Breese and Horvitz, 1990 ] , sensor fusion [ Hager, 1988 ] , and queries in deductive databases <ref> [ Smith, 1989 ] </ref> .
Reference: [ Sproull, 1977 ] <author> Robert F. Sproull. </author> <title> Strategy construction using a synthesis of heuristic and decision-theoretic methods. </title> <type> Technical Report CSL-77-2, </type> <note> Xerox PARC, </note> <year> 1977. </year>
Reference: [ Stankovic, 1988 ] <author> John A. Stankovic. </author> <title> Misconceptions about real-time computing. </title> <journal> IEEE Computer, </journal> <volume> 18 </volume> <pages> 10-18, </pages> <year> 1988. </year>
Reference-contexts: However, it is clear that real-time researchers are beginning to address the same kinds of problems as we are interested in, from a somewhat different perspective (see, for example, <ref> [ Stankovic, 1988 ] </ref> ). 1.4.2 Control Theory The canonical control problem starts with a controller (system) and a plant (environment): the controller can affect the evolving state of the plant in fixed ways and has access to limited information about that state [ Dorf, 1989, Bollinger and Duffie, 1988 ]
Reference: [ Tate, 1977 ] <author> Austin Tate. </author> <title> Generating project networks. </title> <booktitle> In Proceedings IJCAI 5. IJCAI, </booktitle> <year> 1977. </year>
Reference-contexts: Many of these systems employ world models that abstract away the passage of time and the occurrence of events other than the problem-solver's own actions (e.g., the blocksworld) <ref> [ Fikes and Nilsson, 1971, Sacerdoti, 1977, Tate, 1977 ] </ref> . More recently, planners have been built that can take into account the passage of time as the system acts and the possibility of other events occurring, e.g., [ Wilkins, 1984, Vere, 1983, Dean et al., 1987 ] .
Reference: [ Tompkins and Wilson, 1969 ] <author> C.B. Tompkins and W.L. Wilson. </author> <title> Elementary Numerical Analysis. </title> <publisher> Prentice-Hall, </publisher> <year> 1969. </year>
Reference-contexts: Such "well-behaved" anytime algorithms are ubiquitous in computer science. We discuss some examples below. Numerical Approximation The study of methods for iterative approximation is a large and active area in numerical analysis <ref> [ Tompkins and Wilson, 1969, Hageman and Young, 1981 ] </ref> . Two common techniques are Taylor series approximations (e.g., computing or e) and iterative finite-element methods.
Reference: [ Treleaven et al., 1982 ] <author> Philip Treleaven, David Brownbridge, and Richard Hop-kins. </author> <title> Data-driven and demand-driven computer architecture. </title> <journal> Computing Surveys, </journal> <volume> 14(1) </volume> <pages> 93-143, </pages> <year> 1982. </year>
Reference-contexts: We can use simple parallel and serial 11 This is a design-to-time procedure. 12 Procedural-dependency graphs are similar to data-flow graphs <ref> [ Treleaven et al., 1982 ] </ref> 13 If the modifications don't affect the other routine, the procedures are independent and there is no cycle. 38 a 1 2 3 4 combinations to construct performance profiles for composite procedures corresponding to arbitrary procedural-dependency graphs.
Reference: [ Varga, 1962 ] <author> R. S. Varga. </author> <title> Matrix Iterative Methods. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1962. </year>
Reference-contexts: Two common techniques are Taylor series approximations (e.g., computing or e) and iterative finite-element methods. Finite-element methods can be used for approximating conti-nous functions <ref> [ Varga, 1962 ] </ref> , including the solutions to differential equations [ Manohar, 1988 ] . It is usually possible to characterize the convergence properties of these methods, including bounds on the error in the answer resulting from a given number of iterations [ Varga, 1962 ] . <p> can be used for approximating conti-nous functions <ref> [ Varga, 1962 ] </ref> , including the solutions to differential equations [ Manohar, 1988 ] . It is usually possible to characterize the convergence properties of these methods, including bounds on the error in the answer resulting from a given number of iterations [ Varga, 1962 ] . Finite-element methods are not confined to traditionally "mathematical" problems. Hager [ Hager, 1988 ] applies finite-element methods to calculate the most probable interpretation for uncertain sensor data, as well as to determine what new readings can best reduce the uncertainty in that interpretation.
Reference: [ Vere, 1983 ] <author> Steven Vere. </author> <title> Planning in time: Windows and durations for activities and goals. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5 </volume> <pages> 246-267, </pages> <year> 1983. </year>
Reference-contexts: More recently, planners have been built that can take into account the passage of time as the system acts and the possibility of other events occurring, e.g., <ref> [ Wilkins, 1984, Vere, 1983, Dean et al., 1987 ] </ref> . When researchers tried using these planners on robots, they ran into problems resulting from the "top-down" nature of the resulting architecture. The kind of information available from sensors is very different from the symbolic representations the classical planners manipulate.
Reference: [ von Neumann and Morgenstern, 1947 ] <author> John von Neumann and O. Morgenstern. </author> <title> Theory of games and economic behavior. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, 2nd edition, </address> <year> 1947. </year> <month> 178 </month>
Reference-contexts: The main point we take from decision theory is that calculating the expected utility resulting from the decisions made provides a consistent basis for evaluating decision making under uncertainty <ref> [ Raiffa, 1968, von Neumann and Morgenstern, 1947 ] </ref> . This is how we evaluate strategies for deliberation scheduling: an optimal deliberation scheduler maximizes the expected utility of its decisions, given what it knows about the environment and the effect of those allocations. 4 3 Not all of it, however.
Reference: [ Vrbsky et al., 1990 ] <author> S. V. Vrbsky, J. W. S. Liu, and K. P. Smith. </author> <title> An object-oriented query processor that returns monotonically improving approximate answers. </title> <type> Technical Report UIUCDCS-R-90-1568, </type> <institution> Department of Computer Science, UIUC, </institution> <year> 1990. </year>
Reference-contexts: Consider a situation where we want the best estimate possible in the time available of the membership of some relation, where information on that relation can be found in any of several different databases. Vrbsky et al. <ref> [ Vrbsky et al., 1990 ] </ref> have proposed a set of anytime algorithms for relational database queries in which the answers returned improve in the sense that the set returned is closer and closer to the actual set of tuples satisfying the query. <p> These two problems have some common features: * They are event-driven: events occur that require some response (e.g., a disposition 1 Vrbsky et al. <ref> [ Vrbsky et al., 1990 ] </ref> discuss a mechanism for providing partial answers to relational database queries: "partial" in the sense that the set of tuples returned may either contain tuples that do not satisfy the query, or may not contain some of the tuples that do satisfy the query.
Reference: [ Wellman, 1988 ] <author> Michael P. Wellman. </author> <title> Formulation of tradeoffs in planning under uncertainty. </title> <type> Technical Report MIT/LCS/TR-427, </type> <institution> MIT AI Laboratory, </institution> <year> 1988. </year>
Reference-contexts: The most common responses to this fact have been either to limit the expressivity of the language [ Berzuini et al., 1989, Dean and Kanazawa, 1988, Haddawy, 1990 ] , or to use the structure of the application being addressed to constrain the inference that is performed <ref> [ Wellman, 1988, Hanks, 1990 ] </ref> . It would be interesting to extend the model analyzed in this chapter to include uncertain information, and then to see what combination of these approaches might prove to be effective. <p> The most common responses to this fact have been either to limit the expressivity of the language [ Berzuini et al., 1989, Dean and Kanazawa, 1988, Haddawy, 1990 ] or to use the structure of the application being addressed to constrain the inference performed <ref> [ Wellman, 1988, Hanks, 1990 ] </ref> . It would be interesting to extend the examples analyzed in this thesis to include uncertain information and to see what combination of these approaches might prove effective.
Reference: [ Wilkins, 1984 ] <author> David Wilkins. </author> <title> Domain independent planning: Representation and plan generation. </title> <journal> Artificial Intelligence, </journal> <volume> 22 </volume> <pages> 269-302, </pages> <year> 1984. </year>
Reference-contexts: More recently, planners have been built that can take into account the passage of time as the system acts and the possibility of other events occurring, e.g., <ref> [ Wilkins, 1984, Vere, 1983, Dean et al., 1987 ] </ref> . When researchers tried using these planners on robots, they ran into problems resulting from the "top-down" nature of the resulting architecture. The kind of information available from sensors is very different from the symbolic representations the classical planners manipulate.
Reference: [ Wilkins, 1989 ] <author> David E. Wilkins. </author> <title> Can ai planners solve practical problems? Technical Report TR-468, </title> <booktitle> SRI International, </booktitle> <year> 1989. </year>
Reference-contexts: ] have constructed an architecture for planning and acting in which the upper levels iteratively modify a set of situated control rules for the lowest level to follow. [ Zweben et al., 1990 ] present an anytime algorithm for rescheduling, which is a useful planning capability in many domains (e.g., <ref> [ Dean et al., 1987, Wilkins, 1989 ] </ref> ). The enormous advantage to these proposals from our point of view is that these planning methods can be used directly in a solution of a time-dependent problem constructed using expectation-driven iterative refinement.
Reference: [ Zweben et al., 1990 ] <author> M. Zweben, M. Deale, and R. Gargan. Anytime rescheduling. </author> <title> In Proceedings of the DARPA Workshop on Innovative Approaches to Planning, Scheduling, and Control. </title> <booktitle> DARPA, </booktitle> <year> 1990. </year> <month> 179 </month>
Reference-contexts: Drummond and Bresina [ 1990 ] have constructed an architecture for planning and acting in which the upper levels iteratively modify a set of situated control rules for the lowest level to follow. <ref> [ Zweben et al., 1990 ] </ref> present an anytime algorithm for rescheduling, which is a useful planning capability in many domains (e.g., [ Dean et al., 1987, Wilkins, 1989 ] ).
References-found: 105

