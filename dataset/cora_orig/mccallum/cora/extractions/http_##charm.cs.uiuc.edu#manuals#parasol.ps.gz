URL: http://charm.cs.uiuc.edu/manuals/parasol.ps.gz
Refering-URL: http://charm.cs.uiuc.edu/manuals/
Root-URL: http://www.cs.uiuc.edu
Title: ParaSol: A MULTITHREADED SYSTEM FOR PARALLEL SIMULATION BASED ON MOBILE THREADS  
Author: Edward Mascarenhas Felipe Knop Vernon Rego 
Address: West Lafayette, IN 47907, U.S.A.  
Affiliation: Department of Computer Sciences Purdue University  
Abstract: ParaSol is a novel multithreaded system for shared-and distributed-memory parallel simulation, designed to support a variety of domain-specific Simulation Object Libraries. We report on the design of the ParaSol kernel, which drives executions based on optimistic and adaptive synchronization protocols. The active-transaction flow methodology we advocate is enabled by an underlying, efficient lightweight process system. Though this process- and object- interaction view is known to both simplify and speed transition from model design to simulation implementation, mi-gratable threads and objects pose many serious challenges to efficient kernel operation. Good solutions to these challenging problems are key to good simulator performance. We present techniques for the support of optimistic parallel simulations, addressing synchronization, state-saving, rollback, inter-process communication, and process scheduling. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Baezner D., G. Lomow, and B. Unger. </author> <year> 1990. </year> <title> Sim++: The Transition to Distributed Simulation. Distributed Simulation, </title> <booktitle> SCS Simulation Series, </booktitle> <pages> 211-218. </pages>
Reference: <author> Bagrodia R. L. </author> <year> 1991. </year> <title> Iterative Design of Efficient Simulations Using Maisie. </title> <booktitle> In Proceedings of the 1991 Winter Simulation Conference, </booktitle> <pages> 243-247. </pages> <address> BoyanTech, </address> <publisher> Inc. </publisher> <year> 1995. </year> <title> CPSim 1.0 User's Guide and Reference Manual. </title> <publisher> BoyanTech, Inc., </publisher> <address> McLean, VA 22102. </address>
Reference-contexts: Code developed in Maisie <ref> (Bagrodia 1991) </ref> for the same example, was based on the active-resource approach. In contrast, the ParaSol code developed here is based on the active-transaction approach. Consider a system of N fully connected switches, each hosting Q single-server (fifo) queues in tandem.
Reference: <author> Chandy K. M. and J. Misra. </author> <year> 1979. </year> <title> Distributed Simulation: A Case Study in Design and Verification of Distributed Programs. </title> <journal> IEEE Trans. on Softw. Eng., </journal> <volume> 5(5) </volume> <pages> 440-452. </pages>
Reference-contexts: The major focus of parallel simulation research centers around implementation and performance assessment of two well-known synchronization protocols: the conservative protocol and the optimistic protocol. In the conservative approach <ref> (Chandy and Misra 1979) </ref>, events are executed strictly in order of occurrence in simulation time. In the optimistic approach (Jefferson 1985), an LP processes events as event messages become available, hoping the physical order of event message arrival corresponds to order of nondecreasing time.
Reference: <author> Fujimoto R. </author> <year> 1990. </year> <title> Parallel Discrete Event Simulation. </title> <journal> CACM, </journal> <volume> 33(10) </volume> <pages> 30-53. </pages>
Reference-contexts: In this paper, we focus our attention on the ParaSol layer, which supports general parallel simulation and computation through the process- and object- interaction view. We resort to standard parallel simulation terminology <ref> (Fujimoto 1990) </ref> to present background and design ideas. <p> The Rollback Module contains algorithms for effecting rollback: an LP's state is rolled back from its LVT t n to its state at some past time t p . The coast forwarding phase <ref> (Fujimoto 1990) </ref> is necessary when state is saved infrequently, as is done in ParaSol. During the coast-forward, user commands are executed but kernel primitives execute code selectively.
Reference: <author> Jefferson D. and S. Bellenot. </author> <year> 1987. </year> <title> Distributed Simulation and the Time Warp Operating System. </title> <booktitle> ACM Operating System Review, </booktitle> <pages> 77-93. </pages>
Reference: <author> Jefferson D. R. </author> <year> 1985. </year> <title> Virtual Time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(3) </volume> <pages> 404-425. </pages>
Reference-contexts: The major focus of parallel simulation research centers around implementation and performance assessment of two well-known synchronization protocols: the conservative protocol and the optimistic protocol. In the conservative approach (Chandy and Misra 1979), events are executed strictly in order of occurrence in simulation time. In the optimistic approach <ref> (Jefferson 1985) </ref>, an LP processes events as event messages become available, hoping the physical order of event message arrival corresponds to order of nondecreasing time. <p> The location of an object is the identifier of the LP at which the global object is created. The global virtual time (GVT) module in ParaSol computes the GVT periodically. The algorithm is similar to the GVT algorithm used in TWOS <ref> (Jefferson 1985) </ref>. To account for transactions in transit we piggyback ac-knowledgements onto messages. Two distinct modules are responsible for system initialization and termination. Initialization occurs when the simulation "driver" and associated modules are created.
Reference: <author> Knop F., E. Mascarenhas, V. Rego, and V. Sun-deram. </author> <year> 1995. </year> <title> Fail-Safe Concurrent Simulation with EcliPSe: An Introduction. </title> <note> Simulation Practice & Theory (to appear). </note>
Reference-contexts: The challenge lies in moving a parallel simulation forward to completion as fast as possible in real time, while satisfying simulation-time related synchronization constraints. We have embarked on the construction of a four-tiered software architecture, called the ACES system <ref> (Knop et al. 1995) </ref>, for parallel computation and simulation applications. In this paper, we focus our attention on the ParaSol layer, which supports general parallel simulation and computation through the process- and object- interaction view. We resort to standard parallel simulation terminology (Fujimoto 1990) to present background and design ideas.
Reference: <author> Mascarenhas E. and V. Rego. </author> <year> 1995a. </year> <title> Ariadne: Architecture of a Portable Threads System Supporting Thread Migration. </title> <note> Software-Practice and Experience (to appear). </note>
Reference-contexts: The ParaSol kernel is essentially the parallel simulation engine, responsible for driving all the other modules (these are described briefly in Section 3). Kernel modules access threads-layer primitives and communications layer primitives, protecting application-level codes from system details. The ParaSol kernel is currently layered upon the Ariadne <ref> (Mascarenhas and Rego 1995a) </ref> threads system. Like other threads systems, Ariadne supports dynamic creation and destruction of threads, priority-based scheduling and context switching. But Ari-adne is novel in that it also supports thread migration between processors, user-customized schedulers, thread-check-pointing, and thread-image restore operations. <p> Certain ParaSol requirements may not be easily met by other threads systems: support for a large number of co-existing threads, and thread migration. Because Ariadne supports threads in user-space, threads may co-exist in large numbers. One of Ariadne's main design goals was the efficient support of process-based parallel simulators <ref> (Mascarenhas and Rego 1995a) </ref>. 4.2 Scheduler Every simulator must utilize a scheduler to schedule events: the earliest event in the system is scheduled for immediate execution. <p> At the destination, the message is "unpacked" into a thread-shell and is ready for execution. The cost of migrating a thread in this manner is equal to the cost of sending and receiving a message of the same length <ref> (Mascarenhas and Rego 1995a) </ref>. This point is of great significance, because ParaSol does not curtail the number of migrations. The transaction-flow approach may result in a large number of threads, each of which can migrate. Since migrant threads are responsible for rollback, efficient migration is important. <p> The transaction-flow approach may result in a large number of threads, each of which can migrate. Since migrant threads are responsible for rollback, efficient migration is important. Details on migration in Ariadne can be found in <ref> (Mascarenhas and Rego 1995a) </ref>. Transmitting threads instead of messages adds marginal overhead in the form of stack information.
Reference: <author> Mascarenhas E. and V. Rego. </author> <year> 1995b. </year> <title> Migrant Threads on Processor Farms: Parallel Programming with Ariadne. </title> <note> Technical report in preparation, </note> <institution> Computer Sciences Department, Purdue University. </institution>
Reference-contexts: Like other threads systems, Ariadne supports dynamic creation and destruction of threads, priority-based scheduling and context switching. But Ari-adne is novel in that it also supports thread migration between processors, user-customized schedulers, thread-check-pointing, and thread-image restore operations. The Ariadne Parallel Programming System <ref> (Mascarenhas and Rego 1995b) </ref> is based on the notion of migratable threads. With support from Ariadne, ParaSol adopts transaction-migration as a primary remote-object access mechanism, exploiting transparent migration of threads through supporting object location/relocation mechanisms. Since ParaSol was motivated by domain-specific methodologies, the domain layer consists of distinct domain libraries.
Reference: <author> Sang J., E. Mascarenhas, and V. Rego. </author> <year> 1993. </year> <title> Process Mobility in Distributed-Memory Simulation Systems. </title> <booktitle> In Proceedings of the 1993 Winter Simulation Conference, </booktitle> <pages> 722-730. </pages>
Reference-contexts: Transmitting threads instead of messages adds marginal overhead in the form of stack information. But since the dominant component of transmission time is due to transmission latency and not message size or even data packing/unpacking, thread-migration costs are equivalent to message transmission costs <ref> (Sang et al. 1993) </ref>. Finally, migration does not always involve message transmission because both the source and destination LPs may reside within the same process or in the same shared memory multiprocessor.
Reference: <author> Schwetman H. </author> <year> 1986. </year> <title> A C-based Process Oriented Simulation Language. </title> <booktitle> In Proceedings of the 1986 Winter Simulation Conference, </booktitle> <pages> 387-396. </pages>
Reference-contexts: One way of using threads in process-based simulations is to make the threads system an integral part of the simulator. This method is used in CSIM <ref> (Schwetman 1986) </ref>, a sequential process-based simulation system written in C. A serious disadvantage of this approach is that the threads system cannot be replaced if required for instance, when an improved threads system becomes available.
Reference: <author> Steinman J. S. </author> <year> 1992. </year> <title> SPEEDES: A Unified Approach to Parallel Simulation. </title> <booktitle> In Proceedings of 6th Workshop on Parallel and Distributed Simulation, Simulation Series, </booktitle> <pages> 75-84. </pages>
Reference: <author> Sunderam V. S. </author> <year> 1990. </year> <title> PVM: a Framework for Parallel Distributed Computing. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(4) </volume> <pages> 315-339. </pages>

References-found: 13

