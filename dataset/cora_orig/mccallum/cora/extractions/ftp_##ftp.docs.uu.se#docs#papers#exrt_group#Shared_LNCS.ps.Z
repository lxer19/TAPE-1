URL: ftp://ftp.docs.uu.se/docs/papers/exrt_group/Shared_LNCS.ps.Z
Refering-URL: http://www.csd.uu.se/~stinal/publications.html
Root-URL: 
Email: E-mail: -goranw, stinal-@docs.uu.se  
Phone: Phone: +46 18 18 25 00, Fax: +46 18 55 02 25  
Title: Shared Packages Through Linda  
Author: Gran Wall Kristina Lundqvist 
Address: P.O. Box 325, S-751 05 Uppsala, Sweden  
Affiliation: Department of Computer Systems, Uppsala University  
Note: This work is sponsored by NUTEK, project number P1221-2  
Abstract: This paper describes a method to implement the functionality of shared passive packages on top of a logical distributed memory Linda. From a shared passive package a compiler can construct a new normal package that replaces the shared passive package. The new package contains the same subprograms and is extended with abstract data structures mapping Ada objects onto the storage units of Linda. A short program example is included to illustrate the construction process.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> ISO/IEC 8652:1995(E) Ada 95 Reference Manual, </author> <year> 1995, </year> <institution> Intermetrics Inc. </institution>
Reference-contexts: 1 Introduction The Ada 95 standard, RM95 <ref> [1] </ref>, defines a distributed Ada program as a number of partitions working cooperatively. The partitions can be mapped on one or more processing nodes.
Reference: [2] <institution> Ada 95 Rationale, </institution> <month> January </month> <year> 1995, </year> <institution> Intermetrics Inc. </institution>
Reference-contexts: The restrictions imposed on shared passive packages by the standard suggest that they are intended for use only when partitions share a logical address space <ref> [2] </ref>. This can be achieved either by the use of shared physical memory, where the logical and physical address space are identical, or through distributed shared virtual memory (DSVM). An example of distributed shared virtual memory for Ada can be found in [3].
Reference: [3] <author> Y. Kermarrec and L. Pautet, </author> <title> A Distributed Shared Virtual Memory for Ada 83 and Ada 9X applications, </title> <booktitle> proceeding of the TRI-Ada '93 conference, </booktitle> <pages> pages 242-251, </pages> <address> Seatle, Washington, </address> <year> 1993. </year>
Reference-contexts: This can be achieved either by the use of shared physical memory, where the logical and physical address space are identical, or through distributed shared virtual memory (DSVM). An example of distributed shared virtual memory for Ada can be found in <ref> [3] </ref>. On a system not having DSVM or on a heterogeneous system it becomes practically impossible to use shared passive packages, due to different data representation and different instruction sets. Even in the absence of true shared memory it is desirable to have access to shared passive packages.
Reference: [4] <author> A. Silberschatz, and P. B. Galvin, </author> <title> Operating System Concepts, </title> <booktitle> 4th Ed., 1994, </booktitle> <publisher> Addison-Wesley Publishing Company Inc. </publisher>
Reference-contexts: Even in the absence of true shared memory it is desirable to have access to shared passive packages. It offers an uncoupled way for processes to communicate. There are distributed algorithms that uses shared variables, e.g. the Bakery algorithm for mutual exclusion <ref> [4] </ref>. Shared passive packages also offers a simple mutual exclusion policy through shared protected objects. Also things like mode changes can easily be signaled through shared variables.
Reference: [5] <author> S. Ahuja, N. Carriero, and D. Gelernter, </author> <title> Linda and Friends, </title> <journal> IEEE Com puter, </journal> <volume> 19(8) </volume> <pages> 26-34, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: Also things like mode changes can easily be signaled through shared variables. One solution in the absence of DSVM is to use a higher level shared memory that provides a shared logical address space to implement shared passive packages. Linda <ref> [5] </ref> is a language independent model for concurrent and distributed programming. The model introduces a few simple operators on a logical memory called Tuple Space (TS) that can be hosted by an existing language, e.g. Ada 95, without changing the semantics of the host language. <p> Ada 95, without changing the semantics of the host language. There are many implementations of Linda and Lin da-like systems [6] so the model is well tested and spread. An example of a Linda imple-mentation for Ada 83 is Ada-Linda [7]. In <ref> [5] </ref> it is suggested that Linda could be regarded as a machine language for a Linda machine, and that high level language constructs could be compiled into Linda. For example, operations on objects declared in Ada 95 shared passive packages could be compiled into Linda operations.
Reference: [6] <editor> Greg Wilson (editor), </editor> <booktitle> Linda-Like Systems and Their Implementation, </booktitle> <institution> Edinburgh Parallel Computing Centre, </institution> <type> Technical Report 91-13, </type> <month> June 24, </month> <year> 1991. </year>
Reference-contexts: The model introduces a few simple operators on a logical memory called Tuple Space (TS) that can be hosted by an existing language, e.g. Ada 95, without changing the semantics of the host language. There are many implementations of Linda and Lin da-like systems <ref> [6] </ref> so the model is well tested and spread. An example of a Linda imple-mentation for Ada 83 is Ada-Linda [7]. In [5] it is suggested that Linda could be regarded as a machine language for a Linda machine, and that high level language constructs could be compiled into Linda.
Reference: [7] <author> Y. Kermarrec and L. Pautet, Ada-Linda: </author> <title> a power paradigm for programming distributed Ada applications, </title> <booktitle> proceedings of the TRI-Ada '94 conference, </booktitle> <pages> pages 438-445, </pages> <address> Baltimore, Maryland, </address> <year> 1994. </year>
Reference-contexts: Ada 95, without changing the semantics of the host language. There are many implementations of Linda and Lin da-like systems [6] so the model is well tested and spread. An example of a Linda imple-mentation for Ada 83 is Ada-Linda <ref> [7] </ref>. In [5] it is suggested that Linda could be regarded as a machine language for a Linda machine, and that high level language constructs could be compiled into Linda. For example, operations on objects declared in Ada 95 shared passive packages could be compiled into Linda operations.
Reference: [8] <author> D. Gelernter, </author> <title> Multiple Tuple Spaces in Linda, </title> <booktitle> proceedings PARLE '89, </booktitle> <volume> LNCS no 366, </volume> <pages> pp 20-27, </pages> <year> 1989. </year>
Reference-contexts: In Ada each access-to-object type has a storage pool associated with it, RM95 (13.11). When an allocator is called, storage is allocated in the corresponding storage pool. It is possible for a Linda implementation to have multiple tuple spaces <ref> [8] </ref>. These can be use to implement the storage pools of Ada. 3.4 Arrays Intuitively arrays can be handled in two different ways, either the whole array is mapped onto one tuple or each array component is mapped onto a tuple.
Reference: [9] <author> R. Srinivasan, XDR: </author> <title> External Data Representation Standard, Network Working Group, </title> <type> RFC 1832, </type> <institution> Sun Micro Systems, </institution> <month> August </month> <year> 1995 </year>
Reference-contexts: First, the code of a shared package can be compiled for different architectures. Second, shared data is interpreted at Ada level which allows it to be interpreted and exchanged using some intermediate representation, e.g. External Data Representation XDR <ref> [9] </ref>, thus allowing partitions in a heterogeneous system to share variables. Another benefit of using Linda as the underlying shared memory is the blocking property of its operations which solves the problem of having inconsistent views of objects in a system.
References-found: 9

