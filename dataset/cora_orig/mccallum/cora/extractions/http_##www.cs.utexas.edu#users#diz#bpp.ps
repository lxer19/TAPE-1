URL: http://www.cs.utexas.edu/users/diz/bpp.ps
Refering-URL: http://www.cs.utexas.edu/users/diz/pubs.html
Root-URL: 
Email: diz@cs.utexas.edu  
Title: Simulating BPP Using a General Weak Random Source  
Author: David Zuckerman 
Keyword: MAX CLIQUE.  
Date: February 21, 1995  
Address: Austin, TX 78712  
Affiliation: Dept. of Computer Sciences The University of Texas at Austin  
Abstract: We show how to simulate BPP and approximation algorithms in polynomial time using the output from a ffi-source. A ffi-source is a weak random source that is asked only once for R bits, and must output an R-bit string according to some distribution that places probability no more than 2 ffiR on any particular string. We also give an application to the unapproximability of 
Abstract-found: 1
Intro-found: 1
Reference: [AM] <author> N. Alon and V.D. Milman, </author> " <title> 1 , Isoperimetric Inequalities for Graphs and Superconcentra-tors," </title> <journal> J. Combinatorial Theory Ser. B, </journal> <volume> 38 </volume> <pages> 73-88, </pages> <year> 1985. </year>
Reference-contexts: Our model can be modified to generalize this source, too, but then our simulations would fail. 3 graphs are dispersers, yet one cannot even use the eigenvalue techniques in [Tan] and <ref> [AM] </ref> to give a certificate that a random graph is a disperser (see [WZ] for more discussion on this point). This makes it especially interesting that our explicit construction works in time just polylogarithmic in the size of the graph.
Reference: [AL+] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, M. Szegedy, </author> <title> "Proof Verification and Intractibil-ity of Approximation Problems," </title> <booktitle> 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1992, </year> <pages> pp. 14-23. </pages>
Reference-contexts: T I M E (2 polylog (n) )). After the preliminary version of this paper appeared, the above hardness results have been improved: if approximating ! to within a factor of n 1=4o (1) is in ~ P , then N ~ P = coR ~ P <ref> [BS, AL+, AS] </ref>. Since it is infeasible to find close approximations, one can ask whether it is feasible to at least estimate the order of magnitude of !.
Reference: [AS] <author> S. Arora and S. Safra, </author> <title> "Approximating Clique is NP-Complete," </title> <booktitle> 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1992, </year> <pages> pp. 2-13. </pages>
Reference-contexts: T I M E (2 polylog (n) )). After the preliminary version of this paper appeared, the above hardness results have been improved: if approximating ! to within a factor of n 1=4o (1) is in ~ P , then N ~ P = coR ~ P <ref> [BS, AL+, AS] </ref>. Since it is infeasible to find close approximations, one can ask whether it is feasible to at least estimate the order of magnitude of !.
Reference: [BFL] <author> L. Babai, L. Fortnow, and C. Lund, </author> <title> Non-Deterministic Exponential Time Has Two-Prover Interactive Protocols, </title> <journal> Computational Complexity, </journal> <volume> 1 </volume> <pages> 16-25, </pages> <year> 1991. </year>
Reference-contexts: Thus one might have thought it would be easier to construct such an approximation algorithm. Our proof closely follows the proof of [FG+], making great use of the proof in <ref> [BFL] </ref> that NEXP = MIP. Actually, we really use the equivalent theorem (see [FRS]) that any language in NEXP is accepted by a polynomial time probabilistic oracle machine. <p> r [M O (x; r)] = 1 x 62 L ) (8oracles O)P r r [M O (x; r)] &lt; 1=4: Denoting the maximum number of random and communication bits used on inputs of size n as r (n) and c (n), respectively, Feige et.al. give the following improvement of <ref> [BFL] </ref>: Theorem 9 (FG+) Any language L 2 N T I M E (T (n)) (for n T (n) 2 poly (n) ) is accepted by a probabilistic oracle machine running in time T (n) O (log log T (n)) and having r (n) + c (n) = O (log T
Reference: [BS] <author> M. Bellare and M. Sudan, </author> <title> "Improved Non-Approximability Results," </title> <booktitle> 26th ACM Symposium on Theory of Computing, </booktitle> <year> 1994, </year> <pages> pp. 184-193. </pages>
Reference-contexts: T I M E (2 polylog (n) )). After the preliminary version of this paper appeared, the above hardness results have been improved: if approximating ! to within a factor of n 1=4o (1) is in ~ P , then N ~ P = coR ~ P <ref> [BS, AL+, AS] </ref>. Since it is infeasible to find close approximations, one can ask whether it is feasible to at least estimate the order of magnitude of !.
Reference: [Blu] <author> M. Blum, </author> <title> "Independent Unbiased Coin Flips from a Correlated Biased Source: a Finite Markov Chain," </title> <journal> Combinatorica, </journal> <volume> 6 (2): </volume> <pages> 97-108, </pages> <year> 1986. </year>
Reference-contexts: N00014-92-J-1799. Part of this research was done at UT Austin, where the author was supported by NSF NYI Grant No. CCR-9457799. 1 The problem of correlations, however, is more serious. Blum <ref> [Blu] </ref> was the first to tackle this by modeling a weak source as a Markov chain. He showed that a counter-intuitive generalization of von Neumann's algorithm converts the output from such a source into a truly random string.
Reference: [BBR] <author> C.H. Bennett, G. Brassard, and J.-M. Robert, </author> <title> "Privacy Amplification by Public Discussion," </title> <journal> SIAM Journal on Computing, </journal> <volume> 17 (2): </volume> <pages> 210-229, </pages> <year> 1988. </year> <month> 21 </month>
Reference-contexts: The Leftover Hash Lemma was introduced in [ILL] in order to construct cryptographically secure pseudo-random generators from one-way functions. It was then used extensively in [IZ] to construct pseudo-random generators for various tasks without any complexity assumptions. A similar lemma was also used in <ref> [BBR] </ref>. In order to state this lemma, we define Definition 13 (CWe) Let A and B be two sets, and H a family of functions from A to B.
Reference: [BL] <author> M. Ben-Or and N. Linial, </author> <title> "Collective Coin Flipping Robust Voting Schemes and Minimal Banzhaf Values," </title> <booktitle> in Advances in Computing Research 5: Randomness and Computation, </booktitle> <editor> S. Micali, ed., </editor> <publisher> JAI Press, </publisher> <year> 1989. </year>
Reference-contexts: For l = O (log R), Chor and Goldreich showed how to simulate BPP using one such source. Various authors have also considered models for weak sources where an adversary chooses the values of certain bits, but the others are random (see [CG+], <ref> [BL] </ref>, [LLS], [CWi]).
Reference: [CWe] <author> L. Carter and M. Wegman, </author> <title> "Universal Classes of Hash Functions," </title> <journal> J. Comp. and Syst. Sci., </journal> <volume> 18(2): </volume> <pages> 143-154, </pages> <year> 1979. </year>
Reference: [CG1] <author> B. Chor and O. Goldreich, </author> <title> "Unbiased Bits from Sources of Weak Randomness and Probabilistic Communication Complexity," </title> <journal> SIAM J. Comput., </journal> <volume> 17(2) </volume> <pages> 230-261, </pages> <year> 1988. </year>
Reference-contexts: In light of this result, one might give up hope for simulating randomized algorithms with one semi-random source. Nevertheless, [VV] and [Va1] showed how to simulate RP and BPP with one semi-random source. Chor and Goldreich <ref> [CG1] </ref> generalized this model by assuming no sequence of l bits has too high a probability of being output. More precisely, 1 Definition 2 [CG1] An (l; ffi) PRB-source outputs R bits as R=l blocks Y 1 ; : : : ; Y R=l , each of length l, such that <p> Nevertheless, [VV] and [Va1] showed how to simulate RP and BPP with one semi-random source. Chor and Goldreich <ref> [CG1] </ref> generalized this model by assuming no sequence of l bits has too high a probability of being output. More precisely, 1 Definition 2 [CG1] An (l; ffi) PRB-source outputs R bits as R=l blocks Y 1 ; : : : ; Y R=l , each of length l, such that for all l-bit strings y 1 ; : : : ; y R=l , P r [Y i = y i jY 1 = <p> Yet we follow [VV], [Va1], and <ref> [CG1] </ref> and deal with a more abstract "BPP" problem: let an adversary label strings in f0; 1g r either "yes" or "no," provided that at least 3=4 of the strings have the same label. We wish to find out whether the majority say "yes" or "no," with high probability. <p> A block-wise ffi-source is the same as the PRB-source of <ref> [CG1] </ref> except that here the block length is allowed to vary. 5 2.2 Simulations using ffi-sources The first way one would try to simulate randomized algorithms using a ffi-source would be to do what von Neumann did with his sources: convert the "bad" random bits output by the ffi-source into "good" <p> Thus, by taking medians instead of majorities, a good approximation can be obtained with probability 1 2 (R) . 2.3 ffi-sources and Dispersers To give some intuition about ffi-sources, we follow <ref> [CG1] </ref> and define flat ffi-sources and show that we may assume without loss of generality that our ffi-source is flat. We never need this explicitly, but it is useful to keep in mind. <p> Lemma 3 Suppose an algorithm simulates RP (BPP) using a flat ffi-source. Then it also simulates RP (BPP) using a ffi-source. Proof. The proof in our case is much simpler than in <ref> [CG1] </ref>. Fix an algorithm A. On certain input strings, A outputs the correct answer, and on others it doesn't. <p> This method is described by the following lemma, which essentially strengthens related lemmas in [Va1] and <ref> [CG1] </ref>. This lemma is not necessary for the BPP simulation, but is helpful to better appreciate Lemma 7. Intuitively, because the Leftover Hash Lemma says that the ordered pair (h; h (x)) is close to uniform, we may use the same hash function repeatedly.
Reference: [CG2] <author> B. Chor and O. Goldreich, </author> <title> "On the Power of Two-Point Based Sampling," </title> <journal> Journal of Complexity, </journal> <volume> 5 </volume> <pages> 96-106, </pages> <year> 1989. </year>
Reference: [CG+] <author> B. Chor, O. Goldreich, J. Hastad, J. Friedman, S. Rudich, and R. Smolensky, </author> <title> "The Bit Extraction Problem or t-Resilient Functions," </title> <booktitle> 26th Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1985, </year> <pages> pp. 396-407. </pages>
Reference-contexts: For l = O (log R), Chor and Goldreich showed how to simulate BPP using one such source. Various authors have also considered models for weak sources where an adversary chooses the values of certain bits, but the others are random (see <ref> [CG+] </ref>, [BL], [LLS], [CWi]).
Reference: [CWi] <author> A. Cohen and A. Wigderson, "Dispersers, </author> <title> Deterministic Amplification, and Weak Random Sources," </title> <booktitle> 30th Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <pages> pp. 14-19. </pages>
Reference-contexts: For l = O (log R), Chor and Goldreich showed how to simulate BPP using one such source. Various authors have also considered models for weak sources where an adversary chooses the values of certain bits, but the others are random (see [CG+], [BL], [LLS], <ref> [CWi] </ref>). <p> Equivalently, we assume that only one request for random bits is made to the ffi-source. This model essentially generalizes all of the above models, 2 making no structural assumptions about dependencies. The generality of our model is further substantiated by a lemma of Cohen and Wigderson <ref> [CWi] </ref>: an algorithm that simulates RP or BPP using a ffi-source also outputs the correct answer with constant probability using R bits from any source whose entropy is (R), which as remarked earlier is best possible. <p> The first results about these sources were obtained by Cohen and Wigderson <ref> [CWi] </ref>, who showed how to simulate RP using a string from a ffi-source for ffi &gt; 1=2, and BPP for ffi &gt; 3=4. <p> However, the ideas there do help simplify our original construction, so we present the simplified construction here. The simulations of RP and BPP are equivalent to the explicit construction of a certain type of expander graph, called a disperser (see [San], [Sip], <ref> [CWi] </ref>). It is easy to show that random 2 One of the bit-fixing sources in [CWi] has a weaker entropy bound than that which we impose. <p> The simulations of RP and BPP are equivalent to the explicit construction of a certain type of expander graph, called a disperser (see [San], [Sip], <ref> [CWi] </ref>). It is easy to show that random 2 One of the bit-fixing sources in [CWi] has a weaker entropy bound than that which we impose. <p> Thus, the probability of error when the output is from a ffi-source is at most (2 ffi 0 R 1)=2 ffiR . The other direction is similar. Simulations using a ffi-source are equivalent to the construction of a certain type of expander graph, called a disperser (see <ref> [San, Sip, CWi] </ref>). We never use this graph-theoretic approach; however, it is useful to understand the equivalence, as it was used in e.g. [WZ]. Here we rephrase our results in terms of dispersers.
Reference: [DFK] <author> M. Dyer, A. Frieze, and R. Kannan, </author> " <title> A Random Polynomial Time Algorithm For Approximating the Volume of a Convex Body," </title> <journal> J. ACM, </journal> <volume> 38 </volume> <pages> 1-17, </pages> <year> 1991. </year>
Reference-contexts: These algorithms also yield solutions to more general problems. Our RP simulation implies that we can find an n-bit prime using a ffi-source. Our BPP simulation yields simulations for approximation algorithms, e.g. those used to approximate the volume of a convex body <ref> [DFK] </ref>, or a statistical simulation to estimate some quantity or set of quantities. We include separate algorithms for RP and BPP, because the RP algorithm has the advantage of using few random bits from the ffi-source.
Reference: [Eli] <author> P. Elias, </author> <title> "The Efficient Construction of an Unbiased Random Sequence," </title> <journal> Ann. Math. Stat., </journal> <volume> 43(3) </volume> <pages> 865-870, </pages> <year> 1972. </year>
Reference-contexts: The history of weak random sources reflects this ideal of using as weak a source as possible. As far back as 1951, von Neumann [vN] gave a simple and practical algorithm to extract perfectly random bits from a source of independent coin flips of equal but unknown bias. Elias <ref> [Eli] </ref> improved this by showing how to extract bits at the optimal rate. fl This paper appeared in preliminary form in the 32nd Annual Symposium on Foundations of Computer Science, 1991, pp. 79-89. y Most of this research was done while the author was at U.C.
Reference: [FG+] <author> U. Feige, S. Goldwasser, L. Lovasz, S. Safra, and M. Szegedy, </author> <title> "Approximating Clique is Almost NP-Complete," </title> <booktitle> 32nd Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1991. </year>
Reference-contexts: The interested reader should see upcoming work by the author [Zu4]. Computing ! = !(G), the size of the maximum clique of the input graph G, is well known to be NP-complete [Kar]. Little was known about the difficulty of approximating ! until Feige, et.al. <ref> [FG+] </ref> showed that if approximating ! to within a factor of 2 (log n) 1* for some * &gt; 0 is in ~ P , then N ~ P = ~ P ( ~ P denotes quasi-polynomial time, i.e. T I M E (2 polylog (n) )). <p> More precisely, is there an algorithm that for some constant t outputs a number between ! 1=t and ! t ? This is equivalent to approximating log ! to within a constant factor. By applying our disperser construction to the proof of <ref> [FG+] </ref>, we show that the existence of such an algorithm implies N ~ P = ~ P . <p> Feige, et.al. <ref> [FG+] </ref> showed Theorem 7 If for some * the task of approximating ! to within a factor of 2 (log n) 1* is in ~ P , then N ~ P = ~ P ( ~ P denotes quasi-polynomial time, i.e. T IM E (2 polylog )). <p> For example, there is a simple polynomial-time algorithm to distinguish between graphs having ! equal to O (1) or 2 (log n) 1* , whereas the proof in <ref> [FG+] </ref> shows that it is difficult to distinguish between graphs having ! equal to n ffi or n ffi 2 (log n) 1* . <p> Note that such an algorithm has to decide among only O (log log n) values (some approximation of the form 2 t i will do). Thus one might have thought it would be easier to construct such an approximation algorithm. Our proof closely follows the proof of <ref> [FG+] </ref>, making great use of the proof in [BFL] that NEXP = MIP. Actually, we really use the equivalent theorem (see [FRS]) that any language in NEXP is accepted by a polynomial time probabilistic oracle machine.
Reference: [FW] <author> J. Friedman, A. Wigderson, </author> <title> "On the Second Eigenvalue of Hypergraphs," </title> <institution> Princeton University Technical Report CS-TR-232-89, </institution> <year> 1989. </year>
Reference-contexts: Yet breaking the ffi = 1=2 barrier appeared difficult, because it involves doing more than can be done by bounding the second eigenvalue of ordinary graphs (see [WZ]). Friedman and Wigderson <ref> [FW] </ref> showed how to break the barrier and improve this to all ffi &gt; 0 in the RP case if one could construct hypergraphs with small second eigenvalue; yet, constructing such hypergraphs appears difficult.
Reference: [ILL] <author> R. Impagliazzo, L. Levin, and M. Luby, </author> <title> "Pseudo-Random Generation from One-Way Functions," </title> <booktitle> 21st ACM Symposium on Theory of Computing, </booktitle> <year> 1989, </year> <pages> pp. 12-24. </pages>
Reference-contexts: The Leftover Hash Lemma was introduced in <ref> [ILL] </ref> in order to construct cryptographically secure pseudo-random generators from one-way functions. It was then used extensively in [IZ] to construct pseudo-random generators for various tasks without any complexity assumptions. A similar lemma was also used in [BBR]. <p> The Leftover Hash Lemma was originally stated in terms of flat ffi-sources, but it is a simple corollary of the proof that it holds for general ffi-sources. 9 Leftover Hash Lemma <ref> [ILL] </ref>: Let A f0; 1g n ; jAj 2 u . Let e &gt; 0, and let H be a universal family of hash functions mapping n bits to u 2e bits.
Reference: [IZ] <author> R. Impagliazzo and D. Zuckerman, </author> <title> "How to Recycle Random Bits," </title> <booktitle> 30th Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <pages> pp. 248-253. </pages>
Reference-contexts: The Leftover Hash Lemma was introduced in [ILL] in order to construct cryptographically secure pseudo-random generators from one-way functions. It was then used extensively in <ref> [IZ] </ref> to construct pseudo-random generators for various tasks without any complexity assumptions. A similar lemma was also used in [BBR]. In order to state this lemma, we define Definition 13 (CWe) Let A and B be two sets, and H a family of functions from A to B.
Reference: [Kar] <author> R.M. Karp, </author> <title> "Reducibility Among Combinatorial Problems." In R.E. </title> <editor> Miller and J.W. Thatcher, eds., </editor> <booktitle> Complexity of Computer Computations, </booktitle> <year> 1972, </year> <pages> pp. 85-103. </pages>
Reference-contexts: The interested reader should see upcoming work by the author [Zu4]. Computing ! = !(G), the size of the maximum clique of the input graph G, is well known to be NP-complete <ref> [Kar] </ref>.
Reference: [LLS] <author> D. Lichtenstein, N. Linial, and M. Saks, </author> <title> "Some Extremal Problems Arising from Discrete Control Processes," </title> <journal> Combinatorica, </journal> <volume> 9 </volume> <pages> 269-287, </pages> <year> 1989. </year>
Reference-contexts: For l = O (log R), Chor and Goldreich showed how to simulate BPP using one such source. Various authors have also considered models for weak sources where an adversary chooses the values of certain bits, but the others are random (see [CG+], [BL], <ref> [LLS] </ref>, [CWi]).
Reference: [LLSZ] <author> N. Linial, M. Luby, M. Saks, and D. Zuckerman, </author> <title> "Efficient Construction of a Small Hitting Set for Combinatorial Rectangles in High Dimension," </title> <booktitle> 25th ACM Symposium on Theory of Computing, </booktitle> <year> 1993, </year> <pages> pp. 258-267. </pages>
Reference-contexts: The lemma about expander graphs used in the RP construction has been used to explicitly construct a hitting set for high-dimensional rectangles <ref> [LLSZ] </ref>. Our results have recently been extended by Srinivasan and the author [SZ] to the case of subconstant ffi. In particular, they considered ffi-sources outputting R bits such that any string has probability at most 2 R * .
Reference: [MNT] <author> Y. Mansour, N. Nisan, and P. Tiwari, </author> <title> "The Computational Complexity of Universal Hashing," </title> <booktitle> 22nd ACM Symposium on Theory of Computing, </booktitle> <year> 1990, </year> <pages> pp. 235-243. 22 </pages>
Reference: [NZ] <author> N. Nisan and D. Zuckerman, </author> <title> "Randomness is Linear in Space," </title> <journal> J. Comput. Sys. </journal> <note> Sci, to ap-pear. Preliminary version, entitled "More Deterministic Simulation in Logspace," appeared in the 25th ACM Symposium on Theory of Computing, </note> <year> 1993, </year> <pages> pp. 235-244. </pages>
Reference-contexts: Hence this is also a quasi-perfect pseudo-random generator (see [San], [Sip]). Our BPP algorithm requires r O ((log 2 ffi 1 )=ffi) bits. Subsequent to this work, Noam Nisan and the author have extended and simplified the construction, building an "extractor" <ref> [NZ] </ref>, although the construction there does not imply our result. However, the ideas there do help simplify our original construction, so we present the simplified construction here. <p> The author has recently shown that the existence of an efficient algorithm to approximate any iterated logarithm of ! to within a constant factor implies that NP is recognized by slightly-superpolynomial randomized machines (see [Zu3] for the precise statement). The extension of our results in <ref> [NZ] </ref> have had applications to showing that a randomized SPACE (S) machine using poly (S) random bits can be simulated deterministically in SPACE (S) [NZ], and to constructing expander graphs that beat the eigenvalue bound [WZ]. <p> The extension of our results in <ref> [NZ] </ref> have had applications to showing that a randomized SPACE (S) machine using poly (S) random bits can be simulated deterministically in SPACE (S) [NZ], and to constructing expander graphs that beat the eigenvalue bound [WZ]. The lemma about expander graphs used in the RP construction has been used to explicitly construct a hitting set for high-dimensional rectangles [LLSZ]. <p> We actually construct an extractor <ref> [NZ] </ref>. To understand an extractor, recall that we showed earlier that it is impossible to extract a stream of quasi-random bits from a ffi-source. <p> An extractor enables us to extract many quasi-random bits, if we add a small number of truly random bits (think of t t m &lt; n in the following definition): Definition 12 <ref> [NZ] </ref> E : f0; 1g n fi f0; 1g t ! f0; 1g m is called a (ffi; *)-extractor if for any ffi-source D on f0; 1g n , the distribution of E (x; y) ffi y induced by choosing x according to D and y uniformly in f0; 1g t <p> By the remark in Subsection 2.3, this yields a simulator for BPP using a ffi 0 -source for any ffi 0 &gt; ffi. 2 Therefore, instead of directly building a simulator for BPP, we build an extractor. (Our original construction was not an extractor, but using the simplifications in <ref> [NZ] </ref> we convert our construction to an extractor.) The following theorem immediately implies Theorem 2. <p> Note that for constant ffi and *, our construction uses fewer truly random bits than the construction in <ref> [NZ] </ref>, although it outputs fewer quasi-random bits: Theorem 6 [NZ] For any parameters ffi = ffi (n) and * = *(n) with 1=n ffi 1=2 and 2 ffin * 1=n, there exists an easily computable (and explicitly given) (ffi; *)-extractor E : f0; 1g n fi f0; 1g t ! f0; <p> Note that for constant ffi and *, our construction uses fewer truly random bits than the construction in <ref> [NZ] </ref>, although it outputs fewer quasi-random bits: Theorem 6 [NZ] For any parameters ffi = ffi (n) and * = *(n) with 1=n ffi 1=2 and 2 ffin * 1=n, there exists an easily computable (and explicitly given) (ffi; *)-extractor E : f0; 1g n fi f0; 1g t ! f0; 1g m , where t = O ((log * <p> Proof. Following the proof of Lemma 7, due to <ref> [NZ] </ref>, it is easiest to prove this by working backwards. <p> This completes the induction and the proof of the lemma. 2 Unfortunately, for the reductions from a general ffi-source to a block-wise ffi-source, we need to use a block-wise ffi-source with fewer blocks. The following algorithm, taken from <ref> [NZ] </ref>, allows us to do this. The idea is to view the initial 2l truly random bits as a hash function h mapping l bits to ffil=2 bits, and to have the first block X 1 from the block-wise ffi-source be l bits long. <p> For i = s downto 1 do h i1 h i ffi h i (x i ) 5. OUTPUT (a vector in f0; 1g m ): h 0 , excluding the bits of h s . Lemma 7 <ref> [NZ] </ref> Let D be a block-wise ffi-source on f0; 1g l 1 fi : : : f0; 1g l s . <p> all but an * fraction of y 2 f0; 1g t the distribution of B ( ~ X; ~y) is within * from a ffi 0 -source, where ffi 0 = cffi= log ffi 1 and * = 3= p 12 We use the proof of this lemma given in <ref> [NZ] </ref>, with a simplified proof of Lemma 11 due to Leonard Schulman. The intuition is best seen by considering a simple proof to a slightly weaker conclusion: for all but an * fraction of the ~y's the distribution of B ( ~ X; ~y) has (ffil) entropy. <p> Indeed, this was done in <ref> [NZ] </ref>. However, this would require too many random bits. Instead, we extract one large block, as described in the previous section. We first argue that initial segments of the block of geometrically growing size are close to ffi 0 -sources.
Reference: [Rab] <author> M. O. Rabin, </author> <title> "Probabilistic Algorithm for Testing Primality," </title> <journal> Journal of Number Theory, </journal> <volume> 12: </volume> <pages> 128-138, </pages> <year> 1980. </year>
Reference-contexts: 1 Introduction Randomness plays a vital role in almost all areas of computer science, both in theory and in practice. Randomized algorithms are often faster or simpler than the deterministic algorithms for the same problem (see e.g. <ref> [Rab] </ref>). To produce "random" bits, a computer might consult a physical source of randomness, such as a Zener diode, or use the last digits of a real time clock. In either case, it is not clear how random these "random" bits will be. <p> Then the probability that at least one n-tuple among the z i contains a prime is 1 2 (R) . In order to run the primality tests we use the same strings z i . We use only the simpler co-RP algorithms for primality (see e.g. <ref> [Rab] </ref>). These algorithms require O (n) random bits, but let us 6 use n (n 2) random bits. We claim that with high probability, each composite n-bit number will have some z i as a witness to its compositeness.
Reference: [SS] <author> A. Sahay and M. </author> <title> Sudan, </title> <type> personal communication. </type>
Reference-contexts: Then, using different techniques, the author showed how to simulate RP using a ffi-source for all ffi &gt; 0 in time n O (log n) , or in polynomial time under the Generalized Paley Graph Conjecture [Zu1]. Actually, Sahay and Sudan <ref> [SS] </ref> pointed out a mistake in that paper, which we correct in this paper. In our main results, we show how to simulate RP and BPP in polynomial time using a ffi-source without any unproven assumptions. These algorithms also yield solutions to more general problems.
Reference: [SSZ] <author> M. Saks, A. Srinivasan, and S. Zhou, </author> <title> "Explicit Dispersers with Polylog Degree," </title> <booktitle> 27th ACM Symposium on Theory of Computing, </booktitle> <year> 1995, </year> <note> to appear. </note>
Reference-contexts: If * &gt; 1 1=(k + 1) for a positive integer k, they gave n O (log (k) n) time simulations of BPP (log (k) is the logarithm iterated k times). Even more recently, the above results for RP have been improved by Saks, Srinivasan, and Zhou <ref> [SSZ] </ref>. For any fixed * &gt; 0, they give a polynomial-time simulation of RP.
Reference: [San] <author> M. Santha, </author> <title> "On Using Deterministic Functions in Probabilistic Algorithms," </title> <journal> Information and Computation, </journal> <volume> 74(3): </volume> <pages> 241-249, </pages> <year> 1987. </year>
Reference-contexts: Namely, if r truly random bits are used by an RP algorithm to achieve probability of success 1=2, then O (r log r) bits from a ffi-source are used by our RP simulation. Hence this is also a quasi-perfect pseudo-random generator (see <ref> [San] </ref>, [Sip]). Our BPP algorithm requires r O ((log 2 ffi 1 )=ffi) bits. Subsequent to this work, Noam Nisan and the author have extended and simplified the construction, building an "extractor" [NZ], although the construction there does not imply our result. <p> However, the ideas there do help simplify our original construction, so we present the simplified construction here. The simulations of RP and BPP are equivalent to the explicit construction of a certain type of expander graph, called a disperser (see <ref> [San] </ref>, [Sip], [CWi]). It is easy to show that random 2 One of the bit-fixing sources in [CWi] has a weaker entropy bound than that which we impose. <p> Thus, the probability of error when the output is from a ffi-source is at most (2 ffi 0 R 1)=2 ffiR . The other direction is similar. Simulations using a ffi-source are equivalent to the construction of a certain type of expander graph, called a disperser (see <ref> [San, Sip, CWi] </ref>). We never use this graph-theoretic approach; however, it is useful to understand the equivalence, as it was used in e.g. [WZ]. Here we rephrase our results in terms of dispersers.
Reference: [SV] <author> M. Santha and U. Vazirani, </author> <title> "Generating Quasi-Random Sequences from Slightly Random Sources," </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 33 </volume> <pages> 75-87, </pages> <year> 1986. </year>
Reference-contexts: He showed that a counter-intuitive generalization of von Neumann's algorithm converts the output from such a source into a truly random string. Yet the requirement that a source be Markovian is very stringent, requiring the source to be very regular. This motivated Santha and Vazirani <ref> [SV] </ref> to ask: what if we only know that each bit that the source outputs is somewhat random? To answer this, they introduced the model of semi-random sources: Definition 1 [SV] A semi-random source with parameter ffi outputs bits X 1 X 2 : : : X R , such that <p> This motivated Santha and Vazirani <ref> [SV] </ref> to ask: what if we only know that each bit that the source outputs is somewhat random? To answer this, they introduced the model of semi-random sources: Definition 1 [SV] A semi-random source with parameter ffi outputs bits X 1 X 2 : : : X R , such that for all i R and for all x 1 ; : : :; x i 2 f0; 1g, They proved that it is impossible to extract even a single almost-random <p> This has been shown impossible for weaker models, such as the semi-random sources of <ref> [SV] </ref>, but in our case the proof is particularly simple: Lemma 1 For any ffi &lt; 1 1=n, it is impossible to extract a bit from n bits of a ffi-source that takes on both values 0 and 1 with non-zero probability. Proof.
Reference: [Sho] <author> V. Shoup, </author> <title> "New Algorithms for Finding Irreducible Polynomials Over Finite Fields," </title> <journal> Mathematics of Computation, </journal> <volume> 54(189) </volume> <pages> 435-447, </pages> <year> 1990. </year>
Reference: [Sip] <author> M. Sipser, "Expanders, </author> <title> Randomness, or Time Versus Space," </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 36: </volume> <pages> 379-383, </pages> <year> 1988. </year>
Reference-contexts: Namely, if r truly random bits are used by an RP algorithm to achieve probability of success 1=2, then O (r log r) bits from a ffi-source are used by our RP simulation. Hence this is also a quasi-perfect pseudo-random generator (see [San], <ref> [Sip] </ref>). Our BPP algorithm requires r O ((log 2 ffi 1 )=ffi) bits. Subsequent to this work, Noam Nisan and the author have extended and simplified the construction, building an "extractor" [NZ], although the construction there does not imply our result. <p> However, the ideas there do help simplify our original construction, so we present the simplified construction here. The simulations of RP and BPP are equivalent to the explicit construction of a certain type of expander graph, called a disperser (see [San], <ref> [Sip] </ref>, [CWi]). It is easy to show that random 2 One of the bit-fixing sources in [CWi] has a weaker entropy bound than that which we impose. <p> Thus, the probability of error when the output is from a ffi-source is at most (2 ffi 0 R 1)=2 ffiR . The other direction is similar. Simulations using a ffi-source are equivalent to the construction of a certain type of expander graph, called a disperser (see <ref> [San, Sip, CWi] </ref>). We never use this graph-theoretic approach; however, it is useful to understand the equivalence, as it was used in e.g. [WZ]. Here we rephrase our results in terms of dispersers.
Reference: [SZ] <author> A. Srinivasan and D. Zuckerman, </author> <title> "Computing With Very Weak Random Sources," </title> <booktitle> 35th Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1994, </year> <pages> pp. 264-275. </pages>
Reference-contexts: The lemma about expander graphs used in the RP construction has been used to explicitly construct a hitting set for high-dimensional rectangles [LLSZ]. Our results have recently been extended by Srinivasan and the author <ref> [SZ] </ref> to the case of subconstant ffi. In particular, they considered ffi-sources outputting R bits such that any string has probability at most 2 R * . For any fixed * &gt; 0, they gave an n O (log n) simulation of RP using the output from such a source.
Reference: [Tan] <author> R.M. Tanner, </author> <title> "Explicit Construction of Concentrators from Generalized N -gons," </title> <journal> SIAM J. Alg. Discr. Meth., </journal> <volume> 5 </volume> <pages> 287-293, </pages> <year> 1984. </year>
Reference-contexts: Our model can be modified to generalize this source, too, but then our simulations would fail. 3 graphs are dispersers, yet one cannot even use the eigenvalue techniques in <ref> [Tan] </ref> and [AM] to give a certificate that a random graph is a disperser (see [WZ] for more discussion on this point). This makes it especially interesting that our explicit construction works in time just polylogarithmic in the size of the graph.
Reference: [Va1] <author> U. Vazirani, </author> <title> "Randomness, Adversaries and Computation," </title> <type> Ph.D. Thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1986. </year>
Reference-contexts: In light of this result, one might give up hope for simulating randomized algorithms with one semi-random source. Nevertheless, [VV] and <ref> [Va1] </ref> showed how to simulate RP and BPP with one semi-random source. Chor and Goldreich [CG1] generalized this model by assuming no sequence of l bits has too high a probability of being output. <p> Yet we follow [VV], <ref> [Va1] </ref>, and [CG1] and deal with a more abstract "BPP" problem: let an adversary label strings in f0; 1g r either "yes" or "no," provided that at least 3=4 of the strings have the same label. <p> This method is described by the following lemma, which essentially strengthens related lemmas in <ref> [Va1] </ref> and [CG1]. This lemma is not necessary for the BPP simulation, but is helpful to better appreciate Lemma 7. Intuitively, because the Leftover Hash Lemma says that the ordered pair (h; h (x)) is close to uniform, we may use the same hash function repeatedly.
Reference: [Va2] <author> U. Vazirani, </author> <title> "Efficiency Considerations in Using Semi-Random Sources," </title> <booktitle> 19th ACM Symposium on Theory of Computing, </booktitle> <year> 1987. </year>
Reference-contexts: bits X 1 X 2 : : : X R , such that for all i R and for all x 1 ; : : :; x i 2 f0; 1g, They proved that it is impossible to extract even a single almost-random bit from one such source (so Vazirani <ref> [Va2, Va3] </ref> showed how to extract almost-random bits from two independent sources). In light of this result, one might give up hope for simulating randomized algorithms with one semi-random source. Nevertheless, [VV] and [Va1] showed how to simulate RP and BPP with one semi-random source.
Reference: [Va3] <author> U. Vazirani, </author> <title> "Strong Communication Complexity or Generating Quasi-Random Sequences from Two Communicating Semi-Random Sources," </title> <journal> Combinatorica, </journal> <volume> 7 (4): </volume> <pages> 375-392, </pages> <year> 1987. </year>
Reference-contexts: bits X 1 X 2 : : : X R , such that for all i R and for all x 1 ; : : :; x i 2 f0; 1g, They proved that it is impossible to extract even a single almost-random bit from one such source (so Vazirani <ref> [Va2, Va3] </ref> showed how to extract almost-random bits from two independent sources). In light of this result, one might give up hope for simulating randomized algorithms with one semi-random source. Nevertheless, [VV] and [Va1] showed how to simulate RP and BPP with one semi-random source.
Reference: [VV] <author> U. Vazirani and V. Vazirani, </author> <title> "Random Polynomial Time is Equal to Semi-Random Polynomial Time," </title> <booktitle> 26th Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1985, </year> <pages> pp. 417-428. </pages>
Reference-contexts: In light of this result, one might give up hope for simulating randomized algorithms with one semi-random source. Nevertheless, <ref> [VV] </ref> and [Va1] showed how to simulate RP and BPP with one semi-random source. Chor and Goldreich [CG1] generalized this model by assuming no sequence of l bits has too high a probability of being output. <p> Yet we follow <ref> [VV] </ref>, [Va1], and [CG1] and deal with a more abstract "BPP" problem: let an adversary label strings in f0; 1g r either "yes" or "no," provided that at least 3=4 of the strings have the same label.
Reference: [vN] <author> J. von Neumann, </author> <title> "Various Techniques Used in Connection with Random Digits," Notes by G.E. Forsythe, National Bureau of Standards, </title> <journal> Applied Math Series, </journal> <volume> 12 </volume> <pages> 36-38, </pages> <year> 1951. </year> <title> Reprinted in Von Neumann's Collected Works, </title> 5:768-770, 1963. 
Reference-contexts: This ties in with the recent interest in checking. The history of weak random sources reflects this ideal of using as weak a source as possible. As far back as 1951, von Neumann <ref> [vN] </ref> gave a simple and practical algorithm to extract perfectly random bits from a source of independent coin flips of equal but unknown bias.
Reference: [WZ] <author> A. Wigderson and D. Zuckerman, </author> <title> "Expanders that Beat the Eigenvalue Bound: Explicit Construction and Applications," </title> <booktitle> 25th ACM Symposium on Theory of Computing, </booktitle> <year> 1993, </year> <pages> pp. 245-251. </pages>
Reference-contexts: Yet breaking the ffi = 1=2 barrier appeared difficult, because it involves doing more than can be done by bounding the second eigenvalue of ordinary graphs (see <ref> [WZ] </ref>). Friedman and Wigderson [FW] showed how to break the barrier and improve this to all ffi &gt; 0 in the RP case if one could construct hypergraphs with small second eigenvalue; yet, constructing such hypergraphs appears difficult. <p> Our model can be modified to generalize this source, too, but then our simulations would fail. 3 graphs are dispersers, yet one cannot even use the eigenvalue techniques in [Tan] and [AM] to give a certificate that a random graph is a disperser (see <ref> [WZ] </ref> for more discussion on this point). This makes it especially interesting that our explicit construction works in time just polylogarithmic in the size of the graph. It should not be surprising that our disperser constructions are useful in other areas. <p> The extension of our results in [NZ] have had applications to showing that a randomized SPACE (S) machine using poly (S) random bits can be simulated deterministically in SPACE (S) [NZ], and to constructing expander graphs that beat the eigenvalue bound <ref> [WZ] </ref>. The lemma about expander graphs used in the RP construction has been used to explicitly construct a hitting set for high-dimensional rectangles [LLSZ]. Our results have recently been extended by Srinivasan and the author [SZ] to the case of subconstant ffi. <p> The other direction is similar. Simulations using a ffi-source are equivalent to the construction of a certain type of expander graph, called a disperser (see [San, Sip, CWi]). We never use this graph-theoretic approach; however, it is useful to understand the equivalence, as it was used in e.g. <ref> [WZ] </ref>. Here we rephrase our results in terms of dispersers.
Reference: [Zu1] <author> D. Zuckerman, </author> <title> "General Weak Random Sources," </title> <booktitle> 31st Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1990, </year> <pages> pp. 534-543. 23 </pages>
Reference-contexts: Instead, following <ref> [Zu1] </ref>, we propose upper bounding the probability that any particular string is output: Definition 3 For any number R of random bits requested, a ffi-source outputs an R-bit string such that no string has probability more than 2 ffiR of being output, for some fixed ffi &gt; 0. <p> Then, using different techniques, the author showed how to simulate RP using a ffi-source for all ffi &gt; 0 in time n O (log n) , or in polynomial time under the Generalized Paley Graph Conjecture <ref> [Zu1] </ref>. Actually, Sahay and Sudan [SS] pointed out a mistake in that paper, which we correct in this paper. In our main results, we show how to simulate RP and BPP in polynomial time using a ffi-source without any unproven assumptions. These algorithms also yield solutions to more general problems. <p> For the same reason as above, we expect a fraction at least ffi=9 of these sub-blocks to be close to ffi=9-sources. If we tried all possible sequences of sub-blocks, we would arrive at the n O (log n) algorithm of <ref> [Zu1] </ref>. To get down to polynomial time, we need to consider walks on expander graphs, and must introduce a new lemma about expanders. We now need to modify, elaborate, and formalize the above intuition. <p> To get intuition, think of ffi = fi (1), l = r and k 0 = fi (k) = fi (log r). Lemma 17 <ref> [Zu1] </ref> Let ffi, l 3=ffi, and k be given. Let k 0 = 3k=ffi, and set R = k 0 l. Let z be the R-bit output from the ffi-source. <p> Indeed, this was the main obstacle to improving the r O (log r) algorithm of <ref> [Zu1] </ref> to polynomial. 18 To get around this problem, note that the brute force approach does not exploit the fact that good r-bit blocks have many (an (ffi) fraction) good* l i -bit blocks. We exploit this by introducing a new lemma about paths on expander graphs.
Reference: [Zu2] <author> D. Zuckerman, </author> <title> "Simulating BPP Using a General Weak Random Source," </title> <booktitle> 32nd Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1991, </year> <pages> pp. 79-89. </pages>
Reference-contexts: It should not be surprising that our disperser constructions are useful in other areas. Here we give an application to showing the difficulty of approximating the size of the maximum clique. In the preliminary version <ref> [Zu2] </ref>, we also gave an application to the problem of implicit O (1) probe search. This is not included here because the author can use new dispersers to simplify and strengthen these results. The interested reader should see upcoming work by the author [Zu4].
Reference: [Zu3] <author> D. Zuckerman, </author> <title> "NP-Complete Problems Have a Version That's Hard to Approximate," </title> <booktitle> 8th IEEE Conference on Structure in Complexity Theory, </booktitle> <year> 1993, </year> <pages> pp. 305-312. </pages>
Reference-contexts: The author has recently shown that the existence of an efficient algorithm to approximate any iterated logarithm of ! to within a constant factor implies that NP is recognized by slightly-superpolynomial randomized machines (see <ref> [Zu3] </ref> for the precise statement). The extension of our results in [NZ] have had applications to showing that a randomized SPACE (S) machine using poly (S) random bits can be simulated deterministically in SPACE (S) [NZ], and to constructing expander graphs that beat the eigenvalue bound [WZ].
Reference: [Zu4] <author> D. Zuckerman, </author> <title> "An Improved Extractor and Applications." </title> <type> Unpublished manuscript. 24 </type>
Reference-contexts: In the preliminary version [Zu2], we also gave an application to the problem of implicit O (1) probe search. This is not included here because the author can use new dispersers to simplify and strengthen these results. The interested reader should see upcoming work by the author <ref> [Zu4] </ref>. Computing ! = !(G), the size of the maximum clique of the input graph G, is well known to be NP-complete [Kar].
References-found: 43

