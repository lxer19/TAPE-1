URL: http://www.cs.twsu.edu/~haynes/icmas95.ps
Refering-URL: http://adept.cs.twsu.edu/~thomas/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: [haynes,rogerw,sandip]@euler.mcs.utulsa.edu  
Title: Evolving Cooperation Strategies  
Author: Thomas Haynes, Roger Wainwright Sandip Sen 
Keyword: Topic areas: Evolutionary computation, cooperation strategies  
Address: Tulsa  
Affiliation: Department of Mathematical Computer Sciences, The University of  
Abstract: The identification, design, and implementation of strategies for cooperation is a central research issue in the field of Distributed Artificial Intelligence (DAI). We propose a novel approach to the construction of cooperation strategies for a group of problem solvers based on the Genetic Programming (GP) paradigm. GPs are a class of adaptive algorithms used to evolve solution structures that optimize a given evaluation criterion. Our approach is based on designing a representation for cooperation strategies that can be manipulated by GPs. We present results from experiments in the predator-prey domain, which has been extensively studied as a easy-to-describe but difficult-to-solve cooperation problem domain. The key aspect of our approach is the minimal reliance on domain knowledge and human intervention in the construction of good cooperation strategies. Promising comparison results with prior systems lend credence to the viability of this ap proach.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Benda, V. Jagannathan, and R. Dodhiawalla. </author> <title> On optimal cooperation of knowledge sources. </title> <type> Technical Report BCS-G2010-28, </type> <institution> Boeing AI Center, Boeing Computer Services, Bellevue, WA, </institution> <month> August </month> <year> 1985. </year>
Reference-contexts: To test our hypothesis that useful cooperation strategies can be thus evolved for non-trivial problems, we decided to use the predator-prey pursuit game <ref> [1] </ref>, a domain often used to test out new approaches to developing cooperation schemes. A wide variety of approaches [3, 7, 10, 15, 16, 17] have been used to study this domain where multiple predator agents try to capture a prey agent by surrounding it. <p> The original version of this problem was introduced by Benda, et al. <ref> [1] </ref> and consisted of four blue (predator) agents trying to capture a red (prey) agent by surrounding it from four directions on a gridworld. Agent movements were limited to one horizontal or vertical step per time unit.
Reference: [2] <editor> Lawrence Davis, editor. </editor> <booktitle> Handbook of genetic algorithms. </booktitle> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: are not guaranteed to find optimal solutions (un like Simulated Annealing algorithms), they still possess some nice provable properties (optimal allocation of trials to substrings, evaluating exponential number of schemas with linear number of string evaluations, etc.), and have been found to be useful in a number of practical applications <ref> [2] </ref>. Koza's work on Genetic Programming [8] was motivated by the representational constraint in traditional GAs.
Reference: [3] <author> Les Gasser, Nicolas Rouquette, Randall W. Hill, and John Lieb. </author> <title> Representing and using organizational knowledge in DAI systems. </title> <editor> In Les Gasser and Michael N. Huhns, editors, </editor> <booktitle> Distributed Artificial Intelligence, volume 2 of Research Notes in Artificial Intelligence, </booktitle> <pages> pages 55-78. </pages> <publisher> Pitman, </publisher> <year> 1989. </year>
Reference-contexts: To test our hypothesis that useful cooperation strategies can be thus evolved for non-trivial problems, we decided to use the predator-prey pursuit game [1], a domain often used to test out new approaches to developing cooperation schemes. A wide variety of approaches <ref> [3, 7, 10, 15, 16, 17] </ref> have been used to study this domain where multiple predator agents try to capture a prey agent by surrounding it. <p> The goal of this work was to show the effectiveness of nine organizational structures, with varying degrees of agent cooperation and control, on the efficiency with which the blue agents could capture the red agent. The approach undertaken by Gasser et al. <ref> [3] </ref> was for the predators to occupy and maintain a Lieb configuration (each predator occupying a different quadrant, where a quadrant is defined by diagonals intersecting at the location of the prey) while homing in on the prey.
Reference: [4] <author> Thomas D. Haynes and Roger L. Wainwright. </author> <title> A simulation of adaptive agents in a hostile environment. </title> <booktitle> In Proceedings of the 1995 ACM Symposium on Applied Computing, </booktitle> <pages> pages 318-323. </pages> <publisher> ACM Press, </publisher> <year> 1995. </year>
Reference-contexts: The fitness measure is then an average of the training cases. These training cases can be either the same throughout all generations or randomly generated for each generation. 4 Experimental results The GP system, GPengine, used in this research is an extension of that used in <ref> [4] </ref> and is written in C.
Reference: [5] <author> John H. Holland. </author> <booktitle> Adpatation in natural and artificial systems. </booktitle> <publisher> University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference-contexts: A predator can see the prey, but not other predators; neither do they possess any explicit communication skills (that is, two predators cannot communicate to resolve conflicts or negotiate a capture strategy). 3 Genetic Programming Holland's work on adaptive systems <ref> [5] </ref> produced a class of biologically inspired algorithms known as genetic algorithms (GAs) that can manipulate and develop solutions to optimization, learning, and other types of problems.
Reference: [6] <editor> Kenneth E. Kinnear, Jr., editor. </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: Although GPs do not possess the nice theoretical properties of traditional GAs, in a short period of time they have attracted a tremendous number of researchers because of the wide range of applicability of this paradigm, and the easily interpretable form of the solutions that are produced by these algorithms <ref> [6, 9] </ref>. A GP algorithm can be described as follows: 1. Randomly generate a population of N programs made up of functions and terminals in the prob lem. 2.
Reference: [7] <author> Richard E. Korf. </author> <title> A simple solution to pursuit games. </title> <booktitle> In Working Papers of the 11th International Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pages 183-194, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: To test our hypothesis that useful cooperation strategies can be thus evolved for non-trivial problems, we decided to use the predator-prey pursuit game [1], a domain often used to test out new approaches to developing cooperation schemes. A wide variety of approaches <ref> [3, 7, 10, 15, 16, 17] </ref> have been used to study this domain where multiple predator agents try to capture a prey agent by surrounding it. <p> Whereas their method minimizes communication between agents, it is computationally intensive, and does not provide a comparable capture rate. It also assumes that each predator can see the locations of all other predators. Finally, Korf <ref> [7] </ref> claims that a discretization of the continuous world that allows only horizontal and vertical movements (he calls this the orthogonal game) is a poor approximation, and provides greedy solutions to problems where eight predators are allowed to move diagonally as well (the diagonal game), and a world in which six <p> We have also implemented improved versions of greedy heuristic strategies for capturing the prey. Actually the improvement is obtained by changing assumptions about the environment. Korf's claim <ref> [7] </ref> that a simple solution exists for the predator prey problem can be challenged by the experimental results presented in Table 3. In particular, we do not observe significantly high capture rates.
Reference: [8] <author> John R. Koza. </author> <title> Genetic Programming, On the Programming of Computers by Means of Natural Selection. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Koza's work on Genetic Programming <ref> [8] </ref> was motivated by the representational constraint in traditional GAs.
Reference: [9] <author> John R. Koza. </author> <title> Genetic Programming II, Automatic Discovery of Reusable Programs. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Although GPs do not possess the nice theoretical properties of traditional GAs, in a short period of time they have attracted a tremendous number of researchers because of the wide range of applicability of this paradigm, and the easily interpretable form of the solutions that are produced by these algorithms <ref> [6, 9] </ref>. A GP algorithm can be described as follows: 1. Randomly generate a population of N programs made up of functions and terminals in the prob lem. 2.
Reference: [10] <author> Ran Levy and Jeffrey S. Rosenschein. </author> <title> A game theoretic approach to the pursuit problem. </title> <booktitle> In Working Papers of the 11th International Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pages 195-213, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: To test our hypothesis that useful cooperation strategies can be thus evolved for non-trivial problems, we decided to use the predator-prey pursuit game [1], a domain often used to test out new approaches to developing cooperation schemes. A wide variety of approaches <ref> [3, 7, 10, 15, 16, 17] </ref> have been used to study this domain where multiple predator agents try to capture a prey agent by surrounding it. <p> A more realistic scenario would be for all agents to choose their actions concurrently, which will introduce significant uncertainty and complexity into the problem. Levy and Rosenschein <ref> [10] </ref> use results from game theory on cooperative and non-cooperative games to choose optimal moves for the predators. Whereas their method minimizes communication between agents, it is computationally intensive, and does not provide a comparable capture rate.
Reference: [11] <author> Martin C. Martin. graphs.blt. </author> <note> GP FTP Archives, </note> <year> 1994. </year>
Reference-contexts: CellOf ( Bi, N)), MD ( CellOf ( Bi, E), CellOf ( Prey, N))), W, Program 1: The best program generated by GP. graphical reporting system was created for X-Windows using the Tcl and Tk toolkit [13], with the Blt extension; this system was a modification of that by Martin <ref> [11] </ref>. As to be expected, the initial randomly generated programs are extremely poor strategies. The GP, however, was successful in evolving increasingly effective strategies over the run as evidenced by the improvement in average and maximum fitness of structures in the population as the run progresses (see Figure 2).
Reference: [12] <author> David J. Montana. </author> <title> Strongly typed genetic programming. </title> <type> Technical Report 7866, </type> <institution> Bolt Beranek and Newman, Inc., </institution> <month> March 25, </month> <year> 1994. </year>
Reference: [13] <author> John K. Ousterhout. </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1994. </year>
Reference-contexts: ( Prey, N ))), N, IFTE ( &lt;( MD ( CellOf ( Prey, N), CellOf ( Bi, N)), MD ( CellOf ( Bi, E), CellOf ( Prey, N))), W, Program 1: The best program generated by GP. graphical reporting system was created for X-Windows using the Tcl and Tk toolkit <ref> [13] </ref>, with the Blt extension; this system was a modification of that by Martin [11]. As to be expected, the initial randomly generated programs are extremely poor strategies.
Reference: [14] <author> L. Sachs. </author> <title> Applied Statistics: A Handbook of Techniques. </title> <publisher> Springer-Verlag, </publisher> <year> 1982. </year>
Reference-contexts: predators). * Prey moving at the same time results in more capture than prey moving before predators move (except for the MD case and when the prey is moving 2 This apparently uncommon number was used for averaging so that we can use the Wilcoxon matched pair signed rank test <ref> [14] </ref> to test the significance of the results. 6 away from the nearest predator). To explain this trend, let us consider Figure 4 (a). If the prey R moves first, it can escape.
Reference: [15] <author> Munindar P. Singh. </author> <title> The effect of agent control strategy on the performance of a DAI pursuit problem. </title> <booktitle> In Working Papers of the 10th International Workshop on Distributed Artificial Intelligence, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: To test our hypothesis that useful cooperation strategies can be thus evolved for non-trivial problems, we decided to use the predator-prey pursuit game [1], a domain often used to test out new approaches to developing cooperation schemes. A wide variety of approaches <ref> [3, 7, 10, 15, 16, 17] </ref> have been used to study this domain where multiple predator agents try to capture a prey agent by surrounding it. <p> This study, as well as the study by Singh <ref> [15] </ref> on using group intentions for agent coordination, lacks any experimental results that allow comparison with other work on this problem.
Reference: [16] <author> Larry M. Stephens and Matthias B. Merx. </author> <title> Agent organization as an effector of DAI system performance. </title> <booktitle> In Working Papers of the 9th International Workshop on Distributed Artificial Intelligence, </booktitle> <month> September </month> <year> 1989. </year>
Reference-contexts: To test our hypothesis that useful cooperation strategies can be thus evolved for non-trivial problems, we decided to use the predator-prey pursuit game [1], a domain often used to test out new approaches to developing cooperation schemes. A wide variety of approaches <ref> [3, 7, 10, 15, 16, 17] </ref> have been used to study this domain where multiple predator agents try to capture a prey agent by surrounding it. <p> This study, as well as the study by Singh [15] on using group intentions for agent coordination, lacks any experimental results that allow comparison with other work on this problem. Stephens and Merx <ref> [16, 17] </ref> performed a series of experiments to demonstrate the relative effectiveness of different control strategies (local control: a predator broadcasts its position to others when it occupies a neighboring location to the prey, others then concentrate on occupying the other locations neighboring to the prey; distributed control: predators broadcast their
Reference: [17] <author> Larry M. Stephens and Matthias B. Merx. </author> <title> The effect of agent control strategy on the performance of a DAI pursuit problem. </title> <booktitle> In Proceedings of the 1990 Distributed AI Workshop, </booktitle> <month> October </month> <year> 1990. </year> <month> 9 </month>
Reference-contexts: To test our hypothesis that useful cooperation strategies can be thus evolved for non-trivial problems, we decided to use the predator-prey pursuit game [1], a domain often used to test out new approaches to developing cooperation schemes. A wide variety of approaches <ref> [3, 7, 10, 15, 16, 17] </ref> have been used to study this domain where multiple predator agents try to capture a prey agent by surrounding it. <p> This study, as well as the study by Singh [15] on using group intentions for agent coordination, lacks any experimental results that allow comparison with other work on this problem. Stephens and Merx <ref> [16, 17] </ref> performed a series of experiments to demonstrate the relative effectiveness of different control strategies (local control: a predator broadcasts its position to others when it occupies a neighboring location to the prey, others then concentrate on occupying the other locations neighboring to the prey; distributed control: predators broadcast their <p> The program developed by GP, and predator movements using the max norm (MN) and Manhattan distance (MD) metrics were run for 200 steps on 30 test cases used by Stephens <ref> [17] </ref>, and also on a further set of 1000 randomly generated configurations; average number of captures for each of the algorithms are presented in Table 3.
References-found: 17

