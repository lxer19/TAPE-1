URL: http://www.math.tau.ac.il/~mansour/papers/95eurocolt.ps.gz
Refering-URL: 
Root-URL: 
Email: eyalk@cs.technion.ac.il  
Phone: 2  3  
Title: Online Learning versus O*ine Learning  
Author: Shai Ben-David and Eyal Kushilevitz and Yishay Mansour 
Note: shai@cs.technion.ac.il  This research was supported in part by The Israel Science Foundation administered by the Israel Academy of Science and Humanities, and by a grant of the Israeli Ministry of Science and Technology.  
Address: Israel.  Israel.  Israel.  
Affiliation: 1 Computer Science Dept., Technion,  Computer Science Dept., Technion,  Computer Science Dept., Tel-Aviv University,  
Abstract: We present an off-line variant of the mistake-bound model of learning. Just like in the well studied on-line model, a learner in the offline model has to learn an unknown concept from a sequence of elements of the instance space on which he makes "guess and test" trials. In both models, the aim of the learner is to make as few mistakes as possible. The difference between the models is that, while in the on-line model only the set of possible elements is known, in the off-line model the sequence of elements (i.e., the identity of the elements as well as the order in which they are to be presented) is known to the learner in advance. We give a combinatorial characterization of the number of mistakes in the off-line model. We apply this characterization to solve several natural questions that arise for the new model. First, we compare the mistake bounds of an off-line learner to those of a learner learning the same concept classes in the on-line scenario. We show that the number of mistakes in the on-line learning is at most a log n factor more than the off-line learning, where n is the length of the sequence. In addition, we show that if there is an off-line algorithm that does not make more than a constant number of mistakes for each sequence then there is an online algorithm that also does not make more than a constant number of mistakes. The second issue we address is the effect of the ordering of the elements on the number of mistakes of an off-line learner. It turns out that there are sequences on which an off-line learner can guarantee at most one mistake, yet a permutation of the same sequence forces him to err on many elements. We prove, however, that the gap, between the off-line mistake bounds on permutations of the same sequence of n-many elements, cannot be larger than a multiplicative factor of log n, and we present examples that obtain such a gap. 
Abstract-found: 1
Intro-found: 1
Reference: [A89] <author> D. Angluin, </author> <title> "Equivalence Queries and Approximate Fingerprints" Proc. </title> <booktitle> of 2nd COLT pp. </booktitle> <pages> 134-145, </pages> <year> 1989. </year>
Reference-contexts: Finally, let EQ (S; C) 4 Note that the original definitions of Angluin <ref> [A89] </ref> are obtained by considering S = X . The following is a well known (and easy to prove) fact: Claim 2. For every X ; C and S X as above, EQ (S; C) = M on-line (S; C).
Reference: [B90a] <author> A. Blum, </author> <title> "Separating distribution-free and mistake-bound learning models over the Boolean domain" Proceedings of FOCS90, </title> <journal> pp. </journal> <pages> 211-218, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction Since defined by Littlestone [L88, L89], the on-line model of learning has attracted a considerable amount of attention (e.g., <ref> [L88, L89, LW89, B90a, B90b, M91, CM92, HLL92] </ref>). In this model the learner has to make predictions on the next instance based on the previous instances that it has already saw and their "labels". <p> Their results can be easily generalized to our setting. 7 A related result by <ref> [B90a] </ref> implies that if efficiency constraints are imposed on the model, then there are cases in which some orders are "easy" and others are compu tationally "hard".
Reference: [B90b] <author> A. Blum, </author> <title> "Learning Boolean Functions in an Infinite Attribute Space" Machine Learning, </title> <journal> Vol. </journal> <volume> 9, </volume> <year> 1992. </year> <title> (Also, </title> <booktitle> Proceedings of STOC90, </booktitle> <pages> pp. 64-72, </pages> <year> 1990.) </year>
Reference-contexts: 1 Introduction Since defined by Littlestone [L88, L89], the on-line model of learning has attracted a considerable amount of attention (e.g., <ref> [L88, L89, LW89, B90a, B90b, M91, CM92, HLL92] </ref>). In this model the learner has to make predictions on the next instance based on the previous instances that it has already saw and their "labels".
Reference: [B92] <author> A. Blum, </author> <title> "Rank-r Decision Trees are a Subclass of r-Decision Lists" Information Processing Letters, </title> <journal> Vol. </journal> <volume> 42, </volume> <pages> pp. 183-185, </pages> <year> 1992. </year>
Reference-contexts: The following section introduces these technical notions and their basic combinatorial properties. 3.1 Ranks of Trees In this subsection we define the notion of the rank of a binary tree (see, e.g., <ref> [CLR90, EH89, B92] </ref>), which plays a central role in this paper. We then prove some simple properties of this definition. For a tree T , if T is empty then rank (T ) = 1. Otherwise, let T L be its left subtree and T R be its right subtree.
Reference: [CFHHSW93] <author> N. Cesa-Bianchi, Y. Freund, D. P. Helmbold, D. Haussler, R. E. Schapire, and M. K. </author> <title> Warmuth "How to use expert advice", </title> <booktitle> Proceedings of STOC93, </booktitle> <pages> pp. 382-391, </pages> <year> 1993. </year>
Reference-contexts: In addition, we denote the worst case number of mistakes made by the on-line learner by m online . One way to view our setting is through the model of "experts" <ref> [CFHHSW93, FMG92, MF93] </ref>. For each sequence there is an expert, and each expert makes at most m worst mistakes. The on-line learner does not know the sequence in advance, so the question is how close can it get to the best expert, which makes m best mistakes.
Reference: [CM92] <author> Z. Chen, and W. Maass, </author> <booktitle> "On-line Learning of Rectangles" Proceedings of COLT92, </booktitle> <pages> pp. 16-27, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Since defined by Littlestone [L88, L89], the on-line model of learning has attracted a considerable amount of attention (e.g., <ref> [L88, L89, LW89, B90a, B90b, M91, CM92, HLL92] </ref>). In this model the learner has to make predictions on the next instance based on the previous instances that it has already saw and their "labels".
Reference: [CLR90] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Algorithms. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The following section introduces these technical notions and their basic combinatorial properties. 3.1 Ranks of Trees In this subsection we define the notion of the rank of a binary tree (see, e.g., <ref> [CLR90, EH89, B92] </ref>), which plays a central role in this paper. We then prove some simple properties of this definition. For a tree T , if T is empty then rank (T ) = 1. Otherwise, let T L be its left subtree and T R be its right subtree.
Reference: [EH89] <author> A. Ehrenfeucht, and D. Haussler, </author> <title> "Learning Decision Trees from Random Examples" Information and Computation, </title> <journal> Vol. </journal> <volume> 82, </volume> <pages> pp. 231-246, </pages> <year> 1989. </year>
Reference-contexts: The following section introduces these technical notions and their basic combinatorial properties. 3.1 Ranks of Trees In this subsection we define the notion of the rank of a binary tree (see, e.g., <ref> [CLR90, EH89, B92] </ref>), which plays a central role in this paper. We then prove some simple properties of this definition. For a tree T , if T is empty then rank (T ) = 1. Otherwise, let T L be its left subtree and T R be its right subtree.
Reference: [FMG92] <author> M. Feder, N. Merhav, and M. Gutman, </author> <title> "Universal Prediction of Individual Sequences", </title> <journal> IEEE Trans. on Information Theory, IT-38, </journal> <volume> No. 4, </volume> <pages> pp. 1258-1270, </pages> <year> 1992. </year>
Reference-contexts: In addition, we denote the worst case number of mistakes made by the on-line learner by m online . One way to view our setting is through the model of "experts" <ref> [CFHHSW93, FMG92, MF93] </ref>. For each sequence there is an expert, and each expert makes at most m worst mistakes. The on-line learner does not know the sequence in advance, so the question is how close can it get to the best expert, which makes m best mistakes.
Reference: [GRS93] <author> S. A. Goldman, R. L. Rivest, and R. E. Schapire, </author> <title> "Learning Binary Relations and Total Orders", </title> <journal> SIAM Journal on Computing, </journal> <volume> Vol. 22, No. 5, </volume> <pages> pp. 1006-1034, </pages> <year> 1993. </year>
Reference-contexts: In a few cases we are able to derive better bounds: for the cases that m worst = 1 and m worst = 2 we show simple on-line algorithms that have at most 1 and 3 mistakes, respectively. A related model is the self-directed learning studied in <ref> [GRS93, GS94] </ref>. In this model the learner is allowed to choose the sequence of instances. In a sense this is a model in which the leaner can ask membership-queries but is charged according to the number of mistakes.
Reference: [GS94] <author> S. A. Goldman, and R. H. Sloan, </author> <title> "The Power of Self-Directed Learning", </title> <journal> Machine Learning, </journal> <volume> Vol. 14, </volume> <pages> pp. 271-294, </pages> <year> 1994. </year>
Reference-contexts: In a few cases we are able to derive better bounds: for the cases that m worst = 1 and m worst = 2 we show simple on-line algorithms that have at most 1 and 3 mistakes, respectively. A related model is the self-directed learning studied in <ref> [GRS93, GS94] </ref>. In this model the learner is allowed to choose the sequence of instances. In a sense this is a model in which the leaner can ask membership-queries but is charged according to the number of mistakes. <p> The number of mistakes made in self-directed learning is related to our measure m best , however there are few differences. First, in our model the learner is given a set of instances, and then considers the best ordering of them, while in <ref> [GS94] </ref> the best sequence is out of the entire universe. <p> sequence of elements one-by-one based on previous replies, while our model assumes a "static" sequence. (One of our results shows that if there is an adaptive sequence that makes a constant number of errors then there is a static one that makes a constant number of errors.) Goldman and Sloan <ref> [GS94] </ref> address the connection between the complexity of learning a class in their model to the VC-dimension of the class.
Reference: [HLL92] <author> D.P. Helmbold, N. Littlestone, </author> <title> and P.M. Long, "Apple tasting and nearly one-sided learning", </title> <booktitle> Proceedings of FOCS92, </booktitle> <pages> pp. 493-502, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Since defined by Littlestone [L88, L89], the on-line model of learning has attracted a considerable amount of attention (e.g., <ref> [L88, L89, LW89, B90a, B90b, M91, CM92, HLL92] </ref>). In this model the learner has to make predictions on the next instance based on the previous instances that it has already saw and their "labels".
Reference: [L88] <author> N. Littlestone, </author> <title> "Learning when Irrelevant Attributes Abound: A New Linear-Threshold Algorithm" Machine Learning, </title> <journal> Vol. </journal> <volume> 2, </volume> <pages> pp. 285-318, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction Since defined by Littlestone <ref> [L88, L89] </ref>, the on-line model of learning has attracted a considerable amount of attention (e.g., [L88, L89, LW89, B90a, B90b, M91, CM92, HLL92]). In this model the learner has to make predictions on the next instance based on the previous instances that it has already saw and their "labels". <p> 1 Introduction Since defined by Littlestone [L88, L89], the on-line model of learning has attracted a considerable amount of attention (e.g., <ref> [L88, L89, LW89, B90a, B90b, M91, CM92, HLL92] </ref>). In this model the learner has to make predictions on the next instance based on the previous instances that it has already saw and their "labels". <p> The following example would be helpful in understanding both the notions and our results. Consider the class of functions which are a suffix of the interval [0; 1]. Given n points there are only n + 1 possible concepts, and therefore the Halving algorithm <ref> [L88, L89] </ref> is guaranteed to make at most O (log n) mistakes, i.e. m online = O (log n). For this class, a best sequence would be receiving the points in increasing order, in which case the learner makes at most one mistake (i.e., m best = 1). <p> We generalize this example, and show that for any concept class, the exact number of mistakes is the rank of a tree (this tree is based on the consistent extensions). This formalization of the number of mistakes, in the spirit of Littlestone`s formalization for the on-line case <ref> [L88, L89] </ref>, provides us a powerful combinatorial characterization. We study the relationships between m best , m worst and m online . Clearly m best m worst m online . <p> In Section 3 we give the definition of the rank of a tree (as well as some other related definitions), and prove some properties of it. In Section 4 we characterize the off-line complexity (for completeness, we present a characterization of the same nature, based on <ref> [L88, L89] </ref>, for the on-line complexity in Section 4.1) and we use these characterizations to obtain some basic results. In Section 5 we use these characterizations to study the gap between the on-line complexity and offline complexity. <p> The general framework is similar to the on-line learning model defined by Littlestone <ref> [L88, L89] </ref>. Let X be any set, and let C be a collection of boolean functions defined over X (i.e. C f0; 1g X ). We refer to X as the instance space and to C as the concept class. Let S be a finite subset of X . <p> Define the mistake bound of the algorithm, for a fixed S, as M (A [S]) 4 = max ;c t M (A [S]; ; c t ). Finally, let M on-line (S; C) 4 A A ;c t The original definitions of <ref> [L88, L89] </ref> are obtained (at least for finite X ) by considering S = X . An off-line learning algorithm is an algorithm A that is given (in advance) not only the set S, but also the actual sequence as an input. <p> In particular, using the Halving algorithm <ref> [L88, L89] </ref> we get, Theorem 8. For all X ; C and S as above M on-line (S; C) log jC S j. Example 1. Let X be the unit interval [0; 1]. <p> In particular, it provides a characterization of M (; C) in terms of the rank of the tree T C (for any concept class C and any sequence ). A similar characterization was proved by Littlestone <ref> [L88, L89] </ref> for the on-line case (see section 4.1 below). Theorem 9. For all X ; C and as above, M (; C) = rank (T C ). Proof. To show that M (; C) rank (T ) we present an appropriate algorithm. <p> Proof. Combine Theorem 10 with Lemma 1. ut 4.1 Characterizing the On-line It is useful, for the study of the relations between the on-line and the off-line, to have a combinatorial characterization of M on-line (S; C) as well. Such a characterization was given by Littlestone <ref> [L88, L89] </ref>. We reformulate this characterization in terms of ranks of trees. The proof remains similar to the one given by Littlestone [L88, L89] and we provide it here for completeness. Theorem 12. <p> Such a characterization was given by Littlestone <ref> [L88, L89] </ref>. We reformulate this characterization in terms of ranks of trees. The proof remains similar to the one given by Littlestone [L88, L89] and we provide it here for completeness. Theorem 12. For all X ; C and S as above, M on-line (S; C) = max rank (T ) : T 2 T C S : Proof.
Reference: [L89] <author> N. Littlestone, </author> <title> "Mistake bounds and logarithmic linear-threshold learning algorithms" PhD thesis, </title> <institution> U.C. Santa Cruz, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Since defined by Littlestone <ref> [L88, L89] </ref>, the on-line model of learning has attracted a considerable amount of attention (e.g., [L88, L89, LW89, B90a, B90b, M91, CM92, HLL92]). In this model the learner has to make predictions on the next instance based on the previous instances that it has already saw and their "labels". <p> 1 Introduction Since defined by Littlestone [L88, L89], the on-line model of learning has attracted a considerable amount of attention (e.g., <ref> [L88, L89, LW89, B90a, B90b, M91, CM92, HLL92] </ref>). In this model the learner has to make predictions on the next instance based on the previous instances that it has already saw and their "labels". <p> The following example would be helpful in understanding both the notions and our results. Consider the class of functions which are a suffix of the interval [0; 1]. Given n points there are only n + 1 possible concepts, and therefore the Halving algorithm <ref> [L88, L89] </ref> is guaranteed to make at most O (log n) mistakes, i.e. m online = O (log n). For this class, a best sequence would be receiving the points in increasing order, in which case the learner makes at most one mistake (i.e., m best = 1). <p> We generalize this example, and show that for any concept class, the exact number of mistakes is the rank of a tree (this tree is based on the consistent extensions). This formalization of the number of mistakes, in the spirit of Littlestone`s formalization for the on-line case <ref> [L88, L89] </ref>, provides us a powerful combinatorial characterization. We study the relationships between m best , m worst and m online . Clearly m best m worst m online . <p> In Section 3 we give the definition of the rank of a tree (as well as some other related definitions), and prove some properties of it. In Section 4 we characterize the off-line complexity (for completeness, we present a characterization of the same nature, based on <ref> [L88, L89] </ref>, for the on-line complexity in Section 4.1) and we use these characterizations to obtain some basic results. In Section 5 we use these characterizations to study the gap between the on-line complexity and offline complexity. <p> The general framework is similar to the on-line learning model defined by Littlestone <ref> [L88, L89] </ref>. Let X be any set, and let C be a collection of boolean functions defined over X (i.e. C f0; 1g X ). We refer to X as the instance space and to C as the concept class. Let S be a finite subset of X . <p> Define the mistake bound of the algorithm, for a fixed S, as M (A [S]) 4 = max ;c t M (A [S]; ; c t ). Finally, let M on-line (S; C) 4 A A ;c t The original definitions of <ref> [L88, L89] </ref> are obtained (at least for finite X ) by considering S = X . An off-line learning algorithm is an algorithm A that is given (in advance) not only the set S, but also the actual sequence as an input. <p> Proof. The algorithm that gets as an input can always "ignore" the order and use the on-line algorithm for S. ut 2.2 Relations to Equivalence Query Models It is well known that the on-line learning model is, basically, equivalent to the Equivalence Query (EQ) model <ref> [L89] </ref>. It is not hard to realize that our versions of the on-line scenario give rise to corresponding variants of the EQ model. <p> In particular, using the Halving algorithm <ref> [L88, L89] </ref> we get, Theorem 8. For all X ; C and S as above M on-line (S; C) log jC S j. Example 1. Let X be the unit interval [0; 1]. <p> In particular, it provides a characterization of M (; C) in terms of the rank of the tree T C (for any concept class C and any sequence ). A similar characterization was proved by Littlestone <ref> [L88, L89] </ref> for the on-line case (see section 4.1 below). Theorem 9. For all X ; C and as above, M (; C) = rank (T C ). Proof. To show that M (; C) rank (T ) we present an appropriate algorithm. <p> Proof. Combine Theorem 10 with Lemma 1. ut 4.1 Characterizing the On-line It is useful, for the study of the relations between the on-line and the off-line, to have a combinatorial characterization of M on-line (S; C) as well. Such a characterization was given by Littlestone <ref> [L88, L89] </ref>. We reformulate this characterization in terms of ranks of trees. The proof remains similar to the one given by Littlestone [L88, L89] and we provide it here for completeness. Theorem 12. <p> Such a characterization was given by Littlestone <ref> [L88, L89] </ref>. We reformulate this characterization in terms of ranks of trees. The proof remains similar to the one given by Littlestone [L88, L89] and we provide it here for completeness. Theorem 12. For all X ; C and S as above, M on-line (S; C) = max rank (T ) : T 2 T C S : Proof.
Reference: [LW89] <author> N. Littlestone, M. K. Warmuth, </author> <title> "The weighted majority algorithm", </title> <booktitle> Proceedings of FOCS89, </booktitle> <pages> pp. 256-261, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Since defined by Littlestone [L88, L89], the on-line model of learning has attracted a considerable amount of attention (e.g., <ref> [L88, L89, LW89, B90a, B90b, M91, CM92, HLL92] </ref>). In this model the learner has to make predictions on the next instance based on the previous instances that it has already saw and their "labels".
Reference: [M91] <author> W. Maass, </author> <title> "On-line Learning with an Oblivious Environment and the Power of Randomization" Proceedings of COLT91, </title> <journal> pp. </journal> <pages> 167-175, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Since defined by Littlestone [L88, L89], the on-line model of learning has attracted a considerable amount of attention (e.g., <ref> [L88, L89, LW89, B90a, B90b, M91, CM92, HLL92] </ref>). In this model the learner has to make predictions on the next instance based on the previous instances that it has already saw and their "labels".
Reference: [MF93] <author> N. Merhav and M. Feder, </author> <title> "Universal Sequential Decision Schemes from Individual Sequences", </title> <journal> IEEE Trans. on Information Theory, </journal> <volume> IT-39, </volume> <pages> pp. 1280-1292, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: In addition, we denote the worst case number of mistakes made by the on-line learner by m online . One way to view our setting is through the model of "experts" <ref> [CFHHSW93, FMG92, MF93] </ref>. For each sequence there is an expert, and each expert makes at most m worst mistakes. The on-line learner does not know the sequence in advance, so the question is how close can it get to the best expert, which makes m best mistakes.
Reference: [PF88] <author> S. Porat, and J. Feldman, </author> <title> "Learning Automata from Ordered Examples", </title> <booktitle> Proc. of 1st COLT pp. </booktitle> <pages> 386-396, </pages> <year> 1988. </year>
Reference-contexts: = EQ (A []; F ; c t ). 4 Let EQ best (S; C) 4 = min EQ (; C), and let EQ worst (S; C) 4 This variant of the equivalence query model in which the minimal counterexam ple is provided to the algorithm is studied, e.g., in <ref> [PF88] </ref>. Claim 3. For every X ; C and S X as above, for every ordering of S, EQ (; C) = M (; C). Proof.
Reference: [S72] <author> N. Sauer, </author> <title> "On the Density of Families of Sets", </title> <journal> Journal of Combinatorial Theory (A), </journal> <volume> Vol. 13, </volume> <pages> pp. 145-147, </pages> <year> 1972. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: In this case, the adversary chooses the negation of A's prediction; hence, in such a step A makes a mistake and the rank is decreased by 1. Therefore, the adversary can force a total of rank (T ) mistakes. ut Remark. It is worth noting that, by Sauer Lemma <ref> [S72] </ref>, if the concept class C has V C dimension d then the size of T C is bounded by n d (where n, as usual, is the length of ).
References-found: 19

