URL: ftp://ftp.eecs.umich.edu/people/durfee/daiw94-dr.ps.Z
Refering-URL: http://ai.eecs.umich.edu/people/durfee/vita.html
Root-URL: http://www.cs.umich.edu
Email: durfee@umich.edu, jeff@cs.huji.ac.il  
Title: Distributed Problem Solving and Multi-Agent Systems: Comparisons and Examples  
Author: Edmund H. Durfee Jeffrey S. Rosenschein 
Date: May 27, 1994  
Address: Ann Arbor, MI 48109  Jerusalem, ISRAEL  
Affiliation: EECS Department University of Michigan  Computer Science Department Hebrew University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Daniel D. Corkill and Victor R. Lesser. </author> <title> The use of meta-level control for coordination in a distributed problem solving network. </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 748-756, </pages> <institution> Karlsruhe, Federal Republic of Germany, </institution> <month> August </month> <year> 1983. </year> <note> (Also appeared in Computer Architectures for Artificial Intelligence Applications, </note> <editor> Benjamin W. Wah and G.-J. Li, editors, </editor> <publisher> IEEE Computer Society Press, </publisher> <pages> pages 507-515, </pages> <year> 1986). </year>
Reference-contexts: Similarly, a DPS system, while concentrating on robustly accomplishing an externally-imposed task, might also allow variations on internal properties, such as Corkill's work on externally-directed versus internally-directed nodes in the DVMT <ref> [1] </ref>. The variations, however, are generally quite limited. 6 3.3 View 3: MAS and DPS are complementary research agendas Implicit in View 2 is that the kinds of questions/problems asked by MAS researchers are somewhat different from those asked by DPS researchers.
Reference: [2] <author> Daniel David Corkill. </author> <title> A Framework for Organizational Self-Design in Distributed Problem Solving Networks. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, </institution> <month> February </month> <year> 1983. </year> <note> (Also published as Technical Report 82-33, </note> <institution> Department of Computer and Information Science, University of Massachusetts, </institution> <address> Amherst, Massachusetts 01003, </address> <month> December </month> <year> 1982.). </year>
Reference-contexts: Without strict guidelines about responsibilities or interests, agents can inundate each other with superfluous information. Worse, agents can work at cross purposes and send information that can distract others into pursuing unimportant tasks <ref> [2] </ref>. Also unclear is the level at which goals should be common to make a system a DPS system.
Reference: [3] <author> Edmund H. Durfee, Piotr J. Gmytrasiewicz, and Jeffrey S. Rosenschein. </author> <title> The utility of embedded communications and the emergence of protocols. </title> <booktitle> In Submitted to the 1994 Distributed AI Workshop, </booktitle> <year> 1984. </year>
Reference-contexts: On the other hand, when faced with an open system where standard task-level protocols among agents are brittle or undefined, allowing interaction patterns and protocols to emerge from first principles (agent preferences, abilities, and rationality) in an MAS manner is a promising approach <ref> [3] </ref>.
Reference: [4] <author> Eithan Ephrati and Jeffrey S. Rosenschein. </author> <title> Multi-agent planning as a dynamic search for social consensus. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: That is, MAS generally only makes assumptions about the properties of individuals (most typically, that they are rational utility-maximizers), and considers what properties will emerge internally among agents given the incentives (payoffs) and features of their environment. MAS research can thus define incentive structures (as in Clarke Tax mechanisms <ref> [4] </ref>) or environmental features (as in the ability to discover or conceal lies [12]) that either exist naturally or can be imposed such that desired internal properties (such as truth telling or fair access to resources) are achieved. Thus, this view takes a divide and conquer approach to DAI research. <p> The research questions focused on in this work concerned issues such as how efficiently the agents could coordinate their plans, how robust the approach was to agent or network failures, how performance is impacted by message delays or losses, and so on. The work of Ephrati and Rosenschein <ref> [4] </ref> addresses a similar task, namely, how can agents converge on a joint plan to achieve goals when each is constructing pieces of that plan locally.
Reference: [5] <author> Victor R. Lesser and Daniel D. Corkill. </author> <title> The Distributed Vehicle Monitoring Testbed: A tool for investigating distributed problem solving networks. </title> <journal> AI Magazine, </journal> <volume> 4(3):15 9 33, </volume> <month> Fall </month> <year> 1983. </year> <note> (Also published in Blackboard Systems, </note> <editor> Robert S. Engelmore and An--thony Morgan, </editor> <booktitle> editors, </booktitle> <pages> pages 353-386, </pages> <note> Addison-Wesley, 1988 and in Readings from AI Magazine: Volumes 1-5, </note> <editor> Robert Engelmore, </editor> <booktitle> editor, </booktitle> <pages> pages 69-85, </pages> <publisher> AAAI, </publisher> <address> Menlo Park, California, </address> <year> 1988). </year>
Reference-contexts: This assumption could be considered to be at the heart of Contract Net, and is also arguably at the core of cooperation in inherently distributed tasks, such as distributed interpretation tasks, where agents each value the development of a global result. In the DVMT <ref> [5] </ref>, for example, the system-wide goal was for the distributed sensing nodes to integrate their local maps of vehicle movements into a global map of vehicle movements.
Reference: [6] <author> Young pa So and Edmund H. Durfee. </author> <title> Distributed big brother. </title> <booktitle> In Proceedings of the Eighth IEEE Conference on AI Applications, </booktitle> <month> March </month> <year> 1992. </year>
Reference-contexts: task of designing a distributed AI system for monitoring and managing a computer network, where the prime measure of performance is to minimize user complaints, and where the implementation is under the control of the designer (s), techniques borrowed from the DPS side of the line can be fruitfully employed <ref> [6, 7] </ref>. On the other hand, when faced with an open system where standard task-level protocols among agents are brittle or undefined, allowing interaction patterns and protocols to emerge from first principles (agent preferences, abilities, and rationality) in an MAS manner is a promising approach [3].
Reference: [7] <author> Young pa So and Edmund H. Durfee. </author> <title> A distributed problem-solving infrastructure for computer network management. </title> <journal> International Journal of Intelligent and Cooperative Information Systems, </journal> <volume> 1(2) </volume> <pages> 363-392, </pages> <year> 1992. </year>
Reference-contexts: task of designing a distributed AI system for monitoring and managing a computer network, where the prime measure of performance is to minimize user complaints, and where the implementation is under the control of the designer (s), techniques borrowed from the DPS side of the line can be fruitfully employed <ref> [6, 7] </ref>. On the other hand, when faced with an open system where standard task-level protocols among agents are brittle or undefined, allowing interaction patterns and protocols to emerge from first principles (agent preferences, abilities, and rationality) in an MAS manner is a promising approach [3].
Reference: [8] <author> Jeffrey S. Rosenschein and Michael R. Genesereth. </author> <title> Deals among rational agents. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 91-99, </pages> <address> Los Angeles, California, </address> <month> August </month> <year> 1985. </year> <note> (Also published in Readings in Distributed Artificial Intelligence, </note> <editor> Alan H. Bond and Les Gasser, editors, </editor> <address> pages 227-234, </address> <publisher> Morgan Kaufmann, 1988.). </publisher>
Reference-contexts: The Benevolence Assumption. One assumption that has been proposed as a touchstone for whether a system is a DPS system is whether the agents in the system are assumed to be benevolent <ref> [8] </ref>. Typically, benevolence means that the agents want to help each other whenever possible.
Reference: [9] <author> Yoav Shoham and Moshe Tennenholtz. </author> <title> On the synthesis of useful social laws for artificial agents societies (preliminary report). </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: in the case of the common goals assumption, is to what detail must the common designer specify the agent design to make them into a DPS system? Is any commonality in design sufficient? Is identical design down to the smallest detail necessary? For example, in the case of social laws <ref> [9] </ref>, if we assume that all agents are constrained in their design to follow the laws laid down by a common designer (a legislative body, perhaps), then does this make them a DPS? Or is the fact that the society is "open" in the sense that very different agents could come
Reference: [10] <author> Reid G. Smith. </author> <title> The contract net protocol: High-level communication and control in a distributed problem solver. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-29(12):1104-1113, </volume> <month> December </month> <year> 1980. </year>
Reference-contexts: Typically, benevolence means that the agents want to help each other whenever possible. For example, in the Contract Net protocol <ref> [10] </ref>, agents allocate tasks to do based on suitability and availability, without any sense of agents asking "why should I want to do this task for this other agent." Upon hearing a task announcement in the Contract Net, an eligible agent will give an honest bid on the task, indicating how
Reference: [11] <author> Katia Sycara-Cyranski. </author> <title> Arguments of persuasion in labour mediation. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 294-296, </pages> <address> Los Angeles, California, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: If agents are meeting to hold a competition, then they might share a high-level goal 4 of holding the competition while having opposing goals as to who is supposed to win the competition. Similarly, in a situation like that studied by Sycara in her PERSUADER system <ref> [11] </ref>, where the agents are representing opposing sides in a labor contract, the agents share a goal of reaching an agreement (forming a contract) while having very diverse preferences in rating candidate contracts.
Reference: [12] <author> Gilad Zlotkin and Jeffrey S. Rosenschein. </author> <title> Cooperation and conflict resolution via negotiation among autonomous agents in non-cooperative domains. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 21(6), </volume> <month> December </month> <year> 1991. </year> <note> (Special Issue on Distributed AI). </note>
Reference-contexts: MAS research can thus define incentive structures (as in Clarke Tax mechanisms [4]) or environmental features (as in the ability to discover or conceal lies <ref> [12] </ref>) that either exist naturally or can be imposed such that desired internal properties (such as truth telling or fair access to resources) are achieved. Thus, this view takes a divide and conquer approach to DAI research. <p> For example, a MAS approach might, while concentrating on internal properties of the collection of agents, could also have some overall external behavior that can be measured and evaluated (such as maximizing global efficiency in the Postal problem <ref> [12] </ref>). Typically, though, the external problem is an abstracted/simplified version of a real problem because it is not the main emphasis of the goals of the mechanisms.
References-found: 12

