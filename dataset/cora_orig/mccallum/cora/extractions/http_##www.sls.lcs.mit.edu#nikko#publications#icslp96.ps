URL: http://www.sls.lcs.mit.edu/nikko/publications/icslp96.ps
Refering-URL: http://www.sls.lcs.mit.edu/nikko/publications/index.html
Root-URL: 
Title: SPEAKER ADAPTATION BY MODELING THE SPEAKER VARIATION IN A CONTINUOUS SPEECH RECOGNITION SYSTEM Speech, Music
Author: Nikko Strm 
Affiliation: Dept. of  
Abstract: A method for unsupervised instantaneous speaker adaptation is presented and evaluated on a continuous speech recognition task in a man-machine dialogue system. The method is based on modeling of the systematic speaker variation. The variation is modeled by a low-dimensional speaker space and the classification of speech segments is conditioned by the position in the speaker space. Because the effect of the speaker space position on the classification is determined in an offline training procedure using the speakers in a training database, complex systematic speaker variation can be modeled. Speaker adaptation is achieved only by the constraint that the position in the speaker space is constant over each utterance. Therefore, no separate adaptation session is needed and the adaptation is present from the first utterance. Consequently, for a user there is no noticeable difference between this system and a speaker-independent system. The speaker model and the phonetic classification are implemented in the ANN part of a hybrid ANN/HMM system. In experiments with a pilot system, word accuracy is improved for utterances longer than three words and utterance level results are improved for utterances of all lengths. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Bertenstam, J., Blomberg, M., Carlson, R., Elenius, K, Granstrm, B., Gustafson, J., Hunnicutt, S., Hgberg, J., Lindell, R., Neovius, L., de Serpa-Leitao, A. & Strm, N. </author> <title> "The Waxholm Application Database," </title> <booktitle> Proc. EUROSPEECH '95 pp.833-836, </booktitle> <year> 1995. </year>
Reference-contexts: In particular, we believe that explicit speaker variation modeling is advantageous for unsupervised, instantaneous adaptation. In the next sections we describe a pilot ASR system with an explicit speaker model and present some recognition results for the Waxholm database <ref> [1] </ref>. 2. THE BASELINE ASR SYSTEM The baseline ASR system is a hybrid ANN/HMM system where the output probabilities of the HMM states are estimated by output activities of an ANN [2]. 2.1. <p> Lexicon and Grammar The Markov model of the hybrid system uses the lexicon of the Waxholm dialogue project, which is a medium size (about 900 words) task-dependent lexicon with multiple pronunciations for many of the more common words <ref> [1] </ref>. A class-bigram grammar with perplexity 28 is used. 2.2. Feature Extraction Mel cepstrum coefficients are extracted from a the short-time FFT spectrum of the speech signal every 10 ms. The speech is sampled at 16kHz and the short-time spectrum is computed with a Hamming window of 25 ms.
Reference: 2. <author> Bourlard, H. & Morgan, N., </author> <title> Continuous Speech Recognition: A Hybrid Approach, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: THE BASELINE ASR SYSTEM The baseline ASR system is a hybrid ANN/HMM system where the output probabilities of the HMM states are estimated by output activities of an ANN <ref> [2] </ref>. 2.1. Lexicon and Grammar The Markov model of the hybrid system uses the lexicon of the Waxholm dialogue project, which is a medium size (about 900 words) task-dependent lexicon with multiple pronunciations for many of the more common words [1]. A class-bigram grammar with perplexity 28 is used. 2.2.
Reference: 3. <author> Gish, H. </author> <title> A Probabilistic Approach to the Understanding and Training of Neural Network Classifiers , Proc. </title> <booktitle> ICASSP 90, </booktitle> <pages> pp. 1361-1364, </pages> <year> 1990. </year>
Reference-contexts: It has been shown that the activation of the output units estimates the class probabilities, P (c i | o), where c i phoneme i and o is the acoustic observation <ref> [3] </ref>. Bayes rule gives: ( ) ( ) P c P i | = o , where P (o), is constant for all competing hypotheses and P (c i estimated offline from the training database.
Reference: 4. <author> Huang, X.D. & Lee, K.F. </author> <title> On Speaker-Independent, Speaker-Dependent and Speaker-Adaptive Speech Recognition, </title> <booktitle> Proc. ICASSP 91., </booktitle> <pages> pp. 877-880, </pages> <year> 1991. </year>
Reference-contexts: 1. INTRODUCTION It is well known that one of the fundamental problems of automatic speech recognition (ASR), the large variability in the acoustic realization, can be reduced by adapting the speech recognition system to the user <ref> [4] </ref>. When the amount of calibration data from a speaker is large enough, all parameters of the ASR system can be reestimated using the calibration data only, yielding a speaker-dependent (SD) system.
Reference: 5. <author> Leggetter, C.J. & Woodlland, </author> <title> P.C. Speaker Adaptation of Continuous Density HMMs Using Multivariate Linear Regression, </title> <booktitle> Proc. ICSLP 94, </booktitle> <pages> pp 451-454, </pages> <year> 1994. </year>
Reference: 6. <author> Pealmutter, </author> <title> B.A. Dynamic Recurrent Neural Networks, </title> <type> TR CMU-CS-88-191, </type> <institution> CMU Comp. Sc. Dept., </institution> <year> 1990. </year>
Reference-contexts: Additionally, the hidden units are fully intra-connected with recurrent connections delayed one and two frames. Finally, the 45 phoneme output units are connected to the hidden units with a timedelay window of +/- 1 frame. The network was trained using the backpropagation through time algorithm <ref> [6] </ref> on 1418 training utterances of the Waxholm database. It has been shown that the activation of the output units estimates the class probabilities, P (c i | o), where c i phoneme i and o is the acoustic observation [3].
Reference: 7. <author> Strm, N. </author> <title> A Speaker Sensitive Artificial Neural Network Architechture for Speaker Adaptation, </title> <institution> ATR TR-IT-0116 , ATR, </institution> <address> Japan, </address> <year> 1995. </year>
Reference-contexts: Therefore, after training, the positions in the speaker space of all training speakers can be determined by inspecting these connections. Figure 2 shows the speaker space of the speaker sensitive ANN used in this study with two speaker space units. In <ref> [7] </ref> we analyze this automatically generated speaker space in detail. Here we just note that male and female speakers are effectively separated in the space. The introduction of a speaker variation model in the ANN had an unanticipated positive effect on the network performance. <p> This scheme was used to train the baseline SI ANN of this study but not in <ref> [7] </ref> which partly explains the greater difference between speaker sensitive and SI classification reported there. 4. INSTANTANEOUOS UNSUPERVISED SPEAKER ADAPTATION The speakersensitive ANN can be used for different kinds of speaker adaptation.
Reference: 8. <author> Strm, N. </author> <title> Experiments with a New Algorithm for Fast Speaker Adaptation, </title> <booktitle> Proc. ICSLP 94, </booktitle> <pages> pp. 459-462, </pages> <year> 1994. </year>

References-found: 8

