URL: ftp://ftp.eecs.umich.edu/people/hero/Preprints/crc_article.ps.Z
Refering-URL: http://www.eecs.umich.edu/~hero/det_est.html
Root-URL: http://www.cs.umich.edu
Title: Signal Detection and Classification  
Author: Alfred Hero 
Address: Ann Arbor  
Affiliation: University of Michigan,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> E. L. Lehmann, </author> <title> Testing Statistical Hypotheses, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1959. </year>
Reference-contexts: The objective of signal detection and classification theory is to specify systematic strategies for designing algorithms which minimize the average number of decision errors. This theory is grounded in the mathematical discipline of statistical decision theory where detection and classification are respectively called binary and M -ary hypothesis testing <ref> [1, 2] </ref>. However, signal processing engineers must also contend with the exceedingly large size of signal processing datasets, the absence of reliable and tractible signal models, the associated requirement of fast algorithms, and the requirement for real time imbedding of unsupervised algorithms into specialized software or hardware. <p> Therefore, for composite hypotheses other design strategies must generally be adopted to ensure reliable detection performance. There are a wide range of different strategies available including: Bayesian detection [5] and hypothesis testing [6], min-max hypothesis testing [2], CFAR detection [7] and similar, unbiased hypothesis testing <ref> [1] </ref>, invariant hypothesis testing [8, 9], sequential detection [10], simultaneous detection and estimation [11], and non-parametric detection [12]. Detailed discussion of these strategies is outside of the scope of this chapter. <p> For simple hypotheses the Neyman-Pearson Lemma <ref> [1] </ref> states that there exists a most powerful test which maximizes P D subject to the constraint that P F A ff, where ff is a prespecified maximum level of false alarm. <p> It must also be mentioned that if the density g (lj H ) contains delta functions a simple randomization <ref> [1] </ref> of the LRT may be required to meet the false alarm constraint (6). <p> The complex non-central Chi-square distribution is closely related to the real non-central Chi-square distribution with 2p degrees of freedom and non-centrality parameters (; diag ([d; d])) defined in [9]. The case of = 0 and d = <ref> [1; : : : ; 1] </ref> corresponds to the standard (central) complex Chi-square distribution.
Reference: [2] <author> T. S. Ferguson, </author> <title> Mathematical Statistics A Decision Theoretic Approach, </title> <publisher> Academic Press, </publisher> <address> Orlando FL, </address> <year> 1967. </year>
Reference-contexts: The objective of signal detection and classification theory is to specify systematic strategies for designing algorithms which minimize the average number of decision errors. This theory is grounded in the mathematical discipline of statistical decision theory where detection and classification are respectively called binary and M -ary hypothesis testing <ref> [1, 2] </ref>. However, signal processing engineers must also contend with the exceedingly large size of signal processing datasets, the absence of reliable and tractible signal models, the associated requirement of fast algorithms, and the requirement for real time imbedding of unsupervised algorithms into specialized software or hardware. <p> Therefore, for composite hypotheses other design strategies must generally be adopted to ensure reliable detection performance. There are a wide range of different strategies available including: Bayesian detection [5] and hypothesis testing [6], min-max hypothesis testing <ref> [2] </ref>, CFAR detection [7] and similar, unbiased hypothesis testing [1], invariant hypothesis testing [8, 9], sequential detection [10], simultaneous detection and estimation [11], and non-parametric detection [12]. Detailed discussion of these strategies is outside of the scope of this chapter. <p> However classifiers can be designed to minimize other weaker criteria such as average misclassification probability 1 p i=1 P M i [5], worst case misclassification probability max i P M i <ref> [2] </ref>, Bayes posterior misclassification probability [13], and others. The maximum likelihood (ML) classifier is a popular classification technique which is closely related to maximum likelihood parameter estimation.
Reference: [3] <author> D. Middleton, </author> <title> An Introduction to Statistical Communication Theory, </title> <publisher> Peninsula Publishing Co, </publisher> <address> Los Altos CA (Reprint of 1960 McGraw-Hill edition), </address> <year> 1987. </year>
Reference: [4] <author> W. Davenport and W. </author> <title> Root, An introduction to the theory of random signals and noise, </title> <publisher> IEEE Press, </publisher> <address> New York (reprint of 1958 McGraw-Hill edition), </address> <year> 1987. </year>
Reference: [5] <author> H. L. Van-Trees, </author> <title> Detection, Estimation, and Modulation Theory: Part I, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1968. </year>
Reference-contexts: Good detectors have ROC curves which have desirable properties such as concavity (negative curvature), monotone increase in P D as P F A increases, high slope of P D at the point (P F A ; P D ) = (0; 0), etc. <ref> [5] </ref>. For the energy detection example shown in Fig. 1 it is evident that regardless of the actual energy 2 an increase in the rate of correct detections P D can be bought only at the expense of increasing the rate of false alarms 2 P F A . <p> Therefore, for composite hypotheses other design strategies must generally be adopted to ensure reliable detection performance. There are a wide range of different strategies available including: Bayesian detection <ref> [5] </ref> and hypothesis testing [6], min-max hypothesis testing [2], CFAR detection [7] and similar, unbiased hypothesis testing [1], invariant hypothesis testing [8, 9], sequential detection [10], simultaneous detection and estimation [11], and non-parametric detection [12]. Detailed discussion of these strategies is outside of the scope of this chapter. <p> However classifiers can be designed to minimize other weaker criteria such as average misclassification probability 1 p i=1 P M i <ref> [5] </ref>, worst case misclassification probability max i P M i [2], Bayes posterior misclassification probability [13], and others. The maximum likelihood (ML) classifier is a popular classification technique which is closely related to maximum likelihood parameter estimation. <p> For this case, the optimal classifier is given by the maximum a posteriori (MAP) decision rule <ref> [13, 5] </ref> decide H j if and only if f j (x)fi j max k f k (x)fi k ; j = 1; : : :; p: 4 The Linear Multivariate Gaussian Model Assume that X is an m fi n matrix of complex valued Gaussian random variables which obeys the
Reference: [6] <author> D. Blackwell and M. A. Girshik, </author> <title> Theory of Games and Statistical Decisions, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1954. </year>
Reference-contexts: Therefore, for composite hypotheses other design strategies must generally be adopted to ensure reliable detection performance. There are a wide range of different strategies available including: Bayesian detection [5] and hypothesis testing <ref> [6] </ref>, min-max hypothesis testing [2], CFAR detection [7] and similar, unbiased hypothesis testing [1], invariant hypothesis testing [8, 9], sequential detection [10], simultaneous detection and estimation [11], and non-parametric detection [12]. Detailed discussion of these strategies is outside of the scope of this chapter.
Reference: [7] <author> C. Helstrom, </author> <title> Elements of signal detection and estimation, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, </address> <year> 1995. </year>
Reference-contexts: Therefore, for composite hypotheses other design strategies must generally be adopted to ensure reliable detection performance. There are a wide range of different strategies available including: Bayesian detection [5] and hypothesis testing [6], min-max hypothesis testing [2], CFAR detection <ref> [7] </ref> and similar, unbiased hypothesis testing [1], invariant hypothesis testing [8, 9], sequential detection [10], simultaneous detection and estimation [11], and non-parametric detection [12]. Detailed discussion of these strategies is outside of the scope of this chapter.
Reference: [8] <author> L. L. Scharf, </author> <title> Statistical Signal Processing: Detection, Estimation, and Time Series Analysis, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1991. </year>
Reference-contexts: Therefore, for composite hypotheses other design strategies must generally be adopted to ensure reliable detection performance. There are a wide range of different strategies available including: Bayesian detection [5] and hypothesis testing [6], min-max hypothesis testing [2], CFAR detection [7] and similar, unbiased hypothesis testing [1], invariant hypothesis testing <ref> [8, 9] </ref>, sequential detection [10], simultaneous detection and estimation [11], and non-parametric detection [12]. Detailed discussion of these strategies is outside of the scope of this chapter.
Reference: [9] <author> R. J. Muirhead, </author> <title> Aspects of Multivariate Statistical Theory, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: Therefore, for composite hypotheses other design strategies must generally be adopted to ensure reliable detection performance. There are a wide range of different strategies available including: Bayesian detection [5] and hypothesis testing [6], min-max hypothesis testing [2], CFAR detection [7] and similar, unbiased hypothesis testing [1], invariant hypothesis testing <ref> [8, 9] </ref>, sequential detection [10], simultaneous detection and estimation [11], and non-parametric detection [12]. Detailed discussion of these strategies is outside of the scope of this chapter. <p> The complex non-central Chi-square distribution is closely related to the real non-central Chi-square distribution with 2p degrees of freedom and non-centrality parameters (; diag ([d; d])) defined in <ref> [9] </ref>. The case of = 0 and d = [1; : : : ; 1] corresponds to the standard (central) complex Chi-square distribution.
Reference: [10] <author> D. Siegmund, </author> <title> Sequential analysis: tests and confidence intervals, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: There are a wide range of different strategies available including: Bayesian detection [5] and hypothesis testing [6], min-max hypothesis testing [2], CFAR detection [7] and similar, unbiased hypothesis testing [1], invariant hypothesis testing [8, 9], sequential detection <ref> [10] </ref>, simultaneous detection and estimation [11], and non-parametric detection [12]. Detailed discussion of these strategies is outside of the scope of this chapter.
Reference: [11] <author> B. Baygun and A. O. Hero, </author> <title> "Optimal simultaneous detection and estimation under a false alarm constraint," </title> <journal> IEEE Trans. on Inform. Theory, </journal> <volume> vol. 41, no. 3, </volume> <pages> pp. 688-703, </pages> <year> 1995. </year>
Reference-contexts: There are a wide range of different strategies available including: Bayesian detection [5] and hypothesis testing [6], min-max hypothesis testing [2], CFAR detection [7] and similar, unbiased hypothesis testing [1], invariant hypothesis testing [8, 9], sequential detection [10], simultaneous detection and estimation <ref> [11] </ref>, and non-parametric detection [12]. Detailed discussion of these strategies is outside of the scope of this chapter.
Reference: [12] <author> S. Kassam and J. Thomas, </author> <title> Nonparametric detection theory and applications, </title> <editor> Dowden, Hutchinson and Ross, </editor> <year> 1980. </year>
Reference-contexts: There are a wide range of different strategies available including: Bayesian detection [5] and hypothesis testing [6], min-max hypothesis testing [2], CFAR detection [7] and similar, unbiased hypothesis testing [1], invariant hypothesis testing [8, 9], sequential detection [10], simultaneous detection and estimation [11], and non-parametric detection <ref> [12] </ref>. Detailed discussion of these strategies is outside of the scope of this chapter.
Reference: [13] <author> K. Fukunaga, </author> <title> Statistical Pattern Recognition (2nd Ed), </title> <publisher> Academic Press, </publisher> <address> San Diego CA, </address> <year> 1990. </year>
Reference-contexts: However classifiers can be designed to minimize other weaker criteria such as average misclassification probability 1 p i=1 P M i [5], worst case misclassification probability max i P M i [2], Bayes posterior misclassification probability <ref> [13] </ref>, and others. The maximum likelihood (ML) classifier is a popular classification technique which is closely related to maximum likelihood parameter estimation. <p> For this case, the optimal classifier is given by the maximum a posteriori (MAP) decision rule <ref> [13, 5] </ref> decide H j if and only if f j (x)fi j max k f k (x)fi k ; j = 1; : : :; p: 4 The Linear Multivariate Gaussian Model Assume that X is an m fi n matrix of complex valued Gaussian random variables which obeys the <p> Even for this case no general closed form expressions for P M k is available. However, analytical lower bounds on P M k and on average missclassification probability 1 p k=1 P M k can be used to qualitatively assess classifer performance <ref> [13] </ref>. 7.2 Classifying Presence of Multiple Signals We next treat the problem where the signal component of the observation is the linear combination of one of J hypothesized subsets S k , k = 1; : : :; J, of the signal waveforms b 1 ; : : : ; b
Reference: [14] <author> E. J. Kelly and K. M. </author> <title> Forsythe, "Adaptive detection and parameter estimation for multidimensional signal models," </title> <type> Technical Report 848, </type> <institution> M.I.T. Lincoln Laboratory, </institution> <month> April, </month> <year> 1989. </year>
Reference-contexts: D denotes the kronecker product which is the following pr fi qs matrix: C D = 6 6 4 C d 21 C d 22 : : : C d 2s . . . . . . 3 7 7 : (11) The density function of X has the form <ref> [14] </ref> f (X; ) = mn jR w j n exp tr [X ASB][X ASB] H R 1 o where jCj is the determinant and trfDg is the trace of square matrices C and D. <p> The case of = 0 and d = [1; : : : ; 1] corresponds to the standard (central) complex Chi-square distribution. For derivations and details on this and other related distributions see <ref> [14] </ref>. 5 Temporal Signals in Gaussian Noise Consider the time sampled superposed signal model x (t i ) = j=1 where here we interpret t i as time; but it could also be space or other domain. <p> i ) = j=1 p X s jk b k (t i ) + w (t i ); i = 1; : : :; n: This model applies to a wide range of applications in narrowband array processing and has been thoroughly studied in the context of signal detection in <ref> [14] </ref>. The m-element vector x (t i ) is a snapshot at time t i of the m-element array response to p impinging signals arriving from q dif ferent directions. <p> To avoid singular detection it is assumed that A is of rank q, q m, and that B is of rank p, p n. We consider only a few applications of this model here. For many others see <ref> [14] </ref>. 6.1 Detection: Known Gains and Known Spatial Covariance First we assume the gain matrix S and the spatial covariance R w are known. <p> This gives a composite null and alternative hypothesis for which the generalized likelihood ratio test can be derived by maximizing the known-gain likelihood ratio over the gain matrix S. The result is the GLRT <ref> [14] </ref> T g (x) = fi fi A H ^ ^ R K A fi fi fi 1 fi fi &gt; H where j j denotes the determinant, ^ R H = 1 n XX H is a sample estimate of the spatial covariance matrix using all of the snapshots, and <p> See <ref> [14] </ref> for discussion of performance and algorithms for data recursive computation of T g . <p> See [14] for discussion of performance and algorithms for data recursive computation of T g . Generalizations of this GLRT exist which incorporate non-zero mean <ref> [14, 15] </ref>. 7 Signal Classification Typical classification problems arising in signal processing are: classifying an individual signal waveform out of a set of possible linearly independent waveforms, classifying the presence of a particular set of signals as opposed to other sets of signals, classifying among specific linear combinations of signals, and
Reference: [15] <author> T. Kariya and B. K. Sinha, </author> <title> Robustness of Statistical Tests, </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1989. </year> <month> 16 </month>
Reference-contexts: See [14] for discussion of performance and algorithms for data recursive computation of T g . Generalizations of this GLRT exist which incorporate non-zero mean <ref> [14, 15] </ref>. 7 Signal Classification Typical classification problems arising in signal processing are: classifying an individual signal waveform out of a set of possible linearly independent waveforms, classifying the presence of a particular set of signals as opposed to other sets of signals, classifying among specific linear combinations of signals, and
References-found: 15

