URL: ftp://ftp.cs.umd.edu/pub/sel/papers/ese.journal.ps.Z
Refering-URL: http://www.cs.umd.edu/projects/SoftEng/tame/papers/esej.html
Root-URL: 
Email: email: lbriand@crim.ca  email: kelemam@crim.ca  email: morasca@elet.polimi.it  
Title: On the Application of Measurement Theory in Software Engineering  
Author: Lionel Briand Khaled El Emam Sandro Morasca 
Address: Montral, PQ, H3A 2H4 Canada  Montral, PQ, H3A 2H4 Canada  Piazza L. Da Vinci 32, I-20133, Milano Italy  
Affiliation: Centre de Recherche Informatique de Montral (CRIM) Software Engineering Group 1801 McGill College av.  Centre de Recherche Informatique de Montral (CRIM) Software Engineering Group 1801 McGill College av.  Dipartimento di Elettronica e Informazione Politecnico di Milano  
Note: 1  
Abstract: International Software Engineering Research Network technical report #ISERN-95-04 Abstract Elements of measurement theory have recently been introduced into the software engineering discipline. It has been suggested that these elements should serve as the basis for developing, reasoning about, and applying measures. For example, it has been suggested that software complexity measures should be additive, that measures fall into a number of distinct types (i.e., levels of measurement: nominal, ordinal, interval, and ratio), that certain statistical techniques are not appropriate for certain types of measures (e.g., parametric statistics for less-than-interval measures), and that certain transformations are not permissible for certain types of measures (e.g., nonlinear transformations for interval measures). In this paper we argue that, inspite of the importance of measurement theory, and in the context of software engineering, many of these prescriptions and proscriptions are either premature or, if strictly applied, would represent a substantial hindrance to the progress of empirical research in software engineering. This argument is based partially on studies that have been conducted by behavioral scientists and by statisticians over the last five decades. We also present a pragmatic approach to the application of measurement theory in software engineering. While following our approach may lead to violations of the strict prescriptions and proscriptions of measurement theory, we demonstrate that in practical terms these violations would have diminished consequences, especially when compared to the advantages afforded to the practicing researcher. 
Abstract-found: 1
Intro-found: 1
Reference: [AKD+81] <author> F. Andrews, L. Klem, T. Davidson, P. OMalley, and W. Rodgers: </author> <title> A Guide for Selecting Statistical Techniques for Analyzing Social Science Data , Institute for Social Research, </title> <institution> University of Michigan, </institution> <year> 1981. </year>
Reference-contexts: Such proscriptions, of course, are not unique to software engineering. For instance, they serve as the basis of the classic text of Siegel on nonparametric statistics [SC88], and serve as an integral part of the decision tree developed by Andrews et al. <ref> [AKD+81] </ref> to guide researchers in the selection of the most appropriate statistics. Accordingly, if a researchers measures do not reach the interval level, it is advised that s/he use non-parametric statistics (i.e., tests which make less stringent assumptions, such as the Mann-Whitney U test 5 ).
Reference: [BB81] <author> J. Bailey and V. Basili: </author> <title> A Meta-Model for Software Development Resource Expenditures. </title> <booktitle> In Proceedings of the International Conference on Software Engineering , pages 107-116, </booktitle> <year> 1981. </year>
Reference-contexts: In the context of software engineering, this has some serious implications. A very common transformation used in software engineering is the logarithmic transformation. This is applied frequently in the construction of effort estimation models using linear regression. As has been noted by Bailey and Basili <ref> [BB81] </ref> and Basili [Bas80], a general form of such models is: E = a L b where: E = effort L = some measure of size (usually LOC) a, b = constants Examples of this kind of model include the one developed by Walston and Felix [WF77]: E = 5.2 L
Reference: [BHP66] <author> B. Baker, C. Hardyck, and L. Petrinovich: </author> <title> Weak Measurements vs. Strong Statistics: An Empirical Critique of S. </title> <editor> S. </editor> <booktitle> Stevens Proscriptions on Statistics. In Educational and Psychological Measurement , 26 </booktitle> <pages> 291-309, </pages> <year> 1966. </year>
Reference-contexts: Unfortunately, there are no equivalent studies in software engineering on which we can base our arguments. International Software Engineering Research Network technical report #ISERN-95-04 13 5.1 Simulations By Baker et al. In <ref> [BHP66] </ref>, Baker et al. attempted to test empirically the robustness of the Student t test when used to compare the mean of samples coming from an identical distribution. <p> In addition, t values across transformation types were strongly correlated to t values of the reference interval scale. Townsend and Ashby In [TA84], Townsend and Ashbys main criticism of Baker et al <ref> [BHP66] </ref> is that "in general we have no idea as to the degree of transformation that may occur in nature." In other words, the authors think that some ordinal scale may in fact be an extreme distortion of an interval scale without the scientist realizing it.
Reference: [Bas80] <author> V. Basili: </author> <title> Resource Models. In Tutorial on Models and Metrics for Software Management and Engineering , IEEE Computer Society Press, </title> <editor> V. Basili (ed.), </editor> <year> 1980. </year>
Reference-contexts: In the context of software engineering, this has some serious implications. A very common transformation used in software engineering is the logarithmic transformation. This is applied frequently in the construction of effort estimation models using linear regression. As has been noted by Bailey and Basili [BB81] and Basili <ref> [Bas80] </ref>, a general form of such models is: E = a L b where: E = effort L = some measure of size (usually LOC) a, b = constants Examples of this kind of model include the one developed by Walston and Felix [WF77]: E = 5.2 L 0.91 and the <p> is: E = a L b where: E = effort L = some measure of size (usually LOC) a, b = constants Examples of this kind of model include the one developed by Walston and Felix [WF77]: E = 5.2 L 0.91 and the one developed at the NASA SEL <ref> [Bas80] </ref>: E = 1.4 L 0.93 As is common, when using ordinary least squares regression to develop models of this general form, an analyst would use the following estimating equation: ln E = ln a + b ln L Thus, using the above equation, ordinary least square regression estimating formulas could
Reference: [BO89] <author> J. Baroudi and W. Orlikowski: </author> <title> The Problem of Statistical Power in MIS Research. </title> <journal> In MIS Quarterly , pages 87-106, </journal> <year> 1989. </year>
Reference-contexts: Moreover, a review of published empirical research in the related discipline of Management Information Systems (MIS) <ref> [BO89] </ref> found that the power of parametric tests (such as regression and correlation) was always higher than for conventional nonparametric tests (such as the Mann-Whitney U test and the Wilcoxon test) 15 , 16 .
Reference: [BO94] <author> J. Bieman and L. M. Ott: </author> <title> "Measuring Functional Cohesion. </title> <journal> In IEEE Trans. Software Eng. </journal> , <volume> 20(8): </volume> <pages> 644-657, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Additive Ratio Scale and Extensive Structure Unfortunately, despite the arguments presented in the previous section, the argument that complexity measures should be additive [Z91] is gaining increasing acceptance (see <ref> [BO94, CK94, F94] </ref>). In this section, we perform an in-depth critical analysis of the reasoning behind such a standpoint. <p> Unfortunately, this misconception about extensive structures has already had an important impact on the scientific work and the literature. Several authors have quoted Zuse's results in major journals or used his conclusions to validate their work. Examples can be found in journals such as IEEE Transactions on Software Engineering <ref> [F94, CK94, BO94] </ref>. 4. Applying Measurement Theory 4.1 Scale Types and Proscribing Statistics We will now take a more general perspective, i.e., we will focus on the role that measurement theory should have in empirical software engineering.
Reference: [B84] <author> P. Bollman: </author> <title> "Two Axioms for Evaluation Measures in Information Retrieval." </title> <booktitle> In Research and Development in Information Retrieval , ACM, British Computer Society Workshop, Series, </booktitle> <pages> pp. 233-246, </pages> <year> 1984. </year>
Reference-contexts: The above theorem (by Bollmann <ref> [B84] </ref>) provides a set of axioms for extensive structures as a modification of the original and accepted ones, provided in [K71, R79]. In other words, 3 The notation n P denotes the composition of P with itself n times.
Reference: [Bon62] <author> C. Boneau: </author> <title> A Comparison of the Power of the U and t Tests. </title> <booktitle> In Psychological Review , 69(3) </booktitle> <pages> 246-256, </pages> <year> 1962. </year>
Reference-contexts: For example, the Pearson product moment correlation keeps its value under linear transformations (admissible for interval level scales). Second, invariance in reference, whereby the 5 This test is not truly distribution free as all nonparametric statistics are believed to be. For instance, Boneau <ref> [Bon62] </ref> shows through simulation that the Mann-Whitney U test is more sensitive to distribution differences than is the parametric t test. International Software Engineering Research Network technical report #ISERN-95-04 10 value of the statistic may change but it would still refer to the same item or location. <p> International Software Engineering Research Network technical report #ISERN-95-04 17 Boneau <ref> [Bon62] </ref> compared the empirical power of the parametric t test with the nonparametric Mann-Whitney U test. In the case of a normal distribution for both samples, equal variances, and equal group sizes, the t test clearly showed superior power for the two-tailed test at a nominal a level of 0.01. <p> For example, one simulation study concluded that the power of the t-test remains essentially unchanged when the homogeneity of variances assumption is violated <ref> [Bon62] </ref>. <p> that nonlinear 14 The power of the t-test is slightly less than that of the Mann-Whitney U test when sampling from populations whose distributions are different (e.g., normal and exponential); however, this is not the case as the sample sizes of the two groups is increased (from 5 to 15) <ref> [Bon62] </ref>. 15 For this comparison, the Effect Size was kept constant by classifying it into one of three groups defined by Cohen [Coh88]: small, medium, and large. 16 The list of nonparametric statistics excluded the common ChiSquare statistic. 17 When null hypotheses are not rejected, few software engineering researchers consider the
Reference: [BMB94] <author> L. Briand, S. Morasca, and V. Basili: </author> <title> Property Based Software Engineering Measurement. </title> <type> Technical Report , CS-TR-119, </type> <institution> University of Maryland, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: Therefore, if software measurement is to become a scientific discipline, the meaning of these concepts must be made clear and unambiguous, and similarities and differences between measurement concepts must be pointed out. Measurement Theory, if properly applied, is one of the most precious tools in this task. In <ref> [BMB94] </ref>, we proposed a set of properties to characterize size, complexity, cohesion, coupling, and length. Our goal was not to provide "the" sets of properties for each of those concepts, but to point out the need for a clear separation between them.
Reference: [CK94] <author> S. R. Chidamber and C. Kemerer: </author> <title> "A Metrics Suite for Object Oriented Design." </title> <journal> In IEEE Trans. Software Eng. </journal> , <volume> 20(6): </volume> <pages> 476-493, </pages> <month> June </month> <year> 1994. </year> <note> International Software Engineering Research Network technical report #ISERN-95-04 22 </note>
Reference-contexts: Additive Ratio Scale and Extensive Structure Unfortunately, despite the arguments presented in the previous section, the argument that complexity measures should be additive [Z91] is gaining increasing acceptance (see <ref> [BO94, CK94, F94] </ref>). In this section, we perform an in-depth critical analysis of the reasoning behind such a standpoint. <p> Unfortunately, this misconception about extensive structures has already had an important impact on the scientific work and the literature. Several authors have quoted Zuse's results in major journals or used his conclusions to validate their work. Examples can be found in journals such as IEEE Transactions on Software Engineering <ref> [F94, CK94, BO94] </ref>. 4. Applying Measurement Theory 4.1 Scale Types and Proscribing Statistics We will now take a more general perspective, i.e., we will focus on the role that measurement theory should have in empirical software engineering.
Reference: [Coh65] <author> J. Cohen: </author> <title> Some Statistical Issues in Psychological Research. In Handbook of Clinical Psychology , B. </title> <editor> Woleman (ed.), </editor> <publisher> McGraw-Hill, </publisher> <year> 1965. </year>
Reference-contexts: t-test 95.5% Friedman 2-way ANOVA F-test 64% (for k=2) 13 , 72% (for k=3) Kendalls Tau Pearsons r 91% Under the violation of the assumptions of parametric tests, their power levels do not change markedly, and they retain, in general , their greater power when compared to the nonparametric tests <ref> [Coh65] </ref>. For example, one simulation study concluded that the power of the t-test remains essentially unchanged when the homogeneity of variances assumption is violated [Bon62].
Reference: [Coh88] <author> J. Cohen: </author> <title> Statistical Power Analysis for the Behavioral Sciences , Lawrence Erlbaum Associates, </title> <year> 1988. </year>
Reference-contexts: Furthermore, the nonparametric Mann-Whitney U test remains less powerful than the parametric t test when the above assumption is violated. 9 The values in this table are based on the tables provided in [KT87] and <ref> [Coh88] </ref>. 10 The calculations of sample sizes assume that the assumptions of the tests are met. 11 Where there are analogous tables in [Coh88], the sample size values are only slightly different from [KT87] (approximately -2 difference). 12 These values were obtained from [SC88][Gib71][Gib93a][Gib93b]. 13 Where k is the number of <p> powerful than the parametric t test when the above assumption is violated. 9 The values in this table are based on the tables provided in [KT87] and <ref> [Coh88] </ref>. 10 The calculations of sample sizes assume that the assumptions of the tests are met. 11 Where there are analogous tables in [Coh88], the sample size values are only slightly different from [KT87] (approximately -2 difference). 12 These values were obtained from [SC88][Gib71][Gib93a][Gib93b]. 13 Where k is the number of treatments. <p> whose distributions are different (e.g., normal and exponential); however, this is not the case as the sample sizes of the two groups is increased (from 5 to 15) [Bon62]. 15 For this comparison, the Effect Size was kept constant by classifying it into one of three groups defined by Cohen <ref> [Coh88] </ref>: small, medium, and large. 16 The list of nonparametric statistics excluded the common ChiSquare statistic. 17 When null hypotheses are not rejected, few software engineering researchers consider the lack of statistical power as a possible contributing factor. 18 This assumes that the effect sizes would be the same for the
Reference: [CC83] <author> J. Cohen and P. Cohen: </author> <title> Applied Multiple Regression / Correlation Analysis for the Behavioral Sciences , Lawrence Erlbaum Associates, </title> <year> 1983. </year>
Reference-contexts: All this loss for essentially no gain. Similarly, in the context of multiple regression, Cohen and Cohen <ref> [CC83] </ref> state: The issue of the level of scaling and measurement precision required of quantitative variables in [Multiple Regression/Correlation] is complex and controversial. We take the position that, in practice, almost anything goes. <p> There are many reasons why researchers would choose to transform their data. For example, to make nonlinear relationships more linear or to make the data more congruent with the assumptions of a data analysis technique (for instance, to address heteroscedasticity in regression analysis) <ref> [CC83] </ref>. Thus, equation parameters can be more easily estimated, models can be interpreted in a more straightforward manner, and interpolation is made easier [MT77]. According to the principles of measurement theory, there are admissible transformations applicable to each scale type (see Section 2).
Reference: [DG84] <author> W. Dillon and M. Goldstein: </author> <title> Multivariate Analysis: </title> <publisher> Methods and Applications , Wiley & Sons, </publisher> <year> 1984. </year>
Reference-contexts: There exists a point beyond which measures are not interchangeable. One additional argument for using interval level statistics is that they offer well-developed and interpretable multivariate analysis techniques, e.g., multivariate regression analysis, and principal components analysis <ref> [DG84] </ref>. The author, in order to support this point, showed an example where the additive combination of occupational prestige, income and education results had a much stronger impact on suicide rates than each of them considered independently.
Reference: [F91] <author> N. Fenton: </author> <title> Software Metrics: A Rigorous Approach , Chapman & Hall, </title> <year> 1991. </year>
Reference-contexts: Several books and papers on the topic of measurement theory are conveying the idea that scale types should be used to proscribe the use of "inappropriate" statistical techniques. For example, a table similar to the one shown in Figure 1 is given in <ref> [F91] </ref>. This table, for instance, proscribes the use of the Pearson product moment correlation for scale types that are either nominal or ordinal. Such proscriptions, of course, are not unique to software engineering.
Reference: [F94] <author> N. Fenton: </author> <title> Software Measurement: A Necessary Scientific Basis. </title> <journal> In IEEE Transactions on Software Engineering , 20(3) </journal> <pages> 199-206, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: 1. Introduction In empirical software engineering like in other empirical sciences (e.g., experimental psychology) where measurement is noisy, uncertain, and difficult the definition of sensible measures, their statistical analysis, and the search for patterns amongst variables are difficult activities. In recent years, measurement theory has been proposed and extensively discussed <ref> [Z91, F94] </ref> as a means to evaluate the software engineering measures that have been proposed in the literature, and to establish criteria for the statistical techniques to be used in data analysis and in the search for patterns. <p> This means that measures are not defined out of context and that the theories on which they are based can be discussed, adapted, and refined. Some software engineering researchers <ref> [F94, Z91] </ref> have advised that a number of powerful statistical techniques (i.e., parametric statistics) should be proscribed when one cannot prove the measures s/he uses fulfill basic scale requirements (i.e., those of the interval scale). <p> Measurement concepts that are different in nature should be characterized by different sets of properties. For the sake of discussion, we will here examine and compare two fundamental and essentially different concepts related to the internal attributes of software products <ref> [F94] </ref>: size and complexity. The former is the only measurement concept that can be said to be fairly well understood and for which there is some sort of implicit consensus. <p> Additive Ratio Scale and Extensive Structure Unfortunately, despite the arguments presented in the previous section, the argument that complexity measures should be additive [Z91] is gaining increasing acceptance (see <ref> [BO94, CK94, F94] </ref>). In this section, we perform an in-depth critical analysis of the reasoning behind such a standpoint. <p> Unfortunately, this misconception about extensive structures has already had an important impact on the scientific work and the literature. Several authors have quoted Zuse's results in major journals or used his conclusions to validate their work. Examples can be found in journals such as IEEE Transactions on Software Engineering <ref> [F94, CK94, BO94] </ref>. 4. Applying Measurement Theory 4.1 Scale Types and Proscribing Statistics We will now take a more general perspective, i.e., we will focus on the role that measurement theory should have in empirical software engineering.
Reference: [GL89] <author> D. Galletta and A. Lederer: </author> <title> Some Cautions on the Measurement of User Information Satisfaction. </title> <booktitle> In Decision Sciences , 20 </booktitle> <pages> 419-438, </pages> <year> 1989. </year>
Reference-contexts: This kind of subjective measure is often used by researchers in the related discipline of Management Information Systems (MIS) as a surrogate for Information Systems effectiveness [Kim89]. In one article, the authors state that UIS is measured on an ordinal scale <ref> [GL89] </ref>. However, for the kind of scaling model used by this instrument (which is the summative or Likert scaling model [MC81]), some authors argue that it produces measures on an interval scale [MC81].
Reference: [Gar75] <author> P. Gardner: </author> <title> Scales and Statistics. </title> <booktitle> In Review of Educational Research , 45(1) </booktitle> <pages> 43-57, </pages> <month> Winter </month> <year> 1975. </year>
Reference-contexts: However, this very restrictive and rigid view of the use of measurement theory is not shared by many statisticians and data analysts (e.g., see <ref> [Tuk86a, Gar75, VW93] </ref>). There has been, for almost fifty years (since the publication of Steven's 1946 paper [Ste46]), another side to a very intense debate.
Reference: [Gib71] <author> J. Gibbons: </author> <title> Nonparametric Statistical Inference , McGraw-Hill, </title> <year> 1971. </year>
Reference-contexts: In general, for large samples , to achieve the same power as the Spearman correlation, a test using Pearsons coefficient would require only approximately 91% of the formers sample size [SC88]. This is called the asymptotic relative efficiency (ARE) <ref> [Gib71] </ref>. The ARE for various nonparametric tests 12 and their parametric counterparts are shown in Figure 3. Power = 90% Power = 80% Corr.
Reference: [Gib93a] <author> J. Gibbons: </author> <title> Nonparametric Statistics , Sage Publications, </title> <year> 1993. </year>
Reference: [Gib93b] <author> J. Gibbons: </author> <title> Nonparametric Measures of Association , Sage Publications, </title> <year> 1993. </year>
Reference: [IOB83] <author> B. Ives, M. Olson, and J. Baroudi: </author> <title> The Measurement of User Information Satisfaction. </title> <booktitle> In Communications of the ACM , 26(10) </booktitle> <pages> 785-793, </pages> <month> October </month> <year> 1983. </year>
Reference-contexts: Despite a few available techniques to help the researchers in particular situations (e.g., extensive structures in [LK88], as discussed in Section 3), the answer to those questions is hardly ever straightforward. A good example of the confusion about scale types are User Information Satisfaction (UIS) instruments (e.g., see <ref> [IOB83] </ref>). This kind of subjective measure is often used by researchers in the related discipline of Management Information Systems (MIS) as a surrogate for Information Systems effectiveness [Kim89]. In one article, the authors state that UIS is measured on an ordinal scale [GL89].
Reference: [Kim89] <author> K. Kim: </author> <title> User Information Satisfaction: Toward Conceptual Clarity. </title> <booktitle> In Proceedings of the 11th International Conference on Information Systems , pages 183-191, </booktitle> <year> 1989. </year>
Reference-contexts: A good example of the confusion about scale types are User Information Satisfaction (UIS) instruments (e.g., see [IOB83]). This kind of subjective measure is often used by researchers in the related discipline of Management Information Systems (MIS) as a surrogate for Information Systems effectiveness <ref> [Kim89] </ref>. In one article, the authors state that UIS is measured on an ordinal scale [GL89]. However, for the kind of scaling model used by this instrument (which is the summative or Likert scaling model [MC81]), some authors argue that it produces measures on an interval scale [MC81].
Reference: [KT87] <author> H. Kraemer and S. Thiemann: </author> <title> How Many Subjects? Statistical Power Analysis in Research , Sage Publications, </title> <year> 1987. </year>
Reference-contexts: Furthermore, the nonparametric Mann-Whitney U test remains less powerful than the parametric t test when the above assumption is violated. 9 The values in this table are based on the tables provided in <ref> [KT87] </ref> and [Coh88]. 10 The calculations of sample sizes assume that the assumptions of the tests are met. 11 Where there are analogous tables in [Coh88], the sample size values are only slightly different from [KT87] (approximately -2 difference). 12 These values were obtained from [SC88][Gib71][Gib93a][Gib93b]. 13 Where k is the <p> is violated. 9 The values in this table are based on the tables provided in <ref> [KT87] </ref> and [Coh88]. 10 The calculations of sample sizes assume that the assumptions of the tests are met. 11 Where there are analogous tables in [Coh88], the sample size values are only slightly different from [KT87] (approximately -2 difference). 12 These values were obtained from [SC88][Gib71][Gib93a][Gib93b]. 13 Where k is the number of treatments.
Reference: [K71] <author> D. Krantz, R. Luce, P. Suppes, and A. </author> <title> Tversky: </title> <booktitle> Foundations of Measurement , Vol. </booktitle> <volume> 1, </volume> <publisher> Academic Press, </publisher> <year> 1971. </year>
Reference-contexts: The above theorem (by Bollmann [B84]) provides a set of axioms for extensive structures as a modification of the original and accepted ones, provided in <ref> [K71, R79] </ref>. In other words, 3 The notation n P denotes the composition of P with itself n times.
Reference: [Lab67] <author> S. Labovitz: </author> <title> Some Observations on Measurement and Statistics. </title> <booktitle> In Social Forces , 46(2) </booktitle> <pages> 151-160, </pages> <month> December </month> <year> 1967. </year>
Reference-contexts: In an earlier independent study, Labovitz <ref> [Lab67] </ref> investigated the difference between two (hypothetical) therapies and the impact of interval scale transformations on the study of these differences. Patients having undertaken the therapies provides a rank from one to 4 according to the level of effect they think therapy had on them.
Reference: [Lab70] <author> S. Labovitz: </author> <title> The Assignment of Numbers to Rank Order Categories. </title> <booktitle> In American Sociological Review , 35 </booktitle> <pages> 515-524, </pages> <year> 1970. </year>
Reference-contexts: It would be, on the other hand, extremely difficult to determine exactly if a scale is strictly interval. 5.2 Simulations by Labovitz In one study by Labovitz <ref> [Lab70] </ref>, the author states that "Although some small error may accompany the treatment of ordinal variables as interval, this is offset by the use of more powerful, more sensitive, better developed, and more clearly interpretable statistics with known sampling errors." In this sociological study, the relationship between "occupational prestige" and suicide <p> by Labovitz [Lab71] as being extreme because such an exponential distortion nearly dichotomizes the scale (i.e., clusters the scores in one part of the scale to the extent where they are almost not distinguishable and streches the other part of the scale, thereby splitting it) and therefore, as discussed in <ref> [Lab70] </ref>, the author recommends great care in treating the data as interval if scale dichotomization is suspected for any reason. 5.3 Summary The above simulations seem to indicate that, to the extent that they are not extreme, nonlinear transformations do not strongly affect usual statistics such as the t-test or correlation
Reference: [Lab71] <author> S. Labovitz: </author> <title> In Defense of Assigning Numbers to Ranks. </title> <booktitle> In American Sociological Review , 36 </booktitle> <pages> 521-522, </pages> <year> 1971. </year>
Reference-contexts: He shows that the degree of underestimation depends on the variance on the Log Y2 scale. The larger the variance, the larger the underestimation. However, Mayer's argument was disclaimed by Labovitz <ref> [Lab71] </ref> as being extreme because such an exponential distortion nearly dichotomizes the scale (i.e., clusters the scores in one part of the scale to the extent where they are almost not distinguishable and streches the other part of the scale, thereby splitting it) and therefore, as discussed in [Lab70], the author
Reference: [LK88] <author> R. Luce and C. Krumhansl: </author> <title> Measurement, Scaling, and Psychophysics. In Stevens Handbook of Experimental Psychology , Wiley, </title> <year> 1988. </year>
Reference-contexts: Despite a few available techniques to help the researchers in particular situations (e.g., extensive structures in <ref> [LK88] </ref>, as discussed in Section 3), the answer to those questions is hardly ever straightforward. A good example of the confusion about scale types are User Information Satisfaction (UIS) instruments (e.g., see [IOB83]).
Reference: [May71] <author> L. Mayer: </author> <title> A Note on Treating Ordinal Data as Interval Data. </title> <booktitle> In American Sociological Review , 36 </booktitle> <pages> 519-520, </pages> <year> 1971. </year>
Reference-contexts: Mayer However, in a response to Labovitz, Mayer <ref> [May71] </ref> claims that under certain circumstances, treating ordinal data as interval can be disastrous.
Reference: [MC81] <author> J. McIver and E. </author> <title> Carmines: </title> <publisher> Unidimensional Scaling , Sage Publications, </publisher> <year> 1981. </year>
Reference-contexts: In one article, the authors state that UIS is measured on an ordinal scale [GL89]. However, for the kind of scaling model used by this instrument (which is the summative or Likert scaling model <ref> [MC81] </ref>), some authors argue that it produces measures on an interval scale [MC81]. <p> In one article, the authors state that UIS is measured on an ordinal scale [GL89]. However, for the kind of scaling model used by this instrument (which is the summative or Likert scaling model <ref> [MC81] </ref>), some authors argue that it produces measures on an interval scale [MC81]. What kind of statistics should be used by researchers employing the UIS instrument? Therefore, there are many cases where researchers cannot demonstrate that their scales are interval, but they are confident that they are more than only ordinal.
Reference: [M86] <author> J. Michell: </author> <title> Measurement Scales and Statistics: A Clash of Paradigms. </title> <journal> In Psychological Bulletin , 100(3) </journal> <pages> 398-407, </pages> <year> 1986. </year>
Reference-contexts: The above types of measurement scales 2 (i.e., levels of measurement) are ordered from "less powerful" to "more powerful." In particular, the more powerful scales (interval, ratio, and absolute) provide more information and are more useful for measurement purposes. Michell <ref> [M86] </ref> makes a distinction between scalespecific statements and scale-free statements. The former specifies the unit of measurement, while the latter does not specify a unit.
Reference: [MT77] <author> F. Mosteller and J. Tukey: </author> <title> Data Analysis and Regression , Addison-Wesley, </title> <year> 1977. </year>
Reference-contexts: Thus, equation parameters can be more easily estimated, models can be interpreted in a more straightforward manner, and interpolation is made easier <ref> [MT77] </ref>. According to the principles of measurement theory, there are admissible transformations applicable to each scale type (see Section 2).
Reference: [Nun78] <author> J. Nunnally: </author> <note> Psychometric Theory , McGraw-Hill, 1978. International Software Engineering Research Network technical report #ISERN-95-04 23 </note>
Reference-contexts: Consistently with the study above, Labovitz showed that the differences in scoring systems had little effect on Point-Biserial correlation coefficients (i.e., a correlation coefficient between a dichotomous and a continuous variable <ref> [Nun78] </ref>) between the therapies and the subjective scoring of patients. Similarly, he shows that test of differences between means for the two therapies are not significantly affected by the variation in scoring systems. His conclusions are similar to the ones presented above.
Reference: [Ovi80] <author> E. Oviedo: </author> <title> Control Flow, Data Flow, and Program Complexity. </title> <booktitle> In Proceedings of COMPSAC , pp. </booktitle> <pages> 146-152, </pages> <month> November </month> <year> 1980. </year>
Reference-contexts: Therefore, they should not be imposed just to achieve a ratio scale via extensive measurement. For example, most well accepted data flow complexity metrics <ref> [Ovi80] </ref> do not assume commutativity. For example, P1 o P2 might not contain as many definition-use pairs as P2 o P1.
Reference: [R79] <author> F. </author> <title> Roberts : Measurement Theory with Applications to Decisionmaking, Utility, </title> <publisher> and the Social Sciences , Addison-Wesley, </publisher> <year> 1979. </year>
Reference-contexts: Section 8 concludes the paper with a summary of the main points. 2. Basic Concepts of Measurement Theory For the reader's convenience, we now present some basic definitions and notations of measurement theory, as defined in [Z91, pp. 40 - 51], based on <ref> [R79] </ref>. A relational system A is an ordered tuple (A,R 1 n 1 m ) where A is a nonempty set of objects, the R , i = 1,,n are ki-ary relations on A and the o j , j=1,,m are closed binary operations. <p> Definition 4.4 (Meaningfulness): A statement is meaningful if and only if its truth value is invariant against all admissible transformations. Scales are also defined by admissible tranformations. For real scales there is a classification of scales according to their admissible tranformations <ref> [Ste46, Ste51, R79] </ref>: 1 Definition 4.2 was slightly changed as compared to the one in [Z91]. <p> For example, Stevens [Ste62] presents the logarithmic interval scale, and Roberts <ref> [R79] </ref> presents the difference scale. International Software Engineering Research Network technical report #ISERN-95-04 5 3. Usage and Interpretation of Measurement Theory in Software Engineering Before discussing the current state of practice in experimental software engineering, we will first discuss the important concept of complexity. <p> The above theorem (by Bollmann [B84]) provides a set of axioms for extensive structures as a modification of the original and accepted ones, provided in <ref> [K71, R79] </ref>. In other words, 3 The notation n P denotes the composition of P with itself n times.
Reference: [SC88] <author> S. Siegel and J. Castellan: </author> <title> Nonparametric Statistics for the Behavioral Sciences , McGraw Hill, </title> <year> 1988. </year>
Reference-contexts: This table, for instance, proscribes the use of the Pearson product moment correlation for scale types that are either nominal or ordinal. Such proscriptions, of course, are not unique to software engineering. For instance, they serve as the basis of the classic text of Siegel on nonparametric statistics <ref> [SC88] </ref>, and serve as an integral part of the decision tree developed by Andrews et al. [AKD+81] to guide researchers in the selection of the most appropriate statistics. <p> Second, it is quite difficult to determine precisely the scale type of a measure. An example of a nonparametric statistic that makes use of more than rank order information is the Wilcoxon signed rank test for paired differences (see <ref> [SC88] </ref>). One of the steps in calculating this statistic involves taking the difference between the scores of the paired observations. <p> In general, for large samples , to achieve the same power as the Spearman correlation, a test using Pearsons coefficient would require only approximately 91% of the formers sample size <ref> [SC88] </ref>. This is called the asymptotic relative efficiency (ARE) [Gib71]. The ARE for various nonparametric tests 12 and their parametric counterparts are shown in Figure 3. Power = 90% Power = 80% Corr.
Reference: [Ste46] <author> S. Stevens: </author> <booktitle> On the Theory of Scales of Measurement. In Science , 103(2684) </booktitle> <pages> 677-680, </pages> <month> June </month> <year> 1946. </year>
Reference-contexts: However, this very restrictive and rigid view of the use of measurement theory is not shared by many statisticians and data analysts (e.g., see [Tuk86a, Gar75, VW93]). There has been, for almost fifty years (since the publication of Steven's 1946 paper <ref> [Ste46] </ref>), another side to a very intense debate. <p> Definition 4.4 (Meaningfulness): A statement is meaningful if and only if its truth value is invariant against all admissible transformations. Scales are also defined by admissible tranformations. For real scales there is a classification of scales according to their admissible tranformations <ref> [Ste46, Ste51, R79] </ref>: 1 Definition 4.2 was slightly changed as compared to the one in [Z91]. <p> This means that the nonparametric Wilcoxon signed rank test would not be appropriate for scales deemed to be at the ordinal level. Furthermore, in one of his early papers <ref> [Ste46] </ref>, Stevens states that a rank order correlation statistic (such as Spearmans rho) assumes equal intervals between successive ranks and therefore calls for an interval scale . <p> Meeting this demand would rule out the use of all psychological tests, sociological indices, rating scales, and interview responses ... this eliminates virtually all kinds of quantitative variables on which the behavioral sciences depend. Even Stevens himself, with respect to ordinal scales, concedes that <ref> [Ste46] </ref>: "In the strictest propriety the ordinary statistics involving means and standard deviations ought not to be used with these scales, for these statistics imply a knowledge of something more than relative rank-order of data.
Reference: [Ste51] <author> S. Stevens: </author> <title> Mathematics, Measurement, and Psychophysics. In Handbook of Experimental Psychology , S. </title> <editor> Stevens (ed.), </editor> <publisher> John Wiley, </publisher> <year> 1951. </year>
Reference-contexts: Definition 4.4 (Meaningfulness): A statement is meaningful if and only if its truth value is invariant against all admissible transformations. Scales are also defined by admissible tranformations. For real scales there is a classification of scales according to their admissible tranformations <ref> [Ste46, Ste51, R79] </ref>: 1 Definition 4.2 was slightly changed as compared to the one in [Z91]. <p> However, in other papers he considers that rank correlations are appropriate for ordinal level scales [Ste62], and he considers that rank correlations are appropriate for both ordinal and interval level scales in another publication <ref> [Ste51] </ref>. Therefore, from these articles, it is not clear whether rank order correlation is appropriate or not for ordinal level scales. Caution should then be exercised when following the broad prescriptions or proscriptions that the choice of certain classes of statistics should be based on scale types.
Reference: [Ste62] <author> S. Stevens: </author> <title> Measurement, Psychophysics, and Utility. In Measurement: Definitions and Theories , C. </title> <editor> Churchman and P. Ratoosh (eds.), </editor> <publisher> John Wiley, </publisher> <year> 1962. </year>
Reference-contexts: It is clear that this transformed statement cannot be made equivalent to the original statement, and therefore the original statement is meaningless for ratio scales. 2 There are other types of measurement scales that we will not consider here because they are less common. For example, Stevens <ref> [Ste62] </ref> presents the logarithmic interval scale, and Roberts [R79] presents the difference scale. International Software Engineering Research Network technical report #ISERN-95-04 5 3. <p> Stevens <ref> [Ste68, Ste62] </ref> defines two types of invariance. First, invariance in value, whereby the numerical value of the statistic remains unchanged under the admissible transformations. For example, the Pearson product moment correlation keeps its value under linear transformations (admissible for interval level scales). <p> An example of a nonparametric statistic that makes use of more than rank order information is the Wilcoxon signed rank test for paired differences (see [SC88]). One of the steps in calculating this statistic involves taking the difference between the scores of the paired observations. As Stevens himself notes <ref> [Ste62] </ref>, this difference would have no meaning if the scores are rankings on an ordinal scale, and therefore an increasing monotonic transformation would change the values of such differences. <p> Furthermore, in one of his early papers [Ste46], Stevens states that a rank order correlation statistic (such as Spearmans rho) assumes equal intervals between successive ranks and therefore calls for an interval scale . However, in other papers he considers that rank correlations are appropriate for ordinal level scales <ref> [Ste62] </ref>, and he considers that rank correlations are appropriate for both ordinal and interval level scales in another publication [Ste51]. Therefore, from these articles, it is not clear whether rank order correlation is appropriate or not for ordinal level scales.
Reference: [Ste68] <author> S. Stevens: </author> <title> Measurement, Statistics and the Schemapiric View. </title> <booktitle> In Science , 161 </booktitle> <pages> 849-856, </pages> <year> 1968. </year>
Reference-contexts: Stevens <ref> [Ste68, Ste62] </ref> defines two types of invariance. First, invariance in value, whereby the numerical value of the statistic remains unchanged under the admissible transformations. For example, the Pearson product moment correlation keeps its value under linear transformations (admissible for interval level scales).
Reference: [SZ63] <author> P. Suppes and J. Zinnes: </author> <title> Basic Measurement Theory. </title> <booktitle> In Handbook of Mathematical Psychology , Vol. </booktitle> <volume> 1, </volume> <editor> R. Luce, R. Bush, and E. Galanter (eds.), </editor> <publisher> John Wiley, </publisher> <year> 1963. </year>
Reference-contexts: An extensive structure is a sufficient condition for obtaining a ratio scale measure, but by no means a necessary one (also see <ref> [SZ63] </ref> who make the same point). Extensive measurement is remarkable in the sense that, assuming the properties of the extensive structure to be true, one can prove that a measure is defined on a ratio scale. Moreover, additivity is in many circumstances a convenient property.
Reference: [TA84] <author> J. Townsend and F. Ashby: </author> <title> Measurement Scales and Statistics: </title> <journal> The Misconception Misconceived. In Psychological Bulletin , 96(2): </journal> <pages> 394-401, </pages> <year> 1984. </year>
Reference-contexts: In addition, t values across transformation types were strongly correlated to t values of the reference interval scale. Townsend and Ashby In <ref> [TA84] </ref>, Townsend and Ashbys main criticism of Baker et al [BHP66] is that "in general we have no idea as to the degree of transformation that may occur in nature." In other words, the authors think that some ordinal scale may in fact be an extreme distortion of an interval scale
Reference: [Tuk86a] <author> J. Tukey: </author> <title> Data Analysis and Behavioral Science or Learning to Bear the Quantitative Mans Burden by Shunning Badmandments. In The Collected Works of John W. Tukey , Vol. III, </title> <publisher> Wadsworth, </publisher> <year> 1986. </year>
Reference-contexts: However, this very restrictive and rigid view of the use of measurement theory is not shared by many statisticians and data analysts (e.g., see <ref> [Tuk86a, Gar75, VW93] </ref>). There has been, for almost fifty years (since the publication of Steven's 1946 paper [Ste46]), another side to a very intense debate. <p> By treating them as ordinal, researchers would be discarding a good deal of information. Therefore, as Tukey <ref> [Tuk86a] </ref> notes The question must be If a scale is not an interval scale, must it be merely ordinal? Is it realistic to answer questions about scale type with absolute certainty, since their answers always rely on intuition and are therefore subjective? Can we know for sure the scale types of <p> It is informative to note that much of the recent progress in the social sciences would not have been possible if the use of "approximate" measurement scales had been strictly proscribed. For example, Tukey <ref> [Tuk86a] </ref> states after summarizing Stevens proscriptions This view thus summarized is a dangerous one. If generally adopted it would not only lead to inefficient analysis of data, but it would also lead to failure to give any answer at all to questions whose answers are perfectly good, though slightly approximate.
Reference: [Tuk86b] <author> J. Tukey: </author> <title> The Future of Data Analysis. In The Collected Works of John W. Tukey , Vol. III, </title> <publisher> Wadsworth, </publisher> <year> 1986. </year>
Reference-contexts: And in those cases, should we just discard our practical questions whose answers may have a real impact on the software process because we are not 100% positive about the scale types of the measures we are using? To paraphrase Tukey <ref> [Tuk86b] </ref>, "Science is not mathematics" and we are not 6 Here, of course, we assume that there is a specific item at the median and mean values.
Reference: [VW93] <author> P. Velleman and L. Wilkinson: </author> <title> Nominal, Ordinal, Interval, and Ratio Typologies Are Misleading. </title> <booktitle> In The American Statistician , 47(1) </booktitle> <pages> 65-72, </pages> <year> 1993. </year>
Reference-contexts: However, this very restrictive and rigid view of the use of measurement theory is not shared by many statisticians and data analysts (e.g., see <ref> [Tuk86a, Gar75, VW93] </ref>). There has been, for almost fifty years (since the publication of Steven's 1946 paper [Ste46]), another side to a very intense debate.
Reference: [WF77] <author> C. Walston and C. Felix: </author> <title> A Method of Programming Measurement and Estimation. </title> <journal> In IBM Systems Journal , 1 </journal> <pages> 54-73, </pages> <year> 1977. </year>
Reference-contexts: by Bailey and Basili [BB81] and Basili [Bas80], a general form of such models is: E = a L b where: E = effort L = some measure of size (usually LOC) a, b = constants Examples of this kind of model include the one developed by Walston and Felix <ref> [WF77] </ref>: E = 5.2 L 0.91 and the one developed at the NASA SEL [Bas80]: E = 1.4 L 0.93 As is common, when using ordinary least squares regression to develop models of this general form, an analyst would use the following estimating equation: ln E = ln a + b
Reference: [W88] <author> E. Weyuker: </author> <title> Evaluating Software Complexity Measures. </title> <journal> In IEEE Transactions on Software Engineering , 14(9) </journal> <pages> 1357-1365, </pages> <year> 1988. </year>
Reference-contexts: We will now point out the problems deriving from the use of extensive structures as presented by Zuse by examining his review of Weyuker's set of properties for complexity measures <ref> [W88] </ref>. Based on the axioms of extensive structures, Zuse [Z91] states that Weyuker's properties for complexity measures are inconsistent from a measurement-theoretic point of view. <p> However, that is not true, as we now show. In what follows, P, Q, and R will represent program bodies, as defined in <ref> [W88] </ref>. Property W6 $ P, $ Q, $ R ( m (P) = m (Q) and m (P;R) m (Q;R)) 4 By W6, W7, and W9, we will denote Weyuker's properties 6, 7, and 9 of [W88]. <p> In what follows, P, Q, and R will represent program bodies, as defined in <ref> [W88] </ref>. Property W6 $ P, $ Q, $ R ( m (P) = m (Q) and m (P;R) m (Q;R)) 4 By W6, W7, and W9, we will denote Weyuker's properties 6, 7, and 9 of [W88]. These properties correspond to properties 5, 6, and 8 in the review of Weyuker's properties reported in [Z91, pp. 92-96]. <p> The above formula with existential quantifiers is the one that appears in the original published paper <ref> [W88] </ref>. <p> The above formula with existential quantifiers is the one that appears in the original published paper [W88]. Actually, Weyuker explicitly rejects the version with universal quantifiers <ref> [W88, unnumbered property after property W9] </ref>.) In [Z91, p. 96] one can read that W9 "is not meaningful for an interval scale but is meaningful for a ratio scale." All of the above comments quoted for properties W6, W7, and W9 from [Z91] are appropriate.
Reference: [Z91] <author> H. Zuse: </author> <title> Software Complexity: Measures and Methods , de Gruyter, </title> <year> 1991. </year>
Reference-contexts: 1. Introduction In empirical software engineering like in other empirical sciences (e.g., experimental psychology) where measurement is noisy, uncertain, and difficult the definition of sensible measures, their statistical analysis, and the search for patterns amongst variables are difficult activities. In recent years, measurement theory has been proposed and extensively discussed <ref> [Z91, F94] </ref> as a means to evaluate the software engineering measures that have been proposed in the literature, and to establish criteria for the statistical techniques to be used in data analysis and in the search for patterns. <p> This means that measures are not defined out of context and that the theories on which they are based can be discussed, adapted, and refined. Some software engineering researchers <ref> [F94, Z91] </ref> have advised that a number of powerful statistical techniques (i.e., parametric statistics) should be proscribed when one cannot prove the measures s/he uses fulfill basic scale requirements (i.e., those of the interval scale). <p> Section 8 concludes the paper with a summary of the main points. 2. Basic Concepts of Measurement Theory For the reader's convenience, we now present some basic definitions and notations of measurement theory, as defined in <ref> [Z91, pp. 40 - 51] </ref>, based on [R79]. <p> Scales are also defined by admissible tranformations. For real scales there is a classification of scales according to their admissible tranformations [Ste46, Ste51, R79]: 1 Definition 4.2 was slightly changed as compared to the one in <ref> [Z91] </ref>. <p> We only want to point out that additivity must not be a mandatory property for complexity measures, as opposed to size measures. 3.2 Ratio Scale vs. Additive Ratio Scale and Extensive Structure Unfortunately, despite the arguments presented in the previous section, the argument that complexity measures should be additive <ref> [Z91] </ref> is gaining increasing acceptance (see [BO94, CK94, F94]). In this section, we perform an in-depth critical analysis of the reasoning behind such a standpoint. <p> In this section, we perform an in-depth critical analysis of the reasoning behind such a standpoint. In several papers that appeared in the scientific literature on measurement properties <ref> [Z91, Z92, Z94, Z95] </ref>, Zuse advocates the need for a complexity measure to be additive, and for the underlying empirical system to "assume an extensive structure." For the reader's convenience, we will now present the definition of extensive structure used by Zuse in [Z91, p. 57] (in what follows, we will <p> in the scientific literature on measurement properties [Z91, Z92, Z94, Z95], Zuse advocates the need for a complexity measure to be additive, and for the underlying empirical system to "assume an extensive structure." For the reader's convenience, we will now present the definition of extensive structure used by Zuse in <ref> [Z91, p. 57] </ref> (in what follows, we will use [Z91] as the main reference, since it is complete, easily available, and consistent with the other references [Z92, Z94, Z95]). <p> Z94, Z95], Zuse advocates the need for a complexity measure to be additive, and for the underlying empirical system to "assume an extensive structure." For the reader's convenience, we will now present the definition of extensive structure used by Zuse in [Z91, p. 57] (in what follows, we will use <ref> [Z91] </ref> as the main reference, since it is complete, easily available, and consistent with the other references [Z92, Z94, Z95]). In [Z91, p. 46], Zuse assumes that programs are represented by their flowgraphs, and that P is the set of all flowgraphs. <p> In <ref> [Z91, p. 46] </ref>, Zuse assumes that programs are represented by their flowgraphs, and that P is the set of all flowgraphs. Theorem 4.2 (Modified Extensive Structure): Let P be a nonempty set, a binary relation on P, and o a binary operation on P . <p> In other words, 3 The notation n P denotes the composition of P with itself n times. International Software Engineering Research Network technical report #ISERN-95-04 7 axiom A1 states that there is an order relation between objects which is complete, reflexive, and transitive <ref> [Z91, p. 47] </ref> axiom A2 states that the result of a series of compositions does not depend on the order in which they are carried out axiom A3 states that the complexity of the composition of two objects does not depend on which object comes first and which comes second in <p> It is our position that some of the axioms of extensive structures are not suitable for software complexity measurement. The argument used in <ref> [Z91] </ref> in favor of the use of extensive structures is that additive measures (whose underlying empirical system is an extensive structure) are ratio scale measures. Therefore, extensive measurement is a priori appealing because it is a way of achieving the ratio scale. <p> Therefore, extensive measurement is a priori appealing because it is a way of achieving the ratio scale. However, the converse is not true, i.e., not all ratio scale measures are additive and assume an extensive structure (for instance, in <ref> [Z91] </ref>, p. 46, one can read: "Hence, a ratio scale is not always additive" and in p. 51: "However, there exist other possibilities to give necessary and sufficient conditions for the ratio scale."). <p> We will now point out the problems deriving from the use of extensive structures as presented by Zuse by examining his review of Weyuker's set of properties for complexity measures [W88]. Based on the axioms of extensive structures, Zuse <ref> [Z91] </ref> states that Weyuker's properties for complexity measures are inconsistent from a measurement-theoretic point of view. <p> These properties correspond to properties 5, 6, and 8 in the review of Weyuker's properties reported in <ref> [Z91, pp. 92-96] </ref>. International Software Engineering Research Network technical report #ISERN-95-04 8 [Z91, p. 94] says that "if this property of software complexity measures would become a general accepted property, the way to the ratio scale by the Extensive Structure would be blocked. <p> These properties correspond to properties 5, 6, and 8 in the review of Weyuker's properties reported in [Z91, pp. 92-96]. International Software Engineering Research Network technical report #ISERN-95-04 8 <ref> [Z91, p. 94] </ref> says that "if this property of software complexity measures would become a general accepted property, the way to the ratio scale by the Extensive Structure would be blocked. The axiom of monotonicity is an axiom of the Extensive Structure. <p> Extensive Structure is the way to come to the ratio scale, which is required in the literature for software complexity measures." Property W7 There are two program bodies P and Q such that Q is formed by permuting the order of the statements of P, and m (P) m (Q). <ref> [Z91, p.95] </ref> says that "Weyuker does not require the axiom of commutativity which is required by Bache /BACH87/. The axiom of commutativity is also a prerequisite of the Extensive Structure. <p> then there is no way to come to the ratio scale via the Extensive Structure and the proposed concatenation of program by Weyuker." Property W9 $ P, $ Q ( m (P) + m (Q) m (P o Q)) (It is worth noting that in Zuse's description of this property <ref> [Z91, p. 95] </ref> the existential quantifiers are substituted with universal quantifiers. The above formula with existential quantifiers is the one that appears in the original published paper [W88]. <p> The above formula with existential quantifiers is the one that appears in the original published paper [W88]. Actually, Weyuker explicitly rejects the version with universal quantifiers [W88, unnumbered property after property W9].) In <ref> [Z91, p. 96] </ref> one can read that W9 "is not meaningful for an interval scale but is meaningful for a ratio scale." All of the above comments quoted for properties W6, W7, and W9 from [Z91] are appropriate. <p> Weyuker explicitly rejects the version with universal quantifiers [W88, unnumbered property after property W9].) In [Z91, p. 96] one can read that W9 "is not meaningful for an interval scale but is meaningful for a ratio scale." All of the above comments quoted for properties W6, W7, and W9 from <ref> [Z91] </ref> are appropriate. Properties W6 and W7 are inconsistent with two of the requirements of extensive structures, i.e., weak monotonicity and weak commutativity, and property W9 is valid on a ratio scale. <p> Moreover, by applying the ratio scale admissible transformations, one can easily prove that properties W6, W7, and W9 are meaningful for the ratio scale. The above discussion of Weyuker's properties also shows that some of the extensive structure axioms, namely weak commutativity and weak monotonicity as provided by <ref> [Z91] </ref>, are NOT obviously intuitive for complexity measurement. Therefore, they should not be imposed just to achieve a ratio scale via extensive measurement. For example, most well accepted data flow complexity metrics [Ovi80] do not assume commutativity.
Reference: [Z92] <author> H. Zuse: </author> <title> Measuring Factors Contributing to Software Maintenance Complexity. </title> <booktitle> In Proceedings of the 2nd International Conference on Software Quality , Triangle Research Park, </booktitle> <address> NC, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: In this section, we perform an in-depth critical analysis of the reasoning behind such a standpoint. In several papers that appeared in the scientific literature on measurement properties <ref> [Z91, Z92, Z94, Z95] </ref>, Zuse advocates the need for a complexity measure to be additive, and for the underlying empirical system to "assume an extensive structure." For the reader's convenience, we will now present the definition of extensive structure used by Zuse in [Z91, p. 57] (in what follows, we will <p> empirical system to "assume an extensive structure." For the reader's convenience, we will now present the definition of extensive structure used by Zuse in [Z91, p. 57] (in what follows, we will use [Z91] as the main reference, since it is complete, easily available, and consistent with the other references <ref> [Z92, Z94, Z95] </ref>). In [Z91, p. 46], Zuse assumes that programs are represented by their flowgraphs, and that P is the set of all flowgraphs. Theorem 4.2 (Modified Extensive Structure): Let P be a nonempty set, a binary relation on P, and o a binary operation on P .
Reference: [Z94] <author> H. Zuse: </author> <title> "Software Complexity Metrics/Analysis." </title> <journal> In Encylopedia of Software Engineering , J. Marciniak, (ed.), </journal> <volume> Volume I, </volume> <pages> pp. 31-166, </pages> <publisher> John Wiley & Sons, </publisher> <year> 1994. </year>
Reference-contexts: In this section, we perform an in-depth critical analysis of the reasoning behind such a standpoint. In several papers that appeared in the scientific literature on measurement properties <ref> [Z91, Z92, Z94, Z95] </ref>, Zuse advocates the need for a complexity measure to be additive, and for the underlying empirical system to "assume an extensive structure." For the reader's convenience, we will now present the definition of extensive structure used by Zuse in [Z91, p. 57] (in what follows, we will <p> empirical system to "assume an extensive structure." For the reader's convenience, we will now present the definition of extensive structure used by Zuse in [Z91, p. 57] (in what follows, we will use [Z91] as the main reference, since it is complete, easily available, and consistent with the other references <ref> [Z92, Z94, Z95] </ref>). In [Z91, p. 46], Zuse assumes that programs are represented by their flowgraphs, and that P is the set of all flowgraphs. Theorem 4.2 (Modified Extensive Structure): Let P be a nonempty set, a binary relation on P, and o a binary operation on P .
Reference: [Z95] <author> H. Zuse an T. Fetcke: </author> <title> Properties of ObjectOriented Software Measures. </title> <booktitle> In Proceedings of the Annual Oregon Worshop on Software Metrics , 1995. </booktitle>
Reference-contexts: In this section, we perform an in-depth critical analysis of the reasoning behind such a standpoint. In several papers that appeared in the scientific literature on measurement properties <ref> [Z91, Z92, Z94, Z95] </ref>, Zuse advocates the need for a complexity measure to be additive, and for the underlying empirical system to "assume an extensive structure." For the reader's convenience, we will now present the definition of extensive structure used by Zuse in [Z91, p. 57] (in what follows, we will <p> empirical system to "assume an extensive structure." For the reader's convenience, we will now present the definition of extensive structure used by Zuse in [Z91, p. 57] (in what follows, we will use [Z91] as the main reference, since it is complete, easily available, and consistent with the other references <ref> [Z92, Z94, Z95] </ref>). In [Z91, p. 46], Zuse assumes that programs are represented by their flowgraphs, and that P is the set of all flowgraphs. Theorem 4.2 (Modified Extensive Structure): Let P be a nonempty set, a binary relation on P, and o a binary operation on P .
References-found: 52

