URL: ftp://markov.utstat.toronto.edu/jeff/slice.ps.Z
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Convergence of slice sampler Markov chains  
Author: by Gareth O. Roberts* and Jeffrey S. Rosenthal** 
Date: (July 1997; last revised September 10, 1998.)  
Abstract: In this paper, we analyse theoretical properties of the slice sampler. We find that the algorithm has extremely robust geometric ergodicity properties. For the case of just one auxiliary variable, we demonstrate that the algorithm is stochastically monotone, and deduce analytic bounds on the total variation distance from stationarity of the method using Foster-Lyapunov drift condition methodology. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Besag, J.E. and Green, P.J. </author> <year> (1993), </year> <title> Spatial statistics and Bayesian computation (with discussion). </title> <journal> J. Royal Stat. Soc. Ser. </journal> <volume> B 55, </volume> <pages> 25-38. </pages>
Reference: <author> Cowles, M.K. and Rosenthal, J.S. </author> <year> (1996), </year> <title> A simulation approach to convergence rates for Markov chain Monte Carlo algorithms. </title> <type> Preprint. </type>
Reference-contexts: We thus obtain that, for n 23, kP n For example, with n = 530, we obtain kP 530 Hence, for this example, just 530 iterations suffices to make the total variation distance to stationarity provably less than 1% <ref> (a convergence criterion suggested in Cowles and Rosenthal, 1996) </ref>. Now, it follows immediately from Proposition 1 that this same bound applies when (x) = e ax is the (un-normalised) density of the exponential distribution Exp (a) for any a &gt; 0, not just for a = 1.
Reference: <author> Damien, P., Wakefield, J.C. and Walker, S. </author> <year> (1997), </year> <title> Gibbs sampling for Bayesian noncon-jugate and hierarchical models using auxiliary variables. </title> <journal> J. Royal Stat. Soc., Series B, </journal> <note> to appear. </note>
Reference-contexts: Internet: G.O.Roberts@statslab.cam.ac.uk. Supported in part by EPSRC of the U.K. ** Department of Statistics, University of Toronto, Toronto, Ontario, Canada M5S 3G3. Internet: jeff@utstat.toronto.edu. Supported in part by NSERC of Canada. 1 algorithm from a practical point of view, since it frequently allows very straightforward implementation <ref> (see for example Damien et. al., 1997, and Neal, 1997) </ref>. However, except for the original Swendsen-Wang method (which has been shown to be superior to more naive Gibbs methods for sub-critical Ising models), rather little is known about the theoretical properties of auxiliary variable algorithms.
Reference: <author> Daley, D. J. </author> <year> (1968), </year> <title> Stochastically monotone Markov chains. </title> <journal> Z. Wahrscheinlichkeitsth. Verw Geb., </journal> <volume> 10, </volume> <pages> 305-317. </pages>
Reference-contexts: That is, we say that x 1 x 2 if and only if (x 1 ) (x 2 ), and that x 1 x 2 if and only if (x 1 ) &lt; (x 2 ). Now, recall <ref> (Daley, 1968) </ref> that a Markov chain X on a partially ordered space is said to be stochastically monotone if for all fixed z, we have that P (X 1 zjX 0 = x 1 ) P (X 1 zjX 0 = x 2 ) whenever x 1 x 2 , or
Reference: <author> Edwards, R.G. and Sokal, A.D. </author> <year> (1988), </year> <title> Generalization of the Fortuin-Kasteleyn-Swendsen-Wang representation and Monte Carlo algorithm. </title> <journal> Phys. Rev. Lett. </journal> <volume> 38, </volume> <pages> 2009-2012. </pages>
Reference: <author> Fishman, G. </author> <year> (1996), </year> <title> An analysis of Swendsen-Wang and Related Sampling Methods. </title> <type> Preprint, </type> <institution> University of North Carolina, Department of Operations Research. </institution>
Reference: <author> Folland, G.B. </author> <year> (1984), </year> <title> Real analysis: Modern techniques and their applications. </title> <publisher> John Wiley & Sons, </publisher> <address> New York. </address>
Reference: <author> Higdon, D.M. </author> <year> (1996), </year> <title> Auxiliary variable methods for Markov chain Monte Carlo with applications. </title> <type> Preprint, </type> <institution> Institute of Statistics and Decision Sciences, Duke University. 25 Lund, R.B. and Tweedie, R.L. </institution> <year> (1996), </year> <title> Geometric convergence rates of stochastically or-dered Markov chains. </title> <journal> Math. Oper. Research 21, </journal> <pages> 182-194. </pages>
Reference: <author> Marsden, J.E. </author> <year> (1974), </year> <title> Elementary classical analysis. W.H. </title> <publisher> Freeman and Company, </publisher> <address> New York. </address>
Reference-contexts: Furthermore, it is always possible to find such a transformation T for which the quotient f 0 =J is equal to the indicator function of a (possibly infinite) subset of R d . Proof. The first statement follows directly from the multi-dimensional change of variable formula <ref> (see e.g. Marsden, 1974, Section 9.3) </ref>; specifically, sampling T (x) from the density 1 T (L (Y)) () is equivalent to sampling x from the density f 0 ()1 L (Y) .
Reference: <author> Meyn, S.P. and Tweedie, </author> <title> R.L (1993), Markov chains and stochastic stability. </title> <publisher> Springer-Verlag, London. </publisher>
Reference: <author> Meyn, S.P. and Tweedie, R.L. </author> <year> (1994), </year> <title> Computable bounds for convergence rates of Markov chains. </title> <journal> Ann. Appl. Prob. </journal> <volume> 4, </volume> <pages> 981-1011. </pages>
Reference: <author> Mira, A. and Tierney, L. </author> <year> (1997), </year> <title> On the use of auxiliary variables in Markov chain Monte Carlo sampling. </title> <type> Preprint, </type> <institution> School of Statistics, University of Minnesota. </institution>
Reference: <author> Neal, R. </author> <title> (1997) Markov chain Monte Carlo methods based on `slicing' the density function. </title> <type> Preprint. </type>
Reference-contexts: Internet: G.O.Roberts@statslab.cam.ac.uk. Supported in part by EPSRC of the U.K. ** Department of Statistics, University of Toronto, Toronto, Ontario, Canada M5S 3G3. Internet: jeff@utstat.toronto.edu. Supported in part by NSERC of Canada. 1 algorithm from a practical point of view, since it frequently allows very straightforward implementation <ref> (see for example Damien et. al., 1997, and Neal, 1997) </ref>. However, except for the original Swendsen-Wang method (which has been shown to be superior to more naive Gibbs methods for sub-critical Ising models), rather little is known about the theoretical properties of auxiliary variable algorithms.
Reference: <author> Nummelin, E. </author> <year> (1984), </year> <title> General irreducible Markov chains and non-negative operators. </title> <publisher> Cam-bridge University Press. </publisher>
Reference: <author> Peskun, P.H. </author> <year> (1973), </year> <title> Optimum Monte Carlo sampling using Markov chains. </title> <journal> Biometrika 60, </journal> <pages> 607-612. </pages>
Reference: <author> Polson, N.G. </author> <year> (1996), </year> <title> Convergence of Markov chain Monte Carlo algorithms. </title> <booktitle> In Bayesian Statistics V, </booktitle> <pages> 599-608, </pages> <publisher> Clarendon press, Oxford. </publisher>
Reference-contexts: Previous rigorous quantitative bounds for MCMC samplers have generally been established only for very specific models (Meyn and Tweedie, 1994; Rosenthal, 23 1995) or have involved large undetermined constants <ref> (Polson, 1996) </ref>. Indeed, we know of no comparable result which gives a reasonable uniform bound on the convergence rate of a realistic sampling algorithm, over such a broad class of distributions. Of course, it may not always be easy to implement a slice sampler for a particular problem.
Reference: <author> Roberts, </author> <title> G.O. (1991), A comparison theorem for conditioned Markov processes. </title> <journal> J. Appl. Prob. </journal> <volume> 28, </volume> <pages> 74-83. </pages>
Reference: <author> Roberts, G.O. and Rosenthal, J.S. </author> <year> (1997), </year> <title> On convergence rates of Gibbs samplers for uniform distributions. </title> <journal> Ann. Appl. Prob., </journal> <note> to appear. </note>
Reference-contexts: In Section 4, we shall show that the simple slice sampler is nearly always geometrically ergodic using Foster-Lyapunov drift condition techniques. This result is interesting though rather surprising considering the fact that very few other MCMC algorithms exhibit comparably robust properties <ref> (see especially Roberts and Rosenthal, 1997 in this context) </ref>. Moreover, the stochastic monotonicity properties of the algorithm allow us to give useful rigorous quantitative bounds on the total variation distance from stationarity after a given number of iterations. <p> Computable bounds are still possible from the calculations in the proof of Theorem 16 <ref> (see Roberts and Tweedie, 1997) </ref> but will not be as tight as those in Theorem 10. However if either X or X + are finite, then it will be possible to use the techniques of Theorem 9. The example below is an illustration of this.
Reference: <author> Roberts, </author> <title> G.O. and Tweedie, R.L. (1996), Geometric convergence and central limit theorems for multidimensional Hastings Metropolis algorithms. </title> <journal> Biometrika, </journal> <volume> 83, </volume> <pages> 96-110. </pages>
Reference-contexts: It follows therefore that lim sup P V (x) &lt; 1 (at least for appropriate choices of fi). Geometric ergodicity will follow if we can demonstrate that all compact sets are small <ref> (cf. arguments in Roberts and Tweedie, 1996) </ref>.
Reference: <author> Roberts, </author> <title> G.O. and Tweedie, R.L. (1998), Bounds on regeneration times and convergence rates for Markov chains. </title> <type> Preprint. 26 Rosenthal, </type> <institution> J.S. </institution> <year> (1995), </year> <title> Minorization conditions and convergence rates for Markov chain Monte Carlo. </title> <journal> J. Amer. Stat. Assoc. </journal> <volume> 90, </volume> <pages> 558-566. </pages>
Reference: <author> Swendsen, R.H. and Wang, J.S. </author> <year> (1987), </year> <title> Nonuniversal critical dynamics in Monte Carlo simulations. </title> <journal> Phys. Rev. Lett. </journal> <volume> 58, </volume> <pages> 86-88. </pages>
Reference: <author> Tierney, L. </author> <year> (1994), </year> <title> Markov chains for exploring posterior distributions (with discussion). </title>
Reference-contexts: Furthermore, it is easily seen that the Markov chain induced by the slice sampler is - -irreducible and aperiodic. Thus, from standard Markov chain theory <ref> (see e.g. Tierney, 1994) </ref> it follows that from - -almost every starting point, the law of X n will converge to - () as n ! 1. The algorithms as they have been described in this section are all constructed for densities with respect to Lebesgue measure.
Reference: <editor> Ann. Stat. </editor> <volume> 22, </volume> <pages> 1701-1762. </pages>
Reference: <author> Tierney, L. </author> <year> (1995), </year> <title> A note on Metropolis Hastings kernels for general state spaces. </title> <journal> Ann. Appl. Prob., </journal> <note> to appear. 27 </note>
References-found: 24

