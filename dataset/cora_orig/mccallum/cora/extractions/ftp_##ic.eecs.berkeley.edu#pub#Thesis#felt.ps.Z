URL: ftp://ic.eecs.berkeley.edu/pub/Thesis/felt.ps.Z
Refering-URL: http://www-cad.eecs.berkeley.edu/Respep/Research/Thesis/thesis.html
Root-URL: http://www.cs.berkeley.edu
Title: Testing and Characterization of Analog Systems Using Behavioral Models and Optimal Experimental Design  
Author: by Eric James Felt Professor Paul R. Gray Professor Terence P. Speed 
Degree: 1991 M.S. (University of California, Berkeley) 1993 A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Engineering|Electrical Engineering and Computer Sciences in the GRADUATE DIVISION of the UNIVERSITY of CALIFORNIA, BERKELEY Committee in charge: Professor Alberto L. Sangiovanni-Vincentelli, Chair  
Date: Fall 1996  
Affiliation: B.S.E. (Duke University)  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A.K.B. A'ain, A.H. </author> <title> Bratt and A.P. Dorey, "Testing Analogue Circuits by Power Supply Voltage Control," </title> <journal> Electronics Letters, </journal> <volume> vol. 30, </volume> <editor> n. </editor> <volume> 3, </volume> <pages> pp. 214-215, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: The best 23 approach, therefore, is to simply consider the power supply current as an additional circuit output rather than as a special kind of analog test. A related testing technique is to consider the power supply voltage as a controllable circuit input <ref> [1] </ref>.
Reference: [2] <author> M. Al-Qutayri, </author> <title> "Comparison of Voltage and Current Testing of Analogue and Mixed-Signal Circuits," </title> <booktitle> Proc. IEEE International ASIC Conference and Exhibit, </booktitle> <pages> pp. 156-159, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: A recent study [24] measured the cross-correlation between power supply current and voltage output for a low-pass Sallen-Key filter. They concluded that power supply current is more sensitive for detecting faults in MOS transistors and output voltage is better at detecting faults in passive components. <ref> [2] </ref> concluded that the power supply current and output voltage are complementary in terms of achieving a high percentage of fault coverage with a high degree of confidence.
Reference: [3] <author> J.S. Augusto and C.F.B. Almeida, </author> <title> "Fully Automatic DC Fault Dictionary Construction and Test Nodes Selection for Analogue Fault Diagnosis," </title> <booktitle> Proc. The European Design and Test Conference, </booktitle> <address> p. 605, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: Augusto presented a typical implementation in <ref> [3] </ref>, in which he carefully considers manufacturing variations among all parameters. First one good and f faulty circuits are generated, where f is the number of faults. Then a Monte Carlo analysis is performed on each of the f + 1 circuits, with statistical variation of the circuit parameters.
Reference: [4] <author> A. Balivada, J. Chen and J.A. Abraham, </author> <title> "Analog Testing with Time Response Parameters," </title> <journal> IEEE Design & Test of Computers, </journal> <volume> vol. 13, </volume> <editor> n. </editor> <volume> 2, </volume> <pages> pp. 18-25, </pages> <month> Summer </month> <year> 1996. </year>
Reference-contexts: For linear circuits (such as filters) the tested parameters could include DC specifications, like input bias currents and impedances; AC specifications, like the gain bandwidth and total harmonic distortion; and transient specifications, like the step response settling time <ref> [4] </ref>. Verifying the entire set of specifications would provide complete confidence in the tested part. However, the time and cost overheads of such a procedure are high. Moreover, the high redundancy in specifications causes overtesting of the part. <p> After determining a test, he performs fault simulations on the remaining set of faults and eliminates the detected faults from the fault list. Balivada claims that his approach does not suffer from the error introduced by the Laplace to Z-domain transformation of the Nagi method <ref> [4] </ref>. The main shortcomings of these approaches seem to be the single-fault model assumption and the failure to address the issue of manufacturing tolerances of the non-faulty parameters. Slamani proposed a fault-based testing approach for parametric faults which is very similar to the sensitivity-based fault diagnosis algorithms.
Reference: [5] <author> J. Bandler and A. Salama, </author> <title> "Fault Diagnosis of Analog Circuits," </title> <journal> Proc. of the IEEE, </journal> <volume> vol. 73, </volume> <month> August </month> <year> 1985. </year>
Reference-contexts: To ignore some of the parameters, one can analyze a circuit's ambiguity groups, which are the sets of linearly dependent parameters which cause the diagnostic equations to be rank deficient. Finding ambiguity groups is a computationally intense process which has been studied by many researchers over the years <ref> [7, 115, 5, 133, 65] </ref>. Once the ambiguity groups are found, some of the parameters can be assumed to be fault free (set to their nominal values) to make the diagnostic equations solvable [67].
Reference: [6] <author> I.M. Bell, D.A. Camplin, G.E. Taylor and B.R. Bannister, </author> <title> "Supply Current Testing of Mixed Analogue and Digital ICs," </title> <journal> Electronics Letters, </journal> <volume> vol. 27, </volume> <editor> n. </editor> <volume> 17, </volume> <pages> pp. 1581-1583, </pages> <year> 1991. </year>
Reference-contexts: Applying similar techniques to the testing of analog and mixed-signal circuits was first proposed in 1991 <ref> [6] </ref>; DC faults are detected by monitoring the quiescent power supply current. This technique was further developed in [14], in which the authors reported that for a typical circuit, 80% of the catastrophic faults produce a change in the quiescent power supply current of at least 25%.
Reference: [7] <author> R.S. Berkowitz, </author> <title> "Conditions for Network-Element-Value Solvability," </title> <journal> IEEE Trans. on Circuit Theory, </journal> <volume> vol. CT-9, </volume> <pages> pp. 24-29, </pages> <year> 1962. </year>
Reference-contexts: To ignore some of the parameters, one can analyze a circuit's ambiguity groups, which are the sets of linearly dependent parameters which cause the diagnostic equations to be rank deficient. Finding ambiguity groups is a computationally intense process which has been studied by many researchers over the years <ref> [7, 115, 5, 133, 65] </ref>. Once the ambiguity groups are found, some of the parameters can be assumed to be fault free (set to their nominal values) to make the diagnostic equations solvable [67].
Reference: [8] <author> J.L. Bernier, J.J. Merelo, J. Ortega and A. Prieto, </author> <title> "Test Pattern Generation for Analog Circuits Using Neural Networks and Evolutive Algorithms," </title> <booktitle> Proc. International Workshop on Artificial Neural Networks, </booktitle> <pages> pp. 838-844, </pages> <month> June </month> <year> 1995. </year> <month> 102 </month>
Reference-contexts: In his formulation the objective is to determine a test signal that maximizes the quadratic difference between the nominal response and the faulty one due to a defect in the circuit <ref> [8] </ref>. While techniques based on catastrophic faults dominate research in the testing of digital circuits, they are of only limited use when testing analog circuits.
Reference: [9] <author> L. Bonet, J. Ganger, J. Girardeu, C. Greaves, M. Pendelton and D. Yatim, </author> <title> "Test Features of the MC145472 ISDN U-Transceiver," </title> <booktitle> Proc. International Test Conference, </booktitle> <pages> pp. 68-79, </pages> <year> 1990. </year>
Reference-contexts: This test suite frequently defaults to the complete set of circuit specifications. This approach is becoming increasingly expensive in both test development and test execution times. The specifications of mixed analog-digital circuits are usually very large (e.g. see <ref> [9] </ref>), which not only results in long manual test development, but also in prohibitive testing times on very expensive automated test equipment with mixed-signal capabilities; in aggregate, test-related costs for today's electronic products typically range from 30% to 50% of total product cost [13].
Reference: [10] <author> G.E.P. Box and N.R. Draper, </author> <title> Empirical Model-Building and Response Surfaces, </title> <editor> J. </editor> <publisher> Wi-ley & Sons, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: the I-optimality algorithm to select the best additional vectors, one at a time, for use if the prior tests are not conclusive. 3.3.1 Optimality Criteria There are several different optimality criteria (A-, D-, E-, G-, and I-), the relative merits of which have been debated extensively in the relevant literature <ref> [60, 10] </ref>. D-optimality, which is generally considered to be the simplest type of optimality, minimizes the average prediction variance of the model coefficients. <p> An I-optimal design is one which minimizes the normalized average of var ^y (x) over R, I = 2 R This integral simplifies <ref> [10] </ref> to give I = trace n x (3.8) where M is the moment matrix of R, M = R 3.3.2 Optimization Finding an exactly I-optimal design is believed to be NP-complete [23] and hence only feasible for very small problems.
Reference: [11] <author> A.H. Bratt, A.M.D. Richardson, R.J.A. Harvey and A.P. Dorey, </author> <title> "A Design-for-Test Structure for Optimising Analogue and Mixed Signal IC Test," </title> <booktitle> Proc. European Design and Test Conference, </booktitle> <pages> pp. 24-33, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Bratt proposed a similar architecture in which control voltages are injected into an operational 26 amplifier with a configurable internal architecture. Bandwidth performance loss is minimal and area overhead is approximately 5% for each modified operational amplifier <ref> [11] </ref>. In general, DFT schemes based on some kind of a structural division of the circuit have been largely unsuccessful because of their impact on the circuit performance [107]. Analog scan and analog built-in-self-test are efforts to make analog circuits more testable without sacrificing performance.
Reference: [12] <author> T. Butzerin, A. Samad and E. Archambeau, </author> <title> "ASIC Testing with High Fault Coverage," </title> <booktitle> VLSI Systems Design, </booktitle> <volume> vol. 9, </volume> <editor> n. </editor> <volume> 9, </volume> <pages> pp. 50-57, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: In the majority of cases, these test programs are manually created, with an accuracy ranging from 100% to as little as 10% [97]. A surprising amount of research has been directed toward the languages for specifying the test input/output vectors for specific test equipment <ref> [12] </ref> and, in particular, toward automating the conversion of tests from the designers' environments to the specific languages used by the testers [29, 46]. Tektronix sells a Waveform Analysis and Verification Environment which translates test vectors into the format needed for common ATE equipment [91].
Reference: [13] <author> R.L. Campbell and R.A. Tarbox, </author> <title> "Testing Goes Critical Path," </title> <journal> AT&T Technical Journal, </journal> <volume> vol. 73, </volume> <editor> n. </editor> <volume> 2, </volume> <pages> pp. 4-9, </pages> <month> March-April </month> <year> 1994. </year>
Reference-contexts: circuits are usually very large (e.g. see [9]), which not only results in long manual test development, but also in prohibitive testing times on very expensive automated test equipment with mixed-signal capabilities; in aggregate, test-related costs for today's electronic products typically range from 30% to 50% of total product cost <ref> [13] </ref>. Furthermore, the use of sophisticated design automation tools continues to reduce the design cycle time so that the influence of testing on time-to-market and final cost of the circuit is becoming increasingly significant. <p> Therefore, in practice, manufacturers test only a few specifications over a limited input space. The drawback is that such compromise can lessen the quality of shipped parts. This dissertation offers alternatives to specification-based testing which will provide benefits such as <ref> [13] </ref>: * Shorter time to market, * Lower manufacturing cost, * Reduced capital for test equipment, * Reduced development cost, * Improved out-of-the-box quality, * Reduced field-installation time, * Increased product up-time, and * Reduced field-maintenance cost. <p> These techniques allow analog systems to be characterized more accurately and more efficiently than previously possible, thereby significantly reducing system test cost. 1.3 Overview of testing and characterization within this process <ref> [13] </ref>. Our research in analog testing and characterization has impact throughout this design cycle, particularly in the "Design Evaluation" and "Test" stages. There are three major thrusts to our research. <p> For the analog part, Lee proposed a new boundary scan cell design and defined four analog test instructions. 27 2.5.2 Built-In Self-Test (BIST) Although the difficulty of testing microelectronics products has increased, the cost of embedding testability enhancements has decreased <ref> [13] </ref>. This trend explains the increasing interest in built-in self-test. For BIST techniques, a chip contains extra circuitry which enables it to test itself. As an example, consider the fault dictionary approach to testing.
Reference: [14] <author> D.A. Camplin, I.M. Bell, G.E. Taylor and B.R. Bannister, </author> <title> "Can Supply Current Monitoring be Applied to the Testing of Analogue as Well as Digital Portions of Mixed ASICs?," </title> <booktitle> Proc. The European Conference on Design Automation, </booktitle> <pages> pp. 538-542, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Applying similar techniques to the testing of analog and mixed-signal circuits was first proposed in 1991 [6]; DC faults are detected by monitoring the quiescent power supply current. This technique was further developed in <ref> [14] </ref>, in which the authors reported that for a typical circuit, 80% of the catastrophic faults produce a change in the quiescent power supply current of at least 25%.
Reference: [15] <author> H. Chang, E. Charbon, U. Choudhury, A. Demir, E. Felt, E. Liu, E. Malavasi, A. Sangiovanni-Vincentelli and I. Vassiliou, </author> <title> A Top-Down, Constraint-Driven Design Methodology for Analog Integrated Circuits, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1997. </year>
Reference-contexts: Today's design and test methodologies must deal with these components systematically, 2 accurately, and efficiently. 1.1 Design Methodology for Analog Systems Our design technology research group at the University of California, Berkeley has developed a new top-down, constraint-driven design methodology for analog and mixed-signal system design <ref> [18, 17, 16, 15] </ref>. The methodology has two basic goals: (1) making the design cycle robust by use of hierarchical partitioning, behavioral modeling, and specification propagation; (2) drastically reducing the number of design iterations by use of accurate performance evaluation and early error diagnosis.
Reference: [16] <author> H. Chang, E. Felt and A.L. Sangiovanni-Vincentelli, </author> <title> "Top-Down, Constraint-Driven Design Methodology Based Generation of a Second Order - A/D Converter," </title> <booktitle> Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pp. 533-536, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Today's design and test methodologies must deal with these components systematically, 2 accurately, and efficiently. 1.1 Design Methodology for Analog Systems Our design technology research group at the University of California, Berkeley has developed a new top-down, constraint-driven design methodology for analog and mixed-signal system design <ref> [18, 17, 16, 15] </ref>. The methodology has two basic goals: (1) making the design cycle robust by use of hierarchical partitioning, behavioral modeling, and specification propagation; (2) drastically reducing the number of design iterations by use of accurate performance evaluation and early error diagnosis.
Reference: [17] <author> H. Chang, E. Liu, R. Neff, E. Felt, E. Malavasi, E. Charbon, A. Sangiovanni-Vincentelli and P.R. Gray, </author> <title> "Top-Down, Constraint-Driven Methodology Based Generation of n-bit Interpolative Current Source D/A Converters," </title> <booktitle> Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pp. 369-372, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Today's design and test methodologies must deal with these components systematically, 2 accurately, and efficiently. 1.1 Design Methodology for Analog Systems Our design technology research group at the University of California, Berkeley has developed a new top-down, constraint-driven design methodology for analog and mixed-signal system design <ref> [18, 17, 16, 15] </ref>. The methodology has two basic goals: (1) making the design cycle robust by use of hierarchical partitioning, behavioral modeling, and specification propagation; (2) drastically reducing the number of design iterations by use of accurate performance evaluation and early error diagnosis.
Reference: [18] <author> H. Chang, A. Sangiovanni-Vincentelli, E. Charbon, U. Choudhury, E. Felt, G. Jusuf, E. Liu, E. Malavasi and R. Neff, </author> <title> "A Top-Down, Constraint-Driven Design Methodol 103 ogy for Analog Integrated Circuits," </title> <booktitle> Proc. Workshop on "Advances in Analog Circuit Design," Scheveningen, NL, </booktitle> <pages> pp. 301-325, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Today's design and test methodologies must deal with these components systematically, 2 accurately, and efficiently. 1.1 Design Methodology for Analog Systems Our design technology research group at the University of California, Berkeley has developed a new top-down, constraint-driven design methodology for analog and mixed-signal system design <ref> [18, 17, 16, 15] </ref>. The methodology has two basic goals: (1) making the design cycle robust by use of hierarchical partitioning, behavioral modeling, and specification propagation; (2) drastically reducing the number of design iterations by use of accurate performance evaluation and early error diagnosis. <p> One promising approach to dealing with these shortcomings involves the use of 76 behavioral models and hierarchical characterization. Hierarchical characterization is illustrated in Figure 6.1. This characterization method is part of a hierarchical design methodology which involves different levels of abstraction <ref> [18] </ref>. The low-level parameters typically represent transistor model parameters, such as t ox and V T 0 . The intermediate-level parameters typically represent behavioral model parameters, such as open-loop gain and offset of an operational amplifier.
Reference: [19] <author> C.-Y. Chao, H.-J. Lin and L. Milor, </author> <title> "Fault-Driven Testing of LSI Analog Circuits," </title> <booktitle> Midwest Symposium on Circuits and Systems, </booktitle> <volume> vol. 2, </volume> <pages> pp. 927-930, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Milor presented algorithms for detecting parametric faults in [76]. Her approach is based on setting upper and lower bounds on the permissible value of each parameter in the design and then testing the circuit to determine that no parameter falls outside of its acceptable range. In <ref> [19] </ref> Chao and Milor generalized this approach to include behavioral models and both catastrophic and parametric faults. For circuits with a linear input/output relationship, several researchers have published interesting approaches. Tsai formulated the problem of detecting parametric faults as a quadratic programming problem [142].
Reference: [20] <author> A. Chatterjee, B.C. Kim and N. Nagi, </author> <title> "DC Built-In Self-Test for Linear Analog Circuits," </title> <journal> IEEE Design & Test of Computers, </journal> <volume> vol. 13, </volume> <editor> n. </editor> <volume> 2, </volume> <pages> pp. 26-33, </pages> <month> Summer </month> <year> 1996. </year>
Reference-contexts: The method relies upon precision reference components, which must be located off-chip. Olbrich designed a switched-current memory cell with BIST which achieves 95% coverage for shorts and 60% coverage for open circuits [93]. Chatterjee proposed a low-cost BIST technique for linear analog circuits using DC checksum codes <ref> [20] </ref>. Mir et al. published BIST techniques for fully differential circuits in [79] and a review of general analog BIST techniques in [81]. Finally, Lopresti wrote about some experimental general analog BIST techniques in [69].
Reference: [21] <author> K.R. Chin, </author> <title> "Functional Testing of Circuits and SMD Boards with Limited Nodal Access," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 129-143, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: At least three researchers have studied time-domain techniques. Chin analyzed the transient response to step inputs with multivariable discriminant analysis <ref> [21] </ref>. Dai and Souders described a time-domain approach based on sensitivity analysis [25]. Taylor developed testing techniques using transient response analysis for linear sub-systems embedded within mixed-signal ICs [135]. Borrowing an effective technique from digital testing, Sloan proposed the use of random waveforms in [122].
Reference: [22] <author> F. Corsi, M. Chiarantoni, R. Lorusso and C. Marzocca, </author> <title> "A Fault Signature Approach to Analog Devices Testing," </title> <booktitle> Proc. European Test Conference, </booktitle> <pages> pp. 116-121, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: M-sequences are DC level, not bit sequences. A periodic pseudo-noise signal is applied to the circuit under test, and the Weiner-Hopf equation is used to estimate the impulse response of the circuit. Finally, Schreiber and Corsi apply a sequence of pulses with varying amplitude <ref> [111, 22] </ref>. 2.3.7 Power Supply Current Monitoring Several researchers have noted that monitoring the power supply current of the circuit being tested can detect many catastrophic faults.
Reference: [23] <author> S.B. Crary, </author> <title> "Optimal Design of Experiments for Sensor Calibration," </title> <booktitle> Proc. IEEE International Conference on Solid-State Sensors and Actuators, </booktitle> <pages> pp. 404-407, </pages> <year> 1991. </year>
Reference-contexts: Linear regression is used to analyze the results of the tests and compute the required standard errors. Finding an exactly I-optimal design is believed to be NP-complete <ref> [23] </ref> and hence only feasible for very small problems. For larger problems, several heuristic algorithms have been successfully used to find "good" solutions to this and other related problems in the area of optimal experimental design. These heuristic algorithms include simulated annealing [23], greedy swap techniques [89], and gradient descent techniques. <p> exactly I-optimal design is believed to be NP-complete <ref> [23] </ref> and hence only feasible for very small problems. For larger problems, several heuristic algorithms have been successfully used to find "good" solutions to this and other related problems in the area of optimal experimental design. These heuristic algorithms include simulated annealing [23], greedy swap techniques [89], and gradient descent techniques. For this research we used the gradient descent techniques implemented in the software package Gosset, which was recently developed by Hardin and Sloane at AT&T Bell Laboratories [48]. The analog testing algorithm we propose is: 1. <p> which minimizes the normalized average of var ^y (x) over R, I = 2 R This integral simplifies [10] to give I = trace n x (3.8) where M is the moment matrix of R, M = R 3.3.2 Optimization Finding an exactly I-optimal design is believed to be NP-complete <ref> [23] </ref> and hence only feasible for very small problems. For larger problems, several heuristic algorithms have been successfully used to find "good" solutions to this and other related problems in the area of optimal experimental design. These heuristic algorithms include simulated annealing [23], greedy swap techniques [89], and gradient descent techniques. <p> exactly I-optimal design is believed to be NP-complete <ref> [23] </ref> and hence only feasible for very small problems. For larger problems, several heuristic algorithms have been successfully used to find "good" solutions to this and other related problems in the area of optimal experimental design. These heuristic algorithms include simulated annealing [23], greedy swap techniques [89], and gradient descent techniques. For this research we used the gradient descent techniques implemented in the software package 37 Gosset, which was recently developed by Hardin and Sloane at AT&T Bell Laboratories [48]. <p> of the model coefficients, which is the most appropriate figure of merit for evaluating competing test structures. 67 5.2.2 Generating D-Optimal Test Sets Generating a set of test vectors for a given circuit model which minimizes D, as defined in Equation 5.5, is believed to be an NP-complete optimization problem <ref> [23] </ref>. An exact solution is only feasible for very small problems. For larger problems, several heuristic algorithms have been successfully used to find "good" solutions to this and other related problems in the area of optimal experimental design. For this research we used the gradient descent techniques implemented in Gosset.
Reference: [24] <author> J. Machado da Silva, J. Silva Matos, I.M. Bell and G.E. Taylor, </author> <title> "Cross-correlation Between i dd and v out Signals for Testing Analogue Circuits," </title> <journal> Electronics Letters, </journal> <volume> vol. 31, </volume> <editor> n. </editor> <volume> 19, </volume> <pages> pp. 1617-1618, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: Note that the power supply current should be considered an output of the circuit, just like any other output. Therefore all of the techniques described in this dissertation are directly applicable to monitoring power supply current. A recent study <ref> [24] </ref> measured the cross-correlation between power supply current and voltage output for a low-pass Sallen-Key filter.
Reference: [25] <author> H. </author> <title> Dai and T.M. Sounders, "Time-Domain Testing Strategies and Fault Diagnosis for Analog Systems," </title> <journal> IEEE Trans. on Instrumentation and Measurement, </journal> <volume> vol. 39, </volume> <editor> n. </editor> <volume> 1, </volume> <pages> pp. 157-162, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: At least three researchers have studied time-domain techniques. Chin analyzed the transient response to step inputs with multivariable discriminant analysis [21]. Dai and Souders described a time-domain approach based on sensitivity analysis <ref> [25] </ref>. Taylor developed testing techniques using transient response analysis for linear sub-systems embedded within mixed-signal ICs [135]. Borrowing an effective technique from digital testing, Sloan proposed the use of random waveforms in [122]. Russell expanded on this idea in [106], presenting two new types of input stimuli: 1.
Reference: [26] <author> D.W. Daugherty, </author> <title> "Using Fault Simulation to Increase Productivity," </title> <journal> Electronics Test, </journal> <volume> vol. 11, </volume> <editor> n. </editor> <volume> 9, </volume> <pages> pp. 22-24, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Daugherty presented the basic concepts of analog fault simulation in <ref> [26] </ref>. Early work was based on experimental manufacturing defect statistics and showed that open faults and bridging faults are the most frequent catastrophic fault types [70, 148, 157]. Soma and Meixner developed analog fault models by performing Monte-Carlo defect simulations [124, 75].
Reference: [27] <author> G. Devarayanadurg and M. Soma, </author> <title> "Analytic Fault Modeling and Static Test Generation for Analog ICs," </title> <booktitle> Proc. IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pp. 44-47, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Soma reached a similar conclusion in his study of catastrophic fault coverage of DC parametric tests on amplifiers, in which he reported coverage of less than 80% [125]. Another DC test generation technique for detecting catastrophic failures was presented by Devarayanadurg in <ref> [27] </ref>. The algorithm first finds those values of the process parameters which will cause the faulty and good circuits to behave as close to each other as possible, and then finds the corresponding input vector which will detect the fault for this worst case.
Reference: [28] <author> G. Devarayanadurg and M. Soma, </author> <title> "Dynamic Test Signal Design for Analog ICs," </title> <booktitle> Proc. IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pp. 627-630, </pages> <month> November </month> <year> 1995. </year> <month> 104 </month>
Reference-contexts: Thus the test generation problem is formulated as a minimax optimization problem and solved iteratively as successive linear programming problems. An analytical fault modeling technique based on manufacturing defect statistics is used to derive the fault list for the test generation. Devarayanadurg extended the method to AC tests in <ref> [28] </ref>, in which he determines the time points of a transient analysis at which circuits should be compared to maximize difference between the faulty and non-faulty circuits.
Reference: [29] <author> K. Dubrowski and T. Wong, </author> <title> "Mixed Analog/Digital ASICs," </title> <booktitle> VLSI Systems Design, </booktitle> <volume> vol. 9, </volume> <editor> n. </editor> <volume> 9, </volume> <pages> pp. 60-65, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: While less than 20% of a typical mixed-signal ASIC is used for analog circuitry, testing the analog portion is a major problem and one which will cause production bottlenecks as devices integrate higher proportions of analog functions onto mixed-signal chips <ref> [29] </ref>. Analog circuits, in general, require much longer testing times than digital circuits because second-order effects must be considered and because few design automation tools are available to aid in the design of the test vectors. <p> A surprising amount of research has been directed toward the languages for specifying the test input/output vectors for specific test equipment [12] and, in particular, toward automating the conversion of tests from the designers' environments to the specific languages used by the testers <ref> [29, 46] </ref>. Tektronix sells a Waveform Analysis and Verification Environment which translates test vectors into the format needed for common ATE equipment [91]. LTX offers a similar product called enVision, which they describe as a "visual test programming language" [94].
Reference: [30] <author> P. Duhamel and J.C. Rault, </author> <title> "Automatic Test Generation Techniques for Analog Circuits and Systems: A Review," </title> <journal> IEEE Trans. on Circuits and Systems, </journal> <volume> vol. </volume> <editor> CAS-26, n. </editor> <volume> 7, </volume> <pages> pp. 411-440, </pages> <month> July </month> <year> 1979. </year>
Reference-contexts: Analog fault diagnosis received a thorough theoretical treatment in the 1970s. Duhamel and Rault presented an excellent review of the topic <ref> [30] </ref>. Here we summarize some of the more recent work. 2.2.1 Linear Network Theory For systems in which the outputs vary linearly with respect to the possible faults, linear network theory has been used by many researchers to perform fault diagnosis.
Reference: [31] <institution> ELDO User's Manual, ANACAD Electrical Engineering Software, ULM (Donau) Germany, </institution> <year> 1995. </year>
Reference-contexts: Constructing this model involves defining an appropriate experiment, which in SimPilot is typically a simplex experiment for linear models or a Latin hypercube for quadratic models, running Eldo <ref> [31] </ref> (Spice) for each permutation in the experiment, and using linear regression to solve for the coefficients of the response surface model.
Reference: [32] <author> M. Fares and B. Kaminska, </author> <title> "Fuzzy Optimization Models for Analog Test Decisions," </title> <journal> Journal of Electronic Testing: Theory and Applications, </journal> <volume> vol. 5, </volume> <pages> n. 2-3, pp. 299-305, </pages> <month> May-August </month> <year> 1994. </year>
Reference-contexts: Fares proposed an analog testing method which uses fuzzy optimization models to determine whether a circuit is good or bad <ref> [32] </ref>. For example, measurements which are close to their specifications are treated with more skepticism than measurements which clearly exceed their specifications.
Reference: [33] <author> P. Fasang, </author> <title> "Analog/Digital ASIC Design for Testability," </title> <journal> IEEE Trans. on Industrial Electronics, </journal> <volume> vol. 36, </volume> <editor> n. </editor> <volume> 2, </volume> <pages> pp. 219-226, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Scan techniques are used extensively in the testing of digital circuits. Fasang proposed a partial scan architecture for mixed-signal circuits in 1988 <ref> [34, 33] </ref>. He uses scan methods for the digital sections and a special arrangement of multiplexors and additional test points for the analog blocks. Signal storage cells for a fully analog scan technique have been presented by Wey, both for voltages [150] and for currents [151].
Reference: [34] <author> P.P. Fasang, D. Mullins and T. Wong, </author> <title> "Design for Testability for Mixed Analog/Digital ASICs," </title> <booktitle> Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pp. </pages> <address> 16.5.1-16.5.4, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: Scan techniques are used extensively in the testing of digital circuits. Fasang proposed a partial scan architecture for mixed-signal circuits in 1988 <ref> [34, 33] </ref>. He uses scan methods for the digital sections and a special arrangement of multiplexors and additional test points for the analog blocks. Signal storage cells for a fully analog scan technique have been presented by Wey, both for voltages [150] and for currents [151].
Reference: [35] <author> E. Felt, A. Narayan and A. Sangiovanni-Vincentelli, </author> <title> "Measurement and Modeling of MOS Transistor Current Mismatch in Analog ICs," </title> <booktitle> Proc. IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pp. 272-277, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: There were 12 replications of each test structure, with 16-64 transistors per test structure. A summary of the observed variances is shown in Table 5.3; the complete results of this mismatch characterization experiment are reported in <ref> [35] </ref>. With regard to optimal test structure design, the important conclusion to be drawn from these examples is that extracting parameters from relatively complex structures is often more efficient than measuring single devices.
Reference: [36] <author> E. Felt and A. Sangiovanni-Vincentelli, </author> <title> "Testing of Analog Systems Using Behavioral Models and Optimal Experimental Design Techniques," </title> <booktitle> Proc. IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pp. 672-678, </pages> <month> November </month> <year> 1994. </year>
Reference: [37] <author> E. Felt and A.L. Sangiovanni-Vincentelli, </author> <title> "Optimal Design of Analog IC Test Structures," </title> <booktitle> Proc. IEEE International Mixed Signal Testing Workshop, </booktitle> <month> June </month> <year> 1995. </year>
Reference: [38] <author> E. Felt and A.L. Sangiovanni-Vincentelli, </author> <title> "Optimization of Analog IC Test Structures," </title> <booktitle> Proc. IEEE VLSI Test Symposium, </booktitle> <pages> pp. 48-53, </pages> <month> April-May </month> <year> 1996. </year>
Reference: [39] <author> E. Felt, S. Zanella, C. Guardiani and A.L. Sangiovanni-Vincentelli, </author> <title> "Hierarchical Statistical Characterization of Mixed-Signal Circuits Using Behavioral Modeling," </title> <booktitle> Proc. IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pp. 374-380, </pages> <month> November </month> <year> 1996. </year> <month> 105 </month>
Reference: [40] <author> R.R. Fritzemeier, J.M. Soden, R.K. Treece and C.F. Hawkins, </author> <title> "Increased CMOS IC Stuck-At Fault Coverage with Reduced I DDQ Test Set," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 427-435, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: For digital circuits this technique is known as I DDQ testing <ref> [90, 40] </ref>, and is based on the observation that short-circuit and open-circuit faults often dramatically impact the quiescent power supply current, especially 22 for CMOS logic circuitry with most transistors connected to either the power supply or the ground.
Reference: [41] <author> A. Ghosh, S. Devadas and A. Richard Newton, </author> <title> Sequential Logic Testing and Verification, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1992. </year>
Reference-contexts: Most of the previous work in testing of electrical systems has been directed at digital circuits, and efficient techniques have been developed for testing both combinational and sequential digital systems <ref> [112, 41] </ref>. These digital testing techniques are based on the single stuck-at-0/stuck-at-1 fault model and the controllability and observability of each fault. Unfortunately most of the digital testing ideas cannot be directly applied to analog systems.
Reference: [42] <author> G. Gielen, Z. Wang and W. Sansen, </author> <title> "Fault Detection and Input Stimulus Determination for the Testing of Analog Integrated Circuits Based on Power-Supply Current Monitoring," </title> <booktitle> Proc. IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pp. 495-498, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: In [95, 96] the authors proposed a method for identifying AC faults by using the spectrum of the power supply current to construct a fault dictionary. <ref> [42, 149] </ref> presented a similar approach, in which time-domain testing followed by spectral analysis of the power-supply current is used to detect both DC and AC faults.
Reference: [43] <author> N.B. Hamida and B. Kaminska, </author> <title> "Analog Circuit Testing Based on Sensitivity Computation and New Circuit Modeling," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 652-661, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Hamida presented a similar sensitivity-based approach. He uses sensitivity analysis to formulate a flow problem which is solved with linear programming to deduce which parameters should be measured, for single faults <ref> [43] </ref> and for multiple faults [44, 45]. The approach can be viewed as fault diagnosis for only a limited number of faults. The algorithm finds adequate tests for detecting catastrophic and parametric faults, but performs no optimization to find the best tests.
Reference: [44] <author> N.B. Hamida and B. Kaminska, </author> <title> "Multiple Fault Analog Circuit Testing by Sensitivity Analysis," </title> <journal> Journal of Electronic Testing: Theory and Applications, </journal> <volume> vol. 4, </volume> <editor> n. </editor> <volume> 3, </volume> <pages> pp. 331-343, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: Hamida presented a similar sensitivity-based approach. He uses sensitivity analysis to formulate a flow problem which is solved with linear programming to deduce which parameters should be measured, for single faults [43] and for multiple faults <ref> [44, 45] </ref>. The approach can be viewed as fault diagnosis for only a limited number of faults. The algorithm finds adequate tests for detecting catastrophic and parametric faults, but performs no optimization to find the best tests.
Reference: [45] <author> N.B. Hamida and B. Kaminska, </author> <title> "Multiple Fault Testing in Analog Circuits," </title> <booktitle> Proc. International Conference on VLSI Design, </booktitle> <pages> pp. 61-66, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Hamida presented a similar sensitivity-based approach. He uses sensitivity analysis to formulate a flow problem which is solved with linear programming to deduce which parameters should be measured, for single faults [43] and for multiple faults <ref> [44, 45] </ref>. The approach can be viewed as fault diagnosis for only a limited number of faults. The algorithm finds adequate tests for detecting catastrophic and parametric faults, but performs no optimization to find the best tests.
Reference: [46] <author> T. Hamilton and B. Hadley, </author> <title> "Solving the Simulation-to-Test Translation Problem," </title> <journal> Electronics Test, </journal> <volume> vol. 11, </volume> <editor> n. </editor> <volume> 9, </volume> <pages> pp. 47-51, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: A surprising amount of research has been directed toward the languages for specifying the test input/output vectors for specific test equipment [12] and, in particular, toward automating the conversion of tests from the designers' environments to the specific languages used by the testers <ref> [29, 46] </ref>. Tektronix sells a Waveform Analysis and Verification Environment which translates test vectors into the format needed for common ATE equipment [91]. LTX offers a similar product called enVision, which they describe as a "visual test programming language" [94].
Reference: [47] <author> J.M. </author> <title> Hammersley and D.C. Handscomb, Monte Carlo Methods, </title> <publisher> London, Methuen & Co Ltd., </publisher> <year> 1964. </year>
Reference-contexts: The most widely used technique for performing statistical characterization is Monte Carlo analysis <ref> [47, 104] </ref>. Unfortunately, the accuracy of results produced by a Monte Carlo analysis is only proportional to the square root of the number of simulations performed, and the number of Monte Carlo simulations required to produce a relatively accurate result increases exponentially with the number of low-level statistical parameters.
Reference: [48] <author> R.H. Hardin and N.J.A. Sloane, </author> <title> "A New Approach to the Construction of Optimal Designs," </title> <journal> Journal of Statistical Planning and Inference, </journal> <volume> vol. 37, </volume> <pages> pp. 339-369, </pages> <year> 1993. </year>
Reference-contexts: These heuristic algorithms include simulated annealing [23], greedy swap techniques [89], and gradient descent techniques. For this research we used the gradient descent techniques implemented in the software package Gosset, which was recently developed by Hardin and Sloane at AT&T Bell Laboratories <ref> [48] </ref>. The analog testing algorithm we propose is: 1. Linearize about the nominal parameter values and use Gosset to generate an initial set of n test vectors from this linear model, where n is the dimensionality of the space to be characterized. 2. <p> These heuristic algorithms include simulated annealing [23], greedy swap techniques [89], and gradient descent techniques. For this research we used the gradient descent techniques implemented in the software package 37 Gosset, which was recently developed by Hardin and Sloane at AT&T Bell Laboratories <ref> [48] </ref>. The primary focus of Gosset is low-order polynomial models, which are of only limited use in characterizing typical analog circuits. For this research, therefore, Gosset was extended to utilize arbitrary Lipschitz continuous functions, such as the piecewise linear output of common behavioral simulators [68] and Spice [146].
Reference: [49] <author> R.H. Hardin and N.J.A. Sloane, </author> <title> Operating Manual for Gosset: A General-Purpose Program for Constructing Experimental Designs (Second Edition), </title> <institution> Mathematical Sciences Research Center, AT&T Bell Laboratories, </institution> <year> 1994. </year>
Reference-contexts: For this research we used the gradient descent techniques implemented in Gosset. Gosset is a very general computer program for constructing experimental designs <ref> [49] </ref>. Variables may be discrete or continuous, discrete variables may be numeric or symbolic, and continuous variables may range over a cube or a ball. The variables may be required to satisfy linear equalities or inequalities, and the model to be fitted may be any linear function (Equation 5.1).
Reference: [50] <author> A.A. Hatzopoulos, S. Siskos and J.M. Kontoleon, </author> <title> "A Complete Scheme of Built-In Self-Tests (BIST) Structure for Fault Diagnosis in Analog Circuits and Systems," </title> <journal> 106 IEEE Trans. on Instrumentation and Measurement, </journal> <volume> vol. 42, </volume> <editor> n. </editor> <volume> 3, </volume> <pages> pp. 689-694, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: For BIST techniques, a chip contains extra circuitry which enables it to test itself. As an example, consider the fault dictionary approach to testing. Hatzopoulos published a method for performing on-chip fault diagnosis using a "healthy signature dictionary" which is prestored in an EEPROM chip <ref> [50] </ref>. The nodes of excitation, the test points, and the sequence of voltage or current measurements are predefined. A "self-test" of the circuit "passes" when the measurements agree with the corresponding prestored signatures, within certain tolerance bounds. Most research on analog BIST has been directed at specific circuits.
Reference: [51] <institution> HDLA User's Manual, ANACAD Electrical Engineering Software, ULM (Donau) Germany, </institution> <year> 1995. </year>
Reference-contexts: The intermediate-level parameters for the behavioral model of the phase/frequency detector and charge pump are 1. I up and The behavioral models are written in HDLA <ref> [51] </ref>. 6.5.2.1 MOS Model Extraction Statistical MOS models are needed to characterize the blocks in the PLL. To obtain these models, we measured a sample of 100 dies from 5 wafers and 2 lots of a 0.5 m double poly 3.3 V technology.
Reference: [52] <author> G. Hemink, B. Meijer and H. Kerkhoff, </author> <title> "Testability Analysis of Analog Systems," </title> <journal> IEEE Trans. on Computer-Aided Design of Integrated Circuits and Systems, </journal> <volume> vol. CAD-9, </volume> <pages> pp. 573-583, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: And Sen linked the measure of solvability of the system to the fault diagnosis equations [115]. Hemink extended this approach to nonlinear systems <ref> [53, 52] </ref>. He combined a rank-test algorithm with statistical methods to find sets of dependent parameters and determine whether it is possible to calculate a certain parameter with sufficient accuracy.
Reference: [53] <author> G.J. Hemink, B.W. Meijer and H.G. Kerkhoff, </author> <title> "TASTE: A Tool for Analog System Testability Evaluation," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 829-838, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: And Sen linked the measure of solvability of the system to the fault diagnosis equations [115]. Hemink extended this approach to nonlinear systems <ref> [53, 52] </ref>. He combined a rank-test algorithm with statistical methods to find sets of dependent parameters and determine whether it is possible to calculate a certain parameter with sufficient accuracy.
Reference: [54] <author> R. Hooke and T.A. Jeeves, </author> <title> "`Direct Search' Solution of Numerical and Statistical Problems," </title> <journal> Journal of ACM, </journal> <volume> vol. 8, </volume> <pages> pp. 212-229, </pages> <year> 1961. </year>
Reference-contexts: Each test point can be perturbed in the direction of this gradient and the design will have been improved. Gosset uses an optimization algorithm known as Hooke and Jeeves pattern search <ref> [54] </ref>, which is based on the idea of finding a "valley" and following it downward until reaching the lowest point on the response surface, similar to the manner in which a stream flows down a mountain.
Reference: [55] <author> J.E. Jackson, </author> <title> A User's Guide to Principal Components, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: Principal component analysis (PCA) or principal factor analysis (PFA) can be used to extract the statistically relevant combinations of parameters and thereby reduce the number of lower-level parameters which must be considered <ref> [154, 55] </ref>. Given a set of model cards which have been extracted from fabricated devices, Spayn [130] is a commercial tool which performs PCA and PFA.
Reference: [56] <author> M. Jarwala and S.J. Tsai, </author> <title> "A Framework for Design for Testability of Mixed Analog/Digital Circuits," </title> <booktitle> Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pp. </pages> <address> 13.5.1-13.5.4, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: The technique is geared more toward fault diagnosis than production testing, but the testing applications are evident. Most researchers in this area have attempted to develop circuitry which permits the various analog sub-blocks to be individually controlled and observed in isolation, e.g. <ref> [56] </ref>. This can be accomplished by signal multiplexing [147] or the use of MOS switches to isolate filter stages [123].
Reference: [57] <author> B. Johnson, T. Quarles, A.R. Newton, D.O. Pederson and A. Sangiovanni-Vincentelli, </author> <note> SPICE3 Version 3f User's Manual, </note> <institution> University of California, Berkeley, </institution> <year> 1992. </year>
Reference-contexts: The intermediate-level parameters typically represent behavioral model parameters, such as open-loop gain and offset of an operational amplifier. The high-level performances represent circuit performance specifications, such as signal-to-noise ratio of an analog-to-digital converter. A circuit simulator such as Spice <ref> [57] </ref> is used to simulate the intermediate-level parameters as functions of the low-level parameters, and a behavioral-level simulator such as Midas [155] is used to simulate the high-level performances as functions of the intermediate-level parameters. In this hierarchical design methodology, two statistical characterizations are performed.
Reference: [58] <author> B. Kaminska and B. Courtois, </author> <title> "Guest Editors' Introduction: Mixed Analog and Digital Systems," </title> <journal> IEEE Design & Test of Computers, </journal> <volume> vol. 13, </volume> <editor> n. </editor> <volume> 2, </volume> <pages> pp. 8-9, </pages> <month> Summer </month> <year> 1996. </year>
Reference-contexts: The intermingling of analog and digital signals in these systems is likely to increase as more functionality is integrated onto a single chip. Analog components are generally used in these systems for two reasons <ref> [58] </ref>: 1. To interface digital processing with applications-specific environments. Many applications include interactions among electronics and various sensors and actuators; such interactions imply analog signals, since "the real world is analog." 2. To accelerate processing in high-performance systems.
Reference: [59] <author> W.J. Kennedy, Jr. and J.E. </author> <title> Gentle, Statistical Computing, </title> <publisher> Marcel Dekker, Inc., </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: ~x; ~ + *; (4.4) nonlinear regression is an optimization problem which involves choosing ~ to minimize a least squares objective function H, H ~ = 2 k=1 y k f x k ; ~ : (4.5) To perform the optimization we use a modified Gauss-Newton method with step halving <ref> [59] </ref>.
Reference: [60] <author> J. Kiefer, </author> <title> Collected Papers III: Design of Experiments, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year> <month> 107 </month>
Reference-contexts: the I-optimality algorithm to select the best additional vectors, one at a time, for use if the prior tests are not conclusive. 3.3.1 Optimality Criteria There are several different optimality criteria (A-, D-, E-, G-, and I-), the relative merits of which have been debated extensively in the relevant literature <ref> [60, 10] </ref>. D-optimality, which is generally considered to be the simplest type of optimality, minimizes the average prediction variance of the model coefficients.
Reference: [61] <author> F. Kuhns, </author> <title> "Automating Testability Analysis of Analog Circuits and Systems," </title> <booktitle> AU-TOTESTCON: The IEEE Systems Readiness Technology Conference, </booktitle> <pages> pp. 225-231, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Fraction of faults detected, 2. Fault isolation resolution, and 3. Average ambiguity group size. 16 The qualitative descriptions include identifying feedback loops and unique circuit configurations which are difficult to test. The qualitative analysis consists of a set of design rules that are applied to the circuit <ref> [61] </ref>. 2.2.4 Summary The problem of determining precisely what is wrong with a circuit has been becoming less and less important for the past three decades as more and more functionality is integrated on-chip.
Reference: [62] <author> D.P. Kwok and Q. Lu, </author> <title> "On the Testability of Analog Circuits with Directive Faults: A Rule-Based Solution and an Equation Check Approach," </title> <booktitle> International Conference on Industrial Electronics, Control, Instrumentation, and Automation. Power Electronics and Motion Control, </booktitle> <pages> pp. 1556-1561, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Once the ambiguity groups are found, some of the parameters can be assumed to be fault free (set to their nominal values) to make the diagnostic equations solvable [67]. Several researchers have applied these linear network theory ideas to the decomposition of large networks into subnetworks <ref> [110, 62, 131] </ref>. These approaches facilitate testing by localizing the effects of faults to specific subnetworks. 2.2.2 Fault Dictionaries The fault dictionary is one of the oldest approaches to analog fault diagnosis, and it is still frequently used in industrial environments. Its popularity is due to: 1.
Reference: [63] <author> K.-J. Lee, T.-P. Lee, R.-C. Wen and Z.-Y. Lin, </author> <title> "Analogue Boundary Scan Architecture for DC and AC Testing," </title> <journal> Electronics Letters, </journal> <volume> vol. 32, </volume> <editor> n. </editor> <volume> 8, </volume> <pages> pp. 704-705, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: And in [126] he presented a general current-based analog scan cell. The general cell uses current to represent the analog signal to be scanned and otherwise functions the same as a digital scan cell. A new mixed-mode boundary scan architecture was presented by Lee in <ref> [63] </ref>. The digital part of this architecture complies with the IEEE Standard 1149.1.
Reference: [64] <author> D.M.W. Leenaerts and J. van Spaandonk, </author> <title> "DC Testing of Analog Integrated Circuits with Piecewise Linear Approximation and Interval Analysis," </title> <booktitle> Proc. IEEE International Symposium on Circuits and Systems, </booktitle> <pages> pp. 1337-1340, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Leenaerts calculates the mathematical relation between DC parameters and performances, then uses DC measurements to verify performance intervals <ref> [64] </ref>. His approach looks promising, but the algorithm is only illustrated with one parameter, measurement noise and modeling errors are not considered, and he does not propose a method for automatic test pattern generation.
Reference: [65] <author> A. Liberatore, S. Manetti and M.C. Piccirilli, </author> <title> "A New Efficient Method for Analog Circuit Testability Measurement," </title> <booktitle> IEEE Instrumentation and Measurement Technology Conference, </booktitle> <pages> pp. 193-196, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: To ignore some of the parameters, one can analyze a circuit's ambiguity groups, which are the sets of linearly dependent parameters which cause the diagnostic equations to be rank deficient. Finding ambiguity groups is a computationally intense process which has been studied by many researchers over the years <ref> [7, 115, 5, 133, 65] </ref>. Once the ambiguity groups are found, some of the parameters can be assumed to be fault free (set to their nominal values) to make the diagnostic equations solvable [67].
Reference: [66] <author> W.M. Lindermeir, H.E. Graeb and K.J. Antreich, </author> <title> "Design Based Analog Testing by Characteristic Observation Inference," </title> <booktitle> Proc. IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pp. 620-626, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: Fares raises the issue of "error" or uncertainty in testing, which is an important issue that few other researchers have addressed; in this dissertation "error" is dealt with as a statistical phenomenon. Lindermeir recently proposed an interesting approach based on characteristic observation inference (COI) <ref> [66] </ref>. In many situations it is prohibitive to directly verify the circuit specifications due to the test equipment costs. This approach considers a set of 25 reasonable input stimuli and measurements that can be performed with lower-cost test equipment.
Reference: [67] <author> E. Liu, W. Kao, E. Felt and A.L. Sangiovanni-Vincentelli, </author> <title> "Analog Testability Analysis and Fault Diagnosis using Behavioral Modeling," </title> <booktitle> Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <year> 1994. </year>
Reference-contexts: Once the ambiguity groups are found, some of the parameters can be assumed to be fault free (set to their nominal values) to make the diagnostic equations solvable <ref> [67] </ref>. Several researchers have applied these linear network theory ideas to the decomposition of large networks into subnetworks [110, 62, 131]. <p> Furthermore, we have the following theorem. Theorem 3.4.1 Components i and j are in the same ambiguity group if rows i and j of N are non-zero and not orthogonal to each other <ref> [67] </ref>. Proof. Suppose components i and j are not in the same ambiguity group and not orthogonal. <p> Parameter dependencies result in ambiguity groups, which are groups of parameters that are not independent. This algorithm represents a significant computational improvement over previously published algorithms for finding these groups <ref> [133, 67] </ref>.
Reference: [68] <author> E. Liu, A. Sangiovanni-Vincentelli, G. Gielen and P. Gray, </author> <title> "A Behavioral Representation for Nyquist Rate A/D Converters," </title> <booktitle> Proc. IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pp. 386-389, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: The primary focus of Gosset is low-order polynomial models, which are of only limited use in characterizing typical analog circuits. For this research, therefore, Gosset was extended to utilize arbitrary Lipschitz continuous functions, such as the piecewise linear output of common behavioral simulators <ref> [68] </ref> and Spice [146]. <p> The I-optimal design is shown in Table 3.2, along with the next seven extra points which would be chosen, in succession, to tighten the confidence intervals on the estimated performance. Application of the seven initial test vectors to a simulated D/A converter <ref> [68] </ref> 44 Code Inputs I-Value x 5 x 4 x 3 x 2 x 1 x 0 15 0 0 1 1 1 1 22 0 1 0 1 1 0 44 1 0 1 1 0 0 61 1 1 1 1 0 1 1.12500 1 0 0 0 0
Reference: [69] <author> P.V. Lopresti, </author> <title> "Extending Design-for-Test into the Analog and Mixed-Signal Domains," </title> <journal> AT&T Technical Journal, </journal> <volume> vol. 73, </volume> <editor> n. </editor> <volume> 2, </volume> <pages> pp. 49-55, </pages> <month> March-April </month> <year> 1994. </year>
Reference-contexts: Chatterjee proposed a low-cost BIST technique for linear analog circuits using DC checksum codes [20]. Mir et al. published BIST techniques for fully differential circuits in [79] and a review of general analog BIST techniques in [81]. Finally, Lopresti wrote about some experimental general analog BIST techniques in <ref> [69] </ref>. With the continuously decreasing cost of silicon and the increasing cost of mixed-signal testers, BIST is certain to become an important way of testing analog circuits. The performance impact and area impact of the BIST circuitry must be minimal, however, for the technique to be acceptable to designers.
Reference: [70] <author> W. Maly, </author> <title> "Realistic Fault Modeling for VLSI Testing," </title> <booktitle> Proc. ACM/IEEE Design Automation Conference, </booktitle> <pages> pp. 173-180, </pages> <month> June </month> <year> 1987. </year> <month> 108 </month>
Reference-contexts: Daugherty presented the basic concepts of analog fault simulation in [26]. Early work was based on experimental manufacturing defect statistics and showed that open faults and bridging faults are the most frequent catastrophic fault types <ref> [70, 148, 157] </ref>. Soma and Meixner developed analog fault models by performing Monte-Carlo defect simulations [124, 75]. Meixner models faulty analog behavior as modifications to the nominal macromodel. Nagi published some results on fault modeling for both catastrophic and parametric AC and DC faults in passive and active components [84].
Reference: [71] <author> W. Mao, Y. Lu, R.K. Gulati and R. Danapani, </author> <title> "Test Generation for Linear Analog Circuits," </title> <booktitle> Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pp. 521-524, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Furthermore, the method is complicated and exponential in CPU time complexity for the general case of testing for an arbitrary number of simultaneous faults. An algebraic approach to test generation for linear analog circuits was presented in <ref> [71] </ref>. The method is based on frequency domain analysis and expressing the input/output transfer function in a sum-of-products form. The faults considered are single abnormal value changes of elements, e.g. resistors, capacitors, and inductors.
Reference: [72] <author> M.J. Marlett and J.A. Abraham, "DC-IATP: </author> <title> An Iterative Analog Circuit Test Generation Program for Generating DC Single Pattern Tests," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 839-845, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Marlett developed a path sensitization method which can be used for DC test generation using a resistive shunt model <ref> [72] </ref>. Naiknaware published a similar idea which can be used hierarchically. A test model is stored with each generic block in a cell library. The test model is represented by a sequence of tests to be performed on the block.
Reference: [73] <author> A. McKeon and A. Wakeling, </author> <title> "Fault Diagnosis in Analogue Circuits Using AI Techniques," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 118-123, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Sachdev uses IFA directly in his fault dictionary approach [107] to generate realistic fault dictionaries. 2.2.3 Artificial Intelligence The most popular commercial fault diagnosis systems use artificial intelligence (AI) approaches. In the first AI approach, measurement effects were propagated backwards though the circuit model until a fault was found <ref> [73] </ref>. The DC voltage was measured at different nodes. The AI engine deduced the values of parameters within the circuits by propagating the effect of measurement through the model. Faults were inferred from the detection of inconsistencies and located by suspending constraints within the model.
Reference: [74] <author> J. McLeod, </author> <title> "Growth Spurt Opens the Door for US VLSI Test System Makers," </title> <publisher> Electronics, </publisher> <pages> pp. 89-90, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: LTX and Teradyne dominate the market, with 45% and 30% of dollar volumes, respectively. A typical mixed-signal test system costs $1.5 million <ref> [74] </ref>. These expensive test systems require input files that specify which inputs are to be applied and which outputs are to be measured. These input files are referred to as the test program.
Reference: [75] <author> A. Meixner and W. Maly, </author> <title> "Fault Modeling for the Testing of Mixed Integrated Circuits," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 564-572, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Catastrophic faults consist of stuck-at faults, open faults, and bridging faults. The parametric fault class consists of faults that result in performance outside accepted limits and are usually associated with variations in design parameters (e.g. passive component values, device sizes) <ref> [75, 78, 124] </ref>. The previous research in analog testing can be classified into five main categories: practical approaches, fault diagnosis, fault-based testing, performance-based testing, and design for testability. <p> Early work was based on experimental manufacturing defect statistics and showed that open faults and bridging faults are the most frequent catastrophic fault types [70, 148, 157]. Soma and Meixner developed analog fault models by performing Monte-Carlo defect simulations <ref> [124, 75] </ref>. Meixner models faulty analog behavior as modifications to the nominal macromodel. Nagi published some results on fault modeling for both catastrophic and parametric AC and DC faults in passive and active components [84].
Reference: [76] <author> L. Milor and A.L. Sangiovanni-Vincentelli, </author> <title> "Optimal Test Set Design for Analog Circuits," </title> <booktitle> Proc. IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pp. 294-297, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Since these statistical fluctuations can cause violations of the circuit specifications, parametric faults are just as important as catastrophic faults; they are, however, much more difficult to detect. Milor presented algorithms for detecting parametric faults in <ref> [76] </ref>. Her approach is based on setting upper and lower bounds on the permissible value of each parameter in the design and then testing the circuit to determine that no parameter falls outside of its acceptable range.
Reference: [77] <author> L. Milor and A.L. Sangiovanni-Vincentelli, </author> <title> "Minimizing Production Test Time to Detect Faults in Analog Circuits," </title> <journal> IEEE Trans. on Computer-Aided Design of Integrated Circuits and Systems, </journal> <volume> vol. 13, </volume> <editor> n. </editor> <volume> 6, </volume> <pages> pp. 796-813, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Mir chooses several self-testable linear analog circuits as examples. 2.3.5 Ordering of Tests In the area of test ordering, Milor described an algorithm for minimizing average test time by ordering the tests in such a way that those which are most likely to detect faults are performed first <ref> [77] </ref>. Given a statistical description of the fabrication process, the algorithm minimizes the testing time required to verify all of the circuit specifications. This problem reduces to finding the best choice and order of the specification tests such that all of the faults in the model are tested.
Reference: [78] <author> L. Milor and V. Visvanathan, </author> <title> "Detection of Catastrophic Faults in Analog Integrated Circuits," </title> <journal> IEEE Trans. on Computer-Aided Design of Integrated Circuits and Systems, </journal> <volume> vol. </volume> <editor> CAD-8, n. </editor> <volume> 2, </volume> <pages> pp. 114-130, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: Catastrophic faults consist of stuck-at faults, open faults, and bridging faults. The parametric fault class consists of faults that result in performance outside accepted limits and are usually associated with variations in design parameters (e.g. passive component values, device sizes) <ref> [75, 78, 124] </ref>. The previous research in analog testing can be classified into five main categories: practical approaches, fault diagnosis, fault-based testing, performance-based testing, and design for testability. <p> They may be structural deformations like short and open circuits, or cause large variations in design parameters (e.g., a change in a single transis 18 tor's length-to-width ratio caused by a dust particle on a photolithographic mask) <ref> [78] </ref>. Several researchers have developed automatic test pattern generation techniques for detecting catastrophic faults in analog systems using DC tests. Given that the designer can identify the critical parameters in the design and supply a model of process fluctuations, Milor described an efficient algorithm in [78]. <p> particle on a photolithographic mask) <ref> [78] </ref>. Several researchers have developed automatic test pattern generation techniques for detecting catastrophic faults in analog systems using DC tests. Given that the designer can identify the critical parameters in the design and supply a model of process fluctuations, Milor described an efficient algorithm in [78]. Her algorithm is based on fault signatures similar to those used for constructing fault dictionaries, but seeks only to distinguish between faulty and fault-free circuits, rather than to fully diagnose causes of failure.
Reference: [79] <author> S. Mir, V. Kolarik, M. Lubaszewski, C. Nielsen and B. Courtois, </author> <title> "Built-in Self-Test and Fault Diagnosis of Fully Differential Analogue Circuits," </title> <booktitle> Proc. IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pp. 486-490, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Olbrich designed a switched-current memory cell with BIST which achieves 95% coverage for shorts and 60% coverage for open circuits [93]. Chatterjee proposed a low-cost BIST technique for linear analog circuits using DC checksum codes [20]. Mir et al. published BIST techniques for fully differential circuits in <ref> [79] </ref> and a review of general analog BIST techniques in [81]. Finally, Lopresti wrote about some experimental general analog BIST techniques in [69]. With the continuously decreasing cost of silicon and the increasing cost of mixed-signal testers, BIST is certain to become an important way of testing analog circuits.
Reference: [80] <author> S. Mir, M. Lubaszewski, V. Kolarik and B. Courtois, </author> <title> "Automatic Test Generation for Maximal Diagnosis of Linear Analog Circuits," </title> <booktitle> Proc. European Design and Test Conference, </booktitle> <pages> pp. 254-258, </pages> <month> March </month> <year> 1996. </year> <month> 109 </month>
Reference-contexts: The method indicates which elements in the circuit are hard to test. Another fault-based multifrequency test generation and fault diagnosis procedure for linear circuits was proposed by Mir in <ref> [80] </ref>. This procedure selects a minimal set of test measures and generates the minimal set of frequency tests which guarantee maximum fault coverage and maximal fault diagnosis.
Reference: [81] <author> S. Mir, M. Lubaszewski, V. Liberali and B. Courtois, </author> <title> "Built-In Self-Test Approaches for Analogue and Mixed-Signal Integrated Circuits," </title> <booktitle> Midwest Symposium on Circuits and Systems, </booktitle> <pages> pp. 1145-1150, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Chatterjee proposed a low-cost BIST technique for linear analog circuits using DC checksum codes [20]. Mir et al. published BIST techniques for fully differential circuits in [79] and a review of general analog BIST techniques in <ref> [81] </ref>. Finally, Lopresti wrote about some experimental general analog BIST techniques in [69]. With the continuously decreasing cost of silicon and the increasing cost of mixed-signal testers, BIST is certain to become an important way of testing analog circuits.
Reference: [82] <author> Y. Miura, </author> <title> "Real-Time Current Testing for A/D Converters," </title> <journal> IEEE Design & Test of Computers, </journal> <volume> vol. 13, </volume> <editor> n. </editor> <volume> 2, </volume> <pages> pp. 34-41, </pages> <month> Summer </month> <year> 1996. </year>
Reference-contexts: In <ref> [82] </ref> Miura tested an A/D converter for catastrophic faults by measuring the integral of the power supply current during one clock period in which a test vector was applied.
Reference: [83] <author> R.H. Myers and D.C. Montgomery, </author> <title> Response Surface Methodology: Process and Product Optimization Using Designed Experiments, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: Monte Carlo analysis is generally acceptable for the second characterization if the behavioral model being used is fast and involves only a relatively small number of statistical parameters, which is often the case. The non-Monte Carlo techniques described in this chapter utilize response surface methodology (RSM) <ref> [83] </ref>. RSM involves constructing a circuit model which is locally linear or quadratic in the statistical parameters. The RSM model is constructed by performing an "experiment" in which the lower-level parameters are permuted in a regular fashion about their nominal values.
Reference: [84] <author> N. Nagi and J.A. Abraham, </author> <title> "Hierarchical Fault Modeling for Analog and Mixed-Signal Circuits," </title> <booktitle> Proc. IEEE VLSI Test Symposium, </booktitle> <pages> pp. 96-101, </pages> <year> 1992. </year>
Reference-contexts: Soma and Meixner developed analog fault models by performing Monte-Carlo defect simulations [124, 75]. Meixner models faulty analog behavior as modifications to the nominal macromodel. Nagi published some results on fault modeling for both catastrophic and parametric AC and DC faults in passive and active components <ref> [84] </ref>.
Reference: [85] <author> N. Nagi and J.A. Abraham, </author> <title> "Fault-Based Automatic Test Generator for Linear Analog Circuits," </title> <booktitle> Proc. IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pp. 88-91, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: At every chosen input frequency, simulations are performed to determine whether that frequency could be used as a test for a fault, until all faults have been covered <ref> [85] </ref>. Nagi uses inductive fault analysis (IFA) [116] to generate the faults to be considered, and only specific discretized values of parametric faults are considered. Balivada published a similar approach based on time-domain measurements and pole-zero analyses.
Reference: [86] <author> R. Naiknaware, G.N. Nandakumar and S.R. Kasa, </author> <title> "Automatic Test Plan Generation for Analog and Mixed Signal Integrated Circuits using Partial Activation and High Level Simulation," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 139-148, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: To generate the test plan for the chip, Naiknaware finds the chip input values that need to be applied to produce the desired block inputs and the chip output values that need to be measured to detect the appropriate block outputs <ref> [86] </ref>. 2.3.3 Catastrophic Fault Coverage Catastrophic faults are generally considered to be random defects that cause failures in various components.
Reference: [87] <institution> National Technology Road Map for Semiconductors, Semiconductor Industry Association, </institution> <address> San Jose, CA, </address> <year> 1994. </year>
Reference-contexts: Testers that cost under $2M (versus the $50M we would extrapolate from today's situation) must thoroughly test 200-million-gate ASICs with 3,000 I/O pins <ref> [87] </ref>. With typical testing targets currently being better than 40 ppm defect levels [102], testing these huge systems poses many formidable challenges. 3 The analog portions of these huge systems complicate their testing and characterization significantly.
Reference: [88] <author> M.S. Nejad, L. Sebaa, A. Ladick and F. Kuo, </author> <title> "Analog Built-In Self-Test," </title> <booktitle> Proc. IEEE International ASIC Conference and Exhibit, </booktitle> <pages> pp. 407-411, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: He developed on-chip methods to automatically verify frequency response, signal-to-noise ratio, gain tracking, inter-modulation distortion, and harmonic distortion using 8.6 mm 2 of silicon on a BiCMOS 0.8 m process. Najad presented comprehensive approaches for on-chip measurements of passive components <ref> [88] </ref>. The method relies upon precision reference components, which must be located off-chip. Olbrich designed a switched-current memory cell with BIST which achieves 95% coverage for shorts and 60% coverage for open circuits [93]. Chatterjee proposed a low-cost BIST technique for linear analog circuits using DC checksum codes [20].
Reference: [89] <author> N.K. Nguyen and A.J. Miller, </author> <title> "A Review of Some Exchange Algorithms for Constructing Discrete D-Optimal Designs," </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> vol. 14, </volume> <pages> pp. 489-498, </pages> <year> 1992. </year>
Reference-contexts: For larger problems, several heuristic algorithms have been successfully used to find "good" solutions to this and other related problems in the area of optimal experimental design. These heuristic algorithms include simulated annealing [23], greedy swap techniques <ref> [89] </ref>, and gradient descent techniques. For this research we used the gradient descent techniques implemented in the software package Gosset, which was recently developed by Hardin and Sloane at AT&T Bell Laboratories [48]. The analog testing algorithm we propose is: 1. <p> For larger problems, several heuristic algorithms have been successfully used to find "good" solutions to this and other related problems in the area of optimal experimental design. These heuristic algorithms include simulated annealing [23], greedy swap techniques <ref> [89] </ref>, and gradient descent techniques. For this research we used the gradient descent techniques implemented in the software package 37 Gosset, which was recently developed by Hardin and Sloane at AT&T Bell Laboratories [48].
Reference: [90] <author> P. Nigh and W. Maly, </author> <title> "Test Generation for Current Testing (CMOS ICs)," </title> <journal> IEEE Design & Test of Computers, </journal> <volume> vol. 7, </volume> <editor> n. </editor> <volume> 1, </volume> <pages> pp. 26-38, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: For digital circuits this technique is known as I DDQ testing <ref> [90, 40] </ref>, and is based on the observation that short-circuit and open-circuit faults often dramatically impact the quiescent power supply current, especially 22 for CMOS logic circuitry with most transistors connected to either the power supply or the ground.
Reference: [91] <author> J. Novellino, </author> <title> "Software Generates ASIC Test Programs," </title> <journal> Electronic Design, </journal> <volume> vol. 37, </volume> <editor> n. </editor> <volume> 9, </volume> <pages> pp. 59-62, </pages> <month> April </month> <year> 1989. </year> <month> 110 </month>
Reference-contexts: Tektronix sells a Waveform Analysis and Verification Environment which translates test vectors into the format needed for common ATE equipment <ref> [91] </ref>. LTX offers a similar product called enVision, which they describe as a "visual test programming language" [94]. Cadence's DANTES (Design and Test Engineering System) is an integrated design and test environment and a tool set for developing tests for analog and mixed-signal ICs.
Reference: [92] <author> J. Novellino, </author> <title> "Software Creates Analog, Mixed-Signal IC Tests," </title> <journal> Electronic Design, </journal> <volume> vol. 40, </volume> <editor> n. </editor> <volume> 10, </volume> <pages> pp. 104-106, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Test tools are tightly integrated with the design tools to let engineers consider test parameters, tester specifications, and testability issues during the design cycle, rather than at its end. DANTES then produces a test program for a specific tester <ref> [92] </ref>. These commercial analog testing products aid in the writing of test programs in the specific languages used by various mixed-signal testers, but they have generally been quite disappointing because they focus exclusively on practical issues like language and number of inputs and outputs.
Reference: [93] <author> T. Olbrich and A. Richardson, </author> <title> "Design and Self-Test for Switched-Current Building Blocks," </title> <journal> IEEE Design & Test of Computers, </journal> <volume> vol. 13, </volume> <editor> n. </editor> <volume> 2, </volume> <pages> pp. 10-17, </pages> <month> Summer </month> <year> 1996. </year>
Reference-contexts: Najad presented comprehensive approaches for on-chip measurements of passive components [88]. The method relies upon precision reference components, which must be located off-chip. Olbrich designed a switched-current memory cell with BIST which achieves 95% coverage for shorts and 60% coverage for open circuits <ref> [93] </ref>. Chatterjee proposed a low-cost BIST technique for linear analog circuits using DC checksum codes [20]. Mir et al. published BIST techniques for fully differential circuits in [79] and a review of general analog BIST techniques in [81]. Finally, Lopresti wrote about some experimental general analog BIST techniques in [69].
Reference: [94] <author> D. </author> <title> Organ, "enVision: The Inside Story," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 530-536, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Tektronix sells a Waveform Analysis and Verification Environment which translates test vectors into the format needed for common ATE equipment [91]. LTX offers a similar product called enVision, which they describe as a "visual test programming language" <ref> [94] </ref>. Cadence's DANTES (Design and Test Engineering System) is an integrated design and test environment and a tool set for developing tests for analog and mixed-signal ICs.
Reference: [95] <author> D.K. Papakostas and A.A. Hatzopoulos, </author> <title> "Correlation-Based Comparison of Analog Signatures for Identification and Fault Analysis," </title> <journal> IEEE Trans. on Instrumentation and Measurement, </journal> <volume> vol. 42, </volume> <editor> n. </editor> <volume> 4, </volume> <pages> pp. 860-863, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Robson demonstrated how M-sequence and current monitoring can be combined to produce a system level technique for testing mixed-signal circuits, with much of the test hardware being obtained from reconfigured digital system hardware [103]. In <ref> [95, 96] </ref> the authors proposed a method for identifying AC faults by using the spectrum of the power supply current to construct a fault dictionary. [42, 149] presented a similar approach, in which time-domain testing followed by spectral analysis of the power-supply current is used to detect both DC and AC
Reference: [96] <author> D.K. Papakostas and A.A. Hatzopoulos, </author> <title> "Supply Current Testing in Linear Bipolar ICs," </title> <journal> Electronics Letters, </journal> <volume> vol. 30, </volume> <editor> n. </editor> <volume> 2, </volume> <pages> pp. 128-130, </pages> <year> 1994. </year>
Reference-contexts: Robson demonstrated how M-sequence and current monitoring can be combined to produce a system level technique for testing mixed-signal circuits, with much of the test hardware being obtained from reconfigured digital system hardware [103]. In <ref> [95, 96] </ref> the authors proposed a method for identifying AC faults by using the spectrum of the power supply current to construct a fault dictionary. [42, 149] presented a similar approach, in which time-domain testing followed by spectral analysis of the power-supply current is used to detect both DC and AC
Reference: [97] <author> C.M. Pieper, </author> <title> "The Myth and Reality of Linking Design and Test," </title> <journal> Electronics Test, </journal> <volume> vol. 11, </volume> <editor> n. </editor> <volume> 4, </volume> <pages> pp. 55-61, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: These input files are referred to as the test program. In the majority of cases, these test programs are manually created, with an accuracy ranging from 100% to as little as 10% <ref> [97] </ref>. A surprising amount of research has been directed toward the languages for specifying the test input/output vectors for specific test equipment [12] and, in particular, toward automating the conversion of tests from the designers' environments to the specific languages used by the testers [29, 46].
Reference: [98] <author> V.C. Prasad and N.S.C. Babu, </author> <title> "On Minimal Set of Test Nodes for Fault Dictionary of Analog Circuit Fault Diagnosis," </title> <journal> Journal of Electronic Testing: Theory and Applications, </journal> <volume> vol. 7, </volume> <editor> n. </editor> <volume> 3, </volume> <pages> pp. 255-258, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: An interesting method for selecting additional test nodes using Boolean algebra is presented in [100], and a refinement is presented in <ref> [98, 99] </ref> which improves the computational complexity from exponential to O (f p 2 ), where p is the number of nodes and f is the number of faults.
Reference: [99] <author> V.C. Prasad and S.N. Rao Pinjala, </author> <title> "Fast Algorithms for Selection of Test Nodes of an Analog Circuit Using a Generalized Fault Dictionary Approach," Circuits, </title> <journal> Systems, and Signal Processing, </journal> <volume> vol. 14, </volume> <editor> n. </editor> <volume> 6, </volume> <pages> pp. 707-724, </pages> <year> 1995. </year>
Reference-contexts: An interesting method for selecting additional test nodes using Boolean algebra is presented in [100], and a refinement is presented in <ref> [98, 99] </ref> which improves the computational complexity from exponential to O (f p 2 ), where p is the number of nodes and f is the number of faults.
Reference: [100] <author> V.C. Prasad and S.N.R. Pinjala, </author> <title> "Boolean Method for Selection of Minimal Set of Test Nodes for Analogue Fault Dictionary," </title> <journal> Electronics Letters, </journal> <volume> vol. 29, </volume> <editor> n. </editor> <volume> 9, </volume> <pages> pp. 747-749, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: An interesting method for selecting additional test nodes using Boolean algebra is presented in <ref> [100] </ref>, and a refinement is presented in [98, 99] which improves the computational complexity from exponential to O (f p 2 ), where p is the number of nodes and f is the number of faults.
Reference: [101] <author> R. Rastogi and K. Sierzega, </author> <title> "A New Approach to Mixed-Signal Diagnosis," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 591-597, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Faults were inferred from the detection of inconsistencies and located by suspending constraints within the model. Electra is a commercial product based on a different AI approach. Electra uses behavioral models and a special troubleshooting decision tree to diagnose errors, similar to a binary search <ref> [117, 101] </ref>. AutoTEST is another AI-based commercial product which performs testability analysis, generating both quantitative and qualitative descriptions of the testability of a given design. The quantitative measures of testability are: 1. Fraction of faults detected, 2. Fault isolation resolution, and 3.
Reference: [102] <author> A. Richardson, T. Olbrich, V. Liberali and F. Maloberti, </author> <title> "Design-for-Test Strategies for Analogue and Mixed-Signal Integrated Circuits," </title> <booktitle> Midwest Symposium on Circuits and Systems, </booktitle> <pages> pp. 1139-1144, </pages> <month> August </month> <year> 1995. </year> <month> 111 </month>
Reference-contexts: Testers that cost under $2M (versus the $50M we would extrapolate from today's situation) must thoroughly test 200-million-gate ASICs with 3,000 I/O pins [87]. With typical testing targets currently being better than 40 ppm defect levels <ref> [102] </ref>, testing these huge systems poses many formidable challenges. 3 The analog portions of these huge systems complicate their testing and characterization significantly. <p> Many researchers claim to be improving testability by increasing the rank of the fault diagnosis matrix by adding additional circuitry to improve the control and/or ob-servability of the circuit, e.g. additional pins or an analog scan architecture <ref> [102] </ref>. <p> This approach has been increasingly questioned over the past decade due to high implementation costs, the difficulties associated with quantifying the effectiveness of the tests, and difficulties in accessing embedded analog sub-blocks <ref> [102] </ref>. Many researchers have promoted fault-based testing as an alternative to specification-based testing. The idea comes from the testing of digital circuits: since circuits fail because they contain faults, we assume that a circuit meets its specifications if we can verify that it does not contain any faults.
Reference: [103] <author> M. Robson and G. Russel, </author> <title> "Current Monitoring Technique for Testing Embedded Analogue Functions in Mixed Signal ICs," </title> <journal> Electronics Letters, </journal> <volume> vol. 32, </volume> <editor> n. </editor> <volume> 9, </volume> <pages> pp. 796-798, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: Robson demonstrated how M-sequence and current monitoring can be combined to produce a system level technique for testing mixed-signal circuits, with much of the test hardware being obtained from reconfigured digital system hardware <ref> [103] </ref>.
Reference: [104] <author> R.Y. Rubinstein, </author> <title> Simulation and the Monte Carlo Method, </title> <publisher> John Wiley & Sons, </publisher> <year> 1981. </year>
Reference-contexts: The most widely used technique for performing statistical characterization is Monte Carlo analysis <ref> [47, 104] </ref>. Unfortunately, the accuracy of results produced by a Monte Carlo analysis is only proportional to the square root of the number of simulations performed, and the number of Monte Carlo simulations required to produce a relatively accurate result increases exponentially with the number of low-level statistical parameters.
Reference: [105] <author> S. Runyon, </author> <title> "There's Plenty of Activity in the Mixed-Signal Arena," </title> <booktitle> High Performance Systems, </booktitle> <pages> pp. 47-49, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Determining which tests to apply is still a human decision. In 1989 Runyon predicted that we were still 10 years away from any commercial product which would achieve automatic test program generation <ref> [105] </ref>; unfortunately, his prediction has held true. 13 2.2 Fault Diagnosis Fault diagnosis is the process of locating faults in a system, if any exist, by observing the system outputs under various test conditions.
Reference: [106] <author> G. Russell and D.S. Learmonth, </author> <title> "Systematic Approaches to Testing Embedded Analogue Circuit Functions," </title> <journal> Microelectronics Journal, </journal> <volume> vol. 25, </volume> <editor> n. </editor> <volume> 2, </volume> <pages> pp. 133-138, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Taylor developed testing techniques using transient response analysis for linear sub-systems embedded within mixed-signal ICs [135]. Borrowing an effective technique from digital testing, Sloan proposed the use of random waveforms in [122]. Russell expanded on this idea in <ref> [106] </ref>, presenting two new types of input stimuli: 1. Residual multiple frequency testing. This technique is derived from concurrent error detection methods employing `information redundancy' techniques used for testing digital circuits.
Reference: [107] <author> M. Sachdev, </author> <title> "A Realistic Defect Oriented Testability Methodology for Analog Circuits," </title> <journal> Journal of Electronic Testing: Theory and Applications, </journal> <volume> vol. 6, </volume> <editor> n. </editor> <volume> 3, </volume> <pages> pp. 265-276, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: This technique, which is also used extensively on digital circuits, involves randomly placing circular "defects" of various radii onto the layout and recording the shorts and opens created by each simulated defect. Sachdev uses IFA directly in his fault dictionary approach <ref> [107] </ref> to generate realistic fault dictionaries. 2.2.3 Artificial Intelligence The most popular commercial fault diagnosis systems use artificial intelligence (AI) approaches. In the first AI approach, measurement effects were propagated backwards though the circuit model until a fault was found [73]. The DC voltage was measured at different nodes. <p> Performance-based testing refers to testing techniques that verify circuit performance specifications. The most direct form of performance-based testing is the direct measurement of all circuit specifications, which is the way in which almost all analog circuits are presently tested <ref> [107] </ref>. But there are several other approaches which have been developed, including the one described in this dissertation, which are more efficient and at least as effective at distinguishing circuits which meet specifications from those which do not. <p> Bandwidth performance loss is minimal and area overhead is approximately 5% for each modified operational amplifier [11]. In general, DFT schemes based on some kind of a structural division of the circuit have been largely unsuccessful because of their impact on the circuit performance <ref> [107] </ref>. Analog scan and analog built-in-self-test are efforts to make analog circuits more testable without sacrificing performance. The main use for the techniques described in this dissertation in design for testability lies in estimating the number of tests which must be applied to fully verify circuit functionality.
Reference: [108] <author> R. Saeks, </author> <title> "A Measure of Testability and its Application to Test Point Selection Theory," </title> <booktitle> Midwest Symposium on Circuits and Systems, </booktitle> <month> August </month> <year> 1977. </year>
Reference-contexts: The testability of a system generally refers to the solvability of this system of diagnostic equations. Saeks developed a quantitative evaluation of this testability in <ref> [108] </ref>. Temes gave a unique measure of how readily elements can be diagnosed from test terminal measurements, computed from a set of test points on the circuit under test [136]. And Sen linked the measure of solvability of the system to the fault diagnosis equations [115].
Reference: [109] <author> R. Saeks, A. Sangiovanni-Vincentelli and V. Visvanathan, </author> <title> "Diagnosability of Nonlinear Circuits and Systems|Part II: Dynamical Systems," </title> <journal> IEEE Trans. on Circuits and Systems, </journal> <volume> vol. CAS-28, </volume> <pages> pp. 1103-1108, </pages> <month> November </month> <year> 1981. </year>
Reference: [110] <author> A.E. Salama, </author> <title> "A Unified Decomposition Approach for Fault Location in Large Analog Circuits," </title> <journal> IEEE Trans. on Circuits and Systems, </journal> <volume> vol. </volume> <editor> CAS-31, n. </editor> <volume> 7, </volume> <pages> pp. 609-622, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: Once the ambiguity groups are found, some of the parameters can be assumed to be fault free (set to their nominal values) to make the diagnostic equations solvable [67]. Several researchers have applied these linear network theory ideas to the decomposition of large networks into subnetworks <ref> [110, 62, 131] </ref>. These approaches facilitate testing by localizing the effects of faults to specific subnetworks. 2.2.2 Fault Dictionaries The fault dictionary is one of the oldest approaches to analog fault diagnosis, and it is still frequently used in industrial environments. Its popularity is due to: 1.
Reference: [111] <author> H. Schreiber, </author> <title> "Fault Dictionary Based Upon Stimulus Design," </title> <journal> IEEE Trans. on Circuits and Systems, </journal> <volume> vol. CAS-26, </volume> <pages> pp. 529-537, </pages> <month> July </month> <year> 1979. </year>
Reference-contexts: M-sequences are DC level, not bit sequences. A periodic pseudo-noise signal is applied to the circuit under test, and the Weiner-Hopf equation is used to estimate the impulse response of the circuit. Finally, Schreiber and Corsi apply a sequence of pulses with varying amplitude <ref> [111, 22] </ref>. 2.3.7 Power Supply Current Monitoring Several researchers have noted that monitoring the power supply current of the circuit being tested can detect many catastrophic faults.
Reference: [112] <author> M.H. Schultz, E. Trischler and T.M. Sarfert, "SOCRATES: </author> <title> A Highly Efficient Automatic Test Pattern Generation System," </title> <journal> IEEE Trans. on Computer-Aided Design of Integrated Circuits and Systems, </journal> <volume> vol. 7, </volume> <editor> n. </editor> <volume> 1, </volume> <pages> pp. 126-137, </pages> <year> 1988. </year>
Reference-contexts: Most of the previous work in testing of electrical systems has been directed at digital circuits, and efficient techniques have been developed for testing both combinational and sequential digital systems <ref> [112, 41] </ref>. These digital testing techniques are based on the single stuck-at-0/stuck-at-1 fault model and the controllability and observability of each fault. Unfortunately most of the digital testing ideas cannot be directly applied to analog systems.
Reference: [113] <author> S.R. Searle, </author> <title> Linear Models, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1971. </year>
Reference-contexts: Note that for any given coefficients in a quadratic equation, A is uniquely determined <ref> [113] </ref>. Let tr (A) denote the trace of A. Theorems 6.3.3 and 6.3.4 show how E [y i ] and var [y i ] can be calculated. <p> Theorem 6.3.6 is used to compute cov [y i ; y j ] <ref> [113] </ref>. Theorem 6.3.6 If X ~ N p (; ), then cov X 0 AX; X 0 BX = 2tr (AB) + 4 0 AB (6.29) Proof: Let T = [X 0 X 0 ] be the (2p)-dimensional vector formed by replicating X.
Reference: [114] <author> G.A.F. Seber, </author> <title> Linear Regression Analysis, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1977. </year> <month> 112 </month>
Reference-contexts: Given these values we can calculate the exact confidence interval for the entire response surface using Scheffe's method for simultaneous interval estimation <ref> [114, Chapter 5] </ref>. The Scheffe confidence interval is given by CI (^y (x)) = f (x) ^ fi pF ff h i where 1 ff is the exact overall probability that the actual system response lies completely within the confidence interval. <p> When X can be assumed to follow a multivariate normal distribution, i.e. X ~ N p (; ), then E W 0 AW i 2 2 E 0 AW i E 0 AW W 0 AW = 0: (6.27) Theorem 6.3.5 follows immediately <ref> [114] </ref>. Theorem 6.3.5 If X ~ N (; ), then var X 0 AX = 2tr (A) 2 + 4 0 AA (6.28) To compute the off-diagonal elements of D [Y ], we need to compute cov [y i ; y j ] for all i; j. <p> When X is multivariate normal and a quadratic model is used, then (X ) 0 A (X ) ~ 2 r if and only if AA = A, where r is the rank of A <ref> [114] </ref>. Otherwise the distribution of Y does not follow an easily-computable form. In practice, however, one introduces little error by assuming that the intermediate parameters are approximately multivariate normal, even when a quadratic model is used. <p> Pseudo-code for computing the Cholesky decomposition of a symmetric positive semidefinite pfip matrix is shown in Figure 6.3. Note that all variance-covariance matrices are symmetric and positive semidefinite <ref> [114] </ref>. 6.5 Results The statistical characterization techniques described in this chapter have been tested by performing statistical characterizations of two circuits. The first circuit is a folded cascode operational amplifier, which illustrates the building of a statistical behavioral model from a Spice-level block.
Reference: [115] <author> N. Sen and R. Saeks, </author> <title> "Fault Diagnosis for Linear Systems via Multifrequency Measurements," </title> <journal> IEEE Trans. on Circuits and Systems, </journal> <volume> vol. CAS-26, </volume> <year> 1979. </year>
Reference-contexts: Temes gave a unique measure of how readily elements can be diagnosed from test terminal measurements, computed from a set of test points on the circuit under test [136]. And Sen linked the measure of solvability of the system to the fault diagnosis equations <ref> [115] </ref>. Hemink extended this approach to nonlinear systems [53, 52]. He combined a rank-test algorithm with statistical methods to find sets of dependent parameters and determine whether it is possible to calculate a certain parameter with sufficient accuracy. <p> To ignore some of the parameters, one can analyze a circuit's ambiguity groups, which are the sets of linearly dependent parameters which cause the diagnostic equations to be rank deficient. Finding ambiguity groups is a computationally intense process which has been studied by many researchers over the years <ref> [7, 115, 5, 133, 65] </ref>. Once the ambiguity groups are found, some of the parameters can be assumed to be fault free (set to their nominal values) to make the diagnostic equations solvable [67].
Reference: [116] <author> J.P. Shen, W. Maly and F.J. Ferguson, </author> <title> "Inductive Fault Analysis of MOS Integrated Circuits," </title> <journal> IEEE Design & Test of Computers, </journal> <volume> vol. 2, </volume> <editor> n. </editor> <volume> 6, </volume> <pages> pp. 13-26, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: To determine which faults need to be included in the fault dictionary, most implementations use inductive fault analysis (IFA) <ref> [116] </ref>. This technique, which is also used extensively on digital circuits, involves randomly placing circular "defects" of various radii onto the layout and recording the shorts and opens created by each simulated defect. <p> At every chosen input frequency, simulations are performed to determine whether that frequency could be used as a test for a fault, until all faults have been covered [85]. Nagi uses inductive fault analysis (IFA) <ref> [116] </ref> to generate the faults to be considered, and only specific discretized values of parametric faults are considered. Balivada published a similar approach based on time-domain measurements and pole-zero analyses. To determine a test, he chooses the input which maximizes the error for each fault.
Reference: [117] <author> K. Sierzega and R. Rasogi, </author> <title> "Model-based Reasoning Finds Analog PCB Faults," </title> <journal> Electronics Test, </journal> <volume> vol. 13, </volume> <editor> n. </editor> <volume> 3, </volume> <pages> pp. 26-30, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Faults were inferred from the detection of inconsistencies and located by suspending constraints within the model. Electra is a commercial product based on a different AI approach. Electra uses behavioral models and a special troubleshooting decision tree to diagnose errors, similar to a binary search <ref> [117, 101] </ref>. AutoTEST is another AI-based commercial product which performs testability analysis, generating both quantitative and qualitative descriptions of the testability of a given design. The quantitative measures of testability are: 1. Fraction of faults detected, 2. Fault isolation resolution, and 3.
Reference: [118] <institution> SimPilot User's Manual, ANACAD Electrical Engineering Software, ULM (Donau) Germany, </institution> <year> 1995. </year>
Reference-contexts: For each permutation of the lower-level parameters, a simulation is performed and the resultant values of the higher-level parameters are recorded. The coefficients of the RSM model are then obtained by linear regression. SimPilot <ref> [118] </ref> is a commercial tool which implements RSM. At each level of the statistical characterization it is essential to consider the correlations between parameters, as independent parameters are uncommon.
Reference: [119] <author> M. Slamani and B. Kaminska, </author> <title> "Analog Circuit Fault Diagnosis Based on Sensitivity Computation and Functional Testing," </title> <journal> IEEE Design & Test of Computers, </journal> <volume> vol. 9, </volume> <editor> n. </editor> <volume> 1, </volume> <pages> pp. 30-39, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: For these reasons, analog testing is considered to be one of the most important problems in analog and mixed-signal design. The main factors that make analog circuit testing difficult can be summarized as follows <ref> [119] </ref>: * Analog systems are frequently nonlinear, include noise, and have parameter values that vary widely. Thus, deterministic methods are often inefficient for modeling these systems. * Relations between input and output signals in analog circuits are sometimes complicated compared to those of digital systems. <p> Slamani proposed a fault-based testing approach for parametric faults which is very similar to the sensitivity-based fault diagnosis algorithms. His approach uses sensitivity analysis to solve for the values of the internal parameters <ref> [119, 120] </ref>. In the case of linearly dependent parameters, one must add additional test points to make the sensitivity matrix full rank. In [121] Slamani used sensitivities to study fault masking, fault dominance, fault equivalence, and non-observable faults.
Reference: [120] <author> M. Slamani and B. Kaminska, </author> <title> "Testing Analog Circuits by Sensitivity Computation," </title> <booktitle> Proc. The European Conference on Design Automation, </booktitle> <pages> pp. 532-537, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Slamani proposed a fault-based testing approach for parametric faults which is very similar to the sensitivity-based fault diagnosis algorithms. His approach uses sensitivity analysis to solve for the values of the internal parameters <ref> [119, 120] </ref>. In the case of linearly dependent parameters, one must add additional test points to make the sensitivity matrix full rank. In [121] Slamani used sensitivities to study fault masking, fault dominance, fault equivalence, and non-observable faults.
Reference: [121] <author> M. Slamani and B. Kaminska, </author> <title> "Multifrequency Testability Analysis for Analog Circuits," </title> <booktitle> Proc. IEEE VLSI Test Symposium, </booktitle> <pages> pp. 54-59, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: His approach uses sensitivity analysis to solve for the values of the internal parameters [119, 120]. In the case of linearly dependent parameters, one must add additional test points to make the sensitivity matrix full rank. In <ref> [121] </ref> Slamani used sensitivities to study fault masking, fault dominance, fault equivalence, and non-observable faults. For each fault he picks the measurement which 20 maximizes sensitivity of the output node with respect to the candidate fault. Hamida presented a similar sensitivity-based approach.
Reference: [122] <author> E.A. Sloan, </author> <title> "Transfer Function Estimation, Part I, Theoretical and Practical Considerations (Testing Application)," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 426-439, </pages> <month> October </month> <year> 1984. </year>
Reference-contexts: Dai and Souders described a time-domain approach based on sensitivity analysis [25]. Taylor developed testing techniques using transient response analysis for linear sub-systems embedded within mixed-signal ICs [135]. Borrowing an effective technique from digital testing, Sloan proposed the use of random waveforms in <ref> [122] </ref>. Russell expanded on this idea in [106], presenting two new types of input stimuli: 1. Residual multiple frequency testing. This technique is derived from concurrent error detection methods employing `information redundancy' techniques used for testing digital circuits.
Reference: [123] <author> M. Soma, </author> <title> "A Design-for-Test Methodology for Active Analog Filters," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 183-192, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Most researchers in this area have attempted to develop circuitry which permits the various analog sub-blocks to be individually controlled and observed in isolation, e.g. [56]. This can be accomplished by signal multiplexing [147] or the use of MOS switches to isolate filter stages <ref> [123] </ref>. For op-amp-based modules, Renovell proposed some specific circuit modifications that can be used to bring controllability and observability to the frontier of each embedded module by creating transparent paths between external and internal I/Os. <p> These cells allow voltages and currents to be shifted into and out from internal nodes, but use a large area. Soma developed analog scan cells for several specific circuit architectures. In <ref> [123] </ref> he presented an analog scan technique for active analog filters. In [127] he presented a technique for switched-capacitor filters. And in [126] he presented a general current-based analog scan cell.
Reference: [124] <author> M. Soma, </author> <title> "An Experimental Approach to Analog Fault Models," </title> <booktitle> Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pp. </pages> <address> 13.6.1-13.6.4, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Catastrophic faults consist of stuck-at faults, open faults, and bridging faults. The parametric fault class consists of faults that result in performance outside accepted limits and are usually associated with variations in design parameters (e.g. passive component values, device sizes) <ref> [75, 78, 124] </ref>. The previous research in analog testing can be classified into five main categories: practical approaches, fault diagnosis, fault-based testing, performance-based testing, and design for testability. <p> Early work was based on experimental manufacturing defect statistics and showed that open faults and bridging faults are the most frequent catastrophic fault types [70, 148, 157]. Soma and Meixner developed analog fault models by performing Monte-Carlo defect simulations <ref> [124, 75] </ref>. Meixner models faulty analog behavior as modifications to the nominal macromodel. Nagi published some results on fault modeling for both catastrophic and parametric AC and DC faults in passive and active components [84].
Reference: [125] <author> M. Soma, </author> <title> "Fault Coverage of DC Parametric Tests for Embedded Analog Amplifiers," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 566-573, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Soma reached a similar conclusion in his study of catastrophic fault coverage of DC parametric tests on amplifiers, in which he reported coverage of less than 80% <ref> [125] </ref>. Another DC test generation technique for detecting catastrophic failures was presented by Devarayanadurg in [27].
Reference: [126] <author> M. Soma, </author> <title> "Structure and Concepts for Current-Based Analog Scan," </title> <booktitle> Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pp. 517-520, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Soma developed analog scan cells for several specific circuit architectures. In [123] he presented an analog scan technique for active analog filters. In [127] he presented a technique for switched-capacitor filters. And in <ref> [126] </ref> he presented a general current-based analog scan cell. The general cell uses current to represent the analog signal to be scanned and otherwise functions the same as a digital scan cell. A new mixed-mode boundary scan architecture was presented by Lee in [63].
Reference: [127] <author> M. Soma and V. Kolarik, </author> <title> "A Design-for-Test Technique for Switched-Capacitor Filters," </title> <booktitle> Proc. IEEE VLSI Test Symposium, </booktitle> <pages> pp. 42-47, </pages> <month> April </month> <year> 1994. </year> <month> 113 </month>
Reference-contexts: These cells allow voltages and currents to be shifted into and out from internal nodes, but use a large area. Soma developed analog scan cells for several specific circuit architectures. In [123] he presented an analog scan technique for active analog filters. In <ref> [127] </ref> he presented a technique for switched-capacitor filters. And in [126] he presented a general current-based analog scan cell. The general cell uses current to represent the analog signal to be scanned and otherwise functions the same as a digital scan cell.
Reference: [128] <author> T. Souders and G. Stenbakken, </author> <title> "A Comprehensive Approach for Modeling and Testing Analog and Mixed-Signal Devices," </title> <booktitle> IEEE International Test Conference, </booktitle> <pages> pp. 169-176, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The first is a bandpass filter with center frequency of 24.5 kHz <ref> [128] </ref>, which was analyzed using Spice sensitivity analysis. The second is a single MOS transistor, which was analyzed in Spice with a level 3 transistor model.
Reference: [129] <author> T. Souders and G. Stenbakken, </author> <title> "Cutting the High Cost of Testing," </title> <journal> IEEE Spectrum, </journal> <pages> pp. 48-51, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: Souders and Stenbakken developed automatic test pattern generation algorithms for verifying performance specifications using linear models based on the sensitivity of the output with respect to the internal process/model parameters. These linear models can be derived either from simulation [132] or from manufacturing data <ref> [129] </ref> using QR-decomposition. Souders and Stenbakken select test points by using a greedy method, iteratively picking the test point to which the circuit is the most sensitive, given that the previous tests have been applied. The chosen test points are reasonable, but in no sense are they optimal. <p> Many analog systems can be accurately modeled in this fashion by using sensitivity analysis [132] or QR decomposition <ref> [129] </ref>. * may be either specified by the designer or estimated from previous tests. Note that Equation 5.1 is linear in the unknowns ffi i g, but the basis functions fg i g can be nonlinear.
Reference: [130] <author> SPAYN User's Manual, </author> <booktitle> Silvaco International, </booktitle> <address> Santa Clara, California, </address> <year> 1995. </year>
Reference-contexts: Principal component analysis (PCA) or principal factor analysis (PFA) can be used to extract the statistically relevant combinations of parameters and thereby reduce the number of lower-level parameters which must be considered [154, 55]. Given a set of model cards which have been extracted from fabricated devices, Spayn <ref> [130] </ref> is a commercial tool which performs PCA and PFA. This technique typically results in 2-3 statistically relevant principal components per transistor, which can explain at least 75% of the observed variation in 15 level 3 MOS model parameters.
Reference: [131] <author> J.A. Starzyk and H. Dai, </author> <title> "A Decomposition Approach for Testing Large Analog Networks," </title> <journal> Journal of Electronic Testing: Theory and Applications, </journal> <volume> vol. 3, </volume> <editor> n. </editor> <volume> 3, </volume> <pages> pp. 181-195, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Once the ambiguity groups are found, some of the parameters can be assumed to be fault free (set to their nominal values) to make the diagnostic equations solvable [67]. Several researchers have applied these linear network theory ideas to the decomposition of large networks into subnetworks <ref> [110, 62, 131] </ref>. These approaches facilitate testing by localizing the effects of faults to specific subnetworks. 2.2.2 Fault Dictionaries The fault dictionary is one of the oldest approaches to analog fault diagnosis, and it is still frequently used in industrial environments. Its popularity is due to: 1.
Reference: [132] <author> G. Stenbakken and T. Souders, </author> <title> "Test-Point Selection and Testability Measures via QR Factorization of Linear Models," </title> <journal> IEEE Trans. on Instrumentation and Measurement, </journal> <month> June </month> <year> 1987. </year>
Reference-contexts: Souders and Stenbakken developed automatic test pattern generation algorithms for verifying performance specifications using linear models based on the sensitivity of the output with respect to the internal process/model parameters. These linear models can be derived either from simulation <ref> [132] </ref> or from manufacturing data [129] using QR-decomposition. Souders and Stenbakken select test points by using a greedy method, iteratively picking the test point to which the circuit is the most sensitive, given that the previous tests have been applied. <p> Many analog systems can be accurately modeled in this fashion by using sensitivity analysis <ref> [132] </ref> or QR decomposition [129]. * may be either specified by the designer or estimated from previous tests. Note that Equation 5.1 is linear in the unknowns ffi i g, but the basis functions fg i g can be nonlinear.
Reference: [133] <author> G. Stenbakken, T. Souders and G. Stewart, </author> <title> "Ambiguity Groups and Testability," </title> <journal> IEEE Trans. on Instrumentation and Measurement, </journal> <volume> vol. 38, </volume> <month> October </month> <year> 1989. </year>
Reference-contexts: To ignore some of the parameters, one can analyze a circuit's ambiguity groups, which are the sets of linearly dependent parameters which cause the diagnostic equations to be rank deficient. Finding ambiguity groups is a computationally intense process which has been studied by many researchers over the years <ref> [7, 115, 5, 133, 65] </ref>. Once the ambiguity groups are found, some of the parameters can be assumed to be fault free (set to their nominal values) to make the diagnostic equations solvable [67]. <p> Parameter dependencies result in ambiguity groups, which are groups of parameters that are not independent. This algorithm represents a significant computational improvement over previously published algorithms for finding these groups <ref> [133, 67] </ref>.
Reference: [134] <author> G.N. Stenbakken and T.M. Souders, </author> <title> "Linear Error Modeling of Analog and Mixed-Signal Devices," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 573-581, </pages> <year> 1991. </year>
Reference-contexts: We wish to estimate f (a + x). A first-order Taylor series approximation is a reasonably accurate model for many common analog systems with parameters that do not deviate significantly from their nominal values. This is the model used by Stenbakken and Souders <ref> [134] </ref>, and our discussion of it here will be brief.
Reference: [135] <author> D. Taylor, P.S.A. Evans and T.I. Pritchard, </author> <title> "Testing for Functional Defects in Embedded Digital-to-Analogue Converters Using Dynamic Stimuli and Transient Response Analysis," </title> <journal> Microelectronics Journal, </journal> <volume> vol. 25, </volume> <editor> n. </editor> <volume> 6, </volume> <pages> pp. 415-424, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: At least three researchers have studied time-domain techniques. Chin analyzed the transient response to step inputs with multivariable discriminant analysis [21]. Dai and Souders described a time-domain approach based on sensitivity analysis [25]. Taylor developed testing techniques using transient response analysis for linear sub-systems embedded within mixed-signal ICs <ref> [135] </ref>. Borrowing an effective technique from digital testing, Sloan proposed the use of random waveforms in [122]. Russell expanded on this idea in [106], presenting two new types of input stimuli: 1. Residual multiple frequency testing.
Reference: [136] <author> G. Temes, </author> <title> "Large-Change Sensitivities for Linear Digital Networks," </title> <booktitle> Midwest Symposium on Circuits and Systems, </booktitle> <month> August </month> <year> 1977. </year>
Reference-contexts: Saeks developed a quantitative evaluation of this testability in [108]. Temes gave a unique measure of how readily elements can be diagnosed from test terminal measurements, computed from a set of test points on the circuit under test <ref> [136] </ref>. And Sen linked the measure of solvability of the system to the fault diagnosis equations [115]. Hemink extended this approach to nonlinear systems [53, 52].
Reference: [137] <author> M.F. Toner and G.W. Roberts, </author> <title> "A BIST Scheme for an SNR Test of a Sigma-Delta ADC," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 805-814, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: A "self-test" of the circuit "passes" when the measurements agree with the corresponding prestored signatures, within certain tolerance bounds. Most research on analog BIST has been directed at specific circuits. Toner published extensively on using BIST for A/D converter testing <ref> [137, 138, 139, 140, 141] </ref>. He developed on-chip methods to automatically verify frequency response, signal-to-noise ratio, gain tracking, inter-modulation distortion, and harmonic distortion using 8.6 mm 2 of silicon on a BiCMOS 0.8 m process. Najad presented comprehensive approaches for on-chip measurements of passive components [88].
Reference: [138] <author> M.F. Toner and G.W. Roberts, </author> <title> "A BIST Technique for a Frequency Response and Intermodulation Distortion Test of a Sigma-Delta ADC," </title> <booktitle> Proc. IEEE VLSI Test Symposium, </booktitle> <pages> pp. 60-65, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: A "self-test" of the circuit "passes" when the measurements agree with the corresponding prestored signatures, within certain tolerance bounds. Most research on analog BIST has been directed at specific circuits. Toner published extensively on using BIST for A/D converter testing <ref> [137, 138, 139, 140, 141] </ref>. He developed on-chip methods to automatically verify frequency response, signal-to-noise ratio, gain tracking, inter-modulation distortion, and harmonic distortion using 8.6 mm 2 of silicon on a BiCMOS 0.8 m process. Najad presented comprehensive approaches for on-chip measurements of passive components [88].
Reference: [139] <author> M.F. Toner and G.W. Roberts, </author> <title> "A BIST Scheme for a SNR, Gain Tracking, and Frequency Response Test of a Sigma-Delta ADC," </title> <journal> IEEE Trans. on Circuits and 114 Systems II: Analog and Digital Signal Processing, </journal> <volume> vol. 42, </volume> <editor> n. </editor> <volume> 1, </volume> <pages> pp. 1-15, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: A "self-test" of the circuit "passes" when the measurements agree with the corresponding prestored signatures, within certain tolerance bounds. Most research on analog BIST has been directed at specific circuits. Toner published extensively on using BIST for A/D converter testing <ref> [137, 138, 139, 140, 141] </ref>. He developed on-chip methods to automatically verify frequency response, signal-to-noise ratio, gain tracking, inter-modulation distortion, and harmonic distortion using 8.6 mm 2 of silicon on a BiCMOS 0.8 m process. Najad presented comprehensive approaches for on-chip measurements of passive components [88].
Reference: [140] <author> M.F. Toner and G.W. Roberts, </author> <title> "On the Practical Implementation of Mixed Analog-Digital BIST," </title> <booktitle> Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pp. 525-528, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: A "self-test" of the circuit "passes" when the measurements agree with the corresponding prestored signatures, within certain tolerance bounds. Most research on analog BIST has been directed at specific circuits. Toner published extensively on using BIST for A/D converter testing <ref> [137, 138, 139, 140, 141] </ref>. He developed on-chip methods to automatically verify frequency response, signal-to-noise ratio, gain tracking, inter-modulation distortion, and harmonic distortion using 8.6 mm 2 of silicon on a BiCMOS 0.8 m process. Najad presented comprehensive approaches for on-chip measurements of passive components [88].
Reference: [141] <author> M.F. Toner and G.W. Roberts, </author> <title> "A Frequency Response, Harmonic Distortion, and Intermodulation Distortion Test for BIST of a Sigma-Delta ADC," </title> <journal> IEEE Trans. on Circuits and Systems II: Analog and Digital Signal Processing, </journal> <volume> vol. 43, </volume> <editor> n. </editor> <volume> 8, </volume> <pages> pp. 608-613, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: A "self-test" of the circuit "passes" when the measurements agree with the corresponding prestored signatures, within certain tolerance bounds. Most research on analog BIST has been directed at specific circuits. Toner published extensively on using BIST for A/D converter testing <ref> [137, 138, 139, 140, 141] </ref>. He developed on-chip methods to automatically verify frequency response, signal-to-noise ratio, gain tracking, inter-modulation distortion, and harmonic distortion using 8.6 mm 2 of silicon on a BiCMOS 0.8 m process. Najad presented comprehensive approaches for on-chip measurements of passive components [88].
Reference: [142] <author> S.-J. Tsai, </author> <title> "Test Vector Generation for Linear Analog Devices," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 592-597, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: In [19] Chao and Milor generalized this approach to include behavioral models and both catastrophic and parametric faults. For circuits with a linear input/output relationship, several researchers have published interesting approaches. Tsai formulated the problem of detecting parametric faults as a quadratic programming problem <ref> [142] </ref>. Nagi developed DRAFTS (DiscRetized Analog circuit FaulT Simulator), which is an efficient AC fault simulator for linear analog circuits.
Reference: [143] <author> UTMOST User's Manual, </author> <booktitle> Silvaco International, </booktitle> <address> Santa Clara, California, </address> <year> 1995. </year>
Reference-contexts: SGS-Thomson Level 3 NMOS and PMOS models were extracted for each die, with 28 parameters per model. The accuracy of the models is within 5%. An example of extraction is shown in Figure 6.6. The total measurement time was 45 hours using Utmost <ref> [143] </ref> and a prober driven by a Sun Sparc 10.
Reference: [144] <author> R.J. van Rijsinge, A.A.R.M. Haggenburg, C. de Vries and H. Wallinga, </author> <title> "From Specification to Measurement: The Bottleneck in Analog Industrial Testing," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 177-182, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: A useful survey of the most common design for testability techniques for analog and mixed-signal circuits can be found in [156]. Rijsinge proposed a statistical approach; he evaluates the number of test vectors required to measure a given parameter with a specified accuracy <ref> [144] </ref>. The technique is geared more toward fault diagnosis than production testing, but the testing applications are evident. Most researchers in this area have attempted to develop circuitry which permits the various analog sub-blocks to be individually controlled and observed in isolation, e.g. [56].
Reference: [145] <author> V. Visvanathan and A. Sangiovanni-Vincentelli, </author> <title> "A Computational Approach for the Diagnosability of Dynamical Circuits," </title> <journal> IEEE Trans. on Computer-Aided Design of Integrated Circuits and Systems, </journal> <volume> vol. CAD-3, </volume> <pages> pp. 165-171, </pages> <month> July </month> <year> 1984. </year>
Reference: [146] <author> A. Vladimirescu, </author> <title> A.R. Newton and D.O. </title> <journal> Pederson, </journal> <note> SPICE Version 2G.1 User's Guide, </note> <institution> Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, </institution> <address> CA, </address> <year> 1980. </year>
Reference-contexts: The primary focus of Gosset is low-order polynomial models, which are of only limited use in characterizing typical analog circuits. For this research, therefore, Gosset was extended to utilize arbitrary Lipschitz continuous functions, such as the piecewise linear output of common behavioral simulators [68] and Spice <ref> [146] </ref>.
Reference: [147] <author> K.D. Wagner and T.W. Williams, </author> <title> "Design for Testability of Mixed Signal Integrated Circuits," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 823-828, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Most researchers in this area have attempted to develop circuitry which permits the various analog sub-blocks to be individually controlled and observed in isolation, e.g. [56]. This can be accomplished by signal multiplexing <ref> [147] </ref> or the use of MOS switches to isolate filter stages [123]. For op-amp-based modules, Renovell proposed some specific circuit modifications that can be used to bring controllability and observability to the frontier of each embedded module by creating transparent paths between external and internal I/Os.
Reference: [148] <author> D.M.H. Walker, </author> <title> Yield Simulation for Integrated Circuits, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1987. </year>
Reference-contexts: Daugherty presented the basic concepts of analog fault simulation in [26]. Early work was based on experimental manufacturing defect statistics and showed that open faults and bridging faults are the most frequent catastrophic fault types <ref> [70, 148, 157] </ref>. Soma and Meixner developed analog fault models by performing Monte-Carlo defect simulations [124, 75]. Meixner models faulty analog behavior as modifications to the nominal macromodel. Nagi published some results on fault modeling for both catastrophic and parametric AC and DC faults in passive and active components [84].
Reference: [149] <author> Z. Wang, G. Gielen and W. Sansen, </author> <title> "Testing of Analog Integrated Circuits Based on Power-Supply Current Monitoring and Discrimination Analysis," </title> <booktitle> Proc. Asian Test Symposium, </booktitle> <pages> pp. 126-131, </pages> <month> November </month> <year> 1994. </year> <month> 115 </month>
Reference-contexts: In [95, 96] the authors proposed a method for identifying AC faults by using the spectrum of the power supply current to construct a fault dictionary. <ref> [42, 149] </ref> presented a similar approach, in which time-domain testing followed by spectral analysis of the power-supply current is used to detect both DC and AC faults.
Reference: [150] <author> C.-L. Wey, </author> <title> "Built-In Self-Test (BIST) Structure for Analog Circuit Fault Diagnosis," </title> <journal> IEEE Trans. on Instrumentation and Measurement, </journal> <volume> vol. 39, </volume> <editor> n. </editor> <volume> 3, </volume> <pages> pp. 517-521, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: He uses scan methods for the digital sections and a special arrangement of multiplexors and additional test points for the analog blocks. Signal storage cells for a fully analog scan technique have been presented by Wey, both for voltages <ref> [150] </ref> and for currents [151]. These cells allow voltages and currents to be shifted into and out from internal nodes, but use a large area. Soma developed analog scan cells for several specific circuit architectures. In [123] he presented an analog scan technique for active analog filters.
Reference: [151] <author> C.-L. Wey and S. Krishnan, </author> <title> "Built-In Self-Test (BIST) Structure for Analog Circuit Fault Diagnosis with Current Test Data," </title> <journal> IEEE Trans. on Instrumentation and Measurement, </journal> <volume> vol. 41, </volume> <editor> n. </editor> <volume> 4, </volume> <pages> pp. 535-539, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: He uses scan methods for the digital sections and a special arrangement of multiplexors and additional test points for the analog blocks. Signal storage cells for a fully analog scan technique have been presented by Wey, both for voltages [150] and for currents <ref> [151] </ref>. These cells allow voltages and currents to be shifted into and out from internal nodes, but use a large area. Soma developed analog scan cells for several specific circuit architectures. In [123] he presented an analog scan technique for active analog filters.
Reference: [152] <author> C.-L. Wey and R. Saeks, </author> <title> "On the Implementation of an Analog ATPG: the Linear Case," </title> <journal> IEEE Trans. on Instrumentation and Measurement, </journal> <volume> vol. </volume> <editor> IM-34, n. </editor> <volume> 3, </volume> <pages> pp. 442-449, </pages> <month> September </month> <year> 1985. </year>
Reference-contexts: Wey and Saeks represent a circuit as a set of decoupled state machines together with algebraic connection equations. Using this model they simulate all possible single and double catastrophic faults, and have developed an automatic test pattern generation method for circuits with both linear <ref> [152] </ref> and nonlinear [153] input/output transfer functions. Marlett developed a path sensitization method which can be used for DC test generation using a resistive shunt model [72]. Naiknaware published a similar idea which can be used hierarchically. A test model is stored with each generic block in a cell library.
Reference: [153] <author> C.-L. Wey and R. Saeks, </author> <title> "On the Implementation of an Analog ATPG: the Nonlinear Case," </title> <journal> IEEE Trans. on Instrumentation and Measurement, </journal> <volume> vol. 37, </volume> <editor> n. </editor> <volume> 2, </volume> <pages> pp. 252-258, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Wey and Saeks represent a circuit as a set of decoupled state machines together with algebraic connection equations. Using this model they simulate all possible single and double catastrophic faults, and have developed an automatic test pattern generation method for circuits with both linear [152] and nonlinear <ref> [153] </ref> input/output transfer functions. Marlett developed a path sensitization method which can be used for DC test generation using a resistive shunt model [72]. Naiknaware published a similar idea which can be used hierarchically. A test model is stored with each generic block in a cell library.
Reference: [154] <author> T.D. Wickens, </author> <title> The Geometry of Multivariate Statistics, </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, New Jersey, </address> <year> 1995. </year>
Reference-contexts: Principal component analysis (PCA) or principal factor analysis (PFA) can be used to extract the statistically relevant combinations of parameters and thereby reduce the number of lower-level parameters which must be considered <ref> [154, 55] </ref>. Given a set of model cards which have been extracted from fabricated devices, Spayn [130] is a commercial tool which performs PCA and PFA.
Reference: [155] <author> L.A. Williams and B.A. Wooley, </author> <title> "MIDAS|A Functional Simulator for Mixed Digital and Analog Sampled Data Systems," </title> <booktitle> Proc. IEEE International Symposium on Circuits and Systems, </booktitle> <volume> vol. 5, </volume> <pages> pp. 2148-2151, </pages> <year> 1992. </year>
Reference-contexts: The high-level performances represent circuit performance specifications, such as signal-to-noise ratio of an analog-to-digital converter. A circuit simulator such as Spice [57] is used to simulate the intermediate-level parameters as functions of the low-level parameters, and a behavioral-level simulator such as Midas <ref> [155] </ref> is used to simulate the high-level performances as functions of the intermediate-level parameters. In this hierarchical design methodology, two statistical characterizations are performed. First, the statistical distributions of the intermediate-level parameters are calculated from those of the low-level parameters.
Reference: [156] <author> T.W. Williams and K.P. Parker, </author> <title> "Design for Testability|A Survey," </title> <journal> Proc. of the IEEE, </journal> <volume> vol. 71, </volume> <editor> n. </editor> <volume> 1, </volume> <pages> pp. 98-112, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: A useful survey of the most common design for testability techniques for analog and mixed-signal circuits can be found in <ref> [156] </ref>. Rijsinge proposed a statistical approach; he evaluates the number of test vectors required to measure a given parameter with a specified accuracy [144]. The technique is geared more toward fault diagnosis than production testing, but the testing applications are evident.
Reference: [157] <author> B.W. Woodall, B.D. Newman and A.G. Saumuli, </author> <title> "Empirical Results of Undetected Stuck-Open Failures," </title> <booktitle> Proc. IEEE International Test Conference, </booktitle> <pages> pp. 166-170, </pages> <month> September </month> <year> 1987. </year>
Reference-contexts: Daugherty presented the basic concepts of analog fault simulation in [26]. Early work was based on experimental manufacturing defect statistics and showed that open faults and bridging faults are the most frequent catastrophic fault types <ref> [70, 148, 157] </ref>. Soma and Meixner developed analog fault models by performing Monte-Carlo defect simulations [124, 75]. Meixner models faulty analog behavior as modifications to the nominal macromodel. Nagi published some results on fault modeling for both catastrophic and parametric AC and DC faults in passive and active components [84].
Reference: [158] <author> P. Yang, D. Hocevar, P. Cox, C. Machala and P. Chatterjee, </author> <title> "An Integrated and Efficient Approach for MOS VLSI Statistical Circuit Design," </title> <journal> IEEE Trans. on Computer-Aided Design of Integrated Circuits and Systems, </journal> <volume> vol. CAD-5, </volume> <pages> pp. 5-14, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: These contributions improve the efficiency and accuracy of statistical circuit characterization. 6.2 Parameter Mismatch and Correlation Most MOS models are characterized by a relatively large number of parameters, only a few of which are statistically independent <ref> [158] </ref>. Principal component analysis (PCA) or principal factor analysis (PFA) can be used to extract the statistically relevant combinations of parameters and thereby reduce the number of lower-level parameters which must be considered [154, 55].
References-found: 158

