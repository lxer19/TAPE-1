URL: ftp://ic.eecs.berkeley.edu/pub/Papers_Talks/Analog_Group/PostScript/ICCAD94_felt.ps.Z
Refering-URL: http://www-cad.eecs.berkeley.edu:80/~charbon/publications/analog-group-publications.html
Root-URL: http://www.cs.berkeley.edu
Title: Testing of Analog Systems Using Behavioral Models and Optimal Experimental Design Techniques  
Author: Eric Felt Alberto Sangiovanni-Vincentelli 
Address: Berkeley, CA 94720  
Affiliation: Department of Electrical Engineering and Computer Sciences University of California,  
Abstract: This paper describesa new CAD algorithm which performs automatic test pattern generation (ATPG) for a general class of analog systems, namely those circuits which can be efficiently modeled as an additive combination of user-defined basis functions. The algorithm is based on the statistical technique of I-optimal experimental design, in which test vectors are chosen to be maximally independent so that circuit performance will be characterized as accurately as possible in the presence of measurement noise and model inaccuracies. This technique allows analog systems to be characterized more accurately and more efficiently, thereby significantly reducing system test time and hence total manufacturing cost. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Bonet, J. Ganger, J. Girardeu, C. Greaves, M. Pendelton and D. Yatim, </author> <title> Test features of the MC145472 ISDN U-transceiver, </title> <booktitle> Proc. 1990 International Test Conf., </booktitle> <pages> pp. 68-79, </pages> <year> 1990. </year>
Reference-contexts: This test suite frequently defaults to the complete set of circuit specifications. This approach is becoming increasingly expensive in both test development and test execution times. The specifications of mixed analog-digital circuits are usually very large (e.g. see <ref> [1] </ref>), which not only results in long manual test development, but also in prohibitive testing times on very expensive automated test equipment (ATE) with mixed-signal capabilities; it is estimated that testing currently accounts for 30% of total manufacturing cost [2].
Reference: [2] <institution> Semiconductor Industry Technology Workshop Conclusions, Semiconductor Industry Association, </institution> <year> 1993. </year>
Reference-contexts: specifications of mixed analog-digital circuits are usually very large (e.g. see [1]), which not only results in long manual test development, but also in prohibitive testing times on very expensive automated test equipment (ATE) with mixed-signal capabilities; it is estimated that testing currently accounts for 30% of total manufacturing cost <ref> [2] </ref>. Furthermore, the use of sophisticated CAD tools has reduced the design cycle so that the influence of testing on time-to-market and final cost of the circuit is increasingly significant. For these reasons, analog testing is considered to be one of the most important problems in analog and mixed-signal design.
Reference: [3] <author> M. H. Schultz, E. Trischler and T. M. Sarfert, SOCRATES: </author> <title> a highly efficient automatic test pattern generationsystem, </title> <journal> IEEE Trans. on CAD, </journal> <volume> vol. Vol. 7,No. 1, </volume> <pages> pp. 126-137, </pages> <year> 1988. </year>
Reference-contexts: we discuss some new CAD techniques which have been developed and implemented for finding these good test sets. 3 Previous Work Most of the previous work in ATPG for electrical systems has been directed at digital circuits, and efficient techniques have been developed for both combinational and sequential digital systems <ref> [3, 4] </ref>. These test systems are based on the common single stuck-at-0/stuck-at-1 fault model and the controllability and observability of each fault. Unfortunately most of these ideas cannot be directly applied to analog systems.
Reference: [4] <author> A. Ghosh, S. Devadas and A. Richard Newton, </author> <title> Sequential Logic Testing and Verification, </title> <publisher> Kluwer, </publisher> <address> Boston, </address> <year> 1992. </year>
Reference-contexts: we discuss some new CAD techniques which have been developed and implemented for finding these good test sets. 3 Previous Work Most of the previous work in ATPG for electrical systems has been directed at digital circuits, and efficient techniques have been developed for both combinational and sequential digital systems <ref> [3, 4] </ref>. These test systems are based on the common single stuck-at-0/stuck-at-1 fault model and the controllability and observability of each fault. Unfortunately most of these ideas cannot be directly applied to analog systems.
Reference: [5] <author> G. Stenbakken and T. Souders, </author> <title> Test-Point Selection and Testability Measures via QR Factorizationof Linear Models, </title> <journal> IEEE Transactions on Instrumentation and Measurement, </journal> <month> June </month> <year> 1987. </year>
Reference-contexts: In the area of analog testing, work has been done in system modeling and test ordering, both of which are useful toward the goal of reducing testing time. In the area of system modeling, Sounders and Stenbakken proposed using linear models, which can be derived either from simulation <ref> [5] </ref> or from manufacturing data [6] using QR decomposition. In the area of test ordering, Milor has described an algorithm for minimizing average test time by ordering tests in such a way that the tests which are most likely to detect faults are performed first [7].
Reference: [6] <author> T. Souders and G. Stenbakken, </author> <title> Cutting the high cost of testing, </title> <journal> IEEE Spectrum, </journal> <pages> pp. 48-51, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: In the area of system modeling, Sounders and Stenbakken proposed using linear models, which can be derived either from simulation [5] or from manufacturing data <ref> [6] </ref> using QR decomposition. In the area of test ordering, Milor has described an algorithm for minimizing average test time by ordering tests in such a way that the tests which are most likely to detect faults are performed first [7].
Reference: [7] <author> L. Milor and A. L. Sangiovanni-Vincentelli, </author> <title> Minimizing production test time to detect faults in analog circuits, </title> <journal> IEEE Trans. on CAD, </journal> <volume> vol. Vol. 13,No. 6, </volume> <pages> pp. 796-813, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: In the area of test ordering, Milor has described an algorithm for minimizing average test time by ordering tests in such a way that the tests which are most likely to detect faults are performed first <ref> [7] </ref>. In this paper we assume that a suitable linear behavioral model for the system exists (or can be easily derived from sensitivity analysis), and we focus on a new optimization algorithm for selecting the best set of test vectors.
Reference: [8] <author> J. Kiefer, </author> <title> Collected Papers III: Design of Experiments, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Run the I-optimality algorithm to select best additional vectors, one at a time, for use if the prior tests are not conclusive. 4.1 Optimality Criteria There are several different optimality criteria (A-, D-, E-, G-, and I-), the relative merits of which have been debated extensively in the relevant literature <ref> [8, 9] </ref>. D-optimality, which is generally considered to be the simplest type of optimality, minimizes the average prediction variance of the model coefficients.
Reference: [9] <author> G. E. P. Box and N. R. Draper, </author> <title> Empirical Model-Building and Response Surfaces, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Run the I-optimality algorithm to select best additional vectors, one at a time, for use if the prior tests are not conclusive. 4.1 Optimality Criteria There are several different optimality criteria (A-, D-, E-, G-, and I-), the relative merits of which have been debated extensively in the relevant literature <ref> [8, 9] </ref>. D-optimality, which is generally considered to be the simplest type of optimality, minimizes the average prediction variance of the model coefficients. <p> M X = n T and the prediction variance at an arbitrary point x on the response surface is var y (x) = n 1 T An I-optimal design is one which minimizes the average of this variance over the response surface R I = 2 R This integral simplifies <ref> [9] </ref> to give I = tracefM M 1 where M is the moment matrix of the region of interest R. M = R T 4.2 Optimization Finding an exactly I-optimal design is believed to be NP-complete [10] and hence only feasible for very small problems.
Reference: [10] <author> S. B. Crary, </author> <title> Optimal design of experimentsfor sensor calibration, </title> <booktitle> Proc. IEEE International Conference on Solid-State Sensors and Actuators, </booktitle> <pages> pp. 404-407, </pages> <year> 1991. </year>
Reference-contexts: M = R T 4.2 Optimization Finding an exactly I-optimal design is believed to be NP-complete <ref> [10] </ref> and hence only feasible for very small problems. For larger problems, several heuristic algorithms have been successfully used to find good solutions to this and other related problems in the area of optimal experimental design. These heuristic algorithms include simulated annealing [10], greedy swap techniques [11], and gradient descent techniques. <p> exactly I-optimal design is believed to be NP-complete <ref> [10] </ref> and hence only feasible for very small problems. For larger problems, several heuristic algorithms have been successfully used to find good solutions to this and other related problems in the area of optimal experimental design. These heuristic algorithms include simulated annealing [10], greedy swap techniques [11], and gradient descent techniques. For this research we used the gradient descent techniques implemented in the software package gosset, which was recently developed by Hardin and Sloane at AT&T Bell Laboratories [12].
Reference: [11] <author> N. K. Nguyen and A. J. Miller, </author> <title> A review of some exchange algorithms for constructing discrete D-optimal designs, </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> vol. Vol. 14, </volume> <pages> pp. 489-498, </pages> <year> 1992. </year>
Reference-contexts: For larger problems, several heuristic algorithms have been successfully used to find good solutions to this and other related problems in the area of optimal experimental design. These heuristic algorithms include simulated annealing [10], greedy swap techniques <ref> [11] </ref>, and gradient descent techniques. For this research we used the gradient descent techniques implemented in the software package gosset, which was recently developed by Hardin and Sloane at AT&T Bell Laboratories [12].
Reference: [12] <author> R. H. Hardin and N. J. A. Sloane, </author> <title> A new approach to the construction of optimal designs, </title> <journal> Journal of Statistical Planning and Inference, </journal> <volume> vol. Vol. 37, </volume> <pages> pp. 339-369, </pages> <year> 1993. </year>
Reference-contexts: These heuristic algorithms include simulated annealing [10], greedy swap techniques [11], and gradient descent techniques. For this research we used the gradient descent techniques implemented in the software package gosset, which was recently developed by Hardin and Sloane at AT&T Bell Laboratories <ref> [12] </ref>. The primary focus of gosset is low-order polynomial models, which are of only limited use in characterizing typical analog circuits. For this research, therefore, gosset was extended to utilize arbitrary Lipschitz continuous functions, such as the piecewise linear output of common behavioral simulators [13] and SPICE [14].
Reference: [13] <author> E. Liu, A. Sangiovanni-Vincentelli, G. Gielen and P. Gray, </author> <title> A behavioral representation for nyquist rate A/D converters, </title> <booktitle> in Proc. IEEE ICCAD, </booktitle> <pages> pp. 386-389, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: The primary focus of gosset is low-order polynomial models, which are of only limited use in characterizing typical analog circuits. For this research, therefore, gosset was extended to utilize arbitrary Lipschitz continuous functions, such as the piecewise linear output of common behavioral simulators <ref> [13] </ref> and SPICE [14]. <p> The second is a single MOS transistor, which was analyzed in SPICE with a level three transistor model. The third is a 6-bit Nyquist-rate D/A converter which was analyzed using explicit behavioral equations <ref> [13] </ref>. 6.1 Bandpass Filter functions we select the constant function, the nominal frequency response, and the sensitivities of the nominal response with respect to R 1 , C 1 , R 2 , C 2 , R 3 , R 4 , and R 5 .
Reference: [14] <author> A. Vladimirescu, A. R. Newton and D. O. Pederson, </author> <note> SPICE Version 2G.1 User's Guide, </note> <institution> Dept. of Electrical Engineering and Computer Sciences, Univ. of California, Berkeley, </institution> <address> CA, </address> <year> 1980. </year>
Reference-contexts: The primary focus of gosset is low-order polynomial models, which are of only limited use in characterizing typical analog circuits. For this research, therefore, gosset was extended to utilize arbitrary Lipschitz continuous functions, such as the piecewise linear output of common behavioral simulators [13] and SPICE <ref> [14] </ref>. Gosset uses an optimization algorithm known as Hooke and Jeeves pattern search [15], which is based on the idea of finding a valley and following it downward until reaching the lowest point on the response surface, similar to the manner in which a stream flows down a mountain.
Reference: [15] <author> R. Hooke and T. A. Jeeves, </author> <title> `Direct Search' solution of numerical and stastical problems, </title> <journal> J. Assoc. Comp. Machinery, </journal> <volume> vol. Vol. 8, </volume> <pages> pp. 212-229, </pages> <year> 1961. </year>
Reference-contexts: For this research, therefore, gosset was extended to utilize arbitrary Lipschitz continuous functions, such as the piecewise linear output of common behavioral simulators [13] and SPICE [14]. Gosset uses an optimization algorithm known as Hooke and Jeeves pattern search <ref> [15] </ref>, which is based on the idea of finding a valley and following it downward until reaching the lowest point on the response surface, similar to the manner in which a stream flows down a mountain.
Reference: [16] <author> G. N. Stenbakken and T. M. Sounders, </author> <title> Linear error modeling of analog and mixed-signaldevices, </title> <booktitle> Proc. IEEE InternationalTest Converence, </booktitle> <pages> pp. 573-581, </pages> <year> 1991. </year>
Reference-contexts: We wish to estimate f (a + x). A first-order Taylor series approximation is a reasonably accurate model for many common analog systems with parameters that do not deviate significantly from their nominal values. This is the model used by Stenbakken and Sounders <ref> [16] </ref>, and our discussion of it here will be brief.
Reference: [17] <author> E. W. Y. Liu, W. Kao, E. Felt and A. L. Sangiovanni-Vincentelli, </author> <title> Analog testability analysis and fault diagnosis using behavioral modeling, </title> <booktitle> Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <year> 1994. </year>
Reference-contexts: A component i belongs to an ambiguity group if and only if row i of N has a non-zero entry. Furthermore, components i and j are in the same ambiguity group if rows i and j of N are non-zero and not orthogonal to each other <ref> [17] </ref>. It follows that the components fall into the same group if their corresponding row vectors of N are non-zero and not orthogonal. The null space of U can be computed using singular value decomposition (SVD) or Gaussian elimination.
Reference: [18] <author> T. M. Sounders and G. N. Stenbakken, </author> <title> A comprehensive approach for modeling and testing analog and mixed-signal devices, </title> <booktitle> Proc. IEEE International Test Converence, </booktitle> <pages> pp. 169-174, </pages> <year> 1990. </year>
Reference-contexts: The first is a bandpassfilter with center frequency of 24.5 kHz <ref> [18] </ref>, which was analyzed using SPICE sensitivity analysis. The second is a single MOS transistor, which was analyzed in SPICE with a level three transistor model.
References-found: 18

