URL: http://theory.lcs.mit.edu/~strumpen/MIT-LCS-TM-580.ps.gz
Refering-URL: http://theory.lcs.mit.edu/~strumpen/
Root-URL: 
Email: strumpen@supertech.lcs.mit.edu  
Title: Indolent Closure Creation  
Author: Volker Strumpen 
Affiliation: Laboratory for Computer Science of the Massachusetts Institute of Technology  
Address: New Haven,  
Note: This manuscript contains extended notes of a talk entitled Indolent Closure Creation, held by the author at the Yale Multithreaded Programming Workshop in  This manuscript describes research pursued at the  as part of the Cilk Project. Funding for this work has been provided in part by DARPA Grant N00014-94-1-0985.  
Date: June 24, 1998  June 89, 1998.  
Pubnum: Technical Memo MIT-LCS-TM-580  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> R. Alverson, D. Callahan, D. Cummings, B. Koblenz, A. Porterfield, and B. Smith. </author> <title> The Tera Com puter System. </title> <booktitle> In 4th ACM International Conference on Supercomputing, </booktitle> <pages> pages 16, </pages> <address> Amsterdam, The Netherlands, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: But a Stack is Faster. fl This manuscript is an extended version of a talk entitled Indolent Closure Creation, which I gave at the Yale Multithreaded Programming Workshop in New Haven, June 89, 1998. 1 Implementing multithreading in an efficient manner has lead to a variety of proposed multithreaded architectures <ref> [1, 6, 16, 19] </ref>. Efficient software implementations have been proposed for commodity architectures that introduce a compromise between stack and heap allocation techniques. For example, Lazy Threads [8] are based on stacklets, and the Illinois Concert system [9] employs a hybrid stack-heap execution mechanism.
Reference: [2] <author> Andrew W. Appel. </author> <title> Garbage Collection Can Be Faster than Stack Allocation. </title> <journal> Information Processing Letters, </journal> <volume> 25(4):275279, </volume> <month> June </month> <year> 1987. </year>
Reference-contexts: Today, procedure optimizations such as function inlining, leaf-routine optimization and tail-recursion elimination are ubiquitous in modern compilers, and structured programming has prevailed. When garbage collection became popular, the well-established stack abstraction has been questioned by Appel in an article <ref> [2] </ref> entitled Garbage Collection Can Be Fater Than Stack Allocation.
Reference: [3] <author> Robert D. Blumofe, Matteo Frigo, Christopher F. Joerg, Charles E. Leiserson, and Keith H. Randall. </author> <title> Dag-Consistent Distributed Shared Memory. </title> <booktitle> In 10th International Parallel Processing Symposium, </booktitle> <pages> pages 132141, </pages> <address> Honolulu, Hawaii, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: Under this condition, the performance guarantees of the work-stealing scheduler should be effectively unchanged, and the performance of a Cilk computation should be unaffected. The theoretical aspects of scheduling as well as experimental validation are subject to future work. DAG-Consistent Shared Memory When implementing Cilk with DAG-consistent shared memory <ref> [3] </ref>, for example on a symmetric multiprocessor (SMP), the question arises whether indolent closure creation can be implemented without restricting the full range of language features supported by Cilk. In particular, pointers passed by reference appear to be problematic.
Reference: [4] <author> Robert D. Blumofe and Charles E. Leiserson. </author> <title> Scheduling Multithreaded Computations by Work Steal ing. </title> <booktitle> In 35th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 356368, </pages> <address> Santa Fe, New Mexico, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: If a Cilk program is executed on one processor, the semantics of the parallel spawn is equivalent to that of a conventional function call. A statement containing the sync keyword acts like a local barrier to synchronize the parent with its spawned children. Cilk's randomized work-stealing scheduler <ref> [4] </ref> schedules the parent and its spawned children across the processors of a parallel machine in a provably efficient manner. An idling processor becomes a thief that picks a victim processor at random and attempts to steal work. A Cilk computation is characterized by its work and its critical-path length. <p> The latter lower bound is imposed by the structure of the computation, which requires at least the number of steps dictated by the critical path length. Blumofe and Leiserson <ref> [4] </ref> have shown that Cilk's randomized work-stealing scheduler executes a Cilk computation in expected time T P = T 1 =P + O (T 1 ). The work-first principle is based on the analysis of the expected parallel execution time, as described in [7]. <p> The key insight underlying Cilk's randomized work-stealing scheduler <ref> [4] </ref> is that the number of steals O (P T 1 ) is substantially smaller than the number of spawn operations.
Reference: [5] <author> David E. Culler, Seth C. Goldstein, Klaus E. Schauser, and Thorsten von Eicken. </author> <title> TAMA Compiler Controlled Threaded Abstract Machine. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 18(3):347 370, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: I discuss only a subset of them and refer the reader to the papers cited therein. Both papers [8] and [9] discuss a large body of related work. Lazy Threads [8] extend the work on the Threaded Abstract Machine (TAM) <ref> [5] </ref>, a compilation target for parallel nonstrict functional languages. Lazy Threads are based on compiler support which implements customized memory management of activation frames with so-called stacklets. <p> The paper [8] introduces a classification of different closure representations that allows the compiler to select the appropriate representation for particular instantiations. The Fibonacci computation is used in <ref> [5, 8] </ref> to illustrate the proposed mechanisms. The Illinois Concert system [9] employs a customized compiler to reduce the cost of thread management by means of a hybrid stack-heap execution mechanism.
Reference: [6] <author> Susan J. Eggers, Joel S. Emer, Henry M. Levy, Jack L. Lo, Rebecca L. Stamm, and Dean M. Tullsen. </author> <title> Simultaneous Multithreading: A Platform for Next-Generation Processors. </title> <booktitle> IEEE Micro, </booktitle> <pages> pages 1219, </pages> <month> September/October </month> <year> 1997. </year>
Reference-contexts: But a Stack is Faster. fl This manuscript is an extended version of a talk entitled Indolent Closure Creation, which I gave at the Yale Multithreaded Programming Workshop in New Haven, June 89, 1998. 1 Implementing multithreading in an efficient manner has lead to a variety of proposed multithreaded architectures <ref> [1, 6, 16, 19] </ref>. Efficient software implementations have been proposed for commodity architectures that introduce a compromise between stack and heap allocation techniques. For example, Lazy Threads [8] are based on stacklets, and the Illinois Concert system [9] employs a hybrid stack-heap execution mechanism.
Reference: [7] <author> Matteo Frigo, Charles E. Leiserson, and Keith H. Randall. </author> <booktitle> The Implementation of the Cilk-5 Mul tithreaded Language. In Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 212223, </pages> <address> Montreal, Canada, </address> <month> June </month> <year> 1998. </year> <journal> ACM SIGPLAN. </journal>
Reference-contexts: Efficient software implementations have been proposed for commodity architectures that introduce a compromise between stack and heap allocation techniques. For example, Lazy Threads [8] are based on stacklets, and the Illinois Concert system [9] employs a hybrid stack-heap execution mechanism. The multithreaded Cilk language <ref> [7] </ref> exhibits a striking balance between versatility of threads, portability, and efficiency. Cilk's implementation is based on the cactus stack semantics proposed by Moses in 1970 [12]. <p> Related work is sketched in Section 6, and conclusions for future work are drawn in Section 7. 2 Cilk and the Work-First Principle The idea of indolent closures has been motivated by the work-first principle that underlies the implementation of the Cilk language. Cilk extends the C programming language <ref> [7] </ref> into an algorithmic multithreaded language. In Cilk, parallelism is exposed explicitly by means of the spawn and sync keywords. If the spawn keyword precedes the call of a procedure, the calling parent can continue execution in parallel with the called child. <p> Blumofe and Leiserson [4] have shown that Cilk's randomized work-stealing scheduler executes a Cilk computation in expected time T P = T 1 =P + O (T 1 ). The work-first principle is based on the analysis of the expected parallel execution time, as described in <ref> [7] </ref>. An upper bound on T P is given by the critical-path overhead, which is defined as the smallest constant c 1 such that T P T 1 =P + c 1 T 1 . <p> The Cilk language preserves the C semantics of function calls whenever a spawn is executed. There is a difference, however. Before actually calling the spawned procedure, a closure is pushed onto the ready 4 deque <ref> [7] </ref>. Figure 3 shows the ready deque of the victim, which holds closures for all activation frames corresponding to procedure invocations from fib (n) to fib (2). The base case fib (1) does not spawn further invocations. Closures are drawn next to their activation frames. <p> The overhead of the indolent version is shown with respect to the C version. Also included are the corresponding overheads of the Cilk-5 implementation on one processor from <ref> [7, Figure 7] </ref>. For the Pentium, the measurement of the Cilk overhead has been performed on a 200 MHz processor, whereas those of the fast clone of the indolent version were run on a 120 MHz processor. <p> This is roughly the case for all architectures except the MIPS and the UltraSparc processors. For the latter, the effect of the sedative optimization is hardly recognizable. On the MIPS processor, the parallel spawn is even faster than the sequential function call. 6 Related Work The implementation of Cilk-5 <ref> [7] </ref> has been motivating the work on indolent closure creation. Currently, I view indolent closure creation as an optimization for implementations of Cilk.
Reference: [8] <author> Seth C. Goldstein, Klaus E. Schauser, and David E. Culler. </author> <title> Lazy Threads: Impementing a Fast Parallel Call. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 37(1):520, </volume> <month> August </month> <year> 1996. </year>
Reference-contexts: Efficient software implementations have been proposed for commodity architectures that introduce a compromise between stack and heap allocation techniques. For example, Lazy Threads <ref> [8] </ref> are based on stacklets, and the Illinois Concert system [9] employs a hybrid stack-heap execution mechanism. The multithreaded Cilk language [7] exhibits a striking balance between versatility of threads, portability, and efficiency. Cilk's implementation is based on the cactus stack semantics proposed by Moses in 1970 [12]. <p> A comprehensive discussion of the information necessary to be stored in a closure can be found in <ref> [8] </ref>. Two design goals guided the work presented in this memo: 1. <p> Such fine-grained threads must be created with minimal overhead at runtime in order to execute efficiently. Portability excludes implementations that modify a compiler in order to provide a customized stack layout, and customized manipulation of the stack pointer and frame pointer, as done for Lazy Threads <ref> [8] </ref>. Instead, indolent closures rely on source-to-source compilation to enable machine independence. We deploy the porch compiler technology for portable checkpointing [18] to that end. <p> A variety of approaches to low-overhead implementations of multithreaded languages have been studied on commodity computers. I discuss only a subset of them and refer the reader to the papers cited therein. Both papers <ref> [8] </ref> and [9] discuss a large body of related work. Lazy Threads [8] extend the work on the Threaded Abstract Machine (TAM) [5], a compilation target for parallel nonstrict functional languages. Lazy Threads are based on compiler support which implements customized memory management of activation frames with so-called stacklets. <p> A variety of approaches to low-overhead implementations of multithreaded languages have been studied on commodity computers. I discuss only a subset of them and refer the reader to the papers cited therein. Both papers <ref> [8] </ref> and [9] discuss a large body of related work. Lazy Threads [8] extend the work on the Threaded Abstract Machine (TAM) [5], a compilation target for parallel nonstrict functional languages. Lazy Threads are based on compiler support which implements customized memory management of activation frames with so-called stacklets. <p> Lazy Threads are based on compiler support which implements customized memory management of activation frames with so-called stacklets. This customization enables a more general handling of frames in the context of non-strict languages than required by the semantics of a sequential call. The paper <ref> [8] </ref> introduces a classification of different closure representations that allows the compiler to select the appropriate representation for particular instantiations. The Fibonacci computation is used in [5, 8] to illustrate the proposed mechanisms. <p> The paper [8] introduces a classification of different closure representations that allows the compiler to select the appropriate representation for particular instantiations. The Fibonacci computation is used in <ref> [5, 8] </ref> to illustrate the proposed mechanisms. The Illinois Concert system [9] employs a customized compiler to reduce the cost of thread management by means of a hybrid stack-heap execution mechanism.
Reference: [9] <author> Vijay Karamacheti, John Plevyak, and Andrew A. Chien. </author> <title> Runtime Mechanisms for Efficient Dynamic Multithreading. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 37(1):2140, </volume> <month> August </month> <year> 1996. </year>
Reference-contexts: Efficient software implementations have been proposed for commodity architectures that introduce a compromise between stack and heap allocation techniques. For example, Lazy Threads [8] are based on stacklets, and the Illinois Concert system <ref> [9] </ref> employs a hybrid stack-heap execution mechanism. The multithreaded Cilk language [7] exhibits a striking balance between versatility of threads, portability, and efficiency. Cilk's implementation is based on the cactus stack semantics proposed by Moses in 1970 [12]. <p> A variety of approaches to low-overhead implementations of multithreaded languages have been studied on commodity computers. I discuss only a subset of them and refer the reader to the papers cited therein. Both papers [8] and <ref> [9] </ref> discuss a large body of related work. Lazy Threads [8] extend the work on the Threaded Abstract Machine (TAM) [5], a compilation target for parallel nonstrict functional languages. Lazy Threads are based on compiler support which implements customized memory management of activation frames with so-called stacklets. <p> The paper [8] introduces a classification of different closure representations that allows the compiler to select the appropriate representation for particular instantiations. The Fibonacci computation is used in [5, 8] to illustrate the proposed mechanisms. The Illinois Concert system <ref> [9] </ref> employs a customized compiler to reduce the cost of thread management by means of a hybrid stack-heap execution mechanism. Similar to Cilk, the compiler generates two clones for each thread body, one of which executes off a stack-allocated activation frame, and the other from a heap-allocated context.
Reference: [10] <author> James S. Miller and Guillermo J. Rozas. </author> <title> Garbage Collection is Fast, But a Stack is Faster. </title> <journal> MIT Artificial Intelligence Laboratory, </journal> <volume> AI memo 1462, </volume> <month> March </month> <year> 1994. </year>
Reference-contexts: When garbage collection became popular, the well-established stack abstraction has been questioned by Appel in an article [2] entitled Garbage Collection Can Be Fater Than Stack Allocation. In response, Miller and Rozas <ref> [10] </ref> claimed that Garbage Collection is Fast, But a Stack is Faster. fl This manuscript is an extended version of a talk entitled Indolent Closure Creation, which I gave at the Yale Multithreaded Programming Workshop in New Haven, June 89, 1998. 1 Implementing multithreading in an efficient manner has lead to
Reference: [11] <author> Eric Mohr, David A. Kranz, and Jr. Robert H. Halstead. </author> <title> Lazy Task Creation: A Technique for Increas ing the Granularity of Parallel Programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3):264280, </volume> <month> July </month> <year> 1991. </year>
Reference-contexts: Currently, I view indolent closure creation as an optimization for implementations of Cilk. It would be interesting 16 to investigate whether indolent closure creation could be applied to parallel functional languages such as Mul-T <ref> [11] </ref>, Id [13], or the parallel Haskell dialect pH [14]. A variety of approaches to low-overhead implementations of multithreaded languages have been studied on commodity computers. I discuss only a subset of them and refer the reader to the papers cited therein.
Reference: [12] <author> Joel Moses. </author> <title> The Funtion of FUNCTION in LISP, or Why the FUNARG Problem Should be Called the Environment Problem. </title> <journal> MIT Artificial Intelligence Laboratory, </journal> <volume> AI memo 199, </volume> <month> June </month> <year> 1970. </year>
Reference-contexts: The multithreaded Cilk language [7] exhibits a striking balance between versatility of threads, portability, and efficiency. Cilk's implementation is based on the cactus stack semantics proposed by Moses in 1970 <ref> [12] </ref>. As operating systems and compilers are turning into commodity components, it is desirable to implement multithreading in a portable manner, that is independent of processor architecture, operating system and compiler.
Reference: [13] <author> Rishiyur S. Nikhil. </author> <title> A Multithreaded Implementation of Id using P-RISC Graphs. </title> <editor> In U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, </booktitle> <volume> LNCS 768, </volume> <pages> pages 390405, </pages> <address> Portland, Oregon, August 1993. </address> <publisher> Springer Verlag. </publisher> <pages> 18 </pages>
Reference-contexts: Currently, I view indolent closure creation as an optimization for implementations of Cilk. It would be interesting 16 to investigate whether indolent closure creation could be applied to parallel functional languages such as Mul-T [11], Id <ref> [13] </ref>, or the parallel Haskell dialect pH [14]. A variety of approaches to low-overhead implementations of multithreaded languages have been studied on commodity computers. I discuss only a subset of them and refer the reader to the papers cited therein.
Reference: [14] <author> Rishiyur S. Nikhil, Arvind, James Hicks, Shail Aditya, Lennart Augustsson, Jan-Willem Maessen, and Yuli Zhou. </author> <title> pH Language Reference Manual. MIT Computation Structures Group, </title> <type> CSG memo 369, </type> <month> January </month> <year> 1995. </year>
Reference-contexts: Currently, I view indolent closure creation as an optimization for implementations of Cilk. It would be interesting 16 to investigate whether indolent closure creation could be applied to parallel functional languages such as Mul-T [11], Id [13], or the parallel Haskell dialect pH <ref> [14] </ref>. A variety of approaches to low-overhead implementations of multithreaded languages have been studied on commodity computers. I discuss only a subset of them and refer the reader to the papers cited therein. Both papers [8] and [9] discuss a large body of related work.
Reference: [15] <author> Balkrishna Ramkumar and Volker Strumpen. </author> <title> Portable Checkpointing for Heterogeneous Architec tures. </title> <booktitle> In Digest of Papers27th International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 5867, </pages> <address> Seattle, Washington, June 1997. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: Before introducing indolent closure creation, I describe the portable checkpoint compiler porch. The method for providing a portable stack environment employed by porch is the basic implementation technique underlying indolent closure creation. 3 Porch and Stack Environment Portability The porch compiler <ref> [15, 18] </ref> is a source-to-source compiler that translates C programs into semantically equivalent C programs additionally capable of saving and recovering from portable checkpoints. Portable checkpoints capture the state of a computation in a machine-independent format, called Universal Checkpoint FormatUCF. <p> As all other local variables, callid is saved and restored. The instrumentation of save and restore code consists of push and pop operations on a shadow stack, whereby local variables are accessed by name. A description of the save and restore code generation can be found in <ref> [15] </ref>. Note that recovery involves no more than resuming the functions on the runtime stack. Several code transformations are required prior to the release-and-resume instrumentation that are not elaborated here.
Reference: [16] <author> Gurindar S. Sohi, Scott E. </author> <title> Breach, </title> <booktitle> and T.N. Vijaykumar. Multiscalar Processors. In 22nd International Symposium on Computer Architecture, </booktitle> <pages> pages 414425, </pages> <address> Santa Margherita Ligure, Italy, </address> <year> 1995. </year>
Reference-contexts: But a Stack is Faster. fl This manuscript is an extended version of a talk entitled Indolent Closure Creation, which I gave at the Yale Multithreaded Programming Workshop in New Haven, June 89, 1998. 1 Implementing multithreading in an efficient manner has lead to a variety of proposed multithreaded architectures <ref> [1, 6, 16, 19] </ref>. Efficient software implementations have been proposed for commodity architectures that introduce a compromise between stack and heap allocation techniques. For example, Lazy Threads [8] are based on stacklets, and the Illinois Concert system [9] employs a hybrid stack-heap execution mechanism.
Reference: [17] <author> Guy L. Steele, Jr. </author> <title> Debunking the Expensive Procedure Call Myth or, Procedure Call Implementa tions Considered Harmful or, Lambda: The Ultimate GOTO. </title> <journal> MIT Artificial Intelligence Laboratory, </journal> <volume> AI memo 443, </volume> <month> October </month> <year> 1977. </year>
Reference-contexts: This memo proposes an optimization for a key issue in implementing portable multithreaded languages efficiently: How to minimize the overhead of generating parallelism. The question whether an abstraction can be implemented efficiently has been subject to flamy appeals in the past. In 1977, Steele <ref> [17, p. 16] </ref> advocated the procedure call: Procedure calls are demonstrably not inherently as inefficient as computing folklore would lead us to believe. There are implementations of higher-level programming languages in which procedure calls are almost as cheap as GOTO statements.
Reference: [18] <author> Volker Strumpen. </author> <title> Compiler Technology for Portable Checkpoints. </title> <note> submitted for publication (http://theory.lcs. mit.edu/strumpen/porch.ps.gz), </note> <year> 1998. </year>
Reference-contexts: Instead, indolent closures rely on source-to-source compilation to enable machine independence. We deploy the porch compiler technology for portable checkpointing <ref> [18] </ref> to that end. In general, coarse-grained threads do not require a very fast creation mechanism, because the execution time of coarse-grained threads will amortize the cost of thread creation. Indolent closure creation has been investigated in the context of the Cilk multithreaded language. <p> Before introducing indolent closure creation, I describe the portable checkpoint compiler porch. The method for providing a portable stack environment employed by porch is the basic implementation technique underlying indolent closure creation. 3 Porch and Stack Environment Portability The porch compiler <ref> [15, 18] </ref> is a source-to-source compiler that translates C programs into semantically equivalent C programs additionally capable of saving and recovering from portable checkpoints. Portable checkpoints capture the state of a computation in a machine-independent format, called Universal Checkpoint FormatUCF. <p> Note that copying the live variables could be accompanied by an optional data representation conversion to facilitate transferring the closures across binary incompatible machines <ref> [18] </ref>. When all activation frames are released, the runtime stack of the victim is empty. It is rebuilt during the subsequent restore phase (3). The slow clone is executed to copy the live variables from the shadow stack back into the corresponding runtime-stack activation frames. <p> If the slow clone of the indolent version uses the same implementation for sharing of values via the closure, handling pointers is even simpler than in porch. Pointers passed by reference are handled almost as in porch <ref> [18, Section 5] </ref> when unrolling and restoring the runtime stack. During the save and restore phases, pointers are transformed into offsets within the shadow stack. On a shared memory machine, the offset would not be an integer, but the pointer to its target's shadow address.
Reference: [19] <author> J.-Y. Tsai and P.-C. Yew. </author> <title> The Superthreaded Architecture: Thread Pipelining with Run-Time Data Dependence Checking and Control Speculation. </title> <booktitle> In International Conference on Parallel Architectures and Compilation Techniques, </booktitle> <month> October </month> <year> 1996. </year> <month> 19 </month>
Reference-contexts: But a Stack is Faster. fl This manuscript is an extended version of a talk entitled Indolent Closure Creation, which I gave at the Yale Multithreaded Programming Workshop in New Haven, June 89, 1998. 1 Implementing multithreading in an efficient manner has lead to a variety of proposed multithreaded architectures <ref> [1, 6, 16, 19] </ref>. Efficient software implementations have been proposed for commodity architectures that introduce a compromise between stack and heap allocation techniques. For example, Lazy Threads [8] are based on stacklets, and the Illinois Concert system [9] employs a hybrid stack-heap execution mechanism.
References-found: 19

