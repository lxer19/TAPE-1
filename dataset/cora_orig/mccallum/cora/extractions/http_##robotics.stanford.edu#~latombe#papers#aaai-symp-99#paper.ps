URL: http://robotics.stanford.edu/~latombe/papers/aaai-symp-99/paper.ps
Refering-URL: http://robotics.stanford.edu/~latombe/projects/
Root-URL: http://www.cs.stanford.edu
Email: fhhg,latombeg @robotics.stanford.edu  
Title: Integrated Planning for Autonomous Agent Architectures Planning Robot Motions for Range-Image Acquisition and Automatic 3D
Author: Hector Gonzalez-Ba~nos Jean-Claude Latombe 
Address: Stanford, CA 94305  
Affiliation: Department of Computer Science Stanford University,  
Date: 1998  
Note: submitted paper AAAI Fall Symposium Series  
Abstract: In this paper we explore the application of motion planning techniques in the acquisition of range-images using a mobile robot equipped with range sensors. These techniques were developed to further our goal of automatically constructing three-dimensional representations of indoor environments using a team of mobile agents. The key question we ask is the following: How can we deploy the team of robots in such a way as to keep the number of sensing operations to a minimum and do so while allowing the acquired data to be registred and merged into a single consistent representation? We present two algorithms that use a two-dimensional map to estimate the locations where sensing will be most effective. These algorithms are randomized approaches that solve an extended version of the art gallery problem. One of the algorithms is a set-coverage approach, while the other is an incremental scheme that samples the constraint of the problem instead of its domain. Additionally, we explore some of the motion planning considerations that arise when image registration issues are considered. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. E. Banta, Y. Zhien, X. Z. Wang, G. Zhang, M. T. Smith, and M. A. Abidi. </author> <title> A "best-next-view" algorithm for three-dimensional scene reconstruction using range images. </title> <booktitle> In Proc. SPIE vol. </booktitle> <volume> 2588, </volume> <pages> pages 418-29, </pages> <year> 1995. </year>
Reference-contexts: The first three phases deal with range image acquisition and registration aspects, which on themselves have motivated a fair amount of research within the framework of computer graphics and machine vision, but mostly under the assumption that sensing operations are cheap and/or executed in fixed platforms <ref> [10, 1, 7] </ref>. <p> Finally, in the discussion section we present the conclusions and some future extensions to our work. 2 Planning Motions for Data Acquisition A classical problem in automatic range-image acquistion is known as the next-best-view problem <ref> [1, 7] </ref>: Where to place the sensor next in order to maximize the amount of information that will be added to the partial model built so far (Fig. 1)? Existing techniques are not ideally suited for robot sensors.
Reference: [2] <author> H. Gonzalez-Banos and et Al. </author> <title> Motion planning with visibility constraints: Building autonomous observers. </title> <booktitle> In Proc. 1997 International Symposium of Robotics Research, </booktitle> <year> 1997. </year>
Reference-contexts: In general, high-level vision-oriented robot operations involve important aspects of image analysis, robot localization, and dynamic control which must be addressed prior to the development of a practical system. But, even in the absence of these complications, there remains a fundamental planning problem that needs to be solved <ref> [2] </ref>. Such is the case behind the automatic exploration of an environment by a team of autonomous agents.
Reference: [3] <author> L. Guibas, J.C. Latombe, S.M. LaValle, D. Lin, and R. Motwani. </author> <title> Visibility-based pursuit-evasion in a polygonal environment. </title> <booktitle> In Proc. 5th Workshop on Algorihtms and Data Structures (WADS'97), </booktitle> <pages> pages 17-30. </pages> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: As explained in [5], when the presence of visual and motion obstructions are considered, the tracking problem trascends the machine vision context into motion control and planning domains. Another example of vision as end-effector is the hide-and-seek problem presented in <ref> [3] </ref>. Here the task is to move a team of robots in order to localize an unpredictable and arbitrary fast target with absolute certainty.
Reference: [4] <author> K. Kakusho, T. Kitahashi, K. Kondo, and J.-C. Latombe. </author> <title> Continuous purposive sensing and motion for 2d map building. </title> <booktitle> In Proc. IEEE Int. Conf. Systems, Man, & Cybernetics, </booktitle> <pages> pages 1472-1477, </pages> <year> 1995. </year>
Reference-contexts: One reason is that the next-best-view problem is inherently a local planning problem <ref> [4] </ref>. Obtaining a sequence of local next-best views to build a complete model may yield an excessive number of sensing operations. Even if data-acquisition is instantaneous sensing implies a cost. Part of the cost is the time spent mobilizing to all the different sensing positions.
Reference: [5] <author> S.M. LaValle, H. Gonzalez-Banos, C. Becker, and J.C. Latombe. </author> <title> Motion strategies for maintaining visibility of a moving target. </title> <booktitle> In Proc. 1997 IEEE Int'l Conf. Robotics & and Automation, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: Such is the case when visibility requirements are present or when vision sensors act themselves as end-effectors. An example of this is the task of keeping a moving target in view as it moves through a workspace. As explained in <ref> [5] </ref>, when the presence of visual and motion obstructions are considered, the tracking problem trascends the machine vision context into motion control and planning domains. Another example of vision as end-effector is the hide-and-seek problem presented in [3].
Reference: [6] <author> J. O'Rourke. </author> <title> Art Gallery Theorems and Algorithms. </title> <publisher> Oxford University Press, </publisher> <address> New York, NY, </address> <year> 1987. </year>
Reference-contexts: Let us assume that we are given a 2-D layout of a horizontal cross-section of the environment at approximately the height of the range sensor. An art-gallery algorithm will be able to compute the positions that must be visited to eventually see the entire 2-D environment <ref> [6] </ref>. Of course, this basic model-building approach requires additional considerations to make it work in practice: (1) Approximating the solution to the 3-D sensing problem with the output of a planar art-gallery algorithm relies on the existence of a 2-D map.
Reference: [7] <author> R. Pito. </author> <title> A solution to the next best view problem for automated cad model acquisition of free-form objects using range cameras. </title> <type> Technical Report 95-23, </type> <institution> GRASP Lab, University of Pennsylvania, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: The first three phases deal with range image acquisition and registration aspects, which on themselves have motivated a fair amount of research within the framework of computer graphics and machine vision, but mostly under the assumption that sensing operations are cheap and/or executed in fixed platforms <ref> [10, 1, 7] </ref>. <p> Finally, in the discussion section we present the conclusions and some future extensions to our work. 2 Planning Motions for Data Acquisition A classical problem in automatic range-image acquistion is known as the next-best-view problem <ref> [1, 7] </ref>: Where to place the sensor next in order to maximize the amount of information that will be added to the partial model built so far (Fig. 1)? Existing techniques are not ideally suited for robot sensors.
Reference: [8] <author> T. Shermer. </author> <title> Recent results in art galleries. </title> <journal> Proc. IEEE, </journal> <volume> 80(9) </volume> <pages> 1384-1399, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Our approach is currently far from optimal. A complete optimization should consider the registration constraint, the cost of sensing, the cost of moving, and the cost of planning simultaneously. We believe the planning problem then becomes closely connected with the watchman route problem <ref> [8] </ref>: Find the shortest closed path from which the entire workspace is visible. Surprisingly, this problem has been shown to be solvable in polynomial time although the basic art-gallery problem is NP-complete.
Reference: [9] <author> G. Turk and M. Levoy. </author> <title> Zippered polygon meshes from range images. </title> <booktitle> In Proc. ACM SIGGRAPH, </booktitle> <pages> pages 311-318, </pages> <year> 1994. </year>
Reference-contexts: This problem is readily solved if the 3-D representation is constructed under human assistance: simply ask the user to closely line up the views and rerun the aligment procedure. The algorithm will then do the final "zippering" <ref> [9] </ref>. However, if the operation is to be done automatically, there is a strong coupling between the alignment step and the exploration strategy. The strategy should consider alignment issues as part of the constraints of the problem, in addition to sensor limitations and constraints over motion.
Reference: [10] <author> L. Wixson. </author> <title> Viewpoint selection for visual search. </title> <booktitle> In Proc. IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 800-805, </pages> <year> 1994. </year>
Reference-contexts: The first three phases deal with range image acquisition and registration aspects, which on themselves have motivated a fair amount of research within the framework of computer graphics and machine vision, but mostly under the assumption that sensing operations are cheap and/or executed in fixed platforms <ref> [10, 1, 7] </ref>.
References-found: 10

