URL: http://www.cse.psu.edu/~barlow/TLSproc.ps
Refering-URL: http://www.cse.psu.edu/~barlow/papers.html
Root-URL: http://www.cse.psu.edu
Title: Solving Recursive TLS Problems Using the Rank-Revealing ULV Decomposition  
Author: Jesse L. Barlow Peter A. Yoon 
Abstract: Recursive total least squares (TLS) problems are common in applications ranging from signal processing to taking the temperature of the ocean. However, solving the recursive TLS problem requires updating and downdating the singular value decomposition (SVD) at each time step. Present stable software for this problem requires O(n 3 ) flops. Since the late 1960s, various kinds of "rank-revealing" two-sided orthogonal decompositions have been proposed as alternatives to the SVD. Recently, we have become aware that these decompositions can be used to obtain good approximate solutions to TLS problems. Moreover, they can be modified in O(n 2 ) flops and preserve their rank-revealing property. Thus an approximate solution to a recursive TLS problem can be obtained in O(n 2 ) flops per time step instead of O(n 3 ) flops. Perhaps the most useful such decomposition for TLS problems is the ULV decomposition (ULVD). It is shown that we can use the ULVD to obtain efficient, accurate approximate solutions to recursive TLS problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Barlow and P. Yoon, </author> <title> An efficient rank detection procedure for modifying the ULV decomposition, </title> <type> Technical Report, </type> <institution> Department of Computer Science and Engineering, The Pennsylvania State University, University Park, </institution> <address> PA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: The computation of kS 1 (t)k is more complicated. The usual way is to approximate the largest singular value of S 1 (t) by Lanczos or power iterations. Often that can be avoided. Barlow and Yoon <ref> [1] </ref> show that kS 1 (t + 1)k F can be computed from kS 1 (t)k F in O (p 2 ) flops, but that is a pessimistic bound on kS 1 (t + 1)k. <p> Some explanation of that procedure is given in Section 3. In Section 4, we demonstrate the algorithms on a simple test example from <ref> [1] </ref>. 4 2 Updating and Downdating the ULVD 2.1 Updating and Downdating 2 fi 2 Upper Triangular Factors First, we describe algorithms for updating and downdating a 2 fi2 triangular matria R with a 2-vector z given by R = s h ! Here the components g and h are assumed <p> for a downdate jg 11 j for an update :(16) Define the function (a; b; c) = a 2 + b 2 + (a 2 + b 2 ) 2 4a 2 c 2 = 2:(17) We have the following bound on k ^ S 1 k proved by Yoon <ref> [1] </ref>. Theorem 3.1. Assume that ^ L is the result of either by Algorithm 2.1 or 2.2. Suppose that kS 1 k 1 . <p> In that case, the process of determining that ULVD will produce a new estimate for k ^ S 1 k [11]. 9 4 An Example and our Conclusions We now present a computational example from Barlow and Yoon <ref> [1] </ref>. Two other examples are given there with similar results. Example 4.1. We constructed a 110 fi 6 matrix A big and a 110-vector b big . Their entries were chosen from a uniform [0; 1] distribution. <p> Two other examples are given there with similar results. Example 4.1. We constructed a 110 fi 6 matrix A big and a 110-vector b big . Their entries were chosen from a uniform <ref> [0; 1] </ref> distribution. We then chose 85 rows from C big = A big b big at random and multiplied them by 10 4 . We chose * = 10 2 . This example was run in MATLAB on a SUN sparcstation 5 in IEEE double precision arithmetic. <p> The dashed dot line is log 10 j sin 1 (t)j for the Stewart [11] updating algorithm used with the Barlow, Yoon, and Zha [2] downdating algorithm. The dotted and solid line are virtually indistinguishable for this problem, though for some of the other problems in <ref> [1] </ref>, j sin 2 (t)j was distinctly smaller than j sin 1 (t)j as would be expected. We computed the TLS solutions x T LS (t) from V 2 (t) and y T LS (t) from V 2 (t). <p> On this set of problems the value of y T LS (t) computed by Algorithms 2.1 and 2.2 was better than that computed by the algorithms in [2] ,[11], but on other examples in <ref> [1] </ref> there was little difference. Both sets of ULVD modification algorithms gave accurate solutions to these recursive TLS problems. The solid line in the graph "Rank Estimates" of Fig. 1 gives the value of k obtained by the SVD. <p> TLS Example 11 a procedure in <ref> [1] </ref>, again on a logarithmic scale, relative to *. In all of the tests in [1], the authors never had to use an estimate for kS 1 (t)k 1 other than ^ to determine the new value of k. <p> TLS Example 11 a procedure in <ref> [1] </ref>, again on a logarithmic scale, relative to *. In all of the tests in [1], the authors never had to use an estimate for kS 1 (t)k 1 other than ^ to determine the new value of k.
Reference: [2] <author> J. Barlow, P. Yoon, and H. Zha, </author> <title> An algorithm and a stability theory for downdating the ULV decomposition, </title> <journal> BIT, </journal> <volume> 36 (1996), </volume> <pages> pp. 14-40. </pages>
Reference-contexts: In some uses of the "low-rank" ULVD the F (t) and G (t) blocks are not stored explicitly, and cannot be modified using the procedures given here or those in <ref> [2] </ref> or [11]. Let oe i (C (t)) denote the ith singular value of C (t). <p> An algorithm for updating was given by Stewart [11]. A mixed forward stable algorithm for downdating is given by Barlow, Yoon, and Zha <ref> [2] </ref> that does not require keeping U (t). The authors of [2] also give a thorough discussion of the stability and regularity issues for downdating the ULVD. Both procedures require only O (p 2 ) flops and are thus considerably faster than modifying the SVD. <p> An algorithm for updating was given by Stewart [11]. A mixed forward stable algorithm for downdating is given by Barlow, Yoon, and Zha <ref> [2] </ref> that does not require keeping U (t). The authors of [2] also give a thorough discussion of the stability and regularity issues for downdating the ULVD. Both procedures require only O (p 2 ) flops and are thus considerably faster than modifying the SVD. <p> Both procedures require only O (p 2 ) flops and are thus considerably faster than modifying the SVD. Park and Elden [10] give a procedure for downdating the URVD and discuss many of the issues in <ref> [2] </ref>. The conditions (6) and (8) can be verified by computing kF (t)k F , kG (t)k F , and kS 1 (t)k at each new value of t. Barlow, Yoon, and Zha [2] give methods for updating kF (t)k F and kG (t)k F that require O (p) flops altogether. <p> and Elden [10] give a procedure for downdating the URVD and discuss many of the issues in <ref> [2] </ref>. The conditions (6) and (8) can be verified by computing kF (t)k F , kG (t)k F , and kS 1 (t)k at each new value of t. Barlow, Yoon, and Zha [2] give methods for updating kF (t)k F and kG (t)k F that require O (p) flops altogether. We note that ae T LS (t) = kG (t)k F is the norm of the TLS residual for our approximate solution y T LS (t). <p> In that context, we may assume that s 1 . Since the values of 2 and g can be small, they can also be inaccurate because of accumulated rounding errors. We can define the function down22 using a version of the algorithm described in <ref> [2] </ref> applied to R. <p> In that case, we solve a "nearby" downdating problem. We have ff = ~g = 0, and ~ 2 = fl g + fi h which is consistent with the choice of the orthogonal matrix Q. The significance of the latter regularity condition is discussed in <ref> [2, Proposition 3.2] </ref>. 5 2.2 Algorithms for Updating and Downdating the ULVD We now make notational simplifications of (3)-(7) and (8) by writing C = C (t); U = U (t); L = L (t); V = V (t); L = B k pk np+1 pk F (t) G (t) 0 <p> Such a procedure is given in <ref> [2] </ref>. Also compute F (1) = ^ U T 6 Step 2. For each integer i, let f (i) (i) 1 G (i) e 1 . <p> The assumption that S T S z 1 z T 1 is positive semi-definite is sufficient to insure that js (3) kk j j 2 j and thus that step 4 is well defined. Occasionally this assumption is violated, see the discussion in Example 4.1 or the examples in <ref> [2] </ref>. Algorithm 2.2 (Updating Procedure for the ULVD). An updating algorithm for the ULVD may be obtained by making three simple changes to Algorithm 2.1. <p> Similar formulas can be given for the algorithms in <ref> [2] </ref> and [11]. 8 3 Tracking kS 1 k and Related Issues Let ^ S denote the fi principal submatrix of ^ L as defined in (14). <p> To determine which of or 1 is correct, we must estimate k ^ S 1 k. For the algorithms in <ref> [2] </ref> and [11], we must use Lanczos or power iterations, but for Algorithms 2.1 and 2.2 we can get a simple estimate very easily. <p> Then ^ k ^ S 1 k 1 oe ( ^ C). The estimate in Theorem 3.1 is not really free. The updating and downdating algorithms in this paper require about k 2 more flops than those in <ref> [2] </ref>, [11]. Thus the real cost of this estimate is about one power iteration. If kS 1 k 1 &lt; *, then step 8 of Algorithms 2.1 and 2.2 is completed by computing the ULVD of ^ S. <p> The dashed dot line is log 10 j sin 1 (t)j for the Stewart [11] updating algorithm used with the Barlow, Yoon, and Zha <ref> [2] </ref> downdating algorithm. The dotted and solid line are virtually indistinguishable for this problem, though for some of the other problems in [1], j sin 2 (t)j was distinctly smaller than j sin 1 (t)j as would be expected. <p> In the graph "TLS errors" of Fig. 1, the solid line is log 10 ky T LS (t) x T LS (t)k The dashed dot line is the same error using the ULVD modification algorithms from <ref> [2] </ref>, [11]. On this set of problems the value of y T LS (t) computed by Algorithms 2.1 and 2.2 was better than that computed by the algorithms in [2] ,[11], but on other examples in [1] there was little difference. <p> T LS (t) x T LS (t)k The dashed dot line is the same error using the ULVD modification algorithms from <ref> [2] </ref>, [11]. On this set of problems the value of y T LS (t) computed by Algorithms 2.1 and 2.2 was better than that computed by the algorithms in [2] ,[11], but on other examples in [1] there was little difference. Both sets of ULVD modification algorithms gave accurate solutions to these recursive TLS problems. The solid line in the graph "Rank Estimates" of Fig. 1 gives the value of k obtained by the SVD. <p> Notice that k varies greatly. The asterisk "*" indicates that step 7 was necessary in the downdate. The "+"indicates that S T S z 1 z T 1 became indefinite and a step of corrected semi-normal equations as discussed in <ref> [2] </ref>, [3], [10] was necessary to get a more accurate value of z 1 .
Reference: [3] <author> A. Bjorck, H. Park, and L. Elden, </author> <title> Accurate downdating of least squares solutions, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 15 (1994), </volume> <pages> pp. 549-568. </pages>
Reference-contexts: Notice that k varies greatly. The asterisk "*" indicates that step 7 was necessary in the downdate. The "+"indicates that S T S z 1 z T 1 became indefinite and a step of corrected semi-normal equations as discussed in [2], <ref> [3] </ref>, [10] was necessary to get a more accurate value of z 1 .
Reference: [4] <author> C. Davis and W. Kahan, </author> <title> The rotation of eigenvectors by a perturbation III, </title> <journal> SIAM J. Num. </journal> <month> Anal.,7 </month> <year> (1970), </year> <pages> pp. 1-46. </pages>
Reference-contexts: Therefore, it is important that range ( V 2 (t)) be "close" to range (V 2 (t)). To insure that, Fierro and Bunch [6] show that the Davis-Kahan <ref> [4] </ref> sin measure of error in subspaces is bounded by j sin j = kV T oe k+1 (C (t))kF (t)k k+1 (C (t)) A simple use of norm inequalities yields the bound kV T oe k+1 (C (t)) : Thus, a small value of j assures us of an accurate
Reference: [5] <author> D. Faddeev, V. Kublanovskaya, and V. Faddeeva, </author> <title> Solution of Linear Algebraic Systems with Rectangular Matrices, </title> <booktitle> Proc. </booktitle> <institution> Steklov. Inst. Math., </institution> <month> 96 </month> <year> (1968), </year> <pages> pp. 93-111. </pages>
Reference-contexts: The ULV decomposition (ULVD) is such an approximation. The ULVD is a special case of the two-sided orthogonal decompositions defined by Faddeev, Kublanovskaya, and Faddeeva <ref> [5] </ref> and Hanson and Lawson [9]. The most familiar formulation is due to Stewart [11]. A slightly different formulation is given below. <p> In between the publication of <ref> [5] </ref> ,[9] and [11], other similar approximations to the SVD have been proposed. The most prominent have been the rank-revealing orthogonal decompositions (RRQR) and the URV decomposition (URVD). In the RRQR, the middle matrix L (t) is upper triangular and V (t) is merely a permutation matrix.
Reference: [6] <author> R. Fierro and J. Bunch, </author> <title> Bounding the subspaces from rank revealing two-sided orthogonal decompositions, </title> <note> SIAM J. Matrix Anal. Appl., 16 (1995), pp.743-759. </note>
Reference-contexts: Therefore, it is important that range ( V 2 (t)) be "close" to range (V 2 (t)). To insure that, Fierro and Bunch <ref> [6] </ref> show that the Davis-Kahan [4] sin measure of error in subspaces is bounded by j sin j = kV T oe k+1 (C (t))kF (t)k k+1 (C (t)) A simple use of norm inequalities yields the bound kV T oe k+1 (C (t)) : Thus, a small value of j <p> then computed the two error measures j sin 1 (t)j = kV T 1 (t) V 2 (t)k: The value sin 1 (t) is the accumulated error from approximation and rounding in the updated and downdated ULVD, sin 2 (t) is the local approximation error discussed by Fierro and Bunch <ref> [6] </ref> and given in (10). In the graph "Noise Space Errors" in Fig. 1, the solid line is log 10 j sin 1 (t)j, the dotted line is log 10 j sin 2 (t)j.
Reference: [7] <author> R. Fierro, L. Vanhamme, and S. Van Huffel, </author> <title> Total least squares algorithms based on rank-revealing complete orthogonal decompositions, in this volume, </title> <editor> S. Van Huffel, ed., </editor> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <year> 1997. </year>
Reference-contexts: That is, the last n p + 1 columns and the last m p rows of L (t) are known to be zero. The distinction between "high-rank" and "low-rank" ULV decompositions used by Fierro, Vanhamme, and Van Huffel <ref> [7] </ref> makes no difference to the procedures described here as long as the matrix L (t) is lower triangular and stored explicitly.
Reference: [8] <author> M. Gu and S. Eisenstat, </author> <title> Downdating the singular value decomposition, </title> <note> SIAM J. Matrix Anal. Appl.,16 (1995), pp.793-810. </note>
Reference-contexts: (1) as quickly and accurately as possible we might consider using the SVD of C (t) to compute that of C (t + 1), but "practical" procedures for that require O (n 3 ) flops. (We exclude the O (n 2 ) adaptive fast multipole procedure of Gu and Eisenstat <ref> [8] </ref> which is not practical at present). Thus, we would like an approximation to the SVD of C (t + 1) which can be computed from a similar approximation for C (t) in significantly fewer operations. The ULV decomposition (ULVD) is such an approximation.
Reference: [9] <author> R. Hanson and C. Lawson, </author> <title> Extensions and applications of the Householder algorithm for solving linear least squares problems, </title> <journal> Math. Comp., </journal> <volume> 23 (1969), </volume> <pages> pp. 787-812. </pages>
Reference-contexts: The ULV decomposition (ULVD) is such an approximation. The ULVD is a special case of the two-sided orthogonal decompositions defined by Faddeev, Kublanovskaya, and Faddeeva [5] and Hanson and Lawson <ref> [9] </ref>. The most familiar formulation is due to Stewart [11]. A slightly different formulation is given below. <p> For each integer i, let f (i) (i) 1 G (i) e 1 . Find an orthogonal matrix ^ U 3 2 R (k+1)fi (k+1) such that 0 g 11 = ^ U T ff 1 g T g 11 where S (2) is lower triangular. See <ref> [9] </ref> for such a procedure. Define F (2) = (I e 1 e T Step 3.
Reference: [10] <author> H. Park and L. Elden, </author> <title> Downdating a rank-revealing URV decomposition, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 16 (1995), </volume> <pages> pp. 138-156. </pages>
Reference-contexts: The authors of [2] also give a thorough discussion of the stability and regularity issues for downdating the ULVD. Both procedures require only O (p 2 ) flops and are thus considerably faster than modifying the SVD. Park and Elden <ref> [10] </ref> give a procedure for downdating the URVD and discuss many of the issues in [2]. The conditions (6) and (8) can be verified by computing kF (t)k F , kG (t)k F , and kS 1 (t)k at each new value of t. <p> Notice that k varies greatly. The asterisk "*" indicates that step 7 was necessary in the downdate. The "+"indicates that S T S z 1 z T 1 became indefinite and a step of corrected semi-normal equations as discussed in [2], [3], <ref> [10] </ref> was necessary to get a more accurate value of z 1 .
Reference: [11] <author> G. Stewart, </author> <title> Updating a rank-revealing ULV decomposition, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 14 (1993), </volume> <pages> pp. </pages> <month> 494-499. </month> <title> [12] , On an algorithm for refining a rank-revealing URV decomposition and a perturbation theorem for singular values, </title> <type> Technical Report CS-TR 2626, </type> <institution> Department of Computer Science, University of Maryland, College Park, MD, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: The ULV decomposition (ULVD) is such an approximation. The ULVD is a special case of the two-sided orthogonal decompositions defined by Faddeev, Kublanovskaya, and Faddeeva [5] and Hanson and Lawson [9]. The most familiar formulation is due to Stewart <ref> [11] </ref>. A slightly different formulation is given below. <p> In some uses of the "low-rank" ULVD the F (t) and G (t) blocks are not stored explicitly, and cannot be modified using the procedures given here or those in [2] or <ref> [11] </ref>. Let oe i (C (t)) denote the ith singular value of C (t). <p> In between the publication of [5] ,[9] and <ref> [11] </ref>, other similar approximations to the SVD have been proposed. The most prominent have been the rank-revealing orthogonal decompositions (RRQR) and the URV decomposition (URVD). In the RRQR, the middle matrix L (t) is upper triangular and V (t) is merely a permutation matrix. <p> For each value of t, the ULVD of C (t + 1) is formed from that of C (t) by adding a row, thus performing an update operation on L (t), and deleting a row, thus performing a downdate. An algorithm for updating was given by Stewart <ref> [11] </ref>. A mixed forward stable algorithm for downdating is given by Barlow, Yoon, and Zha [2] that does not require keeping U (t). The authors of [2] also give a thorough discussion of the stability and regularity issues for downdating the ULVD. <p> Similar formulas can be given for the algorithms in [2] and <ref> [11] </ref>. 8 3 Tracking kS 1 k and Related Issues Let ^ S denote the fi principal submatrix of ^ L as defined in (14). <p> To determine which of or 1 is correct, we must estimate k ^ S 1 k. For the algorithms in [2] and <ref> [11] </ref>, we must use Lanczos or power iterations, but for Algorithms 2.1 and 2.2 we can get a simple estimate very easily. <p> Then ^ k ^ S 1 k 1 oe ( ^ C). The estimate in Theorem 3.1 is not really free. The updating and downdating algorithms in this paper require about k 2 more flops than those in [2], <ref> [11] </ref>. Thus the real cost of this estimate is about one power iteration. If kS 1 k 1 &lt; *, then step 8 of Algorithms 2.1 and 2.2 is completed by computing the ULVD of ^ S. <p> That can be determined if ^ &lt; *, but the ULVD of ^ S fails to isolate a small last row as in (18). In that case, the process of determining that ULVD will produce a new estimate for k ^ S 1 k <ref> [11] </ref>. 9 4 An Example and our Conclusions We now present a computational example from Barlow and Yoon [1]. Two other examples are given there with similar results. Example 4.1. We constructed a 110 fi 6 matrix A big and a 110-vector b big . <p> In the graph "Noise Space Errors" in Fig. 1, the solid line is log 10 j sin 1 (t)j, the dotted line is log 10 j sin 2 (t)j. The dashed dot line is log 10 j sin 1 (t)j for the Stewart <ref> [11] </ref> updating algorithm used with the Barlow, Yoon, and Zha [2] downdating algorithm. The dotted and solid line are virtually indistinguishable for this problem, though for some of the other problems in [1], j sin 2 (t)j was distinctly smaller than j sin 1 (t)j as would be expected. <p> In the graph "TLS errors" of Fig. 1, the solid line is log 10 ky T LS (t) x T LS (t)k The dashed dot line is the same error using the ULVD modification algorithms from [2], <ref> [11] </ref>. On this set of problems the value of y T LS (t) computed by Algorithms 2.1 and 2.2 was better than that computed by the algorithms in [2] ,[11], but on other examples in [1] there was little difference.
Reference: [13] <author> S. Van Huffel and J. Vandewalle, </author> <title> The Total Least Squares Problem: Computational Aspects and Analysis, </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, PA, </address> <year> 1991. </year>
Reference-contexts: Engineering, The Pennsylvania State University, University Park, PA. 16802-6106 USA, e-mail: barlow@cse.psu.edu. z Department of Computer Science, Azusa Pacific University, Azusa, CA 91702 USA, e mail:pyoon@apu.edu 1 2 and recover the solution, x T LS (t), from the singular value decomposition (SVD) of C (t) in the manner described in <ref> [13, pp.80-81] </ref>. <p> Let V (t) be the right singular vector matrix of C (t) and let V (t) and V (t) be partitioned into V (t) = k nk+1 j i V 1 (t) V 2 (t) :(9) In the manner described in <ref> [13, pp.80-81] </ref>, the exact solution, x T LS (t), to (1) is recovered from V 2 (t) and the approximate solution, y T LS (t), is recovered from V 2 (t). Therefore, it is important that range ( V 2 (t)) be "close" to range (V 2 (t)).
Reference: [14] <author> J.H. Wilkinson, </author> <title> The Algebraic Eigenvalue Problem, </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1965. </year>
Reference-contexts: Let the value of be defined by = k for a downdate k + 1 for an update : A classical theorem on rank-one modifications <ref> [14, pp.94-97] </ref> tells us that if C has k singular values greater than * then the ^ C resulting from Algorithms 2.1 or 2.2 has either 1 or singular values greater than *. To determine which of or 1 is correct, we must estimate k ^ S 1 k.
References-found: 13

