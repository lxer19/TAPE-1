URL: http://www.cis.ohio-state.edu/~kurzion/papers/cgna.ps.gz
Refering-URL: http://www.cis.ohio-state.edu/~kurzion/resume.html
Root-URL: 
Title: Interactive Space Deformation with Hardware Assisted Rendering  
Author: Yair Kurzion and Roni Yagel 
Affiliation: Department of Computer and Information Science The Ohio State University  
Abstract: We introduce a new approach for the deformation of surface and raster models in two and three dimensions. Rather then deforming the model, we deform the rendering agents employed to render it. We introduce the deectors: a new set of operators for modeling both continuous and discontinuous deformations. When the scene is rendered by ray tracings, the deectors bend sight rays traveling through space in a view-independent fashion. Images generated by these curved rays give the impression of a deformed space. Unlike previous methods, our approach deforms only those parts of the model that contribute to the final image. When deforming volumes we avoid resampling the volume during the deformation process. In addition, our approach can deform any object type that can be rendered by a ray casting algorithm, providing a unified solution to deformation of both surface and volume primitives. We describe and analyze a ray casting software implementation and present a hardware assisted slicing-based renderer which exploits texture mapping hardware to provide real-time volume deformation.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Barr A., </author> <title> Global and Local Deformations of Solid Primitives, </title> <booktitle> Proceedings of SIGGRAPH 84, Computer Graphics, </booktitle> <volume> 18(3) </volume> <pages> 21-30, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: Intersecting these curves with the scene objects creates an illusion of a deformed scene. The objects 2 residing in the deformed space now appear to have changed their shape, although they have not been modified in any way. Barr <ref> [1] </ref> introduced the deformation of sight rays as a way to achieve the deformation of solid primitives. He used the inverse of one global deformation transformation in order to deform sight rays. Expressing a complex deformation, such as sculpting, in global terms is almost impossible computationally.
Reference: 2. <author> Barr A., </author> <title> Ray Tracing Deformed Surfaces, </title> <booktitle> Proceedings of SIGGRAPH 86, Computer Graphics, </booktitle> <volume> 20(4) </volume> <pages> 287-296, </pages> <month> August </month> <year> 1986. </year>
Reference: 3. <author> Bier T. and Neely S., </author> <title> Feature Based Image Metamorphosis, </title> <booktitle> Proceedings of SIGGRAPH 92, Computer Graphics, </booktitle> <volume> 26(2) </volume> <pages> 35-42, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: In Section 6 we will present the implementation of space deformation with deectors in the context of a slicing renderer. 1.2 Space Deformation with Deectors Although existing methods for specifying object deformations (e.g., grids [16], vectors <ref> [3] </ref>) may be used to deform sight rays, we have chosen to introduce a new mechanism, called a deector, that is specifically suited to our paradigm of ray deformation. <p> In two dimensions we can use deectors as a modeling primitive for image warping. Unlike existing methods, deector based deformation is much more intuitive as a modeling tool. Existing methods deform the space somewhat indirectly by moving grid points [16] or vectors <ref> [3] </ref>, an extremely laborious operation in 3D. Our approach, on the other hand, simulates the process of creating a sculpture by deforming an initial set of objects in space using a sequence of local deformations. Our hardware assisted volume deformation implementation offers very attractive rendering rates.
Reference: 4. <author> Cabral B., Cam N., and Foran J., </author> <title> Accelerated Volume Rendering and Tomographic Reconstruction Using Texture Mapping Hardware, </title> <booktitle> Proceedings of 1994 Symposium on Volume Visualization, </booktitle> <month> October </month> <year> 1994, </year> <pages> pp. 91-98 </pages>
Reference-contexts: These primitives are rendering agents. They create the interaction between the objects in space and the pixels on the resulting image. In ray casting (tracing) we sample space along sight rays, thus the sight rays are the rendering agents. In slicing based volume rendering <ref> [4] </ref> we render slices through the volume, thus the slices are the rendering agents for the slicing method. In object order polygon scan conversion there is no intermediate element for sampling space, thus there are no rendering agents. <p> Expressing a complex deformation, such as sculpting, in global terms is almost impossible computationally. Our approach employs an aggregate of many simple local deformation operators, thus making sight ray deection easy to compute. When rendering with slicing <ref> [4] </ref>, we deform the rendering agents - polygon slices into deformed samples of space. To simplify our presentation, we will use the intuitive example of ray casting in the discussion that follows. <p> When rendering a single polygon, we get a slice through the 3D raster. By rendering many parallel polygons, slicing the volume and perpendicular to the view direction one generates a view of a rectangular volume data set <ref> [4] </ref>. Rendering these polygons from back to front and blending them into the frame buffer generates a correct image of the volume. We note that the slicing polygons are the rendering agents in the slicing method. Figure 11a shows a stack of parallel polygons slicing through a 3D raster.
Reference: 5. <author> Glassner, A. S. (ed.), </author> <title> An Introduction to Ray Tracing, </title> <publisher> Academic Press, </publisher> <year> 1989. </year>
Reference-contexts: After computing the mapping of all the control points, one is free to render the new model with the most appropriate rendering algorithm. For example, if one employs a ray casting (or ray tracing) algorithm <ref> [5] </ref>, then a collection of rays is cast, from the eye, through each screen pixel, into the deformed scene. Traditionally, one has to develop an algorithm to compute the deformation operation for each object type. Obviously, one cannot use a volume deformation algorithm [7], for example, to deform parametric surfaces. <p> When deforming geometric primitives, we compute the intersection of the deformed ray with the geometry as in traditional ray tracing <ref> [5] </ref>, when deforming 2D rasters we sample at points along the deformed scan lines, and when deforming 3D rasters, we sample along rays as in traditional volume rendering [9]. 5.1 Determining Ray Trajectory When shooting rays we have to distinguish between two cases: either a ray does not intersect any field
Reference: 6. <author> He T., Wang S., and Kaufman A., </author> <title> Wavelet-Based Volume Morphing, </title> <booktitle> Proceedings of Visualization94, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1994, </year> <pages> pp. 85-92. </pages>
Reference: 7. <author> Hughes J.F., </author> <title> Scheduled Fourier Volume Morphing, </title> <booktitle> Proceedings of SIGGRAPH 92, Computer Graphics, </booktitle> <volume> 26(2) </volume> <pages> 43-46, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Traditionally, one has to develop an algorithm to compute the deformation operation for each object type. Obviously, one cannot use a volume deformation algorithm <ref> [7] </ref>, for example, to deform parametric surfaces. In addition, the separation between the modeling and rendering phases requires deforming the entire model - even those parts that do not contribute to the final image. Existing rendering schemes use different primitives for sampling space and generating images.
Reference: 8. <author> Isaacs P.M. and Cohen M.F., </author> <title> Controlling Dynamic Simulation with Kinematic Constrains, Behavior Functions and Inverse Dynamics, </title> <booktitle> Proceedings of SIGGRAPH 87, Computer Graphics, </booktitle> <volume> 21(4) </volume> <pages> 215-224, </pages> <month> July </month> <year> 1987. </year>
Reference: 9. <author> Kaufman A. (ed.), </author> <title> Volume Visualization, </title> <publisher> IEEE Computer Society Press, </publisher> <year> 1990. </year>
Reference-contexts: When deforming geometric primitives, we compute the intersection of the deformed ray with the geometry as in traditional ray tracing [5], when deforming 2D rasters we sample at points along the deformed scan lines, and when deforming 3D rasters, we sample along rays as in traditional volume rendering <ref> [9] </ref>. 5.1 Determining Ray Trajectory When shooting rays we have to distinguish between two cases: either a ray does not intersect any field of gravity, or it intersects at least one such region.
Reference: 10. <author> Kent J.R., Carlson W.E., and Parent R., </author> <title> Shape Transformations for Polyhedral Objects, </title> <booktitle> Proceedings of SIGGRAPH 92, Computer Graphics, </booktitle> <volume> 26(2) </volume> <pages> 47-54, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: This choice of a step size is similar to the choice of a sub-polygon size when breaking a polygon into a mesh of smaller polygons as done in traditional object deformation algorithms <ref> [10] </ref>. The smaller the pieces are, the smoother the resulting deformation is. In volume graphics, we take equidistant steps along each sight ray and sample the volume contents at each step. When stepping along linear segments of a ray, we use standard volume ray tracing techniques. <p> This will increase the number of deectors in a scene but will allow more freedom in the deformation. On the other hand, our technique exhibits attractive characteristics. When deforming polygons, traditional techniques break them down into a mesh of smaller polygons and deform their vertices <ref> [10] </ref>. Many of the smaller polygons may not contribute to the final image because they are hidden by other polygons in space. Moreover, polygons that lie farther away from the eye need not be subdivided into as many polygons as the closer polygons.
Reference: 11. <author> Kurzion Y., and Yagel R., </author> <title> Space Deformation using Ray Deectors, </title> <booktitle> 6th Eurographics Workshop on Rendering 95, </booktitle> <month> June </month> <year> 1995, </year> <pages> pp. 21-32. </pages>
Reference-contexts: Given a deector &lt;C, G, R, T&gt; and given a point p at distance r from C, we define the transform T of point p as: (1) T (p) is well behaved for all G s.t. . A proof of this claim is presented in <ref> [11] </ref>. Note that T (p) is a localized version of the affine translation transform. The translation power of the deector is maximum at its center and it is attenuated towards the sphere boundary. Figure 1 demonstrates how the translate deection transform deects rays.
Reference: 12. <author> Maillot, P. G., </author> <title> Three Dimensional Homogeneous Clipping of Triangle Strips, Graphic Gems II, AP Professional, </title> <booktitle> 1991, </booktitle> <pages> pp. 219-231 </pages>
Reference-contexts: Figure 13a shows a tessellation with non-sampling vertices. Part (b) shows the desired tessellation after we remove the non-sampling vertices and limit our rendering to sampled areas. We adapt a triangle mesh clipping algorithm <ref> [12] </ref> in order to clip out the non-sampling areas. The triangle mesh clipping algorithm clips a triangle mesh by a half plane. It steps along a triangle mesh and assigns each triangle with a code. This code is based on which vertices are clipped in and out.
Reference: 13. <author> Sederberg, T.W. and Greenwood E., </author> <title> A Physically Based Approach to 2-D Shape Blending, </title> <booktitle> Proceedings of SIGGRAPH 92, Computer Graphics, </booktitle> <volume> 26(2) </volume> <pages> 25-34, </pages> <month> July </month> <year> 1992. </year>
Reference: 14. <author> Terzopoulos D., Platt J., Barr A., and Fleischer K., </author> <title> Elastically Deformable Models, </title> <booktitle> Proceedings of SIGGRAPH 87, Computer Graphics, </booktitle> <volume> 21(4) </volume> <pages> 205-214, </pages> <month> July </month> <year> 1987. </year>
Reference: 15. <editor> Williams L., Pyramidal Parametrics, </editor> <booktitle> Proceedings of SIGGRAPH 83, Computer Graphics, </booktitle> <volume> 17(3) </volume> <pages> 1-10, </pages> <month> July </month> <year> 1983. </year>
Reference-contexts: In volume graphics, we wish to improve our sampling technique by using a mip-mapped version of the volume <ref> [15] </ref>. We plan to improve the piecewise-linear approximation of the deformation in the hardware assisted slicing technique by generating an adaptive tessellation. Such tessellation will be denser at areas where the deection function has a high derivative and sparser elsewhere.

References-found: 15

