URL: ftp://ftp.cs.toronto.edu/pub/jepson/papers/fadBMVC.ps.Z
Refering-URL: http://www.cs.toronto.edu/vis/publications/abstracts/fadBMVC.html
Root-URL: 
Title: Detecting Floor Anomalies  
Author: Michael R. M. Jenkin and Allan Jepson ; 
Date: March 14, 1995  
Affiliation: 1 Department of Computer Science, York University, 2 Canadian Institute for Advanced Research, and Department of Computer Science, University of Toronto  
Abstract: When a robot moves about a 2D world such as a planar surface, it is important that obstacles to the robot's motions be detected. This classical problem of "obstacle detection" has proven to be difficult. Many researchers have formulated this problem as being the process of determining where a robot cannot move due to the presence of obstacles. An alternative approach presented here is to determine where an robot can go by identifying floor regions for which the planar floor assumption can be verified. A stereo vision system is developed for Floor Anomaly Detection (FAD), and its relationship to existing stereo obstacle detection algorithms is described.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Ayache. </author> <title> Artificial vision for mobile robots. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: In robotic applications this safety is usually expressed in terms of the robot being able to detect obstacles to its motion. Here we are concerned with the development of a stereo vision system capable of identifying safe places to move on a floor plane. Previous work <ref> [3, 1, 12] </ref> on this problem has taken the goal to be to identify obstacles on the 2D plane over which the robot is to move. What is tacitly assumed in the literature is that the floor plane itself is safe and can be traversed (for an exception, see [2]).
Reference: [2] <author> P. Burt, P. Anandan, K. Hanna, G. van der Wal, and R. Bassman. </author> <title> A front-end vision processor for vehicle navigation. </title> <booktitle> In IAS-3, </booktitle> <pages> pages 653-662, </pages> <address> Pittsburgh, PA, </address> <year> 1993. </year>
Reference-contexts: What is tacitly assumed in the literature is that the floor plane itself is safe and can be traversed (for an exception, see <ref> [2] </ref>). This is an important issue in many robotics environments as the floor may not be particularly safe for the robot to navigate.
Reference: [3] <author> O. Faugeras. </author> <title> Three-dimensional computer vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: In robotic applications this safety is usually expressed in terms of the robot being able to detect obstacles to its motion. Here we are concerned with the development of a stereo vision system capable of identifying safe places to move on a floor plane. Previous work <ref> [3, 1, 12] </ref> on this problem has taken the goal to be to identify obstacles on the 2D plane over which the robot is to move. What is tacitly assumed in the literature is that the floor plane itself is safe and can be traversed (for an exception, see [2]). <p> Here ~n = (n 1 ; n 2 ; n 3 ) T is a unit normal to the plane, and d measures the perpendicular distance of the plane from the origin of the 3D coordinate frame. Then, for pinhole camera models, Faugeras <ref> [3] </ref> has shown that the mapping from a point, ~w r , in the right image to the corresponding point, ~w l , in the left image is given by ~w l = K (~n; d) ~w r ; (2) where K (~n; d) is a 3 fi 3 matrix.
Reference: [4] <author> D. Fleet, A. Jepson, and M. Jenkin. </author> <title> Phase-based disparity measurement. </title> <journal> CVGIP: IU, </journal> <volume> 3(2), </volume> <pages> pages 198-210, </pages> <year> 1991. </year>
Reference-contexts: For our test cases reported below we have chosen a phase-based disparity scheme <ref> [4] </ref>. In particular, given a stereo pair we have the option of prewarping these images according to an initial guess, ~ k 0 , for ~ k. This prewarping is done using bilinear interpolation on the grey levels. <p> The convolution responses are subsampled every second pixel both horizontally and vertically, and then quantized to 8 bits. Phase gradients are computed using the technique described in <ref> [4] </ref>. <p> reduce the number of noisy disparity constraints we discarded filter responses with too low an amplitude (i.e. below the response obtained from a grating having a half-amplitude of 3 grey levels), or too close to a phase singularity (i.e. we used t = 1:5 for the singularity neighbourhood detection in <ref> [4] </ref>). The phase constancy assumption between the left and right images then provided disparity constraints of the form (7), for each of the four filter orientations.
Reference: [5] <author> W. Freeman and E. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE PAMI, </journal> <volume> 13(9), </volume> <pages> pages 891-906, </pages> <year> 1991. </year>
Reference-contexts: This prewarping is done using bilinear interpolation on the grey levels. The resulting images are then bandpass filtered using complex 15 fi 15 kernels based on the steerable quadrature pair G 2 and H 2 developed in <ref> [5] </ref>. This pair has been scaled so that the peak frequency occurs at wavelength = 8 pixels, and four spatial orientations separated by 45 degrees are used. The convolution responses are subsampled every second pixel both horizontally and vertically, and then quantized to 8 bits.
Reference: [6] <author> B. Horn. </author> <title> Robot Vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year> <month> 9 </month>
Reference-contexts: In this paper we consider the camera model proposed by Horn <ref> [6] </ref>. This model includes a general 3D camera position and focal length, along with several important perturbations from an ideal pinhole camera. In particular, Horn's model can represent defects due to a general 3D-misalignment of the sensor array with the optical axis. <p> That is, a given four-vector ~ W represents ~ X if X i = W i =W 4 for i = 1; 2; 3. Similarly, a three vector ~w represents the image point ~x whenever x i = w i =w 3 for i = 1; 2. Now, following <ref> [6] </ref>, we define the transformation from an arbitrary point ~ W in a global coordinate system to an image point ~w as ~w = T ~ W ; (1) where T is a 3x4 matrix of coefficients which specify the transformation.
Reference: [7] <author> M. Jenkin, N. Bains, J. Bruce, T. Campbell, B. Down, P. Jasiobedzki, A. Jepson, B. Ma--jarais, E. Milios, B. Nickerson, J. Service, D. Terzopoulos, J. Tsotsos, and D. Wilkes. </author> <title> ARK: Autonomous mobile robot for an industrial environment. </title> <booktitle> In IEEE/RSJ IROS, </booktitle> <address> Munich, Germany, </address> <year> 1994. </year> <note> (in press). </note>
Reference-contexts: This paper appeared in the Proceedings of the British Machine Vision Conference 1994, Univ. of York, Ed. E. Hancock, BMVA Press, pp. 731-740. 1 floor <ref> [7] </ref>. Thus although the floor of the ARK environment can be expected to be planar, local regions of the floor can be expected to contain structure which violates the planarity assumption. In addition, regions that violate the planarity assumption are not easily mapped and they cannot be completely avoided.
Reference: [8] <author> M. Jenkin, A. Jepson, and J. Tsotsos. </author> <title> Techniques for disparity measurement. </title> <journal> CVGIP: IU, </journal> <volume> 53(1) </volume> <pages> 14-30, </pages> <year> 1991. </year>
Reference-contexts: Both of these steps require the measurement of the local relative shifts, that is, the disparity between the 3 two images. Many different disparity measurement techniques can be used (see <ref> [8] </ref> for a survey).
Reference: [9] <author> M. R. M. Jenkin and A. Jepson. </author> <title> Detecting floor anomalies. </title> <type> ARK Tech. Rep. </type> <note> in preparation. </note>
Reference-contexts: We have shown <ref> [9] </ref> that the same form of equation suffices for the more general camera models described in the previous section, and we have derived a closed-form expression for K in terms of L, R, ~n and d. It turns out that K (~n; d) is a linear function of (~n; d). <p> This makes it a relatively simple matter, using least squares, to convert a coefficient vector ~ k to the corresponding parameters ~n, d for the ground plane in 3D <ref> [9] </ref>. <p> Disparities outside of this range will produce false targets and outlier measurements (see below). The stereo configuration specifies that the true disparities must lie along particular epipolar lines, which can be easily computed from L, R and the current image position ~x <ref> [9] </ref>.
Reference: [10] <author> A. Jepson and M. Black. </author> <title> Mixture models for optical flow computation. </title> <booktitle> In Proc. of the DIMACS Workshop on Partitioning Data Sets, </booktitle> <address> Providence, RI, 1994. </address> <publisher> AMS Pub. </publisher>
Reference-contexts: A successful solution strategy must be robust to the presence of such outliers. 4 5 Mixture Model for Disparity For a robust solution we follow the mixture model approach described in <ref> [11, 10] </ref>. The idea is to consider the disparity ~ d (~x) as arising from one of several simple distributions.
Reference: [11] <author> A. Jepson and M. J. Black. </author> <title> Mixture models for optical flow computation. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition, CVPR-93, </booktitle> <pages> pages 760-761, </pages> <address> New York, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: A successful solution strategy must be robust to the presence of such outliers. 4 5 Mixture Model for Disparity For a robust solution we follow the mixture model approach described in <ref> [11, 10] </ref>. The idea is to consider the disparity ~ d (~x) as arising from one of several simple distributions.
Reference: [12] <author> D. Kim and R. Nevatia. </author> <title> Indoor navigation without a specific map. </title> <booktitle> In IAS-3, </booktitle> <pages> pages 268-277, </pages> <address> Pittsburgh, PA, </address> <year> 1993. </year>
Reference-contexts: In robotic applications this safety is usually expressed in terms of the robot being able to detect obstacles to its motion. Here we are concerned with the development of a stereo vision system capable of identifying safe places to move on a floor plane. Previous work <ref> [3, 1, 12] </ref> on this problem has taken the goal to be to identify obstacles on the 2D plane over which the robot is to move. What is tacitly assumed in the literature is that the floor plane itself is safe and can be traversed (for an exception, see [2]).
Reference: [13] <author> G.J. McLachlan and K.E. Basford. </author> <title> Mixture Models: Inference and Applications to Clustering. </title> <publisher> Marcel Dekker Inc., </publisher> <address> N.Y., </address> <year> 1988. </year> <title> Acknowledgments Funding for this work was provided, in part, by the ARK (Autonomous Robot for a Known environment) Project, which receives its funding from PRECARN Associates Inc., </title> <institution> Industry Canada, the National Research Council of Canada, Technology Ontario, Ontario Hydro Technologies, and Atomic Energy of Canada Limited. The authors also gratefully acknowledge the financial support of NSERC Canada. </institution> <month> 10 </month>
Reference-contexts: It is the probability that the j th constraint belongs to the n th component. These equations for a maximum likelihood fit have been derived by a number of authors; for further details see <ref> [13] </ref>. These equations suggest an iterative algorithm, known as the EM-algorithm [13], for obtaining a maximum likelihood fit for the parameters ~m and ~ k. Given an initial guess for these parameters, we first estimate the ownership probabilities q nj for each constraint belonging to each component. <p> It is the probability that the j th constraint belongs to the n th component. These equations for a maximum likelihood fit have been derived by a number of authors; for further details see <ref> [13] </ref>. These equations suggest an iterative algorithm, known as the EM-algorithm [13], for obtaining a maximum likelihood fit for the parameters ~m and ~ k. Given an initial guess for these parameters, we first estimate the ownership probabilities q nj for each constraint belonging to each component. This expectation step, or "E-step", simply involves evaluating (20). <p> This expectation step, or "E-step", simply involves evaluating (20). Next, the maximization step, or "M-step", maximizes L with these ownerships held fixed. The result is a simple iterative algorithm which is guaranteed to increase the log likelihood of its fit each iteration <ref> [13] </ref>. In the experiments discussed below we do not accurately locate a maximum value for ~ k during the M-step; instead we use only one iteration of Newton's method applied to equation (19b).
References-found: 13

