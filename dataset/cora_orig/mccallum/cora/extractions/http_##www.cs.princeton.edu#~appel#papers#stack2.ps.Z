URL: http://www.cs.princeton.edu/~appel/papers/stack2.ps.Z
Refering-URL: http://www.cs.princeton.edu/~appel/papers/
Root-URL: http://www.cs.princeton.edu
Title: An Empirical and Analytic Study of Stack vs. Heap Cost for Languages with Closures Overall,
Author: ANDREW W. APPEL ZHONG SHAO 
Address: Princeton NJ 08544-2087, U.S.A. 1  New Haven CT 06520-8285, U.S.A. 2  
Affiliation: Dept. of Computer Science, Princeton University,  Dept. of Computer Science, Yale University,  
Date: 1 (1): 1-000, January 1993  
Note: J. Functional Programming  c 1993 Cambridge University Press 1  ment efficiently and correctly.  
Abstract: We present a comprehensive analysis of all the components of creation, access, and disposal of heap-allocated and stack-allocated activation records. Among our results are: * Although stack frames are known to have a better cache read-miss rate than heap frames, our simple analytical model (backed up by simulation results) shows that the difference is too trivial to matter. * The cache write-miss rate of heap frames is very high; we show that a variety of miss-handling strategies (exemplified by specific modern machines) can give good per formance, but not all can. * Stacks restrict the flexibility of closure representations (for higher-order functions) in important (and costly) ways. * The extra load placed on the garbage collector by heap-allocated frames is small. * The demands of modern programming languages make stacks complicated to imple 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, Michael S. and Michael C. Becker. </author> <year> 1993 </year> <month> (February). </month> <title> Multiprocessing aspects of the PowerPC 601. </title> <booktitle> In IEEE COMPCON Spring '93, </booktitle> <pages> pages 117-126. </pages> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: It is more expensive to implement, since it requires a full tag (not just a valid bit) for each word. Diwan et al. found excellent memory subsystem performance for SML/NJ on this machine. Cache-line zero instruction: On some machines (e.g., IBM R/S 6000 (Hardell et al., 1990) and PowerPC <ref> (Allen and Becker, 1993) </ref>) a cache line (64 bytes) can be allocated and zeroed with a special instruction.
Reference: <author> Appel, Andrew W. and Trevor Jim. </author> <year> 1989. </year> <title> Continuation-passing, closure-passing style. </title> <booktitle> In Sixteenth ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pages 293-302, </pages> <address> New York. </address> <publisher> ACM Press. </publisher>
Reference-contexts: This provides empirical evidence for the claim that sizing the allocation space to fit into cache can improve performance." (Reppy, 1994) Unfortunately, the measurements in our current paper were made using the older two-generation collector <ref> (Appel, 1989) </ref>. <p> Compilers using continuation-passing style (such as Rabbit (Steele, 1978), Orbit (Kranz et al., 1986), and SML/NJ <ref> (Appel and Jim, 1989) </ref>) naturally initialize frames as soon as they are allocated, and then never write to them again. In effect, they save up any "changes" in registers, then dump everything out all at once.
Reference: <author> Appel, Andrew W. and Kai Li. </author> <year> 1991 </year> <month> (April). </month> <title> Virtual memory primitives for user programs. </title> <booktitle> In Fourth Int'l Conf. on Architectural Support for Programming Languages and Operating Systems (SIGPLAN Notices v. </booktitle> <volume> 26, no. 4), </volume> <pages> pages 96-107. </pages> <publisher> ACM Press. </publisher>
Reference-contexts: This table shows the proportion of frame allocations that are not in the same block as a non-frame allocation. The results shown are from measurements of ML benchmark programs (see Figure 2) as compiled by the Standard ML of New Jersey <ref> (Appel and MacQueen, 1991) </ref> compiler. Fig. 3. Shared limit checks basic block 1 as other (non-frame) allocations, which would require limit checks anyhow (see Figure 3). The actual cost is therefore 2 0:687 = 1:374. 2. The free-space pointer must be incremented. This costs one instruction. <p> We will now demonstrate that heap-allocated frames have adequate locality of reference in a small cache, if the read miss penalty is not too large and the write miss penalty is zero. 6.1 Write misses The Standard ML of New Jersey compiler <ref> (Appel and MacQueen, 1991) </ref> uses no stack; all frames are allocated on the garbage-collected heap. If any system should have poor cache locality, this is the one.
Reference: <author> Appel, Andrew W. and David B. MacQueen. </author> <year> 1991 </year> <month> (August). </month> <title> Standard ML of New Jersey. </title> <editor> In Wirsing, Martin, editor, </editor> <booktitle> Third Int'l Symp. on Prog. Lang. Implementation and Logic Programming, </booktitle> <pages> pages 1-13, </pages> <address> New York. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: This table shows the proportion of frame allocations that are not in the same block as a non-frame allocation. The results shown are from measurements of ML benchmark programs (see Figure 2) as compiled by the Standard ML of New Jersey <ref> (Appel and MacQueen, 1991) </ref> compiler. Fig. 3. Shared limit checks basic block 1 as other (non-frame) allocations, which would require limit checks anyhow (see Figure 3). The actual cost is therefore 2 0:687 = 1:374. 2. The free-space pointer must be incremented. This costs one instruction. <p> We will now demonstrate that heap-allocated frames have adequate locality of reference in a small cache, if the read miss penalty is not too large and the write miss penalty is zero. 6.1 Write misses The Standard ML of New Jersey compiler <ref> (Appel and MacQueen, 1991) </ref> uses no stack; all frames are allocated on the garbage-collected heap. If any system should have poor cache locality, this is the one.
Reference: <author> Appel, Andrew W. and Zhong Shao. </author> <year> 1992 </year> <month> (September). </month> <title> Callee-save registers in continuation-passing style. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 5 </volume> <pages> 189-219. </pages>
Reference-contexts: . .. . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . .. . . . . ..... ........... ........... ............ * * * Simulations of benchmark programs <ref> (Appel, 1992) </ref> running in direct-mapped D-cache of various sizes, with 10-cycle read miss penalty, no write miss penalty, and "infinite" I-cache. Left-hand-side shows write-allocate cache with partial fill; right-hand-side shows write-around cache. Vertical axis shows execution cycles in millions.
Reference: <author> Appel, Andrew W. </author> <year> 1987. </year> <title> Garbage collection can be faster than stack allocation. </title> <journal> Information Processing Letters, </journal> <volume> 25(4) </volume> <pages> 275-79. </pages> <note> 26 ANDREW W. </note> <author> APPEL and ZHONG SHAO . 1989. </author> <title> Simple generational garbage collection and fast allocation. </title> <journal> Software|Practice and Experience, </journal> 19(2):171-83. . 1992. Compiling with Continuations. Cambridge University Press. . 1994 (June). Emulating write-allocate on a no-write-allocate cache. Technical Report CS-TR-459-94, Princeton University. 
Reference-contexts: One might think that it would be expensive to allocate, at every procedure call, heap storage that becomes garbage on return. But not necessarily <ref> (Appel, 1987) </ref>: 1 E-mail: appel@princeton.edu. Supported in part by NSF Grant CCR-9200790. 2 E-mail: shao@cs.yale.edu. This work was done while the author was at Princeton University, supported in part by NSF Grant CCR-9200790. 2 ANDREW W.
Reference: <author> Asprey, Tom, Gregory S. Averill, Eric DeLano, Russ Mason, Bill Weiner, and Jeff Yetter. </author> <year> 1993 </year> <month> (June). </month> <title> Performance features of the PA7100 microprocessor. </title> <journal> IEEE Micro, </journal> <volume> 13(3). </volume>
Reference-contexts: This avoids the write miss, with a 0.687-instruction cost per frame. 8 Cache-control hint: On the HP PA7100, a store instruction can have a cache-control hint specifying that the block will be overwritten before being read; this avoids the read if the write misses <ref> (Asprey et al., 1993) </ref>. But these machines have very large primary caches anyway, so locality can be handled by generational collection.
Reference: <author> Augustsson, Lennart. </author> <year> 1989 </year> <month> (December). </month> <title> Garbage collection in the &lt; -; g &gt;-machine. </title> <type> Technical Report PMG memo 73, </type> <institution> Dept. of Computer Sciences, Chalmers University of Technology, Goteborg, Sweden. </institution>
Reference-contexts: Complicated descriptors It is possible to allow dead variables in frames and closures, if the garbage collector knows they are dead. This can be accomplished using special descriptors, which would reduce the "copying and sharing" penalty for stack frames. For example, in the Chalmers Lazy ML compiler <ref> (Augustsson, 1989) </ref> or the Gallium compiler (Leroy, 1992), associated with each return address is a descriptor telling which variables in the caller's frame are live after the return 5 . But this is not sufficient; heap closures still cannot point to stack frames.
Reference: <author> Baker, Henry G. </author> <year> 1976 </year> <month> (June). </month> <title> The buried binding and stale binding problems of LISP 1.5. </title> <note> unpublished, undistributed paper. </note>
Reference: <author> Cardelli, Luca. </author> <year> 1984. </year> <title> Compiling a functional language. </title> <booktitle> In 1984 Symp. on LISP and Functional Programming, </booktitle> <pages> pages 208-17, </pages> <address> New York. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Since the final result keeps N closures for different instantiations of h simultaneously|each with a different (large) value for the variable v|it requires O (N 2 ) space consumption instead of O (N ). 4 A flat closure <ref> (Cardelli, 1984) </ref> is a record that holds only the free variables needed by the function. 8 ANDREW W.
Reference: <author> Chase, David R. </author> <year> 1988. </year> <title> Safety considerations for storage allocation optimizations. </title> <booktitle> In Proc. ACM SIGPLAN '88 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 1-9. </pages> <publisher> ACM Press. </publisher>
Reference: <author> Clinger, William D., Anne H. Hartheimer, and Eric M. Ost. </author> <year> 1988 </year> <month> (June). </month> <title> Implementation strategies for continuations. </title> <booktitle> In 1988 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 124-131, </pages> <address> New York. </address> <publisher> ACM Press. </publisher>
Reference: <author> Danvy, Olivier. </author> <year> 1987 </year> <month> (June). </month> <title> Memory allocation and higher-order functions. </title> <booktitle> In Proceedings of the SIGPLAN'87 Symposium on Interpreters and Interpretive Techniques, </booktitle> <pages> pages 241-252. </pages> <publisher> ACM Press. Digital Equipment Corp. </publisher> <year> 1992 </year> <month> (October). </month> <title> DECchip(tm) 21064-AA Microprocessor Hardware Reference Manual. First edition. </title> <address> Maynard, MA. </address>
Reference: <author> Diwan, Amer, David Tarditi, and Eliot Moss. </author> <year> 1994. </year> <title> Memory subsystem performance of programs using copying garbage collection. </title> <booktitle> In Proc. 21st Annual ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, </booktitle> <pages> pages 1-14. </pages> <publisher> ACM Press. </publisher>
Reference-contexts: Thus, a write miss does not require reading the rest of the written cache line from memory. Subsequent (sequential) writes will fill the rest of the line. One-word cache line: The DECstation 5000 has a cache-line size of one word, but four lines are read on a miss <ref> (Diwan, Tarditi, and Moss, 1994) </ref>. For some applications this is better than sub-block placement, but for sequential writes it is equally good. It is more expensive to implement, since it requires a full tag (not just a valid bit) for each word.
Reference: <author> Doligez, Damien and Georges Gonthier. </author> <year> 1994 </year> <month> (March). </month> <title> Re: stack scanning for generational g.c. E-mail message &lt;9403041606.AA07877@lix.polytechnique.fr&gt;. </title>
Reference: <author> Duba, Bruce, Robert Harper, and David MacQueen. </author> <year> 1991 </year> <month> (Jan). </month> <title> Typing first-class continuations in ML. </title> <booktitle> In Eighteenth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 163-73, </pages> <address> New York. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Stack vs. Heap Cost 23 9 First-class continuations The notion of "first class continuations" using the call-with-current-continuation (call/cc) primitive originated in the Scheme language (Rees and Clinger, 1986) and has since been adopted in other systems as well <ref> (Duba, Harper, and Mac-Queen, 1991) </ref>. First class continuations are useful for implementing coroutines (Wand, 1980), concurrency libraries (Reppy, 1991) and multitasking.
Reference: <author> Hanson, David R. </author> <year> 1980. </year> <title> A portable storage management system for the Icon programming language. </title> <journal> Software|Practice and Experience, </journal> <volume> 10 </volume> <pages> 489-500. </pages>
Reference-contexts: The version shown as Ordinary Heap in Figure 4, allocates all frames and closures 3 Some implementations use a BIBOP (BIg Bag Of Pages <ref> (Hanson, 1980) </ref>) scheme that allocates each kind of object in a different contiguous space, so that only one g.c.- descriptor is required per space, instead of per object. This requires a free-space pointer and a limit pointer per space. 6 ANDREW W.
Reference: <author> Hanson, Chris. </author> <year> 1990 </year> <month> (June). </month> <title> Efficient stack allocation for tail-recursive languages. </title> <booktitle> In 1990 ACM Conference on Lisp and Fucntional Programming, </booktitle> <pages> pages 106-118, </pages> <address> New York. </address> <publisher> ACM Press. </publisher>
Reference-contexts: In particular, most conventional stack implementations are not safe for space complexity. 2. To preserve space complexity and correctly implement tail recursion, certain activation records require a complicated scheme to determine when they must be popped <ref> (Hanson, 1990) </ref>. (Or these frames could be heap allocated, even in a stack discipline; but they must be identified by static analysis.) 3. A high-water mark must be maintained to achieve efficiency in the genera tional collector. 4.
Reference: <author> Hardell, William R., Dwain A. Hicks, Lawrence C. Howell, Warren E. Maule, Robert Mon-toye, and David P. Tuttle. </author> <year> 1990. </year> <title> Data cache and storage control units. </title> <booktitle> In IBM RISC System/6000 Technology, </booktitle> <pages> pages 44-50. </pages> <institution> IBM. </institution>
Reference-contexts: It is more expensive to implement, since it requires a full tag (not just a valid bit) for each word. Diwan et al. found excellent memory subsystem performance for SML/NJ on this machine. Cache-line zero instruction: On some machines (e.g., IBM R/S 6000 <ref> (Hardell et al., 1990) </ref> and PowerPC (Allen and Becker, 1993)) a cache line (64 bytes) can be allocated and zeroed with a special instruction.
Reference: <author> Hieb, Robert, R. Kent Dybvig, and Carl Bruggeman. </author> <year> 1990. </year> <title> Representing control in the presence of first-class continuations. </title> <booktitle> In Proc. ACM SIGPLAN '90 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 66-77, </pages> <address> New York. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Let us compare the implementation complexities of heaps vs. stacks, in a garbage-collected environment: 13 "Unfortunately, it has been our experience that memory exceptions are not a tenable means for detecting stack overflow...." <ref> (Hieb, Dybvig, and Bruggeman, 1990) </ref> 24 ANDREW W. APPEL and ZHONG SHAO Implementation of Heap Frames 1. To achieve good performance with heap frames, it is necessary to have an sophisticated algorithm to choose closure representations. <p> A high-water mark must be maintained to achieve efficiency in the genera tional collector. 4. If call/cc is to be supported, then stack copying or some more complicated technique must be implemented <ref> (Hieb, Dybvig, and Bruggeman, 1990) </ref>. 5. To avoid having a descriptor in each frame, the runtime system must maintain a mapping of return addresses to frame layout descriptors. 6. In a system with multiple threads, each thread must have its own stack.
Reference: <author> Hill, Mark D. </author> <year> 1988 </year> <month> (December). </month> <title> A case for direct-mapped caches. </title> <journal> IEEE Computer, </journal> <volume> 21(12) </volume> <pages> 25-40. </pages>
Reference-contexts: We simulated direct-mapped caches of sizes ranging from 2 kbytes to 2 Mbytes, with a 32-byte line size. Most modern machines have direct-mapped caches especially at the first level of the memory hierarchy, so that tag comparison can be overlapped with further computations on the value fetched <ref> (Hill, 1988) </ref>.
Reference: <author> Jones, Richard. </author> <year> 1992. </year> <title> Tail recursion without space leaks. </title> <journal> Journal of Functional Programming, </journal> <volume> 2(1) </volume> <pages> 73-79. </pages>
Reference: <author> Jouppi, Norman P. </author> <year> 1993 </year> <month> (May). </month> <title> Cache write policies and performance. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 191-201. </pages> <note> ACM Press. Stack vs. Heap Cost 27 Kranz, </note> <author> D., R. Kelsey, J. Rees, P. Hudak, J. Philbin, and N. Adams. </author> <year> 1986 </year> <month> (July). </month> <title> ORBIT: An optimizing compiler for Scheme. </title> <booktitle> SIGPLAN Notices (Proc. Sigplan '86 Symp. on Compiler Construction), </booktitle> <volume> 21(7) </volume> <pages> 219-33. </pages>
Reference-contexts: Many modern machines have a zero write-miss penalty, especially for their primary caches <ref> (Jouppi, 1993) </ref>. Simulating machines with a high write-miss penalty, Diwan et al. found that SML/NJ performs badly, as might be expected. Thus: on machines with a zero write-miss penalty, the average cost per frame of write misses is zero. <p> Indeed, this is not true of all machines: the VAX 11/780 and VAX 8800 do write-around, bypassing the primary cache on write misses (causing subsequent read misses); and most pre-1993 designs do fetch-on-write, stalling the processor on a write miss <ref> (Jouppi, 1993) </ref>. In fact, the bad performance of garbage-collected systems on machines with a write-miss penalty is a good reason not to build such machines. Finally, note that a write-miss penalty on large caches is not particularly problematic; as explained above, generational garbage collection solves that problem.
Reference: <author> Kranz, David. </author> <year> 1987. </year> <title> ORBIT: An optimizing compiler for Scheme. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <address> New Haven, CT. </address>
Reference-contexts: Shao and Appel (1994) describe an implementation of such an algorithm, which is not particularly hairy. 2. To avoid having a descriptor in each frame, the runtime system can maintain a mapping of return addresses to frame layout descriptors. Kranz's orbit compiler used this technique <ref> (Kranz, 1987) </ref>. Standard ML of New Jersey does not bother, so it does indeed pay the price of a descriptor in each frame. Implementation of Stacks 1. A good closure analysis algorithm must be used to preserve space complexity while still trying to avoid too much copying.
Reference: <author> Leroy, Xavier. </author> <year> 1992 </year> <month> (January). </month> <title> Unboxed objects and polymorphic typing. </title> <booktitle> In Nineteenth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 177-188, </pages> <address> New York. </address> <publisher> ACM Press. </publisher>
Reference-contexts: This can be accomplished using special descriptors, which would reduce the "copying and sharing" penalty for stack frames. For example, in the Chalmers Lazy ML compiler (Augustsson, 1989) or the Gallium compiler <ref> (Leroy, 1992) </ref>, associated with each return address is a descriptor telling which variables in the caller's frame are live after the return 5 . But this is not sufficient; heap closures still cannot point to stack frames.
Reference: <author> Rees, J. and W. Clinger. </author> <year> 1986. </year> <title> Revised report on the algorithmic language Scheme. </title> <journal> SIGPLAN Notices, </journal> <volume> 21(12) </volume> <pages> 37-79. </pages>
Reference-contexts: Stack vs. Heap Cost 23 9 First-class continuations The notion of "first class continuations" using the call-with-current-continuation (call/cc) primitive originated in the Scheme language <ref> (Rees and Clinger, 1986) </ref> and has since been adopted in other systems as well (Duba, Harper, and Mac-Queen, 1991). First class continuations are useful for implementing coroutines (Wand, 1980), concurrency libraries (Reppy, 1991) and multitasking.
Reference: <author> Reinhold, Mark B. </author> <year> 1994 </year> <month> (June). </month> <title> Cache performance of garbage-collected programs. </title> <booktitle> In Proc. SIGPLAN '94 Symp. on Prog. Language Design and Implementation, </booktitle> <pages> pages 206-217. </pages> <publisher> ACM Press. </publisher>
Reference: <author> Reppy, John H. </author> <year> 1991. </year> <title> CML: A higher-order concurrent language. </title> <booktitle> In Proc. ACM SIGPLAN '91 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 293-305. </pages> <publisher> ACM Press. </publisher> . <year> 1994 </year> <month> (January). </month> <title> A high-performance garbage collector for Standard ML. </title> <type> Technical memorandum, </type> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, NJ. </address>
Reference-contexts: First class continuations are useful for implementing coroutines (Wand, 1980), concurrency libraries <ref> (Reppy, 1991) </ref> and multitasking. But call/cc is much harder to implement efficiently if there is a stack; with an ordinary contiguous stack implementation, the entire stack must be copied on each creation or invocation of a first-class continuation.
Reference: <author> Runciman, Colin and David Wakeling. </author> <year> 1993 </year> <month> (April). </month> <title> Heap profiling of lazy functional programs. </title> <journal> Journal of Functional Programming, </journal> <volume> 3(2) </volume> <pages> 217-246. </pages>
Reference: <author> Shao, Zhong and Andrew W. Appel. </author> <year> 1994. </year> <title> Space-efficient closure representations. </title> <booktitle> In Proc. 1994 ACM Conf. on Lisp and Functional Programming, </booktitle> <pages> pages 150-161. </pages> <publisher> ACM Press. </publisher>
Reference-contexts: But if all activation records are heap-allocated, then closures may point at them. This flexibility allows the closure analysis phase of a good compiler to choose much better (smaller, shallower) representations for closures, with more sharing and less copying <ref> (Shao and Appel, 1994) </ref>. The restriction that heaps cannot point to stacks must be counted as a "cost" of using stack-allocated frames. <p> The restriction that heaps cannot point to stacks must be counted as a "cost" of using stack-allocated frames. To quantify this cost, we measured two versions of the Standard ML of New Jersey compiler (Appel and MacQueen, 1991; Appel, 1992) outfitted with our recently improved closure-representation analysis phase <ref> (Shao and Appel, 1994) </ref>.
Reference: <author> Steele, Guy L. </author> <year> 1978. </year> <title> Rabbit: a compiler for Scheme. </title> <type> Technical Report AI-TR-474, </type> <institution> MIT, </institution> <address> Cambridge, MA. </address>
Reference-contexts: Compilers using continuation-passing style (such as Rabbit <ref> (Steele, 1978) </ref>, Orbit (Kranz et al., 1986), and SML/NJ (Appel and Jim, 1989)) naturally initialize frames as soon as they are allocated, and then never write to them again. In effect, they save up any "changes" in registers, then dump everything out all at once.
Reference: <author> Stefanovic, Darko and J. Eliot B. Moss. </author> <year> 1994. </year> <title> Characterization of object behaviour in Standard ML of New Jersey. </title> <booktitle> In Proc. 1994 ACM Conf. on Lisp and Functional Programming, </booktitle> <pages> pages 43-54. </pages> <note> ACM Press. </note> <institution> System Performance Evaluation Corp. </institution> <year> 1989 </year> <month> (October). </month> <title> SPEC Benchmark Suite Release 1.0. </title>
Reference-contexts: The collector itself helps to improve the locality of reference of the mutator. Thus, locality of reference in a large cache is basically a solved problem. Furthermore, activation records die especially young. It will be extremely rare for an activation record to be promoted to a higher generation <ref> (Stefanovic and Moss, 1994) </ref>. Since only the higher generations can cause cache misses 6 , heap-allocated frames will (almost) never cause cache misses.
Reference: <author> Ungar, David M. </author> <year> 1986. </year> <title> The Design and Evaluation of a High Performance Smalltalk System. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: The last column has references to the section number (in this paper) of the explanation of each component. In the last row, N is the stack depth; X is the size of one stack chunk. Fig. 1. Cost breakdown of different frame allocation strategies modern generational garbage-collection algorithms <ref> (Ungar, 1986) </ref> can reclaim dead frames efficiently, as cheap as the one-instruction cost to pop the stack. But there are other costs involved in creating, accessing, and destroying activation records|whether on a heap or a stack. <p> The analysis of cache behavior of garbage collected systems differs qualitatively depending on the size of the cache. Large Caches For large (e.g., secondary) caches, a generational garbage collection algorithm <ref> (Ungar, 1986) </ref> can keep its youngest generation entirely within the cache (Wilson, Lam, and Moher, 1992; Zorn, 1991). Only the (rare) objects that survive a collection (or two) will be promoted into an older generation where they can cause cache misses.
Reference: <author> Wand, Mitchell. </author> <year> 1980 </year> <month> (August). </month> <title> Continuation-based multiprocessing. </title> <booktitle> In Conf. Record of the 1980 Lisp Conf., </booktitle> <pages> pages 19-28, </pages> <address> New York. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Heap Cost 23 9 First-class continuations The notion of "first class continuations" using the call-with-current-continuation (call/cc) primitive originated in the Scheme language (Rees and Clinger, 1986) and has since been adopted in other systems as well (Duba, Harper, and Mac-Queen, 1991). First class continuations are useful for implementing coroutines <ref> (Wand, 1980) </ref>, concurrency libraries (Reppy, 1991) and multitasking. But call/cc is much harder to implement efficiently if there is a stack; with an ordinary contiguous stack implementation, the entire stack must be copied on each creation or invocation of a first-class continuation.
Reference: <author> Wilson, Paul R., Michael S. Lam, and Thomas G. Moher. </author> <year> 1992 </year> <month> (June). </month> <title> Caching considerations for generational garbage collection. </title> <booktitle> In 1992 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 32-42, </pages> <address> New York. </address> <publisher> ACM Press. </publisher>
Reference: <author> Wilson, Paul R. </author> <year> 1991 </year> <month> (March). </month> <title> Some issues and strategies in heap management and memory hierarchies. </title> <journal> SIGPLAN Notices, </journal> <volume> 26(3) </volume> <pages> 45-52. </pages>
Reference-contexts: But there is a complication. Between collections, if the "high-water" frame is popped, the mark must be moved down to the next-lower frame <ref> (Wilson, 1991) </ref>. 22 ANDREW W. APPEL and ZHONG SHAO The simplest way to do this would be to test for the mark on every return, but this would be expensive. Instead, the mark consists of a "special" return address, which replaces the real return address of a frame.
Reference: <author> Zorn, Benjamin. </author> <year> 1991 </year> <month> (May). </month> <title> The effect of garbage collection on cache performance. </title> <type> Technical Report CU-CS-528-91, </type> <institution> University of Colorado, Boulder, CO. </institution>
References-found: 37

