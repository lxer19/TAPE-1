URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-93-42.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Experimental Implementation of Dynamic Access Ordering  
Author: Sally A. McKee, Robert H. Klenke, Andrew J. Schwab, Wm. A. Wulf, Steven A. Moyer, James H. Aylor, Charles Y. Hitchcock 
Note: This work was supported in part by a grant from Intel Supercomputer Division and by NSF grants MIP-9114110 and MIP 9307626.  
Abstract: Computer Science Report No. CS-93-42 August 1, 1993 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Baer, J. L., Chen, T. F., </author> <title> An Effective On-Chip Preloading Scheme To Reduce Data Access Penalty, </title> <address> Supercomputing91, </address> <month> November, </month> <year> 1991. </year>
Reference: [2] <author> Baron, R.L., and Higbie, L., </author> <title> Computer Architecture, </title> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference: [3] <author> Carr, S., Kennedy, K., </author> <title> Blocking Linear Algebra Codes for Memory Hierarchies, </title> <booktitle> Proc. Fourth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <year> 1989. </year>
Reference: [4] <author> Callahan, D., et. al., </author> <title> Software Prefetching, </title> <booktitle> Fourth International Conference on Architectural Support for Programming Languages and Systems, </booktitle> <month> April, </month> <year> 1991. </year>
Reference: [5] <author> Davidson, J.W., and Benitez, </author> <title> M.E., Code Generation for Streaming: An Access/Execute Mechanism, </title> <booktitle> Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> April, </month> <year> 1991. </year>
Reference-contexts: Nonetheless, the compiler can employ Davidson and Benitezs recurrence detection and optimization algorithm <ref> [5] </ref> to generate streaming code: each computed value is retained in a register so that it will be available for use as on the following iteration. <p> Another advantage is that this combined hardware/software scheme doesnt require heroic compiler technology the compiler need only detect the presence of streams, and Davidson and Benitezs streaming algorithm <ref> [5] </ref> can be used to do this. Note that the compiler is responsible for detecting data dependences. 4.
Reference: [6] <author> Dongarra, et. al., </author> <title> Linpack Users Guide, </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1979. </year>
Reference: [7] <author> Fu, J. W. C., and Patel, J. H., </author> <title> Data Prefetching in Multiprocessor Vector Cache Memories, </title> <booktitle> 18th International Symposium on Computer Architecture, </booktitle> <month> May, </month> <year> 1991. </year>
Reference: [8] <author> Goodman, J. R., et al, </author> <title> PIPE: A VLSI Decoupled Architecture, </title> <booktitle> Twelfth International Symposium on Computer Architecture, </booktitle> <month> June, </month> <year> 1985. </year>
Reference: [9] <author> Gupta, R., and Soffa, M., </author> <title> Compile-time Techniques for Efficient Utilization of Parallel Memories, </title> <journal> SIGPLAN Not., </journal> <volume> 23, 9, </volume> <year> 1986. </year>
Reference-contexts: To get the best performance out of such a system, we must take advantage of the architectures available concurrency. There are a number of hardware and software techniques that can help manage the imbalance between processor and memory speeds. These include altering the placement of data to exploit concurrency <ref> [9] </ref>, reordering the computation to increase locality (as in blocking [17]), address transformations for conict-free access to interleaved memory [10][26][31], software prefetching data to the cache [4][16][29], and hardware prefetching vector data to cache [1][7][14][27].
Reference: [10] <author> Harper, D. T., </author> <title> Address Transformation to Increase Memory Performance, </title> <booktitle> 1989 International Conference on Supercomputing. </booktitle>
Reference: [11] <author> Hayes, J.P., </author> <title> Computer Architecture and Organization, </title> <publisher> McGraw-Hill, </publisher> <year> 1988. </year>
Reference-contexts: Hitchcock Dartmouth College Authors addresses: -mckee, klenke, ajs, wulf, jha-@virginia.edu, moyer@mathcs.emory.edu. Appeared in Proc. 27th Hawaii International Conference on Systems Sciences (HICSS-27), Maui, HI, January 1994. 2 time that gave rise to the term RAM, for Random Access Memory. Many computer architecture textbooks ([2] and <ref> [11] </ref> among them) specifically cultivate this view. Others skirt the issue entirely [19][30]. Somewhat ironically, the assumption no longer applies to modern memory devices: most components manufactured in the last 10-15 years provide special capabilities that make it possible to perform some access sequences faster than others.
Reference: [12] <author> High-speed DRAMs, </author> <title> Special Report, </title> <journal> IEEE Spectrum, </journal> <volume> vol. 29, no. 10, </volume> <month> October, </month> <year> 1992. </year> <title> [13] i860 XP Microprocessor Data Book, </title> <publisher> Intel Corporation, </publisher> <year> 1991. </year>
Reference-contexts: Other common devices offer similar features, such as nibble-mode, static column mode, or a small amount of SRAM cache on chip. This sensitivity to the order of requests is exacerbated in several emerging technologies: for instance, Rambus [25], Ramlink, and the new DRAM designs with high-speed sequential interfaces <ref> [12] </ref> provide high bandwidth for large transfers, but offer little performance benefit for single-word accesses. For multiple-module memory systems, the order of requests is important on yet another level: successive accesses to the same memory bank cannot be performed as quickly as accesses to different banks.
Reference: [14] <author> Jouppi, N., </author> <title> Improving Direct-Mapped Cache Performance by the Addition of a Small Fully Associative Cache and Prefetch Buffers, </title> <booktitle> 17th International Symposium on Computer Architecture, </booktitle> <month> May, </month> <year> 1990. </year>
Reference: [15] <author> Katz, R., and Hennessy, J., </author> <title> High Performance Microprocessor Architectures, </title> <institution> University of California, Berkeley, </institution> <note> Report No. UCB/CSD 89/529, </note> <month> August, </month> <year> 1989. </year>
Reference-contexts: 1. Increasing vector memory bandwidth Processor speeds are increasing much faster than memory speeds: microprocessor performance has increased by 50-100% per year in the last decade, while DRAM performance has risen only 10-15% each year <ref> [15] </ref>. As a result, memory bandwidth is becoming the limiting performance factor for many applications, particularly scientific computations.
Reference: [16] <author> Klaiber, A., et. al., </author> <title> An Architecture for Software-Controlled Data Prefetching, </title> <booktitle> 18th International Symposium on Computer Architecture, </booktitle> <month> May, </month> <year> 1991. </year>
Reference: [17] <author> Lam, Monica, et. al., </author> <title> The Cache Performance and Optimizations of Blocked Algorithms, </title> <booktitle> Fourth International Conference on Architectural Support for Programming Languages and Systems, </booktitle> <month> April, </month> <year> 1991. </year>
Reference-contexts: There are a number of hardware and software techniques that can help manage the imbalance between processor and memory speeds. These include altering the placement of data to exploit concurrency [9], reordering the computation to increase locality (as in blocking <ref> [17] </ref>), address transformations for conict-free access to interleaved memory [10][26][31], software prefetching data to the cache [4][16][29], and hardware prefetching vector data to cache [1][7][14][27].
Reference: [18] <editor> Lawson, et. al., </editor> <title> Basic Linear Algebra Subprograms for Fortran Usage, </title> <journal> ACM Trans. Math. Soft., </journal> <volume> 5, 3, </volume> <year> 1979. </year>
Reference: [19] <author> Maccabe, </author> <title> A.B., Computer Systems: Architecture, Organization, and Programming, </title> <editor> Richard D. Irwin, </editor> <publisher> Inc., </publisher> <year> 1993. </year>
Reference: [20] <author> McCarty, D., </author> <title> Tackling FIFO Design with FPGAs, </title> <type> ASIC & EDA, </type> <month> September, </month> <year> 1992. </year>
Reference-contexts: In order to provide the exibility necessary to explore performance ramifications of different FIFO configurations, we have adopted a virtual FIFO scheme using an internal dual-ported SRAM (DP-SRAM) for storage <ref> [20] </ref>. The depth and number of FIFOs is thus limited only by the size of the implemented DP-SRAM.
Reference: [21] <author> McMahon, F.H., </author> <title> The Livermore Fortran Kernels: </title> <booktitle> A Appeared in Proc. 27th Hawaii International Conference on Systems Sciences (HICSS-27), </booktitle> <address> Maui, HI, </address> <month> January </month> <year> 1994. </year> <title> 10 Computer Test of the Numerical Performance Range, </title> <institution> Lawrence Livermore National Laboratory, UCRL-53745, </institution> <month> December, </month> <year> 1986. </year>
Reference-contexts: Results reported here are for the four kernels described in Figure 4. Daxpy and swap are from the BLAS (Basic Linear Algebra Subroutines) [6][18], tridiag is the fifth Livermore Loop <ref> [21] </ref>, and vaxpy is a vector axpy 1 computation that occurs in matrix-vector multiplication by diagonals. These benchmarks were selected because they are representative of the access patterns found in real scientific codes, including the inner-loops of blocked algorithms.
Reference: [22] <author> McKee, S.A, </author> <title> Hardware Support for Access Ordering: Performance of Some Design Options, </title> <institution> University of Virginia, Department of Computer Science, </institution> <type> Technical Report CS-93-08, </type> <month> April, </month> <year> 1993. </year>
Reference-contexts: Only representative examples of our results are given here; complete results (over 7000 simulations for varying benchmarks and memory systems) can be found in <ref> [22] </ref>. The simulations here use 10,000-element vectors aligned to have no DRAM pages in common, and starting in the same bank. Arithmetic and control are assumed never to be a computational bottleneck, thus we model the processor as a generator of load and store requests only. <p> As noted, these results are for vectors of 10,000 doubleword elements. SMC performance for shorter vectors is not as dramatic, since there are fewer stream elements over which to amortize the cost of the DRAM page misses. Nonetheless, shorter vector computations still benefit significantly from an SMC <ref> [22] </ref>. On the basis of our numerous simulations, we deem the SMC concept worthy of further exploration. Simulation is a useful tool, but the real test of any idea lies in the implementation. Thus we are designing and building an experimental SMC board. 5.
Reference: [23] <author> Moyer, S.A., </author> <title> Access Ordering and Effective Memory Bandwidth, </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science, University of Virginia, </institution> <type> Technical Report CS-93-18, </type> <month> April, </month> <year> 1993. </year>
Reference-contexts: Moyer provides a thorough analysis of the performance and limitations of compile-time access ordering <ref> [23] </ref>. In light of both the impact of access ordering on effective memory bandwidth and the limitations inherent in implementing the technique statically, it makes sense to consider an implementation that reorders accesses dynamically at run time. We explore one such scheme in the remainder of this paper. 3.
Reference: [24] <author> Quinnell, R., </author> <title> High-speed DRAMs, </title> <type> EDN, </type> <month> May 23, </month> <year> 1991. </year>
Reference-contexts: Somewhat ironically, the assumption no longer applies to modern memory devices: most components manufactured in the last 10-15 years provide special capabilities that make it possible to perform some access sequences faster than others. For instance, nearly all current DRAMs implement a form of page-mode operation <ref> [24] </ref>. These devices behave as if implemented with a single on-chip cache line, or page (this should not be confused with a virtual memory page). A memory access falling outside the address range of the current DRAM page forces a new page to be accessed.
Reference: [25] <institution> Architectural Overview, Rambus Inc., Mountain View, </institution> <address> CA, </address> <year> 1992. </year>
Reference-contexts: Other common devices offer similar features, such as nibble-mode, static column mode, or a small amount of SRAM cache on chip. This sensitivity to the order of requests is exacerbated in several emerging technologies: for instance, Rambus <ref> [25] </ref>, Ramlink, and the new DRAM designs with high-speed sequential interfaces [12] provide high bandwidth for large transfers, but offer little performance benefit for single-word accesses.
Reference: [26] <author> Rau, B. R., </author> <title> Pseudo-Randomly Interleaved Memory, </title> <booktitle> 18th International Symposium on Computer Architecture, </booktitle> <month> May, </month> <year> 1991. </year>
Reference: [27] <author> Sklenar, Ivan, </author> <title> Prefetch Unit for Vector Operation on Scalar Computers, </title> <journal> Computer Architecture News, </journal> <volume> 20, 4, </volume> <month> September, </month> <year> 1992. </year>
Reference: [28] <author> Smith, J. E., et al, </author> <title> The ZS-1 Central Processor, </title> <booktitle> The Second International Conference on Architectural Support for Programming Languages and Systems, </booktitle> <month> October, </month> <year> 1987. </year>
Reference: [29] <author> Sohi, G. and Manoj, F., </author> <title> High Bandwidth Memory Systems for Superscalar Processors, </title> <booktitle> Fourth International Conference on Architectural Support for Programming Languages and Systems, </booktitle> <month> April, </month> <year> 1991. </year>
Reference: [30] <editor> Tomek, I., </editor> <booktitle> The Foundations of Computer Architecture and Organization, </booktitle> <publisher> Computer Science Press, </publisher> <year> 1990. </year>
Reference: [31] <author> Valero, M., et. al., </author> <title> Increasing the Number of Strides for Conict-Free Vector Access, </title> <booktitle> 19th International Symposium on Computer Architecture, </booktitle> <month> May, </month> <year> 1992. </year>
Reference: [32] <author> Wolfe, M., </author> <title> Optimizing Supercompilers for Supercomputers, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference: [33] <author> Wulf, W. A., </author> <title> Evaluation of the WM Architecture, </title> <booktitle> 19th Annual International Symposium on Computer Architecture, </booktitle> <month> May, </month> <year> 1992. </year>
Reference-contexts: This organization is both simple and practical from an implementation standpoint: similar designs have been built. In fact, the organization is almost identical to the stream units of the WM architecture <ref> [33] </ref>, or may be thought of as a special case of a decoupled access-execute architecture [8][28].
References-found: 32

