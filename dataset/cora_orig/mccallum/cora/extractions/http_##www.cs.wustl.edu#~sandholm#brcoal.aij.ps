URL: http://www.cs.wustl.edu/~sandholm/brcoal.aij.ps
Refering-URL: http://www.cs.wustl.edu/~sandholm/
Root-URL: 
Email: sandholm@cs.wustl.edu  lesser@cs.umass.edu  
Title: Coalitions among Computationally Bounded Agents  
Author: Tuomas W. Sandholm Victor R. Lesser 
Keyword: Abbreviated title: Coalitions among Computationally Bounded Agents  
Address: One Brookings Drive, Campus Box 1045, St. Louis, MO 63130-4899  Amherst, MA 01003  
Affiliation: Washington University, Department of Computer Science  University of Massachusetts at Amherst, Department of Computer Science  
Abstract: This paper analyzes coalitions among self-interested agents that need to solve combinatorial optimization problems to operate efficiently in the world. By colluding (coordinating their actions by solving a joint optimization problem) the agents can sometimes save costs compared to operating individually. A model of bounded rationality is adopted where computation resources are costly. It is not worthwhile solving the problems optimally: solution quality is decision-theoretically traded off against computation cost. A normative, application- and protocol-independent theory of coalitions among bounded-rational agents is devised. The optimal coalition structure and its stability are significantly affected by the agents' algorithms' performance profiles and the cost of computation. This relationship is first analyzed theoretically. Then a domain classification including rational and bounded-rational agents is introduced. Experimental results are presented in vehicle routing with real data from five dispatch centers. This problem is N P-complete and the instances are so large that|with current technology|any agent's rationality is bounded by computational complexity. 1 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Aumann. </author> <title> Acceptable points in general cooperative n-person games. volume IV 39 of Contributions to the Theory of Games. </title> <publisher> Princeton University Press, </publisher> <year> 1959. </year>
Reference-contexts: It guarantees stability in the sense that no agent alone is motivated to deviate by changing its strategy given that others do not deviate. Often the Nash equilibrium is too weak because subgroups of agents can deviate in a coordinated manner. The Strong Nash equilibrium <ref> [1] </ref> is a solution concept for NFGs that guarantees more stability. It requires that there is no subgroup that can deviate by changing their strategies jointly in a manner that increases the payoff of all of its members given that nonmembers do not deviate from the original solution. <p> research. 16 On the other hand, results with strategic solution concepts are specific to a given interaction protocol while core-based analyses are not (unless the coalition formation process itself affects the payoffs). 26 7 Related research on computational coalition for- mation Coalition formation has been widely studied in game theory <ref> [20, 2, 3, 1, 56, 32] </ref>, and only the most relevant concepts were presented. Many of the solution concepts for coalition formation are static. They address the question of how to divide the payoffs among agents. Some of them also address the question of which coalition structure should form.
Reference: [2] <author> B. D. Bernheim, B. Peleg, and M. D. Whinston. </author> <title> Coalition-proof Nash equilibria: I concepts. </title> <journal> Journal of Economic Theory, </journal> <volume> 42(1) </volume> <pages> 1-12, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: The Strong Nash equilibrium is often too strong a solution concept: in many games no such equilibria exist. Recently, the Coalition-Proof Nash equilibrium <ref> [2, 3] </ref> for NFGs has been suggested as a partial remedy to the nonexistence problem of the Strong Nash equilibrium. <p> research. 16 On the other hand, results with strategic solution concepts are specific to a given interaction protocol while core-based analyses are not (unless the coalition formation process itself affects the payoffs). 26 7 Related research on computational coalition for- mation Coalition formation has been widely studied in game theory <ref> [20, 2, 3, 1, 56, 32] </ref>, and only the most relevant concepts were presented. Many of the solution concepts for coalition formation are static. They address the question of how to divide the payoffs among agents. Some of them also address the question of which coalition structure should form.
Reference: [3] <author> B. D. Bernheim and M. D. Whinston. </author> <title> Coalition-proof Nash equilibria: II applications. </title> <journal> Journal of Economic Theory, </journal> <volume> 42(1) </volume> <pages> 13-29, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: The Strong Nash equilibrium is often too strong a solution concept: in many games no such equilibria exist. Recently, the Coalition-Proof Nash equilibrium <ref> [2, 3] </ref> for NFGs has been suggested as a partial remedy to the nonexistence problem of the Strong Nash equilibrium. <p> research. 16 On the other hand, results with strategic solution concepts are specific to a given interaction protocol while core-based analyses are not (unless the coalition formation process itself affects the payoffs). 26 7 Related research on computational coalition for- mation Coalition formation has been widely studied in game theory <ref> [20, 2, 3, 1, 56, 32] </ref>, and only the most relevant concepts were presented. Many of the solution concepts for coalition formation are static. They address the question of how to divide the payoffs among agents. Some of them also address the question of which coalition structure should form.
Reference: [4] <author> M. Boddy and T. Dean. </author> <title> Deliberation scheduling for problem solving in time-constrained environments. </title> <journal> Artificial Intelligence, </journal> <volume> 67 </volume> <pages> 245-285, </pages> <year> 1994. </year>
Reference-contexts: The design-to-time framework is used instead of the anytime framework <ref> [43, 4, 17, 58] </ref> because to devise a normative theory of self-interested agents, the possibility that they design their algorithms to time has to be accounted for.
Reference: [5] <editor> A. H. Bond and L. Gasser. </editor> <booktitle> Readings in Distributed Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: Such self-interest naturally prevails in negotiations among independent businesses or individuals. In building computer support for coalition formation in such settings, the issue of self-interest has to be dealt with. In cooperative distributed problem solving <ref> [7, 5] </ref>, the system designer imposes an interaction protocol 2 and a strategy (a mapping from state history to action; a way to use the protocol) for each agent. <p> The approach is usually descriptive: the main question is what social outcomes follow given the protocol and assuming that the agents use the imposed strategies. On the other hand, in multiagent systems <ref> [34, 23, 5, 47, 41, 44] </ref>, the agents are provided with an interaction protocol, but each agent will choose its own strategy. A self-interested agent will choose the best strategy for itself, which cannot be explicitly imposed from outside.
Reference: [6] <author> A. Charnes and K. O. Kortanek. </author> <title> On balanced sets, cores, and linear programming. </title> <type> Technical Report 12, </type> <institution> Cornell Univ., Dept. of Industrial Eng. and Operations Res., </institution> <address> Ithaca, NY, </address> <year> 1966. </year>
Reference-contexts: In domains that are not BRSUB, the BRC is sometimes empty. The condition C 6= ; can be converted into necessary and sufficient conditions on the v R S values in games where the grand coalition maximizes social welfare <ref> [51, 6] </ref>. We convert the condition BRC (c comp ) 6= ; into conditions on the v S (c comp ) values analogously. Let B 1 ; :::; B p be distinct, nonempty, proper subsets of A. <p> Furthermore, this set of inequalities is minimal: no smaller set is sufficient [analogous to <ref> [6] </ref>]. Example. <p> Shapley [51] proved the following fact (his Theorem 3) for rational agents. In a superadditive game, C 6= ; iff for every proper minimal balanced set B = fB 1 ; :::; B p g; j=1 j v R A . Charnes and Kortanek <ref> [6] </ref> proved that this set of inequalities is minimal. Theorem 4.3 follows by analogy. 2 Proof. (Theorem 4.4).
Reference: [7] <author> E. Durfee, V. Lesser, and D. Corkill. </author> <title> Cooperative distributed problem solving. </title> <editor> In A. Barr, P. Cohen, and E. Feigenbaum, editors, </editor> <booktitle> The Handbook of Artificial Intelligence, volume IV. </booktitle> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Such self-interest naturally prevails in negotiations among independent businesses or individuals. In building computer support for coalition formation in such settings, the issue of self-interest has to be dealt with. In cooperative distributed problem solving <ref> [7, 5] </ref>, the system designer imposes an interaction protocol 2 and a strategy (a mapping from state history to action; a way to use the protocol) for each agent.
Reference: [8] <author> T. Finin, R. Fritzson, and D. McKay. </author> <title> A language and protocol to support intelligent agent interoperability. </title> <booktitle> In Proc. of the CE & CALS Washington `92 Conference, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Automated negotiation systems with self-interested agents are becoming increasingly important. One reason for this is the technology push of a growing standardized communication infrastructure|Internet, WWW, NII, EDI, KQML <ref> [8] </ref>, FIPA, Tele-script [14], Java, etc|over which separately designed agents belonging to different organizations can interact in an open environment in real-time and safely carry out transactions. The second reason is strong application pull for computer support for negotiation at the operative decision making level.
Reference: [9] <author> K. Fischer, J. Muller, M. Pischel, and D. Schier. </author> <title> A model for cooperative transportation scheduling. </title> <booktitle> In Proceedings of the First International Conference on Multi-Agent Systems (ICMAS-95), </booktitle> <pages> pages 109-116, </pages> <address> San Francisco, CA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Our prior work has already focused on different aspects of automated negotiation in this domain [37, 40, 44, 38, 39, 26, 45, 42], and lately other researchers have studied an almost identical problem, yet with randomly generated instances and with a non-normative approach <ref> [9] </ref>. Also, simpler routing problems have often been used as example applications in recent multiagent systems research [34, 59, 52, 57]. Table 1: One week of real vehicle and delivery data used in the experiments.
Reference: [10] <author> K. E. </author> <title> Friend. An information processing approach to small group interaction in a coalition formation game. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <year> 1973. </year>
Reference-contexts: Some of them also address the question of which coalition structure should form. But being static in nature, they do not usually address the dynamics of the coalition formation process. This section reviews work that has addressed the dynamics. Friend <ref> [10, 20] </ref> has developed a program that simulates a 3-agent coalition formation situation where agents can make offers, acceptances, and rejections to each other regarding coalitions and payoffs. In the model, at most one offer regarding each agent can be active at a time.
Reference: [11] <author> D. Fudenberg and J. Tirole. </author> <title> Game Theory. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: An example protocol is the sealed-bid first-price auction, where each bidder is free to submit one bid to take responsibility for a task, which is awarded to the lowest price bidder at the price of his bid. The analog of a protocol is called a mechanism in game theory <ref> [11, 24] </ref>. 2 guarantees that each agent's desired local strategy is best for that agent|and thus the agent will use it. The normative approach is required in designing robust non-manipulable multiagent systems where the agents may be constructed by separate designers and/or may represent different real world parties. <p> The normative approach is required in designing robust non-manipulable multiagent systems where the agents may be constructed by separate designers and/or may represent different real world parties. Interactions of self-motivated agents have been widely studied in microeconomics| especially in game theory <ref> [28, 11, 24, 33] </ref>. Most of that work assumes perfect rationality of the agents [49, 18], e.g., flawless and costless deduction.
Reference: [12] <author> A. Garvey and V. Lesser. </author> <title> Design-to-time real-time scheduling. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 23(6) </volume> <pages> 1491-1502, </pages> <year> 1993. </year>
Reference-contexts: at a computation unit cost c comp that is so high that it is not worthwhile to take any iterative refinement steps: the initial solutions are used (their computation requirements are assumed negligible). 2.1 Discussion of this model of bounded rationality Conceptually we allow the agents to use design-to-time algorithms <ref> [12, 58, 13] </ref>: once an agent has decided how much CPU time r S it will allocate to a computation, it can design an algorithm that will find a solution of cost c S (r S ).
Reference: [13] <author> A. Garvey and V. Lesser. </author> <booktitle> A survey of research in deliberative real-time artificial intelligence. Real-Time Systems, </booktitle> <volume> 6 </volume> <pages> 317-347, </pages> <year> 1994. </year>
Reference-contexts: at a computation unit cost c comp that is so high that it is not worthwhile to take any iterative refinement steps: the initial solutions are used (their computation requirements are assumed negligible). 2.1 Discussion of this model of bounded rationality Conceptually we allow the agents to use design-to-time algorithms <ref> [12, 58, 13] </ref>: once an agent has decided how much CPU time r S it will allocate to a computation, it can design an algorithm that will find a solution of cost c S (r S ).
Reference: [14] <author> General Magic, Inc. </author> <title> Telescript technology: The foundation for the electronic marketplace, 1994. </title> <type> White paper. 40 </type>
Reference-contexts: 1 Introduction Automated negotiation systems with self-interested agents are becoming increasingly important. One reason for this is the technology push of a growing standardized communication infrastructure|Internet, WWW, NII, EDI, KQML [8], FIPA, Tele-script <ref> [14] </ref>, Java, etc|over which separately designed agents belonging to different organizations can interact in an open environment in real-time and safely carry out transactions. The second reason is strong application pull for computer support for negotiation at the operative decision making level. <p> For example in the vehicle routing problem, the domain cost 7 In practice, CPU time can already be bought, e.g., on supercomputers. Similarly, the developing infrastructure for remotely executing agents provides an equivalent setting. For example in Telescript <ref> [14] </ref>, the remotely executing agents pay Teleclicks for CPU time to the owner of the host machine.
Reference: [15] <author> I. </author> <title> Good. Twenty-seven principles of rationality. </title> <editor> In V. Godambe and D. Sprott, editors, </editor> <title> Foundations of Statistical Inference. </title> <publisher> Toronto: Holt, Rinehart, Winston, </publisher> <year> 1971. </year>
Reference-contexts: However, if the problem is hard and the instance is large, it is unrealistic to assume that it can be solved without deliberation costs. This paper adopts a specific model of bounded rationality <ref> [54, 15] </ref>, where each agent has to pay for the computational resources (CPU cycles) that it uses for deliberation.
Reference: [16] <author> E. A. Hansen and S. Zilberstein. </author> <title> Monitoring the progress of anytime problem-solving. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 1229-1234, </pages> <address> Portland, OR, </address> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: In general, for optimal meta-reasoning, the remaining part of a probabilistic performance profile should be conditioned on the algorithm's performance on that problem instance on previous CPU time steps <ref> [43, 58, 16] </ref>. 10 is divided among the agents in the coalition as will be presented later. <p> Extensions of our work include generalizing the methods of this paper to agents with different and probabilistic performance profiles, as well as anytime algorithms where the performance profiles are conditioned on execution so far <ref> [43, 58, 16] </ref>. Agents with probabilistic performance profiles may want to reselect a coalition if the value of their original coalition is lower than expected|but sunk computation cost has already been incurred. Future research should also address agents that can refine solutions generated by others.
Reference: [17] <author> E. Horvitz. </author> <title> Reasoning about beliefs and actions under computational resource constraints. </title> <booktitle> In Proceedings of Third Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 429-444, </pages> <address> Seattle, Washington, </address> <month> July </month> <year> 1987. </year> <journal> American Association for Artificial Intelligence. </journal> <note> Also in L. </note> <editor> Kanal, T. Levitt, and J. Lemmer, ed., </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <publisher> Elsevier, </publisher> <year> 1989, </year> <month> pps. </month> <pages> 301-324. </pages>
Reference-contexts: The design-to-time framework is used instead of the anytime framework <ref> [43, 4, 17, 58] </ref> because to devise a normative theory of self-interested agents, the possibility that they design their algorithms to time has to be accounted for.
Reference: [18] <author> N. Howard. </author> <title> Paradoxes of Rationality: Theory of Metagames and Political Behavior. </title> <publisher> The MIT Press, </publisher> <year> 1971. </year>
Reference-contexts: Interactions of self-motivated agents have been widely studied in microeconomics| especially in game theory [28, 11, 24, 33]. Most of that work assumes perfect rationality of the agents <ref> [49, 18] </ref>, e.g., flawless and costless deduction. We extend the normative approach of game theory to settings where the agents lack full rationality because they cannot enumerate or evaluate all alternative solutions to a coalition's optimization problem. 3 Instead, they have to search for good solutions.
Reference: [19] <author> J. Hu and M. P. Wellman. </author> <title> Self-fulfilling bias in multiagent learning. </title> <booktitle> In Proceedings of the Second International Conference on Multi-Agent Systems (ICMAS-96), </booktitle> <pages> pages 118-125, </pages> <address> Keihanna Plaza, Kyoto, Japan, </address> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: Recently, Sandholm and Ygge have devised general insincere strategies that allow an agent to drive the market to an equilibrium where the agent's maximal gain from speculation materializes [48]. Speculative behavior in general equilibrium markets has recently been studied in the context of learning by Hu and Wellman <ref> [19] </ref>. Shehory and Kraus [53] analyze coalition formation among rational agents with perfect information in CFGs that are not necessarily superadditive. Their protocol guarantees that if agents follow it (this assumption makes their approach nonnormative), a certain stability criterion (K-stability) is met.
Reference: [20] <author> J. P. Kahan and A. Rapoport. </author> <title> Theories of Coalition Formation. </title> <publisher> Lawrence Erlbaum Associates Publishers, </publisher> <year> 1984. </year>
Reference-contexts: Externalities and agents with different problem solving capabilities are discussed in Section 6. Section 7 presents related research, and Section 8 concludes and describes future research directions. 2 Computation unit cost and algorithm as limits to rationality Coalition formation has been widely studied <ref> [20, 56, 32, 53, 52, 59, 22] </ref>, but to our knowledge, only among rational agents which can solve the coalition's optimization problem exactly, immediately, and without computation cost. This section describes how our model differs because it takes into account the cost of computation. <p> be distributed so that every subgroup of agents is better off staying in the social welfare maximizing coalition structure than by separating into a new coalition (individual agents and the group of all agents are also considered subgroups here)? The core (C) is the solution concept that satisfies this requirement <ref> [20, 56, 32] </ref>. The core of a game is a set of payoff configurations (~x; CS), where each ~x is a vector of payoffs to the agents in such a manner that no subgroup is motivated to depart from the coalition structure CS. <p> It is often too strong: in many cases it is empty <ref> [20, 56, 32, 59] </ref>. In such games there is no way to divide the social good so that the coalition structure becomes stable: any payoff configuration is prone to deviation by some subgroup of agents. <p> An often used solution is to pick the nucleolus which, intuitively speaking, corresponds to a payoff vector that is in the center of the set of payoff vectors in the core <ref> [20, 56, 32] </ref>. A further problem with the core is that the constraints in the definition become numerous as the number of agents increases. This is due to the combinatorial subset operator in the definition. Now we generalize the core to allow for bounded-rational agents. <p> f1,5g, f2,5g, and f3,5g achieved a better initial solution cost than the sum of the initial solution costs of the two agents separately, Fig. 5 (this set of pairs prevailed even without the route length restriction). 6 Externalities among coalitions and different al gorithms among agents As is common practice <ref> [20, 52, 53, 59, 22] </ref>, so far in this paper we have restricted our attention to studying coalition formation in characteristic function games (CFGs), S ). <p> research. 16 On the other hand, results with strategic solution concepts are specific to a given interaction protocol while core-based analyses are not (unless the coalition formation process itself affects the payoffs). 26 7 Related research on computational coalition for- mation Coalition formation has been widely studied in game theory <ref> [20, 2, 3, 1, 56, 32] </ref>, and only the most relevant concepts were presented. Many of the solution concepts for coalition formation are static. They address the question of how to divide the payoffs among agents. Some of them also address the question of which coalition structure should form. <p> Some of them also address the question of which coalition structure should form. But being static in nature, they do not usually address the dynamics of the coalition formation process. This section reviews work that has addressed the dynamics. Friend <ref> [10, 20] </ref> has developed a program that simulates a 3-agent coalition formation situation where agents can make offers, acceptances, and rejections to each other regarding coalitions and payoffs. In the model, at most one offer regarding each agent can be active at a time. <p> The model is purely descriptive. There is no guarantee that a self-interested agent would be best off by using the specified local strategy. Transfer schemes are another dynamic approach to coalition formation <ref> [20] </ref>. The agents stay within a given coalition structure and iteratively exchange payments in a prespecified manner. <p> We do not assume that one agent can take care of all the agents' tasks. Unlike our work, they also assume that all agents have the same capabilities (symmetric cost functions for task sets). Their method guarantees each agent an expected value that equals its Shapley value <ref> [20, 32] </ref>. The Shapley value is a specific payoff division among agents that motivates individual agents to stay with the coalition structure and the group of all agents to stay. Unlike the core, the Shapley value does not in general motivate every subgroup of agents to stay.
Reference: [21] <author> R. Kalakota and A. B. Whinston. </author> <title> Frontiers of Electronic Commerce. </title> <publisher> Addison-Wesley Publishing Company, Inc, </publisher> <year> 1996. </year>
Reference-contexts: The second reason is strong application pull for computer support for negotiation at the operative decision making level. For example, we are witnessing the advent of small transaction commerce on the Internet for purchasing goods, information, and communication bandwidth <ref> [21, 30] </ref>. There is also an industrial trend toward virtual enterprises: dynamic alliances of small, agile enterprises which together can take advantage of economies of scale when available (e.g., respond to more diverse orders than individual agents can), but do not suffer from diseconomies of scale.
Reference: [22] <author> S. Ketchpel. </author> <title> Forming coalitions in the face of uncertain rewards. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 414-419, </pages> <address> Seattle, WA, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Externalities and agents with different problem solving capabilities are discussed in Section 6. Section 7 presents related research, and Section 8 concludes and describes future research directions. 2 Computation unit cost and algorithm as limits to rationality Coalition formation has been widely studied <ref> [20, 56, 32, 53, 52, 59, 22] </ref>, but to our knowledge, only among rational agents which can solve the coalition's optimization problem exactly, immediately, and without computation cost. This section describes how our model differs because it takes into account the cost of computation. <p> f1,5g, f2,5g, and f3,5g achieved a better initial solution cost than the sum of the initial solution costs of the two agents separately, Fig. 5 (this set of pairs prevailed even without the route length restriction). 6 Externalities among coalitions and different al gorithms among agents As is common practice <ref> [20, 52, 53, 59, 22] </ref>, so far in this paper we have restricted our attention to studying coalition formation in characteristic function games (CFGs), S ). <p> Now say that the depots are far from each other. Thus the sum of the route lengths when A1 manages T1 and A2 manages T2 is lower than when either agent individually manages both tasks. Ketchpel <ref> [22] </ref> presents a non-normative coalition formation method for rational agents which have different expectations of coalition values. The (computational) origin of these expectations is not addressed. His assumption of imperfect information differs from our setting where the agents have perfect information but cannot perfectly deduce.
Reference: [23] <author> S. Kraus, J. Wilkenfeld, and G. Zlotkin. </author> <title> Multiagent negotiation under time constraints. </title> <journal> Artificial Intelligence, </journal> <volume> 75 </volume> <pages> 297-345, </pages> <year> 1995. </year>
Reference-contexts: The approach is usually descriptive: the main question is what social outcomes follow given the protocol and assuming that the agents use the imposed strategies. On the other hand, in multiagent systems <ref> [34, 23, 5, 47, 41, 44] </ref>, the agents are provided with an interaction protocol, but each agent will choose its own strategy. A self-interested agent will choose the best strategy for itself, which cannot be explicitly imposed from outside.
Reference: [24] <author> D. M. Kreps. </author> <title> A Course in Microeconomic Theory. </title> <publisher> Princeton University Press, </publisher> <year> 1990. </year>
Reference-contexts: An example protocol is the sealed-bid first-price auction, where each bidder is free to submit one bid to take responsibility for a task, which is awarded to the lowest price bidder at the price of his bid. The analog of a protocol is called a mechanism in game theory <ref> [11, 24] </ref>. 2 guarantees that each agent's desired local strategy is best for that agent|and thus the agent will use it. The normative approach is required in designing robust non-manipulable multiagent systems where the agents may be constructed by separate designers and/or may represent different real world parties. <p> The normative approach is required in designing robust non-manipulable multiagent systems where the agents may be constructed by separate designers and/or may represent different real world parties. Interactions of self-motivated agents have been widely studied in microeconomics| especially in game theory <ref> [28, 11, 24, 33] </ref>. Most of that work assumes perfect rationality of the agents [49, 18], e.g., flawless and costless deduction. <p> the blocks world, positive and negative interactions often occur. 25 solution concept presented earlier which has a purely axiomatic foundation: it postu-lates desirable stability properties of the outcomes, but does not guarantee stability of the strategies that lead to those outcomes. 16 One alternative solution concept is the Nash equilibrium <ref> [29, 24] </ref>. It guarantees stability in the sense that no agent alone is motivated to deviate by changing its strategy given that others do not deviate. Often the Nash equilibrium is too weak because subgroups of agents can deviate in a coordinated manner. <p> The solution concepts presented above guarantee forms of stability for the beginning of the game. To ensure stability throughout the game, the equilibria should prevail in subtrees of the game tree also. To guarantee this, sequential <ref> [24] </ref> or subgame perfect [50, 24] refinements of the above solution concepts should be used. The strategic solution concepts presented above provide a rigorous tool for analyzing general games (NFGs), and they also extend the strategic approach to settings where axiomatic solution concepts like the core are well-defined. <p> The solution concepts presented above guarantee forms of stability for the beginning of the game. To ensure stability throughout the game, the equilibria should prevail in subtrees of the game tree also. To guarantee this, sequential [24] or subgame perfect <ref> [50, 24] </ref> refinements of the above solution concepts should be used. The strategic solution concepts presented above provide a rigorous tool for analyzing general games (NFGs), and they also extend the strategic approach to settings where axiomatic solution concepts like the core are well-defined.
Reference: [25] <author> S. Lin and B. W. Kernighan. </author> <title> An effective heuristic procedure for the traveling salesman problem. </title> <journal> Operations Research, </journal> <volume> 21 </volume> <pages> 498-516, </pages> <year> 1971. </year>
Reference-contexts: One example is completing an iterative refinement algorithm by running an exhaustive complete algorithm after the refinement phase. Another example is switching from using one refinement operator (e.g., 2-swap in TSP <ref> [25, 40] </ref>) to using another refinement operator (e.g., 3-swap in TSP). Furthermore, refinements often decrease solution cost in a step-wise, noncontinuous manner rendering the performance profiles locally nonconvex|as in our experiments (Fig. 2 left).
Reference: [26] <author> S. Linnainmaa, O. Jokinen, T. Sandholm, and A. Vepsalainen. </author> <title> Advanced computer supported vehicle routing for heavy transports. </title> <booktitle> In Finnish Artificial Intelligence Conference (STeP-92), New Directions in Artificial Intelligence, </booktitle> <volume> volume 3, </volume> <pages> pages 163-172, </pages> <address> Espoo, Finland, </address> <year> 1992. </year> <month> 41 </month>
Reference-contexts: They represent one week delivery order and vehicle data. 5 The collected data is characterized in Table 1. Our prior work has already focused on different aspects of automated negotiation in this domain <ref> [37, 40, 44, 38, 39, 26, 45, 42] </ref>, and lately other researchers have studied an almost identical problem, yet with randomly generated instances and with a non-normative approach [9]. Also, simpler routing problems have often been used as example applications in recent multiagent systems research [34, 59, 52, 57].
Reference: [27] <author> M. G. Lundgren, K. Jornsten, and P. Varbrand. </author> <title> On the nucleolus of the ba-sic vehicle routing game. </title> <type> Technical Report 1992-26, </type> <institution> Linkoping Univ., Dept. of Mathematics, Sweden, </institution> <year> 1992. </year>
Reference-contexts: The problem instances in our example are so large that even the smallest ones are too hard to solve optimally. Therefore, rational coalition formation algorithms for vehicle routing problems <ref> [27] </ref> are unusable in this case. To analyze a game, we ran the same algorithm on the vehicle routing problem of each subgroup of agents separately and thus acquired a performance profile for each potential coalition.
Reference: [28] <author> A. Mas-Colell, M. Whinston, and J. R. Green. </author> <title> Microeconomic Theory. </title> <publisher> Oxford University Press, </publisher> <year> 1995. </year>
Reference-contexts: The normative approach is required in designing robust non-manipulable multiagent systems where the agents may be constructed by separate designers and/or may represent different real world parties. Interactions of self-motivated agents have been widely studied in microeconomics| especially in game theory <ref> [28, 11, 24, 33] </ref>. Most of that work assumes perfect rationality of the agents [49, 18], e.g., flawless and costless deduction. <p> If all agents act as price takers, and an equilibrium is reached for the market, that equilibrium is guaranteed to be in the core: no subgroup of agents is motivated to leave the market and form their own market <ref> [28] </ref>. This is not the case if agents speculate how their demands and supplies affect the market prices. Recently, Sandholm and Ygge have devised general insincere strategies that allow an agent to drive the market to an equilibrium where the agent's maximal gain from speculation materializes [48].
Reference: [29] <author> J. Nash. </author> <title> Equilibrium points in n-person games. </title> <booktitle> Proc. of the National Academy of Sciences, </booktitle> <volume> 36 </volume> <pages> 48-49, </pages> <year> 1950. </year>
Reference-contexts: the blocks world, positive and negative interactions often occur. 25 solution concept presented earlier which has a purely axiomatic foundation: it postu-lates desirable stability properties of the outcomes, but does not guarantee stability of the strategies that lead to those outcomes. 16 One alternative solution concept is the Nash equilibrium <ref> [29, 24] </ref>. It guarantees stability in the sense that no agent alone is motivated to deviate by changing its strategy given that others do not deviate. Often the Nash equilibrium is too weak because subgroups of agents can deviate in a coordinated manner.
Reference: [30] <institution> Office of Technology Assesment. Electronic enterprises: </institution> <note> Looking to the future, </note> <year> 1994. </year>
Reference-contexts: The second reason is strong application pull for computer support for negotiation at the operative decision making level. For example, we are witnessing the advent of small transaction commerce on the Internet for purchasing goods, information, and communication bandwidth <ref> [21, 30] </ref>. There is also an industrial trend toward virtual enterprises: dynamic alliances of small, agile enterprises which together can take advantage of economies of scale when available (e.g., respond to more diverse orders than individual agents can), but do not suffer from diseconomies of scale.
Reference: [31] <author> C. H. Papadimitriou and M. Yannakakis. </author> <title> On complexity as bounded rationality. </title> <booktitle> In STOC-94, </booktitle> <pages> pages 726-733, </pages> <year> 1994. </year>
Reference-contexts: pickup nor the drop-off locations of the orders need to be at the depot). 3 Others in game theory have examined the effects of computational limits on rational play in settings where agents play a combinatorially trivial game, but complexity stems from numerous repetitions of that same game, see e.g. <ref> [31] </ref>. 3 * Each vehicle has a maximum load weight constraint. These differ among vehi- cles. * Each vehicle has a maximum load volume constraint.
Reference: [32] <author> H. Raiffa. </author> <title> The Art and Science of Negotiation. </title> <publisher> Harvard Univ. Press, </publisher> <address> Cambridge, Mass., </address> <year> 1982. </year>
Reference-contexts: Externalities and agents with different problem solving capabilities are discussed in Section 6. Section 7 presents related research, and Section 8 concludes and describes future research directions. 2 Computation unit cost and algorithm as limits to rationality Coalition formation has been widely studied <ref> [20, 56, 32, 53, 52, 59, 22] </ref>, but to our knowledge, only among rational agents which can solve the coalition's optimization problem exactly, immediately, and without computation cost. This section describes how our model differs because it takes into account the cost of computation. <p> be distributed so that every subgroup of agents is better off staying in the social welfare maximizing coalition structure than by separating into a new coalition (individual agents and the group of all agents are also considered subgroups here)? The core (C) is the solution concept that satisfies this requirement <ref> [20, 56, 32] </ref>. The core of a game is a set of payoff configurations (~x; CS), where each ~x is a vector of payoffs to the agents in such a manner that no subgroup is motivated to depart from the coalition structure CS. <p> It is often too strong: in many cases it is empty <ref> [20, 56, 32, 59] </ref>. In such games there is no way to divide the social good so that the coalition structure becomes stable: any payoff configuration is prone to deviation by some subgroup of agents. <p> An often used solution is to pick the nucleolus which, intuitively speaking, corresponds to a payoff vector that is in the center of the set of payoff vectors in the core <ref> [20, 56, 32] </ref>. A further problem with the core is that the constraints in the definition become numerous as the number of agents increases. This is due to the combinatorial subset operator in the definition. Now we generalize the core to allow for bounded-rational agents. <p> research. 16 On the other hand, results with strategic solution concepts are specific to a given interaction protocol while core-based analyses are not (unless the coalition formation process itself affects the payoffs). 26 7 Related research on computational coalition for- mation Coalition formation has been widely studied in game theory <ref> [20, 2, 3, 1, 56, 32] </ref>, and only the most relevant concepts were presented. Many of the solution concepts for coalition formation are static. They address the question of how to divide the payoffs among agents. Some of them also address the question of which coalition structure should form. <p> We do not assume that one agent can take care of all the agents' tasks. Unlike our work, they also assume that all agents have the same capabilities (symmetric cost functions for task sets). Their method guarantees each agent an expected value that equals its Shapley value <ref> [20, 32] </ref>. The Shapley value is a specific payoff division among agents that motivates individual agents to stay with the coalition structure and the group of all agents to stay. Unlike the core, the Shapley value does not in general motivate every subgroup of agents to stay.
Reference: [33] <author> E. Rasmusen. </author> <title> Games and Information. </title> <publisher> Basil Blackwell, </publisher> <year> 1989. </year>
Reference-contexts: The normative approach is required in designing robust non-manipulable multiagent systems where the agents may be constructed by separate designers and/or may represent different real world parties. Interactions of self-motivated agents have been widely studied in microeconomics| especially in game theory <ref> [28, 11, 24, 33] </ref>. Most of that work assumes perfect rationality of the agents [49, 18], e.g., flawless and costless deduction.
Reference: [34] <author> J. S. Rosenschein and G. Zlotkin. </author> <title> Rules of Encounter. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: The approach is usually descriptive: the main question is what social outcomes follow given the protocol and assuming that the agents use the imposed strategies. On the other hand, in multiagent systems <ref> [34, 23, 5, 47, 41, 44] </ref>, the agents are provided with an interaction protocol, but each agent will choose its own strategy. A self-interested agent will choose the best strategy for itself, which cannot be explicitly imposed from outside. <p> Also, simpler routing problems have often been used as example applications in recent multiagent systems research <ref> [34, 59, 52, 57] </ref>. Table 1: One week of real vehicle and delivery data used in the experiments. <p> The grand coalition may be the optimal coalition structure even in games which are not superadditive. Similarly, every agent operating alone may be optimal even in games which are not subadditive. show the classification from game theory. Dotted lines show the domain classification of Rosenschein and Zlotkin <ref> [34] </ref> . They use "Subadditive" to mean that an agent's cost for handling tasks is subadditive in tasks. We use subadditive to refer to coalition value functions that are subadditive in agents. The figure does not reflect the fact that Rosenschein and Zlotkin do not allow side payments. <p> Negative externalities can also be caused by conflicting goals. In satisfying their goals, nonmembers may actually move the world further from the coalition's goal state (s) <ref> [34] </ref>. Positive externalities are often caused by partially overlapping goals. In satisfying their goals, nonmembers may actually move the world closer to the coalition's goal state (s). From there the coalition can reach its goals less expensively than it could have without the actions of nonmembers. <p> Alternatively, the agents can be made to explicitly declare their tasks and resources, but they may lie in order to gain monetarily. Rosenschein and Zlotkin have analyzed when rational agents are motivated to declare truthfully <ref> [34] </ref>. Unfortunately that work assumes only two agents and that they can optimally solve exponentially many N P-complete problems without computation costs. Even under these assumptions, in most cases, truth-telling is not achieved. To our knowledge, the effect of bounded rationality on truthful 28 revelation has not been studied. <p> Even under these assumptions, in most cases, truth-telling is not achieved. To our knowledge, the effect of bounded rationality on truthful 28 revelation has not been studied. Our problem is outside the domain classification of Rosenschein and Zlotkin <ref> [34] </ref>, Fig. 3, because agents do not have symmetric capabilities due to heterogeneous fleets. If Rosenschein and Zlotkin's definition were extended to allow asymmetric capabilities, our domain would be in the class SOD but outside the subclass TOD.
Reference: [35] <author> S. Russell and D. Subramanian. </author> <title> Provably bounded-optimal agents. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 1-36, </pages> <year> 1995. </year>
Reference-contexts: For example, Russell and Subramanian have devised algorithms that are optimal for the architecture in simple settings, but in more complex settings they had to resort to an asymptotic criterion of optimality <ref> [35] </ref>. 8 In games where the agents receive revenue from outside|e.g., for handling tasks|this revenue can be incorporated into c S (r S ) by subtracting the coalition members' revenues from the coalition's domain cost. 9 Throughout this chapter on coalition formation, min-operators are used due to their familiarity, although strictly
Reference: [36] <author> S. Russell and E. Wefald. </author> <title> Do the right thing: Studies in Limited Rationality. </title> <publisher> The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: However, we do not assume that the deliberation controller composes the optimal sequence of base level computation actions since even the most advanced methods for such composition rely on assumptions that often do not hold in practice <ref> [36] </ref>. Assuming that the meta-level exactly and costlessly predicts the solution cost is more realistic than assuming optimality of the base level, but it still does not match reality exactly.
Reference: [37] <author> T. W. Sandholm. </author> <title> A strategy for decreasing the total transportation costs among area-distributed transportation centers. In Nordic Operations Analysis in Cooperation (NOAS-91): OR in Business, </title> <institution> Turku School of Economics, Finland, </institution> <year> 1991. </year>
Reference-contexts: They represent one week delivery order and vehicle data. 5 The collected data is characterized in Table 1. Our prior work has already focused on different aspects of automated negotiation in this domain <ref> [37, 40, 44, 38, 39, 26, 45, 42] </ref>, and lately other researchers have studied an almost identical problem, yet with randomly generated instances and with a non-normative approach [9]. Also, simpler routing problems have often been used as example applications in recent multiagent systems research [34, 59, 52, 57].
Reference: [38] <author> T. W. Sandholm. </author> <title> Automatic cooperation of area-distributed dispatch centers in vehicle routing. </title> <booktitle> In International Conference on Artificial Intelligence Applications in Transportation Engineering, </booktitle> <pages> pages 449-467, </pages> <address> San Buenaventura, CA, </address> <year> 1992. </year>
Reference-contexts: They represent one week delivery order and vehicle data. 5 The collected data is characterized in Table 1. Our prior work has already focused on different aspects of automated negotiation in this domain <ref> [37, 40, 44, 38, 39, 26, 45, 42] </ref>, and lately other researchers have studied an almost identical problem, yet with randomly generated instances and with a non-normative approach [9]. Also, simpler routing problems have often been used as example applications in recent multiagent systems research [34, 59, 52, 57].
Reference: [39] <author> T. W. Sandholm. </author> <title> A bargaining network for intelligent agents. </title> <booktitle> In Finnish Artificial Intelligence Conference (STeP-92), New Directions in Artificial Intelligence, </booktitle> <volume> volume 3, </volume> <pages> pages 173-181, </pages> <address> Espoo, Finland, </address> <year> 1992. </year> <month> 42 </month>
Reference-contexts: They represent one week delivery order and vehicle data. 5 The collected data is characterized in Table 1. Our prior work has already focused on different aspects of automated negotiation in this domain <ref> [37, 40, 44, 38, 39, 26, 45, 42] </ref>, and lately other researchers have studied an almost identical problem, yet with randomly generated instances and with a non-normative approach [9]. Also, simpler routing problems have often been used as example applications in recent multiagent systems research [34, 59, 52, 57].
Reference: [40] <author> T. W. Sandholm. </author> <title> An implementation of the contract net protocol based on marginal cost calculations. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 256-262, </pages> <address> Washington, D.C., </address> <month> July </month> <year> 1993. </year>
Reference-contexts: They represent one week delivery order and vehicle data. 5 The collected data is characterized in Table 1. Our prior work has already focused on different aspects of automated negotiation in this domain <ref> [37, 40, 44, 38, 39, 26, 45, 42] </ref>, and lately other researchers have studied an almost identical problem, yet with randomly generated instances and with a non-normative approach [9]. Also, simpler routing problems have often been used as example applications in recent multiagent systems research [34, 59, 52, 57]. <p> One example is completing an iterative refinement algorithm by running an exhaustive complete algorithm after the refinement phase. Another example is switching from using one refinement operator (e.g., 2-swap in TSP <ref> [25, 40] </ref>) to using another refinement operator (e.g., 3-swap in TSP). Furthermore, refinements often decrease solution cost in a step-wise, noncontinuous manner rendering the performance profiles locally nonconvex|as in our experiments (Fig. 2 left). <p> In our approach, if the agents' payoff vector is chosen from within the bounded-rational core, the coalition structure is stable against all offers. Finally, his 2-agent auction is manipulable and computationally inefficient. Ketchpel's method is related to a contracting protocol of Sandholm <ref> [40, 46] </ref> (Traco-net) where agents construct the global solution by contracting a small number of tasks at a time, and payments are made regarding each contract before new contracts take place. An agent updates its approximate local solution after each task transfer.
Reference: [41] <author> T. W. Sandholm. </author> <title> Limitations of the Vickrey auction in computational multiagent systems. </title> <booktitle> In Proceedings of the Second International Conference on Multi-Agent Systems (ICMAS-96), </booktitle> <pages> pages 299-306, </pages> <address> Keihanna Plaza, Kyoto, Japan, </address> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: The approach is usually descriptive: the main question is what social outcomes follow given the protocol and assuming that the agents use the imposed strategies. On the other hand, in multiagent systems <ref> [34, 23, 5, 47, 41, 44] </ref>, the agents are provided with an interaction protocol, but each agent will choose its own strategy. A self-interested agent will choose the best strategy for itself, which cannot be explicitly imposed from outside.
Reference: [42] <author> T. W. Sandholm. </author> <title> Negotiation among Self-Interested Computationally Limited Agents. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, Amherst, </institution> <year> 1996. </year>
Reference-contexts: They represent one week delivery order and vehicle data. 5 The collected data is characterized in Table 1. Our prior work has already focused on different aspects of automated negotiation in this domain <ref> [37, 40, 44, 38, 39, 26, 45, 42] </ref>, and lately other researchers have studied an almost identical problem, yet with randomly generated instances and with a non-normative approach [9]. Also, simpler routing problems have often been used as example applications in recent multiagent systems research [34, 59, 52, 57].
Reference: [43] <author> T. W. Sandholm and V. R. Lesser. </author> <title> Utility-based termination of anytime algorithms. </title> <booktitle> In ECAI Workshop on Decision Theory for DAI Applications, </booktitle> <pages> pages 88-99, </pages> <address> Amsterdam, The Netherlands, </address> <year> 1994. </year> <note> Extended version: </note> <institution> Univ. of Mass. at Amherst, Comp. Sci. </institution> <type> Tech. Report 94-54. </type>
Reference-contexts: The design-to-time framework is used instead of the anytime framework <ref> [43, 4, 17, 58] </ref> because to devise a normative theory of self-interested agents, the possibility that they design their algorithms to time has to be accounted for. <p> In practice there is uncertainty in each performance profile: the meta-level is not exact. 10 Secondly, the performance profile depends on several features of the problem instance, and computing the mapping from the instance to the performance profile <ref> [43] </ref> may take considerable time, thus making the meta-level costly. In the limit, the base algorithm would be run at the meta-level to determine what it would achieve for a given time setting. <p> In general, for optimal meta-reasoning, the remaining part of a probabilistic performance profile should be conditioned on the algorithm's performance on that problem instance on previous CPU time steps <ref> [43, 58, 16] </ref>. 10 is divided among the agents in the coalition as will be presented later. <p> Extensions of our work include generalizing the methods of this paper to agents with different and probabilistic performance profiles, as well as anytime algorithms where the performance profiles are conditioned on execution so far <ref> [43, 58, 16] </ref>. Agents with probabilistic performance profiles may want to reselect a coalition if the value of their original coalition is lower than expected|but sunk computation cost has already been incurred. Future research should also address agents that can refine solutions generated by others.
Reference: [44] <author> T. W. Sandholm and V. R. Lesser. </author> <title> Coalition formation among bounded rational agents. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 662-669, </pages> <address> Montreal, Canada, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: The approach is usually descriptive: the main question is what social outcomes follow given the protocol and assuming that the agents use the imposed strategies. On the other hand, in multiagent systems <ref> [34, 23, 5, 47, 41, 44] </ref>, the agents are provided with an interaction protocol, but each agent will choose its own strategy. A self-interested agent will choose the best strategy for itself, which cannot be explicitly imposed from outside. <p> They represent one week delivery order and vehicle data. 5 The collected data is characterized in Table 1. Our prior work has already focused on different aspects of automated negotiation in this domain <ref> [37, 40, 44, 38, 39, 26, 45, 42] </ref>, and lately other researchers have studied an almost identical problem, yet with randomly generated instances and with a non-normative approach [9]. Also, simpler routing problems have often been used as example applications in recent multiagent systems research [34, 59, 52, 57].
Reference: [45] <author> T. W. Sandholm and V. R. Lesser. </author> <title> Equilibrium analysis of the possibilities of unenforced exchange in multiagent systems. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 694-701, </pages> <address> Montreal, Canada, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: They represent one week delivery order and vehicle data. 5 The collected data is characterized in Table 1. Our prior work has already focused on different aspects of automated negotiation in this domain <ref> [37, 40, 44, 38, 39, 26, 45, 42] </ref>, and lately other researchers have studied an almost identical problem, yet with randomly generated instances and with a non-normative approach [9]. Also, simpler routing problems have often been used as example applications in recent multiagent systems research [34, 59, 52, 57].
Reference: [46] <author> T. W. Sandholm and V. R. Lesser. </author> <title> Issues in automated negotiation and electronic commerce: Extending the contract net framework. </title> <booktitle> In Proceedings of the First International Conference on Multi-Agent Systems (ICMAS-95), </booktitle> <pages> pages 328-335, </pages> <address> San Francisco, CA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: In our approach, if the agents' payoff vector is chosen from within the bounded-rational core, the coalition structure is stable against all offers. Finally, his 2-agent auction is manipulable and computationally inefficient. Ketchpel's method is related to a contracting protocol of Sandholm <ref> [40, 46] </ref> (Traco-net) where agents construct the global solution by contracting a small number of tasks at a time, and payments are made regarding each contract before new contracts take place. An agent updates its approximate local solution after each task transfer.
Reference: [47] <author> T. W. Sandholm and V. R. Lesser. </author> <title> Advantages of a leveled commitment contracting protocol. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 126-133, </pages> <address> Portland, OR, </address> <month> Aug. </month> <year> 1996. </year> <note> Extended version appeared as University of Massachusetts at Amherst, Computer Science Department technical report 95-72. </note>
Reference-contexts: The approach is usually descriptive: the main question is what social outcomes follow given the protocol and assuming that the agents use the imposed strategies. On the other hand, in multiagent systems <ref> [34, 23, 5, 47, 41, 44] </ref>, the agents are provided with an interaction protocol, but each agent will choose its own strategy. A self-interested agent will choose the best strategy for itself, which cannot be explicitly imposed from outside.
Reference: [48] <author> T. W. Sandholm and F. Ygge. </author> <title> On the gains and losses of speculation in equilibrium markets. </title> <booktitle> In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Nagoya, Japan, </address> <month> Aug. </month> <year> 1997. </year>
Reference-contexts: This is not the case if agents speculate how their demands and supplies affect the market prices. Recently, Sandholm and Ygge have devised general insincere strategies that allow an agent to drive the market to an equilibrium where the agent's maximal gain from speculation materializes <ref> [48] </ref>. Speculative behavior in general equilibrium markets has recently been studied in the context of learning by Hu and Wellman [19]. Shehory and Kraus [53] analyze coalition formation among rational agents with perfect information in CFGs that are not necessarily superadditive.
Reference: [49] <author> K. Schweers Cook and M. Levi. </author> <title> The Limits of Rationality. </title> <publisher> University of Chicago Press, </publisher> <year> 1990. </year> <month> 43 </month>
Reference-contexts: Interactions of self-motivated agents have been widely studied in microeconomics| especially in game theory [28, 11, 24, 33]. Most of that work assumes perfect rationality of the agents <ref> [49, 18] </ref>, e.g., flawless and costless deduction. We extend the normative approach of game theory to settings where the agents lack full rationality because they cannot enumerate or evaluate all alternative solutions to a coalition's optimization problem. 3 Instead, they have to search for good solutions.
Reference: [50] <author> R. Selten. </author> <title> Spieltheoretische behandlung eines oligopolmodells mit nach--fragetragheit. </title> <journal> Zeitschrift fur die gesamte Staatswissenschaft, </journal> <volume> 12 </volume> <pages> 301-324, </pages> <year> 1965. </year>
Reference-contexts: The solution concepts presented above guarantee forms of stability for the beginning of the game. To ensure stability throughout the game, the equilibria should prevail in subtrees of the game tree also. To guarantee this, sequential [24] or subgame perfect <ref> [50, 24] </ref> refinements of the above solution concepts should be used. The strategic solution concepts presented above provide a rigorous tool for analyzing general games (NFGs), and they also extend the strategic approach to settings where axiomatic solution concepts like the core are well-defined.
Reference: [51] <author> L. S. Shapley. </author> <title> On balanced sets and cores. </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> 14 </volume> <pages> 453-460, </pages> <year> 1967. </year>
Reference-contexts: In domains that are not BRSUB, the BRC is sometimes empty. The condition C 6= ; can be converted into necessary and sufficient conditions on the v R S values in games where the grand coalition maximizes social welfare <ref> [51, 6] </ref>. We convert the condition BRC (c comp ) 6= ; into conditions on the v S (c comp ) values analogously. Let B 1 ; :::; B p be distinct, nonempty, proper subsets of A. <p> A minimal balanced set includes no other balanced sets. 17 Theorem 4.2 BRC in bounded-rational grand coalition games (necessary and sufficient condition). [Analogous to Shapley <ref> [51] </ref>]. <p> Let us call a minimal balanced set proper if no two of its elements are disjoint. Theorem 4.3 BRC in BRSUP games (necessary and sufficient condition). [Analogous to Shapley <ref> [51] </ref>]. In a game that is BRSUP for some c comp , BRC (c comp ) 6= 18 ; iff for every proper minimal balanced set B = fB 1 ; :::; B p g, P p j=1 j v B j (c comp ) v A (c comp ). <p> Shapley <ref> [51] </ref> proved the following fact (his Theorem 2) for rational agents. In games where fAg is a social welfare maximizing coalition structure for rational agents, C 6= ; iff for every minimal balanced set B = fB 1 ; :::; B p g; j=1 j v R A . <p> In games where fAg is a social welfare maximizing coalition structure for rational agents, C 6= ; iff for every minimal balanced set B = fB 1 ; :::; B p g; j=1 j v R A . Theorem 4.2 follows by analogy. 2 38 Proof. (Theorem 4.3). Shapley <ref> [51] </ref> proved the following fact (his Theorem 3) for rational agents. In a superadditive game, C 6= ; iff for every proper minimal balanced set B = fB 1 ; :::; B p g; j=1 j v R A .
Reference: [52] <author> O. Shehory and S. Kraus. </author> <title> Task allocation via coalition formation among autonomous agents. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 655-661, </pages> <address> Montreal, Canada, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Also, simpler routing problems have often been used as example applications in recent multiagent systems research <ref> [34, 59, 52, 57] </ref>. Table 1: One week of real vehicle and delivery data used in the experiments. <p> Externalities and agents with different problem solving capabilities are discussed in Section 6. Section 7 presents related research, and Section 8 concludes and describes future research directions. 2 Computation unit cost and algorithm as limits to rationality Coalition formation has been widely studied <ref> [20, 56, 32, 53, 52, 59, 22] </ref>, but to our knowledge, only among rational agents which can solve the coalition's optimization problem exactly, immediately, and without computation cost. This section describes how our model differs because it takes into account the cost of computation. <p> f1,5g, f2,5g, and f3,5g achieved a better initial solution cost than the sum of the initial solution costs of the two agents separately, Fig. 5 (this set of pairs prevailed even without the route length restriction). 6 Externalities among coalitions and different al gorithms among agents As is common practice <ref> [20, 52, 53, 59, 22] </ref>, so far in this paper we have restricted our attention to studying coalition formation in characteristic function games (CFGs), S ). <p> Their algorithm switches from one coalition structure to another guaranteeing improvements at each step: coalition structure generation is an anytime algorithm although each domain problem is solved optimally. On the other hand, in our work, each domain problem is solved using an approximation (design-to-time) algorithm. Shehory and Kraus <ref> [52] </ref> also present an algorithm for coalition structure generation among cooperative|social welfare maximizing, i.e., not self-interested|agents. Among such agents the payoff distribution is a non-issue and is thus not addressed. The distributed algorithm forms disjoint coalitions|which by their definition can only handle one task each|and allocates tasks to the coalitions.
Reference: [53] <author> O. Shehory and S. Kraus. </author> <title> A kernel-oriented model for coalition-formation in general environments: Implemetation and results. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 134-140, </pages> <address> Portland, OR, </address> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: Externalities and agents with different problem solving capabilities are discussed in Section 6. Section 7 presents related research, and Section 8 concludes and describes future research directions. 2 Computation unit cost and algorithm as limits to rationality Coalition formation has been widely studied <ref> [20, 56, 32, 53, 52, 59, 22] </ref>, but to our knowledge, only among rational agents which can solve the coalition's optimization problem exactly, immediately, and without computation cost. This section describes how our model differs because it takes into account the cost of computation. <p> f1,5g, f2,5g, and f3,5g achieved a better initial solution cost than the sum of the initial solution costs of the two agents separately, Fig. 5 (this set of pairs prevailed even without the route length restriction). 6 Externalities among coalitions and different al gorithms among agents As is common practice <ref> [20, 52, 53, 59, 22] </ref>, so far in this paper we have restricted our attention to studying coalition formation in characteristic function games (CFGs), S ). <p> Speculative behavior in general equilibrium markets has recently been studied in the context of learning by Hu and Wellman [19]. Shehory and Kraus <ref> [53] </ref> analyze coalition formation among rational agents with perfect information in CFGs that are not necessarily superadditive. Their protocol guarantees that if agents follow it (this assumption makes their approach nonnormative), a certain stability criterion (K-stability) is met. This requires the solution of an exponential number of optimization problems.
Reference: [54] <author> H. A. Simon. </author> <title> Models of bounded rationality, volume 2. </title> <publisher> MIT Press, </publisher> <year> 1982. </year>
Reference-contexts: However, if the problem is hard and the instance is large, it is unrealistic to assume that it can be solved without deliberation costs. This paper adopts a specific model of bounded rationality <ref> [54, 15] </ref>, where each agent has to pay for the computational resources (CPU cycles) that it uses for deliberation.
Reference: [55] <author> F. Tohme and T. W. Sandholm. </author> <title> Coalition formation processes with belief revision among bounded rational self-interested agents. </title> <booktitle> In IJCAI Workshop on Social Interaction and Communityware, </booktitle> <address> Nagoya, Japan, </address> <month> Aug. </month> <year> 1997. </year>
Reference-contexts: The models are equivalent if the domain cost increases linearly with real time and distribution does not speed up computation. Certainly other models of bounded rationality besides these two also deserve attention. Our current work includes analyzing the interplay of dynamic coalition formation and belief revision among bounded-rational agents <ref> [55] </ref>. Extensions of our work include generalizing the methods of this paper to agents with different and probabilistic performance profiles, as well as anytime algorithms where the performance profiles are conditioned on execution so far [43, 58, 16].
Reference: [56] <author> W. J. van der Linden and A. </author> <title> Verbeek. Coalition formation: A game-theoretic approach. </title> <editor> In H. A. M. Wilke, editor, </editor> <booktitle> Coalition Formation, volume 24 of Advances in Psychology. </booktitle> <publisher> North Holland, </publisher> <year> 1985. </year>
Reference-contexts: Externalities and agents with different problem solving capabilities are discussed in Section 6. Section 7 presents related research, and Section 8 concludes and describes future research directions. 2 Computation unit cost and algorithm as limits to rationality Coalition formation has been widely studied <ref> [20, 56, 32, 53, 52, 59, 22] </ref>, but to our knowledge, only among rational agents which can solve the coalition's optimization problem exactly, immediately, and without computation cost. This section describes how our model differs because it takes into account the cost of computation. <p> be distributed so that every subgroup of agents is better off staying in the social welfare maximizing coalition structure than by separating into a new coalition (individual agents and the group of all agents are also considered subgroups here)? The core (C) is the solution concept that satisfies this requirement <ref> [20, 56, 32] </ref>. The core of a game is a set of payoff configurations (~x; CS), where each ~x is a vector of payoffs to the agents in such a manner that no subgroup is motivated to depart from the coalition structure CS. <p> It is often too strong: in many cases it is empty <ref> [20, 56, 32, 59] </ref>. In such games there is no way to divide the social good so that the coalition structure becomes stable: any payoff configuration is prone to deviation by some subgroup of agents. <p> An often used solution is to pick the nucleolus which, intuitively speaking, corresponds to a payoff vector that is in the center of the set of payoff vectors in the core <ref> [20, 56, 32] </ref>. A further problem with the core is that the constraints in the definition become numerous as the number of agents increases. This is due to the combinatorial subset operator in the definition. Now we generalize the core to allow for bounded-rational agents. <p> In such games, the characteristic function value of a coalition is its minimax value from the normal form game <ref> [56] </ref>. A coalition's minimax value is the maximum payoff that the coalition can bring about for itself given that nonmembers choose strategies that are worst for the coalition. 24 function is appropriately rescaled based on the real c comp of the corresponding coalition S. <p> research. 16 On the other hand, results with strategic solution concepts are specific to a given interaction protocol while core-based analyses are not (unless the coalition formation process itself affects the payoffs). 26 7 Related research on computational coalition for- mation Coalition formation has been widely studied in game theory <ref> [20, 2, 3, 1, 56, 32] </ref>, and only the most relevant concepts were presented. Many of the solution concepts for coalition formation are static. They address the question of how to divide the payoffs among agents. Some of them also address the question of which coalition structure should form.
Reference: [57] <author> M. Wellman. </author> <title> A market-oriented programming environment and its application to distributed multicommodity flow problems. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 1-23, </pages> <year> 1993. </year>
Reference-contexts: Also, simpler routing problems have often been used as example applications in recent multiagent systems research <ref> [34, 59, 52, 57] </ref>. Table 1: One week of real vehicle and delivery data used in the experiments. <p> An agent updates its approximate local solution after each task transfer. In general equilibrium market mechanisms such as Walras <ref> [57] </ref>, non-manipulative agents iterate over the allocation of resources and tasks, and payments are usually made only after a final solution has been reached. Unlike our work, general equilibrium methods are only guaranteed to work in very restricted settings.
Reference: [58] <author> S. Zilberstein and S. Russell. </author> <title> Optimal composition of real-time systems. </title> <journal> Artificial Intelligence, </journal> <volume> 82(1-2):181-213, </volume> <year> 1996. </year>
Reference-contexts: at a computation unit cost c comp that is so high that it is not worthwhile to take any iterative refinement steps: the initial solutions are used (their computation requirements are assumed negligible). 2.1 Discussion of this model of bounded rationality Conceptually we allow the agents to use design-to-time algorithms <ref> [12, 58, 13] </ref>: once an agent has decided how much CPU time r S it will allocate to a computation, it can design an algorithm that will find a solution of cost c S (r S ). <p> The design-to-time framework is used instead of the anytime framework <ref> [43, 4, 17, 58] </ref> because to devise a normative theory of self-interested agents, the possibility that they design their algorithms to time has to be accounted for. <p> In general, for optimal meta-reasoning, the remaining part of a probabilistic performance profile should be conditioned on the algorithm's performance on that problem instance on previous CPU time steps <ref> [43, 58, 16] </ref>. 10 is divided among the agents in the coalition as will be presented later. <p> Extensions of our work include generalizing the methods of this paper to agents with different and probabilistic performance profiles, as well as anytime algorithms where the performance profiles are conditioned on execution so far <ref> [43, 58, 16] </ref>. Agents with probabilistic performance profiles may want to reselect a coalition if the value of their original coalition is lower than expected|but sunk computation cost has already been incurred. Future research should also address agents that can refine solutions generated by others.
Reference: [59] <author> G. Zlotkin and J. S. Rosenschein. </author> <title> Coalition, cryptography and stability: Mechanisms for coalition formation in task oriented domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 432-437, </pages> <address> Seattle, WA, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Also, simpler routing problems have often been used as example applications in recent multiagent systems research <ref> [34, 59, 52, 57] </ref>. Table 1: One week of real vehicle and delivery data used in the experiments. <p> Externalities and agents with different problem solving capabilities are discussed in Section 6. Section 7 presents related research, and Section 8 concludes and describes future research directions. 2 Computation unit cost and algorithm as limits to rationality Coalition formation has been widely studied <ref> [20, 56, 32, 53, 52, 59, 22] </ref>, but to our knowledge, only among rational agents which can solve the coalition's optimization problem exactly, immediately, and without computation cost. This section describes how our model differs because it takes into account the cost of computation. <p> It is often too strong: in many cases it is empty <ref> [20, 56, 32, 59] </ref>. In such games there is no way to divide the social good so that the coalition structure becomes stable: any payoff configuration is prone to deviation by some subgroup of agents. <p> f1,5g, f2,5g, and f3,5g achieved a better initial solution cost than the sum of the initial solution costs of the two agents separately, Fig. 5 (this set of pairs prevailed even without the route length restriction). 6 Externalities among coalitions and different al gorithms among agents As is common practice <ref> [20, 52, 53, 59, 22] </ref>, so far in this paper we have restricted our attention to studying coalition formation in characteristic function games (CFGs), S ). <p> Transfer schemes can trivially be used in conjunction with our work. In this hybrid method, our approach would be used to determine the bounded-rational coalition values, and the transfer scheme would be used to find an appropriate payoff division given those values. Zlotkin and Rosenschein <ref> [59] </ref> analyze coalitions among rational agents that cannot make side payments, while our agents do. Their analysis is limited to "Subadditive Task Oriented Domains" (STODs), which are a strict subset of CFGs, Fig. 3.
References-found: 59

