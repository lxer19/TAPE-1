URL: ftp://ftp.cse.ucsc.edu/pub/hsnlab/ucsc-crl-96-23.ps.Z
Refering-URL: http://www.cse.ucsc.edu/research/hsnlab/projects/cong-control.html
Root-URL: http://www.cse.ucsc.edu
Title: Two-Way TCP Traffic over Rate Controlled Channels: Effects and Analysis  
Author: Lampros Kalampoukas Anujan Varma and K. K. Ramakrishnan 
Address: Santa Cruz, CA 95064  Florham Park, NJ 07932  
Affiliation: Board of Studies in Computer Engineering University of California, Santa Cruz  AT&T Labs-Research  
Date: August 21, 1997  
Pubnum: UCSC-CRL-96-23  
Abstract: This research is supported by the Advanced Research Projects Agency (ARPA) under Contract No. F19628-96-C-0038 and by the NSF Young Investigator Award No. MIP-9257103. We thank MIL3 for donating to us the OPNET modeling and simulation tool. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Jacobson, </author> <title> "Congestion avoidance and control," </title> <booktitle> in Proc. of ACM SIGCOMM'88, </booktitle> <pages> pp. 314-329, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction The Transmission Control Protocol (TCP) has become the most widely used transport-layer protocol today, due largely to the explosive growth of the TCP/IP Internet in recent years. An important component of TCP is the collection of algorithms used to perform congestion control and recovery <ref> [1, 2] </ref>. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively [3, 4, 5, 6]. In this paper, our interest is in analyzing the dynamics of TCP connections in an Asynchronous Transfer Mode (ATM) network in the presence of two-way traffic. <p> Before proceeding further, it is important to mention how ack compression originates at the end systems in the two-way environment and how it causes throughput degradation. The genesis of ack compression can be traced to the slow-start phase of a TCP connection that increases the window progressively at startup <ref> [1] </ref>. The slow-start algorithm sets the initial window size to one and increases it by one with every acknowledgement received. This effectively doubles the window every round-trip time. Thus, during slow start, the receipt of every ack causes the end system to add two segments to its outgoing queue.
Reference: [2] <author> V. Jacobson, </author> <title> "Modified TCP congestion avoidance algorithm." message to end2end-interest mailing list, </title> <month> April </month> <year> 1990. </year>
Reference-contexts: 1 Introduction The Transmission Control Protocol (TCP) has become the most widely used transport-layer protocol today, due largely to the explosive growth of the TCP/IP Internet in recent years. An important component of TCP is the collection of algorithms used to perform congestion control and recovery <ref> [1, 2] </ref>. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively [3, 4, 5, 6]. In this paper, our interest is in analyzing the dynamics of TCP connections in an Asynchronous Transfer Mode (ATM) network in the presence of two-way traffic.
Reference: [3] <author> S. Floyd and V. Jacobson, </author> <title> "On traffic phase effects in packet-switched gateways," Internetworking: </title> <journal> Research and Experience, </journal> <volume> vol. 3, no. 3, </volume> <pages> pp. 115-156, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: An important component of TCP is the collection of algorithms used to perform congestion control and recovery [1, 2]. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively <ref> [3, 4, 5, 6] </ref>. In this paper, our interest is in analyzing the dynamics of TCP connections in an Asynchronous Transfer Mode (ATM) network in the presence of two-way traffic.
Reference: [4] <author> J. C. Mogul, </author> <title> "Observing TCP dynamics in real networks," </title> <booktitle> in Proc. of ACM SIGCOMM'92, </booktitle> <pages> pp. 305-317, </pages> <month> August </month> <year> 1992. </year> <note> References 26 </note>
Reference-contexts: An important component of TCP is the collection of algorithms used to perform congestion control and recovery [1, 2]. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively <ref> [3, 4, 5, 6] </ref>. In this paper, our interest is in analyzing the dynamics of TCP connections in an Asynchronous Transfer Mode (ATM) network in the presence of two-way traffic. <p> Alternatively, queueing outgoing acks at a higher priority eliminates ack compression, but requires support for message priorities in the protocol stack. This idea of processing acks at a higher priority was suggested by Mogul <ref> [4] </ref> in the context of IP routers. A subject of our future work will be to investigate these and other solutions to improve the performance of two-way TCP over ATM.
Reference: [5] <author> L. Zhang and D. D. Clark, </author> <title> "Oscillating behavior of network traffic: A case study simulation," </title> <journal> Intenetworking: Research and Experience, </journal> <volume> vol. 1, no. 2, </volume> <pages> pp. 101-112, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: An important component of TCP is the collection of algorithms used to perform congestion control and recovery [1, 2]. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively <ref> [3, 4, 5, 6] </ref>. In this paper, our interest is in analyzing the dynamics of TCP connections in an Asynchronous Transfer Mode (ATM) network in the presence of two-way traffic.
Reference: [6] <author> L. Zhang, S. Shenker, and D. D. Clark, </author> <title> "Observations on the dynamics of a congestion control algorithm: The effects of two-way traffic," </title> <booktitle> in Proc. of ACM SIGCOMM'91, </booktitle> <pages> pp. 133-147, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: An important component of TCP is the collection of algorithms used to perform congestion control and recovery [1, 2]. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively <ref> [3, 4, 5, 6] </ref>. In this paper, our interest is in analyzing the dynamics of TCP connections in an Asynchronous Transfer Mode (ATM) network in the presence of two-way traffic. <p> These packets and acknowledgements may share a common buffer in the end systems as well as network switches/routers. This sharing has been shown to result in an effect called ack compression, where acks of a connection arrive at the source bunched together <ref> [6, 7] </ref>. The result of ack-compression is a marked unfairness in the throughput received with competing connections, and reduced overall throughput compared to what could be expected without this effect [7]. Ack compression may occur either at the end system or in a switch/router. <p> In either case, the smooth flow of acknowledgements to the source is disturbed, potentially resulting in reduction of throughput for the TCP connections involved. The effect of ack compression and the resulting dynamics of transport protocols under two-way traffic have been studied previously by Zhang, et al. <ref> [6] </ref>, and by Wilder, et al. [7]. Zhang, et al. [6] studied TCP dynamics under two-way traffic in a datagram network by simulation, and observed that the queues in the routers exhibit periodic behavior. <p> The effect of ack compression and the resulting dynamics of transport protocols under two-way traffic have been studied previously by Zhang, et al. <ref> [6] </ref>, and by Wilder, et al. [7]. Zhang, et al. [6] studied TCP dynamics under two-way traffic in a datagram network by simulation, and observed that the queues in the routers exhibit periodic behavior. Wilder, et al. [7] observed a similar effect in OSI-based networks under two-way traffic causing unfairness and an overall reduction in throughput.
Reference: [7] <author> R. Wilder, K. K. Ramakrishnan, and A. Mankin, </author> <title> "Dynamics of congestion control and avoidance of two-way traffic in an OSI testbed," </title> <journal> ACM Computer Communication Review, </journal> <volume> vol. 21, no. 2, </volume> <pages> pp. 43-58, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: These packets and acknowledgements may share a common buffer in the end systems as well as network switches/routers. This sharing has been shown to result in an effect called ack compression, where acks of a connection arrive at the source bunched together <ref> [6, 7] </ref>. The result of ack-compression is a marked unfairness in the throughput received with competing connections, and reduced overall throughput compared to what could be expected without this effect [7]. Ack compression may occur either at the end system or in a switch/router. <p> The result of ack-compression is a marked unfairness in the throughput received with competing connections, and reduced overall throughput compared to what could be expected without this effect <ref> [7] </ref>. Ack compression may occur either at the end system or in a switch/router. In either case, the smooth flow of acknowledgements to the source is disturbed, potentially resulting in reduction of throughput for the TCP connections involved. <p> The effect of ack compression and the resulting dynamics of transport protocols under two-way traffic have been studied previously by Zhang, et al. [6], and by Wilder, et al. <ref> [7] </ref>. Zhang, et al. [6] studied TCP dynamics under two-way traffic in a datagram network by simulation, and observed that the queues in the routers exhibit periodic behavior. Wilder, et al. [7] observed a similar effect in OSI-based networks under two-way traffic causing unfairness and an overall reduction in throughput. <p> transport protocols under two-way traffic have been studied previously by Zhang, et al. [6], and by Wilder, et al. <ref> [7] </ref>. Zhang, et al. [6] studied TCP dynamics under two-way traffic in a datagram network by simulation, and observed that the queues in the routers exhibit periodic behavior. Wilder, et al. [7] observed a similar effect in OSI-based networks under two-way traffic causing unfairness and an overall reduction in throughput.
Reference: [8] <author> F. Bonomi and K. W. Fendick, </author> <title> "The rate-based flow Control framework for the Available Bit Rate ATM service," </title> <journal> IEEE Network, </journal> <volume> vol. 9, no. 2, </volume> <pages> pp. 25-39, </pages> <month> March/April </month> <year> 1995. </year>
Reference-contexts: Our interest in this paper is on TCP operating over a rate-controlled channel, such as that offered by the Available Bit Rate (ABR) service in an Asynchronous Transfer Mode (ATM) network <ref> [8] </ref>. It is expected that the burstiness of the traffic seen at the network nodes (switches or routers) would be less in a rate-controlled network as compared to one without rate control. <p> Several earlier studies have been reported on the behavior of TCP in ATM networks [9, 10, 11], but none of them consider the effects of two-way traffic on TCP behavior. The Available-Bit-Rate (ABR) service class <ref> [8] </ref> was defined to support delay-tolerant best-effort applications and employ rate-based feedback mechanisms to allow the sources to adjust their 2. Dynamics of TCP in a Two-Way Traffic Environment 3 transmission rates to make full utilization of the available network capacity [8]. <p> The Available-Bit-Rate (ABR) service class <ref> [8] </ref> was defined to support delay-tolerant best-effort applications and employ rate-based feedback mechanisms to allow the sources to adjust their 2. Dynamics of TCP in a Two-Way Traffic Environment 3 transmission rates to make full utilization of the available network capacity [8]. The rate-control framework developed by the ATM Forum allows a number of options for the switches to signal their congestion state to the source. The most promising of these, the explicit-rate marking option, is the focus of our work.
Reference: [9] <author> D. E. Comer and J. C. Lin, </author> <title> "TCP buffering and performance over an ATM network," </title> <journal> Internet-working: Research and Experience, </journal> <volume> vol. 6, </volume> <pages> pp. 1-13, </pages> <year> 1995. </year>
Reference-contexts: Although our analysis is focussed on TCP over ABR, the results apply equally well to TCP operating over other networks providing a steady rate, predictable delay, and in-order delivery. Several earlier studies have been reported on the behavior of TCP in ATM networks <ref> [9, 10, 11] </ref>, but none of them consider the effects of two-way traffic on TCP behavior. The Available-Bit-Rate (ABR) service class [8] was defined to support delay-tolerant best-effort applications and employ rate-based feedback mechanisms to allow the sources to adjust their 2.
Reference: [10] <author> S. Floyd and A. Romanow, </author> <title> "Dynamics of TCP traffic over ATM networks," </title> <booktitle> in Proc. of ACM SIGCOMM'94, </booktitle> <pages> pp. 79-88, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Although our analysis is focussed on TCP over ABR, the results apply equally well to TCP operating over other networks providing a steady rate, predictable delay, and in-order delivery. Several earlier studies have been reported on the behavior of TCP in ATM networks <ref> [9, 10, 11] </ref>, but none of them consider the effects of two-way traffic on TCP behavior. The Available-Bit-Rate (ABR) service class [8] was defined to support delay-tolerant best-effort applications and employ rate-based feedback mechanisms to allow the sources to adjust their 2.
Reference: [11] <author> L. Kalampoukas and A. Varma, </author> <title> "Performance of TCP over multi-hop ATM networks: A comparative study of ATM layer congestion control schemes," </title> <booktitle> in Proc. of ICC'95, </booktitle> <pages> pp. 1472-1477, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Although our analysis is focussed on TCP over ABR, the results apply equally well to TCP operating over other networks providing a steady rate, predictable delay, and in-order delivery. Several earlier studies have been reported on the behavior of TCP in ATM networks <ref> [9, 10, 11] </ref>, but none of them consider the effects of two-way traffic on TCP behavior. The Available-Bit-Rate (ABR) service class [8] was defined to support delay-tolerant best-effort applications and employ rate-based feedback mechanisms to allow the sources to adjust their 2.
Reference: [12] <author> L. Kalampoukas, A. Varma, and K. K. Ramakrishnan, </author> <title> "Dynamics of an explicit rate allocation algorithm for ATM networks," </title> <booktitle> in Proc. of International Broadband Communications Conference'96, </booktitle> <address> IFIP-IEEE, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: It has been shown that, by the use of a rate-allocation algorithm that maintains state, unfairness problems that occur in a datagram network due to the differences in round-trip delay of TCP connections can be avoided in an ATM network <ref> [12] </ref>. The primary objective of this paper is to analyze the dynamics of two-way TCP traffic over a rate-controlled network, develop analytical models that describe the system behavior, quantify the performance degradation, and validate the models by simulation. <p> Furthermore, in the analysis of Section 3, we assume that the network provides a constant-delay path between the end nodes. Such an assumption is realistic in the ATM ABR environment when the switches employ explicit rate allocation, since the queue sizes in the switches can be maintained small <ref> [12] </ref>. The queueing delays in network switches are taken into account in the simulation results of Section 5. The data segments transmitted by the TCP connection in one direction share a common outgoing ATM virtual channel with the acks transmitted by the connection in the other direction. <p> There is one queue per output port for ABR traffic and its scheduling policy is FIFO, with each output queue being shared by all the virtual channels (VCs) sharing the outgoing link. The switches support the explicit rate allocation algorithm of Kalampoukas, et al. <ref> [12] </ref>. Each of the nodes implements the ABR source policy defined by ATM Forum [15]. <p> The use of per-VC (virtual channel) queues at the end systems does not offer us a cure when the data and acks of a bidirectional TCP conversation share a common VC. In an earlier paper <ref> [12] </ref> we examined the performance of TCP connections having very different round-trip times (RTT) in an ATM network. The maintenance of a current bandwidth allocation per virtual channel (VC) at the ATM switches was shown to achieve fairness in throughput superior to that in a datagram network.
Reference: [13] <author> L. Kalampoukas, A. Varma, and K. K. Ramakrishnan, </author> <title> "Two-way TCP traffic over ATM: Effects and analysis," </title> <type> Tech. Rep. </type> <institution> UCSC-CRL-96-23, Univ. of California, Santa Cruz, </institution> <year> 1996. </year>
Reference-contexts: For simplicity, in our analysis we will assume that the TCP processing time in the end system is small and therefore, can be ignored. A detailed discussion of the effect of non-zero TCP processing time is omitted due to space constraints but can be found in <ref> [13] </ref>. The analysis and the simulation results presented in [13] validate the assumption that a non-zero TCP processing time does not alter the fundamental dynamics of two-way traffic analyzed and presented in this paper. <p> A detailed discussion of the effect of non-zero TCP processing time is omitted due to space constraints but can be found in <ref> [13] </ref>. The analysis and the simulation results presented in [13] validate the assumption that a non-zero TCP processing time does not alter the fundamental dynamics of two-way traffic analyzed and presented in this paper. <p> We will later show that this behavior can persist in steady state when the windows reach their final values. A detailed description of how ack compression builds up can be found in <ref> [13] </ref>. In the preceding discussion we have merely linked the genesis of ack compression to the the slow-start window growth phase. We should make clear however that any window increase (i.e. 3. <p> A detailed discusion and simulation results of this case is omitted due to space contraints and can be found in <ref> [13] </ref>. 5.3 Simulation Results for Networks with Asymmetric Links We now proceed to verify our analytical results for the asymmetric case where the transmission rates in the two directions differ. We consider again the simple configuration of Figure 5.1.
Reference: [14] <author> W. R. Stevens and G. R. </author> <title> Wright, </title> <journal> TCP/IP Illustrated, </journal> <volume> vol. 2. </volume> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1995. </year>
Reference-contexts: Therefore, to avoid packet losses at the source node, we assume that the IP queue has a size equal to the maximum window size of the sending TCP. The interaction between TCP and IP described above is consistent with the 4.4 BSD-Lite Unix Release <ref> [14] </ref>. 3 Analysis of Two-Way TCP Dynamics in Networks with Symmetric Links In the previous section, we described how the TCP window growth during the slow-start process gives rise to the effect of ack compression under two-way traffic.
Reference: [15] <author> S. S. Sathaye, </author> <title> Traffic management specification, version 4.0. Traffic Management Working Group, </title> <month> April </month> <year> 1996. </year>
Reference-contexts: The switches support the explicit rate allocation algorithm of Kalampoukas, et al. [12]. Each of the nodes implements the ABR source policy defined by ATM Forum <ref> [15] </ref>.
Reference: [16] <author> L. Kalampoukas and A. Varma, </author> <title> "Analysis of source policy in rate-controlled ATM networks," </title> <booktitle> in Proc. of ICC'96, IEEE, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: Note that the rate increase process is not smooth but consists of a sequence of steps. This is because of the gaps in the data flow during the TCP slow-start process, and has been analyzed in <ref> [16] </ref>. The progress for the left-to-right TCP connection is shown in Figure 5.4, in terms of the increase in TCP sequence numbers transmitted by the connection.
Reference: [17] <author> R. Cole, D. Shur, and C. Villamizar, </author> <title> "IP over ATM: A framework document," Request for Comments (RFC): </title> <year> 1932, </year> <month> April </month> <year> 1996. </year>
Reference-contexts: The approach currently being undertaken is to map all TCP connections set up between the end-systems (in general, subnetworks containing the end-systems) to a single ATM connection <ref> [17] </ref>. Synchronization among TCP connections that are transported within a common ATM virtual channel can give rise to the effects discussed above. 6. Conclusion 24 5.5 Simulation Results for a Client-Server Topology We close this section with some simulation results from a final network configuration, one that is encountered frequently.
References-found: 17

