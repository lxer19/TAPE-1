URL: ftp://rtcl.eecs.umich.edu/outgoing/zaher/rtss95.ps
Refering-URL: http://www.eecs.umich.edu/~zaher/publications.html
Root-URL: http://www.cs.umich.edu
Email: fzaher,kgshing@eecs.umich.edu  
Title: Optimal Combined Task and Message Scheduling in Distributed Real-Time Systems  
Author: Tarek F. Abdelzaher and Kang G. Shin 
Keyword: Key Words Real-time scheduling, combined task and message scheduling, distributed systems, resource constraints  
Address: Ann Arbor, Michigan 48109-2122  
Affiliation: Real-time Computing Laboratory Department of Electrical Engineering and Computer Science The University of Michigan  
Abstract: In this paper we present a branch-and-bound (B&B) algorithm for combined task and message scheduling in distributed hard real-time systems. The algorithm finds an optimal schedule for a set of communicating tasks with known arrival times, precedence constraints, and resource requirements in conjunction with the assignment and scheduling of intertask messages over communication links. The schedule is "optimal" in the sense of minimizing maximum task lateness under a heuristic message priority assignment found during the search. A robotics application is used to illustrate the utility and potential of the algorithm. Results of an extensive simulation study analyzing its performance are also presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. G. Shin and C. J. Hou, </author> <title> "Analytic models of adaptive load sharing schemes in distributed real-time systems," </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> vol. 4, no. 7, </volume> <pages> pp. 740-761, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Since periodic tasks are the base load of such systems, we shall focus on their scheduling. Aperiodic tasks can be handled by such dynamic techniques as load sharing <ref> [1] </ref>. Intermachine message communication affects task schedulability. For the case of fixed-priority tasks, * The work reported in this paper was supported in part by the National Science Foundation under grant MIP-9203895 and the Office of Naval Research under grants N00014-94-1-0229.
Reference: [2] <author> L. Sha, R. Rajkumar, and S. S. Sathaye, </author> <title> "Generalized rate monotonic scheduling theory: A framework for developing real-time systems," </title> <journal> Proceeding of IEEE, </journal> <volume> vol. 82, no. 1, </volume> <pages> pp. 68-82, </pages> <month> Jan </month> <year> 1994. </year>
Reference-contexts: Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of NSF or ONR. generalized rate monotonic analysis <ref> [2] </ref> provides a uniform theory for scheduling both tasks and messages. A similar scheme is developed by Tindell for a ring architecture running a TDMA protocol [3]. When task priorities are not fixed, several heuristic algorithms have been proposed for combined task and message scheduling, e.g., [4] and [5].
Reference: [3] <author> K. Tindell and J. Clark, </author> <title> "Holistic schedulability analysis for hard real-time systems," </title> <journal> Microprocessing and Microprogramming, </journal> <volume> vol. 40, </volume> <pages> pp. 117-134, </pages> <year> 1994. </year>
Reference-contexts: A similar scheme is developed by Tindell for a ring architecture running a TDMA protocol <ref> [3] </ref>. When task priorities are not fixed, several heuristic algorithms have been proposed for combined task and message scheduling, e.g., [4] and [5]. A flexible scheme which combines off-line analysis with on line guarantess was suggested in [6] for uniprocessors and in [7] for multiprocessors.
Reference: [4] <author> R. Agne, </author> <title> "A distributed o*ine scheduler for distributed hard real-time systems," </title> <booktitle> in Distributed Computer Control Systems. Proceedings of the 10th IFAC Workshop, </booktitle> <pages> pp. 35-40, </pages> <address> Summering, Austria, </address> <month> Septem-ber </month> <year> 1991. </year>
Reference-contexts: A similar scheme is developed by Tindell for a ring architecture running a TDMA protocol [3]. When task priorities are not fixed, several heuristic algorithms have been proposed for combined task and message scheduling, e.g., <ref> [4] </ref> and [5]. A flexible scheme which combines off-line analysis with on line guarantess was suggested in [6] for uniprocessors and in [7] for multiprocessors.
Reference: [5] <author> K. Jeffay, </author> <title> "On latency management in time-shared operating systems," </title> <booktitle> in Real-Time Operating Systems and Software, </booktitle> <pages> pp. 86-90, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: A similar scheme is developed by Tindell for a ring architecture running a TDMA protocol [3]. When task priorities are not fixed, several heuristic algorithms have been proposed for combined task and message scheduling, e.g., [4] and <ref> [5] </ref>. A flexible scheme which combines off-line analysis with on line guarantess was suggested in [6] for uniprocessors and in [7] for multiprocessors. If all future task arrival times are known (e.g., in the case where all tasks are periodic), one may construct the entire task and message schedule off-line.
Reference: [6] <author> H. Chetto, M. Silly, and T. Bouchentouf, </author> <title> "Dynamic scheduling of real-time tasks under precedence constraints," </title> <journal> Journal of Real-Time Systems, </journal> <volume> vol. 2, no. 3, </volume> <pages> pp. 181-194, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: When task priorities are not fixed, several heuristic algorithms have been proposed for combined task and message scheduling, e.g., [4] and [5]. A flexible scheme which combines off-line analysis with on line guarantess was suggested in <ref> [6] </ref> for uniprocessors and in [7] for multiprocessors. If all future task arrival times are known (e.g., in the case where all tasks are periodic), one may construct the entire task and message schedule off-line. A heuristic approach to this problem was presented in [8].
Reference: [7] <author> M. D. Natale and J. A. Stankovic, </author> <title> "Dynamic end-to-end guarantees in distributed real-time systems," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 216-227, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: When task priorities are not fixed, several heuristic algorithms have been proposed for combined task and message scheduling, e.g., [4] and [5]. A flexible scheme which combines off-line analysis with on line guarantess was suggested in [6] for uniprocessors and in <ref> [7] </ref> for multiprocessors. If all future task arrival times are known (e.g., in the case where all tasks are periodic), one may construct the entire task and message schedule off-line. A heuristic approach to this problem was presented in [8]. An optimal implicit enumeration technique was presented in [9]. <p> By substituting from Eqs. (5) and (6) into Eqs. (3) and (4), we compute the lateness lower bound. 4 Application and Evaluation To demonstrate the utility of the algorithm, and compare it to other approaches, it was applied to presched-ule modules for a simple control application described in <ref> [7] </ref>. Physically, the application consists of a sensory device mounted on a motorized platform that must detect and track specific objects in the environment. The model consists of 6 tasks broken into 22 modules, which together exchange 10 messages, 6 of them are sent across processor boundaries. <p> The Actuator Manager communicates locally with an Actuator Control Task T 5 . Together they control actuators. The Signal Task is responsible for detecting alarm conditions and initiating an alarm signal if necessary. Figure 2 is the task flow graph of the system as illustrated in <ref> [7] </ref>. In the graph each node is labeled with the corresponding module number, and each arc representing an interprocessor message is labeled with the corresponding message number. Arcs representing local communication are treated as precedence constraints. (In [7] modules are termed tasks, and tasks are termed processes. <p> Figure 2 is the task flow graph of the system as illustrated in <ref> [7] </ref>. In the graph each node is labeled with the corresponding module number, and each arc representing an interprocessor message is labeled with the corresponding message number. Arcs representing local communication are treated as precedence constraints. (In [7] modules are termed tasks, and tasks are termed processes. Interprocessor messages are modeled as separate modules. We use a different notation for such messages, but for ease of comparison, we denote them by the number used for the corresponding task in [7].) Table 1 gives the computation time and deadline <p> local communication are treated as precedence constraints. (In <ref> [7] </ref> modules are termed tasks, and tasks are termed processes. Interprocessor messages are modeled as separate modules. We use a different notation for such messages, but for ease of comparison, we denote them by the number used for the corresponding task in [7].) Table 1 gives the computation time and deadline for each module, as well as the transmission time of each message drawn from [7]. Modules arrive at time 0. The algorithm was executed, and the optimal schedule was generated (in less than 1 second). <p> We use a different notation for such messages, but for ease of comparison, we denote them by the number used for the corresponding task in <ref> [7] </ref>.) Table 1 gives the computation time and deadline for each module, as well as the transmission time of each message drawn from [7]. Modules arrive at time 0. The algorithm was executed, and the optimal schedule was generated (in less than 1 second). <p> A heuristic algorithm which resolves precedence constraints by assigning non-overlapping time slots to successive modules results in a minimum laxity of 2.57 as mentioned in <ref> [7] </ref>. The performance of our algorithm was evaluated for larger systems. In order to analyze the effects of various workloads, a simulator was constructed to generate task graphs with the desired characteristics. On each run, the algorithm was given a task graph, and the number of generated vertices was recorded.
Reference: [8] <author> K. Ramamritham, </author> <title> "Allocation and scheduling of complex periodic tasks," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 108-115, </pages> <year> 1990. </year>
Reference-contexts: If all future task arrival times are known (e.g., in the case where all tasks are periodic), one may construct the entire task and message schedule off-line. A heuristic approach to this problem was presented in <ref> [8] </ref>. An optimal implicit enumeration technique was presented in [9]. It does not account for resource requirements, and assumes a priori known message delays. While a communication paradigm such as a real-time channel [10] can bound message delays, the bound is generally a function of assigned message priorities.
Reference: [9] <author> D.-T. Peng and K. G. Shin, </author> <title> "Optimal scheduling of cooperative tasks in a distributed system using an enumerative method," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 19, no. 3, </volume> <pages> pp. 253-267, </pages> <month> Mar </month> <year> 1993. </year>
Reference-contexts: If all future task arrival times are known (e.g., in the case where all tasks are periodic), one may construct the entire task and message schedule off-line. A heuristic approach to this problem was presented in [8]. An optimal implicit enumeration technique was presented in <ref> [9] </ref>. It does not account for resource requirements, and assumes a priori known message delays. While a communication paradigm such as a real-time channel [10] can bound message delays, the bound is generally a function of assigned message priorities.
Reference: [10] <author> D. D. Kandlur, K. G. Shin, and D. Ferrari, </author> <title> "Real-time communication in multi-hop networks," </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> vol. 5, no. 10, </volume> <pages> pp. 1044-1056, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: A heuristic approach to this problem was presented in [8]. An optimal implicit enumeration technique was presented in [9]. It does not account for resource requirements, and assumes a priori known message delays. While a communication paradigm such as a real-time channel <ref> [10] </ref> can bound message delays, the bound is generally a function of assigned message priorities. <p> Propagation delays d prop incurred along communication links are proportional to link length, and are therefore constant too. Queuing delays depend on message priorities and contention over the links. We assume that the underlying point-to-point interconnection network is equipped with real-time channels <ref> [10] </ref>. This makes it possible to obtain an estimate of message delays given message priorities and the messages transmitted over each link as described in [10]. The estimate is pessimistic because it assumes all messages across a link arrive at the same time. <p> Queuing delays depend on message priorities and contention over the links. We assume that the underlying point-to-point interconnection network is equipped with real-time channels <ref> [10] </ref>. This makes it possible to obtain an estimate of message delays given message priorities and the messages transmitted over each link as described in [10]. The estimate is pessimistic because it assumes all messages across a link arrive at the same time. In principle a better estimate of communication delays is possible, leading to a better solution.
Reference: [11] <author> D.-T. Peng and K. G. Shin, </author> <title> "Static allocation of periodic tasks with precedence," </title> <booktitle> in Distributed Computing Systems, </booktitle> <pages> pp. 190-198. </pages> <publisher> IEEE, </publisher> <month> Jun </month> <year> 1989. </year>
Reference-contexts: Each task is assumed to reside permanently on one processor. The problem of assigning tasks to processors is not addressed in this paper. A suitable task assignment algorithm is described in <ref> [11] </ref>. 3 The Solution Approach To minimize maximum task lateness (the difference between task completion time and deadline) we use a B&B method which starts with a valid schedule, 1 and improves it in each subsequent search vertex by modifying task synchronization constraints, so that the lateness of the latest task
Reference: [12] <author> J. Xu and D. L. Parnas, </author> <title> "Scheduling processes with release times, deadlines, precedence, and exclusion relations," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. SE-16, no. 3, </volume> <pages> pp. 360-369, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Schedule lateness refers to the lateness of the latest task in the 1 We will discuss later how to find a valid schedule initially. schedule. A schedule is feasible if its lateness is non-positive. A similar approach was proposed by Xu and Parnas <ref> [12] </ref> for uniprocessors. Xu [13] and Shepard & Gagne [14] extended the idea to multiprossor scheduling. Unlike ours, the model by Xu [13], is not suitable for distributed systems, because it neglects interpro-cessor communication delays, and allows for cost-free task migration.
Reference: [13] <author> J. Xu, </author> <title> "Multiprocessor scheduling of processes with release times, deadlines, precedence, and exclusion relations," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 19, no. 2, </volume> <pages> pp. 139-154, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Schedule lateness refers to the lateness of the latest task in the 1 We will discuss later how to find a valid schedule initially. schedule. A schedule is feasible if its lateness is non-positive. A similar approach was proposed by Xu and Parnas [12] for uniprocessors. Xu <ref> [13] </ref> and Shepard & Gagne [14] extended the idea to multiprossor scheduling. Unlike ours, the model by Xu [13], is not suitable for distributed systems, because it neglects interpro-cessor communication delays, and allows for cost-free task migration. <p> A schedule is feasible if its lateness is non-positive. A similar approach was proposed by Xu and Parnas [12] for uniprocessors. Xu <ref> [13] </ref> and Shepard & Gagne [14] extended the idea to multiprossor scheduling. Unlike ours, the model by Xu [13], is not suitable for distributed systems, because it neglects interpro-cessor communication delays, and allows for cost-free task migration.
Reference: [14] <author> T. Shepard and M. Gagne, </author> <title> "A pre-run-time scheduling algorithm for hard real-time systems," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 17, no. 7, </volume> <pages> pp. 669-677, </pages> <month> Jul </month> <year> 1991. </year>
Reference-contexts: A schedule is feasible if its lateness is non-positive. A similar approach was proposed by Xu and Parnas [12] for uniprocessors. Xu [13] and Shepard & Gagne <ref> [14] </ref> extended the idea to multiprossor scheduling. Unlike ours, the model by Xu [13], is not suitable for distributed systems, because it neglects interpro-cessor communication delays, and allows for cost-free task migration. Shepard and Gagne [14] assume a static task assignment, but their algorithm may fail to find an existing feasible <p> Xu [13] and Shepard & Gagne <ref> [14] </ref> extended the idea to multiprossor scheduling. Unlike ours, the model by Xu [13], is not suitable for distributed systems, because it neglects interpro-cessor communication delays, and allows for cost-free task migration. Shepard and Gagne [14] assume a static task assignment, but their algorithm may fail to find an existing feasible solution because it improves the lateness of the latest task by manipulating only its local processor schedule. It does not consider the possibility of forcing its remote predecessors to complete earlier. <p> In general, for a large range of workloads the algorithm generates an optimal solution at or near the root of the search tree. A similar observation was reported in <ref> [14] </ref>. This is due to the nature of the performance measure being optimized. Schedule lateness refers to the lateness of only one module.
Reference: [15] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest, </author> <title> Introduction to Algorithms, </title> <booktitle> chapter 25, </booktitle> <pages> pp. 527-531, </pages> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: To compute delays we need to determine the "best" path for each message. For this, messages are considered in descending order of priority, and the shortest delay path (given the paths taken by higher priority messages) is established for each using Dijkstra's algorithm <ref> [15] </ref>. 3.3 Setting up the Root Vertex Having computed message priorities and delays, a task flow graph is constructed for all task invocations. In the case of periodic tasks only one planning cycle needs to be considered.
Reference: [16] <author> M.-I. Chen and K.-J. Lin, </author> <title> "Dynamic priority ceilings: A concurrency control protocol for real-time systems," </title> <journal> Journal of Real Time Systems, </journal> <volume> vol. 2, no. 4, </volume> <pages> pp. 325-346, </pages> <year> 1990. </year>
Reference-contexts: Furthermore, a running module inherits the highest priority of all higher-priority modules it is blocking (because of exclusion constraints), thus achieving bounded priority inversion. We call this policy EDF with Deadline Inheritance, EDF-DI. Note that we do not use dynamic priority ceilings <ref> [16] </ref>, cause deadlocks cannot occur in our simplified model. In the rest of this paper we will occasionally use the same symbol to denote the module and its priority. 3.5 Branching Consider some vertex V in the search tree generated by our algorithm.
Reference: [17] <author> W. H. Kohler and K. Steiglitz, </author> <title> "Enumerative and iterative computational approach," </title> <journal> Computer and Job-Shop Scheduling Theory, </journal> <pages> pp. 229-287, </pages> <year> 1976. </year>
Reference-contexts: In what follows we first describe how sets L, R and M are generated, then prove that the resulting search space always contains a vertex for an optimal solution. The algorithm will find that solution as long as the bounding function computes a true lower bound <ref> [17] </ref>. To generate a child in set M, the priority of some message is increased to the current priority limit so that the lateness of the latest module at the parent vertex may be reduced. The priority limit is set to 1 (highest priority) at the root.
References-found: 17

