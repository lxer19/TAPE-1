URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1995/TR21.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Email: E-mail: fpanda,sivaramg@cis.ohio-state.edu  
Phone: Tel: (614)-292-5199, Fax: (614)-292-2911  
Title: Fast Broadcast and Multicast in Wormhole Multistage Networks with Multidestination Worms 1  
Author: Dhabaleswar K. Panda and Rajeev Sivaram 
Keyword: Broadcast, Multicast, Collective Communication, Wormhole Routing, Multistage Networks, and Path-based Routing.  
Address: Columbus, OH 43210-1277  
Affiliation: Dept. of Computer and Information Science The Ohio State University,  
Abstract: This paper presents a new approach to implement fast broadcast and multicast operations in bidirectional wormhole Multistage Interconnection Networks (MIN) with loopback, as used in IBM SP1/SP2 network. The novelty lies in using multidestination message passing mechanism instead of single destination (unicast) messages. For broadcast/multicast operation, it is shown that a single worm with multiple destinations is sufficient to allow pipelined replication of flits at appropriate intermediate switches and deliver copies to the required destinations. For higher communication start-up (t s ), for an n-processor system, this new approach leads to an asymptotic improvement by a factor of dlog 2 ne compared to the unicast-based message-passing. Two schemes for broadcast and multicast are presented together with the necessary architectural supports at a switch-level. Storage requirements at a switch to ensure deadlock freedom are also derived. These schemes are evaluated and compared with the unicast-based message-passing for different values of communication start-up time, link propagation time, switch delay, system size, and switch size. It is shown that the multidestination approach demonstrates superiority and scalability for higher t s and smaller switch size (&lt; 16 fi 16). For example, with t s =10.0 microsec, a broadcast operation on a 4K processor MIN with 4 fi 4 switches and 256 flits of message can be implemented in just 15.8 microsec using multidestina-tion approach compared to 138.4 microsec with unicast message-passing. Similarly, for a 1K processor MIN a multicast operation with arbitrary number of destinations takes a constant time of 20 microsec for a 256 flit message. These results indicate that the proposed scheme can be easily applied to current and future generation multistage systems like SP1/SP2 to provide fast and scalable collective communication operations, as defined by the Message Passing Interface (MPI) standard. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Barnett, D. G. Payne, and R. Van de Geijn. </author> <title> Optimal Broadcasting in Mesh-Connected Architectures. </title> <type> Technical Report TR91-38, </type> <institution> Dept. of Computer Science, Universityof Texas at Austin, </institution> <month> Dec </month> <year> 1991. </year>
Reference-contexts: For efficient support of the above paradigms, these systems require fast broadcast and multicast support from the underlying network, as defined by the Message Passing Interface (MPI) Standard [10]. Many software schemes have been recently proposed in the literature to efficiently implement broadcast and multicast in wormhole-routed k-ary n-cube <ref> [1, 9] </ref> and multistage networks [17]. All these schemes use multiple contention-free phases using point-to-point (unicast) message passing. For an n-processor system, these schemes require log 2 n communication phases for broadcast. Similarly, for multicasting to d destinations (d n), dlog 2 de communication phases are required.
Reference: [2] <author> C.-M. Chiang and L. M. Ni. </author> <title> Multi-Address Encoding for Multicast. </title> <booktitle> In Proceedings of the Parallel Computer Routing and Communication Workshop, </booktitle> <pages> pages 146-160, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: In this example, it can be seen that the original multidestination worm gets transformed to 5 multidestination worms. There are different ways to encode the addresses in a multidestination worm <ref> [2] </ref>. Depending on the header format being used and the ease of implementation, the destination list may or may not be actually partitioned. The all-destination encoding scheme uses one or more flits for each destination.
Reference: [3] <author> A. A. Chien and J. H. Kim. </author> <title> Planar-Adaptive Routing: Low-Cost Adaptive Networks for Multiprocessors. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 268-277, </pages> <year> 1992. </year> <month> 26 </month>
Reference-contexts: and have demonstrated that complete global reduction operations (including barrier synchronization) can be efficiently implemented with very small latency. 3 Contrary to the Hamiltonian path-based scheme [7], our scheme uses a Base Routing Con--formed Path (BRCP) model and can be applied to systems supporting deterministic (e-cube [4]) or adaptive (planar-adaptive <ref> [3] </ref> and turn-model [5]) routing. We have demonstrated that the latency of collective communication in k-ary n-cube networks can be significantly reduced by using multidestination worms instead of unicast worms.
Reference: [4] <author> W. J. Dally and C. L. Seitz. </author> <title> Deadlock-Free Message Routing in Multiprocessor Intercon--nection Networks. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 547-553, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: 1 Introduction The wormhole-routing switching technique is becoming the trend in building future parallel systems due to its inherent advantages like low-latency communication and reduced communication hardware overhead <ref> [4, 11] </ref>. IBM SP1/SP2, Intel Paragon, Cray T3D, Ncube, J-Machine, and Stanford DASH are representative systems falling into this category. All systems except IBM SP1/SP2 use k-ary n-cube interconnections. The IBM SP1/SP2 system [16] uses bidirectional multistage interconnection with loopback. <p> a multidestination exchange worm and have demonstrated that complete global reduction operations (including barrier synchronization) can be efficiently implemented with very small latency. 3 Contrary to the Hamiltonian path-based scheme [7], our scheme uses a Base Routing Con--formed Path (BRCP) model and can be applied to systems supporting deterministic (e-cube <ref> [4] </ref>) or adaptive (planar-adaptive [3] and turn-model [5]) routing. We have demonstrated that the latency of collective communication in k-ary n-cube networks can be significantly reduced by using multidestination worms instead of unicast worms.
Reference: [5] <author> C. J. Glass and L. Ni. </author> <title> The Turn Model for Adaptive Routing. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 278-287, </pages> <year> 1992. </year>
Reference-contexts: that complete global reduction operations (including barrier synchronization) can be efficiently implemented with very small latency. 3 Contrary to the Hamiltonian path-based scheme [7], our scheme uses a Base Routing Con--formed Path (BRCP) model and can be applied to systems supporting deterministic (e-cube [4]) or adaptive (planar-adaptive [3] and turn-model <ref> [5] </ref>) routing. We have demonstrated that the latency of collective communication in k-ary n-cube networks can be significantly reduced by using multidestination worms instead of unicast worms.
Reference: [6] <author> V. Kumar, A. Grama, A. Gupta, and G. Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <address> Benjamin/Cummings, </address> <year> 1994. </year>
Reference-contexts: Finally, we conclude the paper with future works. 2 Multidestination Mechanism for MINs In this section, we present a method for implementing the multidestination mechanism on Multistage Interconnection Networks (MINs). For simplicity, we introduce the mechanism with respect to the popular Omega network model <ref> [6] </ref>. However, the concept can be applied to any other MIN with appropriate modification. We also indicate the suitable architectural supports at a switch to implement this mechanism. 2.1 Omega Network Model with Loopback Consider an n-node Omega network with bidirectional interconnection.
Reference: [7] <author> X. Lin, P. K. McKinley, and L. M. Ni. </author> <title> Performance Evaluation of Multicast Wormhole Routing in 2D-Mesh Multicomputers. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages I:435-442, </pages> <year> 1991. </year>
Reference-contexts: In [13], we have introduced a multidestination exchange worm and have demonstrated that complete global reduction operations (including barrier synchronization) can be efficiently implemented with very small latency. 3 Contrary to the Hamiltonian path-based scheme <ref> [7] </ref>, our scheme uses a Base Routing Con--formed Path (BRCP) model and can be applied to systems supporting deterministic (e-cube [4]) or adaptive (planar-adaptive [3] and turn-model [5]) routing.
Reference: [8] <author> X. Lin and L. M. Ni. </author> <title> Deadlock-free Multicast Wormhole Routing in Multicomputer Networks. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 116-124, </pages> <year> 1991. </year>
Reference-contexts: In the following sections, we use a fixed header format (bit-string encoding) and the switches operate on appropriate bit patterns to route multidestination worms. It is to be noted that such replication is different from the hardware tree-based broadcast/multicast which leads to deadlock as discussed in <ref> [8] </ref>. The hardware tree-based replication scheme requires all output buffers to be free before replication is done to any of them. In our scheme, replication proceeds as long as at least one of the required output buffers is free.
Reference: [9] <author> P. K. McKinley, H. Xu, A.-H. Esfahanian, and L. M. Ni. </author> <title> Unicast-based Multicast Communication in Wormhole-routed Direct Networks. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages II:10-19, </pages> <year> 1992. </year>
Reference-contexts: For efficient support of the above paradigms, these systems require fast broadcast and multicast support from the underlying network, as defined by the Message Passing Interface (MPI) Standard [10]. Many software schemes have been recently proposed in the literature to efficiently implement broadcast and multicast in wormhole-routed k-ary n-cube <ref> [1, 9] </ref> and multistage networks [17]. All these schemes use multiple contention-free phases using point-to-point (unicast) message passing. For an n-processor system, these schemes require log 2 n communication phases for broadcast. Similarly, for multicasting to d destinations (d n), dlog 2 de communication phases are required.
Reference: [10] <author> Message Passing Interface Forum. </author> <title> MPI: A Message-Passing Interface Standard, </title> <month> Mar </month> <year> 1994. </year>
Reference-contexts: Such systems are being used for supporting either distributed-memory or distributed-shared memory programming paradigms. For efficient support of the above paradigms, these systems require fast broadcast and multicast support from the underlying network, as defined by the Message Passing Interface (MPI) Standard <ref> [10] </ref>. Many software schemes have been recently proposed in the literature to efficiently implement broadcast and multicast in wormhole-routed k-ary n-cube [1, 9] and multistage networks [17]. All these schemes use multiple contention-free phases using point-to-point (unicast) message passing.
Reference: [11] <author> L. Ni and P. K. McKinley. </author> <title> A Survey of Wormhole Routing Techniques in Direct Networks. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 62-76, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: 1 Introduction The wormhole-routing switching technique is becoming the trend in building future parallel systems due to its inherent advantages like low-latency communication and reduced communication hardware overhead <ref> [4, 11] </ref>. IBM SP1/SP2, Intel Paragon, Cray T3D, Ncube, J-Machine, and Stanford DASH are representative systems falling into this category. All systems except IBM SP1/SP2 use k-ary n-cube interconnections. The IBM SP1/SP2 system [16] uses bidirectional multistage interconnection with loopback.
Reference: [12] <author> D. K. Panda. </author> <title> Fast Barrier Synchronization in Wormhole k-ary n-cube Networks with Multidestination Worms. </title> <booktitle> In International Symposium on High Performance Computer Architecture, </booktitle> <pages> pages 200-209, </pages> <year> 1995. </year>
Reference-contexts: This raises a fundamental question whether the latency of these operations can be reduced by using a new and efficient mechanism. In our recent works <ref> [12, 13, 14] </ref>, we have introduced a new concept of multidestination wormhole routing. In contrast to unicast messages which have a single destination, this mechanism allows a message to have multiple destinations. Such worms can be designed to have different functionality. <p> Such worms can be designed to have different functionality. We have used the multidestination broadcast worm in [14] to design algorithms for broadcast and multicast operations in wormhole-routed k-ary n-cube systems with reduced latency. In <ref> [12] </ref>, we have introduced the concept of multidestination gather worms and in conjunction with the broadcast worm, we have shown how to implement complete and arbitrary barrier synchronization in wormhole-routed systems with reduced latency. <p> We also assume virtual cut-through routing. Each switch is equipped with a central queue where blocked messages can be stored. As described later, we will demonstrate that such an organization allows deadlock freedom during the replication process. 2.2 Supporting Multidestination Mechanism Our earlier work <ref> [12, 13, 14] </ref> on multidestination mechanism for k-ary n-cube networks assumes that a worm moves along a path passing through the routers of the intermediate destinations. The routers were assumed to support forward as well as absorb capability. However, such paths are not feasible in a MIN.
Reference: [13] <author> D. K. Panda. </author> <title> Global Reduction in Wormhole k-ary n-cube Networks with Multidestination Exchange Worms. </title> <booktitle> In International Parallel Processing Symposium, </booktitle> <month> Apr </month> <year> 1995. </year>
Reference-contexts: This raises a fundamental question whether the latency of these operations can be reduced by using a new and efficient mechanism. In our recent works <ref> [12, 13, 14] </ref>, we have introduced a new concept of multidestination wormhole routing. In contrast to unicast messages which have a single destination, this mechanism allows a message to have multiple destinations. Such worms can be designed to have different functionality. <p> In [12], we have introduced the concept of multidestination gather worms and in conjunction with the broadcast worm, we have shown how to implement complete and arbitrary barrier synchronization in wormhole-routed systems with reduced latency. In <ref> [13] </ref>, we have introduced a multidestination exchange worm and have demonstrated that complete global reduction operations (including barrier synchronization) can be efficiently implemented with very small latency. 3 Contrary to the Hamiltonian path-based scheme [7], our scheme uses a Base Routing Con--formed Path (BRCP) model and can be applied to systems <p> We also assume virtual cut-through routing. Each switch is equipped with a central queue where blocked messages can be stored. As described later, we will demonstrate that such an organization allows deadlock freedom during the replication process. 2.2 Supporting Multidestination Mechanism Our earlier work <ref> [12, 13, 14] </ref> on multidestination mechanism for k-ary n-cube networks assumes that a worm moves along a path passing through the routers of the intermediate destinations. The routers were assumed to support forward as well as absorb capability. However, such paths are not feasible in a MIN.
Reference: [14] <author> D. K. Panda, S. Singal, and P. Prabhakaran. </author> <title> Multidestination Message Passing Mechanism Conforming to Base Wormhole Routing Scheme. </title> <booktitle> In Proceedings of the Parallel Computer Routing and Communication Workshop, </booktitle> <pages> pages 131-145, </pages> <year> 1994. </year>
Reference-contexts: This raises a fundamental question whether the latency of these operations can be reduced by using a new and efficient mechanism. In our recent works <ref> [12, 13, 14] </ref>, we have introduced a new concept of multidestination wormhole routing. In contrast to unicast messages which have a single destination, this mechanism allows a message to have multiple destinations. Such worms can be designed to have different functionality. <p> In contrast to unicast messages which have a single destination, this mechanism allows a message to have multiple destinations. Such worms can be designed to have different functionality. We have used the multidestination broadcast worm in <ref> [14] </ref> to design algorithms for broadcast and multicast operations in wormhole-routed k-ary n-cube systems with reduced latency. <p> We also assume virtual cut-through routing. Each switch is equipped with a central queue where blocked messages can be stored. As described later, we will demonstrate that such an organization allows deadlock freedom during the replication process. 2.2 Supporting Multidestination Mechanism Our earlier work <ref> [12, 13, 14] </ref> on multidestination mechanism for k-ary n-cube networks assumes that a worm moves along a path passing through the routers of the intermediate destinations. The routers were assumed to support forward as well as absorb capability. However, such paths are not feasible in a MIN.
Reference: [15] <author> C. B. Stunkel, D. G. Shea, B. Abali, M. M. Denneeau, P. H. Hochschild, D. J. Joseph, B. J. Nathanson, M. Tsao, and P. R. Varker. </author> <booktitle> Architecture and Implementation of Vulcan. In Proceedings of the Int'l Parallel Processing Symposium, </booktitle> <pages> pages 268-274, </pages> <year> 1994. </year> <month> 27 </month>
Reference-contexts: Such movement allows a message going to a closer destination to traverse less number of stages. This feature helps in exploiting communication locality in the network. The switch organization is assumed to be closer to that of the high-performance switch, used in IBM SP1/SP2 <ref> [15] </ref>. A kfik switch has 2k input buffers, 2k output buffers, and controllers associated with the input and output buffers. If the communication links are w-bits wide, we assume the flit size to be w bits too. We also assume virtual cut-through routing.
Reference: [16] <author> Craig Stunkel, D. Shea, D. G. Grice, P. H. Hochschild, and M. Tsao. </author> <title> The SP1 High Performance Switch. </title> <booktitle> In Scalable High Performance Computing Conference, </booktitle> <pages> pages 150-157, </pages> <year> 1994. </year>
Reference-contexts: IBM SP1/SP2, Intel Paragon, Cray T3D, Ncube, J-Machine, and Stanford DASH are representative systems falling into this category. All systems except IBM SP1/SP2 use k-ary n-cube interconnections. The IBM SP1/SP2 system <ref> [16] </ref> uses bidirectional multistage interconnection with loopback. Such systems are being used for supporting either distributed-memory or distributed-shared memory programming paradigms. For efficient support of the above paradigms, these systems require fast broadcast and multicast support from the underlying network, as defined by the Message Passing Interface (MPI) Standard [10]. <p> These results have established the fact that the multidestination mechanism can be used in future generation wormhole systems to provide scalable collective communication. While wormhole systems using k-ary n-cube topology are being built, the traditional multistage interconnection (MIN) is coming back and gaining gradual popularity. Systems like IBM SP1/SP2 <ref> [16] </ref> use a wormhole-routed bidirectional MIN with loopback to exploit locality of references. As parallel systems start using such wormhole interconnection, the challenge is to incorporate efficient architectural supports into the interconnection so as to provide fast collective communication. <p> A typical such organization, with k fi k switches, consists of log k n stages. Each stage uses a shu*e interconnection. Bidirectional communication links connect intermediate stages. Similar to the interconnection structure being used in IBM SP1/SP2 <ref> [16] </ref>, we assume the processors to be connected to one side of the network. The switches support the loopback feature wherein, a typical single-destination unicast message can go up (forward) a few stages and come down (backward) to reach its destination.
Reference: [17] <author> H. Xu, Y.-D. Gui, and L. M. Ni. </author> <title> Optimal Software Multicast in Wormhole-Routed Multistage Networks. </title> <booktitle> In Proceedings of the Supercomputing Conference, </booktitle> <pages> pages pp. 703-712, </pages> <year> 1994. </year>
Reference-contexts: Many software schemes have been recently proposed in the literature to efficiently implement broadcast and multicast in wormhole-routed k-ary n-cube [1, 9] and multistage networks <ref> [17] </ref>. All these schemes use multiple contention-free phases using point-to-point (unicast) message passing. For an n-processor system, these schemes require log 2 n communication phases for broadcast. Similarly, for multicasting to d destinations (d n), dlog 2 de communication phases are required. <p> The associated architectural supports at a switch-level are presented. Storage requirements at a switch to ensure deadlock freedom are also derived. These schemes are evaluated and compared with unicast-based approach <ref> [17] </ref> to implement one-to-all broadcast and one-to-many multicast operations. The interplay between different technological parameters (communication start-up time, link propagation time, and switch delay) and architectural parameters (number of nodes and size of switches) is studied. <p> Fig. 3 (b) illustrates this algorithm for a 16 node Omega network with 2 fi 2 switches. The algorithm is more formally described in Fig. 4. It is to be noted that the unicast-based scheme <ref> [17] </ref> takes log 2 n steps to perform broadcast in an n-node multistage network. This leads to: Theorem 1 Both NLF and LF algorithms can implement one-to-all broadcast operation in an n-processor multistage network using only a single communication start-up.
References-found: 17

