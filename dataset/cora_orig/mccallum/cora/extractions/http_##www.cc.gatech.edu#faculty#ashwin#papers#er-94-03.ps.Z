URL: http://www.cc.gatech.edu/faculty/ashwin/papers/er-94-03.ps.Z
Refering-URL: http://www.cs.gatech.edu/faculty/ashwin/ABSTRACTS-summary.html
Root-URL: 
Email: -cox,ashwin-@cc.gatech.edu  
Title: Choosing Learning Strategies to Achieve Learning Goals  
Author: Michael T. Cox and Ashwin Ram 
Note: To appear in M desJardins A. Ram (Eds.), Proceedings of the 1994 AAAI Spring Symposium on Goal-Driven  AAAI Press.  
Address: Atlanta, GA 30332-0280  Menlo Park, CA:  
Affiliation: College of Computing Georgia Institute of Technology  Learning.  
Abstract: In open world applications a number of machine-learning techniques may potentially apply to a given learning situation. The research presented here illustrates the complexity involved in automatically choosing an appropriate technique in a multistrategy learning system. It also constitutes a step toward a general computational solution to the learning-strategy selection problem. The approach is to treat learning-strategy selection as a separate planning problem with its own set of goals, as is the case with ordinary problem-solvers. Therefore, the management and pursuit of these learning goals becomes a central issue in learning, similar to the goal-management problems associated with traditional planning systems. This paper explores some issues, problems, and possible solutions in such a framework. Examples are presented from a multistrategy learning system called Meta-AQUA.
Abstract-found: 1
Intro-found: 1
Reference: <author> Brodley, C. E. </author> <year> (1993). </year> <title> Addressing the Selective Superiority Problem: Automatic algorithm / model class selection. </title> <booktitle> In Machine Learning: Proceedings of the Tenth International Conference (pp. </booktitle> <pages> 17-24). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Cox, M. T. </author> <year> (1993). </year> <journal> Introspective Multistrategy Learning (Cognitive Science Tech. Rep. </journal> <volume> No. 2). </volume> <month> 8. </month> <title> Empirical results suggest that various inductive algorithms are better at classifying specific classes or particular distributions of data than others. Each algorithm is good at some but not all learning tasks. The selective superiority problem is to choose the most appropriate inductive algorithm, given a particular set of data (Brod-ley, 1993). </title> <type> 10 Atlanta: </type> <institution> Georgia Institute of Technology, College of Computing. </institution>
Reference: <author> Cox, M. T., & Ram, A. </author> <year> (1991). </year> <title> Using Introspective Reasoning to Select Learning Strategies. </title> <booktitle> In R. </booktitle>
Reference: <editor> S. Michalski and G. Tecuci (Eds.), </editor> <booktitle> Proceedings of the First International Workshop on Multistrategy Learning (pp. </booktitle> <pages> 217-230). </pages> <address> Washington, DC: </address> <institution> George Mason University, Center for Artificial Intelligence. </institution>
Reference: <author> Cox, M. T., & Ram, A. </author> <year> (1992). </year> <title> Multistrategy Learning with Introspective Meta-Explanations. </title> <editor> In D. Sleeman & P. Edwards (Eds.), </editor> <booktitle> Machine Learning: Proceedings of the Ninth International Conference (pp. </booktitle> <pages> 123-128). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> DeJong, G., & Mooney, R. </author> <year> (1986). </year> <title> Explanation-Based Learning: An alternative view, </title> <journal> Machine Learning, </journal> <volume> 1(2), </volume> <pages> 145-176. </pages>
Reference: <author> Freed, M., & Collins, G. </author> <year> (1994). </year> <title> Learning to Cope with Task Interactions. </title> <editor> In A. Ram & M. desJardins (Eds.), </editor> <booktitle> Proceedings of the 1994 AAAI Spring Symposium on Goal-Driven Learning. </booktitle> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Hammond, K. J. </author> <year> (1990). </year> <title> Learning and Enforcement: Stabilizing environments to facilitate activity. </title> <editor> In B. W. Porter & R. J. Mooney (Eds.), </editor> <booktitle> Machine Learning: Proceedings of the Seventh International Conference (pp. </booktitle> <pages> 204-210). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Hunter, L. E. </author> <year> (1990). </year> <title> Planning to Learn. </title> <booktitle> In Proceedings of Twelfth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 261-276). </pages> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Keller, R. M. </author> <year> (1986). </year> <title> Deciding What to Learn. </title> <type> (Technical Report ML-TR-6). </type> <institution> New Brunswick, NJ: Rutgers University, Department of Computer Science. </institution>
Reference: <author> Lebowitz, M. </author> <year> (1987). </year> <title> Experiments with Incremental Concept Formation: </title> <journal> UMIMEM. Machine Learning, </journal> <volume> 2, </volume> <pages> 103-138. </pages>
Reference: <author> Michalski, R. S. </author> <year> (1991). </year> <title> Inferential Learning Theory as a Basis for Multistrategy Task-Adaptive Learning. </title> <editor> In R. S. Michalski & G. Tecuci (Eds.), </editor> <booktitle> Proceedings of the First International Workshop on Multistrategy Learning (pp. </booktitle> <pages> 3-18). </pages> <address> Washington, DC: </address> <institution> George Mason University, Center for Artificial Intelligence. </institution>
Reference: <author> Michalski, R. S. </author> <year> (1994). </year> <title> Inferential Theory of Learning: Developing foundations for multistrat-egy learning. </title> <editor> In R. S. Michalski & G. Tecuci (Eds.), </editor> <booktitle> Machine Learning: A multistrategy approach IV. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Minsky, M. L. </author> <year> (1963). </year> <title> Steps Towards Artificial Intelligence. </title> <editor> In E. A. Feigenbaum & J. Feldman (Eds.), </editor> <booktitle> Computers and Thought (pp. </booktitle> <pages> 406-450). </pages> <address> New York: </address> <publisher> McGraw Hill. </publisher>
Reference-contexts: In more general terms, Ram and Cox (1994) have argued that three fundamental learning-subtasks must be solved for effective learning in an open world where many sources of failure exist. The subtasks are referred to as the credit or blame-assignment problem <ref> (Minsky, 1963) </ref>, deciding what to learn (Hunter, 1990; Keller, 1986; Ram, 1991; Ram & Hunter, 1992), and the strategy-selection problem (Cox & Ram, 1991; Michalski, 1991).
Reference: <author> Mitchell, T., Keller, R., & Kedar-Cabelli, S. </author> <year> (1986). </year> <title> Explanation-Based Generalization: A unifying view, </title> <journal> Machine Learning, </journal> <volume> 1(1), </volume> <pages> pp. 47-80. </pages>
Reference: <author> Provost, F. J., & Buchanan, B. G. </author> <year> (1992). </year> <title> Inductive Policy. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 255-261). </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Quilici, A. </author> <title> (in press). Toward Automatic Acquisition of an Advisory Systems Knowledge Base. </title> <note> To appear in Applied Intelligence. </note>
Reference: <author> Ram, A. </author> <year> (1991). </year> <title> A Theory of Questions and Question Asking. </title> <journal> The Journal of the Learning Sciences, </journal> <volume> 1(3&4), </volume> <pages> 273-318. </pages>
Reference: <author> Ram, A. </author> <year> (1993). </year> <title> Indexing, Elaboration and Refinement: Incremental Learning of Explanatory Cases. </title> <journal> Machine Learning, </journal> <volume> 10(3), </volume> <pages> 201-248. </pages>
Reference: <author> Ram, A., & Cox, M. T. </author> <year> (1994). </year> <title> Introspective Reasoning Using Meta-Explanations for Multistrategy Learning. </title> <editor> In R. S. Michalski & G. Tecuci (Eds.), </editor> <booktitle> Machine Learning: A multistrategy approach IV, </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Such reorganization of knowledge affects the conditions under which a particular piece of knowledge is retrieved or the kinds of indexes associated with an item in memory. A program called Meta-AQUA was written to test our theory of explanation, understanding, and learning. Given the short story below <ref> (taken from Ram & Cox, 1994) </ref>, the system attempts to understand each sentence by incorporating it into its current story representation, explain any anomalous or interesting features of the story, and learn from any reasoning failures. S1: A police dog sniffed at a passengers luggage in the Atlanta airport terminal.
Reference: <author> Ram, A., & Hunter, L. </author> <year> (1992). </year> <title> The Use of Explicit Goals for Knowledge to Guide Inference and Learning. </title> <journal> Applied Intelligence, </journal> <volume> 2(1), </volume> <pages> 47-73. </pages>
Reference: <author> Redmond, M. A. </author> <year> (1992). </year> <title> Learning by Observing and Understanding Expert Problem Solving (Technical Report GIT-CC-92/43). </title> <type> Doctoral dissertation, </type> <institution> Atlanta: Georgia Institute of Technology, College of Computing. </institution>
Reference: <author> Sacerdoti, E. D. </author> <year> (1975). </year> <title> A Structure for Plans and Behavior (Technical Note 109). </title> <type> Doctoral dissertation, </type> <institution> Menlo Park, CA: SRI International, Inc., AI Center. </institution>
Reference-contexts: To notice these types of interactions, however, requires a least-commitment approach such as that used in a non-linear hierarchical planner like NOAH <ref> (Sacerdoti, 1975) </ref>. Likewise, the system must realize that any indexing performed by an algorithm that is based on features of the dog-barking concept must follow any changes to the concept resulting from the inductive algorithm.
Reference: <author> Schaffer, C. </author> <year> (1993). </year> <title> Selecting a Classification Method by Cross-Validation. </title> <journal> Machine Learning, </journal> <volume> 13(1), </volume> <pages> 135-143. </pages>
References-found: 24

