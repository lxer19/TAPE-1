URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-437.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: johnliu]@media.mit.edu  
Title: Fast Lighting Independent Background Subtraction  
Author: Yuri Ivanov Aaron Bobick John Liu [yivanov bobick 
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: The Media Laboratory Massachusetts Institute of Technology  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 437 Appears in: Abstract This paper describes a new method of fast background subtraction based upon disparity verification that is invariant to run-time changes in illumination. Using two or more cameras, the method requires the off-line construction of disparity fields mapping the primary (or key) background image to each of the additional reference background images. At runtime, segmentation is performed by checking color intensity values at corresponding pixels. If more than two cameras are available, more robust segmentation can be achieved and in particular, the occlusion shadows can be generally eliminated as well. Because the method only assumes fixed background geometry, the technique allows for illumination variation at runtime. And, because no disparity search is performed at run time, the algorithm is easily implemented in real-time on conventional hardware. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aaron F. Bobick. </author> <title> Movement, activity, and action: The role of knowledge in the perception of motion. </title> <journal> In Philosophical Transactions Royal Society London B, </journal> <year> 1997. </year> <title> 3 a) b) c) object. Bottom row: results using (d) simple tolerance, (e) simple tolerance on refined disparity map, and (f) windowed means on refined disparity map. a) b) c) view, d) subtraction using a) and b) views, e) subtraction using b) and c) views, f) removing of the shadows using both reference cameras. </title> <type> 4 </type>
Reference-contexts: 1 Introduction: Background subtraction As computer vision begins to address the visual interpretation of action <ref> [1] </ref> applications such as surveillance and monitoring are becoming more relevant. Similarly, recent work in intelligent environments and perceptual user interfaces [2, 4] involve vision systems which interpret the pose or gesture of users in a known, indoor environment.
Reference: [2] <author> Trevor Darrell, Pattie Maes, Bruce Blumberg, and Alex Pentland. </author> <title> A novel environment for situated vision and behavior. </title> <booktitle> In Proc. of CVPR-94 Workshop for Visual Behaviors, </booktitle> <pages> pages 68-72, </pages> <address> Seattle, Washington, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: 1 Introduction: Background subtraction As computer vision begins to address the visual interpretation of action [1] applications such as surveillance and monitoring are becoming more relevant. Similarly, recent work in intelligent environments and perceptual user interfaces <ref> [2, 4] </ref> involve vision systems which interpret the pose or gesture of users in a known, indoor environment. In all of these situations the first fundamental problem encountered is the extraction of the image region corresponding to the person or persons in the room.
Reference: [3] <author> James W. Davis and Aaron F. Bobick. </author> <title> The representation and recognition of action using temporal templates. </title> <booktitle> In Proc. of CVPR-97, </booktitle> <year> 1997. </year>
Reference-contexts: The fundamental assumption of the algorithm is that the background is static in all respects: geometry, reflectance, and illumination. The second class of approach is based upon image motion only presuming that the background is stationary or at most slowly varying, but that the person is moving. <ref> [3] </ref>. In these methods no detailed model of the background is required. Of course, these methods are only appropriate for the direct interpretation of motion; if person stops moving, no signal remains to be processed. This method also requires constant or slowly varying geometry, reflectance, and illumination.
Reference: [4] <author> Stephen S. Intille, James W Davis, and Aaron F. Bo-bick. </author> <title> Real-time closed-world tracking. </title> <type> Tr 403, </type> <institution> MIT Media Lab, Vision and Modeling Group, </institution> <year> 1996. </year>
Reference-contexts: 1 Introduction: Background subtraction As computer vision begins to address the visual interpretation of action [1] applications such as surveillance and monitoring are becoming more relevant. Similarly, recent work in intelligent environments and perceptual user interfaces <ref> [2, 4] </ref> involve vision systems which interpret the pose or gesture of users in a known, indoor environment. In all of these situations the first fundamental problem encountered is the extraction of the image region corresponding to the person or persons in the room. <p> The proposed algorithm is simple and fast enough for real time performance. It is as fast as the normal template based background subtraction algorithm used in <ref> [4] </ref> in that each pixel is examined once. One obvious advantage is that in using disparity for iden tifying a candidate background, we can accommodate for changing textures and lighting conditions.
Reference: [5] <author> Ramesh C. Jain and Thomas O. Binford. </author> <title> Dialogue: Ignorance, </title> <booktitle> myopia and naivete in computer vision. In CVGIP, </booktitle> <volume> volume 53, </volume> <pages> pages 112-117, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: In the remainder of this paper we describe the algorithm in detail, present some experimental results, and discuss implementation details critical to the performance of the technique. 2 Our approach As noted in <ref> [5] </ref>, there have been very few efforts to use three-dimensional models of objects and knowledge of image formation in refining segmentation.
Reference: [6] <author> T. Kanade. </author> <title> A stereo machine for video-rate dense depth mapping and its new applications. </title> <booktitle> In Proc. of Image Understanding Workshop, </booktitle> <pages> pages 805-811, </pages> <address> Palm Springs, California, </address> <month> February </month> <year> 1995. </year>
Reference-contexts: Kanade, et al. [7] employ special purpose multi-baseline stereo hardware to compute dense depth maps in real-time. Provided with a background disparity value, the algorithm can perform real-time depth segmentation or "z-keying" <ref> [6] </ref>. The only assumption of the algorithm is that the geometry of the background does not vary. However, the computational burden of computing dense, robust, real-time stereo maps, requires great computational power. In this paper we present a fast, simple method for segmenting people from a geometrically static background. <p> Unfortunately, the direct implementation of this idea requires executing dense stereo algorithms in real time, which is possible, but either requires massive computational power or, as in work of Kanade, requires special hardware <ref> [7, 6] </ref>. The main insight of this paper is that, for the purposes of background subtraction, we can avoid the on-line computation of depth altogether and the reconstruction of the 3D model of space at each step.
Reference: [7] <author> M. Okutomi and T. Kanade. </author> <title> A multiple-baseline stereo. </title> <booktitle> In CMU-CS-TR, </booktitle> <year> 1990. </year>
Reference-contexts: This method also requires constant or slowly varying geometry, reflectance, and illumination. The final approach, and the one most related to the technique presented in this paper, is based upon geometry. Kanade, et al. <ref> [7] </ref> employ special purpose multi-baseline stereo hardware to compute dense depth maps in real-time. Provided with a background disparity value, the algorithm can perform real-time depth segmentation or "z-keying" [6]. The only assumption of the algorithm is that the geometry of the background does not vary. <p> Unfortunately, the direct implementation of this idea requires executing dense stereo algorithms in real time, which is possible, but either requires massive computational power or, as in work of Kanade, requires special hardware <ref> [7, 6] </ref>. The main insight of this paper is that, for the purposes of background subtraction, we can avoid the on-line computation of depth altogether and the reconstruction of the 3D model of space at each step.
Reference: [8] <author> Christopher Wren, Ali Azarbayejani, Trevor Darrell, and Alex Pentland. Pfinder: </author> <title> Real-time tracking of the human body. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 19(7) </volume> <pages> 780-785, </pages> <month> July </month> <year> 1997. </year>
Reference-contexts: Previous attempts at segmenting people from a known background have taken one of three approaches. Most common is a some form of background subtraction. For example, <ref> [8] </ref> uses statistical texture properties of the background observed over extended period of time to construct a model of the background, and use this model to decide which pixels in an input image do not fall into the background class.
References-found: 8

