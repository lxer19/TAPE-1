URL: http://www.cs.umass.edu/~dprecup/publications/Precup-Sutton-ICML-RL97.ps
Refering-URL: http://www-anw.cs.umass.edu/~rich/publications.html
Root-URL: 
Email: dprecup@cs.umass.edu  rich@cs.umass.edu  
Title: Multi-Time Models for Reinforcement Learning  
Author: Doina Precup Richard S. Sutton 
Address: Amherst, MA 01003  Amherst, MA 01003  
Affiliation: Department of Computer Science University of Massachusetts  Department of Computer Science University of Massachusetts  
Abstract: Reinforcement learning can be used not only to predict rewards, but also to predict states, i.e. to learn a model of the world's dynamics. Models can be defined at different levels of temporal abstraction. Multi-time models are models that focus on predicting what will happen, rather than when a certain event will take place. Based on multi-time models, we can define abstract actions, which enable planning (presumably in a more efficient way) at various levels of abstraction.
Abstract-found: 1
Intro-found: 1
Reference: <author> Sutton, R. S. </author> <year> (1995). </year> <title> TD models: Modeling the world as a mixture of time scales. </title> <booktitle> Proceedings of the Twelfth International Conference on Machine Learning (pp. </booktitle> <pages> 531-539). </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The goal of defining expressive and learnable models lead to the definition of fi-models <ref> (Sutton, 1995) </ref>. fi-models are a particular class of models, which "summarize" a mixture of models from different time scales in a single matrix. This section defines fi-models and discusses their properties.
References-found: 1

