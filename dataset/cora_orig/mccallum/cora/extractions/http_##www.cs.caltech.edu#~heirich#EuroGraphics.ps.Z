URL: http://www.cs.caltech.edu/~heirich/EuroGraphics.ps.Z
Refering-URL: http://www.cs.caltech.edu/~heirich/heirich.html
Root-URL: http://www.cs.caltech.edu
Title: Scalable Photorealistic Rendering of Complex Scenes  
Author: Alan Heirich James Arvo 
Date: August 30, 1996  
Address: Pasadena CA, 91125  
Affiliation: Department of Computer Science Center for Advanced Computing Research California Institute of Technology,  
Abstract: Photorealistic rendering of complex scenes poses computational demands as great as those of any large scale scientific or engineering calculation. Just as scientific calculations have benefited from access to scalable computing systems so too can photorealistic rendering. This paper describes an application of scalable parallel processors to photorealistic rendering of complex scenes by Monte Carlo path tracing. The application uses scalable implementation methods in order to achieve good performance on large numbers of computers and on models which require large amounts of data. The implementation is a message driven concurrent pipeline which employs a diffusion algorithm for dynamic load balancing. The application can be extended to partition extremely large models across physically distributed memory as well as to perform out-of-core calculations.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aboulenen, N., Gjessing, S., Goodman, J. & Woest, P. </author> <title> Hardware support for synchronization in the Scalable Coherent Interface (SCI). </title> <booktitle> Proc. 8th IEEE Int. Par. Proc. Symp. </booktitle> <year> (1994). </year>
Reference-contexts: Programming is more difficult on computer systems with physically distributed memory because communication and synchronization must be managed explicitly. As a matter of architectural necessity the largest parallel computer systems have these properties as do all scalable commodity network configurations <ref> [1, 3, 6, 21] </ref>. In order to execute a parallel program efficiently it is necessary to maximize con-currency in the program and to distribute the computation evenly among all of the computers.
Reference: [2] <author> Amdahl, G. M. </author> <title> Validity of the single processor approach to achieving large scale computing capabilities. </title> <booktitle> AFIPS Conf. Proc. </booktitle> <year> (1967) </year> <month> 483-485. </month>
Reference-contexts: Photorealistic rendering of complex scenes poses computational challenges that rival even the largest of these scientific and engineering calculations. It is therefore reasonable to explore how this problem can achieve similar speedups from SPPs. Amdahl's law states (correctly) that only concurrent computations demonstrate significant scalability on parallel computer systems <ref> [2, 12] </ref>. Therefore it is not surprising that the first successful applications of SPP technology have been to solve large scale problems in chemistry and physics that involve concurrent phenomena. The natural world abounds with such phenomena.
Reference: [3] <author> Anderson, T. E., Culler, D. E. & Patterson, D. A. </author> <title> A case for NOW (Networks of Workstations). </title> <booktitle> IEEE Micro 15 (1995) 54-64. </booktitle>
Reference-contexts: Programming is more difficult on computer systems with physically distributed memory because communication and synchronization must be managed explicitly. As a matter of architectural necessity the largest parallel computer systems have these properties as do all scalable commodity network configurations <ref> [1, 3, 6, 21] </ref>. In order to execute a parallel program efficiently it is necessary to maximize con-currency in the program and to distribute the computation evenly among all of the computers. <p> Individual stages can be parallelized to arbitrary degrees. Pipelines avoid synchronization between stages and as a result eliminate the need for synchronous communication. Message driven computation is a term that is sometimes used to describe a method for implementing concurrent pipelines on parallel computer systems with distributed memory <ref> [3, 4, 10] </ref>. When a computer executes one stage of a pipeline it stores along with the result of that stage the identity of the next stage which is to process that result. This allows the next stage to be executed by any computer in the system.
Reference: [4] <author> Athas, W. C. & Seitz, C. L. </author> <title> Multicomputers: message passing concurrent computers. </title> <journal> IEEE Comp. </journal> <month> 21 </month> <year> (1988) </year> <month> 9-24. </month>
Reference-contexts: Individual stages can be parallelized to arbitrary degrees. Pipelines avoid synchronization between stages and as a result eliminate the need for synchronous communication. Message driven computation is a term that is sometimes used to describe a method for implementing concurrent pipelines on parallel computer systems with distributed memory <ref> [3, 4, 10] </ref>. When a computer executes one stage of a pipeline it stores along with the result of that stage the identity of the next stage which is to process that result. This allows the next stage to be executed by any computer in the system.
Reference: [5] <author> Baskett, F. & Hennessy, J. L. </author> <title> Microprocessors: from desktops to supercomputers. </title> <note> Science 261 (1993) 864-871. </note>
Reference-contexts: 1 Introduction In recent years scalable parallel processors (SPPs) have become readily available to solve computationally intensive problems in science and engineering. Experience with these applications has shown that for certain classes of problems these SPPs routinely achieve speedups close to a factor of P using P computers <ref> [5, 15] </ref>. Photorealistic rendering of complex scenes poses computational challenges that rival even the largest of these scientific and engineering calculations. It is therefore reasonable to explore how this problem can achieve similar speedups from SPPs.
Reference: [6] <author> Boden, N. J., Cohen, D., Felderman, R. E., Kulawik, A. E., Seitz, C. L., Seizovic, J. N. & Su, W. Myrinet: </author> <title> a gigabit per second local area network. </title> <booktitle> IEEE Micro 15 (1995) 29-36. </booktitle>
Reference-contexts: Programming is more difficult on computer systems with physically distributed memory because communication and synchronization must be managed explicitly. As a matter of architectural necessity the largest parallel computer systems have these properties as do all scalable commodity network configurations <ref> [1, 3, 6, 21] </ref>. In order to execute a parallel program efficiently it is necessary to maximize con-currency in the program and to distribute the computation evenly among all of the computers.
Reference: [7] <author> Bokhari, S. </author> <title> Assignment problems in parallel and distributed computing. </title> <publisher> Boston : Kluwer (1987). </publisher>
Reference-contexts: This problem was originally posed in terms of mapping a graph of communicating processes onto a network of computers. More recent papers have addressed the analogous problems of mapping data structures <ref> [7, 14, 17, 18, 19, 23] </ref>. Simple and efficient methods exist to compute a static solution to this problem on a network with regular structure. These methods work by recursively subdividing a data structure into locally contiguous pieces, and assigning the pieces to contiguous regions of the network [17, 23].
Reference: [8] <author> Chang, C.-C., Czajkowski, G. & von Eicken, T. </author> <title> Design and performance of active messages on the IBM SP2. </title> <note> Cornell Computer Science Technical Report 96-1572 (1996). </note>
Reference-contexts: New software packages are available specifically for the SP2 to allow user mode access to the high performance communication network in order to eliminate the expensive calls to kernel mode services, and explicit support for active messages <ref> [8, 11] </ref>. By a combination of these techniques we expect to eliminate most of the overhead that is currently spent in handling communication.
Reference: [9] <author> Cybenko, G. </author> <title> Dynamic load balancing for distributed memory multiprocessors. </title> <journal> J. Par. Dist. Comp. </journal> <note> 7 (1989) 279-301. [10] von Eicken, </note> <author> T., Culler, D. E., Goldstein, S. C. & Schauser, K. E. </author> <title> Active messages: a mechanism for integrated communication and computation. </title> <booktitle> Proc. 19th Int. Symp. Comp. Arch., </booktitle> <address> Gold Coast, Australia (1992) 256-266. </address> <note> [11] von Eicken, </note> <author> T., Basu, A., Buch, V. & Voegls, W. U-Net: </author> <title> a user level network interface for parallel and distributed computing. </title> <booktitle> Proc. 15th ACM Symp. Op. Sys. Princ. </booktitle> <year> (1995) </year> <month> 1-14. </month>
Reference-contexts: Following this we describe software implementation methods by which we achieve scalable performance. This performance is demonstrated on a set of images using a diffusion algorithm to perform dynamic load balancing <ref> [9, 13, 14] </ref>. A set of mapping and load balancing strategies is described for models that are partitioned among computers. <p> Completion times varied between 323 and 646 seconds, 50% of the overall elapsed time. Right, completion times for the same image with dynamic load balancing by a diffusion algorithm. These times varied by 54 seconds. among computers <ref> [9, 13, 14] </ref>. Instead of load balancing throughout the computation we have implemented a receiver initiated strategy which becomes active only when a computer has processed all of its messages and has no more pending work. <p> In order to approach the ideal of P times speedup using P computers it is essential to have a scalable load balancing mechanism. For this reason we have employed a diffusion algorithm for dynamic load balancing <ref> [9] </ref>. We have employed a receiver-initiated strategy in order to reduce the number of load balancing events which occur. Diffusive load balancing algorithms have the desirable property of converging in a fixed elapsed time that is independent of P [13].
Reference: [12] <author> Gustafson, J. L. Reevaluating Amdahl's Law. </author> <title> Comm. </title> <booktitle> ACM 31 (1987), </booktitle> <pages> 532-533. </pages>
Reference-contexts: Photorealistic rendering of complex scenes poses computational challenges that rival even the largest of these scientific and engineering calculations. It is therefore reasonable to explore how this problem can achieve similar speedups from SPPs. Amdahl's law states (correctly) that only concurrent computations demonstrate significant scalability on parallel computer systems <ref> [2, 12] </ref>. Therefore it is not surprising that the first successful applications of SPP technology have been to solve large scale problems in chemistry and physics that involve concurrent phenomena. The natural world abounds with such phenomena.
Reference: [13] <author> Heirich, A. & Taylor, S. </author> <title> A parabolic load balancing method. </title> <booktitle> Proc. 24th Intern. Conf. Par. Proc., III, </booktitle> <pages> pp. 192-202. </pages> <publisher> New York : CRC Press (1995). </publisher>
Reference-contexts: Following this we describe software implementation methods by which we achieve scalable performance. This performance is demonstrated on a set of images using a diffusion algorithm to perform dynamic load balancing <ref> [9, 13, 14] </ref>. A set of mapping and load balancing strategies is described for models that are partitioned among computers. <p> Completion times varied between 323 and 646 seconds, 50% of the overall elapsed time. Right, completion times for the same image with dynamic load balancing by a diffusion algorithm. These times varied by 54 seconds. among computers <ref> [9, 13, 14] </ref>. Instead of load balancing throughout the computation we have implemented a receiver initiated strategy which becomes active only when a computer has processed all of its messages and has no more pending work. <p> We have employed a receiver-initiated strategy in order to reduce the number of load balancing events which occur. Diffusive load balancing algorithms have the desirable property of converging in a fixed elapsed time that is independent of P <ref> [13] </ref>. In a later section of this paper we will propose applying a related technique [14] to the problem of partitioning the geometric model on the computer system in order to achieve similar scalable convergence in this phase of the computation.
Reference: [14] <author> Heirich, A. </author> <title> A scalable diffusion algorithm for dynamic mapping and load balancing on networks of arbitrary topology. </title> <institution> Int. J. Found. Comp. Sci. </institution> <year> (1996), </year> <note> to appear. </note>
Reference-contexts: Following this we describe software implementation methods by which we achieve scalable performance. This performance is demonstrated on a set of images using a diffusion algorithm to perform dynamic load balancing <ref> [9, 13, 14] </ref>. A set of mapping and load balancing strategies is described for models that are partitioned among computers. <p> Completion times varied between 323 and 646 seconds, 50% of the overall elapsed time. Right, completion times for the same image with dynamic load balancing by a diffusion algorithm. These times varied by 54 seconds. among computers <ref> [9, 13, 14] </ref>. Instead of load balancing throughout the computation we have implemented a receiver initiated strategy which becomes active only when a computer has processed all of its messages and has no more pending work. <p> At such a time a computer polls all its neighbors in order to solicit work and requests a specific amount of work as determined by a diffusion calculation <ref> [14] </ref>. Neighbors respond by supplying the requested amount of work. This strategy produces an overhead from load balancing which is proportional to the number of computers but which does not depend on the length of time spent in computation. <p> Diffusive load balancing algorithms have the desirable property of converging in a fixed elapsed time that is independent of P [13]. In a later section of this paper we will propose applying a related technique <ref> [14] </ref> to the problem of partitioning the geometric model on the computer system in order to achieve similar scalable convergence in this phase of the computation. <p> We identify the problems to be solved in mapping and parti tioning models among computers. We propose strategies to perform this partitioning, one of which employs a diffusion algorithm related to the algorithm we used for load balancing and has similar scaling properties <ref> [14] </ref>. We describe the impact that this partitioning has upon the other parts of the rendering calculation. <p> This problem was originally posed in terms of mapping a graph of communicating processes onto a network of computers. More recent papers have addressed the analogous problems of mapping data structures <ref> [7, 14, 17, 18, 19, 23] </ref>. Simple and efficient methods exist to compute a static solution to this problem on a network with regular structure. These methods work by recursively subdividing a data structure into locally contiguous pieces, and assigning the pieces to contiguous regions of the network [17, 23]. <p> Diffusion algorithms have a number of properties which make them attractive in distributed computing environments. The correctness of these algorithms, their utility and efficiency in parallel computing, as well as a complete bibliography of related work, is given in <ref> [14] </ref>. The algorithms converge in a fixed amount of elapsed time which is independent of the number of computers on which they execute. This makes them very attractive for massively parallel implementation. They require no synchronization and communicate only among directly connected computers.
Reference: [15] <author> Hillis, W. D.& Bhogosian, B. M. </author> <title> Parallel scientific computation. </title> <note> Science 261 (1993) 856-863. </note>
Reference-contexts: 1 Introduction In recent years scalable parallel processors (SPPs) have become readily available to solve computationally intensive problems in science and engineering. Experience with these applications has shown that for certain classes of problems these SPPs routinely achieve speedups close to a factor of P using P computers <ref> [5, 15] </ref>. Photorealistic rendering of complex scenes poses computational challenges that rival even the largest of these scientific and engineering calculations. It is therefore reasonable to explore how this problem can achieve similar speedups from SPPs.
Reference: [16] <author> Kajiya, J. T. </author> <title> The rendering equation. </title> <booktitle> Comp. Graph. </booktitle> <month> 20 </month> <year> (1986). </year>
Reference-contexts: A full simulation of this kind can be extremely expensive since the number of paths required to produce a high quality image can be enormous, and each path can require a significant amount of geometry processing. Path tracing algorithms reduce the number of paths substantially <ref> [16] </ref>. Despite this improvement a high quality rendering task implemented by path tracing can consume many hours or even days of computing time on a high performance workstation. This paper describes a Monte Carlo implementation of path tracing on a parallel computer system. <p> The values of n and m may vary with the depth of the path, the type of surface, or other factors. If n = 1 and m = 1, then the algorithm corresponds to the path tracing approach introduced by Kajiya <ref> [16] </ref>. 3 A message driven computation with diffusive load balancing Whenever a problem can be solved by a modest number of computers it is usually convenient to employ a symmetric multiprocessor (SMP) or other computer system with shared memory.
Reference: [17] <author> Karypis, G. & Kumar, V. </author> <title> Multilevel graph partitioning schemes. </title> <booktitle> Proc. 24th Intern. Conf. Par. Proc., III, </booktitle> <pages> pp. 113-122. </pages> <publisher> New York : CRC Press (1995). </publisher>
Reference-contexts: This problem was originally posed in terms of mapping a graph of communicating processes onto a network of computers. More recent papers have addressed the analogous problems of mapping data structures <ref> [7, 14, 17, 18, 19, 23] </ref>. Simple and efficient methods exist to compute a static solution to this problem on a network with regular structure. These methods work by recursively subdividing a data structure into locally contiguous pieces, and assigning the pieces to contiguous regions of the network [17, 23]. <p> Simple and efficient methods exist to compute a static solution to this problem on a network with regular structure. These methods work by recursively subdividing a data structure into locally contiguous pieces, and assigning the pieces to contiguous regions of the network <ref> [17, 23] </ref>. For the purposes of rendering these subdivisions can be obtained cheaply by sorting geometric objects according to their relative positions in space.
Reference: [18] <author> Kung, H. T. & Stevenson, D. </author> <title> A software technique for reducing the routing time on a parallel computer with a fixed interconnection network. In High speed computer and algorithm organization, </title> <editor> eds. Kuck, </editor> <booktitle> Lawrie & Sameh (1977). </booktitle>
Reference-contexts: This problem was originally posed in terms of mapping a graph of communicating processes onto a network of computers. More recent papers have addressed the analogous problems of mapping data structures <ref> [7, 14, 17, 18, 19, 23] </ref>. Simple and efficient methods exist to compute a static solution to this problem on a network with regular structure. These methods work by recursively subdividing a data structure into locally contiguous pieces, and assigning the pieces to contiguous regions of the network [17, 23].
Reference: [19] <author> Martin, A. </author> <title> A distributed implementation method for parallel programming. Inf. </title> <booktitle> Proc. </booktitle> <month> 80 </month> <year> (1980) </year> <month> 309-314. </month>
Reference-contexts: This problem was originally posed in terms of mapping a graph of communicating processes onto a network of computers. More recent papers have addressed the analogous problems of mapping data structures <ref> [7, 14, 17, 18, 19, 23] </ref>. Simple and efficient methods exist to compute a static solution to this problem on a network with regular structure. These methods work by recursively subdividing a data structure into locally contiguous pieces, and assigning the pieces to contiguous regions of the network [17, 23].
Reference: [20] <author> Rosenberg, A. </author> <title> Issues in the study of graph embedding. </title> <booktitle> In Graph theoretic concepts in computer science, Lecture Notes in Computer Science 100, </booktitle> <address> New York : Springer (1981) 150-176. </address>
Reference-contexts: Diffusion algorithms can address a number of quadratic minimization problems, including mapping data structures onto parallel computers. The mapping problem is derived from the (NP complete) graph embedding problem <ref> [20] </ref>. In the graph embedding problem the vertices of a relatively large graph, termed the guest, are mapped into the vertices of a smaller graph, termed the host.
Reference: [21] <author> Sterling, T. L. </author> <title> The scientific workstation of the future may be a pile-of-pcs. </title> <journal> Comm. </journal> <note> ACM (1996), to appear. </note>
Reference-contexts: Programming is more difficult on computer systems with physically distributed memory because communication and synchronization must be managed explicitly. As a matter of architectural necessity the largest parallel computer systems have these properties as do all scalable commodity network configurations <ref> [1, 3, 6, 21] </ref>. In order to execute a parallel program efficiently it is necessary to maximize con-currency in the program and to distribute the computation evenly among all of the computers.
Reference: [22] <author> Whitted, T. </author> <title> An improved illumination model for shaded display. </title> <booktitle> Comm. ACM 23 (1980), </booktitle> <pages> 343-349. </pages>
Reference-contexts: Concurrent processing is a prerequisite to real time vision. Photorealistic rendering can be expressed as a problem of modeling photon transport through a geometric environment. Ray tracing algorithms directly simulate transport by following the paths of individual photons <ref> [22] </ref>. A full simulation of this kind can be extremely expensive since the number of paths required to produce a high quality image can be enormous, and each path can require a significant amount of geometry processing. Path tracing algorithms reduce the number of paths substantially [16].
Reference: [23] <author> Williams, R. D. </author> <title> Performance of dynamic load balancing algorithms for unstructured mesh calculations. </title> <journal> Concurrency: Pract. Exp. </journal> <month> 3 </month> <year> (1991) </year> <month> 457-481. </month>
Reference-contexts: This problem was originally posed in terms of mapping a graph of communicating processes onto a network of computers. More recent papers have addressed the analogous problems of mapping data structures <ref> [7, 14, 17, 18, 19, 23] </ref>. Simple and efficient methods exist to compute a static solution to this problem on a network with regular structure. These methods work by recursively subdividing a data structure into locally contiguous pieces, and assigning the pieces to contiguous regions of the network [17, 23]. <p> Simple and efficient methods exist to compute a static solution to this problem on a network with regular structure. These methods work by recursively subdividing a data structure into locally contiguous pieces, and assigning the pieces to contiguous regions of the network <ref> [17, 23] </ref>. For the purposes of rendering these subdivisions can be obtained cheaply by sorting geometric objects according to their relative positions in space.
References-found: 21

