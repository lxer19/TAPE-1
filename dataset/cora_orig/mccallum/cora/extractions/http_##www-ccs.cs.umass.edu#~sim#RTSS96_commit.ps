URL: http://www-ccs.cs.umass.edu/~sim/RTSS96_commit.ps
Refering-URL: http://www-ccs.cs.umass.edu/rtdb/misc.html
Root-URL: 
Title: Commit Processing in Distributed Real-Time Database Systems  
Author: Ramesh Gupta Jayant Haritsa Krithi Ramamritham S. Seshadri 
Abstract: We investigate here the performance implications of supporting transaction atomicity in a distributed real-time database system. Using a detailed simulation model of a firm-deadline distributed real-time database system, we profile the real-time performance of a representative set of commit protocols. A new commit protocol that is designed for the real-time domain and allows transactions to "optimistically" read uncommitted data is also proposed and evaluated. The experimental results show that data distribution has a significant influence on the real-time performance and that the choice of commit protocol clearly affects the magnitude of this influence. Among the protocols evaluated, the new optimistic commit protocol provides the best performance for a variety of workloads and system configurations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Abbott and H. Garcia-Molina, </author> <title> "Scheduling Real-Time Transactions: a Performance Evaluation", </title> <booktitle> Proc. of 14th VLDB Conf., </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: The transaction priority assignment used in all of the experiments described here is Earliest Deadline, wherein transactions with earlier deadlines have higher priority than transactions with later deadlines. For concurrency control, the 2PL High Priority scheme <ref> [1] </ref> is employed. 5.1. Comparative Protocols To help isolate and understand the effects of distribution and atomicity on MissPercent performance, and to serve as a basis for comparison, we have also simulated the performance behavior for two additional scenarios.
Reference: [2] <author> A. Bestavros, </author> <title> "Multi-version Speculative Concurrency Control with Delayed Commit", </title> <booktitle> Proc. of Intl. Conf. on Computers and their Applications, </booktitle> <month> March </month> <year> 1994. </year>
Reference-contexts: Presumed Abort/Commit : The optimizations of Presumed Commit or Presumed Abort discussed 1 A similar, but unrelated, strategy of allowing access to uncommitted data has also been used to improve real-time concur rency control performance <ref> [2] </ref>. earlier for 2PC can also be used in conjunction with OPT to reduce the protocol overheads. We consider both options in our experiments.
Reference: [3] <author> P. Bernstein, V. Hadzilacos and N. Goodman, </author> <title> Concur-rency Control and Recovery in Database Systems, </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: 1. Introduction Many real-time database applications, especially in the areas of communication systems and military systems, are inherently distributed in nature [15]. Incorporating distributed data into the real-time database framework incurs the well-known additional complexities that are associated with transaction concurrency control and database recovery in distributed database systems <ref> [3, 11] </ref>. While the issue of distributed real-time concurrency control has been considered to some extent (e.g. [13, 16, 18]), comparatively little work has been done with regard to distributed real-time database recovery. <p> We consider both options in our experiments. An important point to note here is that the policy of using uncommitted data is generally not recommended in database systems since this can potentially lead to the well-known problem of cascading aborts <ref> [3] </ref> if the transaction whose dirty data has been accessed is later aborted.
Reference: [4] <author> E. Cooper, </author> <title> "Analysis of Distributed Commit Protocols", </title> <booktitle> Proc. of ACM Sigmod Conf., </booktitle> <month> June </month> <year> 1982. </year>
Reference-contexts: That is, is the protocol "blocking" or "non-blocking"? With respect to the above issues, the performance of a representative set of commit protocols has been analyzed to a limited extent in <ref> [4, 10] </ref>. These studies were conducted in the context of a conventional DBMS where transaction throughput or response time is the primary performance metric. In a RTDBS, however, performance is usually measured in terms of the number of transactions that complete before their deadlines.
Reference: [5] <author> M. Carey and M. Livny, </author> <title> "Distributed Concurrency Control Performance: A Study of Algorithms, Distribution, and Replication", </title> <booktitle> Proc. of 14th VLDB Conf., </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: Simulation Model To evaluate the performance of the various commit protocols described in the previous sections, we developed a detailed simulation model of a distributed real-time database system. Our model is based on a loose combination of the distributed database model presented in <ref> [5] </ref> and the real-time processing model of [8]. A summary of the parameters used in the model are given in Table 1. The database is modeled as a collection of DBSize pages that are uniformly distributed across all the N umSites sites.
Reference: [6] <author> J. Gray, </author> <booktitle> "Notes on Database Operating Systems", Operating Systems: An Advanced Course, Lecture Notes in Computer Science, </booktitle> <volume> 60, </volume> <year> 1978. </year>
Reference-contexts: Over the last two decades, a variety of commit protocols have been proposed by database researchers. These include the classical two phase commit (2PC) protocol <ref> [6] </ref>, its variations such as presumed commit and presumed abort [10], and three phase commit [14]. To achieve their functionality, these commit protocols typically require exchange of multiple messages, in multiple phases, between the participating sites where the distributed transaction executed. <p> For this model, a variety of transaction commit protocols have been devised, most of which are based on the classical two phase commit (2PC) protocol <ref> [6] </ref>. In this section, we briefly describe the 2PC protocol and a few popular variations of this protocol complete descriptions are available in [10, 14]. 2.1.
Reference: [7] <author> R. Gupta, J. Haritsa, K. Ramamritham and S. Se-shadri, </author> <title> "Commit Processing in Distributed RTDBS", </title> <institution> TR-96-01, DSL/SERC, Indian Institute of Science (http://dsl.serc.iisc.ernet.in/reports.html). </institution>
Reference-contexts: If the transaction's deadline expires either before this point, or before the master has written the global decision log record, the transaction is killed (the precise semantics of firm deadlines in a distributed environment are defined in <ref> [7] </ref>). As mentioned earlier, transactions in a RTDBS are typically assigned priorities in order to minimize the number of missed deadlines. In our model, all the cohorts of a transaction inherit the master transaction's priority. <p> Due to space limitations, we discuss only a representative set of results here the complete details are available in <ref> [7] </ref>. The performance metric of our experiments is M issP ercent, which is the percentage of input transactions that the system is unable to complete before their deadlines.
Reference: [8] <author> J. Haritsa, M. Carey, and M. Livny, </author> <title> "Data Access Scheduling in Firm Real-Time Database Systems", </title> <journal> Real-Time Systems Journal, </journal> <volume> 4 (3), </volume> <year> 1992. </year>
Reference-contexts: real-time domain, there are two major questions that need to be explored: First, how do we adapt the commit protocols to the real-time domain? Second, how do the real-time variants of the commit protocols compare in their performance? In this paper, we address these questions for the "firm-deadline" application framework <ref> [8] </ref>, wherein transactions that miss their deadlines are considered to be worthless and are immediately "killed", that is, aborted and discarded from the system without being executed to completion. <p> Our model is based on a loose combination of the distributed database model presented in [5] and the real-time processing model of <ref> [8] </ref>. A summary of the parameters used in the model are given in Table 1. The database is modeled as a collection of DBSize pages that are uniformly distributed across all the N umSites sites.
Reference: [9] <author> E. Levy, H. Korth and A. Silberschatz, </author> <title> "An optimistic commit protocol for distributed transaction management", </title> <booktitle> Proc. of ACM SIGMOD Conf., </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: While the compensation-based approach certainly appears to have the potential to improve timeliness, there are quite a few practical difficulties: First, the standard notion of transaction atomicity is not supported instead, a "relaxed" notion of atomicity <ref> [9] </ref> is provided. Second, the design of a compensating transaction is an application-specific task since it is based on application semantics. <p> Fourth, "real actions" such as firing a weapon or dispensing cash may not be compensatable at all <ref> [9] </ref>. Finally, no performance studies are available to evaluate the effectiveness of this approach. Due to the above limitations, we focus here instead on improving the real-time performance of the standard mechanisms for maintaining distributed transaction atomicity. 2.
Reference: [10] <author> C. Mohan, B. Lindsay and R. Obermarck, </author> <title> "Transaction Management in the R fl Distributed Database Management System", </title> <journal> ACM TODS , 11(4), </journal> <year> 1986. </year>
Reference-contexts: Over the last two decades, a variety of commit protocols have been proposed by database researchers. These include the classical two phase commit (2PC) protocol [6], its variations such as presumed commit and presumed abort <ref> [10] </ref>, and three phase commit [14]. To achieve their functionality, these commit protocols typically require exchange of multiple messages, in multiple phases, between the participating sites where the distributed transaction executed. <p> That is, is the protocol "blocking" or "non-blocking"? With respect to the above issues, the performance of a representative set of commit protocols has been analyzed to a limited extent in <ref> [4, 10] </ref>. These studies were conducted in the context of a conventional DBMS where transaction throughput or response time is the primary performance metric. In a RTDBS, however, performance is usually measured in terms of the number of transactions that complete before their deadlines. <p> For this model, a variety of transaction commit protocols have been devised, most of which are based on the classical two phase commit (2PC) protocol [6]. In this section, we briefly describe the 2PC protocol and a few popular variations of this protocol complete descriptions are available in <ref> [10, 14] </ref>. 2.1. Two Phase Commit Protocol The master initiates the first phase of the protocol by sending PREPARE (to commit) messages in parallel to all the cohorts. <p> Finally, the master, after receiving acknowledge-ments from all the prepared cohorts, writes an end log record and then "forgets" the transaction. 2.2. Presumed Abort A variant of the 2PC protocol, called presumed abort (PA) <ref> [10] </ref>, tries to reduce the message and logging overheads by requiring all participants to follow a "in case of doubt, abort" rule. <p> Presumed Commit A variation of the presumed abort protocol is based on the observation that, in general, the number of committed transactions is much more than the number of aborted transactions. In this variation, called presumed commit (PC) <ref> [10] </ref>, the overheads are reduced for committing transactions rather than aborted transactions by requiring all participants to follow a "in case of doubt, commit" rule. In this scheme, cohorts do not send acknowledgments for the commit global decision, and do not force-write the commit log record. <p> In summary, our results have shown that in the firm-deadline real-time domain, the performance rec 4 This conclusion is limited to the completely update transaction workloads considered here. PA and PC have additional optimizations for fully or partially read-only transactions <ref> [10] </ref>. ommendations for distributed commit processing can be considerably different from those for the correspond ing conventional database system.
Reference: [11] <author> M. Oszu and P. Valduriez, </author> <title> Principles of Distributed Database Systems, </title> <publisher> Prentice-Hall, </publisher> <year> 1991. </year>
Reference-contexts: 1. Introduction Many real-time database applications, especially in the areas of communication systems and military systems, are inherently distributed in nature [15]. Incorporating distributed data into the real-time database framework incurs the well-known additional complexities that are associated with transaction concurrency control and database recovery in distributed database systems <ref> [3, 11] </ref>. While the issue of distributed real-time concurrency control has been considered to some extent (e.g. [13, 16, 18]), comparatively little work has been done with regard to distributed real-time database recovery.
Reference: [12] <author> L. Sha, R. Rajkumar and J. Lehoczky, </author> <title> "Priority inheritance protocols: an approach to real-time synchronization", </title> <type> Tech. </type> <institution> Report CMU-CS-87-181 , Carnegie Mellon University. </institution>
Reference-contexts: Real-Time Commit Processing The commit protocols described above were designed for conventional database systems and do not take transaction priorities into account. In a real-time environment, this is clearly undesirable since it may result in priority inversion <ref> [12] </ref>, wherein high priority transactions are made to wait by low priority transactions. Priority inversion is usually prevented by resolving all conflicts in favor of transactions with higher priority. Removing priority inversion in the commit protocol, however, is not fully feasible.
Reference: [13] <author> L. Sha, R. Rajkumar and J. Lehoczky, </author> <title> "Concurrency Control for Distributed Real-Time Databases", </title> <journal> ACM SIGMOD Record, </journal> <volume> 17(1), </volume> <month> March </month> <year> 1988. </year>
Reference-contexts: Incorporating distributed data into the real-time database framework incurs the well-known additional complexities that are associated with transaction concurrency control and database recovery in distributed database systems [3, 11]. While the issue of distributed real-time concurrency control has been considered to some extent (e.g. <ref> [13, 16, 18] </ref>), comparatively little work has been done with regard to distributed real-time database recovery. In this paper, we investigate the performance implications of supporting transaction atomicity in a distributed real-time database system (RTDBS). To the best of our knowledge, this is the first quantitative evaluation of this issue.
Reference: [14] <author> D. Skeen, </author> <title> "Nonblocking Commit Protocols", </title> <booktitle> Proc. of ACM SIGMOD Conf., </booktitle> <month> June </month> <year> 1981. </year>
Reference-contexts: Over the last two decades, a variety of commit protocols have been proposed by database researchers. These include the classical two phase commit (2PC) protocol [6], its variations such as presumed commit and presumed abort [10], and three phase commit <ref> [14] </ref>. To achieve their functionality, these commit protocols typically require exchange of multiple messages, in multiple phases, between the participating sites where the distributed transaction executed. In addition, several log records are generated, some of which have to be "forced", that is, flushed to disk immediately. <p> For this model, a variety of transaction commit protocols have been devised, most of which are based on the classical two phase commit (2PC) protocol [6]. In this section, we briefly describe the 2PC protocol and a few popular variations of this protocol complete descriptions are available in <ref> [10, 14] </ref>. 2.1. Two Phase Commit Protocol The master initiates the first phase of the protocol by sending PREPARE (to commit) messages in parallel to all the cohorts. <p> It is easy to see that, if the blocked period is long, it may result in major disruption of transaction processing activity. To address the blocking problem, a three phase commit (3PC) protocol was proposed in <ref> [14] </ref>. This protocol achieves a nonblocking capability by inserting an extra phase, called the "precommit phase", in between the two phases of the 2PC protocol. In the precommit phase, a preliminary decision is reached regarding the fate of the transaction.
Reference: [15] <author> S. Son, </author> <title> "Real-Time Database Systems: A New Challenge", </title> <journal> Data Engineering, </journal> <volume> 13(4), </volume> <month> December </month> <year> 1990. </year>
Reference-contexts: 1. Introduction Many real-time database applications, especially in the areas of communication systems and military systems, are inherently distributed in nature <ref> [15] </ref>. Incorporating distributed data into the real-time database framework incurs the well-known additional complexities that are associated with transaction concurrency control and database recovery in distributed database systems [3, 11].
Reference: [16] <author> S. Son and S. Kouloumbis, </author> <title> "Replication Control for Distributed Real-Time Database Systems", </title> <booktitle> Proc. of 12th Intl. Conf. on Distributed Computing Systems, </booktitle> <year> 1992. </year>
Reference-contexts: Incorporating distributed data into the real-time database framework incurs the well-known additional complexities that are associated with transaction concurrency control and database recovery in distributed database systems [3, 11]. While the issue of distributed real-time concurrency control has been considered to some extent (e.g. <ref> [13, 16, 18] </ref>), comparatively little work has been done with regard to distributed real-time database recovery. In this paper, we investigate the performance implications of supporting transaction atomicity in a distributed real-time database system (RTDBS). To the best of our knowledge, this is the first quantitative evaluation of this issue.
Reference: [17] <author> N. Soparkar, E. Levy, H. Korth and A. Silberschatz, </author> <title> "Adaptive Commitment for Real-Time Distributed Transactions", TR-92-15, </title> <type> CS, </type> <institution> Univ. of Texas (Austin), </institution> <year> 1992. </year>
Reference-contexts: Using a detailed simulation model of a distributed database system, we compare the real-time performance of a representative set of commit protocols. The performance metric is the steady-state percentage of transaction deadlines that are missed. 1.1. Related Work The design of real-time commit protocols has been investigated earlier in <ref> [17, 19] </ref>. These papers are based on a common theme of allowing individual sites to unilaterally commit the idea is that unilateral commitment results in greater timeliness of actions. If it is later found that the decision is not consistent globally, "compensation" transactions are executed to rectify the errors.
Reference: [18] <author> O. Ulusoy and G. Belford, </author> <title> "Real-Time Lock Based Concur-rency Control in a Distributed Database System", </title> <booktitle> Proc. of 12th Intl. Conf. on Distributed Computing Systems, </booktitle> <year> 1992. </year>
Reference-contexts: Incorporating distributed data into the real-time database framework incurs the well-known additional complexities that are associated with transaction concurrency control and database recovery in distributed database systems [3, 11]. While the issue of distributed real-time concurrency control has been considered to some extent (e.g. <ref> [13, 16, 18] </ref>), comparatively little work has been done with regard to distributed real-time database recovery. In this paper, we investigate the performance implications of supporting transaction atomicity in a distributed real-time database system (RTDBS). To the best of our knowledge, this is the first quantitative evaluation of this issue.
Reference: [19] <author> Y. Yoon, </author> <title> "Transaction Scheduling and Commit Processing for Real-Time Distributed Database Systems", </title> <type> Ph.D. Thesis, </type> <institution> Korea Adv. Inst. of Science and Technology, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: Using a detailed simulation model of a distributed database system, we compare the real-time performance of a representative set of commit protocols. The performance metric is the steady-state percentage of transaction deadlines that are missed. 1.1. Related Work The design of real-time commit protocols has been investigated earlier in <ref> [17, 19] </ref>. These papers are based on a common theme of allowing individual sites to unilaterally commit the idea is that unilateral commitment results in greater timeliness of actions. If it is later found that the decision is not consistent globally, "compensation" transactions are executed to rectify the errors.
References-found: 19

