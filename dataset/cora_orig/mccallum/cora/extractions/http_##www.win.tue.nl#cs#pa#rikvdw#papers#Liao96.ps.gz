URL: http://www.win.tue.nl/cs/pa/rikvdw/papers/Liao96.ps.gz
Refering-URL: http://www.win.tue.nl/cs/pa/rikvdw/bibl.html
Root-URL: http://www.win.tue.nl
Title: Code Generation and Optimization for Embedded Digital Signal Processors  
Author: by Stan Yi-Huang Liao 
Degree: (1992) Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Doctor of Philosophy at the  All rights reserved. Author  Certified by Srinivas Devadas Associate Professor of Electrical Engineering and Computer Science Thesis Supervisor Accepted by Frederic R. Morgenthaler, Professor of Electrical Engineering Chairman, Department Committee on Graduate Students  
Date: June 1996  January 22, 1996  
Address: (1991)  
Affiliation: S.B. (Elec. Engr.) Massachusetts Institute of Technology  S.M. (E.E.C.S.) Massachusetts Institute of Technology  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  c Massachusetts Institute of Technology 1996.  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [Abelson 85] <author> H. Abelson and G. J. Sussman. </author> <title> Structure and Interpretation of Computer Programs. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1985. </year>
Reference-contexts: In Sections B.1-B.4, we will first briefly review interprocedural analysis, and then describe some optimizations that make use of the information gathered by the analysis. B.1 Interprocedural Analysis and Optimizations It has been widely recognized as good programming practice to use abstractions (both procedural and data) <ref> [Abelson 85] </ref>; hence, most software-development environments allow for the division of a large program into a number of files and for the separate compilation of each file. To achieve this, a distinct stage of compilation, linking, is necessary to resolve function calls and global variables.
Reference: [Aho 74] <author> A. Aho, J. Hopcroft, and J. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: We therefore present a heuristic algorithm for MWPC that is similar to Kruskal's maximum spanning tree algorithm <ref> [Aho 74] </ref>. The heuristic is greedy in that it repeatedly selects an edge that seems best at each iteration. The heuristic algorithm is shown in Figure 4-8.
Reference: [Aho 77] <author> A. Aho, S.C. Johnson, and J. Ullman. </author> <title> Code Generation for Expressions with Common Subexpressions. </title> <journal> Journal of the ACM, </journal> <volume> 24(1) </volume> <pages> 146-160, </pages> <year> 1977. </year>
Reference-contexts: Based on properties of worm-partitions, we derive a compact set of clauses to describe the set of all legal worm-partitions. The variables in these clauses appear in other clauses to relate scheduling with the selection of instruction patterns and register transfers. Unlike previous work (e.g., <ref> [Aho 77] </ref>), our formulation clearly and succinctly describes the scheduling constraints along with accumulator spills and reloads, and allows for more-flexible cost functions. We also propose extensions of this formulation to tackle multiple-register machines and other optimization objectives such as the mode optimization problem of [Liao 95a]. <p> By solving the associated binate covering problem we arrive at an optimal solution for the original code generation problem. 3.4.1 Previous Work In <ref> [Aho 77] </ref> Aho et al. presented optimal code generation algorithms (on DAGs) for two different models of one-register machines: * Noncommutative machines, in which available operations are: acc op acc (unary operator) acc acc op mem (binary operator) acc mem (reload) mem acc (spill) where acc denotes the accumulator and mem <p> First, in our application the given DAG may have ternary or higher-arity operators depending on the complex patterns chosen in the first step of binate covering (Section 3.3). Second, the noncommutative model of <ref> [Aho 77] </ref> does not take into account the commutativity of certain operators. It always requires the left operand of a binary operator in the accumulator. <p> Definition 3.3 Let a subject DAG DhV, Ei be given. A worm w in D is a subset of V [ E forming a directed path, possibly of zero length, such that the vertices in the path will appear consecutively in the schedule <ref> [Aho 77] </ref>. By consecutively we do not exclude the possibility of data transfers (i.e., spills and reloads) between the two vertices, which represent computations. 62 CODE GENERATION Definition 3.4 Let w be a directed path (worm). <p> Every vertex of w other than the first and the last is called an interior vertex (with respect to the worm). Definition 3.5 A worm-partition of D is a set of disjoint worms <ref> [Aho 77] </ref>. An edge is said to be selected with respect to a worm-partition if it belongs to some worm in the partition. We can visualize a worm-partition by associating with it a directed graph G, which we call a worm-graph. <p> This partition gives rise to a nontrivial d-cycle in G 3 , and no schedule exists that places the vertices in each worm consecutively. It is readily observed that a sufficient condition for a worm-partition to be legal is that G be d-acyclic <ref> [Aho 77] </ref>. This is because a d-acyclic DAG has a topological sort, and every topological sort of G gives a schedule for D. This condition, however, is not always necessary. <p> Otherwise, one of these clauses will evaluate to false. Hence, two clauses for each u-cycle suffice. No new variables are introduced into the formulation, merely additional clauses. 3.4.7 Self-Loops One important exception needs to be made regarding self-loops in G (which was not addressed in <ref> [Aho 77] </ref>). Consider the fragment of a DAG shown in Figure 3-16, and the selected edges e 1 , e 2 , e 3 , and e 4 . <p> A similar argument applies to last (w). Since the fundamental and u-cycle clauses implicitly enumerate all legal worm-partitions, which in turn implicitly encompass all schedules of D <ref> [Aho 77] </ref>, every total schedule derived from G is optimal. 3.5 Extensions of the Binate Covering Formulation We now consider two extensions of the binate covering formulation for data transfers presented in Section 3.4: * Mode optimization problem. * Data transfers in machines with multiple register classes. <p> For the second phase we have presented a new theory of code generation for one-register machines. This new theory, also based on the binate covering problem, is more general than that of Aho et al. 92 CODE GENERATION <ref> [Aho 77] </ref> and encompasses a wider class of one-register machines. Although we use the same notion of worms and worm-partitions, our exposition is more complete.
Reference: [Aho 86] <author> A. Aho, R. Sethi, and J. Ullman. CompilersPrinciples, </author> <title> Techniques and Tools. </title> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: Also, less effort is required to reuse software written in high-level languages. Programming in a high-level language may, however, incur a code-size penalty. One reason is that compiler optimization techniques (for examples see <ref> [Aho 86] </ref>) have classically focused on code speed and not code density, and most available compilers optimize primarily for speed of execution. Although some optimizing transforms such as local common subexpression elimination can improve both speed and size at the same time, in many cases there is a speed-size trade-off. <p> Portability has always been a concern of compiler researchers since the inception of high-level programming languages and compilers [Conway 58]. Therefore, almost all compilers are organized in two major phases [Wulf 75] <ref> [Aho 86] </ref> (which may, of course, consist of smaller phases). The first phase, called the front-end, consists of lexical analysis and parsing. The task of the front-end is to translate a program from its source-language form to an intermediate form that is largely language-independent and machine-independent. <p> For the purpose of code generation, a basic block is usually represented by an expression directed acyclic graph (DAG), which naturally discovers local common subexpressions <ref> [Aho 86] </ref>. It is also possible to obtain larger and more complicated DAGs for traces [Fisher 81] [Ellis 85] 46 CODE GENERATION basic block. (b) The corresponding expression DAG, assuming p, t, and u are not live upon exit of the basic block. that cross basic block boundaries. <p> The equivalence may be dependent on the context; for example, SUB R1,R1,R1 and MOVE R1,0 are interchangeable if condition codes generated by the former can be ignored (at a particular point in the program). We can use reaching definition analysis <ref> [Aho 86, page 610] </ref> on the condition codes 148 CODE COMPRESSION to determine if they are used by subsequent instructions. Henceforth we assume that this equivalence analysis has already been performed. <p> The selected substitutions are then carried out and the dictionary is formed by combining the selected entries. 5.6.1 Generation of Potential Dictionary Entries The instruction stream is first divided into basic blocks, using the algorithm described in <ref> [Aho 86, page 529] </ref>. Then each basic block is compared with every other basic block, as well as itself, for common substrings. A threshold on the minimum length M (for example, 3) of substrings is prescribed, so that only potentially beneficial substrings are extracted. <p> Mode variables, though certainly machine-dependent, behave very much like user-defined variables: If we treat mode-setting instructions as definitions of a mode variable and instructions affected by a mode variable as uses, we may then use the standard reaching-definition and liveness analyses (see [Hecht 77] and <ref> [Aho 86] </ref>) to determine the definition-use characteristics of each mode variable. Partial redundancy elimination (see [Morel 79] and [Knoop 95]), which makes use of this information, can be readily applied to the mode variables.
Reference: [Aho 89] <author> A. Aho, M. Ganapathi, and S. Tjiang. </author> <title> Code Generation Using Tree Matching and Dynamic Programming. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(4) </volume> <pages> 491-516, </pages> <year> 1989. </year>
Reference-contexts: This method has been used with some success for the code selection phase of existing compilers. A widely used behavioral description methodology is based on grammars and their derivatives (e.g., tree-matcher generators). For example, the input to the code-generator generator TWIG <ref> [Aho 89] </ref> consists of a set of patterns with a cost function for each pattern and a sequence of actions corresponding to emitting code for matches with this pattern. <p> An alternative to parsing is to use pattern-matching techniques on expression trees. Cattell designed a framework in which code generators based on pattern-matching are automatically derived from a machine description language [Cattell 80]. The landmark paper by Aho et al. <ref> [Aho 89] </ref> established the foundation in which several modern dynamic-programming code-generator generators find their origin. One such code-generator generator is IBURG [Fraser 92], employed in the compiler framework LCC [Fraser 95]. The dynamic-programming methodology yields locally optimal code (i.e., within the expression tree). <p> In the code generation process of CODESYN, the source program is first translated into an intermediate form, called BDS (BNR Data Structure). The graph-rewrite phase transforms complex constructs (e.g., if-then-else) in the BDS into constructs available in the target machine. A pattern-matching phase using the dynamic-programming paradigm of <ref> [Aho 89] </ref> selects instructions from the instruction set to implement the functions represented by the subject graph. Global scheduling and register allocation then follow. Finally, the micro-operation compaction, assembly, and linking stages produce the object code. <p> Then, the program is translated via a preliminary code generation stage into another intermediate form called TWIF. The preliminary code generated is produced from a rule-based machine description written in OLIVE [Tjiang 94] or DAG-WOOD [Tjiang 95]. OLIVE, a descendent of TWIG <ref> [Aho 89] </ref> and IBURG [Fraser 92], is a language for writing tree-matchers based on dynamic programming. If tree-covering for preliminary code generation is desired, OLIVE allows for compact specifications of code generators. <p> Aho 48 CODE GENERATION DAG. (b)-(f) Forest of trees resulting from cutting the DAG at vertices t and u, each of which has two fanouts. 3.1 TASKS OF A CODE GENERATOR 49 et al. <ref> [Aho 89] </ref> presented an algorithm based on dynamic programming that allows for complex instruction patterns. More recently, Araujo and Malik [Araujo 95] extended this scheme to handle architectures with irregular and limited register connectivity.
Reference: [F Allen 72] <author> F. E. Allen and J. Cocke. </author> <title> A Catalogue of Optimizing Transformations. </title> <editor> In R. Rustin, editor, </editor> <booktitle> Design and Optimization of Compilers, </booktitle> <pages> pages 1-30. </pages> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1972. </year>
Reference-contexts: For example, subroutine calls take less space than in-line code, but are generally slower due to 26 INTRODUCTION call overheads. Other optimizations that have potential speed-size trade-offs include induction variable elimination (or strength reduction) <ref> [F Allen 72] </ref>, loop unrolling [Lam 88], and partial redundancy elimination [Morel 79]. Where execution speed is not critical, minimizing the code size is usually profitable. <p> Most machine-independent optimizations, such as constant propagation, global common subexpression elimination, dead code elimination, have been very well understood <ref> [F Allen 72] </ref>. Other optimization problems, such as register allocation, are closely tied to the target architecture. Thus, these problems are more difficult to formulate precisely. A common approach to such problems is to use a simpler model that can approximate a wide class of architectures. <p> For example, if a procedure is called with a constant a at some sites and another constant b at some other call sites, we may create two clones of the procedure, one optimized for constant a (e.g., via constant propagation <ref> [F Allen 72] </ref>) and the other optimized for constant b. 3. Global optimization enhanced by interprocedural data-flow information. This has proven to be effective in removing spurious dependencies for parallel compilation. For scalar compilation, mixed results ranging from marginal to moderate improvements have been reported [Hall 91].
Reference: [J Allen 85] <author> J. Allen. </author> <title> Computer Architecture for Digital Signal Processing. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 73(5) </volume> <pages> 852-873, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: Although programmers may rely on optimized library routines for such common tasks as convolution, correlation, and fast Fourier transform, compiler optimizations are necessary for the relatively unstructured portions of the code. There is a clear trend that more complex tasks will involve much unstructured code <ref> [J Allen 85] </ref>, partly due to the use of special-purpose algorithms and partly due to the need for the processor to handle events and interrupts. Therefore, the goal of this thesis is to develop techniques for code generation and optimization for these processors.
Reference: [Araujo 95] <author> G. Araujo and S. Malik. </author> <title> Optimal Code Generation for Embedded Memory Non-Homogeneous Register Architectures. </title> <booktitle> In Proceedings of the 1995 International Symposium on System Synthesis, </booktitle> <pages> pages 36-41, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: More recently, Araujo and Malik <ref> [Araujo 95] </ref> extended this scheme to handle architectures with irregular and limited register connectivity. Independent covering of trees, however, may result in a suboptimal solution for the original DAG, because tree covering inherently precludes the use of complex instructions in cases where internal vertices are shared. <p> As indicated in Section 3.2, in some DSP architectures instructions take operands from specific locations and deposit their results into specific registers. In this section we will use the [1,1] model, as in <ref> [Araujo 95] </ref>, in which every resource class (register or memory) is assumed to have either one or infinitely many elements. For those register classes that have an infinite number of elements, a separate allocation phase (e.g., using a graph-coloring register allocator [Chaitin 81]) is carried out afterwards.
Reference: [Bartley 92] <author> D. H. Bartley. </author> <title> Optimizing Stack Frame Accesses for Processors with Restricted Addressing Modes. </title> <journal> SoftwarePractice and Experience, </journal> <volume> 22(2) </volume> <pages> 101-110, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: By solving the MWPC problem we can obtain a solution to the SOA problem. Bartley was the first to address the SOA problem and presented an approach based on finding a Hamiltonian path of maximum weight on the graph <ref> [Bartley 92] </ref>. However, several aspects of his formulation and implementation can be improved: the inefficiency of his algorithm arises from the reduction of SOA to the weighted STORAGE ASSIGNMENT 95 Hamiltonian path problem, and from the underlying representation of the problem.
Reference: [Beckmann 95] <author> P. E. Beckmann. </author> <type> Personal communication, </type> <month> November </month> <year> 1995. </year>
Reference-contexts: This thesis addresses several issues involved in developing compiler optimizations for fixed-point digital signal processors, which are increasingly used as the processor component in embedded systems due to their favorable performance-cost characteristics <ref> [Beckmann 95] </ref>.
Reference: [Bradlee 91] <author> D. G. Bradlee, R. R. Henry, and S. J. Eggers. </author> <title> The Marion System for Retargetable Instruction Scheduling. </title> <booktitle> In Proceedings of the 1991 ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 229-240, </pages> <month> June </month> <year> 1991. </year> <note> 204 BIBLIOGRAPHY </note>
Reference-contexts: These methods operate at a late stage of the compilation process (i.e., object-to-object transformation) and are not capable of capturing the optimizations at earlier stages, such as register allocation and scheduling. More recently, Bradlee proposed a retargetable scheduler MARION that is used mainly for RISC architectures <ref> [Bradlee 91] </ref>. It uses a machine description that models pipelines and superscalar instruction issues, and schedules instructions accordingly to effectively utilize the features or to reduce conflicts.
Reference: [Brayton 89] <author> R. K. Brayton and F. Somenzi. </author> <title> Boolean Relations and the Incomplete Specification of Logic Networks. </title> <booktitle> In Proceedings of the 1989 International Conference on Computer-Aided Design, </booktitle> <pages> pages 316-319, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: For example, they appear in several stages of logic synthesis, including two-level logic minimization and DAG covering for technology mapping [Rudell 89]. Covering problems are well-known intractable problems and have received considerable attention from researchers. Exact solutions have been given in [Grasselli 65] and <ref> [Brayton 89] </ref> using branch-and-bound search. Heuristic methods have also been proposed, e.g., [Grasselli 65], [Gimpel 67], and [Rudell 89]. Recently, Coudert and Madre discovered new pruning conditions that have substantially improved the efficiency of the search without compromising optimality [Coudert 95].
Reference: [Callahan 91] <author> D. Callahan and B. Koblenz. </author> <title> Register Allocation via Hierarchical Graph Coloring. </title> <booktitle> In Proceedings of the 1991 ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 192-203, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: For instance, for the register allocation problem, the usual starting point is a uniform register set which provides a good approximation for most RISC architectures, and for which several algorithms have been devised (e.g., [Chaitin 81], [F Chow 90], and <ref> [Callahan 91] </ref>). Adapting the algorithms to a particular target may, however, still require much manual effort, since each architecture has its features that need special treatment if they are to be exploited. <p> Because the number of address registers is limited, it is not always possible to allow for merging of variables. Therefore, a more thorough analysis of variable accesses is needed. The tile tree <ref> [Callahan 91] </ref> offers a natural and powerful way of analyzing and summarizing variable usage, and has been successfully applied to the traditional register allocation problem. By effectively using the information derived from tile tree analysis, we can best utilize the data memory while keeping the program small and efficient.
Reference: [Cattell 80] <author> R. Cattell. </author> <title> Automatic Derivation of Code Generators from Machine Descriptions. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 2(2) </volume> <pages> 173-190, </pages> <year> 1980. </year>
Reference-contexts: A survey of various grammar-based code generation methods is presented in [Ganapathi 82]. An alternative to parsing is to use pattern-matching techniques on expression trees. Cattell designed a framework in which code generators based on pattern-matching are automatically derived from a machine description language <ref> [Cattell 80] </ref>. The landmark paper by Aho et al. [Aho 89] established the foundation in which several modern dynamic-programming code-generator generators find their origin. One such code-generator generator is IBURG [Fraser 92], employed in the compiler framework LCC [Fraser 95].
Reference: [Chaitin 81] <author> G. Chaitin, M. Auslander, A. Chandra, J. Cocke, M. Hopkins, and P. Markstein. </author> <title> Register Allocation via Coloring. </title> <journal> Computer Languages, </journal> <volume> 6 </volume> <pages> 47-57, </pages> <year> 1981. </year>
Reference-contexts: For instance, for the register allocation problem, the usual starting point is a uniform register set which provides a good approximation for most RISC architectures, and for which several algorithms have been devised (e.g., <ref> [Chaitin 81] </ref>, [F Chow 90], and [Callahan 91]). Adapting the algorithms to a particular target may, however, still require much manual effort, since each architecture has its features that need special treatment if they are to be exploited. <p> For those register classes that have an infinite number of elements, a separate allocation phase (e.g., using a graph-coloring register allocator <ref> [Chaitin 81] </ref>) is carried out afterwards. As an example, consider the TMS320C25 architecture (see Figure 3-3 on page 51), which has three registers in the main data-path: the accumulator, the P register, and the T register. <p> Just as one had to prove that the register allocation problem is as hard as the coloring problem to which is usually reduced <ref> [Chaitin 81] </ref>, we need to show that the SOA problem is indeed an NP-hard problem. <p> Hence, if a variable has a high penalty, then it may be beneficial to move it to another partition block. The vertices with high penalties correspond to variables that are accessed frequently. As in traditional register allocation <ref> [Chaitin 81] </ref> [F Chow 90] where we tend to keep busy variables in fast registers, here we desire to minimize address arithmetic instructions for busy variables by allocating extra address registers to address them.
Reference: [F Chow 90] <author> F. C. Chow and J. L. Hennessy. </author> <title> The Priority-Based Coloring Approach to Register Allocation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(4) </volume> <pages> 501-536, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: For instance, for the register allocation problem, the usual starting point is a uniform register set which provides a good approximation for most RISC architectures, and for which several algorithms have been devised (e.g., [Chaitin 81], <ref> [F Chow 90] </ref>, and [Callahan 91]). Adapting the algorithms to a particular target may, however, still require much manual effort, since each architecture has its features that need special treatment if they are to be exploited. <p> Hence, if a variable has a high penalty, then it may be beneficial to move it to another partition block. The vertices with high penalties correspond to variables that are accessed frequently. As in traditional register allocation [Chaitin 81] <ref> [F Chow 90] </ref> where we tend to keep busy variables in fast registers, here we desire to minimize address arithmetic instructions for busy variables by allocating extra address registers to address them.
Reference: [P Chow 94] <author> P. Chow and C. G. Lee. </author> <title> Compiler-Driven Architectural Design for DSPs. Research Proposal, </title> <month> July </month> <year> 1994. </year>
Reference-contexts: This naturally leads to a study of the design of architectures in which compiler support plays an important role <ref> [P Chow 94] </ref>. Therefore, in contrast to MIMOLA and CHESS cited in Section 2.3 which primarily emphasize retargetability, this thesis approaches the software compilation problem 2.5 EXPERIMENTAL FRAMEWORK 41 from the standpoint of the generation of high-quality code, and, in particular, program optimization techniques. <p> This insight will, in turn, serve as a guide for the design of ASIPs, which should take compiler support into consideration when making architectural decisions. There has been some work along this direction, e.g., that of Chow et al. <ref> [P Chow 94] </ref>. Appendix A Covering Problems This appendix describes the set (unate) and binate covering problems that we encountered in Chapter 5 for code compression and Chapter 3 for code generation. Covering problems have also been extensively use in other areas of computer-aided design of digital circuits.
Reference: [Conway 58] <author> M. E. Conway. </author> <title> Proposal for an UNCOL. </title> <journal> Communications of the ACM, </journal> <volume> 1, </volume> <year> 1958. </year>
Reference-contexts: By traditional we mean compiler research geared towards general-purpose computing rather than specialized architectures such as digital signal processors. Portability has always been a concern of compiler researchers since the inception of high-level programming languages and compilers <ref> [Conway 58] </ref>. Therefore, almost all compilers are organized in two major phases [Wulf 75] [Aho 86] (which may, of course, consist of smaller phases). The first phase, called the front-end, consists of lexical analysis and parsing.
Reference: [Cormen 90] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Electrical Engineering and Computer Science Series. MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: In particular, selecting an edge e and merging src (e) and dst (e) reduces both jEj and jVj by one, whereby the property jEj = jVj 1 still holds. By Theorem 5.2 of <ref> [Cormen 90, page 91] </ref>, the resulting DAG remains u-acyclic. Therefore, by repeatedly imploding the selected edges of the worm-partition, no u-cycle, much less a d-cycle, will appear in G. The worm-partition is hence legal. If there are u-cycles in D, however, then the fundamental clauses become insufficient. <p> Depth-first search takes O (jEj + jVj) time <ref> [Cormen 90, page 479] </ref>, which is O (jEj) for connected graphs. Theorem 4.2 Given an access sequence T and an integer k, the problem of deciding whether there exists an assignment for T with cost less than or equal to k is NP-hard. <p> A threshold on the minimum length M (for example, 3) of substrings is prescribed, so that only potentially beneficial substrings are extracted. We use a nave algorithm to identify common substrings. This algorithm is similar to the basic string-matching algorithm of <ref> [Cormen 90, page 855] </ref>. We may also apply 5.6 AN ALGORITHM FOR CODE COMPRESSION 161 every other basic block, as well as itself, at all possible positions of overlap. Longest common substrings at each position are extracted.
Reference: [Coudert 95] <author> O. Coudert and J.-C. Madre. </author> <title> New Ideas for Solving Covering Problems. </title> <booktitle> In Proceedings of the 32nd Design Automation Conference, </booktitle> <pages> pages 641-646, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Therefore, we will need to solve the problems of pointer substitution and dictionary generation simultaneously. 5.6 AN ALGORITHM FOR CODE COMPRESSION 163 In this section, we describe a set covering formulation which benefits from the use of recently developed optimum and heuristic covering algorithms <ref> [Coudert 95] </ref>. In the set covering formulation, we create a covering matrix in which the columns of the matrix are variables, and the rows are disjunctive clauses over different subsets of the variables. <p> We use the covering solver SCHERZO described in <ref> [Coudert 95] </ref> to find such an assignment. Note that the value of the objective function C size does not correspond directly to the final code size. <p> Exact solutions have been given in [Grasselli 65] and [Brayton 89] using branch-and-bound search. Heuristic methods have also been proposed, e.g., [Grasselli 65], [Gimpel 67], and [Rudell 89]. Recently, Coudert and Madre discovered new pruning conditions that have substantially improved the efficiency of the search without compromising optimality <ref> [Coudert 95] </ref>. The resulting solver, called SCHERZO, is able to find exact solutions to difficult instances 10-100 times faster than earlier methods. <p> The choice of the column to remove at each iteration and the tightness of the lower-bound computation have great impact on the amount time for the branch-and-bound procedure to complete. Coudert and Madre give an excellent description of effective algorithms for selecting columns and lower-bound computation in <ref> [Coudert 95] </ref>. Appendix B Other Optimizations In addition to the traditional compiler optimizations and the optimizations described in Chapters 3-5 that are targeted to DSP architectures, several other optimizations can be used in conjunction therewith. These optimizations can be easily incorporated into our compiler framework.
Reference: [Davidson 82] <author> J. W. Davidson and C. W. Fraser. </author> <title> Eliminating Redundant Object Code. </title> <booktitle> In Proceedings of the 9th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 128-132, </pages> <year> 1982. </year>
Reference-contexts: Davidson and 36 RELATED RESEARCH AND APPROACH OF THIS THESIS Fraser have proposed a methodology for automatically deriving peephole optimizers from a machine description that consists of a set of code-transformation templates <ref> [Davidson 82] </ref> [Davidson 84]. One of the limitations of this methodology is that the two- or three-instruction window sometimes fails to discover optimizations that are obscured by the presence of unrelated instructions within the window. <p> Also, because interprocedural analysis (Section B.1) is performed in the TWIF intermediate form, this phase assumes the task of resolving symbolic addresses of global variables and procedures as well. Along with this step we can perform peephole optimizations (e.g., [McKeeman 65], [Lamb 81], and <ref> [Davidson 82] </ref>) to eliminate redundancy that may have been neglected 44 RELATED RESEARCH AND APPROACH OF THIS THESIS in earlier phases or may have arisen from the translation of macros and pseudo-instructions.
Reference: [Davidson 84] <author> J. Davidson and C. Fraser. </author> <title> Code Selection through Object Code Optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 6(4), </volume> <year> 1984. </year>
Reference-contexts: Davidson and 36 RELATED RESEARCH AND APPROACH OF THIS THESIS Fraser have proposed a methodology for automatically deriving peephole optimizers from a machine description that consists of a set of code-transformation templates [Davidson 82] <ref> [Davidson 84] </ref>. One of the limitations of this methodology is that the two- or three-instruction window sometimes fails to discover optimizations that are obscured by the presence of unrelated instructions within the window.
Reference: [Depuydt 93] <author> F. Depuydt. </author> <title> Register Optimization and Scheduling for Real-Time Digital Signal Processing Architectures. </title> <type> PhD thesis, </type> <institution> Katholieke Universiteit Leuven, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: Due to their enormous market demand, the manufacturing of electronic systems is very cost-sensitive. Moreover, many applications (e.g., cellular phones) have stringent requirements on power consumption, for the sake of portability. For these reasons, manufacturers profit from integrating an entire system on a single integrated circuit (IC) [Goossens 92] <ref> [Depuydt 93] </ref>. This desired high level of integration has been made possible by the advent of deep submicron processing technology (e.g., the 0.25-micron G10 TM Technology of LSI Logic [LSI 95]), which allows for the integration of several million usable gates on a single die.
Reference: [DES 77] <author> U. S. </author> <title> Department of Commerce, National Bureau of Standards. Data Encryption Standard, </title> <month> January </month> <year> 1977. </year> <note> Federal Information Processing Standards Publication (FIPS PUB 46). BIBLIOGRAPHY 205 </note>
Reference-contexts: The next eight, LOADGIF through 332DITHER, are graphics routines from the xv program. Following them are procedures from the GNU gzip program: GENBITLEN through UNLZW. INITDES and UFCDOIT are two procedures in the GNU implementation of the DES encryption algorithm <ref> [DES 77] </ref>. Finally, MD5C and DECQUAN were taken from an implementation of the RSA cryptosystem [Rivest 78]. The column labeled jVj shows the number of variables, including compiler-generated temporaries, in the procedure. The next column, jEj, gives the number of edges in the initial access graph. <p> Finally, HILL, GNUCRYPT, and RSAREF are data encryption programs. HILL is an encryption scheme based on matrix multiplication. GNUCRYPT, from the GNU C Library, uses the data encryption standard (DES) <ref> [DES 77] </ref>. RSAREF is an implementation of the RSA public-key cryptosystem [Rivest 78]. We have performed the experiments varying the size of the pointer, P. Specifically, we used P = 1 and P = 2 for both methods, and we show the results in Tables 5.2 and 5.3 (pages 174-175).
Reference: [Devadas 94] <author> S. Devadas, A. Ghosh, and K. Keutzer. </author> <title> Logic Synthesis. </title> <publisher> McGraw Hill, </publisher> <address> New York, NY, </address> <year> 1994. </year> <note> ISBN 0-0701-6500-9. </note>
Reference-contexts: Designing an entire system with custom integrated circuit is now neither economical nor practical. As time-to-market requirements place greater burden on designers for fast design cycles, programmable components are introduced in the system and an increasing amount of system functionality is implemented in software relative to hardware <ref> [Devadas 94, page 393] </ref>. These programmable components, called embedded processors or embedded controllers, can be general-purpose microprocessors, off-the-shelf digital signal processors (DSPs), in-house application-specific instruction-set processors (ASIPs), or microcontrollers. Systems containing programmable processors that are employed for applications other than general-purpose computing are called embedded systems.
Reference: [Dhamdhere 92] <author> D. M. Dhamdhere, B. K. Rosen, and F. K. Zadeck. </author> <title> How to Analyze Large Programs Efficiently and Informatively. </title> <booktitle> In Proceedings of the 1992 ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 212-223, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: A critical edge in a control-flow graph is an edge that emanates from a basic block with more than one successor and leads into another basic block with more than one predecessor <ref> [Dhamdhere 92] </ref> [Knoop 95]. impact on code size and performance. In Figure 4-16 (a), the edge f 23 is a critical edge because its source vertex n 2 has two fanouts and its destination vertex n 3 has two fanins.
Reference: [Ellis 85] <author> J. R. Ellis. </author> <title> A Compiler for VLIW Architectures. </title> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference-contexts: For the purpose of code generation, a basic block is usually represented by an expression directed acyclic graph (DAG), which naturally discovers local common subexpressions [Aho 86]. It is also possible to obtain larger and more complicated DAGs for traces [Fisher 81] <ref> [Ellis 85] </ref> 46 CODE GENERATION basic block. (b) The corresponding expression DAG, assuming p, t, and u are not live upon exit of the basic block. that cross basic block boundaries.
Reference: [Fauth 95] <author> A. Fauth, J. Van Praet, and M. Freericks. </author> <title> Describing Instruction Sets Using nML (Extended Version). </title> <type> Technical report, </type> <institution> Technische Universit at Berlin and IMEC, </institution> <address> Berlin (Germany)/Leuven (Belgium), </address> <year> 1995. </year>
Reference-contexts: Bit alignment assures a correct bit-level behavior of the implementation. Finally, a complete schedule is constructed using a list-scheduling algorithm and object code is emitted. The target machine is described using the language nML <ref> [Fauth 95] </ref>. A graphical representation of the architecture called the instruction-set graph (ISG) is then derived from the nML description.
Reference: [Ferrante 87] <author> J. Ferrante, K. J. Ottenstein, and J. D. Warren. </author> <title> The Program Dependence Graph and Its Use in Optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Chapter 3 Code Generation While several compiler researchers have proposed alternative program representations such as the program dependence graph (PDG) <ref> [Ferrante 87] </ref> and the value dependence graph (VDG) [Weise 94] [Ruf 95], the most widely used representation of program structures to date has still been the control-flow graph.
Reference: [Fisher 81] <author> J. A. Fisher. </author> <title> Trace Scheduling: A Technique for Global Microcode Compaction. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30(7):478-490, </volume> <year> 1981. </year>
Reference-contexts: For the purpose of code generation, a basic block is usually represented by an expression directed acyclic graph (DAG), which naturally discovers local common subexpressions [Aho 86]. It is also possible to obtain larger and more complicated DAGs for traces <ref> [Fisher 81] </ref> [Ellis 85] 46 CODE GENERATION basic block. (b) The corresponding expression DAG, assuming p, t, and u are not live upon exit of the basic block. that cross basic block boundaries.
Reference: [Fraser 84] <author> C. W. Fraser, E. W. Myers, and A. L. Wendt. </author> <title> Analyzing and Compressing Assembly Code. </title> <booktitle> In Proceedings of the 1994 ACM SIGPLAN Symposium on Compiler Construction, </booktitle> <pages> pages 117-121, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: Not only does the set covering formulation 142 CODE COMPRESSION yield notably better solutions than our initial greedy algorithm, it can also be extended to take into consideration the performance penalty resulting from code compression. 5.1 Previous Work Fraser et al. presented a compression scheme in <ref> [Fraser 84] </ref> based on cross-jumping and procedural abstraction. In cross-jumping, common tails of basic blocks that have the same successor are extracted and placed in a new basic block, so that the common code only appears once. Figure 5-1 illustrates this transformation.
Reference: [Fraser 92] <author> C. W. Fraser, D. R. Hanson, and T. A. Proebsting. </author> <title> Engineering a Simple, Efficient Code-Generator Generator. </title> <journal> ACM Letters of Programming Languages and Systems, </journal> <volume> 1(3) </volume> <pages> 213-226, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Cattell designed a framework in which code generators based on pattern-matching are automatically derived from a machine description language [Cattell 80]. The landmark paper by Aho et al. [Aho 89] established the foundation in which several modern dynamic-programming code-generator generators find their origin. One such code-generator generator is IBURG <ref> [Fraser 92] </ref>, employed in the compiler framework LCC [Fraser 95]. The dynamic-programming methodology yields locally optimal code (i.e., within the expression tree). <p> Then, the program is translated via a preliminary code generation stage into another intermediate form called TWIF. The preliminary code generated is produced from a rule-based machine description written in OLIVE [Tjiang 94] or DAG-WOOD [Tjiang 95]. OLIVE, a descendent of TWIG [Aho 89] and IBURG <ref> [Fraser 92] </ref>, is a language for writing tree-matchers based on dynamic programming. If tree-covering for preliminary code generation is desired, OLIVE allows for compact specifications of code generators.
Reference: [Fraser 95] <author> C. W. Fraser and D. R. Hanson. </author> <title> A Retargetable C Compiler: Design and Implementation. </title> <publisher> Benjamin/Cummings Publishing Company, </publisher> <address> Redwood City, California, </address> <year> 1995. </year> <note> ISBN 0-8053-1670-1. </note>
Reference-contexts: The landmark paper by Aho et al. [Aho 89] established the foundation in which several modern dynamic-programming code-generator generators find their origin. One such code-generator generator is IBURG [Fraser 92], employed in the compiler framework LCC <ref> [Fraser 95] </ref>. The dynamic-programming methodology yields locally optimal code (i.e., within the expression tree). However, local optimality is often insufficient when the piece of code is placed in the context of the entire procedure, and procedure-wide and program-wide optimizations are required to further improve the code.
Reference: [Ganapathi 82] <author> M. Ganapathi, C. N. Fischer, and J. Hennessy. </author> <title> Retargetable Compiler Code Generation. </title> <journal> ACM Computing Surveys, </journal> <volume> 14(4) </volume> <pages> 573-592, </pages> <year> 1982. </year>
Reference-contexts: Ganapathi and Fischer refined this basic grammar-based approach by 2.2 TRADITIONAL COMPILER RESEARCH 35 using affix grammars with attributes [Ganapathi 85]. A survey of various grammar-based code generation methods is presented in <ref> [Ganapathi 82] </ref>. An alternative to parsing is to use pattern-matching techniques on expression trees. Cattell designed a framework in which code generators based on pattern-matching are automatically derived from a machine description language [Cattell 80].
Reference: [Ganapathi 85] <author> M. Ganapathi and C. N. Fischer. </author> <title> Affix Grammar Driven Code Generation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(4), </volume> <year> 1985. </year>
Reference-contexts: Thus, another level of abstraction is created whereby the compiler writer may describe his code generator more easily and does not have to write it in a general-purpose high-level language. Ganapathi and Fischer refined this basic grammar-based approach by 2.2 TRADITIONAL COMPILER RESEARCH 35 using affix grammars with attributes <ref> [Ganapathi 85] </ref>. A survey of various grammar-based code generation methods is presented in [Ganapathi 82]. An alternative to parsing is to use pattern-matching techniques on expression trees. Cattell designed a framework in which code generators based on pattern-matching are automatically derived from a machine description language [Cattell 80].
Reference: [Ganssle 92] <author> J. G. Ganssle. </author> <title> The Art of Programming Embedded Systems. </title> <publisher> Academic Press, Inc., </publisher> <address> San Diego, California, </address> <year> 1992. </year>
Reference-contexts: In order to avoid excessive design modification, designers usually have to work diligently to reduce the code size, sometimes at the expense of removing certain features of the product <ref> [Ganssle 92] </ref>. Besides code size and performance, there are other important constraints and requirements for embedded systems, most notably data memory and power dissipation.
Reference: [Giegerich 83] <author> R. Giegerich. </author> <title> A Formal Framework for the Derivation of Machine Specific Optimizers. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(3) </volume> <pages> 478-498, </pages> <year> 1983. </year>
Reference-contexts: Another notable work is that of Giegerich, who improved upon the Davidson-Fraser approach by taking machine-level data-flow information into consideration <ref> [Giegerich 83] </ref>. These methods operate at a late stage of the compilation process (i.e., object-to-object transformation) and are not capable of capturing the optimizations at earlier stages, such as register allocation and scheduling. More recently, Bradlee proposed a retargetable scheduler MARION that is used mainly for RISC architectures [Bradlee 91].
Reference: [Gimpel 67] <author> J. Gimpel. </author> <title> The Minimization of TANT Networks. </title> <journal> IEEE Transactions on Electronic Computers, </journal> <volume> EC-16(1):18-38, </volume> <month> February </month> <year> 1967. </year> <note> 206 BIBLIOGRAPHY </note>
Reference-contexts: Covering problems are well-known intractable problems and have received considerable attention from researchers. Exact solutions have been given in [Grasselli 65] and [Brayton 89] using branch-and-bound search. Heuristic methods have also been proposed, e.g., [Grasselli 65], <ref> [Gimpel 67] </ref>, and [Rudell 89]. Recently, Coudert and Madre discovered new pruning conditions that have substantially improved the efficiency of the search without compromising optimality [Coudert 95]. The resulting solver, called SCHERZO, is able to find exact solutions to difficult instances 10-100 times faster than earlier methods. <p> We can apply several reduction techniques to simplify a covering matrix. We will briefly describe the notions of essentiality and dominance. The reader is referred to <ref> [Gimpel 67] </ref> and [Rudell 89] for additional reduction techniques. A column j is essential if there exists some row i such that column j is the only column that covers row i.
Reference: [Glanville 78] <author> R. S. Glanville and S. L. Graham. </author> <title> A New Method for Compiler Code Generation. </title> <booktitle> In Proceedings of the 5th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 231-240, </pages> <year> 1978. </year>
Reference-contexts: In such an organization, portability is achieved in the sense that, whenever a new architecture is to be targeted, only the back-end (instead of the entire compiler) needs to be rewritten. The table-driven code generation technique proposed by Glanville and Graham <ref> [Glanville 78] </ref> [Graham 80] was one of the first efforts to advance the notion of portability by describing the code generator in a grammar and automatically generating the code generator, in a manner much analogous to the parser generator YACC.
Reference: [Goossens 92] <author> G. Goossens, F. Catthoor, D. Lanneer, and H. De Man. </author> <title> Integration of Signal Processing Systems on Heterogeneous IC Architectures. </title> <booktitle> In Proceedings of the 6th International Workshop on High-Level Synthesis, </booktitle> <pages> pages 16-26, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Due to their enormous market demand, the manufacturing of electronic systems is very cost-sensitive. Moreover, many applications (e.g., cellular phones) have stringent requirements on power consumption, for the sake of portability. For these reasons, manufacturers profit from integrating an entire system on a single integrated circuit (IC) <ref> [Goossens 92] </ref> [Depuydt 93]. This desired high level of integration has been made possible by the advent of deep submicron processing technology (e.g., the 0.25-micron G10 TM Technology of LSI Logic [LSI 95]), which allows for the integration of several million usable gates on a single die.
Reference: [Goossens 95] <author> G. Goossens, D. Lanneer, M. Pauwels, F. Depuydt, K. Schoofs, A. Kifli, M. Conero, P. Petroni, F. Catthoor, and H. De Man. </author> <title> Integration of Medium-Throughput Signal Processing Algorithms on Flexible Instruction-Set Architectures. </title> <journal> Journal of VLSI Signal Processing, </journal> <volume> 9(1) </volume> <pages> 49-65, </pages> <year> 1995. </year>
Reference-contexts: [Leupers 94a]) remains to be supported with more experimental results. 2.3.2 CHESS CHESS [Lanneer 95] is a retargetable code generation environment for fixed-point digital signal processors and ASIPs; it was developed in the context of the CATHE 38 RELATED RESEARCH AND APPROACH OF THIS THESIS DRAL II high-level synthesis system <ref> [Goossens 95] </ref>. Unlike MIMOLA which uses mostly-structural models, CHESS employs a mixed behavioral-structural model for processor representation. The code generation process consists of six major phases: (1) optimizing transformations and flow graph refinement, (2) code selection, (3) register allocation, (4) bit alignment, (5) scheduling, and (6) code assembly.
Reference: [Goossens 96] <author> G. Goossens, J. Van Praet, D. Lanneer, W. Geurts, and F. Thoen. </author> <title> Programmable Chips in Consumer Electronics and Telecommunications. </title> <editor> In G. De Micheli and M. G. Sami, editors, Hardware/Software Co-Design. </editor> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, Massachusetts, </address> <year> 1996. </year> <note> ISBN 0-7923-3882-0. </note>
Reference-contexts: Present commercial DSP compilers, which employ standard software compilation techniques, often produce code of quality that leaves much room for improvement [ Zivojnovic 94] <ref> [Goossens 96] </ref>. Thus the central theme of this thesis is that a new goal for code optimization has emerged: the generation of the most dense code with the highest performance, obtainable within any reasonable compilation time. <p> and it is not necessary (unless required during the evaluation of the DAG) to store these values into the memory. 3.1 TASKS OF A CODE GENERATOR 47 3.1 Tasks of a Code Generator Code generation is traditionally viewed as consisting of three main tasks: code selection, scheduling, and register allocation <ref> [Goossens 96] </ref>. Code selection is the task of mapping operators in the intermediate form into target machine operators. Scheduling is the task of ordering the instructions to make the program more efficient and/or smaller. <p> The problem of code generation for expression DAGs has long been known to be computationally complex for many machine models, because the three main tasks of code generation are coupled and because the scheduling of DAGs is by itself difficult for most objective functions. The phase-coupling problem <ref> [Goossens 96] </ref> is especially severe in machines with few registers and irregular data-paths. The standard heuristic to alleviate the problems caused by DAGs is to break a subject DAG into a forest of trees by cutting it at vertices with multiple fanouts.
Reference: [Graham 80] <author> S. L. Graham. </author> <title> Table-Driven Code Generation. </title> <journal> IEEE Computer, </journal> <volume> 13(8) </volume> <pages> 25-34, </pages> <year> 1980. </year>
Reference-contexts: In such an organization, portability is achieved in the sense that, whenever a new architecture is to be targeted, only the back-end (instead of the entire compiler) needs to be rewritten. The table-driven code generation technique proposed by Glanville and Graham [Glanville 78] <ref> [Graham 80] </ref> was one of the first efforts to advance the notion of portability by describing the code generator in a grammar and automatically generating the code generator, in a manner much analogous to the parser generator YACC.
Reference: [Grasselli 65] <author> A. Grasselli and F. Luccio. </author> <title> A Method for Minimizing the Number of Internal States in Incompletely Specified Machines. </title> <journal> IEEE Transactions on Electronic Computers, </journal> <volume> EC-14(3):350-359, </volume> <month> June </month> <year> 1965. </year>
Reference-contexts: For example, they appear in several stages of logic synthesis, including two-level logic minimization and DAG covering for technology mapping [Rudell 89]. Covering problems are well-known intractable problems and have received considerable attention from researchers. Exact solutions have been given in <ref> [Grasselli 65] </ref> and [Brayton 89] using branch-and-bound search. Heuristic methods have also been proposed, e.g., [Grasselli 65], [Gimpel 67], and [Rudell 89]. Recently, Coudert and Madre discovered new pruning conditions that have substantially improved the efficiency of the search without compromising optimality [Coudert 95]. <p> Covering problems are well-known intractable problems and have received considerable attention from researchers. Exact solutions have been given in <ref> [Grasselli 65] </ref> and [Brayton 89] using branch-and-bound search. Heuristic methods have also been proposed, e.g., [Grasselli 65], [Gimpel 67], and [Rudell 89]. Recently, Coudert and Madre discovered new pruning conditions that have substantially improved the efficiency of the search without compromising optimality [Coudert 95]. The resulting solver, called SCHERZO, is able to find exact solutions to difficult instances 10-100 times faster than earlier methods.
Reference: [Gupta 93] <author> R. K. Gupta and G. De Micheli. </author> <title> Hardware-Software Cosynthesis for Digital Systems. </title> <booktitle> IEEE Design & Test of Computers, </booktitle> <pages> pages 29-41, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Because of the trend towards this design style, developers of computer-aided design (CAD) tools are faced with the challenge of providing circuit designers with tools that can support the design of such systems. There have been proposals for the hardware-software co-design of digital systems (e.g., <ref> [Gupta 93] </ref>, [Kalavade 93], and [Thomas 93]). The simplified view of a generic co-design methodology is shown in Figure 1-3. In this design flow, the designer first determines which parts of the functionality of the system will be implemented in hardware and which parts in software.
Reference: [Hall 91] <author> M. W. Hall. </author> <title> Managing Interprocedural Optimization. </title> <type> PhD thesis, </type> <institution> Rice University Department of Computer Science, Houston, Texas, </institution> <month> May </month> <year> 1991. </year> <note> Also technical report RICECS-TR91-157. </note>
Reference-contexts: Global optimization enhanced by interprocedural data-flow information. This has proven to be effective in removing spurious dependencies for parallel compilation. For scalar compilation, mixed results ranging from marginal to moderate improvements have been reported <ref> [Hall 91] </ref>. Global mode optimization to be described in Section B.4 can also naturally benefit from the information gathered by this analysis. Hall presented a comprehensive investigation and experimentation of these interpro-cedural optimizations in [Hall 91]. The first two of these optimizations, however, often trade off size for performance. <p> For scalar compilation, mixed results ranging from marginal to moderate improvements have been reported <ref> [Hall 91] </ref>. Global mode optimization to be described in Section B.4 can also naturally benefit from the information gathered by this analysis. Hall presented a comprehensive investigation and experimentation of these interpro-cedural optimizations in [Hall 91]. The first two of these optimizations, however, often trade off size for performance. In the context of embedded software, especially, we will need to take special caution in applying these optimizations to prevent the program size from growing too large.
Reference: [Hall 92] <author> M. W. Hall and K. Kennedy. </author> <title> Efficient Call Graph Analysis. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1(3), </volume> <month> September </month> <year> 1992. </year>
Reference-contexts: Constructing a call graph in the absence of procedure-valued parameters is trivial: only a single pass over the procedures and call sites is required. An efficient algorithm for constructing the call multigraph in the general case is presented in <ref> [Hall 92] </ref>. In addition to the aforesaid optimizations, the call graph provides information for other types of optimizations as well. Three optimization problems relevant to the context of our work are: static allocation of automatic variables, efficient use of the hardware link register stack, and global mode optimization.
Reference: [Hecht 77] <author> M. S. Hecht. </author> <title> Flow Analysis of Computer Programs. </title> <publisher> Elsevier, North Holland, </publisher> <year> 1977. </year>
Reference-contexts: Mode variables, though certainly machine-dependent, behave very much like user-defined variables: If we treat mode-setting instructions as definitions of a mode variable and instructions affected by a mode variable as uses, we may then use the standard reaching-definition and liveness analyses (see <ref> [Hecht 77] </ref> and [Aho 86]) to determine the definition-use characteristics of each mode variable. Partial redundancy elimination (see [Morel 79] and [Knoop 95]), which makes use of this information, can be readily applied to the mode variables.
Reference: [Holt 95] <author> M. Holt. </author> <title> Using Application-Specific DSPs for Better Performance, Cost. </title> <booktitle> Asian Electronics Engineer, </booktitle> <pages> pages 62-68, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: In fact, semiconductor costs vary exponentially with die sizesmaller die sizes are conducive to higher yields <ref> [Holt 95] </ref>. In heterogeneous systems such as that shown in Figure 1-2, it is not unusual for the single largest factor of the area to be the ROM storing the program code for the embedded processor core.
Reference: [Kalavade 93] <author> A. Kalavade and E. A. Lee. </author> <title> A Hardware-Software Codesign Methodology for DSP Applications. </title> <booktitle> IEEE Design & Test of Computers, </booktitle> <pages> pages 16-28, </pages> <month> September </month> <year> 1993. </year> <note> BIBLIOGRAPHY 207 </note>
Reference-contexts: Because of the trend towards this design style, developers of computer-aided design (CAD) tools are faced with the challenge of providing circuit designers with tools that can support the design of such systems. There have been proposals for the hardware-software co-design of digital systems (e.g., [Gupta 93], <ref> [Kalavade 93] </ref>, and [Thomas 93]). The simplified view of a generic co-design methodology is shown in Figure 1-3. In this design flow, the designer first determines which parts of the functionality of the system will be implemented in hardware and which parts in software.
Reference: [Karp 81] <author> R. M. Karp and M. O. Rabin. </author> <title> Efficient Randomized Pattern-Matching Algorithms. </title> <type> Technical Report TR-31-81, </type> <institution> Aiken Computation Laboratory, Harvard University, </institution> <year> 1981. </year>
Reference-contexts: We may also apply 5.6 AN ALGORITHM FOR CODE COMPRESSION 161 every other basic block, as well as itself, at all possible positions of overlap. Longest common substrings at each position are extracted. In this example, the threshold M is 3. 162 CODE COMPRESSION the modulo techniques of <ref> [Karp 81] </ref> to improve the average-case complexity. For the purpose of exposition, we will simply use the former. The operation of the algorithm is illustrated in Figure 5-7 (page 161).
Reference: [Keutzer 95] <author> K. </author> <title> Keutzer. </title> <type> Personal communication, </type> <year> 1995. </year>
Reference-contexts: As the complexity of embedded systems grows, nevertheless, programming in assembly language and optimization by hand are no longer practical, except for time-critical portions of the program that absolutely require it. Recent statistics from Dataquest indicate that high-level languages such as C and C++ are gradually replacing assembly language <ref> [Keutzer 95] </ref>, because using high-level languages greatly lowers the cost and time of development, as well as the maintenance costs of embedded systems. Also, less effort is required to reuse software written in high-level languages. Programming in a high-level language may, however, incur a code-size penalty.
Reference: [Knoop 95] <author> J. Knoop, O. R uthing, and B. Steffen. </author> <title> The Power of Assignment Motion. </title> <booktitle> In Proceedings of the 1995 ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 233-245, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: A critical edge in a control-flow graph is an edge that emanates from a basic block with more than one successor and leads into another basic block with more than one predecessor [Dhamdhere 92] <ref> [Knoop 95] </ref>. impact on code size and performance. In Figure 4-16 (a), the edge f 23 is a critical edge because its source vertex n 2 has two fanouts and its destination vertex n 3 has two fanins. <p> Because we may at best place n 3 immediately after n 1 or n 5 but not both, we must append a JMP instruction at the end of one of them, presumably the one that is executed less frequently. Like all transformations based on partial redundancy elimination [Morel 79] <ref> [Knoop 95] </ref>, we need to account for not only the cost of the code for basic block n 5 , but also that of the additional JMP instructions required. <p> Partial redundancy elimination (see [Morel 79] and <ref> [Knoop 95] </ref>), which makes use of this information, can be readily applied to the mode variables.
Reference: [Kozuch 94] <author> M. Kozuch and A. Wolfe. </author> <title> Compression of Embedded Systems Programs. </title> <booktitle> In Proceedings of the 1994 International Conference on Computer Design: VLSI in Computers and Processors, </booktitle> <month> October </month> <year> 1994. </year>
Reference-contexts: More recently, Wolfe et al. proposed a novel RISC architecture that can execute programs stored in the memory in compressed form [Wolfe 92] <ref> [Kozuch 94] </ref>. Figure 5-2 (page 144) shows the Wolfe-Chanin architecture. The idea is to decompress, in the cache subsystem, the section of the program immediately to be executed so that the main processor sees the original instructions.
Reference: [Lam 88] <author> M. S. Lam. </author> <title> An Effective Scheduling Technique for VLIW Machines. </title> <booktitle> In Proceedings of the 1988 ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 318-328, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: For example, subroutine calls take less space than in-line code, but are generally slower due to 26 INTRODUCTION call overheads. Other optimizations that have potential speed-size trade-offs include induction variable elimination (or strength reduction) [F Allen 72], loop unrolling <ref> [Lam 88] </ref>, and partial redundancy elimination [Morel 79]. Where execution speed is not critical, minimizing the code size is usually profitable.
Reference: [Lamb 81] <author> D. Lamb. </author> <title> Construction of a Peephole Optimizer. </title> <journal> SoftwarePractices and Experiments, </journal> <volume> 11(6) </volume> <pages> 638-647, </pages> <year> 1981. </year>
Reference-contexts: Also, because interprocedural analysis (Section B.1) is performed in the TWIF intermediate form, this phase assumes the task of resolving symbolic addresses of global variables and procedures as well. Along with this step we can perform peephole optimizations (e.g., [McKeeman 65], <ref> [Lamb 81] </ref>, and [Davidson 82]) to eliminate redundancy that may have been neglected 44 RELATED RESEARCH AND APPROACH OF THIS THESIS in earlier phases or may have arisen from the translation of macros and pseudo-instructions.
Reference: [Lanneer 95] <author> D. Lanneer, J. Van Praet, A. Kifli, K. Schoofs, W. Geurts, F. Thoen, and G. Goossens. </author> <title> CHESS: Retargetable Code Generation for Embedded DSP Processors. </title> <editor> In P. Marwedel and G. Goossens, editors, </editor> <title> Code Generation for Embedded Processors, </title> <booktitle> Chapter 5, </booktitle> <pages> pages 85-102. </pages> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, Massachusetts, </address> <year> 1995. </year>
Reference-contexts: For our experiments we have used existing off-the-shelf DSP processors. Although these are not ASIPs per se, they share a large number of characteristics with ASIPs that make code generation for them a difficult task: the presence of irregular data-paths and nonhomogeneous, specialized registers <ref> [Lanneer 95] </ref>. 1.3 Summary of Contributions of This Thesis This section briefly summarizes the contributions of this thesis to the area of code generation and optimization for embedded digital signal processors. <p> that of the PowerPC compiler [Shipnes 94], which is used for the various members of the PowerPC family. 2.3 Research in Code Generation for Embedded Processors We have selected for review and critique three representative research projects in the area of code generation for embedded systems: MIMOLA [Marwedel 84], CHESS <ref> [Lanneer 95] </ref>, and FLEXWARE [Paulin 95]. The proceedings of the Dagstuhl Workshop [Marwedel 95] contains a collection of papers documenting several other contributors' efforts. 2.3.1 MIMOLA The MIMOLA design system was originally conceived as a design environment for hardware structures, using the MIMOLA hardware description language [Zimmermann 79]. <p> Hence, the effectiveness (in terms of code quality and of the amount of manual work involved) of the many techniques proposed (e.g., [Marwedel 93] and [Leupers 94a]) remains to be supported with more experimental results. 2.3.2 CHESS CHESS <ref> [Lanneer 95] </ref> is a retargetable code generation environment for fixed-point digital signal processors and ASIPs; it was developed in the context of the CATHE 38 RELATED RESEARCH AND APPROACH OF THIS THESIS DRAL II high-level synthesis system [Goossens 95].
Reference: [Lee 88] <author> E. A. Lee. </author> <title> Programmable DSP Architectures: Part I. </title> <journal> IEEE ASSP Magazine, </journal> <pages> pages 4-19, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: The emphasis in digital signal 1.3 SUMMARY OF CONTRIBUTIONS OF THIS THESIS 27 processing has for many years been on performance, and these processors have traditionally been programmed in assembly language and hand-optimized. In addition, DSP architectures are generally designed with little regard for compilers <ref> [Lee 88] </ref> [Lee 89]. Due to the architects' quest for good performance and low cost, irregular data-paths and limited addressing capabilities are often present in DSP architectures.
Reference: [Lee 89] <author> E. A. Lee. </author> <title> Programmable DSP Architectures: Part II. </title> <journal> IEEE ASSP Magazine, </journal> <pages> pages 4-14, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: The emphasis in digital signal 1.3 SUMMARY OF CONTRIBUTIONS OF THIS THESIS 27 processing has for many years been on performance, and these processors have traditionally been programmed in assembly language and hand-optimized. In addition, DSP architectures are generally designed with little regard for compilers [Lee 88] <ref> [Lee 89] </ref>. Due to the architects' quest for good performance and low cost, irregular data-paths and limited addressing capabilities are often present in DSP architectures.
Reference: [Leupers 94a] <author> R. Leupers, R. Niemann, and P. Marwedel. </author> <title> Methods for Retargetable DSP Code Generation. </title> <booktitle> In Proceedings of the 1994 IEEE Workshop on VLSI Signal Processing, </booktitle> <year> 1994. </year>
Reference-contexts: Hence, the effectiveness (in terms of code quality and of the amount of manual work involved) of the many techniques proposed (e.g., [Marwedel 93] and <ref> [Leupers 94a] </ref>) remains to be supported with more experimental results. 2.3.2 CHESS CHESS [Lanneer 95] is a retargetable code generation environment for fixed-point digital signal processors and ASIPs; it was developed in the context of the CATHE 38 RELATED RESEARCH AND APPROACH OF THIS THESIS DRAL II high-level synthesis system [Goossens
Reference: [Leupers 94b] <author> R. Leupers and P. Marwedel. </author> <title> Instruction Set Extraction from Programmable Structures. </title> <booktitle> In Proceedings of the 1994 European Design Automation Conference, </booktitle> <year> 1994. </year>
Reference-contexts: To allow the basic MIMOLA system to handle a wider class of architectures, Leupers et al. have presented a method for extracting the instruction set from the structural description <ref> [Leupers 94b] </ref>, and have retargeted their compiler for the TMS320C25 digital signal processor [Leupers 94c].
Reference: [Leupers 94c] <author> R. Leupers, W. Schenk, and P. Marwedel. </author> <title> Retargetable Assembly Code Generation by Bootstrapping. </title> <booktitle> In Proceedings of the International Symposium on High-Level Synthesis, </booktitle> <month> May </month> <year> 1994. </year> <title> Extended version: </title> <type> Technical report 488, </type> <institution> Lehrstuhl Informatik XII, University of Dortmund, Germany. </institution> <year> 1993. </year> <note> 208 BIBLIOGRAPHY </note>
Reference-contexts: To allow the basic MIMOLA system to handle a wider class of architectures, Leupers et al. have presented a method for extracting the instruction set from the structural description [Leupers 94b], and have retargeted their compiler for the TMS320C25 digital signal processor <ref> [Leupers 94c] </ref>. However, even though the MIMOLA methodology is interesting in its own right, the publications suffer from the fact they offer relatively few demonstrable results, and these few results are often not easy to evaluate and interpret.
Reference: [Liao 95a] <author> S. Y. Liao, S. Devadas, K. Keutzer, S. Tjiang, and A. Wang. </author> <title> Code Optimization Techniques in Embedded DSP Microprocessors. </title> <booktitle> In Proceedings of the 32nd Design Automation Conference, </booktitle> <pages> pages 599-604, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Unlike previous work (e.g., [Aho 77]), our formulation clearly and succinctly describes the scheduling constraints along with accumulator spills and reloads, and allows for more-flexible cost functions. We also propose extensions of this formulation to tackle multiple-register machines and other optimization objectives such as the mode optimization problem of <ref> [Liao 95a] </ref>. In Chapter 4 we address the problem of storage assignment that one frequently encounters in DSP architectures. Unlike general-purpose register machines, DSP architectures typically have limited addressing modes and storage assignment has a great impact on the size as well as performance of the generated code. <p> We must take this cost into account in order to find an optimal instruction selection. The major complication in modeling accumulator spills and reloads is that the spilling of values depends on the chosen instruction schedule <ref> [Liao 95a] </ref> [Liao 95c]. However, since our instruction selection is not yet complete we do not know the schedule. Hence, we have to both choose the instructions and determine a (partial) schedule of these instructions at the same time. <p> Since mode variables assert control beyond that encoded in an instruction, they must be first set to the correct values if the current values are not as desired for the next instruction to be executed. In <ref> [Liao 95a] </ref> the authors presented the mode optimization problem and a strategy to minimize the number of changes in mode settings and accumulator spills. In this section we propose a method to incorporate the mode optimization in the binate covering formulation. <p> The schedule of Figure 3-20 (b) requires three mode changes (in addition to intra-worm changes), whereas that of the partial schedule given by the worm-graph in the presence of mode variables, we need to take this cost into account. The branch-and-bound algorithm described in <ref> [Liao 95a] </ref> is readily applied, here on the worm-graph rather than the subject DAG.
Reference: [Liao 95b] <author> S. Y. Liao, S. Devadas, K. Keutzer, S. Tjiang, and A. Wang. </author> <title> Storage Assignment to Decrease Code Size. </title> <booktitle> In Proceedings of the 1995 ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 186-195, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: subsume it into auto-increment or auto-decrement modes to improve both the performance the the size of the generated code. 94 STORAGE ASSIGNMENT The placement of variables in storage has a significant impact on the effectiveness of subsumption, which is in turn dependent on the patterns in which variables are accessed <ref> [Liao 95b] </ref>. Therefore, we perform the actual assignment of locations to variables after code selection, thereby increasing opportunities to use efficient auto-increment and auto-decrement modes.
Reference: [Liao 95c] <author> S. Y. Liao, S. Devadas, K. Keutzer, and S. Tjiang. </author> <title> Instruction Selection Using Binate Covering for Code Size Optimization. </title> <booktitle> In Proceedings of the 1995 International Conference on Computer-Aided Design, </booktitle> <pages> pages 393-399, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: We must take this cost into account in order to find an optimal instruction selection. The major complication in modeling accumulator spills and reloads is that the spilling of values depends on the chosen instruction schedule [Liao 95a] <ref> [Liao 95c] </ref>. However, since our instruction selection is not yet complete we do not know the schedule. Hence, we have to both choose the instructions and determine a (partial) schedule of these instructions at the same time.
Reference: [Liem 94] <author> C. Liem, T. C. May, and P. G. Paulin. </author> <title> Register Assignment through Resource Classification for ASIP Microcode Generation. </title> <booktitle> In Proceedings of the 1994 IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <pages> pages 397-402, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Resources (i.e., register and memory) are described in terms of their connectivity and relationship (e.g., the points-to relation) with one another. Furthermore, they are classified according to their functionality, which guides the register allocation process <ref> [Liem 94] </ref>. The micro-instruction format is used for compaction, assembly, and linking. Although the approach of Paulin et al., unlike MIMOLA and CHESS, does not use a unified machine representation, it is, among these three approaches, the most conducive to good code quality.
Reference: [LSI 95] <institution> LSI Logic Corporation. </institution> <month> G10: </month> <title> Tenth Generation ASIC Technology, Product brief, </title> <note> 1995. See http://www.lsilogic.com. </note>
Reference-contexts: For these reasons, manufacturers profit from integrating an entire system on a single integrated circuit (IC) [Goossens 92] [Depuydt 93]. This desired high level of integration has been made possible by the advent of deep submicron processing technology (e.g., the 0.25-micron G10 TM Technology of LSI Logic <ref> [LSI 95] </ref>), which allows for the integration of several million usable gates on a single die.
Reference: [Marwedel 84] <author> P. Marwedel. </author> <title> The MIMOLA Design System: Tools for the Design of Digital Processors. </title> <booktitle> In Proceedings of the 21th Design Automation Conference, </booktitle> <pages> pages 587-593, </pages> <year> 1984. </year>
Reference-contexts: retargetable compilers include that of the PowerPC compiler [Shipnes 94], which is used for the various members of the PowerPC family. 2.3 Research in Code Generation for Embedded Processors We have selected for review and critique three representative research projects in the area of code generation for embedded systems: MIMOLA <ref> [Marwedel 84] </ref>, CHESS [Lanneer 95], and FLEXWARE [Paulin 95]. <p> It later evolved into an environment for hardware-software co-design and includes 2.3 RESEARCH IN CODE GENERATION FOR EMBEDDED PROCESSORS 37 a retargetable microcode compiler <ref> [Marwedel 84] </ref> [Marwedel 93]. The microarchitec-ture structure is described in the language MIMOLA as before, and the description is translated into an intermediate representation called TREEMOLA.
Reference: [Marwedel 93] <author> P. Marwedel. </author> <title> Tree-Based Mapping of Algorithms to Predefined Structures. </title> <booktitle> In Proceedings of the 1993 IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <pages> pages 586-593, </pages> <year> 1993. </year> <title> Extended version: </title> <type> Technical report 431, </type> <institution> Lehrstuhl Informatik XII, University of Dortmund, Germany. </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: It later evolved into an environment for hardware-software co-design and includes 2.3 RESEARCH IN CODE GENERATION FOR EMBEDDED PROCESSORS 37 a retargetable microcode compiler [Marwedel 84] <ref> [Marwedel 93] </ref>. The microarchitec-ture structure is described in the language MIMOLA as before, and the description is translated into an intermediate representation called TREEMOLA. <p> Hence, the effectiveness (in terms of code quality and of the amount of manual work involved) of the many techniques proposed (e.g., <ref> [Marwedel 93] </ref> and [Leupers 94a]) remains to be supported with more experimental results. 2.3.2 CHESS CHESS [Lanneer 95] is a retargetable code generation environment for fixed-point digital signal processors and ASIPs; it was developed in the context of the CATHE 38 RELATED RESEARCH AND APPROACH OF THIS THESIS DRAL II high-level
Reference: [Marwedel 95] <author> P. Marwedel and G. Goossens, </author> <title> editors. Code Generation for Embedded Processors. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year> <title> Proceedings of the 1994 Dagstuhl Workshop on Code Generation for Embedded Processors. </title> <note> ISBN 0-7923-9577-8. </note>
Reference-contexts: Research and Approach of This Thesis In response to the need for software-compilation tools that comprise part of a hardware-software co-design environment, there has been increasing research interest in code generation for embedded processors, as evinced by the First Workshop on Code Generation for Embedded Processors (Schloss Dagstuhl, Germany, 1994) <ref> [Marwedel 95] </ref>. Various researchers have taken different approaches to the difficult problem of developing compilers that have the following properties: 1. The code generated by the compiler must be of the highest quality attainable within a reasonable amount of time. 2. <p> The proceedings of the Dagstuhl Workshop <ref> [Marwedel 95] </ref> contains a collection of papers documenting several other contributors' efforts. 2.3.1 MIMOLA The MIMOLA design system was originally conceived as a design environment for hardware structures, using the MIMOLA hardware description language [Zimmermann 79].
Reference: [Mayne 75] <author> A. Mayne and E. B. James. </author> <title> Information Compression by Factoring Common Strings. </title> <journal> Computer Journal, </journal> <volume> 18(2) </volume> <pages> 157-160, </pages> <year> 1975. </year>
Reference-contexts: A heuristic algorithm for generating a dictionary was presented in <ref> [Mayne 75] </ref>.
Reference: [McKeeman 65] <author> W. McKeeman. </author> <title> Peephole Optimization. </title> <journal> Communications of the ACM, </journal> <volume> 8(7) </volume> <pages> 443-444, </pages> <year> 1965. </year>
Reference-contexts: Also, because interprocedural analysis (Section B.1) is performed in the TWIF intermediate form, this phase assumes the task of resolving symbolic addresses of global variables and procedures as well. Along with this step we can perform peephole optimizations (e.g., <ref> [McKeeman 65] </ref>, [Lamb 81], and [Davidson 82]) to eliminate redundancy that may have been neglected 44 RELATED RESEARCH AND APPROACH OF THIS THESIS in earlier phases or may have arisen from the translation of macros and pseudo-instructions.
Reference: [Morel 79] <author> E. Morel and C. </author> <title> Renvoise. Global Optimization by Suppression of Partial Redundancies. </title> <journal> Communications of the ACM, </journal> <volume> 22(2) </volume> <pages> 96-103, </pages> <year> 1979. </year>
Reference-contexts: For example, subroutine calls take less space than in-line code, but are generally slower due to 26 INTRODUCTION call overheads. Other optimizations that have potential speed-size trade-offs include induction variable elimination (or strength reduction) [F Allen 72], loop unrolling [Lam 88], and partial redundancy elimination <ref> [Morel 79] </ref>. Where execution speed is not critical, minimizing the code size is usually profitable. <p> Because we may at best place n 3 immediately after n 1 or n 5 but not both, we must append a JMP instruction at the end of one of them, presumably the one that is executed less frequently. Like all transformations based on partial redundancy elimination <ref> [Morel 79] </ref> [Knoop 95], we need to account for not only the cost of the code for basic block n 5 , but also that of the additional JMP instructions required. <p> Partial redundancy elimination (see <ref> [Morel 79] </ref> and [Knoop 95]), which makes use of this information, can be readily applied to the mode variables.
Reference: [Motorola 90] <author> Motorola, Inc. </author> <title> DSP56000/DSP56001 Digital Signal Processor User's Manual, </title> <year> 1990. </year>
Reference-contexts: This is in contrast to RISC architectures, in which most operations involve general-purpose registers and these registers are usually interchangeable. It is also not unusual to find complex instructions in DSPs. Typical examples include add-with-shift (e.g., TMS320C25 ADD and ADDT) and multiply-add (e.g., DSP56000 MAC <ref> [Motorola 90] </ref>). Utilizing these instructions is essential to generating compact and efficient code. The conventional heuristic of breaking up a DAG into trees prohibits the use of these complex instructions in the case where internal vertices are shared. <p> We formulate this delayed storage allocation as the offset assignment problem. Although some modern DSP architectures permit increments and decrements of values other than one (e.g., Motorola DSP56000 <ref> [Motorola 90] </ref>), it is usually costly to use this feature if the modifier value is frequently changing.
Reference: [Papadimitriou 82] <author> C. H. Papadimitriou and K. Steiglitz. </author> <title> Combinatorial Optimization: Algorithms and Complexity. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1982. </year> <note> BIBLIOGRAPHY 209 </note>
Reference-contexts: It is trivial to show that the constraint matrix of this ILP is totally unimodular (Theorem 13.3 of <ref> [Papadimitriou 82] </ref>). A matrix whose entries are 1, 0, or 1, is said to to be totally unimodular if the determinant of every nonsingular square submatrix is 1 or 1.
Reference: [Paton 69] <author> K. Paton. </author> <title> An Algorithm for Finding a Fundamental Set of Cycles of a Graph. </title> <journal> Communications of the ACM, </journal> <volume> 12 </volume> <pages> 514-518, </pages> <year> 1969. </year>
Reference-contexts: A cycle basis can be generated in O (jVj (jEj jVj + 1)) time using depth-first search <ref> [Paton 69] </ref>. Constructing the set of all u-cycles in a DAG may potentially involve the enumeration of all (2 fl 1) combinations of cycles in the basis. However, in our context the sum of two u-cycles may not always be two u-cycles.
Reference: [Patterson 90] <author> D. A. Patterson and J. L. Hennessy. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, California, </address> <year> 1990. </year>
Reference-contexts: We now consider the quantitative impact of compression on performance. According to the 90/10 Locality Rule <ref> [Patterson 90, pages 11-12] </ref>, in a typical program 10% of its code accounts for most (about 90%) of the instructions executed at run-time.
Reference: [Paulin 94] <author> P. G. Paulin, C. Liem, T. C. May, and S. Sutarwala. CodeSyn: </author> <title> A Retar-getable Code Synthesis System. </title> <booktitle> In Proceedings of the 7th International High-Level Synthesis Workshop, </booktitle> <month> Spring </month> <year> 1994. </year>
Reference-contexts: However, there have been few convincing experimental 2.3 RESEARCH IN CODE GENERATION FOR EMBEDDED PROCESSORS 39 results thus far, and the authors of CHESS have not stated to what extent they have successfully retargeted their compiler. 2.3.3 FLEXWARE FLEXWARE consists of two components: a code generator CODESYN <ref> [Paulin 94] </ref> and an instruction-set simulator INSULIN [Sutarwala 93]. FLEXWARE is a tool-set developed in response to the results of the survey conducted by Paulin et al. regarding trends and requirements in DSP design environments [Paulin 95].
Reference: [Paulin 95] <author> P. G. Paulin, C. Liem, T. C. May, and S. Sutarwala. </author> <title> DSP Design Tool Requirements for Embedded Systems: A Telecommunications Industrial Perspective. </title> <journal> Journal of VLSI Signal Processing, </journal> 9(1/2):23-47, January 1995. 
Reference-contexts: Only the most time-critical tasks need to be implemented in hardware. Second, since embedded processors are field programmable, software design is more flexible than hardware design, and design errors, late specification and design changes, and product evolution can be accommodated more easily [Van Praet 94] <ref> [Paulin 95] </ref>. Moreover, various applications of the same genre may share the same hardware structure, with differences reflected in the software component, and it is possible to use the same mask for all of these applications. <p> compiler [Shipnes 94], which is used for the various members of the PowerPC family. 2.3 Research in Code Generation for Embedded Processors We have selected for review and critique three representative research projects in the area of code generation for embedded systems: MIMOLA [Marwedel 84], CHESS [Lanneer 95], and FLEXWARE <ref> [Paulin 95] </ref>. The proceedings of the Dagstuhl Workshop [Marwedel 95] contains a collection of papers documenting several other contributors' efforts. 2.3.1 MIMOLA The MIMOLA design system was originally conceived as a design environment for hardware structures, using the MIMOLA hardware description language [Zimmermann 79]. <p> FLEXWARE is a tool-set developed in response to the results of the survey conducted by Paulin et al. regarding trends and requirements in DSP design environments <ref> [Paulin 95] </ref>. In the code generation process of CODESYN, the source program is first translated into an intermediate form, called BDS (BNR Data Structure). The graph-rewrite phase transforms complex constructs (e.g., if-then-else) in the BDS into constructs available in the target machine.
Reference: [Quine 59] <author> W. V. O. Quine. </author> <title> On Cores and Prime Implicants of Truth Functions. </title> <journal> American Mathematics Monthly, </journal> <volume> 66 </volume> <pages> 755-760, </pages> <year> 1959. </year>
Reference-contexts: We can repeatedly remove 188 COVERING PROBLEMS essential columns, dominated rows, and dominated columns to arrive at a smaller matrix, called the cyclic core of the covering matrix <ref> [Quine 59] </ref>. A.2 Binate Covering As in unate covering, the binate covering problem is one of finding a minimum cost set of variables that satisfy a set of clauses.
Reference: [Rivest 78] <author> R. L. Rivest, A. Shamir, and L. M. Adleman. </author> <title> A Method for Obtaining Digital Signatures and Public-Key Cryptosystems. </title> <journal> Communications of the ACM, </journal> <volume> 21(2) </volume> <pages> 120-126, </pages> <year> 1978. </year> <note> See also U.S. Patent 4,405,829. Reference implementation available at ftp://ftp.rsa.com. </note>
Reference-contexts: Following them are procedures from the GNU gzip program: GENBITLEN through UNLZW. INITDES and UFCDOIT are two procedures in the GNU implementation of the DES encryption algorithm [DES 77]. Finally, MD5C and DECQUAN were taken from an implementation of the RSA cryptosystem <ref> [Rivest 78] </ref>. The column labeled jVj shows the number of variables, including compiler-generated temporaries, in the procedure. The next column, jEj, gives the number of edges in the initial access graph. It is easily seen that the access graphs are very sparse. <p> Finally, HILL, GNUCRYPT, and RSAREF are data encryption programs. HILL is an encryption scheme based on matrix multiplication. GNUCRYPT, from the GNU C Library, uses the data encryption standard (DES) [DES 77]. RSAREF is an implementation of the RSA public-key cryptosystem <ref> [Rivest 78] </ref>. We have performed the experiments varying the size of the pointer, P. Specifically, we used P = 1 and P = 2 for both methods, and we show the results in Tables 5.2 and 5.3 (pages 174-175).
Reference: [Rudell 89] <author> R. L. Rudell. </author> <title> Logic Synthesis for VLSI Design. </title> <type> PhD thesis, </type> <address> U. C. Berkeley, </address> <month> April </month> <year> 1989. </year> <note> Also ERL Memo 89/49. </note>
Reference-contexts: An alternative to tree covering is to tackle the DAG directly and formulate the DAG-covering problem as a binate covering problem <ref> [Rudell 89] </ref>, a special case of integer linear programming, and solve the problem exactly or heuristically using branch-and-bound methods. (Appendix A gives a brief review of the set covering and binate covering problems.) In the following sections we present a two-phase algorithm for code generation. <p> The purpose of the first phase of DAG covering is to discover complex patterns on the subject DAG, and the formulation is reminiscent of the binate covering formulation for technology mapping in <ref> [Rudell 89] </ref>. Given a set of patterns that correspond to machine instructions, a subject DAG corresponding to a basic block or a trace is to be covered using these patterns. Each pattern has an associated cost that reflects the cost of the corresponding instruction or instructions. <p> The first phase tackles the problem of selecting complex instructions, and the second phase solves the problem of scheduling and data transfers. The problem formulation for the first phase is similar to the DAG-covering formulation for technology mapping in <ref> [Rudell 89] </ref>. For the second phase we have presented a new theory of code generation for one-register machines. This new theory, also based on the binate covering problem, is more general than that of Aho et al. 92 CODE GENERATION [Aho 77] and encompasses a wider class of one-register machines. <p> Covering problems have also been extensively use in other areas of computer-aided design of digital circuits. For example, they appear in several stages of logic synthesis, including two-level logic minimization and DAG covering for technology mapping <ref> [Rudell 89] </ref>. Covering problems are well-known intractable problems and have received considerable attention from researchers. Exact solutions have been given in [Grasselli 65] and [Brayton 89] using branch-and-bound search. Heuristic methods have also been proposed, e.g., [Grasselli 65], [Gimpel 67], and [Rudell 89]. <p> two-level logic minimization and DAG covering for technology mapping <ref> [Rudell 89] </ref>. Covering problems are well-known intractable problems and have received considerable attention from researchers. Exact solutions have been given in [Grasselli 65] and [Brayton 89] using branch-and-bound search. Heuristic methods have also been proposed, e.g., [Grasselli 65], [Gimpel 67], and [Rudell 89]. Recently, Coudert and Madre discovered new pruning conditions that have substantially improved the efficiency of the search without compromising optimality [Coudert 95]. The resulting solver, called SCHERZO, is able to find exact solutions to difficult instances 10-100 times faster than earlier methods. <p> We can apply several reduction techniques to simplify a covering matrix. We will briefly describe the notions of essentiality and dominance. The reader is referred to [Gimpel 67] and <ref> [Rudell 89] </ref> for additional reduction techniques. A column j is essential if there exists some row i such that column j is the only column that covers row i.
Reference: [Ruf 95] <author> E. Ruf. </author> <title> Optimizing Sparse Representations for Dataflow Analysis. </title> <booktitle> In Proceedings of the ACM SIGPLAN Workshop on Intermediate Representations, </booktitle> <pages> pages 50-61, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: Chapter 3 Code Generation While several compiler researchers have proposed alternative program representations such as the program dependence graph (PDG) [Ferrante 87] and the value dependence graph (VDG) [Weise 94] <ref> [Ruf 95] </ref>, the most widely used representation of program structures to date has still been the control-flow graph. Although the PDG and the VDG provide more-powerful program analyses, it is relatively difficult to generate code from these representations and the incremental benefits they offer still remain to be realized.
Reference: [Sethi 70] <author> R. Sethi and J. Ullman. </author> <title> The Generation of Optimal Code for Arithmetic Expressions. </title> <journal> Journal of the ACM, </journal> <volume> 17(4) </volume> <pages> 715-728, </pages> <year> 1970. </year>
Reference-contexts: For example, Sethi and Ullman presented, for machines with uniform registers, an algorithm (the well-known SU-numbering algorithm) that uses the smallest number of registers to evaluate a tree <ref> [Sethi 70] </ref>.
Reference: [Shipnes 94] <author> J. Shipnes and M. Phillip. </author> <title> A Modular Approach to Motorola PowerPC Compilers. </title> <journal> Communications of the ACM, </journal> <volume> 37(6) </volume> <pages> 56-63, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: It uses a machine description that models pipelines and superscalar instruction issues, and schedules instructions accordingly to effectively utilize the features or to reduce conflicts. Other works on retargetable compilers include that of the PowerPC compiler <ref> [Shipnes 94] </ref>, which is used for the various members of the PowerPC family. 2.3 Research in Code Generation for Embedded Processors We have selected for review and critique three representative research projects in the area of code generation for embedded systems: MIMOLA [Marwedel 84], CHESS [Lanneer 95], and FLEXWARE [Paulin 95].
Reference: [Storer 82] <author> J. A. Storer and T. G. Szymanski. </author> <title> Data Compression via Textual Substitution. </title> <journal> Journal of the ACM, </journal> <volume> 29(4) </volume> <pages> 928-951, </pages> <month> October </month> <year> 1982. </year>
Reference-contexts: This scheme is similar to Fraser's procedural abstraction described in the previous section, and is based on a compression model called the external pointer macro (EPM) model <ref> [Storer 82] </ref>. In this model, compressed data consists of a dictionary and a skeleton. The dictionary contains substrings that occur frequently in the original data. <p> In the following sections we will present a framework in which such strategies can be utilized for code-size minimization, and a compression algorithm. 146 CODE COMPRESSION 5.3 Preliminaries 5.3.1 Data Compression We briefly review the basic terminology of the macro model of data compression, as defined in <ref> [Storer 82] </ref>. The source data is treated as a finite string over some alphabet. In the external pointer macro (EPM) model, the compressed form of the source data consists of a dictionary and a skeleton. The dictionary is a string. <p> A heuristic algorithm for generating a dictionary was presented in [Mayne 75]. Storer 5.3 PRELIMINARIES 147 and Szymanski showed that the problem of deciding whether the length of the shortest possible compressed form is less than k is NP-hard <ref> [Storer 82] </ref>. 5.3.2 Definitions, Conventions, and Assumptions Throughout this chapter we will model our system as a machine with a programmable processor, a program ROM, and some application-specific integrated circuit (ASIC).
Reference: [Sutarwala 93] <author> S. Sutarwala, P. G. Paulin, and Y. Kumar. Insulin: </author> <title> An Instruction Set Simulation Environment. </title> <booktitle> In Proceedings of the 1993 Conference on Hardware Description Languages, </booktitle> <pages> pages 355-362, </pages> <year> 1993. </year>
Reference-contexts: few convincing experimental 2.3 RESEARCH IN CODE GENERATION FOR EMBEDDED PROCESSORS 39 results thus far, and the authors of CHESS have not stated to what extent they have successfully retargeted their compiler. 2.3.3 FLEXWARE FLEXWARE consists of two components: a code generator CODESYN [Paulin 94] and an instruction-set simulator INSULIN <ref> [Sutarwala 93] </ref>. FLEXWARE is a tool-set developed in response to the results of the survey conducted by Paulin et al. regarding trends and requirements in DSP design environments [Paulin 95].
Reference: [TI 93] <institution> Texas Instruments. </institution> <note> TMS320C2x User's Guide, January 1993. Revision C. </note>
Reference-contexts: This will be discussed in detail in Section 3.4. We then propose extensions of this method to treat the mode optimization problem and multiple-register machines in Sections 3.5.1 and 3.5.2. 50 CODE GENERATION 3.2 Motivating Example TMS320C25 architecture <ref> [TI 93] </ref> for fixed-point digital signal processing. The TMS320-C25 is an accumulator-based machine. In addition to the usual arithmetic-logic unit (ALU), there is a separate multiplier which takes inputs from the T register and the memory, and places the result in the P register. <p> NOPs can be inserted so that the extended blocks will have this property. Although this may have an adverse effect on the dictionary size, it can potentially 158 CODE COMPRESSION result in greater compression. The exact trade-offs are dependent on the application itself. We use the TMS320C25 architecture <ref> [TI 93] </ref> to exemplify the method. The hardware modifications are shown in Figure 5-6 (for simplicity, much of the data-path is not shown). An S-R flip-flop, a counter, an AND gate, two OR gates, and a link register have been added to the base processor.
Reference: [Thomas 93] <author> D. E. Thomas, J. K. Adams, and H. </author> <title> Schmit. A Model and Methodology for Hardware-Software Codesign. </title> <booktitle> IEEE Design & Test of Computers, </booktitle> <pages> pages 6-15, </pages> <month> September </month> <year> 1993. </year> <note> 210 BIBLIOGRAPHY </note>
Reference-contexts: There have been proposals for the hardware-software co-design of digital systems (e.g., [Gupta 93], [Kalavade 93], and <ref> [Thomas 93] </ref>). The simplified view of a generic co-design methodology is shown in Figure 1-3. In this design flow, the designer first determines which parts of the functionality of the system will be implemented in hardware and which parts in software.
Reference: [Tiwari 94] <author> V. Tiwari, S. Malik, and A. Wolfe. </author> <title> Power Analysis of Embedded Software: </title>
Reference-contexts: As for power dissipation, we observe that code that executes more quickly also consumes less energy, and if we can lower the clock frequency while meeting throughput requirements, power dissipation diminishes as well. Although there has been work on code generation specifically for low power (e.g., <ref> [Tiwari 94] </ref>), we believe that performance is the main factor affecting power dissipation. Hence, we will focus our efforts on code size and performance. The traditional approach to high-quality embedded software has been to write the code in assembly language.
References-found: 90

