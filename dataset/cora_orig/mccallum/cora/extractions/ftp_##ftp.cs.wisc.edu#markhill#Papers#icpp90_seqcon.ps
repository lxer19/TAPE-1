URL: ftp://ftp.cs.wisc.edu/markhill/Papers/icpp90_seqcon.ps
Refering-URL: http://www.cs.wisc.edu/~markhill/
Root-URL: 
Title: Implementing Sequential Consistency In Cache-Based Systems  
Author: Sarita V. Adve Mark D. Hill 
Keyword: shared-memory multiprocessors, sequential consistency, strong ordering, cache coherence.  
Address: Madison, Wisconsin 53706  
Affiliation: Computer Sciences Department University of Wisconsin  
Note: To appear in the Proceedings of the 1990 International Conference on Parallel Processing  
Abstract: In this paper we show that both beliefs are false. First, we prove that (1) is false with a counter-example. Second, we argue that (2) is false by giving sufficient conditions and an implementation that allow a processor to have simultaneous incomplete shared-memory references. While we do not demonstrate that this implementation is superior, we do believe it is practical and worthy of consideration. 
Abstract-found: 1
Intro-found: 1
Reference: [AdH89] <author> S. V. Adve and M. D. Hill, </author> <title> Weak Ordering ANew Definition And Some Implications, </title> <type> Computer Sciences Technical Report #902, </type> <institution> University of Wisconsin, Madison, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: Along with condition 3b, this avoids the possibility of deadlock or the need to roll back. Based on the above reasoning, a proof of correctness of the conditions is given in <ref> [AdH89] </ref>. The proof is based on assigning unique hypothetical timestamps to each access in an execution. The timestamps are assigned so that an ordering of accesses in increasing order of their timestamps is consistent with the result of the execution and program order. This implies sequential consistency. 3.2. <p> When the directory (or memory) receives all the acknowledgements pertaining to a particular write, it is required to send its acknowledgement to the processor cache that issued the write. The implementation described below allows only one write miss of any given processor to be outstanding. In <ref> [AdH89] </ref>, we describe how more outstanding misses might be accommodated. Condition 1 of the algorithm is ensured directly by requiring a processor to issue accesses in program order. Condition 2 is satisfied due to the cache-coherence protocol.
Reference: [AdH90] <author> S. V. Adve and M. D. Hill, </author> <title> Weak Ordering ANew Definition, </title> <booktitle> To appear in the 17th Annual International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: Although our new conditions are less strict than the one-at-a-time approach, they still impose several restrictions on hardware. For higher performance, software support can be solicited <ref> [AdH90, DSB86, ShS88] </ref>.
Reference: [ASH88] <author> A. Agarwal, R. Simoni, M. Horowitz and J. Hennessy, </author> <title> An Evaluation of Directory Schemes for Cache Coherence, </title> <booktitle> Proc. 15th Annual International Symposium on Computer Architecture, </booktitle> <address> Honolulu, Hawaii, </address> <month> June </month> <year> 1988, </year> <pages> 280-289. </pages>
Reference-contexts: This implies sequential consistency. 3.2. Implementation This section discusses an implementation of the new conditions on a cache-coherent system with a general interconnect. A straightforward directory-based, write-back, invalidation cache-coherence protocol, - 3 - - -- similar to those discussed in <ref> [ASH88] </ref>, is assumed. Our protocol allows, however, a line requested by a write to be forwarded to the requesting processor in parallel with the sending of its corresponding invalidations. On receipt of an invalidation, a cache is required to return an acknowledgement message to the directory (or memory).
Reference: [ArB86] <author> J. Archibald and J. Baer, </author> <title> Cache Coherence Protocols: Evaluation Using a Multiprocessor Simulation Model, </title> <journal> ACM Transactions on Computer Systems 4, </journal> <month> 4 (November </month> <year> 1986), </year> <pages> 273-298. </pages>
Reference-contexts: For cache-based systems where processors are connected to memory through a common bus, most of the cache-coherence protocols proposed in the literature satisfy this condition <ref> [ArB86, RuS84] </ref>. The RP3 is a cache-based system that consists of a general interconnection network but does not support the caching of shared variables in hardware [BMW85]. Sequential consistency is maintained by stalling on every request to memory until an acknowledgement is obtained, again satisfying the one-at-a-time condition.
Reference: [BMW85] <author> W. C. Brantley, K. P. McAuliffe and J. Weiss, </author> <title> RP3 Process-Memory Element, </title> <booktitle> International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1985, </year> <pages> 772-781. </pages>
Reference-contexts: We first show that strong ordering, proposed by Dubois, Scheu-rich and Briggs [DSB86], is not equivalent to sequential consistency (Section 2). Next we introduce the second, common approach for implementing sequential consistency that requires processors to perform memory references ``one-at-a-time'' <ref> [BMW85, RuS84, ScD87] </ref>, and illustrate with sufficient conditions and an implementation proposal that this one-at-a-time approach is not necessary in practice (Section 3). 2. <p> The RP3 is a cache-based system that consists of a general interconnection network but does not support the caching of shared variables in hardware <ref> [BMW85] </ref>. Sequential consistency is maintained by stalling on every request to memory until an acknowledgement is obtained, again satisfying the one-at-a-time condition. For cache-based systems with general interconnects that allow shared variables to be cached, a cache-coherence protocol is not sufficient.
Reference: [DSB86] <author> M. Dubois, C. Scheurich and F. A. Briggs, </author> <title> Memory Access Buffering in Multiprocessors, </title> <booktitle> Proc. Thirteenth Annual International Symposium on Computer Architecture 14, </booktitle> <month> 2 (June </month> <year> 1986), </year> <pages> 434-442. </pages>
Reference-contexts: Unlike uniprocessor systems, simple interlock logic within a processor is not sufficient to ensure sequential consistency in multiprocessors. Particularly, as potential for parallelism increases, the conditions for ensuring sequential consistency become quite complex, and impose several restrictions on the hardware <ref> [DSB86] </ref>. This paper is concerned with the hardware implementation of sequential consistency, specifically for cache-based shared memory multiprocessors. We first show that strong ordering, proposed by Dubois, Scheu-rich and Briggs [DSB86], is not equivalent to sequential consistency (Section 2). <p> potential for parallelism increases, the conditions for ensuring sequential consistency become quite complex, and impose several restrictions on the hardware <ref> [DSB86] </ref>. This paper is concerned with the hardware implementation of sequential consistency, specifically for cache-based shared memory multiprocessors. We first show that strong ordering, proposed by Dubois, Scheu-rich and Briggs [DSB86], is not equivalent to sequential consistency (Section 2). <p> Strong Ordering Strong ordering was defined by Dubois, Scheu-rich and Briggs in <ref> [DSB86] </ref> as follows: In a multiprocessor system, storage accesses are strongly ordered if 1) accesses to global data by any one processor are initiated, issued and performed in program order, and if 2) at the time when a STORE - 1 - - -- on global data by processor I is <p> on global data by processor I is observed by processor K, all accesses to global data performed with respect to I before the issuing of the STORE must be performed with respect to K. 1 It was claimed earlier that a system that is strongly ordered is also sequentially consistent <ref> [DSB86, ScD87] </ref>. However, Figure 1 shows an execution that is not precluded by strong ordering, but violates sequential consistency. <p> Apparently for this reason, Scheurich introduces concurrent consistency for systems that are sequentially consistent ``except for programs which explicitly test for sequential consistency or take access timings into consideration'' [Sch89]. Without a formal characterization of these exceptions, however, it is difficult for hardware hhhhhhhhhhhhhhhhhh 1. Refer to <ref> [DSB86] </ref> for a precise definition of the terms issued, initiated, and performed. designers to determine whether an implementation is correct and what restrictions, if any, should be given to software. <p> Although our new conditions are less strict than the one-at-a-time approach, they still impose several restrictions on hardware. For higher performance, software support can be solicited <ref> [AdH90, DSB86, ShS88] </ref>.
Reference: [DuS89] <author> M. Dubois and C. Scheurich, </author> <title> Private Communication, </title> <month> November </month> <year> 1989. </year>
Reference-contexts: However, Figure 1 shows an execution that is not precluded by strong ordering, but violates sequential consistency. Thus, implementing strong ordering is not sufficient for implementing sequential consistency (confirmed by Dubois and Scheurich <ref> [DuS89] </ref>). hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh Initially X = Y = 0 in processor caches P 1 P 2 P 3 x 2 = X Y = 1 Result - x 2 = 1, y 2 = 0, x 3 = 0 Consider a cache-based system with a general interconnect.
Reference: [Lam79] <author> L. Lamport, </author> <title> How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs, </title> <journal> IEEE Trans. on Computers C-28, </journal> <month> 9 (September </month> <year> 1979), </year> <pages> 690-691. </pages>
Reference-contexts: 1. Introduction A model of memory for shared-memory MIMD multiprocessor systems commonly (and often implicitly) assumed by programmers is that of sequential consistency, formally defined by Lamport <ref> [Lam79] </ref> as follows: [Hardware is sequentially consistent if] the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order hhhhhhhhhhhhhhhhhh The material presented here is based
Reference: [RuS84] <author> L. Rudolph and Z. Segall, </author> <title> Dynamic Decentralized Cache Schemes for MIMD Parallel Processors, </title> <booktitle> Proc. Eleventh International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1984, </year> <pages> 340-347. </pages>
Reference-contexts: We first show that strong ordering, proposed by Dubois, Scheu-rich and Briggs [DSB86], is not equivalent to sequential consistency (Section 2). Next we introduce the second, common approach for implementing sequential consistency that requires processors to perform memory references ``one-at-a-time'' <ref> [BMW85, RuS84, ScD87] </ref>, and illustrate with sufficient conditions and an implementation proposal that this one-at-a-time approach is not necessary in practice (Section 3). 2. <p> For cache-based systems where processors are connected to memory through a common bus, most of the cache-coherence protocols proposed in the literature satisfy this condition <ref> [ArB86, RuS84] </ref>. The RP3 is a cache-based system that consists of a general interconnection network but does not support the caching of shared variables in hardware [BMW85]. Sequential consistency is maintained by stalling on every request to memory until an acknowledgement is obtained, again satisfying the one-at-a-time condition.
Reference: [ScD87] <author> C. Scheurich and M. Dubois, </author> <title> Correct Memory Operation of Cache-Based Multiprocessors, </title> <booktitle> Proc. Fourteenth Annual International Symposium on Computer Architecture, </booktitle> <address> Pittsburgh, PA, </address> <month> June </month> <year> 1987, </year> <pages> 234-243. </pages>
Reference-contexts: We first show that strong ordering, proposed by Dubois, Scheu-rich and Briggs [DSB86], is not equivalent to sequential consistency (Section 2). Next we introduce the second, common approach for implementing sequential consistency that requires processors to perform memory references ``one-at-a-time'' <ref> [BMW85, RuS84, ScD87] </ref>, and illustrate with sufficient conditions and an implementation proposal that this one-at-a-time approach is not necessary in practice (Section 3). 2. <p> on global data by processor I is observed by processor K, all accesses to global data performed with respect to I before the issuing of the STORE must be performed with respect to K. 1 It was claimed earlier that a system that is strongly ordered is also sequentially consistent <ref> [DSB86, ScD87] </ref>. However, Figure 1 shows an execution that is not precluded by strong ordering, but violates sequential consistency. <p> For cache-based systems with general interconnects that allow shared variables to be cached, a cache-coherence protocol is not sufficient. Scheurich and Dubois first proposed a sufficient condition for ensuring sequential consistency in such systems <ref> [ScD87, Sch89] </ref>. The condition is satisfied if all processors issue their accesses in program order, and no access is issued by a processor until its previous access is globally performed. <p> Condition 3 states when a processor has to stall because of its own incomplete accesses. Thus, a processor cannot proceed after issuing a read until a return value is bound to the read and all other processors have observed this value. (This restriction is similar to that in <ref> [ScD87, Sch89] </ref> and we do not have any optimizations for it.) A processor cannot proceed after issuing a write until it has the permission to write the line requested. A violation of this condition could lead to deadlock or necessitate rollback.
Reference: [Sch89] <author> C. E. Scheurich, </author> <title> Access Ordering and Coherence in Shared Memory Multiprocessors, </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Engineering, </institution> <type> Technical Report CENG 89-19, </type> <institution> University of Southern California, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: Apparently for this reason, Scheurich introduces concurrent consistency for systems that are sequentially consistent ``except for programs which explicitly test for sequential consistency or take access timings into consideration'' <ref> [Sch89] </ref>. Without a formal characterization of these exceptions, however, it is difficult for hardware hhhhhhhhhhhhhhhhhh 1. Refer to [DSB86] for a precise definition of the terms issued, initiated, and performed. designers to determine whether an implementation is correct and what restrictions, if any, should be given to software. <p> For cache-based systems with general interconnects that allow shared variables to be cached, a cache-coherence protocol is not sufficient. Scheurich and Dubois first proposed a sufficient condition for ensuring sequential consistency in such systems <ref> [ScD87, Sch89] </ref>. The condition is satisfied if all processors issue their accesses in program order, and no access is issued by a processor until its previous access is globally performed. <p> Consider a system with an invalidation-based cache coherence protocol. A write miss to a line in read-only state is globally performed only when all the read-only copies have been invalidated. Scheurich <ref> [Sch89] </ref> observes that sequential consistency will be maintained even if a processor begins its next reference as soon as the invalidations are buffered at all other processors, provided other processors process buffered invalidations before handling a cache miss. <p> Condition 3 states when a processor has to stall because of its own incomplete accesses. Thus, a processor cannot proceed after issuing a read until a return value is bound to the read and all other processors have observed this value. (This restriction is similar to that in <ref> [ScD87, Sch89] </ref> and we do not have any optimizations for it.) A processor cannot proceed after issuing a write until it has the permission to write the line requested. A violation of this condition could lead to deadlock or necessitate rollback.
Reference: [ShS88] <author> D. Shasha and M. Snir, </author> <title> Efficient and Correct Execution of Parallel Programs that Share Memory, </title> <journal> ACM Trans. on Programming Languages and Systems 10, </journal> <month> 2 (April </month> <year> 1988), </year> <pages> 282-312. - 5 </pages> - 
Reference-contexts: Although our new conditions are less strict than the one-at-a-time approach, they still impose several restrictions on hardware. For higher performance, software support can be solicited <ref> [AdH90, DSB86, ShS88] </ref>.
References-found: 12

