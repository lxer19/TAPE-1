URL: http://www.cs.toronto.edu/~wayne/research/net/shep.ps.gz
Refering-URL: http://www.cs.toronto.edu/~wayne/research/net/net.html
Root-URL: 
Email: Internet: wayne@cs.utoronto.ca  
Phone: Phone: 416/978-7321, FAX: 416/978-4765,  Phone: 909/787-7354, FAX: 909/787-4643,  
Title: Solving Capture in Switched Two-Node Ethernets by Changing Only One Node  
Author: Wayne Hayes Mart L. Molle 
Date: 1995 Oct 17-18.  
Note: Internet: mart@cs.ucr.edu To appear in Proceedings of the 20th Annual Conference on Local Computer Networks, Minneapolis, Minn.  
Address: Toronto, Toronto, Canada, M5S 1A4.  Riverside CA, 92521-0304  
Affiliation: Department of Computer Science University of  Computer Science Department University of California,  
Abstract: It is well known that the Ethernet medium access control protocol can cause significant short-term unfairness through a mechanism known as the Capture Effect, and that this unfairness condition is worst in heavily loaded Ethernets with a small number of active nodes. Recently, Ramakrishnan and Yang proposed Capture Avoidance Binary Exponential Back-off (CABEB) to provide 1-packet-per-turn round robin service in the important special case of a 2-node collision domain. In this paper, we introduce an equal time round-robin scheme, in which only one node needs to be modified. In our scheme, the modified node maintains a local copy of the attempts counter of the other node. It uses this information to trigger switching its medium access policy between the two extremes of aggressively persistent and completely passive. As a result, the modified node can control the actions of the other node in such a way that both enjoy fair, low delay, round-robin access to the shared channel. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> "Carrier Sense Multiple Access with Collision Detection (CSMA/CD)". </institution> <address> IEEE Std 802.3-1990 Edition (ISO/DIS 8802-3), </address> <publisher> IEEE, </publisher> <address> New York (1990). </address>
Reference-contexts: Our finite state machine has been written to precisely conform to the IEEE 802.3 Ethernet Medium Access Layer <ref> [1] </ref> down to the bit level | including all the details of inter-frame spacing, preamble, Start Frame Delimiter, header and packet size limits.
Reference: [2] <author> D. R. Boggs, J. C. Mogul, and C. A. Kent. </author> <title> "Measured Capacity of an Ethernet: Myths and Reality". </title> <booktitle> ACM SIGCOMM '88 on Communications Architectures & Protocols, </booktitle> <pages> pp. </pages> <month> 222-234 (Aug. </month> <pages> 16-19, </pages> <year> 1988). </year>
Reference-contexts: However, there is no long term unfairness problem: L's first packet may experience a huge access delay, but thereafter L, too, transmits many packets with essentially zero delay. Boggs, Mogul, and Kent <ref> [2] </ref> devised and ran several experiments that massively overloaded an Ethernet. The Capture Effect was not visible in their measurements because they only reported the mean time between a packet getting to the front of its local queue and the time it is transmitted, i.e., the access time. <p> We validated our simulator by reproducing the setup of a famous and widely-distributed experiment on a real Ethernet by Boggs, Mogul, and Kent <ref> [2] </ref>, and getting identical results in all measurements, within statistical uncertainties. See Molle [6] for a direct comparison of the published measurements by Boggs et al. with our simulation output. In addition, we have taken packet traces of a local undergraduate computing facility. <p> We did simulations duplicating the experiments of Boggs et al. <ref> [2] </ref>, including varying the number of nodes running standard Ethernet protocol while validating our simulator. Our results accurately duplicated all their measures within statistical uncertainties.
Reference: [3] <author> Bruce W. Char. </author> <title> Maple user's guide. </title> <address> WATCOM, Waterloo, Ontario, Canada. </address> <year> (1985) </year>
Reference-contexts: Traces were taken intermittently over many weeks using the tcpdump program, tuned for low processing overhead. Usages on the network varied from the facility full of students doing programming assignments, to having 35 remote Matlabs [5] and Xmaples <ref> [3] </ref> on the compute server, to days of many students playing Xtrek and NetTrek games. The average packet size was usually about 140 bytes, roughly bimodal between the smallest and largest packet sizes.
Reference: [4] <author> Al Geist, Adam Beguelin, Jack Dongarra, We-icheng Jiang, Robert Manchek, Vaidy Sun-deram. </author> <title> PVM: Parallel Virtual Machine:A Users' Guide and Tutorial for Network Parallel Computing. </title> <note> Available via anonymous ftp from netlib2.cs.utk.edu:/pvm3/book/pvm-book.ps. </note>
Reference-contexts: Student home directories are on the file server, accessed via NFS. Typical traffic on the network consists of NFS accesses, remote interactive logins, remote X-Window traffic, and occasional distributed ray tracing using PVM <ref> [4] </ref>. Traces were taken intermittently over many weeks using the tcpdump program, tuned for low processing overhead.
Reference: [5] <author> MATLAB, </author> <title> high-performance numeric computation and visualization software : user's guide : for UNIX workstations. MathWorks, </title> <address> Natick, Mass. </address> <year> (1992) </year>
Reference-contexts: Traces were taken intermittently over many weeks using the tcpdump program, tuned for low processing overhead. Usages on the network varied from the facility full of students doing programming assignments, to having 35 remote Matlabs <ref> [5] </ref> and Xmaples [3] on the compute server, to days of many students playing Xtrek and NetTrek games. The average packet size was usually about 140 bytes, roughly bimodal between the smallest and largest packet sizes.
Reference: [6] <author> Mart L. Molle. </author> <title> "A New Binary Logarithmic Arbitration Method for Ethernet". </title> <type> Technical Report CSRI-298, </type> <note> available by ftp from ftp.cs.utoronto.ca. </note> <month> (July </month> <year> 1994) </year>
Reference-contexts: As a result, we now know that heavily loaded Ethernets are generally stable, but can exhibit severe short-term unfairness as one busy node [10] (or a small group of busy nodes, if each one is too slow to saturate the network by itself <ref> [6] </ref>) "captures" complete control of the network for considerable periods of time. Omitting inessential details, the Ethernet medium access control protocol is summarized in Figure 1. <p> We validated our simulator by reproducing the setup of a famous and widely-distributed experiment on a real Ethernet by Boggs, Mogul, and Kent [2], and getting identical results in all measurements, within statistical uncertainties. See Molle <ref> [6] </ref> for a direct comparison of the published measurements by Boggs et al. with our simulation output. In addition, we have taken packet traces of a local undergraduate computing facility. For each packet, we recorded the inter-arrival time (to the nearest microsecond), size (in bytes), source and destination addresses. <p> Consequently, they end up backing off too far and too quickly whenever congestion occurs, which leads to the Capture Effect. Although other solutions to the Capture Effect have been proposed <ref> [6, 8] </ref>, one must install the modification in all nodes of the network to obtain their full benefit. <p> the end of this packet and proceed to Step 6. 1 In the unlikely event that S somehow doesn't transmit the packet, this step of the SHEP protocol should implement some sort of timeout. 2 We used twice the 96 bit-time inter-packet gap as our grace period, as does Molle <ref> [6] </ref>. 4 2.3 Discussion Some qualitative observations of this protocol exhibit some of its properties. First, there is the obvious fairness of an equal-time round-robin service schedule. <p> We did simulations duplicating the experiments of Boggs et al. [2], including varying the number of nodes running standard Ethernet protocol while validating our simulator. Our results accurately duplicated all their measures within statistical uncertainties. More validation details can be found in Molle <ref> [6] </ref>, which used the same Smurph finite state machine for its standard Ethernet as was used for SHEP results. <p> See Molle <ref> [6] </ref> for a protocol which allows good fairness effects for more than 2 nodes.
Reference: [7] <author> P. Gburzynski and P. Rudnicki. </author> <title> The SMURPH Protocol Modelling Environment. </title> <institution> Department of Computing Science, University of Alberta, Ed-monton, Canada. </institution> <month> (October </month> <year> 1991). </year> <note> The author may be contacted as pawel@cs.ualberta.ca. </note>
Reference-contexts: We chose simulation over direct experimentation because we did not have the means to construct hardware prototypes incorporating our proposed changes to the medium access control protocol. Our simulator was written using a package called the Smurph Protocol Modelling Environment <ref> [7] </ref>. Smurph was designed specifically to allow easy implementation and testing of MAC layer protocols, by conveniently handling all details of the physical layer. Smurph allows realistic topologies to be defined, and can simulate many properties of real-world systems, like clock drift and physical layer noise. <p> third choice, as do all simulations reported in this paper. 3 Note that although 72-byte packets are common on modern networks, they are not common enough to come in long back-to-back streams that would saturate a 2-node network. 3 Simulation results 3.1 Poisson traffic We ran thousands of long Smurph <ref> [7] </ref> simulations of two-node systems consuming several CPU-years on a collection of 70 SPARCstation IPCs. We did simulations duplicating the experiments of Boggs et al. [2], including varying the number of nodes running standard Ethernet protocol while validating our simulator. Our results accurately duplicated all their measures within statistical uncertainties.
Reference: [8] <author> K. K. Ramakrishnan and Henry Yang. </author> <title> "The Ethernet Capture Effect: Analysis and Solution". </title> <booktitle> Proc. 19th Conference on Local Computer Networks, </booktitle> <address> Minneapolis Minn, </address> <month> October </month> <year> 1994, </year> <month> pp.228-240. </month>
Reference-contexts: Consequently, they end up backing off too far and too quickly whenever congestion occurs, which leads to the Capture Effect. Although other solutions to the Capture Effect have been proposed <ref> [6, 8] </ref>, one must install the modification in all nodes of the network to obtain their full benefit. <p> This backwards compat-ibility is a significant advantage for our proposal in comparison to the Capture Avoidance Binary Exponential Backoff algorithm <ref> [8] </ref> (and even to Full-Duplex Ethernet), which gives little (or no) benefit without updating both ends of the link. SHEP fulfills these requirements by following a strategy somewhat analogous to a trial judge having a discussion with a rude lawyer who incessantly interrupts the judge. <p> This is because our experiments have shown that modifying SHEP to SHEP.5 is a poor compromise: using SHEP.5 instead of SHEP in combination with a standard Ethernet node hurts performance, whereas if both nodes can be non-standard then better performance is available using other protocols, such as CABEB <ref> [8] </ref>, that are specifically optimized for 2-node co-operation. 3.2 Packet trace driven traffic 3.2.1 Packet trace environment The traces were taken on the University of Toronto's Undergraduate Computing Disciplines Facility (CDF), which consists of two separate Ethernets on two floors. <p> only two non-negligible quantitative changes are that both run length curves (Figure 8) slope down, and the access delay standard deviations (Figure 11) reach a little higher to about 0.8ms at the highest loads. 4 Comparison with CABEB Last year, Ramakrishnan and Yang introduced the Capture Avoidance Binary Exponential Backoff <ref> [8] </ref>. The most obvious and important difference from CABEB is that SHEP requires only one node be changed. Referring to Tables 6.1 through 6.3 of [8], if a similar update is attempted with CABEB, the CABEB node gains a significant throughput advantage against the standard node. <p> little higher to about 0.8ms at the highest loads. 4 Comparison with CABEB Last year, Ramakrishnan and Yang introduced the Capture Avoidance Binary Exponential Backoff <ref> [8] </ref>. The most obvious and important difference from CABEB is that SHEP requires only one node be changed. Referring to Tables 6.1 through 6.3 of [8], if a similar update is attempted with CABEB, the CABEB node gains a significant throughput advantage against the standard node. With 64 byte packets, the CABEB node gets a throughput of 4.1 vs. 3.5 Mb/s for the standard node.
Reference: [9] <author> S. Salamone, </author> <title> "Ethernet Networking|Switching Hubs Get Their Due". BYTE, </title> <editor> 19:6, p. </editor> <volume> 28. </volume> <year> (1994) </year>
Reference-contexts: An inexpensive way to increase the network bandwidth available to all nodes, while preserving the investment in existing Ethernet equipment, is to segment the network into smaller and smaller collision domains until, in the limit, we have a switched Ethernet system <ref> [9] </ref>. Here each node has a direct connection to a switch port, so that each collision domain consists of only two nodes: the attached user device and its associated switch port.
Reference: [10] <author> S. Shenker. </author> <title> "Some Conjectures on the Behavior of Acknowledgement-Based Transmission Control of Random Access Communications Channels". </title> <booktitle> ACM SIGMETRICS '87 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pp. </pages> <month> 245-255 (May </month> <year> 1987). </year> <month> 9 </month>
Reference-contexts: As a result, we now know that heavily loaded Ethernets are generally stable, but can exhibit severe short-term unfairness as one busy node <ref> [10] </ref> (or a small group of busy nodes, if each one is too slow to saturate the network by itself [6]) "captures" complete control of the network for considerable periods of time. Omitting inessential details, the Ethernet medium access control protocol is summarized in Figure 1.
References-found: 10

