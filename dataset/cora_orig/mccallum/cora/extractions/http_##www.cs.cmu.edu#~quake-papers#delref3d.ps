URL: http://www.cs.cmu.edu/~quake-papers/delref3d.ps
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/project/quake/public/www/papers.html
Root-URL: 
Email: jrs@cs.cmu.edu  
Title: Tetrahedral Mesh Generation by Delaunay Refinement  
Author: Jonathan Richard Shewchuk 
Address: Pittsburgh, Pennsylvania 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: Given a complex of vertices, constraining segments, and planar straight-line constraining facets in E 3 , with no input angle less than 90 ffi , an algorithm presented herein can generate a conforming mesh of Delaunay tetrahedra whose circumradius-to-shortest edge ratios are no greater than two. The sizes of the tetrahedra can provably grade from small to large over a relatively short distance. An implementation demonstrates that the algorithm generates excellent meshes, generally surpassing the theoretical bounds, and is effective in eliminating tetrahedra with small or large dihedral angles, although they are not all covered by the theoretical guarantee. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adrian Bowyer. </author> <title> Computing Dirichlet Tessellations. </title> <journal> Com puter Journal 24(2):162166, </journal> <year> 1981. </year>
Reference-contexts: The De-launay property is maintained, perhaps by the Bowyer/Watson algorithm for the incremental update of Delaunay triangulations <ref> [1, 16] </ref>. The poor simplex cannot survive, because its circumsphere is no longer empty. For brevity, the act of inserting a vertex at a simplex's circumcenter is called splitting a simplex. <p> Figure 10 illustrates the notion in two dimensions (with no facets) by giving examples of such balls for a variety of points. The function lfs () is continuous and has the property that its directional derivatives (where they exist) are bounded in the range <ref> [1; 1] </ref>, as the following lemma shows. This property sets a lower bound (within a constant factor to be derived shortly) on the rate at which edge lengths grade from small to large as one moves away from a small feature.
Reference: [2] <author> L. Paul Chew. </author> <title> Guaranteed-Quality Triangular Meshes. </title> <type> Tech nical Report TR-89-983, </type> <institution> Department of Computer Science, Cornell University, </institution> <year> 1989. </year> <title> [3] . Guaranteed-Quality Mesh Generation for Curved Surfaces. </title> <booktitle> Proceedings of the Ninth Annual Symposium on Computational Geometry, </booktitle> <pages> pages 274280. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1993. </year> <title> [4] . Guaranteed-Quality Delaunay Meshing in 3D. </title> <booktitle> Pro ceedings of the Thirteenth Annual Symposium on Computational Geometry, </booktitle> <pages> pages 391393. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1997. </year>
Reference-contexts: The first provably good Delaunay refinement algorithm is due to Paul Chew <ref> [2] </ref>, and takes as its input a set of vertices and segments that define the region to be meshed. By inserting additional vertices, Chew's algorithm generates a two-dimensional constrained Delaunay triangulation whose angles are bounded between 30 ffi and 120 ffi . <p> Ruppert's Delaunay refinement algorithm [13] employs a bound of B = 2, and Chew's second Delaunay refinement algorithm [3] employs a bound of B = 1. Chew's first Delaunay refinement algorithm <ref> [2] </ref> splits any triangle whose circumradius is greater than the length of the shortest edge in the entire mesh, thus achieving a bound of B = 1, but forcing all triangles to have uniform size.
Reference: [5] <author> Tamal Krishna Dey, Chanderjit L. Bajaj, and Kokichi Sugi hara. </author> <title> On Good Triangulations in Three Dimensions. </title> <journal> International Journal of Computational Geometry & Applications 2(1):7595, </journal> <year> 1992. </year>
Reference-contexts: By inserting additional vertices, Chew's algorithm generates a two-dimensional constrained Delaunay triangulation whose angles are bounded between 30 ffi and 120 ffi . Dey, Bajaj, and Sug-ihara <ref> [5] </ref> and Chew [4] generalize Chew's algorithm to three dimensions, but only for unconstrained point set inputs. All three algorithms produce uniform meshes, whose triangles or tetrahedra are of roughly the same size.
Reference: [6] <author> Lori A. Freitag and Carl Ollivier-Gooch. </author> <title> A Comparison of Tetrahedral Mesh Improvement Techniques. </title> <booktitle> Fifth International Meshing Roundtable (Pittsburgh, Pennsylvania), </booktitle> <pages> pages 87100. </pages> <institution> Sandia National Laboratories, </institution> <month> October </month> <year> 1996. </year>
Reference-contexts: Meshes with bounds on the circumradius-to-shortest edge ratios of their tetrahedra are an excellent starting point for mesh smoothing and optimization methods that remove slivers and otherwise improve the quality of an existing mesh <ref> [6] </ref>.
Reference: [7] <author> William H. Frey. </author> <title> Selective Refinement: A New Strategy for Automatic Node Placement in Graded Triangular Meshes. </title> <note> International Journal for Numerical Methods in Engineering 24(11):21832200, </note> <month> November </month> <year> 1987. </year>
Reference-contexts: It is difficult to trace who first used Delaunay triangulations for finite element meshing, and equally difficult to tell where the suggestion arose to use the triangulation to guide vertex creation. These ideas have been intensively studied in the engineering community since the mid-1980s; for instance, Frey <ref> [7] </ref> eliminates poorly shaped triangles from a triangulation by inserting new vertices at their circumcenters (defined in Section 2), whereas Weatherill [17] inserts new vertices at their centroids.
Reference: [8] <author> Charles L. Lawson. </author> <title> Software for C 1 Surface Interpolation. Mathematical Software III (John R. Rice, </title> <booktitle> editor), </booktitle> <pages> pages 161 194. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: Delaunay triangulations have been extensively studied, and good algorithms are available. Inserting a vertex is a local operation, and is inexpensive except in unusual cases. In two dimensions, Delaunay triangulations maximize the minimum angle, compared with all other triangulations of the same vertex set <ref> [8] </ref>. The greatest advantage of Delaunay triangulations is less obvious. The central question of any Delaunay refinement algorithm is where should the next vertex be inserted? As Section 3 will demonstrate, a reasonable answer is as far from other vertices as possible.
Reference: [9] <author> Gary L. Miller, Dafna Talmor, Shang-Hua Teng, and Noel Walkington. </author> <title> A Delaunay Based Numerical Method for Three Dimensions: Generation, Formulation, and Partition. </title> <booktitle> Proceedings of the Twenty-Seventh Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 683692, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: As a result, the present algorithm typically uses fewer vertices by several orders of magnitude; details are provided elsewhere [14]. 2 A Quality Measure for Simplices Miller, Talmor, Teng, and Walkington <ref> [9] </ref> have pointed out that the most natural and elegant measure for analyzing Delaunay refinement algorithms is the circumradius-to-shortest edge ratio of a triangle or tetrahedron. The circumsphere of a simplex is the unique circle or sphere that passes through all its vertices. <p> Even if slivers are not removed, the Voronoi dual of a tetrahedraliza-tion with bounded circumradius-to-shortest edge ratios has nicely rounded cells, and is sometimes ideal for use in the control volume method <ref> [9] </ref>. 3 The Key Idea Behind Delaunay Refinement The central operation of Chew's, Ruppert's, Dey's, and my own Delaunay refinement algorithms is the insertion of a vertex at the circumcenter of a triangle or tetrahedron of poor quality.
Reference: [10] <author> Gary L. Miller, Dafna Talmor, Shang-Hua Teng, Noel Walk ington, and Han Wang. </author> <title> Control Volume Meshes using Sphere Packing: Generation, Refinement and Coarsening. </title> <booktitle> Fifth International Meshing Roundtable, </booktitle> <pages> pages 4761, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: The octree-based algorithm of Mitchell and Vavasis [11, 12] is a theoretical tour de force, obtaining provable bounds on dihedral angles and grading, but its bounds are too weak to offer any practical reassurance (and have not been explicitly stated). An algorithm by Miller, Talmor, Teng, Walkington, and Wang <ref> [10] </ref> generates its final vertex set before triangulating it. Their algorithm has provable bounds similar to those of the algorithm described herein, but the algorithm herein has the opportunity to stop early if fewer vertices are needed than the theory suggests. <p> Delaunay refinement algorithms, including those of Chew, Ruppert, and Dey et al., are distinguished primarily by how they handle boundaries. 4 Piecewise Linear Complexes The input upon which my three-dimensional Delaunay refinement algorithm operates is called a piecewise linear complex (PLC). See Miller, Talmor, Teng, Walkington, and Wang <ref> [10] </ref> for a definition in E . In three dimensions, a PLC is a set of vertices, segments, and facets. A segment is a constraining edge that must be represented by a sequence of contiguous edges in the final mesh. <p> This slack accumulates as one traces a sequence of descendants from an input vertex, and makes it possible to achieve better bounds on tetrahedron quality and edge length than the theory promises. (Miller et al. <ref> [10] </ref> cannot exploit this slack, and thus require about 8,000 times as many vertices to guarantee a bound of B = 2:5 on the PLC in Figure 13). The main outstanding problem in three-dimensional Delaunay refinement is the question of how best to handle small input angles.
Reference: [11] <author> Scott A. Mitchell and Stephen A. Vavasis. </author> <title> Quality Mesh Generation in Three Dimensions. </title> <booktitle> Proceedings of the Eighth Annual Symposium on Computational Geometry, </booktitle> <pages> pages 212 221, </pages> <year> 1992. </year> <title> [12] . Quality Mesh Generation in Higher Dimensions. </title> <note> Submitted to SIAM Journal on Computing, </note> <month> February </month> <year> 1997. </year>
Reference-contexts: Two other tetrahedral mesh generation algorithms (not based on Delaunay refinement) have provable bounds. The octree-based algorithm of Mitchell and Vavasis <ref> [11, 12] </ref> is a theoretical tour de force, obtaining provable bounds on dihedral angles and grading, but its bounds are too weak to offer any practical reassurance (and have not been explicitly stated). <p> Because this distance may be arbitrarily small, the algorithm is not size-optimal. However, if guaranteed bounds could be established for the dihedral angles, and not merely the circumradius-to-shortest edge ratios, then size-optimality might be proven using ideas like those with which Mitchell and Vavasis <ref> [11, 12] </ref> demonstrate the size-optimality of their octree-based algorithms. Many theoretical improvements can be made to the core algorithm described here.
Reference: [13] <author> Jim Ruppert. </author> <title> A Delaunay Refinement Algorithm for Qual ity 2-Dimensional Mesh Generation. </title> <journal> Journal of Algorithms 18(3):548585, </journal> <month> May </month> <year> 1995. </year>
Reference-contexts: All three algorithms produce uniform meshes, whose triangles or tetrahedra are of roughly the same size. Uniform meshes sometimes have many more triangles or tetrahedra than are necessary, and thus impose an excessive computational load upon the applications that make use of them. Jim Rup-pert <ref> [13] </ref> and Paul Chew [3] have each proposed two-dimensional Delaunay refinement algorithms that produce meshes of well-shaped triangles whose sizes are graded, and Ruppert has furthermore proven that his algorithm produces meshes that are nicely graded in a theoretical sense described in Section 7. <p> Because t has a circumradius-to-shortest edge ratio larger than B, every new edge has length at least B times that of the shortest edge of t. Ruppert's Delaunay refinement algorithm <ref> [13] </ref> employs a bound of B = 2, and Chew's second Delaunay refinement algorithm [3] employs a bound of B = 1. <p> In this example, all equatorial spheres (included the two illustrated) are empty after the split. (c) Splitting a skinny tetrahedron. * The diametral sphere of a subsegment is the (unique) small est sphere that encloses the subsegment. Following Rup-pert <ref> [13] </ref>, a subsegment is said to be encroached if a vertex other than its endpoints lies inside or on its diametral sphere. A subsegment may be encroached whether or not it actually appears as an edge of the tetrahedralization. <p> This property sets a lower bound (within a constant factor to be derived shortly) on the rate at which edge lengths grade from small to large as one moves away from a small feature. Lemma 2 (Ruppert <ref> [13] </ref>) For any PLC X, and any two points u and v, lfs (v) lfs (u) + juvj. Proof: The ball having radius lfs (u) centered at u intersects two nonincident features of X. <p> maxfD T ; D F g D S : (3) If the quality bound B is strictly larger than 2, Inequalities 1, 2, and 3 are simultaneously satisfied by choosing D T = p B 2 (1 + 2)B + 2 ; (3 + 2)B : ffi Theorem 6 (Ruppert <ref> [13] </ref>) For any vertex v of the output mesh, the distance to its nearest neighbor w is at least lfs (v) Proof: Inequality 3 indicates that D S is larger than D T and D F , so Theorem 5 shows that lfs (v) D S for any vertex v. <p> A few other tricks are needed to ensure that all segments and facets are recovered: segments are recovered by using a technique based on concentric spherical shells suggested by Ruppert <ref> [13] </ref>, then facets are recovered by forming a constrained Delaunay tetrahedralization [15]. The reason why a size-optimality result cannot be established is worth exploring. Gary Miller and Dafna Talmor (private communication) have pointed out the counterexample depicted in Figure 16.
Reference: [14] <author> Jonathan Richard Shewchuk. </author> <title> Delaunay Refinement Mesh Generation. </title> <type> Ph.D. thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, </institution> <month> May </month> <year> 1997. </year> <title> Available as Technical Report CMU-CS-97-137. [15] . A Condition Guaranteeing the Existence of Higher Dimensional Constrained Delaunay Triangulations. </title> <booktitle> This proceedings, </booktitle> <month> June </month> <year> 1998. </year>
Reference-contexts: As a result, the present algorithm typically uses fewer vertices by several orders of magnitude; details are provided elsewhere <ref> [14] </ref>. 2 A Quality Measure for Simplices Miller, Talmor, Teng, and Walkington [9] have pointed out that the most natural and elegant measure for analyzing Delaunay refinement algorithms is the circumradius-to-shortest edge ratio of a triangle or tetrahedron. <p> The projection condition can be somewhat weakened; for example, a 60 ffi separation between incident segments suffices. All these improvements are described in detail elsewhere <ref> [14] </ref>. The improvements in circumradius-to-shortest edge ratio, in particular, are significant and further propel the approach described here beyond the pioneering tetrahedral mesh generation algorithms of Dey et al., Chew, and Miller et al.
Reference: [16] <author> David F. Watson. </author> <title> Computing the n-dimensional Delaunay Tessellation with Application to Voronoi Polytopes. </title> <journal> Computer Journal 24(2):167172, </journal> <year> 1981. </year>
Reference-contexts: The De-launay property is maintained, perhaps by the Bowyer/Watson algorithm for the incremental update of Delaunay triangulations <ref> [1, 16] </ref>. The poor simplex cannot survive, because its circumsphere is no longer empty. For brevity, the act of inserting a vertex at a simplex's circumcenter is called splitting a simplex.
Reference: [17] <author> Nigel P. Weatherill. </author> <title> Delaunay Triangulation in Computa tional Fluid Dynamics. </title> <journal> Computers and Mathematics with Applications 24(5/6):129150, </journal> <month> September </month> <year> 1992. </year>
Reference-contexts: These ideas have been intensively studied in the engineering community since the mid-1980s; for instance, Frey [7] eliminates poorly shaped triangles from a triangulation by inserting new vertices at their circumcenters (defined in Section 2), whereas Weatherill <ref> [17] </ref> inserts new vertices at their centroids.
References-found: 13

