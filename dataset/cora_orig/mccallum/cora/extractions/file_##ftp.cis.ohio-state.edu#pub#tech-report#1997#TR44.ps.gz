URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1997/TR44.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Email: E-mail: fgcao, singhalg@cis.ohio-state.edu  
Title: On Consistent Checkpointing in Distributed Systems  
Author: Guohong Cao, Mukesh Singhal 
Keyword: Key words: Distributed system, consistent checkpointing, dependency, non-blocking.  
Address: Columbus, OH 43201  
Affiliation: Department of Computer and Information Science The Ohio State University  
Abstract: Consistent checkpointing simplifies failure recovery and eliminates the domino effect in case of failure by preserving a consistent global checkpoint on the stable storage. However, the approach suffers from high overhead associated with the checkpointing process. Two approaches are used to reduce the overhead: one is to minimize the number of synchronization messages and the number of checkpoints; the other is to make the checkpointing process non-blocking. These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm [17] combined them. In other words, the Prakash-Singhal algorithm forces only a minimum number of processes to take checkpoints, and it does not block the underlying computation. In this paper, we identify two problems in their algorithm [17] and prove that there does not exist a non-blocking algorithm that forces only a minimum number of processes to take their checkpoints. Based on the proof, we present an efficient algorithm that neither forces all processes to take checkpoints, nor blocks the underlying computation during checkpointing. Correctness proofs are also provided. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Barigazzi and L. Strigini. </author> <title> "Application-Transparent Setting of Recovery Points". </title> <booktitle> Digest of Papers FTCS-13, </booktitle> <pages> pages 48-55, </pages> <year> 1983. </year>
Reference-contexts: To initiate a checkpointing, P 2 takes its own checkpoint and sends checkpoint request messages to P 1 , P 3 and P 4 , since R 2 <ref> [1] </ref> = 1; R 2 [3] = 1, and R 2 [4] = 1. When P 2 's request reaches P 4 , P 4 takes a checkpoint. Then, P 4 sends message m3 to P 3 . <p> Similar to Case 2, we have a contradiction. 2 Theorem 3 The checkpointing algorithm terminates within a finite time. Proof. The proof is similar to [17]. 2 1 ! is the "happened before" relation described in [12] 21 6 Related Work The first consistent checkpointing algorithm was presented in <ref> [1] </ref>. However, it assumes that all communications between processes are atomic, which is too restrictive. The Koo-Toueg algorithm [10] relaxes this assumption. In [10], only those processes that have communicated with the checkpoint initiator either directly or indirectly since the last checkpoint need to take new checkpoints. <p> However, a process taking a checkpoint needs to wait for a period that equals to the sum of the maximum deviation between clocks and the maximum time to detect a failure in another process in the system. All the above consistent checkpointing algorithms <ref> [1, 4, 5, 9, 10, 13, 18] </ref> require processes to be blocked during checkpointing. Checkpointing includes the time to trace the dependency tree and to save the state of processes on the stable storage, which may be long. <p> All the above algorithms follow two approaches to reduce the overhead associated with 23 consistent checkpointing algorithms: one is to minimize the number of synchronization mes-sages and the number of checkpoints <ref> [1, 4, 5, 9, 10, 13, 18] </ref>; the other is to make check-pointing non-blocking [3, 6, 11, 19, 24]. These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm [17] combined them. However, their algorithm has two problems.
Reference: [2] <author> B. Bhargava, S.R. Lian, and P.J. Leu. </author> <title> "Experimental Evaluation of Concurrent Check-pointing and Rollback-Recovery Algorithms". </title> <booktitle> Proceedings of the International Conference on Data Engineering, </booktitle> <pages> pages 182-189, </pages> <year> 1990. </year>
Reference-contexts: Checkpointing includes the time to trace the dependency tree and to save the states of processes on the stable storage, which may be long. Therefore, blocking algorithms may dramatically degrade the performance of the system <ref> [2, 6] </ref>. Recently, nonblocking algorithms [6, 19] have received considerable attention. In these algorithms, processes need not block during checkpointing by using a checkpointing sequence 2 number to identify orphan messages. However, these algorithms [6, 19] assume that a distin-guished initiator decides when to take a checkpoint. <p> Therefore, there are two directions in designing efficient consistent checkpointing algorithms. First is to relax the non-blocking condition while keeping the min-process property. The other is to relax the min-process condition while keeping the non-blocking property. Based on the empirical study of <ref> [2, 6] </ref>, blocking the underlying computation may dramatically reduce the performance of the system. Therefore, we develop an algorithm that relaxes the min-process condition; that is, it is non-blocking, but it may force extra processes to take checkpoints. <p> Checkpointing includes the time to trace the dependency tree and to save the state of processes on the stable storage, which may be long. Therefore, blocking algorithms may dramatically reduce the performance of the system <ref> [2, 6] </ref>. The Chandy-Lamport algorithm [3] is the earliest non-blocking algorithm for consistent checkpointing. However, in their algorithm, system messages are sent along all the channels 22 in the network during checkpointing. This leads to a message complexity of O (n 2 ).
Reference: [3] <author> K.M. Chandy and L. Lamport. </author> <title> "Distributed Snapshots: Determining Global States of Distributed Systems". </title> <journal> ACM Transactions on Computer Systems, </journal> <month> February </month> <year> 1985. </year>
Reference-contexts: A system state is said to be consistent if it contains no orphan message; i.e., a message whose receive event is recorded in the state of the destination process, but its send event is lost <ref> [3, 10, 21] </ref>. In order to record a consistent global checkpoint on the stable storage, processes must synchronize their checkpointing activities. In other words, when a process takes a checkpoint, it asks (by sending checkpoint requests to) all relevant processes to take checkpoints. <p> To initiate a checkpointing, P 2 takes its own checkpoint and sends checkpoint request messages to P 1 , P 3 and P 4 , since R 2 [1] = 1; R 2 <ref> [3] </ref> = 1, and R 2 [4] = 1. When P 2 's request reaches P 4 , P 4 takes a checkpoint. Then, P 4 sends message m3 to P 3 . <p> Checkpointing includes the time to trace the dependency tree and to save the state of processes on the stable storage, which may be long. Therefore, blocking algorithms may dramatically reduce the performance of the system [2, 6]. The Chandy-Lamport algorithm <ref> [3] </ref> is the earliest non-blocking algorithm for consistent checkpointing. However, in their algorithm, system messages are sent along all the channels 22 in the network during checkpointing. This leads to a message complexity of O (n 2 ). <p> All the above algorithms follow two approaches to reduce the overhead associated with 23 consistent checkpointing algorithms: one is to minimize the number of synchronization mes-sages and the number of checkpoints [1, 4, 5, 9, 10, 13, 18]; the other is to make check-pointing non-blocking <ref> [3, 6, 11, 19, 24] </ref>. These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm [17] combined them. However, their algorithm has two problems. Therefore, our algorithm is the first correct algorithm to combine these two approaches.
Reference: [4] <author> F. Cristian and F. Jahanian. </author> <title> "A timestamp-based Checkpointing Protocol for long-lived Distributed Computations". </title> <booktitle> Proc. of IEEE Symp. Reliable Distributed Syst., </booktitle> <pages> pages 12-20, </pages> <year> 1991. </year>
Reference-contexts: When P 2 's request reaches P 4 , P 4 takes a checkpoint. Then, P 4 sends message m3 to P 3 . When m3 arrives at P 3 , P 3 takes a checkpoint before processing it because m3:csn &gt; csn 3 <ref> [4] </ref>. For the same reason, P 1 takes a checkpoint before processing m2. P 0 has not communicated with other processes before it takes a local checkpoint. Later, it sends a message m1 to P 1 . <p> To initiate a checkpointing, P 2 takes its own checkpoint and sends checkpoint request messages to P 1 , P 3 and P 4 , since R 2 [1] = 1; R 2 [3] = 1, and R 2 <ref> [4] </ref> = 1. When P 2 's request reaches P 4 , P 4 takes a checkpoint. Then, P 4 sends message m3 to P 3 . When m3 arrives at P 3 , P 3 takes a forced checkpoint before processing it because m3:csn &gt; csn 3 [4] and P <p> R 2 <ref> [4] </ref> = 1. When P 2 's request reaches P 4 , P 4 takes a checkpoint. Then, P 4 sends message m3 to P 3 . When m3 arrives at P 3 , P 3 takes a forced checkpoint before processing it because m3:csn &gt; csn 3 [4] and P 3 has sent a message during the current checkpoint interval. For the same reason, P 1 takes a forced checkpoint before processing m2. P 0 has not communicated with other processes before it takes a local checkpoint. Later, it sends a message m1 to P 1 . <p> Kim and Park [9] proposed an improved scheme that allows the new checkpoints in some subtrees to be committed while the others are aborted. To further reduce the system messages needed to synchronize the checkpointing, loosely synchronous clocks <ref> [4, 18] </ref> are used. More specifically, loosely-synchronized checkpoint clocks can trigger the local checkpointing actions of all participating processes at approximately the same time without the need of broadcasting the checkpoint request by an initiator. <p> However, a process taking a checkpoint needs to wait for a period that equals to the sum of the maximum deviation between clocks and the maximum time to detect a failure in another process in the system. All the above consistent checkpointing algorithms <ref> [1, 4, 5, 9, 10, 13, 18] </ref> require processes to be blocked during checkpointing. Checkpointing includes the time to trace the dependency tree and to save the state of processes on the stable storage, which may be long. <p> All the above algorithms follow two approaches to reduce the overhead associated with 23 consistent checkpointing algorithms: one is to minimize the number of synchronization mes-sages and the number of checkpoints <ref> [1, 4, 5, 9, 10, 13, 18] </ref>; the other is to make check-pointing non-blocking [3, 6, 11, 19, 24]. These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm [17] combined them. However, their algorithm has two problems.
Reference: [5] <author> Y. Deng and E.K. Park. </author> <title> "Checkpointing and Rollback-Recovery Algorithms in Distributed Systems". </title> <journal> Journal of Systems and Software, </journal> <month> April </month> <year> 1994. </year>
Reference-contexts: Therefore, consistent checkpointing suffers from high overhead associated with the checkpointing process. Much of previous work in consistent checkpointing has focused on minimizing the number of processes that must participate in taking a consistent checkpoint <ref> [5, 10, 13] </ref> or to reduce the number of messages required to synchronize the recording of a consistent checkpoint [22, 23]. However, these algorithms (called blocking algorithm) force all relevant processes in the system to block their computations during the checkpointing process. <p> Unlike [7] and [14], which use a vector of n integers to record dependency information, we use bit vector to record dependency information, which significantly reduces space overhead and computation requirements. 4 2.3 Basic Idea of Non-blocking Algorithms Most of the existing consistent checkpointing algorithms <ref> [5, 10, 13] </ref> rely on the two-phase protocol and save two kinds of checkpoints on the stable storage: tentative and permanent. In the first phase, the initiator takes a tentative checkpoint and forces all relevant processes to take tentative checkpoints. <p> However, these two algorithms [10, 13] assume a complex scheme (such as slide window) to deal with the message loss problem and do not consider lost messages in checkpointing and recovery. Deng and Park <ref> [5] </ref> proposed an algorithm, which addresses both orphan message and lost messages. In Koo and Toueg's original scheme [10], if any of the involved processes is not able or not willing to take a checkpoint, then the entire checkpointing process is aborted. <p> However, a process taking a checkpoint needs to wait for a period that equals to the sum of the maximum deviation between clocks and the maximum time to detect a failure in another process in the system. All the above consistent checkpointing algorithms <ref> [1, 4, 5, 9, 10, 13, 18] </ref> require processes to be blocked during checkpointing. Checkpointing includes the time to trace the dependency tree and to save the state of processes on the stable storage, which may be long. <p> All the above algorithms follow two approaches to reduce the overhead associated with 23 consistent checkpointing algorithms: one is to minimize the number of synchronization mes-sages and the number of checkpoints <ref> [1, 4, 5, 9, 10, 13, 18] </ref>; the other is to make check-pointing non-blocking [3, 6, 11, 19, 24]. These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm [17] combined them. However, their algorithm has two problems.
Reference: [6] <author> E.N. Elnozahy, D.B. Johnson, and W. Zwaenepoel. </author> <title> "The Performance of Consistent Checkpointing". </title> <booktitle> Proceedings of the 11th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 86-95, </pages> <month> October </month> <year> 1992. </year> <month> 25 </month>
Reference-contexts: Checkpointing includes the time to trace the dependency tree and to save the states of processes on the stable storage, which may be long. Therefore, blocking algorithms may dramatically degrade the performance of the system <ref> [2, 6] </ref>. Recently, nonblocking algorithms [6, 19] have received considerable attention. In these algorithms, processes need not block during checkpointing by using a checkpointing sequence 2 number to identify orphan messages. However, these algorithms [6, 19] assume that a distin-guished initiator decides when to take a checkpoint. <p> Checkpointing includes the time to trace the dependency tree and to save the states of processes on the stable storage, which may be long. Therefore, blocking algorithms may dramatically degrade the performance of the system [2, 6]. Recently, nonblocking algorithms <ref> [6, 19] </ref> have received considerable attention. In these algorithms, processes need not block during checkpointing by using a checkpointing sequence 2 number to identify orphan messages. However, these algorithms [6, 19] assume that a distin-guished initiator decides when to take a checkpoint. <p> Therefore, blocking algorithms may dramatically degrade the performance of the system [2, 6]. Recently, nonblocking algorithms <ref> [6, 19] </ref> have received considerable attention. In these algorithms, processes need not block during checkpointing by using a checkpointing sequence 2 number to identify orphan messages. However, these algorithms [6, 19] assume that a distin-guished initiator decides when to take a checkpoint. Therefore, they suffer from the disadvantages of centralized algorithms, such as one-site failure, traffic bottle-neck, etc. Moreover, these algorithms [6, 19] require all processes in the computation to take checkpoints during checkpointing, even though most of them may <p> However, these algorithms <ref> [6, 19] </ref> assume that a distin-guished initiator decides when to take a checkpoint. Therefore, they suffer from the disadvantages of centralized algorithms, such as one-site failure, traffic bottle-neck, etc. Moreover, these algorithms [6, 19] require all processes in the computation to take checkpoints during checkpointing, even though most of them may not be necessary. Prakash-Singhal algorithm [17] was the first algorithm to combine these two approaches. <p> Then, P 3 processes m1 when it receives m1. When P 3 receives the checkpoint 5 request from P 2 , it takes a checkpoint. Then, m1 becomes an orphan. Most of the non-blocking algorithms <ref> [6, 19] </ref> use a Checkpoint Sequence Number (csn) to avoid inconsistency. More specifically, a process is forced to take a checkpoint if it receives a computation message whose appended csn is greater than its local csn. <p> Therefore, there are two directions in designing efficient consistent checkpointing algorithms. First is to relax the non-blocking condition while keeping the min-process property. The other is to relax the min-process condition while keeping the non-blocking property. Based on the empirical study of <ref> [2, 6] </ref>, blocking the underlying computation may dramatically reduce the performance of the system. Therefore, we develop an algorithm that relaxes the min-process condition; that is, it is non-blocking, but it may force extra processes to take checkpoints. <p> Checkpointing includes the time to trace the dependency tree and to save the state of processes on the stable storage, which may be long. Therefore, blocking algorithms may dramatically reduce the performance of the system <ref> [2, 6] </ref>. The Chandy-Lamport algorithm [3] is the earliest non-blocking algorithm for consistent checkpointing. However, in their algorithm, system messages are sent along all the channels 22 in the network during checkpointing. This leads to a message complexity of O (n 2 ). <p> However, this scheme requires each process to log each message sent, which may introduce some performance degradation, and require the system to be deterministic. The Elnozahy-Johnson-Zwaenepoel algorithm <ref> [6] </ref> uses the checkpoint sequence number to identify orphan messages, thus avoiding the need for processes to be blocked during check-pointing. However, this approach requires the initiator to communicate with all processes in the computation. The algorithm proposed by Silva and Silva [19] uses a similar idea as [6], except that <p> Elnozahy-Johnson-Zwaenepoel algorithm <ref> [6] </ref> uses the checkpoint sequence number to identify orphan messages, thus avoiding the need for processes to be blocked during check-pointing. However, this approach requires the initiator to communicate with all processes in the computation. The algorithm proposed by Silva and Silva [19] uses a similar idea as [6], except that the processes which did not communicate with others during the previous checkpoint period do not need to take a new checkpoint. Both algorithms [6, 19] assume that a distinguished initiator decides when to take a checkpoint. <p> The algorithm proposed by Silva and Silva [19] uses a similar idea as [6], except that the processes which did not communicate with others during the previous checkpoint period do not need to take a new checkpoint. Both algorithms <ref> [6, 19] </ref> assume that a distinguished initiator decides when to take a checkpoint. Therefore, they suffer from the disadvantages of centralized algorithms, such as one-site failure, traffic bottle-neck, etc. Moreover, their algorithms require almost all processes to take checkpoints, even though most of them are unnecessary. <p> All the above algorithms follow two approaches to reduce the overhead associated with 23 consistent checkpointing algorithms: one is to minimize the number of synchronization mes-sages and the number of checkpoints [1, 4, 5, 9, 10, 13, 18]; the other is to make check-pointing non-blocking <ref> [3, 6, 11, 19, 24] </ref>. These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm [17] combined them. However, their algorithm has two problems. Therefore, our algorithm is the first correct algorithm to combine these two approaches.
Reference: [7] <author> J. Fidge. </author> <title> "Timestamps in Message-Passing Systems that Preserve the Partial Ordering". </title> <booktitle> Proceedings of 11 th Australian Computer Science Conference, </booktitle> <pages> pages 56-66, </pages> <year> 1988. </year>
Reference-contexts: As a result, only P 1 , P 2 , and P 3 take new checkpoints. P 4 and P 5 continues their computation without taking new checkpoints. Unlike <ref> [7] </ref> and [14], which use a vector of n integers to record dependency information, we use bit vector to record dependency information, which significantly reduces space overhead and computation requirements. 4 2.3 Basic Idea of Non-blocking Algorithms Most of the existing consistent checkpointing algorithms [5, 10, 13] rely on the two-phase
Reference: [8] <author> S.T. Huang. </author> <title> "Detecting Termination of Distributed Computations by External Agents". </title> <booktitle> Proceedings of the 9th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 79-84, </pages> <year> 1989. </year>
Reference-contexts: Note that csn i [i] is the checkpoint sequence number of P i . weight: a non-negative variable of type real with maximum value of 1. It is used to detect the termination of the checkpointing as in <ref> [8] </ref>. f irst i : a boolean array of size n maintained by each process P i . The array is initialized to all zeroes each time a checkpoint at that process is taken.
Reference: [9] <author> J.L. Kim and T. Park. </author> <title> "An Efficient Protocol For Checkpointing Recovery in Distributed Systems". </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <pages> pages 955-960, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Deng and Park [5] proposed an algorithm, which addresses both orphan message and lost messages. In Koo and Toueg's original scheme [10], if any of the involved processes is not able or not willing to take a checkpoint, then the entire checkpointing process is aborted. Kim and Park <ref> [9] </ref> proposed an improved scheme that allows the new checkpoints in some subtrees to be committed while the others are aborted. To further reduce the system messages needed to synchronize the checkpointing, loosely synchronous clocks [4, 18] are used. <p> However, a process taking a checkpoint needs to wait for a period that equals to the sum of the maximum deviation between clocks and the maximum time to detect a failure in another process in the system. All the above consistent checkpointing algorithms <ref> [1, 4, 5, 9, 10, 13, 18] </ref> require processes to be blocked during checkpointing. Checkpointing includes the time to trace the dependency tree and to save the state of processes on the stable storage, which may be long. <p> All the above algorithms follow two approaches to reduce the overhead associated with 23 consistent checkpointing algorithms: one is to minimize the number of synchronization mes-sages and the number of checkpoints <ref> [1, 4, 5, 9, 10, 13, 18] </ref>; the other is to make check-pointing non-blocking [3, 6, 11, 19, 24]. These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm [17] combined them. However, their algorithm has two problems.
Reference: [10] <author> R. Koo and S. Toueg. </author> <title> "Checkpointing and Rollback-Recovery for Distributed Systems". </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pages 23-31, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: A system state is said to be consistent if it contains no orphan message; i.e., a message whose receive event is recorded in the state of the destination process, but its send event is lost <ref> [3, 10, 21] </ref>. In order to record a consistent global checkpoint on the stable storage, processes must synchronize their checkpointing activities. In other words, when a process takes a checkpoint, it asks (by sending checkpoint requests to) all relevant processes to take checkpoints. <p> Therefore, consistent checkpointing suffers from high overhead associated with the checkpointing process. Much of previous work in consistent checkpointing has focused on minimizing the number of processes that must participate in taking a consistent checkpoint <ref> [5, 10, 13] </ref> or to reduce the number of messages required to synchronize the recording of a consistent checkpoint [22, 23]. However, these algorithms (called blocking algorithm) force all relevant processes in the system to block their computations during the checkpointing process. <p> Unlike [7] and [14], which use a vector of n integers to record dependency information, we use bit vector to record dependency information, which significantly reduces space overhead and computation requirements. 4 2.3 Basic Idea of Non-blocking Algorithms Most of the existing consistent checkpointing algorithms <ref> [5, 10, 13] </ref> rely on the two-phase protocol and save two kinds of checkpoints on the stable storage: tentative and permanent. In the first phase, the initiator takes a tentative checkpoint and forces all relevant processes to take tentative checkpoints. <p> Each process, which takes a checkpoint, recursively forces all dependent processes to take checkpoints. The Koo-Toueg algorithm <ref> [10] </ref> uses this scheme, and it forces only a minimum number of processes to take checkpoints. 7 We illustrated the only difference between depend and z-depend using Figure 3. Next, we use Figure 3 to show that the Koo-Toueg algorithm [10] is a min-process algorithm. In C 3;k . <p> The Koo-Toueg algorithm <ref> [10] </ref> uses this scheme, and it forces only a minimum number of processes to take checkpoints. 7 We illustrated the only difference between depend and z-depend using Figure 3. Next, we use Figure 3 to show that the Koo-Toueg algorithm [10] is a min-process algorithm. In C 3;k . In the min-process checkpointing algorithm, since P 2 j1 fl k1 takes C 2;j and P 3 takes C 3;k . Assume P 2 receives P 1 's checkpoint request before it receives m2. According to [10], if P 1 takes C <p> show that the Koo-Toueg algorithm <ref> [10] </ref> is a min-process algorithm. In C 3;k . In the min-process checkpointing algorithm, since P 2 j1 fl k1 takes C 2;j and P 3 takes C 3;k . Assume P 2 receives P 1 's checkpoint request before it receives m2. According to [10], if P 1 takes C 1;i , P 1 asks P 2 to take C 2;j . But P 2 does not ask P 3 to take a new checkpoint. <p> Proof. We know that the Koo-Toueg algorithm <ref> [10] </ref> forces only a minimum number of processes to take checkpoints, so we need to prove the follows: in [10], when a process P p initiates a new checkpointing and takes a checkpoint C p;i , a process P q takes a checkpoint C q;j associated with C p;i if and <p> Proof. We know that the Koo-Toueg algorithm <ref> [10] </ref> forces only a minimum number of processes to take checkpoints, so we need to prove the follows: in [10], when a process P p initiates a new checkpointing and takes a checkpoint C p;i , a process P q takes a checkpoint C q;j associated with C p;i if and only if P q fl j1 Necessary: in [10], when a process P p initiates a new checkpoint C <p> take checkpoints, so we need to prove the follows: in <ref> [10] </ref>, when a process P p initiates a new checkpointing and takes a checkpoint C p;i , a process P q takes a checkpoint C q;j associated with C p;i if and only if P q fl j1 Necessary: in [10], when a process P p initiates a new checkpoint C p;i , it recursively asks all dependent processes to take checkpoints. If a process P q takes a checkpoint C q;j associated with C p;i . <p> Proof. The proof is similar to [17]. 2 1 ! is the "happened before" relation described in [12] 21 6 Related Work The first consistent checkpointing algorithm was presented in [1]. However, it assumes that all communications between processes are atomic, which is too restrictive. The Koo-Toueg algorithm <ref> [10] </ref> relaxes this assumption. In [10], only those processes that have communicated with the checkpoint initiator either directly or indirectly since the last checkpoint need to take new checkpoints. Thus, it reduces the number of synchronization messages and the number of checkpoints. <p> However, it assumes that all communications between processes are atomic, which is too restrictive. The Koo-Toueg algorithm <ref> [10] </ref> relaxes this assumption. In [10], only those processes that have communicated with the checkpoint initiator either directly or indirectly since the last checkpoint need to take new checkpoints. Thus, it reduces the number of synchronization messages and the number of checkpoints. <p> Thus, it reduces the number of synchronization messages and the number of checkpoints. Later, Leu and Bhargava [13] presented an algorithm, which is resilient to multiple process failures, and does not assume that the channel is FIFO, which is necessary in <ref> [10] </ref>. However, these two algorithms [10, 13] assume a complex scheme (such as slide window) to deal with the message loss problem and do not consider lost messages in checkpointing and recovery. Deng and Park [5] proposed an algorithm, which addresses both orphan message and lost messages. <p> Thus, it reduces the number of synchronization messages and the number of checkpoints. Later, Leu and Bhargava [13] presented an algorithm, which is resilient to multiple process failures, and does not assume that the channel is FIFO, which is necessary in [10]. However, these two algorithms <ref> [10, 13] </ref> assume a complex scheme (such as slide window) to deal with the message loss problem and do not consider lost messages in checkpointing and recovery. Deng and Park [5] proposed an algorithm, which addresses both orphan message and lost messages. <p> Deng and Park [5] proposed an algorithm, which addresses both orphan message and lost messages. In Koo and Toueg's original scheme <ref> [10] </ref>, if any of the involved processes is not able or not willing to take a checkpoint, then the entire checkpointing process is aborted. Kim and Park [9] proposed an improved scheme that allows the new checkpoints in some subtrees to be committed while the others are aborted. <p> However, a process taking a checkpoint needs to wait for a period that equals to the sum of the maximum deviation between clocks and the maximum time to detect a failure in another process in the system. All the above consistent checkpointing algorithms <ref> [1, 4, 5, 9, 10, 13, 18] </ref> require processes to be blocked during checkpointing. Checkpointing includes the time to trace the dependency tree and to save the state of processes on the stable storage, which may be long. <p> All the above algorithms follow two approaches to reduce the overhead associated with 23 consistent checkpointing algorithms: one is to minimize the number of synchronization mes-sages and the number of checkpoints <ref> [1, 4, 5, 9, 10, 13, 18] </ref>; the other is to make check-pointing non-blocking [3, 6, 11, 19, 24]. These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm [17] combined them. However, their algorithm has two problems.
Reference: [11] <author> T.H. Lai and T.H. Yang. </author> <title> "On Distributed Snapshots". </title> <journal> Information Processing Letters, </journal> <pages> pages 153-158, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: This leads to a message complexity of O (n 2 ). Moreover, it requires all processes to take checkpoints and the channel must be FIFO. To relax the FIFO assumption, Lai and Yang proposed another algorithm <ref> [11] </ref>. In their algorithm, when a process takes a checkpoint, it piggybacks a checkpoint request to the first message it sends out from each channel. The receiver checks the piggybacked message before processing the message. <p> All the above algorithms follow two approaches to reduce the overhead associated with 23 consistent checkpointing algorithms: one is to minimize the number of synchronization mes-sages and the number of checkpoints [1, 4, 5, 9, 10, 13, 18]; the other is to make check-pointing non-blocking <ref> [3, 6, 11, 19, 24] </ref>. These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm [17] combined them. However, their algorithm has two problems. Therefore, our algorithm is the first correct algorithm to combine these two approaches.
Reference: [12] <author> L. Lamport. </author> <title> "Time, Clocks and Ordering of Events in Distributed Systems". </title> <journal> Communication of the ACM, </journal> <month> July </month> <year> 1978. </year>
Reference-contexts: Similar to Case 2, we have a contradiction. 2 Theorem 3 The checkpointing algorithm terminates within a finite time. Proof. The proof is similar to [17]. 2 1 ! is the "happened before" relation described in <ref> [12] </ref> 21 6 Related Work The first consistent checkpointing algorithm was presented in [1]. However, it assumes that all communications between processes are atomic, which is too restrictive. The Koo-Toueg algorithm [10] relaxes this assumption.
Reference: [13] <author> P.Y. Leu and B. Bhargava. </author> <title> "Concurrent Robust Checkpointing and Recovery in Distributed Systems". Pro. </title> <booktitle> 4th IEEE Int. Conf. on Data Eng., </booktitle> <pages> pages 154-163, </pages> <year> 1988. </year>
Reference-contexts: Therefore, consistent checkpointing suffers from high overhead associated with the checkpointing process. Much of previous work in consistent checkpointing has focused on minimizing the number of processes that must participate in taking a consistent checkpoint <ref> [5, 10, 13] </ref> or to reduce the number of messages required to synchronize the recording of a consistent checkpoint [22, 23]. However, these algorithms (called blocking algorithm) force all relevant processes in the system to block their computations during the checkpointing process. <p> Unlike [7] and [14], which use a vector of n integers to record dependency information, we use bit vector to record dependency information, which significantly reduces space overhead and computation requirements. 4 2.3 Basic Idea of Non-blocking Algorithms Most of the existing consistent checkpointing algorithms <ref> [5, 10, 13] </ref> rely on the two-phase protocol and save two kinds of checkpoints on the stable storage: tentative and permanent. In the first phase, the initiator takes a tentative checkpoint and forces all relevant processes to take tentative checkpoints. <p> The Koo-Toueg algorithm [10] relaxes this assumption. In [10], only those processes that have communicated with the checkpoint initiator either directly or indirectly since the last checkpoint need to take new checkpoints. Thus, it reduces the number of synchronization messages and the number of checkpoints. Later, Leu and Bhargava <ref> [13] </ref> presented an algorithm, which is resilient to multiple process failures, and does not assume that the channel is FIFO, which is necessary in [10]. <p> Thus, it reduces the number of synchronization messages and the number of checkpoints. Later, Leu and Bhargava [13] presented an algorithm, which is resilient to multiple process failures, and does not assume that the channel is FIFO, which is necessary in [10]. However, these two algorithms <ref> [10, 13] </ref> assume a complex scheme (such as slide window) to deal with the message loss problem and do not consider lost messages in checkpointing and recovery. Deng and Park [5] proposed an algorithm, which addresses both orphan message and lost messages. <p> However, a process taking a checkpoint needs to wait for a period that equals to the sum of the maximum deviation between clocks and the maximum time to detect a failure in another process in the system. All the above consistent checkpointing algorithms <ref> [1, 4, 5, 9, 10, 13, 18] </ref> require processes to be blocked during checkpointing. Checkpointing includes the time to trace the dependency tree and to save the state of processes on the stable storage, which may be long. <p> All the above algorithms follow two approaches to reduce the overhead associated with 23 consistent checkpointing algorithms: one is to minimize the number of synchronization mes-sages and the number of checkpoints <ref> [1, 4, 5, 9, 10, 13, 18] </ref>; the other is to make check-pointing non-blocking [3, 6, 11, 19, 24]. These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm [17] combined them. However, their algorithm has two problems.
Reference: [14] <author> F. Mattern. </author> <title> "Virtual Time and Global States of Distributed Systems". </title> <booktitle> Proceedings of the workshop on Parallel and Distributed Algorithm, </booktitle> <pages> pages 215-226, </pages> <year> 1993. </year>
Reference-contexts: As a result, only P 1 , P 2 , and P 3 take new checkpoints. P 4 and P 5 continues their computation without taking new checkpoints. Unlike [7] and <ref> [14] </ref>, which use a vector of n integers to record dependency information, we use bit vector to record dependency information, which significantly reduces space overhead and computation requirements. 4 2.3 Basic Idea of Non-blocking Algorithms Most of the existing consistent checkpointing algorithms [5, 10, 13] rely on the two-phase protocol and
Reference: [15] <author> R.H.B. Netzer and Jian Xu. </author> <title> "Necessary and Sufficient Conditions for Consistent Global Snapshots". </title> <journal> IEEE Transactions on Parallel and Distributed System, </journal> <pages> pages 165-169, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: We also assume that each process P p takes an initial checkpoint C p;0 immediately before execution begins and ends with a virtual checkpoint that represents the last state attained before termination <ref> [15] </ref>. <p> However, their algorithm has two problems. Therefore, our algorithm is the first correct algorithm to combine these two approaches. In other words, our non-locking algorithm minimizes the number of extra checkpoints in checkpointing. Netzer and Xu introduced the concept of "zigzag" paths <ref> [15] </ref> to define the necessary and sufficient conditions of consistent checkpoints. Our definition of "z-depend" catches the essence of "zigzag" paths. If an initiator forces all its "transitively z-dependent" processes to take checkpoints, the resulting checkpoints are consistent, and no "zigzag" path exists among them.
Reference: [16] <author> Ravi Prakash and Mukesh Singhal. </author> " <title> Maximal Global Snapshot with Concurrent Initiators". </title> <booktitle> Proceedings of the Sixth IEEE symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 344-351, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Techniques to handle concurrent initiations of checkpointing by multiple processes can be found in <ref> [16] </ref>. As multiple concurrent initiations of checkpointing is orthogonal to our discussion, we only briefly mention the main features of [16]. When a process receives its first request for checkpointing initiated by another process, it takes a local checkpoint and propagates the request. <p> Techniques to handle concurrent initiations of checkpointing by multiple processes can be found in <ref> [16] </ref>. As multiple concurrent initiations of checkpointing is orthogonal to our discussion, we only briefly mention the main features of [16]. When a process receives its first request for checkpointing initiated by another process, it takes a local checkpoint and propagates the request. All the local checkpoints taken by the participating processes for a checkpoint initiation collectively form a global checkpoint.
Reference: [17] <author> Ravi Prakash and Mukesh Singhal. </author> <title> "Low-Cost Checkpointing and Failure Recovery in Mobile Computing Systems". </title> <journal> IEEE Transactions on Parallel and Distributed System, </journal> <pages> pages 1035-1048, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Therefore, they suffer from the disadvantages of centralized algorithms, such as one-site failure, traffic bottle-neck, etc. Moreover, these algorithms [6, 19] require all processes in the computation to take checkpoints during checkpointing, even though most of them may not be necessary. Prakash-Singhal algorithm <ref> [17] </ref> was the first algorithm to combine these two approaches. More specifically, it forces only a minimum number of processes to take checkpoints, and does not block the underlying computation during checkpointing. However, we have found two problems in their algorithm. <p> denotes all the computation performed between its i th and (i + 1) th checkpoint, including the i th checkpoint but not the (i + 1) th checkpoint. 2.2 Minimizing Dependency Information In order to record the dependency relationship among processes, we use a similar approach as the Prakash-Singhal algorithm <ref> [17] </ref>, where each process P i maintains a boolean vector R i . The vector has n bits, representing n processes. At P i , the vector is initialized to 0. When process P i sends a message to P j , it appends R i to the message m. <p> When P 3 receives m1, it takes a checkpoint before processing m1 since the csn appended with m1 is larger than its local csn. This scheme works only when every process in the computation can receive each checkpoint request and then increase its own csn. Since the Prakash-Singhal algorithm <ref> [17] </ref> only forces part of processes to take checkpoints, the csn of some processes may be out-of-date, and hence is insufficient to avoid inconsistency. the Prakash-Singhal algorithm attempts to solve this problem by having each process maintain an array to save the csn, where csn [i] is the expected csn of <p> Similar to Case 2, we have a contradiction. 2 Theorem 3 The checkpointing algorithm terminates within a finite time. Proof. The proof is similar to <ref> [17] </ref>. 2 1 ! is the "happened before" relation described in [12] 21 6 Related Work The first consistent checkpointing algorithm was presented in [1]. However, it assumes that all communications between processes are atomic, which is too restrictive. The Koo-Toueg algorithm [10] relaxes this assumption. <p> These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm <ref> [17] </ref> combined them. However, their algorithm has two problems. Therefore, our algorithm is the first correct algorithm to combine these two approaches. In other words, our non-locking algorithm minimizes the number of extra checkpoints in checkpointing. <p> Based on this innovative idea, our non-blocking algorithm avoids the avalanche effect and minimizes the number of checkpoints. 3. We identified two problems in the Prakash-Singhal algorithm <ref> [17] </ref>. From Theorem 1, no min-process non-blocking algorithm exists. Therefore, there are two directions in designing efficient consistent checkpointing algorithms. In this paper, we proposed a non-blocking algorithm, which relaxed the min-process condition while minimizing the number of checkpoints.
Reference: [18] <author> P. Ramanathan and K.G. Shin. </author> <title> "Use of Common Time Base for Checkpointing and Rollback Recovery in a Distributed System". </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pages 571-583, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Kim and Park [9] proposed an improved scheme that allows the new checkpoints in some subtrees to be committed while the others are aborted. To further reduce the system messages needed to synchronize the checkpointing, loosely synchronous clocks <ref> [4, 18] </ref> are used. More specifically, loosely-synchronized checkpoint clocks can trigger the local checkpointing actions of all participating processes at approximately the same time without the need of broadcasting the checkpoint request by an initiator. <p> However, a process taking a checkpoint needs to wait for a period that equals to the sum of the maximum deviation between clocks and the maximum time to detect a failure in another process in the system. All the above consistent checkpointing algorithms <ref> [1, 4, 5, 9, 10, 13, 18] </ref> require processes to be blocked during checkpointing. Checkpointing includes the time to trace the dependency tree and to save the state of processes on the stable storage, which may be long. <p> All the above algorithms follow two approaches to reduce the overhead associated with 23 consistent checkpointing algorithms: one is to minimize the number of synchronization mes-sages and the number of checkpoints <ref> [1, 4, 5, 9, 10, 13, 18] </ref>; the other is to make check-pointing non-blocking [3, 6, 11, 19, 24]. These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm [17] combined them. However, their algorithm has two problems.
Reference: [19] <author> L.M. Silva and J.G. Silva. </author> <title> "Global Checkpointing for Distributed Programs". </title> <booktitle> Proceedings of the 11th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 155-162, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Checkpointing includes the time to trace the dependency tree and to save the states of processes on the stable storage, which may be long. Therefore, blocking algorithms may dramatically degrade the performance of the system [2, 6]. Recently, nonblocking algorithms <ref> [6, 19] </ref> have received considerable attention. In these algorithms, processes need not block during checkpointing by using a checkpointing sequence 2 number to identify orphan messages. However, these algorithms [6, 19] assume that a distin-guished initiator decides when to take a checkpoint. <p> Therefore, blocking algorithms may dramatically degrade the performance of the system [2, 6]. Recently, nonblocking algorithms <ref> [6, 19] </ref> have received considerable attention. In these algorithms, processes need not block during checkpointing by using a checkpointing sequence 2 number to identify orphan messages. However, these algorithms [6, 19] assume that a distin-guished initiator decides when to take a checkpoint. Therefore, they suffer from the disadvantages of centralized algorithms, such as one-site failure, traffic bottle-neck, etc. Moreover, these algorithms [6, 19] require all processes in the computation to take checkpoints during checkpointing, even though most of them may <p> However, these algorithms <ref> [6, 19] </ref> assume that a distin-guished initiator decides when to take a checkpoint. Therefore, they suffer from the disadvantages of centralized algorithms, such as one-site failure, traffic bottle-neck, etc. Moreover, these algorithms [6, 19] require all processes in the computation to take checkpoints during checkpointing, even though most of them may not be necessary. Prakash-Singhal algorithm [17] was the first algorithm to combine these two approaches. <p> Then, P 3 processes m1 when it receives m1. When P 3 receives the checkpoint 5 request from P 2 , it takes a checkpoint. Then, m1 becomes an orphan. Most of the non-blocking algorithms <ref> [6, 19] </ref> use a Checkpoint Sequence Number (csn) to avoid inconsistency. More specifically, a process is forced to take a checkpoint if it receives a computation message whose appended csn is greater than its local csn. <p> The Elnozahy-Johnson-Zwaenepoel algorithm [6] uses the checkpoint sequence number to identify orphan messages, thus avoiding the need for processes to be blocked during check-pointing. However, this approach requires the initiator to communicate with all processes in the computation. The algorithm proposed by Silva and Silva <ref> [19] </ref> uses a similar idea as [6], except that the processes which did not communicate with others during the previous checkpoint period do not need to take a new checkpoint. Both algorithms [6, 19] assume that a distinguished initiator decides when to take a checkpoint. <p> The algorithm proposed by Silva and Silva [19] uses a similar idea as [6], except that the processes which did not communicate with others during the previous checkpoint period do not need to take a new checkpoint. Both algorithms <ref> [6, 19] </ref> assume that a distinguished initiator decides when to take a checkpoint. Therefore, they suffer from the disadvantages of centralized algorithms, such as one-site failure, traffic bottle-neck, etc. Moreover, their algorithms require almost all processes to take checkpoints, even though most of them are unnecessary. <p> All the above algorithms follow two approaches to reduce the overhead associated with 23 consistent checkpointing algorithms: one is to minimize the number of synchronization mes-sages and the number of checkpoints [1, 4, 5, 9, 10, 13, 18]; the other is to make check-pointing non-blocking <ref> [3, 6, 11, 19, 24] </ref>. These two approaches were orthogonal in previous years until the Prakash-Singhal algorithm [17] combined them. However, their algorithm has two problems. Therefore, our algorithm is the first correct algorithm to combine these two approaches.
Reference: [20] <author> M. Spezialetti and P. Kearns. </author> <title> "Efficient Distributed Snapshots". </title> <booktitle> Proceedings of the 6 th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 382-388, </pages> <year> 1986. </year> <month> 26 </month>
Reference-contexts: The combination is driven by the fact that the union of consistent global checkpoints is also a consistent global checkpoint. The checkpoints thus generated are more recent than each of the checkpoints collected independently, and also more recent than that collected by <ref> [20] </ref>. Therefore, the amount of computation lost during rollback, after process failures, is minimized. Next, we present our non-blocking algorithm. Checkpointing initiation: Any site can initiate a checkpointing.
Reference: [21] <author> R.E. Strom and S.A. Yemini. </author> <title> "Optimistic Recovery In Distributed Systems". </title> <journal> ACM Transactions on Computer Systems, </journal> <pages> pages 204-226, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: A system state is said to be consistent if it contains no orphan message; i.e., a message whose receive event is recorded in the state of the destination process, but its send event is lost <ref> [3, 10, 21] </ref>. In order to record a consistent global checkpoint on the stable storage, processes must synchronize their checkpointing activities. In other words, when a process takes a checkpoint, it asks (by sending checkpoint requests to) all relevant processes to take checkpoints.
Reference: [22] <author> Z. Tong, R.Y. Kain, and W.T. Tsai. </author> <title> "A Lower Overhead Checkpointing and Rollback Recovery Scheme for Distributed Systems". </title> <booktitle> Proceedings of the 8th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 12-20, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Much of previous work in consistent checkpointing has focused on minimizing the number of processes that must participate in taking a consistent checkpoint [5, 10, 13] or to reduce the number of messages required to synchronize the recording of a consistent checkpoint <ref> [22, 23] </ref>. However, these algorithms (called blocking algorithm) force all relevant processes in the system to block their computations during the checkpointing process. Checkpointing includes the time to trace the dependency tree and to save the states of processes on the stable storage, which may be long.
Reference: [23] <author> K. Venkatesh, T. Radhakrishnan, and H.F. Li. </author> <title> "Optimal Checkpointing and Local Recording for Domino-free Rollback Recovery". </title> <journal> Information Processing Letters, </journal> <pages> pages 25 295-303, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Much of previous work in consistent checkpointing has focused on minimizing the number of processes that must participate in taking a consistent checkpoint [5, 10, 13] or to reduce the number of messages required to synchronize the recording of a consistent checkpoint <ref> [22, 23] </ref>. However, these algorithms (called blocking algorithm) force all relevant processes in the system to block their computations during the checkpointing process. Checkpointing includes the time to trace the dependency tree and to save the states of processes on the stable storage, which may be long.

References-found: 23

