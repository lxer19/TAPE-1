URL: http://ciir.cs.umass.edu/info/psfiles/irpubs/ir87.ps.gz
Refering-URL: http://ciir.cs.umass.edu/info/psfiles/irpubs/irnew.html
Root-URL: 
Title: Combining Multiple Evidence from Different Relevance Feedback Methods  
Author: Joon Ho Lee 
Address: Amherst, Massachusetts 01003, USA  
Affiliation: Center for Intelligent Information Retrieval Department of Computer Science, University of Massachusetts  
Abstract: It has been known that using different representations of a query retrieves different sets of documents. Recent work suggests that significant improvement in retrieval performance can be achieved by combining multiple representations of an information need. In this paper, we first investigate a fully automatic way of generating multiple query representations for a given information problem. We produce multiple query vectors by expanding an initial query vector with various relevance feedback methods. We then describe the effect of combining the multiple query vectors on retrieval effectiveness. Experimental results show that significant improvements can be obtained by the combination of multiple query vectors expanded with different relevance feedback methods.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N.J. Belkin, C. Cool, W.B. Croft and J.P. Callan, </author> <title> "The effect of multiple query representations on information retrieval performance," </title> <booktitle> Proceedings of the 16th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 339-346, </pages> <year> 1993. </year>
Reference-contexts: Turtle and Croft implemented the INQUERY retrieval system based on the model, and demonstrated that multiple evidence increases retrieval effectiveness in some circumstances. Fox and Shaw [5] have worked on various methods for combining multiple retrieval runs, and have obtained improvements over any single retrieval run. Belkin, et al. <ref> [1] </ref> showed that progressive combination of different Boolean query formulations could lead to progressive improvements of retrieval effectiveness. <p> As a result, the summation function, which sums up the set of similarity values, or, equivalently, the numerical mean of the set of similarity values works better in most TREC subcollections. Belkin, et al. <ref> [1] </ref> used the summation function to combine multiple Boolean query representations of TREC topics, which is supported by the INQUERY system.
Reference: [2] <author> N.J. Belkin, P. Kantor, E.A. Fox and J.A. Shaw, </author> <title> "Combining the evidence of multiple query representations for information retrieval," </title> <booktitle> Information Processing & Management, </booktitle> <volume> Vol. 31, No. 3, </volume> <pages> pp. 431-448, </pages> <year> 1995. </year>
Reference-contexts: However, when one takes the best performing combination, 2-way and 3-way combination is better than 1-way, 4-way, and 5-way. These are the same results that Belkin, et al. obtained in the combination of different Boolean query formulations <ref> [2] </ref>. 10 Table 6: 11-point average precision of the combined runs (TREC D1 & D2; averages over 50 queries; % change is given with respect to the initial run providing the 11-point average precision 0.2893) Ide Rocchio Pr cl Pr adj 0.3523 0.3482 0.3361 0.3378 Rocchio 0.3482 0.3529 Pr cl (+16.2%)
Reference: [3] <author> W.B. Croft and D.J. Harper, </author> <title> "Using probabilistic models of document retrieval without relevance," </title> <journal> Journal of Documentation, </journal> <volume> Vol. 35, </volume> <pages> pp. 285-295, </pages> <year> 1979. </year>
Reference-contexts: Q new = ff Q old + fi i=1 R i fl T nonrel T nonrel vector for a top-ranked nonrel doc Pr cl This classical probabilistic feedback formula is based on the probabilistic retrieval model <ref> [3] </ref>. w 0 p i (1 q i ) p i = R + 1 n i r i + 0:5 5 r i number of rel docs having term t i n i number of docs having term t i in the collection R total number of rel docs N
Reference: [4] <author> E. Ide, </author> <title> "New experiments in relevance feedback," The Smart system experiments in automatic document processing, </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall Inc., </publisher> <pages> pp. 337-354, </pages> <year> 1971. </year>
Reference-contexts: for nonrel doc d n n rel number of rel docs n nonrel number of nonrel docs Ide The Ide formula is modified from the Rocchio formula by eliminating the normalization for the number of relevant and nonrelevant documents and allowing limited negative feedback from only the top-ranked nonrelevant document <ref> [4] </ref>.
Reference: [5] <author> E.A. Fox and J.A. Shaw, </author> <title> "Combination of multiple searches," </title> <booktitle> Proceedings of the 2nd Text REtrieval Conference (TREC-2), National Institute of Standards and Technology Special Publication 500-215, </booktitle> <pages> pp. 243-252, </pages> <year> 1994. </year>
Reference-contexts: Turtle and Croft implemented the INQUERY retrieval system based on the model, and demonstrated that multiple evidence increases retrieval effectiveness in some circumstances. Fox and Shaw <ref> [5] </ref> have worked on various methods for combining multiple retrieval runs, and have obtained improvements over any single retrieval run. Belkin, et al. [1] showed that progressive combination of different Boolean query formulations could lead to progressive improvements of retrieval effectiveness. <p> Therefore, Min Max Norm can be reduced to Max Norm for SMART. Fox and Shaw <ref> [5] </ref> have tested several functions of combining similarity values with the SMART system. As a result, the summation function, which sums up the set of similarity values, or, equivalently, the numerical mean of the set of similarity values works better in most TREC subcollections.
Reference: [6] <author> N. Fuhr and C. Buckley, </author> <title> "A probabilistic learning approach for document indexing," </title> <journal> ACM Transactions on Information Systems, </journal> <volume> Vol. 9, No. 3, </volume> <pages> pp. 223-248, </pages> <year> 1991. </year>
Reference-contexts: the 0.5 adjustment factor with n i =N [11]. w 0 p i (1 q i ) p i = R + 1 n i r i + n i =N S rpi This is a simplified version of Fuhr's RPI formula that does not use a non-linear similarity function <ref> [6] </ref>. qi = log q i (1 p i ) n rel X w ri q i = n nonrel X n=1 n nonrel w ri weight of term t i in rel doc d r w ni weight of term t i in nonrel doc d n n rel number
Reference: [7] <author> J. Katzer, M.J. McGill, J.A. Tessier, W. Frakes and P. Dasgupta, </author> <title> "A study of the overlap among document representations," </title> <journal> Information Technology: Research and Development, </journal> <volume> Vol. 1, No. 2, </volume> <pages> pp. 261-274, </pages> <year> 1982. </year>
Reference-contexts: McGill, Koll & Norreault [10] found that there was surprisingly little overlap between document sets for the same information need, when documents were retrieved by different users or by the same user using controlled versus free-text vocabularies. Katzer, et al. <ref> [7] </ref> considered the effect of different document fl On leave from Korea Research and Development Information Center, Korea Institute of Science and Technology, P.O. Box 122, Yusong, Taejon 305-600, Korea 1 representations (e.g. title, abstract) on retrieval effectiveness rather than different query representations.
Reference: [8] <author> J.H. Lee, M.H. Kim and Y.J. Lee, </author> <title> "Ranking documents in thesaurus-based Boolean retrieval systems," </title> <booktitle> Information Processing & Management, </booktitle> <volume> Vol. 30, No. 1, </volume> <pages> pp. 79-91, </pages> <year> 1994. </year>
Reference-contexts: Two different methods are exploited to calculate how different the retrieval results are. First of all, we compute the Spearman correlation coefficient to see how two ranked lists are correlated. The Spearman correlation coefficient <ref> [8] </ref> is defined as follows: Suppose k documents such as d 1 ; : : : ; d k are given.
Reference: [9] <author> J.H. Lee, </author> <title> "Combining Multiple Evidence from Different Properties of Weighting Schemes," </title> <booktitle> Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 180-188, </pages> <year> 1995. </year> <month> 13 </month>
Reference-contexts: Fox and Shaw [5] have worked on various methods for combining multiple retrieval runs, and have obtained improvements over any single retrieval run. Belkin, et al. [1] showed that progressive combination of different Boolean query formulations could lead to progressive improvements of retrieval effectiveness. Lee <ref> [9] </ref> described how different properties of weighting schemes may retrieve different types of documents, and showed that significant improvements could be obtained by combining the retrieval results from different properties of weighting schemes.
Reference: [10] <author> M. McGill, M. Koll and T. Norreault, </author> <title> "An evaluation of factors affecting document ranking by infor-mation retrieval systems," </title> <institution> Syracuse, Syracuse University School of Information Studies, </institution> <year> 1979. </year>
Reference-contexts: This general area has been discussed in the literature under the name of "data fusion". McGill, Koll & Norreault <ref> [10] </ref> found that there was surprisingly little overlap between document sets for the same information need, when documents were retrieved by different users or by the same user using controlled versus free-text vocabularies.
Reference: [11] <author> S.E. Robertson, </author> <title> "On relevance weight estimation and query expansion," </title> <journal> Journal of Documentation, </journal> <volume> Vol. 42, </volume> <pages> pp. 182-188, </pages> <year> 1986. </year>
Reference-contexts: i n i number of docs having term t i in the collection R total number of rel docs N number of docs in the collection Pr adj This adjusted probabilistic feedback formula is modified from the Pr cl formula by replacing the 0.5 adjustment factor with n i =N <ref> [11] </ref>. w 0 p i (1 q i ) p i = R + 1 n i r i + n i =N S rpi This is a simplified version of Fuhr's RPI formula that does not use a non-linear similarity function [6]. qi = log q i (1 p i
Reference: [12] <author> J.J.Jr. Rocchio, </author> <title> "Relevance feedback in information retrieval," The Smart system experiments in automatic document processing, </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall Inc., </publisher> <pages> pp. 313-323, </pages> <year> 1971. </year>
Reference-contexts: They are described in the following. Rocchio The new query vector Q new is the vector sum of the old query vector plus the vectors of the relevant and nonrelevant documents <ref> [12] </ref>.
Reference: [13] <author> G. Salton and M.J. McGill, </author> <title> Introduction to Modern Information Retrieval, </title> <publisher> McGraw-Hill, Inc., </publisher> <year> 1983. </year>
Reference-contexts: In section 5, we combine the results retrieved by the multiple query vectors. Finally, concluding remarks are given in section 6. 2 The SMART System The SMART system <ref> [13] </ref> has been developed at Harvard and Cornell Universities for over 35 years. The indexing of both queries and documents is completely automatic, and therefore human experts are not required for either the initial collection creation or the actual query formulation.
Reference: [14] <author> G. Salton and C. Buckley, </author> <title> "Term weighting approaches in automatic text retrieval," </title> <booktitle> Information Processing and Management, </booktitle> <volume> Vol. 24, No. 5, </volume> <pages> pp. 513-523, </pages> <year> 1988. </year>
Reference-contexts: the weights of coinciding terms in the two vectors, and therefore the term weighing scheme is an important factor affecting the effectiveness of SMART. 3 In constructing a term weighting scheme, three main components such as term frequency, collection frequency and normalization have been considered in the information retrieval literature <ref> [14] </ref>. First, the term frequency component assigns higher weights to the terms that occur more frequently in the text. Second, the collection frequency component assigns higher weights to the terms that occur in fewer documents of the collection.
Reference: [15] <author> G. Salton, </author> <title> Automatic Text Processing The Transformation, Analysis and Retrieval of Information by Computer, </title> <publisher> Addison-Wesley Publishing Co., </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: This means that retrieval results are reasonably collection independent and should be valid across a wide range of collections. SMART is based on the vector space model <ref> [15] </ref>, and transforms the description of information problems as well as the stored documents into vectors of the form: d i = (w i1 ; w i2 ; : : : ; w in ) where d i represents a document (or query) text and w ik is the weight of
Reference: [16] <author> G. Salton and C. Buckley, </author> <title> "Improving Retrieval Performance by Relevance Feedback," </title> <journal> Journal of the American Society for Information Science, </journal> <volume> Vol. 41, No. 4, </volume> <pages> pp. 288-297, </pages> <year> 1990. </year>
Reference-contexts: The documents are weighted with the lnc weighting scheme which is the same as the ltc query scheme, except no inverse document frequency factor is used. 3 Relevance Feedback Methods The relevance feedback process is an automatic process for query reformulation <ref> [16] </ref>. The main idea consists in choosing important terms in relevant documents, and of enhancing the weight of these terms in a new query formulation. Analogously, terms included in previously retrieved nonrelevant documents could be deemphasized in any future query formulation.
Reference: [17] <author> T. Saracevic and P. Kantor, </author> <title> "A study of information seeking and retrieving. III. Searchers, searches, overlap," </title> <journal> Journal of the American Society for Information Science, </journal> <volume> Vol. 39, No. 3, </volume> <pages> pp. 197-216, </pages> <year> 1988. </year>
Reference-contexts: They discovered the same phenomenon that the various document representations gave similar retrieval effectiveness, but retrieved quite different sets of documents. These results suggest that the combined run may retrieve more relevant documents than any individual run, therefore providing higher recall. Saracevic and Kantor <ref> [17] </ref> asked different experts to construct Boolean queries based on the same description of information problem in operational online information retrieval systems. Once again, they found that different query formulations generated different documents.
Reference: [18] <author> H. Turtle and W.B. Croft, </author> <title> "Evaluation of an inference network-based retrieval model," </title> <journal> ACM Transactions on Information Systems, </journal> <volume> Vol. 9, No. 3, </volume> <pages> pp. 187-222, </pages> <year> 1991. </year> <month> 14 </month>
Reference-contexts: If the combining method is designed to favor the documents retrieved by more retrieval runs, the combined run can result in more accurate similarity values between queries and documents, and therefore give higher precision. Turtle and Croft <ref> [18] </ref> developed an inference network-based retrieval model, which can combine different document representations and different versions of a query in a consistent probabilistic framework. Turtle and Croft implemented the INQUERY retrieval system based on the model, and demonstrated that multiple evidence increases retrieval effectiveness in some circumstances.
References-found: 18

