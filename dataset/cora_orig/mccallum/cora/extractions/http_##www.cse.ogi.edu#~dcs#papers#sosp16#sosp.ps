URL: http://www.cse.ogi.edu/~dcs/papers/sosp16/sosp.ps
Refering-URL: http://www.cse.ogi.edu/~dcs/
Root-URL: http://www.cse.ogi.edu
Email: dcs@cse.ogi.edu  
Title: Exploiting the Non-Determinism and Asynchrony of Set Iterators to Reduce Aggregate File I/O Latency  
Author: David C. Steere 
Affiliation: Department of Computer Science and Engineering Oregon Graduate Institute  
Abstract: A key goal of distributed systems is to provide prompt access to shared information repositories. The high latency of remote access is a serious impediment to this goal. This paper describes a new file system abstraction called dynamic sets unordered collections created by an application to hold the files it intends to process. Applications that iterate on the set to access its members allow the system to reduce the aggregate I/O latency by exploiting the non-determinism and asychrony inherent in the semantics of set iterators. This reduction in latency comes without relying on reference locality, without modifying DFS servers and protocols, and without unduly complicating the programming model. This paper presents this abstraction and describes an implementation of it that runs on local and distributed file systems, as well as the World Wide Web. Dynamic sets demonstrate substantial performance gains up to 50% savings in runtime for search on NFS, and up to 90% reduction in I/O latency for Web searches. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> ARNOLD, K., AND GOSLING, J. </author> <title> The Java Programming Language. The Java Series. </title> <publisher> Addison-Wesley, </publisher> <year> 1996, </year> <pages> pp. 221-223. </pages>
Reference-contexts: Additional support was provided by the IBM Corporation, Digital Equipment Corporation, and Intel Corporation. tors are a convenient mechanism for processing groups, as attested by the widespread use of iterator-like constructs such as cursors in SQL; foreach loops in shells like perl, tcl, and sh; the Enumeration class in Java <ref> [1] </ref>; and iterators in higher level languages like Alphard [33] and CLU [23]. Third, the use of iterators on sets of files could allow a system to transparently reduce the aggregate I/O latency of accessing the set members if the iterator was visible to the system.
Reference: [2] <author> BACH, M. J. </author> <title> The Design of the Unix Operating System. </title> <publisher> Prentice Hall, Inc. A division of Simon & Schuster, </publisher> <address> Englewood Cliffs, New Jersey 07632, </address> <year> 1986. </year> <title> Chapter 3: The Buffer Cache. </title>
Reference-contexts: One study found a 20x slow down in one case when prefetching data from disk on a parallel computer [21]. However, prefetching can produce substantial improvement if the access pattern is sufficiently regular and easily detected, such as Unix's one-block read-ahead mechanism <ref> [2, 34] </ref>. One way to avoid the problem of inaccurate predictions is to expose asynchronous I/O directly to applications, and let applications manage their I/O explicitly.
Reference: [3] <author> BAENTSCH, M., BAUM, L., MOLTER, G., ROTHKUGEL, S., AND STURM, P. </author> <title> Enhancing the web infrastructure from caching to replication. </title> <booktitle> IEEE Internet Computing 1, </booktitle> <month> 2 (Apr. </month> <year> 1997). </year> <note> Also available as http://www.computer.org/internet/9702/baentsch9702.htm. </note>
Reference-contexts: Second, search exhibits poor locality of reference and thus gets little benefit from caches. Studies of cache performance on the World Wide Web (Web) bear this out: Web proxy caches get low hit rates (30-40%) even with unlimited size and large user populations <ref> [11, 3, 9] </ref>.
Reference: [4] <author> BAKER, M. G., HARTMAN, J. H., KUPFER, M. D., SHIRRIFF, K., AND OUSTERHOUT, J. K. </author> <title> Measurements of a distributed file system. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles (October 1991). </booktitle>
Reference-contexts: However, the range of sizes under which dynamic sets offer greatest performance improvements covers most files in a typical Unix environment. Studies have shown median file sizes between 10KB and 16KB, and 80% to 90% of files are less than 50KB in size <ref> [4, 27, 32] </ref>. 5.5 Reordering In addition to the benefits of prefetching, dynamic sets allow the system to reorder fetches. Reordering is advantageous when I/O latency differs between members, such as when some members are in the cache when the set is created.
Reference: [5] <author> BOWMAN, M., SPASOJEVIC, M., AND SPECTOR, A. </author> <title> File system support for search. </title> <type> Transarc white paper, </type> <year> 1994. </year>
Reference-contexts: Separating the naming mechanism from the search tool in this way allows SETS to utilize a range of tools such as search-enhanced file systems <ref> [10, 24, 5] </ref>, Web search engines, and SQL databases. 4.2 SETS Prefetching Engine The prefetching engine prefetches set members, evaluates specifications, and manages local resources such as the buffer cache on behalf of SETS applications, and consists of a number of worker threads.
Reference: [6] <author> CAO, P., FELTEN, E. W., KARLIN, A., AND LI, K. </author> <title> A study of integrated prefetching and caching strategies. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems (May 1995). </booktitle>
Reference-contexts: The system can safely prefetch based on these hints, and the application is not complicated by the need to control prefetching or manage system resources. Recent studies by Patterson et al. [29], Cao et al. <ref> [6, 7] </ref>, and Kimbrel et al. [18] have found significant speedups from informed prefetch-ing in local file systems, particularly when reading data from multiple disks in parallel. These systems require application programmers to manually augment their code to pass hints of future block accessesto the file system.
Reference: [7] <author> CAO, P., FELTEN, E. W., AND LI, K. </author> <title> Implementation and performance of application-controlled file caching. </title> <booktitle> In Proceedings of the First USENIX Symposium on Operating Systems Design and Implementation (November 1994). </booktitle>
Reference-contexts: The system can safely prefetch based on these hints, and the application is not complicated by the need to control prefetching or manage system resources. Recent studies by Patterson et al. [29], Cao et al. <ref> [6, 7] </ref>, and Kimbrel et al. [18] have found significant speedups from informed prefetch-ing in local file systems, particularly when reading data from multiple disks in parallel. These systems require application programmers to manually augment their code to pass hints of future block accessesto the file system.
Reference: [8] <author> CUREWITZ, K. M., KRISHNAN, P., AND VITTER, J. S. </author> <title> Practical prefetching via data compression. </title> <booktitle> In Proceedings of the 1993 ACM Conf. on Management of Data (SIGMOD) (May 1993). </booktitle>
Reference-contexts: The drawbacks of prefetching are that one must somehow predict future accesses in order to prefetch the data, and inaccurate predictions increase the load on the I/O subsystem, and can lead to thrashing. Systems that infer future accesses based on past accesses <ref> [22, 8, 39, 28, 12] </ref> are most susceptible to this problem. One study found a 20x slow down in one case when prefetching data from disk on a parallel computer [21].
Reference: [9] <author> DUSKA, B., AND MARWOOD, D. </author> <note> Squid proxy analysis. Appeared in the Second Web Caching Workshop, </note> <institution> Boulder, Colorado, </institution> <month> June </month> <year> 1997. </year> <note> http://ircache.nlanr.net/Cache/Workshop97/, 1997. Also available as http://www.cs.ubc.ca/spider/marwood/Projects/SPA/Report/ Report.html. </note>
Reference-contexts: Second, search exhibits poor locality of reference and thus gets little benefit from caches. Studies of cache performance on the World Wide Web (Web) bear this out: Web proxy caches get low hit rates (30-40%) even with unlimited size and large user populations <ref> [11, 3, 9] </ref>.
Reference: [10] <author> GIFFORD, D. K., JOUVELOT, P., SHELDON, M. A., AND O'TOOLE, JR., J. W. </author> <title> Semantic file systems. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles (October 1991). </booktitle>
Reference-contexts: Separating the naming mechanism from the search tool in this way allows SETS to utilize a range of tools such as search-enhanced file systems <ref> [10, 24, 5] </ref>, Web search engines, and SQL databases. 4.2 SETS Prefetching Engine The prefetching engine prefetches set members, evaluates specifications, and manages local resources such as the buffer cache on behalf of SETS applications, and consists of a number of worker threads.
Reference: [11] <author> GLASSMAN, S. </author> <title> A caching relay for the world wide web. </title> <booktitle> Computer Networks and ISDN Systems 27, </booktitle> <address> 2 (Nov. </address> <year> 1994). </year> <note> Special Issue: selected papers from the First International WWW Conference. </note>
Reference-contexts: Second, search exhibits poor locality of reference and thus gets little benefit from caches. Studies of cache performance on the World Wide Web (Web) bear this out: Web proxy caches get low hit rates (30-40%) even with unlimited size and large user populations <ref> [11, 3, 9] </ref>.
Reference: [12] <author> GRIFFIOEN, J., AND APPLETON, R. </author> <title> The design, implementation, and evaluation of a predictive caching file system. </title> <type> Tech. Rep. </type> <institution> CS-264-96, Department of Computer Science, University of Kentucky, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: The drawbacks of prefetching are that one must somehow predict future accesses in order to prefetch the data, and inaccurate predictions increase the load on the I/O subsystem, and can lead to thrashing. Systems that infer future accesses based on past accesses <ref> [22, 8, 39, 28, 12] </ref> are most susceptible to this problem. One study found a 20x slow down in one case when prefetching data from disk on a parallel computer [21].
Reference: [13] <author> GRIMSHAW, A. S., AND LOYOT, E. C., J. </author> <title> ELFS: Object-oriented extensible file systems. </title> <type> Tech. Rep. </type> <institution> TR-91-14, Computer Science Department, University of Virginia, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: Dynamic sets can also be viewed as a higher-level microlan-guage for expressing near-future data accesses, which is used by the storage system to improve performance. Other examples of this approach include collective I/O operations in a parallel file system [20], application defined operations on structured files <ref> [13] </ref>, and domain specific microlanguages [30] such as complex-content multimedia specifications [36]. 3 Dynamic Sets To better understand how applications could use dynamic sets, consider a search using the Unix command grep, such as grep pattern *.c.
Reference: [14] <author> HOWARD, J., KAZAR, M., MENEES, S., NICHOLS, D., SATYA-NARAYANAN, M., SIDEBOTHAM, R., AND WEST, M. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM Trans. Comput. Syst. </journal> <volume> 6, </volume> <month> 1 (Feb. </month> <year> 1988). </year>
Reference-contexts: Caching is widely used, and is nearly ubiquitous in distributed file systems <ref> [14, 31, 26] </ref> in which accessing remote data incurs high latency. However, caching is effective only if applications exhibit temporal locality of reference. Prefetching does not rely on locality and so is more suited to applications with poor locality like search.
Reference: [15] <author> JACOBSON, V. </author> <title> Congestion avoidance control. </title> <booktitle> In Proceedings of the SIGCOMM '88 Conference on Comuunications Architectures and Protocols (1988). </booktitle>
Reference-contexts: On each call to the iterator, SETS starts a new prefetch, and thus automatically tunes the rate at which it prefetches files to the rate at which the application consumes them. This mechanism is similar to TCP's window-based flow control <ref> [15] </ref>, although currently there is no mechanism to dynamically change the window size. In addition, SETS needs to manage its consumption of the file system buffer cache to maximize the application's hite rate and to avoid overruning the cache.
Reference: [16] <author> JOSEPH, A. D., DELESPINASSE, A. F., TAUBER, J. A., GIFFORD, D. K., AND KAASHOEK, M. F. </author> <title> Rover: A toolkit for mobile information access. </title> <booktitle> In Proceedings of the 15th ACM Symposium on Operating Systems Principles (December 1995). </booktitle>
Reference-contexts: In addition, applications that manage I/O themselves are highly sensitive to changes in CPU or I/O speed, and are thus difficult to port or maintain. An example of explicit prefetching is the Queued RPC mechanism of the Rover toolkit <ref> [16] </ref>, which exposes asynchrony to application programmers and users. Although this can result in more efficient I/O, it requires the application programmer to poll to determine when an operation has completed and to maintain the operation's context until the operation terminates.
Reference: [17] <author> JOY, W. </author> <title> An introduction to the C shell. In Unix User's Manual, Supplementary Documents, </title> <editor> M. J. Karels and S. J. Leffler, Eds. </editor> <booktitle> Computer Science Division, </booktitle> <institution> Department of Electrical Engineering and Computer Science, University of California, </institution> <year> 1980. </year>
Reference-contexts: When the process exits, open sets are automatically destroyed and their resources freed. When a set is created, the creator supplies a specification that SETS evaluates to produce a list of the names of the set members. The specification language used by SETS extends the csh wildcard set notation <ref> [17] </ref> to support three types of specifications: explicit, interpreted, and executable. Figure 3 gives examples of each. Explicit specifications use standard csh wildcard notation, or globbing, to indicate the names of the members of the set. Interpreted specifications contain strings in some query language, such as SQL, delimited by n.
Reference: [18] <author> KIMBREL, T., TOKMINS, A., PATTERSON, R. H., BERSHAD, B., CAO, P., FELTEN, E. W., GIBSON, G. A., KARLIN, A. R., AND LI, K. </author> <title> A trace-driven comparison of algorithms for parallel prefetching and caching. </title> <booktitle> In Proceedings of the Second USENIX Symposium on Operating Systems Design and Implementation (Oct. </booktitle> <year> 1996). </year>
Reference-contexts: The system can safely prefetch based on these hints, and the application is not complicated by the need to control prefetching or manage system resources. Recent studies by Patterson et al. [29], Cao et al. [6, 7], and Kimbrel et al. <ref> [18] </ref> have found significant speedups from informed prefetch-ing in local file systems, particularly when reading data from multiple disks in parallel. These systems require application programmers to manually augment their code to pass hints of future block accessesto the file system.
Reference: [19] <author> KLEIMAN, S. Vnodes: </author> <title> An architecture for multiple file system types in Sun UNIX. </title> <booktitle> In Summer USENIX Conference Proceedings (Atlanta, </booktitle> <year> 1986). </year>
Reference-contexts: Wardens can run in the kernel, such as the NFS warden that is based on an in-kernel NFS client, or in user-level processes. User-level wardens communicate with SETS using an existing upcall mechanism [37] that passes VFS file system operations <ref> [19] </ref> to user-level DFS clients, caching data in the kernel to avoid upcalls where possible. I extended this mechanism with operations to prefetch a file, open a cursor for an interpreted specification, expand the cursor to retrieve the resulting filenames, and close the cursor.
Reference: [20] <author> KOTZ, D. </author> <title> Disk-directed I/O for MIMD multiprocessors. </title> <booktitle> In Proceedings of the First USENIX Symposium on Operating Systems Design and Implementation (November 1994). </booktitle>
Reference-contexts: Dynamic sets can also be viewed as a higher-level microlan-guage for expressing near-future data accesses, which is used by the storage system to improve performance. Other examples of this approach include collective I/O operations in a parallel file system <ref> [20] </ref>, application defined operations on structured files [13], and domain specific microlanguages [30] such as complex-content multimedia specifications [36]. 3 Dynamic Sets To better understand how applications could use dynamic sets, consider a search using the Unix command grep, such as grep pattern *.c.
Reference: [21] <author> KOTZ, D., AND ELLIS, C. </author> <title> Practical prefetching techniques for parallel file systems. </title> <booktitle> In Proceedings of the 1st International Conference on Parallel and Distributed Information Systems (Miami Beach, </booktitle> <address> Florida, </address> <month> Dec. </month> <year> 1992). </year>
Reference-contexts: Systems that infer future accesses based on past accesses [22, 8, 39, 28, 12] are most susceptible to this problem. One study found a 20x slow down in one case when prefetching data from disk on a parallel computer <ref> [21] </ref>. However, prefetching can produce substantial improvement if the access pattern is sufficiently regular and easily detected, such as Unix's one-block read-ahead mechanism [2, 34]. One way to avoid the problem of inaccurate predictions is to expose asynchronous I/O directly to applications, and let applications manage their I/O explicitly.
Reference: [22] <author> KUENNING, G. H. </author> <title> The design of the SEER predictive caching system. </title> <booktitle> In Proceedings of the Workshop on Mobile Computing Systems and Applications (Santa Cruz, </booktitle> <address> CA, </address> <month> Dec. </month> <year> 1994). </year>
Reference-contexts: The drawbacks of prefetching are that one must somehow predict future accesses in order to prefetch the data, and inaccurate predictions increase the load on the I/O subsystem, and can lead to thrashing. Systems that infer future accesses based on past accesses <ref> [22, 8, 39, 28, 12] </ref> are most susceptible to this problem. One study found a 20x slow down in one case when prefetching data from disk on a parallel computer [21].
Reference: [23] <author> LISKOV, B., AND GUTTAG, J. </author> <title> Abstraction and Specification in Program Development. The MIT EECS Series. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA ; McGraw-Hill, New York, </address> <year> 1986. </year>
Reference-contexts: Intel Corporation. tors are a convenient mechanism for processing groups, as attested by the widespread use of iterator-like constructs such as cursors in SQL; foreach loops in shells like perl, tcl, and sh; the Enumeration class in Java [1]; and iterators in higher level languages like Alphard [33] and CLU <ref> [23] </ref>. Third, the use of iterators on sets of files could allow a system to transparently reduce the aggregate I/O latency of accessing the set members if the iterator was visible to the system.
Reference: [24] <author> MANBER, U., AND WU, S. Glimpse: </author> <title> A tool to search through en-tire file systems. </title> <note> In Winter USENIX Conference Proceedings (1994). Also available as The University of Arizona Department of Computer Science Technical Report TR 93-34. </note>
Reference-contexts: The warden that interprets the query is not necessarily responsible for the files named by the query, for instance a GLIMPSE <ref> [24] </ref> warden could reference NFS files. The second example in Figure 3 would cause SETS to send the SQL query to a database mounted at /staff. <p> Separating the naming mechanism from the search tool in this way allows SETS to utilize a range of tools such as search-enhanced file systems <ref> [10, 24, 5] </ref>, Web search engines, and SQL databases. 4.2 SETS Prefetching Engine The prefetching engine prefetches set members, evaluates specifications, and manages local resources such as the buffer cache on behalf of SETS applications, and consists of a number of worker threads.
Reference: [25] <author> MOWRY, T. C., DEMKE, A. K., AND KRIEGER, O. </author> <title> Automatic compiler-inserted I/O prefetching for out-of-core applications. </title> <booktitle> In Proceedings of the Second USENIX Symposium on Operating Systems Design and Implementation (Oct. </booktitle> <year> 1996). </year>
Reference-contexts: These systems require application programmers to manually augment their code to pass hints of future block accessesto the file system. Mowry et al. describe a similar approach that uses compiler generated hints to pre-page in a virtual memory system <ref> [25] </ref>. Their compiler generates prefetch requests by analyzing program loops to determine near-future data accesses in virtual memory. Similar analysis allows the compiler to insert hints to release pages as well. The work described here is also a form of informed prefetching to reduce latency, but differs in several respects.
Reference: [26] <author> NELSON, M., WELCH, B., AND OUSTERHOUT, J. </author> <title> Caching in the Sprite Network File System. </title> <journal> ACM Trans. Comput. Syst. </journal> <volume> 6, </volume> <month> 1 (Feb. </month> <year> 1988). </year>
Reference-contexts: Caching is widely used, and is nearly ubiquitous in distributed file systems <ref> [14, 31, 26] </ref> in which accessing remote data incurs high latency. However, caching is effective only if applications exhibit temporal locality of reference. Prefetching does not rely on locality and so is more suited to applications with poor locality like search.
Reference: [27] <author> OUSTERHOUT, J. K., DA COSTA, H., HARRISON, D., KUNZE, J. A., KUPFER, M., AND THOMPSON, J. G. </author> <title> A trace-driven analysis of the UNIX 4.2 BSD file system. </title> <booktitle> In Proceedings of the 10th ACM Symposium on Operating Systems Principles (December 1985). </booktitle>
Reference-contexts: However, the range of sizes under which dynamic sets offer greatest performance improvements covers most files in a typical Unix environment. Studies have shown median file sizes between 10KB and 16KB, and 80% to 90% of files are less than 50KB in size <ref> [4, 27, 32] </ref>. 5.5 Reordering In addition to the benefits of prefetching, dynamic sets allow the system to reorder fetches. Reordering is advantageous when I/O latency differs between members, such as when some members are in the cache when the set is created.
Reference: [28] <author> PADMANABHAN, V. N., AND MOGUL, J. C. </author> <title> Using predictive prefetching to improve world wide web latency. </title> <journal> ACM SIGCOMM Computer Communication Review 26, </journal> <month> 3 (July </month> <year> 1996). </year>
Reference-contexts: The drawbacks of prefetching are that one must somehow predict future accesses in order to prefetch the data, and inaccurate predictions increase the load on the I/O subsystem, and can lead to thrashing. Systems that infer future accesses based on past accesses <ref> [22, 8, 39, 28, 12] </ref> are most susceptible to this problem. One study found a 20x slow down in one case when prefetching data from disk on a parallel computer [21].
Reference: [29] <author> PATTERSON, R. H., GIBSON, G. A., GINTING, E., STODOLSKY, D., AND ZELENKA, J. </author> <title> Informed prefetching and caching. </title> <booktitle> In Proceedings of the 15th ACM Symposium on Operating System Principles (Dec. </booktitle> <year> 1995). </year>
Reference-contexts: The system can safely prefetch based on these hints, and the application is not complicated by the need to control prefetching or manage system resources. Recent studies by Patterson et al. <ref> [29] </ref>, Cao et al. [6, 7], and Kimbrel et al. [18] have found significant speedups from informed prefetch-ing in local file systems, particularly when reading data from multiple disks in parallel. <p> However, controlling data layout in this manner is not practical in a real-world setting. An alternate strategy that avoided concurrently reading more than one file from the same disk should not suffer this problem. An extension of SETS to use a system like TIP2 <ref> [29] </ref> to manage local disk prefetching would have this property. 6 Dynamic Sets and the Web Having seen the benefit of dynamic sets in traditional file systems, it is natural to ask whether search on the World Wide Web could benefit from dynamic sets as well.
Reference: [30] <author> PU, C., BLACK, A., COWAN, C., WALPOLE, J., AND CONSEL, C. </author> <title> Microlanguages for operating system specialization. </title> <booktitle> In Proceedings of the SIGPLAN Workshop on Domain Specific Languages (Paris, </booktitle> <address> France, </address> <month> Jan. </month> <year> 1997). </year>
Reference-contexts: Other examples of this approach include collective I/O operations in a parallel file system [20], application defined operations on structured files [13], and domain specific microlanguages <ref> [30] </ref> such as complex-content multimedia specifications [36]. 3 Dynamic Sets To better understand how applications could use dynamic sets, consider a search using the Unix command grep, such as grep pattern *.c.
Reference: [31] <author> SANDBERG, R., GOLDBERG, D., KLEIMAN, S., WALSH, D., AND LYON, B. </author> <title> Design and implementation of the Sun Network File System. </title> <booktitle> In Summer USENIX Conference Proceedings, </booktitle> <address> Portland (1985). </address>
Reference-contexts: Caching is widely used, and is nearly ubiquitous in distributed file systems <ref> [14, 31, 26] </ref> in which accessing remote data incurs high latency. However, caching is effective only if applications exhibit temporal locality of reference. Prefetching does not rely on locality and so is more suited to applications with poor locality like search.
Reference: [32] <author> SATYANARAYANAN, M. </author> <title> A study of file sizes and functional lifetimes. </title> <booktitle> In Proceedings of the 8th ACM Symposium on Operating Systems Principles (December 1981). </booktitle>
Reference-contexts: However, the range of sizes under which dynamic sets offer greatest performance improvements covers most files in a typical Unix environment. Studies have shown median file sizes between 10KB and 16KB, and 80% to 90% of files are less than 50KB in size <ref> [4, 27, 32] </ref>. 5.5 Reordering In addition to the benefits of prefetching, dynamic sets allow the system to reorder fetches. Reordering is advantageous when I/O latency differs between members, such as when some members are in the cache when the set is created.
Reference: [33] <author> SHAW, M., WULF, W. A., AND LONDON, R. L. </author> <title> Abstraction and verification in Alphard: Defining and specifying iteration and generators. </title> <journal> Commun. ACM 20, </journal> <month> 8 (Mar. </month> <year> 1977). </year> <title> Reprinted in Tutorial: Programming Language Design, text for IEEE Tutorial by Anthony I. </title> <type> Wasserman, </type> <year> 1980, </year> <pages> pp. 145-155. </pages>
Reference-contexts: Equipment Corporation, and Intel Corporation. tors are a convenient mechanism for processing groups, as attested by the widespread use of iterator-like constructs such as cursors in SQL; foreach loops in shells like perl, tcl, and sh; the Enumeration class in Java [1]; and iterators in higher level languages like Alphard <ref> [33] </ref> and CLU [23]. Third, the use of iterators on sets of files could allow a system to transparently reduce the aggregate I/O latency of accessing the set members if the iterator was visible to the system.
Reference: [34] <author> SMITH, A. J. </author> <title> Disk cache miss ratio analysis and design considerations. </title> <journal> ACM Trans. Comput. Syst. </journal> <volume> 3, </volume> <month> 3 (Aug. </month> <year> 1985). </year>
Reference-contexts: One study found a 20x slow down in one case when prefetching data from disk on a parallel computer [21]. However, prefetching can produce substantial improvement if the access pattern is sufficiently regular and easily detected, such as Unix's one-block read-ahead mechanism <ref> [2, 34] </ref>. One way to avoid the problem of inaccurate predictions is to expose asynchronous I/O directly to applications, and let applications manage their I/O explicitly.
Reference: [35] <author> SPASOJEVIC, M., AND SATYANARAYANAN, M. </author> <title> A usage profile and evaluation of a wide-area distributed file system. </title> <booktitle> In Winter Usenix Conference Proceedings (San Francisco, </booktitle> <address> CA, </address> <year> 1994). </year>
Reference-contexts: For instance, the worker may move the member forward in the list of objects to be yielded when the fetch completes. 4.2.1 Prefetching Policy I designed the SETS's prefetching policy to work in an environment where remote access incurs a high latency, such as a wide-area DFS like AFS <ref> [35] </ref> or a mobile client connected over a low-bandwidth link. The policy has to balance conflicting goals: aggressive prefetching results in lower latencies, but may overwhelm disks, networks, or servers, resulting in thrashing and loss of performance.
Reference: [36] <author> STAEHLI, R. </author> <title> Quality of Service Specification for Resource Management in Multimedia Systems. </title> <type> PhD thesis, </type> <institution> Department of Computer Science and Engineering, Oregon Graduate Institute, </institution> <year> 1996. </year> <note> Available as ftp://cse.ogi.edu/pub/tech-reports/1996/96-TH-001.ps.gz. </note>
Reference-contexts: Other examples of this approach include collective I/O operations in a parallel file system [20], application defined operations on structured files [13], and domain specific microlanguages [30] such as complex-content multimedia specifications <ref> [36] </ref>. 3 Dynamic Sets To better understand how applications could use dynamic sets, consider a search using the Unix command grep, such as grep pattern *.c. Currently, the shell expands the wildcard *.c into an alphabetized list of filenames, and grep opens each of these files in that order.
Reference: [37] <author> STEERE, D., KISTLER, J., AND SATYANARAYANAN, M. </author> <title> Efficient user-level file cache management on the Sun vnode interface. </title> <booktitle> In Summer USENIX Conference Proceedings (Anaheim, </booktitle> <address> CA, </address> <year> 1990). </year>
Reference-contexts: Wardens can run in the kernel, such as the NFS warden that is based on an in-kernel NFS client, or in user-level processes. User-level wardens communicate with SETS using an existing upcall mechanism <ref> [37] </ref> that passes VFS file system operations [19] to user-level DFS clients, caching data in the kernel to avoid upcalls where possible.
Reference: [38] <author> STEERE, D. C. </author> <title> Using Dynamic Sets to Reduce the Aggregate Latency of Data Access. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1997. </year> <note> Available as technical report CMU-CS-96-194. </note>
Reference-contexts: In addition, two experiments examine the effect of reordering and the benefits of dynamic sets for search on a local file system. A more complete set of experiments, including low bandwidth and interactive search tests, is described elsewhere <ref> [38] </ref>. 5.1 Test Methodology The experiments use a benchmark program called synthGrep to generate a workload for the system. <p> The traces were replayed during peak hours (afternoon EST) for greatest realism; other experiments that replay the traces on weekends, without loading inlined images, and over a phone line see vastly different latencies but similar relative benefits from the use of sets to those shown here <ref> [38] </ref>. by search task and averaged over 5 runs. Each bar consists of three parts: the user think time captured in the trace, CPU time to fetch and display the images, and the latency seen by Mosaic. <p> As a result, the system can prefetch without accurate predictions of latency by fetching a small number of objects concurrently and opportunistically yielding the first to return. 8 Acknowledgements This paper describes work originally presented in my thesis <ref> [38] </ref> performed while I was a doctoral student in the School of Computer Science at Carnegie Mellon University. My advisor, M. Satyanarayanan, made significant contributions to the work, as did my thesis committee - Garth Gibson, Jeannette Wing, and Hector Garcia-Molina.
Reference: [39] <author> TAIT, C. D., AND DUCHAMP, D. </author> <title> Detection and exploitation of file working sets. </title> <booktitle> In Proceedings of the 11th International Conference on Distributed Com puting Systems (Arlington, </booktitle> <address> TX, </address> <year> 1991). </year>
Reference-contexts: The drawbacks of prefetching are that one must somehow predict future accesses in order to prefetch the data, and inaccurate predictions increase the load on the I/O subsystem, and can lead to thrashing. Systems that infer future accesses based on past accesses <ref> [22, 8, 39, 28, 12] </ref> are most susceptible to this problem. One study found a 20x slow down in one case when prefetching data from disk on a parallel computer [21].
Reference: [40] <institution> WEBCOMPASS 1.0. Quarterdeck, Corp. Marina del Ray, CA. </institution> <note> (800) 683-6696. Additional information is available at http://www.quarterdeck.com. </note>
Reference-contexts: If a user decides that she might wish to visit some number of the links on a page, she could create a set by selecting these links and then iterate on the set to view the members. Tools that provide this capability, such as WebCompass <ref> [40] </ref>, are available, but only prefetch members of predefined sets well in advance of a search.
Reference: [41] <author> WING, J., AND STEERE, D. </author> <title> Specifying weak sets. </title> <booktitle> In Proceedings of the International Conference on Distributed Computer Systems (Van-couver, </booktitle> <month> June </month> <year> 1995). </year> <note> Also available as Carnegie Mellon University School of Computer Science technical report CMU-CS-94-194. </note>
Reference-contexts: However, it can be expensive in system complexity and performance to provide these properties <ref> [41] </ref>. Further, dynamic sets are layered on top of existing systems for simplicity, and as such cannot provide a stronger consistency model than the underlying system. Fortunately, many searches on DFS are satisfied without strong consistency guarantees, as the widespread use of these systems can attest.
References-found: 41

