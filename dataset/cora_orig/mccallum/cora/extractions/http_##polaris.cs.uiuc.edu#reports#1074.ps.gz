URL: http://polaris.cs.uiuc.edu/reports/1074.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: Synchronous Parallel Discrete Event Simulation on Shared-Memory Multiprocessors  
Author: Pavlos Konas and Pen-Chung Yew 
Address: Street, Urbana, IL 61801.  
Affiliation: Center for Supercomputing Research and Development, 305 Talbot Laboratory, 104 S. Wright  
Abstract: This paper describes the implementation and studies the performance of a synchronous, parallel discrete event simulation (SPDES) method on a shared memory multiprocessor. The presented method aims at the efficient simulation of architectural designs for which the asynchronous PDES methods seem to be less effective. A multiprocessor machine is simulated, and the performance achieved is compared to the performance of a parallel version of the synchronous event-driven simulation method (Parsim). The results show that the SPDES method alleviates bottlenecks usually attributed to synchronous methods, and thus we are able to efficiently exploit most of the parallelism available in the simulation of synchronous architectural designs.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Ayani. </author> <title> A Parallel Simulation Scheme Based on Distances Between Objects. </title> <booktitle> Proceedings of the SCS Western Multiconference, </booktitle> <volume> 21(2) </volume> <pages> 113-118, </pages> <month> March, </month> <year> 1989. </year>
Reference-contexts: The speedups achieved by this algorithm on a 16-processor Sequent Symmetry range between 8 (for a 5-stage network), and 14 (for a 9-stage network). 3 Ayani and Rajaei [2] use a conservative but deadlock free algorithm, called the three-phase algorithm <ref> [1] </ref>, to simulate another class of MINs, called Generalized Cube Networks (GCMIN), on a 16-processor Sequent Symmetry. The speedup they obtain increases as the size of the MIN increases and becomes almost linear for MINs with more than 256 inputs.
Reference: [2] <author> R. Ayani and H. Rajaei. </author> <title> Parallel Simulation of a Generalized Cube Multistage Interconnection Network. </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <volume> 22(1) </volume> <pages> 60-63, </pages> <month> January, </month> <year> 1990. </year>
Reference-contexts: The speedups achieved by this algorithm on a 16-processor Sequent Symmetry range between 8 (for a 5-stage network), and 14 (for a 9-stage network). 3 Ayani and Rajaei <ref> [2] </ref> use a conservative but deadlock free algorithm, called the three-phase algorithm [1], to simulate another class of MINs, called Generalized Cube Networks (GCMIN), on a 16-processor Sequent Symmetry.
Reference: [3] <author> B. Berkman and R. Ayani. </author> <title> Parallel Simulation of Multistage Interconnection Networks on a SIMD Computer. </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <volume> 23(1) </volume> <pages> 133-140, </pages> <month> January, </month> <year> 1991. </year>
Reference-contexts: However, the absolute speedups they obtained are slightly optimistic due to the suboptimal implementation of the sequential simulator. The relative speedups they present are lower than the absolute ones and range between 1 and 9 for the largest MIN (512-input) simulated. In a follow-up paper, Ayani and Berkman <ref> [3] </ref> simulate the GCMIN using the three-phase algorithm on a CM-2 with 8,192 processors. Even though they achieve speedups of more than 2,000 for networks with 14 stages, the efficiency of their implementation is considerably low -25% at best.
Reference: [4] <author> J. Bruner, H. Cheong, A. Veidenbaum, and P.-C. Yew. </author> <title> Chief: A Parallel Simulation Environment for Parallel Systems. </title> <booktitle> Proceedings of the 5th International Parallel Processing Symposium, </booktitle> <pages> pages 568-575, </pages> <month> April, </month> <year> 1991. </year>
Reference-contexts: One way to simulate synchronous systems efficiently, is to parallelize the traditional synchronous event-driven algorithm [15]. Parsim is one example of such a parallel implementation. Parsim is a parallel, synchronous event-driven method <ref> [4] </ref>. In Parsim the studied system is modeled as a set of components each of which represents part of the physical system. A component has zero or more inputs, from where it receives new values, and zero or more outputs where it sends new values.
Reference: [5] <author> K.M. Chandy and J. Misra. </author> <title> Distributed Simulation: A Case Study in Design and Verification of Distributed Programs. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-5(5):440-452, </volume> <month> September, </month> <year> 1979. </year>
Reference-contexts: Even though they achieve speedups of more than 2,000 for networks with 14 stages, the efficiency of their implementation is considerably low -25% at best. Konas and Yew [12] compare the performance of a parallel version of the traditional event driven method to the Chandy-Misra <ref> [5] </ref> and Time Warp [10] methods in simulating a synchronous multiprocessor system. The results they present show that the synchronous method is considerably faster than both the Chandy-Misra and the Time Warp approaches.
Reference: [6] <author> R.M. Fujimoto. </author> <title> Parallel Discrete Event Simulation. </title> <journal> Communications of the ACM, </journal> <volume> 33(10) </volume> <pages> 31-53, </pages> <month> October, </month> <year> 1990. </year>
Reference-contexts: In order to avoid these potential problems and reduce the overhead introduced by the simulation method, we propose a conservative synchronous parallel simulation method. Our approach is based on the logical processes model <ref> [6] </ref>. The simulator consists of a set of (communicating) logical processes (LPs), each of which represents a component of the simulated system. Each LP has a single, time-ordered, input (event) queue which acts as its local event list.
Reference: [7] <author> D. Gajski, D.J. Kuck, D.H. Lawrie, and A.H. Sameh. </author> <title> CEDAR A Large Scale Multiprocessor. </title> <booktitle> Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages 524-529, </pages> <month> August, </month> <year> 1983. </year>
Reference-contexts: This system represents many parallel shared memory architectures found in practice <ref> [9, 7, 14] </ref>. During the simulation each processor calculates requests for the memories and transmits them to the appropriate memories through the forward Omega network.
Reference: [8] <author> P.K. Goli, P. Heidelberger, D.F. Towsley, and Q. Yu. </author> <title> Processor Assignment and Synchronization in Parallel Simulation of Multistage Interconnection Networks. </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <volume> 22(1) </volume> <pages> 181-187, </pages> <month> January, </month> <year> 1990. </year>
Reference-contexts: The multibarrier approach achieves the best performance among the three alternatives and delivers speedups between 4 (for a 4-stage network), and 7 (for a 9-stage network), on an 8-processor Sequent Symmetry. In a follow-up paper <ref> [8] </ref>, they present an improved processor allocation and synchronization algorithm, called the two-phase algorithm, which exploits the network's topological structure.
Reference: [9] <author> A. Gottlieb, R. Grishman, C. Kruskal, K. McAliffe, L. Rudolph, and M. Snir. </author> <title> The NYU Ul-tracomputer Designing an MIMD Shared Memory Parallel Computer. </title> <journal> IEEE Transaction on Computers, </journal> <volume> C-32(2):175-189, </volume> <month> February, </month> <year> 1983. </year>
Reference-contexts: This system represents many parallel shared memory architectures found in practice <ref> [9, 7, 14] </ref>. During the simulation each processor calculates requests for the memories and transmits them to the appropriate memories through the forward Omega network.
Reference: [10] <author> D.R. Jefferson. </author> <title> Virtual Time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(3) </volume> <pages> 404-425, </pages> <month> July, </month> <year> 1985. </year>
Reference-contexts: Even though they achieve speedups of more than 2,000 for networks with 14 stages, the efficiency of their implementation is considerably low -25% at best. Konas and Yew [12] compare the performance of a parallel version of the traditional event driven method to the Chandy-Misra [5] and Time Warp <ref> [10] </ref> methods in simulating a synchronous multiprocessor system. The results they present show that the synchronous method is considerably faster than both the Chandy-Misra and the Time Warp approaches.
Reference: [11] <author> P. Konas. </author> <title> Parallel Discrete Event Simulation on Shared Memory Multiprocessors. </title> <type> Master's thesis, </type> <institution> Computer Science Department, University of Illinois at Urbana-Champaign, </institution> <month> May, </month> <year> 1991. </year>
Reference-contexts: Time Warp, on the other hand, introduces the state saving overhead and is not expected to perform well in detailed architectural simulations because such simulators tend to have components with large state sizes. In an associated report <ref> [11] </ref>, Konas observes that although the synchronous method is faster than both the asynchronous approaches, its efficiency is considerably lower.
Reference: [12] <author> P. Konas and P.-C. Yew. </author> <title> Parallel Discrete Event Simulation on Shared-Memory Multiprocessors. </title> <booktitle> Proceedings of the 24th Annual Simulation Symposium, </booktitle> <volume> 21(3) </volume> <pages> 134-148, </pages> <month> April, </month> <year> 1991. </year>
Reference-contexts: In a follow-up paper, Ayani and Berkman [3] simulate the GCMIN using the three-phase algorithm on a CM-2 with 8,192 processors. Even though they achieve speedups of more than 2,000 for networks with 14 stages, the efficiency of their implementation is considerably low -25% at best. Konas and Yew <ref> [12] </ref> compare the performance of a parallel version of the traditional event driven method to the Chandy-Misra [5] and Time Warp [10] methods in simulating a synchronous multiprocessor system. The results they present show that the synchronous method is considerably faster than both the Chandy-Misra and the Time Warp approaches.
Reference: [13] <author> D.H. Lawrie. </author> <title> Access and Alignment of Data in an Array Processor. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-24:1145-1155, </volume> <month> December, </month> <year> 1975. </year> <month> 22 </month>
Reference-contexts: significantly the number of events that have to be evaluated during the course of the simulation. 11 5 The Simulated System In order to study the performance of the implemented simulation method, we examined a behavioral model of a synchronous multiprocessor system: a 16-processor/16-memory system with an Omega interconnection network <ref> [13] </ref>. This system represents many parallel shared memory architectures found in practice [9, 7, 14]. During the simulation each processor calculates requests for the memories and transmits them to the appropriate memories through the forward Omega network.
Reference: [14] <author> G.F. Pfister, W.C. Brantley, D.A. George, S.L. Harvey, W.J.Kleinfekder, K.P. McAuliffe, E.A. Melton, V.A. Norton, and J. Weiss. </author> <title> The IBM Research Parallel Processor Prototype (RP3): Introduction and Architecture. </title> <booktitle> Proceedings of the 12th International Symposium on Computer Architecture, </booktitle> <pages> pages 764-771, </pages> <month> June, </month> <year> 1985. </year>
Reference-contexts: This system represents many parallel shared memory architectures found in practice <ref> [9, 7, 14] </ref>. During the simulation each processor calculates requests for the memories and transmits them to the appropriate memories through the forward Omega network.
Reference: [15] <author> L. Soule and T. Blank. </author> <title> Parallel Logic Simulation on General Purpose Machines. </title> <booktitle> Proceedings of the 25th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 166-171, </pages> <month> March, </month> <year> 1988. </year>
Reference-contexts: Therefore, the key issue in these simulations is how to exploit the large amounts of available parallelism with the least possible overhead. One way to simulate synchronous systems efficiently, is to parallelize the traditional synchronous event-driven algorithm <ref> [15] </ref>. Parsim is one example of such a parallel implementation. Parsim is a parallel, synchronous event-driven method [4]. In Parsim the studied system is modeled as a set of components each of which represents part of the physical system.
Reference: [16] <author> Q. Yu, D. Towsley, and P. Heidelberger. </author> <title> Time-Driven Parallel Simulation of Multistage Interconnection Networks. </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <volume> 21(2) </volume> <pages> 191-196, </pages> <month> March, </month> <year> 1989. </year> <month> 23 </month>
Reference-contexts: Section 5 describes the simulated system and Section 6 presents the experiments we performed on the Alliant and the results we obtained. Finally, our conclusions as well as future directions are discussed in Section 7. 2 Related Work Yu et al. <ref> [16] </ref> use a time-driven algorithm to simulate a class of Multistage Interconnection Networks (MINs) called Buffered Delta Networks. In their work, they focus on the synchronization of the processors within and between time steps and present three approaches for handling the problem: multibarriers, locks, and temporary storage.
References-found: 16

