URL: http://www.cs.cornell.edu/Info/People/ronitt/PAP/par.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/ronitt/papers.html
Root-URL: 
Title: Designing Checkers for Programs that Run in Parallel  
Author: Ronitt Rubinfeld 
Date: September 22, 1994  
Abstract: Program correctness for parallel programs is an even more problematic issue than for serial programs. We extend the theory of program result checking to parallel programs, and find general techniques for designing such result checkers that work for many basic problems in parallel computation. These result checkers are simple to program and are more efficient than the actual computation of the result. For example, sorting, multiplication, parity, the all pairs shortest path problem and majority all have constant depth result checkers, and the result checkers for all but the last problem use a linear number of processors. We show that there are P-complete problems (evaluating straight-line programs, linear programming) that have very fast, even constant depth, result checkers. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adleman, L., Huang, M., Kompella, K., </author> <title> "Efficient Checkers for Number-Theoretic Computations", </title> <note> To appear in Information and Computation. </note>
Reference-contexts: For example, we show that there are P-complete problems (evaluating straight-line programs, linear programming) that have very fast, even constant depth, parallel result checkers. Integer GCD is not known to be in RNC, yet a logarithmic depth parallel result checker exists for it <ref> [1] </ref>. Maximum Matching is not known to be in NC (though it is in RNC), and it has a deterministic NC result checker.
Reference: [2] <author> Aggarwal, A., Anderson, R., </author> <title> "A random NC algorithm for depth first search", </title> <booktitle> Combinatorica 8 (1988), </booktitle> <pages> pp. 1-12. </pages>
Reference-contexts: The output is a rooted tree T which can be obtained by peforming a depth first search on G, starting from r. No "efficient" parallel algorithm for this problem is known. It was shown to be in RNC by Aggarwal and Anderson <ref> [2] </ref>. The checker first confirms that T is a tree, by checking that T is connected and has n 1 edges. Then, the checker confirms that all non-tree edges (v; u) are backedges; i.e. that either v is an ancestor of u or u is an ancestor of v.
Reference: [3] <author> Aggarwal, A., Chazelle, B., Guibas, L., O'Dunlaing, C., Yap, C., </author> <title> "Parallel Computational Geometry", </title> <booktitle> Algorithmica 3 (1988), </booktitle> <pages> pp. 293-327. </pages>
Reference-contexts: This description will be a list of vertices of the convex hull in counter clockwise order around the hull. Model of Computation: CRCW PRAM in which arithmetic operations (+; ; ; =) on real numbers can be performed in one step. 10 The best algorithm for this problem in <ref> [3] </ref> runs in O (log n) depth and uses O (n) processors.
Reference: [4] <author> Alon, N., Babai, L., Itai, </author> <title> "A Fast and Simple Randomized Parallel Algorithm for the Maximal Independent Set Problem", </title> <journal> J. of Algorithms, </journal> <volume> vol. 7, </volume> <year> 1986, </year> <pages> pp. 567-583. </pages>
Reference: [5] <author> Amato, N., Preparata, F., </author> <title> "An NC 1 Parallel 3D Convex Hull Algorithm", </title> <booktitle> In Proc. of Computational Geometry 1993, </booktitle> <pages> pp. 289 - 297. </pages>
Reference-contexts: Model of Computation: CRCW PRAM in which arithmetic operations on real numbers can be performed in one step. The best known parallel algorithm from 3D convex hull mentioned in <ref> [5] </ref> requires O (log n) time with O (n 1+ff ) processors.
Reference: [6] <author> Beame, P., Hastad, J., </author> <title> "Optimal Bounds for Decision Problems on the CRCW PRAM", </title> <editor> J. </editor> <booktitle> ACM 36 (1989), </booktitle> <pages> pp. 643-670. </pages>
Reference-contexts: Maximum Matching is not known to be in NC (though it is in RNC), and it has a deterministic NC result checker. Multiplication, parity and majority all have lower bounds of (log n= log log n) depth <ref> [6] </ref> when computed with a polynomial number of processors, yet all have (completely different) constant depth result checkers. 2 The Parallel Program Result Checking Model In this section, we describe the extension of the program result checking model proposed in [7] to result checking for parallel programs. <p> Output: b = t l where l = 1jn a j . The majority, exactly l and parity functions are all examples of symmetric functions. As mentioned before, <ref> [6] </ref> show that (log n= log log n) depth is required to compute these functions. For these and other examples, no table is needed as input because each t i can be computed in constant depth by the result checker. <p> Any algorithm using only a polynomial number of processors for prefix sums, sum, parity and integer multiplication provably requires (log n= log log n) depth <ref> [6] </ref> Straight-line programming is P-complete. 4.1 Problems that can be solved using Dynamic Programming Dick Karp has pointed out that the basic technique described in this section can be used to check any problem that can be solved sequentially using dynamic programming, regardless of the algorithm used by the program.
Reference: [7] <author> Blum, M., Kannan, S., </author> <title> "Program Correctness Checking ... and the design of programs that check their work", </title> <booktitle> 22nd Symp. on Theory of Computing, </booktitle> <address> pp.86-97, </address> <year> 1989. </year>
Reference-contexts: Even the seemingly simplest of programs can be full of hidden bugs, and in the age of massive software projects, this problem is becoming increasingly important. The complexity of programming parallel computers is even greater. A general theory of result checking algorithms was given in <ref> [7] </ref>. This approach recognizes that proving programs correct is very difficult to do, and with this in mind, aims at the easier task of checking that a program is correct on any given input. <p> have lower bounds of (log n= log log n) depth [6] when computed with a polynomial number of processors, yet all have (completely different) constant depth result checkers. 2 The Parallel Program Result Checking Model In this section, we describe the extension of the program result checking model proposed in <ref> [7] </ref> to result checking for parallel programs. <p> In both cases, we ignore the dependence on the confidence parameter ff. In all of the examples, the result checker first calls the program on the input which is being checked. The problem remains of determining the correctness of the result checker. In the sequential setting, <ref> [7] </ref> suggests that instead, the result checker should be forced to be quantifiably "different" than any program for f by limiting the checking time to be less than that of the fastest correct program known for computing the function. <p> The first task is quite easy, but the second task is nontrivial, and on the algebraic decision tree model, is as difficult a task as sorting. In <ref> [7] </ref> there are randomized algorithms for verifying that X = Y which use hashing and run in O (n) time. We present a deterministic algorithm which checks sorting in O (1) parallel time and O (n) processors. <p> Proposition: Let 1 ; 2 be two AC 0 equivalent computational problems. Then from any fast program result checker C 1 for 1 , it is possible to construct a fast program result checker C 2 for 2 . Proof: Similar to Beigel's trick described in <ref> [7] </ref>. We outline the proof for decision problems, but the general proof is similar. The idea is to construct a program result checker for 2 by transforming 13 it to an instance of 1 and result checking that instance.
Reference: [8] <author> Blum, M., Luby, M., Rubinfeld, R., </author> <title> "Self-Testing/Correcting with Applications to Numerical Problems," </title> <journal> J. Comp. Sys. Sci. </journal> <volume> Vol. 47, No. 3, </volume> <month> December </month> <year> 1993. </year> <month> 14 </month>
Reference-contexts: Many of the result checkers have the property that the total number of processors used is big oh of the number of processors used by the program (e.g. sorting, parity, convex hull) 3 Computability by Random Inputs In <ref> [8] </ref> it is shown that one can design result checkers for many functions that have the property of random self-reducibility that the function can be computed by computing the function on one or more "random" instances. <p> However, the techniques in this chapter are applicable to other functions as well. For example, the running time of the sequential checker for the matrix rank function given in <ref> [8] </ref> can be dramatically improved using the technique given in Section 3.2. <p> O (log fl n + D (n)) and the total number of processors is O (n + N (n)). 3.3 Randomly Self-Reducible, Linear and Smaller Self-Reducible Problems If the program computes a function which is randomly self-reducible and either has the linearity property or is self-reducible to smaller inputs (see <ref> [8] </ref> for a definition), the general techniques described in [8] can be parallelized. This gives constant depth efficient result checkers for checking numerical problems such as integer multiplication, integer division, mod, modular multiplication, modular exponentiation, polynomial multiplication, squaring and matrix multiplication. <p> total number of processors is O (n + N (n)). 3.3 Randomly Self-Reducible, Linear and Smaller Self-Reducible Problems If the program computes a function which is randomly self-reducible and either has the linearity property or is self-reducible to smaller inputs (see <ref> [8] </ref> for a definition), the general techniques described in [8] can be parallelized. This gives constant depth efficient result checkers for checking numerical problems such as integer multiplication, integer division, mod, modular multiplication, modular exponentiation, polynomial multiplication, squaring and matrix multiplication.
Reference: [9] <author> Chandra, A., Fortune, S., Lipton, R., </author> <title> "Unbounded Fan-in Circuits and Associative Functions", </title> <journal> J. Comput. System Sci. </journal> <volume> 30 (1985), </volume> <pages> pp. 222-234. </pages>
Reference: [10] <author> Chandra, A., Stockmeyer, L., Vishkin, U., </author> <title> "Constant Depth Reducibility", </title> <journal> SIAM J. on Com-put.13 (1984),pp. </journal> <pages> 423-439. </pages>
Reference-contexts: The best algorithm for multiplication takes O (log n= log log n) time and O (n 1+* ) (* &gt; 0) operations, by combining [27] with <ref> [10] </ref>. The total time is O (D (n)) with O (n fi A (n) + n fi N (n)) total processors. Because of the following known results, all the checkers presented in this section are quantifiably different.
Reference: [11] <author> Cole, R., Vishkin, U., </author> <title> "Faster optimal parallel prefix sums and list ranking", </title> <booktitle> Information and Computation 70 (1986), </booktitle> <pages> 32-53. </pages>
Reference-contexts: Because of the following known results, all the checkers presented in this section are quantifiably different. When the input consists of integers, the best known algorithm for prefix sums uses O (n= log n) processors and O (log n= log log n) depth <ref> [11] </ref>.
Reference: [12] <author> Furst, M., Saxe, J., Sipser, M., </author> <title> "Parity, Circuits and the Polynomial Time Hierarchy," </title> <journal> Math. Systems Theory, </journal> <volume> vol. 17, </volume> <year> 1984, </year> <month> pp.13-28. </month>
Reference: [13] <author> Gazit, H., </author> <title> "An Optimal Randomized Parallel Algorithm for Finding Connected Components in a Graph", </title> <booktitle> in Proceedings Foundations of Computer Science, </booktitle> <pages> pp. 492-501, </pages> <year> 1986. </year>
Reference-contexts: Connectivity can be determined in O (log n) expected time and O ( m+n log n ) processors using the techniques of <ref> [13] </ref>. Finding lowest common ancestors for all edges can be done in O (log n) time using O (n= log n) processors [26]. In the problem of constructing a breadth first search tree, the input is an undirected graph G and some node r in G.
Reference: [14] <author> Goldberg, M., Spencer, T., </author> <title> "A New Parallel Algorithm for the Maximal Independent Set Problem," </title> <booktitle> FOCS 1987. </booktitle>
Reference: [15] <author> Gross, M., Irani, S., Rubinfeld, R., Seidel, R., </author> <type> personal communication. </type>
Reference-contexts: This can be done in constant parallel time with O (n 2 ) processors. The following algorithm result checks planar convex hull in a way that is is more efficient with processors. Result Checking Algorithm: This result checker is a parallel implementation of the sequential result checker of <ref> [15] </ref>. The result checker must verify that the polygon described in the output is simple and convex. This is done by assigning a processor to each vertex of the hull in order to verify that a left turn is made by the two edges adjacent to this vertex.
Reference: [16] <author> Leighton, F. T., </author> <title> Introduction to Parallel Algorithms and Architectures: arrays, trees, hyper-cubes, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1992. </year>
Reference-contexts: All of the examples in this paper are written for the arbitrary and priority CRCW PRAM models (cf. pages 698-700 of <ref> [16] </ref> for definitions of models). The difference in the complexity of solving a problem in parallel with a polynomial number of processors, as compared to the depth complexity of result checking a problem (again with a polynomial number of processors) is often very dramatic.
Reference: [17] <author> Luby, M., </author> <title> "A Simple Parallel Algorithm for the Maximal Independent Set Problem", </title> <journal> SIAM J. Comput., </journal> <volume> vol. 15, </volume> <year> 1986, </year> <pages> pp. 1036-1053. </pages>
Reference: [18] <author> Kannan, S., </author> <title> "Program Result Checking with Applications", </title> <type> Ph.D. thesis, </type> <institution> U.C. Berkeley, </institution> <year> 1990. </year>
Reference-contexts: This problem is P-complete, so no fast parallel algorithm is known for it. However, it can be result checked in logarithmic time with only two calls to the program using an obvious parallelization of the techniques in <ref> [18] </ref>. Another example is the following: Maximum Matching Input: Graph G = (V; E), where E is represented by an adjacency matrix.
Reference: [19] <author> Karloff, H., </author> <title> "A Las Vegas RNC Algorithm for Maximum Matching," </title> <journal> Combinatorica, </journal> <volume> vol. 6, </volume> <year> 1986, </year> <month> pp.387-392. </month>
Reference-contexts: Result Checking Algorithm: The result checker first checks in parallel that no vertex is matched more than once and that the maximum matching is of size k. Then the algorithm in <ref> [19] </ref> is used to find a proof that there is no matching of size k. This proof will be an odd set cover of size k. Karloff's algorithm calls a matching oracle on other problem instances.
Reference: [20] <author> Karp, R., Ramachandran, V., </author> <title> "A Survey of Parallel Algorithms for Shared-Memory Machines", </title> <type> UC Berkeley Technical Report No. </type> <note> UCB/CSD 88/408. </note>
Reference: [21] <author> Karp, R., Upfal, E., Wigderson, </author> <title> A.,"Constructing a perfect matching is in random NC", </title> <journal> Combinatorica, </journal> <volume> vol. 6, </volume> <year> 1986, </year> <month> pp.35-48. </month>
Reference: [22] <author> Karp, R., Upfal, E., Wigderson, </author> <title> A.,"The Complexity of Parallel Search", </title> <journal> J. Comp. Syst. Sci., </journal> <volume> vol. 36, </volume> <year> 1988, </year> <pages> pp. 225-253. </pages>
Reference: [23] <author> Matias, Y., Vishkin, U., </author> <title> "Converting High Probability into Nearly-Constant Time with Applications to Parallel Hashing", </title> <booktitle> Symp. on Theory of Computing 1991, </booktitle> <address> pp.307-316. </address>
Reference-contexts: Therefore, even if the result checker cannot determine which equivalence class the input is in, it can verify that the answer of P on the input is correct. In the result checking algorithm, several random permutations of the input bits are made; <ref> [23] </ref> provides a way of doing this in O (log fl n) depth with linear processors (and O (log fl n log log fl n) depth with an optimal number of processors). They also show how to do it in O (1) depth and O (n log n) processors.
Reference: [24] <author> Mulmuley, K., Vazirani, U., Vazirani, V., </author> <title> "Matching is as Easy as Matrix Inversion", </title> <address> Combi-natorica 7, </address> <year> (1987), </year> <pages> pp. 105-113. </pages>
Reference-contexts: Output: k = the size of a maximum matching, and the edges in a maximum matching in G No deterministic NC algorithm is known for this problem, but it is known to be in RNC ([21], <ref> [24] </ref>). Result Checking Algorithm: The result checker first checks in parallel that no vertex is matched more than once and that the maximum matching is of size k. Then the algorithm in [19] is used to find a proof that there is no matching of size k.
Reference: [25] <author> Preparata, F., Shamos, M., </author> <title> Computational Geometry: An Introduction. </title> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference: [26] <author> Schieber, B., Vishkin, U., </author> <title> "On Finding Lowest Common Ancestors: Simplification and Paral-lelization", </title> <journal> SIAM J. Comput. </journal> <volume> Vol 17, No. 6, </volume> <month> December </month> <year> 1988. </year>
Reference-contexts: Connectivity can be determined in O (log n) expected time and O ( m+n log n ) processors using the techniques of [13]. Finding lowest common ancestors for all edges can be done in O (log n) time using O (n= log n) processors <ref> [26] </ref>. In the problem of constructing a breadth first search tree, the input is an undirected graph G and some node r in G. The output is a rooted (directed) tree T which can be obtained by performing a breadth first search on G, starting from r.
Reference: [27] <author> Schonhage, A., Strassen, V., "Schnelle Multiplikation grosser Zahlen," </author> <booktitle> Computing 7, </booktitle> <pages> 281-292. 15 </pages>
Reference-contexts: The best algorithm for multiplication takes O (log n= log log n) time and O (n 1+* ) (* &gt; 0) operations, by combining <ref> [27] </ref> with [10]. The total time is O (D (n)) with O (n fi A (n) + n fi N (n)) total processors. Because of the following known results, all the checkers presented in this section are quantifiably different.
Reference: [28] <author> Spivak, M., </author> <title> Differential Geometry, </title> <journal> Vol. </journal> <volume> 3. </volume>
Reference-contexts: Though not enough in two dimension, in three dimensions this is enough to show that the polyhedron is convex since any three dimensional polyhedron which is locally convex at each point on the surface must also be globally convex (see <ref> [28] </ref>). We describe how to check that the polyhedron is locally convex: Since the points on the interior of the faces are locally convex, the only points that must be checked are the points along the edges and the vertices of the polyhedron. <p> We are grateful to Yossi Matias for his valuable comments and suggestions, as well as for pointing out the applications of the techniques to the problems of constructing breadth first and depth first search trees. We thank Mark Gross for pointing us to the result of <ref> [28] </ref> and we thank Klara Kedem and Raimund Seidel for helpful discussions about checking three dimensional convex hull programs. We are grateful to the referee for suggesting the third variant on the definition of quantifiablly different.
Reference: [29] <author> Tamassia, R., Vitter, J. S., </author> <title> "Optimal Parallel Algorithms for Transitive Closure and Point Location in Planar Structures", </title> <booktitle> Proc. 1989 ACM Symposium on Parallel Algorithms and Architectures. </booktitle> <pages> 16 </pages>
Reference-contexts: One must then just test that the point is really in the tetrahedron defined by (p; a; b; c). Determining (a; b; c) is simply a planar point location problem. In <ref> [29] </ref> it shown how to create the planar point location data structure in O (log n) time with n= log n processors that supports point location queries in O (log n) time.
References-found: 29

