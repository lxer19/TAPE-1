URL: http://www.stat.washington.edu:80/tech.reports/tr325.ps
Refering-URL: http://www.stat.washington.edu:80/tech.reports/
Root-URL: 
Title: Bayesian Morphology: Fast Unsupervised Bayesian Image Analysis  
Author: Florence Forbes Adrian E. Raftery 
Date: December 1997  
Address: 1  
Affiliation: INRIA Rhone-Alpes  University of Washington  Department of Statistics University of Washington  
Pubnum: Technical Report no. 325  
Abstract: 1 Florence Forbes is Researcher, Projet IS2, INRIA Rhone-Alpes, ZIRST, 655 av. de l'Europe, 38330 Montbonnot Saint-Martin, France. Email: Florence.Forbes@imag.fr. Adrian E. Raftery is Professor of Statistics and Sociology, Department of Statistics, University of Wash-ington, Box 354322, Seattle, WA 98195-4322. Email: raftery@stat.washington.edu; Web: www.stat.washington.edu/raftery. This work was done while the first author was visiting the University of Washington, and was supported by a Lavoisier grant from the Ministere des Affaires Etrangeres, Paris and Office of Naval Research grant no. N00014-96-1-0192. The authors are grateful to Julian Besag, Simon Byers, Chris Fraley, Todd Mitchell, Christian Posse, Derek Stanford, John Wallace for helpful discussions, to Dr. H. Thomas Robertson, UW Division of Pulmonary and Critical Care for sharing the data in Figure 12 (a) and to Xavier Descombes, INRIA Sophia-Antipolis for providing Figure 6. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Baddeley, A. J. </author> <year> (1992a). </year> <title> An error metric for binary images. </title> <editor> In W. Forstner and S. Ruwiedel,editors, </editor> <booktitle> Robust Computer Vision: Quality of Vision Algorithms, </booktitle> <pages> pp. 59-78. </pages> <publisher> Wichmann Verlag. </publisher>
Reference: <author> Baddeley, A. J. </author> <year> (1992b). </year> <title> Errors in binary images and a L p version of the Hausdorff metric. </title> <publisher> Nieuw Archief coor Wiskunde 10, </publisher> <pages> 157-183. </pages> <note> 45 Banfield, </note> <author> J. and A. E. </author> <title> Raftery (1992). Ice floe identification in satellite images using math-ematical morphology and clustering about principal curves. </title> <journal> Journal of the American Statistical Association 87, </journal> <pages> 7-16. </pages>
Reference: <author> Banfield, J. D. and A. E. </author> <title> Raftery (1993). Model-based Gaussian and Non-Gaussian Clustering. </title> <type> Biometrics 49, </type> <pages> 803-821. </pages>
Reference-contexts: We call this marginal mixture EM segmentation. With multispectral images, the distributions are multivariate, and there has been much progress on estimation methods that combine agglomerative hierarchical clustering methods based on maximum classification likelihood <ref> (Banfield and Raftery 1993) </ref> with the EM algorithm (Dasgupta and Raftery 1998; Byers and Raftery 1998). When the image is very large, it may be necessary to take a sample of the pixels first, as in Banfield and Raftery (1993).
Reference: <author> Bensmail, H. and G. </author> <month> Celeux </month> <year> (1996). </year> <title> Regularized Gaussian discriminant analysis through eigenvalue decomposition. </title> <journal> Journal of the American Statistical Association 91, </journal> <pages> 1743-1748. </pages>
Reference: <author> Besag, J. </author> <year> (1975). </year> <title> Statistical analysis of non-lattice data. </title> <booktitle> The Statistician 24, </booktitle> <pages> 179-195. </pages>
Reference-contexts: Maximum likelihood estimation is usually intractable, except maybe in some cases (see Goutsias 1991), because of the practical impossibility of computing the partition function. In practice, estimation is based on approximations such as maximum pseudo-likelihood <ref> (Besag 1975) </ref>. If the Potts model is "true", this may lead to unaccurate estimators, especially when the dependency is high (Geyer 1991), but for actual images it may yield better restorations, given the often unrealistic global behavior of the Potts model (Besag 1986).
Reference: <author> Besag, J. </author> <year> (1986). </year> <title> On the statistical analysis of dirty pictures. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> series B 48, </volume> <pages> 259-302. </pages>
Reference-contexts: Thus L (yjx) can be written as the product L (yjx) = i2S Finding the MAP estimate under these assumptions can require heavy computation. A less computationally demanding method that provides a fast approximation to the MAP is the Iterated Conditional Modes (ICM) algorithm <ref> (Besag 1986) </ref>. The ICM algorithm is iterative. Given a current estimate ^x of the image, a new one is computed by visiting each pixel in turn. <p> If the Potts model is "true", this may lead to unaccurate estimators, especially when the dependency is high (Geyer 1991), but for actual images it may yield better restorations, given the often unrealistic global behavior of the Potts model <ref> (Besag 1986) </ref>. In our setting, however, the amount of computation that maximum likelihood estimation requires appears to be reasonable. The idea is to take advantage of the insensitivity conditions given in Sections 3.1 and 3.2 .
Reference: <author> Besag, J., J. York, and A. </author> <month> Mollie </month> <year> (1991). </year> <title> Bayesian image restoration with two applications in spatial statistics. </title> <journal> Annals of the Institute of Statistical Mathematics 43, </journal> <pages> 1-59. </pages>
Reference-contexts: This can be seen as a restoration problem where the image to be restored consists of unordered colors (classes) but the observations are usually ordered (measurements). The ICM algorithm can be used for such restorations, assuming a different noise model <ref> (Besag, York, and Mollie 1991) </ref>, but our use of the insensitivity conditions cannot be extended efficiently for this model. It seems that there is no gain in using them rather than estimating the model parameters directly. We believe however, that they can still be used to obtain acceptable segmentations rapidly.
Reference: <author> Byers, S. D. and A. E. </author> <title> Raftery (1998). Nearest neighbor clutter removal for estimating features in spatial point processes. </title> <journal> Journal of the American Statistical Association 93, </journal> <note> to appear. </note>
Reference: <author> Carstensen, J. M. </author> <year> (1992). </year> <title> Description and simulation of visual texture. </title> <type> Ph. D. thesis, </type> <institution> Institute of Mathematical Statistics and Operations Research. Technical University of Denmark, Lyngby. </institution>
Reference: <author> Celeux, G. and G. </author> <month> Govaert </month> <year> (1995). </year> <title> Gaussian Parsimonious Clustering Models. </title> <booktitle> Pattern Recognition 28, </booktitle> <pages> 781-793. </pages>
Reference: <author> Dasgupta, A. and A. E. </author> <title> Raftery (1998). Detecting features in spatial point processes with clutter via model-based clustering. </title> <journal> Journal of the American Statistical Association 93, </journal> <note> To appear. </note>
Reference-contexts: Indeed, this clustering could be used to provide an original image for Bayesian morphology, avoiding the EM algorithm altogether, although this seems likely to perform less well <ref> (Dasgupta and Raftery 1998) </ref>. For standard-sized images, such as 256fi256 or 512fi512, this clustering can be computa-tionally expensive, but clustering on the basis of a subsample of pixels is fast and often works well; see Banfield and Raftery (1993).
Reference: <author> Dempster, A. P., N. Laird, and D. B. </author> <title> Rubin (1977). Maximum likelihood from incomplete data via the EM algorithm (with discussion). </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> series B 39, </volume> <pages> 1-38. </pages>
Reference: <author> Descombes, X., J.-F. Mangin, E. Pechersky, and M. </author> <month> Sigelle </month> <year> (1995). </year> <title> Fine structures preserving Markov model for image processing. </title> <booktitle> Proceedings of the 9th Scandinavian Conference on Image Analysis, </booktitle> <pages> 349-356. </pages> <note> 46 Descombes, </note> <author> X., R. Morris, and J. </author> <month> Zerubia </month> <year> (1996). </year> <title> Estimation of Markov random field prior parameters using Markov chain Monte-Carlo maximum likelihood. </title> <type> Technical Report 3015, </type> <institution> INRIA, Sophia Antipolis, France. </institution>
Reference: <author> Fovell, R. G. </author> <year> (1997). </year> <title> Consensus clustering of U.S. temperature and precipitation data. </title> <journal> Journal of Climate 10, </journal> <pages> 1405-1427. </pages>
Reference: <author> Geman, S. and D. </author> <title> Geman (1984). Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images. </title> <journal> I.E.E.E. Transactions on Pattern Analysis and Machine Intelligence 6, </journal> <pages> 721-741. </pages>
Reference: <author> Geyer, C. J. </author> <year> (1991). </year> <title> Reweighting Monte-Carlo mixtures. </title> <type> Technical Report 568, </type> <institution> School of Statistics, University of Minnesota. </institution>
Reference-contexts: In practice, estimation is based on approximations such as maximum pseudo-likelihood (Besag 1975). If the Potts model is "true", this may lead to unaccurate estimators, especially when the dependency is high <ref> (Geyer 1991) </ref>, but for actual images it may yield better restorations, given the often unrealistic global behavior of the Potts model (Besag 1986). In our setting, however, the amount of computation that maximum likelihood estimation requires appears to be reasonable.
Reference: <author> Geyer, C. J. and E. A. </author> <title> Thompson (1992). Constrained Monte-Carlo maximum likelihood for dependent data (with discussion). </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> series B 54, </volume> <pages> 657-699. </pages>
Reference: <author> Goutsias, J. K. </author> <year> (1991). </year> <title> Unilateral approximation of Gibbs random field images. Computer Vision, Graphics and Image Processing: Graphical Models and Image Processing 53, </title> <type> 240-257. </type>
Reference-contexts: Maximum likelihood estimation is usually intractable, except maybe in some cases <ref> (see Goutsias 1991) </ref>, because of the practical impossibility of computing the partition function. In practice, estimation is based on approximations such as maximum pseudo-likelihood (Besag 1975).
Reference: <author> Grenander, U., Y. Chow, and D. M. </author> <title> Keenan (1991). Hands: a pattern theoretic study of biological shapes. </title> <booktitle> Research Notes on Neural Computing 2. </booktitle>
Reference-contexts: The problem considered here could also be a first step in methods for solving more specialized object recognition problems, such as deformable templates <ref> (Grenander, Chow, and Keenan 1991) </ref> or the EP algorithm (Banfield and Raftery 1992). We consider both performance and speed as criteria for assessing methods. Speed has become increasingly important as the demands on image processing systems have increased over the past 15 years.
Reference: <author> Heijmans, H. J. </author> <year> (1994). </year> <title> Morphological Image Operators. </title> <publisher> Academic Press: </publisher> <address> Boston. </address>
Reference-contexts: However, the choice of an appropriate function f is not clear. In addition, we believe that the morphological point of view can simplify the implementation of statistical algorithms such as ICM and give better insight into their convergence properties, in particular through the properties of iterations of morphological transformations <ref> (see Heijmans 1994) </ref>. This also includes considering alternatives to the commonly used Markov random fields priors such as, for instance, morphologically constrained Markov random fields (Sivakumar and Goutsias 1997). The latter incorporate geometric properties more clearly and may induce algorithms with clear morphological characteristics.
Reference: <author> Higdon, D. </author> <year> (1994). </year> <title> Spatial Applications of Markov Chain Monte-Carlo for Bayesian Inference. </title> <type> Ph. D. thesis, </type> <institution> University of Washington. </institution>
Reference: <author> Hummel, R. A. and S. W. </author> <title> Zucker (1983). On the foundations of relaxation labelling processes. </title> <journal> I.E.E.E. Transactions on Pattern Analysis and Machine Intelligence 5, </journal> <pages> 267-287. </pages>
Reference: <author> Ji, C. and L. </author> <title> Seymour (1996). A consistent model selection procedure for Markov random fields based on penalized pseudolikelihood. </title> <journal> Annals of Applied Probability 6, </journal> <pages> 423-443. </pages>
Reference: <author> Kass, R. E. and A. E. </author> <title> Raftery (1995). Bayes factors. </title> <journal> Journal of the American Statistical Association 90, </journal> <pages> 773-795. </pages>
Reference: <author> Matheron, G. </author> <year> (1975). </year> <title> Random Sets and Integral Geometry. </title> <address> New York: </address> <publisher> John Wiley. </publisher>
Reference: <author> McLachlan, G. J. and K. E. </author> <title> Basford (1988). Mixture Models: Inference and Applications to Clustering. </title> <address> New York: </address> <publisher> Marcel Dekker. 47 Morris, </publisher> <editor> R., X. Descombes, and J. </editor> <month> Zerubia </month> <year> (1996). </year> <title> An analysis of some models used in image segmentation. </title> <type> Technical Report 3016, </type> <institution> INRIA, Sophia Antipolis, France. </institution>
Reference-contexts: The final step is to calculate the posterior probability for each pixel of being of each color, given the estimated parameter values. This is done using Bayes's theorem <ref> (McLachlan and Basford 1988) </ref>. Then each pixel is classified to the most likely color. A byproduct of this is that it could be used to assess the number of distinct colors in the true image if this is unknown, at least roughly.
Reference: <author> Posse, C. </author> <year> (1998). </year> <title> Hierarchical Model-based Clustering for Large Data Sets. </title> <note> In preparation. </note>
Reference-contexts: When the image is very large, it may be necessary to take a sample of the pixels first, as in Banfield and Raftery (1993). The use of minimum spanning trees <ref> (Posse 1998) </ref> has the potential to make this approach feasible even with very large images, without subsampling the pixels. The resulting method is much faster than ICM, and in our experiments with synthetically degraded and real images its performance was comparable to that of ICM.
Reference: <author> Qian, W. and M. </author> <month> Titterington </month> <year> (1992). </year> <title> Stochastic relaxations and EM algorithms for Markov random fields. </title> <journal> Journal of Statistical Computation and Simulation 40, </journal> <pages> 55-69. </pages>
Reference: <author> Roeder, K. and L. A. </author> <title> Wasserman (1997). Practical Bayesian Density Estimation Using Mixtures of Normals. </title> <journal> Journal of the American Statistical Association 92, </journal> <pages> 894-902. </pages>
Reference: <author> Rosenfeld, A., R. A. Hummel, and S. W. </author> <title> Zucker (1976). Scene labelling by relaxation operation. </title> <journal> I.E.E.E. Transactions on Systems, Man and Cybernetics 6, </journal> <pages> 420-433. </pages>
Reference: <author> Serra, J. </author> <year> (1982). </year> <title> Image Analysis and Mathematical Morphology. </title> <publisher> Academic Press. </publisher>
Reference: <author> Sivakumar, K. and J. K. </author> <month> Goutsias </month> <year> (1997). </year> <title> Morphologically constrained discrete random sets. In Advances in Theory and Applications of Random Sets, </title> <editor> D. Jeulin (Ed.). </editor> <publisher> World Scientific Publishing Company. </publisher>
Reference-contexts: This also includes considering alternatives to the commonly used Markov random fields priors such as, for instance, morphologically constrained Markov random fields <ref> (Sivakumar and Goutsias 1997) </ref>. The latter incorporate geometric properties more clearly and may induce algorithms with clear morphological characteristics. Note that although our study and Sivakumar and Goutsias (1997) both attempt to link Bayesian image analysis and mathematical morphology, the goals and results are quite different.
Reference: <author> Swendsen, R. H. and J. S. </author> <title> Wang (1987). Nonuniversal critical dynamics in Monte Carlo simulations. </title> <journal> Physical Review Letters 58, </journal> <pages> 86-88. </pages>
Reference-contexts: The required samples can be generated using Markov chain Monte Carlo. This can be computationally demanding, but can be greatly accelerated for the Potts model using the Swendsen-Wang algorithm <ref> (Swendsen and Wang 1987) </ref>. It considers clusters instead of pixels and converges faster than single site updating algorithms such as the Gibbs sampler. In addition, the Swendsen-Wang algorithm explores the state space more freely so that fewer iterations are required to obtain accurate estimates.
Reference: <author> Titterington, D. M., A. F. Smith, and U. E. </author> <month> Makov </month> <year> (1985). </year> <title> Statistical Analysis of Finite Mixture Distributions. </title> <address> Chichester, U.K.: </address> <publisher> John Wiley. </publisher>
Reference-contexts: When the original image is grey-scale or multispectral, we propose initializing the method by positing a finite mixture model for the marginal distribution of (possibly multivariate) pixel intensities, and estimating this using the EM algorithm <ref> (Titterington, Smith, and Makov 1985) </ref>. We call this marginal mixture EM segmentation.
Reference: <author> Tjelmeland, H. and J. </author> <month> Besag </month> <year> (1998). </year> <title> Markov random fields with higher order interactions. </title> <journal> Scandinavian Journal of Statitics, </journal> <note> To appear. </note>
Reference: <author> Zhang, B., M. N. Shirazi, and H. </author> <title> Noda (1996). Blind restoration of degraded binary Markov random field images. Graphical models and Image Processing 58, </title> <type> 90-98. 48 </type>
References-found: 36

