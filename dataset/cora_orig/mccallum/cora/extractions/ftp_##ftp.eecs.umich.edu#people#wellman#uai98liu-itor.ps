URL: ftp://ftp.eecs.umich.edu/people/wellman/uai98liu-itor.ps
Refering-URL: http://ai.eecs.umich.edu/people/wellman/Publications.html
Root-URL: http://www.cs.umich.edu
Email: fchaolin, wellmang@umich.edu  
Title: Incremental Tradeoff Resolution in Qualitative Probabilistic Networks  
Author: Chao-Lin Liu and Michael P. Wellman 
Affiliation: University of Michigan AI Laboratory  
Date: July 1998  
Address: Madison, WI, USA,  Ann Arbor, Michigan 48109, USA  
Note: In Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI-98), pages 338-345,  
Abstract: Qualitative probabilistic reasoning in a Bayesian network often reveals tradeoffs: relationships that are ambiguous due to competing qualitative influences. We present two techniques that combine qualitative and numeric probabilistic reasoning to resolve such tradeoffs, inferring the qualitative relationship between nodes in a Bayesian network. The first approach incrementally marginalizes nodes that contribute to the ambiguous qualitative relationships. The second approach evaluates approximate Bayesian networks for bounds of probability distributions, and uses these bounds to determinate qualitative relationships in question. This approach is also incremental in that the algorithm refines the state spaces of random variables for tighter bounds until the qualitative relationships are resolved. Both approaches provide systematic methods for tradeoff resolution at potentially lower computational cost than application of purely numeric methods.
Abstract-found: 1
Intro-found: 1
Reference: <author> Dagum, P., and Luby, M. </author> <year> 1993. </year> <title> Approximating probabilistic inference in Bayesian belief networks is NP-hard. </title> <journal> Artificial Intelligence 60:141153. </journal>
Reference-contexts: An estimate fl is an absolute approximation of Pr (y) if where ffi is the range of error. The problem of computing absolute approximations has been shown NP-hard <ref> (Dagum & Luby 1993) </ref>. Consider the task of computing absolute approximations for Pr (y) in a given Bayesian network in which Y is a boolean variable. We construct a corresponding tradeoff resolution problem for this task as follows.
Reference: <author> Druzdzel, M. J., and Henrion, M. </author> <year> 1993. </year> <title> Efficient reasoning in qualitative probabilistic networks. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> 548553. </pages>
Reference-contexts: Since pure qualitative inference can often be substantially more efficient than its numeric counterpart (e.g., in methods based on infinitesimal probabilities (Goldszmidt & Pearl 1992) or ordinal relationships <ref> (Druzdzel & Henrion 1993) </ref>), it is worth exploring any opportunities to exploit qualitative methods even where some numeric information is required. <p> The inference can be carried out via graph reduction (Wellman 1990), or qualitative propagation techniques <ref> (Druzdzel & Henrion 1993) </ref>. If we are fortunate, we may acquire decisive answers from the qualitative inference algorithms. Often, however, the results of such qualitative reasoning are ambiguous. <p> Algorithm 1 ITOR (decision,target,strategy) 1. Remove nodes that are irrelevant to the query about decision's influence on target (Shachter 1988). 2. Attempt to answer the query via qualitative inference <ref> (Druzdzel & Henrion 1993) </ref>. 3. If the answer to the query is decisive, exit; otherwise continue. 4. Select a node to reduce according to strategy. If there is no node that can be reduced, return ?, else perform the node reduction, and calculate the qualitative abstractions of the transformed relationships. <p> The optimal strate gies for respective tasks will differ, in general. For example, a node that is very expensive to reduce at a certain stage of the evaluation might be the best prospect for resolving the tradeoff. We exploit intermediate information provided in qualitative belief propagation <ref> (Druzdzel & Henrion 1993) </ref> in determining which node to reduce next. If we can propagate a decisive qualitative influence from the decision node D all the way to the target node T , we will be able to answer the query.
Reference: <author> Fishburn, P. C., and Vickson, R. G. </author> <year> 1978. </year> <title> Theoretical foundations of stochastic dominance. </title> <editor> In Whitmore, G. A., and Findlay, M. C., eds., </editor> <title> Stochastic Dominance: An Approach to Decision Making Under Risk, </title> <type> 39113. </type> <address> Lexing-ton, MA: D. C. </address> <publisher> Heath and Company. </publisher>
Reference-contexts: Each arc in the network is marked with a signpositive (+), negative (), or ambiguous (?)denoting the sign of the qualitative probabilistic relationship between its terminal nodes. The interpretation of such qualitative influences is based on first-order stochastic dominance (F SD) <ref> (Fishburn & Vick-son 1978) </ref>. Let F (x) and F 0 (x) denote two cumulative distribution functions (CDFs) of a random variable X.
Reference: <author> Goldszmidt, M., and Pearl, J. </author> <year> 1992. </year> <title> Reasoning with qualitative probabilities can be tractable. </title> <booktitle> In Proceedings of the Eighth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> 112120. </pages>
Reference-contexts: Since pure qualitative inference can often be substantially more efficient than its numeric counterpart (e.g., in methods based on infinitesimal probabilities <ref> (Goldszmidt & Pearl 1992) </ref> or ordinal relationships (Druzdzel & Henrion 1993)), it is worth exploring any opportunities to exploit qualitative methods even where some numeric information is required.
Reference: <author> Goldszmidt, M. </author> <year> 1994. </year> <title> Research issues in qualitative and abstract probability. </title> <journal> AI Magazine 15(4):6365. </journal>
Reference-contexts: 1 Introduction Researchers in uncertain reasoning regularly observe that to reach a desired conclusion (e.g., a decision), full precision in probabilistic relationships is rarely required, and that in many cases purely qualitative information (for some conception of qualitative) is sufficient <ref> (Goldszmidt 1994) </ref>. In consequence, the literature has admitted numerous schemes attempting to capture various forms of qualitative relationships (Wellman 1994), useful for various uncertain reasoning tasks.
Reference: <author> Henrion, M., and Druzdzel, M. J. </author> <year> 1991. </year> <title> Qualitative propagation and scenario-based approaches to explanation of probabilistic reasoning. </title> <editor> In Bonissone, P.; Henrion, M.; Kanal, L.; and Lemmer, J., eds., </editor> <booktitle> Uncertainty in Artificial Intelligence 6. </booktitle> <publisher> North Holland: Elsevier. </publisher> <pages> 1732. </pages>
Reference-contexts: Even in such cases, qualitative models may have benefits for explanation or justification <ref> (Henrion & Druzdzel 1991) </ref>, as they can indicate something about the robustness of the conclusions (put another way, they can concisely convey broad classes of conclusions). model is not.
Reference: <author> Kuipers, B., and Berleant, D. </author> <year> 1988. </year> <title> Using incomplete quantitative knowledge in qualitative reasoning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> 324329. </pages>
Reference: <author> Liu, C.-L., and Wellman, M. P. </author> <year> 1998. </year> <title> Using qualitative relationships for bounding probability distributions. </title> <booktitle> In Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence. </booktitle>
Reference-contexts: (4) holds, the curves for F (xjd i ) and F (xjd j ) must intersect as illustrated in the following figure. 5.2 Bounding probability distributions We may compute bounds of conditional probability distributions by using an ISSA algorithm that applies the dominance policy in aggregating states of abstracted nodes <ref> (Liu & Wellman 1998) </ref>. <p> distribution, we assign ^ F (yj [a i;j ]; px (Y )) as follows: ^ F (yj [a i;j ]; px (Y )) = max F (yja l ; px (Y )): We have identified and reported conditions under which the ISSA algorithm may compute bounds of conditional probability distributions <ref> (Liu & Wellman 1998) </ref>. Taking advantage of qualitative relationship and conditional inde pendence among variables, we can compute lower and upper bounds of desired conditional probability distributions. Consider the network in Figure 5. <p> Analogously, we may abstract Y 2 in computing bounds of F (xjd) to further reduce computation time. In addition, we have shown that bounds computed by the ISSA algorithm tighten as we refine the state space of the abstracted nodes <ref> (Liu & Wellman 1998) </ref>. Therefore, we are more likely to resolve qualitative tradeoffs as we carry out more iterations of the ISSA algorithm.
Reference: <author> Parsons, S., and Dohnal, M. </author> <year> 1993. </year> <title> A semiqualitative approach to reasoning in probabilistic networks. </title> <journal> Applied Artificial Intelligence 7:223235. </journal>
Reference: <author> Parsons, S. </author> <year> 1995. </year> <title> Refining reasoning in qualitative probabilistic networks. </title> <booktitle> In Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> 427433. </pages>
Reference: <author> Shachter, R. D. </author> <year> 1988. </year> <title> Probabilistic inference and influence diagrams. Operation Research 36(4):589604. </title>
Reference-contexts: The algorithm is designed to answer queries about the qualitative influence of a decision node on a target node, using a given strategy for selecting the next node to reduce. Algorithm 1 ITOR (decision,target,strategy) 1. Remove nodes that are irrelevant to the query about decision's influence on target <ref> (Shachter 1988) </ref>. 2. Attempt to answer the query via qualitative inference (Druzdzel & Henrion 1993). 3. If the answer to the query is decisive, exit; otherwise continue. 4. Select a node to reduce according to strategy.
Reference: <author> Wellman, M. P. </author> <year> 1990. </year> <title> Fundamental concepts of qualitative probabilistic networks. </title> <booktitle> Artificial Intelligence 44:257 303. </booktitle>
Reference-contexts: The third section explains the incremental marginalization approach, followed by the experimental results. We then discuss the state-space abstraction approach, and conclude with a brief comparison of our approaches with some others. 2 Qualitative probabilistic networks 2.1 Qualitative influences Qualitative probabilistic networks (QPNs) <ref> (Wellman 1990) </ref> are abstractions of Bayesian networks, with conditional probability tables summarized by the signs of qualitative relationships between variables. Each arc in the network is marked with a signpositive (+), negative (), or ambiguous (?)denoting the sign of the qualitative probabilistic relationship between its terminal nodes. <p> The inference can be carried out via graph reduction <ref> (Wellman 1990) </ref>, or qualitative propagation techniques (Druzdzel & Henrion 1993). If we are fortunate, we may acquire decisive answers from the qualitative inference algorithms. Often, however, the results of such qualitative reasoning are ambiguous.
Reference: <author> Wellman, M. P. </author> <year> 1994. </year> <title> Some varieties of qualitative probability. </title> <booktitle> In Proceedings of the Fifth International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems, </booktitle> <pages> 437442. </pages>
Reference-contexts: In consequence, the literature has admitted numerous schemes attempting to capture various forms of qualitative relationships <ref> (Wellman 1994) </ref>, useful for various uncertain reasoning tasks. Unfortunately, we generally lack a robust mapping from tasks to the levels of precision required, and indeed, necessary precision is inevitably variable across problem instances. <p> In previous work, we report an iterative state-space abstraction (ISSA) algorithm for approximate evaluation of Bayesian networks <ref> (Wellman & Liu 1994) </ref>. The ISSA algorithm aggregates states of selected variables, called abstracted nodes, into superstates to construct abstract versions of the original Bayesian networks (OBNs) that specify exact probability distributions.
Reference: <author> Wellman, M. P., and Liu, C.-L. </author> <year> 1994. </year> <title> State-space abstraction for anytime evaluation of probabilistic networks. </title> <booktitle> In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> 567574. </pages>
Reference-contexts: In consequence, the literature has admitted numerous schemes attempting to capture various forms of qualitative relationships <ref> (Wellman 1994) </ref>, useful for various uncertain reasoning tasks. Unfortunately, we generally lack a robust mapping from tasks to the levels of precision required, and indeed, necessary precision is inevitably variable across problem instances. <p> In previous work, we report an iterative state-space abstraction (ISSA) algorithm for approximate evaluation of Bayesian networks <ref> (Wellman & Liu 1994) </ref>. The ISSA algorithm aggregates states of selected variables, called abstracted nodes, into superstates to construct abstract versions of the original Bayesian networks (OBNs) that specify exact probability distributions.
Reference: <author> Zhang, N. L., and Poole, D. </author> <year> 1996. </year> <title> Exploiting causal independence in Bayesian network inference. </title> <journal> Journal of Artificial Intelligence Research 5:301328. </journal>
Reference-contexts: Initial exper iments with incremental marginalization suggest that no-ticeable savings are possible, but definitive evaluation of both methods awaits further empirical and theoretical investigation. The incremental marginalization approach bears some similarity to symbolic probabilistic inference, as in the variable elimination (VE) algorithm <ref> (Zhang & Poole 1996) </ref>, in that we sum out one node from the Bayesian network at a time. The ITOR algorithm differs from the VE algorithm in the determination of the elimination ordering, and of course in the stopping criterion.
References-found: 15

