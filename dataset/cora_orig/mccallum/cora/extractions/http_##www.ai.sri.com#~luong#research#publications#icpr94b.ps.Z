URL: http://www.ai.sri.com/~luong/research/publications/icpr94b.ps.Z
Refering-URL: http://www.ai.sri.com/~luong/research/publications/publications.html
Root-URL: 
Title: An optimization framework for efficient self-calibration and motion determination  
Author: Q.-T. Luong O.D. Faugeras 
Address: 2004, route des Lucioles Berkeley, CA 94720 06902 Sophia-Antipolis, France  
Affiliation: EECS I.N.R.I.A. University of California  
Abstract: The problem of calibrating a camera is extremely important for practical applications. While classical work is based on the use of a calibration pattern whose 3D model is a priori known, self-calibration methods have been recently investigated. These methods require only point matches obtained during unknown motions, without any a priori knowledge of the scenes. However, the method initially presented by Faugeras, Luong and Maybank [7] was computationally expensive and sensitive to noise. In this paper, we propose an alternative method to compute at the same time camera calibration and motion, which is robust and efficient. This method allows also to take into account the important trinocular constraints. The practical applicability of our algorithm is illustrated with numerous real examples, which includes 3D reconstruction. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Basu. </author> <title> Active calibration: alternative strategy and analysis. </title> <booktitle> In Proc. of the conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 495-500, </pages> <address> New-York, </address> <year> 1993. </year>
Reference-contexts: Thus a number of researchers have recently investigated limited self-calibration techniques: almost all of them have put more limitations on their methods by adding supplementary constraints, such as restriction on the camera motions <ref> [5, 1, 4, 21, 10] </ref>. When the camera motion is exactly known in some reference frame, then these methods should be rather called "calibration from motion" than self-calibration, where motion and calibration are estimated.
Reference: [2] <author> R. Deriche, R. Vaillant, and O. Faugeras. </author> <title> From Noisy Edges Points to 3D Reconstruction of a Scene : A Robust Approach and Its Uncertainty Analysis, </title> <booktitle> volume 2, </booktitle> <pages> pages 71-79. </pages> <publisher> World Scientific, </publisher> <year> 1992. </year> <booktitle> Series in Machine Perception and Artificial Intelligence. </booktitle>
Reference-contexts: We have then performed a 3D trinocular reconstruction from the matched points, using our computed projection matrices as input for a the classical reconstruction algorithm of R. Vaillant and R. Deriche <ref> [2] </ref>. In order to compare the reconstruction with the reference data, we have computed the best similarity which relates the two sets of 3D points, using an algorithm of Z. Zhang.
Reference: [3] <author> R. Deriche, Z. Zhang, Q.-T. Luong, and O.D. Faugeras. </author> <title> Robust recovery of the epipolar geometry for an uncalibrated stereo rig. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 567-576, </pages> <address> Stockholm, Sweden, </address> <year> 1994. </year>
Reference-contexts: Iterative minimization. The fundamental matrix is recomputed by a non-linear minimization technique such as those presented in <ref> [13, 3] </ref>, the difference being that the knowledge of the intrinsic parameters allows us to minimize these criteria with respect to five motion parameters, instead of the seven parameters of the epipolar transformation.
Reference: [4] <author> L. Dron. </author> <title> Dynamic camera self-calibration from controled motion sequences. </title> <booktitle> In Proc. of the conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 501-506, </pages> <address> New-York, </address> <year> 1993. </year>
Reference-contexts: Thus a number of researchers have recently investigated limited self-calibration techniques: almost all of them have put more limitations on their methods by adding supplementary constraints, such as restriction on the camera motions <ref> [5, 1, 4, 21, 10] </ref>. When the camera motion is exactly known in some reference frame, then these methods should be rather called "calibration from motion" than self-calibration, where motion and calibration are estimated.
Reference: [5] <author> F. Du and M. Brady. </author> <title> Self-calibration of the intrinsic parameters of cameras for active vision systems. </title> <booktitle> In Proc. of the conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 477-482, </pages> <address> New-York, </address> <year> 1993. </year>
Reference-contexts: Thus a number of researchers have recently investigated limited self-calibration techniques: almost all of them have put more limitations on their methods by adding supplementary constraints, such as restriction on the camera motions <ref> [5, 1, 4, 21, 10] </ref>. When the camera motion is exactly known in some reference frame, then these methods should be rather called "calibration from motion" than self-calibration, where motion and calibration are estimated.
Reference: [6] <author> O.D. Faugeras. </author> <title> Three-dimensional computer vision: a geometric viewpoint. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: The rotation R = e [r] fi is obtained by the Rodrigues formula (see for example <ref> [6] </ref>). Experiments [12] have shown that whereas the iterative approach is more precise in the case of exact intrinsic parameters, the factorization method is less sensitive to the error on the intrinsic parameters.
Reference: [7] <author> O.D. Faugeras, Q.-T. Luong, and S.J. Maybank. </author> <title> Camera self-calibration: theory and experiments. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 321-334, </pages> <address> Santa-Margerita, Italy, </address> <year> 1992. </year>
Reference-contexts: This is why self-calibration methods have been recently investigated. In their full generality, these methods need only point matches obtained during unknown motions, without any a priori knowledge of the scenes. However, the method initially presented by Faugeras, Luong and Maybank <ref> [7] </ref> was computationally expensive and sensitive to noise in spite of some improvements in the formulation [14]. <p> Thus, from this relation, it is seen that the knowledge of F determines two algebraic constraints on A. They are called Kruppa equations and were used in <ref> [7] </ref> (continuation method) [14] (iterative method) to perform self-calibration. Since each displacement provides with 2 such equations and since there are 5 intrinsic parameters, 3 displacements are needed. 2.3 Motion Computation If the intrinsic parameters are known, the 3D motion of the camera can be determined. <p> Since the minimization is highly non-linear, and involves a large number of unknowns (the displacements have to be computed simultaneously) to obtain convergence we need a good starting point, which can fortunately be obtained from the Kruppa method <ref> [7, 14] </ref>. Let us summarize the new algorithm, which can accommodate N independent displacements (N 2), and, for each displacement i, a minimum of eight correspondences (q ij ; q 0 ij ) j : Global computation of intrinsic parameters and motion 1.
Reference: [8] <author> O.D. Faugeras, F. Lustman, and G. Toscani. </author> <title> Motion and Structure from point and line matches. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 25-34, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: The problem of factoring the essential matrix into a rotation R and the translation t such that: E = 0 t 3 t 2 t 2 t 1 0 | -z - R is classical <ref> [11, 20, 8] </ref>. Iterative minimization.
Reference: [9] <author> R.I. </author> <title> Hartley. An algorithm for self calibration from several views. </title> <booktitle> In Proc. Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 908-912, </pages> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: However, for anything else than a robotic head, the method would not work, and thus we are still in need of an efficient general self-calibration method. The closest one we are aware of is a recent work by Hartley <ref> [9] </ref>. However, we believe that our approach has still a number of advantages that we stress in the conclusion.
Reference: [10] <author> R.I. </author> <title> Hartley. Self-calibration from multiple views with a rotating camera. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 471-478, </pages> <address> Stockholm, Sweden, </address> <year> 1994. </year>
Reference-contexts: Thus a number of researchers have recently investigated limited self-calibration techniques: almost all of them have put more limitations on their methods by adding supplementary constraints, such as restriction on the camera motions <ref> [5, 1, 4, 21, 10] </ref>. When the camera motion is exactly known in some reference frame, then these methods should be rather called "calibration from motion" than self-calibration, where motion and calibration are estimated.
Reference: [11] <author> H.C. Longuet-Higgins. </author> <title> A Computer Algorithm for Reconstructing a Scene from Two Projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: The problem of factoring the essential matrix into a rotation R and the translation t such that: E = 0 t 3 t 2 t 2 t 1 0 | -z - R is classical <ref> [11, 20, 8] </ref>. Iterative minimization.
Reference: [12] <author> Q.-T. Luong. </author> <title> Matrice fondamentale et auto-calibration en vision par ordinateur. </title> <type> PhD thesis, </type> <institution> Universite de Paris-Sud, Or-say, </institution> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: The rotation R = e [r] fi is obtained by the Rodrigues formula (see for example [6]). Experiments <ref> [12] </ref> have shown that whereas the iterative approach is more precise in the case of exact intrinsic parameters, the factorization method is less sensitive to the error on the intrinsic parameters. <p> Second, the criterion uses directly more information. This explains that we obtain more precise results. 3.2 Taking into account trinocular con straints It has been shown <ref> [12, 15] </ref> that the three motions required by the self-calibration algorithm can be obtained from three images, which means that the third motion can be obtained by composition of the two first motion. In this case, some new relations arise, which we discuss now. <p> The triplet used in this experiment is shown in figure 5. The points of interest are the light dots and have been located and matched manually. Although the configuration is somewhat de-favorable (long focal length, one translation parallel to the image plane <ref> [12, 16] </ref>), the epipolar geometry found from the three projection matrices obtained by self-calibration is fairly coherent, as illustrated in figure 6, which shows a zoom with epipolar lines of one point of interest.
Reference: [13] <author> Q.-T. Luong, R. Deriche, O.D. Faugeras, and T. Papadopoulo. </author> <title> On determining the Fundamental matrix: analysis of different methods and experimental results. </title> <type> Technical Report RR-1894, </type> <institution> INRIA, </institution> <year> 1993. </year>
Reference-contexts: Iterative minimization. The fundamental matrix is recomputed by a non-linear minimization technique such as those presented in <ref> [13, 3] </ref>, the difference being that the knowledge of the intrinsic parameters allows us to minimize these criteria with respect to five motion parameters, instead of the seven parameters of the epipolar transformation.
Reference: [14] <author> Q.-T. Luong and O.D. Faugeras. </author> <title> Self-calibration of a camera using multiples images. </title> <booktitle> In Proc. International Conference on Pattern Recognition, </booktitle> <pages> pages 9-12, </pages> <address> Den Hag, The Netherlands, </address> <year> 1992. </year>
Reference-contexts: In their full generality, these methods need only point matches obtained during unknown motions, without any a priori knowledge of the scenes. However, the method initially presented by Faugeras, Luong and Maybank [7] was computationally expensive and sensitive to noise in spite of some improvements in the formulation <ref> [14] </ref>. Thus a number of researchers have recently investigated limited self-calibration techniques: almost all of them have put more limitations on their methods by adding supplementary constraints, such as restriction on the camera motions [5, 1, 4, 21, 10]. <p> Thus, from this relation, it is seen that the knowledge of F determines two algebraic constraints on A. They are called Kruppa equations and were used in [7] (continuation method) <ref> [14] </ref> (iterative method) to perform self-calibration. Since each displacement provides with 2 such equations and since there are 5 intrinsic parameters, 3 displacements are needed. 2.3 Motion Computation If the intrinsic parameters are known, the 3D motion of the camera can be determined. We have considered two approaches: Factorization. <p> Since the minimization is highly non-linear, and involves a large number of unknowns (the displacements have to be computed simultaneously) to obtain convergence we need a good starting point, which can fortunately be obtained from the Kruppa method <ref> [7, 14] </ref>. Let us summarize the new algorithm, which can accommodate N independent displacements (N 2), and, for each displacement i, a minimum of eight correspondences (q ij ; q 0 ij ) j : Global computation of intrinsic parameters and motion 1.
Reference: [15] <author> Q.-T. Luong and O.D. Faugeras. </author> <title> Camera calibration, scene motion and structure recovery from point correspondences and fundamental matrices. </title> <note> Submitted to IJCV, </note> <year> 1993. </year>
Reference-contexts: Second, the criterion uses directly more information. This explains that we obtain more precise results. 3.2 Taking into account trinocular con straints It has been shown <ref> [12, 15] </ref> that the three motions required by the self-calibration algorithm can be obtained from three images, which means that the third motion can be obtained by composition of the two first motion. In this case, some new relations arise, which we discuss now.
Reference: [16] <author> Q.-T. Luong and O.D. Faugeras. </author> <title> The fundamental matrix: theory, algorithms, and stability analysis. </title> <journal> Intl. Journal of Computer Vision, </journal> <note> 1994. To appear. </note>
Reference-contexts: The triplet used in this experiment is shown in figure 5. The points of interest are the light dots and have been located and matched manually. Although the configuration is somewhat de-favorable (long focal length, one translation parallel to the image plane <ref> [12, 16] </ref>), the epipolar geometry found from the three projection matrices obtained by self-calibration is fairly coherent, as illustrated in figure 6, which shows a zoom with epipolar lines of one point of interest.
Reference: [17] <author> Q.-T. Luong and T. Vieville. </author> <title> Canonic representations for the geometries of multiple projective views. </title> <type> Technical Report UCB/CSD-93-772, </type> <institution> University of California at Berkeley, </institution> <month> Sept </month> <year> 1993. </year> <note> A shorter version appeared in ECCV'94. </note>
Reference-contexts: This is a way to express the geometric constraints associated to a set of three views taken by the same camera by a parameterization of the set of fundamental matrices which is minimal and complete <ref> [17] </ref>. 4 Experiments: reconstructions from a triplet of uncalibrated images taken by a camera A qualitative experiment The first set of images is used to illustrate the feasibility of the method in a fairly standard indoor environment, such as it appears in the three views of figure 2.
Reference: [18] <author> L. Robert. </author> <title> Reconstruction de courbes et de surfaces par vision stereoscopique. Applications a la robotique mobile. </title> <type> PhD thesis, </type> <institution> Ecole Polytechnique, </institution> <year> 1993. </year>
Reference-contexts: First, self-calibration is performed, based on point correspondences obtained semi-automatically. Then the curved-based stereo algorithm of Luc Robert <ref> [18] </ref> is run to obtain correspondences, and the 3D reconstruction phase is performed in the coordinate system of the first camera using the method of Sec. 3.2. Results of the reconstruction are shown in figure 3 as a stereogram which shows that planar structures and angles are quite well captured.
Reference: [19] <author> R.Y. Tsai. </author> <title> Synopsis of Recent Progress on Camera Calibration for 3D Machine Vision. </title> <editor> In Oussama Khatib, John J. Craig, and Tomas Lozano-Perez, editors, </editor> <booktitle> The Robotics Review, </booktitle> <pages> pages 147-159. </pages> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: 1 Introduction The task of establishing the relationship between 3D world coordinates and 2D pixel coordinates is a prerequisite for 3D vision. The classical approach <ref> [19] </ref> is model based, and thus lacks a lot of flexibility: calibration grids have to be present in the scene.
Reference: [20] <author> R.Y. Tsai and T.S. Huang. </author> <title> Uniqueness and estimation of three-dimensional motion parameters of rigid objects wirth curved surfaces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 13-27, </pages> <year> 1984. </year>
Reference-contexts: The problem of factoring the essential matrix into a rotation R and the translation t such that: E = 0 t 3 t 2 t 2 t 1 0 | -z - R is classical <ref> [11, 20, 8] </ref>. Iterative minimization.
Reference: [21] <author> T. Vieville. </author> <title> Auto-calibration of visual sensor parameters on a robotic head. </title> <journal> Image and Vision Computing, </journal> <volume> 12, </volume> <year> 1994. </year>
Reference-contexts: Thus a number of researchers have recently investigated limited self-calibration techniques: almost all of them have put more limitations on their methods by adding supplementary constraints, such as restriction on the camera motions <ref> [5, 1, 4, 21, 10] </ref>. When the camera motion is exactly known in some reference frame, then these methods should be rather called "calibration from motion" than self-calibration, where motion and calibration are estimated.
References-found: 21

