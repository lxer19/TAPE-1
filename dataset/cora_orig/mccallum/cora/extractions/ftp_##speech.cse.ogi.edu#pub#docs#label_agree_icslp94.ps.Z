URL: ftp://speech.cse.ogi.edu/pub/docs/label_agree_icslp94.ps.Z
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Title: LABELER AGREEMENT IN PHONETIC LABELING OF CONTINUOUS SPEECH  for Spoken Language Understanding  
Author: Ronald Cole, Beatrice T. Oshika, Mike Noel, Terri Lander, and Mark Fanty 
Address: 20000 N.W. Walker Road, P.O. Box 91000, Portland, OR 97291-1000, USA  
Affiliation: Center  Oregon Graduate Institute of Science and Technology  
Abstract: This paper analyzes inter-labeler agreement of label choice and boundary placement for human phonetic transcriptions of continuous telephone speech in different languages. In experiment one, English, German, Mandarin and Spanish are labeled by fluent speakers of the languages. In experiment two, German and Hindi are labeled by linguists who do not speak the languages. Experiment two uses a somewhat finer phonetic transcription set than experiment one. We compare the transcriptions of the utterances in terms of the minimum number of substitutions, insertions and deletions needed to map one transcription to the other. Native speakers agree on the average 67.52% of the time at the finest level of labeling, including diacritics. Non-native linguists agree 34.41% of the time. The implications of the results are discussed for evaluation of phonetic recognition algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> W. Fisher, G. R. Doddington, and K. Goudi-Marshall. </author> <title> "The darpa speech recognition research database: Specification and status," </title> <booktitle> Proceedings DARPA Speech Recognition Workshop, </booktitle> <pages> pp 93-100, </pages> <month> February </month> <year> 1986. </year>
Reference-contexts: 1. INTRODUCTION Phonetically transcribed continuous speech databases are important for understanding the phonological structure of fluent speech and for developing and evaluating segmentation and phonetic recognition algorithms for speech and language recognition. With the availability of phonetically labeled public domain corpora such as TIMIT <ref> [1] </ref>, it has become standard practice to evaluate phonetic recognition algorithms in terms of hand labeled speech.
Reference: 2. <author> Ronald A. Cole and Yeshwant K. Muthusamy, </author> <title> "Perceptual Studies On Vowels Excised From Continuous 3 Speech," </title> <booktitle> Proceedings ICSLP, </booktitle> <year> 1992, </year> <pages> pp 1091-1094. </pages>
Reference-contexts: "correct." Is this a reasonable assumption? Perceptual studies support the notion of variability in human judgments of speech sounds; subjects presented with vowel sounds excised from TIMIT utterances agreed on the vowel category about 60-75% of the time when the vowel was presented in its left and right phonetic context <ref> [2] </ref>, [3]. Given this perceptual variability, it is useful to examine the level of agreement among transcribers. We examined inter-transcriber reliability as a function of precision of available labels and the transcribers' familiarity with the language.
Reference: 3. <author> Gary N. Tajchman and Marcia A. Bush, </author> <title> "Effects of Context and Redundancy in the Perception of Naturally Produced English Vowels," </title> <booktitle> Proceedings ICSLP, </booktitle> <year> 1992, </year> <pages> pp 839-842. </pages>
Reference-contexts: Is this a reasonable assumption? Perceptual studies support the notion of variability in human judgments of speech sounds; subjects presented with vowel sounds excised from TIMIT utterances agreed on the vowel category about 60-75% of the time when the vowel was presented in its left and right phonetic context [2], <ref> [3] </ref>. Given this perceptual variability, it is useful to examine the level of agreement among transcribers. We examined inter-transcriber reliability as a function of precision of available labels and the transcribers' familiarity with the language.
Reference: 4. <author> Y. K. Muthusamy, R. A. Cole, and B. T. Oshika, </author> <title> "The OGI multi-language telephone speech corpus," </title> <booktitle> Proceedings of the International Conference on Spoken Language Proceedings, </booktitle> <address> Banff, Alberta, Canada, Octo-ber, </address> <year> 1992, </year> <pages> pp 895-898. </pages>
Reference-contexts: In experiment one, up to 50 seconds of extemporaneous speech from ten telephone calls in four languages|English, German, Mandarin and Spanish (approximately 30 minutes of continuous speech), were selected from the OGI Multi Language Corpus <ref> [4] </ref>. Each call was transcribed independently by two transcribers. The transcribers were either native speakers of the language or considered very competent speakers. They each underwent extensive training procedures to learn the labeling tools, label sets, and labeling conventions. <p> These were all base labels, which do not include diacritics. Additionally, there were 12 nonspeech labels. 2.3. Data The data transcribed for this experiment were a subset of the OGI Multi-language Telephone Speech corpus <ref> [4] </ref>, the NIST standard for automatic language identification. This corpus contains several 50 second segments of continuous speech, referred to as "stories." Ten stories were randomly selected in each language, resulting in approximately 30 minutes of speech. Each story was transcribed by two la-belers. 2.4. Analysis Label selection. <p> In addition, there were nine nonspeech labels available. The seven additional German Worldbet labels required finer discrimination of vowels and diphthongs. 3.3. Data For this experiment a two-second excerpt was extracted from each of 15 German and Hindi stories. These segments came from the OGI Multi-language Telephone Speech corpus <ref> [4] </ref>. The segments were gender balanced, began and ended with silence, and had few intersegmental pauses. 3.4. Analysis The same analyses were performed as in experiment one. 3.5. Results Table 3 shows the agreement between the two labelers for both Hindi and German.
Reference: 5. <author> Terri Lander, S. T. Metzler, </author> <title> The CSLU Labeling Guide, </title> <address> CSLU Oregon, </address> <month> February, </month> <year> 1994. </year>
Reference-contexts: They were able to listen repeatedly to any length interval of speech and to view an associated waveform and spectrographic display. They were asked to mark segment boundaries, and to label the segments using OGI-bet <ref> [5] </ref>. A second experiment compared transcriptions of 15 two-second files of German and Hindi by two labelers trained in phonetics who are are not speakers of Hindi or German. The transcribers used Worldbet [6] and a set of segmentation conventions taken from [5] developed particularly for this study. <p> boundaries, and to label the segments using OGI-bet <ref> [5] </ref>. A second experiment compared transcriptions of 15 two-second files of German and Hindi by two labelers trained in phonetics who are are not speakers of Hindi or German. The transcribers used Worldbet [6] and a set of segmentation conventions taken from [5] developed particularly for this study. The objective of this study was to compare the performance of transcribers with extensive phonetics background but limited familiarity with the specific languages. 2. EXPERIMENT ONE 2.1. Transcribers The transcribers for each language were either CSLU staff or students. <p> Transcription Procedure Transcription was supported by the OGI Speech tools [7], which display the waveform and corresponding spectro gram. Proceedings of ICSLP-94, Sept., 1994. 1 c fl IEEE 1994 An early version of the CSLU Labeling Guide <ref> [5] </ref> defined the label set and segmentation procedures. The labelers used OGIbet, which is a broad phonetic label set based on TIMIT. OGIbet offers additional phonetic detail beyond TIMIT by use of diacritics.
Reference: 6. <author> James L. Hieronymus, </author> <title> "Ascii phonetic symbols for the world's languages: </title> <institution> Worldbet," AT&T Bell Laboratories Technical Memo, </institution> <year> 1994. </year>
Reference-contexts: They were asked to mark segment boundaries, and to label the segments using OGI-bet [5]. A second experiment compared transcriptions of 15 two-second files of German and Hindi by two labelers trained in phonetics who are are not speakers of Hindi or German. The transcribers used Worldbet <ref> [6] </ref> and a set of segmentation conventions taken from [5] developed particularly for this study. The objective of this study was to compare the performance of transcribers with extensive phonetics background but limited familiarity with the specific languages. 2. EXPERIMENT ONE 2.1. <p> Transcribers The two transcribers were TL (also transcribed Spanish) and BO. Both are trained in phonetics, in spectrogram reading, and in the use of the OGI Speech tools. 3.2. Transcription Procedure Transcription was done using the OGI Speech Tools [7]. The labelers used Worldbet, <ref> [6] </ref> which captures more phonetic detail in the base symbol set than in OGIbet. There were 69 German base labels to choose from (compared to 62 OGIbet) and 67 Hindi base labels. In addition, there were nine nonspeech labels available.
Reference: 7. <author> CSLU. </author> <title> "OGI speech tools user's manual," </title> <type> Technical report, </type> <institution> Center for Spoken Language Understanding, Ore-gon Graduate Institute, </institution> <year> 1993. </year> <month> 4 </month>
Reference-contexts: Although there are three labelers, only two labeled each story. The Spanish transcribers were TL (fluent) and AJ (native, see German). TL is trained in phonetics and has completed the spectrogram reading course along with practical training. 2.2. Transcription Procedure Transcription was supported by the OGI Speech tools <ref> [7] </ref>, which display the waveform and corresponding spectro gram. Proceedings of ICSLP-94, Sept., 1994. 1 c fl IEEE 1994 An early version of the CSLU Labeling Guide [5] defined the label set and segmentation procedures. The labelers used OGIbet, which is a broad phonetic label set based on TIMIT. <p> Transcribers The two transcribers were TL (also transcribed Spanish) and BO. Both are trained in phonetics, in spectrogram reading, and in the use of the OGI Speech tools. 3.2. Transcription Procedure Transcription was done using the OGI Speech Tools <ref> [7] </ref>. The labelers used Worldbet, [6] which captures more phonetic detail in the base symbol set than in OGIbet. There were 69 German base labels to choose from (compared to 62 OGIbet) and 67 Hindi base labels. In addition, there were nine nonspeech labels available.
References-found: 7

