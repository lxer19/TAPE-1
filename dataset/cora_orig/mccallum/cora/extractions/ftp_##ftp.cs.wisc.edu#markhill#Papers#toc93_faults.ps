URL: ftp://ftp.cs.wisc.edu/markhill/Papers/toc93_faults.ps
Refering-URL: http://www.cs.wisc.edu/~markhill/
Root-URL: 
Title: Performance Implications of Tolerating Cache Faults  
Author: Andreas Farid Pour Mark D. Hill 
Keyword: Index Terms: computer architecture, cache performance, trace-driven simulation, fault tolerance, on-chip caches, microprocessors.  
Address: 1210 West Dayton Street Madison, Wisconsin 53706  
Affiliation: Computer Sciences Department University of Wisconsin Madison  
Abstract: Microprocessors are increasingly incorporating one or more on-chip caches. These caches are occupying a greater share of chip area, and thus may be the locus of manufacturing defects. Some of these defects will cause faults in cache tag or data memory. These faults can be tolerated by disabling the cache blocks that contain them. This approach lets chips with defects be used without requiring on-chip caches to have redundant row or columns or to use error correcting codes. Disabling blocks, however, typically increases a cache's miss ratio. This paper investigates how much cache miss ratios increase when blocks are disabled. It shows how the mean miss ratio increase can be characterized as a function of the miss ratios of related caches, develops an efficient approach for calculating the exact distribution of miss ratio increases from all fault patterns, and applies this approach to the ATUM traces [1] . Results reveal that the mean relative miss ratio increase from a few faults decreases with increasing cache size, and is negligible (&lt; 2% per defect) unless a set is completely disabled by faults. The maximum relative increase is also acceptable (&lt; 5% per fault) if no set is entirely disabled. hhhhhhhhhhhhhhhhhh The preliminary version of this work appeared as University of Wisconsin Computer Sciences Technical Report #991, January 1991. This work is supported in part by the National Science Foundation (MIPS-8957278 and CCR-8902536), A.T.& T. Bell Laboratories, Cray Research Foundation and Digital Equipment Corporation. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Agarwal, A., Sites, R., and M. Horowitz, ``ATUM: </author> <title> A New Technique for Capturing Address Traces Using Microcode,'' </title> <booktitle> Proc. the 13th Annual Symposium on Computer Architecture, </booktitle> <pages> pp. 119 - 129, </pages> <address> Tokyo, Japan, </address> <month> June </month> <year> 1986. </year>
Reference-contexts: We concentrate on caches with few faults, because we believe that chips with many faults in the cache will usually have faults in other critical resources, and thus will be discarded anyway. Results with the ATUM traces <ref> [1] </ref> suggest that the mean relative miss ratio increase from a few faults decreases with increasing cache size, and is usually small (&lt; 5% per fault). Furthermore, if no set is completely disabled, mean degradation for large caches is negligible. <p> We validated our results by comparing them with results of the exhaustive simulations. We use the ATUM traces, because they were the only available traces that included operating systems references and multiprogramming effects <ref> [1] </ref>. Table 2 shows the number of instruction fetches, data reads, and data writes for each of the traces used, as well as a brief description of their origins. Due to the large number of traces, we give results only for a combined trace, denoted by all. <p> We then described how to extend all-associativity simulation [5] to calculate these metrics for many caches with a single pass through an address trace. Finally, we applied this technique to the ATUM traces <ref> [1] </ref>. Results suggest that the mean relative miss ratio increase from a few faults is negligible if no sets are completely disabled and is small in any case (&lt; 5% per fault).
Reference: 2. <author> Agarwal, A., Horowitz, M., and J. Hennessy, </author> <title> ``An Analytical Cache Model,'' </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> vol. 7, no. 2, </volume> <pages> pp. 184 - 215, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: For brevity, we will usually refer to this metric as the relative increase. Unless otherwise indicated, the block size will be 16 bytes. 4.1. Single Faults various associativities (number of blocks per set) and cache sizes. The miss ratios ostensibly follow the behavior of fault-free cache miss ratios <ref> [2, 4, 5] </ref> : for all associativities, the miss ratios decrease with - -- hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Data Data Instruction Name Reads Writes Fetches Description iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii dec0.000 106459 72500 183023 DECSIM behavioral simulation of some cache hardware dec0.003 103906 73001 176533 Same as previous fora.000 108979 79156 199799 FORTRAN compiler compiling airco.for
Reference: 3. <author> Berenbaum, A. D., Colbry, B. W., D. R. Ditzel, R. D. Freeman, H. R. McLellan, K. J. O'Connor, and M. Shoji, </author> <title> ``CRISP: A Pipelined 32-bit Microprocessor with 13-kbit of Cache Memory,'' </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. SC-22, no. 5, </volume> <pages> pp. 776 - 782, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: 1. Introduction Commercial and academic microprocessor architectures are increasingly incorporating caches on the processor chip itself to avoid off-chip latencies <ref> [3, 6, 8, 12] </ref>. These on-chip caches are currently small, but the trend is toward larger sizes to hide relatively slower off-chip memory speeds; thus, these chips devote an increasing portion of their area to the memory (tags and blocks) of the cache.
Reference: 4. <author> Goodman, J. R., </author> <title> ``Using Cache Memory to Reduce Processor-Memory Traffic,'' </title> <booktitle> Proc. Tenth International Symposium on Computer Architecture, </booktitle> <pages> pp. 124 - 131, </pages> <address> Stockholm, Sweden, </address> <month> June </month> <year> 1983. </year>
Reference-contexts: For brevity, we will usually refer to this metric as the relative increase. Unless otherwise indicated, the block size will be 16 bytes. 4.1. Single Faults various associativities (number of blocks per set) and cache sizes. The miss ratios ostensibly follow the behavior of fault-free cache miss ratios <ref> [2, 4, 5] </ref> : for all associativities, the miss ratios decrease with - -- hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Data Data Instruction Name Reads Writes Fetches Description iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii dec0.000 106459 72500 183023 DECSIM behavioral simulation of some cache hardware dec0.003 103906 73001 176533 Same as previous fora.000 108979 79156 199799 FORTRAN compiler compiling airco.for
Reference: 5. <author> Hill, M. D. and Smith, A. J., </author> <title> ``Evaluating Associativity in CPU Caches,'' </title> <journal> IEEE Trans. on Computers, </journal> <volume> vol. C-38, no. 12, </volume> <pages> pp. 1612 - 1630, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: We show the mean miss ratio for a 64K-byte cache with associativity four, a block size of 32 bytes and one fault is (511 /512) m 0 + (1/512) m 1 . Second, we show how all-associativity simulation <ref> [5] </ref> can be extended to collect information for finding the effect of all possible patterns of faults on caches with many associativities and sizes (but one block size) in one pass through an address trace. Sohi, on the other hand, performed a simulation for each fault pattern in each cache. <p> In this section, we show how to find the D i (j)'s for many caches with a single pass through an address trace. We also describe the address traces that we use. All-associativity simulation <ref> [5] </ref> is an algorithm that calculates the miss ratios for caches of many sizes and associativities with a single pass through an address trace, provided that all caches have the same block size, use the least-recently-used replacement algorithm and do no prefetching. <p> For brevity, we will usually refer to this metric as the relative increase. Unless otherwise indicated, the block size will be 16 bytes. 4.1. Single Faults various associativities (number of blocks per set) and cache sizes. The miss ratios ostensibly follow the behavior of fault-free cache miss ratios <ref> [2, 4, 5] </ref> : for all associativities, the miss ratios decrease with - -- hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Data Data Instruction Name Reads Writes Fetches Description iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii dec0.000 106459 72500 183023 DECSIM behavioral simulation of some cache hardware dec0.003 103906 73001 176533 Same as previous fora.000 108979 79156 199799 FORTRAN compiler compiling airco.for <p> From Equation (3) we can see that the mean relative increase is proportional to s 1 hh . Furthermore, the fraction m (n) m (n - 1) hhhhhhhh also tends to decrease with increasing cache size <ref> [5] </ref>. MAX Q H = 1 hhhhhh i Q H . For associativities of two and larger, as cache size gets larger, the maximum relative increase generally gets smaller because i Q H decreases faster than the total number of misses (M (n)) declines. <p> We first showed how the miss ratio of a cache with any fault pattern can be calculated from the number of references to the j-th block in the i-th of s sets. We then described how to extend all-associativity simulation <ref> [5] </ref> to calculate these metrics for many caches with a single pass through an address trace. Finally, we applied this technique to the ATUM traces [1].
Reference: 6. <author> Horowitz, M., Chow, P., D. Stark, R. T. Simoni, A. Salz, S. Przybylski, J. Hennessy, G. Gulak, A. Agarwal, and J. M. Acken, ``MIPS-X: </author> <title> A 20-MIPS Peak, 32-bit Microprocessor with On-Chip Cache,'' </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. SC-22, no. 5, </volume> <pages> pp. 790 - 799, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: 1. Introduction Commercial and academic microprocessor architectures are increasingly incorporating caches on the processor chip itself to avoid off-chip latencies <ref> [3, 6, 8, 12] </ref>. These on-chip caches are currently small, but the trend is toward larger sizes to hide relatively slower off-chip memory speeds; thus, these chips devote an increasing portion of their area to the memory (tags and blocks) of the cache.
Reference: 7. <author> Jouppi, Norman P., </author> <title> ``Improving Direct-Mapped Cache Performance by the Addition of a Small Fully-Associative Cache and Prefetch Buffers,'' </title> <booktitle> Proc. 17th Annual Symposium on Computer Architecture, Computer Architecture N ews, </booktitle> <volume> vol. 18, no. 2, </volume> <pages> pp. 364-373, </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: If all blocks in a set are faulty, then one can either (a) discard the chip, (b) bypass the cache and send the requested data directly to its destination (CPU or memory), or (c) save the data in a special buffer, such as a victim cache <ref> [7] </ref>. Clearly, applying option (a) to a direct-mapped cache is equivalent discarding all faulty chips. Disabling cache blocks offers two advantages over using redundant memory, but also suffers two disadvantages. <p> Furthermore, method (3) is clearly faster for chips with no faults (where d = 0), and it is likely that its performance can be improved significantly with victim caches <ref> [7] </ref>. To the best of our knowledge, the only paper to do a detailed investigation of the effect on miss ratios of disabling cache blocks is by Sohi [15]. Sohi investigated the degradation in cache performance by randomly injecting faults into the cache and then running a trace-driven simulation.
Reference: 8. <author> Kadota, H., Miyake, J., I. Okabayashi, T. Maeda, T. Okamoto, M. Nakajima, and K. Kagawa, </author> <title> ``A 32-bit CMOS Microprocessor with On-Chip Cache and TLB,'' </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. SC-22, no. 5, </volume> <pages> pp. 800 - 807, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: 1. Introduction Commercial and academic microprocessor architectures are increasingly incorporating caches on the processor chip itself to avoid off-chip latencies <ref> [3, 6, 8, 12] </ref>. These on-chip caches are currently small, but the trend is toward larger sizes to hide relatively slower off-chip memory speeds; thus, these chips devote an increasing portion of their area to the memory (tags and blocks) of the cache.
Reference: 9. <author> Litzkow, M., Livny, M., and M. W. </author> <title> Mutka, ``Condor A Hunter of Idle Workstations,'' </title> <booktitle> Proceedings of the 8th International Conference os Distributed Computing Systems, </booktitle> <address> San Jose, California, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: We expect that the overall impact of this worst-case behavior will not be significant for machines used to run many different programs. 6. Acknowledgments We thank the Condor project at the University of Wisconsin <ref> [9] </ref> for providing us with the computational resources required for the large number of lengthy simulations performed and G. Sohi for reading and improving drafts of this paper.
Reference: 10. <author> Mattson, R. L., Gecsei, J., D. R. Schultz, and I. L. Traiger, </author> <title> ``Evaluation Techniques for Storage Heirarchies,'' </title> <journal> IBM Systems Journal, </journal> <volume> vol. 9, no. 2, </volume> <pages> pp. 78 - 117, </pages> <year> 1970. </year>
Reference-contexts: Assume a cache has s sets labeled 0 through s - 1, and is referenced by a dynamic reference stream of R references. Assuming all blocks within a set are ordered according to some stack replacement algorithm <ref> [10] </ref> (such as LRU), define D i (j) to be the number of references to the j-th block in the i-th set hhhhhhhhhhhhhhhhhh 2 Assume that the miss ratio of a cache with associativity zero is one. 3 For m&lt;&lt;s, the number of ways to place m faults in s sets
Reference: 11. <author> Patterson, D. A., Garrison, P., M. Hill, D. Lioupis, C. Nyberg, T. Sippel, and K. Van Dyke, </author> <title> ``Architecture for a VLSI Instruction Cache for a RISC,'' </title> <booktitle> The Tenth Annual Symposium on Computer - -- Architecture, </booktitle> <volume> vol. 11, no. 3, </volume> <pages> pp. 108 - 116, </pages> <address> Stockholm, Sweden, </address> <month> June 13-17, </month> <year> 1983. </year>
Reference-contexts: Finally, the number of sets is the cache size divided by the product of the block size and associativity. Caches are usually characterized by their block size, associativity and cache size. One approach to implement the disabling of cache blocks, proposed by Patterson, et al. <ref> [11] </ref>, is to use a second valid bit. Each cache block normally contains a valid bit that is set when a block is brought in and reset when the block is invalidated.
Reference: 12. <author> Phillips, D., </author> <title> ``The Z80000 Microprocessor,'' </title> <journal> IEEE Micro, pp. </journal> <volume> 23 - 36, </volume> <month> December </month> <year> 1985. </year>
Reference-contexts: 1. Introduction Commercial and academic microprocessor architectures are increasingly incorporating caches on the processor chip itself to avoid off-chip latencies <ref> [3, 6, 8, 12] </ref>. These on-chip caches are currently small, but the trend is toward larger sizes to hide relatively slower off-chip memory speeds; thus, these chips devote an increasing portion of their area to the memory (tags and blocks) of the cache.
Reference: 13. <author> Pour, Farid and Hill, Mark D., </author> <title> ``Performance Implications of Tolerating Cache Faults,'' </title> <type> Computer Sciences Technical Report #991, </type> <institution> Univ. of Wisconsin, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: Due to the large number of traces, we give results only for a combined trace, denoted by all. We constructed the combined trace by alternating the individual traces and cache flushes. For results from two representative individual traces, see Pour and Hill <ref> [13] </ref>. We only simulate caches smaller than 64K bytes, because the individual traces are not long enough (typically, 400,000 references) to properly exercise larger caches. 4. Results This section presents simulation results for one, two and many faults.
Reference: 14. <author> Smith, A. J., </author> <title> ``Cache Memories,'' </title> <journal> Computing Surveys, </journal> <volume> vol. 14, no. 3, </volume> <pages> pp. 473 - 530, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: Thus, instead of building redundancy on top of the redundant memory in a cache, this method just causes the cache to avoid using the memory that contains faulty bits. Caches are buffers used to hold data from recently-used parts of main memory <ref> [14] </ref>. Data is usually transferred from main memory in aligned blocks (also called lines). The number of bytes in a block is the block size.
Reference: 15. <author> Sohi, G., </author> <title> ``Cache Memory Organization to Enhance the Yield of High-Performance VLSI Processors,'' </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 38, no. 4, </volume> <pages> pp. 484 - 492, </pages> <month> April </month> <year> 1989. </year> - -- 
Reference-contexts: To the best of our knowledge, the only paper to do a detailed investigation of the effect on miss ratios of disabling cache blocks is by Sohi <ref> [15] </ref>. Sohi investigated the degradation in cache performance by randomly injecting faults into the cache and then running a trace-driven simulation. For each cache, Sohi reports the average miss ratio of several simulations with different fault patterns.
References-found: 15

