URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/epk/www/papers/Paper.ps.gz
Refering-URL: http://www.cs.cmu.edu/~hebert/home.html
Root-URL: 
Email: epk@cs.cmu.edu  
Title: Stereo Perception and Dead Reckoning for a Prototype Lunar Rover  
Author: Eric Krotkov, Martial Hebert, and Reid Simmons 
Address: Pittsburgh, PA 15213  
Affiliation: Robotics Institute Carnegie Mellon University  
Abstract: This paper describes practical, effective approaches to stereo perception and dead reckoning, and presents results from systems implemented for a prototype lunar rover operating in natural, outdoor environments. The stereo perception hardware includes a binocular head mounted on a motion-averaging mast. This head provides images to a normalized correlation matcher, that intelligently selects what part of the image to process (saving time), and subsamples the images (again saving time) without subsampling disparities (which would reduce accuracy). The implementation has operated successfully during long-duration field exercises, processing streams of thousands of images. The dead reckoning approach employs encoders, inclinometers, a compass, and a turn-rate sensor to maintain the position and orientation of the rover as it traverses. The approach integrates classical odometry with inertial guidance. The implementation succeeds in the face of significant sensor noise by virtue of sensor modelling, plus extensive filtering. The stereo and dead reckoning components are used by an obstacle avoidance planner that projects a finite number of arcs through the terrain map, and evaluates the traversability of each arc to choose a travel direction that is safe and effective. With these components integrated into a complete navigation system, a prototype rover has traversed over 1 km in lunar-like environments. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> C. Angle and R. Brooks. Small Planetary Rovers. </editor> <booktitle> In Proc. IEEE Intl. Workshop on Intelligent Robots and Systems, </booktitle> <pages> pp. 383-388, </pages> <address> Tsuchiura, Japan, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: Finally, we summarize the results, and address work required to return to the Moon in this millennium. 2. Related Work 2.1 Stereo Perception A majority of the efforts to navigate mobile robots in natural terrain have employed laser rangefinders [4][12][13][20] or proximity sensors <ref> [1] </ref> rather than stereo. There have been notable exceptions. Matthies [23] developed a near-real-time system using Datacube hardware, and demonstrated 100 m traverses with a planetary rover prototype. Faugeras et al. [3][27] developed a real-time system using Digital Signal Processors (DSPs).
Reference: [2] <author> J. Bares and W. Whittaker, </author> <title> Configuration of Autonomous Walkers for Extreme Terrain, </title> <journal> Intl. J. Robotics Research, </journal> <volume> 13(1):?-?, </volume> <month> February </month> <year> 1994. </year>
Reference-contexts: Although the degree of autonomy is high, the system has yet to be tested in extreme terrain for long durations. Ambler is a six-legged walker developed at Carnegie Mellon University <ref> [2] </ref>. Under autonomous control, Ambler traversed over 100 m in rugged terrain including meter-scale obstacles, and over 500 m in benign terrain including 15 degree slopes and cross-slopes [21]. The navigation system relied on accurate terrain maps built from laser rangefinder data.
Reference: [3] <author> L. Boissier, B. Hotz, C. Proy, O. Faugeras, P. Fua. </author> <title> Autonomous Planetary Rover (VAP): Onboard Perception System Concept and Stereovision by Correlation. </title> <booktitle> In Proc. IEEE Intl. Conf. Robotics and Automation, </booktitle> <pages> pp. 181-186, </pages> <address> Nice, France, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: A second approach is to use special-purpose hardware in order to perform the correlations. This solution has led to several real-time and near real-time stereo systems using DSP <ref> [3] </ref> or Datacube systems [23]. However, for our application, considerations of cost, power, and availability limit us to conventional computing.
Reference: [4] <author> R. Chatila, R. Alami, S. Lacroix, J. Perret, and C. </author> <title> Proust. Planet Exploration by Robots: From Mission Planning to Autonomous Navigation. </title> <booktitle> In Proc. Intl. Conf. Advanced Robotics, </booktitle> <pages> pp. 91-96, </pages> <address> Tokyo, Japan, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: The approach has been tested in an experimental testbed called Eden <ref> [4] </ref>. In Eden, Adam used vision for landmark recognition, a laser rangefinder for obstacle detection, a coarse-scale planner for sub-goal selection, and 2D and 3D motion planners for obstacle avoidance.
Reference: [5] <author> F. Cozman and E. Krotkov. </author> <title> Digital Sextant. </title> <booktitle> To appear in Proc. IEEE Intl. Conf. Robotics and Automation, </booktitle> <address> Nagoya, Japan, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Future work in dead reckoning will improve performance by porting all of the preprocessing and processing onto the on-board system, thus reducing delays. We will then extend the positioning system to use visual landmarks; specifically, we plan to incorporate novel techniques for visual landmark navigation and celestial navigation <ref> [5] </ref>. Our experimental work will take two directions: we will continue to demonstrate and quantify autonomous navigation capabilities using stereo and local obstacle avoidance, and we will also investigate more carefully issues of mixed-mode and safeguarded teleoperation.
Reference: [6] <author> O. Faugeras. </author> <title> Three-Dimensional Computer Vision: A Geometric Viewpoint. </title> <publisher> MIT Press. </publisher> <year> 1994. </year>
Reference-contexts: the order of 70 ms, a negligible fraction of the total computation time compared to the fraction taken by correlation. d stop t stop v v 2mg ( ) += 10 The best disparity d (x,y) is computed by finding the maximum over d of the normalized correlation C (x,y,d) <ref> [6] </ref>: In this expression, W is the window [x-w x ,x+w x ][y-w y ,y+w y ], s (x,y) is the standard deviation of the intensity values in W and n is the number of pixels in the window, n = (2w x +1)(2w y +1).
Reference: [7] <author> L. Feng, J. Borenstein, and H. R. Everett. </author> <title> Where am I? Sensors and Methods for Autonomous Mobile Robot Positioning. </title> <type> Technical Report UM-MEAM-94-21, </type> <institution> University of Michigan, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: The fundamentals of odometry (relating wheel revolutions to vehicle pose) and inertial guidance (relating angular accelerations to vehicle pose) are well known <ref> [7] </ref>, so we will not discuss these. Our contribution is to integrate odometry and inexpensive inertial guidance. We use a suite of simple, inexpensive sensors (wheel encoders, compass, turn-rate sensor, and inclinometers) which are not standard equipment on most mobile robots.
Reference: [8] <author> E. Gat, R. Desai, R. Ivlev, J. Loch, and D. Miller, </author> <title> Behavior Control for Robotic Exploration of Planetary Surfaces, </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 10(4) </volume> <pages> 490-503, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: For this traverse, operators specified navigational waypoints, between which the 3 vehicle traveled autonomously. Rocky is a family of six-wheeled rovers developed at JPL. The Rocky rovers use a control architecture that creates task-oriented modules defined as behaviors and provides for programmable inter-module connections <ref> [8] </ref>. Rocky rovers have performed a number of traverses in outdoor terrain using short-range sensors such as laser light stripers. The Rocky concept is currently the baseline design for the Mars Pathfinder mission, calling for tens of meters of travel, and scheduled for launch in 1996 [33].
Reference: [9] <author> K. Gatland. </author> <title> Robot Explorers: The Encyclopedia of Spaceight in Color. </title> <publisher> Macmillan, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: In particular, capabilities are needed for driving the rover over varied terrain and safeguarding its operation. Previous experience with planetary robots (in particular, Lunokhod II and the Viking soil scoop <ref> [9] </ref>) illustrated how laborious and unpredictable time-delayed teleoperation is for remote operators. Potentially superior modes of operation include supervised teleoperation and autonomous control, because in these modes the rover itself is responsible for making many of the decisions necessary to maintain progress and safety.
Reference: [10] <author> G. Giralt. </author> <title> Technical Thresholds between Robotic, Man-Tended and Permanently Manned Exploration and Exploitation of the Moon. </title> <booktitle> In Proc. ESA Intl. Lunar Workshop, </booktitle> <pages> pp. 103-121, </pages> <address> Beatenberg, Switzerland, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Adam is a six-wheeled rover developed as part of the Iares project in Europe, whose goal is to build a ground demonstrator with capabilities to perform an ambitious (1,000 km traverse over 13 months) scientific mission to Mars by the end of the millennium <ref> [10] </ref>. The approach has been tested in an experimental testbed called Eden [4]. In Eden, Adam used vision for landmark recognition, a laser rangefinder for obstacle detection, a coarse-scale planner for sub-goal selection, and 2D and 3D motion planners for obstacle avoidance.
Reference: [11] <author> P. Grandjean and L. Matthies. </author> <title> Perception control for obstacle detection by a cross-country rover. </title> <booktitle> In Proc. IEEE Intl. Conf. Robotics and Automation, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: As we will see, the size of the sub-image is quite small, assuming that the system is in steady state and that the speed is approximately constant. A complete theory supporting this observation was developed by Kelly [17]. A similar window selection algorithm is described in <ref> [11] </ref>. We exploit this property in the following way: the planner computes the interval I Y = [Y min ,Y max ] of distance from the vehicle within which it needs data in order to expand its map.
Reference: [12] <author> M. Hebert and E. Krotkov. </author> <title> 3-D Measurements from Imaging Laser Radars. </title> <journal> Intl. J. Image and Vision Computing, </journal> <volume> 10(3) </volume> <pages> 170-178, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: This suggests that our stereo gives a precision level that is comparable with the precision of laser range finders used in other navigation systems <ref> [12] </ref>. We employ this simple error model, based on a one pixel disparity error, for the purpose of verifying that the stereo setup generates reasonable errors (cf. Section 5.4).
Reference: [13] <author> M. Hebert and E. Krotkov. </author> <title> Local Perception for Mobile Robot Navigation in Natural Terrain: Two Approaches. </title> <booktitle> In Proc. Workshop on Computer Vision for Space Applications, </booktitle> <pages> pp. 24-31, </pages> <address> Antibes, France, </address> <month> September </month> <year> 1993. </year>
Reference: [14] <author> T. Kanade. </author> <title> Development of a Video-Rate Stereo Machine. </title> <booktitle> In Proc. ARPA Image Understanding Workshop, Monterrey, </booktitle> <address> California, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Matthies [23] developed a near-real-time system using Datacube hardware, and demonstrated 100 m traverses with a planetary rover prototype. Faugeras et al. [3][27] developed a real-time system using Digital Signal Processors (DSPs). Ross [30] developed a trinocular stereo system for the Dante I walking robot. Kanade <ref> [14] </ref> developed a video-rate stereo machine that is capable of generating a dense range map at 30 frames per second. Each of these stereo systems has its virtues, and each exhibits great promise.
Reference: [15] <author> L. Katragadda, J. Murphy, and W. Whittaker. </author> <title> Rover Configuration for Entertainment-Based Lunar Excursion. </title> <booktitle> In International Lunar Exploration Conference, </booktitle> <address> San Diego, California, </address> <month> November </month> <year> 1994. </year> <month> 24 </month>
Reference-contexts: One promising, near-term scenario is to land a pair of rovers on the Moon, and to engage in a two-year, 1,000 kilometer traverse of historic sights, including Apollo 11, Surveyor 5, Ranger 8, Apollo 17 and Lunokhod II <ref> [15] </ref>. In this scenario, one of the rovers will be driven, returning continuous live video, while the other rover remains stationary, to provide high-resolution imagery of the surroundings and to serve as a communications link with Earth for both rovers. <p> Another distinguishing feature is that the other systems, except Robby, rely on laser rangefinders or proximity sensors rather than on stereo vision. The main difference with the Robby system is our utilization of general-purpose computing hardware. 3. Mobile Platform Until a new lunar rover <ref> [15] </ref> enters service, we are using a vehicle designed and built by Sandia National Laboratories [28] as a testbed to develop the remote driving techniques needed for a lunar mission.
Reference: [16] <author> A. Kelly. </author> <title> A Partial Analysis of the High Speed Autonomous Navigation Problem. </title> <type> Technical Report CMU-RI-TR-94-16, </type> <institution> Robotics Institute, Carnegie Mellon University, </institution> <year> 1994. </year>
Reference-contexts: The controller stops the robot if it does not receive a new command before that distance has been traversed. 4.2 Obstacle Avoidance Planner To decide where it is safe to drive, we have adapted techniques developed in ARPAs Unmanned Ground Vehicle program for cross-country navigation <ref> [16] </ref>. The basic idea is to evaluate the hazards along a discrete number of paths (corresponding to a set of steering commands) that the rover could possibly follow in the next few seconds of travel. <p> I Y is computed from the speed of the vehicle and from the anticipated delay in getting the result from stereo <ref> [16] </ref>. The stereo module uses I Y to compute the bounds of a sub-image, (y min ,y max ), and the corresponding bounds in disparity (d min ,d max ). <p> This suggests that it is advantageous to subsample the image in order to process fewer pixels while retaining enough data density for navigability evaluation. This idea has been used successfully in navigation systems using laser range finders <ref> [16] </ref>. In the case of stereo, we have to be more cautious because simple subsampling will automatically degrade the resolution of the disparity. In other words, we want less data but not at the cost of less accurate data.
Reference: [17] <author> A. Kelly. </author> <title> Adaptive Perception for Autonomous Vehicles. </title> <type> Technical Report CMU-RI-TR-94-18, </type> <institution> Robotics Institute, Carnegie Mellon University, </institution> <year> 1994. </year>
Reference-contexts: As we will see, the size of the sub-image is quite small, assuming that the system is in steady state and that the speed is approximately constant. A complete theory supporting this observation was developed by Kelly <ref> [17] </ref>. A similar window selection algorithm is described in [11]. We exploit this property in the following way: the planner computes the interval I Y = [Y min ,Y max ] of distance from the vehicle within which it needs data in order to expand its map.
Reference: [18] <author> E. Krotkov, J. Bares, L. Katragadda, R. Simmons, and R. Whittaker. </author> <title> Lunar Rover Technology Demonstrations with Dante and Ratler. </title> <booktitle> In Proc. Intl. Symp. Artificial Intelligence, Robotics, and Automation for Space, </booktitle> <institution> Jet Propulsion Laboratory, Pasadena, California, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: The rovers would periodically switch roles, continuing this way to explore the Moons surface. The resulting experience is intended to attract mass participation and evoke strong public interest in lunar exploration <ref> [18] </ref>. While the hardware aspects of such a mission are dauntingincluding challenges in communications, power generation, thermal control, and rover reliabilitythe software control aspects are equally challenging. In particular, capabilities are needed for driving the rover over varied terrain and safeguarding its operation. <p> The navigation system relied on accurate terrain maps built from laser rangefinder data. Dante II is an eight-legged walking and rappelling robot developed at Carnegie Mellon University <ref> [18] </ref>. Dante II descended 400 m over 35 degree slopes into the crater oor of Mt. Spurr, an active volcano in Alaska, where it successfully collected gas samples.
Reference: [19] <author> E. Krotkov, M. Hebert, M. Buffa, F. Cozman, and L. Robert. </author> <title> Stereo Driving and Position Estimation for Autonomous Planetary Rovers. </title> <booktitle> In Proc. IARP Workshop on Robotics in Space, </booktitle> <address> Montreal, Canada, </address> <month> July </month> <year> 1994. </year>
Reference: [20] <author> E. Krotkov and R. Hoffman. </author> <title> Terrain Mapping for a Walking Planetary Rover. </title> <journal> IEEE Trans. Robotics and Automation, </journal> <volume> 10(6) </volume> <pages> 728-739, </pages> <month> December </month> <year> 1994. </year>
Reference: [21] <author> E. Krotkov and R. Simmons, </author> <title> Perception, Planning, and Control for Autonomous Walking with the Ambler Planetary Rover. </title> <journal> Intl. J. Robotics Research, </journal> <note> To appear, </note> <year> 1995. </year>
Reference-contexts: Ambler is a six-legged walker developed at Carnegie Mellon University [2]. Under autonomous control, Ambler traversed over 100 m in rugged terrain including meter-scale obstacles, and over 500 m in benign terrain including 15 degree slopes and cross-slopes <ref> [21] </ref>. The navigation system relied on accurate terrain maps built from laser rangefinder data. Dante II is an eight-legged walking and rappelling robot developed at Carnegie Mellon University [18]. Dante II descended 400 m over 35 degree slopes into the crater oor of Mt.
Reference: [22] <author> P. Lescoe, D. Lavery, and R. Bedard. </author> <title> Navigation of military and space unmanned ground vehicles in unstructured terrains. </title> <booktitle> In Proc. Conf. Military Robotic Applications: Military Robotic Vehicles, </booktitle> <month> September </month> <year> 1991. </year>
Reference-contexts: This vehicle traversed on the order of 100 meters of cross-country terrain using stereo vision for obstacle avoidance at a speed of 2 meters/sec ADD CITATION. In a previous effort, the CARD-II system demonstrated a version of safeguarded teleoperation <ref> [22] </ref>. The accomplishments of these navigation systems are remarkable and historic. One distinguishing feature of the present work is greater travel distance (1 km, to date). Another distinguishing feature is that the other systems, except Robby, rely on laser rangefinders or proximity sensors rather than on stereo vision.
Reference: [23] <author> L. Matthies. </author> <title> Stereo Vision for Planetary Rovers: Stochastic Modeling to Near Real-Time Implementation. </title> <journal> Intl. J. Computer Vision, </journal> <volume> 8(1) </volume> <pages> 71-91, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Related Work 2.1 Stereo Perception A majority of the efforts to navigate mobile robots in natural terrain have employed laser rangefinders [4][12][13][20] or proximity sensors [1] rather than stereo. There have been notable exceptions. Matthies <ref> [23] </ref> developed a near-real-time system using Datacube hardware, and demonstrated 100 m traverses with a planetary rover prototype. Faugeras et al. [3][27] developed a real-time system using Digital Signal Processors (DSPs). Ross [30] developed a trinocular stereo system for the Dante I walking robot. <p> Robby is a six-wheeled rover developed at the Jet Propulsion Laboratory (JPL). Robby used stereo and a semi-autonomous control mode to traverse 100 m in a desert arroyo <ref> [23] </ref>. For this traverse, operators specified navigational waypoints, between which the 3 vehicle traveled autonomously. Rocky is a family of six-wheeled rovers developed at JPL. The Rocky rovers use a control architecture that creates task-oriented modules defined as behaviors and provides for programmable inter-module connections [8]. <p> A second approach is to use special-purpose hardware in order to perform the correlations. This solution has led to several real-time and near real-time stereo systems using DSP [3] or Datacube systems <ref> [23] </ref>. However, for our application, considerations of cost, power, and availability limit us to conventional computing.
Reference: [24] <author> L. Matthies. </author> <title> Toward stochastic modeling of obstacle detectability in passive stereo range imagery. </title> <booktitle> In Proc. IEEE Conf. Computer Vision and Pattern Recognition, </booktitle> <month> June </month> <year> 1992. </year>
Reference: [25] <author> L. Matthies and P. Grandjean. </author> <title> Stochastic performance modeling and evaluation of obstacle detectability with imaging sensors. </title> <journal> IEEE Trans. Robotics and Automation, </journal> <volume> 10(6) </volume> <pages> 783-791. </pages> <month> December </month> <year> 1994. </year>
Reference: [26] <author> C. Proy, M. Lamboley, and L. Rastel. </author> <title> Autonomous navigation system for the Marsokhod rover project. </title> <booktitle> In Proc. Third Intl. Symposium on Artificial Inteligence, Robotics, and Automation for Space, </booktitle> <month> October </month> <year> 1994. </year>
Reference-contexts: In practice we use fixed subsampling factors of dx = 5 and dy = 4. With these values, the stereo matching takes 0.7s on average on a Sparc10 workstation using the parameters of Figure 5. Those computation times are similar to those reported in <ref> [26] </ref>. Y (m) C C curve around the maximum 16 5.5 Performance The combination of selective windowing and partial subsampling allows us to achieve both the computational speed and the precision required for continuous motion at low speeds using a general-purpose workstation (with no special-purpose hardware).
Reference: [27] <author> C. Proy, B. Hotz, O. Faugeras, P. Gernesson, and M. Berthod. </author> <title> Onboard Vision System for a Mobile Planetary Exploration Robot. </title> <booktitle> In Proc. Workshop on Computer Vision for Space Applications, </booktitle> <pages> pp. 2-12, </pages> <address> Antibes, France, </address> <month> September </month> <year> 1993. </year>
Reference: [28] <author> J. Purvis and P. Klarer. RATLER: </author> <title> Robotic All Terrain Lunar Exploration Rover. </title> <booktitle> In Proc. Space Operations, Applications and Research Symposium, </booktitle> <institution> Johnson Space Center, Houston Texas, </institution> <year> 1992. </year>
Reference-contexts: The main difference with the Robby system is our utilization of general-purpose computing hardware. 3. Mobile Platform Until a new lunar rover [15] enters service, we are using a vehicle designed and built by Sandia National Laboratories <ref> [28] </ref> as a testbed to develop the remote driving techniques needed for a lunar mission. Ratler (Robotic All-Terrain Lunar Exploration Rover) is a battery-powered, four 4 wheeled, skid-steered vehicle, about 1.2 meters long and wide, with 50 cm diameter wheels (Figure 1).
Reference: [29] <author> L. Robert. </author> <title> Camera Calibration Without Feature Extraction. </title> <booktitle> In Proc. IEEE Intl. Conf. Pattern Recognition, </booktitle> <address> Jerusalem, </address> <year> 1994. </year>
Reference-contexts: In order to ensure that the epipolar lines are correctly aligned with the scanlines, we use a rectification procedure developed by Robert <ref> [29] </ref>. The rectification is applied to the input images and all the algorithms described below are applied to the rectified images. The computation time for rectifying a full image is 100 ms. As we will see below, we use typically only one third of the image. <p> P l and P r are computed by combining the rectification matrices with the calibration matrices computed using a standard calibration procedure <ref> [29] </ref>.
Reference: [30] <author> B. Ross. </author> <title> A Practical Stereo Vision System. </title> <booktitle> In Proc. IEEE Intl. Conf. Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 148-153, </pages> <address> New York. </address> <year> 1993. </year>
Reference-contexts: There have been notable exceptions. Matthies [23] developed a near-real-time system using Datacube hardware, and demonstrated 100 m traverses with a planetary rover prototype. Faugeras et al. [3][27] developed a real-time system using Digital Signal Processors (DSPs). Ross <ref> [30] </ref> developed a trinocular stereo system for the Dante I walking robot. Kanade [14] developed a video-rate stereo machine that is capable of generating a dense range map at 30 frames per second. Each of these stereo systems has its virtues, and each exhibits great promise.
Reference: [31] <author> L. Robert, M. Buffa, and M. Hebert. </author> <title> Weakly-Calibrated Stereo Perception for Rover Navigation. </title> <booktitle> In Proc. ARPA Image Understanding Workshop, </booktitle> <pages> pp. 1317-1324, </pages> <address> Monterey, California, </address> <month> November </month> <year> 1994. </year> <month> 25 </month>
Reference: [32] <author> R. Simmons. </author> <title> Structured Control for Autonomous Robots. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 10(1) </volume> <pages> 34-43, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: Interprocess communication and task sequencing is performed by the Task Control Architecture (TCA). TCA is a general-purpose architecture for mobile robots that provides support for distributed communication via sockets, task decomposition and scheduling, resource management, execution monitoring, and error recovery <ref> [32] </ref>. TCA-based systems consist of a number of distributed, concurrent processes that communicate via coarse-grained message passing. TCA connects processes, routes messages, and coordinates overall control and data ow.
Reference: [33] <author> H. Stone, </author> <booktitle> Design and Control of the MESUR/Pathfinder Microrover. In Proc. Intl. Conf. Advanced Robotics, </booktitle> <pages> pp. 263-270, </pages> <address> Tokyo, Japan, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: Rocky rovers have performed a number of traverses in outdoor terrain using short-range sensors such as laser light stripers. The Rocky concept is currently the baseline design for the Mars Pathfinder mission, calling for tens of meters of travel, and scheduled for launch in 1996 <ref> [33] </ref>. Adam is a six-wheeled rover developed as part of the Iares project in Europe, whose goal is to build a ground demonstrator with capabilities to perform an ambitious (1,000 km traverse over 13 months) scientific mission to Mars by the end of the millennium [10].
Reference: [34] <author> C. Thorpe, </author> <title> editor. Vision and Navigation: </title> <publisher> the Carnegie Mellon Navlab. Kluwer, </publisher> <year> 1990. </year>
Reference-contexts: As a consequence of the choice of inexpensive sensors, our approach requires aggressive filtering of the sensor readings. 2.3 Navigation Systems A significant number of systems have been fielded that are capable of self-reliant operation in outdoor, natural terrain. These include land vehicles such as the Navlab <ref> [34] </ref> and air vehicles such as the cruise missile. However, these vehicles operate under constraints (on mass, power, etc.) far different than those faced by planetary rovers.
References-found: 34

