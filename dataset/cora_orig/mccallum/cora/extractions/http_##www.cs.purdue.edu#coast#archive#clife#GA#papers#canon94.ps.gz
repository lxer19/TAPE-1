URL: http://www.cs.purdue.edu/coast/archive/clife/GA/papers/canon94.ps.gz
Refering-URL: http://www.cs.purdue.edu/coast/archive/clife/GA/papers/
Root-URL: http://www.cs.purdue.edu
Title: Convergence Analysis of Canonical Genetic Algorithms  
Author: G UNTER RUDOLPH 
Keyword: canonical genetic algorithm, global convergence, Markov chains, schema theorem  
Abstract: This paper analyzes the convergence properties of the canonical genetic algorithm (CGA) with mutation, crossover and proportional reproduction applied to static optimization problems. It is proved by means of homogeneous finite Markov chain analysis that a CGA will never converge to the global optimum regardless of the initialization, crossover operator and objective function. But variants of CGAs that always maintain the best solution in the population, either before or after selection, are shown to converge to the global optimum due to the irreducibility property of the underlying original nonconvergent CGA. These results are discussed with respect to the schema theorem.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.H. Holland, </author> <booktitle> Adaptation in natural and artificial systems, </booktitle> <address> Ann Arbor: </address> <publisher> The University of Michigan Press, </publisher> <year> 1975. </year>
Reference-contexts: 1 Introduction Canonical genetic algorithms (CGA) as introduced in <ref> [1] </ref> are often used to tackle static optimization problems of the type maxff (b) j b 2 IB l g (1) assuming that 0 &lt; f (b) &lt; 1 for all b 2 IB l = f0; 1g l and f (b) 6= const. <p> Section 4 is devoted to the Markov chain analysis of CGAs as well as their variants and contains the essential results. Finally, the results are discussed with respect to the schema theorem <ref> [1] </ref>. 1 The author is with the Department of Computer Science, LS XI, University of Dortmund, D-44221 Dortmund, Germany. <p> Therefore the probability that string b i resembles string b 0 i after mutation can be aggregated to P fb i ! b 0 i ) i ) &gt; 0 : (3) Usually, the crossover operator is applied with some probability p c 2 <ref> [0; 1] </ref> in order to construct a bit string from at least two other bit strings chosen at random. Although many crossover operators have been proposed a description can be omitted because the choice of a specific crossover operator does not effect the subsequent analysis. <p> For each entry, p ij 2 <ref> [0; 1] </ref> and P jSj j=1 p ij = 1 for all i 2 S. Matrices with the above properties are called stochastic. <p> This leads to: Theorem 3 The transition matrix of the CGA with mutation probability p m 2 (0; 1), crossover probability p c 2 <ref> [0; 1] </ref> and proportional selection is primitive. Proof: The crossover operator may be regarded as a random total function whose domain and range are S, i.e., each state of S is mapped probabilistically to another state. Therefore, C is stochastic. <p> When using elitist selection the best individual is not only maintained but also used to generate new individuals. This algorithm has another transition matrix and therefore different search dynamics, which may be better in some cases and worse in other cases. Theorem 4 indicates that the schema theorem <ref> [1] </ref> cannot imply convergence to the global optimum. 5 Discussion of results with respect to the schema theorem A schema S describes a specific type of subsets of the feasible region IB l of problem (1) which is again assumed to have only one global optimal point b fl 2 IB <p> The utility of schema S restricted to multiset X is defined as the average objective function value over all elements contained in S " X: u (S; X) := jS " Xj b2S"X The schema theorem states that <ref> [1, p. 102-103] </ref> E [ jS " X t+1 j ] jS " X t j u (S; X t ) almost surely, where (X t ) is the sequence of populations generated by the CGA and c (:) and m (:) are bounds for the probability that an element of <p> Static optimization, however, was not the original purpose in the design of the CGA <ref> [1] </ref>. In fact, the interest was concentrated on a strategy which performs an optimal allocation of trials so as to minimize expected losses in an uncertain environment, possibly with time varying rewards | a problem which is certainly not equivalent to a static optimization problem. The schema theorem [1] does not <p> the CGA <ref> [1] </ref>. In fact, the interest was concentrated on a strategy which performs an optimal allocation of trials so as to minimize expected losses in an uncertain environment, possibly with time varying rewards | a problem which is certainly not equivalent to a static optimization problem. The schema theorem [1] does not imply that the CGA will converge to the global optimum in static optimization problems. Moreover, due to the irreducibility of the CGA it is clear that the CGA will not converge at all.
Reference: [2] <author> A.E. Eiben, E.H.L. Aarts, and K.M. Van Hee, </author> <title> "Global convergence of genetic algorithms: A markov chain analysis", in Parallel Problem Solving from Nature, </title> <editor> H.-P. Schwefel and R. Manner (Eds.), </editor> <publisher> Berlin and Heidelberg: Springer, </publisher> <year> 1991, </year> <pages> pp. 4-12. </pages>
Reference-contexts: A probabilistic version of this definition is used in this paper. Markov chains offer an appropriate model to analyze GAs and they have been used in <ref> [2] </ref> and [3] to prove probabilistic convergence of the best solution within a population to the global optimum under elitist selection (the best individual survives with probability one).
Reference: [3] <editor> D.B. Fogel, </editor> <booktitle> Evolving Artificial Intelligence, PhD dissert., </booktitle> <address> San Diego: </address> <institution> University of California, </institution> <year> 1992. </year> <month> 10 </month>
Reference-contexts: A probabilistic version of this definition is used in this paper. Markov chains offer an appropriate model to analyze GAs and they have been used in [2] and <ref> [3] </ref> to prove probabilistic convergence of the best solution within a population to the global optimum under elitist selection (the best individual survives with probability one).
Reference: [4] <author> D.E. Goldberg, </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning, </title> <publisher> Reading/Mass.: Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Although many crossover operators have been proposed a description can be omitted because the choice of a specific crossover operator does not effect the subsequent analysis. This algorithm and its potential implementation is described in <ref> [4, pp. 59-70] </ref> in more detail. 3 Finite Markov Chains A finite Markov chain describes a probabilistic trajectory over a finite state space S of car-dinality j S j = n, where the states may be numbered from 1 to n.
Reference: [5] <author> E. Seneta, </author> <title> Non-negative Matrices and Markov Chains, </title> <booktitle> 2nd edition, </booktitle> <address> New York: </address> <publisher> Springer, </publisher> <year> 1981. </year>
Reference-contexts: Therefore, a homogeneous finite Markov chain is completely determined by the pair (p 0 ; P). Since the limit behavior of the Markov chain depends on the structure of the transition matrix the following classification is useful <ref> [5] </ref>: Definition 1 A square matrix A : nfin is said to be (a) nonnegative (A 0), if a ij 0 for all i; j 2 f1; :::; ng, (b) positive (A &gt; 0), if a ij &gt; 0 for all i; j 2 f1; :::; ng.
Reference: [6] <author> M. Iosifescu, </author> <title> Finite Markov Processes and Their Applications, </title> <address> Chichester: </address> <publisher> Wiley, </publisher> <year> 1980. </year>
Reference: [7] <author> T.E. Davis and J.C. Principe, </author> <title> "A simulated annealing like convergence theory for the simple genetic algorithm", </title> <booktitle> in Proceedings of the fourth Conference on Genetic Algorithms, </booktitle> <editor> R.K. Belew and L.B. Booker (Eds.), </editor> <address> San Mateo: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1991, </year> <pages> pp. 174-181. </pages>
Reference-contexts: It follows by Lemma 1 that P = C M S is positive. Since every positive matrix is primitive the proof is completed. 2 This result has an alternative representation, also reported in <ref> [7, pp. 177-178] </ref>, albeit derived within a different Markov chain model: 4 Corollary 1 The CGA with parameter ranges as in Theorem 3 is an ergodic Markov chain, i.e., there exists an unique limit distribution for the states of the chain with nonzero probability to be in any state at any
Reference: [8] <author> W. Feller, </author> <title> An Introduction to Probability Theory and Its Applications Vol. 1, 3rd (revised) edition, </title> <publisher> Singapore: Wiley, </publisher> <year> 1970. </year>
Reference-contexts: The reason is quite clear: For a CGA there is a minimal probability bounded from zero to lose the global optimum solution at each generation. It follows from the Borel-Cantelli Lemma (see e.g. <ref> [8, p. 201] </ref>) that this event will occur with probability one. On the other hand, there is a minimal probability to find again a global solution if it was lost, so that this event will also occur with probability one.
Reference: [9] <author> K.A. De Jong, </author> <title> "Are genetic algorithms function optimizers ?", in [13], </title> <journal> pp. </journal> <pages> 3-13. </pages>
Reference-contexts: In other words, the original CGA cannot be regarded as an optimization algorithm for static optimization problems (see also <ref> [9] </ref>) because it is provable that it will not converge to any subset of the set of states containing at least one global solution, even in infinite time. Static optimization, however, was not the original purpose in the design of the CGA [1].
Reference: [10] <author> T.E. Davis, </author> <title> Toward an extrapolation of the simulated annealing convergence theory onto the simple genetic algorithm, </title> <type> PhD dissert., </type> <institution> Gainesville: University of Florida, </institution> <year> 1991. </year>
Reference-contexts: Another possible route to globally optimal convergence might be the introduction of time varying mutation and selection probabilities, so that the corresponding Markov process becomes inhomogeneous. It has been shown in <ref> [10] </ref> that the introduction of time varying mutation probabilities alone does not help, which confirms the insight that the selection operator is the key problem of the CGA.
Reference: [11] <author> T. </author> <title> Back, "The interaction of mutation rate, selection, and self-adaptation within a genetic algorithm", </title> <booktitle> in [13], </booktitle> <pages> pp. 85-94. </pages>
Reference-contexts: A more practical question regards the time complexity of the algorithm to achieve the globally optimal solution. The first steps in this direction have been made in <ref> [11] </ref> and [12] both using simplified but globally optimal convergent GAs. Acknowledgment The author would like to thank David B. Fogel and the anonymous referees for helpful comments on the paper.
Reference: [12] <author> H. Muhlenbein, </author> <title> "How genetic algorithms really work I: Mutation and hillclimbing", </title> <booktitle> in [13], </booktitle> <pages> pp. 15-25. </pages>
Reference-contexts: A more practical question regards the time complexity of the algorithm to achieve the globally optimal solution. The first steps in this direction have been made in [11] and <ref> [12] </ref> both using simplified but globally optimal convergent GAs. Acknowledgment The author would like to thank David B. Fogel and the anonymous referees for helpful comments on the paper.
Reference: [13] <editor> R. Manner and B. Manderick (Eds.), </editor> <title> Parallel Problem Solving from Nature, 2, </title> <publisher> Amster-dam: North Holland, </publisher> <year> 1992. </year> <month> 11 </month>
References-found: 13

