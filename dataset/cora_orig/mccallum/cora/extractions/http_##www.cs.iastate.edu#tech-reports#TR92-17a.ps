URL: http://www.cs.iastate.edu/tech-reports/TR92-17a.ps
Refering-URL: http://www.cs.iastate.edu/tech-reports/catalog.html
Root-URL: 
Title: Preferred Embodiment of a Hardware-Assisted Garbage-Collection System  
Author: TR -a Kelvin D. Nilsen and William J. Schmidt 
Address: 226 Atanasoff Ames, IA 50011  
Affiliation: Iowa State University of Science and Technology Department of Computer Science  
Date: Nov. 18, 1992  
Abstract-found: 0
Intro-found: 1
Reference: 1. <author> H. G. Baker Jr., </author> <title> ``List Processing in Real Time on a Serial Computer'', </title> <journal> Comm. ACM 21, </journal> <month> 4 (Apr. </month> <year> 1978), </year> <pages> 280-293. </pages>
Reference-contexts: data in this subregion. -; str uct controlblock - / / data region control block WPTR srptr ; // points to controlled region UWORD size; // how many total words in controlled block? str uct controlblock *next; // all control blocks are linked through this field str uct sr subregions <ref> [1] </ref>; // this array is e xpanded according to size. -; // Given that a data region occupies a total of numWords words, // how many subregion control blocks are involved? // the answer depends on: // 1. how much of the data area contains data (subtract 1 for header) //
Reference: 2. <author> D. Ungar, </author> <title> Generation Scavenging: A Non-disruptive High Performance Storage Reclamation Algo rithm, </title> <journal> SIGPLAN Notices 19, </journal> <month> 5 (May </month> <year> 1984), </year> <pages> 157-167. </pages>
Reference: 3. <author> T. W. Christopher, </author> <title> ``Reference Count Garbage Collection'', </title> <journal> SoftwarePractice & Experience 14(1984), </journal> <pages> 503-507. </pages>
Reference: 4. <author> K. Nilsen, </author> <title> ``Garbage Collection of Strings and Linked Data Structures in Real Time'', </title> <journal> Software Practice & Experience 18, </journal> <month> 7 (July </month> <year> 1988), </year> <pages> 613-640. </pages>
Reference-contexts: In detailed performance analysis of these systems, the overhead of synchronizing on writes ranges from 3 - 24% of total execution time in one study [5], and synchronizing on reads was found to more than double execution time in a different study <ref> [4] </ref>. Note that in most programs, fetches are much more frequent than stores. Unfortunately, none of the incremental garbage collection systems that require synchronization only on store operations is able to guarantee tight worst-case bounds on the times required to allocate new objects.
Reference: 5. <author> C. Chambers, </author> <title> Cost of Garbage Collection in the SELF System, </title> <booktitle> 1991 Workshop on Garbage Collec tion in Object-Oriented Systems of OOPSLA, </booktitle> <address> Phoenix, AZ, </address> <month> Oct </month> <year> 1991. </year>
Reference-contexts: In detailed performance analysis of these systems, the overhead of synchronizing on writes ranges from 3 - 24% of total execution time in one study <ref> [5] </ref>, and synchronizing on reads was found to more than double execution time in a different study [4]. Note that in most programs, fetches are much more frequent than stores.
Reference: 6. <author> S. L. Engelstad and J. E. Vandendorpe, </author> <title> Automatic Storage Management for Systems with Real-Time Constraints, </title> <booktitle> Oral presentation at 1991 Workshop on Garbage Collection in Object-Oriented Systems of OOPSLA, </booktitle> <address> Phoenix, AZ, </address> <month> Oct </month> <year> 1991. </year>
Reference-contexts: In existing systems, these delays are imposed during reading and writing of heap-allocated memory, and during allocation of new objects. Using stock hardware, the tightest bound currently available on the time applications must occasionally wait for garbage collection during access to previously allocated objects is 500 msec <ref> [6] </ref> for applications that are somewhat restricted in their use of dynamic memory. More general garbage collection systems promise looser bounds, ranging from several to several hundred milliseconds [7, 8]. These delays are too large to be tolerated by many real-time applications.
Reference: 7. <author> R. Johnson, </author> <title> Reducing the Latency of a Real-Time Garbage Collector, </title> <journal> ACM Letters on Pro g. Lang. and Systems, </journal> <note> accepted. </note>
Reference-contexts: More general garbage collection systems promise looser bounds, ranging from several to several hundred milliseconds <ref> [7, 8] </ref>. These delays are too large to be tolerated by many real-time applications. Furthermore, available garbage collection systems offer no guarantees of minimum time separation between consecutive events that require abnormal delays in program execution.
Reference: 8. <author> J. R. Ellis, K. Li and A. W. Appel, </author> <title> ``Real-time Concurrent Collection on Stock Multiprocessors'', </title> <booktitle> ACM SIGPLAN Notices Conference on Programming Language Design and Implementation, </booktitle> <address> J une 1988. </address>
Reference-contexts: More general garbage collection systems promise looser bounds, ranging from several to several hundred milliseconds <ref> [7, 8] </ref>. These delays are too large to be tolerated by many real-time applications. Furthermore, available garbage collection systems offer no guarantees of minimum time separation between consecutive events that require abnormal delays in program execution. <p> exact multiple of the // subregion size, round the size u p. // 3. add 1 because of ProbeOffset alignments // #define NumSubRegions (nw) (((((nw) - 1) + SubRegionSize - 1) / SubRegionSize) + 1) int ProbeOffset = 16; // byte offset at which subregions are aligned. static int nxtprobes <ref> [8] </ref> = - // ProbeOffset is changed for each pass of the garbage collector. 3, 5, 6, 7, 2, 0, 1, 4, #define nextProbe (oldprobe) (nxtprobes [oldprobe / BytesPerWord] * BytesPerWord) The final phase of garbage collection is to postprocess control blocks, carving each of the controlled regions into smaller regions
Reference: 9. <author> H. Boehm and M. Weiser, </author> <title> Garbage Collection in an Uncooperative Environment, </title> <journal> Software Practice & Experience 18, </journal> <month> 9 (Sep </month> <year> 1988), </year> <pages> 807-820. </pages> <month> -38 </month>
Reference-contexts: DRAFT COPY: Last revised 10/24/92. -1 using. Memory also becomes unavailable in non-compactifying garbage collection schemes through frag-mentation. Experience shows that for many common workloads and virtual memory configurations, conservative non-compactifying garbage collectors perform very well <ref> [9, 10] </ref>. However, our goal is to provide reliable garbage collection to real-time programs running in real memory.
Reference: 10. <author> H. Boehm, A. J. Demers and S. Shenker, </author> <title> ``Mostly Parallel Garbage Collection'', </title> <booktitle> ACM SIGPLAN Notices Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: DRAFT COPY: Last revised 10/24/92. -1 using. Memory also becomes unavailable in non-compactifying garbage collection schemes through frag-mentation. Experience shows that for many common workloads and virtual memory configurations, conservative non-compactifying garbage collectors perform very well <ref> [9, 10] </ref>. However, our goal is to provide reliable garbage collection to real-time programs running in real memory.
Reference: 11. <author> K. Nilsen and W. J. Schmidt, </author> <title> Hardware-Assisted General-Purpose Garbage Collection for Hard Real-Time Systems, </title> <institution> Iowa State Univ. </institution> <type> Tech. Rep. </type> <pages> 92-15, </pages> <year> 1992. </year>
Reference-contexts: To achieve high performance, garbage-collected memory cells can be cached, offering high-bandwidth access to the contents of garbage-collected memory. A thorough description of the garbage collection algorithm and its analysis is provided in reference <ref> [11] </ref>. Simulations of C++ programs retargeted to this garbage-collection architecture reveal that hardware-assisted real-time garbage collection provides throughput competitive with traditional C++ implementation techniques 2 . <p> On certain architectures, such as the SPARC, an optimizing compiler might transform this code into the following: 3 Though we make a variety of assumptions in order to simplify the hardware and its description, slight changes in the system design would obviate most of these assumptions, as discussed in references <ref> [11, 13] </ref>. -3 diff = b - a; /* diff overwr ites the register that used to hold b. b is now dead. */ for (aptr = a; aptr &lt; a + 100000; a++) sum += *aptr + aptr [diff]; This optimization is incompatible with our requirements for garbage collection because,
Reference: 12. <author> W. J. Schmidt and K. Nilsen, </author> <title> Empirical Performance of a Hardware-Assisted Real-Time Garbage Collector, </title> <note> In preparation. </note>
Reference-contexts: The garbage-collected C++ dialect garbage collects all objects, including heap-allocated function activation frames. Detailed performance results are described in reference <ref> [12] </ref>. -2 Application processes run on the CPU and garbage-collection tasks run within the garbage-collected memory module. Throughout this paper, application tasks are collectively referred to as the mutator, since, insofar as garbage collection is concerned, their only role is to modify (or mutate) the contents of heap-allocated memory. 3.
Reference: 13. <author> K. Nilsen and W. J. Schmidt, </author> <title> Cost-Effective Object-Space Management for Hardware-Assisted Real-Time Garbage Collection, </title> <journal> ACM Letters on Pro g. Lang. and Systems, </journal> <note> submitted. </note>
Reference-contexts: On certain architectures, such as the SPARC, an optimizing compiler might transform this code into the following: 3 Though we make a variety of assumptions in order to simplify the hardware and its description, slight changes in the system design would obviate most of these assumptions, as discussed in references <ref> [11, 13] </ref>. -3 diff = b - a; /* diff overwr ites the register that used to hold b. b is now dead. */ for (aptr = a; aptr &lt; a + 100000; a++) sum += *aptr + aptr [diff]; This optimization is incompatible with our requirements for garbage collection because, <p> A FindHeader request looks up the -15 location of the header (the first word) of the object containing a particular memory location. A Reset request causes the OSM to initialize its data base to its empty state. The internal organization of the OSM is described in <ref> [13] </ref>.
Reference: 14. <author> H. Boehm, </author> <title> Simple GC-Safe Compilation, </title> <booktitle> 1991 Workshop on Garbage Collection in Object Oriented Systems of OOPSLA, </booktitle> <address> Phoenix, AZ, </address> <month> Oct </month> <year> 1991. </year>
Reference-contexts: Memory words are big-endian. Insofar as the garbage collector is concerned, all pointers referring to a particular object directly address a memory location contained within the referenced object. However, pointers need not address the first word in the referenced object. Further, we require GC-Safe compilation, as described by Boehm <ref> [14] </ref>. The following example of an unsafe program transformation is taken from Boehm's paper.
Reference: 15. <author> A. W. Appel, </author> <title> Allocation Without Locking, </title> <journal> SoftwarePractice & Experience 19, </journal> <month> 7 ( July </month> <year> 1989), </year> <pages> 703-705. </pages>
Reference-contexts: This code only presents problems if multiple tasks share access to the garbage collected heap. In that case, this sort of code must be prohibited, or special techniques for interpreting intermediate results of addressing arithmetic must be provided <ref> [15] </ref>. We also make t he following assumptions about configuration of the data cache 4 Cache-coherency must be maintained between the CPU's cache and the contents of garbage-collected memory. Any of the following alternative techniques is acceptable: 1.
Reference: 16. <author> Motorola, MC88200: </author> <title> Cache/Memory Management Unit User's Manual, </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Engle wood Cliffs, NJ, </address> <note> second edition, </note> <year> 1990. </year>
Reference-contexts: Under software control, the CPU may invalidate particular cache lines and groups of cache lines as specified by address ranges. The CPU uses write-through caching (stores update both the cache and the memory subsystem). These capabilities are available in current cache controllers such as the Motorola 88200 <ref> [16] </ref>. Experimental studies conducted to date suggest that the highest storage throughput is provided by option 2, but that option 1 provides the best combination of high storage throughput and low worst-case alloca tion latency. In t erms of implementation complexity, option 2 is much less expensive than option 1.
Reference: 17. <author> K. Nilsen, </author> <title> Memory Cycle Accountings for Hardware-Assisted Real-Time Garbage Collection, </title> <institution> Iowa State Univ. </institution> <type> Tech. Rep. 91-21, </type> <institution> Iowa State Univ., </institution> <note> 1 991. -39 </note>
Reference-contexts: To minimize the complexity of interrupting the arbiter, sev eral of the routines performed by the arbiter contain rollback points to which internal control backtracks whenever that routine is interrupted. Use of rollback points is described in greater detail in reference <ref> [17] </ref>. The principal motivation for using rollback points is that the interrupting operation may result in changes to the system state.
References-found: 17

