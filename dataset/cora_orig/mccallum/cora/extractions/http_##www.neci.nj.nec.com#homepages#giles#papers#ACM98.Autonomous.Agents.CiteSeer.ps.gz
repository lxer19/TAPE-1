URL: http://www.neci.nj.nec.com/homepages/giles/papers/ACM98.Autonomous.Agents.CiteSeer.ps.gz
Refering-URL: http://www.neci.nj.nec.com/homepages/giles/papers/
Root-URL: 
Email: fkurt,lawrence,gilesg@research.nj.nec.com  
Phone: 1  
Title: CiteSeer: An Autonomous Web Agent for Automatic Retrieval and Identification of Interesting Publications  
Author: Kurt D. Bollacker ; Steve Lawrence and C. Lee Giles ; 
Address: Austin, TX 78712 Princeton, NJ 08540 College Park, MD 20742  
Affiliation: University of Texas at Austin 2 NEC Research Institute 3 UMIACS, University of Maryland  
Abstract: Published research papers available on the World Wide Web (WWW or Web) are often poorly organized, often exist in non-text form (e.g. Postscript) documents, and increase in quantity daily. Significant amounts of time and effort are commonly needed to find interesting and relevant publications on the Web. We have developed a Web based information agent that assists the user in the process of performing a scientific literature search. Given a set of keywords, the agent uses Web search engines and heuristics to locate and download papers. The papers are parsed in order to extract information features such as the abstract and individually identified citations which are placed into an SQL database. The agent's Web interface can be used to find relevant papers in the database using keyword searches, or by navigating the links between papers formed by the citations. Links to both citing and cited publications can be followed. In addition to simple browsing and keyword searches, the agent can find papers which are similar to a given paper using word information and by analyzing common citations made by the papers. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Institute for Scientific Information, </institution> <year> 1997. </year>
Reference-contexts: There are a few existing commercial citation indexed databases, such as those provided by the Institute for Scientific Information (ISI) <ref> [1] </ref>. ISI produces several citation indices including the Science Citation Index R fl, which is a multidisciplinary citation index for scientific periodicals. Another commercial database which provides citation indexing is the legal database offered by the West Group [2], which indexes case law, as opposed to scientific research publications. <p> Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone. Classification and Regression Trees. Wadsworth, Pacific Grove, California, 1984. 6. L. Breiman, J. Friedman, R. Olshen and C. Stone, Classification and Regression Trees, Wadsworth and Brooks, 1984. <ref> [1] </ref> L. Breiman et al. Classification and Regression Trees. Wadsworth, 1984. As suggested by the example citations above, the problem is not completely trivial, and so we have implemented an identical citation grouping (ICG) method.
Reference: [2] <author> Keycite, </author> <year> 1997. </year>
Reference-contexts: ISI produces several citation indices including the Science Citation Index R fl, which is a multidisciplinary citation index for scientific periodicals. Another commercial database which provides citation indexing is the legal database offered by the West Group <ref> [2] </ref>, which indexes case law, as opposed to scientific research publications. CiteSeer-created indices are a departure from commercial indices of scientific literature due to their automatic creation and autonomous extraction of citations, and the ability for users to create by users in real time.
Reference: [3] <author> BALABANOVIC, M. </author> <title> An adaptive Web page recommendation service. </title> <booktitle> In Proceedings of the First International Conference on Autonomous Agents (February 1997). </booktitle>
Reference-contexts: Several Web based assistant agents have been constructed to help the user find interesting and relevant World Wide Web pages more quickly and easily. Some of these, such as <ref> [10, 3, 9, 11] </ref> (and [5] contains an overview of several agents) learn from user feedback in an environment of word vector features to find more relevant Web pages. Interesting changes to known relevant Web pages are learned by the Do-I-Care agent [17]. <p> However, CiteSeer also has a mechanism for the automatic retrieval of related documents based on distance measures of semantic features extracted from those documents. 4 4.2.1 Comparison with Previous Research Previous Web assistant agents (e.g. <ref> [10, 3, 17] </ref>) have used word frequency information to automatically measure how related two documents are. While this has been useful in some domains, uncommon words may be shared by documents simply by coincidence, thereby giving false evidence that the documents are related.
Reference: [4] <author> CAMERON, R. D. </author> <title> A universal citation database as a catalyst for reform in scholarly communication. </title> <booktitle> First Monday (Febru-ary 1997). </booktitle>
Reference-contexts: All previous commercial indices are large, accumulative databases while CiteSeer is an up to date snapshot of relevant literature on the web. 2.4 A Universal Citation Database Cameron has proposed a universal, [Internet-based,] bibliographic and citation database linking every scholarly work ever written <ref> [4] </ref>. He describes a system in which all of the worlds published research would be available to and searchable by any scholar with Internet access. Such a database would be highly comprehensive and up-to-date, making it a powerful tool for academic literature research.
Reference: [5] <author> EDWARDS, P., GREEN, C. L., LOCKIER, P. C., AND LUKINS, T. </author> <title> Exploiting learning technologies for World Wide Web agents. </title> <booktitle> In IEEE Colloquium on Intelligent World Wide Web Agents,Digest No: </booktitle> <month> 97/118 (March </month> <year> 1997). </year>
Reference-contexts: Several Web based assistant agents have been constructed to help the user find interesting and relevant World Wide Web pages more quickly and easily. Some of these, such as [10, 3, 9, 11] (and <ref> [5] </ref> contains an overview of several agents) learn from user feedback in an environment of word vector features to find more relevant Web pages. Interesting changes to known relevant Web pages are learned by the Do-I-Care agent [17].
Reference: [6] <author> GARFIELD, E. </author> <title> The concept of citation indexing: A unique and innovative tool for navigating the research literature. </title> <note> Current Contents January 3 (1994). </note>
Reference-contexts: A citation index contains the references that an article cites, linking the articles with the cited works. Citations are a semantic feature of a research publication which can be used to determine its relationships to other publications. Citation indices were originally designed mainly for information retrieval <ref> [6] </ref>. Papers can be located independent of language, and words in the title, keywords or document. A citation index allows navigation backward in time (the list of cited articles) and forward in time (which subsequent articles cite the current article?) making it a powerful tool for literature search. <p> Each citation is parsed using heuristics to extract the following fields: title, author, year of publication, page numbers, and citation tag. The citation tag is the information in the citation that is used to cite that citation in the body of the document (e.g. <ref> [6] </ref>, [Giles97], Marr 1982). Word frequency of each citation is also recorded, with stop word removal and stemming applied the same as in the document word frequency extraction. Additionally, we use the citation tags to find the locations in the document body text where the citations are actually made.
Reference: [7] <author> LEVENSHTEIN, V. I. </author> <title> Binary codes capable of correcting spurious insertions and deletions of ones (original in Russian). </title> <note> Russian Problemy Peredachi Informatsii 1 (January 1965), 1225. </note>
Reference-contexts: Presently, we are aware of three commonly used types of models. One is the string distance or edit distance measure which considers distance as the amount of difference between strings of symbols. For example, the Levenshtein distance <ref> [7] </ref> is a well known early edit distance where the difference between two text strings is simply the number of insertions, deletions, or substitutions of letters to transform one string into another. <p> For example, the following citations, extracted from neural network publications, are all to the same article: <ref> [7] </ref> L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone. Classification and Regression Trees. Wadsworth, Pacific Grove, California, 1984. 6. L. Breiman, J. Friedman, R. Olshen and C. Stone, Classification and Regression Trees, Wadsworth and Brooks, 1984. [1] L. Breiman et al. Classification and Regression Trees. Wadsworth, 1984.
Reference: [8] <author> LOKE, S. W., DAVISON, A., AND STERLING, L. CIFI: </author> <title> An intelligent agent for citation finding on the World-Wide Web. </title> <type> Technical Report 96/4 Dept. </type> <institution> of Computer Science, University of Melbourne, </institution> <year> 1996. </year> <month> 7 </month>
Reference-contexts: Interesting changes to known relevant Web pages are learned by the Do-I-Care agent [17]. This system also allows the agent to learn from the feedback of another user. Although it does no learning, the heuristic Web agent CiFi <ref> [8] </ref> tries to find citations of a specified paper on the World Wide Web. CiteSeer differs from most previous Web agents in that it actually creates a customized view of a part of the Web.
Reference: [9] <author> MENCZER, F. ARACHNID: </author> <title> Adaptive retrieval agents choosing heuristic neighborhoods for information discovery. </title> <booktitle> In Machine Learning: Proceedings of the fourteenth International Conference (July 1997), </booktitle> <pages> pp. 227235. </pages>
Reference-contexts: Several Web based assistant agents have been constructed to help the user find interesting and relevant World Wide Web pages more quickly and easily. Some of these, such as <ref> [10, 3, 9, 11] </ref> (and [5] contains an overview of several agents) learn from user feedback in an environment of word vector features to find more relevant Web pages. Interesting changes to known relevant Web pages are learned by the Do-I-Care agent [17].
Reference: [10] <author> MOUKAS, A. Amalthaea: </author> <title> Information discovery and filtering using a multiagent evolving ecosystem. </title> <booktitle> In Proceedings of the Conference on Practical Applications of Agents and Mul-tiagent Technology (April 1996). </booktitle>
Reference-contexts: Several Web based assistant agents have been constructed to help the user find interesting and relevant World Wide Web pages more quickly and easily. Some of these, such as <ref> [10, 3, 9, 11] </ref> (and [5] contains an overview of several agents) learn from user feedback in an environment of word vector features to find more relevant Web pages. Interesting changes to known relevant Web pages are learned by the Do-I-Care agent [17]. <p> However, CiteSeer also has a mechanism for the automatic retrieval of related documents based on distance measures of semantic features extracted from those documents. 4 4.2.1 Comparison with Previous Research Previous Web assistant agents (e.g. <ref> [10, 3, 17] </ref>) have used word frequency information to automatically measure how related two documents are. While this has been useful in some domains, uncommon words may be shared by documents simply by coincidence, thereby giving false evidence that the documents are related.
Reference: [11] <author> PAZZANI, M., MURAMATSU, J., AND BILLSUS, D. Syskill & Webert: </author> <title> Identifying interesting Web sites. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI96) (1996). </booktitle>
Reference-contexts: Several Web based assistant agents have been constructed to help the user find interesting and relevant World Wide Web pages more quickly and easily. Some of these, such as <ref> [10, 3, 9, 11] </ref> (and [5] contains an overview of several agents) learn from user feedback in an environment of word vector features to find more relevant Web pages. Interesting changes to known relevant Web pages are learned by the Do-I-Care agent [17].
Reference: [12] <author> PORTER, M. F. </author> <title> an algorithm for suffix stripping. </title> <booktitle> Program 14 (3 1980), </booktitle> <pages> 130137. </pages>
Reference-contexts: In some systems, very common words, sometimes called stop words, such as the, a, etc. are ignored for computational efficiency. Also, sometimes only the stems of words are considered instead of complete words. An often used stemming heuristic introduced by Porter <ref> [12] </ref> tries to return the same stem from several forms of the same word. (e.g. walking, walk, walked all become simply walk.) In a document d, the frequency of each word stem s is f ds , the number of documents having stem s is n s , and the highest
Reference: [13] <author> SALTON, G. </author> <title> Automatic indexing using bibliographic citations. </title> <journal> Journal of Documentation 27 (1971), </journal> <volume> 98110. </volume>
Reference-contexts: A third type of semantic distance measure is one in which knowledge about document components or structure is used. In the case of research publications for example, citations of papers by other papers has been used to create citation indices which can be used to gauge document relatedness <ref> [13] </ref>.
Reference: [14] <author> SALTON, G., AND BUCKLEY, C. </author> <title> Term weighting approaches in automatic text retrieval. </title> <type> Tech Report 87-881 Dept. </type> <institution> of Computer Science, Cornell University, </institution> <year> 1997. </year>
Reference-contexts: In one such TFIDF scheme <ref> [14] </ref> a word weight w ds is calculated as: w ds = f ds )(log n s ) j2d ((0:5 + 0:5 f d max N D ) 2 ) where N D is the total number of documents. <p> We truncate to the top 20 components for each document for computational reasons, but there is evidence that this truncation should not have a large affect on the distance measures <ref> [14] </ref>. A string edit distance measure can also be used to determine document similarity. Currently, CiteSeer uses the LikeIt string distance [19] to measure the edit distance between the headers of documents in a database. <p> CiteSeer uses common citations to make an estimate of which documents in the downloaded database of research papers are the most closely related to a document picked by the user. This measure, Common Citation fi Inverse Document Frequency (CCIDF) is analogous to word oriented TFIDF <ref> [14] </ref> word weights. The algorithm to calculate the CCIDF relatedness of all documents in the database to a document of interest A and choose the best M documents is as follows: 1.
Reference: [15] <author> SALTON, G., AND YANG, C. </author> <title> On the specification of term values in automatic indexing. </title> <note> Journal of Documentation 29 (April 1973), 351372. </note>
Reference-contexts: One commonly used form of this measure, based on word frequencies, is known as term frequency fi inverse document frequency (TFIDF) <ref> [15] </ref>. Consider a dictionary of all of the words (terms) in a corpus of documents. In some systems, very common words, sometimes called stop words, such as the, a, etc. are ignored for computational efficiency. Also, sometimes only the stems of words are considered instead of complete words. <p> One very common semantic feature used to gauge document topic similarity is that of word vectors. We have implemented a TFIDF <ref> [15] </ref> scheme to measure a value of each word stem in each document where a vector of all of the word stem values represent a document.
Reference: [16] <author> SPERTUS, E. ParaSite: </author> <title> Mining structural information on the Web. </title> <booktitle> In Proceeding of The Sixth International World Wide Web Conference (April 1997). </booktitle>
Reference-contexts: In the case of research publications for example, citations of papers by other papers has been used to create citation indices which can be used to gauge document relatedness [13]. Another example is the ParaSite system <ref> [16] </ref>, in which the nearness of links to referenced Web pages in the HTML structure of a referencing Web page are used as an indicator of relatedness of the referenced pages. 2.3 Citation Indexing References contained in scientific articles are used to give credit to previous work in the literature and
Reference: [17] <author> STARR, B., ACKERMAN, M. S., AND PAZZANI, M. Do-I-Care: </author> <title> Tell me what's changed on the Web. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on Machine Learning in Information Access Technical Papers (March 1996). </booktitle>
Reference-contexts: Some of these, such as [10, 3, 9, 11] (and [5] contains an overview of several agents) learn from user feedback in an environment of word vector features to find more relevant Web pages. Interesting changes to known relevant Web pages are learned by the Do-I-Care agent <ref> [17] </ref>. This system also allows the agent to learn from the feedback of another user. Although it does no learning, the heuristic Web agent CiFi [8] tries to find citations of a specified paper on the World Wide Web. <p> However, CiteSeer also has a mechanism for the automatic retrieval of related documents based on distance measures of semantic features extracted from those documents. 4 4.2.1 Comparison with Previous Research Previous Web assistant agents (e.g. <ref> [10, 3, 17] </ref>) have used word frequency information to automatically measure how related two documents are. While this has been useful in some domains, uncommon words may be shared by documents simply by coincidence, thereby giving false evidence that the documents are related.
Reference: [18] <author> YIANILOS, P. </author> <title> The LikeIt intelligent string comparison facility. </title> <type> NEC Institute Tech Report 97-093, </type> <year> 1997. </year>
Reference-contexts: For example, the Levenshtein distance [7] is a well known early edit distance where the difference between two text strings is simply the number of insertions, deletions, or substitutions of letters to transform one string into another. A more recent and sophisticated example is LikeIt <ref> [18, 19] </ref> where a string distance is based on an algorithm that tries to build an optimal weighted matching of the letters and multigraphs (groups of letters).
Reference: [19] <author> YIANILOS, P. N. </author> <title> Data structures and algorithms for nearest neighbor search in general ametric spaces. </title> <booktitle> In Proceedings of the 4th ACM-SIAM Symposium on Discrete Algorithms (1993), </booktitle> <pages> pp. 311321. </pages>
Reference-contexts: For example, the Levenshtein distance [7] is a well known early edit distance where the difference between two text strings is simply the number of insertions, deletions, or substitutions of letters to transform one string into another. A more recent and sophisticated example is LikeIt <ref> [18, 19] </ref> where a string distance is based on an algorithm that tries to build an optimal weighted matching of the letters and multigraphs (groups of letters). <p> A string edit distance measure can also be used to determine document similarity. Currently, CiteSeer uses the LikeIt string distance <ref> [19] </ref> to measure the edit distance between the headers of documents in a database. LikeIt tries to match substrings in a larger string, and common authors, institutions, or words in the title will tend to reduce the LikeIt distance between headers.
References-found: 19

