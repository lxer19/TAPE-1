URL: http://www.cs.dartmouth.edu/~brd/f/s/ijrr-new.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/~brd/www/
Root-URL: http://www.cs.dartmouth.edu
Title: Information Invariants for Distributed Manipulation 1  
Author: Bruce Randall Donald, James Jennings and Daniela Rus 
Note: The author's current address is  The author's current address is  
Address: Ithaca, New York U.S.A  New Orleans, Louisiana, USA.  Hanover, New Hampshire, USA.  
Affiliation: Robotics Vision Laboratory Computer Science Department Cornell University  Department of Computer Science, Tulane University,  Department of Computer Science, Dartmouth College,  
Abstract: In [Don4], we described a manipulation task for cooperating mobile robots that can push large, heavy objects. There, we asked whether explicit local and global communication between the agents can be removed from a family of pushing protocols. In this paper, we answer in the affirmative. We do so by using the general methods of [Don4] analyzing information invariants. 1 This paper describes research done in the Robotics and Vision Laboratory at Cornell University. 
Abstract-found: 1
Intro-found: 1
Reference: [BK] <author> Blum, M. and Kozen, D. </author> <title> On the power of the compass (or, why mazes are easier to search than graphs), </title> <booktitle> Proc. 19 th Symp. Found. Computer Science, </booktitle> <address> Ann Arbor, MI, </address> <pages> pp. </pages> <month> 132-42 </month> <year> (1978). </year>
Reference-contexts: We also observe that rigorous examples of information invariants can be found in the theoretical literature from as far back as 1978 (see, for example, <ref> [BK, Koz] </ref>). We note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, [Reif, HSS, Nat, CR]; see, eg, [Erd1, Don2, Can, Bri] for upper bounds).
Reference: [Bri] <author> Briggs, Amy. </author> <title> An Efficient Algorithm for One-Step Compliant Motion Planning with Uncertainty, </title> <journal> Algorithmica, </journal> <volume> 8, (2), </volume> <year> 1992. </year> <pages> pp. 195-208. </pages>
Reference-contexts: We note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, [Reif, HSS, Nat, CR]; see, eg, <ref> [Erd1, Don2, Can, Bri] </ref> for upper bounds). Rosenschein has developed a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates.
Reference: [Can] <institution> John Canny On computability of fine motion plans, IEEE ICRA, </institution> <address> Scottsdale, AZ, </address> <year> (1989) </year>
Reference-contexts: We note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, [Reif, HSS, Nat, CR]; see, eg, <ref> [Erd1, Don2, Can, Bri] </ref> for upper bounds). Rosenschein has developed a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates.
Reference: [CR] <author> Canny, J., and J. Reif, </author> <title> "New Lower Bound Techniques for Robot Motion Planning Problems", </title> <booktitle> FOCS (1987). </booktitle>
Reference-contexts: We also observe that rigorous examples of information invariants can be found in the theoretical literature from as far back as 1978 (see, for example, [BK, Koz]). We note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, <ref> [Reif, HSS, Nat, CR] </ref>; see, eg, [Erd1, Don2, Can, Bri] for upper bounds). Rosenschein has developed a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates.
Reference: [Don] <author> Donald, B. R. </author> <title> Information Invariants in Robotics, Parts I and II, </title> <booktitle> IEEE International Conference on Robotics and Automation, </booktitle> <address> Atlanta, GA. </address> <year> (1993). </year>
Reference-contexts: Nevertheless, the theory is still biased towards sensing, and it remains to develop a framework that treats action and sensing on an equal footing. This paper draws extensively on the material reported in the monograph by Donald [Don4], and announced in an abbreviated, preliminary version in <ref> [Don] </ref>. We reported on our ideas on coordinated manipulation strategies in a preliminary form in [DJR1-2]. 9 pushing task. The goal is to push the block B in a straight line. <p> We also give a "hierarchy" of reductions, ordered on power, so that the strength of 3 1 is also called &lt; s in <ref> [Don] </ref>. 4 For example: no algorithm exists to decide the existence of a linear-space (or log-space, polynomial time, Turing-computable, etc.) reduction between two CT problems. 11 our transformations can be quantified. Our ideas have the following applications: 1. (Comparison). <p> define the difference G G 0 of G and G 0 as follows: G G 0 = (V V 0 ; E E 0 ): Definition 3.9 may also be lifted to (partially) immersed graphs, and hence to situated manipulation circuits. 3.5 Reductions, Calibration, and Codesignation As we observed in <ref> [Don] </ref>, calibration exploits external state. We wish to order systems on how much information this external state (from calibration) yields, to obtain Definition 3.10, below. Calibration complexity is defined formally in [Don4]. Here is the basic idea. <p> Let comm (S) be a "sensor system" with one datapath e, that has bandwidth log |(b). Then, adding output communication to Q can be viewed as the following transformation on sensor systems: Q 7! Q + comm (S). The transformation 12 1 is also called &lt; s in <ref> [Don] </ref>. 37 is parameterized by (the bandwidth of) S. The bounded-bandwidth datapath e can be spliced into Q anywhere.
Reference: [Don1] <author> Donald, B. R. </author> <title> Robot Motion Planning, </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> (8), No. 2. </volume> <year> (1992). </year>
Reference-contexts: This paper uses the theoretical framework introduced by Donald in [Don,Don4]. A central theme to previous work (see the survey article <ref> [Don1] </ref> for a detailed review) has been to determine what information is required to solve a task, and to direct a robot's actions to acquire that information to solve it. Key questions concern: 1. What information is needed by a particular robot to accomplish a par ticular task? 2. <p> The arrows illustrate the direction of the applied forces. In addition to the work discussed here in Section 1, for a detailed bibliographic essay on previous research on the geometric theory of planning under uncertainty, see, e.g., <ref> [Don1] </ref> or [Don3]. The goals outlined here are ambitious and we have only taken a small step towards them. The questions above provide the setting for our inquiry, but we are far from answering them completely.
Reference: [Don2] <author> Donald, B. R. </author> <title> The Complexity of Planar Compliant Motion Planning with Uncertainty, </title> <journal> Algorithmica, </journal> <volume> 5 (3), </volume> <pages> pp. </pages> <month> 353-382 </month> <year> (1990). </year>
Reference-contexts: We note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, [Reif, HSS, Nat, CR]; see, eg, <ref> [Erd1, Don2, Can, Bri] </ref> for upper bounds). Rosenschein has developed a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates.
Reference: [Don3] <author> Donald, B. R. </author> <title> Error Detection and Recovery in Robotics, </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Vol. 336, </volume> <publisher> Springer-Verlag, </publisher> <address> New York (1989). </address>
Reference-contexts: The arrows illustrate the direction of the applied forces. In addition to the work discussed here in Section 1, for a detailed bibliographic essay on previous research on the geometric theory of planning under uncertainty, see, e.g., [Don1] or <ref> [Don3] </ref>. The goals outlined here are ambitious and we have only taken a small step towards them. The questions above provide the setting for our inquiry, but we are far from answering them completely.
Reference: [Don4] <author> Donald, B. R. </author> <title> Information Invariants in Robotics, , (1993). </title> <journal> Artificial Intelligence, </journal> <volume> 72 </volume> <pages> 217-304, </pages> <year> 1995. </year>
Reference-contexts: Of course, our protocols rely on a number of assumptions in order to work. We develop a framework for analysis and synthesis, based on information invariants <ref> [Don4] </ref>, to reveal these assumptions and expose the information structure of the task. We believe our theory has implications for the parallelization of manipulation tasks on spatially distributed teams of cooperating robots. <p> Hor-swill [Hors] has developed a semantics for sensory systems that models and quantifies the kinds of assumptions a sensori-computational program makes about its environment. He also gives source-to-source transformations on sensori-computational "circuits." The paper <ref> [Don4] </ref> discusses the semantics of sensor systems. This formalism is used to explore some properties of what we call situated sensor systems. [Don4] describes a way to transform sensori-computational systems. <p> He also gives source-to-source transformations on sensori-computational "circuits." The paper <ref> [Don4] </ref> discusses the semantics of sensor systems. This formalism is used to explore some properties of what we call situated sensor systems. [Don4] describes a way to transform sensori-computational systems. When one can be transformed into another, we say the latter can be "reduced" to the former, and we call the transformation a "reduction." We also derive algebraic algorithms for reducing one sensor 7 to another. <p> It is very difficult to analyze the interaction of sensing, computation, communication (a - e) and mechanics (f) (see Table 1) in distributed manipulation tasks. The analyses of <ref> [Don4] </ref> focus on (a - e), and each analysis is "parameterized" by the task. This paper represents an attempt to integrate a measure of the "information content of the task mechanics" (f) into the theory. <p> Nevertheless, the theory is still biased towards sensing, and it remains to develop a framework that treats action and sensing on an equal footing. This paper draws extensively on the material reported in the monograph by Donald <ref> [Don4] </ref>, and announced in an abbreviated, preliminary version in [Don]. We reported on our ideas on coordinated manipulation strategies in a preliminary form in [DJR1-2]. 9 pushing task. The goal is to push the block B in a straight line. <p> We then ask, is there a general theory quantifying the power gained in such trade-offs? In Section 3, we present a theory, which represents a systematic attempt to make such comparisons based on geometric and physical reasoning. In <ref> [Don4] </ref>, we operationalize our analysis by making it computational; we give effective (albeit theoretical) procedures for computing our comparisons. See Section 7 for a summary. We wish to rigorously compare embedded sensori-computational systems. <p> We foreground the task of pushing an object, using two communicating robots who need to infer the position of the first moment of the friction distribution with respect to their lines of pushing (see Figure 4a). In <ref> [Don4] </ref>, we asked whether explicit communication could be removed from this protocol (by "explicit" we mean local communication, such as IR, or global communication, such as RF). In this paper we give a protocol with no explicit communication, and we analyze and compare our protocols using the tools introduced in [Don4]. <p> <ref> [Don4] </ref>, we asked whether explicit communication could be removed from this protocol (by "explicit" we mean local communication, such as IR, or global communication, such as RF). In this paper we give a protocol with no explicit communication, and we analyze and compare our protocols using the tools introduced in [Don4]. <p> We do so below. 3 Reductions and Transformations We now formalize our model of manipulation protocols by viewing them as "manipulation circuits." (The theory in Sections 3-8 is adapted from <ref> [Don4] </ref>, but the particular examples and application (especially, claim 4.1), the definition of manipulation circuits, and the definition of tradeoffs are new.) We model these circuits as graphs. Vertices correspond to different sensori-computational components of the system (what we will call "resources" below). <p> Definition 3.6 can be generalized to any number of "unbound" vertices; see Equation (16) and <ref> [Don4] </ref>. Definition 3.6 precisely characterizes the equivalence relation of strong simulation described in Section 3.1. We now wish to generalize this definition in the case where S and Q are manipulation circuits. <p> Hence, in class edge permutation, we permute edges within a type (or class). In this paper we will restrict our edge permutations to this kind of class edge permutation. Class edge permutation leaves unchanged the complexity bounds and the lemmas of <ref> [Don4] </ref>. To summarize: vertex permutation preserves the graph topology whereas edge permutation can move the edges around. Edge permutation permits arbitrary rewiring (using existing edges). It cannot add new edges, nor can it change their bandwidth. <p> We wish to order systems on how much information this external state (from calibration) yields, to obtain Definition 3.10, below. Calibration complexity is defined formally in <ref> [Don4] </ref>. Here is the basic idea. Calibration complexity measures how much information we add to a sensor system when we install and calibrate it. Installing a sensor system may require physically establishing some spatial relation between two components of the system. <p> For example, the odometry system odom and the -source system in Section 4 are black boxes. More generally, we call a sensor system monotonic if its internal bandwidth is bounded above by its output size. So, black box sensors are trivially monotonic. All the sensor systems in <ref> [Don4] </ref> are monotonic. If we believe that the output size of our protocols is O (log |(p)) bits, then our sensor systems are also monotonic. If we believe the output size is 2 bits, they are not. <p> The definitions and arguments in this section generalize mutatis mutandis from sensor systems to manipulation circuits. 3.5.2 Reductions using Communication In light of this discussion, we now define the reduction 1 from <ref> [Don4] </ref>, using relativized information complexity. Recall the construction of comm () as a sensor system (Section 3.2). First, let S be a monotonic sensor system with output z. In this case, we define comm (S) to be comm (z). <p> We say S is efficiently reducible to Q if S fl Q + comm (S): (2) In this case we write 12 S 1 Q. Now, permutation (the fl operation) and combination (the + operation) "commute" for compatible partial immersions. This is formalized as a "distributive" property in <ref> [Don4] </ref>. So, for example, for any manipulation circuit S, we have ensured that S fl + comm () = (S + comm ()) fl , i.e., we can do the permutation and combination in any order. Second we have ensured that the combination operation + is commutative and associative. <p> It does not appear to be transitive. The reduction fl (Definition 3.11) is a "0-wire" reduction. It is transitive for simple sensor systems <ref> [Don4] </ref>. We could analogously define a 2-wire, or more generally, any k-wire reduction k by modifying Equation (2) in Definition 3.13 to S fl Q + k comm (S); (2 0 ) where k comm (S) denotes k times z -| - comm (S) + + comm (S). <p> The k-wire reductions f i g i2N form a graded relation. Even though we believe that 1 is not transitive (in the elementary sense), the hierarchy has graded transitivity on simple sensor systems <ref> [Don4] </ref>. This means that for any simple sensor systems S, Q, and U , if S i Q and Q j U , then S i+j U . This follows from a lemma that the 0-wire reduction 0 (called fl in Definition 3.11) is elementary transitive for simple sensor systems. <p> Consider the hierarchy of k-wire reductions f i g i2N . We say such a hierarchy collapses if it is isomorphic to an elementary relation. In particular, the hierarchy of k-wire reductions (k &gt; 0) collapses if 1 is elementary transitive <ref> [Don4] </ref>. 4 Comparing Protocols Using Reductions The results in Section 4 apply using both strong and weak simulation. We now apply the ideas above to compare our protocols, P.I (QS) and P.II (the circuits in Figures 8-10). First, we define two black boxes (see sec. 3.5.1). <p> Equations (8) and (9) together argue that B A = 0, in other words, that B and A trade-off, or are equivalent. One caveat is that "B = A" is only valid for the task specified in the codesignation constraints <ref> [Don4] </ref> of Q and S. For example, we prove resource trade-offs for our two manipulation circuits; but we only claim these trade-offs for the pushing task. For some other task, resources A and B may not function equivalently 13 . <p> This defines a partial order on the space of reduction types (fg [ (f=; g fi Z)) 2 , and this partial order in turn defines a hierarchy of trade-offs. 13 To prove trade-offs across a class of tasks, we must use a mechanism called "universal reduction" <ref> [Don4] </ref>, which is beyond the scope of this paper. 14 When S k Q and Q k S we write S = k Q. When S Q and Q S we write S Q. <p> It is somewhat surprising that for strong simulation (but not for weak simulation) we can in fact automate this process: <ref> [Don4] </ref> gives algorithms for deciding the relation 1 . More precisely, given suitable encodings of two sensor systems S and U , we can computationally decide whether S 1 U [Don4]. The algorithm is too complicated to describe here. <p> It is somewhat surprising that for strong simulation (but not for weak simulation) we can in fact automate this process: <ref> [Don4] </ref> gives algorithms for deciding the relation 1 . More precisely, given suitable encodings of two sensor systems S and U , we can computationally decide whether S 1 U [Don4]. The algorithm is too complicated to describe here. We examine a special case to give a flavor for it; many details are omitted. The basic idea involves employing the theory of real closed fields with bounded quantification. <p> We will model (algebraic) codesignation constraints as a (possibly constant) semi-algebraic (s.a.) mapping 7! D ( ) taking an immersion to a s.a. set D ( ) C d . All these methods generalize to graph permutation as well <ref> [Don4] </ref>. Now, 45 Definition 7.1 A simulation function U for U is a map U : C d ! R, where R the space of outputs. We call the value U () 2 R of U on a sensor configuration to be the output value or sensor value at . <p> Here is why: to decide 1 , we must determine whether (S; ) fl (U ; )+comm (S), (Definition 3.13). Recall the definition of compatibility for partial immersions (Section 3.4). We first observe that permutation (the fl operation) and combination (the + operation) "commute" for compatible partial immersions <ref> [Don4] </ref>. Our arguments above for guessing extensions and permutations can be generalized mutatis mutandis to compute the combination (Definition 3.8) of two algebraic sensor systems. <p> This can be done independently, and much faster than Equation (16) can be decided; see <ref> [Don4] </ref>. 46 Let us suppose that U and S are algebraic. Let us define the size d of U to be the number of vertices in U . Let the simulation complexity n be the size of the simulation functions U and S . <p> Note that for "small" sensor systems, Equation (17) becomes d (r c d) O (1) Although complex, Equation (16) is simplified for presentation. The full Tarski sentence also contains codesignation constraints for the outer quantifiers, and is given in <ref> [Don4] </ref>. We must warn that in Section 7 we have examined a special case, where S and U are partially situated (that is, the domains of and are non-empty). A powerful generalization is given in app. A, where the sensor systems can be unsituated. <p> Question (ii) sheds light on whether we can cheaply and cleverly reencode a sensor system so as to gain a lot of "power" (information complexity). <ref> [Don4] </ref> first derives the complexity bounds in lemma 7.3 and Equation (17-18) for vertex permutation. Next, [Don4] asks: how expensive it is to compute the reductions fl and 1 using graph permutation? By extending the configuration space C d to include all possible edge permutations, we obtain an extended configuration space <p> Question (ii) sheds light on whether we can cheaply and cleverly reencode a sensor system so as to gain a lot of "power" (information complexity). <ref> [Don4] </ref> first derives the complexity bounds in lemma 7.3 and Equation (17-18) for vertex permutation. Next, [Don4] asks: how expensive it is to compute the reductions fl and 1 using graph permutation? By extending the configuration space C d to include all possible edge permutations, we obtain an extended configuration space of sufficiently low dimension that we still obtain the same complexity bounds given in lemma 7.3 <p> graph permutation? By extending the configuration space C d to include all possible edge permutations, we obtain an extended configuration space of sufficiently low dimension that we still obtain the same complexity bounds given in lemma 7.3 and eqs. (17-18), (so long as r and s are constants|see Page 23) <ref> [Don4] </ref>. We now address question (ii): does graph permutation give us a more powerful reduction? We show: Lemma 8.1 (The Clone Lemma) Graph permutation can be simulated using vertex permutation, preceded by a linear time and linear space transformation of the sensor system. <p> We are currently completing such an analysis. 19 In terms of program development, synchrony, and communication, we have the following approximate correspondence between these protocols: We believe that a methodology for developing coordinated manipulation protocols is emerging, based on the tools described in this paper, [DJR1 2,RDJ], and <ref> [Don4] </ref>: Developing Parallel Manipulation Protocols 1. Start with a sensorless [EM, EMV] or near-sensorless [Erd4, JR] manipulation protocol requiring global coordination of several "agents" (e.g., fingers [Gol, Rus], or "fences" [PS]). Examples: 4 1 above [Rus] or protocol O (Figure 5). 2. Distribute the protocol over spatially separated agents. <p> Consider the relation = k defined in Section 5. = k is only an equivalence relation for k = 0, althought = k does obey graded transitivity <ref> [Don4] </ref>. By analogy with CT reductions, we may ask, does a given class of sensori-computational systems contain "complete" circuits, to which any member of the class may be reduced? Note that any two complete circuits are "graded equivalent" under = k . <p> Appendix A What is Permutation? In Section 7 we examined a special case, where S and U are partially situated (that is, the domains of and are non-empty). A powerful generalization is given in <ref> [Don4] </ref>, where the sensor systems can be unsituated. Using the ideas in Section 7, we can give an "abstract" version of permutation that is applicable to partially immersed sensor systems with codesignation constraints. Each set of codesignation constraints defines a different arrangement in the space of all immersions. <p> This region constraints the necessary coplacements fl 0 of U relative to (S; 0 ). Perhaps surprisingly, allowing unsituated permutation does not change the complexity bounds of Section 7 <ref> [Don4] </ref>.
Reference: [DJ] <author> Donald, B. R. and J. </author> <title> Jennings Constructive Recognizability for Task-Directed Robot Programming, </title> <journal> Jour. Robotics and Autonomous Systems, </journal> <volume> (9), No. 1, </volume> <pages> Elsevier/North-Holland pp. 41-74. </pages> <year> (1992). </year> <month> 57 </month>
Reference-contexts: His theory is set in a logical framework where sensors are logical predicates. Perhaps our theory could be viewed as a geometric attack on a similar problem. This work was motivated by the theoretical attack on perceptual equivalence begun by <ref> [DJ] </ref> and by the experimental studies of [JR]. Hor-swill [Hors] has developed a semantics for sensory systems that models and quantifies the kinds of assumptions a sensori-computational program makes about its environment. He also gives source-to-source transformations on sensori-computational "circuits." The paper [Don4] discusses the semantics of sensor systems. <p> Such a sensor looks at a visual field and outputs one bit, returning #t if the visual field contains a grandmother and #f if it doesn't. Now, one view of the sensor interpretation problem is that of information reduction and identification (compare <ref> [DJ] </ref>, which discusses hierarchies of sensor information). However consider a somewhat different perspective, that views sensors as model matchers. <p> See [RDJ]. 20 We use the term in the sense of <ref> [DJ] </ref>; others, particularly Henderson have used similar concepts. 52 explicit communication. into the control system or the environment.
Reference: [DJR1] <author> Donald, B. R., J. Jennings, and D. </author> <title> Rus Experimental Infor--mation Invariants for Cooperating Autonomous Mobile Robots, </title> <booktitle> International Joint Conference on Artificial Intelligence (IJCAI) Workshop on Dynamically Interacting Robots. </booktitle> <address> Chambery, France (Aug 28) (1993). </address>
Reference-contexts: We think that information invariants can serve as a framework in which to measure the capabilities of robot systems, to quantify their power, and to reduce their fragility with respect to assumptions that are engineered 19 In particular, we have considerably improved the protocol 4 3 from <ref> [DJR1] </ref>. See [RDJ]. 20 We use the term in the sense of [DJ]; others, particularly Henderson have used similar concepts. 52 explicit communication. into the control system or the environment.
Reference: [DJR2] <author> Donald, B. R., J. Jennings, and D. </author> <title> Rus Towards a Theory of Information Invariants for Cooperating Autonomous Mobile Robots, </title> <booktitle> International Symposium on Robotics Research (ISRR). </booktitle> <address> Hidden Valley, PA (October 2, </address> <year> 1993). (1993). </year>
Reference: [Erd1] <author> Erdmann, M. </author> <title> Using Backprojections for Fine Motion Planning with Uncertainty, </title> <journal> IJRR Vol. </journal> <volume> 5 no. </volume> <month> 1 </month> <year> (1986). </year>
Reference-contexts: We note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, [Reif, HSS, Nat, CR]; see, eg, <ref> [Erd1, Don2, Can, Bri] </ref> for upper bounds). Rosenschein has developed a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates.
Reference: [Erd2] <author> Erdmann, M. </author> <title> On Probabilistic Strategies for Robot Tasks, </title> <type> Ph.D. thesis, </type> <institution> MIT Department of EECS, MIT A.I. Lab, </institution> <address> Cambridge MIT-AI-TR 1155 (1989). </address>
Reference-contexts: In our quest for an intrinsic measure of the information requirements of a task, we are inspired by Erdmann's monograph on sensor design [Erd3], and the information invariants that Erdmann introduced to the robotics community in 1989 <ref> [Erd2] </ref>. We also observe that rigorous examples of information invariants can be found in the theoretical literature from as far back as 1978 (see, for example, [BK, Koz]).
Reference: [Erd3] <author> Erdmann, M. </author> <title> Action Subservient Sensing and Design, </title> <publisher> IEEE ICRA, </publisher> <address> Atlanta. </address> <note> See also the Carnegie-Mellon report CMU-CS-92-116. </note> <year> (1993). </year>
Reference-contexts: In our quest for an intrinsic measure of the information requirements of a task, we are inspired by Erdmann's monograph on sensor design <ref> [Erd3] </ref>, and the information invariants that Erdmann introduced to the robotics community in 1989 [Erd2]. We also observe that rigorous examples of information invariants can be found in the theoretical literature from as far back as 1978 (see, for example, [BK, Koz]).
Reference: [Erd4] <author> Erdmann, M. </author> <title> Randomization for Robot Tasks: Using Dynamic Programming in the Space of Knowledge States, </title> <journal> Algorithmica Vol. </journal> <volume> 10, Nos. 2/3/4, Aug/Sept/Oct. </volume> <pages> pp. </pages> <month> 248-291 </month> <year> (1993). </year>
Reference-contexts: Start with a sensorless [EM, EMV] or near-sensorless <ref> [Erd4, JR] </ref> manipulation protocol requiring global coordination of several "agents" (e.g., fingers [Gol, Rus], or "fences" [PS]). Examples: 4 1 above [Rus] or protocol O (Figure 5). 2. Distribute the protocol over spatially separated agents. Synchronize and coordinate control using explicit local communication.
Reference: [EM] <author> Erdmann, M., and M. Mason, </author> <title> "An Exploration of Sensorless Manipulation", </title> <booktitle> IEEE International Conference on Robotics and Automation, </booktitle> <address> San Francisco, </address> <month> April, </month> <year> 1986. </year>
Reference-contexts: The boxes are typically several robot diameters wide, and 1-2 times the mass of a single robot, although the robots have also pushed couches that are heavier (perhaps 2-4 times the mass, and 8 fi 3 robot diameters in size). We build on the ground-breaking work of <ref> [Mason, EM] </ref> and others on planar sensorless manipulation. Our work differs from previous work on pushing in several ways. First, the robots and boxes are on a similar dynamic and spatial scale. <p> Start with a sensorless <ref> [EM, EMV] </ref> or near-sensorless [Erd4, JR] manipulation protocol requiring global coordination of several "agents" (e.g., fingers [Gol, Rus], or "fences" [PS]). Examples: 4 1 above [Rus] or protocol O (Figure 5). 2. Distribute the protocol over spatially separated agents. Synchronize and coordinate control using explicit local communication.
Reference: [EMV] <author> Erdmann, M., M. Mason, and G. </author> <title> Vanecek Mechanical Parts Orienting: The Case of a Polyhedron on a Table, </title> <journal> Algorithmica Vol. </journal> <volume> 10, Nos. 2/3/4, Aug/Sept/Oct. </volume> <pages> pp. </pages> <month> 266-247 </month> <year> (1993). </year>
Reference-contexts: Start with a sensorless <ref> [EM, EMV] </ref> or near-sensorless [Erd4, JR] manipulation protocol requiring global coordination of several "agents" (e.g., fingers [Gol, Rus], or "fences" [PS]). Examples: 4 1 above [Rus] or protocol O (Figure 5). 2. Distribute the protocol over spatially separated agents. Synchronize and coordinate control using explicit local communication.
Reference: [Gol] <author> Goldberg, K. </author> <title> Y Orienting Parts without Sensors, </title> <journal> Algorithmica Vol. </journal> <volume> 10, Nos. 2/3/4, Aug/Sept/Oct. </volume> <pages> pp. </pages> <month> 201-225 </month> <year> (1993). </year>
Reference-contexts: Start with a sensorless [EM, EMV] or near-sensorless [Erd4, JR] manipulation protocol requiring global coordination of several "agents" (e.g., fingers <ref> [Gol, Rus] </ref>, or "fences" [PS]). Examples: 4 1 above [Rus] or protocol O (Figure 5). 2. Distribute the protocol over spatially separated agents. Synchronize and coordinate control using explicit local communication. Examples: Protocol I (QS), or 4 2 above. 3.
Reference: [HSS] <author> Hopcroft, J. E., Schwartz, J. T., and Sharir, M. </author> <title> 1984 On the Complexity of Motion Planning for Multiple Independent Objects; PSPACE-Hardness of the "Warehouseman's Problem." </title> <journal> International Journal of Robotics Research. </journal> <volume> 3(4) </volume> <pages> 76-88. </pages>
Reference-contexts: We also observe that rigorous examples of information invariants can be found in the theoretical literature from as far back as 1978 (see, for example, [BK, Koz]). We note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, <ref> [Reif, HSS, Nat, CR] </ref>; see, eg, [Erd1, Don2, Can, Bri] for upper bounds). Rosenschein has developed a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates.
Reference: [Hors] <author> Horswill, I. </author> <title> Analysis of Adaptation and Environment, </title> <note> Submitted to Artificial Intelligence (1992). 58 </note>
Reference-contexts: His theory is set in a logical framework where sensors are logical predicates. Perhaps our theory could be viewed as a geometric attack on a similar problem. This work was motivated by the theoretical attack on perceptual equivalence begun by [DJ] and by the experimental studies of [JR]. Hor-swill <ref> [Hors] </ref> has developed a semantics for sensory systems that models and quantifies the kinds of assumptions a sensori-computational program makes about its environment. He also gives source-to-source transformations on sensori-computational "circuits." The paper [Don4] discusses the semantics of sensor systems. <p> that perhaps the intrinsic output complexity of the protocols should be more like log |(x) bits. 10 9 I.e., of the form X = Y or X 6= Y 10 To see that instrumenting and x require the same number of bits, requires an argument like the "decalibration" lemmas of <ref> [Hors] </ref>. For this paper, we can see this from the relation 2r tan (t) = (t): 34 Another idea is to observe that the actuator output p in Push (p) would be at a similar resolution to the orientation sensing (t) or odometry x i (t). <p> We need to argue that a register big enough to hold x i (0) will also hold 0 ; this follows from 2r tan (t) = (t), or from "decalibration" <ref> [Hors] </ref>. Next, we see that we can permute the internal edges of U to wire up the components of P.II in situ|internally. What about externally? Permuting the external wiring almost works, but not quite.
Reference: [JR] <author> Jennings, J. and Rus, D. </author> <title> Active Model Acquisition for Near-Sensorless Manipulation with Mobile Robots, </title> <booktitle> The IASTED International Conference on Robotics and Manufacturing, </booktitle> <address> Oxford, UK (1993). </address>
Reference-contexts: Fourth, our protocols assume neither that the robot has a geometric model of the box, nor that the first moment of the friction distribution is known. Instead, the robot combines sensorimotor experiments and manipulation strategies to infer the necessary information (the experiments have the flavor of <ref> [JR] </ref>). Finally, the pushing literature generally regards the "pushers" as moving kinematic constraints. In our case, because (i) there are at least two robot pushers and (ii) the robots are less massive than the box, the robots are really "force-appliers" in a system with significant friction. <p> His theory is set in a logical framework where sensors are logical predicates. Perhaps our theory could be viewed as a geometric attack on a similar problem. This work was motivated by the theoretical attack on perceptual equivalence begun by [DJ] and by the experimental studies of <ref> [JR] </ref>. Hor-swill [Hors] has developed a semantics for sensory systems that models and quantifies the kinds of assumptions a sensori-computational program makes about its environment. He also gives source-to-source transformations on sensori-computational "circuits." The paper [Don4] discusses the semantics of sensor systems. <p> In addition, each robot has a ring of one-bit 14 contact ("bump") sensors. We assume the following: * using bump sensors, robots in contact with a flat object face can mea sure the relative orientation of that face <ref> [JR] </ref>; * the robots are on the same flat face of the object; * both robots know the direction of pushing, p; * the robots can synchronize their velocities; 5 * by examining the servo-loop in [RD], it is clear that we can compute a measure of applied force by observing <p> Moreover, we observe that the tangent function is monotonic and sign preserving; this means we can adapt the control system to servo on instead of , without knowing r. Specifically, let n be the normal to the box face. <ref> [JR] </ref> describe an algorithm for measuring n with bounded error. In our final protocol, the robots measure 0 (the initial angle between n and p), and compare this value to the angle (t) measured at time t in order to infer the direction of motion of the box. <p> Intuitively, once the control is added to the sensor system, we obtain a manipulation circuit. This augmentation is made precise below. One interesting resource is (t) in Figure 13|we call this box a -source| it produces a signal indicating relative orientation. <ref> [JR] </ref> describe in detail how to implement a bounded-error -source. Here is the basic idea. A - source is an abstraction of relative normal sensing. It allows the normal of the box to be treated as an external "register" that both robots may read and write. <p> It allows the normal of the box to be treated as an external "register" that both robots may read and write. We could implement an (approximate) -source as follows. The robot has a ring of 1-bit bump sensors. These are used to implement relative normal sensing <ref> [JR] </ref>. We specify the pushing direction p, by specifying 0 (see Figure 10), the direction of p relative to the box normal n (0) at time 0. More specifically: at the beginning of the task, each robot does a guarded move along p until contact with the box. <p> More specifically: at the beginning of the task, each robot does a guarded move along p until contact with the box. It then aligns normal to the box, using the bounded-error algorithm of <ref> [JR] </ref>. Finally, the robot turns by angle 0 using pure position control. init is one bit of state, and run= init. The small crossed circles () that these bits run into are gates; the # input must be 1 for the $ signal to pass. <p> In describing Protocol P.II, we demonstrated that one implementation of such a circuit involves using some retained state ( 0 ), and a relative orientation sensor such as the bumper system described in <ref> [JR] </ref>. In fact, Claim 4.1 is a precise statement of this engineering fact. Below, we carefully define the operators + and , and formalize the notions of simulation and efficient reduction, as well as permutation, etc. Our reduction involves two concepts. <p> Start with a sensorless [EM, EMV] or near-sensorless <ref> [Erd4, JR] </ref> manipulation protocol requiring global coordination of several "agents" (e.g., fingers [Gol, Rus], or "fences" [PS]). Examples: 4 1 above [Rus] or protocol O (Figure 5). 2. Distribute the protocol over spatially separated agents. Synchronize and coordinate control using explicit local communication.
Reference: [Koz] <author> Kozen, D. </author> <title> Automata and Planar Graphs, </title> <booktitle> Fundamentals of Computing Theory, Proc. Conference on Algebraic, Arithmetic, and categorical methods in Computation Theory (Berlin) ed. </booktitle> <editor> L. Budach, </editor> <publisher> Akademie Verlag (1979). </publisher>
Reference-contexts: We also observe that rigorous examples of information invariants can be found in the theoretical literature from as far back as 1978 (see, for example, <ref> [BK, Koz] </ref>). We note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, [Reif, HSS, Nat, CR]; see, eg, [Erd1, Don2, Can, Bri] for upper bounds).
Reference: [Lat] <author> Latombe, J.-C. </author> <title> Robot Motion Planning, </title> <publisher> Kluwer: </publisher> <address> New York (1991). </address>
Reference: [LMT] <author> Lozano-Perez, T., Mason, M. T., and Taylor, R. H. </author> <title> Automatic Synthesis of Fine-Motion Strategies for Robots, </title> <journal> Int. J. of Robotics Research, </journal> <volume> Vol 3, no. </volume> <month> 1 </month> <year> (1984). </year>
Reference-contexts: For example, a velocity controller is a component whose output causes the velocity of the system to change. One easy way to model a velocity controller uses a first-order dynamics equation such as generalized damper dynamics (see <ref> [LMT, Erd86, Don89] </ref>. The output of the actuator is still manifested as force tangent to the configuration space. However the dynamics equation is changed to where B is a constant chosen in design. 3.
Reference: [Mas] <author> Mason, M. T. </author> <year> 1986. </year> <title> Mechanics and Planning of Manipulator Pushing Operations. </title> <journal> International Journal of Robotics Research 5(3). </journal>
Reference-contexts: The robot consists of two rigidly connected fingers L and R; for example, they could be the fingers of a parallel-jaw gripper. One complication involves the micro-mechanical variations in the slip of the box on the table <ref> [Mas] </ref>. This phenomenon is very hard to model, and hence it is difficult to predict the results of a one-fingered push; we will only obtain a straight-line trajectory when the center of friction (COF) lies on the line of pushing.
Reference: [ML] <author> Mason, M. and Lynch, K. </author> <title> Dynamic Manipulation, </title> <booktitle> Proc. of the 1993 IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, </booktitle> <address> Yokohama, Japan, </address> <month> July 26-30 </month> <year> (1993). </year>
Reference-contexts: In our case, because (i) there are at least two robot pushers and (ii) the robots are less massive than the box, the robots are really "force-appliers" in a system with significant friction. In this sense, our task is in some ways closer in flavor to dynamic manipulation <ref> [ML] </ref>, even though the box dynamics are essentially quasi-static. Of course, our protocols rely on a number of assumptions in order to work. We develop a framework for analysis and synthesis, based on information invariants [Don4], to reveal these assumptions and expose the information structure of the task.
Reference: [Nat] <author> Natarajan, B. K. </author> <title> On Planning Assemblies, </title> <booktitle> Proc. of the 4th Annual Symposium on Computational Geometry, </booktitle> <address> Urbana, Illinois, </address> <month> June. </month> <pages> pp. 299-308. </pages> <year> (1988). </year>
Reference-contexts: We also observe that rigorous examples of information invariants can be found in the theoretical literature from as far back as 1978 (see, for example, [BK, Koz]). We note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, <ref> [Reif, HSS, Nat, CR] </ref>; see, eg, [Erd1, Don2, Can, Bri] for upper bounds). Rosenschein has developed a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates.
Reference: [PS] <author> Peshkin, M. </author> <title> Planning Robotic Manipulation Strategies for Sliding Objects, </title> <type> Ph.D. dissertation, </type> <institution> Department of Physics, Carnegie-Mellon University (1986). </institution>
Reference-contexts: Start with a sensorless [EM, EMV] or near-sensorless [Erd4, JR] manipulation protocol requiring global coordination of several "agents" (e.g., fingers [Gol, Rus], or "fences" <ref> [PS] </ref>). Examples: 4 1 above [Rus] or protocol O (Figure 5). 2. Distribute the protocol over spatially separated agents. Synchronize and coordinate control using explicit local communication. Examples: Protocol I (QS), or 4 2 above. 3.
Reference: [RD] <author> Rees, J. and B. R. </author> <title> Donald Program Mobile Robots in Scheme, </title> <booktitle> Proc. IEEE International Conference on Robotics and Automation, </booktitle> <address> Nice, France (1992). </address>
Reference-contexts: From the mechanics perspective it might appear we are done. However, it is difficult to overstate how critically Protocol O above relies on global communication and control. Now, consider the analogous pushing task in as those described in <ref> [RD] </ref>. The robots we have in mind are the Cornell mobile robots (see Figure 1), but the details of their construction are not important. The robots can move about by controlling motors attached to wheels. <p> The robots can move about by controlling motors attached to wheels. The robots are autonomous and equipped with a ring of 12 simple Polaroid ultrasonic sonar sensors. Each robot has onboard processors for control and programming. The description in <ref> [RD] </ref> is augmented as follows. (This description characterizes the robots in our lab). We equip each robot with 12 infra-red modems/sensors, arrayed in a ring about the robot body. Each modem consists of an emitter-detector pair. <p> with a flat object face can mea sure the relative orientation of that face [JR]; * the robots are on the same flat face of the object; * both robots know the direction of pushing, p; * the robots can synchronize their velocities; 5 * by examining the servo-loop in <ref> [RD] </ref>, it is clear that we can compute a measure of applied force by observing the applied power, the position and velocity of the robot, and the contact sensors. The pushing strategy described as Protocol 0 can be approximated by observing the following (see Figures 6, 7).
Reference: [Reif ] <author> Reif J., </author> <title> "Complexity of the Mover's Problem and Generalizations," </title> <booktitle> Proc. 20th IEEE Symp. FOCS, </booktitle> <year> (1979). </year>
Reference-contexts: We also observe that rigorous examples of information invariants can be found in the theoretical literature from as far back as 1978 (see, for example, [BK, Koz]). We note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, <ref> [Reif, HSS, Nat, CR] </ref>; see, eg, [Erd1, Don2, Can, Bri] for upper bounds). Rosenschein has developed a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates.
Reference: [Ros] <author> Rosenschein, S.J. </author> <title> Synthesizing Information-Tracking Automata from Environment Descriptions, </title> <journal> Teleos Research TR No. </journal> <month> 2 </month> <year> (1989). </year>
Reference-contexts: Rosenschein has developed a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it <ref> [Ros] </ref>. His theory is set in a logical framework where sensors are logical predicates. Perhaps our theory could be viewed as a geometric attack on a similar problem. This work was motivated by the theoretical attack on perceptual equivalence begun by [DJ] and by the experimental studies of [JR].
Reference: [Rus] <author> Rus, D. </author> <title> "Fine Motion Planning for Dexterous Manipulation", </title> <type> PhD. </type> <note> Thesis available as CU-CS-TR 92-1323 (August) from Comp. </note> <institution> Sci. Dept., Cornell University, </institution> <year> 1992. </year> <month> 59 </month>
Reference-contexts: In this direction, we have also considered three multi-mobot manipulation protocols for box reorientation (see denote them by 4 1 ,4 2 , etc. For these protocols, we started with the o*ine algorithm 4 1 of <ref> [Rus] </ref>, which was designed for multi-fingered robot hands with global coordination. Next, we developed a protocol 4 2 for three cooperating mobile robots with local IR communication. <p> Start with a sensorless [EM, EMV] or near-sensorless [Erd4, JR] manipulation protocol requiring global coordination of several "agents" (e.g., fingers <ref> [Gol, Rus] </ref>, or "fences" [PS]). Examples: 4 1 above [Rus] or protocol O (Figure 5). 2. Distribute the protocol over spatially separated agents. Synchronize and coordinate control using explicit local communication. Examples: Protocol I (QS), or 4 2 above. 3. <p> Start with a sensorless [EM, EMV] or near-sensorless [Erd4, JR] manipulation protocol requiring global coordination of several "agents" (e.g., fingers [Gol, Rus], or "fences" [PS]). Examples: 4 1 above <ref> [Rus] </ref> or protocol O (Figure 5). 2. Distribute the protocol over spatially separated agents. Synchronize and coordinate control using explicit local communication. Examples: Protocol I (QS), or 4 2 above. 3. Define a virtual sensor 20 that measures the key signal we wish to servo on.

References-found: 33

