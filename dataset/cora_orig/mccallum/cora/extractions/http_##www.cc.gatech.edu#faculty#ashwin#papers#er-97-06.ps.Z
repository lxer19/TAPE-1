URL: http://www.cc.gatech.edu/faculty/ashwin/papers/er-97-06.ps.Z
Refering-URL: http://www.cs.gatech.edu/faculty/ashwin/ABSTRACTS-summary.html
Root-URL: 
Title: Continuous Case-Based Reasoning  
Author: A. Ram and J.C. Santamara 
Keyword: Case-based reasoning, machine learning, reinforcement learning, robot navigation, reactive control, motor schema-based navigation.  
Address: Atlanta, GA 30332, USA  
Affiliation: College of Computing, Georgia Institute of Technology,  
Note: To appear in Artificial Intelligence.  
Abstract: Case-based reasoning systems have traditionally been used to perform high-level reasoning in problem domains that can be adequately described using discrete, symbolic representations. However, many real-world problem domains, such as autonomous robotic navigation, are better characterized using continuous representations. Such problem domains also require continuous performance, such as online sensorimotor interaction with the environment, and continuous adaptation and learning during the performance task. This article introduces a new method for continuous case-based reasoning, and discusses its application to the dynamic selection, modification, and acquisition of robot behaviors in an autonomous navigation system, SINS (Self-Improving Navigation System). The computer program and the underlying method are systematically evaluated through statistical analysis of results from several empirical studies. The article concludes with a general discussion of case-based reasoning issues addressed by this research. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.W. Aha, </author> <title> Generalizing from Case Studies: A Case Study, </title> <booktitle> in: Proceedings of the Ninth International Conference of Machine Learning, </booktitle> <address> Aberdeen, Scotland, </address> <year> (1992) </year> <month> 1-10. </month>
Reference: [2] <author> P. Agre and D. Chapman, Pengi: </author> <title> An implementation of a theory of activity, </title> <booktitle> in: Proceedings of the American Association of Artificial Intelligence 1, </booktitle> <publisher> (Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1987) </year> <month> 268-272. </month>
Reference: [3] <author> R.C. Arkin, </author> <title> Motor Schema-Based Mobile Robot Navigation, </title> <note> in The International Journal of Robotics Research 8(4) (1989) 92-112. </note>
Reference-contexts: The interaction is computed according to different schemes, such as subsumption, in which the response of some modules can supress or subsume the response of other modules (e.g., [9]); weighted summation, in which the final response is a weighted average of individual responses (e.g., <ref> [3] </ref>); or voting, in which the final response depends on how many modules propose it (e.g., [31]). One of the main difficulties of the reactive control approach for autonomous navigation is to decide which modules should be active and under what situations. <p> Coordination among motor schemas is accomplished by a set of gains or control parameters, which determine the final response of the robot through a weighted summation schema (e.g., <ref> [3] </ref>). For example, the parameter which modulates the output of the "obstacle avoidance" motor schema affects the robot's tendency to avoid obstacles. In a clear environment with very few obstacles, this parameter should be reduced so as to permit the robot to take a relatively direct path towards the goal. <p> Simple behaviors, such as wandering, obstacle avoidance, and goal following, can combine to produce complex emergent behaviors in a particular environment. Different emergent behaviors can be obtained by modifying the simple behaviors. A detailed description of schema-based reactive control methods can be found in <ref> [3] </ref>. In this research, we used three motor schemas: Avoid-Static-Obstacle, Move-To-Goal, and Noise. Avoid-Static-Obstacle directs the system to move itself away from detected obstacles. Move-To-Goal schema directs the system to move towards a particular point in the terrain.
Reference: [4] <author> R.C. </author> <title> Arkin and D.C. MacKenzie, Temporal Coordination of Perceptual Algorithms for Mobile Robot Navigation, </title> <journal> IEEE Transactions on Robotics and Automation 10(3) (1994) 276-286. </journal> <volume> 58 </volume>
Reference-contexts: In a clear environment with very few obstacles, this parameter should be reduced so as to permit the robot to take a relatively direct path towards the goal. As mentioned previously, one approach to coordinate motor schema-based behaviors is to precompile their priorities (or gains) at design time (e.g., <ref> [4] </ref>). In this approach, the designers know the types of situations the robot may encounter and the appropriate coordination scheme to use under those situations. Thus, the robot must simple detect under what situation is currently navigating and use the precompiled coordination scheme to successfully perform its task.
Reference: [5] <author> K. Ashley and E. Rissland, </author> <title> Compare and Contrast, A Test of Expertise, </title> <booktitle> in: Proceedings of the Sixth National Conference on Artificial Intelligence (Morgan Kaufmann, </booktitle> <address> Los Altos, CA, </address> <year> 1987) </year> <month> 273-284. </month>
Reference: [6] <author> C.G. Atkeson, </author> <title> Memory-Based Learning in Intelligent Control Systems, </title> <booktitle> in: Proceedings of the 1990 American Control Conference, </booktitle> <address> San Diego, CA, </address> <month> 1 </month> <year> (1990) </year> <month> 988. </month>
Reference: [7] <author> Balch, T., Boone, G., Collins, T., Forbes, H., MacKenzie, D., and Santamara, J.C., Io, Ganymede, and Callisto: </author> <title> A Multiagent Robot Janitorial Team, </title> <journal> AI Magazine 16(2) (1995) 39-51. </journal>
Reference: [8] <author> J. Berger, ROENTGEN: </author> <title> Radiation Therapy and Case-based Reasoning, </title> <booktitle> in: Proceedings of the Tenth Conference on Artificial Intelligence for Applications (San Antonio, </booktitle> <address> TX, </address> <year> 1994) </year> <month> 171-177. </month>
Reference: [9] <author> R. Brooks, </author> <title> A Robust Layered Control System for a Mobile Robot, </title> <journal> IEEE Journal of Robotics and Automation RA-2(1) (1986) 14-23. </journal>
Reference-contexts: The response of the robot is the result of the interaction of all the responses in the system. The interaction is computed according to different schemes, such as subsumption, in which the response of some modules can supress or subsume the response of other modules (e.g., <ref> [9] </ref>); weighted summation, in which the final response is a weighted average of individual responses (e.g., [3]); or voting, in which the final response depends on how many modules propose it (e.g., [31]).
Reference: [10] <author> S.A., Chien, </author> <title> M.T. Gervasio, and G.F. DeJong, On Becoming Decreasingly Reactive: Learning to Deliberate Minimally, </title> <booktitle> in: Proceedings of the Eighth International Workshop on Machine Learning Chicago, </booktitle> <address> IL, </address> <year> (1991) </year> <month> 288-292. </month>
Reference-contexts: However, in traditional case-based planning systems (e.g., [22]) learning and adaptation requires a detailed model of the domain. This is exactly what reactive planning systems are trying to avoid. Earlier attempts to combine reactive control with classical planning systems (e.g., <ref> [10] </ref>) or explanation-based learning systems (e.g., [39]) also relied on deep reasoning and were typically too slow for the fast, reflexive behavior required in reactive control systems. Unlike these approaches, our method does not fall back on slow non-reactive techniques for improving reactive control. <p> whether it should be used to modify the information represented in the best available case. 6.9 On-line real-time response Unlike traditional case-based reasoning systems which rely on deep reasoning and analysis (e.g., [22]), and unlike other machine learning augmentations to reactive control systems which fall back on non-reactive reasoning (e.g., <ref> [10] </ref>), our method allows the system to continue to perform reactively with very little performance overhead as compared to a "pure" reactive control system.
Reference: [11] <author> P.R. Cohen and A.E. Howe, </author> <title> How evaluation guides AI research, </title> <journal> AI Magazine 9(4) (1988) 35-43. </journal>
Reference: [12] <author> P.R. Cohen and A.E. Howe, A.E. </author> <title> Towards AI research Methodology: Three Case Studies in Evaluation, </title> <journal> IEEE Transactions on Systems, Man, </journal> <note> and Cybernetics 19(3) (1989) 634-646. </note>
Reference: [13] <author> G.F. DeJong, </author> <title> Learning to Plan in Continuous Domains, </title> <booktitle> Artificial Intelligence 65(1) (1994) 71-141. </booktitle>
Reference-contexts: This assumption could be relaxed if adequate symbolic representations and similarity metrics could be developed (see, for example, <ref> [13] </ref>, for an approach to continuous planning based on qualitative process theory), but more research is needed into this issue.
Reference: [14] <author> E.A. Domeshek, </author> <title> Do the Right Thing: A Component Theory for Indexing Stories as Social Advice, </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT (1992). </address>
Reference-contexts: A better solution would be to develop a method for organization of cases in memory; however, conventional memory organization schemes used in case-based reasoning systems (see [27]) assume structured, nominal information (e.g., <ref> [14] </ref>) rather than continuous, time-varying, analog information of the kind used in our cases. 57 Another open issue is that of the nature of the regularities captured in the sys-tem's cases. While SINS' cases do enhance its performance, they are not easy to interpret.
Reference: [15] <author> R.E. Fikes, P.E. Hart, and N.J. Nilsson, </author> <title> Learning and Executing Generalized Robot Plans. </title> <booktitle> Artificial Intelligence 3 (1972) 251-288. </booktitle>
Reference: [16] <author> D. Fisher, </author> <title> Knowledge Acquisition via Incremental Conceptual Clustering. </title> <note> Machine Learning 2 (1987) 139-172. </note>
Reference: [17] <author> A. Francis and A. Ram, </author> <title> Computational Models of the Utility Problem and their Application to a Utility Analysis of Case-Based Reasoning, </title> <booktitle> in: Proceedings of the ML-93 Workshop on Knowledge Compilation and Speedup Learning Amherst, </booktitle> <address> MA, </address> <year> (1993). </year>
Reference: [18] <author> E.K. Jones and A. Roydhouse, </author> <title> Intelligent Retrieval of Archived Meteorological Data, </title> <booktitle> IEEE Expert 10 (1995) 6. </booktitle>
Reference-contexts: For example, Berger's ([8]) ROENTGEN system, which is used to used design radiation therapy plans for patients, uses representations of continuous attributes. Other domains, such as weather prediction, may also require hybrid symbolic-continuous representations; see, for example, <ref> [18] </ref>). 49 The fine-grained nature of the representations is important in case adapta-tion as well. For example, in the SWALE system ([24,54]), an explanation pattern may be adapted using a rule that recommends that a "man" be substituted by a "horse".
Reference: [19] <author> M. Georgeff, </author> <note> Planning, Annual Review of Computer Science 2 (1987) 359-400. 59 </note>
Reference: [20] <author> A. Goel, A. Khaled, M. Donnellan, A. Gomez De Silva, and T. Callantine, </author> <title> Multistrategy Adaptive Navigational Path Planning, </title> <booktitle> IEEE Expert 9(6) (1994) 57-65. </booktitle>
Reference: [21] <author> J.J. Grefenstette and C.L. Ramsey, </author> <title> An Approach to Anytime Learning, </title> <editor> in: D. Sleeman and P. Edwards, eds., </editor> <booktitle> Machine Learning: Proceedings of the Ninth International Conference (Aberdeen, </booktitle> <address> Scotland, </address> <year> 1992) </year> <month> 189-195. </month>
Reference-contexts: However, while this approach is useful in the initial design 24 of the navigation system, it cannot change schema parameters on-line during navigation when the system faces environments that are significantly different from the environments used in the training phase of the genetic algorithm (but cf. <ref> [21] </ref>). Another approach to self-organizing adaptive control is that of Verschure, Krose, and Pfeifer ([61]), in which a neural network is used to learn how to associate conditional stimulus to unconditional responses.
Reference: [22] <author> K.J. Hammond, </author> <title> Case-Based Planning: Viewing Planning as a Memory Task. </title> <booktitle> Perspectives in Artificial Intelligence (Academic Press, </booktitle> <address> Boston, MA, </address> <year> 1989). </year>
Reference-contexts: However, in traditional case-based planning systems (e.g., <ref> [22] </ref>) learning and adaptation requires a detailed model of the domain. This is exactly what reactive planning systems are trying to avoid. <p> systems as well to determine whether a new experience is different enough to merit its own case or whether it should be used to modify the information represented in the best available case. 6.9 On-line real-time response Unlike traditional case-based reasoning systems which rely on deep reasoning and analysis (e.g., <ref> [22] </ref>), and unlike other machine learning augmentations to reactive control systems which fall back on non-reactive reasoning (e.g., [10]), our method allows the system to continue to perform reactively with very little performance overhead as compared to a "pure" reactive control system.
Reference: [23] <author> L. Kaelbling, </author> <title> Learning in Embedded Systems (MIT Press, </title> <address> Cambridge, MA, </address> <year> 1993). </year>
Reference: [24] <author> A. Kass, Tweaker: </author> <title> Adapting Old Explanations to New Situations. In R.C. </title> <editor> Schank, A. Kass, & C.K. Riesbeck, eds., </editor> <publisher> Inside Case-Based Explanation (Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1994) </year> <month> 263-295. </month>
Reference-contexts: In our application, collisions are undesirable, as is lack of movement; in other applications, any other suitable performance metric could be used instead. In traditional case-based reasoning systems, case adaptation is carried out using a rule-based system which utilizes a hand-coded set of adaptation rules (e.g., <ref> [24] </ref> but cf. [32]). SINS, in contrast, uses a kind of reinforcement learning method to provide the functionality necessary for case adaptation. The issues underlying the integration of multiple learning strategies into a single mul-tistrategy learning system is discussed in more detail in [48].
Reference: [25] <author> D. Kibler and P. Langley, P. </author> <year> 1988. </year> <title> Machine Learning as an Experimental Science, </title> <booktitle> in: Proceedings of the Third European Working Session on Learning, </booktitle> <address> Glasgow, UK, </address> <year> (1988) </year> <month> 81-92. </month>
Reference: [26] <author> J.L. Kolodner, R.L. Simpson, and K. Sycara, </author> <title> A Process Model of Case-Based Reasoning in Problem Solving, </title> <editor> in: A. Joshi, ed., </editor> <booktitle> Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <address> Los Angeles, CA, </address> <year> (1985) </year> <month> 284-290. </month>
Reference: [27] <author> J.L. </author> <title> Kolodner, </title> <publisher> Case-Based Reasoning (Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993). </year>
Reference-contexts: In traditional case-based reasoning terms (e.g., <ref> [27] </ref>), these steps correspond to situation assessment, case retrieval, adaptation, and learning, respectively; critiquing and evaluation are carried out by executing the behaviors suggested by the case (i.e., modifying the control parameters and carrying out the suggested movements) and observing the actual effects using sensory information. <p> Our current solution to this problem is to place an upper bound on the number of cases allowed in the system. A better solution would be to develop a method for organization of cases in memory; however, conventional memory organization schemes used in case-based reasoning systems (see <ref> [27] </ref>) assume structured, nominal information (e.g., [14]) rather than continuous, time-varying, analog information of the kind used in our cases. 57 Another open issue is that of the nature of the regularities captured in the sys-tem's cases. While SINS' cases do enhance its performance, they are not easy to interpret.
Reference: [28] <author> L. Kopeikina, E. Brandau, and A. Lemmon, </author> <title> Case-Based Reasoning for Continuous Control, </title> <booktitle> in: Proceedings of a Workshop on Case-Based Reasoning, </booktitle> <address> Clearwater Beach, FL, </address> <year> (1988) </year> <month> 250-259. </month>
Reference: [29] <author> B.J. Kuipers, </author> <title> A Qualitative Approach to Robot Exploration and Map Learning, </title> <booktitle> in: Proceedings of AAAI Workshop on Spatial Reasoning and Multi-Sensor Fusion, </booktitle> <address> St. Charles, IL, </address> <year> (1987) </year> <month> 390-404. </month>
Reference-contexts: As the robot navigates, it detects new landmarks and verifies its position within the map. Additionally, it selects behaviors that can take it from the current position to the next landmark on the map. However, this and other qualitative map learning approaches (e.g., <ref> [29] </ref>) rely on hand-coded knowledge about what 6 each behavior or combination of behaviors can achieve when activated using a particular priority scheme. This knowledge enables the robot to decide what modules to activate to accomplish some intermediary objective (e.g., get to the next landmark in the qualitative map).
Reference: [30] <author> B.J. Kuipers and Y-T. Byun, </author> <title> A Robust, Qualitative Method for Robot Spatial Learning, </title> <booktitle> in: Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <address> St. Paul, MN, </address> <year> (1988) </year> <month> 774-779. </month>
Reference: [31] <author> D. Langer, J.K. Rosenblatt, and M. Hebert, </author> <title> A Behavior-Based System For OffRoad Navigation, </title> <journal> IEEE Transactions in Robotics and Automation 10(6) (1994) 776-783. </journal>
Reference-contexts: subsumption, in which the response of some modules can supress or subsume the response of other modules (e.g., [9]); weighted summation, in which the final response is a weighted average of individual responses (e.g., [3]); or voting, in which the final response depends on how many modules propose it (e.g., <ref> [31] </ref>). One of the main difficulties of the reactive control approach for autonomous navigation is to decide which modules should be active and under what situations.
Reference: [32] <author> D.B. Leake, </author> <title> Learning Adaptation Strategies by Introspective Reasoning about Memory Search, </title> <booktitle> in: Proceedings of the AAAI-93 Workshop on Case-Based Reasoning (AAAI Press, </booktitle> <address> Menlo Park, CA, </address> <year> 1993) </year> <month> 57-63. </month>
Reference-contexts: In our application, collisions are undesirable, as is lack of movement; in other applications, any other suitable performance metric could be used instead. In traditional case-based reasoning systems, case adaptation is carried out using a rule-based system which utilizes a hand-coded set of adaptation rules (e.g., [24] but cf. <ref> [32] </ref>). SINS, in contrast, uses a kind of reinforcement learning method to provide the functionality necessary for case adaptation. The issues underlying the integration of multiple learning strategies into a single mul-tistrategy learning system is discussed in more detail in [48].
Reference: [33] <author> P. Maes, </author> <title> Situated Agents Can Have Goals, </title> <booktitle> Robotics and Autonomous Systems 6 (1990) 49-70. </booktitle>
Reference: [34] <author> P. Maes, and R.A. Brooks, </author> <title> Learning to Coordinate Behaviors, </title> <booktitle> in: Proceedings of the Eight National Conference on Artificial Intelligence 2 (MIT Press, </booktitle> <address> Cambridge, MA, </address> <year> 1990) </year> <month> 796-802. </month>
Reference: [35] <author> M.J. Mataric, </author> <title> Environment Learning Using a Distributed Representation, </title> <booktitle> in: Proceedings of the IEEE Conference on Robotics and Automation 4 (1990) 402-406. </booktitle>
Reference: [36] <author> D. McDermott, </author> <title> Planning and Acting, </title> <booktitle> Cognitive Science 2(2) (1978) 71-109. </booktitle>
Reference: [37] <author> S. Minton, </author> <title> Learning Effective Search Control Knowledge: An Explanation-Based Approach, </title> <type> Ph.D. thesis, </type> <institution> Carnegie-Mellon University, Computer Science Department, Pittsburgh, PA. </institution> <note> Technical Report CMU-CS-88-133 (1988). </note>
Reference: [38] <author> S. Minton, </author> <title> Quantitative Results Concerning the Utility of Explanation-Based Learning. </title> <booktitle> Artificial Intelligence 42 (1990) 363-391. </booktitle>
Reference: [39] <author> T.M. Mitchell, </author> <title> Becoming Increasingly Reactive, </title> <booktitle> in: Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> Boston, MA, </address> <year> (1990) </year> <month> 1051-1058. </month>
Reference-contexts: However, in traditional case-based planning systems (e.g., [22]) learning and adaptation requires a detailed model of the domain. This is exactly what reactive planning systems are trying to avoid. Earlier attempts to combine reactive control with classical planning systems (e.g., [10]) or explanation-based learning systems (e.g., <ref> [39] </ref>) also relied on deep reasoning and were typically too slow for the fast, reflexive behavior required in reactive control systems. Unlike these approaches, our method does not fall back on slow non-reactive techniques for improving reactive control.
Reference: [40] <author> K. Moorman and A. Ram, </author> <title> A Model of Creative Understanding, </title> <booktitle> Proceedings of the Twelfth National Conference on Artificial Intelligence 1, </booktitle> <address> Seattle, WA, </address> <year> (1994) </year> <month> 74-79. </month>
Reference-contexts: The continuous representations used in SINS permits arbitrarily fine-grained modifications (within the limits of the computer implementation), providing considerable power to the system. This assumption, too, could be relaxed if adequate algorithms for constructive concept creation, interpolation, and modification were to be developed (see, for example, <ref> [40] </ref>), but currently this ability of the SINS system is outside the scope of traditional "discrete" case-based reasoning systems. 6.3 Time-history representations Our methods represent a novel approach to case-based reasoning for a new kind of task, one that requires continuous, on-line performance.
Reference: [41] <author> J. Mostow and N. Bhatnagar, </author> <title> FAILSAFE|A Floor Planner that Uses EBG to Learn from its Failures, </title> <booktitle> in: Proceedings of the Tenth International Joint Conference on Artificial Intelligence (Milan, </booktitle> <address> Italy, </address> <year> 1987) </year> <month> 249-255. </month>
Reference: [42] <author> S. Pandya and S. Hutchinson, </author> <title> A Case-Based Approach to Robot Motion Planning, </title> <booktitle> in: Proceedings of the 1992 IEEE International Conference on Systems, Man, and Cybernetics 1, </booktitle> <address> Chicago, IL, </address> <year> (1992) </year> <month> 492-497. </month>
Reference: [43] <author> D. Payton, </author> <title> An Architecture for Reflexive Autonomous Vehicle Control, </title> <booktitle> in: Proceedings of the IEEE Conference on Robotics and Automation, </booktitle> <address> San Francisco, CA, </address> <year> (1986) </year> <month> 1838-1845. </month>
Reference: [44] <author> A. Ram, </author> <title> Creative Conceptual Change, </title> <booktitle> in: Proceedings of the Fifteenth Annual Conference of the Cognitive Science Society, </booktitle> <address> Boulder, CO (1993) 17-26. </address>
Reference: [45] <author> A. Ram, </author> <title> Indexing, Elaboration & Refinement: Incremental Learning of Explanatory Cases, </title> <note> Machine Learning 10 (1993) 201-248. </note>
Reference-contexts: These assumptions are also common to many traditional case-based reasoning systems (see, for example, the "typicality assumption" of <ref> [45] </ref>), although they are not always stated explicitly or in this exact manner. <p> This approach deviates from standard case-based reasoning where each case contains a previous experience or a generalization of a previous one and future similar experiences do not modify the content of a case (but cf. <ref> [45] </ref>). The notion of a virtual case might be useful in symbolic case-based reasoning systems as well. To take a simple example, AQUA learns about and updates existing cases based on new experiences ([45]).
Reference: [46] <author> A. Ram, R.C. Arkin, G. Boone, G. and M. Pearce, </author> <title> Using Genetic Algorithms to Learn Reactive Control Parameters for Autonomous Robotic Navigation, </title> <booktitle> Adaptive Behavior 2(3) (1994) 277-305. </booktitle>
Reference-contexts: Additionally, designers must determine an appropriate priority scheme for every foreseen situation, which is time-consuming and may require the use of an expert, although this process may be automated (e.g., finding optimal control parameters through the use of genetic algorithms as in <ref> [46] </ref>). A more robust approach is to provide the robot with only knowledge about which situations result from the execution of specific coordinations of motor schemas and then let the robot to learn the topology of situations in the terrain as it navigates.
Reference: [47] <author> A. Ram, R.C. Arkin, K. Moorman, and R.J. Clark, </author> <title> Case-Based Reactive Navigation: A Case-Based Method for On-Line Selection and Adaptation of Reactive Control Parameters in Autonomous Robotic Systems. </title> <type> Technical Report GIT-CC-92/57, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <address> Atlanta, GA (1992). </address> <month> 61 </month>
Reference-contexts: However, on-line selection and modification of the appropriate parameters based on the current environment can enhance navigational performance. We tested this idea by evaluating ACBARR qualitatively and quantitatively through extensive simulation studies using a variety of different environments and several different performance metrics (see <ref> [47] </ref>, for details). The experiments show that ACBARR is very robust, performing well in novel environments. Additionally, it is able to navigate through several "hard" environments, such as box canyons, in which traditional reactive systems would perform poorly. <p> Further details can be found in <ref> [47] </ref>. Two important requirements in ACBARR (and SINS) are the ability to manipulate continuous representations and the ability to perform continuously in real-time. <p> In this article, we have focussed on the case-based reasoning aspects of our work; robot control issues are discussed in <ref> [47] </ref> and [48]. Our research also contributes to and extends related work on behavior coordination. For example, in Mataric's ([35]) approach, the robot learns a topological map of landmarks in a terrain in order to use it for future planning.
Reference: [48] <author> A. Ram and J.C. Santamara, </author> <title> Multistrategy Learning in Reactive Control Systems for Autonomous Robotic Navigation, </title> <note> Informatica 17(4) (1993) 347-369. </note>
Reference-contexts: SINS, in contrast, uses a kind of reinforcement learning method to provide the functionality necessary for case adaptation. The issues underlying the integration of multiple learning strategies into a single mul-tistrategy learning system is discussed in more detail in <ref> [48] </ref>. <p> In this article, we have focussed on the case-based reasoning aspects of our work; robot control issues are discussed in [47] and <ref> [48] </ref>. Our research also contributes to and extends related work on behavior coordination. For example, in Mataric's ([35]) approach, the robot learns a topological map of landmarks in a terrain in order to use it for future planning.
Reference: [49] <editor> C.K. Riesbeck and R.C. Schank, </editor> <title> Inside Case-Based Reasoning, </title> <publisher> (Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ 1989). </address>
Reference: [50] <author> S.J. Rosenschein and L. Kaelbling, </author> <title> The Synthesis of Digital Machines with Provable Epistemic Properties, </title> <editor> in: J. Halpern, ed., </editor> <booktitle> Proceedings of the Conference on Theoretical Aspects of Reasoning About Knowledge, Monterrey, </booktitle> <address> CA (1993). </address>
Reference: [51] <author> E.D. Sacerdoti, </author> <title> A Structure for Plans and Behavior (Elsevier, </title> <address> New York, NY, </address> <year> 1977). </year>
Reference: [52] <author> J.C. Santamara and A. Ram, </author> <title> Systematic Evaluation of Design Decisions in Case-Based Reasoning Systems, </title> <booktitle> in: Proceedings of the AAAI-94 Workshop on Case-Based Reasoning, </booktitle> <address> Seattle, WA (1993) 23-29. </address>
Reference-contexts: Due to their nature, ablation studies can only deal with all-or-nothing resource allocation, disabling the possibility of deciding what would be the optimal amount of resources to allocate to each module. We used a systematic statistical evaluation methodology (proposed by <ref> [52] </ref>) to evaluate the performance of the SINS system. In this methodology, statistical tools are used to analyze the change in the performance of the system in 31 terms of changes in design decisions and domain (or problem) characteristics. <p> The second experiment allows us to study how different domain characteristics affect system's performance (i.e., the same system under different environments). Further details of the methodology are discussed in <ref> [52] </ref>. 5.3 Model construction As explained earlier, the performance of SINS is evaluated by estimating the median time to solve a world.
Reference: [53] <author> R.C. Schank, </author> <title> Dynamic Memory: A Theory of Learning in Computers and People (Cambridge University Press, </title> <address> New York, </address> <year> 1982). </year>
Reference: [54] <author> R.C. Schank, </author> <title> Explanation Patterns: </title> <publisher> Understanding Mechanically and Creatively (Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1986). </year>
Reference: [55] <author> A.M. Segre, </author> <title> Machine Learning of Robot Assembly Plans (Kluwer Academic, </title> <publisher> Norwell, </publisher> <address> MA, </address> <year> 1988). </year>
Reference: [56] <author> R.S. Sutton, </author> <title> Integrated Architectures for Learning, Planning, and Reacting based on Approximating Dynamic Programming, </title> <booktitle> in: Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <address> Austin, TX, </address> <year> (1990) </year> <month> 216-224. </month>
Reference: [57] <author> R.S. Sutton, A.G. Barto, and R.J. Williams, </author> <title> Reinforcement Learning in direct adaptive optimal control, </title> <booktitle> in: Proceedings of the American Control Conference, </booktitle> <address> Boston, MA, </address> <year> (1991) </year> <month> 2143-2146. </month>
Reference: [58] <author> R.S. Sutton, </author> <note> Special Issue on Reiforcement Learning, R.S., </note> <editor> Sutton, ed. </editor> <booktitle> Machine Learning, </booktitle> <month> 8(3/4) </month> <year> (1992). </year>
Reference-contexts: on a combination of ideas from case-based reasoning and learning, which deals with the issue of using past experiences to deal with and learn from novel situations, and from reinforcement learning, which deals with the issue of updating the content of system's knowledge based on feedback from the environment (see <ref> [58] </ref>). However, in traditional case-based planning systems (e.g., [22]) learning and adaptation requires a detailed model of the domain. This is exactly what reactive planning systems are trying to avoid.
Reference: [59] <institution> E.L. Thorndike, Animal Intelligence (Hafner Darien, CT, </institution> <year> 1911). </year>
Reference: [60] <author> M. Veloso and J.G. Carbonell, </author> <title> Derivational Analogy in PRODIGY: Automating Case Generation, Storage, </title> <note> and Retrieval, Machine Learning 10(3) (1993) 249-278. </note>
Reference: [61] <author> P.F.M.J. Verschure, B.J.A. Krose, R. Pfeifer, </author> <title> Distributed Adaptive Control: The Self-Organization of Structured Behavior, </title> <booktitle> Robotics and Autonomous Systems 9(3) (1992) 181-196. </booktitle>
Reference: [62] <author> C.J.C.H. Watkins, </author> <title> Learning from Delayed Rewards, </title> <type> Ph.D. thesis, </type> <institution> University of Cambridge, </institution> <address> England (1989). </address> <month> 62 </month>
References-found: 62

