URL: http://ftp.eecs.umich.edu/people/tyyeh/micro-93.bht-indexing.ps
Refering-URL: http://ftp.eecs.umich.edu/people/tyyeh/
Root-URL: http://www.eecs.umich.edu
Title: Branch History Table Indexing to Prevent Pipeline Bubbles in Wide-Issue Superscalar Processors  
Author: Tse-Yu Yeh and Yale N. Patt 
Address: Ann Arbor, Michigan 48109-2122  
Affiliation: Austin, Texas.  Department of Electrical Engineering and Computer Science The University of Michigan  
Date: December 1 3, 1993,  
Note: The 26th Annual International Symposium on Microarchitecture  
Abstract: Even with a very accurate dynamic branch predictor, a superscalar processor must predict instruction fetch addresses no later than the first pipeline stage to avoid suffering pipeline bubbles every time a branch is taken. Unfortunately, branch addresses generally are not known prior to instruction decode. Therefore, some indirect technique is required to identify a branch instruction and enable branch prediction while the branch instruction is being fetched. This is the branch identification problem. Intel Pentium adopts a scheme that solves this problem; however, its scheme assumes an issue rate of two instructions per cycle. An aggressive superscalar processor, issuing more than two instructions per cycle, cannot effectively use that scheme. In this paper, we propose and compare two viable schemes for solving the branch identification problem for wide-issue superscalar processors. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.V. Aho, R. Sethi, and J. Ullman, </author> <booktitle> "Compilers: Principles, Techniques, and Tools", </booktitle> <publisher> Addison Wesley, </publisher> <month> June </month> <year> 1987. </year>
Reference-contexts: Once a branch path prediction is made using a conditional branch predictor [7, 13], the predicted fetch address is chosen from the possible target addresses provided by the branch history table. Our proposed index schemes use the address of an instruction which dominates <ref> [1] </ref> a branch in the instruction flow as the identifying address of the branch. When an instruction fetch starting with a dominating instruction begins, the branch is identified and a prediction is made before the branch is actually decoded. <p> In a basic block, the flow of control enters at the beginning and leaves at the end without halt or possibility of branching except at the end <ref> [1] </ref>. Since the average basic block size is around four to five instructions in non-scientific programs, it is likely that one basic block is fetched and issued every cycle in wide-issue superscalar processors. <p> In order to make the prediction sufficiently early before the fetch of branch target instructions, a branch should be identified by the address of an instruction which dominates <ref> [1] </ref> the branch. An instruction dominates a branch if it is always executed prior to the branch whenever the branch is executed. The address of an instruction should be used to identify its first dominated branch; therefore, each address identifies a unique branch.
Reference: [2] <author> B. Bray and M. Flynn, </author> <title> "Strategies for Branch Target Buffers", </title> <booktitle> Proceedings of the 24th ACM/IEEE International Symposium and Workshop on Microarchitec-ture, </booktitle> <pages> pp. 42-50, </pages> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: Therefore, in this paper, we propose two viable branch history table index schemes for identifying branches and predicting fetch addresses prior to instruction decode in an aggressive wide-issue superscalar processor which can process up to one basic block each cycle. A branch history ta ble <ref> [2, 6, 8] </ref> is usually used by a branch predictor to store branch prediction information and provide target addresses.
Reference: [3] <author> M. Butler, T-Y Yeh, Y.N. Patt, M. Alsup, H. Scales, and M. Shebanow, </author> <title> "Instruction Level Parallelism is Greater Than Two", </title> <booktitle> Proceedings of the 18th International Symposium on Computer Architecture, </booktitle> <pages> pp. 276-286, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: 1 Introduction A superscalar processor fetches, issues, and executes multiple instructions each cycle to exploit instruction level parallelism available in programs <ref> [3, 4] </ref>. To achieve potential performance, such a processor must predict the next instruction fetch address no later than the first pipeline stage of a branch to avoid pipeline bubbles between instruction fetches.
Reference: [4] <author> P. Chang, S. Mahlke, W. Chen, N. Warter, and W. Hwu, </author> <title> "IMPACT: An Architectural Framework for Multiple-Instruction-Issue Processors", </title> <booktitle> Proceedings of the 18th International Symposium on Computer Architecture, </booktitle> <pages> pp. 266-275, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: 1 Introduction A superscalar processor fetches, issues, and executes multiple instructions each cycle to exploit instruction level parallelism available in programs <ref> [3, 4] </ref>. To achieve potential performance, such a processor must predict the next instruction fetch address no later than the first pipeline stage of a branch to avoid pipeline bubbles between instruction fetches.
Reference: [5] <author> Intel Corporation, </author> <title> "Pentium T M Processor User's Manual, </title> <booktitle> Volume 1, 2, and 3", </booktitle> <address> Mt. Prospect, Illinois, </address> <year> 1993. </year>
Reference-contexts: However, in a superscalar processor, it is difficult to choose the address to access the branch target buffer among several instructions fetched in the same cycle. Waiting until the instructions are decoded to decide the accessing address results in pipeline bubbles. Intel Pentium <ref> [5] </ref> makes predictions while branches are being fetched. In order to predict when a branch is being fetched, it accesses a branch target buffer (which we call the branch history table) with the address of the instruction in the first decode stage.
Reference: [6] <author> D. R. Kaeli and P. G. Emma, </author> <title> "Branch History Table Prediction of Moving Target Branches Due to Subroutine Returns", </title> <booktitle> Proceedings of the 18th International Symposium on Computer Architecture, </booktitle> <pages> pp. 34-42, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: To achieve potential performance, such a processor must predict the next instruction fetch address no later than the first pipeline stage of a branch to avoid pipeline bubbles between instruction fetches. In single-issue pipelined processors that use conventional branch target buffer designs [7] or branch history table designs <ref> [6, 8] </ref>, branches are identified by the branch addresses. As each instruction is fetched from memory, the instruction address is used to access the branch target buffer. If the branch target buffer is hit, it means that a branch is being fetched; therefore, the branch is predicted. <p> Therefore, in this paper, we propose two viable branch history table index schemes for identifying branches and predicting fetch addresses prior to instruction decode in an aggressive wide-issue superscalar processor which can process up to one basic block each cycle. A branch history ta ble <ref> [2, 6, 8] </ref> is usually used by a branch predictor to store branch prediction information and provide target addresses.
Reference: [7] <author> J. Lee and A. J. Smith, </author> <title> "Branch Prediction Strategies and Branch Target Buffer Design", </title> <booktitle> IEEE Computer, </booktitle> <pages> pp. 6-22, </pages> <month> Jan. </month> <year> 1984. </year>
Reference-contexts: To achieve potential performance, such a processor must predict the next instruction fetch address no later than the first pipeline stage of a branch to avoid pipeline bubbles between instruction fetches. In single-issue pipelined processors that use conventional branch target buffer designs <ref> [7] </ref> or branch history table designs [6, 8], branches are identified by the branch addresses. As each instruction is fetched from memory, the instruction address is used to access the branch target buffer. <p> Once a branch path prediction is made using a conditional branch predictor <ref> [7, 13] </ref>, the predicted fetch address is chosen from the possible target addresses provided by the branch history table. Our proposed index schemes use the address of an instruction which dominates [1] a branch in the instruction flow as the identifying address of the branch.
Reference: [8] <author> J. S. Liptay, </author> <title> "Design of the IBM Enterprise System/9000 High-End Processor", </title> <journal> IBM Journal of Research and Development, </journal> <volume> vol. 36, no. 4, </volume> <month> July </month> <year> 1992. </year>
Reference-contexts: To achieve potential performance, such a processor must predict the next instruction fetch address no later than the first pipeline stage of a branch to avoid pipeline bubbles between instruction fetches. In single-issue pipelined processors that use conventional branch target buffer designs [7] or branch history table designs <ref> [6, 8] </ref>, branches are identified by the branch addresses. As each instruction is fetched from memory, the instruction address is used to access the branch target buffer. If the branch target buffer is hit, it means that a branch is being fetched; therefore, the branch is predicted. <p> Therefore, in this paper, we propose two viable branch history table index schemes for identifying branches and predicting fetch addresses prior to instruction decode in an aggressive wide-issue superscalar processor which can process up to one basic block each cycle. A branch history ta ble <ref> [2, 6, 8] </ref> is usually used by a branch predictor to store branch prediction information and provide target addresses.
Reference: [9] <author> Motorola Inc., </author> <title> "M88100 User's Manual", </title> <address> Phoenix, Arizona, March 13, </address> <year> 1989. </year>
Reference-contexts: The source C code of the function is shown in Figure 2. Its translated Motorola 88100 assembly code <ref> [9] </ref> and assigned instruction addresses are shown in Figure 3.
Reference: [10] <author> J.E. Smith, </author> <title> "A Study of Branch Prediction Strategies", </title> <booktitle> Proceedings of the 8th International Symposium on Computer Architecture, </booktitle> <pages> pp. 135-148, </pages> <month> May. </month> <year> 1981. </year>
Reference-contexts: Since there are more taken branches than not-taken branches, when a program starts execution, the value of each counter is initialized to 2, which causes the initial prediction to be taken. * When the BHT is missed, since there is no branch history available, the backward taken, forward not-taken scheme <ref> [10] </ref> is used. * I-cache hit rate is assumed to be 100 percent to eliminate the effect of I-cache capacity, but the line size is considered in the instruction fetch. We used another trace-driven simulator to derive the ideal IPC f of each trace, given function unit constraints.
Reference: [11] <author> T-Y Yeh and Y.N. </author> <title> Patt "Alternative Implementations of Two-Level Adaptive Branch Prediction," </title> <booktitle> Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <pages> pp. 124-134, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: When a BHT entry is newly allocated for a branch, the branch history in the BHT entry is initialized to all 1's. A complete description of P As (6; 16) and related branch pre- dictors is available in <ref> [11, 13] </ref>. * Two-bit up-down saturating counters are used by default in all pattern history table entries for keeping the second-level pattern history of the conditional branch predictor P As (6; 16).
Reference: [12] <author> T-Y Yeh and Y.N. </author> <title> Patt "A Comprehensive Instruction Fetch Mechanism for a Processor Supporting Speculative Execution," </title> <booktitle> Proceedings of the 25th Annual ACM/IEEE International Symposium on Computer Microarchitecture, </booktitle> <pages> pp. 129-139, </pages> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: A branch history ta ble [2, 6, 8] is usually used by a branch predictor to store branch prediction information and provide target addresses. In <ref> [12] </ref>, we proposed storing the possible target addresses (fall-through and taken addresses for a conditional branch and taken address for an unconditional branch), branch type, and when necessary, the history of branches in the branch history table for branch predictions in superscalar processors. <p> Since most branches cannot be resolved as soon as they are fetched and a delay between instruction fetches is not desirable, we prefetch and execute the subsequent instructions speculatively, using a branch prediction mechanism <ref> [12] </ref>. The branch prediction mechanism must be able to make predictions every cycle if we are to sustain an issue rate of one basic block every cycle. An instruction fetch mechanism was proposed in [12] to predict the instruction fetch addresses with high accuracy and to achieve no delay between instruction <p> is not desirable, we prefetch and execute the subsequent instructions speculatively, using a branch prediction mechanism <ref> [12] </ref>. The branch prediction mechanism must be able to make predictions every cycle if we are to sustain an issue rate of one basic block every cycle. An instruction fetch mechanism was proposed in [12] to predict the instruction fetch addresses with high accuracy and to achieve no delay between instruction fetches. We summarize a few details of the mechanism (shown in Figure 1) in this section. <p> The IPC f is a performance metric for the instruction fetch mechanism which measures the average number of legitimate instructions fetched and issued per cycle assuming the ideal performance from all parts of the processor other than the instruction supply <ref> [12] </ref> and no data dependency between instructions. Legitimate instructions do not include the instructions fetched down the incorrectly-predicted path, but the machine cycles wasted in fetching those instructions are counted. Since the same number of instructions are simulated, a higher IPC f number indicates better machine performance.
Reference: [13] <author> T-Y Yeh and Y.N. </author> <title> Patt "A Comparison of Dynamic Branch Predictors that use Two Levels of Branch History," </title> <booktitle> Proceedings of the 20th International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Once a branch path prediction is made using a conditional branch predictor <ref> [7, 13] </ref>, the predicted fetch address is chosen from the possible target addresses provided by the branch history table. Our proposed index schemes use the address of an instruction which dominates [1] a branch in the instruction flow as the identifying address of the branch. <p> The replacement algorithm is Least Recently Used (LRU). The BHT is used for all types of branch instructions, including conditional branches, unconditional branches, and re turns. * For the conditional branch predictor, we simulate a P As (6; 16) which is a Per-address History Two-Level Adaptive branch predictor <ref> [13] </ref>. The P As (6; 16) uses the branch history stored in the BHT to make branch predictions, so the performance of the BHT has a significant effect on its prediction accuracy. <p> When a BHT entry is newly allocated for a branch, the branch history in the BHT entry is initialized to all 1's. A complete description of P As (6; 16) and related branch pre- dictors is available in <ref> [11, 13] </ref>. * Two-bit up-down saturating counters are used by default in all pattern history table entries for keeping the second-level pattern history of the conditional branch predictor P As (6; 16).
Reference: [14] <author> T-Y Yeh, D. Marr, and Y.N. </author> <title> Patt "Increasing Instruction Fetch Rate via Multiple Branch Predictions and a Branch Address Cache," </title> <booktitle> Proceedings of the 7th ACM International Conference on Supercomputing, </booktitle> <pages> pp. 67-76, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Another option is to fetch two sequential cache lines at a time; however, this requires modifications to the above index schemes. When basic blocks are small, fetching multiple basic blocks <ref> [14] </ref> is needed to supply enough instructions. When multiple basic blocks are fetched, the proposed branch history table index schemes can still be used.
References-found: 14

