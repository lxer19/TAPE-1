URL: http://www.cs.ubc.ca/spider/pope/WOR96-Paper.ps.gz
Refering-URL: http://www.cs.ubc.ca/spider/pope/WOR96-Paper.html
Root-URL: 
Phone: 2  
Title: Learning Appearance Models for Object Recognition  
Author: Arthur R. Pope and David G. Lowe David 
Address: CN 5300, Princeton, NJ 08543-5300  Vancouver, B.C., Canada V6T 1Z4  
Affiliation: Sarnoff Research Center,  Dept. of Computer Science, University of British Columbia,  
Abstract: We describe how to model the appearance of an object using multiple views, learn such a model from training images, and recognize objects with it. The model uses probability distributions to characterize the significance, position, and intrinsic measurements of various discrete features of appearance; it also describes topological relations among features. The features and their distributions are learned from training images depicting the modeled object. A matching procedure, combining qualities of both alignment and graph subisomorphism methods, uses feature uncertainty information recorded by the model to guide the search for a match between model and image. Experiments show the method capable of learning to recognize complex objects in cluttered images, acquiring models that represent those objects using relatively few views.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> N. Ayache, </author> <title> O.D. Faugeras. HYPER: A new approach for the recognition and posi tioning of two-dimensional objects. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell. </journal> <volume> PAMI-8:44-54, </volume> <year> 1986. </year>
Reference-contexts: Learning a multiple-view model from training images requires a clustering of the training images and a generalization of each cluster's contents. 2 Related Research 2.1 Use of Uncertainty Information in Matching Iterative alignment has been used with a Kalman filter to estimate transformations from feature pairings in both 2D-2D matching <ref> [1] </ref> and 2D-3D matching [12]. Besides being efficient, this allows feature position uncertainty to determine transformation uncertainty, which in turn is useful in predicting feature positions in order to rate additional feature pairings [12]. <p> 4 0 1 y k x k 0 0 v k u k 7 5 6 4 y t v t 7 5 = A k b t and 3 There is an analogous formulation using affine transformations with advantages only in modeling 3D planar objects. 4 Ayache and Faugeras <ref> [1] </ref>, among others, have also used this formulation to express the transformation as a linear operation. 6 2 6 u t v t 0 0 0 0 u t v t 3 7 2 6 x k u k 3 7 2 6 x t 0 3 7 3.3 Match Quality
Reference: 2. <author> J.S. Beis, D.G. Lowe. </author> <title> Learning indexing functions for 3-D model-based object recognition. </title> <booktitle> In Proc. Conf. Computer Vision and Patt. Recognit., </booktitle> <pages> 275-280, </pages> <year> 1994. </year>
Reference-contexts: Recognition combines the matching procedure with an indexing procedure for selecting likely model views from a model database, and a verification procedure for deciding whether a match presents sufficient evidence that an object is present. Suitable indexing and verification methods have been described elsewhere (e.g., <ref> [2, 19] </ref>), and will not be discussed here. A more complete description of the entire approach may be found in [16]. 3.1 Image and Model Representations An image is represented by a graph with nodes denoting features and arcs denoting abstraction and composition relations among them.
Reference: 3. <author> G.J. Bierman. </author> <title> Factorization Methods for Discrete Sequential Estimation. </title> <publisher> Academic Press, </publisher> <year> 1977. </year>
Reference-contexts: A recursive estimator solves the system, efficiently updating the transformation estimate as pairings are adopted. We use the square root information filter (SRIF) <ref> [3] </ref> form of the Kalman filter for its numerical stability, and its efficiency with batched measurements. The SRIF works by updating the square root of the information matrix, which is the inverse of the estimate's covariance matrix.
Reference: 4. <author> T.M. Breuel. </author> <title> Fast recognition using adaptive subdivisions of transformation space. </title> <booktitle> In Proc. Conf. Computer Vision and Patt. Recognit., </booktitle> <pages> 445-451, </pages> <year> 1992. </year>
Reference-contexts: By combining these two approaches, we gain advantages from employing all constraints. Recognition methods that search transformation space by accumulating votes may use feature uncertainty to weight votes (e.g., [17], although they assume the same uncertainty for all features). Methods that avoid tesselating the space <ref> [4, 7] </ref> have required the use of bounded error models of feature uncertainty to achieve their high efficiency. However, in our situation, where models are learned from positive training examples only, there is no way to determine error bounds; we use Gaussian error models instead.
Reference: 5. <author> J.B. Burns, </author> <title> E.M. Riseman. Matching complex images to multiple 3D objects using view description networks. </title> <booktitle> In Proc. Conf. Computer Vision and Patt. Recognit., </booktitle> <pages> 328-334, </pages> <year> 1992. </year>
Reference-contexts: In view description networks <ref> [5] </ref>, attribute distributions are determined by regularly sampling idealized features. Whereas graph matching enforces topological and geometric relations among groups of features|e.g., ensuring that model line segments sharing a common junction are paired with image line segments sharing a similar junction| alignment enforces the viewpoint consistency constraint [13].
Reference: 6. <author> O.I. Camps, L.G. Shapiro, </author> <title> R.M. Haralick. Object recognition using prediction and probabilistic matching. </title> <booktitle> In Proc. of the IEEE/RSJ Int. Conf. on Intell. Robots and Systems, </booktitle> <pages> 1044-1052, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Most have chosen to represent image feature uncertainty; we have chosen to emphasize model feature uncertainty, which in our case carries the most useful information. Some recognition methods are based on matching attributed graphs in which nodes and arcs represent features and their relations, and attributes record measurements. premio <ref> [6] </ref> uses Gaussian distributions characterizing the expected number of feature and relation matches, and the expected deviation of attributes from their norms, to define a graph similarity measure that guides a fast, heuristic search for matches; all features of one model view, however, share common distributions.
Reference: 7. <author> T.A. Cass. </author> <title> Polynomial-time object recognition in the presence of clutter, occlusion, and uncertainty. </title> <booktitle> In Proc. European Conf. on Computer Vision, </booktitle> <pages> 834-842, </pages> <year> 1992. </year>
Reference-contexts: By combining these two approaches, we gain advantages from employing all constraints. Recognition methods that search transformation space by accumulating votes may use feature uncertainty to weight votes (e.g., [17], although they assume the same uncertainty for all features). Methods that avoid tesselating the space <ref> [4, 7] </ref> have required the use of bounded error models of feature uncertainty to achieve their high efficiency. However, in our situation, where models are learned from positive training examples only, there is no way to determine error bounds; we use Gaussian error models instead.
Reference: 8. <author> C.H. Chen, P.G. Mulgaonkar. </author> <title> Automatic vision programming. CVGIP: </title> <booktitle> Image Un derstanding 55 </booktitle> <pages> 170-183, </pages> <year> 1992. </year>
Reference-contexts: Systems adopting this approach generally assume that all features of a model view have the same likelihood of being detected and the same positional uncertainty, perhaps because better models are difficult to obtain <ref> [8, p. 182] </ref>. Clearly, though, features differ in incidence, localization accuracy, and stability. A system that learns models from example images can directly measure these differences. This paper describes how to represent feature uncertainty in a multiple-view model, learn such models from training images, and recognize objects with them.
Reference: 9. <author> J.H. Connell, M. Brady. </author> <title> Generating and generalizing models of visual objects. </title> <journal> Artificial Intell. </journal> <volume> 31 </volume> <pages> 159-183, </pages> <year> 1987. </year>
Reference-contexts: However, applications of this approach have used global appearance representations, such as entire images, and thus they have not supported recognition of occluded objects. Connell and Brady <ref> [9] </ref> have described a system that learns an appearance model of a 2-D object (or one view of a 3-D object), using structures of localized features. The system incorporates many interesting ideas.
Reference: 10. <author> D.H. Fisher. </author> <title> Knowledge acquisition via incremental conceptual clustering. </title> <booktitle> Machine Learning 2 </booktitle> <pages> 139-172, </pages> <year> 1987. </year>
Reference-contexts: Clustering Training Images. An incremental conceptual clustering algorithm is used to create clusters among the training images. Clustering is incremental in that, as each training image is acquired, it is assigned to an existing cluster or used to form a new one. Like other conceptual clustering algorithms (e.g., cobweb <ref> [10] </ref>), the algorithm uses a global measure of overall clustering quality to guide clustering decisions. This measure is chosen to promote and balance two somewhat-conflicting qualities.
Reference: 11. <author> P. Gros. </author> <title> Matching and clustering: Two steps towards automatic object model gen eration in computer vision. </title> <booktitle> In Proc. AAAI Fall Symp.: Machine Learning in Computer Vision, </booktitle> <publisher> AAAI Press, </publisher> <year> 1993. </year>
Reference-contexts: Learning a multiple-view model from real images requires some means of comparing and clustering appearances. Although several researchers have clustered images rendered from CAD models and thus avoided the feature correspondence problem, only a few have clustered real images. Among them, Gros <ref> [11] </ref> measures the similarity of an image pair as the proportion of matching shape features, whereas Seibert and Waxman [20] use a vector clustering algorithm with fixed-length vectors encoding global appearance.
Reference: 12. <author> Y. Hel-Or, M. Werman. </author> <title> Pose estimation by fusing noisy data of different dimen sions. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell. </journal> <volume> 17 </volume> <pages> 195-201, </pages> <year> 1995. </year>
Reference-contexts: from training images requires a clustering of the training images and a generalization of each cluster's contents. 2 Related Research 2.1 Use of Uncertainty Information in Matching Iterative alignment has been used with a Kalman filter to estimate transformations from feature pairings in both 2D-2D matching [1] and 2D-3D matching <ref> [12] </ref>. Besides being efficient, this allows feature position uncertainty to determine transformation uncertainty, which in turn is useful in predicting feature positions in order to rate additional feature pairings [12]. <p> has been used with a Kalman filter to estimate transformations from feature pairings in both 2D-2D matching [1] and 2D-3D matching <ref> [12] </ref>. Besides being efficient, this allows feature position uncertainty to determine transformation uncertainty, which in turn is useful in predicting feature positions in order to rate additional feature pairings [12]. However, this (partial) least-squares approach can only represent uncertainty in either image or model 3 features, not both; total least squares can represent both, but may not be accurate in predicting feature positions from the estimated transformation [22, p. 5].
Reference: 13. <author> D.G. Lowe. </author> <title> The viewpoint consistency constraint. </title> <booktitle> Int. J. Computer Vision 1:57 72, </booktitle> <year> 1987. </year>
Reference-contexts: Whereas graph matching enforces topological and geometric relations among groups of features|e.g., ensuring that model line segments sharing a common junction are paired with image line segments sharing a similar junction| alignment enforces the viewpoint consistency constraint <ref> [13] </ref>. By combining these two approaches, we gain advantages from employing all constraints. Recognition methods that search transformation space by accumulating votes may use feature uncertainty to weight votes (e.g., [17], although they assume the same uncertainty for all features).
Reference: 14. <author> H. Murase, S.K. Nayar. </author> <title> Learning and recognition of 3-D objects from brightness images. </title> <booktitle> In Proc. AAAI Fall Symp.: Machine Learning in Computer Vision, </booktitle> <pages> 25-29, </pages> <publisher> AAAI Press, </publisher> <year> 1993. </year>
Reference-contexts: supports this choice, at least for some features. 2.2 Learning Appearance Models Some approaches model an object as a subspace within a large space of possible appearances, and use principal components analysis to obtain a concise description of the particular subspace occupied by a given set of training examples (e.g., <ref> [21, 14] </ref>). However, applications of this approach have used global appearance representations, such as entire images, and thus they have not supported recognition of occluded objects.
Reference: 15. <author> A.R. Pope, D.G. Lowe. </author> <title> Learning object recognition models from images. </title> <booktitle> In Proc. Int. Conf. Computer Vision, </booktitle> <pages> 296-301, </pages> <year> 1993. </year> <month> 18 </month>
Reference-contexts: One component of this measure estimates the probability that two features match given their respective position distributions and an aligning transformation; it is described in 3.4; other components have been described previously <ref> [15] </ref>. The method of estimating a transformation from feature pairings is described in 3.6. A matching procedure, described in 3.5, uses the match quality measure and transformation estimator to match model features with image features. <p> We seek a match that maximizes both the number of features paired and the similarity of paired features. Our match quality measure quantifying these goals extends that reported in <ref> [15] </ref> to include an evaluation of how well the transformation aligns features. Pairings are represented by E = he 1 ; e 2 ; : : :i, where e j = k if model feature j matches image feature k, and e j =? if it matches nothing. <p> P ( ~ a j = a k ) is estimated using the series of attribute vectors A j recorded with model feature j, and a non-parametric density estimator described in <ref> [15] </ref>.
Reference: 16. <author> A.R. Pope. </author> <title> Learning to Recognize Objects in Images: Acquiring and Using Prob abilistic Models of Appearance. </title> <type> Ph.D. thesis, </type> <institution> Univ. of British Columbia, </institution> <year> 1995. </year> <note> WWW http://www.cs.ubc.ca/spider/pope/Thesis.html. </note>
Reference-contexts: Suitable indexing and verification methods have been described elsewhere (e.g., [2, 19]), and will not be discussed here. A more complete description of the entire approach may be found in <ref> [16] </ref>. 3.1 Image and Model Representations An image is represented by a graph with nodes denoting features and arcs denoting abstraction and composition relations among them.
Reference: 17. <author> I. Rigoutsos, R. Hummel. </author> <title> Distributed Bayesian object recognition. </title> <booktitle> In Proc. Conf. Computer Vision and Patt. Recognit., </booktitle> <pages> 180-186, </pages> <year> 1993. </year>
Reference-contexts: By combining these two approaches, we gain advantages from employing all constraints. Recognition methods that search transformation space by accumulating votes may use feature uncertainty to weight votes (e.g., <ref> [17] </ref>, although they assume the same uncertainty for all features). Methods that avoid tesselating the space [4, 7] have required the use of bounded error models of feature uncertainty to achieve their high efficiency.
Reference: 18. <author> J. Rissanen. </author> <title> A universal prior for integers and estimation by minimum description length. </title> <journal> Annals of Statistics 11 </journal> <pages> 416-431, </pages> <year> 1983. </year>
Reference-contexts: This measure is chosen to promote and balance two somewhat-conflicting qualities. On one hand, it favors clusterings that result in simple, concise, and efficient models, while on the other hand, it favors clusterings whose resulting model graphs accurately characterize (or match) the training images. The minimum description length principle <ref> [18] </ref> is used to quantify and balance these two qualities. The principle suggests that the learning procedure choose a model that minimizes the number of symbols needed to encode first the model and then the training images.
Reference: 19. <author> K.B. Sarachik, W.E.L. </author> <title> Grimson. Gaussian error models for object recognition. </title> <booktitle> In Proc. Conf. Computer Vision and Patt. Recognit., </booktitle> <pages> 400-406, </pages> <year> 1993. </year>
Reference-contexts: Recognition combines the matching procedure with an indexing procedure for selecting likely model views from a model database, and a verification procedure for deciding whether a match presents sufficient evidence that an object is present. Suitable indexing and verification methods have been described elsewhere (e.g., <ref> [2, 19] </ref>), and will not be discussed here. A more complete description of the entire approach may be found in [16]. 3.1 Image and Model Representations An image is represented by a graph with nodes denoting features and arcs denoting abstraction and composition relations among them.
Reference: 20. <author> M. Seibert, A.M. Waxman. </author> <title> Adaptive 3-D object recognition from multiple views. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell. </journal> <volume> 14 </volume> <pages> 107-124, </pages> <year> 1992. </year>
Reference-contexts: Although several researchers have clustered images rendered from CAD models and thus avoided the feature correspondence problem, only a few have clustered real images. Among them, Gros [11] measures the similarity of an image pair as the proportion of matching shape features, whereas Seibert and Waxman <ref> [20] </ref> use a vector clustering algorithm with fixed-length vectors encoding global appearance.
Reference: 21. <author> M.A. Turk, </author> <title> A.P. Pentland. Face recognition using eigenfaces. </title> <booktitle> In Proc. Conf. Com puter Vision and Patt. Recognit., </booktitle> <pages> 586-591, </pages> <year> 1991. </year>
Reference-contexts: supports this choice, at least for some features. 2.2 Learning Appearance Models Some approaches model an object as a subspace within a large space of possible appearances, and use principal components analysis to obtain a concise description of the particular subspace occupied by a given set of training examples (e.g., <ref> [21, 14] </ref>). However, applications of this approach have used global appearance representations, such as entire images, and thus they have not supported recognition of occluded objects.
Reference: 22. <author> S. van Huffel, J. Vandewalle. </author> <title> The Total Least Squares Problem: Computational Aspects and Analysis. </title> <publisher> SIAM, </publisher> <year> 1991. </year>
Reference-contexts: However, this (partial) least-squares approach can only represent uncertainty in either image or model 3 features, not both; total least squares can represent both, but may not be accurate in predicting feature positions from the estimated transformation <ref> [22, p. 5] </ref>. Most have chosen to represent image feature uncertainty; we have chosen to emphasize model feature uncertainty, which in our case carries the most useful information.
Reference: 23. <author> W.M. Wells III. </author> <title> Statistical Object Recognition. </title> <type> Ph.D. thesis, </type> <institution> MIT, </institution> <year> 1992. </year> <title> This article was processed using the L A T E X macro package with LLNCS style 19 Fig. 7. Other examples of objects the system has learned to recognize. Left: One element drawn from each object's set of training images. Right: Recognition of the objects in test images. </title>
Reference-contexts: However, in our situation, where models are learned from positive training examples only, there is no way to determine error bounds; we use Gaussian error models instead. Empirical evidence <ref> [23, ch. 3] </ref> supports this choice, at least for some features. 2.2 Learning Appearance Models Some approaches model an object as a subspace within a large space of possible appearances, and use principal components analysis to obtain a concise description of the particular subspace occupied by a given set of training
References-found: 23

