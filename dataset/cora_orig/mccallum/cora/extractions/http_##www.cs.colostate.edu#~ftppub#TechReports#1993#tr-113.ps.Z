URL: http://www.cs.colostate.edu/~ftppub/TechReports/1993/tr-113.ps.Z
Refering-URL: http://www.cs.colostate.edu/~ftppub/
Root-URL: 
Affiliation: Department of Computer Science Colorado State University  
Abstract: Empirical Estimation of Fault Exposure Ratio Naixin Li and Yashwant K. Malaiya Technical Report CS-93-113 August 20, 1993 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. D. Musa, A. Iannino, K. Okumoto, </author> <title> Software Reliability Measurement, Prediction, Applications, </title> <publisher> McGraw-Hill, </publisher> <year> 1987. </year>
Reference-contexts: The data collected by Musa <ref> [1] </ref> shows that the number of additional faults introduced during the debugging process is only about 5%. Thus fi E 0 may be estimated as the initial number of faults. <p> Once we know the value of K, fi E 1 can be estimated using, fi E K (2) where T L is the linear execution time <ref> [1] </ref>, given by T L = I s Q r 1 r ; I s is the number of source lines of code; Q r is the average object instructions per source statement; r is the testing CPU instruction rate. Musa et al [1] have speculated that K may depend on <p> T L is the linear execution time <ref> [1] </ref>, given by T L = I s Q r 1 r ; I s is the number of source lines of code; Q r is the average object instructions per source statement; r is the testing CPU instruction rate. Musa et al [1] have speculated that K may depend on program structure in some way. However, they suspected that for large programs, the "structuredness" (as measured by 2 decision density) may average out and thus may not vary much with program size [1]. <p> Musa et al <ref> [1] </ref> have speculated that K may depend on program structure in some way. However, they suspected that for large programs, the "structuredness" (as measured by 2 decision density) may average out and thus may not vary much with program size [1]. Musa has also argued that K should be independent of program size [2]. von Mayrhauser and Teresinki [11] have suggested that K may depend on static metrics like "loopiness" and "branchiness" of the program. However, because of lack of sufficient data, the results are not yet conclusive [12]. <p> However, because of lack of sufficient data, the results are not yet conclusive [12]. The logarithmic model, which is characterized by Equation 3 and Equation 4, has been empirically shown to be superior in general than other software reliability models by several researchers <ref> [14, 1, 6] </ref>. Malaiya et al [6] have shown using a number of diverse data sets that the superiority of the logarithmic model is statistically significant. (t) = fi L 1 t) (3) fi L 1 1 t where (t) is the failure intensity at time t. <p> Trachtenberg [15] proposed a software reliability model based on Zipf's law which fitted Adam's reliability data with an very high correlation coefficient. If we regard the testing phase as a compressed form of operational use <ref> [1] </ref>, then the failure rates during testing phase may also have similar distribution across software projects. <p> However, for the exponential model assumes that K does not change over time. Therefore, the overall value of K can be used for the exponential model as a constant. Table 1, obtained using <ref> [1] </ref>, relates initial defect density and overall fault exposure ratio. Here 10% of the total initial defects are assumed to be present by the end of testing phase. In Musa et al [1], the values of K were computed assuming the exponential model. <p> Table 1, obtained using <ref> [1] </ref>, relates initial defect density and overall fault exposure ratio. Here 10% of the total initial defects are assumed to be present by the end of testing phase. In Musa et al [1], the values of K were computed assuming the exponential model. <p> The value of D 0 has been used in our regression. 8 Table 1: K vs. D 0 <ref> [1] </ref> (K in units of 10 7 ) Data D 0 ^ D K T20 21.17 8.2563 6.5 T1 6.96 2.71 1.87 T3 1.8 0.7 4.11 T19 0.68 0.27 4.54 T16 0.36 0.14 3.03 Applying linear regression analysis to Equation 22 with the data shown in Table 1, we got the <p> Using the above value of ff 0 and ff 1 , we estimate the average value K to be in the range of [1.89..7.24], which is close to the range envisioned by Musa <ref> [1] </ref>. If more failure data are available, the value of ff 0 and ff 1 can be determined more exactly. It should be noted that the defect density shown in Table 1 was calculated using the object instruction count.
Reference: [2] <author> J. D. Musa, </author> <title> Rationale for Fault Exposure Ratio K, </title> <journal> ACM SIGSOFT Software Engineering News, </journal> <month> July </month> <year> 1991, </year> <pages> pp. 79. 12 </pages>
Reference-contexts: However, they suspected that for large programs, the "structuredness" (as measured by 2 decision density) may average out and thus may not vary much with program size [1]. Musa has also argued that K should be independent of program size <ref> [2] </ref>. von Mayrhauser and Teresinki [11] have suggested that K may depend on static metrics like "loopiness" and "branchiness" of the program. However, because of lack of sufficient data, the results are not yet conclusive [12].
Reference: [3] <author> Y. K. Malaiya, A. von Mayrhauser and P. K. Srimani, </author> <title> The Nature of Fault Exposure Ratio, </title> <booktitle> Proc. International Symposium on Software Reliability Engineering, </booktitle> <month> October </month> <year> 1992, </year> <pages> pp. 23-32. </pages>
Reference-contexts: Malaiya et al [6] have shown using a number of diverse data sets that the superiority of the logarithmic model is statistically significant. (t) = fi L 1 t) (3) fi L 1 1 t where (t) is the failure intensity at time t. In paper <ref> [3] </ref> the parameter fi L 0 was related to initial fault exposure ratio K 0 and fi L 1 . <p> Therefore it will be easier and probably more accurate to use at the early phase of testing. The detectability of a fault is defined as the probability that the fault is detected by a randomly selected test input <ref> [3] </ref>. For truly random testing, faults with high detectability tends to be detected earlier in time, so K should in general decline with time [3]. However experiments with real reliability data indicates a reversal of this trend at low defect density areas. <p> The detectability of a fault is defined as the probability that the fault is detected by a randomly selected test input <ref> [3] </ref>. For truly random testing, faults with high detectability tends to be detected earlier in time, so K should in general decline with time [3]. However experiments with real reliability data indicates a reversal of this trend at low defect density areas. An explanation provided for this phenomenon was that at the late stage of testing phase testing becomes more and more directed. <p> K (t) = N (t)(1 + at) where N (t) is the number of faults present at time t; g = K 0 N (0); a is a parameter depending on the "detectability profile" of the software <ref> [3] </ref>. From this model we can derive the well-known logarithmic software reliability growth model with the following interpretation for the parameters: fi L K 0 N 0 (9) 1 = a (10) A study of the factors affecting K is of considerable significance. <p> Then we will apply this relation to a set of real data and see how well it fits the real behavior of software systems. 4 2 Variation of K with Fault Density <ref> [3] </ref> derives an expression for K in term of testing time. Here we will obtain an expression for K in term of the fault density D. <p> logarithm on both sides of Equation 4, we get ln ((t)) = ln (fi L 1 ) ln (1 + fi L Using Equation 3 ln ((t)) = ln (fi L 1 ) fi L (t) (12) On the other hand, by definition, D (t) = I s and from <ref> [3] </ref>, dN (t) = T L Applying the following equation, (t) = dt to Equation 14, we can obtain, K (t) = T L N (t) Thus we have the following, ln (K (t)D (t)) = ln (T L N (t) I s (t) ) = ln ( 1 I s <p> 1 D (22) where the parameters ff 0 and ff 1 are given by, ff 0 = 0 fi L r N 0 ff 1 = fi L (24) This allow us to write K as, K = D Equation 25 can also be derived from Equation 8 proposed in <ref> [3] </ref>. To validate the above assumption about K and D, the example from [3] is used here. <p> by, ff 0 = 0 fi L r N 0 ff 1 = fi L (24) This allow us to write K as, K = D Equation 25 can also be derived from Equation 8 proposed in <ref> [3] </ref>. To validate the above assumption about K and D, the example from [3] is used here. We assume that a debugging process for a system with N 0 = 200 is exactly described by a logarithmic model with fi L 0 = 60 and fi L 1 = 1, we can calculate the values of K at different densities. <p> If we regard the testing phase as a compressed form of operational use [1], then the failure rates during testing phase may also have similar distribution across software projects. Further we suspect that at the beginning of system testing phase, the detectability profiles <ref> [3] </ref> of software projects may have similar shapes in accordance with the Zipf's law. 6 If the testing activity is conducted in the same way, K would be primarily determined by the detectability profile. <p> In case of truely random testing, K would be an weighted average of the detectability of each individual fault <ref> [3] </ref>. We can assume that for a software system, the initial fault exposure ratio K 0 is determined mainly by the initial defect density D 0 .
Reference: [4] <author> Y. K. Malaiya, </author> <title> Early Characterization of the Defect Removal Process, </title> <booktitle> Proc. 9th Annual Software Reliability Symposium, </booktitle> <month> May </month> <year> 1991, </year> <pages> pp. </pages> <month> 6.1-6.4. </month>
Reference: [5] <author> Y. K. Malaiya, A. von Mayrhauser and P.K.Srimani, </author> <title> The Constant Per Fault Hazard Rate Assumption, </title> <booktitle> Proc. 2nd Bellcore/Purdue Workshop on Issues in Software Reliability Estimation, </booktitle> <month> October, </month> <year> 1992, </year> <pages> pp. 1-9. </pages>
Reference: [6] <author> Y. K. Malaiya, N. Karunanithi and P. Verma, </author> <title> Predictability of Software Reliability Models, </title> <journal> IEEE Trans. Reliability, </journal> <month> December </month> <year> 1992, </year> <pages> pp. 539-546. </pages>
Reference-contexts: However, because of lack of sufficient data, the results are not yet conclusive [12]. The logarithmic model, which is characterized by Equation 3 and Equation 4, has been empirically shown to be superior in general than other software reliability models by several researchers <ref> [14, 1, 6] </ref>. Malaiya et al [6] have shown using a number of diverse data sets that the superiority of the logarithmic model is statistically significant. (t) = fi L 1 t) (3) fi L 1 1 t where (t) is the failure intensity at time t. <p> However, because of lack of sufficient data, the results are not yet conclusive [12]. The logarithmic model, which is characterized by Equation 3 and Equation 4, has been empirically shown to be superior in general than other software reliability models by several researchers [14, 1, 6]. Malaiya et al <ref> [6] </ref> have shown using a number of diverse data sets that the superiority of the logarithmic model is statistically significant. (t) = fi L 1 t) (3) fi L 1 1 t where (t) is the failure intensity at time t.
Reference: [7] <author> Y. K. Malaiya and P. Verma, </author> <title> Testability Profile Approach to Software Reliability, Advances in Reliability and Quality Control (Ed. </title> <publisher> M.H.Hamza), Acta Press, </publisher> <month> December </month> <year> 1988, </year> <pages> pp. 67-71. </pages>
Reference-contexts: can be better planned. * When both parameters can be known a priori, the testing time needed to achieve target reliability can be calculated and hence, optimal resource allocation can be done even before testing begins. * In early phases of testing, the failure intensity values observed contain considerable noise <ref> [7] </ref>. the use of reliability growth models in the early phases can sometimes result in grossly incorrect projection. The accuracy can be enhanced by using apriori parameter values in such cases.
Reference: [8] <author> G. A. Kruger, </author> <title> Validation and Further Application of Software Reliability Growth Models, </title> <journal> Hewlett-Packard Journal, </journal> <month> April </month> <year> 1989, </year> <pages> pp. 75-79. </pages>
Reference-contexts: The data collected by Musa [1] shows that the number of additional faults introduced during the debugging process is only about 5%. Thus fi E 0 may be estimated as the initial number of faults. It has been observed <ref> [8] </ref> that in an organization, the defect density (measured in defects/thousand lines of code) at the beginning of the system test phase does not vary significantly and thus may be estimated with acceptable accuracy. Emperical methods to estimate defect density using programmer skill etc. have also been proposed [9, 10].
Reference: [9] <author> M. Takahashi and Y. Kamayachi, </author> <title> An Emperical Study of a Model for Program Error Prediction, in Software Reliability Models, </title> <publisher> IEEE Computer Society, </publisher> <year> 1991. </year> <pages> pp. 71-77. </pages>
Reference-contexts: Emperical methods to estimate defect density using programmer skill etc. have also been proposed <ref> [9, 10] </ref>. The estimation of the other parameter fi E 1 is more complex. <p> Further research is needed to identify and quantify the effect of other factors so that K or K 0 may be approximated more accurately, just as the frequency of specification changes, etc. can enhance the accuracy of estimating the total number of defects <ref> [9] </ref>. The model can be refined further when additional data is available. If there is data available to relate K 0 to D 0 , then we can estimate K 0 and hence the parameter 0 of the logarithmic model (ref. Equation 7) at the beginning of system testing phase.
Reference: [10] <author> T. M. Khoshgoftar and J. C. Munson, </author> <title> The Live of Code Metric as a Predictor of Program Faults: a Critical Analysis", </title> <booktitle> Proc. COMPSAC'90, </booktitle> <pages> pp. 408-413. </pages>
Reference-contexts: Emperical methods to estimate defect density using programmer skill etc. have also been proposed <ref> [9, 10] </ref>. The estimation of the other parameter fi E 1 is more complex.
Reference: [11] <author> A. von Mayrhauser and J. A. Teresinki, </author> <title> The Effects of Static Code Metrics on Dynamic Software Reliability Models, </title> <booktitle> Proc. of Symposium on Software Reliability Engineering, </booktitle> <month> April, </month> <year> 1990, </year> <pages> pp. </pages> <month> 19.1-19.13. </month>
Reference-contexts: However, they suspected that for large programs, the "structuredness" (as measured by 2 decision density) may average out and thus may not vary much with program size [1]. Musa has also argued that K should be independent of program size [2]. von Mayrhauser and Teresinki <ref> [11] </ref> have suggested that K may depend on static metrics like "loopiness" and "branchiness" of the program. However, because of lack of sufficient data, the results are not yet conclusive [12].
Reference: [12] <author> J. M. Keables, </author> <title> Program Structure and Dynamic Models in Software Reliability: Investigation in a Simulated Environment, </title> <type> Ph.D Dissertation, </type> <institution> Computer Science Dept., Illinois Institute of Technology, </institution> <year> 1991. </year>
Reference-contexts: Musa has also argued that K should be independent of program size [2]. von Mayrhauser and Teresinki [11] have suggested that K may depend on static metrics like "loopiness" and "branchiness" of the program. However, because of lack of sufficient data, the results are not yet conclusive <ref> [12] </ref>. The logarithmic model, which is characterized by Equation 3 and Equation 4, has been empirically shown to be superior in general than other software reliability models by several researchers [14, 1, 6].
Reference: [13] <author> E. N. Adams, </author> <title> Optimizing Preventive Service of Software Products, </title> <journal> IBM Journal of Research and Development, </journal> <volume> vol. 28, no. 1, </volume> <month> January </month> <year> 1984, </year> <note> pp.2-14. 13 </note>
Reference-contexts: The values are plotted in Figure 1 along with the fitted model of Equation 25. the figures. 3 Estimation of K Adams <ref> [13] </ref> noticed that software's failure rates in operational phase had similar distribution, which observes Zipf's law," the failure rate of a fault i is inversely proportional to a power of i, when faults are ranked by decreasing failure rate" [15].
Reference: [14] <author> W. H. Farr, </author> <title> A survey of Software Reliability Modeling and Estimation, Naval Surface Weapons Center, </title> <type> TR 82-171, </type> <month> Sept. </month> <year> 1983. </year>
Reference-contexts: However, because of lack of sufficient data, the results are not yet conclusive [12]. The logarithmic model, which is characterized by Equation 3 and Equation 4, has been empirically shown to be superior in general than other software reliability models by several researchers <ref> [14, 1, 6] </ref>. Malaiya et al [6] have shown using a number of diverse data sets that the superiority of the logarithmic model is statistically significant. (t) = fi L 1 t) (3) fi L 1 1 t where (t) is the failure intensity at time t.
Reference: [15] <author> M. Trachtenberg, </author> <title> Why Failure Rates Observe Zipf's Law in Operational Software, </title> <journal> IEEE Trans. Reliability, </journal> <volume> vol. 41, no. 3, </volume> <month> September </month> <year> 1992, </year> <pages> pp. 386-389. 14 </pages>
Reference-contexts: model of Equation 25. the figures. 3 Estimation of K Adams [13] noticed that software's failure rates in operational phase had similar distribution, which observes Zipf's law," the failure rate of a fault i is inversely proportional to a power of i, when faults are ranked by decreasing failure rate" <ref> [15] </ref>. Trachtenberg [15] proposed a software reliability model based on Zipf's law which fitted Adam's reliability data with an very high correlation coefficient. <p> Equation 25. the figures. 3 Estimation of K Adams [13] noticed that software's failure rates in operational phase had similar distribution, which observes Zipf's law," the failure rate of a fault i is inversely proportional to a power of i, when faults are ranked by decreasing failure rate" <ref> [15] </ref>. Trachtenberg [15] proposed a software reliability model based on Zipf's law which fitted Adam's reliability data with an very high correlation coefficient. If we regard the testing phase as a compressed form of operational use [1], then the failure rates during testing phase may also have similar distribution across software projects.
References-found: 15

