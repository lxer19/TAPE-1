URL: ftp://ftp.cs.huji.ac.il/users/clag/paam96/musag.ps.gz
Refering-URL: http://www.cs.huji.ac.il/~clag/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email: clag@cs.huji.ac.il, langera@cs.huji.ac.il, jeff@cs.huji.ac.il  
Title: Musag: an agent that learns what you mean  
Author: Claudia V. Goldman and Amir Langer and Jeffrey S. Rosenschein ph: ---- url:http://www.cs.huji.ac.il/~ fclagjlangerag 
Address: Givat Ram, Jerusalem, Israel  
Affiliation: Institute of Computer Science Hebrew University  
Abstract: This paper presents a system that carries out highly effective searches over collections of textual information, such as those found on the Internet. The system is comprised of two major parts. The first part consists of an agent, MUSAG, that learns to relate concepts that are semantically "similar" to one another. In other words, this agent dynamically builds a dictionary of expressions for a given concept that captures the words people have in mind when mentioning the specific concept. The second part consists of another agent, SAg, who is responsible for retrieving documents, given a set of keywords with relative weights. This retrieval makes use of the dictionary learned by MUSAG, in the sense that the documents to be retrieved for a query are semantically related to the concept given. In this way, we overcome two main problems with current text search engines, which are largely based on syntactic methods. One problem is that the keyword given in the 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Robert Armstrong, Dyne Freitag, Thorsten Joachims, and Tom Mitchell. Webwatcher: </author> <title> A learning apprentice for the world wode web. </title> <booktitle> In Working Notes of the AAAI Spring Symposium Series on Information Gathering from Distributed, Heterogeneous Environments, </booktitle> <year> 1995. </year>
Reference-contexts: Letizia [5] is an interface agent which tries to model the user's browsing behavior by learning from the pages the user decided to view. WebWatcher <ref> [1] </ref> works in a similar vein although there, the recommendations are based on a goal you state before the search. Both agents supplies interactive assistance to the user who performs the search and do not handle any queries the user might have.
Reference: [2] <author> Marko Balabanovic and Yoav Shoham. </author> <title> Learning information retrieval agents: Experiments with automated web browsing. </title> <booktitle> In Working Notes of the AAAI Spring Symposium Series on Information Gathering from Distributed, Heterogeneous Environments, </booktitle> <year> 1995. </year>
Reference-contexts: This agent implements steps 1, 3 and 4 above. 7 Related Work In recent years, there is an increasing amount of works on intelligent software agents on the web which deal with information retrieval and involves learning. M. Balabanovic and Y. Shoham <ref> [2] </ref> constructed an agent that learns about a user's preferences of web pages and suggests new pages to the user from a Best-First search it performs on the web.
Reference: [3] <author> Infoseek. </author> <note> http://www.infoseek.com. </note>
Reference-contexts: Sag implements the A* search algorithm on a spanning tree he creates from the internet. The root of the tree is a document Sag builds, which contains links to documents that are returned by existent search engines: Lycos [6], Yahoo [10], Inktomi [4], Infoseek <ref> [3] </ref>, and Webcrawler [9].
Reference: [4] <author> Inktomi Web Services. </author> <note> http://inktomi.berkeley.edu/. </note>
Reference-contexts: Sag implements the A* search algorithm on a spanning tree he creates from the internet. The root of the tree is a document Sag builds, which contains links to documents that are returned by existent search engines: Lycos [6], Yahoo [10], Inktomi <ref> [4] </ref>, Infoseek [3], and Webcrawler [9].
Reference: [5] <author> Henry Lieberman. Letizia: </author> <title> An agent that assists web browsing. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, Quebec, 1995. [6] lycos T M . http://twelve.srv.lycos.com/. </address>
Reference-contexts: Other direction of research tried to assist the user when browsing the web by suggesting what link to choose or where to go from its current position. Letizia <ref> [5] </ref> is an interface agent which tries to model the user's browsing behavior by learning from the pages the user decided to view. WebWatcher [1] works in a similar vein although there, the recommendations are based on a goal you state before the search.
Reference: [7] <author> Michael L. Mauldin and John R.R. Leavitt. </author> <title> Web agent related research at the center for machine translation, </title> <note> 1994. Presented at SIGNIDR. </note>
Reference-contexts: Queries are handled by all the indexes and search engines that can be found today on the internet. These indexes include agents which build and update a data-base such as Webcrawler [8] and Lycos <ref> [7] </ref>. None of those agents base their database on semantic methods. Other index-based search engines as Yahoo [10], bypassed the semantic issue by presenting the user with a list of predefined domains.
Reference: [8] <author> Brian Pinkerton. </author> <title> Finding what people want: Experiences with the webcrawler. </title> <booktitle> In Proceedings of the Second International WWW Conference, 1994. </booktitle> <address> [9] webcrawler T M . http://webcrawler.com/. </address>
Reference-contexts: Queries are handled by all the indexes and search engines that can be found today on the internet. These indexes include agents which build and update a data-base such as Webcrawler <ref> [8] </ref> and Lycos [7]. None of those agents base their database on semantic methods. Other index-based search engines as Yahoo [10], bypassed the semantic issue by presenting the user with a list of predefined domains.
Reference: [10] <institution> Yahoo! http://www.yahoo.com. </institution>
Reference-contexts: Sag implements the A* search algorithm on a spanning tree he creates from the internet. The root of the tree is a document Sag builds, which contains links to documents that are returned by existent search engines: Lycos [6], Yahoo <ref> [10] </ref>, Inktomi [4], Infoseek [3], and Webcrawler [9]. <p> Since the agents are anytime programs, then eventually SAg will jump to other sites in the search tree. It is obvious that syntax-based search engines could make mistakes when the concept they are asked for has multiple meanings. For example, we queried Yahoo <ref> [10] </ref> about the concept dai . The results we got didn't have any relation to the research area of distributed artificial intelligence. <p> These indexes include agents which build and update a data-base such as Webcrawler [8] and Lycos [7]. None of those agents base their database on semantic methods. Other index-based search engines as Yahoo <ref> [10] </ref>, bypassed the semantic issue by presenting the user with a list of predefined domains. These domains enable the user to focus his search, although the user might be interested in a concept for which there is not any directory.
References-found: 8

