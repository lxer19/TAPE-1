URL: http://www.research.microsoft.com/~ruf/files/tr9505-300.ps
Refering-URL: http://www.research.microsoft.com/~ruf/preprint.htm
Root-URL: http://www.research.microsoft.com
Email: erikruf@microsoft.com  
Title: Optimizing Sparse Representations for Dataflow Analysis  
Author: Erik Ruf 
Note: Paper presented at the First ACM SIGPLAN Workshop on Intermediate Representations (IR'95),  
Address: One Microsoft Way Redmond, WA 98052  
Affiliation: Microsoft Research Advanced Technology Division Microsoft Corporation  
Date: March 3, 1995  January 1995.  
Abstract: Technical Report MSR-TR-95-05 
Abstract-found: 1
Intro-found: 1
Reference: [ABS94] <author> T. M. Austin, S. E. Breach, and G. S. Sohi. </author> <title> Efficient detection of all pointer and array access errors. </title> <booktitle> In Proceedings of the SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 290-301. </pages> <publisher> ACM Press, </publisher> <year> 1994. </year>
Reference-contexts: Similarly, analyses of higher complexity (such as context-sensitive interprocedural analyses) may see larger benefits. 5.2 Results We executed the points-to analysis on VDG representations of a variety of small C programs selected from those used in other pointer analysis and instrumentation publications <ref> [LR92, LRZ93, EGH94, ABS94] </ref>. Figure 7 lists these programs and their sizes in initial VDG form. For each benchmark program, Figure 8 gives four measurements of VDG size and analysis costs at each of five levels of optimization.
Reference: [ASU86] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: The additional "proxy" node assures that the pointer-valued (and thus interesting) formals from and to cannot be deleted as dead code. Our approach of using the same intermediate representation for the original and specialized graphs differs from existing work on sparse-graph-based techniques <ref> [ASU86, CCF91, JPP94] </ref>, which build their sparse representations directly from control flow graphs. Doing so might allow for a more space-efficient representation by avoiding duplication of entire VDG nodes. <p> Definition-use chains <ref> [ASU86] </ref> provide "direct connections" between definitions at the cost of a potentially quadratic number of edges and meet operations. Static single assignment (SSA) form [CFR + 89, CFR + 91] and its "factored" [CCF94] and "pruned" [CCF91] derivatives avoid this expense by combining information as early as possible using -functions.
Reference: [BMO90] <author> R. A. Ballance, A. B. Maccabe, and K. J. Ottenstein. </author> <title> The program dependence web: a representation supporting control-, data-, and demand-driven interpretation of imperative languages. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Because its selectors take a predicate argument, the VDG is more similar to the gated single assignment (GSA) component of the program dependence web (PDW) <ref> [BMO90, CKB93] </ref> and thinned GSA form [Hav93], except that we model looping and unstructured control flow with function calling rather than distinguished versions of -functions. The Dependence Flow Graph (DFG) [PBJ + 90] adds switch nodes to enable backwards analyses.
Reference: [CCF91] <author> J.-D. Choi, R. Cytron, and J. Ferrante. </author> <title> Automatic construction of sparse data flow evaluation graphs. </title> <booktitle> In Proceedings of the Eighteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 55-66. </pages> <publisher> ACM Press, </publisher> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: General sparse representations such as static single assignment (SSA) form [CFR + 89] completely describe a program's behavior, while analysis-specific representations such as sparse evaluation graphs (SEGs) <ref> [CCF91] </ref> represent only those program statements needed to solve a particular dataflow problem. <p> The additional "proxy" node assures that the pointer-valued (and thus interesting) formals from and to cannot be deleted as dead code. Our approach of using the same intermediate representation for the original and specialized graphs differs from existing work on sparse-graph-based techniques <ref> [ASU86, CCF91, JPP94] </ref>, which build their sparse representations directly from control flow graphs. Doing so might allow for a more space-efficient representation by avoiding duplication of entire VDG nodes. <p> This approach of first building a simplistic specialized graph and then optimizing it differs from existing approaches to specialized graph construction. Both the sparse evaluation graph (SEG) <ref> [CCF91] </ref> and the quick propagation graph (QPG) [JPP94] approaches construct an optimized sparse graph from the original control flow graph. <p> Definition-use chains [ASU86] provide "direct connections" between definitions at the cost of a potentially quadratic number of edges and meet operations. Static single assignment (SSA) form [CFR + 89, CFR + 91] and its "factored" [CCF94] and "pruned" <ref> [CCF91] </ref> derivatives avoid this expense by combining information as early as possible using -functions. <p> The analyses used by our standard optimizations would be applicable under these frameworks, but the transformations would become more complicated due to the need to modify the underlying control representation. 6.2 Sparse Dataflow Analysis Methods We have already described sparse evaluation graphs <ref> [CCF91, CF93] </ref> and quick propagation graphs [JPP94]. The slotwise method [DRZ92] takes advantage of sparseness without the need to construct a separate graph, but applies solely to classical bit-vector problems.
Reference: [CCF94] <author> J.-D. Choi, R. Cytron, and J. Ferrante. </author> <title> On the efficient engineering of ambitious program analysis. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 20(2) </volume> <pages> 105-114, </pages> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: Definition-use chains [ASU86] provide "direct connections" between definitions at the cost of a potentially quadratic number of edges and meet operations. Static single assignment (SSA) form [CFR + 89, CFR + 91] and its "factored" <ref> [CCF94] </ref> and "pruned" [CCF91] derivatives avoid this expense by combining information as early as possible using -functions.
Reference: [CF93] <author> R. K. Cytron and J. Ferrante. </author> <title> Efficiently computing -nodes on-the-fly. </title> <booktitle> In Languages and Compilers for Parallel Computing: 6th International Workshop, </booktitle> <pages> pages 461-476. </pages> <publisher> Springer-Verlag, </publisher> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: SEGs use a dominance-frontier method similar to that used in SSA construction to decide where to place meet operations (a newer construction, described in <ref> [CF93] </ref>, uses a more efficient partitioning algorithm), while QPGs use precomputed summary information about single-entry-single-exit regions of the program to bypass regions with identity transfer functions. <p> The analyses used by our standard optimizations would be applicable under these frameworks, but the transformations would become more complicated due to the need to modify the underlying control representation. 6.2 Sparse Dataflow Analysis Methods We have already described sparse evaluation graphs <ref> [CCF91, CF93] </ref> and quick propagation graphs [JPP94]. The slotwise method [DRZ92] takes advantage of sparseness without the need to construct a separate graph, but applies solely to classical bit-vector problems.
Reference: [CFR + 89] <author> R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck. </author> <title> An efficient method of computing static single assignment form. </title> <booktitle> In Proceedings of the Sixteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 25-35. </pages> <publisher> ACM Press, </publisher> <month> Jan. </month> <year> 1989. </year>
Reference-contexts: Sparse program representations attempt to minimize both of these costs by more directly connecting producers of values with their consumers, so that fewer assertions are kept at each point, and fewer need be propagated through each statement. General sparse representations such as static single assignment (SSA) form <ref> [CFR + 89] </ref> completely describe a program's behavior, while analysis-specific representations such as sparse evaluation graphs (SEGs) [CCF91] represent only those program statements needed to solve a particular dataflow problem. <p> The primary differences are that predicates appear at join points rather than split points, and that back edges are implemented using function calls. Another way to view the initial VDG is as a variant of static single assignment form <ref> [CFR + 89] </ref>, in which the -functions (1) take an additional predicate argument and (2) select between entire stores rather than values of particular variables. 3 The VDG as a general-purpose sparse representation The VDG of Figure 1 is anything but sparse, largely due to manipulation of an explicit store. <p> For the sake of efficiency, our implementation performs ar-ity raising with respect to local variables only, making the complexity relative to procedure, rather than program, sizes. Empirical evidence from the SSA work <ref> [CFR + 89, CFR + 91] </ref> indicates that, for a large number of FORTRAN procedures, the number of -functions in SSA form (and thus the number of nodes constructed by arity raising) is linear in procedure size even when all variables qualify. <p> Definition-use chains [ASU86] provide "direct connections" between definitions at the cost of a potentially quadratic number of edges and meet operations. Static single assignment (SSA) form <ref> [CFR + 89, CFR + 91] </ref> and its "factored" [CCF94] and "pruned" [CCF91] derivatives avoid this expense by combining information as early as possible using -functions.
Reference: [CFR + 91] <author> R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck. </author> <title> Efficiently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: For the sake of efficiency, our implementation performs ar-ity raising with respect to local variables only, making the complexity relative to procedure, rather than program, sizes. Empirical evidence from the SSA work <ref> [CFR + 89, CFR + 91] </ref> indicates that, for a large number of FORTRAN procedures, the number of -functions in SSA form (and thus the number of nodes constructed by arity raising) is linear in procedure size even when all variables qualify. <p> Definition-use chains [ASU86] provide "direct connections" between definitions at the cost of a potentially quadratic number of edges and meet operations. Static single assignment (SSA) form <ref> [CFR + 89, CFR + 91] </ref> and its "factored" [CCF94] and "pruned" [CCF91] derivatives avoid this expense by combining information as early as possible using -functions.
Reference: [CG93] <author> R. Cytron and R. Gershbein. </author> <title> Efficient accomo-dation of may-alias information in SSA form. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 36-45. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: This happens, for example, when an induction variable is modified in a loop, but not examined in computations downstream of the loop, or when loop invariant bypassing rewrites a call node, killing the corresponding lambda return. 2 Unlike SSA form, which represents potential assignments through aliases by introducing explicit "IsAlias" <ref> [CG93] </ref> operators, VDG form allows such assignments to remain as operations on an explicit store. Because arity raising removes update nodes, but does not recompute the placement of store-valued if nodes and return parameters, loop invariant store values may be introduced. <p> The sparse SSA construction described in <ref> [CG93] </ref> differs from other sparse graph construction techniques in that it does not rely on a static partition of nodes/edges into "interesting" and "uninteresting" sets.
Reference: [CKB93] <author> P. L. Campbell, K. Krishna, and R. A. Bal-lance. </author> <title> Refining and defining the program dependence web. </title> <type> Technical Report CS93-6, </type> <institution> University of New Mexico, </institution> <address> Albuquerque, </address> <month> Mar. </month> <year> 1993. </year>
Reference-contexts: Because its selectors take a predicate argument, the VDG is more similar to the gated single assignment (GSA) component of the program dependence web (PDW) <ref> [BMO90, CKB93] </ref> and thinned GSA form [Hav93], except that we model looping and unstructured control flow with function calling rather than distinguished versions of -functions. The Dependence Flow Graph (DFG) [PBJ + 90] adds switch nodes to enable backwards analyses.
Reference: [CWZ90] <author> D. R. Chase, M. Wegman, and F. K. Zadeck. </author> <title> Analysis of pointers and structures. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 296-310, </pages> <month> June 20-22, </month> <year> 1990. </year>
Reference-contexts: A "pointer output" is a node output that can carry pointer values; e.g., one whose type is pointer, aggregate containing pointer, or store. Sources: (*) William A. Landi, (y) Todd K. Austin, (z) Free Software Foundation, ( + ) SPEC92 suite. of <ref> [CWZ90, Sections 3 and 4.2] </ref>; it maintains a set of "points-to" pairs on every store- and pointer-containing node output in the program 9 and incrementally grows these sets using a worklist strategy. <p> For each benchmark program, Figure 8 gives four measurements of VDG size and analysis costs at each of five levels of optimization. Analysis times are measured in terms of the number of transfer functions executed by the analysis; unlike execu 9 <ref> [CWZ90] </ref> describes a way to reduce the storage costs (at log n time cost) using a sparse representation for the points-to information itself; this is orthogonal to the use of a sparse representation for the program. 7 name statistic initial arity opt spec spec/opt cum allroots outputs 925 737 (80%) 620
Reference: [DGS94] <author> E. Duesterwald, R. Gupta, and M. L. Soffa. </author> <title> Reducing the cost of data flow analysis by congruence partitioning. </title> <booktitle> In CC '94: Fifth International Conference on Compiler Construction, </booktitle> <pages> pages 357-373, </pages> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: Changing the algorithm to operate in the forward direction might gain a constant factor in performance, but at the cost of significant implementation complexity. The basic specialization algorithm as described in Fig ure 4 is fails to take advantage of two opportunities for optimization (also noted in <ref> [DGS94] </ref>): 1. Common subexpressions in the specialized graph, and 2. Idempotence of the "meet" operator. Case (1) is trivial to handle in a VDG; the standard constructors for VDG nodes perform value numbering based on the identity of the operands. <p> Although our methods are applicable to such problems, we have not yet investigated such problems because the problem of primary interest to us (points-to analysis) is not separable. 10 <ref> [DGS94] </ref> represents a dataflow problem as a network of equations, applies algorithms to partition the equations into equivalence classes with identical solutions, and constructs a new network containing only one representative from each partition. <p> This is similar in spirit to constructing an analysis-specific sparse program representation; indeed, our incremental value-numbering-based construction of specialized graphs, when combined with loop invariant bypassing, appears to provide the same functionality as the "partitioning by idempotence" and "partitioning by common subexpres-sions" strategies in <ref> [DGS94] </ref>. The sparse SSA construction described in [CG93] differs from other sparse graph construction techniques in that it does not rely on a static partition of nodes/edges into "interesting" and "uninteresting" sets.
Reference: [DRZ92] <author> D. M. Dhamdhere, B. K. Rosen, and F. K. Zadeck. </author> <title> How to analyze large programs efficiently and informatively. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 212-223. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: We feel this problem and algorithm form an appropriate test case for sparse graphs. The problem is neither separable nor distributive, meaning that sparse-traversal approaches such as the "slotwise method" <ref> [DRZ92] </ref> cannot be applied, and that constructing a sparse representation is unlikely to be an overly "heavyweight" approach to the problem. <p> The slotwise method <ref> [DRZ92] </ref> takes advantage of sparseness without the need to construct a separate graph, but applies solely to classical bit-vector problems.
Reference: [EGH94] <author> M. Emami, R. Ghiya, and L. J. Hendren. </author> <title> Context-sensitive interprocedural analysis in the presence of function pointers. </title> <booktitle> In Proceedings of the SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 242-256. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: Termination is assured because the number of outputs and points-to pairs are finite, yielding O (n 3 ) time and space bounds in the worst case (O (n 2 ) in the average case, in which each pointer has only a small constant number of referents <ref> [LRZ93, EGH94] </ref>). We feel this problem and algorithm form an appropriate test case for sparse graphs. <p> Similarly, analyses of higher complexity (such as context-sensitive interprocedural analyses) may see larger benefits. 5.2 Results We executed the points-to analysis on VDG representations of a variety of small C programs selected from those used in other pointer analysis and instrumentation publications <ref> [LR92, LRZ93, EGH94, ABS94] </ref>. Figure 7 lists these programs and their sizes in initial VDG form. For each benchmark program, Figure 8 gives four measurements of VDG size and analysis costs at each of five levels of optimization.
Reference: [FOW87] <author> J. Ferrante, K. J. Ottenstein, and J. D. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: The Dependence Flow Graph (DFG) [PBJ + 90] adds switch nodes to enable backwards analyses. The Program Dependence Graph <ref> [FOW87] </ref> and its interprocedural extension, the System Dependence Graph [HRB90] include a data-dependence subgraph that is used for sparse dataflow analyses.
Reference: [Hav93] <author> P. Havlak. </author> <title> Construction of thinned gated single-assignment form. </title> <booktitle> In Proceedings of the Sixth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: Because its selectors take a predicate argument, the VDG is more similar to the gated single assignment (GSA) component of the program dependence web (PDW) [BMO90, CKB93] and thinned GSA form <ref> [Hav93] </ref>, except that we model looping and unstructured control flow with function calling rather than distinguished versions of -functions. The Dependence Flow Graph (DFG) [PBJ + 90] adds switch nodes to enable backwards analyses.
Reference: [HRB90] <author> S. Horwitz, T. Reps, and D. Binkley. </author> <title> Interpro-cedural slicing using dependence graphs. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(1) </volume> <pages> 26-60, </pages> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: The Dependence Flow Graph (DFG) [PBJ + 90] adds switch nodes to enable backwards analyses. The Program Dependence Graph [FOW87] and its interprocedural extension, the System Dependence Graph <ref> [HRB90] </ref> include a data-dependence subgraph that is used for sparse dataflow analyses.
Reference: [JPP94] <author> R. Johnson, D. Pearson, and K. Pingali. </author> <title> The program structure tree: Computing control regions in linear time. </title> <booktitle> In Proceedings of the SIG-PLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 171-185. </pages> <publisher> ACM Press, </publisher> <month> June 20-24, </month> <year> 1994. </year>
Reference-contexts: The additional "proxy" node assures that the pointer-valued (and thus interesting) formals from and to cannot be deleted as dead code. Our approach of using the same intermediate representation for the original and specialized graphs differs from existing work on sparse-graph-based techniques <ref> [ASU86, CCF91, JPP94] </ref>, which build their sparse representations directly from control flow graphs. Doing so might allow for a more space-efficient representation by avoiding duplication of entire VDG nodes. <p> This approach of first building a simplistic specialized graph and then optimizing it differs from existing approaches to specialized graph construction. Both the sparse evaluation graph (SEG) [CCF91] and the quick propagation graph (QPG) <ref> [JPP94] </ref> approaches construct an optimized sparse graph from the original control flow graph. <p> The analyses used by our standard optimizations would be applicable under these frameworks, but the transformations would become more complicated due to the need to modify the underlying control representation. 6.2 Sparse Dataflow Analysis Methods We have already described sparse evaluation graphs [CCF91, CF93] and quick propagation graphs <ref> [JPP94] </ref>. The slotwise method [DRZ92] takes advantage of sparseness without the need to construct a separate graph, but applies solely to classical bit-vector problems.
Reference: [KRS94] <author> J. Knoop, O. Ruthing, and B. Steffen. </author> <title> Partial dead code elimination. </title> <booktitle> In Proceedings of the SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 147-158. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: We willingly pay the cost of loop invariant removal in such cases, as it allows us to avoid the far more costly "IsAlias" representation. 3 The latter case sometimes called "faint" code in the litera ture <ref> [KRS94] </ref>; we make no such distinction. 3 hoisting and bypassing, and dead code elimination. We remove such dead code by computing the transitive closure of all nodes reachable from the program's return nodes, and then garbage-collecting all nodes not contained in the transitive closure.
Reference: [LR92] <author> W. Landi and B. G. Ryder. </author> <title> A safe approximate algorithm for interprocedural pointer aliasing. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 235-248. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: Similarly, analyses of higher complexity (such as context-sensitive interprocedural analyses) may see larger benefits. 5.2 Results We executed the points-to analysis on VDG representations of a variety of small C programs selected from those used in other pointer analysis and instrumentation publications <ref> [LR92, LRZ93, EGH94, ABS94] </ref>. Figure 7 lists these programs and their sizes in initial VDG form. For each benchmark program, Figure 8 gives four measurements of VDG size and analysis costs at each of five levels of optimization.
Reference: [LRZ93] <author> W. Landi, B. G. Ryder, and S. Zhang. </author> <title> Interpro-cedural modification side effect analysis with pointer aliasing. </title> <booktitle> In Proceedings of the SIG-PLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 56-67. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: Termination is assured because the number of outputs and points-to pairs are finite, yielding O (n 3 ) time and space bounds in the worst case (O (n 2 ) in the average case, in which each pointer has only a small constant number of referents <ref> [LRZ93, EGH94] </ref>). We feel this problem and algorithm form an appropriate test case for sparse graphs. <p> Similarly, analyses of higher complexity (such as context-sensitive interprocedural analyses) may see larger benefits. 5.2 Results We executed the points-to analysis on VDG representations of a variety of small C programs selected from those used in other pointer analysis and instrumentation publications <ref> [LR92, LRZ93, EGH94, ABS94] </ref>. Figure 7 lists these programs and their sizes in initial VDG form. For each benchmark program, Figure 8 gives four measurements of VDG size and analysis costs at each of five levels of optimization.
Reference: [PBJ + 90] <author> K. Pingali, M. Beck, R. Johnson, M. Moudg-ill, and P. Stodghill. </author> <title> Dependence flow graphs: An algebraic approach to program dependencies. </title> <type> Technical Report 90-1152, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, NY 14853, </address> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: The Dependence Flow Graph (DFG) <ref> [PBJ + 90] </ref> adds switch nodes to enable backwards analyses. The Program Dependence Graph [FOW87] and its interprocedural extension, the System Dependence Graph [HRB90] include a data-dependence subgraph that is used for sparse dataflow analyses.
Reference: [Rom90] <author> S. Romanenko. </author> <title> Arity raiser and its use in program specialization. </title> <editor> In N. Jones, editor, </editor> <booktitle> ESOP '90. 3rd European Symposium on Programming, </booktitle> <address> Copenhagen, Denmark, </address> <month> May </month> <year> 1990., </year> <booktitle> volume 432 of Lecture Notes in Computer Science, </booktitle> <pages> pages 341-360. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: We replace all lookup nodes for such a variable with appropriate subgraphs that select between the values written by potentially reaching update nodes. We call this process arity raising (after <ref> [Rom90] </ref>) because it adds additional formals and returns to all functions accepting or returning store values.
Reference: [Ruf94] <author> E. Ruf. </author> <title> Context-insensitive alias analysis reconsidered. </title> <note> Submitted for publication, </note> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: For our benchmarks, we will use a simple program-point-specific (but context-insensitive) points-to analysis for C programs. The idea is to determine, for each lookup and update node, which locations may be examined/modified. Our algorithm <ref> [Ruf94] </ref> is similar to the "simple algorithm" 8 Other optimizations, such as arity raising, make little sense on a specialized graph, since the specialized graph construction does not make any additional variables eligible. name source nodes total pointer lines outputs outputs allroots ? 231 802 925 449 backprop y 286 1086
Reference: [Ste95] <author> B. Steensgaard. </author> <title> Sparse functional stores for imperative programs. </title> <booktitle> In ACM SIGPLAN Workshop on Intermediate Representations, </booktitle> <month> Jan. </month> <year> 1995. </year> <note> (this volume). </note>
Reference-contexts: Also, arity raising need not be limited solely to non-aliased variables; elements of aggregate data structures, or even non-interfering portions of the store <ref> [Ste95] </ref>, could be split in similar fashion, in which case we might wish to perform ar-ity raising repeatedly on the VDG. example program.
Reference: [WCES94a] <author> D. Weise, R. F. Crew, M. Ernst, and B. Steens-gaard. </author> <title> Value dependence graphs: Representation without taxation. </title> <booktitle> In Proceedings 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 297-310, </pages> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: Section 5 gives examines the empirical utility of the transformations of Sections 3 and 4 in the context of a simple points-to analysis. We conclude with discussions of related and future work. 2 The VDG The value dependence graph <ref> [WCES94a, WCES94b] </ref> is a functional, graphical representation for imperative programs. Computation is expressed by nodes that consume input values (outputs of other nodes) and produce output values; communication between nodes is expressed via edges that connect each of a node's inputs to some other node's output.
Reference: [WCES94b] <author> D. Weise, R. F. Crew, M. Ernst, and B. Steens-gaard. </author> <title> Value dependence graphs: Representation without taxation. </title> <type> Technical Report MSR-TR-94-03, </type> <institution> Microsoft Research, </institution> <address> Redmond, WA, </address> <month> Apr. 13, </month> <year> 1994. </year> <month> 12 </month>
Reference-contexts: Section 5 gives examines the empirical utility of the transformations of Sections 3 and 4 in the context of a simple points-to analysis. We conclude with discussions of related and future work. 2 The VDG The value dependence graph <ref> [WCES94a, WCES94b] </ref> is a functional, graphical representation for imperative programs. Computation is expressed by nodes that consume input values (outputs of other nodes) and produce output values; communication between nodes is expressed via edges that connect each of a node's inputs to some other node's output. <p> Arrowheads point from consumers to producers; light edges carry scalar values, while dark edges carry store values. erences (such as variable assignments) explicitly manipulate a store. Conditional branching is represented by if nodes (called "selector," or fl, nodes in <ref> [WCES94b] </ref>) that choose between multiple dataflow edges based on the truth value of a third dataflow edge. Looping and unstructured branching are represented as tail-recursive function calls to synthetic, or "internal," lambda nodes representing the branch target. The initial VDG constructed by the algorithm of [WCES94b] implements all variable references and <p> "selector," or fl, nodes in <ref> [WCES94b] </ref>) that choose between multiple dataflow edges based on the truth value of a third dataflow edge. Looping and unstructured branching are represented as tail-recursive function calls to synthetic, or "internal," lambda nodes representing the branch target. The initial VDG constructed by the algorithm of [WCES94b] implements all variable references and assignments as explicit store operations, performing only local simplifications (such as reducing lookup (var, update (var, val, store)) to val). This construction can be performed in time and space linear in program size. a function mapping an input store to an output store.
References-found: 27

