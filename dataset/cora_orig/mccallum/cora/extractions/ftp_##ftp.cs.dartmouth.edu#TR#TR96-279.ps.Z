URL: ftp://ftp.cs.dartmouth.edu/TR/TR96-279.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/reports/abstracts/TR96-279/
Root-URL: http://www.cs.dartmouth.edu
Email: E-mail: robert.s.gray@dartmouth.edu  
Title: Fast compression of transportable Tcl agents  
Author: Robert S. Gray 
Address: Hanover, NH 03755  
Affiliation: Department of Computer Science Dartmouth College  
Abstract: An information agent is charged with the task of searching a collection of electronic resources for information that is relevant to the user's current needs. These resources are often distributed across a network and can contain tremendous quantities of data. One of the paradigms that has been suggested for allowing efficient access to such resources is transportable agents the agent is sent to the machine that maintains the information resource; the agent executes on this remote machine and then returns its results to the local machine. We have implemented a transportable agent system that uses the Tool Command Language (Tcl) as the agent language. Each Tcl script can suspend its execution at an arbitrary point, transport itself to another machine and resume execution on the new machine. The execution state of the script which includes the commands that have not been executed must be transmitted to the new machine. Although the execution state tends to be small, there will be a large number of agents moving across the network in a large-scale system. Thus it is desirable to compress the execution state as much as possible. Furthermore any compression scheme must be fast so that it does not become a bottleneck between the transportable agent system and the network routines. In this paper we explore several fast compression methods. 
Abstract-found: 1
Intro-found: 1
Reference: [BCW90] <author> Timothy C. Bell, John G. Cleary, and Ian H. Witten. </author> <title> Text Compression, chapter A (Variable-length Representations of the Integers), </title> <address> pages 290-295. </address> <publisher> Prentice-Hall, </publisher> <address> Englewoord Cliffs, New Jersey, </address> <year> 1990. </year>
Reference-contexts: The state flags tend to be small - i.e. almost always in the range 0 to 2 but have no fixed upper bound. They should be coded with one of the variable-length integer codes such as fl or ffi <ref> [BCW90] </ref>. The remaining parts of the state are the names and values of variables, the names of procedures, the Tcl scripts that make up the procedure bodies and the Tcl scripts on the command stack. Due to time constraints we will focus on compressing the Tcl scripts. <p> A single-bit flag indicates whether the next symbol has been seen before. S0 achieves 38% compression. S1 takes advantage of the fact that the upper bound on the production and symbol indices is rarely an exact power of two. It encodes the indices using the efficient phased-in scheme of <ref> [BCW90] </ref> - i.e. if a number i is known to be in the range 0 i &lt; p, then i is coded in (k 1) bits if it is less than 2 (dlogpe) p; otherwise i is coded in k bits. S1 achieves 35% compression. <p> S1 achieves 35% compression. S0 and S1 treat integers as symbols that are no different than procedure and variable names. S2 treats integers as integers. A signal-bit flag indicates whether the integer is positive or negative; the magnitude of the integer is coded using the fl code of <ref> [BCW90] </ref>. The savings are small for the four test scripts but should be significant for scripts that contain a larger number of integers. Floating point numbers are not treated separately since the test scripts do not contain any floating point numbers. This must be considered in future work.
Reference: [BJLM92] <author> Michael Burrows, Charles Jerian, Butler Lampson, and Timothy Mann. </author> <title> On-line data compression in a log-structured file system. </title> <booktitle> In Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-V). ACM, </booktitle> <month> October </month> <year> 1992. </year>
Reference-contexts: In the tables and in the remainder of the paper, compression performance is measured relative to the performance of B1 since B1 eliminates the information that does not need to be transmitted at all. B2 is based on the hash table scheme in <ref> [BJLM92] </ref> and [Wil91]. The compression algorithm uses a 4096-element hash table. Each hash bucket contains a 4-character move-to-front (MTF) list. Every character in the hash table is initialized to the null character. The algorithm performs a linear scan through the script (ignoring comments and extraneous whitespace). <p> It has been shown that the hash table schemes such as B2 and B3 can run much faster than gzip with appropriate implementation <ref> [BJLM92, Wil91] </ref>. The syntax-directed encoders with the exception of S6 which uses adaptive arithmetic coding should run much faster than "gzip" if the parse tree is already available and should at least be competitive if the parse tree must be constructed from scratch.
Reference: [Cam88] <author> Robert D. Cameron. </author> <title> Source encoding using syntactic information source models. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 34(4) </volume> <pages> 843-850, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: The Rush research group has a program that semi-automatically converts Tcl scripts to Rush scripts. This program is not publicly available so we converted the corpus of test scripts to Rush syntax by hand. This manual conversion was the limiting factor on the size of the test corpus. <ref> [Cam88] </ref> and [KPT86] are the primary references for syntax-directed compression. Both of these researchers compress Pascal programs. [KPT86] constructs a parse tree for the Pascal program, removes all nodes that have only one child and then linearizes the parse tree. <p> The output of the compression program is the symbol table followed by an encoding of the linearized parse tree - i.e. the symbol and production indices in the parse tree are coded with a fixed-length binary code. [KPT86] achieves 50% compression. <ref> [Cam88] </ref> constructs a parse tree for the Pascal program, performs a preorder walk through the tree and uses arithmetic coding to encode the tree during the course of the walk. For each non-terminal the compression algorithm encodes the probability of the production that was used to expand the non-terminal. <p> The production probabilities are static and are based on evaluation of a corpus of Pascal programs. All user-defined symbols are coded on a character-by-character basis with an adaptive probability model. The order of the model was not specified. <ref> [Cam88] </ref> achieves 25% compression using this base technique and 15% compression with multiple symbol tables and grammar reorginization. 4 Method Comment parray dialog init menu Total S0 Binary 173 (39%) 881 (56%) 1,814 (38%) 3,149 (35%) 6,017 (38%) S1 Phased binary 163 (36%) 821 (52%) 1,709 (36%) 2,851 (32%) 5,544 (35%) <p> These methods are based on the techniques of <ref> [Cam88] </ref> except that we do not use arithmetic or adaptive coding due to the need for fast compression. An LR (1) grammer was written for Tcl scripts (or more precisely Rush scripts since we are using a modified syntax). <p> As long as the decoder walks the tree in the same order as the encoder, it will be able to decode the compressed parse tree. Thus there is no need to have a unique integer id for every production in the grammer. <ref> [Cam88] </ref> uses the same technique except that the productions are assigned probabilities instead of indices. The eight methods differ in their handling of terminal symbols and the coding methods used for the production indices. <p> S5 achieves 30% compression and seems to be the best that can be done with non-adaptive and non-arithmetic techniques. It is competitive with gzip and with the base technique of <ref> [Cam88] </ref>. [Cam88] cites 25% compression for the base technique but is measuring compression against programs that contain whitespace. If we count whitespace, the compression percentages for S5 are around 26% for every script except dialog. <p> S5 achieves 30% compression and seems to be the best that can be done with non-adaptive and non-arithmetic techniques. It is competitive with gzip and with the base technique of <ref> [Cam88] </ref>. [Cam88] cites 25% compression for the base technique but is measuring compression against programs that contain whitespace. If we count whitespace, the compression percentages for S5 are around 26% for every script except dialog. <p> All models are initialized so that all symbols are equally probable. S6 is slower but achieves 27% compression. S6 can be improved significantly with grammar reorginization, more complex models, more symbol tables and better initial values for the probabilities as was done in <ref> [Cam88] </ref>. All of the syntax-directed methods outcompress B3 which uses just the hash table and a static Huffman code. However only S5 and S6 outcompress B4 which is the standard "gzip" program.
Reference: [KK94] <author> Keith Kotay and David Kotz. </author> <title> Transportable agents. </title> <booktitle> In CIKM Workshop on Intelligent Information Agents (held in conjunction with the Third International Conference on Information and Knowledge Managament), </booktitle> <address> Gaithersburg, Maryland, </address> <month> December </month> <year> 1994. </year> <institution> National Institute of Standards and Technology. </institution>
Reference-contexts: These resources are often distributed across a network and can contain tremendous quantities of data. One of the paradigms that has been suggested for allowing efficient access to such resources is transportable agents <ref> [KK94] </ref> the agent is sent to the machine that maintains the information resource; the agent executes on this remote machine and then returns its results to the local machine. We have implemented a transportable agent system.
Reference: [KPT86] <author> Jyrki Katajainen, Martti Penttonen, and Jukka Teuhola. </author> <title> Syntax-directed compression of program files. </title> <journal> Software Practice and Experience, </journal> <volume> 16(3) </volume> <pages> 269-276, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: This program is not publicly available so we converted the corpus of test scripts to Rush syntax by hand. This manual conversion was the limiting factor on the size of the test corpus. [Cam88] and <ref> [KPT86] </ref> are the primary references for syntax-directed compression. Both of these researchers compress Pascal programs. [KPT86] constructs a parse tree for the Pascal program, removes all nodes that have only one child and then linearizes the parse tree. <p> This manual conversion was the limiting factor on the size of the test corpus. [Cam88] and <ref> [KPT86] </ref> are the primary references for syntax-directed compression. Both of these researchers compress Pascal programs. [KPT86] constructs a parse tree for the Pascal program, removes all nodes that have only one child and then linearizes the parse tree. All user-defined symbols are added to a symbol table as the parse tree is constructed. <p> The output of the compression program is the symbol table followed by an encoding of the linearized parse tree - i.e. the symbol and production indices in the parse tree are coded with a fixed-length binary code. <ref> [KPT86] </ref> achieves 50% compression. [Cam88] constructs a parse tree for the Pascal program, performs a preorder walk through the tree and uses arithmetic coding to encode the tree during the course of the walk.
Reference: [Ous94] <author> John K. Ousterhout. </author> <title> Tcl and the Tk toolkit. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1994. </year>
Reference-contexts: We have implemented a transportable agent system. The agents are written in the Tool Command Language (Tcl) a high-level command language that was created by Dr. John Ousterhout at the University of California at Berkeley <ref> [Ous94] </ref>. Tcl is an attractive language for transportable agents. It is popular, easy to use, widely available and platform independent. It can be embedded in other applications due to its dual existence as a stand-alone interpreter and a programming library.
Reference: [SBD94] <author> Adam Sah, Jon Blow, and Brian Dennis. </author> <title> An introduction to the Rush language. </title> <booktitle> In Proceedings of the 1994 Tcl Workshop, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: A walk through the parse tree would be no more more expensive than a linear scan through the original script. Thus it seems reasonable to explore syntactic-directed compression methods for Tcl scripts. We use the modified syntax that is proposed in <ref> [SBD94] </ref> and used in the Tcl-like Rush language. The main syntactic difference between Tcl and Rush is that Rush enforces consistent use of delimiters - i.e. strings must be delimited by double quotes, subcommands must be delimited by curly brackets and so on.
Reference: [Wil91] <author> Ross N. Williams. </author> <title> An extremely fast Liv-Zempel data compression algorithm. </title> <booktitle> In IEEE Data Compression Conference, </booktitle> <address> Snowbird, Utah, </address> <month> April </month> <year> 1991. </year> <journal> IEEE. </journal> <volume> 8 </volume>
Reference-contexts: In the tables and in the remainder of the paper, compression performance is measured relative to the performance of B1 since B1 eliminates the information that does not need to be transmitted at all. B2 is based on the hash table scheme in [BJLM92] and <ref> [Wil91] </ref>. The compression algorithm uses a 4096-element hash table. Each hash bucket contains a 4-character move-to-front (MTF) list. Every character in the hash table is initialized to the null character. The algorithm performs a linear scan through the script (ignoring comments and extraneous whitespace). <p> This is similar to the hash function used in <ref> [Wil91] </ref> except that we have removed a multiplication (at no cost in compression performance). <p> It has been shown that the hash table schemes such as B2 and B3 can run much faster than gzip with appropriate implementation <ref> [BJLM92, Wil91] </ref>. The syntax-directed encoders with the exception of S6 which uses adaptive arithmetic coding should run much faster than "gzip" if the parse tree is already available and should at least be competitive if the parse tree must be constructed from scratch.
References-found: 8

