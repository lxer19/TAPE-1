URL: http://www.cacs.usl.edu/Departments/CACS/Publications/Raghavan/ChRa97a.ps.Z
Refering-URL: http://www.cacs.usl.edu/~raghavan/raghavan-1.html
Root-URL: http://www.cacs.usl.edu/~raghavan/raghavan-1.html
Phone: 2  
Title: Generic and Fully Automatic Content Based Image Retrieval Architecture  
Author: Suresh K Choubey and Vijay V. Raghavan 
Address: Waukesha, WI 53188, USA  Lafayette, LA 70504, USA  
Affiliation: 1 Magnetic Resonance Center, General Electric Medical Systems,  Center for Advanced Computer Studies, University of Southwestern Louisiana,  
Abstract: Content-based retrieval requires the choice of distance functions for determining inter-image distances. Distance functions considered to be desirable for computing inter-image distances are often too expensive, computationally, to be used for on-line retrieval from large image databases. In this paper, we propose a generic and efficient content-based image retrieval architecture where the original images are mapped on to an abstract feature space such that the desired (or real) inter-image distances correspond to the distances between the vector representations of the images in the feature space. It is shown that it is more efficient to compute distances between these feature vectors and use them as estimates of the real distances. We have conducted experiments using color as the low-level feature. The results show a substantial reduction in the size of the feature space. The experimental results also indicate that high accuracy is achieved for the set of queries tested. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> V. Gudivada and V. Raghavan, </author> <title> "Content-Based Image Retrieval Systems," </title> <journal> IEEE Computer, </journal> <volume> vol. 28, no. 9, </volume> <pages> pp. 18-22, </pages> <year> 1995. </year>
Reference-contexts: However, CBIR remains a very difficult problem as the technology for doing retrieval is still in the process of getting mature. It is very difficult to extract semantics associated with a given image <ref> [1] </ref>. Approaches to CBIR can be classified into two broad classes of attribute-based and feature-based. In attribute-based approach, the image contents are modeled as a set of attributes extracted manually or semi-automatically and managed within the framework of conventional database management system. <p> In a feature-based CBIR, images are represented by their contents and the comparison is made between the contents of the query and the images in the image database <ref> [1] </ref>. They have been discussed in detail in [2]. The feature-based approach can be further classified based on the dependence of retrieval process on how generic the approach is and the degree of automation.
Reference: 2. <author> S. K. Choubey, </author> <title> Generic and Fully Automatic Content-Based Image Retrieval Using Color Shape and Texture. </title> <type> PhD thesis, </type> <institution> University of Southwestern Louisiana Lafayette LA, </institution> <year> 1997. </year>
Reference-contexts: In a feature-based CBIR, images are represented by their contents and the comparison is made between the contents of the query and the images in the image database [1]. They have been discussed in detail in <ref> [2] </ref>. The feature-based approach can be further classified based on the dependence of retrieval process on how generic the approach is and the degree of automation. <p> ) can be isometrically represented in the Euclidean m (m = p + q)dimensional space iff the quadratic form given in Definition 2 is positive and of rank less than m. 4.2 Database Population Phase A procedure called "ComputeFeatureVector ()" to compute the feature vectors of images is given in <ref> [2, 4, 5] </ref>. This procedure also generates the training sample by calling "GenerateTrainingSet ()". This training sample is used to compute query feature vector and feature vectors for images in the incremental image set. <p> This training sample is used to compute query feature vector and feature vectors for images in the incremental image set. This procedure is executed during database population phase only and is also not given here due to space consideration. This algorithm can also be found in <ref> [2, 4, 5] </ref>. The execution of the ComputeFeatureVector () gives feature vectors of all the images in the initial set. Let these feature vectors be denoted by F 0 ; F 1 ; : : : ; F k1 . <p> Given the query image Q, one can readily determine the orthogonal projec-tion (w) of Q onto the vector representation space R (p;q) . An algorithm called "ComputeQueryVector ()" to compute the feature vector of the query image is also given in <ref> [2, 4, 5] </ref>. Let the query feature vector be given by F q . Since the matrix T [2, 4, 5] can easily be computed during the database population phase, the only on-line computations are those of b j ; 1 j m. <p> An algorithm called "ComputeQueryVector ()" to compute the feature vector of the query image is also given in <ref> [2, 4, 5] </ref>. Let the query feature vector be given by F q . Since the matrix T [2, 4, 5] can easily be computed during the database population phase, the only on-line computations are those of b j ; 1 j m. This is perfectly feasible since one has control over the dimension m of the representation space. <p> We have used R norm performance measure, which was first introduced in LIVE-Project [14] and is discussed in detail in <ref> [2] </ref>. 5.1 Results The result is tabulated in Table 1. Due to the limited space, only top fifteen retrieved images are shown in this table.
Reference: 3. <author> L. Goldfarb, </author> <title> "A Unified Approach to Pattern Recognition," </title> <journal> Pattern Recognition, </journal> <volume> vol. 17, no. 5, </volume> <pages> pp. 575-582, </pages> <year> 1984. </year>
Reference-contexts: The IR system should also be generic enough to be transparent when different low-level features are used with almost no or very little changes. We propose a generic and efficient feature-based CBIR architecture. This is based on the work done by Goldfarb <ref> [3] </ref> to bridge the gap between syntactic and statistical pattern recognition for classification problems. We have reported image retrieval specific to color only in [4] and image retrieval by texture in [5]. <p> This set of images is also referred as the initial image set. Let jP j = k; where k n. The value of k should be as small as possible, in order to achieve faster training period. According to Goldfarb <ref> [3] </ref>, the dissimilarity measure between two objects can be defined as follows: Let a pseudometric space be a pair (P; ), where P is a set of images and is a non negative real-valued mapping: : P fi P ! R + (1) Fig. 1. <p> Here fi, which is an intermediate representation of low-level image features, is defined as fi : P ! '; (3) where ' is the space of possible representations of low-level image features. Following discussions lead to a theorem <ref> [3] </ref> that lays the condition for preserving the inter-image distance of an interdistance matrix into the derived feature space. <p> This idea is illustrated in Fig. 2. Isometric embedding ensures that there exists a distance preserving mapping <ref> [3] </ref>: Definition 2: Let (P; ) be the pseudometric space defined earlier and let V be a vector space over R of dimension k 1, and let fa i g 1ik1 be a basis of such a vector space.
Reference: 4. <author> S. K. Choubey and V. V. Raghavan, </author> <title> "Generic and fully automatic content-based image retrieval using color," in Pattern Recognition in Practive V, </title> <address> (Vlieland, Netherland), </address> <month> June </month> <year> 1997. </year>
Reference-contexts: We propose a generic and efficient feature-based CBIR architecture. This is based on the work done by Goldfarb [3] to bridge the gap between syntactic and statistical pattern recognition for classification problems. We have reported image retrieval specific to color only in <ref> [4] </ref> and image retrieval by texture in [5]. In this paper, we discuss the general architecture of our approach and provide preliminary experimental results for retrieval by color to show the effectiveness of the proposed approach. <p> ) can be isometrically represented in the Euclidean m (m = p + q)dimensional space iff the quadratic form given in Definition 2 is positive and of rank less than m. 4.2 Database Population Phase A procedure called "ComputeFeatureVector ()" to compute the feature vectors of images is given in <ref> [2, 4, 5] </ref>. This procedure also generates the training sample by calling "GenerateTrainingSet ()". This training sample is used to compute query feature vector and feature vectors for images in the incremental image set. <p> This training sample is used to compute query feature vector and feature vectors for images in the incremental image set. This procedure is executed during database population phase only and is also not given here due to space consideration. This algorithm can also be found in <ref> [2, 4, 5] </ref>. The execution of the ComputeFeatureVector () gives feature vectors of all the images in the initial set. Let these feature vectors be denoted by F 0 ; F 1 ; : : : ; F k1 . <p> Given the query image Q, one can readily determine the orthogonal projec-tion (w) of Q onto the vector representation space R (p;q) . An algorithm called "ComputeQueryVector ()" to compute the feature vector of the query image is also given in <ref> [2, 4, 5] </ref>. Let the query feature vector be given by F q . Since the matrix T [2, 4, 5] can easily be computed during the database population phase, the only on-line computations are those of b j ; 1 j m. <p> An algorithm called "ComputeQueryVector ()" to compute the feature vector of the query image is also given in <ref> [2, 4, 5] </ref>. Let the query feature vector be given by F q . Since the matrix T [2, 4, 5] can easily be computed during the database population phase, the only on-line computations are those of b j ; 1 j m. This is perfectly feasible since one has control over the dimension m of the representation space.
Reference: 5. <author> S. K. Choubey and V. V. Raghavan, </author> <title> "Generic and fully automatic content-based image retrieval using texture," </title> <booktitle> in International Conference on Imaging Science, Systems, and Applications (CISST'97), </booktitle> <address> (Las Vegas, Nevada), </address> <pages> pp. 228-237, </pages> <month> June-July </month> <year> 1997. </year>
Reference-contexts: We propose a generic and efficient feature-based CBIR architecture. This is based on the work done by Goldfarb [3] to bridge the gap between syntactic and statistical pattern recognition for classification problems. We have reported image retrieval specific to color only in [4] and image retrieval by texture in <ref> [5] </ref>. In this paper, we discuss the general architecture of our approach and provide preliminary experimental results for retrieval by color to show the effectiveness of the proposed approach. <p> ) can be isometrically represented in the Euclidean m (m = p + q)dimensional space iff the quadratic form given in Definition 2 is positive and of rank less than m. 4.2 Database Population Phase A procedure called "ComputeFeatureVector ()" to compute the feature vectors of images is given in <ref> [2, 4, 5] </ref>. This procedure also generates the training sample by calling "GenerateTrainingSet ()". This training sample is used to compute query feature vector and feature vectors for images in the incremental image set. <p> This training sample is used to compute query feature vector and feature vectors for images in the incremental image set. This procedure is executed during database population phase only and is also not given here due to space consideration. This algorithm can also be found in <ref> [2, 4, 5] </ref>. The execution of the ComputeFeatureVector () gives feature vectors of all the images in the initial set. Let these feature vectors be denoted by F 0 ; F 1 ; : : : ; F k1 . <p> Given the query image Q, one can readily determine the orthogonal projec-tion (w) of Q onto the vector representation space R (p;q) . An algorithm called "ComputeQueryVector ()" to compute the feature vector of the query image is also given in <ref> [2, 4, 5] </ref>. Let the query feature vector be given by F q . Since the matrix T [2, 4, 5] can easily be computed during the database population phase, the only on-line computations are those of b j ; 1 j m. <p> An algorithm called "ComputeQueryVector ()" to compute the feature vector of the query image is also given in <ref> [2, 4, 5] </ref>. Let the query feature vector be given by F q . Since the matrix T [2, 4, 5] can easily be computed during the database population phase, the only on-line computations are those of b j ; 1 j m. This is perfectly feasible since one has control over the dimension m of the representation space.
Reference: 6. <author> S. F. Chang, A. Eleftheriadis, and D. Anastassiou, </author> <title> "Development of Columbia's Video on Demand Testbed," </title> <journal> International Journal of Image Communication Signal Processing, </journal> <volume> vol. 8, no. 3, </volume> <pages> pp. 191-207, </pages> <year> 1996. </year>
Reference-contexts: The use of low-level features may make the information and storage retrieval system automatic but not necessarily efficient. Chang et al. <ref> [6] </ref> have used color as a discriminating feature for image retrieval. They use real distance between images to index the images in the image database. <p> For example, sunset can be described with the right percentage of the constituent colors of red, green, and blue. We have used an inter-image distance function for retrieval by image color content, also used by Faloutsos et al., Chang el al., and other researchers <ref> [6, 7, 13] </ref>.
Reference: 7. <author> C. Faloutsos et al., </author> <title> "Efficient and Effective Querying by Image Content," </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> vol. 3, no. 3, </volume> <pages> pp. 231-262, </pages> <year> 1994. </year>
Reference-contexts: For a given query, the images in the image database are ranked on the basis of real distance between the query image and the images in the image database. Hence the on-line retrieval is very computation intensive. Faloutsos et al. <ref> [7] </ref>, while using low-level features such as color, have tried to make it more efficient by using estimated distance instead of real distance. They reduce the search space by eliminating many images from consideration by using an estimated distance in such a way that a lower bound lemma is satisfied. <p> For example, sunset can be described with the right percentage of the constituent colors of red, green, and blue. We have used an inter-image distance function for retrieval by image color content, also used by Faloutsos et al., Chang el al., and other researchers <ref> [6, 7, 13] </ref>.
Reference: 8. <author> X. Wan and C. C. J. Kuo, </author> <title> "Color Space Quantization for Image Retrieval," in SPIE:Storage and Retrieval for Still Image and Video Database'96, </title> <address> (SanJose Cal-ifornia), </address> <month> February </month> <year> 1996. </year>
Reference-contexts: Thus, they can not use a nearest neighbor type search. Also the distance estimation is non-generic. This approach may end up computing real distance for a large proportion of original images. In <ref> [8] </ref>, the authors have tried to make the retrieval efficient at the cost of accuracy by reducing the image resolution (the process is called quantization).
Reference: 9. <author> L. Goldfarb, </author> <title> "A New Approach to Pattern Recognition," </title> <booktitle> in Progress in Machine Intelligence and Pattern Recognition, </booktitle> <editor> eds: L.N. Kanal and A. Rosenfeld, </editor> <volume> vol. 2, </volume> <publisher> North Holland Publishing Company, </publisher> <year> 1985. </year>
Reference-contexts: The proof of Theorem 1 is given in <ref> [9] </ref>.
Reference: 10. <author> M. R. Rosenzweig and L. W. Porter, eds., </author> <title> Multidimensional scaling, </title> <journal> vol. </journal> <volume> 31, </volume> <year> 1980. </year>
Reference-contexts: Euclidean distance between feature vectors F i and F q respectively of images O i and query image Q. 4.4 Discussion of Proposed Mapping Scheme Following are the advantages and motivation of using the proposed mapping scheme: Compared to multidimensional scaling (where the mapping is to and from vector representations) <ref> [10] </ref> this approach transforms original images into an intermediate representation to create inter-image distance matrix. Thus, the intermediate representation does not have to be a vector representation; it may be a string representation (in the case of shape representation) or involve other syntactic or structural representations.
Reference: 11. <author> T. Kohonen, </author> <title> "Self-Organized Formation of Topologically Correct Feature Maps," </title> <journal> Biological Cybernetics, </journal> <volume> vol. 43, </volume> <pages> pp. 59-69, </pages> <year> 1982. </year>
Reference-contexts: Interimage distance does not have to a metric. It may be pseudometric. This allows us to apply the mapping technique to a wider range of application areas. In neural networks (e.g., Kohonen's feature map <ref> [11, 12] </ref>), the mapped feature space is restricted to be low (1 to 3) dimensional. In our mapping, there is no such restriction. In Kohonen map [11, 12]), distances between all image pairs should be available at the start to construct the map. <p> This allows us to apply the mapping technique to a wider range of application areas. In neural networks (e.g., Kohonen's feature map <ref> [11, 12] </ref>), the mapped feature space is restricted to be low (1 to 3) dimensional. In our mapping, there is no such restriction. In Kohonen map [11, 12]), distances between all image pairs should be available at the start to construct the map. Hence, that technique can not support incremental addition of new images. 5 Experiments and Results A set of experiments using color was designed to test the retrieval effectiveness of the proposed method.
Reference: 12. <author> T. Kohonen, </author> <title> Self-Organization and Associative Memory. </title> <address> Berlin, Germany: </address> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference-contexts: Interimage distance does not have to a metric. It may be pseudometric. This allows us to apply the mapping technique to a wider range of application areas. In neural networks (e.g., Kohonen's feature map <ref> [11, 12] </ref>), the mapped feature space is restricted to be low (1 to 3) dimensional. In our mapping, there is no such restriction. In Kohonen map [11, 12]), distances between all image pairs should be available at the start to construct the map. <p> This allows us to apply the mapping technique to a wider range of application areas. In neural networks (e.g., Kohonen's feature map <ref> [11, 12] </ref>), the mapped feature space is restricted to be low (1 to 3) dimensional. In our mapping, there is no such restriction. In Kohonen map [11, 12]), distances between all image pairs should be available at the start to construct the map. Hence, that technique can not support incremental addition of new images. 5 Experiments and Results A set of experiments using color was designed to test the retrieval effectiveness of the proposed method.
Reference: 13. <author> A. K. Jain and A. Vailaya, </author> <title> "Image Retrieval Using Color and Shape," </title> <journal> Pattern Recognition, </journal> <volume> vol. 29, no. 8, </volume> <pages> pp. 1233-44, </pages> <year> 1996. </year>
Reference-contexts: For example, sunset can be described with the right percentage of the constituent colors of red, green, and blue. We have used an inter-image distance function for retrieval by image color content, also used by Faloutsos et al., Chang el al., and other researchers <ref> [6, 7, 13] </ref>.
Reference: 14. <author> P. Bollmann et al., </author> <title> "The LIVE-Project|Retrieval Experiments Based on Evaluation Viewpoints," </title> <booktitle> in ACM/SIGIR Conference on Research & Development in Information Retrieval, </booktitle> <address> (Montreal, Canada), </address> <pages> pp. 213-214, </pages> <month> June </month> <year> 1985. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: We have used R norm performance measure, which was first introduced in LIVE-Project <ref> [14] </ref> and is discussed in detail in [2]. 5.1 Results The result is tabulated in Table 1. Due to the limited space, only top fifteen retrieved images are shown in this table.
References-found: 14

