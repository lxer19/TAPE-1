URL: ftp://ftp.cs.huji.ac.il/users/transis/thesis/orni-msc.ps
Refering-URL: http://www.cs.huji.ac.il/labs/transis/thesis.html
Root-URL: http://www.cs.huji.ac.il
Title: PCODE: An Efficient and Reliable Collective Communication Protocol for Unreliable Broadcast Domains  
Author: Prof. Danny Dolev 
Degree: A thesis submitted in fulfillment of the requirements for the degree of Master of Science by Rimon Orni supervised by  
Date: August 11, 1994  
Address: Jerusalem, Israel.  
Affiliation: Institute of Computer Science The Hebrew University of Jerusalem  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> S. Ahuja, N. Carriero, and D. Gelernter. Linda and Friends. </author> <booktitle> Computer, </booktitle> <pages> pages 26-34, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: This enables easy handling of machine failure, as well as load balancing, but slows down the communication considerably. This model is more restricted than shared memory or message passing models, since it does not enable communication among the slaves. Work distribution and replication paradigms are used also in Linda <ref> [1] </ref> and in DIB [20]. Linda uses a virtual tuple space with limited operations to create a model suited mainly for replicated worker applications, where the workers are very much independent of each other.
Reference: [2] <author> Y. Amir, D. Dolev, S. Kramer, and D. Malki. Transis: </author> <title> A Communication SubSystem for High Availability. </title> <booktitle> In 22nd Annual International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 76-84, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [15], ISIS [11, 10], Psync [29], Amoeba [25], 4 Trans [27], Transis <ref> [2] </ref> and Totem [3] (see Section 2). However, we have observed that the properties required from the user-communication layer while devising the known reliable broadcast protocols for distributed systems are different from the properties required from the user-communication layer associated with parallel systems. <p> The V system actually defines reliability as having the message received by at least one recipient. Any higher level of reliability (k-reliability ) must be implemented at the application level. On the other hand the Transis <ref> [2] </ref> and ISIS [11, 10] systems provide full reliability, i.e. either the message is received by all its destinations, or it is received by none (This property is also called message atomicity). <p> Most distributed applications require some degree of message ordering, usually the minimal requirement is causal order, and often total ordering is necessary <ref> [11, 2, 29, 27] </ref>. In our model, the only ordering required from the transport layer is FIFO order from sender (Property 2). The order among concurrent messages is set by the order of requests derived from the Global Program. <p> Therefore when the difference between the minimum and the maximum on gcv is greater than a FLOW WINDOW size, P myid will stop sending, until the difference decreases (Figure 16, Lines 4 to 6). FLOW WINDOW is a tunable size (See <ref> [2] </ref> regarding flow windows). Note that the difference between the minimum and maximum will also be large when the user communication layer on a processor is not initiating the sending of messages. <p> This scheme is much faster than having each sender send in turn. Finally, the work in [28] shows that the performance of PCODE is comparable to that of general reliable broadcast systems such as Transis <ref> [2] </ref> and Horus [33].
Reference: [3] <author> Y. Amir, L. E. Moser, P. M. Melliar-Smith, D. A. Agarwal, and P. Ciarfella. </author> <title> Fast Message Ordering and Membership Using a Logical Token-Passing Ring. </title> <booktitle> In Intl. Conference on Distributed Computing Systems, </booktitle> <pages> pages 551-560, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [15], ISIS [11, 10], Psync [29], Amoeba [25], 4 Trans [27], Transis [2] and Totem <ref> [3] </ref> (see Section 2). However, we have observed that the properties required from the user-communication layer while devising the known reliable broadcast protocols for distributed systems are different from the properties required from the user-communication layer associated with parallel systems. <p> Peterson et. al. [29] and Melliar-Smith et. al. [27] both suggested protocols based on the happened-before or causal ordering of messages (see [26]). These protocols provide reliable broadcast hand in hand with the causal ordering. The Totem protocol by Amir et. al. <ref> [3] </ref> uses a virtual token ring scheme to obtain reliable broadcast, and so achieves total order (which includes the causal order) at no further cost. Further protocols have been suggested to provide total ordering of messages over reliable broadcast [27, 29, 16].
Reference: [4] <author> J. Backus, J. Williams, E. Wimmers, P. Lucas, and A. Aiken. </author> <title> FL Language Manual. </title> <institution> Research Report RJ7100, IBM, </institution> <month> Sep </month> <year> 1989. </year> <note> Parts 1 and 2. </note>
Reference-contexts: The scaffolding provides a console interface, benchmark testing using a script from a text file, and simple statistical measurement. The scaffolding is written in a very high level subset of the functional language FL <ref> [4] </ref> and is intended for ease of use and debugging rather than high performance.
Reference: [5] <author> H. E. Bal, M. F. Kaashoek, and A. S. Tanenbaum. Orca: </author> <title> A Language For Parallel Programming of Distributed Systems. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 18 </volume> <pages> 190-205, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Parallel computing on clusters of workstations and personal computers has very high potential, since it leverages existing hardware and software. In fact, there are a number of existing commercial parallel programming environments that can run on top of clusters of workstations <ref> [6, 22, 30, 5, 14] </ref> (see Section 2). Parallel programming environments offer the user a convenient way for expressing parallel computation and communication. In the message passing paradigm (see [19]) the communication part consists of regular point-to-point communication as well as collective communication. <p> ORCA <ref> [5] </ref> is a language which provides a virtual shared memory machine. The programmer using the top level language writes as if the machine has a shared memory, by using shared objects. Nevertheless, the language is implemented to run over a network.
Reference: [6] <author> V. Bala, J. Bruck, R. Bryant, R. Cypher, P. de Jong, P. Elustondo, D. Frye, A. Ho, C. T. Ho, G. Irwin, S. Kipnis, R. Lawrence, and M. Snir. </author> <title> The IBM External User Interface for Scalable Parallel Systems. </title> <institution> Research Report RC19048, IBM, </institution> <month> July </month> <year> 1993. </year> <note> To appear in Parallel Computing. </note>
Reference-contexts: 1 Introduction Parallel computing on clusters of workstations and personal computers has very high potential, since it leverages existing hardware and software. In fact, there are a number of existing commercial parallel programming environments that can run on top of clusters of workstations <ref> [6, 22, 30, 5, 14] </ref> (see Section 2). Parallel programming environments offer the user a convenient way for expressing parallel computation and communication. In the message passing paradigm (see [19]) the communication part consists of regular point-to-point communication as well as collective communication.
Reference: [7] <author> V. Bala, J. Bruck, R. Cypher, P. Elustondo, A. Ho, C. T. Ho, S. Kipnis, and M. Snir. </author> <title> CCL: A portable and tunable collective communication library for scalable parallel computers. </title> <institution> Research Report RJ9284, IBM, </institution> <month> April </month> <year> 1993. </year> <note> To appear in IEEE Trans. on Parallel and Distributed Computing. </note>
Reference-contexts: Collective communication routines can operate over the entire set of processes that are created at the beginning of an application or over user-specified groups of processes <ref> [7, 19] </ref>. The difference between a parallel machine of the multicomputer type and a cluster of machines is in the hardware implementation of the communication.
Reference: [8] <author> B. N. Bershad, M. J. Zekauskas, and W. A. Sawdon. </author> <title> The Midway Distributed Shared Memory System. </title> <booktitle> In Computer Conference, </booktitle> <year> 1993. </year>
Reference-contexts: These guarantees are of the type required by distributed systems, as discussed in the previous section. Where possible, both Panda and Amoeba will make use of the broadcast capabilities of the network. 8 Other Distributed Shared Memory systems such as Munin and Midway <ref> [13, 8] </ref> sup-port parallel programming over networks by providing a shared memory abstraction that hides all message passing from the programmer. Another package for distributed parallel programming over networks is Marionette [31], which uses the master slave model.
Reference: [9] <author> R. Bhoedjang, T. Ruhl, R. Hofman, K. Langendoen, H. Bal, and M. F. Kaashoek. Panda: </author> <title> A Portable Platform to Support Parallel Programming Languages. In Symposium on Experiences with Distributed and Multiprocessor Systems IV, </title> <address> San Diego, </address> <pages> pages 213-226, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: It has already been tested running over Horus [33] as the reliable broadcast layer. Further work described in <ref> [9] </ref> has been done to provide a general layer for porting parallel programming languages.
Reference: [10] <author> K. P. Birman, R. Cooper, and B. Gleeson. </author> <title> Programming with Process Groups: Group and Multicast Semantics. </title> <type> TR 91-1185, </type> <institution> dept. of Computer Science, Cornell University, </institution> <month> Jan </month> <year> 1991. </year>
Reference-contexts: In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [15], ISIS <ref> [11, 10] </ref>, Psync [29], Amoeba [25], 4 Trans [27], Transis [2] and Totem [3] (see Section 2). <p> The V system actually defines reliability as having the message received by at least one recipient. Any higher level of reliability (k-reliability ) must be implemented at the application level. On the other hand the Transis [2] and ISIS <ref> [11, 10] </ref> systems provide full reliability, i.e. either the message is received by all its destinations, or it is received by none (This property is also called message atomicity).
Reference: [11] <author> K. P. Birman, R. Cooper, T. A. Joseph, K. Marzullo, M. Makpangou, K. Kane, F. Schmuck, and M. Wood. </author> <title> The ISIS System Manual. </title> <institution> Dept of Computer Science, Cornell University, </institution> <month> Sep 90. 32 </month>
Reference-contexts: In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [15], ISIS <ref> [11, 10] </ref>, Psync [29], Amoeba [25], 4 Trans [27], Transis [2] and Totem [3] (see Section 2). <p> The V system actually defines reliability as having the message received by at least one recipient. Any higher level of reliability (k-reliability ) must be implemented at the application level. On the other hand the Transis [2] and ISIS <ref> [11, 10] </ref> systems provide full reliability, i.e. either the message is received by all its destinations, or it is received by none (This property is also called message atomicity). <p> Most distributed applications require some degree of message ordering, usually the minimal requirement is causal order, and often total ordering is necessary <ref> [11, 2, 29, 27] </ref>. In our model, the only ordering required from the transport layer is FIFO order from sender (Property 2). The order among concurrent messages is set by the order of requests derived from the Global Program.
Reference: [12] <author> K. P. Birman and T. Joseph. </author> <title> Exploiting Virtual Synchrony in Distributed Sys--tems. </title> <booktitle> In 11th Ann. Symp. Operating Systems Principles, </booktitle> <pages> pages 123-138, </pages> <month> Nov 87. </month>
Reference-contexts: The ISIS system of Birman and Joseph is one of the leading systems in the area of group communication. It was the first system to provide the virtual synchrony <ref> [12] </ref> property. A new version of ISIS, called Horus, is currently being designed. Apart from being based on more efficient protocols for message recovery, ordering and flow control, Horus has the advantage of being constructed in layers, which the programmer can use in almost any configuration.
Reference: [13] <author> J. B. Carter, J. K. Bennett, and W. Zwaenepoel. </author> <title> Implementation and Performance of Munin. </title> <booktitle> In Proc. of the Thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 152-164, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: These guarantees are of the type required by distributed systems, as discussed in the previous section. Where possible, both Panda and Amoeba will make use of the broadcast capabilities of the network. 8 Other Distributed Shared Memory systems such as Munin and Midway <ref> [13, 8] </ref> sup-port parallel programming over networks by providing a shared memory abstraction that hides all message passing from the programmer. Another package for distributed parallel programming over networks is Marionette [31], which uses the master slave model.
Reference: [14] <author> C. M. Chase, A. L. Cheung, A. P. Reeves, and M. R. Smith. </author> <title> Paragon: A Parallel Programming Environment for Scientific Aplications Using Communications Structures. </title> <booktitle> In Proc. of the International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Parallel computing on clusters of workstations and personal computers has very high potential, since it leverages existing hardware and software. In fact, there are a number of existing commercial parallel programming environments that can run on top of clusters of workstations <ref> [6, 22, 30, 5, 14] </ref> (see Section 2). Parallel programming environments offer the user a convenient way for expressing parallel computation and communication. In the message passing paradigm (see [19]) the communication part consists of regular point-to-point communication as well as collective communication. <p> The communication operations are in the SPMD (Single Program Multiple Data) model, so that each such operation must be called from all the nodes in use. Another high level library implemented over PVM is Paragon <ref> [14] </ref> which supports parallel processing in the data parallel paradigm, using communication structures 9 which enable explicit specification of the communication patterns in the program. The Zipcode message passing system [30] supports group communication as well as virtual topologies for logical grids.
Reference: [15] <author> D. R. Cheriton and W. Zwaenepoel. </author> <title> Distributed Process Groups in the V Kernel. </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> 2(3) </volume> <pages> 77-107, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: Reliable broadcast in distributed systems is a topic that has been studied extensively for more than a decade [24]. In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system <ref> [15] </ref>, ISIS [11, 10], Psync [29], Amoeba [25], 4 Trans [27], Transis [2] and Totem [3] (see Section 2). <p> Further protocols have been suggested to provide total ordering of messages over reliable broadcast [27, 29, 16]. Among the systems which have actually been implemented to provide reliable group communication, there are two major approaches. In the V system <ref> [15] </ref> and in Psync [29] the system guarantees for reliability are relatively weak, and most of the work of recovery (in V system) and ordering is passed on to the application. The V system actually defines reliability as having the message received by at least one recipient.
Reference: [16] <author> D. Dolev, S. Kramer, and D. Malki. </author> <title> Early Delivery Totally Ordered Broadcast in Asynchronous Environments. </title> <booktitle> In 23rd Annual International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 544-553, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: The Totem protocol by Amir et. al. [3] uses a virtual token ring scheme to obtain reliable broadcast, and so achieves total order (which includes the causal order) at no further cost. Further protocols have been suggested to provide total ordering of messages over reliable broadcast <ref> [27, 29, 16] </ref>. Among the systems which have actually been implemented to provide reliable group communication, there are two major approaches.
Reference: [17] <author> D. Dolev, R. Strong, and E. Wimmers. </author> <title> Experience with RAPID Prototypes. </title> <type> Research Report, </type> <institution> IBM, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: This normalization enables us to compare the performance while changing the number of machines. 7.3 RAPID To facilitate debugging, testing, and measurement of the transport layer, we implemented a driver scaffolding in RAPID, an environment for rapid prototyping of distributed protocols <ref> [18, 17] </ref>. The scaffolding provides a console interface, benchmark testing using a script from a text file, and simple statistical measurement. The scaffolding is written in a very high level subset of the functional language FL [4] and is intended for ease of use and debugging rather than high performance.
Reference: [18] <author> D. Dolev, R. Strong, and E. Wimmers. </author> <title> RAPID: An Environment for Rapid Prototyping of Distributed Protocols. </title> <type> Research Report, </type> <institution> IBM, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: This normalization enables us to compare the performance while changing the number of machines. 7.3 RAPID To facilitate debugging, testing, and measurement of the transport layer, we implemented a driver scaffolding in RAPID, an environment for rapid prototyping of distributed protocols <ref> [18, 17] </ref>. The scaffolding provides a console interface, benchmark testing using a script from a text file, and simple statistical measurement. The scaffolding is written in a very high level subset of the functional language FL [4] and is intended for ease of use and debugging rather than high performance.
Reference: [19] <author> J. J. Dongarra, R. Hempel, A. J. G. Hey, and D. W. Walker. </author> <title> A Proposal for a User-Level Message Passing Interface in a Distributed Memory Environment. </title> <journal> TR ORNL/TM-12231, </journal> <volume> ORNL, </volume> <month> March </month> <year> 1993. </year>
Reference-contexts: Parallel programming environments offer the user a convenient way for expressing parallel computation and communication. In the message passing paradigm (see <ref> [19] </ref>) the communication part consists of regular point-to-point communication as well as collective communication. Examples of collective communication operations include one-to-all broadcast, all-to-all broadcast, global combine operation, scatter and gather. The need for collective communication arises frequently in parallel computation. <p> Collective communication routines can operate over the entire set of processes that are created at the beginning of an application or over user-specified groups of processes <ref> [7, 19] </ref>. The difference between a parallel machine of the multicomputer type and a cluster of machines is in the hardware implementation of the communication.
Reference: [20] <author> R. Finkel and U. Manber. </author> <title> A Distributed Implementation of Backtracking. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(2) </volume> <pages> 235-256, </pages> <year> 1987. </year>
Reference-contexts: This model is more restricted than shared memory or message passing models, since it does not enable communication among the slaves. Work distribution and replication paradigms are used also in Linda [1] and in DIB <ref> [20] </ref>. Linda uses a virtual tuple space with limited operations to create a model suited mainly for replicated worker applications, where the workers are very much independent of each other.
Reference: [21] <author> G. Fox, M. Johnson, G. Lyzenga, S. Otto, J. Salmon, and D. Walker. </author> <title> Solving Problems on Concurrent Processors, volume I: General Techniques and Regular Problems. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1988. </year>
Reference-contexts: In particular, collective communication is extensively used in many scientific applications for which the interleaving of stages of local computations with stages of global communication is possible (see <ref> [21] </ref>). Collective communication routines can operate over the entire set of processes that are created at the beginning of an application or over user-specified groups of processes [7, 19].
Reference: [22] <author> G. A. Geist, M. T. Heath, B. W. Peyton, and P. H. Worley. </author> <title> A user's guide to PICL: a Portable Instrumented Communication Library. </title> <journal> TR ORNL/TM-11616, </journal> <volume> ORNL, </volume> <month> October </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Parallel computing on clusters of workstations and personal computers has very high potential, since it leverages existing hardware and software. In fact, there are a number of existing commercial parallel programming environments that can run on top of clusters of workstations <ref> [6, 22, 30, 5, 14] </ref> (see Section 2). Parallel programming environments offer the user a convenient way for expressing parallel computation and communication. In the message passing paradigm (see [19]) the communication part consists of regular point-to-point communication as well as collective communication. <p> The underlying communication of the PVM package is implemented using point to point UDP with recursive doubling, even when broadcasting messages to the complete set of machines. This approach can slow down performance significantly as the number of participating machines rises. The PICL parallel programming language <ref> [22] </ref> has been ported over PVM to enable PICL to run over network based multiprocessing environments [23]. PICL provides routines for high level communication operations, such as global summation or global maximum.
Reference: [23] <author> G. A. Geist and V. S. Sunderam. </author> <title> Network-Based Concurrent Computing on the PVM System. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 4(4) </volume> <pages> 293-311, </pages> <month> June </month> <year> 1992. </year> <month> 33 </month>
Reference-contexts: This approach can slow down performance significantly as the number of participating machines rises. The PICL parallel programming language [22] has been ported over PVM to enable PICL to run over network based multiprocessing environments <ref> [23] </ref>. PICL provides routines for high level communication operations, such as global summation or global maximum. The model requires a designated host which will load and run the program on all the other nodes, which will then run the actual application.
Reference: [24] <author> V. Hadzilacos and S. Toueg. </author> <title> Fault-Tolerant Broadcasts and Related Problems. In Sape Mullender, editor, chapter in: Distributed Systems. </title> <publisher> ACM Press, </publisher> <year> 1993. </year>
Reference-contexts: The challenge in achieving this goal is that the LAN-communication facility within a broadcast domain, typically a User Datagram Protocol (UDP), is unreliable. Reliable broadcast in distributed systems is a topic that has been studied extensively for more than a decade <ref> [24] </ref>. In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [15], ISIS [11, 10], Psync [29], Amoeba [25], 4 Trans [27], Transis [2] and Totem [3] (see Section 2).
Reference: [25] <author> M. F. Kaashoek and A. S. Tanenbaum. </author> <title> Group Communication in the Amoeba Distributed Operating System. </title> <booktitle> In 11th Intl. Conference on Distributed Computing Systems, </booktitle> <pages> pages 882-891, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [15], ISIS [11, 10], Psync [29], Amoeba <ref> [25] </ref>, 4 Trans [27], Transis [2] and Totem [3] (see Section 2). However, we have observed that the properties required from the user-communication layer while devising the known reliable broadcast protocols for distributed systems are different from the properties required from the user-communication layer associated with parallel systems. <p> The Panda interface supports group communication, among other things. The group communication of Panda has the same guarantees as that of Amoeba <ref> [25] </ref>, and is based on the same protocols. These guarantees are of the type required by distributed systems, as discussed in the previous section.
Reference: [26] <author> L. Lamport. </author> <title> Time, Clocks, and the Ordering of Events in a Distributed System. </title> <journal> Comm. ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July 78. </month>
Reference-contexts: Peterson et. al. [29] and Melliar-Smith et. al. [27] both suggested protocols based on the happened-before or causal ordering of messages (see <ref> [26] </ref>). These protocols provide reliable broadcast hand in hand with the causal ordering. The Totem protocol by Amir et. al. [3] uses a virtual token ring scheme to obtain reliable broadcast, and so achieves total order (which includes the causal order) at no further cost.
Reference: [27] <author> P. M. Melliar-Smith, L. E. Moser, and V. Agrawala. </author> <title> Broadcast Protocols for Distributed Systems. </title> <journal> IEEE Trans. Parallel & Distributed Syst., </journal> <volume> 1(1) </volume> <pages> 17-25, </pages> <month> Jan </month> <year> 1990. </year>
Reference-contexts: In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [15], ISIS [11, 10], Psync [29], Amoeba [25], 4 Trans <ref> [27] </ref>, Transis [2] and Totem [3] (see Section 2). However, we have observed that the properties required from the user-communication layer while devising the known reliable broadcast protocols for distributed systems are different from the properties required from the user-communication layer associated with parallel systems. <p> Peterson et. al. [29] and Melliar-Smith et. al. <ref> [27] </ref> both suggested protocols based on the happened-before or causal ordering of messages (see [26]). These protocols provide reliable broadcast hand in hand with the causal ordering. <p> The Totem protocol by Amir et. al. [3] uses a virtual token ring scheme to obtain reliable broadcast, and so achieves total order (which includes the causal order) at no further cost. Further protocols have been suggested to provide total ordering of messages over reliable broadcast <ref> [27, 29, 16] </ref>. Among the systems which have actually been implemented to provide reliable group communication, there are two major approaches. <p> Most distributed applications require some degree of message ordering, usually the minimal requirement is causal order, and often total ordering is necessary <ref> [11, 2, 29, 27] </ref>. In our model, the only ordering required from the transport layer is FIFO order from sender (Property 2). The order among concurrent messages is set by the order of requests derived from the Global Program.
Reference: [28] <author> R. Orni. </author> <title> A Comparative Work on the Performance of PCODE, </title> <month> August </month> <year> 1994. </year> <institution> The Hebrew University of Jerusalem, Lab Project. </institution>
Reference-contexts: Therefore we may say that the above results take into account up to a 3% message loss. Further tests that have been done in separate work <ref> [28] </ref> shows that changing the IPC in PCODE from message queues and shared memory to TCP sockets can improve the performance significantly. <p> This scheme is much faster than having each sender send in turn. Finally, the work in <ref> [28] </ref> shows that the performance of PCODE is comparable to that of general reliable broadcast systems such as Transis [2] and Horus [33].
Reference: [29] <author> L. L. Peterson, N. C. Bucholtz, and R. D. Schlichting. </author> <title> Preserving and Using Context Information in Interprocess Communication. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 7(3) </volume> <pages> 217-246, </pages> <year> 1989. </year>
Reference-contexts: In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [15], ISIS [11, 10], Psync <ref> [29] </ref>, Amoeba [25], 4 Trans [27], Transis [2] and Totem [3] (see Section 2). However, we have observed that the properties required from the user-communication layer while devising the known reliable broadcast protocols for distributed systems are different from the properties required from the user-communication layer associated with parallel systems. <p> The problem with using the broadcast capability of the network directly, is that it is usually unreliable a message is not guaranteed to arrive at all of its destinations. 6 Several protocols have been suggested to provide reliable group communication over an unreliable network. Peterson et. al. <ref> [29] </ref> and Melliar-Smith et. al. [27] both suggested protocols based on the happened-before or causal ordering of messages (see [26]). These protocols provide reliable broadcast hand in hand with the causal ordering. <p> The Totem protocol by Amir et. al. [3] uses a virtual token ring scheme to obtain reliable broadcast, and so achieves total order (which includes the causal order) at no further cost. Further protocols have been suggested to provide total ordering of messages over reliable broadcast <ref> [27, 29, 16] </ref>. Among the systems which have actually been implemented to provide reliable group communication, there are two major approaches. <p> Further protocols have been suggested to provide total ordering of messages over reliable broadcast [27, 29, 16]. Among the systems which have actually been implemented to provide reliable group communication, there are two major approaches. In the V system [15] and in Psync <ref> [29] </ref> the system guarantees for reliability are relatively weak, and most of the work of recovery (in V system) and ordering is passed on to the application. The V system actually defines reliability as having the message received by at least one recipient. <p> Most distributed applications require some degree of message ordering, usually the minimal requirement is causal order, and often total ordering is necessary <ref> [11, 2, 29, 27] </ref>. In our model, the only ordering required from the transport layer is FIFO order from sender (Property 2). The order among concurrent messages is set by the order of requests derived from the Global Program.
Reference: [30] <author> A. Skjellum, S. G. Smith, A. P. Leung, and M Morari. </author> <title> The Design and Evolution of Zipcode. </title> <booktitle> In Parallel Computing, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Parallel computing on clusters of workstations and personal computers has very high potential, since it leverages existing hardware and software. In fact, there are a number of existing commercial parallel programming environments that can run on top of clusters of workstations <ref> [6, 22, 30, 5, 14] </ref> (see Section 2). Parallel programming environments offer the user a convenient way for expressing parallel computation and communication. In the message passing paradigm (see [19]) the communication part consists of regular point-to-point communication as well as collective communication. <p> Another high level library implemented over PVM is Paragon [14] which supports parallel processing in the data parallel paradigm, using communication structures 9 which enable explicit specification of the communication patterns in the program. The Zipcode message passing system <ref> [30] </ref> supports group communication as well as virtual topologies for logical grids. Zipcode is portable today on a range of multicom-puter platforms, including workstation networks. The communication on networks is done either using the above mentioned PVM, or directly over TCP/IP.
Reference: [31] <author> M. Sullivan and D. Anderson. Marionette: </author> <title> a System for Parallel Distributed Programming Using a Master/Slave Model. </title> <booktitle> In Proc. of the 9th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 181-188, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Another package for distributed parallel programming over networks is Marionette <ref> [31] </ref>, which uses the master slave model. The master process can invoke worker operations which will run on the slave machines, or context operations which will update the slaves' states.
Reference: [32] <author> V. Sunderam. </author> <title> PVM: a Framework for Parallel Distributed Computing. </title> <journal> Concur-rency: Practice and Experience, </journal> <volume> 2(4), </volume> <month> December </month> <year> 1990. </year>
Reference-contexts: Both these systems are relatively portable, and can be run over networked processors as well as different parallel machines. When the machine doesn't have a real shared memory, message passing will be used instead. Both systems support machine fault tolerance. PVM <ref> [32] </ref> Parallel Virtual Machine, is a widely used software package which is highly portable. It can run over different parallel machine architectures as well as over loosely coupled networks. Unlike the systems described so far, PVM supports the message passing paradigm of parallel languages.

References-found: 32

