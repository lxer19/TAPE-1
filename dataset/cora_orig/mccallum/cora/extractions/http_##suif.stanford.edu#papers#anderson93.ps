URL: http://suif.stanford.edu/papers/anderson93.ps
Refering-URL: http://suif.stanford.edu/papers/papers.html
Root-URL: 
Title: Global Optimizations for Parallelism and Locality on Scalable Parallel Machines  
Author: Jennifer M. Anderson and Monica S. Lam 
Address: CA 94305  
Affiliation: Computer Systems Laboratory Stanford University,  
Abstract: Data locality is critical to achievinghigh performance on large-scale parallel machines. Non-local data accesses result in communication that can greatly impact performance. Thus the mapping, or decomposition, of the computation and data onto the processors of a scalable parallel machine is a key issue in compiling programs for these architectures. This paper describes a compiler algorithm that automatically finds computation and data decompositions that optimize both parallelism and locality. This algorithm is designed for use with both distributed and shared address space machines. The scope of our algorithm is dense matrix computations where the array accesses are affine functions of the loop indices. Our algorithm can handle programs with general nestings of parallel and sequential loops. We present a mathematical framework that enables us to systematically derive the decompositions. Our algorithm can exploit parallelism in both fully parallelizable loops as well as loops that require explicit synchronization. The algorithm will trade off extra degrees of parallelism to eliminate communication. If communication is needed, the algorithm will try to introduce the least expensive forms of communication into those parts of the program that are least frequently executed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. R. Allen and K. Kennedy. </author> <title> Automatic translation of Fortran programs to vector form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: We refer to such loop-level techniques as local analysis. The global analysis is responsible for optimizing parallelism and locality across multiple loop nests. First, our compiler normalizes the loops and performs loop distribution before executing the decomposition algorithms <ref> [1] </ref>. The compiler runs a loop fusion pass after decomposition to regroup compatible loop nests [5, 10]. Our compiler uses the algorithm developed by Wolf and Lam [25, 36] to apply unimodular transforms to find the coarsest granularity of parallelism within a loop nest.
Reference: [2] <author> S. P. Amarasinghe and M. S. Lam. </author> <title> Communication optimization and code generation for distributed memory machines. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: This algorithm is designed for use with both distributed and shared address space machines. For machines with a distributed address space, the compiler must follow this phase with a pass that maps the decomposition to explicit communication code <ref> [2] </ref>. While it is not necessary to manage the memory directly for machines with a shared address space, many of the techniques used to manage data on distributed memory machines can be used to improve cache performance. <p> Our code generator for distributed address space machines uses data-flow analysis on individual array accesses to find efficient communication when the data moves within a loop nest <ref> [2] </ref>. 6 Dynamic Decompositions In this section we solve the problem of finding data and computation decompositions that maximize parallelism when both data reorganization and pipeline communication are allowed.
Reference: [3] <author> C. Ancourt and F. Irigoin. </author> <title> Scanning polyhedra with DO loops. </title> <booktitle> In Proceedings of the Third ACM/SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 39-50, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: This partition means that elements along the diagonal are allocated to the same processor. In general, when the array index functions are not invertible, we must introduce auxiliary variables and use a pseudo-inverse function. The techniques we use are similar to those presented in other literature <ref> [3, 29] </ref>. This analysis is run on all pairs of arrays involved in a cycle in the interference graph (including the degenerate case of multiple access functions for one array in a loop nest).
Reference: [4] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kremer. </author> <title> A static performance estimator to guide data partitioning decisions. </title> <booktitle> In Proceedings of the Third ACM/SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 213-222, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Carle et. al. have developed an interactive tool, as part of the Fortran D project, that finds data decompositions within and across phases of a procedure [6]. Data can be remapped dynamically between phases. Their approach uses a static performance estimator <ref> [4] </ref> to select the best decompositions among a fixed set of choices. In comparison, our algorithm avoids expensive searches by systematically calculating the decompositions.
Reference: [5] <author> D. Callahan. </author> <title> A Global Approach to Detection of Parallelism. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> April </month> <year> 1987. </year> <note> Published as COMP-TR-87-50. </note>
Reference-contexts: The global analysis is responsible for optimizing parallelism and locality across multiple loop nests. First, our compiler normalizes the loops and performs loop distribution before executing the decomposition algorithms [1]. The compiler runs a loop fusion pass after decomposition to regroup compatible loop nests <ref> [5, 10] </ref>. Our compiler uses the algorithm developed by Wolf and Lam [25, 36] to apply unimodular transforms to find the coarsest granularity of parallelism within a loop nest. This pass leaves the loop nests in a canonical form consisting of a nest of fully permutable loop nests.
Reference: [6] <author> A. Carle, K. Kennedy, U. Kremer, and J. Mellor-Crummey. </author> <title> Automatic data layout for distributed-memory machines in the D programming environment. </title> <type> Technical Report CRPC-TR93-298, </type> <institution> Rice University, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: Their approach is based on an exhaustive search through various possible decompositions using a system of cost estimates. Carle et. al. have developed an interactive tool, as part of the Fortran D project, that finds data decompositions within and across phases of a procedure <ref> [6] </ref>. Data can be remapped dynamically between phases. Their approach uses a static performance estimator [4] to select the best decompositions among a fixed set of choices. In comparison, our algorithm avoids expensive searches by systematically calculating the decompositions.
Reference: [7] <author> B. Chapman, P. Mehrotra, and H. Zima. </author> <title> Programming in Vienna Fortran. </title> <journal> Scientific Programming, </journal> <volume> 1(1) </volume> <pages> 31-50, </pages> <month> Fall </month> <year> 1992. </year>
Reference-contexts: A popular approach to this complex optimization problem is to solicit the programmer's help in determining the data decompositions. Projects using this approach include SUPERB [40], AL [34], ID Noveau [31], Kali [22], Vienna Fortran <ref> [7] </ref> and Fortran D [14, 33]. The current proposal for a High Performance Fortran extension to Fortran 90 also relies upon user-specified data decompositions [13].
Reference: [8] <author> S. Chatterjee, J. R. Gilbert, R. Schreiber, and S.-H. Teng. </author> <title> Automatic array alignment in data-parallel programs. </title> <booktitle> In Proceedings, 20th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 16-28, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Their algorithm works by first calculating the projection vector, which is similar to what we call the partition, of the computation mapping. Many projects have examined the problem of finding array alignments (what we call data orientations and displacements) for data parallel programs <ref> [8, 11, 21, 30, 35] </ref>. These approaches focus on element-wise array operations, and try to eliminate the communication between consecutive loops.
Reference: [9] <author> E. Dahlhaus, D. S. Johnson, C. H. Papadimitriou, P. D. Sey-mour, and M. Yannakakis. </author> <title> The complexity of multiway cuts. </title> <booktitle> In Proceedings of the 24th ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 241-251, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Figures 5 (b) and (c) illustrate the final decompositions for this example, and are discussed in the next section. Theorem 6.1 The dynamic decomposition problem is NP-hard. Proof: We prove the dynamic decomposition problem NP-hard by transforming the known NP-hard problem, Colored Multiway Cut <ref> [9] </ref>, into a subproblem of this problem.
Reference: [10] <author> G. R. Gao, R. Olsen, V. Sarkar, and R. Thekkath. </author> <title> Collective loop fusion for array contraction. </title> <booktitle> In Proceedings of the Fifth Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 171-181, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: The global analysis is responsible for optimizing parallelism and locality across multiple loop nests. First, our compiler normalizes the loops and performs loop distribution before executing the decomposition algorithms [1]. The compiler runs a loop fusion pass after decomposition to regroup compatible loop nests <ref> [5, 10] </ref>. Our compiler uses the algorithm developed by Wolf and Lam [25, 36] to apply unimodular transforms to find the coarsest granularity of parallelism within a loop nest. This pass leaves the loop nests in a canonical form consisting of a nest of fully permutable loop nests.
Reference: [11] <author> J. R. Gilbert and R. Schreiber. </author> <title> Optimal expression evaluation for data parallel architectures. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13(1) </volume> <pages> 58-64, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Their algorithm works by first calculating the projection vector, which is similar to what we call the partition, of the computation mapping. Many projects have examined the problem of finding array alignments (what we call data orientations and displacements) for data parallel programs <ref> [8, 11, 21, 30, 35] </ref>. These approaches focus on element-wise array operations, and try to eliminate the communication between consecutive loops.
Reference: [12] <author> M. Gupta and P. Banerjee. </author> <title> Demonstration of automatic data partitioning techniques for parallelizing compilers on multi-computers. </title> <journal> Transactions on Parallel and Distributed Systems, </journal> <volume> 3(2) </volume> <pages> 179-193, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Several researchers have developed data decomposition algorithms based on searching through a fixed set of possible decompositions. Gupta and Banerjee have developed an algorithm for automatically finding a static data decomposition <ref> [12] </ref>. Their approach is based on an exhaustive search through various possible decompositions using a system of cost estimates. Carle et. al. have developed an interactive tool, as part of the Fortran D project, that finds data decompositions within and across phases of a procedure [6].
Reference: [13] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification, </title> <month> November </month> <year> 1992. </year> <note> Version 0.4. </note>
Reference-contexts: Projects using this approach include SUPERB [40], AL [34], ID Noveau [31], Kali [22], Vienna Fortran [7] and Fortran D [14, 33]. The current proposal for a High Performance Fortran extension to Fortran 90 also relies upon user-specified data decompositions <ref> [13] </ref>. While these languages provide significant benefit to the programmer by eliminating the tedious job of managing the distributed memory explicitly, the programmer is still faced with a very difficult programming problem.
Reference: [14] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Compiling Fortran D for MIMD distributed-memory machines. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: A popular approach to this complex optimization problem is to solicit the programmer's help in determining the data decompositions. Projects using this approach include SUPERB [40], AL [34], ID Noveau [31], Kali [22], Vienna Fortran [7] and Fortran D <ref> [14, 33] </ref>. The current proposal for a High Performance Fortran extension to Fortran 90 also relies upon user-specified data decompositions [13]. <p> The nodes in the graph correspond to the loop nests in the program. The edges in the graph represent places in the program where data reorganization communication can occur. The edges in the graph are calculated using information that is similar to the reaching decompositions <ref> [14, 33] </ref> used in the Fortran D compiler. In Fortran D, the reaching decompositions are defined to be the set of decomposition statements that may reach an array reference that uses the decomposition. In our case, all loop nests may define a decomposition.
Reference: [15] <author> C. H. Huang and P. Sadayappan. </author> <title> Communication-free hyper-plane positioning of nested loops. </title> <editor> In U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 186-200. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany, </address> <year> 1992. </year>
Reference-contexts: A number of researchers have also looked at the specific problem of mapping a single loop nest onto parallel machines <ref> [15, 23, 24] </ref>. We refer to such loop-level techniques as local analysis. The global analysis is responsible for optimizing parallelism and locality across multiple loop nests. First, our compiler normalizes the loops and performs loop distribution before executing the decomposition algorithms [1].
Reference: [16] <author> Y.-T. Hwang and Y. H. Hu. </author> <title> On systolic mapping of multistage algorithms. </title> <booktitle> In Proceedings of the IEEE International Conference on Application Specific Array Processors, </booktitle> <pages> pages 47-61, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Ju and Dietz use a search-based algorithm to find data layout and loop restructuring combinations that reduce cache coherence overhead on shared memory machines [19]. Hwang and Hu describe a method for finding the computation mapping of two systolic array stages that share a single array <ref> [16] </ref>. Their algorithm works by first calculating the projection vector, which is similar to what we call the partition, of the computation mapping. Many projects have examined the problem of finding array alignments (what we call data orientations and displacements) for data parallel programs [8, 11, 21, 30, 35].
Reference: [17] <institution> Intel Corporation, </institution> <address> Santa Clara, CA. </address> <note> iPSC/2 and iPSC/860 User's Guide, </note> <month> June </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Minimizing communication by increasing the locality of data references is an important optimization for achieving high performance on all large-scale parallel machines. The long message-passing overhead of multicomputer architectures, such as the Intel Touchstone <ref> [17] </ref>, makes minimizing communication essential. Locality is also important to scalable machines that support a shared address space in hardware. For example, local cache accesses on the Stanford DASH shared-memory multiprocessor are two orders of magnitude faster than remote accesses [26].
Reference: [18] <author> F. Irigoin and R. Triolet. </author> <title> Supernode partitioning. </title> <booktitle> In Proceedings of the SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 319-329, </pages> <month> Jan-uary </month> <year> 1988. </year>
Reference-contexts: Recall that the local phase of our compiler transforms each loop nest such that the largest possible fully permutable loop nests are outermost. Also within each fully permutable nest, any forall loops are positioned outermost. A loop nest that is fully permutable can also be fully tiled <ref> [18, 38] </ref>. If the dependence vectors in the fully permutable loop nest are all distance vectors, then the pipelined communication is inexpensive because only the data elements at the block boundaries need to move.
Reference: [19] <author> Y. Ju and H. Dietz. </author> <title> Reduction of cache coherence overhead by compiler data layout and loop transformation. </title> <editor> In U. Ban-erjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 344-358. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany, </address> <year> 1992. </year>
Reference-contexts: They use loop interchange and reversal transformations to orient the computation. Ju and Dietz use a search-based algorithm to find data layout and loop restructuring combinations that reduce cache coherence overhead on shared memory machines <ref> [19] </ref>. Hwang and Hu describe a method for finding the computation mapping of two systolic array stages that share a single array [16]. Their algorithm works by first calculating the projection vector, which is similar to what we call the partition, of the computation mapping.
Reference: [20] <author> K. Kennedy and K. S. McKinley. </author> <title> Optimizing for parallelism and data locality. </title> <booktitle> In Proceedings of the 1992 ACM International Conference on Supercomputing, </booktitle> <pages> pages 323-334, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: After presenting a mathematical formulation of decompositions, we then formally state the problem. 2.1 Background Techniques for maximizing parallelism and locality within a single loop nest have been presented in the literature <ref> [20, 25, 36] </ref>. A number of researchers have also looked at the specific problem of mapping a single loop nest onto parallel machines [15, 23, 24]. We refer to such loop-level techniques as local analysis. The global analysis is responsible for optimizing parallelism and locality across multiple loop nests.
Reference: [21] <author> K. Knobe, J. D. Lukas, and G. L. Steele. </author> <title> Data optimization: Allocation of arrays to reduce communication on SIMD machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8 </volume> <pages> 102-118, </pages> <year> 1990. </year>
Reference-contexts: Their algorithm works by first calculating the projection vector, which is similar to what we call the partition, of the computation mapping. Many projects have examined the problem of finding array alignments (what we call data orientations and displacements) for data parallel programs <ref> [8, 11, 21, 30, 35] </ref>. These approaches focus on element-wise array operations, and try to eliminate the communication between consecutive loops.
Reference: [22] <author> C. Koelbel, P. Mehrotra, and J. Van Rosendale. </author> <title> Supporting shared data structures on distributed memory architectures. </title> <booktitle> In Proceedings of the Second ACM/SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 177-186, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: A popular approach to this complex optimization problem is to solicit the programmer's help in determining the data decompositions. Projects using this approach include SUPERB [40], AL [34], ID Noveau [31], Kali <ref> [22] </ref>, Vienna Fortran [7] and Fortran D [14, 33]. The current proposal for a High Performance Fortran extension to Fortran 90 also relies upon user-specified data decompositions [13].
Reference: [23] <author> D. Kulkarni, K. G. Kumar, A. Basu, and A. Paulraj. </author> <title> Loop partitioning for distributed memory multiprocessors as uni-modular transformations. </title> <booktitle> In Proceedings of the 1991 ACM International Conference on Supercomputing, </booktitle> <pages> pages 206-215, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: A number of researchers have also looked at the specific problem of mapping a single loop nest onto parallel machines <ref> [15, 23, 24] </ref>. We refer to such loop-level techniques as local analysis. The global analysis is responsible for optimizing parallelism and locality across multiple loop nests. First, our compiler normalizes the loops and performs loop distribution before executing the decomposition algorithms [1].
Reference: [24] <author> K. G. Kumar, D. Kulkarni, and A. Basu. </author> <title> Deriving good transformations for mapping nested loops on hierarchical parallel machines in polynomial time. </title> <booktitle> In Proceedings of the 1992 ACM International Conference on Supercomputing, </booktitle> <pages> pages 82-91, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: A number of researchers have also looked at the specific problem of mapping a single loop nest onto parallel machines <ref> [15, 23, 24] </ref>. We refer to such loop-level techniques as local analysis. The global analysis is responsible for optimizing parallelism and locality across multiple loop nests. First, our compiler normalizes the loops and performs loop distribution before executing the decomposition algorithms [1].
Reference: [25] <author> M. S. Lam and M. E. Wolf. </author> <title> Compilation techniques to achieve parallelism and locality. </title> <booktitle> In Proceedings of the DARPA Software Technology Conference, </booktitle> <pages> pages 150-158, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: After presenting a mathematical formulation of decompositions, we then formally state the problem. 2.1 Background Techniques for maximizing parallelism and locality within a single loop nest have been presented in the literature <ref> [20, 25, 36] </ref>. A number of researchers have also looked at the specific problem of mapping a single loop nest onto parallel machines [15, 23, 24]. We refer to such loop-level techniques as local analysis. The global analysis is responsible for optimizing parallelism and locality across multiple loop nests. <p> First, our compiler normalizes the loops and performs loop distribution before executing the decomposition algorithms [1]. The compiler runs a loop fusion pass after decomposition to regroup compatible loop nests [5, 10]. Our compiler uses the algorithm developed by Wolf and Lam <ref> [25, 36] </ref> to apply unimodular transforms to find the coarsest granularity of parallelism within a loop nest. This pass leaves the loop nests in a canonical form consisting of a nest of fully permutable loop nests. The nests are as large as possible, starting from the outermost loops.
Reference: [26] <author> D. Lenoski, K. Gharachorloo, J. Laudon, A. Gupta, J. Hen-nessy, M. Horowitz, and M. Lam. </author> <title> The Stanford DASH Multiprocessor. </title> <journal> IEEE Computer, </journal> <volume> 25(3) </volume> <pages> 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Locality is also important to scalable machines that support a shared address space in hardware. For example, local cache accesses on the Stanford DASH shared-memory multiprocessor are two orders of magnitude faster than remote accesses <ref> [26] </ref>. Improving locality can greatly enhance the performance of such machines. The mapping of computation onto the processors of a parallel machine is termed the computation decomposition of the program. <p> The experiments described in this section were performed on the Stanford DASH shared-memory multiprocessor <ref> [26] </ref>. Since we do not have a code generator for DASH at this point, we implemented by hand parallel SPMD programs with the decompositions generated by our compiler. All programs were compiled with the SGI f77 compiler at the -O2 optimization level.
Reference: [27] <author> J. Li and M. Chen. </author> <title> Generating explicit communication from shared-memory program references. </title> <booktitle> In Supercomputing 1990, </booktitle> <pages> pages 865-876. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1990. </year>
Reference-contexts: These approaches focus on element-wise array operations, and try to eliminate the communication between consecutive loops. Li and Chen prove the problem of finding optimal orientations NP-complete [28], and have developed a heuristic solution which is used to implement their functional language Crystal on message-passing machines <ref> [27] </ref>. In contrast to these approaches, our model supports loop nests containing both parallel and sequential loops and general affine array index functions. These approaches all optimize for a fixed degree of parallelism, whereas we make explicit decisions about which loops are run in parallel.
Reference: [28] <author> J. Li and M. Chen. </author> <title> Index domain alignment: Minimizing cost of cross-referencing between distributed arrays. </title> <booktitle> In Proceedings of Frontiers '90: The Third Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 424-432. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1990. </year>
Reference-contexts: These approaches focus on element-wise array operations, and try to eliminate the communication between consecutive loops. Li and Chen prove the problem of finding optimal orientations NP-complete <ref> [28] </ref>, and have developed a heuristic solution which is used to implement their functional language Crystal on message-passing machines [27]. In contrast to these approaches, our model supports loop nests containing both parallel and sequential loops and general affine array index functions.
Reference: [29] <author> D. E. Maydan. </author> <title> Accurate Analysis of Array References. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> September </month> <year> 1992. </year> <note> Published as CSL-TR-92-547. </note>
Reference-contexts: This partition means that elements along the diagonal are allocated to the same processor. In general, when the array index functions are not invertible, we must introduce auxiliary variables and use a pseudo-inverse function. The techniques we use are similar to those presented in other literature <ref> [3, 29] </ref>. This analysis is run on all pairs of arrays involved in a cycle in the interference graph (including the degenerate case of multiple access functions for one array in a loop nest).
Reference: [30] <author> J. F. Prins. </author> <title> A framework for efficient execution of array-based languages on SIMD computers. </title> <booktitle> In Proceedings of Frontiers '90: The Third Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 462-470. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1990. </year>
Reference-contexts: Their algorithm works by first calculating the projection vector, which is similar to what we call the partition, of the computation mapping. Many projects have examined the problem of finding array alignments (what we call data orientations and displacements) for data parallel programs <ref> [8, 11, 21, 30, 35] </ref>. These approaches focus on element-wise array operations, and try to eliminate the communication between consecutive loops.
Reference: [31] <author> A. Rogers and K. Pingali. </author> <title> Compiling for locality. </title> <booktitle> In Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <pages> pages 142-146, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: A popular approach to this complex optimization problem is to solicit the programmer's help in determining the data decompositions. Projects using this approach include SUPERB [40], AL [34], ID Noveau <ref> [31] </ref>, Kali [22], Vienna Fortran [7] and Fortran D [14, 33]. The current proposal for a High Performance Fortran extension to Fortran 90 also relies upon user-specified data decompositions [13].
Reference: [32] <author> V. Sarkar and G. R. Gao. </author> <title> Optimization of array accesses by collective loop transformations. </title> <booktitle> In Proceedings of the 1991 ACM International Conference on Supercomputing, </booktitle> <pages> pages 194-204, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: This is the decomposition our compiler finds when considering both pipeline and reorganization communication. 9 Related Work A number of researchers have addressed problems that are related to the decomposition problem. Sarkar and Gao have developed an algorithm that uses collective loop transformations to perform array contraction <ref> [32] </ref>. They use loop interchange and reversal transformations to orient the computation. Ju and Dietz use a search-based algorithm to find data layout and loop restructuring combinations that reduce cache coherence overhead on shared memory machines [19].
Reference: [33] <author> C.-W. Tseng. </author> <title> An Optimizing Fortran D Compiler for MIMD Distributed-Memory Machines. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> January </month> <year> 1993. </year> <note> Published as Rice COMP TR93-199. </note>
Reference-contexts: A popular approach to this complex optimization problem is to solicit the programmer's help in determining the data decompositions. Projects using this approach include SUPERB [40], AL [34], ID Noveau [31], Kali [22], Vienna Fortran [7] and Fortran D <ref> [14, 33] </ref>. The current proposal for a High Performance Fortran extension to Fortran 90 also relies upon user-specified data decompositions [13]. <p> The nodes in the graph correspond to the loop nests in the program. The edges in the graph represent places in the program where data reorganization communication can occur. The edges in the graph are calculated using information that is similar to the reaching decompositions <ref> [14, 33] </ref> used in the Fortran D compiler. In Fortran D, the reaching decompositions are defined to be the set of decomposition statements that may reach an array reference that uses the decomposition. In our case, all loop nests may define a decomposition.
Reference: [34] <author> P.-S. Tseng. </author> <title> A Parallelizing Compiler for Distributed Memory Parallel Computers. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1989. </year> <note> Published as CMU-CS-89-148. </note>
Reference-contexts: It may be advantageous to abandon some parallelism to create larger granularity tasks if the communication cost overwhelms the benefit of parallelization. A popular approach to this complex optimization problem is to solicit the programmer's help in determining the data decompositions. Projects using this approach include SUPERB [40], AL <ref> [34] </ref>, ID Noveau [31], Kali [22], Vienna Fortran [7] and Fortran D [14, 33]. The current proposal for a High Performance Fortran extension to Fortran 90 also relies upon user-specified data decompositions [13].
Reference: [35] <author> S. Wholey. </author> <title> Automatic Data Mapping for Distributed-Memory Parallel Computers. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1991. </year> <note> Published as CMU-CS-91-121. </note>
Reference-contexts: Their algorithm works by first calculating the projection vector, which is similar to what we call the partition, of the computation mapping. Many projects have examined the problem of finding array alignments (what we call data orientations and displacements) for data parallel programs <ref> [8, 11, 21, 30, 35] </ref>. These approaches focus on element-wise array operations, and try to eliminate the communication between consecutive loops.
Reference: [36] <author> M. E. Wolf. </author> <title> Improving Locality and Parallelism in Nested Loops. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> August </month> <year> 1992. </year> <note> Published as CSL-TR-92-538. </note>
Reference-contexts: After presenting a mathematical formulation of decompositions, we then formally state the problem. 2.1 Background Techniques for maximizing parallelism and locality within a single loop nest have been presented in the literature <ref> [20, 25, 36] </ref>. A number of researchers have also looked at the specific problem of mapping a single loop nest onto parallel machines [15, 23, 24]. We refer to such loop-level techniques as local analysis. The global analysis is responsible for optimizing parallelism and locality across multiple loop nests. <p> First, our compiler normalizes the loops and performs loop distribution before executing the decomposition algorithms [1]. The compiler runs a loop fusion pass after decomposition to regroup compatible loop nests [5, 10]. Our compiler uses the algorithm developed by Wolf and Lam <ref> [25, 36] </ref> to apply unimodular transforms to find the coarsest granularity of parallelism within a loop nest. This pass leaves the loop nests in a canonical form consisting of a nest of fully permutable loop nests. The nests are as large as possible, starting from the outermost loops.
Reference: [37] <author> M. E. Wolf and M. S. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 30-44, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Tiling <ref> [37, 39] </ref> (also known as blocking, unroll-and-jam and stripmine-and-interchange) is a well-known transformation that allows both parallelism and locality to be exploited within a loop nest. <p> Focusing now on the loops within an inner block, the iterations that are allocated to same processor also form a vector space, L c . The vector space L c is called the localized vector space in <ref> [37] </ref>, where L c is used to represent tile iterations that have cache locality. In our model the localized vector space L c contains all dimensions of the iteration space that are local to a processor, be they completely local or blocked. Thus ker C L c .
Reference: [38] <author> M. E. Wolf and M. S. Lam. </author> <title> A loop transformation theory and an algorithm to maximize parallelism. </title> <journal> Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 452-470, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Recall that the local phase of our compiler transforms each loop nest such that the largest possible fully permutable loop nests are outermost. Also within each fully permutable nest, any forall loops are positioned outermost. A loop nest that is fully permutable can also be fully tiled <ref> [18, 38] </ref>. If the dependence vectors in the fully permutable loop nest are all distance vectors, then the pipelined communication is inexpensive because only the data elements at the block boundaries need to move.
Reference: [39] <author> M. J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference-contexts: Tiling <ref> [37, 39] </ref> (also known as blocking, unroll-and-jam and stripmine-and-interchange) is a well-known transformation that allows both parallelism and locality to be exploited within a loop nest.
Reference: [40] <author> H. P. Zima, H.-J. Bast, and M. Gerndt. </author> <title> SUPERB: A tool for semi-automatic MIMD / SIMD parallelization. </title> <journal> Parallel Computing, </journal> <volume> 6(1) </volume> <pages> 1-18, </pages> <month> January </month> <year> 1988. </year> <month> 14 </month>
Reference-contexts: It may be advantageous to abandon some parallelism to create larger granularity tasks if the communication cost overwhelms the benefit of parallelization. A popular approach to this complex optimization problem is to solicit the programmer's help in determining the data decompositions. Projects using this approach include SUPERB <ref> [40] </ref>, AL [34], ID Noveau [31], Kali [22], Vienna Fortran [7] and Fortran D [14, 33]. The current proposal for a High Performance Fortran extension to Fortran 90 also relies upon user-specified data decompositions [13].
References-found: 40

