URL: http://www.cs.huji.ac.il/~feit/parsched/p-95-9.ps.gz
Refering-URL: http://www.cs.huji.ac.il/~feit/parsched/parsched95.html
Root-URL: http://www.cs.huji.ac.il
Email: rose@dsi.unimi.it  esmirni,dowdy@vuse.vanderbilt.edu  serazzi@elet.polimi.it  
Phone: 2  3  
Title: Analysis of Non-Work-Conserving Processor Partitioning Policies  
Author: E. Rosti E. Smirni G. Serazzi L.W. Dowdy 
Address: Milano, Italy  Nashville TN 37235, USA  Milano, Italy  
Affiliation: 1 Dipartimento di Scienze dell'Informazione Universita di  Department of Computer Science, Vanderibilt Univeristy  Dipartimento di Elettronica e Informazione Politecnico di  
Abstract: In multiprocessor systems, a reasonable goal of the sched-uler is to keep all processors as busy as possible. One technique for doing this is to allocate all available processors to the jobs waiting for service. Techniques which allocate all available processors are known as work-conserving policies. In this paper, non-work-conserving policies are examined. These policies keep some number of processors idle (i.e., unallocated) even when there are parallel jobs that are waiting for service. Such non-work-conserving policies set aside idle processors for anticipated new job arrivals or for unexpected system behavior. Two classes of non-work-conserving space-sharing policies are examined. One policy class keeps a certain percentage of the processors free. The other policy class makes an allocation decision based on previously observed system behavior. Two non-work-conserving policies, each selected from the two classes, are evaluated against their work-conserving counterparts. It is demonstrated that non-work-conserving policies can be particularly useful when the workload or the system behavior are irregular. Variability in the workload behavior including bursty arrivals, a high coefficient of variation in the workload execution time, unstable systems with processor failures are among the situations where non-work-conserving policies improve performance. 
Abstract-found: 1
Intro-found: 1
Reference: [AMV93] <author> R. Agrawal, R.K. Mansharamani, </author> <title> M.K. Vernon, "Response time bounds for parallel processor allocation policies," </title> <type> Technical Report # 1152, </type> <institution> Computer Science Dept., Univeristy of Wisconsin, Madison, WI, </institution> <month> June </month> <year> 1993. </year>
Reference: [CMV94] <author> S.-H. Chiang, R.K. Mansharamani, </author> <title> M.K. Vernon, "Use of application char-acteristics and limited preemption for run-to-completion parallel processor scheduling policies," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1994, </year> <pages> pp. 33-44. </pages>
Reference-contexts: However, multiprogramming complicates scheduling since an allocation policy is needed to determine the number of processors which should be allocated to each parallel program. Preemptive or non-preemptive [SRDS93] processor allocation policies have been proposed. Preemptive policies <ref> [Oust82, MEB88, PD89, FR90, DCDP90, LV90, ZM90, MVZ93, CMV94, MZ94] </ref> allow processor redistribution upon job arrivals and departures or when a time quantum expires. <p> Processors may be reclaimed from an executing job's assignment and distributed to newly arrived jobs, or additional processors may be added to an executing job's assignment when processors become available. Dynamic space-sharing policies and time-sharing policies are considered preemptive. Non-preemptive policies <ref> [Sev89, ZM90, GST91, MEB91, RSDSC94, Sev94, CMV94] </ref> keep the number of processors assigned to a job constant during execution. Processor allocation decisions occur only before execution starts. Static and adaptive space-sharing policies are considered non-preemptive. Non-preemptive policies are characterized by low overhead and easy implementation. <p> These are policies that keep processors idle even in the presence of jobs waiting for service or policies that set aside processors for anticipated job arrivals. Traditionally, processor scheduling policies are devised with the goal of maximizing system utilization by assigning all available processors as soon as possible <ref> [ZM90, GST91, CMV94] </ref>. Work-conserving policies are natural in uniprocessors where there is no advantage from keeping the processor idle. When there are multiple processors, nonwork-conserving policies may be effective. A number of non-work-conserving policies have appeared in the literature and have proved to perform well. <p> A uniform comparison of the adaptive space-sharing policies that appeared in the literature has been presented in <ref> [CMV94] </ref>. From this comparison, the ASP-MAX policy is distinguished. The ASP-MAX policy resorts to non-work-conserving scheduling decisions by using the available parallelism of each parallel application and a fixed percentage parameter. A preliminary study of the advantages of leaving idle processors has been conducted in [SRSDS95]. <p> In this paper, two families of non-work-conserving policies are examined. They represent two distinct ways of making non-work-conserving decisions. 2.1 The ASP-MAX Family The ASP-MAX (Adaptive Static Partitioning with a Maximum) family of policies offers a complete range of policies whose performance is a function of the MAX parameter <ref> [CMV94] </ref>. The goal of the policy is to equally distribute all free processors to the jobs waiting in the queue. One constraint applies: the number of processors assigned to the job must be less than or equal to the minimum of the job's available parallelism and the parameter MAX. <p> The policy performance is sensitive to the selection of the parameter MAX. It has been shown that an effective rule of thumb is to set MAX to 20% <ref> [CMV94] </ref>. If a job arrives at an empty system and its available parallelism is equal to the system size then the job is assigned a number of processors MAXfisystem size. <p> In the analysis presented in this paper, it is assumed that the the jobs' speedup curves are monotonically increasing. Therefore, the jobs' available parallelism exceeds the system size. The policy performance with various distributions of the available parallelism has been analyzed in <ref> [CMV94] </ref>. With ASP-MAX policies, the number of processors kept idle can be considerable (e.g., up to 80% of the system size when MAX = 20%). Such a situation does not occur if there are jobs waiting for service in the queue. <p> The performance metric adopted is the response time ratio, defined as the ratio of the average response time under a given policy to the average response time under a reference policy <ref> [CMV94] </ref>. The absolute comparison of the ASP-MAX and PSA policies is not the purpose of this paper 5 .
Reference: [EZL89] <author> D.L. Eager, J. Zahorjan, E.D. Lazowska, </author> <title> "Speedup versus efficiency in parallel systems," </title> <journal> IEEE Trans. on Computers, </journal> <volume> Vol 38(3), </volume> <month> March </month> <year> 1989, </year> <pages> pp. 408-423. </pages>
Reference: [DCDP90] <author> K. Dussa, B.M. Carlson, L.W. Dowdy, K.-H. Park, </author> <title> "Dynamic partitioning in a transputer environment," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1990, </year> <pages> pp. 203-213. </pages>
Reference-contexts: However, multiprogramming complicates scheduling since an allocation policy is needed to determine the number of processors which should be allocated to each parallel program. Preemptive or non-preemptive [SRDS93] processor allocation policies have been proposed. Preemptive policies <ref> [Oust82, MEB88, PD89, FR90, DCDP90, LV90, ZM90, MVZ93, CMV94, MZ94] </ref> allow processor redistribution upon job arrivals and departures or when a time quantum expires.
Reference: [FR90] <author> D.G. Feitelson, L. Rudolph, </author> <title> "Distributed hierarchical control for parallel processing," </title> <journal> IEEE Computer, </journal> <volume> Vol 23(5), </volume> <month> May </month> <year> 1990, </year> <pages> pp. 65-77. </pages>
Reference-contexts: However, multiprogramming complicates scheduling since an allocation policy is needed to determine the number of processors which should be allocated to each parallel program. Preemptive or non-preemptive [SRDS93] processor allocation policies have been proposed. Preemptive policies <ref> [Oust82, MEB88, PD89, FR90, DCDP90, LV90, ZM90, MVZ93, CMV94, MZ94] </ref> allow processor redistribution upon job arrivals and departures or when a time quantum expires.
Reference: [GST91] <author> D. Ghosal, G. </author> <title> Serazzi, S.K. Tripathi, "Processor working set and its use in scheduling multiprocessor systems," </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol 17(5), </volume> <month> May </month> <year> 1991, </year> <pages> pp. 443-453. </pages>
Reference-contexts: Processors may be reclaimed from an executing job's assignment and distributed to newly arrived jobs, or additional processors may be added to an executing job's assignment when processors become available. Dynamic space-sharing policies and time-sharing policies are considered preemptive. Non-preemptive policies <ref> [Sev89, ZM90, GST91, MEB91, RSDSC94, Sev94, CMV94] </ref> keep the number of processors assigned to a job constant during execution. Processor allocation decisions occur only before execution starts. Static and adaptive space-sharing policies are considered non-preemptive. Non-preemptive policies are characterized by low overhead and easy implementation. <p> These are policies that keep processors idle even in the presence of jobs waiting for service or policies that set aside processors for anticipated job arrivals. Traditionally, processor scheduling policies are devised with the goal of maximizing system utilization by assigning all available processors as soon as possible <ref> [ZM90, GST91, CMV94] </ref>. Work-conserving policies are natural in uniprocessors where there is no advantage from keeping the processor idle. When there are multiple processors, nonwork-conserving policies may be effective. A number of non-work-conserving policies have appeared in the literature and have proved to perform well. <p> Restricting the number of processors assigned to a job up to the job's maximum parallelism has been used in the run-to-completion (RTC) policy presented in [ZM90]. The concept of processor working set (PWS) is used as a configuration parameter for several adaptive policies <ref> [GST91] </ref>. Among them, two non-work-conserving policies (FF and FF+LA) restrict the number of allocated processors allocated to the jobs' PWS.
Reference: [GTU91] <author> A. Gupta, A. Tucker, S. Urushibara, </author> <title> "The impact of operating system scheduling policies and synchronization methods on the performance of parallel applications," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1991, </year> <pages> pp. 120-132. </pages>
Reference: [Int93] <author> Intel Corporation, </author> <title> Paragon OSF/1 User's Guide, </title> <year> 1993. </year>
Reference: [Klei75] <author> L. </author> <title> Kleinrock, </title> <journal> Queueing Systems, </journal> <volume> Vol 1, </volume> <publisher> Wiley Interscience, </publisher> <year> 1975. </year>
Reference: [LV90] <author> S.T. </author> <title> Leutenegger, M.K. Vernon, "The performance of multiprogrammed multiprocessor scheduling policies," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1990, </year> <pages> pp. 226-236. </pages>
Reference-contexts: However, multiprogramming complicates scheduling since an allocation policy is needed to determine the number of processors which should be allocated to each parallel program. Preemptive or non-preemptive [SRDS93] processor allocation policies have been proposed. Preemptive policies <ref> [Oust82, MEB88, PD89, FR90, DCDP90, LV90, ZM90, MVZ93, CMV94, MZ94] </ref> allow processor redistribution upon job arrivals and departures or when a time quantum expires.
Reference: [MEB88] <author> S. Majumdar, D.L. Eager, R.B. Bunt, </author> <title> "Scheduling in multiprogrammed parallel systems," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1988, </year> <pages> pp. 104-113. </pages>
Reference-contexts: However, multiprogramming complicates scheduling since an allocation policy is needed to determine the number of processors which should be allocated to each parallel program. Preemptive or non-preemptive [SRDS93] processor allocation policies have been proposed. Preemptive policies <ref> [Oust82, MEB88, PD89, FR90, DCDP90, LV90, ZM90, MVZ93, CMV94, MZ94] </ref> allow processor redistribution upon job arrivals and departures or when a time quantum expires.
Reference: [MEB91] <author> S. Majumdar, D.L. Eager, R. B. Bunt, </author> <title> "Characterization of programs for scheduling in multiprogrammed parallel systems," </title> <journal> Performance Evaluation, </journal> <volume> Vol 13(2), </volume> <year> 1991, </year> <pages> pp. 109-130. </pages>
Reference-contexts: Processors may be reclaimed from an executing job's assignment and distributed to newly arrived jobs, or additional processors may be added to an executing job's assignment when processors become available. Dynamic space-sharing policies and time-sharing policies are considered preemptive. Non-preemptive policies <ref> [Sev89, ZM90, GST91, MEB91, RSDSC94, Sev94, CMV94] </ref> keep the number of processors assigned to a job constant during execution. Processor allocation decisions occur only before execution starts. Static and adaptive space-sharing policies are considered non-preemptive. Non-preemptive policies are characterized by low overhead and easy implementation.
Reference: [MVZ93] <author> C. McCann, R. Vaswani, J. Zahorjan, </author> <title> "A dynamic processor allocation policy for multiprogrammed shared memory multiprocessors," </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> Vol 11(2), </volume> <month> February </month> <year> 1993, </year> <pages> pp. 146-178. </pages>
Reference-contexts: However, multiprogramming complicates scheduling since an allocation policy is needed to determine the number of processors which should be allocated to each parallel program. Preemptive or non-preemptive [SRDS93] processor allocation policies have been proposed. Preemptive policies <ref> [Oust82, MEB88, PD89, FR90, DCDP90, LV90, ZM90, MVZ93, CMV94, MZ94] </ref> allow processor redistribution upon job arrivals and departures or when a time quantum expires.
Reference: [MZ94] <author> C. McCann, J. Zahorjan, </author> <title> "Processor allocation policies for message-passing parallel computers," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1994, </year> <pages> pp. 19-32. </pages>
Reference-contexts: However, multiprogramming complicates scheduling since an allocation policy is needed to determine the number of processors which should be allocated to each parallel program. Preemptive or non-preemptive [SRDS93] processor allocation policies have been proposed. Preemptive policies <ref> [Oust82, MEB88, PD89, FR90, DCDP90, LV90, ZM90, MVZ93, CMV94, MZ94] </ref> allow processor redistribution upon job arrivals and departures or when a time quantum expires.
Reference: [Oust82] <author> J. Ousterhout, </author> <title> "Scheduling techniques for concurrent systems," </title> <booktitle> Proc. 3rd International Conference on Distributed Computing Systems, </booktitle> <year> 1982, </year> <pages> pp. 22-30. </pages>
Reference-contexts: However, multiprogramming complicates scheduling since an allocation policy is needed to determine the number of processors which should be allocated to each parallel program. Preemptive or non-preemptive [SRDS93] processor allocation policies have been proposed. Preemptive policies <ref> [Oust82, MEB88, PD89, FR90, DCDP90, LV90, ZM90, MVZ93, CMV94, MZ94] </ref> allow processor redistribution upon job arrivals and departures or when a time quantum expires.
Reference: [PD89] <author> K.-H. Park, L.W. Dowdy, </author> <title> "Dynamic partitioning of multiprocessor systems," </title> <journal> International Journal of Parallel Programming, </journal> <volume> Vol 18(2), </volume> <year> 1989, </year> <pages> pp. 91-120. </pages>
Reference-contexts: However, multiprogramming complicates scheduling since an allocation policy is needed to determine the number of processors which should be allocated to each parallel program. Preemptive or non-preemptive [SRDS93] processor allocation policies have been proposed. Preemptive policies <ref> [Oust82, MEB88, PD89, FR90, DCDP90, LV90, ZM90, MVZ93, CMV94, MZ94] </ref> allow processor redistribution upon job arrivals and departures or when a time quantum expires.
Reference: [RSDSC94] <author> E. Rosti, E. Smirni, L.W. Dowdy, G. Serazzi, B.M. Carlson, </author> <title> "Robust partitioning policies for multiprocessor systems," </title> <journal> Performance Evaluation, </journal> <volume> Vol 19(2-3), </volume> <month> March </month> <year> 1994, </year> <pages> pp. 141-165. </pages>
Reference-contexts: Processors may be reclaimed from an executing job's assignment and distributed to newly arrived jobs, or additional processors may be added to an executing job's assignment when processors become available. Dynamic space-sharing policies and time-sharing policies are considered preemptive. Non-preemptive policies <ref> [Sev89, ZM90, GST91, MEB91, RSDSC94, Sev94, CMV94] </ref> keep the number of processors assigned to a job constant during execution. Processor allocation decisions occur only before execution starts. Static and adaptive space-sharing policies are considered non-preemptive. Non-preemptive policies are characterized by low overhead and easy implementation. <p> A policy that restricts the number of processors as a function of the average, minimum, and maximum parallelism of the application and the variance in parallelism has been proposed in [Sev89]. Three families of non-work-conserving policies have been presented in <ref> [RSDSC94] </ref>: the insurance policies (IP) that always attempt to "save" a fixed percentage of the free processors for anticipated future arrivals, 4 Dedicated supercomputers are not the target machines of the policies investigated here.
Reference: [SST93] <author> S.K. Setia, </author> <title> M.S. Squillante, S.K. Tripathi, "Processor scheduling in mul-tiprogrammed, distributed memory parallel computers," </title> <booktitle> Proc. ACM SIG-METRICS, </booktitle> <year> 1993, </year> <pages> pp. 158-170. </pages>
Reference: [Sev89] <author> K.C. Sevcik, </author> <title> "Characterization of parallelism in applications and their use in scheduling," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1989, </year> <pages> pp. 171-180. </pages>
Reference-contexts: Processors may be reclaimed from an executing job's assignment and distributed to newly arrived jobs, or additional processors may be added to an executing job's assignment when processors become available. Dynamic space-sharing policies and time-sharing policies are considered preemptive. Non-preemptive policies <ref> [Sev89, ZM90, GST91, MEB91, RSDSC94, Sev94, CMV94] </ref> keep the number of processors assigned to a job constant during execution. Processor allocation decisions occur only before execution starts. Static and adaptive space-sharing policies are considered non-preemptive. Non-preemptive policies are characterized by low overhead and easy implementation. <p> Among them, two non-work-conserving policies (FF and FF+LA) restrict the number of allocated processors allocated to the jobs' PWS. A policy that restricts the number of processors as a function of the average, minimum, and maximum parallelism of the application and the variance in parallelism has been proposed in <ref> [Sev89] </ref>. Three families of non-work-conserving policies have been presented in [RSDSC94]: the insurance policies (IP) that always attempt to "save" a fixed percentage of the free processors for anticipated future arrivals, 4 Dedicated supercomputers are not the target machines of the policies investigated here.
Reference: [Sev94] <author> K.C. Sevcik, </author> <title> "Application scheduling and processor allocation in multipro-grammed multiprocessors," </title> <journal> Performance Evaluation, </journal> <volume> Vol 19(2-3), </volume> <month> March </month> <year> 1994, </year> <pages> pp. 107-140. </pages>
Reference-contexts: Processors may be reclaimed from an executing job's assignment and distributed to newly arrived jobs, or additional processors may be added to an executing job's assignment when processors become available. Dynamic space-sharing policies and time-sharing policies are considered preemptive. Non-preemptive policies <ref> [Sev89, ZM90, GST91, MEB91, RSDSC94, Sev94, CMV94] </ref> keep the number of processors assigned to a job constant during execution. Processor allocation decisions occur only before execution starts. Static and adaptive space-sharing policies are considered non-preemptive. Non-preemptive policies are characterized by low overhead and easy implementation.
Reference: [SRDS93] <author> E. Smirni, E. Rosti, L.W. Dowdy, G. </author> <title> Serazzi, "Evaluation of multiproces-sor allocation policies," </title> <type> Tech. Report, </type> <institution> Computer Science Dept., Vanderbilt University, Nashville, TN, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: Multiprogramming is a viable way to improve system utilization while preserving individual application performance. However, multiprogramming complicates scheduling since an allocation policy is needed to determine the number of processors which should be allocated to each parallel program. Preemptive or non-preemptive <ref> [SRDS93] </ref> processor allocation policies have been proposed. Preemptive policies [Oust82, MEB88, PD89, FR90, DCDP90, LV90, ZM90, MVZ93, CMV94, MZ94] allow processor redistribution upon job arrivals and departures or when a time quantum expires.
Reference: [SRSDS95] <author> E. Smirni, E. Rosti, G. Serazzi, L.W. Dowdy, K.C. Sevcik, </author> <title> "Performance gains from leaving idle processors in multiprocessor systems," </title> <note> to appear in International Conference on Parallel Processing. </note>
Reference-contexts: From this comparison, the ASP-MAX policy is distinguished. The ASP-MAX policy resorts to non-work-conserving scheduling decisions by using the available parallelism of each parallel application and a fixed percentage parameter. A preliminary study of the advantages of leaving idle processors has been conducted in <ref> [SRSDS95] </ref>. In this work, the properties of one specific non-work-conserving strategy were investigated. <p> All waiting jobs are scheduled as long as there is a sufficient number of processors. 2.2 The PSA Family An alternative way of being non-work-conserving is implemented by the PSA (Processor Saving Adaptive) policy <ref> [SRSDS95] </ref>. This policy does not force any a priori constraint on the size of the partition. Non-work-conserving decisions are made based upon the recent past system behavior. At each scheduling round, the policy tries to maintain an equipartitioning scheme. <p> If no arrivals occur during the execution of the newly arrived job, the next incoming job (i.e., in the next scheduling round) will be assigned the entire system and the entire past history is erased. A detailed algorithmic description of the PSA policy is presented in <ref> [SRSDS95] </ref>. Under the PSA policy, memory of the system history is kept for one scheduling round. The severity of non-work-conserving decisions can be extended by increasing the number of scheduling rounds that keep track of the system history.
Reference: [TG89] <author> A. Tucker, A. Gupta, </author> <title> "Process control and scheduling issues for multipro-grammed shared-memory multiprocessors," </title> <booktitle> Proc. of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <year> 1989, </year> <pages> pp. 159-166. </pages>
Reference: [ZM90] <author> J. Zahorjan, C. McCann, </author> <title> "Processor scheduling in shared memory multiprocessors," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1990, </year> <pages> pp. 214-225. </pages>
Reference-contexts: However, multiprogramming complicates scheduling since an allocation policy is needed to determine the number of processors which should be allocated to each parallel program. Preemptive or non-preemptive [SRDS93] processor allocation policies have been proposed. Preemptive policies <ref> [Oust82, MEB88, PD89, FR90, DCDP90, LV90, ZM90, MVZ93, CMV94, MZ94] </ref> allow processor redistribution upon job arrivals and departures or when a time quantum expires. <p> Processors may be reclaimed from an executing job's assignment and distributed to newly arrived jobs, or additional processors may be added to an executing job's assignment when processors become available. Dynamic space-sharing policies and time-sharing policies are considered preemptive. Non-preemptive policies <ref> [Sev89, ZM90, GST91, MEB91, RSDSC94, Sev94, CMV94] </ref> keep the number of processors assigned to a job constant during execution. Processor allocation decisions occur only before execution starts. Static and adaptive space-sharing policies are considered non-preemptive. Non-preemptive policies are characterized by low overhead and easy implementation. <p> These are policies that keep processors idle even in the presence of jobs waiting for service or policies that set aside processors for anticipated job arrivals. Traditionally, processor scheduling policies are devised with the goal of maximizing system utilization by assigning all available processors as soon as possible <ref> [ZM90, GST91, CMV94] </ref>. Work-conserving policies are natural in uniprocessors where there is no advantage from keeping the processor idle. When there are multiple processors, nonwork-conserving policies may be effective. A number of non-work-conserving policies have appeared in the literature and have proved to perform well. <p> A number of non-work-conserving policies have appeared in the literature and have proved to perform well. Restricting the number of processors assigned to a job up to the job's maximum parallelism has been used in the run-to-completion (RTC) policy presented in <ref> [ZM90] </ref>. The concept of processor working set (PWS) is used as a configuration parameter for several adaptive policies [GST91]. Among them, two non-work-conserving policies (FF and FF+LA) restrict the number of allocated processors allocated to the jobs' PWS.
Reference: [ZB91] <author> S. Zhou, T. Brecht, </author> <title> "Processor pool-based scheduling for large-scale NUMA multiprocessors," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1991, </year> <pages> pp. </pages> <month> 133-142. </month> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
References-found: 25

