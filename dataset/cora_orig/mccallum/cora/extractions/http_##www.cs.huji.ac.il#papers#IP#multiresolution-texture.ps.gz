URL: http://www.cs.huji.ac.il/papers/IP/multiresolution-texture.ps.gz
Refering-URL: http://www.cs.huji.ac.il/papers/IP/index.html
Root-URL: 
Email: feyalp,erezs,arir,wermang@cs.huji.ac.il  
Title: Highlight and Reflection-Independent Multiresolution Textures from Image Sequences  
Author: Eyal Ofek Erez Shilat Ari Rappoport Michael Werman 
Keyword: Texture, multiresolution, highlight, rendering, augmented reality.  
Address: Jerusalem 91904, Israel.  
Affiliation: Institute of Computer Science, The Hebrew University of Jerusalem  
Abstract: Rendering is one of the most important tasks in computer graphics and animation. It is widely recognized that texture maps are essential for adding to the visual content of the rendered image. Extraction of textures from a single photograph poses severe difficulties and is sometimes impossible, while artificial texture synthesis does not address the full range of desired textures. In this paper we present a method for computing high quality, multiresolution textures from an image sequence. The method has the following features: (1) it can be used with images in which the textures are present in different resolutions and different perspective distortions; (2) it can extract textures from objects with any known 3-D geometric structure; specifically, we are not restricted to planar textures; (3) removal of directional illumination artifacts such as highlights and reflections; (4) efficient storage of the resulting texture in a multiresolution data structure; and (5) no restrictions are imposed on the computed texture, which can be a constant color texture or a richly colored one. We present an especially attractive application of our technique, in which an existing real object participates in an animation sequence and is endowed with synthetic behaviour. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. T. Kajiya. </author> <title> The rendering equation. </title> <journal> Computer Graphics, </journal> <volume> Vol. 20 No. 2, </volume> <booktitle> SIGGRAPH 1986, </booktitle> <pages> pp. 143-149. </pages>
Reference-contexts: It is widely accepted that texture maps are essential for adding to the visual content of the rendered image. The simulation of light is a well-understood issue <ref> [1] </ref>. Artificial texture generation, on the other hand, still poses some unsolved difficulties. Although specific textures have been simulated successfully, artificially generated textures usually look too `clean', even when noise is added to them using statistical methods. <p> The structure HighlightInfo is a temporary structure which is used only for the directional illumination removal. It is null after eliminating the directional light effects. The structure and its usage will be described in Section 3.3. struct QNode f pointer to QNode child [i] i 2 <ref> [1; 4] </ref> RGB value real certainty pointer to HighlightInfo t g Pointers to the node's children are stored in N.child [i]. The tree is as sparse as possible: only where higher resolution texture is required, a new level is opened.
Reference: [2] <author> P. J. Burt and R. J. Kolczynski. </author> <title> Enhanced image capture through fusion. </title> <booktitle> In Fourth Int. Conf. on Comp. Vision, </booktitle> <year> 1993, </year> <pages> pp. 173-182. </pages>
Reference-contexts: In this paper we present a method for computing high-quality multiresolution 2-D textures from multiple images while overcoming these problems. Related Work Burt and Kolczynski <ref> [2] </ref> present an algorithm for fusion of several images into a single image. The algorithm is limited to images taken by a stationary camera and is mostly suited for fusion of images obtained from sensors of a different nature. <p> Quality is defined in this paper to be the area in the image covered by the tree's node (other definitions are possible, e.g. Burt and Kolzynski's criteria <ref> [2] </ref>). 10 Consider a projection of a uniform net from the texture space into the images (Figure 8). The image's area covered by a single square of the net decreases with the quality.
Reference: [3] <author> M. Irani and S. Peleg. </author> <title> Super resolution from image sequences. </title> <booktitle> In Int. Conf. of Pattern Recognition, </booktitle> <year> 1990, </year> <pages> pp. 115-120. 18 </pages>
Reference-contexts: Related Work Burt and Kolczynski [2] present an algorithm for fusion of several images into a single image. The algorithm is limited to images taken by a stationary camera and is mostly suited for fusion of images obtained from sensors of a different nature. Irani and Peleg <ref> [3] </ref> create a super-resolution image from an image sequence when the relative translations between the images are known to sub-pixel accuracy. Their algorithm assumes only 2-D translations, requires a-priori determination of the final resolution and is highly computa-tionally intensive.
Reference: [4] <author> D. F. Berman, J. T. Bartell, and D. H. Salesin. </author> <title> Multiresolution painting and compositing. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series, SIGGRAPH 1994 pp. </booktitle> <pages> 85-90. </pages>
Reference-contexts: Their algorithm assumes only 2-D translations, requires a-priori determination of the final resolution and is highly computa-tionally intensive. Combining different resolutions in the same setting is usually done through a multiresolution representation, e.g. a pyramid or a quadtree. Berman et al <ref> [4] </ref> describe a system that uses a wavelet quadtree to economically store multiresolution information. Their application is a paint system in which new paint covers (or is blended with) former information. <p> The structure HighlightInfo is a temporary structure which is used only for the directional illumination removal. It is null after eliminating the directional light effects. The structure and its usage will be described in Section 3.3. struct QNode f pointer to QNode child [i] i 2 <ref> [1; 4] </ref> RGB value real certainty pointer to HighlightInfo t g Pointers to the node's children are stored in N.child [i]. The tree is as sparse as possible: only where higher resolution texture is required, a new level is opened.
Reference: [5] <author> L. B. Wolff. </author> <title> Scene understanding from propagation and consistency of polarization-based constraints. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <year> 1994, </year> <pages> pp. 1000-1004. </pages>
Reference-contexts: For highlight recognition and removal from a single image, polarization <ref> [5] </ref> and color space techniques were proposed [6]. Polarization achieves promising results but requires photography using a special filter.
Reference: [6] <author> G. E. Healey, S. A.Shafer, and L. B. Wolff. </author> <title> Color. </title> <publisher> Jones and Barlett Publishers, </publisher> <year> 1992. </year>
Reference-contexts: For highlight recognition and removal from a single image, polarization [5] and color space techniques were proposed <ref> [6] </ref>. Polarization achieves promising results but requires photography using a special filter.
Reference: [7] <author> S. A. Shafer. </author> <title> Using color to separate reflection components. </title> <booktitle> COLOR Research and Application, </booktitle> <volume> Vol. 10 No. 4, </volume> <year> 1985, </year> <pages> pp. 43 - 51. </pages>
Reference-contexts: For highlight recognition and removal from a single image, polarization [5] and color space techniques were proposed [6]. Polarization achieves promising results but requires photography using a special filter. The color space methods use the ideas behind Shafer's dielectric material model <ref> [7] </ref>: pixels corresponding to a dielectric material's color are concentrated near a line segment in color space, while pixels corresponding to the highlights deviate from this segment. Color space methods attempt to isolate the material color's segment. <p> The BRDF can be decomposed into three major components (Figure 15): * Light penetrating a dielectric material and re-emerging after sub-surface scattering and refraction according to Shafer's model <ref> [7] </ref>. This component is usually called `ideal diffuse' in the computer graphics literature and `body reflection' in some of the computer vision literature. Till recently, this component was considered to be Lambertian, i.e. dependent only on the cosine of the angle between the light direction and the surface normal.
Reference: [8] <author> S. W. Lee and R. </author> <title> Bajcsy. Detection of specularity using color and multiple views. </title> <journal> Image and Vision Computing, </journal> <volume> Vol. 10 No. 10, </volume> <year> 1992, </year> <pages> pp. 643-653. </pages>
Reference-contexts: These methods do not work properly when the surface is not smooth or is highly textured, or when there is more than a single light source. Lee and Bajcsy detected nonoverlapping highlight regions in pairs of images, by matching pixels with similar colors <ref> [8] </ref>. Their method can not distinguish between highlight and occlusion and does not specify the highlight regions very accurately. None of the color space methods works for richly colored textures. The Proposed Method In this paper we present a method for computing high quality multiresolution textures from an image sequence.
Reference: [9] <author> E. Shilat, E. Ofek, A. Rappoport and M. Werman. </author> <title> Trackin a rigid object along image sequences using a three-frame matching primitive. </title> <type> Technical Report, </type> <institution> Institute of computer science, The Hebrew University of Jerusalem (http://www.cs.huji.ac.il/papers/IP/index.html) </institution>
Reference-contexts: A tracking method that can transform each pixel of one frame to a corresponding pixel in the next frame (e.g. optical flow) will eliminate the need of a known 3-D model, but those methods are more susceptible to illumination effects than other methods. The method described in <ref> [9] </ref> uses trifocal tensor for the tracking and is relatively stable under the basic assumptions of this paper (described bellow). All the examples in this paper were produced by manually tracking fifteen points of a known 3-D model, on sequences not longer than 16 images.
Reference: [10] <author> M. Oren and S. Nayar. </author> <title> Generalization of the Lambertian model and implication for machine vision. </title> <journal> Int. J. of Comp. Vision, </journal> <volume> Vol. 14 No. </volume> , <year> 1995, </year> <pages> pp. 227 - 251. </pages>
Reference-contexts: Till recently, this component was considered to be Lambertian, i.e. dependent only on the cosine of the angle between the light direction and the surface normal. Oren and Nayar <ref> [10] </ref> and Wolff [11] have shown that this component's dependence on view direction is stronger 12 certainty map of the mapping (c). the rougher the surface is. It is Lambertian only for smooth surfaces.
Reference: [11] <author> L. B. Wolf. </author> <title> Diffuse and specular reflection from dielectric surfaces. </title> <booktitle> In Image Understanding Workshop, </booktitle> <year> 1993, </year> <pages> pp. 1025-1030. </pages>
Reference-contexts: Till recently, this component was considered to be Lambertian, i.e. dependent only on the cosine of the angle between the light direction and the surface normal. Oren and Nayar [10] and Wolff <ref> [11] </ref> have shown that this component's dependence on view direction is stronger 12 certainty map of the mapping (c). the rougher the surface is. It is Lambertian only for smooth surfaces.
Reference: [12] <author> A. Blake and H. Bulthoff. </author> <title> Shape from specularities: </title> <journal> computation and psychophysics. Phil. Trans. R. Soc. London B, </journal> <volume> 331, </volume> <year> 1991, </year> <pages> pp. 237-252. </pages>
Reference-contexts: Blake and Bulthoff <ref> [12] </ref> analyzed the behavior of a highlight resulting from a single light source for a static scene with 14 this object is not planar. a moving observer.
Reference: [13] <author> L. Williams. </author> <title> Pyramidal parametrics. </title> <journal> Computer Graphics, </journal> <volume> Vol. 17 No. 3, </volume> <booktitle> SIGGRAPH 1983, </booktitle> <pages> pp. 1-11. </pages>
Reference-contexts: The second problem is simply solved by re-computing. The extracted texture is used in order to texture map 3-D objects in still and animation image synthesis. Texture mapping is done by an algorithm very similar to Williams' mipmap algorithm <ref> [13] </ref>. The only difference from that algorithm is that filtering requires finding the neighbors of a quadtree node, a well-known quadtree operation. A particularly attractive application of our method is the production of animation sequences of existing objects endowed with synthetic behaviour.
References-found: 13

