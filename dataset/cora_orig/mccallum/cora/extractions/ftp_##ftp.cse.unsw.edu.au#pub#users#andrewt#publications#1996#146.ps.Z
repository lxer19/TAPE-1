URL: ftp://ftp.cse.unsw.edu.au/pub/users/andrewt/publications/1996/146.ps.Z
Refering-URL: http://www.cse.unsw.edu.au/school/publications/1996/SCSE_publications.html
Root-URL: 
Email: Email: fbjtong,jas,anneg@cse.unsw.edu.au  
Phone: Telephone: +61 2 9385 3980 Fax: +61 2 9385 1813  
Title: Query Size Estimation using Machine Learning  
Author: Banchong Harangsri John Shepherd Anne Ngu 
Keyword: Query Size Estimation, Query Optimi-sation, Machine Learning  
Address: Sydney 2052, AUSTRALIA.  
Affiliation: School of Computer Science and Engineering, The University of New South Wales,  
Abstract: We propose two novel notions in this paper: the first is that machine learning techniques can be used to solve the problem of query size estimation and the second is a new generic algorithm to correct the training set of queries in response to updates. The main advantage for machine learning is that no database scan is required to collect statistics for query size estimation. The training set correction algorithm is useful in that it allows us to "re-vitalise" some existing query size estimation methods whose performance previously deteriorated in the presence of high update loads. A by-product of this is that the length of training sets can be fixed the size of the training set determines the level of error in query estimation. Our experimental results show that (1) the machine learning technique is superior to a recent curve fitting method in approximating query result sizes and (2) the machine learning technique still performs as well after the correction algorithm is applied. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. W. Aha. </author> <title> A Study of Instance-Based Algorithms for Supervised Learning Tasks: Mathematical, Empirical, and Psychological Evaluations. </title> <type> PhD thesis, </type> <institution> Department of Information and Computer Science, University of California, </institution> <address> Irvine, CA 92717, </address> <month> Nov 27 </month> <year> 1990. </year>
Reference-contexts: Quinlan's experimental work suggested that the model tree approach to model-based learning was the most effective. A model tree is a regression tree and originated in work by Breiman et. al. [3]. Instance-based learning herein on which we are based was originally proposed in <ref> [12, 1, 2] </ref>. The instance-based learning technique can do either a classification or regression task while the model-tree learning technique does only the regression task. To approximate the size of an unseen query, there are two main steps.
Reference: [2] <author> D. W. Aha, D. Kibler, and M. K. Albert. </author> <title> Instance-Based Learning Algorithms. </title> <journal> Machine Learning, </journal> <volume> 6(1) </volume> <pages> 37-66, </pages> <year> 1991. </year>
Reference-contexts: Quinlan's experimental work suggested that the model tree approach to model-based learning was the most effective. A model tree is a regression tree and originated in work by Breiman et. al. [3]. Instance-based learning herein on which we are based was originally proposed in <ref> [12, 1, 2] </ref>. The instance-based learning technique can do either a classification or regression task while the model-tree learning technique does only the regression task. To approximate the size of an unseen query, there are two main steps.
Reference: [3] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Tress. </title> <publisher> Chapman & Hall, Inc., </publisher> <year> 1984. </year>
Reference-contexts: Our overall approach is to derive size estimation functions using machine learning techniques. Specifically, we proceed as follows: 1. use feedback from a training set of queries to con struct a model tree (or regression tree) <ref> [3] </ref>, 2. when we need to estimate the result size of a given query, determine three most similar queries to the given query from the training set. 3. approximate the result size of the given query by using the model tree and the result sizes of the most similar queries. <p> This technique was originally proposed by Quin-lan [18] as a combination of model-based learning and instance-based learning. Quinlan's experimental work suggested that the model tree approach to model-based learning was the most effective. A model tree is a regression tree and originated in work by Breiman et. al. <ref> [3] </ref>. Instance-based learning herein on which we are based was originally proposed in [12, 1, 2]. The instance-based learning technique can do either a classification or regression task while the model-tree learning technique does only the regression task. <p> The reason in choosing 3 queries instead of other numbers can be described as follows: * Choosing any number has a tradeoff between bias and variance (see the CART book <ref> [3] </ref>); namely, higher numbers have higher bias but lower vari ance. * Generally, the instance-based learning or KNN (K Nearest Neighbor) methods avoid even numbers, since that is more likely to lead to ties.
Reference: [4] <author> C. M. Chen and N. Roussopoulos. </author> <title> Adaptive Selectivity Estimation using Query Feedback. </title> <booktitle> In Proceedings of 1994 ACM-SIGMOD International Conference on Management of Data, </booktitle> <year> 1994. </year>
Reference-contexts: There has been a considerable amount of work on the issue of selectivity estimation over one and a half decades [19, 5, 6, 16, 11, 9, 14, 15, 13, 7, 20, 4]. This previous work can be classified into four categories <ref> [20, 4] </ref>, namely non-parametric, parametric, sampling and curve fitting. Let us briefly describe each of them; the reader can find more details in the references given above. The non-parametric method is table- or histogram-based [16, 15]. <p> Compared with other estimation methods which require no extra delay for the samplings, this could be a significant disadvantage. The curve-fitting method <ref> [20, 4] </ref> is based on polynomial regression to find the best-fit set of coefficients to minimise the criterion of least-squared error. The curve fitting method proposed by [20], scans entire relations and uses regression to determine the distributions of attribute values in each relation. <p> This approach is effective only for low-update database systems. That is, as long as the distributions of attribute values remain fixed, the method performs satisfactorily. However, if the distributions change considerably, then the quality of the size estimates may deteriorate significantly. The curve-fitting method proposed by <ref> [4] </ref> uses query feedback to construct cost estimation functions. It uses queries of the form low a1 high, where a1 is an attribute, and the result sizes of the queries as the basis for regression. <p> Our method has the following advantages over the ASE method: * generic algorithm for updates: The algorithm we give in [8] with some slight modification can also be used with the size estimation methods proposed in <ref> [20, 4] </ref>. In other words, some size estimation methods proposed for retrieval-only or retrieval-intensive environments can be adapted for use with databases with high loads of updates. <p> This ensures that the lists always reflect the frequency f (x i ) and size s i . Obviously, assuming that the original size estimation methods are accurate in query size estimation, the additional approach to deal with updates proposed in <ref> [4] </ref> would be only ad-hoc and not necessarily as ef fective as the original size estimation method. * static list: Since our algorithm for correcting lists of query feedback and distinct-value-frequency makes the current lists always up-to-date, the length of the lists would not necessarily be extended. <p> In other words, after the length of lists has reached a certain size and the error in query size estimation has dropped to a satisfactory level, then the length remains constant. The approach to deal with updates in <ref> [4] </ref> combines the outdated and up-to-date list of query feedback 1 , and thus requires the old list to be retained. <p> the ASE method (see the results in [8]). * In [8] (the complete version of this paper), we have given a novel generic algorithm to correct the distinct-value-frequency list (x i ; f (x i )) [20], the query feedback list (l i ; h i ; s i ) <ref> [4] </ref> and our training set of queries. This algorithm re-validates the original query size estimation methods in [20, 4] which otherwise will be invalid, i.e., poor in query size estimation in the presence of very high loads of updates. <p> This algorithm re-validates the original query size estimation methods in <ref> [20, 4] </ref> which otherwise will be invalid, i.e., poor in query size estimation in the presence of very high loads of updates.
Reference: [5] <author> S. Christodoulakis. </author> <title> Estimating Block Transfers and Join Sizes. </title> <booktitle> In Proceedings of the ACM SIG-MOD Conference, </booktitle> <pages> pages 40-54, </pages> <year> 1983. </year>
Reference-contexts: The method requires scanning an entire relation to build up the histogram and the performance (the accuracy of the size estimation) will not be satisfactory if the number of intervals used is too small. The parametric method <ref> [19, 5, 6] </ref> is one which depends upon underlying assumptions about the data distribution (e.g. uniform, normal, Poisson, Zipf, etc.). The method will give accurate query size estimates if the actual data distribution follows the a priori assumption.
Reference: [6] <author> S. Christodoulakis. </author> <title> Estimating Record Selectivities. </title> <journal> Information System, </journal> <volume> 8(2) </volume> <pages> 105-115, </pages> <year> 1983. </year>
Reference-contexts: The method requires scanning an entire relation to build up the histogram and the performance (the accuracy of the size estimation) will not be satisfactory if the number of intervals used is too small. The parametric method <ref> [19, 5, 6] </ref> is one which depends upon underlying assumptions about the data distribution (e.g. uniform, normal, Poisson, Zipf, etc.). The method will give accurate query size estimates if the actual data distribution follows the a priori assumption.
Reference: [7] <author> P. Haas and A. Swami. </author> <title> Sequential Sampling Procedures for Query Size Estimation. </title> <booktitle> In ACM SIG-MOD Conference on the Management of Data, </booktitle> <pages> pages 341-350, </pages> <year> 1992. </year>
Reference-contexts: The method will give accurate query size estimates if the actual data distribution follows the a priori assumption. In reality, data distributions in real databases may not fit well with the assumptions and, consequently, the quality of the size estimates could be unreliable. The sampling method <ref> [13, 7] </ref> has recently received considerable interest. The accuracy of this method depends upon the size of samples; the higher the sample size, the better the estimation.
Reference: [8] <author> B. Harangsri, J. Shepherd, and A. Ngu. </author> <title> Query Size Estimation using Machine Learning. </title> <type> Technical report, </type> <institution> The University of New South Wales, School of Computer Science and Engineering, </institution> <address> Sydney 2052, AUSTRALIA, </address> <year> 1996. </year>
Reference-contexts: Except for the sampling method, the other schemes lose their accuracy as the database changes. Our method has the following advantages over the ASE method: * generic algorithm for updates: The algorithm we give in <ref> [8] </ref> with some slight modification can also be used with the size estimation methods proposed in [20, 4]. In other words, some size estimation methods proposed for retrieval-only or retrieval-intensive environments can be adapted for use with databases with high loads of updates. <p> Due to the space limit, the sections on size estimation with updates and experimental results are not given here; we refer the reader to the complete version of the paper in <ref> [8] </ref>. 2 Notations and definitions The following notations and terminology either appears throughout the paper or needs clarification: simple query q i A selection query on a single attribute of the form: b relopt x, where b is an attribute of relation R and relopt is one of the relational operators <p> The learning machine M5 has demonstrated its superior performance to the ASE method (see the results in <ref> [8] </ref>). * In [8] (the complete version of this paper), we have given a novel generic algorithm to correct the distinct-value-frequency list (x i ; f (x i )) [20], the query feedback list (l i ; h i ; s i ) [4] and our training set of queries. <p> The learning machine M5 has demonstrated its superior performance to the ASE method (see the results in <ref> [8] </ref>). * In [8] (the complete version of this paper), we have given a novel generic algorithm to correct the distinct-value-frequency list (x i ; f (x i )) [20], the query feedback list (l i ; h i ; s i ) [4] and our training set of queries.
Reference: [9] <author> W. Hou, G. Ozsoyoglu, and B. K. Taneja. </author> <title> Statistical Estimators for Relational Algebra Expressions. </title> <booktitle> In Proceedings of the ACM SIGACT-SIGMOD Symposium on Principles of Database Systems, </booktitle> <pages> pages 276-287, </pages> <year> 1988. </year>
Reference: [10] <author> Y. E. Ioannidis and S. Christodoulakis. </author> <title> On the Propagation of Errors in the Size of Join Results. </title> <booktitle> In Proceedings of the ACM-SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 268-277, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Query optimisers for database systems aim to determine the most efficient query execution plan to be executed by the database system. Choosing an efficient plan relies on cost estimates derived from the statistics maintained by the underlying database system. Work by <ref> [10] </ref> pointed out that inaccurate estimates derived from such statistics may cause the opti-miser to choose a very poor plan. Although the initial error might be negligible for the first subplan (such as the first join/selection), the subsequent errors (errors in the next subplans) can grow very rapidly (i.e., exponentially).
Reference: [11] <author> N. Kamel and R. King. </author> <title> A Method of Data Distribution Based on Texture Analysis. </title> <booktitle> In Proceedings of the ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 319-325, </pages> <year> 1985. </year>
Reference: [12] <author> D. Kibler, D. W. Aha, and M. K. Albert. </author> <title> Instance-Based Prediction of Real-Valued Attributes. </title> <journal> Computational Intelligence, </journal> <volume> 5 </volume> <pages> 51-57, </pages> <year> 1989. </year>
Reference-contexts: Quinlan's experimental work suggested that the model tree approach to model-based learning was the most effective. A model tree is a regression tree and originated in work by Breiman et. al. [3]. Instance-based learning herein on which we are based was originally proposed in <ref> [12, 1, 2] </ref>. The instance-based learning technique can do either a classification or regression task while the model-tree learning technique does only the regression task. To approximate the size of an unseen query, there are two main steps.
Reference: [13] <author> R. J. Lipton, J. F. Naughton, and D. A. Schnei-der. </author> <title> Practical Selectivity Estimation through Adaptive Sampling. </title> <booktitle> In Proceedings of ACM SIG-MOD, </booktitle> <pages> pages 1-12, </pages> <year> 1990. </year>
Reference-contexts: The method will give accurate query size estimates if the actual data distribution follows the a priori assumption. In reality, data distributions in real databases may not fit well with the assumptions and, consequently, the quality of the size estimates could be unreliable. The sampling method <ref> [13, 7] </ref> has recently received considerable interest. The accuracy of this method depends upon the size of samples; the higher the sample size, the better the estimation.
Reference: [14] <author> M. Mannino, P. Chu, and T. Sager. </author> <title> Statistical Profile Estimation in Database Systems. </title> <journal> ACM Computing Surveys, </journal> <volume> 20(3) </volume> <pages> 191-221, </pages> <month> september </month> <year> 1988. </year>
Reference: [15] <author> M. Muralikrishma and D. DeWitt. </author> <title> Equi-depth Histograms for Estimating Selectivity Factors for Multi-Dimensional Queries. </title> <booktitle> In Proceedings of the ACM SIGMOD Conf. on Management of Data, </booktitle> <pages> pages 28-36, </pages> <year> 1988. </year>
Reference-contexts: This previous work can be classified into four categories [20, 4], namely non-parametric, parametric, sampling and curve fitting. Let us briefly describe each of them; the reader can find more details in the references given above. The non-parametric method is table- or histogram-based <ref> [16, 15] </ref>. A histogram is built by dividing an attribute domain into intervals and counting the number of tuples which fall into the ranges of the intervals.
Reference: [16] <author> G. Piatetsky-Shapiro and C. Connell. </author> <title> Accurate Estimation of the Number of Tuples Satisfying a Condition. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference, </booktitle> <pages> pages 256-276, </pages> <address> 1984. Boston, Mass, June, </address> <publisher> ACM, </publisher> <address> New York. </address>
Reference-contexts: This previous work can be classified into four categories [20, 4], namely non-parametric, parametric, sampling and curve fitting. Let us briefly describe each of them; the reader can find more details in the references given above. The non-parametric method is table- or histogram-based <ref> [16, 15] </ref>. A histogram is built by dividing an attribute domain into intervals and counting the number of tuples which fall into the ranges of the intervals.
Reference: [17] <author> J. R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, Cali-fornia, </address> <year> 1993. </year>
Reference-contexts: The idea to construct a model tree is similar to growing a decision tree by C4.5 <ref> [17] </ref>. The difference is that the latter is based on maximising information gain while the former is based on minimising intra-subset variation of class values, i.e., query result sizes in our case.
Reference: [18] <author> J. R. Quinlan. </author> <title> Combining Instance-Based and Model-Based Learning. </title> <booktitle> In Proceedings of Machine Learning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: This technique was originally proposed by Quin-lan <ref> [18] </ref> as a combination of model-based learning and instance-based learning. Quinlan's experimental work suggested that the model tree approach to model-based learning was the most effective. A model tree is a regression tree and originated in work by Breiman et. al. [3]. <p> The algorithm was implemented to suit our own use in the query size estimation problem. Two major differences are that the version we implemented has no pruning procedure and no smoothing procedure. Furthermore, there may be other different internal fine-tunings between our version and the original version <ref> [18] </ref> such as the minimum number of queries in leaf nodes, the minimum error reduction to suppress the recursive partitioning, etc. The idea to construct a model tree is similar to growing a decision tree by C4.5 [17]. <p> p distance * Why don't we use: 3 X S q i fl w q i ; w q i = simval q i P 3 i=1 simval q i : as the query size estimate ^ S q u ? The answer is twofold: * The author described in <ref> [18] </ref> that equation M (q) allows taking into account the difference between the unseen query q u and a most similar query q i , i.e.: and if the equation M (q) is correct, then the adjusted value ( ~ S q i ): S q i (M (q i ) <p> is not the unseen query q u itself, the combination of their adjusted values in equation 2 based on their weights (this is the main principle of KNN) would produce a good estimate for the size of the unseen query. * The second answer is pragmatic: both the experiments in <ref> [18] </ref> and our own experiments show that equation 2 yields the best results. 4 Conclusions The following is what we have achieved in this pa per: * We have proposed a machine learning technique to solve the problem of query size estimation.
Reference: [19] <editor> P.G. Selinger, M.M. Astrahan, D.D. Chamber-lin, R.A. Lorie, and T.G. Price. </editor> <title> Access Path Selection in a Relational Database Management System. </title> <booktitle> In ACM SIGMOD, </booktitle> <pages> pages 23-34, </pages> <address> 1979. Boston, MA, </address> <month> June </month> <year> 1979. </year>
Reference-contexts: The method requires scanning an entire relation to build up the histogram and the performance (the accuracy of the size estimation) will not be satisfactory if the number of intervals used is too small. The parametric method <ref> [19, 5, 6] </ref> is one which depends upon underlying assumptions about the data distribution (e.g. uniform, normal, Poisson, Zipf, etc.). The method will give accurate query size estimates if the actual data distribution follows the a priori assumption.
Reference: [20] <author> W. Sun, Y. Ling, N. Rishe, and Y. Deng. </author> <title> An Instant and Accurate Size Estimation Method for Joins and Selection in a Retrieval-Intensive Environment. </title> <booktitle> In Proceedings of ACM SIGMOD, </booktitle> <pages> pages 79-88, </pages> <year> 1993. </year>
Reference-contexts: There has been a considerable amount of work on the issue of selectivity estimation over one and a half decades [19, 5, 6, 16, 11, 9, 14, 15, 13, 7, 20, 4]. This previous work can be classified into four categories <ref> [20, 4] </ref>, namely non-parametric, parametric, sampling and curve fitting. Let us briefly describe each of them; the reader can find more details in the references given above. The non-parametric method is table- or histogram-based [16, 15]. <p> Compared with other estimation methods which require no extra delay for the samplings, this could be a significant disadvantage. The curve-fitting method <ref> [20, 4] </ref> is based on polynomial regression to find the best-fit set of coefficients to minimise the criterion of least-squared error. The curve fitting method proposed by [20], scans entire relations and uses regression to determine the distributions of attribute values in each relation. <p> Compared with other estimation methods which require no extra delay for the samplings, this could be a significant disadvantage. The curve-fitting method [20, 4] is based on polynomial regression to find the best-fit set of coefficients to minimise the criterion of least-squared error. The curve fitting method proposed by <ref> [20] </ref>, scans entire relations and uses regression to determine the distributions of attribute values in each relation. This approach is effective only for low-update database systems. That is, as long as the distributions of attribute values remain fixed, the method performs satisfactorily. <p> Our method has the following advantages over the ASE method: * generic algorithm for updates: The algorithm we give in [8] with some slight modification can also be used with the size estimation methods proposed in <ref> [20, 4] </ref>. In other words, some size estimation methods proposed for retrieval-only or retrieval-intensive environments can be adapted for use with databases with high loads of updates. <p> The learning machine M5 has demonstrated its superior performance to the ASE method (see the results in [8]). * In [8] (the complete version of this paper), we have given a novel generic algorithm to correct the distinct-value-frequency list (x i ; f (x i )) <ref> [20] </ref>, the query feedback list (l i ; h i ; s i ) [4] and our training set of queries. <p> This algorithm re-validates the original query size estimation methods in <ref> [20, 4] </ref> which otherwise will be invalid, i.e., poor in query size estimation in the presence of very high loads of updates.
References-found: 20

