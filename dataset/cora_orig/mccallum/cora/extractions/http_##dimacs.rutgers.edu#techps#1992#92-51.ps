URL: http://dimacs.rutgers.edu/techps/1992/92-51.ps
Refering-URL: http://dimacs.rutgers.edu/TechnicalReports/1992.html
Root-URL: http://www.cs.rutgers.edu
Title: Weighted Multidimensional Search and its Application to Convex Optimization  
Author: by Richa Agarwala and David Fernandez-Baca ; 
Note: 2 Supported in part by the National Science Foundation under grants CCR-8909626 and CCR 9211262. DIMACS is a cooperative project of Rutgers University, Princeton University, AT&T Bell Laboratories and Bellcore. DIMACS is an NSF Science and Technology Center, funded under contract STC-91-19999; and also receives support from the New Jersey Commission on Science and Technology.  
Address: Ames, Iowa 50011  
Affiliation: Department of Computer Science Iowa State University  
Abstract: DIMACS Technical Report 92-51 March 1993 
Abstract-found: 1
Intro-found: 1
Reference: [AgFe92] <author> R. Agarwala and D. Fernandez-Baca. </author> <title> Solving the Lagrangian dual when the number of constraints is fixed. </title> <booktitle> To appear in Proceedings of 13th Conference on Software Technology and Theoretical Computer Science, Lecture Notes in Computer Science, </booktitle> <year> 1992. </year>
Reference-contexts: An earlier version of this paper appears in <ref> [AgFe92] </ref>. 2 Weighted Multidimensional Search Let us first introduce some notation. Suppose fl R d is convex and that h : R d ! R is an affine function.
Reference: [AKS83] <author> M. Ajtai, J. Komlos, and E. Szemeredi. </author> <title> A O(n log n) sorting network. </title> <booktitle> In Proceedings of the Fifteenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pp 1-9, </pages> <year> 1983. </year>
Reference-contexts: Noting that the crucial first stage of the greedy method (where all comparisons are done) can be carried out in parallel using a O (log n)-depth, O (n)-width sorting circuit <ref> [AKS83] </ref>, we can use the Cohen-Megiddo technique to obtain a - 18 - O ((n log n + n c (n)) log 2d n) algorithm using the approach outlined in Section 3, with the greedy algorithm playing the role of algorithm A.
Reference: [ALS91] <author> S. Arnborg, J. Lagergren, and D. Seese. </author> <title> Easy problems for tree-decomposable graphs. </title> <journal> J. Algorithms, </journal> <volume> 12 </volume> <pages> 308-340. </pages>
Reference-contexts: Even though many optimum subgraph problems are known to be NP-complete, several researchers have developed methodologies for devising linear-time algorithms for graphs of bounded tree-width <ref> [ALS91, ArPr89, Bod87, BPT88, BLW87, Wim87] </ref> (for a definition of tree-width, see [RoSe86]). While their approaches differ from each other in several respects, in essence they all deal with subgraph problems that have certain "regularity" properties that make them amenable to dynamic programming solutions. <p> The class of regular problems is broad, and includes the subgraph problems mentioned above, as well as many others, such as the maximum cut problem and the Steiner tree problem (see, e.g., <ref> [ALS91, BPT88, BLW87] </ref>). Suppose that, in addition to a weight function, every v 2 V (G) (e 2 E (G)) has a d-dimensional size vector s V (v) (s E (e)).
Reference: [AnKa91] <author> Y. P. Aneja and S. N. Kabadi. </author> <title> Polynomial algorithms for lagrangean relaxations in combinatorial problems. </title> <type> Manuscript. </type>
Reference-contexts: Part two (Section 3) discusses the application of our result to a class of convex optimization problems in fixed dimension which were studied earlier by Cohen and Megiddo [Coh91, CoMe91] and, in a different context, by Aneja and Kabadi <ref> [AnKa91] </ref>. In rough terms, the results in [Coh91, CoMe91, AnKa91] can be summarized as follows. <p> Part two (Section 3) discusses the application of our result to a class of convex optimization problems in fixed dimension which were studied earlier by Cohen and Megiddo [Coh91, CoMe91] and, in a different context, by Aneja and Kabadi [AnKa91]. In rough terms, the results in <ref> [Coh91, CoMe91, AnKa91] </ref> can be summarized as follows. <p> By applying weighted multidimensional search and a generalization of Cole's circuit simulation technique [Cole87] we are able to reduce this to O ((D d + log d M)T ) in some cases. Lagrangian relaxation is a source of several problems that fall into the framework described above <ref> [AnKa91] </ref>. This widely-used approach is based on the observation that many hard optimization problems are actually easy problems that are complicated by a relatively small set of side constraints. <p> The third part of this paper (Section 4) explains the application of our results to Lagrangian relaxation problems where the number of bad constraints is fixed. We give two examples of problems where the methods described in Section 3 give faster algorithms than those of <ref> [AnKa91, Coh91] </ref>: solving the Lagrangian duals of matroidal knapsack problems [CMV89] and of certain constrained optimum subgraph problems on graphs of bounded tree-width. An earlier version of this paper appears in [AgFe92]. 2 Weighted Multidimensional Search Let us first introduce some notation. <p> Closely related results were obtained by Norton, Plotkin, and Tardos [NPT92] and Aneja and Kabadi <ref> [AnKa91] </ref>. The main result of this section is to show that weighted multidimensional search in conjunction with Cole's circuit simulation technique [Cole87] can sometimes be used to solve (8) in O ((D d + log d M )T ) time. <p> To streamline the presentation, for the most part we shall omit any mention of constants that depend on d. The magnitude of these values is discussed in Section 3.3. 3.1 The Basic Scheme We now review the solution scheme of Megiddo and Cohen and Aneja and Kabadi <ref> [Coh91, AnKa91] </ref> as it forms the basis for our algorithm. Our presentation is somewhat simpler, among other reasons because it avoids the notion of "minimal weak approximation" used in [Coh91]. We shall assume that problem (8) is bounded. <p> Recently, Bertsimas and Orlin [BeOr91] have presented faster polynomial time algorithms for certain special cases. An issue that has received some attention <ref> [AnKa91] </ref> is whether there exist strongly polynomial algorithms to solve the Lagrangian dual. (An algorithm is said to be strongly polynomial if the number of arithmetic operations it carries out is polynomially bounded, - 17 - independently of the magnitudes of the input numbers.) The algorithms discussed above are not strongly
Reference: [ArPr89] <author> S. Arnborg and A. Proskurowski. </author> <title> Linear time algorithms for NP-hard problems restricted to partial k-trees. </title> <journal> Discr. Appl. Math., </journal> <volume> 23 </volume> <month> 11-24 </month> <year> (1989). </year>
Reference-contexts: Even though many optimum subgraph problems are known to be NP-complete, several researchers have developed methodologies for devising linear-time algorithms for graphs of bounded tree-width <ref> [ALS91, ArPr89, Bod87, BPT88, BLW87, Wim87] </ref> (for a definition of tree-width, see [RoSe86]). While their approaches differ from each other in several respects, in essence they all deal with subgraph problems that have certain "regularity" properties that make them amenable to dynamic programming solutions.
Reference: [BeOr91] <author> D. Bertsimas and J.B. Orlin. </author> <title> A technique for speeding up the solution of the La-grangean dual. </title> <note> Working Paper WP# 3278-91-MSA, </note> <institution> Sloan School of Management, MIT, </institution> <month> April </month> <year> 1991. </year> <booktitle> In Proceedings of IPCO 92. </booktitle>
Reference-contexts: It is well known that if Z D () can be computed in polynomial time for each fixed 0, then the Lagrangian dual can be solved in polynomial time [Sch86]. Recently, Bertsimas and Orlin <ref> [BeOr91] </ref> have presented faster polynomial time algorithms for certain special cases.
Reference: [BLW87] <author> M.W. Bern, E.L. Lawler, and A.L. Wong. </author> <title> Linear time computation of optimal subgraphs of decomposable graphs. </title> <journal> J. Algorithms, </journal> <volume> 8 </volume> <pages> 216-235, </pages> <year> 1987. </year>
Reference-contexts: Even though many optimum subgraph problems are known to be NP-complete, several researchers have developed methodologies for devising linear-time algorithms for graphs of bounded tree-width <ref> [ALS91, ArPr89, Bod87, BPT88, BLW87, Wim87] </ref> (for a definition of tree-width, see [RoSe86]). While their approaches differ from each other in several respects, in essence they all deal with subgraph problems that have certain "regularity" properties that make them amenable to dynamic programming solutions. <p> The class of regular problems is broad, and includes the subgraph problems mentioned above, as well as many others, such as the maximum cut problem and the Steiner tree problem (see, e.g., <ref> [ALS91, BPT88, BLW87] </ref>). Suppose that, in addition to a weight function, every v 2 V (G) (e 2 E (G)) has a d-dimensional size vector s V (v) (s E (e)).
Reference: [Bod87] <author> H.L. Bodlaender. </author> <title> Dynamic programming on graphs with bounded tree-width. </title> <type> Technical Report RUU-CS-88-4, </type> <institution> University of Utrecht, </institution> <year> 1988. </year> <note> Extended Abstract in Proceedings of ICALP88. </note>
Reference-contexts: Even though many optimum subgraph problems are known to be NP-complete, several researchers have developed methodologies for devising linear-time algorithms for graphs of bounded tree-width <ref> [ALS91, ArPr89, Bod87, BPT88, BLW87, Wim87] </ref> (for a definition of tree-width, see [RoSe86]). While their approaches differ from each other in several respects, in essence they all deal with subgraph problems that have certain "regularity" properties that make them amenable to dynamic programming solutions.
Reference: [BPT88] <author> R.B. Borie, R.G. Parker, </author> <title> and C.A. Tovey. Automatic generation of linear-time algorithms &gt;from predicate-calculus descriptions of problems on recursively-constructed graph families. </title> <type> Manuscript, </type> <year> 1988. </year> <note> To appear in Algorithmica. </note>
Reference-contexts: Even though many optimum subgraph problems are known to be NP-complete, several researchers have developed methodologies for devising linear-time algorithms for graphs of bounded tree-width <ref> [ALS91, ArPr89, Bod87, BPT88, BLW87, Wim87] </ref> (for a definition of tree-width, see [RoSe86]). While their approaches differ from each other in several respects, in essence they all deal with subgraph problems that have certain "regularity" properties that make them amenable to dynamic programming solutions. <p> The class of regular problems is broad, and includes the subgraph problems mentioned above, as well as many others, such as the maximum cut problem and the Steiner tree problem (see, e.g., <ref> [ALS91, BPT88, BLW87] </ref>). Suppose that, in addition to a weight function, every v 2 V (G) (e 2 E (G)) has a d-dimensional size vector s V (v) (s E (e)).
Reference: [Cla86] <author> K.L. Clarkson. </author> <title> Linear programming in O(n fi 3 d 2 ) time. </title> <journal> Information Processing Letters 22 </journal> <month> 21-24 </month> <year> (1986). </year>
Reference-contexts: 1 Introduction This paper has three main parts. In the first (Section 2) we present a weighted version of the multidimensional search technique of Megiddo <ref> [Meg84, Dyer86, Cla86] </ref>. Part two (Section 3) discusses the application of our result to a class of convex optimization problems in fixed dimension which were studied earlier by Cohen and Megiddo [Coh91, CoMe91] and, in a different context, by Aneja and Kabadi [AnKa91]. <p> The problem is to resolve every h 2 H using as few oracle calls as possible. The following result is proved in <ref> [Meg84, Dyer86, Cla86] </ref>. <p> Using standard techniques <ref> [Cla86, Dyer86] </ref>, it can be shown that the algorithms described in this section have hidden constants of the form 2 O (d 2 ) , provided the search algorithm with singly exponentially small efficiency is used. Some improvements are possible.
Reference: [CMV89] <author> P.M. Camerini, F. Maffioli, and C. Vercellis. </author> <title> Multi-constrained matroidal knapsack problems. </title> <booktitle> Mathematical Programming 45 </booktitle> <month> 211-231 </month> <year> (1989). </year>
Reference-contexts: We give two examples of problems where the methods described in Section 3 give faster algorithms than those of [AnKa91, Coh91]: solving the Lagrangian duals of matroidal knapsack problems <ref> [CMV89] </ref> and of certain constrained optimum subgraph problems on graphs of bounded tree-width. An earlier version of this paper appears in [AgFe92]. 2 Weighted Multidimensional Search Let us first introduce some notation. Suppose fl R d is convex and that h : R d ! R is an affine function. <p> The problem is to find a base G fl such that Z fl = e2G fl G2G X v (e) : e2G ) We refer the reader to Camerini et. al. <ref> [CMV89] </ref> for a discussion of the various applications of these problems, as well as for references. MMK problems are in general NP-hard. We can bound Z fl by solving its Lagrangian dual. <p> MMK problems are in general NP-hard. We can bound Z fl by solving its Lagrangian dual. Let Z D () = max ( e2G X s (e) C) The Lagrangian dual is: Z fl D = minfZ D () : 0g: (14) In <ref> [CMV89] </ref>, Camerini et al. outline an algorithm for (14) whose running time is not guaranteed to be polynomial.
Reference: [CLR90] <author> T.H. Cormen, C.E. Leiserson, and R.L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA 1990. </address> - <month> 20 </month> - 
Reference-contexts: Step 1 takes O (n) time as elements a and b can be found by repeated median finding <ref> [CLR90] </ref>. Steps 2 and 3 also take linear time, as Match takes linear time. - 5 - 2.2 The Search Algorithm We shall now prove Theorem 2. <p> Like Megiddo's method, Cole's technique applies to one-dimensional paramet ric search problems, but we shall show that it can be extended to higher dimensions. What follows shall require some elementary knowledge of combinational circuits as described, say, in <ref> [CLR90] </ref>. A combinational circuit G is a directed acyclic graph whose nodes are combinational elements (e.g., adders, min gates, etc.), and where an edge from element e 1 to element e 2 implies that the output of e 1 is an input to e 2 .
Reference: [Chv83] <author> V. Chvatal. </author> <title> Linear Programming. W.H. </title> <publisher> Freeman, </publisher> <address> San Francisco 1983. </address>
Reference-contexts: Several well-known algorithms fall into this category, including many network optimization algorithms <ref> [Chv83, Tarj83] </ref>. Suppose Q R d is a (possibly empty) convex set defined by a set of at most l linear inequalities, where l is some fixed integer. Let g : Q ! R be a concave function. <p> By (9), * i d+1 ; : : : ; * i s , can be assumed to be arbitrarily smaller than * i d . Thus sign (t) = sign (t d ). We should note that the use of perturbation techniques is common in mathematical programming <ref> [Chv83, Sch86] </ref>, one example being the lexicographic rule applied in the simplex - 13 - algorithm. Perturbation methods have also found applications in computational geometry [Ede87]. Let c (d) be the running time of C d .
Reference: [Coh91] <author> E. Cohen. </author> <title> Combinatorial algorithms for optimization problems. </title> <type> Report No. </type> <institution> STAN-CS-91-1366, Department of Computer Science, Stanford University, Stanford, </institution> <address> CA 94305. </address>
Reference-contexts: In the first (Section 2) we present a weighted version of the multidimensional search technique of Megiddo [Meg84, Dyer86, Cla86]. Part two (Section 3) discusses the application of our result to a class of convex optimization problems in fixed dimension which were studied earlier by Cohen and Megiddo <ref> [Coh91, CoMe91] </ref> and, in a different context, by Aneja and Kabadi [AnKa91]. In rough terms, the results in [Coh91, CoMe91, AnKa91] can be summarized as follows. <p> Part two (Section 3) discusses the application of our result to a class of convex optimization problems in fixed dimension which were studied earlier by Cohen and Megiddo [Coh91, CoMe91] and, in a different context, by Aneja and Kabadi [AnKa91]. In rough terms, the results in <ref> [Coh91, CoMe91, AnKa91] </ref> can be summarized as follows. <p> The third part of this paper (Section 4) explains the application of our results to Lagrangian relaxation problems where the number of bad constraints is fixed. We give two examples of problems where the methods described in Section 3 give faster algorithms than those of <ref> [AnKa91, Coh91] </ref>: solving the Lagrangian duals of matroidal knapsack problems [CMV89] and of certain constrained optimum subgraph problems on graphs of bounded tree-width. An earlier version of this paper appears in [AgFe92]. 2 Weighted Multidimensional Search Let us first introduce some notation. <p> have a procedure S (d; 2 (60 d1 ); 1=12) whose efficiency is singly exponentially small. 3 Convex Optimization in Fixed Dimension An algorithm is piecewise affine if the only operations it performs on intermediate values that depend on the input numbers are additions, multiplications by constants, copies, and comparisons <ref> [Coh91, CoMe91] </ref>. Several well-known algorithms fall into this category, including many network optimization algorithms [Chv83, Tarj83]. Suppose Q R d is a (possibly empty) convex set defined by a set of at most l linear inequalities, where l is some fixed integer. <p> Let g : Q ! R be a concave function. Our goal is to compute g fl = maxfg () : 2 Qg: (8) or, if Q = ;, to return a message that this problem is infeasible. Cohen and Megiddo <ref> [Coh91, CoMe91] </ref> showed that, if g is computable by a piecewise affine algorithm that runs in time T and makes D sets of at most M comparisons, then problem (8) can be solved in O ((D log M ) d T ) time. <p> To streamline the presentation, for the most part we shall omit any mention of constants that depend on d. The magnitude of these values is discussed in Section 3.3. 3.1 The Basic Scheme We now review the solution scheme of Megiddo and Cohen and Aneja and Kabadi <ref> [Coh91, AnKa91] </ref> as it forms the basis for our algorithm. Our presentation is somewhat simpler, among other reasons because it avoids the notion of "minimal weak approximation" used in [Coh91]. We shall assume that problem (8) is bounded. <p> Our presentation is somewhat simpler, among other reasons because it avoids the notion of "minimal weak approximation" used in <ref> [Coh91] </ref>. We shall assume that problem (8) is bounded. This is done without loss of generality, since unbounded problems can be handled by Seidel's technique of adding "constraints at infinity" [Sei91]. <p> This is done without loss of generality, since unbounded problems can be handled by Seidel's technique of adding "constraints at infinity" [Sei91]. Note also that if g is computable by a piecewise affine algorithm, it is the lower envelope of a finite set of linear functions <ref> [Coh91] </ref>. <p> Megiddo [Meg83] proposed a way to do this in the context of one-dimensional problems, an idea that has subsequently been used in multi-dimensional optimization <ref> [Coh91, NPT92] </ref>. Megiddo's approach is to simulate the execution of a parallel algorithm A for computing g () rather than a sequential one. Suppose A uses M processors and carries out at most D parallel steps.
Reference: [CoMe91] <author> E. Cohen and N. Megiddo. </author> <title> Complexity analysis and algorithms for some flow problems. </title> <booktitle> In Proc. 2nd ACM Symposium on Discrete Algorithms, </booktitle> <pages> pp. 120-130, </pages> <year> 1991. </year>
Reference-contexts: In the first (Section 2) we present a weighted version of the multidimensional search technique of Megiddo [Meg84, Dyer86, Cla86]. Part two (Section 3) discusses the application of our result to a class of convex optimization problems in fixed dimension which were studied earlier by Cohen and Megiddo <ref> [Coh91, CoMe91] </ref> and, in a different context, by Aneja and Kabadi [AnKa91]. In rough terms, the results in [Coh91, CoMe91, AnKa91] can be summarized as follows. <p> Part two (Section 3) discusses the application of our result to a class of convex optimization problems in fixed dimension which were studied earlier by Cohen and Megiddo [Coh91, CoMe91] and, in a different context, by Aneja and Kabadi [AnKa91]. In rough terms, the results in <ref> [Coh91, CoMe91, AnKa91] </ref> can be summarized as follows. <p> have a procedure S (d; 2 (60 d1 ); 1=12) whose efficiency is singly exponentially small. 3 Convex Optimization in Fixed Dimension An algorithm is piecewise affine if the only operations it performs on intermediate values that depend on the input numbers are additions, multiplications by constants, copies, and comparisons <ref> [Coh91, CoMe91] </ref>. Several well-known algorithms fall into this category, including many network optimization algorithms [Chv83, Tarj83]. Suppose Q R d is a (possibly empty) convex set defined by a set of at most l linear inequalities, where l is some fixed integer. <p> Let g : Q ! R be a concave function. Our goal is to compute g fl = maxfg () : 2 Qg: (8) or, if Q = ;, to return a message that this problem is infeasible. Cohen and Megiddo <ref> [Coh91, CoMe91] </ref> showed that, if g is computable by a piecewise affine algorithm that runs in time T and makes D sets of at most M comparisons, then problem (8) can be solved in O ((D log M ) d T ) time.
Reference: [Cole87] <author> R. Cole. </author> <title> Slowing down sorting networks to obtain faster sorting algorithms. </title> <journal> J. Assoc. Comput. Mach. </journal> <volume> 34(1) </volume> <pages> 200-208, </pages> <year> 1987. </year>
Reference-contexts: Thus, if A carries out D parallel steps, each of which does at most M comparisons, the running time will be O ((D log M ) d T ). By applying weighted multidimensional search and a generalization of Cole's circuit simulation technique <ref> [Cole87] </ref> we are able to reduce this to O ((D d + log d M)T ) in some cases. Lagrangian relaxation is a source of several problems that fall into the framework described above [AnKa91]. <p> Closely related results were obtained by Norton, Plotkin, and Tardos [NPT92] and Aneja and Kabadi [AnKa91]. The main result of this section is to show that weighted multidimensional search in conjunction with Cole's circuit simulation technique <ref> [Cole87] </ref> can sometimes be used to solve (8) in O ((D d + log d M )T ) time. To streamline the presentation, for the most part we shall omit any mention of constants that depend on d. <p> Since B d is implemented by making at most three recursive calls to C d1 , and b (1) = O (T ), the running time of C d will be O ((D log d M ) d T ). Cole <ref> [Cole87] </ref> showed that one can improve on Megiddo's results for certain important special cases. Like Megiddo's method, Cole's technique applies to one-dimensional paramet ric search problems, but we shall show that it can be extended to higher dimensions. <p> An ff-oracle with respect to w | or simply an ff-oracle | is a procedure that is guaranteed to resolve a set of active elements whose total weight is at least ffW=2. The following is a restatement and an extension of a result in <ref> [Cole87] </ref>. Lemma 5 Let G be a combinatorial circuit of width M and depth D. Let d min = minfd I ; d O g, where d I (d O ) denotes the maximum fan-in (fan-out) of an element of G.
Reference: [Dyer86] <author> M. E. Dyer. </author> <title> On a multidimensional search technique and its application to the Euclidean one-centre problem. </title> <journal> SIAM J. Comput. </journal> <volume> 15(3) </volume> <month> 725-738 </month> <year> (1986). </year>
Reference-contexts: 1 Introduction This paper has three main parts. In the first (Section 2) we present a weighted version of the multidimensional search technique of Megiddo <ref> [Meg84, Dyer86, Cla86] </ref>. Part two (Section 3) discusses the application of our result to a class of convex optimization problems in fixed dimension which were studied earlier by Cohen and Megiddo [Coh91, CoMe91] and, in a different context, by Aneja and Kabadi [AnKa91]. <p> The problem is to resolve every h 2 H using as few oracle calls as possible. The following result is proved in <ref> [Meg84, Dyer86, Cla86] </ref>. <p> Steps 2 and 3 also take linear time, as Match takes linear time. - 5 - 2.2 The Search Algorithm We shall now prove Theorem 2. The implementation of Weighted-Search that we propose is an extension of Megiddo [Meg84] and Dyer's <ref> [Dyer86] </ref> algorithms for unweighted multidimensional search (see Theorem 1). Suppose H = fh 1 ; : : : ; h n g, where h i (x) = a T i + d i . <p> Hence, fi (d) = 2 d 1 and ff (d) = 12=24 2 d1 . The same arguments as in <ref> [Dyer86] </ref> can be used to show that the total work done by Weighted-Search is O (n). We omit the details. 2.3 Improving the Efficiency of the Search Following Dyer [Dyer86], the efficiency of a search scheme is the ratio e = ff (d)=fi (d). <p> Hence, fi (d) = 2 d 1 and ff (d) = 12=24 2 d1 . The same arguments as in <ref> [Dyer86] </ref> can be used to show that the total work done by Weighted-Search is O (n). We omit the details. 2.3 Improving the Efficiency of the Search Following Dyer [Dyer86], the efficiency of a search scheme is the ratio e = ff (d)=fi (d). As for unweighted search, the efficiency of a weighted search scheme will affect the running time of the algorithms that use the scheme as a subroutine. <p> As for unweighted search, the efficiency of a weighted search scheme will affect the running time of the algorithms that use the scheme as a subroutine. The search scheme we have just presented has e that is doubly exponentially small in d. Borrowing ideas from <ref> [Dyer86] </ref>, we shall sketch how to make the efficiency singly exponentially small. <p> that b (1) = O (T ), we can deduce that the running time of C d is O ((D d + log d M )T ). 3.3 Some Remarks on Constant Factors The use of multidimensional search schemes seems to lead invariably to large constants that depend on d <ref> [Dyer86] </ref>. Using standard techniques [Cla86, Dyer86], it can be shown that the algorithms described in this section have hidden constants of the form 2 O (d 2 ) , provided the search algorithm with singly exponentially small efficiency is used. Some improvements are possible. <p> Using standard techniques <ref> [Cla86, Dyer86] </ref>, it can be shown that the algorithms described in this section have hidden constants of the form 2 O (d 2 ) , provided the search algorithm with singly exponentially small efficiency is used. Some improvements are possible.
Reference: [Ede87] <author> H. Edelsbrunner. </author> <title> Algorithms in Combinatorial Geometry. </title> <publisher> Springer-Verlag, </publisher> <month> Heidel-berg </month> <year> 1987 </year>
Reference-contexts: Thus sign (t) = sign (t d ). We should note that the use of perturbation techniques is common in mathematical programming [Chv83, Sch86], one example being the lexicographic rule applied in the simplex - 13 - algorithm. Perturbation methods have also found applications in computational geometry <ref> [Ede87] </ref>. Let c (d) be the running time of C d .
Reference: [FeSl92] <author> D. Fernandez-Baca and G. Slutzki. </author> <title> Parametric problems on graphs of bounded tree-width. </title> <booktitle> In Proceedings of the 3rd Scandinavian Workshop on Algorithm Theory, </booktitle> <publisher> Springer-Verlag LNCS, </publisher> <year> 1992. </year>
Reference-contexts: Also, as proved in <ref> [FeSl92] </ref>, there exists a O (n)-size, O (log n)-depth combinational circuit - 19 - that computes Z P G () for any fixed . Thus, the results of Cohen and Megiddo summarized in Section 3 imply that the Lagrangian dual can be solved in O (n log 2d n) time.
Reference: [Fis81] <author> M. L. Fisher. </author> <title> The Lagrangian relaxation method for solving integer programming problems. </title> <booktitle> Management Science 27(1) </booktitle> <pages> 1-18, </pages> <year> (1981). </year>
Reference-contexts: Ax 0 into the objective function by introducing a vector = ( 1 ; ; d ) of Lagrange multipliers as follows: Z D () = minfc T x + T Ax : x 2 Xg: (12) It is well known that Z D () Z P for all 0 <ref> [Fis81] </ref>. Thus, if there is an polynomial-time algorithm to compute Z D () for any fixed 0, problem (12) will provide an efficient way to obtain a lower bound on the solution to (11). Such a bound can be of great utility in branch-and-bound methods. <p> Computational experiments have repeatedly shown that Z fl D provides excellent lower bounds on the optimum solution of Z P <ref> [Fis81] </ref>, thus motivating the search for efficient algorithms to solve the Lagrangian dual. One widely-used method is subgradient optimization, first proposed in [HeKa71]. Despite its success in practice, this technique is not known to be a polynomial-time algorithm, even if (12) can be solved in polynomial time.
Reference: [HeKa70] <author> M. Held and R.M. Karp. </author> <title> The traveling salesman problem and minimum spanning trees. </title> <note> Operations Research 18 </note> <month> 1138-1162 </month> <year> (1970). </year>
Reference-contexts: of the optimization algorithm will still have a constant of the form 2 O (d 2 ) , but the constant inside the O will be smaller. 4 Solving the Lagrangian Dual when the Number of Constraints is Fixed The method of Lagrangian relaxation, originally developed by Held and Karp <ref> [HeKa70, HeKa71] </ref>, is motivated by the observation that many combinatorial problems that are known to be NP-hard can be viewed as easy problems complicated by a relatively small set of side constraints.
Reference: [HeKa71] <author> M. Held and R.M. Karp. </author> <title> The traveling salesman problem and minimum spanning trees: part II. </title> <booktitle> Mathematical Programming 6 </booktitle> <month> 6-25 </month> <year> (1971). </year>
Reference-contexts: of the optimization algorithm will still have a constant of the form 2 O (d 2 ) , but the constant inside the O will be smaller. 4 Solving the Lagrangian Dual when the Number of Constraints is Fixed The method of Lagrangian relaxation, originally developed by Held and Karp <ref> [HeKa70, HeKa71] </ref>, is motivated by the observation that many combinatorial problems that are known to be NP-hard can be viewed as easy problems complicated by a relatively small set of side constraints. <p> Computational experiments have repeatedly shown that Z fl D provides excellent lower bounds on the optimum solution of Z P [Fis81], thus motivating the search for efficient algorithms to solve the Lagrangian dual. One widely-used method is subgradient optimization, first proposed in <ref> [HeKa71] </ref>. Despite its success in practice, this technique is not known to be a polynomial-time algorithm, even if (12) can be solved in polynomial time.
Reference: [Law76] <author> E. Lawler. </author> <title> Combinatorial Optimization: Networks and Matroids. </title> <publisher> Holt, Rinehart, and Winston, </publisher> <year> 1976. </year>
Reference-contexts: two broad families of problems where weighted multidimensional search allows us to obtain faster algorithms that the Megiddo-Cohen approach: matroidal knapsack problems and of a class of constrained optimum subgraph problems on graphs of bounded tree-width. 4.1 Matroidal Knapsack Problems What follows presupposes some familiarity with matroid theory (see, e.g., <ref> [Law76] </ref>). Consider a matroid M = (E; G) where E, the ground set, is a finite set and G is a collection of certain subsets of E called independent sets.
Reference: [McPe90] <author> J. McHugh and Y. </author> <title> Perl. Best location of service centers in a treelike network under budget constraints. </title> <journal> Discrete Mathematics, </journal> <volume> 86 </volume> <month> 199-214 </month> <year> (1990). </year>
Reference-contexts: Even if the unconstrained problem is polynomially solvable, the constrained one may be NP-hard. Such is the case, for example, for the domi nating set problem on trees (which are graphs of tree-width 1), even if d = 1 <ref> [McPe90] </ref>. For every v 2 V (G), let W V (v; ) = w V (v) + T s V (v) and for every e 2 E (G), let W E (e; ) = w E (e)+ T s E (e).
Reference: [Meg79] <author> N. Megiddo. </author> <title> Combinatorial optimization with rational objective functions. </title> <journal> Math. Oper. Res. </journal> <volume> 4 </volume> <pages> 414-424. </pages>
Reference-contexts: First, it determines whether Q is empty and, if so, returns a message saying that (8) is infeasible. Since Q is defined by a fixed number of linear inequalities, this takes O (1) time. If Q 6= ;, C d uses Megiddo's algorithm simulation technique <ref> [Meg79, Meg83] </ref> to do one of two things. The first option is to find a hyperplane H defined by h () = 0, such that sign fl (h) = 0. Then, clearly g fl = g fl H .
Reference: [Meg83] <author> N. Megiddo. </author> <title> Applying parallel computation algorithms in the design of serial algorithms. </title> <journal> J. Assoc. Comput. Mach. </journal> <volume> 30(4) </volume> <pages> 852-865, </pages> <year> (1983). </year>
Reference-contexts: First, it determines whether Q is empty and, if so, returns a message saying that (8) is infeasible. Since Q is defined by a fixed number of linear inequalities, this takes O (1) time. If Q 6= ;, C d uses Megiddo's algorithm simulation technique <ref> [Meg79, Meg83] </ref> to do one of two things. The first option is to find a hyperplane H defined by h () = 0, such that sign fl (h) = 0. Then, clearly g fl = g fl H . <p> One way to reduce this problem is to arrange things so that by using a small number of oracle calls we are able to resolve a large number of functions. Megiddo <ref> [Meg83] </ref> proposed a way to do this in the context of one-dimensional problems, an idea that has subsequently been used in multi-dimensional optimization [Coh91, NPT92]. Megiddo's approach is to simulate the execution of a parallel algorithm A for computing g () rather than a sequential one.
Reference: [Meg84] <author> N. Megiddo. </author> <title> Linear programming in linear time when the dimension is fixed. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 31 </volume> <pages> 114-127, </pages> <year> 1984. </year> <month> - 21 </month> - 
Reference-contexts: 1 Introduction This paper has three main parts. In the first (Section 2) we present a weighted version of the multidimensional search technique of Megiddo <ref> [Meg84, Dyer86, Cla86] </ref>. Part two (Section 3) discusses the application of our result to a class of convex optimization problems in fixed dimension which were studied earlier by Cohen and Megiddo [Coh91, CoMe91] and, in a different context, by Aneja and Kabadi [AnKa91]. <p> The problem is to resolve every h 2 H using as few oracle calls as possible. The following result is proved in <ref> [Meg84, Dyer86, Cla86] </ref>. <p> Steps 2 and 3 also take linear time, as Match takes linear time. - 5 - 2.2 The Search Algorithm We shall now prove Theorem 2. The implementation of Weighted-Search that we propose is an extension of Megiddo <ref> [Meg84] </ref> and Dyer's [Dyer86] algorithms for unweighted multidimensional search (see Theorem 1). Suppose H = fh 1 ; : : : ; h n g, where h i (x) = a T i + d i . <p> We now rely on an observation of Megiddo <ref> [Meg84] </ref>, who noted that if we know the position of fl relative to both H (1) (2) ij , we can determine the position of fl relative to at least one of H i and H ij . <p> In this case, solving (8) reduces to solving the linear programming problem maxff () : 2 Q fl g; which can be done in time linear in L, since d is fixed <ref> [Meg84] </ref>. C d relies on the observation that, because A is piecewise affine and its inputs are linear functions of , all the intermediate values of its real variables can be represented implicitly as linear forms in . <p> Furthermore, the output of A will be a linear function f satisfying condition (C2). Since A does O (T ) comparisons, jLj = O (T ) and the resulting linear program in d variables can be solved in O (T ) time <ref> [Meg84] </ref>. The total time for algorithm C d is therefore O (T b (d)), where b (d) is the running time of B d . We now turn our attention to the implementation of B d . Implementing the oracle.
Reference: [NPT92] <author> C.H. Norton, S.A. Plotkin, and E. Tardos. </author> <title> Using separation algorithms in fixed dimension. </title> <editor> J. </editor> <booktitle> Algorithms 13 </booktitle> <month> 79-98 </month> <year> (1992). </year>
Reference-contexts: Closely related results were obtained by Norton, Plotkin, and Tardos <ref> [NPT92] </ref> and Aneja and Kabadi [AnKa91]. The main result of this section is to show that weighted multidimensional search in conjunction with Cole's circuit simulation technique [Cole87] can sometimes be used to solve (8) in O ((D d + log d M )T ) time. <p> Megiddo [Meg83] proposed a way to do this in the context of one-dimensional problems, an idea that has subsequently been used in multi-dimensional optimization <ref> [Coh91, NPT92] </ref>. Megiddo's approach is to simulate the execution of a parallel algorithm A for computing g () rather than a sequential one. Suppose A uses M processors and carries out at most D parallel steps.
Reference: [RoSe86] <author> N. Robertson and P.D. Seymour. </author> <title> Graph minors II: Algorithmic aspects of tree-width. </title> <editor> J. </editor> <booktitle> Algorithms 7 </booktitle> <month> 309-322 </month> <year> (1986). </year>
Reference-contexts: Even though many optimum subgraph problems are known to be NP-complete, several researchers have developed methodologies for devising linear-time algorithms for graphs of bounded tree-width [ALS91, ArPr89, Bod87, BPT88, BLW87, Wim87] (for a definition of tree-width, see <ref> [RoSe86] </ref>). While their approaches differ from each other in several respects, in essence they all deal with subgraph problems that have certain "regularity" properties that make them amenable to dynamic programming solutions.
Reference: [Sch86] <author> A. Schrijver. </author> <title> Theory of Linear and Integer Programming. </title> <publisher> Wiley, </publisher> <address> Chichester 1986. </address>
Reference-contexts: By (9), * i d+1 ; : : : ; * i s , can be assumed to be arbitrarily smaller than * i d . Thus sign (t) = sign (t d ). We should note that the use of perturbation techniques is common in mathematical programming <ref> [Chv83, Sch86] </ref>, one example being the lexicographic rule applied in the simplex - 13 - algorithm. Perturbation methods have also found applications in computational geometry [Ede87]. Let c (d) be the running time of C d . <p> It is well known that if Z D () can be computed in polynomial time for each fixed 0, then the Lagrangian dual can be solved in polynomial time <ref> [Sch86] </ref>. Recently, Bertsimas and Orlin [BeOr91] have presented faster polynomial time algorithms for certain special cases. <p> We shall be interested here only in the case where the number d of complicating constraints is fixed. Since Z D is a concave function <ref> [Sch86] </ref>, if Z D () is computable in strongly polynomial time by a piecewise affine algorithm, the results of Megiddo and Cohen described in Section 3 imply the existence of strongly polynomial time algorithms to solve the Lagrangian dual.
Reference: [Sei91] <author> R. Seidel. </author> <title> Small-dimensional linear programming and convex hulls made easy. </title> <journal> Discrete Comput. Geom. </journal> <volume> 6 </volume> <month> 423-434 </month> <year> (1991). </year>
Reference-contexts: Our presentation is somewhat simpler, among other reasons because it avoids the notion of "minimal weak approximation" used in [Coh91]. We shall assume that problem (8) is bounded. This is done without loss of generality, since unbounded problems can be handled by Seidel's technique of adding "constraints at infinity" <ref> [Sei91] </ref>. Note also that if g is computable by a piecewise affine algorithm, it is the lower envelope of a finite set of linear functions [Coh91].
Reference: [Tarj83] <author> R.E. Tarjan. </author> <title> Data Structures and Network Algorithms. </title> <publisher> SIAM Press, </publisher> <address> Philadelphia 1983. </address>
Reference-contexts: Several well-known algorithms fall into this category, including many network optimization algorithms <ref> [Chv83, Tarj83] </ref>. Suppose Q R d is a (possibly empty) convex set defined by a set of at most l linear inequalities, where l is some fixed integer. Let g : Q ! R be a concave function.
Reference: [Wim87] <author> T.V. Wimer. </author> <title> Linear algorithms on k-terminal graphs. </title> <type> Ph.D. Thesis, Report No. </type> <institution> URI-030, Clemson University (1987). </institution>
Reference-contexts: Even though many optimum subgraph problems are known to be NP-complete, several researchers have developed methodologies for devising linear-time algorithms for graphs of bounded tree-width <ref> [ALS91, ArPr89, Bod87, BPT88, BLW87, Wim87] </ref> (for a definition of tree-width, see [RoSe86]). While their approaches differ from each other in several respects, in essence they all deal with subgraph problems that have certain "regularity" properties that make them amenable to dynamic programming solutions.
References-found: 33

