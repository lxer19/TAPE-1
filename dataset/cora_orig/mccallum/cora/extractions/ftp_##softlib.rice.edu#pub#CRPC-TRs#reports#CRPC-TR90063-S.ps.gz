URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR90063-S.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> D. Callahan and K. Kennedy, </author> <title> "Analysis of interprocedural side effects in a parallel programming environment," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 5, </volume> <pages> pp. 517-550, </pages> <year> 1988. </year>
Reference-contexts: In an earlier paper, Callahan and Kennedy proposed a method called regular section analysis for tracking interprocedural side-effects. Regular sections describe side effects to common substructures of arrays such as elements, rows, columns and diagonals <ref> [1, 2] </ref>. This paper describes an implementation of regular section analysis in the Rice Parallel Fortran Converter (PFC) [3], an automatic parallelization system that also computes dependences for the ParaScope programming environment [4]. <p> The contrived example in Figure 1 shows the different patterns that they can represent precisely. Evaluating these methods involves examining the complexity and precision of: A fA [i; j] j j 2i; 9j 4i + 14; 3j 28 ig fA <ref> [1; 2] </ref>; A [4; 8]; A [10; 6]g Classical Summary Triolet Burke & Cytron Li & Yew Regular Sections Without Bounds With Bounds & Strides DAD/Simple Section fA [i; j] j 1 i 10; 2 j 8; 4 * representing the sets M A S 1 and U A * merging <p> Unfortunately, our experiences with PFC and Ptool indicate that this summary information is too coarse for dependence testing and the effective detection of parallelism <ref> [1] </ref>. The problem is that the only access sets representable in this method are "the whole array" and "none of the array" (see Figure 1). <p> Operations on descriptors should be linear or, at worst, quadratic in the rank of the array. Researchers at Rice have defined several variants of regular sections to represent common access patterns while satisfying these constraints <ref> [2, 1, 22, 23] </ref>. Original Regular Sections Callahan's thesis proposed two regular section frameworks. The first, resembling Li and Yew's atom images, he dismissed due to the difficulty of devising efficient standardization and meet operations [2]. Restricted Regular Sections. <p> Original Regular Sections Callahan's thesis proposed two regular section frameworks. The first, resembling Li and Yew's atom images, he dismissed due to the difficulty of devising efficient standardization and meet operations [2]. Restricted Regular Sections. The second framework, restricted regular sections <ref> [2, 1] </ref>, is limited to access patterns in which each subscript is * a procedure-invariant expression (with constants and procedure inputs), * unknown (and assumed to vary over the entire range of the dimension), or 7 * unknown but diagonal with one or more other subscripts.
Reference: [2] <author> D. Callahan, </author> <title> A Global Approach to Detection of Parallelism. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> Mar. </month> <year> 1987. </year>
Reference-contexts: In an earlier paper, Callahan and Kennedy proposed a method called regular section analysis for tracking interprocedural side-effects. Regular sections describe side effects to common substructures of arrays such as elements, rows, columns and diagonals <ref> [1, 2] </ref>. This paper describes an implementation of regular section analysis in the Rice Parallel Fortran Converter (PFC) [3], an automatic parallelization system that also computes dependences for the ParaScope programming environment [4]. <p> The contrived example in Figure 1 shows the different patterns that they can represent precisely. Evaluating these methods involves examining the complexity and precision of: A fA [i; j] j j 2i; 9j 4i + 14; 3j 28 ig fA <ref> [1; 2] </ref>; A [4; 8]; A [10; 6]g Classical Summary Triolet Burke & Cytron Li & Yew Regular Sections Without Bounds With Bounds & Strides DAD/Simple Section fA [i; j] j 1 i 10; 2 j 8; 4 * representing the sets M A S 1 and U A * merging <p> Atom Images Li and Yew extended Parafrase to compute sets of atom images describing the side effects of procedures [21, 11]. Like the original version of regular sections described in Callahan's thesis <ref> [2] </ref>, these record subscript expressions that are linear in loop induction variables along with bounds on the induction variables. Any reference with linear subscript expressions in a triangular iteration space can be precisely represented, and they keep a separate atom image for each reference. <p> Operations on descriptors should be linear or, at worst, quadratic in the rank of the array. Researchers at Rice have defined several variants of regular sections to represent common access patterns while satisfying these constraints <ref> [2, 1, 22, 23] </ref>. Original Regular Sections Callahan's thesis proposed two regular section frameworks. The first, resembling Li and Yew's atom images, he dismissed due to the difficulty of devising efficient standardization and meet operations [2]. Restricted Regular Sections. <p> Original Regular Sections Callahan's thesis proposed two regular section frameworks. The first, resembling Li and Yew's atom images, he dismissed due to the difficulty of devising efficient standardization and meet operations <ref> [2] </ref>. Restricted Regular Sections. <p> Original Regular Sections Callahan's thesis proposed two regular section frameworks. The first, resembling Li and Yew's atom images, he dismissed due to the difficulty of devising efficient standardization and meet operations [2]. Restricted Regular Sections. The second framework, restricted regular sections <ref> [2, 1] </ref>, is limited to access patterns in which each subscript is * a procedure-invariant expression (with constants and procedure inputs), * unknown (and assumed to vary over the entire range of the dimension), or 7 * unknown but diagonal with one or more other subscripts.
Reference: [3] <author> J. R. Allen and K. Kennedy, </author> <title> "PFC: A program to convert Fortran to parallel form," in Supercomputers: </title> <booktitle> Design and Applications, </booktitle> <pages> pp. 186-205, </pages> <address> Silver Spring, MD: </address> <publisher> IEEE Computer Society Press, </publisher> <year> 1984. </year>
Reference-contexts: Regular sections describe side effects to common substructures of arrays such as elements, rows, columns and diagonals [1, 2]. This paper describes an implementation of regular section analysis in the Rice Parallel Fortran Converter (PFC) <ref> [3] </ref>, an automatic parallelization system that also computes dependences for the ParaScope programming environment [4]. The overriding concern in the implementation is that it be efficient enough to be incorporated in a practical compilation system.
Reference: [4] <author> K. Kennedy, K. S. M c Kinley, and C. Tseng, </author> <title> "Interactive parallel programming using the ParaScope Editor," </title> <type> Tech. Rep. </type> <institution> TR90-137, Dept. of Computer Science, Rice University, </institution> <month> Oct. </month> <year> 1990. </year> <note> To appear in IEEE Transactions on Parallel and Distributed Systems. </note>
Reference-contexts: Regular sections describe side effects to common substructures of arrays such as elements, rows, columns and diagonals [1, 2]. This paper describes an implementation of regular section analysis in the Rice Parallel Fortran Converter (PFC) [3], an automatic parallelization system that also computes dependences for the ParaScope programming environment <ref> [4] </ref>. The overriding concern in the implementation is that it be efficient enough to be incorporated in a practical compilation system. Algorithm 1 summarizes the steps of the analysis, whiich is integrated with the three-phase interprocedural analysis and optimization structure of PFC [5, 6]. <p> The contrived example in Figure 1 shows the different patterns that they can represent precisely. Evaluating these methods involves examining the complexity and precision of: A fA [i; j] j j 2i; 9j 4i + 14; 3j 28 ig fA [1; 2]; A <ref> [4; 8] </ref>; A [10; 6]g Classical Summary Triolet Burke & Cytron Li & Yew Regular Sections Without Bounds With Bounds & Strides DAD/Simple Section fA [i; j] j 1 i 10; 2 j 8; 4 * representing the sets M A S 1 and U A * merging descriptors to summarize <p> We ran the programs through regular section analysis and dependence analysis in PFC, then examined the resulting dependence graphs by hand and in the ParaScope editor, an interactive dependence browser and program transformer <ref> [4] </ref>. LINPACK Analysis of Linpack provides a basis for comparison with other methods for analyzing interprocedural array side effects.
Reference: [5] <author> R. Allen, D. Callahan, and K. Kennedy, </author> <title> "An implementation of interprocedural analysis in a vectorizing Fortran compiler," </title> <type> Tech. Rep. </type> <institution> TR86-38, Dept. of Computer Science, Rice University, </institution> <month> May </month> <year> 1986. </year>
Reference-contexts: The overriding concern in the implementation is that it be efficient enough to be incorporated in a practical compilation system. Algorithm 1 summarizes the steps of the analysis, whiich is integrated with the three-phase interprocedural analysis and optimization structure of PFC <ref> [5, 6] </ref>. Regular section analysis added less than 8000 lines to PFC, a roughly 150,000-line PL/I program which runs under IBM VM/CMS. The remainder of the paper is organized as follows. Section 2 compares various methods for representing side effects to arrays. <p> Both the PFC and IR n /ParaScope systems perform summary and context analysis, as well as constant propagation, and therefore require at least two passes <ref> [30, 5, 6] </ref>. 14 a formal parameter, global, or static array. The symbolic analyzer provides value numbers for the subscripts on demand; the resulting vector is a regular section.
Reference: [6] <author> D. Callahan, K. Cooper, K. Kennedy, and L. Torczon, </author> <title> "Interprocedural constant propagation," </title> <booktitle> in Proceedings of the SIGPLAN '86 Symposium on Compiler Construction, </booktitle> <month> June </month> <year> 1986. </year>
Reference-contexts: The overriding concern in the implementation is that it be efficient enough to be incorporated in a practical compilation system. Algorithm 1 summarizes the steps of the analysis, whiich is integrated with the three-phase interprocedural analysis and optimization structure of PFC <ref> [5, 6] </ref>. Regular section analysis added less than 8000 lines to PFC, a roughly 150,000-line PL/I program which runs under IBM VM/CMS. The remainder of the paper is organized as follows. Section 2 compares various methods for representing side effects to arrays. <p> The contrived example in Figure 1 shows the different patterns that they can represent precisely. Evaluating these methods involves examining the complexity and precision of: A fA [i; j] j j 2i; 9j 4i + 14; 3j 28 ig fA [1; 2]; A [4; 8]; A <ref> [10; 6] </ref>g Classical Summary Triolet Burke & Cytron Li & Yew Regular Sections Without Bounds With Bounds & Strides DAD/Simple Section fA [i; j] j 1 i 10; 2 j 8; 4 * representing the sets M A S 1 and U A * merging descriptors to summarize multiple accesses (we <p> During the interprocedural phase, after producing the classical scalar side effect solution, but before propagating regular sections, we check to see if CLOBBER may change M. If so, we change S1's array side effect to A (?). A similar technique has proven successful for interprocedural constant propagation in PFC <ref> [31, 6] </ref>. Hazards must be recorded with each scalar expression saved for use in regular section analysis: scalar actual parameters and globals at call sites as well as array subscripts. <p> Both the PFC and IR n /ParaScope systems perform summary and context analysis, as well as constant propagation, and therefore require at least two passes <ref> [30, 5, 6] </ref>. 14 a formal parameter, global, or static array. The symbolic analyzer provides value numbers for the subscripts on demand; the resulting vector is a regular section.
Reference: [7] <author> F. Allen and J. Cocke, </author> <title> "A catalogue of optimizing transformations," in Design and Optimization of Compilers (J. </title> <editor> Rustin, ed.), </editor> <publisher> Prentice-Hall, </publisher> <year> 1972. </year>
Reference-contexts: Sections 7 and 8 suggest areas for future research and give our conclusions. 2 Interprocedural Array Side Effects A simple way to make dependence testing more precise around a call site is to perform inline expansion, replacing the called procedure with its body <ref> [7] </ref>. This precisely represents the effects of the procedure as a sequence of ordinary statements, which are readily understood by existing dependence analyzers.
Reference: [8] <author> K. Cooper, M. Hall, and L. Torczon, </author> <title> "An experiment with inline substitution," </title> <type> Tech. Rep. </type> <institution> TR90-128, Dept. of Computer Science, Rice University, </institution> <month> July </month> <year> 1990. </year> <note> To appear in Software| Practice and Experience. </note>
Reference-contexts: However, even if the whole program becomes no larger, the loop nest which contained the call may grow dramatically, causing a time and space explosion due to the non 3 linearity of array dependence analysis <ref> [8] </ref>. To gain some of the benefits of inline expansion without its drawbacks, we must find another representation for the effects of the called procedure. For dependence analysis, we are interested in the memory locations modified or used by a procedure. <p> The contrived example in Figure 1 shows the different patterns that they can represent precisely. Evaluating these methods involves examining the complexity and precision of: A fA [i; j] j j 2i; 9j 4i + 14; 3j 28 ig fA [1; 2]; A <ref> [4; 8] </ref>; A [10; 6]g Classical Summary Triolet Burke & Cytron Li & Yew Regular Sections Without Bounds With Bounds & Strides DAD/Simple Section fA [i; j] j 1 i 10; 2 j 8; 4 * representing the sets M A S 1 and U A * merging descriptors to summarize <p> Porterfield modeled cache performance using an adapted version of PFC [34]. Goff, Kennedy and Tseng studied the performance of dependence tests on Riceps and other benchmarks [35]. Some Riceps and Riceps candidate codes have also been examined in a study on the utility of inline expansion of procedure calls <ref> [8] </ref>. The six programs studied here are two Riceps codes linpackd and track) and four codes from the inlining study. Perfect Club Benchmarks This suite was originally collected for benchmarking the performance of supercomputers on complete applications. <p> More symbolic analysis would improve the practicality of the entire method. Overall, the additional analysis time is comparable to that required to analyze programs after heuristically-determined inline expansion in Cooper, Hall and Torczon's study <ref> [8] </ref>. We have not seen published execution times for the array side effect analyses implemented in Parafrase by Triolet and by Li and Yew, except that Li and Yew state that their method runs 2.6 times faster than Triolet's [21]. <p> to produce this precise result requires that it have an understanding of the control conditions under which expressions are computed. 7 In the inlining study at Rice, none of the commercial compilers was able to detect the parallel call in dogleg even after inlining, presumably due to complicated control flow <ref> [8] </ref>. 23 7.2 Killed Regular Sections We have already found programs (scalgam and euler) in which the ability to recognize and localize temporary arrays would cut the number of dependences dramatically, allowing some calls to be parallelized.
Reference: [9] <author> P. Cousot and R. Cousot, </author> <title> "Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints," </title> <booktitle> in Conference Record of the Fourth ACM Symposium on the Principles of Programming Languages, </booktitle> <address> (Los Angeles), </address> <pages> pp. 238-252, </pages> <month> Jan. </month> <year> 1977. </year>
Reference-contexts: Handling of recursion turns out not to be an issue. Iterative techniques can guarantee convergence to a fixed point solution using Cousot's technique of widening operators <ref> [9, 10] </ref>. Li and Yew proposed a preparatory analysis of recursive programs that guarantees termination in three iterations [11, 12]. Either of these methods may be adapted for regular sections. 2.1 True Summaries True summary methods use descriptors whose size is largely independent of the number of references being summarized.
Reference: [10] <author> P. Cousot, </author> <title> "Semantic foundations of program analysis," in Program Flow Analysis: Theory and Applications (S. </title> <editor> S. Muchnick and M. D. Jones, </editor> <booktitle> eds.), </booktitle> <pages> pp. 303-342, </pages> <address> Prentice-Hall,New Jersey, </address> <year> 1981. </year>
Reference-contexts: The contrived example in Figure 1 shows the different patterns that they can represent precisely. Evaluating these methods involves examining the complexity and precision of: A fA [i; j] j j 2i; 9j 4i + 14; 3j 28 ig fA [1; 2]; A [4; 8]; A <ref> [10; 6] </ref>g Classical Summary Triolet Burke & Cytron Li & Yew Regular Sections Without Bounds With Bounds & Strides DAD/Simple Section fA [i; j] j 1 i 10; 2 j 8; 4 * representing the sets M A S 1 and U A * merging descriptors to summarize multiple accesses (we <p> Handling of recursion turns out not to be an issue. Iterative techniques can guarantee convergence to a fixed point solution using Cousot's technique of widening operators <ref> [9, 10] </ref>. Li and Yew proposed a preparatory analysis of recursive programs that guarantees termination in three iterations [11, 12]. Either of these methods may be adapted for regular sections. 2.1 True Summaries True summary methods use descriptors whose size is largely independent of the number of references being summarized.
Reference: [11] <author> Z. Li and P.-C. Yew, </author> <title> "Interprocedural analysis and program restructuring for parallel programs," </title> <journal> CSRD Rpt. </journal> <volume> No. </volume> <pages> 720, </pages> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> Jan. </month> <year> 1988. </year>
Reference-contexts: Handling of recursion turns out not to be an issue. Iterative techniques can guarantee convergence to a fixed point solution using Cousot's technique of widening operators [9, 10]. Li and Yew proposed a preparatory analysis of recursive programs that guarantees termination in three iterations <ref> [11, 12] </ref>. Either of these methods may be adapted for regular sections. 2.1 True Summaries True summary methods use descriptors whose size is largely independent of the number of references being summarized. <p> Linearization in its pure form is ill-suited to summarization, but might be a useful extension to a true summary technique because of its ability to handle arbitrary reshapes. Atom Images Li and Yew extended Parafrase to compute sets of atom images describing the side effects of procedures <ref> [21, 11] </ref>. Like the original version of regular sections described in Callahan's thesis [2], these record subscript expressions that are linear in loop induction variables along with bounds on the induction variables. <p> However, the proposed Fortran 90 standard allows 16 recursion [25], and we plan an extension or re-implementation that will handle it. Unfortunately, a straightforward iterative approach to the propagation of regular sections will not terminate, since the lattice has unbounded depth. Li and Yew <ref> [11] </ref> and Cooper and Kennedy [16] describe approaches for propagating subarrays that are efficient regardless of the depth of the lattice. However, it may be more convenient to implement a simple iterative technique while simulating a bounded-depth lattice.
Reference: [12] <author> Z. Li and P.-C. Yew, </author> <title> "Program parallelization with interprocedural analysis," </title> <journal> The Journal of Supercomputing, </journal> <volume> vol. 2, </volume> <pages> pp. 225-244, </pages> <year> 1988. </year>
Reference-contexts: Handling of recursion turns out not to be an issue. Iterative techniques can guarantee convergence to a fixed point solution using Cousot's technique of widening operators [9, 10]. Li and Yew proposed a preparatory analysis of recursive programs that guarantees termination in three iterations <ref> [11, 12] </ref>. Either of these methods may be adapted for regular sections. 2.1 True Summaries True summary methods use descriptors whose size is largely independent of the number of references being summarized. <p> However, they lose too much precision by omitting bounds information. While we originally thought that these limitations were necessary for efficient handling of recursive programs, Li and Yew have adapted iterative techniques to work with more general descriptors <ref> [12] </ref>. Bounded Regular Sections Anticipating that restricted regular sections would not be precise enough for effective parallelization, Callahan and Kennedy proposed an implementation of regular sections with bounds. That project is the subject of this paper. The regular sections implemented include bounds and stride information, but omit diagonal constraints.
Reference: [13] <author> J. Banning, </author> <title> A Method for Determining the Side Effects of Procedure Calls. </title> <type> PhD thesis, </type> <institution> Stan-ford University, </institution> <month> Aug. </month> <year> 1978. </year> <month> 25 </month>
Reference-contexts: Classical Methods The classical methods of interprocedural summary dataflow analysis compute mod and use sets indicating which parameters and global variables may be modified or used in the procedure <ref> [13, 14, 15] </ref>. Such summary information costs only two bits per variable. Meet and intersection may be implemented using single-bit or bit-vector logical operations.
Reference: [14] <author> J. Barth, </author> <title> "An interprocedural data flow analysis algorithm," </title> <booktitle> in Conference Record of the Fourth ACM Symposium on the Principles of Programming Languages, </booktitle> <address> (Los Angeles), </address> <month> Jan. </month> <year> 1977. </year>
Reference-contexts: Classical Methods The classical methods of interprocedural summary dataflow analysis compute mod and use sets indicating which parameters and global variables may be modified or used in the procedure <ref> [13, 14, 15] </ref>. Such summary information costs only two bits per variable. Meet and intersection may be implemented using single-bit or bit-vector logical operations.
Reference: [15] <author> K. Cooper and K. Kennedy, </author> <title> "Efficient computation of flow insensitive interprocedural summary information," </title> <booktitle> in Proceedings of the SIGPLAN '84 Symposium on Compiler Construction, SIGPLAN Notices Vol. </booktitle> <volume> 19, No. 6, </volume> <month> July </month> <year> 1985. </year>
Reference-contexts: Classical Methods The classical methods of interprocedural summary dataflow analysis compute mod and use sets indicating which parameters and global variables may be modified or used in the procedure <ref> [13, 14, 15] </ref>. Such summary information costs only two bits per variable. Meet and intersection may be implemented using single-bit or bit-vector logical operations.
Reference: [16] <author> K. Cooper and K. Kennedy, </author> <title> "Interprocedural side-effect analysis in linear time," </title> <booktitle> in Proceedings of the ACM SIGPLAN 88 Conference on Program Language Design and Implementation, </booktitle> <address> (Atlanta, GA), </address> <month> June </month> <year> 1988. </year>
Reference-contexts: Meet and intersection may be implemented using single-bit or bit-vector logical operations. Also, there exist algorithms that compute complete solutions, in which the number of meets is linear in the number of procedures and call sites in the program, even when recursion is permitted <ref> [16] </ref>. Unfortunately, our experiences with PFC and Ptool indicate that this summary information is too coarse for dependence testing and the effective detection of parallelism [1]. The problem is that the only access sets representable in this method are "the whole array" and "none of the array" (see Figure 1). <p> However, the proposed Fortran 90 standard allows 16 recursion [25], and we plan an extension or re-implementation that will handle it. Unfortunately, a straightforward iterative approach to the propagation of regular sections will not terminate, since the lattice has unbounded depth. Li and Yew [11] and Cooper and Kennedy <ref> [16] </ref> describe approaches for propagating subarrays that are efficient regardless of the depth of the lattice. However, it may be more convenient to implement a simple iterative technique while simulating a bounded-depth lattice.
Reference: [17] <author> R. Triolet, F. Irigoin, and P. Feautrier, </author> <title> "Direct parallelization of CALL statements," </title> <booktitle> in Proceedings of the SIGPLAN '86 Symposium on Compiler Construction, </booktitle> <address> (Palo Alto, CA), </address> <pages> pp. 176-185, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: information limits the detection of data decomposition, an important source of parallelism, in which different iterations of a loop work on distinct subsections of a given array. 5 Triolet Regions Triolet, Irigoin and Feautrier proposed to calculate linear inequalities bounding the set of array locations affected by a procedure call <ref> [17, 18] </ref>. This representation and its intersection operation are precise for convex regions. Other patterns, such as array accesses with non-unit stride and non-convex results of meet operations, are given convex approximations.
Reference: [18] <author> R. Triolet, </author> <title> "Interprocedural analysis for program restructuring with Parafrase," </title> <journal> CSRD Rpt. </journal> <volume> No. </volume> <pages> 538, </pages> <institution> Dept. of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> Dec. </month> <year> 1985. </year>
Reference-contexts: information limits the detection of data decomposition, an important source of parallelism, in which different iterations of a loop work on distinct subsections of a given array. 5 Triolet Regions Triolet, Irigoin and Feautrier proposed to calculate linear inequalities bounding the set of array locations affected by a procedure call <ref> [17, 18] </ref>. This representation and its intersection operation are precise for convex regions. Other patterns, such as array accesses with non-unit stride and non-convex results of meet operations, are given convex approximations. <p> LINPACK Analysis of Linpack provides a basis for comparison with other methods for analyzing interprocedural array side effects. Both Li and Yew [21] and Triolet <ref> [18] </ref> found several parallel calls in Linpack using their implementations in the University of Illinois translator, Parafrase. 17 Linpack proves that useful numerical codes can be written in the modular programming style for which parallel calls can be detected.
Reference: [19] <author> U. Banerjee, </author> <title> "A direct parallelization of CALL statements a review," CSRD Rpt. </title> <type> 576, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> Apr. </month> <year> 1986. </year>
Reference-contexts: Other patterns, such as array accesses with non-unit stride and non-convex results of meet operations, are given convex approximations. Operations on these regions are expensive; the meet operation requires finding the convex hull of the combined set of inequalities and intersection uses a potentially exponential linear inequality solver <ref> [19] </ref>. A succession of meet operations can also produce complicated regions with potentially as many inequalities as the number of primitive accesses merged together.
Reference: [20] <author> M. Burke and R. Cytron, </author> <title> "Interprocedural dependence analysis and parallelization," </title> <booktitle> in Proceedings of the SIGPLAN '86 Symposium on Compiler Construction, </booktitle> <pages> pp. 162-175, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: Reference list methods are simple and precise, but are asymptotically as expensive as in-line expansion. Linearization Burke and Cytron proposed representing each multidimensional array reference by linearizing its subscript expressions to a one-dimensional address expression. Their method also retains bounds information for loop induction variables occurring in the expressions <ref> [20] </ref>. They describe two ways of implementing the meet operation. One involves merely keeping a list of the individual address expressions. The other constructs a composite expression that can be polynomial in the loop induction variables. The disadvantages of the first method are described above. <p> The easiest translation method would be to linearize the subscripts for the referenced section of a formal parameter, adding the offset of the passed location of the actual parameter <ref> [20] </ref>. The resulting section would give referenced locations of the actual as if it were a one-dimensional array. However, if some subscripts of the original section are ranges or non-linear expressions, linearization contaminates the other subscripts, greatly reducing the precision of dependence analysis.
Reference: [21] <author> Z. Li and P.-C. Yew, </author> <title> "Efficient interprocedural analysis for program parallelization and restructuring," </title> <booktitle> in ACM SIGPLAN PPEALS, </booktitle> <pages> pp. 85-99, </pages> <year> 1988. </year>
Reference-contexts: Linearization in its pure form is ill-suited to summarization, but might be a useful extension to a true summary technique because of its ability to handle arbitrary reshapes. Atom Images Li and Yew extended Parafrase to compute sets of atom images describing the side effects of procedures <ref> [21, 11] </ref>. Like the original version of regular sections described in Callahan's thesis [2], these record subscript expressions that are linear in loop induction variables along with bounds on the induction variables. <p> LINPACK Analysis of Linpack provides a basis for comparison with other methods for analyzing interprocedural array side effects. Both Li and Yew <ref> [21] </ref> and Triolet [18] found several parallel calls in Linpack using their implementations in the University of Illinois translator, Parafrase. 17 Linpack proves that useful numerical codes can be written in the modular programming style for which parallel calls can be detected. <p> We have not seen published execution times for the array side effect analyses implemented in Parafrase by Triolet and by Li and Yew, except that Li and Yew state that their method runs 2.6 times faster than Triolet's <ref> [21] </ref>. <p> Preliminary results for eight of the 13 Perfect benchmarks indicate a reduction of 0.6 percent in the total size of the dependence graphs. 6 Parallelized Calls Table 3 examines the number of calls in Linpack which were parallelized after summary interprocedural analysis alone ("IP"), after Li and Yew's analysis <ref> [21] </ref>, and after regular section analysis ("RS"). (Triolet's results from Parafrase resembled Li and Yew's.) Most (17) of these call sites were parallelized in ParaScope, based on PFC's dependence graph, with no transformations being necessary.
Reference: [22] <author> V. Balasundaram, </author> <title> Interactive Parallelization of Numerical Scientific Programs. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> July </month> <year> 1989. </year> <note> Available as Rice COMP TR89-95. </note>
Reference-contexts: Operations on descriptors should be linear or, at worst, quadratic in the rank of the array. Researchers at Rice have defined several variants of regular sections to represent common access patterns while satisfying these constraints <ref> [2, 1, 22, 23] </ref>. Original Regular Sections Callahan's thesis proposed two regular section frameworks. The first, resembling Li and Yew's atom images, he dismissed due to the difficulty of devising efficient standardization and meet operations [2]. Restricted Regular Sections. <p> Intersection is implemented using standard dependence tests, which also take time proportional to the number of subscripts. 1 Data Access Descriptors Concurrently with our implementation, Balasundaram and Kennedy developed Data Access Descriptors (DADs) as a general technique for describing data access <ref> [22, 23, 24] </ref>. DADs represent information about both the shapes of array accesses and their traversal order; for our comparison we are interested only in the shapes.
Reference: [23] <author> V. Balasundaram and K. Kennedy, </author> <title> "A technique for summarizing data access and its use in parallelism enhancing transformations," </title> <booktitle> in Proceedings of the ACM SIGPLAN '89 Conference on Program Language Design and Implementation, </booktitle> <address> (Portland, OR), </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Operations on descriptors should be linear or, at worst, quadratic in the rank of the array. Researchers at Rice have defined several variants of regular sections to represent common access patterns while satisfying these constraints <ref> [2, 1, 22, 23] </ref>. Original Regular Sections Callahan's thesis proposed two regular section frameworks. The first, resembling Li and Yew's atom images, he dismissed due to the difficulty of devising efficient standardization and meet operations [2]. Restricted Regular Sections. <p> Intersection is implemented using standard dependence tests, which also take time proportional to the number of subscripts. 1 Data Access Descriptors Concurrently with our implementation, Balasundaram and Kennedy developed Data Access Descriptors (DADs) as a general technique for describing data access <ref> [22, 23, 24] </ref>. DADs represent information about both the shapes of array accesses and their traversal order; for our comparison we are interested only in the shapes.
Reference: [24] <author> V. Balasundaram, </author> <title> "A mechanism for keeping useful internal information in parallel programming tools: the Data Access Descriptor," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 9, </volume> <pages> pp. 154-170, </pages> <year> 1990. </year>
Reference-contexts: Intersection is implemented using standard dependence tests, which also take time proportional to the number of subscripts. 1 Data Access Descriptors Concurrently with our implementation, Balasundaram and Kennedy developed Data Access Descriptors (DADs) as a general technique for describing data access <ref> [22, 23, 24] </ref>. DADs represent information about both the shapes of array accesses and their traversal order; for our comparison we are interested only in the shapes.
Reference: [25] <author> X3J3 Subcommittee of ANSI, </author> <title> American National Standard for Information Systems Programming Language Fortran: </title> <address> S8 (X3.9-198x). New York, NY: </address> <institution> American National Standards Institute, </institution> <year> 1989. </year>
Reference-contexts: Our implementation can be extended to compute DADs if the additional precision proves useful. 3 Bounded Sections and Ranges Bounded regular sections comprise the same set of rectangular subarrays that can be written using triplet notation in the proposed Fortran 90 standard <ref> [25] </ref>. <p> The final summary regular sections are built in order, so that incomplete regular sections need never be translated into a call site. However, the proposed Fortran 90 standard allows 16 recursion <ref> [25] </ref>, and we plan an extension or re-implementation that will handle it. Unfortunately, a straightforward iterative approach to the propagation of regular sections will not terminate, since the lattice has unbounded depth.
Reference: [26] <author> M. Karr, </author> <title> "Affine relationships among variables of a program," </title> <journal> Acta Informatica, </journal> <volume> vol. 6, </volume> <pages> pp. 133-151, </pages> <year> 1976. </year>
Reference-contexts: While there are many published algorithms for performing symbolic analysis and global value numbering <ref> [26, 27, 28] </ref>, their preliminary transformations and complexity make them difficult to integrate into PFC. Our implementation builds global value numbers with the help of PFC's existing dataflow analysis machinery. Leaf value numbers are constants and the global and parameter values available on procedure entry.
Reference: [27] <author> J. H. Reif and R. E. Tarjan, </author> <title> "Symbolic program analysis in almost-linear time," </title> <journal> SIAM Journal on Computing, </journal> <volume> vol. 11, </volume> <pages> pp. 81-93, </pages> <month> Feb. </month> <year> 1981. </year>
Reference-contexts: While there are many published algorithms for performing symbolic analysis and global value numbering <ref> [26, 27, 28] </ref>, their preliminary transformations and complexity make them difficult to integrate into PFC. Our implementation builds global value numbers with the help of PFC's existing dataflow analysis machinery. Leaf value numbers are constants and the global and parameter values available on procedure entry.
Reference: [28] <author> B. K. Rosen, M. N. Wegman, and F. K. Zadeck, </author> <title> "Global value numbers and redundant computations," </title> <booktitle> in Conference Record of the Fifteenth ACM Symposium on the Principles of Programming Languages, </booktitle> <address> (San Diego, CA), </address> <pages> pp. 12-27, </pages> <month> Jan. </month> <year> 1988. </year>
Reference-contexts: While there are many published algorithms for performing symbolic analysis and global value numbering <ref> [26, 27, 28] </ref>, their preliminary transformations and complexity make them difficult to integrate into PFC. Our implementation builds global value numbers with the help of PFC's existing dataflow analysis machinery. Leaf value numbers are constants and the global and parameter values available on procedure entry.
Reference: [29] <author> W. H. Harrison, </author> <title> "Compiler analysis of the value ranges for variables," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-3, </volume> <pages> pp. 243-250, </pages> <month> May </month> <year> 1977. </year>
Reference: [30] <author> K. Cooper, K. Kennedy, and L. Torczon, </author> <title> "The impact of interprocedural analysis and optimization in the IR n programming environment," </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> vol. 8, </volume> <pages> pp. 491-523, </pages> <month> Oct. </month> <year> 1986. </year>
Reference-contexts: Both the PFC and IR n /ParaScope systems perform summary and context analysis, as well as constant propagation, and therefore require at least two passes <ref> [30, 5, 6] </ref>. 14 a formal parameter, global, or static array. The symbolic analyzer provides value numbers for the subscripts on demand; the resulting vector is a regular section.
Reference: [31] <author> L. Torczon, </author> <title> Compilation Dependences in an Ambitious Optimizing Compiler. </title> <type> PhD thesis, </type> <institution> 26 Dept. of Computer Science, Rice University, </institution> <month> May </month> <year> 1985. </year>
Reference-contexts: During the interprocedural phase, after producing the classical scalar side effect solution, but before propagating regular sections, we check to see if CLOBBER may change M. If so, we change S1's array side effect to A (?). A similar technique has proven successful for interprocedural constant propagation in PFC <ref> [31, 6] </ref>. Hazards must be recorded with each scalar expression saved for use in regular section analysis: scalar actual parameters and globals at call sites as well as array subscripts.
Reference: [32] <author> J. J. Dongarra, J. R. Bunch, C. B. Moler, and G. W. Stewart, </author> <title> LINPACK User's Guide. </title> <address> Philadelphia: </address> <publisher> SIAM Publications, </publisher> <year> 1979. </year>
Reference-contexts: Our current candidates for "real programs" are the Linpack library of linear algebra subroutines <ref> [32] </ref>, the Rice Compiler Evaluation Program Suite, and the Perfect Club benchmarks [33]. We ran the programs through regular section analysis and dependence analysis in PFC, then examined the resulting dependence graphs by hand and in the ParaScope editor, an interactive dependence browser and program transformer [4].
Reference: [33] <author> G. Cybenko, L. Kipp, L. Pointer, and D. Kuck, </author> <title> "Supercomputer performance evaluation and the Perfect benchmarks," </title> <booktitle> in Proceedings of the 1990 ACM International Conference on Supercomputing, </booktitle> <address> (Amsterdam, The Netherlands), </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Our current candidates for "real programs" are the Linpack library of linear algebra subroutines [32], the Rice Compiler Evaluation Program Suite, and the Perfect Club benchmarks <ref> [33] </ref>. We ran the programs through regular section analysis and dependence analysis in PFC, then examined the resulting dependence graphs by hand and in the ParaScope editor, an interactive dependence browser and program transformer [4].
Reference: [34] <author> A. Porterfield, </author> <title> Software Methods for Improvement of Cache Performance on Supercomputer Applications. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> May </month> <year> 1989. </year> <note> Available as Rice COMP TR88-93. </note>
Reference-contexts: RiCEPS The Rice Compiler Evaluation Program Suite is a collection of 10 complete applications codes from a broad range of scientific disciplines. Our colleagues at Rice have already run several experiments on Riceps. Porterfield modeled cache performance using an adapted version of PFC <ref> [34] </ref>. Goff, Kennedy and Tseng studied the performance of dependence tests on Riceps and other benchmarks [35]. Some Riceps and Riceps candidate codes have also been examined in a study on the utility of inline expansion of procedure calls [8].
Reference: [35] <author> G. Goff, K. Kennedy, and C. Tseng, </author> <title> "Practical dependence testing," </title> <type> Tech. Rep. </type> <institution> TR90-142, Dept. of Computer Science, Rice University, </institution> <month> Nov. </month> <year> 1990. </year> <booktitle> To appear in the ACM SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Our colleagues at Rice have already run several experiments on Riceps. Porterfield modeled cache performance using an adapted version of PFC [34]. Goff, Kennedy and Tseng studied the performance of dependence tests on Riceps and other benchmarks <ref> [35] </ref>. Some Riceps and Riceps candidate codes have also been examined in a study on the utility of inline expansion of procedure calls [8]. The six programs studied here are two Riceps codes linpackd and track) and four codes from the inlining study.
Reference: [36] <author> Z. Li, </author> <title> "Private communication," </title> <address> Oct. </address> <year> 1990. </year>
Reference-contexts: Starred entries (?) indicate parallel calls which were precisely summarized by regular section analysis, but which were not detected as parallel due to a deficiency in PFC's symbolic dependence test for triangular loops. One call in QRDC was mistakenly parallelized by Parafrase <ref> [36] </ref>. These results indicate, at least for Linpack, that there is no benefit to the generality of Triolet's and Li and Yew's methods. Regular section analysis obtains exactly the same precision, with a different number of loops parallelized only because of differences in dependence analysis and transformations.
Reference: [37] <author> C. M. Rosene, </author> <title> Incremental Dependence Analysis. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> March </month> <year> 1990. </year> <note> Available as Rice COMP TR90-112. </note>
Reference-contexts: In addition, this approach requires an intraprocedural dependence analysis capable of using array kill information, such as those described by Rosene <ref> [37] </ref> and by Gross and Steenkiste [38]. 8 Conclusion Regular section analysis can be a practical addition to a production compiler. Its local analysis and interprocedural propagation can be integrated with those for other interprocedural techniques.
Reference: [38] <author> T. Gross and P. Steenkiste, </author> <title> "Structured dataflow analysis for arrays and its use in an optimizing compiler," </title> <journal> Software|Practice and Experience, </journal> <volume> vol. 20, </volume> <pages> pp. 133-155, </pages> <month> Feb. </month> <year> 1990. </year> <month> 27 </month>
Reference-contexts: In addition, this approach requires an intraprocedural dependence analysis capable of using array kill information, such as those described by Rosene [37] and by Gross and Steenkiste <ref> [38] </ref>. 8 Conclusion Regular section analysis can be a practical addition to a production compiler. Its local analysis and interprocedural propagation can be integrated with those for other interprocedural techniques. The required changes to dependence analysis are trivial|the same ones needed to support Fortran 90 sections.
References-found: 38

