URL: ftp://ftp.it.kth.se/Reports/TELEINFORMATICS/TRITA-IT-9419.ps.gz
Refering-URL: http://www.csd.uu.se/~bjornfot/r1.html
Root-URL: 
Title: Department of Teleinformatics Towards Parallel VHDL Simulation  
Author: Sven Skld and Rassul Ayani 
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Altmae, M., </author> <title> MINT - a VHDL simulation system, </title> <booktitle> EDAC, Proc. of the European Design Automation Conference, </booktitle> <address> Glasgow, March 12-15, </address> <year> 1990, </year> <pages> pp. 102-106. </pages>
Reference-contexts: The available VHDL simulation tools are mostly sequential, e.g. <ref> [1] </ref> and [17], and the existing software solutions that optimize the simulation algorithms on fast workstations are not sufficient for the needs of the industry [9].
Reference: [2] <author> Ashenden, P. J., Detmold, H., McKeen, </author> <title> W.S., Parallel Execution of VHDL Models, </title> <type> Tech, Rep. No. 93-01, </type> <institution> Dept. of CS, University of Adelaide, Australia. </institution>
Reference-contexts: When all processes have suspended, simulation time is advanced to the time of the next scheduled transaction and the cycle is repeated. The simulation cycle is pictured in FIGURE 2 [18]. It is also possible to view the simulation cycle as a sequential iteration consisting of four steps <ref> [2] </ref> where the first two steps are the first stage and the two last steps are the second stage in the two-stage simulation cycle: 1. Advance simulation time to the earliest scheduled transaction. 2. Update signals with transaction values scheduled for the current simulation time. <p> Is for example a massively parallel SIMD computer with thousands of processors or a MIMD machine with less than 10 processors the best alternative? 20 Ashenden et.al <ref> [2] </ref> note that this is highly dependent on the characteristics of the model to be simulated. <p> Timestamp information can therefore be seen as a cross-product of the simulation time and the cycle number. This approach solves the previous sequencing problems. Ashenden et.al. <ref> [2] </ref> come to the same conclusion, i.e. to treat simulation time as a pair: the time value in femto seconds and a count of delta cycles at the particular time step. This leads to no problem for a sequential simulator nor for a centralized-time PDES. <p> The distributed approach with local clocks and time-stamps in transaction messages must however include both the time value and the delta delay cycle count in the messages. All time comparisons in the algorithms must accordingly be made using both time elements. 4.3.2 Transport and inertial delay Ashenden et. al. <ref> [2] </ref> also note that the VHDL semantics for transport and inertial delay impose further changes to the PDES algorithms. <p> A proper mechanism to deal with this needs to be employed. The conservative distributed algorithm is easily modified to cope with this problem by making sure that a process is resumed only when no more transactions with the same time stamp will arrive later <ref> [2] </ref>. The optimistic approach requires even less modification. <p> In the conservative case, a postponed process may not respond to a transaction unless there is a guarantee that no more transactions with the same time stamp will arrive. Ashenden et. al. <ref> [2] </ref> suggest a solution to this problem by making sure that all input signals have passed the current time-step before resuming the postponed process. The process might schedule transactions on output signals but they must have non-zero-delay to cope with the VHDL-93 semantics. <p> One solution to this is to encapsulate shared variables in a monitor process which makes sure that the processes accesses the shared variables in correct order <ref> [2] </ref>. 25 5 Future Research During the last couple of years the interest for parallel VHDL simulation throughout the simulation and computer aided design communities have significantly increased. Recently (May, 1994) a worldwide parallel VHDL simulation study group was formed by the Design Automation Standards Committee (DASC).
Reference: [3] <author> Ashenden, P. J., </author> <title> The VHDL-Cookbook, </title> <institution> The University of Adelaide, South Australia, </institution> <year> 1990. </year>
Reference: [4] <author> Ayani, R. and. Rajaei, H. </author> <year> 1992, </year> <title> Parallel Simulation Using Conservative Time Windows, </title> <booktitle> Proceedings of the 1992 Winter Simulation Conference, </booktitle> <pages> pp. 709-717. </pages>
Reference-contexts: Safe events are said to be kept within a time window. Due to the synchronization method, these algorithms are best suited for shared memory multiprocessors. One example of such simulation schemes is Conservative Time Windows (CTW) <ref> [4] </ref>. initialization: C i := 0 Fill EL i with known future events. repeat if there is at least one message on each incoming link do: 1. Find the message, or event, with smallest timestamp t j . 2. C i := t j 3. Process current event.
Reference: [5] <author> Berge, J-M., Fonkoua A., Maginot, S., Rouillard, J., VHDL-92, </author> <title> The New Features of the VHDL Hardware Description Language, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference: [6] <author> Blank, T., </author> <title> A survey of hardware accelerators used in computer-aided design, </title> <journal> IEEE Transactions on Design and Test, </journal> <month> Aug. </month> <year> 1984, </year> <pages> pp. 21-39. </pages>
Reference-contexts: However, the potential speedup will always be limited by the latest technology improvements. Special-purpose hardware accelerators An approach that gives excellent VHDL simulation performance is letting special-purpose hardware accelerators <ref> [6] </ref> take care of the simulation. The disadvantage with this technique is that they are optimized for specific hardware models. If there is a need to simulate various types of hardware designs, this approach would be very expensive. Hence, this leads to an unpleasant trade-off between utilization, price and performance.
Reference: [7] <author> Chawla, P., Carter, H. W., </author> <title> An investigation of the performance of a distributed functional digital simulator, </title> <journal> ACM SIGDA Newsletter, vol.19, no.2, </journal> <month> Sept. </month> <year> 1989, </year> <pages> pp. 33-34. </pages>
Reference: [8] <author> Chawla, P., Wilsey, P., </author> <title> Synchronizing distributed VHDL simulation, </title> <type> Tech. Rep. TR 131-4-01, </type> <institution> Dept. of Electrical & Computer Engineering, University of Cincinnati, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: Hence, there is a definite need for faster VHDL simulation to keep VHDL as an important tool in future hardware design. 4.1 Why parallel VHDL simulation? When trying to live up to the demand from the industry, Chawla et.al. <ref> [8] </ref> discuss five different approaches to speed up VHDL simulation, all more or less suitable also for speeding up simulation in other areas: 1. Introducing faster circuit technology 2. Using special-purpose hardware accelerators 3. Developing faster uniprocessor algorithms 4. Using vector machines 5. <p> When developing a parallel or distributed VHDL simulator, the programming as well as the host-architecture model are different from the sequential simulator. This introduces some programming difficulties, e.g. synchronization and communication issues, that need to be addressed when developing new parallel algorithms. Together with Chawla et.al. <ref> [8] </ref>, we acknowledge the technique of using general-purpose multiprocessor systems to be the most promising approach to speed up VHDL simulation, i.e. to develop parallel VHDL simulators. <p> The performance of a simulation on a multiprocessor system highly depends on four different issues: program partitioning, process scheduling, inter-process communication and process synchronization <ref> [8] </ref>. 19 4.2.1 Partitioning The partitioning of a simulation program into processes that will effectively run on separate processors is a crucial part of a parallel VHDL implementation. <p> This might cause erroneous behavior, e.g. in the case of rollback. The Time Warp algorithm must therefore be modified to guarantee the sequencing information built into Lamports clock conditions. The suggested solution by Chawla et. al. <ref> [8] </ref> to the issue of Time Warp and delta delays, is to not only send the simulation time with each message but also include the counting of simulation cycles. Timestamp information can therefore be seen as a cross-product of the simulation time and the cycle number.
Reference: [9] <author> Costa A., De Gloria A., Faraboschi P., and Olivieri, M., </author> <title> An Evaluation System for Distributed-Time VHDL Simulation, </title> <institution> University of Genoa, DIBE, </institution> <note> To be presented at PADS 94. </note>
Reference-contexts: The available VHDL simulation tools are mostly sequential, e.g. [1] and [17], and the existing software solutions that optimize the simulation algorithms on fast workstations are not sufficient for the needs of the industry <ref> [9] </ref>. <p> With rather low-level abstraction experimental VHDL models the model functions could be restructured into fine-grained processes, increasing the available parallelism compared to previous studies [28]. As part of the CHESS project [20], Costa et. al. <ref> [9] </ref> built a Trace Driven Parallelism Analyzer (TDPA) to evaluate parallel VHDL performance. Their system makes it possible to investigate the joint effects of different architectural configurations, connection topologies, and different simulation algorithms. <p> Different network topologies are to be considered, as well as if memory should be shared or distributed on the processor nodes. Costa et. al. <ref> [9] </ref>, observed from their trace evaluations that the network topology alone is not the critical factor. What is more important is the actual communication latency between the processors. This further implies the importance of effective process scheduling described in the previous section. <p> Experiments with the TDPA system, see Section 4.2.1 and <ref> [9] </ref>, show that there is a valuable amount of concurrency in VHDL-models using distributed-time simulation algorithms. These results show that the speedup for VHDL simulation using centralized-time algorithms is bounded by a factor 2, while speedup for distributed-time algorithms is bounded by a factor 10. <p> However, choosing optimal parameters for some of the approaches has not yet been fully investigated. An important factor for an efficient Time Warp simulator is that the number of rollbacks as well as the individual rollback lengths are kept low. In the trace simulations performed by Costa et.al. <ref> [9] </ref>, they noted that rollback in optimistic algorithms does not have to be a limiting factor for a distributed VHDL simulation. This is as long as the rollback cost is not too high, e.g. approximately the cost of executing 100 VHDL statements.
Reference: [10] <author> Fujimoto, R. M. </author> <year> 1990, </year> <title> Parallel Discrete Event Simulation, </title> <journal> Comm. of the ACM, </journal> <volume> Vol. 33, No. 10, </volume> <month> (October), </month> <pages> pp. 30-53. </pages>
Reference-contexts: In the following sub-sections the basic ideas behind these approaches to PDES are described. A thorough survey of the area is made by Fujimoto <ref> [10] </ref>. 3.2.2 Conservative PDES Some of the first PDES algorithms were proposed by the end of the 1970s by Chandy and Misra [19][10]. Their algorithm is based on viewing a physical system as a set of physical processes interacting with each other. <p> Process current event. This might lead to changes in the system state, new events inserted in EL i and new messages to be sent. else BLOCK LP i until end of simulation FIGURE 5 The Chandy-Misra PDES algorithm 13 Performance of conservative approach In <ref> [10] </ref> Fujimoto discusses some factors for conservative simulation strategies to be successful. One of the more important issues is lookahead, i.e. the ability to predict if future events will happen, or more necessary, will not happen. For conservative simulation to be effective, it must be possible to exploit lookahead. <p> If the reexecuted process state is identical to the original state, rollback is not needed. Other approaches are to limit the optimism in Time Warp by not allowing a process to run too far ahead of the others, e.g. bounded time widows or moving time windows <ref> [10] </ref>. The problem with memory overhead is mainly associated with large state vectors. One way of reducing the needed memory is to neglect to save the state after executing each event, but 15 instead only save every Nth event, e.g. periodic state-saving or periodic checkpointing [23]. <p> The period N can be difficult to estimate analytically. A better way might be to introduce an adaptive checkpointing algorithm [25]. Performance of optimistic approach Many researchers have reported successful results from various applications using optimistic simulation methods. Among others, Fujimoto <ref> [10] </ref> claims that Time Warp is capable of transparently exploiting all available parallelism in a real system model without application-specific information, such as lookahead, from the user. What seriously limits the usage of the Time Warp mechanism is the need to save the state of each logical process periodically.
Reference: [11] <author> Hodges, B. R., Proicou, M. C., Hatrum, T. C., </author> <title> A Distributed Kernel for VHDL Simulation, </title> <booktitle> Proc. of the IEEE 1990 National Aerospace and Electronics Conf., NAECON 1990, vol.1, </booktitle> <address> Dayton, OH, </address> <month> May 21-25, </month> <year> 1990, </year> <pages> pp. 215-220. </pages>
Reference: [12] <author> Hwang, S. Y., Blank, T., Choi, K., </author> <title> Fast functional simulation: An incremental approach. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, </journal> <volume> Vol. 7, No.7, </volume> <month> July </month> <year> 1988, </year> <pages> pp. 765-774. </pages>
Reference-contexts: Hence, this leads to an unpleasant trade-off between utilization, price and performance. Faster uniprocessor algorithms By developing new and faster uniprocessor algorithms specialized for hardware simulations or optimizing existing sequential simulators, simulation time can be decreased <ref> [12] </ref>. One solution could be to use fast VHDL compilers, i.e. not use a sequential VHDL simulator on top of a high-level language compiler such as a C-compiler, but instead compile the VHDL code directly into executable code.
Reference: [13] <institution> IEEE Standard VHDL Language Reference Manual, IEEE Std 1076-1987, IEEE, </institution> <address> New York, </address> <year> 1988. </year>
Reference-contexts: The result was VHDL (Very High Speed Integrated Circuit Hardware Description Language), which now is the official standard for the United States Department of Defence, widely used by industry, and from 1987 also standardized by IEEE (IEEE Std 1076-1987) <ref> [13] </ref>. A new updated standard called VHDL-93 (first called VHDL-92) has recently been accepted (IEEE Std 1076-1993) [5][14]. 2.1 VHDL hardware modeling VHDL is a language for describing general digital hardware systems. The hardware model describes the functionality and structure of the various digital components included in the model. <p> A process that is sensitive to a signal is therefore sensitive to events on that signal, not to any transaction. How 6 ever, it is possible to make a process active on a transaction by adding a special attribute <ref> [13] </ref> [14][18]. 2.2 VHDL hardware simulation When the structure and behavior of a component or sub-module have been specified it is possible to simulate the module by executing its behavioral description for discrete steps in time.
Reference: [14] <institution> IEEE Standard VHDL Language Reference Manual, IEEE Std 1076-1993, IEEE, </institution> <address> New York, </address> <year> 1994. </year>
Reference: [15] <author> Jefferson, D. R., </author> <title> Virtual Time, </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> Vol. 7, No. 3, </volume> <month> July </month> <year> 1985, </year> <pages> pp. 404-425. </pages>
Reference-contexts: The most well known optimistic method is Time Warp, which is based on the concept of Virtual Time, both of them introduced by Jefferson <ref> [15] </ref>. The Virtual Time paradigm Many other PDES approaches are, in fact, based on the virtual time paradigm in the sense that they describe a system as a set of LPs, each with its local event list and local clock. <p> These virtual clocks ticks virtual time possibly at different speed, and their time is used to measure computational progress and to synchronize processes. An important concept is the global virtual time (GVT) <ref> [15] </ref> that is defined as: GVT at real time r is the minimum of (1) all virtual times in all virtual clocks at time r, and (2) of the virtual send times of all messages that have been sent but have not yet been processed at time r.
Reference: [16] <author> Lamport, L. </author> <year> 1978, </year> <title> Time, Clocks, and the Ordering of Events in a Distributed System, </title> <journal> Comm. of the ACM, </journal> <volume> Vol. 21, no. 7, </volume> <month> (July), </month> <pages> pp. 558-565. </pages>
Reference: [17] <author> Leonard, M., </author> <title> VHDL-based simulator boosts design productivity tenfold, Electronic Design, </title> <address> vol.36, no.11, </address> <month> May 12, </month> <year> 1988, </year> <pages> pp. 63-64. 30 </pages>
Reference-contexts: The available VHDL simulation tools are mostly sequential, e.g. [1] and <ref> [17] </ref>, and the existing software solutions that optimize the simulation algorithms on fast workstations are not sufficient for the needs of the industry [9].
Reference: [18] <author> Lipsett, R., Schaefer, C. and Ussery, C., </author> <title> VHDL: Hardware Description and Design, </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1989. </year>
Reference-contexts: When all processes have suspended, simulation time is advanced to the time of the next scheduled transaction and the cycle is repeated. The simulation cycle is pictured in FIGURE 2 <ref> [18] </ref>. It is also possible to view the simulation cycle as a sequential iteration consisting of four steps [2] where the first two steps are the first stage and the two last steps are the second stage in the two-stage simulation cycle: 1.
Reference: [19] <author> Misra, J. </author> <year> 1986, </year> <title> Distributed Discrete-Event Simulation, </title> <journal> Computing Surveys, </journal> <volume> Vol. 18, No. 1, </volume> <month> (March), pp.39-65. </month>
Reference-contexts: The EL is a set of time-stamped event tuples (t i , m i ), where each event is a message m i scheduled to be evaluated at some future event time t i &gt; clock. The DES simulation algorithm is described in pseudo-code in FIGURE 4 <ref> [19] </ref>. 3.2 Parallel simulation The simulation method described above is the traditional sequential DES. This method often tends to be very slow when simulating large systems. It can take several hours or even days to simulate a large complex system on a sequential computer. <p> This is also described by the pseudo-code algorithm in FIGURE 4 <ref> [19] </ref>. According to this algorithm, LP i will select the link with the smallest time stamp and process that message unless some link is empty.
Reference: [20] <author> Ottens, A. and van Hoogstraeten W., </author> <title> The CHESS Project, </title> <institution> Delft University of Technology, </institution> <address> the Netherlands, </address> <month> November 11, </month> <year> 1993. </year>
Reference-contexts: With rather low-level abstraction experimental VHDL models the model functions could be restructured into fine-grained processes, increasing the available parallelism compared to previous studies [28]. As part of the CHESS project <ref> [20] </ref>, Costa et. al. [9] built a Trace Driven Parallelism Analyzer (TDPA) to evaluate parallel VHDL performance. Their system makes it possible to investigate the joint effects of different architectural configurations, connection topologies, and different simulation algorithms.
Reference: [21] <author> Ottens, A. and van Hoogstraeten W., </author> <title> Sequential VHDL simulation, </title> <type> Internal report No. </type> <institution> 1-68340-44(1993)-08, Delft University of Technology, </institution> <address> the Netherlands, </address> <month> December 9, </month> <year> 1993. </year>
Reference: [22] <author> Padua, D. A., Wolfe, M. J., </author> <title> Advanced Compiler Optimizations for supercomputers, </title> <journal> Comm. of the ACM, </journal> <month> Dec. </month> <year> 1986, </year> <pages> pp. 1184-1200. </pages>
Reference: [23] <author> Palaniswamy, A. C., Aji, S., Wilsey, P. A., </author> <title> Performance Measures for Several Optimizations to a Distributed Digital System Simulator, </title> <booktitle> 26th Annual Simulation Symposium, </booktitle> <address> Arlington, VI, March 29-April 1, </address> <year> 1993, </year> <pages> pp. 21-29. </pages>
Reference-contexts: The problem with memory overhead is mainly associated with large state vectors. One way of reducing the needed memory is to neglect to save the state after executing each event, but 15 instead only save every Nth event, e.g. periodic state-saving or periodic checkpointing <ref> [23] </ref>. The period N can be difficult to estimate analytically. A better way might be to introduce an adaptive checkpointing algorithm [25]. Performance of optimistic approach Many researchers have reported successful results from various applications using optimistic simulation methods. <p> A number of ways to reduce these overheads have been proposed and are mentioned in Section 3.2.3. However, the performance of 22 these optimizations are highly dependent on the particular problem domain and the host architecture. Palaniswamy et. al. <ref> [23] </ref>, have performed a study on the possible effects of these optimizations on parallel simulation of digital systems. They simulated gate-level designs using an object-oriented distributed VHDL simulator running on a modified network of SUN workstations.
Reference: [24] <author> Russel, R. M., </author> <title> The Cray-1 Computer System, </title> <journal> Communications of the ACM, </journal> <month> January </month> <year> 1978, </year> <pages> pp. 63-72. </pages>
Reference-contexts: Still, the processor speed puts a limit on the performance and it is difficult to optimize an algorithm to suit all hardware designs. Vector machines Another approach would be to vectorize the existing simulation algorithms and use fast vector machines for the execution, e.g. a Cray vector machine <ref> [24] </ref>. A problem arises when using vector machines if vector data is not evenly spread in memory modules and in reference order. This could cause memory conict problems.
Reference: [25] <author> Rnngren, R. and Ayani, R., </author> <title> Adaptive checkpointing in time warp, </title> <booktitle> In Proceedings of the 8th ACM/IEEE/SCS Workshop on Parallel and Distributed Simulation (PADS), </booktitle> <address> Edinburgh, UK, </address> <year> 1994. </year>
Reference-contexts: The period N can be difficult to estimate analytically. A better way might be to introduce an adaptive checkpointing algorithm <ref> [25] </ref>. Performance of optimistic approach Many researchers have reported successful results from various applications using optimistic simulation methods. Among others, Fujimoto [10] claims that Time Warp is capable of transparently exploiting all available parallelism in a real system model without application-specific information, such as lookahead, from the user.
Reference: [26] <author> Rnngren, R., Riboe, J. and Ayani, R. </author> <year> 1993, </year> <title> Fast Implementations of the Pending Event Set, </title> <booktitle> Intl. Workshop on Modeling, Analysis and Simulation of Computer and Telecom. Systems (MASCOT-93) </booktitle>
Reference-contexts: Global vs. distributed event lists Another issue that needs to be considered for parallel architectures is how the event list or queues should be stored. There exists several examples of how this can be done <ref> [26] </ref> and which is better is dependent on the particular host-architecture, e.g. shared or distributed memory, and hardware model to be simulated. Vellandi and Lightner [29] introduced a new organization for event lists when simulating VHDL.
Reference: [27] <author> Shannon, R. E. </author> <year> 1992, </year> <title> Introduction to Simulation, </title> <booktitle> Proceedings of the 1992 Winter Simulation Conference, </booktitle> <pages> pp. 65-73. </pages>
Reference: [28] <author> Soule, L., Blank, T., </author> <title> Statistics for Parallelism and Abstraction Level in Digital Simulation, </title> <booktitle> 24th ACM/IEEE DAC 1987, </booktitle> <pages> pp. 588-591. </pages>
Reference-contexts: A low degree of available parallelism in digital systems has earlier been reported by Soule and Blank <ref> [28] </ref> but Vellandi and Lightner [29] claim that this is not true. They have found that a higher degree of parallelism when simulating digital systems is achievable through better parallelism extraction of VHDL models together with exploiting parallelism in sequential DES. <p> With rather low-level abstraction experimental VHDL models the model functions could be restructured into fine-grained processes, increasing the available parallelism compared to previous studies <ref> [28] </ref>. As part of the CHESS project [20], Costa et. al. [9] built a Trace Driven Parallelism Analyzer (TDPA) to evaluate parallel VHDL performance. Their system makes it possible to investigate the joint effects of different architectural configurations, connection topologies, and different simulation algorithms.
Reference: [29] <author> Vellandi, B., Lightner, M., </author> <title> Parallelism extraction and program restructuring of VHDL for parallel simulation, </title> <booktitle> The European Conference on Design Automation, </booktitle> <address> Brussels, Belgium, March 16-19, </address> <year> 1992, </year> <pages> pp. 88-96. </pages>
Reference-contexts: A low degree of available parallelism in digital systems has earlier been reported by Soule and Blank [28] but Vellandi and Lightner <ref> [29] </ref> claim that this is not true. They have found that a higher degree of parallelism when simulating digital systems is achievable through better parallelism extraction of VHDL models together with exploiting parallelism in sequential DES. <p> However, the performance of distributed-time algorithms depends on the inherent parallelism of the VHDL model and will probably increase for larger, more complex models, which is the trend of future hardware designs. As a contrast, Vellandi and Lightner <ref> [29] </ref> noticed with their real experiments on a SIMD computer a substantial possibility of parallelism within a single simulation time step, particularly in the component evaluation phase of the simulation cycle. This would justify the use of a synchronous approach instead of an asynchronous approach, i.e. using a centralized-time algorithm. <p> There exists several examples of how this can be done [26] and which is better is dependent on the particular host-architecture, e.g. shared or distributed memory, and hardware model to be simulated. Vellandi and Lightner <ref> [29] </ref> introduced a new organization for event lists when simulating VHDL. By partitioning the event list by signals they increased the parallelism during the event list manipulation phase of a simulation time step. 4.3 VHDL language specific issues Special care needs to be taken when executing VHDL models in parallel.
Reference: [30] <author> Willis, J. C. and Siewiorek, D. P., </author> <title> Optimizing VHDL Compilation for Parallel Simulation, </title> <journal> IEEE Design and Test of Computers, </journal> <volume> Vol. 9, No 3. </volume> <month> September </month> <year> 1992, </year> <pages> pp. 42-53. </pages>
Reference: [31] <author> Wong, M. and Rnngren, R., </author> <title> An Implementation of Time Warp on a Shared Memory Multiprocessor, </title> <type> Internal Report (Draft version), </type> <institution> Dept. of Teleinformatics, Royal Institute of Technology, Sweden, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: We will focus our studies on PDES and particularly on the optimistic methods. This will be done by porting the Time Warp implementation available at the Department of Telein-formatics <ref> [31] </ref> to a MWS. On top of it, we will develop a parallel VHDL simulator proto type for a subset of VHDL.
Reference: [32] <author> Zhang, G., </author> <title> Partitioning and Transformation of VHDL Models for Distributed Simulation, </title> <booktitle> 6th PADS, 1992 (PADS 92), </booktitle> <pages> pp. 203-205. </pages>
References-found: 32

