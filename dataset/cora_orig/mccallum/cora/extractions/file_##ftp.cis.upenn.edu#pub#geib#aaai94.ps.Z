URL: file://ftp.cis.upenn.edu/pub/geib/aaai94.ps.Z
Refering-URL: http://www.cis.upenn.edu/~hms/publications.html
Root-URL: 
Email: Email: (geib,libby,mmoore)@linc.cis.upenn.edu  
Title: SodaJack: an architecture for agents that search for and manipulate objects  
Author: Christopher Geib Libby Levison Michael B. Moore 
Note: Content Areas: planning, AI architectures  
Date: January 22, 1994  
Address: 200 S. 33rd Street, Philadelphia, PA 19104  
Affiliation: University of Pennsylvania Department of Computer and Information Science  
Abstract: fl This research is partially supported by ARO DAAL03-89-C-0031 including U.S. Army Research Laboratory (Aberdeen); U.S. Air Force DEPTH through Hughes Missile Systems F33615-91-C-0001; Naval Training Systems Center N61339-93-M-0843; DMSO through the University of Iowa; NSF IRI91-17110, CISE CDA88-22719, and Instrumentation and Laboratory Improvement Program #USE-9152503. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Philip Agre. </author> <title> The dynamic structure of everyday life. </title> <type> Technical Report 1085, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1988. </year>
Reference-contexts: This suggests that if we are going to design robotic agents to assist us, they must be able to locate objects and manipulate them. For many planning systems, the issue of searching for objects never arises. For example, <ref> [1, 5, 12, 17] </ref> work under the simplifying assumption that the agent knows all of the objects in the world and their locations, and every object in a plan uniquely refers to an object in the world.
Reference: [2] <author> Philip Agre and David Chapman. Pengi: </author> <title> An implementation of a theory of activity. </title> <booktitle> In Proceedings of AAAI, </booktitle> <year> 1987. </year>
Reference-contexts: the command actually refers to a unique scoop; the assistant knows this, and will go and get it 1 . 1 This is not to suggest only one scoop is available, but rather that the agent does not consider getting some other scoop. 1 Much of the work in planning <ref> [2, 5, 10, 12, 13, 18] </ref> has also abstracted away crucial details of how to carry out low-level object manipulation.
Reference: [3] <author> Norman Badler, Bonnie Webber, Jeff Esakov, and Jugal Kalita. </author> <title> Animation from instructions. </title> <editor> In Norman Badler, Brian A. Barsky, and David Zeltzer, editors, </editor> <title> Making them Move: Mechanics, Control, and Animation of Articulated Figures. </title> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: We will close with a discussion of related work. 2 Background The SodaJack system and architecture are an attempt to develop realistic animations of human figures carrying out tasks specified by high-level goals. These animations are created using the Jack animation system <ref> [3] </ref>. We have named the system SodaJack after its first domain, the counter of a soda fountain (Figure 1). SodaJack accepts as input an ordered set of goals to be achieved. Its task is to develop and monitor the execution of a plan for the agent to achieve these goals.
Reference: [4] <author> Welton Becket and Norman I. Badler. </author> <title> Integrated behavioral agent architecture. </title> <booktitle> 1993 Conference on Computer Generated Forces and Behavior Representation, </booktitle> <year> 1993. </year>
Reference-contexts: SodaJack accepts as input an ordered set of goals to be achieved. Its task is to develop and monitor the execution of a plan for the agent to achieve these goals. Jack accepts as input low-level motion directives <ref> [4] </ref> providing a simple interface to the animated agent. Such motion directives are the output of SodaJack. It is important to recognize that since we are working with an animated agent, many of the problems associated with perception in real agents are not significant for us.
Reference: [5] <author> David Chapman. </author> <title> Planning for conjunctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 333-377, </pages> <year> 1987. </year>
Reference-contexts: This suggests that if we are going to design robotic agents to assist us, they must be able to locate objects and manipulate them. For many planning systems, the issue of searching for objects never arises. For example, <ref> [1, 5, 12, 17] </ref> work under the simplifying assumption that the agent knows all of the objects in the world and their locations, and every object in a plan uniquely refers to an object in the world. <p> the command actually refers to a unique scoop; the assistant knows this, and will go and get it 1 . 1 This is not to suggest only one scoop is available, but rather that the agent does not consider getting some other scoop. 1 Much of the work in planning <ref> [2, 5, 10, 12, 13, 18] </ref> has also abstracted away crucial details of how to carry out low-level object manipulation.
Reference: [6] <author> Christopher Geib. </author> <title> Intentions in means-end planning. </title> <type> Technical Report MS-CIS-92-73, </type> <institution> Department of Computer and Information Science, University of Pennsylvania, </institution> <year> 1992. </year>
Reference-contexts: We have adopted a hierarchical planning architecture for SodaJack, since it directly supports the different levels of abstraction used for search planning and object manipulation. Figure 2 shows a system diagram for SodaJack. The communication between its components will be described in Section 4. ItPlanS <ref> [6] </ref> uses a simple goal expansion method to perform its hierarchical planning. It selects an expansion for an unsatisfied goal from a library of possible expansions, using the world state as a guide. This process is repeated down to the level of primitives actions.
Reference: [7] <author> Michael Georgeff and Francois Felix Ingrand. </author> <title> Decision-making in an embedded reasoning system. </title> <booktitle> In Proceedings of IJCAI, </booktitle> <year> 1989. </year>
Reference-contexts: Pemberton and Korf [15] present algorithms for heuristic search on graph spaces, and where only a portion of the graph is available before the agent must commit to an action. The most obvious work to compare the SodaJack system to might be Georgeff's work on PRS <ref> [7, 8] </ref>. SodaJack and PRS both interleave planning and action. However while PRS provides a rich formalism for the design of agents, it does not provide solutions for specific problems.
Reference: [8] <author> Michael Georgeff and Amy Lansky. </author> <title> Reactive reasoning and planning. </title> <booktitle> In Proceedings of AAAI, </booktitle> <year> 1987. </year>
Reference-contexts: Pemberton and Korf [15] present algorithms for heuristic search on graph spaces, and where only a portion of the graph is available before the agent must commit to an action. The most obvious work to compare the SodaJack system to might be Georgeff's work on PRS <ref> [7, 8] </ref>. SodaJack and PRS both interleave planning and action. However while PRS provides a rich formalism for the design of agents, it does not provide solutions for specific problems.
Reference: [9] <author> Andrew Haas. </author> <title> Natural language and robot planning. </title> <type> Technical Report 9318, </type> <institution> Department of Computer Science, SUNY Albany, </institution> <year> 1993. </year>
Reference-contexts: In the case of our specific problem, the search planner translates information acquisition goals to high-level physical goals for the exploration of the environment. There are a number of desiderata that must be satisfied by planning systems that want to build search plans. First, as Haas points out <ref> [9] </ref>, any plan for acquiring information must rest on what the agent knows about the environment. That is, an agent must know the locations that an object could be at, in order to search for it. <p> Thus, the comparisons that will be made here are at an abstract level or concern only one facet of our system. Haas <ref> [9] </ref> has presented an architecture for a reactive system which engages in search. He argues that there is a conflict between classical planning and the strong representation languages required for reasoning about information acquisition, a claim which we dispute.
Reference: [10] <author> Kristian Hammond. </author> <title> Case-Based Planning: Viewing planning as a memory task. </title> <publisher> Academic Press, </publisher> <year> 1989. </year>
Reference-contexts: the command actually refers to a unique scoop; the assistant knows this, and will go and get it 1 . 1 This is not to suggest only one scoop is available, but rather that the agent does not consider getting some other scoop. 1 Much of the work in planning <ref> [2, 5, 10, 12, 13, 18] </ref> has also abstracted away crucial details of how to carry out low-level object manipulation. <p> Thus, while our work could be built on top of the PRS framework, doing so would not change the structure of the system or the general solution methods for the problems we have looked at. A more interesting parallel is that of the work in case-based planning <ref> [10] </ref>. 11 While we have presented this work as a hierarchical planner it could be viewed from the case-based perspective as well. As described here, ItPlanS is, in effect, doing nothing more than selecting previously learned plans from a library.
Reference: [11] <author> Richard E. Korf. </author> <title> Real-time heuristic search. </title> <address> AIJ, 43(2-3):197-221, </address> <year> 1990. </year>
Reference-contexts: Some of the work on searching graphs and trees is also relevant to our problems in planning searches: specifically any of the work based on searching partially known graphs and trees. For example, Korf <ref> [11] </ref> has examined application of heuristic search when the entire search tree is not known before a node must be selected.
Reference: [12] <author> David McAllester and David Rosenblitt. </author> <title> Systematic nonlinear planning. </title> <booktitle> In Proceedings of AAAI, </booktitle> <year> 1991. </year> <month> 13 </month>
Reference-contexts: This suggests that if we are going to design robotic agents to assist us, they must be able to locate objects and manipulate them. For many planning systems, the issue of searching for objects never arises. For example, <ref> [1, 5, 12, 17] </ref> work under the simplifying assumption that the agent knows all of the objects in the world and their locations, and every object in a plan uniquely refers to an object in the world. <p> the command actually refers to a unique scoop; the assistant knows this, and will go and get it 1 . 1 This is not to suggest only one scoop is available, but rather that the agent does not consider getting some other scoop. 1 Much of the work in planning <ref> [2, 5, 10, 12, 13, 18] </ref> has also abstracted away crucial details of how to carry out low-level object manipulation.
Reference: [13] <author> Drew McDermott. </author> <title> Planning and acting. </title> <journal> Cognitive Science, </journal> <volume> 2 </volume> <pages> 71-109, </pages> <year> 1978. </year>
Reference-contexts: the command actually refers to a unique scoop; the assistant knows this, and will go and get it 1 . 1 This is not to suggest only one scoop is available, but rather that the agent does not consider getting some other scoop. 1 Much of the work in planning <ref> [2, 5, 10, 12, 13, 18] </ref> has also abstracted away crucial details of how to carry out low-level object manipulation.
Reference: [14] <author> Michael B. Moore. </author> <title> Search plans. </title> <type> Technical Report MS-CIS-93-55/LINC LAB 250, </type> <institution> Department of Computer and Information Science, University of Pennsylvania, </institution> <year> 1993. </year>
Reference-contexts: Sequential planners can be used to generate search behavior. (A sequential planner is any planner in which the plans produced are simply sequences of actions.) Our approach to search planning relies on producing and executing a sequential plan as a subroutine in a heuristic search algorithm <ref> [14] </ref>. The heuristic search has as its goal finding the container which contains the desired object. The heuristic search currently uses only distance from the agent to order locations for exploration.
Reference: [15] <author> Joseph C. Pemberton and Richard E. Korf. </author> <title> Incremental path planning on graphs with cycles. </title> <booktitle> In Proceedings of AIPS 92, </booktitle> <pages> pages 179-188, </pages> <year> 1992. </year>
Reference-contexts: For example, Korf [11] has examined application of heuristic search when the entire search tree is not known before a node must be selected. Pemberton and Korf <ref> [15] </ref> present algorithms for heuristic search on graph spaces, and where only a portion of the graph is available before the agent must commit to an action. The most obvious work to compare the SodaJack system to might be Georgeff's work on PRS [7, 8].
Reference: [16] <author> Mark A. Peot and David E. Smith. </author> <title> Conditional nonlinear planning. </title> <booktitle> In Proceedings of AIPS, </booktitle> <year> 1992. </year>
Reference-contexts: In our architecture, the search planner selects a single location from among the places the agent is considering for future exploration. Second, planning for searches requires conditional selection of actions to decide whether to continue exploring locations. This requires building conditional plans, however conditional planners such as <ref> [16, 19] </ref> do not distinguish between what the agent knows about the environment from what is true in it. This makes them unacceptable choices for planning searches.
Reference: [17] <author> Earl Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5 </volume> <pages> 115-135, </pages> <year> 1974. </year>
Reference-contexts: This suggests that if we are going to design robotic agents to assist us, they must be able to locate objects and manipulate them. For many planning systems, the issue of searching for objects never arises. For example, <ref> [1, 5, 12, 17] </ref> work under the simplifying assumption that the agent knows all of the objects in the world and their locations, and every object in a plan uniquely refers to an object in the world.
Reference: [18] <author> Marcel Schoppers. </author> <title> Universal plans of reactive robots in unpredictable environments. </title> <booktitle> In Proceedings of IJCAI, </booktitle> <year> 1987. </year>
Reference-contexts: the command actually refers to a unique scoop; the assistant knows this, and will go and get it 1 . 1 This is not to suggest only one scoop is available, but rather that the agent does not consider getting some other scoop. 1 Much of the work in planning <ref> [2, 5, 10, 12, 13, 18] </ref> has also abstracted away crucial details of how to carry out low-level object manipulation.
Reference: [19] <author> D. Warren. </author> <title> Generating conditional plans and programs. </title> <booktitle> In Proceedings of the Summer Conference on AI and the Simulation of Behavior, </booktitle> <address> Edinburgh, </address> <year> 1976. </year> <month> 14 </month>
Reference-contexts: In our architecture, the search planner selects a single location from among the places the agent is considering for future exploration. Second, planning for searches requires conditional selection of actions to decide whether to continue exploring locations. This requires building conditional plans, however conditional planners such as <ref> [16, 19] </ref> do not distinguish between what the agent knows about the environment from what is true in it. This makes them unacceptable choices for planning searches.
References-found: 19

