URL: http://ptolemy.eecs.berkeley.edu/papers/jvsp_codegen/JVSP-codegen.ps.Z
Refering-URL: http://ptolemy.eecs.berkeley.edu/papers/jvsp_codegen/
Root-URL: 
Title: Software Synthesis for DSP Using Ptolemy Practical signal processing systems today are rarely implemented without
Author: Jos Luis Pino, Soonhoi Ha, Edward A. Lee, and Joseph T. Buck 
Date: 9, 7-21 (1995)  Received November 23, 1992. Revised May 10, 1993.  
Note: 1.0 Introduction  A number of design styles can be used to  appears to be both in the languages themselves, which Journal of VLSI Signal Processing,  1995 Kluwer Academic Publishers, Boston.  This document was created with FrameMaker 4.0.4  
Address: Berkeley, CA 94720  
Affiliation: Department of Electrical Engineering and Computer Sciences University of California  
Abstract: Ptolemy is an environment for simulation, prototyping, and software synthesis for heterogeneous systems. It uses modern object-oriented software technology (in C++) to model each subsystem in a natural and efficient manner, and to integrate these subsystems into a whole. The objectives of Ptolemy encompass practically all aspects of designing signal processing and communications systems, ranging from algorithms and communication strategies, through simulation, hardware and software design, parallel computing, and generation of real-time prototypes. In this paper we will introduce the software synthesis aspects of the Ptolemy system. The environment presented here is both modular and extensible. Ptolemy allows the user to choose among various single- or multiple-processor schedulers. So far, however, the customized core-based ASICs for this application are being designed by the DSP vendor, and not by the producer of the telephone equipment. This approach is viable because the functionality of the ASIC is specified by an international standard, and the market is expected to be very large. However, more proprietary designs cannot proceed in this manner. The design process will more closely resemble that of board-level products using commodity DSPs. Such designs, of course, are mixed hardware and software designs. Our approach to code generation is carefully architected to support such heterogeneous designs. Any complete system design methodology, therefore, must include software synthesis for programmable devices. Mainstream design tool vendors for signal processing, such as those provided by Comdisco Systems, Mentor Graphics, and CADIS, have recognized this. They have all recently added software synthesis for DSPs to their tools (see for example [1] and [2]). Looking forward, future tools should also include high-level software synthesis for real-time control as well as coupling to high-level hardware synthesis tools. Since the design styles for these capabilities are likely to be radically different from one another, the ideal methodology must cleanly support heterogeneity. This paper will concentrate on code generation for DSP, but will describe a software architecture capable of adapting to such heterogeneous design problems. 
Abstract-found: 1
Intro-found: 1
Reference: <institution> Software Synthesis for DSP Using Ptolemy 6.0 References </institution>
Reference: 1. <author> D.G. Powell, E. A.Lee, and W.C. Newman, </author> <title> "Direct Synthesis of Optimized DSP Assembly Code from Signal Flow Block Diagrams," </title> <booktitle> International Conference on Acoustics, Speech and Signal Processing vol. 5, </booktitle> <address> San Francisco, </address> <publisher> IEEE, </publisher> <year> 1992, </year> <pages> p. 553-556. </pages>
Reference-contexts: The ptlang preprocessor makes target and star writing systematic, especially for those unfamiliar with C++ or the Ptolemy kernel. Comparing Ptolemy to the other DSP code generation platforms such Comdisco DPC <ref> [1] </ref>, Mentor DSP Station, and Descartes [7], is difficult since we have addressed somewhat orthogonal issues. Some of these other code generators will do better in terms of efficiency for most SDF assembly language dataow graphs. <p> Even though a simple operation like add might take one cycle on a DSP, the add could potentially take four or more cycles. Future versions of Ptolemy will use registers to exchange data, as done in <ref> [1] </ref>.
Reference: 2. <author> J.M. Rabaey, C. Chu, P. Hoang, and M. Potkonjak, </author> <title> "Fast prototyping of datapath-intensive architectures," </title> <journal> IEEE Design & Test of Computers , vol. </journal> <volume> 8, no. 2, </volume> <year> 1991, </year> <pages> p. 40-51. </pages>
Reference-contexts: We have also developed SDF domains that synthesize assembly code for the Motorola DSP96000 family (CG96) and the Sproc multiprocessor DSP from Star Semiconductor. Finally, a Silage code generation domain is being used to couple to hardware synthesis tools developed at Berkeley <ref> [2] </ref>. As a simple example of how Blocks, Schedulers, and Targets can be mixed and matched, consider a set of Blocks that generate assembly language code for Motor-ola DSP56000 family processors.
Reference: 3. <author> K.W. Leary and W. Waddington, "DSP/C: </author> <title> A Stan dard High Level Language for DSP and Numeric Processing," </title> <booktitle> International Conference on Acoustics, Speech and Signal Processing , vol. 2, 1990, p. </booktitle> <pages> 1065-1068. </pages>
Reference: 4. <author> D. Genin, P. Hilfinger, J. Rabaey, C. Scheers, and H. De Man, </author> <title> "DSP specification using the Silage language," </title> <booktitle> International Conference on Acoustics, Speech and Signal Processing , vol. 2, 1990, p. </booktitle> <pages> 1056-1060. </pages>
Reference: 5. <editor> J.C. Bier, E.E. Goei, W.H. Ho, P.D. Lapsley, M.P. O'Reilly, G.C. Sih, and E.A. Lee, "Gabriel: </editor> <title> A design environment for DSP," </title> <journal> IEEE Micro , vol. </journal> <volume> 10, no. 5, </volume> <year> 1990, </year> <pages> p. 28-45. </pages>
Reference-contexts: Such a Scheduler will not always work with DDF Stars. SDF is an appropriate model for multirate signal processing systems with rationally-related sampling rates throughout [15], and is the model used exclusively in Ptolemys predecessor system Gabriel <ref> [5] </ref>. <p> The Target then generates code by executing the actors in the sequence defined by this schedule. This is a quick and efficient approach unless there are large sample rate changes, in which case it corresponds to completely unrolling all loops. This scheduler is similar to one used in Gabriel <ref> [5] </ref>. The second approach we call loop scheduling. In this approach, actors that have the same sample rate are merged (wherever this will not cause deadlock) and loops are introduced to match the sample rates.
Reference: 6. <author> J. Buck, S. Ha, E.A. Lee, and D.G. Messerschmitt, "Ptolemy: </author> <title> A Platform for Heterogeneous Simulation and Prototyping," </title> <booktitle> European Simulation Conference , Copenhagen, </booktitle> <address> Denmark, </address> <year> 1991. </year>
Reference-contexts: Introduction Software Synthesis for DSP Using Ptolemy erwise comparable systems. For a description of the Ptolemy platform refer to <ref> [6] </ref>. Dynamic dataow (DDF) is a data-driven model of computation originally proposed by Dennis [10]. Although frequently applied to design parallel architectures, it is also suitable as a programming model [11], and is particularly well-suited to signal processing that includes asynchronous operations. <p> The interfacing mechanism that permits one model of computation, or domain, to interface cleanly with another is called a wormhole , after the theoretical cosmological phenomenon widely used in science fiction writing that may connect widely separated regions of space, or even different universes. This mechanism is described in <ref> [6, 20] </ref>, and is explained in the context of code generation in section 2.5.3. 2.2 Targets In Ptolemy, a Target class defines those features of an architecture pertinent to code generation.
Reference: 7. <author> S. Ritz, M. Pankert, and H. Meyr, </author> <title> "High Level Software Sythesis for Signal Processing Systems," </title> <booktitle> Inter national Conference on Application Specific Array Processors , IEEE Computer Society Press, 1992, p. </booktitle> <pages> 679-693. </pages>
Reference-contexts: The ptlang preprocessor makes target and star writing systematic, especially for those unfamiliar with C++ or the Ptolemy kernel. Comparing Ptolemy to the other DSP code generation platforms such Comdisco DPC [1], Mentor DSP Station, and Descartes <ref> [7] </ref>, is difficult since we have addressed somewhat orthogonal issues. Some of these other code generators will do better in terms of efficiency for most SDF assembly language dataow graphs. The reason for this lies in the fact that we have not implemented register allocation.
Reference: 8. <author> E.A. Lee and D.G. Messerschmitt, </author> <title> "Synchronous data flow," </title> <booktitle> Proceedings of the IEEE , vol. </booktitle> <volume> 75, no. 9, </volume> <year> 1987, </year> <pages> p. 1235-1245. </pages>
Reference-contexts: More than one Star may be fired at one time if the Target supports this parallelism. We have used this domain to experiment with static scheduling of programs with run-time dynamics [14, 15]. Synchronous dataow (SDF) <ref> [8] </ref> is a sub-Domain of DDF. SDF Stars consume and generate a static and known number of data tokens on each invocation. Since this is clearly a special case of DDF, any Star or Target that works under the SDF model will also work under the DDF model. <p> The simplest strategy is to choose one randomly.There are many possible schedules for all but the most trivial graphs; the schedule chosen takes resource costs into account, such as the necessity of ushing registers and the amount of buffering required, into account (see <ref> [8] </ref> for detailed discussion of SDF scheduling). The Target then generates code by executing the actors in the sequence defined by this schedule. This is a quick and efficient approach unless there are large sample rate changes, in which case it corresponds to completely unrolling all loops.
Reference: 9. <author> S.S. Bhattacharyya, </author> <title> Scheduling synchronous data-flow graphs for efficient iteration , Master's Thesis, </title> <institution> University of California at Berkeley, </institution> <year> 1991. </year>
Reference-contexts: The result is a hierarchical clustering; within each cluster, the techniques described above can be used to generate a schedule. The code then contains nested loop constructs together with sequences of code from the actors. The loop scheduling techniques used in Ptolemy are described in <ref> [9] </ref>; generalization of loop scheduling to include dynamic actors is discussed in [19]. 2.3.2 Parallel scheduling We have implemented three scheduling techniques that map SDF graphs onto multiple-processors with various interconnection topologies: Hus level-based list scheduling, Sihs dynamic level scheduling [17], and Sihs declustering scheduling [18].
Reference: 10. <author> J.B. Dennis, </author> <title> "Data Flow Supercomputers," </title> <journal> IEEE Computer , vol. </journal> <volume> 13, no. 11, </volume> <year> 1980. </year>
Reference-contexts: Introduction Software Synthesis for DSP Using Ptolemy erwise comparable systems. For a description of the Ptolemy platform refer to [6]. Dynamic dataow (DDF) is a data-driven model of computation originally proposed by Dennis <ref> [10] </ref>. Although frequently applied to design parallel architectures, it is also suitable as a programming model [11], and is particularly well-suited to signal processing that includes asynchronous operations. An equivalent model is embodied in the predecessor system Blosim [12, 13].
Reference: 11. <author> A.L. Davis and R.M. Keller, </author> <title> "Data Flow Program Graphs," </title> <journal> IEEE Computer , vol. </journal> <volume> 15, no. 2, </volume> <year> 1982. </year>
Reference-contexts: Introduction Software Synthesis for DSP Using Ptolemy erwise comparable systems. For a description of the Ptolemy platform refer to [6]. Dynamic dataow (DDF) is a data-driven model of computation originally proposed by Dennis [10]. Although frequently applied to design parallel architectures, it is also suitable as a programming model <ref> [11] </ref>, and is particularly well-suited to signal processing that includes asynchronous operations. An equivalent model is embodied in the predecessor system Blosim [12, 13]. In DDF, Stars are enabled by data at their input PortHoles.
Reference: 12. <author> D.G. Messerschmitt, </author> <title> "Structured Interconnection of Signal Processing Programs," </title> <institution> Globecom , Atlanta, Georgia, </institution> <year> 1984. </year>
Reference-contexts: Although frequently applied to design parallel architectures, it is also suitable as a programming model [11], and is particularly well-suited to signal processing that includes asynchronous operations. An equivalent model is embodied in the predecessor system Blosim <ref> [12, 13] </ref>. In DDF, Stars are enabled by data at their input PortHoles. That data may or may not be consumed by the Star when it fires, and the Star may or may not produce data on its outputs.
Reference: 13. <author> D.G. Messerschmitt, </author> <title> "A Tool for Structured Functional Simulation," </title> <journal> IEEE Journal on Selected Areas in Communications , vol. SAC-2, </journal> <volume> no. 1, </volume> <year> 1984. </year>
Reference-contexts: Although frequently applied to design parallel architectures, it is also suitable as a programming model [11], and is particularly well-suited to signal processing that includes asynchronous operations. An equivalent model is embodied in the predecessor system Blosim <ref> [12, 13] </ref>. In DDF, Stars are enabled by data at their input PortHoles. That data may or may not be consumed by the Star when it fires, and the Star may or may not produce data on its outputs.
Reference: 14. <author> S. Ha, </author> <title> Compile-time scheduling of dataflow program graphs with dynamic constructs , Ph.D. </title> <type> Dissertation, </type> <institution> U.C. Berkeley, </institution> <year> 1992. </year>
Reference-contexts: More than one Star may be fired at one time if the Target supports this parallelism. We have used this domain to experiment with static scheduling of programs with run-time dynamics <ref> [14, 15] </ref>. Synchronous dataow (SDF) [8] is a sub-Domain of DDF. SDF Stars consume and generate a static and known number of data tokens on each invocation. <p> The dynamic constructs inside the SDF Wormhole change the run time execution profile from the scheduled one. We have developed a technique that schedules dataow graphs with run-time decision making, aiming to minimize the cost of run-time decisions <ref> [14] </ref>. We will define a specific Target class for this dynamic construct domain and generate suitable control code for the target architecture corresponding to the dynamic constructs. 2.4 Stars Ptolemy has two basic types of stars: simulation stars and code generation stars. <p> Work is in progress to extend our code genera tion techniques to support more general models of computation, such as the token ow model [19] and dynamic constructs <ref> [14] </ref>.
Reference: 15. <author> J. Buck, S. Ha, E.A. Lee, and D.G. Messerschmitt, </author> <title> "Multirate signal processing in Ptolemy," </title> <booktitle> International Conference on Acoustics, Speech and Signal Processing , vol. 2, </booktitle> <address> New York, NY, USA, </address> <publisher> IEEE, </publisher> <year> 1991, </year> <pages> p. 1245-1248. </pages>
Reference-contexts: More than one Star may be fired at one time if the Target supports this parallelism. We have used this domain to experiment with static scheduling of programs with run-time dynamics <ref> [14, 15] </ref>. Synchronous dataow (SDF) [8] is a sub-Domain of DDF. SDF Stars consume and generate a static and known number of data tokens on each invocation. <p> However, an SDF Sched-uler can take advantage of this static information to construct a schedule that can be used repeatedly. Such a Scheduler will not always work with DDF Stars. SDF is an appropriate model for multirate signal processing systems with rationally-related sampling rates throughout <ref> [15] </ref>, and is the model used exclusively in Ptolemys predecessor system Gabriel [5].
Reference: 16. <author> E.A. Lee and J.C. Bier, </author> <title> "Architectures for statically scheduled dataflow," </title> <journal> Journal of Parallel and Distributed Computing , vol. </journal> <volume> 10, no. 4, </volume> <year> 1990, </year> <pages> p. 333-348. </pages>
Reference: 17. <author> G.C. Sih and E.A. Lee, </author> <title> "Dynamic-level scheduling for heterogeneous processor networks," </title> <booktitle> Second IEEE Symposium on Parallel and Distributed Processing </booktitle>
Reference-contexts: For such targets, certain actors must be assigned to certain targets, and the cost of a given actor is in general a function of which child target it is assigned to. We have developed parallel schedulers that address this problem <ref> [17] </ref>. 2.3 Schedulers Given a Universe of functional blocks to be scheduled and a Target describing the topology and characteristics of the single or multiple-processor system for which code is generated, it is the responsibility of the Scheduler object to perform some or all of the following functions: Determine which processor <p> The loop scheduling techniques used in Ptolemy are described in [9]; generalization of loop scheduling to include dynamic actors is discussed in [19]. 2.3.2 Parallel scheduling We have implemented three scheduling techniques that map SDF graphs onto multiple-processors with various interconnection topologies: Hus level-based list scheduling, Sihs dynamic level scheduling <ref> [17] </ref>, and Sihs declustering scheduling [18]. The target architecture is described by its Target object, a kind of MultiTarget. The Target class provides the scheduler with the necessary information on interprocessor communication to enable both scheduling and code synthesis.
Reference: 18. <author> G.C. Sih and E.A. Lee, </author> <title> "Declustering: A New Multiprocessor Scheduling Technique," </title> <journal> IEEE Transac tions on Parallel and Distributed Systems </journal>
Reference-contexts: in Ptolemy are described in [9]; generalization of loop scheduling to include dynamic actors is discussed in [19]. 2.3.2 Parallel scheduling We have implemented three scheduling techniques that map SDF graphs onto multiple-processors with various interconnection topologies: Hus level-based list scheduling, Sihs dynamic level scheduling [17], and Sihs declustering scheduling <ref> [18] </ref>. The target architecture is described by its Target object, a kind of MultiTarget. The Target class provides the scheduler with the necessary information on interprocessor communication to enable both scheduling and code synthesis.
Reference: 19. <author> J. Buck and E.A. Lee, </author> <title> "The Token Flow Model," Data Flow Workshop , Hamilton Island, </title> <address> Australia, </address> <year> 1992. </year>
Reference-contexts: The intent is to preserve the compile-time scheduling properties of SDF but permit data-dependent execution. This work is very new (see <ref> [19] </ref>) and will not be discussed further in this paper. 1.2 Code Generation Domains A Domain in Ptolemy consists of a set of Blocks and Targets, and associated Schedulers that conform to a common computational model. <p> The code then contains nested loop constructs together with sequences of code from the actors. The loop scheduling techniques used in Ptolemy are described in [9]; generalization of loop scheduling to include dynamic actors is discussed in <ref> [19] </ref>. 2.3.2 Parallel scheduling We have implemented three scheduling techniques that map SDF graphs onto multiple-processors with various interconnection topologies: Hus level-based list scheduling, Sihs dynamic level scheduling [17], and Sihs declustering scheduling [18]. The target architecture is described by its Target object, a kind of MultiTarget. <p> Work is in progress to extend our code genera tion techniques to support more general models of computation, such as the token ow model <ref> [19] </ref> and dynamic constructs [14].
Reference: 20. <author> A. Kalavade, </author> <title> "Hardware/Software Codesign using Ptolemy A Case Study," </title> <booktitle> International Workshop on Hardware/Software Codesign , Grassau, </booktitle> <address> Ger-many, </address> <year> 1992. </year>
Reference-contexts: It is also possible to define targets that have not been built. In these cases the generated code runs on functional simulations of the processors in the Thor domain in Ptolemy <ref> [20] </ref>. Most targets have parameters that select what scheduler is to be used; we have several single and multiple-processor Schedulers that use different algorithms for determining partitioning and order of execution of stars. <p> The interfacing mechanism that permits one model of computation, or domain, to interface cleanly with another is called a wormhole , after the theoretical cosmological phenomenon widely used in science fiction writing that may connect widely separated regions of space, or even different universes. This mechanism is described in <ref> [6, 20] </ref>, and is explained in the context of code generation in section 2.5.3. 2.2 Targets In Ptolemy, a Target class defines those features of an architecture pertinent to code generation.
Reference: 21. <author> D.S. Harrison, P. Moore, R. Spickelmier, and A.R. </author> <title> Newton, "Data Management and Graphics Editing in the Berkeley Design Environment," </title> <booktitle> IEEE Interna-tion Conference on Computer-Aided Design </booktitle>
Reference-contexts: Two interfaces are provided: a graphical interface based on VEM, the graphic editor that is part of U.C. Berke-leys Octtools CAD system <ref> [21] </ref>, and a text interface based on Ousterhouts extensible interpreter language Tcl [22]. The user builds graphs hierarchically out of existing blocks, and may also link in user-written blocks by using Ptolemys incremental linking facility. A special preprocessor makes user-written atomic blocks (stars) easier to produce.
Reference: 22. <author> J.K. Ousterhout, </author> <title> "Tcl: An Embeddable Command Language," </title> <booktitle> Winter USENIX Conference 133-146. </booktitle>
Reference-contexts: Two interfaces are provided: a graphical interface based on VEM, the graphic editor that is part of U.C. Berke-leys Octtools CAD system [21], and a text interface based on Ousterhouts extensible interpreter language Tcl <ref> [22] </ref>. The user builds graphs hierarchically out of existing blocks, and may also link in user-written blocks by using Ptolemys incremental linking facility. A special preprocessor makes user-written atomic blocks (stars) easier to produce.
Reference: 23. <author> J.C. Bier and E.A. Lee, </author> <title> "A Class of Multiprocessor Architectures for Real-Time DSP," </title> <booktitle> International Symposium on Circuits and Systems , vol. 4, IEEE, 1990, p. </booktitle> <pages> 2622-2625. </pages>
Reference-contexts: We are also working on models for actual multiple-processor systems such as the CM-5, the AT&T DSP-3, the ordered transaction architecture <ref> [23] </ref>, the Ariel Hydra board, and the Spectrum VASP. The design of Ptolemy is also intended to support heterogenous multi-processor targets.
Reference: 24. <author> S. Sriram and E.A. Lee, </author> <title> "Design and Implementation of an Ordered Memory Access Architecture," </title> <booktitle> International Conference on Acoustics, Speech and Signal Processing , Minneapolis, </booktitle> <address> MN, </address> <publisher> IEEE, </publisher> <year> 1993. </year>
Reference-contexts: The scheduler uses this information to decide whether the incurred communication cost is low enough to merit exploiting the parallelism. For example, in the OMA target <ref> [24] </ref>, which has a shared-bus and shared-memory architecture, the requests for the shared bus from all processing elements are determined at compile-time. Taking advantage of the communication compile-time information, we can reduce the run time communication costs.
Reference: 25. <author> J.C. Bier and E.A. Lee, "Frigg: </author> <title> A Simulation Environment For Multiple-Processor DSP System Development," </title> <booktitle> International Conference on Computer Design: VLSI in Computers and Processors , Wash-ington, </booktitle> <address> DC, USA, </address> <publisher> IEEE Computer Society Press, </publisher> <year> 1989, </year> <pages> p. 280-283. </pages>
Reference-contexts: For each of the leaf nodes in figure 5, there exist predefined star libraries. However, for most users needs, these libraries will be insufficient. As a result, special attention has been given to make star writing in Ptolemy, like Gabriel, easy and systematic <ref> [25] </ref>. Unlike Gabriel and other code generators previously mentioned, Ptolemy is object oriented, thus allowing users to easily re-use code. For example, the C code generation domain has the family of stars fixed lattice filter, adaptive lattice filter, and a vocoder.
Reference: 26. <author> M. Karjalainen, </author> <title> "DSP software integration by object-oriented programming: a case study of QuickSig," </title> <journal> IEEE ASSP Magazine , vol. </journal> <volume> 7, no. 2, </volume> <year> 1990, </year> <pages> p. 21-31. </pages>
Reference-contexts: For example, the C code generation domain has the family of stars fixed lattice filter, adaptive lattice filter, and a vocoder. Here the vocoder star was derived (in the sense of C++ derived classes) from the adaptive lattice filter, in turn derived from the fixed lattice. Karjalainen in <ref> [26] </ref> states that object oriented programming environments are well suited for DSP programming methodology. A typical user-defined code generation star will consist of portholes, states, code blocks, a start () method, an initCode () method, a go () method, a wra-pup () method, and an execTime () method.
References-found: 27

