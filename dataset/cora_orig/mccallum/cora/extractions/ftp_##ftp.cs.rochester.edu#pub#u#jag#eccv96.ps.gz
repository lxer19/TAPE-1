URL: ftp://ftp.cs.rochester.edu/pub/u/jag/eccv96.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/jag/publications.html
Root-URL: 
Email: fjag,fuentes,nelsong@cs.rochester.edu  
Title: Acquiring Visual-Motor Models for Precision Manipulation with Robot Hands  
Author: Martin Jagersand, Olac Fuentes, Randal Nelson 
Web: http://www.cs.rochester.edu/u/fjag,fuentes,nelsong/  
Address: Rochester, N.Y. 14627 U.S.A.  
Affiliation: Department of Computer Science University of Rochester  
Note: In Proc of 4th European Conference on Computer Vision, 1996, p. 603-612  3, 4 and 6 DOF.  
Abstract: Dextrous high degree of freedom (DOF) robotic hands provide versatile motions for fine manipulation of potentially very different objects. However, fine manipulation of an object grasped by a multifinger hand is much more complex than if the object is rigidly attached to a robot arm. Creating an accurate model is difficult if not impossible. We instead propose a combination of two techniques: the use of an approximate estimated motor model, based on the grasp tetrahedron acquired when grasping an object, and the use of visual feedback to achieve accurate fine manipulation. We present a novel active vision based algorithm for visual servoing, capable of learning the manipulator kinematics and camera calibration online while executing a manipulation task. The approach differs from previous work in that a full, coupled image Jacobian is estimated online without prior models, and that a trust region control method is used, improving stability and convergence. We present an extensive experimental evaluation of visual model acquisition and visual servoing in 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> R. Cipolla, P. A. Hadfield and N. J. </author> <title> Hollinghurst Uncalibrated Stereo Vision with Pointing for a Man-Machine Interface In Proc of IAPR workshop on Machine Vision, </title> <address> Tokyo, </address> <year> 1994. </year>
Reference-contexts: Results with visual servoing and varying degrees of model adaption have been presented for robot arms [23, 4, 21, 15, 16, 13, 2, 11] 2 . Visual models suitable for specifying visual alignments have also been studied <ref> [9, 1, 10] </ref>, but it remains to be proven that the approach works on more complex manipulators than the serial link robot arm. <p> size mesh, as explained in section 4. 3 Visual-Motor Model Estimation In previous visual servoing work a Jacobian has been either (1) derived analytically, (2) derived partially analytically and partially estimated (eg. [4, 21]), or (3) determined experimentally by physically executing a set of orthogonal calibration movements e i (eg. <ref> [1, 9] </ref>) and approximating the Jacobian with finite differences: J (x; d) = (f (x + d 1 e 1 ) f (x); : : : ; f (x + d n e n ) f (x))D 1 (2) where D = diag (d); d 2 &lt; n .
Reference: 2. <author> P. I. Corke. </author> <title> High-Performance Visual Closed-Loop Robot Control. </title> <type> PhD thesis, </type> <institution> University of Melbourne, </institution> <year> 1994. </year>
Reference-contexts: Visual servoing, when supplemented with online visual model estimation, fits into the active vision paradigm. Results with visual servoing and varying degrees of model adaption have been presented for robot arms <ref> [23, 4, 21, 15, 16, 13, 2, 11] </ref> 2 . Visual models suitable for specifying visual alignments have also been studied [9, 1, 10], but it remains to be proven that the approach works on more complex manipulators than the serial link robot arm. <p> In robot ? Support was provided by the Fulbright Commission and ONR grant N00014-93-I-0221. 2 For a review of this work we direct the reader to [15] or <ref> [2] </ref>. In Proc of 4th European Conference on Computer Vision, 1996, p. 603-612 arm manipulation we have found such a fully adaptive approach to be particularly helpful when carrying out difficult tasks, such as manipulation of flexible material [15, 16], or performing large rotations for visually exploring object shape [17]. <p> The model is valid around the current system configuration x k , and described by the image <ref> [2] </ref> or visual-motor Jacobian defined as (J j;i )(x k ) = @x i The image Jacobian not only relates visual changes to motor changes, as is exploited in visual feedback control but also highly constrains the possible visual changes to the nD subspace y k+1 = J x + y <p> For simple robot arm control (eg. move along a line in 3 DOF) we have found that almost any controller based on the Newton method will work [15, 16]. There are also many accounts of success in practical application for low DOF manipulation in the literature <ref> [4, 21, 2, 11] </ref>. Robot arm control is also fairly insensitive to somewhat ill conditioned visual measurements, such as caused by bad camera placement, and the particular choice of visual features to track.
Reference: 3. <author> G. Dahlquist and A. Bjorck. </author> <title> Numerical Methods. </title> <publisher> Prentice Hall, </publisher> <month> 199x, </month> <type> Preprint. </type>
Reference-contexts: We use two ideas from optimization: (1) A trust region method <ref> [3] </ref> estimates the current model validity online, and controller response is restricted to be inside this region of trust. (2) A homotopy or path following method [8] is used to divide a potentially non-convex problem into several smaller convex problems by creating subgoals along trajectories planned in visual space.
Reference: 4. <author> J. T. Feddema and C. S. G. Lee. </author> <title> Adaptive image feature prediction and control for visual tracking with a hand-eye coordinated camera. </title> <journal> IEEE Tr. Sys, man and Cyber, </journal> <volume> 20(5), </volume> <year> 1990. </year>
Reference-contexts: Visual servoing, when supplemented with online visual model estimation, fits into the active vision paradigm. Results with visual servoing and varying degrees of model adaption have been presented for robot arms <ref> [23, 4, 21, 15, 16, 13, 2, 11] </ref> 2 . Visual models suitable for specifying visual alignments have also been studied [9, 1, 10], but it remains to be proven that the approach works on more complex manipulators than the serial link robot arm. <p> A combined model acquisition and control approach has many advantages. In addition to being able to do uncalibrated visual servo control, the online estimated models are useful for instance for: (1) Prediction and constraining search in visual tracking <ref> [16, 4] </ref> (2) Doing local coordinate transformations between manipulator (joint), world and visual frames [15, 16]. (3) Synthesizing views from other agent poses [14]. <p> In our case f is linearized on an adaptive size mesh, as explained in section 4. 3 Visual-Motor Model Estimation In previous visual servoing work a Jacobian has been either (1) derived analytically, (2) derived partially analytically and partially estimated (eg. <ref> [4, 21] </ref>), or (3) determined experimentally by physically executing a set of orthogonal calibration movements e i (eg. [1, 9]) and approximating the Jacobian with finite differences: J (x; d) = (f (x + d 1 e 1 ) f (x); : : : ; f (x + d n e <p> For simple robot arm control (eg. move along a line in 3 DOF) we have found that almost any controller based on the Newton method will work [15, 16]. There are also many accounts of success in practical application for low DOF manipulation in the literature <ref> [4, 21, 2, 11] </ref>. Robot arm control is also fairly insensitive to somewhat ill conditioned visual measurements, such as caused by bad camera placement, and the particular choice of visual features to track.
Reference: 5. <author> R. Fletcher. </author> <title> Practical Methods of Optimization. </title> <address> Chichester, </address> <year> 1987. </year>
Reference-contexts: We want to update the Jacobian in such a way as to satisfy the most recent observation (secant condition): y measured = J k+1 x The above condition is under determined, and a family of Broyden updating formulas can be defined <ref> [5, 13] </ref>.
Reference: 6. <author> O. Fuentes and R. C. Nelson. </author> <title> Experiments on dextrous manipulation without prior object models. </title> <type> TR 606, </type> <institution> Computer Science, U of Rochester, </institution> <year> 1996. </year>
Reference-contexts: As a way to reduce position errors without sacrificing compliance, we implemented a higher-level PID Cartesian controller to correct errors directly in the 6-dimensional position-orientation space, using an estimate of the errors in hx; y; z; ff; fi; fli as input. For details see <ref> [6] </ref>. 6 Experimental Results The Utah/MIT hand is a relatively imprecise and difficult to control manipulator. Each joint is actuated by a pair of pneumatically-driven antagonist tendons. This results in a compliant response, but it also makes reliable and consistent positioning difficult to achieve due to hysteresis and friction effects.
Reference: 7. <author> O. Fuentes and R. C. Nelson. </author> <title> Morphing hands and virtual tools (or what good is an extra degree of freedom?). </title> <type> Technical Report 551, </type> <institution> Computer Science U of Rochester, </institution> <year> 1994. </year>
Reference-contexts: Although a few experimental systems that demonstrate the capabilities of dextrous robot hands have been implemented (e.g. [18, 20, 22]), their potential for performing high-precision tasks in unmodelled environments has not been fully realized. We have proposed an approach to dextrous manipulation <ref> [7] </ref>, which does not require a-priori object models; all the required information can be read directly from the hand's sensors.
Reference: 8. <author> Garcia and Zangwill. </author> <title> Pathways to solutions, fixed points, and equilibria. </title> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: We use two ideas from optimization: (1) A trust region method [3] estimates the current model validity online, and controller response is restricted to be inside this region of trust. (2) A homotopy or path following method <ref> [8] </ref> is used to divide a potentially non-convex problem into several smaller convex problems by creating subgoals along trajectories planned in visual space. For details see [16], in which we describe a method for high level visual space task specification, planning, and trajectory generation.
Reference: 9. <author> G. Hager. </author> <title> Calibration-free visual control using projective invariance. </title> <booktitle> In ICCV 1995. </booktitle>
Reference-contexts: Results with visual servoing and varying degrees of model adaption have been presented for robot arms [23, 4, 21, 15, 16, 13, 2, 11] 2 . Visual models suitable for specifying visual alignments have also been studied <ref> [9, 1, 10] </ref>, but it remains to be proven that the approach works on more complex manipulators than the serial link robot arm. <p> size mesh, as explained in section 4. 3 Visual-Motor Model Estimation In previous visual servoing work a Jacobian has been either (1) derived analytically, (2) derived partially analytically and partially estimated (eg. [4, 21]), or (3) determined experimentally by physically executing a set of orthogonal calibration movements e i (eg. <ref> [1, 9] </ref>) and approximating the Jacobian with finite differences: J (x; d) = (f (x + d 1 e 1 ) f (x); : : : ; f (x + d n e n ) f (x))D 1 (2) where D = diag (d); d 2 &lt; n .
Reference: 10. <author> M. Harris. </author> <title> Vision guided part alignment with degraded data. </title> <address> TR-AI 615, U Edinburgh 93. </address>
Reference-contexts: Results with visual servoing and varying degrees of model adaption have been presented for robot arms [23, 4, 21, 15, 16, 13, 2, 11] 2 . Visual models suitable for specifying visual alignments have also been studied <ref> [9, 1, 10] </ref>, but it remains to be proven that the approach works on more complex manipulators than the serial link robot arm.
Reference: 11. <author> K. Hosoda, M. Asada. </author> <title> Versatile visual servoing without knowledge of true jacobian. </title> <booktitle> In Proc of IROS, </booktitle> <year> 1994. </year>
Reference-contexts: Visual servoing, when supplemented with online visual model estimation, fits into the active vision paradigm. Results with visual servoing and varying degrees of model adaption have been presented for robot arms <ref> [23, 4, 21, 15, 16, 13, 2, 11] </ref> 2 . Visual models suitable for specifying visual alignments have also been studied [9, 1, 10], but it remains to be proven that the approach works on more complex manipulators than the serial link robot arm. <p> For simple robot arm control (eg. move along a line in 3 DOF) we have found that almost any controller based on the Newton method will work [15, 16]. There are also many accounts of success in practical application for low DOF manipulation in the literature <ref> [4, 21, 2, 11] </ref>. Robot arm control is also fairly insensitive to somewhat ill conditioned visual measurements, such as caused by bad camera placement, and the particular choice of visual features to track.
Reference: 12. <author> S. Jacobsen, E. Iversen, D. Knutti, R. Johnson, and K. Bigger. </author> <title> Design of the Utah/MIT Dextrous Hand. </title> <booktitle> In Proc ICRA 1986. </booktitle>
Reference-contexts: 1 2 ff k if d k d lower ff k if d lower &lt; d k d upper max (2kffik; ff) if d k &gt; d upper (5) 5 Non-Model-Based Dextrous Manipulation We propose a non-model-based approach to manipulation for the Utah/MIT hand, a 16 DOF four-fingered dextrous manipulator <ref> [12] </ref>. The method does not require any prior information about the object; all the required information can be read directly from the hand's sensors. The method allows arbitrary (within the robot's physical limits) translations and rotations of the object being grasped.
Reference: 13. <author> M. Jagersand. </author> <title> Visual servoing using trust region methods and estimation of the full coupled visual-motor jacobian. </title> <booktitle> In Proc of IASTED Conf Applications of Robotics and Control, </booktitle> <year> 1996. </year>
Reference-contexts: Visual servoing, when supplemented with online visual model estimation, fits into the active vision paradigm. Results with visual servoing and varying degrees of model adaption have been presented for robot arms <ref> [23, 4, 21, 15, 16, 13, 2, 11] </ref> 2 . Visual models suitable for specifying visual alignments have also been studied [9, 1, 10], but it remains to be proven that the approach works on more complex manipulators than the serial link robot arm. <p> We want to update the Jacobian in such a way as to satisfy the most recent observation (secant condition): y measured = J k+1 x The above condition is under determined, and a family of Broyden updating formulas can be defined <ref> [5, 13] </ref>. <p> In previous work we have had best results with this asymmetric correction formula <ref> [15, 16, 13] </ref>: J k+1 = J k + (y measured J k x)x T (3) This is a rank 1 updating formula in the Broyden hierarchy, and it converges to the Jacobian after n orthogonal moves fx k ; k = 1 : : : ng. <p> For details see [16], in which we describe a method for high level visual space task specification, planning, and trajectory generation. For details on the low level control properties see <ref> [13] </ref>. In addition to allowing convergent control, these two methods serve to synchronize the model acquisition with the control, and cause the model to be estimated on an adaptive size mesh; dense when the visual-motor mapping is difficult, sparse when it is near linear. <p> In some cases the adjustment is too large, impairing accuracy. Fig. 5. Distribution of translational positioning errors for joint and visual feedback positioning of the Utah/MIT hand. 7 Discussion We have been doing visual servo control on robot arms in high DOF spaces for several years <ref> [15, 16, 13] </ref>. Getting it to work well on a multi finger gripper like our Utah/MIT dextrous hand was much harder than we had expected. <p> In most cases, this small movement is enough to get out of the singularity, so that normal servoing can be resumed. The estimation and control algorithms we developed have strong theoretical properties (see <ref> [13] </ref>). It is still very important to experimentally evaluate how they perform in real environments, with real process disturbances/noise and manipulators with real mechanically caused errors and finite precision.
Reference: 14. <author> M. Jagersand. </author> <title> Model Free View Synthesis of an Articulated Agent, </title> <type> Technical Report 595, </type> <institution> Computer Science Department, University of Rochester, Rochester, </institution> <address> New York, </address> <year> 1995. </year>
Reference-contexts: addition to being able to do uncalibrated visual servo control, the online estimated models are useful for instance for: (1) Prediction and constraining search in visual tracking [16, 4] (2) Doing local coordinate transformations between manipulator (joint), world and visual frames [15, 16]. (3) Synthesizing views from other agent poses <ref> [14] </ref>. In robot ? Support was provided by the Fulbright Commission and ONR grant N00014-93-I-0221. 2 For a review of this work we direct the reader to [15] or [2].
Reference: 15. <author> M. Jagersand and R. C. Nelson. </author> <title> Adaptive differential visual feedback for uncalibrated hand eye coordination and motor control. </title> <type> TR 579, </type> <institution> Computer Science U of Rochester, </institution> <year> 1994. </year>
Reference-contexts: Visual servoing, when supplemented with online visual model estimation, fits into the active vision paradigm. Results with visual servoing and varying degrees of model adaption have been presented for robot arms <ref> [23, 4, 21, 15, 16, 13, 2, 11] </ref> 2 . Visual models suitable for specifying visual alignments have also been studied [9, 1, 10], but it remains to be proven that the approach works on more complex manipulators than the serial link robot arm. <p> In addition to being able to do uncalibrated visual servo control, the online estimated models are useful for instance for: (1) Prediction and constraining search in visual tracking [16, 4] (2) Doing local coordinate transformations between manipulator (joint), world and visual frames <ref> [15, 16] </ref>. (3) Synthesizing views from other agent poses [14]. In robot ? Support was provided by the Fulbright Commission and ONR grant N00014-93-I-0221. 2 For a review of this work we direct the reader to [15] or [2]. <p> In robot ? Support was provided by the Fulbright Commission and ONR grant N00014-93-I-0221. 2 For a review of this work we direct the reader to <ref> [15] </ref> or [2]. <p> In Proc of 4th European Conference on Computer Vision, 1996, p. 603-612 arm manipulation we have found such a fully adaptive approach to be particularly helpful when carrying out difficult tasks, such as manipulation of flexible material <ref> [15, 16] </ref>, or performing large rotations for visually exploring object shape [17]. <p> Visual features can be drawn from a large class of visual measurements <ref> [23, 15] </ref>, but we have found that the ones which can be represented as point positions or point vectors in camera space are suitable [16]. We track features such as boundary discontinuities (lines,corners) and surface markings. <p> In previous work we have had best results with this asymmetric correction formula <ref> [15, 16, 13] </ref>: J k+1 = J k + (y measured J k x)x T (3) This is a rank 1 updating formula in the Broyden hierarchy, and it converges to the Jacobian after n orthogonal moves fx k ; k = 1 : : : ng. <p> In some cases the adjustment is too large, impairing accuracy. Fig. 5. Distribution of translational positioning errors for joint and visual feedback positioning of the Utah/MIT hand. 7 Discussion We have been doing visual servo control on robot arms in high DOF spaces for several years <ref> [15, 16, 13] </ref>. Getting it to work well on a multi finger gripper like our Utah/MIT dextrous hand was much harder than we had expected. <p> Getting it to work well on a multi finger gripper like our Utah/MIT dextrous hand was much harder than we had expected. For simple robot arm control (eg. move along a line in 3 DOF) we have found that almost any controller based on the Newton method will work <ref> [15, 16] </ref>. There are also many accounts of success in practical application for low DOF manipulation in the literature [4, 21, 2, 11]. <p> It is still very important to experimentally evaluate how they perform in real environments, with real process disturbances/noise and manipulators with real mechanically caused errors and finite precision. Our results show that visual feedback control yields significant repeatability improvement (5 times) in an imprecise PUMA robot arm <ref> [15] </ref>, while only a smaller improvement in the Utah/MIT hand. This is explained by the different characteristics of the manipulators. The inaccuracies in positioning the PUMA arm stem mainly from backlash, which the visual feedback can correct, and the model adaption is made robust to.
Reference: 16. <author> M. Jagersand and R. C. Nelson. </author> <title> Visual space task specification, planning and control. </title> <booktitle> In Proceedings of the 1995 IEEE Symposium on Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: Visual servoing, when supplemented with online visual model estimation, fits into the active vision paradigm. Results with visual servoing and varying degrees of model adaption have been presented for robot arms <ref> [23, 4, 21, 15, 16, 13, 2, 11] </ref> 2 . Visual models suitable for specifying visual alignments have also been studied [9, 1, 10], but it remains to be proven that the approach works on more complex manipulators than the serial link robot arm. <p> A combined model acquisition and control approach has many advantages. In addition to being able to do uncalibrated visual servo control, the online estimated models are useful for instance for: (1) Prediction and constraining search in visual tracking <ref> [16, 4] </ref> (2) Doing local coordinate transformations between manipulator (joint), world and visual frames [15, 16]. (3) Synthesizing views from other agent poses [14]. <p> In addition to being able to do uncalibrated visual servo control, the online estimated models are useful for instance for: (1) Prediction and constraining search in visual tracking [16, 4] (2) Doing local coordinate transformations between manipulator (joint), world and visual frames <ref> [15, 16] </ref>. (3) Synthesizing views from other agent poses [14]. In robot ? Support was provided by the Fulbright Commission and ONR grant N00014-93-I-0221. 2 For a review of this work we direct the reader to [15] or [2]. <p> In Proc of 4th European Conference on Computer Vision, 1996, p. 603-612 arm manipulation we have found such a fully adaptive approach to be particularly helpful when carrying out difficult tasks, such as manipulation of flexible material <ref> [15, 16] </ref>, or performing large rotations for visually exploring object shape [17]. <p> In the two following sections we describe the online model acquisition. In sections 4 and 5 we describe the visual and motor control of the hand. Visual goal assignment, trajectory generation and what kind of visual features to use are task dependent. In <ref> [16] </ref> we describe the high (task) level parts of the system and how to solve real world manipulation problems with this system, such as solving a shape sorting puzzle, handling flexible materials and exchanging a light bulb. <p> Visual features can be drawn from a large class of visual measurements [23, 15], but we have found that the ones which can be represented as point positions or point vectors in camera space are suitable <ref> [16] </ref>. We track features such as boundary discontinuities (lines,corners) and surface markings. Redundant visual perceptions (m n) are desirable as they are used to constrain the raw visual sensory information. Fig. 3. Visual control setup using two cameras. <p> In previous work we have had best results with this asymmetric correction formula <ref> [15, 16, 13] </ref>: J k+1 = J k + (y measured J k x)x T (3) This is a rank 1 updating formula in the Broyden hierarchy, and it converges to the Jacobian after n orthogonal moves fx k ; k = 1 : : : ng. <p> For details see <ref> [16] </ref>, in which we describe a method for high level visual space task specification, planning, and trajectory generation. For details on the low level control properties see [13]. <p> In some cases the adjustment is too large, impairing accuracy. Fig. 5. Distribution of translational positioning errors for joint and visual feedback positioning of the Utah/MIT hand. 7 Discussion We have been doing visual servo control on robot arms in high DOF spaces for several years <ref> [15, 16, 13] </ref>. Getting it to work well on a multi finger gripper like our Utah/MIT dextrous hand was much harder than we had expected. <p> Getting it to work well on a multi finger gripper like our Utah/MIT dextrous hand was much harder than we had expected. For simple robot arm control (eg. move along a line in 3 DOF) we have found that almost any controller based on the Newton method will work <ref> [15, 16] </ref>. There are also many accounts of success in practical application for low DOF manipulation in the literature [4, 21, 2, 11].
Reference: 17. <author> K. Kutulakos and M. Jagersand. </author> <title> Exploring objects by purposive viewpoint control and invariant-based hand-eye coordination. </title> <booktitle> In Workshop on Vision for Robots, IROS, </booktitle> <year> 1995. </year>
Reference-contexts: In Proc of 4th European Conference on Computer Vision, 1996, p. 603-612 arm manipulation we have found such a fully adaptive approach to be particularly helpful when carrying out difficult tasks, such as manipulation of flexible material [15, 16], or performing large rotations for visually exploring object shape <ref> [17] </ref>. For the Utah/MIT dextrous robot hand the fully adaptive approach is appealing because precisely modeling manipulation of a grasped object is much harder than for a typical robot arm, where the object is rigidly attached to the end effector.
Reference: 18. <author> P. Michelman and P. Allen. </author> <title> Complaint manipulation with a dexterous robot hand. </title> <booktitle> In Proc 1993 IEEE Int. Conference on Robotics and Automation, </booktitle> <pages> pages 711-716, </pages> <year> 1993. </year>
Reference-contexts: The four fingers of the Utah/MIT hand have a total of 16 actuated joints. When grasping a rigid object the fingers form a complex parallel kinematic chain. Although a few experimental systems that demonstrate the capabilities of dextrous robot hands have been implemented (e.g. <ref> [18, 20, 22] </ref>), their potential for performing high-precision tasks in unmodelled environments has not been fully realized. We have proposed an approach to dextrous manipulation [7], which does not require a-priori object models; all the required information can be read directly from the hand's sensors.
Reference: 19. <author> R. Nelson, M. Jagersand, O. </author> <title> Fuentes Virtual Tools: A Framework for Simplifying Sensory Motor Control in Complex Robotic Systems TR 576 University of Rochester, </title> <year> 1995. </year>
Reference-contexts: We have proposed an approach to dextrous manipulation [7], which does not require a-priori object models; all the required information can be read directly from the hand's sensors. This alignment virtual tool <ref> [19] </ref> allows versatile manipulation as shown in fig. 1 by providing an approximate transformation between the 6 DOF pose space of the grasped object and the 16 DOF joint control space.
Reference: 20. <author> W. Paetsch and G. von Wichert. </author> <title> Solving insertion tasks with a multifingered gripper by fumbling. </title> <booktitle> In Proc IEEE Int. Conference on Robotics and Automation, </booktitle> <pages> pages 173-179, </pages> <year> 1993. </year>
Reference-contexts: The four fingers of the Utah/MIT hand have a total of 16 actuated joints. When grasping a rigid object the fingers form a complex parallel kinematic chain. Although a few experimental systems that demonstrate the capabilities of dextrous robot hands have been implemented (e.g. <ref> [18, 20, 22] </ref>), their potential for performing high-precision tasks in unmodelled environments has not been fully realized. We have proposed an approach to dextrous manipulation [7], which does not require a-priori object models; all the required information can be read directly from the hand's sensors.
Reference: 21. <author> N. Papanikolopoulos and P. Khosla. </author> <title> Adaptive robotic visual tracking: Theory and experiments. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> 98(3), </volume> <year> 1993. </year>
Reference-contexts: Visual servoing, when supplemented with online visual model estimation, fits into the active vision paradigm. Results with visual servoing and varying degrees of model adaption have been presented for robot arms <ref> [23, 4, 21, 15, 16, 13, 2, 11] </ref> 2 . Visual models suitable for specifying visual alignments have also been studied [9, 1, 10], but it remains to be proven that the approach works on more complex manipulators than the serial link robot arm. <p> In our case f is linearized on an adaptive size mesh, as explained in section 4. 3 Visual-Motor Model Estimation In previous visual servoing work a Jacobian has been either (1) derived analytically, (2) derived partially analytically and partially estimated (eg. <ref> [4, 21] </ref>), or (3) determined experimentally by physically executing a set of orthogonal calibration movements e i (eg. [1, 9]) and approximating the Jacobian with finite differences: J (x; d) = (f (x + d 1 e 1 ) f (x); : : : ; f (x + d n e <p> For simple robot arm control (eg. move along a line in 3 DOF) we have found that almost any controller based on the Newton method will work [15, 16]. There are also many accounts of success in practical application for low DOF manipulation in the literature <ref> [4, 21, 2, 11] </ref>. Robot arm control is also fairly insensitive to somewhat ill conditioned visual measurements, such as caused by bad camera placement, and the particular choice of visual features to track.
Reference: 22. <author> T. H. Speeter. </author> <title> Primitive based control of the Utah/MIT dextrous hand. </title> <booktitle> In Proc IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 866-877, </pages> <address> Sacramento, </address> <year> 1991. </year>
Reference-contexts: The four fingers of the Utah/MIT hand have a total of 16 actuated joints. When grasping a rigid object the fingers form a complex parallel kinematic chain. Although a few experimental systems that demonstrate the capabilities of dextrous robot hands have been implemented (e.g. <ref> [18, 20, 22] </ref>), their potential for performing high-precision tasks in unmodelled environments has not been fully realized. We have proposed an approach to dextrous manipulation [7], which does not require a-priori object models; all the required information can be read directly from the hand's sensors.
Reference: 23. <author> L. Weiss, A. Sanderson, and C. P. Neuman. </author> <title> Dynamic Sensor-Based Control of Robots with Visual Feedback. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-3(5), </volume> <month> October </month> <year> 1987. </year>
Reference-contexts: Visual servoing, when supplemented with online visual model estimation, fits into the active vision paradigm. Results with visual servoing and varying degrees of model adaption have been presented for robot arms <ref> [23, 4, 21, 15, 16, 13, 2, 11] </ref> 2 . Visual models suitable for specifying visual alignments have also been studied [9, 1, 10], but it remains to be proven that the approach works on more complex manipulators than the serial link robot arm. <p> Visual features can be drawn from a large class of visual measurements <ref> [23, 15] </ref>, but we have found that the ones which can be represented as point positions or point vectors in camera space are suitable [16]. We track features such as boundary discontinuities (lines,corners) and surface markings.
References-found: 23

