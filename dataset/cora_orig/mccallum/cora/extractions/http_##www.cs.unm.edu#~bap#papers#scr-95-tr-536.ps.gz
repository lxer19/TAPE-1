URL: http://www.cs.unm.edu/~bap/papers/scr-95-tr-536.ps.gz
Refering-URL: http://www.cs.unm.edu/~bap/publications.html
Root-URL: http://www.cs.unm.edu
Title: Relating Egomotion and Image Evolution  
Author: Barak A. Pearlmutter Leonid Gurvits 
Address: 4 Independence Way, Princeton, NJ 08540  
Affiliation: NEC Research Institute,  
Note: Present address:  
Abstract: March 1995 Report Number SCR-95-TR-536 Abstract By considering the dynamics of the apparent motion of a stationary object relative to a moving observer, we construct a partial differential equation that relates the changes in an image to the motion of the observer. These come in two varieties: a first order system that describes the coevolution of the egocentric radial distances to objects and the visual scene, and a second order system that does not involve any distances or other geometry. The later equation leads, via the calculus of variations, to a novel technique for recovering egomotion from image sequences, a so-called visual yaw detector, which is tested on real data. For expository purposes the derivation is carried out in two dimensions, but the approach extends immediately to three. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Franzen, W. O. </author> <year> (1991). </year> <title> Structure and motion from uniform 3D acceleration. </title> <booktitle> In Proceedings of the IEEE Workshop on Visual Motion, </booktitle> <pages> pp. </pages> <address> 14-20 Princeton, NJ. </address> <publisher> IEEE Press. </publisher>
Reference: <author> Gorr, R. E., Hancock, T. R., Judd, J. S., Lin, L.-J., Novak, C. L., and Rickard, Jr., S. T. </author> <year> (1995). </year> <title> A Vision Based System for Automatic Vehicle Location. </title> <type> Tech. rep. </type> <institution> SCR-95-TR-534, Siemens Corporate Research, Princeton, NJ. </institution>
Reference: <author> Hassenstein, B. and Reichardt, W. </author> <year> (1956). </year> <institution> Systemtheoretische Analyse der Zeit, Reihenfolgen, und Vorzeichenauswertung bei der Bewegungsperzepion des R usselk afers Chlorophanus. Z. Naturforsch, </institution> <month> 11b, </month> <pages> 513-524. </pages>
Reference: <author> Hildreth, E. C. and Koch, C. </author> <year> (1987). </year> <title> The Analysis of Visual Motion: from Computational Theory to Neuronal Mechanisms. </title> <journal> Annual Review of Neuroscience, </journal> <volume> 10, </volume> <pages> 477-533. </pages>
Reference-contexts: Gradients are more susceptible to noise than correlations, and present difficulties when the 6 spatial and temporal discretization imposed by modern digital computer technology makes for image movements greater than a few pixels per time step <ref> (Hildreth and Koch, 1987) </ref>. This latter problem can be ameliorated by spatially downsampling the image, or, since often the ideal sampling rate varies across a single image, by adaptive multiscale techniques.
Reference: <author> Horn, B. K. P. and Schunck, B. G. </author> <year> (1981). </year> <title> Determining Optical Flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17, </volume> <pages> 185-203. </pages>
Reference: <author> Horn, B. K. P. and Weldon, Jr., E. J. </author> <year> (1988). </year> <title> Direct Methods for Recovering Motion. </title> <journal> International Journal of Computer Vision, </journal> <volume> 2, </volume> <pages> 51-76. </pages>
Reference: <author> Koch, C. </author> <year> (1988). </year> <title> Computing Motion in the Presence of Discontinuities: Algorithm and Analog Networks. </title> <editor> In Eckmiller, R. and von der Malsburg, C. (Eds.), </editor> <booktitle> Neural Computers. </booktitle> <publisher> Springer-Verlag. </publisher>
Reference: <author> Lin, L.-J. and Judd, J. S. </author> <year> (1995). </year> <title> A Robust Landmark-Based System For Vehicle Location Using Low-Bandwidth Vision. </title> <type> Tech. rep. </type> <institution> SCR-95-TR-535, Siemens Corporate Research, Princeton, NJ. </institution>
Reference: <author> Moravec, H. P. </author> <year> (1988). </year> <title> Sensor Fusion in Certainty Grids for Mobile Robots. </title> <journal> AI magazine, </journal> <volume> 9(2), </volume> <pages> 61-74. </pages>
Reference-contexts: These could be created by the broken spring models so popular computer vision, which of course correspond to robust estimators, which themselves might improve performance (Poggio, Torre, and Koch, 1985; Koch, 1988). Another route for improvement would be to attempt to maintain a world model via an occupancy grid <ref> (Moravec, 1988) </ref>. This would have the added benefit that it could be matched against a database, hopefully making the system more robust to seasonal variation in the visual appearance of objects. Unfortunately the computational burden might exceed the capacities of our target platform. 6.4.
Reference: <author> Negahdaripour, S. and Horn, B. K. P. </author> <year> (1987). </year> <title> Direct Passive Navigation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(1), </volume> <pages> 168-176. </pages>
Reference: <author> Novak, C. L. and Hancock, T. R. </author> <year> (1995). </year> <title> Probability Modelling for Visual Matching in Automatic Vehicle Location. </title> <type> Tech. rep. </type> <institution> SCR-95-TR-532, Siemens Corporate Research, Princeton, NJ. </institution>
Reference: <author> Novak, C. L., Hancock, T. R., Rickard, Jr., S. T., and Judd, J. S. </author> <year> (1995). </year> <title> A Visual Gyroscope for Automatic Vehicle Location. </title> <type> Tech. rep. </type> <institution> SCR-95-TR-531, Siemens Corporate Research, Princeton, NJ. </institution>
Reference: <author> Poggio, T. and Reichardt, W. </author> <year> (1973). </year> <title> Considerations on models of movement detection. </title> <journal> Biological Cybernetics, </journal> <volume> 13, </volume> <pages> 223-227. </pages>
Reference: <author> Poggio, T., Torre, V., and Koch, C. </author> <year> (1985). </year> <title> Computational vision and regularization theory. </title> <journal> Nature, </journal> <volume> 317(6035), </volume> <pages> 314-319. </pages>
Reference: <author> Poggio, T., Yang, W., and Torre, V. </author> <year> (1989). </year> <title> Optical Flow: Computational Properties and Networks, Biological and Analog. </title> <publisher> Addison-Wesley. </publisher>
Reference: <author> Potters, M. and Bialek, W. </author> <year> (1994). </year> <title> Statistical mechanics and visual signal processing. </title>
Reference-contexts: On the other hand, there are theoretical reasons to believe that gradient methods perform better than correlation methods in the high signal to noise regime <ref> (Potters and Bialek, 1994) </ref>. Another popular indirect method is point tracking, as in the matrix decomposition method of Tomasi and Kanade (1992) of the chronogeneous motion algorithm of Franzen (1991).
Reference: <author> J. </author> <title> Phys. </title> <booktitle> I France, </booktitle> <volume> 4, </volume> <pages> 1755-1775. </pages>
Reference: <author> Ramachandran, V. S. and Gregory, R. L. </author> <year> (1978). </year> <title> Does color provide an input the human motion perception?. </title> <journal> Nature, </journal> <volume> 275, </volume> <pages> 55-56. </pages> <note> 8 Tomasi, </note> <author> C. and Kanade, T. </author> <year> (1992). </year> <title> Shape and Motion from Image Streams under Orthography. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9(2), </volume> <pages> 137-154. </pages>
Reference-contexts: It is interesting to note that in primates short range motion makes little use of color, while long range motion is quite sensitive to color boundaries <ref> (Ramachandran and Gregory, 1978) </ref>. 7
Reference: <author> Uras, S., Girosi, F., Verri, A., and Torre, V. </author> <year> (1989). </year> <title> A computational approach to motion perception. </title> <journal> Biological Cybernetics, </journal> <volume> 60, </volume> <pages> 79-87. </pages>
Reference-contexts: The approach taken here is a direct one, since image gradients are used directly, rather than being used to calculate the optical flow (Horn and Schunck, 1981; Poggio, Yang, and Torre, 1989; Verri and Poggio, 1989) which in turn constitutes the input to an egomotion module <ref> (Uras et al., 1989) </ref>. 6.3. Noise model The equations shown in the text are optimized for a small amount of additive gaussian noise, and fall into the MLE framework, since they are derived from a least squared formulation and incorporate no regularizer or prior on the egomotion.
Reference: <author> Verri, A. and Poggio, T. </author> <year> (1989). </year> <title> Motion Field and Optical Flow: Qualitative Properties. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11, </volume> <pages> 490-498. 9 </pages>
References-found: 20

