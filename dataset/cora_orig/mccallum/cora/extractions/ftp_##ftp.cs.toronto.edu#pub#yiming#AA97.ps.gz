URL: ftp://ftp.cs.toronto.edu/pub/yiming/AA97.ps.gz
Refering-URL: http://www.cs.toronto.edu/~yiming/Research.html
Root-URL: http://www.cs.toronto.edu
Email: yiming@vis.toronto.edu and tsotsos@vis.toronto.edu  
Title: Knowledge Difference and its Influence on a Search Agent  
Author: Yiming Ye and John K. Tsotsos 
Address: Toronto, Ontario, Canada M5S 1A4  
Affiliation: Department of Computer Science University of Toronto  
Abstract: This paper studies the influence of knowledge difference on the performance of a search agent | a controllable camera that can pan, tilt and zoom. The task of the agent is to search for a 3D target within a 3D environment. The goal is to maximize the probability of detecting the target within a given period of time. The search agent does this by autonomously controlling its state parameters to bring the target into the field of view of the camera and to make the image of the target with quality such that it can be detected by the available recognition algorithms. Before the search process, the agent has some knowledge of the position of the target. This knowledge is used to guide the sensor planning process. Typically, this knowledge is different more or less from the real situation. This "knowledge difference" (the discrepancy between the agent's knowledge and reality) can influence the performance of the agent. In this paper, we study how to formulate quantitatively the knowledge difference and how the performance of the agent is influenced by this difference. We also propose a method to integrate knowledge from different sources such that the knowledge difference can be reduced. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Garvey, T. D. </author> <year> 1976. </year> <title> Perceptual strategies for purposive vision. </title> <type> Technical Report Technical Note 117, </type> <institution> SRI International. </institution>
Reference-contexts: Although sensor planning for object search is very important if a robot is to interact intelligently and effectively with its environment, it is interesting to note that there is little research on this subject within the computer vision community. Garvey <ref> (Garvey 1976) </ref> proposes the idea of indirect search for the target. Wix-son (Wixson 1994) presents a mathematical model of search efficiency and analyzes the efficiency of indirect search, concluding that indirect search can improve efficiency in many situations.
Reference: <author> Jasiobedzki, P.; Jenkin, M.; Milios, E.; Down, B.; and Tsotsos, J. </author> <year> 1993. </year> <title> Laser eye anew 3d sensor for active vision. In Intelligent Robotics and Computer Vision: Sensor Fusion VI. </title> <booktitle> Proceedings of SPIE. </booktitle> <volume> vol. </volume> <year> 2059, </year> <pages> 316-321. </pages>
Reference: <author> K., T.; Allen, P.; and Tsai, R. </author> <year> 1992. </year> <title> A survey of sensor planning in computer vision. </title> <type> Technical report, </type> <institution> Comp. Sci. Dept., Columbia University. </institution>
Reference: <author> Koopman, B. O. </author> <year> 1980. </year> <title> Search and Screen: general principles with historical applications. </title> <address> Elmsford, N.Y: </address> <publisher> Pergaman Press. </publisher>
Reference: <editor> Maver, J., and Bajcsy, R. </editor> <year> 1990. </year> <title> How to decide from the first view where to look next. </title> <booktitle> In Proceedings of the DARPA Image Understanding Workshop. </booktitle>
Reference: <author> Reece, D., and Shafer, S. </author> <year> 1992. </year> <title> Using active vision to simplify perception for robot driving. </title> <type> Technical Report CMU-CS-91-199, </type> <institution> Comp. Sci., Carnegie Mellon. </institution>
Reference: <author> Schubert, J. </author> <year> 1994. </year> <title> Cluster-based specification techniques in Dempster-Shafer Theory for an evidential target tracks. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Numerical Analysis and Computing Science, Royal Institute of Technology, Stockholm, SWEDEN. </institution>
Reference-contexts: Since usually we have more than one knowledge source, we need to combine knowledge from all the sources to obtain the initial distribution. Our strategy is to first use the Dempster-Shafer theory <ref> (Schubert 1994) </ref> to integrate knowledge derived from a variety of sources. Then, we transform the integrated result into a reasonable probability distribution. As discussed before, the search space is tessellated into a series of elements c i . <p> For each knowledge source S i , we can obtain a belief function m S i . To combine the belief functions from two knowledge sources S i and S j , we use Dempster Shafer's rule of combination <ref> (Schubert 1994) </ref> m (A) = m S i m S j (A) P T 1 X Y =OE m S i (X) m S j (Y ) where X is a focal element of m S i ; Y is a focal ele ment of m S j ; m = <p> In order to build the needed probability distribution, we distribute m (A) equally among the atoms of A. Therefore, m (A) is given to each c i j , 1 j k. This procedure corresponds to the Insufficient Reason Principle <ref> (Schubert 1994) </ref>: if one must build a probability distribution on n elements, given a lack of information, give a proba bility 1 k to each element. This procedure is repeated for each mass m.
Reference: <author> Tsotsos, J. </author> <year> 1990. </year> <title> Analyzing vision at the complexity level. </title> <booktitle> The behavioral and brain science 13 </booktitle> <pages> 423-469. </pages>
Reference: <author> Wixson, L. E. </author> <year> 1994. </year> <title> Gaze Selection for Visual Search. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, University of Rochester. </institution>
Reference-contexts: Garvey (Garvey 1976) proposes the idea of indirect search for the target. Wix-son <ref> (Wixson 1994) </ref> presents a mathematical model of search efficiency and analyzes the efficiency of indirect search, concluding that indirect search can improve efficiency in many situations. Connell (Connell 1989) constructed a robot that roams an area searching for and collecting soda cans.
Reference: <author> Ye, Y., and Tsotsos, J. K. </author> <year> 1995. </year> <title> Where to look next in 3d object search. </title> <booktitle> In IEEE International Symposium for Computer Vision. </booktitle>
Reference-contexts: A brief description of the sensor planning strategy is as follows (please refer to (Ye 1996b) and <ref> (Ye & Tsot-sos 1995) </ref> for detail). For a given recognition algorithm, there are many possible viewing angle sizes. However, the whole search region can be examined with high probability of detection using only a small number of them.
Reference: <author> Ye, Y., and Tsotsos, J. K. </author> <year> 1996a. </year> <title> Sensor planning in 3d object search: its formulation and complexity. </title> <booktitle> In The 4th International Symposium on Artificial Intel-ligenceand Mathematics. </booktitle>
Reference-contexts: Since this task is NP-Complete <ref> (Ye & Tsotsos 1996a) </ref>, we consider a simpler problem: decide only which is the very next action to execute.
Reference: <author> Ye, Y., and Tsotsos, J. K. </author> <year> 1996b. </year> <title> Tracking with pan, tilt, </title> <journal> and zoom camera. </journal> <note> In Preparation. </note>
Reference-contexts: According to the image formation process and geometric relations, we have developed a method that can tessellate this huge space of candidate actions into a small number of actions that must be tried. A brief description of the sensor planning strategy is as follows (please refer to <ref> (Ye 1996b) </ref> and (Ye & Tsot-sos 1995) for detail). For a given recognition algorithm, there are many possible viewing angle sizes. However, the whole search region can be examined with high probability of detection using only a small number of them. <p> We have designed an algorithm that can generate only directions such that their union can cover the whole viewing sphere with minimum overlap <ref> (Ye 1996b) </ref>. Only the actions with the viewing angle sizes and the corresponding directions obtained by the above method are taken as the candidate actions. So, the huge space of possible sensing actions is decomposed into a finite set of actions that must be tried.
Reference: <author> Ye, Y. </author> <year> 1996. </year> <title> Sensor Planning for Object Search. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, University of Toronto. </institution>
References-found: 13

