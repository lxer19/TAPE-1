URL: http://www.cs.ucla.edu/~goldman/discovery.ps
Refering-URL: http://www.cs.ucla.edu/~goldman/papers.html
Root-URL: http://www.cs.ucla.edu
Title: P a  
Author: t t e r n T h e o r e t i c L e a r n i n g Jeffrey A. Goldman Timothy D. Ross David A. Gadd Wright-Laboratory 
Address: Street STE 1  45433-7408  
Affiliation: 2690 C  Wright-Patterson AFB, Ohio  
Pubnum: WL/AARA-3  
Abstract: The goal of learning from sample data is to extract a concept that captures the underlying pattern while still representing it in a way useful to the investigator. A new approach based on function decomposition in the Pattern Theory framework is presented here. The objective of this extended abstract is three-fold. The first is to provide an overview of our new approach to learning. Specifically, we wish to show the applicability to discovery. Second, we will demonstrate the correlation of decomposed function cardinality (DFC) and "patterned." Finally, we demonstrate the robustness of this approach by exhibiting experimental results on binary functions with C4.5. This new approach to discovery and learning is a powerful method for finding patterns in a robust manner. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Robert L. Ashenhurst. </author> <title> The decomposition of switching functions. </title> <booktitle> In Proceedings of the Inter--national Symposium on the Theory of Switching, </booktitle> <month> April </month> <year> 1957. </year>
Reference-contexts: It is noted that a given minimal decomposition is not unique. For a more rigorous explanation of the inner workings of function decomposition or function extrapolation, the reader is referred to <ref> [1] </ref> and [5]. An important point is that a function with a low DFC has been experimentally and theoretically determined to be learnable with a small number of samples [5]. Also, functions we are interested in learning, (i.e., functions that are highly "patterned,") have a low DFC.
Reference: [2] <author> David Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <journal> Artificial Intelligence, </journal> <volume> 36(2) </volume> <pages> 177-221, </pages> <year> 1988. </year>
Reference-contexts: 1 The Pattern Theory Approach Pattern Theory is a discipline that arose out of machine learning <ref> [2] </ref> [6] and switching theory [5]. The original goal was to develop formal methods of algorithm design from specifications. The approach is based on a technique called function decomposition and a measure called decomposed function cardinality (DFC).
Reference: [3] <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> Palo Alto, Califor-nia, </address> <year> 1993. </year>
Reference-contexts: example, if there is a particular application where the only important relationships include AND, OR, and NOT, then the concepts we find will only contain those operators while still constrained to find the minimum DFC. 3 Quantitative Results with C4.5 3.1 C4.5 A detailed study of C4.5 is given in <ref> [3] </ref>. The intention of this section is to provide a brief discussion of what was tested. Several parameter options were tested on the entire benchmark set. Different options such as grouping, windowing, threshold, and number of trees were changed in order to yield C4.5's best performance.
Reference: [4] <author> Timothy D. Ross, Jeffrey A. Goldman, David A. Gadd, Michael J. Noviskey, and Mark L. Ax-tell. </author> <title> On the decomposition of real-valued functions. </title> <booktitle> In Third International Workshop on Post-Binary ULSI Systems in affiliation with the Twenty-Fourth International Symposium on Multiple-Valued Logic, </booktitle> <year> 1994. </year>
Reference-contexts: While we have not shown it here, the DFC correspondence extends to other popular machine learning type functions such as the Monk's problems and tic-tac-toe domains. This framework is also being expanded to handle larger numbers of variables, discrete variables, continuous variables <ref> [4] </ref>, and missing values in the inputs.
Reference: [5] <author> Timothy D. Ross, Michael J. Noviskey, Timothy N. Taylor, and David A. Gadd. </author> <title> Pattern theory: An engineering paradigm for algorithm design. </title> <type> Final Technical Report WL-TR-91-1060, </type> <institution> Wright Laboratory, USAF, </institution> <address> WL/AART, WPAFB, OH 45433-6543, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: 1 The Pattern Theory Approach Pattern Theory is a discipline that arose out of machine learning [2] [6] and switching theory <ref> [5] </ref>. The original goal was to develop formal methods of algorithm design from specifications. The approach is based on a technique called function decomposition and a measure called decomposed function cardinality (DFC). <p> It is noted that a given minimal decomposition is not unique. For a more rigorous explanation of the inner workings of function decomposition or function extrapolation, the reader is referred to [1] and <ref> [5] </ref>. An important point is that a function with a low DFC has been experimentally and theoretically determined to be learnable with a small number of samples [5]. Also, functions we are interested in learning, (i.e., functions that are highly "patterned,") have a low DFC. <p> For a more rigorous explanation of the inner workings of function decomposition or function extrapolation, the reader is referred to [1] and <ref> [5] </ref>. An important point is that a function with a low DFC has been experimentally and theoretically determined to be learnable with a small number of samples [5]. Also, functions we are interested in learning, (i.e., functions that are highly "patterned,") have a low DFC. Moreover, "useful" concepts from data correspond to functions that have a low DFC. The Function Learning And Synthesis Hot-Bed (FLASH) was developed to explore function decomposition, and pattern finding.
Reference: [6] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> Novem-ber </month> <year> 1984. </year>
Reference-contexts: 1 The Pattern Theory Approach Pattern Theory is a discipline that arose out of machine learning [2] <ref> [6] </ref> and switching theory [5]. The original goal was to develop formal methods of algorithm design from specifications. The approach is based on a technique called function decomposition and a measure called decomposed function cardinality (DFC).
References-found: 6

