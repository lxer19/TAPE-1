URL: ftp://ftp.cs.rochester.edu/pub/papers/ai/94.tn3.The_TRAINS_Project.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/traum/papers.html
Root-URL: 
Title: The TRAINS Project: A case study in building a conversational planning agent  
Author: James F. Allen, Lenhart K. Schubert, George Ferguson, Peter Heeman, Chung Hee Hwang, Tsuneaki Kato, Marc Light, Nathaniel G. Martin, Bradford W. Miller, Massimo Poesio, David R. Traum 
Note: The TRAINS project has been funded in part by ONR/ARPA grant N00014-92-J-1512, U.S. Air Force Rome Laboratory research contract F30602-91-C-0010, and NSF grant IRI-90-13160.  
Date: September 1994  
Address: Rochester, New York 14627  
Affiliation: The University of Rochester Computer Science Department  
Pubnum: TRAINS Technical Note 94-3  
Abstract: The Trains project is an effort to build a conversationally proficient planning assistant. A key part of the project is the construction of the Trains system, which provides the research platform for a wide range of issues in natural language understanding, mixed-initiative planning systems, and representing and reasoning about time, actions and events. Four years have now passed since the beginning of the project. Each year we have produced a demonstration system that focused on a dialog that illustrates particular aspects of our research. The commitment to building complete integrated systems is a significant overhead on the research, but we feel it is essential to guarantee that the results constitute real progress in the field. This paper describes the goals of the project, and our experience with the effort so far. This paper is to appear in the Journal of Experimental and Theoretical AI, 1995. 
Abstract-found: 1
Intro-found: 1
Reference: [Allen, 1984] <author> James F. Allen, </author> <title> "Towards a general theory of action and time," </title> <journal> Artificial Intelligence, </journal> <volume> 23(2) </volume> <pages> 123-154, </pages> <year> 1984. </year>
Reference-contexts: knowledge management and inference system allowing data-driven inference, goal-driven inference, and featuring integration with about a dozen specialist modules for accelerating temporal, taxonomic, partonomic, set-theoretic, numeric, and other special types of inference. 5.3 The EBTL Representation EBTL (Event Based Temporal Logic) is a typed logic based on interval temporal logic <ref> [Allen, 1984; Allen and Ferguson, 1994] </ref>, which was designed to facilitate reasoning about 21 actions and events in temporally complex worlds.
Reference: [Allen, 1994] <author> James F. Allen, </author> <title> Natural Language Understanding, </title> <address> Benjamin/Cummings, Redwood City, CA, 2nd edition, </address> <year> 1994. </year>
Reference-contexts: The feature trees are non-overlapping, i.e., the features in any one tree are distinct from the features in all other trees. The feature-tree approach leads to a quite compact syntax for grammatical rules. rules (with slight modifications for readability). Subcategorization restrictions are handled 4 See <ref> [Allen, 1994] </ref> for an introduction to chart parsing and rule-by-rule interpretation. 5 There is some similarity to the grammatical sort hierarchy in HPSG [Pollard and Sag, 1994], though HPSG does not subdivide atomic features values. 25 S-tell ;; e.g., [we have to make OJ] [.] :SYNRULE (S tell) &lt;-- (S decl)
Reference: [Allen and Ferguson, 1994] <author> James F. Allen and George Ferguson, </author> <title> "Actions and events in interval temporal logic," </title> <journal> Journal of Logic and Computation, </journal> <note> 1994. To appear. </note>
Reference-contexts: knowledge management and inference system allowing data-driven inference, goal-driven inference, and featuring integration with about a dozen specialist modules for accelerating temporal, taxonomic, partonomic, set-theoretic, numeric, and other special types of inference. 5.3 The EBTL Representation EBTL (Event Based Temporal Logic) is a typed logic based on interval temporal logic <ref> [Allen, 1984; Allen and Ferguson, 1994] </ref>, which was designed to facilitate reasoning about 21 actions and events in temporally complex worlds.
Reference: [Allen et al., 1989] <author> James F. Allen, S. Guez, Elizabeth Hinkelman, Keri Jackson, Alice Kyburg, and David R. Traum, </author> <title> "The Discourse System Project," </title> <type> Technical Report 317, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <year> 1989. </year>
Reference-contexts: If the task is too easy, then people will prefer to solve the problem themselves rather than collaborating with the system. We explored two other tasks before choosing the final one. The first was an automated reference librarian <ref> [Allen et al., 1989] </ref>. In this scenario, a person was given an essay topic and then was asked to interact with the "system" in order to find relevant books from the library catalog.
Reference: [Allen and Miller, 1991] <author> James F. Allen and Bradford W. Miller, </author> <title> "The RHET system: A sequence of self-guided tutorials," </title> <type> Technical Report 325, </type> <institution> Dept. of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <year> 1991. </year>
Reference-contexts: It is built on top of the RHET knowledge representation system <ref> [Allen and Miller, 1991] </ref>, which provides the system with several key reasoning capabilities, including type hierarchies and typed unification, equality reasoning, temporal reasoning, frame-like event representations, and an explicit context mechanism for representing belief contexts, hypothetical reasoning and other modalities.
Reference: [Allen and Perrault, 1980] <author> James F. Allen and C. R. Perrault, </author> <title> "Analyzing intention in utterances," </title> <journal> Artificial Intelligence, </journal> <volume> 15(3) </volume> <pages> 143-178, </pages> <year> 1980. </year>
Reference-contexts: It also observes communicative acts by other agents when utterances are performed by the manager and reports are produced by the Trains world agents. One of the insights of the early computational work on speech acts (e.g., <ref> [Cohen and Perrault, 1979; Allen and Perrault, 1980] </ref>) was that traditional planning mechanisms could be used for communicative acts. Trains can be viewed as continuing in this tradition, although it must deal with many additional complications that arise because of the highly interactive nature of our dialogues.
Reference: [Barwise and Perry, 1983] <author> J. Barwise and J. Perry, </author> <title> Situations and Attitudes, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1983. </year>
Reference-contexts: The most distinctive aspect of EL is its use of episodes, which are similar to situations in situation semantics <ref> [Barwise and Perry, 1983] </ref>. Like a situation, an episode characterizes a partial state of affairs over some period of time at some location. It subsumes the notion of events that is used in many representations based on Davidson [1967], because an event is a particular kind of episode.
Reference: [Bratman et al., 1988] <author> Michael E. Bratman, David Israel, and Martha Pollack, </author> <title> "Plans and resource-bounded practical reasoning," </title> <journal> Computational Intelligence, </journal> <volume> 4 </volume> <pages> 349-355, </pages> <year> 1988. </year>
Reference: [Chierchia and McConnell-Ginet, 1990] <author> G. Chierchia and S. McConnell-Ginet, </author> <title> Meaning and Grammar, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference: [Clark and Schaefer, 1989] <author> H. Clark and E. Schaefer, </author> <title> "Contributing to Discourse," </title> <journal> Cognitive Science, </journal> <volume> 13 </volume> <pages> 259-294, </pages> <year> 1989. </year>
Reference-contexts: is represented using the theory of Conversation Acts [Traum and Hinkelman, 1992] which involves interactions at four different levels: * turn-taking: acts that maintain, release, or take the turn in the dialogue; * grounding: acts that deal with establishing shared knowledge about the dialogue, e.g., acknowledgments and repairs (as in <ref> [Clark and Schaefer, 1989] </ref>); * core speech acts: the illocutionary acts found in traditional approaches, e.g., inform acts; * argumentation: acts that characterize the relationship between utterances (e.g., one utterance elaborates on another). Each utterance will generally contain acts at each of these levels.
Reference: [Cohen and Perrault, 1979] <author> P. R. Cohen and C. R. Perrault, </author> <title> "Elements of a plan-based theory of speech acts," </title> <journal> Cognitive Science, </journal> <volume> 3 </volume> <pages> 177-212, </pages> <year> 1979. </year>
Reference-contexts: It also observes communicative acts by other agents when utterances are performed by the manager and reports are produced by the Trains world agents. One of the insights of the early computational work on speech acts (e.g., <ref> [Cohen and Perrault, 1979; Allen and Perrault, 1980] </ref>) was that traditional planning mechanisms could be used for communicative acts. Trains can be viewed as continuing in this tradition, although it must deal with many additional complications that arise because of the highly interactive nature of our dialogues.
Reference: [Davidson, 1967] <author> Donald Davidson, </author> <title> "The logical form of action sentences," </title> <editor> in N. Rescher, editor, </editor> <title> The Logic of Decision and Action. </title> <publisher> University of Pittsburgh Press, </publisher> <address> Pittsburgh, PA, </address> <year> 1967. </year>
Reference: [Gazdar et al., 1985] <author> G. Gazdar, E. Klein, G. Pullum, and I. Sag, </author> <title> Generalized Phrase Structure Grammar, </title> <publisher> Basil Blackwell, Oxford, </publisher> <address> UK, </address> <year> 1985. </year>
Reference-contexts: in forthcoming papers in the Trains technical note series. 6.1 Syntactic and Semantic Rules The NL front end of Trains consists of a chart parser working off a context-free grammar that directs computes logical forms expressed in EL in rule-by-rule fashion. 4 The grammar is like generalized phrase-structure grammar (GPSG) <ref> [Gazdar et al., 1985] </ref> in its use of categories consisting of features, its treatment of unbounded movement in terms of slash features, and its reliance on feature principles such as the head feature and foot feature principles to constrain feature percolation.
Reference: [Gerevini and Schubert, 1993] <author> Alfonso Gerevini and Lenhart K. Schubert, </author> <title> "Efficient temporal reasoning through timegraphs," </title> <editor> in Ruzena Bajcsy, editor, </editor> <booktitle> Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <address> Chambery, France, </address> <month> 28 August-3 September </month> <year> 1993. </year> <month> 50 </month>
Reference-contexts: Our empirical studies show that this is a substantial win with large datasets of train schedule information. More information on the algorithm can be found in <ref> [Gerevini and Schubert, 1993] </ref>. Extensions to deal with temporal disjointness, such as those needed to express non-overlap between actions are reported in [Gerevini and Schubert, 1994]. 7.3 Speech Repairs As mentioned earlier, one of the immediate problems facing a spoken dialogue system is handling speech repairs.
Reference: [Gerevini and Schubert, 1994] <author> Alfonso Gerevini and Lenhart K. Schubert, </author> <title> "An efficient method for managing disjunctions in qualitative temporal reasoning," </title> <booktitle> in Proceedings of the Fourth International Conference on Principles of Knowledge Representation and Reasoning (KR94), </booktitle> <pages> pages 214-225, </pages> <address> Bonn, Germany, 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Our empirical studies show that this is a substantial win with large datasets of train schedule information. More information on the algorithm can be found in [Gerevini and Schubert, 1993]. Extensions to deal with temporal disjointness, such as those needed to express non-overlap between actions are reported in <ref> [Gerevini and Schubert, 1994] </ref>. 7.3 Speech Repairs As mentioned earlier, one of the immediate problems facing a spoken dialogue system is handling speech repairs.
Reference: [Gross et al., 1993] <author> Derek Gross, James F. Allen, and David R. Traum, </author> <title> "The TRAINS-91 dialogues," </title> <type> TRAINS Technical Note 92-1, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Clearly, the more complex the problem, the longer the dialogue required to solve it. Figure 2 contains an excerpt from one of the dialogues in the Trains-91 corpus <ref> [Gross et al., 1993] </ref>. The utterance number indicates the turn and the utterance in the turn. Thus 1.1 is the first utterance of the first turn, 1.2 is the second utterance of the first turn, and so on.
Reference: [Heeman and Allen, 1994] <author> Peter Heeman and James F. Allen, </author> <title> "Detecting and Correcting Speech Repairs," </title> <booktitle> in Proceedings of the Thirty-Second Annual Meeting of the Association for Computational Linguistics (ACL94), </booktitle> <pages> pages 295-302, </pages> <address> Las Cruces, NM, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: was : : : and pick up um the en- I guess the entire um p- pick up the load of oranges at Corning and the corrected output was : : : and pick up the load of oranges at Corning More details on this work can be found in <ref> [Heeman and Allen, 1994] </ref>. 8 Discussion It has been a large effort over several years to build the Trains systems. Was it worth it? As far as the goal of providing a research platform for research is concerned, it has been well worth the effort.
Reference: [Hinkleman and Allen, 1989] <author> Elizabeth Hinkleman and James F. Allen, </author> <title> "Two constraints on speech act ambiguity," </title> <booktitle> in Proceedings of the Twenty-Seventh Annual Meeting of the Association for Computational Linguistics (ACL89), </booktitle> <pages> pages 212-219, </pages> <year> 1989. </year>
Reference: [Hwang and Schubert, 1992] <author> Chung Hee Hwang and Lenhart K. Schubert, </author> <title> "Tense trees as the "fine structure" of discourse," </title> <booktitle> in Proceedings of the Thirtieth Annual Meeting of the Association for Computational Linguistics (ACL92), </booktitle> <pages> pages 232-240, </pages> <year> 1992. </year>
Reference-contexts: We have developed tense trees, part of the context structure, and a set of deindexing rules <ref> [Hwang and Schubert, 1992] </ref>, that transform the indexical logical form into a context-independent LF, simultaneously updating the tense tree component of the context structure. Tense trees allow us to automatically identify orienting episodes (as indicated by the orients relations in the above formula).
Reference: [Hwang and Schubert, 1993a] <author> Chung Hee Hwang and Lenhart K. Schubert, </author> <title> "Episodic Logic: A situational logic for natural language processing," </title> <editor> in P. Aczel, D. Israel, Y. Katagiri, and S. Peters, editors, </editor> <booktitle> Situation Theory and its Applications, </booktitle> <volume> volume 3, </volume> <pages> pages 303-338. </pages> <publisher> CSLI, Stanford, </publisher> <address> CA, </address> <year> 1993. </year>
Reference-contexts: With the architecture defined, the next two sections consider the major knowledge representation formalisms used in the system. 5.2 Episodic Logic Episodic Logic was developed for use as a semantic theory for natural language understanding <ref> [Hwang and Schubert, 1993a; Hwang and Schubert, 1993b] </ref>. It was designed to meet the following requirements: * expressive adequacy: the language should be powerful enough to allow us to represent various kinds of constructs found in English, as well as the nuances in naturally occurring sentences.
Reference: [Hwang and Schubert, 1993b] <author> Chung Hee Hwang and Lenhart K. Schubert, </author> <title> "Meeting the interlocking needs of LF-computation, deindexing and inference: An organic approach to natural language understanding," </title> <editor> in Ruzena Bajcsy, editor, </editor> <booktitle> Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pages 1297-1302, </pages> <address> Chambery, France, </address> <month> 28 August-3 September </month> <year> 1993. </year>
Reference-contexts: With the architecture defined, the next two sections consider the major knowledge representation formalisms used in the system. 5.2 Episodic Logic Episodic Logic was developed for use as a semantic theory for natural language understanding <ref> [Hwang and Schubert, 1993a; Hwang and Schubert, 1993b] </ref>. It was designed to meet the following requirements: * expressive adequacy: the language should be powerful enough to allow us to represent various kinds of constructs found in English, as well as the nuances in naturally occurring sentences.
Reference: [Kamp, 1981] <author> Hans Kamp, </author> <title> "A theory of truth and semantic representation," </title> <editor> in J. Groe-nendijk, T. Janssen, and M. Stokhof, editors, </editor> <title> Formal Methods in the Study of Language. </title> <publisher> Amsterdam Press, </publisher> <address> Amsterdam, </address> <year> 1981. </year>
Reference-contexts: Poesio [1994] discusses a model-theoretic semantics for unscoped forms, where an unscoped formula denotes a set of fully-scoped propositions, one for each possible interpretation. The theory of discourse interpretation on which the deindexing module is based is Conversation Representation Theory (CRT), an extension of Discourse Representation Theory 32 (DRT) <ref> [Kamp, 1981] </ref>. CRT is designed to deal with semantic ambiguity and to allow the representation of pragmatic information present in conversations, such as the presence of multiple discourse topics and the organization of utterances in discourse segments.
Reference: [Kautz and Ladkin, 1991] <author> Henry A. Kautz and Peter B. Ladkin, </author> <title> "Integrating metric and qualitative temporal reasoning," </title> <booktitle> in Proceedings of the Ninth National Conference on Artificial Intelligence (AAAI-91), </booktitle> <pages> pages 241-246, </pages> <address> Anaheim, CA, 12-19 July 1991. </address> <publisher> MIT Press. </publisher>
Reference-contexts: We evaluated existing systems for temporal reasoning to see how well they scale up. The results were disappointing. Interval reasoning systems like our own TIMELOGIC [Koomen, 1989], which the current system uses, and MATS <ref> [Kautz and Ladkin, 1991] </ref>, suffer from serious efficiency problems once they have to handle about 500 intervals, and become unusable before hitting 1000. Systems using constraint-satisfaction techniques for point-based reasoning fare better, but show degradation as the number of times enters into the thousands (see [Yampratoom and Allen, 1993]).
Reference: [Koomen, 1989] <author> Johannes A.G.M. Koomen, </author> <title> "Localizing temporal constraint propagation," </title> <editor> in R.J. Brachman, H.J. Levesque, and R. Reiter, editors, </editor> <booktitle> Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning (KR-89), </booktitle> <pages> pages 198-202, </pages> <address> Toronto, Ont., 15-18 May 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We evaluated existing systems for temporal reasoning to see how well they scale up. The results were disappointing. Interval reasoning systems like our own TIMELOGIC <ref> [Koomen, 1989] </ref>, which the current system uses, and MATS [Kautz and Ladkin, 1991], suffer from serious efficiency problems once they have to handle about 500 intervals, and become unusable before hitting 1000.
Reference: [Light, 1993] <author> Marc Light, </author> <title> "A computational theory of lexical relatedness," </title> <type> Technical Report 421, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <year> 1993. </year>
Reference-contexts: This will be very time consuming, but there does not seem to be a way to automatically derive this sort of rich semantic information about word meanings in any other way. More details on this approach can be found in <ref> [Light, 1993] </ref>. While all the inflectional forms of words used in the demonstration dialogues were hand-coded in the lexicon, words outside this core set are processed using the Alvey morphological analyzer [Ritchie et al., 1992], which itself uses a Kimmo-based segmenter and a unification-based chart parser.
Reference: [Litman and Allen, 1987] <author> Diane Litman and James F. Allen, </author> <title> "A plan recognition model for subdialogues in conversation," </title> <journal> Cognitive Science, </journal> <volume> 11 </volume> <pages> 163-200, </pages> <year> 1987. </year>
Reference: [Magerman and Weir, 1992] <author> D. Magerman and C. Weir, </author> <title> "Efficiency, robustness and accuracy in picky chart parsing," </title> <booktitle> in Proceedings of the Thirtieth Annual Meeting of the Association for Computational Linguistics (ACL92), </booktitle> <pages> pages 40-47, </pages> <year> 1992. </year>
Reference: [Martin, 1993] <author> Nathaniel G. Martin, </author> <title> Using Statistical Inference to Plan Under Uncertainty, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <year> 1993. </year> <note> To appear as a Technical Report. </note>
Reference-contexts: In any situation, the planner chooses the messages that maximize the expected probability of success. Details on the actual formalism can be found in <ref> [Martin, 1993] </ref>. 44 7 Other Issues This section describes some additional issues of importance to the Trains project, but which are not part of the actual system.
Reference: [Martin et al., 1990] <author> Nathaniel G. Martin, James F. Allen, and Christopher M. Brown, "ARMTRAK: </author> <title> A domain for the unified study of natural language, planning, and active vision," </title> <type> Technical Report 324, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <month> January </month> <year> 1990. </year>
Reference-contexts: The second task we explored was a robotics-control application, where a person communicated with the system to monitor and control a model train layout <ref> [Martin et al., 1990] </ref>. This task supported interesting problem solving behaviors, but did not support a wide range of dialogue behavior. In particular, the tendency was for the person to issue a series of commands to the system.
Reference: [Nakatani and Hirschberg, 1993] <author> C. Nakatani and J. Hirschberg, </author> <title> "A speech-first model for repair detection and correction," </title> <booktitle> in Proceedings of the Thirty-First Annual Meeting of the Association for Computational Linguistics (ACL93), </booktitle> <year> 1993. </year>
Reference-contexts: Of course, there are also prosodic signals of repairs (e.g., see <ref> [Nakatani and Hirschberg, 1993] </ref>), but it is not yet possible to extract such information reliably from the speech signal. So 46 we worked solely from the information that is present in the transcripts.
Reference: [Poesio, 1994] <author> Massimo Poesio, </author> <title> Discourse Interpretation and the Scope of Operators, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <month> June </month> <year> 1994. </year> <note> Available as Technical Report 518. </note>
Reference: [Pollard and Sag, 1994] <author> C. Pollard and I. Sag, </author> <title> Head-Driven Phrase Structure Grammar, </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, IL, </address> <year> 1994. </year>
Reference-contexts: The feature-tree approach leads to a quite compact syntax for grammatical rules. rules (with slight modifications for readability). Subcategorization restrictions are handled 4 See [Allen, 1994] for an introduction to chart parsing and rule-by-rule interpretation. 5 There is some similarity to the grammatical sort hierarchy in HPSG <ref> [Pollard and Sag, 1994] </ref>, though HPSG does not subdivide atomic features values. 25 S-tell ;; e.g., [we have to make OJ] [.] :SYNRULE (S tell) &lt;-- (S decl) (PUNC tell) :SEMRULE (Decl 1) S_n2+v2 ;; e.g., [we][have to make OJ] :SYNRULE (S decl) &lt;-- (NP nom) (VP) :SEMRULE [1 2] V2_V+V2inf
Reference: [Ritchie et al., 1992] <author> G. D. Ritchie, G. Russell, A. Black, and S. Pulman, </author> <title> Computaitonal Morphology, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: In the Trains dialogues, for instance, the following words occur that are not present in the 60,000 word 28 Alvey lexicon <ref> [Ritchie et al., 1992] </ref>: simultaneously, unhitch, unsolvable, independently, ap-proximately, solvable, decouple, and concurrently. The Trains lexical analyzer can produce meaning postulates for classes of words like these that involve derivational affixes. 6 We use knowledge of the meaning of derivational affixes to hypothesize semantic interpretations of previously unknown words. <p> More details on this approach can be found in [Light, 1993]. While all the inflectional forms of words used in the demonstration dialogues were hand-coded in the lexicon, words outside this core set are processed using the Alvey morphological analyzer <ref> [Ritchie et al., 1992] </ref>, which itself uses a Kimmo-based segmenter and a unification-based chart parser. Inflectional affixes are treated compositionally where each inflectional process introduces an operator that transforms the meaning of the stem into the meaning of the inflected form.
Reference: [Schaeffer et al., 1993] <author> Stephanie A. Schaeffer, Chung Hee Hwang, J. de Hann, and Lenhart K. Schubert, "EPILOG: </author> <title> The computational system for Episodic Logic (User's Guide)," </title> <type> Technical report, </type> <institution> Department of Computational Science, University of Alberta, Edmonton, Alberta, </institution> <year> 1993. </year>
Reference-contexts: Episodic Logic readily lends itself to inference; contrary to a widespread myth a rich syntax is no impediment to effective inference. Though only a very limited set of EL inference capabilities has been used in Trains-93, EL has been separately implemented in the EPILOG system <ref> [Schaeffer et al., 1993] </ref>.
Reference: [Traum, 1994] <author> David R. Traum, </author> <title> A Computational Theory of Grounding in Natural Language Conversation, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <month> July </month> <year> 1994. </year> <note> To appear as a Technical Report. </note>
Reference-contexts: Grounding act analysis is based on comparing the current utterance to the discourse history to determine how the current utterance advances the state of mutual understanding. The current utterance might initiate new content, or continue, repair or acknowledge a previously initiated unit. The grounding theory is described in <ref> [Traum, 1994] </ref>. Turn-taking analysis is based on a determination of who is expected to speak next.
Reference: [Traum and Allen, 1994] <author> David R. Traum and James F. Allen, </author> <title> "Discourse Obligations in Dialogue Processing," </title> <booktitle> in Proceedings of the Thirty-Second Annual Meeting of the Association for Computational Linguistics (ACL94), </booktitle> <pages> pages 1-8, </pages> <year> 1994. </year>
Reference-contexts: This results in forming an intention to inform, which is then realized (along with the acknowledgment of the utterances) by the production of utterance 4.1. More detail on the dialogue manager is available in <ref> [Traum and Allen, 1994] </ref>. 6.7 The Domain Plan Reasoner The domain plan reasoner allows the system to reason about the Trains domain. To support language understanding, it provides an algorithm (incorporation) that attempts to find causal and motivational connections between potential interpretations of the current utterance and the current plan.
Reference: [Traum and Hinkelman, 1992] <author> David R. Traum and Elizabeth A. Hinkelman, </author> <title> "Conversation Acts in Task-oriented Spoken Dialogue," </title> <journal> Computational Intelligence, </journal> <volume> 8(3) </volume> <pages> 575-599, </pages> <year> 1992. </year> <note> Also available as University of Rochester TR 425. </note>
Reference-contexts: Besides expanding the basic linguistic capabilities, the Trains-93 system achieved a closer integration of the techniques for reference resolution, scoping and speech act interpretation. In addition, it also contained an implementation of a rich set of conversation acts <ref> [Traum and Hinkelman, 1992] </ref> 15 and the domain plan representation and reasoning component was significantly extended. 5 The TRAINS System Infrastructure Before looking at each component of the Trains-93 system, there are several general issues that must be discussed. These concern the overall system architecture and the knowledge representations used. <p> In such cases, the deindexing module may delay the identification of the referent and leave it for the domain reasoner to determine during plan recognition. 6.5 Conversation Act Analysis Conversational action is represented using the theory of Conversation Acts <ref> [Traum and Hinkelman, 1992] </ref> which involves interactions at four different levels: * turn-taking: acts that maintain, release, or take the turn in the dialogue; * grounding: acts that deal with establishing shared knowledge about the dialogue, e.g., acknowledgments and repairs (as in [Clark and Schaefer, 1989]); * core speech acts: the
Reference: [Yampratoom and Allen, 1993] <author> Ed Yampratoom and James F. Allen, </author> <title> "Performance of temporal reasoning systems," </title> <journal> SIGART Bulletin, </journal> <volume> 4(3), </volume> <year> 1993. </year> <note> Also available as TRAINS Technical Note 93-1. 52 </note>
Reference-contexts: Systems using constraint-satisfaction techniques for point-based reasoning fare better, but show degradation as the number of times enters into the thousands (see <ref> [Yampratoom and Allen, 1993] </ref>). The goal of the TIMEGRAPH-II system was to provide a temporal reasoning system that operated in close to linear time as the datasets grew. As with all reasoning systems, there is an assert time/retrieval time tradeoff in comparing algorithms.
References-found: 38

