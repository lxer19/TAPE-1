URL: http://www.math.rutgers.edu/~sontag/FTP_DIR/ibc-general.ps.gz
Refering-URL: http://www.math.rutgers.edu/~sontag/papers.html
Root-URL: 
Title: Worst-Case Identification of Nonlinear Fading Memory Systems  
Author: Munther A. Dahleh David N.C. Tse Eduardo D. Sontag John N. Tsitsiklis 
Note: This version was never published; the published version (in Automatica, 31, no. 3, March 1995) was very summarized. Research Supported by AFOSR under grant AFOSR-91-0368 and by NSF under grant 9157306-ECS Research supported by an NSERC fellowship from the government of Canada, and by the NSF under Grant ECS-8552419 Research Supported by AFOSR under grant AFOSR-91-0346 Research supported by the NSF under Grant ECS-8552419 and by AFOSR under grant AFOSR-91-0368  
Address: Cambridge, MA 02139  Cambridge, MA 02139  New Brunswick, NJ 08903  Cambridge, MA 02139  
Affiliation: Lab. for Information Decision Systems M.I.T.  Lab. for Information Decision Systems M.I.T.  Dept. of Mathematics, SYCON Rutgers University  Lab. for Information Decision Systems M.I.T.  
Abstract: In this paper, the problem of asymptotic identification for a class of fading memory systems in the presence of bounded noise is studied. For any experiment, the worst-case error is characterized in terms of the diameter of the worst-case uncertainty set. Optimal inputs that minimize the radius of uncertainty are studied and characterized. Finally, a convergent algorithm that does not require knowledge of the noise upper bound is furnished. The algorithm is based on interpolating data with spline functions, which are shown to be well suited for identification in the presence of bounded noise; more so than other basis functions such as polynomials. The methods as well as the results are quite general and are applicable to a larger variety of settings. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Blumer, A. Ehrenfeucht. D. Haussler, M. Warmuth, </author> <note> "Occam's Razor," Information Processing Letters 24, pp.377-380, </note> <year> 1987. </year>
Reference-contexts: The result here is more general and the proof is more elegant. Proposition 3.1 If M is -compact, then D=2 E cau D. Proof. The proof is based on the "Occam's Razor" principle <ref> [1] </ref>: use the simplest explanation consistent with the data. Let M = i=1 M i , with each M i compact. Without loss of generality assume M 1 M 2 : : :. <p> Definition 4.1 An operator h has fading memory (FM) if for each " &gt; 0 there is some T = T (") such that: for every k, every t T and every finite sequences v 2 <ref> [1; 1] </ref> k , w 2 [1; 1] t , jh t+k (vw) h t (w)j &lt; " It can easily be seen that a fading memory system satisfying the above property 1 necessarily must have bounded operator-induced norm. <p> Definition 4.1 An operator h has fading memory (FM) if for each " &gt; 0 there is some T = T (") such that: for every k, every t T and every finite sequences v 2 <ref> [1; 1] </ref> k , w 2 [1; 1] t , jh t+k (vw) h t (w)j &lt; " It can easily be seen that a fading memory system satisfying the above property 1 necessarily must have bounded operator-induced norm. <p> Proof. Define the class of pth-order memory systems, M p , to be the set of all f such that for every k and for every t &gt; p and every finite sequences v 2 <ref> [1; 1] </ref> k ,w 2 [1; 1] t , f t+k (vw) = f t (w). It is clear that any fading memory system can be approximated (in the operator-induced norm) arbitrarily closely by a pth-order memory system for sufficiently large p. <p> Proof. Define the class of pth-order memory systems, M p , to be the set of all f such that for every k and for every t &gt; p and every finite sequences v 2 <ref> [1; 1] </ref> k ,w 2 [1; 1] t , f t+k (vw) = f t (w). It is clear that any fading memory system can be approximated (in the operator-induced norm) arbitrarily closely by a pth-order memory system for sufficiently large p. Hence it suffices to prove that M p is separable for all p. <p> Hence it suffices to prove that M p is separable for all p. Now given any f 2 M p we can find some continuous function g : <ref> [1; 1] </ref> p ! &lt; such that for all time n, and all input u, f n (u) = g (u np ; : : : ; u n1 ) We call g the memory function for f . <p> Hence we have that kf k = kgk 1 , where the infinity norm is taken over <ref> [1; 1] </ref> p . But the space of continuous functions with the uniform topology induced by the ` 1 -norm, denoted by C ([1; 1] p ), is separable, and hence so is M p . <p> In the next theorem, it is shown that such an input will also exist when the model set consists of nonlinear fading memory systems. Proposition 5.4 Let the model set M be some subset of the set of fading memory systems. Let W be any countable dense subset of <ref> [1; 1] </ref> and consider any input ! 0 2 [1; 1] 1 which contains all possible finite sequences of elements of W . Then, V = f! 0 g is PE. Proof. Assume that h 2 M; khk = K &lt; 1. Pick any " &gt; 0. <p> Proposition 5.4 Let the model set M be some subset of the set of fading memory systems. Let W be any countable dense subset of <ref> [1; 1] </ref> and consider any input ! 0 2 [1; 1] 1 which contains all possible finite sequences of elements of W . Then, V = f! 0 g is PE. Proof. Assume that h 2 M; khk = K &lt; 1. Pick any " &gt; 0. Let T = T (") as in the definition of FM. <p> This is a generalization of the univariate linear spline, but because in higher dimension there is no natural ordering of the data points, the description of the interpolant is more complicated. Consider the cube I = <ref> [1; 1] </ref> p &lt; p . Let x 1 ; x 2 ; : : : ; x m ; m &gt; p be m points in the interior of the cube. <p> Given these simplices, we can now define our interpolating linear spline f as follows. First define f (x i ) = y i at the given data points. For other x 2 <ref> [1; 1] </ref> p , if x 2 S j for some j, let f (x) i ff i f (u i ), where u i 's are the vertices of S j and x = P i ff i u i . <p> when the algorithm is collecting data to compute an estimate in M p .) Consider all the blocks (u np+1 ; : : : ; u n1 ; u n ); 8n = n (p 1); : : :; n (p) in the input as data points in the cube <ref> [1; 1] </ref> p . We maintain a simplex structure in [1; 1] p with these data points as vertex set, and the structure is incrementally modified more or less according to the procedure discussed earlier, with a slight twist. <p> in M p .) Consider all the blocks (u np+1 ; : : : ; u n1 ; u n ); 8n = n (p 1); : : :; n (p) in the input as data points in the cube <ref> [1; 1] </ref> p . We maintain a simplex structure in [1; 1] p with these data points as vertex set, and the structure is incrementally modified more or less according to the procedure discussed earlier, with a slight twist. <p> Let C n = [ j S j be the union of the simplices at time n, and d n be the distance between C n and the corner of <ref> [1; 1] </ref> p farthest away from C n . At time n + 1, one more data point is obtained. If d n &lt; ffi p and the new data point lies outside C n , then discard the new point. Otherwise update the simplex structure as described earlier. <p> We now claim that n (p) &lt; 1 for every p. First we see that because the input is persistently exciting, the p-blocks in u are dense in <ref> [1; 1] </ref> p (Otherwise, there is a ball in [1; 1] p which does not contain any blocks in u, and we can construct a p-step finite memory system with a continuous memory function f : &lt; p ! &lt; to be positive at the centre of the ball and zero <p> We now claim that n (p) &lt; 1 for every p. First we see that because the input is persistently exciting, the p-blocks in u are dense in <ref> [1; 1] </ref> p (Otherwise, there is a ball in [1; 1] p which does not contain any blocks in u, and we can construct a p-step finite memory system with a continuous memory function f : &lt; p ! &lt; to be positive at the centre of the ball and zero outside. <p> For p q, n (p) (h (u)+d) is the spline interpolant that approximates the unknown memory function, and y = h (u) + d is the output. We can also extend g * to a function on <ref> [1; 1] </ref> p which depends only on the last q coordinates. <p> We now show that the first term can be made arbitrarily small for large p. Since g * is continuous, g * is a uniformly continuous function on <ref> [1; 1] </ref> q . Choose * 1 such that kx 1 x 2 k 2 * 1 ) kg * (x 1 ) g * (x 2 )k 2 * : (13) Now pick p sufficiently large such that ffi p &lt; * 1 and p &gt; q. <p> Lipschitz condition on the order p memory function g, such as jg (x) g (y)j &lt; M kx yk, then to identify the function up to accuracy * (in the k k 1 norm), the number of data points needed is at least the minimum number of *-balls to cover <ref> [1; 1] </ref> p . Since the volume of an *-ball is O (* p ), it is clear that this minimum number is (( 1 * ) p ), and hence so is the experiment length.
Reference: [2] <author> S. Boyd and L.O. Chua, </author> <title> "Fading Memory and the problem of approximating nonlinear operators with Volterra series," </title> <journal> IEEE Transactions on Circuits and Systems, </journal> <volume> Vol. CAS-32, </volume> <year> 1985, </year> <pages> pp. 1150-1161. </pages>
Reference-contexts: For further details on fading memory operators, see <ref> [2, 30] </ref>. 4.3 Examples of FM Systems Example 1: stable LTI systems. For each h 2 ` 1 consider the input/output map u 7! u fl h. It is clear that these systems satisfy the above conditions. The operator-induced norm in this case is just the ` 1 norm.
Reference: [3] <author> M.A. Dahleh and M.H. Khammash, </author> <title> "Controller Design in the Presence of Structured Uncertainty," </title> <note> to appear in Automatica special issue on robust control. </note>
Reference-contexts: 1 Introduction Recently, there has been an increasing interest among the control community in the problem of identifying plants for control purposes. This generally means that the identified model should approximate the plant in the operator topology, since this allows the immediate use of robust control tools for designing controllers <ref> [3, 5] </ref>. This problem is of special importance when the data are corrupted with bounded noise. The case where the objective is to optimize prediction for a fixed input was analyzed by many researchers in [6, 18, 21, 22, 23, 27, 29].
Reference: [4] <author> M.A. Dahleh, T. Theodosopoulos, and J.N. Tsitsiklis, </author> <title> "The sample complexity of worst-case identification of F.I.R. Linear systems," </title> <note> to appear in Systems and Control Letters. </note>
Reference-contexts: Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in <ref> [8, 17, 24, 25, 15, 28, 4, 14] </ref>. In this paper, the work of Tse et al [35, 36, 38] is extended to general settings, which allows for immediate analysis of larger classes of systems, namely, nonlinear fading memory systems. The study is done in two steps. <p> For nonlinear systems the time complexity is exponential of the order, whether or not there is noise. For the linear case, while it takes only linear time to identify a FIR system exactly when there is no noise, it has been shown <ref> [4, 28] </ref> that the time complexity immediately becomes exponential once we introduce any worst-case noise. Moreover, it has been demonstrated that if we are willing to put a probability distribution on the noise, polynomial time complexity can often be obtained [37].
Reference: [5] <author> J. C. Doyle, </author> <title> "Analysis of feedback systems with structured uncertainty," </title> <booktitle> IEEE Proceedings 129, </booktitle> <address> 242-250,1982. </address>
Reference-contexts: 1 Introduction Recently, there has been an increasing interest among the control community in the problem of identifying plants for control purposes. This generally means that the identified model should approximate the plant in the operator topology, since this allows the immediate use of robust control tools for designing controllers <ref> [3, 5] </ref>. This problem is of special importance when the data are corrupted with bounded noise. The case where the objective is to optimize prediction for a fixed input was analyzed by many researchers in [6, 18, 21, 22, 23, 27, 29].
Reference: [6] <author> E. Fogel and Y. F. Huang, </author> " <title> On the value of information in system identification-bounded noise case", </title> <journal> Automatica, vol.18, no.2, </journal> <volume> pp.229-238, </volume> <year> 1982. </year>
Reference-contexts: This problem is of special importance when the data are corrupted with bounded noise. The case where the objective is to optimize prediction for a fixed input was analyzed by many researchers in <ref> [6, 18, 21, 22, 23, 27, 29] </ref>. The problem is more interesting when the objective is to approximate the original system as an operator, a problem extensively discussed in [39], especially when the plant's order is not known a priori.
Reference: [7] <author> G.C. Goodwin, </author> <title> "Experiment design in system identification" in Encyclopedia of Systems and Control (M. </title> <editor> Singh, Ed.), </editor> <publisher> Pergamon Press, </publisher> <year> 1987. </year> <month> 16 </month>
Reference-contexts: When the topology is induced by the ` 1 norm, a complete study of asymptotic identification was furnished in [35, 36, 38] for arbitrary inputs, and the question of optimal input design was addressed. Input design has been addressed in stochastic settings (e.g. <ref> [7, 20, 40] </ref> ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in [8, 17, 24, 25, 15, 28, 4, 14].
Reference: [8] <author> G.C. Goodwin, M. Gevers and B. Ninness, </author> <title> "Quantifying the error in estimated transfer func-tions with application to model order selection," </title> <journal> IEEE Trans. A-C, </journal> <volume> Vol 37, No. 7, </volume> <month> July </month> <year> 1992, </year> <pages> pp 913-928. </pages>
Reference-contexts: Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in <ref> [8, 17, 24, 25, 15, 28, 4, 14] </ref>. In this paper, the work of Tse et al [35, 36, 38] is extended to general settings, which allows for immediate analysis of larger classes of systems, namely, nonlinear fading memory systems. The study is done in two steps.
Reference: [9] <author> G. Gu, P.P. Khargonekar and Y. Li, </author> <title> "Robust convergence of two stage nonlinear algorithms for identification in H 1 , Systems and Control Letters, </title> <booktitle> Vol 18, </booktitle> <volume> No. 4, </volume> <month> April </month> <year> 1992. </year>
Reference: [10] <author> G. Gu and P.P. Khargonekar, </author> " <title> Linear and nonlinear algorithms for identification in H 1 with error bounds, </title> <journal> IEEE Trans. A-C, </journal> <volume> Vol 37, No. 7, </volume> <month> July </month> <year> 1992, </year> <pages> pp 953-963. </pages>
Reference: [11] <author> A.J. Helmicki, C.A. Jacobson and C.N. Nett, </author> <title> "Identification in H 1 : A robust convergent nonlinear algorithm", </title> <booktitle> Proceedings of the 1989 International Symposium on the Mathematical Theory of Networks and System, </booktitle> <year> 1989. </year>
Reference-contexts: It is noted that for the results on arbitrary inputs, the suggested algorithms require the knowledge of the bound on the noise. Such algoritms are called tuned algorithms (see <ref> [11] </ref>). If however, the near optimal input is used, then an untuned algorithm can be provided that results in a worst-case error equal to the noise bound, ffi. Such an algorithm is based on interpolating data by spline functions of several variables. The contribution of this paper is two fold. <p> This property of linear splines, which is not shared by methods such as global polynomial interpolation, turns out to be the key to guarantee the consistency of the estimates. A similar situation is encountered in linear system identification from frequency response data <ref> [11] </ref>, where 1 dimensional splines are used instead of polynomials to interpolate the noisy data to guarantee robustness of the identification procedure. 6.2 Consistency With the above basic discussions on multivariate linear splines, we may now state the main result of this section.
Reference: [12] <author> A.J. Helmicki, C.A. Jacobson and C.N. Nett, </author> <title> "Identification in H 1 : Linear Algorithms", </title> <booktitle> Proceedings of the 1990 American Control Conference, </booktitle> <pages> pp 2418-2423. </pages>
Reference: [13] <author> A.J. Helmicki, C.A. Jacobson and C.N. Nett, </author> <title> "Control-oriented System Identification: A Worst-case/deterministic Approach in H 1 '," IEEE Trans. </title> <journal> A-C, </journal> <volume> Vol 36, No. 10, </volume> <month> October </month> <year> 1991, </year> <pages> pp 1163-1176. </pages>
Reference: [14] <author> C.A. Jacobson and C.N. Nett, </author> <title> "Worst-case system identification in ` 1 : Optimal algorithms and error bounds," </title> <booktitle> in Proc. of the 1991 American Control Conference, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in <ref> [8, 17, 24, 25, 15, 28, 4, 14] </ref>. In this paper, the work of Tse et al [35, 36, 38] is extended to general settings, which allows for immediate analysis of larger classes of systems, namely, nonlinear fading memory systems. The study is done in two steps.
Reference: [15] <author> B. Kacewicz and M. Milanese, </author> <title> "On the Optimal Experiment Design in the Worst-Case ` 1 System Identification, </title> <note> submitted to CDC. </note>
Reference-contexts: Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in <ref> [8, 17, 24, 25, 15, 28, 4, 14] </ref>. In this paper, the work of Tse et al [35, 36, 38] is extended to general settings, which allows for immediate analysis of larger classes of systems, namely, nonlinear fading memory systems. The study is done in two steps.
Reference: [16] <author> J.M. Krause, G. Stein, </author> <title> P.P. Khargonekar, "Robust Performance of Adaptive Controllers with General Uncertainty Structure", </title> <booktitle> Proceedings of the 29th Conference on Decision and Control, </booktitle> <pages> pp. 3168-3175, </pages> <year> 1990. </year>
Reference: [17] <author> L. Lin, L. Wang and G. Zames, </author> <title> "Uncertainty principle and identification n-Widths for LTI and slowly varying systems, </title> " <booktitle> ACC, </booktitle> <address> Chicago, IL, </address> <year> 1992. </year>
Reference-contexts: Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in <ref> [8, 17, 24, 25, 15, 28, 4, 14] </ref>. In this paper, the work of Tse et al [35, 36, 38] is extended to general settings, which allows for immediate analysis of larger classes of systems, namely, nonlinear fading memory systems. The study is done in two steps.
Reference: [18] <author> R. Lozano-Leal and R. Ortega, </author> <title> "Reformulation of the parameter identification problem for systems with bounded disturbances", </title> <journal> Automatica, vol.23, no.2, </journal> <volume> pp.247-251, </volume> <year> 1987. </year>
Reference-contexts: This problem is of special importance when the data are corrupted with bounded noise. The case where the objective is to optimize prediction for a fixed input was analyzed by many researchers in <ref> [6, 18, 21, 22, 23, 27, 29] </ref>. The problem is more interesting when the objective is to approximate the original system as an operator, a problem extensively discussed in [39], especially when the plant's order is not known a priori.
Reference: [19] <editor> M.K. Lau, R.L. Kosut, S. Boyd, </editor> <title> "Parameter Set Estimation of Systems with Uncertain Non-parametric Dynamics and Disturbances", </title> <booktitle> Proceedings of the 29th Conference on Decision and Control, </booktitle> <pages> pp. 3162-3167, </pages> <year> 1990. </year>
Reference: [20] <author> R.K. Mehra, </author> <title> "Optimal input signals for parameter estimation in dynamic systems-A survey and new results", </title> <journal> em IEEE Trans. Automatic Control, </journal> <volume> vol AC-19, pp.753-768, </volume> <year> 1974. </year>
Reference-contexts: When the topology is induced by the ` 1 norm, a complete study of asymptotic identification was furnished in [35, 36, 38] for arbitrary inputs, and the question of optimal input design was addressed. Input design has been addressed in stochastic settings (e.g. <ref> [7, 20, 40] </ref> ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in [8, 17, 24, 25, 15, 28, 4, 14].
Reference: [21] <author> M. Milanese and G. Belforte, </author> <title> "Estimation theory and uncertainty intervals evaluation in the presence of unknown but bounded errors: Linear families of models and estimators", </title> <journal> IEEE Trans. Automatic Control, AC-27, </journal> <volume> pp.408-414, </volume> <year> 1982. </year>
Reference-contexts: This problem is of special importance when the data are corrupted with bounded noise. The case where the objective is to optimize prediction for a fixed input was analyzed by many researchers in <ref> [6, 18, 21, 22, 23, 27, 29] </ref>. The problem is more interesting when the objective is to approximate the original system as an operator, a problem extensively discussed in [39], especially when the plant's order is not known a priori.
Reference: [22] <author> M. Milanese and R. Tempo, </author> <title> "Optimal algorithm theory for robust estimation and prediction", </title> <journal> IEEE Trans. Automatic Control, </journal> <volume> AC-30, </volume> <pages> pp. 730-738, </pages> <year> 1985. </year>
Reference-contexts: This problem is of special importance when the data are corrupted with bounded noise. The case where the objective is to optimize prediction for a fixed input was analyzed by many researchers in <ref> [6, 18, 21, 22, 23, 27, 29] </ref>. The problem is more interesting when the objective is to approximate the original system as an operator, a problem extensively discussed in [39], especially when the plant's order is not known a priori.
Reference: [23] <author> M. Milanese, </author> <title> "Estimation theory and prediction in the presence of unknown and bounded uncertainty: a survey", in Robustness in Identification and Control, </title> <editor> M. Milanese, R. Tempo, A. Vicino Eds, </editor> <publisher> Plenum Press, </publisher> <year> 1989. </year> <month> 17 </month>
Reference-contexts: This problem is of special importance when the data are corrupted with bounded noise. The case where the objective is to optimize prediction for a fixed input was analyzed by many researchers in <ref> [6, 18, 21, 22, 23, 27, 29] </ref>. The problem is more interesting when the objective is to approximate the original system as an operator, a problem extensively discussed in [39], especially when the plant's order is not known a priori.
Reference: [24] <author> P.M. Makila, </author> <title> "Robust Identification and Galois Sequences", </title> <type> Technical Report 91-1, </type> <institution> Process Control Laboratory, Swedish University of Abo, </institution> <month> January, </month> <year> 1991. </year>
Reference-contexts: Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in <ref> [8, 17, 24, 25, 15, 28, 4, 14] </ref>. In this paper, the work of Tse et al [35, 36, 38] is extended to general settings, which allows for immediate analysis of larger classes of systems, namely, nonlinear fading memory systems. The study is done in two steps. <p> An estimator with this property is known as an untuned estimator. This is in fact a generalization of a result by Makila <ref> [24] </ref>, which was proved in the context of stable LTI systems. 6.1 Linear Splines We shall make use of multivariate piecewise linear spline functions to interpolate between the measured data to form an approximation to the unknown plant.
Reference: [25] <author> P.M. Makila and J.R. Partington, </author> <title> "Robust Approximation and Identification in H 1 ", Proc. </title> <booktitle> 1991 American Control Conference, </booktitle> <month> June, </month> <year> 1991. </year>
Reference-contexts: Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in <ref> [8, 17, 24, 25, 15, 28, 4, 14] </ref>. In this paper, the work of Tse et al [35, 36, 38] is extended to general settings, which allows for immediate analysis of larger classes of systems, namely, nonlinear fading memory systems. The study is done in two steps.
Reference: [26] <author> C.A. Michelli and T.J. Rivlin, </author> <title> "A survey of optimal recovery" in Optimal Estimation in Approximation Theory (C.A. </title> <editor> Michelli and T.J. Rivlin, Eds), Plenun, </editor> <address> New York, </address> <year> 1977. </year>
Reference-contexts: 1 ; b 2 ) : For an uncertainty structure, we then let R and D denote the infinite-horizon radius and diameter of uncertainty, i.e.: R := sup R (S 1 (y)) D := sup D (S 1 (y)) : It is a standard result from Information-Based Complexity (IBC) theory <ref> [26, 32, 33, 34] </ref> ([34], page 21) that: R D 2R : (4) Also from IBC, the optimal worst-case asymptotic error over all arbitrary estimators satisfies: D=2 E arb : (5) Next, it will be shown that under mild assumptions, E cau D.
Reference: [27] <author> J.P. Norton, </author> <title> "Identification and application of bounded-parameter models", </title> <journal> Automatica, vol.23, no.4, </journal> <volume> pp.497-507, </volume> <year> 1987. </year>
Reference-contexts: This problem is of special importance when the data are corrupted with bounded noise. The case where the objective is to optimize prediction for a fixed input was analyzed by many researchers in <ref> [6, 18, 21, 22, 23, 27, 29] </ref>. The problem is more interesting when the objective is to approximate the original system as an operator, a problem extensively discussed in [39], especially when the plant's order is not known a priori.
Reference: [28] <author> K. Poolla and A. Tikku, </author> <title> "On the time complexity of worst-case system identification," </title> <type> preprint, </type> <year> 1992. </year>
Reference-contexts: Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in <ref> [8, 17, 24, 25, 15, 28, 4, 14] </ref>. In this paper, the work of Tse et al [35, 36, 38] is extended to general settings, which allows for immediate analysis of larger classes of systems, namely, nonlinear fading memory systems. The study is done in two steps. <p> For nonlinear systems the time complexity is exponential of the order, whether or not there is noise. For the linear case, while it takes only linear time to identify a FIR system exactly when there is no noise, it has been shown <ref> [4, 28] </ref> that the time complexity immediately becomes exponential once we introduce any worst-case noise. Moreover, it has been demonstrated that if we are willing to put a probability distribution on the noise, polynomial time complexity can often be obtained [37].
Reference: [29] <author> L. Pronzato and E. Walter, </author> <title> "Experiment design in bounded-error context: Comparison with D-optimality", </title> <journal> Automatica, vol.25, no.3, </journal> <volume> pp.383-391, </volume> <year> 1989. </year>
Reference-contexts: This problem is of special importance when the data are corrupted with bounded noise. The case where the objective is to optimize prediction for a fixed input was analyzed by many researchers in <ref> [6, 18, 21, 22, 23, 27, 29] </ref>. The problem is more interesting when the objective is to approximate the original system as an operator, a problem extensively discussed in [39], especially when the plant's order is not known a priori.
Reference: [30] <author> J.S. Shamma and R. Zhao, </author> <title> "Fading memory feedback systems and robust stability," </title> <note> to appear in Automatica. </note>
Reference-contexts: For further details on fading memory operators, see <ref> [2, 30] </ref>. 4.3 Examples of FM Systems Example 1: stable LTI systems. For each h 2 ` 1 consider the input/output map u 7! u fl h. It is clear that these systems satisfy the above conditions. The operator-induced norm in this case is just the ` 1 norm.
Reference: [31] <author> Sontag, E.D., </author> <title> Mathematical Control Theory: Deterministic Finite Dimensional Systems, </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: Let L &lt; 1 be the observation space which contains the output sequences that can be observed in the experiments. We view our models as causal functions from U to &lt; 1 ; these are discrete-time i/o maps, in the sense for instance of <ref> [31] </ref>, possibly non-linear, which take as input a sequence in U to give an output sequence in &lt; 1 . The input and the output at time n will be denoted by u n and h n (u), respectively.
Reference: [32] <author> J.F. Traub and H. Wozniakowski, </author> <title> A General Theory of Optimal Algorithms, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: 1 ; b 2 ) : For an uncertainty structure, we then let R and D denote the infinite-horizon radius and diameter of uncertainty, i.e.: R := sup R (S 1 (y)) D := sup D (S 1 (y)) : It is a standard result from Information-Based Complexity (IBC) theory <ref> [26, 32, 33, 34] </ref> ([34], page 21) that: R D 2R : (4) Also from IBC, the optimal worst-case asymptotic error over all arbitrary estimators satisfies: D=2 E arb : (5) Next, it will be shown that under mild assumptions, E cau D. <p> Lemma 5.1 If 2ffi &lt; (M), then D (V; ffi) 2ffi. Proof. See [35] Recall that M is balanced if h 2 M implies h 2 M. For balanced and convex model sets, it is well known from IBC <ref> [32] </ref> that the worst case diameter is equal to the diameter of the uncertainty set when the output is identically equal to zero. The following lemma summarizes this. 10 Lemma 5.2 Assume that M is balanced and convex.
Reference: [33] <author> J.F. Traub, G. Wasilkowski and H. Wozniakowski, </author> <title> Information-Based Complexity, </title> <publisher> Academic Press, </publisher> <year> 1988. </year>
Reference-contexts: 1 ; b 2 ) : For an uncertainty structure, we then let R and D denote the infinite-horizon radius and diameter of uncertainty, i.e.: R := sup R (S 1 (y)) D := sup D (S 1 (y)) : It is a standard result from Information-Based Complexity (IBC) theory <ref> [26, 32, 33, 34] </ref> ([34], page 21) that: R D 2R : (4) Also from IBC, the optimal worst-case asymptotic error over all arbitrary estimators satisfies: D=2 E arb : (5) Next, it will be shown that under mild assumptions, E cau D.
Reference: [34] <author> J.F. Traub, G. W. Wasilkowski and H. Wozniakowski, </author> <title> "Information, Uncertainty, Complexity,", </title> <publisher> Addison-Wesley, </publisher> <year> 1983. </year>
Reference-contexts: 1 ; b 2 ) : For an uncertainty structure, we then let R and D denote the infinite-horizon radius and diameter of uncertainty, i.e.: R := sup R (S 1 (y)) D := sup D (S 1 (y)) : It is a standard result from Information-Based Complexity (IBC) theory <ref> [26, 32, 33, 34] </ref> ([34], page 21) that: R D 2R : (4) Also from IBC, the optimal worst-case asymptotic error over all arbitrary estimators satisfies: D=2 E arb : (5) Next, it will be shown that under mild assumptions, E cau D.
Reference: [35] <author> D. Tse, M.A. Dahleh and J.N. Tsitsiklis. </author> <title> Optimal Asymptotic Identification under bounded disturbances. </title> <note> Submitted to the IEEE Trans. Automat. Contr. </note>
Reference-contexts: When the topology is induced by the ` 1 norm, a complete study of asymptotic identification was furnished in <ref> [35, 36, 38] </ref> for arbitrary inputs, and the question of optimal input design was addressed. Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. <p> Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in [8, 17, 24, 25, 15, 28, 4, 14]. In this paper, the work of Tse et al <ref> [35, 36, 38] </ref> is extended to general settings, which allows for immediate analysis of larger classes of systems, namely, nonlinear fading memory systems. The study is done in two steps. <p> This, combined with Eqn (5), will give: D=2 E cau D : (6) It should be noted that the next result was proved in <ref> [35] </ref> for linear models and additive noise. The result here is more general and the proof is more elegant. Proposition 3.1 If M is -compact, then D=2 E cau D. Proof. The proof is based on the "Occam's Razor" principle [1]: use the simplest explanation consistent with the data. <p> As stated earlier, the convergence rate depends on the actual process h and possibly the noise. Uniform convergence can be obtained if the model set is compact. A proof of this result in the linear time invariant case is found in <ref> [35] </ref>. The result generalizes to general systems in the same way. 3.1 Separable Case In many common applications, the model set M is not -compact, however, it may be separable, i.e. it has a countable dense subset. <p> Let (M) := supfr j 0 &lt; ffi &lt; r ) 9 g; h 2 M with kg hk = rg : Note: if M is path connected, then (M) = D (M). Lemma 5.1 If 2ffi &lt; (M), then D (V; ffi) 2ffi. Proof. See <ref> [35] </ref> Recall that M is balanced if h 2 M implies h 2 M. For balanced and convex model sets, it is well known from IBC [32] that the worst case diameter is equal to the diameter of the uncertainty set when the output is identically equal to zero. <p> Thus, if the set of inputs used in the experiments is PE, then accurate identification can be achieved asymptotically. An interesting question arises: Does there exist a single input that is PE? In the stable linear shift invariant case, this was shown to be the case <ref> [35] </ref>. In the next theorem, it is shown that such an input will also exist when the model set consists of nonlinear fading memory systems. Proposition 5.4 Let the model set M be some subset of the set of fading memory systems.
Reference: [36] <author> D.N.C. Tse, M.A. Dahleh, J.N. Tsitsiklis, </author> " <title> Optimal and Robust Identification in the ` 1 norm", </title> <booktitle> in Proc. of the 1991 American Control Conference, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: When the topology is induced by the ` 1 norm, a complete study of asymptotic identification was furnished in <ref> [35, 36, 38] </ref> for arbitrary inputs, and the question of optimal input design was addressed. Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. <p> Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in [8, 17, 24, 25, 15, 28, 4, 14]. In this paper, the work of Tse et al <ref> [35, 36, 38] </ref> is extended to general settings, which allows for immediate analysis of larger classes of systems, namely, nonlinear fading memory systems. The study is done in two steps.
Reference: [37] <author> D.N.C. Tse and J.N. Tsitsiklis, </author> " <title> Sample Complexity of Worst-Case System Identification in the Presence of Bounded Random Noise", </title> <note> in preparation. </note>
Reference-contexts: Moreover, it has been demonstrated that if we are willing to put a probability distribution on the noise, polynomial time complexity can often be obtained <ref> [37] </ref>.
Reference: [38] <author> D.N.C. Tse, </author> " <title> Optimal and Robust Identification Under Bounded Disturbances", </title> <type> Master's thesis, </type> <institution> Dept. of Elec. Eng. and Comp. Sci., M.I.T., </institution> <month> February, </month> <year> 1991. </year>
Reference-contexts: When the topology is induced by the ` 1 norm, a complete study of asymptotic identification was furnished in <ref> [35, 36, 38] </ref> for arbitrary inputs, and the question of optimal input design was addressed. Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. <p> Input design has been addressed in stochastic settings (e.g. [7, 20, 40] ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in [8, 17, 24, 25, 15, 28, 4, 14]. In this paper, the work of Tse et al <ref> [35, 36, 38] </ref> is extended to general settings, which allows for immediate analysis of larger classes of systems, namely, nonlinear fading memory systems. The study is done in two steps.
Reference: [39] <author> G. Zames, </author> <title> "On the metric complexity of casual linear systems: *-entropy and *-dimension for continuous-time", </title> <journal> IEEE Trans. on Automatic Control, </journal> <volume> Vol. 24, </volume> <month> April </month> <year> 1979. </year>
Reference-contexts: The case where the objective is to optimize prediction for a fixed input was analyzed by many researchers in [6, 18, 21, 22, 23, 27, 29]. The problem is more interesting when the objective is to approximate the original system as an operator, a problem extensively discussed in <ref> [39] </ref>, especially when the plant's order is not known a priori. For linear time invariant plants, such approximation can be achieved by uniformly approximating the frequency response (H 1 -norm) or the impulse response (` 1 norm).
Reference: [40] <author> M. Zarrop, </author> <title> Optimal Experimental Design for Dynamic System Identification, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1979. </year> <month> 18 </month>
Reference-contexts: When the topology is induced by the ` 1 norm, a complete study of asymptotic identification was furnished in [35, 36, 38] for arbitrary inputs, and the question of optimal input design was addressed. Input design has been addressed in stochastic settings (e.g. <ref> [7, 20, 40] </ref> ), but not in worst-case settings. Related work on the worst-case identification problem was also reported in [8, 17, 24, 25, 15, 28, 4, 14].
References-found: 40

