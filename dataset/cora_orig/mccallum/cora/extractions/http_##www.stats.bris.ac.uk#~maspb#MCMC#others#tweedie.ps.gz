URL: http://www.stats.bris.ac.uk/~maspb/MCMC/others/tweedie.ps.gz
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Rates of convergence of the Hastings and Metropolis algorithms  
Author: K. L. Mengersen and R. L. Tweedie 
Keyword: 0 Keywords: Posterior distributions, Hastings algorithms, Metropolis algorithms, Gibbs sampling, Markov chain Monte Carlo, irreducible Markov processes, geometric ergodicity, stochastic monotonicity, log-concave distributions SHORT TITLE: CONVERGENCE OF HASTINGS ALGORITHMS  
Web: DMS-9205687  
Note: Work supported in part by NSF Grant  
Date: December 2, 1994  
Affiliation: Queensland University of Technology and Colorado State University  
Abstract: We apply recent results in Markov chain theory to Hastings and Metropolis algorithms with either independent or symmetric candidate distributions, and provide necessary and sufficient conditions for the algorithms to converge at a geometric rate to a prescribed distribution . In the independence case (in IR k ) these indicate that geometric convergence essentially occurs if and only if the candidate density is bounded below by a multiple of ; in the symmetric case (in IR only) we show geometric convergence essentially occurs if and only if has geometric tails. We also evaluate recently developed computable bounds on the rates of convergence in this context: examples show that these theoretical bounds can be inherently extremely conservative, although when the chain is stochastically monotone the bounds may well be effective. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Amit. </author> <title> On rates of convergence of stochastic relaxation for Gaussian and non-Gaussian distributions. </title> <journal> J. Multivariate Anal., </journal> <volume> 38 </volume> <pages> 82-99, </pages> <year> 1991. </year>
Reference-contexts: Baxendale [2] has set of bounds, used methods related to those in [12]. Neither of these seem to be uniformly better than those we will apply here [8]. Amit <ref> [1] </ref> considers quite different approaches in an L 2 , as do Schervish and Carlin [18], but these appear rather more specialised in implementation. We illustrate Theorem 4.1 with an application to a distribution concentrated on the non-negative integers ZZ + .
Reference: [2] <author> P. H. Baxendale. </author> <title> Uniform estimates for geometric ergodicity of recurrent Markov processes. </title> <type> Unpublished report, </type> <institution> University of Southern California, </institution> <year> 1993. </year>
Reference-contexts: There have recently been a number of other results found for rates of convergence of Markov chains. Rosenthal [17] uses an elegant coupling method to give bounds on the total variation norm, although they do not cover convergence of unbounded functions of the chain. Baxendale <ref> [2] </ref> has set of bounds, used methods related to those in [12]. Neither of these seem to be uniformly better than those we will apply here [8]. <p> the effective rate of convergence results using Theorem 4.1 (ii) can be applied to a reasonable class of target distributions, and for these realistic and usable bounds can be found. 5 Rates of Convergence: General Case s:rate-gen Even when there is no atom in the space it is shown in <ref> [12, 2, 17] </ref> that under very general conditions it is still possible to get analytical bounds on the rates of convergence which are actually computable, and which are applicable to general Hastings algortihms where only ratios of densities are known. <p> These examples do indicate that, as in Example 3, the bounds are not in general yet of practical value: they do however give an indication of how to construct the drift inequalities that are used in all of the bounds such as those of Theorem 5.1 and <ref> [2, 17] </ref>. Example 4: Estimating Normal Densities Using Normal Candidates If is N (0; 1), then as before we first choose as a symmetric candidate distribution the Normal centred on the current value x with unit variance. <p> A considerable improvement is obtained by choosing the minorising distribution with density -(x) = 1l C (x)e x 2 with N the normalising constant N = R x dx : This gives ffi C = <ref> [2] </ref> 1=2 N e x 2 The infimum occurs at x = x , so that = 1=2 (2x ) [2] 1=2 N e x 2 With the small set and its constants calculated we will consider the test function V (y) = e sjyj for some s to be chosen <p> by choosing the minorising distribution with density -(x) = 1l C (x)e x 2 with N the normalising constant N = R x dx : This gives ffi C = <ref> [2] </ref> 1=2 N e x 2 The infimum occurs at x = x , so that = 1=2 (2x ) [2] 1=2 N e x 2 With the small set and its constants calculated we will consider the test function V (y) = e sjyj for some s to be chosen also.
Reference: [3] <author> J.E. Besag and P.J. Green. </author> <title> Spatial statistics and Bayesian computation (with discussion). </title> <journal> J. Roy. Statist. Soc. Ser. B, </journal> <volume> 55 </volume> <pages> 25-38, </pages> <year> 1993. </year>
Reference-contexts: This is especially relevant when is the posterior distribution in a Bayesian context: see <ref> [3, 21, 20, 14, 22, 4] </ref> for a more detailed introduction. In this paper we are concerned with the rate of convergence of these algorithms for distributions on IR k , and in particular with finding conditions under which the convergence is geometrically fast.
Reference: [4] <author> J.E. Besag, P.J. Green, D. Higdon, and K.L. Mengersen. </author> <title> Spatial statistics, image analysis and Bayesian inference. </title> <journal> Statistical Science, </journal> <note> 1994. (to appear). </note>
Reference-contexts: This is especially relevant when is the posterior distribution in a Bayesian context: see <ref> [3, 21, 20, 14, 22, 4] </ref> for a more detailed introduction. In this paper we are concerned with the rate of convergence of these algorithms for distributions on IR k , and in particular with finding conditions under which the convergence is geometrically fast.
Reference: [5] <author> K.S. Chan. </author> <title> Asymptotic behaviour of the Gibbs sampler. </title> <journal> J. Amer. Statist. Assoc., </journal> <volume> 88 </volume> <pages> 320-326, </pages> <year> 1993. </year>
Reference-contexts: As has been observed often (cf <ref> [20, 22, 5] </ref>) the Hastings algorithms (and other algorithms of the Markov chain Monte Carlo type, such as the Gibbs sampler) can often be analysed using the theory of '-irreducible Markov chains: that is, chains for which there exists a measure ' such that 1 Hastings and Metropolis algorithms and Markov <p> '(A) &gt; 0 ) n (e:varp) (5) For chains with the structure (2) and (3), it is simple to check t:lem1 Lemma 1.1 The chain is -irreducible if (y) &gt; 0 ) q (x; y) &gt; 0; x 2 X: (e:irred) (6) Weaker but less simple conditions are possible (see <ref> [5, 14, 16] </ref>, amongst others). The theory of '-irreducible chains is described in Nummelin [13] or Meyn and Tweedie [11]. As discussed there, in order to develop criteria for rates of convergence, we need the concepts of small sets and aperiodicity. <p> We apply both the necessary and sufficient aspects of the drift condition (14) to the Metropolis algorithm in Theorem 3.2 and Theorem 3.3, whilst the necessity of (15) is applied in Theorem 2.1 in the case of Q independent of x. In the related Gibbs sampling framework, Chan <ref> [5] </ref> has also recently exploited (14). In later sections we also address the question of bounding the rate of convergence in a computable way in (16) using some new Markov chain methods. 2 Convergence of Hastings independence algorithms We first consider the simplest algorithm defined by (2).
Reference: [6] <author> W.K. Hastings. </author> <title> Monte Carlo sampling methods using Markov chains and their applications. </title> <journal> Biometrika, </journal> <volume> 57 </volume> <pages> 97-109, </pages> <year> 1970. </year>
Reference-contexts: In the Hastings algorithm, introduced in <ref> [6] </ref>, a "candidate transition" generated according to the law Q is then accepted with probability ff (x; y) given by ff (x; y) = minf (y) q (y;x) 1 (x)q (x; y) = 0 (e:alpha) (1) Thus actual transitions of the Hastings chain, which we shall denote by = f n
Reference: [7] <author> R.B. Lund and R.L. Tweedie. </author> <title> Geometric convergence rates for stochastically ordered Markov chains. </title> <note> (submitted for publication). </note>
Reference-contexts: However, recent results in <ref> [12, 7, 19] </ref> enable us to derive bounds on the rate of convergence which are actually computable. <p> The stochastic monotonicity result holds also for non-monotone V with the same rate n , but the constant is slightly messier. This version is from Theorem 2.3 of [19]: the main thrust of the result is proved as Theorem 3.1 of <ref> [7] </ref>. The value of as a bound on the rate of convergence is in many cases best possible, as is also shown in [7]. There have recently been a number of other results found for rates of convergence of Markov chains. <p> This version is from Theorem 2.3 of [19]: the main thrust of the result is proved as Theorem 3.1 of <ref> [7] </ref>. The value of as a bound on the rate of convergence is in many cases best possible, as is also shown in [7]. There have recently been a number of other results found for rates of convergence of Markov chains. Rosenthal [17] uses an elegant coupling method to give bounds on the total variation norm, although they do not cover convergence of unbounded functions of the chain. <p> The following table shows the calculations of bounds for various values of the parameter p of the target geometric distribution. p min #(3) #(2 #(1) 0.6 0.97 0.99892 0.99960 0.999974 0.2 0.85 0.99046 0.99503 0.998344 Note from the converse results of <ref> [7] </ref> that this is a case where the exact rate of convergence is indeed min .
Reference: [8] <author> K.L. Mengersen, D.J. Scott, and R.L. Tweedie. </author> <title> Bounds on convergence rates in MCMC: a comparison of methods. </title> <note> (in preparation). </note>
Reference-contexts: Baxendale [2] has set of bounds, used methods related to those in [12]. Neither of these seem to be uniformly better than those we will apply here <ref> [8] </ref>. Amit [1] considers quite different approaches in an L 2 , as do Schervish and Carlin [18], but these appear rather more specialised in implementation. We illustrate Theorem 4.1 with an application to a distribution concentrated on the non-negative integers ZZ + .
Reference: [9] <author> K.L. Mengersen and R.L. Tweedie. </author> <title> Rates of convergence of the Hastings and Metropolis algorithms. </title> <type> Technical Report 93/30, </type> <institution> Colorado State University, </institution> <year> 1993. </year>
Reference-contexts: It is possible to construct variants of standard algorithms that are stochastically monote in some specialised cases, but these are rather artificial <ref> [9] </ref>. The bounds found in Section 5 are also unfortunately relatively close to the best that can be expected using this method of bounding, as can be seen by consideration of the role of ffi C and in the expressions concerned: more details are in [9]. <p> but these are rather artificial <ref> [9] </ref>. The bounds found in Section 5 are also unfortunately relatively close to the best that can be expected using this method of bounding, as can be seen by consideration of the role of ffi C and in the expressions concerned: more details are in [9]. By carrying out the computations above we are able to indicate the type of function V which provides an indicator of the "moments" that will converge in the sense of (16). <p> It is hard to assess how accurate bounds of this nature may be. We saw in Example 3 that they are likely to be inaccurate by several orders of magnitude, and numerical work in <ref> [9] </ref> shows that the convergence of specific moments may well be much faster.
Reference: [10] <author> N. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller. </author> <title> Equations of state calculations by fast computing machines. </title> <journal> J. Chemical Physics, </journal> <volume> 21 </volume> <pages> 1087-1091, </pages> <year> 1953. </year>
Reference-contexts: probability of remaining at the same point given by P (x; fxg) = q (x; y)[1 ff (x; y)] Leb (dy): (3) With this choice of ff we have that satisfies (A) = (dx)P (x; A) for all A 2 B (X): (4) The Metropolis algorithm, which dates back to <ref> [10] </ref>, is a special case of Hastings, utilising a symmetric candidate transition Q: that is, one for which q (x; y) = q (y; x).
Reference: [11] <author> S. P. Meyn and R. L. Tweedie. </author> <title> Markov Chains and Stochastic Stability. </title> <publisher> Springer-Verlag, </publisher> <address> London, </address> <year> 1993. </year>
Reference-contexts: The theory of '-irreducible chains is described in Nummelin [13] or Meyn and Tweedie <ref> [11] </ref>. As discussed there, in order to develop criteria for rates of convergence, we need the concepts of small sets and aperiodicity. <p> The theory of '-irreducible chains is described in Nummelin [13] or Meyn and Tweedie [11]. As discussed there, in order to develop criteria for rates of convergence, we need the concepts of small sets and aperiodicity. It is known <ref> [11, Chapter 5] </ref> that for a '-irreducible chain, any set A with '(A) &gt; 0 contains a small set: that is, a set C such that for some ffi &gt; 0 and n &gt; 0, and some probability measure concentrated on C, P n (x; ) ffi-( ); x 2 C: <p> Consequently, as discussed in <ref> [11] </ref>, Chapter 13, it follows immediately that in the '-irreducible aperiodic case, for -a.e. initial condition x 2 X kP n (x; ) k ! 0 (e:ergo-4) (9) where we define the total variation norm of a signed measure by kk = sup A2B (X) j (A)j: 1 Hastings and Metropolis <p> in the '-irreducible aperiodic case, for -a.e. initial condition x 2 X kP n (x; ) k ! 0 (e:ergo-4) (9) where we define the total variation norm of a signed measure by kk = sup A2B (X) j (A)j: 1 Hastings and Metropolis algorithms and Markov chains 3 From <ref> [11] </ref> we now outline two results which will enable us to analyse convergence properties of Hastings algorithms. <p> The following criteria for uniform ergodicity are taken from <ref> [11] </ref>, Chapter 16. t:operate-big2 Theorem 1.3 For any Markov chain the following are equivalent: (i) The chain is aperiodic and Doeblin's Condition holds: that is, there is a probability measure on B (X) and " &lt; 1; ffi &gt; 0, m 2 ZZ + such that whenever (A) &gt; " inf <p> Even so it is possible to find conditions under which the convergence in (9) takes place at a geometric rate even if there is dependence on the initial state 0 . The following theorem is taken from <ref> [11] </ref>, Chapters 15 and 16. t:operate-big t:rate-c Theorem 1.4 Suppose that is '-irreducible and aperiodic. <p> To see this intuitively consider the equivalent condition in Theorem 1.3 (iii). Note that the Hastings algorithm will move more slowly to hit a set C in the "centre" (due to moves "away") than a random walk that rejects all moves "away": it is well-known <ref> [11] </ref> that for all random walks the number of steps needed to reach the centre of the space is essentially linear in the distance from the centre, and so the number of steps needed for the Hastings algorithm to reach the centre of the space is also unbounded: and so Theorem <p> From Theorem 11.3.4 of <ref> [11] </ref> it follows from (30) that for " = log log V (y) E y [t x ]=" (31) where t x denotes the first hitting time of on (1; x). <p> &gt; 0 that V (y) exp ( 2" + A symmetric argument for the left tail shows that for large values of y we also have V (y) exp ( 2" + Finally we use the fact that, since V satisfies the drift condition (14) then from Theorem 14.0.1 of <ref> [11] </ref>, we must have R (dy)V (y) 1; and the result is proved. ut Note that this necessity result demands no monotonicity properties on at all. If the density (x) is sufficiently regular then we have an elegant dichotomy into geometrically and non-geometrically ergodic chains.
Reference: [12] <author> S. P. Meyn and R. L. Tweedie. </author> <title> Computable bounds for convergence rates of Markov chains. </title> <journal> Ann. Appl. Probab., </journal> <volume> 4 </volume> <pages> 981-1011, </pages> <year> 1994. </year>
Reference-contexts: However, recent results in <ref> [12, 7, 19] </ref> enable us to derive bounds on the rate of convergence which are actually computable. <p> 1) as in (35), and (36) holds for the atom f0g and monotone V , then for any r 1 , kP n (x; ) k V 1 r b ]r n ; n 2 ZZ + : (e:rhos-sm) (43) The result using ff (1) is in Theorems 2.1-2.2 of <ref> [12] </ref>, and requires only that we know ; b and ffi; the results using ff (2) or ff (3) follow from (42) of [12], and require that we know at least a lower bound on p (2), and for ff (3) that we also know (ff). <p> (x; ) k V 1 r b ]r n ; n 2 ZZ + : (e:rhos-sm) (43) The result using ff (1) is in Theorems 2.1-2.2 of <ref> [12] </ref>, and requires only that we know ; b and ffi; the results using ff (2) or ff (3) follow from (42) of [12], and require that we know at least a lower bound on p (2), and for ff (3) that we also know (ff). This will sometimes be the case but in general we have only the coarse bound in (40) available. <p> Rosenthal [17] uses an elegant coupling method to give bounds on the total variation norm, although they do not cover convergence of unbounded functions of the chain. Baxendale [2] has set of bounds, used methods related to those in <ref> [12] </ref>. Neither of these seem to be uniformly better than those we will apply here [8]. Amit [1] considers quite different approaches in an L 2 , as do Schervish and Carlin [18], but these appear rather more specialised in implementation. <p> This is due, as noted in <ref> [12] </ref>, largely to the large value of ff (j), and more work needs to be don to improve this if the bounds are to be of value in practice in evaluating Hastings-Metropolis algorithms. <p> the effective rate of convergence results using Theorem 4.1 (ii) can be applied to a reasonable class of target distributions, and for these realistic and usable bounds can be found. 5 Rates of Convergence: General Case s:rate-gen Even when there is no atom in the space it is shown in <ref> [12, 2, 17] </ref> that under very general conditions it is still possible to get analytical bounds on the rates of convergence which are actually computable, and which are applicable to general Hastings algortihms where only ratios of densities are known. <p> These extend those of Theorem 4.1 (i): from Theorem 2.3 of <ref> [12] </ref> we have t:rates Theorem 5.1 Suppose that in (14) the set C satisfies (7) with n = 1 so that P (x; ) ffi C -( ); x 2 C (e:small-ape) (46) and assume := inf P (x; C) ffi C &gt; 0; v C = sup V (x) &lt;
Reference: [13] <author> E. Nummelin. </author> <title> General Irreducible Markov Chains and Non-Negative Operators. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1984. </year>
Reference-contexts: The theory of '-irreducible chains is described in Nummelin <ref> [13] </ref> or Meyn and Tweedie [11]. As discussed there, in order to develop criteria for rates of convergence, we need the concepts of small sets and aperiodicity.
Reference: [14] <author> G. O. Roberts and N. G.Polson. </author> <title> A note on the geometric convergence of the Gibbs sampler. </title> <journal> J. Roy. Statist. Soc. Ser. B, </journal> <volume> 56 </volume> <pages> 377-384, </pages> <year> 1994. </year>
Reference-contexts: This is especially relevant when is the posterior distribution in a Bayesian context: see <ref> [3, 21, 20, 14, 22, 4] </ref> for a more detailed introduction. In this paper we are concerned with the rate of convergence of these algorithms for distributions on IR k , and in particular with finding conditions under which the convergence is geometrically fast. <p> '(A) &gt; 0 ) n (e:varp) (5) For chains with the structure (2) and (3), it is simple to check t:lem1 Lemma 1.1 The chain is -irreducible if (y) &gt; 0 ) q (x; y) &gt; 0; x 2 X: (e:irred) (6) Weaker but less simple conditions are possible (see <ref> [5, 14, 16] </ref>, amongst others). The theory of '-irreducible chains is described in Nummelin [13] or Meyn and Tweedie [11]. As discussed there, in order to develop criteria for rates of convergence, we need the concepts of small sets and aperiodicity.
Reference: [15] <author> G.O. Roberts and J.S. Rosenthal. </author> <title> Shift-coupling and convergence rates of ergodic averages. </title> <note> (Submitted for publication). </note>
Reference-contexts: An alternative approach to convergence, giving non-geometric but apparently more effective bounds in practice (at least on the total variation norm), has recently been developed in <ref> [15] </ref>, and they also give an application to the examples in Section 5, indicating that the total variation norm distance is likely to decrease more quickly than 10 3 =n in these cases. Nonetheless, they do have the virtue that they are "honest" bounds.
Reference: [16] <author> G.O. Roberts and R.L. Tweedie. </author> <title> Geometric convergence and central limit theorems for multidimensional Hastings and Metropolis algorithms. </title> <journal> Biometrika. </journal> <note> (Accepted subject to revision). </note>
Reference-contexts: '(A) &gt; 0 ) n (e:varp) (5) For chains with the structure (2) and (3), it is simple to check t:lem1 Lemma 1.1 The chain is -irreducible if (y) &gt; 0 ) q (x; y) &gt; 0; x 2 X: (e:irred) (6) Weaker but less simple conditions are possible (see <ref> [5, 14, 16] </ref>, amongst others). The theory of '-irreducible chains is described in Nummelin [13] or Meyn and Tweedie [11]. As discussed there, in order to develop criteria for rates of convergence, we need the concepts of small sets and aperiodicity. <p> In the remainder of this section we shall consider only distributions on IR. Some of the results can be extended, although not simply, to higher dimensions, and this has been done recently in <ref> [16] </ref> Let us define the class M of densities with the properties that (x) is continuous and (x) &gt; 0 for all x 2 IR. <p> In higher dimensions this also seems plausible, and in <ref> [16] </ref> we show that if indeed decreases exponentially as one moves away from the origin, then the Metropolis algorithm is geometrically ergodic, provided also that has smooth contours in an explicit way. Without the extra contour condition, the chain can fail to be geometrically ergodic.
Reference: [17] <author> J.S. Rosenthal. </author> <title> Minorization conditions and convergence rates for Markov chain Monte Carlo. </title> <journal> J. Amer. Statist. Assoc. to appear" volume=" ", pages=" ", year=" </journal> ". 
Reference-contexts: The value of as a bound on the rate of convergence is in many cases best possible, as is also shown in [7]. There have recently been a number of other results found for rates of convergence of Markov chains. Rosenthal <ref> [17] </ref> uses an elegant coupling method to give bounds on the total variation norm, although they do not cover convergence of unbounded functions of the chain. Baxendale [2] has set of bounds, used methods related to those in [12]. <p> the effective rate of convergence results using Theorem 4.1 (ii) can be applied to a reasonable class of target distributions, and for these realistic and usable bounds can be found. 5 Rates of Convergence: General Case s:rate-gen Even when there is no atom in the space it is shown in <ref> [12, 2, 17] </ref> that under very general conditions it is still possible to get analytical bounds on the rates of convergence which are actually computable, and which are applicable to general Hastings algortihms where only ratios of densities are known. <p> These examples do indicate that, as in Example 3, the bounds are not in general yet of practical value: they do however give an indication of how to construct the drift inequalities that are used in all of the bounds such as those of Theorem 5.1 and <ref> [2, 17] </ref>. Example 4: Estimating Normal Densities Using Normal Candidates If is N (0; 1), then as before we first choose as a symmetric candidate distribution the Normal centred on the current value x with unit variance.
Reference: [18] <author> M. J. Schervish and B. P. Carlin. </author> <title> On the convergence of successive substitution sampling. </title> <journal> J. Comp. Graphical Stats., </journal> <volume> 1 </volume> <pages> 111-127, </pages> <year> 1993. </year>
Reference-contexts: Baxendale [2] has set of bounds, used methods related to those in [12]. Neither of these seem to be uniformly better than those we will apply here [8]. Amit [1] considers quite different approaches in an L 2 , as do Schervish and Carlin <ref> [18] </ref>, but these appear rather more specialised in implementation. We illustrate Theorem 4.1 with an application to a distribution concentrated on the non-negative integers ZZ + . This gives some idea of the difference in effectiveness of the two bounds given by (43) and (39). <p> We conclude by considering a modified or adaptive chain which moves relatively quickly to the centre of the space; this is similar to a model analysed by Schervish and Carlin <ref> [18] </ref>, which was shown to converge at rate 1/2, and we might hope to find a faster theoretical rate of convergence here. Again take as N (0; 1), and now let us choose the candidate density by Q (x; ) = N (x=2; 1).
Reference: [19] <author> D.J. Scott and R.L. Tweedie. </author> <title> Explicit rates of convergence of stochastically ordered Markov chains. </title> <note> (in preparation). </note>
Reference-contexts: However, recent results in <ref> [12, 7, 19] </ref> enable us to derive bounds on the rate of convergence which are actually computable. <p> This will sometimes be the case but in general we have only the coarse bound in (40) available. The stochastic monotonicity result holds also for non-monotone V with the same rate n , but the constant is slightly messier. This version is from Theorem 2.3 of <ref> [19] </ref>: the main thrust of the result is proved as Theorem 3.1 of [7]. The value of as a bound on the rate of convergence is in many cases best possible, as is also shown in [7].
Reference: [20] <author> A. F. M. Smith and A. E. Gelfand. </author> <title> Bayesian statistics without tears: A sampling-resampling perspective. </title> <journal> Amer. Statist., </journal> <volume> 46 </volume> <pages> 84-88, </pages> <year> 1992. </year> <note> References 19 </note>
Reference-contexts: This is especially relevant when is the posterior distribution in a Bayesian context: see <ref> [3, 21, 20, 14, 22, 4] </ref> for a more detailed introduction. In this paper we are concerned with the rate of convergence of these algorithms for distributions on IR k , and in particular with finding conditions under which the convergence is geometrically fast. <p> As has been observed often (cf <ref> [20, 22, 5] </ref>) the Hastings algorithms (and other algorithms of the Markov chain Monte Carlo type, such as the Gibbs sampler) can often be analysed using the theory of '-irreducible Markov chains: that is, chains for which there exists a measure ' such that 1 Hastings and Metropolis algorithms and Markov
Reference: [21] <author> A.F.M. Smith and G.O. Roberts. </author> <title> Bayesian computation via the Gibbs sampler and related Markov chain Monte Carlo methods (with discussion). </title> <journal> J. Roy. Statist. Soc. Ser. B, </journal> <volume> 55 </volume> <pages> 3-24, </pages> <year> 1993. </year>
Reference-contexts: This is especially relevant when is the posterior distribution in a Bayesian context: see <ref> [3, 21, 20, 14, 22, 4] </ref> for a more detailed introduction. In this paper we are concerned with the rate of convergence of these algorithms for distributions on IR k , and in particular with finding conditions under which the convergence is geometrically fast.
Reference: [22] <author> L. Tierney. </author> <title> Exploring posterior distributions using Markov chains. </title> <type> Technical Report 560, </type> <institution> University of Minnesota, </institution> <year> 1991. </year>
Reference-contexts: This is especially relevant when is the posterior distribution in a Bayesian context: see <ref> [3, 21, 20, 14, 22, 4] </ref> for a more detailed introduction. In this paper we are concerned with the rate of convergence of these algorithms for distributions on IR k , and in particular with finding conditions under which the convergence is geometrically fast. <p> As has been observed often (cf <ref> [20, 22, 5] </ref>) the Hastings algorithms (and other algorithms of the Markov chain Monte Carlo type, such as the Gibbs sampler) can often be analysed using the theory of '-irreducible Markov chains: that is, chains for which there exists a measure ' such that 1 Hastings and Metropolis algorithms and Markov <p> Since we can take n arbitrarily large, it follows that (15) cannot hold for any &gt; 1. Thus we have a contradiction and the chain is not geometrically ergodic. ut The sufficiency of (19) was noted in <ref> [22] </ref>, but the necessity appears to be new. The fact that without this bound the chain may tend to "stick" in regions of low density is of considerable practical importance, and is not merely a curiosity: seemingly sensible procedures give this behaviour, as the following example illustrates. <p> What happens if &lt; 1 3 Convergence of Metropolis algorithms We next consider the algorithm defined by (2) in the symmetric case where q (x; y) = q (y; x); x; y 2 X: (e:symm) (22) The most common usage of such chains occurs (cf. <ref> [22] </ref>) if Q is not merely symmetric but satisfies q (x; y) = q (x y) = q (y x) (23) for some fixed density q; that is, the candidate increment distributions are identical, and the chain would be a random walk if it were not for the acceptance probabilities, which
Reference: [23] <author> P. Tuominen and R.L. Tweedie. </author> <title> Subgeometric rates of convergence of f -ergodic Markov chains. </title> <journal> Adv. Appl. Probab., </journal> <volume> 26 </volume> <pages> 775-798, </pages> <year> 1994. </year>
Reference-contexts: Thus if is Normal we have geometric convergence but if is a t-distribution this will not occur. We conjecture that convergence rates in the case of polynomial tails of order n will be polynomial of order n 1; this is plausible based on similar results in <ref> [23] </ref>. 4 Computable Rates of Convergence: Chains with Atoms Unlike (13) there exist no simple conditions in general for rates of convergence in the non-uniform case. However, recent results in [12, 7, 19] enable us to derive bounds on the rate of convergence which are actually computable.
References-found: 23

