URL: http://www.cs.princeton.edu/~appel/papers/97.ps
Refering-URL: http://www.cs.princeton.edu/~appel/papers/
Root-URL: http://www.cs.princeton.edu
Title: A Standard ML Compiler  
Author: Andrew W. Appel David B. MacQueen 
Note: Supported by NSF Grant DCR-8603453 and by a Digital Equipment Corporation Faculty Incentive Grant. Part of this author's work was done while an SERC Senior Visiting Fellow at the University of Edinburgh.  
Address: Princeton, NJ 08544  Murray Hill, NJ 07974  
Affiliation: Dept. of Computer Science Princeton University  AT&T Bell Laboratories  
Abstract: Standard ML is a major revision of earlier dialects of the functional language ML. We describe the first compiler written for Standard ML in Standard ML. The compiler incorporates a number of novel features and techniques, and is probably the largest system written to date in Standard ML. Great attention was paid to modularity in the construction of the compiler, leading to a successful large-scale test of the modular capabilities of Standard ML. The front end is useful for purposes other than compilation, and the back end is easily retargetable (we have code generators for the VAX and MC68020). The module facilities of Standard ML were taken into account early in the design of the compiler, and they particularly influenced the environment management component of the front end. For example, the symbol table structure is designed for fast access to opened structures. The front end of the compiler is a single phase that integrates parsing, environment management, and type checking. The middle end uses a sophisticated decision tree scheme to produce efficient pattern matching code for functions and case expressions. The abstract syntax produced by the front end is translated into a simple lambda-calculus-based intermediate representation that lends itself to easy case analysis and optimization in the code generator. Special care was taken in designing the runtime data structures for fast allocation and garbage collection. We describe the overall organization of the compiler and present some of the data representations and algorithms used in its various phases. We conclude with some lessons learned about the ML language itself and about compilers for modern functional languages. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> P. J. Landin, </author> <title> ``The next 700 programming languages,'' </title> <journal> Comm. ACM, </journal> <volume> vol. 9, no. 3, </volume> <pages> pp. 157-166, </pages> <year> 1966. </year>
Reference-contexts: 1. Introduction The ML language is a typed functional language roughly based on Landin's ISWIM <ref> [1] </ref>. It was originally designed in the mid-1970s as the metalanguage of Edinburgh LCF, a machine-assisted reasoning system, and its features were in part motivated by its intended use to express proof tactics.
Reference: 2. <author> Luca Cardelli, </author> <title> ``Compiling a functional language,'' </title> <booktitle> 1984 Symp. on LISP and Functional Programming, </booktitle> <pages> pp. 208-217, </pages> <publisher> ACM, </publisher> <year> 1984. </year>
Reference-contexts: However, these features made it an attractive vehicle for general purpose symbolic programming, and it wasn't long before free-standing implementations appeared, such as Cardelli's compiler <ref> [2] </ref>, which was written in Pascal. In 1983 a group of interested parties began work on an extensive revision of the language design that lead to Standard ML [3, 4, 5, 6]. <p> A fast overlay can be achieved by representing environments as trees of overlay operations, but then access requires a tree search. In the compiled code, closures can be represented as flat or linked structures. A flat closure <ref> [2] </ref> is just a vector with one slot for each free variable, containing the value to which it is bound. A linked closure [17] has the binding of one free variable at the innermost level, along with a pointer to the closure for the enclosing scope. <p> The fact that machine-code fragments contain no pointers is a consequence of the fact that the back-end code generator is never applied to any lambda-expression with free variables. There are several different representations used for constructors, just as in Cardelli's compiler <ref> [2] </ref>. Constructors that carry values are usually represented as pairs of (tag, value). Constant - 18 - desc 78 pointers and an integer desc 62 functions with one free variable constructors (link nil) are represented as small unboxed integers.
Reference: 3. <author> Robin Milner, </author> <title> ``A proposal for Standard ML,'' </title> <booktitle> ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pp. 184-197, </pages> <publisher> ACM, </publisher> <year> 1984. </year>
Reference-contexts: In 1983 a group of interested parties began work on an extensive revision of the language design that lead to Standard ML <ref> [3, 4, 5, 6] </ref>. Standard ML extended the earlier versions in certain ways and incorporated ideas from Hope [7], another language developed in Edinburgh in the late 1970s.
Reference: 4. <author> Robin Milner, </author> <title> ``The Standard ML Core Language,'' </title> <journal> Polymorphism, </journal> <volume> vol. 2, no. 2, </volume> <month> October </month> <year> 1985. </year>
Reference-contexts: In 1983 a group of interested parties began work on an extensive revision of the language design that lead to Standard ML <ref> [3, 4, 5, 6] </ref>. Standard ML extended the earlier versions in certain ways and incorporated ideas from Hope [7], another language developed in Edinburgh in the late 1970s.
Reference: 5. <author> David MacQueen, </author> <title> ``Modules for Standard ML,'' </title> <booktitle> Proc. 1984 ACM Conf. on LISP and Functional Programming, </booktitle> <pages> pp. 198-207, </pages> <publisher> ACM, </publisher> <address> Austin, Texas, </address> <year> 1984. </year>
Reference-contexts: In 1983 a group of interested parties began work on an extensive revision of the language design that lead to Standard ML <ref> [3, 4, 5, 6] </ref>. Standard ML extended the earlier versions in certain ways and incorporated ideas from Hope [7], another language developed in Edinburgh in the late 1970s.
Reference: 6. <author> David MacQueen, </author> <title> ``Modules for Standard ML,'' </title> <journal> Polymorphism, </journal> <volume> vol. 2, no. 2, </volume> <month> October </month> <year> 1985. </year>
Reference-contexts: In 1983 a group of interested parties began work on an extensive revision of the language design that lead to Standard ML <ref> [3, 4, 5, 6] </ref>. Standard ML extended the earlier versions in certain ways and incorporated ideas from Hope [7], another language developed in Edinburgh in the late 1970s.
Reference: 7. <author> R. Burstall, D. MacQueen, and D. Sannella, </author> <title> ``Hope: an Experimental Applicative Language,'' </title> <booktitle> Proceedings of the 1980 LISP Conference, </booktitle> <pages> pp. 136-143, </pages> <address> Stanford, </address> <year> 1980. </year> <month> - 23 </month> - 
Reference-contexts: In 1983 a group of interested parties began work on an extensive revision of the language design that lead to Standard ML [3, 4, 5, 6]. Standard ML extended the earlier versions in certain ways and incorporated ideas from Hope <ref> [7] </ref>, another language developed in Edinburgh in the late 1970s. It also included a module facility that significantly extends the basic polymorphic type system of earlier ML versions and supports large-scale program development. Several implementations of Standard ML have been under development in recent years. <p> The contextual type of an occurrence of the identifier is matched against the scheme and the resulting instantiations of the scheme type variables is used to choose the appropriate variant. This is simpler though more restrictive than the technique used in Hope <ref> [7] </ref>, where variants could have arbitrary types, as long as they were incomparable (i.e. one was not an instance of another). 3.5.
Reference: 8. <author> David C. J. Matthews, </author> <title> ``The Poly manual,'' </title> <journal> SIGPLAN Notices, </journal> <month> September </month> <year> 1985. </year>
Reference-contexts: A new compiler was developed in Cambridge by David Matthews, using his Poly language <ref> [8, 9] </ref> as the implementation language, and sharing the Poly back end. At INRIA, a group headed by Gerard Huet and Guy Cousineau have been implementing an ML variant called CAML [10] that is intermediate between the LCF version and Standard ML.
Reference: 9. <author> David C. J. Matthews, </author> <title> An implementation of Standard ML in Poly, </title> <month> May </month> <year> 1986. </year>
Reference-contexts: A new compiler was developed in Cambridge by David Matthews, using his Poly language <ref> [8, 9] </ref> as the implementation language, and sharing the Poly back end. At INRIA, a group headed by Gerard Huet and Guy Cousineau have been implementing an ML variant called CAML [10] that is intermediate between the LCF version and Standard ML.
Reference: 10. <author> G. Cousineau, P. L. Curien, and M. Mauny, </author> <title> ``The Categorical Abstract Machine,'' </title> <booktitle> in Functional Programming Languages and Computer Architecture, </booktitle> <volume> LNCS Vol 201, </volume> <editor> ed. J. P. </editor> <booktitle> Jouannaud, </booktitle> <pages> pp. 50-64, </pages> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: A new compiler was developed in Cambridge by David Matthews, using his Poly language [8, 9] as the implementation language, and sharing the Poly back end. At INRIA, a group headed by Gerard Huet and Guy Cousineau have been implementing an ML variant called CAML <ref> [10] </ref> that is intermediate between the LCF version and Standard ML. Yet there was still justification for another Standard ML compiler. One of the main motivations was to build a compiler that would itself be implemented in Standard ML. Such a compiler would have several advantages.
Reference: 11. <author> Robin Milner, </author> <title> ``A Theory of Type Polymorphism in Programming,'' </title> <journal> J. CSS, </journal> <volume> vol. 17, </volume> <pages> pp. 348-375, </pages> <year> 1978. </year>
Reference-contexts: This means, of course, that all identifiers must be looked up just to determine if they are constructors. 3.4. Type Checking The conventional polymorphic type checking algorithm <ref> [11, 12] </ref> is used at present. The basis of the algorithm is the unification of type terms by destructively instantiating type variables so that they become indirections to other types.
Reference: 12. <author> Luca Cardelli, </author> <title> ``Basic polymorphic typechecking,'' </title> <journal> Polymorphism, </journal> <volume> vol. 2, no. 1, </volume> <month> January </month> <year> 1985. </year>
Reference-contexts: This means, of course, that all identifiers must be looked up just to determine if they are constructors. 3.4. Type Checking The conventional polymorphic type checking algorithm <ref> [11, 12] </ref> is used at present. The basis of the algorithm is the unification of type terms by destructively instantiating type variables so that they become indirections to other types.
Reference: 13. <author> R. S. Boyer and J Moore, </author> <title> ``The sharing of structure in theorem-proving programs,'' </title> <booktitle> in Machine Intelligence 7, </booktitle> <editor> ed. D. Michie, </editor> <publisher> Edinburgh University Press, </publisher> <year> 1972. </year>
Reference-contexts: The administration of generic or bound type variables is done more systematically than in the Cardelli and Edinburgh compilers, but generic types are still copied for each applied occurrence of a variable. A new type representation and type checking algorithm based on structure sharing (in the Boyer-Moore sense <ref> [13] </ref>) has been prototyped with the help of Nick Rothwell. In this new scheme, a polymorphic type is represented as a scheme whose bound variables are indices into an environment vector; different instantiations share the scheme but have different environment vectors. Overloading is accommodated to a limited extent.
Reference: 14. <author> Luis Damas, </author> <title> ``Type Assignment in Programming Languages,'' </title> <type> PhD Thesis, </type> <institution> Department of Computer Science, University of Edinburgh, </institution> <year> 1985. </year>
Reference-contexts: Exception declarations raise similar problems, which are handled by an analogous use of weak type variables. The Cardelli and Edinburgh compilers used an earlier form of this treatment proposed by Damas <ref> [14] </ref>. This earlier version was looser in one respect (it allowed unbound weak type variables in types) and more restrictive in another (multiple levels of lambda abstraction were not allowed), and it had some rather counterintuitive effects. 3.6.
Reference: 15. <author> Robert Harper, Robin Milner, and Mads Tofte, </author> <title> ``A type discipline for program modules,'' </title> <institution> ECS-LFCS-87-28, Univ. of Edinburgh, </institution> <year> 1987. </year>
Reference-contexts: Structure-sharing The final approach is inspired, like Harper's prototype implementation, by the semantic model developed by Harper, Milner, and Tofte <ref> [15] </ref>. We return to the straightforward idea of actually performing the static reductions to obtain instantiated copies of the functor body, but a structure-sharing representation is used to minimize the amount of copying.
Reference: 16. <author> Marianne Baudinet and David MacQueen, </author> <title> Tree Pattern Matching for ML, </title> <year> 1986. </year>
Reference-contexts: One could imagine a naive compilation of matches just by testing the rules in turn as called for by the semantics. Our approach is to transform a sequence of patterns into a decision tree <ref> [16] </ref>. Each internal node of the decision tree corresponds to a matching test and each branch is labeled with one of the possible results of the matching test and with a list of the patterns that remain potential candidates in that case. <p> This minimizes the size of the generated code and also generally reduces the number of tests performed on value terms. However, finding the decision tree with the minimum number of nodes is an NP-complete problem <ref> [16] </ref>; so a set of efficient heuristics is used that in practice produces an optimal decision tree in almost all cases.
Reference: 17. <author> Guy L. Steele, ``Rabbit: </author> <title> a compiler for Scheme,'' </title> <publisher> AI-TR-474, MIT, </publisher> <year> 1978. </year>
Reference-contexts: A significant advantage of having a very simple lambda-calculus as the intermediate representation is that many compiler optimizations can be cleanly described. This is the approach successfully taken in the Rabbit <ref> [17] </ref> and Orbit [18] compilers for Scheme. <p> However, the details of the Machine signature might be changed to make it less like a stack machine. This might improve the generated code, especially for architectures that are not naturally stack-oriented. We are considering a reimplementation of the code generator using continuation-passing style <ref> [17] </ref> and Orbit [18]. 5.1. Pattern-matching in code generation Many modern code generators are written in the form of tree-pattern matchers [21, 22]. By writing the lambda-calculus tree data structure as an ML datatype (with constructors), the tree pattern matching can be directly specified as an ML function. <p> In the compiled code, closures can be represented as flat or linked structures. A flat closure [2] is just a vector with one slot for each free variable, containing the value to which it is bound. A linked closure <ref> [17] </ref> has the binding of one free variable at the innermost level, along with a pointer to the closure for the enclosing scope. Flat closures have a fast access, but to build the vector takes time proportional to the number of free variables in the function.
Reference: 18. <author> D. Kranz, R. Kelsey, J. Rees, P. Hudak, J. Philbin, and N. Adams, </author> <title> ``ORBIT: An optimizing compiler for Scheme,'' </title> <booktitle> Proc. Sigplan '86 Symp. on Compiler Construction, vol. 21 (Sigplan Notices), </booktitle> <volume> no. 7, </volume> <pages> pp. 219-233, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: A significant advantage of having a very simple lambda-calculus as the intermediate representation is that many compiler optimizations can be cleanly described. This is the approach successfully taken in the Rabbit [17] and Orbit <ref> [18] </ref> compilers for Scheme. <p> However, the details of the Machine signature might be changed to make it less like a stack machine. This might improve the generated code, especially for architectures that are not naturally stack-oriented. We are considering a reimplementation of the code generator using continuation-passing style [17] and Orbit <ref> [18] </ref>. 5.1. Pattern-matching in code generation Many modern code generators are written in the form of tree-pattern matchers [21, 22]. By writing the lambda-calculus tree data structure as an ML datatype (with constructors), the tree pattern matching can be directly specified as an ML function.
Reference: 19. <author> W. Wulf, R. K. Johnsson, C. B. Weinstock, C. B. Hobbs, and C. M. Geschke, </author> <title> Design of an Optimizing Compiler, </title> <publisher> Elsevier North-Holland, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: The last phase is the back-patching of jumps and other relative addresses in a machine-language program. Relative jump instructions on many machines are of different sizes depending on the distance jumped, and several iterations of estimating jump sizes may be required before a fixed point is found <ref> [19] </ref>.
Reference: 20. <author> Luca Cardelli, </author> <title> ``The functional abstract machine,'' </title> <journal> Polymorphism, </journal> <volume> vol. 1, no. 1, </volume> <month> January </month> <year> 1983. </year>
Reference-contexts: The code generator translates programs from lambda language into machine code by means of an abstract machine intermediate form. The abstract machine is similar in spirit to Cardelli's <ref> [20] </ref>. <p> Value-carrying constructors can be represented completely transparently if they carry an always-boxed value, and there are no other value-carrying constructors in the datatype (like cons), or if there is only one constructor in the datatype. Finally, ref cells look like one-word records. Earlier ML compilers <ref> [20] </ref> represented mutually recursive functions as a set of closures that point to each other in a cyclic data structure. We wanted to avoid gratuitous circularity, because many garbage collection algorithms are more efficient on acyclic data structures [24].
Reference: 21. <author> R. G. G. Cattell, </author> <title> ``Formalization and automatic derivation of code generators,'' </title> <type> Ph.D. Thesis, </type> <institution> Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> April </month> <year> 1978. </year>
Reference-contexts: This might improve the generated code, especially for architectures that are not naturally stack-oriented. We are considering a reimplementation of the code generator using continuation-passing style [17] and Orbit [18]. 5.1. Pattern-matching in code generation Many modern code generators are written in the form of tree-pattern matchers <ref> [21, 22] </ref>. By writing the lambda-calculus tree data structure as an ML datatype (with constructors), the tree pattern matching can be directly specified as an ML function.
Reference: 22. <author> A. V. Aho, M. Ganapathi, and S. W. K. Tjiang, </author> <title> ``Code generation using tree matching and dynamic programming,'' </title> <journal> ACM Trans. Prog. Lang. and Systems, </journal> <note> vol. (to appear), </note> <year> 1989. </year>
Reference-contexts: This might improve the generated code, especially for architectures that are not naturally stack-oriented. We are considering a reimplementation of the code generator using continuation-passing style [17] and Orbit [18]. 5.1. Pattern-matching in code generation Many modern code generators are written in the form of tree-pattern matchers <ref> [21, 22] </ref>. By writing the lambda-calculus tree data structure as an ML datatype (with constructors), the tree pattern matching can be directly specified as an ML function.
Reference: 23. <author> D. A. Turner, ``Miranda: </author> <title> a non-strict functional language with polymorphic types,'' </title> <booktitle> in Functional Programming Languages and Computer Architecture, </booktitle> <volume> LNCS Vol 201, </volume> <editor> ed. J. P. </editor> <booktitle> Jouannaud, </booktitle> <pages> pp. 1-16, </pages> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: By the time the else clause is reached, it is impossible to transfer control to the APP (f,a) clause. One solution to this problem is to attach boolean conditions to patterns, as is done in - 16 - Miranda <ref> [23] </ref>: | APP (VAR w, a) when knownfunc (w) =&gt; Though would add some ``syntactic sludge'' to the language, it is worth considering as a future extension. 5.2.
Reference: 24. <author> Henry Lieberman and Carl Hewitt, </author> <title> ``A real-time garbage collector based on the lifetimes of objects,'' </title> <journal> Communications of the ACM, </journal> <volume> vol. 23, no. 6, </volume> <pages> pp. 419-429, </pages> <publisher> ACM, </publisher> <year> 1983. </year>
Reference-contexts: Finally, ref cells look like one-word records. Earlier ML compilers [20] represented mutually recursive functions as a set of closures that point to each other in a cyclic data structure. We wanted to avoid gratuitous circularity, because many garbage collection algorithms are more efficient on acyclic data structures <ref> [24] </ref>. We represent mutually recursive functions with just one closure record that has several function-part entries (Figure 2). To represent function i, one just uses a pointer to the i th field. <p> A fast cons is not helpful if garbage collection is slow. When physical memory is large, then the cost of copying garbage collection, amortized over the cons operations, can come to less than one instruction per cons [25]. We are using a variant of generational garbage collection <ref> [24, 26, 27] </ref> that promises to be very fast even in moderate-size memories. In writing our compiler, we have aimed for clarity and straightforwardness; we have eschewed the coding tricks that enable programmers to avoid using dynamically allocated memory.
Reference: 25. <author> A. W. Appel, </author> <title> ``Garbage collection can be faster than stack allocation,'' </title> <journal> Information Processing Letters, </journal> <volume> vol. 25, no. 4, </volume> <pages> pp. 275-279, </pages> <year> 1987. </year>
Reference-contexts: This is an extremely low-overhead cons operation. A fast cons is not helpful if garbage collection is slow. When physical memory is large, then the cost of copying garbage collection, amortized over the cons operations, can come to less than one instruction per cons <ref> [25] </ref>. We are using a variant of generational garbage collection [24, 26, 27] that promises to be very fast even in moderate-size memories. In writing our compiler, we have aimed for clarity and straightforwardness; we have eschewed the coding tricks that enable programmers to avoid using dynamically allocated memory.
Reference: 26. <author> David A. Moon, </author> <title> ``Garbage collection in a large LISP system,'' </title> <booktitle> ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pp. 235-246, </pages> <publisher> ACM, </publisher> <year> 1984. </year>
Reference-contexts: A fast cons is not helpful if garbage collection is slow. When physical memory is large, then the cost of copying garbage collection, amortized over the cons operations, can come to less than one instruction per cons [25]. We are using a variant of generational garbage collection <ref> [24, 26, 27] </ref> that promises to be very fast even in moderate-size memories. In writing our compiler, we have aimed for clarity and straightforwardness; we have eschewed the coding tricks that enable programmers to avoid using dynamically allocated memory.
Reference: 27. <author> David Ungar, </author> <title> ``Generation scavenging: a non-disruptive high performance storage reclamation algorithm,'' </title> <booktitle> SIGPLAN Notices (Proc. ACM SIGSOFT/SIGPLAN Software Eng. Symp. on Practical Software Development Environments), </booktitle> <volume> vol. 19, no. 5, </volume> <pages> pp. 157-167, </pages> <publisher> ACM, </publisher> <year> 1984. </year>
Reference-contexts: A fast cons is not helpful if garbage collection is slow. When physical memory is large, then the cost of copying garbage collection, amortized over the cons operations, can come to less than one instruction per cons [25]. We are using a variant of generational garbage collection <ref> [24, 26, 27] </ref> that promises to be very fast even in moderate-size memories. In writing our compiler, we have aimed for clarity and straightforwardness; we have eschewed the coding tricks that enable programmers to avoid using dynamically allocated memory.
References-found: 27

