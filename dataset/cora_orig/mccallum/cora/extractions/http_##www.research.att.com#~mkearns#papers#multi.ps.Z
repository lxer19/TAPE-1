URL: http://www.research.att.com/~mkearns/papers/multi.ps.Z
Refering-URL: http://www.research.att.com/~mkearns/
Root-URL: 
Email: mkearns@research.att.com  danar@theory.lcs.mit.edu  
Title: Algorithmic Stability and Sanity-Check Bounds for Leave-One-Out Cross-Validation  
Author: Michael Kearns Dana Ron 
Date: January 1997  
Address: Murray Hill, New Jersey  Cambridge, MA  
Affiliation: AT&T Labs Research  MIT  
Abstract: In this paper we prove sanity-check bounds for the error of the leave-one-out cross-validation estimate of the generalization error: that is, bounds showing that the worst-case error of this estimate is not much worse than that of the training error estimate. The name sanity-check refers to the fact that although we often expect the leave-one-out estimate to perform considerably better than the training error estimate, we are here only seeking assurance that its performance will not be considerably worse. Perhaps surprisingly, such assurance has been given only for rather limited cases in the prior literature on cross-validation. Any nontrivial bound on the error of leave-one-out must rely on some notion of algorithmic stability. Previous bounds relied on the rather strong notion of hypothesis stability, whose application was primarily limited to nearest-neighbor and other local algorithms. Here we introduce the new and weaker notion of error stability, and apply it to obtain sanity-check bounds for leave-one-out for other classes of learning algorithms, including training error minimization procedures and Bayesian algorithms. We also provide lower bounds demonstrating the necessity of error stability for proving bounds on the error of the leave-one-out estimate, and the fact that for training error minimization algorithms, in the worst case such bounds must still depend on the Vapnik-Chervonenkis dimension of the hypothesis class. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Devroye, L. Gyrofi, and G. Lugosi. </author> <title> A Probabilistic Theory of Pattern Recognition. </title> <publisher> Springer Verlag, </publisher> <year> 1996. </year>
Reference-contexts: There are surprisingly few previous results providing bounds on the accuracy of the various estimates [15, 2, 3, 17, 9, 8, 12, 10] (see the recent book of Devroye, Gyorfi and Lugosi <ref> [1] </ref> for an excellent introduction and survey of the topic). <p> This unlimited complexity often makes it difficult to quantify the performance of the learning algorithm except in terms of the asymptotic generalization error (see Devroye, Gyorfi and Lugosi <ref> [1] </ref> for a detailed survey of results for nearest-neighbor algorithms). For this and other reasons, practitioners often prefer to commit to a hypothesis class H of fixed VC dimension d, and use heuristics to find a good function in H. <p> The theorem follows from Theorem 3.1, where ffi 0 is set to d=m. (Theorem 3.2) We should note immediately that the bound of Theorem 3.2 has a dependence on q opposed to the log (1=ffi) dependence for the training error given by Theorem 2.1. Unfortunately, it is well-known <ref> [1] </ref> (and demonstrated in Section 5) that, at least in the unrealizable setting, a 1=ffi dependence is in general unavoidable for the leave-one-out estimate. <p> In any case, in Section 5 we show that some additional assumptions (beyond error stability) are required to obtain nontrivial bounds for the error of leave-one-out. Before stating the main theorem of this section, we give the following simple but important lemma that is well-known <ref> [1] </ref>. <p> m will satisfy Pr ~r ;~r 0 [j*(A (S m ; ~r )) *(A (S m ; ~r 0 ))j 2fi 2 + 2VC (d; m; fl)] 2 fi 1 : (37) If S m satisfies Equation (37), it follows that there must be a fixed value * 0 2 <ref> [0; 1] </ref> such that Pr ~r [j*(A (S m ; ~r )) * 0 j 2fi 2 + 2VC (d; m; fl)] 2 fi 1 : (38) Assuming that Equation (38) holds, how far can E ~r [*(A (S m ; ~r ))] be from * 0 ? The extreme cases <p> Our samples S m now consist of examples hx i ; y i i, where x i 2 &lt; d and y i 2 <ref> [1; 1] </ref>. For any function h : &lt; d ! [1; 1], we now define the generalization error by *(h) = E hx;yi [(h (x) y) 2 ], and similarly the training error becomes *(h) = P hx i ;y i i2S (h (x i ) y i ) 2 . <p> Our samples S m now consist of examples hx i ; y i i, where x i 2 &lt; d and y i 2 <ref> [1; 1] </ref>. For any function h : &lt; d ! [1; 1], we now define the generalization error by *(h) = E hx;yi [(h (x) y) 2 ], and similarly the training error becomes *(h) = P hx i ;y i i2S (h (x i ) y i ) 2 . <p> PROOF: Let X = <ref> [0; 1] </ref> [ z 1 ; z 2 , where z 1 and z 2 are special points. Each of z 1 and z 2 will have weight 1=4 under P , while the interval [0,1] will have weight 1=2 uniformly distributed.
Reference: [2] <author> L. P. Devroye and T. J. Wagner. </author> <title> Distribution-free inequalities for the deleted and holdout error estimates. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-25(2):202-207, </volume> <year> 1979. </year>
Reference-contexts: There are surprisingly few previous results providing bounds on the accuracy of the various estimates <ref> [15, 2, 3, 17, 9, 8, 12, 10] </ref> (see the recent book of Devroye, Gyorfi and Lugosi [1] for an excellent introduction and survey of the topic). <p> On the other hand, among the strongest bounds (in the sense of the quality of the estimate) are those given for the leave-one-out estimate by the work of Rogers and Wagner [15], and Devroye and Wagner <ref> [2, 3] </ref>. The (classification error) leave-one-out estimate is computed by running the learning algorithm m times, each time removing one of the m training examples, and testing the resulting hypothesis on the training example that was deleted; the fraction of failed tests is the leave-one-out estimate. <p> Rogers and Wagner [15] and Devroye and Wagner <ref> [2, 3] </ref> proved that for several specific algorithms, but again for any target function and input distribution, the leave-one-out estimate can be as close as O (1= p m) to the true error.
Reference: [3] <author> L. P. Devroye and T. J. Wagner. </author> <title> Distribution-free performance bounds for potential function rules. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-25(5):601-604, </volume> <year> 1979. </year>
Reference-contexts: There are surprisingly few previous results providing bounds on the accuracy of the various estimates <ref> [15, 2, 3, 17, 9, 8, 12, 10] </ref> (see the recent book of Devroye, Gyorfi and Lugosi [1] for an excellent introduction and survey of the topic). <p> On the other hand, among the strongest bounds (in the sense of the quality of the estimate) are those given for the leave-one-out estimate by the work of Rogers and Wagner [15], and Devroye and Wagner <ref> [2, 3] </ref>. The (classification error) leave-one-out estimate is computed by running the learning algorithm m times, each time removing one of the m training examples, and testing the resulting hypothesis on the training example that was deleted; the fraction of failed tests is the leave-one-out estimate. <p> Rogers and Wagner [15] and Devroye and Wagner <ref> [2, 3] </ref> proved that for several specific algorithms, but again for any target function and input distribution, the leave-one-out estimate can be as close as O (1= p m) to the true error. <p> A moment's reflection should make it intuitively clear that, in contrast to the training error, even a sanity-check bound for leave-one-out cannot come without restrictions on the algorithm under consideration: some form of algorithmic stability is required <ref> [3, 9, 13] </ref>. If the removal of even a single example from the training sample may cause the learning algorithm to jump to a different hypothesis with, say, much larger error than the full-sample hypothesis, it seems hard to expect the leave-one-out estimate to be accurate. <p> The precise nature of the required form of stability is less obvious. Devroye and Wagner <ref> [3] </ref> first identified a rather strong notion of algorithmic stability that we shall refer to as hypothesis stability, and showed that bounds on hypothesis stability directly lead to bounds on the error of the leave-one-out estimate. <p> Perhaps the strongest notion of stability that an interesting learning algorithm might be expected to obey is that of hypothesis stability: namely, that small changes in the sample can only cause the algorithm to move to nearby hypotheses. The notion of hypothesis stability is due to Devroye and Wagner <ref> [3] </ref>, and is formalized in a way that suits our purposes in the following definition 3 . <p> We shall shortly argue that hypothesis stability is in fact too demanding a notion in many realistic situations. But first, we state the elegant theorem of Devroye and Wagner <ref> [3] </ref> that relates the error of the leave-one-out estimate for an algorithm to the hypothesis stability. THEOREM 3.1 Let A be any symmetric algorithm that has hypothesis stability (fi 1 ; fi 2 ). <p> What kind of hypothesis stability should we expect for natural algorithms? Devroye, Rogers and Wagner <ref> [15, 3] </ref> gave rather strong hypothesis stability results for certain nonparametric local learning algorithms (such as nearest-neighbor rules), and thus were able to show that the error of the leave-one-out estimate for such algorithms decreases like 1=m ff (for values of ff ranging from 1=4 to 1=2). <p> However, in such a situation, the goal of hypothesis stability may in fact be at odds with the goal of good performance in the sense of learning. To see 3 Devroye and Wagner <ref> [3] </ref> formalized hypothesis stability in terms of the expected difference between the hypotheses; here we translate to the high probability form for consistency. 4 this, imagine that the input distribution and target function define a generalization error surface over the function space H, and that this surface has minima at h
Reference: [4] <author> R. O. Duda and P. E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <year> 1973. </year>
Reference-contexts: for every ffi &gt; 0, with probability at least 1 ffi, j* A q Two very fortunate properties of the combination of linear functions and squared error make the sanity-check bound given in Theorem 4.7 of particular interest: * There exist polynomial-time algorithms for performing minimization of squared training error <ref> [4] </ref> by linear functions.
Reference: [5] <author> S. Geman and D. Geman. </author> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 721-741, </pages> <year> 1984. </year>
Reference-contexts: Such algorithms are frequently studied in the simulated annealing and statistical physics literature on learning <ref> [16, 5] </ref>.
Reference: [6] <author> D. Haussler, M. Kearns, H.S. Seung, and N. Tishby. </author> <title> Rigourous learning curve bounds from statistical mechanics. </title> <journal> Machine Learning, </journal> <volume> 25 </volume> <pages> 195-236, </pages> <year> 1996. </year>
Reference-contexts: (S m )) = 1=2 by 1=2, and for half of the sample it underestimates the error by 1=2. (Theorem 5.4) 6 Extensions and Open Problems It is worth mentioning explicitly that in the many situations when uniform convergence bounds better than V C (d; m; ffi) can be obtained <ref> [16, 6] </ref> our resulting bounds for leave-one-out will be correspondingly better as well. In the full paper we will also detail the generalizations of our results for other loss functions, and give results for k-fold cross-validation as well. There are a number of interesting open problems, both theoretical and experimental.
Reference: [7] <author> David Haussler. </author> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications. </title> <journal> Information and Computation, </journal> <volume> 100(1) </volume> <pages> 78-150, </pages> <year> 1992. </year>
Reference-contexts: error minimization procedure m times; there is a closed-form solution for the leave-one-out estimate that can be computed directly from the data much more quickly. 14 More generally, many of the results given in this paper can be generalized to other loss functions via the proper generalizations of uniform convergence <ref> [7] </ref>. 4.4 Other Algorithms We now comment briefly on the application of Theorem 4.1 to algorithms other than error minimization and Bayesian procedures.
Reference: [8] <author> S. B. Holden. </author> <title> Cross-validation and the PAC learning model. </title> <note> Research Note RN/96/64, </note> <institution> Dept. of CS, Univ. College, </institution> <address> London, </address> <year> 1996. </year>
Reference-contexts: There are surprisingly few previous results providing bounds on the accuracy of the various estimates <ref> [15, 2, 3, 17, 9, 8, 12, 10] </ref> (see the recent book of Devroye, Gyorfi and Lugosi [1] for an excellent introduction and survey of the topic). <p> probability at least 1 ffi, j* CV (S m ) *(A (S m ))j = O @ (d=m) log (m=d) 1 PROOF: By uniform convergence, with probability at least 1 ffi 0 , *(A (S m )) = dist (f; A (S m )) = O m (5) 4 Holden <ref> [8] </ref> has recently obtained sanity-check bounds, again for the realizable setting, for other cross-validation estimates. 5 and *(A (S m1 )) = dist (f; A (S m1 )) = O m 1 : (6) (Here we are using the stronger O (d=m) uniform convergence bounds that are special to the realizable
Reference: [9] <author> S. B. Holden. </author> <title> PAC-like upper bounds for the sample complexity of leave-one-out cross validation. </title> <booktitle> In Proceedings of the Ninth Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 41-50, </pages> <year> 1996. </year>
Reference-contexts: There are surprisingly few previous results providing bounds on the accuracy of the various estimates <ref> [15, 2, 3, 17, 9, 8, 12, 10] </ref> (see the recent book of Devroye, Gyorfi and Lugosi [1] for an excellent introduction and survey of the topic). <p> A moment's reflection should make it intuitively clear that, in contrast to the training error, even a sanity-check bound for leave-one-out cannot come without restrictions on the algorithm under consideration: some form of algorithmic stability is required <ref> [3, 9, 13] </ref>. If the removal of even a single example from the training sample may cause the learning algorithm to jump to a different hypothesis with, say, much larger error than the full-sample hypothesis, it seems hard to expect the leave-one-out estimate to be accurate. <p> For algorithms drawing hypotheses from a class of fixed VC dimension, the first sanity-check bounds for the leave-one-out estimate were provided by Holden <ref> [9] </ref> for two specific algorithms in the realizable case (that is, when the target function is actually contained in the class of hypothesis functions). <p> In Section 2, we begin by stating some needed preliminaries. In Section 3, we review the Devroye and Wanger notion of hypothesis stability, and generalize the results of Holden <ref> [9] </ref> by showing that in the realizable case this notion can be used to obtain sanity-check bounds for any consistent learning algorithm; but we also discuss the limitations of hypothesis stability in the unrealizable case. <p> First, however, note that the instability of the hypothesis above relied on the assumption that * opt &gt; 0 that is, that we are in the unrealizable setting. In the realizable * opt = 0 case, there is still hope for applying hypothesis stability. Indeed, Holden <ref> [9] </ref> was the first to apply uniform convergence results to obtain sanity-check bounds for leave-one-out via hypothesis stability, for two particular (consistent) algorithms in the realizable setting 4 . Here we generalize Holden's results by giving a sanity-check bound on the leave-one-out error for any consistent algorithm.
Reference: [10] <author> M. Kearns. </author> <title> A bound on the error of cross validation, with consequences for the training-test split. </title> <booktitle> In Advances in Neural Information Processing Systems 8, </booktitle> <pages> pages 183-189, </pages> <year> 1996. </year> <note> To Appear in Neural Computation. </note>
Reference-contexts: There are surprisingly few previous results providing bounds on the accuracy of the various estimates <ref> [15, 2, 3, 17, 9, 8, 12, 10] </ref> (see the recent book of Devroye, Gyorfi and Lugosi [1] for an excellent introduction and survey of the topic).
Reference: [11] <author> M. Kearns, R. Schapire, and L. Sellie. </author> <title> Toward efficient agnostic learning. </title> <journal> Machine Learning, </journal> <volume> 17 </volume> <pages> 115-141, </pages> <year> 1994. </year>
Reference-contexts: However, in the more realistic unrealizable (or agnostic <ref> [11] </ref>) case, the notion of hypothesis stability may simply be too strong to be obeyed by many natural learning algorithms.
Reference: [12] <author> M. J. Kearns, Y. Mansour, A. Ng, , and D. Ron. </author> <title> An experimental and theoretical comparison of model selection methods. </title> <booktitle> In Proceedings of the Eighth Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 21-30, </pages> <year> 1995. </year> <note> To Appear in Machine Learning, COLT95 Special Issue. </note>
Reference-contexts: There are surprisingly few previous results providing bounds on the accuracy of the various estimates <ref> [15, 2, 3, 17, 9, 8, 12, 10] </ref> (see the recent book of Devroye, Gyorfi and Lugosi [1] for an excellent introduction and survey of the topic).
Reference: [13] <author> Ron Kohavi. </author> <title> A study of cross-validation and bootstrap for accuracy estimation and model selection. </title> <booktitle> In the International Joint Conference on Artifical Intelligence, </booktitle> <year> 1995. </year>
Reference-contexts: A moment's reflection should make it intuitively clear that, in contrast to the training error, even a sanity-check bound for leave-one-out cannot come without restrictions on the algorithm under consideration: some form of algorithmic stability is required <ref> [3, 9, 13] </ref>. If the removal of even a single example from the training sample may cause the learning algorithm to jump to a different hypothesis with, say, much larger error than the full-sample hypothesis, it seems hard to expect the leave-one-out estimate to be accurate.
Reference: [14] <author> A.J. Miller. </author> <title> Subset Selection in Regression. </title> <publisher> Chapman and Hall, </publisher> <year> 1990. </year>
Reference-contexts: These algorithms do not necessarily obey the constraint jjwjj B, but we suspect this is not an obstacle to the validity of Theorem 4.7 in most practical settings. * There is an efficient procedure for computing the leave-one-out estimate for training error minimization of squared error over linear functions <ref> [14] </ref>.
Reference: [15] <author> W. H. Rogers and T. J. Wagner. </author> <title> A fine sample distribution-free performance bound for local discrimination rules. </title> <journal> The Annals of Statistics, </journal> <volume> 6(3) </volume> <pages> 506-514, </pages> <year> 1978. </year> <month> 19 </month>
Reference-contexts: There are surprisingly few previous results providing bounds on the accuracy of the various estimates <ref> [15, 2, 3, 17, 9, 8, 12, 10] </ref> (see the recent book of Devroye, Gyorfi and Lugosi [1] for an excellent introduction and survey of the topic). <p> On the other hand, among the strongest bounds (in the sense of the quality of the estimate) are those given for the leave-one-out estimate by the work of Rogers and Wagner <ref> [15] </ref>, and Devroye and Wagner [2, 3]. <p> The (classification error) leave-one-out estimate is computed by running the learning algorithm m times, each time removing one of the m training examples, and testing the resulting hypothesis on the training example that was deleted; the fraction of failed tests is the leave-one-out estimate. Rogers and Wagner <ref> [15] </ref> and Devroye and Wagner [2, 3] proved that for several specific algorithms, but again for any target function and input distribution, the leave-one-out estimate can be as close as O (1= p m) to the true error. <p> What kind of hypothesis stability should we expect for natural algorithms? Devroye, Rogers and Wagner <ref> [15, 3] </ref> gave rather strong hypothesis stability results for certain nonparametric local learning algorithms (such as nearest-neighbor rules), and thus were able to show that the error of the leave-one-out estimate for such algorithms decreases like 1=m ff (for values of ff ranging from 1=4 to 1=2).
Reference: [16] <author> H. S. Seung, H. Sompolinsky, and N. Tishby. </author> <title> Statistical mechanics of learning from examples. </title> <journal> Physical Review, </journal> <volume> A45:6056-6091, </volume> <year> 1992. </year>
Reference-contexts: Such algorithms are frequently studied in the simulated annealing and statistical physics literature on learning <ref> [16, 5] </ref>. <p> (S m )) = 1=2 by 1=2, and for half of the sample it underestimates the error by 1=2. (Theorem 5.4) 6 Extensions and Open Problems It is worth mentioning explicitly that in the many situations when uniform convergence bounds better than V C (d; m; ffi) can be obtained <ref> [16, 6] </ref> our resulting bounds for leave-one-out will be correspondingly better as well. In the full paper we will also detail the generalizations of our results for other loss functions, and give results for k-fold cross-validation as well. There are a number of interesting open problems, both theoretical and experimental.
Reference: [17] <author> V.N. Vapnik. </author> <title> Estimation of Dependences Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year> <month> 20 </month>
Reference-contexts: There are surprisingly few previous results providing bounds on the accuracy of the various estimates <ref> [15, 2, 3, 17, 9, 8, 12, 10] </ref> (see the recent book of Devroye, Gyorfi and Lugosi [1] for an excellent introduction and survey of the topic). <p> Perhaps the most general results are those given for the (classification) training error estimate by Vapnik <ref> [17] </ref>, who proved that for any target function and input distribution, and for any learning algorithm that chooses its hypotheses from a class of VC dimension d, the training error estimate is at most O ( q d=m) 1 away from the true error, where m is the size of the <p> We are thus interested in providing bounds on the error j* A CV (S m ) *(A (S m ))j of the leave-one-out estimate. The following uniform convergence bound, due to Vapnik <ref> [17] </ref> will be central to this paper. THEOREM 2.1 Let H be a hypothesis class with VC dimension d &lt; m.
References-found: 17

