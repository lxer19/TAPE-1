URL: http://L2R.cs.uiuc.edu/~danr/Papers/hardJ.ps.gz
Refering-URL: http://L2R.cs.uiuc.edu/~danr/publications.html
Root-URL: http://www.cs.uiuc.edu
Email: danr@das.harvard.edu  
Title: On the Hardness of Approximate Reasoning  
Author: Dan Roth 
Address: Cambridge, MA 02138.  
Affiliation: Division of Applied Sciences, Harvard University,  
Date: 82 (1996) 273-302  
Note: Artificial Intelligence  
Abstract: Many AI problems, when formalized, reduce to evaluating the probability that a propositional expression is true. In this paper we show that this problem is computationally intractable even in surprisingly restricted cases and even if we settle for an approximation to this probability. We consider various methods used in approximate reasoning such as computing degree of belief and Bayesian belief networks, as well as reasoning techniques such as constraint satisfaction and knowledge compilation, that use approximation to avoid computational difficulties, and reduce them to model-counting problems over a propositional domain. We prove that counting satisfying assignments of propositional languages is intractable even for Horn and monotone formulae, and even when the size of clauses and number of occurrences of the variables are extremely limited. This should be contrasted with the case of deductive reasoning, where Horn theories and theories with binary clauses are distinguished by the existence of linear time satisfiability algorithms. What is even more surprising is that, as we show, even approximating the number of satisfying assignments (i.e., "approximating" approximate reasoning), is intractable for most of these restricted theories. We also identify some restricted classes of propositional formulae for which efficient algorithms for counting satisfying assignments can be given. fl Preliminary version of this paper appeared in the Proceedings of the 13th International Joint Conference on Artificial Intelligence, IJCAI93. y Supported by NSF grants CCR-89-02500 and CCR-92-00884 and by DARPA AFOSR-F4962-92-J-0466. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. Bacchus. </author> <title> Representing and Reasoning With Probabilistic Knowledge: A Logical Approach to Probabilities. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Much work has been done on how to apply this principle, and how to determine what are the basic situations <ref> [4, 1, 2] </ref>. We consider here the question of computing the degree of belief in a restricted case, in which the knowledge base consists of a propositional theory and contains no statistical information.
Reference: [2] <author> F. Bacchus, A. Grove, J. Y. Halpern, and D. Koller. </author> <title> From statistics to beliefs. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 602-608, </pages> <year> 1992. </year>
Reference-contexts: Much work has been done on how to apply this principle, and how to determine what are the basic situations <ref> [4, 1, 2] </ref>. We consider here the question of computing the degree of belief in a restricted case, in which the knowledge base consists of a propositional theory and contains no statistical information.
Reference: [3] <author> M. Cadoli. </author> <title> Semantical and computational aspects of Horn approximations. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 39-44, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Of course, computing the approximations is a hard computational problem, and this is why it is suggested as an "off-line" compilation process. Some computational aspects of computing theory approximations and reasoning with them are studied also in <ref> [3, 11, 21] </ref>. In the following we concentrate on discussing Horn approximation. For notational convenience, when no confusion can arise, we identify in this section the propositional theory with the set of its models (satisfying assignments). <p> Otherwise, the inference procedure returns "don't know". Aside from the two computational problems related to Horn approximations, namely, computing the approximations and the question of the size of the formula representing the approximations (see e.g., <ref> [32, 17, 18, 3, 21] </ref>) a third major question, that is harder to analyze, is the question of evaluating the utility of reasoning with the approximate theories.
Reference: [4] <author> R. Carnap. </author> <title> Logical Foundations of Probability. </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, </address> <year> 1950. </year>
Reference-contexts: Much work has been done on how to apply this principle, and how to determine what are the basic situations <ref> [4, 1, 2] </ref>. We consider here the question of computing the degree of belief in a restricted case, in which the knowledge base consists of a propositional theory and contains no statistical information.
Reference: [5] <author> F. G. Cooper. </author> <title> The computational complexity of probabilistic inference using Bayesian belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 393-405, </pages> <year> 1990. </year>
Reference-contexts: The most restricted form of probabilistic inference, determining P (Y = T ) for some propositional variable Y (with no explicit conditioning information), was analyzed by <ref> [5] </ref> who proved that it is NP-hard. <p> Moreover, for every fixed * &gt; 0, approximating this probability within 2 n 1* (where n is the size of the network) is NP-hard. Proof: The proof is based on the reduction from <ref> [5] </ref>. <p> j2 (1 j m), define the conditional probabilities by: P (c j = T ju 1 j = v 2 ) = 1 if the assignment u 1 j = v 1 ; u 2 j = v 2 satisfies c j 0 otherwise 6 This is not possible in <ref> [5] </ref>, since the results there hinge on the hardness of solving satisfiability, which can be done in polynomial time for 2MONCNF. 8 Finally, the conditional probability for the edges coming into the node Y is defined by P (Y = T jc 1 ; c 2 ; :::c m ) = <p> Moreover, for every fixed * &gt; 0, approximating this probability within 2 n 1* (where n is the size of the network) is NP-hard. Finally we note that as in <ref> [5] </ref>, this reduction can be modified to hold for restricted network topology (limited in-degree, out-degree, etc.) Further restrictions to the topologies of the network can be utilized if we reduce problems of counting satisfying assignments of syntactically restricted CNF formulae to that of computing the probability that a node in the
Reference: [6] <author> P. Dagum and M. Luby. </author> <title> Approximating probabilistic inference in Bayesian belief networks is NP-hard. </title> <journal> Artificial Intelligence, </journal> <volume> 60 </volume> <pages> 141-153, </pages> <year> 1993. </year>
Reference-contexts: In light of the results in Section 3, this can yield even stronger hardness results. Recently, Dagum and Luby <ref> [6] </ref> presented an even stronger result, implying the hardness of computing an absolute approximation of probabilities in Bayesian networks.
Reference: [7] <author> R. Dechter. </author> <title> Constraint networks. </title> <editor> In G. S. Shapiro, editor, </editor> <booktitle> Encyclopedia of Artificial Intelligence. </booktitle> <publisher> John Wiley and Sons, </publisher> <year> 1992. </year>
Reference-contexts: theory with respect to L is always correct if and only if the queries belong to the language L. 4.4 Constraint Satisfaction Problems Constraint satisfaction problems (CSP) provide a convenient way of expressing declarative knowledge, by focusing on local relationships among entities in the domain. 11 A constraint satisfaction problem <ref> [7] </ref> involves a set of n variables x 1 ; : : : ; x n having domains D 1 ; : : : ; D n , where each D i defines the set of values that variable x i may assume.
Reference: [8] <author> R. Dechter and J. Pearl. </author> <title> Network-based heuristics for constraint-satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <volume> 34 </volume> <pages> 1-38, </pages> <year> 1988. </year>
Reference-contexts: These techniques require, in the worst case, exponential search time, and analyzing those techniques in order to get some performance guarantees is usually hard. We exemplify how the counting point of view taken here can be used to evaluate one class of heuristics <ref> [8] </ref> and restrict its feasibility. Dechter and Pearl suggest to use counting to guide the search according to an estimate of the confidence we have that a specific solution can be extended further to a full solution.
Reference: [9] <author> R. Dechter and J. Pearl. </author> <title> Structure identification in relational data. </title> <journal> Artificial Intelligence, </journal> <volume> 58 </volume> <pages> 237-270, </pages> <year> 1992. </year>
Reference-contexts: This can be argued from the fact that the set of models of any Horn formula is closed under intersection (bitwise "and") (see, e.g., <ref> [9] </ref>). Therefore, the size of lub n is exponential in the number n of variables. This question is partially addressed in [11], where learning techniques are used to find a locally-optimal approximation.
Reference: [10] <author> M. Garey and D. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference-contexts: Proofs of the technical results appear in the Appendix. 2 The Computational Complexity of Counting Problems We give in this section a brief overview of the computational complexity of counting problems and the related problems of approximate counting and random generation of solutions. For a detailed 1 discussion consult <ref> [37, 38, 10, 14] </ref>. With a large number of decision problems we can naturally associate a counting problem. For example, counting the number of satisfying assignments of a Boolean formula, counting the number of perfect matchings in a bipartite graph and counting the number of cycles in a graph.
Reference: [11] <author> R. Greiner and D. Schuurmans. </author> <title> Learning useful Horn approximations. </title> <booktitle> In Proceedings of the International Conference on the Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 383-392, </pages> <year> 1992. </year>
Reference-contexts: Of course, computing the approximations is a hard computational problem, and this is why it is suggested as an "off-line" compilation process. Some computational aspects of computing theory approximations and reasoning with them are studied also in <ref> [3, 11, 21] </ref>. In the following we concentrate on discussing Horn approximation. For notational convenience, when no confusion can arise, we identify in this section the propositional theory with the set of its models (satisfying assignments). <p> This can be argued from the fact that the set of models of any Horn formula is closed under intersection (bitwise "and") (see, e.g., [9]). Therefore, the size of lub n is exponential in the number n of variables. This question is partially addressed in <ref> [11] </ref>, where learning techniques are used to find a locally-optimal approximation. However, in [11], as is done in general in the theory of Horn approximations, an approximation is defined in terms of containment, (that is, logical strength), and there is no guarantee that this approximation is "close" to the optimal one, <p> Therefore, the size of lub n is exponential in the number n of variables. This question is partially addressed in <ref> [11] </ref>, where learning techniques are used to find a locally-optimal approximation. However, in [11], as is done in general in the theory of Horn approximations, an approximation is defined in terms of containment, (that is, logical strength), and there is no guarantee that this approximation is "close" to the optimal one, nor that the optimal one approximates the original theory within any reasonable bound,
Reference: [12] <author> A. Grove, J. Y. Halpern, and D. Koller. </author> <title> Asymptotic conditional probabilities for first-order logic. </title> <booktitle> In ACM Symp. of the Theory of Computing, </booktitle> <volume> number 24, </volume> <pages> pages 294-305, </pages> <year> 1992. </year>
Reference-contexts: For every fixed * &gt; 0, approximating this probability within 2 n 1* is NP-hard. 4 The first order version of this problem was considered in <ref> [12] </ref> where it was shown that almost all problems one might want to ask are highly undecidable.
Reference: [13] <author> S. Holtzman. </author> <title> Intelligent Decision Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: We keep the same loose interpretation in the rest of the paper. 6 4.2 Bayesian Belief Networks Bayesian belief networks provide a natural method for representing probabilistic dependencies among a set of variables and are considered an efficient and expressive language for representing knowledge in many domains <ref> [13] </ref>. We consider here the class of multiple connected belief network, i.e., networks that contain at least one pair of nodes (variables) that have more than one undirected path connecting them.
Reference: [14] <author> M. R. Jerrum, L. G. Valiant, and V. V. Vazirani. </author> <title> Random generation of combinatorial structures from a uniform distribution. </title> <journal> Theoretical Computer Science, </journal> <volume> 43 </volume> <pages> 169-188, </pages> <year> 1986. </year>
Reference-contexts: Proofs of the technical results appear in the Appendix. 2 The Computational Complexity of Counting Problems We give in this section a brief overview of the computational complexity of counting problems and the related problems of approximate counting and random generation of solutions. For a detailed 1 discussion consult <ref> [37, 38, 10, 14] </ref>. With a large number of decision problems we can naturally associate a counting problem. For example, counting the number of satisfying assignments of a Boolean formula, counting the number of perfect matchings in a bipartite graph and counting the number of cycles in a graph. <p> This may serve also as indication that #P is outside of the polynomial hierarchy. It is therefore natural to consider the problem of approximate counting. The notion of approximation we use is that of relative approximation <ref> [15, 35, 14] </ref>. Let M; M 0 be two positive numbers and ffi 0. <p> In fact, it is no harder than solving NP-hard problems [35]. For example, there exists a polynomial time randomized algorithm that approximates the number of satisfying assignments of a DNF formula within any constant ratio <ref> [15, 14] </ref>. It is possible, though, for a #P-complete problem, even if its underlying decision problem is easy, to resist even an efficient approximate solution. An example for that was given in [14], and in this paper we exhibit a similar phenomenon. <p> It is possible, though, for a #P-complete problem, even if its underlying decision problem is easy, to resist even an efficient approximate solution. An example for that was given in <ref> [14] </ref>, and in this paper we exhibit a similar phenomenon. We prove, for various propositional languages for which solving satisfiability is easy, that it is NP-hard to approximate the number of satisfying assignments even in a very weak sense. <p> We note that a related class of problems of interest to AI, that of randomly generating solutions from a uniform distribution, was shown in <ref> [14] </ref> to be equivalent to randomized approximate counting, for a wide class of problems. (All natural problems considered here, e.g., finding satisfying assignments of Boolean formulae and various graph problems are in this class.) It is therefore enough, from the computational complexity point of view, to consider the problems of exact
Reference: [15] <author> R. Karp and M. Luby. </author> <title> Monte-carlo algorithms for enumeration and reliability problems. </title> <booktitle> In IEEE Symp. of Foundation of Computer Science, </booktitle> <volume> number 24, </volume> <pages> pages 56-64, </pages> <year> 1983. </year>
Reference-contexts: This may serve also as indication that #P is outside of the polynomial hierarchy. It is therefore natural to consider the problem of approximate counting. The notion of approximation we use is that of relative approximation <ref> [15, 35, 14] </ref>. Let M; M 0 be two positive numbers and ffi 0. <p> In fact, it is no harder than solving NP-hard problems [35]. For example, there exists a polynomial time randomized algorithm that approximates the number of satisfying assignments of a DNF formula within any constant ratio <ref> [15, 14] </ref>. It is possible, though, for a #P-complete problem, even if its underlying decision problem is easy, to resist even an efficient approximate solution. An example for that was given in [14], and in this paper we exhibit a similar phenomenon.
Reference: [16] <author> H. Kautz, M. Kearns, and B. Selman. </author> <title> Horn approximations of empirical data. </title> <journal> Artificial Intelligence, </journal> <year> 1994. </year> <month> Forthcoming. </month>
Reference-contexts: Therefore, for all the 2 jSj 1 queries ff s , reasoning with approximate theories returns "don't know". In <ref> [16] </ref> it is shown that, for a family of propositional languages L which consists of kHorn formulae (all Horn formulae with up to k literals in a clause), one can construct examples of theories for which j lub n j is exponential in the number of variables, where lub is the
Reference: [17] <author> H. Kautz and B. Selman. </author> <title> A general framework for knowledge compilation. </title> <booktitle> In Proceedings of the International Workshop on Processing Declarative Knowledge, </booktitle> <address> Kaiserlautern, Germany, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: In general, every node can be associated with a conditional probability table that is exponential in the size of the network. 9 4.3 Reasoning with Approximate Theories The theory of reasoning with approximate theories was introduced by Selman and Kautz in a series of papers <ref> [32, 17, 18] </ref> as a new approach to developing efficient knowledge representation systems. The goal is to speed up inference by replacing the original theory by two theories that belong to a different propositional language L and approximate the original theory. <p> Otherwise, the inference procedure returns "don't know". Aside from the two computational problems related to Horn approximations, namely, computing the approximations and the question of the size of the formula representing the approximations (see e.g., <ref> [32, 17, 18, 3, 21] </ref>) a third major question, that is harder to analyze, is the question of evaluating the utility of reasoning with the approximate theories.
Reference: [18] <author> H. Kautz and B. Selman. </author> <title> Forming concepts for fast inference. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 786-793, </pages> <year> 1992. </year>
Reference-contexts: In general, every node can be associated with a conditional probability table that is exponential in the size of the network. 9 4.3 Reasoning with Approximate Theories The theory of reasoning with approximate theories was introduced by Selman and Kautz in a series of papers <ref> [32, 17, 18] </ref> as a new approach to developing efficient knowledge representation systems. The goal is to speed up inference by replacing the original theory by two theories that belong to a different propositional language L and approximate the original theory. <p> Otherwise, the inference procedure returns "don't know". Aside from the two computational problems related to Horn approximations, namely, computing the approximations and the question of the size of the formula representing the approximations (see e.g., <ref> [32, 17, 18, 3, 21] </ref>) a third major question, that is harder to analyze, is the question of evaluating the utility of reasoning with the approximate theories.
Reference: [19] <author> H. Kautz and B. Selman. </author> <title> An empirical evaluation of knowledge compilation by theory approximation. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 155-161, </pages> <year> 1994. </year>
Reference-contexts: Thus it motivates an investigation in the direction of reasoning with restricted queries, where it might be possible to avoid these difficulties. Indeed, in <ref> [19] </ref> an experimental analysis is presented in which, under severe restrictions on the classes of queries allowed, reasoning with approximate theories is shown to succeed on a large percentage of the queries.
Reference: [20] <author> R. Khardon and D. Roth. </author> <title> Learning to reason. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 682-687, </pages> <year> 1994. </year> <note> Submitted for publication. Full version: Technical Report TR-02-94, </note> <institution> Aiken Computation Lab., Harvard University, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: One way to get around the difficulties presented here is to allow the reasoner other ways to access the "world", instead, or in addition to the fixed (formula-based, Bayesian network-based, etc.) knowledge-based approach that we analyze here. Promising results in this direction are presented in <ref> [20] </ref>. Acknowledgments I am very grateful to Les Valiant for very helpful discussions and for his comments on an earlier draft of this paper. I would also like to thank Karen Daniels, Roni Khardon and Salil Vadhan for their comments on an earlier draft of this paper. 14
Reference: [21] <author> R. Khardon and D. Roth. </author> <title> Reasoning with models. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 1148-1153, </pages> <year> 1994. </year> <note> Submitted for publication. Full version: Technical Report TR-01-94, </note> <institution> Aiken Computation Lab., Harvard University, </institution> <month> January </month> <year> 1994. </year> <month> 15 </month>
Reference-contexts: Of course, computing the approximations is a hard computational problem, and this is why it is suggested as an "off-line" compilation process. Some computational aspects of computing theory approximations and reasoning with them are studied also in <ref> [3, 11, 21] </ref>. In the following we concentrate on discussing Horn approximation. For notational convenience, when no confusion can arise, we identify in this section the propositional theory with the set of its models (satisfying assignments). <p> Otherwise, the inference procedure returns "don't know". Aside from the two computational problems related to Horn approximations, namely, computing the approximations and the question of the size of the formula representing the approximations (see e.g., <ref> [32, 17, 18, 3, 21] </ref>) a third major question, that is harder to analyze, is the question of evaluating the utility of reasoning with the approximate theories. <p> Using Proposition 4.5, this leads to a double exponential number of queries for which reasoning with approximate theories returns "don't know". In <ref> [21] </ref> tools are developed that allow for a construction of such examples for every language L with respect to which we want to consider theory approximation. <p> Indeed, in [19] an experimental analysis is presented in which, under severe restrictions on the classes of queries allowed, reasoning with approximate theories is shown to succeed on a large percentage of the queries. In <ref> [21] </ref> a general analysis is developed and it is shown, in particular, that reasoning with the least upper bound of a theory with respect to L is always correct if and only if the queries belong to the language L. 4.4 Constraint Satisfaction Problems Constraint satisfaction problems (CSP) provide a convenient <p> This is motivated also by the results in Section 4.3 that suggest that a possible approach to allow for efficient reasoning might be to constrain the queries (rather than the "world"). Indeed, partly motivated by these results, in <ref> [21] </ref> it is shown how constraining the queries gets around the difficulties presented in Section 4.3 and leads to correct reasoning with approximate theories. A possible interpretation of the surprising and widely applicable results presented here is that we need to reconsider the way we model the reasoning problem.
Reference: [22] <author> H. Levesque. </author> <title> Making believers out of computers. </title> <journal> Artificial Intelligence, </journal> <volume> 30 </volume> <pages> 81-108, </pages> <year> 1986. </year>
Reference-contexts: 1 Introduction Investigating the computational cost of tasks that are of interest to AI has been argued <ref> [22, 39] </ref> to be essential to our understanding and our ability to characterize these tasks and to finding knowledge representation systems adequate for them.
Reference: [23] <author> U. Montanari. </author> <title> Networks of constraint: Fundamental properties and applications to picture processing. </title> <journal> Inf. Sci., </journal> <volume> 7 </volume> <pages> 95-132, </pages> <year> 1974. </year>
Reference-contexts: More significantly, in case the original problem possesses a non-trivial structure, the number of solutions 9 Not every n-ary relation can be represented by a network of binary constraints with n-variables <ref> [23] </ref>. 10 We comment, though, that Valiant's results ([38], Fact 7) imply that under simple conditions (e.g., when finding one solution is easy and the problem satisfies a form of self-reducibility), enumerating the solutions is polynomial in their number even when the counting problem is hard.
Reference: [24] <author> N. J. Nilsson. </author> <title> Probabilistic logic. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 71-87, </pages> <year> 1986. </year>
Reference-contexts: This situation is natural in various AI problems 5 such as planning, expert systems and others, where the actions an agent takes may depend crucially on this degree of belief. In <ref> [24] </ref> it is suggested that the kind of reasoning used in expert system is the following: "we are given a knowledge base of facts (possibly, with their associated probabilities); we want to compute the probability of some sentence of interest. ...
Reference: [25] <author> P. Orponen. </author> <title> Dempster`s rule of combination is #P-complete. </title> <journal> Artificial Intelligence, </journal> <volume> 44 </volume> <pages> 245-253, </pages> <year> 1990. </year>
Reference-contexts: Orponen <ref> [25] </ref> shows, by reduction, that the problem of computing Dempster's rule of combination, the main tool in the Dempster-Shafer theory of evidence is at least as hard as the problem of computing the number of satisfying assignments of a propositional CNF formula 11 . <p> The problem is left open (see Figure 1) and its solution might be used to develop efficient algorithms for constraint satisfaction problems, for example. The 11 A similar result, using a different reduction, was proved independently by Provan [30]. We thank Greg Provan for bringing <ref> [25, 30] </ref> to our attention. 13 positive results presented here are important therefore not only for pointing out the tractability frontiers, but also since they provide a collection of techniques that can be used to further enhance our understanding of these problems and develop new results, possibly, for other problems of
Reference: [26] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufman, </publisher> <year> 1988. </year>
Reference-contexts: For definitions and an elaborate discussion of Bayesian belief networks, the expressiveness of this representation, and the type of inference one can utilize using it, see <ref> [26] </ref>. A Bayesian belief network (casual network) consists of a graphical structure augmented by a set of probabilities. The graphical structure is a directed acyclic graph (DAG) in which nodes represent random variables (domain variables) and edges represent the existence of direct casual influence between the linked variables.
Reference: [27] <author> J. Pearl. </author> <title> Reasoning with belief functions: An analysis of compatibility. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 4 </volume> <pages> 343-389, </pages> <year> 1990. </year>
Reference-contexts: It is worth noticing, for example, that while there is an active discussion in the approximate reasoning community as for differences in the semantical basis of the Dempster-Shafer theory and the Bayesian approach, (see, e.g., <ref> [27, 33, 31] </ref>) we show here that there is one computational problem underlying both approaches: computing inference is equivalent to counting satisfying assignments of a theory. Moreover, we have shown that this approach is valuable in evaluating techniques that use approximations in an effort to avoid computational difficulties.
Reference: [28] <author> D. Poole. </author> <title> On the hardness of approximate reasoning. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 607-612, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: The first might include constraining the distributions we can represent in our belief networks (e.g., <ref> [28] </ref>), while the second could imply studying restrictions on the type of queries we need to respond to. This is motivated also by the results in Section 4.3 that suggest that a possible approach to allow for efficient reasoning might be to constrain the queries (rather than the "world").
Reference: [29] <author> J. S. Provan and M. O. Ball. </author> <title> The complexity of counting cuts and of computing the probability that a graph is connected. </title> <journal> SIAM Journal of Computing, </journal> <volume> 12(4) </volume> <pages> 777-788, </pages> <month> Nov. </month> <year> 1983. </year>
Reference-contexts: More significantly, it was also shown that the counting versions of many problems in P are also complete for the same class. Examples of the latter include counting the number of satisfying assignments of a DNF formula, counting the number of cycles in a graph and many other problems <ref> [37, 38, 29] </ref>. Problems that are #P-complete are at least as hard as NP-complete problems, but probably much harder. <p> Theorem 3.1 [Hardness of Exact Counting] Let 2 L be a propositional formula on n variables. If L is one of the following propositional languages, counting the number of satisfying assignments of is complete for #P: (1) L = 2MONCNF [38] (2) L = 2BPMONCNF <ref> [29] </ref> (3) L = 2HORN (4) L = 3-2HORN (5) L = 4-2MON Theorem 3.2 [Hardness of Approximation] Let 2 L be a propositional formula on n variables, and let * &gt; 0 be any constant.
Reference: [30] <author> M. G. Provan. </author> <title> A logical-based analysis of Dempster-Shafer theory. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 4 </volume> <pages> 451-498, </pages> <year> 1990. </year>
Reference-contexts: The problem is left open (see Figure 1) and its solution might be used to develop efficient algorithms for constraint satisfaction problems, for example. The 11 A similar result, using a different reduction, was proved independently by Provan <ref> [30] </ref>. <p> The problem is left open (see Figure 1) and its solution might be used to develop efficient algorithms for constraint satisfaction problems, for example. The 11 A similar result, using a different reduction, was proved independently by Provan [30]. We thank Greg Provan for bringing <ref> [25, 30] </ref> to our attention. 13 positive results presented here are important therefore not only for pointing out the tractability frontiers, but also since they provide a collection of techniques that can be used to further enhance our understanding of these problems and develop new results, possibly, for other problems of
Reference: [31] <author> M. G. Provan. </author> <title> The validity of Dempster-Shafer belief functions. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 6 </volume> <pages> 389-399, </pages> <year> 1992. </year>
Reference-contexts: It is worth noticing, for example, that while there is an active discussion in the approximate reasoning community as for differences in the semantical basis of the Dempster-Shafer theory and the Bayesian approach, (see, e.g., <ref> [27, 33, 31] </ref>) we show here that there is one computational problem underlying both approaches: computing inference is equivalent to counting satisfying assignments of a theory. Moreover, we have shown that this approach is valuable in evaluating techniques that use approximations in an effort to avoid computational difficulties.
Reference: [32] <author> B. Selman and H. Kautz. </author> <title> Knowledge compilation using Horn approximations. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 904-909, </pages> <year> 1991. </year>
Reference-contexts: In general, every node can be associated with a conditional probability table that is exponential in the size of the network. 9 4.3 Reasoning with Approximate Theories The theory of reasoning with approximate theories was introduced by Selman and Kautz in a series of papers <ref> [32, 17, 18] </ref> as a new approach to developing efficient knowledge representation systems. The goal is to speed up inference by replacing the original theory by two theories that belong to a different propositional language L and approximate the original theory. <p> Otherwise, the inference procedure returns "don't know". Aside from the two computational problems related to Horn approximations, namely, computing the approximations and the question of the size of the formula representing the approximations (see e.g., <ref> [32, 17, 18, 3, 21] </ref>) a third major question, that is harder to analyze, is the question of evaluating the utility of reasoning with the approximate theories.
Reference: [33] <author> G. Shafer. </author> <title> Perspectives of the theory and practice of belief functions. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 4 </volume> <pages> 323-362, </pages> <year> 1990. </year>
Reference-contexts: It is worth noticing, for example, that while there is an active discussion in the approximate reasoning community as for differences in the semantical basis of the Dempster-Shafer theory and the Bayesian approach, (see, e.g., <ref> [27, 33, 31] </ref>) we show here that there is one computational problem underlying both approaches: computing inference is equivalent to counting satisfying assignments of a theory. Moreover, we have shown that this approach is valuable in evaluating techniques that use approximations in an effort to avoid computational difficulties.
Reference: [34] <author> A. Sinclair. </author> <title> Randomized Algorithms for Counting and Generating Combinatorial Structures. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Edinburgh, </institution> <year> 1988. </year>
Reference: [35] <author> L. Stockmeyer. </author> <title> On approximation algorithms for #P. </title> <journal> SIAM Journal of Computing, </journal> <volume> 14 </volume> <pages> 849-861, </pages> <year> 1985. </year>
Reference-contexts: This may serve also as indication that #P is outside of the polynomial hierarchy. It is therefore natural to consider the problem of approximate counting. The notion of approximation we use is that of relative approximation <ref> [15, 35, 14] </ref>. Let M; M 0 be two positive numbers and ffi 0. <p> We say that M 0 approximates M within ffi when M 0 =(1 + ffi) M M 0 (1 + ffi): Indeed, approximating a solution to a #P problem might be easier than finding an exact solution. In fact, it is no harder than solving NP-hard problems <ref> [35] </ref>. For example, there exists a polynomial time randomized algorithm that approximates the number of satisfying assignments of a DNF formula within any constant ratio [15, 14]. It is possible, though, for a #P-complete problem, even if its underlying decision problem is easy, to resist even an efficient approximate solution.
Reference: [36] <author> S. </author> <title> Toda. </title> <booktitle> On the computational power of PP and P. In IEEE Symp. of Foundation of Computer Science, </booktitle> <volume> number 30, </volume> <pages> pages 514-519, </pages> <year> 1989. </year>
Reference-contexts: Problems that are #P-complete are at least as hard as NP-complete problems, but probably much harder. Evidence to the hardness of problems in #P is supplied by a result of <ref> [36] </ref> which implies that one call to a #P oracle suffices to solve any problem in the polynomial hierarchy in deterministic polynomial time. This may serve also as indication that #P is outside of the polynomial hierarchy. It is therefore natural to consider the problem of approximate counting.
Reference: [37] <author> L. G. Valiant. </author> <title> The complexity of computing the permanent. </title> <journal> Theoretical Computer Science, </journal> <volume> 8 </volume> <pages> 189-201, </pages> <year> 1979. </year>
Reference-contexts: Proofs of the technical results appear in the Appendix. 2 The Computational Complexity of Counting Problems We give in this section a brief overview of the computational complexity of counting problems and the related problems of approximate counting and random generation of solutions. For a detailed 1 discussion consult <ref> [37, 38, 10, 14] </ref>. With a large number of decision problems we can naturally associate a counting problem. For example, counting the number of satisfying assignments of a Boolean formula, counting the number of perfect matchings in a bipartite graph and counting the number of cycles in a graph. <p> Clearly, the counting version is at least as hard as the decision problem but in many cases, even when the decision problem is easy, no computationally efficient method is known for counting the number of distinct solutions. The class #P was introduced by Valiant <ref> [37, 38] </ref> in an effort to explain these phenomena. <p> More significantly, it was also shown that the counting versions of many problems in P are also complete for the same class. Examples of the latter include counting the number of satisfying assignments of a DNF formula, counting the number of cycles in a graph and many other problems <ref> [37, 38, 29] </ref>. Problems that are #P-complete are at least as hard as NP-complete problems, but probably much harder. <p> In particular, when computing the conditional probability P (Y = yjX = x), of the event Y = y given evidence X = x, since P (Y = yjX = x) = P (X = x) 1 In <ref> [37] </ref> the definition is given in terms of "counting Turing machines". 2 we conclude that: Proposition 2.1 The complexity of computing relative approximation of the conditional probability P (Y = yjX = x) is polynomially related 2 to that of computing relative approximation of the unconditional probability P (Y = y).
Reference: [38] <author> L. G. Valiant. </author> <title> The complexity of enumeration and reliability problems. </title> <journal> SIAM Journal of Computing, </journal> <volume> 8 </volume> <pages> 410-421, </pages> <year> 1979. </year>
Reference-contexts: Proofs of the technical results appear in the Appendix. 2 The Computational Complexity of Counting Problems We give in this section a brief overview of the computational complexity of counting problems and the related problems of approximate counting and random generation of solutions. For a detailed 1 discussion consult <ref> [37, 38, 10, 14] </ref>. With a large number of decision problems we can naturally associate a counting problem. For example, counting the number of satisfying assignments of a Boolean formula, counting the number of perfect matchings in a bipartite graph and counting the number of cycles in a graph. <p> Clearly, the counting version is at least as hard as the decision problem but in many cases, even when the decision problem is easy, no computationally efficient method is known for counting the number of distinct solutions. The class #P was introduced by Valiant <ref> [37, 38] </ref> in an effort to explain these phenomena. <p> More significantly, it was also shown that the counting versions of many problems in P are also complete for the same class. Examples of the latter include counting the number of satisfying assignments of a DNF formula, counting the number of cycles in a graph and many other problems <ref> [37, 38, 29] </ref>. Problems that are #P-complete are at least as hard as NP-complete problems, but probably much harder. <p> Proofs are given in the Appendix. Theorem 3.1 [Hardness of Exact Counting] Let 2 L be a propositional formula on n variables. If L is one of the following propositional languages, counting the number of satisfying assignments of is complete for #P: (1) L = 2MONCNF <ref> [38] </ref> (2) L = 2BPMONCNF [29] (3) L = 2HORN (4) L = 3-2HORN (5) L = 4-2MON Theorem 3.2 [Hardness of Approximation] Let 2 L be a propositional formula on n variables, and let * &gt; 0 be any constant.
Reference: [39] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> Nov. </month> <year> 1984. </year>
Reference-contexts: 1 Introduction Investigating the computational cost of tasks that are of interest to AI has been argued <ref> [22, 39] </ref> to be essential to our understanding and our ability to characterize these tasks and to finding knowledge representation systems adequate for them.
References-found: 39

