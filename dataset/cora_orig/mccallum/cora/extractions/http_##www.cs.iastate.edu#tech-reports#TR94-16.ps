URL: http://www.cs.iastate.edu/tech-reports/TR94-16.ps
Refering-URL: http://www.cs.iastate.edu/tech-reports/catalog.html
Root-URL: http://www.cs.iastate.edu
Title: Symbolic Artificial Intelligence, Connectionist Networks and Beyond TR94-16  
Author: Vasant Honavar and Leonard Uhr 
Address: 226 Atanasoff Ames, IA 50011  
Affiliation: Iowa State University of Science and Technology Department of Computer Science  
Date: August 18, 1994  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Almasi, G. S. & Gottlieb, A. </author> <year> (1989). </year> <title> Highly Parallel Computing. </title> <address> New York: Benjamin-Cummings. </address>
Reference-contexts: output via their output links. 4.1 Nodes in a CN Perform Simple Numerical Computations The input to an n-input node or neuron n j in a CN is a pattern vector X j 2 &lt; n or in the case of binary patterns, by a binary vector X j 2 <ref> [0; 1] </ref> n . Each neuron computes a relatively simple function of its inputs and transmits outputs to other neurons to which it is connected via its output links. A variety of neuron functions are used in practice. The most commonly used are the linear, the threshold, and the sigmoid.
Reference: [2] <author> Arbib, M. A. </author> <year> (1972). </year> <title> The Metaphorical Brain. </title> <address> New York: </address> <publisher> Wiley-Interscience. </publisher>
Reference-contexts: The term hybrid is beginning to be used for systems that in some way try to combine SAI and CN. If any of the above is called a hybrid probably all of the others should also. But usually hybrid refers to systems of type <ref> [2] </ref> or [3]. Types [3] and [4] would appear to be better than [2] (although harder to realize), since they would probably be more efficient and more elegant. <p> If any of the above is called a hybrid probably all of the others should also. But usually hybrid refers to systems of type <ref> [2] </ref> or [3]. Types [3] and [4] would appear to be better than [2] (although harder to realize), since they would probably be more efficient and more elegant. Thus the capabilities of both SAI and CN should be combined by tearing them apart to the essential components of their underlying processes and integrating these as closely as possible.
Reference: [3] <author> Arbib, M. A. </author> <year> (1994). </year> <title> Schema Theory: Cooperative Computation for Brain Theory and Distributed AI. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. and Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference-contexts: The term hybrid is beginning to be used for systems that in some way try to combine SAI and CN. If any of the above is called a hybrid probably all of the others should also. But usually hybrid refers to systems of type [2] or <ref> [3] </ref>. Types [3] and [4] would appear to be better than [2] (although harder to realize), since they would probably be more efficient and more elegant. <p> The term hybrid is beginning to be used for systems that in some way try to combine SAI and CN. If any of the above is called a hybrid probably all of the others should also. But usually hybrid refers to systems of type [2] or <ref> [3] </ref>. Types [3] and [4] would appear to be better than [2] (although harder to realize), since they would probably be more efficient and more elegant.
Reference: [4] <author> Balakrishnan, K. & Honavar, V. </author> <year> (1994). </year> <title> Evolutionary Approaches to the Exploration of the Design Space of Artificial Neural Networks. </title> <note> In preparation. </note>
Reference-contexts: If any of the above is called a hybrid probably all of the others should also. But usually hybrid refers to systems of type [2] or [3]. Types [3] and <ref> [4] </ref> would appear to be better than [2] (although harder to realize), since they would probably be more efficient and more elegant.
Reference: [5] <author> Ballard, D. & Brown, C. </author> <booktitle> (1982) Computer Vision. </booktitle> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall. </publisher>
Reference: [6] <author> Barnden, J. A. </author> <year> (1994). </year> <title> How Might Connectionist Networks Represent Propositional Attitudes? In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [7] <author> Boden, M. </author> <year> (1994). </year> <title> Horses of a Different Color? In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [8] <author> Booker, L. E., Riolo, R. L., & Holland, J. H. </author> <year> (1994). </year> <title> Learning and Representation in Classifier Systems. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. and Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [9] <author> Bookman, L. </author> <year> (1994). </year> <title> A Framework for Integrating Relational and Associational Knowledge for Comprehension. In: Computational Architectures Integrating Symbolic and Neural Processes. Sun, </title> <editor> R. & Bookman, L. (Ed.) </editor> <address> Boston: </address> <publisher> Kluwer. </publisher> <address> 34 Chapter 1 </address>
Reference: [10] <author> Buchanan, B. G. & Wilkins, D. C. </author> <year> (1993). </year> <title> Readings in Knowledge Acquisition and Learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [11] <author> Carpenter, G. & Grossberg, S. </author> <year> (1994). </year> <title> Integrating Symbolic and Neural Processes in a Self-Organizing Architecture for Pattern Recognition and Prediction. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [12] <author> Chandrasekaran, B. Josephson, S. G. </author> <year> (1994). </year> <title> Architecture of Intelligence: The Problems and Current Approaches to Solutions. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [13] <author> Chen, C., & Honavar, V. </author> <year> (1994). </year> <title> Neural Networks for Inference. </title> <note> In preparation. </note>
Reference: [14] <author> Churchland, P. S. & Sejnowski, T. J. </author> <year> (1992). </year> <title> The Computational Brain. </title> <address> Boston, MA: </address> <publisher> MIT Press. </publisher>
Reference: [15] <author> Cohen, D. </author> <year> (1986). </year> <title> Introduction to Computer Theory. </title> <address> New York: </address> <publisher> Wiley. </publisher>
Reference: [16] <author> Dolan, C. P. & Smolensky, P. </author> <year> (1989). </year> <title> Tensor product production system: a modular architecture and representation. </title> <journal> Connection Science, </journal> <volume> 1 </volume> <pages> 53-58. </pages>
Reference: [17] <author> Dyer, M. </author> <year> (1994). </year> <title> Grounding Language in Perception. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [18] <author> Feigenbaum, E. A. </author> <year> (1963). </year> <title> In: Computers and Thought. </title> <editor> Feigenbaum, E. A. & Feldman, J. (Ed.) </editor> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference: [19] <author> Feldmann, J. A. & Ballard, D. H. </author> <year> (1982). </year> <title> Connectionist models and their properties. </title> <journal> Cognitive Science, </journal> <volume> 6 </volume> <pages> 205-264. </pages>
Reference: [20] <author> Fodor, J. </author> <year> (1976). </year> <booktitle> The Language of Thought. </booktitle> <address> Boston, MA: </address> <publisher> Harvard University Press. </publisher>
Reference: [21] <author> Fodor, J. & Pylyshyn, Z. W. </author> <year> (1988). </year> <title> Connectionism and cognitive architecture: a critical analysis. In: Connections and Symbols. Pinker, </title> <editor> S. & Mehler, J. (Ed.) </editor> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: [22] <author> Forgy, C. L. </author> <year> (1982). </year> <title> RETE: A Fast Algorithm for the Many Pattern/Many Object Pattern Match Problem. </title> <journal> Artificial Intelligence, </journal> <volume> 19 </volume> <pages> 17-37. </pages>
Reference: [23] <author> Fu, K. S. </author> <year> (1982). </year> <title> Syntactic Pattern Recognition and Applications. Engle-wood Cliffs, NJ: Prentice Hall. Beyond Symbolic AI and Connectionist Networks 35 </title>
Reference: [24] <author> Gallant, S. </author> <year> (1993). </year> <title> Neural Networks and Expert Systems. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: [25] <author> Genesereth, M. R., & Nilsson, N. J. </author> <year> (1987). </year> <booktitle> Logical Foundations of Artificial Intelligence. </booktitle> <address> Palo Alto, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [26] <author> Ginsberg, M. </author> <year> (1993). </year> <booktitle> Essentials of Artificial Intelligence. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [27] <author> Goldfarb, L. & Nigam, S. </author> <year> (1994). </year> <title> The Unified Learning Paradigm: A Foundation for AI. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [28] <author> Goonatilake, S. & Khebbal, S. </author> <year> (1994). </year> <title> (Ed.) Hybrid Intelligent Systems. </title> <publisher> London: Wiley. </publisher>
Reference: [29] <author> Greenough, W. T. & Bailey, C. H. </author> <year> (1988). </year> <title> The Anatomy of Memory: Convergence of Results Across a Diversity of Tests. </title> <booktitle> Trends in Neuroscience 11, </booktitle> <pages> 142-147. </pages>
Reference: [30] <author> Grossberg, S. </author> <year> (1982). </year> <title> Studies of Mind and Brain. </title> <address> Boston, MA: </address> <publisher> Reidel. </publisher>
Reference: [31] <author> Hanson, S. J. & Burr, D. </author> <year> (1990). </year> <title> What Connectionist Models Learn: Learning and Representation in Connectionist Networks. </title> <journal> Behavior and Brain Sciences, </journal> <volume> 13 </volume> <pages> 1-54. </pages>
Reference: [32] <author> Harnad, S. </author> <year> (1990). </year> <title> The Symbol Grounding Problem. </title> <journal> Physica D, </journal> <volume> 42 </volume> <pages> 335-346. </pages>
Reference: [33] <author> Harnad, S., Hanson, S. J., & Lubin, J. </author> <year> (1994). </year> <title> Learned Categorical Perception in Neural Nets: Implications for Symbol Grounding. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [34] <author> Haykin, S. </author> <year> (1994). </year> <title> Neural Networks. </title> <address> New York: </address> <publisher> Macmillan. </publisher>
Reference: [35] <author> Hewitt, C. </author> <year> (1977). </year> <title> Viewing Control Structures as Patterns of Passing Messages. </title> <journal> Artificial Intelligence, </journal> <volume> 8 </volume> <pages> 232-364. </pages>
Reference: [36] <author> Hillis, D. </author> <year> (1985). </year> <title> The Connection Machine. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: [37] <author> Holland, J. H. </author> <year> (1975). </year> <booktitle> Adaptation in Natural and Artificial Systems. </booktitle> <address> Ann Arbor, MI: </address> <institution> University of Michigan Press. </institution> <note> 36 Chapter 1 </note>
Reference: [38] <author> Hopfield, J. J. </author> <year> (1982). </year> <title> Neural Networks and Physical Systems With Emergent Collective Computational Abilities. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <volume> 79 </volume> <pages> 2554-2558. </pages>
Reference: [39] <author> Honavar, V. </author> <year> (1989). </year> <title> Perceptual Development and Learning: From Behavioral, Neurophysiological and Morphological Evidence to Computational Models. </title> <type> Tech. Rep. 818. </type> <institution> Computer Sciences Dept., University of Wiscon-sin, Madison, Wisconsin. </institution>
Reference: [40] <author> Honavar, V. </author> <year> (1990). </year> <title> Generative Learning Structures for Generalized Connectionist Networks. </title> <type> Ph.D. Dissertation. </type> <institution> University of Wisconsin, Madison, Wisconsin. </institution>
Reference: [41] <author> Honavar, V. </author> <year> (1992a). </year> <title> Some Biases For Efficient Learning of Spatial, Temporal, and Spatio-Temporal Patterns. </title> <booktitle> In: Proceedings of the International Joint Conference on Neural Networks. </booktitle> <address> Beijing, China. </address>
Reference: [42] <author> Honavar, V. </author> <year> (1992b). </year> <title> Inductive Learning Using Generalized Distance Measures. </title> <booktitle> In: Proceedings of the SPIE Conference on Adaptive and Learning Systems. </booktitle> <address> Orlando, Florida. </address>
Reference: [43] <author> Honavar, V. </author> <year> (1994a). </year> <title> Toward Learning Systems That Use Multiple Strategies and Representations. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V., & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [44] <author> Honavar, V. </author> <year> (1994b). </year> <title> Symbolic Artificial Intelligence and Numerical Artificial Neural Networks: Towards a Resolution of the Dichotomy. In: Computational Architectures Integrating Symbolic and Neural Processes. Sun, </title> <editor> R., & Bookman, L. (Ed.) </editor> <address> New York: </address> <publisher> Kluwer. </publisher>
Reference: [45] <author> Honavar, V. & Uhr, L. </author> <year> (1989a). </year> <title> Brain-Structured Connectionist Networks that Perceive and Learn. </title> <journal> Connection Science, </journal> <volume> 1 </volume> <pages> 139-159. </pages>
Reference: [46] <author> Honavar, V. & Uhr, L. </author> <year> (1989b). </year> <title> Generation, Local Receptive Fields, and Global Convergence Improve Perceptual Learning in Connectionist Networks. </title> <booktitle> In: Proceedings of the 1989 International Joint Conference on Artificial Intelligence, </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [47] <author> Honavar, V. & Uhr, L. </author> <year> (1990a). </year> <title> Symbol Processing Systems, Connectionist Networks, and Generalized Connectionist Networks. </title> <type> Tech. Rep. 90-23. </type> <institution> Department of Computer Science, Iowa State University, Ames, Iowa. </institution>
Reference: [48] <author> Honavar, V. & Uhr, L. </author> <year> (1990b). </year> <title> Coordination and Control Structures and Processes: Possibilities for Connectionist Networks. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 277-302. </pages> <booktitle> Beyond Symbolic AI and Connectionist Networks 37 </booktitle>
Reference: [49] <author> Honavar, V. & Uhr, L. </author> <title> (1993) Generative Learning Structures and Processes for Generalized Connectionist Networks, </title> <journal> Information Sciences, </journal> <volume> 70 </volume> <pages> 75-108. </pages>
Reference: [50] <author> Honavar, V. & Uhr, L. </author> <year> (1994a). </year> <title> (Ed.) Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. </title> <address> San Diego, CA.: </address> <publisher> Academic Press. </publisher>
Reference: [51] <author> Johnson-Laird, P. & Byrne, J. </author> <year> (1991). </year> <title> Deduction. </title> <address> New York: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference: [52] <author> Klir, G. J. </author> <year> (1985). </year> <title> Architecture of Systems Problem Solving. </title> <address> New York: </address> <publisher> Plenum. </publisher>
Reference: [53] <author> Kowalski, R. A. </author> <year> (1977). </year> <title> Predicate Logic as a Programming Language. </title> <publisher> Am-sterdam: North-Holland. </publisher>
Reference: [54] <author> Kung, S. Y. </author> <year> (1993). </year> <title> Digital Neural Networks. </title> <address> New York: </address> <publisher> Prentice Hall. </publisher>
Reference: [55] <author> Levine, D. S. Aparicioiv, M. </author> <year> (1994). </year> <title> (Ed.) Neural Networks for Knowledge Representation. </title> <address> New York: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference: [56] <author> Maclennan, B. J. </author> <year> (1994). </year> <title> Image and Symbol Continuous Computation and the Emergence of the Discrete. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [57] <author> McCulloch, W. S. and Pitts, W. </author> <year> (1943). </year> <title> A Logical Calculus of the Ideas Immanent in Neural Activity. </title> <journal> Bulletin of Mathematical Biophysics, </journal> <volume> 5 </volume> <pages> 115-137. </pages>
Reference: [58] <editor> McClelland J., Rumelhart, D. et al. (1986). (Ed.) </editor> <booktitle> Parallel Distributed Processing. </booktitle> <address> Boston, MA: </address> <publisher> MIT Press. </publisher>
Reference: [59] <author> McKenna, T. </author> <year> (1994). </year> <title> The Role of Inter-Disciplinary Research Involving Neuroscience in the Design of Intelligent Systems. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [60] <author> Mead, C. </author> <year> (1989). </year> <title> Analog VLSI and Neural Systems. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference: [61] <author> Medsker, L. </author> <year> (1994). </year> <title> Hybrid Neural Network and Expert Systems. </title> <address> Boston, MA: </address> <publisher> Kluwer. </publisher> <address> 38 Chapter 1 </address>
Reference: [62] <author> Miikkulainen, R. </author> <year> (1994). </year> <title> Integrated Connectionist Models: Building AI Systems on Subsymbolic Foundations. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [63] <author> Michalski, R. S. </author> <year> (1993). </year> <title> Toward a Unified Theory of Learning: Multi-Strategy Task-Adaptive Learning. In: Readings in Knowledge Acquisition and Learning. Buchanan, </title> <editor> B. G., & Wilkins, D. C. (Ed.) </editor> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [64] <author> Miclet, L. </author> <year> (1986). </year> <title> Structural Methods in Pattern Recognition. </title> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference: [65] <author> Minsky, M. </author> <year> (1963). </year> <title> Steps Toward Artificial Intelligence. In: Computers and Thought. </title> <editor> Feigenbaum, E. A. & Feldman, J. (Ed.) </editor> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference: [66] <author> Minsky, M. </author> <year> (1975). </year> <title> A Framework for Representing Knowledge. In: The Psychology of Computer Vision. </title> <editor> Winston, P. H. (Ed). </editor> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference: [67] <author> Minsky, M. </author> <year> (1986). </year> <title> Society of Mind. </title> <address> New York: </address> <publisher> Basic Books. </publisher>
Reference: [68] <author> Newell, A. </author> <year> (1980). </year> <title> Symbol Systems. </title> <journal> Cognitive Science, </journal> <volume> 4 </volume> <pages> 135-183. </pages>
Reference: [69] <author> Newell, A. </author> <year> (1990). </year> <title> Unified Theories of Cognition. </title> <address> Cambridge, MA: </address> <publisher> Harvard University Press. </publisher>
Reference: [70] <author> Newell, A., Shaw, J. C., & Simon, H. </author> <year> (1963). </year> <title> In: Computers and Thought. </title> <editor> Feigenbaum, E. A., & Feldman, J. (Ed.) </editor> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference: [71] <author> Norman, D. A. </author> <year> (1986). </year> <title> Reflections on Cognition and Parallel Distributed Processing. In: Parallel Distributed Processing. </title> <editor> McClelland, J., Rumelhart. D. et al. (Ed.). </editor> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: [72] <author> Norvig, P. </author> <year> (1992). </year> <booktitle> Paradigms in Artificial Intelligence Programming. </booktitle> <address> Palo Alto, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [73] <author> Oden, G. C. </author> <year> (1994). </year> <title> Why the Difference Between Connectionism and Anything Else is More Than You Might Think But Less Than You Might Hope. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [74] <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems. </title> <address> Palo Alto, CA: Morgan Kaufmann. </address> <booktitle> Beyond Symbolic AI and Connectionist Networks 39 </booktitle>
Reference: [75] <author> Pinkas, G. </author> <year> (1994). </year> <title> A Fault-Tolerant Connectionist Architecture for the Construction of Logic Proofs. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [76] <author> Pollack, J. </author> <year> (1990). </year> <title> Recursive Distributed Representations. </title> <journal> Artificial Intelligence, </journal> <volume> 46 </volume> <pages> 77-105. </pages>
Reference: [77] <author> Quillian, M. R. </author> <year> (1968). </year> <title> Semantic Memory. In: Semantic Information Processing. </title> <editor> Minsky, M. (Ed.) </editor> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: [78] <author> Rajaraman, V. </author> <year> (1981). </year> <title> Analog Computation and Simulation. </title> <address> Englewood Cliffs: </address> <publisher> Prentice Hall. </publisher>
Reference: [79] <author> Rashevsky, N. </author> <year> (1960). </year> <institution> Mathematical Biophysics. </institution> <address> New York: </address> <publisher> Dover. </publisher>
Reference: [80] <author> Rosenblatt, F. </author> <year> (1962). </year> <title> Principles of Neurodynamics. </title> <address> Washington, DC: </address> <publisher> Spartan. </publisher>
Reference: [81] <author> Schneider, W. </author> <year> (1987). </year> <title> Connectionism: is it a paradigm shift for psychology? Behavior Research Methods, Instruments, </title> <journal> and Computers, </journal> <volume> 19 </volume> <pages> 73-83. </pages>
Reference: [82] <author> Selfridge, O. G. & Neisser, U. </author> <year> (1963). </year> <title> Pattern Recognition by Machine. In: Computers and Thought. </title> <editor> Feigenbaum, E. A. & Feldman, J. (Ed.) </editor> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference: [83] <author> Sharkey, N. & Jackson, S. J. </author> <year> (1994). </year> <title> Three Horns of a Representational Dilemma. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [84] <author> Shastri, L. & Ajjanagadde, V. </author> <year> (1989). </year> <title> Connectionist System for Rule Based Reasoning with Multi-Place Predicates and Variables. </title> <type> Tech. Rep. </type> <institution> MS-CIS-8906. Computer and Information Science Dept. University of Penn-sylvania, </institution> <address> Philadelphia, PA. </address>
Reference: [85] <author> Shavlik, J. W., & Dietterich, T. G. </author> <year> (1990). </year> <editor> (Ed). </editor> <booktitle> Readings in Machine Learning. </booktitle> <address> San Mateo, California: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [86] <author> Shavlik, J. W. </author> <year> (1994). </year> <title> A Framework for Combining Symbolic and Neural Learning. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [87] <author> Shepherd, G. M. </author> <year> (1989). </year> <title> The significance of real neuron architectures for neural network simulations. In: computational Neuroscience. Schwartz, </title> <editor> E. (Ed.) </editor> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <address> 40 Chapter 1 </address>
Reference: [88] <author> Shepherd, G. M. (Ed.) </author> <year> (1990). </year> <title> Synaptic Organization of the Brain. </title> <address> New York, NY: </address> <publisher> Oxford University Press. </publisher>
Reference: [89] <author> Smolensky, P. </author> <year> (1990). </year> <title> Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems. </title> <journal> Artificial Intelligence, </journal> <volume> 46 </volume> <pages> 159-216. </pages>
Reference: [90] <author> Sowa, J. F. </author> <year> (1984). </year> <title> Conceptual Structures: </title> <booktitle> Information Processing in Mind and Machine. </booktitle> <address> Reading, Massachusetts: </address> <publisher> Addison-Wesley. </publisher>
Reference: [91] <author> Sun, R. </author> <year> (1994). </year> <title> Logic and Variables in Connectionist Models: A Brief Overview. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [92] <author> Sun, R. & Bookman, L. </author> <year> (1994). </year> <editor> (Ed.) </editor> <booktitle> Computational Architectures Integrating Symbolic and Neural Processes. </booktitle> <address> New York: </address> <publisher> Kluwer. </publisher>
Reference: [93] <author> Tanimoto, S. L. & Klinger, A. </author> <year> (1980). </year> <title> Structured Computer Vision: Machine Perception Through Hierarchical Computation Structures. </title> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: [94] <author> Tsang, E. </author> <year> (1993). </year> <title> Foundations of Constraint Satisfaction. </title> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: [95] <author> Uhr, L. & Vossler, C. </author> <year> (1963). </year> <title> A Pattern Recognition Program that Generates, Evaluates, and Adjusts its Own operators. In: Computers and Thought. </title> <editor> Feigenbaum, E. & Feldman, J. (Ed). </editor> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference: [96] <author> Uhr, L. </author> <year> (1973). </year> <title> Pattern Recognition, Learning, </title> <booktitle> and Thought. </booktitle> <address> New York: </address> <publisher> Prentice-Hall. </publisher>
Reference: [97] <author> Uhr, L. </author> <year> (1979). </year> <title> Parallel-serial production systems with many working memories. </title> <booktitle> In: Proceedings of the Fifth International Joint Conference on Artificial Intelligence. </booktitle>
Reference: [98] <author> Uhr, L. </author> <year> (1980). </year> <title> In: Structured Computer Vision. Tanimoto, </title> <editor> S., and Klinger, A. (Ed.) </editor> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: [99] <author> Uhr, L. </author> <year> (1984). </year> <title> Algorithm-Structured Computer Arrays and Networks. </title> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: [100] <author> Uhr, L. </author> <year> (1987a). </year> <title> Parallel Computer Vision. </title> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: [101] <author> Uhr, L. </author> <year> (1987b). </year> <booktitle> Multi-computer Architectures for Artificial Intelligence. </booktitle> <address> New York: </address> <booktitle> Wiley. Beyond Symbolic AI and Connectionist Networks 41 </booktitle>
Reference: [102] <author> Uhr, L. </author> <year> (1990). </year> <title> Increasing the Power of Connectionist Networks by Improving Structures, Processes, Learning. </title> <journal> Connection Science, </journal> <volume> 2 </volume> <pages> 179-193. </pages>
Reference: [103] <author> Uhr, L. </author> <year> (1994). </year> <title> Digital and Analog Sub-Net Structures for Connectionist Networks. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [104] <author> Uhr, L. & Honavar, V. </author> <year> (1994). </year> <title> Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [105] <author> Van Gelder & Port (1994). </author> <title> Beyond Symbolic: Prolegomena to a Kama-Sutra of Compositionality. In: Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. (Ed.) </editor> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: [106] <author> Waterman, D. A. </author> <year> (1985). </year> <title> A Guide to Expert Systems. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference: [107] <author> Wechsler, H. </author> <year> (1990). </year> <title> Computational Vision. </title> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: [108] <author> Winston, P. H. </author> <year> (1992). </year> <booktitle> Artificial Intelligence. </booktitle> <address> Boston, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference: [109] <author> Yager, R. R. & Zadeh, L. A. </author> <year> (1994). </year> <title> (Ed.) Fuzzy Sets, Neural Networks, </title> <booktitle> and Soft Computing. </booktitle> <address> New York: </address> <publisher> Van Nostrand Reinhold. </publisher>
Reference: [110] <author> Zadeh, L. A. </author> <year> (1975). </year> <title> Fuzzy Logic and Approximate Reasoning. </title> <journal> Synthese, </journal> <volume> 30 </volume> <pages> 407-28. </pages>
Reference: [111] <author> Zeidenberg, M. </author> <year> (1989). </year> <booktitle> Neural Networks in Artificial Intelligence. </booktitle> <address> New York: </address> <publisher> Wiley. </publisher>
References-found: 111

