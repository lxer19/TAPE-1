URL: http://www.cs.washington.edu/homes/segal/oversearch.ps.gz
Refering-URL: http://www.cs.washington.edu/homes/segal/papers.html
Root-URL: 
Email: segal@cs.washington.edu  
Title: An Analysis of Oversearch  Keywords: massive search, overfitting, induction.  
Author: Richard Segal 
Note: Submitted to ICML'96  
Date: January 25, 1996  
Address: Box 352350 Seattle, WA 98195-2350  
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract: Recent experiments using massive search suggest that additional search can reduce accuracy. Quinlan and Cameron-Jones [ 1995 ] have argued that the over-searching problem is a natural consequence of large scale search and that it can only be avoided by searching fewer rules. This paper presents an alternative explanation, the oversearching effect is caused by overfitting and by a poor match between the evaluation function used for training and how rule performance is judged. The evaluation function requests that rules with both high accuracy and high coverage be learned, but performance is judged only using rule accuracy. When a bias for shorter rules is added to the evaluation function and credit is given for learning rules with high coverage, massive search shows a significantly reduced oversearching effect. This analysis suggests that the oversearching problem may not be inherent in large scale search, but may be due to the algorithm's evaluation function. 
Abstract-found: 1
Intro-found: 1
Reference: [ Agrawal et al., 1993 ] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Mining associations between sets of items in massive databases. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 207-216, </pages> <address> Washington, DC, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: On a Boeing manufacturing database, Brute found significantly better rules than those found by greedy algorithms. However, Brute used a depth cutoff to reduce the cost of searching. This cutoff introduces a preference for shorter rules and may have contributed to Brute's success. IBM's data mining system <ref> [ Agrawal et al., 1993 ] </ref> also uses accuracy with a minimum coverage requirement. The LaplaceDepth function is an extension of the error function presented by Smyth and 11 Goodman [ Smyth and Goodman, 1991 ] .
Reference: [ Blumer et al., 1987 ] <author> Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred Warmuth. </author> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 377-380, </pages> <year> 1987. </year>
Reference: [ Breiman et al., 1984 ] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <year> 1984. </year>
Reference: [ Clark and Niblett, 1989 ] <author> P. Clark and T. Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 261-283, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: Oversearching may not be inherent in massive search, but a property of the evaluation function being used. Additional experiments are needed to make this determination. 5 Learning Classifiers Several learning algorithms such as CN2 <ref> [ Clark and Niblett, 1989 ] </ref> , Greedy3 [ Pagallo and Haussler, 1990 ] , Cover [ Webb, 1993 ] , and BruteDL [ Segal and Etzioni, 1994 ] combine rule learning algorithms with a covering algorithm to learn complete classifiers.
Reference: [ Good, 1965 ] <author> I. J. </author> <title> Good. The Estimation of Probabilities: An Essay on Modern Bayesian Methods. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass, </address> <year> 1965. </year> <note> Research Monograph 30. </note>
Reference: [ Murphy and Pazzani, 1994 ] <author> Patrick M. Murphy and Michael J. Pazzani. </author> <title> Exploring the decision forest: An empirical investigation of Occam's razor in decision tree induction. </title> <note> Submitted to Artificial Intelligence Research, </note> <year> 1994. </year>
Reference: [ Murphy, 1994 ] <author> Patrick M. Murphy. </author> <title> UCI repository of machine learning databases. [Machine-readable data repository]. </title> <address> Irvine, CA. </address> <institution> University of California, Department of Information and Computer Science, </institution> <year> 1994. </year>
Reference: [ Niblett, 1987 ] <author> T. Niblett. </author> <title> Constructing decision trees in noisy domains. </title> <booktitle> In Progress in Machine Learning (Proceedings of the 2nd European Working Session on Learning), </booktitle> <pages> pages 67-78, </pages> <address> Wilmslow, UK, </address> <year> 1987. </year>
Reference-contexts: Each rule in the hypothesis space is evaluated using Laplace predicted error <ref> [ Niblett, 1987 ] </ref> . If a rule matches n examples of the training data and incorrectly predicts the classification of e of those examples, then the Laplace error for this rule is Laplace = e + k 1 where k is the number of classes.
Reference: [ Pagallo and Haussler, 1990 ] <author> G. Pagallo and D. Haussler. </author> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 5(1) </volume> <pages> 71-100, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Oversearching may not be inherent in massive search, but a property of the evaluation function being used. Additional experiments are needed to make this determination. 5 Learning Classifiers Several learning algorithms such as CN2 [ Clark and Niblett, 1989 ] , Greedy3 <ref> [ Pagallo and Haussler, 1990 ] </ref> , Cover [ Webb, 1993 ] , and BruteDL [ Segal and Etzioni, 1994 ] combine rule learning algorithms with a covering algorithm to learn complete classifiers.
Reference: [ Quinlan and Cameron-Jones, 1995 ] <author> J. R. Quinlan and R. M. Cameron-Jones. </author> <title> Oversearching and layered search in empirical learning. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1019-1024, </pages> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year>
Reference: [ Quinlan and Rivest, 1989 ] <author> J. R. Quinlan and R. Rivest. </author> <title> Inferring decision trees using the Minimum Description Length principle. </title> <journal> Information and Computation, </journal> <volume> 80 </volume> <pages> 227-248, </pages> <year> 1989. </year>
Reference-contexts: Since overfitting can occur with larger beam widths, employing a preference for shorter rules may eliminate the oversearching effect. This is often done using Rissanen's Minimum Description Length (MDL) principle <ref> [ Quinlan and Rivest, 1989 ] </ref> . Since this function uses a different tradeoff between accuracy and coverage than that used by Laplace error, it would be difficult to compare results using MDL to those presented earlier. Instead, we modify Laplace error to include a preference for shorter rules. <p> The LaplaceDepth function is an extension of the error function presented by Smyth and 11 Goodman [ Smyth and Goodman, 1991 ] . Other evaluation functions for reducing overfitting such as Rissanen's Minimum Description Length (MDL) principle <ref> [ Quinlan and Rivest, 1989 ] </ref> may perform better than the function presented here. While rule pruning [ Breiman et al., 1984, Quinlan, 1993, Clark and Niblett, 1989 ] has been used to reduce overfitting in greedy algorithms, it is not appropriate for massive search.
Reference: [ Quinlan, 1993 ] <author> J. R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1993. </year>
Reference: [ Riddle et al., 1994 ] <author> Patricia Riddle, Richard Segal, and Oren Etzioni. </author> <title> Representation design and brute-force induction in a Boeing manufacturing domain. </title> <journal> Applied Artificial Intelligence, </journal> <volume> 8 </volume> <pages> 125-147, </pages> <year> 1994. </year> <month> 13 </month>
Reference-contexts: Most of these systems use Laplace error to evaluate rules and have noticed a decrease in performance due to additional search. One notable exception is Brute <ref> [ Riddle et al., 1994 ] </ref> , a system that applies massive search to data mining. Brute evaluated rules using rule accuracy and employed a minimum coverage requirement to avoid overfitting. On a Boeing manufacturing database, Brute found significantly better rules than those found by greedy algorithms.
Reference: [ Segal and Etzioni, 1994 ] <author> Richard Segal and Oren Etzioni. </author> <title> Learning decision lists using ho-mogeneous rules. </title> <booktitle> In Proceedings of the 12th National Conference on Artificial Intelligence, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: Additional experiments are needed to make this determination. 5 Learning Classifiers Several learning algorithms such as CN2 [ Clark and Niblett, 1989 ] , Greedy3 [ Pagallo and Haussler, 1990 ] , Cover [ Webb, 1993 ] , and BruteDL <ref> [ Segal and Etzioni, 1994 ] </ref> combine rule learning algorithms with a covering algorithm to learn complete classifiers.
Reference: [ Smyth and Goodman, 1991 ] <author> P. Smyth and R. M. Goodman. </author> <title> Rule induction using information theory. </title> <booktitle> In Knowledge Discovery in Databases, </booktitle> <pages> pages 159-176. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: This cutoff introduces a preference for shorter rules and may have contributed to Brute's success. IBM's data mining system [ Agrawal et al., 1993 ] also uses accuracy with a minimum coverage requirement. The LaplaceDepth function is an extension of the error function presented by Smyth and 11 Goodman <ref> [ Smyth and Goodman, 1991 ] </ref> . Other evaluation functions for reducing overfitting such as Rissanen's Minimum Description Length (MDL) principle [ Quinlan and Rivest, 1989 ] may perform better than the function presented here.
Reference: [ Webb, 1993 ] <author> G. I. Webb. </author> <title> Systematic search for categorical attribute-value data-driven machine learning. </title> <editor> In N. Foo and C. Rowles, editors, </editor> <booktitle> AI `93. World Scientific, </booktitle> <address> Singapore, </address> <year> 1993. </year>
Reference-contexts: Additional experiments are needed to make this determination. 5 Learning Classifiers Several learning algorithms such as CN2 [ Clark and Niblett, 1989 ] , Greedy3 [ Pagallo and Haussler, 1990 ] , Cover <ref> [ Webb, 1993 ] </ref> , and BruteDL [ Segal and Etzioni, 1994 ] combine rule learning algorithms with a covering algorithm to learn complete classifiers.
References-found: 16

