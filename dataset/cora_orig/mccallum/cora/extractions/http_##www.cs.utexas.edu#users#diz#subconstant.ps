URL: http://www.cs.utexas.edu/users/diz/subconstant.ps
Refering-URL: http://www.cs.utexas.edu/users/diz/pubs.html
Root-URL: 
Title: COMPUTING WITH VERY WEAK RANDOM SOURCES  
Author: ARAVIND SRINIVASAN AND DAVID ZUCKERMAN 
Keyword: Key words. derandomization, expander graphs, hashing lemmas, hardness of approximation, imperfect sources of randomness, measures of information, pseudo-randomness, pseudo-random generators, randomized computation, time-space tradeoffs  
Note: AMS subject classifications. 60C05, 68Q15, 94A17  
Abstract: We give an efficient algorithm to extract randomness from a very weak random source using a small additional number t of truly random bits. Our work extends that of Nisan & Zuckerman in that t remains small even if the entropy rate is well below constant. A key application of this is in running randomized algorithms using such a very weak source of randomness. For any fixed fl &gt; 0, we show how to simulate RP algorithms in time n O(log n) using the output of a ffi-source with min-entropy R fl . Such a weak random source is asked once for R bits; it outputs an R-bit string according to any probability distribution that places probability at most 2 R fl on each string. If fl &gt; 1=2, our simulation also works for BPP; for fl &gt; 1 1=(k + 1), our simulation takes time n O(log (k) n) (log (k) is the logarithm iterated k times). We also give a polynomial-time BPP simulation using Chor-Goldreich sources of min-entropy R (1) , which is optimal. We present applications to time-space tradeoffs, expander constructions, and to the hardness of approximation. Of independent interest is our randomness-efficient Leftover Hash Lemma, a key tool to extract randomness from weak random sources. 
Abstract-found: 1
Intro-found: 1
Reference: [ABI] <author> N. Alon, L. Babai, and A. Itai, </author> <title> "A fast and simple randomized parallel algorithm for the maximal independent set problem," </title> <journal> Journal of Algorithms, </journal> <volume> 7 </volume> <pages> 567-583, </pages> <year> 1986. </year>
Reference-contexts: Methods to construct such k-wise independent random variables using k log n random bits are well-known: see, e.g., <ref> [ABI, Lub] </ref>. Extracting One Block. The function B: B has 2 parameters: l, the size of the output, and k, the amount of independence used. 1. INPUT: x 2 f0; 1g n ; y 2 f0; 1g t (where t = k log n). 2.
Reference: [AC+] <author> A. E. Andreev, A. E. F. Clementi, J. P. D. Rolim, and L. Trevisan, </author> <title> "Weak Random Sources, Hitting sets, and BPP Simulations", </title> <booktitle> Proc. 38th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1997, </year> <pages> pp. 264-272. </pages>
Reference-contexts: In an exciting new result, Andreev, Clementi, Rolim and Trevisan have shown how to simulate BPP using ffi-sources with min-entropy R fl for any fixed fl &gt; 0, in polynomial time <ref> [AC+] </ref>.
Reference: [AG+] <author> N. Alon, O. Goldreich, J. H-astad, and R. Peralta, </author> <title> "Simple Constructions of Almost k wise Independent Random Variables," Random Structures & Algorithms, </title> <booktitle> 3(3) </booktitle> <pages> 289-303, </pages> <year> 1992. </year>
Reference-contexts: S, then 8I f1; 2; :::; ng; jIj d; 8b 1 ; b 2 ; : : : ; b jIj 2 f0; 1g, jP r ~ X2S [ i2I Simplifying the construction in [NN], d-wise -biased spaces of cardinality O ((d log n=) 2 ) were constructed explicitly in <ref> [AG+] </ref>. In addition, given the random bits to sample from S, any bit of ~ X can be computed in poly (d; log n; log ( 1 )) time. Lemma 3.2. Let A f0; 1g s ; jAj 2 t , k &gt; 0, and * 2 1k .
Reference: [BR] <author> M. Bellare and J. Rompel, </author> <title> "Randomness-Efficient Oblivious Sampling," </title> <booktitle> Proc. 35th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1994, </year> <pages> pp. 276-287. </pages>
Reference-contexts: A Block-Wise Converter. Our block-wise converter is a small modification of that in [NZ]. For our simulations of RP and BPP, it would suffice to change the k-wise independence in [NZ] to pairwise independence, as was done in [Zu2]. However, by using an improved analysis of k-wise independence from <ref> [BR] </ref>, we can give a good extractor for a wider range of parameters. The results of this subsection are essentially taken from [NZ], with the only changes being this improved analysis of [BR]. <p> However, by using an improved analysis of k-wise independence from <ref> [BR] </ref>, we can give a good extractor for a wider range of parameters. The results of this subsection are essentially taken from [NZ], with the only changes being this improved analysis of [BR]. Thus, in order to not obscure the main new ideas, we just present a sketch of the block-wise converter, and leave the necessary details to Appendix A. In order to define our block-wise converter, we first show how to extract one block from a ffi-source.
Reference: [BL] <author> M. Ben-Or and N. Linial, </author> <title> "Collective Coin Flipping," </title> <booktitle> in Advances in Computing Research 5: Randomness and Computation, </booktitle> <editor> S. Micali, ed., </editor> <publisher> JAI Press, </publisher> <year> 1989. </year>
Reference-contexts: These models are called bit-fixing models: some of the bits are perfectly random, while others are controlled by an adversary. Cohen and Wigderson [CW] distinguish three models based on three different adversaries: oblivious bit-fixing sources [CG+], nonoblivious bit-fixing sources <ref> [BL, KKL] </ref>, and adaptive bit-fixing sources [LLS].
Reference: [Blu] <author> M. Blum, </author> <title> "Independent Unbiased Coin Flips from a Correlated Biased Source: a Finite Markov Chain," </title> <journal> Combinatorica, </journal> <volume> 6 (2): </volume> <pages> 97-108, </pages> <year> 1986. </year>
Reference-contexts: Thus we model a weak random source as outputting bits that are slightly random, but not perfectly random. There have been two different directions in the study of weak random sources. The first is an attempt to describe a weak random source arising in practice. Thus Manuel Blum <ref> [Blu] </ref> looked at the model where bits are output by a Markov chain, and showed how to extract perfectly random bits from such a source. Santha and Vazirani [SV] then looked at a model where the only fact known about the source is that each bit has some randomness.
Reference: [CG] <author> B. Chor and O. Goldreich, </author> <title> "Unbiased Bits from Sources of Weak Randomness and Proba bilistic Communication Complexity," </title> <journal> SIAM J. Comput., </journal> <volume> 17(2) </volume> <pages> 230-261, </pages> <year> 1988. </year>
Reference-contexts: Chor and Goldreich <ref> [CG] </ref> generalized the Santha-Vazirani model by assuming that no sequence of l bits has too high a probability of being output. More precisely, Definition 1.2. ([CG]) A block-wise ffi-source outputs bits as blocks Y 1 ; : : : ; Y s , where Y i has length l i , <p> Only for the first model could researchers do something better than they could for general weak random sources ([CW], see below). 1 We modify the notation in <ref> [CG] </ref> to conform better with ours. 2 The two directions in weak random sources were united by the model of ffi-sources [Zu1, Zu2], which generalizes all the previous models: Definition 1.3. <p> Now we use the following modification of a lemma from the final version of [Zu2] which, using the Leftover Hash Lemma in the manner of [IZ], essentially strengthened related lemmas in [Va2] and <ref> [CG] </ref>. Lemma 4.1. Let F be a function family mapping l bits to b 2k bits, satisfying Lemma 3.2 with parameters k = (c + 2) log n and * = n (c+1) . Let D be a block-wise ffi-source on f0; 1g ml .
Reference: [CG+] <author> B. Chor, O. Goldreich, J. H-astad, J. Friedman, S. Rudich, and R. Smolensky, </author> <title> "The Bit Extraction Problem or t-Resilient Functions," </title> <booktitle> Proc. 26th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1985, </year> <pages> pp. 396-407. </pages>
Reference-contexts: These models are called bit-fixing models: some of the bits are perfectly random, while others are controlled by an adversary. Cohen and Wigderson [CW] distinguish three models based on three different adversaries: oblivious bit-fixing sources <ref> [CG+] </ref>, nonoblivious bit-fixing sources [BL, KKL], and adaptive bit-fixing sources [LLS].
Reference: [CW] <author> A. Cohen and A. Wigderson, "Dispersers, </author> <title> Deterministic Amplification, and Weak Random Sources," </title> <booktitle> Proc. 30th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <pages> pp. 14-19. </pages>
Reference-contexts: The other direction researchers have taken is natural mathematically, although it appears to correspond less well to weak sources in practice. These models are called bit-fixing models: some of the bits are perfectly random, while others are controlled by an adversary. Cohen and Wigderson <ref> [CW] </ref> distinguish three models based on three different adversaries: oblivious bit-fixing sources [CG+], nonoblivious bit-fixing sources [BL, KKL], and adaptive bit-fixing sources [LLS]. Only for the first model could researchers do something better than they could for general weak random sources ([CW], see below). 1 We modify the notation in [CG] <p> In light of this, what is left to do? The answer is to extend the result for subconstant ffi. Information-theoretically, it is necessary for the R bits to have min-entropy only R fl , for an arbitrary but fixed fl &gt; 0 <ref> [CW] </ref>. (Of course, if BP P = P then no random bits are necessary: this information-theoretic result holds for an abstract model of BPP where random bits are really necessary. <p> bound? Previously, the only weak source where this information-theoretic lower bound could be achieved was the oblivious bit-fixing source: Cohen and Wigderson showed how to simulate BPP even if the adversary fixes all but R fl bits and leaves the other bits unbiased and independent, matching the above lower bound <ref> [CW] </ref>. In this paper, we come close to our goal: we give a time n O (log n) simulation for any RP algorithm using a ffi-source with min-entropy R fl . For fl &gt; 1=2, our simulations also work for BPP and approximation algorithms. <p> In the case when S is the class of ffi-sources, it is often convenient to view the extractors graph-theoretically, as in <ref> [Sip, San, CW] </ref>. Namely, construct a bipartite graph on f0; 1g n fi f0; 1g m , where x 2 f0; 1g n is adjacent to z 2 f0; 1g m iff z = E (x; y) for some y. <p> Then any set in f0; 1g n of size at least 2 ffin expands almost uniformly into f0; 1g m . In particular, it yields efficient constructions of graphs called dispersers in <ref> [CW] </ref>: Definition 1.6. <p> Sections 5 and 6 contain some of our main results: simulating BPP and RP algorithms using general weak sources with very low min-entropy. Section 7 uses the result of Section 4 to generalize a result of <ref> [CW] </ref> on oblivious bit-fixing sources. Applications of our results are presented in Section 8. Section 9 concludes with some recent work that our work has led to, in part, and presents open questions. 5 In the appendix, we show some technical details that are largely borrowed from [NZ]. 2. Preliminaries. <p> As we can ask for at most r O (1) bits from the source, this is what gives the R fl min-entropy lower bound of <ref> [CW] </ref>. Definition 2.2. <p> Furthermore, this section will be useful in generalizing a result of <ref> [CW] </ref> on oblivious bit-fixing sources: see Section 7. <p> Sources with Many Weakly-Independent Bits. As an application of Theorem 4.2, we now show how to simulate BPP using a generalization of the oblivious bit-fixing source of <ref> [CW] </ref>, using Lemma 4.1. Here again, we actually build an extractor for these sources. We need Definition 7.1.
Reference: [DFK] <author> M. Dyer, A. Frieze, and R. Kannan, </author> " <title> A Random Polynomial Time Algorithm for Approx imating the Volume of a Convex Body," </title> <journal> J. ACM, </journal> <volume> 38 </volume> <pages> 1-17, </pages> <year> 1991. </year> <month> 26 </month>
Reference-contexts: Our BPP simulations also work for approximation algorithms, such as the one for approximating the volume of a convex body <ref> [DFK] </ref>. Our BPP simulations are corollaries of something even stronger, extractor constructions. An extractor is an algorithm which extracts randomness from a weak source, using a small additional number t of truly random bits. We modify the definition given in [NZ] to account for general families of sources. Definition 1.5.
Reference: [FLW] <author> A. M. Ferrenberg, D. P. Landau, and Y. J. Wong, </author> <title> Monte Carlo Simulations: Hidden Errors from "Good" Random Number Generators, </title> <journal> Physical Review Letters, </journal> <volume> 69(23) </volume> <pages> 3382-3384, </pages> <year> 1992. </year>
Reference-contexts: In practice, programs get their "random" bits by using pseudo-random number generators. Yet even in practice there are reports of algorithms giving quite different results under different pseudo-random generators; see, e.g., <ref> [FLW] </ref> for such reports on Monte-Carlo simulations, and [Hsu, HRD] for the deviant performance of some RN C algorithms for graph problems. Other approaches involve using a physical source of randomness, such as a Zener diode, or using the last digits of a real-time clock.
Reference: [GW] <author> O. Goldreich and A. Wigderson, </author> <title> "Tiny Families of Functions with Random Properties: </title>
Reference-contexts: We show how a similar lemma can be achieved, using only O (log s + t) random bits. Because this modification was so useful to us here, we believe it will be useful elsewhere too. A similar lemma was proved independently in <ref> [GW] </ref>; however, our proof is somewhat simpler. One key consequence of our lemma is an improvement of the extractor of [NZ].
References-found: 12

