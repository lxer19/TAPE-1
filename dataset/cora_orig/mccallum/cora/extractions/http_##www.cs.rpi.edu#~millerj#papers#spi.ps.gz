URL: http://www.cs.rpi.edu/~millerj/papers/spi.ps.gz
Refering-URL: http://www.cs.rpi.edu/~stewart/
Root-URL: http://www.cs.rpi.edu
Title: Prediction Intervals for Surface Growing Range Segmentation  
Author: James V. Miller Charles V. Stewart 
Web: http://www.cs.rpi.edu/millerj/ http://www.cs.rpi.edu/stewart/  
Address: Troy, NY 12180-3590 Troy, NY 12180-3590  
Affiliation: Electrical, Computer and Systems Engineering Department of Computer Science Rensselaer Polytechnic Institute Rensselaer Polytechnic Institute  
Abstract: The surface growing framework presented by Besl and Jain [2] has served as the basis for many range segmentation techniques. It has been augmented with alternative fitting techniques [17], model selection criteria [11, 15], and solid modelling components [6]. All of these surface growing approaches, however, require global thresholds. Range scenes typically cannot satisfy the global threshold assumption since it requires data noise characteristics to be constant throughout the scene. Furthermore, these approaches can only be applied to range scenes where large seed regions can be isolated. As scene complexity increases, the number of surfaces, discontinuities, and outliers increase, hindering the identification of large seed regions. We present statistical criteria based on multivariate regression to replace the traditional decision criteria used in surface growing. We use local estimates and their uncertainties to construct criteria which capture the uncertainty associated with extrapolating estimated fits. Our criteria allow small robust seed regions to grow to large surface patches without the use of global thresholds. To make the best use of these criteria, we restrict the surface expansion process to very localized extrapolations. This increases the sensitivity to discontinuities and allows regions to refine their estimates and uncertainties as they expand. Our approach has a small number of parameters which are either statistical thresholds or cardinality measures, i.e. we do not use thresholds defined by specific range distances or orientation angles. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Al-Hujazi and A. Sood, </author> <title> Range Image Segmentation with Applications to Robot Bin-Picking using Vacuum Gripper, </title> <booktitle> IEEE T-SMC 20 (1990), </booktitle> <volume> no. 6, </volume> <pages> 1313-1325. </pages>
Reference-contexts: Its strengths become increasingly important as range sensors are used in more unstructured environments where the number of surfaces, discontinuities, and outliers increase. Existing regularization (see [3] for a review) and image region growing <ref> [5, 1] </ref> techniques, demand a high degree of local data integrity in image plane neighborhoods, faltering when presented with the numerous dis-continuities and outliers from unstructured environments. Even robust estimators, designed for immunity to outliers, are thwarted by the intrinsic structure in the outlying samples from across discontinuities [16].
Reference: [2] <author> P.J. Besl and R.C. Jain, </author> <title> Segmentation Through Variable-Order Surface Fitting, </title> <booktitle> T-PAMI 10 (1988), </booktitle> <pages> 167-192. </pages>
Reference-contexts: 1 Introduction Surface growing range segmentation <ref> [2, 4, 7, 17, 11, 15, 6] </ref> is a local-to-global approach to surface reconstruction. Seed regions initially isolated from discontinu-ities are expanded until the boundaries of the surfaces are detected.
Reference: [3] <author> R. Bolle and B. Vemuri, </author> <title> On Three-Dimensional Surface Reconstruction Methods, </title> <booktitle> T-PAMI 13 (1991), </booktitle> <volume> no. 1, </volume> <pages> 1-13. </pages>
Reference-contexts: The benefit of surface growing is that it leverages off regions of high quality data while searching for discon-tinuities. Its strengths become increasingly important as range sensors are used in more unstructured environments where the number of surfaces, discontinuities, and outliers increase. Existing regularization (see <ref> [3] </ref> for a review) and image region growing [5, 1] techniques, demand a high degree of local data integrity in image plane neighborhoods, faltering when presented with the numerous dis-continuities and outliers from unstructured environments.
Reference: [4] <author> T.E. Boult and M. Lerner, </author> <title> Energy-Based Segmentation of Very Sparse Range Surfaces, </title> <booktitle> IEEE Conference on Robitics and Automation, </booktitle> <year> 1990, </year> <pages> 232-237. </pages>
Reference-contexts: 1 Introduction Surface growing range segmentation <ref> [2, 4, 7, 17, 11, 15, 6] </ref> is a local-to-global approach to surface reconstruction. Seed regions initially isolated from discontinu-ities are expanded until the boundaries of the surfaces are detected.
Reference: [5] <author> O.D. Faugeras, M. Hebert, and E. Pauchon, </author> <title> Segmentation of Range Data into Planar and Quadratic Patches, </title> <journal> IEEE CVPR, </journal> <year> 1983, </year> <pages> 8-13. </pages>
Reference-contexts: Its strengths become increasingly important as range sensors are used in more unstructured environments where the number of surfaces, discontinuities, and outliers increase. Existing regularization (see [3] for a review) and image region growing <ref> [5, 1] </ref> techniques, demand a high degree of local data integrity in image plane neighborhoods, faltering when presented with the numerous dis-continuities and outliers from unstructured environments. Even robust estimators, designed for immunity to outliers, are thwarted by the intrinsic structure in the outlying samples from across discontinuities [16].
Reference: [6] <author> A.W. Fitzgibbon, D.W. Eggert, and R.B. Fisher, </author> <title> High-level CAD Model Acquisition from Range Images, </title> <type> Tech. report, </type> <institution> Dept. of Artificial Intelligence, Univ. of Edinburgh, </institution> <year> 1995. </year>
Reference-contexts: 1 Introduction Surface growing range segmentation <ref> [2, 4, 7, 17, 11, 15, 6] </ref> is a local-to-global approach to surface reconstruction. Seed regions initially isolated from discontinu-ities are expanded until the boundaries of the surfaces are detected. <p> To refine crease locations, we remove the constraint that a point can only be assigned to the surface producing the smallest SPPI interval, and replace it with a constraint based on the intersection of the two surfaces (see <ref> [6] </ref>). 7 Analysis One of the major strengths of the prediction interval framework lies in the ability to reconstruct very small magnitude step discontinuities. The SPI facilitate localized queries along the boundary of a region, identifying when a local expansion attempts to cross a discontinuity. <p> Raw Data UE Reconstruction SPPI, NPI, SPI Reconstruction are bridged by the UE segmenter, however, the prediction interval segmenter handles the small steps correctly due to the SPI. range segmenter (UE segmenter <ref> [6] </ref>). The UE segmenter was chosen for comparison since it had the best overall performance in [10] and because it is the closest in style of those discussed in [10] to the prediction interval segmenter. The parameters for the UE segmenter were set using the techniques discussed in [6] and [10]. <p> (UE segmenter <ref> [6] </ref>). The UE segmenter was chosen for comparison since it had the best overall performance in [10] and because it is the closest in style of those discussed in [10] to the prediction interval segmenter. The parameters for the UE segmenter were set using the techniques discussed in [6] and [10]. In particular, the location threshold was set at 2:5s. The UE segmenter results in bridging fits whereas the prediction interval segmenter properly reconstructs the steps. 8 Results the Perceptron test data sets from the University of South Florida's Segmentation Comparison Project [10]. <p> Furthermore, we supply the SPI criterion which tests candidate points for group inlier compatibility, thereby increasing the sensitivity to small discontinuities. In the future, we plan to extend the surface growing algorithm with solid modelling constraints as in <ref> [6] </ref>, incorporate a model selection methodology to extract higher order surfaces, and perhaps most importantly quantitatively compare our surface growing segmentation technique against other range segmentation techniques using the University of South Florida's segmentation comparison tool [10].
Reference: [7] <author> P. Fua and P. Sander, </author> <title> Reconstructing Surfaces from Unstructured 3D Points, </title> <booktitle> Proc. of the DARPA Image Understanding Workshop, </booktitle> <year> 1991, </year> <pages> 615-625. </pages>
Reference-contexts: 1 Introduction Surface growing range segmentation <ref> [2, 4, 7, 17, 11, 15, 6] </ref> is a local-to-global approach to surface reconstruction. Seed regions initially isolated from discontinu-ities are expanded until the boundaries of the surfaces are detected.
Reference: [8] <author> G.J. Hahn, </author> <title> Simultaneous Prediction Intervals for a Regression Model, </title> <journal> Technometrics 14 (1972), </journal> <volume> no. 1, </volume> <pages> 203-214. </pages>
Reference-contexts: For the case of one-dimensional dependent variables, the simultaneous prediction interval reduces to a k-dimensional Student-t random variable for which there exist multiple approximate interval solutions <ref> [12, 8] </ref>. Here, we derive a summary statistic which is itself univariate yet still applicable to multivariate dependent variables. Consider a set of k points, not used to estimate b B and b S, represented in the matrices Y fl (k fi p) and X fl (k fi q).
Reference: [9] <author> W.L. Hays and R.L. Winkler, </author> <title> Statistics: Probability, Inference, and Decision, </title> <publisher> Holt, Rinehart, and Winston, Inc., </publisher> <address> New York, </address> <year> 1971. </year>
Reference-contexts: Since these chi-squared random variables are independent, their sum is a chi-squared random variable with the sum degrees of freedom <ref> [9] </ref> 1 B 1 + m B 2 s 2 (m B 1 +m B 2 q B 1 q B 2 ) : (19) Equations 16 and 19 are independent (see Section 2) and combine to form a t random variable, where for all ~a a 0 a 0 a
Reference: [10] <author> A. Hoover, G. Jean-Baptiste, X. Jiang, P.J. Flynn, H. Bunke, D.B. Goldgof, K. Bowyer, D.W. Eggert, A. Fitzgibbon, and R.B. Fisher, </author> <title> An Experimental Comparisonn of Range Image Segmentation Algorithms, </title> <booktitle> T-PAMI 18 (1996), </booktitle> <pages> 673-689. </pages>
Reference-contexts: We limit the presentation to extracting connected regions. This will allow us in the future to compare our techniques with other segmentation algorithms using the University of South Florida's Segmentation Comparison Tool <ref> [10] </ref>. As with all the surface growing algorithms, we start with a set of seed regions. Here, we leverage off the criteria's ability to factor in uncertainty, and seed with small surface patches extracted from a robust local operator. <p> Raw Data UE Reconstruction SPPI, NPI, SPI Reconstruction are bridged by the UE segmenter, however, the prediction interval segmenter handles the small steps correctly due to the SPI. range segmenter (UE segmenter [6]). The UE segmenter was chosen for comparison since it had the best overall performance in <ref> [10] </ref> and because it is the closest in style of those discussed in [10] to the prediction interval segmenter. The parameters for the UE segmenter were set using the techniques discussed in [6] and [10]. In particular, the location threshold was set at 2:5s. <p> The UE segmenter was chosen for comparison since it had the best overall performance in <ref> [10] </ref> and because it is the closest in style of those discussed in [10] to the prediction interval segmenter. The parameters for the UE segmenter were set using the techniques discussed in [6] and [10]. In particular, the location threshold was set at 2:5s. <p> The UE segmenter was chosen for comparison since it had the best overall performance in <ref> [10] </ref> and because it is the closest in style of those discussed in [10] to the prediction interval segmenter. The parameters for the UE segmenter were set using the techniques discussed in [6] and [10]. In particular, the location threshold was set at 2:5s. The UE segmenter results in bridging fits whereas the prediction interval segmenter properly reconstructs the steps. 8 Results the Perceptron test data sets from the University of South Florida's Segmentation Comparison Project [10]. <p> set using the techniques discussed in [6] and <ref> [10] </ref>. In particular, the location threshold was set at 2:5s. The UE segmenter results in bridging fits whereas the prediction interval segmenter properly reconstructs the steps. 8 Results the Perceptron test data sets from the University of South Florida's Segmentation Comparison Project [10]. Following their framework, we limit the extraction to planar surfaces. The Perceptron data required a data smoothing stage prior to the initial normals calculation; although, we reverted back to the original data during reconstruction. For comparison, we include segmentation images from the algorithms tested in [10]. <p> Florida's Segmentation Comparison Project <ref> [10] </ref>. Following their framework, we limit the extraction to planar surfaces. The Perceptron data required a data smoothing stage prior to the initial normals calculation; although, we reverted back to the original data during reconstruction. For comparison, we include segmentation images from the algorithms tested in [10]. Qualitatively, our technique performs favorably, erring slightly on the side of oversegment-ing. Instead of reconstructing 7 surfaces on the octagon nut, our segmenter extracted 9 large regions. <p> we plan to extend the surface growing algorithm with solid modelling constraints as in [6], incorporate a model selection methodology to extract higher order surfaces, and perhaps most importantly quantitatively compare our surface growing segmentation technique against other range segmentation techniques using the University of South Florida's segmentation comparison tool <ref> [10] </ref>.
Reference: [11] <author> A. Leonardis, A. Gupta, and R. </author> <title> Bajcsy, Segmentation of Range Images as the Search for Geometric Parametric Models, </title> <booktitle> IJCV 14 (1995), </booktitle> <pages> 253-277. </pages>
Reference-contexts: 1 Introduction Surface growing range segmentation <ref> [2, 4, 7, 17, 11, 15, 6] </ref> is a local-to-global approach to surface reconstruction. Seed regions initially isolated from discontinu-ities are expanded until the boundaries of the surfaces are detected.
Reference: [12] <author> G.J. Lieberman, </author> <title> Prediction Regions for Several Predictions from a Single Regression Line, </title> <journal> Technometrics 3 (1961), </journal> <volume> no. 1, </volume> <pages> 21-27. </pages>
Reference-contexts: For the case of one-dimensional dependent variables, the simultaneous prediction interval reduces to a k-dimensional Student-t random variable for which there exist multiple approximate interval solutions <ref> [12, 8] </ref>. Here, we derive a summary statistic which is itself univariate yet still applicable to multivariate dependent variables. Consider a set of k points, not used to estimate b B and b S, represented in the matrices Y fl (k fi p) and X fl (k fi q).
Reference: [13] <author> K.V. Mardia, J.T. Kent, and J.M. Bibby, </author> <title> Multivariate Analysis, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: However, the general multivariate regression model <ref> [13, Chapter 6] </ref> is Y = XB +U (4) where Y (n fi p) is a matrix of n observations of the p-dimensional dependent variables, X (n fi q) is a matrix of n observations of the (q 1)-dimensional independent variables (the first column of X is a vector of 1's), <p> For the case 4 Composing quadratic forms between Gaussian random variables and independent Wishart random variables is a standard means of creating a univariate statistic with a distribution known as the Hotelling T 2 . See <ref> [13, pages 73-79] </ref>. (a) (b) (a) Seed region with SPPI hyperbola. (b) SPPI filtering allows surface to grow and avoid outliers. <p> As defined in equation 11, the normal function is Gaussian dis tributed on the y = 1 plane since it is a linear mapping of b B which is Gaussian distributed (see Section 2 and <ref> [13, Thereom 3.2.1, page 62] </ref>). Normalizing the normal function would result in a non-linear mapping of the distribution onto the unit sphere, resulting in non-Gaussian random variables (see Figure 4). The complete distribution for n can be deter mined directly from the distribution of b B (given in Section 2). <p> Since only two of the three components of n are random, we concentrate on the distribution of n b B = n x 1 = b B 0 x b B 0 x # Using the covariance of linear forms <ref> [13, page 30] </ref> and the covariance of the components of b B given in the Section 2, it can be shown that the distribution of a regression surface's normal at the point ~p is given by n x 2 b B n x 2 ; s 2 x x 0 x <p> derived from the same underlying surface, 6;7 H B 1 + H B 2 : (16) Using the linear property of Gaussian distributions, a 0 fi H B 1 + H B 2 n B 1 n B 2 p ~ N 1 (0; 1) (17) for all vectors ~a <ref> [13, Corollary 3.2.1.1 & 3.2.1.3, page 62] </ref>. Furthermore, since the two fits are derived from independent sets of samples, we have two independent scale estimates, s B 1 and s B 2 . <p> Since this statistic must be true for all vectors ~a, we only need to examine the vector ~a at which the statistic attains its maximum value. 8 It can be shown that <ref> [13, Corollary A.9.2.2, page 480] </ref> max (a 0 x) 2 = x 0 x: (21) Therefore, we can reduce the infinite set of statistics defined in equation 20 by squaring the statistic and applying the property of the maximum just described, arriving at the single univariate statistic 0 fi fl 1 <p> This situation should indicate that the candidate data is at least partly composed of samples from across a small step 8 Union Intersection Principle, see <ref> [13, Chapter 5] </ref>. discontinuity. Thus, if we use a test on the collection of candidate data, we can identify smaller step heights than with SPPI's alone. There is another motivation for testing the candidate data as a set. <p> Since each row of R fl has a different distribution and the rows are not independent, we cannot treat R fl as a normal data matrix <ref> [13, page 65] </ref>. However, we can operate on R fl as a single random variable by vectorizing R fl . The variable R fl V is the (kp fi 1) vec tor formed by stacking the columns of R fl (k fi p). <p> Consid ering the distribution of each r fl i and their interdependence, the distribution of R fl V is given by R fl V where is the Kronecker matrix product <ref> [13, Appendix A] </ref> and A = I k + X fl (X 0 X) 1 X fl 0 . <p> Since R fl V is a k p-dimensional normal random variable, a 0 R fl V is univariate normal for all fixed vectors a (kp fi 1) (see the definition of a multivariate normal <ref> [13, pages 60-62] </ref>). <p> Furthermore, since the regression surface's estimated covariance is Wishart, i.e. n b S ~ W p (S; n q), then nc 0 b Sc ~ c 2 is a chi-squared random variable with n q degrees of freedom for all fixed vectors c (p fi 1) <ref> [13, page 67] </ref>.
Reference: [14] <author> J.V. Miller and C.V. Stewart, </author> <title> MUSE: Robust Surface Fitting using Unbiased Scale Estimates, </title> <journal> IEEE CVPR, </journal> <year> 1996, </year> <pages> 300-306. </pages>
Reference-contexts: As with all the surface growing algorithms, we start with a set of seed regions. Here, we leverage off the criteria's ability to factor in uncertainty, and seed with small surface patches extracted from a robust local operator. We chose to construct our seed regions using MUSE <ref> [14] </ref> due to its abilities to withstand outliers and extract multiple surfaces in a given region. To use the NPI criterion, we calculate robust normal estimates for every pixel assigned to a seed region.
Reference: [15] <author> M.J. Mirza and K.L. Boyer, </author> <title> An Information Theoretic Robust Sequential Procedure for Surface Model Order Selection in Noisy Range Data, </title> <journal> IEEE CVPR, </journal> <year> 1992, </year> <pages> 366-371. </pages>
Reference-contexts: 1 Introduction Surface growing range segmentation <ref> [2, 4, 7, 17, 11, 15, 6] </ref> is a local-to-global approach to surface reconstruction. Seed regions initially isolated from discontinu-ities are expanded until the boundaries of the surfaces are detected.
Reference: [16] <author> C.V. Stewart, </author> <title> Expected Performance of Robust Estimators Near Discontinuities, </title> <address> ICCV, </address> <year> 1995, </year> <pages> 969-974. </pages>
Reference-contexts: Even robust estimators, designed for immunity to outliers, are thwarted by the intrinsic structure in the outlying samples from across discontinuities <ref> [16] </ref>. Current surface growing techniques, however, have two shortcomings. The first is a dependence on global thresholds. For instance, points are identified as inliers if their residual distances are within 3s range units of the current fit. <p> Also note, the prediction interval performance is achieved without a known or globally estimated scale parameter. on a scene composed of a series of 4s steps. For comparison we include a segmentation from Fitzgibbon et al.'s 12 The limit for window based robust operators is even higher <ref> [16] </ref>. Raw Data UE Reconstruction SPPI, NPI, SPI Reconstruction are bridged by the UE segmenter, however, the prediction interval segmenter handles the small steps correctly due to the SPI. range segmenter (UE segmenter [6]).
Reference: [17] <author> G. Taubin, </author> <title> Estimation of Planar Curves, Surfaces, and NonPlanar Space Curves Defined by Implicit Equations with Applications to Edge and Range Image Segmentation, </title> <booktitle> T-PAMI 13 (1991), </booktitle> <volume> no. 11, </volume> <pages> 1115-1138. </pages>
Reference-contexts: 1 Introduction Surface growing range segmentation <ref> [2, 4, 7, 17, 11, 15, 6] </ref> is a local-to-global approach to surface reconstruction. Seed regions initially isolated from discontinu-ities are expanded until the boundaries of the surfaces are detected.
References-found: 17

