URL: http://www.eecs.berkeley.edu/~pvi/cs252/project_report.ps.gz
Refering-URL: http://www.eecs.berkeley.edu/~pvi/courses/fall95/fall95.html
Root-URL: http://www.cs.berkeley.edu
Note: Contents  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> H. F. Silverman et. al, </author> <title> Processor Reconfiguration Through Instruction-Set Metamorphosis, </title> <journal> IEEE Computer, </journal> <volume> 23(3) </volume> <pages> 11-18, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: By this parameterization, we can study the general problem, by abstracting out considerations as to whether the programmable unit 1 is on the processor chip or on a separate chip. The references <ref> [1] </ref>, [2] report speedups for several arithmetic operations. Our first objective is to evaluate the performance of these operations, parameterized by communication overhead and logic delays. <p> This is an interesting active research area by itself [14], [15]. This topic, however, is beyond the scope of this work. Due to the recent success and popularity of FPGAs, several systems have been built with a programmable unit added on to a host system. PRISM <ref> [1] </ref> [2] developed at Brown University demonstrates the use of reconfigurable logic to substantial speedup in the case of large regular binary operations. <p> DLX is a simple processor, representative of the current generation of RISC processors. Berkeley has a DLX simulator and the Gnu-C-Compiler targeted for DLX. The source code for the DLX simulator is also available.The program interface for the programmable unit will be through Instruction-Set Metamorphosis as proposed in <ref> [1] </ref> i.e, new instructions are added to the processor. The functionality of the instruction depends on the application. The new instructions are implemented by modifying the simulator. The functionality of the programmable unit is also implemented in software, inside the simulator. Our primary measure of performance is execution time.
Reference: [2] <editor> M. Walzlowski et. al, </editor> <booktitle> PRISM-II Compiler and Architecture, Proceedings of the IEEE worksop on FPGAs for Custom Computing Machines 1993, </booktitle> <pages> pp 9-16. </pages>
Reference-contexts: By this parameterization, we can study the general problem, by abstracting out considerations as to whether the programmable unit 1 is on the processor chip or on a separate chip. The references [1], <ref> [2] </ref> report speedups for several arithmetic operations. Our first objective is to evaluate the performance of these operations, parameterized by communication overhead and logic delays. <p> This is an interesting active research area by itself [14], [15]. This topic, however, is beyond the scope of this work. Due to the recent success and popularity of FPGAs, several systems have been built with a programmable unit added on to a host system. PRISM [1] <ref> [2] </ref> developed at Brown University demonstrates the use of reconfigurable logic to substantial speedup in the case of large regular binary operations.
Reference: [3] <author> P.Bertin and H.Touati, </author> <title> PAM Programming Environments: Practice and Experience, </title> <booktitle> Proceedings of the IEEE worksop on FPGAs for Custom Computing Machines 1993, </booktitle> <pages> pp 9-16. </pages>
Reference-contexts: PRISM [1] [2] developed at Brown University demonstrates the use of reconfigurable logic to substantial speedup in the case of large regular binary operations. DEC Paris's PAM (Programmable Active Memories) is an array of Xilinx FPGAs attached to a host work station <ref> [3] </ref> The Super computing Research Center in Maryland has build a system called SPLASH [4]. SPLASH has been used to speed up genome sequence matching applications. We find that the existing literature does not analyze the effect of processor-programmable-logic-interface on the performance of the system.
Reference: [4] <author> D.Lopresti, </author> <title> Rapid Implementation of a Genetic Sequence Comparator using Field-Programmable Logic Arrays, </title> <booktitle> Advanced Research in VLSI, </booktitle> <month> April </month> <year> 1991, </year> <pages> pp 138-152. </pages>
Reference-contexts: DEC Paris's PAM (Programmable Active Memories) is an array of Xilinx FPGAs attached to a host work station [3] The Super computing Research Center in Maryland has build a system called SPLASH <ref> [4] </ref>. SPLASH has been used to speed up genome sequence matching applications. We find that the existing literature does not analyze the effect of processor-programmable-logic-interface on the performance of the system.
Reference: [5] <author> M.Shand and J.Vuillemin, </author> <title> Fast Implementations of RSA Cryptography, </title> <booktitle> Proceedings of the 11th Symposium on Computer Arithmetic, </booktitle> <year> 1993, </year> <pages> pp. 252-259. </pages>
Reference: [6] <author> Andre DeHon, </author> <title> DPGA-Coupled Microprocessors: </title> <booktitle> Commodity ICs for the Early 21st Century, Proceedings of the IEEE worksop on FPGAs for Custom Computing Machines 1994, </booktitle> <pages> pp 31-39. </pages>
Reference-contexts: Improving processor-FPGA communication delays sounds more plausible. One could conceive the FPGA and the processor being in the same Multi Chip Module (MCM) or even in the same chip as suggested in <ref> [6] </ref>. With mpeg play, we were able to schedule the code to utilize the processor and FPGA in parallel. This implementation was robust is the sense that its performance was practically unaffected by variations in communication delay and FPGA circuit delay parameters.
Reference: [7] <author> Wayne Luk, Vincent Lok, Ian Page: </author> <title> Hardware Acceleration of Divide-and-Conquer Paradigms: a Case Study, </title> <booktitle> Proceedings of the IEEE worksop on FPGAs for Custom Computing Machines 1993, </booktitle> <pages> pp 192-201 &lt;P&gt; </pages>
Reference-contexts: A very general and flexible interface between the processor and the FPGA has been designed for the SPLASH system <ref> [7] </ref>, [8]. A detailed description of the interface can be found in [8], [9]. In this report, we will give details sufficient enough to motivate our model of the processor-programmable-unit interface. <p> This would 7 require O (N) operations for insertion sort and O (log N) operations for heap sort per number. A programmable unit can implement this efficiently requiring effectively only one operation per number. A detailed exposition of this method appears in <ref> [7] </ref>. We give a brief summary below: 3.1 Experiment setup The idea is to have N registers to hold the N numbers. Since the hardware can be programmed to have logic between the registers, the programmable unit can behave like an active and intelligent memory.
Reference: [8] <author> Jeffrey M. Arnold, </author> <title> The Splash 2 Software Environment, </title> <booktitle> Proceedings of the IEEE work-sop on FPGAs for Custom Computing Machines 1993, </booktitle> <pages> pp 88 - 93. </pages>
Reference-contexts: A very general and flexible interface between the processor and the FPGA has been designed for the SPLASH system [7], <ref> [8] </ref>. A detailed description of the interface can be found in [8], [9]. In this report, we will give details sufficient enough to motivate our model of the processor-programmable-unit interface. <p> A very general and flexible interface between the processor and the FPGA has been designed for the SPLASH system [7], <ref> [8] </ref>. A detailed description of the interface can be found in [8], [9]. In this report, we will give details sufficient enough to motivate our model of the processor-programmable-unit interface. The SPLASH system (Fig 1) consists of a Sun Sparcstation host, an interface board and up to 16 Splash array boards.
Reference: [9] <institution> Splash 2 interface, Athanas and B.Pudipeddi, </institution> <type> private communication </type>
Reference-contexts: A very general and flexible interface between the processor and the FPGA has been designed for the SPLASH system [7], [8]. A detailed description of the interface can be found in [8], <ref> [9] </ref>. In this report, we will give details sufficient enough to motivate our model of the processor-programmable-unit interface. The SPLASH system (Fig 1) consists of a Sun Sparcstation host, an interface board and up to 16 Splash array boards. <p> Fig 3 shows such an arrangement. Details of such an arrangement can be found in <ref> [9] </ref>.
Reference: [10] <institution> Programmable Logic Data Book, Xilinx Inc. </institution>
Reference-contexts: These results were obtained by simulation. The figures show a linear relationship between T fpga and execution time, as one would expect. The operations are pipelined and the programmable unit can operate at 30MHz, considering the FPGAs on the market today <ref> [10] </ref>. If the processor has a clock of 300MHz, this means that we require 10 processor clock cycles between the start of two successive FSND instructions anyway, even if we allow out of order completion.
Reference: [11] <author> Le Gall Didier, </author> <title> MPEG: A Video Compression Standard for Multimedia Applications, </title> <journal> Communications of the ACM, </journal> <month> April </month> <year> 1991, </year> <month> Vol.34., No.4. </month> <pages> pp 45-58. 35 </pages>
Reference: [12] <author> Wallace Gregory K, </author> <title> JPEG: A Compression Standard for still images, </title> <journal> Communications of the ACM, </journal> <month> April </month> <year> 1991, </year> <month> Vol.34, No.4., </month> <pages> pp 31-44. </pages>
Reference: [13] <author> John L Hennessy and David Patterson, </author> <title> Computer Architecture A Quantitative Approach, 2nd ed., </title> <publisher> Morgan Kaufman 1995. </publisher>
Reference: [14] <author> A Kalavade, </author> <title> System Level Codesign of Mixed Hardware-Software systems, </title> <type> Ph.D Dissertation, </type> <institution> UC Berkeley, </institution> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: This is an interesting active research area by itself <ref> [14] </ref>, [15]. This topic, however, is beyond the scope of this work. Due to the recent success and popularity of FPGAs, several systems have been built with a programmable unit added on to a host system.
Reference: [15] <author> A Kalavade, </author> <title> A Global Criticality / Local Phase driven algorithm for the constrained Hardware/Software Partitioning prolem, </title> <booktitle> Proceedings of Codes/CASHE 94, Third International workshop on Hardware/Software Codesign Grenoble, </booktitle> <address> France, Sept 22-24, </address> <year> 1994. </year> <pages> pp 42-48. </pages>
Reference-contexts: This is an interesting active research area by itself [14], <ref> [15] </ref>. This topic, however, is beyond the scope of this work. Due to the recent success and popularity of FPGAs, several systems have been built with a programmable unit added on to a host system.
Reference: [16] <author> B.Sikstrom, et al., </author> <title> A high speed 2-D discrete cosine transform chip, INTEGRATION, </title> <note> the VLSI journal 5 (1987) pp 159-169. </note>
Reference-contexts: These are the major tradeoffs to be looked into. We also discuss the latency details of the IDCT unit. 5.2.1 Implementation Details This section outlines the rudiments of the implementation details of the IDCT computation as done in <ref> [16] </ref>. The details are the definition of the IDCT, the elementary processing elements, set-up of the 1-D IDCT and expansion to 2-D IDCT are exposited in that order. <p> Implementation of 1-D IDCT: Each PE operates on one set of coefficients and 8 such PEs can generate 8 1-D IDCTs. The ROM for this case has 2 8 entries and as in <ref> [16] </ref>, the symmetry in the coefficients can be exploited to reduce this to just 2 4 = 16 entries. Thus, the first-level 1-D IDCT takes W d clock cycles and the hardware involved are 8 PEs and 8 16-element (with W c bits) ROMs.
Reference: [17] <author> U.Sjostrosm, et al., </author> <title> Discrete Cosine Transform Chips for real-time video applications, </title> <booktitle> Proc. IEEE ISCAS '90, </booktitle> <pages> pp 77-80, </pages> <address> New Orleans, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: This code is implemented in the MPEG decoder mpeg play of UC Berkeley when compiled with the Quality Flag. 13 5.2 Hardware Implementation in IDCT In this subsection, we present details of a hardware implementation of the IDCT procedure. The references on the hardware implementations can be seen in <ref> [17] </ref>, [18], [21]. Here we provide sufficient details of the implementation, so that we have an estimate of the space on the chip required. We shall also show that the speed of the computation is directly proportional to the precision of the input data.
Reference: [18] <author> M.Maruyama, et al., </author> <title> VLSI Architecture and Implementation of a multi-function, forward/inverse Discrete Cosine Transform Processor, </title> <booktitle> SPIE Vol. 1360 Visual Communications and Image Processing '90 pp 410-417. </booktitle>
Reference-contexts: Thus, in the decoding stage, a major computationally intensive procedure is the Inverse Discrete Cosine Transform (IDCT). This makes this application a good benchmark program to run on our DLX simulator and implement the IDCT operation in programmable logic . The IDCT is a floating point intensive operation <ref> [18] </ref> and mpeg play offers two alternative implementations to this computation. These alternatives are explained in the subsection on arithmetic of the IDCT below. <p> The references on the hardware implementations can be seen in [17], <ref> [18] </ref>, [21]. Here we provide sufficient details of the implementation, so that we have an estimate of the space on the chip required. We shall also show that the speed of the computation is directly proportional to the precision of the input data.
Reference: [19] <author> Christoph Loe*er, et al., </author> <title> Practical Fast 1-D DCT Algorithms with 11 Multiplications, </title> <booktitle> Proc. ICASSP 1989 pp. </booktitle> <pages> 988-991. </pages>
Reference-contexts: The first of the implementations j rev dct compromises quality for speed of execution, while the latter float idct is slow, but provides good quality of the transform. 12 5.1.1 j rev dct The implementation is based on a recent result in literature <ref> [19] </ref> which provides an algorithm for IDCT computation in 11 multiplications and 29 additions. It has been shown [19] that 11 is the lower bound for the number of multiplications in the 1 fi 8 IDCT computation. The implementation of j rev dct is on a corollary result in [19] that <p> speed of execution, while the latter float idct is slow, but provides good quality of the transform. 12 5.1.1 j rev dct The implementation is based on a recent result in literature <ref> [19] </ref> which provides an algorithm for IDCT computation in 11 multiplications and 29 additions. It has been shown [19] that 11 is the lower bound for the number of multiplications in the 1 fi 8 IDCT computation. The implementation of j rev dct is on a corollary result in [19] that uses 12 multiplications and 32 additions. <p> literature <ref> [19] </ref> which provides an algorithm for IDCT computation in 11 multiplications and 29 additions. It has been shown [19] that 11 is the lower bound for the number of multiplications in the 1 fi 8 IDCT computation. The implementation of j rev dct is on a corollary result in [19] that uses 12 multiplications and 32 additions. The advantage of this method is that no data path contains more than one multiplication; this allows a very simple and accurate implementation in scaled fixed-point arithmetic, with a minimal number of shifts. <p> Consequently, its run time is data dependent. The error analysis of this implementation is discussed in <ref> [19] </ref>. The code for j rev dct can be obtained by anonymous ftp from ftp-mm.cs.berkeley.edu. 5.1.2 float idct As the name suggests, this implementation uses floating point multiplication and hence achieves accuracy better than the fixed point arithmetic implementation of j rev dct.
Reference: [20] <author> Kronader,T., </author> <title> et alk., VLSI implementation of the discrete cosine transform, </title> <booktitle> Proc. Nordic Symposium. Computers and Communications, </booktitle> <address> Tampere, Finland, </address> <month> June 13-16, </month> <year> 1984. </year>
Reference-contexts: This a 2-D 8 fi 8 transform can be computed in 16 1-D 8-point transforms and with the same set of coefficients and using a transposition of the array of the intermediate data. Processing Elements (PE): The processing elements are based on distributed arithmetic <ref> [20] </ref>, which is an efficient method for computing inner products. The main parts in one PE are a shift-accumulator and a ROM containing all possible sums of the coefficients in the inner product.
Reference: [21] <author> P Duhamel, et al., </author> <title> A DCT chip based on a new structured and computationally effiecient DCT algorithm, </title> <booktitle> Proc. IEEE ISCAS '90, </booktitle> <pages> pp 77-80, </pages> <address> New Orleans May 1990. </address> <month> 36 </month>
Reference-contexts: The references on the hardware implementations can be seen in [17], [18], <ref> [21] </ref>. Here we provide sufficient details of the implementation, so that we have an estimate of the space on the chip required. We shall also show that the speed of the computation is directly proportional to the precision of the input data.
References-found: 21

