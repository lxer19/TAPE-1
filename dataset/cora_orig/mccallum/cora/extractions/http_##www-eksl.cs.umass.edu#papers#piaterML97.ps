URL: http://www-eksl.cs.umass.edu/papers/piaterML97.ps
Refering-URL: http://eksl-www.cs.umass.edu/publications.html
Root-URL: 
Title: A Randomized ANOVA Procedure for Comparing Performance Curves  
Author: Justus H. Piater and Paul R. Cohen 
Abstract: Three factors enter into analyses of performance curves such as learning curves: the amount of training, the learning algorithm, and performance. Often we want to know whether the algorithm affects performance, whether the effect of training on performance depends on the algorithm, and whether these effects are localized in regions of the curves. Analysis of variance is adapted to answer these questions. The carryover effects of learning violate the assumptions of parametric analysis of variance, but they are rendered harmless by a novel, randomized version of the analysis. After a brief outline of the statistical preliminaries, we present the procedure along with some examples on real learning curves, discuss power and Type I error, and give some examples of how our method can be applied to answer more advanced questions in comparing performance curves.
Abstract-found: 1
Intro-found: 1
Reference: <author> Cohen, P. R. </author> <year> (1995). </year> <title> Empirical Methods for Artificial Intelligence. </title> <address> Cam-bridge, Massachusetts: </address> <publisher> MIT Press. 15 Keppel, G. </publisher> <year> (1973). </year> <title> Design and Analysis: A Researcher's Handbook. </title> <address> Engle--wood Cliffs: </address> <publisher> Prentice-Hall. </publisher>
Reference-contexts: The homogeneity of covariance problem can be sidestepped, however, and accurate p values can be obtained, by deriving sampling distributions for F statistics that take the nonindependence of learning curve data into account. The procedure is called randomization <ref> (see, e.g., Cohen 1995, ch. 5) </ref>. Consider first the null hypothesis that Algorithm has no effect on performance. If it were true, then the lines associated with algorithm A 1 in Figure 2 might equally well be associated with A 2 , or with any other algorithm. <p> Randomized sampling distributions say nothing about populations, so the null hypothesis is that Algorithm is independent of performance, on this data set. One should not lose sight of this important difference between classical sampling distributions and randomized sampling distributions <ref> (Cohen 1995, p. 175) </ref>. 3 The Procedure in Detail Consider a set A of m learning algorithms A 1 ; : : : ; A m . For each algorithm A i we have a set L (i) of l learning curves L (i) (i) l .
Reference: <author> O'Brien, R. G. and M. K. </author> <title> Kaiser (1985). MANOVA method for analyzing repeated measures designs: An extensive primer. </title> <journal> Psychological Bulletin 97 (2), </journal> <pages> 316-333. </pages>
Reference: <author> Sutton, R. S. </author> <year> (1988). </year> <title> Learning to predict by the methods of temporal differences. </title> <booktitle> Machine Learning 3, </booktitle> <pages> 9-44. </pages>
References-found: 3

