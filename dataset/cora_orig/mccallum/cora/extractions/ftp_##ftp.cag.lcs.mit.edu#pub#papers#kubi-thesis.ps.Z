URL: ftp://ftp.cag.lcs.mit.edu/pub/papers/kubi-thesis.ps.Z
Refering-URL: http://www.cag.lcs.mit.edu/alewife/papers/kubi-thesis.html
Root-URL: 
Title: Closing the Window of Vulnerability in Multiphase Memory Transactions: The Alewife Transaction Store  
Author: by John David Kubiatowicz Anant Agarwal Campbell L. Searle 
Degree: Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Master of Science at the  The author hereby grants to MIT permission to reproduce and to distribute copies of this thesis document in whole or in part. Signature of Author  Certified by  Associate Professor of Computer Science and Electrical Engineering Thesis Supervisor Accepted by  Chairman, Departmental Committee on Graduate Students  
Note: c Massachusetts Institute of Technology,  
Date: February 1993  1993  February 1, 1993  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Sarita V. Adve and Mark D. Hill. </author> <title> Weak Ordering ANew Definition. </title> <booktitle> In Proceedings 17th Annual International Symposium on Computer Architecture, </booktitle> <address> New York, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Applying basic pipelining ideas, resource utilization can be improved by allowing a processor to transmit more than one memory request at a time. Multiple outstanding transactions can be supported using software prefetch [7, 24], rapid context switching [28, 4], or weak ordering <ref> [1] </ref>. Studies have shown that the utilization of the network, processor, and memory systems can be improved almost in proportion to the number of outstanding transactions allowed [22, 16]. <p> More study is called for here. For instruction accesses, this solution is probably superior to the one given in the previous chapters. It eliminates all concerns of deadlock which are raised by multiple 1 For a discussion of memory-model issues, see <ref> [8, 12, 13, 1] </ref>. 82 primary transactions with thrashlock (Section 4.5). 6.2 Signaling with Block Multithreading With more intrusive pipeline modifications, other solutions become possible. Rather than polling, a system could eliminate the window of vulnerability by consuming data as soon as it returns.
Reference: [2] <author> Anant Agarwal, Johnathan Babb, David Chaiken, Godfrey D'Souza, Kirk John-son, David Kranz, John Kubiatowicz, Beng-Hong Lim, Gino Maa, Ken MacKen-zie, Dan Nussbaum, Mike Parkin, and Donald Yeung. Sparcle: </author> <title> Today's Micro for Tomorrow's Multiprocessor. </title> <booktitle> In HOTCHIPS, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: As shown in Figure 5-1, an Alewife processing node consists of a 33 MHz Sparcle processor, 64K bytes of direct-mapped cache, a 4Mbyte portion of globally-shared main memory, and a floating-point coprocessor. The Sparcle processor is a modified SPARC processor <ref> [19, 2] </ref>, utilizing register-windows for rapid context-switching and block mul-tithreading [4]. The current implementation provides four distinct hardware contexts. Both the cache and floating-point units are SPARC compatible. The nodes communicate via messages through a cost-effective direct network with a mesh topology.
Reference: [3] <author> Anant Agarwal, David Chaiken, Godfrey D'Souza, Kirk Johnson, David Kranz, John Kubiatowicz, Kiyoshi Kurihara, Beng-Hong Lim, Gino Maa, Dan Nuss-baum, Mike Parkin, and Donald Yeung. </author> <title> The MIT Alewife Machine: A Large-Scale Distributed-Memory Multiprocessor. </title> <booktitle> In Proceedings of Workshop on Scalable Shared Memory Multiprocessors. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year> <note> An extended version of this paper has been submitted for publication, and appears as MIT/LCS Memo TM-454, </note> <year> 1991. </year>
Reference-contexts: This thesis investigates several methods of closing the window of vulnerability, culminating in a unifying architectural framework, the transaction store. As described in Chapter 5, the complete framework has been implemented in the MIT Alewife machine <ref> [3] </ref>; however, other multiprocessor architects may choose to implement a subset of this framework.
Reference: [4] <author> Anant Agarwal, Beng-Hong Lim, David A. Kranz, and John Kubiatowicz. </author> <month> APRIL: </month> <title> A Processor Architecture for Multiprocessing. </title> <booktitle> In Proceedings 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 104-114, </pages> <address> New York, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Such transactions include first-time data fetches and invalidations required to enforce coherence. Applying basic pipelining ideas, resource utilization can be improved by allowing a processor to transmit more than one memory request at a time. Multiple outstanding transactions can be supported using software prefetch [7, 24], rapid context switching <ref> [28, 4] </ref>, or weak ordering [1]. Studies have shown that the utilization of the network, processor, and memory systems can be improved almost in proportion to the number of outstanding transactions allowed [22, 16]. <p> The Sparcle processor is a modified SPARC processor [19, 2], utilizing register-windows for rapid context-switching and block mul-tithreading <ref> [4] </ref>. The current implementation provides four distinct hardware contexts. Both the cache and floating-point units are SPARC compatible. The nodes communicate via messages through a cost-effective direct network with a mesh topology.
Reference: [5] <institution> Alpha Architecture Reference Manual. Digital Press, </institution> <year> 1992. </year>
Reference-contexts: The simplest solution to this problem is to separate the data access from the trapping behavior. Trapping loads can be replaced by a two-instruction sequence which uses a non-trapping load followed by a test-and 85 trap instruction. For trapping stores, an Alpha-style load-locked/store-conditional sequence <ref> [5] </ref> is probably desirable, with a Full/Empty bit check sandwiched between two non-trapping data operations. 6.3 Signaling With Interleaved Multithreading Signaling is much easier to implement for processors which support multiple concurrent (or interleaved) hardware threads, such as HEP [27] or Monsoon [25].
Reference: [6] <author> P. A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, MA, </address> <year> 1987. </year>
Reference-contexts: However, for other schemes, the cost is less significant; more details will be given in Chapter 5. 4.1.3 Deadlock Problems Unfortunately, the locking mechanism can lead to four distinct types of deadlock, illustrated in Figure 4-1. This figure contains four different waits-for graphs <ref> [6] </ref>, which represent dependencies between transactions. In these graphs, the large italic letters 32 represent transactions: "D " for data transactions and "I " for instruction transactions. The superscripts either "P" or "S" represent primary or secondary transactions, respectively.
Reference: [7] <author> David Callahan, Ken Kennedy, and Allan Porterfield. </author> <title> Software Prefetching. </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS IV), </booktitle> <pages> pages 40-52. </pages> <publisher> ACM, </publisher> <month> April </month> <year> 1991. </year>
Reference-contexts: Such transactions include first-time data fetches and invalidations required to enforce coherence. Applying basic pipelining ideas, resource utilization can be improved by allowing a processor to transmit more than one memory request at a time. Multiple outstanding transactions can be supported using software prefetch <ref> [7, 24] </ref>, rapid context switching [28, 4], or weak ordering [1]. Studies have shown that the utilization of the network, processor, and memory systems can be improved almost in proportion to the number of outstanding transactions allowed [22, 16].
Reference: [8] <author> Lucien M. Censier and Paul Feautrier. </author> <title> A New Solution to Coherence Problems in Multicache Systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-27(12):1112-1118, </volume> <month> December </month> <year> 1978. </year>
Reference-contexts: More study is called for here. For instruction accesses, this solution is probably superior to the one given in the previous chapters. It eliminates all concerns of deadlock which are raised by multiple 1 For a discussion of memory-model issues, see <ref> [8, 12, 13, 1] </ref>. 82 primary transactions with thrashlock (Section 4.5). 6.2 Signaling with Block Multithreading With more intrusive pipeline modifications, other solutions become possible. Rather than polling, a system could eliminate the window of vulnerability by consuming data as soon as it returns.
Reference: [9] <author> David Chaiken, John Kubiatowicz, and Anant Agarwal. </author> <note> LimitLESS Directories: </note>
Reference-contexts: That is, after a first-time fetch of data from a remote node, subsequent accesses of the data are satisfied entirely within the node. The resulting cache coherence problem can be solved using a variety of directory based schemes <ref> [15, 23, 9] </ref>. In a cache-based system, memory and processor resources are wasted if no processing is done while waiting for memory transactions to complete. Such transactions include first-time data fetches and invalidations required to enforce coherence. <p> Several messages have entered the processor's input queue before the desired memory response. Consequently, the processor will not make forward progress unless a high-availability interrupt is invoked to process these messages. In Alewife, for example, high-availability interrupts are used to implement the LimitLESS coherence protocol <ref> [9] </ref>, a fast user and system-level messaging facility, and network deadlock recovery. LimitLESS interrupts must be able to occur under 17 most circumstances, because they can affect forward progress in the machine, both by deadlocking the protocol and by blocking the network. <p> The nodes communicate via messages through a cost-effective direct network with a mesh topology. A single-chip communications and memory management unit (CMMU) on each node holds the cache tags and transaction buffers (described below), implements a variant of the cache coherence protocol described in <ref> [9] </ref>, and provides a direct message-passing 46 interface to the underlying network [20]. A block-diagram of this chip is shown in This diagram, which is not to scale, illustrates the major components of the CMMU, namely, cache management, memory management, transaction store, remote transaction machine, and network interface. <p> The cache management block is responsible for handling cache fills and invalidations, as well as full/empty bit synchronization [14, 26]; it is responsible for processing all control (non-data) messages for the processor-side of the LimitLESS cache-coherence protocol <ref> [9] </ref>. The memory management block handles the memory-side of the LimitLESS protocol, as well as memory requests from the local processor and DMA requests from the Network Interface; in addition, it handles DRAM refresh and error-correction (ECC).
References-found: 9

