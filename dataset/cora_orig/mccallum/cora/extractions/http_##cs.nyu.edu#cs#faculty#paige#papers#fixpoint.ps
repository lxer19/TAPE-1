URL: http://cs.nyu.edu/cs/faculty/paige/papers/fixpoint.ps
Refering-URL: http://cs.nyu.edu/cs/faculty/paige/research.html
Root-URL: http://www.cs.nyu.edu
Title: Program Derivation by Fixed Point Computation  
Author:  Jiazhen Cai and Robert Paige 
Address: 251 Mercer Street New York, NY 10012/USA  
Affiliation: Dept. of Computer Science NYU/Courant  
Abstract: This paper develops a transformational paradigm by which nonnumerical algorithms are treated as fixed point computations derived from very high level problem specifications. We begin by presenting an abstract functional + problem specification language SQ , which is shown to express any partial recursive function in a fixed point normal form. Next, we give a nondeterministic iterative schema that in the case of finite iteration generalizes the 'chaotic iteration' of Cousot and Cousot for computing fixed points of monotone functions efficiently. New techniques are discussed for recomputing fixed points of distributive functions efficiently. Numerous examples illustrate how these techniques for computing and recomputing fixed points can be incorporated within a transformational programming methodology to facilitate the design and verification of nonnumerical algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Aczel, P. </author> <title> An Introduction to Inductive Definitions. In Handbook of Mathematical Logic, </title> <editor> Barwise, J., Ed., </editor> <publisher> North-Holland, </publisher> <year> 1977, </year> <pages> pp. 739-782. </pages>
Reference-contexts: We are further encouraged by the following facts: Any set generated by inductive definitions can also be defined as the least fixed point of a monotone function <ref> [1] </ref>; Without a fixed point operator, a first order language on finite structures cannot express transitive closure [2]; The language of Relational Calculus [14] over a totally ordered finite domain plus least fixed points of monotone operators precisely expresses all queries computable in polynomial time (in the size of the domain)
Reference: 2. <author> Aho, A.V. and Ullman J.D. </author> <title> Universality of Data Retrieval Language. </title> <booktitle> Proc. 6th ACM Symp. on Principles of Programming Languages, </booktitle> <year> 1979, </year> <pages> pp. 110-117. </pages>
Reference-contexts: We are further encouraged by the following facts: Any set generated by inductive definitions can also be defined as the least fixed point of a monotone function [1]; Without a fixed point operator, a first order language on finite structures cannot express transitive closure <ref> [2] </ref>; The language of Relational Calculus [14] over a totally ordered finite domain plus least fixed points of monotone operators precisely expresses all queries computable in polynomial time (in the size of the domain) on a Turing machine [39, 79]. 1 Part of this work was done while Paige was a <p> Conclusion 7.1. A Survey of Related Work Earlier in the paper the important connection between fixed point computation and global program optimization was mentioned. More recently, fixed point computation has also had a strong impact on relational databases. In 1979 Aho and Ullman <ref> [2] </ref> noted that Codd's Relational Calculus is unable to express transitive closure, and they suggested extending Relational Calculus with fixed point operators. Their paper triggered an extensive study into the expressive power of languages with fixed point constructs. In the theoretical direction logicians have made rapid progress.
Reference: 3. <author> Aho, A., Hopcroft, J., and Ullman, J. </author> <title> Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: Of course, we old new old old should also exploit any local simplifications or optimizations to implement assignment p := d (p,dp) as efficiently as possible. Below we illustrate Transformation 1 with a few computable problems discussed in <ref> [3] </ref>: Example 6: (Reachability continued) If we define f (s) = e [s] s, then f must be inflationary at w. <p> For all vertices v domain e range e, let component (v) be the strongly-connected component that contains v. Then the set C and map component can be computed in O (#e) time [73] (see also <ref> [3] </ref>). Hence, we can conclude, + Lemma 13: For directed graphs in general, r can be maintained in O (1 + #e ) steps when w changes by an element addition and in O (1 + #e ) steps when w changes by an element deletion (c.f. Lemma 12).
Reference: 4. <author> Aho, A., Sethi, R., and Ullman, J. </author> . <title> Compilers. </title> <publisher> Addison-Wesley , 1986. </publisher>
Reference-contexts: The preceding rules define a decidable sublanguage of computable monotone (respectively antimonotone) + SQ functions, which we call positive (respectively negative) functions that can be recognized, say, by an S + attributed attribute grammar (see <ref> [4] </ref>). For example, the SQ function f (x) = s - (t - x) is recognized as positive, because it is the composition of two negative basic functions f1 (e) = s - e and f2 (x) = t - x.
Reference: 5. <author> Ajtai, M and Gurevich, Yuri. </author> <title> "Monotone versus Positive". </title> <type> JACM 34, </type> <month> 4 (Oct. </month> <year> 1987), </year> <pages> 1004-1015. </pages>
Reference-contexts: One problem is that fixed point operations can be computed most easily for monotone formula, but monotonicity is undecidable [32]. Also, not every formula monotone in its parameter P is equivalent to a formula positive in P <ref> [5] </ref>. Since positivity is decidable, it is fortunate that Gurevich and Shelah [34] proved that, for every monotone formula y, there is a positive formula y' such that y and y' have the same least fixed point.
Reference: 6. <author> Backus, J. </author> <title> "Can Programming Be Liberated from the von Neumann Style? A Functional Style and Its Algebra of Programs". </title> <type> CACM 21, </type> <month> 8 (Aug </month> <year> 1978), </year> <pages> 613-641. </pages>
Reference-contexts: this paper rudimentary theoretical underpinnings for a computer assisted program development system in which low level debugging is unnecessary, programming is highly simplified, algorithm design is facilitated by a small collection of powerful transformations, and the major effort is in problem specification (where errors can still be introduced). 46 Backus <ref> [6] </ref> has criticized conventional programming languages for 'their close coupling of semantics to state transitions, their division of programming into a world of expressions and a world of statements, their inability to effectively use powerful combining forms for building new programs from existing ones, and their lack of useful mathematical properties
Reference: 7. <author> Bauer, F. L. and Wossner, H. </author> <title> Algorithmic Language and Program Development. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1982. </year>
Reference-contexts: Other researchers <ref> [7, 62, 49] </ref> have employed fixed point transformations applied to general recursion equations. However, their transformations seem less amenable to full mechanization than ours, and they foster a syntactic bias towards a depth-first or breadth-first search implementation.
Reference: 8. <author> Birkhoff, G. </author> <title> Lattice Theory. </title> <publisher> American Mathematical Society, </publisher> <address> Providence, </address> <year> 1966. </year>
Reference-contexts: We investigate a class of such algorithms that are all instances of a general nondeterministic iterative algorithm schema for computing least or greatest fixed points of computable functions. Various fixed point theorems due to Tarski [75], Kleene [45], Cousot and Cousot [18], and others <ref> [8] </ref> have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory <p> The final section surveys related work and discusses open problems. 2. Preliminaries We first review a few basic definitions and concepts of lattice theory that underlie our main results. This background material may be found in any introductory text on lattice theory; for example, Birkhoff <ref> [8] </ref> or + Gratzer [30]. After that we describe the problem specification language SQ to be used in illustrating transformations for computing and recomputing fixed points. 2.1. Definitions A poset (L,) is a reflexive, transitive, antisymmetric, binary relation on a set L.
Reference: 9. <author> Cai, J. </author> <title> Fixed Point Computation and Transformational Programming. </title> <type> Ph.D. </type> <institution> Th., Rutgers University, </institution> <month> May </month> <year> 1987. </year> <note> appears in Rutgers Technical Report DSC-TR-217. </note>
Reference-contexts: Explicit transformations for greatest fixed points can be found in <ref> [9] </ref>. 3.1.
Reference: 10. <author> Cai, J. </author> <title> An iterative Version of Hopcroft and Tarjan's Planarity Testing Algorithm. </title> <type> Tech. </type> <address> Rept. 324, NYU/Courant Insitute, </address> <month> Oct., </month> <year> 1987. </year>
Reference-contexts: Besides the examples presented here, we have also shown that a significant fragment of an optimizing compiler [11] and even the problem of planarity testing <ref> [10] </ref> are amenable to our transformational methodology. Several open problems and further research arise from this work. We mention some of these briefly below: 1. Are there more general conditions under which the least and greatest fixed points can be recomputed efficiently? 2.
Reference: 11. <author> Cai, J. and Paige, R. </author> <title> Binding Performance at Language Design Time. </title> <booktitle> Proc. 14th ACM Symp. on Principles of Programming Languages, </booktitle> <address> Munich, West Germany, </address> <month> January, </month> <year> 1987, </year> <pages> pp. 85-97. </pages>
Reference-contexts: Transformation 5 also provides an accurate upper bound on the iteration count for the while-loop in code (36). The bound is #dec (p) at the final value of p. Such complexity information provided by Transformation 5 is exploited in <ref> [11] </ref> to develop a syntactic characterization of a class of set theoretic fixed point expressions that can be computed in linear time and space with respect to the input/output space. <p> Besides the examples presented here, we have also shown that a significant fragment of an optimizing compiler <ref> [11] </ref> and even the problem of planarity testing [10] are amenable to our transformational methodology. Several open problems and further research arise from this work. We mention some of these briefly below: 1. <p> We mention some of these briefly below: 1. Are there more general conditions under which the least and greatest fixed points can be recomputed efficiently? 2. Can our previous work characterizing a class of linear time set theoretic fixed point expressions <ref> [11] </ref> be generalized to fixed points over more general lattices and semilattices? 3. Can our transformations be used to implement Prolog queries efficiently? 4.
Reference: 12. <author> Cocke, J. and Kennedy, K. </author> <title> "An Algorithm for Reduction of Operator Strength". </title> <type> CACM 20, </type> <month> 11 (Nov </month> <year> 1977), </year> <pages> 850-856. </pages>
Reference-contexts: We can see that, in general, difference code is not unique. n Difference code for products like 5x are included in the strength reduction transformations of most optimizing compilers and are used to replace certain products with less expensive sums <ref> [12] </ref>. Difference code for a more general class of expressions including the set former above are central to finite differencing and can be found in [22, 26, 57].
Reference: 13. <author> Cocke, J. and Schwartz, J. T. </author> <booktitle> Programming Languages and Their Compilers. </booktitle> <address> CIMS, New York University, </address> <year> 1969. </year> <note> Lecture Notes. </note>
Reference-contexts: Various fixed point theorems due to Tarski [75], Kleene [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz <ref> [13] </ref>, Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory [79, 39, 40, 33, 35, 59], and are used to support high level program transformations [2, 29, <p> In the early development of this field Cocke and Schwartz <ref> [13] </ref> and Kildall [44] justified convergence of their algorithms using condition 1 of Theorem 3 and restricted function f to be distributive; i.e., for every x,y T, f (x y) = f (x) f (y). (Note that distributivity implies monotonicity, but monotonicity does not imply distributivity.) Tenenbaum [77] and Kam and
Reference: 14. <author> Codd, E. </author> <title> "A Relational Model of Data for Large Shared Data Banks". </title> <type> CACM 13, </type> <month> 6 (June </month> <year> 1970), </year> <pages> 377-387. </pages>
Reference-contexts: We are further encouraged by the following facts: Any set generated by inductive definitions can also be defined as the least fixed point of a monotone function [1]; Without a fixed point operator, a first order language on finite structures cannot express transitive closure [2]; The language of Relational Calculus <ref> [14] </ref> over a totally ordered finite domain plus least fixed points of monotone operators precisely expresses all queries computable in polynomial time (in the size of the domain) on a Turing machine [39, 79]. 1 Part of this work was done while Paige was a summer faculty at IBM Yorktown and
Reference: 15. <author> Cousot., P. </author> <title> Semantic Foundations of Program Analysis. In Program Flow Analysis, </title> <editor> Muchnick, S., Jones, N., Eds., </editor> <publisher> Prentice Hall, </publisher> <year> 1981, </year> <pages> pp. 303-342. </pages>
Reference-contexts: Kildall's algorithm was later refined by Tenenbaum [77] and Kam and Ullman [42]. Cousot and Cousot used a strategy similar to this algorithm called 'chaotic' iteration for defining least fixed points as the limit of a sequence, and they applied it in new settings <ref> [16, 15] </ref>. Let e represent the edges of a program control flow graph with nodes labelled 1, ..., k (cf. Example 5).
Reference: 16. <author> Cousot, P. and Cousot, R. </author> <title> Abstract Interpretation: A Unified Lattice Model for Static Analysis of Programs by Construction or Approximation of Fixed points. </title> <booktitle> Proc. 4th ACM Symp. on Principles of Programming Languages, </booktitle> <address> Los Angeles, CA, </address> <month> Jan, </month> <year> 1977, </year> <pages> pp. 238-252. </pages>
Reference-contexts: Various fixed point theorems due to Tarski [75], Kleene [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others <ref> [36, 42, 16, 67, 43, 74] </ref> to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory [79, 39, 40, 33, 35, 59], and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54, <p> [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification <ref> [16, 17, 20, 23] </ref>, arise in complexity theory [79, 39, 40, 33, 35, 59], and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54, 70, 60, 81, 51]. <p> Kildall's algorithm was later refined by Tenenbaum [77] and Kam and Ullman [42]. Cousot and Cousot used a strategy similar to this algorithm called 'chaotic' iteration for defining least fixed points as the limit of a sequence, and they applied it in new settings <ref> [16, 15] </ref>. Let e represent the edges of a program control flow graph with nodes labelled 1, ..., k (cf. Example 5).
Reference: 17. <author> Cousot, P. and Cousot, R. </author> <title> "Automatic Synthesis of Optimal Invariant Assertions: </title> <journal> Mathematical Foundations". SIGPLAN Notices 12, </journal> <month> 8 (Aug </month> <year> 1977), </year> <pages> 1-12. </pages>
Reference-contexts: [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification <ref> [16, 17, 20, 23] </ref>, arise in complexity theory [79, 39, 40, 33, 35, 59], and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54, 70, 60, 81, 51]. <p> We prove that a subset of SQ with operational semantics can express all partially recursive functions; A new nondeterministic algorithm schema for computing least and greatest fixed points of monotone functions is given. This schema generalizes the 'chaotic iteration' found in Kildall [44], Tenenbaum [77], and Cousot and Cousot <ref> [17] </ref> (restricted to finite iteration), so that it can be adapted in a wider range of contexts to synthesize efficient algorithms and to provide succinct transformational correctness proofs. <p> = -- if q p, and -p q- otherwise; d (p, p q) = p q, Assuming that all of the posets (T , , 0 ), i = 1,...,k, are the same, we obtain the 'chaotic' iteration described by i i i 18 Tenenbaum [77] and Cousot and Cousot <ref> [17] </ref> (restricted to finite iteration) to compute least fixed points of systems of equations x = f (x ,...,x ), i=1,...,k; that is, i i 1 k p := w (while $i=1,...,k | f (p) &gt; p (i) ) i p (i) := f (p) i More generally, if we redefine
Reference: 18. <author> Cousot, P. and Cousot, R. </author> <title> "Constructive Versions of Tarski's Fixed Point Theorems". </title> <journal> Pacific J. Math 82, </journal> <month> 1 (May </month> <year> 1979), </year> <pages> 43-57. </pages>
Reference-contexts: We investigate a class of such algorithms that are all instances of a general nondeterministic iterative algorithm schema for computing least or greatest fixed points of computable functions. Various fixed point theorems due to Tarski [75], Kleene [45], Cousot and Cousot <ref> [18] </ref>, and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise <p> Explicit transformations for greatest fixed points can be found in [9]. 3.1. Basic Theory All of our fixed point transformations are derived from the following theorem and corollary, which can be derived from Tarski's more general Theorem [75] or its constructive reformulation due to Cousot and Cousot <ref> [18] </ref>: Theorem 1: (Paige and Henglein [56]) Let (T,) be a poset with a unique minimum element i designated 0. Let f: T fi T be a monotone computable function. <p> The similarity in the programs resulting from applying Transformations 1 and 2 suggests that under some 15 conditions, functions f (s) and s f (s) have the same fixed point. Indeed, we can reformulate Theorem 4.1 of Cousot and Cousot <ref> [18] </ref> without their condition that T be complete: Theorem 5: Let (T,) be a join semilattice. Let f: T fi T be a monotone computable function. Let c = LFP (w f (s),s) 1 c = LFP (f) ,w 3 Then 1. <p> If w f (w), then w f (s) and f have the same set of fixed points that are greater than or equal to w, and thus c = c when they are defined. 1 3 Proof: We prove 2 only. For 1 and 3 see Cousot and Cousot <ref> [18] </ref>. We show that c is a fixed point of h (x) = x f (x), and any other fixed point of h that is greater than 1 or equal to w is also greater than or equal to c .
Reference: 19. <author> Davis, M. and Weyuker, E. </author> <title> Computability, Complexity, and Languages. </title> <publisher> Academic Press, </publisher> <year> 1983. </year> <note> 20. </note> <editor> de Bakker, J. </editor> <title> Mathematical Theory of Program Correctness. </title> <publisher> Prentice-Hall, </publisher> <year> 1980. </year>
Reference-contexts: following program: 2 1 G := --1 (while $ z (-x G | rhs-x- (T lhs [G ])- - G )) 1 1 G &lt;G with:= z&gt; 2 1 end n More complicated grammar transformations such as those used to turn a positive context free grammar into Greibach normal form <ref> [19] </ref> can also be expressed as fixed point specifications and significant loop fusion of the same kind has been observed. Example 21: Consider the following interprocedural analysis problem. Suppose we are given a set of procedure names procs of some input program P.
Reference: 21. <author> Dewar, R., Grand, A., Liu S. C., Schwartz, J. T., and Schonberg, E. </author> <title> "Program by Refinement, as Exemplified by the SETL Representation Sublanguage". </title> <type> TOPLAS 1, </type> <month> 1 (July </month> <year> 1979), </year> <pages> 27-49. </pages>
Reference-contexts: Further improvement in the performance of code (5) can be achieved by applying finite differencing [57, 55] and data structure selection <ref> [21, 65, 56] </ref>. Finite differencing eliminates a major source of inefficiency within (5) - the repeated calculation of e [p] - p at the top of the while-loop. This is achieved by preserving and exploiting the invariant: new = e [p] - p within the while-loop.
Reference: 22. <author> Earley, J. </author> <title> "High Level Iterators and a Method for Automatically Designing Data Structure Representation". </title> <journal> Journal of Computer Languages 1, </journal> <volume> 4 (1976), </volume> <pages> 321-342. </pages>
Reference-contexts: Difference code for a more general class of expressions including the set former above are central to finite differencing and can be found in <ref> [22, 26, 57] </ref>. The following example adopted from [53] shows how finite differencing is used in combination with the fixed point transformations to yield efficient programs: Example 17: (Graph reachability continued) The program derived in Example 11 contains an expensive expression w e [p] pin the while-loop.
Reference: 23. <author> Emerson, E.A. and Lei, C. L. </author> <title> Model Checking in the Propositional Mu-Calculus. </title> <type> Tech. </type> <institution> Rept. 86-06, University of Texas at Austin, Department of Computer Sciences, </institution> <year> 1986. </year> <month> 47 </month>
Reference-contexts: [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification <ref> [16, 17, 20, 23] </ref>, arise in complexity theory [79, 39, 40, 33, 35, 59], and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54, 70, 60, 81, 51].
Reference: 24. <author> Farrow R. </author> <title> Automatic generation of fixed-point-finding evaluators for circular, but well-defined, attribute grammars. </title> <booktitle> Proc. ACM Symp. on Compiler Construction, </booktitle> <year> 1986, </year> <pages> pp. 85-99. </pages>
Reference-contexts: Can our transformations be used to implement Prolog queries efficiently? 4. Can they be applied to implement circular attribute grammars efficiently along the lines of Farrow <ref> [24] </ref>? Conventional software development methodology can be derived from the following informal schema: (converge) problem formulation; algorithm design; programming; debugging; end Problem formulation and algorithm design involve the most conceptual work, and programming and debugging are the most tedious.
Reference: 25. <author> Feather, Martin S. </author> <title> A survey and classification of Some Program Transformation Approaches and Techniques. </title> <booktitle> In IFIP TC 2 WG2.1 Working Conference on Program Specification and Transformation, </booktitle> <address> Bad Tolz, FRG, </address> <year> 1986, </year> <editor> L. G. L. T. Meertens, Ed., </editor> <publisher> North-Holland, </publisher> <year> 1987, </year> <pages> pp. 165-196. </pages>
Reference-contexts: 1. Introduction In a recent survey article <ref> [25] </ref> Martin Feather has said that the current state of the art of program transformations is still some distance from its ambitious goals - to dramatically improve the construction, reliability, maintenance, and extensibility of software. Our paper represents an attempt towards achieving these goals.
Reference: 26. <author> Fong, A. and Ullman, J. </author> <title> Induction Variables in Very High Level Languages. </title> <booktitle> Proc. 3rd ACM Symp. on Principles of Programming Languages, </booktitle> <month> Jan, </month> <year> 1976, </year> <pages> pp. 104-112. </pages>
Reference-contexts: Difference code for a more general class of expressions including the set former above are central to finite differencing and can be found in <ref> [22, 26, 57] </ref>. The following example adopted from [53] shows how finite differencing is used in combination with the fixed point transformations to yield efficient programs: Example 17: (Graph reachability continued) The program derived in Example 11 contains an expensive expression w e [p] pin the while-loop.
Reference: 27. <author> Garey, M. and Johnson, D. Computers and Intractability. Freeman and Johnson, </author> <year> 1979. </year>
Reference-contexts: But 2 1 13 according to <ref> [27] </ref>, e is a feedback set of e, and the problem of finding the minimum feedback set is NP-complete. 1 Thus, Theorem 19: The problem of minimizing the number of equations in system (60) by substitution is NP-complete. n Example 20: (Grammar transformation.) Let G be a context free grammar with
Reference: 28. <author> Goldberg, A. and Paige, R. </author> <title> Stream Processing. </title> <booktitle> Proc. ACM Symp. on LISP and Functional Programming, </booktitle> <month> Aug, </month> <year> 1984, </year> <pages> pp. 53-62. </pages>
Reference-contexts: a problem P (s) can be solved incrementally by computing P at an initial point s and 0 then at successive points s = g (s ), i = 1, .., n, where g is an inexpensive incremental calculation and s = s. ni i-1 Finite differencing and stream processing <ref> [28] </ref> are program transformations that provide a formal basis for studying the three kinds of recomputations just described. However, previous investigations avoided consideration of fixed point expressions. <p> Goldberg and Paige called this technique vertical loop fusion <ref> [28] </ref>. The following theorem and corollary can sometimes be used to introduce opportunities for vertical fusion.
Reference: 29. <author> Gordon, M., Milner, A., and Wadsworth, C. </author> <title> Edinburgh LCF. </title> <publisher> Springer-Verlag, </publisher> <year> 1979. </year>
Reference: 30. <author> Gratzer, G. </author> <title> General Lattice Theory. </title> <publisher> Birkhauser, </publisher> <year> 1978. </year>
Reference-contexts: The final section surveys related work and discusses open problems. 2. Preliminaries We first review a few basic definitions and concepts of lattice theory that underlie our main results. This background material may be found in any introductory text on lattice theory; for example, Birkhoff [8] or + Gratzer <ref> [30] </ref>. After that we describe the problem specification language SQ to be used in illustrating transformations for computing and recomputing fixed points. 2.1. Definitions A poset (L,) is a reflexive, transitive, antisymmetric, binary relation on a set L.
Reference: 31. <author> Gries, D. </author> <title> "Describing an Algorithm by Hopcroft". </title> <journal> Acta Informatica 2 (1973), </journal> <pages> 97-109. </pages>
Reference-contexts: The resulting algorithm was suggested in [58] and comes closer to Hopcroft's original algorithm [38]. Gries gave a more complete but lower level top-down (almost transformational) proof of Hopcroft's algorithm <ref> [31] </ref>. n Computing fixed points for functions of the form f (w,s) = LFP (g (s,t),t) are discussed later. ,w 3.4. Special Data Types It is also worthwhile to refine Transformation 1 with respect to different data types.
Reference: 32. <author> Gurevich, Y. </author> <title> Toward Logic Tailored for Computational Complexity. </title> <booktitle> Lecture Notes in Math: Computation and Proof Theory, </booktitle> <year> 1984, </year> <pages> pp. 175-216. </pages>
Reference-contexts: This condition holds if g is any subset of an set theoretical expression involving only 0, 1, and input parameters. Compile time analysis of inclusion and membership relations have been studied before by Schwartz [68, 67]. 6.3. Monotone and Antimonotone Although monotonicity is undecidable <ref> [32] </ref>, in practice we can recognize a large subclass of computable monotone and antimonotone functions as described below: 1. Define basic computable monotone and antimonotone functions as are shown in table 6-1; 2. <p> Immerman also showed that any query expressible with nested fixed points can be expressed with a single least fixed point application. One problem is that fixed point operations can be computed most easily for monotone formula, but monotonicity is undecidable <ref> [32] </ref>. Also, not every formula monotone in its parameter P is equivalent to a formula positive in P [5].
Reference: 33. <author> Gurevich, Y. </author> <booktitle> Logic and the Challenge of Computer Science. In Current Trends in Theoretical Computer Science, </booktitle> <editor> Egon Boerger, Ed., </editor> <publisher> Computer Science Press, </publisher> <year> 1987. </year>
Reference-contexts: have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory <ref> [79, 39, 40, 33, 35, 59] </ref>, and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54, 70, 60, 81, 51]. <p> Function f is said to be monotone (respectively antimonotone) if for every two elements x, y belonging to its domain such that x y, then f (x) ' f (y) (respectively, f (x) ' f (y)). If posets (T,) and (Q,') are the same, then following Gurevich <ref> [33] </ref>, we say that f is inflationary (respectively, deflationary) at x if f (x) x (resp. f (x) x). Function f is said to be inflationary (resp. deflationary) if it is inflationary (resp. deflationary) at each point in its domain.
Reference: 34. <author> Gurevich, Y. and Shelah, S. </author> <title> Fixed-point Extensions of First-order Logic. </title> <booktitle> 26th Annual Symposium on Foundation of computer Science, </booktitle> <year> 1985, </year> <pages> pp. 346-353. </pages>
Reference-contexts: One problem is that fixed point operations can be computed most easily for monotone formula, but monotonicity is undecidable [32]. Also, not every formula monotone in its parameter P is equivalent to a formula positive in P [5]. Since positivity is decidable, it is fortunate that Gurevich and Shelah <ref> [34] </ref> proved that, for every monotone formula y, there is a positive formula y' such that y and y' have the same least fixed point.
Reference: 35. <author> Harel, D. and Kozen, D. </author> <title> "A Programming Language for the Inductive Sets, </title> <journal> and Applications". Information and Control 63, </journal> <volume> 2 (1985), </volume> <pages> 1-27. </pages>
Reference-contexts: have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory <ref> [79, 39, 40, 33, 35, 59] </ref>, and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54, 70, 60, 81, 51].
Reference: 36. <author> Hecht, M. and Ullman, J. </author> <title> "A Simple Algorithm for Global Data Flow Analysis Problems". </title> <journal> SIAM J. Comput. </journal> <volume> 4, </volume> <month> 4 (December </month> <year> 1975), </year> <pages> 519-532. </pages>
Reference-contexts: Various fixed point theorems due to Tarski [75], Kleene [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others <ref> [36, 42, 16, 67, 43, 74] </ref> to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory [79, 39, 40, 33, 35, 59], and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54,
Reference: 37. <author> Henschen,L.J. and Naqvi,S.A. </author> <title> "On Compiling Queries in Recursive First-order Database". </title> <booktitle> CACM 31 (1984), </booktitle> <pages> 47-85. </pages>
Reference-contexts: No data is transmitted more than once along the same path. While their method is AI oriented, their one-element-at-a-time strategy is quite close to the principle of our finite differencing. In 1984, Henschen and Naqvi <ref> [37] </ref> suggested that a recursive query could be expanded into a set of nonrecursive ones that could be evaluated iteratively. The expansion terminates when no more solutions are found.
Reference: 38. <author> Hopcroft, J. </author> <title> An n log n Algorithm for Minimizing States in a Finite Automaton. In Theory of Machines and Computations, </title> <editor> Kohavi and Paz, Ed., </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1971, </year> <pages> pp. 189-196. </pages> <booktitle> Proc. Intl. Symp. on Theory of Machines and Computation. </booktitle>
Reference-contexts: Application of finite differencing to preserve the values of f (Q) and Q - f (Q) incrementally leads to an algorithm with the same O (nlogn) time bound as Hopcroft's <ref> [38] </ref>. n It is interesting to consider an alternative operational derivation of an algorithm to solve the single function coarsest partition problem based on Theorem 4 (a). Example 9: According to Example 8, we want to compute GFP (f). <p> Note that Hopcroft's algorithm had a similar time bound but required W (nk) space in the worst case <ref> [38] </ref>. We can also consider an alternative derivation that leads to an algorithm with the same asymptotic worst case time but with fewer split operations and O (nk) space. <p> The resulting algorithm was suggested in [58] and comes closer to Hopcroft's original algorithm <ref> [38] </ref>. Gries gave a more complete but lower level top-down (almost transformational) proof of Hopcroft's algorithm [31]. n Computing fixed points for functions of the form f (w,s) = LFP (g (s,t),t) are discussed later. ,w 3.4.
Reference: 39. <author> Immerman, N. </author> <title> Relational queries computable in polynomial time. </title> <booktitle> Proc. 14th ACM Symp. on Theory of Computing, </booktitle> <month> May, </month> <year> 1982, </year> <pages> pp. 147-152. </pages>
Reference-contexts: have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory <ref> [79, 39, 40, 33, 35, 59] </ref>, and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54, 70, 60, 81, 51]. <p> operator, a first order language on finite structures cannot express transitive closure [2]; The language of Relational Calculus [14] over a totally ordered finite domain plus least fixed points of monotone operators precisely expresses all queries computable in polynomial time (in the size of the domain) on a Turing machine <ref> [39, 79] </ref>. 1 Part of this work was done while Paige was a summer faculty at IBM Yorktown and while both authors were at Rutgers University. This work is also partly based upon research supported by the Office of Naval Research under Contract No. <p> Their paper triggered an extensive study into the expressive power of languages with fixed point constructs. In the theoretical direction logicians have made rapid progress. In 1982 Immerman <ref> [39] </ref> and Vardi [79] proved that, in the presence of a linear order (), every relational query computable by a Turing Machine in polynomial time with respect to the size of its input is expressible in first order logic (FO) extended with a least fixed point operator (LFP).
Reference: 40. <author> Immerman, N. </author> <title> Languages Which Capture Complexity Classes. </title> <booktitle> Proc. 15th ACM Symp. on Theory of Computing, </booktitle> <month> April, </month> <year> 1983, </year> <pages> pp. 347-354. </pages>
Reference-contexts: have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory <ref> [79, 39, 40, 33, 35, 59] </ref>, and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54, 70, 60, 81, 51].
Reference: 41. <author> Kam, J. and Ullman, J. </author> <title> "Global Data Flow Analysis and Iterative Algorithms". </title> <journal> JACM 23, </journal> <volume> 1 (1976), </volume> <pages> 158-171. </pages>
Reference-contexts: Kildall [44] justified convergence of their algorithms using condition 1 of Theorem 3 and restricted function f to be distributive; i.e., for every x,y T, f (x y) = f (x) f (y). (Note that distributivity implies monotonicity, but monotonicity does not imply distributivity.) Tenenbaum [77] and Kam and Ullman <ref> [42, 41] </ref> later designed algorithms based on the more general condition 2 of Theorem 3 and the more general monotonicity property for function f. 3.2.
Reference: 42. <author> Kam, J. and Ullman, J. </author> <title> "Monotone Data Flow Analysis Frameworks". </title> <journal> Acta Informatica 7 (1977), </journal> <pages> 305-317. </pages>
Reference-contexts: Various fixed point theorems due to Tarski [75], Kleene [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others <ref> [36, 42, 16, 67, 43, 74] </ref> to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory [79, 39, 40, 33, 35, 59], and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54, <p> Kildall [44] justified convergence of their algorithms using condition 1 of Theorem 3 and restricted function f to be distributive; i.e., for every x,y T, f (x y) = f (x) f (y). (Note that distributivity implies monotonicity, but monotonicity does not imply distributivity.) Tenenbaum [77] and Kam and Ullman <ref> [42, 41] </ref> later designed algorithms based on the more general condition 2 of Theorem 3 and the more general monotonicity property for function f. 3.2. <p> Kildall [44] introduced a fairly general method for program analysis using iterative schema (27). Kildall's algorithm was later refined by Tenenbaum [77] and Kam and Ullman <ref> [42] </ref>. Cousot and Cousot used a strategy similar to this algorithm called 'chaotic' iteration for defining least fixed points as the limit of a sequence, and they applied it in new settings [16, 15].
Reference: 43. <author> Kaplan, M. and Ullman, J. </author> <title> "A Scheme for the Automatic Inference of Variable Types". </title> <journal> JACM 27, </journal> <volume> 1 (1980), </volume> <pages> 128-145. </pages>
Reference-contexts: Various fixed point theorems due to Tarski [75], Kleene [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others <ref> [36, 42, 16, 67, 43, 74] </ref> to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory [79, 39, 40, 33, 35, 59], and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54, <p> Recomputation of Fixed Points of Distributive Functions Although we can recompute least fixed points incrementally under some conditions, the decremental recomputation of least fixed points is much more difficult. In <ref> [43] </ref>, Kaplan and Ullman specify their solution to a general weak type analysis problem as GFP (Y F (s)), where Y (s) = LFP (s B (x), x), F (s) = LFP (s F (x), x), and B and F are two monotone functions representing backward and forward type analysis respectively.
Reference: 44. <author> Kildall, G. </author> <title> A Unified Approach to Global Program Optimization. </title> <booktitle> Proc. 1st ACM Symp. on Principles of Programming Languages, </booktitle> <month> Oct, </month> <year> 1973, </year> <pages> pp. 194-206. </pages>
Reference-contexts: Various fixed point theorems due to Tarski [75], Kleene [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall <ref> [44] </ref>, Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory [79, 39, 40, 33, 35, 59], and are used to support high level program transformations [2, 29, 7, 49, <p> We prove that a subset of SQ with operational semantics can express all partially recursive functions; A new nondeterministic algorithm schema for computing least and greatest fixed points of monotone functions is given. This schema generalizes the 'chaotic iteration' found in Kildall <ref> [44] </ref>, Tenenbaum [77], and Cousot and Cousot [17] (restricted to finite iteration), so that it can be adapted in a wider range of contexts to synthesize efficient algorithms and to provide succinct transformational correctness proofs. <p> Since the range of e is finite, condition 4 of Theorem 3 guarantees that after a finite number of steps, p will be the least fixed point of s e [s] in the space of all sets that include w. n Example 5: Kildall's form of the constant propagation problem <ref> [44] </ref> satisfies the dual form of condition 2 of Theorem 3. <p> In the early development of this field Cocke and Schwartz [13] and Kildall <ref> [44] </ref> justified convergence of their algorithms using condition 1 of Theorem 3 and restricted function f to be distributive; i.e., for every x,y T, f (x y) = f (x) f (y). (Note that distributivity implies monotonicity, but monotonicity does not imply distributivity.) Tenenbaum [77] and Kam and Ullman [42, 41] <p> Hence, q is a common fixed point of F. n 1 2 1 19 Based on Theorem 6 we can show that two seemingly different classical methods of global program analysis are identical. Kildall <ref> [44] </ref> introduced a fairly general method for program analysis using iterative schema (27). Kildall's algorithm was later refined by Tenenbaum [77] and Kam and Ullman [42].
Reference: 45. <author> Kleene. </author> <title> Introduction to Meta-Mathematics. </title> <publisher> Van Nostrand, </publisher> <address> Princeton, NJ, </address> <year> 1952. </year>
Reference-contexts: We investigate a class of such algorithms that are all instances of a general nondeterministic iterative algorithm schema for computing least or greatest fixed points of computable functions. Various fixed point theorems due to Tarski [75], Kleene <ref> [45] </ref>, Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification [16,
Reference: 46. <author> Marlowe, T., Paull, M.C. and Ryder, B. </author> <title> Applicability Of Incremental Iterative Algorithms. </title> <type> Tech. </type> <institution> Rept. DCS-TR-159, Rutgers University, </institution> <month> Aug, </month> <year> 1985. </year>
Reference-contexts: We have also failed to find a general efficient decremental method for i computing least fixed points. However, least fixed points can still be recomputed efficiently under some restricted conditions. One special case observed in <ref> [46] </ref> is when a function has a unique fixed point. In this case, the fixed point can be treated as both a least and a greatest fixed point, and thus can be recomputed incrementally and decrementally.
Reference: 47. <author> McKay, D. and Shapiro, S. </author> <title> Using Active Connection Graphs for reasoning with resursive rules. </title> <booktitle> Proceedings 7th IJCAI, </booktitle> <year> 1981, </year> <pages> pp. 368-374. </pages>
Reference-contexts: They all noticed that the repeated computation of expensive expressions in the fixed point iteration is one of the main sources of inefficiency. Numerous strategies have been proposed to solve this problem. In 1981 McKay and Shapiro <ref> [47] </ref> presented a rule-based inference system that can handle recursive rules. In their system, queries are implemented as processes representing nodes in a graph with edges reflecting 45 producer-consumer relationships between processes.
Reference: 48. <author> Morris, K., Ullman, J. D., and Gelder, A. V. </author> <title> Design Overview of the NAIL! System. </title> <type> Tech. </type> <institution> Rept. STAN-CS-86-1108, Stanford University, </institution> <month> May, </month> <year> 1986. </year>
Reference-contexts: In 1985, Ullman [78] presented a more general approach. Instead of finding a single solution, he suggested the use of different strategies (capture rules) for different queries. This idea is fully developed in the design of NAIL! <ref> [48] </ref>. One interesting strategy used in NAIL! is to divide the whole system of queries into subsystems, with each subsystem corresponding to a strongly connected component in the dependency graph. These subsystems are solved one by one in a topologic order. This strategy further reduces the number of worksets.
Reference: 49. <author> Naqvi, S. and Henschen, L. </author> <title> Synthesizing Least Fixed Point Queries into Non-recursive Iterative Programs. </title> <booktitle> IJCAI 83, </booktitle> <month> Aug, </month> <year> 1983, </year> <pages> pp. 25-28. </pages>
Reference-contexts: Other researchers <ref> [7, 62, 49] </ref> have employed fixed point transformations applied to general recursion equations. However, their transformations seem less amenable to full mechanization than ours, and they foster a syntactic bias towards a depth-first or breadth-first search implementation.
Reference: 50. <author> Naughton, J. F. </author> <title> Optimizing Function-Free Recursive Inference Rules. </title> <type> Tech. </type> <institution> Rept. STAN-CS-86-1114, Stanford University, </institution> <year> 1986. </year> <month> 48 </month>
Reference-contexts: The expansion terminates when no more solutions are found. Their method works well when the query dependency graph forms a single cycle, but in more general situations the control structures of the generated programs would be very complicated. In 1986, Naughton <ref> [50] </ref> showed that under some conditions, this expansion can be done at compile time. In 1985, Ullman [78] presented a more general approach. Instead of finding a single solution, he suggested the use of different strategies (capture rules) for different queries.
Reference: 51. <author> O'Keefe, R.. </author> <title> Finite Fixed-Point Problems. </title> <booktitle> Logic Programming, </booktitle> <year> 1987, </year> <pages> pp. 729-743. </pages> <booktitle> Proc. 4th Intl. Conf. on Logic Prog.. </booktitle>
Reference: 52. <author> Paige, R. </author> <title> Transformational Programming -- Applications to Algorithms and Systems. </title> <booktitle> Proc. 10th ACM Symp. on Principles of Programming Languages, </booktitle> <month> Jan, </month> <year> 1983, </year> <pages> pp. 73-87. </pages>
Reference-contexts: These transformations introduce a minimal form of algorithmic strategy. In the second phase of compilation, the system uses a generalized finite differencing technique to introduce access paths and basic invariants that serve to implement the strategy efficiently <ref> [57, 52, 55] </ref>. In the final phase, the low level set-based program that results from the preceding transformations is compiled into conventional code. Elaboration of the three-step automatic programming scheme just sketched is found in [56]. <p> In <ref> [52] </ref> an efficient dead code elimination procedure was derived from the following specification: (52) live = LFP (f ) 3 where f (s) = prints instof [usetodef [iuses [s]]] compound [s], which determines live statements from data 3 and control flow considerations.
Reference: 53. <author> Paige, R. </author> <title> Supercompilers - Extended Abstract. In Program Transformation and Programming Environments, </title> <editor> P. Pepper, Ed., </editor> <publisher> Springer Verlag, </publisher> <year> 1984, </year> <pages> pp. 331-340. </pages>
Reference-contexts: Preliminary ideas that support this approach are embodied in a working three-phase prototype compiler that automatically translates abstract problem specifications into efficient RAM code <ref> [53, 56] </ref>. This compiler, which was implemented by Paige within the RAPTS transformational programming system, has been used to generate many efficient programs of moderate complexity from succinct problem statements, e.g., graph reachability, cycle detection, live code analysis, and attribute closure. <p> Difference code for a more general class of expressions including the set former above are central to finite differencing and can be found in [22, 26, 57]. The following example adopted from <ref> [53] </ref> shows how finite differencing is used in combination with the fixed point transformations to yield efficient programs: Example 17: (Graph reachability continued) The program derived in Example 11 contains an expensive expression w e [p] pin the while-loop. However, its costly computation can be avoided by applying finite differencing.
Reference: 54. <author> Paige, R., Tarjan, R., and Bonic, R. </author> <title> "A Linear Time Solution to the Single Function Coarsest Partition Problem". </title> <type> TCS 40, </type> <month> 1 (Sep </month> <year> 1985), </year> <pages> 67-84. </pages>
Reference-contexts: The Single Function Coarsest Partition Problem inputs a finite set s, an initial partition P of s, and a total function h on s. It outputs the coarsest (i.e., maximal) refinement Q of P such that " b Q $ d Q | h [b] d. In <ref> [54] </ref> this problem is reformulated as computing the greatest fixed point (that is also a refinement of P) of the following monotone function -1 -1 f (Q) = -b h [q]: b Q, q Q | b h [q] --- which maps a partition Q into a refinement of Q.
Reference: 55. <author> Paige, R. </author> <title> "Programming With Invariants". </title> <booktitle> IEEE Software 3, </booktitle> <month> 1 (Jan </month> <year> 1986), </year> <pages> 56-69. </pages>
Reference-contexts: These transformations introduce a minimal form of algorithmic strategy. In the second phase of compilation, the system uses a generalized finite differencing technique to introduce access paths and basic invariants that serve to implement the strategy efficiently <ref> [57, 52, 55] </ref>. In the final phase, the low level set-based program that results from the preceding transformations is compiled into conventional code. Elaboration of the three-step automatic programming scheme just sketched is found in [56]. <p> Further improvement in the performance of code (5) can be achieved by applying finite differencing <ref> [57, 55] </ref> and data structure selection [21, 65, 56]. Finite differencing eliminates a major source of inefficiency within (5) - the repeated calculation of e [p] - p at the top of the while-loop. <p> For example, a selection sort, which repeatedly performs a linear time search for the minimum value of a set, can be turned into a faster heap sort by using a 'dynamic' heap data structure to compute the minimum set value with only a log factor cost each time <ref> [55] </ref>. <p> However, previous investigations avoided consideration of fixed point expressions. In this section we extend that earlier work in finite differencing by presenting rules for efficient recomputation of fixed point expressions (44). 26 4.1. Finite Differencing In this section we give a brief introduction to finite differencing <ref> [57, 55] </ref>, a technique that can improve the performance of programs generated by our fixed point transformations. The basic goal of this technique is to replace direct calculations of costly expressions f (x ,...,x ) in a program region B by less expensive incremental m 1 calculations.
Reference: 56. <author> Paige, R. and Henglein, F. </author> <title> "Mechanical Translation of Set Theoretic Problem Specifications Into Efficient RAM Code - A Case Study". </title> <journal> Journal of Symbolic Computation 4, </journal> <month> 2 (Aug. </month> <year> 1987), </year> <pages> 207-232. </pages>
Reference-contexts: Preliminary ideas that support this approach are embodied in a working three-phase prototype compiler that automatically translates abstract problem specifications into efficient RAM code <ref> [53, 56] </ref>. This compiler, which was implemented by Paige within the RAPTS transformational programming system, has been used to generate many efficient programs of moderate complexity from succinct problem statements, e.g., graph reachability, cycle detection, live code analysis, and attribute closure. <p> In the final phase, the low level set-based program that results from the preceding transformations is compiled into conventional code. Elaboration of the three-step automatic programming scheme just sketched is found in <ref> [56] </ref>. This article makes the following contributions: + A very high level functional problem specification language SQ is presented. This language contains conventional expressions over boolean and integer datatypes, mathematical dictions found in finite set + theory, and least and greatest fixed point expressions. <p> Before stating our new results, it is worthwhile giving the reader a broader perspective by stepping through the three-phase RAPTS problem specification compiler using a simple case study. (A fuller discussion can be found in <ref> [56] </ref>.) Example 1: (Graph Reachability) Consider the problem of finding the set of vertices s reachable along paths in a directed graph from an arbitrary set of vertices w. We represent the graph by a finite set of edges e (without multi-edges), where each edge is a pair of vertices. <p> Further improvement in the performance of code (5) can be achieved by applying finite differencing [57, 55] and data structure selection <ref> [21, 65, 56] </ref>. Finite differencing eliminates a major source of inefficiency within (5) - the repeated calculation of e [p] - p at the top of the while-loop. This is achieved by preserving and exploiting the invariant: new = e [p] - p within the while-loop. <p> Basic Theory All of our fixed point transformations are derived from the following theorem and corollary, which can be derived from Tarski's more general Theorem [75] or its constructive reformulation due to Cousot and Cousot [18]: Theorem 1: (Paige and Henglein <ref> [56] </ref>) Let (T,) be a poset with a unique minimum element i designated 0. Let f: T fi T be a monotone computable function.
Reference: 57. <author> Paige, R. and Koenig, S. </author> <title> "Finite Differencing of Computable Expressions". </title> <journal> ACM TOPLAS 4, </journal> <month> 3 (July </month> <year> 1982), </year> <pages> 402-454. </pages>
Reference-contexts: These transformations introduce a minimal form of algorithmic strategy. In the second phase of compilation, the system uses a generalized finite differencing technique to introduce access paths and basic invariants that serve to implement the strategy efficiently <ref> [57, 52, 55] </ref>. In the final phase, the low level set-based program that results from the preceding transformations is compiled into conventional code. Elaboration of the three-step automatic programming scheme just sketched is found in [56]. <p> Further improvement in the performance of code (5) can be achieved by applying finite differencing <ref> [57, 55] </ref> and data structure selection [21, 65, 56]. Finite differencing eliminates a major source of inefficiency within (5) - the repeated calculation of e [p] - p at the top of the while-loop. <p> However, previous investigations avoided consideration of fixed point expressions. In this section we extend that earlier work in finite differencing by presenting rules for efficient recomputation of fixed point expressions (44). 26 4.1. Finite Differencing In this section we give a brief introduction to finite differencing <ref> [57, 55] </ref>, a technique that can improve the performance of programs generated by our fixed point transformations. The basic goal of this technique is to replace direct calculations of costly expressions f (x ,...,x ) in a program region B by less expensive incremental m 1 calculations. <p> Difference code for a more general class of expressions including the set former above are central to finite differencing and can be found in <ref> [22, 26, 57] </ref>. The following example adopted from [53] shows how finite differencing is used in combination with the fixed point transformations to yield efficient programs: Example 17: (Graph reachability continued) The program derived in Example 11 contains an expensive expression w e [p] pin the while-loop.
Reference: 58. <author> Paige, R. and Tarjan, R. </author> <title> "Three Partition Refinement Algorithms". </title> <journal> SIAM J. Comput. </journal> <volume> 16, </volume> <month> 6 (Dec </month> <year> 1987), </year> <pages> 973-989. </pages>
Reference-contexts: d (Q,q) = (Q - -q-) -q - b, b 8 where b -x f (Q) | x q and #x #q/2 The preceding feasible functions combine Hopcroft's `choose the smaller half' strategy with the double partition approach that Paige and Tarjan used to solve the relational coarsest partition problem <ref> [58] </ref>. <p> The resulting algorithm was suggested in <ref> [58] </ref> and comes closer to Hopcroft's original algorithm [38]. Gries gave a more complete but lower level top-down (almost transformational) proof of Hopcroft's algorithm [31]. n Computing fixed points for functions of the form f (w,s) = LFP (g (s,t),t) are discussed later. ,w 3.4. <p> Let Q be an initial partition. Then the 0 Relational Coarsest Partition Problem is to find the maximum stable partition Q Q . 0 Let #s = n and #e = m. Two algorithms are presented in <ref> [58] </ref>: one is a general algorithm with O (mn) time complexity, and the other uses the 'smaller half' strategy to achieve a lower time complexity O (mlogn). Both of these two algorithms can be formally derived from abstract specifications. <p> D (g (Q), Q) = -b g (Q) | ($ b Q | b b and #b #b /2)-1 2 1 2 1 2 d (Q,b) = Q datm (b) When the preceding functions are used in connection with Transformation 7, we can derive the O (mlogn) algorithm described in <ref> [58] </ref>. n To compute fixed points of functions defined on lattices that are not FD, we offer no general method other than what has been suggested in the previous section on special functions or on the classical iteration (13) implied by Corollary 2.
Reference: 59. <author> Papadimitriou, C. </author> <title> "A Note On The Expressive Power of PROLOG". </title> <booktitle> Bullitin of EATCS 26 (1985), </booktitle> <pages> 21-23. </pages>
Reference-contexts: have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory <ref> [79, 39, 40, 33, 35, 59] </ref>, and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54, 70, 60, 81, 51].
Reference: 60. <author> Paull, M. </author> <title> Algorithm Design - A recursion Transformation Framework. </title> <publisher> Wiley, </publisher> <year> 1988. </year>
Reference: 61. <author> Reif, J. H. and Lewis, H. R. </author> <title> Symbolic evaluation and the global value graph. </title> <booktitle> Proc. 4th ACM Symp. on Principle of Programming Languages. </booktitle> , <month> Jan, </month> <year> 1977, </year> <pages> pp. 104-118. </pages>
Reference-contexts: The next example illustrates this idea. Example 15: In the constant propagation algorithm given by Reif and Lewis <ref> [61, 80] </ref>, each assignment statement A is associated with either bottom (means undefined), top (means non-constant), or a real number that can result from the execution of A. Let R denote the set of real numbers.
Reference: 62. <author> Reif, J. and Scherlis, W. </author> <title> Deriving Efficient Graph Algorithms. </title> <institution> Carnegie-Mellon U., </institution> <year> 1982. </year> <type> Technical Report. </type>
Reference-contexts: Other researchers <ref> [7, 62, 49] </ref> have employed fixed point transformations applied to general recursion equations. However, their transformations seem less amenable to full mechanization than ours, and they foster a syntactic bias towards a depth-first or breadth-first search implementation.
Reference: 63. <author> Reps, T., Teitelbaum, T., and Demers, A. </author> <title> "Incremental Context-Dependent Analysis for Language-Based Editors". </title> <journal> ACM TOPLAS 5, </journal> <month> 3 (July </month> <year> 1983), </year> <pages> 449-477. </pages>
Reference-contexts: For example, the Cornell Synthesizer [76] is a syntactic editing system that uses an attribute grammar to implement program semantics. Whenever a program is modified using the synthesizer, the program's semantic information must be updated to reflect the editing changes. The attribute reevaluation algorithm of Reps, et. al <ref> [63] </ref> is an efficient incremental algorithm in the sense that it recomputes the new semantics from the old in an optimal way - performing asymptotically better than an algorithm that just recomputes the new semantics from scratch.
Reference: 64. <author> Rogers, H., Jr. </author> <title> Theory of Recursive Functions and Effective Computability. </title> <publisher> McGraw Hill, </publisher> <year> 1967. </year>
Reference-contexts: Every constant (denotations omitted here) and variable is an SQ expression; 2. if 2 See Rogers <ref> [64] </ref> for a more formal definition of computable functions on sets other than natural numbers. 3 Turing Machines are defined in Appendix I. 4 We do not simplify to -y: [x, y] f-, which in SETL means -y: $ x such that [x, y] f-. 6 x is a variable, +
Reference: 65. <author> Schonberg, E., Schwartz, J. T., and Sharir, M. </author> <title> "An Automatic Technique for Selection of Data Representations in in SETL Programs". </title> <journal> ACM TOPLAS 3, </journal> <month> 2 (Apr </month> <year> 1981), </year> <pages> 126-143. </pages>
Reference-contexts: Further improvement in the performance of code (5) can be achieved by applying finite differencing [57, 55] and data structure selection <ref> [21, 65, 56] </ref>. Finite differencing eliminates a major source of inefficiency within (5) - the repeated calculation of e [p] - p at the top of the while-loop. This is achieved by preserving and exploiting the invariant: new = e [p] - p within the while-loop.
Reference: 66. <author> Schwartz, J. T. </author> <title> On Programming: An Interim Report on the SETL Project, Installments I and II. </title> <address> CIMS, New York Univ., New York, </address> <year> 1974. </year>
Reference-contexts: If f is total and partially computable, then f is computable. 2.2. Language + Specification language SQ is essentially a functional subset of the SETL programming language <ref> [66] </ref> + augmented with fixed point operations. In addition to conventional boolean and integer datatypes, SQ includes finite tuples, sets, and maps, which can be nested to arbitrary depth.
Reference: 67. <author> Schwartz, J. T. </author> <title> "Optimization of Very High Level Languages, Parts I, II". </title> <editor> J. </editor> <booktitle> of Computer Languages 1, 2,3 (1975), </booktitle> <pages> 161-218. </pages>
Reference-contexts: Various fixed point theorems due to Tarski [75], Kleene [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others <ref> [36, 42, 16, 67, 43, 74] </ref> to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory [79, 39, 40, 33, 35, 59], and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54, <p> Transformation 2 may require the condition #range (g) &lt; . This condition holds if g is any subset of an set theoretical expression involving only 0, 1, and input parameters. Compile time analysis of inclusion and membership relations have been studied before by Schwartz <ref> [68, 67] </ref>. 6.3. Monotone and Antimonotone Although monotonicity is undecidable [32], in practice we can recognize a large subclass of computable monotone and antimonotone functions as described below: 1. Define basic computable monotone and antimonotone functions as are shown in table 6-1; 2.
Reference: 68. <author> Schwartz, J.T. </author> <title> "Automatic Data Structure Choice in a Language of Very High Level". </title> <type> CACM 18, </type> <month> 12 (Dec </month> <year> 1975), </year> <pages> 722-728. </pages>
Reference-contexts: Transformation 2 may require the condition #range (g) &lt; . This condition holds if g is any subset of an set theoretical expression involving only 0, 1, and input parameters. Compile time analysis of inclusion and membership relations have been studied before by Schwartz <ref> [68, 67] </ref>. 6.3. Monotone and Antimonotone Although monotonicity is undecidable [32], in practice we can recognize a large subclass of computable monotone and antimonotone functions as described below: 1. Define basic computable monotone and antimonotone functions as are shown in table 6-1; 2.
Reference: 69. <author> Scott, D. S. </author> <title> "Data Types as Lattices". </title> <journal> SIAM J. </journal> <volume> Comptng 5 (1976), </volume> <pages> 522-587. </pages>
Reference-contexts: Various fixed point theorems due to Tarski [75], Kleene [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics <ref> [69] </ref>, have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory [79, 39, 40, 33, 35, 59], and are used
Reference: 70. <author> Sharir, M. </author> <title> "Some Observations on Formal Differentiation". </title> <journal> ACM TOPLAS 4, </journal> <month> 2 (Apr. </month> <year> 1982), </year> <pages> 196-225. </pages>
Reference: 71. <author> Sintzoff, M. </author> <title> "Calculating Properties of Programs by Valuations on Specific Models". </title> <journal> ACM SIGPLAN Notices 7, </journal> <volume> 1 (1972), </volume> <pages> 203-207. </pages>
Reference-contexts: In order to incorporate these transformations as part of an effective mechanical program development system, we need to define stronger syntactically defined decidable properties that imply these undecidable semantic properties. Our approach, which is similar to Sintzoff's method of valuations <ref> [71] </ref>, is to specify properties using a formal system of pattern directed inductive definitions.
Reference: 72. <author> Suppes, P. </author> <title> Axiomatic Set Theory. </title> <publisher> Dover, </publisher> <year> 1972. </year>
Reference-contexts: In addition to conventional boolean and integer datatypes, SQ includes finite tuples, sets, and maps, which can be nested to arbitrary depth. With a few exceptions to be described, most of the notations in this language are borrowed from finite set theory <ref> [72] </ref> and conform to universally accepted mathematical notations. We make use of the overloaded size operator #s in the following way. If s is a set, then #s denotes the cardinality of s; if s is a tuple, it denotes the number of components of s. <p> Equational Form We have mentioned problem specifications that can sometimes be expressed more conveniently outside of + SQ in either of the two forms: (71) the s: 0 s | k (s) minimizing s or <ref> (72) </ref> the s: 1 s | k (s) maximizing s Before any of our fixed point transformations can be applied, we must first transform k (s) into an equivalent equational form s = f (s) in which f is monotone. <p> 2. the s: -x s | k (x)- = -- maximizing s fi GFP (s - -x s | k (x)-, s) 3. f (s) s fi s = s f (s) 5. negation elimination and De Morgan's rules Other useful rules for deriving normal form specifications for (71) and <ref> (72) </ref> include: 44 1. the s: s 0 | s = f (s) and s = g (s) minimizing s where h (x) = LFP (f) and h (x) = LFP (g). 21 , x , x 2. the s: s 0 | s = f (s) or s = g
Reference: 73. <author> Tarjan, R. E. </author> <title> "Depth first search and linear graph algorithms". </title> <journal> SIAM J. Computing 1, </journal> <volume> 2 (1972), </volume> <pages> 146-160. </pages>
Reference-contexts: It is well known <ref> [73] </ref> that the directed graph G = -[u, v] C C | (u v) and ($ [m, n] e | m u and n v)- is acyclic. For all vertices v domain e range e, let component (v) be the strongly-connected component that contains v. <p> For all vertices v domain e range e, let component (v) be the strongly-connected component that contains v. Then the set C and map component can be computed in O (#e) time <ref> [73] </ref> (see also [3]). Hence, we can conclude, + Lemma 13: For directed graphs in general, r can be maintained in O (1 + #e ) steps when w changes by an element addition and in O (1 + #e ) steps when w changes by an element deletion (c.f.
Reference: 74. <author> Tarjan, R. </author> <title> Iterative Algorithms for Global Flow Analysis. In Algorithms and Complexity - New Directions and Recent Results, </title> <editor> J. Traub, Ed., </editor> <publisher> Academic Press, </publisher> <year> 1976, </year> <pages> pp. 71-101. </pages>
Reference-contexts: Various fixed point theorems due to Tarski [75], Kleene [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others <ref> [36, 42, 16, 67, 43, 74] </ref> to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory [79, 39, 40, 33, 35, 59], and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54,
Reference: 75. <author> Tarski, A. </author> <title> "A Lattice-Theoretical Fixpoint Theorem and its Application". </title> <journal> Pacific Journal of Mathematics 5 (1955), </journal> <pages> 285-309. </pages>
Reference-contexts: We investigate a class of such algorithms that are all instances of a general nondeterministic iterative algorithm schema for computing least or greatest fixed points of computable functions. Various fixed point theorems due to Tarski <ref> [75] </ref>, Kleene [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program <p> Explicit transformations for greatest fixed points can be found in [9]. 3.1. Basic Theory All of our fixed point transformations are derived from the following theorem and corollary, which can be derived from Tarski's more general Theorem <ref> [75] </ref> or its constructive reformulation due to Cousot and Cousot [18]: Theorem 1: (Paige and Henglein [56]) Let (T,) be a poset with a unique minimum element i designated 0. Let f: T fi T be a monotone computable function.
Reference: 76. <author> Teitelbaum, T. and Reps, T. </author> <title> "The Cornell Program Synthesizer: a syntax-directed programming environment". </title> <type> CACM 24, </type> <month> 9 (Sep </month> <year> 1981), </year> <pages> pp. 563-573. </pages>
Reference-contexts: We also show how to compute fixed points of functions g (u, w) and, hence, nested fixed points. In general, the need for recomputing problems arises naturally in several contexts. For example, the Cornell Synthesizer <ref> [76] </ref> is a syntactic editing system that uses an attribute grammar to implement program semantics. Whenever a program is modified using the synthesizer, the program's semantic information must be updated to reflect the editing changes.
Reference: 77. <author> Tenenbaum, A. </author> <title> Type Determination for Very High Level Languages. </title> <type> Ph.D. </type> <institution> Th., New York University, Dept. of Computer Science, </institution> <month> Oct </month> <year> 1974. </year> <note> appears in Courant Computer Science Report 3. </note>
Reference-contexts: Various fixed point theorems due to Tarski [75], Kleene [45], Cousot and Cousot [18], and others [8] have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum <ref> [77] </ref>, and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory [79, 39, 40, 33, 35, 59], and are used to support high level program transformations [2, 29, 7, 49, 62, 53, <p> We prove that a subset of SQ with operational semantics can express all partially recursive functions; A new nondeterministic algorithm schema for computing least and greatest fixed points of monotone functions is given. This schema generalizes the 'chaotic iteration' found in Kildall [44], Tenenbaum <ref> [77] </ref>, and Cousot and Cousot [17] (restricted to finite iteration), so that it can be adapted in a wider range of contexts to synthesize efficient algorithms and to provide succinct transformational correctness proofs. <p> Cocke and Schwartz [13] and Kildall [44] justified convergence of their algorithms using condition 1 of Theorem 3 and restricted function f to be distributive; i.e., for every x,y T, f (x y) = f (x) f (y). (Note that distributivity implies monotonicity, but monotonicity does not imply distributivity.) Tenenbaum <ref> [77] </ref> and Kam and Ullman [42, 41] later designed algorithms based on the more general condition 2 of Theorem 3 and the more general monotonicity property for function f. 3.2. <p> is defined, D (q, p)) = -- if q p, and -p q- otherwise; d (p, p q) = p q, Assuming that all of the posets (T , , 0 ), i = 1,...,k, are the same, we obtain the 'chaotic' iteration described by i i i 18 Tenenbaum <ref> [77] </ref> and Cousot and Cousot [17] (restricted to finite iteration) to compute least fixed points of systems of equations x = f (x ,...,x ), i=1,...,k; that is, i i 1 k p := w (while $i=1,...,k | f (p) &gt; p (i) ) i p (i) := f (p) i <p> Kildall [44] introduced a fairly general method for program analysis using iterative schema (27). Kildall's algorithm was later refined by Tenenbaum <ref> [77] </ref> and Kam and Ullman [42]. Cousot and Cousot used a strategy similar to this algorithm called 'chaotic' iteration for defining least fixed points as the limit of a sequence, and they applied it in new settings [16, 15].
Reference: 78. <author> Ullman, J.D. </author> <title> "Implementation of Logical Query Languages for Databases". </title> <journal> ACM TODS 10, </journal> <month> 3 (September </month> <year> 1985), </year> <pages> 289-321. </pages>
Reference-contexts: Their method works well when the query dependency graph forms a single cycle, but in more general situations the control structures of the generated programs would be very complicated. In 1986, Naughton [50] showed that under some conditions, this expansion can be done at compile time. In 1985, Ullman <ref> [78] </ref> presented a more general approach. Instead of finding a single solution, he suggested the use of different strategies (capture rules) for different queries. This idea is fully developed in the design of NAIL! [48].
Reference: 79. <author> Vardi, M. </author> <title> Complexity of Relational Query Languages. </title> <booktitle> Proc. 14th ACM Symp. on Theory of Computing, </booktitle> <month> May, </month> <year> 1982, </year> <pages> pp. 137-146. 49 </pages>
Reference-contexts: have been applied by Scott to program semantics [69], have been used by Cocke and Schwartz [13], Kildall [44], Tenenbaum [77], and others [36, 42, 16, 67, 43, 74] to specify and implement global program analysis problems, are important to program verification [16, 17, 20, 23], arise in complexity theory <ref> [79, 39, 40, 33, 35, 59] </ref>, and are used to support high level program transformations [2, 29, 7, 49, 62, 53, 56, 11, 54, 70, 60, 81, 51]. <p> operator, a first order language on finite structures cannot express transitive closure [2]; The language of Relational Calculus [14] over a totally ordered finite domain plus least fixed points of monotone operators precisely expresses all queries computable in polynomial time (in the size of the domain) on a Turing machine <ref> [39, 79] </ref>. 1 Part of this work was done while Paige was a summer faculty at IBM Yorktown and while both authors were at Rutgers University. This work is also partly based upon research supported by the Office of Naval Research under Contract No. <p> Their paper triggered an extensive study into the expressive power of languages with fixed point constructs. In the theoretical direction logicians have made rapid progress. In 1982 Immerman [39] and Vardi <ref> [79] </ref> proved that, in the presence of a linear order (), every relational query computable by a Turing Machine in polynomial time with respect to the size of its input is expressible in first order logic (FO) extended with a least fixed point operator (LFP).
Reference: 80. <author> Wegman, M. N. and Zadeck, F. K. </author> <title> Constant Propagation with Conditional Branches. </title> <booktitle> Proc. 12th ACM Symp. on Principles of Programming Languages, </booktitle> <month> Jan, </month> <year> 1985, </year> <pages> pp. 291-299. </pages>
Reference-contexts: The next example illustrates this idea. Example 15: In the constant propagation algorithm given by Reif and Lewis <ref> [61, 80] </ref>, each assignment statement A is associated with either bottom (means undefined), top (means non-constant), or a real number that can result from the execution of A. Let R denote the set of real numbers.
Reference: 81. <author> Whang, K., and Navathe, S. B. </author> <title> An Extended Disjunctive Normal Form Approach for Processing Recursive Logic Queries in Loosely Coupled Environments. </title> <booktitle> Proc. 13th Intl. Conf. on Very Large Data Bases, </booktitle> <month> Sept., </month> <year> 1987, </year> <pages> pp. 275-287. </pages>
Reference-contexts: These subsystems are solved one by one in a topologic order. This strategy further reduces the number of worksets. In 1987, Kyu-Young Whang <ref> [81] </ref> introduced a rudimentary form of fixed point iteration together with finite differencing to evaluate recursive logic queries efficiently. He noticed that when this technique is applied to linear recursive queries, a one pass algorithm can be obtained.
References-found: 80

