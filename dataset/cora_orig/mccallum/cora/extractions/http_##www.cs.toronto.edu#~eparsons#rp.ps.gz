URL: http://www.cs.toronto.edu/~eparsons/rp.ps.gz
Refering-URL: http://www.cs.toronto.edu/~eparsons/
Root-URL: http://www.cs.toronto.edu
Title: Research Proposal Coordinated Allocation of Resources in Multiprocessors  
Author: Eric W. Parsons 
Note: Contents  
Date: January 19, 1995  
Abstract-found: 0
Intro-found: 1
Reference: [BHMW94] <author> Douglas C. Burger, Rahmat S. Hyder, Barton P. Miller, and David A. Wood. </author> <title> Paging tradeoffs in distributed-shared-memory multiprocessors. </title> <booktitle> In Proceedings Supercomputing '94, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: Another study into the effects of paging in parallel applications shows that scientific applications perform very poorly when the amount of memory is constrained <ref> [BHMW94] </ref>. For instance, the mp3d application from the Splash benchmark experiences a slowdown factor of over 32 when memory is constrained to 90% of the application's actual memory requirements.
Reference: [BSF + 91] <author> William J. Bolosky, Michael L. Scott, Robert P. Fitzgerald, Robert J. Fowler, and Alan L. Cox. </author> <title> NUMA policies and their relation to memory architecture. </title> <booktitle> In Proceedings of the 4th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), </booktitle> <pages> pages 212-221, </pages> <year> 1991. </year>
Reference-contexts: Still an open question is whether a single memory management policy can satisfy the needs of all parallel applications. Depending on the memory access pattern of the application, some memory regions may best be replicated, while others are fixed to a single processor according to some predetermined layout <ref> [LE91, BSF + 91] </ref>. While it would be ideal if the operating system could apply the appropriate policy automatically, the technology has not yet reached this level of sophistication.
Reference: [CMV94] <author> Su-Hui Chiang, Rajesh K. Mansharamani, and Mary K. Vernon. </author> <title> Use of application characteristics and limited preemption for run-to-completion parallel processor scheduling policies. </title> <booktitle> In Proceedings of the 1994 ACM SIGMETRICS Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 33-44, </pages> <year> 1994. </year>
Reference: [Dow88] <author> L. W. Dowdy. </author> <title> On the partitioning of multiprocessor systems. </title> <type> Technical Report 88-06, </type> <institution> Dept. of Computer Science, Vanderbuilt University, </institution> <year> 1988. </year>
Reference: [EZL89] <author> Derek L. Eager, John Zahorjan, and Edward D. Lazowska. </author> <title> Speedup versus efficiency in parallel systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(3) </volume> <pages> 408-423, </pages> <month> March </month> <year> 1989. </year>
Reference: [FR92] <author> D. G. Feitelson and L. Rudolph. </author> <title> Gang scheduling performance benefits for fine-grain synchronization. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 16 </volume> <pages> 306-318, </pages> <year> 1992. </year>
Reference-contexts: Since Majumdar's early work on the scheduling of independent threads [MEB88], research in the area has investigated the relationship between processor allocation and efficiency [Dow88, EZL89, Sev89, LV90, GST91, NSS93, PS94, RSD + 94, Sev94, CMV94], the effects of thread multiplexing on the execution time of applications <ref> [VZ91, GTU91, FR92, ML92, TTG93, SL93] </ref>, and the benefits of reconfiguring the parallelism of jobs [TG89, ZM90, GTS91, MVZ93, MZ94a], among other things. A survey of this work was recently written as part of the author's qualifying examination. <p> For fine-grained synchronization, it is generally accepted that all threads of the computation must be scheduled simultaneously (gang scheduling) <ref> [Ous82, FR92] </ref>. 3 2. Because jobs typically have sublinear speedup, it is advantageous to reduce the average pro-cessor allocation given to jobs as the load on the system increases. This results in increased overall processor efficiency, which leads to increased throughput and reduced mean response time. 3.
Reference: [GST91] <author> Dipak Ghosal, Guiseppe Serazzi, and Satish K. Tripathi. </author> <title> The processor working set and its use in scheduling multiprocess systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(5) </volume> <pages> 443-453, </pages> <month> May </month> <year> 1991. </year>
Reference: [GTS91] <author> Anoop Gupta, Andrew Tucker, and Luis Stevens. </author> <title> Making effective use of shared-memory multiprocessors: The process control approach. </title> <type> Technical Report CSL-TR-91-475A, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <month> July </month> <year> 1991. </year> <month> 11 </month>
Reference-contexts: in the area has investigated the relationship between processor allocation and efficiency [Dow88, EZL89, Sev89, LV90, GST91, NSS93, PS94, RSD + 94, Sev94, CMV94], the effects of thread multiplexing on the execution time of applications [VZ91, GTU91, FR92, ML92, TTG93, SL93], and the benefits of reconfiguring the parallelism of jobs <ref> [TG89, ZM90, GTS91, MVZ93, MZ94a] </ref>, among other things. A survey of this work was recently written as part of the author's qualifying examination. What is remarkable about this research, however, is the lack of attention given to resources other than processors. <p> As long as there is only a single parallel application in the system, the SGI Challenge performs well, but it has not managed to serve the combined needs of interactive applications with those of compute-intensive applications <ref> [GTS91] </ref>. In the KSR1, a different approach has been taken. A user can reserve a block of processors exclusively for his computational needs; other users are prevented from using those processors until they are released. This approach has many problems.
Reference: [GTU91] <author> Anoop Gupta, Andrew Tucker, and Shigeru Urushibara. </author> <title> The impact of operating sys-tem scheduling policies and synchronization methods on the performance of parallel applications. </title> <booktitle> In Proceedings of the 1991 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 120-132, </pages> <year> 1991. </year>
Reference-contexts: Since Majumdar's early work on the scheduling of independent threads [MEB88], research in the area has investigated the relationship between processor allocation and efficiency [Dow88, EZL89, Sev89, LV90, GST91, NSS93, PS94, RSD + 94, Sev94, CMV94], the effects of thread multiplexing on the execution time of applications <ref> [VZ91, GTU91, FR92, ML92, TTG93, SL93] </ref>, and the benefits of reconfiguring the parallelism of jobs [TG89, ZM90, GTS91, MVZ93, MZ94a], among other things. A survey of this work was recently written as part of the author's qualifying examination. <p> The first allows threads to be locked onto particular processors; the thread is then scheduled according to the normal Unix priority scheme so that what one gets is essentially independent thread scheduling. It is well known that for applications that synchronize even moderately, this will result in high overheads <ref> [GTU91] </ref>. The other mechanism is a gang-type of scheduler in which all threads of an application are scheduled simultaneously.
Reference: [KS93] <author> William J. Kaufmann III and Larry L. </author> <title> Smarr. </title> <booktitle> Supercomputing and the Transformation of Science. </booktitle> <publisher> Scientific American Library, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Parallel scientific applications often place extreme demands on certain parts of the system, be it computation, memory, or I/O. It has been shown that the demand for memory in the modeling of physical systems is essentially boundless <ref> [KS93] </ref>, and thus users will use whatever amount of memory they have available. These same users are also apt to use the I/O system with the assumption that they are the only users accessing a disk.
Reference: [LE91] <author> Richard P. LaRowe, Jr. and Carla Schlatter Ellis. </author> <title> Page placement policies for NUMA multiprocessors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 11 </volume> <pages> 112-129, </pages> <year> 1991. </year>
Reference-contexts: Still an open question is whether a single memory management policy can satisfy the needs of all parallel applications. Depending on the memory access pattern of the application, some memory regions may best be replicated, while others are fixed to a single processor according to some predetermined layout <ref> [LE91, BSF + 91] </ref>. While it would be ideal if the operating system could apply the appropriate policy automatically, the technology has not yet reached this level of sophistication.
Reference: [LV90] <author> Scott T. Leutenegger and Mary K. Vernon. </author> <title> The performance of multiprogrammed multiprocessor scheduling policies. </title> <booktitle> In Proceedings of the 1990 ACM SIGMETRICS Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 226-236, </pages> <year> 1990. </year>
Reference: [MEB88] <author> S. Majumdar, D. L. Eager, and R. B. Bunt. </author> <title> Scheduling in multiprogrammed parallel systems. </title> <booktitle> In Proceedings of the 1988 ACM SIGMETRICS Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 104-113, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Multiprocessor scheduling for multiprogrammed environments has received a tremendous amount of attention over the past eight years. Since Majumdar's early work on the scheduling of independent threads <ref> [MEB88] </ref>, research in the area has investigated the relationship between processor allocation and efficiency [Dow88, EZL89, Sev89, LV90, GST91, NSS93, PS94, RSD + 94, Sev94, CMV94], the effects of thread multiplexing on the execution time of applications [VZ91, GTU91, FR92, ML92, TTG93, SL93], and the benefits of reconfiguring the parallelism of
Reference: [ML92] <author> Evangelos P. Markatos and Thomas J. LeBlanc. </author> <title> Using processor affinity in loop scheduling on shared-memory multiprocessors. </title> <booktitle> In Proceedings Supercomputing '92, </booktitle> <pages> pages 104-113, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Since Majumdar's early work on the scheduling of independent threads [MEB88], research in the area has investigated the relationship between processor allocation and efficiency [Dow88, EZL89, Sev89, LV90, GST91, NSS93, PS94, RSD + 94, Sev94, CMV94], the effects of thread multiplexing on the execution time of applications <ref> [VZ91, GTU91, FR92, ML92, TTG93, SL93] </ref>, and the benefits of reconfiguring the parallelism of jobs [TG89, ZM90, GTS91, MVZ93, MZ94a], among other things. A survey of this work was recently written as part of the author's qualifying examination. <p> It is necessary to coordinate the scheduling of threads of an application. For coarse-grained synchronization, it is sufficient to ensure that threads holding locks are not preempted and that the cache context of processors is taken into account when scheduling threads (cache-affinity scheduling) <ref> [VZ91, SL93, TTG93, ML92] </ref>. For fine-grained synchronization, it is generally accepted that all threads of the computation must be scheduled simultaneously (gang scheduling) [Ous82, FR92]. 3 2.
Reference: [MVZ93] <author> Cathy McCann, Raj Vaswani, and John Zahorjan. </author> <title> A dynamic processor allocation policy for multiprogrammed shared-memory multiprocessors. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(2) </volume> <pages> 146-178, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: in the area has investigated the relationship between processor allocation and efficiency [Dow88, EZL89, Sev89, LV90, GST91, NSS93, PS94, RSD + 94, Sev94, CMV94], the effects of thread multiplexing on the execution time of applications [VZ91, GTU91, FR92, ML92, TTG93, SL93], and the benefits of reconfiguring the parallelism of jobs <ref> [TG89, ZM90, GTS91, MVZ93, MZ94a] </ref>, among other things. A survey of this work was recently written as part of the author's qualifying examination. What is remarkable about this research, however, is the lack of attention given to resources other than processors. <p> In the context of the basic results listed above, the disciplines which are known to perform well in each class are Adaptive Static Partitioning (ASP) [ST93], the quantum-based variant FB-ASP [PS94], and Equipartitioning (EQUI) <ref> [MVZ93] </ref>, respectively. The impact of not choosing an appropriate scheduling policy can be quite remarkable. This can be shown by considering a baseline policy in which jobs are scheduled in FCFS order and, for the duration of their execution, retain exclusive control over all processors.
Reference: [MZ94a] <author> Cathy McCann and John Zahorjan. </author> <title> Processor allocation strategies for message-passing parallel computers. </title> <booktitle> In Proceedings of the 1994 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 19-32, </pages> <year> 1994. </year>
Reference-contexts: in the area has investigated the relationship between processor allocation and efficiency [Dow88, EZL89, Sev89, LV90, GST91, NSS93, PS94, RSD + 94, Sev94, CMV94], the effects of thread multiplexing on the execution time of applications [VZ91, GTU91, FR92, ML92, TTG93, SL93], and the benefits of reconfiguring the parallelism of jobs <ref> [TG89, ZM90, GTS91, MVZ93, MZ94a] </ref>, among other things. A survey of this work was recently written as part of the author's qualifying examination. What is remarkable about this research, however, is the lack of attention given to resources other than processors.
Reference: [MZ94b] <author> Cathy McCann and John Zahorjan. </author> <title> Scheduling memory constrained jobs on distributed memory parallel computers. </title> <type> Technical Report 94-10-05, </type> <institution> University of Washington, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: In another study, a minimum bound on the number of processors (presumably due to memory requirements) is used in the scheduling decision, but this particular work has several weaknesses <ref> [MZ94b] </ref>. In particular, it assumes that processing time must be allocated perfectly evenly amongst a set of highest priority jobs in each quantum and it ignores the fact that jobs have a maximum parallelism.
Reference: [NSS93] <author> Vijay K. Naik, Sanjeev K. Setia, and Mark S. Squillante. </author> <title> Performance analysis of job scheduling policies in parallel supercomputing environments. </title> <booktitle> In Supercomputing '93, </booktitle> <pages> pages 824-833, </pages> <year> 1993. </year>
Reference: [Ous82] <author> John K. Ousterhout. </author> <title> Scheduling techniques for concurrent systems. </title> <booktitle> In Proceedings of the 3rd International Conference on Distributed Computing (ICDCS), </booktitle> <pages> pages 22-30, </pages> <month> October </month> <year> 1982. </year>
Reference-contexts: For fine-grained synchronization, it is generally accepted that all threads of the computation must be scheduled simultaneously (gang scheduling) <ref> [Ous82, FR92] </ref>. 3 2. Because jobs typically have sublinear speedup, it is advantageous to reduce the average pro-cessor allocation given to jobs as the load on the system increases. This results in increased overall processor efficiency, which leads to increased throughput and reduced mean response time. 3.
Reference: [PS94] <author> Eric W. Parsons and Kenneth C. Sevcik. </author> <title> Effects of high service-time variability in multiprocessor scheduling. </title> <note> Submitted for publication, </note> <month> October </month> <year> 1994. </year>
Reference-contexts: In the context of the basic results listed above, the disciplines which are known to perform well in each class are Adaptive Static Partitioning (ASP) [ST93], the quantum-based variant FB-ASP <ref> [PS94] </ref>, and Equipartitioning (EQUI) [MVZ93], respectively. The impact of not choosing an appropriate scheduling policy can be quite remarkable. This can be shown by considering a baseline policy in which jobs are scheduled in FCFS order and, for the duration of their execution, retain exclusive control over all processors. <p> Figure 1 shows the performance of the three disciplines just given in comparison to the baseline policy (MAX) as a function of the offered system load. The experiment that produced this graph is very similar to what has been used in previous work <ref> [PS94] </ref> 1 . As can be seen, the baseline discipline performs very poorly, shooting off the graph at very low load. One can also observe the gains obtained from moving from a run-to-completion discipline to a quantum-based discipline to an "ideal" equipartition discipline. <p> Simulations The simulations will be conducted as in the author's previous research on processor scheduling <ref> [PS94] </ref>, using synthetic workloads that are based on the application models. The baseline heuristic will be, in the static case, quantum-based adaptive static partitioning (FB-ASP), and in the dynamic case, equipartitioning (EQUI).
Reference: [PSN94] <author> Vinod G. J. Peris, Mark S. Squillante, and Vijay K. Naik. </author> <title> Analysis of the impact of memory in distributed parallel processing systems. </title> <booktitle> In Proceedings of the 1994 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 5-18, </pages> <year> 1994. </year>
Reference-contexts: But the vast majority of parallel scheduling research has ignored memory requirements. Only recently has the memory access patterns of parallel applications been modeled and used to determine a lower bound on the number of processors that should be allocated to a job <ref> [PSN94] </ref>. In another study, a minimum bound on the number of processors (presumably due to memory requirements) is used in the scheduling decision, but this particular work has several weaknesses [MZ94b].
Reference: [Rei94] <author> Karen Reid. </author> <title> I/O in parallel systems. </title> <type> Depth Report, </type> <institution> University of Toronto, </institution> <year> 1994. </year> <month> 12 </month>
Reference-contexts: Similarly, it will become necessary to provide a framework for studying various I/O mechanisms that may be used to maximize the effective I/O bandwidth to an application <ref> [Rei94] </ref>. As such, the author's research goals are to investigate the importance of using memory and I/O resource requirements in the scheduling decision, primarily in minimizing the mean response time.
Reference: [RSD + 94] <author> E. Rosti, E. Smirni, L. W. Dowdy, G. Serazzi, and B. M. Carlson. </author> <title> Robust partitioning policies of multiprocessor systems. Performance Evaluation, </title> <booktitle> 19 </booktitle> <pages> 141-165, </pages> <year> 1994. </year>
Reference: [Sev89] <author> Kenneth C. Sevcik. </author> <title> Characterizations of parallelism in applications and their use in scheduling. </title> <booktitle> In Proceedings of the 1988 ACM SIGMETRICS International Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 171-180, </pages> <month> May </month> <year> 1989. </year>
Reference: [Sev94] <author> K. C. Sevcik. </author> <title> Application scheduling and processor allocation in multiprogrammed parallel processing systems. Performance Evaluation, </title> <booktitle> 19 </booktitle> <pages> 107-140, </pages> <year> 1994. </year>
Reference: [SL93] <author> Mark S. Squillante and Edward D. Lazowska. </author> <title> Using processor-cache affinity information in shared-memory multiprocessor scheduling. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(2) </volume> <pages> 131-143, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Since Majumdar's early work on the scheduling of independent threads [MEB88], research in the area has investigated the relationship between processor allocation and efficiency [Dow88, EZL89, Sev89, LV90, GST91, NSS93, PS94, RSD + 94, Sev94, CMV94], the effects of thread multiplexing on the execution time of applications <ref> [VZ91, GTU91, FR92, ML92, TTG93, SL93] </ref>, and the benefits of reconfiguring the parallelism of jobs [TG89, ZM90, GTS91, MVZ93, MZ94a], among other things. A survey of this work was recently written as part of the author's qualifying examination. <p> It is necessary to coordinate the scheduling of threads of an application. For coarse-grained synchronization, it is sufficient to ensure that threads holding locks are not preempted and that the cache context of processors is taken into account when scheduling threads (cache-affinity scheduling) <ref> [VZ91, SL93, TTG93, ML92] </ref>. For fine-grained synchronization, it is generally accepted that all threads of the computation must be scheduled simultaneously (gang scheduling) [Ous82, FR92]. 3 2.
Reference: [ST93] <author> Sanjeev Setia and Satish Tripathi. </author> <title> A comparative analysis of static processor partitioning policies for parallel computers. </title> <booktitle> In Proceedings of the International Workshop on Modeling and Simulation of Computer and Telecommunication Systems (MASCOTS), </booktitle> <pages> pages 283-286, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: In the second, the internal parallelism of a job is changed in response to changes in the processor allocation (space sharing). In the context of the basic results listed above, the disciplines which are known to perform well in each class are Adaptive Static Partitioning (ASP) <ref> [ST93] </ref>, the quantum-based variant FB-ASP [PS94], and Equipartitioning (EQUI) [MVZ93], respectively. The impact of not choosing an appropriate scheduling policy can be quite remarkable.
Reference: [TG89] <author> Andrew Tucker and Anoop Gupta. </author> <title> Process control and scheduling issues for multipro-grammed shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 159-166, </pages> <year> 1989. </year>
Reference-contexts: in the area has investigated the relationship between processor allocation and efficiency [Dow88, EZL89, Sev89, LV90, GST91, NSS93, PS94, RSD + 94, Sev94, CMV94], the effects of thread multiplexing on the execution time of applications [VZ91, GTU91, FR92, ML92, TTG93, SL93], and the benefits of reconfiguring the parallelism of jobs <ref> [TG89, ZM90, GTS91, MVZ93, MZ94a] </ref>, among other things. A survey of this work was recently written as part of the author's qualifying examination. What is remarkable about this research, however, is the lack of attention given to resources other than processors.
Reference: [TSWY94] <author> John Turek, Uwe Schwiegelshohn, Joel L. Wolf, and Philip S. Yu. </author> <title> Scheduling parallel tasks to minimize average response time. </title> <booktitle> In Proceedings of the Fifth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), </booktitle> <pages> pages 112-121, </pages> <year> 1994. </year>
Reference-contexts: Ideally, the research will contain a theoretical component, possibly consisting of extensions on recently published work on minimizing mean response time <ref> [TSWY94] </ref>. It is unlikely that coordinated resource allocation will be studied in this context as this would require too much detail. In line with the author's recent work on processor scheduling, the thesis will also contain a simulation component, with the principal focus being multiple resources. <p> The solution to this problem is known to be NP-complete <ref> [TSWY94] </ref>. In fact, there has been very little theoretical work done on algorithms for minimizing the mean response time; the only work that exists assumes that jobs have fixed parallelism and that all jobs are all initially available [TSWY94]. <p> The solution to this problem is known to be NP-complete <ref> [TSWY94] </ref>. In fact, there has been very little theoretical work done on algorithms for minimizing the mean response time; the only work that exists assumes that jobs have fixed parallelism and that all jobs are all initially available [TSWY94]. The research would extend these results along the lines just described, first by considering "malleability", then by considering memory and disk requirements.
Reference: [TTG93] <author> Josep Torrellas, Andrew Tucker, and Anoop Gupta. </author> <title> Benefits of cache-affinity scheduling in shared-memory multiprocessors: A summary. </title> <booktitle> In Proceedings of the 1993 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 272-274, </pages> <year> 1993. </year>
Reference-contexts: Since Majumdar's early work on the scheduling of independent threads [MEB88], research in the area has investigated the relationship between processor allocation and efficiency [Dow88, EZL89, Sev89, LV90, GST91, NSS93, PS94, RSD + 94, Sev94, CMV94], the effects of thread multiplexing on the execution time of applications <ref> [VZ91, GTU91, FR92, ML92, TTG93, SL93] </ref>, and the benefits of reconfiguring the parallelism of jobs [TG89, ZM90, GTS91, MVZ93, MZ94a], among other things. A survey of this work was recently written as part of the author's qualifying examination. <p> It is necessary to coordinate the scheduling of threads of an application. For coarse-grained synchronization, it is sufficient to ensure that threads holding locks are not preempted and that the cache context of processors is taken into account when scheduling threads (cache-affinity scheduling) <ref> [VZ91, SL93, TTG93, ML92] </ref>. For fine-grained synchronization, it is generally accepted that all threads of the computation must be scheduled simultaneously (gang scheduling) [Ous82, FR92]. 3 2.
Reference: [VZ91] <author> Raj Vaswani and John Zahorjan. </author> <title> The implications of cache affinity on processor scheduling for multiprogrammed, shared memory multiprocessors. </title> <booktitle> In Proceedings of the Thirteenth Symposium on Operating System Principles (SOSP), </booktitle> <pages> pages 26-40, </pages> <year> 1991. </year>
Reference-contexts: Since Majumdar's early work on the scheduling of independent threads [MEB88], research in the area has investigated the relationship between processor allocation and efficiency [Dow88, EZL89, Sev89, LV90, GST91, NSS93, PS94, RSD + 94, Sev94, CMV94], the effects of thread multiplexing on the execution time of applications <ref> [VZ91, GTU91, FR92, ML92, TTG93, SL93] </ref>, and the benefits of reconfiguring the parallelism of jobs [TG89, ZM90, GTS91, MVZ93, MZ94a], among other things. A survey of this work was recently written as part of the author's qualifying examination. <p> It is necessary to coordinate the scheduling of threads of an application. For coarse-grained synchronization, it is sufficient to ensure that threads holding locks are not preempted and that the cache context of processors is taken into account when scheduling threads (cache-affinity scheduling) <ref> [VZ91, SL93, TTG93, ML92] </ref>. For fine-grained synchronization, it is generally accepted that all threads of the computation must be scheduled simultaneously (gang scheduling) [Ous82, FR92]. 3 2.
Reference: [ZM90] <author> John Zahorjan and Cathy McCann. </author> <title> Processor scheduling in shared memory multiprocessors. </title> <booktitle> In Proceedings of the 1990 ACM SIGMETRICS Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 214-225, </pages> <year> 1990. </year> <month> 13 </month>
Reference-contexts: in the area has investigated the relationship between processor allocation and efficiency [Dow88, EZL89, Sev89, LV90, GST91, NSS93, PS94, RSD + 94, Sev94, CMV94], the effects of thread multiplexing on the execution time of applications [VZ91, GTU91, FR92, ML92, TTG93, SL93], and the benefits of reconfiguring the parallelism of jobs <ref> [TG89, ZM90, GTS91, MVZ93, MZ94a] </ref>, among other things. A survey of this work was recently written as part of the author's qualifying examination. What is remarkable about this research, however, is the lack of attention given to resources other than processors.
References-found: 32

