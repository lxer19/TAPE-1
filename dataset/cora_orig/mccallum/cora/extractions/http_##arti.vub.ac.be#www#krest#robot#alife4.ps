URL: http://arti.vub.ac.be/www/krest/robot/alife4.ps
Refering-URL: http://www.cs.brandeis.edu/~zippy/alife-library.html
Root-URL: 
Email: E-mail: steels@arti.vub.ac.be  
Title: Emergent functionality in robotic agents through on-line evolution.  
Author: Luc Steels 
Address: Pleinlaan 2, B-1050 Brussels, Belgium  
Affiliation: Artificial Intelligence Laboratory Vrije Universiteit Brussel  
Abstract: The paper proposes an architecture for the online evolution of new behavioral competences on a robotic agent. Some experimental results for evolving a set of primitive behaviors are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [Brooks1991] <author> Brooks, R. </author> <title> (1991b) Challenges for Complete Creature Architectures. </title> <editor> In: Meyer, J-A., and S.W. </editor> <booktitle> Wilson (1991) From Animals to An-imats. Proceedings of the First International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books. </publisher> <address> Cambridge Ma. p. </address> <pages> 434-443. </pages>
Reference-contexts: There has already been a large amount of work attempting to use selectionist techniques for evolving behavioral competences. Holland for example has developed classifier systems and used genetic algorithms to evolve them [Holland1975]. Koza has shown how the reactive finite state machines proposed by Brooks <ref> [Brooks1991] </ref> can be evolved using genetic programming techniques [Koza1991]. The Sussex group [Cliffs,et.al.1993] has proposed an experimental environment for using genetic techniques based on real sensory data. <p> This implies that we must evolve dynamical systems instead of symbolic computation rules. * Cooperation vs Subsumption. Many architectures for robotic agents, such as the subsumption architecture <ref> [Brooks1991] </ref>, allow different behavioral modules to inhibit one another. We want instead to create a `level playing field' in which one behavioral module cannot inhibit another one. Different modules must cooperate or compete with each other in order to achieve a coherent behavior. <p> Most of the genetic experiments so far have been performed in a simulation setting. Instead, we want to work on real robots in view of the large discrepancies between simulations and artificial systems and the complexity of building realistic simulators <ref> [Brooks1991] </ref>. Moreover we want the agent to remain viable as a task-achieving agent instead of running the genetic algorithm off-line and then transplanting a solution for testing on the robot, as in [Cliffs,et.al.1993].
Reference: [Cliffs,et.al.1993] <author> Cliff, D., P. Husbands, and I. </author> <title> Har-vey (1993) Evolving Visually Guided Robots. </title> <editor> In: Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wil-son (1993) From Animals to Animats2. Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 374-383. </pages>
Reference-contexts: Holland for example has developed classifier systems and used genetic algorithms to evolve them [Holland1975]. Koza has shown how the reactive finite state machines proposed by Brooks [Brooks1991] can be evolved using genetic programming techniques [Koza1991]. The Sussex group <ref> [Cliffs,et.al.1993] </ref> has proposed an experimental environment for using genetic techniques based on real sensory data. Selectionist mechanisms have also been proposed by neurobiologists, notably Edelman, as an alternative explanation to the inductive or associative mechanisms dominating the literature on neural networks [Edelman1987]. <p> Moreover we want the agent to remain viable as a task-achieving agent instead of running the genetic algorithm off-line and then transplanting a solution for testing on the robot, as in <ref> [Cliffs,et.al.1993] </ref>.
Reference: [Deneubourg1993] <author> Deneubourg, J-L, et.al. </author> <title> (1993) Self-organisation and life: from simple rules to global complexity. </title> <booktitle> Proceedings of the Second European Conference on Artificial Life. </booktitle> <address> ULB, Brussels. </address>
Reference-contexts: Selectionism and self-organisation have so far been put forward as the key explanatory principles [Langton1989]. These principles have been been applied at many level of biological systems, from the chemical reactions that explain the origin of life [Kaufmann1993] to the interaction between individuals in societies <ref> [Deneubourg1993] </ref>. This paper explores in how far selectionism and self-organisation may lead to the build up of behavioral complexity in animals. In the tradition of Alife research, this exploration takes place by building artificial systems, i.c. robotic agents.
Reference: [Edelman1987] <author> Edelman, G. </author> <title> (1987) Neural Darwinism: The Theory of Neuronal Group Selection. </title> <publisher> Basic Books, </publisher> <address> New York. </address>
Reference-contexts: The Sussex group [Cliffs,et.al.1993] has proposed an experimental environment for using genetic techniques based on real sensory data. Selectionist mechanisms have also been proposed by neurobiologists, notably Edelman, as an alternative explanation to the inductive or associative mechanisms dominating the literature on neural networks <ref> [Edelman1987] </ref>. All this work is extremely valuable and has provided inspiration and techniques for the work reported here. Our own approach differs however in the following respects: * Subsymbolic vs symbolic. The classifier systems of Hol-land are in the tradition of symbolic AI.
Reference: [Holland1975] <author> Holland, J.H. </author> <booktitle> (1975) Adaptation in Natural and Artificial Systems. </booktitle> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, Michigan. </address>
Reference-contexts: In the tradition of Alife research, this exploration takes place by building artificial systems, i.c. robotic agents. There has already been a large amount of work attempting to use selectionist techniques for evolving behavioral competences. Holland for example has developed classifier systems and used genetic algorithms to evolve them <ref> [Holland1975] </ref>. Koza has shown how the reactive finite state machines proposed by Brooks [Brooks1991] can be evolved using genetic programming techniques [Koza1991]. The Sussex group [Cliffs,et.al.1993] has proposed an experimental environment for using genetic techniques based on real sensory data.
Reference: [Kaufmann1993] <author> Kauffman, S.A. </author> <title> (1993) The origins of order: self organization and selection in evolution. </title> <publisher> Oxford University Press, Oxford. </publisher>
Reference-contexts: Selectionism and self-organisation have so far been put forward as the key explanatory principles [Langton1989]. These principles have been been applied at many level of biological systems, from the chemical reactions that explain the origin of life <ref> [Kaufmann1993] </ref> to the interaction between individuals in societies [Deneubourg1993]. This paper explores in how far selectionism and self-organisation may lead to the build up of behavioral complexity in animals. In the tradition of Alife research, this exploration takes place by building artificial systems, i.c. robotic agents.
Reference: [Koza1991] <author> Koza, J. </author> <title> (1991) Evolving Emergent Wall Following Robotic Behavior sing the Genetic Programming Paradigm. </title> <editor> In: Varela, F.J. and P. Bourgine (eds.) </editor> <booktitle> (1992) Toward a Practice of Autonomous Systems. Proceedings of the First European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 110-119. </pages>
Reference-contexts: Holland for example has developed classifier systems and used genetic algorithms to evolve them [Holland1975]. Koza has shown how the reactive finite state machines proposed by Brooks [Brooks1991] can be evolved using genetic programming techniques <ref> [Koza1991] </ref>. The Sussex group [Cliffs,et.al.1993] has proposed an experimental environment for using genetic techniques based on real sensory data. Selectionist mechanisms have also been proposed by neurobiologists, notably Edelman, as an alternative explanation to the inductive or associative mechanisms dominating the literature on neural networks [Edelman1987]. <p> Evolving a behavior system means to derive a set of processes that are capable together to cause the condition to be satisfied. There are many variants of selectionist mechanisms, but they typically involve the following steps <ref> [Koza1991] </ref>: 1. An initial population is generated. 2. The elements of the population are assigned a fitness value. 3. The constellation of the population is changed using copy and mutate operations whose probability of occurrence is a function of the fitness of the elements engaged in the operations.
Reference: [Langton1989] <author> Langton, </author> <title> C.G. </title> <booktitle> (1989) Artificial Life. Santa Fe Institute Studies in the Sciences of Complexity. Proc. Vol VI. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading Ma. </address>
Reference-contexts: Introduction A central question in ALife research is how new complexity and new functionality may emerge [Steels1994]. Selectionism and self-organisation have so far been put forward as the key explanatory principles <ref> [Langton1989] </ref>. These principles have been been applied at many level of biological systems, from the chemical reactions that explain the origin of life [Kaufmann1993] to the interaction between individuals in societies [Deneubourg1993].
Reference: [McFarland1992] <author> McFarland, D. </author> <title> (1992) Animals as cost-based Robots. </title> <booktitle> International Studies in the Philosophy of Science, </booktitle> <volume> Vol 6, 2. </volume> <pages> p. 133-153. </pages>
Reference-contexts: We want instead to create a `level playing field' in which one behavioral module cannot inhibit another one. Different modules must cooperate or compete with each other in order to achieve a coherent behavior. Genuine conflicts are handled by motivational systems, as studied extensively in ethology <ref> [McFarland1992] </ref>. This 'level playing field' appears crucial to apply selectionism properly because otherwise some behavior systems get an unfair advan tage. * On-line vs off-line. Most of the genetic experiments so far have been performed in a simulation setting. <p> To regulate the interaction between different behavior systems motivations and behavioral tendencies have been introduced. Both terms are used in their ethologi-cal sense <ref> [McFarland1992] </ref>, although we introduce them to constrain the internal architecture of the robot not to explain empirically observed behavior as is usually done in ethology. A motivation is a quantity which reflects the cost of reaching a particular state. <p> The same strength in behavioral tendency will be observed with low motivation but high cue strength as with high motivation but low cue strength. This is often shown by drawing the isoclines of the behavioral tendencies. (Figure 3.) Motivations and behavioral tendencies are well established notions in ethology <ref> [McFarland1992] </ref> and have been suggested as applicable to robotics [McFarlandBoesser1994]. We incorporate them here as explicit internal quantities. There are processes which determine the level of motivations as well as the levels of behavioral tendencies.
Reference: [McFarlandBoesser1994] <author> McFarland, D. and T. </author> <booktitle> Boesser (1994) Intelligent Behavior in Animals and Robots. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. </address>
Reference-contexts: This is often shown by drawing the isoclines of the behavioral tendencies. (Figure 3.) Motivations and behavioral tendencies are well established notions in ethology [McFarland1992] and have been suggested as applicable to robotics <ref> [McFarlandBoesser1994] </ref>. We incorporate them here as explicit internal quantities. There are processes which determine the level of motivations as well as the levels of behavioral tendencies. The influence imposed by a behavior system is always a (multiplicative) function of the tendency associated with the behavior.
Reference: [Ray1992] <author> Ray, T. </author> <title> (1992) An Approach to the Synthesis of Life. </title> <editor> In: Langton, C.G., C. Taylor, J.D. Farmer, and S. </editor> <booktitle> Rasmussen (1992) Artificial Life II. Proceedings of the Workshop on Artificial Life Held February, </booktitle> <address> 1990 in Santa Fe, New Mex-ico. p. </address> <pages> 325-371. </pages>
Reference-contexts: This way we obtain a situation in which there is natural se-lection as opposed to artificial selection, much in the same way the computational constraints in the Tierra system <ref> [Ray1992] </ref> constitute a natural selection environment for evolving copying programs. This paper reports on progress towards the ambitious objectives stated above.
Reference: [Smithers1992] <author> Smithers, T. </author> <title> (1992) Taking Eliminative Materialism Seriously: A Methodology for Autonomous Systems Research. </title> <editor> In Varela, F.J. and P. Bourgine (eds.) </editor> <booktitle> (1992) Toward a Practice of Autonomous Systems. Proceedings of the First European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 31-40. </pages>
Reference-contexts: The third basic unit in the architecture is called a behavior system. A behavior is a regularity in the interaction dynamics between an agent and the environment (for example a certain distance is maintained from the wall) <ref> [Smithers1992] </ref>. A behavior system is the set of internal processes that are active when the regularity is observed. Each behavior system can be said to establish a particular condition.
Reference: [Steels1993] <author> Steels, L. </author> <title> (1993) Building Agents with Autonomous Behavior Systems. </title> <editor> In: Steels, L. and R. Brooks (eds.) </editor> <booktitle> (1993) The `artificial life' route to `artificial intelligence'. Building situated embodied agents. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <address> New Haven. </address>
Reference-contexts: At the same time, the choice of robot architecture is influenced by whether it supports selectionist mechanisms. We have adopted a cooperative dynamics architecture which is implemented with an associated language called PDL <ref> [Steels1993] </ref>. This architecture assumes that the sensors deliver a continuous (discretised) stream of data and that there is a continous (discretised) stream of parameters flowing to the effectors (e.g. the speed or acceleration of the motors).
Reference: [Steels1994] <editor> Steels, L. </editor> <booktitle> (1994) The Artificial Life roots of Artificial Intelligence. Journal of Artificial Life. </booktitle> <publisher> MIT Press. </publisher> <address> 1,1/2. p. </address> <pages> 89-125. </pages>
Reference-contexts: Introduction A central question in ALife research is how new complexity and new functionality may emerge <ref> [Steels1994] </ref>. Selectionism and self-organisation have so far been put forward as the key explanatory principles [Langton1989]. These principles have been been applied at many level of biological systems, from the chemical reactions that explain the origin of life [Kaufmann1993] to the interaction between individuals in societies [Deneubourg1993].
Reference: [Steels1994b] <author> Steels, L. </author> <title> (1994b) A case study in the behavior-oriented design of autonomous agents. </title> <booktitle> Proceedings of the Simulation of Adaptive Behavior Conference. </booktitle> <address> Brighton. Cambridge: </address> <publisher> MIT Press. </publisher>
References-found: 15

