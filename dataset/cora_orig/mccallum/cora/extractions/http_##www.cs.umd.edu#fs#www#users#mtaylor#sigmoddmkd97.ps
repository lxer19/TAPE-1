URL: http://www.cs.umd.edu/fs/www/users/mtaylor/sigmoddmkd97.ps
Refering-URL: http://www.cs.umd.edu/projects/plus/papers.html
Root-URL: 
Email: mtaylor@cs.umd.edu  stoffel@cs.umd.edu  hendler@cs.umd.edu  
Title: Ontology-based Induction of High Level Classification Rules  
Author: Merwyn G. Taylor Kilian Stoffel James A. Hendler 
Address: College Park, MD, 20742  College Park, MD, 20742  College Park, MD, 20742  
Affiliation: University of Maryland Computer Science Department  University of Maryland Computer Science Department  University of Maryland Computer Science Department  
Abstract: A tool that could be beneficial to the data mining community is one that facilitates the seamless integration of knowledge bases and databases. This kind of tool could form the foundation of a data mining system capable of finding interesting information using ontologies. In this paper, we describe a new algorithm based on the query facilities provided by such a tool, ParkaDB which is a knowledge representation system. Ontologies and relational databases are merged thus extending the range of queries that can be issued against databases. This extended query capability makes it possible to generalize from low-level concepts to high-level concepts on demand. Given this extended querying capability, we are developing a classification algorithm that will find classification rules at multiple levels of abstraction. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Rakesh Agrawal Tomasz Imielinski and Arun Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In 1993 International Conference on Management of Data (SIGMOD93), </booktitle> <pages> pages 207-216, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: To make it feasible to analyze databases, researchers have been developing tools for knowledge discovery in databases (KDD). These tools can be used to find various types of interesting information in databases. KDD tools have been developed to find association rules <ref> [1] </ref>, perform time sequence analysis [2], and find classification rules [3]. To supplement the discovery process, some systems use background knowledge [4, 9]. The background knowledge can be in the form of domain rules and concept-hierarchies (ontologies).
Reference: [2] <author> Ira J. Haimowitz. </author> <title> Knowledge-based Trend Detection and Diagnosis. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> June </month> <year> 1994. </year> <month> MIT/LCS/TR-620. </month>
Reference-contexts: To make it feasible to analyze databases, researchers have been developing tools for knowledge discovery in databases (KDD). These tools can be used to find various types of interesting information in databases. KDD tools have been developed to find association rules [1], perform time sequence analysis <ref> [2] </ref>, and find classification rules [3]. To supplement the discovery process, some systems use background knowledge [4, 9]. The background knowledge can be in the form of domain rules and concept-hierarchies (ontologies). The background knowledge is often used to guide the discovery process such that uninteresting information is avoided.
Reference: [3] <author> J. Ross Quinlan. </author> <title> Induction of decision trees. </title> <booktitle> In Readings in Machine Learning, </booktitle> <pages> pages 81-106. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: These tools can be used to find various types of interesting information in databases. KDD tools have been developed to find association rules [1], perform time sequence analysis [2], and find classification rules <ref> [3] </ref>. To supplement the discovery process, some systems use background knowledge [4, 9]. The background knowledge can be in the form of domain rules and concept-hierarchies (ontologies). The background knowledge is often used to guide the discovery process such that uninteresting information is avoided. <p> Dr. Hendler is also affiliated with the UM Institute for Systems Research (NSF Grant NSF EEC 94-02384). on features of the data. Many of them are based on decision tree technology introduced by Quinlan <ref> [3] </ref>, while others employ various techniques such as implication rule search. Classification problems exist in a variety of domains.
Reference: [4] <author> Yandong Cai, Nick Cercone, and Jiawei Han. </author> <title> Attribute-oriented induction in 6 relational databases. In Knowledge Discovery in Databases. </title> <publisher> AAAI/MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: These tools can be used to find various types of interesting information in databases. KDD tools have been developed to find association rules [1], perform time sequence analysis [2], and find classification rules [3]. To supplement the discovery process, some systems use background knowledge <ref> [4, 9] </ref>. The background knowledge can be in the form of domain rules and concept-hierarchies (ontologies). The background knowledge is often used to guide the discovery process such that uninteresting information is avoided. <p> Currently, most ontology management systems cannot support extremely large ontologies, making it difficult to create efficient knowledge-based systems. For this reason, KDD tools that use ontologies usually pre-generalize databases before applying the core data mining algorithm <ref> [4, 10, 12] </ref>. We have developed a tool, ParkaDB that is capable of managing large ontologies. ParkaDB [7, 8] has a very efficient structural design and it is based on high-performance computing technologies. <p> Soda is a generalization of Pepsi and Coke, while Dairy Beverage is a generalization of AB Milk and AB Egg Nog. The rules are the result of data mining at a higher level of abstraction. The designers of DBLearn <ref> [4] </ref> and KBRL [9] have explored data mining at higher levels of abstraction. In this paper we present a technique similar to those used in the aforementioned systems. <p> In this paper we present a technique similar to those used in the aforementioned systems. Our system is based on high-level abstraction using domain ontologies and an efficient, scalable ontology management tool, ParkaDB, which allows it to induce multi-level classification rules without pre-generalizing tables (see <ref> [10, 4, 12] </ref>). Data mining at high levels of abstraction has several advantages over data mining at low levels. First, high-level rules can provide a "clearer" synopsis of databases. In general, data mining systems generate summaries of databases in the form of low-level information. <p> This information has been used in many different ways. Here we will only consider systems that use taxonomic background knowledge. Walker [10] was the first to use concept taxonomies. The taxonomies were used to replace values by more general values. Han et al. <ref> [4] </ref> proposed a similar approach to find characterization and classification rules at high levels of generality. Later, Dhar and Tuzhilin [12] proposed a generalization of the techniques of Walker and Han.
Reference: [5] <author> UMLS. </author> <title> Unified Medical Language System. </title> <booktitle> National Library of Medicine, </booktitle> <year> 1994. </year>
Reference-contexts: Classification problems exist in a variety of domains. A classic classification problem is that of a lending institution in search of rules that can be used to predict the type of borrowers that are likely to default on a loan and those that are not. Ontologies such as UMLS <ref> [5] </ref>, and WordNet [6] have been created for use in knowledge-based systems. In KDD, ontologies provide a mechanism by which domain specific knowledge may be included to aide the discovery process. However, ontologies are only useful if they can be repeatedly queried efficiently and quickly.
Reference: [6] <author> George A. Miller. </author> <title> Human language technology. </title> <type> Technical report, </type> <institution> Psychology Department, Green Hall, Princeton University, </institution> <year> 1996. </year>
Reference-contexts: A classic classification problem is that of a lending institution in search of rules that can be used to predict the type of borrowers that are likely to default on a loan and those that are not. Ontologies such as UMLS [5], and WordNet <ref> [6] </ref> have been created for use in knowledge-based systems. In KDD, ontologies provide a mechanism by which domain specific knowledge may be included to aide the discovery process. However, ontologies are only useful if they can be repeatedly queried efficiently and quickly.
Reference: [7] <author> James Hendler, Kilian Stoffel, and Merwyn Taylor. </author> <title> Advances in high performance knowledge representation. </title> <type> Technical Report CS-TR-3672, </type> <institution> University of Maryland @ College Park, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: For this reason, KDD tools that use ontologies usually pre-generalize databases before applying the core data mining algorithm [4, 10, 12]. We have developed a tool, ParkaDB that is capable of managing large ontologies. ParkaDB <ref> [7, 8] </ref> has a very efficient structural design and it is based on high-performance computing technologies. Because of its ability to query large ontologies, both serially and in parallel, ParkaDB makes it feasible to merge large ontologies with large databases. <p> It supports the storage, loading, querying and updating of very large ontologies, both traditional, and hybrid. In this section we describe ParakaDB's query language. See <ref> [7, 8] </ref> for a discussion on ParkaDB in general. ParkaDB supports a conjunctive query language in which every conjunct is a triple (P; D; R). P can be one of several predefined structural relationships, "isa", "instanceOf", "subCat", etc. Alternatively, P can be an attribute defined on a database.
Reference: [8] <author> Kilian Stoffel, Merwyn Taylor, and James Hendler. </author> <title> Efficient management of very large ontologies. </title> <booktitle> In AAAI-97 Proceedings, </booktitle> <year> 1997. </year>
Reference-contexts: For this reason, KDD tools that use ontologies usually pre-generalize databases before applying the core data mining algorithm [4, 10, 12]. We have developed a tool, ParkaDB that is capable of managing large ontologies. ParkaDB <ref> [7, 8] </ref> has a very efficient structural design and it is based on high-performance computing technologies. Because of its ability to query large ontologies, both serially and in parallel, ParkaDB makes it feasible to merge large ontologies with large databases. <p> This second group may consist of a relatively small ontological part and a much larger example base, or as a dense combination of relations and instances. In this paper, we will assume that our data stores are in the form of hybrid ontologies. See <ref> [8] </ref> for a discussion on ontologies. Concept taxonomies are traditional ontologies in which every assertion represents a sub-class to supper-class, or vice-versa, relationship between concepts. Traditionally, concept taxonomies have been created using "isa" assertions. <p> It supports the storage, loading, querying and updating of very large ontologies, both traditional, and hybrid. In this section we describe ParakaDB's query language. See <ref> [7, 8] </ref> for a discussion on ParkaDB in general. ParkaDB supports a conjunctive query language in which every conjunct is a triple (P; D; R). P can be one of several predefined structural relationships, "isa", "instanceOf", "subCat", etc. Alternatively, P can be an attribute defined on a database.
Reference: [9] <author> John M. Aronis and Foster J. Provost. </author> <title> Efficiently constructing relational features from background knowledge for inductive machine learning. </title> <booktitle> In Proceedings: AAAI-94 Workshop on Knowledge Discovery in Databases, </booktitle> <month> March </month> <year> 1996. </year>
Reference-contexts: These tools can be used to find various types of interesting information in databases. KDD tools have been developed to find association rules [1], perform time sequence analysis [2], and find classification rules [3]. To supplement the discovery process, some systems use background knowledge <ref> [4, 9] </ref>. The background knowledge can be in the form of domain rules and concept-hierarchies (ontologies). The background knowledge is often used to guide the discovery process such that uninteresting information is avoided. <p> Soda is a generalization of Pepsi and Coke, while Dairy Beverage is a generalization of AB Milk and AB Egg Nog. The rules are the result of data mining at a higher level of abstraction. The designers of DBLearn [4] and KBRL <ref> [9] </ref> have explored data mining at higher levels of abstraction. In this paper we present a technique similar to those used in the aforementioned systems.
Reference: [10] <author> A. Walker. </author> <title> On retrieval from a small version of a large database. </title> <booktitle> VLDB Conference, </booktitle> <year> 1980. </year>
Reference-contexts: Currently, most ontology management systems cannot support extremely large ontologies, making it difficult to create efficient knowledge-based systems. For this reason, KDD tools that use ontologies usually pre-generalize databases before applying the core data mining algorithm <ref> [4, 10, 12] </ref>. We have developed a tool, ParkaDB that is capable of managing large ontologies. ParkaDB [7, 8] has a very efficient structural design and it is based on high-performance computing technologies. <p> In this paper we present a technique similar to those used in the aforementioned systems. Our system is based on high-level abstraction using domain ontologies and an efficient, scalable ontology management tool, ParkaDB, which allows it to induce multi-level classification rules without pre-generalizing tables (see <ref> [10, 4, 12] </ref>). Data mining at high levels of abstraction has several advantages over data mining at low levels. First, high-level rules can provide a "clearer" synopsis of databases. In general, data mining systems generate summaries of databases in the form of low-level information. <p> Background knowledge has been represented as rules, domain constraints, taxonomies, and more recently as full ontologies. This information has been used in many different ways. Here we will only consider systems that use taxonomic background knowledge. Walker <ref> [10] </ref> was the first to use concept taxonomies. The taxonomies were used to replace values by more general values. Han et al. [4] proposed a similar approach to find characterization and classification rules at high levels of generality.
Reference: [11] <author> Kilian Stoffel, James Hendler, and Merwyn Taylor. </author> <title> Induction of hierarchical dependencies from relational databases. </title> <type> Technical Report CS-TR-3757, </type> <institution> University of Maryland @ College Park, </institution> <month> January </month> <year> 1997. </year>
Reference-contexts: The frequency counts for an attribute-value pair (A,v) are reduced so that they indicate the number of tuples remaining in the database that contain the value "v", or any of its descendants, for 1 We developed an algorithm that will find these relationships <ref> [11] </ref> 2 Is generalizable to attribute "A" that are not covered by a rule previously generated. In Figure 7 the frequency counts for the "Beverage" taxonomy have been reduced based on the results of the extended query above.
Reference: [12] <author> Vasant Dhar and Alexander Tuzhilin. </author> <title> Abstract-driven pattern discovery in databases. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 5(6), </volume> <month> December </month> <year> 1993. </year>
Reference-contexts: Currently, most ontology management systems cannot support extremely large ontologies, making it difficult to create efficient knowledge-based systems. For this reason, KDD tools that use ontologies usually pre-generalize databases before applying the core data mining algorithm <ref> [4, 10, 12] </ref>. We have developed a tool, ParkaDB that is capable of managing large ontologies. ParkaDB [7, 8] has a very efficient structural design and it is based on high-performance computing technologies. <p> In this paper we present a technique similar to those used in the aforementioned systems. Our system is based on high-level abstraction using domain ontologies and an efficient, scalable ontology management tool, ParkaDB, which allows it to induce multi-level classification rules without pre-generalizing tables (see <ref> [10, 4, 12] </ref>). Data mining at high levels of abstraction has several advantages over data mining at low levels. First, high-level rules can provide a "clearer" synopsis of databases. In general, data mining systems generate summaries of databases in the form of low-level information. <p> Walker [10] was the first to use concept taxonomies. The taxonomies were used to replace values by more general values. Han et al. [4] proposed a similar approach to find characterization and classification rules at high levels of generality. Later, Dhar and Tuzhilin <ref> [12] </ref> proposed a generalization of the techniques of Walker and Han. Their approach used database views and con cept hierarchies to represent background knowledge and could induce a broader range of interesting patterns. All of the above mentioned approaches were based on traditional relational database technology.
Reference: [13] <author> Merwyn Taylor. </author> <title> Hybrid knowledge- and databases. </title> <booktitle> In Thirteenth National Conference on Artificial Intelligence, </booktitle> <volume> volume 2, </volume> <pages> page 1411. </pages> <publisher> AAAI/MIT Press, </publisher> <year> 1996. </year> <month> 7 </month>
Reference-contexts: We are using ParkaDB to integrate ontologies and database. Such an integration in crucial to effectively use ontologies (concept hierarchies) within data mining systems. This tool simplifies data mining with background knowledge by allowing databases to be queried at high levels of abstraction <ref> [13] </ref>. The algorithm presented in this paper is the major component of a data mining system that will be used at Johns Hopkins Hospital. The system will be used to find conditions under which patients had positive responses to platelet transfusions as well as negative responses.
References-found: 13

