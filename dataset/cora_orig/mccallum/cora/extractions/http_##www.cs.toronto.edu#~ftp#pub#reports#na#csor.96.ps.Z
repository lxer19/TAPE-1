URL: http://www.cs.toronto.edu/~ftp/pub/reports/na/csor.96.ps.Z
Refering-URL: http://www.cs.toronto.edu/NA/reports.html
Root-URL: http://www.cs.toronto.edu
Title: Remarks on the optimal convolution kernel for CSOR waveform relaxation  
Author: Min Hu ; Ken Jackson ; Jan Janssen ; and Stefan Vandewalle ; 
Keyword: convolution, iterative methods, parallel ODE solvers, successive over-relaxation, waveform relaxation  
Address: 1440 Hurontario Street, Mississauga, Ontario, Canada L5G 3H4  10 King's College Road, Toronto, Ontario, Canada M5S 3G4  Celestijnenlaan 200 A, B-3001 Heverlee, Belgium  Ontario.  
Affiliation: 1 Comnetix Computer Systems Inc.,  Department of Computer Science, University of Toronto,  Department of Computer Science, Katholieke Universiteit Leuven,  Sciences and Engineering Research Council of Canada and the Information Technology Research Centre of  
Note: Baltzer Journals  Subject classification: AMS(MOS) 65F10, 65L05 This research was supported in part by the Natural  This research has been funded by the Research Fund K.U.Leuven (OT/94/16) and the Bel gian National Fund for Scientific Research (N.F.W.O., project G.0235.96). Postdoctoral Fellow of the Belgian National Fund for Scientific Research (N.F.W.O.).  
Email: E-mail: mhu@Comnetix.COM  E-mail: krj@cs.toronto.edu  E-mail: janj,stefan@cs.kuleuven.ac.be  
Phone: 2  3  
Date: August 27, 1996  
Abstract: The convolution SOR waveform relaxation method is a numerical method for solving large-scale systems of ordinary differential equations on parallel computers. It is similar in spirit to the SOR acceleration method for solving linear systems of algebraic equations, but replaces the multiplication with an overrelax-ation parameter by a convolution with a time-dependent overrelaxation function. Its convergence depends strongly on the particular choice of this function. In this paper, an analytic expression is presented for the optimal continuous-time convolution kernel and its relation to the optimal kernel for the discrete-time iteration is derived. We investigate whether this analytic expression can be used in actual computations. Also, the validity of the formulae that are currently used to determine the optimal continuous-time and discrete-time kernels is extended towards a larger class of ODE systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Abramowitz and I. A. </author> <title> Stegun. Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables. </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: We will assume that k starting values y [0]; y <ref> [1] </ref>; : : :; y [k 1] are available. The characteristic polynomials of the linear multistep method are given by a (z) = P k P k l=0 fi l z l , and the stability region is denoted by S. <p> Hu et al./ Optimal convolution SOR waveform relaxation 8 the latter of which can be found in <ref> [1, eq. (29.3.53)] </ref>. The shape of the function (! c ) opt (t) is characterised by the properties given in the following lemma. <p> opt (t), given by (14), satisfies the following properties: 1: (! c ) opt (0) = 0 3: 1 4: 0 (! c ) opt (t) dt = 1 p 1 ) 2 : Proof A series expression for the modified Bessel function I 2 (t) can be found in <ref> [1, eq. (9.6.10)] </ref>. <p> As an example, we will illustrate these implications of Lemma 6 for the one-dimensional heat equation on the unit interval, @u (x; t) @x 2 = 0 ; x 2 <ref> [0; 1] </ref> ; t &gt; 0 ; (20) discretised using finite differences on a mesh fx i = ih j 0 i 1=hg with mesh size h. <p> The resulting ODE system (1), with B = I, d a = 2=h 2 and 1 = cos (h), satisfies the conditions of Theorem 5. Figure 1 shows a logarithmic plot of (! c ) opt (t) for t 2 <ref> [10 5 ; 1] </ref> and for several values of the mesh size h. Note that its maximum increases and is attained at a smaller t-value for decreasing h, while, for sufficiently large t, the value of the optimal kernel rapidly approaches 0. <p> the convergence of the discrete-time kernel to the continuous-time one with decreasing time increment, we have plotted the absolute value of the difference ((! c ) opt ) o [n] (! c ) opt (no ) (36) in Figure 2 for several values of o and t = no 2 <ref> [10 4 ; 1] </ref>. We used the Crank M.
Reference: [2] <author> A. Bellen, Z. Jackiewicz, and M. Zennaro. </author> <title> Contractivity of waveform relaxation Runge-Kutta iterations and related limit methods for dissipative systems in the maximum norm. </title> <editor> M. Hu et al./ </editor> <title> Optimal convolution SOR waveform relaxation 24 SIAM J. </title> <journal> Numer. Anal., </journal> <volume> 31(2) </volume> <pages> 499-523, </pages> <month> April </month> <year> 1994. </year>
Reference: [3] <author> A. Bellen and M. Zennaro. </author> <title> The use of Runge-Kutta formulae in waveform relaxation methods. </title> <journal> Appl. Numer. Math., </journal> <volume> 11 </volume> <pages> 95-114, </pages> <year> 1993. </year>
Reference: [4] <author> R. N. Bracewell. </author> <title> The Fourier Transform and its Applications. </title> <publisher> McGraw-Hill Kogakusha, Ltd., </publisher> <address> Tokyo, 2nd edition, </address> <year> 1978. </year>
Reference-contexts: Therefore, for any such z the optimal ( e opt ) o (z) is given by the combination of (12) and (27) . This function is bounded and analytic for jzj 1; by using the inverse Z-transform formula, <ref> [4, p. 262] </ref>, we arrive at the expression ((! c ) opt ) o [n] = 2i jzj=1 i j As we have derived the conditions for existence of the optimal kernels, we can now prove the correctness of (23). We start by considering the case of t = 0.
Reference: [5] <author> E. Hairer and G. Wanner. </author> <title> Solving Ordinary Differential Equations II, </title> <booktitle> volume 14 of Springer Series in Computational Mathematics. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: We will also need the notion of a strictly stable multistep method, which is such that 1 is the only (simple) root of a (z) on the unit circle, <ref> [5] </ref>. The first step of the discrete-time CSOR waveform relaxation algorithm is obtained by discretising (2) using a linear multistep method. <p> (11) and (15), i.e., ( 1 ) o (z) = 1 a (z) 1 : (27) Because of the strict stability of the multistep method at least a small disk of the form fj : jj + dj dg with d &gt; 0 is contained in the stability region S, <ref> [5, p. 259] </ref>. Consequently, we have for small enough o that fj : jj +d a j d a g ae o 1 S. <p> The proof is then completed by setting g () to be the L 1 (1; 1)-function g () = &lt; 1 2 [L; L] jj 2 62 [L; L] ; with L &gt; M d a . Remark 3 The strict stability condition is a very natural condition. In <ref> [5, p. 272] </ref> we find that it is satisfied by any multistep method of practical interest with nonempty int S. However, methods that do not satisfy the condition on the stability region do exist - Nystrom methods, for example, [5, p. 262]. <p> In [5, p. 272] we find that it is satisfied by any multistep method of practical interest with nonempty int S. However, methods that do not satisfy the condition on the stability region do exist - Nystrom methods, for example, <ref> [5, p. 262] </ref>. For such methods ( e opt ) o (z) from (12) is not analytic for jzj 1, and the inverse Z-transform calculation is not feasible. M.
Reference: [6] <author> G. Horton, S. Vandewalle, and P. Worley. </author> <title> An algorithm with polylog parallel complexity for solving parabolic partial differential equations. </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 16(3) </volume> <pages> 531-541, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Waveform relaxation is an iterative method for numerically solving large-scale systems of ordinary differential equations (ODEs). The method is well suited for implementation on parallel computers, and high parallel efficiencies have been demonstrated for various applications, <ref> [6, 19, 22] </ref>. The convergence of the basic Ja-cobi and Gauss-Seidel waveform relaxation methods can be accelerated in several ways, such as by successive overrelaxation ([2, 3, 8, 14, 15, 19]), by Chebyshev iteration ([11, 20]), by Krylov subspace methods ([13]) and by multigrid techniques ([9, 10, 12, 21]).
Reference: [7] <author> M. Hu, K. Jackson, and B. Zhu. </author> <title> Complex optimal SOR parameters and convergence regions. </title> <institution> Department of Computer Science, University of Toronto, Canada, </institution> <note> Working Notes, </note> <year> 1995. </year>
Reference-contexts: If the collinearity assumption is not satisfied, however, one cannot find an optimal e o (z) easily, and a more complex SOR theory may have to be used. Such a theory was recently developed by Hu, Jackson and Zhu, <ref> [7] </ref>. They assume the eigenvalues of K JAC o (z) to lie in a region R (p o (z); q o (z); OE o (z)), the closed interior of an ellipse centred around the origin. <p> Hu et al./ Optimal convolution SOR waveform relaxation 19 e o (z) as o (z)2R (p o (z);q o (z);OE o (z)) j o (z)j : o (z) + e o (z) 1 = o (z) e o (z) o (z) : In <ref> [7] </ref>, Hu, Jackson and Zhu determine a value ( e ellipse ) o (z) which minimises this upper bound for a given ellipse. Based on their result, [7, Thm. 1], we can immediately formulate the following lemma. <p> Based on their result, <ref> [7, Thm. 1] </ref>, we can immediately formulate the following lemma. Lemma 8 Assume the matrices B and A are such that o 1 a (z)=b (z)B + A is a block-consistently ordered matrix with nonsingular diagonal blocks. <p> The following remarkable result from <ref> [7, x3] </ref> shows that there actually exists an ellipse for which the bound in (45) is attained. Uniqueness, however, of this optimal ellipse is not guaranteed by the theory in the above reference. <p> We do not know how to find such an optimal ellipse when the eigenvalues of K JAC o (z) are not collinear. Although an example has been given in <ref> [7, x4] </ref>, even the problem of finding a good ellipse (which surrounds the spectrum of the Jacobi symbol and for which the associated bound is relatively sharp) may prove to be a formidable task.
Reference: [8] <author> J. Janssen and S. Vandewalle. </author> <title> On SOR waveform relaxation methods. </title> <type> Technical Report CRPC-95-4, </type> <institution> Center for Research on Parallel Computation, California Institute of Technology, Pasadena, California, U.S.A., </institution> <month> October </month> <year> 1995. </year> <note> (accepted for publication in SIAM J. Numer. Anal.) </note>
Reference-contexts: Recently, we have analysed the acceleration of the waveform method for (1) by successive overrelaxation (SOR) techniques, <ref> [8] </ref>. <p> In the second step, the old approximation u (1) i (t) is updated to give the new iterate u () i (t). In the standard SOR waveform scheme this involves the multiplication of the correction ^u () (1) i (t) by a scalar overrelaxation parameter !, <ref> [8, eq. (2.2)] </ref>. In the convolution SOR (CSOR) waveform relaxation algorithm, the correction is convolved with a time-dependent kernel (t), u i (t) = u i (t) + 0 i () (1) j The success of the latter depends strongly on the particular choice of convolution kernel. <p> This means that the asymptotic convergence factor of the CSOR waveform relaxation method behaves as 1 O (h) for small h, while the spectral radii of the Jacobi, Gauss-Seidel and standard SOR waveform methods are all known to satisfy a formula of the form 1 O (h 2 ), <ref> [8] </ref>. A very substantial improvement over the less sophisticated waveform schemes may therefore be expected. In this paper, we will continue our exploration of the CSOR waveform relaxation method. <p> For a more detailed study of the method, including proofs, references and a comparison with other waveform methods, we refer to <ref> [8] </ref>. 2.1 The continuous-time case The continuous-time CSOR waveform relaxation method, defined by (2) and (3), can be written formally as u () (t) = K CSOR u (1) (t) + '(t) ; where K CSOR is a linear operator consisting of a matrix multiplication and a Volterra convolution part. <p> A convolution kernel of the form (t) = !ffi (t) + ! c (t) ; (4) is assumed, with ! a scalar parameter and ffi (t) the delta function. Theorem 1 <ref> [8, Thm. 3.4] </ref> Assume all eigenvalues of D 1 B D A have positive real parts, and let (t) be of the form (4) with ! c (t) 2 L 1 (0; 1). <p> The Laplace-transform expression of the optimal convolution kernel opt (t) depends on the location of the eigenvalues of the Jacobi symbol K JAC (z) = (zD B + D A ) (z (L B + U B ) + (L A + U A )) : (6) Lemma 2 <ref> [8, Lemma 3.6] </ref> Assume the matrices B and A are such that zB + A is a block-consistently ordered matrix with nonsingular diagonal blocks. <p> In particular, ae K CSOR;opt (z) j fi fi e opt (z) 1 fi 2.2 The discrete-time case In an actual implementation, the continuous-time method is replaced by a discrete time method. As in <ref> [8] </ref>, we will only deal with (irreducible, consistent, zero-stable) linear multistep formulae for time discretisation. <p> The discrete-time equivalent to Theorem 1 is given next. Theorem 3 <ref> [8, Thm. 4.4] </ref> Assume oe (o D 1 B D A ) ae intS and o 2 l 1 (1). <p> It depends on the eigenvalue distribution of the discrete-time Jacobi symbol, which is related to its continuous-time equivalent (6) by [10, eq. (4.10)], K JAC o b (z) : (11) Lemma 4 <ref> [8, Lemma 4.5] </ref> Assume the matrices B and A are such that o 1 a (z)=b (z)B + A is a block-consistently ordered matrix with nonsingular diagonal blocks. <p> Remark 1 then yields that opt (t) is of the form (4) with ! c (t) 2 L 1 (0; 1), while ! = lim z!1 e opt (z) = 1 by <ref> [8, Prop. 3.2] </ref>. The correctness of the analytic expression for opt (t) or (! c ) opt (t) can be checked as an elementary exercise by using the Laplace-transform pairs L (ffi (t)) = 1 and a b t)=t = ( z + a + z + b) 4 M. <p> Calculation of the maxima of the upper and lower bounds (18) and (19) over t 0 leads to Property 3. Finally, Property 4 follows immediately from <ref> [8, Prop. 3.2] </ref>. M. Hu et al./ Optimal convolution SOR waveform relaxation 9 (dotted), h = 1=32 (dashed) and h = 1=64 (dash-dotted). When the system of ODEs is derived by semi discretisation of a parabolic partial differential equation, 1 is often close to one. <p> 3 10 4 10 5 10 6 BDF (3) 0.710 1.261 1.069 0.249 -0.729 -1.727 Nicolson (CN) method and the third-order backward differentiation (BDF (3)) formula for time discretisation and approximated the discrete kernel from (12) by an inverse Z-transform algorithm based on the use of FFT's, as explained in <ref> [8, x5.4] </ref>. The downward peaks are due to the zero crossing of (36). To illustrate the convergence at t = 0, we report values of log i o in Table 1. <p> Thus, the value opt [n] can be approximated by the n-th element of the discrete Fourier transform of the sequence n i jo M1 for some M N (M is usually selected to be larger than N to anticipate certain aliasing effects), <ref> [8, x5.4] </ref>. The approach is illustrated for the model problem with CN time discretisation in Table 3. We observe that the experimental convergence factors are independent of the time increment o . <p> We observe that the experimental convergence factors are independent of the time increment o . More precisely, they are almost identical to the optimal continuous-time spectral radii ae (K CSOR;opt ), which are proved to behave as 1 2h for small h, <ref> [8, x5.1] </ref>. Next, we consider the case of problems for which ( 1 ) o (z) is not known analytically. For such systems, we cannot compute the analytic expression of ( e opt ) o (z) explicitly. <p> We will limit the discussion to the discrete-time case. The continuous-time case can be treated similarly. Lemma 4 was proved by applying a classical SOR result for complex matrices to the linear system (o 1 a (z)=b (z)B +A)u = f . It was noted in <ref> [8] </ref> that the CSOR symbol K CSOR o (z) represents the SOR iteration matrix for the latter system, with e o (z) acting as the complex overrelaxation parameter. <p> A similar operation applied to the ellipse surrounding the latter spectrum is then expected to lead to a good ellipse for the current value of z. This approach is however not applicable when B 6= I or D A 6= d a I. Therefore, the numerical experiments in <ref> [8, x6] </ref> and [19] were performed with still another convolution sequence. In those references, the convolution kernel was computed by using the formula in the right-hand side of (12). <p> Hu et al./ Optimal convolution SOR waveform relaxation 21 not guaranteed to be the optimal one, or even a good one. Nevertheless, numerical evidence showed that this procedure yields excellent convergence rates for the problems considered. This observation led us in <ref> [8] </ref> to talk about the robustness of the CSOR waveform relaxation method. With the generalised CSOR theory, this robustness can now be explained in an intuitive manner as follows. <p> In our experiments, this always appeared to be near the value z = 1. Fortunately, this is exactly where the eigenvalues of the Jacobi symbol are collinear or nearly collinear. The above discussion will be illustrated by means of the model problem of <ref> [8, x6] </ref>, that is, the two-dimensional heat equation, discretised on a regular, triangular mesh f (x i = ih; y j = jh) j 0 i; j 1 h g using linear finite elements. <p> Consequently, the linewise CSOR waveform relaxation method with the approximating kernel from (12) should demonstrate similar convergence results. This observation is confirmed by the numerical experiments in <ref> [8, x6] </ref>, the resulting averaged convergence factors of which are recalled in Table 4. Acknowledgements The authors would like to thank Andrew Lumsdaine and Mark W. Reichelt for many interesting discussions on the topic of this paper.
Reference: [9] <author> J. Janssen and S. Vandewalle. </author> <title> Multigrid waveform relaxation on spatial finite-element meshes: The continuous-time case. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 33(2) </volume> <pages> 456-474, </pages> <month> April </month> <year> 1996. </year>
Reference: [10] <author> J. Janssen and S. Vandewalle. </author> <title> Multigrid waveform relaxation on spatial finite-element meshes: The discrete-time case. </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 17(1) </volume> <pages> 133-155, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: Finally, we recall the discrete-time version of Lemma 2, which gives an expression of the Z-transform of the optimal convolution sequence ( opt ) o . It depends on the eigenvalue distribution of the discrete-time Jacobi symbol, which is related to its continuous-time equivalent (6) by <ref> [10, eq. (4.10)] </ref>, K JAC o b (z) : (11) Lemma 4 [8, Lemma 4.5] Assume the matrices B and A are such that o 1 a (z)=b (z)B + A is a block-consistently ordered matrix with nonsingular diagonal blocks.
Reference: [11] <author> C. Lubich. </author> <title> Chebyshev acceleration of Picard-Lindelof iteration. </title> <journal> BIT, </journal> <volume> 32 </volume> <pages> 535-538, </pages> <year> 1992. </year>
Reference: [12] <author> C. Lubich and A. Ostermann. </author> <title> Multi-grid dynamic iteration for parabolic equations. </title> <journal> BIT, </journal> <volume> 27 </volume> <pages> 216-234, </pages> <year> 1987. </year>
Reference: [13] <author> A. Lumsdaine. </author> <title> Theoretical and Practical Aspects of Parallel Numerical Algorithms for Initial Values Problems, with Applications. </title> <institution> Ph.D.-thesis, Deptartment of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, Massachusetts, U.S.A., </institution> <month> Januari </month> <year> 1992. </year>
Reference: [14] <author> U. Miekkala and O. Nevanlinna. </author> <title> Convergence of dynamic iteration methods for initial value problems. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 8(4) </volume> <pages> 459-482, </pages> <month> July </month> <year> 1987. </year>
Reference: [15] <author> U. Miekkala and O. Nevanlinna. </author> <title> Sets of convergence and stability regions. </title> <journal> BIT, </journal> <volume> 27 </volume> <pages> 554-584, </pages> <year> 1987. </year>
Reference: [16] <author> A. D. Poularakis and S. Seely. </author> <title> Elements of Signals and Systems. </title> <booktitle> PWS-Kent Series in Electrical Engineering. </booktitle> <publisher> PWS-Kent Publishing Company, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference-contexts: In that case we can use Property 1 of Lemma 6. Hence, we need to show that lim ((! c ) opt ) o [0] = (! c ) opt (0) = 0 : (29) By the initial-value theorem for the Z-transform, <ref> [16, Eq. (7.35)] </ref>, we find ((! c ) opt ) o [0] = lim i j 2 r i z!1 j 2 M.
Reference: [17] <author> S. Reed and B. Simon. </author> <title> Functional Analysis, volume 1 of Methods of Modern Mathematical Physics. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference: [18] <author> M. W. Reichelt. </author> <title> Accelerated Waveform Relaxation Techniques for the Parallel Transient Simulation of Semiconductor Devices. </title> <institution> Ph.D.-thesis, Deptartment of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, Massachusetts, U.S.A., </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: For use in this situation, an automatic procedure was developed by Reichelt et al. for computing an analytic approximation to ( e opt ) o (z), <ref> [18, x5.6] </ref> and [19, x6]. The largest-magnitude eigenvalue ( 1 ) o (z) for some specific values of z (e.g. z = 1; 1; 1; : : :) are estimated by subspace iteration or the implicitly restarted Arnoldi method, and inserted in (12).
Reference: [19] <author> M. W. Reichelt, J. K. White, and J. Allen. </author> <title> Optimal convolution SOR acceleration of waveform relaxation with application to parallel simulation of semiconductor devices. </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 16(5) </volume> <pages> 1137-1158, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Waveform relaxation is an iterative method for numerically solving large-scale systems of ordinary differential equations (ODEs). The method is well suited for implementation on parallel computers, and high parallel efficiencies have been demonstrated for various applications, <ref> [6, 19, 22] </ref>. The convergence of the basic Ja-cobi and Gauss-Seidel waveform relaxation methods can be accelerated in several ways, such as by successive overrelaxation ([2, 3, 8, 14, 15, 19]), by Chebyshev iteration ([11, 20]), by Krylov subspace methods ([13]) and by multigrid techniques ([9, 10, 12, 21]). <p> For use in this situation, an automatic procedure was developed by Reichelt et al. for computing an analytic approximation to ( e opt ) o (z), [18, x5.6] and <ref> [19, x6] </ref>. The largest-magnitude eigenvalue ( 1 ) o (z) for some specific values of z (e.g. z = 1; 1; 1; : : :) are estimated by subspace iteration or the implicitly restarted Arnoldi method, and inserted in (12). <p> The procedure M. Hu et al./ Optimal convolution SOR waveform relaxation 18 is illustrated for certain nonlinear semi-conductor device problems in <ref> [19] </ref>, and is shown to lead to very satisfactory results, even for systems of ODEs that do not satisfy the assumptions of Theorem 4. <p> This approach is however not applicable when B 6= I or D A 6= d a I. Therefore, the numerical experiments in [8, x6] and <ref> [19] </ref> were performed with still another convolution sequence. In those references, the convolution kernel was computed by using the formula in the right-hand side of (12).
Reference: [20] <author> R. Skeel. </author> <title> Waveform iteration and the shifted Picard splitting. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 10(4) </volume> <pages> 756-776, </pages> <month> July </month> <year> 1989. </year>
Reference: [21] <author> S. Vandewalle. </author> <title> Parallel Multigrid Waveform Relaxation for Parabolic Problems. </title> <address> B.G. Teub-ner, Stuttgart, </address> <year> 1993. </year>
Reference: [22] <author> S. Vandewalle and E. Van de Velde. </author> <title> Space-time concurrent multigrid waveform relaxation. </title> <journal> Annals of Numer. Math., </journal> <volume> 1 </volume> <pages> 347-363, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction Waveform relaxation is an iterative method for numerically solving large-scale systems of ordinary differential equations (ODEs). The method is well suited for implementation on parallel computers, and high parallel efficiencies have been demonstrated for various applications, <ref> [6, 19, 22] </ref>. The convergence of the basic Ja-cobi and Gauss-Seidel waveform relaxation methods can be accelerated in several ways, such as by successive overrelaxation ([2, 3, 8, 14, 15, 19]), by Chebyshev iteration ([11, 20]), by Krylov subspace methods ([13]) and by multigrid techniques ([9, 10, 12, 21]).
Reference: [23] <author> D. M. Young. </author> <title> Iterative Solution of Large Linear Systems. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1971. </year>
Reference-contexts: Since the coefficient matrix of the linear system is assumed to be block-consistently ordered, the eigenvalues of the SOR iteration matrix, o (z), are related to the eigenvalues o (z) of K JAC o (z) by the Young-relation, <ref> [23, Thm. 14-3.4] </ref>, o (z) + e o (z) 1 = o (z) e o (z) o (z) : (40) This implies that the spectral radius ae (K CSOR o (z)) for a given e o (z) equals max ae q oe When the eigenvalues of K JAC o (z) are
References-found: 23

