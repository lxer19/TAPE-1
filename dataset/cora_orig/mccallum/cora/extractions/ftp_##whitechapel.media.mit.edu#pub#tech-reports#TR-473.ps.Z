URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-473.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Title: Pattern Classification  
Author: Elias Vyzas and Rosalind W. Picard 
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: The Media Laboratory Massachusetts Institute of Technology  
Note: Affective  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 473 Also appears in the 1998 AAAI Fall Symposium Series: Emotional and Intelligent: The Tangled Knot of Cognition, October 23-25, 1998, Orlando, Florida Abstract We develop a method for recognizing the emotional state of a person who is deliberately expressing one of eight emotions. Four physiological signals were measured and six features of each of these signals were extracted. We investigated three methods for the recognition: (1) Sequential floating forward search (SFFS) feature selection with K-nearest neighbors classification, (2) Fisher projection on structured subsets of features with MAP classification, and (3) A hybrid SFFS-Fisher projection method. Each method was evaluated on the full set of eight emotions as well as on several subsets. The SFFS attained the highest rate for a trio of emotions, 2.7 times that of random guessing, while the Fisher projection with structured subsets attained the best performance on the full set of emotions, 3.9 times random. The emotion recognition problem is demonstrated to be a difficult one, with day-to-day variations within the same class often exceeding between-class variations on the same day. We present a way to take account of the day information, resulting in an improvement to the Fisher-based methods. The findings in this paper demonstrate that there is significant information in physiological signals for classifying the affective state of a person who is deliberately expressing a small set of emotions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. W. </author> <title> Picard. Affective Computing. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1997. </year>
Reference-contexts: 1 Introduction This paper addresses emotion recognition, specifically the recognition by computer of affective information expressed by people. This is part of a larger effort in "affective computing," computing that relates to, arises from, or deliberately influences emotions <ref> [1] </ref>. Affective computing has numerous applications and motivations, one of which is giving computers the skills involved in so-called "emotional intelligence," such as the ability to recognize a person's emotions. <p> to her, and he just prevented her from obtaining it; therefore, she might be angry at him." The best emotion recognition is likely to come from pattern recognition and reasoning applied to a combination of all of these modalities, including both low-level signal recognition, and higher-level reasoning about the situation <ref> [1] </ref>. For the research described here, four physiological signals of an actress were recorded during deliberate emotional expression. The signals measured were electromyo-gram (EMG) from the jaws, representing muscular tension or jaw clenching, blood volume pressure (BVP) and skin conductivity (GSR) from the fingers, and respiration from chest expansion. <p> Therefore in general the number of Fisher projection dimensions d is 1 d min (n; c) 1. For example, when 24 features are used on all 8 classes, all d = <ref> [1; 7] </ref> are tried. When 4 features are used on 8 classes, all d = [1; 3] are tried. 3.3 Hybrid SFFS with Fisher Projection (SFFS-FP) As mentioned above, the SFFS algorithm proposes one subset of m features for each m, 2 m n. <p> Therefore in general the number of Fisher projection dimensions d is 1 d min (n; c) 1. For example, when 24 features are used on all 8 classes, all d = [1; 7] are tried. When 4 features are used on 8 classes, all d = <ref> [1; 3] </ref> are tried. 3.3 Hybrid SFFS with Fisher Projection (SFFS-FP) As mentioned above, the SFFS algorithm proposes one subset of m features for each m, 2 m n.
Reference: [2] <author> D. Goleman. </author> <title> Emotional Intelligence. </title> <publisher> Bantam Books, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: Such skills have been argued to be more important in general than mathematical and verbal abilities in determining a person's success in life <ref> [2] </ref>. Recognition of emotional information is a key step toward giving computers the ability to interact more naturally and intelligently with people. The research described here focuses on recognition of emotional states during deliberate emotional expression by an actress.
Reference: [3] <author> Dr. M. Clynes. Sentics: </author> <title> The Touch of the Emotions. </title> <address> Anchor Press/Doubleday, </address> <year> 1977. </year>
Reference-contexts: The research described here focuses on recognition of emotional states during deliberate emotional expression by an actress. The actress, trained in guided imagery, used the Clynes method of sentic cycles to assist in eliciting the emotional states <ref> [3] </ref>. For example, to elicit the state of "Neutral," (no emotion) she focused on a blank piece of paper or a typewriter. To elicit the state of "Anger" she focused on people who aroused anger in her. <p> Therefore in general the number of Fisher projection dimensions d is 1 d min (n; c) 1. For example, when 24 features are used on all 8 classes, all d = [1; 7] are tried. When 4 features are used on 8 classes, all d = <ref> [1; 3] </ref> are tried. 3.3 Hybrid SFFS with Fisher Projection (SFFS-FP) As mentioned above, the SFFS algorithm proposes one subset of m features for each m, 2 m n.
Reference: [4] <author> P. J. Lang. </author> <title> The emotion probe: Studies of motivation and attention. </title> <journal> American Psychologist, </journal> <volume> 50(5) </volume> <pages> 372-385, </pages> <year> 1995. </year>
Reference-contexts: The specific states one would want a computer to recognize will depend on the particular application. The eight emotions used in this research are intended to be representative of a broad range, which can be described in terms of the "arousal-valence" space commonly used by psychologists <ref> [4] </ref>. The arousal axis ranges from calm and peaceful to active and excited, while the valence axis ranges from negative to positive. For example, anger was considered high in arousal, while reverence was considered low. Love was considered positive, while hate was considered negative.
Reference: [5] <author> K. R. Scherer. Ch. </author> <title> 10: Speech and emotional states. </title> <editor> In J. K. Darby, editor, </editor> <booktitle> Speech Evaluation in Psychiatry, </booktitle> <pages> pages 189-220. </pages> <publisher> Grune and Stratton, Inc., </publisher> <year> 1981. </year>
Reference-contexts: The problem is a hard one when you look at the few benchmarks which exist. In general, people can recognize affect in neutral-content speech with about 60% accuracy, choosing from among about six different affective states <ref> [5] </ref>. Computer algorithms can match this accuracy but only under more restrictive assumptions, such as when the sentence content is known. Facial expression recognition is easier, and the rates computers obtain are higher: from 80-98% accuracy when recognizing 5-7 classes of emotional expression on groups of 8-32 people [6, 7].
Reference: [6] <author> Y. Yacoob and L. S. Davis. </author> <title> Recognizing human facial expressions from log image sequences using optical flow. </title> <journal> IEEE T. Patt. Analy. and Mach. Intell., </journal> <volume> 18(6) </volume> <pages> 636-642, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Computer algorithms can match this accuracy but only under more restrictive assumptions, such as when the sentence content is known. Facial expression recognition is easier, and the rates computers obtain are higher: from 80-98% accuracy when recognizing 5-7 classes of emotional expression on groups of 8-32 people <ref> [6, 7] </ref>. Facial expressions are easily controlled by people, and easily exaggerated, facilitating their discrimination. Emotion recognition can also involve other modalities such as analyzing posture, gait, gesture, and a variety of physiological features in addition to the ones described in this paper.
Reference: [7] <author> Irfan Essa and Alex Pentland. </author> <title> Coding, analysis, interpretation and recognition of facial expressions. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 19(7) </volume> <pages> 757-763, </pages> <month> July </month> <year> 1997. </year>
Reference-contexts: Computer algorithms can match this accuracy but only under more restrictive assumptions, such as when the sentence content is known. Facial expression recognition is easier, and the rates computers obtain are higher: from 80-98% accuracy when recognizing 5-7 classes of emotional expression on groups of 8-32 people <ref> [6, 7] </ref>. Facial expressions are easily controlled by people, and easily exaggerated, facilitating their discrimination. Emotion recognition can also involve other modalities such as analyzing posture, gait, gesture, and a variety of physiological features in addition to the ones described in this paper. <p> Therefore in general the number of Fisher projection dimensions d is 1 d min (n; c) 1. For example, when 24 features are used on all 8 classes, all d = <ref> [1; 7] </ref> are tried. When 4 features are used on 8 classes, all d = [1; 3] are tried. 3.3 Hybrid SFFS with Fisher Projection (SFFS-FP) As mentioned above, the SFFS algorithm proposes one subset of m features for each m, 2 m n.
Reference: [8] <author> John T. Cacioppo and Louis G. Tassinary. </author> <title> Inferring psychological significance from physiological signals. </title> <journal> American Psychologist, </journal> <volume> 45(1) </volume> <pages> 16-28, </pages> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: Some psychologists have argued that emotions might be recognizable from physiological signals given suitable pattern recognition techniques <ref> [8] </ref>, but nobody has yet to demonstrate which physiological signals, or which features of those signals, or which methods of classification, give reliable indications of an underlying emotion, if any.
Reference: [9] <author> P. Pudil, J. Novovicova, and J. Kittler. </author> <title> Floating search methods in feature selection. </title> <journal> Pattern Recognition Letters, </journal> <volume> 15 </volume> <pages> 1119-1125, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Therefore, reductions in the dimensionality of the feature space need to be explored, among with other options. In this paper we focus on three methods for reducing the dimensionality, and evaluate the performance of these methods. 3.1 Sequential Floating Forward Search The Sequential Floating Forward Search (SFFS) method <ref> [9] </ref> is chosen due to its consistent success in previous evaluations of feature selection algorithms, where it has recently been shown to outperform methods such as Sequential Forward and Sequential Backward Search (SFS, SBS), Generalized SFS and SBS, and Max-Min, [10] in several benchmarks. <p> It then does a non-exhaustive search on the feature space by iteratively adding and subtracting features. It outputs one subset of m features for each m, 2 m n, together with its classification rate. The algorithm is described in detail in <ref> [9] </ref>. 3.2 Fisher Projection Fisher projection is a well-known method of reducing the dimensionality of the problem in hand, which involves less computation than SFFS. The goal is to find a projection of the data to a space of fewer dimensions than the original where the classes are well separated.
Reference: [10] <author> A. K. Jain and D. Zongker. </author> <title> Feature selection: Evaluation, application, and small sample performance. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 19(2) </volume> <pages> 153-158, </pages> <month> February </month> <year> 1997. </year> <month> 6 </month>
Reference-contexts: Floating Forward Search The Sequential Floating Forward Search (SFFS) method [9] is chosen due to its consistent success in previous evaluations of feature selection algorithms, where it has recently been shown to outperform methods such as Sequential Forward and Sequential Backward Search (SFS, SBS), Generalized SFS and SBS, and Max-Min, <ref> [10] </ref> in several benchmarks. Of course the performance of SFFS is data dependent and the data here is new and difficult; hence, the SFFS may not be the best method to use.
References-found: 10

