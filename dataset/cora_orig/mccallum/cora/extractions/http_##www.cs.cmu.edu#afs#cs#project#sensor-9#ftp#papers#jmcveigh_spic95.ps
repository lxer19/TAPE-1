URL: http://www.cs.cmu.edu/afs/cs/project/sensor-9/ftp/papers/jmcveigh_spic95.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs/project/sensor-9/ftp/papers/
Root-URL: 
Email: Contact Address:  jmcveigh@cmu.edu  
Title: Intermediate view synthesis considering occluded and ambiguously referenced image regions  
Author: Jeffrey S. McVeigh M. W. Siegel and Angel G. Jordan Jeffrey S. McVeigh 
Address: Pittsburgh, PA 15213  5000 Forbes Avenue Pittsburgh, PA 15213  
Affiliation: Department of Electrical and Computer Engineering Robotics Institute School of Computer Science Carnegie Mellon University,  Department of Electrical and Computer Engineering Carnegie Mellon University  
Abstract-found: 0
Intro-found: 1
Reference: 1. <institution> This research was supported by the Advanced Research Projects Agency under ARPA Grant No. MDA 972-92-J-1010. </institution>
Reference-contexts: After a brief discussion of prior work on image interpolation, we describe our algorithm for intermediate view synthesis. Synthesis is performed, in the standard manner, using the geometric relationship between the given views and estimated disparity values <ref> [1, 4, 6, 7, 10-12] </ref>. <p> Intermediate view synthesis is closely related to work performed on motion compensated interpolation for frame rate conversion, de-interlacing and frame skipping, where views are generated from two temporally offset images <ref> [1, 7, 10, 12] </ref>. For these techniques, when a portion of the interpolated image is not mapped from the given displacement vectors, zero displacement is often assumed most probable and the missing region is mapped from the corresponding region in one of the two reference image. <p> In our synthesis algorithm, we perform block-based disparity estimation in both directions. We first attempt to eliminate false estimates due to occluded regions with a procedure similar to one proposed by Cafforio, et. al. <ref> [1] </ref>. If only a single vector was detected as coming from an unoccluded region, this vector is used to perform the mapping. Otherwise, the ambiguously referenced intermediate pixel is mapped using the disparity vector with maximum estimation confidence. <p> Our occlusion detection procedure is similar to one proposed by Cafforio, et. at.; however, our procedure takes the form of a classic detection problem, and does not require a search step <ref> [1, 13] </ref>. For each pixel in both images, we sum the disparity vector in one direction with the corresponding disparity vector in the opposite direction. If the absolute value of the sum is greater than a threshold the pixel is assumed to be occluded.
Reference: 2. <editor> We speculate that those viewers who have difficulty fusing stereopairs may derive as much stereopsis sensation from the reduced depth range image as other viewers who have no difficulty derive from increased depth range. </editor> <title> These assessments are informal in the sense that designed and controlled human factors experiments were not conducted. They are our impressions based on perceptions reported by colleagues and the many visitors to our lab. </title> <type> 12 </type>
Reference-contexts: Other prior work has attempted to construct a three-dimensional model of the scene from two or more images and then utilize computer-graphics routines to synthesize intermediate views <ref> [2] </ref>. However, the construction of a 3D model may be an unnecessary and time-consuming step if the ultimate goal is only the intermediate view.
References-found: 2

