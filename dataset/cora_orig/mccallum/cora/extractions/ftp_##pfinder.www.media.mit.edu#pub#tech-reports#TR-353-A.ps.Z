URL: ftp://pfinder.www.media.mit.edu/pub/tech-reports/TR-353-A.ps.Z
Refering-URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-353-ABSTRACT.html
Root-URL: http://www.media.mit.edu
Title: Pfinder: Real-Time Tracking of the Human Body  
Author: by Christopher R. Wren Alex P. Pentland 
Degree: Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Masters of Science in Electrical Engineering and Computer Science at the  All rights reserved. Author  Certified by  Associate Professor Thesis Supervisor Accepted by Frederic R. Morgenthaler Chairman, Department Committee on Graduate Students  
Date: September 1996  August 1, 1996  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY  c Massachusetts Institute of Technology 1996.  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <editor> ACM. Mandala: </editor> <title> Virtual Village, </title> <booktitle> ACM SIGGraph, Computer Graphics Visual Proceedings, </booktitle> <year> 1993. </year>
Reference-contexts: More recently the Mandala group <ref> [1] </ref>, has commercialized and improved this technology by using analog chromakey video processing to isolate colored gloves, etc., worn by users. In both cases, most of the focus is on improving the graphics interaction, with the visual input processing being at most a secondary concern.
Reference: [2] <author> A. Azarbayejani and A.P. Pentland. </author> <title> Recursive estimation of motion, structure, and focal length. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 17(6) </volume> <pages> 562-575, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Pfinder is a more general, and more accurate, method for person segmentation, tracking, and interpretation. 1.1 Related Work Pfinder is descended from a variety of interesting experiments in human-computer interface and computer mediated communication. Initial exploration into this space 1 Use of existing image-to-image registration techniques <ref> [2, 13] </ref> allow Pfinder to function in the presence of camera rotation and zoom, but real-time performance cannot be achieved without special purpose hardware 9 of applications was by Krueger [11], who showed that even 2-D binary vision pro-cessing of the human form can be used as an interesting interface. <p> This makes processing very efficient. In order to accommodate camera rotation and zooming, the input image must be transformed back to the coordinate system of the scene texture model before we compare the input image and scene model. Although we can estimate the camera transform parameters in real time <ref> [2, 13] </ref>, we cannot currently apply the transform to the input image in real time. 3.2 Detect Person After the scene has been modeled, Pfinder watches for large deviations from this model.
Reference: [3] <author> Ali Azarbayejani and Alex Pentland. </author> <title> Real-time self-calibrating stereo person tracking using 3-D shape estimation from blob features. </title> <booktitle> In Proceedings of 13th ICPR, </booktitle> <address> Vienna, Austria, August 1996. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: In this context 26 the tracking information becomes useful for understanding simple pointing gestures. With quite a bit more work, systems can use this information to estimate a more complete picture of the user's configuration. Azarbayejani and Pentland <ref> [3] </ref> are currently building a system which combines Pfinder-based monocular tracking systems into a wide-baseline stereo system called the STereo Interactive Virtual Environment (STIVE). STIVE is capable of resolving 3-D position and orientation from the given 2-D position and orientation tracking.
Reference: [4] <author> A. Baumberg and D. Hogg. </author> <title> An efficient method for contour tracking using active shape models. </title> <booktitle> In Proceeding of the Workshop on Motion of Nonrigid and Articulated Objects. IEEE Computer Society, </booktitle> <year> 1994. </year>
Reference-contexts: In addition, despite some efforts to handle occlusion, currently such models cannot reliably deal with large occlusions. Finally, such approaches require relatively massive computational resources to run in real-time. Pfinder is perhaps most closely related to the work of Bichsel [5] and Baumberg and Hogg <ref> [4] </ref>. These systems segmented the person from the background in real time using only a standard workstation. Their limitation is that they did not analyze the person's shape or internal features, but only the silhouette of the person.
Reference: [5] <author> Martin Bichsel. </author> <title> Segmenting simply connected moving objects in a static scene. </title> <journal> Pattern Analysis and Machine Intelligence, </journal> <volume> 16(11) </volume> <pages> 1138-1142, </pages> <month> Nov </month> <year> 1994. </year>
Reference-contexts: In addition, despite some efforts to handle occlusion, currently such models cannot reliably deal with large occlusions. Finally, such approaches require relatively massive computational resources to run in real-time. Pfinder is perhaps most closely related to the work of Bichsel <ref> [5] </ref> and Baumberg and Hogg [4]. These systems segmented the person from the background in real time using only a standard workstation. Their limitation is that they did not analyze the person's shape or internal features, but only the silhouette of the person.
Reference: [6] <author> Trevor Darrell, Bruce Blumberg, Sharon Daniel, Brad Rhodes, Pattie Maes, and Alex Pentland. </author> <title> Alive: Dreams and illusions. </title> <booktitle> In ACM SIGGraph, Computer Graphics Visual Proceedings, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Pfinder has been used as a real-time interface device for information spaces [19], performance spaces [22], video games [18], and a distributed virtual reality populated by artificial life <ref> [6] </ref>. It has also been used as a pre-processor for gesture recognition systems, including one that can recognize a forty-word subset of American Sign Language with near perfect accuracy [20]. <p> Each blob can also have a detailed representation of its shape and appearance, modeled as differences from the underlying blob statistics. The ability to efficiently compute compact representations of people's appearance is useful for low-bandwidth applications, such as our demonstration of a shared virtual environments at SIG-GRAPH '95 <ref> [6] </ref>. The statistics of each blob are recursively updated to combine information contained in the most recent measurements with knowledge contained in the current class statistics and the priors.
Reference: [7] <author> Trevor Darrell, Pattie Maes, Bruce Blumberg, and Alex Pentland. </author> <title> A novel environment for situated vision and behavior. </title> <booktitle> In Proc. of CVPR-94 Workshop for Visual Behaviors, </booktitle> <pages> pages 68-72, </pages> <address> Seattle, Washington, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: The central tracking and description algorithms, however, can equally well be applied to tracking vehicles or animals, and in fact we have done informal experiments in these areas. Pfinder is a descendant of the vision routines originally developed for the ALIVE system <ref> [7] </ref>, which performed person tracking but had no explicit model of the person and required a controlled background. <p> The geometry of these protrusions is then analyzed using statistically-derived rules to determine which protrusion is the head, which the hands, and so forth <ref> [10, 7] </ref>.
Reference: [8] <author> D. M. Gavrila and L. S. Davis. </author> <title> Towards 3-d model-based tracking and recognition of human movement: a multi-view approach. </title> <booktitle> In International Workshop on Automatic Face- and Gesture-Recognition. IEEE Computer Society, 1995. </booktitle> <address> Zurich. </address>
Reference-contexts: Pfinder goes well beyond these systems by providing a detailed level of analysis impossible with primitive binary vision. Pfinder is also related to body-tracking projects like those by Rehg and Kanade [16], Rohr [17], and Gavrila and Davis <ref> [8] </ref> that use kinematic models, or those by Pentland and Horowitz [15] and Metaxas and Terzopolous [14] that use dynamic models. Such models, however, require reasonably accurate initialization, a currently unsolved problem. In addition, despite some efforts to handle occlusion, currently such models cannot reliably deal with large occlusions.
Reference: [9] <author> Paul S. Heckbert. </author> <title> A seed fill algorithm. </title> <editor> In Andrew S. Glassner, editor, </editor> <booktitle> Graphics Gems, chapter 4, </booktitle> <pages> pages 275-277. </pages> <publisher> Academic Press Professional, </publisher> <year> 1990. </year>
Reference-contexts: By starting at model-determined seed points and expanding analysis outward, Pfinder identifies all the pixels the belong to a single connected region (given the assumption that people are connected). The algorithm for the grow is the familiar "brush fire" algorithm from computer graphics work <ref> [9] </ref>.
Reference: [10] <author> Michael Johnson, Trevor Darrell, and Pattie Maes. </author> <title> Evolving visual routines. </title> <journal> Artificial Life, </journal> <volume> 1(4), </volume> <year> 1994. </year>
Reference-contexts: The geometry of these protrusions is then analyzed using statistically-derived rules to determine which protrusion is the head, which the hands, and so forth <ref> [10, 7] </ref>.
Reference: [11] <author> M. W. Krueger. </author> <title> Artificial Reality II. </title> <publisher> Addison Wesley, </publisher> <year> 1990. </year> <month> 39 </month>
Reference-contexts: Initial exploration into this space 1 Use of existing image-to-image registration techniques [2, 13] allow Pfinder to function in the presence of camera rotation and zoom, but real-time performance cannot be achieved without special purpose hardware 9 of applications was by Krueger <ref> [11] </ref>, who showed that even 2-D binary vision pro-cessing of the human form can be used as an interesting interface. More recently the Mandala group [1], has commercialized and improved this technology by using analog chromakey video processing to isolate colored gloves, etc., worn by users.
Reference: [12] <author> Pattie Maes, Bruce Blumberg, Trevor Darrell, and Alex Pentland. </author> <title> The alive sys-tem: Full-body interaction with animated autonomous agents. </title> <journal> ACM Multimedia Systems, </journal> <volume> 5 </volume> <pages> 105-112, </pages> <year> 1997. </year>
Reference-contexts: Clever mapping design can thus greatly reduce the need for sensor systems to perform flawlessly by playing off the expectations and socialization of the user. Because of that trait, this was the first system to be implemented in our lab (by Maes, Darrell, Blumberg, and Pentland <ref> [12] </ref>), in the form of the Artificial Life Interactive Virtual Environment (ALIVE). ALIVE combines autonomous agents with an interactive space. The user experiences the agents (including hamster-like creatures, a puppet, and a well-mannered dog|Figure 5-6) through a "magic-mirror" idiom.
Reference: [13] <author> S. Mann and R. W. </author> <title> Picard. Video orbits: characterizing the coordinate transformation between two images using the projective group. </title> <editor> IEEE T. </editor> <booktitle> Image Proc., </booktitle> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: Pfinder is a more general, and more accurate, method for person segmentation, tracking, and interpretation. 1.1 Related Work Pfinder is descended from a variety of interesting experiments in human-computer interface and computer mediated communication. Initial exploration into this space 1 Use of existing image-to-image registration techniques <ref> [2, 13] </ref> allow Pfinder to function in the presence of camera rotation and zoom, but real-time performance cannot be achieved without special purpose hardware 9 of applications was by Krueger [11], who showed that even 2-D binary vision pro-cessing of the human form can be used as an interesting interface. <p> This makes processing very efficient. In order to accommodate camera rotation and zooming, the input image must be transformed back to the coordinate system of the scene texture model before we compare the input image and scene model. Although we can estimate the camera transform parameters in real time <ref> [2, 13] </ref>, we cannot currently apply the transform to the input image in real time. 3.2 Detect Person After the scene has been modeled, Pfinder watches for large deviations from this model.
Reference: [14] <author> D. Metaxas and D. Terzopoulos. </author> <title> Shape and non-rigid motion estimation through physics-based synthesis. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 15 </volume> <pages> 580-591, </pages> <year> 1993. </year>
Reference-contexts: Pfinder is also related to body-tracking projects like those by Rehg and Kanade [16], Rohr [17], and Gavrila and Davis [8] that use kinematic models, or those by Pentland and Horowitz [15] and Metaxas and Terzopolous <ref> [14] </ref> that use dynamic models. Such models, however, require reasonably accurate initialization, a currently unsolved problem. In addition, despite some efforts to handle occlusion, currently such models cannot reliably deal with large occlusions. Finally, such approaches require relatively massive computational resources to run in real-time.
Reference: [15] <author> A. Pentland and B. Horowitz. </author> <title> Recovery of nonrigid motion and structure. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 13(7) </volume> <pages> 730-742, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Pfinder goes well beyond these systems by providing a detailed level of analysis impossible with primitive binary vision. Pfinder is also related to body-tracking projects like those by Rehg and Kanade [16], Rohr [17], and Gavrila and Davis [8] that use kinematic models, or those by Pentland and Horowitz <ref> [15] </ref> and Metaxas and Terzopolous [14] that use dynamic models. Such models, however, require reasonably accurate initialization, a currently unsolved problem. In addition, despite some efforts to handle occlusion, currently such models cannot reliably deal with large occlusions. Finally, such approaches require relatively massive computational resources to run in real-time.
Reference: [16] <author> J.M. Rehg and T. Kanade. </author> <title> Visual tracking of high dof articulated structures: An application to human hand tracking. </title> <booktitle> In European Conference on Computer Vision, </booktitle> <pages> pages B:35-46, </pages> <year> 1994. </year>
Reference-contexts: Pfinder goes well beyond these systems by providing a detailed level of analysis impossible with primitive binary vision. Pfinder is also related to body-tracking projects like those by Rehg and Kanade <ref> [16] </ref>, Rohr [17], and Gavrila and Davis [8] that use kinematic models, or those by Pentland and Horowitz [15] and Metaxas and Terzopolous [14] that use dynamic models. Such models, however, require reasonably accurate initialization, a currently unsolved problem.
Reference: [17] <author> K. Rohr. </author> <title> Towards model-based recognition of human movements in image sequences. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 59(1) </volume> <pages> 94-115, </pages> <month> Jan </month> <year> 1994. </year>
Reference-contexts: Pfinder goes well beyond these systems by providing a detailed level of analysis impossible with primitive binary vision. Pfinder is also related to body-tracking projects like those by Rehg and Kanade [16], Rohr <ref> [17] </ref>, and Gavrila and Davis [8] that use kinematic models, or those by Pentland and Horowitz [15] and Metaxas and Terzopolous [14] that use dynamic models. Such models, however, require reasonably accurate initialization, a currently unsolved problem.
Reference: [18] <author> Kenneth Russell, Thad Starner, and Alex Pentland. </author> <title> Unencumbered virtual environments. </title> <booktitle> In IJCAI-95 Workshop on Entertainment and AI/Alife, </booktitle> <year> 1995. </year>
Reference-contexts: The system provides interactive performance on general-purpose hardware, and has been tested on thousands of people in several installations around the world, and has performed quite reliably. Pfinder has been used as a real-time interface device for information spaces [19], performance spaces [22], video games <ref> [18] </ref>, and a distributed virtual reality populated by artificial life [6]. It has also been used as a pre-processor for gesture recognition systems, including one that can recognize a forty-word subset of American Sign Language with near perfect accuracy [20]. <p> Usually a small amount of filtering will be required, and possibly it's desirable to use non-linear mappings, but otherwise interface outputs feed directly into application inputs. Russell and Starner <ref> [18] </ref> created an application called SURVIVE (Simulated Urban Recreational Violence Interactive Virtual Environment), an entertainment application 25 (a) that uses a direct mapping. SURVIVE allows the user to interact with a 3D game environment using the IVE space. Figure 5-1 shows a user in SURVIVE.
Reference: [19] <author> Flavia Sparacino, Christopher Wren, Alex Pentland, and Glorianna Davenport. Hyperplex: </author> <title> a world of 3d interactive digital movies. </title> <booktitle> In IJCAI-95 Workshop on Entertainment and AI/Alife, </booktitle> <year> 1995. </year>
Reference-contexts: The system provides interactive performance on general-purpose hardware, and has been tested on thousands of people in several installations around the world, and has performed quite reliably. Pfinder has been used as a real-time interface device for information spaces <ref> [19] </ref>, performance spaces [22], video games [18], and a distributed virtual reality populated by artificial life [6]. It has also been used as a pre-processor for gesture recognition systems, including one that can recognize a forty-word subset of American Sign Language with near perfect accuracy [20].
Reference: [20] <author> Thad Starner and Alex Pentland. </author> <title> Real-time american sign language recognition from video using hidden markov models. </title> <booktitle> In Proceedings of International Symposium on Computer Vision, Coral Gables, </booktitle> <address> FL, USA, 1995. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: It has also been used as a pre-processor for gesture recognition systems, including one that can recognize a forty-word subset of American Sign Language with near perfect accuracy <ref> [20] </ref>. Pfinder adopts a Maximum A Posteriori Probability (MAP) approach to detection and tracking of the human body using simple 2 1 2 -D models. It incorporates a priori knowledge about people primarily to bootstrap itself and to recover from errors. <p> This gives the user a sense the URLs existing in a surrounding 3D environment. To navigate this virtual 3D environment, users stand in front of the screen and use voice and hand gestures to explore (Figure 5-3). 5.4 American Sign Language Starner and Pentland <ref> [20] </ref> explored the extremes of gesture-based mapping by combining th pfinder statistics representation with hidden Markov modeling to interpret a forty word subset of American Sign Language (ASL). Using this approach they were able to produce a real-time ASL interpreter with a 99% sign recognition accuracy.
Reference: [21] <author> Charles W. Therrien. </author> <title> Decision, Estimation, and Classification. </title> <publisher> John Wiley and Sons, Inc., </publisher> <year> 1989. </year>
Reference-contexts: The process of transforming feature vectors into classification tags is a richly studied topic known as pattern recognition. A brief description of the main ideas used by Pfinder follows, but a very thorough discussion of this material can be found in Therrien <ref> [21] </ref>. Video chroma-key segmentation is an instructive place to start. Chroma-keying is the process of identifying pixels in an image sequence that are of a particular color, usually for the purpose of compositing two video signals. The classes for chroma-keying are foreground and background.
Reference: [22] <author> C. Wren, F. Sparacino, A. Azarbayejani, T. Darrell, T. Starner, Kotani A, C. Chao, M. Hlavac, K. Russell, and Pentland A. </author> <title> Perceptive spaces for pe-formance and entertainment: Untethered interaction using computer vision and audition. </title> <journal> Applied Artificial Intelligence, </journal> <volume> 11(4) </volume> <pages> 267-284, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: The system provides interactive performance on general-purpose hardware, and has been tested on thousands of people in several installations around the world, and has performed quite reliably. Pfinder has been used as a real-time interface device for information spaces [19], performance spaces <ref> [22] </ref>, video games [18], and a distributed virtual reality populated by artificial life [6]. It has also been used as a pre-processor for gesture recognition systems, including one that can recognize a forty-word subset of American Sign Language with near perfect accuracy [20]. <p> Systems that employ this kind of mapping must have very flexible, and quick, mechanisms for resolving misunderstandings. See Sections 5.5 and 5.6, for interesting answers to this problem. Sparacino and Hlavac's <ref> [22] </ref> Netspace is an example of an application that uses a gesture-based mapping. NetSpace is an immersive, interactive web browser that makes use of people's strength at remembering the surrounding 3D spatial layout. <p> Thad Starner is shown using this system in Fig. 5-4. 5.5 DanceSpace (a) (b) generated by the user in DanceSpace Closely related to the gesture-based interface mapping discussed in Section 5.3, the conductor-style interface mapping of Sparacino's <ref> [22] </ref> DanceSpace also uses a form 28 of predefined gesture language. Unlike the rigid gesture-language of NetSpace the conductor mapping results in a much more fluid interface. The system is designed to produce constructive, interesting results the user doesn't know the details of the mapping.
Reference: [23] <author> Christopher Wren, Ali Azarbayejani, Trevor Darrell, and Alex Pentland. Pfinder: </author> <title> Real-time tracking of the human body. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 19(7) </volume> <pages> 780-785, </pages> <month> July </month> <year> 1997. </year> <month> 40 </month>
Reference-contexts: Wren and Pentland <ref> [23] </ref> have begun work on a system that utilizes dynamic and stochastic components to explicitly model the human body. The first version of the system assumed a 2-D dynamic model of the user.
References-found: 23

