URL: http://www.cs.columbia.edu/~hgs/InternetTC/GlobalInternet96/Wang9611:Prefetching.ps.gz
Refering-URL: http://gaia.cs.umass.edu:80/tccc/internet96/schedule.html
Root-URL: 
Title: Prefetching in World Wide Web  
Author: Zheng Wang Jon Crowcroft 
Address: London WC1E 6BT, United Kingdom  
Affiliation: Department of Computer Science, University College London  
Abstract: This paper considers the use of prefetching in WWW for reducing perceived latency. We first look at a number of basic issues and tradeoff in prefetching. Our analysis shows that, unless the traffic is very light or the prefetching efficiency is very high, statistical prefetching may not necessarily reduce perceived delay. We then present an implementation of deterministic prefetching in a hotlist manager. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jeffrey Mogul, </author> <booktitle> The Case for Persistent-Connection HTTP, in Proceedings of ACM SIGCOMM'95, </booktitle> <month> Oct </month> <year> 1995. </year>
Reference-contexts: In current HTTP implementation, each object in a Web page requires a new TCP connection, hence at least 2 RTTs. The new persistent HTTP can reuse TCP connections so it requires only one TCP setup for each interaction <ref> [1] </ref>. The latency experienced by users varies considerably depending on the bandwidth available, the propagation delay to the server, the size of the Web page and the server load.
Reference: [2] <author> Carlos Cunha, Azer Bestavros, and Mark Crovella, </author> <title> Char--acteristics of WWW Client-based Traces, </title> <type> Technical Report TR-95-010, </type> <institution> Boston University, </institution> <address> Boston, MA 02215, </address> <month> April, </month> <year> 1995. </year>
Reference-contexts: To illustrate the delay Web users currently experience, we calculated the delay distribution with 79,430 samples from the client-based traces collected at Boston University during November 1994 to February 1995 <ref> [2] </ref>. Figure 1 shows the distribution of delay for retrieving an object from non-local servers (i.e., the servers other than the ones on users' LANs). For most objects, the retrieving time is between 0.4-4 seconds.
Reference: [3] <author> Azer Bestavros, </author> <title> Using speculation to reduce server load and service time on the WWW, in Proceedings of CIKM'95: </title> <booktitle> The Fourth ACM International Conference on Information and Knowledge Management, </booktitle> <address> Baltimore, Maryland, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: The information on access patterns may be derived from servers' access statistics or from clients' configuration. Recent studies on the WWW traffic show that there are considerable interdependencies among consecutive accesses to some Web pages <ref> [3] </ref>. Such results are not surprising. As WWW is a hypertext based information system, it is natural that many Web pages are closely linked together.
Reference: [4] <author> J.D. </author> <title> Touch and D.J. Farber, An Experiment in Latency Reduction, </title> <booktitle> in Proceedings of IEEE INFOCOM'94, </booktitle> <address> Toronto, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: There is a general tradeoff between bandwidth and latency here. As we reduce the threshold for statistical prefetching, the latency may improve, but at at the price of increased bandwidth consumption. A study on FTP shows that the latency can be reduced by 67% for 7-fold increase in bandwidth <ref> [4] </ref>. Unfortunately, bandwidth is still scarce resources in most networks, particularly over long distance paths. Thus, statistical prefetching has be used with great care to avoid any waste of bandwidth.
Reference: [5] <author> Tom Magliery, Briand Sanderson, </author> <title> Writing Web software through client APIs, </title> <booktitle> In the Tutorial Notes of 4th World Wide Web Conference, </booktitle> <address> Boston USA, </address> <month> Nov </month> <year> 1995 </year>
Reference-contexts: Although Coolist can prefetch most web pages directly by itself, it does not work with Web sites that require passwords, cookie or transparent redirection. In our implementation, Coolist uses client APIs <ref> [5] </ref> to control browsers to do prefetching. When Coolist needs to fetch a web page, it issues a client API command to the browser to open the web page specified.
Reference: [6] <author> Lynx, </author> <title> Lynx On-Line Documents, </title> <note> (http://ftp2.cc.ukans.edu/pub/lynx/), 1995. </note>
Reference-contexts: Invoking Netscape as: netscape -remote 'openURL (http://home.netscape.com /newsref/std/x-remote.html)' has the same effect on Netscape browsers. When doing batch prefetching, Coolist forks out a cron job with a line mode browser to fetch the web pages at specified time. In our implementation, we choose Lynx <ref> [6] </ref> (with the line mode option) since it is available on most Unix systems. Although prefetched pages can be cached in Coolist, we use the caching proxy as the store for prefetched pages.
References-found: 6

