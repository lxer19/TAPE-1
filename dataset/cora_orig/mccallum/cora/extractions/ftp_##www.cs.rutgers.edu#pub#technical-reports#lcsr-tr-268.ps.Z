URL: ftp://www.cs.rutgers.edu/pub/technical-reports/lcsr-tr-268.ps.Z
Refering-URL: http://www.cs.rutgers.edu/pub/technical-reports/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Active Object Recognition Integrating Attention and Viewpoint Control  
Author: Sven J. Dickinson Henrik I. Christensen John K. Tsotsos Goran Olofsson 
Address: New Brunswick, NJ 08903  DK-9220 Aalborg, Denmark  Toronto, 6 King's College Rd. Toronto, Ontario, Canada M5S 1A4  S-100 44 Stockholm, Sweden  
Affiliation: Department of Computer Science and Center for Cognitive Science Rutgers University  Laboratory of Image Analysis, IES Aalborg University  Department of Computer Science University of  Computational Vision and Active Perception Laboratory Dept. of Numerical Analysis and Computing Science Royal Institute of Technology,  
Abstract: We present an active object recognition strategy which combines the use of an attention mechanism for focusing the search for a 3-D object in a 2-D image, with a viewpoint control strategy for disambiguating recovered object features. The attention mechanism consists of a probabilistic search through a hierarchy of predicted feature observations, taking objects into a set of regions classified according to the shapes of their bounding contours. We motivate the use of image regions as a focus-feature and compare their uncertainty in inferring objects with the uncertainty of more commonly used features such as lines or corners. If the features recovered during the attention phase do not provide a unique mapping to the 3-D object being searched, the probabilistic feature hierarchy can be used to guide the camera to a new viewpoint from where the object can be disambiguated. The power of the underlying representation is its ability to unify these object recognition behaviors within a single framework. We present the approach in detail and evaluate its performance in the context of a project providing robotic aids for the disabled. fl To appear in Computer Vision and Image Understanding. An earlier, condensed version of this paper was presented at the 1994 European Conference on Computer Vision (ECCV), in Stockholm. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Bergevin and M. D. Levine. </author> <title> Generic object recognition: Building coarse 3D descriptions from line drawings. </title> <booktitle> In Proceedings, IEEE Workshop on Interpretation of 3D Scenes, </booktitle> <pages> pages 68-74, </pages> <address> Austin, TX, </address> <year> 1989. </year>
Reference-contexts: Since the introduction of Biederman's geons to the vision community, a number of other researchers have developed computational models for geon recovery resulting in a number of geon-based recognition systems (e.g., Dickinson et al. [8], Bergevin and Levine <ref> [1] </ref>, Hummel and Biederman [17], Munck-Fairwood [15], Jacot-Descombes and Pun [20], and Narayan and Jain [35]). However, unlike these approaches, which are typically applied to manually segmented line drawings, our approach is applied to real images and is not dependent on the choice of geons as modeling primitives.
Reference: [2] <author> I. Biederman. </author> <title> Human image understanding: Recent research and a theory. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 32 </volume> <pages> 29-73, </pages> <year> 1985. </year>
Reference-contexts: The attention mechanism not only provides initial placement in this graph, but is used in the process of verifying the visual events. 3 Review of the Object Representation 3.1 Object-Centered Modeling To demonstrate our approach to attention, we have selected an object representation similar to that used by Biederman <ref> [2] </ref>, in which the Cartesian product of contrastive shape properties gives rise to a set of volumetric primitives called geons.
Reference: [3] <author> K. Brunnstrom, T. Lindeberg, and J. Eklundh. </author> <title> Active detection and classification of junctions by foveation with a hand-eye system guided by the scale-space primal sketch. </title> <type> Technical Report ISRN KTH/NA/P-91/31-SE, </type> <institution> Computer Vision and Active Perception Laboratory (CVAP), Royal Institute of Technology, Stockholm, Sweden, </institution> <year> 1991. </year>
Reference-contexts: Stark et al. [38] used functional verification procedures in combination with relation specification for the selection of operators and the definition of attention regions; the reasoning is based on fuzzy logic for evidence combination. Brunnstrom, Lindeberg, and Eklundh <ref> [3] </ref> describe a foveation system in which blobs in a scale-space representation of the image are used to guide a foveation mechanism which recovers junction information. Although some heuristics were introduced to accommodate over-segmentation in OPTICA, lighting conditions had to be favorable for a successful interpretation to be generated [14].
Reference: [4] <author> Andrea Califano, Rick Kjeldsen, and Ruud M. Bolle. </author> <title> Data and model driven foviation. </title> <booktitle> In Proceedings, IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 1-7. </pages> <publisher> IEEE CS Press, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Furthermore, the approach focused more on scene context than on how a particular 3-D object may be viewed. Califano et al. <ref> [4] </ref> used a heuristic method for the selection of operators based on discriminative power; the attention region is defined in terms of the region of ambiguity. Kittler et al. [31] used a rule based method for the selection of operators to facilitate verification of objects based on 2-D information.
Reference: [5] <author> S. Culhane and J. Tsotsos. </author> <title> An attentional prototype for early vision. </title> <editor> In G. Sandini, editor, </editor> <booktitle> Second European Conference on Computer Vision, </booktitle> <volume> LNCS-Series Vol. 588, </volume> <pages> pages 551-560, </pages> <address> Santa Margherita Ligure, Italy, May 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: At the earlier end of visual processing, methods exist for the localization of salient image features. A biologically plausible scheme to solve the problem of selective visual attention appears in Tsotsos [42] and Culhane and Tsotsos <ref> [5, 6] </ref>. It proposes a method that solves the problem of locating and localizing items in the visual field and shows how to implement the idea of an inhibitory attention beam.
Reference: [6] <author> S. Culhane and J. Tsotsos. </author> <title> A prototype for data-driven visual attention. </title> <booktitle> In 11th ICPR, </booktitle> <pages> pages 36-40, </pages> <address> The Hague, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: At the earlier end of visual processing, methods exist for the localization of salient image features. A biologically plausible scheme to solve the problem of selective visual attention appears in Tsotsos [42] and Culhane and Tsotsos <ref> [5, 6] </ref>. It proposes a method that solves the problem of locating and localizing items in the visual field and shows how to implement the idea of an inhibitory attention beam.
Reference: [7] <author> S. Dickinson. </author> <title> The recovery and recognition of three-dimensional objects using part-based aspect matching. </title> <type> Technical Report CAR-TR-572, </type> <institution> Center for Automation Research, University of Maryland, </institution> <year> 1991. </year>
Reference-contexts: The ambiguous mappings between the levels of the aspect hierarchy were originally captured in a set of upward conditional probabilities (Dickinson et al. <ref> [7] </ref>), mapping boundary groups to faces, faces to aspects, and aspects to volumes. <p> For each view, we orthographically project the shape onto the image plane, and classify the view in terms of one of the aspects. 3 The resulting frequency distribution gives rise to a set of bottom-up (found in <ref> [7] </ref>) and top-down conditional probability matrices. 4 Preattentive Feature Extraction 4.1 A Case for Focusing on Regions Given the various levels of the augmented aspect hierarchy, the question arises: At which recovered features from the image do we focus our search for a particular object? Many CAD-based recognition systems (e.g., Lowe
Reference: [8] <author> S. Dickinson, I. Biederman, A. Pentland, J.-O. Eklundh, R. Bergevin, and R. Munck-Fairwood. </author> <title> The use of geons for generic 3-D object recognition. </title> <booktitle> In Proceedings, International Joint Conference on Artificial Intelligence (IJCAI), </booktitle> <pages> pages 1693-1699, </pages> <address> Chambery, France, </address> <month> August </month> <year> 1993. </year> <month> 30 </month>
Reference-contexts: Since the introduction of Biederman's geons to the vision community, a number of other researchers have developed computational models for geon recovery resulting in a number of geon-based recognition systems (e.g., Dickinson et al. <ref> [8] </ref>, Bergevin and Levine [1], Hummel and Biederman [17], Munck-Fairwood [15], Jacot-Descombes and Pun [20], and Narayan and Jain [35]).
Reference: [9] <author> S. Dickinson, P. Jasiobedzki, H. Christensen, and G. Olofsson. </author> <title> Qualitative tracking of 3-D objects using active contour networks. </title> <booktitle> In Proceedings, IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Seattle, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Our approach to qualitative object tracking, as shown in Figure 11, combines a symbolic tracker and an image tracker, which we briefly discuss below; details can be found in <ref> [9] </ref>. The symbolic tracker tracks movement from one node to another in the aspect prediction graph. For our viewpoint control strategy, we begin at the node in the APG representing the ambiguous view (current node). <p> To verify the target aspect (highlighted in the image), we invoked the attention mechanism and restricted it to those regions in the new image that intersect with those regions in the old image defining the ambiguous aspect. In future work, we will integrate the active contour tracker reported in <ref> [9] </ref>. In a second example, shown in Figure 16 (c), a cylinder is recovered in its second most likely aspect (common to volumes 1, 2, 3, 4, 5, and 10).
Reference: [10] <author> S. Dickinson and D. Metaxas. </author> <title> Integrating qualitative and quantitative shape recovery. </title> <journal> International Journal of Computer Vision, </journal> <volume> 13(3) </volume> <pages> 1-20, </pages> <year> 1994. </year>
Reference-contexts: Conversely, the aspects corresponding to two disconnected parts in 3-D may be topologically adjacent in 2-D. Absolute verification of a connection would require recovering the geometry and pose of the two parts, which we address in <ref> [10] </ref>. Given our connectivity constraint, a target volume should be chosen as the most discriminating volume among those that are connected in 3-D to a volume already verified. <p> Furthermore, less likely views of a volume often underconstrain an attempt to fit a quantitative shape model to the recovered qualitative shape (Dickinson and Metaxas <ref> [10] </ref>).
Reference: [11] <author> S. Dickinson and A. Pentland. </author> <title> A unified approach to the recognition of expected and unexpected geon-based objects. </title> <booktitle> In Proceedings, SPIE Applications of AI X: Machine Vision and Robotics, special session on "Recognition by Components", </booktitle> <address> Orlando, FL, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: OPTICA was first extended to the problem of top-down, expected object recognition, by using knowledge of the target object to focus the various search procedures inherent in OPTICA's unexpected object recognition paradigm (Dickinson and Pentland <ref> [11] </ref>). However, as a starting point, it still required complete aspect and volume coverings of the image. When dealing with noisy images of less constrained scenes, along with shadows and poor lighting, such coverings of the image are not only very costly, but overly ambitious.
Reference: [12] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> A representation for qualitative 3-D object recognition integrating object-centered and viewer-centered models. </title> <editor> In K. Leibovic, editor, </editor> <title> Vision: A Convergence of Disciplines. </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: For our investigation, we have chosen three properties including cross-section shape, axis shape, and cross-section size variation (Dickinson, Pentland, and Rosenfeld <ref> [12] </ref>). The cartesian product of the dichotomous and trichotomous values of these properties give rise to a set of ten volumes (a subset of Biederman's geons), modeled using Pentland's SuperSketch 3-D modeling tool [34], and illustrated in Figure 1. <p> To generate the conditional probabilities of the aspects given the shapes, we employ the following procedure, as described in <ref> [12] </ref>. We first model our 3-D volumetric primitives using the Supersketch modeling tool (Pentland [34]). Supersketch models each shape using a superquadric surface subject to stretching, bending, twisting, and tapering deformations.
Reference: [13] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> From volumes to views: An approach to 3-D object recognition. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 55(2) </volume> <pages> 130-154, </pages> <year> 1992. </year>
Reference-contexts: A system called OPTICA (Object recognition using Probabilistic Three-dimensional Interpretation of Component Aspects) was built to demonstrate the approach, and it was successfully applied to the problem of unexpected object recognition from real images (Dickinson, Pentland, and Rosenfeld <ref> [13] </ref>). A major limitation of the approach was both its dependency on a complete and consistent covering of the image regions in terms of a set of aspects, and its assumption that all objects visible in the image are made up of the chosen volumes.
Reference: [14] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> 3-D shape recovery using distributed aspect matching. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(2) </volume> <pages> 174-198, </pages> <year> 1992. </year>
Reference-contexts: the system as they apply to the domain of object recognition for robotics aids for the disabled. 2 Related Work In previous work, we presented a bottom-up approach to the recovery and recognition of objects composed of qualitative 3-D volumetric parts from a single 2-D image (Dickinson, Pentland, and Rosenfeld <ref> [14] </ref>). The approach is based on a hybrid object representation in which objects are composed of a set of chosen 3-D object-centered volumetric parts; the parts, in turn, are mapped to a set of 2-D viewer-centered aspects. <p> Although some heuristics were introduced to accommodate over-segmentation in OPTICA, lighting conditions had to be favorable for a successful interpretation to be generated <ref> [14] </ref>. Furthermore, there was no support for viewpoint control to offset the effects of poor region segmentation or ambiguous views of the object. <p> Recognition is the process by which we move from a matched target face node in the search tree back up to an object. Once we have a matched face leaf node, our next step is to verify its parent (target) aspect <ref> [14] </ref>. This entails searching the vicinity of the target face for faces whose labels and configuration match the target aspect using an interpretation tree search (Grimson and Lozano-Perez [16]). <p> Furthermore, a specification of how the parts are attached in 3-D can be mapped to a specification as to which regions in their respective aspects are adjacent in 2-D <ref> [14] </ref>. Note that this constraint is simply a heuristic used in our search. Due to occlusion, the aspects corresponding to two two parts connected in 3-D may not be topologically adjacent in 2-D. Conversely, the aspects corresponding to two disconnected parts in 3-D may be topologically adjacent in 2-D. <p> Since the score of the recovered aspect falls far short, the verification fails, and it is concluded that the highlighted object is not a block. At this point, two options are available. The bottom-up shape recovery strategy, as outlined in <ref> [14] </ref>, can be applied to both frames, with the added constraint that the recovered aspect in the two frames must be consistent with a single volume.
Reference: [15] <author> R. Fairwood. </author> <title> Recognition of generic components using logic-program relations of image contours. </title> <journal> Image and Vision Computing, </journal> <volume> 9(2) </volume> <pages> 113-122, </pages> <year> 1991. </year>
Reference-contexts: Since the introduction of Biederman's geons to the vision community, a number of other researchers have developed computational models for geon recovery resulting in a number of geon-based recognition systems (e.g., Dickinson et al. [8], Bergevin and Levine [1], Hummel and Biederman [17], Munck-Fairwood <ref> [15] </ref>, Jacot-Descombes and Pun [20], and Narayan and Jain [35]). However, unlike these approaches, which are typically applied to manually segmented line drawings, our approach is applied to real images and is not dependent on the choice of geons as modeling primitives.
Reference: [16] <author> W. Grimson and T. Lozano-Perez. </author> <title> Model-based recognition and localization from sparse range or tactile data. </title> <journal> International Journal of Robotics Research, </journal> <volume> 3(3) </volume> <pages> 3-35, </pages> <year> 1984. </year>
Reference-contexts: The classification of an image region consists of matching its region boundary graph to those graphs representing the faces in the augmented aspect hierarchy using an interpretation tree search (Grimson and Lozano-Perez <ref> [16] </ref>). If there is an exact match, as shown in Figure 4, then we immediately generate a face hypothesis for that image region, identifying the label of the face. <p> Once we have a matched face leaf node, our next step is to verify its parent (target) aspect [14]. This entails searching the vicinity of the target face for faces whose labels and configuration match the target aspect using an interpretation tree search (Grimson and Lozano-Perez <ref> [16] </ref>).
Reference: [17] <author> J. Hummel and I. Biederman. </author> <title> Dynamic binding in a neural net model for shape recognition. </title> <journal> Psychological Review, </journal> <volume> 99 </volume> <pages> 480-517, </pages> <year> 1992. </year>
Reference-contexts: Since the introduction of Biederman's geons to the vision community, a number of other researchers have developed computational models for geon recovery resulting in a number of geon-based recognition systems (e.g., Dickinson et al. [8], Bergevin and Levine [1], Hummel and Biederman <ref> [17] </ref>, Munck-Fairwood [15], Jacot-Descombes and Pun [20], and Narayan and Jain [35]). However, unlike these approaches, which are typically applied to manually segmented line drawings, our approach is applied to real images and is not dependent on the choice of geons as modeling primitives.
Reference: [18] <author> S. Hutchinson and A. Kak. </author> <title> Planning sensing strategies in a robot work cell with multi-sensor capabilities. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 5(6) </volume> <pages> 765-783, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: With viewpoint control, they effectively reduce the 3-D recognition problem to a 2-D recognition problem. Hutchinson and Kak <ref> [18] </ref> describe a system for disambiguating objects recovered from range images. Based on a set of current hypotheses about the identity and position of an object, they evaluate candidate sensing operations with regard to their effectiveness in minimizing ambiguity.
Reference: [19] <author> D. Huttenlocher and S. Ullman. </author> <title> Recognizing solid objects by alignment with an image. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5(2) </volume> <pages> 195-212, </pages> <year> 1990. </year>
Reference-contexts: If the recovered features are common to every object being searched, they offer little in the way of focusing the search for an object. This is typical in object recognition systems which match simple image features like corners or zeroes of curvature to model features <ref> [30, 19, 39, 26] </ref>. Although invariant to viewpoint, there may be an abundance of such features in the image, leading to a combinatorial explosion in the number of possible correspondences between image and model features that must be verified. <p> matrices. 4 Preattentive Feature Extraction 4.1 A Case for Focusing on Regions Given the various levels of the augmented aspect hierarchy, the question arises: At which recovered features from the image do we focus our search for a particular object? Many CAD-based recognition systems (e.g., Lowe [30], Huttenlocher and Ullman <ref> [19] </ref>, Thompson and Mundy [39], and Lamdan, Schwartz and Wolfson [26]) advocate extracting simple features like corners, high curvature points, or zeroes of curvature. Although robustly recoverable from the image, there may be many such features in the image offering marginal utility for directing a search.
Reference: [20] <author> A. Jacot-Descombes and T. Pun. </author> <title> A probabilistic approach to 3-D inference of geons from a 2-D view. </title> <booktitle> In Proceedings, SPIE Applications of Artificial Intelligence X: Machine Vision and Robotics, </booktitle> <pages> pages 579-588, </pages> <address> Orlando, FL, </address> <year> 1992. </year>
Reference-contexts: Since the introduction of Biederman's geons to the vision community, a number of other researchers have developed computational models for geon recovery resulting in a number of geon-based recognition systems (e.g., Dickinson et al. [8], Bergevin and Levine [1], Hummel and Biederman [17], Munck-Fairwood [15], Jacot-Descombes and Pun <ref> [20] </ref>, and Narayan and Jain [35]). However, unlike these approaches, which are typically applied to manually segmented line drawings, our approach is applied to real images and is not dependent on the choice of geons as modeling primitives.
Reference: [21] <author> F. Jensen, H. Christensen, and J. Nielsen. </author> <title> Baysian methods for interpretation and control in multiagent vision systems. </title> <editor> In K. Bowyer, editor, </editor> <booktitle> SPIE Applications of AI X: Machine Vision and Robotics, </booktitle> <volume> volume 1708, </volume> <pages> pages 536-548, </pages> <address> Orlando, FL, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: The approach is thus centered around the use of a Bayesian approach to integration and control. Similar techniques have also been reported by Rimey and Brown [36], and Jensen et al. <ref> [21] </ref>, where both regions of interest and feature detectors are selected according to utility/cost strategies.
Reference: [22] <author> M. Kass, A. Witkin, and D. Terzopolous. Snakes: </author> <title> Active contour models. </title> <journal> Internation Journal of Computer Vision, </journal> <volume> 1(4) </volume> <pages> 321-331, </pages> <year> 1988. </year>
Reference-contexts: The image tracker employs a representation called an adaptive adjacency graph, or AAG. The AAG is initially created from the recovered (ambiguous) aspect, and consists of a network of active contours (snakes) <ref> [22] </ref>. In addition, the AAG encodes the topology of the network's regions, as defined by minimal cycles of contours. Contours in the AAG can deform subject to both internal and external (image) forces while retaining their connectivity at nodes.
Reference: [23] <author> H.-S. Kim, R. Jain, and R. Volz. </author> <title> Object recognition using multiple views. </title> <booktitle> In Proceedings, IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 28-33, </pages> <address> St. Louis, MO, </address> <month> March </month> <year> 1985. </year> <month> 31 </month>
Reference-contexts: Maver and Bajcsy [32] describe an approach to choosing the next view in order to resolve occluded regions in a range image. Based on height information at the polygonally-approximated border of an occluded region, a sequence of views is planned. Kim, Jain, and Volz <ref> [23] </ref> explore an approach which determines both optimal camera distance from the object as well as viewing direction.
Reference: [24] <author> C. Koch and S. Ullman. </author> <title> Shifts in selective visual attention. </title> <journal> Human Neurobiology, </journal> <volume> 4 </volume> <pages> 219-227, </pages> <year> 1985. </year>
Reference-contexts: It proposes a method that solves the problem of locating and localizing items in the visual field and shows how to implement the idea of an inhibitory attention beam. The scheme is based on the foundation laid by Koch and Ullman <ref> [24] </ref>, but incorporates several novel changes and additions which permit a proof of convergence with constant 3 time convergence properties. Furthermore, it addresses the issue of saliency maps and the binding across representations, and includes much tighter comparisons to biology.
Reference: [25] <author> J. Koenderink and A. van Doorn. </author> <title> The internal representation of solid shape with respect to vision. </title> <journal> Biological Cybernetics, </journal> <volume> 32 </volume> <pages> 211-216, </pages> <year> 1979. </year>
Reference-contexts: junction of two volumes involves exactly one distinct surface from each volume. 3.2 Viewer-Centered Modeling Traditional aspect graph representations of 3-D objects model an entire object with a set of aspects, each defining a topologically distinct view of an object in terms of its visible surfaces (Koenderink and van Doorn <ref> [25] </ref>). Our approach differs in that we use aspects to represent a (typically small) set of volumetric parts from which each object in our database is constructed, rather than representing an entire object directly. <p> To capture these relationships, we have constructed an aspect prediction graph for each of the ten volumes. The aspect prediction graph (APG) is derived from two sources. The first is a traditional aspect graph (Koenderink and van Doorn <ref> [25] </ref>) in which nodes represent topologically distinct views of an object and arcs specify transitions between the views. The APG is a more compact version of the aspect graph in which topologically equivalent nodes are grouped regardless of whether their faces map to different surfaces on the object.
Reference: [26] <author> Y. Lamdan, J. Schwartz, and H. Wolfson. </author> <title> On recognition of 3-D objects from 2-D images. </title> <booktitle> In Proceedings, IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1407-1413, </pages> <address> Philadelphia, PA, </address> <year> 1988. </year>
Reference-contexts: If the recovered features are common to every object being searched, they offer little in the way of focusing the search for an object. This is typical in object recognition systems which match simple image features like corners or zeroes of curvature to model features <ref> [30, 19, 39, 26] </ref>. Although invariant to viewpoint, there may be an abundance of such features in the image, leading to a combinatorial explosion in the number of possible correspondences between image and model features that must be verified. <p> on Regions Given the various levels of the augmented aspect hierarchy, the question arises: At which recovered features from the image do we focus our search for a particular object? Many CAD-based recognition systems (e.g., Lowe [30], Huttenlocher and Ullman [19], Thompson and Mundy [39], and Lamdan, Schwartz and Wolfson <ref> [26] </ref>) advocate extracting simple features like corners, high curvature points, or zeroes of curvature. Although robustly recoverable from the image, there may be many such features in the image offering marginal utility for directing a search.
Reference: [27] <author> J. Lee, R. Haralick, and L Shapiro. </author> <title> Morphologic edge detection. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-3(2):142-155, </volume> <year> 1987. </year>
Reference-contexts: In our implementation, we begin by applying Saint-Marc, Chen, and Medioni's edge-preserving adaptive smoothing filter to the image [37], followed by a morphological gradient operator (Lee et al. <ref> [27] </ref>). A hysteresis thresholding operation is then applied to produce a binary image from which a set of connected components is extracted. Edge regions are then thinned and assigned to neighboring regions, resulting in a region topology graph in which nodes represent regions and arcs specify region adjacencies.
Reference: [28] <author> T. Levitt, J. Agosta, and T. Binford. </author> <title> Model based influence diagrams for machine vision. </title> <editor> In M. Herion, R. Shacter, L. Kanal, and J. lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 5, volume 10 of Machine Intelligence and Pattern Recognition Series, </booktitle> <pages> pages 371-388. </pages> <publisher> North Holland, </publisher> <year> 1990. </year>
Reference-contexts: In selecting which recovered face to focus our attention on, we utilize a decision theoretic approach using a Bayesian framework. A similar approach was reported by Levitt et al. <ref> [28] </ref>, who use Bayesian networks for both model representation and description of recovered image features. Specifically, they use Bayesian networks for both data aggregation and selection of actions and feature detectors based on expected utility.
Reference: [29] <author> M. Li. </author> <title> Minimum description length based 2-D shape description. </title> <type> Technical Report CVAP114, </type> <institution> Computational Vision and Active Perception Lab, Royal Institute of Technology, Stockholm, Sweden, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: The steps of partitioning the bounding contour and classifying the resulting contours are performed simultaneously using a minimal description length algorithm due to Li <ref> [29] </ref>.
Reference: [30] <author> D. Lowe. </author> <title> Perceptual Organization and Visual Recognition. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Nor-well, MA, </address> <year> 1985. </year>
Reference-contexts: If the recovered features are common to every object being searched, they offer little in the way of focusing the search for an object. This is typical in object recognition systems which match simple image features like corners or zeroes of curvature to model features <ref> [30, 19, 39, 26] </ref>. Although invariant to viewpoint, there may be an abundance of such features in the image, leading to a combinatorial explosion in the number of possible correspondences between image and model features that must be verified. <p> and top-down conditional probability matrices. 4 Preattentive Feature Extraction 4.1 A Case for Focusing on Regions Given the various levels of the augmented aspect hierarchy, the question arises: At which recovered features from the image do we focus our search for a particular object? Many CAD-based recognition systems (e.g., Lowe <ref> [30] </ref>, Huttenlocher and Ullman [19], Thompson and Mundy [39], and Lamdan, Schwartz and Wolfson [26]) advocate extracting simple features like corners, high curvature points, or zeroes of curvature. Although robustly recoverable from the image, there may be many such features in the image offering marginal utility for directing a search. <p> By using simple region segmentation techniques whose complexity is comparable to common edge detection techniques, we can avoid the complexity of grouping lines into faces <ref> [30] </ref>. <p> Tracing the boundary of a region yields the bounding contour. In an edge-based approach, edges are extracted and grouped to form closed sets of contours. Inevitable gaps in the edges make the grouping process computationally complex, as was demonstrated by Lowe <ref> [30] </ref>. We avoid this grouping complexity by simply performing a connected component labeling of an edge image. If a gap exists in a line, 8 then the regions on either side of the line will get the same component label.
Reference: [31] <author> J. Matas, P. Remnagnino, J. Kittler, and J. Illingworth. </author> <title> Control of scene interpretation. </title> <editor> In J. Crowley and H. Christensen, editors, </editor> <title> Vision as Process. </title> <publisher> Springer-Verlag, </publisher> <month> January </month> <year> 1995. </year>
Reference-contexts: Califano et al. [4] used a heuristic method for the selection of operators based on discriminative power; the attention region is defined in terms of the region of ambiguity. Kittler et al. <ref> [31] </ref> used a rule based method for the selection of operators to facilitate verification of objects based on 2-D information. The method also includes the ability to define spatial attention regions based on temporal context.
Reference: [32] <author> J. Maver and R. </author> <title> Bajcsy. How to decide from the first view where to look next. </title> <booktitle> In Proceedings, DARPA Image Understanding Workshop, </booktitle> <pages> pages 482-496, </pages> <address> Pittsburgh, PA, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: Hutchinson and Kak [18] describe a system for disambiguating objects recovered from range images. Based on a set of current hypotheses about the identity and position of an object, they evaluate candidate sensing operations with regard to their effectiveness in minimizing ambiguity. Maver and Bajcsy <ref> [32] </ref> describe an approach to choosing the next view in order to resolve occluded regions in a range image. Based on height information at the polygonally-approximated border of an occluded region, a sequence of views is planned.
Reference: [33] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1987. </year>
Reference-contexts: To select a region of interest, i.e., attend to a particular face, the augmented aspect hierarchy may be considered as a Bayesian network, allowing us to utilize decision theory as described, for example, by Pearl <ref> [33] </ref>. To apply such a strategy, it is necessary to define both utility and cost measures.
Reference: [34] <author> A. Pentland. </author> <title> Perceptual organization and the representation of natural form. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 293-331, </pages> <year> 1986. </year>
Reference-contexts: The cartesian product of the dichotomous and trichotomous values of these properties give rise to a set of ten volumes (a subset of Biederman's geons), modeled using Pentland's SuperSketch 3-D modeling tool <ref> [34] </ref>, and illustrated in Figure 1. <p> To generate the conditional probabilities of the aspects given the shapes, we employ the following procedure, as described in [12]. We first model our 3-D volumetric primitives using the Supersketch modeling tool (Pentland <ref> [34] </ref>). Supersketch models each shape using a superquadric surface subject to stretching, bending, twisting, and tapering deformations.
Reference: [35] <author> N. Raja and A. Jain. </author> <title> Recognizing geons from superquadrics fitted to range data. </title> <journal> Image and Vision Computing, </journal> <volume> 10(3) </volume> <pages> 179-190, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: of Biederman's geons to the vision community, a number of other researchers have developed computational models for geon recovery resulting in a number of geon-based recognition systems (e.g., Dickinson et al. [8], Bergevin and Levine [1], Hummel and Biederman [17], Munck-Fairwood [15], Jacot-Descombes and Pun [20], and Narayan and Jain <ref> [35] </ref>). However, unlike these approaches, which are typically applied to manually segmented line drawings, our approach is applied to real images and is not dependent on the choice of geons as modeling primitives.
Reference: [36] <author> R. Rimey and C. Brown. </author> <title> Where to look next using a bayes net: Incorporating geometric relations. </title> <editor> In G. Sandini, editor, </editor> <booktitle> European Conference on Computer Vision (ECCV), volume 588 of Lecture Notes in Computer Science, </booktitle> <pages> pages 542-550. </pages> <publisher> Springer-Verlag, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: The present work has a similar flavor, but adds to the abstract framework a priori probability measures for 3-D object recognition. Several other researchers have addressed the problem of attention in the context of computer vision systems. Rimey and Brown <ref> [36] </ref> used Bayesian networks for selection of preprocessing modules and spatial attention regions, but the approach is based on explicit and accurate modeling of the domain. Furthermore, the approach focused more on scene context than on how a particular 3-D object may be viewed. <p> Specifically, they use Bayesian networks for both data aggregation and selection of actions and feature detectors based on expected utility. The approach is thus centered around the use of a Bayesian approach to integration and control. Similar techniques have also been reported by Rimey and Brown <ref> [36] </ref>, and Jensen et al. [21], where both regions of interest and feature detectors are selected according to utility/cost strategies.
Reference: [37] <author> P. Saint-Marc, J.-S. Chen, and G. Medioni. </author> <title> Adaptive smoothing: A general tool for early vision. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(6) </volume> <pages> 514-529, </pages> <year> 1991. </year>
Reference-contexts: The result is that there is significant region undersegmentation in the image, but the computational complexity is comparable to simple region-based approaches. In our implementation, we begin by applying Saint-Marc, Chen, and Medioni's edge-preserving adaptive smoothing filter to the image <ref> [37] </ref>, followed by a morphological gradient operator (Lee et al. [27]). A hysteresis thresholding operation is then applied to produce a binary image from which a set of connected components is extracted.
Reference: [38] <author> L. Stark and K. Bowyer. </author> <title> Achieving generalized object recognition through reasoning about association of function to structure. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(10) </volume> <pages> 1097-1104, </pages> <year> 1991. </year>
Reference-contexts: Kittler et al. [31] used a rule based method for the selection of operators to facilitate verification of objects based on 2-D information. The method also includes the ability to define spatial attention regions based on temporal context. Stark et al. <ref> [38] </ref> used functional verification procedures in combination with relation specification for the selection of operators and the definition of attention regions; the reasoning is based on fuzzy logic for evidence combination.
Reference: [39] <author> D. Thompson and J. Mundy. </author> <title> Model-directed object recognition on the connection machine. </title> <booktitle> In Proceedings, DARPA Image Understanding Workshop, </booktitle> <pages> pages 93-106, </pages> <address> Los Angeles, CA, </address> <year> 1987. </year> <month> 32 </month>
Reference-contexts: If the recovered features are common to every object being searched, they offer little in the way of focusing the search for an object. This is typical in object recognition systems which match simple image features like corners or zeroes of curvature to model features <ref> [30, 19, 39, 26] </ref>. Although invariant to viewpoint, there may be an abundance of such features in the image, leading to a combinatorial explosion in the number of possible correspondences between image and model features that must be verified. <p> Extraction 4.1 A Case for Focusing on Regions Given the various levels of the augmented aspect hierarchy, the question arises: At which recovered features from the image do we focus our search for a particular object? Many CAD-based recognition systems (e.g., Lowe [30], Huttenlocher and Ullman [19], Thompson and Mundy <ref> [39] </ref>, and Lamdan, Schwartz and Wolfson [26]) advocate extracting simple features like corners, high curvature points, or zeroes of curvature. Although robustly recoverable from the image, there may be many such features in the image offering marginal utility for directing a search.
Reference: [40] <author> J. Tsotsos. </author> <title> Representational axes and temporal cooperative processes. </title> <editor> In M. Arbib and A. Han--son, editors, </editor> <booktitle> Vision, Brain and Cooperative Computation, </booktitle> <pages> pages 361-418. </pages> <publisher> MIT Press / Bradford Books, </publisher> <year> 1987. </year>
Reference-contexts: The importance of incorporating attention mechanisms into an interpretation framework was argued by Tsotsos in <ref> [40] </ref>. There, both psychological as well as computational evidence was presented. In addition, a model for recognition was described and was applied by way of experimental example to a time-varying medical image domain. In the system of Tsotsos [40], attention was tied to the limiting of search for candidate interpretations. <p> incorporating attention mechanisms into an interpretation framework was argued by Tsotsos in <ref> [40] </ref>. There, both psychological as well as computational evidence was presented. In addition, a model for recognition was described and was applied by way of experimental example to a time-varying medical image domain. In the system of Tsotsos [40], attention was tied to the limiting of search for candidate interpretations. This relationship was subsequently formalized in [41]. A focus of attention during search is derived from the "best guesses" for the solution of the problem at hand. However, search in vision can take many forms. <p> Furthermore, it addresses the issue of saliency maps and the binding across representations, and includes much tighter comparisons to biology. Experiments show that luminance, edge, and motion fields (regions of common flow) can be used equally well as input representations. At the higher end of visual interpretation, Tsotsos <ref> [40] </ref> showed how to use a number of different organizational axes of a model database to limit search through a set of default heuristics. The present work has a similar flavor, but adds to the abstract framework a priori probability measures for 3-D object recognition.
Reference: [41] <author> J. Tsotsos. </author> <title> A complexity level analysis of vision. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 13(3) </volume> <pages> 423-455, </pages> <year> 1990. </year>
Reference-contexts: In addition, a model for recognition was described and was applied by way of experimental example to a time-varying medical image domain. In the system of Tsotsos [40], attention was tied to the limiting of search for candidate interpretations. This relationship was subsequently formalized in <ref> [41] </ref>. A focus of attention during search is derived from the "best guesses" for the solution of the problem at hand. However, search in vision can take many forms.
Reference: [42] <author> J. Tsotsos. </author> <title> An inhibitory beam for attentional selection. </title> <editor> In L. Harris and M. Jenkin, editors, </editor> <title> Spatial Vision in Humans and Robots. </title> <publisher> Cambridge University Press, </publisher> <year> 1993. </year>
Reference-contexts: At the earlier end of visual processing, methods exist for the localization of salient image features. A biologically plausible scheme to solve the problem of selective visual attention appears in Tsotsos <ref> [42] </ref> and Culhane and Tsotsos [5, 6]. It proposes a method that solves the problem of locating and localizing items in the visual field and shows how to implement the idea of an inhibitory attention beam.
Reference: [43] <author> J. Tsotsos, S. Dickinson, M. Jenkin, E. Milios, A. Jepson, B. Down, E. Amdur, S. Stevenson, M. Black, D. Metaxas, J. Cooperstock, S. Culhane, F. Nuflo, G. Verghese, W. Wai, D. Wilkes, and Y. Ye. </author> <title> The playbot project. </title> <booktitle> In Workshop on AI Applications for Disabled People (held in conjunction with the 14th International Joint Conference on Artificial Intelligence (IJCAI)), </booktitle> <address> Montreal, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: face foreshortening, then the image tracker will signal to the symbolic tracker that the event could not be verified. 7 Results We test the attention and viewpoint control strategies in the context of a multidisciplinary research effort exploring active vision in the domain of robotic aids for a disabled child <ref> [43] </ref>. Through a touch-screen interface, a child can instruct a mobile robot vision system to identify, localize, and manipulate 3-D objects in its environment. One of the ways the child can select an object for manipulation is through a set of object icons on the touch-screen.
Reference: [44] <author> D. Wilkes, S. Dickinson, and J. Tsotsos. </author> <title> A quantitative analysis of view degeneracy and its application to active focal length control. </title> <booktitle> In Proceedings, International Conference on Computer Vision, </booktitle> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: In fact, the likelihood is significant that some viewpoint degeneracy will occur (see Wilkes, Dickinson, and Tsotsos <ref> [44] </ref>). Unfortunately, in examining the conditional probabilities inherent in the augmented aspect hierarchy, we discover that less likely views of a volume may not be unique to that volume.
Reference: [45] <author> D. Wilkes and J. Tsotsos. </author> <title> Active object recognition. </title> <booktitle> In Proceedings, Computer Vision and Pattern Recognition '92, </booktitle> <address> Urbana, IL, </address> <month> June </month> <year> 1992. </year> <month> 33 </month>
Reference-contexts: Although some heuristics were introduced to accommodate over-segmentation in OPTICA, lighting conditions had to be favorable for a successful interpretation to be generated [14]. Furthermore, there was no support for viewpoint control to offset the effects of poor region segmentation or ambiguous views of the object. Wilkes and Tsotsos <ref> [45] </ref> offer a solution to polyhedral object recognition, whereby the camera is moved to a canonical viewpoint of the object based on maximizing the projected lengths of two non-parallel edges in the image. With viewpoint control, they effectively reduce the 3-D recognition problem to a 2-D recognition problem.
References-found: 45

