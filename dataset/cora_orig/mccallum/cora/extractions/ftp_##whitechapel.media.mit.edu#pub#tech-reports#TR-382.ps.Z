URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-382.ps.Z
Refering-URL: http://www.media.mit.edu/~szummer/
Root-URL: http://www.media.mit.edu
Email: picard@media.mit.edu,  
Title: Modeling user subjectivity in image libraries  
Author: Rosalind W. Picard, Thomas P. Minka, Martin Szummer 
Web: http://www.media.mit.edu/~picard/  
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: MIT Media Laboratory,  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 382 Also appearing: IEEE Int. Conf. on Image Proc., Lausanne, Sep. 1996. Abstract In addition to the problem of which image analysis models to use in digital libraries, e.g. wavelet, Wold, color histograms, is the problem of how to combine these models with their different strengths. Most present systems place the burden of combination on the user, e.g. the user specifies 50% texture features, 20% color features, etc. This is a problem since most users do not know how to best pick the settings for the given data and search problem. This paper addresses this problem, describing research in progress for a system that (1) automatically infers which combination of models best represents the data of interest to the user and (2) learns continuously during interaction with each user. In particular, these two components inference and learning provide a solution that adapts to the subjective and hard-to-predict behaviors frequently seen when people query or browse image libraries. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Furht, S. W. Smoliar, and H.-J. Zhang, </author> <title> Video and Image Processing in Multimedia Systems. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: 1 Introduction The earliest systems designed for image retrieval (see <ref> [1] </ref> for several descriptions) and those that have become commercially available, tend to follow a basic paradigm: (1) pre-compute features or model parameters for each image, (2) have the user specify which models or ranges of parameters are most important, and (3) have the user select example images to initiate a
Reference: [2] <author> J. Mao and A. K. Jain, </author> <title> "Texture classification and segmentation using multiresolution simultaneous autore-gressive models," </title> <booktitle> Patt. Rec., </booktitle> <volume> vol. 25, no. 2, </volume> <pages> pp. 173-188, </pages> <year> 1992. </year>
Reference-contexts: In the figure, User 1 gives two examples of textured, cubist paintings of different colors. The system infers that color is not relevant, and searches for images with similar texture (using a multiscale simultaneous autoregressive texture model from <ref> [2] </ref>). User 2 also gives two examples. The first image is identical to that of user 1, but the second has a different texture and the same color.
Reference: [3] <author> Y.-I. Ohta, T. Kanade, and T. Sakai, </author> <title> "Color information for region segmentation," Comp. Graph. </title> <journal> and Img. Proc., </journal> <volume> vol. 13, </volume> <pages> pp. 222-241, </pages> <year> 1980. </year>
Reference-contexts: In this case, the system determines that color is important and retrieves other images with similar colors (using Euclidean distances on 256-bucket color histograms from the decorrelating color space of <ref> [3] </ref>). The browser can also combine texture and color for one query, or choose combinations of other available similarity models. To refine the query results, the user simply gives additional examples. This is called "relevance feedback" in the information retrieval community.
Reference: [4] <author> T. P. Minka, </author> <title> "An image database browser that learns from user interaction," </title> <type> Master's thesis, </type> <institution> MIT, </institution> <address> Cambridge, MA, </address> <month> February </month> <year> 1996. </year> <institution> EECS. </institution>
Reference-contexts: Another model, or combination of models, might perform better still. With no claims of starting with the best models, but with evidence that combining suboptimal ones can outperform a single one <ref> [4] </ref>, we describe the following method for making combinations which can improve joint performance. We have explored many ways for combining models. Initially, we considered direct linear combinations of model features the traditional approach. <p> To date, the most successful combination method we have found (for avoiding the scaling and dimensionality problems, and for running in interactive time) is based on quantization of the feature spaces followed by a learning algorithm, such as set cover <ref> [4] </ref>. <p> Additional criteria can also be added depending on the domain, and performance can be improved by adding the ability to learn these criteria. (See <ref> [4] </ref> for details.) An example of using this method, starting with three models (and a database of only six elements) is shown in Fig. 2. The inference method presently acts on both positive and negative examples. <p> The current inference/combination method processes about 5 examples per CPU second on an HP 735/99 using a database with thousands of leaf elements and about a half dozen models. Details on its complexity are in <ref> [4] </ref>. <p> Having the right bias is crucial to successful learning, especially when a small number of examples (as desired in an interactive setting) leaves open many possible solutions. The "FourEyes" browser improves its bias over time <ref> [4] </ref>. When the system sees a problem similar to one it has seen before, it automatically switches to the bias that it learned for that problem. When it sees a significantly new problem, FourEyes learns a new bias. <p> This is also learned during interaction with the user. (See <ref> [4] </ref> for details.) We have applied a test of generalization to FourEyes, to evaluate how its learning mechanism performs on problems it hasn't seen before. <p> The other curves are the result of sequential training running on problem 1, then problem 2, etc. They tilt slightly downward to the right, indicating the presence of generalization. ization study are in <ref> [4] </ref>, which also contains additional evaluations. To summarize the results here, the curves above indicate that the time needed to learn decreases from left to right, showing that the learner gains performance on the later problems, even before having seen them.
Reference: [5] <author> R. O. Duda and P. E. Hart, </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley-Interscience, </publisher> <year> 1973. </year>
Reference-contexts: However, concatenating model features causes an exponential growth in the space used to represent the data, and has a variety of other problems, especially the problem when features from one model are of a different scale than features from another model, and simple re-scaling of them destroys their discrimination properties <ref> [5] </ref>. To date, the most successful combination method we have found (for avoiding the scaling and dimensionality problems, and for running in interactive time) is based on quantization of the feature spaces followed by a learning algorithm, such as set cover [4].
Reference: [6] <author> T. P. Minka and R. W. </author> <title> Picard, "Interactive learning using a `society of models'," </title> <journal> Pattern Recognition, </journal> <note> 1996. To appear. Also appears as MIT Media Lab Perceptual Computing TR#349. </note>
Reference: [7] <author> T. M. Mitchell, </author> <title> "The need for biases in learning generalizations," </title> <institution> Computer Science CBM-TR-117, Rutgers University, </institution> <address> New Brunswick, NJ, </address> <month> May </month> <year> 1980. </year> <month> 4 </month>
Reference-contexts: Therefore, on top of the set-covering algorithm, we've added a dynamic bias. The bias of a learner is defined to be any basis for choosing one generalization over another, other than strict consistency with the training examples <ref> [7] </ref>. Having the right bias is crucial to successful learning, especially when a small number of examples (as desired in an interactive setting) leaves open many possible solutions. The "FourEyes" browser improves its bias over time [4].
References-found: 7

