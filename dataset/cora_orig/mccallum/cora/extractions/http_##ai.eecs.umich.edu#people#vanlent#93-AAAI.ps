URL: http://ai.eecs.umich.edu/people/vanlent/93-AAAI.ps
Refering-URL: http://ai.eecs.umich.edu/people/vanlent/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fvanlent,mutchlerg@cs.utk.edu  
Title: A Pruning Algorithm for Imperfect Information Games  
Author: Michael van Lent and David Mutchler 
Address: Knoxville, TN 37996-1301  
Affiliation: Department of Computer Science University of Tennessee  
Abstract: IMP-minimax is the analog to minimax for games with imperfect information, like card games such as bridge or poker. It computes an optimal strategy for the game if the game has a single player and a certain natural property called perfect recall. IMP-minimax is described fully in a companion paper in this proceedings. Here we introduce an algorithm IMP-alpha-beta that is to IMP-minimax as alpha-beta is to minimax. That is, IMP-alpha-beta computes the same value as IMP-minimax does, but usually faster through pruning (i.e., not examining the value of some leaves). IMP-alpha-beta includes common pruning techniques and introduces a new technique, information set pruning. We suggest a natural model in which to study the performance of search algorithms for imperfect information games and we analyze IMP-alpha-beta in the context of that model. Our analysis includes both theorems bounding the performance of IMP-alpha-beta and empirical data indicating its average-case behavior. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bruce W. Ballard. </author> <title> The fl-minimax search procedure for trees containing chance nodes. </title> <journal> Artificial Intelligence, </journal> <volume> 21(1,2):327-350, </volume> <month> March </month> <year> 1983. </year>
Reference-contexts: Fortunately, a simple assumption permits pruning in one-player games: suppose there is a known upper bound on the payoffs at leaves. This assumption is quite reasonable in practice, and is also used in multi-player pruning [5, 6] and chance-node pruning <ref> [1] </ref>. We introduce a new form of pruning, information set pruning, which assumes such an upper bound. Before formally stating the IMP-alpha-beta algorithm that implements this pruning, we show how it works through examples. <p> Information set pruning is more closely related to chance-node pruning <ref> [1] </ref>, although the two are by definition not the same, since chance-node pruning operates at chance nodes while information set pruning operates at collections of information sets that may be far removed from any chance nodes. Algorithm IMP-alpha-beta appears in the box at the top of the next page. <p> The same is true when only chance nodes are present, and motivates the "probing" in Ballard's pruning algorithms for perfect information games with chance nodes <ref> [1] </ref>.
Reference: [2] <author> Jean R. S. Blair, David Mutchler, and Cheng Liu. </author> <title> Heuristic search in one-player games with hidden information. </title> <type> Technical Report CS-92-162, </type> <institution> Dept. of Computer Science, University of Tennessee, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Games with imperfect information are important and interesting. Two fundamental results for such games are <ref> [2, 3] </ref>: * Solving games with imperfect information is NP-hard (in contrast to games with perfect informa tion), even when there is only a single player. * An algorithm called IMP-minimax (for "imperfect information minimax") computes a strategy for games with imperfect information in time linear in y This research was <p> Imperfect information games are interesting because large classes of common games, such as card games like bridge and poker, include the imperfect information property. We refer the reader to <ref> [2, 3] </ref> (the latter in this proceedings) for further motivation for studying imperfect information games. <p> Thus pruning algorithms for IMP-minimax, like the IMP-alpha-beta algorithm presented herein, are important too. We refer the reader to <ref> [2, 3] </ref> for precise definitions and several examples of imperfect information games and IMP-minimax. Our treatment here is necessarily brief. Both IMP-minimax and IMP-alpha-beta can be stated in two-player versions; however, in such games they may not return an optimal strategy. Therefore, we restrict our discussion to their one-player versions. <p> Further, at each chance node in our examples, the probability distribution associated with that node is the uniform distribution (i.e., each alternative 1 This simple example is not adequate for motivating the use of information sets. See <ref> [2, 3] </ref> (the latter in this proceedings) for more elaborate examples and explanation. is equally likely). A strategy is a prescription for what alternatives to select at the player nodes. <p> If the imperfect information game has a certain property called perfect recall, then it can be shown that its value (as computed by IMP-minimax) equals the expected value of the optimal strategy <ref> [2, 3] </ref>. Informally, perfect recall means the player recalls her previous moves; the technical definition can be found in our companion paper in this proceedings [3]. Note that perfect recall is not the same thing as perfect information. <p> See <ref> [2, 3] </ref> (the latter in this proceedings) for a more complete exposition of IMP-minimax, including examples of its use. 2 Information set pruning The following theorem shows that in general pruning is not possible in one-player games. <p> By observing which cards are revealed a good player not only learns what cards were held but also guesses what cards the opponent may or may not still have. (Although bridge is a two-team game, IMP-alpha-beta may still be useful for it, as a heuristic or subfunction <ref> [2, 3] </ref>.) Another example is card counting, that is, calculating the probability that a certain card will be on top of the deck based on knowledge of which cards have already been played. 4 Effectiveness of IMP-alpha-beta How much faster is IMP-alpha-beta than IMP-minimax? This section addresses that question, in the <p> to magnify pruning significantly in applications in which a few information sets have large probability and the rest have small probability. * The best test for the pruning effectiveness of IMP-alpha-beta is its performance in a real application, possibly as a one-player heuristic for a two-player game, as described in <ref> [2, 3] </ref>. Acknowledgments We appreciate the useful comments we received from Jean Blair and the anonymous reviewers.
Reference: [3] <author> Jean R. S. Blair, David Mutchler, and Cheng Liu. </author> <title> Games with imperfect information. </title> <booktitle> In Proc. of the AAAI Fall Symposium on Games: Planning and Learning, </booktitle> <address> Raleigh, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Games with imperfect information are important and interesting. Two fundamental results for such games are <ref> [2, 3] </ref>: * Solving games with imperfect information is NP-hard (in contrast to games with perfect informa tion), even when there is only a single player. * An algorithm called IMP-minimax (for "imperfect information minimax") computes a strategy for games with imperfect information in time linear in y This research was <p> Imperfect information games are interesting because large classes of common games, such as card games like bridge and poker, include the imperfect information property. We refer the reader to <ref> [2, 3] </ref> (the latter in this proceedings) for further motivation for studying imperfect information games. <p> Thus pruning algorithms for IMP-minimax, like the IMP-alpha-beta algorithm presented herein, are important too. We refer the reader to <ref> [2, 3] </ref> for precise definitions and several examples of imperfect information games and IMP-minimax. Our treatment here is necessarily brief. Both IMP-minimax and IMP-alpha-beta can be stated in two-player versions; however, in such games they may not return an optimal strategy. Therefore, we restrict our discussion to their one-player versions. <p> Further, at each chance node in our examples, the probability distribution associated with that node is the uniform distribution (i.e., each alternative 1 This simple example is not adequate for motivating the use of information sets. See <ref> [2, 3] </ref> (the latter in this proceedings) for more elaborate examples and explanation. is equally likely). A strategy is a prescription for what alternatives to select at the player nodes. <p> If the imperfect information game has a certain property called perfect recall, then it can be shown that its value (as computed by IMP-minimax) equals the expected value of the optimal strategy <ref> [2, 3] </ref>. Informally, perfect recall means the player recalls her previous moves; the technical definition can be found in our companion paper in this proceedings [3]. Note that perfect recall is not the same thing as perfect information. <p> Informally, perfect recall means the player recalls her previous moves; the technical definition can be found in our companion paper in this proceedings <ref> [3] </ref>. Note that perfect recall is not the same thing as perfect information. <p> See <ref> [2, 3] </ref> (the latter in this proceedings) for a more complete exposition of IMP-minimax, including examples of its use. 2 Information set pruning The following theorem shows that in general pruning is not possible in one-player games. <p> By observing which cards are revealed a good player not only learns what cards were held but also guesses what cards the opponent may or may not still have. (Although bridge is a two-team game, IMP-alpha-beta may still be useful for it, as a heuristic or subfunction <ref> [2, 3] </ref>.) Another example is card counting, that is, calculating the probability that a certain card will be on top of the deck based on knowledge of which cards have already been played. 4 Effectiveness of IMP-alpha-beta How much faster is IMP-alpha-beta than IMP-minimax? This section addresses that question, in the <p> to magnify pruning significantly in applications in which a few information sets have large probability and the rest have small probability. * The best test for the pruning effectiveness of IMP-alpha-beta is its performance in a real application, possibly as a one-player heuristic for a two-player game, as described in <ref> [2, 3] </ref>. Acknowledgments We appreciate the useful comments we received from Jean Blair and the anonymous reviewers.
Reference: [4] <author> Donald E. Knuth and Ronald W. Moore. </author> <title> An analysis of alpha-beta pruning. </title> <journal> Artificial Intelligence, </journal> <volume> 6(4) </volume> <pages> 293-326, </pages> <month> Winter </month> <year> 1975. </year>
Reference-contexts: As we will see, IMP-alpha-beta propagates this value (combined with other pruning information) down to the bottommost information set, where the pruning of node ?? occurs. Information set pruning is different from alpha-beta pruning <ref> [4, 8] </ref>, which requires both MAX and MIN nodes. <p> The third result bears strong resemblance to the best-case behavior of alpha-beta, in which approximately 2b d=2 leaves out of b d total leaves are examined <ref> [4] </ref>. When k equals b, the above theorem shows that, in the best case, fewer than db d1 leaves will be explored out of b 2 (d1) total leaves. 4.2 Average case analysis Theorem 4 gives upper and lower bounds on how much pruning can be obtained by using IMP-alpha-beta. <p> The above contrasts with the analysis of alpha-beta, where for every set of payoffs and placements thereof, the best-first ordering yields as much pruning as is possible, in uniform trees <ref> [4] </ref>. 5 Summary and open questions We have introduced and analyzed IMP-alpha-beta, a pruning algorithm for IMP-minimax. Both algorithms find optimal strategies in imperfect information games that have a single player and perfect recall, and can be used as heuristics in more general games.
Reference: [5] <author> Richard E. Korf. </author> <title> Multi-player alpha-beta pruning. </title> <journal> Artificial Intelligence, </journal> <volume> 48(1) </volume> <pages> 99-111, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: Fortunately, a simple assumption permits pruning in one-player games: suppose there is a known upper bound on the payoffs at leaves. This assumption is quite reasonable in practice, and is also used in multi-player pruning <ref> [5, 6] </ref> and chance-node pruning [1]. We introduce a new form of pruning, information set pruning, which assumes such an upper bound. Before formally stating the IMP-alpha-beta algorithm that implements this pruning, we show how it works through examples.
Reference: [6] <author> Carol A. Luckhardt and Keki B. Irani. </author> <title> An algorithmic solution of n-person games. </title> <booktitle> In Proc. of the Fifth National Conference on Artificial Intelligence (AAAI-86), </booktitle> <pages> pages 158-162, </pages> <address> Los Altos, CA, 1986. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: Fortunately, a simple assumption permits pruning in one-player games: suppose there is a known upper bound on the payoffs at leaves. This assumption is quite reasonable in practice, and is also used in multi-player pruning <ref> [5, 6] </ref> and chance-node pruning [1]. We introduce a new form of pruning, information set pruning, which assumes such an upper bound. Before formally stating the IMP-alpha-beta algorithm that implements this pruning, we show how it works through examples.
Reference: [7] <author> David Mutchler and Michael van Lent. </author> <title> A pruning algorithm for imperfect information games. </title> <type> Technical report, </type> <institution> Dept. of Computer Science, University of Tennessee, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: Proof: by induction on the number of recursive calls to V . See <ref> [7, 9] </ref> for details. To obtain the strategy associated with the value IMP-alpha-beta returns, simply record in Max-Set the alternative with which best is associated. <p> For brevity we omit the proofs of the theorems; they can be found in <ref> [7, 9] </ref>. Theorem 3 IMP-minimax examines all (kb) d1 leaves in the IMP-model tree. 4.1 Boundaries The following theorem provides both upper and lower bounds on the amount of pruning available in the IMP-model. <p> At each leaf encountered, we obtain its payoff from the built-in function call (random 11), which yields an integer between 0 and 10, inclusive. For each trial we ran, we 2 For brevity we omit the k = 1 special case; it is given in <ref> [7, 9] </ref>. 3 Austin Kyoto Common Lisp is public domain software written by William Schelter at the University of Texas, and is based on Kyoto Common Lisp, written by Taiichi Yuasa and Masami Hagiya, Kyota University, 1984. recorded the initial state of the random number generator, so that our results can
Reference: [8] <author> James R. Slagle and John K. Dixon. </author> <title> Experiments with some programs that search game trees. </title> <journal> Journal of the ACM, </journal> <volume> 16(2) </volume> <pages> 189-207, </pages> <month> April </month> <year> 1969. </year>
Reference-contexts: As we will see, IMP-alpha-beta propagates this value (combined with other pruning information) down to the bottommost information set, where the pruning of node ?? occurs. Information set pruning is different from alpha-beta pruning <ref> [4, 8] </ref>, which requires both MAX and MIN nodes.
Reference: [9] <author> Michael van Lent. </author> <title> A pruning algorithm for one player games with hidden information. </title> <type> Master's thesis, </type> <institution> University of Tennessee, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Proof: by induction on the number of recursive calls to V . See <ref> [7, 9] </ref> for details. To obtain the strategy associated with the value IMP-alpha-beta returns, simply record in Max-Set the alternative with which best is associated. <p> For brevity we omit the proofs of the theorems; they can be found in <ref> [7, 9] </ref>. Theorem 3 IMP-minimax examines all (kb) d1 leaves in the IMP-model tree. 4.1 Boundaries The following theorem provides both upper and lower bounds on the amount of pruning available in the IMP-model. <p> At each leaf encountered, we obtain its payoff from the built-in function call (random 11), which yields an integer between 0 and 10, inclusive. For each trial we ran, we 2 For brevity we omit the k = 1 special case; it is given in <ref> [7, 9] </ref>. 3 Austin Kyoto Common Lisp is public domain software written by William Schelter at the University of Texas, and is based on Kyoto Common Lisp, written by Taiichi Yuasa and Masami Hagiya, Kyota University, 1984. recorded the initial state of the random number generator, so that our results can
References-found: 9

