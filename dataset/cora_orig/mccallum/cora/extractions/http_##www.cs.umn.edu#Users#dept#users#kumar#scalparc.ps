URL: http://www.cs.umn.edu/Users/dept/users/kumar/scalparc.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Title: ScalParC A New Scalable and Efficient Parallel Classification Algorithm for Mining Large Datasets  
Author: Mahesh V. Joshi George Karypis Vipin Kumar 
Keyword: Parallel Data Mining, Decision Tree, Classification.  
Abstract: In this paper, we present ScalParC (Scalable Parallel Classifier), a new parallel formulation of a decision tree based classification process. Like other state-of-the-art decision tree classifiers such as SPRINT, ScalParC is suited for handling large datasets. We show that existing parallel formulation of SPRINT is unscalable, whereas ScalParC is shown to be scalable in both runtime and memory requirements. We present the experimental results of classifying up to 6.4 million records on up to 128 processors of Cray T3D, in order to demonstrate the scalable behavior of ScalParC. A key component of ScalParC is the parallel hash table. The proposed parallel hashing paradigm can be used to parallelize other algorithms that require many concurrent updates to a large hash table. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> John Shafer, Rakesh Agrawal and Manish Mehta, SPRINT: </author> <title> A Scalable Parallel Classifier for Data Mining, </title> <booktitle> Proc. of 22nd International Conference on Very Large Databases, </booktitle> <address> Mumbai, India, </address> <month> Sept. </month> <year> 1996. </year>
Reference-contexts: The decision-tree based classifiers that handle large datasets are attractive, because use of larger datasets improves the classification accuracy even further [4]. Recently proposed classifiers SLIQ [2] and SPRINT <ref> [1] </ref> use entire dataset for classification and are shown to be more accurate as compared to the classifiers that use sampled dataset or multiple partitions of the dataset [4, 5]. <p> The parallel formulation, however, must address the issues of efficiency and scalability in both memory requirements and parallel runtime. Relatively little work has been done so far for development of parallel formulations for decision tree based classifiers <ref> [1, 7, 6] </ref>. Among these, the most relevant one is the parallel formulation of SPRINT [1], as it requires sorting of continuous attributes only once. SPRINT's design allows it to parallelize the split determining phase effectively. <p> Relatively little work has been done so far for development of parallel formulations for decision tree based classifiers [1, 7, 6]. Among these, the most relevant one is the parallel formulation of SPRINT <ref> [1] </ref>, as it requires sorting of continuous attributes only once. SPRINT's design allows it to parallelize the split determining phase effectively. The parallel formulation proposed for the splitting phase, however, is inherently unscalable in both memory requirements and runtime. <p> So, the best way to achieve load balance at the root node is to fragment each attribute list horizontally into p fragments of equal sizes and to assign each fragment to a different processor <ref> [7, 1] </ref>. We assume that the initial assignment of data to the processors remains unchanged throughout the process of classification. With this approach, the splitting decision may cause the records of a node to be distributed unevenly among processors. Refer to Figure 2 for an example of such an imbalance. <p> The implementation of the split determining phase is straightforward. For the continuous attributes, the design presented in parallel formulation of SPRINT <ref> [1] </ref> is efficient. For a given 7 continuous attribute, it initializes the count matrices on every processor corresponding to the split point lying at the beginning of the local attribute list on that processor. <p> Then each processor proceeds to compute gini indices for all possible positions in its local part of the list. For the categorical attributes, the local count matrices from all the processors can be gathered onto a single processor, where the gini index can be computed <ref> [1, 7] </ref>. The parallelization of the splitting phase is more difficult. In the parallel formulation of SPRINT, the hash table required for consistent splitting is built on all the processors for each node of the decision tree. <p> We tested ScalParC for training sets containing up to 6.4 million records, each containing seven attributes. There were two possible class labels. The training sets were artificially generated using a scheme similar to that used for SPRINT <ref> [1] </ref>. for various training set sizes. For a given problem instance, the relative speedups decrease as the number of processors are increased, because of increased overheads.
Reference: [2] <author> Manish Mehta, Rakesh Agrawal and Jorma Rissanen, SLIQ: </author> <title> A Fast Scalable Classifier for Data Mining, </title> <booktitle> Proc. of the 5th International Conference on Extending Database Technology (EDBT), </booktitle> <address> Avignon, France, </address> <month> March </month> <year> 1996. </year> <month> 19 </month>
Reference-contexts: The decision-tree based classifiers that handle large datasets are attractive, because use of larger datasets improves the classification accuracy even further [4]. Recently proposed classifiers SLIQ <ref> [2] </ref> and SPRINT [1] use entire dataset for classification and are shown to be more accurate as compared to the classifiers that use sampled dataset or multiple partitions of the dataset [4, 5]. <p> The key component of ScalParC is the parallel hash table. The parallel hashing paradigm can be used to parallelize other algorithms that require many concurrent updates to a large hash table. For example, it can be used to design an equally scalable parallelization of the SLIQ classifier <ref> [2] </ref>, whose sequential approach is more efficient than that of SPRINT, but suffers a severe memory limitation. Refer to [12] for details of parallelizing SLIQ scalably. The communication patterns used by ScalParC while doing the parallel hashing were inspired by those used in parallel sparse matrix-vector multiplication algorithms.
Reference: [3] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis, </author> <title> Introduction to Par--allel Computing: Algorithm Design and Analysis, </title> <address> Benjamin-Cummings/Addison Wes-ley, Redwood City, </address> <year> 1994. </year>
Reference-contexts: After the initial sorting of the continuous attributes, the serial runtime is T s = O (N ) for a majority of levels, when large datasets are being classified. Memory efficient and scalable formulations of parallel sorting are well known <ref> [3] </ref>. Hence, for runtime scalability, the algorithm must be designed such that none of the components of the overall communication overhead of the classification process exceeds O (N ) at any level; i.e., the per processor communication overhead should exceed O (N=p) per level. <p> Each entry in this buffer is an (l; v) pair. Note that some of these buffers might be empty, if none of the keys hashes to the corresponding processors. Then one step of an all-to-all-personalized communication <ref> [3] </ref> is done. Finally, each processor extracts the (l; v) pairs from the received buffers and stores value v at index l of their respective hash tables. The same process can be followed while searching for values given their corresponding keys. <p> If each processor has m keys to hash at a time, then the all-to-all personalized communication can be done in O (m) time provided m is (p) <ref> [3] </ref>. Thus, the parallel hashing done in the proposed manner above is scalable as long as (p 2 ) keys are hashed at the same time. <p> The algorithm is illustrated on three processors, using an example training set shown in Figure 3 (a). 13 14 * Pre-sort. We use the parallel sample sort algorithm followed by a parallel shift op-eration, to sort all the continuous attributes. This algorithm is scalable <ref> [3] </ref>. The shift operation is needed to maintain equal number of records on each processor initially and is performed very efficiently in our implementation. The result of the pre-sorting phase is shown in Figure 6 for both the continuous attributes: Salary and Age. * Find-Split-I. <p> For a continuous attribute, each processor first computes the local count matrix corresponding to the split position lying at the beginning of the local attribute list. Then a parallel prefix operation <ref> [3] </ref> is performed to compute the global count matrices for these split point positions. This process is illustrated in Figure 6, where for each processor, the local count matrix for attribute Age is shown for the beginning of the local part of the list. <p> For a categorical attribute, there is only one count matrix possible per node. Each processor fills in its local copy of the count matrix. The global count matrix for that node is computed on a coordinating processor by doing a parallel reduction operation <ref> [3] </ref>. Note that, for any attribute, the count matrices from all the nodes at the current level of processing are combined before performing the collective communication. * Find-Split-II. <p> In particular, while going from 64 to 128 processors, the relative speedup obtained for 6.4 million records was 1.43 and a relative speedup obtained for 3.2 million records was 1.36. These trends are typical of a normal scalable parallel algorithm <ref> [3] </ref>. Note that ScalParC could classify 6.4 million records in just 77 seconds on 128 processors. This demonstrates that large classification problems can be solved quickly using ScalParC. Another look can be obtained at the parallelization overhead behavior using Figure 7 (b).
Reference: [4] <author> Jason Catlett, </author> <title> Megainduction: Machine Learning on Very Large Databases, </title> <type> PhD thesis, </type> <institution> University of Sydney, </institution> <year> 1991. </year>
Reference-contexts: The decision-tree based classifiers that handle large datasets are attractive, because use of larger datasets improves the classification accuracy even further <ref> [4] </ref>. Recently proposed classifiers SLIQ [2] and SPRINT [1] use entire dataset for classification and are shown to be more accurate as compared to the classifiers that use sampled dataset or multiple partitions of the dataset [4, 5]. <p> Recently proposed classifiers SLIQ [2] and SPRINT [1] use entire dataset for classification and are shown to be more accurate as compared to the classifiers that use sampled dataset or multiple partitions of the dataset <ref> [4, 5] </ref>. The decision tree model is built by recursively splitting the training set based on a locally optimal criterion until all or most of the records belonging to each of the partitions bear the same class label.
Reference: [5] <author> Philip K. Chan and Salvatore J. Stolfo, </author> <title> Meta-learning for multistrategy and parallel learning, </title> <booktitle> In Proc. Second Intl. Workshop on Multistrategy Learning, </booktitle> <address> pp.150-165, </address> <year> 1993. </year>
Reference-contexts: Recently proposed classifiers SLIQ [2] and SPRINT [1] use entire dataset for classification and are shown to be more accurate as compared to the classifiers that use sampled dataset or multiple partitions of the dataset <ref> [4, 5] </ref>. The decision tree model is built by recursively splitting the training set based on a locally optimal criterion until all or most of the records belonging to each of the partitions bear the same class label.
Reference: [6] <author> D. J. Fifield, </author> <title> Distributed tree construction from large data-sets, </title> <type> Bachelor's Honors Thesis, </type> <institution> Australian National University, </institution> <year> 1992. </year>
Reference-contexts: The parallel formulation, however, must address the issues of efficiency and scalability in both memory requirements and parallel runtime. Relatively little work has been done so far for development of parallel formulations for decision tree based classifiers <ref> [1, 7, 6] </ref>. Among these, the most relevant one is the parallel formulation of SPRINT [1], as it requires sorting of continuous attributes only once. SPRINT's design allows it to parallelize the split determining phase effectively.
Reference: [7] <author> Eui-Hong (Sam) Han, Anurag Srivastava, Vipin Kumar, </author> <title> Parallel Formulations of Inductive Classification Learning Algorithm, </title> <type> Technical Report 96-040, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, </institution> <year> 1996. </year>
Reference-contexts: The parallel formulation, however, must address the issues of efficiency and scalability in both memory requirements and parallel runtime. Relatively little work has been done so far for development of parallel formulations for decision tree based classifiers <ref> [1, 7, 6] </ref>. Among these, the most relevant one is the parallel formulation of SPRINT [1], as it requires sorting of continuous attributes only once. SPRINT's design allows it to parallelize the split determining phase effectively. <p> So, the best way to achieve load balance at the root node is to fragment each attribute list horizontally into p fragments of equal sizes and to assign each fragment to a different processor <ref> [7, 1] </ref>. We assume that the initial assignment of data to the processors remains unchanged throughout the process of classification. With this approach, the splitting decision may cause the records of a node to be distributed unevenly among processors. Refer to Figure 2 for an example of such an imbalance. <p> Then each processor proceeds to compute gini indices for all possible positions in its local part of the list. For the categorical attributes, the local count matrices from all the processors can be gathered onto a single processor, where the gini index can be computed <ref> [1, 7] </ref>. The parallelization of the splitting phase is more difficult. In the parallel formulation of SPRINT, the hash table required for consistent splitting is built on all the processors for each node of the decision tree. <p> However, an absolute load balance can be maintained by redistributing the lists among processors when the elimination of records start causing a severe load imbalance. This approach is explored in <ref> [7] </ref>. ScalParC's design allows it to handle very large datasets by using increasing number of 18 processors. This is because, it requires just the local part of the distributed node table to remain in the main memory of each processor.
Reference: [8] <author> Sreerama K. Murthy, Simon Kasif and Steven Salzberg, </author> <title> A System for Induction of Oblique Decision Trees, </title> <journal> Journal of Artificial Intelligence Research vol. </journal> <volume> 2, </volume> <pages> pp. 1-32, </pages> <year> 1994. </year>
Reference-contexts: If the continuous attribute is sorted on its values at each of the nodes in the tree, then a linear search can be made for the optimal value of v by moving the possible 1 Some classifiers allow a condition on a linear combination of many attributes <ref> [8] </ref>, but we restrict ourselves to a single splitting attribute. 2 It is also possible to form two partitions for a categorical attribute each characterized by a subset of values in its domain. 4 split point from the beginning to the end of the list, one value at a time, updating
Reference: [9] <author> D. Michie, D.J. Spiegelhalter and C. C. Taylor, </author> <title> Machine Learning, Neural and Statistical Classification. </title> <publisher> Ellis Horwood, </publisher> <year> 1994. </year>
Reference-contexts: Related papers are available via WWW at URL: http://www.cs.umn.edu/~kumar. y Department of Computer Science, University of Minnesota, Minneapolis, MN 55455 1 yield comparable or better accuracy as compared to other models such as neural networks, statistical models or genetic models <ref> [9] </ref>. The decision-tree based classifiers that handle large datasets are attractive, because use of larger datasets improves the classification accuracy even further [4].
Reference: [10] <author> L. Breiman, J. H. Friedman, R. A. Olshen and C. J. Stone, </author> <title> Classification and Regression Trees, </title> <publisher> Wadsworth, </publisher> <address> Belmont, </address> <year> 1984. </year>
Reference-contexts: The handling of categorical attributes in both phases is straightforward. Handling the continuous attributes is challenging. An efficient determination of the splitting decision used in most of the existing classifiers requires these attributes to be sorted on values. The classifiers such as CART <ref> [10] </ref> and C4.5 [11] perform sorting at every node of the decision tree, which makes them very expensive for large datasets, since this sorting has to be done out-of-core. The approach taken by SLIQ and SPRINT sorts the continuous attributes only once in the beginning. <p> The second phase is called the splitting phase. It splits the records into children nodes based on the decision made. The process stops when all the leaves have records bearing only one class label. One of the commonly used splitting criteria is to minimize the gini index <ref> [10] </ref> of the split. The calculation of gini index involves computing the frequency of each class in each of the partitions. Let a parent node, having n records from c possible classes, be split into d partitions, each partition corresponding to a child of the the parent node.
Reference: [11] <author> J. Ross Quinlan, C4.5: </author> <title> Programs for Machine Learning, </title> <publisher> Morgan Kaufman, </publisher> <year> 1993. </year>
Reference-contexts: The handling of categorical attributes in both phases is straightforward. Handling the continuous attributes is challenging. An efficient determination of the splitting decision used in most of the existing classifiers requires these attributes to be sorted on values. The classifiers such as CART [10] and C4.5 <ref> [11] </ref> perform sorting at every node of the decision tree, which makes them very expensive for large datasets, since this sorting has to be done out-of-core. The approach taken by SLIQ and SPRINT sorts the continuous attributes only once in the beginning.
Reference: [12] <author> Mahesh V. Joshi, George Karypis and Vipin Kumar, </author> <title> Design of scalable parallel classification algorithms via a new parallel hashing paradigm, </title> <type> Technical Report under preparation, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, </institution> <year> 1997. </year> <month> 20 </month>
Reference-contexts: For example, it can be used to design an equally scalable parallelization of the SLIQ classifier [2], whose sequential approach is more efficient than that of SPRINT, but suffers a severe memory limitation. Refer to <ref> [12] </ref> for details of parallelizing SLIQ scalably. The communication patterns used by ScalParC while doing the parallel hashing were inspired by those used in parallel sparse matrix-vector multiplication algorithms.
References-found: 12

