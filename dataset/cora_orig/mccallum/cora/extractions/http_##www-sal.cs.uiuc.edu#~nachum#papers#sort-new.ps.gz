URL: http://www-sal.cs.uiuc.edu/~nachum/papers/sort-new.ps.gz
Refering-URL: http://sal.cs.uiuc.edu/~nachum/papers/
Root-URL: http://www.cs.uiuc.edu
Title: FAST EXCHANGE SORTS  
Author: Nachum Dershowitz Hon-Wai Leong 
Address: Urbana, IL 61801, USA Singapore 0511  
Affiliation: Department of Computer Science Department of Computer Science University of Illinois National University of Singapore  
Abstract: We present three variations of the following new sorting theme: Throughout the sort, the array is maintained in piles of sorted elements. At each step, the piles are split into two parts, so that the elements of the left piles are smaller than (or equal to) the elements of the right piles. Then, the two parts are each sorted, recursively. The theme, then, is a combination of Hoare's Quicksort idea, and the Pick algorithm, by Blum, et al., for linear selection. The variations arise from the possible choices of splitting method. Two variations attempt to minimize the average number of comparisons. The better of these has an average performance of 1:075n lg n comparisons. The third variation sacrifices the average case for a worst-case performance of 1:756n lg n, which is better than Heapsort. They all require minimal extra space and about as many data moves as comparisons.
Abstract-found: 1
Intro-found: 1
Reference: [BlFP73] <author> Blum, M., R. W. Floyd, V. Pratt, R. L. Rivest, and R. E. Tarjan, </author> <title> "Time Bounds for Selection," </title> <journal> Journal of Computer and System Sciences, (1973), </journal> <volume> Vol. 7, </volume> <pages> pp. 448-461. </pages>
Reference-contexts: By combining ideas from Hoare's Quicksort algorithm [Hoar61, Hoar62] and Blum, Floyd, Pratt, Rivest, and Tarjan's Pick algorithm <ref> [BlFP73] </ref> for linear selection, we have come up with a new scheme for exchange sorts. <p> Accordingly, the worst case is 1:756n lg n, which is better than Heapsort's worst-case performance of 2n lg n. 7 If we replace the 3m median find algorithm of [ScPP76] by the slow-er 5:4305m Pick algorithm <ref> [BlFP73] </ref>, the worst case of the sort will be max (1:920; 1:979)n lg n = 1:979n lg n which is just under 2n lg n. We can also consider grouping the middle elements into piles of three, instead of five.
Reference: [Brow76] <author> Brown, T., </author> <title> "Remarks on Algorithm 489," </title> <journal> Trans. on Mathematical Software, (1976), </journal> <volume> Vol. 3, No. 2, </volume> <pages> pp. 301-304. </pages>
Reference-contexts: The idea here is to always split the piles evenly into two parts using a fast median selection algorithm for Pile-Partition. We use the fastest known method, Select, by Floyd and Rivest [FlRi75a, FlRi75b] as modified by Brown <ref> [Brow76] </ref> which requires 1:5m comparisons on the average, to find the median of m elements. This variation of the sorting method is called Select-Pilesort. The average case can be partially analyzed as follows: The worst-case split of the piles is x = 0:5.
Reference: [Floy64] <author> Floyd, R. W., </author> <title> "Algorithm 245 (Treesort3)," </title> <journal> Comm. of ACM, (1964), </journal> <volume> Vol. 7, No. 12, </volume> <editor> p. </editor> <volume> 701. </volume>
Reference-contexts: The variations we consider arise from different possibilities for splitting. Two variations attempt to minimize the average number of comparisons (over all possible input array permutations); another sacrifices average-case performance for an O (n lg n) worst-case that out-performs Heapsort <ref> [Will64, Floy64] </ref>. They all require some extra space and about as many data moves as comparisons; their practical value is limited to cases where comparisons are relatively expensive. In the next section, we elaborate on the general scheme. Section 3 analyzes its time complexity.
Reference: [FlRi75a] <author> Floyd, R. W., and R. L. Rivest, </author> <title> "Expected Time Bounds for Selection," </title> <journal> Comm. of ACM, (1975), </journal> <volume> Vol. 18, No. 3, </volume> <pages> pp. 165-172. </pages>
Reference-contexts: The idea here is to always split the piles evenly into two parts using a fast median selection algorithm for Pile-Partition. We use the fastest known method, Select, by Floyd and Rivest <ref> [FlRi75a, FlRi75b] </ref> as modified by Brown [Brow76] which requires 1:5m comparisons on the average, to find the median of m elements. This variation of the sorting method is called Select-Pilesort. The average case can be partially analyzed as follows: The worst-case split of the piles is x = 0:5.
Reference: [FlRi75b] <author> Floyd, R. W., and R. L. Rivest, </author> <title> "Algorithm 489 (The Algorithm SELECT for Finding the i-th Smallest of n Elements)," </title> <journal> Comm. of ACM, (1975), </journal> <volume> Vol. 18, No. 3, </volume> <editor> p. </editor> <volume> 173. </volume>
Reference-contexts: The idea here is to always split the piles evenly into two parts using a fast median selection algorithm for Pile-Partition. We use the fastest known method, Select, by Floyd and Rivest <ref> [FlRi75a, FlRi75b] </ref> as modified by Brown [Brow76] which requires 1:5m comparisons on the average, to find the median of m elements. This variation of the sorting method is called Select-Pilesort. The average case can be partially analyzed as follows: The worst-case split of the piles is x = 0:5.
Reference: [FrMc70] <author> Frazer, W. D. and A. C. McKellar, "Samplesort: </author> <title> A Sampling Approach to Minimal Tree Sorting," </title> <journal> Journal of ACM, (1970), </journal> <volume> Vol. 17, No. 3, </volume> <pages> pp. 496-507. </pages>
Reference: [Hoar61] <author> Hoare, C. A. R., </author> <title> "Algorithm 63 (Partition); 64 (Quicksort); 65 (Find)," </title> <journal> Comm. of ACM, (1961), </journal> <volume> Vol. 4, No. 7, </volume> <pages> pp. 321-322. </pages>
Reference-contexts: An exchange sort [Knut73] is one that goes about this task by repeatedly looking for a pair of elements a i and a j (1 i &lt; j n) that are inverted (a i &gt; a j ) and exchanging them. By combining ideas from Hoare's Quicksort algorithm <ref> [Hoar61, Hoar62] </ref> and Blum, Floyd, Pratt, Rivest, and Tarjan's Pick algorithm [BlFP73] for linear selection, we have come up with a new scheme for exchange sorts. <p> Furthermore, there are well-known methods that are optimal to within a multiplicative constant. Heapsort [Will64] has both average- and worst-case performances of O (n lg n); asymptotically, its worst case is 2n lg n. Quicksort <ref> [Hoar61] </ref> has average-case performance of 1:39n lg n [Knut73]. This was improved by Singleton [Sing69] to 1:19n lg n using the median-of-three method, and can be made arbitrarily close to n lg n by increasing the sample size. However, Quicksort suffers from quadratic worst-case performance. <p> Select-Pilesort uses the Select algorithm for choosing the pivot; Fast-Pilesort is the improved version using Select; Random-Pilesort uses Partition; Random-Pilesort-3 is the variation using three piles. For comparison, we also implemented Quicksort <ref> [Hoar61] </ref> and Singleton's median-of-three variation [Sing69], which we will call Quicksort-3. The implementations are all in Pascal and were tested on a CDC Cyber 175.
Reference: [Hoar62] <author> Hoare, C. A. R., </author> <title> "Quicksort," </title> <journal> Computer Journal, (1962), </journal> <volume> Vol. 5, No. 1, </volume> <pages> pp. 10-15. </pages>
Reference-contexts: An exchange sort [Knut73] is one that goes about this task by repeatedly looking for a pair of elements a i and a j (1 i &lt; j n) that are inverted (a i &gt; a j ) and exchanging them. By combining ideas from Hoare's Quicksort algorithm <ref> [Hoar61, Hoar62] </ref> and Blum, Floyd, Pratt, Rivest, and Tarjan's Pick algorithm [BlFP73] for linear selection, we have come up with a new scheme for exchange sorts.
Reference: [Knut73] <author> Knuth, D. E., </author> <title> The Art of Computer Programming, Vol. 3 (Sorting and Searching), (1973), </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: 1 Introduction The sorting problem is: Given an array a 1 ; a 2 ; ; a n of elements, rearrange them so that a 1 a 2 a n , where is a given linear ordering of elements. An exchange sort <ref> [Knut73] </ref> is one that goes about this task by repeatedly looking for a pair of elements a i and a j (1 i &lt; j n) that are inverted (a i &gt; a j ) and exchanging them. <p> The model under consideration is a comparison--based model; the cost of a method is measured by the number of comparisons required for sorting n elements. It is well-known <ref> [Knut73] </ref> that under this comparison-based model, sorting has cost (n lg n). Furthermore, there are well-known methods that are optimal to within a multiplicative constant. Heapsort [Will64] has both average- and worst-case performances of O (n lg n); asymptotically, its worst case is 2n lg n. <p> Furthermore, there are well-known methods that are optimal to within a multiplicative constant. Heapsort [Will64] has both average- and worst-case performances of O (n lg n); asymptotically, its worst case is 2n lg n. Quicksort [Hoar61] has average-case performance of 1:39n lg n <ref> [Knut73] </ref>. This was improved by Singleton [Sing69] to 1:19n lg n using the median-of-three method, and can be made arbitrarily close to n lg n by increasing the sample size. However, Quicksort suffers from quadratic worst-case performance. <p> However, Quicksort suffers from quadratic worst-case performance. In both Heapsort and Quicksort, the number of data-moves is the same order of magnitude as the number of comparisons. Binary-Insertion Sort <ref> [Knut73] </ref> is also optimal for this model, since it has worst-case performance of O (n lg n) comparisons; however, it requires O (nsup2) data-moves. Briefly, our scheme is as follows: The array is maintained in small piles of sorted elements throughout the sorting process. <p> following procedures sketch the whole sorting scheme: procedure Sort; 3 begin Initial-Piling (1,N); Pilesort (1,N) end; procedure Pilesort ( L, R ); begin if ( R - L ) &lt;= Threshold then Smallsort (L,R) else begin Pile-Partition (L,R,T); Partition-Cleanup (L,R,T); Pilesort (L, T-1); Pilesort (T+1, R) end As in Quicksort <ref> [Knut73] </ref>, a Smallsort routine is used whenever the array segment is so small that the overhead does not justify recursive calls. The Partition-Cleanup procedure does tasks (a) and (b) simultaneously. It is similar to the Partition phase of Quicksort and is applied to the X and Y elements. <p> The fastest linear median selection algorithm is that of Schonhage, Pa-terson, and Pippenger [ScPP76] (improved in [Eber79]; see also <ref> [Knut73] </ref>). It has a 3k asymptotic upper bound on the number of comparisons to find the median of k elements. <p> Step P3, then moves the piles in Q [ R into the proper partition. Step P1 costs 6 (n=15) = 2n=5, since it takes at most 6 comparisons to find the middle of five elements <ref> [Knut73] </ref>. Step P2 costs 3n=15 = n=5, using the 3m worst-case median find algorithm. Lastly, Step P3 costs just 2n=15 comparisons. Therefore, Pile-Partition costs 11n=15 comparisons.
Reference: [ScPP76] <author> Schonhage, A., M. S. Paterson, N. Pippenger, </author> <title> "Finding the Median," </title> <journal> Journal of Computer and System Sciences, (1976), </journal> <volume> Vol. 13, </volume> <pages> pp. 184-199. </pages>
Reference-contexts: In fact, any linear time selection procedure that partitions the m piles so that the worst-case split is proportional to m will guarantee an O (n lg n) worst-case sorting method. The fastest linear median selection algorithm is that of Schonhage, Pa-terson, and Pippenger <ref> [ScPP76] </ref> (improved in [Eber79]; see also [Knut73]). It has a 3k asymptotic upper bound on the number of comparisons to find the median of k elements. <p> Accordingly, the worst case is 1:756n lg n, which is better than Heapsort's worst-case performance of 2n lg n. 7 If we replace the 3m median find algorithm of <ref> [ScPP76] </ref> by the slow-er 5:4305m Pick algorithm [BlFP73], the worst case of the sort will be max (1:920; 1:979)n lg n = 1:979n lg n which is just under 2n lg n. We can also consider grouping the middle elements into piles of three, instead of five.
Reference: [Sing69] <author> Singleton, R. C., </author> <title> "Algorithm 347 (An Efficient Algorithm for Sorting with Minimal Storage)," </title> <journal> Comm. of ACM, (1969), </journal> <volume> Vol. 12, No. 3, </volume> <pages> pp. 185-187. </pages>
Reference-contexts: Furthermore, there are well-known methods that are optimal to within a multiplicative constant. Heapsort [Will64] has both average- and worst-case performances of O (n lg n); asymptotically, its worst case is 2n lg n. Quicksort [Hoar61] has average-case performance of 1:39n lg n [Knut73]. This was improved by Singleton <ref> [Sing69] </ref> to 1:19n lg n using the median-of-three method, and can be made arbitrarily close to n lg n by increasing the sample size. However, Quicksort suffers from quadratic worst-case performance. <p> Select-Pilesort uses the Select algorithm for choosing the pivot; Fast-Pilesort is the improved version using Select; Random-Pilesort uses Partition; Random-Pilesort-3 is the variation using three piles. For comparison, we also implemented Quicksort [Hoar61] and Singleton's median-of-three variation <ref> [Sing69] </ref>, which we will call Quicksort-3. The implementations are all in Pascal and were tested on a CDC Cyber 175. A summary of the implemented algorithms is given in The data used to test the programs were randomly generated real numbers uniformly distributed over [10000.0 , 100000.0).
Reference: [Will64] <author> Williams, J. W. J., </author> <title> "Algorithm 232 (Heapsort)," </title> <journal> Comm. of ACM, (1964), </journal> <volume> Vol. 7, No. 6, </volume> <pages> pp. 347-348. 12 </pages>
Reference-contexts: It is well-known [Knut73] that under this comparison-based model, sorting has cost (n lg n). Furthermore, there are well-known methods that are optimal to within a multiplicative constant. Heapsort <ref> [Will64] </ref> has both average- and worst-case performances of O (n lg n); asymptotically, its worst case is 2n lg n. Quicksort [Hoar61] has average-case performance of 1:39n lg n [Knut73]. <p> The variations we consider arise from different possibilities for splitting. Two variations attempt to minimize the average number of comparisons (over all possible input array permutations); another sacrifices average-case performance for an O (n lg n) worst-case that out-performs Heapsort <ref> [Will64, Floy64] </ref>. They all require some extra space and about as many data moves as comparisons; their practical value is limited to cases where comparisons are relatively expensive. In the next section, we elaborate on the general scheme. Section 3 analyzes its time complexity.
References-found: 12

