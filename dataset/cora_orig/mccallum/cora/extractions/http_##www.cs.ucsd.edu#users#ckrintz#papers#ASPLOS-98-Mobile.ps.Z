URL: http://www.cs.ucsd.edu/users/ckrintz/papers/ASPLOS-98-Mobile.ps.Z
Refering-URL: http://www.cs.ucsd.edu/users/ckrintz/
Root-URL: http://www.cs.ucsd.edu
Email: fckrintz,calderg@cs.ucsd.edu fhan.lee,zorng@cs.colorado.edu  
Title: Overlapping Execution with Transfer Using Non-Strict Execution for Mobile Programs  
Author: Chandra Krintz Brad Calder Han Bok Lee Benjamin G. Zorn 
Affiliation: Dept. of Computer Science and Engineering Dept. of Computer Science University of California, San Diego University of Colorado  
Abstract: In order to execute a program on a remote computer, it must first be transferred over a network. This transmission incurs the overhead of network latency before execution can begin. This latency can vary greatly depending upon the size of the program, where it is located (e.g., on a local network or across the Internet), and the bandwidth available to retrieve the program. Existing technologies, like Java, require that a file be fully transferred before it can start executing. For large files and low bandwidth lines, this delay can be significant. In this paper we propose and evaluate a non-strict form of mobile program execution. A mobile program is any program that is transferred to a different machine and executed. The goal of non-strict execution is to overlap execution with transfer, allowing the program to start executing as soon as possible. Non-strict execution allows a procedure in the program to start executing as soon as its code and data have transferred. To enable this technology, we examine several techniques for rearranging procedures and reorganizing the data inside Java class files. Our results show that non-strict execution decreases the initial transfer delay between 31% and 56% on average, with an average reduction in overall execution time between 25% and 40%. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Adl-Tabatabai, G. Langdale, S. Lucco, and R. Wahbe. </author> <title> Efficient and language-independent mobile programs. </title> <booktitle> In Programming Language Design and Implementation, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Our methods can potentially be applied to any mobile program system (e.g., Omniware <ref> [1] </ref> or ActiveX [4]), but we choose to use Java because of its widespread use and built-in support for mobile programs. In this section we describe non-strict execution and its implications for Java.
Reference: [2] <author> Jean-Loup Baer and Gary R. Sager. </author> <title> Dynamic improvement of locality in virtual memory systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-2(1):5462, </volume> <month> March </month> <year> 1976. </year>
Reference-contexts: For example, if procedures are referenced at approximately the same time, then they are placed on the same page. Attempts to understand and exploit reference patterns of code and data have resulted in such algorithms as least recently used page replacement (e.g., see <ref> [2, 13] </ref>) and Denning's working set model [5]. More recently, as memory sizes have increased, interest has shifted to improving both temporal and spatial locality for all levels of memory. Many software techniques have been developed for improving instruction cache performance.
Reference: [3] <author> M. Bellare and P. Rogaway. </author> <title> Entity authentication and key distribution. </title> <booktitle> In Advances in Cryptology - Crypto 93 Proceedings, Lecture Notes in Co mputer Science, </booktitle> <year> 1994. </year>
Reference-contexts: The whole verification process can be avoided by providing a means of trust between the compiler that produced the Java class file and the JVM interpreter. For example, with security mechanisms for digital signatures <ref> [3] </ref> or software fault isolation [26], the verification step can be skipped completely. 4 First Use Procedure Reordering To capitalize on the benefit achieved from non-strict execution, it is necessary to predict the execution order of the procedures in the program, and then to place them in the class file in
Reference: [4] <author> D. Chappell. </author> <title> Understanding ActiveX and OLE. </title> <publisher> Microsoft Press, </publisher> <year> 1996. </year>
Reference-contexts: Our methods can potentially be applied to any mobile program system (e.g., Omniware [1] or ActiveX <ref> [4] </ref>), but we choose to use Java because of its widespread use and built-in support for mobile programs. In this section we describe non-strict execution and its implications for Java.
Reference: [5] <author> Peter Denning. </author> <title> Working sets past and present. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-6(1):6484, </volume> <month> January </month> <year> 1980. </year>
Reference-contexts: Attempts to understand and exploit reference patterns of code and data have resulted in such algorithms as least recently used page replacement (e.g., see [2, 13]) and Denning's working set model <ref> [5] </ref>. More recently, as memory sizes have increased, interest has shifted to improving both temporal and spatial locality for all levels of memory. Many software techniques have been developed for improving instruction cache performance.
Reference: [6] <author> W. J. Doherty and R. P. Kelisky. </author> <title> Managing VM/CMS systems for user effectiveness. </title> <journal> IBM Systems Journal, </journal> <pages> pages 143163, </pages> <year> 1979. </year>
Reference-contexts: Invocation latency is the time from application invocation to when execution of the program actually begins. Research has shown that invocation latency is crucial in how users view the performance of an application. Early work investigated the effect of time-sharing systems on productivity (e.g., see <ref> [6] </ref>), and concluded, among other things, that increased system response time disrupted user thought processes. More recent work focuses on the effect of transmitting video over the Web, and contrasts the negative impact of unpredictable Web latency with earlier systems in which latency was more predictable [15].
Reference: [7] <author> Jens Ernst, William Evans, Christopher W. Fraser, Steven Lucco, and Todd A. Proebsting. </author> <title> Code compression. </title> <booktitle> In Proceedings of the SIG-PLAN'97 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 358365, </pages> <address> Las Vegas, NV, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: An alternative and complementary approach is to reduce the quantity of data transferred through compression (i.e., latency avoidance). Several approaches to compression have been proposed to reduce network delay in mobile execution environments, and we discuss those here. Ernst et al. <ref> [7] </ref> describe an executable representation called BRISC that is comparable in size to gzipped x86 executables and can be interpreted without decompression.
Reference: [8] <author> Michael Franz and Thomas Kistler. </author> <title> Slim binaries. </title> <journal> Communications of the ACM, </journal> <volume> 40(12):87103, </volume> <month> December </month> <year> 1997. </year>
Reference-contexts: Both of these approaches are directed at reducing the size of the actual code, and do not attempt to compress the associated data. Franz describes a format called slim binaries in which programs are represented in a high-level tree-structured intermediate format, and compressed for transmission across a wire <ref> [8] </ref>. The compression factor with slim binaries is comparable to that reported by Ernst et al., however Franz' reports results for compression of entire executables and not just code segments. Additional work on code compression includes [9, 18, 27].
Reference: [9] <author> Christopher W. Fraser and Todd A. Proebsting. </author> <title> Custom instruction sets for code compression. </title> <note> Available at: http://www.cs.arizona.edu/people/todd/papers/pldi2.ps, October 1995. </note>
Reference-contexts: The compression factor with slim binaries is comparable to that reported by Ernst et al., however Franz' reports results for compression of entire executables and not just code segments. Additional work on code compression includes <ref> [9, 18, 27] </ref>. Our work is distinct from, and complementary to, code compression techniques as the approaches mentioned do not attempt to reorganize the code and data that is being compressed.
Reference: [10] <author> N. Gloy, T. Blockwell, M.D. Smith, and B. Calder. </author> <title> Procedure placement using temporal ordering information. </title> <booktitle> In 30th International Symposium on Microarchitecture, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: More recently, as memory sizes have increased, interest has shifted to improving both temporal and spatial locality for all levels of memory. Many software techniques have been developed for improving instruction cache performance. Techniques such as basic block re-ordering [14, 22], function grouping <ref> [10, 12, 14, 22] </ref>, reordering based on control structure [20], and reordering of system code [25] have all been shown to significantly improve instruction cache performance.
Reference: [11] <author> J. Gosling and McGilton H. </author> <title> The Java Language Environment: A white paper. In Sun Microsystems, </title> <publisher> Inc., </publisher> <address> White Paper, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: To amortize the cost of network transfer to the execution site, code execution should occur concurrently with (i.e., overlap) code and data transfer. However, existing mobile execution facilities such as those provided by the Java programming environment <ref> [11] </ref> typically enforce strict execution semantics as part of their runtime systems. Strict execution requires a program and all of its potentially accessible data to fully transfer before execution can begin. The advantage of this execution paradigm is that it enables secure interpretation and straightforward linking and verification.
Reference: [12] <author> Amir H. Hashemi, David R. Kaeli, and Brad Calder. </author> <title> Efficient procedure mapping using cache line coloring. </title> <booktitle> In Proceedings of the SIG-PLAN'97 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 171182, </pages> <address> Las Vegas, NV, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: More recently, as memory sizes have increased, interest has shifted to improving both temporal and spatial locality for all levels of memory. Many software techniques have been developed for improving instruction cache performance. Techniques such as basic block re-ordering [14, 22], function grouping <ref> [10, 12, 14, 22] </ref>, reordering based on control structure [20], and reordering of system code [25] have all been shown to significantly improve instruction cache performance.
Reference: [13] <author> D. J. </author> <title> Hatfield. Experiments on page size, program access patterns, and virtual memory performance. </title> <journal> IBM Journal of Research and Development, </journal> <pages> pages 5866, </pages> <month> January </month> <year> 1972. </year>
Reference-contexts: For example, if procedures are referenced at approximately the same time, then they are placed on the same page. Attempts to understand and exploit reference patterns of code and data have resulted in such algorithms as least recently used page replacement (e.g., see <ref> [2, 13] </ref>) and Denning's working set model [5]. More recently, as memory sizes have increased, interest has shifted to improving both temporal and spatial locality for all levels of memory. Many software techniques have been developed for improving instruction cache performance.
Reference: [14] <author> W. W. Hwu and P. P. Chang. </author> <title> Achieving high instruction cache performance with an optimizing compiler. </title> <booktitle> Proceedings of the16th International Symposium on Computer Architecture, </booktitle> <pages> pages 242251, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: More recently, as memory sizes have increased, interest has shifted to improving both temporal and spatial locality for all levels of memory. Many software techniques have been developed for improving instruction cache performance. Techniques such as basic block re-ordering <ref> [14, 22] </ref>, function grouping [10, 12, 14, 22], reordering based on control structure [20], and reordering of system code [25] have all been shown to significantly improve instruction cache performance. <p> More recently, as memory sizes have increased, interest has shifted to improving both temporal and spatial locality for all levels of memory. Many software techniques have been developed for improving instruction cache performance. Techniques such as basic block re-ordering [14, 22], function grouping <ref> [10, 12, 14, 22] </ref>, reordering based on control structure [20], and reordering of system code [25] have all been shown to significantly improve instruction cache performance.
Reference: [15] <author> Chris Johnson. </author> <title> Human Factors and Web Development, chapter 16: The Ten Golden Rules for Providing Video Over the Web or 0% of 2.4M (at 270k/sec, 340 sec remaining), </title> <publisher> pages 207221. Lawrence Erlbaum Associates, Publishers, </publisher> <address> Mahwah, New Jersey, </address> <year> 1998. </year>
Reference-contexts: More recent work focuses on the effect of transmitting video over the Web, and contrasts the negative impact of unpredictable Web latency with earlier systems in which latency was more predictable <ref> [15] </ref>. Network transfer delays can result in significant invocation latency and the communication delay can dominate execution time of mobile applications. To amortize the cost of network transfer to the execution site, code execution should occur concurrently with (i.e., overlap) code and data transfer.
Reference: [16] <author> Han Bok Lee. </author> <title> BIT: Bytecode instrumenting tool. </title> <type> Master's thesis, </type> <institution> University of Colorado, Boulder, Department of Computer Science, University of Colorado, Boulder, CO, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: If this information has not arrived, then execution is stalled until the necessary transfer completes. 6 Experimental Methodology To evaluate non-strict execution for Java, we used a bytecode instrumentation tool called BIT <ref> [16, 17] </ref>. The BIT interface enables elements of the bytecode class files, such as bytecode instructions, basic blocks and procedures, to be queried and manipulated. We use BIT to generate our first-use profiles, to perform the reordering, and to simulate the execution of the restructured class files.
Reference: [17] <author> Han Bok Lee and Benjamin G. Zorn. </author> <title> BIT: A tool for instrumenting java bytcodes. </title> <booktitle> In Proceedings of the 1997 USENIX Symposium on Internet Technologies and Systems (USITS97), </booktitle> <pages> pages 7382, </pages> <address> Monterey, CA, </address> <month> December </month> <year> 1997. </year> <institution> USENIX Association. </institution>
Reference-contexts: If this information has not arrived, then execution is stalled until the necessary transfer completes. 6 Experimental Methodology To evaluate non-strict execution for Java, we used a bytecode instrumentation tool called BIT <ref> [16, 17] </ref>. The BIT interface enables elements of the bytecode class files, such as bytecode instructions, basic blocks and procedures, to be queried and manipulated. We use BIT to generate our first-use profiles, to perform the reordering, and to simulate the execution of the restructured class files. <p> The programs were chosen based on the large number of bytecodes contained in each. The programs are well known and have been used in previous studies to evaluate tools such as Java compilers, decompilers, profilers, bytecode to binary, and bytecode to source translators <ref> [17, 24] </ref>. Table 2 shows the general statistics for the benchmarks. For each benchmark we use two inputs, the test input and a smaller train input.
Reference: [18] <author> Charles Lefurgy, Peter Bird, I-Cheng Chen, and Trevor Mudge. </author> <title> Improving code density using compression techniques. </title> <booktitle> In 30th International Symposium on Microarchitecture, </booktitle> <address> Research Triangle Park, NC, </address> <month> December </month> <year> 1997. </year>
Reference-contexts: The compression factor with slim binaries is comparable to that reported by Ernst et al., however Franz' reports results for compression of entire executables and not just code segments. Additional work on code compression includes <ref> [9, 18, 27] </ref>. Our work is distinct from, and complementary to, code compression techniques as the approaches mentioned do not attempt to reorganize the code and data that is being compressed.
Reference: [19] <author> Tim Lindholm and Frank Yellin. </author> <title> The Java Virtual Machine Specification. </title> <publisher> Addison Wesley, </publisher> <year> 1997. </year>
Reference-contexts: While verification and preparation can be performed once the global data is transferred, resolution can be performed lazily as procedures are invoked. 3.1.1 Verification for Non-Strict Java The JVM has five steps in verifying a class file as described in <ref> [19] </ref>. The first two verify the structure of the class file and the global data. Since the global data is the first to transfer, this verification can proceed as soon as the global data is transferred. <p> Table 8 shows the major parts of the class file pertinent to global data and the size of each as a percentage of the total global data size. These fields are described in detail in <ref> [19] </ref>. Since the constant pool takes up a majority of the class file, we also describe the parts of this structure in Table 8.
Reference: [20] <author> S. McFarling. </author> <title> Procedure merging with instruction caches. </title> <booktitle> Proceedings of the ACM SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> 26(6):7179, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Many software techniques have been developed for improving instruction cache performance. Techniques such as basic block re-ordering [14, 22], function grouping [10, 12, 14, 22], reordering based on control structure <ref> [20] </ref>, and reordering of system code [25] have all been shown to significantly improve instruction cache performance. The increasing latency of second-level caches means that expensive cache usage patterns, such as ping-ponging between code laid out on the same cache line, can have dramatic effects on program performance.
Reference: [21] <author> H.F. Nielsen, J. Gettys, A. Baird-Smith, E. Prudhommeau, H.W. Lie, and C. Lilley. </author> <title> Network performance effects of HTTP/1.1, CSS1, </title> <booktitle> and PNG. In ACM Applications, Technologies, Architectures and Protocols for Computer Communication, </booktitle> <month> September </month> <year> 1997. </year>
Reference-contexts: The latest release of the HTTP 1.1 specification uses a single TCP connection. This allows up to four outstanding requests can be made (pipelining) <ref> [21] </ref>. In this vain, we model the transfer of multiple classes at once to assure that methods arrive as near to the predicted start of their execution as possible. The transferring files split the fixed amount of bandwidth available equally.
Reference: [22] <author> K. Pettis and R. C. Hansen. </author> <title> Profile guided code positioning. </title> <booktitle> Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <address> 25(6):1627, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: More recently, as memory sizes have increased, interest has shifted to improving both temporal and spatial locality for all levels of memory. Many software techniques have been developed for improving instruction cache performance. Techniques such as basic block re-ordering <ref> [14, 22] </ref>, function grouping [10, 12, 14, 22], reordering based on control structure [20], and reordering of system code [25] have all been shown to significantly improve instruction cache performance. <p> More recently, as memory sizes have increased, interest has shifted to improving both temporal and spatial locality for all levels of memory. Many software techniques have been developed for improving instruction cache performance. Techniques such as basic block re-ordering [14, 22], function grouping <ref> [10, 12, 14, 22] </ref>, reordering based on control structure [20], and reordering of system code [25] have all been shown to significantly improve instruction cache performance.
Reference: [23] <author> Michael P. Plezbert and Ron K. Cytron. </author> <title> Does just in time = better late than never? In Proceedings of the SIGPLAN'97 Conference on Programming Language Design and Implementation, </title> <month> January </month> <year> 1997. </year>
Reference-contexts: of reorganizing mobile programs for wire transfer, is substantially different, in that we are only concerned with the first use of an object and are (at least in the current work) not concerned with subsequent uses. 2.3 Continuous Compilation The final area of related research is that of continuous compilation <ref> [23] </ref>. Continuous compilation is a method for improving the performance of JustInTime compilers. JustInTime compilation produces executable code just prior to when it is executed.
Reference: [24] <author> Todd A. Proebsting, Gregg Townsend, Patrick Bridges, John H. Hart-man, Tim Newsham, and Scott A. Watterson. Toba: </author> <title> Java for applications a way ahead of time (wat) compiler. </title> <booktitle> In Proceedings of the Third Conference on ObjectOriented Technologies and Systems, </booktitle> <year> 1997. </year>
Reference-contexts: The programs were chosen based on the large number of bytecodes contained in each. The programs are well known and have been used in previous studies to evaluate tools such as Java compilers, decompilers, profilers, bytecode to binary, and bytecode to source translators <ref> [17, 24] </ref>. Table 2 shows the general statistics for the benchmarks. For each benchmark we use two inputs, the test input and a smaller train input.
Reference: [25] <author> J. Torrellas, C. Xia, and R. Daigle. </author> <title> Optimizing instruction cache performance for operating system intensive workloads. </title> <booktitle> In Proceedings of the First International Symposium on High-Performance Computer Architecture, </booktitle> <pages> pages 360369, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: Many software techniques have been developed for improving instruction cache performance. Techniques such as basic block re-ordering [14, 22], function grouping [10, 12, 14, 22], reordering based on control structure [20], and reordering of system code <ref> [25] </ref> have all been shown to significantly improve instruction cache performance. The increasing latency of second-level caches means that expensive cache usage patterns, such as ping-ponging between code laid out on the same cache line, can have dramatic effects on program performance.
Reference: [26] <author> Robert Wahbe, Steven Lucco, Thomas E. Anderson, and Susan L. Graham. </author> <title> Efficient software-based fault isolation. </title> <editor> In Barbara Liskov, editor, </editor> <booktitle> Proceedings of the 14th Symposium on Operating Systems Principles, pages 203216, </booktitle> <address> New York, NY, USA, </address> <month> December </month> <year> 1993. </year> <note> ACM Press. </note>
Reference-contexts: The whole verification process can be avoided by providing a means of trust between the compiler that produced the Java class file and the JVM interpreter. For example, with security mechanisms for digital signatures [3] or software fault isolation <ref> [26] </ref>, the verification step can be skipped completely. 4 First Use Procedure Reordering To capitalize on the benefit achieved from non-strict execution, it is necessary to predict the execution order of the procedures in the program, and then to place them in the class file in this predicted order.
Reference: [27] <author> Andrew Wolfe and Alex Chanin. </author> <title> Executing compressed programs on an embedded risc architecture. </title> <booktitle> In 25th International Symposium on Microarchitecture, </booktitle> <pages> pages 8191, </pages> <year> 1992. </year> <month> 11 </month>
Reference-contexts: The compression factor with slim binaries is comparable to that reported by Ernst et al., however Franz' reports results for compression of entire executables and not just code segments. Additional work on code compression includes <ref> [9, 18, 27] </ref>. Our work is distinct from, and complementary to, code compression techniques as the approaches mentioned do not attempt to reorganize the code and data that is being compressed.
References-found: 27

