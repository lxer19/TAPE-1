URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1992/tr-92-043.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1992.html
Root-URL: http://www.icsi.berkeley.edu
Title: A Symbolic Complexity Analysis of Connectionist Algorithms for Distributed-Memory Machines  
Phone: 1-510-642-4274 FAX 1-510-643-7684  
Author: Jonathan Bachrach 
Date: July 1992  
Address: I 1947 Center Street Suite 600 Berkeley, California 94704  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  
Pubnum: TR-92-043  
Abstract: This paper attempts to rigorously determine the computation and communication requirements of connectionist algorithms running on a distributed-memory machine. The strategy involves (1) specifying key connectionist algorithms in a high-level object-oriented language, (2) extracting their running times as polynomials, and (3) analyzing these polynomials to determine the algorithms' space and time complexity. Results are presented for various implementations of the back-propagation algorithm [4]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Phil Kohn. </author> <title> Connectionist layered object-oriented network simulator (clones): User's manual. </title> <type> Technical Report TR-91-073, </type> <institution> International Computer Science Institute, </institution> <address> 1947 Center Street, Suite 600; Berkeley, California 94704-1105, </address> <year> 1992. </year>
Reference-contexts: The overall design of the data-structures are loosely based on data-structures found in a connectionist simulator called CLONES (Kohn, <ref> [1] </ref>). For the purposes of this paper, a very simple network with one input LAYER and one output LAYER and a CONNECT between them is considered. Each LAYER contains a VECTOR of outputs, errors, and biases and a LOOKUP-TABLE for the transfer function and its derivative.
Reference: [2] <author> Nelson Morgan, James Beck, Phil Kohn, Jeff Bilmes, Eric Allman, and Joachim Beer. </author> <title> The ring array processor: A multiprocessing peripheral for connectionist applications. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 14(3) </volume> <pages> 248-259, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: For transposed-vector-multiply routines for non-DOUBLE-MATRIX's, the intermediate results of local computations must be merged. This merge calculation can be performed efficiently on a ring of processors as discussed in Morgan et. al, <ref> [2] </ref>. Using these VECTOR and MATRIX objects as building blocks, there are eight possible combinations of networks as shown below: local distributed fi dense sparse fi single double : The local/distributed distinction applies to all objects, while the dense/sparse and single/double distinctions apply only to MATRIX objects.
Reference: [3] <author> Stephen M. Omohundro. </author> <title> The sather language. Unpublished Manual, </title> <booktitle> International Computer Science Institute, </booktitle> <address> 1947 Center Street, Suite 600; Berkeley, California 94704-1105, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: As an example, the average time to complete a VECTOR addition of length n would be n (2r + w + a). The Sather code for this example is shown in Table 3. The algorithms are coded in an object-oriented programming language called Sather (Omohundro, <ref> [3] </ref>). There are objects for all the connectionist data structures such as VECTOR's, MATRIX's, LAYER's, CONNECT's, and NETWORK's. Each object has a set of routines that define the object's allowable routines. Objects are composed out of other objects in the usual manner.
Reference: [4] <author> David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart and J. L. McClel-land, editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, vol.1: Foundations. </booktitle> <publisher> Bradford Books/MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: algorithm on a n fi n sized network on one processor and T (n; p) is the time to run the algorithm on a n fi n sized network on p processors? 3 Algorithms and Data-Structures The focus of this paper is on the standard back-propagation algorithm (Rumelhart et. al, <ref> [4] </ref>). The overall design of the data-structures are loosely based on data-structures found in a connectionist simulator called CLONES (Kohn, [1]). For the purposes of this paper, a very simple network with one input LAYER and one output LAYER and a CONNECT between them is considered.
Reference: [5] <author> Stephen Wolfram. </author> <title> Mathematica. </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year> <month> 19 </month>
Reference-contexts: The POLYNOMIAL class and its subclasses are show in Figure 1. Every POLYNOMIAL class has a numeric value, can evaluate itself with eval, can output itself (using print) in a suitable form for inputting to Mathematic (Wolfram, <ref> [5] </ref>), and can build compound POLYNOMIAL's us 1 Name Binding Description a 1 Primitive arithmetic routine r 1 Single word memory read w 1 Single word memory write i 8 Network routine initiation x 8 Network transfer time / word Table 2: The constants used in time polynomials, representing the average
References-found: 5

