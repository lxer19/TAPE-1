URL: http://www.cs.tu-berlin.de/techreports/kit/documents/Quantz/jelia92.ps.gz
Refering-URL: http://www.cs.tu-berlin.de/techreports/
Root-URL: 
Phone: 2  
Title: Deriving Inference Rules for Terminological Logics  
Author: In D. Pearce, G. Wagner V eronique Royer and J. Joachim Quantz 
Address: Onera-Cert, 2 av. Edouard Belin, BP 4025, F-31055 Toulouse  Berlin, KIT-BACK, FR 5-12, Franklinstr. 28/29, W-1000 Berlin 10  
Affiliation: 1  Technische Universitat  
Note: (eds), Logics in AI, Proceedings of JELIA'92, Berlin: Springer, LNAI 633, 1992, pp. 84-105  
Abstract: Terminological Logics can be investigated under different perspectives. The aim of this paper is to provide the basis for a tighter combination of theoretical investigations with issues arising in the actual implementation of terminological representation systems. We propose to use inference rules, derived via the sequent calculus, as a new method for specifying terminological inference algorithms. This approach combines the advantages of the tableaux methods and the normalize-combine algorithms that have been predominant in terminological proof theory so far. We first show how a completeness proof for the inference rules of a relatively restricted terminological logic can be given. We then show how these inference rules can be used to construct normalize-compare algorithms and prove their completeness. Furthermore, these rules can be used in two ways for the characterization of terminological representation systems: first, the incompleteness of of systems can be documented by listing those rules that have not been implemented; second, the reasoning strategy can be described by spesifying which rules are applied forward and which backward.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> K.Apt, H.Blair, A.Walker, </author> <title> Toward a Theory of Declarative Knowledge, </title> <booktitle> in Workshop on Foundations of Deductive Databases, </booktitle> <year> 1986 </year>
Reference-contexts: The semantics of deductive databases is defined by the closure of the extensional part (the factual information) under a so-called immediate consequence operator which formalizes the execution in forward chaining of the database rules <ref> [1, 14] </ref>. The task of specifying an inference relation ` T L for a terminological logic would thus consist in specifying a set of inferences rules, whose closure computes the set of all TL-formulas terminologically entailed by some given set of TL-formulas.
Reference: 2. <author> A.Avron, </author> <title> Simple Consequence Relations, </title> <booktitle> Information and Computation 92, </booktitle> <pages> 105-139, </pages> <year> 1991 </year>
Reference-contexts: This is not satisfactory enough from the point of view of computation: this closure is better characterized proof-theoretically, by an inference relation ` T L . This concept is seen as more and more fundamental in modern treatments of logic <ref> [2] </ref>. Such proof-theoretic considerations meet also the least fixed point semantics approach which is especially popular in the field of deductive databases.
Reference: 3. <author> J.Castaing, </author> <title> A New Formalisation of Subsumption in Frame-based Representation System, </title> <booktitle> in KR'91, </booktitle> <pages> 78-88 </pages>
Reference-contexts: In <ref> [3] </ref> the Linear Sequent Calculus 9 was used to formalize a tractable notion of subsumption. Namely, the author defined subsumption to be linear sequent entailment: AvB is by definition the sequent 8 (x)A (x) ) 9xB (y) in Linear Sequent Calculus (a translation which is less than natural).
Reference: 4. <author> C.L. Chang, R.C.T. Lee (eds), </author> <title> Symbolic Logic and Mechanical Theorem Proving, </title> <address> New York: </address> <publisher> Academic Press, </publisher> <year> 1973 </year>
Reference: 5. <author> F.M. Donini, M. Lenzerini, D. Nardi, W. Nutt, </author> <title> The Complexity of Concept Languages, </title> <booktitle> KR'91, </booktitle> <pages> 151-162 </pages>
Reference-contexts: Thus in the current BACK implementation (cf. [17]) the subsumption relations between all concepts and roles of the terminology 4 See [15] for a discussion of these aspects. 5 Confer, for example, [13]. 6 Confer, for example, <ref> [5] </ref> and [6]. 86 are computed and stored, as well as the most special description for each object.
Reference: 6. <author> F.M. Donini, M. Lenzerini, D. Nardi, W. Nutt, </author> <title> Tractable Concept Languages IJCAI'91, </title> <type> 458-463 </type>
Reference-contexts: Thus in the current BACK implementation (cf. [17]) the subsumption relations between all concepts and roles of the terminology 4 See [15] for a discussion of these aspects. 5 Confer, for example, [13]. 6 Confer, for example, [5] and <ref> [6] </ref>. 86 are computed and stored, as well as the most special description for each object.
Reference: 7. <author> J.Gallier, </author> <title> Logic for Computer Science; Foundations of Automatic Theorem Proving, </title> <address> New York: </address> <publisher> Harper and Row, </publisher> <year> 1986 </year>
Reference-contexts: Relying on other Sequent Calculi is quite possible but would characterize non-classical terminological entailments. 3 Translation of Terminological Formulas into First-Order Sequents 3.1 Classical Sequent Calculus We assume that the reader is familiar with Gentzen's Sequent Calculi (e.g., <ref> [7, 9, 10] </ref>). The main advantages for using Sequent Calculi lies in their systematic and principled approach to Proof Theory. Indeed, the proof process in Sequent Calculi is seen as a morphism of the set of formulas into the set of proofs. <p> We list the rules of the Sequent Calculus in Fig. 1, where a stands for a parameter (called eigen-parameter or eigen-variable) which does not appear in the lower sequent; t stands for a term appearing in the lower sequent (thus we consider pure proofs <ref> [7] </ref>). 3.2 The Translation Function We take the classical principles for the translation of TL-formulas into FOL-formulas [19]. <p> Proposition 5. The lifting process is complete for the rules relative to quantor formulas. Proof (Sketch). The proof relies on the normalisation property for the proofs in classical Sequent Calculus <ref> [7] </ref> which states that a sequent ) is provable in first-order Sequent Calculus iff there is an intermediate sequent 0 0 such that: 1. ) is provable propositionally (i.e., in the propositional fragment of SC). 2. ) reduces to the sequent 0 0 by quantification rules (or structural rules different from <p> One classical condition is that the sequents contain only prenex formulas, which is not the case with the terminological sequents. We rely here on a more general version of the normalization theorem for formulas in negation normal form NNF, 13 (cf. <ref> [7, Chap. 7] </ref>). The theorem also uses a more general version of the quantifier rules (quantifier rules for subformulas). To apply the NNF normalization theorem, we have to show that terminological sequents can be put into negation normal form.
Reference: 8. <author> J.Y.Girard, </author> <title> Linear Logic, </title> <booktitle> Theoretical Computer Science 50, </booktitle> <pages> 1-102, </pages> <year> 1987 </year>
Reference-contexts: Given the terminological language T L SAN , the set of concept-names and primitive 9 A sequent calculus for Linear Logic <ref> [8] </ref>. 88 Operator left-rule right-rule Weakening ) ;ff) );ff Contraction ;ff;ff) ;ff) )ff; Axiom/Cut-Rule ; ff ) ; ff 1 ;ff) 1 ; 2 ) 2 ;ff _ ;ff) ;;fi) );ff_fi ^ ;ff;fi) );ff ; );fi ! ;fi) ; )ff; ;ff);fi : ;ff) );ff 8 ;8xA (x)) );8xA (x) ;A (a))
Reference: 9. <author> J.Y.Girard, Y.Laffont, P.Taylor, </author> <title> Proofs and Types, </title> <publisher> Cambridge: Cambridge University Press, </publisher> <year> 1989 </year>
Reference-contexts: Relying on other Sequent Calculi is quite possible but would characterize non-classical terminological entailments. 3 Translation of Terminological Formulas into First-Order Sequents 3.1 Classical Sequent Calculus We assume that the reader is familiar with Gentzen's Sequent Calculi (e.g., <ref> [7, 9, 10] </ref>). The main advantages for using Sequent Calculi lies in their systematic and principled approach to Proof Theory. Indeed, the proof process in Sequent Calculi is seen as a morphism of the set of formulas into the set of proofs. <p> In classical first-order Sequent Calculus the subformula property relies on the Cut Elimination theorem, we recall just below. Proposition 1 Cut Elimination Theorem <ref> [9] </ref>. Let S be a set of sequents (proper axioms) and s an individual sequent.
Reference: 10. <author> G. Sundholm, </author> <title> Systems of Deduction, </title> <editor> in D.Gabbay, F.Guenthner (eds), </editor> <booktitle> Handbook of Philosophical Logic, </booktitle> <volume> Vol. I, </volume> <publisher> Dordrecht: Reidel, </publisher> <pages> 133-188, </pages> <year> 1983 </year>
Reference-contexts: Relying on other Sequent Calculi is quite possible but would characterize non-classical terminological entailments. 3 Translation of Terminological Formulas into First-Order Sequents 3.1 Classical Sequent Calculus We assume that the reader is familiar with Gentzen's Sequent Calculi (e.g., <ref> [7, 9, 10] </ref>). The main advantages for using Sequent Calculi lies in their systematic and principled approach to Proof Theory. Indeed, the proof process in Sequent Calculi is seen as a morphism of the set of formulas into the set of proofs. <p> By using the !-rule we get the simpler equivalent sequent: C 1 (a) ) C 2 (a). In the literature the constant symbol a is called the eigen-parameter of the universal formula <ref> [10] </ref>. Each application of 8-right gives rise to a new different eigen-parameter. Definition 4. A concept will be called prime iff it is a concept-name or a concept of the form (q r.c) for some quantor q.
Reference: 11. <author> C. Kindermann, </author> <title> Class Instances in a Terminological Framework-an Experience Report, </title> <editor> in H. Marburger (ed.), </editor> <booktitle> Proc. of GWAI-90, </booktitle> <address> Berlin: </address> <publisher> Springer, </publisher> <pages> 48-57, </pages> <year> 1990 </year>
Reference-contexts: the equivalence with a fragment of Sequent Calculus corresponding to the embedding of TL (more exactly, we prove completeness by showing that every proof in Sequent Calculus of fl can be rewritten into a derivation of fl using the inference rules). 7 Kindermann compares implementation strategies for retrieval support in <ref> [11] </ref>. 8 For details see next section. 87 Remark. In [3] the Linear Sequent Calculus 9 was used to formalize a tractable notion of subsumption.
Reference: 12. <author> R.M. MacGregor, D. Brill, </author> <title> Recognition Algorithms for the Loom Classifier, </title> <note> to appear in AAAI-92 </note>
Reference-contexts: Note that we do not claim that our normal forms are optimal for TL-systems. Indeed we think that the determination of adequate normal forms is one of the most important topics in the development of TL-systems and has to rely on empirical studies (cf., for example <ref> [12] </ref>). All we want to show is that the completeness of normalize-compare algorithms can be proved via completeness of inference rules. Before presenting NORM we will slightly change our notation for terms.
Reference: 13. <author> B. Nebel, </author> <title> Reasoning and Revision in Hybrid Representation Systems, </title> <publisher> Berlin: Springer, </publisher> <year> 1990 </year>
Reference-contexts: (3) [[8r:c]] I = fd 2 D : [[r]] I (d) [[c]] I g (5) Satisfaction of formulas is then defined as follows: M j= t n = t iff [[t n ]] I = [[t]] I (7) M j= o : c iff [[o]] 2 [[c]] (9) 3 See <ref> [13, p. 54ff] </ref> for the role of primitive components. 85 A structure M is a model of a formula fl iff M j= fl; it is a model of a set of formulas iff it is a model of every formula in . <p> Thus in the current BACK implementation (cf. [17]) the subsumption relations between all concepts and roles of the terminology 4 See [15] for a discussion of these aspects. 5 Confer, for example, <ref> [13] </ref>. 6 Confer, for example, [5] and [6]. 86 are computed and stored, as well as the most special description for each object. <p> Our subsumption algorithm, which is similar to the one presented by Nebel in <ref> [13] </ref>, will consist of two parts, namely a normalization part NORM and a comparison part COMP. NORM transforms a term t into a normal form n and COMP compares two normal forms. <p> In order to talk about subsumption between normal forms and atomic restrictions we need the inverse of " which maps normal forms and atomic restrictions into concepts: 16 This is called abstraction from term introductions in <ref> [13, p. 60] </ref>. 100 Definition 11. #fa 1 ; : : : ; a n g = #a 1 u : : : u #a n (70) def #8r:n = 8 #r: #n (72) def Clearly, this switch between terms and sets is meaning preserving: Lemma 12.
Reference: 14. <author> R.Kowalski, M.H.Van Emden, </author> <title> The Semantics of Predicate Logic as a Programming Language, </title> <journal> Journal of ACM 23(4), </journal> <year> 1976 </year>
Reference-contexts: The semantics of deductive databases is defined by the closure of the extensional part (the factual information) under a so-called immediate consequence operator which formalizes the execution in forward chaining of the database rules <ref> [1, 14] </ref>. The task of specifying an inference relation ` T L for a terminological logic would thus consist in specifying a set of inferences rules, whose closure computes the set of all TL-formulas terminologically entailed by some given set of TL-formulas.
Reference: 15. <author> J. Quantz, </author> <title> Modeling and Reasoning with Defined Roles in BACK, </title> <type> KIT-Report 84, </type> <institution> Technische Universitat Berlin, </institution> <year> 1990 </year>
Reference-contexts: Given such a framework it is advantageous to precompute information that is implicitly given in order to speed up the query-answering in the retrieval phase. Thus in the current BACK implementation (cf. [17]) the subsumption relations between all concepts and roles of the terminology 4 See <ref> [15] </ref> for a discussion of these aspects. 5 Confer, for example, [13]. 6 Confer, for example, [5] and [6]. 86 are computed and stored, as well as the most special description for each object.
Reference: 16. <author> J. Quantz, </author> <title> How to Fit Generalized Quantifiers into Terminological Logics, </title> <note> to appear in ECAI-92 </note>
Reference-contexts: :c 2 (54) c 1 v c 2 ; r 1 v r 2 * :9r 2 :c 2 v :9r 1 :c 1 (56) The proofs being all similar, we only give the proof for inference rule 54. 15 These rules reflect the monotonicity properties of the quantifiers (cf. <ref> [16] </ref>). 96 Proof. Provability of ) 8xC 1 (x) ! C 2 (x) is equivalent to provability of C 1 (b) ) C 2 (b). The expansion rule allows to introduce a role term R 1 (a; b) in the left-hand side of the sequent.
Reference: 17. <author> J. Quantz, C. </author> <title> Kindermann Implementation of the BACK System Version 4, </title> <type> KIT Report 78, </type> <institution> Technische Universitat Berlin, </institution> <year> 1990 </year>
Reference-contexts: Given such a framework it is advantageous to precompute information that is implicitly given in order to speed up the query-answering in the retrieval phase. Thus in the current BACK implementation (cf. <ref> [17] </ref>) the subsumption relations between all concepts and roles of the terminology 4 See [15] for a discussion of these aspects. 5 Confer, for example, [13]. 6 Confer, for example, [5] and [6]. 86 are computed and stored, as well as the most special description for each object. <p> As an example, consider value restrictions, i.e. terms 8r.c. In BACK V4 for each concept the value restriction at each relevant role is computed and stored <ref> [17] </ref>. This value restriction is used in comparing the concepts and also for forward propagation to role fillers. In the following we will restrict ourselves to the problem of subsumption with respect to a set of cycle-free definitions.
Reference: 18. <author> V. Royer, J. Quantz, </author> <title> Deriving Inference Rules for Terminological Logics: a Rewriting Approach into Sequent Calculi. </title> <note> KIT Report in preparation </note>
Reference-contexts: We are currently applying the method developed in this paper to the terminological logic of BACK V5 and intend to present the results in <ref> [18] </ref>. The following specifies the syntax T L SAN . We use t i to denote terms in general, c i and r i to denote concepts and roles respectively. <p> The derivation is easy but rather long because it proceeds by a systematic case analysis of the possible quantor structure for C 1 and C 2 . We just give some technical details of the derivation (the complete proof can be found in <ref> [18] </ref>). Derivation Method. Let us suppose that we have to prove the terminological formula c 1 v c 2 t c 3 , represented by the sequent S = C 1 (a) ) C 2 (a); C 3 (a) for some eigen-parameter a. <p> * ) 9r 1 :c 1 u :9r 2 :c 2 v ? (46) Exploiting systematically the negation duality, we can still derive the additional rules 48 and 49 (which follow easily from the precedent ones if we had an explicit negation rule for more details see the complete paper <ref> [18] </ref>). <p> (some R 2 C 2 )(a) ` SC ) 8x (some R 1 C 1 )(x) ! (some R 2 C 2 )(x)) ` T L 9r 1 :c 1 v 9r 2 :c 2 Note that the inference rules are reversible when inconsistent roles and concepts are excluded (see <ref> [18] </ref> for details). Lifting Axioms c 1 u c 2 v c3. We now lift conjunctive axioms of the form: c 1 u c 2 v c 3 . So we start with the sequent C 1 (b); C 2 (b) ) C 3 (b). <p> of definitions, i.e., does not contain any rules. (We emphasize again that this is only one reasoning task among others in TL-systems, though an important one.) Due to this restriction we can ignore the inference rules 36 to 39 and the ) direction for 46, 47, 52, and 53 (see <ref> [18] </ref> for details). Our subsumption algorithm, which is similar to the one presented by Nebel in [13], will consist of two parts, namely a normalization part NORM and a comparison part COMP. NORM transforms a term t into a normal form n and COMP compares two normal forms. <p> This approach can be extended to more expressive languages. Due to the introduction of equality axioms by the translation of qualified number-restrictions, however, completeness proofs for languages containing these constructs will be a lot harder to achieve (cf. <ref> [18] </ref>). From an implementation-oriented point of view the terminological inference rules can be used for several purposes. The most obvious is to check the completeness of a terminological representation system. Furthermore, incomplete representation systems can be compared by pointing out which rules have been implemented and which have not.
Reference: 19. <author> J. Schmolze, D. Israel, </author> <title> KL-ONE: Semantics and Classification, in Research in Knowledge Representation and Natural Language Understanding, BBN Annual Report 5421, 27-39 1983 This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: where a stands for a parameter (called eigen-parameter or eigen-variable) which does not appear in the lower sequent; t stands for a term appearing in the lower sequent (thus we consider pure proofs [7]). 3.2 The Translation Function We take the classical principles for the translation of TL-formulas into FOL-formulas <ref> [19] </ref>.
References-found: 19

