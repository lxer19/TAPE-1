URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-92-41.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Note: This work is partially funded by NSF grant ASC-9201822.  
Abstract: The Good News About Dynamic Object-Oriented Parallel Processing Andrew S. Grimshaw,W. Timothy Strayer,Padmini Narayan Technical Report No. CS-92-41 December 17, 1992 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. S. Grimshaw, </author> <title> Easy to Use Object-Oriented Parallel Programming with Mentat, </title> <note> to appear in IEEE Computer, </note> <month> May, </month> <year> 1993. </year>
Reference-contexts: By combining the object-oriented paradigm with parallel processing compiler and run-time system technology, the task of writing high-performance parallel software can be simplified. Mentat <ref> [1] </ref> is an object-oriented parallel processing system that addresses the need for easy-to-use tools that facilitate the construction of portable medium-grain parallel software. Mentat extends an existing object-oriented language, C++, with mechanisms that allow the programmer to indicate which application classes are sufficiently computationally complex to warrant parallel execution.
Reference: [2] <author> C. </author> <title> Polychronopoulos, </title> <publisher> Parallel Programming and Compilers,Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: 1. Introduction Writing software for parallel processing systems has proven to be more difficult than writing sequential software. In the early 1980s it was believed that automatic parallelization tools could be constructed that would automate the process of turning dusty deck sequential programs, usually written in FORTRAN, into parallel codes <ref> [2] </ref>. These tools have been somewhat successful when targeted to tightly coupled shared memory systems, yet the results are disappointing for the greater challenge of the distributed memory systems that have come to dominate the field of parallel processing.
Reference: [3] <author> A. S. Grimshaw and V. E. Vivas, </author> <title> FALCON: A Distributed Scheduler for MIMD Architectures, </title> <booktitle> Proceedings of the Symposium on Experiences with Distributed and Multiprocessor Systems, </booktitle> <pages> pp. 149-163, </pages> <address> Atlanta, GA, </address> <month> March, </month> <year> 1991. </year>
Reference-contexts: The network of workstations, however, cannot be dedicated in that way, so we try to factor out transient interference; the best times reect more closely a dedicated system. Some of the irregularities seen in the graphs are due to the algorithm used by the Mentat scheduler <ref> [3] </ref>.
Reference: [4] <author> T. F. Smith and M. S. Waterman, </author> <title> Identification of common molecular subsequences, </title> <journal> J. Mol. Biol., </journal> <volume> 147, </volume> <pages> pp. 195-197, </pages> <year> 1981. </year>
Reference-contexts: Biologists want to know the degree of relationship of two sequences. Two given sequences are compared and, using one of several algorithms, a score is generated reecting commonality. Three popular algorithms are Smith-Waterman <ref> [4] </ref>, FASTA [5], and Blast [6]. The latter two algorithms are heuristics; the quality of the score is traded for speed. Smith-Waterman is the benchmark algorithm, generating the most reliable scores although at considerable time expense.
Reference: [5] <author> W. R. Pearson and D. Lipman, </author> <title> Improved tools for biological sequence analysis, </title> <booktitle> Proc. </booktitle> <institution> Natl. Acad. Sci. USA, </institution> <month> 85, </month> <pages> pp. 2444-2448, </pages> <year> 1988. </year>
Reference-contexts: Biologists want to know the degree of relationship of two sequences. Two given sequences are compared and, using one of several algorithms, a score is generated reecting commonality. Three popular algorithms are Smith-Waterman [4], FASTA <ref> [5] </ref>, and Blast [6]. The latter two algorithms are heuristics; the quality of the score is traded for speed. Smith-Waterman is the benchmark algorithm, generating the most reliable scores although at considerable time expense.
Reference: [6] <author> S. F. Altschul, W. Gish, W. Miller, E. W. Myers, D. J. Lipman, </author> <title> Basic local alignment search tool, </title> <journal> J. Mol. Biol., </journal> <volume> 215, </volume> <pages> pp. 403-410, </pages> <year> 1990. </year>
Reference-contexts: Biologists want to know the degree of relationship of two sequences. Two given sequences are compared and, using one of several algorithms, a score is generated reecting commonality. Three popular algorithms are Smith-Waterman [4], FASTA [5], and Blast <ref> [6] </ref>. The latter two algorithms are heuristics; the quality of the score is traded for speed. Smith-Waterman is the benchmark algorithm, generating the most reliable scores although at considerable time expense.
Reference: [7] <author> A. S. Grimshaw, E. A. West, and W.R. Pearson, </author> <title> No Pain and Gain! - Experiences with Mentat on Biological Application, </title> <booktitle> Proceedings of the First Symposium on High-Performance Distributed Computing, </booktitle> <pages> pp. 57-66, </pages> <address> Syracuse, NY, </address> <month> Sept., </month> <year> 1992. </year>
Reference-contexts: Performance Performance on this application clearly demonstrates that for naturally data-parallel applications with no inter-worker communication and little worker-master communication, neither the object-oriented paradigm nor dynamic management of parallelism seriously affect performance. Indeed, in <ref> [7] </ref> we show 1 // master program routine -- initialization details omitted 2 // -- get the number of workers 3 // -- divide the library into a partition for each worker 4 5 sw_worker worker; 6 // invoke the comparison for each partition of the library 7 for (i = <p> Table 3 shows the Mentat performance of Gaussian Elimination and scanlib compared to results from hand-coded versions given in [20] and <ref> [7] </ref>. The Mentat version compares well with the hand-coded versions. 5. Summary and Future Work Overhead is the friction of parallel processing. The dynamic detection and management of parallelism, the use of the object-oriented paradigm, and the use of a virtual machine all contribute to overhead in Mentat.
Reference: [8] <author> M. J. Quinn, </author> <title> Designing Efficient Algorithms For Parallel Computers, </title> <publisher> McGraw-Hill Book Company, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Image convolution was chosen because it is an intuitive member of a class of algorithms called stencil algorithms. Other stencil algorithms include Jacobi iteration and many partial differential equation solvers <ref> [8] </ref>. In stencil algorithms, the next value of a point in space is a function of its neighboring points. Exactly which neighbors contribute to the next value of a (b) Smith-Waterman on the Intel iPSC/2 (a) Smith-Waterman on the Sparc IPC network 15 given point is determined by the stencil.
Reference: [9] <author> P. Lemkin, </author> <type> Personal Communication, </type> <month> April, </month> <year> 1992. </year> <month> 34 </month>
Reference-contexts: However, for realistic size images, e.g., 512 512 and up, we have found this not to be a problem. Figure 12 presents performance data for convolving 512 512, 1024 1024, and 2048 2048 two dimensional electrophoresis gel images obtained from the National Cancer Institute <ref> [9] </ref>. We cannot positively explain the bumps in the iPSC/2 graph. We believe that they are an artifact of placement decisions made by the scheduler. Currently the scheduler does not use application topology information in placing objects. This can result in poor placement decisions.
Reference: [10] <author> A.S. Grimshaw, J.B.Weissman, </author> <title> and E.A. West, Meta Systems: An Approach Combining Parallel Processing And Heterogeneous Distributed Computing Systems, </title> <note> Submitted to Journal of Parallel and Distributed Computing. </note>
Reference-contexts: At this point the problem has been partitioned into the optimum grain size for the architecture. Adding additional workers will decrease the grain size below optimum, and therefore, decrease speedup. This is clearly visible in the graphs. Currently, finding the optimum operating point is the programmers responsibility. In <ref> [10] </ref> we present techniques still in their formative stages that automate this process. How significant are the overhead costs? If overhead costs, including communication, were zero, then the performance curves would not hit a maximum and then decline (as long as N is much greater than the number of workers).
Reference: [11] <author> L. </author> <title> Pointer, (ed). </title> <type> Perfect Report 1, </type> <institution> Center for Supercomputing Research & Development, Univ. Illinois, Champaign-Urbana, IL. </institution> <month> July </month> <year> 1989. </year>
Reference-contexts: First, it is rare for two different projects to implement and publish performance results that are comparable. The applications differ, the problem sizes differ, and the platforms upon which the results were gathered differ. In theory benchmark suites such as the Perfect club <ref> [11] </ref> and SLALOM [12] provide an even playing field on which to compare systems. Unfortunately there are no C++ benchmark standards of which we are aware. Another problem with benchmark suites are that they are usually toy problems.
Reference: [12] <author> J. Gustafson, D. Rover, S. ELbert, and M. Carter, SLALOM: </author> <title> The First Scalable Supercomputing Benchmark, </title> <institution> Ames Laboratory, Ames, </institution> <address> IA 50011-3020. </address>
Reference-contexts: First, it is rare for two different projects to implement and publish performance results that are comparable. The applications differ, the problem sizes differ, and the platforms upon which the results were gathered differ. In theory benchmark suites such as the Perfect club [11] and SLALOM <ref> [12] </ref> provide an even playing field on which to compare systems. Unfortunately there are no C++ benchmark standards of which we are aware. Another problem with benchmark suites are that they are usually toy problems.
Reference: [13] <author> B. Beck, </author> <title> Shared Memory Parallel Programming in C++, </title> <journal> IEEE Software, </journal> <pages> 7(4) pp. 38-48, </pages> <month> July, </month> <year> 1990. </year>
Reference: [14] <author> B. N. Bershad, E. D. Lazowska, and H. M. Levy, </author> <title> Presto: A System for Object-Oriented Parallel Programming, </title> <journal> Software - Practice and Experience, </journal> <volume> 18(8), </volume> <pages> pp. 713-732, </pages> <month> August, </month> <year> 1988. </year>
Reference-contexts: Futures may not be passed to other remote invocations, limiting the amount of parallelism. Finally, ESP supports only fixed size arguments (except strings). This makes the construction of general purpose library classes, e.g., matrix operators, difficult. Performance is difficult to compare. The performance of PRESTO <ref> [14] </ref> is very good, much better than Mentat for Gaussian elimination. However, the results are for the Sequent, a shared memory processor for which communication and synchronization are very cheap.
Reference: [15] <author> J. K. Lee and D. Gannon, </author> <title> Object Oriented Parallel Programming Experiments and Results, </title> <booktitle> Proceedings of Supercomputing 91, </booktitle> <pages> pp. 273-282, </pages> <address> Albuquerque, NM, </address> <year> 1991. </year>
Reference-contexts: PC++ <ref> [15] </ref> and Paragon [16] on the other hand are data-parallel derivatives of C++. Mentat accommodates both functional and data-parallelism, often within the same program. ESP [17] is perhaps the most similar of the parallel object-oriented systems. It too is a high-performance extension to C++ that supports both functional and data-parallelism.
Reference: [16] <author> A.L.Cheung, and A.P. Reeves, </author> <title> High Performance Computing on a Cluster of Workstations, </title> <booktitle> Proceedings of the First Symposium on High-Performance Distributed Computing, </booktitle> <pages> pp. 152-160, </pages> <address> Syracuse, NY, </address> <month> Sept., </month> <year> 1992. </year>
Reference-contexts: PC++ [15] and Paragon <ref> [16] </ref> on the other hand are data-parallel derivatives of C++. Mentat accommodates both functional and data-parallelism, often within the same program. ESP [17] is perhaps the most similar of the parallel object-oriented systems. It too is a high-performance extension to C++ that supports both functional and data-parallelism. <p> They do not extend to distributed memory machines. 4.2 Compiled Distributed Memory Systems Until recently, there were few results for compiled, as opposed to hand-coded applications on distributed memory machines. There are now several active projects in this area, Fortran-D [20], Dataparallel C [21], Paragon <ref> [16] </ref>, and the inspector/executor [22] model to name a few. The underlying characteristics of each of the above is that they are primarily data-parallel languages. What differentiates our work from theirs is that Mentat exploits opportunities for both functional and data-parallelism.
Reference: [17] <author> S. K. Smith, et al., </author> <title> Experimental Systems Project at MCC, </title> <type> MCC Technical Report Number: </type> <institution> ACA-ESP-089-89, </institution> <month> March 2, </month> <year> 1989. </year>
Reference-contexts: PC++ [15] and Paragon [16] on the other hand are data-parallel derivatives of C++. Mentat accommodates both functional and data-parallelism, often within the same program. ESP <ref> [17] </ref> is perhaps the most similar of the parallel object-oriented systems. It too is a high-performance extension to C++ that supports both functional and data-parallelism. What distinguishes 29 Mentat is our compiler support. In ESP remote invocations either return values or futures.
Reference: [18] <author> G. C. Fox, et al., </author> <title> Fortran D Language Specifications, </title> <type> Technical Report SCCS 42c, </type> <institution> NPAC, Syracuse University, Syracuse, NY. </institution>
Reference: [19] <author> D. Callahan and K. </author> <title> Kennedy,Compiling Programs for Distributed-Memory Multiprocessors The Journal of Supercomputing, </title> <journal> no. </journal> <volume> 2, </volume> <pages> pp. 151-169, </pages> <address> 1988, </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: We are uncertain how the Linda speedups were computed, or what type of workstation was used. 4.3 Portable Systems Applications portability across parallel architectures is an objective of many projects. Examples include PVM [25], Linda [26][24], the Argonne P4 macros [27], and Fortran D <ref> [19] </ref>. Our effort shares with these and other projects the basic idea of providing a portable virtual machine to the programmer. The primary difference is the level of the abstraction. Low-level abstractions such as in [25][26][27] require the programmer to operate at the assembly language level of parallelism.
Reference: [20] <author> Min-You Wu, and G.C. Fox, </author> <title> A Test Suite Approach for Fortran90D Compilers on MIMD Distributed Memory Parallel Computers, </title> <booktitle> Proceedings of the First Symposium on High-Performance Distributed Computing, </booktitle> <pages> pp. 393-400, </pages> <address> Syracuse, NY, </address> <month> Sept., </month> <year> 1992. </year>
Reference-contexts: They do not extend to distributed memory machines. 4.2 Compiled Distributed Memory Systems Until recently, there were few results for compiled, as opposed to hand-coded applications on distributed memory machines. There are now several active projects in this area, Fortran-D <ref> [20] </ref>, Dataparallel C [21], Paragon [16], and the inspector/executor [22] model to name a few. The underlying characteristics of each of the above is that they are primarily data-parallel languages. What differentiates our work from theirs is that Mentat exploits opportunities for both functional and data-parallelism. <p> Most other systems statically determine the communication and synchronization requirements of the program at compile-time. Performance results for the solution of a system of linear equations on the Intel iPSC/2 are available for both Fortran D <ref> [20] </ref> and Dataparallel C [23] 5 . Table 1 compares the three implementations. It 30 is unclear from [20] exactly what is timed, i.e., whether data distribution time is included. The Dataparallel C implementation uses Gauss-Jordan to solve the system of equations. <p> Performance results for the solution of a system of linear equations on the Intel iPSC/2 are available for both Fortran D <ref> [20] </ref> and Dataparallel C [23] 5 . Table 1 compares the three implementations. It 30 is unclear from [20] exactly what is timed, i.e., whether data distribution time is included. The Dataparallel C implementation uses Gauss-Jordan to solve the system of equations. As can be seen, the three systems offer comparable performance for relatively small problems. <p> Table 3 shows the Mentat performance of Gaussian Elimination and scanlib compared to results from hand-coded versions given in <ref> [20] </ref> and [7]. The Mentat version compares well with the hand-coded versions. 5. Summary and Future Work Overhead is the friction of parallel processing. The dynamic detection and management of parallelism, the use of the object-oriented paradigm, and the use of a virtual machine all contribute to overhead in Mentat.
Reference: [21] <author> N. Nedeljkovic, and M.J. Quinn, </author> <title> Data-Parallel Programming on a Network of Heterogeneous Workstations, </title> <booktitle> Proceedings of the First Symposium on High-Performance Distributed Computing, </booktitle> <pages> pp. 28-36, </pages> <address> Syracuse, NY, </address> <month> Sept., </month> <year> 1992. </year>
Reference-contexts: They do not extend to distributed memory machines. 4.2 Compiled Distributed Memory Systems Until recently, there were few results for compiled, as opposed to hand-coded applications on distributed memory machines. There are now several active projects in this area, Fortran-D [20], Dataparallel C <ref> [21] </ref>, Paragon [16], and the inspector/executor [22] model to name a few. The underlying characteristics of each of the above is that they are primarily data-parallel languages. What differentiates our work from theirs is that Mentat exploits opportunities for both functional and data-parallelism.
Reference: [22] <author> J. Saltz, H. Berryman, and J. Wu, </author> <title> Multiprocessors and Runtime Compilation, </title> <type> ICASE Report No. </type> <pages> 90-59, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: They do not extend to distributed memory machines. 4.2 Compiled Distributed Memory Systems Until recently, there were few results for compiled, as opposed to hand-coded applications on distributed memory machines. There are now several active projects in this area, Fortran-D [20], Dataparallel C [21], Paragon [16], and the inspector/executor <ref> [22] </ref> model to name a few. The underlying characteristics of each of the above is that they are primarily data-parallel languages. What differentiates our work from theirs is that Mentat exploits opportunities for both functional and data-parallelism.
Reference: [23] <author> P.J. Hatcher, </author> <title> A Production-Quality C* Compiler for Hypercube Multicomputers, </title> <booktitle> Proceedings of the Third ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming, </booktitle> <address> Williamsburg, VA, </address> <month> April 21-24, </month> <year> 1991. </year>
Reference-contexts: Most other systems statically determine the communication and synchronization requirements of the program at compile-time. Performance results for the solution of a system of linear equations on the Intel iPSC/2 are available for both Fortran D [20] and Dataparallel C <ref> [23] </ref> 5 . Table 1 compares the three implementations. It 30 is unclear from [20] exactly what is timed, i.e., whether data distribution time is included. The Dataparallel C implementation uses Gauss-Jordan to solve the system of equations.
Reference: [24] <author> R. Bjornson, et al., </author> <title> Experience with Linda, </title> <institution> Yale University, YALEU/DCS/TR-866, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: The apparent superlinear speedup is due to the sequential code being executed on the host running Unix. This introduces overhead not present on the nodes. b. The Linda times were interpreted from a graph on page 10 of <ref> [24] </ref> using a straight-edge. a. Once again, the numbers are approximations from a graph.
Reference: [25] <author> V.S. Sunderam, </author> <title> PVM: A framework for parallel distributed computing, </title> <journal> Concurrency: Practice and Experience, </journal> <volume> vol. 2(4), </volume> <pages> pp. 315-339, </pages> <month> December, </month> <year> 1990. </year>
Reference-contexts: The Linda implementation is LU factorization only. We are uncertain how the Linda speedups were computed, or what type of workstation was used. 4.3 Portable Systems Applications portability across parallel architectures is an objective of many projects. Examples include PVM <ref> [25] </ref>, Linda [26][24], the Argonne P4 macros [27], and Fortran D [19]. Our effort shares with these and other projects the basic idea of providing a portable virtual machine to the programmer. The primary difference is the level of the abstraction. Low-level abstractions such as in [25][26][27] require the programmer to
Reference: [26] <author> N. Carriero and D. Gelernter, </author> <title> Linda in Context, </title> <journal> Comm. of the ACM, </journal> <pages> pp. 444-458, </pages> <month> April, </month> <year> 1989. </year>
Reference: [27] <author> J. Boyle et al., </author> <title> Portable Programs for Parallel Processors, </title> <publisher> Holt, Rinehart and Winston, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: The Linda implementation is LU factorization only. We are uncertain how the Linda speedups were computed, or what type of workstation was used. 4.3 Portable Systems Applications portability across parallel architectures is an objective of many projects. Examples include PVM [25], Linda [26][24], the Argonne P4 macros <ref> [27] </ref>, and Fortran D [19]. Our effort shares with these and other projects the basic idea of providing a portable virtual machine to the programmer. The primary difference is the level of the abstraction. Low-level abstractions such as in [25][26][27] require the programmer to operate at the assembly language level of
References-found: 27

