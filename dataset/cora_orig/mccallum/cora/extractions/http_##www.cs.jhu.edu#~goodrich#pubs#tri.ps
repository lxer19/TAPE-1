URL: http://www.cs.jhu.edu/~goodrich/pubs/tri.ps
Refering-URL: http://www.cs.jhu.edu/~goodrich/pubs/index.html
Root-URL: http://www.cs.jhu.edu
Title: Planar Separators and Parallel Polygon Triangulation  
Author: Michael T. Goodrich 
Abstract: We show how to construct an O( p n)-separator decomposition of a planar graph G in O(n) time. Such a decomposition defines a binary tree where each node corresponds to a subgraph of G and stores an O( p n)-separator of that subgraph. We also show how to construct an O(n * )-way decomposition tree in parallel in O(log n) time so that each node corresponds to a subgraph of G and stores an O(n 1=2+* )-separator of that subgraph. We demonstrate the utility of such a separator decomposition by showing how it can be used in the design of a parallel algorithm for triangulating a simple polygon deterministically in O(log n) time using O(n= log n) processors on a CRCW PRAM. Keywords: Computational geometry, algorithmic graph theory, planar graphs, planar separators, polygon triangulation, parallel algorithms, PRAM model.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal, B. Chazelle, L. Guibas, C. O'Dunlaing, and C. Yap, </author> <title> "Parallel Computational Geometry," </title> <journal> Algorithmica, </journal> <volume> 3(3), </volume> <year> 1988, </year> <pages> 293-328. </pages>
Reference-contexts: This problem was first studied in the parallel setting by Aggarwal et al. <ref> [1] </ref>, and is a problem with many applications (e.g., see [11, 25, 27]).
Reference: [2] <author> A.V. Aho, J.E. Hopcroft, and J.D. Ullman, </author> <title> Data Structures and Algorithms, </title> <publisher> Addison-Wesley (Reading, </publisher> <address> Mass.: </address> <year> 1983). </year>
Reference-contexts: These data structures include standard binary search trees (such as red-black trees [28, 43]) as well as the more-sophisticated link-cut tree data structure of Sleator and Tarjan [42, 43]. Throughout the recursive decomposition we maintain the breadth-first spanning (BFS) tree <ref> [2, 17] </ref> of each individual piece the graph, so as to avoid the recomputation of BFS trees as would be required by simple recursive applications of Lipton and Tarjan's algorithm. <p> In each internal node in B (i) (or B) we store the number of the leaf descendents of . Maintaining this information for the B (i)'s subject to the above operations can easily be done in O (log n) time per operation (e.g., see <ref> [2, 17, 43] </ref>). In addition to its adjacency information, we represent T using the link-cut tree data structure of Sleator and Tarjan [42, 43]. This data structure represents an arbitrary rooted tree, such as T , as a collection of paths joined by edges not on any of these paths.
Reference: [3] <author> R.J. Anderson and G.L. Miller, </author> <title> "Deterministic Parallel List Ranking," </title> <booktitle> Lecture Notes in Computer Science, 319: 3rd Aegean Workshop on Computing, AWOC 88, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1988, </year> <pages> 81-90. </pages>
Reference-contexts: With each node v in this list we associate its level number l (v), which can be computed by another application of the Euler-tour technique, along with calls to the well-known list ranking <ref> [3, 14] </ref> and parallel prefix [34, 35] techniques 3 (see also [31, 32]). All of this can be implemented in O (log n) time using O (n= log n) processors. <p> Linking each node v to its neighbors in L (i) gives us a linked-list representation of each L (i). A final application of list ranking <ref> [3, 14] </ref>, then, gives us each L (i) represented in an array. 2 Given the L (i) lists we build a binary tree B "on top" of these lists, as we did in the previous section.
Reference: [4] <author> B.G. Baumgart, </author> <title> "A Polyhedron Representation for Computer Vision," </title> <booktitle> Proc. 1975 AFIPS National Computer Conf., </booktitle> <volume> 44, </volume> <publisher> AFIPS Press, </publisher> <year> 1975, </year> <pages> 589-596. 30 </pages>
Reference-contexts: We assume that G is represented so that the adjacencies for any vertex v are stored in cyclic order around v in a circular doubly-linked list. For example, G could be represented using the "winged edge" structure of Baumgart <ref> [4] </ref>, the "quad edge" structure of Guibas and Stolfi [29], or the "doubly-connected edge list" structure of Muller and Preparata [40, 41].
Reference: [5] <author> J.L. Bentley and D. Wood, </author> <title> "An Optimal Worst Case Algorithm for Reporting Intersections of Rectangles," </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-29(7), </volume> <year> 1980, </year> <pages> 571-576. </pages>
Reference-contexts: In particular, let the leaves of T be numbered left-to-right 1; 2; : : : ; n, and let each internal node v of T be associated with the interval [a; b] that spans v's descendents. As in the (binary) segment tree data structure of Bentley and Wood <ref> [5] </ref>, we say that an interval [c; d] covers a node v if [c; d] contains the interval for v but does not contain the interval for v's parent. An interval [c; d] can therefore be represented by the union intervals in T that it covers.
Reference: [6] <author> O. Berman, D. Breslauer, Z. Galil, B. Schieber, and U. Vishkin, </author> <title> "Highly Parallelizable Problems," </title> <booktitle> Proc. 21st ACM Symp. on Theory of Computing, </booktitle> <year> 1989, </year> <pages> 309-319. </pages>
Reference-contexts: The problem of locating all such neighbors for every node in L is known as the all nearest larger values problem, can, as shown by Berkman et al. <ref> [6] </ref>, this can be solved in O (log n) time using O (n= log n) processors on a CREW PRAM. Linking each node v to its neighbors in L (i) gives us a linked-list representation of each L (i).
Reference: [7] <author> S.N. Bhatt and F.T. Leighton, </author> <title> "A Framework for Solving VLSI Graph Layout Problems," </title> <journal> J. Comp. and Sys. Sci., </journal> <volume> 28(2), </volume> <year> 1984, </year> <pages> 300-343. </pages>
Reference-contexts: 1 Introduction Let G = (V; E) be an n-node graph. An f (n)-separator is an f (n)-sized subset of V whose removal disconnects G into two subgraphs G 1 and G 2 each of size at most 2n=3 [37]. Typically, separator finding is used to drive divide-and-conquer algorithms <ref> [7, 38] </ref>, where one finds an f (n)-separator of G, dividing G into G 1 and G 2 , and then recurses on each G i . Such a recursive decomposition is called an f (n)-separator decomposition of G [7]. <p> Typically, separator finding is used to drive divide-and-conquer algorithms [7, 38], where one finds an f (n)-separator of G, dividing G into G 1 and G 2 , and then recurses on each G i . Such a recursive decomposition is called an f (n)-separator decomposition of G <ref> [7] </ref>. <p> This, of course, immediately leads to an O (n log n)-time algorithm for constructing an O ( p n)-separator decomposition of such a graph G, a result that has been used to solve a number of problems in VLSI layout, computational geometry, and algorithmic graph theory (e.g., see <ref> [7, 11, 20, 36, 38] </ref>). In this paper we show how to construct an O ( p n)-separator decomposition of a planar graph G in O (n) time. <p> Incidentally, this theorem immediately implies that one can perform the VLSI embedding of a planar graph in O (n) time using the algorithms of <ref> [7, 36] </ref>. Moreover, in a manner similar to the approach of Lipton and Tarjan [37], it is straightforward to generalize our methods to weighted graphs.
Reference: [8] <author> J.A. Bondy and U.S.R. Murty, </author> <title> Graph Theory with Applications, </title> <publisher> North-Holland (New York: </publisher> <year> 1976). </year>
Reference-contexts: conclude in Section 5. 1 These methods are optimal, however, if P is allowed to contain polygonal holes, which we do not allow. 3 2 Separator Decomposition Suppose we are given an n-node plane graph G, i.e., an n-node graph embedded on a sphere so that no two edges cross <ref> [8] </ref>. Moreover, let us assume that each face, including the external face, has three edges|we refer to such a graph as being triangulated. We also assume that G is simple, i.e., no two edges e and f are incident upon the same vertices. <p> 2 , and G 3 . (See Figure 1.) Cutting the nodes at a level involves the removal of all nodes on that level together with all of their incident edges, of which there can be at most O (n), since G's being planar implies that jEj is O (n) <ref> [8] </ref>. If the middle piece, G 2 , is of size at most 2n=3, then we're done. So suppose jG 2 j &gt; 2n=3. Create a new root r and join r to all the roots of subtrees created when we cut T at l 0 . <p> Then jEj = 3jV j 6. Proof: The proof is essentially the same as that for the similar relationship that holds for simple plane graphs (e.g., see <ref> [8] </ref> (p. 144)). 2 So, let us begin our method by assuming inductively that we are given the above B, T , and D structures representing G. Let n denote the number of active vertices in G, let k denote the number of deactivated vertices in G.
Reference: [9] <author> R.P. Brent, </author> <title> "The Parallel Evaluation of General Arithmetic Expressions," </title> <journal> J. ACM, </journal> <volume> 21(2), </volume> <year> 1974, </year> <pages> 201-206. </pages>
Reference-contexts: This implies that W (n) is O (n). Having established the work bound to be O (n), we may then make a simple application of Brent's Theorem <ref> [9] </ref> (which is also known as the work-time scheduling principle [31]) to establish the processor bounds.
Reference: [10] <author> B. Chazelle, </author> <title> "A Theorem on Polygon Cutting with Applications," </title> <booktitle> Proc. 23rd IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1982, </year> <pages> 339-349. </pages>
Reference-contexts: Of course, if G is a tree, then this is easy, for there is a node, called the centroid, that is itself a separator <ref> [10] </ref>, and fl This research was announced in preliminary form in Proc. 24th ACM Symp. on Theory of Computing, 1992, 507-516. y This research was supported by NSF Grants CCR-9003299 and IRI-9116843, and by NSF/DARPA Grant CCR-8908092. Author's address: Dept. of Computer Science, The Johns Hopkins University, Baltimore, MD 21218.
Reference: [11] <author> B. Chazelle, </author> <title> "Triangulating a Simple Polygon in Linear Time," </title> <journal> Disc. and Comp. Geom., </journal> <volume> 6, </volume> <year> 1991, </year> <pages> 485-524. </pages>
Reference-contexts: This, of course, immediately leads to an O (n log n)-time algorithm for constructing an O ( p n)-separator decomposition of such a graph G, a result that has been used to solve a number of problems in VLSI layout, computational geometry, and algorithmic graph theory (e.g., see <ref> [7, 11, 20, 36, 38] </ref>). In this paper we show how to construct an O ( p n)-separator decomposition of a planar graph G in O (n) time. <p> Our O (n 3 ) processor bound might seem excessively high, but, by following an approach similar to that used in the sequential algorithm by Chazelle <ref> [11] </ref>, we show how to use this inefficient algorithm to design an optimal parallel method for polygon triangulation: the problem of augmenting a simple polygon P with diagonals so that each internal face in the resulting planar subdivision is a triangle [22]. <p> This problem was first studied in the parallel setting by Aggarwal et al. [1], and is a problem with many applications (e.g., see <ref> [11, 25, 27] </ref>). Our method runs in O (log n) time using O (n= log n) processors in the deterministic PRAM model where simultaneous concurrent reads and writes are allowed (the CRCW PRAM model [31, 32]), where we assume concurrent write conflicts are resolved arbitrarily. <p> This matches the work bound of the best sequential method, due to Chazelle <ref> [11] </ref>, and improves the previous parallel method, due to Clarkson, Cole, and Tarjan [12], which runs in O (log n log log n log fl n) expected time and has an expected O (n) work bound on a randomized CRCW PRAM. <p> It also improves the previous best deterministic methods, which run in O (log n) time using O (n) processors 1 [24, 46]. As mentioned above, our triangulation method is based on an approach similar to that used in the sequential method of Chazelle <ref> [11] </ref>. Specifically, we use a divide-and-conquer approach to construct a submap of P , that is, a partitioning of P into subpolygons of size O (n ffi ), for some ffi &lt; 1, which are then refined to form a triangulation. <p> In a fashion analogous to a sequential structure used by Chazelle <ref> [11] </ref>, in this subsection we show how to use the parallel separator decomposition theorem (3.3) to design a data structure that allows for arbitrary horizontal ray shooting queries to be performed in O (log n) time using O ((n)m 1=2+* ) processors. <p> This theorem plays an important role in our method for polygon triangulation, which we now describe. 4.2 Our Polygon Triangulation Algorithm: An Overview Suppose we are given a simple polygonal chain 5 P . Following elegant conventions used by Chazelle <ref> [11] </ref>, as well as Kirkpatrick, Klawe, and Tarjan [33], we view the edges of P as having two distinct sides and we view P as being embedded in a sphere. <p> By adopting the convention that P is embedded in a sphere, we view horizontal ray shooting operations that "miss" P as actually wrapping around the sphere and hitting P from the other side. (See Figure 7.) Following Chazelle's approach <ref> [11] </ref>, our method for constructing a triangulation of P is to construct a submap of P and then refine that submap into a trapezoidal map, that is, the decomposition formed by adding an edge from each vertex of P to its shadows on P 's boundary. <p> Indeed, several recent triangulation 5 We describe our method assuming a possibly open polygonal chain, since our method is based upon applying recursion to the edges of this chain. 21 algorithms (e.g., <ref> [11, 33, 44] </ref>) actually produce a trapezoidal map and then apply this result to construct a triangulation. In our case, we will construct a trapezoidal map and then apply an algorithm due to the author [24] to convert this trapezoidal map into a triangulation in parallel. <p> Because of the two-sided nature of P , there are no edges in D that correspond to adjacencies that cross the boundary of P ; hence, D is a tree. Following the terminology of Chazelle <ref> [11] </ref>, we say that S is conformal if D has degree at most 4. <p> and compressing any edge e in D incident upon a node of degree 3, by removing the chord dual to e, would create a node with weight more than fl. (See Figure 7.) As the following lemma shows, conformality and granularity imply an "even distribution" of regions: Lemma 4.2 (Chazelle <ref> [11] </ref>): A fl-granular conformal submap of an n-edge polygonal curve P has O (n=fl + 1) regions and each region is bounded by O (fl) edges. <p> For example, the true processor bound here is O (n (1*)ffi 2 ). Proof: Chazelle <ref> [11] </ref> shows that in any submap, S, the Jordan curves (not counting chords) bounding a region R appear in the order they occur on P . <p> This local test is similar to a binary-search test given by Chazelle <ref> [11] </ref> and is based on the fact that the edges bounding R occur in the same order they occur on P 's boundary. <p> Proof: Suppose there is region R in S 0 with whose boundary contains the sequence of curves c 1 ; c 2 ; : : : ; c l , with l &gt; 4. Chazelle <ref> [11] </ref> shows that in such a region there are a pair of curves c j and c k on R that contain two mutually horizontally-visible points with jk jj &gt; 1. <p> For the base case, when n is below some constant, then we construct a fully augmented n ffi -granular submap for P using the sequential algorithm of Chazelle <ref> [11] </ref>. This implies that W (n) is O (n). Having established the work bound to be O (n), we may then make a simple application of Brent's Theorem [9] (which is also known as the work-time scheduling principle [31]) to establish the processor bounds. <p> This technique is certainly not new to this paper, for it is used in such methods as Chazelle's algorithm for polygon triangulation <ref> [11] </ref> and the centroid decomposition algorithm of Guibas et al. [27], but its use in this paper provides further evidence of its power. It is sure to appear again in future divide-and-conquer algorithms.
Reference: [12] <author> K.L. Clarkson, R. Cole, and R.E. Tarjan, </author> <title> "Randomized Parallel Algorithms for Trapezoidal Diagrams," </title> <journal> Int. J. of Computational Geometry and Applications, </journal> <volume> 2(2), </volume> <year> 1992, </year> <pages> 117-134. </pages>
Reference-contexts: This matches the work bound of the best sequential method, due to Chazelle [11], and improves the previous parallel method, due to Clarkson, Cole, and Tarjan <ref> [12] </ref>, which runs in O (log n log log n log fl n) expected time and has an expected O (n) work bound on a randomized CRCW PRAM. It also improves the previous best deterministic methods, which run in O (log n) time using O (n) processors 1 [24, 46].
Reference: [13] <author> R. Cole, </author> <title> "Parallel Merge Sort," </title> <journal> SIAM J. Comput., </journal> <volume> 17(4), </volume> <year> 1988, </year> <pages> 770-785. </pages>
Reference-contexts: We then sort the shadow points with respect to their ordering around P to determine all the adjacencies between endpoints and shadow points, and also between consecutive shadow points. This can be implemented in O (log n) time using O (n 1ffi+* ) processors <ref> [13] </ref> (which is clearly dominated by (1)).
Reference: [14] <author> R. Cole and U. Vishkin, </author> <title> "Approximate Parallel Scheduling, Part I: The Basic Technique with Applications to Optimal Parallel List Ranking in Logarithmic Time," </title> <journal> SIAM J. Comput., </journal> <volume> 17(1), </volume> <year> 1988, </year> <pages> 128-142. </pages>
Reference-contexts: With each node v in this list we associate its level number l (v), which can be computed by another application of the Euler-tour technique, along with calls to the well-known list ranking <ref> [3, 14] </ref> and parallel prefix [34, 35] techniques 3 (see also [31, 32]). All of this can be implemented in O (log n) time using O (n= log n) processors. <p> Linking each node v to its neighbors in L (i) gives us a linked-list representation of each L (i). A final application of list ranking <ref> [3, 14] </ref>, then, gives us each L (i) represented in an array. 2 Given the L (i) lists we build a binary tree B "on top" of these lists, as we did in the previous section. <p> In this case we can satisfy these conditions by either an ad-hoc method based on the recurrence relation for W (n) or by applying the duration-unknown task scheduling method of Cole and Vishkin <ref> [14] </ref> or Cole and Zajicek [16]. 2 4.7 The Trapezoidal Map Of course, we wish to construct a trapezoidal map, not merely an n ffi -granular conformal submap.
Reference: [15] <author> R. Cole and U. Vishkin, </author> <title> "The Accelerated Centroid Decomposition Technique for Optimal Parallel Tree Evaluation in Logarithmic Time," </title> <journal> Algorithmica, </journal> <volume> 3, </volume> <year> 1988, </year> <pages> 329-346. </pages>
Reference-contexts: Email: goodrich@cs.jhu.edu. 1 its removal disconnects G into trees that may then be recursively decomposed. Moreover, one can construct a centroid decomposition of such a G in O (n) time sequentially (e.g., see [27]) or in parallel in O (log n) time using O (n= log n) processors <ref> [15] </ref>. If, on the other hand, G is a planar graph, then, in what is now a classic result in algorithmic graph theory, Lipton and Tarjan [37] show that G has an O ( p n)-separator that can be found in O (n) time. <p> We therefore form a centroid decomposition of D i using the accelerated centroid decomposition method of Cole and Vishkin <ref> [15] </ref>, which can be implemented for G i in O (log n) time using O (n i = log n) processors. <p> After a preprocessing step that computes a centroid decomposition of D 00 in O (log n) time <ref> [15] </ref>, this can easily be implemented in O (log n) time, using O (n 1ffi+4* ) (3) processors. So, we now have an n ffi -granular conformal submap. <p> Now that we have D, the dual tree for S, the first of these is fairly straightforward to construct in O (log n) time using O (n 1ffi = log n) (4) processors <ref> [15] </ref>. The second structure, used for ray shooting queries, requires a little more effort, however.
Reference: [16] <author> R. Cole and O. Zajicek, </author> <title> "An Optimal Parallel Algorithm for Building a Data Structure for Planar Point Location," </title> <journal> J. Par. and Dist. Comput., </journal> <volume> 8, </volume> <year> 1990, </year> <pages> 280-285. </pages>
Reference-contexts: In this case we can satisfy these conditions by either an ad-hoc method based on the recurrence relation for W (n) or by applying the duration-unknown task scheduling method of Cole and Vishkin [14] or Cole and Zajicek <ref> [16] </ref>. 2 4.7 The Trapezoidal Map Of course, we wish to construct a trapezoidal map, not merely an n ffi -granular conformal submap. That is, we desire the subdivision of P determined by the chords produced by a horizontal ray shooting operation from each vertex on P .
Reference: [17] <author> T.H. Cormen, C.E. Leiserson, and R.L. Rivest, </author> <title> Introduction to Algorithms, </title> <publisher> MIT Press (Cam-bridge, </publisher> <address> Mass.: </address> <year> 1990). </year>
Reference-contexts: These data structures include standard binary search trees (such as red-black trees [28, 43]) as well as the more-sophisticated link-cut tree data structure of Sleator and Tarjan [42, 43]. Throughout the recursive decomposition we maintain the breadth-first spanning (BFS) tree <ref> [2, 17] </ref> of each individual piece the graph, so as to avoid the recomputation of BFS trees as would be required by simple recursive applications of Lipton and Tarjan's algorithm. <p> In each internal node in B (i) (or B) we store the number of the leaf descendents of . Maintaining this information for the B (i)'s subject to the above operations can easily be done in O (log n) time per operation (e.g., see <ref> [2, 17, 43] </ref>). In addition to its adjacency information, we represent T using the link-cut tree data structure of Sleator and Tarjan [42, 43]. This data structure represents an arbitrary rooted tree, such as T , as a collection of paths joined by edges not on any of these paths.
Reference: [18] <author> D. Eppstein, Z. Galil, G. Italiano, T. Spencer, </author> <title> "Separator Based Sparsification for Dynamic Planar Graph Algorithms," </title> <booktitle> Proc. 25th ACM Symp. on Theory of Computing, </booktitle> <year> 1993. </year>
Reference-contexts: Indeed, our planar separator result has been used recently by Eppstein et al. <ref> [18] </ref> in improved methods for dynamic planar graph algorithms, and our parallel polygon triangulation result has been used recently by Hershberger [30] for improved parallel computational geometry algorithms. Although our methods for solving these two problems are quite different, they are both based upon similar paradigms.
Reference: [19] <author> D. Eppstein, G.F. Italiano, R. Tamassia, R.E. Tarjan, J. Westbrook, and M. Yung, </author> <title> "Maintenance of a Minimum Spanning Forest in a Dynamic Planar Graph," </title> <journal> J. of Algorithms, </journal> <volume> 13, </volume> <year> 1992, </year> <pages> 33-54. </pages>
Reference-contexts: Indeed, this tree interlacing technique of maintaining a spanning tree and its inverse to speed up dynamic graph maintenance is central to our method. Incidentally, this technique seems to be quite powerful, as it was also employed recently by Eppstein et al. <ref> [19] </ref> for fast maintenance of dynamic minimum spanning trees and by Goodrich and Tamassia [26] for maintaining dynamic planar subdivisions for fast planar point location. Interestingly, our tree interlacing approach also leads to improved methods for finding many-way separators in parallel. <p> In addition, as shown by Eppstein et al. <ref> [19] </ref>, this data structure also supports the following operations (see Figure 2): * Compress (u; w): compress the edge (u; w) in T so as to identify u and w as a single vertex, v. <p> One of these paradigms is the dynamic maintenance of a planar graph using a spanning tree and its inverse. Indeed, this tree interlacing technique has already proved useful for solving a number of other problems as well <ref> [19, 26] </ref>. The second main paradigm our two algorithms share is that they both employ the divide-and-conquer technique, but in a slightly non-standard way.
Reference: [20] <author> G.N. Frederickson, </author> <title> "Fast Algorithms for Shortest Paths in Planar Graphs, with Applications," </title> <journal> SIAM J. Comput., </journal> <volume> 6, </volume> <year> 1987, </year> <pages> 1004-1022. </pages>
Reference-contexts: This, of course, immediately leads to an O (n log n)-time algorithm for constructing an O ( p n)-separator decomposition of such a graph G, a result that has been used to solve a number of problems in VLSI layout, computational geometry, and algorithmic graph theory (e.g., see <ref> [7, 11, 20, 36, 38] </ref>). In this paper we show how to construct an O ( p n)-separator decomposition of a planar graph G in O (n) time.
Reference: [21] <author> A. Fournier and D.Y. Montuno, </author> <title> "Triangulating Simple Polygons and Equivalent Problems," </title> <journal> ACM Trans. on Graphics, </journal> <volume> Vol. 3, No. 2, </volume> <month> April </month> <year> 1984, </year> <pages> pp. 153-174. </pages>
Reference-contexts: By a well-known result of Fournier and Montuno <ref> [21] </ref>, constructing a trapezoidal map is linear-time equivalent to polygon triangulation.
Reference: [22] <author> M.R. Garey, D.S. Johnson, F.P. Preparata, and R.E. Tarjan, </author> <title> "Triangulating a Simple Polygon," </title> <journal> Information Processing Letters, </journal> <volume> 7(4), </volume> <year> 1978, </year> <pages> 175-179. </pages>
Reference-contexts: to that used in the sequential algorithm by Chazelle [11], we show how to use this inefficient algorithm to design an optimal parallel method for polygon triangulation: the problem of augmenting a simple polygon P with diagonals so that each internal face in the resulting planar subdivision is a triangle <ref> [22] </ref>. This problem was first studied in the parallel setting by Aggarwal et al. [1], and is a problem with many applications (e.g., see [11, 25, 27]).
Reference: [23] <author> H. Gazit and G.L. Miller, </author> <title> "A Parallel Algorithm for Finding a Separator in Planar Graphs," </title> <booktitle> Proc. 28th IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1987, </year> <pages> 238-248. </pages>
Reference-contexts: Note that one could iteratively use Miller's method to find a separator similar to ours, but this would require O (log 2 n) 2 time. There is also a parallel separator-finding method due to Gazit and Miller <ref> [23] </ref> that has a more efficient processor bound than our method, but it runs in O (log 3 n) time (hence, would run in O (log 4 n) time to find a separator such as ours).
Reference: [24] <author> M.T. Goodrich, </author> <title> "Triangulating a Polygon in Parallel," </title> <journal> J. of Algorithms, </journal> <volume> 10, </volume> <year> 1989, </year> <pages> 327-351. 31 </pages>
Reference-contexts: It also improves the previous best deterministic methods, which run in O (log n) time using O (n) processors 1 <ref> [24, 46] </ref>. As mentioned above, our triangulation method is based on an approach similar to that used in the sequential method of Chazelle [11]. <p> In our case, we will construct a trapezoidal map and then apply an algorithm due to the author <ref> [24] </ref> to convert this trapezoidal map into a triangulation in parallel. So, let us begin our discussion by describing the specific kind of submap we construct in the first phase of our algorithm. Let S be a submap of P , and let D be the graph-theoretic dual of S. <p> 4.7: Given an n-vertex simple polygon P , one can triangulate P in O (log n) time using O (n= log n) processors in the CRCW PRAM model. 29 Proof: Apply the above algorithm to produce a trapezoidal map of P , and then apply the result of the author <ref> [24] </ref> to refine this into a triangulation. 2 An immediate consequence of this theorem is that it eliminates the bottleneck computation in the algorithm of Goodrich et al. [25] so that one can now preprocess a polygon P in O (log n) time using O (n= log n) processors so as
Reference: [25] <author> M.T. Goodrich, S. Shauck, and S. Guha, </author> <title> "Parallel Methods for Visibility and Shortest Path Problems in Simple Polygons," </title> <booktitle> Proc. 6th ACM Symp. on Computational Geometry, </booktitle> <year> 1990, </year> <pages> 73-82. </pages>
Reference-contexts: This problem was first studied in the parallel setting by Aggarwal et al. [1], and is a problem with many applications (e.g., see <ref> [11, 25, 27] </ref>). Our method runs in O (log n) time using O (n= log n) processors in the deterministic PRAM model where simultaneous concurrent reads and writes are allowed (the CRCW PRAM model [31, 32]), where we assume concurrent write conflicts are resolved arbitrarily. <p> 29 Proof: Apply the above algorithm to produce a trapezoidal map of P , and then apply the result of the author [24] to refine this into a triangulation. 2 An immediate consequence of this theorem is that it eliminates the bottleneck computation in the algorithm of Goodrich et al. <ref> [25] </ref> so that one can now preprocess a polygon P in O (log n) time using O (n= log n) processors so as to answer shortest path queries inside P in O (log n) time using a single processor. 5 Conclusion We have given optimal algorithms for sequentially constructing planar separator
Reference: [26] <author> M.T. Goodrich and R. Tamassia, </author> <title> "Dynamic Trees and Dynamic Point Location," </title> <booktitle> Proc. 23rd ACM Symp. on Theory of Computing, </booktitle> <year> 1991, </year> <pages> 523-533. </pages>
Reference-contexts: Incidentally, this technique seems to be quite powerful, as it was also employed recently by Eppstein et al. [19] for fast maintenance of dynamic minimum spanning trees and by Goodrich and Tamassia <ref> [26] </ref> for maintaining dynamic planar subdivisions for fast planar point location. Interestingly, our tree interlacing approach also leads to improved methods for finding many-way separators in parallel. <p> This can all be done in O (n) time (see <ref> [26, 28, 42, 43] </ref>). 2.3 Separating G into G 1 , G 2 , and G 3 Our method for performing recursive separator, then, is to use these structures to find an O ( n)-separator and then remove the separator vertices while maintaining these data structures in the resulting "pieces." In <p> Moreover, using the method of Goodrich and Tamassia <ref> [26] </ref>, we may locate a centroid node v in D 2 in O (log n) time. This centroid location is implemented by a simple search in the solid path in D 2 containing the root [26], and does not require any modifications to the standard link-cut tree representation [42]. <p> Moreover, using the method of Goodrich and Tamassia <ref> [26] </ref>, we may locate a centroid node v in D 2 in O (log n) time. This centroid location is implemented by a simple search in the solid path in D 2 containing the root [26], and does not require any modifications to the standard link-cut tree representation [42]. Using the information obtained from the queries in T 2 , we can then perform a (temporary) cut at v and recurse on the appropriate subtree of D 2 . <p> One of these paradigms is the dynamic maintenance of a planar graph using a spanning tree and its inverse. Indeed, this tree interlacing technique has already proved useful for solving a number of other problems as well <ref> [19, 26] </ref>. The second main paradigm our two algorithms share is that they both employ the divide-and-conquer technique, but in a slightly non-standard way.
Reference: [27] <author> L. Guibas, J. Hershberger, D. Leven, M. Sharir and R. Tarjan, </author> <title> "Linear Time Algorithms for Visibility and Shortest Path Problems Inside Triangulated Simple Polygons," </title> <journal> Algorithmica, </journal> <volume> 2, </volume> <year> 1987, </year> <pages> 209-233. </pages>
Reference-contexts: Author's address: Dept. of Computer Science, The Johns Hopkins University, Baltimore, MD 21218. Email: goodrich@cs.jhu.edu. 1 its removal disconnects G into trees that may then be recursively decomposed. Moreover, one can construct a centroid decomposition of such a G in O (n) time sequentially (e.g., see <ref> [27] </ref>) or in parallel in O (log n) time using O (n= log n) processors [15]. <p> This problem was first studied in the parallel setting by Aggarwal et al. [1], and is a problem with many applications (e.g., see <ref> [11, 25, 27] </ref>). Our method runs in O (log n) time using O (n= log n) processors in the deterministic PRAM model where simultaneous concurrent reads and writes are allowed (the CRCW PRAM model [31, 32]), where we assume concurrent write conflicts are resolved arbitrarily. <p> This technique is certainly not new to this paper, for it is used in such methods as Chazelle's algorithm for polygon triangulation [11] and the centroid decomposition algorithm of Guibas et al. <ref> [27] </ref>, but its use in this paper provides further evidence of its power. It is sure to appear again in future divide-and-conquer algorithms.
Reference: [28] <author> L.J. Guibas and R. Sedgewick, </author> <title> "A Dichromatic Framework for Balanced Trees," </title> <booktitle> Proc. 19th IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1978, </year> <pages> 8-21. </pages>
Reference-contexts: These data structures include standard binary search trees (such as red-black trees <ref> [28, 43] </ref>) as well as the more-sophisticated link-cut tree data structure of Sleator and Tarjan [42, 43]. <p> We also maintain a dynamic search tree B that is built upon the B (i)'s, stored by increasing level numbers. The specific data structure one uses is not crucial (e.g., a red-black tree <ref> [28, 43] </ref> will do) so long as, in addition to the usual operations of Search, Insert, and Delete, it also supports the following operations: * Split (B; x): split the tree B into two trees, B 1 and B 2 , such that every element in B 1 is less than <p> This can all be done in O (n) time (see <ref> [26, 28, 42, 43] </ref>). 2.3 Separating G into G 1 , G 2 , and G 3 Our method for performing recursive separator, then, is to use these structures to find an O ( n)-separator and then remove the separator vertices while maintaining these data structures in the resulting "pieces." In
Reference: [29] <author> L.J. Guibas and J. Stolfi, </author> <title> "Primitives for the Manipulation of General Subdivisions and the Computation of Voronoi Diagrams," </title> <journal> ACM Transactions on Graphics, </journal> <volume> Vol. 4, </volume> <year> 1985, </year> <pages> 75-123. </pages>
Reference-contexts: We assume that G is represented so that the adjacencies for any vertex v are stored in cyclic order around v in a circular doubly-linked list. For example, G could be represented using the "winged edge" structure of Baumgart [4], the "quad edge" structure of Guibas and Stolfi <ref> [29] </ref>, or the "doubly-connected edge list" structure of Muller and Preparata [40, 41].
Reference: [30] <author> J. Hershberger, </author> <title> "Optimal Parallel Algorithms for Triangulated Simple Polygons," </title> <booktitle> Proc. 8th ACM Symp. on Computational Geometry, </booktitle> <year> 1992, </year> <pages> 33-42. </pages>
Reference-contexts: Indeed, our planar separator result has been used recently by Eppstein et al. [18] in improved methods for dynamic planar graph algorithms, and our parallel polygon triangulation result has been used recently by Hershberger <ref> [30] </ref> for improved parallel computational geometry algorithms. Although our methods for solving these two problems are quite different, they are both based upon similar paradigms. One of these paradigms is the dynamic maintenance of a planar graph using a spanning tree and its inverse.
Reference: [31] <author> J. JaJa, </author> <title> An Introduction to Parallel Algorithms, </title> <publisher> Addison-Wesley (Reading, </publisher> <address> Mass.), </address> <year> 1992. </year>
Reference-contexts: We show that a many-way O (n 1=2+* )-separator can be found in O (log n) time using O (n= log n) processors assuming one is given a BFS tree as part of the input (otherwise, it requires O (log n) time using O (n 3 ) processors <ref> [31, 32] </ref>). Our model of computation is the parallel random access machine (PRAM), the synchronous shared-memory parallel model in which simultaneous concurrent reads or writes are either allowed or disallowed, depending upon the submodel designation. <p> Our method runs in O (log n) time using O (n= log n) processors in the deterministic PRAM model where simultaneous concurrent reads and writes are allowed (the CRCW PRAM model <ref> [31, 32] </ref>), where we assume concurrent write conflicts are resolved arbitrarily. <p> Assuming we are given a BFS spanning tree as part of the input, our method runs in O (log n) time using O (n= log n) 15 processors in the deterministic PRAM model where concurrent reads are allowed but writes must be exclusive (the CREW PRAM model <ref> [31, 32] </ref>). If we are not given the BFS spanning tree, then our method runs in O (log n) time using O (n 3 ) processors on a CRCW PRAM (e.g., see [31, 32] for a method for constructing a BFS tree in these bounds). 3.1 Many-way Trees Since our method <p> the deterministic PRAM model where concurrent reads are allowed but writes must be exclusive (the CREW PRAM model <ref> [31, 32] </ref>). If we are not given the BFS spanning tree, then our method runs in O (log n) time using O (n 3 ) processors on a CRCW PRAM (e.g., see [31, 32] for a method for constructing a BFS tree in these bounds). 3.1 Many-way Trees Since our method produces a separation of G into many subgraphs it gives rise to a decomposition tree that is not binary. <p> One can construct a level linking of T in O (log n) time using O (n= log n) processors on a CREW PRAM. Proof: Using the Euler-tour technique on trees <ref> [31, 32, 45] </ref>, we construct a list L of the nodes in T listed in the order they would be traversed in a recursive tree traversal (such as the in-order traversal), so long as the children of a node v are "visited" according to their cyclic ordering around v. <p> With each node v in this list we associate its level number l (v), which can be computed by another application of the Euler-tour technique, along with calls to the well-known list ranking [3, 14] and parallel prefix [34, 35] techniques 3 (see also <ref> [31, 32] </ref>). All of this can be implemented in O (log n) time using O (n= log n) processors. Let v be a node in T , and let v first and v last respectively denote the first and last copies of v in L. <p> The large processor bound comes from the best known bound for constructing a BFS tree in O (log n) time (e.g., see <ref> [31, 32] </ref>). 2 We give a non-trivial application of this result in the following section. 4 Parallel Polygon Triangulation Suppose we are given a simple polygon P . <p> This implies that W (n) is O (n). Having established the work bound to be O (n), we may then make a simple application of Brent's Theorem [9] (which is also known as the work-time scheduling principle <ref> [31] </ref>) to establish the processor bounds.
Reference: [32] <author> Karp, R.M., and Ramachandran, V., </author> <title> "Parallel Algorithms for Shared-Memory Machines," in Handbook of Theoretical Computer Science, Vol. A: Algorithms and Complexity, </title> <editor> ed., J. Van Leeuwen, </editor> <publisher> The MIT Press (Cambridge, </publisher> <address> Mass.), </address> <year> 1990, </year> <pages> 869-942. </pages>
Reference-contexts: We show that a many-way O (n 1=2+* )-separator can be found in O (log n) time using O (n= log n) processors assuming one is given a BFS tree as part of the input (otherwise, it requires O (log n) time using O (n 3 ) processors <ref> [31, 32] </ref>). Our model of computation is the parallel random access machine (PRAM), the synchronous shared-memory parallel model in which simultaneous concurrent reads or writes are either allowed or disallowed, depending upon the submodel designation. <p> Our method runs in O (log n) time using O (n= log n) processors in the deterministic PRAM model where simultaneous concurrent reads and writes are allowed (the CRCW PRAM model <ref> [31, 32] </ref>), where we assume concurrent write conflicts are resolved arbitrarily. <p> Assuming we are given a BFS spanning tree as part of the input, our method runs in O (log n) time using O (n= log n) 15 processors in the deterministic PRAM model where concurrent reads are allowed but writes must be exclusive (the CREW PRAM model <ref> [31, 32] </ref>). If we are not given the BFS spanning tree, then our method runs in O (log n) time using O (n 3 ) processors on a CRCW PRAM (e.g., see [31, 32] for a method for constructing a BFS tree in these bounds). 3.1 Many-way Trees Since our method <p> the deterministic PRAM model where concurrent reads are allowed but writes must be exclusive (the CREW PRAM model <ref> [31, 32] </ref>). If we are not given the BFS spanning tree, then our method runs in O (log n) time using O (n 3 ) processors on a CRCW PRAM (e.g., see [31, 32] for a method for constructing a BFS tree in these bounds). 3.1 Many-way Trees Since our method produces a separation of G into many subgraphs it gives rise to a decomposition tree that is not binary. <p> One can construct a level linking of T in O (log n) time using O (n= log n) processors on a CREW PRAM. Proof: Using the Euler-tour technique on trees <ref> [31, 32, 45] </ref>, we construct a list L of the nodes in T listed in the order they would be traversed in a recursive tree traversal (such as the in-order traversal), so long as the children of a node v are "visited" according to their cyclic ordering around v. <p> With each node v in this list we associate its level number l (v), which can be computed by another application of the Euler-tour technique, along with calls to the well-known list ranking [3, 14] and parallel prefix [34, 35] techniques 3 (see also <ref> [31, 32] </ref>). All of this can be implemented in O (log n) time using O (n= log n) processors. Let v be a node in T , and let v first and v last respectively denote the first and last copies of v in L. <p> The large processor bound comes from the best known bound for constructing a BFS tree in O (log n) time (e.g., see <ref> [31, 32] </ref>). 2 We give a non-trivial application of this result in the following section. 4 Parallel Polygon Triangulation Suppose we are given a simple polygon P .
Reference: [33] <author> D.G. Kirkpatrick, M.M. Klawe, and R.E. Tarjan, </author> <title> "Polygon Triangulation in O(n log log n) time with Simple Data Structures," </title> <booktitle> Proc. 6th ACM Symp. on Computational Geometry, </booktitle> <year> 1990, </year> <pages> 34-43. </pages>
Reference-contexts: This theorem plays an important role in our method for polygon triangulation, which we now describe. 4.2 Our Polygon Triangulation Algorithm: An Overview Suppose we are given a simple polygonal chain 5 P . Following elegant conventions used by Chazelle [11], as well as Kirkpatrick, Klawe, and Tarjan <ref> [33] </ref>, we view the edges of P as having two distinct sides and we view P as being embedded in a sphere. <p> Indeed, several recent triangulation 5 We describe our method assuming a possibly open polygonal chain, since our method is based upon applying recursion to the edges of this chain. 21 algorithms (e.g., <ref> [11, 33, 44] </ref>) actually produce a trapezoidal map and then apply this result to construct a triangulation. In our case, we will construct a trapezoidal map and then apply an algorithm due to the author [24] to convert this trapezoidal map into a triangulation in parallel.
Reference: [34] <author> C. Kruskal, L. Rudolph, and M. Snir, </author> <title> "The Power of Parallel Prefix," </title> <booktitle> Proc. 1985 IEEE Int. Conf. on Parallel Proc., </booktitle> <pages> 180-185. </pages>
Reference-contexts: With each node v in this list we associate its level number l (v), which can be computed by another application of the Euler-tour technique, along with calls to the well-known list ranking [3, 14] and parallel prefix <ref> [34, 35] </ref> techniques 3 (see also [31, 32]). All of this can be implemented in O (log n) time using O (n= log n) processors.
Reference: [35] <author> R.E. Ladner and M.J. Fischer, </author> <title> "Parallel Prefix Computation," </title> <journal> J. ACM, </journal> <year> 1980, </year> <pages> 831-838. </pages>
Reference-contexts: With each node v in this list we associate its level number l (v), which can be computed by another application of the Euler-tour technique, along with calls to the well-known list ranking [3, 14] and parallel prefix <ref> [34, 35] </ref> techniques 3 (see also [31, 32]). All of this can be implemented in O (log n) time using O (n= log n) processors.
Reference: [36] <author> C.E. Leiserson, </author> <title> "Area-Efficient Graph Layouts (for VLSI)," </title> <booktitle> Proc. 21st IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1980, </year> <pages> 270-281. </pages>
Reference-contexts: This, of course, immediately leads to an O (n log n)-time algorithm for constructing an O ( p n)-separator decomposition of such a graph G, a result that has been used to solve a number of problems in VLSI layout, computational geometry, and algorithmic graph theory (e.g., see <ref> [7, 11, 20, 36, 38] </ref>). In this paper we show how to construct an O ( p n)-separator decomposition of a planar graph G in O (n) time. <p> Incidentally, this theorem immediately implies that one can perform the VLSI embedding of a planar graph in O (n) time using the algorithms of <ref> [7, 36] </ref>. Moreover, in a manner similar to the approach of Lipton and Tarjan [37], it is straightforward to generalize our methods to weighted graphs.
Reference: [37] <author> R.J. Lipton and R.E. Tarjan, </author> <title> "A Separator Theorem for Planar Graphs," </title> <journal> SIAM J. Appl. Math., </journal> <volume> 36(2), </volume> <year> 1979, </year> <pages> 177-189. </pages>
Reference-contexts: 1 Introduction Let G = (V; E) be an n-node graph. An f (n)-separator is an f (n)-sized subset of V whose removal disconnects G into two subgraphs G 1 and G 2 each of size at most 2n=3 <ref> [37] </ref>. Typically, separator finding is used to drive divide-and-conquer algorithms [7, 38], where one finds an f (n)-separator of G, dividing G into G 1 and G 2 , and then recurses on each G i . Such a recursive decomposition is called an f (n)-separator decomposition of G [7]. <p> If, on the other hand, G is a planar graph, then, in what is now a classic result in algorithmic graph theory, Lipton and Tarjan <ref> [37] </ref> show that G has an O ( p n)-separator that can be found in O (n) time. <p> In this section we present our linear-time method for constructing an O ( p n)-separator decomposition of G. 2.1 Our Approach Before we give our method, however, let us review the approach taken by Lipton and Tar-jan <ref> [37] </ref>, which we will emulate. Let T be a rooted BFS tree for G. Let L (i) denote the set of nodes at level i in T , and let F (e) denote the fundamental cycle determined by T and some non-tree edge e. <p> It is easy to see that any L (i) is a separator, since T is BFS tree, and any F (e) is a separator, since T is a spanning tree for an embedded planar graph. Lipton and Tarjan's separator theorem <ref> [37] </ref> can be viewed as an elegant method for pitting these two kinds of separators against each other in order to find an O ( p n)-sized separator. For completeness, we present a simplified version of their approach here. <p> Moreover, as Lipton and Tarjan show <ref> [37] </ref>, the resulting graph, G 0 , remains a plane graph. <p> Incidentally, this theorem immediately implies that one can perform the VLSI embedding of a planar graph in O (n) time using the algorithms of [7, 36]. Moreover, in a manner similar to the approach of Lipton and Tarjan <ref> [37] </ref>, it is straightforward to generalize our methods to weighted graphs.
Reference: [38] <author> R.J. Lipton and R.E. Tarjan, </author> <title> "Applications of a Planar Separator Theorem," </title> <journal> SIAM J. Com-put., </journal> <volume> 9(3), </volume> <year> 1980, </year> <pages> 615-627. </pages>
Reference-contexts: 1 Introduction Let G = (V; E) be an n-node graph. An f (n)-separator is an f (n)-sized subset of V whose removal disconnects G into two subgraphs G 1 and G 2 each of size at most 2n=3 [37]. Typically, separator finding is used to drive divide-and-conquer algorithms <ref> [7, 38] </ref>, where one finds an f (n)-separator of G, dividing G into G 1 and G 2 , and then recurses on each G i . Such a recursive decomposition is called an f (n)-separator decomposition of G [7]. <p> This, of course, immediately leads to an O (n log n)-time algorithm for constructing an O ( p n)-separator decomposition of such a graph G, a result that has been used to solve a number of problems in VLSI layout, computational geometry, and algorithmic graph theory (e.g., see <ref> [7, 11, 20, 36, 38] </ref>). In this paper we show how to construct an O ( p n)-separator decomposition of a planar graph G in O (n) time.
Reference: [39] <author> G.L. Miller, </author> <title> "Finding Small Simple Cycle Separators for 2-Connected Planar Graphs," </title> <journal> J. Comp. and Sys. Sci., </journal> <volume> 32, </volume> <year> 1986, </year> <pages> 265-279. </pages>
Reference-contexts: Our model of computation is the parallel random access machine (PRAM), the synchronous shared-memory parallel model in which simultaneous concurrent reads or writes are either allowed or disallowed, depending upon the submodel designation. This contrasts with the fastest previous parallel algorithm, due to Miller <ref> [39] </ref>, which finds an O ( n)-sized binary (cycle) separator in these same bounds. Note that one could iteratively use Miller's method to find a separator similar to ours, but this would require O (log 2 n) 2 time.
Reference: [40] <author> D.E. Muller and F.P. Preparata, </author> <title> "Finding the Intersection of Two Convex Polyhedra," </title> <journal> Theoretical Computer Science, </journal> <volume> Vol. 7, No. 2, </volume> <month> October </month> <year> 1978, </year> <pages> 217-236. </pages>
Reference-contexts: For example, G could be represented using the "winged edge" structure of Baumgart [4], the "quad edge" structure of Guibas and Stolfi [29], or the "doubly-connected edge list" structure of Muller and Preparata <ref> [40, 41] </ref>. In this section we present our linear-time method for constructing an O ( p n)-separator decomposition of G. 2.1 Our Approach Before we give our method, however, let us review the approach taken by Lipton and Tar-jan [37], which we will emulate.
Reference: [41] <author> F.P. Preparata and M.I. Shamos, </author> <title> Computational Geometry: An Introduction, </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1985. </year>
Reference-contexts: For example, G could be represented using the "winged edge" structure of Baumgart [4], the "quad edge" structure of Guibas and Stolfi [29], or the "doubly-connected edge list" structure of Muller and Preparata <ref> [40, 41] </ref>. In this section we present our linear-time method for constructing an O ( p n)-separator decomposition of G. 2.1 Our Approach Before we give our method, however, let us review the approach taken by Lipton and Tar-jan [37], which we will emulate.
Reference: [42] <author> D.D. Sleator and R.E. Tarjan, </author> <title> "A Data Structure for Dynamic Trees," </title> <journal> J. Comput. and Sys. Sci., </journal> <volume> 26, </volume> <pages> 362-391, </pages> <year> 1983. </year>
Reference-contexts: These data structures include standard binary search trees (such as red-black trees [28, 43]) as well as the more-sophisticated link-cut tree data structure of Sleator and Tarjan <ref> [42, 43] </ref>. Throughout the recursive decomposition we maintain the breadth-first spanning (BFS) tree [2, 17] of each individual piece the graph, so as to avoid the recomputation of BFS trees as would be required by simple recursive applications of Lipton and Tarjan's algorithm. <p> Maintaining this information for the B (i)'s subject to the above operations can easily be done in O (log n) time per operation (e.g., see [2, 17, 43]). In addition to its adjacency information, we represent T using the link-cut tree data structure of Sleator and Tarjan <ref> [42, 43] </ref>. This data structure represents an arbitrary rooted tree, such as T , as a collection of paths joined by edges not on any of these paths. <p> In particular, as mentioned in the introduction, we maintain a tree D such that each edge of D is the graph-theoretic dual of a non-tree edge in G. (See Figure 3.) As with T , we maintain D using the link-cut tree data structure of Sleator and Tarjan <ref> [42, 43] </ref>. We initialize our recursive computation by constructing each of these data structures. <p> This can all be done in O (n) time (see <ref> [26, 28, 42, 43] </ref>). 2.3 Separating G into G 1 , G 2 , and G 3 Our method for performing recursive separator, then, is to use these structures to find an O ( n)-separator and then remove the separator vertices while maintaining these data structures in the resulting "pieces." In <p> This centroid location is implemented by a simple search in the solid path in D 2 containing the root [26], and does not require any modifications to the standard link-cut tree representation <ref> [42] </ref>. Using the information obtained from the queries in T 2 , we can then perform a (temporary) cut at v and recurse on the appropriate subtree of D 2 .
Reference: [43] <author> R.E. Tarjan, </author> <title> Data Structures and Network Algorithms, </title> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <year> 1983. </year>
Reference-contexts: These data structures include standard binary search trees (such as red-black trees <ref> [28, 43] </ref>) as well as the more-sophisticated link-cut tree data structure of Sleator and Tarjan [42, 43]. <p> These data structures include standard binary search trees (such as red-black trees [28, 43]) as well as the more-sophisticated link-cut tree data structure of Sleator and Tarjan <ref> [42, 43] </ref>. Throughout the recursive decomposition we maintain the breadth-first spanning (BFS) tree [2, 17] of each individual piece the graph, so as to avoid the recomputation of BFS trees as would be required by simple recursive applications of Lipton and Tarjan's algorithm. <p> We also maintain a dynamic search tree B that is built upon the B (i)'s, stored by increasing level numbers. The specific data structure one uses is not crucial (e.g., a red-black tree <ref> [28, 43] </ref> will do) so long as, in addition to the usual operations of Search, Insert, and Delete, it also supports the following operations: * Split (B; x): split the tree B into two trees, B 1 and B 2 , such that every element in B 1 is less than <p> In each internal node in B (i) (or B) we store the number of the leaf descendents of . Maintaining this information for the B (i)'s subject to the above operations can easily be done in O (log n) time per operation (e.g., see <ref> [2, 17, 43] </ref>). In addition to its adjacency information, we represent T using the link-cut tree data structure of Sleator and Tarjan [42, 43]. This data structure represents an arbitrary rooted tree, such as T , as a collection of paths joined by edges not on any of these paths. <p> Maintaining this information for the B (i)'s subject to the above operations can easily be done in O (log n) time per operation (e.g., see [2, 17, 43]). In addition to its adjacency information, we represent T using the link-cut tree data structure of Sleator and Tarjan <ref> [42, 43] </ref>. This data structure represents an arbitrary rooted tree, such as T , as a collection of paths joined by edges not on any of these paths. <p> In particular, as mentioned in the introduction, we maintain a tree D such that each edge of D is the graph-theoretic dual of a non-tree edge in G. (See Figure 3.) As with T , we maintain D using the link-cut tree data structure of Sleator and Tarjan <ref> [42, 43] </ref>. We initialize our recursive computation by constructing each of these data structures. <p> This can all be done in O (n) time (see <ref> [26, 28, 42, 43] </ref>). 2.3 Separating G into G 1 , G 2 , and G 3 Our method for performing recursive separator, then, is to use these structures to find an O ( n)-separator and then remove the separator vertices while maintaining these data structures in the resulting "pieces." In
Reference: [44] <author> R.E. Tarjan and C.J. Van Wyk, </author> <title> "An O(n log log n)-time Algorithm for Triangulating a Simple Polygon," </title> <journal> SIAM J. Comput., </journal> <volume> 17, </volume> <year> 1988, </year> <pages> 143-178. 32 </pages>
Reference-contexts: Indeed, several recent triangulation 5 We describe our method assuming a possibly open polygonal chain, since our method is based upon applying recursion to the edges of this chain. 21 algorithms (e.g., <ref> [11, 33, 44] </ref>) actually produce a trapezoidal map and then apply this result to construct a triangulation. In our case, we will construct a trapezoidal map and then apply an algorithm due to the author [24] to convert this trapezoidal map into a triangulation in parallel.
Reference: [45] <author> R.E. Tarjan and U. Vishkin, </author> <title> "Finding Biconnected Components and Computing Tree Func--tions in Logarithmic Parallel Time," </title> <journal> SIAM J. Comput., </journal> <volume> 14, </volume> <year> 1985, </year> <pages> 862-874. </pages>
Reference-contexts: One can construct a level linking of T in O (log n) time using O (n= log n) processors on a CREW PRAM. Proof: Using the Euler-tour technique on trees <ref> [31, 32, 45] </ref>, we construct a list L of the nodes in T listed in the order they would be traversed in a recursive tree traversal (such as the in-order traversal), so long as the children of a node v are "visited" according to their cyclic ordering around v.
Reference: [46] <author> C.K. Yap, </author> <title> "Parallel Triangulation of a Polygon in Two Calls to the Trapezoidal Map," </title> <journal> Al-gorithmica, </journal> <volume> 3, </volume> <year> 1988, </year> <pages> 279-288. 33 </pages>
Reference-contexts: It also improves the previous best deterministic methods, which run in O (log n) time using O (n) processors 1 <ref> [24, 46] </ref>. As mentioned above, our triangulation method is based on an approach similar to that used in the sequential method of Chazelle [11].
References-found: 46

