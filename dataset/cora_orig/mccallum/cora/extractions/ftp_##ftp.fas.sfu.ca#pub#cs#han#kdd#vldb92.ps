URL: ftp://ftp.fas.sfu.ca/pub/cs/han/kdd/vldb92.ps
Refering-URL: http://fas.sfu.ca/cs/research/groups/DB/sections/publication/kdd/kdd.html
Root-URL: 
Email: -@cs.sfu.ca  
Title: Knowledge Discovery in Databases: An Attribute-Oriented Approach  
Author: Jiawei Han Yandong Cai, and Nick Cercone han, cai, nick 
Address: Canada V5A 1S6  
Affiliation: School of Computing Science Simon Fraser University Burnaby, British Columbia,  
Abstract: Knowledge discovery in databases, or data mining, is an important issue in the development of data- and knowledge-base systems. An attribute-oriented induction method has been developed for knowledge discovery in databases. The method integrates a machine learning paradigm, especially learning-from-examples techniques, with set-oriented database operations and extracts generalized data from actual data in databases. An attribute-oriented concept tree ascension technique is applied in generalization, which substantially reduces the computational complexity of database learning processes. Different kinds of knowledge rules, including characteristic rules, discrimination rules, quantitative rules, and data evolution regularities can be discovered efficiently using the attribute-oriented approach. In addition to learning in relational databases, the approach can be applied to knowledge discovery in nested relational and deductive databases. Learning can also be performed with databases containing noisy data and exceptional cases using database statistics. Furthermore, the rules discovered can be used to query database knowledge, answer cooperative queries and facilitate semantic query optimization. Based upon these principles, a prototyped database learning system, DBLEARN, has been constructed for experimentation. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Y. Cai, N. Cercone and J. Han, </author> <title> Attribute-Oriented Induction in Relational Databases, </title> <editor> in G. Piatetsky-Shapiro and W. J. Frawley (eds.), </editor> <title> Knowledge Discovery in Databases, </title> <publisher> AAAI/MIT Press, </publisher> <year> 1991, </year> <pages> 213-228. </pages>
Reference-contexts: Recently, data mining has been ranked as one of the most promising research topics for the 1990s by both database and machine learning researchers [7, 20]. In our previous studies <ref> [1, 10] </ref>, an attribute-oriented induction method has been developed for knowledge discovery in relational databases. The method integrates a machine learning paradigm, especially learning-from-examples techniques, with database operations and extracts generalized data from actual data in databases. <p> Notice that (iv) and (v) are optional since default concept hierarchies and a default generalization threshold can be used if no preference is specified explicitly. A database learning system, DBLEARN, has been proposed in our study <ref> [1] </ref>. The language of DBLEARN can be viewed as an extension to the relational language SQL for knowledge discovery in databases. Because of limited space, we present one short illustrative example of a learning request specified to DBLEARN. Example 2.
Reference: 2. <author> U. S. Chakravarthy, J. Grant and J. Minker, </author> <title> Logic-Based Approach to Semantic Query Optimization, </title> <journal> ACM Trans. Database Syst., </journal> <volume> 15(2), </volume> <year> 1990, </year> <pages> 162-207. </pages>
Reference-contexts: Cooperative query answering consists of analyzing the intent of query and providing generalized, neighborhood or associated information relevant to the query [4]. Semantic query optimization applies database semantics, integrity constraints and knowledge rules to optimize queries for efficient processing <ref> [2] </ref>. Previous studies on querying database knowledge and intelligent query answering [17, 19] were focused on rules and integrity constraints in relational or deductive databases. With the availability of knowledge discovery tools, it is straightforward to query general data characteristics and utilize induced rules and concept hierarchies.
Reference: 3. <author> K. C. C. Chan and A. K. C. Wong, </author> <title> A Statistical Technique for Extracting Classificatory Knowledge from Databases, </title> <editor> in G. Piatetsky-Shapiro and W. J. Frawley (eds.), </editor> <title> Knowledge Discovery in Databases, </title> <publisher> AAAI/MIT Press, </publisher> <year> 1991, </year> <pages> 107-124. </pages>
Reference-contexts: Exceptional data often occur in a large relation. It is important to consider exceptional cases when learning in databases. Statistical information helps learning-from-examples to handle exceptions and/or noisy data <ref> [3, 15] </ref>. A special attribute, vote, can be added to each generalized relation to register the number of tuples in the original relation which are generalized to the current tuple in the generalized relation. <p> Since relational operations are set-oriented and have been implemented efficiently in many existing systems, our approach is not only efficient but easily exported to many relational systems. Our approach has absorbed many advanced features of recently developed learning algorithms <ref> [3, 13] </ref>. As shown in our study, attribute-oriented induction can learn disjuctive rules and handle exceptional cases elegantly by incorporating statistical techniques in the learning process.
Reference: 4. <author> F. Cuppens and R. Demolombe, </author> <title> Cooperative Answering: A Methodology to Provide Intelligent Access to Databases, </title> <booktitle> Proc. 2nd Int. Conf. Expert Database Systems, </booktitle> <address> Fairfax, VA, </address> <month> April </month> <year> 1988, </year> <pages> 621-643. </pages>
Reference-contexts: Database knowledge represents the semantic information associated with databases, which includes deduction rules, integrity constraints, concept hierarchies about data and general data characteristics [17]. Cooperative query answering consists of analyzing the intent of query and providing generalized, neighborhood or associated information relevant to the query <ref> [4] </ref>. Semantic query optimization applies database semantics, integrity constraints and knowledge rules to optimize queries for efficient processing [2]. Previous studies on querying database knowledge and intelligent query answering [17, 19] were focused on rules and integrity constraints in relational or deductive databases.
Reference: 5. <author> T. G. Dietterich and R. S. Michalski, </author> <title> A Comparative Review of Selected Methods for Learning from Examples, </title> <editor> in Michalski et. al. (eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol. 1, </volume> <publisher> Morgan Kaufmann, </publisher> <year> 1983, </year> <pages> 41-82. </pages>
Reference-contexts: A database learning language Given a number of examples, generalization can be performed in many different directions <ref> [5] </ref>. Unconstrained learning may result in a very large set of learned rules. Moreover, different rules can be extracted from the same set of data using different background knowledge (concept hierarchies). <p> Relational systems store a large amount of information in a structured and organized manner and are implemented by well-developed storage and accessing techniques [20]. In contrast to most existing learning algorithms which do not take full advantages of these database facilities <ref> [5, 12, 15] </ref>, our approach primarily adopts relational operations, such as selection, join, projection (extracting relevant data and removing attributes), tuple substitution (ascending concept trees), and intersection (discovering common tuples among classes).
Reference: 6. <author> D. Fisher, </author> <title> Improving Inference Through Conceptual Clustering, </title> <booktitle> Proc. 1987 AAAI Conf., </booktitle> <address> Seattle, Washington, </address> <month> July </month> <year> 1987, </year> <pages> 461-465. </pages>
Reference-contexts: One may classify 0 to 1.99 into one class, and 2 to 2.99 into another but give finer classifications for those between 3 and 4. Even for attributes with discrete values, statistical techniques can be used under certain circumstances <ref> [6] </ref>. For example, if the birthplace of most students are clustered in Canada and scattered in many different countries, the highest level concepts of the attribute can be categorized into "Canada" and "foreign". Similarly, an available concept hierarchy can be modified based on database statistics. <p> Similarly, an available concept hierarchy can be modified based on database statistics. Moreover, the concept hierarchy of an attribute can also be discovered or refined based on its relationship with other attributes <ref> [6] </ref>. Different concept hierarchies can be constructed on the same attribute based on different viewpoints or preferences.
Reference: 7. <author> W. J. Frawley, G. Piatetsky-Shapiro and C. J. Matheus, </author> <title> Knowledge Discovery in Databases: An Overview, </title> <editor> in G. Piatetsky-Shapiro and W. J. Frawley (eds.), </editor> <title> Knowledge Discovery in Databases, </title> <publisher> AAAI/MIT Press, </publisher> <year> 1991, </year> <pages> 1-27. </pages>
Reference-contexts: 1. Introduction Knowledge discovery is the nontrivial extraction of implicit, previously unknown, and potentially useful information from data <ref> [7] </ref>. <p> Recently, data mining has been ranked as one of the most promising research topics for the 1990s by both database and machine learning researchers <ref> [7, 20] </ref>. In our previous studies [1, 10], an attribute-oriented induction method has been developed for knowledge discovery in relational databases. The method integrates a machine learning paradigm, especially learning-from-examples techniques, with database operations and extracts generalized data from actual data in databases. <p> A Comparison with Other Learning Algorithms Attribute-oriented induction provides a simple and efficient way to learn different kinds of knowledge rules in relational and extended relational databases. As a newly emerging field, there have been only a few database-oriented knowledge discovery systems reported <ref> [7, 12] </ref>, most of which are based on the previously developed learning algorithms. The major difference of our approach from others is attribute-oriented vs. tuple-oriented induction. It is essential to compare these two approaches.
Reference: 8. <editor> H. Gallaire, J. Minker and J. Nicolas, </editor> <title> Logic and Databases: A Deductive Approach, </title> <journal> ACM Comput. Surv., </journal> <volume> 16(2), </volume> <year> 1984, </year> <pages> 153-185. </pages>
Reference-contexts: Further generalization of the relation. The final generalized relation consists of only a small number of tuples, and this generalized relation can be transformed into a simple logical formula. Based upon the principles of logic and databases <ref> [8, 22] </ref>, we have evolved Strategy 7. Strategy 7. (Rule transformation) A tuple in a final generalized relation is transformed to conjunctive normal form, and multiple tuples are transformed to disjunctive normal form. <p> The first phase is performed by finding all of the award candidates in the computing science department. This corresponds to a dedutive query which can be processed using deductive database technology <ref> [8, 22] </ref>. The second phase is to extract knowledge from those candidates, which is the same as attribute-oriented induction for learning characteristic rules. ` When deduction rules involve recursion, the deduction process itself could be rather complex [22].
Reference: 9. <author> M. Genesereth and N. Nilsson, </author> <booktitle> Logical Foundations of Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year>
Reference-contexts: Relevant data may extend over several relations. A query can be used to collect task-relevant data from the database. Task-relevant data can be viewed as examples for learning processes. Undoubtedly, learning-from-examples <ref> [9, 14] </ref> should be an important strategy for knowledge discovery in databases. Most learning-from-examples algorithms partition the set of examples into positive and negative sets and perform generalization using the positive data and specialization using the negative ones [14].
Reference: 10. <author> J. Han, Y. Cai and N. Cercone, </author> <title> Data-Driven Discovery of Quantitative Rules in Relational Databases, </title> <journal> IEEE Trans. Knowledge and Data Engineering, </journal> <volume> 4(3), </volume> <year> 1992. </year>
Reference-contexts: Recently, data mining has been ranked as one of the most promising research topics for the 1990s by both database and machine learning researchers [7, 20]. In our previous studies <ref> [1, 10] </ref>, an attribute-oriented induction method has been developed for knowledge discovery in relational databases. The method integrates a machine learning paradigm, especially learning-from-examples techniques, with database operations and extracts generalized data from actual data in databases.
Reference: 11. <author> D. Haussler, </author> <title> Bias, Version Spaces and Valiant's Learning Framework, </title> <booktitle> Proc. 4th Int. Workshop on Machine Learning, </booktitle> <address> Irvine, CA, </address> <year> 1987, </year> <pages> 324-336. </pages>
Reference-contexts: The concept taxonomy can be partially ordered according to a general-to-specific ordering. The most general concept is the null description (described by a reserved word "ANY"), and the most specific concepts correspond to the specific values of attributes in the database <ref> [11] </ref>.
Reference: 12. <author> K. A. Kaufman, R. S. Michalski and L. Kerschberg, </author> <title> Mining for Knowledge in Databases: Goals and General Description of the INLEN System, </title> <editor> in G. Piatetsky-Shapiro and W. J. Frawley (eds.), </editor> <title> Knowledge Discovery in Databases, </title> <publisher> AAAI/MIT Press, </publisher> <year> 1991, </year> <pages> 449-462. </pages>
Reference-contexts: A Comparison with Other Learning Algorithms Attribute-oriented induction provides a simple and efficient way to learn different kinds of knowledge rules in relational and extended relational databases. As a newly emerging field, there have been only a few database-oriented knowledge discovery systems reported <ref> [7, 12] </ref>, most of which are based on the previously developed learning algorithms. The major difference of our approach from others is attribute-oriented vs. tuple-oriented induction. It is essential to compare these two approaches. <p> Relational systems store a large amount of information in a structured and organized manner and are implemented by well-developed storage and accessing techniques [20]. In contrast to most existing learning algorithms which do not take full advantages of these database facilities <ref> [5, 12, 15] </ref>, our approach primarily adopts relational operations, such as selection, join, projection (extracting relevant data and removing attributes), tuple substitution (ascending concept trees), and intersection (discovering common tuples among classes).
Reference: 13. <author> M. V. Manago and Y. Kodratoff, </author> <title> Noise and Knowledge Acquisition, </title> <booktitle> Proc. 10th Int. Joint Conf. Artificial Intelligence, </booktitle> <address> Milan, Italy, </address> <year> 1987, </year> <pages> 348-354. </pages>
Reference-contexts: Since relational operations are set-oriented and have been implemented efficiently in many existing systems, our approach is not only efficient but easily exported to many relational systems. Our approach has absorbed many advanced features of recently developed learning algorithms <ref> [3, 13] </ref>. As shown in our study, attribute-oriented induction can learn disjuctive rules and handle exceptional cases elegantly by incorporating statistical techniques in the learning process.
Reference: 14. <author> R. S. Michalski, </author> <title> A Theory and Methodology of Inductive Learning, </title> <editor> in Michalski et. al. (eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol. 1, </volume> <publisher> Morgan Kaufmann, </publisher> <year> 1983, </year> <pages> 83-134. </pages>
Reference-contexts: Relevant data may extend over several relations. A query can be used to collect task-relevant data from the database. Task-relevant data can be viewed as examples for learning processes. Undoubtedly, learning-from-examples <ref> [9, 14] </ref> should be an important strategy for knowledge discovery in databases. Most learning-from-examples algorithms partition the set of examples into positive and negative sets and perform generalization using the positive data and specialization using the negative ones [14]. <p> Undoubtedly, learning-from-examples [9, 14] should be an important strategy for knowledge discovery in databases. Most learning-from-examples algorithms partition the set of examples into positive and negative sets and perform generalization using the positive data and specialization using the negative ones <ref> [14] </ref>. Unfortunately, a relational database does not explicitly store negative data, and thus no explicitly specified negative examples can be used for specialization. Therefore, a database induction process relies mainly on generalization, which should be performed cautiously to avoid overgeneralization. <p> In a generalized relation, some or all of its attribute values are generalized data, that is, nonleaf nodes in the concept hierarchies. Some learning-from-examples algorithms require the final learned rule to be in conjunctive normal form <ref> [14] </ref>. This requirement is usually unreasonable for large databases since the generalized data often contain different cases. However, a rule containing a large number of disjuncts indicates that it is in a complex form and further generalization should be performed. <p> Strategy 2. (Attribute removal) If there is a large set of distinct values for an attribute but there is no higher level concept provided for the attribute, the attribute should be removed in the generalization process. Rationale. This strategy corresponds to the generalization rule, dropping conditions, in learning-from-examples <ref> [14] </ref>. Since an attribute-value pair represents a conjunct in the logical form of a tuple, removal of a conjunct eliminates a constraint and thus generalizes the rule. <p> Minimal generalization should be enforced by ascending the tree one level at a time. Rationale. This strategy corresponds to the generalization rule, climbing generalization trees, in learning-from-examples <ref> [14] </ref>. The substitution of an attribute value by its higher level concept makes the tuple cover more cases than the original one and thus generalizes the tuple.
Reference: 15. <author> R. S. Michalski, J. G. Carbonell and T. M. Mitchell, </author> <title> Machine Learning, </title> <booktitle> An Artificial Intelligence Approach, </booktitle> <volume> Vol. 2, </volume> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: Exceptional data often occur in a large relation. It is important to consider exceptional cases when learning in databases. Statistical information helps learning-from-examples to handle exceptions and/or noisy data <ref> [3, 15] </ref>. A special attribute, vote, can be added to each generalized relation to register the number of tuples in the original relation which are generalized to the current tuple in the generalized relation. <p> Relational systems store a large amount of information in a structured and organized manner and are implemented by well-developed storage and accessing techniques [20]. In contrast to most existing learning algorithms which do not take full advantages of these database facilities <ref> [5, 12, 15] </ref>, our approach primarily adopts relational operations, such as selection, join, projection (extracting relevant data and removing attributes), tuple substitution (ascending concept trees), and intersection (discovering common tuples among classes). <p> Moreover, when a new tuple is inserted into a database relation, rather than restarting the learning process from the beginning, it is preferable to amend and fortify what was learned from the previous data. Our algorithms can be easily extended to faciliate such incremental learning <ref> [15] </ref>. Let the generalized relation be stored in the database. When a new tuple is inserted into a database, the concepts of the new tuple are first generalized to the level of the concepts in the generalized relation. Then the generalized tuple can be naturally merged into the generalized relation.
Reference: 16. <author> T. M. Mitchell, </author> <title> Generalization as Search, </title> <journal> Artificial Intelligence, </journal> <volume> 18, </volume> <year> 1982, </year> <pages> 203-226. </pages>
Reference-contexts: However, the former technique performs generalization tuple by tuple, while the latter, attribute by attribute. The two approaches involves significantly different search spaces. Among many learning-from-examples algorithms, we use the candidate elimination algorithm <ref> [16] </ref> as an example to demonstrate such a difference. In the candidate elimination algorithm, the set of all of the concepts which are consistent with training examples is called the version space of the training examples.
Reference: 17. <author> A. Motro and Q. Yuan, </author> <title> Querying Database Knowledge, </title> <booktitle> Proc. 1990 ACM-SIGMOD Conf. Management of Data, </booktitle> <address> Atlantic City, NJ, </address> <month> June </month> <year> 1990, </year> <pages> 173-183. </pages>
Reference-contexts: Lots can be explored using meta-data (such as concept hierarchies) and discovered knowledge. We present a few ideas for this below. Database knowledge represents the semantic information associated with databases, which includes deduction rules, integrity constraints, concept hierarchies about data and general data characteristics <ref> [17] </ref>. Cooperative query answering consists of analyzing the intent of query and providing generalized, neighborhood or associated information relevant to the query [4]. Semantic query optimization applies database semantics, integrity constraints and knowledge rules to optimize queries for efficient processing [2]. <p> Semantic query optimization applies database semantics, integrity constraints and knowledge rules to optimize queries for efficient processing [2]. Previous studies on querying database knowledge and intelligent query answering <ref> [17, 19] </ref> were focused on rules and integrity constraints in relational or deductive databases. With the availability of knowledge discovery tools, it is straightforward to query general data characteristics and utilize induced rules and concept hierarchies. <p> Example 8. To describe the characteristics of the graduate students in cs (computing science) who were born in Canada with excellent academic performance, the query can be formulated using a syntax similar to the knowledge queries in <ref> [17] </ref> as follows. describe Student where Status = "graduate" and Major = "cs" and Birth_Place = "Canada" and GPA = "excellent" Notice that "graduate", "Canada" and "excellent" are not stored as primitive data in the Student relation.
Reference: 18. <author> M. A. Roth, H. F. Korth and A. Silberschatz, </author> <title> Extended Algebra and Calculus for Nested Relational Databases, </title> <journal> ACM Trans. Database Syst., </journal> <volume> 13(4), </volume> <year> 1988, </year> <pages> 389-417. </pages>
Reference-contexts: Nested-relational and deductive databases are two influential extended-relational systems. Interestingly, attribute-oriented induction can be easily extended to knowledge discovery in these systems. The nested relational model allows nonatomic, relational-valued domains. Thus, a hierarchy of nested relations is formed <ref> [18] </ref>. The attribute-oriented induction can be performed easily on the atomic domains in the same way as in relational systems.
Reference: 19. <author> C. D. Shum and R. Muntz, </author> <title> Implicit Representation for Extensional Answers, </title> <booktitle> Proc. 2nd Int. Conf. Expert Database Systems, </booktitle> <address> Vienna, VA, </address> <month> April </month> <year> 1988, </year> <pages> 497-522. </pages>
Reference-contexts: Semantic query optimization applies database semantics, integrity constraints and knowledge rules to optimize queries for efficient processing [2]. Previous studies on querying database knowledge and intelligent query answering <ref> [17, 19] </ref> were focused on rules and integrity constraints in relational or deductive databases. With the availability of knowledge discovery tools, it is straightforward to query general data characteristics and utilize induced rules and concept hierarchies.
Reference: 20. <author> A. Silberschatz, M. Stonebraker and J. D. Ullman, </author> <title> Database Systems: Achievements and Opportunities, </title> <journal> Comm. ACM, </journal> <volume> 34(10), </volume> <year> 1991, </year> <pages> 94-109. </pages>
Reference-contexts: Recently, data mining has been ranked as one of the most promising research topics for the 1990s by both database and machine learning researchers <ref> [7, 20] </ref>. In our previous studies [1, 10], an attribute-oriented induction method has been developed for knowledge discovery in relational databases. The method integrates a machine learning paradigm, especially learning-from-examples techniques, with database operations and extracts generalized data from actual data in databases. <p> Towards Knowledge Discovery in Extended-Relational Databases The relational data model has been extended in many ways to meet the requirements of new database applications <ref> [20] </ref>. Nested-relational and deductive databases are two influential extended-relational systems. Interestingly, attribute-oriented induction can be easily extended to knowledge discovery in these systems. The nested relational model allows nonatomic, relational-valued domains. Thus, a hierarchy of nested relations is formed [18]. <p> Another obvious advantage of our approach over many other learning algorithms is our integration of the learning process with database operations. Relational systems store a large amount of information in a structured and organized manner and are implemented by well-developed storage and accessing techniques <ref> [20] </ref>. In contrast to most existing learning algorithms which do not take full advantages of these database facilities [5, 12, 15], our approach primarily adopts relational operations, such as selection, join, projection (extracting relevant data and removing attributes), tuple substitution (ascending concept trees), and intersection (discovering common tuples among classes).
Reference: 21. <author> D. Subramanian and J. Feigenbaum, </author> <title> Factorization in Experiment Generation, </title> <booktitle> Proc. 1986 AAAI Conf., </booktitle> <address> Philadelphia, PA, </address> <month> August </month> <year> 1986, </year> <pages> 518-522. </pages>
Reference-contexts: Suppose there are p nodes in each concept tree and there are k concept trees (attributes) in the relation, the total size of k factorized version spaces is p k . However, the size of the unfactorized version space for the same concept tree should be p k <ref> [21] </ref>. This can be verified from Fig. 3. Suppose the concept hierarchy is specified as: math, physics- science, and -M.S., Ph.D.- graduate. The corresponding entire version space and factored version space are Fig. 3 (a) and Fig. 3 (b), respectively.
Reference: 22. <author> J. D. Ullman, </author> <title> Principles of Database and Knowledge-Base Systems, </title> <journal> Vols. </journal> <volume> 1 & 2, </volume> <publisher> Computer Science Press, </publisher> <year> 1989. </year>
Reference-contexts: Further generalization of the relation. The final generalized relation consists of only a small number of tuples, and this generalized relation can be transformed into a simple logical formula. Based upon the principles of logic and databases <ref> [8, 22] </ref>, we have evolved Strategy 7. Strategy 7. (Rule transformation) A tuple in a final generalized relation is transformed to conjunctive normal form, and multiple tuples are transformed to disjunctive normal form. <p> The first phase is performed by finding all of the award candidates in the computing science department. This corresponds to a dedutive query which can be processed using deductive database technology <ref> [8, 22] </ref>. The second phase is to extract knowledge from those candidates, which is the same as attribute-oriented induction for learning characteristic rules. ` When deduction rules involve recursion, the deduction process itself could be rather complex [22]. <p> The second phase is to extract knowledge from those candidates, which is the same as attribute-oriented induction for learning characteristic rules. ` When deduction rules involve recursion, the deduction process itself could be rather complex <ref> [22] </ref>. However, the knowledge discovery process is still carried out by performing first deduction then induction. Notice that deduction may involve consulting concept hierarchies if a deduction rule is defined using higher-level concepts.
Reference: 23. <author> J. Zytkow and J. Baker, </author> <title> Interactive Mining of Regularities in Databases, </title> <editor> in G. Piatetsky-Shapiro and W. J. Frawley (eds.), </editor> <title> Knowledge Discovery in Databases, </title> <publisher> AAAI/MIT Press, </publisher> <year> 1991, </year> <pages> 31-54. </pages>
Reference-contexts: Following different paths corresponds to the way in which different people may learn differently from the same set of examples. The generalized relations can be examined by users or experts interactively to filter out trivial rules and preserve interesting ones <ref> [23] </ref>. Table 3 represents a generalized relation consisting of five tuples. Further generalization is needed to reduce the number of tuples.
References-found: 23

