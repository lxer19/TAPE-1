URL: http://www.cs.ucsd.edu/~calder/papers/ISCA-95-Spec.ps.Z
Refering-URL: http://www.cs.ucsd.edu/~calder/papers.html
Root-URL: http://www.cs.ucsd.edu
Email: fdlee,baerg@cs.washington.edu  fcalder,grunwaldg@cs.colorado.edu  
Title: Instruction Cache Fetch Policies for Speculative Execution  
Author: Dennis Lee and Jean-Loup Baer Brad Calder and Dirk Grunwald 
Address: Box 352350  Seattle, WA 98195-2350  Campus Box 430  Boulder, CO 80309  
Affiliation: Department of Computer Science and Engineering,  University of Washington  Department of Computer Science  University of Colorado  
Abstract: In this paper, we investigate the implications of speculative execution on instruction cache performance. We explore policies for managing instruction cache misses ranging from aggressive policies (always fetch on the speculative path) to conservative ones (wait until branches are resolved). We test these policies and their interaction with next-line prefetching by simulating the effects on instruction caches with varying architectural parameters. Our results suggest that an aggressive policy combined with next-line prefetching is best for small latencies while more conservative policies are preferable for large latencies. 
Abstract-found: 1
Intro-found: 1
Reference: [Bray & Flynn 91] <author> Bray, B. and Flynn, M. J. </author> <title> Strategies for branch target buffers. </title> <booktitle> In 24th Annual International Symposium and Workshop on Microprogramming, </booktitle> <pages> pages 42-50. </pages> <publisher> ACM, </publisher> <year> 1991. </year>
Reference: [Calder & Grunwald 94] <author> Calder, B. and Grunwald, D. </author> <title> Fast & accurate instruction fetch and branch prediction. </title> <booktitle> In 21st Annual International Symposium on Computer Architecture. ACM, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: An alternative BTB architecture is the decoupled design, where the branch prediction information is not associated with the BTB and is used for all conditional branches, including those not recorded in the BTB. <ref> [Calder & Grunwald 94] </ref> found that decoupled designs performed better than coupled designs. This allows conditional branches that do not hit in the BTB to use dynamic prediction. The PowerPC 604 is an example of an architecture using a decoupled design.
Reference: [Jouppi 90] <author> Jouppi, N. </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers. </title> <booktitle> In 17th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 364-373. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1990. </year>
Reference-contexts: An extension to next-line prefetching where several consecutive data streams are prefetched in FIFO stream buffers has been proposed by <ref> [Jouppi 90] </ref>. It was found that 85% of the misses of a 4KB I-cache could be removed by a stream buffer with four 8-byte entries. [Smith & W.-C.Hsu 92] studied next-line prefetching for instruction caches in machines with high bandwidth and large cache lines (e.g., 16 to 128 words).
Reference: [Lee & Smith 84] <author> Lee, J. K. F. and Smith, A. J. </author> <title> Branch prediction strategies and branch target buffer design. </title> <journal> IEEE Computer, </journal> <volume> 21(7) </volume> <pages> 6-22, </pages> <month> January </month> <year> 1984. </year>
Reference: [McFarling & Hennessy 86] <author> McFarling, S. and Hennessy, J. </author> <title> Reducing the cost of branches. </title> <booktitle> In 13th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 396-403. </pages> <publisher> ACM, </publisher> <year> 1986. </year>
Reference: [McFarling 93] <author> McFarling, S. </author> <title> Combining branch predictors. </title> <address> TN 36, DEC-WRL, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: The shift register is used as an index into the PHT, much as the program counter is used for a direct-mapped PHT. This provides contextual information and correlation about particular patterns of branches. Recently, <ref> [McFarling 93] </ref> showed that combining branch history with the branch's address was more effective. His method used the exclusive-or of the global history register and the branch address as the index into the PHT. 2.2 Instruction cache prefetching The next-line prefetching policy was introduced by [Smith 82] for unified caches.
Reference: [Pan et al. 92] <author> Pan, S.-T., So, K., and Rahmeh, J. T. </author> <title> Improving the accuracy of dynamic branch prediction using branch correlation. </title> <booktitle> In Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 76-84, </pages> <address> Boston, Mass., </address> <month> October </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: There are several different PHT variations. <ref> [Pan et al. 92] </ref> and [Yeh & Patt 92a, Yeh & Patt 93] investigated branch-correlation or two-level branch prediction mechanisms. Although there are a number of variants, these mechanisms generally combine the history of several recent branches to predict the outcome of a branch.
Reference: [Perleberg & Smith 93] <author> Perleberg, C. and Smith, A. J. </author> <title> Branch target buffer design and optimization. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 42(4) </volume> <pages> 396-412, </pages> <month> April </month> <year> 1993. </year>
Reference: [Pierce & Mudge 94] <author> Pierce, J. and Mudge, T. </author> <title> Wrong-path instruction prefetching. </title> <type> Technical Report CSE-222-94, </type> <institution> University of Michigan, </institution> <year> 1994. </year>
Reference-contexts: They also examined target prefetch ing, which uses a table of target addresses for prefetching taken branches. Their results show that next-line prefetching performed slightly better than target prefetching, and when these two techniques were combined, the original miss rate was reduced by a factor of 2 to 3. <ref> [Pierce & Mudge 94] </ref> investigated a prefetching algorithm where both paths of a conditional branch are prefetched. They called this scheme wrong-path prefetching because no attempt is made to prefetch from the predicted path. Their approach combines next-line prefetching and target prefetching. <p> An I-cache miss takes precedence over any prefetch, and target prefetches take precedence over next-line prefetches. They found that next-line prefetching accounts for 70 to 80% of the gain in performance with this scheme, and target prefetching accounts for the rest [Pierce 95]. Neither [Smith & W.-C.Hsu 92] nor <ref> [Pierce & Mudge 94] </ref> examined the effects of handling cache misses during speculative execution and its interaction with prefetching. 3 Instruction Cache Policies and Speculative Execution In contrast with the studies mentioned above, we investigate the effect of speculative execution and instruction prefetching on a blocking I-cache and on a very
Reference: [Pierce 95] <author> Pierce, J. E. </author> <title> Cache Behavior in the Presence of Speculative Execution The Benefits of Misprediction. </title> <type> PhD dissertation, </type> <institution> University of Michigan, </institution> <year> 1995. </year>
Reference-contexts: An I-cache miss takes precedence over any prefetch, and target prefetches take precedence over next-line prefetches. They found that next-line prefetching accounts for 70 to 80% of the gain in performance with this scheme, and target prefetching accounts for the rest <ref> [Pierce 95] </ref>.
Reference: [Smith & W.-C.Hsu 92] <author> Smith, J. and W.-C.Hsu. </author> <title> Prefetching in supercomputer instruction caches. </title> <booktitle> In Supercomputing '92, </booktitle> <pages> pages 332-339, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: An extension to next-line prefetching where several consecutive data streams are prefetched in FIFO stream buffers has been proposed by [Jouppi 90]. It was found that 85% of the misses of a 4KB I-cache could be removed by a stream buffer with four 8-byte entries. <ref> [Smith & W.-C.Hsu 92] </ref> studied next-line prefetching for instruction caches in machines with high bandwidth and large cache lines (e.g., 16 to 128 words). <p> They called this scheme wrong-path prefetching because no attempt is made to prefetch from the predicted path. Their approach combines next-line prefetching and target prefetching. The next-line prefetching prefetches the fall-through path of the conditional branch while target prefetching prefetches the taken path. Unlike <ref> [Smith & W.-C.Hsu 92] </ref>, the target address of the conditional branch is computed in the decode stage instead of using a table of target addresses. All prefetch line addresses are put into a prefetch queue and are processed in a priority order. <p> An I-cache miss takes precedence over any prefetch, and target prefetches take precedence over next-line prefetches. They found that next-line prefetching accounts for 70 to 80% of the gain in performance with this scheme, and target prefetching accounts for the rest [Pierce 95]. Neither <ref> [Smith & W.-C.Hsu 92] </ref> nor [Pierce & Mudge 94] examined the effects of handling cache misses during speculative execution and its interaction with prefetching. 3 Instruction Cache Policies and Speculative Execution In contrast with the studies mentioned above, we investigate the effect of speculative execution and instruction prefetching on a blocking <p> However, for applications that have a high miss rate (i.e., gcc, tex, cfront, groff, and lic), Resume still offers a modest improvement (8-12%) in instruction issue rates over Optimistic. 5.3 Next-line prefetching Next-line prefetching has been shown to significantly improve the performance of the I-cache <ref> [Smith & W.-C.Hsu 92] </ref>. In this section, we look into the interaction between prefetching and speculative execution. with and without next-line prefetching. The bars labelled with 8 without next-line prefetching for Oracle, Resume, and Pessimistic.
Reference: [Smith 81] <author> Smith, J. E. </author> <title> A study of branch prediction strategies. </title> <booktitle> In 8th Annual International Symposium of Computer Architecture. ACM, </booktitle> <year> 1981. </year>
Reference: [Smith 82] <author> Smith, A. J. </author> <title> Cache memories. </title> <journal> Computing Surveys, </journal> <volume> 14(3) </volume> <pages> 473-530, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: Recently, [McFarling 93] showed that combining branch history with the branch's address was more effective. His method used the exclusive-or of the global history register and the branch address as the index into the PHT. 2.2 Instruction cache prefetching The next-line prefetching policy was introduced by <ref> [Smith 82] </ref> for unified caches. Upon referencing line i, line i +1 can be prefetched.
Reference: [Srivastava & Eustace 94] <author> Srivastava, A. and Eustace, A. </author> <title> Atom: A system for building customized program analysis tools. </title> <booktitle> In Proceedings of the ACM SIGPLAN '94 Conference on Programming Language Design and Implementation. ACM, </booktitle> <year> 1994. </year>
Reference-contexts: We instrumented programs from the SPEC92 benchmark suite and object-oriented programs written in C++. Table 2 describes the programs we simulated and the inputs used. We used ATOM <ref> [Srivastava & Eustace 94] </ref> to instrument the programs. Due to the structure of ATOM, we did not need to record traces and could trace very long-running programs. 4.1 Architectures Simulated and Performance Metrics We simulated a four-way superscalar machine.
Reference: [Yeh & Patt 92a] <author> Yeh, T.-Y. and Patt, Y. N. </author> <title> Alternative implementations of two-level adaptive branch predictions. </title> <booktitle> In 19th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 124-134, </pages> <address> Gold Coast, Australia, </address> <month> May </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: There are several different PHT variations. [Pan et al. 92] and <ref> [Yeh & Patt 92a, Yeh & Patt 93] </ref> investigated branch-correlation or two-level branch prediction mechanisms. Although there are a number of variants, these mechanisms generally combine the history of several recent branches to predict the outcome of a branch. The simplest example is the degenerate method.
Reference: [Yeh & Patt 92b] <author> Yeh, T.-Y. and Patt, Y. N. </author> <title> A comprehensive instruction fetch mechanism for a processor supporting speculative execution. </title> <booktitle> In 25th Annual International Symposium on Microar-chitecture, </booktitle> <pages> pages 129-139, </pages> <address> Portland, Or, </address> <month> December </month> <year> 1992. </year> <note> ACM. </note>
Reference: [Yeh & Patt 93] <author> Yeh, T.-Y. and Patt, Y. N. </author> <title> A comparison of dynamic branch predictors that use two levels of branch history. </title> <booktitle> In 20th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 257-266, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <journal> ACM. </journal> <volume> 11 </volume>
Reference-contexts: There are several different PHT variations. [Pan et al. 92] and <ref> [Yeh & Patt 92a, Yeh & Patt 93] </ref> investigated branch-correlation or two-level branch prediction mechanisms. Although there are a number of variants, these mechanisms generally combine the history of several recent branches to predict the outcome of a branch. The simplest example is the degenerate method.
References-found: 17

