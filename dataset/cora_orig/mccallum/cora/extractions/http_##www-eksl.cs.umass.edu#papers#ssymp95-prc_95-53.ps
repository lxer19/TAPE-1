URL: http://www-eksl.cs.umass.edu/papers/ssymp95-prc_95-53.ps
Refering-URL: http://eksl-www.cs.umass.edu/publications.html
Root-URL: 
Title: A Representation and Learning Mechanisms for Mental States  
Author: Paul Cohen, Marc Atkin, Tim Oates and Dawn Gregory 
Address: Box 34610  Amherst, MA 01003-4610  
Affiliation: Computer Science  Experimental Knowledge Systems Laboratory Computer Science Department,  Lederle Graduate Research Center University of Massachusetts  
Note: In Working Notes of the Symposium on Representing Mental States and Mechanisms, AAAI-95 Spring Symposium Series, pp. 15-21.  This research is supported by ARPA/Rome Laboratory under contract F30602-93-C-0100.  
Pubnum: Technical Report 95-53  
Abstract: We want to build an agent that plans by imagining sequences of future states. Subjectively, these states seem very rich and detailed. Providing an agent with sufficiently rich knowledge about its world is an impediment to studying this kind of planning, so we have developed mechanisms for an agent to learn about its world. One mechanism learns dependencies between synchronous "snapshots" of the world; the other learns about processes and their relationships. 
Abstract-found: 1
Intro-found: 1
Reference: <institution> Computational Intelligence. </institution> <year> 1994. </year> <title> The Imagery Debate Revisited. </title> <journal> Special issue of Computational Intelligence, </journal> <volume> Vol. 9, No. </volume> <pages> 4. </pages>
Reference-contexts: We know enough about processes such as hoisting cabinets to support planning by visualization. The focus of this paper is how we learn about processes. Our purpose here is not to enter the debate about the nature and implementation of mental imagery <ref> (Computational Intelligence, 1994) </ref>. Nor are we claiming that propositional AI planning is incompatible with the sort of imagining we just described.
Reference: <author> Gibson, J .J. </author> <year> 1979. </year> <title> The Ecological Approach to Visual Perception. </title> <address> Boston: Houghton-Mi*in. </address>
Reference-contexts: Informally, a fluent is something that doesn't change over time. The components of the (aaabbb) + fluent change, but their pattern does not. Fluents are analogous to the Gib-sonian notion of perceptual invariant|something that remains constant amidst change, like the derivative of a function <ref> (Gibson, 1979) </ref>. The durations of fluents vary, whereas the duration of a multitoken is just one time step. We want agents to learn to characterize the current state by the fluents that are currently active, not by the current multitoken.
Reference: <author> Hammond., K. </author> <year> 1986. </year> <title> CHEF: A Model of Case-based Planning. </title> <booktitle> Proceedings of the Fifth National Conference on Artificial Intelligence. </booktitle> <pages> pp. 261-271. </pages>
Reference-contexts: In fact, we don't know whether relationships between fluents are different in kind from the knowledge we use to imagine activities. The structure of fluents (and relationships among them) seems minimal compared with the rich structures in, say, the case-based planning literature <ref> (e.g., Hammond, 1986) </ref>. We do not yet know how Baby "carves up" its experiences. We tend to think of processes in terms of a beginning, middle, and end, and there's considerable consensus about which activities are which.
Reference: <author> A. E. Howe and P. R. Cohen. </author> <title> Understanding Planner Behavior. </title> <note> To appear in AI Journal, </note> <year> 1995. </year>
Reference: <author> J. M. Mandler. </author> <title> How to Build a Baby: II. Conceptual Primitives. </title> <journal> Psychological Review, 1992, </journal> <volume> Vol. 99, No. 4, </volume> <pages> pp. 587-604. </pages>
Reference-contexts: Thus the fluent (aaabbb) + tells the agent that two sensory experiences follow each other repeatedly. In this sense, fluents provide the sort of abstraction of sensory information that Jean Mandler argues is essential for infant conceptual and language development <ref> (Mandler, 1992) </ref>.
Reference: <author> J. McCarthy and P. J. Hayes. </author> <year> 1969. </year> <title> Some Philosophical Problems from the Standpoint of Artificial Intelligence. </title> <editor> In B. Meltzer and D. Michie, </editor> <booktitle> Machine Intelligence IV. </booktitle> <publisher> Elsevier. </publisher>
Reference-contexts: Perhaps crude plans can be generated by conventional, propositional AI algorithms, but checking a plan seems to require some ability to imagine or visualize oneself executing it. Subjectively, the frame problem and problems of relevance don't seem to arise <ref> (McCarthy and Hayes, 1969) </ref>. Suppose that in an attempt to have the screws near at hand, you place them on one of the shelves of the cabinet before you lift it.
Reference: <author> T. Oates, D. E. Gregory and P. R. Cohen. </author> <title> Detecting Complex Dependencies in Data. </title> <booktitle> To appear in Proceedings of the Fifth International Workshop on AI and Statistics, </booktitle> <year> 1995. </year>
Reference-contexts: Thus, we can present an agent with an arbitrarily rich environment from which to construct rules governing mul-titoken transitions. In one experiment <ref> (Oates et al.,1995) </ref> we generated streams that were for the most part random but contained a small number of probabilistic dependencies between multitokens. <p> On ten datasets for which multiple results have been published, msdd performance exceeds that of half the reported results on six datasets. In only one case did it perform badly (the soybean dataset), and often it performed extremely well <ref> (Oates, Gregory and Cohen, 1995) </ref>. 5 Fluents vs. Multitokens With multitoken transition rules for the abstract Streams World environment, an agent can imagine possible future multitokens by chaining through its rules. But when we consider how real environments might be encoded in streams we run into a problem.
Reference: <author> Z. Zheng. </author> <title> A benchmark for classifier learning. </title> <institution> Technical Report from Basser Department of Computer Science, University of Sydney, NSW. </institution> <year> 1994. </year> <title> 9 Acknowledgments We thank two anonymous reviewers for their insightful and encouraging comments. The work on msdd was supported by arpa/rl Contract F30602-93-C-0100. </title>
References-found: 8

