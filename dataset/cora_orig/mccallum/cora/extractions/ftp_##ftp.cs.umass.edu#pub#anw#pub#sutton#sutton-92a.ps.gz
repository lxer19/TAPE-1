URL: ftp://ftp.cs.umass.edu/pub/anw/pub/sutton/sutton-92a.ps.gz
Refering-URL: http://www-anw.cs.umass.edu/~rich/publications.html
Root-URL: 
Email: sutton@gte.com  
Title: Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta  
Author: Richard S. Sutton 
Address: Waltham, MA 02254  
Affiliation: GTE Laboratories Incorporated  
Note: Appeared in Proceedings of the Tenth National Conf. on Artificial Intelligence, pp. 171-176, MIT Press, 1992.  
Abstract: Appropriate bias is widely viewed as the key to efficient learning and generalization. I present a new algorithm, the Incremental Delta-Bar-Delta (IDBD) algorithm, for the learning of appropriate biases based on previous learning experience. The IDBD algorithm is developed for the case of a simple, linear learning system|the LMS or delta rule with a separate learning-rate parameter for each input. The IDBD algorithm adjusts the learning-rate parameters, which are an important form of bias for this system. Because bias in this approach is adapted based on previous learning experience, the appropriate testbeds are drifting or non-stationary learning tasks. For particular tasks of this type, I show that the IDBD algorithm performs better than ordinary LMS and in fact finds the optimal learning rates. The IDBD algorithm extends and improves over prior work by Jacobs and by me in that it is fully incremental and has only a single free parameter. This paper also extends previous work by presenting a derivation of the IDBD algorithm as gradient descent in the space of learning-rate parameters. Finally, I offer a novel interpretation of the IDBD algorithm as an incremental form of hold-one-out cross validation. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Barto, A.G. & Sutton, </author> <title> R.S. (1981) Adaptation of learning rate parameters, Appendix C of Goal Seeking Components for Adaptive Intelligence: An Initial Assessment. </title> <institution> Air Force Wright Aeronautical Laboratories/Avionics Laboratory Technical Report AFWAL-TR-81-1070, Wright-Patterson AFB, Ohio. </institution>
Reference: <author> Gluck, M.A. & Glauthier P.T. </author> <title> (in preparation) Representation of dimensional stimulus structure in network theories of associative learning. </title>
Reference: <author> Gluck, M.A., Glauthier, P.T., & Sutton, </author> <title> R.S. (in preparation) Dynamically modifiable stimulus associability in network models of category learning. </title>
Reference: <author> Hampson, S.E. & Volper, </author> <title> D.J. (1986) Linear function neurons: Structure and training. </title> <booktitle> Biological Cybernetics 53, </booktitle> <pages> 203-217. </pages>
Reference-contexts: In the IDBD algorithm there is a different learning rate, ff i , for each input x i , and these change according to a meta-learning process <ref> (cf. Hampson & Volper 1986) </ref>. The base-level learning rule is 1 w i (t + 1) = w i (t) + ff i (t + 1)ffi (t)x i (t): (3) The learning rates are a powerful form of bias in this system.
Reference: <author> Hurwitz, J.B. </author> <title> (1990) A hidden-pattern unit network model of category learning. </title> <type> PhD thesis, </type> <institution> Harvard Psychology Dept. </institution>
Reference: <author> Jacobs, R.A. </author> <title> (1988) Increased rates of convergence through learning rate adaptation. </title> <booktitle> Neural Networks 1, </booktitle> <pages> 295-307. </pages>
Reference: <author> Kesten, H. </author> <title> (1958) Accelerated stochastic approximation. </title> <journal> Annals of Mathematical Statistics 29, </journal> <pages> 41-59. </pages>
Reference: <author> Kruschke, J.K. </author> <year> (1992) </year> <month> ALCOVE: </month> <title> An exemplar-based connectionist model of category learning. </title> <journal> Psychological Review. </journal>
Reference: <author> Lee, Y. & Lippmann, </author> <title> R.P. (1990) Practical characteristics of neural network and conventional pattern classifiers on artificial and speech problems. </title> <booktitle> In Advances in Neural Information Processing Systems 2, </booktitle> <editor> D.S. Touretzky, Ed., </editor> <month> 168-177. </month>
Reference: <author> Rendell, L.A., Seshu, R.M., and Tcheng, D.K. </author> <title> (1987) Layered concept learning and dynamically-variable bias management, </title> <booktitle> Proc. Tenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 308-314. </pages>
Reference-contexts: This has resulted in an accumulation of specialized and non-extensible techniques. Is there an alternative? If bias is what a learner brings to a learning problem, then how could the learner itself generate an appropriate bias? The only way is to generate the bias from previous learning experience <ref> (e.g., Rendell, Seshu, & Tcheng 1987) </ref>. And this is possible only if the learner encounters a series of different problems requiring the same or similar biases. I believe that is a correct characterization of the learning task facing people and real-world learning machines.
Reference: <author> Schlimmer, </author> <title> J.C. (1987) Concept acquisition through representation adjustment. </title> <type> PhD thesis, </type> <institution> University of Califor-nia, Information and Computer Science Dept., </institution> <type> Technical Report 87-19. </type>
Reference-contexts: However, these boundings were not required to obtain the empirical results pre sented in the next section. Results The capabilities of the IDBD algorithm were assessed using a series of tracking tasks|supervised-learning or concept-learning tasks in which the target concept drifts over time and has to be tracked <ref> (cf. Schlimmer 1987) </ref>. Non-stationary tasks are more appropriate here than conventional learning tasks because we are trying to assess the IDBD algorithm's ability to learn biases during early learning and then use them in later learning.
Reference: <author> Silva, </author> <title> F.M. & Almeida, L.B. (1990) Acceleration techniques for the backpropagation algorithm. </title> <booktitle> In Neural Networks: EURASIP Workshop 1990, </booktitle> <editor> L.B. Almeida and C.J. Wellekens, Eds., </editor> <address> 110-119. Berlin: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Sutton, </author> <title> R.S. (1982) A theory of salience change dependent on the relationship between discrepancies on successive trials on which the stimulus is present. </title> <note> Unpublished working paper. </note>
Reference: <author> Sutton, </author> <title> R.S. (1986) Two problems with backpropagation and other steepest-descent learning procedures for networks. </title> <booktitle> Proceedings of the Eighth Annual Conference of the Cognitive Science Society, </booktitle> <pages> 823-831. </pages>
Reference: <author> Widrow, B. & Stearns, </author> <title> S.D. Adaptive Signal Processing. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1985. </year>
Reference-contexts: The IDBD Algorithm The IDBD algorithm is a meta-learning algorithm in the sense that it learns the learning-rate parameters of an underlying base learning system. The base learning system is the Least-Mean-Square (LMS) rule, also known as the delta rule, the ADALINE, the Rescorla-Wagner rule, and the Widrow-Hoff rule <ref> (see, e.g., Widrow & Stearns 1985) </ref>. This learning system is often thought of as a single connectionist unit as shown in figure 1.
Reference: <author> Williams, R.J. & Zipser, D. </author> <title> (1989) Experimental analysis of the real-time recurrent learning algorithm. </title> <booktitle> Connection Science 1, </booktitle> <pages> 87-111. </pages>
Reference-contexts: In this equation, the partial derivitive with respect to fi i without a time index should be interpretted as the derivative with repect to an infintesimal change in fi i at all time steps. A similar technique is used in gradient-descent analyses of recurrent connectionist networks <ref> (c.f., e.g., Williams & Zipser 1989) </ref>.
References-found: 16

