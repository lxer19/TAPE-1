URL: http://www.ai.mit.edu/~mpf/desktop/research/QC/other_papers/Hogg.ps
Refering-URL: 
Root-URL: 
Email: hogg@parc.xerox.com  
Title: Quantum Computing and Phase Transitions in Combinatorial Search  
Author: Tad Hogg 
Address: 3333 Coyote Hill Road Palo Alto, CA 94304  
Affiliation: Dynamics of Computation Group Xerox Palo Alto Research Center  
Date: 16 Aug 1995  
Note: quant-ph/9508012  August 16, 1995  
Abstract: We introduce an algorithm for combinatorial search on quantum computers that is capable of significantly concentrating amplitude into solutions for some NP search problems, on average. This is done by exploiting the same aspects of problem structure as used by classical backtrack methods to avoid unproductive search choices. This quantum algorithm is much more likely to find solutions than the simple direct use of quantum parallelism. Furthermore, empirical evaluation on small problems shows this quantum algorithm displays the same phase transition behavior, and at the same location, as seen in many previously studied classical search methods. Specifically, difficult problem instances are concentrated near the abrupt change from underconstrained to overconstrained problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Andrew B. Baker. </author> <title> Intelligent backtracking on the hardest constraint problems. </title> <journal> J. of Artificial Intelligence Research, </journal> <note> 1995. to appear. </note>
Reference-contexts: Hence this provides another example of a distinct class of algorithms, as with more sophisticated backtracking <ref> [1] </ref>, that appears to avoid hard problems in the underconstrained region. 20 Fig. 5. Expected number of trials to find a solution vs. fi for random problems with prespecified solution with binary constraints, using inverted phases for nogoods.
Reference: [2] <author> Adriano Barenco, David Deutsch, and Artur Ekert. </author> <title> Conditional quantum dynamics and logic gates. </title> <journal> Physical Review Letters, </journal> <volume> 74 </volume> <pages> 4083-4086, </pages> <year> 1995. </year>
Reference-contexts: The scaling behavior of the algorithm for larger cases is also of interest, which can perhaps be approached by examining the asymptotic nature of the matrix coefficients of Eqs. 10 and 12. An important practical question is the physical implementation of quantum computers in general <ref> [2, 43, 9] </ref>, and the requirements imposed by the algorithm described here. Any implementation of a quantum computer will need to deal with two important difficulties [32]. First, there will be defects in the construction of the device.
Reference: [3] <author> P. Benioff. </author> <title> Quantum mechanical hamiltonian models of turing machines. </title> <journal> J. Stat. Phys., </journal> <volume> 29 </volume> <pages> 515-546, </pages> <year> 1982. </year>
Reference: [4] <author> Charles H. Bennett, Ethan Bernstein, Gilles Brassard, and Umesh V. Vazirani. </author> <title> Strengths and weaknesses of quantum computing. </title> <type> preprint, </type> <month> December 1 </month> <year> 1994. </year> <month> 27 </month>
Reference: [5] <author> Ethan Bernstein and Umesh Vazirani. </author> <title> Quantum complexity theory. </title> <booktitle> In Proc. 25th ACM Symp. on Theory of Computation, </booktitle> <pages> pages 11-20, </pages> <year> 1993. </year>
Reference: [6] <author> Vladimir Cerny. </author> <title> Quantum computers and intractable (NP-complete) computing problems. </title> <journal> Physical Review A, </journal> <volume> 48 </volume> <pages> 116-119, </pages> <year> 1993. </year>
Reference-contexts: This shows a trade-off between time and energy (or other physical resources), conjectured to apply more generally to solving these search problems <ref> [6] </ref>, and also seen in the trade-off of time and number of processors in parallel computers.
Reference: [7] <author> Peter Cheeseman, Bob Kanefsky, and William M. Taylor. </author> <title> Where the really hard problems are. </title> <editor> In J. Mylopoulos and R. Reiter, editors, </editor> <booktitle> Proceedings of IJCAI91, </booktitle> <pages> pages 331-337, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Recently there have been a number of studies of the structure of the class of NP search problems focusing on regularities of the typical behavior <ref> [7, 36, 48, 25, 2 23] </ref>. This work has identified a number of common behaviors. Specifically, for large problems, a few parameters characterizing their structure determine the relative difficulty for a wide variety of common search methods, on average. <p> This always produces problems with at least one solution. Although these problems tend to be a bit easier than randomly selected soluble problems, they nevertheless exhibit the same concentration of hard problems and at about the same location as general random problems <ref> [7, 48] </ref>. For our class of problems, this behavior is illustrated in Fig. 3. Specifically, this shows the cost to solve the problem with a simple chronological backtrack search. The cost is given in terms of the number of decision points considered until a solution is found. <p> However the observation that this behavior persists for many classes of problems with other search methods suggests it will be widely applicable. It is also of interest to see if other phase transition phenomena appear in these quantum search algorithms, such as observed in optimization searches <ref> [7, 38, 50] </ref>. There may also be transitions unique to quantum algorithms, for example in the required coherence time or sensitivity to environmental noise. For the specific instances of the algorithm presented here, there are also some remaining issues.
Reference: [8] <author> I. L. Chuang, R. Laflamme, P. Shor, and W. H. Zurek. </author> <title> Quantum computers, factoring and decoherence. </title> <type> preprint, </type> <month> March 23 </month> <year> 1995. </year>
Reference-contexts: The second major difficulty with constructing quantum computers is maintaining coherence of the superposition of states long enough to complete the computation. Environmental noise gradually couples to the state of the device, reducing the coherence and eventually limiting the time over which a coherent superposition can perform useful computations <ref> [47, 8] </ref>. In effect, the coupling to the environment can be viewed as performing a measurement on the quantum system, destroying the superposition of states. This problem is particularly severe for proposed universal quantum computers that need to maintain superpositions for arbitrarily long times.
Reference: [9] <author> J. I. Cirac and P. Zoller. </author> <title> Quantum computations with cold trapped ions. </title> <journal> Physical Review Letters, </journal> <volume> 74 </volume> <pages> 4091-4094, </pages> <year> 1995. </year>
Reference-contexts: The scaling behavior of the algorithm for larger cases is also of interest, which can perhaps be approached by examining the asymptotic nature of the matrix coefficients of Eqs. 10 and 12. An important practical question is the physical implementation of quantum computers in general <ref> [2, 43, 9] </ref>, and the requirements imposed by the algorithm described here. Any implementation of a quantum computer will need to deal with two important difficulties [32]. First, there will be defects in the construction of the device.
Reference: [10] <author> James M. Crawford and Larry D. Auton. </author> <title> Experimental results on the cross-over point in satisfiability problems. </title> <booktitle> In Proc. of the 11th Natl. Conf. on Artificial Intelligence (AAAI93), </booktitle> <pages> pages 21-27, </pages> <address> Menlo Park, CA, 1993. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Furthermore, the additional structure of the necessary nogoods and the larger size of the constraints, compared with the previous set of problems, makes it more likely that larger problems will be required to see the asymptotic scaling behavior. However, at least some asymptotic behaviors have been observed <ref> [10] </ref> to persist quite accurately even for problems as small as n = 3, so some indication of the scaling behavior is not out of the question for the small problems considered here.
Reference: [11] <author> D. Deutsch. </author> <title> Quantum theory, the Church-Turing principle and the universal quantum computer. </title> <journal> Proc. R. Soc. London A, </journal> <volume> 400 </volume> <pages> 97-117, </pages> <year> 1985. </year>
Reference-contexts: An example is the development of parallel computers with their trade-off of overall computation time against the number of processors employed. Effective use of this trade-off can require algorithms that would be very inefficient if implemented serially. Another example is given by hypothetical quantum computers <ref> [11] </ref>. They offer the potential of exploiting quantum parallelism to trade computation time against the use of coherent interference among very many different computational paths. <p> Quantum Search Methods This section briefly describes the capabilities of ideal quantum computers, why some straightforward attempts to exploit these capabilities for search are not particularly effective, then motivates and describes a new search algorithm 3.1. An Overview of Quantum Computers The basic distinguishing feature of a quantum computer <ref> [3-5, 11, 12, 16, 17, 27, 29, 33, 42, 46] </ref> is its ability to operate simultaneously on a collection of classical states, thus potentially performing very many operations in the time a classical computer would do just one.
Reference: [12] <author> D. Deutsch. </author> <title> Quantum computational networks. </title> <journal> Proc. R. Soc. Lond., </journal> <volume> A425:73-90, </volume> <year> 1989. </year>
Reference-contexts: Quantum Search Methods This section briefly describes the capabilities of ideal quantum computers, why some straightforward attempts to exploit these capabilities for search are not particularly effective, then motivates and describes a new search algorithm 3.1. An Overview of Quantum Computers The basic distinguishing feature of a quantum computer <ref> [3-5, 11, 12, 16, 17, 27, 29, 33, 42, 46] </ref> is its ability to operate simultaneously on a collection of classical states, thus potentially performing very many operations in the time a classical computer would do just one.
Reference: [13] <author> P. A. M. </author> <title> Dirac. </title> <booktitle> The Principles of Quantum Mechanics. Oxford, 4th edition, </booktitle> <year> 1958. </year>
Reference-contexts: The corresponding state of the quantum computer is described by a linear superposition of these classical states jsi, each with an associated complex number called its amplitude, i.e., jsi = P Here we use the standard ket notation from quantum mechanics <ref> [13, section 6] </ref> to denote various states, and to distinguish these states from the amplitudes 2 .
Reference: [14] <author> K. Eric Drexler. Nanosystems: </author> <title> Molecular Machinery, Manufacturing, and Computation. </title> <publisher> John Wiley, </publisher> <address> NY, </address> <year> 1992. </year>
Reference-contexts: We also need to address the extent to which such errors can be minimized in the first place, thus placing less severe requirements on the algorithm. Particularly relevant in this respect is the possibility of drastically reducing defects in manufactured devices by atomically precise control of the hardware <ref> [14, 15, 37] </ref>. This could substantially extend the range of ideal quantum algorithms that will be possible to implement. The second major difficulty with constructing quantum computers is maintaining coherence of the superposition of states long enough to complete the computation.
Reference: [15] <author> D. M. Eigler and E. K. Schweizer. </author> <title> Positioning single atoms with a scanning tunnelling microscope. </title> <journal> Nature, </journal> <volume> 344 </volume> <pages> 524-526, </pages> <year> 1990. </year>
Reference-contexts: We also need to address the extent to which such errors can be minimized in the first place, thus placing less severe requirements on the algorithm. Particularly relevant in this respect is the possibility of drastically reducing defects in manufactured devices by atomically precise control of the hardware <ref> [14, 15, 37] </ref>. This could substantially extend the range of ideal quantum algorithms that will be possible to implement. The second major difficulty with constructing quantum computers is maintaining coherence of the superposition of states long enough to complete the computation.
Reference: [16] <author> Artur Ekert and Richard Jozsa. </author> <title> Shor's quantum algorithm for factorising numbers. </title> <journal> Rev. Mod. Phys., </journal> <note> 1995. to appear. </note>
Reference-contexts: Quantum Search Methods This section briefly describes the capabilities of ideal quantum computers, why some straightforward attempts to exploit these capabilities for search are not particularly effective, then motivates and describes a new search algorithm 3.1. An Overview of Quantum Computers The basic distinguishing feature of a quantum computer <ref> [3-5, 11, 12, 16, 17, 27, 29, 33, 42, 46] </ref> is its ability to operate simultaneously on a collection of classical states, thus potentially performing very many operations in the time a classical computer would do just one.
Reference: [17] <author> R. P. </author> <title> Feynman. Quantum mechanical computers. </title> <journal> Foundations of Physics, </journal> <volume> 16 </volume> <pages> 507-531, </pages> <year> 1986. </year>
Reference-contexts: Quantum Search Methods This section briefly describes the capabilities of ideal quantum computers, why some straightforward attempts to exploit these capabilities for search are not particularly effective, then motivates and describes a new search algorithm 3.1. An Overview of Quantum Computers The basic distinguishing feature of a quantum computer <ref> [3-5, 11, 12, 16, 17, 27, 29, 33, 42, 46] </ref> is its ability to operate simultaneously on a collection of classical states, thus potentially performing very many operations in the time a classical computer would do just one.
Reference: [18] <author> Richard P. </author> <title> Feynman. QED: The Strange Theory of Light and Matter. </title> <publisher> Princeton Univ. Press, </publisher> <address> NJ, </address> <year> 1985. </year>
Reference-contexts: This means the search method is incomplete: it can find a solution if one exists but can never guarantee a solution doesn't exist. A useful conceptual view of these quantum maps is provided by the path integral approach to quantum mechanics <ref> [18] </ref>. In this view, the final amplitude of a given state is obtained by summing over all possible paths that produce that state, weighted by suitable amplitudes. In this way, the various possibilities involved in a computation can interfere with each other, either constructively or destructively.
Reference: [19] <author> Eugene C. Freuder and Richard J. Wallace. </author> <title> Partial constraint satisfaction. </title> <journal> Artificial Intelligence, </journal> <volume> 58 </volume> <pages> 21-70, </pages> <year> 1992. </year>
Reference-contexts: Another possibility is for the phase to be adjusted based on how many constraints are violated, which could be particularly appropriate for partial constraint satisfaction problems <ref> [19] </ref> or other optimization searches. Summary The search algorithm starts by evenly dividing amplitude among the goods at level 2 of the lattice (whose number is proportional to N 2 ).
Reference: [20] <author> M. R. Garey and D. S. Johnson. </author> <title> A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference-contexts: Finally, some important caveats for the implementation of quantum computers and open issues are presented. 2. Combinatorial Search Combinatorial search is among the hardest of common computational problems: the solution time can grow exponentially with the size of the problem <ref> [20] </ref>. Examples arise in scheduling, planning, circuit layout and machine vision, to name a few areas. Many of these examples can be viewed as constraint satisfaction problems [34]. Here we are given a set of n variables each of which can be assigned b possible values. <p> Another example is propositional satisfiability, where the variables take on logical values of true or false, and the assignment must satisfy a specified propositional formula involving the variables. Both these examples are instances of particularly difficult NP problems known as the class of NP-complete search problems <ref> [20] </ref>. 2.1. Phase Transitions Much of the theoretical work on NP search problems examines their worst case behavior. Although these search problems can be very hard, in the worst case, there is a great deal of individual variation in these problems and among different search methods.
Reference: [21] <author> Ian P. Gent and Toby Walsh. </author> <title> Easy problems are sometimes hard. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 335-345, </pages> <year> 1994. </year>
Reference-contexts: Another common feature of phase transitions is an increased variance around the transition region. For this method we see a peak in the variance as well, shown in Fig. 6. Furthermore, there is no indication of the rare hard cases in the easy region of underconstrained problems <ref> [21, 26, 44] </ref>.
Reference: [22] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> John Hopkins University Press, </publisher> <address> Baltimore, MD, </address> <year> 1983. </year>
Reference-contexts: Restricting attention to the subspace defined by the original vectors, this can be obtained 4 using the singular value decomposition <ref> [22] </ref> (SVD) of the matrix M whose columns are the k given vectors. Specifically, this decomposition is M = A y flB, where fl is a diagonal matrix containing the singular values of M and both A y and B have orthonormal columns. <p> Then the matrix U = A y B has orthonormal columns and is the closest set of orthogonal vectors according to the Frobenius matrix norm. For example, 4 I thank J. Gilbert for pointing out this technique, as a variant of the orthogonal Procrustes problem <ref> [22] </ref>. 12 the mapping from level 1 to 2 with N = 3 given in Eq. 8 produces U = 3 @ 2 1 2 1 We should note that this construction fails if k &gt; m since an m-dimensional space cannot have more than m orthogonal vectors.
Reference: [23] <author> Tad Hogg. </author> <title> Phase transitions in constraint satisfaction search. A World Wide Web page with URL ftp://parcftp.xerox.com/pub/dynamics/constraints.html, </title> <year> 1994. </year>
Reference: [24] <author> Tad Hogg. </author> <title> Refining the phase transitions in combinatorial search. </title> <journal> Artificial Intelligence, </journal> <note> 1995. to appear. </note>
Reference-contexts: For instance, to what extent 25 does this behavior apply to more realistic classes of problems? For instance including the structure due to prohibiting multiple assignments in constraint satisfaction problems [39, 45] or clustering inherent in situations involving localized interactions <ref> [24] </ref>. This will be difficult to check empirically due to the limitation to small problems that are feasible for a classical simulation of this algorithm. However the observation that this behavior persists for many classes of problems with other search methods suggests it will be widely applicable.
Reference: [25] <author> Tad Hogg, Bernardo A. Huberman, and Colin Williams. </author> <title> Phase transitions and the search problem. </title> <journal> Artificial Intelligence, </journal> <note> 1995. to appear. </note>
Reference-contexts: In fact, recent studies have revealed a more detailed structure of the class of search problems. Specifically, for a wide variety of classical search methods, the hard instances are not only rare but also concentrated near abrupt transitions in problem behavior analogous to physical phase transitions <ref> [25] </ref>. In order to exhibit this concentration of hard instances a search algorithm must exploit the problem constraints to prune unproductive search choices. Unfortunately, this is not easy to do within the range of allowable quantum computational operations. <p> Recently there have been a number of studies of the structure of the class of NP search problems focusing on regularities of the typical behavior <ref> [7, 36, 48, 25, 2 23] </ref>. This work has identified a number of common behaviors. Specifically, for large problems, a few parameters characterizing their structure determine the relative difficulty for a wide variety of common search methods, on average.
Reference: [26] <author> Tad Hogg and Colin P. Williams. </author> <title> The hardest constraint problems: A double phase transition. </title> <journal> Artificial Intelligence, </journal> <volume> 69 </volume> <pages> 359-377, </pages> <year> 1994. </year>
Reference-contexts: In between these two cases are the hard problems: enough constraints so good choices are rare but few enough that bad choices are usually recognized only with a lot of additional search. A more detailed analysis suggests a series of transitions <ref> [26] </ref>. With very few constraints, the average search cost scales polynomially. As more constraints are added, there is a transition to exponential scaling. The rate of growth of this exponential increases until the transition region described above is reached. <p> Furthermore, the theory predicts there is a regime of polynomial average cost for sufficiently few constraints <ref> [26] </ref>. This is determined by the condition that the expected number of goods at each level in the lattice is monotonically increasing. <p> Another common feature of phase transitions is an increased variance around the transition region. For this method we see a peak in the variance as well, shown in Fig. 6. Furthermore, there is no indication of the rare hard cases in the easy region of underconstrained problems <ref> [21, 26, 44] </ref>.
Reference: [27] <author> Richard Jozsa. </author> <title> Computation and quantum superposition. </title> <booktitle> In Proc. of the Physics of Computation Workshop. IEEE Computer Society, </booktitle> <month> October 2-4 </month> <year> 1992. </year>
Reference-contexts: Quantum Search Methods This section briefly describes the capabilities of ideal quantum computers, why some straightforward attempts to exploit these capabilities for search are not particularly effective, then motivates and describes a new search algorithm 3.1. An Overview of Quantum Computers The basic distinguishing feature of a quantum computer <ref> [3-5, 11, 12, 16, 17, 27, 29, 33, 42, 46] </ref> is its ability to operate simultaneously on a collection of classical states, thus potentially performing very many operations in the time a classical computer would do just one.
Reference: [28] <author> Samuel Karlin and Howard M. Taylor. </author> <title> A First Course in Stochastic Processes. </title> <publisher> Academic Press, </publisher> <address> NY, 2nd edition, </address> <year> 1975. </year>
Reference-contexts: Ignoring the variation in the magnitude of the amplitudes at each level this gives r i = r i1 i X e i m = r i1 i (6) because the sum of i random phases is equivalent to an unbiased random walk <ref> [28] </ref> with i unit steps which has expected net distance of p i. Thus we get r i = r k p r i = i!k! for i &gt; k. This crude argument gives a rough estimate of the relative probabilities for solutions compared to complete nogoods.
Reference: [29] <author> Don Kimber. </author> <title> An introduction to quantum computation. </title> <type> Technical report, </type> <note> Xerox PARC, </note> <month> February </month> <year> 1992. </year>
Reference-contexts: Quantum Search Methods This section briefly describes the capabilities of ideal quantum computers, why some straightforward attempts to exploit these capabilities for search are not particularly effective, then motivates and describes a new search algorithm 3.1. An Overview of Quantum Computers The basic distinguishing feature of a quantum computer <ref> [3-5, 11, 12, 16, 17, 27, 29, 33, 42, 46] </ref> is its ability to operate simultaneously on a collection of classical states, thus potentially performing very many operations in the time a classical computer would do just one.
Reference: [30] <author> S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. </author> <title> Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> 220 </volume> <pages> 671-680, </pages> <year> 1983. </year>
Reference-contexts: Various search methods correspond to different strategies for examining the sets in this lattice. For instance, methods such as simulated annealing <ref> [30] </ref>, heuristic repair [35] and GSAT [41] move among complete sets, attempting to find a solution by a series of small changes to the sets. Generally these search techniques continue indefinitely if the problem has no solution and thus they can never show that a problem is insoluble.
Reference: [31] <author> Rolf Landauer. </author> <title> Information is physical. </title> <journal> Physics Today, </journal> <volume> 44(5) </volume> <pages> 23-29, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: 1. Introduction Computation is ultimately a physical process <ref> [31] </ref>. That is, in practice the range of physically realizable devices determines what is computable and the resources, such as computer time, required to solve a given problem. Computing machines can exploit a variety of physical processes and structures to provide distinct trade-offs in resource requirements.
Reference: [32] <author> Rolf Landauer. </author> <title> Is quantum mechanically coherent computation useful? In D. </title> <editor> H. Feng and B-L. Hu, editors, </editor> <booktitle> Proc. of the Drexel-4 Symposium on Quantum Nonintegrability. </booktitle> <publisher> International Press, </publisher> <year> 1994. </year>
Reference-contexts: An important practical question is the physical implementation of quantum computers in general [2, 43, 9], and the requirements imposed by the algorithm described here. Any implementation of a quantum computer will need to deal with two important difficulties <ref> [32] </ref>. First, there will be defects in the construction of the device. Thus even if an ideal design exactly produces the desired mapping, occasional manufacturing defects and environmental noise will introduce errors. We thus need to understand the sensitivity of the algorithm's behavior to errors in the mappings.
Reference: [33] <author> Seth Lloyd. </author> <title> A potentially realizable quantum computer. </title> <journal> Science, </journal> <volume> 261 </volume> <pages> 1569-1571, </pages> <month> September 17 </month> <year> 1993. </year>
Reference-contexts: Quantum Search Methods This section briefly describes the capabilities of ideal quantum computers, why some straightforward attempts to exploit these capabilities for search are not particularly effective, then motivates and describes a new search algorithm 3.1. An Overview of Quantum Computers The basic distinguishing feature of a quantum computer <ref> [3-5, 11, 12, 16, 17, 27, 29, 33, 42, 46] </ref> is its ability to operate simultaneously on a collection of classical states, thus potentially performing very many operations in the time a classical computer would do just one.
Reference: [34] <author> A. K. Mackworth. </author> <title> Constraint satisfaction. </title> <editor> In S. Shapiro and D. Eckroth, editors, </editor> <booktitle> Encyclopedia of A.I., </booktitle> <pages> pages 205-211. </pages> <publisher> John Wiley and Sons, </publisher> <year> 1987. </year>
Reference-contexts: Examples arise in scheduling, planning, circuit layout and machine vision, to name a few areas. Many of these examples can be viewed as constraint satisfaction problems <ref> [34] </ref>. Here we are given a set of n variables each of which can be assigned b possible values. The problem is to find an assignment for each variable that together satisfy some specified constraints.
Reference: [35] <author> Steven Minton, Mark D. Johnston, Andrew B. Philips, and Philip Laird. </author> <title> Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems. </title> <journal> Artificial Intelligence, </journal> <volume> 58 </volume> <pages> 161-205, </pages> <year> 1992. </year>
Reference-contexts: Various search methods correspond to different strategies for examining the sets in this lattice. For instance, methods such as simulated annealing [30], heuristic repair <ref> [35] </ref> and GSAT [41] move among complete sets, attempting to find a solution by a series of small changes to the sets. Generally these search techniques continue indefinitely if the problem has no solution and thus they can never show that a problem is insoluble. Such methods are called incomplete.
Reference: [36] <author> David Mitchell, Bart Selman, and Hector Levesque. </author> <title> Hard and easy distributions of SAT problems. </title> <booktitle> In Proc. of the 10th Natl. Conf. on Artificial Intelligence (AAAI92), </booktitle> <pages> pages 459-465, </pages> <address> Menlo Park, 1992. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Recently there have been a number of studies of the structure of the class of NP search problems focusing on regularities of the typical behavior <ref> [7, 36, 48, 25, 2 23] </ref>. This work has identified a number of common behaviors. Specifically, for large problems, a few parameters characterizing their structure determine the relative difficulty for a wide variety of common search methods, on average. <p> We generate random problems with a given number of clauses by selecting that number of different nogoods of size 3 from among those not already excluded by the necessary nogoods 10 . For random 3SAT, the hard problems are concentrated near the transition <ref> [36] </ref> at c = 4:2n. We investigated a range of values for c=n: 2, 4, 6 and 8. Finally, from among these randomly generated problems, we use only those that do in fact have a solution 11 .
Reference: [37] <author> Wolfgang T. Muller, David L. Klein, Thomas Lee, John Clarke, Paul L. McEuen, and Peter G. Schultz. </author> <title> A strategy for the chemical synthesis of nanostructures. </title> <journal> Science, </journal> <volume> 268 </volume> <pages> 272-273, </pages> <year> 1995. </year>
Reference-contexts: We also need to address the extent to which such errors can be minimized in the first place, thus placing less severe requirements on the algorithm. Particularly relevant in this respect is the possibility of drastically reducing defects in manufactured devices by atomically precise control of the hardware <ref> [14, 15, 37] </ref>. This could substantially extend the range of ideal quantum algorithms that will be possible to implement. The second major difficulty with constructing quantum computers is maintaining coherence of the superposition of states long enough to complete the computation.
Reference: [38] <author> Joseph C. Pemberton and Weixiong Zhang. Epsilon-transformation: </author> <title> Exploiting phase transitions to solve combinatorial optimization problems. </title> <journal> Artificial Intelligence, </journal> <note> 1995. to appear. </note>
Reference-contexts: However the observation that this behavior persists for many classes of problems with other search methods suggests it will be widely applicable. It is also of interest to see if other phase transition phenomena appear in these quantum search algorithms, such as observed in optimization searches <ref> [7, 38, 50] </ref>. There may also be transitions unique to quantum algorithms, for example in the required coherence time or sensitivity to environmental noise. For the specific instances of the algorithm presented here, there are also some remaining issues.
Reference: [39] <author> Patrick Prosser. </author> <title> An empirical study of phase transitions in binary constraint satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <note> 1995. to appear. </note>
Reference-contexts: Here we select a particularly simple class of problems by supposing the constraints specify nogoods randomly at level 2 in the lattice. This corresponds to binary constraint satisfaction problems <ref> [39, 45] </ref>, but ignores the detailed structure of the nogoods imposed by the requirement that variables have a unique assignment. <p> For instance, to what extent 25 does this behavior apply to more realistic classes of problems? For instance including the structure due to prohibiting multiple assignments in constraint satisfaction problems <ref> [39, 45] </ref> or clustering inherent in situations involving localized interactions [24]. This will be difficult to check empirically due to the limitation to small problems that are feasible for a classical simulation of this algorithm.
Reference: [40] <author> Robert Schrag and James Crawford. </author> <title> Implicates and prime implicates in random 3-SAT. </title> <journal> Artificial Intelligence, </journal> <note> 1995. to appear. </note>
Reference-contexts: Finally, from among these randomly generated problems, we use only those that do in fact have a solution 11 . Using randomly selected soluble problems, rather than a prespecified solution results in somewhat harder problems. Like other studies that need to examine many goods and nogoods in the lattice <ref> [40] </ref>, these results are restricted to much smaller problems than in most studies of random SAT. Consequently, the transition region is rather spread out.
Reference: [41] <author> Bart Selman, Hector Levesque, and David Mitchell. </author> <title> A new method for solving hard satisfiability problems. </title> <booktitle> In Proc. of the 10th Natl. Conf. on Artificial Intelligence (AAAI92), </booktitle> <pages> pages 440-446, </pages> <address> Menlo Park, CA, 1992. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Various search methods correspond to different strategies for examining the sets in this lattice. For instance, methods such as simulated annealing [30], heuristic repair [35] and GSAT <ref> [41] </ref> move among complete sets, attempting to find a solution by a series of small changes to the sets. Generally these search techniques continue indefinitely if the problem has no solution and thus they can never show that a problem is insoluble. Such methods are called incomplete.
Reference: [42] <author> Peter W. Shor. </author> <title> Algorithms for quantum computation: Discrete logarithms and factoring. </title> <editor> In S. Goldwasser, editor, </editor> <booktitle> Proc. of the 35th Symposium on Foundations of Computer Science, </booktitle> <pages> pages 124-134. </pages> <publisher> IEEE Press, </publisher> <month> November </month> <year> 1994. </year>
Reference-contexts: However, restrictions on physically realizable operations make this trade-off difficult to exploit for search problems, resulting in algorithms essentially equivalent to the inefficient method of generate-and-test. Fortunately, recent work on factoring <ref> [42] </ref> shows that better algorithms are possible. Here we continue this line of work by introducing a new quantum algorithm, motivated by classical backtrack search methods, for a class of particularly difficult combinatorial search problems. <p> Quantum Search Methods This section briefly describes the capabilities of ideal quantum computers, why some straightforward attempts to exploit these capabilities for search are not particularly effective, then motivates and describes a new search algorithm 3.1. An Overview of Quantum Computers The basic distinguishing feature of a quantum computer <ref> [3-5, 11, 12, 16, 17, 27, 29, 33, 42, 46] </ref> is its ability to operate simultaneously on a collection of classical states, thus potentially performing very many operations in the time a classical computer would do just one. <p> One approach is to arrange for constructive interference in solutions while nonsolutions receive random contributions to their amplitude. While such random contributions are not as effective as a complete destructive interference, they are easier to construct and form the basis for a recent factoring algorithm <ref> [42] </ref> as well as the method presented here. One possible mapping is based on analogy with backtracking search methods. Instead of examining just one path through the lattice of sets at a time, a superposition of states allows for considering all paths simultaneously. <p> While it is by no means clear to what extent quantum coherence provides more powerful computational behavior than classical machines, a recent proposal for rapid factoring <ref> [42] </ref> is an encouraging indication of its capabilities. A more subtle question along these lines is how the average scaling behaves away from the transition region of hard problems.
Reference: [43] <author> Tycho Sleator and Harald Weinfurter. </author> <title> Realizable universal quantum logic gates. </title> <journal> Physical Review Letters, </journal> <volume> 74 </volume> <pages> 4087-4090, </pages> <year> 1995. </year>
Reference-contexts: The scaling behavior of the algorithm for larger cases is also of interest, which can perhaps be approached by examining the asymptotic nature of the matrix coefficients of Eqs. 10 and 12. An important practical question is the physical implementation of quantum computers in general <ref> [2, 43, 9] </ref>, and the requirements imposed by the algorithm described here. Any implementation of a quantum computer will need to deal with two important difficulties [32]. First, there will be defects in the construction of the device.
Reference: [44] <author> Barbara M. Smith. </author> <title> In search of exceptionally difficult constraint satisfaction problems. </title> <booktitle> In Proc. of ECAI94 Workshop on Constraint Processing, </booktitle> <pages> pages 79-86, </pages> <year> 1994. </year>
Reference-contexts: Another common feature of phase transitions is an increased variance around the transition region. For this method we see a peak in the variance as well, shown in Fig. 6. Furthermore, there is no indication of the rare hard cases in the easy region of underconstrained problems <ref> [21, 26, 44] </ref>.
Reference: [45] <author> Barbara M. Smith and Martin E. Dyer. </author> <title> Locating the phase transition in binary constraint satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <note> 1995. to appear. </note>
Reference-contexts: Here we select a particularly simple class of problems by supposing the constraints specify nogoods randomly at level 2 in the lattice. This corresponds to binary constraint satisfaction problems <ref> [39, 45] </ref>, but ignores the detailed structure of the nogoods imposed by the requirement that variables have a unique assignment. <p> Moreover, this peak is near the critically constrained region where random problems change from mostly soluble to mostly insoluble. A simple, but approximate, theoretical value for the location of the transition region is given by the point where the expected number of solutions is equal to one <ref> [45, 48] </ref>. Applying this to the class of problems considered here is straightforward. Specifically, there are N L complete sets for the problem, as given by Eq. 1. <p> This close correspondence with the theory (derived for the limit of large problems), suggests that we are observing the correct transition behavior even with these 8 This differs slightly from the results for problems with more specified structure on the nogoods, such as explicitly removing the necessary nogoods from consideration <ref> [45, 48] </ref>. 9 This is a particularly large error for this theory: it does better for problems with larger constraints or more allowed values per variable. 19 relatively small problems. Hence it is a reasonable basis for evaluating the behavior of the quantum search algorithm. <p> For instance, to what extent 25 does this behavior apply to more realistic classes of problems? For instance including the structure due to prohibiting multiple assignments in constraint satisfaction problems <ref> [39, 45] </ref> or clustering inherent in situations involving localized interactions [24]. This will be difficult to check empirically due to the limitation to small problems that are feasible for a classical simulation of this algorithm.
Reference: [46] <author> K. Svozil. </author> <title> Quantum computation and complexity theory. </title> <type> Technical report, </type> <institution> Univ. of Technology Vienna, </institution> <month> December 5 </month> <year> 1994. </year>
Reference-contexts: Quantum Search Methods This section briefly describes the capabilities of ideal quantum computers, why some straightforward attempts to exploit these capabilities for search are not particularly effective, then motivates and describes a new search algorithm 3.1. An Overview of Quantum Computers The basic distinguishing feature of a quantum computer <ref> [3-5, 11, 12, 16, 17, 27, 29, 33, 42, 46] </ref> is its ability to operate simultaneously on a collection of classical states, thus potentially performing very many operations in the time a classical computer would do just one.
Reference: [47] <author> W. G. Unruh. </author> <title> Maintaining coherence in quantum computers. </title> <type> preprint, </type> <year> 1994. </year>
Reference-contexts: The second major difficulty with constructing quantum computers is maintaining coherence of the superposition of states long enough to complete the computation. Environmental noise gradually couples to the state of the device, reducing the coherence and eventually limiting the time over which a coherent superposition can perform useful computations <ref> [47, 8] </ref>. In effect, the coupling to the environment can be viewed as performing a measurement on the quantum system, destroying the superposition of states. This problem is particularly severe for proposed universal quantum computers that need to maintain superpositions for arbitrarily long times.
Reference: [48] <author> Colin P. Williams and Tad Hogg. </author> <title> Exploiting the deep structure of constraint problems. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 73-117, </pages> <year> 1994. </year>
Reference-contexts: Recently there have been a number of studies of the structure of the class of NP search problems focusing on regularities of the typical behavior <ref> [7, 36, 48, 25, 2 23] </ref>. This work has identified a number of common behaviors. Specifically, for large problems, a few parameters characterizing their structure determine the relative difficulty for a wide variety of common search methods, on average. <p> Another representation that avoids this problem is to consider assignments in only a single arbitrary order. This version of the set lattice has been previously used in theoretical analyses of search <ref> [48] </ref>. This may be useful to explore further for the quantum search, but is unlikely to be as effective. <p> This always produces problems with at least one solution. Although these problems tend to be a bit easier than randomly selected soluble problems, they nevertheless exhibit the same concentration of hard problems and at about the same location as general random problems <ref> [7, 48] </ref>. For our class of problems, this behavior is illustrated in Fig. 3. Specifically, this shows the cost to solve the problem with a simple chronological backtrack search. The cost is given in terms of the number of decision points considered until a solution is found. <p> Moreover, this peak is near the critically constrained region where random problems change from mostly soluble to mostly insoluble. A simple, but approximate, theoretical value for the location of the transition region is given by the point where the expected number of solutions is equal to one <ref> [45, 48] </ref>. Applying this to the class of problems considered here is straightforward. Specifically, there are N L complete sets for the problem, as given by Eq. 1. <p> This close correspondence with the theory (derived for the limit of large problems), suggests that we are observing the correct transition behavior even with these 8 This differs slightly from the results for problems with more specified structure on the nogoods, such as explicitly removing the necessary nogoods from consideration <ref> [45, 48] </ref>. 9 This is a particularly large error for this theory: it does better for problems with larger constraints or more allowed values per variable. 19 relatively small problems. Hence it is a reasonable basis for evaluating the behavior of the quantum search algorithm. <p> We consider the well-studied NP-complete 3SAT problem where the formula is a conjunction of c clauses, each of which is a disjunction of 3 (possibly negated) variables. The SAT problem is readily represented in terms of nogoods in the lattice of sets <ref> [48] </ref>. As described in Sec. 2.2, there will be n necessary nogoods, each of size 2. In addition, each distinct clause in the proposition gives a single nogood of size 3. This case is thus of additional interest in having specified nogoods of two sizes. <p> The transition behavior is readily understood because problems near the transition point have many large partial goods that do not lead to solutions <ref> [48] </ref>. Thus there will be a relatively high proportion of paths through the lattice that appear good for quite a while but eventually give deadends.
Reference: [49] <author> Stephen Wolfram. </author> <title> Mathematica: A System for Doing Mathematics by Computer. </title> <publisher> Addison-Wesley, </publisher> <address> NY, 2nd edition, </address> <year> 1991. </year>
Reference-contexts: Despite the simple values for the example of Eq. 9, the a k values in general do not appear to have a simple closed form expression. This is suggested by obtaining exact solutions to Eqs. 10 and 12 using a symbolic algebra program <ref> [49] </ref>. In most cases this gives complicated expressions involving nested roots. Since it is always possible such expressions could simplify, the a k values were also checked for being close to rational numbers and whether they are roots of single variable polynomials of low degree 5 .
Reference: [50] <author> Weixiong Zhang and Richard E. Korf. </author> <title> A unified view of complexity transitions on the travelling salesman problem. </title> <journal> Artificial Intelligence, </journal> <note> 1995. to appear. 29 </note>
Reference-contexts: However the observation that this behavior persists for many classes of problems with other search methods suggests it will be widely applicable. It is also of interest to see if other phase transition phenomena appear in these quantum search algorithms, such as observed in optimization searches <ref> [7, 38, 50] </ref>. There may also be transitions unique to quantum algorithms, for example in the required coherence time or sensitivity to environmental noise. For the specific instances of the algorithm presented here, there are also some remaining issues.
References-found: 50

