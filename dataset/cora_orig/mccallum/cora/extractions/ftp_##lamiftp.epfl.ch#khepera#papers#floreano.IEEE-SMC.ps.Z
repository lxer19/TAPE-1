URL: ftp://lamiftp.epfl.ch/khepera/papers/floreano.IEEE-SMC.ps.Z
Refering-URL: http://iridia.ulb.ac.be/dorigo/SI/Special_Issue.html
Root-URL: 
Title: Evolution of Homing Navigation in a Real Mobile Robot  
Author: Dario Floreano, Francesco Mondada 
Keyword: Autonomous Robots, Genetic Algorithms, Neural Networks.  
Date: 1996 1  
Note: IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS, VOL. XX, NO. Y, MONTH  
Abstract: In this paper we describe the evolution of a discrete-time recurrent neural network to control a real mobile robot. In all our experiments the evolutionary procedure is carried out entirely on the physical robot without human intervention. We show that the autonomous development of a set of behaviors for locating a battery charger and periodically returning to it can be achieved by lifting constraints in the design of the robot/environment interactions that were employed in a preliminary experiment. The emergent homing behavior is based on the autonomous development of an internal neural topographic map (which is not pre-designed) that allows the robot to choose the appropriate trajectory as function of location and remaining energy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. J. McFarland, </author> <title> "Autonomy and self-sufficiency in robots", </title> <type> AI-Memo 92-03, </type> <institution> Artificial Intelligence Laboratory, Vrije Universiteit Brussel, Belgium, </institution> <year> 1992. </year>
Reference-contexts: As in the case of animals, this behavior relied on two important stages: the monitoring of the "physiological" variable (the level of the battery charge), and the calibration of the monitored message (i.e. the decision about when to initiate the sequence of actions needed for reaching the recharging area) <ref> [1] </ref>. The experiments showed that it is possible to perform behavior engineering [20] of intelligent agents without re 12 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS, VOL. XX, NO. Y, MONTH 1996 sorting to the abstract design of their cognitive abilities and artificially restricting its range of actions.
Reference: [2] <author> L. Steels, </author> <title> "Building agents out of autonomous behavior systems", in The "artificial life" route to "artificial intelligence". Building situated embodied agents, </title> <editor> L. Steels and R. Brooks, Eds. </editor> <publisher> Lawrence Erlbaum, </publisher> <address> New Haven, </address> <year> 1993. </year>
Reference-contexts: Additionally, the evolved agent can hardly be said to be autonomous because its behavior is dictated by the experimenter <ref> [2] </ref>.
Reference: [3] <author> R. A. Brooks, </author> <title> "Elephants don't play chess", </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> vol. 6, </volume> <pages> pp. 3-15, </pages> <year> 1990. </year>
Reference: [4] <author> R. A. Brooks, </author> <title> "Intelligence without representation", </title> <journal> Artificial Intelligence, </journal> <volume> vol. 47, </volume> <pages> pp. 139-59, </pages> <year> 1991. </year>
Reference: [5] <editor> P. Maes, </editor> <booktitle> "Behavior-based artificial intelligence", in From Animals to Animats II: Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> J. Meyer, H. L. Roitblat, and S. W. Wilson, Eds. </editor> <publisher> MIT Press-Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference: [6] <author> M. Dorigo and U. Schnepf, </author> <title> "Genetic-based machine learning and behavior based robotics: a new synthesis", </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> vol. 23, </volume> <pages> pp. 141-154, </pages> <year> 1993. </year>
Reference-contexts: Dorigo and Schnepf <ref> [6] </ref> have developed a parallel robot controller (ALECSYS) based on a classifier system evolved by means of a genetic algorithm that can coordinate several different behaviors of a simulated agent. The design and the evaluation of their system is strongly based on ethological considerations.
Reference: [7] <editor> I. Rechenberg, Evolutionstrategie: Optimierung technischer Sys-teme nach Prinzipien der biologischen Evolution, </editor> <publisher> Friedrich Fro-mann Verlag, Stuttgart, </publisher> <year> 1973. </year>
Reference: [8] <author> J. H. Holland, </author> <title> Adaptation in natural and artificial systems, </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, </address> <year> 1975. </year>
Reference: [9] <author> D. Parisi, F. Cecconi, and S. Nolfi, "Econets: </author> <title> Neural networks that learn in an environment", </title> <journal> Network, </journal> <volume> vol. 1, </volume> <pages> pp. 149-168, </pages> <year> 1990. </year>
Reference-contexts: On similar lines is the work by Parisi, Cecconi and Nolfi <ref> [9] </ref> who also stress the importance for an evolving organism to learn to predict the sensory consequences of its own actions in order to develop an internal world model.
Reference: [10] <author> J. R. Koza, </author> <title> Genetic programming: On the programming of computers by means of natural selection, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: Neural networks are not the only structure that have been used to evolve simulated autonomous agents. The evolution of programs (whose composition is similar to the symbolic expressions found in Lisp), also termed Genetic Programming by its inventor Koza <ref> [10] </ref>, has been successfully employed -among other examples- to recreate the patterns of locomotion of a lizard [59], to evolve coordinate group motion of visually guided agents [60] and to develop corridor-following behaviors [13].
Reference: [11] <author> R. D. Beer and J. C. Gallagher, </author> <title> "Evolving dynamical neural networks for adaptive behavior", </title> <booktitle> Adaptive Behavior, </booktitle> <volume> vol. 1, </volume> <pages> pp. 91-122, </pages> <year> 1992. </year>
Reference-contexts: In this case, the design of the fitness function even for a simple task requires some effort and empirical trials because it is not possible to identify and specify in advance the desired actions of an autonomous agent <ref> [11] </ref>, [15]. Additionally, the evolved agent can hardly be said to be autonomous because its behavior is dictated by the experimenter [2]. <p> On similar lines is the work by Parisi, Cecconi and Nolfi [9] who also stress the importance for an evolving organism to learn to predict the sensory consequences of its own actions in order to develop an internal world model. Beer and Gallagher <ref> [11] </ref> use a genetic algorithm to develop a set of chemotactic behaviors for a simulated agent with a circular and symmetric structure (geometrically similar to the robot employed in our experiments) and to control locomotion of a six-legged agent.
Reference: [12] <author> D. Cliff, I. Harvey, and P. Husbands, </author> <booktitle> "Explorations in evolutionary robotics", Adaptive Behavior, </booktitle> <volume> vol. 2, </volume> <pages> pp. 73-110, </pages> <year> 1993. </year>
Reference-contexts: Several explorations in this direction have been described by Cliff, Husbands, and Harvey in a number of papers. Their major claim is that artificial evolution represents an alternative and more fruitful approach (contrasted to design by hand) to developing the control systems of autonomous mobile robots <ref> [12] </ref>. In their view the evolutionary method should be incremental [53] and operate on recurrent real-time neu FLOREANO AND MONDADA: EVOLUTION OF HOMING NAVIGATION IN A REAL MOBILE ROBOT 11 ral networks [54].
Reference: [13] <author> C. W. Reynolds, </author> <title> "Evolution of corridor following behavior in a noisy world", </title> <booktitle> in From Animals to Animats III: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> D. Cliff, P. Husbands, J. Meyer, and S. W. Wilson, Eds. </editor> <publisher> MIT Press-Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: is similar to the symbolic expressions found in Lisp), also termed Genetic Programming by its inventor Koza [10], has been successfully employed -among other examples- to recreate the patterns of locomotion of a lizard [59], to evolve coordinate group motion of visually guided agents [60] and to develop corridor-following behaviors <ref> [13] </ref>. Dorigo and Schnepf [6] have developed a parallel robot controller (ALECSYS) based on a classifier system evolved by means of a genetic algorithm that can coordinate several different behaviors of a simulated agent. The design and the evaluation of their system is strongly based on ethological considerations.
Reference: [14] <author> D. T. Cliff and S. G. Bullock, </author> <title> "Adding "foveal vision" to Wil-son's animat", </title> <booktitle> Adaptive Behavior, </booktitle> <volume> vol. 2, </volume> <pages> pp. 49-72, </pages> <year> 1993. </year>
Reference-contexts: Those individuals that moved in the other direction were very likely to get stuck in a convex corner without being able to detect it (because of the poor information provided by the two sensors) and, hence, soon disappeared from the population (see <ref> [14] </ref> for a similar example of evolutionary adaptation of the control system to the visual configuration of a simulated agent). <p> Developing on these lines, they present results of several evolved behaviors for a simulated robot with a very simple visual system [55], [56], [57], <ref> [14] </ref>. Flore-ano [35] has studied the evolution of a simulated agent who developed the ability to reach a nest where it could eat the food found in the external environment.
Reference: [15] <editor> L. Steels, </editor> <booktitle> "The Artificial Life Roots of Artificial Intelligence", Artificial Life, </booktitle> <volume> vol. 1, </volume> <pages> pp. 75-110, </pages> <year> 1994. </year>
Reference-contexts: In this case, the design of the fitness function even for a simple task requires some effort and empirical trials because it is not possible to identify and specify in advance the desired actions of an autonomous agent [11], <ref> [15] </ref>. Additionally, the evolved agent can hardly be said to be autonomous because its behavior is dictated by the experimenter [2].
Reference: [16] <author> S. Nolfi, D. Floreano, O. Miglino, and F. Mondada, </author> <title> "How to evolve autonomous robots: </title> <booktitle> Different approaches in evolutionary robotics", in Proceedings of the Fourth Workshop on Artificial Life, </booktitle> <editor> R. Brooks and P. Maes, Eds., </editor> <address> Boston, MA, 1994, </address> <publisher> MIT Press. </publisher>
Reference-contexts: The results obtained by evolving simulated agents may have little in common with the evolution of real robots [61]. Although for simple environments and simple tasks (obstacle avoidance and light following) the control system evolved in a computer simulation may be directly transferred into a real robot [62], [63], <ref> [16] </ref>, [46], [20], this method is not guaranteed to work in more complex domains. The difficulty of making faithful simulations of complex visually-guided robots, has led a group of researchers to apply the evolutionary procedure directly on a real robot [64].
Reference: [17] <author> J. J. Gibson, </author> <title> The Ecological Approach to Visual Perception, </title> <publisher> Houghton Mi*in, </publisher> <address> Boston, </address> <year> 1979. </year>
Reference: [18] <author> F. Mondada, E. Franzi, and P. Ienne, </author> <title> "Mobile robot miniaturization: A tool for investigation in control algorithms", </title> <booktitle> in Proceedings of the Third International Symposium on Experimental Robotics, </booktitle> <address> Kyoto, Japan, </address> <year> 1993. </year>
Reference: [19] <author> M. J. Patel, </author> <title> "Situation Assessment and Adaptive Learning: Theoretical and Experimental Issues", </title> <booktitle> in Proceedings of the Second International Round-Table on Abstract Intelligent Agents, </booktitle> <address> Rome, </address> <year> 1994, </year> <note> ERCIM Research Report 03/94-R030 CNR. </note>
Reference-contexts: XX, NO. Y, MONTH 1996 sorting to the abstract design of their cognitive abilities and artificially restricting its range of actions. The results stressed the importance of situation assessment in adaptive agents <ref> [19] </ref> for the autonomous development of intelligent behaviors and interesting computational strategies.
Reference: [20] <author> M. Colombetti, M. Dorigo, and G. Borghi, </author> <title> "Behavior Analysis and Training: A Methodology for Behavior Engineering", </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <note> vol. This issue, </note> <year> 1996. </year>
Reference-contexts: Although for simple environments and simple tasks (obstacle avoidance and light following) the control system evolved in a computer simulation may be directly transferred into a real robot [62], [63], [16], [46], <ref> [20] </ref>, this method is not guaranteed to work in more complex domains. The difficulty of making faithful simulations of complex visually-guided robots, has led a group of researchers to apply the evolutionary procedure directly on a real robot [64]. <p> VII. Summary We have described the application of an evolutionary procedure to a real mobile robot in two different settings. In the first experiment the environment and the robot shell <ref> [20] </ref> were very simple, and the fitness function was very detailed and aimed at developing a specific behavior, i.e. straight navigation and obstacle avoidance. <p> The experiments showed that it is possible to perform behavior engineering <ref> [20] </ref> of intelligent agents without re 12 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS, VOL. XX, NO. Y, MONTH 1996 sorting to the abstract design of their cognitive abilities and artificially restricting its range of actions.
Reference: [21] <author> D. E. Goldberg, </author> <title> Genetic algorithms in search, optimization and machine learning, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: When all the individuals in the population had been tested, three genetic operators -selective reproduction, crossover, and mutation- were applied to create a completely new population of the same size. Selective reproduction consisted of a linear scaling of the fitness values <ref> [21] </ref> followed by a probabilistic allocation of a number of offspring proportional to the fitness value of each individual. All offspring, simple copies of their parents, were then randomly paired and a random single-point crossover was performed with a given probability.
Reference: [22] <author> D. Montana and L. Davis, </author> <title> "Training feed forward neural networks using genetic algorithms", </title> <booktitle> in Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> San Mateo, CA, 1989, </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Each value of the newly gabbia.eps 86 fi 55 mm Fig. 4. Environment of the experiment on navigation and obstacle avoidance. obtained strings was then mutated with a given probability by adding a small random value within a negative and positive mutation range ("biased mutation" <ref> [22] </ref>). The neuron model is simply described by a linear sum of the incoming weighted inputs (the threshold is taken as the contribution of an additional weighted input coming from a neuron which is always active) filtered through a sigmoid squashing function.
Reference: [23] <author> D. Floreano and F. Mondada, </author> <title> "Automatic Creation of an Autonomous Agent: Genetic Evolution of a Neural-Network Driven Robot", </title> <booktitle> in From Animals to Animats III: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> D. Cliff, P. Husbands, J. Meyer, and S. W. Wilson, Eds. </editor> <publisher> MIT Press-Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: The fitness function employed was very precisely engineered to achieve this type of behavior. Nevertheless, the evolved control systems displayed a number of interesting solutions that were indirectly instrumental to providing better performance (see <ref> [23] </ref> for a detailed discussion of the results). A. The experiment The robot was put in an environment consisting of a sort of circular corridor whose external size was approx. 80x50 cm large (Figure 4). <p> In fact, unlike the feedforward and internal symmetric structure of the Braitenberg vehicle which cannot drive the robot away from symmetric frontal obstacles, the evolved settings of the recurrent connections are such that our robot never became trapped <ref> [23] </ref>. The best robots also displayed a self-regulation of the cruising speed (approximately three quarters of the maximum available speed) that depended upon the characteristics of the environment, the response properties of the sensors, and the refreshing rate of the neurons. IV.
Reference: [24] <author> V. </author> <title> Braitenberg, Vehicles. Experiments in Synthetic Psychology, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1984. </year>
Reference-contexts: When compared to the performance of a simple Braitenberg vehicle <ref> [24] </ref> (type 3c modified and implemented on Khepera to perform obstacle avoidance), our evolved robot displayed a better global performance, especially when facing concave corners.
Reference: [25] <author> J. L. Elman, </author> <title> "Finding Structure in Time", </title> <journal> Cognitive Science, </journal> <volume> vol. 14, </volume> <pages> pp. 179-211, </pages> <year> 1990. </year>
Reference-contexts: The neural network. The input layer consists of twelve receptors, each clamped to one sensor (8 for infrared emitted light, 2 for ambient light, 1 for floor brightness, and 1 for battery charge) and fully connected to five hidden units. A set of recurrent connections <ref> [25] </ref> are added to the hidden units. The hidden units are fully connected to two motor neurons, each controlling the speed of rotation of the corresponding wheel. ner (Figure 8). <p> The neural network controlling the robot was a multilayer perceptron of continuous sigmoid units (Figure 9). The hidden layer consisted of 5 units with recurrent connections <ref> [25] </ref>; we did not attempt to optimize the number of units required and the connectivity pattern. Each robot started its life with a fully charged battery which was discharged by a fixed amount at each time step: a fully charged battery allowed a robot to move for 50 time steps.
Reference: [26] <author> W. Atmar, </author> <title> "Notes on the Simulation of Evolution", </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 5, </volume> <pages> pp. 130-148, </pages> <year> 1993. </year>
Reference-contexts: The spirit of our approach consists in making artificial evolution closer to natural evolution: Darwinian evolution is not an optimization algorithm, it has no sense of predetermined goal-directedness, but is rather a dynamic process governed by the principle of the survival of the individual <ref> [26] </ref>. <p> Although we have still maintained a vague global performance criterion and we have not taken into consideration the important influence of sociogenetic and ontogenetic learning <ref> [26] </ref>, our results are the first showing that these principles can be applied to robot learning in order to obtain more complex and meaningful behaviors.
Reference: [27] <author> P. Cariani, </author> <title> "Emergence and Artificial Life", </title> <booktitle> in Artificial Life II: Proceedings Volume of Santa Fe Conference, </booktitle> <editor> C.G. Langton, J.D. Farmer, S. Rasmussen, and C. Taylor, Eds., </editor> <volume> vol. </volume> <editor> XI. Addison Wesley: </editor> <booktitle> series of the Santa Fe Institute Studies in the Sciences of Complexities, </booktitle> <address> Reading, MA, </address> <year> 1991. </year>
Reference-contexts: To this extent, our methodology goes along the lines of those who think that the fitness function is not a global and precisely defined criterion, but is rather a characteristic of the individual and of the environment where it lives <ref> [27] </ref>, [28], [29] and, hence, it may also change with time [30].
Reference: [28] <author> T. S. Ray, </author> <title> "An approach to the synthesis of life", </title> <booktitle> in Artificial Life II: Proceedings Volume of Santa Fe Conference, </booktitle> <editor> C.G. Lang-ton, J.D. Farmer, S. Rasmussen, and C. Taylor, Eds., </editor> <volume> vol. </volume> <editor> XI. Addison Wesley: </editor> <booktitle> series of the Santa Fe Institute Studies in the Sciences of Complexities, </booktitle> <year> 1991. </year>
Reference-contexts: To this extent, our methodology goes along the lines of those who think that the fitness function is not a global and precisely defined criterion, but is rather a characteristic of the individual and of the environment where it lives [27], <ref> [28] </ref>, [29] and, hence, it may also change with time [30].
Reference: [29] <author> M. M. Rizki and M. Conrad, </author> <title> "Computing the Theory of Evolution", </title> <journal> Physica, </journal> <volume> vol. </volume> <pages> 22D, pp. 83-99, </pages> <year> 1986. </year>
Reference-contexts: To this extent, our methodology goes along the lines of those who think that the fitness function is not a global and precisely defined criterion, but is rather a characteristic of the individual and of the environment where it lives [27], [28], <ref> [29] </ref> and, hence, it may also change with time [30].
Reference: [30] <author> H. H. Lund and D. Parisi, </author> <title> "Simulations with an Evolvable Fitness Formula", </title> <type> Tech. Rep. 94-01, </type> <institution> Institute of Psychology, CNR, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: this extent, our methodology goes along the lines of those who think that the fitness function is not a global and precisely defined criterion, but is rather a characteristic of the individual and of the environment where it lives [27], [28], [29] and, hence, it may also change with time <ref> [30] </ref>.
Reference: [31] <author> J. O'Keefe and L. </author> <title> Nadel, The Hippocampus as a Cognitive Map, </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1978. </year>
Reference-contexts: The functioning of node v h4 (Figure 17) vaguely resembles the classic findings about the organization of the rat hippocampus, where most of the cells are "place cells", i.e. they fire only when the rat is in a particular portion of its environment <ref> [31] </ref>.
Reference: [32] <author> J. S. Taube, R. U. Muller, and J. B. Jr. Ranck, </author> <title> "Head-direction cells recorded from the postsubiculum in freely moving rats. I. Description and quantitative analysis", </title> <journal> Journal of Neuroscience, </journal> <volume> vol. 10, </volume> <pages> pp. 420-435, </pages> <year> 1990. </year>
Reference-contexts: With regard to the head-direction activity of node v h4, agreement (in functional terms) is found with recent findings about the existence of few "head-direction" cells (whose firing modality depends upon the direction of the rat's head) in regions neighbouring the rat hippocampus <ref> [32] </ref>.
Reference: [33] <author> E. C. Tolman, </author> <title> "Cognitive maps in rats and men", </title> <journal> Psychological Review, </journal> <volume> vol. 55, </volume> <pages> pp. 189-208, </pages> <year> 1948. </year>
Reference-contexts: XX, NO. Y, MONTH 1996 reached nearly 50 years ago in psychology <ref> [33] </ref> and formed the basis for a large conceptual revolution). A rather interesting result comes from the dual role played by node v h4 as an orienteering device and as a controller of battery charge.
Reference: [34] <editor> M. Abeles, Corticonics, </editor> <publisher> Cambridge University Press, </publisher> <address> Cam-bridge, </address> <year> 1991. </year>
Reference-contexts: Such a dual and concurrent processing modality has been hypothesized for biological neurons <ref> [34] </ref> too, but it can be hardly analyzed in living organisms because of technical difficulties. However, it can be displayed and thus analyzed in artificial neural network models which have recurrent (discrete or continuous) dynamics.
Reference: [35] <author> D. Floreano, </author> <title> "Emergence of Home-Based Foraging Strategies in Ecosystems of Neural Networks", in From Animals to Ani-mats II: </title> <booktitle> Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> J. Meyer, H. L. Roitblat, and S. W. Wilson, Eds. </editor> <publisher> MIT Press-Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: In order to make the fitness surface smoother, we adopted a more gradual approach by introducing obstacles only after that the robot learned to locate the recharging area (see <ref> [35] </ref> and [36] for a similar procedure). The resulting behavior was not completely satisfactory, although the robot displayed some degree of adaptation to the new environment (this experiment lasted almost 1,000 hours): the best individuals could reach the recharging area only from a very few starting positions. <p> Developing on these lines, they present results of several evolved behaviors for a simulated robot with a very simple visual system [55], [56], [57], [14]. Flore-ano <ref> [35] </ref> has studied the evolution of a simulated agent who developed the ability to reach a nest where it could eat the food found in the external environment.
Reference: [36] <author> I. Harvey, P. Husbands, and D. Cliff, </author> <title> "Seeing The Light: Artificial Evolution, Real Vision", </title> <booktitle> in From Animals to Animats III: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> D. Cliff, P. Husbands, J. Meyer, and S. W. Wilson, Eds. </editor> <publisher> MIT Press-Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year> <title> FLOREANO AND MONDADA: EVOLUTION OF HOMING NAVIGATION IN A REAL MOBILE ROBOT 13 </title>
Reference-contexts: In order to make the fitness surface smoother, we adopted a more gradual approach by introducing obstacles only after that the robot learned to locate the recharging area (see [35] and <ref> [36] </ref> for a similar procedure). The resulting behavior was not completely satisfactory, although the robot displayed some degree of adaptation to the new environment (this experiment lasted almost 1,000 hours): the best individuals could reach the recharging area only from a very few starting positions. <p> Several methods [40], [41], [42], [43], [44], [45] have been proposed and shown to yield better and faster solutions than traditional encoding methods on simple tasks, but only a few [46], <ref> [36] </ref> have been applied to autonomous agents. Although these methods can evolve modular architectures that are suited to the requirements of the task, it is still premature to assess the superiority of one approach over the other for the evolution of real robots. VI. <p> Harvey, Husbands, and Cliff have evolved target-approaching and object-following behaviors on a real robot with a circular body and a rotating camera suspended from a gantry-frame which allows 2-dimensional motion on the surface of the environment <ref> [36] </ref>. The evolution of the morphology of the visual system along with the structure of the neural network has resulted in smart and economical, but efficient, solutions. However, the development of increasingly more complex behaviors was achieved by using specifically-engineered fitness functions and by resorting to an incremental approach.
Reference: [37] <author> G. E. Hinton and S. J. Nowlan, </author> <title> "How learning can guide evolution", </title> <journal> Complex Systems, </journal> <volume> vol. 1, </volume> <pages> pp. 495-502, </pages> <year> 1987. </year>
Reference-contexts: cyclic pattern of activity that was completely uncorrelated with any external and internal parameter (position, orientation, battery status). the selection procedure can evaluate a large set of values for each string (due to the oscillations of performance on the fitness surface caused by synaptic change), rather than a single value <ref> [37] </ref> as in our case. Some experimental results on the evolution of simulated learning agents have shown both a speed-up in the convergence time [38] and the ability to deal with a very complex environment [39]. Our current work is focusing on this approach.
Reference: [38] <author> S. Nolfi, J. L. Elman, and D. Parisi, </author> <title> "Learning and evolution in neural networks", </title> <booktitle> Adaptive Behavior, </booktitle> <volume> vol. 3, </volume> <pages> pp. 5-28, </pages> <year> 1994. </year>
Reference-contexts: Some experimental results on the evolution of simulated learning agents have shown both a speed-up in the convergence time <ref> [38] </ref> and the ability to deal with a very complex environment [39]. Our current work is focusing on this approach.
Reference: [39] <author> D. H. Ackley and M. L. Littman, </author> <title> "Interactions between learning and evolution", </title> <booktitle> in Artificial Life II: Proceedings Volume of Santa Fe Conference, </booktitle> <editor> C.G. Langton, J.D. Farmer, S. Ras-mussen, and C. Taylor, Eds., </editor> <volume> vol. </volume> <editor> XI. Addison Wesley: </editor> <booktitle> series of the Santa Fe Institute Studies in the Sciences of Complexities, </booktitle> <address> Reading, MA, </address> <year> 1991. </year>
Reference-contexts: Some experimental results on the evolution of simulated learning agents have shown both a speed-up in the convergence time [38] and the ability to deal with a very complex environment <ref> [39] </ref>. Our current work is focusing on this approach.
Reference: [40] <author> H. Kitano, </author> <title> "Designing neural networks using genetic algorithms with graph generation system", </title> <journal> Complex Systems, </journal> <volume> vol. 4, </volume> <pages> pp. 461-476, </pages> <year> 1990. </year>
Reference-contexts: An alternative solution to the scalability problems outlined above and to the reduction of the evolution time could be provided by a more efficient genetic encoding that would use more compact or suitable representations which capture the essential features of a neural network model. Several methods <ref> [40] </ref>, [41], [42], [43], [44], [45] have been proposed and shown to yield better and faster solutions than traditional encoding methods on simple tasks, but only a few [46], [36] have been applied to autonomous agents.
Reference: [41] <author> S. A. Harp, T. Samad, and A. Guha, </author> <title> "Toward the genetic synthesis of neural networks", </title> <booktitle> in Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <editor> J. D. Schaffer, Ed. </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: An alternative solution to the scalability problems outlined above and to the reduction of the evolution time could be provided by a more efficient genetic encoding that would use more compact or suitable representations which capture the essential features of a neural network model. Several methods [40], <ref> [41] </ref>, [42], [43], [44], [45] have been proposed and shown to yield better and faster solutions than traditional encoding methods on simple tasks, but only a few [46], [36] have been applied to autonomous agents.
Reference: [42] <author> E. J. W. Boers and H. Kuiper, </author> <title> "Biological metaphors and the design of modular artificial neural networks", </title> <type> Tech. Rep. Master Thesis, </type> <institution> Computer Science, University of Leiden, The Nether-lands, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: An alternative solution to the scalability problems outlined above and to the reduction of the evolution time could be provided by a more efficient genetic encoding that would use more compact or suitable representations which capture the essential features of a neural network model. Several methods [40], [41], <ref> [42] </ref>, [43], [44], [45] have been proposed and shown to yield better and faster solutions than traditional encoding methods on simple tasks, but only a few [46], [36] have been applied to autonomous agents.
Reference: [43] <author> F. Gruau, </author> <title> "Genetic systems of boolean neural networks with a cell rewriting developmental process", in Combination of Genetic Algorithms and Neural Networks, </title> <editor> D. Whitley and J. D. Schaffer, Eds. </editor> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1992. </year>
Reference-contexts: An alternative solution to the scalability problems outlined above and to the reduction of the evolution time could be provided by a more efficient genetic encoding that would use more compact or suitable representations which capture the essential features of a neural network model. Several methods [40], [41], [42], <ref> [43] </ref>, [44], [45] have been proposed and shown to yield better and faster solutions than traditional encoding methods on simple tasks, but only a few [46], [36] have been applied to autonomous agents.
Reference: [44] <author> P. J. Angeline, G. M. Saunders, and J. B. Pollack, </author> <title> "An Evolutionary Algorithm That Constructs Recurrent Neural Networks", </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 5, </volume> <pages> pp. 54-65, </pages> <year> 1993. </year>
Reference-contexts: Several methods [40], [41], [42], [43], <ref> [44] </ref>, [45] have been proposed and shown to yield better and faster solutions than traditional encoding methods on simple tasks, but only a few [46], [36] have been applied to autonomous agents.
Reference: [45] <author> V. Maniezzo, </author> <title> "Genetic Evolution of the Topology and Weight Distribution of Neural Networks", </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 5, </volume> <pages> pp. 39-53, </pages> <year> 1993. </year>
Reference-contexts: Several methods [40], [41], [42], [43], [44], <ref> [45] </ref> have been proposed and shown to yield better and faster solutions than traditional encoding methods on simple tasks, but only a few [46], [36] have been applied to autonomous agents.
Reference: [46] <author> S. Nolfi, O. Miglino, and D. Parisi, </author> <title> "Phenotipic Plasticity in Evolving Neural Networks", in Proceedings of the conference From Perception to Action, </title> <editor> J-D. Nicoud and P. Gaussier, Eds. </editor> <publisher> IEEE Computer Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1994. </year>
Reference-contexts: Several methods [40], [41], [42], [43], [44], [45] have been proposed and shown to yield better and faster solutions than traditional encoding methods on simple tasks, but only a few <ref> [46] </ref>, [36] have been applied to autonomous agents. Although these methods can evolve modular architectures that are suited to the requirements of the task, it is still premature to assess the superiority of one approach over the other for the evolution of real robots. VI. <p> Although for simple environments and simple tasks (obstacle avoidance and light following) the control system evolved in a computer simulation may be directly transferred into a real robot [62], [63], [16], <ref> [46] </ref>, [20], this method is not guaranteed to work in more complex domains. The difficulty of making faithful simulations of complex visually-guided robots, has led a group of researchers to apply the evolutionary procedure directly on a real robot [64].
Reference: [47] <author> M. Rudnick, </author> <title> "A Bibliography of the Intersection of Genetic Search and Artificial Neural Networks", </title> <type> Tech. Rep. CS/E 90-001, </type> <institution> Department of Computer Science and Engineering, Oregon Graduate Center, </institution> <month> January </month> <year> 1990. </year>
Reference-contexts: VI. Related work There is a large literature on the application of evolutionary techniques to the design and training of neural networks (see <ref> [47] </ref> for a specific bibliography, [48], [49], [50] for a description of the various approaches employed, and the 1993 special issue on Evolutionary Computation of the IEEE Transactions on Neural Networks for an outline of more recent results).
Reference: [48] <author> G. Weiss, </author> <title> "Combining neural and evolutionary learning: Aspects and approaches", </title> <type> Tech. Rep. </type> <institution> FKI-132-90, Institut fur In-formatik, Technische Universitat Munchen, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: VI. Related work There is a large literature on the application of evolutionary techniques to the design and training of neural networks (see [47] for a specific bibliography, <ref> [48] </ref>, [49], [50] for a description of the various approaches employed, and the 1993 special issue on Evolutionary Computation of the IEEE Transactions on Neural Networks for an outline of more recent results).
Reference: [49] <editor> J. D. Schaffer, D. Whitley, and L. J. Eshelman, </editor> <title> "Combinations of Genetic Algorithms and Neural Networks: A Survey of the State of the Art", </title> <booktitle> in Proceedings of an International Workshop on the Combinations of Genetic Algorithms and Neural Networks (COGANN-92). 1992, </booktitle> <publisher> IEEE Press. </publisher>
Reference-contexts: VI. Related work There is a large literature on the application of evolutionary techniques to the design and training of neural networks (see [47] for a specific bibliography, [48], <ref> [49] </ref>, [50] for a description of the various approaches employed, and the 1993 special issue on Evolutionary Computation of the IEEE Transactions on Neural Networks for an outline of more recent results).
Reference: [50] <author> X. Yao, </author> <title> "A review of evolutionary artificial neural networks", </title> <journal> International Journal of Intelligent Systems, </journal> <volume> vol. 4, </volume> <pages> pp. 203-222, </pages> <year> 1993. </year>
Reference-contexts: VI. Related work There is a large literature on the application of evolutionary techniques to the design and training of neural networks (see [47] for a specific bibliography, [48], [49], <ref> [50] </ref> for a description of the various approaches employed, and the 1993 special issue on Evolutionary Computation of the IEEE Transactions on Neural Networks for an outline of more recent results).
Reference: [51] <author> D. T. Cliff, </author> <title> "Computational neuroethology: a provisional manifesto", </title> <booktitle> in From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> J. A. Meyer and S. W. Wilson, Eds. </editor> <publisher> MIT Press-Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: Nevertheless, the research reported here is based and variously related to some of these contributions, which we briefly mention below. Cliff <ref> [51] </ref> provides a theoretical background for the study of simulated organisms situated in closed environment and defines Computational Neuroethology as the attempt to relate behavior with the activity of neural mechanisms using the methodology of computational neuroscience (a similar approach is described also in [52]).
Reference: [52] <author> R. D. Beer, </author> <title> Intelligence as adaptive behavior: an experiment in computational neuroethology, </title> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1990. </year>
Reference-contexts: Cliff [51] provides a theoretical background for the study of simulated organisms situated in closed environment and defines Computational Neuroethology as the attempt to relate behavior with the activity of neural mechanisms using the methodology of computational neuroscience (a similar approach is described also in <ref> [52] </ref>). On similar lines is the work by Parisi, Cecconi and Nolfi [9] who also stress the importance for an evolving organism to learn to predict the sensory consequences of its own actions in order to develop an internal world model.
Reference: [53] <author> D. Cliff, I. Harvey, and P. Husbands, </author> <title> "Incremental Evolution of Neural Architectures for Adaptive Behaviour", </title> <type> Tech. Rep. </type> <institution> CSRP 256, School of Cognitive and Computing Science, University of Sussex, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: Their major claim is that artificial evolution represents an alternative and more fruitful approach (contrasted to design by hand) to developing the control systems of autonomous mobile robots [12]. In their view the evolutionary method should be incremental <ref> [53] </ref> and operate on recurrent real-time neu FLOREANO AND MONDADA: EVOLUTION OF HOMING NAVIGATION IN A REAL MOBILE ROBOT 11 ral networks [54].
Reference: [54] <author> I. Harvey, P. Husbands, and D. Cliff, </author> <booktitle> "Issues in Evolutionary Robotics", in From Animals to Animats II: Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> J. Meyer, H. L. Roitblat, and S. W. Wilson, Eds. </editor> <publisher> MIT Press-Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: In their view the evolutionary method should be incremental [53] and operate on recurrent real-time neu FLOREANO AND MONDADA: EVOLUTION OF HOMING NAVIGATION IN A REAL MOBILE ROBOT 11 ral networks <ref> [54] </ref>. They suggest that some sort of visual processing is necessary for evolving non-trivial behaviors, but also say that careful simulations of the robot and of the robot/environment interactions can be necessary because of time constraints.
Reference: [55] <author> D. T. Cliff, P. Husbands, and I. Harvey, </author> <title> "Evolving visually guided robots", in From Animals to Animats II: </title> <booktitle> Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> J. Meyer, H. L. Roitblat, and S. W. Wilson, Eds. </editor> <publisher> MIT Press-Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: Developing on these lines, they present results of several evolved behaviors for a simulated robot with a very simple visual system <ref> [55] </ref>, [56], [57], [14]. Flore-ano [35] has studied the evolution of a simulated agent who developed the ability to reach a nest where it could eat the food found in the external environment.
Reference: [56] <author> D. Cliff, P. Husbands, and I. Harvey, </author> <title> "Analysis of Evolved Sensory-Motor Controllers", </title> <type> Tech. Rep. </type> <institution> CSRP 264, School of Cognitive and Computing Science, University of Sussex, </institution> <month> Decem-ber </month> <year> 1992. </year>
Reference-contexts: Developing on these lines, they present results of several evolved behaviors for a simulated robot with a very simple visual system [55], <ref> [56] </ref>, [57], [14]. Flore-ano [35] has studied the evolution of a simulated agent who developed the ability to reach a nest where it could eat the food found in the external environment.
Reference: [57] <author> P. Husbands, I. Harvey, and D. Cliff, </author> <title> "Analysing Recurrent Dynamical Networks Evolved for Robot Control", </title> <type> Tech. Rep. </type> <institution> CSRP 265, School of Cognitive and Computing Science, University of Sussex, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: Developing on these lines, they present results of several evolved behaviors for a simulated robot with a very simple visual system [55], [56], <ref> [57] </ref>, [14]. Flore-ano [35] has studied the evolution of a simulated agent who developed the ability to reach a nest where it could eat the food found in the external environment.
Reference: [58] <author> A. Treves, O. Miglino, and D. Parisi, "Rats, </author> <title> nets, maps, and the emergence of place cells", </title> <journal> Psychobiology, </journal> <volume> vol. 20(1), </volume> <pages> pp. 1-8, </pages> <year> 1992. </year>
Reference-contexts: Similarly, reaching for a hidden location by means of visual landmarks has been reported by Treves, Miglino and Parisi <ref> [58] </ref> in evolved simulated agents. Their analysis of the resulting neural activity (in simple feed-forward architecture) reveals a functional analogy with the neural mechanisms employed by rats to navigate and resembles the topological patterns of activity described here (Figure 17).
Reference: [59] <author> J. R. Koza, J. P. Rice, and J. Roughgarden, </author> <title> "Evolution of Food-Foraging Strategies for the Caribbean Anolis Lizard Using Genetic Programming", </title> <booktitle> Adaptive Behavior, </booktitle> <volume> vol. 1, </volume> <pages> pp. 171-199, </pages> <year> 1992. </year>
Reference-contexts: The evolution of programs (whose composition is similar to the symbolic expressions found in Lisp), also termed Genetic Programming by its inventor Koza [10], has been successfully employed -among other examples- to recreate the patterns of locomotion of a lizard <ref> [59] </ref>, to evolve coordinate group motion of visually guided agents [60] and to develop corridor-following behaviors [13]. Dorigo and Schnepf [6] have developed a parallel robot controller (ALECSYS) based on a classifier system evolved by means of a genetic algorithm that can coordinate several different behaviors of a simulated agent.
Reference: [60] <author> C. W. Reynolds, </author> <title> "An Evolved, Vision-Based Behavioral Model of Coordinated Group Motion", in From Animals to Animats II: </title> <booktitle> Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> J. Meyer, H. L. Roitblat, and S. W. Wilson, Eds. </editor> <publisher> MIT Press-Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: The evolution of programs (whose composition is similar to the symbolic expressions found in Lisp), also termed Genetic Programming by its inventor Koza [10], has been successfully employed -among other examples- to recreate the patterns of locomotion of a lizard [59], to evolve coordinate group motion of visually guided agents <ref> [60] </ref> and to develop corridor-following behaviors [13]. Dorigo and Schnepf [6] have developed a parallel robot controller (ALECSYS) based on a classifier system evolved by means of a genetic algorithm that can coordinate several different behaviors of a simulated agent.
Reference: [61] <author> R. Brooks, </author> <title> "Artificial Life and real robots", in Toward a practice of autonomous systems: </title> <booktitle> Proceedings of the First European Conference on Artificial Life, </booktitle> <editor> F. J. Varela and P. Bourgine, Eds. </editor> <publisher> The MIT Press/Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: The design and the evaluation of their system is strongly based on ethological considerations. The results obtained by evolving simulated agents may have little in common with the evolution of real robots <ref> [61] </ref>. Although for simple environments and simple tasks (obstacle avoidance and light following) the control system evolved in a computer simulation may be directly transferred into a real robot [62], [63], [16], [46], [20], this method is not guaranteed to work in more complex domains.
Reference: [62] <author> M. Colombetti and M. Dorigo, </author> <title> "Learning to Control an Autonomous Robot by Distributed Genetic Algorithms", in From Animals to Animats II: </title> <booktitle> Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> J. Meyer, H. L. Roitblat, and S. W. Wilson, Eds. </editor> <publisher> MIT Press-Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: The results obtained by evolving simulated agents may have little in common with the evolution of real robots [61]. Although for simple environments and simple tasks (obstacle avoidance and light following) the control system evolved in a computer simulation may be directly transferred into a real robot <ref> [62] </ref>, [63], [16], [46], [20], this method is not guaranteed to work in more complex domains. The difficulty of making faithful simulations of complex visually-guided robots, has led a group of researchers to apply the evolutionary procedure directly on a real robot [64].
Reference: [63] <author> O. Miglino, C. Nafasi, and C. Taylor, </author> <title> "Selection for Wandering Behavior in a Small Robot", </title> <type> Tech. Rep. </type> <institution> UCLA-CRSP-94-01, Department of Cognitive Science, UCLA, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: The results obtained by evolving simulated agents may have little in common with the evolution of real robots [61]. Although for simple environments and simple tasks (obstacle avoidance and light following) the control system evolved in a computer simulation may be directly transferred into a real robot [62], <ref> [63] </ref>, [16], [46], [20], this method is not guaranteed to work in more complex domains. The difficulty of making faithful simulations of complex visually-guided robots, has led a group of researchers to apply the evolutionary procedure directly on a real robot [64].
Reference: [64] <author> P. Husbands, I. Harvey, D. Cliff, and G. Miller, </author> <title> "The Use of Genetic Algorithms for the Development of Sensorimotor Control Systems", in Proceedings of the conference From Perception to Action, </title> <editor> J-D. Nicoud and P. Gaussier, Eds. </editor> <publisher> IEEE Computer Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1994. </year>
Reference-contexts: The difficulty of making faithful simulations of complex visually-guided robots, has led a group of researchers to apply the evolutionary procedure directly on a real robot <ref> [64] </ref>. Harvey, Husbands, and Cliff have evolved target-approaching and object-following behaviors on a real robot with a circular body and a rotating camera suspended from a gantry-frame which allows 2-dimensional motion on the surface of the environment [36].
Reference: [65] <author> S. Baluja, </author> <title> "Evolution of an Artificial Neural Network Based Autonomous Land Vehicle Controller", </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <note> vol. This issue, </note> <year> 1996. </year>
Reference-contexts: Baluja shows that genetic algorithms can provide strategies to control an autonomous land vehicle (ALVINN) that are comparable to those found by a supervised learning algorithm <ref> [65] </ref>. The main difference from our work is that Baluja knows exactly what are the appropriate actions that the vehicle should take in the situations employed for training and can exploit this knowledge to assess the performance of the neural networks.

References-found: 65

