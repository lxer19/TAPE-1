URL: http://www.cs.umn.edu/Users/dept/users/kumar/mahesh/pspases-manual.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/mahesh/
Root-URL: http://www.cs.umn.edu
Email: fmjoshi,karypis,kumarg@cs.umn.edu  anshul@watson.ibm.com  
Title: PSPASES Scalable Parallel Direct Solver Library for Sparse Symmetric Positive Definite Linear Systems User's Manual
Author: Mahesh Joshi, George Karypis, and Vipin Kumar Anshul Gupta and Fred Gustavson 
Note: Last updated on September 23, 1998 at 1:37am  
Address: Minneapolis, MN 55455.  Yorktown Heights, NY 10598.  
Affiliation: Department of Computer Science, University of Minnesota  IBM Thomas J. Watson Research Center  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> George Karypis and Vipin Kumar, ParMETIS: </author> <title> Parallel Graph Partitioning Library, </title> <note> Version 1.0, Available via URL : http://www.cs.umn.edu/~metis, July 1997. </note>
Reference-contexts: PSPASES solves the given system using the direct method of solution, which consists of four consecutive stages of processing: ordering, symbolic factorization, Cholesky factorization, and triangular systems solution. Each of these phases is implemented using the scalable and high performance algorithms developed by the authors <ref> [1, 4, 2, 3] </ref>. PSPASES can be used on any parallel computer or network of workstations equipped with MPI, and Fortran-90 and C language compilers. It has been tested on IBM SP, network of IBM RS6000 workstations, SGI Power Challenge, SGI Origin 2000, and Cray T3E. <p> Following is the description of each of the subroutines. - PSPACEO (Ordering): Computes a fill reducing ordering using ParMETIS <ref> [1] </ref>, given the nonzero structure of A. This is the first phase of the direct solution method. 6 - PSPACEY (SYmbolic factorization): Computes the nonzero structure of L, given the ordering. <p> Refer to [2] for details. (default = 64) ioptions <ref> [1] </ref> (I,G) if 1, checks the symmetry of the non-zeros of A. (default = 0) ioptions [2] (I,G) if 1, sorts the column indices, stored in ainds, for every row of A. <p> Must be set to 1, if not sure of the sorted order (default = 0) ioptions [3-15] Unused. doptions (O,L) An array of size 16. doptions [0] (O,L) Memory used in PSPASES Communicator (in bytes) for the calling process. This is already allocated. doptions <ref> [1] </ref> (O,L) Estimated extra memory requirement (in bytes), for the calling process, to complete numerical factorization.
Reference: [2] <author> Anshul Gupta, George Karypis, and Vipin Kumar, </author> <title> Highly Scalable Parallel Algorithms for Sparse Matrix Factorizations, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, vol.8, </journal> <volume> no.5, </volume> <year> 1995. </year>
Reference-contexts: PSPASES solves the given system using the direct method of solution, which consists of four consecutive stages of processing: ordering, symbolic factorization, Cholesky factorization, and triangular systems solution. Each of these phases is implemented using the scalable and high performance algorithms developed by the authors <ref> [1, 4, 2, 3] </ref>. PSPASES can be used on any parallel computer or network of workstations equipped with MPI, and Fortran-90 and C language compilers. It has been tested on IBM SP, network of IBM RS6000 workstations, SGI Power Challenge, SGI Origin 2000, and Cray T3E. <p> Note that, aptrs must be stored in a column-major order. ainds (I,L) As described in section 2.2. order (I,L) As described in section 2.4. sizes (I,G) As described in section 2.4. ioptions (I,G) An array of size 16. ioptions [0] (M,G) block size for distributing A internally. Refer to <ref> [2] </ref> for details. (default = 64) ioptions [1] (I,G) if 1, checks the symmetry of the non-zeros of A. (default = 0) ioptions [2] (I,G) if 1, sorts the column indices, stored in ainds, for every row of A. <p> Refer to <ref> [2] </ref> for details. (default = 64) ioptions [1] (I,G) if 1, checks the symmetry of the non-zeros of A. (default = 0) ioptions [2] (I,G) if 1, sorts the column indices, stored in ainds, for every row of A. <p> This is already allocated. doptions [1] (O,L) Estimated extra memory requirement (in bytes), for the calling process, to complete numerical factorization. Add this to doptions [0] to get the total Memory Requirement. doptions <ref> [2] </ref> (O,L) Number of non-zeros in the triangular part of global A. (Relevant only on processor 0). doptions [3] (O,L) Number of non-zeros in global L. (Relevant only on processor 0). doptions [4] (O,L) Opcount for sequential factorization. (Relevant only on processor 0). doptions [5] (O,L) Computational load imbalance caused by
Reference: [3] <author> Mahesh Joshi, Anshul Gupta, George Karypis, and Vipin Kumar, </author> <title> A High Performance Two Dimensional Scalable Parallel Algorithm for Solving Sparse Triangular Systems, </title> <booktitle> Proc. 1997 International Conference on High Performance Computing (HiPC'97), </booktitle> <address> Bangalore, India, </address> <year> 1997. </year>
Reference-contexts: PSPASES solves the given system using the direct method of solution, which consists of four consecutive stages of processing: ordering, symbolic factorization, Cholesky factorization, and triangular systems solution. Each of these phases is implemented using the scalable and high performance algorithms developed by the authors <ref> [1, 4, 2, 3] </ref>. PSPASES can be used on any parallel computer or network of workstations equipped with MPI, and Fortran-90 and C language compilers. It has been tested on IBM SP, network of IBM RS6000 workstations, SGI Power Challenge, SGI Origin 2000, and Cray T3E. <p> Note that, aptrs must be stored in a column-major order. ainds (I,L) As described in section 2.2. order (O,L) As described in section 2.4. sizes (O,G) As described in section 2.4. ioptions (I,G) An array of size 16. ioptions <ref> [3] </ref> (I,G) if 1, does sequential ordering using METIS. Default is to do parallel ordering using ParMETIS. mpicomm (I,G) Pointer to MPI Communicator (The size of the communicator must be 2 i ; i 1). <p> Add this to doptions [0] to get the total Memory Requirement. doptions [2] (O,L) Number of non-zeros in the triangular part of global A. (Relevant only on processor 0). doptions <ref> [3] </ref> (O,L) Number of non-zeros in global L. (Relevant only on processor 0). doptions [4] (O,L) Opcount for sequential factorization. (Relevant only on processor 0). doptions [5] (O,L) Computational load imbalance caused by imbalance in the supernodal tree. <p> Note that, the value stored at avals [k] must correspond to the nonzero index stored at ainds [k]. ioptions (I,G) Same as described in PSPACEY, plus ioptions <ref> [3] </ref> (I,G) if 1, does sequential ordering using METIS. Default is to do parallel ordering using ParMETIS. doptions (O,L) Same as described in PSPACEY. pspcomm (O,G) Pointer to PSPASES Communicator. mpicomm (I,G) Pointer to MPI Communicator (The size of the communicator must be 2 i ; i 1).
Reference: [4] <author> Anshul Gupta, Fred G. Gustavson, Mahesh Joshi, George Karypis, </author> <title> and Vipin Kumar,Design and Implementation of a Scalable Parallel Direct Solver for Sparse Symmetric Positive Definite Systems: Preliminary Results, </title> <booktitle> Proc. Eighth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <address> Minneapolis, </address> <month> March </month> <year> 1997. </year>
Reference-contexts: PSPASES solves the given system using the direct method of solution, which consists of four consecutive stages of processing: ordering, symbolic factorization, Cholesky factorization, and triangular systems solution. Each of these phases is implemented using the scalable and high performance algorithms developed by the authors <ref> [1, 4, 2, 3] </ref>. PSPASES can be used on any parallel computer or network of workstations equipped with MPI, and Fortran-90 and C language compilers. It has been tested on IBM SP, network of IBM RS6000 workstations, SGI Power Challenge, SGI Origin 2000, and Cray T3E. <p> PSPASES would then reorder this matrix to realize the specified permutation. However, the user must be familiar with the algorithms of PSPASES in order to provide such ordering information. Refer to <ref> [4] </ref> for the concept of elimination trees and their abstraction to supernodal trees used in PSPASES algorithms. The ordering provided by the user must yield a supernodal tree that is binary in the top log p levels, when the problem is being solved on p processors. <p> Add this to doptions [0] to get the total Memory Requirement. doptions [2] (O,L) Number of non-zeros in the triangular part of global A. (Relevant only on processor 0). doptions [3] (O,L) Number of non-zeros in global L. (Relevant only on processor 0). doptions <ref> [4] </ref> (O,L) Opcount for sequential factorization. (Relevant only on processor 0). doptions [5] (O,L) Computational load imbalance caused by imbalance in the supernodal tree.
Reference: [5] <author> Anshul Gupta, Mahesh Joshi, and Vipin Kumar, WSSMP: </author> <title> Watson Symmetric Sparse Matrix Package, </title> <note> IBM Research Report RC 20923 (92669), 1997. (Also available at ftp://ftp.cs.umn.edu//users/kumar/anshul//WSSMP-manual.ps) 17 </note>
Reference-contexts: It has been tested on IBM SP, network of IBM RS6000 workstations, SGI Power Challenge, SGI Origin 2000, and Cray T3E. A faster version with enhanced functionality for IBM RS6000 workstations and IBM SP parallel computers is available as WSSMP <ref> [5] </ref>. 1.1 Organization of this Manual This manual describes different functions provided by PSPASES, and explains how to use them. Section 2 describes the input and output formats of A, B, and X accepted by PSPASES functions. <p> get the total Memory Requirement. doptions [2] (O,L) Number of non-zeros in the triangular part of global A. (Relevant only on processor 0). doptions [3] (O,L) Number of non-zeros in global L. (Relevant only on processor 0). doptions [4] (O,L) Opcount for sequential factorization. (Relevant only on processor 0). doptions <ref> [5] </ref> (O,L) Computational load imbalance caused by imbalance in the supernodal tree. <p> The current available version of these libraries is supplied with PSPASES distribution. The latest versions can be obtained from the METIS web-site : http://www.cs.umn.edu/~metis. A faster version of PSPASES, with enhanced functionalities, is available for IBM RS6000 workstations and IBM SP parallel computers as the WSSMP <ref> [5] </ref> library. This library can solve positive definite as well as indefinite systems. For further information, refer to ftp://ftp.cs.umn.edu//users/kumar/anshul/WSSMP-manual.ps.
References-found: 5

