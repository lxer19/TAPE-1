URL: ftp://ftp.cs.washington.edu/tr/1994/12/UW-CSE-94-12-07.PS.Z
Refering-URL: http://www.cs.washington.edu/homes/pardo/papers.html
Root-URL: 
Title: Wait-Free Algorithms for Heaps  
Author: Greg Barnes 
Date: February 3, 1992  
Address: Seattle, WA 98195  
Affiliation: Dept. of Computer Science and Engineering, FR-35 University of Washington  
Abstract: This paper examines algorithms to implement heaps on shared memory multiprocessors. A natural model for these machines is an asynchronous parallel machine, in which the processors are subject to arbitrary delays. On such machines, it is desirable for algorithms to be wait-free, meaning that each thread makes progress independent of the other threads executing on the machine. We present a wait-free algorithm to implement heaps. The algorithms are similar to the general approach given in [4], with optimizations that allow many threads to work on the heap simultaneously, while still guaranteeing a strong serializability property.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Alemany and E. W. Felten. </author> <title> Performance issues in non-blocking synchronization on shared-memory multiprocessors. </title> <booktitle> In Proceedings of the Eleventh Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 124-134, </pages> <address> Vancouver, B.C., Canada, </address> <month> Aug. </month> <year> 1992. </year> <month> 14 </month>
Reference-contexts: Using Load Linked and Store Conditional, a universal pair of primitives similar to Compare&Swap, Herlihy [15] describes a methodology for converting synchronous implementations of data structure algorithms to non-blocking and wait-free implementations. Alemany and Felten <ref> [1] </ref> present techniques for improving the performance of Herlihy's protocol in practice. Anderson and Woll [2] use Compare&Swap to design efficient asynchronous algorithms for the Union-Find problem. Heaps are often used to implement priority queues.
Reference: [2] <author> R. J. Anderson and H. Woll. </author> <title> Wait-free parallel algorithms for the union--find problem. </title> <type> Technical Report 91-04-05, </type> <institution> University of Washington, </institution> <year> 1991. </year> <note> See also [3]. </note>
Reference-contexts: Alemany and Felten [1] present techniques for improving the performance of Herlihy's protocol in practice. Anderson and Woll <ref> [2] </ref> use Compare&Swap to design efficient asynchronous algorithms for the Union-Find problem. Heaps are often used to implement priority queues. Many researchers have examined the problem of concurrent access to priority queue structures such as skew trees, B-trees, or 2-3 trees. <p> Each node is a record consisting of the key, some flags, and a few auxiliary variables. By using Load Linked and Store Conditional on the pointer to a record, the algorithm can atomically check in the entire record. A similar strategy is used by Anderson and Woll <ref> [2] </ref> in their Union-Find algorithms. <p> The algorithm poses other interesting theoretical and practical questions. The lower bound given in Section 6 is not very satisfactory. It would be nice if we could show better bounds in special cases. Anderson and Woll <ref> [2] </ref> show that their Union-Find data structure algorithms perform much better if the threads can choose a request randomly from a large pool of outstanding requests.
Reference: [3] <author> R. J. Anderson and H. Woll. </author> <title> Wait-free parallel algorithms for the union-find problem. </title> <booktitle> In Proceedings of the Twenty-Third Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 370-380, </pages> <address> New Orleans, LA, </address> <month> May </month> <year> 1991. </year>
Reference: [4] <author> G. Barnes. </author> <title> A method for implementing lock-free shared data structures. </title> <booktitle> In Proceedings of the 1993 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 261-270, </pages> <address> Velen, Germany, </address> <month> June </month> <year> 1993. </year>
Reference: [5] <author> R. Bayer and M. Schkolnick. </author> <title> Concurrency of operations on B-trees. </title> <journal> Acta Informatica, </journal> <volume> 9(1) </volume> <pages> 1-21, </pages> <year> 1977. </year>
Reference-contexts: Heaps are often used to implement priority queues. Many researchers have examined the problem of concurrent access to priority queue structures such as skew trees, B-trees, or 2-3 trees. Most existing algorithms use locks to control concurrent access to the structure <ref> [5, 8, 11, 13, 18, 22, 26] </ref>. Herlihy [15] provides the only previously known wait-free implementation of heaps.
Reference: [6] <author> B. N. Bershad. </author> <title> Mutual exclusion for multiprocessors. </title> <type> Technical Report CMU-CS-91-116, </type> <institution> Carnegie Mellon University, </institution> <year> 1991. </year>
Reference-contexts: For this algorithm to work correctly, it is necessary that threads be able to detect and complete an incomplete series of changes to the structure. Bershad describes a similar idea for implementing synchronization primitives on machines that do not support these primitives <ref> [6, 7] </ref>. This approach offers four advantages. First, we expect the algorithm to achieve better speedup than the copying algorithm.
Reference: [7] <author> B. N. Bershad. </author> <title> Practical considerations for lock-free concurrent objects. </title> <type> Technical Report CMU-CS-91-183, </type> <institution> Carnegie Mellon University, </institution> <year> 1991. </year>
Reference-contexts: For this algorithm to work correctly, it is necessary that threads be able to detect and complete an incomplete series of changes to the structure. Bershad describes a similar idea for implementing synchronization primitives on machines that do not support these primitives <ref> [6, 7] </ref>. This approach offers four advantages. First, we expect the algorithm to achieve better speedup than the copying algorithm.
Reference: [8] <author> J. Biswas and J. C. Browne. </author> <title> Simultaneous update of priority structures. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages 124-131, </pages> <year> 1987. </year>
Reference-contexts: Heaps are often used to implement priority queues. Many researchers have examined the problem of concurrent access to priority queue structures such as skew trees, B-trees, or 2-3 trees. Most existing algorithms use locks to control concurrent access to the structure <ref> [5, 8, 11, 13, 18, 22, 26] </ref>. Herlihy [15] provides the only previously known wait-free implementation of heaps.
Reference: [9] <author> R. Cole and O. Zajicek. </author> <title> The APRAM: Incorporating asynchrony into the PRAM model. </title> <booktitle> In Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 169-178, </pages> <address> Santa Fe, NM, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: key in the root must be less than all other keys in the tree. 2 Note that Lemma 5.3 would not be true if inserted keys were sifted up from the leaves. 6 Performance In recent years, researchers have proposed many different versions of the asynchronous PRAM, or APRAM (including <ref> [9, 10, 12, 25] </ref>), most with differing notions of run-time. We measure the performance of our algorithm using work, the same measure used in a series of papers on fault-tolerant PRAMs [20, 19, 23]. The work done by an algorithm is the total number of steps taken by all threads.
Reference: [10] <author> R. Cole and O. Zajicek. </author> <title> The expected advantage of asynchrony. </title> <booktitle> In Proceedings of the 1990 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 85-94, </pages> <address> Crete, Greece, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: key in the root must be less than all other keys in the tree. 2 Note that Lemma 5.3 would not be true if inserted keys were sifted up from the leaves. 6 Performance In recent years, researchers have proposed many different versions of the asynchronous PRAM, or APRAM (including <ref> [9, 10, 12, 25] </ref>), most with differing notions of run-time. We measure the performance of our algorithm using work, the same measure used in a series of papers on fault-tolerant PRAMs [20, 19, 23]. The work done by an algorithm is the total number of steps taken by all threads.
Reference: [11] <author> R. Ford and J. Calhoun. </author> <title> Concurrency control mechanisms and the se-rializability of concurrent tree algorithms. </title> <booktitle> In Proceedings of the Third Annual ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 51-60, </pages> <year> 1984. </year>
Reference-contexts: Heaps are often used to implement priority queues. Many researchers have examined the problem of concurrent access to priority queue structures such as skew trees, B-trees, or 2-3 trees. Most existing algorithms use locks to control concurrent access to the structure <ref> [5, 8, 11, 13, 18, 22, 26] </ref>. Herlihy [15] provides the only previously known wait-free implementation of heaps.
Reference: [12] <author> P. B. Gibbons. </author> <title> A more practical PRAM model. </title> <booktitle> In Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 158-168, </pages> <address> Santa Fe, NM, </address> <month> June </month> <year> 1989. </year> <month> 15 </month>
Reference-contexts: key in the root must be less than all other keys in the tree. 2 Note that Lemma 5.3 would not be true if inserted keys were sifted up from the leaves. 6 Performance In recent years, researchers have proposed many different versions of the asynchronous PRAM, or APRAM (including <ref> [9, 10, 12, 25] </ref>), most with differing notions of run-time. We measure the performance of our algorithm using work, the same measure used in a series of papers on fault-tolerant PRAMs [20, 19, 23]. The work done by an algorithm is the total number of steps taken by all threads.
Reference: [13] <author> L. J. Guibas and R. Sedgewick. </author> <title> A dichromatic framework for balanced trees. </title> <booktitle> In 19th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 8-21, </pages> <address> Ann Arbor, MI, </address> <month> Oct. </month> <year> 1978. </year> <note> IEEE. </note>
Reference-contexts: Heaps are often used to implement priority queues. Many researchers have examined the problem of concurrent access to priority queue structures such as skew trees, B-trees, or 2-3 trees. Most existing algorithms use locks to control concurrent access to the structure <ref> [5, 8, 11, 13, 18, 22, 26] </ref>. Herlihy [15] provides the only previously known wait-free implementation of heaps.
Reference: [14] <author> M. Herlihy. </author> <title> A methodology for implementing highly concurrent data objects. </title> <booktitle> In Proceedings of the Second Annual ACM SIGPLAN Symposium on Principles and Practices of Parallel Programming, </booktitle> <pages> pages 197-206, </pages> <month> Mar. </month> <year> 1990. </year>
Reference: [15] <author> M. Herlihy. </author> <title> A methodology for implementing highly concurrent data objects. </title> <type> Technical Report CRL 91/10, </type> <institution> DEC Cambridge Research Lab, </institution> <month> Oct. </month> <year> 1991. </year> <note> See also [14]. </note>
Reference-contexts: This paper presents a wait-free algorithm to manipulate heaps. The algorithm uses an approach significantly different from previous wait-free algorithms for concurrent objects. The only previously known wait-free algorithm to manipulate heaps arises from Herlihy's work on a methodology for implementing concurrent objects <ref> [15] </ref>. Herlihy's basic methodology requires a thread to check out a pointer to the object, make and change a copy of the object, and check the object back in. <p> Herlihy [16] unifies much of this work by showing the existence of universal primitives, such as Compare&Swap, which can be used to implement any wait-free object. Using Load Linked and Store Conditional, a universal pair of primitives similar to Compare&Swap, Herlihy <ref> [15] </ref> describes a methodology for converting synchronous implementations of data structure algorithms to non-blocking and wait-free implementations. Alemany and Felten [1] present techniques for improving the performance of Herlihy's protocol in practice. Anderson and Woll [2] use Compare&Swap to design efficient asynchronous algorithms for the Union-Find problem. <p> Heaps are often used to implement priority queues. Many researchers have examined the problem of concurrent access to priority queue structures such as skew trees, B-trees, or 2-3 trees. Most existing algorithms use locks to control concurrent access to the structure [5, 8, 11, 13, 18, 22, 26]. Herlihy <ref> [15] </ref> provides the only previously known wait-free implementation of heaps. <p> Still, assuming a finite number of operations are to be performed on the heap, this algorithm is wait-free. Given an unbounded number of operations, the algorithm as written is merely non-blocking, but an auxiliary scheduling scheme, such as the one described by Herlihy <ref> [15] </ref>, would solve this problem. It is not difficult to show that this process guarantees that no more than one preliminary phase will be executed at a time. The most important function in the algorithm is fix.
Reference: [16] <author> M. Herlihy. </author> <title> Wait-free synchronization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(1) </volume> <pages> 124-149, </pages> <year> 1991. </year>
Reference-contexts: A wait-free algorithm is a special case of a non-blocking algorithm that guarantees all threads will complete their work in a finite number of steps. Early work on wait-free objects focused on proving the power of various synchronization primitives. Herlihy <ref> [16] </ref> unifies much of this work by showing the existence of universal primitives, such as Compare&Swap, which can be used to implement any wait-free object.
Reference: [17] <author> M. Herlihy and J. Wing. </author> <title> Axioms for concurrent objects. </title> <booktitle> In Conference Record of the Fourteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 13-26, </pages> <address> Munich, West Germany, </address> <month> Jan. </month> <year> 1987. </year>
Reference-contexts: be able to detect if T 's suboperation is incomplete. 5.1 Serializability of Operations The standard notion of correctness in asynchronous parallel algorithms is to assume the atomic instructions of all threads are interleaved in some linear order; the algorithm is correct if it behaves properly for all such interleav-ings <ref> [17, 21] </ref>. In this context, proper behavior is defined by the results of the delete min operations; if the results of the delete min operations correspond to some serialization of the operations, the algorithm is correct.
Reference: [18] <author> D. W. Jones. </author> <title> Concurrent operations on priority queues. </title> <journal> Communications of the ACM, </journal> <volume> 32(1) </volume> <pages> 132-137, </pages> <month> Jan. </month> <year> 1989. </year>
Reference-contexts: Heaps are often used to implement priority queues. Many researchers have examined the problem of concurrent access to priority queue structures such as skew trees, B-trees, or 2-3 trees. Most existing algorithms use locks to control concurrent access to the structure <ref> [5, 8, 11, 13, 18, 22, 26] </ref>. Herlihy [15] provides the only previously known wait-free implementation of heaps.
Reference: [19] <author> P. C. Kanellakis and A. Shvartsman. </author> <title> Efficient parallel algorithms can be made robust. </title> <booktitle> In Proceedings of the Eighth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 211-222, </pages> <address> Edmonton, Al-berta, Canada, </address> <month> Aug. </month> <year> 1989. </year>
Reference-contexts: We measure the performance of our algorithm using work, the same measure used in a series of papers on fault-tolerant PRAMs <ref> [20, 19, 23] </ref>. The work done by an algorithm is the total number of steps taken by all threads. In the absence of other threads, every operation takes O (log n) work, where n is the maximum number of nodes in the tree.
Reference: [20] <author> Z. M. Kedem, K. V. Palem, and P. G. Spirakis. </author> <title> Efficient robust parallel computations. </title> <booktitle> In Proceedings of the Twenty-Second Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 138-148, </pages> <address> Baltimore, MD, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: We measure the performance of our algorithm using work, the same measure used in a series of papers on fault-tolerant PRAMs <ref> [20, 19, 23] </ref>. The work done by an algorithm is the total number of steps taken by all threads. In the absence of other threads, every operation takes O (log n) work, where n is the maximum number of nodes in the tree.
Reference: [21] <author> L. Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocessor programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9):690-691, </volume> <year> 1979. </year>
Reference-contexts: be able to detect if T 's suboperation is incomplete. 5.1 Serializability of Operations The standard notion of correctness in asynchronous parallel algorithms is to assume the atomic instructions of all threads are interleaved in some linear order; the algorithm is correct if it behaves properly for all such interleav-ings <ref> [17, 21] </ref>. In this context, proper behavior is defined by the results of the delete min operations; if the results of the delete min operations correspond to some serialization of the operations, the algorithm is correct.
Reference: [22] <author> P. L. Lehman and S. B. Yao. </author> <title> Efficient locking for concurrent operations on B-trees. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 6(3) </volume> <pages> 650-670, </pages> <month> Dec. </month> <year> 1981. </year>
Reference-contexts: Heaps are often used to implement priority queues. Many researchers have examined the problem of concurrent access to priority queue structures such as skew trees, B-trees, or 2-3 trees. Most existing algorithms use locks to control concurrent access to the structure <ref> [5, 8, 11, 13, 18, 22, 26] </ref>. Herlihy [15] provides the only previously known wait-free implementation of heaps.
Reference: [23] <author> C. Martel, R. Subramonian, and A. Park. </author> <title> Asynchronous PRAMs are (almost) as good as synchronous PRAMs. </title> <booktitle> In Proceedings 31st Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 590-599, </pages> <address> St. Louis, MO, </address> <month> Oct. </month> <year> 1990. </year> <note> IEEE. </note>
Reference-contexts: We measure the performance of our algorithm using work, the same measure used in a series of papers on fault-tolerant PRAMs <ref> [20, 19, 23] </ref>. The work done by an algorithm is the total number of steps taken by all threads. In the absence of other threads, every operation takes O (log n) work, where n is the maximum number of nodes in the tree.
Reference: [24] <institution> MIPS Computer Company. The MIPS RISC architecture. </institution>
Reference-contexts: Store Conditional returns a boolean value indicating whether the write succeeded or failed. Load Linked and Store Conditional can be efficiently implemented given a cache-coherent architecture, and are supported in the MIPS-II architecture <ref> [24] </ref>. The remainder of the paper is organized as follows. We begin with a discussion of the basic approach of the algorithm in Section 3. Section 4 presents a high-level sketch of the algorithm, and Section 5 provides a sketch of the proof of the correctness of the algorithm.
Reference: [25] <author> N. Nishimura. </author> <title> Asynchronous shared memory parallel computation. </title> <booktitle> In Proceedings of the 1990 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 76-84, </pages> <address> Crete, Greece, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: key in the root must be less than all other keys in the tree. 2 Note that Lemma 5.3 would not be true if inserted keys were sifted up from the leaves. 6 Performance In recent years, researchers have proposed many different versions of the asynchronous PRAM, or APRAM (including <ref> [9, 10, 12, 25] </ref>), most with differing notions of run-time. We measure the performance of our algorithm using work, the same measure used in a series of papers on fault-tolerant PRAMs [20, 19, 23]. The work done by an algorithm is the total number of steps taken by all threads.
Reference: [26] <author> Y. Sagiv. </author> <title> Concurrent operations on B-trees with overtaking. </title> <booktitle> In Proceedings of the Fourth Annual ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 28-37, </pages> <month> Jan. </month> <year> 1985. </year> <month> 17 </month>
Reference-contexts: Heaps are often used to implement priority queues. Many researchers have examined the problem of concurrent access to priority queue structures such as skew trees, B-trees, or 2-3 trees. Most existing algorithms use locks to control concurrent access to the structure <ref> [5, 8, 11, 13, 18, 22, 26] </ref>. Herlihy [15] provides the only previously known wait-free implementation of heaps.
References-found: 26

