URL: http://www.cs.cmu.edu/afs/cs/project/iwarp/archive/iWarp-papers/ieee-pdt-pcs-tools.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs/project/iwarp/archive/WWW-pages/comm-arch-papers.html
Root-URL: 
Email: shinrich@cs.cmu.edu  
Title: A Compile Time Model for Composing Parallel Programs  
Author: Susan Hinrichs 
Keyword: Parallel systems, communication architecture, parallel programming, connection-based communication, programming tools  
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: Many distributed memory machines support connection-based communication instead of or in addition to connection-less message passing. Connection-based communication can be more efficient than message passing because the resources are reserved once for the connection and multiple messages can be sent over the connection. While long-lived connections enable more efficient use of the communication system in some situations, managing connection resources adds another level of complexity to programming such machines. iWarp is an example of a distributed memory machine that supports long-lived connections. To aid the iWarp programmer and program generator tools, we developed a tool chain that enables the programmer to define connections and compose parallel programs. The communication tool chain has been in use for four years in various forms. In that time, we have found many benefits and a few pitfalls in our model. This paper describes the design of the programming model and tools and discusses our experiences with this implementation. 
Abstract-found: 1
Intro-found: 1
Reference: [ABT92] <author> J-M. Adamo, C. Bonello, and L. Trejo. </author> <title> The C NET Programming Environment: An Overview. </title> <booktitle> In Parallel Processing: CONPAR92-VAPPAV The Second Joint International Conference on Vector and Parallel Processing, </booktitle> <pages> pages 115-120, </pages> <address> Lyon, France, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: Transputer systems also incorporate the connection abstraction into their programming model via channels. Without additional routing switches the T800 systems do not support direct connections between nodes that are not physically adjacent. Channels can only connect adjacent processors, which simplifies allocating network resources. The C NET programming environment <ref> [ABT92] </ref> has been developed for the SuperNode architecture, a system of T800 processors and routing chips that enable reconfigurable connections between processors. The C NET environment employs abstractions for long-lived connection and communication phases.
Reference: [B + 88] <author> S. Borkar et al. </author> <title> iWarp: An Integrated Solution to High-Speed Parallel Computing. </title> <booktitle> In Proceedings of the Supercomputing Conference, </booktitle> <pages> pages 330-339, </pages> <year> 1988. </year>
Reference-contexts: On iWarp, the messages as routed in Figure 3 (b) are sent at 40 MB/s, but the messages as routed in Figure 3 (a) are only sent at 20 MB/s. 2.2 Connection implementation issues Connection implementation differs between different systems. The current PCS implementation was developed for iWarp <ref> [B + 88, B + 90] </ref>, so for an example of connection configuration issues, we describe iWarp's connection hardware support. iWarp supports connections with a limited number of communication queues. Data from different queues are multiplexed over the physical bus on a word by word basis.
Reference: [B + 90] <author> S. Borkar et al. </author> <title> Supporting Systolic and Memory Communication in iWarp. </title> <booktitle> In Proc. 17th Intl. Symposium on Computer Architecture, </booktitle> <pages> pages 70-81. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1990. </year> <note> A revised version has appeared as technical report CMU-CS-90-197. </note>
Reference-contexts: On iWarp, the messages as routed in Figure 3 (b) are sent at 40 MB/s, but the messages as routed in Figure 3 (a) are only sent at 20 MB/s. 2.2 Connection implementation issues Connection implementation differs between different systems. The current PCS implementation was developed for iWarp <ref> [B + 88, B + 90] </ref>, so for an example of connection configuration issues, we describe iWarp's connection hardware support. iWarp supports connections with a limited number of communication queues. Data from different queues are multiplexed over the physical bus on a word by word basis.
Reference: [BIK91] <author> J. E. Boillat, N. Iselin, and P. G. Kropf. MARC: </author> <title> A Tool for Automatic Configuration of Parallel Programs. </title> <booktitle> In Transputing '91, </booktitle> <pages> pages 311-329, </pages> <year> 1991. </year>
Reference-contexts: The C NET environment does not utilize the array module abstraction and does not allow array module composition. MARC <ref> [BIK91] </ref> is another tool developed for a network of T800's. MARC is more directed towards automatically mapping and routing a set of communicating sequential processes than supporting a programmer using the communication system directly. Newer transputer systems should provide greater opportunity for using long-lived connections [MTW93].
Reference: [Bra92] <author> T. Braunl. </author> <title> Transparent Massively Parallel Programming with Parallaxis. </title> <journal> International Journal of Mini and Microcomputers, </journal> <volume> 14(2) </volume> <pages> 82-87, </pages> <year> 1992. </year>
Reference-contexts: While PVM and Express support the idea of creating connections between processing elements, the required buffering eliminates the possibility of supporting low latency communication using these tools. The communication structures are embedded in the node program, so are not executed until run time. Fortran M [FC93] and Parallaxis <ref> [Bra92] </ref> are two examples of programming models that augment the base language to support communication pattern definitions. They can also be thought of as coordination languages except the communication definitions are language extensions not orthogonal additions.
Reference: [CG89] <author> N. Carriero and D. Gelernter. </author> <title> Linda in Context. </title> <journal> Communication of the ACM, </journal> <volume> 32(4) </volume> <pages> 444-58, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Thus, without sophisticated compile time analysis, the communication structures must be defined at run time contributing to the run time communication 15 Mod2 contains three submodules. overhead. PVM [Sun90], Express [FKB91], and Linda <ref> [CG89] </ref> are three widely used coordination languages. They have been ported to a wide variety of architectures and are quite general. This generality means that the systems must buffer messages and hide many of the features of the target communication system.
Reference: [DS87] <author> W. J. Dally and C. L. Seitz. </author> <title> Deadlock-Free Message Routing in Multiprocessor Interconnection Networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(5):547-553, </volume> <month> May </month> <year> 1987. </year>
Reference-contexts: To ensure resource availability at run time, the node must communicate via a deadlock free channel, which is potentially error prone and/or expensive. The short-lived connections used in message passing avoid this problem by using the deadlock avoidance techniques described in <ref> [DS87] </ref>. 4 tions. The dashed lines show attempted connections. 2.3 PCS view of communication Long-live connections can be defined at run time, but safely opening long-lived connections at run time without pre-computed information can be a tricky operation.
Reference: [FC93] <author> I. T. Foster and K. M. Chandy. </author> <title> Fortran M: A Language for Modular Parallel Programming. </title> <type> Technical Report ANL, </type> <institution> Argonne National Laboratory, </institution> <year> 1993. </year>
Reference-contexts: While PVM and Express support the idea of creating connections between processing elements, the required buffering eliminates the possibility of supporting low latency communication using these tools. The communication structures are embedded in the node program, so are not executed until run time. Fortran M <ref> [FC93] </ref> and Parallaxis [Bra92] are two examples of programming models that augment the base language to support communication pattern definitions. They can also be thought of as coordination languages except the communication definitions are language extensions not orthogonal additions.
Reference: [FKB91] <author> J. Flower, A. Kolawa, and S. Bharadwaj. </author> <title> The Express Way to Distributed Processing. </title> <booktitle> Supercomputing Review, </booktitle> <pages> pages 54-55, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Most implementations of these coordination languages embed the definition of the communication structure in the run time node program. Thus, without sophisticated compile time analysis, the communication structures must be defined at run time contributing to the run time communication 15 Mod2 contains three submodules. overhead. PVM [Sun90], Express <ref> [FKB91] </ref>, and Linda [CG89] are three widely used coordination languages. They have been ported to a wide variety of architectures and are quite general. This generality means that the systems must buffer messages and hide many of the features of the target communication system.
Reference: [Hin93] <author> S. Hinrichs. </author> <title> Programmed Communcation Service Tool Chain User's Guide, </title> <month> March </month> <year> 1993. </year> <month> 18 </month>
Reference-contexts: C and PCS are also directly used by system programmers for explicitly programming communication. Starting in 1992, Intel included the PCS tool 12 chain in its iWarp software distribution [Int92]. The Carnegie Mellon version of PCS has continued to evolve as we gain additional experience with iWarp <ref> [Hin93] </ref>. The network abstraction for long-lived connections has been very useful. For regular communication patterns, it is natural for the node program to be aware of the topology of the program. For instance, many hypercube algorithms make explicit use of the hypercube topology.
Reference: [Int92] <author> Intel. </author> <title> iWarp Programmer's Guide, </title> <month> August </month> <year> 1992. </year>
Reference-contexts: C and PCS are also directly used by system programmers for explicitly programming communication. Starting in 1992, Intel included the PCS tool 12 chain in its iWarp software distribution <ref> [Int92] </ref>. The Carnegie Mellon version of PCS has continued to evolve as we gain additional experience with iWarp [Hin93]. The network abstraction for long-lived connections has been very useful. For regular communication patterns, it is natural for the node program to be aware of the topology of the program.
Reference: [MKS89] <author> O. Menzilcioglu, H.T. Kung, and S. W. Song. </author> <title> Comprehensive Evaluation of a Two-Dimensional Configurable Array. </title> <booktitle> In Proceedings of the Nineteenth International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 93-100, </pages> <year> 1989. </year>
Reference-contexts: The current implementation does simple row then column routing for unspecified routes. The programmer can also leave both node placement and network routing unspecificed. In this case, the system uses an automatic placement and routing algorithm defined in <ref> [MKS89] </ref>. This search algorithm tries to optimize the use of the limited number of communication hardware resources.
Reference: [MPS93] <author> W. Moore, M. Pandit, and W. Shubert. </author> <title> Tau Software Virtual Crossbar Facility. Intel Supercomputer Systems Division, </title> <month> January </month> <year> 1993. </year> <note> Research report. </note>
Reference-contexts: Similarly, Figure 2 compares the performance of message passing and connections between two Paragon nodes. In addition to the NX message passing library [PR94], Paragon has support for connections through the Virtual Connection Facility (VCF), a library that implements connections over the packet-based communication hardware <ref> [MPS93] </ref>. Due to the lower latency of connection-based communication, the VCF implementation out performs the NX implementation, but as the message size increases both implementations approach the same performance limits. Long-lived connections are not dynamically opened and closed, so deadlock avoidance is not an issue.
Reference: [MTW93] <author> M.D. May, P. W. Thompson, and P. H. Welch, </author> <title> editors. Networks, Routers, and Transputers: Function, Performance, and Application. </title> <publisher> IOS Press, Inc., </publisher> <address> Amsterdam, Netherlands, </address> <year> 1993. </year>
Reference-contexts: MARC [BIK91] is another tool developed for a network of T800's. MARC is more directed towards automatically mapping and routing a set of communicating sequential processes than supporting a programmer using the communication system directly. Newer transputer systems should provide greater opportunity for using long-lived connections <ref> [MTW93] </ref>. The T9000 processor provides virtual channel support, so multiple virtual channels can be mapped to the same physical channel. Therefore, multiple long-lived virtual channels can coexist.
Reference: [O'H91] <author> D. R. O'Hallaron. </author> <title> The Assign Parallel Program Generator. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computer Conference, </booktitle> <year> 1991. </year>
Reference-contexts: C and PCS have been used to implement several parallel program generators developed at Carnegie Mellon including Adapt [Web92], Assign <ref> [O'H91] </ref>, and Fx [SSOG93]. C and PCS are also directly used by system programmers for explicitly programming communication. Starting in 1992, Intel included the PCS tool 12 chain in its iWarp software distribution [Int92].
Reference: [PR94] <author> P. Pierce and G. Regnier. </author> <title> The Paragon Implementation of the NX Message Passing Interface. </title> <booktitle> In Scalable High-Performance Computing Conference, </booktitle> <pages> pages 184-190, </pages> <address> Knoxville, TN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Section 5 describes other communication systems and how they relate to PCS. In Section 6, we present our conclusions. 2 Communication models Most distributed memory systems support a message passing package that performs general communication, such as the PVM [Sun90] and NX <ref> [PR94] </ref> libraries. In this model, all nodes appear to be equally connected from the programmer's point of view. Therefore, the target machine's topology is hidden from the programmer. In addition to the message passing model, many distributed memory machines can support the connection-based communication model. <p> Since communication patterns are generally repeated, this resource reservation performance improvement is applicable to many programs. Similarly, Figure 2 compares the performance of message passing and connections between two Paragon nodes. In addition to the NX message passing library <ref> [PR94] </ref>, Paragon has support for connections through the Virtual Connection Facility (VCF), a library that implements connections over the packet-based communication hardware [MPS93].
Reference: [SQH92] <author> B. Seevers, M. J. Quinn, and P. J. Hatcher. </author> <title> A Parallel Programming Environment Supporting Multiple Data-Parallel Modules. </title> <booktitle> In Workshop on Languages, Compilers, and Run-Time Environments for Distributed Memory Machines, </booktitle> <pages> pages 44-47, </pages> <address> Boulder, CO, </address> <month> October </month> <year> 1992. </year> <journal> SIGPLAN Notices 28(1), </journal> <month> Jan 93. </month>
Reference-contexts: The T9000 processor provides virtual channel support, so multiple virtual channels can be mapped to the same physical channel. Therefore, multiple long-lived virtual channels can coexist. The C104 routing chip supports connections between processors that are not necessarily physically adjacent. <ref> [SQH92] </ref> describes a tool to create connections between Data Parallel C modules. This is similar to the PCS support for external ports and hierarchically nesting array modules.
Reference: [SSOG93] <author> J. Subhlok, J. M. Stichnoth, D. R. O'Hallaron, and T. Gross. </author> <title> Exploiting Task and Data Parallelism on a Multicomputer. </title> <booktitle> In Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 13-22, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: C and PCS have been used to implement several parallel program generators developed at Carnegie Mellon including Adapt [Web92], Assign [O'H91], and Fx <ref> [SSOG93] </ref>. C and PCS are also directly used by system programmers for explicitly programming communication. Starting in 1992, Intel included the PCS tool 12 chain in its iWarp software distribution [Int92]. The Carnegie Mellon version of PCS has continued to evolve as we gain additional experience with iWarp [Hin93]. <p> In some cases, it would be useful to run a series of array modules. For instance, the current implementation of tasking in the Fx parallel compiler uses array modules to represent tasks <ref> [SSOG93] </ref>. However, to support a general tasking scheme, array modules must be more dynamic. For instance, consider the task graph shown in Figure 15. To execute tasks 2 and 3 concurrently, the array is split into two groups.
Reference: [Sun90] <author> V. S. Sunderam. </author> <title> PVM: a Framework for Parallel Distributed Computing. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(4) </volume> <pages> 315-39, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Section 5 describes other communication systems and how they relate to PCS. In Section 6, we present our conclusions. 2 Communication models Most distributed memory systems support a message passing package that performs general communication, such as the PVM <ref> [Sun90] </ref> and NX [PR94] libraries. In this model, all nodes appear to be equally connected from the programmer's point of view. Therefore, the target machine's topology is hidden from the programmer. In addition to the message passing model, many distributed memory machines can support the connection-based communication model. <p> Most implementations of these coordination languages embed the definition of the communication structure in the run time node program. Thus, without sophisticated compile time analysis, the communication structures must be defined at run time contributing to the run time communication 15 Mod2 contains three submodules. overhead. PVM <ref> [Sun90] </ref>, Express [FKB91], and Linda [CG89] are three widely used coordination languages. They have been ported to a wide variety of architectures and are quite general. This generality means that the systems must buffer messages and hide many of the features of the target communication system.
Reference: [Web92] <author> J. A. Webb. </author> <title> Steps Toward Architecture-Independent Image Processing. </title> <journal> Computer, </journal> <volume> 25(2) </volume> <pages> 21-31, </pages> <month> February </month> <year> 1992. </year> <month> 19 </month>
Reference-contexts: C and PCS have been used to implement several parallel program generators developed at Carnegie Mellon including Adapt <ref> [Web92] </ref>, Assign [O'H91], and Fx [SSOG93]. C and PCS are also directly used by system programmers for explicitly programming communication. Starting in 1992, Intel included the PCS tool 12 chain in its iWarp software distribution [Int92].
References-found: 20

