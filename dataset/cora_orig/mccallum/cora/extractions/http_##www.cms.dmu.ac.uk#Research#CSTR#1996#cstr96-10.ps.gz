URL: http://www.cms.dmu.ac.uk/Research/CSTR/1996/cstr96-10.ps.gz
Refering-URL: http://www.cms.dmu.ac.uk/Research/CSTR/1996/
Root-URL: 
Email: jde@tomedii.demon.co.uk cph@dmu.ac.uk  
Title: MaPS: Movement and Planning Support for Navigation in an Immersive VRML Browser than being hard-coded
Author: John Edwards and Chris Hand 
Keyword: VRML2; immersive browser; first-class user interface; navigation techniques; user interface metaphors.  
Note: Rather  are considered.  
Address: LE1 9BH  
Affiliation: Department of Computer Science De Montfort University The Gateway, Leicester, UK  
Abstract: This paper describes the design and implementation of the user interface for a prototype immersive VRML2 browser, with particular reference to the planning and viewpoint movement aspects of navigation in the virtual environment. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Boff, K.R. and Lincoln, </author> <title> J.E. Engineering Data Compendium: Human Perception and Performance. </title> <institution> Wright-Patterson AFB, Ohio, USA, </institution> <year> 1988. </year>
Reference-contexts: Every time a "clock pulse" is received, the sliders output (out) is modified according to values at the Boolean directional inputs ( inc, dec). The Slider is, of course, reusable in any situation requiring potentiometerstyle control. 5.6 User representation The two-point theorem <ref> [1] </ref> states that the map reader should be able to match two points on the map with two points in the environment. This task is simplified if the user is given some indication of their position in the environment on the map view. <p> The scale and perspective of the map view may be altered by adjusting the height of the TextureCamera above the user and its field of view (possibly via a Slider node). Map view (View-aligned). This map view utilises the forward-up equivalence principle <ref> [1] </ref> to ensure that the upward direction on the map shows what is in front of the user. (The North-aligned and View-aligned map views were the main focus of our initial evaluations.) Rearmounted Camera. In this example, the TextureCamera is positioned above and behind the user.
Reference: [2] <author> Brooks, F. P. </author> <title> Grasping Reality Through Illusion Interactive Graphics Serving Science. </title> <booktitle> Proceedings of CHI88, </booktitle> <month> May </month> <year> 1988. </year> <month> pp1-11. </month>
Reference-contexts: Projects such as MITs 3-Draw [12], have demonstrated the efffectiveness of instrumenting familiar tools (such as a clipboard and stylus) with a 6-DOF tracking device, allowing direct input 2 techniques to be used. Navigation techniques have also used this approach: Brooks shopping cart metaphor <ref> [2] </ref>, the Delft Scooter [14] and Slaters virtual treadmill [13] all provided inherent (and in some cases active) kinaesthetic feedback.
Reference: [3] <author> Darken, R. and Sibert, J. </author> <title> A Toolset for Navigation in Virtual Environments. </title> <booktitle> ACM User Interface Software and Technology, </booktitle> <year> 1993, </year> <month> pp157-165. </month>
Reference-contexts: This may add meaning to the environment, or just make places easier to find in the future. The markers are similar to simple landmarks, with the important difference that true landmarks are created by the designer of the environment, whereas trail marks are created by users. Darken and Sibert <ref> [3] </ref> describe the use of elevated (for visibility) coloured cubes as visual markers, or virtual breadcrumbs, which may be dropped by the user as a means of assisting navigation. The mechanism was 4 provided for trail making and a facility existed for dropping breadcrumbs automatically at a preset frequency. <p> ability to rapidly obtain survey knowledge makes maps an invaluable tool for navigation in a real environment and this is also the case in a virtual environment; as might be expected, the subjects whom Darken and Sibert provided with a map showed significant improvements in navigational ability over those without <ref> [3] </ref>. The design of maps for virtual environments can draw on real world map design principles [6]: 1. Two-point theorem : it must be possible for the user to relate two points on the map with two points in the environment. 2. <p> The principles are actually easier to achieve with a virtual environment, as the map alignment and an indication of current position can be generated dynamically. The alignment principle can be modified to suit specific navigational tasks. Empirical evaluations <ref> [3] </ref> demonstrate that a view-aligned map (the map turned with the view) is more effective for exploration, whereas a terrain-aligned view (the map remained stationary) maintains a more consistent cognitive map of the overall environment. There is no reason why this should not be switchable depending on the search task.
Reference: [4] <author> Gale, N., Golledge, R., Pellegrino, J.W. and Doherty, S. </author> <title> The Acquisition and Integration of Route Knowledge in an Unfamiliar Neighbourhood, </title> <journal> Journal of Environmental Psychology, </journal> <volume> 10, </volume> <year> (1990), </year> <month> pp3-25. </month>
Reference-contexts: Sections 4.1 and 4.2 examine these two aspects of navigation while section 5 describes the practical implementation of these ideas. 4.1 Movement A fundamental requirement for navigation in a virtual environment is a facility to manipulate the effective viewpoint, that is, to move. Gale et al <ref> [4] </ref> note that the acquisition of spatial knowledge, essential for wayfinding, is primarily based on direct environmental experience which is usually gained via movement. In considering the many metaphors for viewpoint manipulation, it is possible to make a further classification based on the effective frame of reference.
Reference: [5] <author> Hinckley, K., Pausch, R., Goble, J. C. and Kassell, N. F. </author> <title> Passive Real-World Interface Props for Neurosurgical Visualization. </title> <booktitle> Proceedings of CHI94, </booktitle> <month> April </month> <year> 1994. </year> <month> pp452-458. </month>
Reference-contexts: Navigation techniques have also used this approach: Brooks shopping cart metaphor [2], the Delft Scooter [14] and Slaters virtual treadmill [13] all provided inherent (and in some cases active) kinaesthetic feedback. However, while instrumented props <ref> [5] </ref> are useful for specific tasks, there is also a requirement for more general purpose techniques (and, in the case of VRML browsers, for using more widely-available 3D devices).
Reference: [6] <author> Levine, M., Jankovic, I. N. and Palij, M. </author> <title> Principles of Spatial Problem Solving. </title> <journal> Journal of Experimental Psychology: </journal> <volume> General , 111(2): </volume> <pages> 157-175. </pages> <year> (1982) </year>
Reference-contexts: The design of maps for virtual environments can draw on real world map design principles <ref> [6] </ref>: 1. Two-point theorem : it must be possible for the user to relate two points on the map with two points in the environment. 2. Alignment principle: the map should be aligned with the terrain. 3.
Reference: [7] <author> Lynch, K. </author> <title> The Image of the City . Cambridge: </title> <publisher> MIT Press, </publisher> <year> 1960. </year>
Reference-contexts: Survey Knowledge (or map knowledge) on the other hand enables efficient planning of journeys not previously encountered, and is based on an exocentric reference frame. Survey knowledge has been shown to be essential for effective wayfinding <ref> [7] </ref>, and although it can be derived from extensive route knowledge, it is available directly from a map.
Reference: [8] <author> Mackinlay, J. D., Card, S. K., and Robertson, G. </author> <title> Rapid Controlled Movement through a Virtual 3D Workspace, </title> <booktitle> Computer Graphics 24(4), </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: Such isolation would not be possible if objects were required to accumulate transformations from the Navigator via composition. The simpler types of navigation, for example walking and flying, represent a relatively straightforward remapping of the inputs from the V-Flexor and HMD. Point-of-interest navigation <ref> [8] </ref> and hyperlinking involve rather more complex algorithms. Techniques for enacting the following of hyperlinks have been investigated but not yet implemented (this functionality would probably be incorporated as part of the Navigator node).
Reference: [9] <author> Mandeville, J., Davidson, J., Campbell, D., Dahl, A., Schwartz, P. and Furness, T. </author> <title> A Shared Virtual Environment for Architectural Design Review. Proceedings of Collaborative Virtual Environments 96, </title> <institution> University of Nottingham, UK, </institution> <month> 19-20 September </month> <year> 1996. </year>
Reference-contexts: The WIM technique has also been used in a collaborative, immersive VRML-based system implemented by HITL during phase II of their Greenspace project <ref> [9] </ref>, albeit using a predefined model rather than a dynamically updated representation. 3.
Reference: [10] <author> Murta, A. </author> <title> Vertical Axis Awareness in 3D Environments. Proceedings of the Framework for Immersive Virtual Environments '95 , London, </title> <address> UK, </address> <month> 18-19 December </month> <year> 1995, </year> <month> pp.169-176 </month>
Reference-contexts: The user was therefore able to move their head and hand independently of the direction of travel. This configuration takes advantage of the natural constraints afforded by the cyberspace metaphor [18], particularly its ability to orient the user in relation to the vertical axis. Murta maintains <ref> [10] </ref> that users perceptions of the vertical axis are critical to their ability to make sense of a virtual environment. The Navigator node is essentially a tool for generating geometric transformations and aims to centralise all of the movement functionality required by the interface on a single node. <p> In this example, the TextureCamera is positioned above and behind the user. The view is aligned with the positive vertical axis, as one would normally expect from a camera view. This choice of view alignment is likely to contribute to vertical axis awareness <ref> [10] </ref> and should help the user to make sense of the view. Targeting Satellite Camera. This camera may be moved relative to the users position using the functionality provided by the Navigator node. Wherever it is, it will always point at the user, with an up-aligned view.
Reference: [11] <author> Riva, G., Bolzoni, M. and Melis, L. </author> <title> Effects of Immersive Virtual Reality on Body Representations. </title> <booktitle> Proceedings of the 3rd UK VR-SIG Conference, </booktitle> <institution> De Montfort University, Leicester, </institution> <note> 3rd July 1996. pp121-132. </note>
Reference-contexts: Among other things, the users own avatar may be examined in this mirror. The capacity for self-examination may assist in the processing of establishing the users presence in the environment, or may be useful in the growing area of research into the visualisation of body image in VEs (e.g. <ref> [11] </ref>). Magnifying Glass. Almost identical to the handheld Mirror, but without the rotational offset, this virtual device mirrors the operation of a real world magnifying glass, except that by giving the user control of the field of view (via the Slider) the device also becomes zoomable.
Reference: [12] <author> Sachs, E., Roberts, A. and Stoops, D. 3-Draw: </author> <title> A Tool for Designing 3-D Shapes. </title> <journal> IEEE Computer Graphics and Applications, </journal> <month> November </month> <year> 1991, </year> <month> pp18-26. </month>
Reference-contexts: Projects such as MITs 3-Draw <ref> [12] </ref>, have demonstrated the efffectiveness of instrumenting familiar tools (such as a clipboard and stylus) with a 6-DOF tracking device, allowing direct input 2 techniques to be used.
Reference: [13] <author> Slater, M., Steed, A. and Usoh, M. </author> <title> The Virtual Treadmill: A Naturalistic Metaphor for Navigation in Immersive Virtual Environments. </title> <booktitle> Proceedings of the Eurographics Workshop on Virtual Reality , Barcelona, </booktitle> <month> Sept </month> <year> 1993. </year> <month> pp71-83. </month>
Reference-contexts: Navigation techniques have also used this approach: Brooks shopping cart metaphor [2], the Delft Scooter [14] and Slaters virtual treadmill <ref> [13] </ref> all provided inherent (and in some cases active) kinaesthetic feedback. However, while instrumented props [5] are useful for specific tasks, there is also a requirement for more general purpose techniques (and, in the case of VRML browsers, for using more widely-available 3D devices).
Reference: [14] <author> Smets, G. J. F., Stappers, P. J., Overbeeke, K. J. and van der Mast, C. </author> <title> Designing in Virtual Reality: </title> <editor> Perception-Action Coupling and Affordances. In K. Carr and R. England ( Eds), </editor> <title> Simulated and Virtual Realities: Elements of Perception , Taylor & Francis, </title> <year> 1995. </year> <month> pp189-208. </month>
Reference-contexts: Projects such as MITs 3-Draw [12], have demonstrated the efffectiveness of instrumenting familiar tools (such as a clipboard and stylus) with a 6-DOF tracking device, allowing direct input 2 techniques to be used. Navigation techniques have also used this approach: Brooks shopping cart metaphor [2], the Delft Scooter <ref> [14] </ref> and Slaters virtual treadmill [13] all provided inherent (and in some cases active) kinaesthetic feedback. However, while instrumented props [5] are useful for specific tasks, there is also a requirement for more general purpose techniques (and, in the case of VRML browsers, for using more widely-available 3D devices).
Reference: [15] <author> Steele, H. Re: </author> <title> Dynamic Routes in VRML 2 Message posted to VRML mailing list, </title> <note> 6 th August 1996. &lt;URL: http://vag.vrml.org/www-vrml/archives/vrml.9608.gz&gt; </note>
Reference-contexts: However the VRML2 specification, in conjunction with dynamic routing capabilities such as those of the Carmel 2 graphics kernel <ref> [15] </ref> used in our implementation, makes it possible to instantiate the interface components as first-class world objects both in terms of visibility (they could be rendered as part of the normal scene graph) and connectability (they could be connected directly to objects in the environment using ROUTEs).
Reference: [16] <author> Stoakley, R., Conway, M.J., and Pausch, R. </author> <title> Virtual Reality on a WIM: </title> <booktitle> Interactive worlds in miniature. Proceedings of CHI 95, </booktitle> <month> March </month> <year> 1995. </year>
Reference-contexts: The Virtual Tricorder was the initial inspiration for the immersive VRML navigation control described below. Another approach which is related to the work described here is the world in miniature (WIM) metaphor <ref> [16] </ref>, an extension of the world-in-hand technique [18] which provides the user with a handheld miniature version of the virtual world. The WIM technique as described by Stoakley et al allowed for both navigation and object manipulation, although controlling the scale of the WIM model was an issue.
Reference: [17] <author> Ware, C. </author> <title> Using Hand Position for Virtual Object Placement. </title> <booktitle> The Visual Computer 6 </booktitle> <pages> 245-253, </pages> <year> 1990. </year> <month> 10 </month>
Reference-contexts: within the virtual world. 2.1 Related Work Designers of 3D interfaces have recognised for some time that creating a one-to-one mapping between a 6-DOF input device and its representation in the VE has direct benefits in terms of improved spatial understanding during object manipulation, due to the natural kinaesthetic correspondence <ref> [17] </ref> between hand position and the manipulated object or tool. Projects such as MITs 3-Draw [12], have demonstrated the efffectiveness of instrumenting familiar tools (such as a clipboard and stylus) with a 6-DOF tracking device, allowing direct input 2 techniques to be used.
Reference: [18] <author> Ware, C. and Osborne, S. </author> <year> (1990). </year> <title> Exploration and Virtual Camera Control in Virtual Three Dimensional Environments. </title> <booktitle> Proceedings of the 1990 Symposium on Interactive 3D Graphics (Snowbird, </booktitle> <address> Utah, </address> <month> March </month> <year> 1990). </year> <booktitle> In Computer Graphics 24(2): </booktitle> <pages> 175-183. </pages>
Reference-contexts: The Virtual Tricorder was the initial inspiration for the immersive VRML navigation control described below. Another approach which is related to the work described here is the world in miniature (WIM) metaphor [16], an extension of the world-in-hand technique <ref> [18] </ref> which provides the user with a handheld miniature version of the virtual world. The WIM technique as described by Stoakley et al allowed for both navigation and object manipulation, although controlling the scale of the WIM model was an issue. <p> In general, navigation through an environment is associated with an egocentric viewpoint. Examples of egocentric movement include the eyeball-in-hand and flying vehicle metaphors <ref> [18] </ref>. Movement metaphors may also be classified depending on what we might call natural movement as opposed to vehicle movement. Natural movement is often characterised by a one-to-one mapping between movement of the input device and its manifestation in the virtual environment. <p> The user was therefore able to move their head and hand independently of the direction of travel. This configuration takes advantage of the natural constraints afforded by the cyberspace metaphor <ref> [18] </ref>, particularly its ability to orient the user in relation to the vertical axis. Murta maintains [10] that users perceptions of the vertical axis are critical to their ability to make sense of a virtual environment.
Reference: [19] <author> Wloka, M.M. and Greenfield, E. </author> <title> The Virtual Tricorder. </title> <type> Technical Report CS-95-05, </type> <institution> Department of Computer Science, Brown University, </institution> <address> Providence RI, USA, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: However, while instrumented props [5] are useful for specific tasks, there is also a requirement for more general purpose techniques (and, in the case of VRML browsers, for using more widely-available 3D devices). The solution proposed by Wloka and Greenfield, known as the Virtual Tricorder <ref> [19] </ref>, uses the metaphor of a reconfigurable tool and again adopts a direct mapping between input device and its virtual representation. <p> This technique replicates the functionality of the Virtual Tricorders magic lens <ref> [19] </ref>. 6. INITIAL EVALUATION A small number of initial user trials were run to compare the North-aligned and View-aligned map tools. The scenario used for testing was a simple mazerunning task using a small maze comprised of cubes, cones and cylinders each of which could appear at two different heights.
References-found: 19

