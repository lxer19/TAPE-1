URL: ftp://ftp.cs.dartmouth.edu/pub/kotz/papers/kotz:dapple.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/~dfk/papers/kotz:dapple.html
Root-URL: http://www.cs.dartmouth.edu
Email: dfk@cs.dartmouth.edu  
Title: A DATA-PARALLEL PROGRAMMING LIBRARY FOR EDUCATION (DAPPLE)  
Author: David Kotz 
Address: Hanover, NH 03755-3510  
Affiliation: Department of Computer Science Dartmouth College  
Web: URL ftp://ftp.cs.dartmouth.edu/pub/CS-papers/Kotz/kotz:dapple.ps.Z.  
Note: Appeared in SIGCSE '95, pages 76-81. Available at  Copyright 1995 by the Association for Computing Machinery, Inc. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that new copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abtracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Publications Dept., ACM Inc., fax +1(212)869-0481, or &lt;permissions@acm.org&gt;.  
Abstract: In the context of our overall goal to bring the concepts of parallel computing into the undergraduate curriculum, we set out to find a parallel-programming language for student use. To make it accessible to students at all levels, and to be independent of any particular hardware platform, we chose to design our own language, based on a data-parallel model and on C++. The result, DAPPLE, is a C++ class library designed to provide the illusion of a data-parallel programming language on conventional hardware and with conventional compilers. DAPPLE defines Vectors and Matrices as basic classes, with all the usual C++ operators overloaded to provide elementwise arithmetic. In addition, DAPPLE provides typical data-parallel operations like scans, permutations, and reductions. Finally, DAPPLE provides a parallel if-then-else statement to restrict the scope of the above operations to partial vectors or matrices. 
Abstract-found: 1
Intro-found: 1
Reference: [BBG + 93] <author> Francois Bodin, Peter Beckman, Denis Gannon, Srinivas Narayana, and Shelby X. Yang. </author> <title> Distributed pC++: basic ideas for an object parallel language. </title> <journal> Scientific Programming, </journal> <volume> 2(3), </volume> <month> Fall </month> <year> 1993. </year>
Reference-contexts: We found many research projects designing parallel C++ variants. C** [LRV92] is perhaps the closest candidate, in that it supports a data-parallel model, but it requires a new compiler and is not yet available. pC++ <ref> [BBG + 93] </ref> can also provide a data-parallel model, using only a preprocessor and library, but its syntax is a little complicated for beginners. Other data-parallel options like Presto++ [Kil92] and Compositional C++ [CK92] are also rather complex for beginners.
Reference: [Ble93] <author> Guy E. Blelloch. NESL: </author> <title> a nested data-parallel language. </title> <type> Technical Report CMU-CS-93-129, </type> <institution> Carnegie Mellon University, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: Although many data-parallel languages exist, including C*, Fortran90, NESL <ref> [Ble93] </ref>, and HPF [Lov93], they are difficult to use, are not similar to C++, or are not easily portable to student computers. We found many research projects designing parallel C++ variants. <p> It restricts the context to the left partition and recurses, and then restricts the context to the right partition and recurses. The quicksort example demonstrates one weakness of DAPPLE, its inability to support nested data parallelism <ref> [Ble93] </ref>. The two recursive calls to quicksort () must be done sequentially, each with only a small subset of the virtual processors active. Given this model, other sorting algorithms would be more appropriate.
Reference: [CGH94] <author> Rohit Chandra, Anoop Gupta, and John L. Hen-nessey. </author> <title> COOL: an object-based language for parallel programming. </title> <journal> IEEE Computer, </journal> <volume> 27(8) </volume> <pages> 14-26, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Other data-parallel options like Presto++ [Kil92] and Compositional C++ [CK92] are also rather complex for beginners. Others, like Mentat [Gri93], CHARM++ [KK93], and COOL <ref> [CGH94] </ref>, are more task-parallel than data-parallel. Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++. The result is DAPPLE, a DAta-Parallel Programming Library for Education.
Reference: [CK92] <author> K. Mani Chandy and Carl Kesselman. </author> <title> Compositional C++: Compositional parallel programming. </title> <type> Technical Report CS-TR-92-13, </type> <institution> Califor-nia Institute of Technology, </institution> <year> 1992. </year>
Reference-contexts: Other data-parallel options like Presto++ [Kil92] and Compositional C++ <ref> [CK92] </ref> are also rather complex for beginners. Others, like Mentat [Gri93], CHARM++ [KK93], and COOL [CGH94], are more task-parallel than data-parallel. Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++.
Reference: [ES90] <author> Margaret A. Ellis and Bjarne Stroustrup. </author> <title> The Annotated C++ Reference Manual. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year> <title> Ninth printing. </title>
Reference-contexts: The functional style makes it easier to compose operations, e.g., B = shift (B,1) + B + shift (B,-1), than if shift () modified B. Recommended by the ARM <ref> [ES90, page 249] </ref>, the functional syntax shift (B,1) makes it clear that the operand B is not modified, while in B.shift (1) it is not as clear.
Reference: [Gri93] <author> Andrew S. Grimshaw. </author> <title> Easy-to-use object-oriented parallel processing with Mentat. </title> <journal> IEEE Computer, </journal> <volume> 26(5) </volume> <pages> 39-51, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Other data-parallel options like Presto++ [Kil92] and Compositional C++ [CK92] are also rather complex for beginners. Others, like Mentat <ref> [Gri93] </ref>, CHARM++ [KK93], and COOL [CGH94], are more task-parallel than data-parallel. Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++. The result is DAPPLE, a DAta-Parallel Programming Library for Education.
Reference: [JKM94] <author> Donald Johnson, David Kotz, and Fillia Make-don. </author> <title> Teaching parallel computing to freshmen. </title> <booktitle> In Conference on Parallel Computing for Undergraduates. </booktitle> <address> Colgate University, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: We believe parallelism should be introduced early in the curriculum, before the habits of sequential thinking are ingrained. Indeed, we are preparing to teach it to freshmen in CS2 <ref> [JKM94] </ref>. <p> Exploring this issue would be a valuable lesson for students. 4 SUMMARY AND STATUS The DAPPLE extensions to C++ are summarized in Table 1. We are fine-tuning the language and implementation for use in a parallel-computing course later this year <ref> [JKM94] </ref>. DAPPLE should be useful beyond that course, however, in other courses and in other institutions. DAPPLE currently runs on DECstation 5000 workstations with Ultrix and the g++ compiler, and we are porting it to other Unix workstations (Sun, SGI, and DEC Alpha) and to the Macintosh (using Symantec C++).
Reference: [Kil92] <author> Michael F. Kilian. </author> <title> Parallel Sets: An Object-oriented Methodology for Massively Parallel Programming. </title> <type> PhD thesis, </type> <institution> Harvard University, </institution> <year> 1992. </year>
Reference-contexts: Other data-parallel options like Presto++ <ref> [Kil92] </ref> and Compositional C++ [CK92] are also rather complex for beginners. Others, like Mentat [Gri93], CHARM++ [KK93], and COOL [CGH94], are more task-parallel than data-parallel. Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++.
Reference: [KK93] <author> L.V. Kale and Sanjeev Krishnan. CHARM++: </author> <title> A portable concurrent object oriented system based on C++. </title> <booktitle> In Proceedings of the Conference on Object Oriented Programming Systems, Languages and Applications, </booktitle> <year> 1993. </year>
Reference-contexts: Other data-parallel options like Presto++ [Kil92] and Compositional C++ [CK92] are also rather complex for beginners. Others, like Mentat [Gri93], CHARM++ <ref> [KK93] </ref>, and COOL [CGH94], are more task-parallel than data-parallel. Finding no suitable existing language, we decided to design and implement our own language as a set of macros and classes that extended C++. The result is DAPPLE, a DAta-Parallel Programming Library for Education.
Reference: [Lov93] <author> David B. Loveman. </author> <title> High Performance Fortran. </title> <journal> IEEE Parallel and Distributed Technology, </journal> <volume> 1(1) </volume> <pages> 25-42, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Although many data-parallel languages exist, including C*, Fortran90, NESL [Ble93], and HPF <ref> [Lov93] </ref>, they are difficult to use, are not similar to C++, or are not easily portable to student computers. We found many research projects designing parallel C++ variants.
Reference: [LRV92] <author> James R. Larus, Brad Richards, and Guhan Viswanathan. </author> <title> C**: A large-grain, object-oriented, data-parallel programming language. </title> <type> Technical Report #1126, </type> <institution> University of Wisconsin-Madison, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Although many data-parallel languages exist, including C*, Fortran90, NESL [Ble93], and HPF [Lov93], they are difficult to use, are not similar to C++, or are not easily portable to student computers. We found many research projects designing parallel C++ variants. C** <ref> [LRV92] </ref> is perhaps the closest candidate, in that it supports a data-parallel model, but it requires a new compiler and is not yet available. pC++ [BBG + 93] can also provide a data-parallel model, using only a preprocessor and library, but its syntax is a little complicated for beginners. <p> A nested loop computes each element of the result matrix C as an inner product (dot product) of the appropriate row of A and the appropriate column of B, demonstrating DAPPLE's capability to work with matrix slices <ref> [LRV92] </ref>. Here, A [r][_] is a row slice, representing row r of matrix A, and B [_][c] is a column slice, representing column c of matrix B. Slices may be used anywhere vectors may be used, including on the left-hand side of an assignment operator.

References-found: 11

