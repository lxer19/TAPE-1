URL: ftp://ftp.cs.bham.ac.uk/pub/tech-reports/1997/CSRP-97-08.ps.gz
Refering-URL: http://www.cs.bham.ac.uk/~rmp/eebic/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-mail: fR.Poli,W.B.Langdong@cs.bham.ac.uk  
Title: An Experimental Analysis of Schema Creation, Propagation and Disruption in Genetic Programming  
Author: Riccardo Poli and W.B. Langdon 
Date: February 1997 (Revised May 1997)  
Address: (UK)  
Affiliation: School of Computer Science The University of Birmingham  
Pubnum: Technical Report: CSRP-97-8  
Abstract: In this paper we first review the main results in the theory of schemata in Genetic Programming (GP) and summarise a new GP schema theory which is based on a new definition of schema. Then we study the creation, propagation and disruption of this new form of schemata in real runs, for standard crossover, one-point crossover and selection only. Finally, we discuss these results in the light our GP schema theorem. 
Abstract-found: 1
Intro-found: 1
Reference: [Altenberg, 1995] <author> Altenberg, L. </author> <title> The Schema Theorem and Price's Theorem. </title> <editor> In Whitley, L. D. and Vose, M. D., editors, </editor> <booktitle> Foundations of Genetic Algorithms 3, </booktitle> <pages> pages 23-49, </pages> <address> Estes Park, Colorado, USA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Since John Holland's seminal work in the mid seventies and his well known schema theorem (see [Holland, 1992] and [Goldberg, 1989]), schemata are often used to explain why GAs work (although their usefulness has been recently criticised, e.g. in <ref> [Altenberg, 1995] </ref>). In particular it is believed that GAs solve problems by hierarchically composing relatively fit, short schemata to form complete solutions (Building Block Hypothesis).
Reference: [Angeline and Kinnear, Jr., 1996] <editor> Angeline, P. J. and Kinnear, Jr., K. E., editors. </editor> <booktitle> Advances in Genetic Programming 2. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, USA. </address>
Reference: [Goldberg, 1989] <author> Goldberg, D. E. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts. </address>
Reference-contexts: E. Kinnear, Jr., 1994, Angeline and Kinnear, Jr., 1996]. However a relatively small number of theoretical results are available to try and explain why and how it works. Since John Holland's seminal work in the mid seventies and his well known schema theorem (see [Holland, 1992] and <ref> [Goldberg, 1989] </ref>), schemata are often used to explain why GAs work (although their usefulness has been recently criticised, e.g. in [Altenberg, 1995]). In particular it is believed that GAs solve problems by hierarchically composing relatively fit, short schemata to form complete solutions (Building Block Hypothesis). <p> The zero-order schemata G (H)'s represent different groups of programs all with the same shape and size. For this 4 reason we call them hyperspaces of programs. We denote non-zero-order schemata with the term hyperplanes. Equation 2 is more complicated than the corresponding version for genetic algorithms <ref> [Goldberg, 1989, Holland, 1992, Whitley, 1993] </ref> because in GP the trees undergoing optimisation have variable size and shape. <p> In summary, these experiments suggest that there is a good agreement between the predictions of the schema theorem and the observed number of instances of any schemata. However, we have not observed the exponential schema growth/decay often claimed to happen in GAs <ref> [Goldberg, 1989] </ref>. The experiments also show that when small populations are used genetic drift plays an important role at all stages. This becomes prominent when the selective pressure decreases, i.e. when nearly all the programs in the population have the same fitness.
Reference: [Holland, 1992] <author> Holland, J. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <note> second edition. </note>
Reference-contexts: E. Kinnear, Jr., 1994, Angeline and Kinnear, Jr., 1996]. However a relatively small number of theoretical results are available to try and explain why and how it works. Since John Holland's seminal work in the mid seventies and his well known schema theorem (see <ref> [Holland, 1992] </ref> and [Goldberg, 1989]), schemata are often used to explain why GAs work (although their usefulness has been recently criticised, e.g. in [Altenberg, 1995]). In particular it is believed that GAs solve problems by hierarchically composing relatively fit, short schemata to form complete solutions (Building Block Hypothesis). <p> The zero-order schemata G (H)'s represent different groups of programs all with the same shape and size. For this 4 reason we call them hyperspaces of programs. We denote non-zero-order schemata with the term hyperplanes. Equation 2 is more complicated than the corresponding version for genetic algorithms <ref> [Goldberg, 1989, Holland, 1992, Whitley, 1993] </ref> because in GP the trees undergoing optimisation have variable size and shape.
Reference: [K. E. Kinnear, Jr., 1994] <editor> K. E. Kinnear, Jr., editor. </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> MIT Press. </publisher>
Reference: [Koza, 1992] <author> Koza, J. R. </author> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection. </title> <publisher> MIT Press. </publisher>
Reference-contexts: One of the difficulties in obtaining theoretical results using the idea of schema is that the definition of schema for GP is much less straightforward than for GAs and alternative definitions have been proposed <ref> [Koza, 1992, O'Reilly and Oppacher, 1995, 1 Whigham, 1995] </ref>. These define schemata as composed of one or multiple fragments of a tree. These definitions allow a schema to be present multiple times within the same program. <p> We present the results of these experiments in Section 4, we discuss them in Section 5 and we draw some conclusions in Section 6. 2 Previous Work on GP Schemata The first attempt to produce a schema theory for GP was made by Koza <ref> [Koza, 1992, pages 116-119] </ref>, who produced an informal argument showing that Holland's schema theorem would apply to GP as well. The argument was based on the idea of defining a schema as the subspace of all trees which contain, as subtrees, a predefined set of complete subtrees. <p> We were also able to study subsets of the schemata present in populations of programs with maximum depth 3. The population was initialised using the "grow" method <ref> [Koza, 1992] </ref>. The fitness of a solution was the number of entries in the XOR truth-table it correctly predicted. In 5 the following subsections we describe the results obtained with selection only and with different forms of crossover (with p c = 0:35).
Reference: [O'Reilly and Oppacher, 1995] <author> O'Reilly, U.-M. and Oppacher, F. </author> <title> The troubling aspects of a building block hypothesis for genetic programming. </title> <editor> In Whitley, L. D. and Vose, M. D., editors, </editor> <booktitle> Foundations of Genetic Algorithms 3, </booktitle> <pages> pages 73-88, </pages> <address> Estes Park, Col-orado, USA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: One of the difficulties in obtaining theoretical results using the idea of schema is that the definition of schema for GP is much less straightforward than for GAs and alternative definitions have been proposed <ref> [Koza, 1992, O'Reilly and Oppacher, 1995, 1 Whigham, 1995] </ref>. These define schemata as composed of one or multiple fragments of a tree. These definitions allow a schema to be present multiple times within the same program. <p> H=f (+ 1 x), (* x y)g represents all the programs including at least one occurrence of (+ 1 x) and one of (* x y). Koza's work was later formalised and refined into a schema theorem for GP in <ref> [O'Reilly and Oppacher, 1995] </ref>. A schema was defined as an unordered collection (a multiset) of subtrees and tree fragments. Tree fragments are trees with at least one leaf that is a "don't care" symbol ('#') which can be matched by any subtree. <p> Therefore, during this phase all schemata with above average fitness and short defining-length would tend to have a low disruption probability. In <ref> [O'Reilly and Oppacher, 1995] </ref> serious doubts have been cast on the correctness of the Building Block Hypothesis (BBH) for standard GP. <p> all runs with standard crossover (e.g. in Figure 5) seem to suggest that, however large, the probability of schema disruption P d (H; t) in Equation 1 is not constant but may vary significantly from one generation to the next and should be considered a stochastic variable as suggested in <ref> [O'Reilly and Oppacher, 1995] </ref>. Our experiments also suggest that the probabilities of disruption P d (H; t)'s for schemata of different order are correlated. One-point crossover allows the convergence of the population. So, on average we must assume that its schema disruption probability is smaller than for standard crossover.
Reference: [Poli and Langdon, 1997a] <author> Poli, R. and Langdon, W. B. </author> <title> A new schema theory for genetic programming with one-point crossover and point mutation. </title> <booktitle> Proceedings of Genetic Programming'97, </booktitle> <address> Stanford, July 1997. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 15 </pages>
Reference-contexts: Nonetheless two of these definitions have been used in schema theorems for GP, which we will review in Section 2. In recent work <ref> [Poli and Langdon, 1997a] </ref> we have proposed a new simpler definition of schema for GP which is much closer to the original concept of schema in GAs. <p> for GP is that they make the effects on schemata of the genetic operators used in GP too difficult to evaluate mathematically. 3 Recently we have proposed a simpler definition of schema for GP and a form of crossover which have allowed us to derive a new GP schema theorem <ref> [Poli and Langdon, 1997a] </ref>. We define a schema as a tree composed of functions from the set F [ f=g and terminals from the set T [ f=g, where F and T are the function set and the terminal set used in a GP run. <p> the two parents, one-point crossover starts analysing the two trees from the root nodes and considering for the selection of the crossover point only the parts of the two trees which have the same topology (i.e. the same arity in the nodes encountered traversing the trees from the root node) <ref> [Poli and Langdon, 1997a] </ref>. <p> symbols, M is the number of individuals in the population, p diff (t) is the conditional probability that H is disrupted by crossover when the second parent has a different shape (i.e. does not sample G (H)), and the other symbols have the same meaning as in Equation 1 (see <ref> [Poli and Langdon, 1997a] </ref> for the proof). The zero-order schemata G (H)'s represent different groups of programs all with the same shape and size. For this 4 reason we call them hyperspaces of programs. We denote non-zero-order schemata with the term hyperplanes. <p> This is accounted for by the presence of the terms m (G (H); t) and f (G (H); t), which summarise the characteristics of the programs belonging to the same hyperspace in which H is a hyperplane. In <ref> [Poli and Langdon, 1997a] </ref> we analysed Equation 2 in detail and discussed the likely interactions between hyperspaces and hyperplanes and the expected time-dependence of the probability p diff (t) during a run. <p> crossover is used, it is as relevant to GP with one-point crossover as it is for traditional GAs. 6 Conclusions In this paper we have first reviewed the main results available to date on the theory of schemata for GP and summarised a new schema theory we have recently developed <ref> [Poli and Langdon, 1997a] </ref>. The theory is based on a new simpler definition of the concept of schema for GP which is very close to the original concept of schema in GAs. On the basis of this theory, we made several conjectures on the behaviours of GP with one-point crossover.
Reference: [Poli and Langdon, 1997b] <author> Poli, R. and Langdon, W. B. </author> <title> Genetic programming with one--point crossover and point mutation. </title> <type> Technical Report CSRP-97-13, </type> <institution> School of Computer Science, The University of Birmingham. </institution>
Reference-contexts: This prevents the population from converging. One--point crossover is very disruptive at the beginning of a run but becomes less and less so generation after generation. This suggests that mutation could be a very important operator in runs with one-point crossover, as recently observed in <ref> [Poli and Langdon, 1997b] </ref>. More theoretical and experimental work will be needed to investigate which form of crossover is better and in which cases. Acknowledgements The authors wish to thank the members of the EEBIC (Evolutionary and Emergent Behaviour Intelligence and Computation) group for useful discussions and comments.
Reference: [Radcliffe, 1991] <author> Radcliffe, N. J. </author> <title> Forma analysis and random respectful recombination. </title> <booktitle> In Proceedings of the Fourth International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Whigham overcame these problems by considering the average disruption probability and the average fitness of each schema. 3 New GP Schema Theory As highlighted in <ref> [Radcliffe, 1991] </ref>, a schema is a subspace of the space of possible solutions, usually represented using some concise notation (rather than enumerating all the solutions it contains). Schemata are mathematical tools to describe which areas of the search space are sampled by a population.
Reference: [Ridley, 1993] <author> Ridley, M. </author> <title> Evolution. </title> <publisher> Blackwell Scientific Publications, </publisher> <address> Boston. </address>
Reference-contexts: This is due to the stochastic nature of the selection process which makes the number of instances of each individual vary with a kind of Brownian motion which can lead to extinction or to take over the whole population (genetic drift) <ref> [Ridley, 1993] </ref>. In the run shown in Figure 1 there were initially 2,892 schemata: an average of 62.9 per program. This relatively small number is the effect of the depth limit we imposed, which prevents any program from having more than 7 nodes and, therefore, more than 128 schemata.
Reference: [Whigham, 1995] <author> Whigham, P. A. </author> <title> A schema theorem for context-free grammars. </title> <booktitle> In 1995 IEEE Conference on Evolutionary Computation, </booktitle> <volume> volume 1, </volume> <pages> pages 178-181, </pages> <address> Perth, Australia. </address> <publisher> IEEE Press. </publisher>
Reference-contexts: In the framework of his GP system based on context free grammars (CFG-GP) Whigham produced a very general concept of schema for context-free grammars and the related schema theorem <ref> [Whigham, 1995] </ref>. In CFG-GP programs are the result of applying a set of rewrite rules to a starting symbol.
Reference: [Whitley, 1993] <author> Whitley, D. </author> <title> A genetic algorithm tutorial. </title> <type> Technical Report CS-93-103, </type> <institution> Department of Computer Science, Colorado State University. </institution> <month> 16 </month>
Reference-contexts: The zero-order schemata G (H)'s represent different groups of programs all with the same shape and size. For this 4 reason we call them hyperspaces of programs. We denote non-zero-order schemata with the term hyperplanes. Equation 2 is more complicated than the corresponding version for genetic algorithms <ref> [Goldberg, 1989, Holland, 1992, Whitley, 1993] </ref> because in GP the trees undergoing optimisation have variable size and shape.
References-found: 13

