URL: ftp://ftp.cs.utexas.edu/pub/rdb/FOCS94.ps.gz
Refering-URL: http://www.cs.utexas.edu/users/rdb/cs395T/
Root-URL: 
Title: Scheduling Multithreaded Computations by Work Stealing  
Author: Robert D. Blumofe Charles E. Leiserson 
Address: 545 Technology Square Cambridge, MA 02139  
Affiliation: MIT Laboratory for Computer Science  
Abstract: This paper studies the problem of efficiently scheduling fully strict (i.e., well-structured) multithreaded computations on parallel computers. A popular and practical method of scheduling this kind of dynamic MIMD-style computation is "work stealing," in which processors needing work steal computational threads from other processors. In this paper, we give the first provably good work-stealing scheduler for multithreaded computations with dependencies. Specifically, our analysis shows that the expected time T P to execute a fully strict computation on P processors using our work-stealing scheduler is T P = O(T 1 =P + T 1 ), where T 1 is the minimum serial execution time of the multithreaded computation and T 1 is the minimum execution time with an infinite number of processors. Moreover, the space S P required by the execution satisfies S P S 1 P . We also show that the expected total communication of the algorithm is at most O(T 1 S max P ), where S max is the size of the largest activation record of any thread, thereby justifying the folk wisdom that work-stealing schedulers are more communication efficient than their work-sharing counterparts. All three of these bounds are existentially optimal to within a constant factor. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Arvind, Rishiyur S. Nikhil, and Keshav K. Pingali. I-structures: </author> <title> Data structures for parallel computing. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(4) </volume> <pages> 598-632, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: In this paper, we present and analyze a work-stealing algorithm for scheduling "fully strict" (well-structured) multithreaded computations. This class of computations encompasses both backtrack search computations [15, 26] and divide-and-conquer computations [25], as well as dataflow computations <ref> [1] </ref> in which threads may stall due to a data dependency. We analyze our algorithms in a stringent atomic access model similar to the atomic message-passing model of [17] in which concurrent accesses to the same data structure are serially queued by an adversary.
Reference: [2] <author> Robert D. Blumofe, Christopher F. Joerg, Bradley C. Kuszmaul, Charles E. Leiserson, Phil Lisiecki, Keith H. Randall, Andy Shaw, and Yuli Zhou. </author> <title> Cilk 1.0 reference manual. </title> <type> MIT Technical Report, </type> <note> to appear, </note> <year> 1994. </year>
Reference-contexts: How practical are the methods analyzed in this paper? We have been actively engaged in building a C-based language called "Cilk" for programming mul-tithreaded computations <ref> [2] </ref>. We currently have preliminary versions of the system that run on the Connection Machine CM-5, the Phish runtime system for networks of Unix workstations [4], and the Sparcsta-tion 10 symmetric multiprocessor.
Reference: [3] <author> Robert D. Blumofe and Charles E. Leiserson. </author> <title> Space-efficient scheduling of multithreaded computations. </title> <booktitle> In Proceedings of the Twenty Fifth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 362-371, </pages> <address> San Diego, California, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Our main contribution is a randomized work-stealing scheduling algorithm for fully strict multi-threaded computations which is provably efficient in terms of time, space, and communication. The bounds on space and time are better than previous bounds for work-sharing schedulers <ref> [3] </ref>, and the work-stealing scheduler is much simpler and eminently practical. Part of this improvement is due to our focusing on fully strict computations, as compared to the (general) strict computations studied in [3]. <p> The bounds on space and time are better than previous bounds for work-sharing schedulers <ref> [3] </ref>, and the work-stealing scheduler is much simpler and eminently practical. Part of this improvement is due to our focusing on fully strict computations, as compared to the (general) strict computations studied in [3]. Moreover, we are also able to provide a bound on the communication of fully strict computations which is existentially tight to within a constant factor, meeting the lower bound of Wu and Kung [25] for communication in parallel divide-and-conquer. In contrast, work-sharing sched-ulers have near worst-case behavior for communication. <p> Burton [6] shows how to limit space in certain parallel computations without causing deadlock. The remainder of this paper is organized as follows. In Section 2 we review the graph-theoretic model of multithreaded computations introduced in <ref> [3] </ref>, which provides a theoretical basis for analyzing schedulers. Section 3 gives a simple scheduling algorithm which uses a central queue. This "busy-leaves" algorithm forms the basis for our randomized work-stealing algorithm, which we present in Section 4. <p> We make some concluding remarks in Section 7. 2 A model for multithreaded computation This section reprises the graph-theoretic model of mul-tithreaded computation introduced in <ref> [3] </ref>. We also define what it means for computations to be "fully strict." We conclude with a statement of the greedy-scheduling theorem, which is an adaptation of theorems by Brent [5] and Graham [11, 12] on dag scheduling. <p> The tasks are connected by continue edges into threads, and the threads form an activation tree with the spawn edges. Because multithreaded computations with arbitrary data dependencies can be impossible to schedule efficiently <ref> [3] </ref>, we study subclasses of general multi-threaded computations in which the kinds of data-dependencies that can occur are restricted. A strict multithreaded computation is one in which all data-dependency edges from a thread go to an ancestor of the thread in the activation tree. <p> Early work on dag scheduling by Brent [5] and Graham [11, 12] shows that there exist P -processor execution schedules with T P T 1 =P +T 1 . The following theorem, proved in <ref> [3] </ref>, extends these results minimally to show that this upper bound on T P can be obtained by greedy schedules: those in which at each step of the execution, if at least P tasks are ready, then P tasks execute, and if fewer than P tasks are ready, then all execute.
Reference: [4] <author> Robert D. Blumofe and David S. Park. </author> <title> Scheduling large-scale parallel computations on networks of workstations. </title> <booktitle> In Proceedings of the Third International Symposium on High Performance Distributed Computing, </booktitle> <pages> pages 96-105, </pages> <address> San Francisco, California, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: The work-stealing idea dates back at least as far as Burton and Sleep's research [7] on parallel execution of functional programs and Halstead's implementation of Multilisp [14]. Since then, many researchers have implemented variants on this strategy <ref> [4, 9, 10, 13, 16, 18, 24] </ref>. Rudolph, Slivkin-Allalouf, and Upfal [22] analyzed a randomized work-stealing strategy for load balancing independent jobs on a parallel computer, and Karp and Zhang [15] analyzed a randomized work-stealing strategy for parallel backtrack search. <p> We currently have preliminary versions of the system that run on the Connection Machine CM-5, the Phish runtime system for networks of Unix workstations <ref> [4] </ref>, and the Sparcsta-tion 10 symmetric multiprocessor. Cilk is derived from the PCM "parallel continuation machine" system [13], which was itself inspired in part by the research reported here.
Reference: [5] <author> Richard P. Brent. </author> <title> The parallel evaluation of general arithmetic expressions. </title> <journal> Journal of the ACM, </journal> <volume> 21(2) </volume> <pages> 201-206, </pages> <month> April </month> <year> 1974. </year>
Reference-contexts: We also define what it means for computations to be "fully strict." We conclude with a statement of the greedy-scheduling theorem, which is an adaptation of theorems by Brent <ref> [5] </ref> and Graham [11, 12] on dag scheduling. A multithreaded computation is composed of a set of threads, each of which is a sequential ordering of unit-time tasks. <p> The work is denoted 3 T 1 , because it is the minimum time it takes to exe-cute the computation with 1 processor. Notice that T P T 1 =P , because P processors can execute only P tasks per time step. Early work on dag scheduling by Brent <ref> [5] </ref> and Graham [11, 12] shows that there exist P -processor execution schedules with T P T 1 =P +T 1 .
Reference: [6] <author> F. Warren Burton. </author> <title> Storage management in virtual tree machines. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(3) </volume> <pages> 321-328, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: Others have studied and continue to study the problem of efficiently managing the space requirements of parallel computations. Culler and Arvind [8] and Ruggiero and Sargeant [23] give heuristics for limiting the space required by dataflow programs. Burton <ref> [6] </ref> shows how to limit space in certain parallel computations without causing deadlock. The remainder of this paper is organized as follows. In Section 2 we review the graph-theoretic model of multithreaded computations introduced in [3], which provides a theoretical basis for analyzing schedulers.
Reference: [7] <author> F. Warren Burton and M. Ronan Sleep. </author> <title> Executing functional programs on a virtual tree of processors. </title> <booktitle> In Proceedings of the 1981 Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 187-194, </pages> <address> Portsmouth, New Hampshire, </address> <month> Octo-ber </month> <year> 1981. </year>
Reference-contexts: The work-stealing idea dates back at least as far as Burton and Sleep's research <ref> [7] </ref> on parallel execution of functional programs and Halstead's implementation of Multilisp [14]. Since then, many researchers have implemented variants on this strategy [4, 9, 10, 13, 16, 18, 24].
Reference: [8] <author> David E. Culler and Arvind. </author> <title> Resource requirements of dataflow programs. </title> <booktitle> In Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 141-150, </pages> <address> Honolulu, Hawaii, </address> <month> May </month> <year> 1988. </year> <note> Also: </note> <institution> MIT Laboratory for Computer Science, </institution> <note> Computation Structures Group Memo 280. </note>
Reference-contexts: In contrast, work-sharing sched-ulers have near worst-case behavior for communication. Thus, our results bolster the folk wisdom that work stealing is superior to work sharing. Others have studied and continue to study the problem of efficiently managing the space requirements of parallel computations. Culler and Arvind <ref> [8] </ref> and Ruggiero and Sargeant [23] give heuristics for limiting the space required by dataflow programs. Burton [6] shows how to limit space in certain parallel computations without causing deadlock. The remainder of this paper is organized as follows.
Reference: [9] <author> R. Feldmann, P. Mysliwietz, and B. Monien. </author> <title> A fully distributed chess program. </title> <type> Technical Report 79, </type> <institution> University of Paderborn, Germany, </institution> <month> February </month> <year> 1991. </year>
Reference-contexts: The work-stealing idea dates back at least as far as Burton and Sleep's research [7] on parallel execution of functional programs and Halstead's implementation of Multilisp [14]. Since then, many researchers have implemented variants on this strategy <ref> [4, 9, 10, 13, 16, 18, 24] </ref>. Rudolph, Slivkin-Allalouf, and Upfal [22] analyzed a randomized work-stealing strategy for load balancing independent jobs on a parallel computer, and Karp and Zhang [15] analyzed a randomized work-stealing strategy for parallel backtrack search.
Reference: [10] <author> Raphael Finkel and Udi Manber. </author> <title> DIB | a distributed implementation of backtracking. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(2) </volume> <pages> 235-256, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: The work-stealing idea dates back at least as far as Burton and Sleep's research [7] on parallel execution of functional programs and Halstead's implementation of Multilisp [14]. Since then, many researchers have implemented variants on this strategy <ref> [4, 9, 10, 13, 16, 18, 24] </ref>. Rudolph, Slivkin-Allalouf, and Upfal [22] analyzed a randomized work-stealing strategy for load balancing independent jobs on a parallel computer, and Karp and Zhang [15] analyzed a randomized work-stealing strategy for parallel backtrack search.
Reference: [11] <author> R. L. Graham. </author> <title> Bounds for certain multiprocessing anomalies. </title> <journal> The Bell System Technical Journal, </journal> <volume> 45 </volume> <pages> 1563-1581, </pages> <month> November </month> <year> 1966. </year>
Reference-contexts: We also define what it means for computations to be "fully strict." We conclude with a statement of the greedy-scheduling theorem, which is an adaptation of theorems by Brent [5] and Graham <ref> [11, 12] </ref> on dag scheduling. A multithreaded computation is composed of a set of threads, each of which is a sequential ordering of unit-time tasks. <p> Notice that T P T 1 =P , because P processors can execute only P tasks per time step. Early work on dag scheduling by Brent [5] and Graham <ref> [11, 12] </ref> shows that there exist P -processor execution schedules with T P T 1 =P +T 1 .
Reference: [12] <author> R. L. Graham. </author> <title> Bounds on multiprocessing timing anomalies. </title> <journal> SIAM Journal on Applied Mathematics, </journal> <volume> 17(2) </volume> <pages> 416-429, </pages> <month> March </month> <year> 1969. </year>
Reference-contexts: We also define what it means for computations to be "fully strict." We conclude with a statement of the greedy-scheduling theorem, which is an adaptation of theorems by Brent [5] and Graham <ref> [11, 12] </ref> on dag scheduling. A multithreaded computation is composed of a set of threads, each of which is a sequential ordering of unit-time tasks. <p> Notice that T P T 1 =P , because P processors can execute only P tasks per time step. Early work on dag scheduling by Brent [5] and Graham <ref> [11, 12] </ref> shows that there exist P -processor execution schedules with T P T 1 =P +T 1 .
Reference: [13] <author> Michael Halbherr, Yuli Zhou, and Chris F. Joerg. </author> <title> MIMD-style parallel programming with continuation-passing threads. </title> <booktitle> In Proceedings of the 2nd International Workshop on Massive Parallelism: Hardware, Software, and Applications, </booktitle> <address> Capri, Italy, </address> <month> September </month> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: The work-stealing idea dates back at least as far as Burton and Sleep's research [7] on parallel execution of functional programs and Halstead's implementation of Multilisp [14]. Since then, many researchers have implemented variants on this strategy <ref> [4, 9, 10, 13, 16, 18, 24] </ref>. Rudolph, Slivkin-Allalouf, and Upfal [22] analyzed a randomized work-stealing strategy for load balancing independent jobs on a parallel computer, and Karp and Zhang [15] analyzed a randomized work-stealing strategy for parallel backtrack search. <p> We currently have preliminary versions of the system that run on the Connection Machine CM-5, the Phish runtime system for networks of Unix workstations [4], and the Sparcsta-tion 10 symmetric multiprocessor. Cilk is derived from the PCM "parallel continuation machine" system <ref> [13] </ref>, which was itself inspired in part by the research reported here. The per-processor overhead of the Cilk implementation, compared with a native C implementation, is typically at most 15 percent on various applications that we have programmed.
Reference: [14] <author> Robert H. Halstead, Jr. </author> <title> Implementation of Multilisp: Lisp on a multiprocessor. </title> <booktitle> In Conference Record of the 1984 ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 9-17, </pages> <address> Austin, Texas, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: The work-stealing idea dates back at least as far as Burton and Sleep's research [7] on parallel execution of functional programs and Halstead's implementation of Multilisp <ref> [14] </ref>. Since then, many researchers have implemented variants on this strategy [4, 9, 10, 13, 16, 18, 24].
Reference: [15] <author> Richard M. Karp and Yanjun Zhang. </author> <title> Randomized parallel algorithms for backtrack search and branch-and-bound computation. </title> <journal> Journal of the ACM, </journal> <volume> 40(3) </volume> <pages> 765-789, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Since then, many researchers have implemented variants on this strategy [4, 9, 10, 13, 16, 18, 24]. Rudolph, Slivkin-Allalouf, and Upfal [22] analyzed a randomized work-stealing strategy for load balancing independent jobs on a parallel computer, and Karp and Zhang <ref> [15] </ref> analyzed a randomized work-stealing strategy for parallel backtrack search. Recently, Zhang and Ortynski [26] have obtained good bounds on the communication requirements of the randomized parallel backtrack search algorithm presented in [15]. In this paper, we present and analyze a work-stealing algorithm for scheduling "fully strict" (well-structured) multithreaded computations. <p> analyzed a randomized work-stealing strategy for load balancing independent jobs on a parallel computer, and Karp and Zhang <ref> [15] </ref> analyzed a randomized work-stealing strategy for parallel backtrack search. Recently, Zhang and Ortynski [26] have obtained good bounds on the communication requirements of the randomized parallel backtrack search algorithm presented in [15]. In this paper, we present and analyze a work-stealing algorithm for scheduling "fully strict" (well-structured) multithreaded computations. This class of computations encompasses both backtrack search computations [15, 26] and divide-and-conquer computations [25], as well as dataflow computations [1] in which threads may stall due to a data dependency. <p> Recently, Zhang and Ortynski [26] have obtained good bounds on the communication requirements of the randomized parallel backtrack search algorithm presented in [15]. In this paper, we present and analyze a work-stealing algorithm for scheduling "fully strict" (well-structured) multithreaded computations. This class of computations encompasses both backtrack search computations <ref> [15, 26] </ref> and divide-and-conquer computations [25], as well as dataflow computations [1] in which threads may stall due to a data dependency. <p> Our analysis assumes that concurrent accesses to the same data structure are serially queued by an adversary, as in the atomic message-passing model of [17]. This assumption is more stringent than that in the model of Karp and Zhang <ref> [15] </ref>. They assume that if concurrent steal requests are made to a queue, in one time step, one request is satisfied and all the others are denied.
Reference: [16] <author> Bradley C. Kuszmaul. </author> <title> Synchronized MIMD Computing. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: The work-stealing idea dates back at least as far as Burton and Sleep's research [7] on parallel execution of functional programs and Halstead's implementation of Multilisp [14]. Since then, many researchers have implemented variants on this strategy <ref> [4, 9, 10, 13, 16, 18, 24] </ref>. Rudolph, Slivkin-Allalouf, and Upfal [22] analyzed a randomized work-stealing strategy for load balancing independent jobs on a parallel computer, and Karp and Zhang [15] analyzed a randomized work-stealing strategy for parallel backtrack search.
Reference: [17] <author> Pangfeng Liu, William Aiello, and Sandeep Bhatt. </author> <title> An atomic model for message-passing. </title> <booktitle> In Proceedings of the Fifth Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 154-163, </pages> <address> Velen, Germany, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: This class of computations encompasses both backtrack search computations [15, 26] and divide-and-conquer computations [25], as well as dataflow computations [1] in which threads may stall due to a data dependency. We analyze our algorithms in a stringent atomic access model similar to the atomic message-passing model of <ref> [17] </ref> in which concurrent accesses to the same data structure are serially queued by an adversary. Our main contribution is a randomized work-stealing scheduling algorithm for fully strict multi-threaded computations which is provably efficient in terms of time, space, and communication. <p> We assume that the machine is an asynchronous parallel computer with P processors, and its memory can be either distributed or shared. Our analysis assumes that concurrent accesses to the same data structure are serially queued by an adversary, as in the atomic message-passing model of <ref> [17] </ref>. This assumption is more stringent than that in the model of Karp and Zhang [15]. They assume that if concurrent steal requests are made to a queue, in one time step, one request is satisfied and all the others are denied. <p> In this case, as we have indicated in Section 5, we make the conservative assumption that an adversary serially queues the work-stealing requests as in the atomic message-passing model of <ref> [17] </ref>. To analyze the running time of Algorithm WS executing a fully strict multithreaded computation with work T 1 and dag depth T 1 on a computer with P processors, we use an accounting argument. At each step of the algorithm, we collect P dollars, one from each processor.
Reference: [18] <author> Eric Mohr, David A. Kranz, and Robert H. Halstead, Jr. </author> <title> Lazy task creation: A technique for increasing the granularity of parallel programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 264-280, </pages> <month> July </month> <year> 1991. </year> <note> Also: </note> <institution> MIT Laboratory for Computer Science Technical Report MIT/LCS/TM-449. </institution>
Reference-contexts: The work-stealing idea dates back at least as far as Burton and Sleep's research [7] on parallel execution of functional programs and Halstead's implementation of Multilisp [14]. Since then, many researchers have implemented variants on this strategy <ref> [4, 9, 10, 13, 16, 18, 24] </ref>. Rudolph, Slivkin-Allalouf, and Upfal [22] analyzed a randomized work-stealing strategy for load balancing independent jobs on a parallel computer, and Karp and Zhang [15] analyzed a randomized work-stealing strategy for parallel backtrack search.
Reference: [19] <author> Vijay S. Pande, Christopher F. Joerg, Alexander Yu Grosberg, and Toyoichi Tanaka. </author> <title> Enumerations of the hamiltonian walks on a cubic sublattice. </title> <journal> Journal of Physics A, </journal> <note> 1994. To appear. </note>
Reference-contexts: The per-processor overhead of the Cilk implementation, compared with a native C implementation, is typically at most 15 percent on various applications that we have programmed. To date, our applications include a protein-folding program <ref> [19] </ref>, which was the first program to find the number of hamiltonian paths in a 4 fi 4 fi 3 grid, and a parallel chess-playing program ?Socrates, which won third prize at the 1994 ACM International Computer Chess Championship. 12 Acknowledgments Thanks to Bruce Maggs of Carnegie Mellon, who outlined the
Reference: [20] <author> C. Gregory Plaxton, </author> <month> August </month> <year> 1994. </year> <title> Private communication. </title>
Reference-contexts: the strategy by which the adversary chooses a ball from each bin is immaterial, and thus, we can assume that balls 1 Greg Plaxton of University of Texas, Austin has recently improved this bound to O (M) for the case when 1=* is at most polynomial in M and P <ref> [20] </ref>. 6 are queued in their bins in a first-in-first-out (FIFO) order. The adversary removes balls from the front of the queue, and when he tosses a ball, it is placed on the back of the queue. <p> This lemma says that for any * &gt; 0, with probability at least 1 *, the number of dollars in the Wait bucket is at most a constant 2 With Plaxton's bound <ref> [20] </ref> for Lemma 5, this bound becomes T P = O (T 1 =P +T 1 ), whenever 1=* is at most polynomial in M and P . times the number of dollars in the Steal bucket plus O (P lg P + P lg (1=*)), and the expected number of
Reference: [21] <author> Abhiram Ranade. </author> <title> How to emulate shared memory. </title> <booktitle> In Proceedings of the 28th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 185-194, </pages> <address> Los An-geles, California, </address> <month> October </month> <year> 1987. </year>
Reference-contexts: We then use this bound along with a delay-sequence argument <ref> [21] </ref> in Section 6 to analyze the execution time and communication cost of the work-stealing algorithm. We make some concluding remarks in Section 7. 2 A model for multithreaded computation This section reprises the graph-theoretic model of mul-tithreaded computation introduced in [3].
Reference: [22] <author> Larry Rudolph, Miriam Slivkin-Allalouf, and Eli Up-fal. </author> <title> A simple load balancing scheme for task allocation in parallel machines. </title> <booktitle> In Proceedings of the Third Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 237-245, </pages> <address> Hilton Head, South Carolina, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: The work-stealing idea dates back at least as far as Burton and Sleep's research [7] on parallel execution of functional programs and Halstead's implementation of Multilisp [14]. Since then, many researchers have implemented variants on this strategy [4, 9, 10, 13, 16, 18, 24]. Rudolph, Slivkin-Allalouf, and Upfal <ref> [22] </ref> analyzed a randomized work-stealing strategy for load balancing independent jobs on a parallel computer, and Karp and Zhang [15] analyzed a randomized work-stealing strategy for parallel backtrack search.
Reference: [23] <author> Carlos A. Ruggiero and John Sargeant. </author> <title> Control of parallelism in the Manchester dataflow machine. </title> <booktitle> In Functional Programming Languages and Computer Architecture, number 274 in Lecture Notes in Computer Science, </booktitle> <pages> pages 1-15. </pages> <publisher> Springer-Verlag, </publisher> <year> 1987. </year>
Reference-contexts: Thus, our results bolster the folk wisdom that work stealing is superior to work sharing. Others have studied and continue to study the problem of efficiently managing the space requirements of parallel computations. Culler and Arvind [8] and Ruggiero and Sargeant <ref> [23] </ref> give heuristics for limiting the space required by dataflow programs. Burton [6] shows how to limit space in certain parallel computations without causing deadlock. The remainder of this paper is organized as follows.
Reference: [24] <author> Mark T. Vandevoorde and Eric S. Roberts. WorkCrews: </author> <title> An abstraction for controlling parallelism. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 17(4) </volume> <pages> 347-366, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: The work-stealing idea dates back at least as far as Burton and Sleep's research [7] on parallel execution of functional programs and Halstead's implementation of Multilisp [14]. Since then, many researchers have implemented variants on this strategy <ref> [4, 9, 10, 13, 16, 18, 24] </ref>. Rudolph, Slivkin-Allalouf, and Upfal [22] analyzed a randomized work-stealing strategy for load balancing independent jobs on a parallel computer, and Karp and Zhang [15] analyzed a randomized work-stealing strategy for parallel backtrack search.
Reference: [25] <author> I-Chen Wu and H. T. Kung. </author> <title> Communication complexity for parallel divide-and-conquer. </title> <booktitle> In Proceedings of the 32nd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 151-162, </pages> <address> San Juan, Puerto Rico, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: In this paper, we present and analyze a work-stealing algorithm for scheduling "fully strict" (well-structured) multithreaded computations. This class of computations encompasses both backtrack search computations [15, 26] and divide-and-conquer computations <ref> [25] </ref>, as well as dataflow computations [1] in which threads may stall due to a data dependency. We analyze our algorithms in a stringent atomic access model similar to the atomic message-passing model of [17] in which concurrent accesses to the same data structure are serially queued by an adversary. <p> Moreover, we are also able to provide a bound on the communication of fully strict computations which is existentially tight to within a constant factor, meeting the lower bound of Wu and Kung <ref> [25] </ref> for communication in parallel divide-and-conquer. In contrast, work-sharing sched-ulers have near worst-case behavior for communication. Thus, our results bolster the folk wisdom that work stealing is superior to work sharing. Others have studied and continue to study the problem of efficiently managing the space requirements of parallel computations. <p> The communication bounds in this theorem are existentially tight, in that there exist fully strict computations that require (P T 1 S max ) total communication for any execution schedule. This result follows directly from a theorem of Wu and Kung <ref> [25] </ref>, who showed that divide-and-conquer computations| a special case of fully strict computations|require this much communication. In the case when the algorithm has linear expected speedup|that is, when P = O (T 1 =T 1 )|the total communication is at most O (T 1 S max ).
Reference: [26] <author> Y. Zhang and A. Ortynski. </author> <title> The efficiency of randomized parallel backtrack search. </title> <booktitle> In Proceedings of the 6th IEEE Symposium on Parallel and Distributed Processing, </booktitle> <address> Dallas, Texas, </address> <month> October </month> <year> 1994. </year> <note> To appear. 13 </note>
Reference-contexts: Rudolph, Slivkin-Allalouf, and Upfal [22] analyzed a randomized work-stealing strategy for load balancing independent jobs on a parallel computer, and Karp and Zhang [15] analyzed a randomized work-stealing strategy for parallel backtrack search. Recently, Zhang and Ortynski <ref> [26] </ref> have obtained good bounds on the communication requirements of the randomized parallel backtrack search algorithm presented in [15]. In this paper, we present and analyze a work-stealing algorithm for scheduling "fully strict" (well-structured) multithreaded computations. <p> Recently, Zhang and Ortynski [26] have obtained good bounds on the communication requirements of the randomized parallel backtrack search algorithm presented in [15]. In this paper, we present and analyze a work-stealing algorithm for scheduling "fully strict" (well-structured) multithreaded computations. This class of computations encompasses both backtrack search computations <ref> [15, 26] </ref> and divide-and-conquer computations [25], as well as dataflow computations [1] in which threads may stall due to a data dependency.
References-found: 26

