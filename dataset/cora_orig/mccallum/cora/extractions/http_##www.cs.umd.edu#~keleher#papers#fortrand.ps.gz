URL: http://www.cs.umd.edu/~keleher/papers/fortrand.ps.gz
Refering-URL: http://www.cs.umd.edu/users/keleher/syllabus.818.html
Root-URL: 
Title: Compiling Fortran D for MIMD Distributed-Memory Machines  
Author: Seema Hiranandani Ken Kennedy Chau-Wen Tseng 
Address: Houston, TX 77251-1892  
Affiliation: Department of Computer Science Rice University  
Abstract: Fortran D, a version of Fortran extended with data decomposition specifications, is designed to provide a machine-independent data-parallel programming model. This paper describes analysis, optimization, and code generation algorithms employed in the Fortran D compiler. The compiler first partitions programs using the owner computes rule. It then performs communication analysis, followed by communication and parallelism optimizations based on data dependence. Finally, the Fortran D compiler generates message-passing programs that can execute efficiently on MIMD distributed-memory machines. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. R. Allen and K. Kennedy. </author> <title> Automatic translation of Fortran programs to vector form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: Dependences may be either loop-independent or loop-carried. Loop-independent dependences occur on the same loop iteration; loop-carried dependences occur on different iterations of a particular loop. The level of a loop-carried dependence is the depth of the loop carrying the dependence <ref> [1] </ref>. Loop-independent dependences have infinite depth. The number of loop iterations separating the source and sink of the loop-carried dependence may be characterized by a dependence distance or direction [34]. Dependence analysis is vital to shared-memory vec-torizing and parallelizing compilers. <p> We begin by describing some program transformations. 3.4.1 Program Transformations Shared-memory parallelizing compilers apply program transformations to expose or enhance parallelism in scientific codes, using dependence information to determine their legality and profitability <ref> [1, 21, 23, 34] </ref>. Program transformations are also useful for distributed-memory compilers. The legality of each transformation is determined in exactly the same manner, since the same execution order must be preserved in order to retain the meaning of the original program. However, their profitability criteria are now totally different. <p> It may be applied only if the source and sink of each dependence are not reversed in the resulting program. This may be determined by examining the distance or direction vector associated with each dependence <ref> [1, 34] </ref>. Strip Mining Strip mining increases the step size of an existing loop and adds an additional inner loop. The legality of applying strip-mine followed by loop interchange is determined in the same manner as for unroll-and-jam [21].
Reference: [2] <author> F. Andre, J. Pazat, and H. Thomas. </author> <title> Pandore: A system to manage data distribution. </title> <booktitle> In Proceedings of the 1990 ACM International Conference on Supercomputing, </booktitle> <address> Amsterdam, The Netherlands, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: It is related to other distributed-memory compilation systems such as Al [33], CM Fortran [32], C* [29], Dataparallel C [13], Dino [30], MIMDizer [15], Pandore <ref> [2] </ref>, Paragon [9], and Spot [31], but mostly builds on the following research projects. Superb is a semi-automatic parallelization tool that supports arbitrary user-specified contiguous block distributions [12, 37]. It originated overlaps as a means to both specify and store nonlocal data accesses.
Reference: [3] <author> ANSI X3J3/S8.115. </author> <title> Fortran 90, </title> <month> June </month> <year> 1990. </year>
Reference-contexts: Multiple-instruction, multiple-data (MIMD) shared-memory machines such as the Cray Research C90 are programmed with explicit synchronization and parallel loops found in Parallel Computer Forum (PCF) Fortran [24]. Single-instruction, multiple-data (SIMD) machines such as the Thinking Machines CM-2 are programmed using parallel array constructs found in Fortran 90 <ref> [3] </ref>. MIMD distributed-memory machines such as the In-tel Paragon provide the most difficult programming model. Users must write message-passing Fortran 77 programs that deal with separate address spaces, synchronizing processors, and communicating data using messages. The process is time-consuming, tedious, and error-prone.
Reference: [4] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kre-mer. </author> <title> An interactive environment for data partitioning and distribution. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: This replaces many small messages with one large message, reducing both 6 message startup cost and latency. Algorithm We use the following algorithm from Bal-asundaram et al. and Gerndt to calculate the appropriate loop level to insert messages for nonlocal references <ref> [4, 12] </ref>. We define the commlevel for loop-carried dependences to be the level of the dependence. For loop-independent dependences we define it to be the level of the deepest loop common to both the source and sink of the dependence. <p> We believe that Fortran D, a version of Fortran enhanced with data decompositions, provides such a portable data-parallel programming model. Its success will depend on the effectiveness of the compiler, as well as environmental support for automatic data decomposition and static performance estimation <ref> [4, 5, 16] </ref>. The current prototype of the Fortran D compiler performs message vectorization, collective communication, fine-grain pipelining, and several other optimizations for block-distributed arrays.
Reference: [5] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kre-mer. </author> <title> A static performance estimator to guide data partitioning decisions. </title> <booktitle> In Proceedings of the Third ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Williamsburg, VA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: We believe that Fortran D, a version of Fortran enhanced with data decompositions, provides such a portable data-parallel programming model. Its success will depend on the effectiveness of the compiler, as well as environmental support for automatic data decomposition and static performance estimation <ref> [4, 5, 16] </ref>. The current prototype of the Fortran D compiler performs message vectorization, collective communication, fine-grain pipelining, and several other optimizations for block-distributed arrays.
Reference: [6] <author> D. Callahan, K. Cooper, R. Hood, K. Kennedy, and L. Torczon. </author> <title> ParaScope: A parallel programming environment. </title> <journal> The International Journal of Supercomputer Applications, </journal> <volume> 2(4) </volume> <pages> 84-99, </pages> <month> Winter </month> <year> 1988. </year>
Reference-contexts: Dependence analysis is vital to shared-memory vec-torizing and parallelizing compilers. We show that it is also highly useful for guiding compiler optimizations for distributed-memory machines. The prototype Fortran D compiler is being developed in the context of the ParaScope programming environment and incorporates the following analysis capabilities <ref> [6, 21] </ref>. Scalar dataflow analysis Control flow, control dependence, and live range information are computed during the scalar dataflow analysis phase.
Reference: [7] <author> D. Callahan and K. Kennedy. </author> <title> Compiling programs for distributed-memory multiprocessors. </title> <journal> Journal of Supercomputing, </journal> <volume> 2 </volume> <pages> 151-169, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: DECOMPOSITION D (N,N) DISTRIBUTE D (:,BLOCK) DISTRIBUTE D (CYCLIC,:) Note that data distribution does not subsume alignment. For instance, the distribute statement alone cannot specify that one 2D array be mapped with the transpose of another. Many previous researchers have supplied data decomposition extensions <ref> [7, 22, 28, 30, 32, 37] </ref>. <p> It translates Fortran D programs into single-program, multiple-data (SPMD) form with explicit message-passing that execute directly on the nodes of the distributed-memory machine. The compiler partitions the program using the owner computes rule, by which each processor computes values of data it owns <ref> [7, 28, 37] </ref>. The compiler is subdivided into three major phases|program analysis, program optimization, and code generation. <p> It is particularly useful to consider cross-processor dependences| dependences whose endpoints are executed by different processors. 3.2.1 Message Vectorization A naive but workable algorithm known as runtime resolution inserts guarded send and/or recv operations directly preceding each nonlocal reference <ref> [7, 28, 37] </ref>. Unfortunately, this simple approach generates many small messages that prove extremely inefficient due to communication overhead [18, 28]. The most basic communication optimization performed by the Fortran D compiler is message vector-ization. <p> For these statements the compiler needs to add explicit guards based on membership tests for the local iteration set of the statement <ref> [7, 17, 28, 37] </ref>. 3.3.2 Message Generation The Fortran D compiler uses information calculated in the communication analysis and optimization phases to guide message generation. <p> The inspector strategy is not applicable for unanalyzable references causing loop-carried true dependences. In this case the Fortran D compiler inserts guards to resolve the needed communication and program execution at runtime <ref> [7, 28, 37] </ref>. 3.3.3 Storage Management One of the major responsibilities of the Fortran D compiler is to select and manage storage for all nonlocal array references. There are three different storage schemes. Overlaps Overlaps are expansions of local array sections to accommodate neighboring nonlocal elements [12]. <p> Exsr statements are inserted in the program to communicate overlap regions. Data dependence information is then used to apply loop distribution and vectorize these statements, resulting in vectorized messages. Superb also performs interprocedural analysis and code generation. Callahan & Kennedy propose distributed-memory compilation techniques based on data dependence <ref> [7] </ref>. User-defined distribution functions are used to specify the data decomposition for Fortran programs.
Reference: [8] <author> D. Callahan, K. Kennedy, and U. Kremer. </author> <title> A dynamic study of vectorization in PFC. </title> <type> Technical Report TR89-97, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> July </month> <year> 1989. </year>
Reference-contexts: However, parallel computers are not likely to be widely successful until they are easy to program. A major component in the success of vector supercomputers is the ability of scientists to write Fortran programs in a "vectorizable" style and expect vectorizing compilers to automatically produce efficient code <ref> [8, 35] </ref>. The resulting programs are easily maintained, debugged, and ported across different vector machines. Compare this with the current situation for programming parallel machines. Scientists wishing to use such machines must rewrite their programs in an extension of Fortran that explicitly reflects the architecture of the underlying machine.
Reference: [9] <author> C. Chase, A. Cheung, A. Reeves, and M. Smith. </author> <title> Paragon: A parallel programming environment for scientific applications using communication structures. </title> <booktitle> In Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <address> St. Charles, IL, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: It is related to other distributed-memory compilation systems such as Al [33], CM Fortran [32], C* [29], Dataparallel C [13], Dino [30], MIMDizer [15], Pandore [2], Paragon <ref> [9] </ref>, and Spot [31], but mostly builds on the following research projects. Superb is a semi-automatic parallelization tool that supports arbitrary user-specified contiguous block distributions [12, 37]. It originated overlaps as a means to both specify and store nonlocal data accesses.
Reference: [10] <author> G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, C. Tseng, and M. Wu. </author> <title> Fortran D language specification. </title> <type> Technical Report TR90-141, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: Fortran D also provides a forall loop, irregular data distribution, and dynamic data decomposition, i.e., changing the alignment or distribution of a decomposition at any point in the program. The complete language is described in detail elsewhere <ref> [10] </ref>. 3 Fortran D Compiler The two major steps in writing a data-parallel program are selecting a data decomposition and using it to derive node programs with explicit data movement. We leave the task of selecting a data decomposition to the user or automatic tools.
Reference: [11] <author> G. Fox, M. Johnson, G. Lyzenga, S. Otto, J. Salmon, and D. Walker. </author> <title> Solving Problems on Concurrent Processors, volume 1. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year>
Reference-contexts: It may also be used with loop interchange to help exploit pipeline parallelism, as discussed in the next section. 3.4.2 Pipelined Computations In loosely synchronous computations all processors execute SPMD programs in a loose lockstep, alternating between phases of local computation and synchronous global communication <ref> [11] </ref>. These problems achieve good load balance because all processors are utilized during the computation phase. For instance, Jacobi and Red-black SOR are loosely synchronous.
Reference: [12] <author> M. Gerndt. </author> <title> Updating distributed variables in local computations. </title> <journal> Concurrency: Practice & Experience, </journal> <volume> 2(3) </volume> <pages> 171-193, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: This replaces many small messages with one large message, reducing both 6 message startup cost and latency. Algorithm We use the following algorithm from Bal-asundaram et al. and Gerndt to calculate the appropriate loop level to insert messages for nonlocal references <ref> [4, 12] </ref>. We define the commlevel for loop-carried dependences to be the level of the dependence. For loop-independent dependences we define it to be the level of the deepest loop common to both the source and sink of the dependence. <p> There are three different storage schemes. Overlaps Overlaps are expansions of local array sections to accommodate neighboring nonlocal elements <ref> [12] </ref>. For programs with high locality of reference, overlaps are useful for generating clean code. However, they are permanent and specific to each array, and thus may require more storage. Buffers Buffers avoid the contiguous and permanent nature of overlaps. <p> Superb is a semi-automatic parallelization tool that supports arbitrary user-specified contiguous block distributions <ref> [12, 37] </ref>. It originated overlaps as a means to both specify and store nonlocal data accesses. Exsr statements are inserted in the program to communicate overlap regions. Data dependence information is then used to apply loop distribution and vectorize these statements, resulting in vectorized messages.
Reference: [13] <author> P. Hatcher, M. Quinn, A. Lapadula, B. Seevers, R. An-derson, and R. Jones. </author> <title> Data-parallel programming on MIMD computers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 377-383, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: It is related to other distributed-memory compilation systems such as Al [33], CM Fortran [32], C* [29], Dataparallel C <ref> [13] </ref>, Dino [30], MIMDizer [15], Pandore [2], Paragon [9], and Spot [31], but mostly builds on the following research projects. Superb is a semi-automatic parallelization tool that supports arbitrary user-specified contiguous block distributions [12, 37]. It originated overlaps as a means to both specify and store nonlocal data accesses.
Reference: [14] <author> P. Havlak and K. Kennedy. </author> <title> An implementation of interprocedural bounded regular section analysis. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 350-360, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: In many cases, the Fortran D compiler can construct iteration or index sets using regular section descriptors (RSDs), a compact representation of rectangular sections (with some constant step) and their higher dimension analogs <ref> [14] </ref>. The union and intersection of RSDs can be calculated inexpensively, making them highly useful for the Fortran D compiler.
Reference: [15] <author> R. Hill. MIMDizer: </author> <title> A new tool for parallelization. </title> <journal> Supercomputing Review, </journal> <volume> 3(4) </volume> <pages> 26-28, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: It is related to other distributed-memory compilation systems such as Al [33], CM Fortran [32], C* [29], Dataparallel C [13], Dino [30], MIMDizer <ref> [15] </ref>, Pandore [2], Paragon [9], and Spot [31], but mostly builds on the following research projects. Superb is a semi-automatic parallelization tool that supports arbitrary user-specified contiguous block distributions [12, 37]. It originated overlaps as a means to both specify and store nonlocal data accesses.
Reference: [16] <author> S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, and C. Tseng. </author> <title> An overview of the Fortran D programming system. </title> <booktitle> In Proceedings of the Fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, CA, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: We believe that Fortran D, a version of Fortran enhanced with data decompositions, provides such a portable data-parallel programming model. Its success will depend on the effectiveness of the compiler, as well as environmental support for automatic data decomposition and static performance estimation <ref> [4, 5, 16] </ref>. The current prototype of the Fortran D compiler performs message vectorization, collective communication, fine-grain pipelining, and several other optimizations for block-distributed arrays.
Reference: [17] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Compiler support for machine-independent parallel pro 14 gramming in Fortran D. </title> <editor> In J. Saltz and P. Mehrotra, editors, </editor> <title> Compilers and Runtime Software for Scalable Multiprocessors. </title> <publisher> Elsevier, </publisher> <address> Amsterdam, The Nether-lands, </address> <year> 1992. </year>
Reference-contexts: Note how the local indices calculated for the local index set of each array have been used to derive the local indices for the local iteration set. The calculation of local index and iteration sets is described in greater detail elsewhere <ref> [17] </ref>. Handling boundary conditions Because alignment and distribution specifications in Fortran D are fairly simple, local index sets and their derived iteration sets may usually be calculated at compile time. In fact, in most regular computations local index and iteration sets are identical for every processor except for boundary conditions. <p> For these statements the compiler needs to add explicit guards based on membership tests for the local iteration set of the statement <ref> [7, 17, 28, 37] </ref>. 3.3.2 Message Generation The Fortran D compiler uses information calculated in the communication analysis and optimization phases to guide message generation.
Reference: [18] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Evaluation of compiler optimizations for Fortran D on MIMD distributed-memory machines. </title> <booktitle> In Proceedings of the 1992 ACM International Conference on Supercomputing, </booktitle> <address> Washington, DC, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Unfortunately, this simple approach generates many small messages that prove extremely inefficient due to communication overhead <ref> [18, 28] </ref>. The most basic communication optimization performed by the Fortran D compiler is message vector-ization. It uses the level of loop-carried data dependences to calculate whether communication may be legally performed at outer loops. <p> Iteration reordering extracts local loop iterations to increase the amount of computation that can be overlapped. Nonblocking messages rely on architectural support to hide message copy times. These optimizations are discussed in detail elsewhere <ref> [18, 22, 28] </ref>. Communication may also be optimized by considering interactions between all the loop nests in the program. <p> A message is sent for each block of nonlocal data, decreasing communication overhead at the expense of some parallelism. Selecting an efficient block size depends on the data decomposition, processor topology, and ratio of communication to computation cost for the underlying machine. A detailed algorithm is presented elsewhere <ref> [18] </ref>. Empirical results show that exploiting pipeline parallelism is important for common scientific computations such as tridiagonal solvers. 4 Related Work We view the Fortran D compiler as a second-generation distributed-memory compiler that integrates and extends analysis and optimization techniques from many other research projects.
Reference: [19] <author> S. Hiranandani, J. Saltz, P. Mehrotra, and H. Berry-man. </author> <title> Performance of hashed cache data migration schemes on multicomputers. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 12(4), </volume> <month> August </month> <year> 1991. </year>
Reference-contexts: Hash tables Hash tables may be used when the set of nonlocal elements accessed is sparse, as for many irregular computations. They also provide a quick lookup mechanism for arbitrary sets of nonlocal values <ref> [19] </ref>. The extent of all RSDs representing nonlocal accesses produced during message generation are examined to select the appropriate storage type for each array. If overlaps have been selected, array declarations are modified to take into account storage for nonlocal data. <p> It was motivated by Parti, a set of runtime library routines that support irregular computations on MIMD distributed-memory machines. Parti is the first to propose and implement user-defined irregular distributions [26] and a hashed cache for nonlocal values <ref> [19] </ref>. 4.1 Comparison with Fortran D The Fortran D compiler integrates more compiler optimizations than the first generation research systems described, and in addition possesses two main advan 13 tages.
Reference: [20] <author> K. Ikudome, G. Fox, A. Kolawa, and J. Flower. </author> <title> An automatic and symbolic parallelization system for distributed memory parallel computers. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: Program analysis and optimization are different because it targets a purely functional language. Crystal pioneered the strategy of identifying collective communication opportunities used in the Fortran D compiler. Aspar is a Fortran compiler that performs simple dependence analysis of using A-lists to detect parallel loops <ref> [20] </ref>. Loop iterations are then partitioned and used to automatically derive data decompositions. A micro-stencil based on the computation is used to gen erate a macro-stencil, identifying communication requirements. Collective communications are also generated.
Reference: [21] <author> K. Kennedy, K. S. M c Kinley, and C. Tseng. </author> <title> Analysis and transformation in the ParaScope Editor. </title> <booktitle> In Proceedings of the 1991 ACM International Conference on Supercomputing, </booktitle> <address> Cologne, Germany, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Dependence analysis is vital to shared-memory vec-torizing and parallelizing compilers. We show that it is also highly useful for guiding compiler optimizations for distributed-memory machines. The prototype Fortran D compiler is being developed in the context of the ParaScope programming environment and incorporates the following analysis capabilities <ref> [6, 21] </ref>. Scalar dataflow analysis Control flow, control dependence, and live range information are computed during the scalar dataflow analysis phase. <p> We begin by describing some program transformations. 3.4.1 Program Transformations Shared-memory parallelizing compilers apply program transformations to expose or enhance parallelism in scientific codes, using dependence information to determine their legality and profitability <ref> [1, 21, 23, 34] </ref>. Program transformations are also useful for distributed-memory compilers. The legality of each transformation is determined in exactly the same manner, since the same execution order must be preserved in order to retain the meaning of the original program. However, their profitability criteria are now totally different. <p> Loop Distribution Loop distribution separates independent statements inside a single loop into multiple loops with identical headers. Loop distribution may be applied only if the statements are not involved in a recurrence and the direction of existing loop-carried dependences are not reversed in the resulting loops <ref> [21, 23] </ref>. It can separate statements in loop nests with different local iteration sets, avoiding the need to evaluate guards at runtime. Loop distribution may also separate the source and sink of loop-carried or loop-independent cross-processor dependences, allowing individual messages to be combined into a single vector message. <p> Strip Mining Strip mining increases the step size of an existing loop and adds an additional inner loop. The legality of applying strip-mine followed by loop interchange is determined in the same manner as for unroll-and-jam <ref> [21] </ref>. The Fortran D compiler may apply strip mining in order to reduce storage requirements for computations.
Reference: [22] <author> C. Koelbel and P. Mehrotra. </author> <title> Compiling global name-space parallel loops for distributed execution. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 440-451, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: DECOMPOSITION D (N,N) DISTRIBUTE D (:,BLOCK) DISTRIBUTE D (CYCLIC,:) Note that data distribution does not subsume alignment. For instance, the distribute statement alone cannot specify that one 2D array be mapped with the transpose of another. Many previous researchers have supplied data decomposition extensions <ref> [7, 22, 28, 30, 32, 37] </ref>. <p> Because f is an irregular function (e.g., an index array), the Fortran D compiler cannot precisely determine at compile-time what communication is required. However, inspectors and executors may be created during code generation to combine messages at runtime <ref> [22, 26] </ref>. 3.2.3 Additional Optimizations The Fortran D compiler performs other communication optimizations. Message coalescing combines messages for different references to the same array. Message aggregation combines messages from different arrays to the same processor, at the expense of copying them to a single contiguous buffer. <p> Iteration reordering extracts local loop iterations to increase the amount of computation that can be overlapped. Nonblocking messages rely on architectural support to hide message copy times. These optimizations are discussed in detail elsewhere <ref> [18, 22, 28] </ref>. Communication may also be optimized by considering interactions between all the loop nests in the program. <p> Despite the expense of additional communication, experimental evidence from several systems show that it can improve performance by grouping communication to access nonlocal data outside of the loop nest, especially if the information generated may be reused on later iterations <ref> [22, 26] </ref>. The inspector strategy is not applicable for unanalyzable references causing loop-carried true dependences. <p> Loop iterations are then partitioned and used to automatically derive data decompositions. A micro-stencil based on the computation is used to gen erate a macro-stencil, identifying communication requirements. Collective communications are also generated. Kali is the first compiler that supports both regular and irregular computations on MIMD distributed-memory machines <ref> [22] </ref>. Since dependence analysis is not provided, programmers must declare all parallel loops. Instead of deriving a parallel program from the data decomposition, Kali requires that the programmer explicitly partition loop iterations onto processors using an on clause.
Reference: [23] <author> D. Kuck, R. Kuhn, D. Padua, B. Leasure, and M. J. Wolfe. </author> <title> Dependence graphs and compiler optimizations. </title> <booktitle> In Conference Record of the Eighth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <address> Williamsburg, VA, </address> <month> January </month> <year> 1981. </year>
Reference-contexts: Its goal is to automate the task of deriving node programs based on the data decomposition. For these machines, it is particularly important to reduce both communication and load imbalance. We present a code generation strategy based on the concept of data dependence <ref> [23] </ref> that unifies and extends previous techniques. The rest of this paper presents the data decomposition specifications in Fortran D, basic compiler analysis and code generation algorithms, and compiler optimizations to reduce communication cost and exploit pipeline parallelism. <p> A data dependence between two references R 1 and R 2 indicates that they read or write a common memory location in a way that requires their execution order to be maintained <ref> [23] </ref>. We call R 1 the source and R 2 the sink of the dependence if R 1 must be executed before R 2 . If R 1 is a write and R 2 is a read, we call the result a true (or flow) dependence. <p> We begin by describing some program transformations. 3.4.1 Program Transformations Shared-memory parallelizing compilers apply program transformations to expose or enhance parallelism in scientific codes, using dependence information to determine their legality and profitability <ref> [1, 21, 23, 34] </ref>. Program transformations are also useful for distributed-memory compilers. The legality of each transformation is determined in exactly the same manner, since the same execution order must be preserved in order to retain the meaning of the original program. However, their profitability criteria are now totally different. <p> Loop Distribution Loop distribution separates independent statements inside a single loop into multiple loops with identical headers. Loop distribution may be applied only if the statements are not involved in a recurrence and the direction of existing loop-carried dependences are not reversed in the resulting loops <ref> [21, 23] </ref>. It can separate statements in loop nests with different local iteration sets, avoiding the need to evaluate guards at runtime. Loop distribution may also separate the source and sink of loop-carried or loop-independent cross-processor dependences, allowing individual messages to be combined into a single vector message. <p> Loop Fusion Loop fusion combines multiple loops with identical headers into a single loop. It is legal if the direction of existing dependences are not reversed after fusion <ref> [23, 34] </ref>. Loop fusion can improve data locality, but its main use is to enable loop interchange and strip-mine. Loop Interchange Loop interchange swaps adjacent loop headers to alter the traversal order of the itera 10 tion space.
Reference: [24] <author> B. Leasure, </author> <title> editor. PCF Fortran: Language Definition, version 3.1. </title> <booktitle> The Parallel Computing Forum, </booktitle> <address> Cham-paign, IL, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: Multiple-instruction, multiple-data (MIMD) shared-memory machines such as the Cray Research C90 are programmed with explicit synchronization and parallel loops found in Parallel Computer Forum (PCF) Fortran <ref> [24] </ref>. Single-instruction, multiple-data (SIMD) machines such as the Thinking Machines CM-2 are programmed using parallel array constructs found in Fortran 90 [3]. MIMD distributed-memory machines such as the In-tel Paragon provide the most difficult programming model.
Reference: [25] <author> J. Li and M. Chen. </author> <title> Compiling communication-efficient programs for massively parallel machines. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 361-376, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: For these stencil computations, individual calls to send and recv primitives are very efficient. This is the case for the Jacobi, SOR, and Red-black SOR examples previously discussed. Collective Communication More complicated subscript expressions indicate the need for collective communication <ref> [25] </ref>. For example, the loop-invariant subscript for B (c; j) in S 2 can be efficiently communicated using broadcast. Collective communication is also useful in performing transposes for differing alignments between lhs and rhs references, or accumulating partial results for reductions. <p> Collective communication is selected because these communication patterns are not well-described by individual messages, and can be performed significantly faster using special purpose routines. The Fortran D compiler applies techniques pioneered by Li and Chen <ref> [25] </ref>. Runtime Processing A third type of communication is needed to communicate the values needed by by B (f (i); j) in S 3 . Because f is an irregular function (e.g., an index array), the Fortran D compiler cannot precisely determine at compile-time what communication is required. <p> Analysis is considerably simplified through the use of write-once arrays called I-structures. Global accumulate (reduction) operations are supported. Unlike other systems, program partitioning produces distinct programs for each node processor. Crystal is a high-level functional language compiled to distributed-memory machines using both automatic data decomposition and communication generation <ref> [25] </ref>. Program analysis and optimization are different because it targets a purely functional language. Crystal pioneered the strategy of identifying collective communication opportunities used in the Fortran D compiler. Aspar is a Fortran compiler that performs simple dependence analysis of using A-lists to detect parallel loops [20].
Reference: [26] <author> R. Mirchandaney, J. Saltz, R. Smith, D. Nicol, and K. Crowley. </author> <title> Principles of runtime support for parallel processors. </title> <booktitle> In Proceedings of the Second International Conference on Supercomputing, </booktitle> <address> St. Malo, France, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: Because f is an irregular function (e.g., an index array), the Fortran D compiler cannot precisely determine at compile-time what communication is required. However, inspectors and executors may be created during code generation to combine messages at runtime <ref> [22, 26] </ref>. 3.2.3 Additional Optimizations The Fortran D compiler performs other communication optimizations. Message coalescing combines messages for different references to the same array. Message aggregation combines messages from different arrays to the same processor, at the expense of copying them to a single contiguous buffer. <p> The nonlocal RSDs for P roc (1) and P roc (2:3) are both <ref> [2:99, 26] </ref> and are therefore combined. The RSD for P roc (4) consists of only local data and is discarded. The sending processor is determined by computing the owners of the section [2:99,26] @ P roc (1:3), resulting in P roc (2:4) sending data to their left processors. <p> Additional communication is also appended following loops containing reductions to accumulate the results of each reduction. Runtime Processing Runtime processing is applied to computations whose nonlocal data requirements are not known at compile time. An inspector <ref> [26] </ref> is constructed to preprocess the loop body at run-time to determine what nonlocal data will be accessed. This in effect calculates the receive index set for each processor. A global transpose operation between processors is then used to calculate the send index sets. <p> Despite the expense of additional communication, experimental evidence from several systems show that it can improve performance by grouping communication to access nonlocal data outside of the loop nest, especially if the information generated may be reused on later iterations <ref> [22, 26] </ref>. The inspector strategy is not applicable for unanalyzable references causing loop-carried true dependences. <p> It was motivated by Parti, a set of runtime library routines that support irregular computations on MIMD distributed-memory machines. Parti is the first to propose and implement user-defined irregular distributions <ref> [26] </ref> and a hashed cache for nonlocal values [19]. 4.1 Comparison with Fortran D The Fortran D compiler integrates more compiler optimizations than the first generation research systems described, and in addition possesses two main advan 13 tages.
Reference: [27] <author> C. Pancake and D. Bergmark. </author> <title> Do parallel languages respond to the needs of scientific programmers? IEEE Computer, </title> <booktitle> 23(12) </booktitle> <pages> 13-23, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: To be successful, the compiler needs additional information not present in vanilla Fortran. However, most parallel programming languages provide no support for data decomposition <ref> [27] </ref>. For these reasons, we have developed an enhanced version of Fortran that introduces data decomposition specifications. We call the extended language Fortran D, where "D" suggests data, decomposition, or distribution.
Reference: [28] <author> A. Rogers and K. Pingali. </author> <title> Process decomposition through locality of reference. </title> <booktitle> In Proceedings of the SIGPLAN '89 Conference on Program Language Design and Implementation, </booktitle> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: DECOMPOSITION D (N,N) DISTRIBUTE D (:,BLOCK) DISTRIBUTE D (CYCLIC,:) Note that data distribution does not subsume alignment. For instance, the distribute statement alone cannot specify that one 2D array be mapped with the transpose of another. Many previous researchers have supplied data decomposition extensions <ref> [7, 22, 28, 30, 32, 37] </ref>. <p> It translates Fortran D programs into single-program, multiple-data (SPMD) form with explicit message-passing that execute directly on the nodes of the distributed-memory machine. The compiler partitions the program using the owner computes rule, by which each processor computes values of data it owns <ref> [7, 28, 37] </ref>. The compiler is subdivided into three major phases|program analysis, program optimization, and code generation. <p> It is particularly useful to consider cross-processor dependences| dependences whose endpoints are executed by different processors. 3.2.1 Message Vectorization A naive but workable algorithm known as runtime resolution inserts guarded send and/or recv operations directly preceding each nonlocal reference <ref> [7, 28, 37] </ref>. Unfortunately, this simple approach generates many small messages that prove extremely inefficient due to communication overhead [18, 28]. The most basic communication optimization performed by the Fortran D compiler is message vector-ization. <p> Unfortunately, this simple approach generates many small messages that prove extremely inefficient due to communication overhead <ref> [18, 28] </ref>. The most basic communication optimization performed by the Fortran D compiler is message vector-ization. It uses the level of loop-carried data dependences to calculate whether communication may be legally performed at outer loops. <p> Iteration reordering extracts local loop iterations to increase the amount of computation that can be overlapped. Nonblocking messages rely on architectural support to hide message copy times. These optimizations are discussed in detail elsewhere <ref> [18, 22, 28] </ref>. Communication may also be optimized by considering interactions between all the loop nests in the program. <p> For these statements the compiler needs to add explicit guards based on membership tests for the local iteration set of the statement <ref> [7, 17, 28, 37] </ref>. 3.3.2 Message Generation The Fortran D compiler uses information calculated in the communication analysis and optimization phases to guide message generation. <p> The inspector strategy is not applicable for unanalyzable references causing loop-carried true dependences. In this case the Fortran D compiler inserts guards to resolve the needed communication and program execution at runtime <ref> [7, 28, 37] </ref>. 3.3.3 Storage Management One of the major responsibilities of the Fortran D compiler is to select and manage storage for all nonlocal array references. There are three different storage schemes. Overlaps Overlaps are expansions of local array sections to accommodate neighboring nonlocal elements [12]. <p> Exploiting Pipeline Parallelism Parallelism may be exploited in pipelined computations through message pipelining|sending a message when its value is first computed, rather than waiting until its value is needed <ref> [28] </ref>. Rogers and Pingali applied this optimization to a Gauss-Seidel computation (a special case of SOR) that is distributed cyclically. <p> X (i-1,j) Loops & Communication Cross-Processor do j = 1,N enddo enddo Fine-grain Pipelining do j = 1,N enddo Coarse-grain Pipelining do jj = 1,N,Bk enddo enddo ALIGN X (I,J) with A (I,J) Data Decomposition DISTRIBUTE A (BLOCK,:) Id Nouveau is a functional language enhanced with block and cyclic distributions <ref> [28] </ref>. Initially, send and receive statements are inserted to communicate each nonlocal array access. Message vectorization is applied to combine messages for previously written array elements. Loop jamming (fusion) and strip mining are used when writing array elements. Analysis is considerably simplified through the use of write-once arrays called I-structures.
Reference: [29] <author> J. Rose and G. Steele, Jr. </author> <title> C fl : An extended C language for data parallel programming. </title> <editor> In L. Kartashev and S. Kartashev, editors, </editor> <booktitle> Proceedings of the Second International Conference on Supercomputing, </booktitle> <address> Santa Clara, CA, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: It is related to other distributed-memory compilation systems such as Al [33], CM Fortran [32], C* <ref> [29] </ref>, Dataparallel C [13], Dino [30], MIMDizer [15], Pandore [2], Paragon [9], and Spot [31], but mostly builds on the following research projects. Superb is a semi-automatic parallelization tool that supports arbitrary user-specified contiguous block distributions [12, 37].
Reference: [30] <author> M. Rosing, R. Schnabel, and R. Weaver. </author> <title> The DINO parallel programming language. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13(1) </volume> <pages> 30-42, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: DECOMPOSITION D (N,N) DISTRIBUTE D (:,BLOCK) DISTRIBUTE D (CYCLIC,:) Note that data distribution does not subsume alignment. For instance, the distribute statement alone cannot specify that one 2D array be mapped with the transpose of another. Many previous researchers have supplied data decomposition extensions <ref> [7, 22, 28, 30, 32, 37] </ref>. <p> It is related to other distributed-memory compilation systems such as Al [33], CM Fortran [32], C* [29], Dataparallel C [13], Dino <ref> [30] </ref>, MIMDizer [15], Pandore [2], Paragon [9], and Spot [31], but mostly builds on the following research projects. Superb is a semi-automatic parallelization tool that supports arbitrary user-specified contiguous block distributions [12, 37]. It originated overlaps as a means to both specify and store nonlocal data accesses.
Reference: [31] <author> D. Socha. </author> <title> Compiling single-point iterative programs for distributed memory computers. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: It is related to other distributed-memory compilation systems such as Al [33], CM Fortran [32], C* [29], Dataparallel C [13], Dino [30], MIMDizer [15], Pandore [2], Paragon [9], and Spot <ref> [31] </ref>, but mostly builds on the following research projects. Superb is a semi-automatic parallelization tool that supports arbitrary user-specified contiguous block distributions [12, 37]. It originated overlaps as a means to both specify and store nonlocal data accesses. Exsr statements are inserted in the program to communicate overlap regions.
Reference: [32] <institution> Thinking Machines Corporation, </institution> <address> Cambridge, MA. </address> <note> CM Fortran Reference Manual, version 5.2-0.6 edition, </note> <month> September </month> <year> 1989. </year>
Reference-contexts: DECOMPOSITION D (N,N) DISTRIBUTE D (:,BLOCK) DISTRIBUTE D (CYCLIC,:) Note that data distribution does not subsume alignment. For instance, the distribute statement alone cannot specify that one 2D array be mapped with the transpose of another. Many previous researchers have supplied data decomposition extensions <ref> [7, 22, 28, 30, 32, 37] </ref>. <p> It is related to other distributed-memory compilation systems such as Al [33], CM Fortran <ref> [32] </ref>, C* [29], Dataparallel C [13], Dino [30], MIMDizer [15], Pandore [2], Paragon [9], and Spot [31], but mostly builds on the following research projects. Superb is a semi-automatic parallelization tool that supports arbitrary user-specified contiguous block distributions [12, 37].
Reference: [33] <author> P.-S. Tseng. </author> <title> A parallelizing compiler for distributed memory parallel computers. </title> <booktitle> In Proceedings of the SIG-PLAN '90 Conference on Program Language Design and Implementation, </booktitle> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: It is related to other distributed-memory compilation systems such as Al <ref> [33] </ref>, CM Fortran [32], C* [29], Dataparallel C [13], Dino [30], MIMDizer [15], Pandore [2], Paragon [9], and Spot [31], but mostly builds on the following research projects. Superb is a semi-automatic parallelization tool that supports arbitrary user-specified contiguous block distributions [12, 37].
Reference: [34] <author> M. J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference-contexts: The level of a loop-carried dependence is the depth of the loop carrying the dependence [1]. Loop-independent dependences have infinite depth. The number of loop iterations separating the source and sink of the loop-carried dependence may be characterized by a dependence distance or direction <ref> [34] </ref>. Dependence analysis is vital to shared-memory vec-torizing and parallelizing compilers. We show that it is also highly useful for guiding compiler optimizations for distributed-memory machines. The prototype Fortran D compiler is being developed in the context of the ParaScope programming environment and incorporates the following analysis capabilities [6, 21]. <p> We begin by describing some program transformations. 3.4.1 Program Transformations Shared-memory parallelizing compilers apply program transformations to expose or enhance parallelism in scientific codes, using dependence information to determine their legality and profitability <ref> [1, 21, 23, 34] </ref>. Program transformations are also useful for distributed-memory compilers. The legality of each transformation is determined in exactly the same manner, since the same execution order must be preserved in order to retain the meaning of the original program. However, their profitability criteria are now totally different. <p> Loop Fusion Loop fusion combines multiple loops with identical headers into a single loop. It is legal if the direction of existing dependences are not reversed after fusion <ref> [23, 34] </ref>. Loop fusion can improve data locality, but its main use is to enable loop interchange and strip-mine. Loop Interchange Loop interchange swaps adjacent loop headers to alter the traversal order of the itera 10 tion space. <p> It may be applied only if the source and sink of each dependence are not reversed in the resulting program. This may be determined by examining the distance or direction vector associated with each dependence <ref> [1, 34] </ref>. Strip Mining Strip mining increases the step size of an existing loop and adds an additional inner loop. The legality of applying strip-mine followed by loop interchange is determined in the same manner as for unroll-and-jam [21].
Reference: [35] <author> M. J. Wolfe. </author> <title> Semi-automatic domain decomposition. </title> <booktitle> In Proceedings of the 4th Conference on Hypercube Concurrent Computers and Applications, </booktitle> <address> Monterey, CA, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: However, parallel computers are not likely to be widely successful until they are easy to program. A major component in the success of vector supercomputers is the ability of scientists to write Fortran programs in a "vectorizable" style and expect vectorizing compilers to automatically produce efficient code <ref> [8, 35] </ref>. The resulting programs are easily maintained, debugged, and ported across different vector machines. Compare this with the current situation for programming parallel machines. Scientists wishing to use such machines must rewrite their programs in an extension of Fortran that explicitly reflects the architecture of the underlying machine.
Reference: [36] <author> J. Wu, J. Saltz, S. Hiranandani, and H. Berryman. </author> <title> Runtime compilation methods for multicomputers. </title> <booktitle> In Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <address> St. Charles, IL, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: Instead of deriving a parallel program from the data decomposition, Kali requires that the programmer explicitly partition loop iterations onto processors using an on clause. Arf is a compiler that automatically generates inspector and executor loops for runtime preprocessing of programs with block, cyclic, and user-defined irregular distributions <ref> [36] </ref>. It was motivated by Parti, a set of runtime library routines that support irregular computations on MIMD distributed-memory machines.
Reference: [37] <author> H. Zima, H.-J. Bast, and M. Gerndt. </author> <title> SUPERB: A tool for semi-automatic MIMD/SIMD parallelization. </title> <journal> Parallel Computing, </journal> <volume> 6 </volume> <pages> 1-18, </pages> <year> 1988. </year> <month> 15 </month>
Reference-contexts: DECOMPOSITION D (N,N) DISTRIBUTE D (:,BLOCK) DISTRIBUTE D (CYCLIC,:) Note that data distribution does not subsume alignment. For instance, the distribute statement alone cannot specify that one 2D array be mapped with the transpose of another. Many previous researchers have supplied data decomposition extensions <ref> [7, 22, 28, 30, 32, 37] </ref>. <p> It translates Fortran D programs into single-program, multiple-data (SPMD) form with explicit message-passing that execute directly on the nodes of the distributed-memory machine. The compiler partitions the program using the owner computes rule, by which each processor computes values of data it owns <ref> [7, 28, 37] </ref>. The compiler is subdivided into three major phases|program analysis, program optimization, and code generation. <p> It is particularly useful to consider cross-processor dependences| dependences whose endpoints are executed by different processors. 3.2.1 Message Vectorization A naive but workable algorithm known as runtime resolution inserts guarded send and/or recv operations directly preceding each nonlocal reference <ref> [7, 28, 37] </ref>. Unfortunately, this simple approach generates many small messages that prove extremely inefficient due to communication overhead [18, 28]. The most basic communication optimization performed by the Fortran D compiler is message vector-ization. <p> For these statements the compiler needs to add explicit guards based on membership tests for the local iteration set of the statement <ref> [7, 17, 28, 37] </ref>. 3.3.2 Message Generation The Fortran D compiler uses information calculated in the communication analysis and optimization phases to guide message generation. <p> The inspector strategy is not applicable for unanalyzable references causing loop-carried true dependences. In this case the Fortran D compiler inserts guards to resolve the needed communication and program execution at runtime <ref> [7, 28, 37] </ref>. 3.3.3 Storage Management One of the major responsibilities of the Fortran D compiler is to select and manage storage for all nonlocal array references. There are three different storage schemes. Overlaps Overlaps are expansions of local array sections to accommodate neighboring nonlocal elements [12]. <p> Superb is a semi-automatic parallelization tool that supports arbitrary user-specified contiguous block distributions <ref> [12, 37] </ref>. It originated overlaps as a means to both specify and store nonlocal data accesses. Exsr statements are inserted in the program to communicate overlap regions. Data dependence information is then used to apply loop distribution and vectorize these statements, resulting in vectorized messages.
References-found: 37

