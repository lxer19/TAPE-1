URL: http://graphics.lcs.mit.edu/~satyan/pubs/partition-sas95.ps.Z
Refering-URL: http://graphics.lcs.mit.edu/~satyan/pubs.html
Root-URL: 
Title: Partitioning Non-strict Functional Languages for Multi-threaded Code Generation  
Author: Satyan R. Coorg 
Keyword: Partitioning, abstract interpretation, demand and tolerance sets, inter-procedural analysis, non-strict functional languages.  
Address: NE43-217, 545 Technology Square Cambridge, MA 02139, USA  
Affiliation: MIT Laboratory for Computer Science  
Abstract: In this paper, we present a new approach to partitioning, the problem of generating sequential threads for programs written in a non-strict functional language. The goal of partitioning is to generate threads as large as possible, while retaining the non-strict semantics of the program. We define partitioning as a program transformation and design algorithms for basic block partitioning and inter-procedural partitioning. The inter-procedural algorithm presented here is more powerful than the ones previously known and is based on abstract interpretation, enabling the algorithm to handle recursion in a straightforward manner. We prove the correctness of these algorithms in a denotational semantic framework.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Z. Ariola and Arvind. P-TAC: </author> <title> A Parallel Intermediate Language. </title> <booktitle> In Proceedings of the ACM Conference on Functional Programming Languages and Computer Architecture, </booktitle> <address> London, UK, </address> <pages> pages 230-242. </pages> <publisher> ACM, </publisher> <month> September </month> <year> 1989. </year>
Reference-contexts: Section 6 compares this paper with related work and section 7 concludes. 2 Notation, Syntax and Semantics We design our algorithms on a simple kernel language, SP-TAC (Simple P-TAC) language based on the intermediate language P-TAC (Parallel Three-Address Code) <ref> [1] </ref> that is used during the compilation of Id. SP-TAC is a simple first order functional language, with constants, variables, primitive operators, conditionals, user defined functions and recursive let-blocks.
Reference: 2. <author> A. Bloss. </author> <title> Path Analysis and the Optimization of Non-strict Functional Languages. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Yale University, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: For example, when we refer to nodes in a block, we actually refer to the nodes in the dataflow graph corresponding to the block. 2.3 Semantics The denotational semantics of SP-TAC is based on the semantics given in <ref> [2] </ref> and uses the following domains and functions. <p> There are two issues that need to be addressed here: - (Correctness) We should show that there is a strong relation between the standard semantics defined in section 2 and the path semantics give here. The proof of this is quite long, the reader is referred to <ref> [2, 5] </ref> for details. Basically, the safety of path semantics guarantees that a function always takes one of the paths computed by the path semantics. - (Computability) The algorithm computing paths should terminate on every possible input program. <p> In some cases, demand set partitioning can generate better code than traditional strictness analysis, by making use of the fact that two arguments are always used "together" in a function, even though the function may not be strict in them [20]. Path analysis <ref> [3, 2] </ref> identifies the order in which expressions in a function are evaluated. It has applications in reusing storage, optimizing representation of thunks [2]. <p> Path analysis [3, 2] identifies the order in which expressions in a function are evaluated. It has applications in reusing storage, optimizing representation of thunks <ref> [2] </ref>. Our contribution is to recognize that a restricted definition of paths is very useful in capturing dependence information of functions, and this information can be effectively used in a global partitioning algorithm. Much of the research in partitioning is based on the seminal work in [19].
Reference: 3. <author> A. Bloss and P. Hudak. </author> <title> Path Semantics. </title> <booktitle> In Mathematical Foundations of Programming Language Semantics (LNCS 298). </booktitle> <publisher> Springer-Verlag, </publisher> <month> April </month> <year> 1987. </year>
Reference-contexts: These are similar to the paths introduced in <ref> [3] </ref>, except that the paths in [3] also considered different orderings of the arguments. That is, the path [u; v] was considered different from the path [v; u]. 4 Actually, it is an element of the Egli-Milner Powerdomain of the Paths domain. <p> These are similar to the paths introduced in <ref> [3] </ref>, except that the paths in [3] also considered different orderings of the arguments. That is, the path [u; v] was considered different from the path [v; u]. 4 Actually, it is an element of the Egli-Milner Powerdomain of the Paths domain. <p> The complexity of the algorithm is O (2 MN ) for a function with N-arguments and M-results. Though this is exponential, it is still practical for ordinary programs if the number of arguments of a function is bounded by some small constant. As it subsumes strictness analysis <ref> [3] </ref>, it is not possible to give a more efficient algorithm (strictness analysis requires exponential time [9]). 5.3 Global Partitioning using Paths In this section, we design a global partitioning algorithm using the path analysis described in the previous section. <p> In some cases, demand set partitioning can generate better code than traditional strictness analysis, by making use of the fact that two arguments are always used "together" in a function, even though the function may not be strict in them [20]. Path analysis <ref> [3, 2] </ref> identifies the order in which expressions in a function are evaluated. It has applications in reusing storage, optimizing representation of thunks [2].
Reference: 4. <author> J. Burn, C. Hankin, and S. Abramsky. </author> <title> Strictness Analysis for Higher-order Functions. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 9, </volume> <year> 1986. </year>
Reference-contexts: We have to make sure the "dummy" operators introduced do not fall into any partition. 6 Comparison with Related Work Strictness analysis <ref> [11, 4] </ref> has similar goals to that of partitioning. It tries to determine which arguments of a function are strict, so that they may be evaluated directly instead of building a closure/graph for them, which is significantly more expensive.
Reference: 5. <author> S. R. Coorg. </author> <title> Partitioning Non-strict Languages for Multi-threaded Code Generation. </title> <type> Masters Thesis, </type> <institution> EECS, MIT, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: Design of a new basic block partitioning algorithm. Also, a precise charac terization of the complexity of the partitioning problem. Anew inter-procedural partitioning algorithm based on abstract interpreta tion. Also, the algorithms developed here are proved to be correct in <ref> [5] </ref>. Due to space constraints, we have omitted the proofs from this paper. The rest of the paper is organized as follows. Section 2 defines a simple non-strict kernel language and its semantics. Section 3 formally defines the partitioning problem and the notion of correctness of a partitioning. <p> An important property of the partitioning transformation is that it could at most result in the output values of a block being undefined, but cannot change a fully defined value <ref> [5] </ref>. In designing our algorithms in later sections, we assume that there is no cycle consisting of primitive operators in our input blocks. <p> Do the graphs we construct (G merge ) have any special structure that can be exploited to give a more efficient algorithm? Unfortunately, the answer is no. It is possible to show that finding an optimal partitioning (either minimum number of partitions or largest size partitions) is NP-hard <ref> [5] </ref>. Assuming that we are content with maximal cliques, we can estimate the complexity of the algorithm as follows. The complexity is dominated by the loop in step 3, which merges partitions at each step. The number of such steps is Algorithm 1 Given a basic block b: 1. <p> There are two issues that need to be addressed here: - (Correctness) We should show that there is a strong relation between the standard semantics defined in section 2 and the path semantics give here. The proof of this is quite long, the reader is referred to <ref> [2, 5] </ref> for details. Basically, the safety of path semantics guarantees that a function always takes one of the paths computed by the path semantics. - (Computability) The algorithm computing paths should terminate on every possible input program.
Reference: 6. <author> D. E. Culler, S. C. Goldstein, K. E. Schauser, and T. von Eicken. </author> <title> TAM | A Compiler Controlled Threaded Abstract Machine. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 18(4) </volume> <pages> 347-370, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Each thread is a sequence of instructions and once a thread begins execution, it does not need any dynamic scheduling/synchronization during its execution. Threads of this form yield efficient implementation on conventional architectures using an abstract machine such as TAM <ref> [6] </ref>. They can also be implemented on parallel multi-threaded hardware (e.g., *T [13]). Combining instructions into threads enables more efficient use of registers and amortizes the overhead of dynamic scheduling/synchronization over many instructions.
Reference: 7. <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman, </publisher> <address> San Francisco, CA, </address> <year> 1979. </year>
Reference-contexts: Figure 4 also shows the partitions obtained by algorithm 1 on a basic block. Algorithm 1 generates the largest possible threads if instead of merging maximal cliques, it merged maximum cliques. However, it is well known that finding the maximum clique in a general graph is NP-hard <ref> [7] </ref>. The best known algorithm for this problem takes exponential time in the size of the input graph. Do the graphs we construct (G merge ) have any special structure that can be exploited to give a more efficient algorithm? Unfortunately, the answer is no.
Reference: 8. <author> J. E. Hoch, D. M. Davenprot, V. G. Grafe, and K. M. Steele. </author> <title> Compile-time Partitioning of a Non-strict Language into Sequential Threads. </title> <booktitle> In Proc. Symp. on Parallel and Distributed Processing, </booktitle> <month> Dec </month> <year> 1991. </year>
Reference-contexts: Our work provides the first insight into the complexity of the problem it shows that finding an optimal partitioning (minimum number of partitions or largest possible partitions) is NP-hard even for basic blocks. Developing heuristics to generate safe partitions is the focus of many papers <ref> [8, 17, 16] </ref>. Our technique of using demand and tolerance sets subsume the various heuristics suggested in these papers. Most of these papers did not do any global analysis for partitioning, they used the disconnecting operation used in algorithm 3 to handle conditionals and calls to user defined functions.
Reference: 9. <author> P. Hudak and J. Young. </author> <title> Higher-order Strictness Analysis of the Untyped Lambda-Calculus. </title> <booktitle> In Proc. 12th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 97-109. </pages> <publisher> ACM, </publisher> <month> Jan </month> <year> 1986. </year>
Reference-contexts: Though this is exponential, it is still practical for ordinary programs if the number of arguments of a function is bounded by some small constant. As it subsumes strictness analysis [3], it is not possible to give a more efficient algorithm (strictness analysis requires exponential time <ref> [9] </ref>). 5.3 Global Partitioning using Paths In this section, we design a global partitioning algorithm using the path analysis described in the previous section. Our algorithm is based on the intuition presented in section 5, that is, convert general to basic blocks.
Reference: 10. <editor> Paul Hudak, Simon L. Peyton Jones, and Philip Wadler (editors). </editor> <title> Report on the programming language haskell, a non-strict purely functional language (version 1.2). </title> <journal> SIGPLAN Notices, </journal> <month> Mar, </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Functional programming languages can be divided into two classes: strict and non-strict. In a non-strict language, functions may return values before all their arguments are available, and data structures may be defined before all their components are defined. Many modern functional languages are non-strict; examples include Haskell <ref> [10] </ref> and Id [12]. Such languages give greater expressive power to the programmer than a strict language. Some of the languages provide non-strictness because of its cleaner semantics. Others, like Id, also use non-strictness to generate parallelism in a program.
Reference: 11. <author> A. Mycroft. </author> <title> The Theory and Practice of Transforming Call-by-need into Call-by-value. </title> <booktitle> In International Symposium on Programming (LNCS 83). </booktitle> <publisher> Springer-Verlag, </publisher> <month> April </month> <year> 1980. </year>
Reference-contexts: We have to make sure the "dummy" operators introduced do not fall into any partition. 6 Comparison with Related Work Strictness analysis <ref> [11, 4] </ref> has similar goals to that of partitioning. It tries to determine which arguments of a function are strict, so that they may be evaluated directly instead of building a closure/graph for them, which is significantly more expensive.
Reference: 12. <author> R. S. Nikhil. </author> <title> Id Language Reference Manual Version 90.1. </title> <type> Technical Report CSG Memo 284-2, </type> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cam-bridge, MA 02139, </address> <month> July 15 </month> <year> 1991. </year>
Reference-contexts: In a non-strict language, functions may return values before all their arguments are available, and data structures may be defined before all their components are defined. Many modern functional languages are non-strict; examples include Haskell [10] and Id <ref> [12] </ref>. Such languages give greater expressive power to the programmer than a strict language. Some of the languages provide non-strictness because of its cleaner semantics. Others, like Id, also use non-strictness to generate parallelism in a program.
Reference: 13. <author> R.S. Nikhil, G.M. Papadopoulos, and Arvind. </author> <title> *T: A Multithreaded Massively Parallel Architecture. </title> <booktitle> In Proc. 19th Annual Intl. Symp. on Computer Architecture, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: Threads of this form yield efficient implementation on conventional architectures using an abstract machine such as TAM [6]. They can also be implemented on parallel multi-threaded hardware (e.g., *T <ref> [13] </ref>). Combining instructions into threads enables more efficient use of registers and amortizes the overhead of dynamic scheduling/synchronization over many instructions. Partitioning attempts to make threads as large as possible, to enable efficient execution of non-strict programs on microprocessors.
Reference: 14. <author> G. Papadopoulos and D. Culler. Monsoon: </author> <title> an Explicit Token-Store Architecture. </title> <booktitle> In Proc. of the 17th Intl. Symp. on Computer Architecture, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: Some of the languages provide non-strictness because of its cleaner semantics. Others, like Id, also use non-strictness to generate parallelism in a program. Compiling non-strict languages to conventional microprocessors has been the focus of many recent papers [20, 17, 16]. Unlike research microprocessors like Monsoon <ref> [14] </ref>, these do not have any hardware support for fast synchronization y The research described in this paper was funded in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N00014-92-J-1310. fl Email:satyan@lcs.mit.edu, Phone: 617-253-8858, Fax: 617-253-6652. and context switching.
Reference: 15. <author> K. E. Schauser. </author> <title> Compiling Lenient Languages for Parallel Asynchronous Execution. </title> <type> PhD thesis, </type> <institution> Computer Science Div., Univ. of California at Berkeley., </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: Our algorithm has no such limitations, as the paths of recursive functions are well-defined and our inter-procedural algorithm is based only on a function's paths. Independent of this work, the partitioning algorithms in [20] have been extended in <ref> [16, 15] </ref> to generate maximal partitions for basic blocks and to handle recursive functions. Algorithm 1 for partitioning basic blocks is equivalent to the one presented in [15], though it is a different formulation and its complexity is slightly better. <p> Independent of this work, the partitioning algorithms in [20] have been extended in [16, 15] to generate maximal partitions for basic blocks and to handle recursive functions. Algorithm 1 for partitioning basic blocks is equivalent to the one presented in <ref> [15] </ref>, though it is a different formulation and its complexity is slightly better. The inter-procedural algorithm given in [15] differs from algo-rithm 3 in that it still uses dependence and demand sets to propagate global information, and thus retains some of the limitations of [20]. <p> Algorithm 1 for partitioning basic blocks is equivalent to the one presented in <ref> [15] </ref>, though it is a different formulation and its complexity is slightly better. The inter-procedural algorithm given in [15] differs from algo-rithm 3 in that it still uses dependence and demand sets to propagate global information, and thus retains some of the limitations of [20]. However, the complexity of our inter-procedural algorithm is higher than that of the algorithm in [15]. 7 Conclusions and Extensions In this paper, we <p> The inter-procedural algorithm given in <ref> [15] </ref> differs from algo-rithm 3 in that it still uses dependence and demand sets to propagate global information, and thus retains some of the limitations of [20]. However, the complexity of our inter-procedural algorithm is higher than that of the algorithm in [15]. 7 Conclusions and Extensions In this paper, we have presented new algorithms for partitioning non-strict functional languages. We have presented a new algorithm for basic block partitioning and characterized the complexity of the problem. We have extended the basic block algorithms to propagate information globally.
Reference: 16. <author> K. E. Schauser, D. Culler, and S. C. Goldstein. </author> <title> Separation Constraint Partitioning ANew Algorithm for Partitioning Non-strict Programs into Sequential Threads. </title> <booktitle> In Proc. ACM Conference on Principles of Programming Languages (POPL), </booktitle> <month> Jan-uary </month> <year> 1995. </year>
Reference-contexts: Some of the languages provide non-strictness because of its cleaner semantics. Others, like Id, also use non-strictness to generate parallelism in a program. Compiling non-strict languages to conventional microprocessors has been the focus of many recent papers <ref> [20, 17, 16] </ref>. <p> Our work provides the first insight into the complexity of the problem it shows that finding an optimal partitioning (minimum number of partitions or largest possible partitions) is NP-hard even for basic blocks. Developing heuristics to generate safe partitions is the focus of many papers <ref> [8, 17, 16] </ref>. Our technique of using demand and tolerance sets subsume the various heuristics suggested in these papers. Most of these papers did not do any global analysis for partitioning, they used the disconnecting operation used in algorithm 3 to handle conditionals and calls to user defined functions. <p> Our algorithm has no such limitations, as the paths of recursive functions are well-defined and our inter-procedural algorithm is based only on a function's paths. Independent of this work, the partitioning algorithms in [20] have been extended in <ref> [16, 15] </ref> to generate maximal partitions for basic blocks and to handle recursive functions. Algorithm 1 for partitioning basic blocks is equivalent to the one presented in [15], though it is a different formulation and its complexity is slightly better.
Reference: 17. <author> K. E. Schauser, D. Culler, and von Eicken T. </author> <booktitle> Compiler-controlled Multithread-ing for Lenient Parallel Languages. In Proc. Conf. on Functional Programming Languages and Computer Architecture, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: Some of the languages provide non-strictness because of its cleaner semantics. Others, like Id, also use non-strictness to generate parallelism in a program. Compiling non-strict languages to conventional microprocessors has been the focus of many recent papers <ref> [20, 17, 16] </ref>. <p> Our work provides the first insight into the complexity of the problem it shows that finding an optimal partitioning (minimum number of partitions or largest possible partitions) is NP-hard even for basic blocks. Developing heuristics to generate safe partitions is the focus of many papers <ref> [8, 17, 16] </ref>. Our technique of using demand and tolerance sets subsume the various heuristics suggested in these papers. Most of these papers did not do any global analysis for partitioning, they used the disconnecting operation used in algorithm 3 to handle conditionals and calls to user defined functions.
Reference: 18. <author> K. R. Traub. </author> <title> A Compiler for the MIT Tagged-Token Dataflow Architecture. </title> <type> Technical Report TR-370, </type> <institution> MIT Lab. for Computer Science, </institution> <month> August </month> <year> 1986. </year> <type> (MS Thesis, </type> <institution> Dept. of EECS, MIT). </institution>
Reference-contexts: This representation (called a dataflow graph) is similar to the one used in the Id compiler to perform various optimizations <ref> [18] </ref>. The language syntax shown in the previous section is essentially a textual representation of these dataflow graphs. Definition 1 Dataflow Graph. Given a block b, the dataflow graph G (b) corresponding to b is a directed graph.
Reference: 19. <author> K. R. Traub. </author> <title> Implementation of Non-strict Functional Programming Languages. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: Synchronization is also expensive in these processors since it has to be explicitly performed (in software) using instructions. For programs in a non-strict language, it is not always possible at compile-time to specify an exact ordering of instructions. The goal of partitioning <ref> [19] </ref> is to infer the possible dependencies in a program and use that information to sequentialize parts of a program. This is achieved by compiling each function into a set of threads while preserving the function's non-strict semantics. <p> Partitioning attempts to make threads as large as possible, to enable efficient execution of non-strict programs on microprocessors. Functions in our language can accept undefined arguments and return partial results. This is termed the lenient strategy <ref> [19] </ref>. Another strategy that provides non-strictness is the lazy evaluation strategy, where the evaluation of an expression is delayed until the execution cannot proceed without the value of that expression. Unlike lenient evaluation, lazy evaluation also gives the user the ability to manipulate infinite data structures. <p> Partitioning techniques could be useful in compiling lazy functional languages too. The difference is that the choice for partitioning algorithms is restricted: only demand set partitioning preserves laziness <ref> [19] </ref>. In some cases, demand set partitioning can generate better code than traditional strictness analysis, by making use of the fact that two arguments are always used "together" in a function, even though the function may not be strict in them [20]. <p> Our contribution is to recognize that a restricted definition of paths is very useful in capturing dependence information of functions, and this information can be effectively used in a global partitioning algorithm. Much of the research in partitioning is based on the seminal work in <ref> [19] </ref>. It defined the partitioning problem, its relation to dependence analysis and provided some insight into the partitioning problem by proving a related problem NP-hard.
Reference: 20. <author> K. R. Traub, D. E. Culler, and K. E. Schauser. </author> <title> Global Analysis for Partitioning Non-strict Programs into Sequential Threads. </title> <booktitle> In Proc. of the ACM Conf. on LISP and Functional Programming, </booktitle> <month> June </month> <year> 1992. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: Some of the languages provide non-strictness because of its cleaner semantics. Others, like Id, also use non-strictness to generate parallelism in a program. Compiling non-strict languages to conventional microprocessors has been the focus of many recent papers <ref> [20, 17, 16] </ref>. <p> In some cases, demand set partitioning can generate better code than traditional strictness analysis, by making use of the fact that two arguments are always used "together" in a function, even though the function may not be strict in them <ref> [20] </ref>. Path analysis [3, 2] identifies the order in which expressions in a function are evaluated. It has applications in reusing storage, optimizing representation of thunks [2]. <p> Also, these algorithms did not produce maximal partitions, i.e., even after these algorithms terminated, it was possible that there are two partitions that could be merged safely. An inter-procedural algorithm for partitioning was first designed in <ref> [20] </ref>. This algorithm is based on the idea that the demand/dependence sets themselves contain some dependence information, and propagating these sets between the definition of a function to its call-site yields better partitions. A major limitation of the inter-procedural algorithm given there is its inability to handle recursive functions. <p> A major limitation of the inter-procedural algorithm given there is its inability to handle recursive functions. Our algorithm has no such limitations, as the paths of recursive functions are well-defined and our inter-procedural algorithm is based only on a function's paths. Independent of this work, the partitioning algorithms in <ref> [20] </ref> have been extended in [16, 15] to generate maximal partitions for basic blocks and to handle recursive functions. Algorithm 1 for partitioning basic blocks is equivalent to the one presented in [15], though it is a different formulation and its complexity is slightly better. <p> The inter-procedural algorithm given in [15] differs from algo-rithm 3 in that it still uses dependence and demand sets to propagate global information, and thus retains some of the limitations of <ref> [20] </ref>. However, the complexity of our inter-procedural algorithm is higher than that of the algorithm in [15]. 7 Conclusions and Extensions In this paper, we have presented new algorithms for partitioning non-strict functional languages.
References-found: 20

