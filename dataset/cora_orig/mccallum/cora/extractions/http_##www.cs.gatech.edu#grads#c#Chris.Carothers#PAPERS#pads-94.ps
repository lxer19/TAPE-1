URL: http://www.cs.gatech.edu/grads/c/Chris.Carothers/PAPERS/pads-94.ps
Refering-URL: http://www.cs.gatech.edu/grads/c/Chris.Carothers/homepage.html
Root-URL: 
Title: Effect of Communication Overheads on Time Warp Performance: An Experimental Study  
Author: Christopher D. Carothers and Richard M. Fujimoto Paul England 
Address: Atlanta, Georgia 30332 Morristown, New Jersey 07962  
Affiliation: College of Computing MRE-2L-336 Georgia Institute of Technology Bellcore  
Abstract: This paper describes results of an empirical study to evaluate the effect of communications delays on the performance of the Time Warp mechanism in order to assess the effectiveness of Time Warp in distributed computing evironments. An implementation of Time Warp on a collection of networked workstations is used in this study. Performance using synchronous and asynchronous message passing primitives are compared, and it is observed that Time Warp experiences much more rolled back computation when using the synchronous primitives for certain applications. Message passing is decomposed into a computation component at the sender and receiver processors, and a transmission delay component that represents the amount of time the message remains in transit within the network. The effect of each of these components on Time Warp performance is studied. It is observed that communications latency in distributed computing environments can significantly degrade the efficiency of Time Warp for applications containing large numbers of simulator objects with small event granularity (by increasing the amount of rolled back computation), particularly applications using self-driving simulator objects. However, for applications containing large grained events, communication delay appears to have little effect on rollback behavior in Time Warp. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Briner, Jr. </author> <title> Fast parallel simulation of digital systems. </title> <booktitle> In Advances in Parallel and Distributed Simulation, </booktitle> <volume> volume 23, </volume> <pages> pages 71-77. </pages> <booktitle> SCS Simulation Series, </booktitle> <month> January </month> <year> 1991. </year>
Reference-contexts: Numerous analytic and empirical studies of the performance of Time Warp have been performed, e.g., see [8, 7] for recent surveys. Time Warp has demonstrated good success in speeding up simulations of combat models [17], communication networks [14], queueing networks [5], and digital logic circuits <ref> [1] </ref>, among others. The bulk of the research that has been performed thus far has focused on execution of multiprocessor and multicomputer systems with fast interprocessor communications.
Reference: [2] <author> R. Brown. </author> <title> Calendar queues: A fast O(1) priority queue implementation for the simulation event set problem. </title> <journal> Communications of the ACM, </journal> <volume> 31(10) </volume> <pages> 1220-1227, </pages> <month> Oct. </month> <year> 1988. </year>
Reference-contexts: It is anticipated that many simulations will contain thousands of objects on each processor. A priority queue data structure called the calendar queue <ref> [2] </ref> is used in each processor to efficiently select the next object to execute. The processor's scheduler always selects the object containing the smallest timestamped event as the next one for execution.
Reference: [3] <author> C. D. Carothers, R. M. Fujimoto, Y-B. Lin, and P. </author> <title> England. Distributed simulation of large-scale pcs networks. </title> <booktitle> In Proceedings of the 1994 MASCOTS Conference, </booktitle> <month> January </month> <year> 1994. </year>
Reference-contexts: The behavior of a portable is modeled by different types of events, such as portable move, call arrival, and call completion. A detailed description of this application is presented in <ref> [3] </ref>. Unlike the PHOLD model, this application's ILAR is extremely poor (ILAR = 0:0), due to zero time stamp increment event for portable moves between cells.
Reference: [4] <author> D. C. Cox. </author> <title> Personal Communications A Viewpoint. </title> <journal> IEEE Communications Magazine, </journal> <volume> 128(11), </volume> <year> 1990. </year>
Reference-contexts: For the first category, simulations with large-grained events, we used a benchmark based on the PHOLD synthetic workload model [6]. For the second category, we used a simulation of a personal communication services (PCS) network <ref> [4] </ref>. Each of these are described next. PHOLD is a simulation using a synthetic workload model [6]. The simulation consists of a fixed message population that move among the objects making up the simulation.
Reference: [5] <author> R. M. Fujimoto. </author> <title> Time Warp on a shared memory multiprocessor. </title> <journal> Transactions of the Society for Computer Simulation, </journal> <volume> 6(3) </volume> <pages> 211-239, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Numerous analytic and empirical studies of the performance of Time Warp have been performed, e.g., see [8, 7] for recent surveys. Time Warp has demonstrated good success in speeding up simulations of combat models [17], communication networks [14], queueing networks <ref> [5] </ref>, and digital logic circuits [1], among others. The bulk of the research that has been performed thus far has focused on execution of multiprocessor and multicomputer systems with fast interprocessor communications.
Reference: [6] <author> R. M. Fujimoto. </author> <title> Performance of Time Warp under synthetic workloads. </title> <booktitle> In Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <volume> volume 22, </volume> <pages> pages 23-28. </pages> <booktitle> SCS Simulation Series, </booktitle> <month> January </month> <year> 1990. </year>
Reference-contexts: For the first category, simulations with large-grained events, we used a benchmark based on the PHOLD synthetic workload model <ref> [6] </ref>. For the second category, we used a simulation of a personal communication services (PCS) network [4]. Each of these are described next. PHOLD is a simulation using a synthetic workload model [6]. The simulation consists of a fixed message population that move among the objects making up the simulation. <p> the first category, simulations with large-grained events, we used a benchmark based on the PHOLD synthetic workload model <ref> [6] </ref>. For the second category, we used a simulation of a personal communication services (PCS) network [4]. Each of these are described next. PHOLD is a simulation using a synthetic workload model [6]. The simulation consists of a fixed message population that move among the objects making up the simulation. The processing of a message consists of computing for a certain amount of time and then sending one new message to another simulator object with a certain timestamp increment. <p> The timestamp increment is selected from an exponential distribution. The inverse lookahead ratio (ILAR) <ref> [6] </ref>, which characterizes the degree to which processes can look ahead into the simulated future, for this application is 1:0, the maximum value. The fan-in 3 for PHOLD is 4,while the fan-out 4 is 1.
Reference: [7] <author> R. M. Fujimoto. </author> <title> Parallel and distributed discrete event simulation: </title> <booktitle> Algorithms and applications. In 1993 Winter Simulation Conference Proceedings, </booktitle> <month> December </month> <year> 1993. </year>
Reference-contexts: Numerous analytic and empirical studies of the performance of Time Warp have been performed, e.g., see <ref> [8, 7] </ref> for recent surveys. Time Warp has demonstrated good success in speeding up simulations of combat models [17], communication networks [14], queueing networks [5], and digital logic circuits [1], among others.
Reference: [8] <author> R. M. Fujimoto and D. M. Nicol. </author> <title> State of the art in parallel simulation. </title> <booktitle> In 1992 Winter Simulation Conference Proceedings, </booktitle> <pages> pages 122-127, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Numerous analytic and empirical studies of the performance of Time Warp have been performed, e.g., see <ref> [8, 7] </ref> for recent surveys. Time Warp has demonstrated good success in speeding up simulations of combat models [17], communication networks [14], queueing networks [5], and digital logic circuits [1], among others.
Reference: [9] <author> Brian K. Grant and Anthony Skjellum. </author> <title> The pvm systems: An indepth analysis and documenting study consise edition. Unpublished work, </title> <month> Aug </month> <year> 1992. </year>
Reference-contexts: For a detailed description of PVM 2.4, see <ref> [9] </ref>. PVM was designed using a master-slave approach to distributed computing. To begin a PVM application, the master PVM daemon is started.
Reference: [10] <author> A. Gupta, I. F. Akyildiz, and R. M. Fujimoto. </author> <title> Performance analysis of Time Warp with multiple homogenousprocessors. </title> <journal> IEEE Transactions on Software Engineering,17(10):1013-1027, </journal> <month> Oc-tober </month> <year> 1991. </year>
Reference-contexts: Accordingly, PVM's synchronous message mechanism can lead to instabilities caused by large send and receive computation times. The 75K portables case differs from the 50K portables case because the processor has become saturated with local work and is unable to progress in simulated time at a rapid rate. In <ref> [10] </ref>, it is observed that as the message population approaches 1, the efficiency of Time Warp approaches 100%. Because of the large number of portables, a similar effect is observed in the 75k portables case, which accounts for PVM`s 95% efficiency.
Reference: [11] <author> D. R. Jefferson. </author> <title> Virtual time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(3) </volume> <pages> 404-425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: 1 Introduction Time Warp <ref> [11] </ref> is an optimistic synchronization protocol that uses runtime detection of errors caused by out of order execution of dependent simulator events, and recovery using a rollback mechanism.
Reference: [12] <author> B. Lubachevsky, A. Weiss, and A. Shwartz. </author> <title> An analysis of rollback-based simulation. </title> <journal> ACM Transactions on Modeling and Computer Simulation, </journal> <volume> 1(2) </volume> <pages> 154-192, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: This effect is more pronounced in low granularity simulations such as the PCS benchmark. The use of synchronous message sends can, in fact, lead to situations where extremely poor performance is obtained. To illustrate this point, consider the echo example discussed in <ref> [12] </ref>. The system is composed of two queues, A and B, and two types of customers, 1 and 2. Type 1 customers have preemptive priority over type 2 customers. When an interrupted type 2 customer is resubmitted, it must restart its service from the beginning.
Reference: [13] <author> N. Manjikian and W. M. Loucks. </author> <title> High performance parallel logic simulation on a network of workstations. </title> <booktitle> In 7 th Workshop on Parallel and Distributed Simulation, </booktitle> <volume> volume 23, </volume> <pages> pages 76-84. </pages> <booktitle> SCS Simulation Series, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Each object will typically contain only a small amount of state. Large-scale simulations of telecommunication networks where each event might do little more than route data packets or place them in queues is an example of this type of simulation. Simulation of logic networks are a second example <ref> [15, 13] </ref>. Because there are so many objects, each processor may have thousands of objects mapped to it. The requirement of infrequent interprocessor communications will be satisfied if most communications occur between objects that are mapped to the same processor.
Reference: [14] <author> M. Presley, M. Ebling, F. Wieland, and D. R. Jefferson. </author> <title> Bench-marking the Time Warp Operating System with a computer network simulation. </title> <booktitle> In Proceedings of the SCS Multiconfer-ence on Distributed Simulation, </booktitle> <volume> volume 21, </volume> <pages> pages 8-13. </pages> <booktitle> SCS Simulation Series, </booktitle> <month> March </month> <year> 1989. </year>
Reference-contexts: Numerous analytic and empirical studies of the performance of Time Warp have been performed, e.g., see [8, 7] for recent surveys. Time Warp has demonstrated good success in speeding up simulations of combat models [17], communication networks <ref> [14] </ref>, queueing networks [5], and digital logic circuits [1], among others. The bulk of the research that has been performed thus far has focused on execution of multiprocessor and multicomputer systems with fast interprocessor communications.
Reference: [15] <author> C. Sporrer and H. Bauer. </author> <title> Corolla partitioning for distributed logic simulation of vlsi-circuits. </title> <booktitle> In 7 th Workshop on Parallel and Distributed Simulation, </booktitle> <volume> volume 23, </volume> <pages> pages 85-92. </pages> <booktitle> SCS Simulation Series, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Each object will typically contain only a small amount of state. Large-scale simulations of telecommunication networks where each event might do little more than route data packets or place them in queues is an example of this type of simulation. Simulation of logic networks are a second example <ref> [15, 13] </ref>. Because there are so many objects, each processor may have thousands of objects mapped to it. The requirement of infrequent interprocessor communications will be satisfied if most communications occur between objects that are mapped to the same processor.
Reference: [16] <author> J. S. Steinman. </author> <title> Breathing time warp. </title> <booktitle> In 7 th Workshop on Parallel and Distributed Simulation, </booktitle> <volume> volume 23, </volume> <pages> pages 109-118. </pages> <booktitle> SCS Simulation Series, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: The first are those applications that contain a substantial amount of computation per event. For instance, models involving projectiles in free flight (e.g., missiles) fall into this category because a substantial amount of computation is required to compute trajectories <ref> [16] </ref>. A second class of applications involves simulation of large numbers, (thousands or tens of thousands), of light weight objects with relatively little computation in each event. Each object will typically contain only a small amount of state.
Reference: [17] <author> F. Wieland, L. Hawley, A. Feinberg, M. DiLorento, L. Blume, P. Reiher, B. Beckman, P. Hontalas, S. Bellenot, and D. R. Jefferson. </author> <title> Distributed combat simulation and Time Warp: The model and its performance. </title> <booktitle> In Proceedings of the SCS Multi-conference on Distributed Simulation, </booktitle> <volume> volume 21, </volume> <pages> pages 14-20. </pages> <booktitle> SCS Simulation Series, </booktitle> <month> March </month> <year> 1989. </year>
Reference-contexts: Numerous analytic and empirical studies of the performance of Time Warp have been performed, e.g., see [8, 7] for recent surveys. Time Warp has demonstrated good success in speeding up simulations of combat models <ref> [17] </ref>, communication networks [14], queueing networks [5], and digital logic circuits [1], among others. The bulk of the research that has been performed thus far has focused on execution of multiprocessor and multicomputer systems with fast interprocessor communications.
References-found: 17

