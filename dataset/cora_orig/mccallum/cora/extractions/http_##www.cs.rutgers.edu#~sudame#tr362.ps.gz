URL: http://www.cs.rutgers.edu/~sudame/tr362.ps.gz
Refering-URL: http://www.cs.rutgers.edu/~sudame/
Root-URL: http://www.cs.rutgers.edu
Email: fbadri,sudameg@cs.rutgers.edu  
Title: An efficient multi-point to point aggregation mechanism in IP networks  
Author: B. R. Badrinath Pradeep Sudame 
Date: July 26, 1998  
Address: Piscataway, NJ 08855  
Affiliation: Department of Computer Science Rutgers University  
Note: Gathercast:  
Abstract: Technical Report No. 362, Department of Computer Science, Rutgers University 1 Abstract IP multicast is an efficient point to multi-point protocol. However, a number of scenarios exist where the reverse mechanism of multi-point to point protocol is needed. Gathercast is a mechanism by which packet flows from a large number of nodes can be gathered as the packets are routed towards the gatherer. Gathercast uses transformer tunnels [1] at routers to provide a mechanism for aggregating packets directed towards a node. Increased goodput for applications that need flow aggregation can be obtained by using any of a number of transformation functions such as recombination of small packets, compressing data, rate control, replication removal, and so on, along a distribution tree. Gathercast works well in conjunction with the current IP multicast model. Simulations results for gathercast show that using aggregators along a gather tree improves the network utilization.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Sudame and B. R. Badrinath, </author> <title> "Transformer tunnels: A framework for providing route-specific adaptations," </title> <booktitle> in Proceedings of the USENIX Annual Technical Conference, </booktitle> <month> June </month> <year> 1998. </year>
Reference-contexts: Gathercast, on the other hand, addresses the reverse problem: how to gather information from a large number of nodes with the objective of increasing goodput. We have already developed the concept of transformer tunnels <ref> [1] </ref>. A transformer tunnel can be programmed to optimize a flow for a given link. In gathercast, we propose to use transformer tunnels in the context of IP multicast where transformer tunnels are established over paths leading to the gatherer.
Reference: [2] <author> S. Deering, </author> <title> Multicast Routing in a Datagram Internetwork. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> Dec. </month> <year> 1990. </year> <month> ftp://gregorio.stanford.edu/vmtp-ip/sdthesis[123].ps.Z. </month>
Reference-contexts: 1 Introduction The number of end-user devices reachable by the Internet is increasing at a tremendous rate. Scalable mechanisms for not only distributing data but also for gathering data from such devices are needed. IP Multicast <ref> [2] </ref> provides an efficient mechanism for point to multi-point packet distribution such as multimedia communication and group communication [3]. In this paper, we propose the concept of gathercast, an efficient mechanism for large scale gathering of data from a large set of nodes.
Reference: [3] <author> N. L. </author> <note> for Applied Research, "ICP working group." http://ircache.nlanr.net/Cache/ICP/. </note>
Reference-contexts: Scalable mechanisms for not only distributing data but also for gathering data from such devices are needed. IP Multicast [2] provides an efficient mechanism for point to multi-point packet distribution such as multimedia communication and group communication <ref> [3] </ref>. In this paper, we propose the concept of gathercast, an efficient mechanism for large scale gathering of data from a large set of nodes.
Reference: [4] <author> S. Elord, G. Hall, R. Costanza, M. Dixon, and J. </author> <title> des Rivieres, "The responsive environment," </title> <type> Tech. Rep. </type> <institution> CSL-93-5, Xerox Park, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: In this paper, we propose the concept of gathercast, an efficient mechanism for large scale gathering of data from a large set of nodes. Applications that need such a mechanism include sensor networks, smart spaces, responsive environments <ref> [4] </ref>, situation awareness (where soldiers periodically send update messages about their location), remote utility metering, web servers [5], cache state from cache servers, gathering web (Nielsen) ratings to determine clicking habits of users, and monitoring the status of devices at home or office [6].
Reference: [5] <author> S. Gribble, </author> <title> "UC Berkeley Home IP Web Traces." </title> <address> http://www.cs.berkeley.edu/~gribble/traces/index.html. </address>
Reference-contexts: Applications that need such a mechanism include sensor networks, smart spaces, responsive environments [4], situation awareness (where soldiers periodically send update messages about their location), remote utility metering, web servers <ref> [5] </ref>, cache state from cache servers, gathering web (Nielsen) ratings to determine clicking habits of users, and monitoring the status of devices at home or office [6]. <p> Such a distribution represents a sensor network application where the devices send status report periodically. In the second method, we used a packet trace obtained from University of California at Berkeley <ref> [5] </ref>. This trace represents packets generated by various clients. The trace was collected at web proxies. In both the methods, every node delayed packets by at most 10 seconds.
Reference: [6] <author> V. Cerf, </author> <title> "Keynote address." </title> <booktitle> Infocom 97, </booktitle> <address> Kobe, Japan, </address> <month> March </month> <year> 1997. </year>
Reference-contexts: include sensor networks, smart spaces, responsive environments [4], situation awareness (where soldiers periodically send update messages about their location), remote utility metering, web servers [5], cache state from cache servers, gathering web (Nielsen) ratings to determine clicking habits of users, and monitoring the status of devices at home or office <ref> [6] </ref>. In all these situations, we have the problem of a large number of nodes sending small updates to another node (a gatherer) that gathers or monitors information in such networks. These updates may be periodic, spontaneous, or in response to a query from the gatherer.
Reference: [7] <author> L. Fan, P. Cao, and J. A. anndrei Z. Broder, </author> <title> "Summary cache: A scalable wide-area web cache sharing protocol." </title> <note> To appear in SIGCOMM'98. </note>
Reference-contexts: These updates may be periodic, spontaneous, or in response to a query from the gatherer. Even in today's networks, in the context of web cache updates, there is evidence of small packet traffic originating from a set of nodes to another node <ref> [7] </ref>. Also, the packet trace at MIT [8] shows that replicated packets (packets with identical payloads) form a significant fraction of the total number of packets in a network.
Reference: [8] <author> J. Santos and D. Wetherall, </author> <title> "Increasing effective link bandwidth by suppressing replicated data," </title> <booktitle> in Proceedings of the USENIX Annual Technical Conference, </booktitle> <month> June </month> <year> 1998. </year>
Reference-contexts: These updates may be periodic, spontaneous, or in response to a query from the gatherer. Even in today's networks, in the context of web cache updates, there is evidence of small packet traffic originating from a set of nodes to another node [7]. Also, the packet trace at MIT <ref> [8] </ref> shows that replicated packets (packets with identical payloads) form a significant fraction of the total number of packets in a network. Thus, a scalable mechanism for gathering information sent by a large number of entities, without overwhelming the receiver and the network, is needed. <p> The reassembly function combines small packets to form a larger packet. This reduces the number of packets within the network and also reduces load at the receiver by reducing the number of interrupts generated. The replication-removal function <ref> [8] </ref> reduces redundancy in the data packets flowing over a link by sending identical payloads only once across the link. This paper is organized as follows. Section 3 describes what aggregation functions are meaningful in the context of gathercast. Section 4 gives the details of the gathercast protocol. <p> It also improves the gatherer performance by reducing the number of interrupts the gatherer receives because of incoming packets. 3.3 Replication removal The MIT trace <ref> [8] </ref> shows that in today's networks, there is a significant number of replicated packets. Since all the replicated packets carry identical payloads (and hence have the same md5 6 fingerprint), payload needs to be sent only with the first packet.
Reference: [9] <author> S. Floyd, V. Jacobson, S. McCanne, C.-G. Liu, and L. Zhang, </author> <title> "A reliable multicast framework for light-weight sessions and application level framing," </title> <booktitle> in Proceedings of the ACM SIGCOMM, </booktitle> <pages> pp. 342-356, </pages> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: Section 6 explains how we 2 evaluated the gathercast protocol. The paper concludes with a description of possible extensions of this work. 2 Related Work There are mechanisms that require network participation for increasing the goodput. For example, many reliable multicast schemes <ref> [9, 10, 11, 12] </ref> propose suppressing NACKs to solve the problem of NACK implosion. In such schemes, if a node within the network receives identical NACKs from multiple nodes, it forwards just one NACK to the source.
Reference: [10] <author> L. wei H. Lehman, S. J. Garland, and D. L. Tennenhouse, </author> <title> "Active reliable multicast," </title> <booktitle> in Proceedings of the INFOCOM, </booktitle> <year> 1998. </year>
Reference-contexts: Section 6 explains how we 2 evaluated the gathercast protocol. The paper concludes with a description of possible extensions of this work. 2 Related Work There are mechanisms that require network participation for increasing the goodput. For example, many reliable multicast schemes <ref> [9, 10, 11, 12] </ref> propose suppressing NACKs to solve the problem of NACK implosion. In such schemes, if a node within the network receives identical NACKs from multiple nodes, it forwards just one NACK to the source.
Reference: [11] <author> C. Papadopoulos and G. Varghese, </author> <title> "An error control scheme for large-scale multicast applications," </title> <booktitle> in Proceedings of the INFOCOM, </booktitle> <year> 1998. </year>
Reference-contexts: Section 6 explains how we 2 evaluated the gathercast protocol. The paper concludes with a description of possible extensions of this work. 2 Related Work There are mechanisms that require network participation for increasing the goodput. For example, many reliable multicast schemes <ref> [9, 10, 11, 12] </ref> propose suppressing NACKs to solve the problem of NACK implosion. In such schemes, if a node within the network receives identical NACKs from multiple nodes, it forwards just one NACK to the source. <p> can therefore control parameters at all the routers in the network. 6 Evaluation For evaluating the impact of gathercast, we used three different tree configurations: a complete binary tree with fifteen nodes, a complete binary tree with 127 nodes, and a tree (given in the paper by Papadopoulos et al. <ref> [11] </ref>.) for simulating a WAN topology.
Reference: [12] <author> T. Speakman, D. Farinacci, S. Lin, and A. Tweedly, </author> <title> "PGM Reliable transport protocol specification," 1998. Internet draft, Work in progress. [13] "CU-SeeMe Project." </title> <publisher> ftp://gated.cornell.edu/pub/video. </publisher>
Reference-contexts: Section 6 explains how we 2 evaluated the gathercast protocol. The paper concludes with a description of possible extensions of this work. 2 Related Work There are mechanisms that require network participation for increasing the goodput. For example, many reliable multicast schemes <ref> [9, 10, 11, 12] </ref> propose suppressing NACKs to solve the problem of NACK implosion. In such schemes, if a node within the network receives identical NACKs from multiple nodes, it forwards just one NACK to the source. <p> We use transformer tunnels for this purpose also. The transformation function attached to the tunnel encapsulates the packets in a multicast message with TTL value 1 (same as for join messages used by the DVMRP [22] and PGM <ref> [12] </ref>). The tunnel also adds metadata to the packet indicating a special 11 reverse transformation function, multicast-lookup (that looks at the multicast routing table at the receiver and find out the previous-hop router), should be performed by the receiver of this packet.
Reference: [14] <author> D. L. Tennenhouse, J. M. Smith, W. D. Sincoskie, D. J. Wetherall, and G. Minden, </author> <title> "A survey of active network research," </title> <journal> in IEEE Communications, </journal> <month> Jan. </month> <year> 1997. </year>
Reference-contexts: Loss reports are sent back up the distribution tree via the reflectors. Reflectors can also collapse loss reports. Gathercast provides a generic mechanism for aggregating data from a number of sources, and allows applications to use either multicast or unicast as the underlying transport mechanism. Active networks <ref> [14] </ref> suggest use of internal nodes for combining information from multiple nodes (fusion). Gathercast is a special case of such active networks where programmability of the internal nodes is achieved using transformer tunnels. 3 Aggregators Transformer tunnels provide a uniform mechanism to transform packet flows in a network.
Reference: [15] <author> M. Degermark and S. Pink, </author> <title> "Soft state header compression for wireless networks," </title> <booktitle> in Proceedings of the 2nd MOBICOM Conference, </booktitle> <pages> pp. 1-14, </pages> <month> Nov. </month> <year> 1996. </year>
Reference-contexts: Header compression techniques <ref> [15, 16] </ref> have been proposed to improve performance for such links. On very slow links, compressing the data portion leads to even more gains [17, 18]. Compressing data is not useful on fast links, because the compression and decom 4 pression overheads offset the savings obtained by sending fewer bits.
Reference: [16] <author> V. Jacobson, </author> <title> "RFC 1144: Compressing TCP/IP headers for low speed serial links," </title> <year> 1990. </year>
Reference-contexts: Header compression techniques <ref> [15, 16] </ref> have been proposed to improve performance for such links. On very slow links, compressing the data portion leads to even more gains [17, 18]. Compressing data is not useful on fast links, because the compression and decom 4 pression overheads offset the savings obtained by sending fewer bits.
Reference: [17] <author> A. Sacham, R. Monsour, R. Pereiera, and M. Thomas, </author> <title> "IP payload compression protocol (IPComp)," </title> <address> Oct. </address> <year> 1997. </year> <title> Internet draft, </title> <booktitle> Work in progress. </booktitle>
Reference-contexts: Header compression techniques [15, 16] have been proposed to improve performance for such links. On very slow links, compressing the data portion leads to even more gains <ref> [17, 18] </ref>. Compressing data is not useful on fast links, because the compression and decom 4 pression overheads offset the savings obtained by sending fewer bits.
Reference: [18] <author> V. Schryver, "RFC1977: </author> <title> PPP BSD compression protocol," </title> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: Header compression techniques [15, 16] have been proposed to improve performance for such links. On very slow links, compressing the data portion leads to even more gains <ref> [17, 18] </ref>. Compressing data is not useful on fast links, because the compression and decom 4 pression overheads offset the savings obtained by sending fewer bits.
Reference: [19] <author> M. F. X. J. Oberhumer, </author> <title> "miniLZO mini version of the LZO real-time data compression library." </title> <address> http://www.infosys.tuwien.ac.at/Staff/lux/marco/lzo.html. </address>
Reference-contexts: On slow links, however, a fast compression function (where the time per byte for compression and decompression multiplied by the bandwidth is less than the fraction of bytes saved) leads to improved performance. We have used a simple compression function provided by the minilzo library <ref> [19] </ref>. If the packet is incompressible, we send the original packet without any modifications. The LZO compression method is fast enough to be useful even on a 2-Mbps WaveLAN. For wide-area networks (where gathercast will typically be used), compression will lead to more gains.
Reference: [20] <author> A. Ballardie, </author> <title> "RFC 2201: Core Based Trees (CBT) multicast routing architecture," </title> <booktitle> 1997. </booktitle> <pages> 18 </pages>
Reference-contexts: explain the gathercast protocol by use of reassembly transformation function as the only aggregator being used at the intermediate nodes. * Combining close to the gatherer only (NEAR ROOT): If a reassembly function is placed very close to the root of the tree, (for example in a core based tree <ref> [20] </ref> we can have a 7 transformer tunnel from the rendezvous point to the receiver), it will achieve reassembly with low latency. Unfortunately, this means that rest of the network will not see any advantages of reassembly.
Reference: [21] <author> A. Terzis, L. Zhang, and E. Hahne, </author> <title> "Making reservations for aggregate flows: Experiences from an RSVP tunnels implementation." </title> <note> To appear in IWQoS '98, Napa Valley, CA. </note>
Reference-contexts: However, the routes from the senders (leaves) to the gatherer need not overlap. In such cases, the transformer tunnels may not be of any help at all. Also, this scheme requires that intermediate routers check packets contents (such as UDP port number as used by RSVP tunnels <ref> [21] </ref>) which leads to excessive overheads at all the routers. 5.1.1 Tunnel establishment To establish tunnels along the network, the gatherer sends a multicast message to the leaves. <p> This is required to ensure that these messages follow the same unicast routes (from leaves to the root of the gather tree) as used by the data packets. While bouncing the packet, the receivers use IP+UDP encapsulation similar to that used by RSVP tunnels <ref> [21] </ref>. All the routers along the path then intercept this packet. The routers that do not support transformer tunnels just forward the packet. Routers that support transformer tunnels check if the packet with the same id was received recently.
Reference: [22] <author> D. Waitzman, C. Partridge, and S. Deering, </author> <title> "RFC 1075: Distance vector multicast routing protocol," </title> <booktitle> 1988. </booktitle> <pages> 19 </pages>
Reference-contexts: We use transformer tunnels for this purpose also. The transformation function attached to the tunnel encapsulates the packets in a multicast message with TTL value 1 (same as for join messages used by the DVMRP <ref> [22] </ref> and PGM [12]). The tunnel also adds metadata to the packet indicating a special 11 reverse transformation function, multicast-lookup (that looks at the multicast routing table at the receiver and find out the previous-hop router), should be performed by the receiver of this packet.
References-found: 21

