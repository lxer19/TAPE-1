URL: ftp://ftp.cogsci.indiana.edu/pub/wang.revision.ps
Refering-URL: http://www.cogsci.indiana.edu/farg/peiwang/papers.html
Root-URL: 
Email: pwang@cogsci.indiana.edu  
Title: Belief Revision in Probability Theory  
Author: Pei Wang 
Address: Bloominton, IN 47408  
Affiliation: Indiana University  
Note: Center for Research on Concepts and Cognition  
Abstract: In a probability-based reasoning system, Bayes' theorem and its variations are often used to revise the system's beliefs. However, if the explicit conditions and the implicit conditions of probability assignments are properly distinguished, it follows that Bayes' theorem is not a generally applicable revision rule. Upon properly distinguishing belief revision from belief updating, we see that Jeffrey's rule and its variations are not revision rules, either. Without these distinctions, the limitation of the Bayesian approach is often ignored or underestimated. Revision, in its general form, cannot be done in the Bayesian approach, because a probability distribution function alone does not contain the information needed by the operation.
Abstract-found: 1
Intro-found: 1
Reference: <author> R. Bhatnagar and L. </author> <title> Kanal (1986). Handling uncertain information. </title> <editor> In N. Kanal and J. Lemmer (eds.), </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 3-26. </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference-contexts: In different systems, A and m may have different forms and interpretations, and the operations on them may be defined differently. However, there are still operations shared by many systems, in spite of all the differences <ref> (Bhatnagar and Kanal 1986) </ref>: Comparison: To decide which of the A i [m i ] has the high est certainty by comparing m i (i = 1; 2; ; n).
Reference: <author> P. </author> <title> Cheeseman (1985). In defense of probability. </title> <booktitle> Proceedings of IJCAI-85, </booktitle> <address> Los Angeles, </address> <pages> pp. 1002-1009. </pages>
Reference-contexts: However, this observation is also often misinterpreted. To argue against the opinion that more than one number is needed to represent uncertainty, Cheeseman claimed <ref> (Cheeseman 1985) </ref> that a point value and a density function will give the same result in decision making, which I agree to certain extent.
Reference: <author> P. </author> <title> Cheeseman (1986). Probabilistic vs. fuzzy reasoning. </title>
Reference-contexts: Cheeseman said that conditional probability statements contain the context (conditions) associated with their values, which make explicit our prior knowledge <ref> (Cheeseman 1986) </ref>. <p> A related method was suggested to process uncertain evidence E [m] (m 2 (0; 1)), where a virtual proposition V is introduced to represent the new knowledge as a (unspecified) proposition V is true, and P (EjV ) = m <ref> (Cheeseman 1986 and Nilsson 1986) </ref>.
Reference: <editor> In N. Kanal and J. Lemmer (eds.), </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 85-102. </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference: <author> P. </author> <title> Cheeseman (1988). An inquiry into computer understanding. </title> <booktitle> The Computational Intelligence 4, </booktitle> <pages> pp. 58-66. </pages>
Reference: <author> D. Dubois and H. </author> <title> Prade (1991). Updating with belief functions, ordinal conditional functions and possibility measures. </title> <editor> In P. Bonissone et al. (eds.), </editor> <booktitle> Uncertainty in Artificial Intelligence 6, </booktitle> <pages> pp. 311-330. </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference-contexts: In an updating, when the new knowledge the probability of A should be m arrives, the system's opinion on A is completely dominated by the new knowledge, regardless of P C (A), the previous opinion about A <ref> (Dubois and Prade 1991) </ref>, and then the distribution function is modified accordingly. Such a complete updating seldom happens in human reasoning. For revision in general, new evidence usually causes an adjustment, rather than an abandonment, of the previous opinion. <p> What I mean isn't that updating is not a valid operation in uncertain reasoning, but that it is different from revision. In certain situations, it is more proper to interpret belief changes as updatings <ref> (Dubois and Prade 1991) </ref>, but revision seems to be a more general and important operation.
Reference: <author> J. </author> <month> Earman </month> <year> (1992). </year> <institution> Bayes or Bust? The MIT Press, Cam-bridge, Massachusetts. </institution>
Reference-contexts: This is the conditionalization principle <ref> (Earman 1992, Levi 1983, and Weirich 1983) </ref>.
Reference: <author> D. </author> <title> Heckerman (1988). An axiomatic framework for belief updates. </title> <editor> In J. Lemmer and N. Kanal (eds.), </editor> <booktitle> Uncertainty in Artificial Intelligence 2, </booktitle> <pages> pp. 11-22. </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference: <author> H. </author> <title> Kyburg (1987). Bayesian and non-Bayesian evidential updating. </title> <booktitle> Artificial Intelligence 31, </booktitle> <pages> pp. 271-294. </pages>
Reference-contexts: The probability of a proposition A (A 2 S) should be changed to m, assuming the conditional probabilities that with A or :A as explicit condition are unchanged, we can update the probability assignment for every proposition x in S to get a new distribution function by using Jeffrey's rule <ref> (Kyburg 1987 and Pearl 1988) </ref>: P C 0 (x) = P C (xjA) fi m + If we interpret A happens as A's probability should be changed to 1, then Bayes' theorem, when used as a revision rule, becomes a special case of Jeffrey's rule, where m = 1.
Reference: <author> I. </author> <title> Levi (1983). The Enterprise of Knowledge. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference: <author> N. </author> <title> Nilsson (1986). Probability logic. </title> <booktitle> Artificial Intelligence 28, </booktitle> <pages> pp. 71-88. </pages>
Reference-contexts: A related method was suggested to process uncertain evidence E [m] (m 2 (0; 1)), where a virtual proposition V is introduced to represent the new knowledge as a (unspecified) proposition V is true, and P (EjV ) = m <ref> (Cheeseman 1986 and Nilsson 1986) </ref>.
Reference: <author> G. Paa(1991). </author> <title> Second order probabilities for uncertain and conflicting evidence. </title> <editor> In P. Bonissone et al. (eds.), </editor> <booktitle> Uncertainty in Artificial Intelligence 6, </booktitle> <pages> pp. 447-456. </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference: <author> J. </author> <title> Pearl (1986). Fusion, propagation, and structuring in belief networks. </title> <booktitle> Artificial Intelligence 29, </booktitle> <pages> pp. 241-288. </pages>
Reference-contexts: This is the conditionalization principle (Earman 1992, Levi 1983, and Weirich 1983). To distinguish this usage from the previous one of Bayes' theorem, a new function BEL (x) can be defined on S <ref> (Pearl 1986) </ref>, which representing the probability distributionunder all available evidence: BEL (x) = P C (xjK) (2) where x 2 S, and K is the current evidence, that is, the conjunction of all propositions in S that are known to be true. <p> However, no matter which procedure is followed and how the process is interpreted, the result is the same. Some other systems process uncertain evidence by providing likelihood ratios of virtual propositions <ref> (Pearl 1986 and Heckerman 1988) </ref>, and this method also leads to condi-tionalization of a virtual condition, therefore the rule is an updating rule, too. What I mean isn't that updating is not a valid operation in uncertain reasoning, but that it is different from revision.
Reference: <author> J. </author> <title> Pearl (1987). Bayesian decision methods. </title> <booktitle> Encyclopedia of AI, </booktitle> <pages> pp. 48-56. </pages> <publisher> John Wiley & Sons, Inc., </publisher> <address> New York. </address>
Reference-contexts: What does the K (and B, C) mean in these formulas? Pearl interpreted P (AjK) as a person's subjective belief in A given a body of knowledge K <ref> (Pearl 1987) </ref>. Cheeseman said that conditional probability statements contain the context (conditions) associated with their values, which make explicit our prior knowledge (Cheeseman 1986). <p> The probability of a proposition A (A 2 S) should be changed to m, assuming the conditional probabilities that with A or :A as explicit condition are unchanged, we can update the probability assignment for every proposition x in S to get a new distribution function by using Jeffrey's rule <ref> (Kyburg 1987 and Pearl 1988) </ref>: P C 0 (x) = P C (xjA) fi m + If we interpret A happens as A's probability should be changed to 1, then Bayes' theorem, when used as a revision rule, becomes a special case of Jeffrey's rule, where m = 1.
Reference: <author> J. </author> <title> Pearl (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, California. </address>
Reference-contexts: In propagation, the system generates a new proposition (with its certainty value) that was not among the premises. In revision, the system modifies the certainty value of an existing proposition. Other authors may use the two words differently <ref> (Pearl 1988) </ref>, but we can still make the above distinction, no matter how the operations are named. Bayes' theorem seems to be an exception. In some systems, it is used as a propagation rule, while in others, as a revision rule. <p> Pearl said our confidence in the assessment of BEL (E) is measured by the (narrowness of the) distribution of BEL (Ejc) as c ranges over all combinations of contingencies, and each combination c is weighted by its current belief BEL (c) <ref> (Pearl 1988) </ref>. I agree with him that ignorance is the lack of confidence, and confidence can be measured by how much a belief assignment can be modified by possible future evidence.
Reference: <author> K. </author> <title> Popper (1968). The Logic of Scientific Discovery. </title> <publisher> Hutchinson, London. </publisher>
Reference-contexts: the system get from them J 10 : bird f lyer &lt; 0; 0:288 &gt; Therefore, penguin provide a negative example for Birds are flyers, but doesn't completely falsify the hypothesis, because the hypothesis is treated by NARS as a statistical proposition, rather than an universal generalization in Popper's sense <ref> (Popper 1968) </ref>.
Reference: <author> G. </author> <title> Shafer (1976). A Mathematical Theory of Evidence. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, New Jersey. </address>
Reference-contexts: As discussed above, the information about C i cannot be derived from m i . To revise a belief, the belief's implicit condition must be somehow represented. 6 AN EXAMPLE There are several paradigms using more than one numbers to represent a proposition's uncertainty, such as Dempster-Shafer theory <ref> (Shafer 1976) </ref>, probability interval (Weichsel-berger and Pohlmann 1990), and higher-order probability (Paa1991). I'm also working on an intelligent reasoning system myself, which use a pair of real numbers as a proposition's truth-value.
Reference: <author> P. </author> <note> Wang (1993). Non-Axiomatic Reasoning System (Version 2.2). Technical Report (No. 75) of Center for Research on Concepts and Cognition, Indiana University. </note>
Reference-contexts: In most cases, we cannot guarantee that all knowledge the system get is unchangeable, or later acquired knowledge is always truer than earlier acquired knowledge. More than that, under certain conditions we even cannot guarantee that the system's beliefs are free from internal conflicts <ref> (Wang 1993) </ref>. Therefore, we really hope a formal system can revise its knowledge in the general sense. For the second question, let's look at the revision operation as defined in the first section. <p> The system, Non-Axiomatic Reasoning System (or NARS for short), is described in a technical report <ref> (Wang 1993) </ref> in detail. In the following, I'll briefly mention (with necessary simplifications) some of its properties that are most directly related to our current topic. <p> This is the rule in NARS that corresponds to updating as discussed in previous sections. For a detailed discussion about the rules (as well as other rules in NARS, such as those for deduction and abduction), see the technical report <ref> (Wang 1993) </ref>. premises, therefore supported by more evidence (compared with the premises), no matter whether the premises are consistent with each other (as when J 7 is generated) or in conflict with each other (as when J 11 is generated).
Reference: <author> K. Weichselberger and S. </author> <month> Pohlmann </month> <year> (1990). </year> <title> A Methodology for Uncertainty in Knowledge-Based Systems. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference: <author> P. </author> <month> Weirich </month> <year> (1983). </year> <title> Conditional probabilities and probabilities given knowledge of a condition. </title> <booktitle> Philosophy of Science 50, </booktitle> <pages> pp. 82-95. </pages>
Reference: <author> B. Wise and M. </author> <month> Henrion </month> <year> (1986). </year> <title> A framework for comparing uncertain inference systems to probability. </title> <editor> In N. Kanal and J. Lemmer (eds.), </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 69-84. </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference-contexts: S is the set of all propositions to be processed by the system, and may be generated from a set of atomic propositions, using logical operators <ref> (Wise and Henrion 1986) </ref>. As the starting point of all probability calculations, a prior probability distribution should be defined on S, under the constraints of the axioms of probability theory.
References-found: 21

