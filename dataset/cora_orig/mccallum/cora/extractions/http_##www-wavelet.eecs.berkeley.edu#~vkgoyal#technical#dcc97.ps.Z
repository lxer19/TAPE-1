URL: http://www-wavelet.eecs.berkeley.edu/~vkgoyal/technical/dcc97.ps.Z
Refering-URL: http://www-wavelet.eecs.berkeley.edu/~vkgoyal/technical/dcc97.html
Root-URL: 
Email: fvkgoyal,zhuang,marting@eecs.berkeley.edu  
Title: Universal Transform Coding Based On Backward Adaptation  
Author: Vivek K Goyal, Jun Zhuang, and Martin Vetterli 
Web: http://www-wavelet.eecs.berkeley.edu/  
Address: Berkeley  
Affiliation: Dept. of Electrical Engineering and Computer Sciences University of California,  
Abstract: The method for universal transform coding based on backward adaptation introduced in [1] is reviewed and further analyzed. This algorithm uses a linear transform which is periodically updated based on a local Karhunen-Loeve Transform (KLT) estimate. The KLT estimate is derived purely from quantized data, so the decoder can track the encoder state without any side information. The effect of estimating only from quantized data is quantitatively analyzed. Two convergence results which hold in the absence of estimation noise are presented. The first applies for any vector dimension but does not preclude the necessity of a sequence of quantization step sizes that goes to zero. The second applies only in the two-dimensional case, but shows local convergence for a fixed, sufficiently small quantization step size. Refinements which reduce the storage and computational requirements of the algorithm are suggested.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. K Goyal, J. Zhuang, M. Vetterli, and C. Chan. </author> <title> Transform coding using adaptive bases and quantization. </title> <booktitle> In IEEE Int. Conf. Image Proc., </booktitle> <volume> vol. II, </volume> <pages> pp. 365-368, </pages> <year> 1996. </year>
Reference-contexts: Classification methods generally rely on training for defining classes and/or designing a transform code for each class. This paper extends results on a method for universal transform coding that we introduced in <ref> [1] </ref>. This scheme does not rely on classification or on a priori training; instead, it periodically adjusts the transform to approximately match the KLT estimated from local statistics. <p> The goal is to achieve the performance of an optimal transform coder despite an initial lack of knowledge about the source distribution. The earlier paper <ref> [1] </ref> described the feasibility of this backward adaptive scheme and presented experimental results on the coding of Gauss-Markov sources. <p> This is made more precise by the following theorem <ref> [1] </ref>: Theorem 1 Let X = [X 1 ; : : : ; X k ] T , X ~ N (0; ), where is an unknown nondegenerate covariance matrix. <p> The proof is based on finding the mapping between the moments of X and the moments of ^ X and then showing that this mapping is invertible. The general form of the mapping is complicated, but if the quantization step sizes are small very simple approximations can be used <ref> [1] </ref>. 2 It is interesting to note that even very coarse scalar quantization can yield enough information to fit a reasonable parametric model. For example, quantizing with only three bins will yield 3 k 1 independent probability estimates, where k is the vector dimension. <p> But as mentioned in the previous section, the actual proposed algorithm uses estimates of moments of the quantized signal directly as estimates of the moments of the original signal. In a variety of simulations, some of which were reported in <ref> [1] </ref>, this algorithm has converged. In analytically studying the convergence of the algorithm, it is convenient to first consider a "non-stochastic" version of the algorithm where certain quantities which would be estimated online are replaced by their expected values. <p> Substituting in (2) and comparing to d fi fi d f W () fi = ? fi fi d W () fi fi fi ; so the iteration converges in a neighborhood of ? . 5 Computational Refinements In the simulations reported in <ref> [1] </ref>, conceptually simple data structures and computational mechanisms were used. In particular, ^r x (m) = K k=0 was used as an autocorrelation estimate computed from samples fx k g K1 k=0 , and eigen decompositions were computed using the MATLAB eig function.
Reference: [2] <author> M. Effros and P. A. Chou. </author> <title> Weighted universal transform coding: Universal image compression with the Karhunen-Loeve transform. </title> <booktitle> In IEEE Int. Conf. Image Proc., </booktitle> <volume> vol. II, </volume> <pages> pp. 61-64, </pages> <year> 1995. </year>
Reference-contexts: Recently, very good transform coding results have been reported using classification based methods, i.e. schemes in which the signal space is divided into a finite set of classes and a fixed transform is designed for each class <ref> [2, 3] </ref>. Classification methods generally rely on training for defining classes and/or designing a transform code for each class. This paper extends results on a method for universal transform coding that we introduced in [1].
Reference: [3] <author> R. D. Dony and S. Haykin. </author> <title> Optimally adaptive transform coding. </title> <journal> IEEE Trans. Image Proc., </journal> <volume> 4(10) </volume> <pages> 1358-1370, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: Recently, very good transform coding results have been reported using classification based methods, i.e. schemes in which the signal space is divided into a finite set of classes and a fixed transform is designed for each class <ref> [2, 3] </ref>. Classification methods generally rely on training for defining classes and/or designing a transform code for each class. This paper extends results on a method for universal transform coding that we introduced in [1].
Reference: [4] <author> H. S. Malvar. </author> <title> Signal Processing with Lapped Transforms. </title> <publisher> Artech House, </publisher> <year> 1992. </year>
Reference-contexts: However, because of a lack of methods for finding an optimal transform that are 1 In practical forward adaptive transform coding systems in which only the quantization is adapted, 20 to 40 percent of the available bit rate is assigned to side information <ref> [4, x2:3] </ref>. A system which adapts the transform itself would presumably require at least as much side information. practical for "on-line" use, we will in fact attempt to estimate and use the KLT.
Reference: [5] <author> B. Yu. </author> <title> A statistical analysis of adaptive scalar quantization based on quantized past. </title> <journal> Submitted to IEEE Trans. Info. Theory, </journal> <year> 1995. </year>
Reference-contexts: The following subsections address the estimation of R x n when only the quantized version ^x n can be observed. 3.1 Parametric case Consider the coding of a scalar source and suppose that the source can be described by a parametric model. Then, as described by Yu <ref> [5] </ref>, the parameters of the source can in general be consistently estimated from observations of a quantized version of the source as long as the number of quantization bins exceeds the number of parameters.
Reference: [6] <author> L. Cheded and P. A. Payne. </author> <title> The exact impact of amplitude quantization on multidimensional, high-order moments estimation. </title> <journal> Sig. Proc., </journal> <volume> 39(3) </volume> <pages> 293-315, </pages> <year> 1994. </year>
Reference-contexts: An elementary calculation shows that Var (^s 2 ) = E [ ^ X 4 1 ]E [ ^ X 2 1 ] k , where one can obtain expressions for E [ ^ X 4 1 ] and E [ ^ X 2 1 ] by manipulating expressions from <ref> [6] </ref>. Normalizing the variance of the estimate of 2 (approximated through (1)) by 2 4 k (the variance obtained without quantization) characterizes precisely how much is lost by estimating from quantized data.
Reference: [7] <author> J. Zhuang. </author> <title> Adaptive transforms and quantization. </title> <type> MS thesis, </type> <institution> UC-Berkeley, </institution> <year> 1997. </year>
Reference-contexts: The proof, which is omitted due to its length (see <ref> [7] </ref>), is based on the existence at iteration n of n 2 R + such that jjjR y n+1 jjj 1 2 jjjR y n jjj. Thus the proof does not preclude the possibility that we must have lim n!1 n = 0 for convergence.
Reference: [8] <author> C. R. Johnson, Jr. </author> <title> Lectures on Adaptive Parameter Estimation. </title> <publisher> Prentice Hall, </publisher> <year> 1988. </year>
Reference-contexts: There is no a priori requirement that each of the P estimates be weighted equally. One way to more heavily weight the later autocorrelation estimates is to use a "forgetting factor" ff as in Recursive Least Squares <ref> [8] </ref>. The estimate would then be updated through ^r x;new = (1 ff)^r x;old + ff^r 0 as each new ^r 0 x is calculated.
Reference: [9] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <institution> Johns Hopkins Univ. </institution> <note> Press, second edition, </note> <year> 1989. </year>
Reference-contexts: This feature can be exploited in the calculation of the KLT. For example, one can first approximately diagonalize the autocorrelation matrix using the previous KLT estimate. Then it should be possible to complete the diagonalization with a small number of Jacobi rotation steps (see <ref> [9, x8.5] </ref>). 6 Conclusions and Ongoing Work A method for universal transform coding which updates the transform based on a local KLT estimate was developed. The KLT estimate is derived purely from quantized data, so the decoder can track the encoder state without any side information.
References-found: 9

