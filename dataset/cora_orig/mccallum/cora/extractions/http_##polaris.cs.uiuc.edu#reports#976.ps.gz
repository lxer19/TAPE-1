URL: http://polaris.cs.uiuc.edu/reports/976.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: Analysis of a SIMD Computer  
Author: Jose Eduardo Moreira Wilson Vicente Ruggiero Departamento de Engenharia de Eletricidade, Escola Politecnica da 
Note: This work was supported in part by the Interamerican Development Bank/University of S~ao Paulo project, and the U. S. Department of Energy under Grant No. DE-FG02-85ER25001. Jose E. Moreira is with Laboratorio de Sistemas Integraveis, and Wilson V. Ruggiero is with Laboratorio  
Date: February 1990  976  
Address: S~ao Paulo, Brasil  USA  
Affiliation: Universidade de  Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign,  de Sistemas Digitais  
Pubnum: CSRD Report No.  
Abstract: We here detail and analyze some implementation alternatives for a SIMD (array-processor) computer. The computer is aimed for GaAs implementation, and so it is very simple. The LIDEX Simulation Environment is used to describe the various implementation techniques and simulate the execution of vector arithmetic and reduction operations. A matrix multiplication algorithm is analyzed in its complexity. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Advanced Micro Devices, </institution> <address> Sunnyvale, CA. </address> <booktitle> Bipolar Microprocessor Logic and Interface Data Book, </booktitle> <year> 1985. </year>
Reference-contexts: In order to allow the implementation of the proposed architecture with currently available GaAs technology, we assume that each PE shall have no more than 15,000 gates, and that 4kbit (1kx4) GaAs memories are used. 4 With 15,000 gates one can implement a very sophisticated 32-bit ALU (including mul-tiplication capability <ref> [1] </ref>, and although 16kbit GaAs SRAMs do exist, they currently present a very low yield. In our proposed architecture, each PE has its own local data-memory, for retrieving operands and storing results, and the necessary circuits for communicating with other PEs through an inter-PE communication network.
Reference: [2] <author> W. J. Bouknight et al. </author> <title> Computer Structures: Principles and Examples, chapter The Illiac IV System. </title> <publisher> McGraw-Hill Book Company, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: In any case, a data-routing mechanism is necessary between the PEs. A large number of SIMD computers have been built, but none of them have enjoyed much commercial success. The most famous of them all is of course the Illiac IV <ref> [2] </ref>, the grandparent of parallel processing, which (as many other computers) suffered from the lack of appropriate implementation technology. The most powerful SIMD computer already built is the IBM-GF11 [4], which is dedicated to special purpose computing (mainly quantum chromodynamics). <p> We call the unit formed by a PE, its data-memory and interconnection circuit, a processor element-memory. Following the Illiac IV terminology <ref> [2] </ref>, we shall call the set of all PEMs the array-unit of the computer.
Reference: [3] <author> W. Daniel Hillis. </author> <title> The Connection Machine. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year>
Reference-contexts: The most powerful SIMD computer already built is the IBM-GF11 [4], which is dedicated to special purpose computing (mainly quantum chromodynamics). The most commercially successful SIMD computers are the Connection Machine series <ref> [3, 4] </ref> by Thinking Machines, which now include the CM-1 and the CM-2. Other examples of SIMD computers (including attached-processors) are the Loral MPP, ICL/DAP and FPS 164/MAX. <p> A set of masking-schemes, used to enable and disable PEs during each operation. A large number of interconnection networks among processors-elements and among processor-elements and memory-modules (useful not only for SIMD computers, but also for MIMD ones) have been proposed. Hillis <ref> [3] </ref> recognizes that the most difficult technical problem in the design of a Connection Machine computer is the design of the general interconnection network, and that the literature offers the designer a rich set of choices (which contributes to make his or her job even more difficult). <p> Several interconnection networks and their classifications are discussed in <ref> [3, 5, 6] </ref>. 3 Basic Proposed Architecture We here present an architecture evolved from the one presented in [7]. The objective here, as in [7], is to define a very simple architecture, that can be implemented in GaAs, and execute at very high-speed (200MHz).
Reference: [4] <author> Kai Hwang. </author> <title> Advanced parallel processing with supercomputer architectures. </title> <booktitle> Proceedings of the IEEE, </booktitle> <pages> pages 1348-1379, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: The most famous of them all is of course the Illiac IV [2], the grandparent of parallel processing, which (as many other computers) suffered from the lack of appropriate implementation technology. The most powerful SIMD computer already built is the IBM-GF11 <ref> [4] </ref>, which is dedicated to special purpose computing (mainly quantum chromodynamics). The most commercially successful SIMD computers are the Connection Machine series [3, 4] by Thinking Machines, which now include the CM-1 and the CM-2. Other examples of SIMD computers (including attached-processors) are the Loral MPP, ICL/DAP and FPS 164/MAX. <p> The most powerful SIMD computer already built is the IBM-GF11 [4], which is dedicated to special purpose computing (mainly quantum chromodynamics). The most commercially successful SIMD computers are the Connection Machine series <ref> [3, 4] </ref> by Thinking Machines, which now include the CM-1 and the CM-2. Other examples of SIMD computers (including attached-processors) are the Loral MPP, ICL/DAP and FPS 164/MAX.
Reference: [5] <author> Kai Hwang and Faye A. Briggs. </author> <title> Computer Architecture and Parallel Processing. </title> <publisher> McGraw-Hill Book Company, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: The data-flow units are usually called processing-elements (PE). Since there is only one control-unit (CU), all PEs execute the same operations simultaneously and in lock-step (although it is usually possible to inhibit designated PEs from executing any operation) <ref> [5] </ref>. Besides the PEs and the CU, a SIMD computer also has a series of memory-modules (MM), which can be private to each PE or shared among them. In the later case, an appropriate network must be provided to connect the PEs to the MMs. <p> Several interconnection networks and their classifications are discussed in <ref> [3, 5, 6] </ref>. 3 Basic Proposed Architecture We here present an architecture evolved from the one presented in [7]. The objective here, as in [7], is to define a very simple architecture, that can be implemented in GaAs, and execute at very high-speed (200MHz). <p> We simulated a program for multiplying 2 N fiN matrices in a N-PEM array-processor, using a variation of the algorithm proposed in <ref> [5] </ref> for doing matrix multiplication in O (n 2 ) time. The algorithm used is the following: 1. Start with matrix A distributed among the PEMs, each PEM holds one row of the matrix A; matrix B is stored in the control unit data-memory; 2. Let i = 1; 3.
Reference: [6] <editor> Veljko M. Milutinovic, editor. </editor> <booktitle> Computer Architecture, Concepts and Systems. </booktitle> <address> Noth-Holland, New York, </address> <year> 1988. </year>
Reference-contexts: Several interconnection networks and their classifications are discussed in <ref> [3, 5, 6] </ref>. 3 Basic Proposed Architecture We here present an architecture evolved from the one presented in [7]. The objective here, as in [7], is to define a very simple architecture, that can be implemented in GaAs, and execute at very high-speed (200MHz). <p> By instruction latency we mean that the result produced by one control-unit instruction is not available for the instruction immediately following it (this problem could have been solved using a technique called feed-forwarding <ref> [6] </ref>). By delayed branching we mean that the instruction (both the array-unit and control-unit subinstructions) immediately following a control-unit jump is always executed. We then run two different versions of the program in this last implementation.
Reference: [7] <author> Jose E. Moreira. </author> <title> Uma Arquitetura RISC para Computadores SIMD em GaAs. </title> <editor> In Anais do II Simposio Brasileiro de Arquitetura de Computadores Processamento Paralelo. Aguas de Lindoia, </editor> <booktitle> SP, </booktitle> <pages> pages 5.A.3.1-5.A.3.10, </pages> <month> September </month> <year> 1988. </year> <month> 21 </month>
Reference-contexts: Several interconnection networks and their classifications are discussed in [3, 5, 6]. 3 Basic Proposed Architecture We here present an architecture evolved from the one presented in <ref> [7] </ref>. The objective here, as in [7], is to define a very simple architecture, that can be implemented in GaAs, and execute at very high-speed (200MHz). SIMD architectures are convenient for GaAs implementation, for each PE does not need to have a control-unit, thus reducing the transistor count. <p> Several interconnection networks and their classifications are discussed in [3, 5, 6]. 3 Basic Proposed Architecture We here present an architecture evolved from the one presented in <ref> [7] </ref>. The objective here, as in [7], is to define a very simple architecture, that can be implemented in GaAs, and execute at very high-speed (200MHz). SIMD architectures are convenient for GaAs implementation, for each PE does not need to have a control-unit, thus reducing the transistor count.
References-found: 7

