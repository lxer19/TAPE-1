URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1993/GIT-CC-93-20.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.93.html
Root-URL: 
Title: Introspective Multistrategy Learning  
Author: Michael T. Cox S c i e n c eC o g n i t i v e 
Affiliation: GEORGIA INSTITUTE OF TECHNOLOGY A UNIT OF THE UNIVERSITY SYSTEM OF GEORGIA  
Date: March 16, 1993  
Pubnum: Report No. 2  
Abstract-found: 0
Intro-found: 1
Reference: <author> Anderson, J. R. </author> <year> (1983). </year> <title> The Architecture of Cognition. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Bhatta, S., and Ram, A. </author> <year> (1991). </year> <title> Learning Indices for Schema Selection. </title> <editor> In M. B. Fishman (ed.), </editor> <booktitle> Proceedings of the Fourth Florida Artificial Intelligence Research Symposium (FLAIRS), </booktitle> <address> Cocoa Beach, FL, </address> <month> (April), </month> <pages> pp. 226-231. </pages>
Reference: <author> Birnbaum, L. </author> <year> (1986). </year> <title> "Integrated Processing in Planning and Understanding," </title> <type> PhD Thesis, Research Report 489, </type> <institution> Yale University, New Haven, CT (December). </institution>
Reference: <author> Birnbaum, L., and Collins, G. </author> <year> (1984). </year> <title> Opportunistic Planning and Freudian Slips. </title> <booktitle> In Proceedings of the Sixth Annual Conference of the Cognitive Science Society. </booktitle> <address> Boulder, </address> <publisher> CO, </publisher> <pages> pp. 124-127. </pages>
Reference: <author> Birnbaum, L., and Collins, G., Freed, M. and Krulwich, B. </author> <year> (1990). </year> <title> Model-Based Diagnosis of Planning Failures. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> Boston, MA, </address> <pages> pp. 318-323. </pages>
Reference: <author> Booker, L. B., Goldberg, D. E. and Holland, J. H. </author> <year> (1989). </year> <title> Classifier Systems and Genetic Algorithms. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 40, </volume> <pages> pp. 235-282. </pages>
Reference-contexts: In reasoning tasks, the blame may be due to measurement errors, obsolete data, missing data, or explicit deception by another agent. The solution is to learn the conditions under which knowledge sources are reliable and the kinds of data that are necessary in a given situation <ref> (Booker, Goldberg & Holland, 1989) </ref>.
Reference: <author> Carbonell, J. G. </author> <year> (1986). </year> <title> Derivational Analogy: A theory of reconstructive problem solving and expertise acquisition. </title> <editor> In R. Michalski, J. Carbonell and T. Mitchell (eds.), </editor> <booktitle> Machine Learning: An artificial intelligence approach, </booktitle> <volume> Vol 2. </volume> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <pages> pp. 371-392. </pages>
Reference: <author> Carbonell, J. G., Knoblock, C. A., and Minton, S. </author> <year> (1991). </year> <title> PRODIGY: An integrated architecture for planning and learning. </title> <editor> In K. Van Lehn (ed.), </editor> <booktitle> Architecture for Intelligence: The twenty-second Carnegie Melon symposium on cognition. </booktitle> <publisher> Lawrence Erlbaum, Associates, </publisher> <address> Hillsdale, NJ, </address> <pages> pp. 241-278. </pages>
Reference-contexts: a police dog is used to find a marijuana plant in a trash bin within a suspects home produces no errors. 4.2 Process Model of Learning Meta-AQUA records its reasoning during the task of story understanding in a trace structure similar to the derivational analogy traces of the PRODIGY system <ref> (Veloso & Carbonell, 1991) </ref>. These knowledge structures contain representations for each of the reasoning phases: anomaly identification, hypothesis formation, and verification. For each phase the structure records the considerations that prompted the phase, the bases for making a reasoning strategy decision, and the result of such strategy execution.
Reference: <author> Chandrasekaran, B. </author> <year> (1989). </year> <title> Task-Structures, </title> <journal> Knowledge Acquisition and Learning, Machine Learning, </journal> <volume> Vol. 4. </volume> <pages> pp. 339-345. </pages>
Reference: <author> Chi, M. T. H. </author> <year> (1987). </year> <title> Representing Knowledge and Metaknowledge: Implications for interpreting metamemory research. </title> <editor> in F. E. Weinert and R. H. Kluwe (eds.), Metacognition, </editor> <title> Motivation, and Understanding. </title> <publisher> Lawrence Erlbaum Associates, Publishers, </publisher> <address> Hillsdale, NJ, </address> <pages> pp. 239-266. </pages>
Reference: <author> Chi, M. T. H., and Van Lehn, K. A. </author> <year> (1991). </year> <title> The Content of Physics Self-Explanations. </title> <journal> The Journal of the Learning Sciences, </journal> <volume> Vol. 1, No. 1, </volume> <pages> pp. 69-105. </pages>
Reference: <author> Clancey, W. J. </author> <year> (1991). </year> <title> The Frame of Reference Problem in the Design of Intelligent Machines. </title> <editor> In K. Van Lehn (ed.), </editor> <booktitle> Architecture for Intelligence: The twenty-second Carnegie Melon symposium on cognition. </booktitle> <publisher> Lawrence Erlbaum, Associates, </publisher> <address> Hillsdale, NJ, </address> <pages> pp. 357-423. </pages>
Reference: <author> Collins, G., Birnbaum, L., Krulwich, B., and Freed, M. </author> <year> (1992). </year> <title> The Role of Self-Models in Learning to Plan. </title> <editor> In A. Meyrowitz (ed.), </editor> <title> Machine Learning: Induction, analogy and discovery. </title> <type> Kluwer Academic Publishers. </type> <note> (Also available as Technical Report 24, </note> <institution> Institute of the learning Sciences, Northwestern University, </institution> <address> Evanston, IL, </address> <month> April, </month> <year> 1992). </year> <note> 76 Cox, </note> <author> M. T. </author> <year> (1991). </year> <note> Reasoning about Reasoning via META-XPs. Unpublished. </note>
Reference: <author> Cox, M. T. </author> <year> (1992). </year> <title> Toward an Epistemological Treatment of the Blame Assignment Problem. </title> <note> Unpublished. </note>
Reference: <author> Cox, M. T. </author> <year> (1993). </year> <title> Metacognition, Problem Solving and Aging. </title> <note> Submitted to The Psychology Graduate Student Journal (PSYCGRAD). </note>
Reference: <author> Cox, M. T., and Ram, A. </author> <year> (1991). </year> <title> Using Introspective Reasoning to Select Learning Strategies. </title> <editor> In R. S. Michalski and G. Tecuci (eds.), </editor> <booktitle> Proceedings of the First International Workshop on Multi-strategy Learning. </booktitle> <address> Harpers Ferry, WV, </address> <month> (November), </month> <pages> pp. 217-230. </pages>
Reference: <author> Cox, M. T., and Ram, A. </author> <year> (1992a). </year> <title> Multistrategy Learning with Introspective Meta-Explanations. </title>
Reference: <editor> In D. Sleeman and P. Edwards (eds.), </editor> <booktitle> Machine Learning: Proceedings of the ninth international conference (ML92), </booktitle> <address> Aberdeen, Scotland, </address> <month> (July 1-3), </month> <pages> pp. 123-128. </pages>
Reference: <author> Cox, M. T., and Ram, A. </author> <year> (1992b). </year> <title> An Explicit Representation of Forgetting. </title> <editor> In J. W. Brahan and G. E. Lasker (eds.), </editor> <booktitle> Proceedings of the Sixth International Conference on Systems Research, Infor-matics and Cybernetics. Vol. 2 (Advances in Artificial Intelligence - Theory and application), </booktitle> <address> Baden-Baden, Germany, </address> <month> (August 17-23), </month> <pages> pp. 115-120. </pages>
Reference-contexts: To explain this problem effectively, it is useful to have a mental interpretation of the problem solving process, as well as an explanation that deals with the problem itself. As another case of the intertwined relationship between blame assignment and introspection, consider the stranded motorist example <ref> (Cox & Ram, 1992b) </ref>. If an agent runs out of gas on a vacation, a number of causes could have contributed to the failure. <p> At present, the input column, the domain knowledge, and knowledge selection columns have explicit Meta-XP representations, many of which will be shown in section 4.3, Content Theory of Introspective Explanations, starting on page 43. Additionally, both the Missing Goal and the Forgotten Goal cells of the table are represented <ref> (see Cox and Ram, 1992b) </ref>. <p> Although diverging from the framework suggested by Chi, Meta-XP theory provides a robust form with which to represent knowledge 66 about knowledge and knowledge about process. For example, Meta-XPs can represent the difference between remembering and forgetting <ref> (Cox & Ram, 1992b) </ref>. Since forgetting is characterized by the absence of a successful outcome, it is quite difficult to capture in most representational languages.
Reference: <author> Davis, R. </author> <year> (1980). </year> <title> Meta-Rules: Reasoning about control. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 15, No. 3, </volume> <pages> pp. 179-222. </pages>
Reference: <author> Davis, R., and Buchanan, B. G. </author> <year> (1977). </year> <title> Meta-Level Knowledge: Overview and applications. </title> <booktitle> In Proceedings of the 5th International Joint Conference on Artificial Intelligence. </booktitle> <volume> Vol. </volume> <pages> 2, </pages> <address> Cambridge, MA, </address> <month> (August 22-25), </month> <pages> pp. 920-927. </pages>
Reference: <author> DeJong, G., and Mooney, R. </author> <year> (1986). </year> <title> Explanation-Based Learning: An alternative view, </title> <journal> Machine Learning, </journal> <volume> Vol. 1, No. 2, </volume> <pages> pp. 145-176. </pages>
Reference: <author> Domeshek, E. A. </author> <year> (1992). </year> <title> "Do the Right Thing: A component theory for indexing stories as social advice," </title> <type> PhD Thesis, Technical Report 26, </type> <institution> Institute for the Learning Sciences, Northwestern University, </institution> <address> Evanston, IL (May). </address>
Reference-contexts: Content theories provide a component theory that specifies the objects or components in the domain and the features that best describe the components. Also, a content theory provides constraints and inferential relationships between the features. Content theories therefore possess commitments to both domain ontology as well as domain physics <ref> (Domeshek, 1992) </ref>. Because the domain of this research is reasoning itself, rather than some external behavior, our con 7 tent theory is unique in that it becomes a descriptive language of the processes found in our process theory.
Reference: <author> Doyle, J. </author> <year> (1979). </year> <title> A Truth Maintenance System, </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 12, </volume> <pages> pp. 231-272. </pages>
Reference-contexts: To represent these conditions, Meta-AQUA uses non-monotonic logic values of in (in the current set of beliefs) and out (out of the current set of beliefs) <ref> (Doyle, 1979) </ref>. Extended values include hypothesized-in (weakly assumed in) and hypothesized (unknown). Thus, absolute retrieval failure is represented by A (truth = in) = E (truth = out).
Reference: <author> Flavell, J. H., and Wellman, H. M. </author> <year> (1977). </year> <editor> Metamemory. In R. V. Kail, Jr., and J. W. Hagen (eds.), </editor> <booktitle> Perspectives on the Development of Memory and Cognition. </booktitle> <publisher> Lawrence Erlbaum Associates, Publishers, </publisher> <address> Hillsdale, NJ, </address> <pages> pp. 3-33. </pages>
Reference: <author> Freed, M., Krulwich, B., Birnbaum, L., and Collins, G. </author> <year> (1992). </year> <title> Reasoning about Performance Intentions. </title> <booktitle> In Proceedings of Fourteenth Annual Conference of the Cognitive Science Society, Bloomington, IN, </booktitle> <month> (July 29 - August 1), </month> <pages> pp. 7-12. </pages>
Reference-contexts: They explicitly model, however, the planner itself. They also explicitly model and reason about the intentions of an actor in order to find and repair the faults that underlie a planning failure <ref> (see Freed et al., 1992) </ref>.
Reference: <author> Garner, R. </author> <year> (1987). </year> <title> Metacognition and Reading Comprehension. </title> <publisher> Ablex Publishing Corporation, </publisher> <address> Norwood, NJ. </address>
Reference: <author> Gavelek, J. R., and Raphael, T. E. </author> <year> (1985). </year> <title> Metacognition, Instruction, and the Role of Questioning Activities. </title> <editor> In D. L. Forrest-Pressley, G. E. MacKinnon, and T. G. Waller (eds.), Metacognition, </editor> <title> Cognition and Human Performance. Vol. 2 (Instructional Practices), </title> <publisher> Academic Press, Inc., </publisher> <address> New York, </address> <pages> pp. 103-136. </pages>
Reference: <author> Goel, A. K., and Callantine, T. J. </author> <year> (1991). </year> <title> A Control Architecture for Run-Time Method Selection and Integration. </title> <booktitle> In Proceedings of the AAAI Workshop on Cooperation Among Heterogeneous 77 Intelligent Agents, </booktitle> <address> Anaheim, CA (July, </address> <month> 15). </month>
Reference: <author> Hammond, K. J. </author> <year> (1988). </year> <title> Opportunistic Memory: </title> <editor> Storing and recalling suspended goals, In J. </editor> <publisher> L. </publisher>
Reference: <editor> Kolodner (ed.), </editor> <booktitle> Proceedings of a Workshop on Case-Based Reasoning. </booktitle> <address> Clearwater Beach, FL, </address> <month> (May 10-13), </month> <pages> pp. 154-168. </pages>
Reference: <author> Hammond, K. J. </author> <year> (1989). </year> <title> Case-Based Planning: Viewing planning as a memory task. </title> <booktitle> Vol. 1 of Perspectives in Artificial Intelligence. </booktitle> <publisher> Academic Press, </publisher> <address> San Diego, CA. </address>
Reference: <author> Hayes-Roth, B., and Hayes-Roth F. </author> <year> (1979). </year> <title> A Cognitive Model of Planning, </title> <journal> Cognitive Science, </journal> <volume> Vol. 2, </volume> <pages> pp. 275-310. </pages>
Reference: <author> Hinrichs, T. R. </author> <year> (1992). </year> <title> Problem Solving in Open Worlds. </title> <publisher> Lawrence Erlbaum Associates, Publishers, </publisher> <address> Hillsdale, NJ. </address>
Reference-contexts: JULIA <ref> (Hinrichs, 1992) </ref>, a case-based meal planner, implements the processes depicted in figure 1. A design goal is input into an analysis process that determines an appropriate search method. The search method is given to the retrieval process, which finds a relevant past case from the systems case memory.
Reference: <author> Hunter, L. E. </author> <year> (1989). </year> <title> "Knowledge Acquisition Planning: Gaining experience through experience," </title> <type> PhD Thesis, Research Report 678, </type> <institution> Yale University, </institution> <address> New Haven, </address> <note> CT (January). </note>
Reference: <author> Hunter, L. E. </author> <year> (1990). </year> <title> Planning to Learn. </title> <booktitle> In Proceedings of Twelfth Annual Conference of the Cognitive Science Society, </booktitle> <address> Cambridge, MA, </address> <month> (July 25-28), </month> <pages> pp. 261-276. </pages>
Reference: <author> Jones, R., and Van Lehn, K. </author> <year> (1991). </year> <title> Strategy Shifts without Impasses: A computational model of the sum-to-min transition. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society. </booktitle> <address> Chicago, IL, </address> <month> (August 7-10), </month> <pages> pp. 358-363. </pages>
Reference: <author> Kass, A., Leake, D., and Owens, C. </author> <year> (1986). </year> <title> "SWALE: A program that explains," </title> <editor> In R. C. Schank, </editor> <title> Explanation Patterns: Understanding mechanically and creatively, </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Keller, R. M. </author> <year> (1986). </year> <title> Deciding What to Learn. </title> <type> Technical Report ML-TR-6, </type> <institution> Rutgers University, Department of Computer Science. </institution>
Reference: <author> Kolodner, J. L. </author> <year> (1984). </year> <title> Retrieval and Organizational Strategies in Conceptual Memory: A computer model. </title> <publisher> Lawrence Erlbaum Associates, Publishers, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Kolodner, J. L. </author> <year> (1987). </year> <title> Capitalizing on Failure through Case-Based Inference. </title> <booktitle> In Proceedings of the Ninth Annual Conference of the Cognitive Science Society, </booktitle> <address> Seattle, WA, </address> <pages> pp. 715-726. </pages> <note> (Also available as Technical Report GIT-ICS-87/18, </note> <institution> College of Computing, Georgia Institute of Technology, </institution> <address> Atlanta, GA). </address>
Reference: <author> Konolige, K. </author> <year> (1988). </year> <title> Reasoning by Introspection, </title> <editor> In P. Maes and D. Nardi (eds.), </editor> <booktitle> Meta-Level Architectures and Reection, </booktitle> <publisher> North Holland, Amsterdam, </publisher> <pages> pp. 61-74. </pages>
Reference-contexts: Although many in the artificial intelligence community have recognized the necessity of reasoning about ones own beliefs (e.g., Davis & Buchanan, 1977; Maes, 1988), and some have even called it introspection <ref> (e.g., Konolige, 1988) </ref>, few have both modeled and represented the processes that generates beliefs, 13 and made them available to the reasoner itself. This section develops a brief content theory of understanding in order to formalize knowledge about the reasoning itself.
Reference: <author> Krulwich, B. </author> <year> (1991). </year> <title> Determining What to Learn in a Multi-Component Planning System. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society. </booktitle> <address> Chicago, IL, </address> <month> (August 7-10), </month> <pages> pp. 102-107. </pages>
Reference: <author> Kuokka, D. R. </author> <year> (1990). </year> <title> The Deliberative Integration of Planning, Execution, and Learning. </title> <type> PhD thesis, Report CMU-CS-90-135, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference: <author> Lachman, J. L., Lachman, R., and Thronesbery, C. </author> <year> (1979). </year> <title> Metamemory Through the Adult Life Span. </title> <journal> Developmental Psychology, </journal> <volume> Vol. 15, No. 5, </volume> <pages> pp. 543-551. </pages>
Reference-contexts: Thus, search and elaboration is pursued when an item is on the tip of the tongue'' and abandoned when an item is judged unfamiliar. This search heuristic provides efficient control of memory and avoids the combinatoric explosion of inferences <ref> (Lachman, Lachman & Thronesbery, 1979) </ref>. Modelling this dimension of human metaknowledge requires a two-layered memory architecture. In the lower layer would be the actual memories, cases and propositions. The second layer would be a 67 metamemory, which stores memories of the first layer.
Reference: <author> Laird J. E., Rosenbloom, P. S., and Newell, A. </author> <year> (1986). </year> <title> Chunking in SOAR: The Anatomy of a General Learning Mechanism, </title> <journal> Machine Learning, </journal> <volume> Vol. 1, </volume> <pages> pp. 11-46. </pages> <note> 78 Leake, </note> <author> D., and Ram, A. </author> <title> (to appear). Goal-Driven Learning: Fundamental issues and symposium report. </title> <journal> AI Magazine. </journal> <note> (Also available as Technical Report 85, </note> <institution> Cognitive Science Program, Indiana University, Bloomington, IN, </institution> <year> 1993). </year>
Reference-contexts: Multistrategy learning systems are those that integrate various learning algorithms into a unified whole, and thus contrast with single-strategy systems such as Soar <ref> (Laird, Rosen-bloom & Newell, 1986) </ref> in which all learning is performed by a single learning mechanism. Whereas all learning in Soar reduces to chunking, methods as disparate as explanation-based learn 1. The background knowledge includes more than simply domain knowledge.
Reference: <author> Maes, P. </author> <year> (1988). </year> <title> Issues in Computational Reection. </title> <editor> In P. Maes and D. Nardi (eds.), </editor> <booktitle> Meta-Level Architectures and Reection. </booktitle> <publisher> North Holland, Amsterdam, </publisher> <pages> pp. 21-35. </pages>
Reference: <author> Michalski, R. S. </author> <year> (1991). </year> <title> Inferential Learning Theory as a Basis for Multistrategy Task-Adaptive Learning, </title> <editor> In R. S. Michalski and G. Tecuci (eds.), </editor> <booktitle> Proceedings of the First International Workshop on Multistrategy Learning. </booktitle> <address> Harpers Ferry, WV, </address> <month> (November), </month> <pages> pp. 3-18. </pages>
Reference-contexts: Incorrect Domain Knowledge: Even if the reasoner has applicable knowledge structures, they may be incorrect or incomplete. Learning in such situations is usually incremental, and involves strategies such as elaborative question asking (Ram, 1991, 1993) applied to the reasoning chain, 32 and abstraction and generalization techniques <ref> (Michalski, 1991) </ref> applied to the domain knowledge. Missing Input: The system requires information or otherwise detects some information that is lacking in the givens. A question is formed to fill the gap in the current knowledge (Ram, 1989, 1991).
Reference: <editor> Michalski, R. S., and Tecuci, G. (eds), </editor> <booktitle> (1991). Proceedings of the First International Workshop on Multistrategy Learning. </booktitle> <address> Harpers Ferry, WV, </address> <institution> George Mason University, </institution> <month> (November). </month>
Reference-contexts: Incorrect Domain Knowledge: Even if the reasoner has applicable knowledge structures, they may be incorrect or incomplete. Learning in such situations is usually incremental, and involves strategies such as elaborative question asking (Ram, 1991, 1993) applied to the reasoning chain, 32 and abstraction and generalization techniques <ref> (Michalski, 1991) </ref> applied to the domain knowledge. Missing Input: The system requires information or otherwise detects some information that is lacking in the givens. A question is formed to fill the gap in the current knowledge (Ram, 1989, 1991).
Reference: <editor> Michalski, R. S., and Tecuci, G. (eds.) </editor> <title> (to appear) Machine Learning: A multistrategy approach IV, </title> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address>
Reference: <author> Minsky, M. L. </author> <year> (1963). </year> <title> Steps Towards Artificial Intelligence. </title> <editor> in E. A. Feigenbaum & J. Feldman (eds.), </editor> <booktitle> Computers and Thought. </booktitle> <address> McGraw Hill, New York, </address> <pages> pp. 406-450. </pages>
Reference: <author> Mitchell, T., Utgoff, P. E., and Banerji, R. </author> <year> (1983). </year> <title> Learning by Experimentation: Acquiring and refining problem-solving heuristics. </title> <editor> In R. S. Michalski, J. G. Carbonell and T. M. Mitchell (eds.) </editor> <booktitle> Machine Learning: An artificial intelligence approach. </booktitle> <publisher> Morgan Kaufmann, Inc., </publisher> <address> Los Altos, CA, </address> <pages> pp. 163-189. </pages>
Reference: <author> Mitchell, T., Keller, R., and Kedar-Cabelli, S. </author> <year> (1986). </year> <title> Explanation-Based Generalization: A unifying view, </title> <journal> Machine Learning, </journal> <volume> Vol. 1, No. 1, </volume> <pages> pp. 47-80. </pages>
Reference: <author> Mooney, R., and Ourston, D. </author> <year> (1991). </year> <title> A Multistrategy Approach to Theory Refinement. </title> <editor> In R. </editor> <publisher> S. </publisher>
Reference-contexts: general when they are missing antecedents or when they possess extra rules (in a frame system this entails missing preconditions or extra types), since an extra rule included an example that should be left out, while the inclusion of a missing antecedent rejects an example that was not left out <ref> (Mooney & Ourston, 1991) </ref>. 17. Note that the use of incompleteness as a logical term is different. A logically incomplete domain theory is one in which a positive example of a category cannot be proven.
Reference: <editor> Michalski and G. Tecuci (eds.), </editor> <booktitle> Proceedings of the First International Workshop on Multistrategy Learning. </booktitle> <address> Harpers Ferry, WV, </address> <month> (November), </month> <pages> pp. 217-230. </pages>
Reference: <author> Newell, A., and Simon, H. A. </author> <year> (1972). </year> <title> Human Problem Solving. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ. </address>
Reference: <author> Owens, C. </author> <year> (1991). </year> <title> A Functional Taxonomy of Abstract Plan Failures, </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society. </booktitle> <address> Chicago, IL, </address> <month> (August 7-10), </month> <pages> pp. 167-172. </pages>
Reference-contexts: When a plan fails, the planner must recover from the error so additional progress can be made toward the goal. After recovery, the plan needs to be repaired and stored again in memory, so that the plan failure will not recur. For example <ref> (taken from Owens, 1991) </ref>, if an autonomous robot vehicle finds an expected fuel cache missing and thereby runs out of gasoline, it must first recover from the potentially threatening situation by obtaining fuel. Owens claims that the explanation of the failure will dictate the means of recovery.
Reference: <author> Park, Y. T., and Wilkins, D. C. </author> <year> (1990). </year> <title> Establishing the Coherence of an Explanation to Improve Refinement of an Incomplete knowledge Base. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence. </booktitle> <address> Boston, MA, </address> <pages> pp. 318-323. </pages>
Reference: <author> Pazzani, M. </author> <year> (1991). </year> <title> Learning Causal Patterns: Deliberately overgeneralizing to facilitate transfer. </title>
Reference: <editor> In R. S. Michalski and G. Tecuci (eds.), </editor> <booktitle> Proceedings of the First International Workshop on Mul-tistrategy Learning. </booktitle> <address> Harpers Ferry, WV, </address> <month> (November), </month> <pages> pp. 19-33. </pages>
Reference: <author> Pirolli, P., and Bielaczyc, K. </author> <year> (1989). </year> <title> Empirical Analyses of Self-Explanation and Transfer in Learning to Program. </title> <booktitle> In Proceedings of the Eleventh Annual Conference of the Cognitive Science Society. </booktitle> <address> Ann Arbor, MI, </address> <pages> pp. 450-457. </pages>
Reference: <author> Punch III, W. F. </author> <year> (1991). </year> <title> TIPS (Task-Integrated Problem Solver), a Task-Specific Integration Architecture for Heterogeneous Agents. </title> <booktitle> In Proceedings of the AAAI Workshop on Cooperation Among Heterogeneous Intelligent Agents, </booktitle> <address> Anaheim, CA, </address> <month> (July, </month> <note> 15). 79 Ram, </note> <author> A. </author> <year> (1989). </year> <title> "Question-Driven Understanding: An integrated theory of story understanding, memory and learning," </title> <type> PhD Thesis, Research Report 710, </type> <institution> Yale University, </institution> <address> New Haven, CT (May). </address>
Reference: <author> Ram, A. </author> <year> (1990). </year> <title> Decision Models: A theory of volitional explanation, </title> <booktitle> In Proceedings of Twelfth Annual Conference of the Cognitive Science Society, </booktitle> <address> Cambridge, MA, </address> <month> (July 25-28), </month> <pages> pp. 198-205. </pages>
Reference-contexts: To explain the incongruity, the system must analyze the anomaly. AQUA accomplishes this by consulting a decision-model <ref> (Ram, 1990) </ref> that describes the planning process an agent goes through when considering the choice of actions to be performed in the world. <p> These nodes represent what must be present in the current situation for the XP to apply. One distinguished node in this set is called the EXPLAINS node. It is bound to the concept which is being explained. Source nodes are termed XP-ASSERTED-NODES. All other nodes are INTERNAL-XP-NODES <ref> (Ram, 1990, 1991, 1993) </ref>. For an XP to apply to a given situation, all PRE-XP-NODES must be in the current set of beliefs.
Reference: <author> Ram, A. </author> <year> (1991). </year> <title> A Theory of Questions and Question Asking. </title> <journal> The Journal of the Learning Sciences, </journal> <volume> Vol. 1, Nos. 3&4, </volume> <pages> pp 273-318. </pages>
Reference-contexts: Following this specification the system can pick an explanation method that will answer these questions. Though AQUA itself does not choose a method, but has only a single procedure, any number of abductive methods will suffice instead <ref> (Ram & Leake, 1991) </ref>. Once a strategy is settled on, the program can generate the explanation. The first step in explanation generation is similar to the blame assignment step in learning, the second is goal specification, and the third is strategy selection. <p> Incorrect Domain Knowledge: Even if the reasoner has applicable knowledge structures, they may be incorrect or incomplete. Learning in such situations is usually incremental, and involves strategies such as elaborative question asking <ref> (Ram, 1991, 1993) </ref> applied to the reasoning chain, 32 and abstraction and generalization techniques (Michalski, 1991) applied to the domain knowledge. Missing Input: The system requires information or otherwise detects some information that is lacking in the givens.
Reference: <author> Ram, A. </author> <year> (1993). </year> <title> Indexing, Elaboration and Refinement: Incremental Learning of Explanatory Cases. </title> <journal> Machine Learning. </journal> <volume> Vol. 10, </volume> <pages> pp. 201-248. </pages>
Reference-contexts: In such cases, the reasoner could use a variety of learning strategies, including explanation-based generalization (DeJong and Mooney, 1986; Mitchell, Keller & Kedar-Cabelli, 1986) or explanation-based refinement <ref> (Ram, 1993) </ref>, coupled with index learning (Bhatta & Ram, 1991; Hammond, 1989; Ram, 1993) to organize the new knowledge structures. Incorrect Domain Knowledge: Even if the reasoner has applicable knowledge structures, they may be incorrect or incomplete.
Reference: <author> Ram, A., and Cox, M. T. </author> <title> (to appear). Introspective Reasoning Using Meta-Explanations for Mul-tistrategy Learning. In Machine Learning: A multistrategy approach IV, </title> <editor> Michalski, R. S. and Tecuci, G. (eds.). </editor> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address> <note> (Also available as Technical Report GIT-CC-92/19, </note> <institution> College of Computing, Georgia Institute of Technology, </institution> <address> Atlanta, GA). </address>
Reference: <author> Ram, A., Cox, M. T. and Narayanan, S. </author> <year> (1992). </year> <title> An Architecture for Integrated Introspective Learning. </title> <editor> In M. Weintraub (ed.), </editor> <booktitle> Proceedings of the ML-92 Workshop on Computational Architectures for Supporting Machine Learning & Knowledge Acquisition, </booktitle> <address> Aberdeen, Scotland, </address> <month> (July 4). </month>
Reference: <author> Ram, A., and Hunter, L. </author> <year> (1992). </year> <title> The Use of Explicit Goals for Knowledge to Guide Inference and Learning. </title> <journal> Applied Intelligence, </journal> <volume> Vol 2, No. 1, </volume> <pages> pp. 47-73. </pages>
Reference: <author> Ram, A., and Leake, D. </author> <year> (1991). </year> <title> Evaluation of Explanatory Hypotheses. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society. </booktitle> <address> Chicago, IL, </address> <month> (August 7-10), </month> <pages> pp. 867-871. </pages>
Reference-contexts: Following this specification the system can pick an explanation method that will answer these questions. Though AQUA itself does not choose a method, but has only a single procedure, any number of abductive methods will suffice instead <ref> (Ram & Leake, 1991) </ref>. Once a strategy is settled on, the program can generate the explanation. The first step in explanation generation is similar to the blame assignment step in learning, the second is goal specification, and the third is strategy selection. <p> Incorrect Domain Knowledge: Even if the reasoner has applicable knowledge structures, they may be incorrect or incomplete. Learning in such situations is usually incremental, and involves strategies such as elaborative question asking <ref> (Ram, 1991, 1993) </ref> applied to the reasoning chain, 32 and abstraction and generalization techniques (Michalski, 1991) applied to the domain knowledge. Missing Input: The system requires information or otherwise detects some information that is lacking in the givens.
Reference: <author> Recker, M., and Pirolli, P. </author> <title> (to appear). Modelling Individual Differences in Students Learning Strategies, </title> <journal> Journal of the Learning Sciences. </journal>
Reference: <author> Redmond, M. A. </author> <year> (1992). </year> <title> "Learning by Observing and Understanding Expert Problem Solving." </title> <type> PhD Thesis, Technical Report GIT-CC-92/43, </type> <institution> Georgia Institute of Technology, </institution> <address> Atlanta, GA (Sep-tember). </address>
Reference: <author> Rosenbloom, P., Laird, J. and Newell, A. </author> <year> (1988). </year> <editor> Meta-Levels in Soar. In P. Maes and D. Nardi (eds.), </editor> <booktitle> Meta-Level Architectures and Reection. </booktitle> <publisher> North Holland, Amsterdam, </publisher> <pages> pp. 227-240. </pages>
Reference-contexts: Although the fundamental philosophies and approaches of multistrategy learning and learning via chunking appear to be incongruent, it is anticipated that the differences can be reconciled, and that a complete accounting of learning will likely include both theories. In addition, Soar claims to possess a meta-level architecture <ref> (see Rosenbloom, Laird, and Newell, 1988) </ref>. These claims must also be evaluated with respect to the theory embodied in Meta-AQUA.
Reference: <author> Schank, R. C. </author> <year> (1982). </year> <title> Dynamic Memory: A theory of reminding and learning in computers and people. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Schank, R. C. </author> <year> (1986). </year> <title> Explanation Patterns: Understanding mechanically and creatively. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Schank, R. C., and Leake, D. </author> <year> (1990). </year> <title> Creativity and Learning in a Case-Based Explainer. </title> <editor> In J. </editor> <publisher> G. </publisher>
Reference: <editor> Carbonell (ed.), </editor> <title> Machine Learning: Paradigms and methods. </title> <publisher> MIT Press. </publisher> <address> Cambridge, MA. </address>
Reference: <author> Schank, R. C., and Osgood, R. </author> <year> (1990). </year> <title> A Content Theory of Memory Indexing. </title> <type> Technical Report 2. </type> <institution> Institute for the Learning Sciences, Northwestern University, </institution> <address> Evanston, IL. </address>
Reference: <author> Schank, R. C., and Owens, C. C. </author> <year> (1987). </year> <title> Understanding by Explaining Expectation Failures. </title> <booktitle> In R. </booktitle>
Reference: <author> G. Reilly (ed.), </author> <title> Communication Failure in Dialogue and Discourse. </title> <publisher> Elsevier Science Publishers B. V., </publisher> <address> New York. </address>
Reference: <author> Schneider, W. </author> <year> (1985). </year> <title> Developmental Trends in the Metamemory-Memory Behavior Relation 80 ship: An integrative review. </title> <editor> In D. L. Forrest-Pressley, G. E. MacKinnon, and T. G. Waller (eds.), Metacognition, </editor> <booktitle> Cognition and Human Performance. Vol. 1 (Theoretical Perspectives), </booktitle> <publisher> Academic Press, Inc., </publisher> <address> New York, </address> <pages> pp. 57-109. </pages>
Reference: <author> Sleeman, D., Langley, P., and Mitchell, T. </author> <year> (1984). </year> <title> Learning from Solution Paths: An approach to the credit assignment problem. </title> <note> CIP Working Paper 443. </note> <institution> Carnegie Melon University. </institution> <address> Pittsburgh, PA. </address>
Reference: <author> Spear, N. E. </author> <year> (1978). </year> <title> The Processing of Memories: Forgetting and retention. </title> <publisher> Lawrence Erlbaum Associates, Publishers, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Stefik, M. </author> <year> (1981). </year> <title> Planning and Metaplanning (MOLGEN: Part 2), </title> <journal> Artificial Intelligence. </journal> <volume> Vol. 16, </volume> <pages> pp. 141-169. </pages>
Reference: <author> Stroulia, E. </author> <year> (1992). </year> <title> "Towards a Functional Model of Reective Learning." </title> <type> PhD Proposal, Technical Report GIT-CC-92/56, </type> <institution> Georgia Institute of Technology, Atlanta, GA (November). </institution>
Reference: <author> Stroulia, E., and Goel, A. </author> <year> (1992). </year> <title> A Model-Based Approach to Incremental Self-Adaptation. </title> <booktitle> In M. </booktitle>
Reference: <editor> Weintraub (ed.), </editor> <booktitle> Proceedings of the ML-92 Workshop on Computational Architectures for Supporting Machine Learning & Knowledge Acquisition, </booktitle> <address> Aberdeen, Scotland, </address> <month> (July, 4). </month>
Reference: <author> Stroulia, E., Shankar, M., Goel, A., and Penberthy, L. </author> <title> (1992) A Model-Based Approach to Blame Assignment in Design. </title> <editor> In J. S.Gero (ed.), </editor> <booktitle> Proceedings of AID'92: Second International Conference on AI in Design, </booktitle> <month> (June), </month> <pages> pp. 519-537. </pages>
Reference: <author> Suchman, L. </author> <year> (1987). </year> <title> Plans and Situated Action: The problem of human-machine communication. </title> <publisher> Cambridge Press. </publisher> <address> Cambridge, MA. </address>
Reference: <author> Sussman, G. J. </author> <year> (1975). </year> <title> A Computer Model of Skill Acquisition. </title> <address> New York: </address> <publisher> American Elsevier. </publisher>
Reference: <author> Van Lehn, K. </author> <year> (1991). </year> <title> Rule Acquisition Events in the Discovery of Problem Solving Strategies. </title> <journal> Cognitive Science. </journal> <volume> Vol. 15, No. 1, </volume> <pages> pp. 1-47. </pages>
Reference: <author> Van Lehn, K., Jones, R. M., and Chi, M. T. H. </author> <year> (1992). </year> <title> A Model of the Self-Explanation Effect. </title> <journal> Journal of the Learning Sciences, </journal> <volume> Vol. 2, No. 1, </volume> <pages> pp. 1-60. </pages>
Reference: <author> Veloso, M., and Carbonell, J. G. </author> <year> (1991). </year> <title> Automating Case Generation, Storage and Retrieval in PRODIGY, </title> <editor> In R. S. Michalski, and G. Tecuci (eds.), </editor> <booktitle> Proceedings of the First International Workshop on Multistrategy Learning. </booktitle> <address> Harpers Ferry, WV, </address> <month> (November), pp.363-377. </month>
Reference-contexts: a police dog is used to find a marijuana plant in a trash bin within a suspects home produces no errors. 4.2 Process Model of Learning Meta-AQUA records its reasoning during the task of story understanding in a trace structure similar to the derivational analogy traces of the PRODIGY system <ref> (Veloso & Carbonell, 1991) </ref>. These knowledge structures contain representations for each of the reasoning phases: anomaly identification, hypothesis formation, and verification. For each phase the structure records the considerations that prompted the phase, the bases for making a reasoning strategy decision, and the result of such strategy execution.
Reference: <author> Weinert, F. E. </author> <year> (1987). </year> <title> Introduction and Overview: Metacognition and motivation as determinants of effective learning and understanding. </title> <editor> In F. E. Weinert and R. H. Kluwe (eds.), Metacognition, </editor> <title> Motivation, and Understanding. </title> <publisher> Lawrence Erlbaum Associates, Publishers, </publisher> <address> Hillsdale, NJ. </address>
Reference-contexts: Humans often know when they are making progress in problem solving, even if they are far from a solution, and they know when they have sufficiently learned something with respect to some goal <ref> (Weinert, 1987) </ref>. They know how to allocate mental resources and can judge when learning is over. Many reviews (e.g., Chi, 1987; Schneider, 1985; Wellman, 1983) cite evidence for such claims.
Reference: <author> Weintraub, M. A. </author> <year> (1991). </year> <title> "An Explanation-Based Approach to Assigning Credit" PhD Thesis. </title> <institution> Ohio State University. </institution>
Reference: <author> Wellman, H. M. </author> <year> (1983). </year> <title> Metamemory Revisited. </title> <editor> In M. T. H. Chi (ed.), </editor> <booktitle> Contributions to Human Development. Vol. 9 (Trends in memory development research). </booktitle> <editor> S. Karger, </editor> <publisher> AG, Basel, Switzer-land. </publisher>
Reference: <author> Wellman, H. M. </author> <year> (1985). </year> <title> The Origins of Metacognition. </title> <editor> In D. L. Forrest-Pressley, G. E. MacKin-non, and T. G. Waller (eds.), Metacognition, </editor> <booktitle> Cognition and Human Performance. Vol. 1 (Theoretical Perspectives), </booktitle> <publisher> Academic Press, Inc., </publisher> <address> New York, </address> <pages> pp. 1-31. </pages> <note> 81 Wellman, </note> <author> H. M., and Johnson, C. N. </author> <year> (1979). </year> <title> Understanding of Mental Process: A developmental study of "remember" and "forget," Child Development, </title> <journal> Vol. </journal> <volume> 50, </volume> <pages> pp. 79-88. </pages>
Reference: <author> Wilson, T. D., and Schooler, J. W. </author> <year> (1991). </year> <title> Thinking Too Much: Introspection can reduce the quality of preferences and decisions. </title> <journal> Journal of Personality and Social Psychology, </journal> <volume> Vol. 60, No. 2, </volume> <pages> pp. 181-192. </pages>

References-found: 97

