URL: http://cobar.cs.umass.edu/pubfiles/cb-28.ps.gz
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Title: What you saw is what you want: Using Cases to seed Information Retrieval.  
Author: Jody J. Daniels and Edwina L. Rissland 
Address: Amherst, MA 01003 USA  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: This paper presents a hybrid case-based reasoning (CBR) and information retrieval (IR) system, called SPIRE, that both retrieves documents from a full-text document corpus and from within individual documents, and locates passages likely to contain information about important problem-solving features of cases. SPIRE uses two case-bases, one containing past precedents, and one containing excerpts from past case texts. Both are used by SPIRE to automatically generate queries, which are then run by the INQUERY full-text retrieval engine on a large text collection in the case of document retrieval and on individual text documents for passage retrieval.
Abstract-found: 1
Intro-found: 1
Reference: [Ash90] <author> Kevin D. Ashley. </author> <title> Modeling Legal Argument: Reasoning with Cases and Hy-potheticals. </title> <publisher> M.I.T. Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: The first case-base is the standard type of case-base used by many generations of our own HYPO-style CBR systems with their concomitant mechanisms of dimension-based analysis, sorting into a claim lattice, etc. <ref> [Ash90] </ref>. The second is simply a collection of textual fragments partitioned into sub-case-bases, one for each problem feature of interest. Indexing and selection are minimal in the second case-base at this point; the feature (name) serves as the index and all fragments are selected. <p> In the usual CBR fashion, SPIRE determines the similarity of each known case to the new problem and represents the results of this analysis in a standard claim lattice <ref> [Ash90] </ref>. The most relevant cases from this analysis|typically the cases in the top two layers of the claim lattice|are then used to "prime the pump" of INQUERY's relevance feedback module.
Reference: [CCH92] <author> James P. Callan, W. Bruce Croft, and Stephen M. Harding. </author> <title> The INQUERY Retrieval System. </title> <editor> In A. M. Tjoa and I. Ramos, editors, </editor> <booktitle> Database and Expert Systems Applications: Proceedings of the International Conference in Valen-cia, Spain, </booktitle> <pages> pages 78-83, </pages> <address> Valencia, Spain, 1992. </address> <publisher> Springer Verlag, </publisher> <address> NY. </address>
Reference-contexts: Both case-bases are used by SPIRE to generate queries, which are then acted upon by the INQUERY retrieval engine in its usual manner <ref> [CCH92] </ref>. The first case-base is the standard type of case-base used by many generations of our own HYPO-style CBR systems with their concomitant mechanisms of dimension-based analysis, sorting into a claim lattice, etc. [Ash90].
Reference: [Coo68] <author> William S. Cooper. </author> <title> Expected Search Length: A Single Measure of Retrieval Effectiveness Based on the Weak Ordering Action of Retrieval Systems. </title> <journal> American Documentation, </journal> <volume> 19 </volume> <pages> 30-41, </pages> <year> 1968. </year>
Reference: [Dan97] <author> Jody J. Daniels. </author> <title> Retreival of Passages for Information Reduction. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, </institution> <address> Amherst, Amherst, MA, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: Example excerpts are given in Section 3. There are numerous techniques for transforming the excerpts into passage retrieval queries. (A fuller discussion of this can be found in <ref> [Dan97] </ref>.) SPIRE presents the query along with a specified document to the IR engine, which, in turn, retrieves the top ranked passages for presentation to the user or possibly to an information extraction system. <p> These are the two base methods that performed the best. The others in this set were: bag of words plus phrases, sum plus phrases, and set of words. Formation and results for these queries is discussed in more detail in <ref> [Dan97] </ref>. We had SPIRE build two other sets of queries. The first is based on a term weighting scheme suggested by Kwok [Kwo96] and the second set is what we called semi-random. The latter incorporated only one-half or one-third of the available query terms from the excerpt case-base. <p> The latter incorporated only one-half or one-third of the available query terms from the excerpt case-base. Neither of these sets performed better than the two base queries. (See <ref> [Dan97] </ref> for details.) To provide another point of comparison, we also had a human expert, familiar with both the domain and INQUERY query operators, create queries. These manual queries are highly refined expert queries and provide a very high baseline.
Reference: [DR95] <author> Jody J. Daniels and Edwina L. Rissland. </author> <title> A Case-Based Approach to Intelligent Information Retrieval. </title> <booktitle> In Proceedings of the 18th Annual International ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 238-245, </pages> <address> Seattle, WA, </address> <month> July </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: EEC-9209623, State/Industry/- University Cooperative Research on Intelligent Information Retrieval. features. In this paper, we emphasize retrieval at the passage level; other papers have detailed retrieval at the document level <ref> [DR95, RD96] </ref>. After problem entry, SPIRE performs all of its processing, including the generation of needed queries, without any intervention on the part of the user. <p> This query is then run against the larger corpus of texts, with the result that new documents are retrieved and ranked according to INQUERY's belief as to their relevance to the posed query. (A detailed description of this first stage can be found in <ref> [DR95, RD96] </ref>.) Fig. 1. Overview of SPIRE. In the second stage, SPIRE locates germane passages within each of the texts retrieved in stage one. In this stage SPIRE locates passages within a single document rather than documents within a collection. Again SPIRE uses a hybrid CBR-IR approach.
Reference: [Kol93] <author> Janet L. Kolodner. </author> <title> Case-Based Reasoning. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Thus, the only representational or processing burden on the user is the specification of the problem case, which is done in a manner that is standard practice in CBR systems (without natural language front-ends) <ref> [Kol93] </ref>. Thus SPIRE locates relevant textual regions within documents without imposing on the user the burden of reading entire documents. SPIRE uses two case-bases: 1. A case-base of past, resolved problem situations (precedents) represented as case-frames of features for use by a HYPO-style CBR module. 2.
Reference: [Kwo96] <author> K. L. Kwok. </author> <title> A New Method of Weighting Query Terms for Ad-Hoc Retrieval. </title> <booktitle> In Proceedings of the 19th Annual International ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 187-195, </pages> <address> Zurich, Switzerland, </address> <month> August </month> <year> 1996. </year> <note> ACM. </note>
Reference-contexts: Formation and results for these queries is discussed in more detail in [Dan97]. We had SPIRE build two other sets of queries. The first is based on a term weighting scheme suggested by Kwok <ref> [Kwo96] </ref> and the second set is what we called semi-random. The latter incorporated only one-half or one-third of the available query terms from the excerpt case-base.
Reference: [RD95] <author> Edwina L. Rissland and Jody J. Daniels. </author> <title> Using CBR to Drive IR. </title> <booktitle> In Proceedings, 14th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 400-407, </pages> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year> <note> AAAI. </note>
Reference-contexts: The most relevant cases from this analysis|typically the cases in the top two layers of the claim lattice|are then used to "prime the pump" of INQUERY's relevance feedback module. This set of cases is called the relevance feedback case-knowledge-base or RF-CKB <ref> [RD95, RD96] </ref>. (These are labeled as "Best Case Texts" in Figure 1.) The original texts of the cases in the RF-CKB are passed to the INQUERY IR engine, which then treats them as though they had been marked relevant by a user.
Reference: [RD96] <author> Edwina L. Rissland and Jody J. Daniels. </author> <title> The Synergistic Application of CBR to IR. </title> <journal> Artificial Intelligence Review, </journal> <volume> 10 </volume> <pages> 441-475, </pages> <year> 1996. </year>
Reference-contexts: EEC-9209623, State/Industry/- University Cooperative Research on Intelligent Information Retrieval. features. In this paper, we emphasize retrieval at the passage level; other papers have detailed retrieval at the document level <ref> [DR95, RD96] </ref>. After problem entry, SPIRE performs all of its processing, including the generation of needed queries, without any intervention on the part of the user. <p> The most relevant cases from this analysis|typically the cases in the top two layers of the claim lattice|are then used to "prime the pump" of INQUERY's relevance feedback module. This set of cases is called the relevance feedback case-knowledge-base or RF-CKB <ref> [RD95, RD96] </ref>. (These are labeled as "Best Case Texts" in Figure 1.) The original texts of the cases in the RF-CKB are passed to the INQUERY IR engine, which then treats them as though they had been marked relevant by a user. <p> This query is then run against the larger corpus of texts, with the result that new documents are retrieved and ranked according to INQUERY's belief as to their relevance to the posed query. (A detailed description of this first stage can be found in <ref> [DR95, RD96] </ref>.) Fig. 1. Overview of SPIRE. In the second stage, SPIRE locates germane passages within each of the texts retrieved in stage one. In this stage SPIRE locates passages within a single document rather than documents within a collection. Again SPIRE uses a hybrid CBR-IR approach.
Reference: [RSF96] <author> Edwina L. Rissland, D. B. Skalak, and M. Timur Friedman. BankXX: </author> <title> Supporting Legal Arguments through Heuristic Retrieval. </title> <journal> Artificial Intelligence Review, </journal> <pages> 10(1-71), </pages> <year> 1996. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: However, since we were re-using a portion of the bankruptcy case-base used in the BankXX project <ref> [RSF96] </ref>, this highlighting of textual examples was done post hoc.
References-found: 10

