URL: http://www.cs.umd.edu/users/franklin/papers/diskcache.ps.gz
Refering-URL: http://www.cs.umd.edu/~franklin/papers.html
Root-URL: 
Email: fmjf,carey,mirong@cs.wisc.edu  
Title: Local Disk Caching for Client-Server Database Systems  
Author: Michael J. Franklin Michael J. Carey Miron Livny 
Address: Wisconsin Madison  
Affiliation: Computer Sciences Department University of  
Abstract: The performance and scalability of a client-server database system can be improved by employing client disks for caching. Client disk caching is particularly useful due to the lower cost per byte (compared to memory) and non-volatility of disk storage. Because of performance considerations, however, disk caching is not a straightforward extension of memory caching. In this paper, we examine the performance impacts of adding client disks to the storage hierarchy of a client-server DBMS and investigate the tradeoffs inherent in keeping a large volume of disk-cached data consistent. We describe and analyze four algorithms for managing disk caches. We also address two extensions to cache management algorithms that arise due to the performance characteristics of large disk caches: 1) the need for methods to reduce the work performed by the server for ensuring transaction durability, and 2) techniques for bringing a large disk-resident cache up-to-date after an extended off-line period.
Abstract-found: 1
Intro-found: 1
Reference: [Alon90] <author> R. Alonso, D. Barbara, H. Garcia-Molina, </author> <title> "Data Caching Issues in an Information Retrieval System", </title> <journal> ACM Trans on Database Systems, </journal> <volume> 15(3), </volume> <month> September, </month> <year> 1990. </year>
Reference: [Care91] <author> M. Carey, M. Franklin, M. Livny, and E. Shekita, </author> <title> "Data Caching Tradeoffs in Client-Server DBMS Architectures", </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Denver, </address> <month> June, </month> <year> 1991. </year>
Reference-contexts: This omission is potentially costly, as client disks represent a valuable addition to the storage hierarchy of a client-server OODBMS due to their capacity and non-volatility. Inter-transaction memory caching and other client memory management techniques have been shown to provide substantial performance benefits for client-server database systems <ref> [Wilk90, Care91, Wang91, Fran92a, Fran92b] </ref>. In this paper, we investigate the extension of client-server caching to the use of client disks. We focus on data-shipping systems in which pages serve as the unit of interaction between clients and servers. <p> In this paper, we study a different approach to using client disks, namely, we extend our previous work on memory caching <ref> [Care91, Fran92a, Fran92b] </ref> to take advantage of client disks. Caching can be thought of as a method of dynamic replication, where the location of pages is driven by the access patterns of applications. <p> Otherwise, the chosen page is simply overwritten. 2.2 An Algorithm for Memory Cache Management Based on the results of our earlier investigations of algorithms for memory cache management <ref> [Care91, Fran92a] </ref>, we have adopted the Callback-Read (CB-R) algorithm to serve as the basis for our ongoing work. As is shown in [Fran92a], CB-R provides good performance and is robust with respect to many system and workload parameters. <p> The size of this information is proportional to the number of distinct items that are cached. The third important tradeoff relates to a metric we call the effective disk cache size. In earlier studies <ref> [Dan90, Care91] </ref> it has been observed that for memory caches, the amount of useful (valid) data that can be kept in client caches is lower for detection than for avoidance. This is because detection allows pages to remain in the cache after they become out-of-date. <p> In this section, we briefly describe the model; a more detailed description of the basic model can be found in <ref> [Care91] </ref>. The model was constructed using the 10 DeNet discrete event simulation language [Livn88]. It consists of components that model a server machine and a varying number of client workstations that are connected over a simple network. <p> Therefore, LD/A does more total (server and client) disk reads to get its pages than SM/D. Third, with one client, LD/A does not access any pages from the server memory, but then reaches a fairly stable level of access. As seen in previous studies <ref> [Dan90, Care91, Fran92a] </ref>, the initial low server memory hit rate is due to correlation between the contents of the client's caches and the server memory with few clients, the server memory largely contains copies of the pages that are in client memories, so the server memory is less effective for serving
Reference: [Dan90] <author> A. Dan, D. Dias, P.Yu, </author> <title> "The Effect of Skewed Data Access on Buffer Hits and Data Contention in a Data Sharing Environment", </title> <booktitle> Proc. 16th VLDB Conf., </booktitle> <address> Brisbane, Australia, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: The size of this information is proportional to the number of distinct items that are cached. The third important tradeoff relates to a metric we call the effective disk cache size. In earlier studies <ref> [Dan90, Care91] </ref> it has been observed that for memory caches, the amount of useful (valid) data that can be kept in client caches is lower for detection than for avoidance. This is because detection allows pages to remain in the cache after they become out-of-date. <p> Therefore, LD/A does more total (server and client) disk reads to get its pages than SM/D. Third, with one client, LD/A does not access any pages from the server memory, but then reaches a fairly stable level of access. As seen in previous studies <ref> [Dan90, Care91, Fran92a] </ref>, the initial low server memory hit rate is due to correlation between the contents of the client's caches and the server memory with few clients, the server memory largely contains copies of the pages that are in client memories, so the server memory is less effective for serving
Reference: [Dan92] <author> A. Dan, P. Yu, </author> <title> "Performance Analysis of Coherency Control Policies through Lock Retention", </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> San Diego, </address> <month> June, </month> <year> 1992. </year>
Reference-contexts: Detection-based schemes are often referred to as check-on-access algorithms <ref> [Dan92] </ref>. In contrast, avoidance-based schemes ensure that all accessible copies of a data page are valid so that access to invalid data is avoided. This can be done by invalidating other replicas of an updated item, or by propagating the new data value to the other replicas. <p> While we are unaware of any work in that has addressed this issue for client-server DBMS, it should be noted that similar issues can arise when transferring pages among the processing nodes of shared-disk transaction processing systems <ref> [Moha91, Dan92] </ref>. In the following discussion, we assume a system that uses a write-ahead-logging (WAL) protocol [Gray93] between clients and the server. Therefore the server is always guaranteed to have all of the log records required to reconstruct the most recently committed state of all database pages.
Reference: [Deli92] <author> A. Delis, N. Roussopoulos, </author> <title> "Performance and Scalability of Client-Server Database Architectures", </title> <booktitle> Proc. 18th VLDB Conf., </booktitle> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Because this approach uses the client disks as an extension of the client's memory-resident caches, we refer to this as the extended cache architecture. In terms of related work, we are aware of only one other study of client disk caching for database systems <ref> [Deli92] </ref>. This work investigates a system in which relational query results are cached on client disks but all updates are performed at the server. Prior to executing a query, a client sends a message to the server requesting any updates that have been applied to tuples cached at the client. <p> The ADMS system developed at Maryland [Rous86] uses an incremental method to update query results that are cached at clients. Updates are performed at clients prior to executing a query at a client. As discussed in Section 1.1, the performance of a similar scheme is studied in <ref> [Deli92] </ref>. Techniques to reduce update overhead for caches in information retrieval systems are addressed in [Alon92]. These techniques are based on quasi-copies; i.e., copies whose values are allowed to diverge from the value of the primary copy.
Reference: [Deux91] <editor> O. Deux et al., </editor> <title> "The O2 System", </title> <journal> Communications of the ACM, </journal> <volume> 34(10), </volume> <month> October, </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Object-Oriented Database Management Systems (OODBMS) are typically constructed using client-server software architectures. Examples include products such as O2 <ref> [Deux91] </ref>, Objectivity [Obje91], ObjectStore [Lamb91], Ontos [Onto92], and Versant [Vers91], as well as research systems such as ORION [Kim90] and EXODUS [Fran92c]. A primary motivation for the use of client-server architectures is the desire to exploit the plentiful and relatively inexpensive resources provided by current workstation technology.
Reference: [DeWi90] <author> D. DeWitt, P. Futtersack, D. Maier, F. Velez, </author> <title> "A Study of Three Alternative Workstation-Server Architectures for Object-Oriented Database Systems", </title> <booktitle> Proc. 16th VLDB Conf., </booktitle> <address> Brisbane, Australia, </address> <month> August, </month> <year> 1990. </year>
Reference-contexts: In this paper, we investigate the extension of client-server caching to the use of client disks. We focus on data-shipping systems in which pages serve as the unit of interaction between clients and servers. Such systems are referred to as page servers <ref> [DeWi90] </ref>. 1.1 Architectural Alternatives for Integrating Client Disks The first step in determining how best to use client disks is to decide how to fit them into the storage hierarchy of an OODBMS. Two important issues that must be considered are data placement and data ownership.
Reference: [Fran92a] <author> M. Franklin, M. Carey, </author> <title> "Client-Server Caching Revisited", </title> <booktitle> Proc. of the Int'l Workshop on Distributed Object Mgmt., </booktitle> <address> Edmonton, Canada, </address> <month> August, </month> <year> 1992. </year>
Reference-contexts: This omission is potentially costly, as client disks represent a valuable addition to the storage hierarchy of a client-server OODBMS due to their capacity and non-volatility. Inter-transaction memory caching and other client memory management techniques have been shown to provide substantial performance benefits for client-server database systems <ref> [Wilk90, Care91, Wang91, Fran92a, Fran92b] </ref>. In this paper, we investigate the extension of client-server caching to the use of client disks. We focus on data-shipping systems in which pages serve as the unit of interaction between clients and servers. <p> In this paper, we study a different approach to using client disks, namely, we extend our previous work on memory caching <ref> [Care91, Fran92a, Fran92b] </ref> to take advantage of client disks. Caching can be thought of as a method of dynamic replication, where the location of pages is driven by the access patterns of applications. <p> Otherwise, the chosen page is simply overwritten. 2.2 An Algorithm for Memory Cache Management Based on the results of our earlier investigations of algorithms for memory cache management <ref> [Care91, Fran92a] </ref>, we have adopted the Callback-Read (CB-R) algorithm to serve as the basis for our ongoing work. As is shown in [Fran92a], CB-R provides good performance and is robust with respect to many system and workload parameters. <p> As is shown in <ref> [Fran92a] </ref>, CB-R provides good performance and is robust with respect to many system and workload parameters. Callback-Read is derived from techniques that were originally used to maintain cache consistency in distributed file systems such as Andrew [Howa88] and Sprite [Nels88]; however, these algorithms did not support serializable transactions. <p> Transactional callback locking algorithms have been employed in the ObjectStore OODBMS [Lamb91] and have been studied in [Wang91] and later in <ref> [Fran92a] </ref>. Under CB-R, all pages in a client's memory cache are guaranteed to be valid. CB-R grants clients authority 5 to read objects in their memory caches, but they must obtain permission from the server to write objects . <p> Therefore, LD/A does more total (server and client) disk reads to get its pages than SM/D. Third, with one client, LD/A does not access any pages from the server memory, but then reaches a fairly stable level of access. As seen in previous studies <ref> [Dan90, Care91, Fran92a] </ref>, the initial low server memory hit rate is due to correlation between the contents of the client's caches and the server memory with few clients, the server memory largely contains copies of the pages that are in client memories, so the server memory is less effective for serving <p> This facility can be added to our existing algorithms by using the Callback-Write (CB-W) algorithm as a basis rather than Callback-Read. As described in <ref> [Fran92a] </ref>, CB-W is a callback locking algorithm that allows clients to retain write (as well as read) permission on pages across transaction boundaries.
Reference: [Fran92b] <author> M. Franklin, M. Carey, and M. Livny, </author> <title> "Global Memory Management in Client-Server DBMS Architectures", </title> <booktitle> Proc. 18th VLDB Conf., </booktitle> <address> Vancouver, B.C., Canada, </address> <month> August, </month> <year> 1992. </year>
Reference-contexts: This omission is potentially costly, as client disks represent a valuable addition to the storage hierarchy of a client-server OODBMS due to their capacity and non-volatility. Inter-transaction memory caching and other client memory management techniques have been shown to provide substantial performance benefits for client-server database systems <ref> [Wilk90, Care91, Wang91, Fran92a, Fran92b] </ref>. In this paper, we investigate the extension of client-server caching to the use of client disks. We focus on data-shipping systems in which pages serve as the unit of interaction between clients and servers. <p> In this paper, we study a different approach to using client disks, namely, we extend our previous work on memory caching <ref> [Care91, Fran92a, Fran92b] </ref> to take advantage of client disks. Caching can be thought of as a method of dynamic replication, where the location of pages is driven by the access patterns of applications. <p> The cost of obtaining a page from a location in the storage hierarchy is dependent on several factors. These include: 1. The path length of accessing the location (e.g., the cost of sending and receiving messages, the cost of performing disk I/O, etc.) 2 As described in <ref> [Fran92b] </ref>, clients can also be allowed to obtain pages from other clients. The additional resources represented by remote clients can be fit into the framework used in this paper; however, for simplicity this issue is not addressed in this study. 6 2. <p> As it turns out, the commit-time page send policy hurts the server memory hit rate because the server memory becomes filled with copies of dirty pages that are also cached at clients (this phenomenon was also observed in <ref> [Fran92b] </ref>). In this experiment, LD/A-KeepDisk reaches a bottleneck at the server CPU because of messages sent for invalidations, and thus, its performance falls steeply beyond 20 clients. <p> We described several approaches that allow clients to re-establish the validity of their cache contents after an off-line period. The use of client disk caches is related to our earlier work on global memory management <ref> [Fran92b] </ref>, as both techniques utilize client resources to offload the server disk. Client disk caching is likely to be easier to add to an existing system because the disk is treated as an extension of the memory cache, while global memory management requires new communication paths.
Reference: [Fran92c] <author> M. Franklin, M. Zwilling, C. Tan, M. Carey, and D. DeWitt, </author> <title> "Crash Recovery in Client-Server EXODUS", </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> San Diego, </address> <month> June, </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Object-Oriented Database Management Systems (OODBMS) are typically constructed using client-server software architectures. Examples include products such as O2 [Deux91], Objectivity [Obje91], ObjectStore [Lamb91], Ontos [Onto92], and Versant [Vers91], as well as research systems such as ORION [Kim90] and EXODUS <ref> [Fran92c] </ref>. A primary motivation for the use of client-server architectures is the desire to exploit the plentiful and relatively inexpensive resources provided by current workstation technology. Moving functionality to the clients provides both performance and scalability benefits. <p> Therefore the server is always guaranteed to have all of the log records required to reconstruct the most recently committed state of all database pages. A description of the implementation of such a protocol (i.e., ARIES [Moha92]) for a client-server DBMS can be found in <ref> [Fran92c] </ref>. 5.1.1 Consequences of Retaining Dirty Pages Relaxing the commit-time page send policy places certain constraints on the operation of clients.
Reference: [Gray93] <author> J. Gray, A. Reuter, </author> <title> Transaction Processing: Concepts and Techniques, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: We also assume that each page is tagged with a version number that uniquely identifies the state of the page with respect to the updates applied to it. Such version numbers are typically maintained by DBMS systems to support recovery (e.g., Log Sequence Numbers (LSN)) <ref> [Gray93] </ref>. The memory cache is managed through the use of a data structure containing an entry for each resident page and a list of available memory cache slots. The LRU chain is threaded through this structure. The disk cache is also managed using LRU replacement. <p> In the following discussion, we assume a system that uses a write-ahead-logging (WAL) protocol <ref> [Gray93] </ref> between clients and the server. Therefore the server is always guaranteed to have all of the log records required to reconstruct the most recently committed state of all database pages.
Reference: [Guy91] <author> R. Guy, "Ficus: </author> <title> A Very Large Scale Reliable Distributed File System", </title> <type> Ph.D. Dissertation, UCLA Technical Report CSD-910018, </type> <month> June, </month> <year> 1991. </year>
Reference-contexts: These techniques are based on quasi-copies; i.e., copies whose values are allowed to diverge from the value of the primary copy. Finally, distributed file systems that support disconnected operation, such as CODA [Kist91] and Ficus <ref> [Guy91] </ref>, must address issues of validating local caches after a disconnected period.
Reference: [Howa88] <author> J. Howard. et al. </author> <title> "Scale and Performance in a Distributed File System", </title> <journal> ACM Trans. on Computer Sys., </journal> <volume> 6(1), </volume> <month> February, </month> <year> 1988. </year>
Reference-contexts: Also related is work on distributed file systems. Unlike existing database systems, some distributed file systems do use client disks for caching, e.g., Andrew <ref> [Howa88] </ref> and its follow-on project CODA [Kist91]. Such caching is viewed as crucial for enabling file-system scalability. <p> As is shown in [Fran92a], CB-R provides good performance and is robust with respect to many system and workload parameters. Callback-Read is derived from techniques that were originally used to maintain cache consistency in distributed file systems such as Andrew <ref> [Howa88] </ref> and Sprite [Nels88]; however, these algorithms did not support serializable transactions. Transactional callback locking algorithms have been employed in the ObjectStore OODBMS [Lamb91] and have been studied in [Wang91] and later in [Fran92a]. Under CB-R, all pages in a client's memory cache are guaranteed to be valid.
Reference: [Kim90] <author> W. Kim, et al., </author> <title> "The Architecture of the ORION Next-Generation Database System," </title> <journal> IEEE Trans. on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <month> March, </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Object-Oriented Database Management Systems (OODBMS) are typically constructed using client-server software architectures. Examples include products such as O2 [Deux91], Objectivity [Obje91], ObjectStore [Lamb91], Ontos [Onto92], and Versant [Vers91], as well as research systems such as ORION <ref> [Kim90] </ref> and EXODUS [Fran92c]. A primary motivation for the use of client-server architectures is the desire to exploit the plentiful and relatively inexpensive resources provided by current workstation technology. Moving functionality to the clients provides both performance and scalability benefits.
Reference: [Kist91] <author> J. Kistler, M. Satyanarayanan, </author> <title> "Disconnected Operation in the Coda File System", </title> <booktitle> Proc. 13th SOSP, </booktitle> <address> Pacific Grove, CA, </address> <month> October </month> <year> 1991. </year> <month> 27 </month>
Reference-contexts: Also related is work on distributed file systems. Unlike existing database systems, some distributed file systems do use client disks for caching, e.g., Andrew [Howa88] and its follow-on project CODA <ref> [Kist91] </ref>. Such caching is viewed as crucial for enabling file-system scalability. <p> Techniques to reduce update overhead for caches in information retrieval systems are addressed in [Alon92]. These techniques are based on quasi-copies; i.e., copies whose values are allowed to diverge from the value of the primary copy. Finally, distributed file systems that support disconnected operation, such as CODA <ref> [Kist91] </ref> and Ficus [Guy91], must address issues of validating local caches after a disconnected period.
Reference: [Lamb91] <author> C. Lamb, G. Landis, J. Orenstein, and D. Weinreb, </author> <title> "The ObjectStore Database System", </title> <journal> Comm. of the ACM, </journal> <volume> 34(10), </volume> <month> October, </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Object-Oriented Database Management Systems (OODBMS) are typically constructed using client-server software architectures. Examples include products such as O2 [Deux91], Objectivity [Obje91], ObjectStore <ref> [Lamb91] </ref>, Ontos [Onto92], and Versant [Vers91], as well as research systems such as ORION [Kim90] and EXODUS [Fran92c]. A primary motivation for the use of client-server architectures is the desire to exploit the plentiful and relatively inexpensive resources provided by current workstation technology. <p> Callback-Read is derived from techniques that were originally used to maintain cache consistency in distributed file systems such as Andrew [Howa88] and Sprite [Nels88]; however, these algorithms did not support serializable transactions. Transactional callback locking algorithms have been employed in the ObjectStore OODBMS <ref> [Lamb91] </ref> and have been studied in [Wang91] and later in [Fran92a]. Under CB-R, all pages in a client's memory cache are guaranteed to be valid. CB-R grants clients authority 5 to read objects in their memory caches, but they must obtain permission from the server to write objects .
Reference: [Livn88] <author> M. Livny, </author> <note> DeNet User's Guide, Version 1.0, Comp. </note> <institution> Sci. Dept., Univ. of Wisconsin-Madison, </institution> <year> 1988. </year>
Reference-contexts: In this section, we briefly describe the model; a more detailed description of the basic model can be found in [Care91]. The model was constructed using the 10 DeNet discrete event simulation language <ref> [Livn88] </ref>. It consists of components that model a server machine and a varying number of client workstations that are connected over a simple network.
Reference: [Moha91] <author> C. Mohan, I. Narang, </author> <title> "Recovery and Coherency-Control Protocols for Fast Intersystem Page Transfer and Fine-Granularity Locking in a Shared Disks Transaction Environment", </title> <booktitle> Proc. 17th VLDB Conf., </booktitle> <address> Barcelona, </address> <month> Sept., </month> <year> 1991. </year>
Reference-contexts: While we are unaware of any work in that has addressed this issue for client-server DBMS, it should be noted that similar issues can arise when transferring pages among the processing nodes of shared-disk transaction processing systems <ref> [Moha91, Dan92] </ref>. In the following discussion, we assume a system that uses a write-ahead-logging (WAL) protocol [Gray93] between clients and the server. Therefore the server is always guaranteed to have all of the log records required to reconstruct the most recently committed state of all database pages.
Reference: [Moha92] <author> C. Mohan, et al., </author> <title> "ARIES: A Transaction Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging", </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 17(1), </volume> <month> March, </month> <year> 1992. </year>
Reference-contexts: Therefore the server is always guaranteed to have all of the log records required to reconstruct the most recently committed state of all database pages. A description of the implementation of such a protocol (i.e., ARIES <ref> [Moha92] </ref>) for a client-server DBMS can be found in [Fran92c]. 5.1.1 Consequences of Retaining Dirty Pages Relaxing the commit-time page send policy places certain constraints on the operation of clients.
Reference: [Nels88] <author> M. Nelson, B. Welch, J. Ousterhout, </author> <title> "Caching in the Sprite Network File System", </title> <journal> ACM Trans. on Computer Sys. </journal> <volume> 6(1), </volume> <month> February, </month> <year> 1988. </year>
Reference-contexts: As is shown in [Fran92a], CB-R provides good performance and is robust with respect to many system and workload parameters. Callback-Read is derived from techniques that were originally used to maintain cache consistency in distributed file systems such as Andrew [Howa88] and Sprite <ref> [Nels88] </ref>; however, these algorithms did not support serializable transactions. Transactional callback locking algorithms have been employed in the ObjectStore OODBMS [Lamb91] and have been studied in [Wang91] and later in [Fran92a]. Under CB-R, all pages in a client's memory cache are guaranteed to be valid.
Reference: [Obje91] <institution> Objectivity Inc., </institution> <note> Objectivity/DB Documentation Vol. 1, </note> <year> 1991. </year>
Reference-contexts: 1 Introduction Object-Oriented Database Management Systems (OODBMS) are typically constructed using client-server software architectures. Examples include products such as O2 [Deux91], Objectivity <ref> [Obje91] </ref>, ObjectStore [Lamb91], Ontos [Onto92], and Versant [Vers91], as well as research systems such as ORION [Kim90] and EXODUS [Fran92c]. A primary motivation for the use of client-server architectures is the desire to exploit the plentiful and relatively inexpensive resources provided by current workstation technology.
Reference: [Onto92] <author> ONTOS Inc., </author> <title> ONTOS DB 2.2 Reference Manual, </title> <year> 1992. </year>
Reference-contexts: 1 Introduction Object-Oriented Database Management Systems (OODBMS) are typically constructed using client-server software architectures. Examples include products such as O2 [Deux91], Objectivity [Obje91], ObjectStore [Lamb91], Ontos <ref> [Onto92] </ref>, and Versant [Vers91], as well as research systems such as ORION [Kim90] and EXODUS [Fran92c]. A primary motivation for the use of client-server architectures is the desire to exploit the plentiful and relatively inexpensive resources provided by current workstation technology.
Reference: [Rous86] <author> N. Roussopoulos, H. Kang, </author> <booktitle> "Principles and Techniques in the Design of ADMS+-", IEEE Computer, </booktitle> <month> December, </month> <year> 1986. </year>
Reference-contexts: Several projects have performed work on deferred consistency maintenance that is related to the proposals of this section. The ADMS system developed at Maryland <ref> [Rous86] </ref> uses an incremental method to update query results that are cached at clients. Updates are performed at clients prior to executing a query at a client. As discussed in Section 1.1, the performance of a similar scheme is studied in [Deli92].
Reference: [Trai82] <author> I. Traiger, </author> <title> "Virtual Memory Management for Database Systems", </title> <journal> Operating Systems Review, </journal> <volume> 16(4), </volume> <month> October, </month> <year> 1982. </year>
Reference-contexts: The problems of the second approach, using operating system virtual memory for buffer management, are well known (e.g., <ref> [Ston81, Trai82] </ref>), and stem from 2 (among other things) the operating system's lack of knowledge about database access patterns and differences in disk management policies. Relying on the operating system to manage the client disk places an important performance issue beyond the control of the database system.
Reference: [Vers91] <author> Versant Object Technology, </author> <title> VERSANT System Reference Manual, Release 1.6, </title> <address> Menlo Park, CA, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Object-Oriented Database Management Systems (OODBMS) are typically constructed using client-server software architectures. Examples include products such as O2 [Deux91], Objectivity [Obje91], ObjectStore [Lamb91], Ontos [Onto92], and Versant <ref> [Vers91] </ref>, as well as research systems such as ORION [Kim90] and EXODUS [Fran92c]. A primary motivation for the use of client-server architectures is the desire to exploit the plentiful and relatively inexpensive resources provided by current workstation technology. Moving functionality to the clients provides both performance and scalability benefits. <p> Most OODBMS keep their client caches in virtual memory, so if the cache becomes larger than the allocated physical memory, the operating system will swap parts of the cache to disk. The Versant system provides an additional way of using client disks, called the Personal Database <ref> [Vers91] </ref>. Users can check objects out from the shared database and place them in a personal database, which can reside on the client disk. Objects that are checked out cannot be accessed by other clients.
Reference: [Wang91] <author> Y. Wang and L. Rowe, </author> <title> "Cache Consistency and Concurrency Control in a Client/Server DBMS Architecture", </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Denver, </address> <month> June, </month> <year> 1991 </year>
Reference-contexts: This omission is potentially costly, as client disks represent a valuable addition to the storage hierarchy of a client-server OODBMS due to their capacity and non-volatility. Inter-transaction memory caching and other client memory management techniques have been shown to provide substantial performance benefits for client-server database systems <ref> [Wilk90, Care91, Wang91, Fran92a, Fran92b] </ref>. In this paper, we investigate the extension of client-server caching to the use of client disks. We focus on data-shipping systems in which pages serve as the unit of interaction between clients and servers. <p> Callback-Read is derived from techniques that were originally used to maintain cache consistency in distributed file systems such as Andrew [Howa88] and Sprite [Nels88]; however, these algorithms did not support serializable transactions. Transactional callback locking algorithms have been employed in the ObjectStore OODBMS [Lamb91] and have been studied in <ref> [Wang91] </ref> and later in [Fran92a]. Under CB-R, all pages in a client's memory cache are guaranteed to be valid. CB-R grants clients authority 5 to read objects in their memory caches, but they must obtain permission from the server to write objects .
Reference: [Wilk90] <author> W. Wilkinson, and M. Neimat, </author> <title> "Maintaining Consistency of Client Cached Data", </title> <booktitle> Proc. 16th VLDB Conf., </booktitle> <address> Brisbane, Australia, </address> <month> August, </month> <year> 1990. </year> <month> 28 </month>
Reference-contexts: This omission is potentially costly, as client disks represent a valuable addition to the storage hierarchy of a client-server OODBMS due to their capacity and non-volatility. Inter-transaction memory caching and other client memory management techniques have been shown to provide substantial performance benefits for client-server database systems <ref> [Wilk90, Care91, Wang91, Fran92a, Fran92b] </ref>. In this paper, we investigate the extension of client-server caching to the use of client disks. We focus on data-shipping systems in which pages serve as the unit of interaction between clients and servers.
References-found: 27

