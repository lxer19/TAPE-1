URL: http://www.cs.sunysb.edu/~juliana/exp-bf-tabling.ps.gz
Refering-URL: http://www.cs.sunysb.edu/~juliana/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: fjuliana,tswift,warreng@cs.sunysb.edu  
Title: Taking I/O Seriously: Resolution Reconsidered for Disk (Expanded Version Draft)  
Author: Juliana Freire Terrance Swift David S. Warren 
Date: February 21, 1996  
Address: NY 11794-4400  
Affiliation: Department of Computer Science State University of New York at Stony Brook Stony Brook,  
Abstract: Modern compilation techniques can give Prolog programs, in the best cases, a speed comparable to C. However, Prolog has proven to be unacceptable for data-oriented queries for two major reasons: its sometimes poor termination and complexity properties for Datalog, and its tuple-at-a-time strategy. A number of tabling frameworks and systems have addressed the first problem, most notably the XSB system which has achieved Prolog speeds for tabled programs. Yet, tabling systems such as XSB continue to use the tuple-at-a-time paradigm. As a result, these systems are not amenable to a tight interconnection with disk-resident data. However, in a tabling framework the difference between tuple-at-a-time behavior and set-at-a-time can be viewed as one of scheduling. Accordingly, we define a breadth-first set-at-a-time tabling strategy and prove it iteration equivalent to a form of semi-naive magic evaluation. That is, we extend the well-known asymptotic results of Seki [15] by proving that each iteration of the tabling strategy produces the same information as semi-naive magic. Further, this set-at-a-time scheduling is amenable to implementation in an engine that uses Prolog compilation. We describe both the engine, which is freely available, and its performance, which is comparable with the depth-first strategy even for in-memory Datalog queries. Because of its performance and its fine level of integration of Prolog with a database-style search, the set-at-a-time engine appears as an important key to linking logic programming and deductive databases.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. At-Kaci. </author> <title> WAM: A Tutorial Reconstruction. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: A table entry is created when a tabled subgoal is first called, during subgoal call. At this time a generator choice point and a completion frame are also created. The choice point frame contains a superset of the information present in a regular WAM <ref> [1] </ref> choice point, and is used to schedule program clause resolution for the subgoal. The completion frame is used during the completion operation as will be explained below.
Reference: [2] <author> W. Chen, M. Kifer, and D.S. Warren. HiLog: </author> <title> A foundation for higher-order logic programming. </title> <journal> J. Logic Programming, </journal> <volume> 15(3) </volume> <pages> 187-230, </pages> <year> 1993. </year>
Reference-contexts: This rewrite is formally defined in many places, so we provide only an example here. Example 2.1 To illustrate semi-naive rewriting, consider the rule ancestor (X; Z) : ancestor (X; Y ); ancestor (Y; Z): Then we may use a variant of HiLog notation <ref> [2] </ref> to denote the set of all answers for ancestor (X; Y ) at time t as ancestor (t)(X; Y ) and the corresponding delta set as ffiancestor (t)(X; Y ). ancestor (t + 1)(X; Z) : ffiancestor (t)(X; Y ); ancestor (t 1)(Y; Z): ancestor (t + 1)(X; Z) : <p> The disadvantage of this approach is that the list of all solutions must be created, regardless of the function to be computed. XSB provides an efficient implementation of a clean and declarative way to represent aggregates using HiLog <ref> [2] </ref> syntax. In this section we give a brief description of the aggregate predicates through examples, the reader is referred to [7] for more details. The aggregate predicates available compute minimum, maximum, sum, count and average of predicates with relation to an argument. Consider the following example. <p> It is worth pointing out that XSB provides an efficient implementation aggregates using HiLog <ref> [2] </ref> syntax.
Reference: [3] <author> W. Chen and D.S. Warren. </author> <title> Tabled evaluation with delaying for general logic programs. </title> <journal> JACM, </journal> <note> 1993. To appear. An extended abstract appeared in the Proceedings of the 12th PODS. </note>
Reference: [4] <author> D. Chimenti, R. Gamboa, R. Krishnamurthy, S. Naqvi, S. Tsur, and C. Zaniolo. </author> <title> The LDL system prototype. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2 </volume> <pages> 76-89, </pages> <year> 1990. </year> <month> 26 </month>
Reference-contexts: Both magic and tabling combine top-down goal orientation with bottom-up redundancy checking. Indeed, for range-restricted programs, they have been proven to be asymptotically equivalent [15, 13] under certain assumptions. Despite these well-known equivalences, magic-style systems have traditionally differed from tabling systems. Magic-style systems, such as LDL <ref> [4] </ref>, CORAL [12], Glue/Nail [5], are built upon set-at-a-time semi-naive engines, while tabling systems, such as XSB [14], use a tuple-at-a-time strategy that reflects their genesis in the logic programming community. Each class of systems has its advantages and disadvantages.
Reference: [5] <author> M. Derr, S. Morishita, and G. Phipps. </author> <title> Design and implementation of the Glue-Nail database system. </title> <booktitle> In Proc. of the SIGMOD 1993 Conf., </booktitle> <pages> pages 147-156. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Indeed, for range-restricted programs, they have been proven to be asymptotically equivalent [15, 13] under certain assumptions. Despite these well-known equivalences, magic-style systems have traditionally differed from tabling systems. Magic-style systems, such as LDL [4], CORAL [12], Glue/Nail <ref> [5] </ref>, are built upon set-at-a-time semi-naive engines, while tabling systems, such as XSB [14], use a tuple-at-a-time strategy that reflects their genesis in the logic programming community. Each class of systems has its advantages and disadvantages.
Reference: [6] <author> J. Freire, T. Swift, and D.S. Warren. </author> <title> Batched answers: An alternative strategy for tabled evaluations. </title> <type> Technical report, </type> <institution> State University of New York at Stony Brook, </institution> <year> 1995. </year> <note> In preparation. </note>
Reference-contexts: Because of space limitations, some implementation details have been omitted; more details can be found in <ref> [6] </ref>. 4.1 Breadth-First SLG-WAM Before going on to the implementation details, we briefly present some data structures used by the SLG-WAM engine. The table maintains information about all (tabled) subgoals encountered by the evaluation as well as answers for each subgoal. <p> Table 1: Normalized times for linear chains of varying lengths Emulator/Length 1k 2k 4k 8k 16k Breadth-First 1 1 1 1 1 XSB v. 1.4 0.891 0.9 0.846 0.88 0.88 SLD 0.718 0.63 0.64 0.66 0.657 * XSB v. 1.4 [19, 20]: original depth-first (tuple-at-a-time) strategy. * XSB v. 1.5 <ref> [6] </ref>: delays the return of answers to consuming nodes. The search is still mostly depth-first but it has proven to be more efficient in terms of memory utilization and execution time than XSB v. 1.4. * Breadth-First: breadth-first (set-at-a-time) strategy described in Section 4. <p> Notice that, as expected, the space utilization for Breadth-First is about the same as for XSB v. 1.5 for left recursion, whereas for right recursion it is considerably higher. One of the main advantages of XSB v. 1.5 <ref> [6] </ref> over XSB v. 1.4 is memory utilization, as Table 10 clearly shows. The differences are sometimes huge, e.g. for left-recursion on chains.
Reference: [7] <author> Juliana Freire, I.V. Ramakrishnan, Prasad Rao, Terrance Swift, and David S. Warren. </author> <title> Combining HiLog and tabling to implement aggregate queries. </title> <note> Draft available at http://www.cs.sunysb.edu/~sbprolog. </note>
Reference-contexts: XSB provides an efficient implementation of a clean and declarative way to represent aggregates using HiLog [2] syntax. In this section we give a brief description of the aggregate predicates through examples, the reader is referred to <ref> [7] </ref> for more details. The aggregate predicates available compute minimum, maximum, sum, count and average of predicates with relation to an argument. Consider the following example. Example 4.3 Consider a database of employees in a company, where the employee relation contains the emloyee's name, department and salary.
Reference: [8] <author> D. E. Knuth. </author> <title> The Stanford GraphBase: A Platform for Combinatorial Computing. </title> <publisher> Addison Wesley, </publisher> <year> 1993. </year>
Reference-contexts: Next we examine some different and ostensibly more realistic graphs. Words and subsets of it with fewer vertices and edges, and Roget were generated with Knuth's Stanford Graph Base <ref> [8] </ref>. Genome is a piece of a DNA sequence, while Cylinder is a 24x24 (2-connected) cylinder. A description of these graphs is given in Table 5.
Reference: [9] <author> I. S. Mumick, H. Pirahesh, and R. Ramakrishnan. </author> <title> The Magic of Duplicates and Aggregates. </title> <booktitle> In Proceedings of the 16th International Conference on Very Large Databases, </booktitle> <pages> pages 264-277, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: AnswerReturn If there are new answers to resolve and the current answer was created in the previous iteration Return current answer; Update last resolved answer; Else Fail; 2 For queries to disk-resident data, an alternative mechanism is used as explained in Section 4.3. 14 4.2 Declarative Aggregate Computation Several people <ref> [9, 18, 23] </ref> have considered aggregates in the context of recursive queries in deductive databases. In Prolog, a natural way to compute aggregates is by using all-solution predicates, that is, collecting all solutions and then doing the necessary computation.
Reference: [10] <author> Oracle. </author> <title> Programmer's Guide to the Oracle(REG) Precompilers, </title> <month> December 92. </month>
Reference-contexts: The current version of db call (&lt;database&gt;)/3 is implemented for Oracle, and uses Oracle host arrays <ref> [10] </ref> to fill a temporary table with the arguments of the input list. <p> In the second clause, the predicate batch findall gathers all answers available for reach in L, which is then passed on to db call (oracle). Using Oracle host arrays <ref> [10] </ref>, db call (oracle) fills a table in Oracle with the answers in L, and performs a semi-join with the words table stored in Oracle. The answers are fetched into XSB in batches from the resulting cursor, also through host arrays.
Reference: [11] <author> R. Ramakrishnan. </author> <title> Magic templates: A spellbinding approach to logic programs. </title> <journal> J. Logic Programming, </journal> <volume> 11 </volume> <pages> 189-216, </pages> <year> 1991. </year>
Reference-contexts: Throughout this paper, we use semi-naive to strictly refer to Algorithm 2.1. A central difficulty of pure bottom-up evaluation, such as semi-naive, is that it is not goal-oriented: to answer a query, the entire model of a program must be constructed. Magic templates rewriting (see e.g. <ref> [11] </ref>) avoids this problem by means of a program transformation. Magic is well-discussed in the literature; here we present only the magic templates transformation along with an example of its use. Note that this transformation requires a statically-determined computation rule.
Reference: [12] <author> R. Ramakrishnan, D. Srivastava, and S. Sudarshan. </author> <title> CORAL: Control, relations, </title> <booktitle> and logic. In Proc. of the 18th Int'l Conf. on Very Large Data Bases, </booktitle> <pages> pages 238-249. </pages> <publisher> VLDB End., </publisher> <year> 1992. </year>
Reference-contexts: Both magic and tabling combine top-down goal orientation with bottom-up redundancy checking. Indeed, for range-restricted programs, they have been proven to be asymptotically equivalent [15, 13] under certain assumptions. Despite these well-known equivalences, magic-style systems have traditionally differed from tabling systems. Magic-style systems, such as LDL [4], CORAL <ref> [12] </ref>, Glue/Nail [5], are built upon set-at-a-time semi-naive engines, while tabling systems, such as XSB [14], use a tuple-at-a-time strategy that reflects their genesis in the logic programming community. Each class of systems has its advantages and disadvantages.
Reference: [13] <author> K.A. Ross. </author> <title> Modular stratification and magic sets for datalog programs with negation. </title> <journal> In JACM, </journal> <pages> pages 1216-1266, </pages> <year> 1994. </year>
Reference-contexts: Magic evaluation closely resembles tabling. Both magic and tabling combine top-down goal orientation with bottom-up redundancy checking. Indeed, for range-restricted programs, they have been proven to be asymptotically equivalent <ref> [15, 13] </ref> under certain assumptions. Despite these well-known equivalences, magic-style systems have traditionally differed from tabling systems.
Reference: [14] <author> K. Sagonas, T. Swift, and D.S. Warren. </author> <title> XSB as an efficient deductive database engine. </title> <booktitle> In Proc. of SIGMOD 1994 Conf., </booktitle> <pages> pages 442-453. </pages> <publisher> ACM, </publisher> <year> 1994. </year>
Reference-contexts: Despite these well-known equivalences, magic-style systems have traditionally differed from tabling systems. Magic-style systems, such as LDL [4], CORAL [12], Glue/Nail [5], are built upon set-at-a-time semi-naive engines, while tabling systems, such as XSB <ref> [14] </ref>, use a tuple-at-a-time strategy that reflects their genesis in the logic programming community. Each class of systems has its advantages and disadvantages. <p> Each class of systems has its advantages and disadvantages. Presently for in-memory Datalog queries, the fastest tabling systems show an order of magnitude speedup over magic-style systems due to the use of Prolog compilation technology by the tabling systems <ref> [14] </ref>. However, the tuple-at-a-time strategy of tabling systems is not efficiently extendible to disk. A close look at tabling indicates that there is no reason why a set-at-a-time strategy cannot be closely integrated into a tabling engine. Doing so offers tremendous advantages. <p> [ret (1,2),ret (2,3),ret (3,4),ret (4,1)]; L = [ret (1,4),ret (2,1),ret (3,2),ret (4,3)]; Each time a new set is returned from batch findall (in the second clause of path/2), db call (oracle) is evaluated and returns the result of the join performed in the database. 5 Performance Analysis In previous papers <ref> [20, 14] </ref> the WAM-style tabling implementation of XSB v. 1.4 was shown to be about an order of magnitude faster than other deductive database systems for a variety of in-memory queries.
Reference: [15] <author> H. Seki. </author> <title> On the power of Alexander templates. </title> <booktitle> In Proc. of 8th PODS, </booktitle> <pages> pages 150-159. </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: Magic evaluation closely resembles tabling. Both magic and tabling combine top-down goal orientation with bottom-up redundancy checking. Indeed, for range-restricted programs, they have been proven to be asymptotically equivalent <ref> [15, 13] </ref> under certain assumptions. Despite these well-known equivalences, magic-style systems have traditionally differed from tabling systems. <p> The major results of this paper are as follows. * Derivation of a Tight Equivalence between Tabling and the Semi-Naive Evaluation of a Magic-Transformed Program (SNMT). Broad equivalences between tabling and magic-style methods have long been known. In <ref> [15] </ref> Seki obtained an asymptotic equivalence between a naive evaluation of a program rewritten using Alexander Templates and a version of a tabling method. After specifying a breadth-first search strategy for tabling, we extend the equivalence of Seki in two ways.
Reference: [16] <author> S. Sudarshan. </author> <title> Optimizing Bottom-up Query Evaluation for Deductive Databases. </title> <type> PhD thesis, </type> <institution> University of Wisconsin, </institution> <year> 1992. </year>
Reference-contexts: Differences between the two methods arise in non-ground programs, but we believe that these these differences can be obviated by the use of alternate magic rewriting techniques developed to reduce the complexity of magic with respect to Prolog <ref> [16] </ref>. Example 3.1 Consider the following program and query q:- p (a),p (X),r (X). ?- q.
Reference: [17] <author> S. Sudarshan and R. Ramakrishnan. </author> <title> Aggregation and relevance in deductive databases. </title> <booktitle> In Proc. of the 17th Int'l Conf. on Very Large Data Bases, </booktitle> <pages> pages 501-511. </pages> <publisher> VLDB End., </publisher> <year> 1991. </year>
Reference-contexts: Thus tabling systems, which only use a given answer once in a given position and rule, are said to have the semi-naive property in <ref> [17] </ref>. Throughout this paper, we use semi-naive to strictly refer to Algorithm 2.1. A central difficulty of pure bottom-up evaluation, such as semi-naive, is that it is not goal-oriented: to answer a query, the entire model of a program must be constructed.
Reference: [18] <author> S. Sudarshan and R. Ramakrishnan. </author> <title> Aggregation and Relevance in Deductive Databases. </title> <booktitle> In Proceedings of the 17th International Conference on Very Large Databases, </booktitle> <pages> pages 501-511, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: AnswerReturn If there are new answers to resolve and the current answer was created in the previous iteration Return current answer; Update last resolved answer; Else Fail; 2 For queries to disk-resident data, an alternative mechanism is used as explained in Section 4.3. 14 4.2 Declarative Aggregate Computation Several people <ref> [9, 18, 23] </ref> have considered aggregates in the context of recursive queries in deductive databases. In Prolog, a natural way to compute aggregates is by using all-solution predicates, that is, collecting all solutions and then doing the necessary computation.
Reference: [19] <author> T. Swift and D. S. Warren. </author> <title> An abstract machine for SLG resolution: definite programs. </title> <booktitle> In Proceedings of the Symposium on Logic Programming, </booktitle> <pages> pages 633-654, </pages> <year> 1994. </year>
Reference-contexts: an expressive data query language, these results now indicate that compilation techniques of logic programming have a direct practical impact on implementing database queries, as will be demonstrated in the following sections. 4 Engine Design In this section we describe the changes to make the search procedure of the SLG-WAM <ref> [19] </ref> breadth-first. Because of space limitations, some implementation details have been omitted; more details can be found in [6]. 4.1 Breadth-First SLG-WAM Before going on to the implementation details, we briefly present some data structures used by the SLG-WAM engine. <p> memory, and the engines considered in this section are: 17 Table 1: Normalized times for linear chains of varying lengths Emulator/Length 1k 2k 4k 8k 16k Breadth-First 1 1 1 1 1 XSB v. 1.4 0.891 0.9 0.846 0.88 0.88 SLD 0.718 0.63 0.64 0.66 0.657 * XSB v. 1.4 <ref> [19, 20] </ref>: original depth-first (tuple-at-a-time) strategy. * XSB v. 1.5 [6]: delays the return of answers to consuming nodes.
Reference: [20] <author> T. Swift and D. S. Warren. </author> <title> Analysis of sequential SLG evaluation. </title> <booktitle> In Proceedings of the Symposium on Logic Programming, </booktitle> <pages> pages 219-238, </pages> <year> 1994. </year> <month> 27 </month>
Reference-contexts: Other tabling methods with set-at-a-time properties have been developed, most notably the SLD-AL strategy of [22]. The engine described here has, in addition to its iteration equivalence to magic, the advantage that it uses the low-level data structures and compilation techniques of Prolog technology. As presented in <ref> [20] </ref>, this technology, as implemented in the SLG-WAM, leads to an extremely fast, robust, and flexible implementation of a deductive database engine. The resulting implementation of the Breadth-First XSB is available upon request. <p> [ret (1,2),ret (2,3),ret (3,4),ret (4,1)]; L = [ret (1,4),ret (2,1),ret (3,2),ret (4,3)]; Each time a new set is returned from batch findall (in the second clause of path/2), db call (oracle) is evaluated and returns the result of the join performed in the database. 5 Performance Analysis In previous papers <ref> [20, 14] </ref> the WAM-style tabling implementation of XSB v. 1.4 was shown to be about an order of magnitude faster than other deductive database systems for a variety of in-memory queries. <p> Since many deductive databases, including XSB, are under continual development, the difference in speed may change over time; nevertheless the comparisons of <ref> [20] </ref> indicate the importance of the use of compilation technology and of low-level engine optimizations to deductive database speed. <p> memory, and the engines considered in this section are: 17 Table 1: Normalized times for linear chains of varying lengths Emulator/Length 1k 2k 4k 8k 16k Breadth-First 1 1 1 1 1 XSB v. 1.4 0.891 0.9 0.846 0.88 0.88 SLD 0.718 0.63 0.64 0.66 0.657 * XSB v. 1.4 <ref> [19, 20] </ref>: original depth-first (tuple-at-a-time) strategy. * XSB v. 1.5 [6]: delays the return of answers to consuming nodes.
Reference: [21] <author> J. Ullman. </author> <title> Principles of Data and Knowledge-base Systems Vol I. </title> <publisher> Computer Science Press, </publisher> <year> 1989. </year>
Reference-contexts: Semi-Naive Evaluation and Magic Rewriting The well-known semi-naive evaluation algorithm <ref> [21] </ref> is an incremental iterative fixpoint algorithm. It is iterative in that it repeatedly generates facts by applying program rules. It is incremental in the sense that a given rule uses a given fact in a given position only once for further derivation.
Reference: [22] <author> L. Vieille. </author> <title> Recursive query processing: The power of logic. </title> <journal> Theoretical Computer Science, </journal> <volume> 69 </volume> <pages> 1-53, </pages> <year> 1989. </year>
Reference-contexts: Using iteration equivalence, we demonstrate that every answer of every iteration of our tabling strategy is produced at the corresponding iteration of SNMT. * Design and Implementation of an Engine to Evaluate Breadth-First Tabling. Other tabling methods with set-at-a-time properties have been developed, most notably the SLD-AL strategy of <ref> [22] </ref>. The engine described here has, in addition to its iteration equivalence to magic, the advantage that it uses the low-level data structures and compilation techniques of Prolog technology.
Reference: [23] <author> C. Zaniolo, N. Arni, and K. Ong. </author> <title> Negation and Aggregates in Recursive Rules: the LDL++ Approach. </title> <booktitle> In Proceedings of the International Conference on Deductive and Object-Oriented Databases, </booktitle> <pages> pages 204-221, </pages> <year> 1993. </year> <title> This appendix contains only supplementary reference material for the convenience of the referees. </title>
Reference-contexts: AnswerReturn If there are new answers to resolve and the current answer was created in the previous iteration Return current answer; Update last resolved answer; Else Fail; 2 For queries to disk-resident data, an alternative mechanism is used as explained in Section 4.3. 14 4.2 Declarative Aggregate Computation Several people <ref> [9, 18, 23] </ref> have considered aggregates in the context of recursive queries in deductive databases. In Prolog, a natural way to compute aggregates is by using all-solution predicates, that is, collecting all solutions and then doing the necessary computation.
References-found: 23

