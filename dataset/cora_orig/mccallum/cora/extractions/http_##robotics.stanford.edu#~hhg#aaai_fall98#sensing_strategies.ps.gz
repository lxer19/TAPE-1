URL: http://robotics.stanford.edu/~hhg/aaai_fall98/sensing_strategies.ps.gz
Refering-URL: http://robotics.stanford.edu/~hhg/aaai_fall98/
Root-URL: http://www.cs.stanford.edu
Email: fhhg,latombeg @robotics.stanford.edu  
Title: Integrated Planning for Autonomous Agent Architectures Planning Robot Motions for Range-Image Acquisition and Automatic 3D
Author: Hector Gonzalez-Ba~nos Jean-Claude Latombe 
Address: Stanford, CA 94305  
Affiliation: Department of Computer Science Stanford University,  
Date: 1998  
Note: submitted abstract AAAI Fall Symposium Series  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. E. Banta, Y. Zhien, X. Z. Wang, G. Zhang, M. T. Smith, and M. A. Abidi. </author> <title> A "best-next-view" algorithm for three-dimensional scene reconstruction using range images. </title> <booktitle> In Proc. SPIE vol. </booktitle> <volume> 2588, </volume> <pages> pages 418-29, </pages> <year> 1995. </year>
Reference-contexts: The topic of range image acquisition and registration has spawned a good deal of work within the framework of computer graphics and machine vision, but mostly under the assumption that sensing operations are cheap and/or executed in fixed platforms <ref> [10, 1, 7] </ref>. However, when the sensorium consists of multiple robots exploring a non-trivial environment, the situation is further complicated by the emergence of an underlying motion problem. <p> We will present how planning techiques may improve range-image acquisition tasks and make automatic 3-D mod-elling possible by accounting for the constraints on motion imposed by the other phases. 2 Planning Motions for Data Acquisition A classical problem in automatic range-image acquistion is known as the next-best-view problem <ref> [1, 7] </ref>: Where to place the sensor next to maximize the amount of information that will be added to the partial model built so far (Fig. 1)? But existing techniques do not ideally suit robotic sensors. One reason is that the next-best-view problem is inherently a local planning problem [4].
Reference: [2] <author> H. Gonzalez-Banos and et Al. </author> <title> Motion planning with visibility constraints: Building autonomous observers. </title> <booktitle> In Proc. 1997 International Symposium of Robotics Research, </booktitle> <year> 1997. </year>
Reference-contexts: High-level vision-oriented operations involve important aspects of image analysis, robot localization, and dynamic control which must be addressed prior development of practical systems. But even in the absence of these complications there remains a fundamental planning problem that needs to be solved <ref> [2] </ref>. A particularly interesting planning problem is the developement of motion strategies for the economical acquisition of range data and the construction of efficient representations of the environment. Imagine a collection of autonomous agents dropped into a new environment.
Reference: [3] <author> L. Guibas, J.C. Latombe, S.M. LaValle, D. Lin, and R. Motwani. </author> <title> Visibility-based pursuit-evasion in a polygonal environment. </title> <booktitle> In Proc. 5th Workshop on Algorihtms and Data Structures (WADS'97), </booktitle> <pages> pages 17-30. </pages> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: As explained in [5], when the presence of visual and motion obstructions are considered the tracking problem trascends the machine vision context into motion control and planning domains. Another example of vision as end-effector is the hide-and-seek problem presented in <ref> [3] </ref>. Here the task is to move a team of robots in order to localize an unpredictable and arbitrary fast target with absolute certainty. High-level vision-oriented operations involve important aspects of image analysis, robot localization, and dynamic control which must be addressed prior development of practical systems.
Reference: [4] <author> K. Kakusho, T. Kitahashi, K. Kondo, and J.-C. Latombe. </author> <title> Continuous purposive sensing and motion for 2d map building. </title> <booktitle> In Proc. IEEE Int. Conf. Systems, Man, & Cybernetics, </booktitle> <pages> pages 1472-1477, </pages> <year> 1995. </year>
Reference-contexts: One reason is that the next-best-view problem is inherently a local planning problem <ref> [4] </ref>. Obtaining a sequence of local next-best views to build a complete model may yield too many sensing operations. If the sensor is a robot, 3-D sensing is almost never cheap, even if data-acquisition is instantaneous.
Reference: [5] <author> S.M. LaValle, H. Gonzalez-Banos, C. Becker, and J.C. Latombe. </author> <title> Motion strategies for maintaining visibility of a moving target. </title> <booktitle> In Proc. 1997 IEEE Int'l Conf. Robotics & and Automation, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: An important case is when visibility requirements are present or when vision sensors act as end-effectors. An example of this is the task of keeping a moving target in view as it moves through a workspace. As explained in <ref> [5] </ref>, when the presence of visual and motion obstructions are considered the tracking problem trascends the machine vision context into motion control and planning domains. Another example of vision as end-effector is the hide-and-seek problem presented in [3].
Reference: [6] <author> J. O'Rourke. </author> <title> Art Gallery Theorems and Algorithms. </title> <publisher> Oxford University Press, </publisher> <address> New York, NY, </address> <year> 1987. </year>
Reference-contexts: Lets assume that we are given a 2-D layout of a horizontal cross-section of the environment at approximately the height of the range sensor. An art-gallery algorithm will be able to compute the positions that must be visited to eventually see the entire 2-D environment <ref> [6] </ref>. Of course, this basic model-building approach requires additional considerations to make it work in practice: (1) Approximating the solution to the 3-D sensing problem with the output of a planar art-gallery algorithm relies on the existence of a 2-D map.
Reference: [7] <author> R. Pito. </author> <title> A solution to the next best view problem for automated cad model acquisition of free-form objects using range cameras. </title> <type> Technical Report 95-23, </type> <institution> GRASP Lab, University of Pennsylvania, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: The topic of range image acquisition and registration has spawned a good deal of work within the framework of computer graphics and machine vision, but mostly under the assumption that sensing operations are cheap and/or executed in fixed platforms <ref> [10, 1, 7] </ref>. However, when the sensorium consists of multiple robots exploring a non-trivial environment, the situation is further complicated by the emergence of an underlying motion problem. <p> We will present how planning techiques may improve range-image acquisition tasks and make automatic 3-D mod-elling possible by accounting for the constraints on motion imposed by the other phases. 2 Planning Motions for Data Acquisition A classical problem in automatic range-image acquistion is known as the next-best-view problem <ref> [1, 7] </ref>: Where to place the sensor next to maximize the amount of information that will be added to the partial model built so far (Fig. 1)? But existing techniques do not ideally suit robotic sensors. One reason is that the next-best-view problem is inherently a local planning problem [4].
Reference: [8] <author> T. Shermer. </author> <title> Recent results in art galleries. </title> <journal> Proc. IEEE, </journal> <volume> 80(9) </volume> <pages> 1384-1399, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Furthermore, the order with which the different views are processed is crucial. We believe the planning problem then becomes closely connected with the watchman route problem <ref> [8] </ref>: Find the shortest closed path from which the entire workspace is visible. Surprisingly, this problem has been shown to be solvable in polynomial time although the basic art-gallery problem is NP-complete. 4 Conclusion High-level vision-oriented operations involve important motion planning problems that have received little attention so far.
Reference: [9] <author> G. Turk and M. Levoy. </author> <title> Zippered polygon meshes from range images. </title> <booktitle> In Proc. ACM SIGGRAPH, </booktitle> <pages> pages 311-318, </pages> <year> 1994. </year>
Reference-contexts: This problem is readily solved if the 3-D representation is constructed under human assistance: simply ask the user to closely line up the views and rerun the aligment procedure. The algorithm will then do the final "zippering" <ref> [9] </ref>. However, if the operation is to be done automatically, there is a strong coupling between the alignment step and the exploration strategy. The strategy should consider alignment issues as part of the constraints of the problem, in addition to sensor limitations and contraints over motion.
Reference: [10] <author> L. Wixson. </author> <title> Viewpoint selection for visual search. </title> <booktitle> In Proc. IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 800-805, </pages> <year> 1994. </year>
Reference-contexts: The topic of range image acquisition and registration has spawned a good deal of work within the framework of computer graphics and machine vision, but mostly under the assumption that sensing operations are cheap and/or executed in fixed platforms <ref> [10, 1, 7] </ref>. However, when the sensorium consists of multiple robots exploring a non-trivial environment, the situation is further complicated by the emergence of an underlying motion problem.
References-found: 10

