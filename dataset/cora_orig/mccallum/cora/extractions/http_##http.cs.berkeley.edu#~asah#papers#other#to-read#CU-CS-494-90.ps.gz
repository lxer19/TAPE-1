URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/CU-CS-494-90.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/
Root-URL: http://www.cs.berkeley.edu
Title: Barrier Methods for Garbage Collection  
Author: Benjamin Zorn 
Date: November 1990  
Address: Boulder  Boulder  
Affiliation: Department of Computer Science University of Colorado at  ffi University of Colorado at  
Pubnum: CU-CS-494-90  
Abstract: Technical Report CU-CS-494-90 Department of Computer Science Campus Box 430 University of Colorado Boulder, Colorado 80309 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Thomas E. Anderson, Henry M. Levy, Brian N. Bershad, and Edward D. Lazowska. </author> <title> The interaction of architecture and operating system design. </title> <type> Technical Report Technical Report 90-08-01, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <address> Seattle, WA, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: Interestingly, just as this paper questions the suitability of current operating systems designs for language runtime systems, very recently, Anderson et al have noted that the designs of modern operating systems and microprocessor architectures are mismatched <ref> [1] </ref>. Among other things, Anderson notes that recent architectures tend to provide less support for fast memory protection faults. This observation suggests that design for optimal execution requires the cooperation of computer architects, operating systems, and language designers.
Reference: [2] <author> Andrew Appel, John Ellis, and Kai Li. </author> <title> Real-time concurrent collection on stock multiprocessors. </title> <booktitle> In Proceedings of the SIGPLAN'88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 11-20, </pages> <address> Atlanta, GA, </address> <month> June </month> <year> 1988. </year> <title> SIGPLAN, </title> <publisher> ACM Press. </publisher>
Reference-contexts: While other approaches to incremental collection have 21 overhead of different write barrier approachs for the Prolog compiler and microcode assembler ap plications are presented. 22 been attempted, most notably work by Brooks [6] and Appel <ref> [2] </ref>, this section will consider implementations of Baker-style incremental collection, where pointers into fromspace are relocated as they are loaded into registers. Three implementations of the read barrier are described: special hardware, inline software, and read protection faults. Before discussing the implementations, I will outline the memory organization assumed. <p> Furthermore Brooks does not attempt to quantify the overhead of his technique or compare its efficiency with other techniques. Appel, Ellis, and Li describe an approach to incremental collection that protects pages in tospace and relocates the pointers on protected pages as they are referenced <ref> [2] </ref>. This method avoids the per-load costs of maintaining the read barrier in software, but also results in longer pauses than Baker's method. This method also prevents the use of the read barrier to increase data locality, as described by Courts [9]. <p> Two approaches to garbage collection based on protection faults have proven to be successful <ref> [2, 20] </ref>, but both required changes to the operating system kernel. Unfortunately, most operating systems are not designed to provide fast memory protection faults because they assume that these faults occur only in error situations.
Reference: [3] <author> Andrew W. Appel. </author> <title> Simple generational garbage collection and fast allocation. </title> <journal> Software| Practice and Experience, </journal> <volume> 19(2) </volume> <pages> 171-183, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: After an intergeneration pointer has been discovered, its location must be recorded in the remembered set. Simple representations of the remembered set maintain a sequence of addresses, where each generation trap adds the address of the intergeneration pointer to the sequence <ref> [3, 27, 31] </ref>. One problem with a sequence representation is that the same address can occur in the sequence many times. Such redundancy wastes space and also time when the sequence is scanned during garbage collection. <p> By expanding each of these instructions into eight instructions, the overall code expansion should be on the order of 20-30%. Some researchers consider this code expansion to be potentially very costly and suggest unconditional generation traps that record information about every NIP 16 store <ref> [3] </ref>. The actual impact of this code expansion depends on the size and configuration of the machine memory hierarchy, and in particular the instruction cache. <p> Appel describes an implementation of the Standard ML generation collector where every NIP store to the heap adds an item to the remembered set (implemented as a list) <ref> [3] </ref>. At collection time, the list is scanned for intergeneration pointers. The two advantages of an unconditional store are reduced code expansion (because it avoids a conditional test) and global registers are not required to hold the generation boundaries.
Reference: [4] <author> Henry G. Baker, Jr. </author> <title> List processing in real time on a serial computer. </title> <journal> Communications of the ACM, </journal> <volume> 21(4) </volume> <pages> 280-294, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: In the last decade, two enhancements to copying algorithms have increased their effectiveness. Henry Baker proposed a technique called "incremental garbage collection" which greatly shortens the pauses associated with stop-and-copy algorithms <ref> [4] </ref>. In 1983, Lieberman and Hewitt introduced the idea of generation garbage collection, where only a fraction of the entire heap needs to be considered for most collections [16]. This enhancement both reduces the memory reference disruption during garbage collection and shortens collection-related pauses. <p> This paper 6 considers several alternative implementations of the write barrier to determine the most efficient method. 1.3 Incremental Garbage Collection Henry Baker introduced an enhancement of the standard copying collection algorithm that greatly reduces pauses associated with garbage collection <ref> [4] </ref>, making garbage collection potentially suitable for real-time applications. The actions performed by Baker's incremental algorithm are essentially identical to those of the traditional copying algorithm|only the time at which the copying is performed changes.
Reference: [5] <author> H. Boehm and M. Weiser. </author> <title> Garbage collection in an uncooperative environment. </title> <journal> Software| Practice and Experience, </journal> <pages> pages 807-820, </pages> <month> September </month> <year> 1988. </year> <month> 35 </month>
Reference-contexts: More recently defined block-structured languages such as Modula-3 [7] and Cedar [19] also include automatic storage reclamation. Even C, widely used as a systems programming language, has been extended to include garbage collection of heap-allocated objects <ref> [5] </ref>. Because of the widespread use of garbage collection in programming languages, care ful evaluation of implementation techniques for these algorithms is extremely important. 1 Unfortunately, there has been little empirical data published about the behavior of Lisp systems and even fewer measurements comparing alternative implementations of garbage collection algorithms.
Reference: [6] <author> Rodney A. Brooks. </author> <title> Trading data space for reduced time and code space in real-time garbage collection on stock hardware. </title> <booktitle> In Conference Record of the 1984 ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 256-262, </pages> <address> Austin, TX, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: While other approaches to incremental collection have 21 overhead of different write barrier approachs for the Prolog compiler and microcode assembler ap plications are presented. 22 been attempted, most notably work by Brooks <ref> [6] </ref> and Appel [2], this section will consider implementations of Baker-style incremental collection, where pointers into fromspace are relocated as they are loaded into registers. Three implementations of the read barrier are described: special hardware, inline software, and read protection faults. <p> Several other approaches have been taken toward providing incremental garbage collection on stock hardware. Brooks proposes a technique that adds an extra pointer per object and an extra indirection per object reference in order to allow incremental garbage collection on stock hardware <ref> [6] </ref>. While this technique reduces the code expansion of inline tests, the data expansion associated with adding an extra pointer per cons cell (33% increase) is probably more significant. Furthermore Brooks does not attempt to quantify the overhead of his technique or compare its efficiency with other techniques.
Reference: [7] <author> Luca Cardelli, James Donahue, Lucille Glassman, Mick Jordan, Bill Kalsow, and Greg Nelson. </author> <title> The Modula-3 report. </title> <type> Technical Report Research Report 31, </type> <institution> Digital Equipment Corporation System Research Center, </institution> <address> Palo Alto, CA, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Garbage collection is a technique of automatic heap storage reclamation that has been used in Lisp runtime systems for many years. More recently defined block-structured languages such as Modula-3 <ref> [7] </ref> and Cedar [19] also include automatic storage reclamation. Even C, widely used as a systems programming language, has been extended to include garbage collection of heap-allocated objects [5].
Reference: [8] <author> C. J. </author> <title> Cheney. A nonrecursive list compacting algorithm. </title> <journal> Communications of the ACM, </journal> <volume> 13(11) </volume> <pages> 677-678, </pages> <month> November </month> <year> 1970. </year>
Reference-contexts: By visiting all live objects, all other objects are known to be garbage and can be reclaimed. The basic idea of copying garbage collection can be attributed to Fenichel and Yochel-son [11], and to Cheney, who eliminated the need for auxiliary stacks in the algorithm <ref> [8] </ref>. Copying garbage collection reclaims garbage by dividing the address space into two semis-paces (fromspace and tospace), only one of which is in use most of the time. During normal program operation, all objects are located in one semispace (tospace) in which new objects are also allocated.
Reference: [9] <author> Robert Courts. </author> <title> Improving locality of reference in a garbage-collecting memory management system. </title> <journal> Communications of the ACM, </journal> <volume> 31(9) </volume> <pages> 1128-1138, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: For Lisp systems with large address spaces, Baker's algorithm greatly reduces the pauses associated with garbage collection. This algorithm, coupled with generation collection, 7 has been used successfully for many years by Lisp machines such as the Symbolics [17] and Explorer <ref> [9] </ref>. Studies of the Explorer's algorithm by Courts suggest that the copy-on-demand strategy of incremental collection significantly improves the memory reference locality of Lisp programs by dynamically compacting the working set of the data [9]. Lisp machines provide hardware support for the read and write barriers, substantially reducing the overhead. <p> been used successfully for many years by Lisp machines such as the Symbolics [17] and Explorer <ref> [9] </ref>. Studies of the Explorer's algorithm by Courts suggest that the copy-on-demand strategy of incremental collection significantly improves the memory reference locality of Lisp programs by dynamically compacting the working set of the data [9]. Lisp machines provide hardware support for the read and write barriers, substantially reducing the overhead. Unfortunately, high performance RISC microprocessors do not provide any hardware support for barriers. <p> This method avoids the per-load costs of maintaining the read barrier in software, but also results in longer pauses than Baker's method. This method also prevents the use of the read barrier to increase data locality, as described by Courts <ref> [9] </ref>. Nevertheless, Appel's method provides an alternative to the costly Baker collection algorithm. Johnson discusses the value of the read barrier in improving the locality of reference in a very large Lisp program [14].
Reference: [10] <author> Bruce Edwards, Greg Efland, and Neil Weste. </author> <title> The symbolics I-machine architecture: A symbolic processor architecture for VLSI implementation. </title> <booktitle> In ICCD, </booktitle> <year> 1987. </year>
Reference-contexts: In general, instruction reorganization can often fill this delay slot, and the cost of the hardware read barrier, like the hardware write barrier, is negligible. Such a barrier has been successfully implemented in several generations of Lisp machine architectures <ref> [10, 18] </ref>. 4.2 The Software Read Barrier As an alternative to the hardware read barrier, the read barrier tests can be performed inline after the pointer is loaded. Unlike the write barrier, where numerous checks must be performed to detect a generation trap, the read barrier requires two simple comparisons.
Reference: [11] <author> Robert R. Fenichel and Jerome C. Yochelson. </author> <title> A Lisp garbage-collector for virtual memory computer systems. </title> <journal> Communications of the ACM, </journal> <volume> 12(11) </volume> <pages> 611-612, </pages> <month> November </month> <year> 1969. </year>
Reference-contexts: By visiting all live objects, all other objects are known to be garbage and can be reclaimed. The basic idea of copying garbage collection can be attributed to Fenichel and Yochel-son <ref> [11] </ref>, and to Cheney, who eliminated the need for auxiliary stacks in the algorithm [8]. Copying garbage collection reclaims garbage by dividing the address space into two semis-paces (fromspace and tospace), only one of which is in use most of the time.
Reference: [12] <author> Franz Incorporated. </author> <title> Allegro Common Lisp User Guide, Release 3.0 (beta) edition, </title> <month> April </month> <year> 1988. </year>
Reference-contexts: example, as provided by the Symbolics, which supports page marking in hardware) is unnecessary because the cost of maintaining the remembered set information using software is already small. 3.2 The Software Write Barrier The most common approach to implementing the write barrier on stock hardware, used in commercial Lisp systems <ref> [12] </ref>, is to implement the generation test inline with every non-initializing pointer store (NIP store). Because these stores are quite frequent (5-10% of all references), this approach requires careful design in order to minimize the cost per store. <p> The pointer is assumed to use the two lower bits of the address as a type tag (low-tagging) as has been used in several Lisp systems <ref> [12, 28] </ref>. To correctly estimate the overhead of this implementation of the write barrier, a CPU cost must be determined for each possible value for the generation of the pointer and the container.
Reference: [13] <author> Mark Hill, Susan Eggers, James Larus, George Taylor, et al. </author> <title> SPUR: A VLSI multiprocessor workstation. </title> <journal> IEEE Computer, </journal> 19(11) 8-22, November 1986. 
Reference-contexts: If a generation trap occurs, a trap handler records the intergeneration pointer in the remembered set and continues. Several architectures provide hardware write barriers, including SPUR <ref> [13] </ref> and the Symbolics [17]. Because the generation check is performed in parallel with the store, the total overhead using this method occurs during the handling of generation traps. <p> In all cases, implementing the read and write barriers with hardware results in negligible performance degradation, as long as hardware traps are handled sufficiently fast. While several architectures have provided support for these barriers, including the Symbolics [18], Explorer [25], and SPUR <ref> [13] </ref>, most new general-purpose computer architectures do not. The most significant result of this paper is that carefully implemented inline software tests can result in relatively simple, low overhead implementations of the read and write barriers.
Reference: [14] <author> Douglas Johnson. </author> <title> The case for a read barrier. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-IV), </booktitle> <pages> pages 279-287, </pages> <address> Santa Clara, CA, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: Nevertheless, Appel's method provides an alternative to the costly Baker collection algorithm. Johnson discusses the value of the read barrier in improving the locality of reference in a very large Lisp program <ref> [14] </ref>. Citing Zorn [29] and Johnson [15], he concludes that the read barrier is too expensive to implement in software.
Reference: [15] <author> Douglas Johnson. </author> <title> Trap architectures for Lisp systems. </title> <booktitle> In Proceedings of the 1990 ACM Conference on LISP and Functional Programming, </booktitle> <pages> pages 79-86, </pages> <address> Nice, France, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: The only additional overhead is the instruction sequence to handle the machine trap and return from it. The cost of fielding a trap differs with architectures, but without careful design, can amount to 100-200 instructions, as Johnson points out <ref> [15] </ref>. If we assume a well-designed trap architecture allowing fast traps (as we should if there is hardware support for the write barrier), the cost of fielding a trap is also small, as few as 10 instructions as suggested by Johnson. <p> These disadvantages are relatively minor in ML, where stores are discouraged (because ML is a mostly-functional language), but would be significant in a Lisp system, where stores are more common. Johnson describes hardware modifications that increase the speed of user trap handlers <ref> [15] </ref>. In the paper, he estimates the cost an inline software write barrier as 7-10% based on Steenkiste's measurement of stores to the heap. Moon estimates that implementing the Symbolics write barrier with software would result in a 10-20% overhead [17]. <p> Nevertheless, Appel's method provides an alternative to the costly Baker collection algorithm. Johnson discusses the value of the read barrier in improving the locality of reference in a very large Lisp program [14]. Citing Zorn [29] and Johnson <ref> [15] </ref>, he concludes that the read barrier is too expensive to implement in software. In work that predates the present evaluation, Zorn uses the same evaluation techniques to arrive at larger costs for the inline implementations and smaller costs for the fault protection implementations of the barriers [29].
Reference: [16] <author> Henry Lieberman and Carl Hewitt. </author> <title> A real-time garbage collector based on the lifetimes of objects. </title> <journal> Communications of the ACM, </journal> <volume> 26(6) </volume> <pages> 419-429, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: Henry Baker proposed a technique called "incremental garbage collection" which greatly shortens the pauses associated with stop-and-copy algorithms [4]. In 1983, Lieberman and Hewitt introduced the idea of generation garbage collection, where only a fraction of the entire heap needs to be considered for most collections <ref> [16] </ref>. This enhancement both reduces the memory reference disruption during garbage collection and shortens collection-related pauses. This paper considers several different implementation techniques for generation and incremental collection, and reaches important and suprising conclusions about the effectiveness of these implementations.
Reference: [17] <author> David A. Moon. </author> <title> Garbage collection in a large Lisp system. </title> <booktitle> In Conference Record of the 1984 ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 235-246, </pages> <address> Austin, Texas, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: This insures that tospace will not fill before fromspace is evacuated. For Lisp systems with large address spaces, Baker's algorithm greatly reduces the pauses associated with garbage collection. This algorithm, coupled with generation collection, 7 has been used successfully for many years by Lisp machines such as the Symbolics <ref> [17] </ref> and Explorer [9]. Studies of the Explorer's algorithm by Courts suggest that the copy-on-demand strategy of incremental collection significantly improves the memory reference locality of Lisp programs by dynamically compacting the working set of the data [9]. <p> Another alternative, which Sobalvarro calls card marking, uses a bitmap to indicate if an intergeneration pointer is stored in a region of memory (the card). The Symbolics uses such a method where the card is a hardware page <ref> [17] </ref>. Card marking 12 is less desirable than word marking because at collection time each marked card must be scanned to locate the intergeneration references. Sobalvarro describes a 10 instruction sequence for the MC68020 architecture that implements write barrier word marking. <p> If a generation trap occurs, a trap handler records the intergeneration pointer in the remembered set and continues. Several architectures provide hardware write barriers, including SPUR [13] and the Symbolics <ref> [17] </ref>. Because the generation check is performed in parallel with the store, the total overhead using this method occurs during the handling of generation traps. <p> In the paper, he estimates the cost an inline software write barrier as 7-10% based on Steenkiste's measurement of stores to the heap. Moon estimates that implementing the Symbolics write barrier with software would result in a 10-20% overhead <ref> [17] </ref>. My results show that hardware support for the write barrier trap can almost eliminate overhead, and that hardware support for the remembered set (such as is provided by the Symbolics) is unnecessary.
Reference: [18] <author> David A. Moon. </author> <title> Architecture of the Symbolics 3600. </title> <booktitle> In Proceedings of the Twelfth Symposium on Computer Architecture, </booktitle> <address> Boston, Massachusetts, </address> <month> June </month> <year> 1985. </year>
Reference-contexts: In general, instruction reorganization can often fill this delay slot, and the cost of the hardware read barrier, like the hardware write barrier, is negligible. Such a barrier has been successfully implemented in several generations of Lisp machine architectures <ref> [10, 18] </ref>. 4.2 The Software Read Barrier As an alternative to the hardware read barrier, the read barrier tests can be performed inline after the pointer is loaded. Unlike the write barrier, where numerous checks must be performed to detect a generation trap, the read barrier requires two simple comparisons. <p> In all cases, implementing the read and write barriers with hardware results in negligible performance degradation, as long as hardware traps are handled sufficiently fast. While several architectures have provided support for these barriers, including the Symbolics <ref> [18] </ref>, Explorer [25], and SPUR [13], most new general-purpose computer architectures do not. The most significant result of this paper is that carefully implemented inline software tests can result in relatively simple, low overhead implementations of the read and write barriers.
Reference: [19] <author> Paul Rovner. </author> <title> On adding garbage collection and runtime types to a strongly-typed, statically checked, concurrent language. </title> <type> Technical Report CSL-84-7, </type> <institution> Xerox Palo Alto Research Center, Palo Alto, California, </institution> <month> July </month> <year> 1985. </year>
Reference-contexts: 1 Introduction Garbage collection is a technique of automatic heap storage reclamation that has been used in Lisp runtime systems for many years. More recently defined block-structured languages such as Modula-3 [7] and Cedar <ref> [19] </ref> also include automatic storage reclamation. Even C, widely used as a systems programming language, has been extended to include garbage collection of heap-allocated objects [5].
Reference: [20] <author> Robert A. Shaw. </author> <title> Improving garbage collector performance in virtual memory. </title> <type> Technical Report CSL-TR-87-323, </type> <institution> Stanford University, </institution> <month> March </month> <year> 1987. </year>
Reference-contexts: With generation garbage collection, individual generations are collected independently, greatly reducing the memory disruption and pause length normally associated with copying collection. Generation collection also takes advantage of the well-documented empirical fact that most heap-allocated objects become garbage shortly after they are allocated <ref> [20, 29] </ref>. By frequently collecting the youngest objects, the efficiency of collection is considerably increased. In a generation algorithm, objects are allocated in the youngest generation (newspace). If an object remains alive long enough, it is eventually copied to the next older generation. <p> This approach was first described by Shaw, who suggests that small modifications to the virtual memory interface of traditional operating systems (essentially providing user-access to "dirty-bits") would allow this information to be maintained very cheaply <ref> [20] </ref>. 17 Without operating system changes, the collection algorithm must maintain its own "dirty--bit" information about oldspace pages. My version of this method behaves as follows. <p> Two approaches to garbage collection based on protection faults have proven to be successful <ref> [2, 20] </ref>, but both required changes to the operating system kernel. Unfortunately, most operating systems are not designed to provide fast memory protection faults because they assume that these faults occur only in error situations.
Reference: [21] <author> Robert A. Shaw. </author> <title> Empirical Analysis of a Lisp System. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <address> Stan-ford, CA, </address> <month> February </month> <year> 1988. </year> <note> Also appears as Computer Systems Laboratory tech report CSL-TR-88-351. </note>
Reference-contexts: Furthermore, my estimates of the the cost of a software write barrier indicate Moon's estimates of 10-20% are too high. Shaw compares software and "dirty-bit" implementations of the write barrier <ref> [21] </ref>. Shaw estimates that inline software implementation would add 7-14% overhead. As an alternative, he suggests that the operating system virtual memory interface should be extended to let the user know about dirty pages.
Reference: [22] <author> Patrick G. Sobalvarro. </author> <title> A lifetime-based garbage collector for LISP systems on general purpose computers. </title> <type> Bachelor's thesis, </type> <institution> MIT, </institution> <year> 1988. </year>
Reference-contexts: The advantages of a sequence representation are simplicity of implementation and speed of trap handling. Sobalvarro describes an organization, called word marking, where a bitmap is used to indicate the memory locations of intergeneration pointers <ref> [22] </ref>. In this case, the generation trap handler simply sets a bit in the bitmap. Word marking avoids the redundancy of a sequence representation at the memory cost of the bitmap.
Reference: [23] <author> Peter Steenkiste. </author> <title> The impact of code density on instruction cache performance. </title> <booktitle> In Proceedings of the Sixteenth Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 252-259, </pages> <address> Jerusalem, Israel, </address> <month> May </month> <year> 1989. </year> <month> 36 </month>
Reference-contexts: The effect of this expansion on performance of Lisp programs has been considered by Steenkiste, who shows that a code expansion of 30% has negligible impact on performance (&lt; 2%) if instruction caches are 4 kilobytes or larger <ref> [23] </ref>. 3.3 The Write Barrier Using Write Protection Faults Another approach to implementing the write barrier differs significantly from the previous two. Instead of testing stores as they occur, this technique uses operating system page protection mechanisms to identify stores into oldspace.
Reference: [24] <author> George Taylor. </author> <title> Static instruction counts of SPUR Lisp programs. </title> <type> Personal communication. </type> <note> Actual data will be published in forthcoming PhD thesis. </note>
Reference-contexts: Similar data was gathered for the MIPS R2000 and MC68020 architectures. The code sequence associated with an inline write barrier test replaces a one instruction store with eight instructions. Measurements of several large SPUR Lisp programs <ref> [24] </ref> indicate that the static frequency of store instructions is typically less than 4%. By expanding each of these instructions into eight instructions, the overall code expansion should be on the order of 20-30%.
Reference: [25] <institution> Texas Instruments, Incorporated, Austin, </institution> <address> TX. </address> <booktitle> Explorer Programming Concepts and Tools, </booktitle> <month> June </month> <year> 1985. </year>
Reference-contexts: In all cases, implementing the read and write barriers with hardware results in negligible performance degradation, as long as hardware traps are handled sufficiently fast. While several architectures have provided support for these barriers, including the Symbolics [18], Explorer <ref> [25] </ref>, and SPUR [13], most new general-purpose computer architectures do not. The most significant result of this paper is that carefully implemented inline software tests can result in relatively simple, low overhead implementations of the read and write barriers.
Reference: [26] <author> David Ungar and Frank Jackson. </author> <title> Tenuring policies for generation-based storage reclamation. </title> <booktitle> In OOPSLA'88 Conference Proceedings, </booktitle> <pages> pages 1-17. </pages> <publisher> ACM, </publisher> <month> September </month> <year> 1988. </year>
Reference-contexts: Object-level tracing has been used to investigate many aspects of garbage collection performance <ref> [26, 30] </ref>. The events that form the trace used to simulate garbage collection algorithms are: object references (loads and stores), allocations, and deallocations. MARS (Memory Allocation and Reference Simulator) is the simulator that collected the event counts used in this paper [29].
Reference: [27] <author> David M. Ungar. </author> <title> The Design and Evaluation of A High Performance Smalltalk System. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, Berkeley, </institution> <address> CA, </address> <month> March </month> <year> 1986. </year> <note> Also appears as tech report UCB/CSD 86/287. </note>
Reference-contexts: After an intergeneration pointer has been discovered, its location must be recorded in the remembered set. Simple representations of the remembered set maintain a sequence of addresses, where each generation trap adds the address of the intergeneration pointer to the sequence <ref> [3, 27, 31] </ref>. One problem with a sequence representation is that the same address can occur in the sequence many times. Such redundancy wastes space and also time when the sequence is scanned during garbage collection.
Reference: [28] <author> Steve Vegdahl and Uwe F. Pleban. </author> <title> The runtime environment of Screme, a Scheme implementation for the 88000. </title> <booktitle> In Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS III), </booktitle> <pages> pages 172-182, </pages> <address> Boston, MA, </address> <month> April </month> <year> 1989. </year> <note> ACM. </note>
Reference-contexts: The pointer is assumed to use the two lower bits of the address as a type tag (low-tagging) as has been used in several Lisp systems <ref> [12, 28] </ref>. To correctly estimate the overhead of this implementation of the write barrier, a CPU cost must be determined for each possible value for the generation of the pointer and the container.
Reference: [29] <author> Benjamin Zorn. </author> <title> Comparative Performance Evaluation of Garbage Collection Algorithms. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, Berkeley, </institution> <address> CA, </address> <month> November </month> <year> 1989. </year> <note> Also appears as tech report UCB/CSD 89/544. </note>
Reference-contexts: With generation garbage collection, individual generations are collected independently, greatly reducing the memory disruption and pause length normally associated with copying collection. Generation collection also takes advantage of the well-documented empirical fact that most heap-allocated objects become garbage shortly after they are allocated <ref> [20, 29] </ref>. By frequently collecting the youngest objects, the efficiency of collection is considerably increased. In a generation algorithm, objects are allocated in the youngest generation (newspace). If an object remains alive long enough, it is eventually copied to the next older generation. <p> The events that form the trace used to simulate garbage collection algorithms are: object references (loads and stores), allocations, and deallocations. MARS (Memory Allocation and Reference Simulator) is the simulator that collected the event counts used in this paper <ref> [29] </ref>. MARS is attached to a commercial Common Lisp system (Franz Allegro Common Lisp), and large Lisp programs drive the algorithm simulation. In order to simulate the behavior of garbage collection algorithms, the simulator maintains its own view of how objects are organized in memory. <p> While the number of generation traps depends on the promotion policy and allocation threshold, the fraction of instructions causing generation traps is typically small (Zorn reports typically &lt; 0.01% of all instructions <ref> [29] </ref>). Using a remembered set implemented with word-marking, the number of instructions to mark a word is small, 22 at most as indicated above. The only additional overhead is the instruction sequence to handle the machine trap and return from it. <p> We can estimate the cost using a rough calculation. The precise costs will be presented later. Memory references to the heap (as opposed to the runtime stack), account for an average of 12% of all instructions over a variety of applications (as measured by Zorn <ref> [29] </ref>). Of these, approximately 70% are pointer loads (see table above). With inline tests, three or five additional instructions are added to each load (and we will assume the split is 50/50). <p> Nevertheless, Appel's method provides an alternative to the costly Baker collection algorithm. Johnson discusses the value of the read barrier in improving the locality of reference in a very large Lisp program [14]. Citing Zorn <ref> [29] </ref> and Johnson [15], he concludes that the read barrier is too expensive to implement in software. In work that predates the present evaluation, Zorn uses the same evaluation techniques to arrive at larger costs for the inline implementations and smaller costs for the fault protection implementations of the barriers [29]. <p> <ref> [29] </ref> and Johnson [15], he concludes that the read barrier is too expensive to implement in software. In work that predates the present evaluation, Zorn uses the same evaluation techniques to arrive at larger costs for the inline implementations and smaller costs for the fault protection implementations of the barriers [29]. Zorn's previous results are pessimistic in predicting the inline costs because he used instruction counts to determine CPU costs.
Reference: [30] <author> Benjamin Zorn. </author> <title> Comparing mark-and-sweep and stop-and-copy garbage collection. </title> <booktitle> In Proceedings of the 1990 ACM Conference on LISP and Functional Programming, </booktitle> <pages> pages 87-98, </pages> <address> Nice, France, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Object-level tracing has been used to investigate many aspects of garbage collection performance <ref> [26, 30] </ref>. The events that form the trace used to simulate garbage collection algorithms are: object references (loads and stores), allocations, and deallocations. MARS (Memory Allocation and Reference Simulator) is the simulator that collected the event counts used in this paper [29].
Reference: [31] <author> Benjamin Zorn, Paul Hilfinger, Kinson Ho, and James Larus. </author> <title> SPUR Lisp: Design and implementation. </title> <type> Technical Report UCB/CSD 87/373, </type> <institution> Computer Science Division (EECS), University of California, Berkeley, </institution> <month> October </month> <year> 1987. </year> <month> 37 </month>
Reference-contexts: After an intergeneration pointer has been discovered, its location must be recorded in the remembered set. Simple representations of the remembered set maintain a sequence of addresses, where each generation trap adds the address of the intergeneration pointer to the sequence <ref> [3, 27, 31] </ref>. One problem with a sequence representation is that the same address can occur in the sequence many times. Such redundancy wastes space and also time when the sequence is scanned during garbage collection.
References-found: 31

