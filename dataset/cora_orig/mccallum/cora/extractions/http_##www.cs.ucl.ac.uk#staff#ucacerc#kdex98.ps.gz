URL: http://www.cs.ucl.ac.uk/staff/ucacerc/kdex98.ps.gz
Refering-URL: http://www.cs.ucl.ac.uk/staff/E.Collopy/research.html
Root-URL: http://www.cs.ucl.ac.uk
Email: ecollopy@cs.ucl.ac.uk mlevene@cs.ucl.ac.uk  
Title: Using Numerical Dependencies and the Bootstrap for the Consistency Problem  
Author: Ethan Collopy Mark Levene 
Keyword: Key Words Indefinite Information, Numerical Dependency, Bootstrap sampling, Data Mining  
Address: Gower Street, London WC1E 6BT, U.K.  
Affiliation: Department of Computer Science University College London  
Abstract: Indefinite information in relations allows cells to contain a set of values thereby allowing disjunction to be represented within a relational database. A definite relation extracted from an indefinite relation has all indefinite cells replaced with just one of the indefinite cell values. The consistency problem, widely known within the database community, denotes the problem of finding a definite relation, extracted from an indefinite relation, that satisfies a given set of functional dependencies (FDs). It has been shown to be NP-Complete [7]. We propose a stochastic procedure which approximates the set of FDs in terms of numerical dependencies (NDs) and combines the chase procedure, a well known technique for modifying a relation to satisfy constraints by removing redundant values, for NDs with hill-climbing methods. The computer intensive statistical process known as the Bootstrap is used to determine a suitable sampling size of definite relations from the indefinite relation. Extensive simulations were conducted over 12 FD sets with the domain, tuple, and indefinite cell ar-ity varied across batches, each containing 500 runs. This was performed for both a naive random generation of possible worlds and a 'chase and hill climbing approach'. A proximity metric was devised and used to assess the distance of each resulting ND set to the given FD set. In real-world terms a low proximity may denote a poorly specified set of FDs emphasising the data mining aspect of this work. Our results show that the chase and hill climbing approach has, on average, much faster run times than its naive counterpart though the final results may be similar. As either the relation size or the degree of indefinite cells in a relation increases the chase and hill-climbing approach becomes more effective. The best performance of the chase and hill climbing nearly always outperforms the naive procedure within a batch. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Collopy and M. Levene. </author> <title> Using numerical dependencies and the bootstrap for the consistency problem. </title> <type> Technical Report RN/98/2, </type> <institution> University College London, U.K., </institution> <year> 1998. </year>
Reference-contexts: Proposition 2.1 The maximum distance between any two points in the lattice to their lub is always equivalent to the distance from the bottom to the top of the lattice. Proof. Given in <ref> [1] </ref>. 2 The metric p is a distance function given that the distance between two NDs is zero only when they are equivalent and that p (n 1 ; n 2 ) = p (n 2 ; n 1 ) always holds. <p> It also satisfies the triangle inequality, whose proof we give in <ref> [1] </ref>. <p> The backward chase removes values from indefinite cells of attributes on the left hand side of an FD thereby forcing a new partition of attribute values and hence a closer ND set approximation. The chase heuristic is formally presented in <ref> [1] </ref>. Algorithm 4, CHECK CONS (r, F, B), uses the CHASE procedure, generates a suitable sample size ff using the bootstrap and then iterates ff times from an initial possible world generated by ND GEN applying the CHASE in a hill climbing fashion.
Reference: [2] <author> B. Efron and R. Tibshirani. </author> <title> Bootstrap methods for standard errors, confidence intervals, and other measures of statistical accuracy. </title> <journal> Statistical Science, </journal> <volume> 1(1):54 - 77, </volume> <year> 1986. </year>
Reference-contexts: We assume that all possible worlds are equally probable having a uniform distribution. We wish to know what is a suitable limit on the generation of possible worlds to give the hill-climbing chase procedure for which we use the Bootstrap procedure <ref> [2] </ref>. We initially take a sample of n observed possible worlds. Based upon this sample we perform a number of bootstrap replications. Each bootstrap replication samples from the observed possible worlds with replacement. <p> Definition 2.8 (The consistency problem) Given a set of FDs F and a relation r the consistency problem is the problem of deciding whether r j F. 2.2 Incorporating the Bootstrap The bootstrap <ref> [2] </ref> is a data driven simulation method for statistical inference. It is a computa-tionally intensive procedure that has been shown to ably provide confidence limits which would not have been capable of being similarly generated more than 30 years ago. <p> This suggests applying a bootstrap procedure to a sample of definite instances to approximate the population distribution based on the sample distribution <ref> [2] </ref>. Informally, we use this incremental bootstrap procedure to tell us how many worlds we need to consider so that we have a high confidence that generating additional worlds will not improve our solution. <p> of B bootstrap samples ~p ? b , we calculate the mean s (), or any other statistic of interest, in domain size of 4 for each dependency exactly the same way as we would have for the original sample, s ( ~p ? b ) = B i )=B. <ref> [2] </ref> tackles how large the BRS should be. Given a BRS B, [2] refers to the ideal bootstrap estimate which takes B equal to infinity. This is not true for relations where the ideal limit is related to the number of possible worlds in the relation. [2] show the amount of <p> s (), or any other statistic of interest, in domain size of 4 for each dependency exactly the same way as we would have for the original sample, s ( ~p ? b ) = B i )=B. <ref> [2] </ref> tackles how large the BRS should be. Given a BRS B, [2] refers to the ideal bootstrap estimate which takes B equal to infinity. This is not true for relations where the ideal limit is related to the number of possible worlds in the relation. [2] show the amount of computation time it takes for increased BRS sizes increases linearly. <p> = B i )=B. <ref> [2] </ref> tackles how large the BRS should be. Given a BRS B, [2] refers to the ideal bootstrap estimate which takes B equal to infinity. This is not true for relations where the ideal limit is related to the number of possible worlds in the relation. [2] show the amount of computation time it takes for increased BRS sizes increases linearly. This is also the case for increasing the BRS for indefinite relations. We now describe the methods of our Bootstrap application.
Reference: [3] <author> J. Grant and J. Minker. </author> <title> Inferences for numerical dependencies. </title> <journal> Theoretical Computer Science, </journal> <volume> 41 </volume> <pages> 271-287, </pages> <year> 1985. </year>
Reference-contexts: Functional dependencies (FDs) are by far the most common integrity constraint which appear in practice. There may be cases, highlighted below, where the traditional FD is too strict and a weaker integrity constraint is required. We claim that the numerical dependencies (NDs) <ref> [3] </ref> are worthwhile generalisations of FDs which allow an attribute set to uniquely determine up to k different attribute set values, noting that k = 1 in the case of FDs. <p> We can generalise the concept of an FD by a numerical dependency <ref> [3] </ref>. Definition 2.3 (ND satisfaction) A numerical dependency over R (or simply an ND) is a statement of the form X ! k Y, where X, Y R and k 1.
Reference: [4] <author> T. Imielinski, R. Van Der Meyden, and K. Vadaparty. </author> <title> Complexity tailored design: A new design methodol ogy for databases with incomplete information. </title> <journal> Jour nal of Computer and System Sciences, </journal> <volume> 51 </volume> <pages> 405-432, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction Indefinite information representation in relations has been shown to be a useful facility for incomplete specifications in design and planning applications <ref> [4, 7] </ref>. We define indefinite cells as cells containing one or more values which represent a set of possibilities denoting the current limit of knowledge in the database. <p> It also satisfies the triangle inequality, whose proof we give in [1]. This implies that the distance between any two ND sets which approximate an FD set F is less than or equal to the distance between the two ND sets and F. 2.1 The Consistency Problem <ref> [4] </ref> motivated the use of indefinite information within a relation using a scheduling application, denoting indefinite information as OR objects. In this context the consistency problem is equivalent to asking whether a particular schedule in invalid. It was shown in [7] that the consistency problem is, in general, NP-complete. <p> The superiority of the chase and hill-climbing procedure in dependency sets which do not determine each other highlighted this fact. 4 Conclusion We have described how the representation of indefinite information is a valuable extension to relational databases, following on from the work in <ref> [4, 7] </ref>. The use of NDs extends the work of [7] where relations which do not satisfy the constraint set functionally are said to be unrealizable.
Reference: [5] <author> H. Mannila and K-J. Raiha. </author> <title> The Design of Relational Databases. </title> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference-contexts: This is widely known as the consistency problem. The consistency problem has been shown to be NP-Complete in general. Henceforth, we refer to definite relations as possible worlds. Our approach in attempting to solve the consistency problem is based on using the chase procedure <ref> [5] </ref> as a heuristic in conjunction with a hill-climbing technique. We start by applying the chase procedure to remove inconsistent data from the relation which does not satisfy an initial ND set. <p> It is a heuristic procedure extended from the standard chase procedure for FDs <ref> [5] </ref> which, given the current set of NDs, attempts to remove extraneous or redundant information that may prevent the ND set from being satisfied. <p> We concentrated on a few FD sets demarcated by the number of dependencies in the set and whether they were BCNF <ref> [5] </ref>, where every dependency is a superkey, or non-BCNF.
Reference: [6] <author> G. Piatetsky-Shapiro and C. J. Matheus. </author> <title> Measuring data dependencies in large databases. </title> <booktitle> In Proceedings of the Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 162-173, </pages> <address> Washington DC, </address> <year> 1993. </year>
Reference-contexts: The use of NDs extends the work of [7] where relations which do not satisfy the constraint set functionally are said to be unrealizable. In many dependency data mining applications, which range from data summari-sation to learning within decision trees <ref> [6] </ref>, we may wish to obtain a numerical value, between 0 and 1, denoting how close a set of FDs are to being satisfied; the metric presented in this paper achieves this. The consistency problem for relations with indefinite information is widely known to be NP-complete.
Reference: [7] <author> K. Vadaparty and S. Naqvi. </author> <title> Using constraints for effi cient query processing in non-deterministic databases. </title> <journal> IEEE Transactions on Knowledge and Data Engineer ing, </journal> <volume> 7(6):850 - 864, </volume> <year> 1995. </year>
Reference-contexts: 1 Introduction Indefinite information representation in relations has been shown to be a useful facility for incomplete specifications in design and planning applications <ref> [4, 7] </ref>. We define indefinite cells as cells containing one or more values which represent a set of possibilities denoting the current limit of knowledge in the database. <p> In this context the consistency problem is equivalent to asking whether a particular schedule in invalid. It was shown in <ref> [7] </ref> that the consistency problem is, in general, NP-complete. It follows that the corresponding consistency problem for NDs is also NP-complete, since FDs are a special case of NDs. <p> In the special case when for all attributes A in the left-hand sides of the FDs in F the A-values of all the tuples in r are definite, then the consistency problem can be solved in polynomial time in the sizes of F and r <ref> [7] </ref>. Definition 2.8 (The consistency problem) Given a set of FDs F and a relation r the consistency problem is the problem of deciding whether r j F. 2.2 Incorporating the Bootstrap The bootstrap [2] is a data driven simulation method for statistical inference. <p> The superiority of the chase and hill-climbing procedure in dependency sets which do not determine each other highlighted this fact. 4 Conclusion We have described how the representation of indefinite information is a valuable extension to relational databases, following on from the work in <ref> [4, 7] </ref>. The use of NDs extends the work of [7] where relations which do not satisfy the constraint set functionally are said to be unrealizable. <p> The use of NDs extends the work of <ref> [7] </ref> where relations which do not satisfy the constraint set functionally are said to be unrealizable. <p> The consistency problem for relations with indefinite information is widely known to be NP-complete. Therefore we cannot expect to develop a polynomial time based solution unless P = N P or the database is restricted as in <ref> [7] </ref>. Our approach does however introduce an interesting new technique based on sampling, extending the bootstrap to providing useful approximations for problems such as the consistency problem. We have shown the Bootstrap gives valid upper bounds which may have other data mining applications. <p> The simulations have shown that our procedure can provide useful approximations to FD sets in the form of ND sets for any indefinite relation. We compared different weightings of indefinite information within a relation and showed that as a relation approaches what <ref> [7] </ref> refer to as a good database, one without indefinite information in the left hand side of the dependencies, then the chase procedure for NDs becomes more effective.
References-found: 7

