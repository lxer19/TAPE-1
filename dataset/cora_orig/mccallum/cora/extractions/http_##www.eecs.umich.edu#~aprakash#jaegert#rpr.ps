URL: http://www.eecs.umich.edu/~aprakash/jaegert/rpr.ps
Refering-URL: http://www.eecs.umich.edu/~aprakash/csrg_pub.html
Root-URL: http://www.cs.umich.edu
Email: jaegert@eecs.umich.edu rubin@bellcore.com  
Title: Preserving Integrity in Remote File Location and Retrieval  
Author: Trent Jaeger Aviel D. Rubin 
Keyword: needed. Keywords: Digital signatures, cryptographic digests, remote procedure calls, wide-area network file location, trusted authorities, C-shells.  
Address: 445 South Street Ann Arbor, MI 48105 Morristown, NJ 07960  
Affiliation: Software Systems Research Lab Security Research Group EECS Department Bellcore University of Michigan  
Note: Copyright c 1996 IEEE. See full copyright notice at Table of Contents.  This work was done while this author was a summer intern at Bellcore.  
Abstract: We present a service for locating and retrieving files from an untrusted network such that the integrity of the retrieved files can be verified. This service enables groups of people in geographically remote locations to share files using an untrusted network. For example, distribution of an organization's software to all the organization's sites can be accomplished using this service. Distribution of files in an untrusted network is complicated by two issues: (1) location of files and (2) verification of file integrity. ftp and World-wide Web (WWW) services require some user intervention to locate a file, so they cannot be embedded in automated systems. Distributed systems have mechanisms for automated file location and retrieval, but they require trust in all system principals and do not provide an appropriate balance between availability of files and retrieval cost for our applications. Verification of the integrity of a file retrieved from an untrusted network is necessary because the file is subject to malicious modification attacks. Our service provides the capability to automatically locate, retrieve, and verify files specified by a client using a single trusted principal. We demonstrate our service by building a system shell that automatically downloads remote software when 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> NIST FIPS PUB XX, </author> <title> Digital Signature Standard, </title> <month> February </month> <year> 1993. </year> <institution> National Institute of Standards and Technology, U.S. Department of Commerce DRAFT. </institution>
Reference-contexts: Clients are the only principals that need the CA's public key. They store the CA's public key in a read-only file. In the future, the use of secure hardware (e.g., smart cards) should be considered. In our implementation, all digital signatures are generated using the Digital Signature Algorithm (DSA) <ref> [1] </ref>. DSA was developed and patented by the National Security Agency (NSA) and is the proposed standard digital signature algorithm of the National Institute of Standards and Technology (NIST). DSA is a public key algorithm whose security is based on the hardness of the discrete logarithm problem.
Reference: [2] <author> D. Balenson. </author> <title> Privacy enhancement for Internet electronic mail: Part III: algorithms, modes, and identifiers, </title> <month> February </month> <year> 1993. </year> <title> Internet RFC 1423. </title>
Reference-contexts: This contrasts with the PEM <ref> [2] </ref> model where a CA would certify the public key of each author, and authors would certify files directly. The advantages of CA's certifying files are that: (1) the certification date of the file can be trusted; and (2) certification using previously revoked public keys is prevented. <p> At present, we assume that each organization will have one CA. If a group of organizations wants to share information, a web of trust between the CA's of those organizations can be created using the mechanism used for PEM <ref> [2] </ref> or PGP [18] 2 . Clients need not trust location servers nor distribution servers. If a distribution server delivers an incorrect or tampered file, the client recognizes it.
Reference: [3] <author> A. D. Birrell, R. Levin, R. M. Needham, and M. D. Schroeder. Grapevine: </author> <title> An exercise in distributed computing. </title> <journal> Communications of ACM, </journal> <volume> 25(4) </volume> <pages> 260-274, </pages> <month> April </month> <year> 1982. </year>
Reference-contexts: Liaison servers reduce the number of broadcasts that are necessary since a file that has been located once is stored by at least one liaison server. In push systems, such as Grapevine <ref> [3] </ref>, DEC Global Name Service [7], and Ameoba [17], servers generate information about remote files and distribute that information to clients. The push model makes retrieval more efficient because the information about the location of each remote file is closer to the client.
Reference: [4] <author> D. R. Cheriton. </author> <title> The V distributed system. </title> <journal> Communications of ACM, </journal> <volume> 31(3) </volume> <pages> 314-333, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: The file retrieval problem is for the client to obtain an authentic version of that file from a distribution server. Current file location mechanisms can be divided into two categories: (1) pull; and (2) push. Pull systems, such as V <ref> [4, 5] </ref> and shared virtual memory systems like Ivy [9] and Emerald [6], generate file location information on demand and cache the information locally. Location of new files requires a broadcast, so it can be expensive.
Reference: [5] <author> D. R. Cheriton and T. P. Mann. </author> <title> Decentralizing a global naming service for improved performance and fault-tolerance. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(2) </volume> <pages> 147-183, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: The file retrieval problem is for the client to obtain an authentic version of that file from a distribution server. Current file location mechanisms can be divided into two categories: (1) pull; and (2) push. Pull systems, such as V <ref> [4, 5] </ref> and shared virtual memory systems like Ivy [9] and Emerald [6], generate file location information on demand and cache the information locally. Location of new files requires a broadcast, so it can be expensive. <p> Location servers store a map of file identifiers to the set of servers that provide them. Our implementation allows for a distributed model of location servers, similar to the model of liaison servers in the V operating system <ref> [5] </ref>. Liaison servers update their database as they fulfill client requests. In our implementation, only published files can be retrieved and the location of these files is uploaded to location servers. 6 to distribution server; (2) Publisher uploads a file identifier-to-distribution server mapping to location server.
Reference: [6] <author> E. Jul, H. Levy, N. Hutchinson, and A. Black. </author> <title> Fine-grained mobility in the Emerald system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 109-133, </pages> <month> Febru-ary </month> <year> 1988. </year>
Reference-contexts: Current file location mechanisms can be divided into two categories: (1) pull; and (2) push. Pull systems, such as V [4, 5] and shared virtual memory systems like Ivy [9] and Emerald <ref> [6] </ref>, generate file location information on demand and cache the information locally. Location of new files requires a broadcast, so it can be expensive. V defines domain-wide caches, called liaison servers, for storing location information generated by all clients in a domain.
Reference: [7] <author> B. Lampson. </author> <title> Designing a global name service. </title> <booktitle> In Proceedings of the Fifth ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 1-10, </pages> <year> 1986. </year>
Reference-contexts: Liaison servers reduce the number of broadcasts that are necessary since a file that has been located once is stored by at least one liaison server. In push systems, such as Grapevine [3], DEC Global Name Service <ref> [7] </ref>, and Ameoba [17], servers generate information about remote files and distribute that information to clients. The push model makes retrieval more efficient because the information about the location of each remote file is closer to the client. However, the cost of forwarding change messages can be high.
Reference: [8] <author> A. K. Lenstra. </author> <title> Documentation of LIP, </title> <month> March </month> <year> 1995. </year> <note> Bellcore TM-24936. Available via anonymous ftp from flash.bellcore.com (soon ftp.bellcore.com). </note>
Reference-contexts: The version of DSA used in our implementation is part of the Long Integer Package (LIP) <ref> [8] </ref> developed by Arjen Lenstra. LIP provides a library of functions for computing with arbitrarily long integers. For example, LIP can generate 1024-bit integer DSA keys and perform the modular exponentiation operations necessary for signature generation and verification.
Reference: [9] <author> K. Li and P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: The file retrieval problem is for the client to obtain an authentic version of that file from a distribution server. Current file location mechanisms can be divided into two categories: (1) pull; and (2) push. Pull systems, such as V [4, 5] and shared virtual memory systems like Ivy <ref> [9] </ref> and Emerald [6], generate file location information on demand and cache the information locally. Location of new files requires a broadcast, so it can be expensive. V defines domain-wide caches, called liaison servers, for storing location information generated by all clients in a domain.
Reference: [10] <author> R. C. Merkle. </author> <title> Protocols for public key cryptosystems. </title> <booktitle> In Proceedings of IEEE Symposium on Security and Privacy, </booktitle> <pages> pages 122-133, </pages> <year> 1980. </year>
Reference-contexts: Determination of whether to permanently store retrieved files and how to organize related files would help. Another issue is that the service's security is based on the trust in the CA's. However, it would be preferable to not require trust in any system principal. Merkle <ref> [10] </ref> defines a mechanism by which malicious action on the part of a CA can be detected by outside observers. With this enhancement, the requirement for complete trust in the CA is eliminated. Acknowledgements We thank the anonymous referees for their many valuable comments.
Reference: [11] <author> J. Ousterhout. </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: In addition, when new versions of utilities are published these can be downloaded as well. System administrators announce new software is available using the file publication protocol described above. A form is defined for system administrators to enter the publication information. This form is created using Tcl/Tk <ref> [11] </ref> and shown in Figure 5. The location server field in the form specifies the domain name of the location server. The file path field indicates the file name and the location of the file. The certificate path field indicates the location of the file's certificate.
Reference: [12] <author> R. Rivest. </author> <title> The MD5 message digest algorithm, </title> <month> April </month> <year> 1992. </year> <title> Internet RFC 1321. </title>
Reference-contexts: The following protocol is used to verify file authenticity. First, a user compares the file identifier and author in the certificate to the file identifier and author expected by the user. Next, the user computes a cryptographic digest of the file (using a trusted hash program, such as MD5 <ref> [12] </ref>) and compares this digest to the cryptographic digest in the certificate to verify the file's integrity. If the user trusts the CA and the two comparisons succeed, then the file satisfies the Betsi verification protocol. <p> This version contains all the functionality of the Bellcore-proprietary version of LIP we used, except for the DSA code itself. However, the DSA algorithm is widely published [15], and it can implemented using the basic LIP functions. The MD5 <ref> [12] </ref> hash algorithm is used to generate cryptographic digests.
Reference: [13] <author> R. Rivest, A. Shamir, and L. Adleman. </author> <title> On digital signatures and public-key cryptosystems. </title> <journal> Communications of the ACM, </journal> <volume> 21(2) </volume> <pages> 120-126, </pages> <month> February </month> <year> 1978. </year>
Reference-contexts: DSA is a public key algorithm whose security is based on the hardness of the discrete logarithm problem. Our choice of DSA may be somewhat controversial given that a large majority of digital signature applications use the RSA <ref> [13] </ref> algorithm. However, DSA has the advantage that NIST claims that DSA can be exported and that it is royalty-free 3 . On the other hand, the exportation of RSA is tightly controlled and its use requires royalty payments to the patent holders.
Reference: [14] <author> A. Rubin. </author> <title> Trusted distribution of software over the Internet. </title> <booktitle> In Proc. Symposium on Network and Distributed System Security, </booktitle> <year> 1995. </year>
Reference-contexts: Even worse, the malicious software may contain a virus or a Trojan horse. Bellcore's Trusted Software Integrity (Betsi) system <ref> [14] </ref> enables users to manually verify the integrity of a file obtained from the Internet. <p> We assume that a client believes any statement made and digitally signed by a trusted authority. Therefore, a client can compare the file retrieved to authentication information signed by a trusted authority to determine if a file is authentic. This is the protocol implemented by the Betsi system <ref> [14] </ref>. In Betsi, a trusted certification authority (CA) creates certificates that associate a registered author with a file identifier and a cryptographic digest of the file. Betsi's author registration protocol prevents an attacker from masquerading as another registered author.
Reference: [15] <author> B. Schneier. </author> <title> Applied Cryptography. </title> <publisher> Wiley & Sons, </publisher> <year> 1994. </year>
Reference-contexts: A free version of LIP is available via ftp from the site ox.ac.uk at /pub/math/freelip/freelip 1.0.tar.gz. This version contains all the functionality of the Bellcore-proprietary version of LIP we used, except for the DSA code itself. However, the DSA algorithm is widely published <ref> [15] </ref>, and it can implemented using the basic LIP functions. The MD5 [12] hash algorithm is used to generate cryptographic digests.
Reference: [16] <author> R. Srinivasan. </author> <title> RPC: Remote procedure call protocol specification version 2, </title> <month> August </month> <year> 1995. </year> <title> Internet RFC 1831. </title>
Reference-contexts: These features and the fact that the code is in the public domain have made MD5 an RFC standard one-way hash function. Interaction between principals is implemented using the Sun RPC mechanism <ref> [16] </ref>. Each of the steps shown in Figure 1 correspond to an RPC request and reply. The publisher and client principals make RPC requests to the appropriate server principal as necessary. The server then responds with a result.
Reference: [17] <author> A. S. Tannenbaum, R. van Renesse, H. van Staveren, G. Sharp, S. Mullender, J. Jansen, and G. van Rus-som. </author> <title> Experiences with the Ameoba distributed operating system. </title> <journal> Communications of ACM, </journal> <volume> 33(12) </volume> <pages> 46-63, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Liaison servers reduce the number of broadcasts that are necessary since a file that has been located once is stored by at least one liaison server. In push systems, such as Grapevine [3], DEC Global Name Service [7], and Ameoba <ref> [17] </ref>, servers generate information about remote files and distribute that information to clients. The push model makes retrieval more efficient because the information about the location of each remote file is closer to the client. However, the cost of forwarding change messages can be high. <p> The act of `publishing' was first used in the Ameoba system <ref> [17] </ref> as a way to advertise that a particular service resides on a particular server. In Ameoba, a file publication protocol activates server agents on client machines to catch and forward service requests.
Reference: [18] <author> P. Zimmermann. </author> <title> PGP user's guide. </title> <institution> Distributed by the Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1994. </year> <month> 11 </month>
Reference-contexts: At present, we assume that each organization will have one CA. If a group of organizations wants to share information, a web of trust between the CA's of those organizations can be created using the mechanism used for PEM [2] or PGP <ref> [18] </ref> 2 . Clients need not trust location servers nor distribution servers. If a distribution server delivers an incorrect or tampered file, the client recognizes it. Any change to the certificate is detected by signature verification, and any change to the file is detected by the digest comparison.
References-found: 18

