URL: ftp://ftp.cs.wisc.edu/computer-vision/rvs95-seitz.ps.gz
Refering-URL: http://www.cs.wisc.edu/computer-vision/pubs.html
Root-URL: 
Email: seitz@cs.wisc.edu dyer@cs.wisc.edu  
Title: Physically-Valid View Synthesis by Image Interpolation  
Author: Steven M. Seitz Charles R. Dyer 
Note: Appearing in Proc. Workshop on Representations of Visual Scenes,  
Address: Madison, WI 53706  Cambridge MA, 1995.  
Affiliation: Department of Computer Sciences University of Wisconsin  
Abstract: Image warping is a popular tool for smoothly transforming one image to another. "Morphing" techniques based on geometric image interpolation create compelling visual effects, but the validity of such transformations has not been established. In particular, does 2D interpolation of two views of the same scene produce a sequence of physically valid in-between views of that scene? In this paper, we describe a simple image rectification procedure which guarantees that interpolation does in fact produce valid views, under generic assumptions about visibility and the projection process. Towards this end, it is first shown that two basis views are sufficient to predict the appearance of the scene within a specific range of new viewpoints. Second, it is demonstrated that interpolation of the rectified basis images produces exactly this range of views. Finally, it is shown that generating this range of views is a theoretically well-posed problem, requiring neither knowledge of camera positions nor 3D scene reconstruction. A scanline algorithm for view interpolation is presented that requires only four user-provided feature correspondences to produce valid orthographic views. The quality of the resulting images is demonstrated with interpolations of real imagery. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Toelg and T. Poggio, </author> <title> "Towards an example-based image compression architecture for video conferencing," </title> <journal> A.I. </journal> <volume> Memo No. 1494, </volume> <publisher> M.I.T., </publisher> <address> Boston, MA, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: The result depends on an assumption of monotonicity which requires that corresponding scene points appear in the same order in both images. Practical applications of view synthesis include virtual teleconferencing <ref> [1, 2] </ref> with limited network bandwidth. By using view synthesis at the receiving end, different views of the participants can be synthesized from a small number of transmitted views. View synthesis has also been used to create panoramic mosaic images [3]. <p> Two groups [2, 6] have recently developed image warping techniques for perspective-correct view synthesis. Under the assumption that a complete pixel-wise correspondence is available, it is possible to predict a broad range of views. Several researchers <ref> [1, 7, 8, 9, 10] </ref> have used interpolation to produce new images without establishing the physical validity of the resulting images. <p> We chose to use dynamic programming techniques because they make strong use of monotonic-ity and are relatively simple to implement. It should be noted, however, that our approach is not dependent on a particular stereo matching algorithm; other researchers <ref> [1, 9, 10] </ref> have had success with different stereo algorithms for view synthesis. The complete algorithm is as follows: 1. Obtain either 4 or more feature correspondences or relative camera positions from the user 2. <p> Furthermore, we demonstrated that a particular range of views can be generated by linear interpolation of the basis images, if the basis images are first rectified. This result provides a theoretical basis for morphing techniques based on geometric image interpolation <ref> [1, 7, 8, 9, 10] </ref> and provides a simple way of generating new views of a scene. Finally, a scan-line algorithm for interpolating two basis images was described that requires only a small number of user-provided feature correspondences. The application of the method was demonstrated on real images.
Reference: [2] <author> L. McMillan and G. Bishop, </author> <title> "Head-tracked stereoscopic display using image warping," </title> <booktitle> in Proc. SPIE 2409A, </booktitle> <year> 1995. </year>
Reference-contexts: The result depends on an assumption of monotonicity which requires that corresponding scene points appear in the same order in both images. Practical applications of view synthesis include virtual teleconferencing <ref> [1, 2] </ref> with limited network bandwidth. By using view synthesis at the receiving end, different views of the participants can be synthesized from a small number of transmitted views. View synthesis has also been used to create panoramic mosaic images [3]. <p> They investigated special situations in which interpolation produces valid perspective views, but concluded that the interpolated images do not in general correspond to exact perspective views. Two groups <ref> [2, 6] </ref> have recently developed image warping techniques for perspective-correct view synthesis. Under the assumption that a complete pixel-wise correspondence is available, it is possible to predict a broad range of views.
Reference: [3] <author> R. Kumar, P. Anandan, and K. Hanna, </author> <title> "Direct recovery of shape from multiple views: A parallax based approach," </title> <booktitle> in Proc. ICPR, </booktitle> <pages> pp. 685-688, </pages> <year> 1994. </year>
Reference-contexts: Practical applications of view synthesis include virtual teleconferencing [1, 2] with limited network bandwidth. By using view synthesis at the receiving end, different views of the participants can be synthesized from a small number of transmitted views. View synthesis has also been used to create panoramic mosaic images <ref> [3] </ref>. Several images of a scene can be combined to create a single mosaic image by warping the images to be consistent with a common viewpoint. An advantage of image-based view synthesis is that rendering time is independent of scene complexity.
Reference: [4] <author> S. E. Chen and L. Williams, </author> <title> "View interpolation for image synthesis," </title> <booktitle> in Proc. SIGGRAPH 93, </booktitle> <pages> pp. 279-288, </pages> <year> 1993. </year>
Reference-contexts: An advantage of image-based view synthesis is that rendering time is independent of scene complexity. This property can be exploited to speed up rendering of complex scenes <ref> [4] </ref>. The remainder of the paper is structured as follows: Section 2 reviews related work in image-based view synthesis. Section 3 describes the projection model and relevant terminology. Section 4 formalizes the notion of view interpolation and proves that the problem is well-posed under a general visibility assumption. <p> However, their work does not take into account visibility issues that are crucial to understanding which views can be synthesized. Chen and Williams <ref> [4] </ref> described an approach for view synthesis based on linear interpolation of corresponding image points using range data to obtain correspondences. They investigated special situations in which interpolation produces valid perspective views, but concluded that the interpolated images do not in general correspond to exact perspective views.
Reference: [5] <author> S. Ullman and R. Basri, </author> <title> "Recognition by linear combinations of models," </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 13, no. 10, </volume> <pages> pp. 992-1006, </pages> <year> 1991. </year>
Reference-contexts: The feasibility of using image interpolation for view in 1 terpolation is explored in Section 5 and a scanline algo-rithm for view interpolation using minimal correspondence information is introduced in Section 6. Section 7 presents results on real images. 2 Related Work Ullman and Basri <ref> [5] </ref> demonstrated that new views can be expressed as linear combinations of other views of the same scene. Although the focus of their work was recognition, it has clear ramifications for view synthesis, providing a simple mechanism for predicting the positions of features in new views. <p> and I 2 are represented by arrays of corresponding points, then image interpolation is expressed by the following equation: I i = (2 i)I 1 + (i 1)I 2 (2) Image interpolation has a direct physical interpretation in terms of views, a connection that was recognized by Ullman and Basri <ref> [5] </ref> in the general context of linear combinations of views. Here we present a simple geometric interpretation that makes the underlying principles more explicit. Consider two views V 1 and V 2 of a scene S.
Reference: [6] <author> S. Laveau and O. Faugeras, </author> <title> "3-D scene representation as a collection of images and fundamental matrices," </title> <type> Tech. Rep. 2205, </type> <institution> INRIA, Sophia-Antipolis, France, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: They investigated special situations in which interpolation produces valid perspective views, but concluded that the interpolated images do not in general correspond to exact perspective views. Two groups <ref> [2, 6] </ref> have recently developed image warping techniques for perspective-correct view synthesis. Under the assumption that a complete pixel-wise correspondence is available, it is possible to predict a broad range of views.
Reference: [7] <author> G. Wolberg, </author> <title> Digital Image Warping. </title> <address> Los Alami-tos, CA: </address> <publisher> IEEE Computer Society Press, </publisher> <year> 1990. </year>
Reference-contexts: Two groups [2, 6] have recently developed image warping techniques for perspective-correct view synthesis. Under the assumption that a complete pixel-wise correspondence is available, it is possible to predict a broad range of views. Several researchers <ref> [1, 7, 8, 9, 10] </ref> have used interpolation to produce new images without establishing the physical validity of the resulting images. <p> Furthermore, we demonstrated that a particular range of views can be generated by linear interpolation of the basis images, if the basis images are first rectified. This result provides a theoretical basis for morphing techniques based on geometric image interpolation <ref> [1, 7, 8, 9, 10] </ref> and provides a simple way of generating new views of a scene. Finally, a scan-line algorithm for interpolating two basis images was described that requires only a small number of user-provided feature correspondences. The application of the method was demonstrated on real images.
Reference: [8] <author> T. Beier and S. Neely, </author> <title> "Feature-based image metamorphosis," </title> <booktitle> in Proc. SIGGRAPH 92, </booktitle> <pages> pp. 35-42, </pages> <year> 1992. </year>
Reference-contexts: Two groups [2, 6] have recently developed image warping techniques for perspective-correct view synthesis. Under the assumption that a complete pixel-wise correspondence is available, it is possible to predict a broad range of views. Several researchers <ref> [1, 7, 8, 9, 10] </ref> have used interpolation to produce new images without establishing the physical validity of the resulting images. <p> Furthermore, we demonstrated that a particular range of views can be generated by linear interpolation of the basis images, if the basis images are first rectified. This result provides a theoretical basis for morphing techniques based on geometric image interpolation <ref> [1, 7, 8, 9, 10] </ref> and provides a simple way of generating new views of a scene. Finally, a scan-line algorithm for interpolating two basis images was described that requires only a small number of user-provided feature correspondences. The application of the method was demonstrated on real images.
Reference: [9] <author> T. Poggio and R. Brunelli, </author> <title> "A novel approach to graphics," </title> <journal> A.I. </journal> <volume> Memo No. 1354, </volume> <publisher> M.I.T., </publisher> <address> Boston, MA, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: Two groups [2, 6] have recently developed image warping techniques for perspective-correct view synthesis. Under the assumption that a complete pixel-wise correspondence is available, it is possible to predict a broad range of views. Several researchers <ref> [1, 7, 8, 9, 10] </ref> have used interpolation to produce new images without establishing the physical validity of the resulting images. <p> We chose to use dynamic programming techniques because they make strong use of monotonic-ity and are relatively simple to implement. It should be noted, however, that our approach is not dependent on a particular stereo matching algorithm; other researchers <ref> [1, 9, 10] </ref> have had success with different stereo algorithms for view synthesis. The complete algorithm is as follows: 1. Obtain either 4 or more feature correspondences or relative camera positions from the user 2. <p> Furthermore, we demonstrated that a particular range of views can be generated by linear interpolation of the basis images, if the basis images are first rectified. This result provides a theoretical basis for morphing techniques based on geometric image interpolation <ref> [1, 7, 8, 9, 10] </ref> and provides a simple way of generating new views of a scene. Finally, a scan-line algorithm for interpolating two basis images was described that requires only a small number of user-provided feature correspondences. The application of the method was demonstrated on real images.
Reference: [10] <author> D. Beymer, A. Shashua, and T. Poggio, </author> <title> "Example based image analysis and synthesis," </title> <journal> A.I. </journal> <volume> Memo No. 1431, </volume> <publisher> M.I.T., </publisher> <address> Boston, MA, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: Two groups [2, 6] have recently developed image warping techniques for perspective-correct view synthesis. Under the assumption that a complete pixel-wise correspondence is available, it is possible to predict a broad range of views. Several researchers <ref> [1, 7, 8, 9, 10] </ref> have used interpolation to produce new images without establishing the physical validity of the resulting images. <p> We chose to use dynamic programming techniques because they make strong use of monotonic-ity and are relatively simple to implement. It should be noted, however, that our approach is not dependent on a particular stereo matching algorithm; other researchers <ref> [1, 9, 10] </ref> have had success with different stereo algorithms for view synthesis. The complete algorithm is as follows: 1. Obtain either 4 or more feature correspondences or relative camera positions from the user 2. <p> Furthermore, we demonstrated that a particular range of views can be generated by linear interpolation of the basis images, if the basis images are first rectified. This result provides a theoretical basis for morphing techniques based on geometric image interpolation <ref> [1, 7, 8, 9, 10] </ref> and provides a simple way of generating new views of a scene. Finally, a scan-line algorithm for interpolating two basis images was described that requires only a small number of user-provided feature correspondences. The application of the method was demonstrated on real images.
Reference: [11] <author> J. J. Koenderink and A. J. van Doorn, </author> <title> "Affine structure from motion," </title> <journal> Opt. Soc. Am. A, </journal> <volume> vol. 8, </volume> <pages> pp. 377-385, </pages> <year> 1991. </year>
Reference-contexts: The image plane unit normal, also known as the optical axis or direction of gaze of V is denoted Z. Under strict orthographic projection, X and Y are constrained to be orthonormal, whereas in a general affine model <ref> [11] </ref> X and Y may be any two linearly independent vectors. Finally, an image is the projection of the visible scene into the view. An image can be represented as an array of pixels I or a matrix of feature positions I.
Reference: [12] <author> H. H. Baker and T. O. Binford, </author> <title> "Depth from edge and intensity based stereo," </title> <booktitle> in Proc. 7th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 631-636, </pages> <year> 1981. </year>
Reference-contexts: This constraint reduces the search for correspondences to a 1-D search along epipolar lines. Further constraints have been used to help reduce the search within epipolar lines by making assumptions about the structure of the scene. One example of such a constraint is monotonic-ity <ref> [12, 13] </ref>, which requires that the relative ordering of points along epipolar lines be preserved. Let I 1 and I 2 be two images of a scene taken from views V 1 and V 2 , respectively.
Reference: [13] <author> Y. Ohta and T. Kanade, </author> <title> "Stereo by intra- and inter-scanline search using dynamic programming," </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 7, no. 2, </volume> <pages> pp. 139-154, </pages> <year> 1985. </year>
Reference-contexts: This constraint reduces the search for correspondences to a 1-D search along epipolar lines. Further constraints have been used to help reduce the search within epipolar lines by making assumptions about the structure of the scene. One example of such a constraint is monotonic-ity <ref> [12, 13] </ref>, which requires that the relative ordering of points along epipolar lines be preserved. Let I 1 and I 2 be two images of a scene taken from views V 1 and V 2 , respectively. <p> Consequently, our approach is to find the optimal monotonic warp ^ W of ^ I 1 that minimizes j ^ W ( ^ I 1 ) ^ I 2 j. We employ a stereo correspondence algorithm adapted from <ref> [13] </ref> to find W that uses both inter-scanline and intra-scanline constraints. We chose to use dynamic programming techniques because they make strong use of monotonic-ity and are relatively simple to implement.
Reference: [14] <author> T. Poggio, V. Torre, and C. Koch, </author> <title> "Computational vision and regularization theory," </title> <journal> Nature, </journal> <volume> vol. 317, </volume> <pages> pp. 314-319, </pages> <year> 1985. </year>
Reference-contexts: Although it is possible to determine which uniform regions correspond in different images, it is impossible to determine correspondences within these regions. As a result, additional smoothness assumptions are needed to solve problems such as optical flow and stereo vision <ref> [14] </ref>. In contrast, we show in this section that view synthesis does not suffer from the aperture problem and is therefore inherently well-posed.
Reference: [15] <author> S. M. Seitz and C. R. Dyer, </author> <title> "Complete structure from four point correspondences," </title> <booktitle> in Proc. Intl. Conf. on Computer Vision, </booktitle> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: In other words, a point (x 1 ; y) in the first image will correspond to point (x 2 ; y) in the second. The technique is a variant of the rectification procedure described in <ref> [15] </ref>. We assume that a set of at least four reference image features is provided and that their positions in each image are known. <p> Define B i as B i = A 1 i d i 1 = 1 B 2 and 0 T third column of 0 i . In <ref> [15] </ref> it is shown that the epipolar lines in image I i make an angle of i = arctan ( y i x i ) with the horizontal axis.

References-found: 15

