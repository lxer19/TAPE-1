URL: http://www.isle.org/~langley/papers/review.fs94.ps
Refering-URL: http://www.isle.org/publications.html
Root-URL: 
Email: (Langley@flamingo.stanford.edu)  
Title: Selection of Relevant Features in Machine Learning  
Author: Pat Langley 
Address: 2451 High Street, Palo Alto, CA 94301  
Affiliation: Institute for the Study of Learning and Expertise  
Note: From Proceedings of the AAAI Fall Symposium on Relevance (1994). New Orleans, LA: AAAI Press.  
Abstract: In this paper, we review the problem of selecting relevant features for use in machine learning. We describe this problem in terms of heuristic search through a space of feature sets, and we identify four dimensions along which approaches to the problem can vary. We consider recent work on feature selection in terms of this framework, then close with some challenges for future work in the area. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. W., & Bankert, R. L. </author> <year> (1994). </year> <title> Feature selection for case-based classification of cloud types. </title> <booktitle> Working Notes of the AAAI94 Workshop on Case-Based Reasoning (pp. </booktitle> <pages> 106-112). </pages> <address> Seattle, WA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Almuallim, H., & Dietterich, T. G. </author> <year> (1991). </year> <title> Learning with many irrelevant features. </title> <booktitle> Proceedings of the Ninth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 547-552). </pages> <address> San Jose, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Cardie, C. </author> <year> (1993). </year> <title> Using decision trees to improve case-based learning. </title> <booktitle> Proceedings of the Tenth International Conference on Machine Learning (pp. </booktitle> <pages> 25-32). </pages> <address> Amherst, MA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Caruana, R. A., & Freitag, D. </author> <year> (1994). </year> <title> Greedy attribute selection. </title> <booktitle> Proceedings of the Eleventh International Conference on Machine Learning (pp. </booktitle> <pages> 28-36). </pages> <address> New Brunswick, NJ: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Devijver, P. A., & Kittler, J. </author> <year> (1982). </year> <title> Pattern recognition: A statistical approach. </title> <address> New York: </address> <publisher> Prentice-Hall. </publisher>
Reference-contexts: Feature Selection in Machine Learning 3 3. Recent Work on Feature Selection The problem of feature selection has long been an active research topic within statistics and pattern recognition <ref> (e.g., Devijver & Kittler, 1982) </ref>, but most work in this area has dealt with linear regression. In the past few years, feature selection has received considerable attention from machine learning researchers interested in improving the performance of their algorithms.
Reference: <author> Doak, J. </author> <year> (1992). </year> <title> An evaluation of feature-selection methods and their application to computer security (Technical Report CSE-92-18). </title> <institution> Davis: University of California, Department of Computer Science. </institution>
Reference: <author> John, G. H., Kohavi, R., & Pfleger, K. </author> <year> (1994). </year> <title> Irrelevant features and the subset selection problem. </title> <booktitle> Proceedings of the Eleventh International Conference on Machine Learning (pp. </booktitle> <pages> 121-129). </pages> <address> New Brunswick, NJ: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kira, K., & Rendell, L. </author> <year> (1992). </year> <title> A practical approach to feature selection. </title> <booktitle> Proceedings of the Ninth International Conference on Machine Learning (pp. </booktitle> <pages> 249-256). </pages> <address> Aberdeen, Scotland: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kononenko, I. </author> <year> (1994). </year> <title> Estimating attributes: Analysis and extensions of Relief. </title> <booktitle> Proceedings of the 1994 European Conference on Machine Learning. </booktitle>
Reference: <author> Kubat, M., Flotzinger, D., & Pfurtscheller, G. </author> <year> (1993). </year> <title> Discovering patterns in EEG signals: Comparative study of a few methods. </title> <booktitle> Proceedings of the 1993 Eu-ropean Conference on Machine Learning (pp. </booktitle> <pages> 367-371). </pages> <address> Vienna: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Langley, P., & Iba, W. </author> <year> (1993. </year> <title> Average-case analysis of a nearest neighbor algorithm. </title> <booktitle> Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 889-894). </pages> <address> Chambery, France. </address>
Reference: <author> Langley, P., & Sage, S. </author> <year> (1994a). </year> <title> Oblivious decision trees and abstract cases. </title> <booktitle> Working Notes of the AAAI-94 Workshop on Case-Based Reasoning (pp. </booktitle> <pages> 113-117). </pages> <address> Seattle, WA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Langley, P., & Sage, S. </author> <year> (1994b). </year> <title> Induction of selective Bayesian classifiers. </title> <booktitle> Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (pp. </booktitle> <pages> 399-406). </pages> <address> Seattle, WA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Langley, P., & Sage, S. </author> <title> (in press). Scaling to domains with many irrelevant features. </title> <editor> In R. Greiner (Ed.), </editor> <booktitle> Computational learning theory and natural learning systems (Vol. 4). </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Littlestone, N. </author> <year> (1987). </year> <title> Learning quickly when irrelevant attributes abound: A new linear threshold algorithm. </title> <note> Machine Learning , 2 , 285-318. </note>
Reference: <author> Moore, A. W., & Lee, M. S. </author> <year> (1994). </year> <title> Efficient algorithms for minimizing cross validation error. </title> <booktitle> Proceedings of the Eleventh International Conference on Machine Learning (pp. </booktitle> <pages> 190-198). </pages> <address> New Brunswick, NJ: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Pazzani, M. J., & Sarrett, W. </author> <year> (1992). </year> <title> A framework for the average case analysis of conjunctive learning algorithms. </title> <booktitle> Machine Learning, </booktitle> <pages> 9 , 349-372. </pages>
Reference: <author> Quinlan, J. R. </author> <year> (1993). </year> <title> C4.5: Programs for machine learning . San Mateo, </title> <address> CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Schlimmer, J. C. </author> <year> (1987). </year> <title> Efficiently inducing determinations: A complete and efficient search algorithm that uses optimal pruning. </title> <booktitle> Proceedings of the Tenth International Conference on Machine Learning (pp. </booktitle> <pages> 284-290). </pages> <address> Amherst, MA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Skalak, D. B. </author> <year> (1994). </year> <title> Prototype and feature selection by sampling and random mutation hill-climbing algorithms. </title> <booktitle> Proceedings of the Eleventh International Conference on Machine Learning (pp. </booktitle> <pages> 293-301). </pages> <address> New Brunswick, NJ: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Townsend-Weber, T., & Kibler, D. </author> <year> (1994). </year> <title> Instance-based prediction of continuous values. </title> <booktitle> Working Notes of the AAAI94 Workshop on Case-Based Reasoning (pp. </booktitle> <pages> 30-35). </pages> <address> Seattle, WA: </address> <publisher> AAAI Press. </publisher>
References-found: 21

