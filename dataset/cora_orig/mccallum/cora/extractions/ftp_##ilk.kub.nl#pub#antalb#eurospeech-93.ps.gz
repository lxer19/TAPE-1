URL: ftp://ilk.kub.nl/pub/antalb/eurospeech-93.ps.gz
Refering-URL: http://ilk.kub.nl/~antalb/pubs-time.html
Root-URL: 
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Aha, D., D. Kibler, & M. </author> <title> Albert (1991). Instance-Based Learning Algorithms. </title> <booktitle> Machine Learning 6, </booktitle> <pages> 37-66. </pages>
Reference-contexts: Furthermore, language-specificity of a grapheme-to-phoneme model tends to be incompatible with reusability of the developed implementation, i.e., for each language, a specific set of rules and principles has to be found in order to successfully run the model. MITalk <ref> [1] </ref> is a classic example of such a model for English; for Dutch, Morpa-cum-Morphon [6] can be considered state-of-the-art. <p> Secondly, we present a comparison of the performance of our model on corpora of English, Dutch and French word-pronunciation pairs. TabTalk Van den Bosch & Daelemans [2] present two machine learning techniques, Instance-Based Learning <ref> [1] </ref> and Table Lookup with defaults which they train on grapheme-to-phoneme conversion. Both techniques take as their basis a large corpus of word-pronunciation pairs, store (parts of) this corpus in a memory base and apply a certain retrieval mechanism in order to categorise unseen test cases as correctly as possible. <p> The data in Figure 2 are the IG values for the complete English CELEX corpus described in the next section. the focus grapheme, computed for the complete English CELEX corpus. IBL <ref> [1] </ref> is a framework and methodology for incremental supervised machine learning. Algorithms developed within this framework are inspired by statistical pattern recognition, especially the rich research tradition on the nearest-neighbour decision rule (see e.g.
Reference: [2] <author> Bosch, A. van den & W. </author> <title> Daelemans (1993). Data-oriented methods for grapheme-to-phoneme conversion. </title> <booktitle> Proceedings of European Chapter of ACL, Utrecht, </booktitle> <pages> 45-53. </pages>
Reference-contexts: For the latter language, we compare our results with those of Morpa-cum-Morphon [6] on the same test material. Secondly, we present a comparison of the performance of our model on corpora of English, Dutch and French word-pronunciation pairs. TabTalk Van den Bosch & Daelemans <ref> [2] </ref> present two machine learning techniques, Instance-Based Learning [1] and Table Lookup with defaults which they train on grapheme-to-phoneme conversion. <p> In those cases, the first grapheme of that cluster is mapped to the phoneme, and the other graphemes are mapped to phonemic nulls. In Van den Bosch & Daelemans <ref> [2] </ref>, we showed that both the lookup table (augmented with a default table containing the most frequently occurring phonemic mapping) and the IBL technique (augmented with IG weighing) performed better in terms of generalisation performance than the connectionist NetTalk architecture [8] applied to Dutch data.
Reference: [3] <author> Content, A., P. Mousty, & M. </author> <title> Radeau (1991). Brulex: une base de donnees lexicales informatisee pour le fran~cais ecrit et parle. </title> <journal> L'Annee Psychologique, </journal> <volume> 90, </volume> <pages> 551-566. </pages>
Reference-contexts: We applied the Table Lookup approach to corpora of equal size (20,000 words) of English (the NetTalk corpus as used in [8]), French (a subset of the Brulex data base <ref> [3] </ref>) and Dutch (a subset of the corpus used in Experiment 1). After construction, the English table contains 35,000 patterns, the Dutch 27,000 and the French 18,000, reflecting differences in deepness of orthography between the three languages.
Reference: [4] <author> Daelemans, W. & A. van den Bosch (1992). </author> <title> Generalization performance of backpropagation learning on a syllabification task. </title> <editor> In M. Drossaers & A. Nij-holt (Eds.), </editor> <booktitle> Proceedings of the 3rd Twente Workshop on Language Technology. Enschede: Univer-siteit Twente, </booktitle> <pages> 27-37. </pages>
Reference-contexts: If it is not in memory, all memory items are sorted according to the similarity of their pattern to the test pattern. The (most frequent) phonemic mapping of the highest ranking exemplar is then predicted as the category of the test pattern. Daelemans & Van den Bosch <ref> [4] </ref> extended the basic IBL algorithm by introducing Information Gain as a means to assigning different weights to different grapheme positions when computing the similarity between training and test patterns (instead of Euclidean distance).
Reference: [5] <author> Devijver, P.A. & J. </author> <title> Kittler (1982). Pattern recognition. A statistical approach. </title> <publisher> London: Prentice-Hall. </publisher>
Reference-contexts: IBL [1] is a framework and methodology for incremental supervised machine learning. Algorithms developed within this framework are inspired by statistical pattern recognition, especially the rich research tradition on the nearest-neighbour decision rule (see e.g. Devijver & Kittler <ref> [5] </ref> for an overview) and can be categorised in the class of Similarity-Based Reasoning (SBR) techniques.
Reference: [6] <author> Nunn, A. & V.J. van Heuven (1993). MOR-PHON, </author> <title> lexicon-based text-to-phoneme conversion and phonological rules. </title> <editor> In V.J. van Heuven & L.C.W. Pols (Eds.), </editor> <title> Analysis and synthesis of speech; strategic research towards high-quality text-to-speech generation. </title> <publisher> Berlin: Mouton de Gruyter. </publisher>
Reference-contexts: MITalk [1] is a classic example of such a model for English; for Dutch, Morpa-cum-Morphon <ref> [6] </ref> can be considered state-of-the-art. In this paper, we present a model the construction of which is simple and does not involve linguistic engineering, nor the inclusion of language-specific knowledge, viz. a combination of Trie Search and Similarity-Based Reasoning. <p> After a description of the two machine learning techniques, we present performance results of our model for English and for Dutch. For the latter language, we compare our results with those of Morpa-cum-Morphon <ref> [6] </ref> on the same test material. Secondly, we present a comparison of the performance of our model on corpora of English, Dutch and French word-pronunciation pairs. <p> Testing on data proposed by Nunn & Van Heuven <ref> [6] </ref>, we also investigated how the performance results of the simple Table Lookup model would relate to the results of the knowledge-based Morpa-cum-Morphon system reported in [6]. The test data consisted of 1,971 words from newspaper text, compounds, neologisms and low-frequency words. <p> Testing on data proposed by Nunn & Van Heuven <ref> [6] </ref>, we also investigated how the performance results of the simple Table Lookup model would relate to the results of the knowledge-based Morpa-cum-Morphon system reported in [6]. The test data consisted of 1,971 words from newspaper text, compounds, neologisms and low-frequency words. Results show that the Table Lookup model scores significantly higher.
Reference: [7] <author> Quinlan, J.R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning. </journal> <volume> 1, </volume> <pages> 81-206. </pages>
Reference-contexts: The order in which the context graphemes are added to the trie search is not randomly determined, but is computed using the concept of Information Gain (IG). This ordering method is used in a similar way in ID3-learning <ref> [7] </ref>. The main difference with ID3-learning is the fact that our model computes the expansion ordering only once for the complete trie, whereas in ID3-learning the ordering is computed at every node.
Reference: [8] <author> Sejnowski, T.J. & C.R. </author> <title> Rosenberg (1987), Parallel networks that learn to pronounce English text. </title> <journal> Complex Systems, </journal> <volume> 1, </volume> <pages> 145-168. </pages>
Reference-contexts: In Van den Bosch & Daelemans [2], we showed that both the lookup table (augmented with a default table containing the most frequently occurring phonemic mapping) and the IBL technique (augmented with IG weighing) performed better in terms of generalisation performance than the connectionist NetTalk architecture <ref> [8] </ref> applied to Dutch data. Testing on data proposed by Nunn & Van Heuven [6], we also investigated how the performance results of the simple Table Lookup model would relate to the results of the knowledge-based Morpa-cum-Morphon system reported in [6]. <p> When corpus sizes are comparable, application of the technique renders models of which the differences can reveal interesting differences between the languages of the two corpora. We applied the Table Lookup approach to corpora of equal size (20,000 words) of English (the NetTalk corpus as used in <ref> [8] </ref>), French (a subset of the Brulex data base [3]) and Dutch (a subset of the corpus used in Experiment 1). After construction, the English table contains 35,000 patterns, the Dutch 27,000 and the French 18,000, reflecting differences in deepness of orthography between the three languages.
References-found: 8

