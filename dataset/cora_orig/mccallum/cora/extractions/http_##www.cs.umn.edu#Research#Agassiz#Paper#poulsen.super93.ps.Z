URL: http://www.cs.umn.edu/Research/Agassiz/Paper/poulsen.super93.ps.Z
Refering-URL: http://www.cs.umn.edu/Research/Agassiz/agassiz_pubs.html
Root-URL: http://www.cs.umn.edu
Title: Execution-Driven Tools for Parallel Simulation of Parallel Architectures and Applications  
Author: David K. Poulsen and Pen-Chung Yew 
Address: Urbana, IL 61801  
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Stunkel, C. B., Janssens, B., and Fuchs, W. K., </author> <title> "Address Tracing for Parallel Machines", </title> <booktitle> IEEE Computer, </booktitle> <month> January </month> <year> 1991, </year> <pages> pp. 31-38. </pages>
Reference-contexts: The resulting instrumented codes execute on a host machine using actual input data. Execution causes the generation of events reflecting the behavior of the original applications executing on a hypothetical modeled machine. Other event generation techniques include hardware monitoring, interrupt-based methods, pure simulation, and microcode-based methods <ref> [1] </ref>; these techniques can be used to study multiprogramming and operating system behavior in addition to application behavior. This paper concerns itself with execution-driven event generation techniques based on application code instrumentation, and tools resulting from the use of these techniques. <p> Other CPS tools have been used to measure program parallelism [7] and to perform dynamic dependence analysis [8]. ETG tools instrument serial codes for trace generation on uniprocessor hosts <ref> [1] </ref>, or parallel codes for trace generation on parallel hosts [9, 10]. Examples of EDS systems include Tango [2], Proteus [11], and PEET [12]. These systems use serial or parallel codes to drive simulations that execute on uniprocessor hosts.
Reference: 2. <author> Davis, H., Goldschmidt, S., and Hennessy, J., </author> <title> "Multiprocessor Simulation and Tracing Using Tango", </title> <booktitle> Proceedings of ICPP 1991, </booktitle> <pages> pp. </pages> <month> II-99-106. </month>
Reference-contexts: This feedback can be used to alter the ordering, timing, or latency of subsequently-generated events. In a simulated parallel code, the path of execution, and ordering and latency of events, may depend on the ordering and timing of preceding events <ref> [2] </ref>. In TDS, these dependences cannot be taken into account, limiting the accuracy of such simulations [3, 4]. EDS correctly models processor interactions. <p> Other CPS tools have been used to measure program parallelism [7] and to perform dynamic dependence analysis [8]. ETG tools instrument serial codes for trace generation on uniprocessor hosts [1], or parallel codes for trace generation on parallel hosts [9, 10]. Examples of EDS systems include Tango <ref> [2] </ref>, Proteus [11], and PEET [12]. These systems use serial or parallel codes to drive simulations that execute on uniprocessor hosts. Simulators exist that perform EDS for parallel codes on parallel hosts, but only for particular types of host architectures or modeled system architectures [13].
Reference: 3. <author> Bitar, P., </author> <title> "A Critique of Trace-Driven Simulation for Shared-Memory Multiprocessors", </title> <editor> in Dubois, M., and Thakkar, S. (eds.), </editor> <booktitle> 16th ISCA Workshop on Cache and Interconnect Architectures in Multiprocessors, </booktitle> <address> Boston: </address> <publisher> Kluwer Academic, </publisher> <year> 1989. </year>
Reference-contexts: In a simulated parallel code, the path of execution, and ordering and latency of events, may depend on the ordering and timing of preceding events [2]. In TDS, these dependences cannot be taken into account, limiting the accuracy of such simulations <ref> [3, 4] </ref>. EDS correctly models processor interactions. Another limitation of TDS is that traces, particularly those generated by non-execution-driven means, are biased to the particular system being traced, so they cannot be used arbitrarily in simulations of dissimilar systems (e.g., with different numbers of processors).
Reference: 4. <author> Goldschmidt, S. R., and Hennessy, J. L., </author> <title> "The Accuracy of Trace-Driven Simulations of Multiprocessors", </title> <booktitle> Proceedings of SIGMETRICS 1993, </booktitle> <pages> pp. 146-157. </pages>
Reference-contexts: In a simulated parallel code, the path of execution, and ordering and latency of events, may depend on the ordering and timing of preceding events [2]. In TDS, these dependences cannot be taken into account, limiting the accuracy of such simulations <ref> [3, 4] </ref>. EDS correctly models processor interactions. Another limitation of TDS is that traces, particularly those generated by non-execution-driven means, are biased to the particular system being traced, so they cannot be used arbitrarily in simulations of dissimilar systems (e.g., with different numbers of processors). <p> TDS uses near-optimal processor scheduling, performed at ETG time, whereas EDS uses self-scheduling at execution time. While the difference in cache hit ratio is negligible, and the difference in speedup is only 1.3%, TRFD-p does not use any constructs that typically cause larger accuracy discrepancies <ref> [4] </ref>. The execution time required to generate events for EDS is the same as that required for ETG (line 1 in Figure 8) since the same instrumented code is executed in both cases.
Reference: 5. <author> Poulsen, D. K., and Yew, P.-C., </author> <title> "Execution-Driven Tools for Parallel Simulation of Parallel Architectures and Applications", </title> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <note> CSRD Report No. 1280, </note> <month> September </month> <year> 1993. </year>
Reference-contexts: The last section of the paper presents experimental results that illustrate the functionality and usefulness of EPG-sim. A more extensive discussion of the systems, capabilities, and issues described in this paper can be found in <ref> [5] </ref>. 2. Background The design of EPG-sim addresses the need for an integrated set of tools that combines the best features of existing execution-driven simulation and tracing systems. The following paragraphs provide a brief survey of these systems and discuss the ways in which their capabilities are combined in EPG-sim.
Reference: 6. <author> Chen, D.-K., Su, H.-M., and Yew, P.-C., </author> <title> "The Impact of Synchronization and Granularity on Parallel Systems", </title> <booktitle> Proceedings of ISCA 1990, </booktitle> <pages> pp. 239-249. </pages>
Reference-contexts: The following paragraphs provide a brief survey of these systems and discuss the ways in which their capabilities are combined in EPG-sim. Many execution-driven simulation and tracing systems have been described in the literature. MaxPar <ref> [6] </ref> is a CPS tool that measures the potential performance, parallelism, and behavior of optimistically parallelized codes given various architectural parameters. Other CPS tools have been used to measure program parallelism [7] and to perform dynamic dependence analysis [8]. <p> The processor scheduler is implemented as a runtime library routine that can be used to implement arbitrary scheduling policies. Scheduling strategies include round-robin, earliest available processor, and near-optimal <ref> [6] </ref>, which attempts to maximize processor utilization. 3.2 Critical path simulation (CPS) CPS in EPG-sim uses instrumentation to measure the minimum parallel execution time of optimistically parallelized codes, given various architectural and timing parameters. <p> Variations on the techniques described here are also used to implement ETG and EDS, as discussed in the following sections. The techniques used are based on those used in MaxPar <ref> [6] </ref>. Minimum parallel execution time is measured by instrumenting to compute the earliest time at which each task could execute, given complete dynamic, interprocedural knowledge of data and control dependences, task grain size and associated serialization constraints, processor scheduling, resource constraints, and other parameters. <p> The maximum speedup (or inherent parallelism <ref> [6] </ref>) of each code, compared to serial execution time as calculated during CPS, is also given, followed by the speedup for 512 processors using near-optimal processor scheduling. The unconstrained processor speedups represent the maximum parallelism of the codes.
Reference: 7. <author> Larus, J., </author> <title> "Parallelism in Numeric and Symbolic Programs", </title> <booktitle> Third Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: Many execution-driven simulation and tracing systems have been described in the literature. MaxPar [6] is a CPS tool that measures the potential performance, parallelism, and behavior of optimistically parallelized codes given various architectural parameters. Other CPS tools have been used to measure program parallelism <ref> [7] </ref> and to perform dynamic dependence analysis [8]. ETG tools instrument serial codes for trace generation on uniprocessor hosts [1], or parallel codes for trace generation on parallel hosts [9, 10]. Examples of EDS systems include Tango [2], Proteus [11], and PEET [12].
Reference: 8. <author> Petersen, P., and Padua, D., </author> <title> "Dynamic Dependence Analysis: A Novel Method for Data Dependence Evaluation", </title> <booktitle> Presented at the 5th Annual Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> New Haven, CT, </address> <month> August 3-5, </month> <year> 1992. </year>
Reference-contexts: MaxPar [6] is a CPS tool that measures the potential performance, parallelism, and behavior of optimistically parallelized codes given various architectural parameters. Other CPS tools have been used to measure program parallelism [7] and to perform dynamic dependence analysis <ref> [8] </ref>. ETG tools instrument serial codes for trace generation on uniprocessor hosts [1], or parallel codes for trace generation on parallel hosts [9, 10]. Examples of EDS systems include Tango [2], Proteus [11], and PEET [12].
Reference: 9. <author> Eggers, S., Keppel, D., Koldinger, E., and Levy, H., </author> <title> "Techniques for Efficient Inline Tracing on a Shared-Memory Multiprocessor", </title> <booktitle> Proceedings of SIGMETRICS 1990, </booktitle> <pages> pp. 37-47. </pages>
Reference-contexts: Other CPS tools have been used to measure program parallelism [7] and to perform dynamic dependence analysis [8]. ETG tools instrument serial codes for trace generation on uniprocessor hosts [1], or parallel codes for trace generation on parallel hosts <ref> [9, 10] </ref>. Examples of EDS systems include Tango [2], Proteus [11], and PEET [12]. These systems use serial or parallel codes to drive simulations that execute on uniprocessor hosts.
Reference: 10. <author> Stunkel, C. B., and Fuchs, W. K., "TRAPEDS: </author> <title> Producing Traces for Multicomputers via Execution-Driven Simulation", </title> <booktitle> Proceedings of SIGMETRICS 1989, </booktitle> <pages> pp. 70-78. </pages>
Reference-contexts: Other CPS tools have been used to measure program parallelism [7] and to perform dynamic dependence analysis [8]. ETG tools instrument serial codes for trace generation on uniprocessor hosts [1], or parallel codes for trace generation on parallel hosts <ref> [9, 10] </ref>. Examples of EDS systems include Tango [2], Proteus [11], and PEET [12]. These systems use serial or parallel codes to drive simulations that execute on uniprocessor hosts.
Reference: 11. <author> Brewer, E., Dellarocas, C., Colbrook, A., and Weihl, W., "Proteus: </author> <title> A High Performance Parallel Architecture Simulator", </title> <institution> Laboratory for Computer Science, MIT, MIT/LCS/TR-516, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: Other CPS tools have been used to measure program parallelism [7] and to perform dynamic dependence analysis [8]. ETG tools instrument serial codes for trace generation on uniprocessor hosts [1], or parallel codes for trace generation on parallel hosts [9, 10]. Examples of EDS systems include Tango [2], Proteus <ref> [11] </ref>, and PEET [12]. These systems use serial or parallel codes to drive simulations that execute on uniprocessor hosts. Simulators exist that perform EDS for parallel codes on parallel hosts, but only for particular types of host architectures or modeled system architectures [13].
Reference: 12. <author> Grunwald, D., Nutt, G. J., Sloane, A. M., Wagner, D., and Zorn, B., </author> <title> "A Testbed for Studying Parallel Programs and Parallel Execution Architectures", </title> <type> Technical Report, </type> <institution> Department of Computer Science, University of Colorado, Boulder, </institution> <month> April 28, </month> <year> 1992. </year>
Reference-contexts: ETG tools instrument serial codes for trace generation on uniprocessor hosts [1], or parallel codes for trace generation on parallel hosts [9, 10]. Examples of EDS systems include Tango [2], Proteus [11], and PEET <ref> [12] </ref>. These systems use serial or parallel codes to drive simulations that execute on uniprocessor hosts. Simulators exist that perform EDS for parallel codes on parallel hosts, but only for particular types of host architectures or modeled system architectures [13].
Reference: 13. <author> Reinhardt, S. K., Hill, M. D., Larus, J. R., Lebeck, A. R., Lewis, J. C., and Wood, D. A., </author> <title> "The Wisconsin Wind Tunnel: Virtual Prototyping of Parallel Computers", </title> <booktitle> Proceedings of SIGMETRICS 1993, </booktitle> <pages> pp. 48-60. </pages>
Reference-contexts: These systems use serial or parallel codes to drive simulations that execute on uniprocessor hosts. Simulators exist that perform EDS for parallel codes on parallel hosts, but only for particular types of host architectures or modeled system architectures <ref> [13] </ref>. EPG-sim allows CPS, ETG, and EDS to be driven by serial, optimistically parallelized, or parallel codes. This can be done because of the extension of CPS instrumentation techniques to ETG and EDS. CPS executes on uniprocessor hosts and measures optimistically parallelized codes.
Reference: 14. <author> Polychronopoulos, C. D., Girkar, M. B., Haghighat, M. R., Lee, C. L., Leung, B. P., and Schouten, D. A., </author> <title> "Parafrase-2: An Environment for Parallelizing, Partitioning, Synchronizing and Scheduling Programs on Multiprocessors", </title> <booktitle> Proceedings of ICPP 1989, </booktitle> <pages> pp. </pages> <month> II-39-48. </month>
Reference-contexts: The following sections describe the various components of EPG-sim in more detail. 3.1 Source-level instrumentation EPG-sim uses source-level instrumentation to generate events for CPS, ETG, and EDS. Source-level event generators are implemented by instrumenting application codes using tools based on the Parafrase-2 compiler <ref> [14] </ref>, CHIEF simulation tools Fortran-77 Cedar Fortran CARL component descriptions EPG Discrete-event processor architectural source code simulation component parameters instrumentation PSPP descriptions tools preprocessor Fortran-77 C or C++ compiler compiler simulation kernel library runtime library lightweight thread library linker linker CPS ETG EDS developed at CSRD.
Reference: 15. <author> Hoeflinger, J., </author> <title> "Cedar Fortran Programmer's Handbook", </title> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <note> CSRD Report No. 1157, </note> <month> October </month> <year> 1991. </year>
Reference-contexts: Parafrase-2 supports Fortran-77 and Cedar Fortran <ref> [15] </ref>, allowing both serial and parallel codes to be instrumented. The EPG (Execution-driven Program Generation) source code instrumentation tools are implemented as a set of passes within Parafrase-2. These tools perform instrumentation and constitute the front-end for EPG-sim.
Reference: 16. <author> Bruner, J., Cheong, H., Veidenbaum, A., and Yew, P.-C., </author> <title> "CHIEF: A Parallel Simulation Environment for Parallel Systems", </title> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <note> CSRD Report No. 1050, </note> <month> November </month> <year> 1990. </year>
Reference-contexts: These event generators are coupled with parallel discrete-event simulators to implement EDS. The overall structure of an EPG-sim EDS is shown in Figure 1. CHIEF <ref> [16] </ref> parallel discrete-event simulators are used to construct system models and to perform simulation. The CHIEF system is portable, allowing simulations to be executed on a variety of uniprocessor and parallel host machines. A CHIEF simulator consists of a simulation model and a kernel library that drives the simulation.
Reference: 17. <author> Konas, P., and Yew, P.-C., </author> <title> "Synchronous Parallel Discrete-Event Simulation on Shared-Memory Multiprocessors", </title> <booktitle> Presented at the 6th Workshop on Parallel and Distributed Simulations, </booktitle> <address> Newport Beach, CA, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: A CHIEF simulator consists of a simulation model and a kernel library that drives the simulation. Multiple simulation paradigms are supported through the use of different kernel libraries. Paradigms currently supported use standard parallel discrete-event simulation, Chandy-Misra, or Time-Warp techniques <ref> [17] </ref>. Since CHIEF simulation kernels support parallel discrete-event simulation, EDS in EPG-sim is supported on uniprocessor or parallel hosts. Because of the features of the execution-driven event generators used, EDS in EPG-sim can be driven by serial, optimistically parallelized, or parallel codes.
Reference: 18. <author> Beckmann, C. J., "CARL: </author> <title> An Architecture Simulation Language", </title> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <note> CSRD Report No. 1066, </note> <month> December </month> <year> 1990. </year>
Reference-contexts: This results in the ability to perform parallel simulation of optimistically parallelized codes on parallel hosts. CHIEF simulation models are described and constructed using a hardware description language, CARL <ref> [18] </ref>. CARL, an extension of C, supports hierarchical, component-based modeling of parallel systems at a wide range of levels of detail, from high-level abstract models to detailed behavioral register-transfer-level models.
Reference: 19. <author> Berry, M., Chen, D.-K., Koss, P., Kuck, D., Pointer, L., Lo, S., Pang, Y., Roloff, R., Sameh, A., Clementi, E., Chin, S., Schneider, D., Fox, G., Messina, P., Walker, D., Hsiung, C., Schwarzmeier, J., Lue, K., Orszag, S., Seidl, F., Johnson, O., Swanson, G., Goodrum, R., and Martin, J., </author> <title> "The Perfect Club Benchmarks: Effective Performance Evaluation of Supercomputers", </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> Vol. 3, No. 3, </volume> <month> Fall </month> <year> 1989, </year> <pages> pp. 5-40. </pages>
Reference-contexts: The examples are intended only to illustrate the usefulness of EPG-sim; no detailed attempts are made to discuss the architectural significance of the results obtained. CPS for several Perfect Benchmarks (R) codes <ref> [19] </ref> was performed to illustrate the usefulness and efficiency of such simulations. Most experiments were performed with unconstrained numbers of modeled processors (speedup results for fixed numbers of processors and near-optimal processor scheduling are also presented). Local (intratask) memory accesses, and arithmetic and logical operations, took one cycle each.
Reference: 20. <author> Blume, W., and Eigenmann, R., </author> <title> "Performance Analysis of Parallelizing Compilers on the Perfect Benchmarks (R) Programs", </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol. 3, No. 6, </volume> <month> November </month> <year> 1992, </year> <pages> pp. 643-656. </pages>
Reference-contexts: Fixing the number of processors shows that some codes require large numbers of processors in order to exploit this parallelism effectively. Even with a fixed number of processors, CPS is able to identify considerably more parallelism than current parallelizing compilers <ref> [20] </ref>. displaying the number of task instantiations against parallel execution time. The data are sampled in large buckets; each point accumulates a task instantiation count for a range of approximately 20,000 cycles of simulation time.
Reference: 21. <author> Andrews, J. A., and Gallivan, K. A., </author> <title> "Analysis of a Cedar Implementation of TRFD", </title> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <note> CSRD Report No. 1312, </note> <month> August </month> <year> 1993. </year>
Reference-contexts: Experiments were performed with parameters and assumptions as in the previous CPS experiments. Three versions of TRFD were studied: TRFD, the original code; TRFD-p, a functionally equivalent parallel version of TRFD <ref> [21] </ref>; and TRFD-s, a serial version of TRFD-p. code num speed cpu TRFD unc 41.23 1.06 TRFD 512 37.36 65.31 TRFD 128 26.74 17.31 TRFD 32 15.28 5.31 TRFD 16 9.59 3.31 TRFD-s unc 893.33 5.00 TRFD-s 512 185.06 325.00 TRFD-s 128 55.49 85.25 TRFD-s 32 18.34 26.00 TRFD-s 16 9.91
References-found: 21

