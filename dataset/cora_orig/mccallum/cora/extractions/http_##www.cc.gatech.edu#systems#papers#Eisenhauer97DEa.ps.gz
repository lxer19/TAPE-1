URL: http://www.cc.gatech.edu/systems/papers/Eisenhauer97DEa.ps.gz
Refering-URL: http://www.cs.gatech.edu/people/home/beth/
Root-URL: 
Title: DataExchange: High Performance Communications in Distributed Laboratories  
Author: Greg Eisenhauer, Beth Schroeder, Karsten Schwan 
Address: Atlanta, Georgia 30332  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract: Current communications tools and libraries for high performance computing are designed for platforms and applications that exhibit relatively stable computational and communication characteristics. In contrast, the demands of (1) mixed environments in which high performance applications interact with multiple end users, visualizations, storage engines, and I/O engines termed `distributed laboratories' in our research and (2) high performance collaborative computing applications in general, exhibit additional complexities in terms of dynamic behaviors. This paper explores the communication requirements of distributed laboratories, and it describes the DataExchange communication infrastructure supporting their high performance interactive and collaborative applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Scott B. Baden. </author> <title> Software infrastructure for non-uniform scientific computations on parallel processors. </title> <journal> Applied Computing Review, </journal> <month> May </month> <year> 1996. </year> <journal> ACM Special Interest Group on Applied Computing. </journal>
Reference-contexts: Support for the dynamic addition of clients is being included in MPI-2 [8]. Similarly, the San Diego project KeLP <ref> [1] </ref> seeks to improve the manner in which accesses to remote data may be made more efficient by investigation of object-based data bases for data storage that enable computations to migrate toward useful data as well as by investigation of alternative, compiler-based approaches to linking interactive applications [18]. <p> *) data; Limits *lim = (Limits *) cli_data_arg; /* return value controls forwarding */ return !(rec-&gt;level &lt; lim-&gt;lower_bound || rec-&gt;level &gt; lim-&gt;upper_bound); - void main (int argc, char *argv []) - char *group_id = NULL; Limits *cli_dat = malloc (sizeof (Limits)); DExchange de = DExchange_create (); cli_dat.lower_bound = atoi (argv <ref> [1] </ref>); /* lower and upper bounds for */ cli_dat.upper_bound = atoi (argv [2]); /* filtering of atmospheric levels */ DExchange_register_format (de, "x mixing ratio", x_mixing_list); DExchange_register_filter (de, "x mixing ratio", xMixFilter, (void*)cli_dat); if (DExchange_listen (de, 0) == -1) exit (-1); /* open socket, select port */ group_id = setup_comm_group (NULL, "atmosphericModel",
Reference: [2] <author> Ken Calvert, Robin Kravets, and Boby Krupczak. </author> <title> An extensible end-to-end protocol and framework. </title> <booktitle> In Proceedings of the 1995 IFIP International Working Conference on Upper Layers Protocols, Architectures and Applications (ULPAA), </booktitle> <month> December </month> <year> 1995. </year> <month> 19 </month>
Reference-contexts: In addition, it is well known that significant performance improvements may be derived for high performance applications from the runtime configuration of selected application attributes [5], from the online adjustment of their execution environment (e.g., process migration), and from the adaptation of underlying operating system or communication facilities <ref> [2] </ref>. 3 Fig. 1. A sample distributed laboratories application configuration. Taken as a whole, this application scenario has requirements for data management and exchange that go well beyond those of a traditional parallel or distributed application. <p> forwarding */ return !(rec-&gt;level &lt; lim-&gt;lower_bound || rec-&gt;level &gt; lim-&gt;upper_bound); - void main (int argc, char *argv []) - char *group_id = NULL; Limits *cli_dat = malloc (sizeof (Limits)); DExchange de = DExchange_create (); cli_dat.lower_bound = atoi (argv [1]); /* lower and upper bounds for */ cli_dat.upper_bound = atoi (argv <ref> [2] </ref>); /* filtering of atmospheric levels */ DExchange_register_format (de, "x mixing ratio", x_mixing_list); DExchange_register_filter (de, "x mixing ratio", xMixFilter, (void*)cli_dat); if (DExchange_listen (de, 0) == -1) exit (-1); /* open socket, select port */ group_id = setup_comm_group (NULL, "atmosphericModel", "model", 300, DExchange_host_name (de), DExchange_inet_port (de)); while (1) - DExchange_poll_and_handle (de, TRUE);
Reference: [3] <author> D.D.Clark and D.L.Tennenhouse. </author> <title> Architectural considerations for a new generation of protocols. </title> <booktitle> In Proceedings of the SIGCOMM '90 Synposium, </booktitle> <pages> pages 200-208, </pages> <month> Sept </month> <year> 1990. </year>
Reference-contexts: This conversion is another form of the "marshaling problem" that occurs widely in network communication. That marshaling can be a significant overhead is well known <ref> [3] </ref> and tools such as USC [13] attempt to optimize marshaling with compile-time solutions. Unfortunately, the dynamic form of the marshaling problem in DataExchange rules out such static solutions. As described above, the conversion overhead is nil for some data exchanges, but for others, it can be significant.
Reference: [4] <author> Greg Eisenhauer. </author> <title> Portable self-describing binary data streams. </title> <type> Technical Report GIT-CC-94-45, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <year> 1994. </year> <note> (anon. ftp from ftp.cc.gatech.edu). </note>
Reference-contexts: First, DataEx-change is based on PBIO <ref> [4] </ref>, a binary I/O package which provides a variety of mechanisms for handling operation in a diverse environment. Second, DataExchange provides facilities for naming and locating data sources, for dynamically connecting to those data sources and for automatic and configurable redirection of data flow.
Reference: [5] <author> Greg Eisenhauer, Weiming Gu, Karsten Schwan, and Niru Mallavarupu. </author> <title> Falcon toward interactive parallel programs: The on-line steering of a molecular dynamics application. </title> <booktitle> In Proceedings of The Third International Symposium on High-Performance Distributed Computing (HPDC-3). IEEE, IEEE Computer Society, </booktitle> <month> August </month> <year> 1994. </year> <note> Also available as Georgia Institute of Technology Tech Report GIT-CC-94-08. </note>
Reference-contexts: In addition, it is well known that significant performance improvements may be derived for high performance applications from the runtime configuration of selected application attributes <ref> [5] </ref>, from the online adjustment of their execution environment (e.g., process migration), and from the adaptation of underlying operating system or communication facilities [2]. 3 Fig. 1. A sample distributed laboratories application configuration.
Reference: [6] <author> Greg Eisenhauer and Beth Schroeder. </author> <title> The DataExchange library. </title> <type> Technical Report GIT-CC-96-17, </type> <institution> Georgia Institute of Technology, College of Computing, </institution> <address> Atlanta, GA 30332-0280, </address> <year> 1996. </year> <note> (anon. ftp from ftp.cc.gatech.edu). </note>
Reference-contexts: DataExchange currently executes on Sun Solaris, SGI, Linux, RS6000, and Windows NT platforms. A detailed description of the library interface can be found in <ref> [6] </ref>. 4.1 Concepts Before discussing the services provided by DataExchange, we introduce several general concepts, an understanding of which is useful for understanding those services. One enables Dataexchange communication by creating a DataExchange context . The context, specific to a single process, supports a group of related connections.
Reference: [7] <author> Dawson R. Engler. </author> <title> Vcode: a retargetable, extensible, very fast dynamic code generation system. </title> <booktitle> In Proceedings of the SIGPLAN Conference on Programming Language Design and Implementation (PLDI '96), </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: However, employing dynamic code generation for conversions means that DataExchange must bear the cost of generating the code as well as executing it. Because of the format 2 The dynamic code generation described in this paper was implemented using the Vcode package <ref> [7] </ref> developed at MIT by Dawson Engler. 17 Fig. 7.
Reference: [8] <author> Message Passing Interface Forum. </author> <title> MPI-2: Extensions to the Message-Passing Interface. </title> <note> http: //www.mcs.anl.gov/mpi/mpi2/mpi2.html. </note>
Reference-contexts: Support for the dynamic addition of clients is being included in MPI-2 <ref> [8] </ref>.
Reference: [9] <author> MPI Forum. </author> <title> MPI: A Message-Passing Interface. </title> <type> Technical Report CS/E 94-013, </type> <institution> Department of Computer Science, Oregon Graduate Institute, </institution> <month> March 94. </month>
Reference-contexts: 1 Communication Substrates for High Performance Applications Communication tools and libraries for high performance distributed computing have evolved substantially during the last few years, from systems enabling distributed parallel computing such as PVM [10], to industrial standards being actively implemented and improved such as MPI <ref> [9] </ref>, to recent proposals for infrastructures that can facilitate the construction of nationwide, networked supercomputers. Our work contributes to such research by addressing several specific issues that arise whenever diverse networked machines are used in research and development settings or even in production environments, by single or multiple end users.
Reference: [10] <author> Al Geist, Adam Beguelin, Jack Dongarra, Weicheng Jiang, Robert Manchek, and Vaidy Sunderam. </author> <title> PVM 3 Users Guide and Reference manual. </title> <institution> Oak Ridge National Laboratory, Oak Ridge, Tennessee 37831, </institution> <month> May 94. </month>
Reference-contexts: 1 Communication Substrates for High Performance Applications Communication tools and libraries for high performance distributed computing have evolved substantially during the last few years, from systems enabling distributed parallel computing such as PVM <ref> [10] </ref>, to industrial standards being actively implemented and improved such as MPI [9], to recent proposals for infrastructures that can facilitate the construction of nationwide, networked supercomputers. <p> PVM <ref> [10] </ref> allows per-message construction and transfer of information through packing and unpacking of elementary data elements in communication buffers. The application is responsible for ensuring that unpack operations occur in the same order as pack operations. MPI allows the specification and use of user-defined data types in communication.
Reference: [11] <author> Thomas Kindler, Karsten Schwan, Dilma Silva, Mary Trauner, and Fred Alyea. </author> <title> A parallel spectral model for atmospheric transport processes. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 8(9) </volume> <pages> 639-666, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: In particular, consider a large scientific simulation running 2 on a set of computational resources, such as a global climate model being developed for networked parallel machines <ref> [11] </ref>. This global model might interact with more detailed local climate, atmospheric or pollution models in order to enhance the accuracy of both the local and global models. <p> Models like these are important tools for answering scientific questions concerning the stratospheric-tropospheric exchange mechanism or the distribution of species such as chlorofluorocarbons (CFCs), hydrochlorofluorocarbon (HCFCs) and ozone. Details of the model's solution approach, parallelization, and performance results are described in <ref> [11] </ref>. A common scenario in a distributed laboratories environment is to connect one or more visualization/steering/filtering/analysis clients to such a scientific model. We base our example on this scenario. Our simple example consists of three applications: a supplier, a filter/forwarder, and a consumer.
Reference: [12] <author> LabSpace. </author> <title> Creating virtual laboratories for scientists. </title> <publisher> URL:http://www.cs.northeastern.edu/ research/labspace. </publisher>
Reference-contexts: The needs of dynamic environments like distributed laboratories are the focus of recent research efforts on a variety of fronts. For instance, the LabSpace project at Argonne and at Northeastern University <ref> [12] </ref> is trying to create a virtual space in which scientists who are distributed across the nation can meet, talk, plan their research, and run their experiments. Support for the dynamic addition of clients is being included in MPI-2 [8].
Reference: [13] <author> S. W. O'Malley, T. A. Proebsting, and A. B. Montz. </author> <title> Universal stub compiler. </title> <booktitle> In Proceedings of the SIGCOMM '94 Symposium, </booktitle> <month> Aug </month> <year> 1994. </year>
Reference-contexts: This conversion is another form of the "marshaling problem" that occurs widely in network communication. That marshaling can be a significant overhead is well known [3] and tools such as USC <ref> [13] </ref> attempt to optimize marshaling with compile-time solutions. Unfortunately, the dynamic form of the marshaling problem in DataExchange rules out such static solutions. As described above, the conversion overhead is nil for some data exchanges, but for others, it can be significant.
Reference: [14] <author> Scott Pakin, Mario Lauria, and Andre Chien. </author> <title> High performance messaging on workstations: Illinois fast messages (FM) for myrinet. </title> <booktitle> In Proceedings of Supercomputing '95, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: In addition, when application requirements can be stated statically, users should be able to exploit available tools, such as specialized communication libraries (e.g., fast messages <ref> [14] </ref>) or the automatic support for parallelization and inter-task communications offered HPF compilers .
Reference: [15] <author> Beth Schroeder, Greg Eisenhauer, Karsten Schwan, Jeremy Heiner, Vernard Martin, and Jeffrey Vetter. </author> <title> From interactive applications to distributed laboratories. </title> <type> Technical Report GIT-CC-96-23, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <year> 1996. </year> <note> http://www.cc.gatech.edu/tech reports. </note>
Reference: [16] <author> Jon Siegel. </author> <title> CORBA Fundamentals and Programming. </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1996. </year>
Reference-contexts: PVM supports communication with a dynamically forked remote process, but lacks the ability to initiate communication between two unrelated processes. MPI contains no support for initiating communication between unrelated processes, though MPI-2 will provide some primitive communicator location facilities. CORBA <ref> [16] </ref> recognizes the problem of dynamic location and includes a specification for the CORBA Name Service (which is getting widespread implementation). The Spring Operating System [17] also has an extensive name service.
Reference: [17] <author> J. Stankovic and K. Ramamritham. </author> <title> The design of the spring kernel. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 146-157, </pages> <month> December </month> <year> 1987. </year> <month> 20 </month>
Reference-contexts: MPI contains no support for initiating communication between unrelated processes, though MPI-2 will provide some primitive communicator location facilities. CORBA [16] recognizes the problem of dynamic location and includes a specification for the CORBA Name Service (which is getting widespread implementation). The Spring Operating System <ref> [17] </ref> also has an extensive name service. However, Spring is not widely used, and the CORBA name service is not useful outside of the CORBA domain. While a naming service to support communication in the distributed laboratory need not be overly complex, it must be available.
Reference: [18] <author> P. David Stotts and James M. Purtilo. </author> <title> Virtual environment architectures: Interoperability through software interconnection technology. </title> <booktitle> In Proceedings of the Third Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises, </booktitle> <pages> pages 221-224, </pages> <address> Morgantown, W.Va., April 17-19 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Diego project KeLP [1] seeks to improve the manner in which accesses to remote data may be made more efficient by investigation of object-based data bases for data storage that enable computations to migrate toward useful data as well as by investigation of alternative, compiler-based approaches to linking interactive applications <ref> [18] </ref>. Our work complements the efforts described above by assuming that end users should be able to exploit the potentially high performance of vendor-provided implementations of standards like MPI when appropriate for their applications.
Reference: [19] <author> Mark D. Wood and Bradford B. Glade. </author> <title> Information servers: A scaleable communication paradigm for wide area networks and the information superhighway. </title> <booktitle> In Proceedings of the 7th SIGOPS European Workshop. Association of Computing Machinery, </booktitle> <year> 1996. </year> <month> 21 </month>
Reference-contexts: One can, of course, program the application such that it responds to the dynamic connection of clients and automatically routes information flows to interested parties. However, such implementations tend to make inefficient use of network resources <ref> [19] </ref> and to require the application programmer to create some complex code 5 on top of the basic one-to-one communication mechanisms.
References-found: 19

