URL: http://jrs.www.media.mit.edu/~jrs/evolve_dyn.ps
Refering-URL: http://jrs.www.media.mit.edu/~jrs/
Root-URL: http://www.media.mit.edu
Title: Evolving Dynamical Systems with the Genetic Algorithm  
Author: by Joshua R. Smith WILLIAMS 
Degree: A Thesis Submitted in partial fulfillment of the requirements for the Degree of Bachelor of Arts with Honors in Computer Science  
Date: December 6, 1994  
Affiliation: COLLEGE Williamstown, Massachusetts  
Abstract-found: 0
Intro-found: 1
Reference: [1] <editor> Richard K. Belew, editor. </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, California, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This uses the GAdget Genetic Algorithm toolkit // to evolve models of dynamical systems #include "population.h" #include "display.h" #include "other.h" #include "fn.h" main (int argc, char* argv []) - // Seed random number generator with value from cmd line if available if (argc &gt; 1) - //cout &lt;< atoi (argv <ref> [1] </ref>) &lt;< ""n"; srand48 (atoi (argv [1])); - // The basic parameters int const NUM_GENS = 1500; int const POP_SZ = 30; double const P_CROSS = 0.67; double const P_MUTATE = 0.01; 60 double const MUTATE_STD = 0.01; // How many genes to use to solve the problem (depends on many <p> toolkit // to evolve models of dynamical systems #include "population.h" #include "display.h" #include "other.h" #include "fn.h" main (int argc, char* argv []) - // Seed random number generator with value from cmd line if available if (argc &gt; 1) - //cout &lt;< atoi (argv <ref> [1] </ref>) &lt;< ""n"; srand48 (atoi (argv [1])); - // The basic parameters int const NUM_GENS = 1500; int const POP_SZ = 30; double const P_CROSS = 0.67; double const P_MUTATE = 0.01; 60 double const MUTATE_STD = 0.01; // How many genes to use to solve the problem (depends on many // genes are expected by the
Reference: [2] <author> Edward Beltrami. </author> <title> Mathematics for Dynamic Modeling. </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1987. </year>
Reference-contexts: This search takes longer than one constrained to search only the space of linear systems. equation <ref> [2] </ref>, which is a much-studied non-linear differential equation that cannot be solved. The Van der Pol Equation In its usual form, the Van der Pol equation is written v + v + ff _v (v 2 1) = 0: (5:1) Notice that this system contains a _vv 2 term. <p> We said in section 2.3.1 that our method was not applicable to systems of this form; we said that our white-box's structure was not capable of representing such systems. But the Van der Pol equation can be rewritten as a first order system with no cross terms <ref> [2] </ref>, in a form our method can handle: ( _v = x ff ( v 3 (5:2) To verify that these equations are in fact the same, differentiate the second system with respect to time (and remember to use the chain rule).[40] 49 page are two unevolved functions, one specifying change
Reference: [3] <author> John Tyler Bonner. </author> <title> The Evolution of Complexity. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, New Jersey, </address> <year> 1988. </year>
Reference: [4] <author> L. Booker. </author> <title> Improving search in genetic algorithms. </title> <editor> In L. Davis, editor, </editor> <title> Genetic Algorithms and Simulated Annealing. </title> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, California, </address> <year> 1987. </year>
Reference-contexts: Crossover can be generalized in a variety of ways. DeJong (cited in <ref> [4] </ref>) noted that If we think of the chromosome as a circle with the first gene immediately following the last then it becomes immediately clear that there are in fact 2 crossover points: one fixed at position zero and the other randomly selected.
Reference: [5] <author> Richard Dawkins. </author> <title> The Blind Watchmaker. </title> <publisher> Longman, </publisher> <address> Harlow, </address> <year> 1986. </year>
Reference: [6] <author> Richard Dawkins. </author> <title> The evolution of evolvability. </title> <editor> In Christopher G. Langton, editor, </editor> <booktitle> Artificial Life: The Proceedings of an Interdisciplinary Workshop on the Synthesis and Simulation of Living Systems, </booktitle> <address> Redwood City, California, 1989. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: After all, we are usually not interested in the genes themselves, but rather in the structures they specify. As in natural evolution, a genotype specifies a phenotype, which is then selected according to its fitness. The function from GTYPE to PTYPE is often called the embryology function <ref> [6] </ref>. In GAdget, an object called Embryology "grows" the PTYPES from the GTYPES and evaluates their performance. Since this process may be quite complex, Embryology will often use other classes.
Reference: [7] <author> John Denker, others, and John Hopfield. </author> <title> Large automatic learning, rule extraction, and generalization. </title> <journal> Complex Systems, </journal> <volume> 1 </volume> <pages> 877-922, </pages> <year> 1987. </year>
Reference-contexts: In the first way of describing the problem, one thinks of the time series as empirical data to be explained; in the second, as a training set to be learned or memorized. Thus the terms memorization, rule extraction, and generalization, which Denker et al. and Hopfield <ref> [7] </ref> defined precisely (quantitatively, in fact) in an automatic learning context, will prove useful for discussing our problem. We will define these terms, but not quantitatively. <p> Figure 2.1 shows the phase field of a of these frozen phase portraits would be too strange.[40] 4 A direction field indicates the instantaneous direction of change; a phase field indicates the (approximate) magnitude and direction of change after an interval of t. 5 Denker et al. and Hopfield <ref> [7] </ref> would probably advocate sampling randomly. 13 oscillator. linearly damped harmonic oscillator. It was generated from a GoalDyn, one of our grey-box goal systems. 2.4.4 Error Our error measure for dynamical systems involves comparing phase fields.
Reference: [8] <editor> Larry J. Eshelman, Richard A. Caruna, and J. David Schaffer. </editor> <title> Biases in the crossover landscape. </title> <editor> In J. David Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, California, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: These names suggest a further generalization: n-point or multi-point crossover. One-point, two-point, and n-point crossover are known as traditional crossover operators. They all work in basically the same way; they only differ in the number of crossover points. But there are other variations on crossover as well <ref> [8] </ref>. In the traditional schemes, the number of sections of genetic material swapped is fixed. <p> Thus a child is created by copying a gene from one parent, flipping a coin weighted with the switching probability, and then deciding whether or not to switch the source of the next gene to the other parent based on the outcome of the coin toss <ref> [8] </ref>. Uniform crossover, another so-called non-traditional crossover operator, exchanges individual genes rather than segments. It is usually described in terms of a crossover mask whose bits specify the gene sites at which crossover 24 will occur. <p> In uniform crossover, each bit of the mask is determined by an independent coin flip which can, of course, be weighted [38]<ref> [8] </ref>. The various crossover operators behave differently; which one is most appropriate may depend on the application. [8] provides theoretical and empirical results which give one some basis for making an informed decision.
Reference: [9] <author> David E. Goldberg. </author> <title> Genetic algorithms and walsh functions: Part i, a gentle introduction. </title> <journal> Complex Systems, </journal> <volume> 3 </volume> <pages> 129-152, </pages> <year> 1989. </year>
Reference-contexts: Thus when the GA evaluates a single organism-string, it is, in effect, simultaneously calculating the average fitness of all the organism's substrings. Holland dubbed the GA's capacity to perform these simultaneous tasks implicit parallelism. For accessible introductions to schema theory, see [11], <ref> [9] </ref> and [10]. 3 The slot machine has nothing to do with this part|its only role is in solving the problem. It plays no part in representing or posing the problem.
Reference: [10] <author> David E. Goldberg. </author> <title> Genetic algorithms and walsh functions: Part ii, deception and its analysis. </title> <journal> Complex Systems, </journal> <volume> 3 </volume> <pages> 153-171, </pages> <year> 1989. </year> <month> 64 </month>
Reference-contexts: Thus when the GA evaluates a single organism-string, it is, in effect, simultaneously calculating the average fitness of all the organism's substrings. Holland dubbed the GA's capacity to perform these simultaneous tasks implicit parallelism. For accessible introductions to schema theory, see [11], [9] and <ref> [10] </ref>. 3 The slot machine has nothing to do with this part|its only role is in solving the problem. It plays no part in representing or posing the problem.
Reference: [11] <author> David E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: One feature of GAs that makes them attractive to us is their ability to optimize black (or grey) boxes|no special knowledge of the objective function is needed. Many optimization methods, notably "gradient descent"-type techniques, require that derivatives be known and that the function and its partial derivatives be continuous <ref> [11] </ref>. A GA can be applied to any objective function whose value can be computed (or otherwise known) for all domain values. <p> In this vein, Genetic Algorithms are interesting inasmuch as they contribute to the Artificial Life project of "locating life-as-we-know-it within the larger picture of life-as-it-could-be"[29]. 17 3.2 GAs, Codings, and Evolutionsstrategie GAs do not operate on the parameters, the x -s, themselves, but on codings of the parameters <ref> [11] </ref>. When Holland originally defined the Genetic Algorithm, he used binary codings. Some restrict the definition of GAs to include only techniques which employ finite-alphabet (i.e. discrete) codings. Evolution-sstrategie, a method very similar to Genetic Algorithms, evolved independently in Germany. <p> Questions about how and why these techniques differ, and of which is better, are being hotly contested right now. It should be noted that schema theory <ref> [11] </ref>, the only developed theory of GA operation, applies only to discrete-coded GAs. <p> The selection algorithm assigns each individual x in generation t a real number tsr (x; t), the target sampling rate which is its expected number of offspring. Then the sampling algorithm decides (usually stochastically) how many children each organism will actually produce. Goldberg <ref> [11] </ref> uses the term selection operator to describe the thing which actually decides how many offspring each organism produces (what Grefen-stette calls the sampling algorithm). The fitness function is responsible for producing the evaluation on which the selection operator's decisions are based. <p> Sampling techniques which use fitness proportional selection implement this basic idea. With proportional selection, tsr (x; t) = u (t) [19]<ref> [11] </ref>. The simplest selection method is stochastic sampling with replacement, also known as roulette wheel selection. There are better mechanisms, but this one is simple and effective [11]. Each organism is allotted a slice of a roulette wheel. The size of each slice is proportional to its organism's fitness. Pairs are selected by spinning the wheel and stopping it at a random point. <p> Of course, this selection technique is subject to stochastic sampling errors which reduce the GA's performance, and some of the efforts to improve the selection operator have focused on reducing this type of error. See <ref> [11] </ref>, p. 121. 3.4.3 Crossover Once a pair of organisms has been chosen for breeding, the crossover operator comes into play. <p> Crossover is one of the things which separates the GA from most other evolution-inspired methods, and may be partly responsible for the GA's implicit parallelism, which is described in Goldberg's book <ref> [11] </ref>. Crossover does not necessarily occur every time two organisms are bred; it occurs with a probability that is specified as one of the GA's parameters. A typical value for the probability of crossover would be 0:67. <p> As with crossover, the probability that mutation will occur is specified as a parameter to the GA. A typical value for the probability of a bit mutation would be 0:001 <ref> [11] </ref>. There seems to be less literature on mutation of real genes, but one natural way to perform mutation in real-coded GAs is to add Gaussian noise to each gene that is to be mutated. The variance of the noise can be specified as a parameter to the GA. <p> Goldberg has shown that Reordering Operators are in principle effective but may be extremely slow [16]. For information on other operators, also see <ref> [11] </ref> and [22]. 3.5 Understanding GAs We have now described in some detail many strains of GA. We have not, however, given any description of the dynamics of a GA system as it progresses toward a solution and have not provided any explanation of why it might be effective. <p> But since, in a large enough population, each schema will occur many times, each schema does receive its own average value. By evaluating the fitness function only n times, the GA calculates the average fitness values of n 3 schemata <ref> [11] </ref>. If the GA really is searching the space of genome subsets, then it is doing so at far less cost than one might expect, because it is only doing the computation necessary to search the much smaller space of complete genomes. <p> Thus when the GA evaluates a single organism-string, it is, in effect, simultaneously calculating the average fitness of all the organism's substrings. Holland dubbed the GA's capacity to perform these simultaneous tasks implicit parallelism. For accessible introductions to schema theory, see <ref> [11] </ref>, [9] and [10]. 3 The slot machine has nothing to do with this part|its only role is in solving the problem. It plays no part in representing or posing the problem.
Reference: [12] <author> David E. Goldberg. </author> <title> Messy genetic algorithms: Motivation, analysis, and first results. </title> <journal> Complex Systems, </journal> <volume> 3 </volume> <pages> 493-530, </pages> <year> 1989. </year>
Reference-contexts: There has been very little experimentation with mGAs, which Goldberg <ref> [12] </ref> introduced in 1989. 3.4.4 Mutation Like crossover, the mutation operator is quite straightforward in implementation, but its behavior and purpose is more obscure.
Reference: [13] <author> David E. Goldberg. </author> <title> Zen and the art of genetic algorithms. </title> <editor> In J. David Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, California, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [14] <author> David E. Goldberg. </author> <title> Genetic algorithms and classifier systems. </title> <booktitle> AAAI-90 Tutorial, </booktitle> <month> July </month> <year> 1990. </year>
Reference-contexts: Another strength of the GA is its suitability for parallelization. (Some have called it "embarrassingly" parallel <ref> [14] </ref>.) Many papers on parallel versions of the genetic algorithm appear in the proceedings of the International Conferences on Genetic Algorithms [18][17][33][1]. While other optimization techniques might seem more practical now, GAs may be better able to take advantage of parallel computers when they become widely available.
Reference: [15] <author> David E. Goldberg. </author> <title> Real-coded genetic algorithms, virtual alphabets, and blocking (draft). </title> <type> Technical Report 90001, </type> <institution> Illinois Genetic Algorithms Laboratory, Department of General Engineering, University of Illinois at Urbana-Champaign, </institution> <year> 1990. </year>
Reference-contexts: Though we will use the same name for both the real-coded and discrete-coded techniques, and though the steps the algorithms carry out may be the same, the behavior of the algorithms, that is, how, why, and how well they work, remains quite different <ref> [15] </ref>. Questions about how and why these techniques differ, and of which is better, are being hotly contested right now. It should be noted that schema theory [11], the only developed theory of GA operation, applies only to discrete-coded GAs. <p> Actually, Schema theory suggests that real-coded GAs should not work as well as they in practice appear to, a fact that has lead to much head-scratching, as in a recent technical report by Goldberg <ref> [15] </ref>. 3.3 Data Structures and Definitions We informally introduced the term "organism" earlier. Let us now be more explicit about its meaning: "organism" is (almost) synonymous with "parameter vector". As in section 3.1, we will use p to denote the number of components in the parameter vector.
Reference: [16] <author> David E. Goldberg and Clayton L. </author> <title> Bridges. An analysis of a reordering operator on a ga-hard problem. </title> <journal> Biological Cybernetics, </journal> <volume> 62 </volume> <pages> 397-405, </pages> <year> 1990. </year>
Reference-contexts: In particular, there is a class of operators called Reordering Operators which allow the GA to search for an adequate representation with which to solve the problem. Goldberg has shown that Reordering Operators are in principle effective but may be extremely slow <ref> [16] </ref>. For information on other operators, also see [11] and [22]. 3.5 Understanding GAs We have now described in some detail many strains of GA.
Reference: [17] <editor> John J. Grefenstette, editor. </editor> <booktitle> Genetic Algorithms and Their Applications: Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <address> Hillsdale, New Jersey, 1987. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: [18] <editor> John J. Grefenstette, editor. </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms, </booktitle> <address> Hillsdale, New Jersey, 1987. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: [19] <author> John J. Grefenstette and J.E. Baker. </author> <title> How genetic algorithms work: A critical look at implicit parallelism. </title> <editor> In J. David Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, Califor-nia, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Most researchers break this process down into several parts, and most name one of these parts selection. But which part of this process is called selection seems to vary from researcher to researcher. Grefenstette and Baker <ref> [19] </ref> call the larger process of allocating children the selection phase. This phase has two parts: the selection algorithm and the sampling algorithm. The selection algorithm assigns each individual x in generation t a real number tsr (x; t), the target sampling rate which is its expected number of offspring. <p> Another would be to let k be a function that varies with time. It might decay smoothly, or, in each generation, it might take on the value of the greatest (i.e. worst) objective function value in the population: k (t) = max ff (x)jx 2 P (t)g <ref> [19] </ref>. These last two techniques might be attractive because they maintain strong selective pressure throughout a run of the GA; with the first method, the pressure to adapt or find better solutions drops off as the algorithm "progresses" toward convergence.
Reference: [20] <author> Richard Haberman. </author> <title> Mathematical Models: Mechanical Vibrations, Population Dynamics, and Traffic Flow. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1977. </year>
Reference-contexts: Our method for comparing dynamical systems relies on a discrete approximation of the phase portrait. We will call this approximated phase portrait a phase field , because it is very similar to a direction field <ref> [20] </ref>. Phase fields and direction fields can be drawn (or calculated) without solving equation 2.8.
Reference: [21] <author> Richard W. </author> <title> Hamming. Information and Coding Theory. </title> <publisher> Prentice-Hall, </publisher> <address> En-glewood Cliffs, New Jersey, </address> <year> 1980. </year>
Reference: [22] <author> John H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, </address> <year> 1975. </year> <month> 65 </month>
Reference-contexts: Goldberg has shown that Reordering Operators are in principle effective but may be extremely slow [16]. For information on other operators, also see [11] and <ref> [22] </ref>. 3.5 Understanding GAs We have now described in some detail many strains of GA. We have not, however, given any description of the dynamics of a GA system as it progresses toward a solution and have not provided any explanation of why it might be effective.
Reference: [23] <author> John J. </author> <title> Hopfield. `neural' computation of decisions in optimization problems. </title> <journal> Biological Cybernetics, </journal> <volume> 52 </volume> <pages> 141-152, </pages> <year> 1985. </year>
Reference: [24] <author> A.I. Khinchin. </author> <title> Mathematical Foundations of Information Theory. </title> <publisher> Dover, </publisher> <address> New York, </address> <year> 1957. </year>
Reference-contexts: At this point, we can easily write down the Shannon Entropy of the population: 7 H = k=1 Notice that H = 0 if and only if one of the numbers p 1 ; p 2 ; :::; p n is one and all the others are zero <ref> [24] </ref>. So there is zero entropy when all the organisms are packed into one cell. Furthermore, the entropy is maximized when the organisms are distributed evenly throughout the space.
Reference: [25] <author> H. Kitano. </author> <title> Empirical studies on the speed of convergence of neural network training using genetic algorithms. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> Menlo Park, 1990. </address> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: A mutation operator which takes small steps will be effective for local search <ref> [25] </ref>: the combination of selection and small-mutations should lead to what one might call "stochastic gradient descent." Contrast this with the binary case: a bit mutation in the high order bit of a gene will cause a tremendous jump.
Reference: [26] <author> Donald E. Knuth. </author> <booktitle> The Art of Computer Programming, Volume 2: Seminu-merical Algorithms. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1969. </year>
Reference-contexts: This is often accomplished by setting the genes of the original population, generation 0, randomly. However, since pseudo-random number generators tend to be unreliable <ref> [26] </ref>, it may be preferable not to choose the initial population "randomly" but to deterministically set up a uniform distribution in the search space. For certain theoretical purposes, it may also be useful to start the entire population at a few fixed points in the space.
Reference: [27] <author> John R. Koza. </author> <title> Genetic programming: A paradigm for genetically breeding populations of computer programs to solve problems. </title> <type> Technical Report STAN-CS-90-1314, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1990. </year>
Reference-contexts: Unconstrained, this space would probably be too big to search. Still, some have successfully used this type of approach to search constrained versions of program space <ref> [27] </ref>. Another method would be to use polynomial approximations of infinite series.
Reference: [28] <author> Kuppers, Bernd-Olaf. </author> <title> Information and the Origin of Life. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, Massachusetts, </address> <year> 1990. </year>
Reference: [29] <author> Christopher G. Langton. </author> <title> Artificial life. </title> <editor> In Christopher G. Langton, editor, </editor> <booktitle> Artificial Life: The Proceedings of an Interdisciplinary Workshop on the Synthesis and Simulation of Living Systems, </booktitle> <address> Redwood City, California, 1989. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: So in order to Gray code the genetic information, one would write a Nucleus, called perhaps GrayNucleus, which was a subclass of BinaryNu-cleus. The only major change needed would be to add the Gray decoding function. 4.2.3 Embryology The split between Nucleus and Organism mirrors the GTYPE/PTYPE split Langton <ref> [29] </ref> identifies in both natural and artificial life. He argues that "The most salient characteristic of living systems, from the behavior generalization point of view, is the genotype/phenotype distinction.
Reference: [30] <author> Eric Mjolsness. </author> <type> Personal Communication. </type>
Reference-contexts: The design of our system, which is written in C++, is similar to that of Eric Mjolsness's Nemesis neural network simulation package <ref> [30] </ref>. In designing our toolkit, we strove to decouple the problem solving technique, the GA, from the problem itself, the code which implements the objective function.
Reference: [31] <author> M. P. Vecchi S. Kirkpatrick, C.D. Gelatt, Jr. </author> <title> Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> 220(4598) </volume> <pages> 671-680, </pages> <year> 1983. </year>
Reference: [32] <author> James T. Sandfeur. </author> <title> Discrete dynamical modeling. </title> <journal> The College Methematics Journal, </journal> <volume> 22(1) </volume> <pages> 13-22, </pages> <year> 1991. </year>
Reference: [33] <editor> J. David Schaffer, editor. </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, California, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [34] <author> N.N. Schraudolph and R.K. Belew. </author> <title> Dynamic parameter encoding for genetic algorithms. </title> <type> Technical Report CS90-175, </type> <institution> Los Alamos National Laboratory, </institution> <year> 1990. </year>
Reference-contexts: For a binary-coded GA, d : f0; 1g l ! &lt; p . Some have argued that for binary GAs, it is desirable to Gray code the genetic material so that the mutation operator can perform local search <ref> [34] </ref>. Researchers have also advocated dynamically changing the decoding as the GA approaches convergence; this way the GA can concentrate it resources on searching coarsely at first and more finely later [34]. Objective Function We introduced the term objective function in section 3.1. <p> GAs, it is desirable to Gray code the genetic material so that the mutation operator can perform local search <ref> [34] </ref>. Researchers have also advocated dynamically changing the decoding as the GA approaches convergence; this way the GA can concentrate it resources on searching coarsely at first and more finely later [34]. Objective Function We introduced the term objective function in section 3.1. Again, the objective function specifies the problem that the GA is trying to solve. <p> Some researchers <ref> [34] </ref> advocate Gray coding genes to prevent this problem, though others disagree on the grounds that Gray coding can introduce further undesirable non-linearities into the search space and suggest mutating the decision variables themselves (the decoded binary genes) to achieve "stochastic gradient descent"[15][9].
Reference: [35] <author> George F. Simmons. </author> <title> Differential Equations With Applications and Historical Notes. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1972. </year> <month> 66 </month>
Reference-contexts: making, for chaotic systems, predictions that are not local in time: for chaotic systems, the geometry 12 portrait of a system of (generally non-linear) differential equations consists of infinitely many directed paths which never cross, plus isolated "critical points," states where the time derivative of each state variable is zero <ref> [35] </ref>. Each path represents the behavior of the system for a different set of initial conditions. Strictly speaking, the term phase portrait means the graph of a set of equations specifying trajectories.
Reference: [36] <author> Herbert A. Simon. </author> <booktitle> The Sciences of the Artificial. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <note> second edition, </note> <year> 1985. </year>
Reference-contexts: But before we explain what GAs are, it might make sense first to consider why they are useful and interesting. 3.1 Why GAs? Before we explain some of the Genetic Algorithm's advantages over other optimization techniques, we should define optimization more precisely. Op 1 Simon <ref> [36] </ref> coined this term, which means "good enough," as opposed to strictly optimal. 16 timization is the process of finding, for some objective function f : &lt; p ! &lt;, a parameter vector (x 1 ; x 2 ; : : : ; x p ) such that f (x 1
Reference: [37] <author> Joshua R. Smith. </author> <title> Designing biomorphs with an interactive genetic algorithm. </title> <editor> In Richard K. Belew, editor, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, California, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [38] <author> Gilbert Syswerda. </author> <title> Uniform crossover in genetic algorithms. </title> <editor> In J. David Schaf-fer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, California, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [39] <author> William K. </author> <title> Wootters. </title> <type> Personal Communication. </type>
Reference-contexts: The behavior of chaotic systems can only be predicted locally in time, so an error function which tries to do otherwise is not likely to be a good one <ref> [39] </ref>. 2.4.3 Phase Fields Since we have restricted ourselves to autonomous systems, which do not depend on time, we can avoid the problems of the naive method by using an error function based on the notion of a phase portrait or phase space diagram. <p> This picture of the GA also allows us to consider the entropy of the system as it evolves. One way of measuring entropy would be to impose a grid on the search space in order to break it up into a finite number of l dimensional boxes <ref> [39] </ref>. If the initial bounding box were a hypercube with sides of length b, and the grid cells were hypercubes with sides of length g, 6 there would of course be c = (b=g) l grid cells.
Reference: [40] <author> Jason Zimba. </author> <type> Personal Communication. 67 </type>
References-found: 40

