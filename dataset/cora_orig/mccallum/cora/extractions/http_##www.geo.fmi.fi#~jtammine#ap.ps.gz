URL: http://www.geo.fmi.fi/~jtammine/ap.ps.gz
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Summary  
Phone: 2  
Title: Adaptive proposal distribution for random walk Metropolis algorithm  
Author: Heikki Haario Eero Saksman and Johanna Tamminen 
Keyword: MCMC, Adaptive MCMC, Metropolis-Hastings algorithm, convergence, experimental design  
Address: P.O.Box 4 (Yliopistonkatu 5), FIN-00014 University of Helsinki, Finland  P.O.Box 503, FIN-00101 Helsinki, Finland  
Affiliation: 1 Department of Mathematics,  Finnish Meteorological Insitute, Department of Geophysics,  
Abstract: The choice of a suitable MCMC method and further the choice of a proposal distribution is known to be crucial for the convergence of the Markov chain. However, in many cases the choice of an effective proposal distribution is difficult. As a remedy we suggest a method called Adaptive Proposal (AP). Although the stationary distribution of the AP algorithm is slightly biased, it appears to provide an efficient tool for, e.g., reasonably low dimensional problems, as typically encountered in non-linear regression problems in natural sciences. As a realistic example we include a successful application of the AP algorithm in parameter estimation for the satellite instrument 'GO-MOS'. In this paper we also present a comprehensive test procedure and systematic performance criteria for comparing Adaptive Proposal algorithm with more traditional Metropolis algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Atkinson, A. C. & Donev, A. N. </author> <year> (1992), </year> <title> Optimum Experimental Designs, </title> <publisher> Clasendon Press, Oxford. </publisher>
Reference-contexts: The existence of an optimal choice for H and U was expected, and so such experimental designs were employed that allow the estimation of a quadratic regression model. Initial runs with a central composite design plan <ref> (Atkinson & Donev 1992) </ref> did not yield results that would have been convincing enough.
Reference: <author> Bertaux, J. L., Megie, G., Widemann, T., Chassefiere, E., Pellinen, R., Kyrola, E., Korpela, S. & Simon, P. </author> <year> (1991), </year> <title> `Monitoring of Ozone Trend by Stellar Occultations: The GOMOS instrument', </title> <booktitle> Advanced Space Research 11, </booktitle> <pages> 237-242. </pages>
Reference-contexts: The GOMOS (Global Ozone Monitoring by Occultation of Stars) instrument is a Euro-pean Space Agency's satellite instrument which will measure atmospheric gases, and especially ozone in the stratosphere. The instrument is a part of ENVISAT-1 satellite, which will be launched in 1999. For more information see <ref> (Bertaux, Megie, Widemann, Chassefiere, Pellinen, Kyrola, Korpela & Simon 1991) </ref> and (Kyrola, Sihvola, Kotivuori, Tikka, Tuomi & Haario 1993). A characteristic feature here is that each measurement, in fact, consists of a set of some 50 data sets obtained at different altitudes.
Reference: <author> Gelfand, A. E. & Smith, A. F. M. </author> <year> (1990), </year> <title> `Sampling-based approaches to calculate marginal densities', </title> <journal> J. Am. Stat. Ass. </journal> <volume> 85, </volume> <pages> 853-409. </pages>
Reference-contexts: This is especially important in numerous applications where the full conditional distributions do not reduce to known simple distributions, and hence it is not reasonable to apply the Gibbs sampler <ref> (Gelfand & Smith 1990) </ref>. * The Adaptive Proposal does not simulate exactly the target distribution. However, in practice it is very close to be exact. Our tests show that the difference of the limit distribution of the AP and the true target distribution is negligible in most, reasonably behaving cases.
Reference: <author> Gelman, A. G., Roberts, G. O. & Gilks, W. R. </author> <year> (1996), </year> <title> Efficient Metropolis jumping rules, </title> <editor> in J. M. Bernardo, J. O. Berger, A. F. David & A. F. M. Smith, eds, </editor> <title> `Bayesian Statistics V', </title> <publisher> Oxford University press, Oxford, </publisher> <pages> pp. 599-608. </pages>
Reference-contexts: () denotes the (unscaled) probability density of the target distribu tion. 5 3 Pitfalls in selecting the proposal distribution The shape and the size of the proposal distribution q () is known to be very crucial for the convergence of the Markov chain corresponding the MCMC algorithm, see for example <ref> (Gelman, Roberts & Gilks 1996) </ref>, (Gilks, Richardson & Spiegelhalter 1995), (Gilks, Roberts & Sahu 1998) and (Roberts, Gelman & Gilks 1994). Even when the acceptance probability does not depend on the proposal distribution (like in Metropolis algorithm) the mixing of the chain depends on it. <p> On the other hand, when the proposal distribution is too small, too many candidate points are accepted and the chain converges slowly again. In addition, to ensure computational efficiency one should choose the proposal distribution so that sampling from it would be fast and easy. In <ref> (Gelman et al. 1996) </ref> and (Roberts et al. 1994) the authors present optimal acceptance rates for Gaussian target distributions in different dimensions when the proposal distribution is also Gaussian. <p> The use of the scaling parameter c d is heuristi-cal, but its usefulness is supported by empirical tests. As a basic choice, we have adopted the value c d = 2:4= p d from <ref> (Gelman et al. 1996) </ref>, which corresponds to theoretical optimization of mixing properties of the Metropolis-Hastings search in the case of Gaussian targets and Gaussian proposals. 2-dimensional 'banana-shaped' distribution. The ellipsoids refer to 95% confidence regions of different proposal distributions. <p> In the case of Gaussian target distributions 1 and 2 the Metropolis algorithm was run using Gaussian proposal distributions with known covariances C 1 and C 2 together with the optimal scaling <ref> (Gelman et al. 1996) </ref>, ie. the proposals were (2:4= p p d) fi N (0; C 2 ), respectively. Thus the algorithm should perform optimally well. <p> It turns out that all three variables do have an effect, but the dependence on U and H is rather weak. Instead, a proper scaling by c d is more essential. The choice c d = 2:4= p d (discussed in <ref> (Gelman et al. 1996) </ref>) clearly improves the results in the case of Gaussian targets, if compared to the runs with no scaling.
Reference: <author> Gilks, W. R., Richardson, S. & Spiegelhalter, D. J. </author> <year> (1995), </year> <title> Introducing Markov chain Monte Carlo, </title> <editor> in W. R. Gilks, S. Richardson & D. J. Spiegelhalter, eds, </editor> <title> `Markov Chain Monte Carlo in Practice', </title> <publisher> Chapman & Hall, </publisher> <pages> pp. 1-19. </pages>
Reference-contexts: density of the target distribu tion. 5 3 Pitfalls in selecting the proposal distribution The shape and the size of the proposal distribution q () is known to be very crucial for the convergence of the Markov chain corresponding the MCMC algorithm, see for example (Gelman, Roberts & Gilks 1996), <ref> (Gilks, Richardson & Spiegelhalter 1995) </ref>, (Gilks, Roberts & Sahu 1998) and (Roberts, Gelman & Gilks 1994). Even when the acceptance probability does not depend on the proposal distribution (like in Metropolis algorithm) the mixing of the chain depends on it. <p> For other adaptive approaches and related work see (Gilks, Roberts & George 1994), <ref> (Gilks & Roberts 1995) </ref>, (Gilks et al. 1998), (Sahu & Zhigljavsky 1998a) and (Sahu & Zhigljavsky 1998b). Before going into details, we first point out that due to the adaptive nature of the AP algorithm, the convergence and ergodicity properties of the AP 6 algorithm are not obvious.
Reference: <author> Gilks, W. R., Roberts, G. O. & George, E. I. </author> <year> (1994), </year> <title> `Adaptive direction sampling', </title> <booktitle> Statistical Science 43, </booktitle> <pages> 179-189. </pages>
Reference-contexts: the proposal distribution The shape and the size of the proposal distribution q () is known to be very crucial for the convergence of the Markov chain corresponding the MCMC algorithm, see for example (Gelman, Roberts & Gilks 1996), (Gilks, Richardson & Spiegelhalter 1995), (Gilks, Roberts & Sahu 1998) and <ref> (Roberts, Gelman & Gilks 1994) </ref>. Even when the acceptance probability does not depend on the proposal distribution (like in Metropolis algorithm) the mixing of the chain depends on it. <p> For other adaptive approaches and related work see <ref> (Gilks, Roberts & George 1994) </ref>, (Gilks & Roberts 1995), (Gilks et al. 1998), (Sahu & Zhigljavsky 1998a) and (Sahu & Zhigljavsky 1998b).
Reference: <author> Gilks, W. & Roberts, G. </author> <year> (1995), </year> <title> Stategies for improving MCMC, </title> <editor> in W. </editor> <publisher> R. </publisher>
Reference-contexts: density of the target distribu tion. 5 3 Pitfalls in selecting the proposal distribution The shape and the size of the proposal distribution q () is known to be very crucial for the convergence of the Markov chain corresponding the MCMC algorithm, see for example (Gelman, Roberts & Gilks 1996), <ref> (Gilks, Richardson & Spiegelhalter 1995) </ref>, (Gilks, Roberts & Sahu 1998) and (Roberts, Gelman & Gilks 1994). Even when the acceptance probability does not depend on the proposal distribution (like in Metropolis algorithm) the mixing of the chain depends on it. <p> For other adaptive approaches and related work see (Gilks, Roberts & George 1994), <ref> (Gilks & Roberts 1995) </ref>, (Gilks et al. 1998), (Sahu & Zhigljavsky 1998a) and (Sahu & Zhigljavsky 1998b). Before going into details, we first point out that due to the adaptive nature of the AP algorithm, the convergence and ergodicity properties of the AP 6 algorithm are not obvious.
Reference: <author> Gilks, S. Richardson & D. J. Spiegelhalter, eds, </author> <title> `Markov Chain Monte Carlo in Practice', </title> <publisher> Chapman & Hall, </publisher> <pages> pp. 75-88. </pages>
Reference: <author> Gilks, W., Roberts, G. & Sahu, S. </author> <year> (1998), </year> <title> `Adaptive Markov chain Monte Carlo through regeneration', </title> <journal> J. Amer. Statist. Assoc. </journal> . <note> To appear. </note>
Reference-contexts: tion. 5 3 Pitfalls in selecting the proposal distribution The shape and the size of the proposal distribution q () is known to be very crucial for the convergence of the Markov chain corresponding the MCMC algorithm, see for example (Gelman, Roberts & Gilks 1996), (Gilks, Richardson & Spiegelhalter 1995), <ref> (Gilks, Roberts & Sahu 1998) </ref> and (Roberts, Gelman & Gilks 1994). Even when the acceptance probability does not depend on the proposal distribution (like in Metropolis algorithm) the mixing of the chain depends on it. <p> For other adaptive approaches and related work see (Gilks, Roberts & George 1994), (Gilks & Roberts 1995), <ref> (Gilks et al. 1998) </ref>, (Sahu & Zhigljavsky 1998a) and (Sahu & Zhigljavsky 1998b). Before going into details, we first point out that due to the adaptive nature of the AP algorithm, the convergence and ergodicity properties of the AP 6 algorithm are not obvious. This is discussed in section 7.
Reference: <author> Haario, H., Saksman, E. & Tamminen, J. </author> <year> (1998), </year> <title> An Adaptive Metropolis algorithm. </title> <institution> Reports of the Department of Mathematics, University of Helsinki, </institution> <type> Preprint 187. </type>
Reference-contexts: We found this method especially suitable for the data processing of the GOMOS satellite instrument. More theoretical considerations of other variations of the idea that will make the process fully ergodic will be discussed in a subsequent paper <ref> (Haario, Saksman & Tamminen 1998) </ref>.
Reference: <author> Hastings, W. </author> <year> (1970), </year> <title> `Monte Carlo sampling methods using Markov chains and their applications', </title> <booktitle> Biometrica 57, </booktitle> <pages> 97-109. </pages> <note> 27 Kyrola, </note> <author> E., Sihvola, E., Kotivuori, Y., Tikka, M., Tuomi, T. & Haario, H. </author> <year> (1993), </year> <title> `Inverse Theory for Occultation Measurements, 1. Spectral Inversion', </title> <journal> J. Geophys. Res. </journal> <volume> 98, </volume> <pages> 7367-7381. </pages>
Reference-contexts: 1 Introduction In this paper we will introduce a new adaptive Markov Chain Monte Carlo method that yields a quick and flexible tool for estimating posteriori distributions in parameter estimation problems. Basically the method consists of the well-known Metropolis algorithm (Metropolis, Rosenbluth, Rosenbluth, Teller & Teller 1953) <ref> (Hastings 1970) </ref> (Tierney 1994), where however, the proposal distribution is tuned along the search according to the covariance calculated from a fixed number of previous states.
Reference: <author> Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H. & Teller, E. </author> <year> (1953), </year> <title> `Equations of state calculations by fast computing machine', </title> <journal> J. Chem. Phys. </journal> <volume> 21, </volume> <pages> 1087-1091. </pages>
Reference-contexts: 1 Introduction In this paper we will introduce a new adaptive Markov Chain Monte Carlo method that yields a quick and flexible tool for estimating posteriori distributions in parameter estimation problems. Basically the method consists of the well-known Metropolis algorithm <ref> (Metropolis, Rosenbluth, Rosenbluth, Teller & Teller 1953) </ref> (Hastings 1970) (Tierney 1994), where however, the proposal distribution is tuned along the search according to the covariance calculated from a fixed number of previous states. <p> Since the critical features are different for the two methods, we 4 will compare Adaptive Proposal only to basic Metropolis-Hastings methods. For the convenience of the reader we next recall the definitions of the two algorithms used in the comparison. The single component Metropolis-Hastings algorithm The original Metropolis algorithm <ref> (Metropolis et al. 1953) </ref> is based on sampling each component of the new state separately one after another. Each new state in the chain is, therefore, sampled in as many steps as there are components (e.g. coordinates) in the parameter space.
Reference: <author> Nummelin, E. </author> <year> (1984), </year> <title> General irreducible Markov chains and non-negative operators, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge. </address>
Reference-contexts: In order to determine the actual distribution yielded by the algorithm one may consider the chain Y k = (X k ; X k1 ; : : :; X Uk+1 ) in the state space IR dfiU . Now the general theory of ergodicity for Markov processes becomes applicable <ref> (Nummelin 1984) </ref>. By projecting the limit distribution of the chain (Y k ) back to IR d to obtain the distribution e that (X k ) eventually simulates.

References-found: 13

