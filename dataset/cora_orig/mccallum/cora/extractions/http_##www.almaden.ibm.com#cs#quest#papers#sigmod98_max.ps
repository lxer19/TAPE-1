URL: http://www.almaden.ibm.com/cs/quest/papers/sigmod98_max.ps
Refering-URL: http://www.almaden.ibm.com/cs/quest/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Abstract  
Keyword: ous algorithms based on Apriori scale exponentially with longest  
Note: tude or more.  
Abstract: We present a pattern-mining algorithm that scales roughly linearly pattern length. Experiments on real data show that when the patterns are long, our algorithm is more efficient by an order of magni in the number of maximal patterns embedded in a database irrespective of the length of the longest pattern. In comparison, previ
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Agrawal, R.; Imielinski, T.; and Swami, A. </author> <year> 1993. </year> <title> Mining Association Rules between Sets of Items in Large Databases. </title> <booktitle> In Proc. of the 1993 ACM-SIGMOD Conf. on the Management of Data, </booktitle> <pages> 207-216. </pages>
Reference-contexts: 1. Introduction Finding patterns in databases is the fundamental operation behind several common data-mining tasks including association rule <ref> [1] </ref> and sequential pattern mining [4]. For the most part, pattern mining algorithms have been developed to operate on databases where the longest patterns are relatively short. This leaves data outside this mold unexplorable using current techniques.
Reference: [2] <author> Agrawal, R.; Mannila, H.; Srikant, R.; Toivonen, H.; and Verkamo, A. I. </author> <year> 1996. </year> <title> Fast Discovery of Association Rules. In Advances in Knowledge Discovery and Data Mining, </title> <publisher> AAAI Press, </publisher> <pages> 307-328. </pages>
Reference-contexts: Most categorically-valued datasets used for classification problems (e.g. targeted marketing campaigns) also tend to have long patterns because they contain many frequently occurring items and have a wide average record length. Almost every recently-proposed pattern-mining algorithm is a variant of Apriori <ref> [2] </ref>. Two recent papers have demonstrated that Apriori-like algorithms are inadequate on datasets with long patterns. Brin et al. [6] applied their association-rule miner DIC to a dataset composed of PUMS census records.
Reference: [3] <author> Agrawal, R., and Srikant, R. </author> <year> 1994. </year> <title> Fast Algorithms for Mining Association Rules. </title> <institution> IBM Research Report RJ9839, </institution> <month> June </month> <year> 1994, </year> <institution> IBM Almaden Research Center, </institution> <address> San Jose, CA. </address>
Reference-contexts: expressions is similar to the problem of generating hypergraph transversals, and Gunopulos et al. [7] have previously shown that hypergraph transversal algorithms can be used as a component of an algorithm for mining maximal frequent itemsets. 3.3 Implementation Details Max-Miner can use the same data-structures as Apriori (as detailed in <ref> [3] </ref>) for efficiently computing itemset supports. The primary data-structure used by Apriori is the hash tree to index candidate itemsets. Max-Miner uses the hash tree to index only the head of each candidate group. <p> Our implementation of Max-Miner diverges from the pseudo-code description in only one way. During the second pass over the dataset, we use a two-dimensional array for quickly computing the support of all 2-itemsets as suggested in <ref> [3] </ref>, and do not compute the support of the long itemsets .
Reference: [4] <author> Agrawal, R. and Srikant, R. </author> <year> 1995. </year> <title> Mining Sequential Patterns. </title> <booktitle> In Proc. of the 11th Int'l Conf. on Data Engineering, </booktitle> <pages> 3-14. </pages>
Reference-contexts: 1. Introduction Finding patterns in databases is the fundamental operation behind several common data-mining tasks including association rule [1] and sequential pattern mining <ref> [4] </ref>. For the most part, pattern mining algorithms have been developed to operate on databases where the longest patterns are relatively short. This leaves data outside this mold unexplorable using current techniques.
Reference: [5] <author> Bayardo, R. J. </author> <year> 1997. </year> <title> Brute-Force Mining of High-Confidence Classification Rules. </title> <booktitle> In Proc. of the Third Intl Conf. on Knowledge Discovery and Data Mining, </booktitle> <pages> 123-126. </pages>
Reference-contexts: Brin et al. [6] applied their association-rule miner DIC to a dataset composed of PUMS census records. To reduce the difficulty of this dataset, they removed all items appearing in over 80% of the transactions yet still could only mine efficiently at high support. We <ref> [5] </ref> previously applied an Apriori-inspired algorithm to several datasets from the Irvine Machine Learning Database Repository. In order to mine efficiently, this algorithm had to sometimes apply pruning strategies that rendered the search incomplete. Apriori involves a phase for finding patterns called frequent itemsets. <p> Though incomplete techniques at association rule mining may sometimes be sufficient, completeness is more desirable. We believe that incorporating additional constraints into the search for frequent patterns is the only way to achieve completeness on complex data. Association rule confidence is a constraint that Bayardo <ref> [5] </ref> uses to prune some itemsets from consideration. Other constraints that have been used during the search for patterns include item constraints [15] and information-theoretic constraints [13]. Interestingness constraints thus far applied only during post-processing (e.g. [6]) might also be exploitable during search to improve efficiency.
Reference: [6] <author> Brin, S.; Motwani, R.; Ullman, J.; and Tsur, S. </author> <year> 1997. </year> <title> Dynamic Itemset Counting and Implication Rules for Market Basket Data. </title> <booktitle> In Proc. of the 1997 SIGMOD Conf. on the Management of Data, </booktitle> <pages> 255-264. </pages>
Reference-contexts: Almost every recently-proposed pattern-mining algorithm is a variant of Apriori [2]. Two recent papers have demonstrated that Apriori-like algorithms are inadequate on datasets with long patterns. Brin et al. <ref> [6] </ref> applied their association-rule miner DIC to a dataset composed of PUMS census records. To reduce the difficulty of this dataset, they removed all items appearing in over 80% of the transactions yet still could only mine efficiently at high support. <p> Apriori in its purest form checks itemsets of length for frequency during database pass . DIC <ref> [6] </ref> is more eager and begins checking an itemset shortly after all its subsets have been determined frequent, rather than waiting until the database pass completes. Partition [11] identifies all frequent-itemsets in memory-sized partitions of the database, and then checks these against the entire database during a final pass. <p> Association rule confidence is a constraint that Bayardo [5] uses to prune some itemsets from consideration. Other constraints that have been used during the search for patterns include item constraints [15] and information-theoretic constraints [13]. Interestingness constraints thus far applied only during post-processing (e.g. <ref> [6] </ref>) might also be exploitable during search to improve efficiency. Max-Miner provides a framework in which additional constraints can often be easily integrated into the search. Consider as an example the problem of finding only the longest frequent itemsets. <p> The dataset that is not publicly available was provided by a retailer. This dataset contains records listing all of the items purchased by a customer over a period of time. We produced another of our datasets from PUMS census data available at http://augustus.csscr.washington.edu/census/ comp_013.html. Following Brin et al. <ref> [6] </ref>, we discretized continuous attributes and removed uninformative attributes. We created another version of the dataset where all items with 80% or greater support were discarded. The raw data from the web consists of both housing and person records, but we extracted only the person records.
Reference: [7] <author> Gunopulos, G.; Mannila, H.; and Saluja, S. </author> <year> 1997. </year> <title> Discovering All Most Specific Sentences by Randomized Algorithms. </title> <booktitle> In Proc. of the 6th Intl Conf. on Database Theory, </booktitle> <pages> 215-229. </pages>
Reference-contexts: It also uses the hashing scheme to rewrite a smaller database after each pass in order to reduce the overhead of subsequent passes. Still, like Apriori, it considers every frequent itemset. Gunopulos et al. <ref> [7] </ref> present a randomized algorithm for identifying maximal frequent itemsets in memory-resident databases. Their algorithm works by iteratively attempting to extend a working pattern until failure. <p> The fact that the same policy works well for both problems is likely due to their close relationship. Finding prime implicants in CNF expressions is similar to the problem of generating hypergraph transversals, and Gunopulos et al. <ref> [7] </ref> have previously shown that hypergraph transversal algorithms can be used as a component of an algorithm for mining maximal frequent itemsets. 3.3 Implementation Details Max-Miner can use the same data-structures as Apriori (as detailed in [3]) for efficiently computing itemset supports.
Reference: [8] <author> Lin, D. and Kedem, Z. M. </author> <year> 1998. </year> <title> PincerSearch: A New Algorithm for Discovering the Maximum Frequent Set. </title> <booktitle> In Proc. of the Sixth European Conf. on Extending Database Technology, to appear. </booktitle>
Reference-contexts: Concurrent to our work, Lin and Kedem <ref> [8] </ref> have proposed an algorithm called PincerSearch for mining long maximal frequent itemsets. Like Max-Miner, PincerSearch attempts to identify long patterns throughout the search. The difference between these algorithms is primarily in the long candidate itemsets considered by each. <p> For most of these data points, the number of longest frequent itemsets was under 300. 6.5 Comparison with PincerSearch Because our work was done concurrently, we have thus far only had the opportunity to perform a preliminary comparison with Lin and Kedems PincerSearch algorithm <ref> [8] </ref>. We have run Max-Miner on the dataset from their evaluation with the longest frequent itemsets (T20.I15.D100K). Unfortunately, it was not challenging enough for either algorithm to draw any solid conclusions.
Reference: [9] <author> Park, J. S.; Chen, M.-S.; and Yu, P. S. </author> <year> 1996. </year> <title> An Effective Hash Based Algorithm for Mining Association Rules. </title> <booktitle> In Proc. of the 1995 SIGMOD Conf. on the Management of Data, </booktitle> <pages> 175-186. </pages>
Reference-contexts: DIC considers the same number of candidate itemsets as Apriori, and Partition can consider more but never fewer candidate itemsets than Apriori, potentially exacerbating problems associated with long patterns. Park et al. <ref> [9] </ref> enhance Apriori with a hashing scheme that can identify (and thereby eliminate from consideration) some candidates that will turn up infrequent if checked against the database. It also uses the hashing scheme to rewrite a smaller database after each pass in order to reduce the overhead of subsequent passes.
Reference: [10] <author> Rymon, R. </author> <year> 1992. </year> <title> Search through Systematic Set Enumeration. </title> <booktitle> In Proc. of Third Intl Conf. on Principles of Knowledge Representation and Reasoning, </booktitle> <month> 539-550. </month> <title> 1 Candidate itemset counts for both PincerSearch and Max-Miner do not include the 1 and 2-itemsets. Runtimes are not directly comparable due to differences in hardware and implementation details. </title>
Reference-contexts: The minsup parameter will sometimes be specified as a percentage of the transactions in the dataset instead of as an absolute number of transactions. Max-Miner can be described using Rymons generic set-enumeration tree search framework <ref> [10] </ref>. The idea is to expand sets over an ordered and finite item domain as illustrated in Figure 1 where four items are denoted by their position in the ordering.
Reference: [11] <author> Savasere, A.; Omiecinski, E.; and Navathe, S. </author> <year> 1995. </year> <title> An Effi--cient Algorithm for Mining Association Rules in Large Databases. </title> <booktitle> In Proc. of the 21st Conf. on Very Large DataBases, </booktitle> <pages> 432-444. </pages>
Reference-contexts: Apriori in its purest form checks itemsets of length for frequency during database pass . DIC [6] is more eager and begins checking an itemset shortly after all its subsets have been determined frequent, rather than waiting until the database pass completes. Partition <ref> [11] </ref> identifies all frequent-itemsets in memory-sized partitions of the database, and then checks these against the entire database during a final pass.
Reference: [12] <author> Slagel, J. R.; Chang, C.-L.; and Lee, R. C. T. </author> <year> 1970. </year> <title> A New Algorithm for Generating Prime Implicants. </title> <journal> IEEE Trans. on Computers, C-19(4):304-310. </journal>
Reference-contexts: This function orders the tail items of a group in increasing order of . This strategy tunes the frequency heuristic by having it consider only the subset of transactions relevant to the given node. Interestingly, the same item reordering heuristic is used by Slagel et al. <ref> [12] </ref> in a set-enumeration algorithm for identifying prime implicants in CNF propositional logic expressions. The fact that the same policy works well for both problems is likely due to their close relationship.
Reference: [13] <author> Smythe, P. and Goodman, R. M. </author> <year> 1992. </year> <title> An Information Theoretic Approach to Rule Induction from Databases. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 4(4) </volume> <pages> 301-316. </pages>
Reference-contexts: Association rule confidence is a constraint that Bayardo [5] uses to prune some itemsets from consideration. Other constraints that have been used during the search for patterns include item constraints [15] and information-theoretic constraints <ref> [13] </ref>. Interestingness constraints thus far applied only during post-processing (e.g. [6]) might also be exploitable during search to improve efficiency. Max-Miner provides a framework in which additional constraints can often be easily integrated into the search. Consider as an example the problem of finding only the longest frequent itemsets.
Reference: [14] <author> Srikant, R. and Agrawal, R. </author> <year> 1996. </year> <title> Mining Sequential Patterns: Generalizations and Performance Improvements. </title> <booktitle> In Proc. of the Fifth Int'l Conf. on Extending Database Technology, </booktitle> <pages> 3-17. </pages>
Reference: [15] <author> Srikant, R.; Vu, Q.; and Agrawal, R. </author> <year> 1997. </year> <title> Mining Association Rules with Item Constraints. </title> <booktitle> In Proc. of the Third Int'l Conf. on Knowledge Discovery in Databases and Data Mining, </booktitle> <pages> 67-73. </pages>
Reference-contexts: Association rule confidence is a constraint that Bayardo [5] uses to prune some itemsets from consideration. Other constraints that have been used during the search for patterns include item constraints <ref> [15] </ref> and information-theoretic constraints [13]. Interestingness constraints thus far applied only during post-processing (e.g. [6]) might also be exploitable during search to improve efficiency. Max-Miner provides a framework in which additional constraints can often be easily integrated into the search.
Reference: [16] <author> Zaki, M. J.; Parthasarathy, S.; Ogihara, M.; and Li, W. </author> <year> 1997. </year> <title> New Algorithms for Fast Discovery of Association Rules. </title> <booktitle> In Proc. of the Third Int'l Conf. on Knowledge Discovery in Databases and Data Mining, </booktitle> <pages> 283-286. </pages>
Reference-contexts: It also remains to be seen how the l 2 l Efficiently Mining Long Patterns from Databases Roberto J. Bayardo Jr. IBM Almaden Research Center http://www.almaden.ibm.com/cs/people/bayardo/ bayardo@alum.mit.edu proposed complete version of the algorithm would perform in practice. Zaki et al. <ref> [16] </ref> present the algorithms MaxEclat and MaxClique for identifying maximal frequent itemsets. These algorithms are similar to Max-Miner in that they also attempt to look ahead and identify long frequent itemsets early on to help prune the space of candidate itemsets considered. <p> After the second database pass, the PincerSearch long candidate itemset generation procedure amounts to identifying all the maximal cliques in a graph where the nodes are the frequent 1-itemsets and the edges are the frequent 2-itemsets, much as Zakis MaxClique algorithm <ref> [16] </ref>. Unlike MaxClique, PincerSearch uses a top-down instead of bottom-up approach for finding the cliques. But due to the fact that the problem is NP-hard, any approach at generating candidates in this manner may be prone to performance problems when the frequent itemsets (and hence the maximal cliques) are long.
References-found: 16

