URL: http://www.cs.princeton.edu/sio/papers/OSDI94.ps
Refering-URL: http://www.cs.princeton.edu/sio/
Root-URL: http://www.cs.princeton.edu
Email: fpc,felten,lig@cs.princeton.edu  
Title: Implementation and Performance of Application-Controlled File Caching  
Author: Pei Cao, Edward W. Felten, and Kai Li 
Address: Princeton, NJ 08544 USA  
Affiliation: Department of Computer Science Princeton University  
Abstract: Traditional file system implementations do not allow applications to control file caching replacement decisions. We have implemented two-level replacement, a scheme that allows applications to control their own cache replacement, while letting the kernel control the allocation of cache space among processes. We designed an interface to let applications exert control on replacement via a set of directives to the kernel. This is effective and requires low overhead. We demonstrate that for applications that do not perform well under traditional caching policies, the combination of good application-chosen replacement strategies, and our kernel allocation policy LRU-SP, can reduce the number of block I/Os by up to 80%, and can reduce the elapsed time by up to 45%. We also show that LRU-SP is crucial to the performance improvement for multiple concurrent applications: LRU-SP fairly distributes cache blocks and offers protection against foolish applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Mary Baker, John H. Hartman, Michael D. Kupfer, Ken W. Shirriff, and John Ousterhout. </author> <title> Measurements of a distributed file system. </title> <booktitle> In Proceedings of the Thirteenth Symposium on Operating Systems Principles, </booktitle> <pages> pages 198-211, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The main design challenge is to devise an interface that allows applications to exert the control they need, without introducing the overhead that would result from a totally general mechanism. Our approach was to first consider common file access patterns reported in the literature (e.g. <ref> [24, 1, 6] </ref>) as well as patterns that we observed in the applications discussed below. We then chose a simple interface that was sufficient to compose caching strategies to support these access patterns.
Reference: [2] <author> Brian N. Bershad, Craig Chambers, Susan Eggers, Chris Maeda, Dylan MaNamee, Przemystaw Pardyak, Stefan Savage, and Emin Gun Sirer. </author> <title> SPIN | an extensible microkernel for applicatoin-specific operating system services. </title> <type> Technical Report TR 94-03-03, </type> <institution> Dept. of Computer Science and Engineering, University of Washington, </institution> <year> 1994. </year>
Reference-contexts: In all our following experiments, however, we put all files on local disks to avoid impact on performance from network traffic. We believe this interface could be used if one wanted to implement two level replacement using upcalls or dropped-in-kernel "user-level handlers" <ref> [2] </ref>. In particular user-level handlers could know which blocks are in cache by keeping track of new block and block gone calls. Our current implementation adds negligible overhead to file accesses. For processes that do not control their own caching, there is no added overhead on cache hits.
Reference: [3] <author> Pei Cao, Edward W. Felten, and Kai Li. </author> <title> Application-controlled file caching policies. </title> <booktitle> In Conference Proceedings of the USENIX Summer 1994 Technical Conference, </booktitle> <pages> pages 171-182, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: 1 Introduction File caching is a widely used technique in file systems. Cache management policy is normally centrally controlled by the operating system kernel. Recently, we have shown by simulation that application-controlled file caching can offer higher file cache hit ratios than the traditional approach <ref> [3] </ref>. This paper presents the design and implementation of an application-controlled file cache and reports its performance benefit under a real application workload. The design of our application-controlled file cache is based on a two-level replacement scheme proposed in [3]. <p> can offer higher file cache hit ratios than the traditional approach <ref> [3] </ref>. This paper presents the design and implementation of an application-controlled file cache and reports its performance benefit under a real application workload. The design of our application-controlled file cache is based on a two-level replacement scheme proposed in [3]. This method lets the kernel dynamically allocate cache blocks to user processes, and allows each user process to apply its favorite file caching policy to its blocks. A cache block allocation policy, called Least-Recently-Used with Swapping and Placeholders (LRU-SP), is used to guarantee the fairness of allocation. <p> For a full discussion see <ref> [3] </ref>. <p> In <ref> [3] </ref> we proposed a kernel policy called LRU-SP that satisfies these criteria. <p> If it uses a worse policy than LRU, then placeholders are necessary to prevent it from hurting other processes. For more details please see <ref> [3] </ref>. 3 Supporting Application Control There are a variety of ways to implement the user-kernel interaction in two level block replacement, as discussed in [3]. <p> If it uses a worse policy than LRU, then placeholders are necessary to prevent it from hurting other processes. For more details please see <ref> [3] </ref>. 3 Supporting Application Control There are a variety of ways to implement the user-kernel interaction in two level block replacement, as discussed in [3]. The main design challenge is to devise an interface that allows applications to exert the control they need, without introducing the overhead that would result from a totally general mechanism. <p> The raw data for this experiment appear in the appendix 4 . Application-specific policies reduce the number of block I/Os by an amount ranging from 9% to over 80%. This confirms our simulation result <ref> [3] </ref> that miss ratio is reduced by application controlled caching. The reduction in elapsed time ranges from 6% to over 45%. <p> Figure 5 shows the normalized elapsed time and the number of block I/Os. As can be seen, LRU-SP indeed improves the performance of the whole system. The improvement becomes more significant as the file cache size increases. 6 Analysis of LRU-SP In our simulation study <ref> [3] </ref> we found that both the swapping and placeholders techniques in LRU-SP are necessary, and that LRU-SP satisfies our allocation criteria as described in Section 2. <p> The data clearly shows that place-holders are necessary to protect the oblivious readN from losing its share of cache blocks. (For a detailed explanation of why placeholders provide this protection, see <ref> [3] </ref>.) However, the data also shows that placeholders did not prevent the increasing in elapsed times of ReadN. The next subsection explains why. 6.2 Criteria Test We have seen in Section 5 that smart processes improve their performance. <p> Our work differs from that described in these papers in three significant ways: * None of these papers (except [12]) addresses the global allocation policy problem. By contrast, we discuss this problem in detail, and provide a solution, LRU-SP, which we have simulated <ref> [3] </ref> and now have implemented. * Most of these papers relied on RPC or upcalls for kernel-to-user communication, and consequently reported overhead as high as 10% of the total execution time [19, 28]. <p> We provide a flexible interface for applications to issue primitives to exert control on cache replacement; we found that this is adequate most of the time and requires low overhead. * Most of these papers do not adequately consider which replacement policy an application should use. In <ref> [3] </ref> we proposed that application replacement policies be based on the optimal replacement principle [8], and in this paper we discussed which policies to use for our example applications. On the other hand, our work shares some common purposes with the existing work on application-controlled virtual memory. <p> We believe our approach to file caching fully applies to these systems as well, with only some minor changes in data structures. Finally, the difference between this paper and the work described in <ref> [3] </ref> is that in [3] we proposed and simulated LRU-SP, and in this paper we proposed a concrete scheme for user-kernel interaction and implemented both the interaction scheme and application-controlled caching in a real kernel. 8 Conclusion and Future Work Our main conclusion is that two level replacement with LRU-SP works. <p> We believe our approach to file caching fully applies to these systems as well, with only some minor changes in data structures. Finally, the difference between this paper and the work described in <ref> [3] </ref> is that in [3] we proposed and simulated LRU-SP, and in this paper we proposed a concrete scheme for user-kernel interaction and implemented both the interaction scheme and application-controlled caching in a real kernel. 8 Conclusion and Future Work Our main conclusion is that two level replacement with LRU-SP works. <p> As a result, the number of disk I/Os can be significantly reduced, and the application's elapsed time and the system's throughput can improve. We are working on improving our user-kernel interface, and on supporting user-level control over caching of concurrently shared files <ref> [3] </ref>. In addition, our current implementation ignores metadata blocks like inodes, partly because there is a separate caching scheme for them inside the file system. We plan to look more into metadata caching performance and investigate what should be done.
Reference: [4] <author> David Cheriton. </author> <title> Effective use of large RAM disk-less workstations with the V virtual memory system. </title> <type> Technical report, </type> <institution> Dept. of Computer Science, Stan-ford University, </institution> <year> 1987. </year>
Reference-contexts: Although placeholders do not completely eliminate the harm done by foolish processes, they at least help the kernel take administrative measures to solve the problem. 7 Related Work There have been many studies on caching in file systems (e.g. <ref> [27, 4, 26, 14, 22, 15] </ref>), but these investigations were not primarily concerned with the performance impact of different replacement policies.
Reference: [5] <author> Khien-Mien Chew, A. Jyothy Reddy, Theodore H. Romer, and Avi Silberschatz. </author> <title> Kernel support for recoverable-persistent virtual memory. </title> <type> Technical Report TR-93-06, </type> <institution> University of Texas at Austin, Dept. of Computer Science, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: Recently several research projects have tried to improve file system performance in a number of other ways, including prefetching <ref> [30, 25, 7, 5, 11] </ref>, delayed writeback [21] and disk block clustering [20, 29]. Most of these papers still assume global LRU as the basic cache replacement policy, and they do not address how to use application control over replacement to improve cache hit ratio.
Reference: [6] <author> Hong-Tai Chou and David J. DeWitt. </author> <title> An evaluation of buffer management strategies for relational database systems. </title> <booktitle> In Proceedings of the Eleventh International Conference on Very Large Databases, </booktitle> <pages> pages 127-141, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: The main design challenge is to devise an interface that allows applications to exert the control they need, without introducing the overhead that would result from a totally general mechanism. Our approach was to first consider common file access patterns reported in the literature (e.g. <ref> [24, 1, 6] </ref>) as well as patterns that we observed in the applications discussed below. We then chose a simple interface that was sufficient to compose caching strategies to support these access patterns. <p> Our work is complementary to these approaches; in other words, with application-controlled file caching, these approaches will improve file system performance even more. The database community has long studied access patterns and buffer replacement policies <ref> [31, 6, 23] </ref>. In our experiments we used pjn (Postgres join) as an example of how database systems may use our inter face to control file caching. We believe our interface is flexible enough to implement most of the policies a database system might want to use.
Reference: [7] <author> Kenneth M. Curewitz, P. Krishnan, and Jeffrey Scott Vitter. </author> <title> Practical prefetching via data compression. </title> <booktitle> In Proc. 1993 ACM-SIGMOD Conference on Management of Data, </booktitle> <pages> pages 257-266, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Recently several research projects have tried to improve file system performance in a number of other ways, including prefetching <ref> [30, 25, 7, 5, 11] </ref>, delayed writeback [21] and disk block clustering [20, 29]. Most of these papers still assume global LRU as the basic cache replacement policy, and they do not address how to use application control over replacement to improve cache hit ratio.
Reference: [8] <author> Edward G. Coffman, Jr. and Peter J. Denning. </author> <title> Operating Systems Theory. </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1973. </year>
Reference-contexts: In [3] we proposed that application replacement policies be based on the optimal replacement principle <ref> [8] </ref>, and in this paper we discussed which policies to use for our example applications. On the other hand, our work shares some common purposes with the existing work on application-controlled virtual memory. We believe that, with some minor modifications, our approach applies to virtual memory cache management as well.
Reference: [9] <author> Gregory R. Ganger and Yale N. Patt. </author> <title> The process-flow model: Examing I/O performance from the system's point of view. </title> <booktitle> In Proceedings of SIGMETRICS 1993, </booktitle> <pages> pages 86-97, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The search for better global allocation policies requires a clear definition of the goal and an examination of the interactions between caching and scheduling/management policies in other parts of the system, particularly process scheduling and disk scheduling <ref> [9] </ref>. This is a fruitful area for future work. Acknowledgements We are grateful to our paper shepherd Jay Lepreau and the anonymous referees for their valuable comments. Keith Bostic and Randy Appleton also provided help- ful feedback.
Reference: [10] <author> Jim Gray. </author> <title> The Benchmark Handbook. </title> <address> Morgen-Kaufman, San Mateo, Ca., </address> <year> 1991. </year>
Reference-contexts: We chose one query operation: a join between an indexed and a non-indexed relation, to illustrate how it can use application control on file caching. The relations are a 200,000 tuple one, twohundredk, and a 20,000 tuple one, twentyk, from a scaled-up Wisconsin benchmark <ref> [10] </ref>. The join is on field unique1, which is uniquely random within 1-200,000 in twohundredk, and uniquely random within 1-1,000,020 in twentyk. The size of twentyk is roughly 3.2MB, twohundredk 32MB, and index twohundredk unique1 5MB.
Reference: [11] <author> Jim Griffioen and Randy Appleton. </author> <title> Reducing file system latency using a predictive approach. </title> <booktitle> In Conference Proceedings of the USENIX Summer 1994 Technical Conference, </booktitle> <pages> pages 197-208, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Recently several research projects have tried to improve file system performance in a number of other ways, including prefetching <ref> [30, 25, 7, 5, 11] </ref>, delayed writeback [21] and disk block clustering [20, 29]. Most of these papers still assume global LRU as the basic cache replacement policy, and they do not address how to use application control over replacement to improve cache hit ratio.
Reference: [12] <author> Kieran Harty and David R. Cheriton. </author> <title> Application-controlled physical memory using external page-cache management. </title> <booktitle> In The Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 187-197, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: However, this interface is much more limited than ours, allowing specification of only a small number of basic patterns and no priorities. As a result, in the past few years there has been a stream of research papers on application control of caching in the virtual memory context <ref> [19, 28, 12, 16] </ref>. Our work differs from that described in these papers in three significant ways: * None of these papers (except [12]) addresses the global allocation policy problem. <p> As a result, in the past few years there has been a stream of research papers on application control of caching in the virtual memory context [19, 28, 12, 16]. Our work differs from that described in these papers in three significant ways: * None of these papers (except <ref> [12] </ref>) addresses the global allocation policy problem.
Reference: [13] <author> John L. Hennessy and David A. Patterson. </author> <title> Computer Organization & Design: The Hardware/Software Interface. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1994. </year>
Reference-contexts: only necessary call is: set_policy (0, MRU); (When there is a mix of these queries, cscope can keep or discard "cscope.out" in cache when necessary by raising or lowering its priority.) dinero [din] Dinero is a cache simulator written by Mark Hill and used in Hennessy and Patterson's architecture textbook <ref> [13] </ref>. The distribution package for the course material includes the simulator and several program trace files. We chose the "cc" trace (about 8MB) from the distribution package, and ran a set of simulations, varying the cache line size from 32 to 128 bytes, and set associativity from 1 to 4.
Reference: [14] <author> John H. Howard, Michael Kazar, Sherri G. Menees, David A. Nichols, M. Satyanarayanan, Robert N. Sidebotham, and Michael J. West. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <pages> pages 6(1) 51-81, </pages> <month> Febru-ary </month> <year> 1988. </year>
Reference-contexts: Although placeholders do not completely eliminate the harm done by foolish processes, they at least help the kernel take administrative measures to solve the problem. 7 Related Work There have been many studies on caching in file systems (e.g. <ref> [27, 4, 26, 14, 22, 15] </ref>), but these investigations were not primarily concerned with the performance impact of different replacement policies.
Reference: [15] <author> James J. Kistler and M. Satyanarayanan. </author> <title> Disconnected operation in the Coda file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <pages> pages 6(1) 1-25, </pages> <month> Febru-ary </month> <year> 1992. </year>
Reference-contexts: Although placeholders do not completely eliminate the harm done by foolish processes, they at least help the kernel take administrative measures to solve the problem. 7 Related Work There have been many studies on caching in file systems (e.g. <ref> [27, 4, 26, 14, 22, 15] </ref>), but these investigations were not primarily concerned with the performance impact of different replacement policies.
Reference: [16] <author> Keith Krueger, David Loftesness, Amin Vahdat, and Tom Anderson. </author> <title> Tools for the development of application-specific virtual memory management. </title> <booktitle> In OOPSLA '93 Conference Proceedings, </booktitle> <pages> pages 48-64, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: However, this interface is much more limited than ours, allowing specification of only a small number of basic patterns and no priorities. As a result, in the past few years there has been a stream of research papers on application control of caching in the virtual memory context <ref> [19, 28, 12, 16] </ref>. Our work differs from that described in these papers in three significant ways: * None of these papers (except [12]) addresses the global allocation policy problem.
Reference: [17] <author> Udi Manber and Sun Wu. GLIMPSE: </author> <title> A tool to search through entire file systems. </title> <booktitle> In Conference Proceedings of the USENIX Winter 1994 Technical Conference, </booktitle> <pages> pages 23-32, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Strategy: Dinero reads the trace file sequentially on each simulation. Hence the right policy is MRU on trace file and the call is: set_priority (trace, 0); set_policy (0, MRU); glimpse [gli] Glimpse is a text information retrieval system <ref> [17] </ref>. It builds approximate indexes for words to allow both relatively fast search and small index files. We took a snapshot of news articles in several comp.* newsgroups on May 22, 1994, about 40MB of texts. Then we glimpseindexed it, resulting in about 2MB of indexes. <p> Hence glimpse gives the index files long-term priority 1, and the articles the default long-term priority 0. Since index files are always accessed in the same order, and several groups of articles (called partitions <ref> [17] </ref>) are accessed in the same order, MRU is chosen for both levels. The calls are: set_priority (".glimpse_index", 1); set_priority (".glimpse_partitions", 1); set_priority (".glimpse_filenames", 1); set_priority (".glimpse_statistics", 1); set_policy (1, MRU); set_policy (0, MRU); link editor [ldk] Ld is the Ultrix link-editor.
Reference: [18] <author> M. McKusick, W. Joy, S. Le*er, and R. Fabry. </author> <title> A fast file system for UNIX. </title> <journal> ACM Transactions on Computer Systems, </journal> <month> August </month> <year> 1984. </year>
Reference-contexts: The interface is well defined, and the procedures are called with no lock held. Since BUF and ACM sit below the VFS interface, our implementation works for both UFS <ref> [18] </ref> and NFS [26]. In all our following experiments, however, we put all files on local disks to avoid impact on performance from network traffic. We believe this interface could be used if one wanted to implement two level replacement using upcalls or dropped-in-kernel "user-level handlers" [2].
Reference: [19] <author> Dylan McNamee and Katherine Armstrong. </author> <title> Extending the Mach external pager interface to accommodate user-level page replacement policies. </title> <booktitle> In Proceedings of the USENIX Association Mach Workshop, </booktitle> <pages> pages 17-29, </pages> <year> 1990. </year>
Reference-contexts: However, this interface is much more limited than ours, allowing specification of only a small number of basic patterns and no priorities. As a result, in the past few years there has been a stream of research papers on application control of caching in the virtual memory context <ref> [19, 28, 12, 16] </ref>. Our work differs from that described in these papers in three significant ways: * None of these papers (except [12]) addresses the global allocation policy problem. <p> By contrast, we discuss this problem in detail, and provide a solution, LRU-SP, which we have simulated [3] and now have implemented. * Most of these papers relied on RPC or upcalls for kernel-to-user communication, and consequently reported overhead as high as 10% of the total execution time <ref> [19, 28] </ref>. We provide a flexible interface for applications to issue primitives to exert control on cache replacement; we found that this is adequate most of the time and requires low overhead. * Most of these papers do not adequately consider which replacement policy an application should use.
Reference: [20] <author> L. W. McVoy and S. R. Kleiman. </author> <title> Extent-like performance from a UNIX file system. </title> <booktitle> In 1991 Winter USENIX, </booktitle> <pages> pages 33-43, </pages> <year> 1991. </year>
Reference-contexts: Recently several research projects have tried to improve file system performance in a number of other ways, including prefetching [30, 25, 7, 5, 11], delayed writeback [21] and disk block clustering <ref> [20, 29] </ref>. Most of these papers still assume global LRU as the basic cache replacement policy, and they do not address how to use application control over replacement to improve cache hit ratio.
Reference: [21] <author> Jeffrey C. Mogul. </author> <title> A better update policy. </title> <booktitle> In Proceedings of 1994 Summer USENIX, </booktitle> <pages> pages 99-111, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Recently several research projects have tried to improve file system performance in a number of other ways, including prefetching [30, 25, 7, 5, 11], delayed writeback <ref> [21] </ref> and disk block clustering [20, 29]. Most of these papers still assume global LRU as the basic cache replacement policy, and they do not address how to use application control over replacement to improve cache hit ratio.
Reference: [22] <author> Michael N. Nelson, Brent B. Welch, and John K. Ousterhout. </author> <title> Caching in the Sprite file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <pages> pages 6(1) 134-154, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Although placeholders do not completely eliminate the harm done by foolish processes, they at least help the kernel take administrative measures to solve the problem. 7 Related Work There have been many studies on caching in file systems (e.g. <ref> [27, 4, 26, 14, 22, 15] </ref>), but these investigations were not primarily concerned with the performance impact of different replacement policies.
Reference: [23] <author> Elizabeth J. O'Neil, Patrick E. O'Neil, and Gerhard Weikum. </author> <title> The LRU-K page replacement algorithm for database disk buffering. </title> <booktitle> In Proc. 1993 ACM-SIGMOD Conference on Management of Data, </booktitle> <pages> pages 297-306, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Our work is complementary to these approaches; in other words, with application-controlled file caching, these approaches will improve file system performance even more. The database community has long studied access patterns and buffer replacement policies <ref> [31, 6, 23] </ref>. In our experiments we used pjn (Postgres join) as an example of how database systems may use our inter face to control file caching. We believe our interface is flexible enough to implement most of the policies a database system might want to use.
Reference: [24] <author> J. K. Ousterhout, H. Da Costa, D. Harrison, J.A. Kunze, M. Kupfer, and J. G. Tompson. </author> <title> A trace-driven analysis of the UNIX 4.2 BSD file system. </title> <booktitle> In Proceedings of the Tenth Symposium on Operating Systems Principles, </booktitle> <pages> pages 15-24, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: The main design challenge is to devise an interface that allows applications to exert the control they need, without introducing the overhead that would result from a totally general mechanism. Our approach was to first consider common file access patterns reported in the literature (e.g. <ref> [24, 1, 6] </ref>) as well as patterns that we observed in the applications discussed below. We then chose a simple interface that was sufficient to compose caching strategies to support these access patterns.
Reference: [25] <author> Hugo Patterson, Garth Gibson, and M. Satya-narayanan. </author> <title> Transparent informed prefetching. </title> <booktitle> ACM Operating Systems Review, </booktitle> <pages> pages 21-34, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Recently several research projects have tried to improve file system performance in a number of other ways, including prefetching <ref> [30, 25, 7, 5, 11] </ref>, delayed writeback [21] and disk block clustering [20, 29]. Most of these papers still assume global LRU as the basic cache replacement policy, and they do not address how to use application control over replacement to improve cache hit ratio.
Reference: [26] <author> R. Sandberg, D. Boldberg, S. Kleiman, D. Walsh, and B. Lyon. </author> <title> Design and implementation of the Sun network filesystem. </title> <booktitle> In Summer Usenix Conference Proceedings, </booktitle> <pages> pages 119-130, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: The interface is well defined, and the procedures are called with no lock held. Since BUF and ACM sit below the VFS interface, our implementation works for both UFS [18] and NFS <ref> [26] </ref>. In all our following experiments, however, we put all files on local disks to avoid impact on performance from network traffic. We believe this interface could be used if one wanted to implement two level replacement using upcalls or dropped-in-kernel "user-level handlers" [2]. <p> Although placeholders do not completely eliminate the harm done by foolish processes, they at least help the kernel take administrative measures to solve the problem. 7 Related Work There have been many studies on caching in file systems (e.g. <ref> [27, 4, 26, 14, 22, 15] </ref>), but these investigations were not primarily concerned with the performance impact of different replacement policies.
Reference: [27] <author> M. D. Schroeder, D. K. Gifford, and R. M. Needham. </author> <title> A caching file system for a programmer's workstation. </title> <booktitle> ACM Operating Systems Review, </booktitle> <pages> pages 19(5) 35-50, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: Although placeholders do not completely eliminate the harm done by foolish processes, they at least help the kernel take administrative measures to solve the problem. 7 Related Work There have been many studies on caching in file systems (e.g. <ref> [27, 4, 26, 14, 22, 15] </ref>), but these investigations were not primarily concerned with the performance impact of different replacement policies.
Reference: [28] <author> Stuart Sechrest and Yoonho Park. </author> <title> User-level physical memory management for Mach. </title> <booktitle> In Proceedings of the USENIX Mach Symposium, </booktitle> <pages> pages 189-199, </pages> <year> 1991. </year>
Reference-contexts: However, this interface is much more limited than ours, allowing specification of only a small number of basic patterns and no priorities. As a result, in the past few years there has been a stream of research papers on application control of caching in the virtual memory context <ref> [19, 28, 12, 16] </ref>. Our work differs from that described in these papers in three significant ways: * None of these papers (except [12]) addresses the global allocation policy problem. <p> By contrast, we discuss this problem in detail, and provide a solution, LRU-SP, which we have simulated [3] and now have implemented. * Most of these papers relied on RPC or upcalls for kernel-to-user communication, and consequently reported overhead as high as 10% of the total execution time <ref> [19, 28] </ref>. We provide a flexible interface for applications to issue primitives to exert control on cache replacement; we found that this is adequate most of the time and requires low overhead. * Most of these papers do not adequately consider which replacement policy an application should use.
Reference: [29] <author> Margo Seltzer, Keith Bostic, Marshall Kirk McKu-sick, and Carl Staelin. </author> <title> An implementation of a log-structured file system for UNIX. </title> <booktitle> In Proceedings of 1993 Winter USENIX, </booktitle> <month> January </month> <year> 1993. </year>
Reference-contexts: Recently several research projects have tried to improve file system performance in a number of other ways, including prefetching [30, 25, 7, 5, 11], delayed writeback [21] and disk block clustering <ref> [20, 29] </ref>. Most of these papers still assume global LRU as the basic cache replacement policy, and they do not address how to use application control over replacement to improve cache hit ratio.
Reference: [30] <author> Alan Jay Smith. </author> <title> Cache memories. </title> <journal> ACM Computing Surveys, </journal> <volume> 14(3) </volume> <pages> 473-530, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: Recently several research projects have tried to improve file system performance in a number of other ways, including prefetching <ref> [30, 25, 7, 5, 11] </ref>, delayed writeback [21] and disk block clustering [20, 29]. Most of these papers still assume global LRU as the basic cache replacement policy, and they do not address how to use application control over replacement to improve cache hit ratio.
Reference: [31] <author> Michael Stonebraker. </author> <title> Operating system support for database management. </title> <journal> Communications of the ACM, v. </journal> <volume> 24, no. 7, </volume> <pages> pages 412-418, </pages> <month> July </month> <year> 1981. </year>
Reference-contexts: Our work is complementary to these approaches; in other words, with application-controlled file caching, these approaches will improve file system performance even more. The database community has long studied access patterns and buffer replacement policies <ref> [31, 6, 23] </ref>. In our experiments we used pjn (Postgres join) as an example of how database systems may use our inter face to control file caching. We believe our interface is flexible enough to implement most of the policies a database system might want to use.
References-found: 31

