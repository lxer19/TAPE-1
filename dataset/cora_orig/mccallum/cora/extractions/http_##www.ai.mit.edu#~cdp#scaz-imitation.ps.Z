URL: http://www.ai.mit.edu/~cdp/scaz-imitation.ps.Z
Refering-URL: http://www.ai.mit.edu/people/scaz/scaz.html
Root-URL: 
Email: scaz@ai.mit.edu  
Title: Imitation and Mechanisms of Shared Attention: A Developmental Structure for Building Social Skills  
Author: Brian Scassellati 
Address: 545 Technology Square Cambridge, MA, 02139, USA  
Affiliation: MIT Artificial Intelligence Lab  
Abstract: This paper explores the use of imitation in an on-going research program aimed at enabling a humanoid robot to communicate naturally with humans. Our group has constructed an upper-torso humanoid robot, called Cog, in part to investigate how to build intelligent robotic systems by following a developmental progression of skills similar to that observed in human development. Just as a child learns social skills and conventions through interactions with its parents, our robot will learn to interact with people using natural social communication. Our models of social interaction are drawn from developmental models of normal children, developmental models of autism, and on models of the evolutionary development of social skills. In this paper, we consider the role that imitation plays in the development of a critical pre-cursor of normal human social development, mechanisms of shared attention. Mechanisms of shared attention serve to direct two individuals to attend to the same object in the environment, through eye direction, pointing gestures, and other means. Imitation serves a critical role in bootstrapping a system from simple eye behaviors to more complex social skills. We will present data from a face and eye finding system that serves as the basis of this developmental chain, and a short example of how this system can imitate the head movements of an individual. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Baron-Cohen, S. </author> <year> (1995), </year> <title> Mindblindness, </title> <publisher> MIT Press. </publisher>
Reference: <author> Brooks, R. & Stein, L. A. </author> <year> (1994), </year> <title> `Building Brains for Bodies', </title> <booktitle> Autonomous Robots 1:1, </booktitle> <pages> 7-25. </pages>
Reference: <author> Brooks, R. A., Ferrell, C., Irie, R., Kemp, C. C., Mar-janovic, M., Scassellati, B. & Williamson, M. </author> <year> (1998), </year> <title> Alternative Essences of Intelligence, </title> <booktitle> in `Proceedings of the Fifteenth National Conference on Artificial Intelligence (AAAI-98)', </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: We are interested in shared attention as a precursor to social communication for two reasons. First, we believe that by using a developmental program to build social capabilities we will be able to achieve a wide range of natural interactions with untrained observers <ref> (Brooks, Ferrell, Irie, Kemp, Marjanovic, Scassellati & Williamson 1998) </ref>. Constructing a machine that can recognize the social cues from a human observer allows for more natural human-machine interaction and creates possibilities for machines to learn by directly observing untrained human instructors.
Reference: <author> Burghardt, G. M. & Greene, H. W. </author> <year> (1990), </year> <title> `Predator Simulation and Duration of Death Feigning in Neonate Hog-nose Snakes', </title> <booktitle> Animal Behaviour 36(6), </booktitle> <pages> 1842-1843. </pages>
Reference-contexts: The first step in producing mechanisms of shared attention is the recognition and maintenance of eye contact. Many animals have been shown to be extremely sensitive to eyes that are directed at them, including reptiles like the hognosed snake <ref> (Burghardt & Greene 1990) </ref>, avians like the chicken (Scaife 1976) and the plover (Ristau 1991), and all primates (Cheney & Seyfarth 1990).
Reference: <author> Butterworth, G. </author> <year> (1991), </year> <title> The Ontogeny and Phylogeny of Joint Visual Attention, </title> <editor> in A. Whiten, ed., </editor> <title> `Natural Theories of Mind', </title> <publisher> Blackwell. </publisher>
Reference: <author> Cheney, D. L. & Seyfarth, R. M. </author> <year> (1990), </year> <title> How Monkeys See the World, </title> <publisher> University of Chicago Press. </publisher>
Reference-contexts: Many animals have been shown to be extremely sensitive to eyes that are directed at them, including reptiles like the hognosed snake (Burghardt & Greene 1990), avians like the chicken (Scaife 1976) and the plover (Ristau 1991), and all primates <ref> (Cheney & Seyfarth 1990) </ref>. Identifying whether or not something is looking at you provides an obvious evolutionary advantage in escaping predators, but in many mammals, especially primates, the recognition that another is looking at you carries social significance. <p> <ref> (Cheney & Seyfarth 1990) </ref>. Identifying whether or not something is looking at you provides an obvious evolutionary advantage in escaping predators, but in many mammals, especially primates, the recognition that another is looking at you carries social significance. In monkeys, eye contact is significant for maintaining a social dominance hierarchy (Cheney & Seyfarth 1990). In humans, the reliance on eye contact as a social cue is even more striking. Infants have an innate preference for looking at human faces and eyes, and maintain (and thus recognize) eye contact within the first three months. <p> Imperative pointing is a gesture used to request an object that is out of reach by pointing at that object. This behavior is first seen in human children at about nine months of age (Baron-Cohen 1995), and occurs in many monkeys <ref> (Cheney & Seyfarth 1990) </ref>. From the child's perspective, imperative pointing is a relatively simple extension of normal reaching behavior.
Reference: <author> Diamond, A. </author> <year> (1990), </year> <title> Developmental Time Course in Human Infants and Infant Monkeys, and the Neural Bases, of Inhibitory Control in Reaching, </title> <booktitle> in `Development and Neural Bases of Higher Cognitive Functions', </booktitle> <volume> Vol. 608, </volume> <publisher> New York Academy of Sciences, </publisher> <pages> pp. 637-676. </pages>
Reference-contexts: Children pass through a developmental progression of reaching skills <ref> (Diamond 1990) </ref>. The fist stage in this progression appears around the fifth month and is characterized by a very stereotyped reach which always initiates from a position close to the child's eyes and moves ballistically along an angle of gaze directly toward the target object.
Reference: <author> Frith, U. </author> <year> (1990), </year> <title> Autism : Explaining the Enigma, </title> <publisher> Basil Blackwell. </publisher>
Reference-contexts: There are also developmental disorders, such as autism, that limit and fracture the components of this system <ref> (Frith 1990) </ref>. Additionally, this same ontological progression can be seen as an evolutionary progression in which the increasingly complex set of skills can be mapped to animals that are increasingly closer to humans on a phy-logenetic scale (Povinelli & Preuss 1995).
Reference: <author> Hauser, M. D. </author> <year> (1996), </year> <title> Evolution of Communication, </title> <publisher> MIT Press. </publisher>
Reference-contexts: From the phylogenetic perspective, declarative pointing has not been identified in any non-human primate (Premack 1988). This also corresponds to the phylogeny of imitation; no non-human primate has ever been documented to display true imitative behavior <ref> (Hauser 1996) </ref>. We propose that the child first learns to recognize the declarative pointing gestures of the adult and then imitates those gestures in order to produce declarative pointing.
Reference: <author> Hobson, R. P. </author> <year> (1993), </year> <title> Autism and the Development of Mind, </title> <publisher> Erlbaum. </publisher>
Reference-contexts: Evidence from childhood development shows that not all mechanisms for shared attention are present from birth, and there is a stereotypic progression of skills that occurs in all infants at roughly the same rate <ref> (Hobson 1993) </ref>. There are also developmental disorders, such as autism, that limit and fracture the components of this system (Frith 1990).
Reference: <author> Karmiloff-Smith, A., Klima, E., Bellugi, U., Grant, J. & Baron-Cohen, S. </author> <year> (1995), </year> <title> `Is there a social module? Language, face processing, and theory of mind in individuals with Williams Syndrome', </title> <journal> Journal of Cognitive Neuroscience 7:2, </journal> <pages> 196-208. </pages>
Reference: <author> Marjanovic, M., Scassellati, B. & Williamson, M. </author> <year> (1996), </year> <title> Self-Taught Visually-Guided Pointing for a Humanoid Robot, </title> <booktitle> in `From Animals to Animats 4: Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior (SAB-96)', </booktitle> <publisher> Bradford Books, </publisher> <pages> pp. 35-44. </pages>
Reference: <author> Povinelli, D. J. & Preuss, T. M. </author> <year> (1995), </year> <title> `Theory of mind: evolutionary history of a cognitive specialization', </title> <booktitle> Trends in Neuroscience 18(9), </booktitle> <pages> 418-424. </pages>
Reference-contexts: Additionally, this same ontological progression can be seen as an evolutionary progression in which the increasingly complex set of skills can be mapped to animals that are increasingly closer to humans on a phy-logenetic scale <ref> (Povinelli & Preuss 1995) </ref>. As the basis for our implementation of shared attention, we turn to a developmental model from Baron-Cohen (1995). <p> While many animals are sensitive to eyes that are gazing directly at them, only great apes 2 show the capability to extrapolate from the direction of gaze to a distal object <ref> (Povinelli & Preuss 1995) </ref>. This evolutionary progression is also mirrored in the ontogeny of social skills. At least by the age of three months, human infants display maintenance (and thus recognition) of eye contact. However, it is not until nine months that children gener 1995).
Reference: <author> Pratt, G. A. & Williamson, M. M. </author> <year> (1995), </year> <title> Series Elastic Actuators, </title> <booktitle> in `Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS-95)', </booktitle> <volume> Vol. </volume> <pages> 1, </pages> <address> Pittsburg, PA, </address> <pages> pp. 399-406. </pages>
Reference-contexts: The robot also has a three degree of freedom neck and a pair of human-like arms. Each arm has six compliant degrees of freedom, each of which is powered by a series elastic actuator <ref> (Pratt & Williamson 1995) </ref> which provides a sensible "natural" behavior: if it is disturbed, or hits an obstacle, the arm simply deflects out of the way.
Reference: <author> Premack, D. </author> <year> (1988), </year> <title> "Does the chimpanzee have a theory of mind?" revisited, </title> <editor> in R. Byrne & A. Whiten, eds, </editor> <booktitle> `Machiavellian Intelligence: Social Expertise and the Evolution of Intellect in Monkeys, Apes, and Humans.', </booktitle> <publisher> Oxford University Press. </publisher>
Reference-contexts: From an ontological perspective, declarative pointing begins to emerge at approximately 12 months in human infants, which is also the same time that other complex imitative behaviors such as pretend play begin to emerge. From the phylogenetic perspective, declarative pointing has not been identified in any non-human primate <ref> (Premack 1988) </ref>. This also corresponds to the phylogeny of imitation; no non-human primate has ever been documented to display true imitative behavior (Hauser 1996).
Reference: <author> Ristau, C. A. </author> <year> (1991), </year> <title> Before Mindreading: Attention, Purposes and Deception in Birds?, </title> <editor> in A. Whiten, ed., </editor> <title> `Natural Theories of Mind', </title> <publisher> Blackwell. </publisher>
Reference-contexts: Many animals have been shown to be extremely sensitive to eyes that are directed at them, including reptiles like the hognosed snake (Burghardt & Greene 1990), avians like the chicken (Scaife 1976) and the plover <ref> (Ristau 1991) </ref>, and all primates (Cheney & Seyfarth 1990). Identifying whether or not something is looking at you provides an obvious evolutionary advantage in escaping predators, but in many mammals, especially primates, the recognition that another is looking at you carries social significance.
Reference: <author> Rowley, H., Baluja, S. & Kanade, T. </author> <year> (1995), </year> <title> Human Face Detection in Visual Scenes, </title> <type> Technical Report CMU-CS-95-158, </type> <institution> Carnegie Mellon University. </institution>
Reference: <author> Scaife, M. </author> <year> (1976), </year> <title> `The response to eye-like shapes by birds. II. The importance of staring, pairedness, and shape.', </title> <booktitle> Animal Behavior 24, </booktitle> <pages> 200-206. </pages>
Reference-contexts: The first step in producing mechanisms of shared attention is the recognition and maintenance of eye contact. Many animals have been shown to be extremely sensitive to eyes that are directed at them, including reptiles like the hognosed snake (Burghardt & Greene 1990), avians like the chicken <ref> (Scaife 1976) </ref> and the plover (Ristau 1991), and all primates (Cheney & Seyfarth 1990). Identifying whether or not something is looking at you provides an obvious evolutionary advantage in escaping predators, but in many mammals, especially primates, the recognition that another is looking at you carries social significance.
Reference: <author> Scaife, M. & Bruner, J. </author> <year> (1975), </year> <title> `The capacity for joint visual attention in the infant.', </title> <booktitle> Nature 253, </booktitle> <pages> 265-266. </pages>
Reference-contexts: These abilities, collectively named mechanisms of shared (or joint) attention, are vital to the normal development of social skills in children <ref> (Scaife & Bruner 1975) </ref>. The primary focus of the research reported here is to investigate how individuals develop the skills to recognize and produce these social cues by implementing models of this developmental progression on a humanoid robot (see Figure 1).
Reference: <author> Scassellati, B. </author> <year> (1996), </year> <title> Mechanisms of Shared Attention for a Humanoid Robot, in `Embodied Cognition and Action: </title> <booktitle> Papers from the 1996 AAAI Fall Symposium', </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: The primary focus of the research reported here is to investigate how individuals develop the skills to recognize and produce these social cues by implementing models of this developmental progression on a humanoid robot (see Figure 1). A more detailed account of this project can be found in <ref> (Scassellati 1996) </ref>. We are interested in shared attention as a precursor to social communication for two reasons.
Reference: <author> Scassellati, B. </author> <year> (1998a), </year> <title> A Binocular, Foveated Active Vision System, </title> <type> Technical Report 1628, </type> <institution> MIT Artificial Intelligence Lab Memo. </institution>
Reference-contexts: With a basic repertoire of sensori-motor and perceptual skills, we can begin to construct the developmental program outlined above. The hardware platform that we use for vision is a binocular, foveated, active vision system designed to mimic some of the capabilities of the human visual system <ref> (Scassellati 1998a) </ref>. 3 To allow for both a wide field of view and high resolution vision, there are two cameras per eye, one which captures a wide-angle view of the periphery (approximately 110 ffi field of view) and one which captures a narrow-angle view of the central (foveal) area (approximately 20
Reference: <author> Scassellati, B. </author> <year> (1998b), </year> <title> Finding Eyes and Faces with a Foveated Vision System, </title> <booktitle> in `Proceedings of the Fifteenth National Conference on Artificial Intelligence (AAAI-98)', </booktitle> <publisher> AAAI Press. </publisher>
Reference: <author> Sinha, P. </author> <year> (1994), </year> <title> `Object Recognition via Image Invariants: </title>
References-found: 23

