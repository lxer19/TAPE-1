URL: ftp://ftp.cs.columbia.edu/reports/reports-1998/cucs-011-98.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1998.html
Root-URL: http://www.cs.columbia.edu
Email: fandreas,salg@cs.columbia.edu  
Title: Pruning Meta-Classifiers in a Distributed Data Mining System CUCS-032-97  
Author: Andreas L. Prodromidis Salvatore J. Stolfo 
Keyword: distributed data mining, meta-learning, classifier evaluation, machine learning, credit card fraud detection.  
Note: This research is supported by the Intrusion Detection Program (BAA9603) from DARPA (F30602-96-1-0311), NSF (IRI-96-32225 and CDA 96-25374) and NYSSTF (423115-445). Supported in part by an IBM fellowship  
Date: July 10, 1998  
Address: 1214 Amsterdam Ave. Mail Code 0401 New York, NY 10027  
Affiliation: Department of Computer Science Columbia University  
Abstract: JAM is a powerful and portable agent-based distributed data mining system that employs meta-learning techniques to integrate a number of independent classifiers (models) derived in parallel from independent and (possibly) inherently distributed databases. Although meta-learning promotes scalability and accuracy in a simple and straightforward manner, brute force meta-learning techniques can result in large, redundant, inefficient and some times inaccurate meta-classifier hierarchies. In this paper we explore several methods for evaluating classifiers and composing meta-classifiers, we expose ther limitations and we demonstrate that meta-learning combined with certain pruning methods has the potential to achieve similar or even better performance results in a much more cost effective manner. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Ali and M. Pazzani. </author> <title> Error reduction through learning multiple descriptions. </title> <booktitle> Machine Learning, </booktitle> <address> 24:173202, </address> <year> 1996. </year>
Reference-contexts: In this paper, we focus on the diversity and specialty metrics. Apart from these metrics and accuracy, correlation error and coverage have also been used to analyze and explain the properties and performance of classifiers. Ali and Pazzani <ref> [1] </ref> define as correlation error the fraction of instances for which a pair of base classifiers make the same incorrect predictions and Brodley and Lane [4] measured coverage by computing the fraction of instances for which at least one of the base classifiers produces the correct prediction. 2.1 Diversity Brodley [5] <p> of the base classifiers. (When the predictions of the classifiers are distributed evenly across the possible classes, the entropy is higher and the set of classifiers more diverse.) Kwok and Carter [16] correlate the error rates of a set of decision trees to their syntactical diversity, while Ali and Pazzani <ref> [1] </ref> studied the impact of the number of gain ties 4 on the accuracy of an ensemble of classifiers.
Reference: [2] <author> L. Breiman. </author> <title> Stacked regressions. </title> <booktitle> Machine Learning, </booktitle> <address> 24:4148, </address> <year> 1996. </year>
Reference-contexts: Before we present the metrics employed in this study, we summarize the previous and current research within the Machine Learning and KDD communities. Leo Breiman <ref> [2] </ref> and LeBlanc and Tibshirani [17] acknowledge the value of using multiple predictive models to increase accuracy, but they view the problem from a different perspective.
Reference: [3] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont, CA, </address> <year> 1984. </year>
Reference-contexts: ID3, its successor C4.5, and Cart <ref> [3] </ref> are decision tree based algorithms, Bayes, described in [11], is a naive Bayesian classifier and Ripper [9] is a rule induction algorithm.
Reference: [4] <author> C. Brodley and T. Lane. </author> <title> Creating and exploiting coverage and diversity. In Work. </title> <booktitle> Notes AAAI-96 Workshop Integrating Multiple Learned Models, </booktitle> <pages> pages 814, </pages> <year> 1996. </year>
Reference-contexts: Ali and Pazzani [1] define as correlation error the fraction of instances for which a pair of base classifiers make the same incorrect predictions and Brodley and Lane <ref> [4] </ref> measured coverage by computing the fraction of instances for which at least one of the base classifiers produces the correct prediction. 2.1 Diversity Brodley [5] defines diversity by measuring the classification overlap of a pair of classifiers, i.e. the percentage of the instances classified the same way by two classifiers
Reference: [5] <author> C.Brodley. </author> <title> Addressing the selective superiority problem: Automatic algorithm/model class selection. </title> <booktitle> In Proc. 10th Intl. Conf. Machine Learning, </booktitle> <pages> pages 1724. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: [1] define as correlation error the fraction of instances for which a pair of base classifiers make the same incorrect predictions and Brodley and Lane [4] measured coverage by computing the fraction of instances for which at least one of the base classifiers produces the correct prediction. 2.1 Diversity Brodley <ref> [5] </ref> defines diversity by measuring the classification overlap of a pair of classifiers, i.e. the percentage of the instances classified the same way by two classifiers while Chan [6] associates it with the entropy in the predictions of the base classifiers. (When the predictions of the classifiers are distributed evenly across
Reference: [6] <author> P. Chan. </author> <title> An Extensible Meta-Learning Approach for Scalable and Accurate Inductive Learning. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Columbia University, </institution> <address> New York, NY, </address> <year> 1996. </year>
Reference-contexts: by computing the fraction of instances for which at least one of the base classifiers produces the correct prediction. 2.1 Diversity Brodley [5] defines diversity by measuring the classification overlap of a pair of classifiers, i.e. the percentage of the instances classified the same way by two classifiers while Chan <ref> [6] </ref> associates it with the entropy in the predictions of the base classifiers. (When the predictions of the classifiers are distributed evenly across the possible classes, the entropy is higher and the set of classifiers more diverse.) Kwok and Carter [16] correlate the error rates of a set of decision trees
Reference: [7] <author> P. Chan and S. Stolfo. </author> <title> Meta-learning for multistrategy and parallel learning. </title> <booktitle> In Proc. Second Intl. Work. Multi-strategy Learning, </booktitle> <pages> pages 150165, </pages> <year> 1993. </year>
Reference-contexts: We call the problem of learning useful new information from large and inherently distributed databases, the scaling problem for machine learning. Meta-learning <ref> [7] </ref>, a technique similar to stacking [32], was developed recently to deal with the scaling problem.
Reference: [8] <author> P. Chan and S. Stolfo. </author> <title> Sharing learned models among remote database partitions by local meta-learning. </title> <booktitle> In Proc. Second Intl. Conf. Knowledge Discovery and Data Mining, </booktitle> <pages> pages 27, </pages> <year> 1996. </year>
Reference-contexts: Retaining a large number of base classifiers and 2 meta-classifiers may not be practical nor feasible. Meta classifiers are defined recursively as collections of classifiers structured in multi-level trees <ref> [8] </ref>, hence determining the optimal set of classifiers is a combinatorial problem. Pre-training pruning 1 refers to the filtering of the classifiers before they are used in the training of a meta-classifier.
Reference: [9] <author> W. Cohen. </author> <title> Fast effective rule induction. </title> <booktitle> In Proc. 12th Intl. Conf. Machine Learning, </booktitle> <pages> pages 115123, </pages> <year> 1995. </year>
Reference-contexts: ID3, its successor C4.5, and Cart [3] are decision tree based algorithms, Bayes, described in [11], is a naive Bayesian classifier and Ripper <ref> [9] </ref> is a rule induction algorithm. Learning tasks Two data sets of real credit card transactions were used in our experiments provided by the Chase and First Union Banks, members of the FSTC (Financial Services Technology Consortium). The two data sets contain credit card transactions labeled as fraudulent or legitimate.
Reference: [10] <author> T.G. Dietterich. </author> <title> Machine learning research: Four current directions. </title> <journal> AI Magazine, </journal> <volume> 18(4):97136, </volume> <year> 1997. </year>
Reference-contexts: The focus of this paper, however, is on evaluation methods that are suitable for multi-class problems and on metrics that provide information about the interdependencies among the base classifiers and their potential when forming ensembles of classifiers <ref> [10, 14] </ref>. In the most related work, Margineantu and Dietterich [18] studied the problem of pruning the ensemble of classifiers (i.e. the set of hypothesis (classifiers)) obtained by the boosting algorithm ADABOOST [13].
Reference: [11] <author> C. </author> <type> Elkan. </type> <institution> Boosting and naive bayesian learning [http://www-cse.ucsd.edu/~elkan/papers/bnb.ps]. Department of Computer Science and Engineering, Univ. of California, </institution> <address> San Diego, CA, </address> <year> 1997. </year>
Reference-contexts: ID3, its successor C4.5, and Cart [3] are decision tree based algorithms, Bayes, described in <ref> [11] </ref>, is a naive Bayesian classifier and Ripper [9] is a rule induction algorithm. Learning tasks Two data sets of real credit card transactions were used in our experiments provided by the Chase and First Union Banks, members of the FSTC (Financial Services Technology Consortium).
Reference: [12] <author> E.R.Carson and U.Fischer. </author> <title> Models and computers in diabetes research and diabetes care. Computer methods and programs in biomedicine, </title> <journal> special issue, </journal> <volume> 32, </volume> <year> 1990. </year>
Reference-contexts: Over the past decade, machine learning has evolved from a field of laboratory demonstrations to a field of significant commercial value [22]. Machine-learning algorithms have been deployed in heart disease diagnosis [29], in predicting glucose levels for diabetic patients <ref> [12] </ref>, in detecting credit card fraud [30], in steering vehicles driving autonomously on public highways at 70 miles an hour [24], in predicting stock option pricing [23], in computing customizing electronic newspapers [15] etc.
Reference: [13] <author> Y. Freund and R. Schapire. </author> <title> Experiments with a new boosting algorithm. </title> <booktitle> In Proc. Thirteenth Conf. Machine Learning, </booktitle> <pages> pages 148156, </pages> <year> 1996. </year>
Reference-contexts: In the most related work, Margineantu and Dietterich [18] studied the problem of pruning the ensemble of classifiers (i.e. the set of hypothesis (classifiers)) obtained by the boosting algorithm ADABOOST <ref> [13] </ref>. According to their findings, by examining the diversity and accuracy of the available classifiers, it is possible for a subset of classifiers to achieve similar levels of performance as the entire set. <p> For example, to obtain diverse classifiers from a single learning program Freund and Schapire <ref> [13] </ref> introduced a sophisticate algorithm for sampling the data set to artificially generate diverse training subsets. In our experiments, the diversity of the base classifiers is attributed, first, on the use of disparate learning algorithms, and second, on the degree the training sets are different.
Reference: [14] <author> L. Hansen and P. Salamon. </author> <title> Neural network ensembles. </title> <journal> IEEE Trans. Pattern Analysis and Mach. Itell., </journal> <volume> 12:993 1001, </volume> <year> 1990. </year>
Reference-contexts: The focus of this paper, however, is on evaluation methods that are suitable for multi-class problems and on metrics that provide information about the interdependencies among the base classifiers and their potential when forming ensembles of classifiers <ref> [10, 14] </ref>. In the most related work, Margineantu and Dietterich [18] studied the problem of pruning the ensemble of classifiers (i.e. the set of hypothesis (classifiers)) obtained by the boosting algorithm ADABOOST [13].
Reference: [15] <author> K.Lang. </author> <title> News weeder: Learning to filter net news. </title> <editor> In A.Prieditis and S.Russel, editors, </editor> <booktitle> Proc. 12th Intl. Conf. Machine Learning, </booktitle> <pages> pages 331339. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1995. </year>
Reference-contexts: Machine-learning algorithms have been deployed in heart disease diagnosis [29], in predicting glucose levels for diabetic patients [12], in detecting credit card fraud [30], in steering vehicles driving autonomously on public highways at 70 miles an hour [24], in predicting stock option pricing [23], in computing customizing electronic newspapers <ref> [15] </ref> etc. Many large business institutions and market analysis firms attempt to distinguish the low-risk (high profit) potential customers by learn simple categorical classifications of their potential customer data base.
Reference: [16] <author> S. Kwok and C. Carter. </author> <title> Multiple decision trees. </title> <booktitle> In Uncertainty in Aritificial Intelligence 4, </booktitle> <pages> pages 327335, </pages> <year> 1990. </year>
Reference-contexts: instances classified the same way by two classifiers while Chan [6] associates it with the entropy in the predictions of the base classifiers. (When the predictions of the classifiers are distributed evenly across the possible classes, the entropy is higher and the set of classifiers more diverse.) Kwok and Carter <ref> [16] </ref> correlate the error rates of a set of decision trees to their syntactical diversity, while Ali and Pazzani [1] studied the impact of the number of gain ties 4 on the accuracy of an ensemble of classifiers.
Reference: [17] <author> M. LeBlanc and R. Tibshirani. </author> <title> Combining estimates in regression and classification. </title> <type> Technical Report 9318, </type> <institution> Department of Statistics, University of Toronto, Toronto, ON, </institution> <year> 1993. </year>
Reference-contexts: Before we present the metrics employed in this study, we summarize the previous and current research within the Machine Learning and KDD communities. Leo Breiman [2] and LeBlanc and Tibshirani <ref> [17] </ref> acknowledge the value of using multiple predictive models to increase accuracy, but they view the problem from a different perspective.
Reference: [18] <author> D. Margineantu and T. Dietterich. </author> <title> Pruning adaptive boosting. </title> <booktitle> In Proc. Fourteenth Intl. Conf. Machine Learning, </booktitle> <pages> pages 211218, </pages> <year> 1997. </year>
Reference-contexts: The focus of this paper, however, is on evaluation methods that are suitable for multi-class problems and on metrics that provide information about the interdependencies among the base classifiers and their potential when forming ensembles of classifiers [10, 14]. In the most related work, Margineantu and Dietterich <ref> [18] </ref> studied the problem of pruning the ensemble of classifiers (i.e. the set of hypothesis (classifiers)) obtained by the boosting algorithm ADABOOST [13].
Reference: [19] <author> C. Merz. </author> <title> Using correspondence analysis to combine classifiers. </title> <booktitle> Machine Learning, </booktitle> <year> 1998. </year>
Reference-contexts: Meta-learning has the advantage of searching for more complex and non-linear relations among the classifiers, at the expense of generating less intuitive representations. In a related study, Merz's SCAN N algorithm <ref> [19] </ref> employs correspondence analysis 2 to map the predictions of the available classifiers onto a new scaled space that clusters similar prediction behaviors and then uses the nearest neighbor algorithm to meta-learn the transformed predictions of the individual classifiers.
Reference: [20] <author> R. Michalski. </author> <title> A theory and methodology of inductive learning. </title> <editor> In R. Michalski, J. Carbonell, and T. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> pages 83134. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1983. </year>
Reference-contexts: Similarly, defense and intelligence operations utilize similar methodologies on vast information sources to predict a wide range of conditions in various contexts. Machine learning or Inductive learning (or learning from examples <ref> [20] </ref>) aims to identify regularities in a given set of training examples with little or no knowledge about the domain from which the examples are drawn.
Reference: [21] <author> T. Mitchell. </author> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18:203226, </volume> <year> 1982. </year>
Reference-contexts: Meta-Learning, is scalable because meta-classifiers are classifiers themselves that can be further combined into higher level meta-classifiers by employing meta-learning in a similar manner. Furthermore, it improves accuracy by combining different learning systems each having different inductive bias (e.g representation, search heuristics, search space) <ref> [21] </ref>. By combining separately learned classifiers, meta-learning is expected to derive a higher level learned model that explains a large database more accurately than any of the individual learners. The J AM system (Java Agents for Meta-learning) [31] is a distributed agent-based data mining system that implements meta-learning.
Reference: [22] <author> Tom M. Mitchell. </author> <title> Does machine learning really work? AI Magazine, </title> <address> 18(3):1120, </address> <year> 1997. </year>
Reference-contexts: Over the past decade, machine learning has evolved from a field of laboratory demonstrations to a field of significant commercial value <ref> [22] </ref>.
Reference: [23] <author> M.Malliaris and L.Salchenberger. </author> <title> A neural network model for estimating option prices. </title> <journal> Applied Intelligence, </journal> <volume> 3(3):193206, </volume> <year> 1993. </year>
Reference-contexts: Machine-learning algorithms have been deployed in heart disease diagnosis [29], in predicting glucose levels for diabetic patients [12], in detecting credit card fraud [30], in steering vehicles driving autonomously on public highways at 70 miles an hour [24], in predicting stock option pricing <ref> [23] </ref>, in computing customizing electronic newspapers [15] etc. Many large business institutions and market analysis firms attempt to distinguish the low-risk (high profit) potential customers by learn simple categorical classifications of their potential customer data base.
Reference: [24] <author> D. Pomerleau. </author> <title> Neural network perception for mobile robot guidance. </title> <type> PhD thesis, </type> <institution> School of Computer Sci., Carnegie Mellon Univ., </institution> <address> Pittsburgh, PA, </address> <year> 1992. </year> <type> (Tech. Rep. </type> <institution> CMU-CS-92-115). </institution>
Reference-contexts: Machine-learning algorithms have been deployed in heart disease diagnosis [29], in predicting glucose levels for diabetic patients [12], in detecting credit card fraud [30], in steering vehicles driving autonomously on public highways at 70 miles an hour <ref> [24] </ref>, in predicting stock option pricing [23], in computing customizing electronic newspapers [15] etc. Many large business institutions and market analysis firms attempt to distinguish the low-risk (high profit) potential customers by learn simple categorical classifications of their potential customer data base.
Reference: [25] <author> A. L. Prodromidis. </author> <title> On the management of distributed learning agents. </title> <type> Technical Report CUCS-032-97 (PhD Thesis proposal), </type> <institution> Department of Computer Science, Columbia University, </institution> <address> New York, NY, </address> <year> 1997. </year>
Reference-contexts: Provost and Fawcett [26] introduced the ROC convex hull method for its intuitiveness and flexibility. The method evaluates models for binary classification problems, by mapping them onto a True Positive/False Negative plane and 1 As opposed to post-training pruning <ref> [25] </ref> which denotes the evaluation and revision/pruning of the meta-classifier after it is computed. 2 Very similar to Principal Component Analysis 3 Although the transformed predictions may be mapped on a new scaled space of lower dimension than the original (i.e the number of base classifiers), SCANN still needs all base-classifiers
Reference: [26] <author> F. Provost and T. Fawcett. </author> <title> Anaylysis and visualization of classifier performance: Comparison under imprecise class and cost distributions. </title> <booktitle> In Proc. Third Intl. Conf. Knowledge Discovery and Data Mining, </booktitle> <pages> pages 4348, </pages> <year> 1997. </year>
Reference-contexts: On the other hand, the pruning methods presented in this paper precede the meta-learning phase and, as such, can be used in conjunction with SCAN N or any other algorithm. Provost and Fawcett <ref> [26] </ref> introduced the ROC convex hull method for its intuitiveness and flexibility. <p> In comparing the classifiers, one can replace the T P F P spread, which defines a certain family of curves in the ROC plot, with a different metric or even with a complete analysis <ref> [26] </ref> in the ROC space. 8 to evaluate base classifiers; instead it combines them in a random order, i.e. when they become available.
Reference: [27] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <booktitle> Machine Learning, </booktitle> <address> 1:81106, </address> <year> 1986. </year>
Reference: [28] <author> J. R. Quinlan. C4.5: </author> <title> programs for machine learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference: [29] <author> R.Detrano, A.Janosi, W.Steinbrunn, M.Pfisterer, J.Schmid, S.Sandhu, K.Guppy, S.Lee, and V.Froelicher. </author> <title> International application of a new probability algorithm for the diagnosis of coronary artery disease. </title> <journal> American Journal of Cardiology, </journal> <volume> 64:304310, </volume> <year> 1989. </year>
Reference-contexts: Over the past decade, machine learning has evolved from a field of laboratory demonstrations to a field of significant commercial value [22]. Machine-learning algorithms have been deployed in heart disease diagnosis <ref> [29] </ref>, in predicting glucose levels for diabetic patients [12], in detecting credit card fraud [30], in steering vehicles driving autonomously on public highways at 70 miles an hour [24], in predicting stock option pricing [23], in computing customizing electronic newspapers [15] etc.
Reference: [30] <author> S. Stolfo, W. Fan, W. Lee, A. Prodromidis, and P. Chan. </author> <title> Credit card fraud detection using meta-learning: Issues and initial results. </title> <booktitle> Working notes of AAAI Workshop on AI Approaches to Fraud Detection and Risk Management, </booktitle> <year> 1997. </year>
Reference-contexts: Over the past decade, machine learning has evolved from a field of laboratory demonstrations to a field of significant commercial value [22]. Machine-learning algorithms have been deployed in heart disease diagnosis [29], in predicting glucose levels for diabetic patients [12], in detecting credit card fraud <ref> [30] </ref>, in steering vehicles driving autonomously on public highways at 70 miles an hour [24], in predicting stock option pricing [23], in computing customizing electronic newspapers [15] etc. <p> For example, one possible approach would be to combine the (base-) classifiers with high coverage and low correlation error. In another study <ref> [30] </ref> concerning credit card fraud detection we employ evaluation formulas for selecting classifiers that are based on characteristics such as diversity, coverage and correlated error or their combinations, i.e. True Positive rate and diversity.
Reference: [31] <author> S. Stolfo, A. Prodromidis, S. Tselepis, W. Lee, W. Fan, and P. Chan. </author> <title> JAM: Java agents for meta-learning over distributed databases. </title> <booktitle> In Proc. 3rd Intl. Conf. Knowledge Discovery and Data Mining, </booktitle> <pages> pages 7481, </pages> <year> 1997. </year>
Reference-contexts: By combining separately learned classifiers, meta-learning is expected to derive a higher level learned model that explains a large database more accurately than any of the individual learners. The J AM system (Java Agents for Meta-learning) <ref> [31] </ref> is a distributed agent-based data mining system that implements meta-learning.
Reference: [32] <author> D. Wolpert. </author> <title> Stacked generalization. Neural Networks, </title> <address> 5:241259, </address> <year> 1992. </year>
Reference-contexts: We call the problem of learning useful new information from large and inherently distributed databases, the scaling problem for machine learning. Meta-learning [7], a technique similar to stacking <ref> [32] </ref>, was developed recently to deal with the scaling problem. The basic idea is to execute a number of machine learning processes on a number of data subsets in parallel, and then 1 to combine their collective results (classifiers) through an additional phase of learning.
References-found: 32

