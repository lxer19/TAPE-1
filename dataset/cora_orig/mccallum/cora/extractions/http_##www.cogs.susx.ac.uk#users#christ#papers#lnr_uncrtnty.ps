URL: http://www.cogs.susx.ac.uk/users/christ/papers/lnr_uncrtnty.ps
Refering-URL: http://www.cogs.susx.ac.uk/users/christ/index-noframes.html
Root-URL: 
Email: Email: Chris.Thornton@cogs.susx.ac.uk  
Title: A Definition of Learner Uncertainty  
Author: Chris Thornton 
Date: June 9, 1993  
Address: Brighton BN1 9QN  
Affiliation: Cognitive and Computing Sciences University of Sussex  
Abstract: The paper considers the quantification of inductive bias in concept learning. It argues that some of the best known measures of bias (eg. Vapnik-Chervonenkis dimension) are context-free in the sense that they measure the effectiveness of bias in general, rather than with respect to a particular problem. This approach has many advantages but in cases where we want to evaluate the performance of a particular algorithm on a particular problem we need a context-sensitive measure, ie. a way of measuring bias that takes into account the characteristics of the relevant problem. The paper describes a generalization of the ID3 `information-needed' concept that provides such a measure. It also shows how the measure can be used to predict learning performance in simple concept learning experiments.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Mitchell, T. </author> <year> (1980). </year> <title> The need for bias in learning generalizations. </title> <type> Technical Report CBM-TR-117, </type> <institution> Dept. of Computer Science, Rutgers University. </institution>
Reference-contexts: 1 Introduction In general, learning mechanisms require some background knowledge in order to be able to operate successfully <ref> [1] </ref>. However, when we are trying to evaluate the performance of a given learner on a given task, we need to know how much of the generated solution is due to the algorithm and how much to the background knowledge.
Reference: [2] <author> Lenat, D. and Brown, J. </author> <year> (1984). </year> <title> Why AM and EURISKO appear to work. </title> <journal> Artificial Intelligence, </journal> <volume> 23, No. </volume> <pages> 3 (pp. 269-294). </pages>
Reference-contexts: In particular, we want to be able to decide whether the solution provided by the learner is implicitly contained in the background knowledge since in this case no real learning would have taken place. <ref> [2] </ref> In the familiar case of concept learning it is conventional to think of the learner 1 as searching through a space of hypotheses for one that satisfies the constraints 1 imposed by the training set [3].
Reference: [3] <author> Rendell, L. </author> <year> (1986). </year> <title> A general framework for induction and a study of selective induction. </title> <journal> Machine Learning, </journal> <volume> 1, No. </volume> <pages> 1 (pp. 177-226). </pages>
Reference-contexts: the background knowledge since in this case no real learning would have taken place. [2] In the familiar case of concept learning it is conventional to think of the learner 1 as searching through a space of hypotheses for one that satisfies the constraints 1 imposed by the training set <ref> [3] </ref>. In this model, the only way background knowledge can affect the learning is by causing the learner to prefer certain hypotheses over others, ie. by causing it to search the space of hypotheses in a directed way.
Reference: [4] <author> Haussler, D. </author> <year> (1987). </year> <title> Bias, version spaces and valiant's learning framework. </title> <booktitle> Proceedings of the Fourth International Workshop on Machine Learning (pp. </booktitle> <pages> 324-336). </pages> <institution> University of California, Irvine: </institution> <month> (June 22-25). </month>
Reference: [5] <author> Haussler, D. </author> <year> (1988). </year> <title> Quantifying inductive bias: AI learning and valiant's learning framework. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 36 (pp. 177-221). 11 </pages>
Reference: [6] <author> Haussler, D. </author> <year> (1990). </year> <title> Probably approximately correct learning. </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence. </booktitle> <volume> Vol. </volume> <pages> Two, </pages> <address> Cam-bridge, Mass.: MIT Press (July 29 1990-Aug 3 1990). </address>
Reference-contexts: Haussler has proposed various other ways of quantifying the bias but the VC dimension measure has significant attractions. Not only does it provide us with a single, numeric value but it also enables performance and learnability bounds to be derived for a number of learning algorithms <ref> [6] </ref>. 3 Context-free versus context-sensitive bias mea sures As we noted, in Haussler's analysis the measures of bias are context free.
Reference: [7] <author> Valiant, L. </author> <year> (1984). </year> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <pages> 27 (pp. 1134-42). </pages>
Reference: [8] <author> Valiant, L. </author> <year> (1985). </year> <title> Learning disjunctions of conjunctions. </title> <booktitle> Proceedings of the Ninth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 560-566). </pages> <address> Los Altos: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [9] <author> Vapnik, V. and Chervonenkis, A. </author> <year> (1971). </year> <title> On the uniform convergence of relative frequencies of events to their probabilities. </title> <journal> Theor. Probab. Appl., </journal> <volume> 16, No. </volume> <pages> 2 (pp. 264-280). </pages>
Reference-contexts: A general framework that enables us to quantify inductive bias has been provided by Haussler [4,5,6]. This framework makes use of the PAC learning model of Valiant [7,8] and the concept of the VC (Vapnik-Chervonenkis) dimension <ref> [9] </ref>. A remarkable attribute of Haussler's framework is that it is essentially `context-free'. It allows us to quantify the inductive bias of an algorithm in general, rather than with respect to some specific problem.
Reference: [10] <author> Haussler, D., Kearns, M. and Schapire, R. </author> <year> (1992). </year> <title> Bounds on the sample complexity of bayesian learning using information theory and the VC dimension. </title> <institution> UCSC-CRL-91-44, University of California at Santa Cruz. </institution>
Reference: [11] <author> Quinlan, J. </author> <year> (1983). </year> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In R. Michalski, J. Carbonell and T. Mitchell (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <address> Palo Alto: </address> <publisher> Tioga. </publisher>
Reference-contexts: The information theoretic heuristic is applied at the point where an attribute must be selected on which to split the instances at a given leaf node. The essential idea is that an ideal split should create a set of child nodes whose average information deficit 5 is minimized <ref> [11] </ref>. The information deficit of node X is simply the amount of information required to produce a true classification of an arbitrary instance that currently classifies at X.
Reference: [12] <author> Quinlan, J. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <booktitle> Machine Learning, </booktitle> <pages> 1 (pp. 81-106). </pages>
Reference-contexts: The information measures have been used for various purposes in machine learning. But here we focus on the way in which Quinlan used information theory in formulating the splitting heuristic of the ID3 learning algorithm <ref> [12] </ref>. In ID3 decision trees are constructed by repeatedly splitting the available instances on the features of selected attributes. The information theoretic heuristic is applied at the point where an attribute must be selected on which to split the instances at a given leaf node.
Reference: [13] <author> Sejnowski, T. and Rosenberg, C. </author> <year> (1987). </year> <title> Parallel networks that learn to pronounce english text. </title> <journal> Complex Systems, </journal> <pages> 1 (pp. 145-68). </pages>
Reference-contexts: We often want to know whether the performance involves learning, or is, in fact, a trivial consequence of the available background knowledge. The very real nature of this problem is demonstrated by the controversies that have raged over the learning feats of such as the NETtalk system <ref> [13] </ref> and the AM and EURISKO systems [14,15]. There are a number of ways in which we might try to derive a context-sensitive measure of bias. The one described here is based on information theory and has been derived as a generalization of the standard method for computing information deficits.
Reference: [14] <author> Lenat, D. </author> <year> (1982). </year> <title> AM: discovery in mathematics as heuristic search. </title> <editor> In R. Davis and D.B. Lenat (Eds.), </editor> <booktitle> Knowledge-Based Systems in Artificial Intelligence (pp. </booktitle> <pages> 1-225). </pages> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference: [15] <author> Lenat, D. </author> <year> (1983). </year> <title> Theory formation by heuristic search; the nature of heuristics II: background and examples. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 21 (pp. 31-59). </pages>
Reference: [16] <author> Shannon, C. and Weaver, W. </author> <year> (1949). </year> <title> The Mathematical Theory of Information. </title> <institution> Urbana: University of Illinois Press. </institution>
Reference-contexts: The mathematical basis of the measure is Shannon's information formula. In its most basic form, this states that the amount of information contained in any message (or in general, any event) is inversely and logarithmically related to the a priori probability of that message <ref> [16] </ref>.
Reference: [17] <author> Mackay, D. </author> <year> (1969). </year> <title> Information, Mechanism and Meaning. </title> <publisher> London: MIT Press. </publisher>
Reference-contexts: then Haussler's approach can be used. 4 Here, I is the information content and P i is the a priori probability of the ith message. 3 In the case where there is no fixed a priori probability, it is appropriate to use the probability as it appears to the receiver <ref> [17] </ref>. The meaning of the equation is roughly summarised by saying that the amount of information is equal to the receiver's uncertainty that the message in question will be received.
Reference: [18] <author> Watanabe, S. </author> <year> (1969). </year> <title> Knowing and Guessing: A Quantitative Study of Inference and Information. </title> <address> New York: </address> <publisher> Wiley. </publisher> <pages> 12 </pages>
Reference-contexts: The uncertainty is defined by the entropy equation: 4 i=1 given that n X P i = 1 This measures the overall uncertainty (or expected surprise) with respect to a forthcoming message <ref> [18] </ref>. The information measures have been used for various purposes in machine learning. But here we focus on the way in which Quinlan used information theory in formulating the splitting heuristic of the ID3 learning algorithm [12].
References-found: 18

