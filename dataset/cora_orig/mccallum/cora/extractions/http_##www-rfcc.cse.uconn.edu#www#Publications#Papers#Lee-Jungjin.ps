URL: http://www-rfcc.cse.uconn.edu/www/Publications/Papers/Lee-Jungjin.ps
Refering-URL: http://www-rfcc.cse.uconn.edu/www/Recognition.html
Root-URL: 
Email: jjl@cse.uconn.edu and robert@cse.uconn.edu  
Phone: Phone: 203-486-0005 Fax:  
Title: User Modelling in A Flexible and Robust Interface  
Author: Jung-Jin Lee and Robert McCartney 
Keyword: Intelligent Interface, Plan Recognition, User Modeling  
Address: Storrs, CT 06269-3155, U.S.A  203-486-4817  
Affiliation: Department of Computer Science and Engineering University of Connecticut  
Abstract: The field of Human Computer Interaction (HCI) proposes several kinds of models for predicting aspects of user's behavior. Although these models deal with user's behavior with interactive computer systems, they do so rather poorly. HCI should be designed to be versatile enough to handle a broad range of interactions between a man and a machine, rather than depending on a pre-defined user model. A goal in HCI is to develop cooperative systems: for a system to cooperate with a user, it must be able to determine what the user is trying to accomplish, that is, it must recognize user plans. For a system to exhibit the intelligence required in a dialogue with a user it needs the ability to understand and reply properly to a wide range of responses. Additionally, if a system fully participates in a dialogue, it can support ad hoc requests from a user, maintain the topic of discourse, and keep a user from digressing out of the subject. Toward this goal of participation, we focus on handling a user's answer to a question posed by a system. The adaptability of a system is essential when the interaction between a user and the system is a dialogue. To be flexible and incremental, a system should be able to adapt itself by reconstituting a plan. We use meta-rules as a strategy of controlling an irregular discourse; these can be applied to unexpected responses from a user to analyze if the responses are incomplete, ambiguous, or inexact in relation to the expectation. Further adaptability in the system is provided by the process of plan creation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Barr. </author> <title> Meta-knowlege and memory. heuristic programming project. </title> <type> HPP Technical Report 77-37, </type> <institution> Department of Computer Science, Stanford University, </institution> <address> Palo Alto, CA, </address> <year> 1977. </year>
Reference-contexts: The ideal system needs to handle the expectation failure based on "the extent and limit of available knowledge, what facts are relevant in a given situation, how dependable they are, and how they are to be used" <ref> [1] </ref>. This supports the use of meta-rules. 4.1 Task-Oriented Plans PIUM starts with an initial set of three task-oriented plans. Without having a rich set of user models, it is guided by knowing where it lacks knowledge and where a user has a misunderstanding.
Reference: [2] <author> R. Calistri-Yeh. </author> <title> Utilizing user models to handle ambiguity and misconceptions in robust plan recognition. User Modeling and User-Adapted Interaction, </title> <journal> Special Issue on Plan Recognition, </journal> <year> 1991. </year>
Reference-contexts: A simplicity constraint is applied to minimize the TLAs and propagates down the hierarchies. Their work runs under the closed world assumptions, such as complete action hierarchies and all actions are purposeful. Calistri <ref> [2] </ref> executes a plan recognition process with modified A* algorithm through a plan hierarchy. His algorithm takes one observed action and a plan hierarchy in an AND/OR tree, and searches for a path to find a top-level goal, while trying to deal with violated plans and ill-formed plans.
Reference: [3] <author> S. Carberry. </author> <title> A Model of plan recognition that facilitates default inferences. </title> <booktitle> In Proc. of the Second International Workshop on User Modeling, </booktitle> <pages> pages 1-13, </pages> <address> Honolulu, HI, </address> <year> 1990. </year>
Reference-contexts: Although his work requires no closed world assumptions, it has no means to choose one plan over the others among multiple possible plans, a shortcoming shared with Kautz's work. Work has been performed to create intelligent interfaces. [7], [12], and [13] . Carberry <ref> [3] </ref> advocates the need of dynamic construction of a plan for an analysis of naturally occurring dialogue. For dynamic plan recognition, the system uses a tree structure called a context 1 model to represent the system's beliefs about the user's plan through the dialogue.
Reference: [4] <author> S. Carberry. </author> <title> Plan recognition in natural language. In Plan Recognitio in Natural Language. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Toward this goal of participation, we focus on handling a user's answer to a question posed by a system. By its nature, a dialogue-capable interface needs to be modeled dynamically <ref> [4] </ref>. The adaptability of a system is essential when the interaction between a user and the system is a dialogue. To be flexible and incremental, a system should be able to adapt itself by reconstituting a plan.
Reference: [5] <author> E. Charniak and R. Goldman. </author> <title> A Bayesian model of plan recognition. </title> <journal> Artificial Intelligence, </journal> <volume> 64(1) </volume> <pages> 53-79, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: As an unexpected success may occur when the system predicts that the plan will fail, learning based only on generalized explanation of failures may lead to overly pessimistic prediction. Charniak and Goldman presents a Bayesian model of plan recognition, <ref> [5] </ref> and argue that the problem of plan recognition is largely a problem of inference under conditions of uncertainty. The key of their model is a set of rules for translating plan recognition problems into Bayesian networks. It uses a marker-passing scheme as a focusing mechanism.
Reference: [6] <author> S. Chien and G. DeJong. </author> <title> Recognizing prevention in plans for explanation-based learning. </title> <year> 1988. </year>
Reference-contexts: They claim that their system never overcommits in recognizing the user's plan so that backtracking for debugging dialogue is unnecessary. However, it still runs under the closed world assumptions of a complete plan library and user correctness. Chien and DeJong <ref> [6] </ref> postulate that a new problem-solving concept is learned through observing, explaining and generalizing an expert's solution. The system detects learning opportunities, constructs an explanation of the expert's solution to the particular problem, and generalizes the explanation of the observed solution.
Reference: [7] <author> D. Chin. KNOME: </author> <title> Modeling what the user knows in uc. </title> <booktitle> In In User Models in Dialog Systems. </booktitle> <address> Springer-Verlog, New York, NY, </address> <year> 1989. </year>
Reference-contexts: Although his work requires no closed world assumptions, it has no means to choose one plan over the others among multiple possible plans, a shortcoming shared with Kautz's work. Work has been performed to create intelligent interfaces. <ref> [7] </ref>, [12], and [13] . Carberry [3] advocates the need of dynamic construction of a plan for an analysis of naturally occurring dialogue. For dynamic plan recognition, the system uses a tree structure called a context 1 model to represent the system's beliefs about the user's plan through the dialogue. <p> TAILOR [13] uses information about a user's level of expertise to combine several discourse strategies in a single text in order to generate texts for users. The user models of the user's expertise is used to tailor a reply to the user's question. KNOME <ref> [7] </ref> is the user modeling component of Unix Consultant (UC). It models a user's knowledge to tailor the responses through the interaction with a user. <p> However, considering the problems in both of these models <ref> [7] </ref>, leads to the point that the ideal system needs to combine the best of both. Based on this idea, PIUM uses an open world model as it serves, while it starts with a closed world model.
Reference: [8] <author> G. Collins. </author> <title> Plan creation. In In Inside Case-based Reasoning. </title> <publisher> Lawrence Erlbaum, </publisher> <year> 1989. </year>
Reference-contexts: We use meta-rules as a strategy of controlling an irregular discourse; these can be applied to unexpected responses from a user to analyze if the responses are incomplete, ambiguous, or inexact in relation to the expectation. Further adaptability in the system is provided by the process of plan creation <ref> [8] </ref> which enhances the plan library over time. 2 Related Work Our system called PIUM (Plan-based Interface Using Meta-rules) [11] is an initiative interface, that is, an interface that actively participates in a dialogue. <p> Plan Creation (as mentioned in item 4 and 5 of the motivating example) is similar to Collins' work <ref> [8] </ref>. In the situation in item 4 a target's location is in Massachusetts and a caller's location is unknown. This causes a plan failure and presents a possible linkage to plan 2 or plan 3 (Appendix A).
Reference: [9] <author> B. Goodman and D. Litman. </author> <title> On the Interaction between plan recognition and intelligent interfaces. </title> <booktitle> User Modeling and User-Adapted Interaction, </booktitle> <volume> 2 </volume> <pages> 83-116, </pages> <year> 1992. </year>
Reference: [10] <author> H. Kautz. </author> <title> A Formal theory of plan recognition and its implementation. </title> <booktitle> In Reasoning about Plans, </booktitle> <pages> pages 69-125. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: The work of PIUM encompasses the research of mainstream plan recognition and user modeling: providing more intelligent interfaces for interactive environments. Work has been done addressing problem-solving in plan recognition. Kautz and Allen <ref> [10] </ref> used a graph search algorithm for this process. The algorithm is based on an action taxonomy, an exhaustive description of the ways for actions to be performed. Their algorithm works by taking observations and chaining up the abstraction and decomposition hierarchy until a top-level action (TLA) is reached.
Reference: [11] <author> J.J. Lee. </author> <title> The use of meta-rules to enhance plan-based discourse modeling. </title> <type> Technical report, </type> <institution> Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, </institution> <year> 1992. </year>
Reference-contexts: Further adaptability in the system is provided by the process of plan creation [8] which enhances the plan library over time. 2 Related Work Our system called PIUM (Plan-based Interface Using Meta-rules) <ref> [11] </ref> is an initiative interface, that is, an interface that actively participates in a dialogue. The work of PIUM encompasses the research of mainstream plan recognition and user modeling: providing more intelligent interfaces for interactive environments. Work has been done addressing problem-solving in plan recognition. <p> These are for the purpose of controlling the plan application. How the meta rules can be utilized is explained in following examples. Due to space constraints, an example of an actual run will be shown later in an Appendix B. For more information, see <ref> [11] </ref>. Here is an example of hypothesizing intention using above meta rule. CALLER : Amherst INFORMATION : Amherst, MA ? 4 DEFAULT PLAN (Plan-1) Assumption : The caller's target resides at Connecticut.
Reference: [12] <author> J. Moore and W. Swartout. </author> <title> Pointing: A way toward explanation dialogue. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> Boston, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: Although his work requires no closed world assumptions, it has no means to choose one plan over the others among multiple possible plans, a shortcoming shared with Kautz's work. Work has been performed to create intelligent interfaces. [7], <ref> [12] </ref>, and [13] . Carberry [3] advocates the need of dynamic construction of a plan for an analysis of naturally occurring dialogue. For dynamic plan recognition, the system uses a tree structure called a context 1 model to represent the system's beliefs about the user's plan through the dialogue. <p> It also maintains a model of the user's knowledge and deduces individual facts about what the user does or does not know, then combines the evidence to adjust the likelihood ratings for its expertise level. A reactive method <ref> [12] </ref> to an explanation process is proposed with the information concerning the goal structure of the explanation, assumptions made during its generation, and alternative strategies for follow-up questions. Most work has been done in a single particular domain, which requires a specific knowledge base and user models.
Reference: [13] <author> C. Paris. </author> <title> The Use of explicit user models in a generation system for tailoring answers to the user's level of expertise. </title> <booktitle> In In User Models in Dialog Systems. </booktitle> <address> Springer-Verlog, New York, NY, </address> <year> 1989. </year>
Reference-contexts: Although his work requires no closed world assumptions, it has no means to choose one plan over the others among multiple possible plans, a shortcoming shared with Kautz's work. Work has been performed to create intelligent interfaces. [7], [12], and <ref> [13] </ref> . Carberry [3] advocates the need of dynamic construction of a plan for an analysis of naturally occurring dialogue. For dynamic plan recognition, the system uses a tree structure called a context 1 model to represent the system's beliefs about the user's plan through the dialogue. <p> Dynamically computed preference rules using Dempster-Shafer methods are used to rank alternative conclusions according to plausibility. A great deal of research on intelligent interfaces has been in the domain of discourse-based consultants. TAILOR <ref> [13] </ref> uses information about a user's level of expertise to combine several discourse strategies in a single text in order to generate texts for users. The user models of the user's expertise is used to tailor a reply to the user's question.
Reference: [14] <author> K. Schmidt R. Cohen and P. van Beek. </author> <title> A Framework for soliciting clarification from users during plan recognition. </title> <booktitle> In Proceedings of Fourth International Conference on User Modeling, </booktitle> <pages> pages 11-17, </pages> <address> Hyannis, MA, </address> <year> 1994. </year> <month> 13 </month>
Reference-contexts: Moreover, most work does not keep track of a user's level of expertise and change its judgment of that level, even though the user's expertise may increase as time goes by. Cohen et al. <ref> [14] </ref> use plan recognition to improve responses to users in an advice-giving setting. In their work, to improve dialogue coherence, they characterize when to engage a user in clarification dialogue with a default strategy and provide options to reduce the length of the clarification dialogue.
Reference: [15] <author> D. Shin. Lk: </author> <title> A language for capturing real world meanings of the stored data. </title> <booktitle> In Proc. of the International Conference on Data Engineering, </booktitle> <pages> pages 738-745, </pages> <address> Kobe, Japan, </address> <year> 1991. </year> <month> 14 </month>
Reference-contexts: pending plan once it is chosen. 5.3 Meta rule Representation The representation language used for meta rules is a predicate logic that associates predicates and events in the Lk language form which attempts to combine the advantages of the foundations of a formal logic with the structural flexibility of frames <ref> [15] </ref>. A meta rule in PIUM consists of a representations of situations and a handling strategy. Each meta rule includes what PIUM knows about a current situation, how PIUM will handle this situation, and what PIUM knows as possible side effects.
References-found: 15

