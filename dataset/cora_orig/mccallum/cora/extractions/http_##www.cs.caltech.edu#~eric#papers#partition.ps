URL: http://www.cs.caltech.edu/~eric/papers/partition.ps
Refering-URL: http://www.cs.caltech.edu/~eric/papers/papers.html
Root-URL: http://www.cs.caltech.edu
Email: eric@cs.caltech.edu  
Title: Partition-Based Uniform Error Bounds  
Author: Eric Bax 
Keyword: Key words machine learning, learning theory, error bounds, validation, Vapnik-Chervonenkis.  
Address: Pasadena, CA 91125  
Affiliation: Computer Science Dept. California Institute of Technology 256-80  
Abstract: This paper develops probabilistic bounds on out-of-sample error rates for several classifiers using a single set of in-sample data. The bounds are based on probabilities over partitions of the union of in-sample and out-of-sample data into in-sample and out-of-sample data sets. The bounds apply when in-sample and out-of-sample data are drawn from the same distribution. Partition-based bounds are stronger than VC-type bounds, but they require more computation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Abu-Mostafa, </author> <title> What you need to know about the VC Inequality, Class notes from CS156, </title> <institution> California Institute of Technology, </institution> <year> 1996. </year>
Reference-contexts: However, the VC bounds can be adapted to our framework with examples drawn i.i.d. <ref> [1] </ref>. Likewise, the partition-based bounds can be adapted to a framework with an infinite set of classifiers [4]. To compare VC bounds to bounds B M (*) and B fl M (*), let us first review a derivation of VC bounds for our framework [1]. <p> our framework with examples drawn i.i.d. <ref> [1] </ref>. Likewise, the partition-based bounds can be adapted to a framework with an infinite set of classifiers [4]. To compare VC bounds to bounds B M (*) and B fl M (*), let us first review a derivation of VC bounds for our framework [1]. Recall that there are d in-sample examples and n d out-of-sample examples, drawn i.i.d. from the underlying distribution. For a single classifier, let w be a random variable representing the number of the n drawn examples for which the classifier errs.
Reference: [2] <author> E. Bax, Z. Cataltepe, and J. Sill, </author> <title> Alternative error bounds for the classifier chosen by early stopping, </title> <booktitle> Proc. IEEE Pacific Rim Conf. on Communications, Computers, and Signal Processing, </booktitle> <address> Victoria, B.C., Canada. </address> (1997):811-814. 
Reference-contexts: Introduction Partition-based bounds have been used in several contexts <ref> [2, 3, 4, 5] </ref>. This paper focuses on the bounds themselves, developing them through illustrative examples. Initially, we outline our machine-learning framework. Then we use the classic probability model of drawing colored marbles from a jar to develop a partition-based error bound for a single classifier. <p> We have also exhibited a scenario in which partition-based bounds apply directly. For fur ther applications of these results and tests on real-world data, refer to <ref> [2, 3, 4, 5] </ref>. Acknowledgements Thanks to Dr. Yaser Abu-Mostafa for his teaching. This paper was inspired by ideas from his course on learning theory. Thanks to Dr. Joel Franklin for his advice and encouragement.
Reference: [3] <author> E. Bax, </author> <title> Validation of voting committees, </title> <note> to appear in Neural Computation. </note>
Reference-contexts: Introduction Partition-based bounds have been used in several contexts <ref> [2, 3, 4, 5] </ref>. This paper focuses on the bounds themselves, developing them through illustrative examples. Initially, we outline our machine-learning framework. Then we use the classic probability model of drawing colored marbles from a jar to develop a partition-based error bound for a single classifier. <p> For example, if, for some person, the first two tests indicate radiation exposure but the third test does not, then the person corresponds to either a green-green-red marble or a red-red-green marble, depending on the (unknown) outcome of the expensive test. For details, see <ref> [3, 5] </ref>. This idea of using information about the out-of-sample data set to improve the bound is inspired by recent work by Vapnik [8], in which learning is based on out-of-sample inputs as well as in-sample data. <p> We have not proven that the direct partition-based bound B M (*) is superior to the VC bound B V C M (*), but it has been observed empirically that B 1 (*) is generally less than B V C 1 (*) <ref> [3] </ref>. Hence, M B 1 (*) is generally less than B V C M (*). This is convenient because it is easier to compute B M (*) than B fl M (*). For applications of mixed bounds involving B M (*) to real-world data, refer to [5]. <p> We have also exhibited a scenario in which partition-based bounds apply directly. For fur ther applications of these results and tests on real-world data, refer to <ref> [2, 3, 4, 5] </ref>. Acknowledgements Thanks to Dr. Yaser Abu-Mostafa for his teaching. This paper was inspired by ideas from his course on learning theory. Thanks to Dr. Joel Franklin for his advice and encouragement.
Reference: [4] <author> E. Bax, </author> <title> Similar classifiers and VC error bounds, </title> <publisher> CalTech-CS-TR-97-14. </publisher>
Reference-contexts: Introduction Partition-based bounds have been used in several contexts <ref> [2, 3, 4, 5] </ref>. This paper focuses on the bounds themselves, developing them through illustrative examples. Initially, we outline our machine-learning framework. Then we use the classic probability model of drawing colored marbles from a jar to develop a partition-based error bound for a single classifier. <p> However, the VC bounds can be adapted to our framework with examples drawn i.i.d. [1]. Likewise, the partition-based bounds can be adapted to a framework with an infinite set of classifiers <ref> [4] </ref>. To compare VC bounds to bounds B M (*) and B fl M (*), let us first review a derivation of VC bounds for our framework [1]. Recall that there are d in-sample examples and n d out-of-sample examples, drawn i.i.d. from the underlying distribution. <p> We have also exhibited a scenario in which partition-based bounds apply directly. For fur ther applications of these results and tests on real-world data, refer to <ref> [2, 3, 4, 5] </ref>. Acknowledgements Thanks to Dr. Yaser Abu-Mostafa for his teaching. This paper was inspired by ideas from his course on learning theory. Thanks to Dr. Joel Franklin for his advice and encouragement.
Reference: [5] <author> E. Bax, </author> <title> Improved uniform test error bounds, </title> <publisher> CalTech-CS-TR-97-15. </publisher>
Reference-contexts: Introduction Partition-based bounds have been used in several contexts <ref> [2, 3, 4, 5] </ref>. This paper focuses on the bounds themselves, developing them through illustrative examples. Initially, we outline our machine-learning framework. Then we use the classic probability model of drawing colored marbles from a jar to develop a partition-based error bound for a single classifier. <p> Then B M (*) is a partition-based bound for the probability that the out-of-sample error rate exceeds the in sample error rate by at least * for some classifier. Meth ods to compute and bound B M (*) are given in <ref> [5] </ref>. The i.i.d. Framework A Concrete Example Suppose we have a very expensive, but completely accurate, test for long-term exposure to low levels of radiation. Our budget only allows us to use the test on 200 people. We have hired 3 contractors to develop affordable tests. <p> For example, if, for some person, the first two tests indicate radiation exposure but the third test does not, then the person corresponds to either a green-green-red marble or a red-red-green marble, depending on the (unknown) outcome of the expensive test. For details, see <ref> [3, 5] </ref>. This idea of using information about the out-of-sample data set to improve the bound is inspired by recent work by Vapnik [8], in which learning is based on out-of-sample inputs as well as in-sample data. <p> Also, more intensive computation can be used to compute stronger bounds. For example, the sum bound can be applied to union bounds for pairs of classifiers <ref> [5] </ref>: B fl M B fl We refer to bounds of this form as mixed bounds. <p> Hence, M B 1 (*) is generally less than B V C M (*). This is convenient because it is easier to compute B M (*) than B fl M (*). For applications of mixed bounds involving B M (*) to real-world data, refer to <ref> [5] </ref>. The partition-based bounds have their roots in the reasoning behind the VC bound. The derivation of the original VC bound [9], p. 270, involves a special case of the partition-based bound B 1 (*) in which the out-of-sample and in-sample data sets have the same sizes. <p> We have also exhibited a scenario in which partition-based bounds apply directly. For fur ther applications of these results and tests on real-world data, refer to <ref> [2, 3, 4, 5] </ref>. Acknowledgements Thanks to Dr. Yaser Abu-Mostafa for his teaching. This paper was inspired by ideas from his course on learning theory. Thanks to Dr. Joel Franklin for his advice and encouragement.
Reference: [6] <author> W. Hoeffding, </author> <title> Probability inequalities for sums of bounded random variables, </title> <journal> Am. Stat. Assoc. J., </journal> <volume> 58 </volume> (1963):13-30. 
Reference-contexts: The in-sample error rate is k d , and the out-of-sample error rate is wk nd . Let p ; be the expected error rate over the entire distribution, i.e., the probability that the classifier errs for an example drawn at random. By Hoeffding's bound <ref> [6, 7] </ref>, Prfp ; k + *g e 2* 2 d (20) Prf n d Combine these two probabilities to bound the proba bility that the out-of-sample error rate exceeds the in sample error rate by at least *.
Reference: [7] <author> V. N. Vapnik, </author> <title> Estimation of Dependences Based on Empirical Data p.31, </title> <publisher> Springer-Verlag New York, Inc. </publisher> <year> 1982. </year>
Reference-contexts: Next, we outline a scenario in which the partition-based bounds apply directly. Then, we compare partition-based bounds to VC-style bounds <ref> [7, 9] </ref>. Machine-Learning Framework Our machine-learning framework has the following structure. There is an unknown boolean-valued target function and a distribution over its input space. <p> Comparison to VC Bounds The Vapnik-Chervonenkis bounds <ref> [7, 9] </ref> are the standard error bounds of learning theory. The VC bounds are designed for a slightly different framework than the one used in this paper, a framework that allows an infinite set of classifiers and has the goal of estimating the expected error rate over the input distribution. <p> The in-sample error rate is k d , and the out-of-sample error rate is wk nd . Let p ; be the expected error rate over the entire distribution, i.e., the probability that the classifier errs for an example drawn at random. By Hoeffding's bound <ref> [6, 7] </ref>, Prfp ; k + *g e 2* 2 d (20) Prf n d Combine these two probabilities to bound the proba bility that the out-of-sample error rate exceeds the in sample error rate by at least *.
Reference: [8] <author> V. N. Vapnik, </author> <title> The Nature of Statistical Learning Theory, </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address> <year> 1995. </year>
Reference-contexts: For details, see [3, 5]. This idea of using information about the out-of-sample data set to improve the bound is inspired by recent work by Vapnik <ref> [8] </ref>, in which learning is based on out-of-sample inputs as well as in-sample data. Direct Application of Partition-Based Bounds Now we outline a scenario in which the partition-based bounds apply directly. Suppose we are starting a small mail-order company. We have a database of 10,200 prospective customers.
Reference: [9] <author> V. N. Vapnik and A. Chervonenkis, </author> <title> On the uniform convergence of relative frequencies of events to their probabilities, </title> <journal> Theory Prob. Appl., </journal> <volume> 16(1971) </volume> <pages> 264-280. </pages>
Reference-contexts: Next, we outline a scenario in which the partition-based bounds apply directly. Then, we compare partition-based bounds to VC-style bounds <ref> [7, 9] </ref>. Machine-Learning Framework Our machine-learning framework has the following structure. There is an unknown boolean-valued target function and a distribution over its input space. <p> Comparison to VC Bounds The Vapnik-Chervonenkis bounds <ref> [7, 9] </ref> are the standard error bounds of learning theory. The VC bounds are designed for a slightly different framework than the one used in this paper, a framework that allows an infinite set of classifiers and has the goal of estimating the expected error rate over the input distribution. <p> For applications of mixed bounds involving B M (*) to real-world data, refer to [5]. The partition-based bounds have their roots in the reasoning behind the VC bound. The derivation of the original VC bound <ref> [9] </ref>, p. 270, involves a special case of the partition-based bound B 1 (*) in which the out-of-sample and in-sample data sets have the same sizes.
References-found: 9

