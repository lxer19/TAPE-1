URL: ftp://coast.cs.purdue.edu/pub/COAST/papers/ivan-krsul/krsul-thesis-proposal.ps
Refering-URL: http://www.cs.purdue.edu/coast/coast-library.html
Root-URL: http://www.cs.purdue.edu
Email: krsul@cs.purdue.edu  
Title: Computer Vulnerability Analysis  
Author: Ivan Krsul 
Degree: Thesis Proposal  
Date: April 15, 1997  
Address: West Lafayette, IN 47907-1398  
Affiliation: The COAST Laboratory Department of Computer Sciences Purdue University  
Pubnum: Technical Report CSD-TR-97-026  
Abstract: Computer security professionals and researchers do not have a history of sharing and analyzing computer vulnerability information. Scientists and engineers from older or more established fields have long understood that publicizing, analyzing, and learning from other people's mistakes is essential to the stepwise refinement of complex systems. Computer scientists, however, have not followed suit. Programmers reinvent classical programming mistakes, contributing to the reappearance of known vulnerabilities. In the recent past, computer systems have come to be a part of critical systems that have a direct effect on the safety and well-being of human beings and hence we must have lower tolerance for software failures. In the dissertation I will attempt to show that computer vulnerability information presents important regularities and these can be detected, and possibly visualized, providing important insight about the reason of their prevalence and existence. The information derived from these observations could be used to improve on all phases of the development of software systems, as could be in the design, development, debugging, testing and maintenance of complex computer systems that must implement a set of policies defined by security analysis. A significant portion of the work that must be performed will concentrate on the development of classifications and taxonomies that will permit the visualization and analysis of computer vulnerability information. I hope that these classifications and taxonomies applied to a collection of vulnerabilities will provide a set of features whose analysis will show that there are clear statistical clusterings and patterns caused because developers and programmers are not learning from each others mistakes. This analysis may be performed by applying statistical analysis and knowledge discovery tools.
Abstract-found: 1
Intro-found: 1
Reference: [A + 76] <author> R.P. Abbott et al. </author> <title> Security Analysis and Enhancements of Computer Operating Systems. </title> <type> Technical Report NBSIR 76-1041, </type> <institution> Institute for Computer Science and Technology, National Bureau of Standards, </institution> <year> 1976. </year>
Reference-contexts: have dealt with the issue of identifying and classifying software faults, including the Protection Analysis (PA) Project which conducted research on protection errors in operating systems [CBP75, BPC75]; the RISOS project that was aimed at understanding security problems in existing operating systems and to suggest ways to enhance their security <ref> [A + 76] </ref>; the paper published by Carl Landwehr (et al.) in which he published a collection of security flaws in different operating systems and classified each flaw according to its genesis, or the time it was introduced into the system, or the section of code where each flaw was introduced
Reference: [act96] <institution> The Microsoft Active Platform Overview. </institution> <note> http://www.microsoft.com/ActiveX/, October 1996. </note>
Reference-contexts: Also, a working definition of a vulnerability based on explicit policies is particularly difficult in technologies such as Microsoft's ActiveX [Gar96]. Systems running ActiveX, either as part of Microsoft's proposed Active Desktop <ref> [act96] </ref> or as part of the Microsoft Explorer WWW browser, 5 dynamically download binary executables from the Internet without verifying that their execution satisfies the policies for the system in which it will run.
Reference: [AKS96a] <author> Taimur Aslam, Ivan Krsul, and Eugene Spafford. </author> <title> Use of A Taxonomy of Security Faults. </title> <booktitle> In 19th National Information Systems Security Conference Proceedings, </booktitle> <address> Baltimore, MD, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: intrusion detection work done by Kumar et al. at the COAST laboratory, that concludes that vulnerabilities can be grouped together in generic classes described by patterns [KS94, KS95b, Kum95, KS95a, CDE + 96]; and the vulnerability classification work done by Aslam and Krsul that provides a taxonomy of security faults <ref> [Asl95, AKS96a] </ref>; Ross Anderson collected and analyzed vulnerability information for automatic teller machine (ATM) cryptosystems [And94] and concluded that designers of automatic teller machines (ATM) cryptosystems failed to understand the real threat model because vulnerability information is not collected, published and analyzed. <p> This should be a powerful incentive for the development of a freely available vulnerability database that could be used to learn from other people's mistakes. Many articles in the literature make similar arguments for the need of publicly available data collections and analysis tools <ref> [And94, Asl95, AKS96a, Pol] </ref>: computer programmers are not learning from their mistakes and we do not have tools that allow us to understand why this is the case. The last few years have seen a surge in interest for the design and maintenance of vulnerability databases. <p> The ability to perform these operations is of importance in the prevention of the exploitation of unknown (but familiar) vulnerabilities. In <ref> [Asl95, AKS96a] </ref> Aslam and Krsul explore the development of a classification scheme that can aid in the understanding of software faults that can subvert security mechanisms. <p> The Aslam classification was designed by Taimur Aslam and later refined by Ivan Krsul at the COAST laboratory <ref> [AKS96a] </ref>. * Coding Faults * Synchronization errors * Timing window/Race condition: A fault can be exploited because of a timing window between two operations. * Improper serialization: A fault results from improper serialization of operations. * Atomicity: Did the error occur when partially-modified data structures were observed by another process? Did
Reference: [AKS96b] <author> Taimur Aslam, Ivan Krsul, and Eugene Spafford. </author> <title> Use of a taxonomy of security faults. </title> <type> Technical Report TR-96-051, </type> <institution> Purdue University, Department of Computer Sciences Purdue University West Lafayette, </institution> <note> IN 47907-1398, </note> <month> September </month> <year> 1996. </year> <month> 20 </month>
Reference-contexts: Does a mechanism for detecting the exploitation of the vulnerability exist? Test. Does a mechanism exist for detecting a vulnerability in a particular system? Patch. Does a patch exist for the vulnerability? 11 Exploit. Does an exploit script exist for the vulnerability? Aslam Classification. The Aslam et al. classification <ref> [AKS96b] </ref>. System Category. To what system component does the vulnerability belong to? Software Metrics. A number of software metrics collected from the vulnerable systems might be useful includ ing: Program Complexity . System Call Usage. The use of several notorious system calls in programs that contain vulnerabilities. Programming Language.
Reference: [And94] <author> Ross Anderson. </author> <title> Why Cryptosystems Fail. </title> <type> Technical report, </type> <institution> University Computer Laboratory, Cam--bridge, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: developers have been repairing vulnerabilities in their products for many years, only a few researchers are beginning to understand that vulnerability analysis is an essential process in the step-wise refinement of software products. 1 Traditional sciences and engineering have a long history in the analysis of vulnerabilities of complex systems <ref> [Per84, Sch94, And94, Pet85, LS92] </ref>. For example, the aerospace industry has a long record of recovering vulnerability information from incidents, storing this information and finding regularities or patterns and incorporating their findings into production systems, making each subsequent product safer than the preceding one. <p> vulnerabilities can be grouped together in generic classes described by patterns [KS94, KS95b, Kum95, KS95a, CDE + 96]; and the vulnerability classification work done by Aslam and Krsul that provides a taxonomy of security faults [Asl95, AKS96a]; Ross Anderson collected and analyzed vulnerability information for automatic teller machine (ATM) cryptosystems <ref> [And94] </ref> and concluded that designers of automatic teller machines (ATM) cryptosystems failed to understand the real threat model because vulnerability information is not collected, published and analyzed. <p> This should be a powerful incentive for the development of a freely available vulnerability database that could be used to learn from other people's mistakes. Many articles in the literature make similar arguments for the need of publicly available data collections and analysis tools <ref> [And94, Asl95, AKS96a, Pol] </ref>: computer programmers are not learning from their mistakes and we do not have tools that allow us to understand why this is the case. The last few years have seen a surge in interest for the design and maintenance of vulnerability databases. <p> Already in 1975 Frederick Brooks wrote in his book The Mythical Man-Month that "Since software construction is inherently a systems effort-an exercise in complex interrelationships-communication effort is great, and it quickly dominates the decrease in individual task time brought about by partitioning." [Jr.95] In "Why Cryptosystems Fail" <ref> [And94] </ref>, Ross Anderson writes the following about this topic: "When an aircraft crashes, it is front page news. <p> The same argument can be made in the design of airplanes, bridges, nuclear power plants, or any complex system where it is virtually impossible to design a correct system from scratch <ref> [Pet85, Jr.95, Sch94, Per84, Dor96, And94] </ref>. As Confucius said: "If you wish to control the future, study the past" [bri95].
Reference: [Asl95] <author> Taimur Aslam. </author> <title> A Taxonomy of Security Faults in the Unix Operating System. </title> <type> Master's thesis, </type> <institution> Purdue University, </institution> <year> 1995. </year>
Reference-contexts: intrusion detection work done by Kumar et al. at the COAST laboratory, that concludes that vulnerabilities can be grouped together in generic classes described by patterns [KS94, KS95b, Kum95, KS95a, CDE + 96]; and the vulnerability classification work done by Aslam and Krsul that provides a taxonomy of security faults <ref> [Asl95, AKS96a] </ref>; Ross Anderson collected and analyzed vulnerability information for automatic teller machine (ATM) cryptosystems [And94] and concluded that designers of automatic teller machines (ATM) cryptosystems failed to understand the real threat model because vulnerability information is not collected, published and analyzed. <p> This should be a powerful incentive for the development of a freely available vulnerability database that could be used to learn from other people's mistakes. Many articles in the literature make similar arguments for the need of publicly available data collections and analysis tools <ref> [And94, Asl95, AKS96a, Pol] </ref>: computer programmers are not learning from their mistakes and we do not have tools that allow us to understand why this is the case. The last few years have seen a surge in interest for the design and maintenance of vulnerability databases. <p> The ability to perform these operations is of importance in the prevention of the exploitation of unknown (but familiar) vulnerabilities. In <ref> [Asl95, AKS96a] </ref> Aslam and Krsul explore the development of a classification scheme that can aid in the understanding of software faults that can subvert security mechanisms. <p> A byproduct of my research is a vulnerability database that is substantially better than the previous collection of vulnerabilities that resulted from the work done by Taimur Aslam for his masters thesis <ref> [Asl95] </ref>. As of this writing, the database consists of several fields that can be of types text, list, or hierarchical classifier. Text fields are free format and can include any information. Values for list fields are limited to codes defined in a field definition file. <p> However, for more complex vulnerabilities this may be a time consuming and error prone task. What is really needed is a classification mechanism that allows us to unequivocally group similar vulnerabilities together. In trying to address this particular issue, Taimur Aslam <ref> [Asl95] </ref> worked on a taxonomy of security faults in the Unix operating system. This work includes a classification scheme, based on a binary decision tree, that allows such grouping of vulnerabilities. Many of these classifications are rough indications of the kinds of problems that make intrusions possible.
Reference: [aut96] <institution> Microsoft Authenticode Technology. </institution> <note> http://www.microsoft.com/intdev/security/misf8-f.htm, 1996. </note>
Reference-contexts: Microsoft argues that it's Authenticode Technology guarantees the authenticity of software as <ref> [aut96] </ref> explains: "Today's web sites provide not only a rich experience for users but also the possibility of unwittingly downloading malicious code. With increasingly active content on the Internet, end users often must decide whether or not to download code over the Internet.
Reference: [BB96] <author> Matt Bishop and Dave Bailey. </author> <title> A Critical Analysis of Vulnerability Taxonomies. </title> <type> Technical Report CSE-96-11, </type> <institution> Department of Computer Science at the University of California at Davis, </institution> <month> September </month> <year> 1996. </year>
Reference-contexts: Unfortunately, there is widespread disagreement on the precise definition of the term "computer vulnerabilitiy." Consider, for example, the following three widely accepted definitions: 1. In <ref> [BB96] </ref> Matt Bishop and Dave Bailey give the following definition of computer vulnerability: 2 "A computer system is composed of states describing the current configuration of the entities that make up the computer system. The system computes through the application of state transitions that change the state of the system.
Reference: [BD96] <author> Matt Bishop and Michael Dilger. </author> <title> Checking for Race Conditions in File Accesses. </title> <journal> Computing Systems, </journal> <volume> 9(2) </volume> <pages> 131-152, </pages> <year> 1996. </year>
Reference-contexts: It is connected with an inborn propensity to lookout for regularities, or with a need to find regularities..." [Pop69] There are a few instances of researchers who have indeed attempted to find such regularities in computer vulnerabilities, including the vulnerability analysis project at the University of California at Davis <ref> [BD96] </ref> and the vulnerability classification efforts by Matt Bishop at the University of California at Davis [Bis95], both of which are used to develop generic vulnerability detection mechanisms; the intrusion detection work done by Kumar et al. at the COAST laboratory, that concludes that vulnerabilities can be grouped together in generic
Reference: [Bis95] <author> Matt Bishop. </author> <title> A Taxonomy of UNIX System and Network Vulnerabilities. </title> <type> Technical Report CSE-95-10, </type> <institution> Department of Computer Science at the University of California at Davis, </institution> <year> 1995. </year>
Reference-contexts: to find regularities..." [Pop69] There are a few instances of researchers who have indeed attempted to find such regularities in computer vulnerabilities, including the vulnerability analysis project at the University of California at Davis [BD96] and the vulnerability classification efforts by Matt Bishop at the University of California at Davis <ref> [Bis95] </ref>, both of which are used to develop generic vulnerability detection mechanisms; the intrusion detection work done by Kumar et al. at the COAST laboratory, that concludes that vulnerabilities can be grouped together in generic classes described by patterns [KS94, KS95b, Kum95, KS95a, CDE + 96]; and the vulnerability classification work <p> It is unfortunate that policies are often not stated explicitly during the development of software systems and when they are specified they are often ambiguous. 3 Consider the first definition given above and it's application to a well known and documented vulnerability--the xterm log vulnerability in Unix systems <ref> [KS95a, KS95b, CDE + 96, Bis95] </ref>. The xterm program runs as root and is tricked into changing the ownership of an arbitrary file to that of the current user.
Reference: [Bla93] <author> Matt Blaze. </author> <title> A Cryptographic File System for Unix. </title> <booktitle> In Proceedings of the First ACM Conference on Computer and Communications Security, </booktitle> <pages> pages 9 - 16, </pages> <address> Fairfax, VA, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: Values for list fields are limited to codes defined in a field definition file. Similarly, values for hierarchical classifiers are limited to codes defined in hierarchical field definition file. The vulnerability database can be found in /homes/krsul/security/vulner. This directory must be mounted as a Cryptographic File System <ref> [Bla93] </ref> before it can be used. Applications and tables related to the database can be found in /homes/krsul/security/vdbase. We will refer to this directory as the $VAPP directory. Library files including field definitions and lists and classifiers are in the $VAPP/lib directory.
Reference: [BPC75] <author> Richard Bibsey, Gerald Popek, and Jim Carlstead. </author> <title> Inconsistency of a Single Data Value over time. </title> <type> Technical report, </type> <institution> Information Sciences Institute,University of Southern California, </institution> <month> December </month> <year> 1975. </year>
Reference-contexts: Several projects have dealt with the issue of identifying and classifying software faults, including the Protection Analysis (PA) Project which conducted research on protection errors in operating systems <ref> [CBP75, BPC75] </ref>; the RISOS project that was aimed at understanding security problems in existing operating systems and to suggest ways to enhance their security [A + 76]; the paper published by Carl Landwehr (et al.) in which he published a collection of security flaws in different operating systems and classified each
Reference: [Bre94] <author> Leo Breiman. </author> <title> Bagging predictors. </title> <type> Technical Report TR 421, </type> <institution> Department of Statistics, University of California, </institution> <month> September </month> <year> 1994. </year>
Reference-contexts: If we have 30 features in the state space, we must have at least 60-90 samples. After reviewing some of the machine learning literature <ref> [WK91, DH73, Qui86, QCJ, Bre94, FS96] </ref> we can provide an initial estimation of the number of samples and number of features that will be needed: approximately 100-200 samples and 20-30 features. 6.2 Feature Indentification A feature for a computer vulnerability is characteristic or metric of the vulnerability, it's exploitation, and the
Reference: [bri95] <author> Encyclopedia Britannica, </author> <note> Fifteenth Edition. Encyclopedia Britannica Online version 1.2, </note> <year> 1995. </year>
Reference-contexts: As Confucius said: "If you wish to control the future, study the past" <ref> [bri95] </ref>. Accordingly, a fundamental contribution from my work will be the organization of past vulnerability data into a state space where the classification of vulnerabilities (i.e. for each vulnerability assigning values to each of the dimensions of the space) is repeatable.
Reference: [CBP75] <author> Jim Carlstead, Richard Bibsey II, and Gerald Popek. </author> <title> Pattern-directed protection evaluation. </title> <type> Technical report, </type> <institution> Information Sciences Institute,University of Southern California, </institution> <month> June </month> <year> 1975. </year>
Reference-contexts: Several projects have dealt with the issue of identifying and classifying software faults, including the Protection Analysis (PA) Project which conducted research on protection errors in operating systems <ref> [CBP75, BPC75] </ref>; the RISOS project that was aimed at understanding security problems in existing operating systems and to suggest ways to enhance their security [A + 76]; the paper published by Carl Landwehr (et al.) in which he published a collection of security flaws in different operating systems and classified each
Reference: [CDE + 96] <author> Mark Crosbie, Bryn Dole, Todd Ellis, Ivan Krsul, and Eugene Spafford. </author> <title> IDIOT Users Guide. </title> <type> Technical Report TR-96-050, </type> <institution> Purdue University, </institution> <month> September </month> <year> 1996. </year>
Reference-contexts: efforts by Matt Bishop at the University of California at Davis [Bis95], both of which are used to develop generic vulnerability detection mechanisms; the intrusion detection work done by Kumar et al. at the COAST laboratory, that concludes that vulnerabilities can be grouped together in generic classes described by patterns <ref> [KS94, KS95b, Kum95, KS95a, CDE + 96] </ref>; and the vulnerability classification work done by Aslam and Krsul that provides a taxonomy of security faults [Asl95, AKS96a]; Ross Anderson collected and analyzed vulnerability information for automatic teller machine (ATM) cryptosystems [And94] and concluded that designers of automatic teller machines (ATM) cryptosystems failed <p> It is unfortunate that policies are often not stated explicitly during the development of software systems and when they are specified they are often ambiguous. 3 Consider the first definition given above and it's application to a well known and documented vulnerability--the xterm log vulnerability in Unix systems <ref> [KS95a, KS95b, CDE + 96, Bis95] </ref>. The xterm program runs as root and is tricked into changing the ownership of an arbitrary file to that of the current user. <p> IDIOT patterns are encodings of vulnerabilities as Colored Petri Nets that encode the transitions that a typical vulnerability (from a class of similar vulnerabilities) takes. Development of a pattern implies detailed working knowledge of the problem and of the structure of the system being analyzed. For example, <ref> [CDE + 96, KS95a, KS94, Kum95] </ref> all describe in detail a pattern to detect the exploitation of a famous xterm log bug: The problem is that a user could create only one end of a named pipe and run xterm requesting that it create a log with the same filename as
Reference: [Den83] <author> Dorothy Denning. </author> <title> Cryptography and Data Security. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1983. </year>
Reference-contexts: In her book "Cryptography and Data Security", Dorothy Denning states that an access control policy specifies the authorized accesses of a system and gives the following definitions of system states and policies <ref> [Den83] </ref>: The state of a system is defined by a triple (S; O; A), where: 1. S is a set of subjects, which are the active entities of the model. Subjects are also considered to be objects; thus S O. 2.
Reference: [DH73] <author> Richard Duda and Peter Hart. </author> <title> Pattern classification and scene analysis. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: These are assumed to be a good representation of the true population. Another useful insight regarding the size of the state space is the rule that learning systems need samples that must exceed two to three times the number of features <ref> [DH73] </ref>. If we have 30 features in the state space, we must have at least 60-90 samples. <p> If we have 30 features in the state space, we must have at least 60-90 samples. After reviewing some of the machine learning literature <ref> [WK91, DH73, Qui86, QCJ, Bre94, FS96] </ref> we can provide an initial estimation of the number of samples and number of features that will be needed: approximately 100-200 samples and 20-30 features. 6.2 Feature Indentification A feature for a computer vulnerability is characteristic or metric of the vulnerability, it's exploitation, and the
Reference: [Dor96] <author> Dietrich Dorner. </author> <title> The Logic of Failure. </title> <publisher> Metropolitan Books, </publisher> <year> 1996. </year>
Reference-contexts: In "The logic of failure," Dietrich Dorner <ref> [Dor96] </ref> points out that complex systems that fail often have four characteristics that make them specially prone to failure: complexity, intransparence 3 , internal dynamics, and incomplete or incorrect understanding of the system. <p> The same argument can be made in the design of airplanes, bridges, nuclear power plants, or any complex system where it is virtually impossible to design a correct system from scratch <ref> [Pet85, Jr.95, Sch94, Per84, Dor96, And94] </ref>. As Confucius said: "If you wish to control the future, study the past" [bri95].
Reference: [Eis97] <author> Marc Eisenstadt. </author> <title> My hariest bug war stories. </title> <journal> Communications of the ACM, </journal> <volume> 40(4), </volume> <month> April </month> <year> 1997. </year>
Reference-contexts: and causes This classifier was originally defined from a talk given by Tom Longstaff [Lon97] and attempts to identify the origins of the vulnerability. * Lack of training * Procedures not followed * Problem re-introduced * Bug fix not propagated * Inconsistent specifications * Debug code not removed * From <ref> [Eis97] </ref>: Faulty assumption/model or misdirected blame.
Reference: [Eva84] <author> M. </author> <title> Evangelist. Program complexity and programming style. </title> <booktitle> In Proceedings of the International Conference of Data Engineering, </booktitle> <pages> pages 534-541. </pages> <publisher> IEEE, </publisher> <year> 1984. </year>
Reference: [FS91] <author> Daniel Farmer and Eugene H. Spafford. </author> <title> The COPS Security Checker System. </title> <type> Technical Report CSD-TR-993, </type> <institution> Software Engineering Research Center, Purdue University, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: Finally, there are several products that incorporate vulnerability information for detection of their presence in computer systems. The more widely known are the COPS security checker <ref> [FS91] </ref>, SATAN, Tiger, ISS, and the TAMU security checker. 4 Proposed Solution In the ideal case it would be desirable to perform sophisticated computer analysis on existing vulnerability information including, but not limited to, the detection of hidden and significant, and possibly non-obvious, relationships in vulnerabilities; the application of correlation and
Reference: [FS96] <author> Yoav Freund and Robert E. Schapire. </author> <title> Experiments with a new boosting algorithm. </title> <year> 1996. </year>
Reference-contexts: If we have 30 features in the state space, we must have at least 60-90 samples. After reviewing some of the machine learning literature <ref> [WK91, DH73, Qui86, QCJ, Bre94, FS96] </ref> we can provide an initial estimation of the number of samples and number of features that will be needed: approximately 100-200 samples and 20-30 features. 6.2 Feature Indentification A feature for a computer vulnerability is characteristic or metric of the vulnerability, it's exploitation, and the
Reference: [Gar96] <author> Simson Garfinkel. </author> <note> Could ActiveX pose a threat to national security? http://www.packet.com/packet/, Nov 1996. </note>
Reference-contexts: Hence, it is difficult to provide a precise working definition of what a vulnerability is because this depends on a precise security policy for any system being analyzed. Also, a working definition of a vulnerability based on explicit policies is particularly difficult in technologies such as Microsoft's ActiveX <ref> [Gar96] </ref>. Systems running ActiveX, either as part of Microsoft's proposed Active Desktop [act96] or as part of the Microsoft Explorer WWW browser, 5 dynamically download binary executables from the Internet without verifying that their execution satisfies the policies for the system in which it will run.
Reference: [han96] <institution> Handbook of INFOSEC Terms Version 2.0. CDROM, </institution> <year> 1996. </year>
Reference-contexts: The attack or harmful event, or the opportunity available to a threat agent to mount that attack." 3. The Handbook of INFOSEC Terms <ref> [han96] </ref> provides the following definiton of computer vulnerabilty: "1) A weakness in automated system security procedures, administrative controls, internal controls, and so forth, that could be exploited by a threat to gain unauthorized access to information or disrupt critical processing. 2) A weakness in system security procedures, hardware design, internal controls,
Reference: [Haw88] <author> Stephen W. Hawking. </author> <title> A Brief History of Time: From the Big Bang to Black Holes. </title> <publisher> Bantam Books, </publisher> <year> 1988. </year>
Reference-contexts: Each time new experiments are observed to agree with the predictions the theory survives, and our confidence in it is increased; but if ever a new observation is found to disagree, we have to abandon or modify the theory." <ref> [Haw88] </ref> And indeed I make a significant prediction: Computer vulnerability information presents important regularities and these can be detected, and possibly visualized, providing important insight about the reason of their prevalence and existence.
Reference: [Hed95] <author> Sara Reese Hedberg. </author> <title> The Data Gold Rush. </title> <journal> BYTE, </journal> <month> October </month> <year> 1995. </year>
Reference-contexts: The figure illustrates how projections of a three dimensional state space can generate a two dimensional grid that could be used to detect patterns using cluster analysis. the data of a good vulnerability state space including tools for discovery statistics, visualization, neural networks, applied perception, and machine learning <ref> [Wat95, Hed95, kdd, HS94] </ref>. The database model that this vulnerability state space is implemented on is not of critical importance. The COAST group, for example, has structured its database as a relational hierarchy implemented as flat text files.
Reference: [HS94] <author> Marcel Holsheimer and Arno Siebes. </author> <title> Data Mining: The Search for Knowledge in Databases. </title> <type> Technical Report CS-R9406, </type> <institution> Centrum voor Wiskunde en Informatica, </institution> <year> 1994. </year>
Reference-contexts: The figure illustrates how projections of a three dimensional state space can generate a two dimensional grid that could be used to detect patterns using cluster analysis. the data of a good vulnerability state space including tools for discovery statistics, visualization, neural networks, applied perception, and machine learning <ref> [Wat95, Hed95, kdd, HS94] </ref>. The database model that this vulnerability state space is implemented on is not of critical importance. The COAST group, for example, has structured its database as a relational hierarchy implemented as flat text files.
Reference: [Jr.95] <author> Frederick P. Brooks Jr. </author> <title> The Mythical Man-Month. </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: Already in 1975 Frederick Brooks wrote in his book The Mythical Man-Month that "Since software construction is inherently a systems effort-an exercise in complex interrelationships-communication effort is great, and it quickly dominates the decrease in individual task time brought about by partitioning." <ref> [Jr.95] </ref> In "Why Cryptosystems Fail" [And94], Ross Anderson writes the following about this topic: "When an aircraft crashes, it is front page news. <p> The same argument can be made in the design of airplanes, bridges, nuclear power plants, or any complex system where it is virtually impossible to design a correct system from scratch <ref> [Pet85, Jr.95, Sch94, Per84, Dor96, And94] </ref>. As Confucius said: "If you wish to control the future, study the past" [bri95].
Reference: [kdd] <author> S*i*ftware: </author> <title> Tools for Data Mining and Knowledge Discovery. </title> <note> WWW URL http://info.gte.com/~kdd/siftware.html. </note>
Reference-contexts: The figure illustrates how projections of a three dimensional state space can generate a two dimensional grid that could be used to detect patterns using cluster analysis. the data of a good vulnerability state space including tools for discovery statistics, visualization, neural networks, applied perception, and machine learning <ref> [Wat95, Hed95, kdd, HS94] </ref>. The database model that this vulnerability state space is implemented on is not of critical importance. The COAST group, for example, has structured its database as a relational hierarchy implemented as flat text files.
Reference: [KP78] <author> B. Kernighan and P. Plauger. </author> <title> The Elements of Programming Style. </title> <publisher> McGraw-Hill Book Company, </publisher> <address> second edition, </address> <year> 1978. </year>
Reference: [KS94] <author> Sandeep Kumar and Eugene Spafford. </author> <title> A Pattern Matching Model for Misuse Intrusion Detection. </title> <booktitle> In 17th National Computer Security Conference, </booktitle> <year> 1994. </year>
Reference-contexts: efforts by Matt Bishop at the University of California at Davis [Bis95], both of which are used to develop generic vulnerability detection mechanisms; the intrusion detection work done by Kumar et al. at the COAST laboratory, that concludes that vulnerabilities can be grouped together in generic classes described by patterns <ref> [KS94, KS95b, Kum95, KS95a, CDE + 96] </ref>; and the vulnerability classification work done by Aslam and Krsul that provides a taxonomy of security faults [Asl95, AKS96a]; Ross Anderson collected and analyzed vulnerability information for automatic teller machine (ATM) cryptosystems [And94] and concluded that designers of automatic teller machines (ATM) cryptosystems failed <p> However, in practice it may be possible to structure the information to make the generation of exploit scripts as difficult as possible. The generation of intrusion detection signatures or patterns, and in particular patterns for the IDIOT intrusion detection system <ref> [KS94, KS95b, Kum95] </ref>, is a difficult and time consuming task. IDIOT patterns are encodings of vulnerabilities as Colored Petri Nets that encode the transitions that a typical vulnerability (from a class of similar vulnerabilities) takes. <p> IDIOT patterns are encodings of vulnerabilities as Colored Petri Nets that encode the transitions that a typical vulnerability (from a class of similar vulnerabilities) takes. Development of a pattern implies detailed working knowledge of the problem and of the structure of the system being analyzed. For example, <ref> [CDE + 96, KS95a, KS94, Kum95] </ref> all describe in detail a pattern to detect the exploitation of a famous xterm log bug: The problem is that a user could create only one end of a named pipe and run xterm requesting that it create a log with the same filename as
Reference: [KS95a] <author> Sandeep Kumar and Eugene Spafford. </author> <title> A Taxonomy of Common Computer Security Vulnerabilities based on their Method of Detection. </title> <type> Technical report, </type> <institution> Purdue University, </institution> <year> 1995. </year>
Reference-contexts: efforts by Matt Bishop at the University of California at Davis [Bis95], both of which are used to develop generic vulnerability detection mechanisms; the intrusion detection work done by Kumar et al. at the COAST laboratory, that concludes that vulnerabilities can be grouped together in generic classes described by patterns <ref> [KS94, KS95b, Kum95, KS95a, CDE + 96] </ref>; and the vulnerability classification work done by Aslam and Krsul that provides a taxonomy of security faults [Asl95, AKS96a]; Ross Anderson collected and analyzed vulnerability information for automatic teller machine (ATM) cryptosystems [And94] and concluded that designers of automatic teller machines (ATM) cryptosystems failed <p> It is unfortunate that policies are often not stated explicitly during the development of software systems and when they are specified they are often ambiguous. 3 Consider the first definition given above and it's application to a well known and documented vulnerability--the xterm log vulnerability in Unix systems <ref> [KS95a, KS95b, CDE + 96, Bis95] </ref>. The xterm program runs as root and is tricked into changing the ownership of an arbitrary file to that of the current user. <p> IDIOT patterns are encodings of vulnerabilities as Colored Petri Nets that encode the transitions that a typical vulnerability (from a class of similar vulnerabilities) takes. Development of a pattern implies detailed working knowledge of the problem and of the structure of the system being analyzed. For example, <ref> [CDE + 96, KS95a, KS94, Kum95] </ref> all describe in detail a pattern to detect the exploitation of a famous xterm log bug: The problem is that a user could create only one end of a named pipe and run xterm requesting that it create a log with the same filename as
Reference: [KS95b] <author> Sandeep Kumar and Eugene H. Spafford. </author> <title> A Software Architecture to Support Misuse Intrusion Detection. </title> <type> Technical Report CSD-TR-95-009, </type> <institution> Purdue University, </institution> <year> 1995. </year>
Reference-contexts: efforts by Matt Bishop at the University of California at Davis [Bis95], both of which are used to develop generic vulnerability detection mechanisms; the intrusion detection work done by Kumar et al. at the COAST laboratory, that concludes that vulnerabilities can be grouped together in generic classes described by patterns <ref> [KS94, KS95b, Kum95, KS95a, CDE + 96] </ref>; and the vulnerability classification work done by Aslam and Krsul that provides a taxonomy of security faults [Asl95, AKS96a]; Ross Anderson collected and analyzed vulnerability information for automatic teller machine (ATM) cryptosystems [And94] and concluded that designers of automatic teller machines (ATM) cryptosystems failed <p> It is unfortunate that policies are often not stated explicitly during the development of software systems and when they are specified they are often ambiguous. 3 Consider the first definition given above and it's application to a well known and documented vulnerability--the xterm log vulnerability in Unix systems <ref> [KS95a, KS95b, CDE + 96, Bis95] </ref>. The xterm program runs as root and is tricked into changing the ownership of an arbitrary file to that of the current user. <p> However, in practice it may be possible to structure the information to make the generation of exploit scripts as difficult as possible. The generation of intrusion detection signatures or patterns, and in particular patterns for the IDIOT intrusion detection system <ref> [KS94, KS95b, Kum95] </ref>, is a difficult and time consuming task. IDIOT patterns are encodings of vulnerabilities as Colored Petri Nets that encode the transitions that a typical vulnerability (from a class of similar vulnerabilities) takes.
Reference: [KS96] <author> Ivan Krsul and Eugene Spafford. </author> <title> Authorship analysis: Identifying the author of a program. </title> <type> Technical Report TR-96-052, </type> <institution> Purdue University, Department of Computer Sciences Purdue University West Lafayette, </institution> <note> IN 47907-1398, </note> <month> September </month> <year> 1996. </year>
Reference: [Kum95] <author> Sandeep Kumar. </author> <title> Classification and Detection of Computer Intrusions. </title> <type> PhD thesis, </type> <institution> Purdue University, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: efforts by Matt Bishop at the University of California at Davis [Bis95], both of which are used to develop generic vulnerability detection mechanisms; the intrusion detection work done by Kumar et al. at the COAST laboratory, that concludes that vulnerabilities can be grouped together in generic classes described by patterns <ref> [KS94, KS95b, Kum95, KS95a, CDE + 96] </ref>; and the vulnerability classification work done by Aslam and Krsul that provides a taxonomy of security faults [Asl95, AKS96a]; Ross Anderson collected and analyzed vulnerability information for automatic teller machine (ATM) cryptosystems [And94] and concluded that designers of automatic teller machines (ATM) cryptosystems failed <p> However, in practice it may be possible to structure the information to make the generation of exploit scripts as difficult as possible. The generation of intrusion detection signatures or patterns, and in particular patterns for the IDIOT intrusion detection system <ref> [KS94, KS95b, Kum95] </ref>, is a difficult and time consuming task. IDIOT patterns are encodings of vulnerabilities as Colored Petri Nets that encode the transitions that a typical vulnerability (from a class of similar vulnerabilities) takes. <p> IDIOT patterns are encodings of vulnerabilities as Colored Petri Nets that encode the transitions that a typical vulnerability (from a class of similar vulnerabilities) takes. Development of a pattern implies detailed working knowledge of the problem and of the structure of the system being analyzed. For example, <ref> [CDE + 96, KS95a, KS94, Kum95] </ref> all describe in detail a pattern to detect the exploitation of a famous xterm log bug: The problem is that a user could create only one end of a named pipe and run xterm requesting that it create a log with the same filename as
Reference: [L + 93] <editor> Carl Landwher et al. </editor> <title> A Taxonomy of Computer Program Security Flaws. </title> <type> Technical report, </type> <institution> Naval Research Laboratory, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: + 76]; the paper published by Carl Landwehr (et al.) in which he published a collection of security flaws in different operating systems and classified each flaw according to its genesis, or the time it was introduced into the system, or the section of code where each flaw was introduced <ref> [L + 93] </ref>; and the survey published by Brian Marick of software fault studies from the software engineering literature (the studies reported faults that were discovered in production quality software) [Mar90]. Finally, there are several products that incorporate vulnerability information for detection of their presence in computer systems.
Reference: [Lon97] <author> Tom Longstaff. </author> <title> Update: </title> <note> Cert/cc vulnerability knowledgebase. Technical presentation at a DARPA workshop in Savannah, </note> <institution> Georgia, </institution> <month> February </month> <year> 1997. </year>
Reference-contexts: the vulnerability List (Verification of vulnerability) Field ID Title Description Type verif Verified by Person or entity that verified the vulnerability Text The following lists and hierarchical classifiers are currently defined in the vulnerability database: Classifier: Access required This classifier was originally defined from a talk given by Tom Longstaff <ref> [Lon97] </ref> and defines the kind of access that is required to exploit the vulnerability. * Remote using a common service * Trusted system * User account * Physical access * Privileged access Classifier: Application This classifier defines the application that has the vulnerability. <p> Independently the modules may function according to specifications but an error occurs when they are subjected to a specific set of inputs in a particular configuration environment. Classifier: Ease of Exploit This classifier was originally defined from a talk given by Tom Longstaff <ref> [Lon97] </ref> and attempts to identify how easy (or how hard) it is to exploit the vulnerability. * Simple command * Toolkit available * Expertise required * Must convince a user to take an action * Must convince an administrator to take an action Classifier: Impact This classifier attempts to identify the <p> privileges * Execution of scripts with user privileges * Internal users can execute scripts * External users can execute scripts * Denial of service * System resources are exhausted * System resources are eliminated Classifier: Origin and causes This classifier was originally defined from a talk given by Tom Longstaff <ref> [Lon97] </ref> and attempts to identify the origins of the vulnerability. * Lack of training * Procedures not followed * Problem re-introduced * Bug fix not propagated * Inconsistent specifications * Debug code not removed * From [Eis97]: Faulty assumption/model or misdirected blame.
Reference: [LR92] <author> D. Longley and S. Rigby. </author> <title> An Automatic Search for Security Flaws in Key Management Schemes. </title> <journal> Computers & Security, </journal> <volume> 11(1) </volume> <pages> 75-89, </pages> <month> March </month> <year> 1992. </year>
Reference: [LS90] <author> Dennis Longley and Michael Shain. </author> <title> The Data and Computer Security Dictionary of Standards, Concepts, and Terms, </title> <year> 1990. </year>
Reference-contexts: If generic, the vulnerability may characterize many vulnerable states; if specific, it may characterize only one..." 2. The Data & Computer Security Dictionary of Standards, Concepts, and Terms <ref> [LS90] </ref> provides the following definition of computer vulnerability: "1) In computer security, a weakness in automated systems security procedures, administrative controls, Internet controls, etc., that could be exploited by a threat to gain unauthorized access to information of to disrupt critical processing. 2) In computer security, a weakness in the physical
Reference: [LS92] <author> Matthys Levy and Mario Salvadori. </author> <title> Why Buildings Fall Down. </title> <editor> W. W. </editor> <publisher> Norton & Company, </publisher> <year> 1992. </year>
Reference-contexts: developers have been repairing vulnerabilities in their products for many years, only a few researchers are beginning to understand that vulnerability analysis is an essential process in the step-wise refinement of software products. 1 Traditional sciences and engineering have a long history in the analysis of vulnerabilities of complex systems <ref> [Per84, Sch94, And94, Pet85, LS92] </ref>. For example, the aerospace industry has a long record of recovering vulnerability information from incidents, storing this information and finding regularities or patterns and incorporating their findings into production systems, making each subsequent product safer than the preceding one. <p> Scientists and engineers that are responsible for the development of critical systems are used to the idea of learning from past mistakes. In "Why Buildings Fall Down" <ref> [LS92] </ref>, Levy and Salvadori describe in great detail some of the more spectacular structural failures in history and provide evidence that structural failures are likely to become less common because of the application of the knowledge gathered in the examination of past failures to modern designs.
Reference: [Mar90] <author> Brian Marick. </author> <title> A survey of software fault surveys. </title> <type> Technical Report UIUCDCS-R-90-1651, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: genesis, or the time it was introduced into the system, or the section of code where each flaw was introduced [L + 93]; and the survey published by Brian Marick of software fault studies from the software engineering literature (the studies reported faults that were discovered in production quality software) <ref> [Mar90] </ref>. Finally, there are several products that incorporate vulnerability information for detection of their presence in computer systems.
Reference: [OC90] <author> P. Oman and C. Cook. </author> <title> A Taxonomy for Programming Style. </title> <booktitle> In Eighteenth Annual ACM Computer Science Conference Proceedings, </booktitle> <pages> pages 244-247. </pages> <publisher> ACM, </publisher> <year> 1990. </year>
Reference: [OC91] <author> P. Oman and C. Cook. </author> <title> A Programming Style Taxonomy. </title> <journal> Journal of Systems Software, </journal> <volume> 15(4) </volume> <pages> 287-301, </pages> <year> 1991. </year>
Reference: [Per84] <author> Charles Perrow. </author> <title> Normal Accidents: Living With High-Risk Technologies. </title> <publisher> Basic Books, </publisher> <year> 1984. </year>
Reference-contexts: developers have been repairing vulnerabilities in their products for many years, only a few researchers are beginning to understand that vulnerability analysis is an essential process in the step-wise refinement of software products. 1 Traditional sciences and engineering have a long history in the analysis of vulnerabilities of complex systems <ref> [Per84, Sch94, And94, Pet85, LS92] </ref>. For example, the aerospace industry has a long record of recovering vulnerability information from incidents, storing this information and finding regularities or patterns and incorporating their findings into production systems, making each subsequent product safer than the preceding one. <p> are maintained and piloted by fallible human beings, at hundreds of miles an hour through congested airspace, in bad weather and at night, the risk of being killed on an air journey is only about one in a million." Several other sources including "When Technology Fails" [Sch94] and "Normal Accidents" <ref> [Per84] </ref> make it clear that prompt and complete information dissemination is critical if we want to learn from past mistakes. More often than not, it is not the designers of the systems that find and debug complex systems but observers who find patterns that lead to the cause of failures. <p> The same argument can be made in the design of airplanes, bridges, nuclear power plants, or any complex system where it is virtually impossible to design a correct system from scratch <ref> [Pet85, Jr.95, Sch94, Per84, Dor96, And94] </ref>. As Confucius said: "If you wish to control the future, study the past" [bri95].
Reference: [Pet85] <author> Henry Petrosky. </author> <title> To engineer is human : the role of failure in successful design. </title> <address> St. </address> <publisher> Martin's Press, </publisher> <year> 1985. </year>
Reference-contexts: developers have been repairing vulnerabilities in their products for many years, only a few researchers are beginning to understand that vulnerability analysis is an essential process in the step-wise refinement of software products. 1 Traditional sciences and engineering have a long history in the analysis of vulnerabilities of complex systems <ref> [Per84, Sch94, And94, Pet85, LS92] </ref>. For example, the aerospace industry has a long record of recovering vulnerability information from incidents, storing this information and finding regularities or patterns and incorporating their findings into production systems, making each subsequent product safer than the preceding one. <p> The same argument can be made in the design of airplanes, bridges, nuclear power plants, or any complex system where it is virtually impossible to design a correct system from scratch <ref> [Pet85, Jr.95, Sch94, Per84, Dor96, And94] </ref>. As Confucius said: "If you wish to control the future, study the past" [bri95].
Reference: [Pol] <author> W. Timothy Polk. </author> <title> Automated Tools for Testing Computer System Vulnerability. </title> <note> Unknown if a published version of the paper exists. </note>
Reference-contexts: This should be a powerful incentive for the development of a freely available vulnerability database that could be used to learn from other people's mistakes. Many articles in the literature make similar arguments for the need of publicly available data collections and analysis tools <ref> [And94, Asl95, AKS96a, Pol] </ref>: computer programmers are not learning from their mistakes and we do not have tools that allow us to understand why this is the case. The last few years have seen a surge in interest for the design and maintenance of vulnerability databases.
Reference: [Pop69] <author> Karl R. Popper. Conjections and Refutations. Routledge and Kegan Paul, </author> <year> 1969. </year>
Reference-contexts: It is connected with an inborn propensity to lookout for regularities, or with a need to find regularities..." <ref> [Pop69] </ref> There are a few instances of researchers who have indeed attempted to find such regularities in computer vulnerabilities, including the vulnerability analysis project at the University of California at Davis [BD96] and the vulnerability classification efforts by Matt Bishop at the University of California at Davis [Bis95], both of which <p> In his book Conjectures and Refutations he states that "...every genuine test of a theory is an attempt to falsify it, or to refute it. Testability is falsifiability." <ref> [Pop69] </ref>. As the physicist Stephen Hawking remarked: "Any physical theory is always provisional, in the sense that it is only a hypothesis: you can never prove it.
Reference: [Pow96] <author> Richar Power. </author> <title> Current And Future Danger: A CSI Primer of Computer Crime & Information Warfare. </title> <journal> CSI Bulletin, </journal> <year> 1996. </year>
Reference-contexts: Immediate Impact. Rather than the ultimate or eventual impact of the vulnerability (which in Unix tends to be root access), the first or immediate impact of the vulnerability. Threat. Threat based on Don Parker's threat classification scheme <ref> [Pow96] </ref>. System Vendor. System Version. Application. Application Version. Advisories. Institutions or groups that have issued an advisory about the vulnerability. Analysis. Do we have a detailed analysis about the vulnerability? Detection. Does a mechanism for detecting the exploitation of the vulnerability exist? Test. <p> NEC XX-UX * Hewlett-Packard Unix * IBM's AIX * OpenStep * OSF * Caldera * NEC's Goah Classifier: Threat This hierarchical classifier attempts to classify the threat that vulnerabilities create and was extracted from "Current and Future Danger: A CSI Primer on Computer Crime & Information Warfare" by Richard Power <ref> [Pow96] </ref>.
Reference: [QCJ] <author> J. R. Quinlan and R. M. Cemeron-Jones. </author> <title> Oversearching and Layered Search in Empirical Learning. </title>
Reference-contexts: If we have 30 features in the state space, we must have at least 60-90 samples. After reviewing some of the machine learning literature <ref> [WK91, DH73, Qui86, QCJ, Bre94, FS96] </ref> we can provide an initial estimation of the number of samples and number of features that will be needed: approximately 100-200 samples and 20-30 features. 6.2 Feature Indentification A feature for a computer vulnerability is characteristic or metric of the vulnerability, it's exploitation, and the
Reference: [Qui86] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <booktitle> Machine Learning, </booktitle> <pages> pages 81-106, </pages> <year> 1986. </year>
Reference-contexts: If we have 30 features in the state space, we must have at least 60-90 samples. After reviewing some of the machine learning literature <ref> [WK91, DH73, Qui86, QCJ, Bre94, FS96] </ref> we can provide an initial estimation of the number of samples and number of features that will be needed: approximately 100-200 samples and 20-30 features. 6.2 Feature Indentification A feature for a computer vulnerability is characteristic or metric of the vulnerability, it's exploitation, and the
Reference: [RN93] <author> J. Ranade and A. Nash. </author> <title> The Elements of C Programming Style. </title> <publisher> McGraw-Hill Inc., </publisher> <year> 1993. </year>
Reference: [Sch94] <author> Neil Schlager. </author> <title> When Technology Fails: Significant Technological Disasters, Accidents, and Failures of the Twentieth Century. </title> <publisher> Gale Research Inc., </publisher> <year> 1994. </year>
Reference-contexts: developers have been repairing vulnerabilities in their products for many years, only a few researchers are beginning to understand that vulnerability analysis is an essential process in the step-wise refinement of software products. 1 Traditional sciences and engineering have a long history in the analysis of vulnerabilities of complex systems <ref> [Per84, Sch94, And94, Pet85, LS92] </ref>. For example, the aerospace industry has a long record of recovering vulnerability information from incidents, storing this information and finding regularities or patterns and incorporating their findings into production systems, making each subsequent product safer than the preceding one. <p> in large aircraft, which are maintained and piloted by fallible human beings, at hundreds of miles an hour through congested airspace, in bad weather and at night, the risk of being killed on an air journey is only about one in a million." Several other sources including "When Technology Fails" <ref> [Sch94] </ref> and "Normal Accidents" [Per84] make it clear that prompt and complete information dissemination is critical if we want to learn from past mistakes. <p> The same argument can be made in the design of airplanes, bridges, nuclear power plants, or any complex system where it is virtually impossible to design a correct system from scratch <ref> [Pet85, Jr.95, Sch94, Per84, Dor96, And94] </ref>. As Confucius said: "If you wish to control the future, study the past" [bri95].
Reference: [SCS86] <author> H. Dunsmore S. Conte and V. Shen. </author> <title> Software Engineering Metrics and Models. </title> <publisher> The Ben-jamin/Cummings Publishing Company, </publisher> <year> 1986. </year>
Reference: [SSTG92] <author> S. R. Snapp, S. E. Smaha, D. M. Teal, and T. Grance. </author> <title> The DIDS (distributed intrusion detection system) prototype. </title> <booktitle> In USENIX Association. Proceedings of the Summer 1992 USENIX Conference, </booktitle> <pages> pages 227-33, </pages> <address> Berkeley, CA, USA, </address> <month> June </month> <year> 1992. </year> <booktitle> USENIX Association, USENIX Association. </booktitle>
Reference: [Tas78] <author> Dennie Van Tassel. </author> <title> Program Style, Design, Efficiency, Debugging, and Testing. </title> <publisher> Prentice Hall, </publisher> <year> 1978. </year>
Reference: [Tou94] <author> M. Toure. </author> <title> An interdisciplinary approach for adding knowledge to computer security systems. </title> <booktitle> In Proceedings. The Institute of Electrical and Electronics Engineers 28th Annual 1994 International Carnahan Conference on Security Technology, </booktitle> <pages> pages 158-68, </pages> <address> New York, NY, USA, </address> <month> October </month> <year> 1994. </year> <journal> The Institute of Electrical and Electronics Engineers, IEEE. </journal>
Reference: [Wat95] <author> Karen Watterson. </author> <title> A Data Miner's Tools. </title> <journal> BYTE, </journal> <month> October </month> <year> 1995. </year>
Reference-contexts: The figure illustrates how projections of a three dimensional state space can generate a two dimensional grid that could be used to detect patterns using cluster analysis. the data of a good vulnerability state space including tools for discovery statistics, visualization, neural networks, applied perception, and machine learning <ref> [Wat95, Hed95, kdd, HS94] </ref>. The database model that this vulnerability state space is implemented on is not of critical importance. The COAST group, for example, has structured its database as a relational hierarchy implemented as flat text files.
Reference: [WK91] <author> Sholom Weiss and Casimir Kulikowski. </author> <title> Computer systems that learn : classification and prediction methods from statistics, neural nets, machine learning, and expert systems. </title> <editor> M. </editor> <publisher> Kaufmann Publishers, </publisher> <year> 1991. </year>
Reference-contexts: It is important to note that at this point in time, these guidelines set only very tentative limits to the initial size of the state space. In <ref> [WK91] </ref>, Weiss Kulikowsk claim that that for classifiers and learning systems, a surprisingly small number of test cases are needed for accurate error rate estimations: at 50 test cases there is a good chance that, even though the test sample error rate is 0%, the true error rate is as large <p> If we have 30 features in the state space, we must have at least 60-90 samples. After reviewing some of the machine learning literature <ref> [WK91, DH73, Qui86, QCJ, Bre94, FS96] </ref> we can provide an initial estimation of the number of samples and number of features that will be needed: approximately 100-200 samples and 20-30 features. 6.2 Feature Indentification A feature for a computer vulnerability is characteristic or metric of the vulnerability, it's exploitation, and the
References-found: 59

