URL: ftp://ftp.cs.columbia.edu/reports/reports-1990/cucs-050-90.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1990.html
Root-URL: http://www.cs.columbia.edu
Email: tait@cs.columbia.edu  duchamp@cs.columbia.edu  
Title: Detection and Exploitation of File Working Sets  
Author: Carl D. Tait Dan Duchamp 
Note: This work is supported by the New York State Science and Technology Foundation Center for Advanced Technology in Computer and Information Systems, the AT&T Foundation, IBM Corporation, and Hewlett-Packard Corporation. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of any of the sponsoring agencies.  
Address: New York, NY 10027 CUCS-050-90  
Affiliation: Computer Science Department Columbia University  
Abstract: The work habits of most individuals yield file access patterns that are quite pronounced and can be regarded as defining working sets of files used for particular applications. This paper describes a client-side cache management technique for detecting these patterns and then exploiting them to successfully prefetch files from servers. Trace-driven simulations show the technique substantially increases the hit rate of a client file cache in an environment in which a client workstation is dedicated to a single user. Successful file prefetching carries three major advantages: (1) applications run faster, (2) there is less ``burst'' load placed on the network, and (3) properly-loaded client caches can better survive network outages. Our technique requires little extra code, and because it is simply an augmentation of the standard LRU client cache management algorithm is easily incorporated into existing software. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Alonso, D. Barbara, and L. L. Cova. </author> <title> Face: Enhancing Distributed File Systems for Autonomous Computing Environments. </title> <type> Technical Report CS-TR-214-89, </type> <institution> Princeton Univ., </institution> <month> March, </month> <year> 1989. </year>
Reference-contexts: A very large cache would help in this, but clearly anticipatory fetches play a role as well. Shortly afterward, Alonso's group listed a number of stashing methods that they contemplated for inclusion in their Face file system <ref> [1, 2] </ref>. In order of increasing sophistication, they are: 1. Make users responsible for which files are stashed. Various methods were proposed. One is enumerating the files that are to be stashed a ``.stashrc'' file. Another is making an explicit ``stash'' command available to the user.
Reference: [2] <author> R. Alonso, D. Barbara, and L. L. Cova. </author> <title> Augmenting Availability in Distributed File Systems. </title> <type> Technical Report CS-TR-234-89, </type> <institution> Princeton Univ., </institution> <month> October, </month> <year> 1989. </year>
Reference-contexts: A very large cache would help in this, but clearly anticipatory fetches play a role as well. Shortly afterward, Alonso's group listed a number of stashing methods that they contemplated for inclusion in their Face file system <ref> [1, 2] </ref>. In order of increasing sophistication, they are: 1. Make users responsible for which files are stashed. Various methods were proposed. One is enumerating the files that are to be stashed a ``.stashrc'' file. Another is making an explicit ``stash'' command available to the user.
Reference: [3] <author> A. </author> <title> Birrell. </title> <booktitle> Position given in Autonomy and Storage section of Third European SIGOPS Workshop. Operating Systems Review 23(2) </booktitle> <pages> 3-19, </pages> <month> April, </month> <year> 1989. </year>
Reference-contexts: Previous practical work on the topic is discussed below. We argue that our work has substantial advantages over previous work in this direction. An early discussion of the concept of stashing occurred in a 1988 workshop <ref> [3, p. 16] </ref>. The idea is simple: to gather at the client most or all of the files it will need in the near future so as to survive communication failures. A very large cache would help in this, but clearly anticipatory fetches play a role as well.
Reference: [4] <author> R. A. Floyd and C. S. Ellis. </author> <title> Directory Reference Patterns in Hierarchical File Systems. </title> <journal> IEEE Trans. on Knowledge and Data Engineering 1(2) </journal> <pages> 238-247, </pages> <month> June, </month> <year> 1989. </year>
Reference-contexts: Our simulator is implicitly based on whole-file caching. This is perhaps acceptable, since studies indicate that the great majority of files are read in their entirety <ref> [4, 7] </ref>. Furthermore, there is a minor trend toward file systems that use whole-file caching 13 [5, 10]. Very large files and shared files should remain at the server, however, and we have not yet addressed the problem of how to deal with these files.
Reference: [5] <author> J. H. Howard, et. al. </author> <title> Scale and Performance in a Distributed File System. </title> <journal> ACM Trans. on Computer Systems 6(1) </journal> <pages> 51-81, </pages> <month> February, </month> <year> 1988. </year>
Reference-contexts: Our simulator is implicitly based on whole-file caching. This is perhaps acceptable, since studies indicate that the great majority of files are read in their entirety [4, 7]. Furthermore, there is a minor trend toward file systems that use whole-file caching 13 <ref> [5, 10] </ref>. Very large files and shared files should remain at the server, however, and we have not yet addressed the problem of how to deal with these files. Finally, we would like to gather more trace data from different environments.
Reference: [6] <author> K. Korner. </author> <title> Intelligent Caching for Remote File Services. </title> <booktitle> In Proc. Tenth Intl. Conf. on Distributed Computing Systems, </booktitle> <pages> pages 220-226. </pages> <publisher> IEEE, </publisher> <month> May, </month> <year> 1990. </year>
Reference-contexts: The client cache is large enough to accommodate the whole volume of its user (s) as well as any other needed files. 16 The work most closely related to our own is Korner's work on detecting and exploiting the block access patterns of individual files <ref> [6] </ref>. The ``style'' of this work is similar to ours in that patterns are detected and exploited. However, several important aspects make Korner's work different: 1. The detection of patterns is an off-line process performed by two expert systems, whereas our method provides on-line real-time detection and exploitation. 2.
Reference: [7] <author> J. Ousterhout, et. </author> <note> al. </note>
Reference-contexts: Our simulator is implicitly based on whole-file caching. This is perhaps acceptable, since studies indicate that the great majority of files are read in their entirety <ref> [4, 7] </ref>. Furthermore, there is a minor trend toward file systems that use whole-file caching 13 [5, 10]. Very large files and shared files should remain at the server, however, and we have not yet addressed the problem of how to deal with these files. <p> Korner's objective is the more limited problem of detecting and exploiting the block access patterns within a file, not file access patterns within an application. Since a large proportion of files are accessed in their entirety <ref> [7] </ref>, it is not clear what percentage of files could benefit from Korner's prefetch rules. Our method benefits any application whose file access behavior is predictable. In addition, Korner's proposed exploitation is for the file server's in-memory cache of disk blocks, not for a client-side cache of server contents.
References-found: 7

