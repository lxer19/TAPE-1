URL: http://www.cs.berkeley.edu/Research/Projects/brass/documents/Gama.ps.Z
Refering-URL: http://www.cs.berkeley.edu/Research/Projects/brass/documents/Gama.html
Root-URL: 
Title: Fast Module Mapping and Placement for Datapaths in FPGAs  
Author: Timothy J. Callahan Philip Chong, Andre DeHon, and John Wawrzynek 
Address: Berkeley  
Affiliation: University of California at  
Abstract: By tailoring a compiler tree-parsing tool for datapath module mapping, we produce good quality results for datapath synthesis in very fast run time. Rather than flattening the design to gates, we preserve the datapath structure; this allows exploitation of specialized datapath features in FPGAs, retains regularity, and also results in a smaller problem size. To further achieve high mapping speed, we formulate the problem as tree covering and solve it efficiently with a linear-time dynamic programming algorithm. In a novel extension to the tree-covering algorithm, we perform module placement simultaneously with the mapping, still in linear time. Integrating placement has the potential to increase the quality of the result since we can optimize total delay including routing delays. To our knowledge this is the first effort to leverage a grammar-based tree covering tool for datapath module mapping. Further, it is the first work to integrate simultaneous placement with module mapping in a way that preserves linear time complexity. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> AHO, A., AND GANAPATHI, M. </author> <title> Efficient Tree Pattern Matching: An Aid to Code Generation. </title> <booktitle> In Conf. Record of the Twelfth Annual ACM Symposium on Principles of Programming Languages (Jan. </booktitle> <year> 1985), </year> <pages> pp. 334-340. </pages>
Reference-contexts: The algorithm and underlying theory was originally developed for code generation in compilers <ref> [1] </ref>, and was first used for the analogous problem of technology binding by Keutzer in DAGON. GAMA utilizes lburg, a tool developed for the task of code generation in the lcc compiler [7]. We found some modifications to lburg necessary as described in Subsection 3.3.
Reference: [2] <author> AHO, A., JOHNSON, S., AND ULLMAN, J. </author> <title> Code Generation for Expressions with Common Subexpressions. </title> <journal> Journal of the ACM 24, </journal> <month> 1 (Jan. </month> <year> 1977), </year> <pages> 146-60. </pages>
Reference-contexts: The size threshold for duplicating vs. splitting is a run-time option. Note that even if each tree covering is optimal, the overall solution is not necessarily optimal using this approach. However, optimal covering of DAGs is NP-complete <ref> [2] </ref> and so is not directly attempted. Tree covering Because of the hardware resources present in typical CLBs, it is often possible to implement multiple nodes from the DFG together in a compound module that is much smaller and/or faster than if they were implemented separately.
Reference: [3] <author> AMARASINGHE, S. P., ANDERSON, J. M., WILSON, C. S., LIAO, S.-W., MURPHY, B. M., FRENCH, R. S., LAM, M. S., AND HALL, M. W. </author> <title> Multiprocessors from a Software Perspective. </title> <booktitle> IEEE Micro 16, </booktitle> <month> 3 (June </month> <year> 1996), </year> <pages> 52-61. </pages> <note> See also http://suif.stanford.edu/. </note>
Reference-contexts: Many different resource interactions must be handled. We have found that GAMA's grammar handles these interactions in a very natural way. We are using GAMA as part of automatic compilation from ANSI C. This work is based on the SUIF compiler system <ref> [3] </ref> from Stanford. Kernels from the C program are automatically extracted and fed to GAMA. The remainder of the program is compiled to execute on Garp's MIPS processor. The array is dynamically reconfigured as needed throughout the execution of the program.
Reference: [4] <author> CHAUDHARY, K., AND PEDRAM, M. </author> <title> A Near Optimal Algorithm for Technology Mapping Minimizing Area Under Delay Constraints. </title> <booktitle> In Proc. 29th ACM/IEEE Design Automation Conference DAC '92 (June 1992), </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 492-498. </pages>
Reference-contexts: We will implement and experiment with an algorithm similar to that described by Chaudhary and Pedram <ref> [4] </ref>. The dynamic programming algorithm will be modified to keep not just a single best cover at each node, but all non 9 inferior points along the area-time tradeoff curve. This will involve further modification of lburg to generate code that handles lists of covers rather than single covers.
Reference: [5] <author> DEHON, A. </author> <title> DPGA-Coupled Microprocessors: </title> <booktitle> Commodity ICs for the Early 21st Century. In Proceedings IEEE Workshop on FPGAs for Custom Computing Machines (Cat. No.94TH0611-4) (1994), </booktitle> <publisher> IEEE Comput. Soc. Press, </publisher> <pages> pp. 31-9. </pages> <month> AN4754544. </month>
Reference-contexts: The Garp array contains a rich variety of computation, routing, and I/O resources especially designed to support datapath computation. It is likely that FPGAs with similar features will become commonplace in the future as their use as reconfigurable copro-cessors become more widespread <ref> [5] </ref>. A commercial embedded processor with a reconfigurable coprocessor, the National Semiconductor NAPA1000 [14], has already been announced. While the Garp array's specialized resources ultimately enable better datapath performance, they complicate the mapping task. Many different resource interactions must be handled.
Reference: [6] <author> FRANCIS, R. </author> <title> Technology Mapping for Lookup-Table Based Field-Programmable Ga te Arrays. </title> <type> PhD thesis, </type> <institution> University of Toronto, </institution> <year> 1992. </year>
Reference-contexts: The idea of optimizing area on non-critical paths was also used in Chortle <ref> [6] </ref>, although the details of the implementation are slightly different. 3.5 Large Module Library As mentioned earlier, there are an extremely large number of different compound modules that can be implemented by a row/column of LUT-based CLBs. GAMA uses two techniques to keep the library size manageable.
Reference: [7] <author> FRASER, C., AND HANSON, D. </author> <title> A Retargetable C Compiler: Design and Implementation. </title> <address> Benjamin/Cummings, </address> <year> 1995. </year>
Reference-contexts: The algorithm and underlying theory was originally developed for code generation in compilers [1], and was first used for the analogous problem of technology binding by Keutzer in DAGON. GAMA utilizes lburg, a tool developed for the task of code generation in the lcc compiler <ref> [7] </ref>. We found some modifications to lburg necessary as described in Subsection 3.3. This modified version of lburg translates a targetspecific grammar into the actual tree-covering code that gets compiled into GAMA. 3.1 Basic Algorithm For review, this subsection describes the basic tree-covering algorithm.
Reference: [8] <author> HAUSER, J., AND WAWRZYNEK, J. Garp: </author> <title> A MIPS Processor with a Reconfigurable Coprocessor. </title> <booktitle> In Proceedings of IEEE Symposium on FPGAs for Custom Computing Machines (Napa, </booktitle> <address> CA, </address> <month> Apr. </month> <year> 1997), </year> <editor> K. L. Pocek and J. M. Arnold, </editor> <publisher> Eds. </publisher>
Reference-contexts: Finally, this approach is flexible; it has been utilized in mapping to two FPGA architectures: Xilinx 4000 series FPGAs and the Garp chip's reconfigurable array being developed in our group <ref> [8] </ref>. Although both are based on 4-input lookup tables (4-LUTs), these two arrays present very different mapping problems. <p> section, however, shows that a design flow that from start to finish is optimized for datapath-intense circuits can perform the complete synthesis task orders of magnitude faster. 4.2 Targeting Garp The majority of our experience with GAMA to this point is targeting the Garp chip being developed in our group <ref> [8] </ref>. Garp consists of a standard MIPS processor augmented with a reconfigurable coprocessor on the same chip. The Garp array contains a rich variety of computation, routing, and I/O resources especially designed to support datapath computation.
Reference: [9] <author> KEUTZER, K. DAGON: </author> <title> Technology Binding and Local Optimization by DAG Matching. </title> <booktitle> In Proc. 24th ACM/IEEE Design Automation Conference (1987), ACM, </booktitle> <pages> pp. 341-347. </pages>
Reference-contexts: Each of these will be fed to the tree-covering algorithm, and the results ultimately connected together. Cycles are broken at appropriate places, usually storage elements demarking iteration boundaries. This produces a directed acyclic graph (DAG), which must be further split into trees. The simplest approach, used in DAGON <ref> [9] </ref>, is to split the DAG at the output of each mul 2 tiple fanout node (see (a) below). GAMA goes further and considers duplicating a shared subtree if it is small, since duplication can lead to faster and smaller mappings in some cases (see (b) below).
Reference: [10] <author> KOCH, A. </author> <title> Module Compaction in FPGA-based Regular Datap-aths. </title> <booktitle> In Proc. 33rd ACM/IEEE Design Automation Conference (1996), ACM. </booktitle>
Reference-contexts: This approach can be fast, and it leads to a regular bitslice layout. However, assuming modules with fixed layouts, no optimization across module boundaries is performed. As pointed out by Koch <ref> [10] </ref>, this approach can lead to the underutilization of FPGA computation resources, especially with coarse-grained architectures (Figure 1b). Koch's Structured Design Implementation [10] addresses this underutilization problem by performing a module compaction step after module selection and placement, using standard tools to optimize one bit slice of the datapath and then <p> However, assuming modules with fixed layouts, no optimization across module boundaries is performed. As pointed out by Koch <ref> [10] </ref>, this approach can lead to the underutilization of FPGA computation resources, especially with coarse-grained architectures (Figure 1b). Koch's Structured Design Implementation [10] addresses this underutilization problem by performing a module compaction step after module selection and placement, using standard tools to optimize one bit slice of the datapath and then tiling the re 1 Implementing each operation as basic gates and then feeding to traditional flow. <p> Our experience is that maintenance difficulties become a limit on the size of the grammar long before performance becomes an issue. 5 Related Work Koch's Structured Design Implementation (SDI) <ref> [10, 11] </ref> also optimizes across datapath module boundaries while retaining and exploiting the regularity present. It first records the regularity present in a design. Then it basically feeds a single bit slice of the design to the standard random logic tools to perform logic optimization.
Reference: [11] <author> KOCH, A. </author> <title> Structured Design Implementation AStrategy for Implementing Regular Datapaths on FPGAs. </title> <booktitle> In Proc. ACM/SIGDA International Symposium on Field Programmable Gate Arrays (Monterey CA USA, 1996), ACM, </booktitle> <pages> pp. 151-157. </pages>
Reference-contexts: Our experience is that maintenance difficulties become a limit on the size of the grammar long before performance becomes an issue. 5 Related Work Koch's Structured Design Implementation (SDI) <ref> [10, 11] </ref> also optimizes across datapath module boundaries while retaining and exploiting the regularity present. It first records the regularity present in a design. Then it basically feeds a single bit slice of the design to the standard random logic tools to perform logic optimization.
Reference: [12] <author> LOU, J., SALEK, A. H., AND PEDRAM, M. </author> <title> An Exact Solution to Simultaneous Technology Mapping and Linear Placement Problem for Trees. </title> <booktitle> In Proc. International Workshop on Logic Synthesis (May 1997), </booktitle> <pages> pp. 1-4. </pages>
Reference-contexts: Finally, another method using dynamic programming to obtain a mapping and linear placement of logic modules is SEMPA, as described by Lou et al. <ref> [12] </ref>. SEMPA solely addresses area minimization, however, and utilizes a super-linear-time algorithm that considers all possible module orderings. In contrast, GAMA can perform delay optimization and runs in time linear with the number of nodes in the tree, but only considers a restricted subset of module orderings.
Reference: [13] <author> NASEER, A., BALAKRISHNAN, M., AND KUMAR, A. </author> <title> An Efficient Technique for Mapping RTL Structures onto FPGAs. </title> <booktitle> In Proc. 4th International Workshop on Field-Programmable Logic and Applications, </booktitle> <address> FPL '94 (Prague, Czech Republic, Sept. 1994), </address> <publisher> Springer-Verlag, </publisher> <pages> pp. 99-110. </pages>
Reference-contexts: Another limitation is that only physically adjacent modules in the previously determined floorplan are considered for compaction. In the FAST system <ref> [13] </ref>, groups of nodes in the graph of da-tapath operations that can be merged are identified; groups are then greedily chosen to be mapped to optimized modules. <p> One benefit that SDI gains by using the general tools is that it can effectively create an unbounded variety of very large compound modules. The variety of modules created by GAMA is limited by library size considerations. The approach used in the FAST compiler <ref> [13] </ref> is similar to GAMA in that it directly attempts to find in the dataflow graph feasible cones (groups of nodes that can be implemented in a compound module), rather than using standard logic optimization techniques on the gate-level representation.
Reference: [14] <institution> NATIONAL SEMICONDUCTOR CORPORATION. NAPA1000 Data Sheet, </institution> <year> 1996. </year>
Reference-contexts: It is likely that FPGAs with similar features will become commonplace in the future as their use as reconfigurable copro-cessors become more widespread [5]. A commercial embedded processor with a reconfigurable coprocessor, the National Semiconductor NAPA1000 <ref> [14] </ref>, has already been announced. While the Garp array's specialized resources ultimately enable better datapath performance, they complicate the mapping task. Many different resource interactions must be handled. We have found that GAMA's grammar handles these interactions in a very natural way.
Reference: [15] <author> TJIANG, S. </author> <title> Twig Reference Manual. </title> <institution> Comp. Sci. </institution> <type> Tech. Rep. 120, </type> <institution> AT&T Bell Laboratories, </institution> <month> January </month> <year> 1986. </year>
Reference-contexts: To support this, we extended lburg so that the costs are represented by a user-defined structure (where the `user' here is the person coding GAMA). DAGON also used both area and delay costs. The tree matcher generator tool that it used, Twig <ref> [15] </ref>, already had support for aggregate costs and so did not need modification. Associated with each pattern in the library is a small C code fragment, supplied by the user, to calculate the cost of the resulting cover if that pattern is matched.
Reference: [16] <author> XILINX. </author> <title> The Programmable Logic Data Book. </title> <booktitle> 1994. </booktitle> <pages> 10 </pages>
Reference-contexts: the modules in the library, which is very different than the best solution possible given the FPGA architecture; the solution can only be as good as the module library. 4 Results 4.1 Targeting Xilinx XC4000 Series We have implemented a simple grammar for mapping DFGs to Xilinx XC4000 series parts <ref> [16] </ref>, for which GAMA shows compilation time and performance benefits over a number of alternative approaches. Three simple C code fragments were used as benchmarks. Each operation in these fragments was mapped directly to a node in the dataflow graph fed to GAMA.
References-found: 16

