URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-279.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Title: Moving Images with Layers  
Author: John Y. A. Wang AND Edward H. Adelson 
Keyword: Image coding, motion analysis, image segmentation, image representation, robust estimation.  
Note: Representing  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 279 (Replaces TR-228) Appears in the IEEE Transactions on Image Processing Special Issue: Image Sequence Compression, vol 3, no. 5, p. 625-638, September 1994. Revised: May, 1994 Abstract We describe a system for representing moving images with sets of overlapping layers. Each layer contains an intensity map that defines the additive values of each pixel, along with an alpha map that serves as a mask indicating the transparency. The layers are ordered in depth and they occlude each other in accord with the rules of compositing. Velocity maps define how the layers are to be warped over time. The layered representation is more flexible than standard image transforms and can capture many important properties of natural image sequences. We describe some methods for decomposing image sequences into layers using motion analysis, and we discuss how the representation may be used for image coding and other applications.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. H. Adelson. </author> <title> Layered representation for image coding. </title> <type> Technical Report 181, </type> <institution> The MIT Media Lab, </institution> <year> 1991. </year>
Reference-contexts: Since the world consists of stable objects undergoing smooth motions, our decomposition should also contain stable objects undergoing smooth motions. An earlier description of layered formats is found in <ref> [1] </ref>. 1 (a) Intensity map Alpha map Velocity map (b) Intensity map Alpha map Velocity map (c) Frame 1 Frame 2 Frame 3 into layers. (a) The background layer. <p> The alpha map is unity where the hand is present and zero where the hand is absent; the velocity map is smoothly varying. (c) The resynthesized image sequence based on the layers. In the representation that we use, following Adelson <ref> [1] </ref>, each layer contains three different maps: (1) the intensity map, (often called a "texture map" in computer graphics); (2) the alpha map, which defines the opacity or transparency of the layer at each point; and (3) the velocity map, which describes how the map should be warped over time.
Reference: [2] <author> J. Bergen, P. Anandan, K. Hana, and R. Hingorini al. </author> <title> Hierarchial model-based motion estimation. </title> <booktitle> In Proc. Second European Conf. on Comput. Vision, </booktitle> <pages> pages 237-252, </pages> <address> Santa Margherita Ligure, Italy, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: we impose constraints on coherent region size and local connectivity by applying simple thresholds to reject outliers at different stages in the algorithm, thus providing stability and robustness. 5.1 Optic flow estimation Our local motion estimate is obtained with a multi-scale coarse-to-fine algorithm based on a gradient approach described by <ref> [2, 12, 16] </ref>.
Reference: [3] <author> J. Bergen, P. Burt, R. Hingorini, and S. Peleg. </author> <title> Computing two motions from three frames. </title> <booktitle> In Proc. Third Int'l Conf. Comput. Vision, </booktitle> <pages> pages 27-32, </pages> <address> Os-aka, Japan, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: Critical processing involves motion estimation and segmentation. A number of authors have described methods for achieving multiple affine motion decompositions <ref> [3, 5, 9] </ref>. Our method is based on robust estimation and k-means clus 5 tering in affine parameter space. In many multiple motion estimation techniques, a recursive algorithm is used is to detect multiple motion regions in the scene [3, 9]. <p> Our method is based on robust estimation and k-means clus 5 tering in affine parameter space. In many multiple motion estimation techniques, a recursive algorithm is used is to detect multiple motion regions in the scene <ref> [3, 9] </ref>. At each iteration, these algorithms assume that a dominant motion region can be detected. Once the dominant region is identified and the motion within the region is estimated, it is eliminated and the next dominant motion is estimated from the remaining portion of the image.
Reference: [4] <author> M. J. Black and P. Anandan. </author> <title> Robust dynamic motion estimation over time. </title> <booktitle> In Proc. IEEE Conf. Comput. Vision Pattern Recog., </booktitle> <pages> pages 296-302, </pages> <address> Maui, Hawaii, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: The segmentation framework is outlined in figure 10. At each iteration, our multiple model framework identifies multiple coherent motion regions simultaneously. Iteratively, the motion model parameters are calculated within these coherent regions and segmentation is refined. Several authors have presented robust techniques <ref> [4, 5, 6] </ref> for multiple motion estimation. Black and Anandan described a multiple motion estimation technique that applies image constraints via influence functions that regulate the effects of outliers in a simulated annealing framework.
Reference: [5] <author> T. Darrell and A. Pentland. </author> <title> Robust estimation of a multi-layered motion representation. </title> <booktitle> In Proc. IEEE Workshop on Visual Motion, </booktitle> <pages> pages 173-178, </pages> <address> Prince-ton, New Jersey, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Critical processing involves motion estimation and segmentation. A number of authors have described methods for achieving multiple affine motion decompositions <ref> [3, 5, 9] </ref>. Our method is based on robust estimation and k-means clus 5 tering in affine parameter space. In many multiple motion estimation techniques, a recursive algorithm is used is to detect multiple motion regions in the scene [3, 9]. <p> The segmentation framework is outlined in figure 10. At each iteration, our multiple model framework identifies multiple coherent motion regions simultaneously. Iteratively, the motion model parameters are calculated within these coherent regions and segmentation is refined. Several authors have presented robust techniques <ref> [4, 5, 6] </ref> for multiple motion estimation. Black and Anandan described a multiple motion estimation technique that applies image constraints via influence functions that regulate the effects of outliers in a simulated annealing framework.
Reference: [6] <author> R. Depommier and E. Dubois. </author> <title> Motion estimation with detection of occlusion areas. </title> <booktitle> In Proc. IEEE ICASSP, </booktitle> <volume> volume 3, </volume> <pages> pages 269-273, </pages> <address> San Francisco, California, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: The segmentation framework is outlined in figure 10. At each iteration, our multiple model framework identifies multiple coherent motion regions simultaneously. Iteratively, the motion model parameters are calculated within these coherent regions and segmentation is refined. Several authors have presented robust techniques <ref> [4, 5, 6] </ref> for multiple motion estimation. Black and Anandan described a multiple motion estimation technique that applies image constraints via influence functions that regulate the effects of outliers in a simulated annealing framework.
Reference: [7] <author> S. Geman and D. Geman. </author> <title> Stochastic relaxation, gibbs distributions, and the bayesian restoration of images. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 6(6) </volume> <pages> 721-741, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: The velocity field is single-valued and smooth, and so the mixing of the two motions is inevitable. The analysis can be improved by allowing for sharp breaks in the velocity field, as is often done with regularization <ref> [7, 15] </ref>.
Reference: [8] <author> T. S. Huang and Y. P. Hsu. </author> <title> Image sequence enhancement. </title> <editor> In T. S. Huang, editor, </editor> <booktitle> Image Sequence Analysis, </booktitle> <pages> pages 289-309. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1981. </year>
Reference-contexts: Ear 8 lier studies have shown that motion compensation median filter can enhance noisy images and preserve edge informa tion better than a temporal averaging filter <ref> [8] </ref>.
Reference: [9] <author> M. Irani and S. Peleg. </author> <title> Image sequence enhancement using multiple motions analysis. </title> <booktitle> In Proc. IEEE Conf. Comput. Vision Pattern Recog., </booktitle> <pages> pages 216-221, </pages> <address> Champaign, Illinois, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Having built up this extended background, one can simply move the viewing frame over it, thereby requiring a minimal amount of data. camera is selecting one part of the extended background <ref> [9, 18] </ref>. To build up the extended background we may consider (a) original scene that is larger than any individual frame. (b) The information from all the frames may be accumulated into a single large layer. <p> Critical processing involves motion estimation and segmentation. A number of authors have described methods for achieving multiple affine motion decompositions <ref> [3, 5, 9] </ref>. Our method is based on robust estimation and k-means clus 5 tering in affine parameter space. In many multiple motion estimation techniques, a recursive algorithm is used is to detect multiple motion regions in the scene [3, 9]. <p> Our method is based on robust estimation and k-means clus 5 tering in affine parameter space. In many multiple motion estimation techniques, a recursive algorithm is used is to detect multiple motion regions in the scene <ref> [3, 9] </ref>. At each iteration, these algorithms assume that a dominant motion region can be detected. Once the dominant region is identified and the motion within the region is estimated, it is eliminated and the next dominant motion is estimated from the remaining portion of the image.
Reference: [10] <author> R. Lenz and A. Gerhard. </author> <title> Image sequence coding using scene analysis and spatio-temporal interpolation. </title> <editor> In T. S. Huang, editor, </editor> <title> Image sequence processing and dynamic scene analysis, </title> <booktitle> volume F2 of NATO ASI Series, </booktitle> <pages> pages 264-274. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1983. </year>
Reference-contexts: The box labeled "cmp" generates the complement of alpha, (1 ff) The layered representation that we propose is also an imperfect model of the world but it is able to cope with a wider variety of phenomena than the traditional representations. The approach may be categorized with object-based methods <ref> [10, 14] </ref>. 2 The layered representation As discussed above, a layer contains a set of maps specifying its intensity, opacity, and motion. Other maps can be defined as well, but these ones are crucial.
Reference: [11] <author> A. Lippman and R. Kermode. </author> <title> Generalized predictive coding of movies. </title> <booktitle> In Picture Encoding Symposium, </booktitle> <pages> pages 17-19, </pages> <address> Lausanne, Switzerland, </address> <year> 1993. </year>
Reference-contexts: Each frame is then a glimpse into this layer as viewed through a window. the background to be a continuous function of unlimited spatial extent <ref> [11, 13] </ref>. Each image in a sequence captures a set of discrete samples from that function within the bounds specified by the viewing frame. The viewing parameters may change over time; for example the background image may undergo affine or higher-order distortions.
Reference: [12] <author> B. Lucas and T. Kanade. </author> <title> An iterative image registration technique with an application to stereo vision. </title> <booktitle> In Image Understanding Workshop, </booktitle> <pages> pages 121-130, </pages> <year> 1981. </year>
Reference-contexts: we impose constraints on coherent region size and local connectivity by applying simple thresholds to reject outliers at different stages in the algorithm, thus providing stability and robustness. 5.1 Optic flow estimation Our local motion estimate is obtained with a multi-scale coarse-to-fine algorithm based on a gradient approach described by <ref> [2, 12, 16] </ref>.
Reference: [13] <author> P. C. McLean. </author> <title> Structured video coding. </title> <institution> Master of science in media arts and sciences, The Media Lab, Mas-sachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Each frame is then a glimpse into this layer as viewed through a window. the background to be a continuous function of unlimited spatial extent <ref> [11, 13] </ref>. Each image in a sequence captures a set of discrete samples from that function within the bounds specified by the viewing frame. The viewing parameters may change over time; for example the background image may undergo affine or higher-order distortions.
Reference: [14] <author> H. G. Musmann, M. Hotter, and J. Ostermann. </author> <title> Object-oriented analysis-synthesis coding of moving images. </title> <booktitle> Signal Processing: Image Communication 1, </booktitle> <pages> pages 117-138, </pages> <year> 1989. </year>
Reference-contexts: The box labeled "cmp" generates the complement of alpha, (1 ff) The layered representation that we propose is also an imperfect model of the world but it is able to cope with a wider variety of phenomena than the traditional representations. The approach may be categorized with object-based methods <ref> [10, 14] </ref>. 2 The layered representation As discussed above, a layer contains a set of maps specifying its intensity, opacity, and motion. Other maps can be defined as well, but these ones are crucial.
Reference: [15] <author> T. Poggio, V. Torre, and C. Koch. </author> <title> Computational vision and regularization theory. </title> <journal> Nature, </journal> <volume> 317 </volume> <pages> 314-319, </pages> <year> 1985. </year>
Reference-contexts: The velocity field is single-valued and smooth, and so the mixing of the two motions is inevitable. The analysis can be improved by allowing for sharp breaks in the velocity field, as is often done with regularization <ref> [7, 15] </ref>.
Reference: [16] <author> L. H. Quam. </author> <title> Hierarchial warp stereo. </title> <booktitle> In Proc. DARPA Image Understing Workshop, </booktitle> <pages> pages 149-155, </pages> <address> New Or-leans, Lousiana, 1984. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: we impose constraints on coherent region size and local connectivity by applying simple thresholds to reject outliers at different stages in the algorithm, thus providing stability and robustness. 5.1 Optic flow estimation Our local motion estimate is obtained with a multi-scale coarse-to-fine algorithm based on a gradient approach described by <ref> [2, 12, 16] </ref>.
Reference: [17] <author> M. Shizawa and K. Mase. </author> <title> A unified computational theory for motion transparency and motion boundaries based on eigenenergy analysis. </title> <booktitle> In Proc. IEEE Conf. Comput. Vision Pattern Recog., </booktitle> <pages> pages 289-295, </pages> <address> Maui, Hawaii, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: The summation is taken over a small neighborhood around the point (x; y). The multi-scale implementation allows for estimation of large motions. When analyzing scenes exhibiting transparent phenomena, the motion estimation technique described by Shizawa and Mase <ref> [17] </ref> may be suitable. However, in most natural scenes, the simple optic flow model provides a good starting point for our segmentation algorithm. 5.2 Motion segmentation Given the optic flow field, the task of segmentation is to identify the coherent motion regions.
Reference: [18] <author> L. Teodosio and W. Bender. </author> <title> Salient video stills. </title> <booktitle> In Proc. of the ACM Multimedia Conference, </booktitle> <address> Anaheim, CA, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Having built up this extended background, one can simply move the viewing frame over it, thereby requiring a minimal amount of data. camera is selecting one part of the extended background <ref> [9, 18] </ref>. To build up the extended background we may consider (a) original scene that is larger than any individual frame. (b) The information from all the frames may be accumulated into a single large layer.
Reference: [19] <author> C. W. Therrien. </author> <title> Decision Estimation and Classification. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Motion models from regions that cover the same object will have similar parameters. These are grouped in the affine motion parameter space with a k-means clustering algorithm <ref> [19] </ref>, which is modified to allow k to be determined adaptively. In the clustering process, we derive a representative model for each group of similar models. This model clustering produces a set of likely affine motion models that are exhibited by objects in the scene.
Reference: [20] <author> J. Y. A. Wang and E. H. Adelson. </author> <title> Layered representation for image sequence coding. </title> <booktitle> In Proc. IEEE ICASSP, </booktitle> <volume> volume 5, </volume> <pages> pages 221-224, </pages> <address> Minneapolis, Min-nesota, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: The velocity maps are restricted to affine transformations. There are no delta maps used. In spite of these simplifications the representation is able to capture much of the desired image information. Earlier discussions of this work are contained in <ref> [20, 21] </ref>. 3 Analysis into layers Let us begin by considering the first layer: the background. Sometimes the background is stationary but often it is undergoing a smooth motion due, for example, to a camera pan.
Reference: [21] <author> J. Y. A. Wang and E. H. Adelson. </author> <title> Layered representation for motion analysis. </title> <booktitle> In Proc. IEEE Conf. Comput. Vision Pattern Recog., </booktitle> <pages> pages 361-366, </pages> <address> New York, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: The velocity maps are restricted to affine transformations. There are no delta maps used. In spite of these simplifications the representation is able to capture much of the desired image information. Earlier discussions of this work are contained in <ref> [20, 21] </ref>. 3 Analysis into layers Let us begin by considering the first layer: the background. Sometimes the background is stationary but often it is undergoing a smooth motion due, for example, to a camera pan.
Reference: [22] <author> J. Y. A. Wang, E. H. Adelson, and U. Y. Desai. </author> <title> Applying mid-level vision techniques for video data compression and manipulation. </title> <booktitle> In Proc. SPIE on Digital Video Compression on Personal Computers: Algorithms and Technologies, </booktitle> <volume> volume 2187, </volume> <pages> pages 116-127, </pages> <address> San Jose, California, </address> <month> February </month> <year> 1994. </year> <month> 13 </month>
Reference-contexts: The layers can be compressed using conventional still image compression schemes. While we have not yet done extensive studies of compression we can describe some preliminary results <ref> [22] </ref>. The data that must be sent to reconstruct the flower garden sequence includes the intensity maps, the alpha maps, and the motion parameters for each layer. To compress the intensity map we used a JPEG coder.
References-found: 22

