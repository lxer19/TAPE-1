URL: http://www.cs.huji.ac.il/papers/IP/gram.ps.gz
Refering-URL: http://www.cs.huji.ac.il/papers/IP/index.html
Root-URL: 
Title: Model-based invariants for 3D vision  
Author: Daphna Weinshall 
Address: H1-B47 P.O.Box 704 Yorktown Heights, NY 10598  
Affiliation: IBM T.J. Watson Research Center,  
Abstract: Invariance under a group of 3D transformations seems a desirable component of an efficient 3D shape representation. We propose representations which are invariant under weak perspective to either rigid or affine 3D transformations, and we show how they can be computed efficiently from a sequence of images with a linear and incremental algorithm. We show simulated results with perspective projection and noise, and the results of model acquisition from a real sequence of images. The use of linear computation, together with the integration through time of invariant representations, offers improved robustness and stability. Using these invariant representations, we derive model-based projective invariant functions of general 3D objects. We discuss the use of the model-based invariants with existing recognition strategies: alignment without transformation, and constant time indexing from 2D images of general 3D objects.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Y. Aloimonos and C. M. Brown. </author> <title> Perception of structure from motion: I: optic flow vs. discrete displacements, II: lower bound results. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 510-517, </pages> <address> Miami Beach, FL, </address> <year> 1986. </year>
Reference-contexts: From Eq (8) it also follows that each image gives two linear equations in the elements of B. Since there are five independent unknowns, we need at least three views to compute B 1 . This is the theoretically minimal information required for structure from motion <ref> [22, 1] </ref>. Note, however, that three views give us six equations, enough to compute B and to verify that the three views of the four points indeed come from a rigid object and a rigid transformation. <p> the value of f B as a function of the varying distance between the camera and the object, using two different test objects: International Journal of Computer Vision 10 (1):27-42, 1993 15 * The first test object (graphs I in Fig 3) was composed of four points selected randomly in <ref> [0; 1] </ref> 3 . We compared it to two other types of objects: in type 1 the objects were composed of four points selected randomly in [0; 1] 3 ; in type 2 the object was composed of four non coplanar corners of the unity cube. * The second test object <p> Computer Vision 10 (1):27-42, 1993 15 * The first test object (graphs I in Fig 3) was composed of four points selected randomly in <ref> [0; 1] </ref> 3 . We compared it to two other types of objects: in type 1 the objects were composed of four points selected randomly in [0; 1] 3 ; in type 2 the object was composed of four non coplanar corners of the unity cube. * The second test object (graphs II in Fig 3) was composed of four non-coplanar corners of the unity cube. <p> Thus there are 6 unknown elements in B, for which two images give three constraints each. If the equations were independent, two images of four points should have been sufficient to compute depth. This contradicts previous results <ref> [1] </ref>, and therefore it is not surprising that the 6 equations are linearly dependent, as the following discussion shows.
Reference: [2] <author> J.B. Burns, R. Weiss, and E. Riseman. </author> <title> View variation of point-set and line segment features. </title> <booktitle> In Proceedings Image Understanding Workshop, </booktitle> <pages> pages 650-659, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Invariance with respect to projective transformation is harder to accomplish. Recently, Burns et al. <ref> [2] </ref> (as well as Clemens & Jacobs [3] and Moses & Ullman [16]) have shown that unconstrained projective invariant functions do not exist. Most of the research in the area of projective invariance has concentrated on the identification of computable invariances in some special cases [26]. <p> More precise definitions, as well as the enumeration of the number of invariants under different transformation groups G and object sets , are given in [5, 6]. As discussed in the introduction, a few recent papers showed that universal invariant functions (which are not constant) do not exist <ref> [2, 3, 16] </ref> for perspective and weak perspective projections. Special-case invariants for special sets of objects are discussed in [16, 5], for example.
Reference: [3] <author> D. T. Clemens and D. W. Jacobs. </author> <title> Space and time bounds on indexing 3-D models from 2-D images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(10) </volume> <pages> 1007-1017, </pages> <year> 1991. </year>
Reference-contexts: Invariance with respect to projective transformation is harder to accomplish. Recently, Burns et al. [2] (as well as Clemens & Jacobs <ref> [3] </ref> and Moses & Ullman [16]) have shown that unconstrained projective invariant functions do not exist. Most of the research in the area of projective invariance has concentrated on the identification of computable invariances in some special cases [26]. <p> More precise definitions, as well as the enumeration of the number of invariants under different transformation groups G and object sets , are given in [5, 6]. As discussed in the introduction, a few recent papers showed that universal invariant functions (which are not constant) do not exist <ref> [2, 3, 16] </ref> for perspective and weak perspective projections. Special-case invariants for special sets of objects are discussed in [16, 5], for example.
Reference: [4] <author> O. Faugeras. </author> <booktitle> What can be seen in three dimensions with an uncalibrated stereo rig? In Proceedings of the 2nd European Conference on Computer Vision, </booktitle> <pages> pages 563-578, </pages> <address> Santa Margherita Ligure, Italy, 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: To compensate, the weak perspective algorithm uses all the available images in order to minimize the errors due to noise and higher order effects of perspectivity. The weak perspective scheme requires at least three images. Algorithms that use full perspective (see <ref> [4, 15] </ref> for recent related work on structure without calibration) are useful under conditions typical to stereo viewing, namely, when there are only two images or when the differences between the images are large and observable.
Reference: [5] <author> D. Forsyth, J. L. Mundy, A. Zisserman, C. Coelho, A. Heller, and C. Rothwell. </author> <title> Invariant descriptors for 3-D object recognition and pose. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <pages> 971-991, </pages> <year> 1991. </year>
Reference-contexts: In fact, most of the published results address planar collections of points or curves. One elegant example of the use of such invariants, e.g. pairs of plane conics, has been recently given in <ref> [5] </ref>. More generally, Moses & Ullman [16] studied the existence of projective invariants for specific classes of objects, such as bilaterally symmetric objects. In this paper we describe a particular hierarchy of affine and rigid invariant representations. <p> More precise definitions, as well as the enumeration of the number of invariants under different transformation groups G and object sets , are given in <ref> [5, 6] </ref>. As discussed in the introduction, a few recent papers showed that universal invariant functions (which are not constant) do not exist [2, 3, 16] for perspective and weak perspective projections. Special-case invariants for special sets of objects are discussed in [16, 5], for example. <p> As discussed in the introduction, a few recent papers showed that universal invariant functions (which are not constant) do not exist [2, 3, 16] for perspective and weak perspective projections. Special-case invariants for special sets of objects are discussed in <ref> [16, 5] </ref>, for example. A projective invariant function f is model-based invariant if its domain of objects is a single general 3D object, namely, = f!g; ! 2 R 3n (see illustration in Fig. 1).
Reference: [6] <author> P. Gros and L. Quan. </author> <title> Invariant theory: a practical introduction. </title> <institution> RT 69-IMAG-7 LIFIA, Institut IMAG, University of Grenoble, France, </institution> <year> 1991. </year>
Reference-contexts: More precise definitions, as well as the enumeration of the number of invariants under different transformation groups G and object sets , are given in <ref> [5, 6] </ref>. As discussed in the introduction, a few recent papers showed that universal invariant functions (which are not constant) do not exist [2, 3, 16] for perspective and weak perspective projections. Special-case invariants for special sets of objects are discussed in [16, 5], for example.
Reference: [7] <author> D. Heeger and A. Jepson. </author> <title> Simple method for computing 3D motion and depth. </title> <booktitle> In Proceedings of the 3rd International Conference on Computer Vision, </booktitle> <pages> pages 96-100, </pages> <address> Osaka, Japan, 1990. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: Nevertheless, most Structure From Motion algorithms attempt to compute a complete representation of the scene, namely, structure in the form of a depth map and pose, using a sequence of 2D images (see, for example, <ref> [18, 7] </ref>). The invariant representations do not require the computation of camera calibration (or pose), and therefore they should be easier to compute robustly. Moreover, an invariant representation is a natural frame of reference for the integration of information across time.
Reference: [8] <author> T. S. Huang and C. H. Lee. </author> <title> Motion and structure from orthographic projections. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11(5) </volume> <pages> 536-540, </pages> <year> 1989. </year>
Reference-contexts: Let X and Y denote the coordinates of the three points in a second image, and let R = fr i;j g 3 i;j=1 denote the 3D rotation matrix between the two images. In addition to the relations in (15), which hold for both images, we know from <ref> [8] </ref> that: Y = r 13 r 31 y + r 13 where r 2 31 = r 2 13 ) c 2 2 c 2 Substituting (16) in one of the corresponding relations given in (15) for the second image, and using X T BX = 1, we get: Y
Reference: [9] <author> D. P. Huttenlocher and S. Ullman. </author> <title> Object recognition using alignment. </title> <booktitle> In Proceedings of the 1st International Conference on Computer Vision, </booktitle> <pages> pages 102-111, </pages> <address> London, England, June 1987. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: Alignment without transformation: The alignment method for recognition <ref> [9] </ref> can be summarized as follows: 1. match three points in the image to the model; 2. compute the transformation between the model and the image; 3. verify recognition by predicting and matching additional model points using the computed transformation.
Reference: [10] <author> D. W. Jacobs. </author> <title> Space efficient 3D model indexing. </title> <booktitle> In Proceedings Image Understanding Workshop, </booktitle> <month> January </month> <year> 1992. </year>
Reference-contexts: We also pay in a higher frequency of inevitable false positive matches (or accidental matches). As an example, we will derive the lookup table for the affine model-based invariant function (a similar scheme is described in <ref> [10] </ref>): Let b denote the affine representation of five non-coplanar image points, as defined in Eq (3). There are three unknown parameters in this representation, b 1 ; b 2 ; b 3 , while a single image gives only two constraints on these unknowns.
Reference: [11] <author> J. J. Koenderink and A. J. van Doorn. </author> <title> Affine structure from motion. </title> <journal> Journal of the Optical Society of America, </journal> <volume> 8(2) </volume> <pages> 377-385, </pages> <year> 1991. </year>
Reference-contexts: Other transformations describe the change of illumination. In this paper we are interested in the group of 3D transformations. We describe a hierarchy of invariant representations, produced by the particular selection of the group of 3D transformations (cf. <ref> [11] </ref>): Complete: The complete representation of a scene includes the 3D coordinates of each point, possibly as a depth map, and the pose of the camera relative to the object in each image. This representation is typically sought in reconstruction algorithms in computer vision. <p> Therefore when the pose information is not needed, which is typically the case in recognition tasks, the use of invariant representations promises significant computational advantages. Affine invariant representations in particular, and their computational advantages, were discussed in <ref> [11] </ref>. Affine representations were initially used for recognition applications, in geometric hashing [12] and linear combination [24]. <p> A rigid-invariant representation is therefore desirable since it eliminates the need to compute the orientation of the object. For computational convenience, we also consider the group of transformations G af f , which includes 3D translations and linear (or affine) transformations <ref> [11] </ref>. A representation function D, which is invariant to G af f , will be called an affine-invariant representation. Affine representations cannot be unique: objects which are related by a linear transformation will have the same affine representation. Note that an affine-invariant representation is also rigid-invariant.
Reference: [12] <author> Y. Lamdan and H. Wolfson. </author> <title> Geometric hashing: a general and efficient recognition scheme. </title> <booktitle> In Proceedings of the 2nd International Conference on Computer Vision, </booktitle> <pages> pages 238-251, </pages> <address> Tarpon Springs, FL, 1988. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: Therefore when the pose information is not needed, which is typically the case in recognition tasks, the use of invariant representations promises significant computational advantages. Affine invariant representations in particular, and their computational advantages, were discussed in [11]. Affine representations were initially used for recognition applications, in geometric hashing <ref> [12] </ref> and linear combination [24]. The cost of using an affine representation is more false positive matches, since affine representations are not unique. 3D shape representations, which are invariant to projective 3D transformations, are of particular interest for the recognition of 3D objects from 2D images. <p> The computational complexity of these invariant functions depends linearly on the number of objects. We also show how model-based invariant functions can be used for recognition with constant computational complexity, providing a constant time index into a lookup table (cf. <ref> [12] </ref>). The cost is the need to use large multi-dimensional lookup tables (two- and four-dimensional in our examples) instead of a one-dimensional table. The rest of this paper is organized as follows: in Section 2 we describe affine and rigid invariant representations of 3D shape. <p> R 3 can be written as a linear combination of this basis: p l = b l 2 v 2 + b l The vector b l = (b l 1 ; b l 3 ) is an affine invariant of point P l (a related representation is discussed in <ref> [12] </ref>). Given a particular basis of three independent vectors fv l g 3 l=1 defining the coordinate system V , the affine coordinates fb l g n l=1 of the set of points hP i are unique, providing an affine-invariant representation of the object. <p> It follows from the definition that affine invariants lead to non-accidental matches. 3.2 Examples of model based invariant functions: Rigid invariant: Consider an object composed of four non-coplanar 3D points. (If all points are coplanar, there exist a few other projective invariants, e.g., the affine invariant discussed in <ref> [12] </ref>). Let fP l g 3 l=0 denote the 3D coordinates of the four points in some frame of reference. <p> The time complexity of the proposed computation does not depend on M . Another application for indexing is described in [14]. In this discussion we use a variation on the recognition scheme proposed by Lamdan & Wolfson in <ref> [12] </ref>. The idea there is to store as much information as possible on all the objects in the database, and all their possible appearances, in a lookup table. <p> The principle behind this approach is the conversion of on-line time-complexity at recognition time to space-complexity, at the cost of additional preprocessing computation time. In the scheme proposed in <ref> [12] </ref>, each ordered subset of the object features is represented by a single entry in the table. At recognition time, using 2D images of coplanar objects or using range data, the data provides a unique index into the table.
Reference: [13] <author> H. Mitsumoto, S. Tamura, K. Okazaki, N. Kajimi, and Y. </author> <title> Fukui. 3-D reconstruction using mirror images based on a plane symmetry recovering method. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(9) </volume> <pages> 941-946, </pages> <year> 1992. </year> <journal> International Journal of Computer Vision 10(1):27-42, 1993 24 </journal>
Reference-contexts: For example, with known bilateral symmetry there are only four unknown elements in B, thus two views are sufficient to compute the rigid structure of the four points and to verify their rigidity. This complements the results discussed in <ref> [17, 13] </ref>, where it was shown that a single view of a bilaterally symmetric object is equivalent to having two views of the object. 3 Model Based Invariant functions We now define model-based projective invariant functions (Section 3.1), and describe a rigid and an affine model-based invariant functions (Section 3.2). 2
Reference: [14] <author> R. Mohan, D. Weinshall, and R. R. Sarukkai. </author> <title> 3D object recognition by indexing structural invariants from multiple views. </title> <booktitle> In Proceedings of the 4th International Conference on Computer Vision, </booktitle> <pages> pages 264-268, </pages> <address> Berlin, Germany, 1993. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: This can be implemented by storing up to O (n 4 ) 3 fi 3 matrices (see <ref> [14] </ref>). It is also possible to represent hP i by a n fi n symmetric matrix ~ B, the extension of the inverse Gramian B to n + 1 points. <p> We now describe a different use for recognition of the model-based invariant functions given in Eq (9) and Eq (10). The time complexity of the proposed computation does not depend on M . Another application for indexing is described in <ref> [14] </ref>. In this discussion we use a variation on the recognition scheme proposed by Lamdan & Wolfson in [12]. The idea there is to store as much information as possible on all the objects in the database, and all their possible appearances, in a lookup table.
Reference: [15] <author> R. Mohr, , L. Quan, F. Veillon, and B. Boufama. </author> <title> Relative 3D reconstruction using multiple uncalibrated images. </title> <institution> RT 84-IMAG-12 LIFIA, Institut IMAG, University of Grenoble, France, </institution> <year> 1992. </year>
Reference-contexts: To compensate, the weak perspective algorithm uses all the available images in order to minimize the errors due to noise and higher order effects of perspectivity. The weak perspective scheme requires at least three images. Algorithms that use full perspective (see <ref> [4, 15] </ref> for recent related work on structure without calibration) are useful under conditions typical to stereo viewing, namely, when there are only two images or when the differences between the images are large and observable.
Reference: [16] <author> Y. Moses and S. Ullman. </author> <title> Limitations of non model-based schemes. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1301, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1991. </year>
Reference-contexts: Invariance with respect to projective transformation is harder to accomplish. Recently, Burns et al. [2] (as well as Clemens & Jacobs [3] and Moses & Ullman <ref> [16] </ref>) have shown that unconstrained projective invariant functions do not exist. Most of the research in the area of projective invariance has concentrated on the identification of computable invariances in some special cases [26]. In fact, most of the published results address planar collections of points or curves. <p> In fact, most of the published results address planar collections of points or curves. One elegant example of the use of such invariants, e.g. pairs of plane conics, has been recently given in [5]. More generally, Moses & Ullman <ref> [16] </ref> studied the existence of projective invariants for specific classes of objects, such as bilaterally symmetric objects. In this paper we describe a particular hierarchy of affine and rigid invariant representations. We describe the transformations between different representations, and show some object symmetries that are readily mediated by these representations. <p> More precise definitions, as well as the enumeration of the number of invariants under different transformation groups G and object sets , are given in [5, 6]. As discussed in the introduction, a few recent papers showed that universal invariant functions (which are not constant) do not exist <ref> [2, 3, 16] </ref> for perspective and weak perspective projections. Special-case invariants for special sets of objects are discussed in [16, 5], for example. <p> As discussed in the introduction, a few recent papers showed that universal invariant functions (which are not constant) do not exist [2, 3, 16] for perspective and weak perspective projections. Special-case invariants for special sets of objects are discussed in <ref> [16, 5] </ref>, for example. A projective invariant function f is model-based invariant if its domain of objects is a single general 3D object, namely, = f!g; ! 2 R 3n (see illustration in Fig. 1).
Reference: [17] <author> T. Poggio and T. Vetter. </author> <title> Recognition of structure from one 2D model view: observations of prototypes, object classes and symmetries. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1347, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1992. </year>
Reference-contexts: For example, with known bilateral symmetry there are only four unknown elements in B, thus two views are sufficient to compute the rigid structure of the four points and to verify their rigidity. This complements the results discussed in <ref> [17, 13] </ref>, where it was shown that a single view of a bilaterally symmetric object is equivalent to having two views of the object. 3 Model Based Invariant functions We now define model-based projective invariant functions (Section 3.1), and describe a rigid and an affine model-based invariant functions (Section 3.2). 2
Reference: [18] <author> H. S. Sawhney, J. Oliensis, and A. R. Hanson. </author> <title> Description and reconstruction from image trajectories of rotational motion. </title> <booktitle> In Proceedings of the 3rd International Conference on Computer Vision, </booktitle> <pages> pages 494-498, </pages> <address> Osaka, Japan, 1990. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: Nevertheless, most Structure From Motion algorithms attempt to compute a complete representation of the scene, namely, structure in the form of a depth map and pose, using a sequence of 2D images (see, for example, <ref> [18, 7] </ref>). The invariant representations do not require the computation of camera calibration (or pose), and therefore they should be easier to compute robustly. Moreover, an invariant representation is a natural frame of reference for the integration of information across time.
Reference: [19] <author> A. Shashua. </author> <title> Correspondence and affine shape from two orthographic view: motion and recognition. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1327, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: Indeed, it can be readily shown that it is sufficient to use one view and the perpendicular component of the 2D motion field at each point. (This result has also been shown by Shashua in <ref> [19] </ref>.) This is useful when the aperture problem constrains the computation of the 2D motion field, and for the generalization of this analysis to continuous optical flow.
Reference: [20] <author> C. Tomasi and T. Kanade. </author> <title> Shape and motion from image streams: a factorization method - 3. detection and tracking of point features. </title> <institution> CMU-CS-91-132, School of Computer Science, </institution> <address> CMU, </address> <year> 1991. </year>
Reference-contexts: The sequence was provided by Carlo Tomasi, who also provided the coordinates of the tracked marks, which were obtained by his tracking algorithm described in <ref> [20] </ref>. One image of the sequence is shown in Fig 4. The object was relatively far from the camera, and therefore the weak perspective assumption is appropriate for this sequence. Four points were selected to serve as basis points.
Reference: [21] <author> C. Tomasi and T. Kanade. </author> <title> Shape and motion from image streams under orthography: a factorization method. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9(2) </volume> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: Discussion The invariant structure from motion algorithm described above belongs to a small group of recent algorithms which rely on many images to compute structure (e.g., <ref> [21] </ref>; see also [23] for an earlier work). This is an important feature, since motion disparities are typically noisy with low signal to noise ratios. Our algorithm is particularly simple, requiring only the closed-form solution of over-determined linear systems of equations.
Reference: [22] <author> S. Ullman. </author> <title> Computational studies in the interpretation of structure and motion: summary and extension. </title> <editor> In J. Beck, B. Hope, and A. Rosenfeld, editors, </editor> <booktitle> Human and Machine Vision. </booktitle> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: From Eq (8) it also follows that each image gives two linear equations in the elements of B. Since there are five independent unknowns, we need at least three views to compute B 1 . This is the theoretically minimal information required for structure from motion <ref> [22, 1] </ref>. Note, however, that three views give us six equations, enough to compute B and to verify that the three views of the four points indeed come from a rigid object and a rigid transformation.
Reference: [23] <author> S. Ullman. </author> <title> Maximizing rigidity: the incremental recovery of 3D structure from rigid and rubbery motion. </title> <journal> Perception, </journal> <volume> 13 </volume> <pages> 255-274, </pages> <year> 1984. </year>
Reference-contexts: Discussion The invariant structure from motion algorithm described above belongs to a small group of recent algorithms which rely on many images to compute structure (e.g., [21]; see also <ref> [23] </ref> for an earlier work). This is an important feature, since motion disparities are typically noisy with low signal to noise ratios. Our algorithm is particularly simple, requiring only the closed-form solution of over-determined linear systems of equations. <p> Our algorithm is particularly simple, requiring only the closed-form solution of over-determined linear systems of equations. Unlike most algorithms, our algorithm computes shape without computing explicit depth or the transformation between images. Like <ref> [23] </ref> and unlike most algorithms, it can be implemented in an incremental way, updating the results with additional data without storing all the previous data.
Reference: [24] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <pages> 992-1006, </pages> <year> 1991. </year>
Reference-contexts: Affine invariant representations in particular, and their computational advantages, were discussed in [11]. Affine representations were initially used for recognition applications, in geometric hashing [12] and linear combination <ref> [24] </ref>. The cost of using an affine representation is more false positive matches, since affine representations are not unique. 3D shape representations, which are invariant to projective 3D transformations, are of particular interest for the recognition of 3D objects from 2D images.
Reference: [25] <author> D. Weinshall and C. Tomasi. </author> <title> Linear and incremental acquisition of invariant shape models from image sequences. </title> <booktitle> In Proceedings of the 4th International Conference on Computer Vision, </booktitle> <pages> pages 675-682, </pages> <address> Berlin, Germany, 1993. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: In Section 4.1 we use this property to outline a new structure from motion algorithm. In Section 4.2 we show results with simulated and real data. A more complete and efficient algorithm is described in <ref> [25] </ref>, with additional tests and a quantitative comparison to other algorithms. 4.1 Linear structure from motion algorithm given correspondence We have shown that the rigid representation D rig can be computed from as few as three images of four points with a linear algorithm.
Reference: [26] <author> I. Weiss. </author> <title> Projective invariants of shapes. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 291-297, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Recently, Burns et al. [2] (as well as Clemens & Jacobs [3] and Moses & Ullman [16]) have shown that unconstrained projective invariant functions do not exist. Most of the research in the area of projective invariance has concentrated on the identification of computable invariances in some special cases <ref> [26] </ref>. In fact, most of the published results address planar collections of points or curves. One elegant example of the use of such invariants, e.g. pairs of plane conics, has been recently given in [5].
References-found: 26

