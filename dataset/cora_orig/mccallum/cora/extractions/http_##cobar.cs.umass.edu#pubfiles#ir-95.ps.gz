URL: http://cobar.cs.umass.edu/pubfiles/ir-95.ps.gz
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: croftg@cs.umass.edu  
Title: Corpus-Based Stemming using Co-occurrence of Word Variants  
Author: Jinxi Xu and W. Bruce Croft 
Address: Amherst, MA 01003. fxu,  
Affiliation: Computer Science Department University of Massachusetts,  
Abstract: Stemming is used in many information retrieval (IR) systems to reduce variant word forms to common roots. It is one of the simplest applications of natural language processing to IR, and one of the most effective in terms of user acceptance and consistent, though small, retrieval improvements. Current stemming techniques do not, however, reflect the language use in specific corpora and this can lead to occasional serious retrieval failures. We propose a technique for using corpus-based word variant co-occurrence statistics to modify or create a stemmer. The experimental results generated using English newspaper and legal text and Spanish text demonstrate the viability of this technique and its advantages relative to conventional approaches Categories and Subject Descriptors: H.3.1. [Information Storage and Retrieval]: Content Analysis and Indexing indexing methods; linguistic processing; H.3.3. [Information Storage and Retrieval]: Information Search and Retrieval query formulation; search process General terms: Algorithms, Experimentation, Performance Additional Key Words and Phrases: information retrieval, stemming, corpus analysis, co-occurrence, class refinement, n-gram that only employ morphological rules.
Abstract-found: 1
Intro-found: 1
Reference: [Broglio et al., 1994] <author> Broglio, J., Callan, J. P., and Croft, W. </author> <year> (1994). </year> <title> An overview of the INQUERY system as used for the TIPSTER project. </title> <booktitle> In Proceedings of the TIPSTER Workshop, </booktitle> <pages> pp. 47-67. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Co-occurrence metrics and class refinement algorithms are discussed there. Section 4 describes the experimental setup. Section 5 presents the experiment results obtained on the English corpora. Section 6 is about results obtained on the Spanish corpus. All experiments are carried out using the INQUERY retrieval system <ref> [Broglio et al., 1994] </ref>. 2 2 Corpora Used in Experiments The retrieval experiments in this study are carried out on three English corpora and a Spanish corpus.
Reference: [Broglio et al., 1995] <author> Broglio, J., Callan, J. P., Croft, W. B., and Nachbar, D. W. </author> <year> (1995). </year> <title> Document Retrieval and Routing Using the INQUERY System. </title> <editor> In Harman, D., editor, </editor> <booktitle> Proceedings of the Third Text REtrieval Conference (TREC-3), </booktitle> <pages> pp. 22-29. </pages> <note> NIST Special Publication 500-225. </note>
Reference-contexts: The baseline stemmer for the Spanish experiment is a Porter style stemmer designed at the Center for Intelligent Information Retrieval at University of Massachusetts at Amherst and used by UMASS in the Spanish experiments of TREC conferences <ref> [Broglio et al., 1995] </ref>. 16 Precision (% change) - 25 queries Recall baseline ngramCC ngramOptimal 10 48.9 49.6 (+1:4) 50.0 (+2:4) 30 31.8 33.7 (+6:0) 33.8 (+6:1) 50 21.6 21.9 (+1:3) 20.8 (3:9) 70 12.6 12.6 (+0:2) 12.8 (+2:1) 90 4.9 5.0 (+1:4) 5.2 (+6:5) average 21.2 21.6 (+1:9) 21.9 (+3:3)
Reference: [Church and Hanks, 1989] <author> Church, K., and Hanks, P. </author> <year> (1989). </year> <title> Word association norms, mutual information, and lexicography. </title> <booktitle> In Proceedings of the 27th ACL Meeting, </booktitle> <pages> pp. 76-83. </pages>
Reference-contexts: The basic hypothesis is that the word forms that should be conflated for a given corpus will co-occur in documents from that corpus. Based on that hypothesis, we use a co-occurrence measure similar to the expected mutual information measure (EMIM <ref> [van Rijsbergen, 1979; Church and Hanks, 1989] </ref>) to modify an initial set of con-flation classes generated by a stemmer. In the past, co-occurrence information was primarily used for thesaurus construction [Sparck Jones, 1971]. <p> En (a; b) is the expected number of co-occurrences assuming a and b are statistically independent. The metric is a variation of EMIM (expected mutual information measure) <ref> [van Rijsbergen, 1979; Church and Hanks, 1989] </ref>, which is widely used to measure significance of associations.
Reference: [Croft and Xu, 1995] <author> Croft, W. B., and Xu, J. </author> <year> (1995). </year> <title> Corpus-specific stemming using word form co-occurrence. </title> <booktitle> In Fourth Annual Symposium on Document Analysis and Information Retrieval, </booktitle> <pages> pp. 147-159. </pages>
Reference-contexts: If the window size is too large, step 3 will consume too much time because its running time is proportional to the window size. Our previous work showed that the appropriate window size should be 50-100 words <ref> [Croft and Xu, 1995] </ref>. In this work, we always use 100 as the window size. In step 4, we must decide on the em threshold for the connected component algorithm and the ffi value for the optimal partition algorithm. <p> When the window size is fixed, the em threshold controls how many conflations are prevented: the higher the threshold, the smaller the equivalence classes after applying the connected component algorithm and the more conservative the resulted stemmer. Our previous work <ref> [Croft and Xu, 1995] </ref> showed that for window size 100, the appropriate em threshold is 0.01, which is used in this paper.
Reference: [Harman, 1991] <author> Harman, D. </author> <year> (1991). </year> <title> How effective is suffixing? Journal of the American Society for Information Science, </title> <publisher> 42(1),7-15. </publisher>
Reference-contexts: Although stemming has been studied mainly for English, there is evidence that it is useful for a number of languages, such as Slovene [Popovic and Willett, 1992] and Dutch [Kraaij, 1996]. Evaluations of stemming using test collections have produced mixed results <ref> [Harman, 1991] </ref>, but more recent work has shown consistent (if rather small) improvements in retrieval effectiveness across a range of collections [Krovetz, 1993; Hull, 1996].
Reference: [Harman, 1995] <author> Harman, D. </author> <year> (1995). </year> <title> Overview of the Third Text REtrieval Conference (TREC-3). </title> <editor> In Harman, D., editor, </editor> <booktitle> Proceedings of the Third Text REtrieval Conference (TREC-3), </booktitle> <pages> pp. 1-20. </pages> <note> NIST Special Publication 500-225. </note>
Reference-contexts: The English corpora are the WEST legal document collection [Turtle, 1994], and two collections of news articles from the TREC experiments <ref> [Harman, 1995] </ref>, WSJ (Wall Street Journal 1987-1991) 1 , and WSJ91 (Wall Street Journal 1991). The Spanish corpus is the ISM collection of the TREC conferences. The query set on ISM is the Spanish adhoc queries of TREC 4.
Reference: [Hull, 1993] <author> Hull, D. </author> <year> (1993). </year> <title> Using statistical testing in the evaluation of retrieval experiments. </title> <booktitle> In Proceedings of the 13 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 329-338. </pages>
Reference-contexts: The expanded queries are run against the unstemmed database of the corpus. Retrieval results are evaluated using the standard 10 point average precision and compared with the queries expanded by the baseline stemmers. The paired t-test <ref> [Hull, 1993] </ref> is used to decide whether the performance improvements over the baselines are statistically significant. To decide whether the improvement by method A over method B is significant, the t-test calculates a p value based on the performance data of A and B.
Reference: [Hull, 1996] <author> Hull, D. A. </author> <year> (1996). </year> <title> Stemming algorithms: A case study for detailed evaluation. </title> <journal> Journal of the American Society for Information Science, 47(1),70-84. </journal>
Reference-contexts: Evaluations of stemming using test collections have produced mixed results [Harman, 1991], but more recent work has shown consistent (if rather small) improvements in retrieval effectiveness across a range of collections <ref> [Krovetz, 1993; Hull, 1996] </ref>.
Reference: [Jing and Croft, 1994] <author> Jing, Y., and Croft, W. </author> <year> (1994). </year> <title> An association thesaurus for information retrieval. </title> <booktitle> In Proceedings of RIAO 94, </booktitle> <pages> pp. 146-160. </pages>
Reference-contexts: Because Wall Street Journal 1992 has only 0.03 GB of data, this fact should not affect the results reported in this paper 2 Jing and Croft <ref> [Jing and Croft, 1994] </ref> discuss a corpus-based technique for query expansion that produces signif icant effectiveness improvements 3 Wall St. Journal that discuss stock prices will typically contain both the words "stock" and "stocks". This technique should identify the corpus-dependent conflations ("stock" and "stocks").
Reference: [Kraaij, 1996] <author> Kraaij, W. </author> <year> (1996). </year> <title> Viewing stemming as recall enhancement. </title> <booktitle> In Proceedings of the 19 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 40-48. </pages>
Reference-contexts: Although stemming has been studied mainly for English, there is evidence that it is useful for a number of languages, such as Slovene [Popovic and Willett, 1992] and Dutch <ref> [Kraaij, 1996] </ref>. Evaluations of stemming using test collections have produced mixed results [Harman, 1991], but more recent work has shown consistent (if rather small) improvements in retrieval effectiveness across a range of collections [Krovetz, 1993; Hull, 1996].
Reference: [Krovetz, 1993] <author> Krovetz, R. </author> <year> (1993). </year> <title> Viewing morphology as an inference process. </title> <booktitle> In Proceedings of the 16 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 191-202. </pages>
Reference-contexts: 1 Introduction Stemming is a common form of language processing in most information retrieval systems <ref> [Krovetz, 1993] </ref>. It is similar to the morphological processing used in natural language processing, but has somewhat different aims. In an information retrieval system, stemming is used to reduce variant word forms to common roots, and thereby improve the ability of the system to match query and document vocabulary. <p> Evaluations of stemming using test collections have produced mixed results [Harman, 1991], but more recent work has shown consistent (if rather small) improvements in retrieval effectiveness across a range of collections <ref> [Krovetz, 1993; Hull, 1996] </ref>. <p> Despite these problems, recall/precision evaluations of the Porter stemmer have shown that it performs at least as well as other stemmers (Lovins, inflectional, derivational and removing s)[Hull, 1996]. Krovetz <ref> [Krovetz, 1993] </ref> developed a new approach to stemming based on machine-readable dictionaries and well-defined rules for inflectional and derivational morphology. This stemmer (now called KSTEM) addresses many of the problems with the Porter stemmer, but does not produce consistently better recall/precision performance. <p> The Spanish corpus is the ISM collection of the TREC conferences. The query set on ISM is the Spanish adhoc queries of TREC 4. Statistics derived from the corpora and the associated queries are shown in table 1. In previous work, stemming phrases produced different results than stemming words <ref> [Krovetz, 1993] </ref>. A stemmer could be better on word based queries but worse on phrase based queries than another stemmer. To ensure the generality of the results in the paper, we use two sets of queries on WEST, a natural language query set and a structured query set.
Reference: [Popovic and Willett, 1992] <author> Popovic, M., and Willett, P. </author> <year> (1992). </year> <title> The effectiveness of stemming for natural-language access to slovene textual data. </title> <journal> Journal of the American Society for Information Science, 43(5),384-390. </journal>
Reference-contexts: Although stemming has been studied mainly for English, there is evidence that it is useful for a number of languages, such as Slovene <ref> [Popovic and Willett, 1992] </ref> and Dutch [Kraaij, 1996]. Evaluations of stemming using test collections have produced mixed results [Harman, 1991], but more recent work has shown consistent (if rather small) improvements in retrieval effectiveness across a range of collections [Krovetz, 1993; Hull, 1996].
Reference: [Porter, 1980] <author> Porter, M. </author> <year> (1980). </year> <title> An algorithm for suffix stripping. Program, </title> <publisher> 14(3),130-137. </publisher>
Reference-contexts: One of the best-known stemmers used in experimental IR systems is the Porter stemmer <ref> [Porter, 1980] </ref>, which iteratively removes endings from a word until termination conditions are met.
Reference: [Salton, 1989] <author> Salton, G. </author> <year> (1989). </year> <title> Automatic Text Processing. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: But the connected component algorithm occasionally produces large sparsely connected equivalence classes, called "strings" in the clustering literature <ref> [Salton, 1989] </ref>, which hurt the retrieval effectiveness. Figure 1 gives some equivalence classes generated by the Porter stemmer on WSJ. <p> To process these long classes (with more than 12 members), we implement an approximation algorithm to the optimal partition algorithm. The approximation algorithm is a slightly modified version of the average link clustering algorithm <ref> [Salton, 1989] </ref>. To refine an equivalence class, we start by making each word in it a singleton class. At each step, we merge the pair of classes which have the largest cohesion.
Reference: [Sparck Jones, 1971] <author> Sparck Jones, K. </author> <year> (1971). </year> <title> Automatic Keyword Classification for Information Retrieval. </title> <publisher> Archon Books. </publisher>
Reference-contexts: Based on that hypothesis, we use a co-occurrence measure similar to the expected mutual information measure (EMIM [van Rijsbergen, 1979; Church and Hanks, 1989]) to modify an initial set of con-flation classes generated by a stemmer. In the past, co-occurrence information was primarily used for thesaurus construction <ref> [Sparck Jones, 1971] </ref>. We also test the viability of building a new stemmer without linguistic knowledge by modifying equivalence classes generated by a simple n-gram approach. The equivalence classes generated by stemmers and corpus analysis could be used at document indexing time, or when the query is formulated.
Reference: [Turtle, 1994] <author> Turtle, H. </author> <year> (1994). </year> <title> Natural language vs. Boolean query evaluation: A comparison of retrieval performance. </title> <booktitle> In Proceedings of the 17 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 212-220. </pages> <editor> [van Rijsbergen, 1979] van Rijsbergen, C. </editor> <year> (1979). </year> <note> Information Retrieval. Butterworths, second edition. </note>
Reference-contexts: All experiments are carried out using the INQUERY retrieval system [Broglio et al., 1994]. 2 2 Corpora Used in Experiments The retrieval experiments in this study are carried out on three English corpora and a Spanish corpus. The English corpora are the WEST legal document collection <ref> [Turtle, 1994] </ref>, and two collections of news articles from the TREC experiments [Harman, 1995], WSJ (Wall Street Journal 1987-1991) 1 , and WSJ91 (Wall Street Journal 1991). The Spanish corpus is the ISM collection of the TREC conferences.
Reference: [Voorhees, 1994] <author> Voorhees, E. </author> <year> (1994). </year> <title> Query expansion using lexical-semantic relations. </title> <booktitle> In Proceedings of the 17 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 61-69. 19 </pages>
Reference-contexts: For example, using a general thesaurus for automatic query expansion does not consistently improve the effectiveness of the system and can, indeed, result in less effective retrieval (e.g. <ref> [Voorhees, 1994] </ref>). When the tool can be tuned to a given domain or text corpus, however, the results are usually much better 2 .
References-found: 17

