URL: http://www.math.tau.ac.il/~mansour/papers/95-jcss.ps.gz
Refering-URL: 
Root-URL: 
Title: An O(n log log n Learning Algorithm for DNF under the Uniform Distribution  
Author: Yishay Mansour 
Date: February 4, 1998  
Abstract: We show that a DNF with terms of size at most d can be approximated by a function with at most d O(d log1=") non zero Fourier coefficients such that the expected error squared, with respect to the uniform distribution, is at most ". This property is used to derive a learning algorithm for DNF, under the uniform distribution. The learning algorithm uses queries and learns, with respect to the uniform distribution, a DNF with terms of size at most d in time polynomial in n and d O(d log 1=") . The interesting implications are for the case when " is constant. In this case our algorithm learns a DNF with a polynomial number of terms in time n O(log log n) , and a DNF with terms of size at most O(log n= log log n) in polynomial time.
Abstract-found: 1
Intro-found: 1
Reference: [Ajt83] <author> M. Ajtai. </author> <title> P 1 1 -formulae on finite structure. </title> <journal> Annals of Pure and Applied Logic, </journal> <volume> 24 </volume> <pages> 1-48, </pages> <year> 1983. </year>
Reference-contexts: Our results are based on the lower bound techniques that were developed for proving lower bound for polynomial size constant depth circuit <ref> [Ajt83, FSS84, Yao85, Has86] </ref>. Those techniques work almost identically for DNF and CNF; for this reason all our results apply also to CNF. The paper is organized as following. Section 2 gives the notation and definition that is used later.
Reference: [AK91] <author> Dana Angluin and Michael Kharitonov. </author> <booktitle> When won't membership quiries help? In Proceedings of STOC '91, </booktitle> <pages> pages 44-454. </pages> <publisher> ACM, </publisher> <year> 1991. </year>
Reference-contexts: Unfortunately none of the results seem to extend to the general case. Negative results have been shown for learning DNF in the PAC model. In [PV88] it was shown that deciding if a given set of examples can be described as a two term DNF is NP Complete. In <ref> [AK91] </ref> it was shown that, under some cryptographic assumptions, the problems fl IBM - Thomas J. Watson Research Center. P. O. Box 704, Yorktown Heights, New York 10598.
Reference: [AM91] <author> William Aiello and Milena Mihail. </author> <title> Learning the fourier spectrum of probabilistic lists and trees. </title> <booktitle> In Proceedings SODA 91. ACM, </booktitle> <month> Jan </month> <year> 1991. </year> <month> 11 </month>
Reference-contexts: Their main result is an interesting property of the representation of the Fourier transform of AC 0 circuits; based on it they derived a learning algorithm for AC 0 . In <ref> [AM91] </ref> polynomial time algorithms are given for learning both decision lists and read once decision trees with respect to the uniform distribution. The work of [KM91] uses the Fourier representation to derive a polynomial time learning algorithm for decision trees, with respect to the uniform distribution.
Reference: [AP91] <author> Howard Aizenstein and Leonard Pitt. </author> <title> Exact learning of read-twice DNF formulas. </title> <booktitle> In 32nd Annual Symposium on Foundation of Computer Science, </booktitle> <pages> pages 170-179, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: There has been some success in devising algorithms for learning DNF with various restriction on the number of times a variable can appear in the DNF formula (see <ref> [KLPV87, Han91, HM91, AP91] </ref>). Unfortunately none of the results seem to extend to the general case. Negative results have been shown for learning DNF in the PAC model.
Reference: [BHO90] <author> Y. Brandman, J. Hennessy, and A. Orlitsky. </author> <title> A spectral lower bound technique for the size of decision trees and two level circuits. </title> <journal> IEEE Trans. on Computers., </journal> <volume> 39(2) </volume> <pages> 282-287, </pages> <year> 1990. </year>
Reference-contexts: The work of [KM91] uses the Fourier representation to derive a polynomial time learning algorithm for decision trees, with respect to the uniform distribution. The relation between DNFs and their Fourier transform representation is also studied in <ref> [BHO90] </ref>. Other works that are investigating the Fourier transform of Boolean functions are [Bru90, BS90b, SB91]. The techniques developed in [GL89, KM91] give a randomized polynomial time algorithm that performs the following task.
Reference: [Bru90] <author> J. Bruck. </author> <title> Harmonic analysis of polynomial threshold functions. </title> <journal> Siam J. on Disc. Math., </journal> <volume> 3(2) </volume> <pages> 168-177, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: The relation between DNFs and their Fourier transform representation is also studied in [BHO90]. Other works that are investigating the Fourier transform of Boolean functions are <ref> [Bru90, BS90b, SB91] </ref>. The techniques developed in [GL89, KM91] give a randomized polynomial time algorithm that performs the following task.
Reference: [BS90a] <author> R. Boppana and M. Sipser. </author> <title> The complexity of finite functions. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of theor. comp. sci. </booktitle> <year> 1990. </year>
Reference-contexts: Note that this equals the degree of f as a real (multi-linear) polynomial. 2.2 RANDOM RESTRICTION The technique of random restriction was introduced in [FSS84] in order to derive lower bounds for AC 0 circuits. It was latter used in [Yao85, Has86] to improve the lower bounds. (See <ref> [BS90a] </ref> for an excellent survey on the subject.) A restriction is a mapping of the input variables to 0, 1 and fl. The function obtained from f (x 1 ; ; x n ) by applying a restriction is denoted by f .
Reference: [BS90b] <author> J. Bruck and R. Smolensky. </author> <title> Polynomial threshold functions, AC 0 functions and spectral norms. </title> <booktitle> In 31 th Annual Symposium on Foundations of Computer Science, </booktitle> <address> St. Louis, </address> <publisher> Missouri, </publisher> <pages> pages 632-641, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: The relation between DNFs and their Fourier transform representation is also studied in [BHO90]. Other works that are investigating the Fourier transform of Boolean functions are <ref> [Bru90, BS90b, SB91] </ref>. The techniques developed in [GL89, KM91] give a randomized polynomial time algorithm that performs the following task.
Reference: [FSS84] <author> M. Furst, J. Saxe, and M. Sipser. </author> <title> Parity, circuits, and the polynomial time hierarchy. </title> <journal> Mathematical Systems Theory, </journal> <volume> 17 </volume> <pages> 13-27, </pages> <year> 1984. </year>
Reference-contexts: Our results are based on the lower bound techniques that were developed for proving lower bound for polynomial size constant depth circuit <ref> [Ajt83, FSS84, Yao85, Has86] </ref>. Those techniques work almost identically for DNF and CNF; for this reason all our results apply also to CNF. The paper is organized as following. Section 2 gives the notation and definition that is used later. <p> Note that this equals the degree of f as a real (multi-linear) polynomial. 2.2 RANDOM RESTRICTION The technique of random restriction was introduced in <ref> [FSS84] </ref> in order to derive lower bounds for AC 0 circuits. It was latter used in [Yao85, Has86] to improve the lower bounds. (See [BS90a] for an excellent survey on the subject.) A restriction is a mapping of the input variables to 0, 1 and fl.
Reference: [GL89] <author> O. Goldreich and L. Levin. </author> <title> A hard-core predicate for all one-way functions. </title> <booktitle> In Proc. 21st ACM Symposium on Theory of Computing, </booktitle> <pages> pages 25-32. </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: The relation between DNFs and their Fourier transform representation is also studied in [BHO90]. Other works that are investigating the Fourier transform of Boolean functions are [Bru90, BS90b, SB91]. The techniques developed in <ref> [GL89, KM91] </ref> give a randomized polynomial time algorithm that performs the following task. The input is a Boolean function f that can be approximated by a polynomially sparse function g (a function with a polynomial number of non-zero coefficients) such that the expected error square (i.e. <p> This result, in conjunction with the results of <ref> [GL89, KM91] </ref>, gives a learning algorithm that runs in time d O (d log 1=") , and learns a DNF with terms of size d, with respect to the uniform distribution.
Reference: [Han91] <author> Thomas Hancock. </author> <title> Learning 2 DNF and k decision trees. </title> <booktitle> In 4th COLT, </booktitle> <pages> pages 199-209, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: There has been some success in devising algorithms for learning DNF with various restriction on the number of times a variable can appear in the DNF formula (see <ref> [KLPV87, Han91, HM91, AP91] </ref>). Unfortunately none of the results seem to extend to the general case. Negative results have been shown for learning DNF in the PAC model.
Reference: [Has86] <author> J. Hastad. </author> <title> Computational limitations for small depth circuits. </title> <publisher> MIT Press, </publisher> <year> 1986. </year> <type> Ph.D. thesis. </type>
Reference-contexts: Our results are based on the lower bound techniques that were developed for proving lower bound for polynomial size constant depth circuit <ref> [Ajt83, FSS84, Yao85, Has86] </ref>. Those techniques work almost identically for DNF and CNF; for this reason all our results apply also to CNF. The paper is organized as following. Section 2 gives the notation and definition that is used later. <p> Note that this equals the degree of f as a real (multi-linear) polynomial. 2.2 RANDOM RESTRICTION The technique of random restriction was introduced in [FSS84] in order to derive lower bounds for AC 0 circuits. It was latter used in <ref> [Yao85, Has86] </ref> to improve the lower bounds. (See [BS90a] for an excellent survey on the subject.) A restriction is a mapping of the input variables to 0, 1 and fl. <p> Lemma 4.1 ([LMN89]) For any Boolean function f , X ^ f 2 (S) 2P rob [F-deg (f ) tp=2] Note that the result is non-trivial only if P rob [F-deg (f ) tp=2] 1 2 . As in [LMN89], we use the Switching lemma, from <ref> [Has86] </ref>, stated below. Lemma 4.2 (Hastad) Let f be given by a DNF formula where each term has size at most d, and choose a random restriction with parameter p (i.e. P r [(x i ) = fl] = p). <p> The construction of such a function appears, essentially, in <ref> [Has86] </ref> and is described below for completeness. Consider the following function. Of the n inputs, the function uses only 1 2 d log 1=" variables as its support. The function has 1=2 log 1=" disjoint blocks of input variables, each block of size d.
Reference: [HM91] <author> Thomas Hancock and Yishay Mansour. </author> <title> Learning monotone k DNF formulas on product distributions. </title> <booktitle> In COLT, </booktitle> <pages> pages 179-183, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: There has been some success in devising algorithms for learning DNF with various restriction on the number of times a variable can appear in the DNF formula (see <ref> [KLPV87, Han91, HM91, AP91] </ref>). Unfortunately none of the results seem to extend to the general case. Negative results have been shown for learning DNF in the PAC model.
Reference: [Kha92] <author> Michael Kharitonov. </author> <booktitle> When won't membership quiries help? In Proceedings of COLT '92, </booktitle> <pages> pages 29-36. </pages> <publisher> ACM, </publisher> <year> 1992. </year>
Reference-contexts: Part of the work was done while the author was at: Aiken Computation Laboratory, Harvard University, Cambridge, MA 02138 of learning DNF with and without membership queries are equivalent. Both results apply only to very specific distributions, and do not seem to extend to the uniform distribution. In <ref> [Kha92] </ref>, the hardness of learning AC 1 circuits, even under uniform distribution, is shown, under specific cryptographic assumption about the hardness of the subset sum. The work of [LMN89] established the connection between the Fourier spectrum and learn-ability. They presented a quasi-polynomial-time (i.e.
Reference: [KLPV87] <author> Michael Kearns, Ming Li, Leonard Pitt, and Leslie Valiant. </author> <title> On the learnability of Boolean formulae. </title> <booktitle> In Proceedings of the Nineteenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 285-295, </pages> <address> New York, New York, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: There has been some success in devising algorithms for learning DNF with various restriction on the number of times a variable can appear in the DNF formula (see <ref> [KLPV87, Han91, HM91, AP91] </ref>). Unfortunately none of the results seem to extend to the general case. Negative results have been shown for learning DNF in the PAC model.
Reference: [KM91] <author> E. Kushilevitz and Y. Mansour. </author> <title> Learning decision trees using the fourier spectrum. </title> <booktitle> In Proceedings of the 23 rd Annual ACM Symposium on Theory of Computing, </booktitle> <month> May </month> <year> 1991. </year> <note> to appear. </note>
Reference-contexts: In [AM91] polynomial time algorithms are given for learning both decision lists and read once decision trees with respect to the uniform distribution. The work of <ref> [KM91] </ref> uses the Fourier representation to derive a polynomial time learning algorithm for decision trees, with respect to the uniform distribution. The relation between DNFs and their Fourier transform representation is also studied in [BHO90]. Other works that are investigating the Fourier transform of Boolean functions are [Bru90, BS90b, SB91]. <p> The relation between DNFs and their Fourier transform representation is also studied in [BHO90]. Other works that are investigating the Fourier transform of Boolean functions are [Bru90, BS90b, SB91]. The techniques developed in <ref> [GL89, KM91] </ref> give a randomized polynomial time algorithm that performs the following task. The input is a Boolean function f that can be approximated by a polynomially sparse function g (a function with a polynomial number of non-zero coefficients) such that the expected error square (i.e. <p> This result, in conjunction with the results of <ref> [GL89, KM91] </ref>, gives a learning algorithm that runs in time d O (d log 1=") , and learns a DNF with terms of size d, with respect to the uniform distribution. <p> This property shows that the sum, in absolute value, of the coefficients of the "small" sets, is small. Namely, let L = P jSjt j ^ f (S)j, then L d O (t) . In a similar way to <ref> [KM91] </ref> we show that if the sum in absolute value of the coefficients is L, then there can be at most ( 2L " ) 2 "interesting" coefficients. <p> The learning algorithms are based on the following result of <ref> [KM91] </ref>. Theorem 3.4 ([KM91]) Let f be a Boolean function such that there exists a t-sparse function g that "-approximates f. <p> Another tool that we use here is that we can bound the L 1 norm of the coefficients of a decision tree. The following is a special case of the bound in <ref> [KM91] </ref>. 9 Lemma 5.1 ([KM91]) For a function f, if DT-depth (f ) s then L 1 (f) 2 s . We start by showing that after a random restriction the L 1 norm of the restricted function is very small.
Reference: [LMN89] <author> N. Linial, Y. Mansour, and N. Nisan. </author> <title> Constant depth circuits, fourier transform and learnability. </title> <booktitle> In 30 th Annual Symposium on Foundations of Computer Science, </booktitle> <address> Reseach Triangle Park, NC, </address> <pages> pages 574-579, </pages> <month> October </month> <year> 1989. </year> <month> 12 </month>
Reference-contexts: Both results apply only to very specific distributions, and do not seem to extend to the uniform distribution. In [Kha92], the hardness of learning AC 1 circuits, even under uniform distribution, is shown, under specific cryptographic assumption about the hardness of the subset sum. The work of <ref> [LMN89] </ref> established the connection between the Fourier spectrum and learn-ability. They presented a quasi-polynomial-time (i.e. O (n polylog (n) )) algorithm for learning the class AC 0 (polynomial size constant depth circuits); the approximation is with respect to the uniform distribution. <p> Lemma 3.2 Let f be a function that can be written as a DNF with terms of size d. Then, X " " 5 The proof of the above lemma is found is Section 4, and it is essentially a special case of the proof in <ref> [LMN89] </ref>. In Lemma 3.3, which is proved in Section 5, we restrict our attention to coefficients of sets of size at most t . <p> This intuitively implies that when approximating such a DNF, we can ignore the coefficients of sets larger than t (d). The main goal of this section is proving Lemma 3.2, which was already claimed and used in Section 3. Implicit in the proofs of <ref> [LMN89] </ref> is the following connection between a random restriction of a function and the coefficients of "large" sets of the function. Lemma 4.1 ([LMN89]) For any Boolean function f , X ^ f 2 (S) 2P rob [F-deg (f ) tp=2] Note that the result is non-trivial only if P rob <p> Lemma 4.1 (<ref> [LMN89] </ref>) For any Boolean function f , X ^ f 2 (S) 2P rob [F-deg (f ) tp=2] Note that the result is non-trivial only if P rob [F-deg (f ) tp=2] 1 2 . As in [LMN89], we use the Switching lemma, from [Has86], stated below. Lemma 4.2 (Hastad) Let f be given by a DNF formula where each term has size at most d, and choose a random restriction with parameter p (i.e. P r [(x i ) = fl] = p). <p> Therefore the Fourier coefficients of T , for any set larger than s, are zero (see <ref> [LMN89] </ref>). This implies that F-deg (f ) DT-depth (f ), which immediately bounds P rob [F-deg (f ) tp=2] from above by P rob [DT-depth (f ) tp=2]. Combining this with Lemma 4.1, Lemma 4.2 and setting p = 1=(10d) and t = 20d log 4 " proves Lemma 3.2.
Reference: [LV91] <author> M. Luby and B. Velickovic. </author> <title> On deterministic approximation of DNF. </title> <booktitle> In Proceedings of the 23 rd Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 430-438, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: This can be contrasted with the results based on the Sunflower Theorem that show that a DNF with terms of size at most d can be approximated by a DNF with O (2 d 2 ) terms of size at most d (see <ref> [LV91] </ref>). Our results are based on the lower bound techniques that were developed for proving lower bound for polynomial size constant depth circuit [Ajt83, FSS84, Yao85, Has86]. Those techniques work almost identically for DNF and CNF; for this reason all our results apply also to CNF.
Reference: [PV88] <author> Leonard Pitt and Leslie G. Valiant. </author> <title> Computational limitations on learning from examples. </title> <journal> J. ACM, </journal> <volume> 35(4) </volume> <pages> 965-984, </pages> <year> 1988. </year>
Reference-contexts: Unfortunately none of the results seem to extend to the general case. Negative results have been shown for learning DNF in the PAC model. In <ref> [PV88] </ref> it was shown that deciding if a given set of examples can be described as a two term DNF is NP Complete. In [AK91] it was shown that, under some cryptographic assumptions, the problems fl IBM - Thomas J. Watson Research Center. P. O.
Reference: [SB91] <author> Kai-Yeung Sui and Jehoshua Bruck. </author> <title> On the power of threshold circuits with small weights. </title> <journal> Siam J. on Disc. Math., </journal> <volume> 4(3) </volume> <pages> 423-435, </pages> <month> Aug </month> <year> 1991. </year>
Reference-contexts: The relation between DNFs and their Fourier transform representation is also studied in [BHO90]. Other works that are investigating the Fourier transform of Boolean functions are <ref> [Bru90, BS90b, SB91] </ref>. The techniques developed in [GL89, KM91] give a randomized polynomial time algorithm that performs the following task.
Reference: [Val84] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: 1 INTRODUCTION One of the most basic problems in theoretical machine learning has been learning the class of DNFs with a polynomial number of terms. This task has been an open problem since the work of Valiant <ref> [Val84] </ref> introducing the PAC model. Learning a DNF with a polynomial number of terms in polynomial time remains an open question even when the examples are drawn from the uniform distribution and the learner is allowed to query the DNF. In his seminal paper Valiant [Val84] gave a polynomial time algorithm <p> since the work of Valiant <ref> [Val84] </ref> introducing the PAC model. Learning a DNF with a polynomial number of terms in polynomial time remains an open question even when the examples are drawn from the uniform distribution and the learner is allowed to query the DNF. In his seminal paper Valiant [Val84] gave a polynomial time algorithm for learning k-CNF, in the PAC model, and showed how to learn polynomial size monotone DNF formulas using queries.
Reference: [Ver90] <author> Karsten Verbeurgt. </author> <title> Learning DNF under the uniform distribution in quasi-polynomial time. </title> <booktitle> In Proceedings of COLT '90, </booktitle> <pages> pages 314-326, </pages> <year> 1990. </year>
Reference-contexts: For a DNF with a polynomial number of terms (i.e. m = n O (1) ) this immediately gives an O (n log n ) learning algorithm. (See <ref> [Ver90] </ref>). The results here are mainly interesting in the case that " is a constant. In this case the algorithm runs in time O (n log log n ) and finds an approximation to a polynomial size DNF, with respect to the uniform distribution.
Reference: [Yao85] <author> A. C. Yao. </author> <title> Separating the polynomial-time hierarchy by oracles. </title> <booktitle> In 26 th Annual Symposium on Foundations of Computer Science, Portland, Oregon, </booktitle> <pages> pages 1-10, </pages> <month> October </month> <year> 1985. </year> <month> 13 </month>
Reference-contexts: Our results are based on the lower bound techniques that were developed for proving lower bound for polynomial size constant depth circuit <ref> [Ajt83, FSS84, Yao85, Has86] </ref>. Those techniques work almost identically for DNF and CNF; for this reason all our results apply also to CNF. The paper is organized as following. Section 2 gives the notation and definition that is used later. <p> Note that this equals the degree of f as a real (multi-linear) polynomial. 2.2 RANDOM RESTRICTION The technique of random restriction was introduced in [FSS84] in order to derive lower bounds for AC 0 circuits. It was latter used in <ref> [Yao85, Has86] </ref> to improve the lower bounds. (See [BS90a] for an excellent survey on the subject.) A restriction is a mapping of the input variables to 0, 1 and fl.
References-found: 23

