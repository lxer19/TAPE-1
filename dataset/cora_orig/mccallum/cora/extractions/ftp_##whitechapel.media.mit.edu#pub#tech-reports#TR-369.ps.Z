URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-369.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: (bobick jdavis@media.mit.edu)  
Title: Appearance-based Representation of Action  
Author: Aaron F. Bobick and James W. Davis 
Keyword: Categories: Human motion understanding; Action recognition; Motion representation  
Note: An  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 369 Appears in International Conference on Pattern Recognition, 1996 Abstract A new view-based approach to the representation of action is presented. The work is motivated by the observation that a human observer can easily and instantly recognize action in extremely low resolution imagery, even imagery in which individual frames provide no information about three-dimensional structure of the scene. Our underlying representations are view-based descriptions of the coarse image motion associated with viewing given actions from particular directions. Using these descriptions, we propose an appearance-based action-recognition strategy comprised of two stages: first a motion energy image (MEI) is computed that grossly describes the spatial distribution of motion energy for a given view of a given action. The input MEI is matched against stored models which span the range of views of known actions. Second, any models that plausibly match the input are tested for a coarse, categorical agreement between a stored motion model of the action and a parameterization of the input motion. Using a "sitting" action as an example, and using a manually placed stick model, we develop a representation and verification technique that collapses the temporal variations of the motion parameters into a single, low-order vector. Finally we show the type of patch-based motion model we intend to employ in a data driven action segmentation and recognition system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Akita, K., </author> <title> "Image Sequence Analysis of Real World Human Motion," </title> <journal> Pattern Recognition, </journal> <volume> 17, </volume> <year> 1984. </year>
Reference-contexts: We divide the relevant prior work into three areas: action recognition, view-based (usually aspect) matching, and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 8, 11, 14, 19, 20, 6, 24] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action (e.g. [11]), while others use only the two-dimensional appearance (e.g. [8]).
Reference: [2] <author> Bergen, J., P. Anadan, K. Hanna, and R. </author> <title> Hingo-rami [1992] "Hierarchical model-based motion estimation," </title> <booktitle> Proc. European Conference on Computer Vision, France, </booktitle> <pages> 237-252. </pages>
Reference-contexts: We have experimented with several methods for determining motion-energy. An obvious approach is to com 3 These motion energy images are computed on the blurred versions of the imagery. pute optic flow field between each pair of frames using a local, gradient-based technique similar to Lucas and Kanade <ref> [2] </ref> yielding a vector image ~ I i (x; y) for each sequential pair. <p> One example of tracked patches is shown in Figure 7. The three polygonal patches are created man ually but tracked automatically using an affine model of optic flow <ref> [2] </ref>. The initial placement and scale of the 7 these patches needs to be adjusted to fit the position and size of the motion in the image.
Reference: [3] <author> Black, M. and Y. Yacoob, </author> <title> "Tracking and Recognizing Rigid and Non-rigid Facial Motion using Local Parametric Models of Image Motion," </title> <address> ICCV, </address> <year> 1995. </year>
Reference-contexts: The spatial distribution of motion integrated over some temporal extent of the motion is employed as the initial filter proposing possible actions and viewing directions. 4. A coarse patch model of motion (similar to <ref> [3] </ref>) is capable of discriminating motions, once the motion energy distribution is used to pre-filter the hy potheses. 1 The only instruction was: "You are about to see a particular action happening. <p> We next explore the appropriate parameterization of the motion appearance models. Our eventual goal is to use motion patch deformations similar to <ref> [3] </ref> but where the patches selected are different for each known motion. To that end, using the sitting action as an example, we develop a representation and verification technique that collapses the temporal variations of the motion parameters into a single, low-order vector. <p> However, when not possible, our model can also accommodate discrete regions or aspects. Finally there is the work on direct motion recognition <ref> [18, 21, 23, 3] </ref>. These approaches attempt to characterize the motion itself without any reference to the underlying static images. Of these techniques, the work of Black and Yacoob [3] is the most relevant to the results presented here. <p> Finally there is the work on direct motion recognition [18, 21, 23, 3]. These approaches attempt to characterize the motion itself without any reference to the underlying static images. Of these techniques, the work of Black and Yacoob <ref> [3] </ref> is the most relevant to the results presented here. The goal of their research is to recognize human facial expressions as a dynamic system, where it is the motion that is relevant. Their approach does not represent motion as a sequence of poses or configurations. <p> The idea is partially motivated by the previously mentioned facial-expression recognition work of Black and Yacoob <ref> [3] </ref>. Their innovative paper proposed a qualitative description of the motion of predefined patches of the face. The parameterization and location relative to the face of each patch was given a priori. <p> One possibility is to use centroid- and moment- based alignment between the input and target MEIs to define the necessary 3-parameter transformation for the patches. We have not yet achieved a robust enough model placement and tracking algorithm to test the recognition method on patches. Unlike face images of <ref> [3] </ref>, our sitting images can have quite a variety of image textures which makes motion estimation a non-trivial operation. 4.4 Motion aspects We conclude the section on motion description by noting that it is unlikely that a single patch representation can be robustly tracked over all possible views of an action.
Reference: [4] <author> Campbell, L. and A. Bobick, </author> <title> "Recognition of Human Body Motion Using Phase Space Constraints," </title> <address> ICCV, </address> <year> 1995. </year>
Reference-contexts: We divide the relevant prior work into three areas: action recognition, view-based (usually aspect) matching, and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 8, 11, 14, 19, 20, 6, 24] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action (e.g. [11]), while others use only the two-dimensional appearance (e.g. [8]).
Reference: [5] <author> Cedras, C. and M. Shah, </author> <title> "Motion-Based Recognition: A Survey," </title> <booktitle> Image and Vision Computing, </booktitle> <year> 1993. </year>
Reference-contexts: For an excellent review on the machine understanding of motion see <ref> [5] </ref>. We divide the relevant prior work into three areas: action recognition, view-based (usually aspect) matching, and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action.
Reference: [6] <author> Cui, Y., D. Swets, and J. Weng, </author> <title> "Learning-based Hand Sign Recognition Using SHOSLIF-M," </title> <address> ICCV, </address> <year> 1995. </year>
Reference-contexts: We divide the relevant prior work into three areas: action recognition, view-based (usually aspect) matching, and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 8, 11, 14, 19, 20, 6, 24] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action (e.g. [11]), while others use only the two-dimensional appearance (e.g. [8]).
Reference: [7] <author> Darrell, T., P. Maes, B. Blumberg, and A. Pent-land, </author> <title> "A Novel Environment for Situated Vision and Behavior", </title> <booktitle> Proc. IEEE Wkshp. for Visual Behaviors (CVPR-94), </booktitle> <publisher> IEEE C.S. Press, </publisher> <address> Los Alami-tos, CA, </address> <year> 1994 </year>
Reference-contexts: 1 Introduction The recent shift in computer vision from static images to video sequences has focused research on the understanding of action or behavior. In particular, the lure of wireless interfaces (e.g. [10]) and interactive environments <ref> [7] </ref> has heightened interest in understanding human actions. Recently a number of approaches have appeared attempting the full three-dimensional reconstruction of the human form from image sequences, with the presumption that such information would be useful and perhaps even necessary to understand the action taking place (e.g. [19]).
Reference: [8] <author> Darrell, T. and A. Pentland, </author> <title> "Space-Time Gestures," </title> <address> CVPR, </address> <year> 1993 </year>
Reference-contexts: We divide the relevant prior work into three areas: action recognition, view-based (usually aspect) matching, and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 8, 11, 14, 19, 20, 6, 24] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action (e.g. [11]), while others use only the two-dimensional appearance (e.g. [8]). <p> Some recent examples include [1, 4, 8, 11, 14, 19, 20, 6, 24]. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action (e.g. [11]), while others use only the two-dimensional appearance (e.g. <ref> [8] </ref>). However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations. <p> The method relies on looking backward in time, much as is done by <ref> [8] </ref>. The system will continually construct MEIs backwards, up to a time delay of t d , and attempt to find a matching MEI in the library. If any matches are found, the corresponding motion appearance model is retrieved and applied backward in time attempting to verify the motion.
Reference: [9] <author> Eggert, D., K. Bowyer, C. Dyer, H. Christensen, and D. Goldgof, </author> <title> "The Scale Space Aspect Graph," </title> <journal> IEEE Trans. PAMI, </journal> <volume> 15, 11, </volume> <year> 1993. </year>
Reference-contexts: These approaches accomplish motion understanding by recognizing a sequence of static configurations. It is difficult to imagine that such techniques could be extended to the blurred sequence of Figure 1. The second area related to this work is that of appearance- or aspect-based recognition (e.g. <ref> [17, 16, 9] </ref>). The formal description of aspects [17] referred to the visible surfaces of objects undergoing self occlusion. <p> Ikeuchi and Hong [16] refer to the shape change within an aspect as a "linear shape change." Eggert, et al. <ref> [9] </ref> extend the use of aspects to include scale by understanding how the visibility of surfaces is affected by the scale of observation. In general, the term "aspect" recognition has come to include any recognition scheme that partitions the view sphere into distinct models.
Reference: [10] <author> Freeman, W., </author> <title> "Orientation Histogram for Hand Gesture Recognition," </title> <booktitle> Int'l Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <address> Zurich, </address> <year> 1995. </year>
Reference-contexts: 1 Introduction The recent shift in computer vision from static images to video sequences has focused research on the understanding of action or behavior. In particular, the lure of wireless interfaces (e.g. <ref> [10] </ref>) and interactive environments [7] has heightened interest in understanding human actions.
Reference: [11] <author> Goncalves, L., E. DiBernardo, E. Ursella, P. Per-ona, </author> <title> "Monocular tracking of the human arm in 3D," </title> <address> ICCV, </address> <year> 1995. </year>
Reference-contexts: We divide the relevant prior work into three areas: action recognition, view-based (usually aspect) matching, and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 8, 11, 14, 19, 20, 6, 24] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action (e.g. [11]), while others use only the two-dimensional appearance (e.g. [8]). <p> The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include [1, 4, 8, 11, 14, 19, 20, 6, 24]. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action (e.g. <ref> [11] </ref>), while others use only the two-dimensional appearance (e.g. [8]). However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations.
Reference: [12] <author> Grimson, W. E., </author> <title> Object Recognition By Computer: The Role of Geometric Constraints, </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The basic components of the theory are: 1. A motion model to be recognized is a coarse or categorical description of the motion observed when a known movement is viewed from a given angle. 2. Motion recognition is embedded in a simple hypothesis and test paradigm <ref> [12] </ref> where a data-driven initial computation is used to index plausible motions which are then verified by a more rigorous match. 3. The spatial distribution of motion integrated over some temporal extent of the motion is employed as the initial filter proposing possible actions and viewing directions. 4.
Reference: [13] <author> Hoffman, D. and B. Flinchbaugh, </author> <title> "The Interpreta--tion of Biological Motion," </title> <journal> Biological Cybernetics, </journal> <volume> 45, </volume> <year> 1982. </year>
Reference-contexts: This distinction is important: although individual frames of moving light displays also contain insufficient information from which to recover pose, they do contain features that allow for the structural recovery of the limbs <ref> [13] </ref> without a priori knowledge of the semantic assignments (e.g. "light 1 is the left hip"). One cannot prove that the blurred sequence of Figure 1 cannot be analyzed for three-dimensional structure before the assignment of body parts to image regions.
Reference: [14] <author> Hogg, D., </author> <title> "Model-based vision: a paradigm to see a walking person," </title> <journal> Image and Vision Computing, </journal> <volume> 1, 1, </volume> <year> 1983. </year>
Reference-contexts: We divide the relevant prior work into three areas: action recognition, view-based (usually aspect) matching, and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 8, 11, 14, 19, 20, 6, 24] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action (e.g. [11]), while others use only the two-dimensional appearance (e.g. [8]).
Reference: [15] <author> Hu, M., </author> <title> "Visual Pattern Recognition by Moment Invariants," </title> <journal> IRE Trans. Information Theory, IT-8, </journal> <volume> 2, </volume> <year> 1962. </year>
Reference-contexts: Motion images computed on the blurred imagery. 0 ffi 10 ffi 20 ffi 30 ffi 40 ffi are the Hu moments <ref> [15] </ref> which are known to yield reasonable shape discrimination in a translation-, scale-, and rotation-invariant manner.
Reference: [16] <author> Ikeuchi, K. and K. S. Hong, </author> <title> "Determining Linear Shape Change: Toward Automatic Generation of Object Recognition Programs", CVGIP, </title> <booktitle> Image Understanding, </booktitle> <volume> 53, 2, </volume> <year> 1991. </year>
Reference-contexts: These approaches accomplish motion understanding by recognizing a sequence of static configurations. It is difficult to imagine that such techniques could be extended to the blurred sequence of Figure 1. The second area related to this work is that of appearance- or aspect-based recognition (e.g. <ref> [17, 16, 9] </ref>). The formal description of aspects [17] referred to the visible surfaces of objects undergoing self occlusion. <p> We wanted to use blurred images of the same resolution as Figure 1 but we had difficulty getting stable motion im age estimates. 2 ible surfaces remains constant and only the shape of their projection changes. Ikeuchi and Hong <ref> [16] </ref> refer to the shape change within an aspect as a "linear shape change." Eggert, et al. [9] extend the use of aspects to include scale by understanding how the visibility of surfaces is affected by the scale of observation.
Reference: [17] <author> Koenderink, and A. van Doorn, </author> " <title> The internal representation of solid shape with respect to vision," </title> <journal> Biological Cybernetics, </journal> <volume> 32, </volume> <year> 1979. </year>
Reference-contexts: These approaches accomplish motion understanding by recognizing a sequence of static configurations. It is difficult to imagine that such techniques could be extended to the blurred sequence of Figure 1. The second area related to this work is that of appearance- or aspect-based recognition (e.g. <ref> [17, 16, 9] </ref>). The formal description of aspects [17] referred to the visible surfaces of objects undergoing self occlusion. <p> It is difficult to imagine that such techniques could be extended to the blurred sequence of Figure 1. The second area related to this work is that of appearance- or aspect-based recognition (e.g. [17, 16, 9]). The formal description of aspects <ref> [17] </ref> referred to the visible surfaces of objects undergoing self occlusion. For a range of viewing angles, which surfaces are vis 2 All the results presented in this paper use a blur kernel corresponding to the second level of a Gaussian pyramid giving an effective resolution of 80 by 60.
Reference: [18] <author> Polana, R. and R. Nelson, </author> <title> "Low Level Recognition of Human Motion," </title> <booktitle> IEEE Workshop on Non-rigid and Articulated Motion, </booktitle> <address> Austin, </address> <year> 1994. </year>
Reference-contexts: However, when not possible, our model can also accommodate discrete regions or aspects. Finally there is the work on direct motion recognition <ref> [18, 21, 23, 3] </ref>. These approaches attempt to characterize the motion itself without any reference to the underlying static images. Of these techniques, the work of Black and Yacoob [3] is the most relevant to the results presented here.
Reference: [19] <author> Rehg, J. and T. Kanade, </author> <title> "Model-based Tracking of Self-Occluding Articulated Objects," </title> <address> ICCV, </address> <year> 1995. </year>
Reference-contexts: Recently a number of approaches have appeared attempting the full three-dimensional reconstruction of the human form from image sequences, with the presumption that such information would be useful and perhaps even necessary to understand the action taking place (e.g. <ref> [19] </ref>). This paper presents an alter Frame 10 20 Frame 30 40 each frame, nor are there any features from which to compute a structural description (as would be in a moving light display). Yet people can trivially recognize the action as someone sitting. native to the three-dimensional reconstruction proposal. <p> We divide the relevant prior work into three areas: action recognition, view-based (usually aspect) matching, and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 8, 11, 14, 19, 20, 6, 24] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action (e.g. [11]), while others use only the two-dimensional appearance (e.g. [8]).
Reference: [20] <author> Rohr, </author> <title> K, "Towards Model-based Recognition of Human Movements in Image Sequences," CVGIP, </title> <booktitle> Image Understanding, </booktitle> <volume> 59, 1, </volume> <year> 1994. </year>
Reference-contexts: We divide the relevant prior work into three areas: action recognition, view-based (usually aspect) matching, and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 8, 11, 14, 19, 20, 6, 24] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action (e.g. [11]), while others use only the two-dimensional appearance (e.g. [8]).
Reference: [21] <author> Shavit, E. and A. Jepson, </author> <title> "Motion understanding using phase portraits," </title> <booktitle> IJCAI Workshop: Looking at People, </booktitle> <address> Chambery, </address> <year> 1995. </year>
Reference-contexts: However, when not possible, our model can also accommodate discrete regions or aspects. Finally there is the work on direct motion recognition <ref> [18, 21, 23, 3] </ref>. These approaches attempt to characterize the motion itself without any reference to the underlying static images. Of these techniques, the work of Black and Yacoob [3] is the most relevant to the results presented here.
Reference: [22] <author> Ullman, S., </author> <title> "Analysis of Visual Motion by Biological and Computer Systems," </title> <booktitle> Computer, </booktitle> <month> August, </month> <year> 1981. </year>
Reference-contexts: A more subtle observation is that no good features exist upon which to base a structure-from-motion algorithm <ref> [22] </ref>. This distinction is important: although individual frames of moving light displays also contain insufficient information from which to recover pose, they do contain features that allow for the structural recovery of the limbs [13] without a priori knowledge of the semantic assignments (e.g. "light 1 is the left hip").
Reference: [23] <author> Yacoob, Y. and L. Davis, </author> <title> "Computing Spatio-temporal Representations of Human Faces," </title> <address> CVPR, </address> <year> 1994. </year>
Reference-contexts: However, when not possible, our model can also accommodate discrete regions or aspects. Finally there is the work on direct motion recognition <ref> [18, 21, 23, 3] </ref>. These approaches attempt to characterize the motion itself without any reference to the underlying static images. Of these techniques, the work of Black and Yacoob [3] is the most relevant to the results presented here.
Reference: [24] <author> Yamato, J., J. Ohya, and K. Ishii, </author> <title> "Recognizing Human Action in Time Sequential Images using Hidden Markov Models," </title> <address> CVPR, </address> <year> 1992. </year> <month> 9 </month>
Reference-contexts: We divide the relevant prior work into three areas: action recognition, view-based (usually aspect) matching, and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 8, 11, 14, 19, 20, 6, 24] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action (e.g. [11]), while others use only the two-dimensional appearance (e.g. [8]).
References-found: 24

