URL: http://ai.iit.nrc.ca/DEIL/grobelnik.ps.Z
Refering-URL: http://ai.iit.nrc.ca/DEIL/abstracts.html
Root-URL: 
Email: E-mail: marko.grobelnik@ijs.si  E-mail: vesna.prasnikar@uni-lj.si  
Phone: Phone: +386 61 1773745,  
Title: Strategy extraction when playing games  
Author: Marko Grobelnik Vesna Prasnikar 
Keyword: machine learning, game theory, knowledge acquisition, qualitative modelling  
Address: Jamova 39, Ljubljana, Slovenia  Ljubljana, Slovenia  
Affiliation: AI Lab., J. Stefan Institute,  Faculty for Economics, University  Northwestern University, Kellogg School of Management  
Abstract: Modelling of a subject's strategy is rather important task for many situations e.g. in economy. However, modelling is mainly done by hand, i.e. repeating the cycle of proposing a hypothesis model and verifying it with various statistical approaches. In our work we use machine learning tools for automatic modelling of strategies in a game which is particularly interesting from the game theoretic point of view. More precisely, we modelled the decision process in the ultimatum bargaining game, experimentally performed in 4 countries. The results were decision trees corresponding to the qualitative models of the player types, confirming intuition about the game playing and the rational behaviour hypotheses of the players.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Cestnik, B., Kononenko, I. and Bratko, I. </author> <title> (1987) ASSISTANT 86: A knowledge elicitation tool for sophisticated users. </title> <editor> In Bratko, I. and Lavrac, N. (eds.) </editor> <booktitle> Progress in machine learning, </booktitle> <pages> pp. 31-45. </pages> <address> Wilmslow, </address> <publisher> Sigma Press. </publisher>
Reference-contexts: The game is interesting, because the theoretical results differ from the measured data. For the purposes of the automatic qualitative modelling of the player's strategy we used the machine learning tool Magnus-Assistant [2] which is based on the Assistant algorithm <ref> [1] </ref> (rather sophisticated descendant of the ID3 algorithm). The results show very applicable models of players that confirm the intuition about the game strategy. Furthermore, different substrategies are shown for different countries (nations), and within particular country several types of population are identified. <p> The players were additionally stimulated by being actually paid earned money in one randomly chosen round. 4 Assistant algorithm In the analysis, the system Magnus-Assistant [2] was used. It is based on the Assistant algorithm <ref> [1] </ref> from the family of the "top down induction decision tree algorithms". Assistant's basic paradigm is top-down construction of binary decision trees. It can handle noisy and incomplete input data, and has ability to preprune and postprune decision trees.
Reference: [2] <author> Mladenic, D. </author> <title> (1990) Machine learning system Magnus Assistant (in Slovene). </title> <type> BSc Thesis, </type> <institution> University of Ljubljana, Faculty for Electrical Engineering and Computer Science, </institution> <year> 1990. </year>
Reference-contexts: The game is interesting, because the theoretical results differ from the measured data. For the purposes of the automatic qualitative modelling of the player's strategy we used the machine learning tool Magnus-Assistant <ref> [2] </ref> which is based on the Assistant algorithm [1] (rather sophisticated descendant of the ID3 algorithm). The results show very applicable models of players that confirm the intuition about the game strategy. <p> The amount of $10 was recalculated into the local currency with the corresponding purchasing power. The players were additionally stimulated by being actually paid earned money in one randomly chosen round. 4 Assistant algorithm In the analysis, the system Magnus-Assistant <ref> [2] </ref> was used. It is based on the Assistant algorithm [1] from the family of the "top down induction decision tree algorithms". Assistant's basic paradigm is top-down construction of binary decision trees. It can handle noisy and incomplete input data, and has ability to preprune and postprune decision trees.
Reference: [3] <author> Prasnikar, V., Roth, A. E. </author> <title> (1992) Consideration of Fairness and Strategy: Experimental Data From Sequential Games. </title> <journal> The Quarterly Journal of Economics, </journal> <month> August 865-888. </month>
Reference-contexts: That is, the division of Q that results from this solution gives player 1 a payoff of Q *, and player 2 a payoff of * <ref> [3] </ref>.
Reference: [4] <author> Roth, A. E., Prasnikar, V., Fujiwara, M. O., Zamir, S. </author> <title> (1991) Bargaining and Market Behaviour in Jerusalem, Ljubljana, Pittsburgh, and Tokyo: An Experimental Study. </title> <journal> American Economic Review, </journal> <volume> 81, </volume> <month> December, </month> <pages> 1068-1095. </pages>
Reference-contexts: Observed experimental results have been quite different, with player 1's, predominantly offering player 2's much larger shares (typically in the neighbourhood of 40% of Q). 3 Experiment description The experiment, with the game described in the previous section, was performed in 4 countries <ref> [4] </ref>: USA (Pittsburgh), Slovenia (Ljubljana), Israel (Jerusalem) and Japan (Tokyo). In each country 2n students were involved: n in the role of player 1 and n in the role of player 2. More precisely: 74 in USA, 60 in Slovenia and Israel, and 58 in Japan, altogether 252.
Reference: [5] <author> Osborne, M. J., Rubinstein, A. </author> <title> (1990) Bargaining and Markets. </title> <publisher> Academic Press, </publisher> <address> San Diego. </address>
Reference-contexts: The presentation is continued with the problem formulation for the machine learning system, and concluded with results of the analysis. 2 Game definition The game we used for modelling is simple, maybe simpler than someone would expect. According to the game theory, it is categorised into the ultimatum games <ref> [6, 5] </ref> The ultimatum bargaining game is a two-person game played as follows. There is some quantity Q of money to be divided, and player 1 makes an offer of the form (x 1 ; x 2 ), where x 2 = Q x 1 .
Reference: [6] <author> Roth, A. E. </author> <title> (1979) Axiomatic Models of Bargaining. </title> <publisher> Springer Verlag, </publisher> <address> Berlin. </address>
Reference-contexts: The presentation is continued with the problem formulation for the machine learning system, and concluded with results of the analysis. 2 Game definition The game we used for modelling is simple, maybe simpler than someone would expect. According to the game theory, it is categorised into the ultimatum games <ref> [6, 5] </ref> The ultimatum bargaining game is a two-person game played as follows. There is some quantity Q of money to be divided, and player 1 makes an offer of the form (x 1 ; x 2 ), where x 2 = Q x 1 .
Reference: [7] <author> Quinlan, J.R. </author> <title> (1986) Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> Vol. 1, </volume> <pages> pp. 81-106. </pages>
Reference-contexts: Assistant's basic paradigm is top-down construction of binary decision trees. It can handle noisy and incomplete input data, and has ability to preprune and postprune decision trees. It could be said, that Assistant is rather sophisticated descendant of the well known ID3 <ref> [7] </ref> algorithm.
References-found: 7

