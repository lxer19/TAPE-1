URL: ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-94-36.ps.Z
Refering-URL: ftp://ftp.cse.ucsc.edu/pub/tr/README.html
Root-URL: http://www.cse.ucsc.edu
Title: Tight worst-case loss bounds for predicting with expert advice  
Author: David Haussler Jyrki Kivinen Manfred K. Warmuth 
Keyword: p Keywords: worst-case loss bounds, on-line learning, learning theory  
Note: Supported by NSF grant IRI-9123692;  Funded by the  Supported by NSF grant IRI-9123692;  
Address: Santa Cruz, CA 95064 USA  Finland;  
Affiliation: Baskin Center for Computer Engineering Information Sciences University of California, Santa Cruz  Academy of  
Pubnum: UCSC-CRL-94-36  
Email: e-mail haussler@cse.ucsc.edu.  e-mail kivinen@cse.ucsc.edu  e-mail manfred@cse.ucsc.edu.  
Date: November 3, 1994 (Revised December 8, 1994)  
Abstract: We consider on-line algorithms for predicting binary or continuous-valued outcomes, when the algorithm has available the predictions made by N experts. For a sequence of trials, we compute total losses for both the algorithm and the experts under a loss function. At the end of the trial sequence, we compare the total loss of the algorithm to the total loss of the best expert, i.e., the expert with the least loss on the particular trial sequence. Vovk has introduced a simple algorithm for this prediction problem and proved that for a large class of loss functions, with binary outcomes the total loss of the algorithm exceeds the total loss of the best expert at most by the amount c ln N , where c is a constant determined by the loss function. This upper bound does not depend on any assumptions on how the experts' predictions or the outcomes are generated, and the trial sequence can be arbitrarily long. We give a straightforward alternative method for finding the correct value c and show by a lower bound that for this value of c, the upper bound is asymptotically tight. The lower bound is based on a probabilistic adversary argument. The class of loss functions for which the c ln N upper bound holds includes the square loss, the logarithmic loss, and the Hellinger loss. We also consider another class of loss functions, including the absolute loss, for which we have an lower bound, where ` is the number of trials. We show that for the square and logarithmic loss functions, Vovk's algorithm achieves the same worst-case upper bounds with continuous-valued outcomes as with binary outcomes. For the absolute loss, we show how bounds earlier achieved for binary outcomes can be achieved with continuous-valued outcomes using a slightly more complicated algorithm.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Patrick Billingsley. </author> <title> Probability and Measure. </title> <publisher> Wiley, </publisher> <address> New York, NY, </address> <year> 1986. </year> <note> Second Edition. </note>
Reference-contexts: We take the predictions of both the algorithm and the experts, as well as the outcomes, to be real numbers in <ref> [0; 1] </ref>. The performance of a learning algorithm is measured using a loss function L, which is a mapping from [0; 1] fi [0; 1] to [0; 1); sometimes also the value 1 is allowed. <p> We take the predictions of both the algorithm and the experts, as well as the outcomes, to be real numbers in <ref> [0; 1] </ref>. The performance of a learning algorithm is measured using a loss function L, which is a mapping from [0; 1] fi [0; 1] to [0; 1); sometimes also the value 1 is allowed. The square loss, L sq , defined by L sq (p; q) = (p q) 2 , is a typical loss function. <p> We take the predictions of both the algorithm and the experts, as well as the outcomes, to be real numbers in <ref> [0; 1] </ref>. The performance of a learning algorithm is measured using a loss function L, which is a mapping from [0; 1] fi [0; 1] to [0; 1); sometimes also the value 1 is allowed. The square loss, L sq , defined by L sq (p; q) = (p q) 2 , is a typical loss function. <p> Thus, the algorithm could predict with ^y t close to 1=2 to avoid committing itself too strongly to either possible outcome y t = 0 or y t = 1. We later see how the results can be generalized for continuous-valued outcomes y t 2 <ref> [0; 1] </ref>. Cesa-Bianchi et al. [3] have considered the case in which both the outcomes and the predictions of the experts and the algorithm are required to be binary. <p> Slightly weaker results for the absolute loss were obtained already by Littlestone and Warmuth [13]. In this paper, we give a simplified version of Vovk's analysis in the case that the predictions can range continuously in <ref> [0; 1] </ref>. This gives a straightforward method for obtaining the value c L in (1.1). The value c L itself is the same as implied by Vovk's results. Further, we see that our method gives optimal values for the constant c L . <p> The sequence S is an N -expert trial sequence if the tth prediction vector x t is in <ref> [0; 1] </ref> N for t = 1; : : : ; `. We consider both binary outcomes , with the outcomes y t either 0 or 1, and continuous-valued outcomes, with y t any real number from the interval [0; 1]. <p> trial sequence if the tth prediction vector x t is in <ref> [0; 1] </ref> N for t = 1; : : : ; `. We consider both binary outcomes , with the outcomes y t either 0 or 1, and continuous-valued outcomes, with y t any real number from the interval [0; 1]. At trial t, the algorithm A produces its prediction ^y t 2 [0; 1] as a function of the prediction vectors x 1 ; : : : ; x t and the outcomes y 1 ; : : : ; y t1 . <p> We consider both binary outcomes , with the outcomes y t either 0 or 1, and continuous-valued outcomes, with y t any real number from the interval <ref> [0; 1] </ref>. At trial t, the algorithm A produces its prediction ^y t 2 [0; 1] as a function of the prediction vectors x 1 ; : : : ; x t and the outcomes y 1 ; : : : ; y t1 . <p> The performance of the learner at trial t is measured by L (y t ; ^y t ), where L is a loss function with the range <ref> [0; 1), or sometimes [0; 1] </ref>. For binary outcomes y t 2 f 0; 1 g it suffices to consider the functions L 0 and L 1 defined by L 0 (y; ^y) = L (0; ^y) and L 1 (^y) = L (1; ^y). <p> The performance of the learner at trial t is measured by L (y t ; ^y t ), where L is a loss function with the range [0; 1), or sometimes <ref> [0; 1] </ref>. For binary outcomes y t 2 f 0; 1 g it suffices to consider the functions L 0 and L 1 defined by L 0 (y; ^y) = L (0; ^y) and L 1 (^y) = L (1; ^y). <p> In each case, the function L 0 is increasing and L 1 decreasing in <ref> [0; 1] </ref>, so the loss L (y; ^y) increases as the prediction ^y moves away from the outcome y. The functions L 0 and L 1 are differentiable, and by the previous remark, L 0 0 (z) 0 and L 0 1 (z) 0 for all z. <p> We let V L;A (N; `) = sup V L;A (((x 1 ; y 1 ); : : : ; (x ` ; y ` ))) j x t 2 <ref> [0; 1] </ref> N ; y t 2 f 0; 1 g be the worst case amount of additional loss for A, when the outcomes in an N -expert trial of length ` are restricted to be binary. <p> The goal of this paper is to study for general loss functions L what are the lowest additional losses V L;A (N; `) that can be obtained by an on-line prediction algorithm, and to generalize the results for continuous-valued outcomes y t 2 <ref> [0; 1] </ref>. We are particularly interested in whether V L;A (N; `) can have an upper bound that is independent on `. Such bounds have previously been proven for square loss and logarithmic loss when the outcomes are binary. <p> Let Q be a probability measure on f 0; 1 g, with Pr y2Q [y = 1] = q. For a prediction z 2 <ref> [0; 1] </ref>, the expected loss for probability measure Q, or for bias q, is E y2Q [L (y; z)] = (1q)L 0 (z)+qL 1 (z). Here we define 0 1 = 0. <p> To obtain explicit bounds for ^y t from these conditions, we need to have some notion of an inverse for L 0 and L 1 . Assume that L 0 is continuous and strictly increasing and L 1 is continuous and strictly decreasing in <ref> [0; 1] </ref>, which is implied by the assumptions of Theorem 3.1. <p> Thus, the equivalence between (3.12) and (3.15) will be maintained for all nonnegative 0 if the inverse L 1 0 is extended in such a way that the condition ^y t L 1 0 ( 0 ) holds for all ^y t 2 <ref> [0; 1] </ref> when 0 &gt; L 0 (1). Hence, we say that L 1 0 is a generalized inverse of L 0 if L 1 0 ( 0 ) 1 whenever 0 L 0 (1). <p> Similarly, L 1 1 is a generalized inverse of L 1 if L 1 1 (L 1 (^y)) = ^y for all ^y 2 <ref> [0; 1] </ref> and L 1 1 ( 1 ) 0 whenever 1 L 1 (0). <p> Lemma 3.9: Assume that L is a loss function such that L 0 (0) = L 1 (1) = 0, L 0 is continuous and strictly increasing in <ref> [0; 1] </ref>, and L 1 is continuous and strictly decreasing in [0; 1]. For any generalized inverses L 1 0 and L 1 1 , the condition (3.15) is equivalent to (3.12) for y 2 f 0; 1 g. <p> Lemma 3.9: Assume that L is a loss function such that L 0 (0) = L 1 (1) = 0, L 0 is continuous and strictly increasing in <ref> [0; 1] </ref>, and L 1 is continuous and strictly decreasing in [0; 1]. For any generalized inverses L 1 0 and L 1 1 , the condition (3.15) is equivalent to (3.12) for y 2 f 0; 1 g. <p> Proof If 0 62 [0; L 0 (1)], then both L 0 (^y t ) 0 and ^y t L 1 0 ( 0 ) hold for all ^y t 2 <ref> [0; 1] </ref>. If 1 62 [0; L 1 (0)], then both L 1 (^y t ) 1 and L 1 1 ( 1 ) ^y t hold for all ^y t 2 [0; 1]. <p> t ) 0 and ^y t L 1 0 ( 0 ) hold for all ^y t 2 <ref> [0; 1] </ref>. If 1 62 [0; L 1 (0)], then both L 1 (^y t ) 1 and L 1 1 ( 1 ) ^y t hold for all ^y t 2 [0; 1]. Hence, we may assume that 0 is in the range of L 0 and 1 is in the range of L 1 . <p> We therefore let &gt; 0 be arbitrary, and see for which values c the absolute loss is (c; )-realizable. By using the bound e x 1 (1 e )x that holds for all x 2 <ref> [0; 1] </ref>, we obtain L 1 1 ( 1 ) N X v t;i e x t;i 1 + c ln i=1 ! N X v t;i (1 (1 e )x t;i ) ln i=1 ! = c ln (1 p t + p t e ) ln (p t + <p> fi U 1` fi 1+p N 1 + j U y fi y fi dP N 1 + E x2P U 1` (x) i As the sequence U y y fl2 ; : : : converges in distribution to F fl , the bound (3.22) with p = 1 guarantees <ref> [1, Corollary, p. 292] </ref> lim `!1 E x2P fi y fl = E [F fl ] for all y and, therefore, lim `!1 r ` (y)E x2P U fl` (x) = E [F fl ] with probability 1 for y drawn from Q. <p> The bound (3.22) with p = 0 implies fi fi y fl fi fi 2BN , and the bounded convergence theorem <ref> [1, Thm. 16.5, p. 180] </ref> `!1 fi fi y flfl = E [F fl ] ; as claimed. 2 Theorem 3.16 shows how a probability measure for the experts and outcomes leads to a lower bound for V L (N; `) for large N and `. 13 Theorem 3.16: Let P <p> fi fi y flfl = E [F fl ] ; as claimed. 2 Theorem 3.16 shows how a probability measure for the experts and outcomes leads to a lower bound for V L (N; `) for large N and `. 13 Theorem 3.16: Let P be a probability measure on <ref> [0; 1] </ref> and Q a probability measure on f 0; 1 g. Assume that for y = 0 and y = 1, the condition Pr x2P [L (y; x) &gt; K] = 0 holds for some constant K. Let b be a Bayes-optimal prediction for Q. <p> Then for all " &gt; 0 there is an ` " such that for all ` ` " we have V L (N; `) `E y2Q [L (y; b)] `t + (a N ") ` ln N ; (3:23) where lim N!1 a N = p Proof Given x 2 <ref> [0; 1] </ref> Nfi` and y 2 f 0; 1 g ` , we define an N -expert trial sequence of length ` by hx; yi = ((x 1 ; y 1 ); : : :; (x ` ; y ` )). <p> For x 2 <ref> [0; 1] </ref> Nfi1 and y 2 f 0; 1 g 1 , let T ij (x) = L (y j ; x ij ) be the loss of expert i at trial j, if x is the sequence of experts' predictions and y the sequence of outcomes. <p> We consider T y a random variable on the domain <ref> [0; 1] </ref> Nfi1 . We now define for i = 1; : : : ; N and ` = 1; 2; : : : the random variable S i` in the domain [0; 1] Nfi1 fi f 0; 1 g 1 P ` denote the loss of expert i in the <p> We consider T y a random variable on the domain <ref> [0; 1] </ref> Nfi1 . We now define for i = 1; : : : ; N and ` = 1; 2; : : : the random variable S i` in the domain [0; 1] Nfi1 fi f 0; 1 g 1 P ` denote the loss of expert i in the first ` trials. We also define for a given sequence y 2 f 0; 1 g 1 14 the random variable S y y P ` y ij . <p> Let A be an arbitrary on-line prediction algorithm. For any probability measure P on <ref> [0; 1] </ref> and for any " &gt; 0, we have by Theorem 3.16 for sufficiently large ` the bound V L;A (N; `) `(E y2Q [L (y; b)] t ) + (a N ") ` ln N ; (3:27) where lim N!1 a N = p 2. <p> This gives = 1=2, and hence V L (N; `) (1 o (1)) p (` ln N )=2, which is the result obtained by Cesa-Bianchi et al. [2]. Lemma 3.19: If a prediction z 2 (0; 1) is not Bayes-optimal for any bias q 2 <ref> [0; 1] </ref>, then there are two predictions b 1 and b 2 with b 1 &lt; z &lt; b 2 such that for some bias q both b 1 and b 2 are Bayes-optimal. Proof Consider a prediction z 2 (0; 1) that is not Bayes-optimal for any bias. <p> If we can show R 1 " R 2 6= ;, we are done. Since z is never Bayes-optimal, we have R 1 <ref> [ R 2 = [0; 1] </ref>. Hence, if both R 1 and R 2 are closed, their intersection cannot be empty. Suppose that R 1 is not closed. <p> If we can show R 1 " R 2 6= ;, we are done. Since z is never Bayes-optimal, we have R 1 [ R 2 = <ref> [0; 1] </ref>. Hence, if both R 1 and R 2 are closed, their intersection cannot be empty. Suppose that R 1 is not closed. <p> show lim `!1 V L (2; `) c L ln 2, and our conjecture is that this is true for the square loss. 4 Continuous-valued outcomes 4.1 Applying the Generic Algorithm We now show that under certain assumptions, The Generic Algorithm 3.7 also works for continuous-valued outcomes y t 2 <ref> [0; 1] </ref>. These assumptions hold for the square and relative entropy loss, but not for the absolute loss, which will be considered in Subsection 4.2. We also consider the more general situation where the values x t;i and y t are not in the range [0; 1]. <p> continuous-valued outcomes y t 2 <ref> [0; 1] </ref>. These assumptions hold for the square and relative entropy loss, but not for the absolute loss, which will be considered in Subsection 4.2. We also consider the more general situation where the values x t;i and y t are not in the range [0; 1]. Lemma 4.1: Assume that for all y; a; b 2 [0; 1], the function g defined by g (y; a; b) = L (y; a)=c L (y; b) satisfies @ 2 g (y; a; b) @y 0 : (4:1) If (3.12) holds for binary values y 2 f 0; <p> We also consider the more general situation where the values x t;i and y t are not in the range <ref> [0; 1] </ref>. Lemma 4.1: Assume that for all y; a; b 2 [0; 1], the function g defined by g (y; a; b) = L (y; a)=c L (y; b) satisfies @ 2 g (y; a; b) @y 0 : (4:1) If (3.12) holds for binary values y 2 f 0; 1 g, then it holds for all values y 2 [0; 1]. <p> 2 <ref> [0; 1] </ref>, the function g defined by g (y; a; b) = L (y; a)=c L (y; b) satisfies @ 2 g (y; a; b) @y 0 : (4:1) If (3.12) holds for binary values y 2 f 0; 1 g, then it holds for all values y 2 [0; 1]. 20 Proof We write (3.12) as (L (y; ^y t ) (y))=c 0. By exponentiating both sides and applying (3.11), this becomes e L (y;^y t )=c i=1 Let us denote the left-hand side of (4.2) by f (y). <p> derivative of F we get @ 2 f (y) N X v t;i @ 2 g (y; ^y t ; x t;i ) @y e g (y;^y t ;x t;i ) : As our assumption implies this to be nonnegative, the maximum value of f for y in the interval <ref> [0; 1] </ref> occurs for y = 0 or y = 1. <p> Let S = ((x 1 ; y 1 ); : : : ; (x ` ; y ` )) be a trial sequence for which x t 2 <ref> [0; 1] </ref> N and y t 2 [0; 1] hold for all t. Then the algorithm does not fail during the trial sequence, and its additional loss satisfies V L;A (S) c L ln N : Proof First note that by Lemma 3.10, the algorithm A does not fail. <p> Let S = ((x 1 ; y 1 ); : : : ; (x ` ; y ` )) be a trial sequence for which x t 2 <ref> [0; 1] </ref> N and y t 2 [0; 1] hold for all t. Then the algorithm does not fail during the trial sequence, and its additional loss satisfies V L;A (S) c L ln N : Proof First note that by Lemma 3.10, the algorithm A does not fail. <p> Recall that c L = 1 for the relative entropy loss. Hence, by Theorem 4.2, if A is the Generic Algorithm 3.7 with c = = 1, we have V L;A (S) ln N for any N -expert trial sequence S even if the outcomes y t 2 <ref> [0; 1] </ref> are continuous-valued. 2 Example 4.4: Let L be the square loss L sq . As the second derivative @ 2 L (y; z)=@y 2 is constant, the second derivative of the function g of Lemma 4.1 is 0 whenever c = 1=, and hence (4.1) trivially holds. <p> We see in Lemma 4.6 that there always is a prediction ^y t that satisfies (4.4) and that (4.4) implies jy ^y t j (y) for all y 2 <ref> [0; 1] </ref> and not merely for y 2 f 0; 1 g, which was the requirement in the Generic Algorithm. Hence, we now get for continuous-valued outcomes y t 2 [0; 1] the bound (3.20) that was previously obtained for binary outcomes y t 2 f 0; 1 g. <p> a prediction ^y t that satisfies (4.4) and that (4.4) implies jy ^y t j (y) for all y 2 <ref> [0; 1] </ref> and not merely for y 2 f 0; 1 g, which was the requirement in the Generic Algorithm. Hence, we now get for continuous-valued outcomes y t 2 [0; 1] the bound (3.20) that was previously obtained for binary outcomes y t 2 f 0; 1 g. Note that if (3.20) holds for y t 2 [0; 1], it actually holds for all y t , provided we still have x t;i 2 [0; 1]. <p> Hence, we now get for continuous-valued outcomes y t 2 <ref> [0; 1] </ref> the bound (3.20) that was previously obtained for binary outcomes y t 2 f 0; 1 g. Note that if (3.20) holds for y t 2 [0; 1], it actually holds for all y t , provided we still have x t;i 2 [0; 1]. <p> continuous-valued outcomes y t 2 <ref> [0; 1] </ref> the bound (3.20) that was previously obtained for binary outcomes y t 2 f 0; 1 g. Note that if (3.20) holds for y t 2 [0; 1], it actually holds for all y t , provided we still have x t;i 2 [0; 1]. <p> Again, the parameter can be tuned as mentioned in Example 3.14, and the scaling method of Example 4.4 can be used if the values x t;i are not in the range <ref> [0; 1] </ref>. For the absolute loss, (3.12) has a simple geometric interpretation. Figure 4.1 gives an example of the graphs of the left-hand side jy ^yj and the right-hand side (y) as functions of y, fixing ^y = 0:58 and x = (0:33; 0:83; 0:97; 0:52). <p> The graph of has a nondifferentiable tip at each value y = x i . The condition (3.12) states that the vee-curve must be below the graph of at y. For continuous-valued outcomes we wish (3.12) to hold for y 2 <ref> [0; 1] </ref> and hence the vee-curve to be below the graph of everywhere. If we were to move the tip of the vee to the left of 0:51, the right arm of the vee would intersect the -curve at the value y = 0:97. <p> We now show that a prediction that satisfies (4.4) always exists and satisfies the conditions of Theorem 3.8. Lemma 4.6: Let v t 2 <ref> [0; 1] </ref> N with P i v t;i = 1 and x t 2 [0; 1] N , and let &gt; 0. Then a prediction ^y t that satisfies (4.4) exists. Further, (4.4) implies jy ^y t j (y) for all y 2 [0; 1]. <p> We now show that a prediction that satisfies (4.4) always exists and satisfies the conditions of Theorem 3.8. Lemma 4.6: Let v t 2 <ref> [0; 1] </ref> N with P i v t;i = 1 and x t 2 [0; 1] N , and let &gt; 0. Then a prediction ^y t that satisfies (4.4) exists. Further, (4.4) implies jy ^y t j (y) for all y 2 [0; 1]. <p> Lemma 4.6: Let v t 2 <ref> [0; 1] </ref> N with P i v t;i = 1 and x t 2 [0; 1] N , and let &gt; 0. Then a prediction ^y t that satisfies (4.4) exists. Further, (4.4) implies jy ^y t j (y) for all y 2 [0; 1]. Proof We prove the existence of ^y t by showing that y (y) z + (z) (4:5) holds for all y, z, v t , and x t . <p> This holds for all 0 p 1 because the function ln is concave. A similar argument based on second derivatives shows that for y 2 <ref> [0; 1] </ref>, the value y (y) obtains its maximum and the value y + (y) its minimum when y 2 f 0; 1; x t;1 ; : : : ; x t;N g. 2 Lemma 4.6 immediately implies the following result. <p> Theorem 4.7: Let S = ((x 1 ; y 1 ); : : : ; (x ` ; y ` )) be a trial sequence with x t 2 <ref> [0; 1] </ref> N and y t 2 [0; 1] for all t. Let L be the absolute loss and A be the Vee Algorithm 4.5. <p> Theorem 4.7: Let S = ((x 1 ; y 1 ); : : : ; (x ` ; y ` )) be a trial sequence with x t 2 <ref> [0; 1] </ref> N and y t 2 [0; 1] for all t. Let L be the absolute loss and A be the Vee Algorithm 4.5.
Reference: [2] <author> N. Cesa-Bianchi, Y. Freund, D. P. Helmbold, D. Haussler, R. E. Schapire, and M. K. Warmuth. </author> <title> How to use expert advice. </title> <type> Technical Report UCSC-CRL-94-33, </type> <institution> Univ. of Calif. Computer Research Lab, </institution> <address> Santa Cruz, CA, </address> <year> 1994. </year> <note> An extended abstract appeared in STOC '93. </note>
Reference-contexts: The only allowance we make for the algorithm is that it can make a large loss if none of the experts is good. Our framework for on-line prediction is based on the work of Vovk [16, 17] and Cesa-Bianchi et al. <ref> [2] </ref>. Similar frameworks have also been considered by Cover [6], Dawid [7], Feder et al. [9, 14, 19], and Mycielski [15]. See Chung [5] for recent related results. <p> Note that the bound (1.1) for the additional loss is independent of the length ` of the trial sequence S. On the other hand, for the absolute loss L abs given by L abs (y t ; ^y t ) = jy t ^y t j Cesa-Bianchi et al. <ref> [2] </ref> have shown that bounds of the form (1.1) are not obtainable, but the best possible algorithm has a worst-case bound of the form Loss L (A; S) min 1iN Loss L (E i ; S) = fi ` log N . <p> Thus, in a sense we see that in our particular setting, the average case is almost as difficult as the worst case. The proof technique with a randomized adversary was used by Cesa-Bianchi et al. <ref> [2] </ref> in the special case of the absolute loss. Finally, in Subsection 4.1 we show that for certain loss functions, such as the square and logarithmic loss, Vovk's algorithm achieves the same worst-case loss bound even if the outcomes are allowed to be continuous-valued. <p> Finally, in Subsection 4.1 we show that for certain loss functions, such as the square and logarithmic loss, Vovk's algorithm achieves the same worst-case loss bound even if the outcomes are allowed to be continuous-valued. For the absolute loss, the worst-case bounds proven for binary outcomes <ref> [16, 2] </ref> can be achieved with continuous-valued outcomes by using a slightly more complicated algorithm, as we show in Subsection 4.2. 2 On-line prediction and loss bounds We consider the performance of an on-line learning algorithm A over a sequence S = ((x 1 ; y 1 ); : : : <p> On the other hand, for the absolute loss it is known that no upper bound of this form exists, but the algorithm A that minimizes V L;A (N; `) has V L;A (N; `) = p <ref> [2] </ref>. One of our results provides a formula from which the best possible upper bound for V L;A (N; `) can be obtained for a wide class of loss functions L. For example, we obtain V L;A (N; `) 2 1=2 ln N if L is the Hellinger loss. <p> The special case of absolute loss was considered by Cesa-Bianchi et al. <ref> [2] </ref>. They show that for the optimal algorithm A we have V L;A (N; `) = fi p . For the absolute loss, the value c L is infinite because the denominator S (z) is 0 for all z. <p> If S (z) &lt; 0 for some 0 &lt; z &lt; 1, or there are values a &lt; b such that S (z) = 0 for all a z b, we have V L (N; `) = ` log N : (3:10) This generalizes the results of Cesa-Bianchi et al. <ref> [2] </ref> for the absolute loss. Finally, it is possible to construct loss functions L for which the value c L is infinite, but the denominator S (z) is positive for all z. For such loss functions the results of this paper have no implications whatsoever. <p> By Jensen's inequality, this is positive for c (2 ln 2 1+e ) 1 , and the prediction condition (3.12) for y 2 f 0; 1 g becomes 1 + P N 2 ln 2 ^y t P N 2 ln 2 : (3:19) Cesa-Bianchi et al. <ref> [2] </ref> have noted that (3.19) always holds if we choose ^y t = ln (1 p t + p t e ) + ln ((1 p t )e + p t ) but does not in general hold for ^y t = p t . <p> We would like to choose the learning rate in such a way that the loss bound on the right-hand side of (3.20) is minimized. This tuning of the learning rate is discussed in detail by Cesa-Bianchi et al. <ref> [2, 3] </ref>. Here we just cite some of the basic results. <p> Similar results can be obtained by basing the choise of on an upper bound for the loss min i Loss L (E i ; S) of the best expert instead of on `. Finally, we consider the variations of the Generic Algorithm given by Cesa-Bianchi et al. <ref> [2] </ref> for the special case of the absolute loss. <p> Hence, the algorithm works and gives the same worst-case loss bound for any choice e jy t x t;i j ff t;i 1 (1 e )x t;i : (3:21) Interestingly enough, the weights obtained using ff t;i = 1 (1 e )x t;i have a Bayesian interpretation <ref> [2] </ref>. 2 3.3 Lower bounds This subsection contains proofs of the lower bounds for V L (N; `) stated in Theorems 3.1 and 3.5 in Subsection 3.1. The lower bounds hold even for algorithms that receive ` as input begore the first trial. <p> This gives = 1=2, and hence V L (N; `) (1 o (1)) p (` ln N )=2, which is the result obtained by Cesa-Bianchi et al. <ref> [2] </ref>. <p> and y = 1, which gives the weaker condition that the vee-curve must be below the graph of at the endpoints. 23 For binary outcomes, the loss bound (3.20) was previously shown for a whole family of algorithms defined by a number of different prediction and update factors ff t;i <ref> [2] </ref>, as was briefly explained in Example 3.14. In the continuous case we have less freedom. Suppose we were to use ff t;i = 1 (1 e )x t;i , and let N = 1, x = (0), and = 1.
Reference: [3] <author> N. Cesa-Bianchi, Y. Freund, D. P. Helmbold, and M. Warmuth. </author> <title> On-line prediction and conversion strategies. </title> <booktitle> In Computational Learning Theory: Eurocolt '93, volume New Series Number 53 of The Institute of Mathematics and its Applications Conference Series, </booktitle> <pages> pages 205-216, </pages> <address> Oxford, 1994. </address> <publisher> Oxford University Press. </publisher>
Reference-contexts: We later see how the results can be generalized for continuous-valued outcomes y t 2 [0; 1]. Cesa-Bianchi et al. <ref> [3] </ref> have considered the case in which both the outcomes and the predictions of the experts and the algorithm are required to be binary. <p> We would like to choose the learning rate in such a way that the loss bound on the right-hand side of (3.20) is minimized. This tuning of the learning rate is discussed in detail by Cesa-Bianchi et al. <ref> [2, 3] </ref>. Here we just cite some of the basic results.
Reference: [4] <author> N. Cesa-Bianchi, P. Long, and M. Warmuth. </author> <title> Worst-case quadratic loss bounds for on-line prediction of linear functions by gradient descent. </title> <type> Technical Report UCSC-CRL-93-36, </type> <institution> Univ. of Calif. Computer Research Lab, </institution> <address> Santa Cruz, CA, </address> <year> 1993. </year> <note> An extended abstract appeared in COLT '93. </note>
Reference-contexts: In this paper we have given bounds of the additional loss of our algorithms over the loss of the best expert. A more challenging problem is to bound the additional loss of the algorithms over the best linear combination of experts <ref> [12, 4, 11] </ref>. The only worst-case loss bounds for the latter case that have been obtained were for the square loss function. Hopefully, some of the 25 results of the present paper can be generalized to the linear combination case.
Reference: [5] <author> T. H. Chung. </author> <title> Approximate methods for sequential decision making using expert advice. </title> <booktitle> In Proc. 7th Annu. ACM Workshop on Comput. Learning Theory, </booktitle> <pages> pages 183-189. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: Our framework for on-line prediction is based on the work of Vovk [16, 17] and Cesa-Bianchi et al. [2]. Similar frameworks have also been considered by Cover [6], Dawid [7], Feder et al. [9, 14, 19], and Mycielski [15]. See Chung <ref> [5] </ref> for recent related results. In this paper, we start by considering the case in which the outcomes are binary, i.e., y t 2 f 0; 1 g for all t. <p> The next challenge is to extend the results for continuous-valued outcomes to more general loss functions. Another direction worth exploring is to let outcomes be discrete valued with more than two choices. The recent results of Chung <ref> [5] </ref> address some of these problems. In this paper we restricted the predictions of the experts to lie between zero and one, except in specific examples where we have indicated how scaling tricks can be used.
Reference: [6] <author> T. </author> <title> Cover. Behavior of sequential predictors of binary sequences. </title> <booktitle> In Proceedings of the 4th Prague Conference on Information Theory, Statistical Decision Functions and Random Processes, </booktitle> <pages> pages 263-272. </pages> <publisher> Publishing House of the Czechoslovak Academy of Sciences, </publisher> <year> 1965. </year>
Reference-contexts: Our framework for on-line prediction is based on the work of Vovk [16, 17] and Cesa-Bianchi et al. [2]. Similar frameworks have also been considered by Cover <ref> [6] </ref>, Dawid [7], Feder et al. [9, 14, 19], and Mycielski [15]. See Chung [5] for recent related results. In this paper, we start by considering the case in which the outcomes are binary, i.e., y t 2 f 0; 1 g for all t.
Reference: [7] <author> A. P. Dawid. </author> <title> Prequential analysis, stochastic complexity and bayesian inference. Bayesian Statistics. </title> <note> To appear. </note>
Reference-contexts: Our framework for on-line prediction is based on the work of Vovk [16, 17] and Cesa-Bianchi et al. [2]. Similar frameworks have also been considered by Cover [6], Dawid <ref> [7] </ref>, Feder et al. [9, 14, 19], and Mycielski [15]. See Chung [5] for recent related results. In this paper, we start by considering the case in which the outcomes are binary, i.e., y t 2 f 0; 1 g for all t.
Reference: [8] <author> A. DeSantis, G. Markowsky, and M. N. Wegman. </author> <title> Learning probabilistic prediction functions. </title> <booktitle> In Proc. 29th Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 110-119. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1988. </year>
Reference-contexts: For instance, for the square loss Vovk's algorithm achieves the bound with c L = 1=2 [16], and for logarithmic loss with c L = 1 <ref> [8, 16] </ref>. Note that the bound (1.1) for the additional loss is independent of the length ` of the trial sequence S. <p> Such bounds have previously been proven for square loss and logarithmic loss when the outcomes are binary. For these loss functions there are algorithms that satisfy V L;A (N; `) 1 2 ln N and V L;A (N; `) ln N , respectively <ref> [16, 8] </ref>. On the other hand, for the absolute loss it is known that no upper bound of this form exists, but the algorithm A that minimizes V L;A (N; `) has V L;A (N; `) = p [2]. <p> The loss bound we obtain was previously shown by De Santis et al. <ref> [8] </ref> and Vovk [16]. 2 10 Example 3.13: Let L be the square loss. Vovk [16] has shown that the square loss is (1=2; 2)- realizable. Here the result follows from Lemma 3.10 and Example 3.2.
Reference: [9] <author> M. Feder, N. Merhav, and M. Gutman. </author> <title> Universal prediction of individual sequences. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 38 </volume> <pages> 1258-1270, </pages> <year> 1992. </year>
Reference-contexts: Our framework for on-line prediction is based on the work of Vovk [16, 17] and Cesa-Bianchi et al. [2]. Similar frameworks have also been considered by Cover [6], Dawid [7], Feder et al. <ref> [9, 14, 19] </ref>, and Mycielski [15]. See Chung [5] for recent related results. In this paper, we start by considering the case in which the outcomes are binary, i.e., y t 2 f 0; 1 g for all t.
Reference: [10] <author> Janos Galambos. </author> <title> The Asymptotic Theory of Extreme Order Statistics. </title> <editor> R. E. </editor> <publisher> Krieger, </publisher> <address> Malabar, FL, </address> <year> 1987. </year> <note> Second Edition. </note>
Reference-contexts: We now apply Lemma 3.15 to the random variables U y i` . Then the random variables F i in Lemma 3.15 have standard normal distribution. By a standard result <ref> [10] </ref>, their minimum F fl has expectation E [F fl ] = a N p ln N, where lim N!1 a N = p 2. We take r ` (y) = ^ ` (y)=.
Reference: [11] <author> J. Kivinen and M. K. Warmuth. </author> <title> Exponentiated gradient versus gradient descent for linear predictors. </title> <type> Technical Report UCSC-CRL-94-16, </type> <institution> University of California, Santa Cruz, Computer Research Laboratory, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: In this paper we have given bounds of the additional loss of our algorithms over the loss of the best expert. A more challenging problem is to bound the additional loss of the algorithms over the best linear combination of experts <ref> [12, 4, 11] </ref>. The only worst-case loss bounds for the latter case that have been obtained were for the square loss function. Hopefully, some of the 25 results of the present paper can be generalized to the linear combination case.
Reference: [12] <author> N. Littlestone, P. M. Long, and M. K. Warmuth. </author> <title> On-line learning of linear functions. </title> <booktitle> In Proc. of the 23rd Symposium on Theory of Computing, </booktitle> <pages> pages 465-475. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1991. </year> <month> 26 </month>
Reference-contexts: In this paper we have given bounds of the additional loss of our algorithms over the loss of the best expert. A more challenging problem is to bound the additional loss of the algorithms over the best linear combination of experts <ref> [12, 4, 11] </ref>. The only worst-case loss bounds for the latter case that have been obtained were for the square loss function. Hopefully, some of the 25 results of the present paper can be generalized to the linear combination case.
Reference: [13] <author> N. Littlestone and M. K. Warmuth. </author> <title> The weighted majority algorithm. </title> <journal> Information and Computation, </journal> <volume> 108(2) </volume> <pages> 212-261, </pages> <year> 1994. </year>
Reference-contexts: Slightly weaker results for the absolute loss were obtained already by Littlestone and Warmuth <ref> [13] </ref>. In this paper, we give a simplified version of Vovk's analysis in the case that the predictions can range continuously in [0; 1]. This gives a straightforward method for obtaining the value c L in (1.1). The value c L itself is the same as implied by Vovk's results. <p> We would then have (0) = 0 and 1 (1) 0:316, and hence the condition (4.4) would not hold for any ^y t . The Algorithm WMC <ref> [13] </ref> does work for the continuous case, and is allowed to use any update that satisfies (3.21). However, its worst case bound has 1 e in the denominator instead of 2 ln 2 1+e , and hence it is slightly worse than the bounds given here.
Reference: [14] <author> N. Merhav and M. Feder. </author> <title> Universal sequential learning and decisions from individual data sequences. </title> <booktitle> In Proc. 5th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 413-427. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: Our framework for on-line prediction is based on the work of Vovk [16, 17] and Cesa-Bianchi et al. [2]. Similar frameworks have also been considered by Cover [6], Dawid [7], Feder et al. <ref> [9, 14, 19] </ref>, and Mycielski [15]. See Chung [5] for recent related results. In this paper, we start by considering the case in which the outcomes are binary, i.e., y t 2 f 0; 1 g for all t.
Reference: [15] <author> J. Mycielski. </author> <title> A learning algorithm for linear operators. </title> <journal> Proceedings of the American Mathematical Society, </journal> <volume> 103(2) </volume> <pages> 547-550, </pages> <year> 1988. </year>
Reference-contexts: Our framework for on-line prediction is based on the work of Vovk [16, 17] and Cesa-Bianchi et al. [2]. Similar frameworks have also been considered by Cover [6], Dawid [7], Feder et al. [9, 14, 19], and Mycielski <ref> [15] </ref>. See Chung [5] for recent related results. In this paper, we start by considering the case in which the outcomes are binary, i.e., y t 2 f 0; 1 g for all t.
Reference: [16] <author> V. Vovk. </author> <title> Aggregating strategies. </title> <booktitle> In Proc. 3rd Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 371-383. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: The only allowance we make for the algorithm is that it can make a large loss if none of the experts is good. Our framework for on-line prediction is based on the work of Vovk <ref> [16, 17] </ref> and Cesa-Bianchi et al. [2]. Similar frameworks have also been considered by Cover [6], Dawid [7], Feder et al. [9, 14, 19], and Mycielski [15]. See Chung [5] for recent related results. <p> Further, for the square and logarithmic loss, the algorithm for binary outcomes works for continuous outcomes, as well. We are interested in what bounds for the worst-case additional loss are possible for different loss functions. Vovk <ref> [16] </ref> introduced a general on-line prediction algorithm that is applicable for all loss functions when the outcomes are binary. Vovk's analysis allows for a more general setting than the one we consider; for instance, the predictions may be restricted to some discrete set. <p> For instance, for the square loss Vovk's algorithm achieves the bound with c L = 1=2 <ref> [16] </ref>, and for logarithmic loss with c L = 1 [8, 16]. Note that the bound (1.1) for the additional loss is independent of the length ` of the trial sequence S. <p> For instance, for the square loss Vovk's algorithm achieves the bound with c L = 1=2 [16], and for logarithmic loss with c L = 1 <ref> [8, 16] </ref>. Note that the bound (1.1) for the additional loss is independent of the length ` of the trial sequence S. <p> Finally, in Subsection 4.1 we show that for certain loss functions, such as the square and logarithmic loss, Vovk's algorithm achieves the same worst-case loss bound even if the outcomes are allowed to be continuous-valued. For the absolute loss, the worst-case bounds proven for binary outcomes <ref> [16, 2] </ref> can be achieved with continuous-valued outcomes by using a slightly more complicated algorithm, as we show in Subsection 4.2. 2 On-line prediction and loss bounds We consider the performance of an on-line learning algorithm A over a sequence S = ((x 1 ; y 1 ); : : : <p> Such bounds have previously been proven for square loss and logarithmic loss when the outcomes are binary. For these loss functions there are algorithms that satisfy V L;A (N; `) 1 2 ln N and V L;A (N; `) ln N , respectively <ref> [16, 8] </ref>. On the other hand, for the absolute loss it is known that no upper bound of this form exists, but the algorithm A that minimizes V L;A (N; `) has V L;A (N; `) = p [2]. <p> The algorithm A that obtains the bound (3.4), as well as the proof of the bound, are already given by Vovk <ref> [16] </ref>. The algorithm makes its predictions independently of the length ` of the trial sequence. We give the algorithm and a simplified proof in Subsection 3.2. The lower bound (3.5) is based on a probabilistic proof that is given in Subsection 3.3. <p> The basic idea of proving the upper bound for the loss of the Generic Algorithm is based on relating the total potential increase U `+1 U 1 to the total loss of the best expert. The following upper bound was already given by Vovk <ref> [16] </ref>. Theorem 3.8: Let L be any loss function. Let S = ((x 1 ; y 1 ); : : :; (x ` ; y ` )) be an N -expert trial sequence in which the outcomes y t 2 f 0; 1 g are binary. <p> The result then follows from Theorem 3.8 by setting w 1;i = 1 for all i. The rest of this subsection gives our formulation of Vovk's <ref> [16] </ref> proof for these results. We first devolop an equivalent version of condition (3.12). <p> The loss bound we obtain was previously shown by De Santis et al. [8] and Vovk <ref> [16] </ref>. 2 10 Example 3.13: Let L be the square loss. Vovk [16] has shown that the square loss is (1=2; 2)- realizable. Here the result follows from Lemma 3.10 and Example 3.2. <p> The loss bound we obtain was previously shown by De Santis et al. [8] and Vovk <ref> [16] </ref>. 2 10 Example 3.13: Let L be the square loss. Vovk [16] has shown that the square loss is (1=2; 2)- realizable. Here the result follows from Lemma 3.10 and Example 3.2. The note after the proof of Lemma 3.10 further implies that the square loss is not (c; 1=c)-realizable for any c &lt; 1=2. <p> prediction, but cannot be used directly. 11 The bound obtained by applying Theorem 3.8 for the absolute loss with the choice c = 1+e , namely Loss L (A; S) ln W 1 + Loss L (E i ; S) 2 ln 2 ; (3:20) was first proven by Vovk <ref> [16] </ref>. We would like to choose the learning rate in such a way that the loss bound on the right-hand side of (3.20) is minimized. This tuning of the learning rate is discussed in detail by Cesa-Bianchi et al. [2, 3]. Here we just cite some of the basic results.
Reference: [17] <author> V. Vovk. </author> <title> Universal forecasting algorithms. </title> <journal> Inform. Comput., </journal> <volume> 96(2) </volume> <pages> 245-277, </pages> <year> 1992. </year>
Reference-contexts: The only allowance we make for the algorithm is that it can make a large loss if none of the experts is good. Our framework for on-line prediction is based on the work of Vovk <ref> [16, 17] </ref> and Cesa-Bianchi et al. [2]. Similar frameworks have also been considered by Cover [6], Dawid [7], Feder et al. [9, 14, 19], and Mycielski [15]. See Chung [5] for recent related results.
Reference: [18] <author> V. </author> <title> Vovk. </title> <type> Unpublished manuscript, </type> <month> October </month> <year> 1994. </year>
Reference-contexts: The results of this section were obtained independently by Vovk <ref> [18] </ref>. We call our algorithm the Vee Algorithm. In choosing the prediction it is now necessary to explicitly also consider other outcomes than just y = 0 and y = 1. We will show that the prediction can still be computed in time O (N log N ).
Reference: [19] <author> M. J. Weinberger, N. Merhav, and M. Feder. </author> <title> Optimal sequential probability assignment for individual sequences. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 40(2) </volume> <pages> 384-396, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Our framework for on-line prediction is based on the work of Vovk [16, 17] and Cesa-Bianchi et al. [2]. Similar frameworks have also been considered by Cover [6], Dawid [7], Feder et al. <ref> [9, 14, 19] </ref>, and Mycielski [15]. See Chung [5] for recent related results. In this paper, we start by considering the case in which the outcomes are binary, i.e., y t 2 f 0; 1 g for all t.
References-found: 19

