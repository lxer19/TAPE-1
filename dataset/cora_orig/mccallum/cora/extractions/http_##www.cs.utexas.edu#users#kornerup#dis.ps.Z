URL: http://www.cs.utexas.edu/users/kornerup/dis.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/kornerup/kornerup-papers.html
Root-URL: http://www.cs.utexas.edu
Title: Data Structures for Parallel Recursion  
Author: by Jacob Kornerup, Cand. Scient. 
Degree: Dissertation Presented to the Faculty of the Graduate School of  in Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy  
Date: December 1997  
Address: Austin  Austin  
Affiliation: The University of Texas at  The University of Texas at  
Abstract-found: 0
Intro-found: 1
Reference: [Ada94] <author> Will E. Adams. </author> <title> Verifying adder circuits using powerlists. </title> <type> Technical Report CS-TR-94-02, </type> <institution> University of Texas at Austin, Department of Computer Sciences, </institution> <month> March </month> <year> 1994. </year> <note> Available by ftp as ftp://ftp.cs.utexas.edu/pub/techreports/tr94-02.ps.Z. </note>
Reference-contexts: These functions are fundamental building blocks for PowerList functions. The operators ! ("right-shift") and ("left-shift") have the type: ! : X fi PowerList:X:n ! PowerList:X:n : PowerList:X:n fi X ! PowerList:X:n They can be defined as follows <ref> [Ada94] </ref> 1 : x!hai = hx i (2.29) 1 The operators ! and have a binding power that is greater than that of the other binary operators, with the exception of function application (infix dot). <p> j q) = last:q (2.36) We use the following shorthand for first and last when convenient: p = first:p and ! p = last:p Using first and last we can provide an alternative definition of ! and using j as the constructor (a proof of (2.37) can be found in <ref> [Ada94] </ref>; the proof of (2.38) is dual): a!(p j q) = a!p j p !q (2.37) 27 The function rr : PowerList:X:n ! PowerList:X:n rotates the elements of a PowerList one position to the right, wrapping the rightmost element around; its inverse rl : PowerList:X:n ! PowerList:X:n rotates the elements of <p> p, where p 2 PowerList:Y:n and the data type Y has the property that (Y; +; 0) is a monoid, can be defined [Mis94] as the (unique) solution to the equation (in u): u = (0!u) p (2.57) A proof that (2.57) has a unique solution can be found in <ref> [Ada94] </ref>. We define the function ps : PowerList:Y:n ! PowerList:Y:n to realize a well known algorithm for computing the prefix sum due to Ladner and Fischer [LF80]. This algorithm has roots in an algorithm presented by Ofman [Ofm63] and later implemented on a perfect shu*e network by Stone [Sto71]. <p> a .p j q/ b) (3.115) This proof is omitted, since it follows closely the proof given in Chapter 2. 88 The proof of the dual result odd:(p/ b) p/ b :(odd:(p/ b) = p/ b) (3.116) is similar to the above proof and is omitted. 3.4 Adder Circuits In <ref> [Ada94] </ref> Will Adams presented PowerList descriptions for two arithmetic circuits that perform addition on natural numbers: the ripple carry adder and the carry lookahead adder. <p> The result is a pair; the first component of the pair is a ParList containing the result of the addition, and the second component is the carry-out bit from the addition. The following equations defines rc, where (3.117) and (3.118) are taken from <ref> [Ada94] </ref>: rc:b:hx i:hyi = (h (x + y + b) mod 2i; (x + y + b) ffi 2) (3.117) where t = u j v (u; c) = rc:b:p:r (3.119) where x = (a + b + d) ffi 2 y = (a + b + d) mod 2 The <p> y = 8 : if x 6= y ? : Trit fi Trit ! Trit x ? y = 8 : x if y = 90 fi : Trit fi Trit ! Trit x fi y = 8 : :y if y = where :0 = 1 : = Adams <ref> [Ada94] </ref> defined the carry lookahead adder by cl:b:p:q = (t; d) (3.124) where t = s fi r d = s ? r s = ps:(b!r) and ps is computed using the associative operator ? (that has as its neutral element). <p> Proof rc:c:(p/ a):(q/ b) = cl:c:(p/ a):(q/ b) (s/ ((a + b + d) mod 2); (a + b + d) ffi 2) = (t/ (e fi (x * y)); e ? (x * y)) f by induction (s; d) = (t; e) <ref> [Ada94] </ref> g (s/ ((a + b + d) mod 2); (a + b + d) ffi 2) = (s/ (d fi (x * y)); d ? (x * y)) f equality on pairs g (a + b + d) ffi 2 = d ? (x * y) ^ s/ ((a + <p> + d) ffi 2 = d ? (x * y) ^ s = s ^ (a + b + d) mod 2 = d fi (x * y) f (3.128) and (3.129) see below g true End of Proof In the last hint we used the following identities established in <ref> [Ada94] </ref>: d ? (x * y) = (x + y + d) ffi 2 (3.128) Note that in the inductive step we need to establish that the lemmas that were used in proving the equivalence [Ada94] generalize to ParLists. <p> true End of Proof In the last hint we used the following identities established in <ref> [Ada94] </ref>: d ? (x * y) = (x + y + d) ffi 2 (3.128) Note that in the inductive step we need to establish that the lemmas that were used in proving the equivalence [Ada94] generalize to ParLists. These proofs are omitted in this presentation, since they add little insight into the problem or the ParList theory. 3.5 Summary The ParList notation is an appropriate generalization of the PowerList notation. <p> We 131 address the issue of multidimensional extensions of the three structures in Section 5.2. Adams <ref> [Ada94] </ref> derived and verified two addition circuits in PowerLists in a rigorous manner. We extended his main results to ParLists in Section 3.4, but did not include the proofs of the lemmas that Adams introduced in order to prove the equivalence of the circuits.
Reference: [Ada95] <author> Will E. Adams. </author> <title> Multiplication circuits in powerlists. </title> <type> Unpublished manuscript, </type> <year> 1995. </year>
Reference-contexts: We extended his main results to ParLists in Section 3.4, but did not include the proofs of the lemmas that Adams introduced in order to prove the equivalence of the circuits. Using a similar framework, Adams <ref> [Ada95] </ref> presented a PowerList description of a multiplication circuit. Many basic results of the PowerList theory, as presented in [Mis94], and many of Adam's results have been mechanically verified by Kapur and Subramaniam [KS95, KS96a, KS96b] using the inductive theorem prover Rewrite Rule Laboratory.
Reference: [ANSI90] <author> American National Standard Institute. </author> <title> American National Standard for Information Systems Programming Language Fortran (Fortran 90). ANSI, </title> <address> X3.198 1991 edition, </address> <year> 1990. </year>
Reference-contexts: A significant amount of parallel software is now written in sequential programming languages extended with "parallelism constructs." These constructs allow the programmer to specify how selected portions of the program can be executed in parallel, and how data are assigned to physical processors. Examples of such languages are FORTRAN-90 <ref> [ANSI90] </ref>, C* [RS87], *Lisp [Las86], multiC [Wav92] and many others. The use of such languages is close to an acceptance of Eckert's statement, since the programmer is only trusted with a sequential language. Some compilers are designed with this acceptance in mind.
Reference: [AS96] <author> Klaus Achatz and Wolfram Schulte. </author> <title> Massive parallelization of divide-and-conquer algorithms over powerlists. </title> <booktitle> Science of Computer Programming, </booktitle> <address> 26(1-3):59-78, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: However, as seen in this dissertation, the equal treatment of the two constructors is one of the strengths of the PowerList theory. It is unfortunate that this symmetry does not carry over to automated approaches. 132 In <ref> [AS96] </ref> Aschatz and Schulte present rules to transform PowerList func-tions to programs with sequential work flows, aiming at an efficient implementation on a Wavetracer machine 1 .
Reference: [Bac78] <author> John W. Backus. </author> <title> Can programming be liberated from the von Neumann style? A functional programming style and its algebra of programs. </title> <journal> Communications of the ACM, </journal> <volume> 21(8) </volume> <pages> 613-641, </pages> <month> August </month> <year> 1978. </year>
Reference-contexts: The theories presented in this dissertation have been developed with this goal in mind, while keeping the number of built-in operators to a minimum. Some very convincing arguments for functional parallel programming were made by Backus in his Turing Award lecture <ref> [Bac78] </ref>. Backus proposed the parallel functional language FP, based on the use of second-order functions (functionals, like reduce and map defined for PowerLists in Section 2.1) that manipulate basic functions over linear lists.
Reference: [Bat68] <author> K. Batcher. </author> <title> Sorting networks and their application. </title> <booktitle> In Proceedings of the AFIPS Spring Joint Computer Conference, </booktitle> <volume> volume 32, </volume> <pages> pages 307-314, </pages> <address> Reston, Va, 1968. </address> <publisher> AFIPS Press. </publisher> <pages> 141 </pages>
Reference-contexts: It turns out that this algorithm is difficult to express in PowerList since it does not have a simple recursive description. We start the section by presenting two sorting networks, batcher and bitonic, due to Batcher <ref> [Bat68] </ref> that Misra [Mis94] gave elegant PowerList descriptions of. These descriptions are included to show that the PowerList can be used effectively and elegantly to specify sorting algorithms. We study sorting over a totally ordered domain (M; ). <p> operators " (for maximum) and # (for minimum) are defined by: (8x; y : x; y 2 M : x " y = y x y) (2.100) (8x : x 2 M : ? x ^ x &gt; ) (2.102) In [Mis94] Misra presented two sorting networks due to Batcher <ref> [Bat68] </ref>, the Bitonic sort and the Batcher merge. We present these networks below, using a slightly modified syntax.
Reference: [BCFO91] <author> A. P. W. Bohm, D. C. Cahn, J. T. Feo, and R. R. Oldehoft. </author> <title> SISAL 2.0 reference manual. </title> <type> Technical Report UCRL-MA-109098, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: Sisal was designed to produce efficient implementations; as a result, a number of "features" of other parallel functional language are missing, such as higher order functions and built-in permutations. These features were included in the proposal for a new version of the language <ref> [BCFO91] </ref> that has not yet been implemented. In comparison to PowerList it is interesting to observe that the fundamental data structure in Sisal is non-empty arrays.
Reference: [Bir89] <author> Richard S. Bird. </author> <title> Lectures on constructive functional programming. </title> <editor> In Manfred Broy, editor, </editor> <booktitle> Constructive Methods in Computer Science, NATO ASI Series, </booktitle> <pages> pages 151-216. </pages> <publisher> Springer Verlag, </publisher> <year> 1989. </year>
Reference-contexts: a = b (2.8) p ./ q = u ./ v p = u ^ q = v (2.10) (p j q) ./ (u j v) = (p ./ u) j (q ./ v) (2.12) We often refer to Axiom (2.12) by saying that zip and tie commute (Richard Bird <ref> [Bir89] </ref> calls this property abide). There is no way to directly address a particular element of a PowerList. The only way to access the elements of a PowerList is to break it down using ./ and j as deconstructors, i.e., by using Axioms (2.6) and (2.7). <p> This definition corresponds to linear list theory, which is well-known from sequential, functional languages such as Miranda TM [Tur86], ML [MTH90] and Haskell [HJW + 92], and from the Bird-Meertens theory of lists <ref> [Bir89, BW88, Ski94] </ref>. <p> While Sisal programs are more concise than corresponding Fortran programs, they are not easily amenable to formal proofs of correctness due to extensive use of indexing notations. 5.1.3 Bird-Meertens Formalism The Bird-Meertens formalism <ref> [Bir89, Mee86, Ski94] </ref> has its roots in FP, but is more general since it applies to a number of different categorical data types [Mal90], including linear lists. <p> The functions sum, reduce and map are all exam-ples of homomorphisms. A homomorphism like h above satisfies the following law 3 <ref> [Bir89] </ref>: h = reduce: ffi map:f where f:a = h:[a] (5.2) and can be implemented in time proportional to the logarithm of the length of the list on most parallel architectures [Ski94, Gor96]. The Bird-Meertens formalism is very rich, providing many interesting results about functions over linear lists.
Reference: [Ble89] <author> Guy E. Blelloch. </author> <title> Scans as primitive parallel operations. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-38(11):1526-1538, </volume> <month> November </month> <year> 1989. </year>
Reference-contexts: It is often used as a building block for other parallel algorithms <ref> [Ble89, Ble90, Ble93] </ref>. We will see its use in the specification of the Carry lookahead adder in Chapter 3.
Reference: [Ble90] <author> Guy E. Blelloch. </author> <title> Vector Models for Data-Parallel Computing. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: It is often used as a building block for other parallel algorithms <ref> [Ble89, Ble90, Ble93] </ref>. We will see its use in the specification of the Carry lookahead adder in Chapter 3.
Reference: [Ble93] <author> Guy E. Blelloch. </author> <title> Prefix sums and their applications. </title> <editor> In John H. Reif, editor, </editor> <booktitle> Synthesis of Parallel Algorithms, chapter 1, </booktitle> <pages> pages 33-60. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1993. </year>
Reference-contexts: It is often used as a building block for other parallel algorithms <ref> [Ble89, Ble90, Ble93] </ref>. We will see its use in the specification of the Carry lookahead adder in Chapter 3.
Reference: [Ble95] <author> Guy E. Blelloch. NESL: </author> <title> A nested data-parallel language (version 3.1). </title> <type> Technical Report CMU//CS-95-170, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: For these reasons it would be difficult to prove the kind of properties we have proven in this dissertation. Guy Blelloch developed and implemented the functional programming language NESL <ref> [Ble95] </ref>. The language is based on nested parallelism over linear lists: NESL functions can be applied to lists that may in turn contain lists as elements. PowerLists as presented in [Mis94] do support this notion of nested parallelism. <p> We recognize that these three structures are not the final word in parallel programming. There are classes of computations that only have awkward descriptions in our structures. An example of such a computation is the parallel version of Quicksort <ref> [Ble95] </ref>, where subproblems have different sizes depending on the values in the list to be sorted. However, we hope that we have demonstrated that for computations with regular communication patterns, these structures allow elegant and efficient solutions to be constructed and verified in a rigorous manner. 140
Reference: [Bre74] <author> Richard P. Brent. </author> <title> The parallel evaluation of general arithmetic expressions. </title> <journal> Journal of the ACM, </journal> <volume> 21(2) </volume> <pages> 201-206, </pages> <month> April </month> <year> 1974. </year>
Reference-contexts: Let S:n denote the time complexity of the best known sequential algorithm that solves a problem of size n, and let P:n be the time complexity of the algorithm that we are studying. According to Brent's Scheduling Principle <ref> [Bre74] </ref> P:n S:n=p (1.14) where p is the number of processors used by the parallel algorithm.
Reference: [BW88] <author> Richard Bird and Philip Wadler. </author> <title> Introduction to Functional Programming. </title> <publisher> Prentice Hall International Series in Computer Science. Prentice Hall, </publisher> <year> 1988. </year>
Reference-contexts: When a function name is given with such a number in a hint, it refers to the formula that defines the function. The functional notations we define enjoy the referential transparency property <ref> [BW88] </ref>; that is, variables do not change their values within the context of their definition, and can thus be substituted using a simplified version of the Rule of Leibnitz : (8x; y; f : x; y 2 A ^ f 2 (A ! B) : x = y ) f:x = <p> This definition corresponds to linear list theory, which is well-known from sequential, functional languages such as Miranda TM [Tur86], ML [MTH90] and Haskell [HJW + 92], and from the Bird-Meertens theory of lists <ref> [Bir89, BW88, Ski94] </ref>.
Reference: [Can92] <author> David Cann. </author> <booktitle> Retire Fortran? Communications of the ACM, </booktitle> <volume> 35(8) </volume> <pages> 81-89, </pages> <month> August </month> <year> 1992. </year> <month> 142 </month>
Reference-contexts: The programming language Sisal [MSA + 85] is a functional, parallel program 134 ming language designed for efficient compilations to existing parallel architectures. The goal behind the language is to provide programmers with an alternative to Fortran yielding more efficient implementations than optimizing Fortran compilers can provide <ref> [Can92] </ref>. Sisal is based on the idea of single assignment variables, i.e., a "variable" that is either undefined or, if it attains a value, then its value does not change in the remainder of the computation.
Reference: [CKP + 93] <author> David Culler, Richard Karp, David Patterson, Abhijit Sahay, Klaus Erik Schauser, Eunice Santos, Ramesh Subramonian, and van Eicken Thorsten. </author> <title> LogP: Towards a realistic model of parallel computation. </title> <booktitle> In Proceedings of the Fourth ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming, </booktitle> <pages> pages 1-12, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: A realistic complexity model for parallel algorithms needs to consider the communication costs that are inherent in most architectures. One such proposal is LogP <ref> [CKP + 93] </ref>, that models an architecture abstractly with four parameters to specify: the computing bandwidth, the communication bandwidth, the communication delay, and the efficiency of coupling communication and computation.
Reference: [CLR90] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald E. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> McGraw Hill, </publisher> <year> 1990. </year>
Reference-contexts: This prevents equational reasoning using the "big O" notation. Most good expositions of the notation make cautionary remarks about its use. Cormen, Leiserson and Rivest acknowledge this potential abuse of notation in their textbook <ref> [CLR90] </ref>. They define O as a function that maps natural valued functions to sets of natural valued functions, and state complicated rules to interpret equalities containing O.
Reference: [Col89] <author> Murray Cole. </author> <title> Algorithmic Skeletons: Structured Management of Parallel Computation. </title> <booktitle> Research Monograms in Computer Science. </booktitle> <publisher> MIT press, </publisher> <year> 1989. </year>
Reference-contexts: Their approach is somewhat unusual: they transform PowerList descriptions into an intermediate language based on skeletons <ref> [Col89] </ref>, thereby eliminating most of the structure that is present in the PowerList descriptions. <p> However, most parallel architectures are not hypercubic or hypercube-like. More work is needed to present efficient implementations on common architectures, like the different mesh-based architectures that prevail in the marketplace. One approach, suggested by Cole <ref> [Col89] </ref> in the context of divide and conquer algorithms, is to lay out the computation using H-trees on a 2-dimensional mesh. This layout does not utilize all the processors of the mesh, and thus other strategies need to be pursued in the search for an optimal solution.
Reference: [CT65] <author> James W. Cooley and John W. Tukey. </author> <title> An algorithm for the machine calculation of complex Fourier series. </title> <journal> Mathematics of Computation, </journal> <volume> 19 </volume> <pages> 297-301, </pages> <month> April </month> <year> 1965. </year>
Reference-contexts: The transform maps a sample from a cycle of data points of a periodic signal onto a frequency spectrum representation containing the same number of points. 45 The Fast Fourier Transform is a method to compute the Discrete Fourier Transform made popular by Cooley & Tukey <ref> [CT65] </ref>. Misra [Mis94] derived this algorithm from its definition.
Reference: [CT89] <author> K. M. Chandy and S. Taylor. </author> <title> The composition of parallel programs. </title> <booktitle> In Supercomputing 89, </booktitle> <pages> pages 557-561, </pages> <year> 1989. </year>
Reference-contexts: The key concept in the formalism is a list homomorphism, an algebraic property that a function (say h) over lists has if it "respects" list construction, i.e.: h:(p - q) = h:p h:q (5.1) 2 The concept of single assignment is also used in PCN <ref> [CT89, CT90] </ref>, a notation for parallel composition of sequential programs. 135 for some associative operator . The functions sum, reduce and map are all exam-ples of homomorphisms.
Reference: [CT90] <author> K Mani Chandy and Stephen Taylor. </author> <title> Primer for program composition notation. </title> <type> Technical Report CS-TR-90-10, </type> <institution> California Institute of Technology, </institution> <year> 1990. </year>
Reference-contexts: The key concept in the formalism is a list homomorphism, an algebraic property that a function (say h) over lists has if it "respects" list construction, i.e.: h:(p - q) = h:p h:q (5.1) 2 The concept of single assignment is also used in PCN <ref> [CT89, CT90] </ref>, a notation for parallel composition of sequential programs. 135 for some associative operator . The functions sum, reduce and map are all exam-ples of homomorphisms.
Reference: [Dem56] <author> Howard B. Demuth. </author> <title> Electronic Data Sorting. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1956. </year>
Reference-contexts: At even steps, we perform the same operation for cells 2 and 3, 4 and 5, etc." 4 As a parallel sorting technique the odd-even sort is well established in the literature <ref> [Sew54, Dem56] </ref>. Knuth [Knu73, exercise 5.3.4.37] poses its proof of correctness as an exercise. 48 In contrast to Batcher's networks, the odd-even sort is iterative in nature and does not have a simple definition in the PowerList notation.
Reference: [DNS81] <author> E. Dekel, D. Nassimi, and S. Sahni. </author> <title> Parallel matrix and graph algorithms. </title> <journal> SIAM Journal on Computing, </journal> <volume> 10(4) </volume> <pages> 657-675, </pages> <year> 1981. </year>
Reference-contexts: Some simple matrix algorithms have elegant descriptions in the higher dimension extensions of PowerList; for example, we have descriptions of different versions of matrix multiplication: the standard divide and conquer technique, the Strassen algorithm [Str69] and the hypercube algorithm by Dekel, Nassimi and Sahni <ref> [DNS81] </ref>. The latter algorithm is described using an extended version of PowerLists in [Kor94]. 5.3 Final Comments The three data structures we presented were useful in expressing parallel computations. Equally important was the use of formal techniques to derive many of these descriptions from their specifications.
Reference: [DS90] <author> Edsger W. Dijkstra and Carel S. Sholten. </author> <title> Predicate Calculus and Program Semantics. </title> <publisher> Springer Verlag, </publisher> <year> 1990. </year> <month> 143 </month>
Reference-contexts: group the operators have the same binding power: 4 A function like ParList is often called a type constructor [MTH90]. 8 : G G fl . / ffi - ) ( ! 1.2.3 Notation and Proof Style We will use a notation similar to that presented by Dijkstra and Scholten <ref> [DS90] </ref>, which includes writing function application by an infix, left associative dot "." operator; for example, f:x denotes the value returned by the function f when applied to the argument x . <p> context of their definition, and can thus be substituted using a simplified version of the Rule of Leibnitz : (8x; y; f : x; y 2 A ^ f 2 (A ! B) : x = y ) f:x = f:y ) (1.2) Above we used the quantified notation from <ref> [DS90] </ref> where the dummies are x, y, f , the range is x; y 2 A ^ f 2 (A ! B) and the term is x = y ) f:x = f:y.
Reference: [Eck46] <author> J. P. Eckert, Jr. </author> <title> A parallel channel computing machine. </title> <editor> In H. H. Golds--tine, H. A. Aitken, A. W. Burks, Jr. J.P. Eckert, J B. Mauchly, and J. von Neumann, editors, </editor> <booktitle> The Moore School Lectures. </booktitle> <institution> The Moore School, University of Pennsylvania, </institution> <year> 1946. </year> <title> Reprinted as The Moore School Lectures, </title> <booktitle> lecture 45, in volume 9 of the Charles Babbage Institute Reprint Series for the History of Computing, </booktitle> <publisher> by MIT Press and Tomash Publishers, </publisher> <year> 1986. </year>
Reference-contexts: It has been shown over and over again that any departure from this procedure results in a system which is far too complicated to use." The above statement was made by J. P. Eckert, Jr. in 1946 <ref> [Eck46] </ref> (as cited in [Kel89]) in an argument for parallel data transfer and arithmetic in the computers of the EDVAC's generation. The statement gave a rather pessimistic outlook for the spread of parallel programming as performed by the operator.
Reference: [Gam97] <author> Ruben A. Gamboa. </author> <title> Defthms about zip and tie: Reasoning about pow-erlists in ACL2. </title> <type> Technical Report CS-TR-97-02, </type> <institution> The University of Texas at Austin, Department of Computer Sciences, </institution> <month> January 23 </month> <year> 1997. </year>
Reference-contexts: Many basic results of the PowerList theory, as presented in [Mis94], and many of Adam's results have been mechanically verified by Kapur and Subramaniam [KS95, KS96a, KS96b] using the inductive theorem prover Rewrite Rule Laboratory. Gamboa <ref> [Gam97] </ref> has verified many fundamental results about PowerLists using the ACL2 theorem prover. His work focuses on the verification of Batcher's sorting networks as found in [Mis94]. The use of mechanical verification has been valuable for the PowerList research.
Reference: [Gor96] <author> Sergei Gorlatch. </author> <title> Systematic efficient parallelization of scan and other list homomorphisms. </title> <editor> In Luc Bouge et al., editor, </editor> <booktitle> Proceedings of Euro-Par'96, number 1124 in LNCS, </booktitle> <pages> pages 401-408. </pages> <publisher> Springer Verlag, </publisher> <year> 1996. </year>
Reference-contexts: A homomorphism like h above satisfies the following law 3 [Bir89]: h = reduce: ffi map:f where f:a = h:[a] (5.2) and can be implemented in time proportional to the logarithm of the length of the list on most parallel architectures <ref> [Ski94, Gor96] </ref>. The Bird-Meertens formalism is very rich, providing many interesting results about functions over linear lists. Most of these results can be reused in the theories we presented in this dissertation, since the data structures can be viewed as linear lists by ignoring the way they were constructed. <p> However, such a high level of abstraction may also deter the programmer from coming up with efficient solutions since most reasoning is done with higher order functions. Gorlatch <ref> [Gor96] </ref> adapted the Bird-Meertens formalism towards PowerLists by restricting list concatenation to lists of the same length. He categorized a class of functions called distributable homomorphisms that includes the prefix sum.
Reference: [Gra53] <author> Frank Gray. </author> <title> Pulse code communication. </title> <type> U.S. Patent 2,632,058, </type> <year> 1953. </year>
Reference-contexts: Frank Gray to lower the data loss when transmitting signals across noisy wires. The coding was patented by his employer, Bell Labs, in 1953 <ref> [Gra53] </ref>. The reflected Gray coding of a PowerList permutes the elements in such a way that neighboring elements in the original PowerList are placed in positions of the coded PowerList whose indices written as a binary string only differ in one position.
Reference: [HJW + 92] <editor> Paul Hudak, Simon L. Peyton Jones, Philip Wadler, et al. </editor> <title> A report on the functional language Haskell. </title> <journal> SIGPLAN Notices, </journal> <year> 1992. </year>
Reference-contexts: In (3.1) a is the first element of v and b is the last element of v. This definition corresponds to linear list theory, which is well-known from sequential, functional languages such as Miranda TM [Tur86], ML [MTH90] and Haskell <ref> [HJW + 92] </ref>, and from the Bird-Meertens theory of lists [Bir89, BW88, Ski94].
Reference: [Ive62] <author> Kenneth E. Iverson. </author> <title> A Programming Language. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1962. </year>
Reference-contexts: These skeleton descriptions are then transformed into the programming language multiC [Wav92] that can be compiled for the Wavetracer architecture. 5.1.2 Functional Parallel Programming Iverson developed the programming language APL <ref> [Ive62] </ref> based on the idea of applying a single operation to each element of a data structure. APL is a rich language with many operators that allow complex algorithms to be expressed succinctly.
Reference: [JaJ92] <author> Joseph JaJa. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1992. </year>
Reference-contexts: :: f:n + c)) ) f O id (1.11) (9c : c 2 Nat : f . (n :: c)) ( f O one (1.13) 1.3.1 Parallel Algorithm Complexity To motivate the cost calculus we introduce some basic concepts from parallel algorithm complexity theory as presented in the literature (e.g., <ref> [KR90, JaJ92] </ref>). Assume 14 that we are studying a parallel algorithm that solves a particular problem, parame--terizable by the size of the input n. <p> We have H:cube ps O id (2.62) through a similar derivation as was performed for sum in Section 2.3. The algorithm cube ps is well known in the literature <ref> [MP89, JaJ92] </ref>, and is considered as part of the folklore; its close connection to the algorithm by Ladner and Fischer is interesting. 2.5 Mapping PowerLists Onto Hypercubes So far we have studied the standard encoding of PowerLists onto hypercubes.
Reference: [JH95] <author> S. Lennart Johnsson and Ching-Tien Ho. </author> <title> On the conversion between binary code and binary-reflected gray code on binary cubes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 44(1) </volume> <pages> 47-53, </pages> <month> January </month> <year> 1995. </year> <month> 144 </month>
Reference-contexts: ./ v)) = (gray:p ./ v) ./ (gray:q ./ u) (2.66) The inverse function of gray is yarg, defined by: yarg:hai = hai (2.67) yarg:(u j v) = yarg:u j rev:(yarg:v) (2.68) 3 The proof of a more general complexity result, presented in a different formalism, can be found in <ref> [JH95] </ref>. 2.5.1 The Gray Coded Operators Next we study how operators in the PowerList notation can be implemented in the Gray coded domain.
Reference: [JS90] <author> Geraint Jones and Mary Sheeran. </author> <title> Circuit design in Ruby. </title> <editor> In Jtrgen Staunstrup, editor, </editor> <title> Formal Methods for VLSI Design, </title> <booktitle> IFIP WG 10.5 Lecture Notes, chapter 1, </booktitle> <pages> pages 13-70. </pages> <publisher> North-Holland, </publisher> <year> 1990. </year>
Reference-contexts: It can be shown [Sch90] that a normal hypercube algorithm g can be simulated with a constant slowdown on a butterfly (and thus on a CCC): g is normal ) B:g O H:g Ruby Ruby <ref> [JS90] </ref> is a relational algebra, developed by Jones and Sheeran for designing integrated circuits at a high level. The goal of Ruby is to algebraically specify the layout of the wires that connect computational elements.
Reference: [JS91] <author> Geraint Jones and Mary Sheeran. </author> <title> Collecting butterflies. </title> <type> Technical Monograph PRG-91, </type> <institution> Oxford University, </institution> <month> February </month> <year> 1991. </year>
Reference-contexts: The PowerList constructors can be found in Ruby as predefined relations. They are not given any special treatment; instead they are considered part of a "tool box" available to the circuit designer. In <ref> [JS91] </ref> Jones and Sheeran present recursive descriptions in Ruby of the Butterfly network, the Fast Fourier Transform algorithm, and Batcher's sorting networks.
Reference: [Kap94] <author> D. Kapur. </author> <title> Constructors can be partial too. </title> <type> Technical Report 94-16, </type> <institution> SUNY Buffalo, </institution> <year> 1994. </year>
Reference-contexts: This rigor is achieved by the use of theorem provers which require that all data structures and applied methods be axiomatized before a proof that utilizes them can be completed. The PowerList data structure has been an interesting challenge for the theorem-proving community <ref> [Kap94] </ref>. The constructors are partial, since they require that their arguments have the same length, and a non-singleton PowerList can be constructed using either ./ and j. Another complication for automated theorem provers posed by the PowerList theory is the use of two constructors.
Reference: [Kel89] <author> Paul Kelly. </author> <title> Functional Programming for Loosely-Coupled Multiprocessors. </title> <booktitle> Research Monograms in Computer Science. </booktitle> <publisher> MIT press, </publisher> <year> 1989. </year>
Reference-contexts: It has been shown over and over again that any departure from this procedure results in a system which is far too complicated to use." The above statement was made by J. P. Eckert, Jr. in 1946 [Eck46] (as cited in <ref> [Kel89] </ref>) in an argument for parallel data transfer and arithmetic in the computers of the EDVAC's generation. The statement gave a rather pessimistic outlook for the spread of parallel programming as performed by the operator.
Reference: [Knu73] <author> Donald E. Knuth. </author> <title> The Art of Computer Programming, Vol. 3 : Sorting and Searching. </title> <booktitle> Series in Computer Science and Information Processing. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, </address> <year> 1973. </year>
Reference-contexts: The 0-1 principle is often attributed to Knuth <ref> [Knu73] </ref>, where Batcher's networks are also presented. 2.7.1 Odd-even Sort in PowerLists We will study the odd-even sort which can be considered a parallel version of bubble sort ; it is simple to implement and to explain operationally, yet it is inefficient and somewhat tedious to prove correct 4 . <p> At even steps, we perform the same operation for cells 2 and 3, 4 and 5, etc." 4 As a parallel sorting technique the odd-even sort is well established in the literature [Sew54, Dem56]. Knuth <ref> [Knu73, exercise 5.3.4.37] </ref> poses its proof of correctness as an exercise. 48 In contrast to Batcher's networks, the odd-even sort is iterative in nature and does not have a simple definition in the PowerList notation.
Reference: [Kor94] <author> Jacob Kornerup. </author> <title> Mapping powerlists onto hypercubes. </title> <type> Technical Report CS-TR-94-05, </type> <institution> University of Texas at Austin, Department of Computer Sciences, </institution> <month> August </month> <year> 1994. </year> <note> Available for download as ftp://ftp.cs.utexas.edu/pub/techreports/tr94-05.ps.Z. </note>
Reference-contexts: We provide a cost calculus that allows us to quantify the time that implementations of the PowerList notation may take on particular parallel architectures and show an efficient mapping of the PowerList operators to hypercubes <ref> [Kor94, Kor95] </ref>. <p> The latter algorithm is described using an extended version of PowerLists in <ref> [Kor94] </ref>. 5.3 Final Comments The three data structures we presented were useful in expressing parallel computations. Equally important was the use of formal techniques to derive many of these descriptions from their specifications.
Reference: [Kor95] <author> Jacob Kornerup. </author> <title> Mapping a functional notation for parallel programs onto hypercubes. </title> <journal> Information Processing Letters, </journal> <volume> 53 </volume> <pages> 153-158, </pages> <year> 1995. </year>
Reference-contexts: We provide a cost calculus that allows us to quantify the time that implementations of the PowerList notation may take on particular parallel architectures and show an efficient mapping of the PowerList operators to hypercubes <ref> [Kor94, Kor95] </ref>.
Reference: [Kor97a] <author> Jacob Kornerup. </author> <title> Odd-even sort in powerlists. </title> <journal> Information Processing Letters, </journal> <volume> 61 </volume> <pages> 15-24, </pages> <year> 1997. </year>
Reference-contexts: Finally, we study how different sorting algorithms can be expressed in the PowerList notation, focusing on a derivation of the odd-even transposition sort <ref> [Kor97a, Kor97c] </ref>. 2.1 Introduction Functional programming languages typically employ lists where the basic constructors (adding or removing a single element) allow for sequential processing of the list elements. The PowerList notation [Mis94] uses balanced division of lists in order to allow for parallel processing.
Reference: [Kor97b] <author> Jacob Kornerup. </author> <title> Parlists a generalization of powerlists. </title> <editor> In Christian Lengauer, editor, </editor> <booktitle> Proceedings of Euro-Par'97, </booktitle> <publisher> LNCS. Springer Verlag, </publisher> <year> 1997. </year> <note> To appear. 145 </note>
Reference-contexts: Functions over ParLists are defined using structural induction over the data structure, by a base case for singleton ParLists and two inductive cases: one for even length and one for odd length ParLists. An earlier version of this work was presented in <ref> [Kor97b] </ref> and [Kor97c] based on ideas from my advisor, Jayadev Misra [Mis96]. <p> ./ q) = (u ./ v)/ b f introduce symmetry on right-hand side with Axiom (3.12) g c .(a .(p ./ q)) = c .(u ./ v)/ b f Axiom (3.26) and Axiom (3.25) g 2 The axiom set above is simpler and more expressive than the one found in <ref> [Kor97b, Kor97c] </ref> where (3.24), (3.25) and (3.26) were replaced by (3.27), (3.30) and (3.31). 67 c .p ./ a .q = c .v ./ u/ b f Axioms (3.11) and (3.12) g p = v ^ a .q = u/ b Proof of (3.28) p/ a ./ q/ b = ((p
Reference: [Kor97c] <author> Jacob Kornerup. </author> <title> Parlists a generalization of powerlists (extended ver-sion). </title> <type> Technical Report CS-TR-97-15, </type> <institution> University of Texas at Austin, Department of Computer Sciences, </institution> <month> June </month> <year> 1997. </year> <note> Available for download as ftp://ftp.cs.utexas.edu/pub/techreports/tr97-15.ps.Z. </note>
Reference-contexts: Finally, we study how different sorting algorithms can be expressed in the PowerList notation, focusing on a derivation of the odd-even transposition sort <ref> [Kor97a, Kor97c] </ref>. 2.1 Introduction Functional programming languages typically employ lists where the basic constructors (adding or removing a single element) allow for sequential processing of the list elements. The PowerList notation [Mis94] uses balanced division of lists in order to allow for parallel processing. <p> Functions over ParLists are defined using structural induction over the data structure, by a base case for singleton ParLists and two inductive cases: one for even length and one for odd length ParLists. An earlier version of this work was presented in [Kor97b] and <ref> [Kor97c] </ref> based on ideas from my advisor, Jayadev Misra [Mis96]. <p> ./ q) = (u ./ v)/ b f introduce symmetry on right-hand side with Axiom (3.12) g c .(a .(p ./ q)) = c .(u ./ v)/ b f Axiom (3.26) and Axiom (3.25) g 2 The axiom set above is simpler and more expressive than the one found in <ref> [Kor97b, Kor97c] </ref> where (3.24), (3.25) and (3.26) were replaced by (3.27), (3.30) and (3.31). 67 c .p ./ a .q = c .v ./ u/ b f Axioms (3.11) and (3.12) g p = v ^ a .q = u/ b Proof of (3.28) p/ a ./ q/ b = ((p <p> = (p u) ./ (q v) (3.36) As alternatives to (3.35) and (3.36) we could have chosen (3.37) and (3.38) as they are interchangeable: (p/ a) (q/ b) = (p q)/ (a b) (3.37) The proofs that (3.37) and (3.38) follows from (3.34), (3.35) and (3.36) can be found in <ref> [Kor97c] </ref>. 3.1.2 Induction Principle for ParList A ParList p with elements from the type X (i.e., p 2 ParLists:X) can be deconstructed uniquely into an ordered sequence of its elements; this can be achieved by building a constructor tree for p. <p> A longer proof that does not use (3.43) can be found in <ref> [Kor97c] </ref>. 3.1.4 Data Movement Functions In this section we define operators and functions that move elements within a ParList. The operators ! and are used in defining the odd-even sort in Section 3.3, and in defining the prefix sum.
Reference: [KR90] <author> Richard M. Karp and Vijaya Ramachandran. </author> <title> Parallel algorithms for shared memory machines. </title> <editor> In Jan van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume A. </booktitle> <publisher> Elsevier North-Holland, </publisher> <year> 1990. </year>
Reference-contexts: :: f:n + c)) ) f O id (1.11) (9c : c 2 Nat : f . (n :: c)) ( f O one (1.13) 1.3.1 Parallel Algorithm Complexity To motivate the cost calculus we introduce some basic concepts from parallel algorithm complexity theory as presented in the literature (e.g., <ref> [KR90, JaJ92] </ref>). Assume 14 that we are studying a parallel algorithm that solves a particular problem, parame--terizable by the size of the input n.
Reference: [KS95] <author> D. Kapur and M. Subramaniam. </author> <title> Automated reasoning about parallel algorithms using powerlists. </title> <editor> In Vangalur S. Alagar and M. Nivat, editors, </editor> <booktitle> AMAST '95, volume 936 of LNCS, </booktitle> <pages> page 416. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Using a similar framework, Adams [Ada95] presented a PowerList description of a multiplication circuit. Many basic results of the PowerList theory, as presented in [Mis94], and many of Adam's results have been mechanically verified by Kapur and Subramaniam <ref> [KS95, KS96a, KS96b] </ref> using the inductive theorem prover Rewrite Rule Laboratory. Gamboa [Gam97] has verified many fundamental results about PowerLists using the ACL2 theorem prover. His work focuses on the verification of Batcher's sorting networks as found in [Mis94].
Reference: [KS96a] <author> D. Kapur and M. Subramaniam. </author> <title> Automating induction over mutually recursive functions. </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <address> 1101:117, </address> <year> 1996. </year>
Reference-contexts: Using a similar framework, Adams [Ada95] presented a PowerList description of a multiplication circuit. Many basic results of the PowerList theory, as presented in [Mis94], and many of Adam's results have been mechanically verified by Kapur and Subramaniam <ref> [KS95, KS96a, KS96b] </ref> using the inductive theorem prover Rewrite Rule Laboratory. Gamboa [Gam97] has verified many fundamental results about PowerLists using the ACL2 theorem prover. His work focuses on the verification of Batcher's sorting networks as found in [Mis94].
Reference: [KS96b] <author> D. Kapur and M. Subramaniam. </author> <title> Mechanically verifying a family of multiplier circuits. </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <address> 1102:135, </address> <year> 1996. </year>
Reference-contexts: Using a similar framework, Adams [Ada95] presented a PowerList description of a multiplication circuit. Many basic results of the PowerList theory, as presented in [Mis94], and many of Adam's results have been mechanically verified by Kapur and Subramaniam <ref> [KS95, KS96a, KS96b] </ref> using the inductive theorem prover Rewrite Rule Laboratory. Gamboa [Gam97] has verified many fundamental results about PowerLists using the ACL2 theorem prover. His work focuses on the verification of Batcher's sorting networks as found in [Mis94].
Reference: [Las86] <author> Clifford Lasser. </author> <title> The essential *lisp manual. </title> <type> Technical report, </type> <institution> Thinking Machines Corporation, </institution> <address> Cambridge, MA, </address> <month> July </month> <year> 1986. </year>
Reference-contexts: Examples of such languages are FORTRAN-90 [ANSI90], C* [RS87], *Lisp <ref> [Las86] </ref>, multiC [Wav92] and many others. The use of such languages is close to an acceptance of Eckert's statement, since the programmer is only trusted with a sequential language. Some compilers are designed with this acceptance in mind.
Reference: [Lei92] <author> Frank Thomson Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays * Trees * Hypercubes. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA 94403, </address> <year> 1992. </year>
Reference-contexts: We note that the diameter (maximum distance between any two nodes) is n. The hypercube topology is very versatile, and many topologies can be embedded in the hypercube; Leighton <ref> [Lei92] </ref> shows a number of these embeddings. 2 For a specific permutation function it is straightforward to establish that the the lemma applies. <p> The algorithm consists of a sequence of phases, where each phase consists of an "even" step followed by an "odd" step. It is often described operationally as follows <ref> [Lei92] </ref>: "At odd steps, we compare the contents of cells 1 and 2, 3 and 4, etc., exchanging values if necessary so that the smaller value ends up in the leftmost cell. <p> The n incident edges to a hypercube node are assigned in their dimensional order to the nodes in the corresponding ring on the CCC. Thus, each node on the CCC has degree 3. The CCC and the butterfly networks have very similar topologies <ref> [Lei92] </ref> and both can simulate hypercube algorithms efficiently.
Reference: [LF80] <author> Richard E. Ladner and Michael J. Fischer. </author> <title> Parallel prefix computation. </title> <journal> Journal of the ACM, </journal> <volume> 27(4) </volume> <pages> 831-838, </pages> <month> October </month> <year> 1980. </year>
Reference-contexts: We define the function ps : PowerList:Y:n ! PowerList:Y:n to realize a well known algorithm for computing the prefix sum due to Ladner and Fischer <ref> [LF80] </ref>. This algorithm has roots in an algorithm presented by Ofman [Ofm63] and later implemented on a perfect shu*e network by Stone [Sto71].
Reference: [Mal90] <author> Grant Malcolm. </author> <title> Algebraic Data Types and Program Transformation. </title> <type> PhD thesis, </type> <institution> Rijkuniversiteit Groeningen, </institution> <month> September </month> <year> 1990. </year> <month> 146 </month>
Reference-contexts: than corresponding Fortran programs, they are not easily amenable to formal proofs of correctness due to extensive use of indexing notations. 5.1.3 Bird-Meertens Formalism The Bird-Meertens formalism [Bir89, Mee86, Ski94] has its roots in FP, but is more general since it applies to a number of different categorical data types <ref> [Mal90] </ref>, including linear lists. In the following we present a simple version of the formalism based on linear lists (constructed with the concatenation operator - ), basic functions and higher order functions.
Reference: [McC91] <author> William F. McColl. </author> <title> General purpose parallel computing. </title> <editor> In A. M. Gib--bons and P. Spirakis, editors, </editor> <booktitle> Lectures on Parallel Computation, Spring School on Parallel Computation, </booktitle> <pages> pages 337-391. </pages> <address> ALCOM, </address> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: Degree the maximal number of edges incident to a node. The lower the degree the easier it is to physically realize the design in hardware. There are many different proposals for topologies for parallel architectures, among them are (from <ref> [McC91] </ref>): Topology Degree Diameter 1D array (ring) 2 p=2 Shu*e-exchange 3 2 fl log p Cube-connected-cycles 3 (5=2) fl log p 2D mesh of trees 3 2 fl log p 3D mesh of trees 3 2 fl log p 2D array (toroidal) 4 p Butterfly (wrapped) 4 2 fl log p
Reference: [Mee86] <author> Lambert Meertens. </author> <title> Algorithmics towards programming as a mathematical activity. </title> <booktitle> In CWI Symposium on mathematics and Computer Science, </booktitle> <pages> pages 289-334. </pages> <publisher> North-Holland, </publisher> <year> 1986. </year>
Reference-contexts: While Sisal programs are more concise than corresponding Fortran programs, they are not easily amenable to formal proofs of correctness due to extensive use of indexing notations. 5.1.3 Bird-Meertens Formalism The Bird-Meertens formalism <ref> [Bir89, Mee86, Ski94] </ref> has its roots in FP, but is more general since it applies to a number of different categorical data types [Mal90], including linear lists.
Reference: [MH88] <author> Zhijing G. Mou and Paul Hudak. </author> <title> An algebraic model for divide-and-conquer and its parallelism. </title> <journal> The Journal of Supercomputing, </journal> <volume> 2(3) </volume> <pages> 257-278, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: Parallelism in FP is introduced by evaluating the second order functions in parallel. Mou and Hudak <ref> [MH88, Mou90] </ref> presented Divacon, a very general functional notation for describing divide-and-conquer programs. The Divacon notation is meant to capture the entire class of divide-and-conquer algorithms. The emphasis of their work is to implement divide-and-conquer descriptions efficiently on parallel architectures, and to demonstrate that these implementations are efficient.
Reference: [Mis94] <author> Jayadev Misra. Powerlist: </author> <title> A structure for parallel recursion. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 16(6) </volume> <pages> 1737-1767, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: For our purposes such a model is too complex, since we want to avoid working with architectures at this level of detail. 19 Chapter 2 Powerlists In this chapter we present the PowerList data structure and its theory <ref> [Mis94] </ref> illustrated with examples of parallel algorithms expressed as functions over PowerList. We provide a cost calculus that allows us to quantify the time that implementations of the PowerList notation may take on particular parallel architectures and show an efficient mapping of the PowerList operators to hypercubes [Kor94, Kor95]. <p> The PowerList notation <ref> [Mis94] </ref> uses balanced division of lists in order to allow for parallel processing. A PowerList is a linear data structure whose elements are all of the same data type. The length of a PowerList is always a power of two. <p> For example, if is addition over the integers we have: ps:h3 2 0 5i = h3 5 5 10i More formally, the prefix sum of a PowerList p, where p 2 PowerList:Y:n and the data type Y has the property that (Y; +; 0) is a monoid, can be defined <ref> [Mis94] </ref> as the (unique) solution to the equation (in u): u = (0!u) p (2.57) A proof that (2.57) has a unique solution can be found in [Ada94]. <p> We define the function ps : PowerList:Y:n ! PowerList:Y:n to realize a well known algorithm for computing the prefix sum due to Ladner and Fischer [LF80]. This algorithm has roots in an algorithm presented by Ofman [Ofm63] and later implemented on a perfect shu*e network by Stone [Sto71]. Misra <ref> [Mis94] </ref> derived the algorithm for PowerLists; we show a slightly different derivation below: u ./ v = f define u ./ v := ps:(p ./ q) g ps:(p ./ q) = f defining equation for ps (2.57) g 0!ps:(p ./ q) p ./ q = f definition of u; v g <p> of Proof Since each of the Gray coded operators have efficient implementations, we have ob tained an efficient implementation of Ladner and Fischer's algorithm for hypercubic architectures. 2.6 Fast Fourier Transform In this section we present the Discrete Fast Fourier Transform algorithm as it was derived for PowerList by Misra <ref> [Mis94] </ref>. The succinctness of the PowerList description illustrates the expressive power of having both ./ and j in the PowerList notation. The Discrete Fourier Transform is an important tool used in many scientific applications, especially in digital signal processing. <p> The transform maps a sample from a cycle of data points of a periodic signal onto a frequency spectrum representation containing the same number of points. 45 The Fast Fourier Transform is a method to compute the Discrete Fourier Transform made popular by Cooley & Tukey [CT65]. Misra <ref> [Mis94] </ref> derived this algorithm from its definition. <p> It turns out that this algorithm is difficult to express in PowerList since it does not have a simple recursive description. We start the section by presenting two sorting networks, batcher and bitonic, due to Batcher [Bat68] that Misra <ref> [Mis94] </ref> gave elegant PowerList descriptions of. These descriptions are included to show that the PowerList can be used effectively and elegantly to specify sorting algorithms. We study sorting over a totally ordered domain (M; ). <p> maximum element &gt; and that the symmetric and associative operators " (for maximum) and # (for minimum) are defined by: (8x; y : x; y 2 M : x " y = y x y) (2.100) (8x : x 2 M : ? x ^ x &gt; ) (2.102) In <ref> [Mis94] </ref> Misra presented two sorting networks due to Batcher [Bat68], the Bitonic sort and the Batcher merge. We present these networks below, using a slightly modified syntax. <p> Properties of PowerLists can be proven using a simple induction principle that closely mimics how PowerList functions are defined. We derived Ladner and Fischer's algorithm and an efficient hypercube 6 We take no credit for the PowerList description of these algorithms, they were originally presented in <ref> [Mis94] </ref>. 60 algorithm for prefix sum from their specifications using equational reasoning over PowerList. We established the close connection between the PowerList notation and hy-percubic architectures. Using the Gray coded mapping, we obtained efficient implementations of PowerList functions on hypercubic architectures. <p> End Remark 3.1.1 Axioms In the following, we extend the axioms of the PowerList theory <ref> [Mis94] </ref> to an axiomatization of the ParList algebra. <p> Finally, we present work that is related to PowerLists, but use a different approach. 5.1.1 PowerLists The work presented in this dissertation is an extension of the work done on PowerLists developed by Misra. Misra <ref> [Mis94] </ref> presented the PowerList theory along with a number of fundamental parallel algorithms, such as Batcher's two sorting networks, the Fast Fourier Transform and two algorithms for the Prefix Sum; Misra also presented a theory for generalizing the notation to multidimensional PowerLists. <p> Using a similar framework, Adams [Ada95] presented a PowerList description of a multiplication circuit. Many basic results of the PowerList theory, as presented in <ref> [Mis94] </ref>, and many of Adam's results have been mechanically verified by Kapur and Subramaniam [KS95, KS96a, KS96b] using the inductive theorem prover Rewrite Rule Laboratory. Gamboa [Gam97] has verified many fundamental results about PowerLists using the ACL2 theorem prover. <p> Gamboa [Gam97] has verified many fundamental results about PowerLists using the ACL2 theorem prover. His work focuses on the verification of Batcher's sorting networks as found in <ref> [Mis94] </ref>. The use of mechanical verification has been valuable for the PowerList research. Many of the basic properties of PowerLists have been mechanically verified in a more rigorous way than in the original proofs generated by humans. <p> Guy Blelloch developed and implemented the functional programming language NESL [Ble95]. The language is based on nested parallelism over linear lists: NESL functions can be applied to lists that may in turn contain lists as elements. PowerLists as presented in <ref> [Mis94] </ref> do support this notion of nested parallelism. NESL lists are dynamic in length, and in contrast with PowerLists there are no restrictions on the lengths of lists that are returned from functions. <p> In [JS91] Jones and Sheeran present recursive descriptions in Ruby of the Butterfly network, the Fast Fourier Transform algorithm, and Batcher's sorting networks. These descriptions were derived using geometrical considerations and are more complex than the corresponding PowerList descriptions given by Misra <ref> [Mis94] </ref>. 5.2 Future Work PowerList In Chapter 2 we established that many PowerList functions can be implemented efficiently on hypercubic architectures. However, most parallel architectures are not hypercubic or hypercube-like. <p> This enables us to describe matrix computations, using a similar approach to the one presented in this dissertation. Misra <ref> [Mis94] </ref> presented an outline of this idea for PowerList. Preliminary results using these extensions appear promising for the other data structures as well.
Reference: [Mis96] <author> Jayadev Misra. </author> <title> Generalized powerlists. </title> <type> Unpublished manuscript, </type> <month> May </month> <year> 1996. </year>
Reference-contexts: An earlier version of this work was presented in [Kor97b] and [Kor97c] based on ideas from my advisor, Jayadev Misra <ref> [Mis96] </ref>.
Reference: [MK97] <author> Jayadev Misra and Jacob Kornerup. </author> <title> Describing structures of interconnection networks. </title> <note> In preparation, </note> <year> 1997. </year>
Reference-contexts: We illustrate the PList notation by specifying three generalized connection networks and proving that these network are isomorphic. This work is joint work with my advisor Jayadev Misra <ref> [MK97] </ref>. Note on Notation We use square brackets to denote ordered quantification in the PList algebra. The expression [./ i : i 2 n : p:i] is a closed form for the application of the n-ary operator ./ applied to the PLists p:i in order.
Reference: [Mou90] <author> Zhijing G. Mou. </author> <title> A Formal Model for Divide-and-Conquer and Its Parallel Realization. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Yale University, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: Parallelism in FP is introduced by evaluating the second order functions in parallel. Mou and Hudak <ref> [MH88, Mou90] </ref> presented Divacon, a very general functional notation for describing divide-and-conquer programs. The Divacon notation is meant to capture the entire class of divide-and-conquer algorithms. The emphasis of their work is to implement divide-and-conquer descriptions efficiently on parallel architectures, and to demonstrate that these implementations are efficient.
Reference: [MP89] <author> Ernst W. Mayr and Greg Plaxton. </author> <title> Pipelined parallel computations, and sorting on a pipelined hypercube. </title> <type> Technical Report STAN-CS-89-1261, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1989. </year>
Reference-contexts: We have H:cube ps O id (2.62) through a similar derivation as was performed for sum in Section 2.3. The algorithm cube ps is well known in the literature <ref> [MP89, JaJ92] </ref>, and is considered as part of the folklore; its close connection to the algorithm by Ladner and Fischer is interesting. 2.5 Mapping PowerLists Onto Hypercubes So far we have studied the standard encoding of PowerLists onto hypercubes.
Reference: [MS97] <author> M. Douglas McIlroy and Joseph P. Savicki. </author> <title> Routing and complexity of rearrangeable networks. </title> <type> Personal Communication, </type> <year> 1997. </year> <month> 147 </month>
Reference-contexts: It includes the PowerList theory as a special case. While this generality is not always needed in order to describe parallel computations, it may prove useful when the problem is stated in a different radix than 4 This work was inspired by a paper by McIlroy and Savicki <ref> [MS97] </ref> where similar results were proven using index-based notations. 129 2, or in a mixed radix as in the case of the generalized networks discussed in this chapter. 130 Chapter 5 Conclusion We start this chapter by surveying related research and comparing it to the work presented in this dissertation.
Reference: [MSA + 85] <author> James McGraw, Stephen Skezielewski, Stephen Allan, Rod Oldehoeft, John Glauert, Chris Kirkham, and Robert Thomas. </author> <title> SISAL: Streams and Iterations in a Single Assignment Language. </title> <institution> Lawrence Livermore National Laboratory, </institution> <note> Reference manual version 1.2. manual M-146, Rev. 1 edition, </note> <month> March </month> <year> 1985. </year>
Reference-contexts: NESL was designed to produce efficient implementations of parallel algorithms on actual architectures and to reason about their theoretical complexity measures. Little consideration was given to providing a framework to prove NESL programs correct. The programming language Sisal <ref> [MSA + 85] </ref> is a functional, parallel program 134 ming language designed for efficient compilations to existing parallel architectures. The goal behind the language is to provide programmers with an alternative to Fortran yielding more efficient implementations than optimizing Fortran compilers can provide [Can92]. <p> This layout does not utilize all the processors of the mesh, and thus other strategies need to be pursued in the search for an optimal solution. Another approach to implementing PowerList, as well as ParLists and PLists, is to map the functions to Sisal programs <ref> [MSA + 85] </ref>. This approach has the advantage that Sisal has efficient implementations on many parallel architectures. ParList The issue of efficient implementations becomes even more interesting when we turn to the ParList structure.
Reference: [MTH90] <author> Robin Milner, Mads Tofte, and R. Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The operators in the table are grouped in decreasing binding power downwards; within a group the operators have the same binding power: 4 A function like ParList is often called a type constructor <ref> [MTH90] </ref>. 8 : G G fl . / ffi - ) ( ! 1.2.3 Notation and Proof Style We will use a notation similar to that presented by Dijkstra and Scholten [DS90], which includes writing function application by an infix, left associative dot "." operator; for example, f:x denotes the value <p> We could have used j in defining 4 over PowerLists, since a simple consequence of (2.17) is (p j q) 4 (u j v) (p 4 u) ^ (q 4 v) (2.18) Functions on PowerLists are defined using pattern matching known from functional programming languages such as ML <ref> [MTH90] </ref> and Miranda TM [Tur86]. It follows from the PowerList axioms that a singleton can be deconstructed uniquely, and similarly that a non-singleton PowerList can be deconstructed uniquely using both ./ and j. <p> In (3.1) a is the first element of v and b is the last element of v. This definition corresponds to linear list theory, which is well-known from sequential, functional languages such as Miranda TM [Tur86], ML <ref> [MTH90] </ref> and Haskell [HJW + 92], and from the Bird-Meertens theory of lists [Bir89, BW88, Ski94].
Reference: [Ofm63] <author> Yu. Ofman. </author> <title> On the algorithmic complexity of discrete function. </title> <journal> Soviet Physics Doklady, </journal> <volume> 7(7) </volume> <pages> 289-591, </pages> <year> 1963. </year>
Reference-contexts: We define the function ps : PowerList:Y:n ! PowerList:Y:n to realize a well known algorithm for computing the prefix sum due to Ladner and Fischer [LF80]. This algorithm has roots in an algorithm presented by Ofman <ref> [Ofm63] </ref> and later implemented on a perfect shu*e network by Stone [Sto71].
Reference: [PV81] <author> Franco P. Preparata and Jean Vuillemin. </author> <title> The cube-connected cycles: A versatile network for parallel computation. </title> <journal> Communications of the ACM, </journal> <volume> 24(5) </volume> <pages> 300-309, </pages> <month> May </month> <year> 1981. </year>
Reference-contexts: He then showed that this class has an efficient implementation on hypercubic architectures, using a technique similar to the one we derived for the prefix sum algorithm on hypercubes in Section 2.4.1. 5.1.4 Other Models for Parallel Programming Ascend and Descend Algorithms Preparata and Vuillemin <ref> [PV81] </ref> presented the cube-connected-cycles (CCC) a network that has many of the topological properties of a hypercube, with only a constant number of neighbors for each node. <p> function f on inputs of length 2 n on a hypercube; similarly, we define B:f:n as a measure for simulating the function on a butterfly (or CCC), this can be done with a polylogarithmic slowdown: B:f O (n :: n 2 ) fl H:f An even more important result in <ref> [PV81] </ref> is the classification of the group of divide-and-conquer algorithms called Ascend and Descend, that in PowerList correspond closely to deconstruction arguments with ./ and j respectively 4 . Preparata and Vuillemin presented Ascend and Descend algorithms for Batcher's merge and the Fast Fourier Transform.
Reference: [RS87] <author> John R. Rose and Guy L. Steele Jr. </author> <title> C fl : An extended language for data parallel programming. </title> <booktitle> In Proceedings Second International Conference on Supercomputing, </booktitle> <volume> volume 2, </volume> <pages> pages 2-16, </pages> <address> San Francisco, CA, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: Examples of such languages are FORTRAN-90 [ANSI90], C* <ref> [RS87] </ref>, *Lisp [Las86], multiC [Wav92] and many others. The use of such languages is close to an acceptance of Eckert's statement, since the programmer is only trusted with a sequential language. Some compilers are designed with this acceptance in mind.
Reference: [Sch90] <author> E. Schwabe. </author> <title> On the computational equivalence of hypercube-derived networks. </title> <booktitle> In Proceedings of the 2nd Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 388-397. </pages> <publisher> ACM, </publisher> <month> July </month> <year> 1990. </year>
Reference-contexts: Preparata and Vuillemin presented Ascend and Descend algorithms for Batcher's merge and the Fast Fourier Transform. The class of Ascend and Descend algorithms are contained in the class of normal algorithms, consisting of the hypercube algorithms that utilize adjacent dimensions in adjacent steps. It can be shown <ref> [Sch90] </ref> that a normal hypercube algorithm g can be simulated with a constant slowdown on a butterfly (and thus on a CCC): g is normal ) B:g O H:g Ruby Ruby [JS90] is a relational algebra, developed by Jones and Sheeran for designing integrated circuits at a high level.
Reference: [Sew54] <author> Harold E. Seward. </author> <title> Information sorting in the application of electronic digital computers to business operations. </title> <type> Master's thesis, </type> <institution> Stanford University, </institution> <year> 1954. </year>
Reference-contexts: At even steps, we perform the same operation for cells 2 and 3, 4 and 5, etc." 4 As a parallel sorting technique the odd-even sort is well established in the literature <ref> [Sew54, Dem56] </ref>. Knuth [Knu73, exercise 5.3.4.37] poses its proof of correctness as an exercise. 48 In contrast to Batcher's networks, the odd-even sort is iterative in nature and does not have a simple definition in the PowerList notation.
Reference: [Ski94] <author> David B. </author> <title> Skillicorn. </title> <booktitle> Foundations of Parallel Programming. Series in Parallel Computation. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1994. </year>
Reference-contexts: This definition corresponds to linear list theory, which is well-known from sequential, functional languages such as Miranda TM [Tur86], ML [MTH90] and Haskell [HJW + 92], and from the Bird-Meertens theory of lists <ref> [Bir89, BW88, Ski94] </ref>. <p> While Sisal programs are more concise than corresponding Fortran programs, they are not easily amenable to formal proofs of correctness due to extensive use of indexing notations. 5.1.3 Bird-Meertens Formalism The Bird-Meertens formalism <ref> [Bir89, Mee86, Ski94] </ref> has its roots in FP, but is more general since it applies to a number of different categorical data types [Mal90], including linear lists. <p> A homomorphism like h above satisfies the following law 3 [Bir89]: h = reduce: ffi map:f where f:a = h:[a] (5.2) and can be implemented in time proportional to the logarithm of the length of the list on most parallel architectures <ref> [Ski94, Gor96] </ref>. The Bird-Meertens formalism is very rich, providing many interesting results about functions over linear lists. Most of these results can be reused in the theories we presented in this dissertation, since the data structures can be viewed as linear lists by ignoring the way they were constructed.
Reference: [Sto71] <author> H. S. Stone. </author> <title> Parallel processing with the perfect shu*e. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-20(2):153-161, </volume> <year> 1971. </year> <month> 148 </month>
Reference-contexts: We define the function ps : PowerList:Y:n ! PowerList:Y:n to realize a well known algorithm for computing the prefix sum due to Ladner and Fischer [LF80]. This algorithm has roots in an algorithm presented by Ofman [Ofm63] and later implemented on a perfect shu*e network by Stone <ref> [Sto71] </ref>.
Reference: [Str69] <author> Volker Strassen. </author> <title> Gaussian elimination is not optimal. </title> <journal> Numerische Math--ematik, </journal> <volume> 13 </volume> <pages> 354-356, </pages> <year> 1969. </year>
Reference-contexts: Preliminary results using these extensions appear promising for the other data structures as well. Some simple matrix algorithms have elegant descriptions in the higher dimension extensions of PowerList; for example, we have descriptions of different versions of matrix multiplication: the standard divide and conquer technique, the Strassen algorithm <ref> [Str69] </ref> and the hypercube algorithm by Dekel, Nassimi and Sahni [DNS81]. The latter algorithm is described using an extended version of PowerLists in [Kor94]. 5.3 Final Comments The three data structures we presented were useful in expressing parallel computations.
Reference: [Tur86] <author> David Turner. </author> <title> An overview of Miranda. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 21 </volume> <pages> 156-166, </pages> <year> 1986. </year>
Reference-contexts: have used j in defining 4 over PowerLists, since a simple consequence of (2.17) is (p j q) 4 (u j v) (p 4 u) ^ (q 4 v) (2.18) Functions on PowerLists are defined using pattern matching known from functional programming languages such as ML [MTH90] and Miranda TM <ref> [Tur86] </ref>. It follows from the PowerList axioms that a singleton can be deconstructed uniquely, and similarly that a non-singleton PowerList can be deconstructed uniquely using both ./ and j. <p> In (3.1) a is the first element of v and b is the last element of v. This definition corresponds to linear list theory, which is well-known from sequential, functional languages such as Miranda TM <ref> [Tur86] </ref>, ML [MTH90] and Haskell [HJW + 92], and from the Bird-Meertens theory of lists [Bir89, BW88, Ski94].
Reference: [Wav92] <institution> Wavetracer, Inc. MultiC Basics for DTC Systems, </institution> <year> 1992. </year> <month> 149 </month>
Reference-contexts: Examples of such languages are FORTRAN-90 [ANSI90], C* [RS87], *Lisp [Las86], multiC <ref> [Wav92] </ref> and many others. The use of such languages is close to an acceptance of Eckert's statement, since the programmer is only trusted with a sequential language. Some compilers are designed with this acceptance in mind. <p> Their approach is somewhat unusual: they transform PowerList descriptions into an intermediate language based on skeletons [Col89], thereby eliminating most of the structure that is present in the PowerList descriptions. These skeleton descriptions are then transformed into the programming language multiC <ref> [Wav92] </ref> that can be compiled for the Wavetracer architecture. 5.1.2 Functional Parallel Programming Iverson developed the programming language APL [Ive62] based on the idea of applying a single operation to each element of a data structure.
References-found: 71

