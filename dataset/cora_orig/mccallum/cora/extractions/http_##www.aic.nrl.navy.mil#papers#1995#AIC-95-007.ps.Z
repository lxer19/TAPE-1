URL: http://www.aic.nrl.navy.mil/papers/1995/AIC-95-007.ps.Z
Refering-URL: http://www.aic.nrl.navy.mil/papers/1995/
Root-URL: 
Title: Evaluation and Selection of Biases in Machine Learning  
Author: DIANA F. GORDON Editor: Thomas G. Dietterich 
Keyword: bias, concept learning  
Address: desJARDINS  
Affiliation: Naval Research Laboratory MARIE  SRI International  
Note: Machine Learning Journal,  c 1995 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Email: gordon@aic.nrl.navy.mil  marie@erg.sri.com  
Date: 20, 1-17 (1995)  
Abstract: In this introduction, we define the term bias as it is used in machine learning systems. We motivate the importance of automated methods for evaluating and selecting biases using a framework of bias selection as search in bias and meta-bias spaces. Recent research in the field of machine learning bias is summarized. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Aha, D. and Bankert, R. </author> <year> (1994). </year> <title> Feature selection for case-based classification of cloud types. </title> <booktitle> In Proceedings of the 1994 Workshop on Case-Based Reasoning, </booktitle> <pages> pages 106-112. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: PREDICTOR performs feature selection. There has recently been an increasing interest in this topic, e.g., by Almuallim and Dietterich [2], Kira and Rendell [20], Vafaie and De Jong [37], Aha and Bankert <ref> [1] </ref>, and John et al. [18]. The system of Bloedorn et al. [5] searches all three tiers of Figure 1, including meta-bias space. The performance goals are predictive accuracy, simplicity, and efficiency. Heuristics are used extensively in the bias selection process.
Reference: 2. <author> Almuallim, H. and Dietterich, T. </author> <year> (1991). </year> <title> Learning with many irrelevant features. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 547-552. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: PREDICTOR performs feature selection. There has recently been an increasing interest in this topic, e.g., by Almuallim and Dietterich <ref> [2] </ref>, Kira and Rendell [20], Vafaie and De Jong [37], Aha and Bankert [1], and John et al. [18]. The system of Bloedorn et al. [5] searches all three tiers of Figure 1, including meta-bias space. The performance goals are predictive accuracy, simplicity, and efficiency.
Reference: 3. <author> Angluin, D. </author> <year> (1988). </year> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342. </pages>
Reference-contexts: The performance goal is to minimize the number of instances required to learn the target concept. PREDICTOR evaluates its bias using membership queries (i.e., requested instances <ref> [3] </ref>). This work reveals an important tradeoff between the reduced cost of learning with a stronger bias and the increased cost of more queries used to help in choosing a stronger bias. PREDICTOR performs feature selection.
Reference: 4. <author> Baltes, J. and MacDonald, B. </author> <year> (1992). </year> <title> Case-based meta learning: Sustained learning supported by a dynamically biased version space. </title> <booktitle> In Proceedings of the ML92 Workshop on Biases in Inductive Learning. </booktitle>
Reference-contexts: This method provides an evaluation function over the space of representational biases L (H), and could be extended to evaluate procedural biases as well. Baltes and MacDonald <ref> [4] </ref> and Datta and Kibler [13] also describe methods that use previously learned concepts (prior knowledge) to bias the learning of new concepts. The use of prior knowledge to bias genetic algorithms and neural networks have recently been studied by several researchers.
Reference: 5. <author> Bloedorn, E., Michalski, R., and Wnek, J. </author> <year> (1993). </year> <title> Multistrategy constructive induction: </title> <booktitle> AQ17-MCI. In Proceedings of the Second International Workshop on Multistrategy Learning, </booktitle> <pages> pages 188-206. </pages>
Reference-contexts: PREDICTOR performs feature selection. There has recently been an increasing interest in this topic, e.g., by Almuallim and Dietterich [2], Kira and Rendell [20], Vafaie and De Jong [37], Aha and Bankert [1], and John et al. [18]. The system of Bloedorn et al. <ref> [5] </ref> searches all three tiers of Figure 1, including meta-bias space. The performance goals are predictive accuracy, simplicity, and efficiency. Heuristics are used extensively in the bias selection process.
Reference: 6. <author> Blumer, A., Ehrenfeucht, A., Haussler, D., and Warmuth, M. </author> <year> (1987). </year> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 377-380. </pages>
Reference-contexts: A procedural bias (also called algorithmic bias [26]) determines the order of traversal of the states in the space defined by a representational bias. Examples of procedural biases include the beam width in a beam search and a preference for simple or specific hypotheses. Occam's Razor <ref> [6] </ref> and the Minimum Description Length Principle [9] [33] provide formal motivations for why a preference for simple hypotheses works well theoretically. However, they leave the question of a practical implementation open, and appropriate representational biases and search heuristics that find simple hypotheses are still required.
Reference: 7. <author> Blumer, A., Ehrenfeucht, A., Haussler, D., and Warmuth, M. </author> <year> (1989). </year> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 36(4) </volume> <pages> 929-965. </pages>
Reference-contexts: The computational learning community has also explored the issue of bias strength from a formal, analytical perspective. Vapnik and Chervonenkis [38] define a measure of the size of a bias defined by a given representation, called the VC-dimension. Blumer et al. <ref> [7] </ref> use the VC-dimension to provide bounds on the number of examples required for any consistent learning algorithm to approximate the target concept with high confidence. A procedural bias (also called algorithmic bias [26]) determines the order of traversal of the states in the space defined by a representational bias.
Reference: 8. <author> Cardie, C. </author> <year> (1993). </year> <title> Using cognitive biases to guide feature set selection. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 743-748. </pages> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: However, they leave the question of a practical implementation open, and appropriate representational biases and search heuristics that find simple hypotheses are still required. Note that biases may interact; a procedural and a representational bias might interact synergistically or conflict. Few researchers have studied bias interactions (see Cardie <ref> [8] </ref> and Cobb [11] for exceptions). Hopefully, future work will explore this important topic. Both representational and procedural biases can be evaluated (empirically or analytically) by determining the effect they have or are expected to have on learning performance.
Reference: 9. <author> Chaitin, G. J. </author> <year> (1977). </year> <title> Algorithmic information theory. </title> <journal> IBM J. Res. Develop., </journal> <volume> 21 </volume> <pages> 350-359. </pages>
Reference-contexts: Examples of procedural biases include the beam width in a beam search and a preference for simple or specific hypotheses. Occam's Razor [6] and the Minimum Description Length Principle <ref> [9] </ref> [33] provide formal motivations for why a preference for simple hypotheses works well theoretically. However, they leave the question of a practical implementation open, and appropriate representational biases and search heuristics that find simple hypotheses are still required.
Reference: 10. <author> Chrisman, L. </author> <year> (1989). </year> <title> Evaluating bias during PAC-learning. </title> <booktitle> In Machine Learning Workshop, </booktitle> <pages> pages 469-471. </pages> <publisher> Morgan Kaufmann. 16 D. </publisher> <editor> GORDON AND M. </editor> <publisher> desJARDINS </publisher>
Reference-contexts: Generate-and-test methods are valuable for gathering knowledge in knowledge-poor situations. Predictive theoretical analyses are also valuable when they do not make too many simplifying assumptions. The knowledge gained from generate-and-test and analytical evaluations may be kept o*ine. Chrisman <ref> [10] </ref> describes a method for analyzing learning performance to identify inappropriate biases (this can be thought of as the "test" stage of a generate-and-test evaluation method).
Reference: 11. <author> Cobb, H. </author> <year> (1992). </year> <title> Inductive biases in a reinforcement learner. </title> <booktitle> In Proceedings of the ML92 Workshop on Biases in Inductive Learning. </booktitle>
Reference-contexts: Note that biases may interact; a procedural and a representational bias might interact synergistically or conflict. Few researchers have studied bias interactions (see Cardie [8] and Cobb <ref> [11] </ref> for exceptions). Hopefully, future work will explore this important topic. Both representational and procedural biases can be evaluated (empirically or analytically) by determining the effect they have or are expected to have on learning performance.
Reference: 12. <author> Cohen, W. W. </author> <year> (1995). </year> <title> Grammatically biased learning: Learning Horn theories using an explicit antecedent description language. </title> <journal> Artificial Intelligence. </journal>
Reference-contexts: Russell and Grosof [29] first introduced the concept of declarative bias, an explicit specification of the representational bias l (H ). The advantage of declarative bias is that because the bias is represented explicitly, it is easy to analyze and modify it when necessary. Cohen's GRENDEL <ref> [12] </ref> allows a user to specify bias declaratively in a FOIL-like inductive learning system.
Reference: 13. <author> Datta, P. and Kibler, D. </author> <year> (1992). </year> <title> Utilizing prior concepts for learning. </title> <booktitle> In Proceedings of the ML92 Workshop on Biases in Inductive Learning. </booktitle> <volume> 14. </volume> <editor> desJardins, M. </editor> <year> (1994). </year> <title> Evaluation of learning biases using probabilistic domain knowledge. </title> <booktitle> In Computational Learning Theory and Natural Learning Systems, </booktitle> <volume> vol. 2, chapter 7, </volume> <pages> pages 95-112. </pages> <publisher> The MIT Press. </publisher>
Reference-contexts: This method provides an evaluation function over the space of representational biases L (H), and could be extended to evaluate procedural biases as well. Baltes and MacDonald [4] and Datta and Kibler <ref> [13] </ref> also describe methods that use previously learned concepts (prior knowledge) to bias the learning of new concepts. The use of prior knowledge to bias genetic algorithms and neural networks have recently been studied by several researchers.
Reference: 15. <author> Gordon, D. </author> <year> (1990). </year> <title> Active Bias Selection for Incremental, Supervised Concept Learning. </title> <type> PhD thesis, </type> <institution> University of Maryland, Department of Computer Science. </institution> <note> Also available as Technical Report UMIACS-TR-90-60 CS-TR-2464. </note>
Reference-contexts: The degree of hypothesis consistency is a choice of p (l (H)) because it is an evaluation over the hypotheses in the set l (H). The performance goal is improved predictive accuracy. Spears and Gordon find that lower consistency is preferable when the data is noisy. Gordon's PREDICTOR system <ref> [15] </ref> searches L (H ) by strengthening inductive bias whenever possible, and weakening bias minimally when necessary to restore bias correctness. The performance goal is to minimize the number of instances required to learn the target concept. PREDICTOR evaluates its bias using membership queries (i.e., requested instances [3]).
Reference: 16. <author> Gordon, D. and Subramanian, D. </author> <year> (1993). </year> <title> A multistrategy learning scheme for agent knowledge acquisition. </title> <journal> Informatica, </journal> <volume> 17 </volume> <pages> 331-346. </pages>
Reference-contexts: The use of prior knowledge to bias genetic algorithms and neural networks have recently been studied by several researchers. The systems of Gordon and Subrama-nian <ref> [16] </ref>, as well as Schultz and Grefenstette [32], use prior knowledge to initialize a genetic algorithm. The former system uses high-level advice for the initialization. KBANN [35] uses a domain theory in the form of propositional rules to initialize a neural network.
Reference: 17. <author> Hirsh, H. </author> <year> (1990). </year> <title> Knowledge as bias. In Change of Representation and Inductive Bias. </title> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: Background (e.g., task) knowledge has sometimes been considered to be a bias as well <ref> [17] </ref>. However, since knowledge has the supportive role of providing information to select a representational or procedural bias, here we do not consider it to be a bias per se. A representational bias defines the states in a search space. Typically, this search space is the space of hypotheses.
Reference: 18. <author> John, G., Kohavi, R., and Pfleger, K. </author> <year> (1994). </year> <title> Irrelevant features and the subset selection problem. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pages 121-129. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: PREDICTOR performs feature selection. There has recently been an increasing interest in this topic, e.g., by Almuallim and Dietterich [2], Kira and Rendell [20], Vafaie and De Jong [37], Aha and Bankert [1], and John et al. <ref> [18] </ref>. The system of Bloedorn et al. [5] searches all three tiers of Figure 1, including meta-bias space. The performance goals are predictive accuracy, simplicity, and efficiency. Heuristics are used extensively in the bias selection process.
Reference: 19. <author> Kietz, J. and Morik, K. </author> <year> (1994). </year> <title> A polynomial approach to the constructive induction of structured knowledge. </title> <journal> Machine Learning, </journal> <volume> 14(2) </volume> <pages> 193-218. </pages>
Reference-contexts: This followed a 1991 Machine Learning workshop on "Constructive Induction" chaired by Matheus. Several papers in a recent special issue of Machine Learning on "Evaluating and Changing Representation" examine constructive induction. For example, in that issue Wnek and Michalski [39], Wrobel [41], and Kietz and Morik <ref> [19] </ref> describe methods for dynamically shifting bias by performing constructive induction when learning fails. Furthermore, those papers address some of the same issues we focus on here. Rendell has done much work on this topic. The performance goals of Rendell's [27] constructive induction system are speed, accuracy, and conciseness (simplicity).
Reference: 20. <author> Kira, K. and Rendell, L. </author> <year> (1992). </year> <title> A practical approach to feature selection. </title> <booktitle> In Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <pages> pages 249-256. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: PREDICTOR performs feature selection. There has recently been an increasing interest in this topic, e.g., by Almuallim and Dietterich [2], Kira and Rendell <ref> [20] </ref>, Vafaie and De Jong [37], Aha and Bankert [1], and John et al. [18]. The system of Bloedorn et al. [5] searches all three tiers of Figure 1, including meta-bias space. The performance goals are predictive accuracy, simplicity, and efficiency. Heuristics are used extensively in the bias selection process.
Reference: 21. <author> Matheus, C. </author> <year> (1991). </year> <title> The need for constructive induction. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 173-177. </pages> <publisher> Tioga. </publisher>
Reference-contexts: The constructive induction method used is "peak merging." New peaks (hypothesis disjuncts) are formed by constructing new terms (attributes). Each new peak is comprised of multiple old peaks. As mentioned at the beginning of this section, a pertinent question to ask is, "What evaluation method facilitates bias selection?" Matheus <ref> [21] </ref> presents a framework in which he elaborates sources upon which to base the evaluation of a bias shift involving feature construction (e.g., peak merging). These sources are the instances, the hypotheses, and the domain knowledge. 6.2.2.
Reference: 22. <author> Michalski, R. </author> <year> (1983). </year> <title> A theory and methodology of inductive learning. </title> <editor> In Michalski, R., Carbonell, J., and Mitchell, T., editors, </editor> <booktitle> Machine Learning I, </booktitle> <pages> pages 83-134. </pages> <publisher> Tioga. </publisher>
Reference-contexts: In this special issue, we hope to give the reader insights into the advantages and disadvantages of particular static biases and bias shifting methods. Michalski <ref> [22] </ref> and Rendell [26] both show how bias shifting can be viewed as a search through a space of biases. Figure 1 presents our framework, which has three search tiers for a bias shifting system (like the framework in Rendell [26]).
Reference: 23. <author> Mitchell, T. </author> <year> (1980). </year> <title> The need for biases in learning generalizations. </title> <type> Technical Report CBM-TR-117, </type> <institution> Rutgers University. </institution>
Reference-contexts: We then describe our search-based framework for bias selection. Finally, we survey recent research in this field, using the concepts developed in our framework to guide the discussion. 2 D. GORDON AND M. desJARDINS 2. What is a bias? Mitchell <ref> [23] </ref> defines bias as "any basis for choosing one generalization over another, other than strict consistency with the instances." We broaden this definition to include any factor (including consistency with the instances) that influences the definition or selection of inductive hypotheses. 1 There are two major types of bias: representational and
Reference: 24. <author> Pratt, L. Y. </author> <year> (1993). </year> <title> Discriminability-based transfer between neural networks. </title> <editor> In Giles, C. L., Hanson, S. J., and Cowan, J. D., editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <pages> pages 204-211. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: The systems of Gordon and Subrama-nian [16], as well as Schultz and Grefenstette [32], use prior knowledge to initialize a genetic algorithm. The former system uses high-level advice for the initialization. KBANN [35] uses a domain theory in the form of propositional rules to initialize a neural network. Pratt <ref> [24] </ref> describes the discriminability-based transfer method for incorporating knowledge acquired during previous learning tasks into a neural network. 7.
Reference: 25. <author> Provost, F. J. and Buchanan, B. </author> <year> (1992). </year> <title> Inductive policy. </title> <booktitle> In AAAI-92, </booktitle> <pages> pages 255-261. </pages> <publisher> AAAI Press/The MIT Press. </publisher>
Reference-contexts: Current bias shifting systems perform search in the first two tiers; some also perform search in the third tier. We are not aware of any systems that search in more than three tiers. Our framework is related to both Rendell's conceptual framework [26] and the diagram in Provost <ref> [25] </ref>. However, our framework is more general than Provost's and clarifies some of the issues raised by Rendell. For example, Rendell describes the three tiers and also the representational/procedural (which he calls "algorithmic") bias distinction, but does not explain how this distinction extends easily to meta-bias space.
Reference: 26. <author> Rendell, L. </author> <year> (1987). </year> <title> Similarity-based learning and its extensions. </title> <journal> Computational Intelligence, </journal> <volume> 3 </volume> <pages> 241-266. </pages>
Reference-contexts: Blumer et al. [7] use the VC-dimension to provide bounds on the number of examples required for any consistent learning algorithm to approximate the target concept with high confidence. A procedural bias (also called algorithmic bias <ref> [26] </ref>) determines the order of traversal of the states in the space defined by a representational bias. Examples of procedural biases include the beam width in a beam search and a preference for simple or specific hypotheses. <p> In this special issue, we hope to give the reader insights into the advantages and disadvantages of particular static biases and bias shifting methods. Michalski [22] and Rendell <ref> [26] </ref> both show how bias shifting can be viewed as a search through a space of biases. Figure 1 presents our framework, which has three search tiers for a bias shifting system (like the framework in Rendell [26]). <p> Michalski [22] and Rendell <ref> [26] </ref> both show how bias shifting can be viewed as a search through a space of biases. Figure 1 presents our framework, which has three search tiers for a bias shifting system (like the framework in Rendell [26]). The lowest (first) tier in Figure 1 represents the inductive learning process, which can be viewed as a search through a space of inductive hypotheses. 2 The representational and procedural biases for the hypothesis space can be chosen either statically or dynamically. <p> Current bias shifting systems perform search in the first two tiers; some also perform search in the third tier. We are not aware of any systems that search in more than three tiers. Our framework is related to both Rendell's conceptual framework <ref> [26] </ref> and the diagram in Provost [25]. However, our framework is more general than Provost's and clarifies some of the issues raised by Rendell.
Reference: 27. <author> Rendell, L. </author> <year> (1990). </year> <title> Feature construction for concept learning. </title> <booktitle> In Change of Representation and Inductive Bias, </booktitle> <pages> pages 327-353. </pages> <publisher> Kluwer. </publisher>
Reference-contexts: One common method for searching the representational bias space is constructive induction, which uses feature constructors to move from a stronger to a weaker bias. Constructive induction is typically done to increase the likelihood that the representational bias l (H) is correct, but can also improve efficiency <ref> [27] </ref>. <p> Furthermore, those papers address some of the same issues we focus on here. Rendell has done much work on this topic. The performance goals of Rendell's <ref> [27] </ref> constructive induction system are speed, accuracy, and conciseness (simplicity). The constructive induction method used is "peak merging." New peaks (hypothesis disjuncts) are formed by constructing new terms (attributes). Each new peak is comprised of multiple old peaks.
Reference: 28. <author> Rendell, L., Seshu, R., and Tcheng, D. </author> <year> (1987). </year> <title> More robust concept learning using dynamically-variable bias. </title> <booktitle> In Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <pages> pages 66-78. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In other words, we can identify the "best" bias for each given set of problem space characteristics (e.g., the quality of the data, the type of attributes, or the contents of the current hypothesis) and performance goals. VBMS <ref> [28] </ref> is an example of this approach. In VBMS, the domain-independent heuristics are learned from "training examples" that are themselves inductive learning problems. Brodley's MCS (this issue) is a more recent heuristic-based system in which the heuristics are manually generated.
Reference: 29. <author> Russell, S. and Grosof, B. </author> <year> (1987). </year> <title> A declarative approach to bias in concept learning. </title> <booktitle> In AAAI, </booktitle> <pages> pages 505-510. </pages>
Reference-contexts: In 1992, desJardins chaired a AAAI workshop entitled "Constraining Learning with Prior Knowledge" that explored novel approaches for using existing knowledge to reduce the computational complexity of the learning problem, including the evaluation and selection of biases. Russell and Grosof <ref> [29] </ref> first introduced the concept of declarative bias, an explicit specification of the representational bias l (H ). The advantage of declarative bias is that because the bias is represented explicitly, it is easy to analyze and modify it when necessary.
Reference: 30. <author> Saxena, S. </author> <year> (1991). </year> <title> On the effect of instance representation on generalization. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 198-202. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Their comments improved both the style and content of this paper. We also thank the reviewers for their thoughtful reviews of the papers in this issue. Notes 1. Biases can also affect the definition or selection of instances (see Saxena <ref> [30] </ref>). We omit a discussion of this topic for the sake of brevity. 2. The arrows in Figure 1 go downward only. This is a simplification to clarify our presentation. Bias revision is typically both data- and model-driven, so that the lower tiers influence the higher tiers and vice versa.
Reference: 31. <author> Schaffer, C. </author> <year> (1994). </year> <title> A conservation law for generalization performance. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pages 259-265. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Many of the papers in this special issue could be considered as providing steps toward the carving out of regions of expertise for biases. Recently, there has been a great deal of discussion regarding "no-free-lunch" theorems about induction <ref> [31] </ref>, [40]. These results state that when performance is averaged uniformly over all possible problems, one learner cannot be better than another. Nevertheless, these results still allow the possibility of one learner being better than another for a particular distribution of problems.
Reference: 32. <author> Schultz, A. and Grefenstette, J. </author> <year> (1990). </year> <title> Improving tactical plans with genetic algorithms. </title> <booktitle> In Proceedings of the IEEE Conference on Tools for AI, </booktitle> <pages> pages 328-334. </pages> <publisher> IEEE Press. </publisher>
Reference-contexts: The use of prior knowledge to bias genetic algorithms and neural networks have recently been studied by several researchers. The systems of Gordon and Subrama-nian [16], as well as Schultz and Grefenstette <ref> [32] </ref>, use prior knowledge to initialize a genetic algorithm. The former system uses high-level advice for the initialization. KBANN [35] uses a domain theory in the form of propositional rules to initialize a neural network.
Reference: 33. <author> Solomonoff, R. J. </author> <year> (1964). </year> <title> A formal theory of inductive inference. </title> <journal> Information and Control, </journal> <volume> 7. </volume>
Reference-contexts: Examples of procedural biases include the beam width in a beam search and a preference for simple or specific hypotheses. Occam's Razor [6] and the Minimum Description Length Principle [9] <ref> [33] </ref> provide formal motivations for why a preference for simple hypotheses works well theoretically. However, they leave the question of a practical implementation open, and appropriate representational biases and search heuristics that find simple hypotheses are still required.
Reference: 34. <author> Spears, W. and Gordon, D. </author> <year> (1992). </year> <title> Is consistency harmful? In Proceedings of the ML92 Workshop on Biases in Inductive Learning. </title>
Reference-contexts: The performance goals in Subramanian's work are accuracy and computational efficiency. Both a formal analysis of the irrelevance principle and empirical results of its application to learning domains are given. The GABIL system of Spears and Gordon <ref> [34] </ref> uses cross-validation, a generate-and-test method, to select the degree to which the hypotheses are consistent with previously seen training data. The degree of hypothesis consistency is a choice of p (l (H)) because it is an evaluation over the hypotheses in the set l (H).
Reference: 35. <author> Towell, G., Shavlik, J., and Noordewier, M. </author> <year> (1990). </year> <title> Refinement of approximate domain theories by knowledge-based neural networks. </title> <booktitle> In Proceedings of AAAI-90, </booktitle> <pages> pages 861-866. </pages> <publisher> Morgan Kaufmann. EVALUATION AND SELECTION OF BIASES 17 </publisher>
Reference-contexts: The systems of Gordon and Subrama-nian [16], as well as Schultz and Grefenstette [32], use prior knowledge to initialize a genetic algorithm. The former system uses high-level advice for the initialization. KBANN <ref> [35] </ref> uses a domain theory in the form of propositional rules to initialize a neural network. Pratt [24] describes the discriminability-based transfer method for incorporating knowledge acquired during previous learning tasks into a neural network. 7.
Reference: 36. <author> Utgoff, P. </author> <year> (1986). </year> <title> Shift of bias for inductive concept learning. </title> <editor> In Michalski, R., Carbonell, J., and Mitchell, T., editors, </editor> <booktitle> Machine Learning II, </booktitle> <pages> pages 107-148. </pages> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Representational bias can be characterized along several axes, including strength and correctness. According to Utgoff <ref> [36] </ref>, a strong representational bias for the hypothesis space implies a small hypothesis space; a weak representational bias implies a large hypothesis space. A representational bias is considered correct if it defines a hypothesis space that includes the target concept; otherwise, it is incorrect.
Reference: 37. <author> Vafaie, H. and Jong, K. D. </author> <year> (1993). </year> <title> Robust feature selection algorithms. </title> <booktitle> In Proceedings of the Fifth Conference on Tools for Artificial Intelligence, </booktitle> <pages> pages 356-363. </pages> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: PREDICTOR performs feature selection. There has recently been an increasing interest in this topic, e.g., by Almuallim and Dietterich [2], Kira and Rendell [20], Vafaie and De Jong <ref> [37] </ref>, Aha and Bankert [1], and John et al. [18]. The system of Bloedorn et al. [5] searches all three tiers of Figure 1, including meta-bias space. The performance goals are predictive accuracy, simplicity, and efficiency. Heuristics are used extensively in the bias selection process.
Reference: 38. <author> Vapnik, V. and Chervonenkis, A. </author> <year> (1971). </year> <title> On the uniform convergence of relative frequencies of events to their probabilities. </title> <journal> Theory of Probability and its Applications, </journal> <volume> 16(2) </volume> <pages> 264-280. </pages>
Reference-contexts: A representational bias is considered correct if it defines a hypothesis space that includes the target concept; otherwise, it is incorrect. The computational learning community has also explored the issue of bias strength from a formal, analytical perspective. Vapnik and Chervonenkis <ref> [38] </ref> define a measure of the size of a bias defined by a given representation, called the VC-dimension. Blumer et al. [7] use the VC-dimension to provide bounds on the number of examples required for any consistent learning algorithm to approximate the target concept with high confidence.
Reference: 39. <author> Wnek, J. and Michalski, R. </author> <year> (1994). </year> <title> Hypothesis-driven constructive induction in AQ17-HCI: A method and experiments. </title> <journal> Machine Learning, </journal> <volume> 14(2) </volume> <pages> 139-168. </pages>
Reference-contexts: This followed a 1991 Machine Learning workshop on "Constructive Induction" chaired by Matheus. Several papers in a recent special issue of Machine Learning on "Evaluating and Changing Representation" examine constructive induction. For example, in that issue Wnek and Michalski <ref> [39] </ref>, Wrobel [41], and Kietz and Morik [19] describe methods for dynamically shifting bias by performing constructive induction when learning fails. Furthermore, those papers address some of the same issues we focus on here. Rendell has done much work on this topic.
Reference: 40. <author> Wolpert, D. </author> <year> (1992). </year> <title> On the connection between in-sample testing and generalization error. </title> <journal> Complex Systems, </journal> <volume> 6 </volume> <pages> 47-94. </pages>
Reference-contexts: Many of the papers in this special issue could be considered as providing steps toward the carving out of regions of expertise for biases. Recently, there has been a great deal of discussion regarding "no-free-lunch" theorems about induction [31], <ref> [40] </ref>. These results state that when performance is averaged uniformly over all possible problems, one learner cannot be better than another. Nevertheless, these results still allow the possibility of one learner being better than another for a particular distribution of problems.
Reference: 41. <author> Wrobel, S. </author> <year> (1994). </year> <title> Concept formation during interactive theory revision. </title> <journal> Machine Learning, </journal> <volume> 14(2) </volume> <pages> 169-192. </pages>
Reference-contexts: This followed a 1991 Machine Learning workshop on "Constructive Induction" chaired by Matheus. Several papers in a recent special issue of Machine Learning on "Evaluating and Changing Representation" examine constructive induction. For example, in that issue Wnek and Michalski [39], Wrobel <ref> [41] </ref>, and Kietz and Morik [19] describe methods for dynamically shifting bias by performing constructive induction when learning fails. Furthermore, those papers address some of the same issues we focus on here. Rendell has done much work on this topic.
References-found: 40

