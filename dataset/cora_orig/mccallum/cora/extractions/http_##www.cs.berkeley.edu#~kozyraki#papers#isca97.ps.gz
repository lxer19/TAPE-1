URL: http://www.cs.berkeley.edu/~kozyraki/papers/isca97.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~kozyraki/papers/papers.html
Root-URL: 
Title: The Energy Efficiency of IRAM Architectures  
Author: Richard Fromm, Stylianos Perissakis, Neal Cardwell, Christoforos Kozyrakis, Bruce McGaughy, David Patterson, Tom Anderson, Katherine Yelick 
Address: California-Berkeley  
Affiliation: Computer Science Division, University of  
Abstract: Portable systems demand energy efficiency in order to maximize battery life. IRAM architectures, which combine DRAM and a processor on the same chip in a DRAM process, are more energy efficient than conventional systems. The high density of DRAM permits a much larger amount of memory on-chip than a traditional SRAM cache design in a logic process. This allows most or all IRAM memory accesses to be satisfied on-chip. Thus there is much less need to drive high-capacitance off-chip buses, which contribute significantly to the energy consumption of a system. To quantify this advantage we apply models of energy consumption in DRAM and SRAM memories to results from cache simulations of applications reflective of personal productivity tasks on low power systems. We find that IRAM memory hierarchies consume as little as 22% of the energy consumed by a conventional memory hierarchy for memory-intensive applications, while delivering comparable performance. Furthermore, the energy consumed by a system consisting of an IRAM memory hierarchy combined with an energy efficient CPU core is as little as 40% of that of the same CPU core with a traditional memory hierarchy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Accelerix Incorporated. </institution> <note> http://www.accelerix.com/. </note>
Reference-contexts: However, previous discussions have concentrated on the potential performance benefits. This paper is the first to quantify the energy efficiency advantages of IRAM. Commercial products integrating DRAM and logic include graphics accelerators from NeoMagic [29] and Accelerix <ref> [1] </ref>, and a chip from NEC that combines 16 Mb of DRAM with 128 8-bit processors for image-processing applications [2]. In addition, Mitsubishi has announced the M32R/D, which integrates a processor, 2KB of SRAM cache, and 2 MB of DRAM and is targeted at personal digital assistants [41][22].
Reference: [2] <editor> AIMOTO, Y., ET AL. A 7.68 GIPS, </editor> <booktitle> 3.84 GB/s 1W parallel image-processing RAM integrating a 16 Mb DRAM and 128 processors. In Digest of Technical Papers, 1996 IEEE International Solid-State Circuits Conference (San Francisco, </booktitle> <address> CA, </address> <month> Feb </month> <year> 1996), </year> <journal> vol. </journal> <volume> 39, </volume> <pages> pp. 372-373, 476. </pages>
Reference-contexts: This paper is the first to quantify the energy efficiency advantages of IRAM. Commercial products integrating DRAM and logic include graphics accelerators from NeoMagic [29] and Accelerix [1], and a chip from NEC that combines 16 Mb of DRAM with 128 8-bit processors for image-processing applications <ref> [2] </ref>. In addition, Mitsubishi has announced the M32R/D, which integrates a processor, 2KB of SRAM cache, and 2 MB of DRAM and is targeted at personal digital assistants [41][22]. They state that integrating a processor with memory significantly reduces power dissipation.
Reference: [3] <author> BURD, B., AND BRODERSEN, R. </author> <title> Energy efficient CMOS microprocessor design. </title> <booktitle> In Proroceedings of the Twenty-Eighth Hawaii International Conference on System Sciences (Los Alamitos, </booktitle> <address> CA, </address> <month> Jan. </month> <journal> 1995), </journal> <volume> vol. 1, </volume> <pages> pp. 288-297. </pages>
Reference: [4] <author> CHANDRAKASAN, A. </author> <title> Low Power Digital CMOS Design. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <year> 1994. </year>
Reference: [5] <author> CHANDRAKASAN, A., ET AL. </author> <title> System design of a multimedia I/O terminal. </title> <booktitle> In Proceedings of IEEE Workshop on VLSI Signal Processing (Veldhoven, </booktitle> <address> Netherlands, </address> <month> October </month> <year> 1993), </year> <pages> pp. 57-65. </pages>
Reference: [6] <author> CULBERT, M. </author> <title> Low power hardware for a high performance PDA. </title> <booktitle> In Digest of Technical Papers, 1994 IEEE Symposium on Low Power Electronics (San Diego, </booktitle> <address> CA, </address> <month> Oct. </month> <year> 1994), </year> <pages> pp. 28-31. </pages>
Reference-contexts: In smaller handheld portable devices, such as the Apple Newton and U.S. Robotics Pilot, there is no disk and the screen consumes much less power. The LCD on the original Newton consumed only 5 mW for static images, for example <ref> [6] </ref>. Hence, for these systems the power consumption of the CPU and memory is an even larger fraction of the total. There are three parts to the portion labeled CPU and Memory in Figure 1: CPU core, on-chip caches, and external memory.
Reference: [7] <author> CVETANOVIC, Z., AND BHANDARKAR, D. </author> <title> Performance characterization of the Alpha 21164 microprocessor using TP and SPEC workloads. </title> <booktitle> In Proceedings, Second International Symposium on High-Performance Computer Architecture (San Jose, </booktitle> <address> CA, </address> <month> Feb </month> <year> 1996), </year> <pages> pp. 270-280. </pages>
Reference-contexts: Many more of the memory accesses can be satisfied in the low-latency, high-bandwidth on-chip memory, due to the much higher density of DRAM than SRAM. For instance, Cvetanovic and Bhandarkar <ref> [7] </ref> found that a 300 MHz Alpha 21164 microprocessor spends about 75% of its time in the memory hierarchy for database and matrix computations.
Reference: [8] <author> DIGITAL EQUIPMENT CORPORATION. </author> <title> Alpha 21164 Micropro--cessor Hardware Reference Manual, </title> <year> 1995. </year>
Reference-contexts: The 30 ns on-chip DRAM access time is based on [24], the 180 ns off-chip access time is based on [11], and the 18.75 ns on-chip L2 SRAM cache access time is chosen to be slightly larger than the on-chip L2 cache of the Alpha 21164A <ref> [8] </ref>, which is slightly smaller (96 KB). The narrow bus width matches StrongARM, and the wide bus width takes advantage of the additional bandwidth available to main memory in an IRAM configuration. Note that it is only sensible to perform comparisons between SMALL-CONVENTIONAL and SMALL-IRAM and between LARGE-CONVENTIONAL and LARGE-IRAM.
Reference: [9] <author> DIMARCO, D., ET AL. </author> <title> A 200MHz 256KB second-level cache with 1.6GB/s data bandwidth. </title> <booktitle> In Digest of Technical Papers, 1996 IEEE International Solid-State Circuits Conference (San Francisco, </booktitle> <address> CA, </address> <month> Feb </month> <year> 1996), </year> <journal> vol. </journal> <volume> 39, </volume> <pages> pp. 158-159. </pages>
Reference: [10] <author> DOBBERPUHL, D. </author> <title> The design of a high performance low power microprocessor. </title> <booktitle> In Digest of Technical Papers, 1996 International Symposium on Low Power Electronics and Design (Montery, </booktitle> <address> CA, </address> <month> Aug. </month> <year> 1996), </year> <pages> pp. 11-16. </pages>
Reference: [11] <author> DOBBERPUHL, D. </author> <type> Personal communication, </type> <month> Nov. </month> <year> 1996. </year>
Reference-contexts: All caches are write-back to minimize energy consumption from unnecessarily switching internal and/or external buses. The 30 ns on-chip DRAM access time is based on [24], the 180 ns off-chip access time is based on <ref> [11] </ref>, and the 18.75 ns on-chip L2 SRAM cache access time is chosen to be slightly larger than the on-chip L2 cache of the Alpha 21164A [8], which is slightly smaller (96 KB).
Reference: [12] <author> FOSS, R. </author> <title> Implementing application specific memory. </title> <booktitle> In Digest of Technical Papers, 1996 IEEE International SolidState Circuits Conference (San Francisco, </booktitle> <address> CA, </address> <month> Feb. </month> <year> 1996), </year> <pages> pp. 260-261, 456. </pages>
Reference-contexts: The second idea is what we are suggesting for IRAM. The third idea has a number of technological disadvantages, including a significant loss in memory density and a much higher refresh rate for the DRAM, due to DRAM process optimizations which are not present in a logic process <ref> [12] </ref>. Therefore, we only consider the first two approaches. IRAM has a number of advantages over a conventional approach in achieving energy efficiency. First, DRAM is more energy efficient than SRAM per memory access, so accesses to the on-chip memory consume less energy. <p> of the number of cells per unit area for DRAM versus SRAM is much greater than the 4:1 or 6:1 figure that one would assume if the only relevant factor was the number of transistors, four or six for an SRAM cell versus a single transistor for a DRAM cell <ref> [12] </ref>. DRAM storage cells use pseudo-3-dimensional trench or stacked capacitors to achieve very small cell sizes [35]. As Table 2 shows, the DRAM cell size for a 64 Mb DRAM implemented in a 0.4 m CMOS process [24] is 16 times smaller than the SRAM cell size for StrongARM [37].
Reference: [13] <institution> Galileo project. http://www.cs.wisc.edu/galileo/. Computer Sciences Department, University of Wisconin - Madison. </institution>
Reference-contexts: Other research projects investigating processor-memory integration include the Galileo project at the University of Wisconsin <ref> [13] </ref>, the PPRAM project at Kyushu University in Japan [34], and the Processor-in-Memory Technology Infrastructure Development project at the University of Notre Dame. 7 Future Work There is much more work to be done in this area, concerning both low level circuit issues and high level architectural issues.
Reference: [14] <author> GARRIS, M., ET AL. </author> <title> Public Domain OCR: NIST Form-Based Handprint Recognition System. </title> <institution> National Institute of Standards and Technology, </institution> <address> http://www.nist.gov/itl/div894/894.03/ databases/defs/nist ocr.html. </address>
Reference-contexts: Hsfsys <ref> [14] </ref> is from the National Institute of Standards and Technology (NIST), and noway [36] was written at the University of Sheffield. Nowsort was developed at the University of California-Berkeley. Ghostscript (gs) and ispell are well-known utilities. The final three benchmarks are from the SPECint95 benchmark suite [42].
Reference: [15] <author> GIACALONE, G., ET AL. </author> <title> A 1 MB, 100 MHz integrated L2 cache memory with 128b interface and ECC protection. </title> <booktitle> In Digest of Technical Papers, 1996 IEEE International Solid-State Circuits Conference (San Francisco, </booktitle> <address> CA, </address> <month> Feb. </month> <year> 1996), </year> <pages> pp. 370-371. </pages>
Reference-contexts: The physical implications (including temperature and noise) of closely integrating logic and memory need to be studied. For instance, as a rule of thumb, for every increase of 10 degrees Celsius, the minimum refresh rate of a DRAM is roughly doubled <ref> [15] </ref>. Research in process development would be useful in this and other areas. Perhaps the best realization of processor-memory integration can be achieved in a hybrid CMOS process that incorporates the best features of both logic and DRAM processes.
Reference: [16] <author> GONZALEZ, R., AND HOROWITZ, M. </author> <title> Energy dissipation in general purpose microprocessors. </title> <journal> IEEE Journal of SolidState Circuits 31, </journal> <month> 9 (Sept. </month> <year> 1996), </year> <pages> 1277-1284. </pages>
Reference-contexts: Their results indicate that the instruction and data caches consume 60% of the total processor power. Gonzalez and Horowitz <ref> [16] </ref> show in their simulations that 25-40% of the energy on a microprocessor is dissipated by the on-chip caches. They note that although each individual memory cell dissipates very little energy, the total represents a very significant sum.
Reference: [17] <author> HARRIS, E., ET AL. </author> <title> Technology directions for portable computers. </title> <booktitle> In Proceedings of the IEEE (Apr. 1995), </booktitle> <volume> vol. 83, </volume> <pages> pp. 636-658. </pages>
Reference: [18] <author> HENNESSY, J., AND PATTERSON, D. </author> <booktitle> Computer Architecture: </booktitle>
Reference-contexts: In general, performance is measured by the execution time of a workload. However, we use MIPS to compare the performance of different systems on a given application since we limit our consideration to a single executable for a single instruction set architecture <ref> [18] </ref>. 3 Benefits of Processor-Memory Integration 3.1 Energy Components of Current Systems Given that portable devices, and hence energy efficient systems, are becoming more prevalent, it is useful to examine where the energy is consumed in such a device. <p> The average is shown. levels (see Table 5). It is closely modeled after the familiar equation for average memory access time <ref> [18] </ref>: Energy per instruction = AE L1 + (MR L1 fi (1 + DP L1 ) fi AE off-chip ))) where AE = access energy, MR = miss rate, and DP = dirty probability.
References-found: 18

