URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1097/CS-TR-92-1097.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1097/
Root-URL: http://www.cs.wisc.edu
Title: OPTIMIZING AND PARALLELIZING LOOPS IN OBJECT-ORIENTED DATABASE PROGRAMMING LANGUAGES  
Author: by DANIEL F. LIEUWEN 
Degree: A thesis submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Sciences) at the  
Note: This research was partially supported by a grant from AT&T Bell Laboratories, by the Defense Advanced Research Pro jects Agency under contract N00014-85-K-0788, and by a donation from Texas Instruments.  
Date: 1992  
Address: WISCONSIN MADISON  
Affiliation: UNIVERSITY OF  
Abstract-found: 0
Intro-found: 1
Reference: [ABU81] <author> Walid Abu-Sufah, David J. Kuck, and Duncan H. Lawrie. </author> <title> On the Performance Enhancement of Paging Systems Through Program Analysis and Transformations. </title> <journal> IEEE Trans. on Computers C-30,5 (May 1981), </journal> <pages> 341-355. </pages>
Reference-contexts: Thus the general idea is similar although the analysis used is different. Loop fission has been used to optimize FORTRAN programs. Loop fission breaks a single loop into several smaller loops to improve the locality of data reference. This can improve paging performance dramatically <ref> [ABU81] </ref>. Our transformations serve a similar functionbreaking a large loop into several small ones to enable database-style optimization. 2.2. RELATED PARALLELIZATION WORK Our parallelization work uses both transformations and pointer-based join techniques. We discuss the related work for each in turn. 2.2.1.
Reference: [AGRA89] <author> R. Agrawal and N. H. Gehani. </author> <title> Rationale for the Design of Persistence and Query Processing Facilities in the Database Programming Language O++. </title> <booktitle> Proc. 2nd Int. Workshop on Database Programming Languages, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: Converting the graph structure between the database and programming language format creates new opportunities for programming errors. Thus, more powerful database systems are needed. Recently, a number of object-oriented database systems (OODBSs) with the full data modelling power of a conventional programming language have been developed <ref> [AGRA89, LAMB91, LECL89, RICH92] </ref>. However, unless the query language of the OODBS is computationally complete, some computations will still need to be performed using a conventional programming language. <p> They can be optimized using standard relational techniques [SELI79] or the more complex techniques developed for OODBSs [SHAW89, BEER90, VAND91]. Instead, we will concentrate on set iterators. Since DBPLs such as PASCAL/R [SCHM77], O 2 [LECL89], E [RICH92], and O++ <ref> [AGRA89] </ref> provide constructs to iterate through a set in some unspecified order, it is possible to nest iterators to express value-based joins. <p> Joins can be implicitly expressed with a group-by loop; they can also be expressed explicitly. The SQL query (3.2) select (D.all, P.all) from Dept D, Professor P where D.did=P.did can be expressed in O++ <ref> [AGRA89] </ref> as the following join loop: (3.3) for (D of Dept; P of Professor) suchthat (D-&gt;did==P->did) D-&gt;print (); P-&gt;print (); newline (); - /* join loop */ Ignoring output formatting, the two statements are equivalent. 9 3.1. <p> Section 5.1 describes the tree representation of set loops that is used by the optimizer. Section 5.2 will show how the transformations can be expressed as tree-rewrites. Section 5.3 describes how we used these techniques to build an optimizer for the AT&T Bell Labs O++ <ref> [AGRA89] </ref> compiler. We used the resulting optimizing compiler to experimentally validate the ideas in this thesis. The experiments described in Section 5.4 show that this technique can significantly improve the performance of database programming languages. 5.1. <p> Next, the steps the optimizer goes through (along a single transformation path) to transform a group-by loop involving three sets into a better plan were traced. Both the optimizer's tree representation of the plan and the corresponding O++ <ref> [AGRA89] </ref> code were described for each step. We then described an implementation of these transformations for the O++ compiler.
Reference: [AGRA91] <author> R. Agrawal, S. Dar, and N. H. Gehani. </author> <title> The O++ Database Programming Language: Implementation and Experience. </title> <institution> AT&T Bell Labs Technical Memorandum, </institution> <year> 1991. </year>
Reference-contexts: However, our optimizations are intended to improve the performance of queries where only some of the data fits in main memory; they have only minimal impact on performance if all the data fits in main memory. Thus, a different storage manager was needed for our purposes here. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 9 <ref> [AGRA91] </ref> describes the original O++ run-time system.
Reference: [ATKI87] <author> Malcolm P. Atkinson and O. Peter Buneman. </author> <title> Types and Persistence in Database Programming Languages. </title> <journal> ACM Computing Surveys 19,2 (June 1987), </journal> <pages> 105-190. </pages>
Reference-contexts: However, relational systems have two major drawbacks. First, relational query languages (e.g. SQL) are not computationally complete. Thus, some database computations must be performed using a conventional programming language. As a result, clumsy interfaces between two languages based on different paradigms must be used <ref> [ATKI87] </ref>. This is called the impedance mismatch [VOSS91]. Second, SQL's type system is inadequate for many applications.
Reference: [ATKI89] <author> Malcolm P. Atkinson, Francois Bancilhon, David DeWitt, Klaus Dittrich, David Maier, and Stanley Zdonik. </author> <title> The Object-Oriented Database System Manifesto, invited paper, </title> <booktitle> 1st Int. Conf. on DOOD (Deductive and Object-Oriented Databases), </booktitle> <address> Japan, </address> <month> December, </month> <year> 1989. </year>
Reference-contexts: Since the language of the OODBS is more complex than SQL, this would require a very complex interface between the OODBS and the programming language. Thus, many researchers believe that an OODBS must include computa-tionally complete language for data retrieval and modification <ref> [ATKI89] </ref>. Since an OODBS includes sets, computational completeness includes the ability to iterate through a set. However, giving programmers this power allows them to write programs that can be orders of magnitude slower than the desired computation should be. The programs can also be very difficult to parallelize.
Reference: [BATE90] <author> Samuel Bates, </author> <title> private communication. </title>
Reference-contexts: If the right-hand side of (4.2) evaluates to a positive integer and v is known to be positive, a /= operation of the above form is also self-commutative ignoring overflow <ref> [BATE90] </ref>. (The result of integer division where one of the operands is negative is implementation dependent in the C language.) The "variable" v may also be a field of an iterator variable Xi-&gt;fj provided Xi-&gt;fj is not used by a loop predicate or examined by any statements in Sm1 except implicitly
Reference: [BEER90] <author> C. Beeri and Y. Kornatzky. </author> <title> Algebraic Optimization of Object-Oriented Query Languages. </title> <booktitle> Proc. 1990 Int. Conf. Database Theory, </booktitle> <month> December </month> <year> 1990. </year>
Reference-contexts: In this thesis, we ignore the optimization of joins written in a non-procedural fashion. They can be optimized using standard relational techniques [SELI79] or the more complex techniques developed for OODBSs <ref> [SHAW89, BEER90, VAND91] </ref>. Instead, we will concentrate on set iterators. Since DBPLs such as PASCAL/R [SCHM77], O 2 [LECL89], E [RICH92], and O++ [AGRA89] provide constructs to iterate through a set in some unspecified order, it is possible to nest iterators to express value-based joins.
Reference: [BUTT91] <author> Paul Butterworth, Allen Otis, and Jacob Stein. </author> <title> The GemStone Object Database Management System. </title> <journal> CACM 34,10 (October 1991), </journal> <pages> 64-77. </pages>
Reference: [CARE86] <author> Michael Carey, David DeWitt, Joel Richardson, and Eugene Shekita. </author> <title> Object and File Management in the EXODUS Extensible Database System. </title> <booktitle> Proc. 1986 Conf. Very Large Databases, </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: Thus, a different storage manager was needed for our purposes here. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 9 [AGRA91] describes the original O++ run-time system. It also contains examples of translating O++ code into C++ code. 63 We used Version 2.0.2 of the EXODUS Storage Manager <ref> [CARE86] </ref> to hold our test database. 10 In order to minimize the number of changes that needed to be made to the O++ compiler, we wrote C++ classes with interfaces that were very similar to the interfaces of the classes used by the original O++ storage manager for accessing and creating <p> Only minor changes to the original compiler were requiredthe new code was localized in two "black boxes": an optimizer built using the EXODUS Optimizer Generator [GRAE87] and a code generator for plans. A brief description of a new run-time system built on top of the EXODUS Storage Manager <ref> [CARE86] </ref> was also given. The resulting optimizing compiler was used to empirically demonstrate that our transformations can significantly improve the performance of a DBPL.
Reference: [CARE90] <author> Michael Carey, Eugene Shekita, George Lapis, Bruce Lindsay, and John McPherson. </author> <title> An Incremental Join Attachment for Starburst. </title> <booktitle> Proc. 1990 Conf. Very Large Databases, </booktitle> <month> August </month> <year> 1990. </year> <month> 122 </month>
Reference-contexts: algorithm, and showed that a more elaborate join algorithm using join indices could frequently produce better performance than Hybrid-hash in a uniprocessor system. [OMIE89] compared the two algorithms in a parallel environment and showed that Hybrid-hash will almost always outperform join indices except when the join selectivity is very high. <ref> [CARE90] </ref> describes an incremental join facility added to Starburst to enable a relational DBMS to efficiently handle many-to-one relationships. The set representation employed is similar to the representation provided by network database systems.
Reference: [DAYA87] <author> Umeshwar Dayal. </author> <title> Of Nests and Trees: A Unified Approach to Process Queries That Contain Nested Subqueries, Aggregates, and Quantifiers. </title> <booktitle> Proc. 1987 Conf. Very Large Databases, </booktitle> <month> August </month> <year> 1987. </year>
Reference-contexts: Other transformations take a more complicated nested query and produce two or more subqueries that compute the same result. Some subqueries are not flat, but their nesting patterns are simpler than the nesting pattern of the untransformed query. These subqueries can be simplified further by other transformations. <ref> [DAYA87, GANS87, MURA89] </ref> corrected errors in Kim's technique by replacing joins with outerjoins. [DAYA87, MURA89] developed pipelining techniques that remove some of the temporary relations introduced by Kim's technique. [MUMI90] uses this prior work to convert queries with nested query blocks into a series of queries and view definitions. <p> Some subqueries are not flat, but their nesting patterns are simpler than the nesting pattern of the untransformed query. These subqueries can be simplified further by other transformations. [DAYA87, GANS87, MURA89] corrected errors in Kim's technique by replacing joins with outerjoins. <ref> [DAYA87, MURA89] </ref> developed pipelining techniques that remove some of the temporary relations introduced by Kim's technique. [MUMI90] uses this prior work to convert queries with nested query blocks into a series of queries and view definitions.
Reference: [DEMO85] <author> G. Barbara Demo and Sukhamay Kundu. </author> <title> Analysis of the Context Dependency of CODASYL FIND-statements with Application to Database Program Conversion. </title> <booktitle> Proc. 1985 SIGMOD, </booktitle> <month> May </month> <year> 1985. </year>
Reference-contexts: This algebra also does not recognize that certain nested loops are semantically equivalent to joins, an observation that our optimizer exploits. Our work is similar to work done in <ref> [KATZ82, DEMO85] </ref> to decompile CODASYL DML into embedded relational queries. In [KATZ85], data flow analysis and pattern matching are used to transform CODASYL DML statements into DAPLEX-like statements. This transformation makes some flow of control statements unnecessary, so these statements are removed. <p> In [KATZ85], data flow analysis and pattern matching are used to transform CODASYL DML statements into DAPLEX-like statements. This transformation makes some flow of control statements unnecessary, so these statements are removed. Finally, the DAPLEX-like statements are transformed into relational queries. <ref> [DEMO85] </ref> uses a more sophisticated analysis to decompile a larger class of programs. Both our work and theirs tries to take an imperative program and make it as declarative as possible while maintaining the program semantics. Both use dataflow analysis and pattern matching.
Reference: [DEUX91] <editor> O. Deux et al. </editor> <title> The O 2 System. </title> <journal> CACM 34,10 (October 1991), </journal> <pages> 34-48. </pages>
Reference-contexts: Thus, the decision of several commercial object database vendors <ref> [DEUX91, LAMB91, LECL89] </ref> to supply indices before supplying transformations is a reasonable one. However, as demonstrated above, to maximize performance, both access-path-selection and transformations are ultimately needed. 77 5.5. SUMMARY This chapter described how standard transformation-based technology can be used to optimize group-by loops.
Reference: [DEWI84] <author> David DeWitt, Randy Katz, Frank Olken, Leonard Shapiro, Michael Stonebraker, and David Wood. </author> <title> Implementation Techniques for Main Memory Database Systems. </title> <booktitle> Proc. 1984 SIGMOD, </booktitle> <month> June </month> <year> 1984. </year>
Reference-contexts: Thus, joins are a very important operation. Unfortunately, they can also be very expensive to compute. As a result, a large amount of research on relational databases has been aimed at computing joins efficiently <ref> [SELI79, JARK84, DEWI84, GERB86, SCHN89, MUMI90, DEWI92b] </ref>. For an OODBS to satisfy customer performance requirements, it must effectively optimize joins. <p> This is necessary to get an accurate estimate of the cost of the nested-loops join algorithm. 15 In this chapter, we will assume that queries are evaluated using the centralized Hybrid-hash algorithm. <ref> [DEWI84] </ref> describes the Hybrid-hash algorithm as follows: (1) Scan R, selecting those objects of R that satisfy the selection criterion, projecting out unnecessary attributes to produce R'. <p> Thus, the join is broken into N smaller joins. If the hash function produces an R i $i 1iN partition that will not fit in the available memory, an overflow tactic like Simple Hash Join <ref> [DEWI84] </ref> must be employed. <p> The cost of executing a query using the Hybrid-hash algorithm is: P R + P S Read R and S + (P R' +P S' ) . 2 . (1-q) Writing and rereading hash partitions 16 Our formula for Hybrid-hash is similar to the one in <ref> [DEWI84] </ref>. There are only two differences: (1) following [SHAP86], we do not distinguish between random and sequential I/O, 6 and (2) R' and S' replace R and S in the definitions of B and q and in the second line of the cost formula. <p> Figure 3.1 compares the performance predicted by the analysis of the untransformed simple group-by loop (3.9) and the optimized query (T1) when P Set1 = 250 and P Set2 = 5000. Following <ref> [DEWI84] </ref>, we assume F = 1.2. The size of memory was increased in 200 page increments until increasing the memory size did not change performance. The curves flatten when the inner set's hash table fits entirely in main memory, since then each set is read only once. <p> If the match was found during hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 9 A variant of this algorithm would only keep parents that have unseen children. This requires a write of such parents during step (b). The variant has some similarities to the Simple-Hash join algorithm <ref> [DEWI84] </ref>. In both, the tuples that need to be processed later are written to a new file and that new file is used for the next iteration. The actual Probe-child join algorithm, however, proceeds in much the same way as the Hashed Loops join algorithm for centralized databases [GERB86]. <p> Thus, M i pages are available for the hash table and the output buffers at node i . Using reasoning from <ref> [DEWI84] </ref>, B i R J M i P i HH hhhhhhhhhhhhhhhh H J output buffers are needed and the fraction 104 HH-H = min J L P i M i HH-H hhhhhhhhhhhhh M J of the pages of Set2 i -tuples can be put in the hash table (the min is <p> Since the space requirements of step (1) of Hybrid-hash/page-pointer and step (2) of Hybrid-hash/node pointer for repartitioning Set1 are identical, M i HH pages are available for the hash table and the output buffers at node i . Using analysis in <ref> [DEWI84] </ref>, B i R J M i P i HH hhhhhhhhhhhhhh H J output buffers will be needed, and the fraction q i I J 1.0, HH . F HH - B i hhhhhhhhhhhhh M J of the arriving pages of Set1-tuples can be put in the hash table.
Reference: [DEWI91] <author> David DeWitt, Jeffrey Naughton, and Donovan Schneider. </author> <title> A comparison of non-equijoin algorithms. </title> <booktitle> Proc. 1991 Conf. Very Large Databases, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: An equi-join involving two extents will not require replication. However, some algorithms for band-joins require replicating elements of one of the sets <ref> [DEWI91] </ref>. If an object is replicated, merging the updates made to different copies of the object may be impossible. 82 Unfortunately, not all set loops parallelize so nicely. Some loops must be executed sequentially to avoid violating the sequential semantics of the program. Consider a database of pictures of people.
Reference: [DEWI92a] <author> David DeWitt and Jim Gray. </author> <title> Parallel Database Systems: The Future of High Performance Database Systems. </title> <journal> CACM 35,6 (June 1992), </journal> <pages> 85-98. </pages>
Reference-contexts: RELATED PARALLELIZATION WORK Our parallelization work uses both transformations and pointer-based join techniques. We discuss the related work for each in turn. 2.2.1. Related Transformation Work An enormous amount of work has been done on parallelizing relational queries (e.g. <ref> [GERB86, SCHN89, GRAE90, KITS90, WOLF90, HUA91, WALT91, DEWI92a] </ref>). Other work has been on parallelizing loops in FORTRAN (e.g. [PADU86, WOLF86, WOLF89]) and in LISP [LARU89]. All this work makes extensive use of program transformations. [HART88, HART89] discuss their parallelizing compiler for FAD, a functional DBPL. <p> Section 6.3 presents and analyzes algorithms for computing joins involving set-valued attributes. 6.1. PARALLELISM BOUNDARY CONDITIONS It is well known that relational joins can be executed in a highly-parallel manner <ref> [DEWI92a] </ref>. Many join loops can be parallelized to the same extent by modifying parallel join algorithms so that they execute program statements rather than produce result tuples. <p> Many join loops can be parallelized to the same extent by modifying parallel join algorithms so that they execute program statements rather than produce result tuples. As an example, consider parallelizing query (6.1) using a modified Hybrid-hash algorithm <ref> [GERB86, SCHN89, DEWI92a] </ref>: (6.1) for (D of Dept; P of Professor) suchthat (D-&gt;did==P->did) - Insert &lt;D-&gt;name,P->name,P->sal> into PayInfo; D-&gt;budget += P-&gt;sal; profcount++; - To simplify the description of the parallelization of query (6.1), assume that the Dept and Professor objects are declustered [RIES78, LIVN87, GHAN90] across the same n nodes, that <p> This section describes, analyzes, and compares four execution strategies for loops like (6.6): the Hash-loops [SHEK90, MEHT91], the Probe-children, the Hybrid-hash/node-pointer [MEHT91], and the Hybrid-hash/page-pointer [MEHT91] join algorithms. It also contains the Find-children algorithm which allows algorithms like <ref> [GERB86, SCHN89, DEWI92a] </ref>'s parallel Hybrid-hash and our Probe-children join algorithm to be used even when an explicit extent of children of Set1 does not exist. <p> Otherwise, it will be better to replicate each Set1 object once per child pointer, repartition both Set1 and Set2 (tagging each Set2-tuple with its oid), and use a standard parallel Hybrid-hash algorithm <ref> [GERB86, SCHN89, DEWI92a] </ref> with the oids as join attributesin which case we would expect performance similar to Hybrid-hash/node-pointer 113 in Figure 6.9 after shifting it up about 19 seconds everywhere to account for having approximately twice as much to read in order to partition Set2 at the node with tuple-placement-skew.
Reference: [DEWI92b] <author> David DeWitt, Jeffrey Naughton, Donovan Schneider, and S. Seshadri. </author> <title> Practical Skew Handling Algorithms For Parallel Joins. </title> <booktitle> Proc. 1992 Conf. Very Large Databases, </booktitle> <month> August </month> <year> 1992, </year> <note> to appear. </note>
Reference-contexts: Thus, joins are a very important operation. Unfortunately, they can also be very expensive to compute. As a result, a large amount of research on relational databases has been aimed at computing joins efficiently <ref> [SELI79, JARK84, DEWI84, GERB86, SCHN89, MUMI90, DEWI92b] </ref>. For an OODBS to satisfy customer performance requirements, it must effectively optimize joins. <p> A hash function that ignores the node but uses the page and slot identifier from the pointer should produce fairly uniformly sized partitions. Alternatively, a skew resistant join technique <ref> [KITS90, WOLF90, HUA91, WALT91, DEWI92b] </ref> might be used after producing Set1-tuples. Note that the Find-children algorithm must be used to allow either of these techniques if Set2 is not an explicit extent. 6.3.7.4.
Reference: [GANS87] <author> Richard A. Ganski and Harry K. T. Wong. </author> <title> Optimization of Nested SQL Queries Revisited. </title> <booktitle> Proc. 1987 SIGMOD, </booktitle> <month> May </month> <year> 1987. </year>
Reference-contexts: Other transformations take a more complicated nested query and produce two or more subqueries that compute the same result. Some subqueries are not flat, but their nesting patterns are simpler than the nesting pattern of the untransformed query. These subqueries can be simplified further by other transformations. <ref> [DAYA87, GANS87, MURA89] </ref> corrected errors in Kim's technique by replacing joins with outerjoins. [DAYA87, MURA89] developed pipelining techniques that remove some of the temporary relations introduced by Kim's technique. [MUMI90] uses this prior work to convert queries with nested query blocks into a series of queries and view definitions.
Reference: [GERB86] <author> Robert Gerber. </author> <title> Ph.D Thesis. Dataflow Query Processing using Multiprocessor Hash-partitioned Algorithms. </title> <institution> University of Wisconsin (1986). </institution>
Reference-contexts: Thus, joins are a very important operation. Unfortunately, they can also be very expensive to compute. As a result, a large amount of research on relational databases has been aimed at computing joins efficiently <ref> [SELI79, JARK84, DEWI84, GERB86, SCHN89, MUMI90, DEWI92b] </ref>. For an OODBS to satisfy customer performance requirements, it must effectively optimize joins. <p> RELATED PARALLELIZATION WORK Our parallelization work uses both transformations and pointer-based join techniques. We discuss the related work for each in turn. 2.2.1. Related Transformation Work An enormous amount of work has been done on parallelizing relational queries (e.g. <ref> [GERB86, SCHN89, GRAE90, KITS90, WOLF90, HUA91, WALT91, DEWI92a] </ref>). Other work has been on parallelizing loops in FORTRAN (e.g. [PADU86, WOLF86, WOLF89]) and in LISP [LARU89]. All this work makes extensive use of program transformations. [HART88, HART89] discuss their parallelizing compiler for FAD, a functional DBPL. <p> Many join loops can be parallelized to the same extent by modifying parallel join algorithms so that they execute program statements rather than produce result tuples. As an example, consider parallelizing query (6.1) using a modified Hybrid-hash algorithm <ref> [GERB86, SCHN89, DEWI92a] </ref>: (6.1) for (D of Dept; P of Professor) suchthat (D-&gt;did==P->did) - Insert &lt;D-&gt;name,P->name,P->sal> into PayInfo; D-&gt;budget += P-&gt;sal; profcount++; - To simplify the description of the parallelization of query (6.1), assume that the Dept and Professor objects are declustered [RIES78, LIVN87, GHAN90] across the same n nodes, that <p> This section describes, analyzes, and compares four execution strategies for loops like (6.6): the Hash-loops [SHEK90, MEHT91], the Probe-children, the Hybrid-hash/node-pointer [MEHT91], and the Hybrid-hash/page-pointer [MEHT91] join algorithms. It also contains the Find-children algorithm which allows algorithms like <ref> [GERB86, SCHN89, DEWI92a] </ref>'s parallel Hybrid-hash and our Probe-children join algorithm to be used even when an explicit extent of children of Set1 does not exist. <p> In both, the tuples that need to be processed later are written to a new file and that new file is used for the next iteration. The actual Probe-child join algorithm, however, proceeds in much the same way as the Hashed Loops join algorithm for centralized databases <ref> [GERB86] </ref>. Both build a memory-sized hash table for some fraction of the inner set Set2. They read the whole (local partition of the) set of Set1-tuples to probe the hash table. This continues until all of Set2 has been processed. <p> Otherwise, it will be better to replicate each Set1 object once per child pointer, repartition both Set1 and Set2 (tagging each Set2-tuple with its oid), and use a standard parallel Hybrid-hash algorithm <ref> [GERB86, SCHN89, DEWI92a] </ref> with the oids as join attributesin which case we would expect performance similar to Hybrid-hash/node-pointer 113 in Figure 6.9 after shifting it up about 19 seconds everywhere to account for having approximately twice as much to read in order to partition Set2 at the node with tuple-placement-skew.
Reference: [GHAN90] <author> Shahram Ghandeharizadeh. </author> <type> Ph.D Thesis. </type> <institution> Physical Database Design in Multiprocessor Database Systems. University of Wisconsin (1990). </institution>
Reference-contexts: parallelizing query (6.1) using a modified Hybrid-hash algorithm [GERB86, SCHN89, DEWI92a]: (6.1) for (D of Dept; P of Professor) suchthat (D-&gt;did==P->did) - Insert &lt;D-&gt;name,P->name,P->sal> into PayInfo; D-&gt;budget += P-&gt;sal; profcount++; - To simplify the description of the parallelization of query (6.1), assume that the Dept and Professor objects are declustered <ref> [RIES78, LIVN87, GHAN90] </ref> across the same n nodes, that these n nodes will be used to execute the join, and that all of the Dept objects will fit in the aggregate memory of the n processors.
Reference: [GRAY92] <author> Jim Gray, </author> <title> private communication. </title>
Reference-contexts: Applying the techniques developed here to nested SQL cursors embedded in COBOL or C would also be interesting. This is a common programming paradigmbecause some users don't trust the optimizer, while others need functionality like outerjoins that their system does not provide <ref> [GRAY92] </ref>. These applications may eventually need to be run on a parallel system, and to gain the benefits of parallelism, these programs must be rewritten to remove the nested cursors. This is a time-consuming task that is likely to add programming errors.
Reference: [GRAE87] <author> Goetz Graefe. </author> <type> Ph.D. Thesis. </type> <note> Rule-Base Query Optimization in Extensible Database Systems. </note> <institution> University of Wisconsin (1987). </institution>
Reference-contexts: While this is a good representation from which to generate code, it is a poor one for database-style optimization. We wished to use an optimizer generator <ref> [GRAE87, LOHM88] </ref>, a tool that take a set of rules and produces an optimizer. However, the EXODUS Optimizer Generator (OptGen), the only generator we had access to, expects all operators to have fixed arity. <p> This is not necessarypredicates involving such variables can be handled, but handling them requires complicating the representation and the exposition. The tree representation used here is different from a typical representation used to represent relational joins, the left deep query tree <ref> [GRAE87] </ref>. A tree's cost function cannot be evaluated bottom up unless each leaf node maintains information about how many times the set loop corresponding to the node is expected to be executed (For example, the value would be one for the X1 node in (5.2). <p> Pred32 (X1,X2,X3)) ||g (JPred: Pred22 (X1,X2)) X3Var = Supernode First = NULL Second = NULL X1 X2 First = S41 Second = NULL two applications of Supernoding transformation Note that the tree representation in Figure 5.6 would closely resemble a standard tree representation for relational joins, the left-deep query tree <ref> [GRAE87] </ref>, if the Supernodes were removed from the tree. 5.2.1. Simple group-by loops Having introduced our basic terminology and the tree representation that is used for unoptimized queries, we next show how some of the transformations presented in Chapter 3 can be represented as tree rewrites. <p> We then described an implementation of these transformations for the O++ compiler. Only minor changes to the original compiler were requiredthe new code was localized in two "black boxes": an optimizer built using the EXODUS Optimizer Generator <ref> [GRAE87] </ref> and a code generator for plans. A brief description of a new run-time system built on top of the EXODUS Storage Manager [CARE86] was also given. The resulting optimizing compiler was used to empirically demonstrate that our transformations can significantly improve the performance of a DBPL.
Reference: [GRAE90] <author> Goetz Graefe. </author> <title> Encapsulation of Parallelism in the Volcano Query Processing System. </title> <booktitle> Proc. </booktitle> <year> 1990 </year> <month> SIG-MOD, May </month> <year> 1990. </year>
Reference-contexts: RELATED PARALLELIZATION WORK Our parallelization work uses both transformations and pointer-based join techniques. We discuss the related work for each in turn. 2.2.1. Related Transformation Work An enormous amount of work has been done on parallelizing relational queries (e.g. <ref> [GERB86, SCHN89, GRAE90, KITS90, WOLF90, HUA91, WALT91, DEWI92a] </ref>). Other work has been on parallelizing loops in FORTRAN (e.g. [PADU86, WOLF86, WOLF89]) and in LISP [LARU89]. All this work makes extensive use of program transformations. [HART88, HART89] discuss their parallelizing compiler for FAD, a functional DBPL.
Reference: [HART88] <author> Brian Hart, Scott Danforth, and Patrick Valduriez. </author> <title> Parallelizing a Database Programming Language. </title> <booktitle> 1988 Int. Symposium on Databases in Parallel and Dist. Syst., </booktitle> <month> December </month> <year> 1988. </year> <month> 123 </month>
Reference-contexts: Other work has been on parallelizing loops in FORTRAN (e.g. [PADU86, WOLF86, WOLF89]) and in LISP [LARU89]. All this work makes extensive use of program transformations. <ref> [HART88, HART89] </ref> discuss their parallelizing compiler for FAD, a functional DBPL. They use analysis to determine if a program can correctly be executed in parallelbringing all the data to a central site and executing the program there is the default. They target their techniques toward a parallel, shared-nothing architecture.
Reference: [HART89] <author> Brian Hart, Patrick Valduriez, and Scott Danforth. </author> <title> Parallelizing FAD using Compile-time Analysis Techniques. </title> <booktitle> Data Engineering 12,1 (March 1989), </booktitle> <pages> 9-15. </pages>
Reference-contexts: Other work has been on parallelizing loops in FORTRAN (e.g. [PADU86, WOLF86, WOLF89]) and in LISP [LARU89]. All this work makes extensive use of program transformations. <ref> [HART88, HART89] </ref> discuss their parallelizing compiler for FAD, a functional DBPL. They use analysis to determine if a program can correctly be executed in parallelbringing all the data to a central site and executing the program there is the default. They target their techniques toward a parallel, shared-nothing architecture.
Reference: [HUA91] <author> Kien Hua and Chiang Lee. </author> <title> Handling Data Skew in Multiprocessor Database Computers Using Partition Tuning. </title> <booktitle> Proc. 1991 Conf. Very Large Databases, </booktitle> <month> September </month> <year> 1991. </year>
Reference-contexts: RELATED PARALLELIZATION WORK Our parallelization work uses both transformations and pointer-based join techniques. We discuss the related work for each in turn. 2.2.1. Related Transformation Work An enormous amount of work has been done on parallelizing relational queries (e.g. <ref> [GERB86, SCHN89, GRAE90, KITS90, WOLF90, HUA91, WALT91, DEWI92a] </ref>). Other work has been on parallelizing loops in FORTRAN (e.g. [PADU86, WOLF86, WOLF89]) and in LISP [LARU89]. All this work makes extensive use of program transformations. [HART88, HART89] discuss their parallelizing compiler for FAD, a functional DBPL. <p> A hash function that ignores the node but uses the page and slot identifier from the pointer should produce fairly uniformly sized partitions. Alternatively, a skew resistant join technique <ref> [KITS90, WOLF90, HUA91, WALT91, DEWI92b] </ref> might be used after producing Set1-tuples. Note that the Find-children algorithm must be used to allow either of these techniques if Set2 is not an explicit extent. 6.3.7.4.
Reference: [JARK84] <author> Matthias Jarke and Jurgen Koch. </author> <title> Query Optimization in Database Systems. </title> <journal> ACM Computing Surveys 16,2 (June 1984), </journal> <pages> 111-152. </pages>
Reference-contexts: Since their query languages are non-procedural, the system has a great deal of latitude in how it chooses to compute a query result. To take advantage of this latitude, relational database systems use very complex optimizers that search a space of alternative query plans for the least expensive alternative <ref> [SELI79, JARK84] </ref>. The resulting plan will often be orders of magnitude faster than a naive implementation. However, relational systems have two major drawbacks. First, relational query languages (e.g. SQL) are not computationally complete. Thus, some database computations must be performed using a conventional programming language. <p> Thus, joins are a very important operation. Unfortunately, they can also be very expensive to compute. As a result, a large amount of research on relational databases has been aimed at computing joins efficiently <ref> [SELI79, JARK84, DEWI84, GERB86, SCHN89, MUMI90, DEWI92b] </ref>. For an OODBS to satisfy customer performance requirements, it must effectively optimize joins.
Reference: [KATZ82] <author> R. H. Katz and E. Wong. </author> <title> Decompiling CODASYL DML into Relational Queries. </title> <journal> ACM Trans. Database Syst. </journal> <month> 7,1 (March </month> <year> 1982), </year> <pages> 1-23. </pages>
Reference-contexts: This algebra also does not recognize that certain nested loops are semantically equivalent to joins, an observation that our optimizer exploits. Our work is similar to work done in <ref> [KATZ82, DEMO85] </ref> to decompile CODASYL DML into embedded relational queries. In [KATZ85], data flow analysis and pattern matching are used to transform CODASYL DML statements into DAPLEX-like statements. This transformation makes some flow of control statements unnecessary, so these statements are removed.
Reference: [KHOS86] <author> Setrag Khoshafian and George Copeland. </author> <title> Object Identify. </title> <booktitle> Proc. 1986 OOPSLA, </booktitle> <month> September </month> <year> 1986. </year>
Reference: [KIM80] <author> Won Kim. </author> <title> A New Way to Compute the Product and Join of Relations. </title> <booktitle> Proc. 1980 SIGMOD, </booktitle> <month> May </month> <year> 1980. </year>
Reference-contexts: Otherwise, the result of the computation will (potentially) be non-deterministic. 3 Such statements are likely to be errors. We also note that we cannot execute group-by loops using a blocked-nested loop join algorithm <ref> [KIM80] </ref> unless Sm1, the inner statement, is self-commutative. To see this, suppose that blocked-nested-loops is used to execute hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 2 We are using FORTRAN optimization terminology.
Reference: [KIM82] <author> Won Kim. </author> <title> On Optimizing an SQL-like Nested Query. </title> <journal> ACM Trans. Database Syst. </journal> <month> 7,3 (September </month> <year> 1982), </year> <pages> 443-469. </pages>
Reference-contexts: Their work (once modified to take grouping constraints into account) can be used as a preprocessing step that allows our transformations to be applied. The work in this thesis is also related to the work on transforming nested query blocks in SQL into equivalent queries with no nesting <ref> [KIM82] </ref>. The style of transformation is similar. [KIM82] starts with a simple kind of nested query and shows how to transform it into a join query that does not have a nested query in the where clause. <p> The work in this thesis is also related to the work on transforming nested query blocks in SQL into equivalent queries with no nesting <ref> [KIM82] </ref>. The style of transformation is similar. [KIM82] starts with a simple kind of nested query and shows how to transform it into a join query that does not have a nested query in the where clause. Other transformations take a more complicated nested query and produce two or more subqueries that compute the same result.
Reference: [KITS90] <author> Masaru Kitsuregawa and Yasushi Ogawa. </author> <title> Bucket Spreading Parallel Hash: A New, Robust, Parallel Hash Join Method for Data Skew in the Super Database Computer (SDC). </title> <booktitle> Proc. 1990 Conf. Very Large Databases, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: RELATED PARALLELIZATION WORK Our parallelization work uses both transformations and pointer-based join techniques. We discuss the related work for each in turn. 2.2.1. Related Transformation Work An enormous amount of work has been done on parallelizing relational queries (e.g. <ref> [GERB86, SCHN89, GRAE90, KITS90, WOLF90, HUA91, WALT91, DEWI92a] </ref>). Other work has been on parallelizing loops in FORTRAN (e.g. [PADU86, WOLF86, WOLF89]) and in LISP [LARU89]. All this work makes extensive use of program transformations. [HART88, HART89] discuss their parallelizing compiler for FAD, a functional DBPL. <p> A hash function that ignores the node but uses the page and slot identifier from the pointer should produce fairly uniformly sized partitions. Alternatively, a skew resistant join technique <ref> [KITS90, WOLF90, HUA91, WALT91, DEWI92b] </ref> might be used after producing Set1-tuples. Note that the Find-children algorithm must be used to allow either of these techniques if Set2 is not an explicit extent. 6.3.7.4.
Reference: [KORT91] <author> Henry Korth and Abraham Silberschatz. </author> <title> Database System Concepts (2nd edition). </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1991. </year>
Reference: [LAMB91] <author> Charles Lamb, Gordon Landis, Jack Orenstein, and Dan Weinreb. </author> <title> The ObjectStore Database System. </title> <journal> CACM 34,10 (October 1991), </journal> <pages> 50-63. </pages>
Reference-contexts: Converting the graph structure between the database and programming language format creates new opportunities for programming errors. Thus, more powerful database systems are needed. Recently, a number of object-oriented database systems (OODBSs) with the full data modelling power of a conventional programming language have been developed <ref> [AGRA89, LAMB91, LECL89, RICH92] </ref>. However, unless the query language of the OODBS is computationally complete, some computations will still need to be performed using a conventional programming language. <p> Thus, the decision of several commercial object database vendors <ref> [DEUX91, LAMB91, LECL89] </ref> to supply indices before supplying transformations is a reasonable one. However, as demonstrated above, to maximize performance, both access-path-selection and transformations are ultimately needed. 77 5.5. SUMMARY This chapter described how standard transformation-based technology can be used to optimize group-by loops.
Reference: [LARU89] <author> James Larus. </author> <title> Ph.D Thesis. Restructuring Symbolic Programs for Concurrent Execution on Multiprocessors. </title> <institution> University of California (1989). </institution>
Reference-contexts: Related Transformation Work An enormous amount of work has been done on parallelizing relational queries (e.g. [GERB86, SCHN89, GRAE90, KITS90, WOLF90, HUA91, WALT91, DEWI92a]). Other work has been on parallelizing loops in FORTRAN (e.g. [PADU86, WOLF86, WOLF89]) and in LISP <ref> [LARU89] </ref>. All this work makes extensive use of program transformations. [HART88, HART89] discuss their parallelizing compiler for FAD, a functional DBPL. They use analysis to determine if a program can correctly be executed in parallelbringing all the data to a central site and executing the program there is the default. <p> It is currently an implementation technique; we would like to produce an algebra. Incorporating object sharing dataflow analysis of the sort described in <ref> [LARU89] </ref> is also a priority. Our dependence analysis is currently very conservative, and we would like to improve it. Applying the techniques developed here to nested SQL cursors embedded in COBOL or C would also be interesting.
Reference: [LIVN87] <author> M. Livny, S. Khoshafian, and H. Boral. </author> <title> Multi-Disk Management Algorithms. </title> <booktitle> Proc. </booktitle> <year> 1987 </year> <month> SIG-METRICS, May </month> <year> 1987. </year>
Reference-contexts: parallelizing query (6.1) using a modified Hybrid-hash algorithm [GERB86, SCHN89, DEWI92a]: (6.1) for (D of Dept; P of Professor) suchthat (D-&gt;did==P->did) - Insert &lt;D-&gt;name,P->name,P->sal> into PayInfo; D-&gt;budget += P-&gt;sal; profcount++; - To simplify the description of the parallelization of query (6.1), assume that the Dept and Professor objects are declustered <ref> [RIES78, LIVN87, GHAN90] </ref> across the same n nodes, that these n nodes will be used to execute the join, and that all of the Dept objects will fit in the aggregate memory of the n processors.
Reference: [LECL89] <author> C. Lecluse and P. Richard. </author> <title> The O 2 Database Programming Language. </title> <booktitle> Proc. 1989 Conf. Very Large Databases, </booktitle> <month> August </month> <year> 1989. </year> <month> 124 </month>
Reference-contexts: Converting the graph structure between the database and programming language format creates new opportunities for programming errors. Thus, more powerful database systems are needed. Recently, a number of object-oriented database systems (OODBSs) with the full data modelling power of a conventional programming language have been developed <ref> [AGRA89, LAMB91, LECL89, RICH92] </ref>. However, unless the query language of the OODBS is computationally complete, some computations will still need to be performed using a conventional programming language. <p> In this thesis, we ignore the optimization of joins written in a non-procedural fashion. They can be optimized using standard relational techniques [SELI79] or the more complex techniques developed for OODBSs [SHAW89, BEER90, VAND91]. Instead, we will concentrate on set iterators. Since DBPLs such as PASCAL/R [SCHM77], O 2 <ref> [LECL89] </ref>, E [RICH92], and O++ [AGRA89] provide constructs to iterate through a set in some unspecified order, it is possible to nest iterators to express value-based joins. <p> Thus, the decision of several commercial object database vendors <ref> [DEUX91, LAMB91, LECL89] </ref> to supply indices before supplying transformations is a reasonable one. However, as demonstrated above, to maximize performance, both access-path-selection and transformations are ultimately needed. 77 5.5. SUMMARY This chapter described how standard transformation-based technology can be used to optimize group-by loops.
Reference: [LIEU91] <author> Daniel Lieuwen and David DeWitt, </author> <title> Optimizing Loops in Database Programming Languages. </title> <booktitle> Proc. 3rd Int. Workshop on Database Programming Languages, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: All the fields of last will be NULL when T is the first element of Temp; all the fields of next will be NULL when T is the last element of Temp. The associativity rewrite is the following: 9 hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 9 (T6) in <ref> [LIEU91] </ref> was incorrect, so this (T6) differs from the one there. 30 (T6) Temp = []; /* Empty sequence */ for (X2 of Set2) suchthat (Pred2'(X2)) - for (X3 of Set3) suchthat (Pred3'(X2,X3)) Append &lt;oid (X2),Needed (X2),Needed (X3)&gt; to Temp; if (nothing was added to Temp in for X3 loop) Append
Reference: [LIEU92] <author> Daniel Lieuwen and David DeWitt, </author> <title> A Transformation-based Approach to Optimizing Loops in Database Programming Languages. </title> <booktitle> Proc. 1992 SIGMOD, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: The client had a 2 megabyte (500 4K page) buffer pool; the server had a 600K (150 4K page) buffer pool. 11 The schema was as follows: hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 10 Earlier experiments reported in <ref> [LIEU92] </ref> were run on Version 1.2 of the EXODUS Storage Manager. We moved to the newer version to have access to the B-trees provided by the new release. 11 In [LIEU92], we used a 10 megabyte buffer pool on a DECstation 3100, and our buffer pool could hold approximately 70% of <p> had a 600K (150 4K page) buffer pool. 11 The schema was as follows: hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 10 Earlier experiments reported in <ref> [LIEU92] </ref> were run on Version 1.2 of the EXODUS Storage Manager. We moved to the newer version to have access to the B-trees provided by the new release. 11 In [LIEU92], we used a 10 megabyte buffer pool on a DECstation 3100, and our buffer pool could hold approximately 70% of the database. To make our examples more realistic, we wanted to decrease the fraction of the database that fits in the buffer pool. <p> To do this, we compare the hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 13 The names created by the compiler for the optimized code were simplified by hand. 14 If more examples are desired, see <ref> [LIEU92] </ref>. [LIEU92] contains two other queries in the experimental sections, shows how they are optimized by an earlier version of the system (which did not have indices), and gives timing information for running the queries. One optimized implementation for each plan was shown. <p> To do this, we compare the hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 13 The names created by the compiler for the optimized code were simplified by hand. 14 If more examples are desired, see <ref> [LIEU92] </ref>. [LIEU92] contains two other queries in the experimental sections, shows how they are optimized by an earlier version of the system (which did not have indices), and gives timing information for running the queries. One optimized implementation for each plan was shown. <p> One optimized implementation for each plan was shown. Producing the optimized versions described in this section required using all of the transformations used in the two examples in <ref> [LIEU92] </ref>. 66 response time of the code generated in the three modes. The exact difference in performance of the generated code is unimportant; the point of this section is to demonstrate that combining access-path-selection and transformation produces better code than using either technique by itself.
Reference: [LOHM88] <author> Guy Lohman. </author> <title> Grammar-like Functional Rules for Representing Query Optimization Alternatives. </title> <booktitle> Proc. 1988 SIGMOD, </booktitle> <month> June </month> <year> 1988. </year>
Reference-contexts: While this is a good representation from which to generate code, it is a poor one for database-style optimization. We wished to use an optimizer generator <ref> [GRAE87, LOHM88] </ref>, a tool that take a set of rules and produces an optimizer. However, the EXODUS Optimizer Generator (OptGen), the only generator we had access to, expects all operators to have fixed arity.
Reference: [MACK89] <author> Lothar Mackert and Guy Lohman. </author> <title> Index Scans Using a Finite LRU Buffer: A Validated I/O Model. </title> <journal> ACM Trans. Database Syst. </journal> <month> 14,3 (September </month> <year> 1989), </year> <pages> 401-424. </pages>
Reference: [MEHT91] <author> Manish Mehta and David DeWitt. </author> <title> Pointer Join Techniques for Parallel Database Machines, </title> <type> manuscript. </type>
Reference-contexts: The paper describes, analyzes, and compares uni-processor versions of the pointer-based Hybrid-hash and Hash-loops join algorithms. <ref> [MEHT91] </ref> describes parallel versions of both these algorithms. [MEHT91] also analyzes three parallel versions of Hybrid-hash and compares their performance. Other proposed pointer-based join algorithms include pointer-based nested loops [SHEK90], pointer-based sort-merge [SHEK90], and pointer-based PID-partitioning [SHEK91]. <p> The paper describes, analyzes, and compares uni-processor versions of the pointer-based Hybrid-hash and Hash-loops join algorithms. <ref> [MEHT91] </ref> describes parallel versions of both these algorithms. [MEHT91] also analyzes three parallel versions of Hybrid-hash and compares their performance. Other proposed pointer-based join algorithms include pointer-based nested loops [SHEK90], pointer-based sort-merge [SHEK90], and pointer-based PID-partitioning [SHEK91]. <p> We do not consider the case where children have back-pointers to their parents; this eliminates a number of the execution strategies that [SHEK90, SHEK91] presented for uni-processor systems. This section describes, analyzes, and compares four execution strategies for loops like (6.6): the Hash-loops <ref> [SHEK90, MEHT91] </ref>, the Probe-children, the Hybrid-hash/node-pointer [MEHT91], and the Hybrid-hash/page-pointer [MEHT91] join algorithms. It also contains the Find-children algorithm which allows algorithms like [GERB86, SCHN89, DEWI92a]'s parallel Hybrid-hash and our Probe-children join algorithm to be used even when an explicit extent of children of Set1 does not exist. <p> We do not consider the case where children have back-pointers to their parents; this eliminates a number of the execution strategies that [SHEK90, SHEK91] presented for uni-processor systems. This section describes, analyzes, and compares four execution strategies for loops like (6.6): the Hash-loops [SHEK90, MEHT91], the Probe-children, the Hybrid-hash/node-pointer <ref> [MEHT91] </ref>, and the Hybrid-hash/page-pointer [MEHT91] join algorithms. It also contains the Find-children algorithm which allows algorithms like [GERB86, SCHN89, DEWI92a]'s parallel Hybrid-hash and our Probe-children join algorithm to be used even when an explicit extent of children of Set1 does not exist. <p> This section describes, analyzes, and compares four execution strategies for loops like (6.6): the Hash-loops [SHEK90, MEHT91], the Probe-children, the Hybrid-hash/node-pointer <ref> [MEHT91] </ref>, and the Hybrid-hash/page-pointer [MEHT91] join algorithms. It also contains the Find-children algorithm which allows algorithms like [GERB86, SCHN89, DEWI92a]'s parallel Hybrid-hash and our Probe-children join algorithm to be used even when an explicit extent of children of Set1 does not exist. <p> Thus, Probe-children and Hybrid-hash/node-pointer can be used for parallel relational database systems that support range and/or hash partitioning. A uni-processor version of the Hash-loops algorithm was described and analyzed in [SHEK90] assuming no sharing of objects. <ref> [MEHT91] </ref> described a parallel version, but did not analyze it. Both implicitly assumed that all objects mentioned in the query could be accessed through an extent. We do not make this assumption, but instead propose the Find-children algorithm to compute an implicit extent when an explicit extent does not exist.
Reference: [MUMI90] <author> Inderpal Singh Mumick, Sheldon J. Finkelstein, Hamid Pirahesh, Raghu Ramakrishnan. </author> <title> Magic is Relevant. </title> <booktitle> Proc. 1990 SIGMOD, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: Thus, joins are a very important operation. Unfortunately, they can also be very expensive to compute. As a result, a large amount of research on relational databases has been aimed at computing joins efficiently <ref> [SELI79, JARK84, DEWI84, GERB86, SCHN89, MUMI90, DEWI92b] </ref>. For an OODBS to satisfy customer performance requirements, it must effectively optimize joins. <p> These subqueries can be simplified further by other transformations. [DAYA87, GANS87, MURA89] corrected errors in Kim's technique by replacing joins with outerjoins. [DAYA87, MURA89] developed pipelining techniques that remove some of the temporary relations introduced by Kim's technique. <ref> [MUMI90] </ref> uses this prior work to convert queries with nested query blocks into a series of queries and view definitions.
Reference: [MURA89] <author> M. Muralikrishna. </author> <title> Optimization and Dataflow Algorithms for Nested Tree Queries. </title> <booktitle> Proc. 1989 Conf. Very Large Databases, </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: Other transformations take a more complicated nested query and produce two or more subqueries that compute the same result. Some subqueries are not flat, but their nesting patterns are simpler than the nesting pattern of the untransformed query. These subqueries can be simplified further by other transformations. <ref> [DAYA87, GANS87, MURA89] </ref> corrected errors in Kim's technique by replacing joins with outerjoins. [DAYA87, MURA89] developed pipelining techniques that remove some of the temporary relations introduced by Kim's technique. [MUMI90] uses this prior work to convert queries with nested query blocks into a series of queries and view definitions. <p> Some subqueries are not flat, but their nesting patterns are simpler than the nesting pattern of the untransformed query. These subqueries can be simplified further by other transformations. [DAYA87, GANS87, MURA89] corrected errors in Kim's technique by replacing joins with outerjoins. <ref> [DAYA87, MURA89] </ref> developed pipelining techniques that remove some of the temporary relations introduced by Kim's technique. [MUMI90] uses this prior work to convert queries with nested query blocks into a series of queries and view definitions.
Reference: [OMIE89] <author> Edward Omiecinski and Eileen Tien Lin. </author> <title> Hash-Based and Index-Based Join Algorithms for Cube and Ring Connected Multicomputers. </title> <journal> IEEE Trans. Knowledge and Data Engineering 1,3 (September 1989), </journal> <pages> 329-343. </pages>
Reference-contexts: In a uni-processor system, the basic algorithm scans the index, reading the referenced tuples. [VALD87] compared the performance of join indices to the Hybrid-hash join algorithm, and showed that a more elaborate join algorithm using join indices could frequently produce better performance than Hybrid-hash in a uniprocessor system. <ref> [OMIE89] </ref> compared the two algorithms in a parallel environment and showed that Hybrid-hash will almost always outperform join indices except when the join selectivity is very high. [CARE90] describes an incremental join facility added to Starburst to enable a relational DBMS to efficiently handle many-to-one relationships.
Reference: [PADU86] <author> David A. Padua and Michael J. Wolfe. </author> <title> Advanced Compiler Optimizations for Supercomputers. </title> <journal> CACM 29,12 (December 1986), </journal> <pages> 1184-1201. </pages>
Reference-contexts: In this thesis, we combine the execution of a subquery with the partitioning phase of a Hybrid-hash joinwhich is similar to using pipelining. The idea of interchanging loops appears frequently in work on vectorizing FORTRAN <ref> [PADU86, WOLF86, WOLF89] </ref>. For instance, do I = 1, N S = S + B (I,J) enddo enddo cannot be directly vectorized. However, if we interchange the I and J loops, the definition of A (I,J+1) can be vectorized. The definition of S involves a reduction operation. <p> We discuss the related work for each in turn. 2.2.1. Related Transformation Work An enormous amount of work has been done on parallelizing relational queries (e.g. [GERB86, SCHN89, GRAE90, KITS90, WOLF90, HUA91, WALT91, DEWI92a]). Other work has been on parallelizing loops in FORTRAN (e.g. <ref> [PADU86, WOLF86, WOLF89] </ref>) and in LISP [LARU89]. All this work makes extensive use of program transformations. [HART88, HART89] discuss their parallelizing compiler for FAD, a functional DBPL.
Reference: [RIES78] <author> D. Ries and R. Epstein. </author> <title> Evaluation of Distribution Criteria for Distributed Database Systems. </title> <type> UCB/ERL Technical Report M78/22, </type> <institution> UC Berkeley, </institution> <month> May </month> <year> 1978. </year>
Reference-contexts: parallelizing query (6.1) using a modified Hybrid-hash algorithm [GERB86, SCHN89, DEWI92a]: (6.1) for (D of Dept; P of Professor) suchthat (D-&gt;did==P->did) - Insert &lt;D-&gt;name,P->name,P->sal> into PayInfo; D-&gt;budget += P-&gt;sal; profcount++; - To simplify the description of the parallelization of query (6.1), assume that the Dept and Professor objects are declustered <ref> [RIES78, LIVN87, GHAN90] </ref> across the same n nodes, that these n nodes will be used to execute the join, and that all of the Dept objects will fit in the aggregate memory of the n processors.
Reference: [RIES83] <author> Daniel Ries, Arvola Chan, Umeshwar Dayal, Stephen Fox, Wen-Te Lin, and Laura Yedwab. </author> <title> Decom-pilation and Optimization for ADAPLEX: A Procedural Database Language. </title> <institution> Computer Corporation of America, </institution> <type> Technical Report CCA-82-04, </type> <address> Cambridge, Mass., </address> <month> September </month> <year> 1983. </year>
Reference-contexts: It is the only transformation that is carefully characterized in [SHOP80]other transformations are illustrated with examples, but the conditions under which they are applicable are not stated. We implemented a slightly more general version of loop inversion than the version described in [SHOP80]. <ref> [RIES83] </ref> uses an algebraic framework to optimize set loops in ADAPLEX. The algebra handles looping constructs more complicated than those covered in this thesis. However, this algebra does not allow breaking a nested set iterator loop into several loops, a key technique in this thesis.
Reference: [RICH92] <author> Joel Richardson, Michael Carey, and Daniel Schuh. </author> <title> The Design of the E Programming Language. </title> <journal> ACM Trans. Programming Languages and Syst. </journal> <note> (1992), to appear. 125 </note>
Reference-contexts: Converting the graph structure between the database and programming language format creates new opportunities for programming errors. Thus, more powerful database systems are needed. Recently, a number of object-oriented database systems (OODBSs) with the full data modelling power of a conventional programming language have been developed <ref> [AGRA89, LAMB91, LECL89, RICH92] </ref>. However, unless the query language of the OODBS is computationally complete, some computations will still need to be performed using a conventional programming language. <p> They can be optimized using standard relational techniques [SELI79] or the more complex techniques developed for OODBSs [SHAW89, BEER90, VAND91]. Instead, we will concentrate on set iterators. Since DBPLs such as PASCAL/R [SCHM77], O 2 [LECL89], E <ref> [RICH92] </ref>, and O++ [AGRA89] provide constructs to iterate through a set in some unspecified order, it is possible to nest iterators to express value-based joins.
Reference: [SCHM77] <author> Joachim Schmidt. </author> <title> Some High Level Language Constructs for Data of Type Relation. </title> <journal> ACM Trans. Database Syst. </journal> <month> 2,3 (September </month> <year> 1977), </year> <pages> 247-261. </pages>
Reference-contexts: In this thesis, we ignore the optimization of joins written in a non-procedural fashion. They can be optimized using standard relational techniques [SELI79] or the more complex techniques developed for OODBSs [SHAW89, BEER90, VAND91]. Instead, we will concentrate on set iterators. Since DBPLs such as PASCAL/R <ref> [SCHM77] </ref>, O 2 [LECL89], E [RICH92], and O++ [AGRA89] provide constructs to iterate through a set in some unspecified order, it is possible to nest iterators to express value-based joins.
Reference: [SCHN89] <author> Donovan A. Schneider and David J. DeWitt. </author> <title> A Performance Evaluation of Four Parallel Join Algorithms in a Shared-Nothing Multiprocessor Environment. </title> <booktitle> Proc. 1989 SIGMOD, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: Thus, joins are a very important operation. Unfortunately, they can also be very expensive to compute. As a result, a large amount of research on relational databases has been aimed at computing joins efficiently <ref> [SELI79, JARK84, DEWI84, GERB86, SCHN89, MUMI90, DEWI92b] </ref>. For an OODBS to satisfy customer performance requirements, it must effectively optimize joins. <p> RELATED PARALLELIZATION WORK Our parallelization work uses both transformations and pointer-based join techniques. We discuss the related work for each in turn. 2.2.1. Related Transformation Work An enormous amount of work has been done on parallelizing relational queries (e.g. <ref> [GERB86, SCHN89, GRAE90, KITS90, WOLF90, HUA91, WALT91, DEWI92a] </ref>). Other work has been on parallelizing loops in FORTRAN (e.g. [PADU86, WOLF86, WOLF89]) and in LISP [LARU89]. All this work makes extensive use of program transformations. [HART88, HART89] discuss their parallelizing compiler for FAD, a functional DBPL. <p> Many join loops can be parallelized to the same extent by modifying parallel join algorithms so that they execute program statements rather than produce result tuples. As an example, consider parallelizing query (6.1) using a modified Hybrid-hash algorithm <ref> [GERB86, SCHN89, DEWI92a] </ref>: (6.1) for (D of Dept; P of Professor) suchthat (D-&gt;did==P->did) - Insert &lt;D-&gt;name,P->name,P->sal> into PayInfo; D-&gt;budget += P-&gt;sal; profcount++; - To simplify the description of the parallelization of query (6.1), assume that the Dept and Professor objects are declustered [RIES78, LIVN87, GHAN90] across the same n nodes, that <p> This section describes, analyzes, and compares four execution strategies for loops like (6.6): the Hash-loops [SHEK90, MEHT91], the Probe-children, the Hybrid-hash/node-pointer [MEHT91], and the Hybrid-hash/page-pointer [MEHT91] join algorithms. It also contains the Find-children algorithm which allows algorithms like <ref> [GERB86, SCHN89, DEWI92a] </ref>'s parallel Hybrid-hash and our Probe-children join algorithm to be used even when an explicit extent of children of Set1 does not exist. <p> Otherwise, it will be better to replicate each Set1 object once per child pointer, repartition both Set1 and Set2 (tagging each Set2-tuple with its oid), and use a standard parallel Hybrid-hash algorithm <ref> [GERB86, SCHN89, DEWI92a] </ref> with the oids as join attributesin which case we would expect performance similar to Hybrid-hash/node-pointer 113 in Figure 6.9 after shifting it up about 19 seconds everywhere to account for having approximately twice as much to read in order to partition Set2 at the node with tuple-placement-skew.
Reference: [SELI79] <author> P. Selinger, M. Astrahan, D. Chamberlin, R. Lorie, and T. Price. </author> <title> Access Path Selection in a Relational Database Management System. </title> <booktitle> Proc. 1979 SIGMOD, </booktitle> <month> May-June </month> <year> 1979. </year>
Reference-contexts: Since their query languages are non-procedural, the system has a great deal of latitude in how it chooses to compute a query result. To take advantage of this latitude, relational database systems use very complex optimizers that search a space of alternative query plans for the least expensive alternative <ref> [SELI79, JARK84] </ref>. The resulting plan will often be orders of magnitude faster than a naive implementation. However, relational systems have two major drawbacks. First, relational query languages (e.g. SQL) are not computationally complete. Thus, some database computations must be performed using a conventional programming language. <p> Thus, joins are a very important operation. Unfortunately, they can also be very expensive to compute. As a result, a large amount of research on relational databases has been aimed at computing joins efficiently <ref> [SELI79, JARK84, DEWI84, GERB86, SCHN89, MUMI90, DEWI92b] </ref>. For an OODBS to satisfy customer performance requirements, it must effectively optimize joins. <p> In this thesis, we ignore the optimization of joins written in a non-procedural fashion. They can be optimized using standard relational techniques <ref> [SELI79] </ref> or the more complex techniques developed for OODBSs [SHAW89, BEER90, VAND91]. Instead, we will concentrate on set iterators. <p> The following is an example of a nested iterator expressed in O++: (1.1) for (D of Division) - divisioncnt++; for (E of Employee) suchthat (E-&gt;division==D) - D-&gt;print (); E-&gt;print (); - Unless analysis is used, query (1.1) must be evaluated using a tuple-at-a-time nested-loops join algorithm <ref> [SELI79] </ref>. One element of Division must be read. Then divisioncnt is incremented, and all the elements of Employee are scanned to see if any of them match with the Division element. For each match, some printing is performed. <p> However, the cost functions for our implementation include CPU cost. We used System R <ref> [SELI79] </ref> style optimizationso the cost function was produced using a combination of the number of pages read and the number of tuples requested from the storage manager. <p> The experiments also demonstrate that both access-path-selection and transformations are needed to maximize performance. 78 CHAPTER 6 PARALLELIZING LOOPS IN DATABASE PROGRAMMING LANGUAGES Without program analysis, joins that are expressed as nested set loops must be evaluated using a tuple-at-a-time nested-loops join algorithm <ref> [SELI79] </ref> because otherwise program semantics may be violated. In addition, since loops have a sequential semantics, they must be executed at a centralized site.
Reference: [SELL88] <author> Timos Sellis. </author> <title> Multi-Query Optimization. </title> <journal> ACM Trans. Database Syst. </journal> <month> 13,1 (March </month> <year> 1988), </year> <pages> 23-52. </pages>
Reference-contexts: FUTURE RESEARCH DIRECTIONS Future work derived from this thesis includes finding new transformations, particularly transformations that can combine several loops that appear sequentially in the program text into a single large loop (in some ways finding an inverse of transformation (T4)closely related to multi-query optimization <ref> [SELL88] </ref>). We currently do combine some loops produced by the optimizer while transforming a single group-by loop. However, we would like to apply this technique more widely.
Reference: [SHAP86] <author> Leonard D. Shapiro. </author> <title> Join Processing in Database Systems with Large Main Memories. </title> <journal> ACM Trans. Database Syst. </journal> <month> 11,3 (September </month> <year> 1986), </year> <pages> 239-264. </pages>
Reference-contexts: There are only two differences: (1) following <ref> [SHAP86] </ref>, we do not distinguish between random and sequential I/O, 6 and (2) R' and S' replace R and S in the definitions of B and q and in the second line of the cost formula. For Hybrid-hash to be applicable, M ( dd P R' . <p> Note that size Temp = (pwidth Set1 + pwidth Set2 ). Given this, P Temp can be calculated using the formula in Table 3.1. Assume that M &gt; ddddd P Temp . Then Temp can be sorted in two passes <ref> [SHAP86] </ref>, and the cost to execute the query resulting from transformation (T2) is join cost of Set2||Set1 Join using Set2 as the outer set with M 1 = (M-1) buffer pages +Unbuff (P Temp ) Write pages of Temp that cannot be buffered during join (see definition below) +Unbuff (P Temp <p> join (see definition below) +Unbuff (P Temp ) Read pages of Temp written during join for first pass of sort +P Temp . 2 Write runs, and read them back for sort -min (P Temp ,M-1- ddddd P Temp ) . 2 I/O savings if extra memory available during sort <ref> [SHAP86] </ref> The memory resident hash table for Set1 has first claim on memory during the join, so if (P Set1' . F) M 1 , all of Temp must be written to disk during the join. <p> Also, in reality the load-child algorithms should perform better relative to the load-parent algorithms than the graph indicates because the load-child algorithms read Set2 pages sequentially (since Find-children sorts the page identifiers) while the load-parent algorithms read them randomly. However, following <ref> [SHAP86, WALT91] </ref>, our analysis did not take 107 Time in seconds (sel Set2 =0.50) 140 100 60 20 1400120010008006004002000 Hybrid-hash/node-pointer Probe-children Hybrid-hash/page-pointer Hash-loops the different types of I/O into account.
Reference: [SHAW89] <author> Gail Shaw and Stanley Zdonik. </author> <title> An Object-Oriented Query Algebra. </title> <booktitle> Data Engineering 12,3 (Sep-tember 1989), </booktitle> <pages> 29-36. </pages>
Reference-contexts: In this thesis, we ignore the optimization of joins written in a non-procedural fashion. They can be optimized using standard relational techniques [SELI79] or the more complex techniques developed for OODBSs <ref> [SHAW89, BEER90, VAND91] </ref>. Instead, we will concentrate on set iterators. Since DBPLs such as PASCAL/R [SCHM77], O 2 [LECL89], E [RICH92], and O++ [AGRA89] provide constructs to iterate through a set in some unspecified order, it is possible to nest iterators to express value-based joins.
Reference: [SHEK90] <author> Eugene J. Shekita and Michael J. Carey. </author> <title> A Performance Evaluation of Pointer-Based Joins. </title> <booktitle> Proc. 1990 SIGMOD, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: The set representation employed is similar to the representation provided by network database systems. The paper describes the results of an empirical performance study comparing the performance of a number of pointer-based join algorithms. <ref> [SHEK90] </ref> assumes a different set representationone where objects contain lists of other objects' oids. The paper describes, analyzes, and compares uni-processor versions of the pointer-based Hybrid-hash and Hash-loops join algorithms. [MEHT91] describes parallel versions of both these algorithms. [MEHT91] also analyzes three parallel versions of Hybrid-hash and compares their performance. <p> The paper describes, analyzes, and compares uni-processor versions of the pointer-based Hybrid-hash and Hash-loops join algorithms. [MEHT91] describes parallel versions of both these algorithms. [MEHT91] also analyzes three parallel versions of Hybrid-hash and compares their performance. Other proposed pointer-based join algorithms include pointer-based nested loops <ref> [SHEK90] </ref>, pointer-based sort-merge [SHEK90], and pointer-based PID-partitioning [SHEK91]. These three algorithms are analyzed in [SHEK91]. 8 CHAPTER 3 TRANSFORMATIONS This chapter will examine six program transformations for nested set iterators like (3.1). Using analysis and examples, it will demonstrate that these transformations can reduce the execution time for a program. <p> The paper describes, analyzes, and compares uni-processor versions of the pointer-based Hybrid-hash and Hash-loops join algorithms. [MEHT91] describes parallel versions of both these algorithms. [MEHT91] also analyzes three parallel versions of Hybrid-hash and compares their performance. Other proposed pointer-based join algorithms include pointer-based nested loops <ref> [SHEK90] </ref>, pointer-based sort-merge [SHEK90], and pointer-based PID-partitioning [SHEK91]. These three algorithms are analyzed in [SHEK91]. 8 CHAPTER 3 TRANSFORMATIONS This chapter will examine six program transformations for nested set iterators like (3.1). Using analysis and examples, it will demonstrate that these transformations can reduce the execution time for a program. <p> We term the (implicit) set of all children objects Set2. We do not consider the case where children have back-pointers to their parents; this eliminates a number of the execution strategies that <ref> [SHEK90, SHEK91] </ref> presented for uni-processor systems. This section describes, analyzes, and compares four execution strategies for loops like (6.6): the Hash-loops [SHEK90, MEHT91], the Probe-children, the Hybrid-hash/node-pointer [MEHT91], and the Hybrid-hash/page-pointer [MEHT91] join algorithms. <p> We do not consider the case where children have back-pointers to their parents; this eliminates a number of the execution strategies that [SHEK90, SHEK91] presented for uni-processor systems. This section describes, analyzes, and compares four execution strategies for loops like (6.6): the Hash-loops <ref> [SHEK90, MEHT91] </ref>, the Probe-children, the Hybrid-hash/node-pointer [MEHT91], and the Hybrid-hash/page-pointer [MEHT91] join algorithms. It also contains the Find-children algorithm which allows algorithms like [GERB86, SCHN89, DEWI92a]'s parallel Hybrid-hash and our Probe-children join algorithm to be used even when an explicit extent of children of Set1 does not exist. <p> Thus, Probe-children and Hybrid-hash/node-pointer can be used for parallel relational database systems that support range and/or hash partitioning. A uni-processor version of the Hash-loops algorithm was described and analyzed in <ref> [SHEK90] </ref> assuming no sharing of objects. [MEHT91] described a parallel version, but did not analyze it. Both implicitly assumed that all objects mentioned in the query could be accessed through an extent. <p> We analyze the parallel algorithms. Our analysis can handle multiple parents sharing a child. We also develop and analyze a new pointer-based join algorithm. The spirit of the Hash-loops analysis was influenced by <ref> [SHEK90] </ref>. However, changes were required to account for the effects of sharing, of selection and projection, and of decluster-ing objects. [SHEK90] did not take space overhead for a hash table into account; replacing [SHEK90]'s assumption that a hash table for c pages of persistent data requires c pages of main memory <p> Our analysis can handle multiple parents sharing a child. We also develop and analyze a new pointer-based join algorithm. The spirit of the Hash-loops analysis was influenced by <ref> [SHEK90] </ref>. However, changes were required to account for the effects of sharing, of selection and projection, and of decluster-ing objects. [SHEK90] did not take space overhead for a hash table into account; replacing [SHEK90]'s assumption that a hash table for c pages of persistent data requires c pages of main memory also required a number of changes. 6.3.1. Hash-loops This algorithm is a parallel version of the Hash-loops join algorithm. <p> a hash table into account; replacing <ref> [SHEK90] </ref>'s assumption that a hash table for c pages of persistent data requires c pages of main memory also required a number of changes. 6.3.1. Hash-loops This algorithm is a parallel version of the Hash-loops join algorithm. We will first present the uni-processor version [SHEK90], and then examine a parallel version. Both require physical oids to be applicable. Let S i be the 88 subset of set S at node i . <p> Find-children If the implicit set Set2 is not an explicit extent, one must use a parallel version of the Hash-loops, pointer based nested loops, or pointer-based Hybrid-hash join algorithm <ref> [SHEK90] </ref>. Alternatively, an extent can be expli citly computedwhich is what the Find-children algorithm does. Find-children computes which of each node's pages contain elements of the implicit set Set2. <p> Thus, the Probe-children algorithm will potentially produce fewer Set1-tuples. Third, Probe-children may reread the same Set1-tuples multiple times; Hybrid-hash/node-pointer will reread Set1-tuples at most once because it partitions Set1- and Set2- tuples into buckets. 6.3.5. Hybrid-hash/page-pointer This algorithm is almost identical to the pointer-based Hybrid-hash join algorithm of <ref> [SHEK90] </ref>. Only step (1) which redistributes Set1 is different. The algorithm proceeds as follows at each node i "i 1in: 96 (1) Scan Set1 i and distribute Set1-tuples, each of which contains exactly one Set2 (child) oid, to the relevant Set2 node. <p> This section also demonstrated that algorithms that avoid replication can produce significant performance advantages. Hash-loops looks much more attractive in an environment where using Hybrid-hash requires replication than it did in <ref> [SHEK90] </ref> provided that most of the Set1 objects reference Set2 objects on a small number of nodes 13 and that data is relatively uniformly distributed across nodes. [SHEK90] only examined the performance of algorithms that have sets of pointers from parents-to-children when there was a corresponding child-to-parent pointer; this gave more <p> Hash-loops looks much more attractive in an environment where using Hybrid-hash requires replication than it did in <ref> [SHEK90] </ref> provided that most of the Set1 objects reference Set2 objects on a small number of nodes 13 and that data is relatively uniformly distributed across nodes. [SHEK90] only examined the performance of algorithms that have sets of pointers from parents-to-children when there was a corresponding child-to-parent pointer; this gave more options and made Hash-loops look less attractive. However, in an OODBS, child-to-parent pointers frequently do not exist, and each child may potentially have many parents. <p> However, in an OODBS, child-to-parent pointers frequently do not exist, and each child may potentially have many parents. Thus, even in a centralized system, replication may be required in order to use Hybrid-hash algorithmsmaking Hash-loops a better choice more often than it was in <ref> [SHEK90] </ref>. We also showed that using Find-children and a load-child algorithm can be a clear winner at moderate memory sizes. <p> These pointer-based join algorithms show great promise for parallelizing a DBPL. Since some of the pointer-based joins were originally proposed for use by centralized relational database systems with referential integrity support <ref> [SHEK90] </ref>, these algorithms should also be useful for such relational systems. 118 CHAPTER 7 SUMMARY 7.1. CONCLUSIONS Database Programming Languages have been proposed as a solution to the impedance mismatch problem resulting from the limited expressive power of relational query languages.
Reference: [SHEK91] <author> Eugene Shekita. </author> <title> Ph.D Thesis. High-Performance Implementation Techniques for Next-Generation Database Systems. </title> <institution> University of Wisconsin (1991). </institution>
Reference-contexts: Other proposed pointer-based join algorithms include pointer-based nested loops [SHEK90], pointer-based sort-merge [SHEK90], and pointer-based PID-partitioning <ref> [SHEK91] </ref>. These three algorithms are analyzed in [SHEK91]. 8 CHAPTER 3 TRANSFORMATIONS This chapter will examine six program transformations for nested set iterators like (3.1). Using analysis and examples, it will demonstrate that these transformations can reduce the execution time for a program. <p> Other proposed pointer-based join algorithms include pointer-based nested loops [SHEK90], pointer-based sort-merge [SHEK90], and pointer-based PID-partitioning <ref> [SHEK91] </ref>. These three algorithms are analyzed in [SHEK91]. 8 CHAPTER 3 TRANSFORMATIONS This chapter will examine six program transformations for nested set iterators like (3.1). Using analysis and examples, it will demonstrate that these transformations can reduce the execution time for a program. <p> We term the (implicit) set of all children objects Set2. We do not consider the case where children have back-pointers to their parents; this eliminates a number of the execution strategies that <ref> [SHEK90, SHEK91] </ref> presented for uni-processor systems. This section describes, analyzes, and compares four execution strategies for loops like (6.6): the Hash-loops [SHEK90, MEHT91], the Probe-children, the Hybrid-hash/node-pointer [MEHT91], and the Hybrid-hash/page-pointer [MEHT91] join algorithms.
Reference: [SHOP80] <author> Jonathan Shopiro. </author> <title> Ph.D. Thesis. A Very High Level Language And Optimized Implementation Design For Relational Databases. </title> <institution> University of Rochester (1980). </institution>
Reference-contexts: Our conclusions and future work are described in Chapter 7. 4 CHAPTER 2 RELATED WORK 2.1. RELATED TRANSFORMATION WORK The work most closely related to ours can be found in <ref> [SHOP80] </ref>; the transformation that [SHOP80] called loop inversion is explored in Section 3.2.3.3. Loop inversion is used to calculate aggregate functions more efficiently. It is the only transformation that is carefully characterized in [SHOP80]other transformations are illustrated with examples, but the conditions under which they are applicable are not stated. <p> Our conclusions and future work are described in Chapter 7. 4 CHAPTER 2 RELATED WORK 2.1. RELATED TRANSFORMATION WORK The work most closely related to ours can be found in <ref> [SHOP80] </ref>; the transformation that [SHOP80] called loop inversion is explored in Section 3.2.3.3. Loop inversion is used to calculate aggregate functions more efficiently. It is the only transformation that is carefully characterized in [SHOP80]other transformations are illustrated with examples, but the conditions under which they are applicable are not stated. <p> It is the only transformation that is carefully characterized in <ref> [SHOP80] </ref>other transformations are illustrated with examples, but the conditions under which they are applicable are not stated. We implemented a slightly more general version of loop inversion than the version described in [SHOP80]. [RIES83] uses an algebraic framework to optimize set loops in ADAPLEX. The algebra handles looping constructs more complicated than those covered in this thesis. However, this algebra does not allow breaking a nested set iterator loop into several loops, a key technique in this thesis. <p> D, Professor P where D.did=P.did group by D.name This SQL query can be expressed in O++ as: 27 (3.22) for (D of Dept) - cnt = 0; //S11 for (P of Professor) suchthat (D-&gt;did==P->did) cnt++; //S21 printf ("%s %d", D-&gt;name, cnt); newline (); //S12 - We consider a transformation from <ref> [SHOP80] </ref> to rewrite queries involving aggregate functions such as (3.22). (We repeat (3.10) as (3.23) for ease of exposition.) In (3.23) for (X1 of Set1) suchthat (Pred1 (X1)) - S11; for (X2 of Set2) suchthat (Pred2 (X1,X2)) S21; - suppose that S11 can be partitioned into two sets of statements: those
Reference: [VALD87] <author> Patrick Valduriez. </author> <title> Join Indices. </title> <journal> ACM Trans. Database Syst. </journal> <month> 12,2 (June </month> <year> 1987), </year> <pages> 218-246. </pages>
Reference-contexts: Most optimizers only applies a transformation if analysis indicates that the transformation will produce an equivalent program. However, their optimizer will sometimes apply a transformation and then check (using abstract interpretation) that the two programs are equivalent. 2.2.2. Related Pointer-based join Work In <ref> [VALD87] </ref>, auxiliary data structures called join indices that can be used to speedup join processing are described. A join index for relations R and S essentially precomputes the join between those two relations by stor 7 ing pairs of tuple identifiers (tids). <p> Each pair contains a tid from both R and S such that the corresponding tuples join with one another. In a uni-processor system, the basic algorithm scans the index, reading the referenced tuples. <ref> [VALD87] </ref> compared the performance of join indices to the Hybrid-hash join algorithm, and showed that a more elaborate join algorithm using join indices could frequently produce better performance than Hybrid-hash in a uniprocessor system. [OMIE89] compared the two algorithms in a parallel environment and showed that Hybrid-hash will almost always outperform
Reference: [VAND91] <author> Scott Vandenberg and David DeWitt. </author> <title> Algebraic Support for Complex Objects with Arrays, Identity, and Inheritance. </title> <booktitle> Proc. 1991 SIGMOD, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: In this thesis, we ignore the optimization of joins written in a non-procedural fashion. They can be optimized using standard relational techniques [SELI79] or the more complex techniques developed for OODBSs <ref> [SHAW89, BEER90, VAND91] </ref>. Instead, we will concentrate on set iterators. Since DBPLs such as PASCAL/R [SCHM77], O 2 [LECL89], E [RICH92], and O++ [AGRA89] provide constructs to iterate through a set in some unspecified order, it is possible to nest iterators to express value-based joins.
Reference: [VOSS91] <author> Gottfried Vossen. </author> <title> Data Models, Database Languages and Database Management Systems. </title> <publisher> Addison Wesley, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: First, relational query languages (e.g. SQL) are not computationally complete. Thus, some database computations must be performed using a conventional programming language. As a result, clumsy interfaces between two languages based on different paradigms must be used [ATKI87]. This is called the impedance mismatch <ref> [VOSS91] </ref>. Second, SQL's type system is inadequate for many applications. A user with a complex graph structure (for example, a VLSI chip design) that needs to be stored in the database must first encode the nodes and edges of the graph using flat records. This can be very burdensome.
Reference: [WALT91] <author> Christopher Walton, Alfred Dale, and Roy Jenevein. </author> <title> A Taxonomy and Performance Model of Data Skew Effects in Parallel Joins. </title> <booktitle> Proc. 1991 Conf. Very Large Databases, </booktitle> <month> September </month> <year> 1991. </year>
Reference-contexts: RELATED PARALLELIZATION WORK Our parallelization work uses both transformations and pointer-based join techniques. We discuss the related work for each in turn. 2.2.1. Related Transformation Work An enormous amount of work has been done on parallelizing relational queries (e.g. <ref> [GERB86, SCHN89, GRAE90, KITS90, WOLF90, HUA91, WALT91, DEWI92a] </ref>). Other work has been on parallelizing loops in FORTRAN (e.g. [PADU86, WOLF86, WOLF89]) and in LISP [LARU89]. All this work makes extensive use of program transformations. [HART88, HART89] discuss their parallelizing compiler for FAD, a functional DBPL. <p> Assumptions for Analysis We assume that the selection predicates on Set1 and Set2 are equally selective at each node (i.e. no Selectivity Skew <ref> [WALT91] </ref>). We repeat the definitions of two functions from Chapter 3 for use in the analysis. <p> Since our algorithm comparisons do not select Set1, this assumption does not affect our results. We do not include CPU times in our analysis; a similar join algorithm analysis in <ref> [WALT91] </ref> included CPU time and found that none of the queries were CPU boundthe CPU time was always lost in the overlap with I/O and communication. Thus, we feel it is safe to neglect CPU time in our analysis. Originally, we used [WALT91]'s style of capturing overlapped communication and I/O. <p> We assume in all of our comparisons that the selection predicates are equally selective at each node (i.e. no Selectivity Skew <ref> [WALT91] </ref>). 6.3.7.1. Poorly Clustered Database In the first algorithm comparison, the system defaults from Table 6.1 were used. Data was uniformly distributed across n=32 nodes, with | Set1 i | =6080 and | Set2 i | =30,400 "i 1in. <p> Also, in reality the load-child algorithms should perform better relative to the load-parent algorithms than the graph indicates because the load-child algorithms read Set2 pages sequentially (since Find-children sorts the page identifiers) while the load-parent algorithms read them randomly. However, following <ref> [SHAP86, WALT91] </ref>, our analysis did not take 107 Time in seconds (sel Set2 =0.50) 140 100 60 20 1400120010008006004002000 Hybrid-hash/node-pointer Probe-children Hybrid-hash/page-pointer Hash-loops the different types of I/O into account. <p> Database with Tuple Placement Skew In our next algorithm comparison, we considered a well-clustered database with tuple-placement skew <ref> [WALT91] </ref>. Since the performance of the whole query is determined by the slowest node, we use 31 evenly balanced nodes, each of which has 29,488 Set2 objects, and one node with 58,672 Set2 objects. Set2 has the same number of elements as in the past comparisonsit is just differently distributed. <p> A hash function that ignores the node but uses the page and slot identifier from the pointer should produce fairly uniformly sized partitions. Alternatively, a skew resistant join technique <ref> [KITS90, WOLF90, HUA91, WALT91, DEWI92b] </ref> might be used after producing Set1-tuples. Note that the Find-children algorithm must be used to allow either of these techniques if Set2 is not an explicit extent. 6.3.7.4.
Reference: [WOLF86] <author> Michael Wolfe. </author> <title> Advanced Loop Interchanging. </title> <booktitle> Proc. 1986 Int. Conf. Parallel Processing, </booktitle> <month> August </month> <year> 1986. </year> <month> 126 </month>
Reference-contexts: In this thesis, we combine the execution of a subquery with the partitioning phase of a Hybrid-hash joinwhich is similar to using pipelining. The idea of interchanging loops appears frequently in work on vectorizing FORTRAN <ref> [PADU86, WOLF86, WOLF89] </ref>. For instance, do I = 1, N S = S + B (I,J) enddo enddo cannot be directly vectorized. However, if we interchange the I and J loops, the definition of A (I,J+1) can be vectorized. The definition of S involves a reduction operation. <p> We discuss the related work for each in turn. 2.2.1. Related Transformation Work An enormous amount of work has been done on parallelizing relational queries (e.g. [GERB86, SCHN89, GRAE90, KITS90, WOLF90, HUA91, WALT91, DEWI92a]). Other work has been on parallelizing loops in FORTRAN (e.g. <ref> [PADU86, WOLF86, WOLF89] </ref>) and in LISP [LARU89]. All this work makes extensive use of program transformations. [HART88, HART89] discuss their parallelizing compiler for FAD, a functional DBPL.
Reference: [WOLF89] <author> Michael Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Mas-sachusetts, </address> <year> 1989. </year>
Reference-contexts: In this thesis, we combine the execution of a subquery with the partitioning phase of a Hybrid-hash joinwhich is similar to using pipelining. The idea of interchanging loops appears frequently in work on vectorizing FORTRAN <ref> [PADU86, WOLF86, WOLF89] </ref>. For instance, do I = 1, N S = S + B (I,J) enddo enddo cannot be directly vectorized. However, if we interchange the I and J loops, the definition of A (I,J+1) can be vectorized. The definition of S involves a reduction operation. <p> We discuss the related work for each in turn. 2.2.1. Related Transformation Work An enormous amount of work has been done on parallelizing relational queries (e.g. [GERB86, SCHN89, GRAE90, KITS90, WOLF90, HUA91, WALT91, DEWI92a]). Other work has been on parallelizing loops in FORTRAN (e.g. <ref> [PADU86, WOLF86, WOLF89] </ref>) and in LISP [LARU89]. All this work makes extensive use of program transformations. [HART88, HART89] discuss their parallelizing compiler for FAD, a functional DBPL. <p> We call operations of the form (4.2) reductions because they reduce a subset of a set or Cartesian product to a single value in an order independent manner. This is a natural extension to the concept of array reduction, a concept used in the optimization of programs for supercomputers <ref> [WOLF89] </ref>.
Reference: [WOLF90] <author> Joel Wolf. Daniel Dias, Philip Yu, and John Turek. </author> <title> An effective algorithm for parallelizing hash joins in the presence of data skew. </title> <institution> IBM T. J. Watson Research Center Technical Report RC 15510, </institution> <year> 1990. </year>
Reference-contexts: RELATED PARALLELIZATION WORK Our parallelization work uses both transformations and pointer-based join techniques. We discuss the related work for each in turn. 2.2.1. Related Transformation Work An enormous amount of work has been done on parallelizing relational queries (e.g. <ref> [GERB86, SCHN89, GRAE90, KITS90, WOLF90, HUA91, WALT91, DEWI92a] </ref>). Other work has been on parallelizing loops in FORTRAN (e.g. [PADU86, WOLF86, WOLF89]) and in LISP [LARU89]. All this work makes extensive use of program transformations. [HART88, HART89] discuss their parallelizing compiler for FAD, a functional DBPL. <p> A hash function that ignores the node but uses the page and slot identifier from the pointer should produce fairly uniformly sized partitions. Alternatively, a skew resistant join technique <ref> [KITS90, WOLF90, HUA91, WALT91, DEWI92b] </ref> might be used after producing Set1-tuples. Note that the Find-children algorithm must be used to allow either of these techniques if Set2 is not an explicit extent. 6.3.7.4.
Reference: [YAO77] <author> S. B. Yao. </author> <title> Approximating Block Accesses in Database Organizations. </title> <journal> CACM 20,4 (April 1977), </journal> <pages> 260-261. </pages>
Reference-contexts: To calculate the number of page reads for Set2 i objects, we use a formula from <ref> [YAO77] </ref> for calculating the expected fraction of pages of a set with cardinality | S | that must be read to examine a subset of size | S s | provided O S objects fit on a page.
Reference: [ZDON90] <author> Stanley Zdonik and David Maier. </author> <title> Readings in Object-Oriented Database Systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1990. </year>

References-found: 67

