URL: http://www.eecs.umich.edu/Rio/papers/databaseReliableMem.ps
Refering-URL: http://www.eecs.umich.edu/Rio/papers.html
Root-URL: http://www.eecs.umich.edu
Title: Abstract  
Note: This research was supported in part by NSF grant MIP-9521386 and Digital Equipment Corporation. Peter Chen was also supported by an NSF CAREER and Research Initiation Award (MIP-9624869 and MIP-9409229). Proceedings of the 23rd VLDB Conference Athens, Greece, 1997  
Abstract: Recent results in the Rio project at the University of Michigan show that it is possible to create an area of main memory that is as safe as disk from operating system crashes. This paper explores how to integrate the reliable memory provided by the Rio file cache into a database system. We propose three designs for integrating reliable memory into databases: non-persistent database buffer cache, persistent database buffer cache, and persistent database buffer cache with protection. Non-persistent buffer caches use an I/O interface to reliable memory and require the fewest modifications to existing databases. However, they waste memory capacity and bandwidth due to double buffering. Persistent buffer caches use a memory interface to reliable memory by mapping it into the database address space. This places reliable memory under complete database control and eliminates double buffering, but it may expose the buffer cache to database errors. Our third design reduces this exposure by write protecting the buffer pages. Extensive fault tests show that mapping reliable memory into the database address space does not significantly hurt reliability. This is because wild stores rarely touch dirty, committed pages written by previous transactions. As a result, we believe that databases should use a memory interface to reliable memory. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the VLDB copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Very Large Data Base Endowment. To copy otherwise, or to republish, requires a fee and/or special permission from the Endowment. 
Abstract-found: 1
Intro-found: 1
Reference: [Agrawal89] <author> Rakesh Agrawal and H. V. Jagadish. </author> <title> Recovery algorithms for database machines with nonvolatile main memory. In Database Machines. </title> <booktitle> Sixth International Workshop, IWDM 89 Proceedings., </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: Since undo records can be eliminated after a transaction commits, removing the redo log implies that no log records need be written to disk if memory is large enough to contain the undo records for all transactions in progress <ref> [Agrawal89] </ref>. In addition, storing the database buffer cache in reliable memory allows the system to begin operation after a crash with the contents present prior to the crash (a warm cache) [Sullivan93, Elhardt84, Bhide93].
Reference: [Akyurek95] <author> Sedat Akyurek and Kenneth Salem. </author> <title> Management of partially safe buffers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 44(3):394407, </volume> <month> March </month> <year> 1995. </year>
Reference-contexts: This makes all buffer cache changes permanent without writing to disk. Like the force-at-commit policy, this eliminates the need for checkpoints and a redo log in recovering from system crashes (partial redo) <ref> [Haerder83, Akyurek95] </ref>. This simplifies and accelerates recovery, because there is no need to redo incomplete operations; each commit is a transaction-consistent checkpoint. Recovering from media failures (global redo) still requires a redo log; however, redundant disk storage makes this scenario less likely [Chen94].
Reference: [APC96] <institution> The Power Protection Handbook. </institution> <type> Technical report, </type> <note> American Power Conversion, </note> <year> 1996. </year>
Reference-contexts: Memory is considered unreliable for two reasons: power outages and software crashes. Memorys vulnerability to power outages is straightforward to understand and fix. A $100 uninterruptible power supply can keep a system running long enough to dump memory to disk in the event of a power outage <ref> [APC96] </ref>, or one can use nonvolatile memory such as Flash RAM [Wu94]. Critical database installations often use uninterruptible power supplies to protect against power failure.
Reference: [Bartlett81] <author> Joel F. Bartlett. </author> <title> A NonStop Kernel. </title> <booktitle> In Proceedings of the 1981 Symposium on Operating System Principles, </booktitle> <pages> pages 22 29, </pages> <month> December </month> <year> 1981. </year>
Reference-contexts: Other general means to protect memory include using separate processes <ref> [Bartlett81] </ref>, replication [Liskov91, Muller96], and software fault isolation [Wahbe93]. [Copeland89] discusses two organizations for integrating reliable memory (safe RAM) in databases.
Reference: [Barton90] <author> James H. Barton, Edward W. Czeck, Zary Z. Segall, and Daniel P. Siewiorek. </author> <title> Fault injection experiments using FIAT. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(4):575582, </volume> <month> April </month> <year> 1990. </year>
Reference-contexts: Our primary goal in designing these faults is to generate a wide variety of database crashes. Our models are derived from studies of commercial databases and operating systems [Sullivan92, Sullivan91b, Lee93] and from prior models used in fault-injection studies <ref> [Barton90, Kao93, Kanawati95, Chen96] </ref>. The faults we inject range from low-level hardware faults such as ipping bits in memory to high-level software faults such as memory allocation errors. We classify injected faults into three categories: bit ips, low-level software faults, and high-level software faults. <p> This happened about 1/3 of the time and led to one instance of corruption. The first category of faults ips random bits in the databases address space <ref> [Barton90, Kanawati95] </ref>. We target three areas of the databases address space: the text, heap, and stack. These faults are easy to inject, and they cause a variety of different crashes. They are the least realistic of our bugs, however.
Reference: [Bershad95] <author> Brian N. Bershad, Stefan Savage, Przemyslaw Par-dyak, Emin Gun Sirer, Marc E. Fiuczynski, David Becker, Craig Chambers, and Susan Eggers. </author> <title> Extensibility, Safety and Performance in the SPIN Operating System. </title> <booktitle> In Proceedings of the 1995 Symposium on Operating Systems Principles, </booktitle> <pages> pages 267283, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: This is likely to make memory less effective at buffering database data, however, because a database can manage its buffer cache more effectively than file systems can (databases have more information on usage patterns). Researchers have proposed various ways for applications to control memory <ref> [Harty92, Patterson95, Bershad95, Seltzer96] </ref>, and eventually this may enable the file cache to be as effective as a database buffer cache.
Reference: [Bhide93] <author> Anupam Bhide, Daniel Dias, Nagui Halim, Basil Smith, and Francis Parr. </author> <title> A Case for Fault-Tolerant Memory for Transaction Processing. </title> <booktitle> In Proceedings of the 1993 International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 451460, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: To our knowledge, this is the first work that measures how often data is corrupted by database crashes. 2 Benefits of Reliable Memory This section summarizes the main benefits of reliable memory, which have been discussed and quantified by many studies <ref> [Copeland89, Bhide93, Lowell97] </ref>. Reliable memory can be used to store the log (or the tail of the log). Keeping the log in reliable memory removes all synchronous disk writes from the critical path of a transaction [Copeland89]. <p> In addition, storing the database buffer cache in reliable memory allows the system to begin operation after a crash with the contents present prior to the crash (a warm cache) <ref> [Sullivan93, Elhardt84, Bhide93] </ref>. Storing the log and/or the buffer cache in reliable memory can thus simplify and accelerate database systems.
Reference: [Bitton83] <author> Dina Bitton, David J. DeWitt, and Carolyn Turbyfill. </author> <title> Benchmarking Database SystemsA Systematic Approach. </title> <booktitle> In Very Large Database Conference, </booktitle> <pages> pages 819, </pages> <month> October </month> <year> 1983. </year>
Reference-contexts: We show the corruption rate for three weightings: equal, DB2, and IMS. Even without protection, the reliability of the persistent database buffer cache is about the same as a traditional, non-persistent buffer cache. We have observed similar results in an earlier experiment using the Wisconsin benchmark <ref> [Bitton83] </ref> as the workload.
Reference: [Bohannon97] <author> Philip Bohannon, Daniel Lieuwen, Rajeev Rasto-gi, S. Seshadri, Avi Silberschatz, and S. Sudarshan. </author> <title> The Architecture of the Dali Main-Memory Storage Manager. </title> <journal> Journal of Multimedia Tools and Applications, </journal> <year> 1997. </year>
Reference-contexts: For example, storing an appropriate pointer in reliable memory can save scanning the log to find the last checkpoint [DeWitt84]. A more aggressive use of reliable memory is to store the database buffer cache, or to store an entire main-memory database <ref> [GM92, Bohannon97] </ref>. This makes all buffer cache changes permanent without writing to disk. Like the force-at-commit policy, this eliminates the need for checkpoints and a redo log in recovering from system crashes (partial redo) [Haerder83, Akyurek95].
Reference: [Chen94] <author> Peter M. Chen, Edward K. Lee, Garth A. Gibson, Randy H. Katz, and David A. Patterson. </author> <title> RAID: High-Performance, Reliable Secondary Storage. </title> <journal> ACM Computing Surveys, </journal> <volume> 26(2):145188, </volume> <month> June </month> <year> 1994. </year>
Reference-contexts: This simplifies and accelerates recovery, because there is no need to redo incomplete operations; each commit is a transaction-consistent checkpoint. Recovering from media failures (global redo) still requires a redo log; however, redundant disk storage makes this scenario less likely <ref> [Chen94] </ref>. Since undo records can be eliminated after a transaction commits, removing the redo log implies that no log records need be written to disk if memory is large enough to contain the undo records for all transactions in progress [Agrawal89].
Reference: [Chen96] <author> Peter M. Chen, Wee Teck Ng, Subhachandra Chandra, Christopher M. Aycock, Gurushankar Rajamani, and David Low-ell. </author> <title> The Rio File Cache: Surviving Operating System Crashes. </title> <booktitle> In Proceedings of the 1996 International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), </booktitle> <pages> pages 7483, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Even with logging and group commit, disk bandwidth is a significant and growing bottleneck to high performance (Figure 1) [Rosenblum95]. Recent results in the Rio project at the University of Michigan show that it is possible to create memory that is as safe as disk from operating system crashes <ref> [Chen96] </ref>. This paper explores how to integrate the reliable memory provided by the Rio file cache into a database system. In particular, we examine how different software designs expose the memory to database crashes. <p> The performance improvement resulting from the simplicity of VistaVista is roughly 1/10 the size of RVMis hard to quantify but is probably also significant. 3 The Rio File Cache The Rio file cache is an area of memory, maintained by the operating system, that buffers file system data <ref> [Chen96] </ref>. <p> See <ref> [Chen96] </ref> for more details on these experiments and subsequent improvement in performance. The goal of this paper is to explore how to use the Rio file cache to provide reliable memory for databases. <p> Our primary goal in designing these faults is to generate a wide variety of database crashes. Our models are derived from studies of commercial databases and operating systems [Sullivan92, Sullivan91b, Lee93] and from prior models used in fault-injection studies <ref> [Barton90, Kao93, Kanawati95, Chen96] </ref>. The faults we inject range from low-level hardware faults such as ipping bits in memory to high-level software faults such as memory allocation errors. We classify injected faults into three categories: bit ips, low-level software faults, and high-level software faults.
Reference: [Copeland89] <author> George Copeland, Tom Keller, Ravi Krishnamur-thy, and Marc Smith. </author> <title> The Case for Safe RAM. </title> <booktitle> In Proceedings of the Fifteenth International Conference on Very Large Data Bases, </booktitle> <pages> pages 327335, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: To our knowledge, this is the first work that measures how often data is corrupted by database crashes. 2 Benefits of Reliable Memory This section summarizes the main benefits of reliable memory, which have been discussed and quantified by many studies <ref> [Copeland89, Bhide93, Lowell97] </ref>. Reliable memory can be used to store the log (or the tail of the log). Keeping the log in reliable memory removes all synchronous disk writes from the critical path of a transaction [Copeland89]. <p> Reliable memory can be used to store the log (or the tail of the log). Keeping the log in reliable memory removes all synchronous disk writes from the critical path of a transaction <ref> [Copeland89] </ref>. This decreases transaction commit time and can help to reduce lock contention and increase concurrency [DeWitt84]. It also removes the need for group commit, which improves log throughput at the cost of increased transaction commit time. <p> Other general means to protect memory include using separate processes [Bartlett81], replication [Liskov91, Muller96], and software fault isolation [Wahbe93]. <ref> [Copeland89] </ref> discusses two organizations for integrating reliable memory (safe RAM) in databases. A separate safe uses an I/O interface to reliable memory, while an integrated safe is similar to our memory interface to reliable memory. [Copeland89] evaluates analytically the performance of the separate safe, but does not evaluate the effect on <p> protect memory include using separate processes [Bartlett81], replication [Liskov91, Muller96], and software fault isolation [Wahbe93]. <ref> [Copeland89] </ref> discusses two organizations for integrating reliable memory (safe RAM) in databases. A separate safe uses an I/O interface to reliable memory, while an integrated safe is similar to our memory interface to reliable memory. [Copeland89] evaluates analytically the performance of the separate safe, but does not evaluate the effect on reliability of either organization. [Rahm92] examines different technologies that can be used as reliable memory (SSD, disk cache, extended memory) but assumes these are not directly addressable by the processor.
Reference: [DeWitt84] <author> D. J. DeWitt, R. H. Katz, F. Olken, L. D. Shapiro, M. R. Stonebraker, and D. Wood. </author> <title> Implementation Techniques for Main Memory Database Systems. </title> <booktitle> In Proceedings of the 1984 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 18, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: Reliable memory can be used to store the log (or the tail of the log). Keeping the log in reliable memory removes all synchronous disk writes from the critical path of a transaction [Copeland89]. This decreases transaction commit time and can help to reduce lock contention and increase concurrency <ref> [DeWitt84] </ref>. It also removes the need for group commit, which improves log throughput at the cost of increased transaction commit time. <p> It also removes the need for group commit, which improves log throughput at the cost of increased transaction commit time. Storing the log in reliable memory can also decrease disk bandwidth due to logging, because many log records can be removed before being written to the log disk <ref> [DeWitt84, Hagmann86] </ref>. For example, undo records may be removed if they belong to transactions that have committed, and redo records may be removed if they belong to transactions that have aborted. Finally, critical information may be stored in the stable memory to help improve recovery time. <p> Finally, critical information may be stored in the stable memory to help improve recovery time. For example, storing an appropriate pointer in reliable memory can save scanning the log to find the last checkpoint <ref> [DeWitt84] </ref>. A more aggressive use of reliable memory is to store the database buffer cache, or to store an entire main-memory database [GM92, Bohannon97]. This makes all buffer cache changes permanent without writing to disk.
Reference: [Elhardt84] <author> Klaus Elhardt and Rudolf Bayer. </author> <title> A Database Cache for High Performance and Fast Restart in Database Systems. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 9(4):503525, </volume> <month> Decem-ber </month> <year> 1984. </year>
Reference-contexts: In addition, storing the database buffer cache in reliable memory allows the system to begin operation after a crash with the contents present prior to the crash (a warm cache) <ref> [Sullivan93, Elhardt84, Bhide93] </ref>. Storing the log and/or the buffer cache in reliable memory can thus simplify and accelerate database systems.
Reference: [GM92] <author> Hector Garcia-Molina and Kenneth Salem. </author> <title> Main Mem ory Database Systems: An Overview. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 4(6):509516, </volume> <month> December </month> <year> 1992. </year>
Reference-contexts: For example, storing an appropriate pointer in reliable memory can save scanning the log to find the last checkpoint [DeWitt84]. A more aggressive use of reliable memory is to store the database buffer cache, or to store an entire main-memory database <ref> [GM92, Bohannon97] </ref>. This makes all buffer cache changes permanent without writing to disk. Like the force-at-commit policy, this eliminates the need for checkpoints and a redo log in recovering from system crashes (partial redo) [Haerder83, Akyurek95].
Reference: [Gray78] <author> J. N. Gray. </author> <title> Operating Systems: An Advanced Course. </title> <publisher> Springer-Verlag, </publisher> <year> 1978. </year> <booktitle> Notes on Database Operating Systems. </booktitle>
Reference-contexts: On the other hand, database systems traditionally assume that the contents of main memory (RAM) are lost whenever the system crashes [Gray81, Haerder83], an assumption that appears to have its roots in the switch from core memories to volatile DRAM <ref> [Gray78] </ref>. Memory is considered unreliable for two reasons: power outages and software crashes. Memorys vulnerability to power outages is straightforward to understand and fix. <p> First, buffer caches managed by the file system make it difficult for the database to order updates to disk. These writes to disk need to be done in order to obey the constraints imposed by write-ahead logging <ref> [Gray78] </ref>. To order updates to disk, databases either use fsync or bypass the file cache entirely using direct I/O. The Rio file cache solves this problem completely, because data is persistent as soon as it enters the file cache.
Reference: [Gray81] <author> Jim Gray, Paul McJones, Mike Blasgen, Bruce Lindsay, Raymond Lorie, Tom Price, Franco Putzolu, and Irving Traiger. </author> <title> The Recovery Manager of the System R Database Manager. </title> <journal> ACM Computing Surveys, </journal> <volume> 13(2):223242, </volume> <month> June </month> <year> 1981. </year>
Reference-contexts: 1 Introduction Current database systems store data on disk and in memory. Disks are considered stable storagethey are assumed to survive system crashes and power outages. On the other hand, database systems traditionally assume that the contents of main memory (RAM) are lost whenever the system crashes <ref> [Gray81, Haerder83] </ref>, an assumption that appears to have its roots in the switch from core memories to volatile DRAM [Gray78]. Memory is considered unreliable for two reasons: power outages and software crashes. Memorys vulnerability to power outages is straightforward to understand and fix.
Reference: [Haerder83] <author> Theo Haerder and Andreas Reuter. </author> <title> Principles of Transaction-Oriented Database Recovery. </title> <journal> ACM Computing Surveys, </journal> <volume> 15(4):287317, </volume> <month> December </month> <year> 1983. </year>
Reference-contexts: 1 Introduction Current database systems store data on disk and in memory. Disks are considered stable storagethey are assumed to survive system crashes and power outages. On the other hand, database systems traditionally assume that the contents of main memory (RAM) are lost whenever the system crashes <ref> [Gray81, Haerder83] </ref>, an assumption that appears to have its roots in the switch from core memories to volatile DRAM [Gray78]. Memory is considered unreliable for two reasons: power outages and software crashes. Memorys vulnerability to power outages is straightforward to understand and fix. <p> This makes all buffer cache changes permanent without writing to disk. Like the force-at-commit policy, this eliminates the need for checkpoints and a redo log in recovering from system crashes (partial redo) <ref> [Haerder83, Akyurek95] </ref>. This simplifies and accelerates recovery, because there is no need to redo incomplete operations; each commit is a transaction-consistent checkpoint. Recovering from media failures (global redo) still requires a redo log; however, redundant disk storage makes this scenario less likely [Chen94]. <p> Third, this design can simplify databases by eliminating the need for redo logs and checkpoints (Section 2). Making the database buffer cache persistent leads to a few changes to the database. These changes are the same as those needed by a database using a steal policy <ref> [Haerder83] </ref>. The steal policy allows dirty buffers to be written back to disk (that is, made persistent) at any time. In particular, buffers may be made persistent before the transaction commits. This policy requires an undo log so the original values may be restored if the transaction aborts.
Reference: [Hagmann86] <author> Robert B. Hagmann. </author> <title> A Crash Recovery Scheme for a Memory-Resident Database System. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35(9):839843, </volume> <month> September </month> <year> 1986. </year>
Reference-contexts: It also removes the need for group commit, which improves log throughput at the cost of increased transaction commit time. Storing the log in reliable memory can also decrease disk bandwidth due to logging, because many log records can be removed before being written to the log disk <ref> [DeWitt84, Hagmann86] </ref>. For example, undo records may be removed if they belong to transactions that have committed, and redo records may be removed if they belong to transactions that have aborted. Finally, critical information may be stored in the stable memory to help improve recovery time.
Reference: [Harty92] <author> Kieran Harty and David R. Cheriton. </author> <title> Application-Controlled Physical Memory using External Page-Cache Management. </title> <booktitle> In Proceedings of the 1992 International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), </booktitle> <pages> pages 187197, </pages> <year> 1992. </year>
Reference-contexts: This is likely to make memory less effective at buffering database data, however, because a database can manage its buffer cache more effectively than file systems can (databases have more information on usage patterns). Researchers have proposed various ways for applications to control memory <ref> [Harty92, Patterson95, Bershad95, Seltzer96] </ref>, and eventually this may enable the file cache to be as effective as a database buffer cache.
Reference: [Kanawati95] <author> Ghani A. Kanawati, Nasser A. Kanawati, and Jacob A. Abraham. FERRARI: </author> <title> A Flexible Software-Based Fault and Error Injection System. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 44(2):248260, </volume> <month> February </month> <year> 1995. </year>
Reference-contexts: Our primary goal in designing these faults is to generate a wide variety of database crashes. Our models are derived from studies of commercial databases and operating systems [Sullivan92, Sullivan91b, Lee93] and from prior models used in fault-injection studies <ref> [Barton90, Kao93, Kanawati95, Chen96] </ref>. The faults we inject range from low-level hardware faults such as ipping bits in memory to high-level software faults such as memory allocation errors. We classify injected faults into three categories: bit ips, low-level software faults, and high-level software faults. <p> This happened about 1/3 of the time and led to one instance of corruption. The first category of faults ips random bits in the databases address space <ref> [Barton90, Kanawati95] </ref>. We target three areas of the databases address space: the text, heap, and stack. These faults are easy to inject, and they cause a variety of different crashes. They are the least realistic of our bugs, however.
Reference: [Kao93] <author> Wei-Lun Kao, Ravishankar K. Iyer, and Dong Tang. </author> <title> FINE: A Fault Injection and Monitoring Environment for Tracing the UNIX System Behavior under Faults. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 19(11):11051118, </volume> <month> November </month> <year> 1993. </year>
Reference-contexts: Our primary goal in designing these faults is to generate a wide variety of database crashes. Our models are derived from studies of commercial databases and operating systems [Sullivan92, Sullivan91b, Lee93] and from prior models used in fault-injection studies <ref> [Barton90, Kao93, Kanawati95, Chen96] </ref>. The faults we inject range from low-level hardware faults such as ipping bits in memory to high-level software faults such as memory allocation errors. We classify injected faults into three categories: bit ips, low-level software faults, and high-level software faults. <p> The second category of fault changes individual instructions in the database text segment. These faults are intended to approximate the assembly-level manifestation of real C-level programming errors <ref> [Kao93] </ref>. We corrupt assignment statements by changing the source or destination register. We corrupt conditional constructs by deleting branches. We also delete random instructions (both branch and non-branch). The last and most extensive category of faults imitate specific programming errors in the database [Sullivan91b]. <p> i&lt;sizeUsed; i++) -a [i] = b [i]-; for (i=0; i&lt;sizeTotal; i++) -a [i] = b [i]-; off-by-one for (i=0; i&lt;size; i++) for (i=0; i&lt;=size; i++) synchronization getWriteLock; write (); freeWriteLock; write (); memory leak free (ptr); interface error insert (buf, index); insert (buf1,index); variable at the start of a procedure <ref> [Kao93, Lee93] </ref>. We inject pointer corruption by 1) finding a register that is used as a base register of a load or store and 2) deleting the most recent instruction before the load/store that modifies that register [Sullivan91b, Lee93].
Reference: [Lee93] <author> Inhwan Lee and Ravishankar K. Iyer. </author> <title> Faults, Symptoms, and Software Fault Tolerance in the Tandem GUARDIAN Operating System. </title> <booktitle> In International Symposium on Fault-Tolerant Computing (FTCS), pages 2029, </booktitle> <year> 1993. </year>
Reference-contexts: Our primary goal in designing these faults is to generate a wide variety of database crashes. Our models are derived from studies of commercial databases and operating systems <ref> [Sullivan92, Sullivan91b, Lee93] </ref> and from prior models used in fault-injection studies [Barton90, Kao93, Kanawati95, Chen96]. The faults we inject range from low-level hardware faults such as ipping bits in memory to high-level software faults such as memory allocation errors. <p> i&lt;sizeUsed; i++) -a [i] = b [i]-; for (i=0; i&lt;sizeTotal; i++) -a [i] = b [i]-; off-by-one for (i=0; i&lt;size; i++) for (i=0; i&lt;=size; i++) synchronization getWriteLock; write (); freeWriteLock; write (); memory leak free (ptr); interface error insert (buf, index); insert (buf1,index); variable at the start of a procedure <ref> [Kao93, Lee93] </ref>. We inject pointer corruption by 1) finding a register that is used as a base register of a load or store and 2) deleting the most recent instruction before the load/store that modifies that register [Sullivan91b, Lee93]. <p> We inject pointer corruption by 1) finding a register that is used as a base register of a load or store and 2) deleting the most recent instruction before the load/store that modifies that register <ref> [Sullivan91b, Lee93] </ref>. We do not corrupt the stack pointer register, as this is used to access local variables instead of as a pointer variable.
Reference: [Liskov91] <author> Barbara Liskov, Sanjay Ghemawat, Robert Gruber, Paul Johnson, Liuba Shrira, and Michael Williams. </author> <title> Replication in the Harp File System. </title> <booktitle> In Proceedings of the 1991 Symposium on Operating System Principles, </booktitle> <pages> pages 226238, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Other general means to protect memory include using separate processes [Bartlett81], replication <ref> [Liskov91, Muller96] </ref>, and software fault isolation [Wahbe93]. [Copeland89] discusses two organizations for integrating reliable memory (safe RAM) in databases.
Reference: [Lowell97] <author> David E. Lowell and Peter M. Chen. </author> <title> Free Transactions with Rio Vista. </title> <booktitle> In Proceedings of the 1997 Symposium on Operating Systems Principles, </booktitle> <month> October </month> <year> 1997. </year>
Reference-contexts: To our knowledge, this is the first work that measures how often data is corrupted by database crashes. 2 Benefits of Reliable Memory This section summarizes the main benefits of reliable memory, which have been discussed and quantified by many studies <ref> [Copeland89, Bhide93, Lowell97] </ref>. Reliable memory can be used to store the log (or the tail of the log). Keeping the log in reliable memory removes all synchronous disk writes from the critical path of a transaction [Copeland89]. <p> Storing the log and/or the buffer cache in reliable memory can thus simplify and accelerate database systems. A recent study shows that using a persistent database buffer cache can yield a system 40 times faster than using a non-persistent buffer cache, even when both run on reliable memory <ref> [Lowell97] </ref>. Figure 2 compares the performance of three systems on a workload based on TPC-B. RVM is a simple transaction system with a redo log and achieves about 100 transactions/second without reliable memory [Satyanarayanan93].
Reference: [Muller96] <author> Gilles Muller, Michel Banatre, Nadine Peyrouze, and Bruno Rochat. </author> <title> Lessons from FTM: An Experiment in Design and Implementation of a Low-Cost Fault-Tolerant System. </title> <journal> IEEE Transactions on Reliability, </journal> <volume> 45(2):332340, </volume> <month> June </month> <year> 1996. </year>
Reference-contexts: Other general means to protect memory include using separate processes [Bartlett81], replication <ref> [Liskov91, Muller96] </ref>, and software fault isolation [Wahbe93]. [Copeland89] discusses two organizations for integrating reliable memory (safe RAM) in databases.
Reference: [Patterson95] <author> R. Hugo Patterson, Garth A. Gibson, Eka Ginting, Daniel Stodolsky, and Jim Zelenka. </author> <title> Informed Prefetching and Caching. </title> <booktitle> In Proceedings of the 1995 Symposium on Operating Systems Principles, </booktitle> <pages> pages 7995, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: This is likely to make memory less effective at buffering database data, however, because a database can manage its buffer cache more effectively than file systems can (databases have more information on usage patterns). Researchers have proposed various ways for applications to control memory <ref> [Harty92, Patterson95, Bershad95, Seltzer96] </ref>, and eventually this may enable the file cache to be as effective as a database buffer cache.
Reference: [Rahm92] <author> Erhard Rahm. </author> <title> Performance Evaluation of Extended Storage Architectures for Transaction Processing. </title> <booktitle> In Proceedings of the 1992 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 308317, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The interface to stable storage with this design is now much simpler: load/store instructions instead of read/write system calls. Hence it is easier for a software bug in the database to accidentally overwrite persistent data <ref> [Rahm92, Sullivan91a] </ref>. This section discusses the increased vulnerability conceptually, and Section 6 com database write ()read () database system operating system Rio file cache (reliable memory) hides the reliable memory under the file system interface. <p> A separate safe uses an I/O interface to reliable memory, while an integrated safe is similar to our memory interface to reliable memory. [Copeland89] evaluates analytically the performance of the separate safe, but does not evaluate the effect on reliability of either organization. <ref> [Rahm92] </ref> examines different technologies that can be used as reliable memory (SSD, disk cache, extended memory) but assumes these are not directly addressable by the processor. Hence he evaluates only the performance benefits of using an I/O interface to reliable memory.
Reference: [Rosenblum95] <author> Mendel Rosenblum, Edouard Bugnion, Stephen Alan Herrod, Emmett Witchel, and Anoop Gupta. </author> <title> The Impact of Architectural Trends on Operating System Performance. </title> <booktitle> In Proceedings of the 1995 Symposium on Operating Systems Principles, </booktitle> <pages> pages 285298, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: Systems use strategies such as logging and group commit to minimize disk I/O, but these strategies complicate locking and recovery and do not improve commit response time. Even with logging and group commit, disk bandwidth is a significant and growing bottleneck to high performance (Figure 1) <ref> [Rosenblum95] </ref>. Recent results in the Rio project at the University of Michigan show that it is possible to create memory that is as safe as disk from operating system crashes [Chen96]. This paper explores how to integrate the reliable memory provided by the Rio file cache into a database system. <p> It is protected from operating system crashes by virtual memory protection, and this protection is enhanced 100 60 20 1994 1996 1998 Disk I/O Other Normalized Ex ecution T ime (%) <ref> [Rosenblum95] </ref> and shows execution time of a database workload (Sybase SQL server running the TPC-B benchmark) on three machine models. The time is normalized to the speed of the 1994 model.
Reference: [Satyanarayanan93] <author> M. Satyanarayanan, Henry H. Mashburn, Puneet Kumar, David C. Steere, and James J. Kistler. </author> <title> Lightweight Recoverable Virtual Memory. </title> <booktitle> In Proceedings of the 1993 Symposium on Operating System Principles, </booktitle> <pages> pages 146160, </pages> <month> De-cember </month> <year> 1993. </year>
Reference-contexts: Figure 2 compares the performance of three systems on a workload based on TPC-B. RVM is a simple transaction system with a redo log and achieves about 100 transactions/second without reliable memory <ref> [Satyanarayanan93] </ref>. Running RVM on Rio with an I/O interface to reliable memory speeds it up by a factor of 13. Vista is a transaction system tailored to run on Rio.
Reference: [Seltzer96] <author> Margo I. Seltzer, Yasuhiro Endo, Christopher Small, and Keith A. Smith. </author> <title> Dealing With Disaster: Surviving Misbehaving Kernel Extensions. </title> <booktitle> Operating Systems Design and Implementation (OSDI), </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: This is likely to make memory less effective at buffering database data, however, because a database can manage its buffer cache more effectively than file systems can (databases have more information on usage patterns). Researchers have proposed various ways for applications to control memory <ref> [Harty92, Patterson95, Bershad95, Seltzer96] </ref>, and eventually this may enable the file cache to be as effective as a database buffer cache.
Reference: [Srivastava94] <author> Amitabh Srivastava and Alan Eustace. </author> <title> ATOM: A System for Building Customized Program Analysis Tools. </title> <booktitle> In Proceedings of the 1994 Conference on Programming Language Design and Implementation (PLDI), </booktitle> <pages> pages 196205, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: This is con sistent with the estimates given in [Sullivan91a, Sullivan93]. There are several factors that minimize the reliability impact of persistent buffer caches. First, most stores in Postgres are not to the buffer cache. Using the ATOM program analysis tool <ref> [Srivastava94] </ref>, we found that only 2-3% of stores executed during a run were to the buffer cache. Second, store instructions that are not intended to access the buffer cache have little chance of accidentally wandering into buffer cache space, especially with the vast, 64-bit virtual address space on DEC Alphas.
Reference: [Stonebraker81] <author> Michael Stonebraker. </author> <title> Operating system support for database management. </title> <journal> Communications of the ACM, </journal> <volume> 24(7):412418, </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: The goal of this paper is to explore how to use the Rio file cache to provide reliable memory for databases. Database systems traditionally encounter two problems in trying to use buffer caches managed by the operating system (the file cache) <ref> [Stonebraker81] </ref>. First, buffer caches managed by the file system make it difficult for the database to order updates to disk. These writes to disk need to be done in order to obey the constraints imposed by write-ahead logging [Gray78].
Reference: [Stonebraker87] <author> M. Stonebraker. </author> <title> The design of the POSTGRES storage system. </title> <booktitle> In Proceedings of the 1987 International Conference on Very Large Data Bases, </booktitle> <pages> pages 289300, </pages> <month> September </month> <year> 1987. </year>
Reference-contexts: This exposes reliable memory to database crashes, and we quantify the increased risk posed by this design. 4 The Postgres Storage System We use the Postgres95 database management system developed at U.C. Berkeley as the database in our experiments <ref> [Stonebraker87] </ref>. Postgres has a few unique features which are relevant to this paper, but our results should apply to more conventional databases as well. One novel aspect of Postgres is that it appends new data at commit.
Reference: [Sullivan91a] <author> M. Sullivan and M. Stonebraker. </author> <title> Using write protected data structures to improve software fault tolerance in highly available database management systems. </title> <booktitle> In Proceedings of the 1991 International Conference on Very Large Data Bases (VLDB), </booktitle> <pages> pages 171180, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: The interface to stable storage with this design is now much simpler: load/store instructions instead of read/write system calls. Hence it is easier for a software bug in the database to accidentally overwrite persistent data <ref> [Rahm92, Sullivan91a] </ref>. This section discusses the increased vulnerability conceptually, and Section 6 com database write ()read () database system operating system Rio file cache (reliable memory) hides the reliable memory under the file system interface. <p> long enough to propagate them to disk. 5.3 Memory Interface to Reliable Memory with Protection (Persistent, Protected Database Buffer Cache) Our third design also uses a memory interface to reliable memory but adds virtual memory protection to protect against wild stores to dirty, committed buffers (this scheme was suggested in <ref> [Sullivan91a] </ref>). In this system, clean or committed buffers are kept write protected. When a transaction locks an object, the page containing the object is unprotected; when the transaction commits, the page is reprotected. <p> Our main conclusion is that mapping reliable memory directly into the database address space has only a small effect on the overall reliability of the system. This is con sistent with the estimates given in <ref> [Sullivan91a, Sullivan93] </ref>. There are several factors that minimize the reliability impact of persistent buffer caches. First, most stores in Postgres are not to the buffer cache. Using the ATOM program analysis tool [Srivastava94], we found that only 2-3% of stores executed during a run were to the buffer cache. <p> In this section, we describe prior studies that have suggested methods for integrating and protecting reliable memory in databases. The study most closely related to this paper was done by Mark Sullivan in the context of the Postgres project <ref> [Sullivan91a, Sullivan93] </ref>. Sullivan implemented two general methods for protecting database buffers from database errors using virtual memory protection. Expose page unprotects a page before writing to a record on the page and reprotects the page after the write is done. <p> examining prior failure studies and estimating which fault categories were most likely to be affected. [Sullivan93] concludes that only 5-7% of errors are the type of error (wild stores) that would be prevented by his protection mechanism, although this ignores secondary effects such as wild stores generated by other errors. <ref> [Sullivan91a] </ref> mentions as future work the type of fault injection studies performed in this paper. These fault injection studies can provide more detailed data than Table 3: Proportional Mapping.
Reference: [Sullivan91b] <author> Mark Sullivan and R. Chillarege. </author> <title> Software Defects and Their Impact on System AvailabilityA Study of Field Failures in Operating Systems. </title> <booktitle> In Proceedings of the 1991 International Symposium on Fault-Tolerant Computing, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: Our primary goal in designing these faults is to generate a wide variety of database crashes. Our models are derived from studies of commercial databases and operating systems <ref> [Sullivan92, Sullivan91b, Lee93] </ref> and from prior models used in fault-injection studies [Barton90, Kao93, Kanawati95, Chen96]. The faults we inject range from low-level hardware faults such as ipping bits in memory to high-level software faults such as memory allocation errors. <p> We corrupt assignment statements by changing the source or destination register. We corrupt conditional constructs by deleting branches. We also delete random instructions (both branch and non-branch). The last and most extensive category of faults imitate specific programming errors in the database <ref> [Sullivan91b] </ref>. These are more targeted at specific programming errors than the previous fault category. We inject an initialization fault by deleting instructions responsible for initializing a Table 1: Relating faults to programming errors. <p> We inject pointer corruption by 1) finding a register that is used as a base register of a load or store and 2) deleting the most recent instruction before the load/store that modifies that register <ref> [Sullivan91b, Lee93] </ref>. We do not corrupt the stack pointer register, as this is used to access local variables instead of as a pointer variable. <p> The length of the overrun was distributed as follows: 50% corrupt one byte; 44% corrupt 2-1024 bytes; 6% corrupt 2-4 KB. This distribution was chosen by starting with the data gathered in <ref> [Sullivan91b] </ref> and modifying it somewhat according to our specific platform and experience. bcopy is set to inject this error every 1000-4000 times it is called; this occurs approximately every 5 seconds. We inject off-by-one errors by changing conditions such as &gt; to &gt;=, &lt; to &lt;=, and so on.
Reference: [Sullivan92] <author> Mark Sullivan and Ram Chillarege. </author> <title> A Comparison of Software Defects in Database Management Systems and Operating Systems. </title> <booktitle> In Proceedings of the 1992 International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 475484, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Our primary goal in designing these faults is to generate a wide variety of database crashes. Our models are derived from studies of commercial databases and operating systems <ref> [Sullivan92, Sullivan91b, Lee93] </ref> and from prior models used in fault-injection studies [Barton90, Kao93, Kanawati95, Chen96]. The faults we inject range from low-level hardware faults such as ipping bits in memory to high-level software faults such as memory allocation errors. <p> As it is difficult to prove that our fault model represents real faults, we present two other interpretations of the data by varying the weights associated with each fault type according to fault distributions published on DB2 and IMS <ref> [Sullivan92] </ref>. Sullivans study includes a detailed breakdown of software errors according to the following classification: deadlock and synchronization, pointer management, memory leak, uninitialized data, copy overrun, allocation management, statement logic, data error, interface error, undefined state, and other. <p> These fault injection studies can provide more detailed data than Table 3: Proportional Mapping. This table shows how we map between the fault type in our study and those of <ref> [Sullivan92] </ref>, and the corresponding weight assigned to each fault type.
Reference: [Sullivan93] <author> Mark Paul Sullivan. </author> <title> System Support for Software Fault Tolerance in Highly Available Database Management Systems. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: In addition, storing the database buffer cache in reliable memory allows the system to begin operation after a crash with the contents present prior to the crash (a warm cache) <ref> [Sullivan93, Elhardt84, Bhide93] </ref>. Storing the log and/or the buffer cache in reliable memory can thus simplify and accelerate database systems. <p> Our main conclusion is that mapping reliable memory directly into the database address space has only a small effect on the overall reliability of the system. This is con sistent with the estimates given in <ref> [Sullivan91a, Sullivan93] </ref>. There are several factors that minimize the reliability impact of persistent buffer caches. First, most stores in Postgres are not to the buffer cache. Using the ATOM program analysis tool [Srivastava94], we found that only 2-3% of stores executed during a run were to the buffer cache. <p> In this section, we describe prior studies that have suggested methods for integrating and protecting reliable memory in databases. The study most closely related to this paper was done by Mark Sullivan in the context of the Postgres project <ref> [Sullivan91a, Sullivan93] </ref>. Sullivan implemented two general methods for protecting database buffers from database errors using virtual memory protection. Expose page unprotects a page before writing to a record on the page and reprotects the page after the write is done. <p> Sullivan evaluates the reliability impact of these protection schemes by examining prior failure studies and estimating which fault categories were most likely to be affected. <ref> [Sullivan93] </ref> concludes that only 5-7% of errors are the type of error (wild stores) that would be prevented by his protection mechanism, although this ignores secondary effects such as wild stores generated by other errors. [Sullivan91a] mentions as future work the type of fault injection studies performed in this paper.
Reference: [TPC90] <editor> TPC Benchmark B Standard Specification. </editor> <title> Technical report, Transaction Processing Performance Council, </title> <month> August </month> <year> 1990. </year>
Reference-contexts: This section compares the reliability of the different designs quantitatively by injecting software bugs into Postgres to crash it, then measuring the amount of corruption in the database. We detect database corruption by running a repeatable set of database commands modeled after TPB-B <ref> [TPC90] </ref> and comparing the database image after a crash with the image that should exist at the point at which the crash occurred. 6.1 Fault Models This section describes the types of faults we inject.
Reference: [Wahbe93] <author> Robert Wahbe, Steven Lucco, Thomas E. Anderson, and Susan L. Graham. </author> <title> Efficient Software-Based Fault Isolation. </title> <booktitle> In Proceedings of the 14th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 203216, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Other general means to protect memory include using separate processes [Bartlett81], replication [Liskov91, Muller96], and software fault isolation <ref> [Wahbe93] </ref>. [Copeland89] discusses two organizations for integrating reliable memory (safe RAM) in databases.
Reference: [Wu94] <author> Michael Wu and Willy Zwaenepoel. eNVy: </author> <title> A Non-Volatile, Main Memory Storage System. </title> <booktitle> In Proceedings of the 1994 International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), </booktitle> <month> October </month> <year> 1994. </year>
Reference-contexts: Memorys vulnerability to power outages is straightforward to understand and fix. A $100 uninterruptible power supply can keep a system running long enough to dump memory to disk in the event of a power outage [APC96], or one can use nonvolatile memory such as Flash RAM <ref> [Wu94] </ref>. Critical database installations often use uninterruptible power supplies to protect against power failure. Memorys vulnerability to software crashes is more challenging to fix; thus database systems assume the contents of buffers in memory are lost when either the operating system or database system crashes.
References-found: 41

