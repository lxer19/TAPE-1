URL: http://www.cs.rutgers.edu/~davison/pubs/hpcdtr59.ps
Refering-URL: http://www.cs.rutgers.edu/~davison/pubs/hpcdtr59.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: flou,davisong@cs.rutgers.edu  
Title: Highest Utility First Search: a Control Method for Multi-level Stochastic Design 1  
Author: Louis Steinberg J. Storrs Hall Brian D. Davison 
Address: New Brunswick, NJ 08903, USA  
Affiliation: Department of Computer Science, Rutgers University  
Abstract: An intrinsic characteristic of stochastic optimization methods, such as simulated annealing, genetic algorithms and multi-start hill climbing, is that they can be run again and again on the same inputs, each time potentially producing a different answer. When such algorithms are used in a design process with multiple levels of abstraction, where the output of one stochastic optimizer becomes the problem statement for another stochastic optimizer, we get an implicit tree of alternative designs. After each optimizer run we face a control problem of which level's optimizer to run next, and which design alternative to run it on. This problem is made more difficult by the fact that we generally can get a precise evaluation of the design alternatives only at the lowest level (the final results), and must make do at higher levels with only an estimate of how good a final design each alternative will lead to. 
Abstract-found: 1
Intro-found: 1
Reference: [Boddy and Dean, 1994] <author> Boddy, M. and Dean, T. </author> <year> (1994). </year> <title> Deliberation scheduling for problem solving in time-constrained environments. </title> <journal> Artificial Intelligence, </journal> <volume> 67 </volume> <pages> 245-285. </pages>
Reference-contexts: Hansen and Zilberstein [Hansen and Zilberstein, 1996a], [Hansen and Zilberstein, 1996b] are concerned with anytime algorithms <ref> [Boddy and Dean, 1994] </ref>, [Dean and Boddy, 1988]. An anytime algorithm is one that can be stopped after working for a variable amount of time.
Reference: [Dean and Boddy, 1988] <author> Dean, T. L. and Boddy, M. </author> <year> (1988). </year> <title> An analysis of time-dependent planning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 49-54, </pages> <address> Minneapolis, Minnesota. </address>
Reference-contexts: Hansen and Zilberstein [Hansen and Zilberstein, 1996a], [Hansen and Zilberstein, 1996b] are concerned with anytime algorithms [Boddy and Dean, 1994], <ref> [Dean and Boddy, 1988] </ref>. An anytime algorithm is one that can be stopped after working for a variable amount of time. If it is stopped after working for a short time, it will give lower quality results than if it is stopped after working for a longer time.
Reference: [Etzioni, 1991] <author> Etzioni, O. </author> <year> (1991). </year> <title> Embedding decision-analytic control in a learning architecture. </title> <journal> Artificial Intelligence, </journal> <volume> 49 </volume> <pages> 129-159. </pages>
Reference-contexts: Another relevant paper is <ref> [Etzioni, 1991] </ref>. <p> If it is stopped before any ground-level design is produced, then it gives no answer at all. It would be interesting to see if HUFS could be turned into an anytime algorithm; this is related to the issue of our model of time cost 30 discussed above. Etzioni <ref> [Etzioni, 1991] </ref> describes an approach to a planning problem that is quite different from our problem here, but he uses a notion called "marginal utility".
Reference: [Hansen and Zilberstein, 1996a] <author> Hansen, E. and Zilberstein, S. </author> <year> (1996a). </year> <title> Monitoring anytime algorithms. </title> <journal> SIGART Bulletin Special Issue on Anytime Algorithms and Deliberation Scheduling, </journal> <volume> 7(2) </volume> <pages> 28-33. </pages>
Reference-contexts: Hansen and Zilberstein <ref> [Hansen and Zilberstein, 1996a] </ref>, [Hansen and Zilberstein, 1996b] are concerned with anytime algorithms [Boddy and Dean, 1994], [Dean and Boddy, 1988]. An anytime algorithm is one that can be stopped after working for a variable amount of time. <p> Two papers, <ref> [Hansen and Zilberstein, 1996a] </ref> and [Hansen and Zilberstein, 1996b], deal specifically with the issue of monitoring anytime algorithms, i.e. deciding how long to run them. <p> Our problem here is a case of what they refer to as "active monitoring", basing the decision of when to stop in part on what occurs during the process, rather than making the decision before the run starts. <ref> [Hansen and Zilberstein, 1996a] </ref> defines the "myopic expected value of computation" (myopic EVC) as "the expected utility of acting on the result that will be available after continuing the algorithm for exactly one more time step minus the expected value of acting immediately on the result currently available." This is equivalent
Reference: [Hansen and Zilberstein, 1996b] <author> Hansen, E. and Zilberstein, S. </author> <year> (1996b). </year> <title> Monitoring the progress of anytime problem-solving. </title> <booktitle> In Proceedings of the 13th National Conference on Artificial Intelligence, </booktitle> <pages> pages 1229-1234, </pages> <month> Portland,Oregon. </month>
Reference-contexts: Hansen and Zilberstein [Hansen and Zilberstein, 1996a], <ref> [Hansen and Zilberstein, 1996b] </ref> are concerned with anytime algorithms [Boddy and Dean, 1994], [Dean and Boddy, 1988]. An anytime algorithm is one that can be stopped after working for a variable amount of time. <p> Two papers, [Hansen and Zilberstein, 1996a] and <ref> [Hansen and Zilberstein, 1996b] </ref>, deal specifically with the issue of monitoring anytime algorithms, i.e. deciding how long to run them.
Reference: [Russell and Wefald, 1991] <author> Russell, S. and Wefald, E. </author> <year> (1991). </year> <title> Do the Right Thing. </title> <publisher> MIT Press. </publisher>
Reference-contexts: This approach was inspired by the "rational meta-reasoning" advocated by Russell and Wefald <ref> [Russell and Wefald, 1991] </ref>. In our context, we can use the notion of the utility of a computation to define the utility of a design alternative. <p> and use HUFS to handle the variance, the total system may be faster than the more complex GA or SA alone. 6 Related Work The two bodies of literature that are most relevant to our work on HUFS are the work on utility-based meta-reasoning by Russell and Wefald reported in <ref> [Russell and Wefald, 1991] </ref> and the work on monitoring anytime algorithms by Zilberstein and colleagues. Another relevant paper is [Etzioni, 1991].
Reference: [Zilberstein, 1993] <author> Zilberstein, S. </author> <year> (1993). </year> <title> Operational Rationality Through Compilation of Anytime Algorithms. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley. </institution>
Reference-contexts: However, Hansen and Zilberstein are concerned with the general case of anytime algorithms (and also with the cost of the monitoring, which we do not consider), and thus does not derive any more specific formula for myopic EVC. They also do not consider multi-level systems. <ref> [Zilberstein, 1993] </ref> and [Zilberstein and Russell, 1996] primarily deal with composing anytime algorithms into larger anytime algorithms, but also deal with monitoring. They define a stopping rule similar to ours and prove that, under conditions similar to those that hold in our single-level case, it is optimal.
Reference: [Zilberstein and Russell, 1996] <author> Zilberstein, S. and Russell, S. </author> <year> (1996). </year> <title> Optimal composition of real-time systems. </title> <journal> Artificial Intelligence, 82(1-2):181-213. </journal>
Reference-contexts: However, Hansen and Zilberstein are concerned with the general case of anytime algorithms (and also with the cost of the monitoring, which we do not consider), and thus does not derive any more specific formula for myopic EVC. They also do not consider multi-level systems. [Zilberstein, 1993] and <ref> [Zilberstein and Russell, 1996] </ref> primarily deal with composing anytime algorithms into larger anytime algorithms, but also deal with monitoring. They define a stopping rule similar to ours and prove that, under conditions similar to those that hold in our single-level case, it is optimal.
References-found: 8

