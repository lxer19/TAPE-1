URL: http://www.cse.ucsc.edu/~manfred/pubs/lin.ps
Refering-URL: http://www.cse.ucsc.edu/~manfred/pubs.html
Root-URL: http://www.cse.ucsc.edu
Title: Exponentiated Gradient Versus Gradient Descent for Linear Predictors  
Author: Jyrki Kivinen Manfred K. Warmuth 
Keyword: On-line prediction, linear regression, gradient descent, worst-case analysis  
Date: September 5, 1996  
Address: P.O. Box 26 (Teollisuuskatu 23)  Finland  Santa Cruz, CA 95064 USA  
Affiliation: Department of Computer Science  University of Helsinki  Computer and Information Sciences University of California, Santa Cruz  
Pubnum: FIN-00014  
Abstract: We consider two algorithm for on-line prediction based on a linear model. The algorithms are the well-known gradient descent (GD) algorithm and a new algorithm, which we call EG . They both maintain a weight vector using simple updates. For the GD algorithm, the update is based on subtracting the gradient of the squared error made on a prediction. The EG algorithm uses the components of the gradient in the exponents of factors that are used in updating the weight vector multiplicatively. We present worst-case loss bounds for EG and compare them to previously known bounds for the GD algorithm. The bounds suggest that the losses of the algorithms are in general incomparable, but EG has a much smaller loss if only few components of the input are relevant for the predictions. We have performed experiments, which show that our worst-case upper bounds are quite tight already on simple artificial data. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Amari, S. </author> <year> (1994), </year> <title> "Information geometry of the EM and em algorithms for neural networks," </title> <type> Technical Report METR 94-4, </type> <institution> University of Tokyo. </institution>
Reference: <author> Amari, S. </author> <year> (1995), </year> <title> The EM algorithm and information geometry in neural network learning, </title> <booktitle> Neural Computation 7, </booktitle> <pages> 13-18. </pages>
Reference: <author> Boser, B. E., Guyon, I. M., and Vapnik, V. N. </author> <year> (1992), </year> <title> A training algorithm for optimal margin classifiers, </title> <booktitle> in "Proceedings, 5th Annual Workshop on Computational Learning Theory," </booktitle> <pages> pp. 144-152, </pages> <publisher> ACM Press, </publisher> <address> New York. </address>
Reference-contexts: Then a linear prediction algorithm could actually use a linear combination of the basis functions as its predictor. As an example, we might include all the O (N q ) products of up to q original input variables <ref> (Boser et al., 1992) </ref>. Assuming that the input variables are in the range [1; 1], this does not increase the L 1 norms of the instances.
Reference: <author> Cesa-Bianchi, N., Freund, Y., Haussler, D., Helmbold, D. P., Schapire, R. E., and Warmuth, M. K. </author> <year> (1994), </year> <title> "How to use expert advice," </title> <type> Technical Report UCSC-CRL-94-33, </type> <institution> University of California, </institution> <address> Santa Cruz, </address> <booktitle> Computer Research Laboratory. An extended abstract appeared in "Proceedings, 25th Annual ACM Symposium on the Theory of Computing," </booktitle> <pages> pp. 382-381, </pages> <publisher> ACM Press, </publisher> <address> New York. </address>
Reference: <author> Cesa-Bianchi, N., Long, P., and Warmuth, M. K. </author> <year> (1996), </year> <title> Worst-case quadratic loss bounds for on-line prediction of linear functions by gradient descent, </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 7, </volume> <pages> 604-619. </pages>
Reference: <author> Cormen, T. H., Leiserson, C. E., and Rivest, R. L. </author> <year> (1990), </year> <title> "Introduction to Algorithms," </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address> <note> Exponentiated gradient 56 Dempster,A. </note> <author> P., Laird, N. M., and Rubin, D. B. </author> <year> (1977), </year> <title> Maximum-likelihood from incomplete data via the EM algorithm, </title> <journal> Journal of the Royal Statistical Society B39, </journal> <pages> 1-38. </pages>
Reference-contexts: These distance measures will also be useful in proving worst-case loss bounds. They have a role similar to that of potential functions in amortized algorithm analysis <ref> (Cormen et al., 1990) </ref>. <p> Different distance functions lead to radically different algorithms. This framework has been adapted recently (Helmbold et al., 1996b and 1996c) to an unsupervised setting. 3. The distance function also serves in a second role as a potential function in proving worst-case loss bounds by amortized analysis <ref> (Cormen et al., 1990) </ref>. The bounds are first expressed as a function of the learning rate and various norms of the instances and target vectors, as well as the loss of the target vector. Good loss bounds are then obtained by carefully tuning the learning rate.
Reference: <author> Haussler, D., Kivinen, J., and Warmuth, M. K. </author> <year> (1994), </year> <title> "Tight worst-case loss bounds for predicting with expert advice," </title> <type> Technical Report UCSC-CRL-94-36, </type> <institution> University of Cali-fornia, Santa Cruz, Computer Research Laboratory. </institution> <note> Partial results appeared in "Euro-COLT '93," pp. </note> <editor> 109-120, </editor> <publisher> Clarendon Press, </publisher> <address> Oxford, </address> <booktitle> and in "EuroCOLT '95," </booktitle> <pages> pp. 69-83, </pages> <publisher> Springer, </publisher> <address> Berlin. </address>
Reference: <author> Haykin, S. </author> <year> (1991), </year> <title> "Adaptive Filter Theory," </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ. </address> <note> Second edition. </note>
Reference: <author> Haykin, S. </author> <year> (1993), </year> <title> "Neural Networks: a Comprehensive Foundation," </title> <publisher> Macmillan, </publisher> <address> New York. </address>
Reference: <author> Helmbold, D. P., Kivinen, J., and Warmuth, M. K. </author> <year> (1996a), </year> <title> Worst-case loss bounds for sig-moided linear neurons, </title> <booktitle> in "Advances in Neural Information Processing Systems 8," </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <note> MA (to appear). </note>
Reference: <author> Helmbold, D. P., Schapire, R. E., Singer, Y., and Warmuth, M. K. </author> <year> (1996b), </year> <title> A comparison of new and old algorithms for a mixture estimation problem, </title> <note> Machine Learning (to appear). </note>
Reference-contexts: However, we shall see in Subsection 4.4 that the update rule (3.5) also has another motivation that is not based on approximating (3.3). It has also been noticed that in applying the exponentiated gradient update to a certain unsupervised learning problem <ref> (Helmbold et al., 1996b and 1996c) </ref> the approximation given here leads to a generalization of the Expectation Maximization algorithm (Dempster et al., 1977). Note that the update rule (3.5) maintains the invariant P N i=1 w t;j = 1. <p> In a simple unsupervised learning problem for learning mixture coefficients it has been noticed that the distance measure d 2 can also be used to motivate a generalization of the Expectation Maximization (EM) optimization method <ref> (Helmbold et al., 1996b and 1996c) </ref>. In summary, we have seen that there are two different ways of arriving at the same approximated EG algorithm. First, one can approximate the exponential function in the update rule of EG. <p> We apply the bound ln (1 q (1 e p )) pq + p 2 =8, which holds for 0 q 1 and p 2 R <ref> (Helmbold et al., 1996b, Lemma 1) </ref>. <p> We introduce a common framework for deriving learning algorithms based on the tradeoff between the distance traveled from the current weight vector and a loss function. Different distance functions lead to radically different algorithms. This framework has been adapted recently <ref> (Helmbold et al., 1996b and 1996c) </ref> to an unsupervised setting. 3. The distance function also serves in a second role as a potential function in proving worst-case loss bounds by amortized analysis (Cormen et al., 1990).
Reference: <author> Helmbold, D. P., Schapire, R. E., Singer, Y., and Warmuth, M. K. </author> <year> (1996c), </year> <title> On-line portfolio selection using multiplicative updates, </title> <booktitle> in "Proceedings, 13th International Conference on Machine Learning," </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco (to appear). </address>
Reference: <author> Helmbold, D. P., and Warmuth, M. K. </author> <year> (1995), </year> <title> On weak learning, </title> <journal> Journal of Computer and System Sciences 50, </journal> <pages> 551-573. </pages>
Reference-contexts: If the start vector of the algorithm is equal to u and the learning rate is positive, then the expected loss of the second hypothesis w 2 obviously is higher than that of the initial hypothesis w 1 = u. We conclude this section by presenting a simple method <ref> (Helmbold and Warmuth, 1995) </ref> that can be used for proving expected instantaneous loss bounds for all algorithms and distributions.
Reference: <author> Hinton, G. E. </author> <year> (1986), </year> <title> Learning distributed representations of concepts, </title> <booktitle> in "Proceedings, 8th Annual Conference of the Cognitive Science Society," </booktitle> <pages> pp. 1-12, </pages> <publisher> Erlbaum, </publisher> <address> Hillsdale. </address>
Reference-contexts: This class of algorithms also includes a basic variant of weight decay, where an additional jjw t jj 2 2 error term is used as a penalty for large weights <ref> (Hinton, 1986) </ref>. According to a commonly accepted heuristic, the number of examples needed to learn linear functions is roughly proportional to the number of dimensions in the instances. The results presented here do not contradict this in any way.
Reference: <author> Jumarie, G. </author> <year> (1990), </year> <title> "Relative information," </title> <publisher> Springer, </publisher> <address> New York. </address>
Reference: <author> Kapur, J. N., and Kesavan, H. K. </author> <year> (1992), </year> <title> "Entropy Optimization Principles with Applications," </title> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: <author> Kearns, M. J., Schapire, R. E., and Sellie, L. M. </author> <year> (1994), </year> <title> Toward efficient agnostic learning, </title> <booktitle> Machine Learning 17, </booktitle> <pages> 115-142. </pages>
Reference-contexts: To set a reasonable goal, we measure the performance of the algorithm against the performances of predictors from some fixed comparison class P . (The comparison class is analogous to the touchstone class of the agnostic PAC model of learning <ref> (Kearns et al., 1994) </ref>.) The algorithm is required to perform well if at least one predictor from the comparison class performs well.
Reference: <author> Littlestone, N. </author> <year> (1988), </year> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm, </title> <booktitle> Machine Learning 2, </booktitle> <pages> 285-318. </pages>
Reference-contexts: This family includes the Perceptron algorithm for thresholded linear functions, the GD algorithm for linear functions, the standard back-propagation algorithm for multilayer sigmoid networks, and the Linear Least Squares algorithm for fitting a line to data points. The new family includes, respectively, the Winnow algorithm <ref> (Littlestone, 1988) </ref>, the EG algorithm, the exponentiated back-propagation algorithm, and an algorithm for fitting a line to data points so that the relative entropy of the coefficient vector is minimized. The new family uses a new bias, which favors sparse weight vectors.
Reference: <author> Littlestone, N. </author> <year> (1989), </year> <title> From on-line to batch learning, </title> <booktitle> in "Procedings, 2nd Annual Workshop on Computational Learning Theory," </booktitle> <pages> pp. 269-284, </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Littlestone, N. </author> <year> (1989), </year> <title> "Mistake Bounds and Logarithmic Linear-threshold Learning Algorithms," </title> <type> PhD thesis, Technical Report UCSC-CRL-89-11, </type> <institution> University of California, Santa Cruz, Computer Research Laboratory. </institution>
Reference: <author> Littlestone, N. </author> <year> (1991), </year> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow, </title> <booktitle> in "Proceedings, 4th Annual Workshop on Computational Learning Theory," </booktitle> <pages> pp. 147-156, </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address> <note> Exponentiated gradient 57 Littlestone, </note> <author> N., Long, P. M., and Warmuth, M. K. </author> <year> (1995), </year> <title> On-line learning of linear functions, </title> <journal> Journal of Computational Complexity 5, </journal> <pages> 1-23. </pages>
Reference: <author> Littlestone, N., and Warmuth, M. K. </author> <year> (1994), </year> <title> The weighted majority algorithm, </title> <booktitle> Information and Computation 108, </booktitle> <pages> 212-261. </pages>
Reference: <author> Luenberger, D. G. </author> <year> (1984), </year> <title> "Linear and Nonlinear Programming," </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: If we use the squared Euclidean distance together with the constraint that the weights w i must sum to one, we obtain an algorithm GP L that is known as the gradient projection algorithm <ref> (Luenberger, 1984) </ref>.
Reference: <author> Royden, H. </author> <year> (1963), </year> <title> "Real Analysis," </title> <publisher> Macmillan, </publisher> <address> New York. </address>
Reference-contexts: Note that L p and L q are dual norms if 1=p + 1=q = 1 <ref> (Royden, 1963) </ref>. Hence, the L 1 norm used for the comparison vectors and the L 1 norm used for the instances in the bounds for the EG algorithm are dual. <p> If the norms L p and L q are dual, then the Cauchy-Schwartz Inequality can be generalized to show that jjujj p U and jjxjj q X together imply ju xj U X <ref> (Royden, 1963) </ref>. Theorem 6.1 Let p; q 2 R + [ f 1 g. Let A be an arbitrary on-line prediction algorithm, and let K, U , and X be arbitrary positive reals.
Reference: <author> Schapire, R. E., and Warmuth, M. K. </author> <year> (1994), </year> <title> On the worst-case analysis of temporal-difference learing algorithms, </title> <booktitle> in "Proceddings, 11th International Conference on Machine Learning," </booktitle> <pages> pp. 266-274, </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA. </address> <note> To appear in Machine Learning. </note>
Reference-contexts: The upper bound of Theorem 7.1 can be shown to be tight <ref> (Schapire and Warmuth, 1994) </ref>. We now give a similar result for the EGM algorithm. The proof is based on a reduction that allows us to apply directly the upper bound given in Theorem 5.10 for the EG algorithm.
Reference: <author> Vovk, V. </author> <year> (1990), </year> <title> Aggregating strategies, </title> <booktitle> in "Proceedings, 3rd Annual Workshop on Computational Learning Theory," </booktitle> <pages> pp. 371-383, </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: a simpler situation, where the learner is not trying to learn a linear function but merely to pick out the best single component of the instances for predicting the outcomes, it has been possible to use a similar approach to prove bounds for a very general class of loss functions <ref> (Vovk, 1990) </ref>. Exponentiated gradient 20 As noted in Section 4, the algorithms can be motivated by applying a distance measure to the weight vectors maintained by the algorithms. These distance measures will also be useful in proving worst-case loss bounds.
Reference: <author> Widrow, B., and Stearns, S. </author> <year> (1985), </year> <title> "Adaptive Signal Processing," </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ. </address>
References-found: 27

