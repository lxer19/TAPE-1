URL: ftp://ftp.cc.gatech.edu/pub/people/roland/papers/vis-HCI.ps.gz
Refering-URL: http://www.cs.gatech.edu/people/home/roland/papers/vis-HCI.html
Root-URL: 
Email: narayan@eng.auburn.edu  roland@cc.gatech.edu  
Title: Visual Language Theory: Towards a Human-Computer Interaction Perspective  
Author: N. Hari Narayanan Roland Hubscher 
Date: May 1997  
Address: Auburn, AL 36849  Atlanta, GA 30332-0280  
Affiliation: Visual Information, Intelligence Interaction Research Group Department of Computer Science Engineering Auburn University  EduTech Institute College of Computing Georgia Institute of Technology  
Abstract: The main reason for using visual languages is that they are often far more convenient to the user than traditional textual languages. Therefore, visual languages intended for use by both computers and humans ought to be designed and analyzed not only from the perspective of computational resource requirements, but equally importantly, also from the perspective of languages that are cognitively usable and useful. Theoretical and practical research on visual languages need to take into account the full context of a coupled human-computer system in which the visual language facilitates interactions between the computational and the cognitive parts. This implies that theoretical analyses ought to address issues of comprehension, reasoning and interaction in the cognitive realm as well as issues of visual program parsing, execution and feedback in the computational realm. The human aspect is crucial to visual languages, and therefore we advocate a correspondingly broadened scope of inquiry for visual language research. In this chapter we describe aspects of human use of visual languages that ought to be important considerations in visual language research and design, and summarize research from related fields such as software visualization and diagrammatic reasoning that addresses these issues. A framework consistent with the broadened scope of visual language research is proposed and used to categorize and discuss several formalizations and implemented systems. In the course of showing how a sample of current work fits into this framework, open issues and fruitful directions for future research are also identified. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Abelson, G. J. Sussman, and J. Sussman. </author> <title> Structure and Interpretation of Computer Programs. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, 2nd edition, </address> <year> 1996. </year>
Reference-contexts: Some have even suggested that an important goal of most visual programming languages is that these provide a medium for human-human communication; the fact that a program can be executed on a computer is "just" a nice side effect <ref> [1] </ref>. While cognitive issues are equally relevant to conventional programming languages since the programming task is carried out by humans, design and analysis of programming languages have always been driven by issues of tractability and efficiency, not usability or comprehensibility.
Reference: [2] <author> M. Andries, G. Engels, and J. Rekers. </author> <title> Using graph grammars to represent visual programs. </title> <editor> In B. Meyer and K. Marriott, editors, </editor> <title> Visual Language Theory. </title> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: Different kinds of S $ VS mapping (e.g., homomorphism, isomorphism) are examined by Gurr [37], which results in a characterization of visual representations in terms of properties such as lucidity, laconicity, soundness and completeness. Andries et al. <ref> [2] </ref> propose graph data structures for representing VS and S, and a "represents/represented-by" relation that maps between the two.
Reference: [3] <author> A. Antonietti. </author> <title> Why does mental visualization facilitate problem solving? In R. </title> <editor> H. Logie and M. Denis, editors, </editor> <booktitle> Mental Images in Human Cognition, </booktitle> <pages> pages 211-227. </pages> <publisher> Elsevier Science Publishers, </publisher> <address> Amsterdam, Netherlands, </address> <year> 1991. </year>
Reference-contexts: This supports the use of knowledge intensive parsing and interpretation techniques that systems like Beatrix [72] and Anon [47] employ. It has been found that people employ mental visualization <ref> [3, 40, 64] </ref> to make inferences when static pictures are used to represent dynamic ADs, and that this process creates a mismatch between the external and internal representations resulting in increased cognitive load [65].
Reference: [4] <author> R. Arnheim. </author> <title> Visual Thinking. </title> <publisher> University of California Press, </publisher> <address> Berkeley, CA, </address> <year> 1969. </year>
Reference-contexts: Conversely, our brains are adept at converting thoughts into visual representations, some of which are constrained by conventions, while others are brilliantly executed depictions governed by nothing other than the imaginations of an artist. In fact, visual thinking <ref> [4] </ref> is deeply embedded in the psyche of every culture, and visual languages predate the development of textual ones [98]. <p> In this chapter, we will look at visual languages from a human-computer interaction perspective. We will restrict ourselves to visual languages that are interesting in the context of computers, and will therefore ignore a large class of visual languages, especially those originating from the visual arts <ref> [29, 4, 31] </ref>. These languages are cognitively inspired and are not necessarily the result of visualizing a formal language. We will discuss some of their characteristics to argue that current theories of visual languages need to be extended to include a larger, more interesting class of languages. <p> Thus many dimensions and taxonomies are needed to determine a language's overall effectiveness." Theories of human visual languages have existed for quite some time: visual thinking <ref> [4] </ref>, semi-otics of visual languages [82], etc. But new types of theories are necessary for visual languages in the context of human-computer interaction. A theory of visual languages must be formal enough to derive its computational properties.
Reference: [5] <author> A. Badre and J. Allen. </author> <title> Graphic language representation and programming behavior. </title> <editor> In S. Salvendy and M. J. Smith, editors, </editor> <title> Designing and Using Human-Computer Interfaces and Knowledge Based Systems, </title> <address> pages 59-65. </address> <publisher> Elsevier Science Publishers, </publisher> <address> Amsterdam, Nether-lands, </address> <year> 1989. </year>
Reference-contexts: On the other side, there is literature that questions the validity of the belief that graphical syntax alone will increase comprehensibility or programmability <ref> [5, 33, 35, 73] </ref>. A visual language whose graphical syntax is as incomprehensible as that of a terse textual language can provide no justification for the additional complexity that such a language introduces on the computational side. <p> One usability study <ref> [5] </ref> appears to indicate that graphical notations do not provide an advantage for procedural languages.
Reference: [6] <editor> J. Barwise and J. Etchemendy. Hyperproof. </editor> <publisher> Cambridge University Press, </publisher> <address> Cambridge, England, </address> <year> 1994. </year>
Reference-contexts: Consider, for example, Hyperproof <ref> [6] </ref> which is a mixed visual language consisting of geometric diagrams and logic sentences. It is an interactive language using which students solve logic problems assisted by the computer. Its AD is configurations of 3D geometric objects in 3-space. <p> There is no significant research yet that addresses both computational and cognitive evaluation of the same visual language. Hyperproof <ref> [6] </ref> is a mixed visual language system that was designed to teach logic to students. <p> Such guidance can result in a lower number of alternatives that the inference process needs to evaluate, thereby making it more efficient. Computer programs that use diagrams that humans find equally useful for guiding and controlling inferences, such as Redraw [94] and Hy-perproof <ref> [6] </ref>, illustrate this point. Characterizing this role of visual languages is an open problem in visual language theory. 6.2 Further Characteristics of Visual Representations 6.2.1 Deriving Meaning from Multiple Pictures Many current theories specify pictures using text, such that for each meaningful visual sentence there is a corresponding propositional sentence.
Reference: [7] <author> J. Barwise and J. Etchemendy. </author> <title> Heterogeneous logic. </title> <editor> In J. Glasgow, N. H. Narayanan, and B. Chandrasekaran, editors, </editor> <booktitle> Diagrammatic Reasoning: Cognitive and Computational Perspectives, </booktitle> <pages> pages 211-234. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, </address> <publisher> CA and MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: Therefore, researchers in this area have developed formal characterizations of diagrammatic representations using a heterogeneous logic that exploits propositional and diagrammatic representations <ref> [7, 39, 86] </ref>. 4.5 Graphical Simulations The notion of diagrammatic reasoning is combined with direct manipulation in interactive graphical simulations. These have become an important tool in educational research [15]. Many user friendly tools for creating such simulations are becoming available. <p> Two properties of visual representations make them difficult to parse and interpret. One is that they are multidimensional unlike text which can be linearly read and decomposed. The second is that visual primitives are typically token-referential unlike textual symbols which are generally type- referential <ref> [7] </ref>. Since visual primitives that are of the same type may not necessarily have common semantics because of token-referentiality, interpretation of such primitives is more difficult 17 5 A FRAMEWORK FOR ANALYSIS AND SYNTHESIS OF VISUAL LANGUAGES than that of type-referential primitives. <p> There is no significant research yet that addresses both computational and cognitive evaluation of the same visual language. Hyperproof [6] is a mixed visual language system that was designed to teach logic to students. While its authors have studied theoretical and computational issues <ref> [7] </ref>, others have looked at the cognitive effectiveness of the language|i.e., how well it helps students 22 6 ISSUES FOR VISUAL LANGUAGE RESEARCH learn logic in comparison with traditional teaching methods. <p> There are, however, exceptions to this. Figure 7 showed that visual representations afford certain inferences, thereby reducing reasoning to recognition of a spatial relationship. Visual and non-visual reasoning are often intertwined <ref> [7, 93] </ref>, and in such cases visual representations can provide guidance to the logical reasoning process. Such guidance can result in a lower number of alternatives that the inference process needs to evaluate, thereby making it more efficient.
Reference: [8] <author> J. Bertin. </author> <title> Semiology of Graphics. 1967. English translation by W. </title> <institution> J. Berg, University of Wisconsin Press, Madison, WI, </institution> <year> 1983. </year>
Reference-contexts: There are a variety of dimensions such as shape, geometry, color, texture, 2D and 3D locations, etc., and a variety of visual relations that can be used to carry meaning. There are a number of studies that have attempted to enumerate and classify visual representations [52], dimensions and relations <ref> [8, 28, 31] </ref>. Nevertheless, a systematic categorization and the use of such a categorization to characterize and compare visual languages in terms of their visual syntax have not yet been done.
Reference: [9] <author> A. F. Blackwell. </author> <title> Metacognitive theories of visual programming: What do we think we are doing? In IEEE Workshop on Visual Languages, </title> <address> pages 240-246. </address> <publisher> IEEE Computer Society Press, </publisher> <year> 1996. </year>
Reference-contexts: The ease with which we create and comprehend visual representations is surely a significant factor motivating research in the area of visual languages, and this is articulated in many different ways <ref> [9] </ref>. Most of this research has been on visual programming languages in the past. However, the adeptness of the human visual system masks the computational complexity of parsing, interpreting, and operationalizing the semantics carried by visual representations|from the simplest of diagrams to complex real world scenes. <p> Fisher [55] state: "Only by acknowledging the cognitive reality in which the language is employed by programmers and end users, can we recognize that visual programming does introduce a new paradigm." However, despite the pervasiveness of the cognitive benefit assumption in the visual languages 2 2 WHICH VISUAL LANGUAGES? community <ref> [9] </ref>, there is a lack of research to back it up. On the other side, there is literature that questions the validity of the belief that graphical syntax alone will increase comprehensibility or programmability [5, 33, 35, 73]. <p> A research project intended to rigorously define the scientific basis for cognitive advantages of visual programming, an initial result from which is an explicit enumeration of metacognitive beliefs motivating the design of visual languages, holds considerable promise for achieving this goal <ref> [9] </ref>. There is no significant research yet that addresses both computational and cognitive evaluation of the same visual language. Hyperproof [6] is a mixed visual language system that was designed to teach logic to students.
Reference: [10] <author> P. Bottoni, M. F. Costabile, S. Levialdi, and P. Mussio. </author> <title> Formalizing visual languages. </title> <booktitle> In IEEE Workshop on Visual Languages, </booktitle> <pages> pages 45-52. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1995. </year> <title> 30 REFERENCES REFERENCES </title>
Reference-contexts: We extend this notion to include computational as well as cognitive processes in the use of visual languages. Figure 4 provides a detailed view of this category. Bottoni and colleagues <ref> [10, 11] </ref> have developed a theoretical characterization of visual languages from the interaction and communication perspective illustrated by Figure 1.
Reference: [11] <author> P. Bottoni, M. F. Costabile, S. Levialdi, and P. Mussio. </author> <title> Specification of visual languages as means for interaction. In Visual Language Theory. </title> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: We extend this notion to include computational as well as cognitive processes in the use of visual languages. Figure 4 provides a detailed view of this category. Bottoni and colleagues <ref> [10, 11] </ref> have developed a theoretical characterization of visual languages from the interaction and communication perspective illustrated by Figure 1.
Reference: [12] <author> F. P. Brooks. </author> <title> No silver bullet: </title> <journal> Essence and accidents of software engineering. IEEE Computer, </journal> <volume> 20(4) </volume> <pages> 10-19, </pages> <year> 1987. </year>
Reference-contexts: This perceived lack of progress led one prominent researcher to conclude, prematurely in our opinion, that "nothing even convincing, much less exciting, has yet emerged from such efforts [on visual programming]: : : I am persuaded that nothing will" <ref> [12] </ref>.
Reference: [13] <author> M. H. Brown and R. Sedgewick. </author> <title> Techniques for algorithm animation. </title> <journal> IEEE Software, </journal> <volume> 2(1) </volume> <pages> 28-38, </pages> <year> 1985. </year>
Reference-contexts: Generality of AD is an important dimension. Some visual languages are tailored to one specific AD. Weather maps used by meteorologists and circuit diagrams that electrical engineers use are examples. Algorithm animation systems such as Balsa <ref> [13] </ref> can be used to automatically create and display a visual language that depicts the operation of a single algorithm. Others can represent a class of domains. Pictorial Janus [48] and Prograph [91] are examples of visual programming languages that can represent a variety of concurrent and dataflow computations respectively. <p> The results [92] have been mixed in that while advanced students benefited, students with less knowledge or visual capability did not show improved learning. Researchers in software visualization in general [75], and algorithm animation in particular <ref> [13] </ref>, strive to create visual languages using which computers can communicate the inner workings of programs to humans. These are not visual languages that support the full cycle of interaction|instead, they are intended for one-way communication from the computational to the cognitive.
Reference: [14] <author> M. D. Byrne, R. Catrambone, and J. T. Stasko. </author> <title> Do algorithm animations aid learning? Technical Report GIT-GVU-96-18, </title> <month> August </month> <year> 1996. </year>
Reference-contexts: Most visualizations that have been designed so far are special purpose languages designed for a particular algorithm or program, or a class of algorithms. Recent research on the cognitive effectiveness of such visualizations has also unearthed mixed results <ref> [14] </ref>. It should be noted that in all these cases the visual languages have already been designed and implemented in the computational realm before cognitive studies were undertaken. In contrast, Mahling and Fisher [55] apply cognitive theory to design rather than evaluation of a visual language.
Reference: [15] <author> CACM. </author> <title> Special section on educational technology, </title> <journal> communications of the acm, </journal> <volume> 39(4), </volume> <month> april., </month> <year> 1996. </year>
Reference-contexts: These have become an important tool in educational research <ref> [15] </ref>. Many user friendly tools for creating such simulations are becoming available. Some examples are KidSim TM from Apple Computer [89], Star Logo from MIT Media Laboratory [80] and Agentsheets from the University of Colorado [79].
Reference: [16] <author> S.-K. Chang. </author> <title> Visual languages: A tutorial and survey. </title> <journal> IEEE Software, </journal> <volume> 4 </volume> <pages> 29-39, </pages> <year> 1987. </year>
Reference-contexts: Shu [87] uses three dimensions|level of the language, its scope or generality, and the extent of meaningful visual expressions it utilizes|to characterize a number of languages. Menzies [58] uses the dimensions of purpose, visual expressions, and design of the visual programming system to assess the languages. Chang <ref> [16] </ref> categorizes visual languages in terms of the type of activity they support|visual interaction, visual programming, visual information processing or iconic visual information processing.
Reference: [17] <author> T. B. Dinesh and S. Uskudarli. </author> <title> Specifying input and output of visual languages. </title> <editor> In B. Meyer and K. Marriott, editors, </editor> <title> Visual Language Theory. </title> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: Most current literature on visual language theory is about those visual languages which are visualizations of originally textual languages. Logic programming languages [76] and finite state automata <ref> [17] </ref> are some examples. Although formalizing such languages is useful and their visual forms are sometimes advantageous over the textual ones, such languages may not help us understand those properties that make human visual languages so powerful.
Reference: [18] <author> S. Douglas, C. Hundhausen, and D. McKeown. </author> <title> Toward empirically-based software visualization languages. </title> <booktitle> In Proc. IEEE Symposium on Visual Languages, </booktitle> <pages> pages 342-349. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1995. </year>
Reference-contexts: The signature morphism is a consistent mapping. While the authors propose it only for the static semantics of pictures, this approach appears suitable for dynamic semantics as well. On the other hand, Douglas et al. <ref> [18] </ref> describe a technique called visualization storyboarding by which a mapping from the application domain of algorithms to a software visualization language can be derived empirically. 2 Cycle of Interaction So far we have discussed the structure and meaning of visual languages|syntax and semantics of visual sentences and their transformations.
Reference: [19] <author> Y. Engelhardt, J. Bruin, T. Janssen, and R. Scha. </author> <title> The visual grammar of information graphics. </title> <editor> In N. H. Narayanan and J. Damski, editors, </editor> <booktitle> Proc. AID'96 Workshop on Visual Representation, Reasoning and Interaction in Design, </booktitle> <institution> Key Center for Design Computing, University of Sydney, </institution> <year> 1996. </year>
Reference-contexts: Andries et al. [2] propose graph data structures for representing VS and S, and a "represents/represented-by" relation that maps between the two. Tufte [95, 96, 97] and Engelhardt and colleagues <ref> [19] </ref> suggest principles for mapping from different kinds of information (e.g., nominal, categorical, ordinal, quantitative, topological and spatial) to visual primitives, dimensions and relations. This mapping captures the static semantics of the language.
Reference: [20] <author> M. Erwig and B. Meyer. </author> <title> Heterogeneous visual languages: Integrating visual and textual programming. </title> <booktitle> In Proc. IEEE Symposium on Visual Languages, </booktitle> <pages> pages 318-325. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1995. </year>
Reference-contexts: V n includes the spatial relations stated above. Both D and V n may be visually depicted and textually specified. The semantic mapping in Hyperproof is consistent. Just as Hyperproof is an implementation of the notion of heterogeneous logic of symbols and pictures, Erwig and Meyer <ref> [20] </ref> describe the design of a programming environment that implements the notion of heterogeneous programming that integrates visual and textual aspects. A heterogeneous visual programming language (HVPL) is an extension of a textual programming language that allows the programmer to replace parts of a textual program with diagrams. <p> This improves cognitive effectiveness since complex code can be replaced with self-evident pictures. For an example, see the illustrated code for AVL tree insertion in Erwig & Meyer <ref> [20] </ref>.
Reference: [21] <author> M. R. Frank and J. D. Foley. </author> <title> A pure reasoning engine for programming by example. </title> <type> Technical Report GIT-GVU-94-11, </type> <month> April </month> <year> 1994. </year>
Reference-contexts: This executes the command (move &lt;file&gt; trash-folder). With direct manipulation users 5 4 COGNITIVE UTILITY OF VISUAL LANGUAGES 4.2 Visualization of Information can "depict" the operations they desire; without it they would have to describe the command to an interpreter which then translates the command into the actual action <ref> [21] </ref>. The cognitive benefits of direct manipulation arise from the elimination of the need to move between two vastly different representations: the natural visual representation (e.g., metaphorical desktop) which permits interactive gestures and the textual program that specifies the objects and behaviors visible on the screen [44].
Reference: [22] <author> E. Freeman, D. Gelernter, and S. Jagannathan. </author> <title> In search of a simple visual vocabulary. </title> <booktitle> In Proc. IEEE Symposium on Visual Languages, </booktitle> <pages> pages 302-309. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1995. </year>
Reference-contexts: Data structures and program control flows are often easier to understand when visualized using graphs and flowcharts. The hierarchical file structure of an operating system is easily visualized either with a directory tree or folders. Three dimensional spatial arrangement of nested transparent cubes have been proposed recently <ref> [22] </ref> as a means of visualizing program structure and execution. Program visualization is essentially the inverse of parsing a visual programming language.
Reference: [23] <author> G. W. Furnas. </author> <title> New graphical reasoning models for understanding graphical interfaces. </title> <booktitle> In Proc. Human Factors in Computing Systems Conference (CHI'91), </booktitle> <pages> pages 71-78. </pages> <publisher> ACM Press, </publisher> <year> 1991. </year>
Reference-contexts: Drawings by our cave-dwelling 11 5 A FRAMEWORK FOR ANALYSIS AND SYNTHESIS OF VISUAL LANGUAGES ancestors were purely graphical. Most current human visual languages and visual programming environments use mixed notations. Bitpict <ref> [23, 24] </ref> and Cartoonist [45] are visual programming languages that use purely graphical notations. There are a variety of dimensions such as shape, geometry, color, texture, 2D and 3D locations, etc., and a variety of visual relations that can be used to carry meaning. <p> In practice, animations are employed even when the corresponding AD is not continuous (e.g., algorithm animations), but whether this contributes to cognitive effectiveness or is merely an irrelevant and potentially distracting feature is yet to be determined. Rewrite rules that systems like Agentsheets [79] and Bitpict <ref> [23, 24] </ref> utilize are examples of dynamic syntax specifications.
Reference: [24] <author> G. W. Furnas. </author> <title> Reasoning with diagrams only. </title> <type> Technical Report SS-92-02, </type> <month> March </month> <year> 1992. </year>
Reference-contexts: Drawings by our cave-dwelling 11 5 A FRAMEWORK FOR ANALYSIS AND SYNTHESIS OF VISUAL LANGUAGES ancestors were purely graphical. Most current human visual languages and visual programming environments use mixed notations. Bitpict <ref> [23, 24] </ref> and Cartoonist [45] are visual programming languages that use purely graphical notations. There are a variety of dimensions such as shape, geometry, color, texture, 2D and 3D locations, etc., and a variety of visual relations that can be used to carry meaning. <p> In practice, animations are employed even when the corresponding AD is not continuous (e.g., algorithm animations), but whether this contributes to cognitive effectiveness or is merely an irrelevant and potentially distracting feature is yet to be determined. Rewrite rules that systems like Agentsheets [79] and Bitpict <ref> [23, 24] </ref> utilize are examples of dynamic syntax specifications.
Reference: [25] <author> J. S. Gero and M. Yan. </author> <title> Shape emergence by symbolic reasoning. Environment and Planning B: </title> <journal> Planning and Design, </journal> <volume> 21 </volume> <pages> 191-218, </pages> <year> 1994. </year> <title> 31 REFERENCES REFERENCES </title>
Reference-contexts: Another approach is enforcing type-referentiality at the cost of expressiveness in computer visual languages (e.g., Hyperproof) and in formalisms (e.g., the partial order over types in signature morphisms). Other obstacles to efficient parsing and interpretation of general purpose visual representations are detecting emergent 1 objects <ref> [49, 25] </ref>, context sensitivity of their interpretations (Figure 6 provides an example), ambiguity, and semantic density (see Subcategory 3.2 below). Another chapter in this volume [56] provides more information on visual language parsing. Generative grammars allow computers to generate or recognize valid visual sentences.
Reference: [26] <author> J. Glasgow, N. H. Narayanan, and B. Chandrasekaran. </author> <title> Diagrammatic Reasoning: Cognitive and Computational Perspectives. </title> <publisher> AAAI Press, </publisher> <address> Menlo Park, </address> <publisher> CA and MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: This makes such representations especially suitable for reasoning by mental simulation. Most propositional descriptions tend to loose these advantages. Therefore, one kind of visual representation|diagrammatic representation|and its role in reasoning have been the subject of recent research interest <ref> [61, 26] </ref>. Diagrammatic representations are different from propositional representations because visual properties of the constituent units of the representation contribute to the semantics of a diagrammatic representation as much as the semantics of the constituent units themselves.
Reference: [27] <author> E. P. Glinert. </author> <title> Nontextual programming environments. </title> <editor> In S.-K. Chang, editor, </editor> <booktitle> Principles of Visual Programming Systems, </booktitle> <pages> pages 144-230. </pages> <publisher> Prentice-Hall, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: A visual language with low salience needs to make the relevant primitives, dimensions or relations visually explicit in order to aid comprehension. A related measure is confusion count, developed by Nickerson [69] by modifying a metric originally proposed by Glinert <ref> [27] </ref>. It is the sum of the number of crossings and elbows in a diagrammatic notation, with the assumption that a high number of these adversely affect comprehensibility. The broad notion of usability, borrowed from interactive system and user interface design literature [42, 68], is a useful measure to apply.
Reference: [28] <author> Vinod Goel. </author> <booktitle> Sketches of Thought. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: There are a variety of dimensions such as shape, geometry, color, texture, 2D and 3D locations, etc., and a variety of visual relations that can be used to carry meaning. There are a number of studies that have attempted to enumerate and classify visual representations [52], dimensions and relations <ref> [8, 28, 31] </ref>. Nevertheless, a systematic categorization and the use of such a categorization to characterize and compare visual languages in terms of their visual syntax have not yet been done. <p> This provides a strong argument for additional research on the dynamic syntax and semantics of visual languages. It has been observed that diagram generation and manipulation activities play an important role in creative thought processes such as architectural design <ref> [28] </ref>. This points to the potential utility of developing advanced knowledge-based visual languages to assist such human endeavors. Results from studies on how humans comprehend diagrammatic representations can serve to illuminate the cognitive processes. Narayanan and Hegarty [62] have developed a cognitive model of comprehension of diagrams and mixed representations.
Reference: [29] <author> E. H. Gombrich. </author> <title> Art and Illusion: A Study in the Psychology of Pictorial Representations. </title> <address> Phaidon, London, </address> <year> 1968. </year>
Reference-contexts: In this chapter, we will look at visual languages from a human-computer interaction perspective. We will restrict ourselves to visual languages that are interesting in the context of computers, and will therefore ignore a large class of visual languages, especially those originating from the visual arts <ref> [29, 4, 31] </ref>. These languages are cognitively inspired and are not necessarily the result of visualizing a formal language. We will discuss some of their characteristics to argue that current theories of visual languages need to be extended to include a larger, more interesting class of languages.
Reference: [30] <author> J. M. Gooday and A. G. Cohn. </author> <title> Visual language syntax and semantics: A spatial logic approach. </title> <editor> In B. Meyer and K. Marriott, editors, </editor> <title> Visual Language Theory. </title> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: An advantage of this approach is that it allows the construction of visual language editors that can both verify the soundness of specifications of a visual language developed in this framework and parse visual sentences of the language. Gooday and Cohn <ref> [30] </ref> show how spatial logic can be used to describe syntax and procedural semantics of a visual language without having to first translate the visual language into a 12 5 A FRAMEWORK FOR ANALYSIS AND SYNTHESIS OF VISUAL LANGUAGES textual one before specifications can be written. <p> Consider, for example, the difficulty of developing specifications of architects' sketches using the spatial logic approach of Gooday and Cohn <ref> [30] </ref> without loosing the aesthetic properties of the sketches. 6.1.1 Explicit Representation Visual representations are designed by people to explicitly depict those relations that are important in the domain or for the task at hand.
Reference: [31] <author> N. Goodman. </author> <title> Languages of Art: An Approach to a Theory of Symbols. </title> <address> Indianapolis, Indiana. </address> <publisher> Hackett Publishing Company, </publisher> <year> 1976. </year>
Reference-contexts: In this chapter, we will look at visual languages from a human-computer interaction perspective. We will restrict ourselves to visual languages that are interesting in the context of computers, and will therefore ignore a large class of visual languages, especially those originating from the visual arts <ref> [29, 4, 31] </ref>. These languages are cognitively inspired and are not necessarily the result of visualizing a formal language. We will discuss some of their characteristics to argue that current theories of visual languages need to be extended to include a larger, more interesting class of languages. <p> A continuous domain, on the other hand, is one in which state changes are fluid, making it difficult to distinguish discrete states and transitions. The ecosystem of a pond is an example. Such systems are semantically dense <ref> [31] </ref>, and require explicit abstraction and quantization in order to be describable in terms of S and S. Generality of AD is an important dimension. Some visual languages are tailored to one specific AD. Weather maps used by meteorologists and circuit diagrams that electrical engineers use are examples. <p> There are a variety of dimensions such as shape, geometry, color, texture, 2D and 3D locations, etc., and a variety of visual relations that can be used to carry meaning. There are a number of studies that have attempted to enumerate and classify visual representations [52], dimensions and relations <ref> [8, 28, 31] </ref>. Nevertheless, a systematic categorization and the use of such a categorization to characterize and compare visual languages in terms of their visual syntax have not yet been done. <p> A complete treatment of various approaches can be found in [56]. One interesting issue to consider is the development of declarative specifications of syntactically and semantically dense <ref> [31] </ref> visual languages. This requires deeming certain aspects of visual sentences as irrelevant and discarding them while explicitly describing certain others. To see this, consider developing a set of assertions to describe Mona Lisa. <p> This implies that visual sentences of the language will form a notational system rather than a much richer analog system <ref> [31] </ref>. 1.4 Dynamic Syntax The dynamic syntax of a visual language specifies how visual sentences may be transformed. Such transformations may include creating, deleting or modifying graphical primitives|G, changing the attributes of graphical objects|D, or changing the spatial relations between graphical objects|V n , in a visual sentence. <p> The latter option is preferable for cognitive effectiveness because the visual language then becomes both syntactically and semantically dense <ref> [31] </ref>, faithfully reflecting the continuous nature of the AD. However, this can create computational difficulties. Computational properties of such visual languages are yet to be explored. <p> How these syntactic measures of visual notations relate to complexity measures of the corresponding visual languages, and whether there are other useful measures need to be further researched. Another interesting possibility is to examine computational implications of Goodman's <ref> [31] </ref> notions of syntactic and semantic differentiation and density, and the corresponding notions of notational and analog systems (see [77] for definitions) for visual languages. 3.2 Cognitive Evaluation Conducting a cognitive evaluation requires experimental research with human participants, which is outside the scope of visual language theory. <p> Since such visual representations evolve in a continuous fashion and are syntactically and semantically dense <ref> [31] </ref>, one can find many intermediate pictures between two that represent a qualitative change of state that can propositionally be asserted. For example, consider the set of pictures one can draw depicting states between not over (cube,hole) and over (cube,hole) in Figure 7 above.
Reference: [32] <author> T. R. G. Green. </author> <title> Cognitive dimensions of notations. </title> <booktitle> In Proc. Human Factors in Computing Systems Conference (CHI'90), </booktitle> <year> 1990. </year>
Reference-contexts: The cognitive dimensions approach of Green <ref> [32, 34] </ref> provides additional measures. For example, the dimension of hidden dependencies indicates how much or how little of the local and global dependencies between variables, subroutines, etc. are made explicitly visible by the visual language syntax.
Reference: [33] <author> T. R. G. Green and M. Petre. </author> <title> When visual programs are harder to read than textual programs. </title> <editor> In G. C. van der Veer, M. J. Tauber, S. Bagnarola, and M. Antavolits, editors, </editor> <title> Human-Computer Interaction: Tasks and Organization, </title> <booktitle> Proc. 6th European Conference on Cognitive Ergonomics, </booktitle> <pages> pages 167-180, </pages> <year> 1992. </year>
Reference-contexts: On the other side, there is literature that questions the validity of the belief that graphical syntax alone will increase comprehensibility or programmability <ref> [5, 33, 35, 73] </ref>. A visual language whose graphical syntax is as incomprehensible as that of a terse textual language can provide no justification for the additional complexity that such a language introduces on the computational side.
Reference: [34] <author> T. R. G. Green and M. Petre. </author> <title> Usability analysis of visual programming environments: A cognitive dimensions framework. </title> <journal> Journal of Visual Languages and Computing, </journal> <volume> 7(2) </volume> <pages> 131-174, </pages> <year> 1996. </year>
Reference-contexts: Nine years after Brook's criticism, a more optimistic note is struck by <ref> [34] </ref>: "Overall, we believe that in many respects visual programming languages offer substantial gains 4 4 COGNITIVE UTILITY OF VISUAL LANGUAGES over conventional textual languages, but at present their human-computer interaction aspects are still under-developed." Visual languages abound in human endeavors and enjoy prominence comparable to that of non-visual languages. <p> On one end of this spectrum lie completely visual languages and at the other end are completely textual languages. Languages that use symbols of one kind or the other as secondary notations <ref> [75, 34] </ref> fall in the middle. Textual languages that also utilize graphical secondary notations|e.g., text that uses color, boldfacing etc. to convey additional information|and graphical languages that utilize textual secondary notations|e.g., map with labels|are two intermediate points of this spectrum. <p> The cognitive dimensions approach of Green <ref> [32, 34] </ref> provides additional measures. For example, the dimension of hidden dependencies indicates how much or how little of the local and global dependencies between variables, subroutines, etc. are made explicitly visible by the visual language syntax.
Reference: [35] <author> T. R. G. Green, M. Petre, and R. K. E. Bellamy. </author> <title> Comprehensibility of visual and textual programs: A test of superlativism against the match-mismatch conjecture. </title> <editor> In J. Koenemann-Belliveau, T. G. Moher, and S. P. Robertson, editors, </editor> <booktitle> Proc. Fourth Workshop on Empirical Studies of Programmers. </booktitle> <publisher> Ablex Publishers, </publisher> <year> 1992. </year>
Reference-contexts: On the other side, there is literature that questions the validity of the belief that graphical syntax alone will increase comprehensibility or programmability <ref> [5, 33, 35, 73] </ref>. A visual language whose graphical syntax is as incomprehensible as that of a terse textual language can provide no justification for the additional complexity that such a language introduces on the computational side.
Reference: [36] <author> M. Gross. </author> <title> The fat pencil, the cocktail napkin, and the slide library. </title> <editor> In A. Harfmann and M. Fraser, editors, </editor> <booktitle> Proc. </booktitle> <volume> ACADIA 94, </volume> <pages> pages 103-113, </pages> <year> 1994. </year>
Reference-contexts: Whether grammars and rewrite rules help human users understand computational processes in the interaction cycle has not yet been studied in the context of any visual language. Interpreting diagrams used in human visual languages remains a difficult problem as well. Electronic Cocktail Napkin <ref> [36] </ref>, Beatrix [72], Redraw [94], and Anon [47] are examples of computer programs that use artificial intelligence techniques to understand diagrams commonly employed in human endeavors.
Reference: [37] <author> C. A. Gurr. </author> <title> On the isomorphism (or otherwise) of representations. </title> <editor> In B. Meyer and K. Mar-riott, editors, </editor> <title> Visual Language Theory. </title> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: Venn diagrams represent a many-to-one mapping since a single circle represents many elements in the AD. Network and tree diagrams use a R n $ P mapping: the "connected" relation is represented by a line. Different kinds of S $ VS mapping (e.g., homomorphism, isomorphism) are examined by Gurr <ref> [37] </ref>, which results in a characterization of visual representations in terms of properties such as lucidity, laconicity, soundness and completeness. Andries et al. [2] propose graph data structures for representing VS and S, and a "represents/represented-by" relation that maps between the two. <p> A number of findings from this research are relevant to visual languages. It has been found that parsing and semantic interpretation is not easy for humans [53] and that realism facilitates semantic interpretation [83]. This supports the argument that isomorphism <ref> [37] </ref> is an important property. <p> Isomorphic visual representations can aid this, and thus increase comprehensibility, if transformations of the visual representations are isomorphic to the domain processes being simulated. Gurr <ref> [37] </ref> analyzes properties that contribute to isomorphism, and develops characterizations of different levels of similarity. Using Gurr's terminology, it appears that at least a homomorphic mapping between the AD and visual sentences is required for similarity.
Reference: [38] <author> V. Haarslev. </author> <title> A fully formalized theory for describing visual notations. </title> <editor> In B. Meyer and K. Marriott, editors, </editor> <title> Visual Language Theory. </title> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: A number of researchers have addressed the issue of formally specifying the static semantics of a visual language. Meyer [59] describes a specification scheme that itself uses a mixed vocabulary consisting of textual symbols and partially specified pictures, suitable for human comprehension. Haarslev <ref> [38] </ref> presents a theoretical framework that combines topology, spatial relations, and description logics for developing syntactic and semantic specifications of static visual sentences. <p> Visual languages with a fine granularity of interaction are typically interpreted whereas those with a coarse granularity may be compiled. Some commercial mixed languages allow both. Researchers have addressed the issue of specifying meanings of visual sentences in such a way that the specifications are executable <ref> [38] </ref>. Whether grammars and rewrite rules help human users understand computational processes in the interaction cycle has not yet been studied in the context of any visual language. Interpreting diagrams used in human visual languages remains a difficult problem as well.
Reference: [39] <author> E. Hammer. </author> <title> Logic and visual information. In Studies in Logic, Language & Computation. </title> <publisher> CSLI Press, Stanford University, </publisher> <year> 1995. </year> <title> 32 REFERENCES REFERENCES </title>
Reference-contexts: Therefore, researchers in this area have developed formal characterizations of diagrammatic representations using a heterogeneous logic that exploits propositional and diagrammatic representations <ref> [7, 39, 86] </ref>. 4.5 Graphical Simulations The notion of diagrammatic reasoning is combined with direct manipulation in interactive graphical simulations. These have become an important tool in educational research [15]. Many user friendly tools for creating such simulations are becoming available.
Reference: [40] <author> M. Hegarty. </author> <title> Mental animation: Inferring motion from static displays of mechanical systems. </title> <journal> Journal of Experimental Psychology: Learning, Memory & Cognition, </journal> <volume> 18(5) </volume> <pages> 1084-1102, </pages> <year> 1992. </year>
Reference-contexts: This supports the use of knowledge intensive parsing and interpretation techniques that systems like Beatrix [72] and Anon [47] employ. It has been found that people employ mental visualization <ref> [3, 40, 64] </ref> to make inferences when static pictures are used to represent dynamic ADs, and that this process creates a mismatch between the external and internal representations resulting in increased cognitive load [65]. <p> Such representations have been called isomorphic representations. It has been experimentally observed that when static visual representations depict dynamic situations, people tend to mentally simulate the dynamic processes by internally manipulating the visual representations <ref> [40, 66, 85, 83] </ref>. Isomorphic visual representations can aid this, and thus increase comprehensibility, if transformations of the visual representations are isomorphic to the domain processes being simulated. Gurr [37] analyzes properties that contribute to isomorphism, and develops characterizations of different levels of similarity. <p> Visual representations support such reasoning by facilitating the process of transforming the image under the domain's constraints, generating new hypotheses, and testing them against the state of affairs depicted by the transformed image <ref> [64, 40] </ref>. The examples in Figure 7 show situations where the visual representation affords reasoning by image transformation more than a corresponding propositional one. Figure 7A shows a round hole and a cube. The question to be answered is whether the cube can be pushed through the hole.
Reference: [41] <author> M. Hegarty and M. A. </author> <title> Just. Constructing mental models of machines from text and diagrams. </title> <journal> Journal of Memory and Language, </journal> <volume> 32 </volume> <pages> 717-742, </pages> <year> 1993. </year>
Reference-contexts: the visual sentence has the same referent, as in the case of a mixed visual sentence consisting of text and picture in which many words and graphical units refer to same things, and constructing a unified model of information from text and diagrams is difficult both computationally [72] and cognitively <ref> [41] </ref>. This is relevant to the type of mapping a visual language utilizes, indicating that one-to-many mappings from AD to visual sentences may not be a good idea.
Reference: [42] <author> D. Hix and H. R. Hartson. </author> <title> Developing User Interfaces: Ensuring Usability Through Product & Process. </title> <publisher> John Wiley & Sons, Inc., </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: It is the sum of the number of crossings and elbows in a diagrammatic notation, with the assumption that a high number of these adversely affect comprehensibility. The broad notion of usability, borrowed from interactive system and user interface design literature <ref> [42, 68] </ref>, is a useful measure to apply.
Reference: [43] <author> R. Hubscher. </author> <title> Rewriting interaction. </title> <booktitle> In Proc. Human Factors in Computing Systems Conference, (CHI'95), </booktitle> <pages> pages 105-106. </pages> <publisher> ACM Press, </publisher> <year> 1995. </year>
Reference-contexts: The cognitive benefits of such interactive graphical simulations arise from the elimination of the need to move between two vastly different representations: the natural dynamic visual representations of processes being simulated and the underlying descriptive specifications of them <ref> [43] </ref>. 5 A Framework for Analysis and Synthesis of Visual Languages In this section we propose a framework, which consists of a model of visual language use and a corresponding taxonomy of issues, that is expected to be useful for the discourse on design of new visual languages as well as
Reference: [44] <author> R. Hubscher. </author> <title> Composing complex behavior from simple visual descriptions. </title> <booktitle> In Proc. IEEE Symposium on Visual Languages, </booktitle> <pages> pages 88-94, </pages> <year> 1996. </year>
Reference-contexts: The cognitive benefits of direct manipulation arise from the elimination of the need to move between two vastly different representations: the natural visual representation (e.g., metaphorical desktop) which permits interactive gestures and the textual program that specifies the objects and behaviors visible on the screen <ref> [44] </ref>. Thus, graphical user interfaces for direct manipulation may be viewed as visual languages that humans use to interact with computers. 4.2 Visualization of Information Visual representations are often used to make higher order relations more accessible to the human intuition [96]. <p> There are four possible mappings: (1) S $ VS, (2) S $ VS , (3) S $ VS , and (4) S $ VS . (1) and (2) are commonly occurring mappings. An example is a visual language representation a microworld consisting of moving balls and stationary walls <ref> [44] </ref> that maps balls and walls to circles and rectangles in a display, and maps the motions of balls to the corresponding motions of circles on the display.
Reference: [45] <author> R. Hubscher. </author> <title> Visual constraint rules. </title> <journal> Journal of Visual Languages and Computing, </journal> <note> 1997. to appear. </note>
Reference-contexts: Drawings by our cave-dwelling 11 5 A FRAMEWORK FOR ANALYSIS AND SYNTHESIS OF VISUAL LANGUAGES ancestors were purely graphical. Most current human visual languages and visual programming environments use mixed notations. Bitpict [23, 24] and Cartoonist <ref> [45] </ref> are visual programming languages that use purely graphical notations. There are a variety of dimensions such as shape, geometry, color, texture, 2D and 3D locations, etc., and a variety of visual relations that can be used to carry meaning.
Reference: [46] <author> J. Huttenlocher. </author> <title> Constructing spatial images: A strategy in reasoning. </title> <journal> Psychological Review, </journal> <volume> 75(6) </volume> <pages> 550-560, </pages> <year> 1968. </year>
Reference-contexts: In these kinds of problems, even when given a descriptive propositional or natural language 26 6 ISSUES FOR VISUAL LANGUAGE RESEARCH6.2 Further Characteristics of Visual Representations representation people tend to draw or mentally image a corresponding visual representations in order to solve the problems <ref> [46] </ref>. 6.1.4 Computational Complexity Visual representations make characteristics of the represented situation explicit, group related information spatially or by other visual cues, and facilitate inferences based on direct manipulation. In comparison, propositional representations contain considerable implicit information.
Reference: [47] <author> S. H. Joseph and T. P. Pridmore. </author> <title> Knowledge-directed interpretation of mechanical engineering drawings. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(9) </volume> <pages> 928-940, </pages> <year> 1992. </year>
Reference-contexts: Interpreting diagrams used in human visual languages remains a difficult problem as well. Electronic Cocktail Napkin [36], Beatrix [72], Redraw [94], and Anon <ref> [47] </ref> are examples of computer programs that use artificial intelligence techniques to understand diagrams commonly employed in human endeavors. <p> This supports the use of knowledge intensive parsing and interpretation techniques that systems like Beatrix [72] and Anon <ref> [47] </ref> employ. It has been found that people employ mental visualization [3, 40, 64] to make inferences when static pictures are used to represent dynamic ADs, and that this process creates a mismatch between the external and internal representations resulting in increased cognitive load [65].
Reference: [48] <author> K. M. Kahn and V. A. Saraswat. </author> <title> omplete visualizations of concurrent programs and their executions. </title> <booktitle> In Proc. IEEE Symposium on Visual Languages, </booktitle> <pages> pages 7-14. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1990. </year>
Reference-contexts: Weather maps used by meteorologists and circuit diagrams that electrical engineers use are examples. Algorithm animation systems such as Balsa [13] can be used to automatically create and display a visual language that depicts the operation of a single algorithm. Others can represent a class of domains. Pictorial Janus <ref> [48] </ref> and Prograph [91] are examples of visual programming languages that can represent a variety of concurrent and dataflow computations respectively. The American Sign Language is a visual language that is very general.
Reference: [49] <author> K. R. Koedinger. </author> <title> Emergent properties and structural constraints: Advantages of diagrammatic representations for reasoning and learning. </title> <booktitle> In Proc. AAAI Spring Symposium on Reasoning with Diagrammatic Representations, </booktitle> <pages> pages 154-169, </pages> <year> 1992. </year> <note> AAAI Technical Report SS-92-02. </note>
Reference-contexts: Another approach is enforcing type-referentiality at the cost of expressiveness in computer visual languages (e.g., Hyperproof) and in formalisms (e.g., the partial order over types in signature morphisms). Other obstacles to efficient parsing and interpretation of general purpose visual representations are detecting emergent 1 objects <ref> [49, 25] </ref>, context sensitivity of their interpretations (Figure 6 provides an example), ambiguity, and semantic density (see Subcategory 3.2 below). Another chapter in this volume [56] provides more information on visual language parsing. Generative grammars allow computers to generate or recognize valid visual sentences.
Reference: [50] <author> J. Larkin. </author> <title> Display based problem solving. </title> <editor> In D. Klahr and K. Kotovsky, editors, </editor> <booktitle> Complex Information Processing. </booktitle> <publisher> Lawrence Erlbaum Publishers, </publisher> <address> Hillsdale, NJ, </address> <year> 1989. </year>
Reference-contexts: This makes it easy for humans to make inferences from pictorial displays <ref> [50] </ref>. Furthermore, since visual representations typically represent spatial and geometric properties of their referents in an isomorphic way, modifications of these properties of the constituents of such a representation can be used to reason about the effects of real world processes in which the represented objects participate [65].
Reference: [51] <author> J. H. Larkin and H. A. Simon. </author> <title> Why a diagram is (sometimes) worth ten thousand words. </title> <journal> Cognitive Science, </journal> <volume> 11 </volume> <pages> 65-99, </pages> <year> 1987. </year>
Reference-contexts: Many visual relations and properties are implicit in propositional representations and require extensive reasoning to be deduced, whereas visual representations display them explicitly at all times <ref> [51] </ref>. 6 5 A FRAMEWORK FOR ANALYSIS AND SYNTHESIS OF VISUAL LANGUAGES4.5 Graphical Simulations Visual representations such as diagrams facilitate situated reasoning because these make serendipitous inferences, inferences by recognition, prediction by mental visualization, and cueing prior knowledge possible [63]. <p> One useful cognitive measure is comprehensibility|how easy is it for a user to understand and learn the syntax and semantics of the language. A number of factors influence comprehensibility. It has been noted that visual representations are easier to understand because they make information explicit <ref> [51] </ref>. One way of achieving explicitness is through representations that are similar or analogous to the represented, and which preserve properties of the represented in an explicit way. Such representations have been called isomorphic representations. <p> Another dimension is secondary notations|the use of D and V n to convey meaning. One way to accomplish this is by spatial clustering. Graphical representations can spatially organize and localize relevant information together <ref> [51] </ref> so that a visual search can locate information quickly. Very little research has been done on how secondary notations might improve cognitive effectiveness. Another dimension called viscosity, the effort required to transform a visual representation from one valid state to another, may also be useful for evaluation and comparison. <p> They allow the use of visual cues such as color or texture to convey information 25 6 ISSUES FOR VISUAL LANGUAGE RESEARCH 6.1 Affordances of Visual Representations and to draw the reasoner's attention to relevant objects and properties. Larkin and Simon <ref> [51] </ref> provide an analysis of how spatial adjacency and connectedness can be used to reduce the complexity of reasoning in solving physics problems when the problem descriptions are accompanied by diagrams. <p> Thus, informationally equivalent representations can have different computational complexity depending on the operations performed on them and the nature of the underlying information processing architecture that performs the operations <ref> [51] </ref>. The implication for visual language theories is that making visual languages easier for humans may in general result in making them harder for computers and vice versa. There are, however, exceptions to this.
Reference: [52] <author> G. I. Lohse, K. Biolsi, N. Walker, and H. H. Rueler. </author> <title> A classification of visual representations. </title> <journal> Communications of the ACM, </journal> <volume> 37(12) </volume> <pages> 36-49, </pages> <year> 1994. </year>
Reference-contexts: There are a variety of dimensions such as shape, geometry, color, texture, 2D and 3D locations, etc., and a variety of visual relations that can be used to carry meaning. There are a number of studies that have attempted to enumerate and classify visual representations <ref> [52] </ref>, dimensions and relations [8, 28, 31]. Nevertheless, a systematic categorization and the use of such a categorization to characterize and compare visual languages in terms of their visual syntax have not yet been done.
Reference: [53] <author> R. K. Lowe. </author> <title> Constructing a mental representation from an abstract technical diagram. Learning and Instruction, </title> <booktitle> 3 </booktitle> <pages> 157-179, </pages> <year> 1993. </year>
Reference-contexts: A number of findings from this research are relevant to visual languages. It has been found that parsing and semantic interpretation is not easy for humans <ref> [53] </ref> and that realism facilitates semantic interpretation [83]. This supports the argument that isomorphism [37] is an important property.
Reference: [54] <author> R. K. Lowe. </author> <title> Selectivity in diagrams: Reading beyond the lines. </title> <journal> Educational Psychology, </journal> <volume> 14 </volume> <pages> 467-491, </pages> <year> 1994. </year> <title> REFERENCES REFERENCES </title>
Reference-contexts: This is relevant to the type of mapping a visual language utilizes, indicating that one-to-many mappings from AD to visual sentences may not be a good idea. Prior knowledge such as that of diagramming conventions has been found to be critical to correct interpretation <ref> [54] </ref>, and visual primitives help cue and retrieve relevant prior knowledge from long term memory [64]. This supports the use of knowledge intensive parsing and interpretation techniques that systems like Beatrix [72] and Anon [47] employ.
Reference: [55] <author> D. E. Mahling and D. L. Fisher. </author> <booktitle> The cognitive engineering of visual languages. In Journal of Visual Languages and Computing, </booktitle> <pages> pages 22-28. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1990. </year>
Reference-contexts: So the central role of visual languages usable by both humans and computers may turn out to be as tools for communication and interaction. This implies that visual language theory requires a broader and interdisciplinary basis, compared to programming language theory. As Mahling and Fisher <ref> [55] </ref> state: "Only by acknowledging the cognitive reality in which the language is employed by programmers and end users, can we recognize that visual programming does introduce a new paradigm." However, despite the pervasiveness of the cognitive benefit assumption in the visual languages 2 2 WHICH VISUAL LANGUAGES? community [9], there <p> Recent research on the cognitive effectiveness of such visualizations has also unearthed mixed results [14]. It should be noted that in all these cases the visual languages have already been designed and implemented in the computational realm before cognitive studies were undertaken. In contrast, Mahling and Fisher <ref> [55] </ref> apply cognitive theory to design rather than evaluation of a visual language.
Reference: [56] <author> K. Marriott, B. Meyer, and K. Wittenburg. </author> <title> Towards a hierarchy of visual languages. </title> <editor> In B. Meyer and K. Marriott, editors, </editor> <title> Visual Language Theory. </title> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: Selker and Koved [84] present a taxonomy of issues for analyzing and designing visual languages, with five major categories: visual alphabet, visual syntax, interaction, structure, and coverage. In a more recent and rigorous approach, Marriott et al. <ref> [56] </ref> use the measures of expressiveness and parsing complexity to classify visual language grammars. Our hope is that the past and present efforts will stimulate additional research along these lines, resulting in the development of other taxonomies, revisions of existing ones, or the integration of multiple taxonomies. <p> A complete treatment of various approaches can be found in <ref> [56] </ref>. One interesting issue to consider is the development of declarative specifications of syntactically and semantically dense [31] visual languages. This requires deeming certain aspects of visual sentences as irrelevant and discarding them while explicitly describing certain others. <p> Other obstacles to efficient parsing and interpretation of general purpose visual representations are detecting emergent 1 objects [49, 25], context sensitivity of their interpretations (Figure 6 provides an example), ambiguity, and semantic density (see Subcategory 3.2 below). Another chapter in this volume <ref> [56] </ref> provides more information on visual language parsing. Generative grammars allow computers to generate or recognize valid visual sentences. Such grammars are useful for implementing interpreters or compilers for visual languages. But grammars are not useful for transforming one valid visual sentence to another in order to capture AD dynamics. <p> The analysis can be done at an individual level, to characterize the tractability of a specific visual language. Multiple languages may be compared using these mea sures. An example is the complexity hierarchies developed by Marriott and Meyer <ref> [56] </ref>. Nickerson 20 5 A FRAMEWORK FOR ANALYSIS AND SYNTHESIS OF VISUAL LANGUAGES [69] proposes two integer-valued measures, graphic token count and diagram class complexity, and one real-valued measure, graphic token density, that are useful for comparing common diagrammatic notations such as graphs and trees.
Reference: [57] <author> Pamela McCorduck. </author> <title> Aaron's Code. </title> <publisher> Freeman, </publisher> <address> San Francisco, CA, </address> <year> 1991. </year>
Reference-contexts: Computers are not yet capable of vision at the human scale. Neither are these machines capable of generating visual representations that depict abstract thoughts and ideas except under the direction of a human <ref> [57] </ref>. Chapters of this book demonstrate the difficulty of formalizing visual languages so that their computational properties can be analyzed and corresponding parsers, interpreters, or compilers can be built with the assurance that they will run in reasonable time and consume reasonable resources.
Reference: [58] <author> T. Menzies. </author> <title> Frameworks for assessing visual languages. </title> <type> Technical Report TR 95-35, </type> <year> 1995. </year>
Reference-contexts: Shu [87] uses three dimensions|level of the language, its scope or generality, and the extent of meaningful visual expressions it utilizes|to characterize a number of languages. Menzies <ref> [58] </ref> uses the dimensions of purpose, visual expressions, and design of the visual programming system to assess the languages. Chang [16] categorizes visual languages in terms of the type of activity they support|visual interaction, visual programming, visual information processing or iconic visual information processing.
Reference: [59] <author> B. Meyer. </author> <title> Pictures depicting pictures: On the specification of visual languages by visual grammars. </title> <type> Technical Report No. 139, </type> <year> 1993. </year>
Reference-contexts: A number of researchers have addressed the issue of formally specifying the static semantics of a visual language. Meyer <ref> [59] </ref> describes a specification scheme that itself uses a mixed vocabulary consisting of textual symbols and partially specified pictures, suitable for human comprehension. Haarslev [38] presents a theoretical framework that combines topology, spatial relations, and description logics for developing syntactic and semantic specifications of static visual sentences. <p> Once the translation is done in which information is discarded or lost, the reverse translation cannot be done uniquely. As Meyer <ref> [59] </ref> states: "If we want visual languages to be more than standard languages in disguise, we have to learn how to describe pictures by pictures." 6.1.2 Spatial and Visual Organization of Information Visual representations help guide reasoning because they permit related information to be spatially organized.
Reference: [60] <author> B. Myers. </author> <title> Visual programming, programming by example and program visualization: A taxonomy. </title> <booktitle> In Proc. Human Factors in Computing Systems Conference (CHI'86), </booktitle> <pages> pages 59-66. </pages> <publisher> ACM Press, </publisher> <year> 1986. </year>
Reference-contexts: There have been many attempts at classification, but these prior approaches generally emphasize only a few measures. Myers <ref> [60] </ref> describes an operational approach to classification based on two programming styles (programming by example and visual programming), three kinds of visualizations (program visualization, visualizing static data and visualizing dynamic data) and two interaction styles (batch mode and interactive).
Reference: [61] <author> N. H. Narayanan. </author> <note> Proc. aaai spring symposium on reasoning with diagrammatic representations. Technical Report SS-92-02, </note> <year> 1992. </year>
Reference-contexts: This makes such representations especially suitable for reasoning by mental simulation. Most propositional descriptions tend to loose these advantages. Therefore, one kind of visual representation|diagrammatic representation|and its role in reasoning have been the subject of recent research interest <ref> [61, 26] </ref>. Diagrammatic representations are different from propositional representations because visual properties of the constituent units of the representation contribute to the semantics of a diagrammatic representation as much as the semantics of the constituent units themselves.
Reference: [62] <author> N. H. Narayanan and M. Hegarty. </author> <title> On designing comprehensible interactive hypermedia manuals, </title> <year> 1997. </year>
Reference-contexts: This points to the potential utility of developing advanced knowledge-based visual languages to assist such human endeavors. Results from studies on how humans comprehend diagrammatic representations can serve to illuminate the cognitive processes. Narayanan and Hegarty <ref> [62] </ref> have developed a cognitive model of comprehension of diagrams and mixed representations.
Reference: [63] <author> N. H. Narayanan, M. Suwa, and H. Motoda. </author> <title> How things appear to work: Predicting behaviors from device diagrams. </title> <booktitle> In Proc. 12th National Conference on Artificial Intelligence, </booktitle> <pages> pages 1161-1167. </pages> <publisher> AAAI Press, </publisher> <year> 1994. </year>
Reference-contexts: be deduced, whereas visual representations display them explicitly at all times [51]. 6 5 A FRAMEWORK FOR ANALYSIS AND SYNTHESIS OF VISUAL LANGUAGES4.5 Graphical Simulations Visual representations such as diagrams facilitate situated reasoning because these make serendipitous inferences, inferences by recognition, prediction by mental visualization, and cueing prior knowledge possible <ref> [63] </ref>. This makes it easy for humans to make inferences from pictorial displays [50].
Reference: [64] <author> N. H. Narayanan, M. Suwa, and H. Motoda. </author> <title> A study of diagrammatic reasoning from verbal and gestural protocols. </title> <booktitle> In Proc. 16th Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 652-657. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1994. </year>
Reference-contexts: Prior knowledge such as that of diagramming conventions has been found to be critical to correct interpretation [54], and visual primitives help cue and retrieve relevant prior knowledge from long term memory <ref> [64] </ref>. This supports the use of knowledge intensive parsing and interpretation techniques that systems like Beatrix [72] and Anon [47] employ. <p> This supports the use of knowledge intensive parsing and interpretation techniques that systems like Beatrix [72] and Anon [47] employ. It has been found that people employ mental visualization <ref> [3, 40, 64] </ref> to make inferences when static pictures are used to represent dynamic ADs, and that this process creates a mismatch between the external and internal representations resulting in increased cognitive load [65]. <p> Larkin and Simon [51] provide an analysis of how spatial adjacency and connectedness can be used to reduce the complexity of reasoning in solving physics problems when the problem descriptions are accompanied by diagrams. A series of experiments on how people reason about mechanical devices from cross-sectional schematic diagrams <ref> [64, 66] </ref> show that diagrams guide the reasoning process along the lines of causal propagation in the operation of the device. People use an incremental reasoning strategy of predicting behaviors of local components and propagating these to other components by exploiting spatial cues of adjacency and connectedness. <p> Visual representations support such reasoning by facilitating the process of transforming the image under the domain's constraints, generating new hypotheses, and testing them against the state of affairs depicted by the transformed image <ref> [64, 40] </ref>. The examples in Figure 7 show situations where the visual representation affords reasoning by image transformation more than a corresponding propositional one. Figure 7A shows a round hole and a cube. The question to be answered is whether the cube can be pushed through the hole.
Reference: [65] <author> N. H. Narayanan, M. Suwa, and H. Motoda. </author> <title> Behavior hypothesis from schematic diagrams. </title> <editor> In J. Glasgow, N. H. Narayanan, and B. Chandrasekaran, editors, </editor> <booktitle> Diagrammatic Reasoning: Cognitive and Computational Perspectives, </booktitle> <pages> pages 501-534. </pages> <publisher> AAAI Press and MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: Furthermore, since visual representations typically represent spatial and geometric properties of their referents in an isomorphic way, modifications of these properties of the constituents of such a representation can be used to reason about the effects of real world processes in which the represented objects participate <ref> [65] </ref>. This makes such representations especially suitable for reasoning by mental simulation. Most propositional descriptions tend to loose these advantages. Therefore, one kind of visual representation|diagrammatic representation|and its role in reasoning have been the subject of recent research interest [61, 26]. <p> It has been found that people employ mental visualization [3, 40, 64] to make inferences when static pictures are used to represent dynamic ADs, and that this process creates a mismatch between the external and internal representations resulting in increased cognitive load <ref> [65] </ref>. This provides a strong argument for additional research on the dynamic syntax and semantics of visual languages. It has been observed that diagram generation and manipulation activities play an important role in creative thought processes such as architectural design [28].
Reference: [66] <author> N. H. Narayanan, M. Suwa, and H. Motoda. </author> <title> Diagram-based problem solving: The case of an impossible problem. </title> <booktitle> In Proc. 17th Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 206-211. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1995. </year>
Reference-contexts: Such representations have been called isomorphic representations. It has been experimentally observed that when static visual representations depict dynamic situations, people tend to mentally simulate the dynamic processes by internally manipulating the visual representations <ref> [40, 66, 85, 83] </ref>. Isomorphic visual representations can aid this, and thus increase comprehensibility, if transformations of the visual representations are isomorphic to the domain processes being simulated. Gurr [37] analyzes properties that contribute to isomorphism, and develops characterizations of different levels of similarity. <p> Larkin and Simon [51] provide an analysis of how spatial adjacency and connectedness can be used to reduce the complexity of reasoning in solving physics problems when the problem descriptions are accompanied by diagrams. A series of experiments on how people reason about mechanical devices from cross-sectional schematic diagrams <ref> [64, 66] </ref> show that diagrams guide the reasoning process along the lines of causal propagation in the operation of the device. People use an incremental reasoning strategy of predicting behaviors of local components and propagating these to other components by exploiting spatial cues of adjacency and connectedness.
Reference: [67] <author> A. Newell and H. A. Simon. </author> <title> Human Problem Solving. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1972. </year>
Reference-contexts: Rewrite rules [78] allow computers to transform existing visual sentences to represent some dynamic process. Rewrite rules are similar in nature to operators that allow a computation to move from one valid state to another in a problem space <ref> [67] </ref>. Visual languages with a fine granularity of interaction are typically interpreted whereas those with a coarse granularity may be compiled. Some commercial mixed languages allow both. Researchers have addressed the issue of specifying meanings of visual sentences in such a way that the specifications are executable [38].
Reference: [68] <author> W. M. Newman and M. G. Lamming. </author> <title> Interactive System Design. </title> <publisher> Addison-Wesley, </publisher> <address> Woking-ham, England, </address> <year> 1995. </year>
Reference-contexts: It is the sum of the number of crossings and elbows in a diagrammatic notation, with the assumption that a high number of these adversely affect comprehensibility. The broad notion of usability, borrowed from interactive system and user interface design literature <ref> [42, 68] </ref>, is a useful measure to apply.
Reference: [69] <author> J. V. Nickerson. </author> <title> Visual programming: Limits of graphic representation. </title> <booktitle> In Proc. IEEE Symposium on Visual Languages, </booktitle> <pages> pages 178-179. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year> <title> 34 REFERENCES REFERENCES </title>
Reference-contexts: Multiple languages may be compared using these mea sures. An example is the complexity hierarchies developed by Marriott and Meyer [56]. Nickerson 20 5 A FRAMEWORK FOR ANALYSIS AND SYNTHESIS OF VISUAL LANGUAGES <ref> [69] </ref> proposes two integer-valued measures, graphic token count and diagram class complexity, and one real-valued measure, graphic token density, that are useful for comparing common diagrammatic notations such as graphs and trees. <p> However, theorists can contribute by identifying relevant cognitive measures to characterize individual languages or to comparatively analyze multiple ones. Excellent beginnings along these lines are presented in [77] and Nickerson <ref> [69] </ref>. <p> "The visual character of languages is rooted in their ability to use dense representations to describe dense domains" [77]. "Application of these metrics to current visual programming languages does not paint an optimistic future for the use of fully general, fully diagrammatic visual programming languages due to their low density" <ref> [69] </ref>. Unfortunately this line of research, judging by the literature, appears not to have been pursued further. One useful cognitive measure is comprehensibility|how easy is it for a user to understand and learn the syntax and semantics of the language. A number of factors influence comprehensibility. <p> A visual language with low salience needs to make the relevant primitives, dimensions or relations visually explicit in order to aid comprehension. A related measure is confusion count, developed by Nickerson <ref> [69] </ref> by modifying a metric originally proposed by Glinert [27]. It is the sum of the number of crossings and elbows in a diagrammatic notation, with the assumption that a high number of these adversely affect comprehensibility.
Reference: [70] <author> D. A. Norman. </author> <title> Cognitive engineering. </title> <editor> In D. A. Norman and S. W. Draper, editors, </editor> <booktitle> User Centered System Design, </booktitle> <pages> pages 31-65. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1986. </year>
Reference-contexts: One way of modeling this is to consider the cycles of interaction involved in visual language use. The cycle of interaction is a term proposed by Norman <ref> [70] </ref> to describe the cognitive processes that take place in one cycle of activity during an ongoing episode of human-computer interaction. We extend this notion to include computational as well as cognitive processes in the use of visual languages. Figure 4 provides a detailed view of this category.
Reference: [71] <author> D. A. Norman. </author> <title> The Psychology of Everyday Things. </title> <publisher> Basic Books, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: This advantage does not carry over to propositional representations since visual properties of constituent symbols do not carry meaning in such representations. Thus, even an informationally equivalent propositional representation may not explicitly represent the same properties as the corresponding picture. It 2 Affordance is a term that Norman introduced <ref> [71] </ref>.
Reference: [72] <author> G. S. Novak and W. C. Bulko. </author> <title> Diagrams and text as computer input. </title> <journal> Journal of Visual Languages and Computing, </journal> <volume> 4 </volume> <pages> 161-175, </pages> <year> 1993. </year>
Reference-contexts: Whether grammars and rewrite rules help human users understand computational processes in the interaction cycle has not yet been studied in the context of any visual language. Interpreting diagrams used in human visual languages remains a difficult problem as well. Electronic Cocktail Napkin [36], Beatrix <ref> [72] </ref>, Redraw [94], and Anon [47] are examples of computer programs that use artificial intelligence techniques to understand diagrams commonly employed in human endeavors. <p> These systems illustrate the difficulty of interpreting even highly stylized visual representations used in their respective ADs. When visual representations use a mixed vocabulary of diagrams and text, there is an additional source of difficulty|that of resolving coreferences <ref> [72] </ref>. <p> multiple elements of the visual sentence has the same referent, as in the case of a mixed visual sentence consisting of text and picture in which many words and graphical units refer to same things, and constructing a unified model of information from text and diagrams is difficult both computationally <ref> [72] </ref> and cognitively [41]. This is relevant to the type of mapping a visual language utilizes, indicating that one-to-many mappings from AD to visual sentences may not be a good idea. <p> Prior knowledge such as that of diagramming conventions has been found to be critical to correct interpretation [54], and visual primitives help cue and retrieve relevant prior knowledge from long term memory [64]. This supports the use of knowledge intensive parsing and interpretation techniques that systems like Beatrix <ref> [72] </ref> and Anon [47] employ. It has been found that people employ mental visualization [3, 40, 64] to make inferences when static pictures are used to represent dynamic ADs, and that this process creates a mismatch between the external and internal representations resulting in increased cognitive load [65].
Reference: [73] <author> M. Petre. </author> <title> Why looking isn't always seeing: Readership skills and graphical programming. </title> <journal> Communications of the ACM, </journal> <volume> 38 </volume> <pages> 33-44, </pages> <year> 1995. </year>
Reference-contexts: On the other side, there is literature that questions the validity of the belief that graphical syntax alone will increase comprehensibility or programmability <ref> [5, 33, 35, 73] </ref>. A visual language whose graphical syntax is as incomprehensible as that of a terse textual language can provide no justification for the additional complexity that such a language introduces on the computational side. <p> A variety of related terms, all containing the root word "visual" appear in the literature with subtly different meanings. Many authors (for example, [75] and <ref> [73] </ref>) rightly observe that it is not correct to restrict terms such as "visual" or "visualization" to visible images only.
Reference: [74] <author> M. Petre, A. F. Blackwell, and T. R. G. Green. </author> <title> Cognitive questions in software visualization. </title> <editor> In J. Stasko, J. Domingue, B. Price, and M. Brown, editors, </editor> <title> Software Visualization: Programming as a Multi-Media Experience. </title> <publisher> MIT Press. in press. </publisher>
Reference-contexts: However, cognitive researchers have generally investigated human visual languages such as engineering diagrams, weather maps and architectural sketches, not visual languages that both computers and humans can use. Cognitive issues in the cycle of interaction for visual languages have not yet been thoroughly explored <ref> [74] </ref>. 19 5 A FRAMEWORK FOR ANALYSIS AND SYNTHESIS OF VISUAL LANGUAGES 3 Evaluation 3.1 Computational Evaluation 3.1.1 Measures: Expressiveness, Time Complexity, Space Complexity, Graphic Token Count, Diagram Class Complexity, Graphic Token Density, Syntactic Differentiation/Density, Semantic Differentiation/Density, etc. 3.1.2 Characterization of Individuals: Notational, Analog, etc. 3.1.3 Comparative Analysis 3.2 Cognitive Evaluation <p> Cognitive fit [88], or the match between the forms of information users seek in the context of a problem solving task or application domain and the forms in which the visual language presents information <ref> [74] </ref>, is another factor affecting the usability of visual languages. The cognitive dimensions approach of Green [32, 34] provides additional measures.
Reference: [75] <author> B. A. Price, R. M. Baecker, and I. S. </author> <title> Small. A principled taxonomy of software visualization. </title> <journal> Journal of Visual Languages and Computing, </journal> <volume> 4(3) </volume> <pages> 211-266, </pages> <year> 1993. </year>
Reference-contexts: A variety of related terms, all containing the root word "visual" appear in the literature with subtly different meanings. Many authors (for example, <ref> [75] </ref> and [73]) rightly observe that it is not correct to restrict terms such as "visual" or "visualization" to visible images only. <p> Thus, information visualization is an area concerned with developing visual languages for communicating information structures to humans and allowing them to interact with these structures through direct manipulation. 4.3 Visualization of Software Visualizing static and dynamic characteristics of programs can facilitate comprehension and debugging for the user <ref> [75] </ref>. Data structures and program control flows are often easier to understand when visualized using graphs and flowcharts. The hierarchical file structure of an operating system is easily visualized either with a directory tree or folders. <p> On one end of this spectrum lie completely visual languages and at the other end are completely textual languages. Languages that use symbols of one kind or the other as secondary notations <ref> [75, 34] </ref> fall in the middle. Textual languages that also utilize graphical secondary notations|e.g., text that uses color, boldfacing etc. to convey additional information|and graphical languages that utilize textual secondary notations|e.g., map with labels|are two intermediate points of this spectrum. <p> The results [92] have been mixed in that while advanced students benefited, students with less knowledge or visual capability did not show improved learning. Researchers in software visualization in general <ref> [75] </ref>, and algorithm animation in particular [13], strive to create visual languages using which computers can communicate the inner workings of programs to humans. These are not visual languages that support the full cycle of interaction|instead, they are intended for one-way communication from the computational to the cognitive.
Reference: [76] <author> J. Puigsegur, J. Agusti, and D. Robertson. </author> <title> A visual programming language. </title> <booktitle> In Proc. IEEE Symposium on Visual Languages, </booktitle> <pages> pages 214-215. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1996. </year>
Reference-contexts: Most current literature on visual language theory is about those visual languages which are visualizations of originally textual languages. Logic programming languages <ref> [76] </ref> and finite state automata [17] are some examples. Although formalizing such languages is useful and their visual forms are sometimes advantageous over the textual ones, such languages may not help us understand those properties that make human visual languages so powerful.
Reference: [77] <author> D. R. Raymond. </author> <title> Characterizing visual languages. </title> <booktitle> In Proc. IEEE Symposium on Visual Languages, </booktitle> <pages> pages 176-182. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: Animations are examples of the latter. The former is suitable when the visual language is notational and the latter is suitable when the visual language is analog <ref> [77] </ref>, and the corresponding AD is continuous. In practice, animations are employed even when the corresponding AD is not continuous (e.g., algorithm animations), but whether this contributes to cognitive effectiveness or is merely an irrelevant and potentially distracting feature is yet to be determined. <p> Another interesting possibility is to examine computational implications of Goodman's [31] notions of syntactic and semantic differentiation and density, and the corresponding notions of notational and analog systems (see <ref> [77] </ref> for definitions) for visual languages. 3.2 Cognitive Evaluation Conducting a cognitive evaluation requires experimental research with human participants, which is outside the scope of visual language theory. However, theorists can contribute by identifying relevant cognitive measures to characterize individual languages or to comparatively analyze multiple ones. <p> However, theorists can contribute by identifying relevant cognitive measures to characterize individual languages or to comparatively analyze multiple ones. Excellent beginnings along these lines are presented in <ref> [77] </ref> and Nickerson [69]. Both authors come to similar conclusions regarding the kind of visual language that is likely to be most effective: "The visual character of languages is rooted in their ability to use dense representations to describe dense domains" [77]. "Application of these metrics to current visual programming languages <p> Excellent beginnings along these lines are presented in <ref> [77] </ref> and Nickerson [69]. Both authors come to similar conclusions regarding the kind of visual language that is likely to be most effective: "The visual character of languages is rooted in their ability to use dense representations to describe dense domains" [77]. "Application of these metrics to current visual programming languages does not paint an optimistic future for the use of fully general, fully diagrammatic visual programming languages due to their low density" [69]. Unfortunately this line of research, judging by the literature, appears not to have been pursued further. <p> We propose the taxonomy not as an end, but as a means to encourage further research on the issues that it explicitly addresses. We agree with Raymond <ref> [77] </ref> when he asserts: "Practical languages contain both visual and notational elements, however, and we must evaluate a given language for its suitability both visually and as a notation.
Reference: [78] <author> A. Repenning. </author> <title> Bending the rules: Steps toward semantically enriched graphical rewrite rules. </title> <booktitle> In Proc. IEEE Symposium on Visual Languages, </booktitle> <pages> pages 226-233. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1995. </year>
Reference-contexts: There is not much research yet on developing specifications of the dynamic semantics of visual languages intended for human comprehension and computer execution. Typically this semantics is implicitly captured in the graphical procedures or rewrite rules employed by the system. Repenning <ref> [78] </ref> discusses extending rewrite rules to explicitly capture dynamic semantics. For continuous AD s, this mapping requires either quantization of the continuous state changes so that a continuous domain can be represented by a discrete visual language, or specifying the dynamic syntax so that the visual display is continuously changed. <p> Generative grammars allow computers to generate or recognize valid visual sentences. Such grammars are useful for implementing interpreters or compilers for visual languages. But grammars are not useful for transforming one valid visual sentence to another in order to capture AD dynamics. Rewrite rules <ref> [78] </ref> allow computers to transform existing visual sentences to represent some dynamic process. Rewrite rules are similar in nature to operators that allow a computation to move from one valid state to another in a problem space [67].
Reference: [79] <author> A. Repenning and T. Sumner. Agentsheets: </author> <title> A medium for creating domain-oriented visual languages. </title> <journal> IEEE Computer, </journal> <volume> 28 </volume> <pages> 17-25, </pages> <year> 1995. </year>
Reference-contexts: These have become an important tool in educational research [15]. Many user friendly tools for creating such simulations are becoming available. Some examples are KidSim TM from Apple Computer [89], Star Logo from MIT Media Laboratory [80] and Agentsheets from the University of Colorado <ref> [79] </ref>. Such simulations employ direct manipulation techniques to specify the model to be simulated and its initial conditions, and produce visualizations of time-varying processes (e.g., predator-prey relationships in an ecosystem). Users can directly manipulate objects in the simulation without having to access their internal representations. <p> In practice, animations are employed even when the corresponding AD is not continuous (e.g., algorithm animations), but whether this contributes to cognitive effectiveness or is merely an irrelevant and potentially distracting feature is yet to be determined. Rewrite rules that systems like Agentsheets <ref> [79] </ref> and Bitpict [23, 24] utilize are examples of dynamic syntax specifications.
Reference: [80] <author> M. Resnick. </author> <title> Beyond the centralized mindset. </title> <journal> Journal of the Learning Sciences, </journal> <volume> 5(1) </volume> <pages> 1-22, </pages> <year> 1996. </year>
Reference-contexts: These have become an important tool in educational research [15]. Many user friendly tools for creating such simulations are becoming available. Some examples are KidSim TM from Apple Computer [89], Star Logo from MIT Media Laboratory <ref> [80] </ref> and Agentsheets from the University of Colorado [79]. Such simulations employ direct manipulation techniques to specify the model to be simulated and its initial conditions, and produce visualizations of time-varying processes (e.g., predator-prey relationships in an ecosystem). <p> The Alternate Reality Kit [90], which is an environment for users to create and experiment with the dynamics of moving particles, is an early example. KidSim TM [89] and Star Logo <ref> [80] </ref> are currently popular mixed visual languages using which one can build simulations of microworlds and processes occurring inside them. The computer then executes the simulations and depicts results graphically through interactive animations of the microworlds using pictures created by the user.
Reference: [81] <author> G. G. Robertson, S. K. Card, and J. D. Mackinlay. </author> <title> Information visualization using 3d interactive animation. </title> <journal> Communications of the ACM, </journal> <volume> 36(4) </volume> <pages> 57-71, </pages> <year> 1993. </year>
Reference-contexts: In these cases, visual views of descriptive representations allow the viewer to discover relations and characteristics that are hidden in the textual representation. This is particularly true of complex hypermedia information structures such as the World Wide Web for which various graphical visualizations (e.g., Cone Trees <ref> [81] </ref>) have been developed.
Reference: [82] <author> F. Saint-Martin. </author> <title> Semiotics of Visual Language. </title> <publisher> Indiana University Press, </publisher> <address> Bloomington, IN, </address> <year> 1990. </year>
Reference-contexts: Thus many dimensions and taxonomies are needed to determine a language's overall effectiveness." Theories of human visual languages have existed for quite some time: visual thinking [4], semi-otics of visual languages <ref> [82] </ref>, etc. But new types of theories are necessary for visual languages in the context of human-computer interaction. A theory of visual languages must be formal enough to derive its computational properties.
Reference: [83] <author> D. L. Schwartz and J. B. Black. </author> <title> Analog imagery in mental model reasoning: Depictive models. </title> <journal> Cognitive Psychology, </journal> <volume> 30 </volume> <pages> 254-219, </pages> <year> 1996. </year>
Reference-contexts: A number of findings from this research are relevant to visual languages. It has been found that parsing and semantic interpretation is not easy for humans [53] and that realism facilitates semantic interpretation <ref> [83] </ref>. This supports the argument that isomorphism [37] is an important property. <p> Such representations have been called isomorphic representations. It has been experimentally observed that when static visual representations depict dynamic situations, people tend to mentally simulate the dynamic processes by internally manipulating the visual representations <ref> [40, 66, 85, 83] </ref>. Isomorphic visual representations can aid this, and thus increase comprehensibility, if transformations of the visual representations are isomorphic to the domain processes being simulated. Gurr [37] analyzes properties that contribute to isomorphism, and develops characterizations of different levels of similarity.
Reference: [84] <author> T. Selker and L. Koved. </author> <title> Elements of visual language. </title> <booktitle> In Proc. IEEE Symposium on Visual Languages, </booktitle> <pages> pages 38-44. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1988. </year>
Reference-contexts: Menzies [58] uses the dimensions of purpose, visual expressions, and design of the visual programming system to assess the languages. Chang [16] categorizes visual languages in terms of the type of activity they support|visual interaction, visual programming, visual information processing or iconic visual information processing. Selker and Koved <ref> [84] </ref> present a taxonomy of issues for analyzing and designing visual languages, with five major categories: visual alphabet, visual syntax, interaction, structure, and coverage. In a more recent and rigorous approach, Marriott et al. [56] use the measures of expressiveness and parsing complexity to classify visual language grammars.
Reference: [85] <author> R. N. Shepard and L. A. Cooper. </author> <title> Mental Images and Their Transformations. </title> <publisher> The MIT Press, </publisher> <address> Cambridge. MA, </address> <year> 1986. </year> <title> 35 REFERENCES REFERENCES </title>
Reference-contexts: Such representations have been called isomorphic representations. It has been experimentally observed that when static visual representations depict dynamic situations, people tend to mentally simulate the dynamic processes by internally manipulating the visual representations <ref> [40, 66, 85, 83] </ref>. Isomorphic visual representations can aid this, and thus increase comprehensibility, if transformations of the visual representations are isomorphic to the domain processes being simulated. Gurr [37] analyzes properties that contribute to isomorphism, and develops characterizations of different levels of similarity.
Reference: [86] <author> S J. Shin. </author> <title> The Logical Status of Diagrams. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, England, </address> <year> 1994. </year>
Reference-contexts: Therefore, researchers in this area have developed formal characterizations of diagrammatic representations using a heterogeneous logic that exploits propositional and diagrammatic representations <ref> [7, 39, 86] </ref>. 4.5 Graphical Simulations The notion of diagrammatic reasoning is combined with direct manipulation in interactive graphical simulations. These have become an important tool in educational research [15]. Many user friendly tools for creating such simulations are becoming available.
Reference: [87] <author> N. C. Shu. </author> <title> Visual programming languages: A perspective and a dimensional analysis. </title> <editor> In S.-K. Chang, T. Ichikawa, and P. A. Ligomenides, editors, </editor> <booktitle> Visual Languages, </booktitle> <pages> pages 11-34. </pages> <publisher> Plenum Publishing Corporation, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Myers [60] describes an operational approach to classification based on two programming styles (programming by example and visual programming), three kinds of visualizations (program visualization, visualizing static data and visualizing dynamic data) and two interaction styles (batch mode and interactive). Shu <ref> [87] </ref> uses three dimensions|level of the language, its scope or generality, and the extent of meaningful visual expressions it utilizes|to characterize a number of languages. Menzies [58] uses the dimensions of purpose, visual expressions, and design of the visual programming system to assess the languages.
Reference: [88] <author> A. Sinha and I. Vessey. </author> <title> Cognitive fit in recursion and iteration: An empirical study. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> SE-10(5):386-379, </volume> <year> 1992. </year>
Reference-contexts: One usability study [5] appears to indicate that graphical notations do not provide an advantage for procedural languages. Cognitive fit <ref> [88] </ref>, or the match between the forms of information users seek in the context of a problem solving task or application domain and the forms in which the visual language presents information [74], is another factor affecting the usability of visual languages.
Reference: [89] <author> David Cantwell Smith, Allen Cypher, and Jim Spohrer. KidSim: </author> <title> Programming agents without a programming language. </title> <journal> Communications of the ACM, </journal> <volume> 37 </volume> <pages> 54-68, </pages> <year> 1994. </year>
Reference-contexts: These have become an important tool in educational research [15]. Many user friendly tools for creating such simulations are becoming available. Some examples are KidSim TM from Apple Computer <ref> [89] </ref>, Star Logo from MIT Media Laboratory [80] and Agentsheets from the University of Colorado [79]. Such simulations employ direct manipulation techniques to specify the model to be simulated and its initial conditions, and produce visualizations of time-varying processes (e.g., predator-prey relationships in an ecosystem). <p> The Alternate Reality Kit [90], which is an environment for users to create and experiment with the dynamics of moving particles, is an early example. KidSim TM <ref> [89] </ref> and Star Logo [80] are currently popular mixed visual languages using which one can build simulations of microworlds and processes occurring inside them. The computer then executes the simulations and depicts results graphically through interactive animations of the microworlds using pictures created by the user.
Reference: [90] <author> R. B. Smith. </author> <title> The alternate reality kit: An animated environment for creating interactive simulations. </title> <booktitle> In Proc. IEEE Symposium on Visual Languages, </booktitle> <pages> pages 99-106. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1986. </year>
Reference-contexts: The Alternate Reality Kit <ref> [90] </ref>, which is an environment for users to create and experiment with the dynamics of moving particles, is an early example. KidSim TM [89] and Star Logo [80] are currently popular mixed visual languages using which one can build simulations of microworlds and processes occurring inside them.
Reference: [91] <author> S. Steinman and K. Carver. </author> <title> Visual programming with Prograph CPX. </title> <publisher> Manning Publications/Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1995. </year>
Reference-contexts: Algorithm animation systems such as Balsa [13] can be used to automatically create and display a visual language that depicts the operation of a single algorithm. Others can represent a class of domains. Pictorial Janus [48] and Prograph <ref> [91] </ref> are examples of visual programming languages that can represent a variety of concurrent and dataflow computations respectively. The American Sign Language is a visual language that is very general. The next issues are how to represent the information (syntax) and how to associate the representation with the represented (semantics).
Reference: [92] <author> K. Stenning, R. Cox, and J. Oberlander. </author> <title> Contrasting the cognitive effects of graphical and sentential logic teaching: Reasoning, representation and individual differences. </title> <booktitle> Language and Cognitive Processes, </booktitle> 10(3/4):333-354, 1995. 
Reference-contexts: While its authors have studied theoretical and computational issues [7], others have looked at the cognitive effectiveness of the language|i.e., how well it helps students 22 6 ISSUES FOR VISUAL LANGUAGE RESEARCH learn logic in comparison with traditional teaching methods. The results <ref> [92] </ref> have been mixed in that while advanced students benefited, students with less knowledge or visual capability did not show improved learning.
Reference: [93] <author> K. Stenning and J. Oberlander. </author> <title> A cognitive theory of graphical and linguistic reasoning: Logic and implementation. </title> <journal> Cognitive Science, </journal> <volume> 19 </volume> <pages> 97-140, </pages> <year> 1995. </year>
Reference-contexts: There are, however, exceptions to this. Figure 7 showed that visual representations afford certain inferences, thereby reducing reasoning to recognition of a spatial relationship. Visual and non-visual reasoning are often intertwined <ref> [7, 93] </ref>, and in such cases visual representations can provide guidance to the logical reasoning process. Such guidance can result in a lower number of alternatives that the inference process needs to evaluate, thereby making it more efficient.
Reference: [94] <author> S. Tessler, Y. Iwasaki, and K. </author> <title> Law. Qualitative structural analysis using diagrammatic reasoning. </title> <editor> In J. Glasgow, N. H. Narayanan, and B. Chandrasekaran, editors, </editor> <booktitle> Diagrammatic Reasoning: Cognitive and Computational Perspectives, </booktitle> <pages> pages 711-730. </pages> <publisher> AAAI Press and MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: Whether grammars and rewrite rules help human users understand computational processes in the interaction cycle has not yet been studied in the context of any visual language. Interpreting diagrams used in human visual languages remains a difficult problem as well. Electronic Cocktail Napkin [36], Beatrix [72], Redraw <ref> [94] </ref>, and Anon [47] are examples of computer programs that use artificial intelligence techniques to understand diagrams commonly employed in human endeavors. <p> Such guidance can result in a lower number of alternatives that the inference process needs to evaluate, thereby making it more efficient. Computer programs that use diagrams that humans find equally useful for guiding and controlling inferences, such as Redraw <ref> [94] </ref> and Hy-perproof [6], illustrate this point.
Reference: [95] <author> E. R. Tufte. </author> <title> The Visual Display of Quantitative Information. </title> <publisher> Graphics Press, </publisher> <address> Cheshire, CT, </address> <year> 1983. </year>
Reference-contexts: Andries et al. [2] propose graph data structures for representing VS and S, and a "represents/represented-by" relation that maps between the two. Tufte <ref> [95, 96, 97] </ref> and Engelhardt and colleagues [19] suggest principles for mapping from different kinds of information (e.g., nominal, categorical, ordinal, quantitative, topological and spatial) to visual primitives, dimensions and relations. This mapping captures the static semantics of the language.
Reference: [96] <author> E. R. Tufte. </author> <title> Envisioning Information. </title> <publisher> Graphics Press, </publisher> <address> Cheshire, CT, </address> <year> 1990. </year>
Reference-contexts: Thus, graphical user interfaces for direct manipulation may be viewed as visual languages that humans use to interact with computers. 4.2 Visualization of Information Visual representations are often used to make higher order relations more accessible to the human intuition <ref> [96] </ref>. A graph of a function makes its characteristics much more explicit than a table of values of the same function even though informationally both are equivalent. <p> Andries et al. [2] propose graph data structures for representing VS and S, and a "represents/represented-by" relation that maps between the two. Tufte <ref> [95, 96, 97] </ref> and Engelhardt and colleagues [19] suggest principles for mapping from different kinds of information (e.g., nominal, categorical, ordinal, quantitative, topological and spatial) to visual primitives, dimensions and relations. This mapping captures the static semantics of the language.
Reference: [97] <author> E. R. Tufte. </author> <title> Visual Explanations. </title> <publisher> Graphics Press, </publisher> <address> Cheshire, CT, </address> <year> 1997. </year>
Reference-contexts: Andries et al. [2] propose graph data structures for representing VS and S, and a "represents/represented-by" relation that maps between the two. Tufte <ref> [95, 96, 97] </ref> and Engelhardt and colleagues [19] suggest principles for mapping from different kinds of information (e.g., nominal, categorical, ordinal, quantitative, topological and spatial) to visual primitives, dimensions and relations. This mapping captures the static semantics of the language.
Reference: [98] <author> B. Tversky. </author> <title> Cognitive origins of graphic productions. </title> <editor> In F. T. Marchese, editor, </editor> <title> Understanding Images: Finding Meaning in Digital Imagery, </title> <address> pages 29-53. </address> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: In fact, visual thinking [4] is deeply embedded in the psyche of every culture, and visual languages predate the development of textual ones <ref> [98] </ref>. The ease with which we create and comprehend visual representations is surely a significant factor motivating research in the area of visual languages, and this is articulated in many different ways [9]. Most of this research has been on visual programming languages in the past.
Reference: [99] <author> D. Wang, J. R. Lee, and H. Zeevat. </author> <title> Reasoning with diagrammatic representations. </title> <editor> In J. Glasgow, N. H. Narayanan, and B. Chandrasekaran, editors, </editor> <booktitle> Diagrammatic Reasoning: Cognitive and Computational Perspectives, </booktitle> <pages> pages 339-396. </pages> <publisher> AAAI Press and MIT Press, </publisher> <year> 1995. </year> <title> 36 REFERENCES REFERENCES </title>
Reference-contexts: The mapping is implemented as a set of productions that translate diagrams into their textual equivalents. The translated text is merged with the text of the rest of the program, which can then be compiled and executed. Signature morphism, proposed by Wang and colleagues <ref> [99, 100] </ref>, is a formally derived one-to-one mapping between signatures of a visual sentence and a state of the AD, specifying the meaning of the sentence. <p> This requires careful design of representations. One informal yardstick to apply might be "guessability" of the signature morphism <ref> [99] </ref> of the visual representation. Consider the configuration of disks in Figure 6, which can easily be described in propositional form using their absolute coordinates.
Reference: [100] <author> D. Wang and H. Zeevat. </author> <title> A syntax directed approach to picture semantics. </title> <editor> In B. Meyer and K. Marriott, editors, </editor> <title> Visual Language Theory. </title> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: The mapping is implemented as a set of productions that translate diagrams into their textual equivalents. The translated text is merged with the text of the rest of the program, which can then be compiled and executed. Signature morphism, proposed by Wang and colleagues <ref> [99, 100] </ref>, is a formally derived one-to-one mapping between signatures of a visual sentence and a state of the AD, specifying the meaning of the sentence.
Reference: [101] <author> K. Wittenburg and L. Weitzman. </author> <title> Relational grammars: Theory and practice in a visual language interface for process modeling. </title> <editor> In B. Meyer and K. Marriott, editors, </editor> <title> Visual Language Theory. </title> <publisher> Springer Verlag, </publisher> <year> 1997. </year> <month> 37 </month>
Reference-contexts: Wittenburg and Weitzman <ref> [101] </ref> describe a practical application of visual language theory that supports the cycle of interaction. <p> Software visualization systems such as algorithm animators, on the other hand, require users to use textual means for visualization specifications, the result of executing which is a visual language that depicts program execution for the benefit of the user. Other visual languages such as ShowBiz <ref> [101] </ref> or those used in virtual reality systems are designed for two-way communication.
References-found: 101

