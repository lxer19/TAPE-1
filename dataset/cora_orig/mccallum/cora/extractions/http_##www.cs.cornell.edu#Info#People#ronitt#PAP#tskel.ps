URL: http://www.cs.cornell.edu/Info/People/ronitt/PAP/tskel.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/ronitt/papers.html
Root-URL: 
Title: A Mathematical Theory of Self-Checking, Self-Testing and Self-Correcting Programs  
Author: Ronitt Rubinfeld 
Note: This research was supported by NSF grant CCR 88-13632, by the International Computer Science Institute and by an IBM Graduate Fellowship.  
Abstract: Suppose someone gives us an extremely fast program P that we can call as a black box to compute a function f . Rather than trust that P works correctly, a self-testing/correcting pair for f allows us to: (1) estimate the probability that P (x) 6= f (x) when x is randomly chosen; (2) on any input x, compute f (x) correctly as long as P is not too faulty on average. Furthermore, both (1) and (2) require only a small multiplicative overhead (usually constant) over the running time of P . A program result checker for f (as introduced by Manuel Blum) allows us to check that on particular input x, P (x) = f (x). We present general techniques for constructing simple to program self-testing/correcting pairs for a variety of numerical functions. The self-testing/correcting pairs introduced for many of the problems are based on the property that the solution to a particular instance of the problem can be expressed as the solution to a few random instances of the same size. An important idea is to design self-testing/correcting pairs for an entire library of functions rather than for each function individually. We extend these notions and some of the general techniques to check programs for some specific functions which are only intended to give good approximations to f (x). We extend the above models and techniques of program result checking and self-testing/correcting to the case where the behavior of the program is modelled as being adaptive, i.e. the program may not always give the same answer on a particular input. These stronger checkers provide multi-prover interactive proofs for these problems. The theory of checking is also extended to parallel programs [Rubinfeld]. We construct parallel checkers for many basic problems in parallel computation. We show that for some problems, result checkers which are much more efficient can be constructed if the answers are checked in batches, i.e. many answers are checked at the same time. For these problems, the multiplicative overhead of checking the result can be made arbitrarily small. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Abadi, M., Feigenbaum, J., Kilian, J., </author> <title> "On Hiding Information from an Oracle", </title> <journal> Journal of Computer and System Sciences, </journal> <volume> Vol. 39, No. 1, </volume> <month> August </month> <year> 1989, </year> <pages> pp. 29-50. </pages>
Reference-contexts: 2 ) mod p (2) d+1 X ff j P (x + p2 n jt 2 ) mod p] 1 4 (d + 1)ffi 0 (3) Using the definitions of G and Lemma 19, equation (1) holds with probability 1 2 (d + 1)ffi 0 since for any i 2 <ref> [1; : : :; d + 1] </ref>, Pr t 1 2Z p2 n [(x + p2 n it 1 ) 2 G and P (x + p2 n it 1 ) = P d+1 j=1 ff i P ((x + p2 n it 1 ) + p2 n jt 2 ) <p> This is similar to the model introduced in <ref> [1, Abadi Feigenbaum Kilian] </ref> and later extended in [9, Beaver Feigenbaum] to allow using several non-communicating programs for the same function, except that here we do not trust the program to return correct answers. In addition, we only allow protocols which are restricted versions of [1, Abadi Feigenbaum Kilian] [9, Beaver <p> to the model introduced in <ref> [1, Abadi Feigenbaum Kilian] </ref> and later extended in [9, Beaver Feigenbaum] to allow using several non-communicating programs for the same function, except that here we do not trust the program to return correct answers. In addition, we only allow protocols which are restricted versions of [1, Abadi Feigenbaum Kilian] [9, Beaver Feigenbaum] where the result checker may only ask the program questions of the form "What is the value of f (x)?". We call a program that satisfies the above constraints a private result checker. <p> order to define a private result checker: Let k be the number of programs purporting to compute f , such that none of these programs can communicate with any other program, and let P i be the program on the i th machine for 1 i k. 87 As in <ref> [1, Abadi Feigenbaum Kilian] </ref>, we define L to be a function which we call the leak function. Intuitively, L (x) is the amount of information leaked by the result checker to the programs on input x.
Reference: [2] <author> Adleman, L., Huang, M., Kompella, K., </author> <title> "Efficient Checkers for Number-Theoretic Computations", </title> <note> Submitted to Information and Computation. </note>
Reference-contexts: Program Result Checking has been successfully applied to a wide range of problems, including sorting, matrix rank, linear programming, graph isomorphism, matrix multiplication, greatest common divisor <ref> [2, Adleman Huang Kompella] </ref>, [15, Blum], [17, Blum Kannan], [18, Blum Kan-nan Rubinfeld], [20, Blum Luby Rubinfeld 2], [23, Blum Raghavan], [34, Freivalds],[39, Kannan]. The question remains of how to verify that the result checker program meets its specifications. <p> be as efficient as possible. 2.2 Examples Many result checkers have been found for various types of problems such as graph iso-morphism, matrix rank, quadratic residuocity, linear programming, maximum matching, greatest common divisor, permanent and even PSPACE-complete problems [15, Blum], [23, Blum Raghavan], [17, Blum Kannan], [18, Blum Kannan Rubinfeld], <ref> [2, Adleman Huang Kompella] </ref> [50, Fortnow Karloff Lund Nisan] [62, Shamir]. <p> Previous to our work, [38, Kaminski] gives program result checkers for integer and polynomial multiplication. Independently of our work, <ref> [2, Adleman Huang Kompella] </ref> give program result checkers for integer multiplication and modular exponentiation. Both of these papers use very different techniques than ours. <p> Proof: Similar to the proof of Theorem 12 (page 48). The incremental and total time of Mod Expon Bootstrap Self-Test are linear in the incremental and total time of Mod ExpSC (n; R; fi= log (n)), respectively. <ref> [2, Adleman Huang Kompella] </ref> have independently discovered a method of result checking the exponentiation function without the restriction that a and R be relatively prime. Their method uses similar ideas of testing by bootstrapping. <p> For example, we show that there are P-complete problems (evaluating straight-line programs, linear programming) that have very fast (even constant depth) parallel result checkers. Integer GCD is not known to be in RNC, yet a logarithmic depth parallel result checker exists for it <ref> [2, Adleman Huang Kompella] </ref>. Maximum Matching is not known to be in NC (though it is in RNC), and it has a deterministic NC result checker. Multiplication, parity and majority all have lower bounds of (log n= log log n) depth, yet all have (completely different) constant depth result checkers. <p> By slightly changing it, the sequential result checker can be parallelized to run in O (log n) depth. The sequential result checker for Integer GCD <ref> [2, Adleman Huang Kompella] </ref> uses ideas from interactive proofs and can be made into a parallel result checker. It runs in O (log n) depth, with n processors. <p> An adaptive result checker is automatically a k-adaptive result checker, and a k-adaptive result checker is automatically a (non-adaptive) result checker. Many result checkers that have been found are also adaptive result checkers. For example, it can easily be seen that the GCD checker in <ref> [2, Adleman Huang Kompella] </ref> and that all of the result checkers given in [17, Blum Kannan] are adaptive. Other result checkers do not work for an adaptive program. <p> This result checker trivially works for an adaptive program as well, because it makes no extra calls to the program. Independently of our work, <ref> [2, Adleman Huang Kompella] </ref> describe a result checker for multiplication in the same spirit but different than [38, Kaminski] which also makes no calls to the program.
Reference: [3] <author> Aho, A., Hopcroft, J., Ullman, J., </author> <title> The Design and Analysis of Computer Algorithms, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachussetts, </address> <year> 1974. </year>
Reference-contexts: See [39, Kannan] for a discussion of checking probabilistic programs. * The model of computation typically used in this work will be a RAM bit cost model of computation as defined in <ref> [3, Aho Hopcroft Ullman] </ref>. A very important idea is to allow the result checker to call the program on other inputs while checking it on a given input. <p> The notion of libraries is useful for another reason as well: Consider again the problem of designing a self-testing/correcting pair for the determinant. Many of the proposed solutions require matrix multiplication. However, matrix multiplication and determinant are equivalent problems with respect to asymptotic running times <ref> [3, Aho Hopcroft Ullman] </ref>. Therefore, a determinant self-testing/correcting pair using matrix multiplication will not be quantifiably different from a program for the determinant.
Reference: [4] <author> Ajtai, M., </author> <type> personal communication through M. Naor. </type>
Reference-contexts: Therefore, even if the result checker cannot determine which equivalence class the input is in, it can verify that the answer of P on the input is correct. In the result checking algorithm, several random permutations of the input bits are made; <ref> [4, Ajtai] </ref> gives a way of doing this in constant depth.
Reference: [5] <author> Alon, N., Babai, L., Itai, </author> <title> "A Fast and Simple Randomized Parallel Algorithm for the Maximal Independent Set Problem", </title> <journal> J. Algorithms, </journal> <volume> vol. 7, </volume> <year> 1986, </year> <pages> pp. 567-583. </pages>
Reference-contexts: Furthermore, the checker is deterministic, and no other calls to the program are made. In contrast, the best known algorithms for this problem use at least logarithmic parallel time [36, Goldberg Spencer], <ref> [5, Alon Babai Itai] </ref>, [49, Luby]. 77 6.3 Computability by Random Inputs In Chapter 3, [20, Blum Luby Rubinfeld 2] we show that one can design result checkers for many functions that have the property of random self-reducibility that the function can be computed by computing the function on one or
Reference: [6] <author> Babai, L., </author> <title> "Trading Group Theory for Randomness", </title> <booktitle> Proc. 17th ACM Symposium on Theory of Computing, </booktitle> <year> 1985, </year> <pages> pp. 421-429. </pages>
Reference: [7] <author> Babai, L., </author> <title> "E-mail and the Power of Interaction", </title> <booktitle> Proc. 5th Structure in Complexity Theory Conference, </booktitle> <year> 1990. </year>
Reference-contexts: This led to the eventual discovery that IP = PSPACE ([50, Fortnow Karloff Lund Nisan], [62, Shamir], <ref> [7, Babai] </ref>). The results in this chapter are related to those in [8, Babai Fortnow Lund].
Reference: [8] <author> Babai, L., Fortnow, L., Lund, C., </author> <title> "Non-Deterministic Exponential Time has Two-Prover Interactive Protocols", </title> <type> Technical Report 90-03, </type> <institution> University of Chicago, Dept. of Computer Science. </institution> <note> Also to appear in Proceedings of the 31st Annual Symposium on Foundations of Computer Science,, </note> <year> 1990. </year>
Reference-contexts: This led to the eventual discovery that IP = PSPACE ([50, Fortnow Karloff Lund Nisan], [62, Shamir], [7, Babai]). The results in this chapter are related to those in <ref> [8, Babai Fortnow Lund] </ref>. <p> The incremental running time of their test, not counting the time for calls to P , runs in time polynomial in n and is independent of the number of terms in f . Combining the ideas in <ref> [8, Babai Fortnow Lund] </ref> with those in this chapter yields a self-tester for this same task which is much simpler, using only additions, comparisons and calls to P . A simple self-test is not a major issue with respect to the result in [8, Babai Fortnow Lund], where polynomial time is <p> Combining the ideas in <ref> [8, Babai Fortnow Lund] </ref> with those in this chapter yields a self-tester for this same task which is much simpler, using only additions, comparisons and calls to P . A simple self-test is not a major issue with respect to the result in [8, Babai Fortnow Lund], where polynomial time is the major issue, but it is an important issue with respect to designing efficient self-testing/correcting pairs. 3.2 The Basics For expository purposes, we restrict ourselves to the case when f is a function of one input from some universe I. <p> A question that arises naturally is whether a result checker can in general be converted into a 1-adaptive result checker, as opposed to 2-adaptive. Since there is a complete language in EXPTIME that has a result checker <ref> [8, Babai Fortnow Lund] </ref>, there is no general technique that converts any result checker into a 1-adaptive result checker unless EXPTIME=PSPACE. To see this, suppose there is such a general technique and consider the result checker for the complete language in EXPTIME. <p> Since there is a complete problem in EXP T IM E that has a polynomial time checker <ref> [8, Babai Fortnow Lund] </ref>, there is no correlation between the complexity of computing a function and the complexity of result checking the function.
Reference: [9] <author> Beaver, D., Feigenbaum, J., </author> <title> "Hiding Instance in Multioracle Queries", </title> <note> STACS 1990. </note>
Reference-contexts: interactive proofs (see [37, Goldwasser Micali Rackoff], [15, Babai] and [13, Ben-Or Goldwasser Kilian Wigderson] for the discussion of interactive proofs). [53, Nisan] noted that the self-testing/correcting technique based on bootstrapping discussed in Section 3.6 can be combined with the observation about the permanent problem in [48, Lipton] (based on <ref> [9, Beaver Feigenbaum] </ref>) to construct a two-prover interactive proof system for the permanent problem. This led to the eventual discovery that IP = PSPACE ([50, Fortnow Karloff Lund Nisan], [62, Shamir], [7, Babai]). The results in this chapter are related to those in [8, Babai Fortnow Lund]. <p> Proof: Follows the outline of the proof of Lemma 3. 3.3.9 Multivariate Polynomial Function We consider the problem of computing any multivariate polynomial function over a finite field. In [48, Lipton], Lipton has shown a self-corrector for this problem based on the techniques of <ref> [9, Beaver Feigenbaum] </ref> which uses scalar multiplications and some preprocessing. We describe a similar self-corrector suggested by Mike Luby and Steven Omohundro that uses only additions and no preprocessing, and works for fields of prime cardinality. <p> This is similar to the model introduced in [1, Abadi Feigenbaum Kilian] and later extended in <ref> [9, Beaver Feigenbaum] </ref> to allow using several non-communicating programs for the same function, except that here we do not trust the program to return correct answers. In addition, we only allow protocols which are restricted versions of [1, Abadi Feigenbaum Kilian] [9, Beaver Feigenbaum] where the result checker may only ask <p> in [1, Abadi Feigenbaum Kilian] and later extended in <ref> [9, Beaver Feigenbaum] </ref> to allow using several non-communicating programs for the same function, except that here we do not trust the program to return correct answers. In addition, we only allow protocols which are restricted versions of [1, Abadi Feigenbaum Kilian] [9, Beaver Feigenbaum] where the result checker may only ask the program questions of the form "What is the value of f (x)?". We call a program that satisfies the above constraints a private result checker. <p> with O (jxj) oracles that are trusted not to err, however the oracles are not restricted to answer questions of the form "What is the value of f (x)?". [Beaver Feigenbaum Kilian Rogaway] later improved this result to show that it can be done with O (jxj= log jxj) oracles. <ref> [9, Beaver Feigenbaum] </ref> [48, Lipton] show that any function that is a polynomial of degree d over a finite field is d-random-self-reducible.
Reference: [10] <author> Beaver, D., Feigenbaum, J., Kilian, J., Rogaway, P., </author> <title> "Cryptographic Applications of Locally Random Reductions", </title> <institution> AT&T Bell Laboratories Technical Memorandum, </institution> <month> November </month> <year> 1989. </year>
Reference: [11] <author> Beigel, R., Feigenbaum, J., </author> <title> "On the Complexity of Coherent Sets", </title> <institution> AT&T Bell Laboratories Technical Memorandum, </institution> <month> February </month> <year> 1990. </year>
Reference-contexts: Yao [66] has shown that there are functions in DSP ACE (2 n logn ) that do not have polynomial time result checkers. Beigel and Feigenbaum <ref> [11] </ref>, later improved upon this to show that there is a function in DSP ACE (n log fl n ) that has no polynomial time result checker and is not polynomial time random self-reducible.
Reference: [12] <author> Ben-Or, M., Coppersmith, D., Luby, M., Rubinfeld, R., </author> <title> "Convolutions on Groups", </title> <note> in preparation. 99 </note>
Reference-contexts: In all cases, the resulting self-testing program is extremely simple to code, different and efficient. For simplicity, we assume that all groups are abelian; these results can be generalized to non-abelian groups as well <ref> [12, Ben-Or Coppersmith Luby Rubinfeld] </ref>, but our applications 30 are to abelian groups. Let G be a finite group with group operation ffi and with c generators g 1 ; : : : ; g c and identity element 0. <p> If, for all i = 1; ; c, ffi i &lt; 1=2, then ffi 2 =9. The specific proofs we give of Theorems 2 and 3, due largely to Don Coppersmith, are simpler than our original proofs. A full exposition of some related general probability results will appear in <ref> [12, Ben-Or Coppersmith Luby Rubinfeld] </ref>. We now introduce some more notation and prove some intermediate lemmas that are used in the proofs of Theorems 2 and 3.
Reference: [13] <author> Ben-Or, M., Goldwasser, S., Kilian, J., and Wigderson, A., </author> <title> "Multi-Prover Interactive Proofs: How to Remove Intractability", </title> <booktitle> Proc. 20th ACM Symposium on Theory of Computing, </booktitle> <year> 1988, </year> <pages> pp. 113-131. </pages>
Reference-contexts: In [15, Blum] [17, Blum Kannan], the relationship between result checkers and interactive proofs [37, Goldwasser Micali Rackoff] is studied. We discuss the relationship between result checkers and the multi-prover interactive proofs of <ref> [13, Ben-Or Goldwasser Kilian Wigderson] </ref>. Batch Result Checking Though many programmers are willing to spend some time overhead in order to verify that their programs give correct answers, for some applications, where efficiency is crucial, even a constant multiplicative time overhead makes result checking undesirable. <p> A priori, it would seem that the additional power to call the program does not help much, but due to recent advances in complexity theory and new notions of a mathematical proof ([15, Babai],[37, Goldwasser Micali Rackoff], <ref> [13, Ben-Or Goldwasser Kilian Wigderson] </ref>, this often simplifies the checking process, and in some cases (for example the permanent problem) it is the only way that we know how to do polynomial time checking at all. <p> Our self-testing algorithm for the mod function on input R can be used to efficiently either validate or refute this assumption. The techniques in this chapter have been applied to the theory of interactive proofs (see [37, Goldwasser Micali Rackoff], [15, Babai] and <ref> [13, Ben-Or Goldwasser Kilian Wigderson] </ref> for the discussion of interactive proofs). [53, Nisan] noted that the self-testing/correcting technique based on bootstrapping discussed in Section 3.6 can be combined with the observation about the permanent problem in [48, Lipton] (based on [9, Beaver Feigenbaum]) to construct a two-prover interactive proof system for <p> This corresponds to a restriction of the multi-prover interactive proof systems model of <ref> [13, Ben Or Goldwasser Kilian Wigderson] </ref> where k is the number of provers. <p> In <ref> [13, Ben Or Goldwasser Kilian Wigderson] </ref> [33, Fortnow Rompel Sipser], there is a general technique for turning any result checker into a 2-adaptive result checker. This technique can actually be used for many of the result checkers. However, it requires a quadratic blowup in the number of calls made. <p> For example, we give a way of converting one of the result checking techniques in Chapter 3, which makes O (log n) calls to the program, into an adaptive result checker which is of the same efficiency as the original result checker. The techniques of <ref> [13, Ben Or Goldwasser Kilian Wigderson] </ref> [33, Fortnow Rompel Sipser] yield an adaptive result checker that is slower than the original result checker by a multiplicative factor of O (log n). In [13, Ben Or Goldwasser Kilian Wigderson], there is a general technique for turning any k-adaptive result checker into a <p> The techniques of <ref> [13, Ben Or Goldwasser Kilian Wigderson] </ref> [33, Fortnow Rompel Sipser] yield an adaptive result checker that is slower than the original result checker by a multiplicative factor of O (log n). In [13, Ben Or Goldwasser Kilian Wigderson], there is a general technique for turning any k-adaptive result checker into a 2-adaptive result checker. This technique requires an additional O (k) multiplicative factor in the number of calls made. <p> Theorem 17 Any function which is computable by random homomorphisms has efficient and different 2-adaptive and (k; L)-private/adaptive result checkers, for constant k = maxf4; c 1 + 1g, where L (x) = G (G is the underlying group). Proof: [of Theorem 17 (idea)] <ref> [13, Ben-Or Goldwasser Kilian Wigderson] </ref> [33, Fortnow Rompel Sipser] show how to transform any result checker into a 2-adaptive result checker by simply running the original result checking protocol with the first program. <p> The above protocol overcomes this by asking the questions on each machine in a random order. Using the techniques of <ref> [13, Ben Or Goldwasser Kilian Wigderson] </ref>, one can simply transform the bootstrap result checker into a 2-adaptive result checker, with an additional cost of O (log n) multiplicative overhead in the running time over the original result checker. <p> L Without P Total Int. Mult. 4 jxj; jyj n M (n) Poly. Mult. 4 deg (p); deg (q) n M (n) Mod Exp., no 5 jxj; jyj; R n ln n M (n) ln n Matrix Mult. 4 n n M (n) Using the method of <ref> [13, Ben Or Goldwasser Kilian Wigderson] </ref>, one can convert all of the above adaptive result checkers into 2-adaptive result checkers.
Reference: [14] <author> Beame, P., Hastad, J., </author> <title> "Optimal Bounds for Decision Problems on the CRCW PRAM", </title> <booktitle> Proc. 19th ACM Symposium on Theory of Computing, </booktitle> <year> 1987. </year>
Reference-contexts: Output: b = t i where i = 1jn a j . The majority, exactly i and parity functions are all examples of symmetric functions. As mentioned before, <ref> [14, Beame Hastad] </ref> show that (log n= log log n) depth is required to compute these functions. For these and other examples, no table is needed as input because the table can be computed in constant depth by the result checker.
Reference: [15] <author> Blum, M., </author> <title> "Designing programs to check their work", </title> <note> Submitted to CACM. </note>
Reference-contexts: The "independent" program 2 is often a previous version of the same program that is being replaced, or one that is written by different people (who are likely to make the same types of errors) and thus is not independent at all. Program Result Checking Recently, Manuel Blum in <ref> [15, Blum] </ref> has proposed a promising new framework, Program Result Checking, for allowing progammers to build result checkers into their programs. <p> We define a program result checker more formally in Chapter 2. The first program result checkers for a number of important problems are given in <ref> [15, Blum] </ref>, [17, Blum Kannan], [23, Blum Raghavan] [39, Kannan]. Program Result Checking has been successfully applied to a wide range of problems, including sorting, matrix rank, linear programming, graph isomorphism, matrix multiplication, greatest common divisor [2, Adleman Huang Kompella], [15, Blum], [17, Blum Kannan], [18, Blum Kan-nan Rubinfeld], [20, Blum <p> checkers for a number of important problems are given in <ref> [15, Blum] </ref>, [17, Blum Kannan], [23, Blum Raghavan] [39, Kannan]. Program Result Checking has been successfully applied to a wide range of problems, including sorting, matrix rank, linear programming, graph isomorphism, matrix multiplication, greatest common divisor [2, Adleman Huang Kompella], [15, Blum], [17, Blum Kannan], [18, Blum Kan-nan Rubinfeld], [20, Blum Luby Rubinfeld 2], [23, Blum Raghavan], [34, Freivalds],[39, Kannan]. The question remains of how to verify that the result checker program meets its specifications. Although there is no final answer to this question, there are some partial answers. <p> Rather than trading the assumption that the program is correct for the assumption that the result checker is correct, <ref> [15, Blum] </ref> suggests that the result checker should be in some quantifiable way "different" than any program that correctly computes the function directly, because then it is unlikely that the result checker makes mistakes of the same type as those made by the program: specifically, [15, Blum] suggests the requirement that <p> the result checker is correct, <ref> [15, Blum] </ref> suggests that the result checker should be in some quantifiable way "different" than any program that correctly computes the function directly, because then it is unlikely that the result checker makes mistakes of the same type as those made by the program: specifically, [15, Blum] suggests the requirement that the running time of the result checker (not including the running time of the program on any of the calls that the result checker makes to it) be strictly faster than the fastest program for computing the function. <p> In this case, the result checker can even be used to find faults in the program due to hardware errors that develop over time. An advantage of the approach of <ref> [15, Blum] </ref> is illustrated by the following example. 4 Suppose we have a correct program which we want to run as fast as possible. We have two kinds of hardware, non-faulty hardware and faster but possibly faulty hardware. <p> It is reasonable therefore to use programs in these packages to help test and correct each other. In Chapter 5, we extend the theory proposed in <ref> [15, Blum] </ref> to allow the use of several programs, or a library, to aid in result checking, testing and correcting. We show that this allows one to construct result checkers and self-testing/correcting pairs for functions which did not previously have efficient result checkers, self-testing programs or self-correcting programs. <p> We find result checkers for many basic problems in parallel computation and show that for many problems, checking the parallel program's answer does not increase the parallel computation time and total work done by much. Adaptive Checking and Interactive Proofs In the theory of program result checking introduced in <ref> [15, Blum] </ref>, the program is always assumed to be a fixed program, whose output on any particular input is always the same. This is not always the case, as there are programs whose behavior changes as they run, even though the functions that they supposedly compute remain fixed. <p> We show how to replace this assumption by the assumption that there are two copies of the program which do not affect each other in Chapter 7. In <ref> [15, Blum] </ref> [17, Blum Kannan], the relationship between result checkers and interactive proofs [37, Goldwasser Micali Rackoff] is studied. We discuss the relationship between result checkers and the multi-prover interactive proofs of [13, Ben-Or Goldwasser Kilian Wigderson]. <p> greater efficiency, and we give examples of functions for which batch result checking allows one to reduce the overhead of the result checking process to the point where it is arbitrarily small. 8 Chapter 2 Program Result Checking In this chapter, we describe the program result checking model proposed in <ref> [15, Blum] </ref>. We discuss several aspects of the model, and then we give examples of program result checkers. 2.1 The Model Definition 2.1.1 (probabilistic oracle program and running time) A probabilistic program M is an oracle program if it makes calls to another program that is specified at run time. <p> Two reasons why allowing the result checker to call the program reduces the complexity of (sequential) checking are: Many decision problems are self-reducible, and a correct program can aid in solving the search problem, giving a proof of correctness. Secondly, it is noted in <ref> [15, Blum] </ref> [17, Blum Kannan], that the result checker can be thought of as a restricted version of an interactive proof as defined 10 in [37, Goldwasser Micali Rackoff]. <p> These notions are based on limiting some resource of the result checker to enforce it to do something quantifiably different than the program. Thus far, most of the result checkers found which satisfy these quantifiable notions seem to be simpler than any program for the function as well. <ref> [15, Blum] </ref> introduces 11 a notion of quantifiably different based on the running time requirements of the result checker versus that of the fastest correct program for f . <p> However, for many interesting problems there is no known non-trivial lower bound on the running time of a correct program. Thus, as in <ref> [15, Blum] </ref>, we adopt this more pragmatic definition of quantifiably different. 2 In this paper, ln ff denote the natural log of ff. <p> be efficient, but failing that, we would like the result checker to be as efficient as possible. 2.2 Examples Many result checkers have been found for various types of problems such as graph iso-morphism, matrix rank, quadratic residuocity, linear programming, maximum matching, greatest common divisor, permanent and even PSPACE-complete problems <ref> [15, Blum] </ref>, [23, Blum Raghavan], [17, Blum Kannan], [18, Blum Kannan Rubinfeld], [2, Adleman Huang Kompella] [50, Fortnow Karloff Lund Nisan] [62, Shamir]. <p> The first task is quite easy, but the second task is nontrivial, and on the algebraic decision tree model, is as difficult a task as sorting. In <ref> [15, Blum] </ref>, [17, Blum Kannan] there are randomized algorithms for verifying that X = Y which use hashing and run in O (n) time. We present a deterministic algorithm which checks sorting in O (n) time. <p> Our self-testing algorithm for the mod function on input R can be used to efficiently either validate or refute this assumption. The techniques in this chapter have been applied to the theory of interactive proofs (see [37, Goldwasser Micali Rackoff], <ref> [15, Babai] </ref> and [13, Ben-Or Goldwasser Kilian Wigderson] for the discussion of interactive proofs). [53, Nisan] noted that the self-testing/correcting technique based on bootstrapping discussed in Section 3.6 can be combined with the observation about the permanent problem in [48, Lipton] (based on [9, Beaver Feigenbaum]) to construct a two-prover interactive <p> It is reasonable therefore to use programs in these packages to help test and correct each other. We extend the theory proposed in <ref> [15, Blum] </ref> to allow the use of several programs, or a library, to aid in testing and correcting. We show that this allows one to construct self-testing/correcting pairs for functions which did not previously have efficient self-testing or self-correcting programs, or even result checkers. <p> In fact, some of the major ideas used in checking sequential programs do not seem to be as applicable in checking parallel programs. For example, one of the ideas proposed in <ref> [15, Blum] </ref> for the sequential checking of decision problems is the idea of reducing a search problem to a decision problem. This gives a simple proof of the correctness of a `yes' instance. <p> Proposition 39 Let 1 ; 2 be two AC 0 equivalent computational problems. Then from any fast program result checker C 1 for 1 , is is possible to construct a fast program result checker C 2 for 2 . Proof: Similar to Beigel's trick described in <ref> [15, Blum] </ref>. We outline the proof for decision problems, but the general proof is similar. The idea is to construct a program result checker for 2 by transforming it to an instance of 1 and result checking that instance. <p> Moreover, a problem is presented for which programs can be written that run in small depth, but for which result checking the result is P-complete. 85 Chapter 7 Adaptive Programs and Cryptographic Settings In the theory of program result checking introduced in <ref> [15, Blum] </ref>, P is always assumed to be a fixed program, whose output on input x is a static function P (x). This is not always the case, as there are programs whose behavior changes as they run, even though the functions that they supposedly compute remain fixed. <p> Some initial results about result checking/self-testing/correcting with respect to cryptographic multi-party protocols are given in [51, Micali Rubinfeld]. 1 If one shows a polynomial time result checker for any NP -complete problem, a polynomial time result checker for any other NP -complete problem can be constructed using Beigel's theorem <ref> [15, Blum] </ref>. 98
Reference: [16] <author> Blum, M., Evans, W., Gemmell, P., Kannan, S., Naor, M., </author> <title> "Checking the Correctness of Data Storage and Retrieval Algorithms" (tentative title), </title> <note> in preparation. </note>
Reference-contexts: We mention some areas that deserve special attention: One new area is that of data-structure checking as introduced in <ref> [16, Blum Evans Gemmell Kannan Naor] </ref>. They study result checkers for database problems, and for programs that manipulate simple data structures such as stacks. A second important area is that of problems dealing with real numbers.
Reference: [17] <author> Blum, M., Kannan, S., </author> <title> "Program correctness checking ... and the design of programs that check their work", </title> <booktitle> Proc. 21st ACM Symposium on Theory of Computing, </booktitle> <year> 1989. </year>
Reference-contexts: We define a program result checker more formally in Chapter 2. The first program result checkers for a number of important problems are given in [15, Blum], <ref> [17, Blum Kannan] </ref>, [23, Blum Raghavan] [39, Kannan]. Program Result Checking has been successfully applied to a wide range of problems, including sorting, matrix rank, linear programming, graph isomorphism, matrix multiplication, greatest common divisor [2, Adleman Huang Kompella], [15, Blum], [17, Blum Kannan], [18, Blum Kan-nan Rubinfeld], [20, Blum Luby Rubinfeld <p> a number of important problems are given in [15, Blum], <ref> [17, Blum Kannan] </ref>, [23, Blum Raghavan] [39, Kannan]. Program Result Checking has been successfully applied to a wide range of problems, including sorting, matrix rank, linear programming, graph isomorphism, matrix multiplication, greatest common divisor [2, Adleman Huang Kompella], [15, Blum], [17, Blum Kannan], [18, Blum Kan-nan Rubinfeld], [20, Blum Luby Rubinfeld 2], [23, Blum Raghavan], [34, Freivalds],[39, Kannan]. The question remains of how to verify that the result checker program meets its specifications. Although there is no final answer to this question, there are some partial answers. <p> We show how to replace this assumption by the assumption that there are two copies of the program which do not affect each other in Chapter 7. In [15, Blum] <ref> [17, Blum Kannan] </ref>, the relationship between result checkers and interactive proofs [37, Goldwasser Micali Rackoff] is studied. We discuss the relationship between result checkers and the multi-prover interactive proofs of [13, Ben-Or Goldwasser Kilian Wigderson]. <p> However, there are at least two known examples of result checkers where the weaker condition is needed. These are the matrix rank checker in <ref> [17, Blum Kannan] </ref>,[39, Kannan], and the quadratic residuocity checker in [45, Kompella]. * We do not assume that the programs being checked are deterministic, we only require that their specifications require them to always be correct, i.e. often a probabilistic program may err with small probability and still be a correct <p> Two reasons why allowing the result checker to call the program reduces the complexity of (sequential) checking are: Many decision problems are self-reducible, and a correct program can aid in solving the search problem, giving a proof of correctness. Secondly, it is noted in [15, Blum] <ref> [17, Blum Kannan] </ref>, that the result checker can be thought of as a restricted version of an interactive proof as defined 10 in [37, Goldwasser Micali Rackoff]. <p> we would like the result checker to be as efficient as possible. 2.2 Examples Many result checkers have been found for various types of problems such as graph iso-morphism, matrix rank, quadratic residuocity, linear programming, maximum matching, greatest common divisor, permanent and even PSPACE-complete problems [15, Blum], [23, Blum Raghavan], <ref> [17, Blum Kannan] </ref>, [18, Blum Kannan Rubinfeld], [2, Adleman Huang Kompella] [50, Fortnow Karloff Lund Nisan] [62, Shamir]. <p> The first task is quite easy, but the second task is nontrivial, and on the algebraic decision tree model, is as difficult a task as sorting. In [15, Blum], <ref> [17, Blum Kannan] </ref> there are randomized algorithms for verifying that X = Y which use hashing and run in O (n) time. We present a deterministic algorithm which checks sorting in O (n) time. <p> Many result checkers that have been found are also adaptive result checkers. For example, it can easily be seen that the GCD checker in [2, Adleman Huang Kompella] and that all of the result checkers given in <ref> [17, Blum Kannan] </ref> are adaptive. Other result checkers do not work for an adaptive program. Examples of such result checkers are the ones in Chapter 3, [20, Blum Luby Rubinfeld 2], where adaptive programs can easily fool the result checkers.
Reference: [18] <author> Blum, M., Kannan, S., Rubinfeld, R., </author> <title> "A catalogue of checkable problems", </title> <note> in preparation. </note>
Reference-contexts: Program Result Checking has been successfully applied to a wide range of problems, including sorting, matrix rank, linear programming, graph isomorphism, matrix multiplication, greatest common divisor [2, Adleman Huang Kompella], [15, Blum], [17, Blum Kannan], <ref> [18, Blum Kan-nan Rubinfeld] </ref>, [20, Blum Luby Rubinfeld 2], [23, Blum Raghavan], [34, Freivalds],[39, Kannan]. The question remains of how to verify that the result checker program meets its specifications. Although there is no final answer to this question, there are some partial answers. <p> the result checker to be as efficient as possible. 2.2 Examples Many result checkers have been found for various types of problems such as graph iso-morphism, matrix rank, quadratic residuocity, linear programming, maximum matching, greatest common divisor, permanent and even PSPACE-complete problems [15, Blum], [23, Blum Raghavan], [17, Blum Kannan], <ref> [18, Blum Kannan Rubinfeld] </ref>, [2, Adleman Huang Kompella] [50, Fortnow Karloff Lund Nisan] [62, Shamir]. <p> If the program claims that there is no solution or that the solution is unbounded, this can be verified symbolically using the program in <ref> [18, Blum Kannan Rubinfeld] </ref>. This problem is P-complete, so no fast parallel algorithm is known for it. However, it can be result checked in logarithmic time with only two calls to the program.
Reference: [19] <author> Blum, M., Luby, M., Rubinfeld, R., </author> <title> "Program Result Checking Against Adaptive Programs and in Cryptographic Settings", </title> <booktitle> DIMACS Workshop on Distributed Computing and Cryptography, </booktitle> <year> 1989. </year>
Reference-contexts: We call such a program that can modify itself and its subsequent computation an adaptive program. We call a result checker that works for such a program an adaptive result checker. The work in this chapter was done in collaboration with Manuel Blum and Michael Luby <ref> [19, Blum Luby Rubinfeld 1] </ref>. This model is a restriction of the model used in interactive proof systems of [37, Goldwasser Micali Rackoff], in which the role of the verifier is played by the result checker and the role of the prover is played by the program P .
Reference: [20] <author> Blum, M., Luby, M., Rubinfeld, R., </author> <title> "Self-Testing/Correcting with Applications to Numerical Problems," </title> <type> ICSI Technical Report No. </type> <institution> TR-90-041. </institution>
Reference-contexts: Program Result Checking has been successfully applied to a wide range of problems, including sorting, matrix rank, linear programming, graph isomorphism, matrix multiplication, greatest common divisor [2, Adleman Huang Kompella], [15, Blum], [17, Blum Kannan], [18, Blum Kan-nan Rubinfeld], <ref> [20, Blum Luby Rubinfeld 2] </ref>, [23, Blum Raghavan], [34, Freivalds],[39, Kannan]. The question remains of how to verify that the result checker program meets its specifications. Although there is no final answer to this question, there are some partial answers. <p> The work in this chapter was done in collaboration with Mike Luby and Manuel Blum <ref> [20, Blum Luby Rubinfeld 2] </ref>, [21, Blum Luby Rubinfeld 3], with the exception of the results in Section 3.5 which was done in collaboration with Madhu Sudan [56, Rubinfeld Sudan]. Consider any program P whose task is to evaluate a function f . <p> The results in this chapter were done in collaboration with Manuel Blum and Michael Luby <ref> [20, Blum Luby Rubinfeld 2] </ref>, [21, Blum Luby Rubinfeld 3]. 5.1 Definitions We give the following definitions, which generalize the previously given result checking and self-testing/correcting definitions. Definition 5.1.1 (library) Let c be a positive integer. <p> Furthermore, the checker is deterministic, and no other calls to the program are made. In contrast, the best known algorithms for this problem use at least logarithmic parallel time [36, Goldberg Spencer], [5, Alon Babai Itai], [49, Luby]. 77 6.3 Computability by Random Inputs In Chapter 3, <ref> [20, Blum Luby Rubinfeld 2] </ref> we show that one can design result checkers for many functions that have the property of random self-reducibility that the function can be computed by computing the function on one or more "random" instances. <p> However, the techniques in this chapter are applicable to other functions as well. For example, using the technique in Section 6.3.2, the running time of the sequential self-tester for the matrix rank function given in [21, Blum Luby Rubinfeld 3] is dramatically improved in Chapter 5, page 72, <ref> [20, Blum Luby Rubinfeld 2] </ref>. <p> is O (C (n) + N (n)). 6.3.3 Randomly Self-Reducible, Linear and Smaller Self-Reducible Prob lems If the program computes a function which is randomly self-reducible and either has the linearity property or is self-reducible to smaller inputs (see definitions on pages 31,46), the general techniques described in Chapter 3, <ref> [20, Blum Luby Rubinfeld 2] </ref> can be paral lelized. This gives constant depth efficient result checkers for checking numerical problems such as integer multiplication, integer division, mod, modular multiplication, modular exponentiation, polynomial multiplication, squaring and matrix multiplication. <p> Other result checkers do not work for an adaptive program. Examples of such result checkers are the ones in Chapter 3, <ref> [20, Blum Luby Rubinfeld 2] </ref>, where adaptive programs can easily fool the result checkers. At the present time we see no way to convert such a result checker into an adaptive result checker.
Reference: [21] <author> Blum, M., Luby, M., Rubinfeld, R., </author> <title> "Self-Testing/Correcting with Applications to Numerical Problems," </title> <booktitle> Proc. 22th ACM Symposium on Theory of Computing, </booktitle> <year> 1990. </year>
Reference-contexts: The work in this chapter was done in collaboration with Mike Luby and Manuel Blum [20, Blum Luby Rubinfeld 2], <ref> [21, Blum Luby Rubinfeld 3] </ref>, with the exception of the results in Section 3.5 which was done in collaboration with Madhu Sudan [56, Rubinfeld Sudan]. Consider any program P whose task is to evaluate a function f . <p> The results in this chapter were done in collaboration with Manuel Blum and Michael Luby [20, Blum Luby Rubinfeld 2], <ref> [21, Blum Luby Rubinfeld 3] </ref>. 5.1 Definitions We give the following definitions, which generalize the previously given result checking and self-testing/correcting definitions. Definition 5.1.1 (library) Let c be a positive integer. <p> However, the techniques in this chapter are applicable to other functions as well. For example, using the technique in Section 6.3.2, the running time of the sequential self-tester for the matrix rank function given in <ref> [21, Blum Luby Rubinfeld 3] </ref> is dramatically improved in Chapter 5, page 72, [20, Blum Luby Rubinfeld 2].
Reference: [22] <author> Blum, M., and Micali, S., </author> <title> "How to Generate Cryptographically Strong Sequences of Pseudo-Random Bits", </title> <journal> SIAM J. on Computing, </journal> <volume> Vol. 13, </volume> <year> 1984, </year> <pages> pp. 850-864. </pages>
Reference-contexts: Since it is computationally much easier to determine whether a property is satisfied most of the time than it is to determine whether it is always satisfied, this relaxation is important for self-testing. 3.1 Related Work <ref> [22, Blum Micali] </ref> construct a pseudo-random generator, where a crucial ingredient of the construction can be thought of as a self-correcting program for the discrete log function. [57, Rubinfeld] introduces checking for parallel programs, and uses self-testing to design a constant depth circuit to check the majority function (see section 6.3.1).
Reference: [23] <author> Blum, M., and Raghavan, P., </author> <title> "Program Correctness: Can One Test for It?", </title> <institution> IBM T.J. Watson Research Center Technical Report (1988). </institution>
Reference-contexts: We define a program result checker more formally in Chapter 2. The first program result checkers for a number of important problems are given in [15, Blum], [17, Blum Kannan], <ref> [23, Blum Raghavan] </ref> [39, Kannan]. <p> Kannan], <ref> [23, Blum Raghavan] </ref> [39, Kannan]. Program Result Checking has been successfully applied to a wide range of problems, including sorting, matrix rank, linear programming, graph isomorphism, matrix multiplication, greatest common divisor [2, Adleman Huang Kompella], [15, Blum], [17, Blum Kannan], [18, Blum Kan-nan Rubinfeld], [20, Blum Luby Rubinfeld 2], [23, Blum Raghavan], [34, Freivalds],[39, Kannan]. The question remains of how to verify that the result checker program meets its specifications. Although there is no final answer to this question, there are some partial answers. <p> but failing that, we would like the result checker to be as efficient as possible. 2.2 Examples Many result checkers have been found for various types of problems such as graph iso-morphism, matrix rank, quadratic residuocity, linear programming, maximum matching, greatest common divisor, permanent and even PSPACE-complete problems [15, Blum], <ref> [23, Blum Raghavan] </ref>, [17, Blum Kannan], [18, Blum Kannan Rubinfeld], [2, Adleman Huang Kompella] [50, Fortnow Karloff Lund Nisan] [62, Shamir].
Reference: [24] <author> Chandra, A., Fortune, S., Lipton, R., </author> <title> "Unbounded Fan-in Circuits and Associative Functions", </title> <booktitle> Proc. 15th ACM Symposium on Theory of Computing, </booktitle> <year> 1983. </year>
Reference-contexts: The incremental time is O (1), and the incremental number of processors is n fi A (n), where A (n) is the number of processors required to do addition in constant depth. In <ref> [24, Chandra Fortune Lipton] </ref>, it is shown that A (n) is O (ng 1 (n)) for any strictly increasing primitive recursive function g. The total time is O (D (n)) with O (n fi A (n) + n fi N (n)) total processors.
Reference: [25] <author> Cleve, R., Luby, </author> <title> M.,"A Note on Self-Testing/Correcting Methods for Trigonometric Functions", </title> <institution> International Computer Science Institute Technical Report TR-90-032, </institution> <month> July, </month> <year> 1990. </year>
Reference-contexts: We develop general techniques for constructing simple to program self-testing/correcting pairs for a variety of numerical functions. We show how our techniques apply to integer multiplication, the mod function, modular multiplication, integer division, polynomial multiplication, modular exponentiation, matrix multiplication and the evaluation of any fixed polynomial. Recently, <ref> [25, Cleve Luby] </ref> have shown how to apply these techniques to get self-testing/correcting pairs for the sine and cosine functions. It is not known how to solve any of these problems in linear time.
Reference: [26] <author> Coppersmith, D., Winograd, S., </author> <title> "Matrix Multiplication via Arithmetic Progressions", </title> <booktitle> Proc. 19th ACM Symposium on Theory of Computing, </booktitle> <year> 1987. </year>
Reference-contexts: For example, the integer multiplication checker presented here seems much simpler than multiplication programs based on Fast Fourier transforms, and the matrix multiplication checker seems much simpler than matrix multiplication programs based on the methods in [63, Strassen], <ref> [26, Coppersmith Winograd] </ref>. Blum suggests that we force the checker to be quantifiably different than any program for f .
Reference: [27] <author> De Millo, R.A., Lipton, R.J., Perlis, A.J., </author> <title> "Social Processes and Proofs of Theorems and Programs," </title> <journal> Communications of the ACM, May 1979, </journal> <volume> Vol. 22, No. 5, </volume> <pages> pp. 271-280. 100 </pages>
Reference-contexts: Since verification is too tedious of a task to do by hand, efforts have been aimed at automating or semi-automating the process. Such efforts have met with limited success. Additional complexity is introduced when programming on parallel processors and distributed computing environments. These are among the reasons that <ref> [27, De Millo Lipton Perlis] </ref> use to argue that program verification should not be the only way of approaching the problem of software reliability.
Reference: [28] <author> Feigenbaum, J., Kannan, S., Nisan, N., </author> <title> "Lower Bounds on Random Self-Reducibili--ty", </title> <booktitle> Proc. 5th Structure in Complexity Theory Conference, </booktitle> <year> 1990. </year>
Reference-contexts: This motivates the study of which functions are random self-reducible. The definition of random self-reducibility given in Chapter 3 differs from the standard definition (see for example <ref> [28, Feigenbaum Kannan Nisan] </ref>) in that it requires the reduction to be faster than any program for the original function, whereas the latter only requires that the reduction be in polynomial time. <p> For the purposes of this discussion, we refer to the latter notion of random self-reducibility as polynomial time random self-reducibility. <ref> [28, Feigenbaum Kannan Nisan] </ref> have shown that random boolean functions are not polynomial time random self-reducible, and that if a function is polynomial time 2-random self-reducible (for definition see [28]), then the function can be computed nonuniformly in nondeterministic polynomial time. <p> For the purposes of this discussion, we refer to the latter notion of random self-reducibility as polynomial time random self-reducibility. [28, Feigenbaum Kannan Nisan] have shown that random boolean functions are not polynomial time random self-reducible, and that if a function is polynomial time 2-random self-reducible (for definition see <ref> [28] </ref>), then the function can be computed nonuniformly in nondeterministic polynomial time. No such results are known for random self-reducibility, because for random self-reducibility the only requirement is that the computation of the random self-reduction be faster than the computation of the function itself.
Reference: [29] <author> Feldman, P., </author> <title> "The Optimum Prover Lies in PSPACE", </title> <type> manuscript, </type> <year> 1986. </year>
Reference-contexts: To see this, suppose there is such a general technique and consider the result checker for the complete language in EXPTIME. Now, because we can supposedly convert this result checker into a 1-adaptive result checker, there is an interactive proof for the language. Then by the result of <ref> [29, Feldman] </ref> the language must be in PSPACE. Since there is probably no general technique for converting a result checker into a 1-adaptive result checker, it would be interesting to charactize which problems do have adaptive result checkers.
Reference: [30] <author> Fiat, A., Naor, M., </author> <type> Personal communication through Moni Naor. </type>
Reference-contexts: The technique is based on the idea of Freivalds [34, Freivalds] used in the result checker for matrix multiplication (see Section 2.2.2, page 14). Freivalds' idea was also used in a similar setting by <ref> [30, Fiat Naor] </ref> where many modular exponentiation computations are verified by doing very few modular exponentiation computations.
Reference: [31] <author> Fich, F., </author> <title> "New bounds for parallel prefix circuits", </title> <booktitle> Proc. 15th ACM Symposium on Theory of Computing, </booktitle> <year> 1983, </year> <month> pp.27-36. </month>
Reference: [32] <author> Fortnow, L., </author> <title> "Complexity-Theoretic Aspects of Interactive Proof Systems", </title> <type> Tech Report MIT/LCS/TR-447, </type> <month> May </month> <year> 1989. </year>
Reference: [33] <author> Fortnow, L., Rompel, J., Sipser, M., </author> <title> "On the Power of Multi-Prover Interactive Protocols", </title> <booktitle> Proc. 3 rd Structure in Complexity Theory Conference, </booktitle> <year> 1988, </year> <pages> pp. 156-161. </pages>
Reference-contexts: In [13, Ben Or Goldwasser Kilian Wigderson] <ref> [33, Fortnow Rompel Sipser] </ref>, there is a general technique for turning any result checker into a 2-adaptive result checker. This technique can actually be used for many of the result checkers. However, it requires a quadratic blowup in the number of calls made. <p> The techniques of [13, Ben Or Goldwasser Kilian Wigderson] <ref> [33, Fortnow Rompel Sipser] </ref> yield an adaptive result checker that is slower than the original result checker by a multiplicative factor of O (log n). In [13, Ben Or Goldwasser Kilian Wigderson], there is a general technique for turning any k-adaptive result checker into a 2-adaptive result checker. <p> Theorem 17 Any function which is computable by random homomorphisms has efficient and different 2-adaptive and (k; L)-private/adaptive result checkers, for constant k = maxf4; c 1 + 1g, where L (x) = G (G is the underlying group). Proof: [of Theorem 17 (idea)] [13, Ben-Or Goldwasser Kilian Wigderson] <ref> [33, Fortnow Rompel Sipser] </ref> show how to transform any result checker into a 2-adaptive result checker by simply running the original result checking protocol with the first program. <p> However, the stated privacy constraints will no longer be satisfied. 7.3 Open Questions By the results of <ref> [33, Fortnow Rompel Sipser] </ref>, any checker can be converted into a 2-adaptive result checker. A question that arises naturally is whether a result checker can in general be converted into a 1-adaptive result checker, as opposed to 2-adaptive. <p> Another interesting question is under what conditions on L it is true that a (1; L)- private result checker is always a 1-adaptive result checker? <ref> [33, Fortnow Rompel Sipser] </ref> have shown a technique by which any result checker can be made into a 2-adaptive result checker.
Reference: [34] <author> Freivalds, R., </author> <title> "Fast Probabilistic Algorithms", </title> <publisher> Springer Verlag Lecture Notes in CS No. </publisher> <pages> 74, </pages> <note> Mathematical Foundations of CS, </note> <month> 57-69 </month> <year> (1979). </year>
Reference-contexts: Program Result Checking has been successfully applied to a wide range of problems, including sorting, matrix rank, linear programming, graph isomorphism, matrix multiplication, greatest common divisor [2, Adleman Huang Kompella], [15, Blum], [17, Blum Kannan], [18, Blum Kan-nan Rubinfeld], [20, Blum Luby Rubinfeld 2], [23, Blum Raghavan], <ref> [34, Freivalds] </ref>,[39, Kannan]. The question remains of how to verify that the result checker program meets its specifications. Although there is no final answer to this question, there are some partial answers. <p> We give two examples of result checkers: we show a result checker for integer sorting, and the result checker for matrix multiplication from <ref> [34, Freivalds] </ref>. 2.2.1 Sorting Consider the problem of sorting integers with the following specifications: Input: A set of integers X = fx 1 ; x 2 ; :::; x n g (not necessarily distinct). <p> If any verification fails, output "FAIL", else output "PASS". 2.2.2 Matrix Multiplication Input: Integer n; n fi n matrices A; B; fi Output: C = A B The result checker presented here is due to Freivalds <ref> [34, Freivalds] </ref>. Specifications: On input A; B; C; fi, if C 6= A B then output "FAIL" with probability at least 1 fi. If C = A B then output "PASS". The running time is O (n 2 dlog (1=fi)e). <p> Previous to our work, [38, Kaminski] gives program result checkers for integer and polynomial multiplication. Independently of our work, [2, Adleman Huang Kompella] give program result checkers for integer multiplication and modular exponentiation. Both of these papers use very different techniques than ours. Previous to our work, <ref> [34, Freivalds] </ref> introduces a program result checker for matrix multiplication over a finite field. [48, Lipton], independently of our work, discusses the concept of self-correcting pro grams and gives self-correctors for several functions. To highlight the importance of being 17 able to self-test, consider the mod function. <p> Independently of our work, [2, Adleman Huang Kompella] describe a result checker for multiplication in the same spirit but different than [38, Kaminski] which also makes no calls to the program. Also previous to our work, <ref> [34, Freivalds] </ref> introduced a result checker for matrix multiplication which does not call the 89 program. 7.2 Private/Adaptive Checker We first show how to construct a different and efficient result checker that is both adaptive and private for any function that has the linearity property. <p> We present the specific batch result checker that results from applying the technique to the mod R function. The technique is based on the idea of Freivalds <ref> [34, Freivalds] </ref> used in the result checker for matrix multiplication (see Section 2.2.2, page 14). Freivalds' idea was also used in a similar setting by [30, Fiat Naor] where many modular exponentiation computations are verified by doing very few modular exponentiation computations.
Reference: [35] <author> Furst, M., Saxe, J., Sipser, M., </author> <title> "Parity, Circuits and the Polynomial Time Hierarchy", </title> <journal> Math. Systems Theory, </journal> <volume> vol. 17, </volume> <year> 1984, </year> <month> pp.13-28. </month>
Reference: [36] <author> Goldberg, M., Spencer, T., </author> <title> "A New Parallel Algorithm for the Maximal Independent Set Problem," </title> <booktitle> Proceedings of the 28th Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1987. </year>
Reference-contexts: Furthermore, the checker is deterministic, and no other calls to the program are made. In contrast, the best known algorithms for this problem use at least logarithmic parallel time <ref> [36, Goldberg Spencer] </ref>, [5, Alon Babai Itai], [49, Luby]. 77 6.3 Computability by Random Inputs In Chapter 3, [20, Blum Luby Rubinfeld 2] we show that one can design result checkers for many functions that have the property of random self-reducibility that the function can be computed by computing the function
Reference: [37] <author> Goldwasser, S., Micali, S., Rackoff, C., </author> <title> The Knowledge Complexity of Interactive Proof Systems", </title> <journal> SIAM J. Comput., </journal> <volume> 18(1),1989, </volume> <pages> pp. 186-208. </pages>
Reference-contexts: We show how to replace this assumption by the assumption that there are two copies of the program which do not affect each other in Chapter 7. In [15, Blum] [17, Blum Kannan], the relationship between result checkers and interactive proofs <ref> [37, Goldwasser Micali Rackoff] </ref> is studied. We discuss the relationship between result checkers and the multi-prover interactive proofs of [13, Ben-Or Goldwasser Kilian Wigderson]. <p> Secondly, it is noted in [15, Blum] [17, Blum Kannan], that the result checker can be thought of as a restricted version of an interactive proof as defined 10 in <ref> [37, Goldwasser Micali Rackoff] </ref>. Intuitively, the program is proving to the user that the program has computed the result correctly. 2.1.1 Correctness of Result Checker The problem remains of determining the correctness of the result checker. <p> This requires a different assumption for each distinct modulus R. Our self-testing algorithm for the mod function on input R can be used to efficiently either validate or refute this assumption. The techniques in this chapter have been applied to the theory of interactive proofs (see <ref> [37, Goldwasser Micali Rackoff] </ref>, [15, Babai] and [13, Ben-Or Goldwasser Kilian Wigderson] for the discussion of interactive proofs). [53, Nisan] noted that the self-testing/correcting technique based on bootstrapping discussed in Section 3.6 can be combined with the observation about the permanent problem in [48, Lipton] (based on [9, Beaver Feigenbaum]) to <p> We call a result checker that works for such a program an adaptive result checker. The work in this chapter was done in collaboration with Manuel Blum and Michael Luby [19, Blum Luby Rubinfeld 1]. This model is a restriction of the model used in interactive proof systems of <ref> [37, Goldwasser Micali Rackoff] </ref>, in which the role of the verifier is played by the result checker and the role of the prover is played by the program P . The restriction is that the verifier may only ask questions of the form "What is the value of f (x)?".
Reference: [38] <author> Kaminski, Michael, </author> <title> "A note on probabilistically verifying integer and polynomial products," </title> <journal> JACM, </journal> <volume> Vol. 36, No. 1, </volume> <month> January </month> <year> 1989, </year> <month> pp.142-149. </month>
Reference-contexts: We will also see that a program result checker for f implies a self-tester for f , but it is not known whether a program result checker also implies a self-corrector. Previous to our work, <ref> [38, Kaminski] </ref> gives program result checkers for integer and polynomial multiplication. Independently of our work, [2, Adleman Huang Kompella] give program result checkers for integer multiplication and modular exponentiation. Both of these papers use very different techniques than ours. <p> In [13, Ben Or Goldwasser Kilian Wigderson], there is a general technique for turning any k-adaptive result checker into a 2-adaptive result checker. This technique requires an additional O (k) multiplicative factor in the number of calls made. Previous to our work, <ref> [38, Kaminski] </ref> introduced a result checker for integer and polynomial multiplication based on computing the result of the program mod small special numbers. This result checker trivially works for an adaptive program as well, because it makes no extra calls to the program. <p> This result checker trivially works for an adaptive program as well, because it makes no extra calls to the program. Independently of our work, [2, Adleman Huang Kompella] describe a result checker for multiplication in the same spirit but different than <ref> [38, Kaminski] </ref> which also makes no calls to the program.
Reference: [39] <author> Kannan, S., </author> <title> "Program Result Checking with Applications", </title> <type> Ph.D. thesis, </type> <institution> U.C. Berke-ley, </institution> <year> 1990. </year>
Reference-contexts: We define a program result checker more formally in Chapter 2. The first program result checkers for a number of important problems are given in [15, Blum], [17, Blum Kannan], [23, Blum Raghavan] <ref> [39, Kannan] </ref>. <p> See <ref> [39, Kannan] </ref> for a discussion of checking probabilistic programs. * The model of computation typically used in this work will be a RAM bit cost model of computation as defined in [3, Aho Hopcroft Ullman]. <p> With such a library, the self-testing/correcting for all functions can be done with only a small number of additions, subtractions, comparisons and generation of random numbers. Previously, <ref> [39, Kannan] </ref> provides elegant program result checkers for the problems of computing the determinant and rank of a matrix, but they are not efficient. <p> For example, the deterministic result checker algorithm for sorting presented in Chapter 2 can be easily implemented in constant depth with O (n) processors. A sequential result checker for a program that finds the rank of a matrix (over a finite field) is described in <ref> [39, Kannan] </ref>. This result checker uses the ideas of interactive proofs to check that the program is correct by making sure that it is consistent with itself. By slightly changing it, the sequential result checker can be parallelized to run in O (log n) depth. <p> Since 1 and 2 are AC 0 equivalent, the fastest parallel program for each is related by a constant factor. Therefore, if 1 is a fast program result checker, so is 2 . More recently, in <ref> [39, Kannan] </ref> Section 2.3, Beigel's theorem was generalized to problems in the same robust complexity classes, and used to show that if two problems are equivalent under N C reductions, and if one has a result checker, then so does the other. <p> We have already shown two P-complete problems that are checkable in small depth: linear programming and straight line programming. In <ref> [39, Kannan] </ref> it is observed that since P-complete problems are all N C-reducible to each other, all P-complete problems are checkable in polylogarithmic depth.
Reference: [40] <author> Karloff, H., </author> <title> "A Las Vegas RNC Algorithm for Maximum Matching," </title> <journal> Combinatorica, </journal> <volume> vol. 6, </volume> <year> 1986, </year> <month> pp.387-392. </month>
Reference-contexts: Result Checking Algorithm:(sketch) The result checker first checks in parallel that no vertex is matched more than once and that the maximum matching is of size k. Then the algorithm in <ref> [40, Karloff] </ref> is used to find a proof that there is no matching of size k. This proof will be an odd set cover of size k. Karloff's algorithm requires computing a maximal independent set. This computation can be checked using the result checker described earlier.
Reference: [41] <author> Karp, R., Luby, M., Madras, N., </author> <title> "Monte-Carlo Approximation Algorithms for Enumeration Problems," </title> <journal> J. of Algorithms, </journal> <volume> Vol. 10, No. 3, </volume> <month> Sept. </month> <year> 1989, </year> <pages> pp. 429-448. </pages>
Reference-contexts: This proposition can be proved using standard techniques from an inequality due to Bernstein cited in [55, Renyi]. For a proof of this proposition, see for example <ref> [41, Karp Luby Madras] </ref>. 35 Proposition 17 Let Y 1 ; Y 2 ; : : : be independent identically distributed 0/1-valued random variables with mean . Let 2.
Reference: [42] <author> Karp, R., Ramachandran, V., </author> <title> "A Survey of Parallel Algorithms for Shared-Memory Machines", </title> <type> UC Berkeley Technical Report No. </type> <note> UCB/CSD 88/408. </note>
Reference: [43] <author> Karp, R., Upfal, E., Wigderson, </author> <title> A.,"Constructing a perfect matching is in random NC", </title> <journal> Combinatorica, </journal> <volume> vol. 6, </volume> <year> 1986, </year> <note> pp.35-48. 101 </note>
Reference: [44] <author> Karp, R., Upfal, E., Wigderson, </author> <title> A.,"The Complexity of Parallel Search", </title> <institution> J. Comp. Syst. Sci., </institution> <year> 1988. </year>
Reference-contexts: This gives a simple proof of the correctness of a `yes' instance. Results in [52, Mulmuley Vazirani Vazirani] show that there are techniques for reducing a search problem to a decision problem for weighted search problems. However results in <ref> [44, Karp Upfal Wigderson 2] </ref> about the difficulty of reducing search to decision in NC indicate that in general this idea could be difficult to utilize in parallel.
Reference: [45] <author> Kompella, K., </author> <title> "Efficient Checkers for Cryptography", </title> <type> manuscript. </type>
Reference-contexts: However, there are at least two known examples of result checkers where the weaker condition is needed. These are the matrix rank checker in [17, Blum Kannan],[39, Kannan], and the quadratic residuocity checker in <ref> [45, Kompella] </ref>. * We do not assume that the programs being checked are deterministic, we only require that their specifications require them to always be correct, i.e. often a probabilistic program may err with small probability and still be a correct program.
Reference: [46] <author> Kompella, K., Adleman, </author> <title> L.,"Checkers for RSA", </title> <type> manuscript. </type>
Reference: [47] <author> Ladner, R., Fischer, </author> <title> M.,"Parallel Prefix Computation", </title> <journal> JACM, </journal> <volume> vol. 27, </volume> <year> 1980, </year> <month> pp.831-838. </month>
Reference: [48] <author> Lipton, R., </author> <title> "New directions in testing", </title> <type> manuscript. </type>
Reference-contexts: Independently of our work, [2, Adleman Huang Kompella] give program result checkers for integer multiplication and modular exponentiation. Both of these papers use very different techniques than ours. Previous to our work, [34, Freivalds] introduces a program result checker for matrix multiplication over a finite field. <ref> [48, Lipton] </ref>, independently of our work, discusses the concept of self-correcting pro grams and gives self-correctors for several functions. To highlight the importance of being 17 able to self-test, consider the mod function. To self-correct on input x and modulus R, the assumption in [48, Lipton] and here is that the <p> matrix multiplication over a finite field. <ref> [48, Lipton] </ref>, independently of our work, discusses the concept of self-correcting pro grams and gives self-correctors for several functions. To highlight the importance of being 17 able to self-test, consider the mod function. To self-correct on input x and modulus R, the assumption in [48, Lipton] and here is that the program is correct for most inputs x with respect to the particular modulus R. This requires a different assumption for each distinct modulus R. <p> to the theory of interactive proofs (see [37, Goldwasser Micali Rackoff], [15, Babai] and [13, Ben-Or Goldwasser Kilian Wigderson] for the discussion of interactive proofs). [53, Nisan] noted that the self-testing/correcting technique based on bootstrapping discussed in Section 3.6 can be combined with the observation about the permanent problem in <ref> [48, Lipton] </ref> (based on [9, Beaver Feigenbaum]) to construct a two-prover interactive proof system for the permanent problem. This led to the eventual discovery that IP = PSPACE ([50, Fortnow Karloff Lund Nisan], [62, Shamir], [7, Babai]). <p> For completeness, we then give the specific details of the self-correcting programs for integer multiplication, modular multiplication, modular exponentiation, integer division, matrix multiplication and polynomial multiplication. We also describe the result in <ref> [48, Lipton] </ref> which uses the same basic outline to develop a self-correcting program for any multivariate polynomial function over a finite field. 3.3.1 The Mod Function We consider computing an integer mod R for a positive number R. In this case, f (x; R) = x mod R. <p> Proof: Follows the outline of the proof of Lemma 3. 3.3.9 Multivariate Polynomial Function We consider the problem of computing any multivariate polynomial function over a finite field. In <ref> [48, Lipton] </ref>, Lipton has shown a self-corrector for this problem based on the techniques of [9, Beaver Feigenbaum] which uses scalar multiplications and some preprocessing. <p> In <ref> [48, Lipton] </ref>, it is shown that in any finite field of size p, there are weights ff 1 ; : : : ; ff d+1 , such that for any polynomial q (X ) of degree d &lt; p, and any x; t in the field, d+1 X ff i f <p> To self-correct on input x and modulus R, the assumption in <ref> [48, Lipton] </ref> and here is that the program is correct for most inputs x with respect to the particular modulus R. This requires a different assumption for each distinct modulus R. <p> oracles that are trusted not to err, however the oracles are not restricted to answer questions of the form "What is the value of f (x)?". [Beaver Feigenbaum Kilian Rogaway] later improved this result to show that it can be done with O (jxj= log jxj) oracles. [9, Beaver Feigenbaum] <ref> [48, Lipton] </ref> show that any function that is a polynomial of degree d over a finite field is d-random-self-reducible.
Reference: [49] <author> Luby, M., </author> <title> "A Simple Parallel Algorithm for the Maximal Independent Set Problem", </title> <journal> SIAM J. Comput., </journal> <volume> vol. 15, </volume> <year> 1986, </year> <pages> pp. 1036-1053. </pages>
Reference-contexts: Furthermore, the checker is deterministic, and no other calls to the program are made. In contrast, the best known algorithms for this problem use at least logarithmic parallel time [36, Goldberg Spencer], [5, Alon Babai Itai], <ref> [49, Luby] </ref>. 77 6.3 Computability by Random Inputs In Chapter 3, [20, Blum Luby Rubinfeld 2] we show that one can design result checkers for many functions that have the property of random self-reducibility that the function can be computed by computing the function on one or more "random" instances.
Reference: [50] <author> Lund, C., Fortnow, L., Karloff, H., Nisan, N., </author> <title> "Algebraic Methods for Interactive Proof Systems", </title> <booktitle> to appear in Proceedings of the 31st Annual Symposium on Foundations of Computer Science,, </booktitle> <year> 1990. </year>
Reference-contexts: possible. 2.2 Examples Many result checkers have been found for various types of problems such as graph iso-morphism, matrix rank, quadratic residuocity, linear programming, maximum matching, greatest common divisor, permanent and even PSPACE-complete problems [15, Blum], [23, Blum Raghavan], [17, Blum Kannan], [18, Blum Kannan Rubinfeld], [2, Adleman Huang Kompella] <ref> [50, Fortnow Karloff Lund Nisan] </ref> [62, Shamir].
Reference: [51] <author> Micali, S., Rubinfeld, R., </author> <title> "Privacy Implies Correctness", </title> <type> manuscript. </type>
Reference-contexts: A third area is that of cryptographic protocols. Some initial results about result checking/self-testing/correcting with respect to cryptographic multi-party protocols are given in <ref> [51, Micali Rubinfeld] </ref>. 1 If one shows a polynomial time result checker for any NP -complete problem, a polynomial time result checker for any other NP -complete problem can be constructed using Beigel's theorem [15, Blum]. 98
Reference: [52] <author> Mulmuley, K., Vazirani, U., Vazirani, V., </author> <title> "Matching is as Easy as Matrix Inversion", </title> <booktitle> Proc. 19th ACM Symposium on Theory of Computing, </booktitle> <year> 1987. </year>
Reference-contexts: For example, one of the ideas proposed in [15, Blum] for the sequential checking of decision problems is the idea of reducing a search problem to a decision problem. This gives a simple proof of the correctness of a `yes' instance. Results in <ref> [52, Mulmuley Vazirani Vazirani] </ref> show that there are techniques for reducing a search problem to a decision problem for weighted search problems. <p> is the following: Maximum Matching Input: Graph G = (V; E) Output: k = the size of a maximum matching, and the edges in a maximum matching in G No deterministic NC algorithm is known for this problem, but it is known to be in RNC ([43, Karp Upfal Wigderson], <ref> [52, Mulmuley Vazirani Vazirani] </ref>). Result Checking Algorithm:(sketch) The result checker first checks in parallel that no vertex is matched more than once and that the maximum matching is of size k.
Reference: [53] <author> Nisan, N., </author> <title> "Co-SAT Has Multi-Prover Interactive Proofs", </title> <type> e-mail announcement, </type> <month> November </month> <year> 1989. </year>
Reference-contexts: The techniques in this chapter have been applied to the theory of interactive proofs (see [37, Goldwasser Micali Rackoff], [15, Babai] and [13, Ben-Or Goldwasser Kilian Wigderson] for the discussion of interactive proofs). <ref> [53, Nisan] </ref> noted that the self-testing/correcting technique based on bootstrapping discussed in Section 3.6 can be combined with the observation about the permanent problem in [48, Lipton] (based on [9, Beaver Feigenbaum]) to construct a two-prover interactive proof system for the permanent problem.
Reference: [54] <author> Randall, D., </author> <title> "Efficient Random Generation of Invertible Matrices", </title> <type> manuscript. </type>
Reference-contexts: We use program Gen Inv Matrix (n) as a subroutine in our code to choose A 2 U M n nfin [F ]. Gen Inv Matrix (n) is due to <ref> [54, Randall] </ref>, and a description of it can be found there. The incremental time of Gen Inv Matrix (n) is O (n 2 ), excluding the time for computing the one required matrix multiplication. We assume that Gen Inv Matrix (n) calls MMSC in order to compute the matrix multiplication. <p> We assume that Gen Inv Matrix (n) calls MMSC in order to compute the matrix multiplication. Thus, Gen Inv Matrix (n) has a small probability of error, which we ignore for purposes of clarity. Gen Inv Matrix/Det (n), also due to <ref> [54, Randall] </ref>, in addition to outputting A 2 U M n nfin [F ], also outputs det (A).
Reference: [55] <author> Renyi, A., </author> <year> (1970), </year> <title> Probability Theory, </title> <publisher> North-Holland, Amsterdam. </publisher>
Reference-contexts: The following proposition is used to quantify the number of random samples needed to guarantee good estimates of ffi and ffi 1 ; : : : ; ffi c with high probability. This proposition can be proved using standard techniques from an inequality due to Bernstein cited in <ref> [55, Renyi] </ref>. For a proof of this proposition, see for example [41, Karp Luby Madras]. 35 Proposition 17 Let Y 1 ; Y 2 ; : : : be independent identically distributed 0/1-valued random variables with mean . Let 2.
Reference: [56] <author> Rosser, J.B., Schoenfeld, L., </author> <title> "Approximate formulas for some functions of prime numbers", </title> <journal> Illinois J. Math, </journal> <volume> 6, </volume> <year> 1962, </year> <month> pp.64-94. </month>
Reference-contexts: The work in this chapter was done in collaboration with Mike Luby and Manuel Blum [20, Blum Luby Rubinfeld 2], [21, Blum Luby Rubinfeld 3], with the exception of the results in Section 3.5 which was done in collaboration with Madhu Sudan <ref> [56, Rubinfeld Sudan] </ref>. Consider any program P whose task is to evaluate a function f . A self-tester for f is a program that estimates the fraction of x for which P (x) 6= f (x). <p> We can easily estimate this probability by randomly choosing several independent x 2 U Z R and computing the fraction of these x that satisfy P (x; R) R x = 1. For all R &gt; 3, (R) = jZ fl 6 ln (n) <ref> [56, Rosser, Schoenfeld] </ref>, and thus if P is correct for a constant fraction ffi of the x 2 Z fl R then the above condition is true with c = 6=ffi.
Reference: [57] <author> Rubinfeld, R., </author> <title> "Designing Checkers for Programs that Run in Parallel", </title> <type> ICSI Technical Report No. </type> <institution> TR-90-040. </institution>
Reference-contexts: most of the time than it is to determine whether it is always satisfied, this relaxation is important for self-testing. 3.1 Related Work [22, Blum Micali] construct a pseudo-random generator, where a crucial ingredient of the construction can be thought of as a self-correcting program for the discrete log function. <ref> [57, Rubinfeld] </ref> introduces checking for parallel programs, and uses self-testing to design a constant depth circuit to check the majority function (see section 6.3.1). We will see that a self-testing/correcting pair for a function f implies a program result checker for f . <p> Multiplication, parity and majority all have lower bounds of (log n= log log n) depth, yet all have (completely different) constant depth result checkers. The results in this chapter also appear in <ref> [57, Rubinfeld 1] </ref>. 75 6.1 The Parallel Program Result Checking Model A parallel result checker must satisfy all of the same requirements as a sequential result checker mentioned in Chapter 2, with the following added remarks which are specific to the parallel programming setting.
Reference: [58] <author> Rubinfeld, R. </author> <title> "Batch Checking for the Mod Function", </title> <type> manuscript, </type> <year> 1990. </year>
Reference: [59] <author> Rubinfeld, R., Sudan, M., </author> <title> "Self-Testing Polynomial Functions and Approximate Functions", </title> <note> in preparation. </note>
Reference: [60] <author> Schonhage, A., </author> <type> personal communication through Michael Fischer. </type>
Reference-contexts: For example, integer multiplication and matrix multiplication are commonly used functions for which fast but complicated programs have been written and implemented ([26, Coppersmith Winograd], [63, Strassen], <ref> [60, Schonhage] </ref>). Thus, the self-testing/correcting pairs we develop for integer and matrix multiplication may be useful in practice. We develop general techniques for constructing simple to program self-testing/correcting pairs for a variety of numerical functions.
Reference: [61] <author> Schonhage, A., Strassen, V., "Schnelle Multiplikation grosser Zahlen," </author> <booktitle> Computing 7, </booktitle> <pages> 281-292. </pages>
Reference: [62] <author> Shamir, Adi, "IP=PSPACE", </author> <booktitle> to appear in Proceedings of the 31st Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1990. </year> <month> 102 </month>
Reference-contexts: checkers have been found for various types of problems such as graph iso-morphism, matrix rank, quadratic residuocity, linear programming, maximum matching, greatest common divisor, permanent and even PSPACE-complete problems [15, Blum], [23, Blum Raghavan], [17, Blum Kannan], [18, Blum Kannan Rubinfeld], [2, Adleman Huang Kompella] [50, Fortnow Karloff Lund Nisan] <ref> [62, Shamir] </ref>. <p> This led to the eventual discovery that IP = PSPACE ([50, Fortnow Karloff Lund Nisan], <ref> [62, Shamir] </ref>, [7, Babai]). The results in this chapter are related to those in [8, Babai Fortnow Lund].
Reference: [63] <author> Strassen, V., </author> <title> "Gaussian Elimination is not Optimal", </title> <journal> Numerische Mathematik, </journal> <volume> 13, </volume> <year> 1969, </year> <pages> pp. 354-356. </pages>
Reference-contexts: For example, the integer multiplication checker presented here seems much simpler than multiplication programs based on Fast Fourier transforms, and the matrix multiplication checker seems much simpler than matrix multiplication programs based on the methods in <ref> [63, Strassen] </ref>, [26, Coppersmith Winograd]. Blum suggests that we force the checker to be quantifiably different than any program for f . <p> For example, integer multiplication and matrix multiplication are commonly used functions for which fast but complicated programs have been written and implemented ([26, Coppersmith Winograd], <ref> [63, Strassen] </ref>, [60, Schonhage]). Thus, the self-testing/correcting pairs we develop for integer and matrix multiplication may be useful in practice. We develop general techniques for constructing simple to program self-testing/correcting pairs for a variety of numerical functions.
Reference: [64] <author> Van Der Waerden, </author> <title> B.L., </title> <journal> Algebra, </journal> <volume> Vol. 1, </volume> <publisher> Frederick Ungar Publishing Co., Inc., </publisher> <pages> pp. 86-91, </pages> <year> 1970. </year>
Reference-contexts: Since the ff i 's are the same for every polynomial of degree d, this is something that can be done once in preprocessing. The self-corrector will need to perform multiplications by these ff i 's. However, if p is prime, then using the method of differences described in <ref> [64, Van Der Waerden] </ref> (pg. 89), P l i=k ff i f (x + i t) can be computed using only O ((l k) 2 ) additions at runtime. In this case, the ff i 's turn out to be ff i = (1) i i . <p> Lemma 22 g is a polynomial of degree d. 44 Proof: [of Lemma 22] It is sufficient to show that 8x; t P d+1 <ref> [64, Van Der Waerden] </ref> p.89.
Reference: [65] <author> Wilkes, M., </author> <title> Memoirs of a Computer Pioneer, </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Mass., p. 145, </address> <year> 1985. </year>
Reference-contexts: Introduction In his book, Memoirs of a Computer Pioneer <ref> [65] </ref>, Maurice Wilkes writes : By June 1949 people had begun to realize that it was not so easy to get a program right as had at one time appeared. I well remember when this realization first came on me with full force.
Reference: [66] <author> Yao, A., </author> <title> "Coherent Functions and Program Checking", </title> <booktitle> Proc. 22th ACM Symposium on Theory of Computing, </booktitle> <year> 1990. </year> <month> 103 </month>
Reference-contexts: In the definition of different, we ignore the running time dependence on the confidence parameter fi, which is typically a multiplicative factor of O (ln (1=fi)). 2 Another quantifiable notion of difference that we consider is with respect to the algebraic model of computation (this notion is also considered in <ref> [66, Yao] </ref>). (Similar definitions can be made with respect to other structured models of computation.) Consider the problem of integer multiplication. Natural primitives to consider in writing a program for this this task are addition, the shift operation and comparisons. <p> Is it possible to determine whether or not sorting is random self-reducible? Some inroads have been made in the study of which functions do not have polynomial time result checkers. Yao <ref> [66] </ref> has shown that there are functions in DSP ACE (2 n logn ) that do not have polynomial time result checkers.
References-found: 66

