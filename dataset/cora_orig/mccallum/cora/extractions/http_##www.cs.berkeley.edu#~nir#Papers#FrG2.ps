URL: http://www.cs.berkeley.edu/~nir/Papers/FrG2.ps
Refering-URL: http://http.cs.berkeley.edu/~nir/publications.html
Root-URL: 
Email: nir@cs.stanford.edu  moises@rpal.rockwell.com  
Title: Discretizing Continuous Attributes While Learning Bayesian Networks  
Author: Nir Friedman Moises Goldszmidt 
Address: Gates Building 1A Stanford, CA 94305-9010  444 High St., Suite 400 Palo Alto, CA 94301  
Affiliation: Stanford University Dept. of Computer Science  Rockwell Science Center  
Abstract: We introduce a method for learning Bayesian networks that handles the discretization of continuous variables as an integral part of the learning process. The main ingredient in this method is a new metric based on the Minimal Description Length principle for choosing the threshold values for the discretization while learning the Bayesian network structure. This score balances the complexity of the learned discretization and the learned network structure against how well they model the training data. This ensures that the discretization of each variable introduces just enough intervals to capture its interaction with adjacent variables in the network. We formally derive the new metric, study its main properties, and propose an iterative algorithm for learning a discretization policy. Finally, we illustrate its behavior in applications to supervised learning.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. R. Bouckaert. </author> <title> Properties of Bayesian network learning algorithms. </title> <booktitle> In UAI '94, </booktitle> <pages> pp. 102-109. </pages> <year> 1994. </year>
Reference-contexts: Building Bayesian networks can be a laborious and expensive process in large applications. Thus, learning Bayesian networks from data has become a rapidly growing field of research that has seen a great deal of activity in recent years <ref> [1, 2, 4, 10, 14] </ref>. The objective is to induce a network (or a set of networks) that best describes the probability distribution over the training data. This optimization process is implemented in practice using heuristic search techniques to find the best candidate over the space of possible networks. <p> The MDL score of a network B is composed of two parts. The first part measures the complexity of the network, while the second part measures how good the network is as a model for the data <ref> [14, 1] </ref>. The optimal network B given a data set D is the network that minimizes the MDL score. This minimization involves a tradeoff between the two parts of the score. In practice, the MDL score regulates the number of parameters learned and helps avoid overfitting. <p> For the table associated with X i , we need to store jj X i jj (jjX i jj 1) parameters. The representation length of these parameters depends on the number of bits we use for each numeric parameter. The usual choice in the literature is 1=2 log N <ref> [1, 9] </ref>. Thus, the encoding length of fi is 1 P We remark that the description length of B is only a function of U and of G, and it does not depend on the actual values of parameters in fi. <p> In practice, this is usually done by searching over the space of possible networks. Since this space is large, this search is a non-trivial problem. Details about the search process can be found in <ref> [1, 9] </ref>. 3 MDL SCORE FOR DISCRETIZATION Until now we have assumed that all the variables X i in the universe U are discrete (or nominal). We now consider the case where some of the variables take numerical values.
Reference: [2] <author> W. Buntine. </author> <title> Operations for learning with graphical models. </title> <journal> J. of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 159-225, </pages> <year> 1994. </year>
Reference-contexts: Building Bayesian networks can be a laborious and expensive process in large applications. Thus, learning Bayesian networks from data has become a rapidly growing field of research that has seen a great deal of activity in recent years <ref> [1, 2, 4, 10, 14] </ref>. The objective is to induce a network (or a set of networks) that best describes the probability distribution over the training data. This optimization process is implemented in practice using heuristic search techniques to find the best candidate over the space of possible networks.
Reference: [3] <author> P. Cheeseman, J. Kelly, M. Self, J. Stutz, W. Taylor, and D. Freeman. </author> <title> Autoclass: a Bayesian classification system. </title> <booktitle> In ML '88. </booktitle> <year> 1988. </year>
Reference-contexts: In several domains of interest, such as medicine and in dustrial control, variables in the training data often have continuous values. We have two basic approaches to deal with continuous variables: we can restrict ourselves to specific families of parametric distributions and use the methods described in <ref> [11, 16, 12, 3] </ref>, or we can discretize these variables and learn a network over the discretized domain. There is tradeoff between the two options. The first can model the conditional density of each variable in the network (under some assumptions regarding the family of distributions).
Reference: [4] <author> G. F. Cooper and E. Herskovits. </author> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 309-347, </pages> <year> 1992. </year>
Reference-contexts: Building Bayesian networks can be a laborious and expensive process in large applications. Thus, learning Bayesian networks from data has become a rapidly growing field of research that has seen a great deal of activity in recent years <ref> [1, 2, 4, 10, 14] </ref>. The objective is to induce a network (or a set of networks) that best describes the probability distribution over the training data. This optimization process is implemented in practice using heuristic search techniques to find the best candidate over the space of possible networks. <p> Several different scoring functions have been proposed in the literature <ref> [4, 10, 14] </ref>. In this paper we focus our attention on the MDL score [14]. This score is simple, very intuitive, and has proven to be quite effective in practice. The idea behind the MDL principle is as follows.
Reference: [5] <author> T. M. Cover and J. A. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> Wiley, </publisher> <year> 1991. </year>
Reference-contexts: The idea is as follows: a network B assigns a probability to each instance of U. Using these probabilities we can construct an efficient code. In particular, we use the Huffman code <ref> [5] </ref>, which assigns shorter codes to frequent instances. The benefit of using the MDL as a scoring metric is that the best network for D optimally balances the complexity 1 Formally there is a notion of minimality associated with this definition, but we will ignore it in this paper. <p> Using the probability measure defined by B, we construct a Huffman code for the instances in D. In this code, the exact length of each codeword depends on the probability assigned to that particular instance. There is no closed form description of this length. However, it is known <ref> [5] </ref> that when we choose longer coding blocks we can approximate the optimal encoding length in which the encoding of each u is log P B (u) bits. Thus, the description length of the data is simply: P N We can rewrite this expression in a more convenient form. <p> Let ^ P D be the probability measure that corresponds to the frequency of instances in the data. Using (1) and some algebraic manipulations we can rewrite the representation 2 This number is slightly imprecise since we do not know in advance the length of the encoding <ref> [5] </ref>. length of the data as: i=1 X X ^ P D (x i ; x i ) log x i j x i Using standard arguments, we can show that this term is minimized if we set x i j x i = ^ P D (x i j x <p> (D; G) = N X H (X i j X i ) Where H (XjY) = P ^ P D (x; y) log ^ P D (xjy) is the conditional entropy of X given Y (if Y = ; then H (XjY) = H (X), the unconditional entropy of X) <ref> [5] </ref>. Using this information-theoretic interpretation we can rewrite DL data (D; G) slightly. <p> All we need to store is the index of the discretization policy in some enumeration of the k i 1 different discretization policies of cardinality k i = jjX fl i jj. This index can be described using log N i 1 bits. Using Sterling's approximation (see <ref> [5, p. 151] </ref>), we get that log N 1 1 N i 1 ), where H (p) = p log p (1 p) log (1 p). 3 Thus the description of fl is of length: DL fl (fl) = X i 2U cont (N i 1)H ( N i 1 Finally, <p> Using basic properties of the entropy and mutual information measures (see <ref> [5] </ref>), we easily prove the following: Proposition 3.1: H (X fl i j fl i ) = H (X i ) i ; fl Note that H (X i ) is a function of the data D and does not depend on fl and G. Thus, we can ignore it. <p> This guarantees that we do not discretize X i before we propagate the changes made in the previous discretization of X i to all of its neighbors. This procedure has to be initialized with some discretiza-tion. In our current implementation, we use the least square quantization <ref> [5] </ref> method. This method attempts to find the best k-partitioning of a random variable, essentially by Input: An initial discretization fl of U. Output: A (locally) optimal discretization of U. Push all continuous variables onto a queue Q. While Q is not empty Remove the first element X from Q.
Reference: [6] <author> J. Dougherty, R. Kohavi, and M. Sahami. </author> <title> Supervised and unsupervised discretization of continuous features. </title> <booktitle> In ML '95. </booktitle> <year> 1995. </year>
Reference-contexts: This method is considered state of the art in supervised learning <ref> [6] </ref>. In their approach, FI attempt to maximize the mutual-information between each variable and the class variable. Although their method was not developed in the context of Bayesian networks, it is applicable for one particular network structure, namely that of a naive Bayes classifier. <p> Table 1 shows the results of this comparison: naive denotes a naive Bayes classifier that was learned from the original data discretized with our approach; in FI-naive the data set was prediscretized by the method of FI using only the training data, in the manner described in <ref> [6] </ref>, then, a naive Bayes classifier was learned over the discretized data. As these Table 2: Experimental results comparing unsupervised learning of network structure.
Reference: [7] <author> U. M. Fayyad and K. B. Irani. </author> <title> Multi-interval dis-cretization of continuous-valued attributes for classification learning. </title> <booktitle> In IJCAI '93, </booktitle> <pages> pp. 1022-1027, </pages> <year> 1993. </year>
Reference-contexts: This new metric provides a principled approach for selecting the threshold values in the discretization process. Our proposal can be regarded as a generalization of the method proposed by Fayyad and Irani <ref> [7] </ref>. Roughly speaking, their approach, which applies to supervised learning only, discretizes variables to increase the mutual information with respect to the class variable. <p> In Section 4 we examine computational issues and identify several properties of our scoring metric that can be exploited in this regard. In Section 5 we present experimental results that evaluate this method in classification tasks and compare it to the method proposed by Fayyad and Irani <ref> [7] </ref>. Finally, Section 6 summarizes our contributions and discusses future work. 2 LEARNING BAYESIAN NETWORKS Consider a finite set U = fX 1 ; : : : ; X n g of discrete random variables where each variable X i may take on values from a finite domain. <p> In practice, we search this space by starting with the trivial discretization (i.e., the discretization with the empty threshold list), and search over the possible refinements. This approach, which is usually called top-down, is common in the supervised learning literature <ref> [18, 7] </ref>. The search strategy can be any of the well known ones, greedy search (or hill climb search), beam search, etc. Carrying out this search can be very expensive. <p> We also report the standard deviation of the accuracies found in each fold. These computations were done using the MLC++ library. (See [8, 13] for more details.) Our first experiment is concerned with an application to supervised learning and a comparison to the discretization method of Fayyad and Irani <ref> [7] </ref> (FI from now on). This method is considered state of the art in supervised learning [6]. In their approach, FI attempt to maximize the mutual-information between each variable and the class variable.
Reference: [8] <author> N. Friedman and M. Goldszmidt. </author> <title> Building classifiers using Bayesian networks. </title> <booktitle> In AAAI '96. </booktitle> <year> 1996. </year>
Reference-contexts: We report the mean of the prediction accuracies over all cross-validation folds. We also report the standard deviation of the accuracies found in each fold. These computations were done using the MLC++ library. (See <ref> [8, 13] </ref> for more details.) Our first experiment is concerned with an application to supervised learning and a comparison to the discretization method of Fayyad and Irani [7] (FI from now on). This method is considered state of the art in supervised learning [6]. <p> However, in datasets with multiple attributes their performance can be poor. We explain this phenomena is detail in <ref> [8] </ref>. Table 3 lists the prediction accuracies as well as C4.5's performance when given the data without prediscretization. As these results show that our procedures, even the unsupervised ones, are comparative with FI's method and with C4.5's internal discretization.
Reference: [9] <author> D. Heckerman. </author> <title> A tutorial on learning Bayesian networks. </title> <type> Technical Report MSR-TR-95-06, </type> <institution> Microsoft Research, </institution> <year> 1995. </year>
Reference-contexts: To formalize the notion of goodness of fit of a network with respect to the data, we normally introduce a scoring function, and to solve the optimization problem we usually rely on heuristic search techniques over the space of possible networks <ref> [9] </ref>. Several different scoring functions have been proposed in the literature [4, 10, 14]. In this paper we focus our attention on the MDL score [14]. This score is simple, very intuitive, and has proven to be quite effective in practice. The idea behind the MDL principle is as follows. <p> For the table associated with X i , we need to store jj X i jj (jjX i jj 1) parameters. The representation length of these parameters depends on the number of bits we use for each numeric parameter. The usual choice in the literature is 1=2 log N <ref> [1, 9] </ref>. Thus, the encoding length of fi is 1 P We remark that the description length of B is only a function of U and of G, and it does not depend on the actual values of parameters in fi. <p> In practice, this is usually done by searching over the space of possible networks. Since this space is large, this search is a non-trivial problem. Details about the search process can be found in <ref> [1, 9] </ref>. 3 MDL SCORE FOR DISCRETIZATION Until now we have assumed that all the variables X i in the universe U are discrete (or nominal). We now consider the case where some of the variables take numerical values.
Reference: [10] <author> D. Heckerman, D. Geiger, and D. M. Chickering. </author> <title> Learning Bayesian networks: The combination of knowlege and statistical data. </title> <journal> Machine Learning, </journal> <volume> 20 </volume> <pages> 197-243, </pages> <year> 1995. </year>
Reference-contexts: Building Bayesian networks can be a laborious and expensive process in large applications. Thus, learning Bayesian networks from data has become a rapidly growing field of research that has seen a great deal of activity in recent years <ref> [1, 2, 4, 10, 14] </ref>. The objective is to induce a network (or a set of networks) that best describes the probability distribution over the training data. This optimization process is implemented in practice using heuristic search techniques to find the best candidate over the space of possible networks. <p> Several different scoring functions have been proposed in the literature <ref> [4, 10, 14] </ref>. In this paper we focus our attention on the MDL score [14]. This score is simple, very intuitive, and has proven to be quite effective in practice. The idea behind the MDL principle is as follows. <p> Finally, an open question is the development of a similar scoring metric for discretization based on Bayesian concepts as opposed to the MDL principle. A natural path would be to augment the Bayesian scoring metric introduced in <ref> [11, 10] </ref>. The main obstacle is to specify in a compact way a prior for the parameters fi, for each possible discretization of the data. This is a non trivial problem, Table 3: Using learned discretizations for C4.5. <p> 69.19+-2.62 69.62+-1.95 67.75+-2.50 glass2 75.44+-1.10 74.26+-4.24 74.28+-3.60 76.67+-1.63 73.60+-4.06 iris 94.00+-1.25 95.33+-0.82 94.00+-1.25 94.00+-1.25 94.67+-1.33 lymphography 77.03+-1.21 77.70+-0.82 74.97+-1.84 77.03+-1.21 77.01+-0.77 pima 75.65+-1.29 74.99+-1.14 75.39+-1.12 75.13+-1.52 72.65+-1.78 shuttle-small 99.22+-0.20 99.38+-0.18 99.33+-0.19 99.17+-0.21 99.53+-0.15 vehicle 69.16+-2.30 66.31+-1.57 70.80+-1.02 69.74+-1.52 69.86+-1.84 waveform-21 72.47+-0.65 69.98+-0.67 72.64+-0.65 74.70+-0.63 70.36+-0.67 for which the methods of <ref> [10] </ref> do not immediately apply. Acknowledgments The authors are grateful to Denise Draper, Usama Fayyad, Ronny Kohavi and Meheran Sahami for comments on a previous draft of this paper and useful discussions relating to this work.
Reference: [11] <author> D. Heckermann and D. Geiger. </author> <title> Learning bayesian networks: a unification for discrete and gaussian domains. </title> <booktitle> In UAI '95, </booktitle> <pages> pp. 274-284. </pages> <year> 1995. </year>
Reference-contexts: In several domains of interest, such as medicine and in dustrial control, variables in the training data often have continuous values. We have two basic approaches to deal with continuous variables: we can restrict ourselves to specific families of parametric distributions and use the methods described in <ref> [11, 16, 12, 3] </ref>, or we can discretize these variables and learn a network over the discretized domain. There is tradeoff between the two options. The first can model the conditional density of each variable in the network (under some assumptions regarding the family of distributions). <p> Finally, an open question is the development of a similar scoring metric for discretization based on Bayesian concepts as opposed to the MDL principle. A natural path would be to augment the Bayesian scoring metric introduced in <ref> [11, 10] </ref>. The main obstacle is to specify in a compact way a prior for the parameters fi, for each possible discretization of the data. This is a non trivial problem, Table 3: Using learned discretizations for C4.5.
Reference: [12] <author> G. H. John and P. Langley. </author> <title> Estimating continuous distributions in bayesian classifiers. </title> <booktitle> In UAI '95, </booktitle> <pages> pp. 338-345. </pages> <year> 1995. </year>
Reference-contexts: In several domains of interest, such as medicine and in dustrial control, variables in the training data often have continuous values. We have two basic approaches to deal with continuous variables: we can restrict ourselves to specific families of parametric distributions and use the methods described in <ref> [11, 16, 12, 3] </ref>, or we can discretize these variables and learn a network over the discretized domain. There is tradeoff between the two options. The first can model the conditional density of each variable in the network (under some assumptions regarding the family of distributions).
Reference: [13] <author> R. Kohavi, G. John, R. Long, D. Manley, and K. Pfleger. MLC++: </author> <title> A machine learning library in C++. </title> <booktitle> In Tools with Artificial Intelligence, </booktitle> <pages> pp. 740-743. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year>
Reference-contexts: We report the mean of the prediction accuracies over all cross-validation folds. We also report the standard deviation of the accuracies found in each fold. These computations were done using the MLC++ library. (See <ref> [8, 13] </ref> for more details.) Our first experiment is concerned with an application to supervised learning and a comparison to the discretization method of Fayyad and Irani [7] (FI from now on). This method is considered state of the art in supervised learning [6].
Reference: [14] <author> W. Lam and F. Bacchus. </author> <title> Learning Bayesian belief networks. An approach based on the MDL principle. </title> <journal> Computational Intelligence, </journal> <volume> 10 </volume> <pages> 269-293, </pages> <year> 1994. </year>
Reference-contexts: Building Bayesian networks can be a laborious and expensive process in large applications. Thus, learning Bayesian networks from data has become a rapidly growing field of research that has seen a great deal of activity in recent years <ref> [1, 2, 4, 10, 14] </ref>. The objective is to induce a network (or a set of networks) that best describes the probability distribution over the training data. This optimization process is implemented in practice using heuristic search techniques to find the best candidate over the space of possible networks. <p> The MDL score of a network B is composed of two parts. The first part measures the complexity of the network, while the second part measures how good the network is as a model for the data <ref> [14, 1] </ref>. The optimal network B given a data set D is the network that minimizes the MDL score. This minimization involves a tradeoff between the two parts of the score. In practice, the MDL score regulates the number of parameters learned and helps avoid overfitting. <p> Several different scoring functions have been proposed in the literature <ref> [4, 10, 14] </ref>. In this paper we focus our attention on the MDL score [14]. This score is simple, very intuitive, and has proven to be quite effective in practice. The idea behind the MDL principle is as follows. <p> Several different scoring functions have been proposed in the literature [4, 10, 14]. In this paper we focus our attention on the MDL score <ref> [14] </ref>. This score is simple, very intuitive, and has proven to be quite effective in practice. The idea behind the MDL principle is as follows. Suppose that we are given a set D of instances which we would like to store and keep in our records.
Reference: [15] <author> P. M. Murphy and D. W. Aha. </author> <title> UCI repository of machine learning databases. </title> <address> http://www.ics. uci.edu/mlearn/MLRepository.html. </address>
Reference-contexts: The experiments were run on 13 datasets from the Irvine repository <ref> [15] </ref>. We estimated the accuracy of the learned classifiers using 5-fold cross-validation, except for the shuttle-small and waveform-21 datasets where we used the hold-out method. We report the mean of the prediction accuracies over all cross-validation folds. We also report the standard deviation of the accuracies found in each fold.
Reference: [16] <author> R. M. Neal. </author> <title> Connectionist learning of belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 56 </volume> <pages> 71-113, </pages> <year> 1992. </year>
Reference-contexts: In several domains of interest, such as medicine and in dustrial control, variables in the training data often have continuous values. We have two basic approaches to deal with continuous variables: we can restrict ourselves to specific families of parametric distributions and use the methods described in <ref> [11, 16, 12, 3] </ref>, or we can discretize these variables and learn a network over the discretized domain. There is tradeoff between the two options. The first can model the conditional density of each variable in the network (under some assumptions regarding the family of distributions).
Reference: [17] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: The graph structure G encodes the following set of independence assumptions: each node X i is independent of its non-descendants given its parents in G <ref> [17] </ref>. 1 The second component of the pair, namely fi, represents the set of parameters that quantifies the network. <p> The benefit of using the MDL as a scoring metric is that the best network for D optimally balances the complexity 1 Formally there is a notion of minimality associated with this definition, but we will ignore it in this paper. See <ref> [17] </ref> for details. of the network with the degree of accuracy with which the network represents the frequencies in D. We now describe in detail the representation length required for the storage of both the network and the coded data. <p> The important aspect of this result, is that DL local (X i ; G; fl; D) involves only variables that are in the Markov blanket of X i <ref> [17] </ref>, i.e., X i 's parents, X i 's children, and parents of X i 's children in G.
Reference: [18] <author> J. R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: In practice, we search this space by starting with the trivial discretization (i.e., the discretization with the empty threshold list), and search over the possible refinements. This approach, which is usually called top-down, is common in the supervised learning literature <ref> [18, 7] </ref>. The search strategy can be any of the well known ones, greedy search (or hill climb search), beam search, etc. Carrying out this search can be very expensive. <p> Finally in order to compare the discretization policies computed in each of these experiments, we used the discretiza-tions learned by naive, unsup (LS), unsup (naive) and FI's method as a prediscretized input for the C4.5 classifier <ref> [18] </ref>. 4 We note that unsupervised Bayesian network classifiers are often better than the naive Bayes classifier. However, in datasets with multiple attributes their performance can be poor. We explain this phenomena is detail in [8].
References-found: 18

