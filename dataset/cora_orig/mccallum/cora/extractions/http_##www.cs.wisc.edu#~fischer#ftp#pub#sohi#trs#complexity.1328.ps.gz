URL: http://www.cs.wisc.edu/~fischer/ftp/pub/sohi/trs/complexity.1328.ps.gz
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/sohi/trs/
Root-URL: http://www.cs.wisc.edu
Email: subbarao@cs.wisc.edu  jouppi@pa.dec.com  jes@ece.wisc.edu  
Title: Quantifying the Complexity of Superscalar Processors  
Author: Subbarao Palacharla Norman P. Jouppi James E. Smith 
Address: Madison, WI 53706, USA  Palo Alto, CA 94301, USA  Madison, WI 53706, USA  
Affiliation: Computer Sciences Department University of Wisconsin-Madison  Western Research Laboratory Digital Equipment Corporation  Department of ECE University of Wisconsin-Madison  
Abstract: To characterize future performance limitations of superscalar processors, the delays of key pipeline structures in superscalar processors are studied. First, a generic superscalar pipeline is defined. Then the specific areas of register renaming, instruction window wakeup and selection logic, and operand bypassing are analyzed. Each is modeled and Spice simulated for feature sizes of 0:8m, 0:35m, and 0:18m. Performance (delay) results and trends are expressed in terms of issue width and window size. This analysis indicates that window (wakeup and select) logic and operand bypass logic are likely to be the most critical in the future.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. S. Ahuja, D. W. Clark, and A. Rogers. </author> <title> The Performance Impact of Incomplete Bypassing in Processor Pipelines. </title> <booktitle> In Proceedings of the 28th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 36-45, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: The hardware datap-aths and control added for this purpose form the bypass logic. The number of bypasses required is determined by the depth of the pipeline and the issue width of the microarchitecture. As pointed out in <ref> [1] </ref>, if IW is the issue width, and if there are S pipestages after the first result-producing stage, then a fully bypassed design would require (2 fi IW 2 fi S) bypass paths assuming 2-input functional units. <p> The hardware or the compiler or both will have to ensure that inter-cluster bypasses occur infrequently. In addition to mitigating the delay of the bypass logic, this organization also has the advantage of faster register files because there are fewer ports on each register file. Another technique <ref> [1] </ref> that can be used to improve bypass performance is to use an incomplete bypass network. In an incomplete bypass network only the frequently used bypass paths are provided while interlocks are used in the remaining situations.
Reference: [2] <author> C. Asato, R. Montoye, J. Gmuender, E. W. Simmons, A. Ike, and J. Zasio. </author> <title> A 14-port 3.8ns 116-word 64b Read-Renaming Register File. </title> <booktitle> In 1995 IEEE International Sold-State Circuits Conference Digest of Technical Papers, </booktitle> <pages> pages 104-105, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: Recovery is performed by writing the bit in the appropriate shift register cell back into the main cell. CAM scheme An alternative scheme for register renaming uses a CAM (content-addressable memory [32]) to store the current mappings. Such a scheme is implemented in the HAL SPARC <ref> [2] </ref> and the DEC 21264 [18]. The number of entries in the CAM is equal to the number of physical registers. Each entry contains two fields. The first field stores the logical register designator that is mapped to the physical register represented by the entry.
Reference: [3] <institution> Semiconductor Industry Association. The National Technology Roadmap for Semiconductors, </institution> <year> 1994. </year>
Reference-contexts: The remaining terms will be defined when they are introduced. 4 Technology Trends Feature sizes of MOS devices have been steadily decreasing. This trend towards smaller devices is likely to continue at least for the next decade <ref> [3] </ref>. In this section, we briefly discuss the effect of shrinking feature sizes on circuit delays. The effect of scaling feature sizes on circuit performance is an active area of research [8, 21]. We are only interested in illustrating the trends in this section.
Reference: [4] <author> Mark T. Bohr. </author> <title> Interconnect Scaling The Real Limiter to High Performance ULSI. </title> <booktitle> In 1995 International Electron Devices Meeting Technical Digest, </booktitle> <pages> pages 241-244, </pages> <year> 1995. </year>
Reference-contexts: In order to study the impact of shrinking feature sizes on wire delays we first have to analyze how the resistance, R metal , and the parasitic capacitance, C metal , of metal wires vary with feature size. We use the simple model presented by Bohr in <ref> [4] </ref> to estimate how R metal and C metal scale with feature size. Note that both these quantities are per unit length measures. From [4], R metal = =(width fl thickness) C metal = C fringe + C parallelplate = 2 fl * fl * 0 fl thickness=width + 2 fl <p> We use the simple model presented by Bohr in <ref> [4] </ref> to estimate how R metal and C metal scale with feature size. Note that both these quantities are per unit length measures. From [4], R metal = =(width fl thickness) C metal = C fringe + C parallelplate = 2 fl * fl * 0 fl thickness=width + 2 fl * fl * 0 fl width=thickness where width is the width of the wire, thickness is the thickness of the wire, is the resistivity
Reference: [5] <author> M. Butler and Y. N. Patt. </author> <title> An Investigation of the Performance of Various Dynamic Scheduling Techniques. </title> <booktitle> In Proceedings of the 25th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 1-9, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: A selection policy is used to decide which of the requesting instructions is granted the functional unit. An example selection policy is oldest ready first the ready instruction that occurs earliest in program order is granted the functional unit. Butler and Patt <ref> [5] </ref> studied various policies for scheduling ready instructions and found that overall performance is largely independent of the selection policy. For example, the HP PA-8000 [19] uses a selection policy that is based on the location of the instruction in the window.
Reference: [6] <author> T. Chappell. </author> <title> A 2ns cycle, 4 ns access 512kb CMOS ECL SRAM. </title> <booktitle> In 1991 IEEE International Sold-State Circuits Conference Digest of Technical Papers, </booktitle> <pages> pages 50-51, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: While it is easy to see how dependence checking can be pipelined, it is not so obvious how the map table access can be pipelined. However, there are schemes <ref> [6, 23] </ref> for pipelining RAMs that can be employed to pipeline the map table access.
Reference: [7] <author> Marvin Denman. </author> <title> Design of the PowerPC 604e RISC Microprocessor, December 1995. </title> <booktitle> Tutorial Talk at 28th Annual International Symposium on Microarchitecture. </booktitle>
Reference-contexts: Hence, the structures identified above apply to these three processors. On the other hand, the Intel Pentium Pro [13], the PowerPC 604 <ref> [7] </ref>, and the HAL SPARC64 [12] are based on the reservation station model shown in Figure 2. There are two main differences between the two models. First, in the baseline model all the register values, both speculative and non-speculative, reside in the physical register file.
Reference: [8] <author> R. Dennard et al. </author> <title> Design of Ion-implanted MOSFETS with Very Small Physical Dimensions. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> SC-9:256-268, </volume> <year> 1974. </year>
Reference-contexts: This trend towards smaller devices is likely to continue at least for the next decade [3]. In this section, we briefly discuss the effect of shrinking feature sizes on circuit delays. The effect of scaling feature sizes on circuit performance is an active area of research <ref> [8, 21] </ref>. We are only interested in illustrating the trends in this section. Circuit delays consist of logic delays and wire delays. Logic delays are delays resulting from gates that are driving other gates.
Reference: [9] <author> D. Dobberpuhl et al. </author> <title> A 200-MHz 64-b dual-issue CMOS Microprocessor. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> 27 </volume> <pages> 1555-1557, </pages> <year> 1992. </year>
Reference-contexts: This technique has been used in the DEC 21264 [18]. In this case two copies of the integer register file are used. * Cache access Cache access can be pipelined in a number of ways. One scheme, implemented in the DEC 21064 <ref> [9] </ref>, reads the tags and the data in the first cycle and performs the hit/miss detection operation in the second cycle. A second, more aggressive scheme could pipeline both the tag RAM and the data RAM themselves.
Reference: [10] <author> P. K. Dubey and M. J. Flynn. </author> <title> Optimal Pipelining. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8 </volume> <pages> 10-19, </pages> <year> 1990. </year> <month> 39 </month>
Reference-contexts: The current trend in the microprocessor industry is towards deeper pipelining. For example, the pipeline in the Intel Pentium Pro [13] has as many as 14 pipestages. The general subject of the effect of pipelining depth on overall performance has been the focus of a number of studies <ref> [20, 17, 10] </ref>. We took a different approach in our study. We studied the feasibility of pipelining each of the critical structures and identified atomic operations, if any, implemented by the structures.
Reference: [11] <author> Keith I. Farkas, Norman P. Jouppi, and Paul Chow. </author> <title> Register File Design Considerations in Dynamically Sched--uled Processors. </title> <booktitle> In Proceedings of the Second IEEE Symposium on High-Performance Computer Architecture, </booktitle> <pages> pages 40-51, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: The access time of the register file is a function of the number of physical registers and the number of read and write ports. Farkas et. al. <ref> [11] </ref> study how the access time of the register file varies with the number of registers and the number of ports. Because it is studied elsewhere, we do not include it here. * Caches The instruction and data caches provide low latency access to instructions and memory operands respectively. <p> The dependence check logic, shown in Figure 4, proceeds in parallel with the map table access. Every 2 Farkas et. al. <ref> [11] </ref> have shown that for significant performance up to 80 physical registers are required for a 4-wide issue machine and up to 120 physical registers are required for a 8-wide issue machine. 12 logical register designator being renamed is compared against the destination register designators (logical) of earlier instructions in the
Reference: [12] <author> Linley Gwennap. </author> <title> HAL Reveals Multichip SPARC Processor. </title> <type> Microprocessor Report, 9(3), </type> <month> March </month> <year> 1995. </year>
Reference-contexts: Hence, the structures identified above apply to these three processors. On the other hand, the Intel Pentium Pro [13], the PowerPC 604 [7], and the HAL SPARC64 <ref> [12] </ref> are based on the reservation station model shown in Figure 2. There are two main differences between the two models. First, in the baseline model all the register values, both speculative and non-speculative, reside in the physical register file.
Reference: [13] <author> Linley Gwennap. </author> <title> Intel's P6 Uses Decoupled Superscalar Design. </title> <type> Microprocessor Report, 9(2), </type> <month> February </month> <year> 1995. </year>
Reference-contexts: Hence, the structures identified above apply to these three processors. On the other hand, the Intel Pentium Pro <ref> [13] </ref>, the PowerPC 604 [7], and the HAL SPARC64 [12] are based on the reservation station model shown in Figure 2. There are two main differences between the two models. First, in the baseline model all the register values, both speculative and non-speculative, reside in the physical register file. <p> Length = regf ile height + ALU gen height + ALU simple height + 2 fi LDST height 7 In a reservation-station based microarchitecture like the Intel Pentium Pro <ref> [13] </ref>, the operand bits come from the data field of the reservation station entry. 33 Functional unit Height () Description Adder 1400 64-bit adder Shifter 1500 64-bit barrel shifter Logic Unit 300 Performs logical operations Complete ALU (ALU gen ) 3200 Comprises adder, shifter, and logic unit Simple ALU (ALU simple <p> The current trend in the microprocessor industry is towards deeper pipelining. For example, the pipeline in the Intel Pentium Pro <ref> [13] </ref> has as many as 14 pipestages. The general subject of the effect of pipelining depth on overall performance has been the focus of a number of studies [20, 17, 10]. We took a different approach in our study.
Reference: [14] <author> I. S. Hwang and A. L. Fisher. </author> <title> A 3.1ns 32b CMOS Adder in Multiple Output Domino Logic. </title> <booktitle> In 1988 IEEE International Sold-State Circuits Conference Digest of Technical Papers, </booktitle> <pages> pages 140-141, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: We expect this component of the delay to become relatively less significant as the feature size is reduced. 5.6.3 Results Table 2 shows typical heights of functional units. The lengths were estimated based on data presented in papers <ref> [14, 28, 15] </ref> describing specific implementations of functional units. For example, the height of a complete ALU is 3200 , where is half the feature size. The complete ALU, referred to as ALU gen , comprises an adder, a shifter, and a logic unit.
Reference: [15] <author> Inoue et al. </author> <title> A 0.4um 1.4ns 32b Dynamic Adder using Non-Precharge Multiplexers and Reduced Precharge Voltage Techniques. </title> <booktitle> In 1995 Symposium on VLSI Circuits Digest of Technical Papers, </booktitle> <pages> pages 9-10, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: We expect this component of the delay to become relatively less significant as the feature size is reduced. 5.6.3 Results Table 2 shows typical heights of functional units. The lengths were estimated based on data presented in papers <ref> [14, 28, 15] </ref> describing specific implementations of functional units. For example, the height of a complete ALU is 3200 , where is half the feature size. The complete ALU, referred to as ALU gen , comprises an adder, a shifter, and a logic unit.
Reference: [16] <author> Mark G. Johnson and Norman P. Jouppi. </author> <title> Transistor Model for a Synthetic 0.8um CMOS Process, </title> <month> May </month> <year> 1990. </year> <institution> Class notes for Stanford University EE371. </institution>
Reference-contexts: To study the effect of reducing the feature size on the delays of the structures, we simulated the circuits for three different feature sizes: 0:8m, 0:35m, and 0:18m respectively. The process parameters for the 0:8m CMOS process were taken from <ref> [16] </ref>. These parameters were used by Wilton and Jouppi in their study of cache access times [33]. Because process parameters are proprietary information, we had to use extrapolation to come up with process parameters for the 0:35m and 0:18m technologies.
Reference: [17] <author> Norman P. Jouppi and David W. Wall. </author> <title> Available Instruction-Level Parallelism for Superscalar and Superpipelined Machines. </title> <booktitle> In Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> April </month> <year> 1989. </year>
Reference-contexts: The current trend in the microprocessor industry is towards deeper pipelining. For example, the pipeline in the Intel Pentium Pro [13] has as many as 14 pipestages. The general subject of the effect of pipelining depth on overall performance has been the focus of a number of studies <ref> [20, 17, 10] </ref>. We took a different approach in our study. We studied the feasibility of pipelining each of the critical structures and identified atomic operations, if any, implemented by the structures.
Reference: [18] <author> Jim Keller. </author> <title> The 21264: A Superscalar Alpha Processor with Out-of-Order Execution, October 1996. </title> <booktitle> Presentation at the 9th Annual Microprocessor Forum, </booktitle> <address> San Jose, California. </address>
Reference-contexts: CAM scheme An alternative scheme for register renaming uses a CAM (content-addressable memory [32]) to store the current mappings. Such a scheme is implemented in the HAL SPARC [2] and the DEC 21264 <ref> [18] </ref>. The number of entries in the CAM is equal to the number of physical registers. Each entry contains two fields. The first field stores the logical register designator that is mapped to the physical register represented by the entry. <p> Each cluster has its own copy of the register file. Bypasses within a cluster complete in a single cycle while inter-cluster bypasses take 2 or more cycles. Such a scheme is implemented in the DEC 21264 <ref> [18] </ref>. The hardware or the compiler or both will have to ensure that inter-cluster bypasses occur infrequently. In addition to mitigating the delay of the bypass logic, this organization also has the advantage of faster register files because there are fewer ports on each register file. <p> Each copy of the register file will have half the number of read ports as the original register file. This technique has been used in the DEC 21264 <ref> [18] </ref>. In this case two copies of the integer register file are used. * Cache access Cache access can be pipelined in a number of ways. <p> We believe that these wire delays will force architects to consider clustered microarchitectures like the one employed by the DEC 21264 <ref> [18] </ref>. Acknowledgements This work was supported in part by an internship at DEC Western Research Laboratory, and by grants from the NSF Grant MIP-9505853, and the U.S. Army Intelligence Center and Fort Huachuca under Contract DABT63-95-C-0127 and ARPA order no. D346.
Reference: [19] <author> Ashok Kumar. </author> <title> The HP-PA8000 RISC CPU: A High Performance Out-of-Order Processor. </title> <booktitle> In Proceedings of the Hot Chips VIII, </booktitle> <pages> pages 9-20, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: Butler and Patt [5] studied various policies for scheduling ready instructions and found that overall performance is largely independent of the selection policy. For example, the HP PA-8000 <ref> [19] </ref> uses a selection policy that is based on the location of the instruction in the window. We assume the same selection policy in our study. 5.4.1 Structure The assumed structure of the selection logic is shown in Figure 18. <p> The overall selection logic works in two phases. In the first phase, the request signals are propagated up the tree. Each cell raises the anyreq signal if any of its input request signals is high. This in turn raises the 5 In some designs, for example the HP PA-8000 <ref> [19] </ref>, the entry is freed only after the instruction has been committed i.e. its result value is made part of the architectural state. 27 input request signal of its parent arbiter cell. <p> For example, in the MIPS R10000 [34], the window is partitioned into three sets called the integer queue, floating-point queue, and the address queue. Only instructions in the integer queue are monitored for execution on the two integer functional units. Similarly, in the HP PA-8000 <ref> [19] </ref>, the window 28 is partitioned into the ALU queue and the MEM queue. The ALU queue buffers integer and floating-point instructions. Only instructions in the ALU queue are monitored for execution on the two integer functional units and two floating-point functional units. The MEM queue buffers load/store instructions.
Reference: [20] <author> S. R. Kunkel and J. E. Smith. </author> <title> Optimal Pipelining in Supercomputers. </title> <booktitle> In Proceedings of the 13th Annual International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1986. </year>
Reference-contexts: The current trend in the microprocessor industry is towards deeper pipelining. For example, the pipeline in the Intel Pentium Pro [13] has as many as 14 pipestages. The general subject of the effect of pipelining depth on overall performance has been the focus of a number of studies <ref> [20, 17, 10] </ref>. We took a different approach in our study. We studied the feasibility of pipelining each of the critical structures and identified atomic operations, if any, implemented by the structures.
Reference: [21] <author> Grant McFarland and Michael Flynn. </author> <title> Limits of Scaling MOSFETS. </title> <type> Technical Report CSL-TR-95-662 (Revised), </type> <institution> Stanford University, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: This trend towards smaller devices is likely to continue at least for the next decade [3]. In this section, we briefly discuss the effect of shrinking feature sizes on circuit delays. The effect of scaling feature sizes on circuit performance is an active area of research <ref> [8, 21] </ref>. We are only interested in illustrating the trends in this section. Circuit delays consist of logic delays and wire delays. Logic delays are delays resulting from gates that are driving other gates. <p> First, not all wires reduce in length perfectly (by a factor of S). Second, some of the global wires, like the clock, actually increase in length due to bigger dice that are made possible with each generation. McFarland and Flynn <ref> [21] </ref> studied various scaling schemes for local interconnects and conclude that quasi-ideal scaling scheme as the one that closely tracks future deep submicron technologies. Quasi-ideal scaling performs ideal scaling of the horizontal dimensions but scales the thickness more slowly.
Reference: [22] <author> Meta-Software Inc. </author> <note> HSpice User's Manual, </note> <month> June </month> <year> 1987. </year>
Reference-contexts: In one case, register renaming, we had to study (simulate) two different schemes whose performance was similar. In the second phase we implemented the circuit and optimized the circuit for speed. We used the HSPICE circuit simulator <ref> [22] </ref> from MetaSoftware to simulate the circuits. We mostly used static logic. However, in situations where dynamic logic helped in boosting the performance significantly, we used dynamic logic. For example, in the wakeup logic, we used a dynamic 7-input NOR gate for comparisons instead of a static gate.
Reference: [23] <author> Robert J. Proebsting. </author> <title> Speed Enhancement Technique for CMOS Circuits, </title> <month> January </month> <year> 1991. </year> <title> United States Patent No. </title> <publisher> 4,985,643. </publisher>
Reference-contexts: While it is easy to see how dependence checking can be pipelined, it is not so obvious how the map table access can be pipelined. However, there are schemes <ref> [6, 23] </ref> for pipelining RAMs that can be employed to pipeline the map table access.
Reference: [24] <author> Jan M. Rabaey. </author> <title> Digital Integrated Circuits A Design Perspective. </title> <publisher> Prentice Hall Electronics and VLSI Series, </publisher> <year> 1996. </year>
Reference-contexts: As the feature size is reduced, the supply voltage has to be scaled down to keep the power consumption at manageable levels. Because voltages cannot be scaled arbitrarily they follow a different scaling curve from feature sizes. From <ref> [24] </ref>, for submicron devices, if S is the scaling factor for feature sizes, and U is the scaling factor for supply voltages, then C L , V , and I scale by factors of 1=S, 1=U , and 1=U respectively. <p> Because the delay of a gate is a quadratic function of the fan-in <ref> [32, 24] </ref> we can write the delay as T matchOR = c 0 + c 1 fi IW + c 2 fi IW 2 For the design space we explored (issue widths of 2, 4, and 8), the quadratic component was relatively small.
Reference: [25] <author> K. Rahmat, O. S. Nakagawa, S-Y. Oh, and J. Moll. </author> <title> A Scaling Scheme for Interconnect in Deep-Submicron Processes. </title> <type> Technical Report HPL-95-77, </type> <institution> Hewlett-Packard Laboratories, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: Parallel-plate capacitance is the result of capacitance between the bottom-wall of the wires and the substrate. Assuming that the thickness remains constant, it can be seen from the equation for C metal that the fringe component becomes the dominant component as we move towards smaller feature sizes. In <ref> [25] </ref>, the authors show that as features sizes are reduced, 9 the fringe capacitance will be responsible for an increasingly larger fraction of the total capacitance. For ex-ample, they show that for feature sizes less than 0:1m, the fringe capacitance contributes 90% of the total capacitance.
Reference: [26] <author> Eric Rotenberg, Steve Bennet, and J. E. Smith. </author> <title> Trace Cache: a Low Latency Approach to High Bandwidth Instruction Fetching. </title> <booktitle> In Proccedings of the 29th Annual International Symposium on Microarchitecture, </booktitle> <month> December </month> <year> 1996. </year>
Reference-contexts: Then, non-contiguous blocks of instructions will have to be fetched from the instruction cache and compacted into a contiguous block prior to renaming. The logic required for these operations are described in some detail in <ref> [26] </ref>. However, delay models remain to be developed. And, although they are important, we chose not to consider them here. Finally, we must point out once again that in real designs there may be structures not listed above that may influence the overall delay of the critical path.
Reference: [27] <author> J. E. Smith and A. R. Pleszkun. </author> <title> Implementing Precise Interrupts in Pipelined Processors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37 </volume> <pages> 562-573, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: The dependence check logic detects such dependences and sets up the output MUXes so that the appropriate physical register designators are generated. The shadow table is used to checkpoint old mappings so that the processor can quickly recover to a precise state <ref> [27] </ref> from branch mispredictions 1 .
Reference: [28] <author> M. Suzuki et al. </author> <title> A 1.4ns 32b CMOS ALU in Double Pass-Transistor Logic. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> 28(11), </volume> <month> November </month> <year> 1993. </year> <month> 40 </month>
Reference-contexts: We expect this component of the delay to become relatively less significant as the feature size is reduced. 5.6.3 Results Table 2 shows typical heights of functional units. The lengths were estimated based on data presented in papers <ref> [14, 28, 15] </ref> describing specific implementations of functional units. For example, the height of a complete ALU is 3200 , where is half the feature size. The complete ALU, referred to as ALU gen , comprises an adder, a shifter, and a logic unit.
Reference: [29] <author> Dean M. Tullsen et al. </author> <title> Exploiting Choice: Instruction Fetch and Issue on an Implementable Simultaneous Mul--tithreading Processor. </title> <booktitle> In Proceedings of the 23rd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 191-202, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: For wide issue machines (width greater than 4) some form of clustering will be required to make this feasible. 37 * Register file access Again, the techniques used to pipeline RAM can be employed to pipeline the register file. Tullsen et. al. <ref> [29] </ref> studied the effect of spreading register read over two pipestages. They found that single thread performance degraded by only 2% for their design. Once again, it must be mentioned that instead of pipelining the register file, architects can reduce its latency by duplicating the register file.
Reference: [30] <author> N. Vasseghi et al. </author> <title> 200 MHz Superscalar RISC Processor Circuit Design Issues. </title> <booktitle> In 1996 IEEE International Sold-State Circuits Conference Digest of Technical Papers, </booktitle> <pages> pages 356-357, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: The priority logic slows down because the delay of the logic used to compute priority increases due to the higher fan-in. We found the optimal number of inputs to be four in our case. The selection logic in the MIPS R10000, described in <ref> [30] </ref>, is also based on four-input arbiter cells. 30 5.5.2 Spice Results a single functional unit is being scheduled. The delay is broken down into the three components discussed earlier. From the graph we can see that for all the three technologies, the delay increases logarithmically with window size.
Reference: [31] <author> Tomohisa Wada, Suresh Rajan, and Steven A. Przybylski. </author> <title> An Analytical Access Time Model for On-Chip Cache Memories. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> 27(8) </volume> <pages> 1147-1156, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: In order to provide the necessary load/store bandwidth in a superscalar processor, the cache has to be banked or duplicated. The access time of a cache is a function of the size of the cache and the associativity of the cache. Wada et. al. <ref> [31] </ref> and Wilton and Jouppi [33] have developed detailed models that estimate the access time of a cache given its size and associativity. Again, because it is studied elsewhere, we do not consider cache logic in this report. * Instruction fetch logic Instruction caches are discussed above. <p> Again, we found that the quadratic component is very small relative to the other components. Hence, the overall bitline delay is linearly dependent on the issue width. Sense amplifier delay We used Wada's sense amplifier from <ref> [31] </ref>. Wada's sense amplifier amplifies a voltage difference of 2 fi V bitsense to V dd . Because we assumed single-ended read lines, we tied one of the inputs of the sense amplifier to a reference voltage V ref .
Reference: [32] <author> Neil H.E. Weste and Kamran Eshraghian. </author> <title> Principles of CMOS VLSI Design. </title> <publisher> Addison Wesley, </publisher> <address> Second Edition, </address> <year> 1993. </year>
Reference-contexts: Mappings are checkpointed by copying the current contents of each cell into the shift register. Recovery is performed by writing the bit in the appropriate shift register cell back into the main cell. CAM scheme An alternative scheme for register renaming uses a CAM (content-addressable memory <ref> [32] </ref>) to store the current mappings. Such a scheme is implemented in the HAL SPARC [2] and the DEC 21264 [18]. The number of entries in the CAM is equal to the number of physical registers. Each entry contains two fields. <p> Hence, the overall delay is given by, Delay = T decode + T wordline + T bitline + T senseamp Each of the components is analyzed next. 13 Decoder delay The structure of the decoder is shown in Figure 6. We use predecoding <ref> [32] </ref> to improve the speed of decoding. A 3-bit predecode field generates 8 predecode lines, each of which is fed to 4 row decode gates. The predecode gates are 3-input NAND gates and the row decode gates are 3-input NOR gates. <p> Once all the operands of an instruction become available (both rdyL and rdyR are set), the instruction is ready to execute and the rdy flag is set to indicate this. The issue window is a CAM (content addressable memory <ref> [32] </ref>) array holding one instruction per entry. Buffers, shown at the top of the figure, are used to drive the result tags tag1 to tagW where W is the issue width. <p> Because the delay of a gate is a quadratic function of the fan-in <ref> [32, 24] </ref> we can write the delay as T matchOR = c 0 + c 1 fi IW + c 2 fi IW 2 For the design space we explored (issue widths of 2, 4, and 8), the quadratic component was relatively small.
Reference: [33] <author> Steven J. E. Wilton and Norman P. Jouppi. </author> <title> An Enhanced Access and Cycle Time Model for On-Chip Caches. </title> <type> Technical Report 93/5, </type> <institution> DEC Western Research Laboratory, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: In order to provide the necessary load/store bandwidth in a superscalar processor, the cache has to be banked or duplicated. The access time of a cache is a function of the size of the cache and the associativity of the cache. Wada et. al. [31] and Wilton and Jouppi <ref> [33] </ref> have developed detailed models that estimate the access time of a cache given its size and associativity. Again, because it is studied elsewhere, we do not consider cache logic in this report. * Instruction fetch logic Instruction caches are discussed above. <p> The process parameters for the 0:8m CMOS process were taken from [16]. These parameters were used by Wilton and Jouppi in their study of cache access times <ref> [33] </ref>. Because process parameters are proprietary information, we had to use extrapolation to come up with process parameters for the 0:35m and 0:18m technologies. We used the 0:8m process parameters, 0:5m process parameters from MOSIS, and process parameters used in the literature as inputs.
Reference: [34] <author> K. C. Yeager. </author> <title> MIPS R10000 Superscalar Microprocessor. </title> <booktitle> In IEEE Micro, </booktitle> <month> April </month> <year> 1996. </year> <month> 41 </month>
Reference-contexts: These two schemes, called the RAM scheme and the CAM scheme, are described next. RAM scheme In the RAM scheme, as implemented in the MIPS R10000 <ref> [34] </ref>, the map table is a register file where each entry contains the physical register that is mapped to the logical register whose designator is used to index the table. The number of entries in the map table is equal to the number of logical registers. <p> The stacked design might not be a feasible alternative beyond two functional units because the resulting delay can be significant. An alternative option is to statically partition the window entries among the functional units. For example, in the MIPS R10000 <ref> [34] </ref>, the window is partitioned into three sets called the integer queue, floating-point queue, and the address queue. Only instructions in the integer queue are monitored for execution on the two integer functional units.
References-found: 34

