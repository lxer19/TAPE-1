URL: http://www.cs.wisc.edu/~cao/WISP98/final-versions/davidm.ps
Refering-URL: http://www.cs.wisc.edu/~cao/WISP98-program.html
Root-URL: http://www.cs.wisc.edu
Email: davidm@hpl.hp.com,  tai@hpl.hp.com,  
Title: httperfA Tool for Measuring Web Server Performance  
Author: David Mosberger Tai Jin 
Web: http://www.hpl.hp.com/personal/David Mosberger/  http://www.hpl.hp.com/personal/Tai Jin/  
Affiliation: HP Research Labs  HP Research Labs  
Abstract: This paper describes httperf, a tool for measuring web server performance. It provides a flexible facility for generating various HTTP workloads and for measuring server performance. The focus of httperf is not on implementing one particular benchmark but on providing a robust, high-performance tool that facilitates the construction of both micro- and macro-level benchmarks. The three distinguishing characteristics of httperf are its robustness, which includes the ability to generate and sustain server overload, support for the HTTP/1.1 protocol, and its extensibility to new workload generators and performance measurements. In addition to reporting on the design and implementation of httperf this paper also discusses some of the experiences and insights gained while realizing this tool. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Gaurav Banga and Peter Druschel. </author> <title> Measuring the capacity of a web server. </title> <booktitle> In USENIX Symposium on Internet Technologies and Systems, </booktitle> <pages> pages 6171, </pages> <address> Monterey, CA, </address> <month> December </month> <year> 1997. </year> <note> http://www.usenix.org/publications/library/proceedings/usits97/banga.html. </note>
Reference-contexts: Given that the potential user base of an Internet-based server is on the order of hundreds of millions of users it is clear that simulating a fixed and relatively small number of clients is often insufficient. For this reason, Banga and Druschel <ref> [1] </ref> recently argued the case for measuring web servers with tools that can generate and sustain overload, which is effectively equivalent to simulating an infinite user base. They also presented a tool called s-clients that is capable of generating such loads.
Reference: [2] <author> R. Fielding, J. Gettys, J. Mogul, H. Frystyk, and T. Berners-Lee. </author> <title> Hypertext Transfer Protocol HTTP/1.1. Internet Engineering Task Force, </title> <month> January </month> <year> 1997. ftp://ftp.internic.net/rfc/rfc2068.txt. </year>
Reference-contexts: 1 Introduction A web system consists of a web server, a number of clients, and a network that connects the clients to the server. The protocol used to communicate between the client and server is HTTP <ref> [2] </ref>. In order to measure server performance in such a system it is necessary to run a tool on the clients that generates a specific HTTP workload. Currently, web server measurements are conducted using bench marks such as SPECweb or WebStone [6, 8] which simulate a fixed number of clients. <p> In the third part, we mention some possible future directions for httperf. The HTTP core engine in httperf currently supports both HTTP/1.0 and HTTP/1.1. Among the more interesting features of this engine are support for: persistent connections, request pipelining, and the chunked transfer-encoding <ref> [2, 4] </ref>. Higher-level HTTP processing is enabled by the fact that the engine exposes each reply header-line and all of the reply body to the other parts of httperf by signalling appropriate events.
Reference: [3] <author> Rai Jain. </author> <title> The Art of Computer Systems Performance Analysis. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: This allows observing throughput during all phases of a test. Also, with a sample period of 5 seconds, running a test for at least 3 minutes results in enough throughput samples that confidence intervals can be computed without having to make assumptions on the distribution of the samples <ref> [3] </ref>. 4 Implementation In this section, we first present the capabilities of the current version of httperf and then we discuss some of the more subtle implementation issues dis covered so far. In the third part, we mention some possible future directions for httperf.
Reference: [4] <author> H. Nielsen, J. Gettys, A. Baird-Smith, E. Prud'hommeaux, Hakon W. Lie, and C. Lilley. </author> <title> Network performance effects of HTTP/1.1, CSS1, </title> <booktitle> and PNG. In Proceedings of SIGCOMM '97 Symposium, </booktitle> <pages> pages 155166, </pages> <address> Cannes, France, </address> <month> October </month> <year> 1997. </year> <journal> Association of Computing Machinery. </journal> <note> http://www.acm.org/sigcomm/sigcomm97/papers/p102.html. </note>
Reference-contexts: In the third part, we mention some possible future directions for httperf. The HTTP core engine in httperf currently supports both HTTP/1.0 and HTTP/1.1. Among the more interesting features of this engine are support for: persistent connections, request pipelining, and the chunked transfer-encoding <ref> [2, 4] </ref>. Higher-level HTTP processing is enabled by the fact that the engine exposes each reply header-line and all of the reply body to the other parts of httperf by signalling appropriate events.
Reference: [5] <author> Jon Postel. </author> <title> Transmission Control Protocol. </title> <booktitle> DARPA, </booktitle> <month> September </month> <year> 1981. </year> <month> ftp://ftp.internic.net/rfc/rfc793.txt. </month>
Reference-contexts: Since a given port number cannot be reused until the TCP TIME WAIT state expires, this can seriously limit the client sustainable offered rate. Specifically, with a 1 minute timeout (common for BSD-derived OSes) the maximum sustainable rate per client is about 1,075 requests per second. With the RFC-793 <ref> [5] </ref> recommended value of 4 minutes, the maximum rate would drop to just 268 requests per second. Number of open file descriptors: Most operating systems limit both the total and per-process number of file descriptors that can be opened.
Reference: [6] <author> SPEC. </author> <title> An explanation of the SPECweb96 benchmark, </title> <month> December </month> <year> 1996. </year> <note> http://www.specbench.org/osg/web96/webpaper.html. </note>
Reference-contexts: In order to measure server performance in such a system it is necessary to run a tool on the clients that generates a specific HTTP workload. Currently, web server measurements are conducted using bench marks such as SPECweb or WebStone <ref> [6, 8] </ref> which simulate a fixed number of clients. Given that the potential user base of an Internet-based server is on the order of hundreds of millions of users it is clear that simulating a fixed and relatively small number of clients is often insufficient.
Reference: [7] <author> Richard W. Stevens. </author> <title> TCP/IP Illustrated: The Protocols, volume 1. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1994. </year>
Reference-contexts: that care should be taken to avoid unnecessary background tasks on the client machine while a test is in progress. 4.2 Limited Number of Ephemeral Ports Many TCP implementations restrict the TCP ports available to sockets that are not bound to a specific local address to the so-called ephemeral ports <ref> [7] </ref>. Ephemeral ports are typically in the range from 1,024 to 5,000. This has the unfortunate effect that even moderate request rates may cause a test client to quickly run out of port numbers.
Reference: [8] <author> Gene Trent and Mark Sake. WebSTONE: </author> <title> The first generation in HTTP server benchmarking, </title> <month> February </month> <year> 1995. </year> <note> http://www.mindcraft.com/webstone/paper.html. </note>
Reference-contexts: In order to measure server performance in such a system it is necessary to run a tool on the clients that generates a specific HTTP workload. Currently, web server measurements are conducted using bench marks such as SPECweb or WebStone <ref> [6, 8] </ref> which simulate a fixed number of clients. Given that the potential user base of an Internet-based server is on the order of hundreds of millions of users it is clear that simulating a fixed and relatively small number of clients is often insufficient.
References-found: 8

