URL: http://www.ultimode.com/wray/thesis.ps.gz
Refering-URL: http://WWW.Ultimode.com/~wray/refs.html
Root-URL: 
Title: A THEORY OF LEARNING CLASSIFICATION RULES  
Author: Wray Lindsay Buntine 
Degree: a dissertation submitted to the  in fulfillment of the requirements for the degree of doctor of philosophy By  
Date: November 1992  
Address: sydney  
Affiliation: school of computing science in the university of technology,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. </author> <title> Abramowitz and I.A. Stegun. Handbook of Mathematical Functions. </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: Given the example space X and the classified example space, E = X fi ftrue; f alseg, a noise filter specifies how noise will alter a classified example. It can be represented as a function N from E fi E to <ref> [0; 1] </ref>, where N (e 1 ; e 2 ) denotes the probability that e 1 will be converted by noise to e 2 . <p> Examples of the Prolog reverse predicate can be found by a combined process of resolution and instantiation from a Prolog reverse program, as for instance, given in Figure 3.5. For instance, the example reverse ([1; 2; 3]; <ref> [3; 2; 1] </ref>) can be found by a resolution proof from the reverse program proving reverse ([X; Y; Z]; [Z; Y; X]), together with an instantiation of X to 1, Y to 2 and Z to 3. A generation protocol needs to specify this process. <p> The probability of the example reverse ([1; 2; 3]; <ref> [3; 2; 1] </ref>) been generated by this program is then is then 2 3 3 1 2 3 . This is because the first reverse1 clause occurs once in the proof, the second reverse1 clause three times, and then three variables are instantiated to 1, 2 and 3. <p> The result follows assuming the true concept is in the hypothesis space, since it then will be one of the consistent hypotheses. 2 Fast formulae for computing the incomplete beta function and its inverse are available in mathematical and numerical handbooks <ref> [1, 71] </ref>. To give an idea of the behaviour of beta error, a approximation can be constructed as follows. The beta distribution for sufficiently large parameters can be approximated using the normal distribution.
Reference: [2] <author> D.W. Aha and D. Kibler. </author> <title> Noise-tolerant instance-based learning algorithm. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 794-799, </pages> <address> Detroit, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Examples of the Prolog reverse predicate can be found by a combined process of resolution and instantiation from a Prolog reverse program, as for instance, given in Figure 3.5. For instance, the example reverse ([1; 2; 3]; <ref> [3; 2; 1] </ref>) can be found by a resolution proof from the reverse program proving reverse ([X; Y; Z]; [Z; Y; X]), together with an instantiation of X to 1, Y to 2 and Z to 3. A generation protocol needs to specify this process. <p> The probability of the example reverse ([1; 2; 3]; <ref> [3; 2; 1] </ref>) been generated by this program is then is then 2 3 3 1 2 3 . This is because the first reverse1 clause occurs once in the proof, the second reverse1 clause three times, and then three variables are instantiated to 1, 2 and 3. <p> The experiments serve as an interesting study in their own right, however, because few comparative studies of this scale have been made. While many of the data sets used have results already multiply reported in the literature <ref> [102, 17, 23, 26, 75, 2] </ref>, comparisons with literature results will not be made in this and later experiments (although general comparisons were made during implementation of the algorithms as a safety check).
Reference: [3] <author> J. </author> <title> Amsterdam. Extending the Valiant learning model. </title> <booktitle> In Fifth International Conference on Machine Learning, </booktitle> <pages> pages 381-394, </pages> <address> Ann Arbor, Michigan, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: What, for instance, is being averaged over? Simulations reported in Chapter 5 indicate just what a huge gap exists between current theoretical error bounds and the kinds of errors that might occur in practice. Amsterdam <ref> [3] </ref> has said Valiant's formal model of concept learning : : : has rarely been used in practice, in part because the known learnable concept classes are too restricted. <p> Examples of the Prolog reverse predicate can be found by a combined process of resolution and instantiation from a Prolog reverse program, as for instance, given in Figure 3.5. For instance, the example reverse ([1; 2; 3]; <ref> [3; 2; 1] </ref>) can be found by a resolution proof from the reverse program proving reverse ([X; Y; Z]; [Z; Y; X]), together with an instantiation of X to 1, Y to 2 and Z to 3. A generation protocol needs to specify this process. <p> The probability of the example reverse ([1; 2; 3]; <ref> [3; 2; 1] </ref>) been generated by this program is then is then 2 3 3 1 2 3 . This is because the first reverse1 clause occurs once in the proof, the second reverse1 clause three times, and then three variables are instantiated to 1, 2 and 3. <p> The Valiant model has also received strong criticism from 64 CHAPTER 5. EXTENSIONS TO VALIANT'S FRAMEWORK 65 Amsterdam for its poor track record in applied learning <ref> [3] </ref>, and for its restricted scope [4]. The Valiant model is becoming recognised as a standard for formal learning theory and several extensions exist [6, 3, 83]. <p> EXTENSIONS TO VALIANT'S FRAMEWORK 65 Amsterdam for its poor track record in applied learning [3], and for its restricted scope [4]. The Valiant model is becoming recognised as a standard for formal learning theory and several extensions exist <ref> [6, 3, 83] </ref>. But if it is to be a standard, we should heed Amsterdams criticisms and first consider just how well the Valiant model handles its intended task, without extensions and considering only its (admittedly restricted) current scope.
Reference: [4] <author> J. </author> <title> Amsterdam. Some philosophical problems with formal learning theory. </title> <booktitle> In Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 580-584, </pages> <address> Saint Paul, Minnesota, </address> <year> 1988. </year>
Reference-contexts: Amsterdam has also highlighted what most applied learning researchers knew from the outset: the Valiant theory is too restricted in scope <ref> [4] </ref>. The theory fails to handle uncertain concepts, which are most common in practice, and does not address issues regarding the utility of knowledge, such as comprehensibility. The theory is, however, in a fairly early stage of development, and many such issues are currently being addressed. <p> The Valiant model has also received strong criticism from 64 CHAPTER 5. EXTENSIONS TO VALIANT'S FRAMEWORK 65 Amsterdam for its poor track record in applied learning [3], and for its restricted scope <ref> [4] </ref>. The Valiant model is becoming recognised as a standard for formal learning theory and several extensions exist [6, 3, 83].
Reference: [5] <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-343, </pages> <year> 1988. </year>
Reference-contexts: An oracle may, for instance, be a human expert on the concept who is able to correctly classify examples of the concept. A commonly considered query is "what is the class of example x?" Angluin refers to these as membership queries, and lists some other query types <ref> [5] </ref> such as subset queries that ask whether the logical concept suggested is a subset of the "true" one. Only queries with a "yes" or "no" answer will be considered in this thesis. For the query protocol the learner deterministically selects an admissible question to ask of the oracle. <p> The incremental induction problem [51], is concerned with economising computational cost as well as prediction errors while new examples are being presented. The relationship between queries and computational utility of learning is discussed by Angluin <ref> [5] </ref>. Utility of the concept representation: The utility of the representation of a concept can be measured in terms of its comprehensibility [75, 64] or, as in explanation based learning, its computational efficiency or operationality [72, 59]. Learning requires that an appropriate representation for the concept be found.
Reference: [6] <author> D. Angluin and P. Laird. </author> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370, </pages> <year> 1988. </year>
Reference-contexts: Results from the Valiant style theory of machine learning are based on searching for any hypothesis consistent with the sample [38], and in the context of noise, any hypothesis that has the least number of inconsistencies with the sample <ref> [6] </ref>. Both these suggestions go against the grain of much applied work in machine learning. They are, however, quite appropriate when the sample is sufficient and we are not also concerned with, for instance, the comprehensibility of the concept. <p> This has been widely followed in theoretical computer science. In this section we look merely at the statistical component of Valiant's framework and consider the potential shortcomings of the simple model Valiant has adopted. 4.2.1 PACness Angluin and Laird precis the statistical component of the Valiant model as follows <ref> [6] </ref>: The idea is that after randomly sampling [classified examples] of a concept, an identifi cation procedure should conjecture a concept that with "high probability" is "not too different" from the correct concept. <p> EXTENSIONS TO VALIANT'S FRAMEWORK 65 Amsterdam for its poor track record in applied learning [3], and for its restricted scope [4]. The Valiant model is becoming recognised as a standard for formal learning theory and several extensions exist <ref> [6, 3, 83] </ref>. But if it is to be a standard, we should heed Amsterdams criticisms and first consider just how well the Valiant model handles its intended task, without extensions and considering only its (admittedly restricted) current scope.
Reference: [7] <author> D. Angluin and C.H. Smith. </author> <title> Inductive inference: Theories and methods. </title> <journal> Computing Surveys, </journal> <volume> 15(3) </volume> <pages> 237-269, </pages> <year> 1983. </year>
Reference-contexts: The chapter is built around a framework for induction in both the logical and the uncertain contexts. The framework is based on ideas from Valiant [99] and Angluin and Smith <ref> [7] </ref>, but has been configured so that it is suitable for applying Bayesian principles. The resultant theory gives a precise and statistically founded basis for Mitchell's notion of induction "as search" [61], specifying suitable search spaces and search heuristics for different learning contexts. <p> COMPARISONS 47 4.1 Gold's paradigm A general paradigm of inductive inference|learning concepts in an uncertainty-free context|was outlined by Gold [35] in the late '60s. Considerable extensions to the paradigm have been made since <ref> [7] </ref>. The theory has its roots in computability and the theory of recursive functions.
Reference: [8] <author> J. O. Berger. </author> <title> Statistical Decision Theory and Bayesian Analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: This feature has been described as the "accuracy vs. complexity tradeoff" and various studies exist on this in the machine learning literature [75, 31]. This problem is widely acknowledged outside machine learning and a variety of approaches exist <ref> [33, 100, 8] </ref>. Should these approaches be applied to the machine learning techniques developed within the AI community. <p> Should we model classification rules by noise-free decision trees [73], Bayes nets [67], linear classifiers, class probability trees, or perhaps even rules in a pseudo 1st-order logic such as Datalog? The correct choice of model is known to have considerable bearing on statistical problems like learning <ref> [8, p110] </ref>, The choice should be made in the light of subjective knowledge available about the domain, for instance, elicited in an interview with an expert. <p> Chapter 2 An Introduction to Bayesian Analysis The basic statistical theory used in this thesis is Bayesian decision theory. Bayesian methods offer a unified and well developed approach to a broad class of problems in statistics and decision making <ref> [8] </ref> and a growing class of problems under the general banner of intelligent systems [67]. It is not in the scope of this thesis to attempt to justify this choice in statistics. There is already ample material on this. The approach has strong foundations [8] and typically gives results in accord <p> problems in statistics and decision making <ref> [8] </ref> and a growing class of problems under the general banner of intelligent systems [67]. It is not in the scope of this thesis to attempt to justify this choice in statistics. There is already ample material on this. The approach has strong foundations [8] and typically gives results in accord with intuition [67, 70]. Discussions of criticisms about the approach are documented by Berger [8] and Cheeseman [24], and appraisals and comparisons of the approach and other uncertainty approaches from an artificial intelligence perspective are given by Horvitz, Heckerman and Langlotz [41]. <p> There is already ample material on this. The approach has strong foundations <ref> [8] </ref> and typically gives results in accord with intuition [67, 70]. Discussions of criticisms about the approach are documented by Berger [8] and Cheeseman [24], and appraisals and comparisons of the approach and other uncertainty approaches from an artificial intelligence perspective are given by Horvitz, Heckerman and Langlotz [41]. <p> For discrete domains, for instance, this is given by P r (A) = H2H; A holds in H P r (H) = E H 1 AjH : 2.2 Basic principles Two simple principles underlie the Bayesian approach <ref> [8] </ref>. <p> This is a controversial issue in statistics because priors are considered to introduce a "subjective" component into statistical reasoning and because many consider it is not always possible to introduce priors for a given problem. Appropriate discussions on this aspect can be found in <ref> [8, p109] </ref>. We take the approach here that the use of prior probabilities is unavoidable. A non-Bayesian method, for instance, can be said to make an implicit assumption about a prior. There can, of course, be no objection to the careful application of such a method in practice. <p> We can, however, minimise the pitfalls of working with priors by the use of non-informative priors, the use of priors leaning towards non-informative, or the use of sensitivity analysis (working with a range of priors) or other robustness techniques (see <ref> [8, Sct. 4.7] </ref>). A discussion of these notions can be found in some introductory texts on Bayesian statistics, we shall not assume knowledge of them here. In the usual knowledge acquisition context, priors are a mechanism for introducing an expert's hunches and intuition into the statistical process. <p> If we really have no additional knowledge about the class proportions then we should use what is referred to as a non-informative prior. These are priors intended to be as non-informative as possible, to represent the least amount fo information. Various arguments <ref> [8] </ref> lead to the use of a symmetric Dirichlet prior of the form P r () / i=1 i ; CHAPTER 2. AN INTRODUCTION TO BAYESIAN ANALYSIS 20 where ff is usually given the value 0.5, and ff = 1:0 corresponds to the uniform prior. <p> The prior parameter ff is in each of these cases is varied from 0:25, 0:5, 0:75, 1:0 to 1:25. This gives some idea of the impact of prior belief on posterior belief. The general technique of varying the prior within reasonable bounds is referred to as sensitivity analysis <ref> [8] </ref>. Notice how the impact of the prior decreases as the sample size increases. For large sample sizes, the prior can be ignored within reason. CHAPTER 2. <p> The entropy function has been used by Quinlan and others to devise a heuristic for building decision trees [73]. Some useful expectations of the Dirichlet distribution follow by manipulating Equation 2.3a. Below, the means, variances, and covariances are given (from <ref> [8] </ref>). <p> CHAPTER 3. BASIC LEARNING THEORY 41 We briefly review the first two questions in this section. For the questions of appropriateness, a related topic in the Bayesian literature is robustness <ref> [8, Sct. 4.7] </ref>, which is a methodology for hedging against inappropriateness at the outset. The first question considered here is the choice of actions. 3.4.1 Making Actions Depending on the protocol, the learner may have a number of actions available for improving performance. <p> The best that can be done by a learning system is perhaps measure how sensitive any actions made by the learner are to the choice of utility function. Methods for considering appropriateness in Bayesian statistics fall under the category of robustness methods 1 <ref> [8, Sct. 4.7] </ref>. There are methods for model robustness, prior robustness and utility robustness corresponding to the above appropriateness checks. In this section, we will consider how to check the hypothesis space given that the protocol likelihood function is considered correct. <p> An indication that there exists a reasonable extension to the space containing a hypothesis giving a significantly better fit to the data is whether the current hypothesis space only contains hypotheses giving relatively poor fit to the data. Some measures of "relatively poor fit", following Berger <ref> [8, p 201] </ref>, are * if P r (~c j ~x; H) is significantly less than maximum ~ d P r ( ~ d j ~x; H), * if P r (~c j ~x; H) is significantly less than E ~ d * if P r (~c j ~x; H) is <p> COMPARISONS 50 independently and identically distributed sample is equivalent to l (x j ) for some , then posterior belief given the sample will be concentrated about (see, for instance, <ref> [8, p224] </ref>). The first identification result follows from such an asymptotic result by a change of variables. While the result holds for finite discrete example spaces given proper priors, a similar result should hold for infinite discrete or continuous example spaces 2 . <p> To extend this result to continuous example spaces, one would need to consider identification in belief to a set of hypotheses arbitrarily close to the true hypothesis. 2 Berger <ref> [8, p224] </ref> gives a result that would handle the case of continuous example spaces given twice differentiable likelihoods. CHAPTER 4. <p> the terminology of this chapter, given evidence E, the one version of the MML approach finds a hypothesis H and additional parameters that maximises the quantity [100, p245,p248] P r (H; )P r (E j H; ) I E (H; ) where I E (H; ) is the Fisher information <ref> [8, p88] </ref> for evidence E given by det E E~H; D 2 log P r (E j H; ) ; (4.25) where det () corresponds to the standard matrix determinant, are the jHj + jj continuous pa rameters in the model for H; , and D 2 D D is the <p> The shortcomings may be viewed as symptomatic of the underlying pseudo-classical statistical philosophy of PACness in the Valiant model, as discussed previously. The main theoretical machinery that the Bayesian approach here adds is the notion of a prior. While priors certainly have to be used with caution <ref> [8, p109] </ref>, there use allows a much more powerful statistical analysis of the logical induction problem that still shares all the "distribution-free" advantages of the Valiant model [38, p179], albeit in an average-case rather than worst-case sense. 5.2 The Blumer bound and its use Blumer, Ehrenfuecht, Haussler and Warmuth [9] have
Reference: [9] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M.K. Warmuth. </author> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 377-380, </pages> <year> 1987. </year>
Reference-contexts: For instance, one hopes to find an algorithm and bounds relating *, ffi, C, and the sample size that guarantee learnability. Most work rests on two theorems, the Blumer, Ehrenfeucht, Haussler and Warmuth bound <ref> [9] </ref>, introduced and discussed further in Chapter 5, and a bound using the Vapnik-Chervonenkis dimension [38]. To ensure PAC-learnability, these need to be coupled with a polynomial time algorithm for finding a hypothesis consistent with a sample. <p> caution [8, p109], there use allows a much more powerful statistical analysis of the logical induction problem that still shares all the "distribution-free" advantages of the Valiant model [38, p179], albeit in an average-case rather than worst-case sense. 5.2 The Blumer bound and its use Blumer, Ehrenfuecht, Haussler and Warmuth <ref> [9] </ref> have developed a bound that allows the classical notion of PACness to be determined.
Reference: [10] <author> J.H. Boose. </author> <title> Expertise Transfer for Expert System Design. </title> <publisher> Elsevier, </publisher> <year> 1986. </year>
Reference-contexts: Also, the expert could appraise results of induction and possibly resubmit certain fragments for further processing. There are, of course, other methods being used for obtaining subjective knowledge from an expert: the traditional manual knowledge acquisition method [39], and hybrid methods such as computer-aided interviewing <ref> [10] </ref> and computer-aided knowledge refinement [69]. Although the use CHAPTER 1. INTRODUCTION 10 of sophisticated aids for input, interviewing and editing is improving the speed of these interview-driven methods, they are still time intensive for the expert. Problems over and above this slow development time exist with these methods.
Reference: [11] <author> I. Bratko and I. Kononenko. </author> <title> Learning diagnostic rules from incomplete and noisy data. </title> <booktitle> In AI Methods in Statistics, </booktitle> <pages> pages 67-83, </pages> <address> Uxbridge, 1986. </address> <publisher> Unicom seminars. </publisher>
Reference-contexts: There are three acknowledged problems with the information gain splitting rule. CHAPTER 6. LEARNING CLASS PROBABILITY TREES 106 Multi-valued attributes: If the attributes being tested are a mixture of binary and multi-valued attributes, then the splitting rule tends to detrimentally favour the multi-valued at tributes <ref> [73, 11] </ref>. Real valued attributes: Similarly to the above, the splitting rule tends to detrimentally favour splitting on real valued attributes, and to choose cut-points too close to the extreme values (Breiman et al. call this end-cut preference [12]).
Reference: [12] <author> L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont, </address> <year> 1984. </year>
Reference-contexts: Again good ideas were the initial motivational forces. Hunt's learning system, CLS, has lead to a line of decision tree learning systems such as ID3 and its various commercial derivatives [73], and a parallel family of systems have been developed independently in the applied statistics area <ref> [12] </ref>. The early systems were quite simple and gave promising results, and were followed by a sequence of extensions and experimental studies that gradually identified further problems and suggested more good ideas for their solution. <p> To an extent, part of this theoretical work has been done by Breiman, Friedman, Olshen and Stone <ref> [12] </ref>, however their analysis is according to classical statistics so only looks at these systems from one viewpoint. It is a starting point for this thesis that research on empirical learning within the machine learning community is at a similar juncture. <p> For many learning systems in the literature, ideal search bias is never actually specified. Some notable exceptions are the decision tree work of Breiman et al. <ref> [12] </ref> and Quinlan and Rivest [78]. Many publications describe an algorithm and results of the algorithm but never actually describe in general goal oriented terms what the algorithm should be trying to achieve, though they give a description of what the algorithm actually achieves. <p> Partitioning methods: These approaches parallel the various rule and decision tree building methods being developed in artificial intelligence. Perhaps the state of the art here is the CART system <ref> [12] </ref>. Discriminant analysis methods, common for instance in credit scoring, make the strong assumption of normality in the data. This also assumes the examples are described by real valued attributes and not discrete attributes. <p> These strong assumptions usually cause problems in practice and lead to the rise of the kernel density and nearest neighbour methods. But Breiman, Friedman, Olshen and Stone have the following to say 4 about these <ref> [12, p17] </ref>. The kernel density estimation and kth nearest neighbour methods make minimal assumptions about the form of the underlying distribution. But there are serious limita tions common to both methods. 1. <p> An alternative approach to parameter estimation is the use of cross-validation, and a number of related methods that attempt to manufacture extra samples from the current sample. Such methods have been widely used in partitioning approaches, for instance <ref> [12, 28] </ref>. <p> There are two main motives for such a study. First, it is unclear how Bayesian methods will perform in this learning task, and in particular, whether they will offer any clear advantage over existing methods. The statistical approaches, such as as CART <ref> [12] </ref>, are particularly suited to the context of a sufficient sample, and by association should perform quite well for smaller sample sizes as well. <p> We begin, however, with a brief historical sketch in Section 6.1. 6.1 Historical sketch A standard technique for building classification rules from data is the so called recursive partitioning algorithm that forms the basis of systems such as ID3 [73] and CART <ref> [12] </ref>. These algorithms build a tree such as the one shown in Figure 6.25 which has the classes hyperthyroid and not. <p> Later separate work by applied statisticians developed the methods as non-parametric alternatives to discriminant analysis and nearest-neighbour methods, culminating in the widely known book by Breiman, Friedman, Olshen and Stone <ref> [12] </ref> and the commercially available computer program CART. In computer science decision trees were used to convert decision tables to nested "if-then" rules. Eventually Hyafil and Rivest [45] showed the problem was actually NP-complete. <p> GINI index of diversity: minimise the risk involved when making predictions once having made the test <ref> [12] </ref>: G (classjtest) = T X P r (outcome i) G (classjoutcome i) CHAPTER 6. <p> The test that yields the best evaluation is chosen. 6.2.3 Pruning rules Pruning is considered to be the most important part of the tree building task in noisy domains <ref> [12] </ref>. Most approaches work using estimates of error and attempt to find a subtree of the grown tree that minimises this error estimate. Because the trees have been grown to "fit the data", these error estimates are usually fairly coarse. <p> The first uses a test set to estimate error and determine at which level cost complexity pruning should be done. CHAPTER 6. LEARNING CLASS PROBABILITY TREES 94 The cost complexity pruning algorithm with test set <ref> [12, p79,p309] </ref> uses cost complexity to give an easily computed nested sequence of subtrees and a test set to give "honest" error estimates for these subtrees. <p> The pruned subtree is now the R ff -minimising subtree at the maximum level of ff so that the subtree has a substitution error estimate from the test set of less than R 0 + X SE 0 . The cost complexity pruning algorithm with cross validation <ref> [12, p79,p309] </ref> uses cross validation to form test sets instead. This is identical except that cross validation is used to estimate error. This also means the approach incorporates tree growing. Cross validation applies to tree growing methods, not individual trees. The approach is given in Figure 6.31. <p> Because of this, any comparisons across separate studies will be weak at best unless both authors used an approach such as leaving-one-out cross-validation to report accuracy <ref> [12, 102] </ref>. 6.4.1 Experiment outline These experiments combine several splitting rules with several pruning rules and evaluate the resultant tree growing method on several different size test sets from a varied collection of data sets. <p> Performance of the current system was checked with earlier versions to ensure no bugs were introduced during rewriting. Extensions included in the current implementation include an experiment control and analysis suite, cost complexity pruning methods (taken from <ref> [12] </ref>), and the Bayesian methods reported in Section 6.6. The original Bayesian splitting rule reported in Section 6.6 was implemented by Chris Carter, although the current version has been rewritten. <p> The original Bayesian splitting rule reported in Section 6.6 was implemented by Chris Carter, although the current version has been rewritten. The most likely place for bugs in the existing implementation is in the cost complexity pruning module, though this works on several test cases exactly as described in <ref> [12] </ref>. 6.4.3 Data sets This section describes data sets that were used in this and later experiments. <p> The class is whether the human subject made a left or right bang, and recorded over 1800 different decision circumstances. LED The "LED" data set is the Breiman et al.'s classic manufactured test data on the digit recognition problem <ref> [12] </ref>. There are ten classes, representing whether a faulty LED is showing 0-9. The seven binary valued attributes record whether each of the seven LED elements (one on top and on bottom, two on each side and one horizontally in the centre) is on or off. <p> Real valued attributes: Similarly to the above, the splitting rule tends to detrimentally favour splitting on real valued attributes, and to choose cut-points too close to the extreme values (Breiman et al. call this end-cut preference <ref> [12] </ref>). Preference for extreme partitions: The splitting rule tends to choose tests partitioning the data into a small and a large set rather than equal size sets. In some cases, we would like more equal partitions [57]. This was discussed in the previous section.
Reference: [13] <editor> B.G. Buchanan and E.A. Feigenbaum. DENDRAL and META-DENDRAL: </editor> <title> there applications dimension. </title> <journal> Artificial Intelligence, </journal> <volume> 11 </volume> <pages> 5-24, </pages> <year> 1978. </year>
Reference-contexts: There are notable exceptions such as the META-DENDRAL experiments <ref> [13] </ref>. Whereas fields such as explanation-based learning, analogical learning, and knowledge-base refinement certainly embrace the strong knowledge principle, in empirical learning, as it is often described in the literature, one simply picks a universal learning method, inputs the data and then receive as output a classification rule.
Reference: [14] <author> W.L. Buntine. </author> <title> Generalised subsumption and its applications to induction and redundancy. </title> <journal> Artificial Intelligence, </journal> <volume> 36(2) </volume> <pages> 149-176, </pages> <year> 1988. </year> <note> 162 BIBLIOGRAPHY 163 </note>
Reference-contexts: While early logical induction systems like Marvin [86] and subsequent systems such as CIGOL [65] do appear to incorporate background knowledge, they usually do so to extend the search space rather than to guide the search <ref> [14] </ref>. Some successful machine learning methodologies do incorporate weaker application specific knowledge by some means. Two approaches are the careful selection of attributes in which examples are described [77, 55] and the use of various forms of interaction with an expert [90, 56, 20].
Reference: [15] <author> W.L. Buntine. </author> <title> Decision tree induction systems: a Bayesian analysis. </title> <editor> In L. N. Kanal, T. S. Levitt, and J. F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3. </booktitle> <publisher> Elsevier Science Publishers, </publisher> <address> Amsterdam, </address> <year> 1989. </year>
Reference-contexts: Assuming that belief in hypotheses and the distribution of examples are a prior independent (that is P r (H; ) = P r (H)P r ()), the belief updating formulae CHAPTER 3. BASIC LEARNING THEORY 31 in this case (the general case is worked through in <ref> [15] </ref>) become P r (H j x; c) / f (c j x; H) P r (H) ; (3.11) The belief updating formulae for a set of random examples (x i ; c i ) for i = 1; : : : ; N are P r (H j ~x; ~c)
Reference: [16] <author> W.L. Buntine. </author> <title> Inductive knowledge acquisition and inductive methodologies. </title> <journal> Knowledge-Based Systems, </journal> <volume> 2(1), </volume> <year> 1989. </year>
Reference-contexts: Empirical learning, in this context, would be the learning of the classification rule from a set of historical medical records which already have the correct class attached. The knowledge acquisition environment provides specific goals for and constraints on an empirical learning system <ref> [16] </ref>: the system should fit neatly into some broader knowledge acquisition strategy, the system should be able to take advantage of any additional information over and above the examples, for instance, acquired interactively from an expert, the system should only require the use of readily available information, and of course the
Reference: [17] <author> W.L. Buntine. </author> <title> Learning classification rules using Bayes. </title> <booktitle> In Proceedings of the Sixth International Machine Learning Workshop, </booktitle> <publisher> Cornell, </publisher> <address> New York, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In addition, Bayesian statistics, with its notion of subjective knowledge or prior belief, could provide a means by which application specific knowledge can be cautiously incorporated into the learning process <ref> [17] </ref>. <p> These essentially allow a modular decomposition of the attribute space using principles of independence, sometimes guided by intuition about causality. The simplest example is the simple (or "idiot") Bayes classifier which assumes all attributes are independent given class. These are highly competitive with trees on some problems <ref> [17, 23] </ref> and there is little doubt that with more thorough net learning approaches, this competitive performance can be considerably improved. <p> The experiments serve as an interesting study in their own right, however, because few comparative studies of this scale have been made. While many of the data sets used have results already multiply reported in the literature <ref> [102, 17, 23, 26, 75, 2] </ref>, comparisons with literature results will not be made in this and later experiments (although general comparisons were made during implementation of the algorithms as a safety check).
Reference: [18] <author> W.L. Buntine. </author> <title> Stratifying samples to improve learning. </title> <booktitle> In Proceedings of the Knowledge Discovery in Databases Workshop, </booktitle> <address> Detroit, </address> <year> 1989. </year>
Reference-contexts: Notice that the process as it is specified is strictly not an independent protocol. Some experiments with this kind of protocol with an uncertain concept have been reported in <ref> [18] </ref>. Unfortunately, the analysis here has not been extended to these uncertain domains because no simplified form could be found for the resulting expectations.
Reference: [19] <author> W.L. Buntine. </author> <title> Modelling default and likelihood reasoning as probabilistic reasoning. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <volume> 4 </volume> <pages> 25-68, </pages> <year> 1991. </year>
Reference-contexts: In these cases, approximate or qualitative solutions are instead preferable (see, for instance <ref> [19] </ref> for a discussion in the context of plausible reasoning). Or, as in the case of a sufficient sample, the Bayesian methods become unnecessary. One can simply use the sample as an implicit definition and subsequently solve the problem empirically.
Reference: [20] <author> W.L. Buntine and D.A. Stirling. </author> <title> Interactive induction. </title> <editor> In J. Hayes, D. Michie, and E. Tyugu, editors, MI-12: </editor> <booktitle> Machine Intelligence 12, Machine Analysis and Synthesis of Knowledge. </booktitle> <publisher> Oxford University Press, Oxford, </publisher> <year> 1990. </year>
Reference-contexts: Some successful machine learning methodologies do incorporate weaker application specific knowledge by some means. Two approaches are the careful selection of attributes in which examples are described [77, 55] and the use of various forms of interaction with an expert <ref> [90, 56, 20] </ref>. In addition, Bayesian statistics, with its notion of subjective knowledge or prior belief, could provide a means by which application specific knowledge can be cautiously incorporated into the learning process [17]. <p> Nevertheless, explanations are a common source of subjective information in the training of novices; perhaps they can also play a key role in knowledge acquisition. A summary of some modes of interaction during learning is given in Table 1.1 (from <ref> [20] </ref>). <p> INTRODUCTION 11 validation is required. How much system interaction or manual interview should be appropriate and how validation should be performed in a particular problem depends on a range of issues. Some suggestions are given in Table 1.2 (from <ref> [20] </ref>). The main choices to be made are on the method of validation and on the particular style of acquisition.
Reference: [21] <author> R.M. Burstall and J. Darlington. </author> <title> A transformation system for developing recursive programs. </title> <journal> Journal of the ACM, </journal> <volume> 24(1), </volume> <year> 1977. </year>
Reference-contexts: The second concern is refinement, which would consist of transforming a pure Prolog program into a program that would operate on, say, a standard Prolog interpreter, while at the same time attempting to improve the efficiency of the program. For instance, program transformation techniques <ref> [21, 95] </ref> are concerned with this task. Second, to accommodate computational efficiency when analysing learning performance, the following approach can be used. The strategy best used by a learner with unbounded computing resources should first be found.
Reference: [22] <author> J. Catlett. </author> <title> Megainduction: machine learning on very large databases. </title> <type> PhD thesis, </type> <institution> University of Sydney, </institution> <year> 1991. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 5 1.2.3 "Sufficient" vs. "insufficient" sample methods While more recent research is focusing on such distinctions as learning from large as opposed to smaller data sets <ref> [22] </ref>, and incremental as opposed to batch learning [88], a related distinction that is widely understood but never really highlighted is the distinction between "sufficient" and "insufficient" sample sizes.
Reference: [23] <author> B. Cestnik, I. Kononenko, and I. Bratko. Assistant86: </author> <title> A knowledge-elicitation tool for sophisticated users. </title> <editor> In I. Bratko and N. Lavrac, editors, </editor> <booktitle> Progress in Machine Learning: Proceedings of EWSL-87, </booktitle> <pages> pages 31-45, </pages> <address> Bled, Yugoslavia, 1987. </address> <publisher> Sigma Press. </publisher>
Reference-contexts: to relate the problem of bias to well known problems in Bayesian statistics, and to subsequently decompose bias into functional components that should allow a better understanding of bias and its development. 1.2.2 Overfitting In noisy or uncertain domains decision tree learning algorithms use Occam's razor, a bias towards simplicity <ref> [23, 75] </ref>. This feature has been described as the "accuracy vs. complexity tradeoff" and various studies exist on this in the machine learning literature [75, 31]. This problem is widely acknowledged outside machine learning and a variety of approaches exist [33, 100, 8]. <p> This, much later, led to the work of Quinlan in the late '70s and early '80s who popularised tree methods in AI. Bratko and colleagues <ref> [23] </ref> and Michie and colleagues went on to extend these methods in various ways and several commercial spinoffs resulted. <p> These are generally considered not as effective as post-pruning rules, although there is some contention on this <ref> [23] </ref>. <p> These essentially allow a modular decomposition of the attribute space using principles of independence, sometimes guided by intuition about causality. The simplest example is the simple (or "idiot") Bayes classifier which assumes all attributes are independent given class. These are highly competitive with trees on some problems <ref> [17, 23] </ref> and there is little doubt that with more thorough net learning approaches, this competitive performance can be considerably improved. <p> For a reasonable comparison with the Bayesian methods to be made, it was felt that the better current methods should be first established. This is not an exhaustive search of current methods, however, as many other potential improvements exist <ref> [23, 28] </ref>, but it certainly gives a reasonable representation of current methods. The experiments reported in this section are simply to determine which of the splitting rules and which of the pruning rules should be later compared with the Bayesian methods. <p> The experiments serve as an interesting study in their own right, however, because few comparative studies of this scale have been made. While many of the data sets used have results already multiply reported in the literature <ref> [102, 17, 23, 26, 75, 2] </ref>, comparisons with literature results will not be made in this and later experiments (although general comparisons were made during implementation of the algorithms as a safety check). <p> by other authors often contain subtle differences (for instance, treatment of unknowns or stopping rules) affecting results. * Reported results usually fail to include confidence limits on error bounds 1 , without which comparisons with current results are doubtful (one notable exception is a study by Cestnik, Kononenko and Bratko <ref> [23] </ref>). * Reported accuracies are often the average of as little as four different trials, so (according to experience) they can quite easily have an error in that accuracy of as much as 5% on problems where small test sets are used. * Comparisons based on reported accuracies do not allow <p> There are nine attributes giving details about the original cancer nodes, position on the breast and age, with multi-valued discrete and real values. This data set, along with the next two, comes from the Institute of Oncology, Ljubljana and has been previously reported on by Cestnik et al. <ref> [23] </ref> and Clark and Niblett [26]. lymph The "lymph" data set comes from the lymphography domain in Oncology. The classes are normal, metastases, malignant or fibrosis and there are nineteen attributes giving details about the lymphatics and lymph nodes, with multi-valued discrete and real values but no unknowns. CHAPTER 6.
Reference: [24] <author> P.C. Cheeseman. </author> <title> In defence of probability. </title> <booktitle> In Proceedings of IJCAI-85, </booktitle> <pages> pages 1002-9. </pages> <publisher> Kaufmann, </publisher> <address> Los Angeles, CA, </address> <year> 1985. </year>
Reference-contexts: There is already ample material on this. The approach has strong foundations [8] and typically gives results in accord with intuition [67, 70]. Discussions of criticisms about the approach are documented by Berger [8] and Cheeseman <ref> [24] </ref>, and appraisals and comparisons of the approach and other uncertainty approaches from an artificial intelligence perspective are given by Horvitz, Heckerman and Langlotz [41].
Reference: [25] <author> P.A. Chou. </author> <title> Applications of Information Theory to Pattern Recognition and the Design of Decision Trees and Trellises. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1988. </year>
Reference-contexts: Also, the tree need not be binary; if an n-valued attribute is tested at one of the nodes, then the tree might have n branches coming from the node, one for each value. These tree methods have been developed independently in a wide number of different areas <ref> [25] </ref>. In statistics, decision trees were built as a means of sequential testing for pattern classification, for instance, using dynamic programming methods. <p> Later work in pattern recognition and, particularly, character recognition combined the statistical and computing science approaches with concerns for measurement costs (the inherent cost of making tests at nodes when processing a new example) <ref> [25] </ref>. Decision tree methods were also developed independently in AI, initially by Hunt and his colleagues [43, 44], who sought to learn structured concepts from examples. This, much later, led to the work of Quinlan in the late '70s and early '80s who popularised tree methods in AI. <p> However, it is often used anyway because it is an estimate where no other might be available. Affine tree functionals: Real-valued functions on trees and their subtrees, such as sample error estimates and leaf counts, are known as tree functionals <ref> [25] </ref>. Many of the functionals used here have the convenient property that they can be computed as the sum of values at the nodes in the tree. These are called affine or linear functionals. <p> Quinlan has suggested post-processing trees into rule sets [74], Matheus and Rendell, and Pagallo have proposed growing trees with conjunctive tests at nodes instead of single attribute tests [53, 66], and Chou has proposed an efficient algorithm for growing trellises instead of trees <ref> [25] </ref> where trellises are directed acyclic graphs with class probability vectors at the leaves and tests at internal nodes (that is, like trees but internal nodes can have multiple parents).
Reference: [26] <author> P. Clark and T. Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 261-283, </pages> <year> 1989. </year>
Reference-contexts: The experiments serve as an interesting study in their own right, however, because few comparative studies of this scale have been made. While many of the data sets used have results already multiply reported in the literature <ref> [102, 17, 23, 26, 75, 2] </ref>, comparisons with literature results will not be made in this and later experiments (although general comparisons were made during implementation of the algorithms as a safety check). <p> This data set, along with the next two, comes from the Institute of Oncology, Ljubljana and has been previously reported on by Cestnik et al. [23] and Clark and Niblett <ref> [26] </ref>. lymph The "lymph" data set comes from the lymphography domain in Oncology. The classes are normal, metastases, malignant or fibrosis and there are nineteen attributes giving details about the lymphatics and lymph nodes, with multi-valued discrete and real values but no unknowns. CHAPTER 6.
Reference: [27] <author> D.A. Cleaves. </author> <title> Cognitive biases and corrective techniques: proposals for improving elicitation procedures for knowledge-based systems. </title> <editor> In B. Gaines and J. Boose, editors, </editor> <booktitle> Knowledge Acquisition for Knowledge-Based Systems, </booktitle> <pages> pages 23-34. </pages> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1988. </year>
Reference-contexts: For instance, in the context of uncertainty, people have limitations with reasoning and in articulating their reasoning [49], so knowledge elicited must be interpreted with caution <ref> [27] </ref>. This can be partially overcome by working in a structured probabilistic environment [40], although maybe at the expense of even slower development time. So we do not always wish to totally replace learning by some method of obtaining subjective knowledge from an expert.
Reference: [28] <author> S.L. Crawford. </author> <title> Extensions to the CART algorithm. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 31(2) </volume> <pages> 197-217, </pages> <year> 1989. </year>
Reference-contexts: An alternative approach to parameter estimation is the use of cross-validation, and a number of related methods that attempt to manufacture extra samples from the current sample. Such methods have been widely used in partitioning approaches, for instance <ref> [12, 28] </ref>. <p> For a reasonable comparison with the Bayesian methods to be made, it was felt that the better current methods should be first established. This is not an exhaustive search of current methods, however, as many other potential improvements exist <ref> [23, 28] </ref>, but it certainly gives a reasonable representation of current methods. The experiments reported in this section are simply to determine which of the splitting rules and which of the pruning rules should be later compared with the Bayesian methods.
Reference: [29] <author> P.A. Devijuer and J. Kittler. </author> <title> Pattern Recognition: a statistical approach. </title> <publisher> Prentice Hall, </publisher> <year> 1982. </year> <note> BIBLIOGRAPHY 164 </note>
Reference-contexts: paradigm would take many more pages than can be reasonably allotted in this thesis. 4.5.1 Major approaches The major approaches developed in classical statistics can be grouped as follows: Discriminant analysis: Broadly speaking, these methods assume the distribution of the exam ples conditioned on class follows a multivariate normal model <ref> [29] </ref>. They then seek to estimate CHAPTER 4. COMPARISONS 62 the parameters of the model and determine discriminant functions, linear or quadratic func tions of an example which are used to discriminate between classes. <p> Feature selection and extraction: A major problem with basic nearest neighbour is the choice of distance metric. A broad class of methods, such as the Karhunen-Loeve expansion, exist for selecting and extracting a suitable set of variables on which a distance metric can be developed <ref> [29] </ref>. A recent method, projection pursuit [48], searches for a linear projection of the variables to construct a few new attributes in a low dimensional space. Partitioning methods: These approaches parallel the various rule and decision tree building methods being developed in artificial intelligence.
Reference: [30] <author> D.H. Fisher and K.B. McKusick. </author> <title> An empirical comparison of ID3 and back-propagation and machine learning classification methods. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 788-793, </pages> <address> Detroit, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Yet many comparative studies from the machine learning community, for instance, fail to consider even broad characteristics of an application or a machine learning algorithm that would help decide whether an algorithm is appropriate for an application (see <ref> [62, 102, 30] </ref>), and hence whether the comparison of algorithms on the application is a fair one. The same problem has been noted by Fisher and Schlimmer [31, p27].
Reference: [31] <author> D.H. Fisher and J.C. Schlimmer. </author> <title> Concept simplification and prediction accuracy. </title> <booktitle> In Fifth International Conference on Machine Learning, </booktitle> <pages> pages 22-28, </pages> <address> Ann Arbor, Michigan, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Much of this research has concentrated on domains without noise or uncertainty. In noisy domains, some researchers have considered the "bias towards simplicity" <ref> [31] </ref>. There are, however, critical open issues on this line of research. <p> This feature has been described as the "accuracy vs. complexity tradeoff" and various studies exist on this in the machine learning literature <ref> [75, 31] </ref>. This problem is widely acknowledged outside machine learning and a variety of approaches exist [33, 100, 8]. Should these approaches be applied to the machine learning techniques developed within the AI community. <p> The same problem has been noted by Fisher and Schlimmer <ref> [31, p27] </ref>. Using a statistical measure to characterise prediction tasks instantiates a methodology forwarded by Simon (1969) domains must be characterised before an AI system's effectiveness can be properly evaluated.
Reference: [32] <author> R.A. Fisher. </author> <title> Multiple measurements in taxonomic problems. </title> <journal> Annals of Eugenics, </journal> <volume> VII:179-188, </volume> <year> 1936. </year>
Reference-contexts: The combinatorics of that comparative study would seem to deny the possibility of getting a clear outcome from the comparison. The data sets used are as follows. iris The "iris" data set, Fisher's classic test data <ref> [32] </ref>, has classes which are three types of iris plants and real valued attributes which are petal and sepal width and length, with no unknowns.
Reference: [33] <author> T.G. Freeman. </author> <title> Selecting the best model to fit data. </title> <booktitle> Mathematics and Computers in Simulation, </booktitle> <volume> 27 </volume> <pages> 137-140, </pages> <year> 1985. </year>
Reference-contexts: This feature has been described as the "accuracy vs. complexity tradeoff" and various studies exist on this in the machine learning literature [75, 31]. This problem is widely acknowledged outside machine learning and a variety of approaches exist <ref> [33, 100, 8] </ref>. Should these approaches be applied to the machine learning techniques developed within the AI community. <p> Parameter estimation was a feature, for instance, of Rissanen's MDL approach. There is an embarrassingly wide selection of methods for estimating parameters and the comparative reliability of these methods is unclear <ref> [33] </ref>. An alternative approach to parameter estimation is the use of cross-validation, and a number of related methods that attempt to manufacture extra samples from the current sample. Such methods have been widely used in partitioning approaches, for instance [12, 28].
Reference: [34] <author> S. Ganapathy and V. Rajamaran. </author> <title> Information theory applied to the conversion of decision tables to computer programs. </title> <journal> CACM, </journal> <volume> 16 </volume> <pages> 532-539, </pages> <year> 1973. </year>
Reference-contexts: In computer science decision trees were used to convert decision tables to nested "if-then" rules. Eventually Hyafil and Rivest [45] showed the problem was actually NP-complete. Suboptimal methods have been developed using heuristic search of an AND/OR graph [52], and using an information theory approach <ref> [34] </ref> essentially the same as Quinlan's ID3 algorithm [73], developed much later. Later work in pattern recognition and, particularly, character recognition combined the statistical and computing science approaches with concerns for measurement costs (the inherent cost of making tests at nodes when processing a new example) [25].
Reference: [35] <author> E.M. Gold. </author> <title> Language identification in the limit. </title> <journal> Information and Control, </journal> <volume> 10 </volume> <pages> 447-474, </pages> <year> 1967. </year>
Reference-contexts: Substantial experimental work has been undertaken, a host of issues and problems have been raised, but some existing theories of learning in the computing literature (some such theories <ref> [35, 99] </ref> are reviewed in Chapter 4) seem inadequate to explain the observed phenomena or resolve the problems. It would seem that further theory, borrowed from statistics for instance, needs to be thrown at these problems and experimentally evaluated to help guide in the search for solutions. <p> The learning theories considered are a representative set of those most prominent in the computing literature. And due to space, we only consider the fundamental characteristics of each coupled with a fairly broad-brush comparison. The first theory compared is Gold's paradigm <ref> [35] </ref>, widely recognised as the first learning theory in computing science. The second considered is computational learning theory, developed by Valiant [99], Haussler [38] and others. The third theory covered is the bias framework reviewed in the Introduction, Chapter 1. <p> To supplement this quad, a breaf discussion is made of classical statistics and pattern recognition methods at the end of the chapter. 46 CHAPTER 4. COMPARISONS 47 4.1 Gold's paradigm A general paradigm of inductive inference|learning concepts in an uncertainty-free context|was outlined by Gold <ref> [35] </ref> in the late '60s. Considerable extensions to the paradigm have been made since [7]. The theory has its roots in computability and the theory of recursive functions. <p> This holds for an induction system if, after being presented with a finite number of examples of an uncertainty-free concept, the system settles on a correct hypothesis describing the concept, and will not change its mind on being presented with further examples. (Only ineffective versions of identification are considered here <ref> [35, p457] </ref>). <p> One works through the enumeration until a hypothesis consistent with the current evidence is found. Subsequently, if newly presented evidence is inconsistent, one continues along the enumeration. By the two conditions above, the method will eventually settle on a correct hypothesis <ref> [35, p458] </ref>. This method is of fundamental importance in learning logical concepts because no other method is uniformly more powerful in the following sense: every other method will, for at least some concepts, need to see more evidence before settling on a correct hypothesis [35, p462]. <p> This method is of fundamental importance in learning logical concepts because no other method is uniformly more powerful in the following sense: every other method will, for at least some concepts, need to see more evidence before settling on a correct hypothesis <ref> [35, p462] </ref>. Since almost all reasonable logic learning algorithms can be classed in the broad category of "identification by enumeration", we can conclude that some algorithms perform well on some types of problems, others perform well on other types of problems, but no algorithm performs uniformly better. <p> Gold has shown that most infinite languages cannot be identified in the limit from positive examples only <ref> [35, p452] </ref>. The Bayesian theory presented in Sections 3.2.4 and 3.2.6 for the positive random and positive generated protocols shows that posterior belief is stronger for consistent hypotheses with a lower overall proportion of positive examples.
Reference: [36] <author> D.J. </author> <title> Hand. Kernel Discriminant Analysis. </title> <publisher> Wiley, </publisher> <address> Chichester, </address> <year> 1982. </year>
Reference-contexts: COMPARISONS 62 the parameters of the model and determine discriminant functions, linear or quadratic func tions of an example which are used to discriminate between classes. Kernel density estimation: These methods make a non-parametric estimate of the distribution of the examples conditioned on class <ref> [36] </ref>. This is done by smoothing over the "histogram" of examples for a given class. The smoothing function is typically constructed from a distance metric between examples. Classification is done by computing afresh for each new example, the class conditional probabilities from the sample.
Reference: [37] <author> D. Haussler. </author> <title> Editorial. </title> <journal> Machine Learning, </journal> <volume> 2(4), </volume> <year> 1988. </year>
Reference-contexts: This provides a broad framework for addressing issues such as constructive induction or learning in other representational contexts. 1.2.5 The theory and the practice of learning algorithms Valiant's framework views learning from a computational complexity perspective and seeks to precisely define the computational capabilities of learning systems <ref> [99, 37] </ref>. In the learning of logical concepts from random examples, where much of the theory has been concentrated, results centre around the strength of bias and resultant worst-case complexity results about learning [38]. This, however, only contributes a small way towards an understanding of the design of learning algorithms.
Reference: [38] <author> D. Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <journal> Artificial Intelligence, </journal> <volume> 36(2) </volume> <pages> 177-222, </pages> <year> 1988. </year>
Reference-contexts: Several researchers have since extended this theory. Haussler and others have studied the impact of the strength of bias on learning <ref> [38] </ref> and Russell and others have presented a logical treatment of declarative bias [85, 84], Researchers have also experimented on the appropriateness of bias [68], and the learning of bias [96, 98]. Much of this research has concentrated on domains without noise or uncertainty. <p> Results from the Valiant style theory of machine learning are based on searching for any hypothesis consistent with the sample <ref> [38] </ref>, and in the context of noise, any hypothesis that has the least number of inconsistencies with the sample [6]. Both these suggestions go against the grain of much applied work in machine learning. <p> In the learning of logical concepts from random examples, where much of the theory has been concentrated, results centre around the strength of bias and resultant worst-case complexity results about learning <ref> [38] </ref>. This, however, only contributes a small way towards an understanding of the design of learning algorithms. For instance, the techniques do not mesh well with the widespread practice of employing Occam's razor as a preference bias. <p> An example x is produced according to a fixed distribution and independently of the true concept or other examples. The example is then classified as class c according to the true logical concept to produce a classified example (x; c). This protocol is typically considered in the Valiant framework <ref> [38] </ref>. The distribution of examples will be denoted d (x j ), where is an appropriate parameterisation. The protocol therefore specifies the likelihood function P r (x; c j H; ) = 1 x is cjH d (x j ) ; where (x; c) is the new example obtained. <p> Computational utility of learning: The learner must of course perform within reasonable computational limits. In addition, computational efficiency may sometimes be traded for another kind of learning performance. This general aspect of learning is a subject of considerable breadth. Valiant [99] and Haussler <ref> [38] </ref>, among others, have developed a framework and present results on this in the context of the logical random example protocol. The incremental induction problem [51], is concerned with economising computational cost as well as prediction errors while new examples are being presented. <p> We would like to be able to assess the appropriateness of these choices. It was implicit in the learning framework that the hypothesis space chosen contains a good approximation to the true hypothesis, as remarked in Section 2.4. Results such as Haussler's <ref> [38] </ref> indicate the benefits of using a strong bias or smaller hypothesis space when learning. In following this line of thinking, we may err on the side of over-simplification and choose an hypothesis space CHAPTER 3. <p> And due to space, we only consider the fundamental characteristics of each coupled with a fairly broad-brush comparison. The first theory compared is Gold's paradigm [35], widely recognised as the first learning theory in computing science. The second considered is computational learning theory, developed by Valiant [99], Haussler <ref> [38] </ref> and others. The third theory covered is the bias framework reviewed in the Introduction, Chapter 1. The third theory covered in some detail is the encoding approaches introduced by several authors, Risannen's Minimum Description Length (MDL) and Wallace's Minimum Message Length (MML). <p> Angluin and Laird have termed this notion probably approximately correct (PAC) and a common interpretation <ref> [38] </ref> is, in a nutshell: there are so few hypotheses left that are consistent with the classified examples that every consistent hypothesis is with a confidence of 1 ffi approximately correct with error at most * on future samples. A typical definition of this notion is as follows. <p> Because neither of these last two CHAPTER 4. COMPARISONS 53 pieces of information are known in the learning context, the usual approach is to develop results that would hold for any concept and distribution on examples. In the Valiant approach, these results are referred to as "distribution free" <ref> [38] </ref>, and is considered an advantage of the approach. 4.2.2 A Bayesian interpretation of PACness A corresponding definition in the Bayesian framework given in this chapter makes all the conditioned information in the classical definition of PACness precise. <p> For instance, one hopes to find an algorithm and bounds relating *, ffi, C, and the sample size that guarantee learnability. Most work rests on two theorems, the Blumer, Ehrenfeucht, Haussler and Warmuth bound [9], introduced and discussed further in Chapter 5, and a bound using the Vapnik-Chervonenkis dimension <ref> [38] </ref>. To ensure PAC-learnability, these need to be coupled with a polynomial time algorithm for finding a hypothesis consistent with a sample. <p> To ensure PAC-learnability, these need to be coupled with a polynomial time algorithm for finding a hypothesis consistent with a sample. The generality of these two theorems has allowed an extensive variety of concept classes to be considered <ref> [38, 82] </ref>. 4.2.4 Discussion The framework and techniques developed within computational learning theory, for instance PAC-ness and learnability, have allowed extensive worst case complexity results to be developed. <p> Finally, a theoretical treatment is given in Section 5.6 of the Bayesian approach to the problem of error bounds. 5.1 Introduction The Valiant model has been developed by a number of researchers to yield an impressive array of results and research tools <ref> [38, 82] </ref>. The Valiant model has also received strong criticism from 64 CHAPTER 5. EXTENSIONS TO VALIANT'S FRAMEWORK 65 Amsterdam for its poor track record in applied learning [3], and for its restricted scope [4]. <p> While priors certainly have to be used with caution [8, p109], there use allows a much more powerful statistical analysis of the logical induction problem that still shares all the "distribution-free" advantages of the Valiant model <ref> [38, p179] </ref>, albeit in an average-case rather than worst-case sense. 5.2 The Blumer bound and its use Blumer, Ehrenfuecht, Haussler and Warmuth [9] have developed a bound that allows the classical notion of PACness to be determined. <p> 1=ffi ; p literals in certain configuration : * &lt; p ln (2n + 1) + ln 1=ffi ; k conjunctions/disjunctions : * &lt; kn ln 3 + ln 1=ffi : For propositional languages but not others, these results are superior to those obtained using the Vapnik-Chervonenski dimension (see Haussler <ref> [38] </ref> Theorems 3.3 and 3.10 with p = ks, and the discussion at the end of Section 2). <p> This demonstrates just how important it is to make use of knowledge about a sample when evaluating PACness. 5.4 Average rather than worst case PACness The use of the bound obtained in Lemma 5.3.2 or the Blumer bound, as with Haussler's notion of *-exhausting a hypothesis space <ref> [38] </ref>, are really worst case analyses: they apply to every consistent hypothesis. If we choose a single consistent hypothesis arbitrarily, then we may choose a worst case, or we may choose a more accurate hypothesis. <p> CONCLUSION 124 3. What are suitable algorithms and what is the computational complexity of searching for "preferred" consistent hypothesis for various concept classes and preference criteria? Both Haussler <ref> [38, Section 5] </ref> and Rivest [82, Section 5.3] have briefly considered this question using "simplicity". 4.
Reference: [39] <author> F. Hayes-Roth, D.A. Waterman, and D. Lenat, </author> <title> editors. Building Expert Systems. </title> <publisher> Addison Wesley, </publisher> <year> 1983. </year>
Reference-contexts: Also, the expert could appraise results of induction and possibly resubmit certain fragments for further processing. There are, of course, other methods being used for obtaining subjective knowledge from an expert: the traditional manual knowledge acquisition method <ref> [39] </ref>, and hybrid methods such as computer-aided interviewing [10] and computer-aided knowledge refinement [69]. Although the use CHAPTER 1. INTRODUCTION 10 of sophisticated aids for input, interviewing and editing is improving the speed of these interview-driven methods, they are still time intensive for the expert. <p> Problems over and above this slow development time exist with these methods. Knowledge elicited is not always reliable. Significant incongruities between what an expert says he does, what he actually does, and what he should have done in hindsight are now accepted in expert systems methodology <ref> [39] </ref>. For instance, in the context of uncertainty, people have limitations with reasoning and in articulating their reasoning [49], so knowledge elicited must be interpreted with caution [27].
Reference: [40] <author> M. Henrion and D.R. Cooley. </author> <title> An experimental comparison of knowledge engineering for expert systems and for decision analysis. </title> <booktitle> In Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pages 471-476, </pages> <address> Seattle, </address> <year> 1987. </year>
Reference-contexts: For instance, in the context of uncertainty, people have limitations with reasoning and in articulating their reasoning [49], so knowledge elicited must be interpreted with caution [27]. This can be partially overcome by working in a structured probabilistic environment <ref> [40] </ref>, although maybe at the expense of even slower development time. So we do not always wish to totally replace learning by some method of obtaining subjective knowledge from an expert. A compromise is to enhance the interaction with an expert during empirical learning.
Reference: [41] <author> E.J. Horvitz, D.E. Heckerman, </author> <title> and C.P. Langlotz. A framework for comparing alternative formalisms for plausible reasoning. </title> <booktitle> In Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pages 210-214, </pages> <address> Philadelphia, </address> <year> 1986. </year>
Reference-contexts: Discussions of criticisms about the approach are documented by Berger [8] and Cheeseman [24], and appraisals and comparisons of the approach and other uncertainty approaches from an artificial intelligence perspective are given by Horvitz, Heckerman and Langlotz <ref> [41] </ref>. Perhaps the major valid criticisms of the approach are that in some cases it requires too precise a specification of a problem to do all the required Bayesian contortions, and that the final suggested solution is too computationally complex to evaluate.
Reference: [42] <author> R.A. Howard. </author> <title> Decision analysis: perspectives on inference, decision, and experimentation. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 58(5), </volume> <year> 1970. </year>
Reference-contexts: This serves to introduce a trivialised version of the problem of learning classification rules, and to introduce some of the properties of Dirichlet distributions and beta functions that are used in later chapters. A related introduction can be found in <ref> [42] </ref>. First consider the problem of learning classification rules. Typically, we have a number of classified examples and we wish to learn a classification rule to predict the class of newly supplied examples. Examples are usually described in terms of attributes, real valued or discrete (dependent) variables.
Reference: [43] <author> E.B. Hunt and C.I. Hovland. </author> <title> Programming a model of human concept formation. In E.A. </title> <editor> Feigenbaum and J. Feldman, editors, </editor> <booktitle> Computers and Thought, </booktitle> <pages> pages 310-325. </pages> <publisher> McGraw-Hill, </publisher> <year> 1963. </year>
Reference-contexts: Fortunately, a second wave of promising "neural net" research is now underway. CHAPTER 1. INTRODUCTION 3 While early perceptron work might be considered a negative example of learning research, a positive example can be seen in the early work of Hunt and his colleagues <ref> [43, 44] </ref>. These psychologists and early AI researchers sought to model human learning, and sought to learn structured concepts rather than simple linear thresholding units. This has been a major theme in machine learning research since then. Again good ideas were the initial motivational forces. <p> Decision tree methods were also developed independently in AI, initially by Hunt and his colleagues <ref> [43, 44] </ref>, who sought to learn structured concepts from examples. This, much later, led to the work of Quinlan in the late '70s and early '80s who popularised tree methods in AI.
Reference: [44] <author> E.B. Hunt, J. Marin, and P.T. Stone. </author> <title> Experiments in Induction. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: Fortunately, a second wave of promising "neural net" research is now underway. CHAPTER 1. INTRODUCTION 3 While early perceptron work might be considered a negative example of learning research, a positive example can be seen in the early work of Hunt and his colleagues <ref> [43, 44] </ref>. These psychologists and early AI researchers sought to model human learning, and sought to learn structured concepts rather than simple linear thresholding units. This has been a major theme in machine learning research since then. Again good ideas were the initial motivational forces. <p> Decision tree methods were also developed independently in AI, initially by Hunt and his colleagues <ref> [43, 44] </ref>, who sought to learn structured concepts from examples. This, much later, led to the work of Quinlan in the late '70s and early '80s who popularised tree methods in AI.
Reference: [45] <author> L. Hyafil and R.L. Rivest. </author> <title> Constructing optimal binary decision trees is NP-complete. </title> <journal> Information Processing Letters, </journal> <volume> 5 </volume> <pages> 15-17, </pages> <year> 1976. </year> <note> BIBLIOGRAPHY 165 </note>
Reference-contexts: In computer science decision trees were used to convert decision tables to nested "if-then" rules. Eventually Hyafil and Rivest <ref> [45] </ref> showed the problem was actually NP-complete. Suboptimal methods have been developed using heuristic search of an AND/OR graph [52], and using an information theory approach [34] essentially the same as Quinlan's ID3 algorithm [73], developed much later.
Reference: [46] <author> H. Jeffreys. </author> <title> Theory of Probability. </title> <publisher> Clarendon Press, Oxford, </publisher> <address> third edition, </address> <year> 1961. </year>
Reference-contexts: We can adjust for this problem by using a trick such as Jeffreys' test for one new parameter <ref> [46] </ref>. Suppose the tree structure T is parameterised by the single cut-point c chosen from the range [a; b]. Then we can anull the effects of the choice of c by averaging it out.
Reference: [47] <author> R.J. Jessen. </author> <title> Statistical Survey Techniques. </title> <publisher> Wiley, </publisher> <year> 1978. </year>
Reference-contexts: Statistical survey techniques often use stratified sampling where a population is split into strata and each stratum is sampled independently <ref> [47] </ref>. This is used widely for population surveys, where the strata might correspond to postcode regions, market research, where the strata might correspond to different professions or income groups, and even applications like auditing, where the auditor would hope to sample a representative selection of accounts of different dollar value.
Reference: [48] <author> M.C. Jones and R. Sibson. </author> <title> What is projection pursuit. </title> <journal> J. Roy. Statist. Soc. A, </journal> <volume> 150 </volume> <pages> 1-36, </pages> <year> 1987. </year>
Reference-contexts: A broad class of methods, such as the Karhunen-Loeve expansion, exist for selecting and extracting a suitable set of variables on which a distance metric can be developed [29]. A recent method, projection pursuit <ref> [48] </ref>, searches for a linear projection of the variables to construct a few new attributes in a low dimensional space. Partitioning methods: These approaches parallel the various rule and decision tree building methods being developed in artificial intelligence. Perhaps the state of the art here is the CART system [12].
Reference: [49] <author> D. Kahneman, P. Slovic, and A. Tversky. </author> <title> Judgement under Uncertainty: Heuristics and Biases. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1982. </year>
Reference-contexts: Significant incongruities between what an expert says he does, what he actually does, and what he should have done in hindsight are now accepted in expert systems methodology [39]. For instance, in the context of uncertainty, people have limitations with reasoning and in articulating their reasoning <ref> [49] </ref>, so knowledge elicited must be interpreted with caution [27]. This can be partially overcome by working in a structured probabilistic environment [40], although maybe at the expense of even slower development time.
Reference: [50] <author> S.L. Lauritzen and D.J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> J. Roy. Statist. Soc. B, </journal> <volume> 50(2) </volume> <pages> 240-265, </pages> <year> 1988. </year>
Reference-contexts: An alternative to class probability trees for representing uncertain classification rules is the use of Bayes or causal nets <ref> [50, 67] </ref>. These essentially allow a modular decomposition of the attribute space using principles of independence, sometimes guided by intuition about causality. The simplest example is the simple (or "idiot") Bayes classifier which assumes all attributes are independent given class.
Reference: [51] <author> N. Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: a new linear threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: A prediction error occurs if this disagrees with the actual. Different kinds of prediction errors might have different utilities. For instance, wrongly predicting negative when diagnosing cancer might result in late treatment and potential death of a patient. The working phase will usually be preceded by a training phase <ref> [51] </ref> in which predictions are not required to be made. In the training phase examples are provided purely for training purposes. Queries to the oracle: Each query made to the oracle during the course of an interactive protocol may require some effort on the part of the oracle. <p> This general aspect of learning is a subject of considerable breadth. Valiant [99] and Haussler [38], among others, have developed a framework and present results on this in the context of the logical random example protocol. The incremental induction problem <ref> [51] </ref>, is concerned with economising computational cost as well as prediction errors while new examples are being presented. The relationship between queries and computational utility of learning is discussed by Angluin [5]. <p> Most practitioners spend their time trying to find a hypothesis that they believe is in some sense the best. How should this be done? Merely choosing just any consistent hypothesis may ignore vital information of a form not able to restrict the hypothesis space. Suppose, as Littlestone considers <ref> [51] </ref>, we suspect there are abundant irrelevant or redundant attributes. It would be an obscure application where we know exactly how many attributes are irrelevant or redundant. Suppose, as Rivest considers [82], we believe decision lists form a suitable hypothesis space.
Reference: [52] <author> A. Martelli and U. Montanari. </author> <title> Optimising decision trees through heuristically guided search. </title> <journal> CACM, </journal> <volume> 21 </volume> <pages> 1025-1039, </pages> <year> 1978. </year>
Reference-contexts: In computer science decision trees were used to convert decision tables to nested "if-then" rules. Eventually Hyafil and Rivest [45] showed the problem was actually NP-complete. Suboptimal methods have been developed using heuristic search of an AND/OR graph <ref> [52] </ref>, and using an information theory approach [34] essentially the same as Quinlan's ID3 algorithm [73], developed much later.
Reference: [53] <author> C.J. Matheus and L.A. Rendell. </author> <title> Constructive induction on decision trees. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 645-650, </pages> <address> Detroit, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Recurrent problems in machine learning such as splitting and pruning rules for decision trees [57, 75] and the evaluation of new predicates for constructive induction <ref> [53] </ref> are just some symptoms of this broad search problem. Results from the Valiant style theory of machine learning are based on searching for any hypothesis consistent with the sample [38], and in the context of noise, any hypothesis that has the least number of inconsistencies with the sample [6]. <p> This becomes critical in areas such as constructive induction where one is trying to construct new terms from existing terms used to describe examples, the careful evaluation of potential new terms is critical for success. Mathues <ref> [53] </ref> surveys a number of constructive induction methods and reports that few use a coherent evaluation strategy for new terms. Finally, a few questions raised in Section 1.2.1 concerned domain dependent versus domain independent biases and what is the nature of "good" bias. We briefly review these here. <p> There are many variations on this representation theme and several researchers have considered solutions. Quinlan has suggested post-processing trees into rule sets [74], Matheus and Rendell, and Pagallo have proposed growing trees with conjunctive tests at nodes instead of single attribute tests <ref> [53, 66] </ref>, and Chou has proposed an efficient algorithm for growing trellises instead of trees [25] where trellises are directed acyclic graphs with class probability vectors at the leaves and tests at internal nodes (that is, like trees but internal nodes can have multiple parents).
Reference: [54] <author> D. Michie. </author> <title> The superarticulacy phenomenon in the context of software manufacture. </title> <journal> Proc. Roy. Soc. (A), </journal> <volume> 405 </volume> <pages> 185-212, </pages> <year> 1986. </year>
Reference-contexts: The right subjective knowledge may well be equivalent in value to a possibly expensive sample. The importance of suitable attributes (features or descriptors) for expressing concepts, for instance, is well recognised [77]. This is one way in which subjective knowledge can be provided to commercially available induction tools <ref> [54] </ref>: This provision does not necessarily have to be made overtly. With medical records, for instance, only relevant decision-aiding details about a patient tend to be recorded. A second type of subjective knowledge that could be harnessed is causality [67].
Reference: [55] <author> D. Michie. </author> <title> Current developments in expert systems. </title> <editor> In J.R. Quinlan, editor, </editor> <booktitle> Applications of Expert Systems. </booktitle> <publisher> Addison Wesley, </publisher> <address> London, </address> <year> 1987. </year>
Reference-contexts: Some successful machine learning methodologies do incorporate weaker application specific knowledge by some means. Two approaches are the careful selection of attributes in which examples are described <ref> [77, 55] </ref> and the use of various forms of interaction with an expert [90, 56, 20]. In addition, Bayesian statistics, with its notion of subjective knowledge or prior belief, could provide a means by which application specific knowledge can be cautiously incorporated into the learning process [17].
Reference: [56] <author> D. Michie. </author> <title> Statistical classifiers compared with decision-tree classifiers as applied to credit scoring. </title> <editor> In J. Hayes, D. Michie, and E. Tyugu, editors, MI-12: </editor> <booktitle> Machine Intelligence 12, Machine Analysis and Synthesis of Knowledge. </booktitle> <publisher> Oxford University Press, Oxford, </publisher> <year> 1990. </year>
Reference-contexts: Some successful machine learning methodologies do incorporate weaker application specific knowledge by some means. Two approaches are the careful selection of attributes in which examples are described [77, 55] and the use of various forms of interaction with an expert <ref> [90, 56, 20] </ref>. In addition, Bayesian statistics, with its notion of subjective knowledge or prior belief, could provide a means by which application specific knowledge can be cautiously incorporated into the learning process [17]. <p> An interactive approach has been reported by Shapiro [90]. He extended an ID3-like algorithm so that the tree building process itself, the selection of tests at each new decision tree node, could be guided by the user/expert. Michie <ref> [56] </ref> describes an application of this technique to the credit assessment domain, in which a 5% increase in accuracy over automatically generated trees was obtained. Tecuci describes the Disciple system [97], a system that interactively develops rules from data by extracting explanations from an expert.
Reference: [57] <author> J. Mingers. </author> <title> An empirical comparison of selection measures for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 319-342, </pages> <year> 1989. </year>
Reference-contexts: Recurrent problems in machine learning such as splitting and pruning rules for decision trees <ref> [57, 75] </ref> and the evaluation of new predicates for constructive induction [53] are just some symptoms of this broad search problem. <p> Many other test types are possible, but these two are representative and so are sufficient for this thesis. The statistical tests commonly used are intended to favour splits that yield rows having significantly different class distributions. A survey of many different splitting rules can be found in <ref> [57] </ref>. These are mostly similar to the chi-squared statistic for testing dependence in a contingency table. <p> It was felt that this large mix of data sets was necessary since several different tree algorithms (accounting for combinations) are being tested. A previous author <ref> [57] </ref> has compared some ten different splitting rules on a mere four data sets. The combinatorics of that comparative study would seem to deny the possibility of getting a clear outcome from the comparison. <p> Preference for extreme partitions: The splitting rule tends to choose tests partitioning the data into a small and a large set rather than equal size sets. In some cases, we would like more equal partitions <ref> [57] </ref>. This was discussed in the previous section. Notice that the Bayesian splitting rule above is only justified for discrete attributes. If some of the attributes are real-valued, then the basic affine tree functional W is incorrect.
Reference: [58] <author> M. Minsky and S. Papert. </author> <title> Perceptrons: An Introduction to Computational Geometry. </title> <publisher> MIT Press, </publisher> <address> second edition, </address> <year> 1972. </year>
Reference-contexts: It allows basic issues and problems to come to the fore, and basic techniques and methodologies to be developed. Although it should be more and more augmented with theoretical developments as the area progresses. Early comments by Minsky and Papert <ref> [58] </ref> throw some light onto this kind of development approach. They were discussing history of research in the perceptron, a simple linear thresholding unit that, along with an iterative learning method, was a subject of intense study in early machine learning and pattern recognition. <p> They were discussing history of research in the perceptron, a simple linear thresholding unit that, along with an iterative learning method, was a subject of intense study in early machine learning and pattern recognition. They first comment on the attraction of the perceptron paradigm <ref> [58, p18] </ref>. Part of the attraction of the perceptron lies in the possibility of using very simple physical devices|"analogue computers"|to evaluate the linear threshold functions. . . . <p> Good ideas and apparent plausibility were clearly the initial motivating force. While perceptrons usually worked quite well on simple problems, their performance deteriorated rapidly on the more ambitious domains. Minsky and Papert sum up much of the research as follows <ref> [58, p19] </ref>: The results of these hundreds of projects and experiments were generally disappointing, and the explanations inconclusive. It was only after this apparent lack of success that Minsky and Papert set about developing a more comprehensive theory of perceptrons and their capabilities.
Reference: [59] <author> S. Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> In Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 564-569, </pages> <address> Saint Paul, Minnesota, </address> <year> 1988. </year>
Reference-contexts: The relationship between queries and computational utility of learning is discussed by Angluin [5]. Utility of the concept representation: The utility of the representation of a concept can be measured in terms of its comprehensibility [75, 64] or, as in explanation based learning, its computational efficiency or operationality <ref> [72, 59] </ref>. Learning requires that an appropriate representation for the concept be found. To restrict the scope of this thesis, the concerns of computational utility and representational utility have been cordoned off using two rough tricks. No claim is made here that they are optimal in any sense.
Reference: [60] <author> T.M. Mitchell. </author> <title> The need for biases in learning generalisations. </title> <type> CBM-TR 5-110, </type> <institution> Rutgers University, </institution> <address> New Brunswick, NJ, </address> <year> 1980. </year>
Reference-contexts: The first clear enunciation of this problem was by Mitchell, who referred to it as the problem of bias <ref> [60] </ref>, where bias is the set of influences that cause a learner to favour one hypothesis over another. Utgoff developed this idea further, saying [98, p5] CHAPTER 1. INTRODUCTION 4 Given a set of training instances, bias is the set of all factors that collectively influence hypothesis selection. <p> Clearly, we should not choose such a hypothesis arbitrarily. This issue has caused Mitchell to propose the need for "bias" in induction <ref> [60] </ref>. Bias is information extraneous to the sample used when choosing a hypothesis. For instance, we might choose a hypotheses that is "preferred" in some sense. <p> These answer Mitchell's CHAPTER 5. EXTENSIONS TO VALIANT'S FRAMEWORK 83 concerns <ref> [60] </ref> in mathematical detail: how "bias" is required, how it can be implemented (as a measure of belief), and how it effects the logical induction process. The Bayesian approach is discussed here.
Reference: [61] <author> T.M. Mitchell. </author> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18(2) </volume> <pages> 203-226, </pages> <year> 1982. </year> <note> BIBLIOGRAPHY 166 </note>
Reference-contexts: it is not? Another result of this thesis is to provide a framework for learning in the context of an insufficient sample, and to demonstrate its use in learning decision trees. 1.2.4 Learning as search A seminal paper by Mitchell argued that learning should be cast as a search problem <ref> [61] </ref>. Mitchell's argument was based on the version space approach to learning logical concepts. The version spaces approach, while providing impressive results in the specific META-DENDRAL application, does not generalise well as a paradigm for learning logical concepts [63]. CHAPTER 1. <p> The framework is based on ideas from Valiant [99] and Angluin and Smith [7], but has been configured so that it is suitable for applying Bayesian principles. The resultant theory gives a precise and statistically founded basis for Mitchell's notion of induction "as search" <ref> [61] </ref>, specifying suitable search spaces and search heuristics for different learning contexts. The framework splits a learning problem into three components. Bare in mind that these components should only be considered from the learner's perspective, because it is a learner we are interested in designing.
Reference: [62] <author> R. Mooney, J. Shavlik, G. Towell, and A. Gove. </author> <title> An experimental comparison of symbolic and connectionist learning algorithms. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 775-780, </pages> <address> Detroit, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Yet many comparative studies from the machine learning community, for instance, fail to consider even broad characteristics of an application or a machine learning algorithm that would help decide whether an algorithm is appropriate for an application (see <ref> [62, 102, 30] </ref>), and hence whether the comparison of algorithms on the application is a fair one. The same problem has been noted by Fisher and Schlimmer [31, p27].
Reference: [63] <author> S. Muggleton. </author> <title> A strategy for constructing new predicates in first-order logic. </title> <editor> In D. Sleeman, editor, </editor> <booktitle> Proceedings of the Third European Working Session on Learning, </booktitle> <pages> pages 123-130, </pages> <institution> Turing Institute, </institution> <address> Glasgow, 1988. </address> <publisher> Pitman Publishing. </publisher>
Reference-contexts: Mitchell's argument was based on the version space approach to learning logical concepts. The version spaces approach, while providing impressive results in the specific META-DENDRAL application, does not generalise well as a paradigm for learning logical concepts <ref> [63] </ref>. CHAPTER 1. INTRODUCTION 6 While few would argue that a complex problem such as learning will require search, there appears to be no broad agreement in the machine learning community as to what sorts of goals a learning algorithm should be searching for.
Reference: [64] <author> S.H. Muggleton. Duce, </author> <title> an oracle based approach to constructive induction. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 287-292, </pages> <address> Milan, </address> <year> 1987. </year>
Reference-contexts: To obtain a precise search goal, it remains to add some performance criterion such as minimising errors, maximising comprehensibility, etc. Muggleton's Duce system has been applied in this context where a logical concept is assumed to be fully elaborated in the sample <ref> [64] </ref>, as in the case of a complete chess database. In the sufficient sample case, the bias problem reduces to the problem of designing a search algorithm appropriate to the known search goal. Duce searched for a succinct concept, possibly introducing new predicates. <p> The relationship between queries and computational utility of learning is discussed by Angluin [5]. Utility of the concept representation: The utility of the representation of a concept can be measured in terms of its comprehensibility <ref> [75, 64] </ref> or, as in explanation based learning, its computational efficiency or operationality [72, 59]. Learning requires that an appropriate representation for the concept be found. To restrict the scope of this thesis, the concerns of computational utility and representational utility have been cordoned off using two rough tricks.
Reference: [65] <author> S.H. Muggleton and W. Buntine. </author> <title> Towards constructive induction in first-order predicate calculus. </title> <booktitle> TIRM, The Turing Institute, </booktitle> <address> Glasgow, </address> <year> 1988. </year>
Reference-contexts: While early logical induction systems like Marvin [86] and subsequent systems such as CIGOL <ref> [65] </ref> do appear to incorporate background knowledge, they usually do so to extend the search space rather than to guide the search [14]. Some successful machine learning methodologies do incorporate weaker application specific knowledge by some means.
Reference: [66] <author> G. Pagallo. </author> <title> Learning DNF by decision trees. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 639-644, </pages> <address> Detroit, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: These areas address the needs for * potentially more appropriate representations which retain the implementation advantages of trees but gain the flexibility and comprehensibility of representations like sets of conjunctive rules [74, 82], or trees with conjunctive tests at the leaves <ref> [66] </ref>; * more powerful and flexible search methods rather than the greedy algorithms currently in predominance; and 85 CHAPTER 6. LEARNING CLASS PROBABILITY TREES 86 * support for the knowledge engineer and for a more interactive approach to learning classifi cation rules. <p> There are many variations on this representation theme and several researchers have considered solutions. Quinlan has suggested post-processing trees into rule sets [74], Matheus and Rendell, and Pagallo have proposed growing trees with conjunctive tests at nodes instead of single attribute tests <ref> [53, 66] </ref>, and Chou has proposed an efficient algorithm for growing trellises instead of trees [25] where trellises are directed acyclic graphs with class probability vectors at the leaves and tests at internal nodes (that is, like trees but internal nodes can have multiple parents).
Reference: [67] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan and Kauffman, </publisher> <year> 1988. </year>
Reference-contexts: One part of the process is to develop a basic inference model for the classification task. Should we model classification rules by noise-free decision trees [73], Bayes nets <ref> [67] </ref>, linear classifiers, class probability trees, or perhaps even rules in a pseudo 1st-order logic such as Datalog? The correct choice of model is known to have considerable bearing on statistical problems like learning [8, p110], The choice should be made in the light of subjective knowledge available about the domain, <p> With medical records, for instance, only relevant decision-aiding details about a patient tend to be recorded. A second type of subjective knowledge that could be harnessed is causality <ref> [67] </ref>. Also, the expert could appraise results of induction and possibly resubmit certain fragments for further processing. <p> Bayesian methods offer a unified and well developed approach to a broad class of problems in statistics and decision making [8] and a growing class of problems under the general banner of intelligent systems <ref> [67] </ref>. It is not in the scope of this thesis to attempt to justify this choice in statistics. There is already ample material on this. The approach has strong foundations [8] and typically gives results in accord with intuition [67, 70]. <p> It is not in the scope of this thesis to attempt to justify this choice in statistics. There is already ample material on this. The approach has strong foundations [8] and typically gives results in accord with intuition <ref> [67, 70] </ref>. Discussions of criticisms about the approach are documented by Berger [8] and Cheeseman [24], and appraisals and comparisons of the approach and other uncertainty approaches from an artificial intelligence perspective are given by Horvitz, Heckerman and Langlotz [41]. <p> An alternative to class probability trees for representing uncertain classification rules is the use of Bayes or causal nets <ref> [50, 67] </ref>. These essentially allow a modular decomposition of the attribute space using principles of independence, sometimes guided by intuition about causality. The simplest example is the simple (or "idiot") Bayes classifier which assumes all attributes are independent given class.
Reference: [68] <author> P.B. Philips, R. Holte, and L. </author> <title> Rendell, </title> <editor> editors. </editor> <booktitle> Proc. of First Int. Work. on Change of Representation and Inductive Bias. </booktitle> <year> 1988. </year>
Reference-contexts: Several researchers have since extended this theory. Haussler and others have studied the impact of the strength of bias on learning [38] and Russell and others have presented a logical treatment of declarative bias [85, 84], Researchers have also experimented on the appropriateness of bias <ref> [68] </ref>, and the learning of bias [96, 98]. Much of this research has concentrated on domains without noise or uncertainty. In noisy domains, some researchers have considered the "bias towards simplicity" [31]. There are, however, critical open issues on this line of research.
Reference: [69] <author> P.G. Politakis. </author> <title> Empirical Analysis for Expert Systems. </title> <publisher> Pitman, </publisher> <address> Boston, </address> <year> 1985. </year>
Reference-contexts: There are, of course, other methods being used for obtaining subjective knowledge from an expert: the traditional manual knowledge acquisition method [39], and hybrid methods such as computer-aided interviewing [10] and computer-aided knowledge refinement <ref> [69] </ref>. Although the use CHAPTER 1. INTRODUCTION 10 of sophisticated aids for input, interviewing and editing is improving the speed of these interview-driven methods, they are still time intensive for the expert. Problems over and above this slow development time exist with these methods. Knowledge elicited is not always reliable.
Reference: [70] <author> G. Polya. </author> <title> Patterns of Plausible Inference. </title> <publisher> Princeton University Press, </publisher> <year> 1954. </year>
Reference-contexts: It is not in the scope of this thesis to attempt to justify this choice in statistics. There is already ample material on this. The approach has strong foundations [8] and typically gives results in accord with intuition <ref> [67, 70] </ref>. Discussions of criticisms about the approach are documented by Berger [8] and Cheeseman [24], and appraisals and comparisons of the approach and other uncertainty approaches from an artificial intelligence perspective are given by Horvitz, Heckerman and Langlotz [41].
Reference: [71] <author> W.H. Press, B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling. </author> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1988. </year>
Reference-contexts: The result follows assuming the true concept is in the hypothesis space, since it then will be one of the consistent hypotheses. 2 Fast formulae for computing the incomplete beta function and its inverse are available in mathematical and numerical handbooks <ref> [1, 71] </ref>. To give an idea of the behaviour of beta error, a approximation can be constructed as follows. The beta distribution for sufficiently large parameters can be approximated using the normal distribution.
Reference: [72] <author> J.F. Puget. </author> <title> Goal regression with opponent. </title> <editor> In I. Bratko and N. Lavrac, editors, </editor> <booktitle> Progress in Machine Learning, </booktitle> <pages> pages 121-137. </pages> <publisher> Sigma Press, </publisher> <address> Wilmslow, England, </address> <year> 1987. </year>
Reference-contexts: The relationship between queries and computational utility of learning is discussed by Angluin [5]. Utility of the concept representation: The utility of the representation of a concept can be measured in terms of its comprehensibility [75, 64] or, as in explanation based learning, its computational efficiency or operationality <ref> [72, 59] </ref>. Learning requires that an appropriate representation for the concept be found. To restrict the scope of this thesis, the concerns of computational utility and representational utility have been cordoned off using two rough tricks. No claim is made here that they are optimal in any sense.
Reference: [73] <author> J.R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: This has been a major theme in machine learning research since then. Again good ideas were the initial motivational forces. Hunt's learning system, CLS, has lead to a line of decision tree learning systems such as ID3 and its various commercial derivatives <ref> [73] </ref>, and a parallel family of systems have been developed independently in the applied statistics area [12]. <p> One part of the process is to develop a basic inference model for the classification task. Should we model classification rules by noise-free decision trees <ref> [73] </ref>, Bayes nets [67], linear classifiers, class probability trees, or perhaps even rules in a pseudo 1st-order logic such as Datalog? The correct choice of model is known to have considerable bearing on statistical problems like learning [8, p110], The choice should be made in the light of subjective knowledge available <p> The sample size is usually about the same as ff 0 , and for large ff 0 , the last two terms in the approximation can be dropped out. The entropy function has been used by Quinlan and others to devise a heuristic for building decision trees <ref> [73] </ref>. Some useful expectations of the Dirichlet distribution follow by manipulating Equation 2.3a. Below, the means, variances, and covariances are given (from [8]). <p> A common approach in machine learning is to partition the example space X into disjoint subsets, X = X 1 [ : : : [ X V say, and then to associate a probabilistic rule with each partition. Systems such as ID3 <ref> [73] </ref> and PLS1 [79] do this. Denote a partition by P V . <p> For instance, in a space over 6 propositions, jHj = 2 64 . With a sample of size 200 and confidence of 90% the Blumer bound gives a bound of * &lt; 0:23. Experience with induction tools such as ID3 <ref> [73] </ref> indicates that this bound is not optimal. <p> The approach used by many applied logic induction systems is to use Occam's razor as a "preference ordering" on hypotheses. These systems search for "simpler" consistent hypotheses where the notion of simple is a syntactic notion relative to the description language chosen for the application. For instance, Quinlan's ID3 <ref> [73] </ref> does this by making a simple greedy search for a more compact decision tree consistent with the sample. As a result, the ID3 algorithm could not be expected to perform well, for instance, in learning some DNF formulae. These can have quite complex decision tree representations. <p> We begin, however, with a brief historical sketch in Section 6.1. 6.1 Historical sketch A standard technique for building classification rules from data is the so called recursive partitioning algorithm that forms the basis of systems such as ID3 <ref> [73] </ref> and CART [12]. These algorithms build a tree such as the one shown in Figure 6.25 which has the classes hyperthyroid and not. <p> Eventually Hyafil and Rivest [45] showed the problem was actually NP-complete. Suboptimal methods have been developed using heuristic search of an AND/OR graph [52], and using an information theory approach [34] essentially the same as Quinlan's ID3 algorithm <ref> [73] </ref>, developed much later. Later work in pattern recognition and, particularly, character recognition combined the statistical and computing science approaches with concerns for measurement costs (the inherent cost of making tests at nodes when processing a new example) [25]. <p> For each possible test, hypothetically build leaf nodes at each of the branches corresponding to outcomes of the test and then CHAPTER 6. LEARNING CLASS PROBABILITY TREES 89 evaluate the resultant subtree of depth one according to some heuristic such as information gain <ref> [73] </ref>. The evaluation process can also be looked at in terms of a table. <p> A survey of many different splitting rules can be found in [57]. These are mostly similar to the chi-squared statistic for testing dependence in a contingency table. Some common tests are Information gain: minimise the information left to be gained about the class after having made the test <ref> [73] </ref>: I (class) I (classjtest) = I (class) T X P r (outcome i) I (classjoutcome i) = I (class) + T X n ;i C X n j;i log n ;i The information in the class I (class) is a constant for all potential tests so can be ignored. <p> There are three acknowledged problems with the information gain splitting rule. CHAPTER 6. LEARNING CLASS PROBABILITY TREES 106 Multi-valued attributes: If the attributes being tested are a mixture of binary and multi-valued attributes, then the splitting rule tends to detrimentally favour the multi-valued at tributes <ref> [73, 11] </ref>. Real valued attributes: Similarly to the above, the splitting rule tends to detrimentally favour splitting on real valued attributes, and to choose cut-points too close to the extreme values (Breiman et al. call this end-cut preference [12]).
Reference: [74] <author> J.R. Quinlan. </author> <title> Generating production rules from decision trees. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 304-307, </pages> <address> Milan, </address> <year> 1987. </year>
Reference-contexts: Second, there are important research areas where the Bayesian approach does in principle offer strong guidelines. These areas address the needs for * potentially more appropriate representations which retain the implementation advantages of trees but gain the flexibility and comprehensibility of representations like sets of conjunctive rules <ref> [74, 82] </ref>, or trees with conjunctive tests at the leaves [66]; * more powerful and flexible search methods rather than the greedy algorithms currently in predominance; and 85 CHAPTER 6. <p> Since finer partitions give less accurate probability estimates, the tree growing methods are considerably disadvantaged on such problems. There are many variations on this representation theme and several researchers have considered solutions. Quinlan has suggested post-processing trees into rule sets <ref> [74] </ref>, Matheus and Rendell, and Pagallo have proposed growing trees with conjunctive tests at nodes instead of single attribute tests [53, 66], and Chou has proposed an efficient algorithm for growing trellises instead of trees [25] where trellises are directed acyclic graphs with class probability vectors at the leaves and tests
Reference: [75] <author> J.R. Quinlan. </author> <title> Simplifying decision trees. </title> <editor> In B. Gaines and J. Boose, editors, </editor> <booktitle> Knowledge Acquisition for Knowledge-Based Systems, </booktitle> <pages> pages 239-252. </pages> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1988. </year>
Reference-contexts: to relate the problem of bias to well known problems in Bayesian statistics, and to subsequently decompose bias into functional components that should allow a better understanding of bias and its development. 1.2.2 Overfitting In noisy or uncertain domains decision tree learning algorithms use Occam's razor, a bias towards simplicity <ref> [23, 75] </ref>. This feature has been described as the "accuracy vs. complexity tradeoff" and various studies exist on this in the machine learning literature [75, 31]. This problem is widely acknowledged outside machine learning and a variety of approaches exist [33, 100, 8]. <p> This feature has been described as the "accuracy vs. complexity tradeoff" and various studies exist on this in the machine learning literature <ref> [75, 31] </ref>. This problem is widely acknowledged outside machine learning and a variety of approaches exist [33, 100, 8]. Should these approaches be applied to the machine learning techniques developed within the AI community. <p> Recurrent problems in machine learning such as splitting and pruning rules for decision trees <ref> [57, 75] </ref> and the evaluation of new predicates for constructive induction [53] are just some symptoms of this broad search problem. <p> The relationship between queries and computational utility of learning is discussed by Angluin [5]. Utility of the concept representation: The utility of the representation of a concept can be measured in terms of its comprehensibility <ref> [75, 64] </ref> or, as in explanation based learning, its computational efficiency or operationality [72, 59]. Learning requires that an appropriate representation for the concept be found. To restrict the scope of this thesis, the concerns of computational utility and representational utility have been cordoned off using two rough tricks. <p> The current surge in interest in tree methods, in America especially, has largely been to due to the comparative success of these commercial ventures, and the consistently high standard of empirical work coming from Quinlan and others <ref> [77, 75] </ref>. <p> As each node is being built the subset of training examples that would belong at that node is considered. The basic algorithm is summarised in Figure 6.26. Sometimes, the resultant tree is modified at the end, for instance by pruning back branches into leaves <ref> [75] </ref>. This means there are three important sub-routines for the recursive partitioning algorithm: CHAPTER 6. LEARNING CLASS PROBABILITY TREES 88 Input: A set of training examples. Stopping and splitting rules. Output: A tree with class counts at the leaves. 1. <p> Because the tree has been "grown to fit the sample", this is usually an underestimate and the standard error of the estimate is not appropriate. Resubstitution error estimate with continuity correction The so-called continuity correct <ref> [75] </ref> makes account of the fact that substitution error estimates come from an integral measurement, but in fact the "true" error rates are actually real valued. Quinlan has used this to obtain a conservative estimate of error given by the affine tree functional 1 leaves X l=1 CHAPTER 6. <p> Cross validation can also be used as a means of evaluating a tree building method on a test set using many different samples with independent test sets. Pessimistic pruning Pessimistic pruning, used in earlier versions of C4 <ref> [75] </ref> is given in Figure 6.29. A tree is first grown on the full training set, and then pruned using pessimistic pruning. To prune more or less severely, this method can be made to work with X standard errors in Step 2. <p> There is also, of course, the reoccurring issues of stopping, splitting and pruning rules, and treating unknown values. 6.3.1 Extended representations Decision trees are very verbose in representing certain disjunctive concepts. This was highlighted by Quinlan <ref> [75] </ref> who attempted to build a decision tree equivalent to the logical expression A1 ^ A2 ^ A3 _ A4 ^ A5 ^ A6 _ A7 ^ A8 ^ A9 : (6.35) The smallest possible tree for this expression has 39 internal nodes and 40 leaves, considerably larger than the representation <p> The experiments serve as an interesting study in their own right, however, because few comparative studies of this scale have been made. While many of the data sets used have results already multiply reported in the literature <ref> [102, 17, 23, 26, 75, 2] </ref>, comparisons with literature results will not be made in this and later experiments (although general comparisons were made during implementation of the algorithms as a safety check). <p> This data set of 150 examples gives amazingly good results on almost all classical learning methods (discriminant analysis, etc.) and is included here for comparison. hypo The "hypo" data set is Quinlan's hypothyroid data described in <ref> [77, 75] </ref>, and supplied from an expert system for advising on thyroid disorders which is in routine use at the Garvan Institute of Medical Research in Sydney. <p> The data sets "glass", "votes" and "mush" came from David Aha's machine learning data base available over the academic computer network from the University of California at Irvine, "hypo" and "xd6" came from a collection by Ross Quinlan of the University of Sydney <ref> [75] </ref>, "breast", "lymph" and "tumor" came via Pete Clark of the Turing Institute, and "iris" from Stuart Crawford of Advanced Decision Systems. 6.4.4 Results Relevant results and significance tests for these and the second set of experiments are tabulated in Appendix D.
Reference: [76] <author> J.R. Quinlan. </author> <title> Unknown attribute values in induction. </title> <booktitle> In Proceedings of the Sixth International Machine Learning Workshop, </booktitle> <publisher> Cornell, </publisher> <address> New York, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: If some attribute values are not known the unit probability may be distributed across several leaves to which the example could belong. Quinlan has made an extensive empirical study of various suggested solutions to these problems of unknown values <ref> [76] </ref>. Some of the methods compared included ignoring examples with unknown values, filling in the missing values somehow, splitting an example into a set of fractional examples with unknown values filled in, or treating unknowns as a separate outcome for each test.
Reference: [77] <author> J.R. Quinlan, P.J. Compton, K.A. Horn, and L. Lazarus. </author> <title> Inductive knowledge acquisition: A case study. </title> <editor> In J.R. Quinlan, editor, </editor> <booktitle> Applications of Expert Systems. </booktitle> <publisher> Addison Wesley, </publisher> <address> London, </address> <year> 1987. </year>
Reference-contexts: A large body of research in empirical learning (or induction) of classification rules addresses learning as a knowledge acquisition sub-task in the building of classification systems. Here, learning is intended to replace the manual elicitation of rules from a domain expert <ref> [77] </ref>. Classification rules are used to predict the class of an example, where the class is some discrete (not continuous) variable of practical importance. <p> Some successful machine learning methodologies do incorporate weaker application specific knowledge by some means. Two approaches are the careful selection of attributes in which examples are described <ref> [77, 55] </ref> and the use of various forms of interaction with an expert [90, 56, 20]. In addition, Bayesian statistics, with its notion of subjective knowledge or prior belief, could provide a means by which application specific knowledge can be cautiously incorporated into the learning process [17]. <p> The right subjective knowledge may well be equivalent in value to a possibly expensive sample. The importance of suitable attributes (features or descriptors) for expressing concepts, for instance, is well recognised <ref> [77] </ref>. This is one way in which subjective knowledge can be provided to commercially available induction tools [54]: This provision does not necessarily have to be made overtly. With medical records, for instance, only relevant decision-aiding details about a patient tend to be recorded. <p> The current surge in interest in tree methods, in America especially, has largely been to due to the comparative success of these commercial ventures, and the consistently high standard of empirical work coming from Quinlan and others <ref> [77, 75] </ref>. <p> This data set of 150 examples gives amazingly good results on almost all classical learning methods (discriminant analysis, etc.) and is included here for comparison. hypo The "hypo" data set is Quinlan's hypothyroid data described in <ref> [77, 75] </ref>, and supplied from an expert system for advising on thyroid disorders which is in routine use at the Garvan Institute of Medical Research in Sydney.
Reference: [78] <author> J.R. Quinlan and R.L. Rivest. </author> <title> Inferring decision trees using the minimum description length principle. </title> <journal> Information and Computation, </journal> <volume> 80 </volume> <pages> 227-248, </pages> <year> 1989. </year> <note> BIBLIOGRAPHY 167 </note>
Reference-contexts: For many learning systems in the literature, ideal search bias is never actually specified. Some notable exceptions are the decision tree work of Breiman et al. [12] and Quinlan and Rivest <ref> [78] </ref>. Many publications describe an algorithm and results of the algorithm but never actually describe in general goal oriented terms what the algorithm should be trying to achieve, though they give a description of what the algorithm actually achieves. <p> In learning decision trees, however, the main problem would surely be the super-exponential number of trees in the space. Quinlan and Rivest recently applied minimum encoding methods to learning class probability trees <ref> [78] </ref>. Their encoding approach was similar to MDL but differed in quantitisation. The approach lacked any clear forethought as to the form of the prior implicit in the encoding. The implicit prior actually gave a very strong preference to smaller decision trees, and not surprisingly, they reported overpruning.
Reference: [79] <author> L. Rendell. </author> <title> A general framework for induction and a study of selective induction. </title> <journal> Machine Learning, </journal> <volume> 1(2) </volume> <pages> 172-226, </pages> <year> 1986. </year>
Reference-contexts: A common approach in machine learning is to partition the example space X into disjoint subsets, X = X 1 [ : : : [ X V say, and then to associate a probabilistic rule with each partition. Systems such as ID3 [73] and PLS1 <ref> [79] </ref> do this. Denote a partition by P V . Such an uncertain concept can be modelled by associating class proportions with each partition, as f (c j j x 2 X k ; H) = j;k ; for j indexing the classes and k indexing the partitions.
Reference: [80] <author> B.D. Ripley. </author> <title> An introduction to statistical pattern recognition. </title> <booktitle> In Interactions in Artificial Intelligence and Statistical Methods, </booktitle> <pages> pages 176-187, </pages> <address> Aldershot, UK, 1987. </address> <publisher> Unicom, Gower Technical Press. </publisher>
Reference-contexts: CHAPTER 4. COMPARISONS 63 The criticisms by Breiman et al. are perhaps a bit harsh. For instance, methods of handling discrete variables do exist <ref> [80] </ref>, and various ways of selecting or extracting feature vectors are a means of handling the choice of distance metric.
Reference: [81] <author> J. Rissanen. </author> <title> Stochastic complexity. </title> <journal> J. Roy. Statist. Soc. B, </journal> <volume> 49(3) </volume> <pages> 223-239, </pages> <year> 1987. </year>
Reference-contexts: More recent refinements of the principle come from Wallace and co-workers in the late '60s and Rissanen in the late '70s (see <ref> [100, 81] </ref>). The two more recent approaches are discussed separately below. 4.4.1 Minimum message length Wallace and co-workers adopt a method they refer to as minimum message length (MML). <p> Rissanen makes no appeal to Bayesian methods but instead adopts minimum encoding as a fundamental principle in its own right, as <ref> [81] </ref> a "formal measure of the amount of randomness in the data, defined relative to the selected class of models". This principle originates from the algorithmic complexity theory of Solomonoff, Kolmogorov and Chaitin. <p> This selection method also has an alternative approximate coding interpretation <ref> [81, p231] </ref>. The calculation of the expectation requires having a prior for conditioned on knowing the model class M k . Rissanen suggests choosing a prior to minimise the encoding. MDL uses asymptotic properties of the likelihood and has a ready interpretation as a coding formulae. <p> Rissanen suggests choosing a prior to minimise the encoding. MDL uses asymptotic properties of the likelihood and has a ready interpretation as a coding formulae. One chooses ^ k and ^ to minimise <ref> [81, Equat. 3.9] </ref>. log f (E j M k ; ) + 2 2 This can be interpreted as a modified maximum likelihood approach. The second two terms modify the likelihood according to the dimensionality of the class M k and the size N of the evidence. <p> The second two terms modify the likelihood according to the dimensionality of the class M k and the size N of the evidence. Because in our case k = jHj + jj, this approach is almost equivalent to choosing H to minimise <ref> [81, Equat. 3.9] </ref>. CHAPTER 4. COMPARISONS 60 log f (~c j ~x; H) + 2 2 This formula should be compared with Formula 4.27 from the minimum message length framework. The MDL formula differs primarily in that it has no prior term, but also the final minor quantitisation term differs. <p> He suggests a way of introducing utilities into his analysis is to adjust the model class so that the utility function is incorporated into the selection of model class. For instance, to minimise mean square error, you should use the Gaussian family of densities <ref> [81, p224] </ref> as the basic model class. This is certainly an unnecessary restriction. Suppose, for instance, you thought a Gaussian model was a poor model of the data and you did not wish to use it in the first place.
Reference: [82] <author> R.L. Rivest. </author> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2(3) </volume> <pages> 229-246, </pages> <year> 1987. </year>
Reference-contexts: To ensure PAC-learnability, these need to be coupled with a polynomial time algorithm for finding a hypothesis consistent with a sample. The generality of these two theorems has allowed an extensive variety of concept classes to be considered <ref> [38, 82] </ref>. 4.2.4 Discussion The framework and techniques developed within computational learning theory, for instance PAC-ness and learnability, have allowed extensive worst case complexity results to be developed. <p> Finally, a theoretical treatment is given in Section 5.6 of the Bayesian approach to the problem of error bounds. 5.1 Introduction The Valiant model has been developed by a number of researchers to yield an impressive array of results and research tools <ref> [38, 82] </ref>. The Valiant model has also received strong criticism from 64 CHAPTER 5. EXTENSIONS TO VALIANT'S FRAMEWORK 65 Amsterdam for its poor track record in applied learning [3], and for its restricted scope [4]. <p> Suppose, as Littlestone considers [51], we suspect there are abundant irrelevant or redundant attributes. It would be an obscure application where we know exactly how many attributes are irrelevant or redundant. Suppose, as Rivest considers <ref> [82] </ref>, we believe decision lists form a suitable hypothesis space. Do we use 5-DL (decision lists with conjunctions of size 5 at each decision) or maybe 10-DL? In fact, this is what we typically want the induction system to tell us. <p> Second, there are important research areas where the Bayesian approach does in principle offer strong guidelines. These areas address the needs for * potentially more appropriate representations which retain the implementation advantages of trees but gain the flexibility and comprehensibility of representations like sets of conjunctive rules <ref> [74, 82] </ref>, or trees with conjunctive tests at the leaves [66]; * more powerful and flexible search methods rather than the greedy algorithms currently in predominance; and 85 CHAPTER 6. <p> CONCLUSION 124 3. What are suitable algorithms and what is the computational complexity of searching for "preferred" consistent hypothesis for various concept classes and preference criteria? Both Haussler [38, Section 5] and Rivest <ref> [82, Section 5.3] </ref> have briefly considered this question using "simplicity". 4.
Reference: [83] <author> R.L. Rivest and R. Sloan. </author> <title> Learning complicated concepts reliably and usefully (extended abstract). </title> <booktitle> In Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 635-640, </pages> <address> Saint Paul, Minnesota, </address> <year> 1988. </year>
Reference-contexts: EXTENSIONS TO VALIANT'S FRAMEWORK 65 Amsterdam for its poor track record in applied learning [3], and for its restricted scope [4]. The Valiant model is becoming recognised as a standard for formal learning theory and several extensions exist <ref> [6, 3, 83] </ref>. But if it is to be a standard, we should heed Amsterdams criticisms and first consider just how well the Valiant model handles its intended task, without extensions and considering only its (admittedly restricted) current scope.
Reference: [84] <author> S.J. Russell. </author> <title> Tree-structured bias. </title> <booktitle> In Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 641-645, </pages> <address> Saint Paul, Minnesota, </address> <year> 1988. </year>
Reference-contexts: Several researchers have since extended this theory. Haussler and others have studied the impact of the strength of bias on learning [38] and Russell and others have presented a logical treatment of declarative bias <ref> [85, 84] </ref>, Researchers have also experimented on the appropriateness of bias [68], and the learning of bias [96, 98]. Much of this research has concentrated on domains without noise or uncertainty. In noisy domains, some researchers have considered the "bias towards simplicity" [31]. <p> The Bayesian framework has no corresponding component. CHAPTER 4. COMPARISONS 56 Much of the bias research in the machine learning community is concerned with hypothesis space bias. Russell, for instance, considers how this bias can be derived using a declarative bias, from logical definitions of the space of concepts <ref> [84] </ref>, while Haussler and others have considered how the size and structure of the hypothesis space effect bounds of learning performance. For many learning systems in the literature, ideal search bias is never actually specified.
Reference: [85] <author> S.J. Russell and B.N. Grosof. </author> <title> A declarative approach to bias in concept learning. </title> <booktitle> In Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pages 505-510, </pages> <address> Seattle, </address> <year> 1987. </year>
Reference-contexts: Several researchers have since extended this theory. Haussler and others have studied the impact of the strength of bias on learning [38] and Russell and others have presented a logical treatment of declarative bias <ref> [85, 84] </ref>, Researchers have also experimented on the appropriateness of bias [68], and the learning of bias [96, 98]. Much of this research has concentrated on domains without noise or uncertainty. In noisy domains, some researchers have considered the "bias towards simplicity" [31].
Reference: [86] <author> C. A. Sammut and R.B. Banerji. </author> <title> Hierarchical memories: an aid to concept learning. In R.S. </title> <editor> Michalski, J. Carbonell, and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning AnArtificial Intelligence Approach, </booktitle> <volume> Vol. II. </volume> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, </address> <year> 1986. </year>
Reference-contexts: While early logical induction systems like Marvin <ref> [86] </ref> and subsequent systems such as CIGOL [65] do appear to incorporate background knowledge, they usually do so to extend the search space rather than to guide the search [14]. Some successful machine learning methodologies do incorporate weaker application specific knowledge by some means.
Reference: [87] <author> J.C. Schlimmer and R.H. Granger Jr. </author> <title> Incremental learning from noisy data. </title> <journal> Machine Learning, </journal> <volume> 1(3) </volume> <pages> 317-354, </pages> <year> 1986. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 8 1.2.7 Incremental learning and concept drift Incremental learning is the task of learning where examples are supplied in increments rather than in a single batch and the learner is required to incrementally update the working hypothesis as the increments are received <ref> [88, 87] </ref>. Concept drift is a problem that only applies in the incremental context. It describes the situation where the concept being learned is time dependent, so the learning system must also track the change in the concept as time progresses [87]. <p> Concept drift is a problem that only applies in the incremental context. It describes the situation where the concept being learned is time dependent, so the learning system must also track the change in the concept as time progresses <ref> [87] </ref>. While these are certainly worthy problems, they are problems that are perhaps best addressed when the basic process of non-incremental learning of a time independent concept is better understood. In the relatively mature area of decision tree learning, these problems are currently being investigated with some success. <p> The data was transcribed from a field manual on mushrooms and filled in to give 8000 examples by J. Schlimmer and reported in his thesis and elsewhere <ref> [87] </ref>. Due to its book source, it can be considered virtually noise free. votes The "votes" data extracts details from the 1984 United States congressional voting records. These 435 examples record key votes of 267 democrats and 168 republicans on issues such CHAPTER 6.
Reference: [88] <editor> A.M. Segre, editor. </editor> <booktitle> Proceedings of the Sixth International Machine Learning Workshop. </booktitle> <publisher> Morgan Kaufmann, Cornell, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 5 1.2.3 "Sufficient" vs. "insufficient" sample methods While more recent research is focusing on such distinctions as learning from large as opposed to smaller data sets [22], and incremental as opposed to batch learning <ref> [88] </ref>, a related distinction that is widely understood but never really highlighted is the distinction between "sufficient" and "insufficient" sample sizes. Any reasonable model of statistics or learning has asymptotic properties that guarantee the model will converge on an optimal hypothesis in some sense. <p> CHAPTER 1. INTRODUCTION 8 1.2.7 Incremental learning and concept drift Incremental learning is the task of learning where examples are supplied in increments rather than in a single batch and the learner is required to incrementally update the working hypothesis as the increments are received <ref> [88, 87] </ref>. Concept drift is a problem that only applies in the incremental context. It describes the situation where the concept being learned is time dependent, so the learning system must also track the change in the concept as time progresses [87].
Reference: [89] <author> G. Shackelford and D. Volper. </author> <title> Learning k-dnf with noise in the attributes. </title> <editor> In D. Haussler and L. Pitt, editors, COLT'88: </editor> <booktitle> 1988 Workshop on Computational Learning Theory, </booktitle> <pages> pages 97-105, </pages> <publisher> MIT, </publisher> <address> Boston, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Appendix B Inverting a Noise Model This appendix shows how to invert a noise model on discrete domains. This is a generalised and simplified version of a proof by Shackelford and Volper <ref> [89] </ref>. Suppose an example x is described by a discrete attributes as a vector (x 1 ; : : : ; x a ) where x i is the value of the i-th attribute. Suppose also that the class for x is given by x 0 is is also discrete.
Reference: [90] <author> A. Shapiro. </author> <title> Structured Induction in Expert Systems. </title> <publisher> Addison Wesley, </publisher> <address> London, </address> <year> 1987. </year>
Reference-contexts: Some successful machine learning methodologies do incorporate weaker application specific knowledge by some means. Two approaches are the careful selection of attributes in which examples are described [77, 55] and the use of various forms of interaction with an expert <ref> [90, 56, 20] </ref>. In addition, Bayesian statistics, with its notion of subjective knowledge or prior belief, could provide a means by which application specific knowledge can be cautiously incorporated into the learning process [17]. <p> So we do not always wish to totally replace learning by some method of obtaining subjective knowledge from an expert. A compromise is to enhance the interaction with an expert during empirical learning. An interactive approach has been reported by Shapiro <ref> [90] </ref>. He extended an ID3-like algorithm so that the tree building process itself, the selection of tests at each new decision tree node, could be guided by the user/expert.
Reference: [91] <author> J.E. Shore. </author> <title> Relative entropy, probabilistic inference and AI. </title> <editor> In L. N. Kanal and J. F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence. </booktitle> <publisher> Elsevier Science Publishers, </publisher> <address> Amsterdam, </address> <year> 1986. </year>
Reference-contexts: ff C ) ff 0 I ff 1 ; : : : ; ff 0 2 1 log i=1 ff i ! I (p 1 ; : : : ; p C ) = i=1 p i log p i ...entropy function (2.3h) Notice that the entropy or information function <ref> [91] </ref> of Equation 2.3h occurs in the approximation of the beta function, Equation 2.3g. The sample size is usually about the same as ff 0 , and for large ff 0 , the last two terms in the approximation can be dropped out. <p> That is, the (protocol) likelihood function for the hypothesis is the same as the other hypothesis. One suitable measure for the closeness of two distributions P 1 and P 2 on evidence space E is an information theoretic one: cross entropy <ref> [91] </ref> or discriminant information, given by H e (P 1 ; P 2 ) = E e~P 1 log P 2 : Any reasonable metric on probability distributions could be used instead.
Reference: [92] <author> R. Sloan. </author> <title> Types of noise in data for concept learning. </title> <editor> In D. Haussler and L. Pitt, editors, COLT'88: </editor> <booktitle> 1988 Workshop on Computational Learning Theory, </booktitle> <pages> pages 91-96, </pages> <publisher> MIT, </publisher> <address> Boston, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Examples are generated as for the logical random examples, but are passed through a noise filter before being presented. The noise filter distorts the examples in some manner and it is up to the learner to somehow reverse the effects of this distortion to uncover the logical concept. Sloan <ref> [92] </ref> reviews a number of models for noise that include malicious and benevolent noise. Malicious noise comes from an omnipotent omniscient adversary that has knowledge of the learner's state to alter the classified examples in the worst possible manner. Benevolent noise is independent of the learner's state.
Reference: [93] <author> R. Solomonoff. </author> <title> The applications of algorithmic probability to problems in artificial intelligence. </title> <editor> In L. N. Kanal and J. F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence. </booktitle> <publisher> Elsevier Science Publishers, </publisher> <address> Amsterdam, </address> <year> 1986. </year> <note> BIBLIOGRAPHY 168 </note>
Reference-contexts: We thus naturally arrive at a very simple trade-off between the complexity of a model and its goodness of fit. Early developments on this general principle arose independently from Solomonoff <ref> [93] </ref>, Kol-mogorov and Chaitin in the '60s (see references in [100]); they emphasised the computability aspects of the principle and their theory is sometimes referred to as algorithmic complexity.
Reference: [94] <author> L. Sterling and E. Shapiro. </author> <title> The Art of Prolog: Advanced Programming Techniques. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: With concepts expressible in first-order logic, the distinction between interpretation and representation becomes critical because different implementations of first-order sentences can have vastly different termination and computational properties. For instance, some Prolog programs terminate on a breadth-first interpreter but not a depth-first interpreter <ref> [94] </ref>. Learning requires searching the space of representations, and we give this a special status. The space of representations is called the hypothesis space and is usually denoted H. The other aspects of a concept, however, will need to be considered in a theory of learning. <p> We shall consider three kinds of concept representations in this thesis: Definite clauses: These are the logical sentences used in the purest version of the programming language Prolog. They form an interesting subset of first-order logic. The notation of Sterling and Shapiro <ref> [94] </ref>, similar to Edinburgh Prolog, is followed here. Figure 3.5 gives two programs for reversing lists. "[AjList]" represents the element A concatenated to the list List, and corresponds to (cons A List) in LISP. A formal and a syntactic definition of the language can be found in [94]. reverse (List; Listrev) <p> Sterling and Shapiro <ref> [94] </ref>, similar to Edinburgh Prolog, is followed here. Figure 3.5 gives two programs for reversing lists. "[AjList]" represents the element A concatenated to the list List, and corresponds to (cons A List) in LISP. A formal and a syntactic definition of the language can be found in [94]. reverse (List; Listrev) reverse1 (List; []; Listrev): reverse1 ([]; Ans; Ans): reverse1 ([AjList]; Rev; Ans) reverse1 (List; [AjRev]; Ans): naive reverse ([AjList]; Ans) naive reverse (List; Listrev); append (Listrev; [A]; Ans): append ([]; Ans; Ans): append ([AjList1]; List2; [AjAns]) append (List1; List2; Ans): CHAPTER 3.
Reference: [95] <author> H. Tamaki and T. Sato. </author> <title> Unfold/Fold transformations of logic programs. </title> <booktitle> In Proceedings of 2nd International Logic Programming Conference, </booktitle> <pages> pages 127-138, </pages> <institution> Uppsala, Sweden, </institution> <year> 1984. </year>
Reference-contexts: The second concern is refinement, which would consist of transforming a pure Prolog program into a program that would operate on, say, a standard Prolog interpreter, while at the same time attempting to improve the efficiency of the program. For instance, program transformation techniques <ref> [21, 95] </ref> are concerned with this task. Second, to accommodate computational efficiency when analysing learning performance, the following approach can be used. The strategy best used by a learner with unbounded computing resources should first be found.
Reference: [96] <author> D. Tcheng, B. Lambert, S. C-Y. Lu, and L. Rendell. </author> <title> Building robust learning systems by combining induction and optimization. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 806-812, </pages> <address> Detroit, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Haussler and others have studied the impact of the strength of bias on learning [38] and Russell and others have presented a logical treatment of declarative bias [85, 84], Researchers have also experimented on the appropriateness of bias [68], and the learning of bias <ref> [96, 98] </ref>. Much of this research has concentrated on domains without noise or uncertainty. In noisy domains, some researchers have considered the "bias towards simplicity" [31]. There are, however, critical open issues on this line of research.
Reference: [97] <editor> G. Tecuci. DISCIPLE: </editor> <title> a theory, methodology and system for learning expert knowledge. </title> <type> PhD thesis, </type> <institution> Universite de Paris-Sud, </institution> <year> 1988. </year>
Reference-contexts: Michie [56] describes an application of this technique to the credit assessment domain, in which a 5% increase in accuracy over automatically generated trees was obtained. Tecuci describes the Disciple system <ref> [97] </ref>, a system that interactively develops rules from data by extracting explanations from an expert. Expert supplied explanations, like interview obtained rules, are well known to be often incomplete or overly general.
Reference: [98] <author> P.E. Utgoff. </author> <title> Machine Learning of Inductive Bias. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1986. </year>
Reference-contexts: The first clear enunciation of this problem was by Mitchell, who referred to it as the problem of bias [60], where bias is the set of influences that cause a learner to favour one hypothesis over another. Utgoff developed this idea further, saying <ref> [98, p5] </ref> CHAPTER 1. INTRODUCTION 4 Given a set of training instances, bias is the set of all factors that collectively influence hypothesis selection. These factors include the definition of the space of hypotheses and definition of the algorithm that searches the space of concept descriptions. <p> Haussler and others have studied the impact of the strength of bias on learning [38] and Russell and others have presented a logical treatment of declarative bias [85, 84], Researchers have also experimented on the appropriateness of bias [68], and the learning of bias <ref> [96, 98] </ref>. Much of this research has concentrated on domains without noise or uncertainty. In noisy domains, some researchers have considered the "bias towards simplicity" [31]. There are, however, critical open issues on this line of research.
Reference: [99] <author> L.G. Valiant. </author> <title> A theory of the learnable. </title> <journal> CACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <year> 1985. </year>
Reference-contexts: Substantial experimental work has been undertaken, a host of issues and problems have been raised, but some existing theories of learning in the computing literature (some such theories <ref> [35, 99] </ref> are reviewed in Chapter 4) seem inadequate to explain the observed phenomena or resolve the problems. It would seem that further theory, borrowed from statistics for instance, needs to be thrown at these problems and experimentally evaluated to help guide in the search for solutions. <p> This provides a broad framework for addressing issues such as constructive induction or learning in other representational contexts. 1.2.5 The theory and the practice of learning algorithms Valiant's framework views learning from a computational complexity perspective and seeks to precisely define the computational capabilities of learning systems <ref> [99, 37] </ref>. In the learning of logical concepts from random examples, where much of the theory has been concentrated, results centre around the strength of bias and resultant worst-case complexity results about learning [38]. This, however, only contributes a small way towards an understanding of the design of learning algorithms. <p> The chapter is built around a framework for induction in both the logical and the uncertain contexts. The framework is based on ideas from Valiant <ref> [99] </ref> and Angluin and Smith [7], but has been configured so that it is suitable for applying Bayesian principles. The resultant theory gives a precise and statistically founded basis for Mitchell's notion of induction "as search" [61], specifying suitable search spaces and search heuristics for different learning contexts. <p> For the learner to completely determine the presentation process, he must determine (1) what the logical concept is, but also (2) how the unclassified examples are randomly selected. Valiant has represented this second requirement by a function D <ref> [99, p1136] </ref> giving the distribution of examples. Additional parameters independent of the true concept are sometimes required to specify (2). The learning protocol together with Bayes theorem enables posterior belief in hypotheses, conditioned on the evidence, to be determined. <p> Computational utility of learning: The learner must of course perform within reasonable computational limits. In addition, computational efficiency may sometimes be traded for another kind of learning performance. This general aspect of learning is a subject of considerable breadth. Valiant <ref> [99] </ref> and Haussler [38], among others, have developed a framework and present results on this in the context of the logical random example protocol. The incremental induction problem [51], is concerned with economising computational cost as well as prediction errors while new examples are being presented. <p> And due to space, we only consider the fundamental characteristics of each coupled with a fairly broad-brush comparison. The first theory compared is Gold's paradigm [35], widely recognised as the first learning theory in computing science. The second considered is computational learning theory, developed by Valiant <ref> [99] </ref>, Haussler [38] and others. The third theory covered is the bias framework reviewed in the Introduction, Chapter 1. The third theory covered in some detail is the encoding approaches introduced by several authors, Risannen's Minimum Description Length (MDL) and Wallace's Minimum Message Length (MML). <p> This was, arguably, the first formal attempt to develop a theory of learning within a computational complexity framework. Valiant wished to show that <ref> [99, p1134] </ref>: 1. The machines can provably learn whole classes of concepts. Furthermore, these classes can be characterised. 2. The computational process by which the machines deduce the desired programs requires a feasible (i.e. polynomial) number of steps.
Reference: [100] <author> C.S. Wallace and P.R. Freeman. </author> <title> Estimation and inference by compact encoding. </title> <journal> J. Roy. Statist. Soc. B, </journal> <volume> 49(3) </volume> <pages> 240-265, </pages> <year> 1987. </year>
Reference-contexts: This feature has been described as the "accuracy vs. complexity tradeoff" and various studies exist on this in the machine learning literature [75, 31]. This problem is widely acknowledged outside machine learning and a variety of approaches exist <ref> [33, 100, 8] </ref>. Should these approaches be applied to the machine learning techniques developed within the AI community. <p> COMPARISONS 57 parts, the first part encodes the suggested hypothesis and the second part encodes the sample on the assumption that the hypothesis is indeed the true one. The minimum encoding principle says to find the hypothesis minimising the total encoding. Wallace and Freeman <ref> [100] </ref> say: We may first estimate the parameters [for the data model] and then encode the data under the assumption that these are the true values. The encoding string must now, however, contain a specification of the estimated values. <p> We thus naturally arrive at a very simple trade-off between the complexity of a model and its goodness of fit. Early developments on this general principle arose independently from Solomonoff [93], Kol-mogorov and Chaitin in the '60s (see references in <ref> [100] </ref>); they emphasised the computability aspects of the principle and their theory is sometimes referred to as algorithmic complexity. More recent refinements of the principle come from Wallace and co-workers in the late '60s and Rissanen in the late '70s (see [100, 81]). <p> More recent refinements of the principle come from Wallace and co-workers in the late '60s and Rissanen in the late '70s (see <ref> [100, 81] </ref>). The two more recent approaches are discussed separately below. 4.4.1 Minimum message length Wallace and co-workers adopt a method they refer to as minimum message length (MML). <p> In the terminology of this chapter, given evidence E, the one version of the MML approach finds a hypothesis H and additional parameters that maximises the quantity <ref> [100, p245,p248] </ref> P r (H; )P r (E j H; ) I E (H; ) where I E (H; ) is the Fisher information [8, p88] for evidence E given by det E E~H; D 2 log P r (E j H; ) ; (4.25) where det () corresponds to the <p> The argument involves considering maximising a likelihood defined over the space of quantitisations, and second order expansions of the data likelihood <ref> [100] </ref>. 4.4.2 Stochastic complexity Rissanen's general approach is referred to as stochastic complexity and he proposes two methods of implementing this, the minimum description length (MDL) principle and the predictive minimum description length (PMDL) principle.
Reference: [101] <author> D.A. Waterman. </author> <title> A Guide to Expert Systems. </title> <publisher> Addison Wesley, </publisher> <year> 1986. </year>
Reference-contexts: INTRODUCTION 7 Another result is to highlight that computational learning theory, in its current form, provides an extensive theory for learning in the context of a sufficient sample. 1.2.6 The myth of "universal" learning methods Empirical learning seems to ignore one of the key lessons for AI in the 1970s <ref> [101, p4] </ref>, the strong knowledge principle: to make a program intelligent, provide it with lots of high quality specific knowledge about some problem area. There are notable exceptions such as the META-DENDRAL experiments [13].

References-found: 101

