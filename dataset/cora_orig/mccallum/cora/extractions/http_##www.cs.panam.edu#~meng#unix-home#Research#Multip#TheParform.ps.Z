URL: http://www.cs.panam.edu/~meng/unix-home/Research/Multip/TheParform.ps.Z
Refering-URL: http://www.cs.panam.edu/~meng/unix-home/Research/Multip/
Root-URL: http://www.cs.panam.edu
Email: fcap, strumpeng@ifi.unizh.ch  
Title: The Parform A High Performance Platform for Parallel Computing in a Distributed Workstation Environment  
Author: Clemens H. Cap, Volker Strumpen 
Keyword: Distributed parallel computing, idle workstations, dynamic load balancing, scalability, finite difference methods.  
Note: Subject Classification: D.1.3, D.4.7, C.2.5 (ACM/CRCS)  
Date: June 23, 1992  
Address: Winterthurerstrasse 190 CH-8057 Zurich, Switzerland  
Affiliation: Institut fur Informatik Universitat Zurich  
Abstract: The typical workstation in a LAN is idle during large periods of time. Under the concept of a hypercomputer this unused, distributed computing power can be put at the disposal of the user. The dynamic, heterogeneous, and distributed environment calls for a platform taking care of transparency, parallelization, load balancing and other issues. We describe such a system which, by optimized design and dynamic load distribution, proves faster than many related approaches. Performance measurements and an analytic model on scalability are presented for an explicit finite difference PDE solver. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Ahuja, N. Carriero, D. Gelernter, Linda and Friends, </author> <booktitle> IEEE Computer 19(8) (1986), </booktitle> <pages> 26-34. </pages>
Reference-contexts: In research institutions with state of the art RISC workstations often some 300 Mflops are wasted by idling. A number of recent research activities try to exploit the computing power of such environments, for example LINDA <ref> [1] </ref> and PVM [2]. In this paper we identify and describe the main problems of those approaches. Section 2 describes the architecture of the hypercomputer platform designed in our group, nicknamed The Parform.
Reference: [2] <author> A. Beguelin, J.J. Dongarra, G.A. Geist, R. Mancheck, </author> <title> V.S. Sunderam, A User's Guide to PVM Parallel Virtual Machine, </title> <institution> Oak Ridge National Laboratory, ORNL/TM-11828, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: In research institutions with state of the art RISC workstations often some 300 Mflops are wasted by idling. A number of recent research activities try to exploit the computing power of such environments, for example LINDA [1] and PVM <ref> [2] </ref>. In this paper we identify and describe the main problems of those approaches. Section 2 describes the architecture of the hypercomputer platform designed in our group, nicknamed The Parform. <p> Runtimes for heat solver in seconds. The Parallel Virtual Machine PVM, developed by Dongarra and others <ref> [2] </ref> is a very similar approach to The Parform. Measurements with PVM version 2.4.0 using the new fast communication primitives vrcv and vsnd show lower performance than The Parform. Several concepts in PVM, for example the startup phase or the remote daemons produce more overhead than The Parform.
Reference: [3] <author> B. Lyon, </author> <title> Sun External Data Representation Specification (Sun Microsystems, </title> <publisher> Inc., </publisher> <address> Mountain View, </address> <year> 1984). </year>
Reference-contexts: The library functions supporting communication also perform presentation layer tasks like converting different data representations. Upon startup, flags for the necessary conversions are set as encoded in the host file. By choosing appropriate values for the conversion flags, the user has the choice between sender-makes-it-right, receiver-makes-it-right or XDR-style encoding <ref> [3] </ref>.
Reference: [4] <author> S. Mullender, </author> <title> Distributed Systems (Addison-Wesley, </title> <address> New York, </address> <year> 1989). </year>
Reference-contexts: In heterogeneous environments the data representations of different architectures should be converted without programmer interaction. These two issues are well known in distributed systems <ref> [4] </ref>. At the present state of the art it seems virtually impossible to get high speedup by applying automatic parallelization techniques to arbitrary programs. This is even true for classical static, homogeneous, tightly coupled architectures. Therefore, a suitable parallel programming model has to be provided to the programmer. <p> USENET groups cited "ISO-OSI will tomorrow handle the loads of yesterday whereas TCP today is handling the loads of today". NASA designs the officially required standardized protocols of their space station Freedom around high speed protocols of their own [5]. Nevertheless, porting The Parform to the ANSA network standard <ref> [4] </ref> is planned for a later phase of the project to study aspects of interfacing with existing distributed system platforms. However, at the cost of additional overhead.
Reference: [5] <author> A.C. Weaver, </author> <title> XTP for the NASA Space Station, Protocols for HighSpeed Networks, </title> <editor> H. Rudin, R. Williamson, ed. </editor> <publisher> (North-Holland, </publisher> <address> Amsterdam, </address> <year> 1989). </year>
Reference-contexts: But many of them produce much overhead. USENET groups cited "ISO-OSI will tomorrow handle the loads of yesterday whereas TCP today is handling the loads of today". NASA designs the officially required standardized protocols of their space station Freedom around high speed protocols of their own <ref> [5] </ref>. Nevertheless, porting The Parform to the ANSA network standard [4] is planned for a later phase of the project to study aspects of interfacing with existing distributed system platforms. However, at the cost of additional overhead.
Reference: [6] <author> G. Schoinas, </author> <title> Issues on the Implementation of Programming System for Distributed Applications, </title> <type> Draft Paper, </type> <institution> University of Crete (1991). </institution>
Reference: [7] <author> M. Schwartz, </author> <title> Telecommunication Networks: Protocols, Modeling and Analysis (Addison-Wesley, </title> <address> Reading, </address> <year> 1987). </year> <month> 19 </month>
Reference-contexts: Network congestion occurs, when the rate of communication comes close to the throughput of the network. This phenomenon is a physical limitation of the communication medium. As it is well known <ref> [7] </ref>, this is more likely to be a problem 15 with CSMA/CD type networks like the Ethernet than with token-passing tech-niques. With the random-access technique of the Ethernet collisions might occur when many stations try to transmit a frame at approximately the same time. <p> The frame length f is the quotient of the number of bits of the frame and the cable transmission rate, which is 10 Mbit per second in a standard Ethernet. Thus, f = 0:65ms for our 818 byte frames. Ethernet modeling in <ref> [7] </ref> offers the following formula for the normalized transfer time fl of a single frame, assuming constant frame length f : fl = ae 2 [1 ae (1 + (2e + 1)a)] + 2 (1 e 2aea )( 2 2 (e ae (a+1)1 1 + e 2aea ) 16 e is
Reference: [8] <author> G.D. Smith, </author> <title> Numerical Solution of Partial Differential Equations: </title> <publisher> Finite Differ--ence Methods (Oxford University Press, </publisher> <address> New York, </address> <year> 1985). </year>
Reference-contexts: For more details see <ref> [8] </ref>. Given the initial condition u (0) i;j , the values u (k+1) i;j are calculated with the recursive equation u (k+1) = f (u (k) ).
Reference: [9] <author> W.R. Stevens, </author> <title> UNIX Network Programming (Prentice-Hall, </title> <address> Englewood Cliffs, </address> <year> 1990). </year>
Reference-contexts: We also successfully employed a MicroVax running Ultrix and Silicon Graphics workstations during early phases of our work. The system is implemented on top of the UNIX operating system and the transport layer of the Internet protocol suite, using TCP, UDP and the Berkeley socket mechanisms <ref> [9] </ref>. Application programs must be written in message passing style assuming distributed memory. Communication preserves the ordering of messages and uses the reliable, bidirectional, connection oriented TCP protocol. Synchronization can be done by blocking platform function calls, which wait until the receipt of a message.
Reference: [10] <author> A.S. Tanenbaum, </author> <booktitle> Modern Operating Systems (Prentice-Hall, </booktitle> <address> Englewood Cliffs, </address> <year> 1992). </year>
Reference-contexts: Nevertheless, porting The Parform to the ANSA network standard [4] is planned for a later phase of the project to study aspects of interfacing with existing distributed system platforms. However, at the cost of additional overhead. More attractive are ports to the MACH operating system <ref> [10] </ref>, since they allow The Parform to use the efficient scheduling and communication primitives of modern microkernel architectures. 3 An Application: Heat Conduction During the various phases of the development of The Parform a number of examples has been studied, among them the calculation of fractals, cubic convolution algorithms for performing
Reference: [11] <author> G. Wilson, ed., </author> <title> Linda-Like Systems and Their Implementation, </title> <type> Technical Report 91-13, </type> <note> Edinburgh Parallel Computing Centre (June 1991). 20 </note>
Reference-contexts: This poses problems, if a task is divided into an inappropriate number of subtasks. The main bottleneck of LINDA in a distributed environment is the concept of tuple space, especially the necessary scanning operations to find tuples of certain formats <ref> [11] </ref>. In our approach though, size and number of the subtasks are optimized with respect to the present load situation analyzed by the load sensors of the platform. A heuristic, adapted to the problem, determines division-parameters, which characterize the subtasks. <p> The poor performance of the LINDA implementation POSYBL can thoroughly be explained by the overhead of tuple space management. With 10 to 20 processors the speedup essentially remains constant. Although work on high speed tuple space implementations is in progress <ref> [11] </ref>, tuple space management is a principle bottleneck of the LINDA approach, rather suited for shared memory architectures than for distributed systems. Processors Linda PVM The Parform, homogen. Part. The Parform, heterogen.
References-found: 11

