URL: http://www.ai.mit.edu/projects/cbcl/course9.641-F97/pmlp.ps
Refering-URL: http://www.ai.mit.edu/projects/cbcl/course9.641-F97/
Root-URL: 
Title: A MEAN FIELD LEARNING ALGORITHM FOR UNSUPERVISED NEURAL NETWORKS  
Author: LAWRENCE SAUL AND MICHAEL JORDAN 
Address: 180 Park Ave D-130 Florham Park, NJ 07932  79 Amherst Street, E10-034D Cambridge, MA 02139  
Affiliation: AT&T Labs Research  Massachusetts Institute of Technology Center for Biological and Computational Learning  
Abstract: We introduce a learning algorithm for unsupervised neural networks based on ideas from statistical mechanics. The algorithm is derived from a mean field approximation for large, layered sigmoid belief networks. We show how to (approximately) infer the statistics of these networks without resort to sampling. This is done by solving the mean field equations, which relate the statistics of each unit to those of its Markov blanket. Using these statistics as target values, the weights in the network are adapted by a local delta rule. We evaluate the strengths and weaknesses of these networks for problems in statistical pattern recognition. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> D. Ackley, G. Hinton, and T. Sejnowski. </author> <title> A learning algorithm for Boltzmann machines. </title> <booktitle> Cognitive Science 9 </booktitle> <month> 147-169 </month> <year> (1985). </year>
Reference-contexts: The probabilistic semantics in these networks allow one to infer target values for hidden units, even in an unsupervised setting. The Boltzmann machine <ref> [1] </ref> was the first neural network to be endowed with probabilistic semantics. It has a simple Hebb-like learning rule and a fully probabilistic interpretation as a Markov random field. A serious problem for Boltzmann machines, however, is computing the statistics that appear in the learning rule. <p> The right hand side of eq. (22) is minimized when: ~ = hzi + 2 (1 2~)hffiz 2 i Eq. (23) has a unique solution in the interval ~ 2 <ref> [0; 1] </ref>. Given values for hzi and hffiz 2 i, it is easily solved by iteration; in fact, the iteration ~ hzi + 1 2 (1 2~)hffiz 2 i i is guaranteed to tighten the upper bound in eq. (22). <p> On the other hand, iterating eq. (8) for ` i does not always lead to an increase in eq. (24); hence, the optimal values for ` i cannot be found in this way. Instead, for each update, one must search the interval ` i 2 <ref> [0; 1] </ref> using some sort of bracketing procedure [17] to find a local maximum in eq. (24).
Reference: 2. <author> C. Peterson and J. R. Anderson. </author> <title> A mean field theory learning algorithm for neural networks. </title> <journal> Complex Systems 1 </journal> <month> 995-1019 </month> <year> (1987). </year>
Reference-contexts: A serious problem for Boltzmann machines, however, is computing the statistics that appear in the learning rule. In general, one has to rely on approximate methods, such as Gibbs sampling or mean field theory <ref> [2] </ref>, to estimate these statistics; exact calculations are not tractable for layered networks. Experience has shown, however, that sampling methods are too slow, and mean field approximations too impoverished [3], to be used in this way. A different approach has been to recast neural networks as layered belief networks [4]. <p> The terms inside the brackets can be viewed as effective influences (or "mean fields") on each unit in the network. The reader will note that sigmoid belief networks have twice as many mean field parameters as their undirected counterparts <ref> [2] </ref>. For this we can offer the following intuition. Whereas the parameters ` i are determined by top-down and bottom-up influences, the parameters ~ ` i are determined only by top-down influences. The distinction|essentially, one between parents and children|is only meaningful for directed graphical models.
Reference: 3. <author> C. Galland. </author> <title> The limitations of deterministic Boltzmann machine learning. </title> <booktitle> Network 4 </booktitle> <pages> 355-379. </pages>
Reference-contexts: In general, one has to rely on approximate methods, such as Gibbs sampling or mean field theory [2], to estimate these statistics; exact calculations are not tractable for layered networks. Experience has shown, however, that sampling methods are too slow, and mean field approximations too impoverished <ref> [3] </ref>, to be used in this way. A different approach has been to recast neural networks as layered belief networks [4]. These networks have a fully probabilistic interpretation as directed graphical models [5, 6].
Reference: 4. <author> R. Neal. </author> <title> Connectionist learning of belief networks. </title> <booktitle> Artificial Intelligence 56 </booktitle> <month> 71-113 </month> <year> (1992). </year>
Reference-contexts: Experience has shown, however, that sampling methods are too slow, and mean field approximations too impoverished [3], to be used in this way. A different approach has been to recast neural networks as layered belief networks <ref> [4] </ref>. These networks have a fully probabilistic interpretation as directed graphical models [5, 6]. They can also be viewed as top-down generative models for the data that is encoded by the units in the bottom layer [7, 8, 9]. <p> In this paper we consider an algorithm based on ideas from statistical mechanics. Our lower bound is derived from a mean field approximation for sigmoid belief networks <ref> [4] </ref>. The original derivation [10] of this approximation made no restrictions on the network architecture or the location of visible units. The purpose of the current paper is to tailor the approximation to networks that represent hierarchical generative models. <p> The joint distribution over all the units in the network is given by: P (S) = `i i ) S ` i ) 1S ` A neural network, endowed with probabilistic semantics in this way, is known as a sigmoid belief network <ref> [4] </ref>. Layered belief networks were proposed as hierarchical generative models by Hinton et al [7]. 4 LAWRENCE SAUL AND MICHAEL JORDAN for the units in the bottom layer. The goal of unsupervised learning is to model the data by the units in the bottom layer. <p> Note that the updates take the form of a delta rule, with unit activations ` i being matched to target values S ` i . Many authors <ref> [4, 18] </ref> have noted the associative, error-correcting nature of gradient-based learn ing rules in belief networks. 2.2. MEAN FIELD LEARNING In general, it is intractable [11, 12] to calculate the likelihood in eq. (3) or the statistics in eqs. (4-5). <p> All these features demonstrate the advantages of tailoring a mean field approximation to the properties of layered networks. It is worth comparing our approach to methods based on Gibbs sampling <ref> [4] </ref>. One advantage of the mean field approximation is that it enables one to compute a lower bound on the marginal likelihood, P (V ).
Reference: 5. <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann: </publisher> <address> San Mateo, CA (1988). </address>
Reference-contexts: Experience has shown, however, that sampling methods are too slow, and mean field approximations too impoverished [3], to be used in this way. A different approach has been to recast neural networks as layered belief networks [4]. These networks have a fully probabilistic interpretation as directed graphical models <ref> [5, 6] </ref>. They can also be viewed as top-down generative models for the data that is encoded by the units in the bottom layer [7, 8, 9]. Though it remains difficult to compute the statistics of the hidden units, the directionality of belief networks confers an important advantage. <p> The tradeoff for this simplicity is that the recognition model cannot handle missing data or support certain types of reasoning, such as explaining away <ref> [5] </ref>, that rely on top-down and bottom-up processing. In this paper we consider an algorithm based on ideas from statistical mechanics. Our lower bound is derived from a mean field approximation for sigmoid belief networks [4]. <p> This procedure for solving the mean field equations can be viewed as a sequence of local message-passing operations that "match" the statistics of each hidden unit to those of its Markov blanket <ref> [5] </ref>. For the parameters ~ ` i , new values can be found by iterating eq. (9); it is straightforward to show that this iteration always leads to an increase in the objective function.
Reference: 6. <author> S. Lauritzen. </author> <title> Graphical Models. </title> <publisher> Oxford University Press: </publisher> <address> Oxford (1996). </address>
Reference-contexts: Experience has shown, however, that sampling methods are too slow, and mean field approximations too impoverished [3], to be used in this way. A different approach has been to recast neural networks as layered belief networks [4]. These networks have a fully probabilistic interpretation as directed graphical models <ref> [5, 6] </ref>. They can also be viewed as top-down generative models for the data that is encoded by the units in the bottom layer [7, 8, 9]. Though it remains difficult to compute the statistics of the hidden units, the directionality of belief networks confers an important advantage.
Reference: 7. <author> G. Hinton, P. Dayan, B. Frey, and R. Neal. </author> <title> The wake-sleep algorithm for unsupervised neural networks. </title> <booktitle> Science 268 </booktitle> <month> 1158-1161 </month> <year> (1995). </year>
Reference-contexts: A different approach has been to recast neural networks as layered belief networks [4]. These networks have a fully probabilistic interpretation as directed graphical models [5, 6]. They can also be viewed as top-down generative models for the data that is encoded by the units in the bottom layer <ref> [7, 8, 9] </ref>. Though it remains difficult to compute the statistics of the hidden units, the directionality of belief networks confers an important advantage. In these networks one can derive a simple lower bound on the likelihood and develop learning rules based on maximizing this lower bound. <p> Though it remains difficult to compute the statistics of the hidden units, the directionality of belief networks confers an important advantage. In these networks one can derive a simple lower bound on the likelihood and develop learning rules based on maximizing this lower bound. The Helmholtz machine <ref> [7, 8] </ref> was the first neural network to put this idea into practice. It uses a fast, bottom-up recognition model to compute the statistics of the hidden units and a simple stochastic learning rule, known as wake-sleep, to adapt the weights. <p> Layered belief networks were proposed as hierarchical generative models by Hinton et al <ref> [7] </ref>. 4 LAWRENCE SAUL AND MICHAEL JORDAN for the units in the bottom layer. The goal of unsupervised learning is to model the data by the units in the bottom layer. <p> MEAN FIELD LEARNING In general, it is intractable [11, 12] to calculate the likelihood in eq. (3) or the statistics in eqs. (4-5). It is also time-consuming to estimate them by sampling from P (HjV ). One way to proceed is based on the following idea <ref> [7] </ref>. Suppose we have an approximate distribution, Q (HjV ) P (HjV ). <p> Currently, the overall computation time is dominated by the iterative solution of the mean field equations. It may be possible to reduce processing times by fine tuning the number of mean field updates or by training a feed-forward network (i.e., a bottom-up recognition model <ref> [7, 8] </ref>) to initialize the mean field parameters close to solutions of eqs. (8-9). In the current implementation, we found the processing times (per image) to scale linearly with the number of weights in the network. An interesting question is whether mean field algorithms can support massively parallel implementations.
Reference: 8. <author> P. Dayan, G. Hinton, R. Neal, and R. Zemel. </author> <title> The Helmholtz machine. </title> <booktitle> Neural Computation 7 </booktitle> <month> 889-904 </month> <year> (1995). </year>
Reference-contexts: A different approach has been to recast neural networks as layered belief networks [4]. These networks have a fully probabilistic interpretation as directed graphical models [5, 6]. They can also be viewed as top-down generative models for the data that is encoded by the units in the bottom layer <ref> [7, 8, 9] </ref>. Though it remains difficult to compute the statistics of the hidden units, the directionality of belief networks confers an important advantage. In these networks one can derive a simple lower bound on the likelihood and develop learning rules based on maximizing this lower bound. <p> Though it remains difficult to compute the statistics of the hidden units, the directionality of belief networks confers an important advantage. In these networks one can derive a simple lower bound on the likelihood and develop learning rules based on maximizing this lower bound. The Helmholtz machine <ref> [7, 8] </ref> was the first neural network to put this idea into practice. It uses a fast, bottom-up recognition model to compute the statistics of the hidden units and a simple stochastic learning rule, known as wake-sleep, to adapt the weights. <p> Currently, the overall computation time is dominated by the iterative solution of the mean field equations. It may be possible to reduce processing times by fine tuning the number of mean field updates or by training a feed-forward network (i.e., a bottom-up recognition model <ref> [7, 8] </ref>) to initialize the mean field parameters close to solutions of eqs. (8-9). In the current implementation, we found the processing times (per image) to scale linearly with the number of weights in the network. An interesting question is whether mean field algorithms can support massively parallel implementations.
Reference: 9. <author> M. Lewicki and T. Sejnowski. </author> <title> Bayesian unsupervised learning of higher order structure. </title> <editor> In M. Mozer, M. Jordan, and T. Petsche, eds. </editor> <booktitle> Advances in Neural Information Processing Systems 9: </booktitle> . <publisher> MIT Press: </publisher> <address> Cambridge (1996). </address>
Reference-contexts: A different approach has been to recast neural networks as layered belief networks [4]. These networks have a fully probabilistic interpretation as directed graphical models [5, 6]. They can also be viewed as top-down generative models for the data that is encoded by the units in the bottom layer <ref> [7, 8, 9] </ref>. Though it remains difficult to compute the statistics of the hidden units, the directionality of belief networks confers an important advantage. In these networks one can derive a simple lower bound on the likelihood and develop learning rules based on maximizing this lower bound.
Reference: 10. <author> L. Saul, T. Jaakkola, and M. Jordan. </author> <title> Mean field theory for sigmoid belief networks. </title> <journal> Journal of Artificial Intelligence Research 4 </journal> <month> 61-76 </month> <year> (1996). </year>
Reference-contexts: In this paper we consider an algorithm based on ideas from statistical mechanics. Our lower bound is derived from a mean field approximation for sigmoid belief networks [4]. The original derivation <ref> [10] </ref> of this approximation made no restrictions on the network architecture or the location of visible units. The purpose of the current paper is to tailor the approximation to networks that represent hierarchical generative models. <p> In a recent study, Frey et al [15] reported that learning by Gibbs sampling was an extremely slow process for sigmoid belief networks. Mean field algorithms are evolving. The algorithm in this paper is considerably faster and easier to implement than our previous one <ref> [10, 15] </ref>. There are several important areas for future research. Currently, the overall computation time is dominated by the iterative solution of the mean field equations. <p> This is necessary to ensure that the mean field parameters converge to a solution of eqs. (8-9). 4 Our earlier work <ref> [10] </ref> showed how to obtain a strict lower bound on the log likelihood; i.e., the earlier work made no appeal to a Gaussian approximation for Q (z ` i jV ).
Reference: 11. <author> G. Cooper. </author> <title> Computational complexity of probabilistic inference using Bayesian belief networks. </title> <booktitle> Artificial Intelligence 42 </booktitle> <month> 393-405 </month> <year> (1990). </year>
Reference-contexts: Many authors [4, 18] have noted the associative, error-correcting nature of gradient-based learn ing rules in belief networks. 2.2. MEAN FIELD LEARNING In general, it is intractable <ref> [11, 12] </ref> to calculate the likelihood in eq. (3) or the statistics in eqs. (4-5). It is also time-consuming to estimate them by sampling from P (HjV ). One way to proceed is based on the following idea [7].
Reference: 12. <author> P. Dagum and M. Luby. </author> <title> Approximately probabilistic reasoning in Bayesian belief networks is NP-hard. </title> <booktitle> Artificial Intelligence 60 </booktitle> <month> 141-153 </month> <year> (1993). </year>
Reference-contexts: Many authors [4, 18] have noted the associative, error-correcting nature of gradient-based learn ing rules in belief networks. 2.2. MEAN FIELD LEARNING In general, it is intractable <ref> [11, 12] </ref> to calculate the likelihood in eq. (3) or the statistics in eqs. (4-5). It is also time-consuming to estimate them by sampling from P (HjV ). One way to proceed is based on the following idea [7].
Reference: 13. <author> G. Parisi. </author> <title> Statistical Field Theory. </title> <publisher> Addison-Wesley: </publisher> <address> Redwood City (1988). </address>
Reference-contexts: Though one cannot guarantee that such learning rules always increase the actual likelihood, they provide an efficient alternative to implementing the learning rules in eqs. (4-5). Our choice of Q (HjV ) is motivated by ideas from statistical mechanics. The mean field approximation <ref> [13] </ref> is a general method for estimating the statistics of large numbers of correlated variables.
Reference: 14. <author> J. Hertz, A. Krogh, and R.G. Palmer. </author> <title> Introduction to the Theory of Neural Computation. </title> <publisher> Addison-Wesley: </publisher> <address> Redwood City (1991). </address>
Reference: 15. <author> B. Frey, G. Hinton, and P. Dayan. </author> <title> Does the wake-sleep algorithm produce good density estimators? In D. </title> <editor> Touretzky, M. Mozer, and M. Hasselmo, eds. </editor> <booktitle> Advances in Neural Information Processing Systems 8 </booktitle> <pages> 661-667. </pages> <publisher> MIT Press: </publisher> <address> Cambridge, MA (1996). </address>
Reference-contexts: Estimat 10 LAWRENCE SAUL AND MICHAEL JORDAN ing these likelihoods by sampling is not so straightforward; indeed, it is considerably harder than estimating the statistics of individual units. In a recent study, Frey et al <ref> [15] </ref> reported that learning by Gibbs sampling was an extremely slow process for sigmoid belief networks. Mean field algorithms are evolving. The algorithm in this paper is considerably faster and easier to implement than our previous one [10, 15]. There are several important areas for future research. <p> In a recent study, Frey et al [15] reported that learning by Gibbs sampling was an extremely slow process for sigmoid belief networks. Mean field algorithms are evolving. The algorithm in this paper is considerably faster and easier to implement than our previous one <ref> [10, 15] </ref>. There are several important areas for future research. Currently, the overall computation time is dominated by the iterative solution of the mean field equations.
Reference: 16. <author> Y. LeCun, L. Jackel, L. Bottou, A. Brunot, C. Cortes, J. Denker, H. Drucker, I. Guyon, U. Muller, E. Sackinger, P. Simard, and V. Vapnik. </author> <title> Comparison of learning algorithms for handwritten digit recognition. </title> <booktitle> In Proceedings of ICANN'95. </booktitle>
Reference-contexts: Experiments We used a large database of handwritten digits to evaluate the strengths and weaknesses of these networks. The database <ref> [16] </ref> was constructed from NIST Special Databases 1 and 3. The examples in this database were deslanted, downsampled, and thresholded to create 10 fi 10 binary images. <p> The learning rate followed a fixed schedule: 0.02 for four epochs and 0.005 for four epochs. 3 All the error rates in this paper apply to experiments with 10 fi 10 binary images. The best backpropagation networks <ref> [16] </ref>, which exploit prior knowledge and operate on 20 fi 20 greyscale images, can obtain error rates less than one percent. 8 LAWRENCE SAUL AND MICHAEL JORDAN versus the number of epochs, for a 4 fi 12 fi 36 fi 100 network trained on the digit two. <p> Continuous-valued units, as opposed to binary-valued ones, would help to smooth the output of the generative model. We have not exploited any sort of local connectivity between layers, although this structure is known to be helpful in supervised learning <ref> [16] </ref>. An important consideration is how to incorporate prior knowledge about the data (e.g., translation/rotation invariance [20]) into the network.
Reference: 17. <author> W. Press, B. Flannery, S. Teukolsky, and W. Vetterling. </author> <title> Numerical Recipes. </title> <publisher> Cam-bridge University Press: </publisher> <address> Cambridge (1986). </address>
Reference-contexts: Instead, for each update, one must search the interval ` i 2 [0; 1] using some sort of bracketing procedure <ref> [17] </ref> to find a local maximum in eq. (24).
Reference: 18. <author> S. Russell, J. Binder, D. Koller, and K. </author> <title> Kanazawa. Local learning in probabilistic networks with hidden variables. </title> <booktitle> In Proceedings of IJCAI-95. </booktitle>
Reference-contexts: Note that the updates take the form of a delta rule, with unit activations ` i being matched to target values S ` i . Many authors <ref> [4, 18] </ref> have noted the associative, error-correcting nature of gradient-based learn ing rules in belief networks. 2.2. MEAN FIELD LEARNING In general, it is intractable [11, 12] to calculate the likelihood in eq. (3) or the statistics in eqs. (4-5).
Reference: 19. <author> A. Dempster, N. Laird, and D. Rubin. </author> <year> 1977. </year> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society B39:1-38. </journal>
Reference-contexts: The simplest of these is a mixture model in which the pixel values (within each mixture component) are conditionally distributed as independent binary random variables. Models of this type can be trained by an Expectation-Maximization (EM) algorithm <ref> [19] </ref> for maximum likelihood estimation. Classification via mixture models was investigated in a separate set of experiments. Each experiment consisted of training ten mixture models, one for each digit, then using the mixture models to classify the A MEAN FIELD ALGORITHM FOR UNSUPERVISED LEARNING 9 set.
Reference: 20. <author> P. Simard, Y. LeCun, and J. Denker. </author> <title> Efficient pattern recognition using a new transformation distance. </title> <editor> In S. Hanson, J. Cowan, and C. Giles, eds. </editor> <booktitle> Advances in Neural Information Processing Systems 5 </booktitle> <pages> 50-58. </pages> <publisher> Morgan Kaufmann: </publisher> <address> San Mateo, CA (1993). </address>
Reference-contexts: We have not exploited any sort of local connectivity between layers, although this structure is known to be helpful in supervised learning [16]. An important consideration is how to incorporate prior knowledge about the data (e.g., translation/rotation invariance <ref> [20] </ref>) into the network. Finally, the synthetic images in figure 3 reveal an inherent weakness of top-down generative models; while these models require an element of stochasticity to model the variability in the data, they lack a feedback mechanism (i.e., relaxation [21]) to clean up noisy pixels.
Reference: 21. <author> S. Geman and D. Geman. </author> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence 6 </journal> <month> 721-741 </month> <year> (1984). </year>
Reference-contexts: Finally, the synthetic images in figure 3 reveal an inherent weakness of top-down generative models; while these models require an element of stochasticity to model the variability in the data, they lack a feedback mechanism (i.e., relaxation <ref> [21] </ref>) to clean up noisy pixels. These extensions and others will be necessary to realize the full potential of unsupervised neural networks. ACKNOWLEDGEMENTS The authors acknowledge useful discussions with T. Jaakkola, H. Seung, P. Dayan, G. Hinton, and Y. LeCun and thank the anonymous reviewers for many helpful suggestions. A.
Reference: 22. <author> H. Seung. </author> <title> Annealed theories of learning. </title> <editor> In J.-H. Oh, C. Kwon, and S. Cho, eds. </editor> <booktitle> Neural Networks: The Statistical Mechanics Perspective, Proceedings of the CTP-PRSRI Joint Workshop on Theoretical Physics. World Scientific: </booktitle> <address> Singapore (1995). </address>
Reference-contexts: Let z denote a Gaussian random variable with mean hzi and variance hffiz 2 i, and consider the expected value, hln [1 + e z ]i. For any real number ~, we can form the upper bound <ref> [22] </ref>: hln [1 + e z ]i = hln [e ~z e ~z (1 + e z )]i; (19) ~hzi + lnhe ~z + e (1~)z i; (21) where the last line follows from Jensen's inequality.
References-found: 22

