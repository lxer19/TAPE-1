URL: http://www.cam.sri.com/tr/crc032/paper.ps.Z
Refering-URL: http://www.cam.sri.com/tr/ABSTRACTS.html
Root-URL: 
Phone: (2)  (3)  (4)  
Title: SPOKEN LANGUAGE TRANSLATION WITH MID-90'S TECHNOLOGY: A CASE STUDY  
Author: Manny Rayner Ivan Bretan David Carter Michael Collins Vassilios Digalakis Bjorn Gamback Jaan Kaja Jussi Karlgren Bertil Lyberg Steve Pulman Patti Price and Christer Samuelsson 
Address: 23 Millers Yard, Cambridge CB2 1RQ, UK  333 Ravenswood Ave, Menlo Park, CA 94025, USA  Box 1263, S-164 28 Kista, Stockholm, Sweden  AB, Rudsjoterassen 2, S-136 80 Haninge, Sweden  
Affiliation: (1) SRI International,  SRI International,  Swedish Institute for Computer Science,  Telia Research  
Date: 1993  
Note: Berlin,  
Web: URL: http://www.cam.sri.com/tr/crc032/paper.ps.ZEurospeech,  
Abstract: We describe 1 the architecture of the Spoken Language Translator (SLT), a prototype speech translation system which can translate queries from spoken English to spoken Swedish in the domain of air travel information systems. Though the performance given the level of effort so far has been extremely encouraging, more work is needed to provide a technology that will support widespread applications. With this goal, we have developed techniques for rapid development and for evaluation. These techniques allow us to estimate the level of effort required to achieve higher levels of performance. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Alshawi, H. (ed.), </author> <title> The Core Language Engine, </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: The output is an N-best hypothesis list, produced using a progressive recognition search [7]. Text processing for both languages is performed by the SRI Core Language Engine (CLE), a general natural-language processing system developed at SRI Cambridge <ref> [1] </ref>. Two copies of the CLE are used, equipped with English and Swedish grammars respectively. The English grammar is a large general-purpose feature grammar, which has been augmented with a small number of domain-specific rules. The Swedish grammar has been adapted fairly directly from the English one [4].
Reference: 2. <author> Alshawi, H., Carter, D., Rayner, M. and Gamback, B., </author> <title> "Transfer through Quasi Logical Form", </title> <booktitle> Proc. 29th ACL, </booktitle> <address> Berkeley, </address> <year> 1991. </year>
Reference-contexts: The English grammar is a large general-purpose feature grammar, which has been augmented with a small number of domain-specific rules. The Swedish grammar has been adapted fairly directly from the English one [4]. Each CLE grammar associates surface strings with representations in Quasi Logical Form (QLF; <ref> [2] </ref>), and can be compiled to run both in analysis mode (turning strings into QLFs), and generation mode (turning QLFs into strings). Generation is performed using a version of the Semantic Head-Driven generation algorithm [9]. <p> When the preference component has made its choice, the selected QLF is passed to the transfer component, which uses a set of simple non-deterministic recursive pattern-matching rules to rewrite it into a set of possible target-language QLFs <ref> [2] </ref>. A second application of the preference component is now performed, using a different set of preference functions, to select the most plausible transferred QLF.
Reference: 3. <author> Ceder, K. and Lyberg, B., </author> <title> "Yet Another Rule Compiler for Text-to-Speech Conversion?", </title> <booktitle> Proc. ICSLP, </booktitle> <address> Banff, </address> <year> 1993. </year>
Reference-contexts: Generation is performed using a version of the Semantic Head-Driven generation algorithm [9]. Target language speech synthesis is performed by the Swedish Telecom Prophon system <ref> [3] </ref>, using polyphone syn-thesis. The polyphones are concatenated and the prosodic pattern determined by the Prophon analysis (which has access to the syntax and semantics of the utterance) is imposed via the PSOLA (pitch synchronous overlap add) signal processing technique [5].
Reference: 4. <author> Gamback, B. and Rayner, M., </author> <title> "The Swedish Core Language Engine", </title> <booktitle> Proc. 3rd NOTEX, </booktitle> <address> Linkoping, </address> <year> 1992. </year>
Reference-contexts: Two copies of the CLE are used, equipped with English and Swedish grammars respectively. The English grammar is a large general-purpose feature grammar, which has been augmented with a small number of domain-specific rules. The Swedish grammar has been adapted fairly directly from the English one <ref> [4] </ref>. Each CLE grammar associates surface strings with representations in Quasi Logical Form (QLF; [2]), and can be compiled to run both in analysis mode (turning strings into QLFs), and generation mode (turning QLFs into strings). Generation is performed using a version of the Semantic Head-Driven generation algorithm [9].
Reference: 5. <author> Moulines, E. and Charpentier, F., </author> <title> "Pitch-Synchronous Waveform Processing Techniques for Text-to-Speech Synthesis Using Diphones", </title> <journal> Speech Communication Vol. </journal> <volume> 9, </volume> <year> 1990. </year>
Reference-contexts: The polyphones are concatenated and the prosodic pattern determined by the Prophon analysis (which has access to the syntax and semantics of the utterance) is imposed via the PSOLA (pitch synchronous overlap add) signal processing technique <ref> [5] </ref>. The components are connected together in a pipelined sequence as follows. The input signal is processed by the recognizer, and a set of N-best hypotheses is passed to the English-language version of the CLE, each hypothesis tagged with an associated acoustic score.
Reference: 6. <author> Murveit, H., Butzberger, J. and Weintraub, M., </author> <title> "Speech Recognition in SRI's Resource Management and ATIS Systems", </title> <booktitle> Proc. DARPA Workshop on Speech and Natural Language, </booktitle> <year> 1991. </year>
Reference-contexts: We begin by describing the main system components, for speech recognition, text language processing, and speech synthesis. The speech recognizer used is a fast version of SRI's DECIPHER (TM) speaker-independent continuous speech recognition system <ref> [6] </ref>. It uses context-dependent phonetic-based hidden Markov models (HMMs) with discrete observation distributions for four features: cepstrum, delta-cepstrum, energy and delta-energy. The models are gender-independent and the system is trained on 19,000 sentences and has a 1381-word vocabulary.
Reference: 7. <author> Murveit, H., Butzberger, J., Digalakis, V. and Wein-traub, M., </author> <title> "Large Vocabulary Dictation using SRI's DECIPHER(TM) Speech Recognition System: Progressive Search Techniques", </title> <booktitle> Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <address> Minneapolis, Minnesota, </address> <month> April </month> <year> 1993, </year> <pages> pp. </pages> <address> II-319 II-322. </address>
Reference-contexts: The models are gender-independent and the system is trained on 19,000 sentences and has a 1381-word vocabulary. The output is an N-best hypothesis list, produced using a progressive recognition search <ref> [7] </ref>. Text processing for both languages is performed by the SRI Core Language Engine (CLE), a general natural-language processing system developed at SRI Cambridge [1]. Two copies of the CLE are used, equipped with English and Swedish grammars respectively.
Reference: 8. <author> Rayner, M., Alshawi, H., Bretan, I., Carter, D., Di-galakis, V., Gamback B., Kaja J., Karlgren J., Lyberg B., Price, P., Pulman, S. and Samuelsson, C., </author> <title> "A Speech to Speech Translation System Built From Standard Components". To appear in: </title> <booktitle> Proceedings of the ARPA workshop on Human Language Technology, </booktitle> <address> Plainsboro, NJ, </address> <year> 1993. </year>
Reference-contexts: Section 5 concludes. 2. Overview of the SLT system This section gives a brief overview of the SLT system; for a longer treatment, the reader is referred to <ref> [8] </ref>. At the highest level of generality, the guiding themes of the project has been those of intelligent reuse of standard components and robust interfaces. <p> The collocational preferences reflect facts about the relative frequencies of co-occurrence of different head-words in the specified grammatical relations; also, the relative weights given to the individual preference functions can be tuned, using a statistical optimization method described in <ref> [8] </ref>, to values appropriate for the given domain. When the preference component has made its choice, the selected QLF is passed to the transfer component, which uses a set of simple non-deterministic recursive pattern-matching rules to rewrite it into a set of possible target-language QLFs [2].
Reference: 9. <author> Shieber, S. M., van Noord, G., Pereira, F.C.N and Moore, </author> <title> R.C., </title> <journal> "Semantic-Head-Driven Generation", Computational Linguistics, </journal> <volume> 16 </volume> <pages> 30-43, </pages> <year> 1990. </year>
Reference-contexts: Each CLE grammar associates surface strings with representations in Quasi Logical Form (QLF; [2]), and can be compiled to run both in analysis mode (turning strings into QLFs), and generation mode (turning QLFs into strings). Generation is performed using a version of the Semantic Head-Driven generation algorithm <ref> [9] </ref>. Target language speech synthesis is performed by the Swedish Telecom Prophon system [3], using polyphone syn-thesis.
References-found: 9

