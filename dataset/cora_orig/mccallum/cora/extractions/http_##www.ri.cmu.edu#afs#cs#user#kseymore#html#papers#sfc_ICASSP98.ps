URL: http://www.ri.cmu.edu/afs/cs/user/kseymore/html/papers/sfc_ICASSP98.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs/user/kseymore/html/papers.html
Root-URL: 
Email: fsfc,kseymore,ronig@cs.cmu.edu  
Title: TOPIC ADAPTATION FOR LANGUAGE MODELING USING UNNORMALIZED EXPONENTIAL MODELS  
Author: Stanley F. Chen, Kristie Seymore, Ronald Rosenfeld 
Address: Pittsburgh, Pennsylvania 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: In this paper, we present novel techniques for performing topic adaptation on an n-gram language model. Given training text labeled with topic information, we automatically identify the most relevant topics for new text. We adapt our language model toward these topics using an exponential model, by adjusting probabilities in our model to agree with those found in the topical subset of the training data. For efficiency, we do not normalize the model; that is, we do not require that the probabilities in the language model sum to 1. With these techniques, we were able to achieve a modest reduction in speech recognition word-error rate in the Broadcast News domain. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Berger, S. Della Pietra, and V. Della Pietra. </author> <title> A maximum entropy approach to natural language processing. </title> <booktitle> Computational Linguistics, </booktitle> <address> 22(1):3971, </address> <year> 1996. </year>
Reference-contexts: Simpson are also labeled with the topic DNA testing (recall that articles usually have multiple topics), then the topic DNA testing may be considered on-topic for the word Kato according to this heuristic. A method for modeling these partial dependencies is to use maximum entropy training for exponential models <ref> [1] </ref>.
Reference: [2] <author> P. Clarkson and A. Robinson. </author> <title> Language model adaptation using mixtures and an exponentially decaying cache. </title> <booktitle> In Proc. </booktitle> <address> ICASSP-97, </address> <year> 1997. </year>
Reference-contexts: For example, if a speech document is recognized as describing O.J. Simp-son's trial, then the probability of the word Kato occurring should be boosted. There has been much previous work in topic adaptation. 1 Numerous efforts have demonstrated large improvements in the measure of perplexity <ref> [2, 4, 9] </ref>; however, perplexity has been shown to correlate poorly with speech recognition performance.
Reference: [3] <author> R. Iyer and M. Ostendorf. </author> <title> Modeling long distance dependence in language: Topic mixtures vs. dynamic cache models. </title> <booktitle> In Proc. ICSLP, </booktitle> <pages> pages 236239, </pages> <year> 1996. </year>
Reference-contexts: Several papers have reported modest speech recognition word-error rate (WER) improvements of about 0.5% absolute: Sekine and Grishman [14] add ad hoc topic and cache scores to their language model score in log probability space, and Iyer and Ostendorf <ref> [3] </ref> This work was supported by the National Security Agency under grants MDA904-96-1-0113 and MDA904-97-1-0006.
Reference: [4] <author> R. Kneser and J. Peters. </author> <title> Semantic clustering for adaptive language modeling. </title> <booktitle> In Proc. ICASSP-97, </booktitle> <volume> volume 2, </volume> <pages> pages 779782, </pages> <year> 1997. </year>
Reference-contexts: For example, if a speech document is recognized as describing O.J. Simp-son's trial, then the probability of the word Kato occurring should be boosted. There has been much previous work in topic adaptation. 1 Numerous efforts have demonstrated large improvements in the measure of perplexity <ref> [2, 4, 9] </ref>; however, perplexity has been shown to correlate poorly with speech recognition performance. <p> Recently, there has been evidence that exponential models are superior to linear interpolation in combining multiple information sources <ref> [13, 5, 4] </ref>.
Reference: [5] <author> R. Kneser, J. Peters, and D. Klakow. </author> <title> Language model adaptation using dynamic marginals. </title> <booktitle> In Proc. Eurospeech '97, </booktitle> <year> 1997. </year>
Reference-contexts: Recently, there has been evidence that exponential models are superior to linear interpolation in combining multiple information sources <ref> [13, 5, 4] </ref>.
Reference: [6] <author> F. Kubala. </author> <title> Design of the 1994 CSR benchmark tests. </title> <booktitle> In Proc. Spoken Language Sys. Technology Workshop, </booktitle> <pages> pages 4146, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: This contrasts with the situation where a topic-specific adaptation text is explicitly given, as in Spoke 2 of the 1994 ARPA CSR evaluation <ref> [6] </ref>. and Seymore and Rosenfeld [16] use linear interpolation to combine topic n-gram models with a general n-gram model. In this work, we extend the research in [16] by using unnor-malized exponential models to combine topic information.
Reference: [7] <author> R. Kuhn and R. D. Mori. </author> <title> A cache-based natural language model for speech reproduction. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 12(6):570583, </volume> <year> 1990. </year>
Reference-contexts: Simpson. * We consider features that boost the probabilities of words and n-grams that occur frequently in the current article being evaluated. These features are similar in effect to a lan guage model cache <ref> [7] </ref>. In the next sections, we discuss each of these feature types in turn. <p> Boosting Article-Specific n-Gram Probabilities Cache models attempt to characterize the phenomenon that words and n-grams tend to repeat themselves within articles, by increasing the probabilities of n-grams that have occurred previously in an article <ref> [7] </ref>. We can place this type of modeling within our adaptation framework by viewing the first-pass hypothesis transcription of an article to be another topic adaptation text. We can adapt our 3 This procedure is a crude but quick approximation to maximum entropy training with this feature set.
Reference: [8] <author> J. Lafferty and B. Suhm. </author> <title> Cluster expansions and iterative scaling for maximum entropy language models. </title> <editor> In K. Han-son and R. Silver, editors, </editor> <title> Maximum Entropy and Bayesian Methods. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: This process yielded about 200,000 features. Unlike the other exponential models used in this work, the topic unigram model was normalized. We used optimizations as described by Lafferty and Suhm <ref> [8] </ref> in the maximum entropy training; each iteration took less than 10 minutes on a Pentium II processor. The training yielded positive depression factors for 30,000 words. An excerpt of these factors is displayed in Table 1.
Reference: [9] <author> S. Martin, J. Liermann, and H. Ney. </author> <title> Adaptive topic-dependent language modelling using word-based varigrams. </title> <booktitle> In Proc. Eurospeech '97, </booktitle> <year> 1997. </year>
Reference-contexts: For example, if a speech document is recognized as describing O.J. Simp-son's trial, then the probability of the word Kato occurring should be boosted. There has been much previous work in topic adaptation. 1 Numerous efforts have demonstrated large improvements in the measure of perplexity <ref> [2, 4, 9] </ref>; however, perplexity has been shown to correlate poorly with speech recognition performance.
Reference: [10] <author> P. Placeway, S. Chen, M. Eskenazi, U. Jain, V. Parikh, B. Raj, M. Ravishankar, R. Rosenfeld, K. Seymore, M. Siegler, R. Stern, and E. Thayer. </author> <booktitle> The 1996 Hub-4 Sphinx-3 system. In Proc. DARPA Speech Recog. Workshop, </booktitle> <month> February </month> <year> 1997. </year>
Reference-contexts: Thus, it seems likely that our scheme is less susceptible to speech recognition errors. 4. EXPERIMENTS In our experiments, we used speech recognition lattices generated by the Sphinx-III system <ref> [10] </ref> on 20 articles of Broadcast News data (16,700 words). For each article, we first generated a hypothesis using a trigram model generated by the CMU language modeling toolkit [11] from our 130M words of training text. The word-error rate of these hypotheses were 30.8%.
Reference: [11] <author> R. Rosenfeld. </author> <title> The CMU statistical language modeling toolkit and its use in the 1994 ARPA CSR evaluation. </title> <booktitle> In Proc. Spoken Language Sys. Technology Workshop, </booktitle> <pages> pages 4750, </pages> <address> Austin, Texas, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: EXPERIMENTS In our experiments, we used speech recognition lattices generated by the Sphinx-III system [10] on 20 articles of Broadcast News data (16,700 words). For each article, we first generated a hypothesis using a trigram model generated by the CMU language modeling toolkit <ref> [11] </ref> from our 130M words of training text. The word-error rate of these hypotheses were 30.8%. We found twenty relevant topics for each article using a Bayes classifier on these first-pass hypotheses. In each experiment, word-error rates were calculated through lattice rescoring with the adapted model.
Reference: [12] <author> R. Rosenfeld. </author> <title> Optimizing lexical and n-gram coverage via judicious use of linguistic data. </title> <booktitle> In Proc. Eurospeech '95, </booktitle> <pages> pages 17631766, </pages> <year> 1995. </year>
Reference: [13] <author> R. Rosenfeld. </author> <title> A maximum entropy approach to adaptive statistical language modeling. </title> <booktitle> Computer, Speech, and Language, </booktitle> <volume> 10, </volume> <year> 1996. </year>
Reference-contexts: Recently, there has been evidence that exponential models are superior to linear interpolation in combining multiple information sources <ref> [13, 5, 4] </ref>.
Reference: [14] <author> S. Sekine and R. Grisham. </author> <title> NYU language modeling experiments for the 1995 CSR evaluation. </title> <booktitle> In Proc. ARPA Spoken Language Sys. Technology Workshop, </booktitle> <year> 1995. </year>
Reference-contexts: Several papers have reported modest speech recognition word-error rate (WER) improvements of about 0.5% absolute: Sekine and Grishman <ref> [14] </ref> add ad hoc topic and cache scores to their language model score in log probability space, and Iyer and Ostendorf [3] This work was supported by the National Security Agency under grants MDA904-96-1-0113 and MDA904-97-1-0006.
Reference: [15] <author> K. Seymore, S. Chen, M. Eskenazi, and R. Rosenfeld. </author> <title> Language and pronunciation modeling in the CMU 1996 Hub 4 evaluation. </title> <booktitle> In Proc. DARPA Speech Recog. Workshop, </booktitle> <address> Wash-ington, D.C., </address> <month> February </month> <year> 1997. </year>
Reference: [16] <author> K. Seymore and R. Rosenfeld. </author> <title> Using story topics for language model adaptation. </title> <booktitle> In Proc. Eurospeech '97, </booktitle> <year> 1997. </year>
Reference-contexts: This contrasts with the situation where a topic-specific adaptation text is explicitly given, as in Spoke 2 of the 1994 ARPA CSR evaluation [6]. and Seymore and Rosenfeld <ref> [16] </ref> use linear interpolation to combine topic n-gram models with a general n-gram model. In this work, we extend the research in [16] by using unnor-malized exponential models to combine topic information. In [16], a first-pass transcription hypothesis is generated for each article in the test set using an unadapted trigram <p> This contrasts with the situation where a topic-specific adaptation text is explicitly given, as in Spoke 2 of the 1994 ARPA CSR evaluation [6]. and Seymore and Rosenfeld <ref> [16] </ref> use linear interpolation to combine topic n-gram models with a general n-gram model. In this work, we extend the research in [16] by using unnor-malized exponential models to combine topic information. In [16], a first-pass transcription hypothesis is generated for each article in the test set using an unadapted trigram model. The twenty most relevant topics for each hypothesis are identified using a Bayes classifier. <p> explicitly given, as in Spoke 2 of the 1994 ARPA CSR evaluation [6]. and Seymore and Rosenfeld <ref> [16] </ref> use linear interpolation to combine topic n-gram models with a general n-gram model. In this work, we extend the research in [16] by using unnor-malized exponential models to combine topic information. In [16], a first-pass transcription hypothesis is generated for each article in the test set using an unadapted trigram model. The twenty most relevant topics for each hypothesis are identified using a Bayes classifier.
References-found: 16

