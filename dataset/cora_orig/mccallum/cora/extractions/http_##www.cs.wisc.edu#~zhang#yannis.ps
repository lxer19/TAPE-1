URL: http://www.cs.wisc.edu/~zhang/yannis.ps
Refering-URL: http://www.cs.wisc.edu/~zhang/
Root-URL: 
Email: fyannis,kang,zhangg@cs.wisc.edu  
Title: Cost Wells in Random Graphs  
Author: Yannis E. Ioannidis Younkyung Cha Kang Tian Zhang 
Note: Partially supported by the National Science Foundation under grant IRI-9157368 (PYI Award) and by grants from DEC, IBM, HP, AT&T, Oracle, and Informix.  
Date: December 16, 1996  
Address: Madison, WI 53706  
Affiliation: Computer Sciences Department University of Wisconsin  
Abstract: Many randomized optimization algorithms operate by searching a graph whose nodes are all the potential solutions to a given optimization problem. Each graph node has a cost associated with it and the goal is to identify the node with the optimum cost. In principle, the set of edges in the graph can be arbitrary. Nevertheless, the behavior and effectiveness of many of these algorithms depend on the shape of the cost function over these graphs, which is directly affected by how nodes are connected. In particular, some of these algorithms are very effective when that shape forms a `well' with smooth sides and uneven bottom. It is thus beneficial for designers of optimization modules to connect nodes so that a `well' is formed. In this paper, we study the notion of `well' in the context of random graphs, and identify several factors that affect the formation or not of a `well' in them. These include the average node degree in the graph, the average cost difference between adjacent nodes in the graph, and the overall cost distribution of the nodes in the graph. We also present a combination of analytical and experimental results that quantify the precise effect of these factors to the cost function shape and show that, as with many other properties, "almost all" random graphs form a `well'. Although search graphs in real-life optimization problems are not random, we believe that the essence of our results can be used as a guideline in designing the edge structure of these graphs to facilitate the formation of `well's. 
Abstract-found: 1
Intro-found: 1
Reference: [AHS85] <author> D. H. Ackley, G. E. Hinton, and T. J. Sejnowski. </author> <title> A learning algorithm for boltzmann machines. </title> <journal> Cognitive Science, </journal> <volume> 9 </volume> <pages> 147-169, </pages> <year> 1985. </year> <month> 22 </month>
Reference-contexts: 1 Introduction Randomized algorithms have been successfully applied to various combinatorial optimization problems, e.g. the traveling salesman problem [AJMS84, MO97], neural networks and other machine learning approaches <ref> [AHS85] </ref>, database query optimization [IK90, IK91], etc. Most such algorithms operate by searching a graph whose nodes are all the potential solutions to the optimization problem. Each graph node S has a cost associated with it, which is given by some problem-specific cost function c (S).
Reference: [AJMS84] <author> C. R. Aragon, D. S. Johnson, L. A. Megeoch, and C. Schevon. </author> <title> Optimization by simulated annealing: An experimental evaluation, </title> <month> October </month> <year> 1984. </year> <type> Unpublished manuscript. </type>
Reference-contexts: 1 Introduction Randomized algorithms have been successfully applied to various combinatorial optimization problems, e.g. the traveling salesman problem <ref> [AJMS84, MO97] </ref>, neural networks and other machine learning approaches [AHS85], database query optimization [IK90, IK91], etc. Most such algorithms operate by searching a graph whose nodes are all the potential solutions to the optimization problem.
Reference: [Bol85] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press, </publisher> <address> Orlando, FL, </address> <year> 1985. </year>
Reference-contexts: An interesting by-product of this effort is the introduction of a new model for random graphs that captures node costs, which is a generalization of the traditional G N;p model <ref> [Bol85] </ref>. Certainly, no real optimization application deals with search graphs that are generated based on a random graph model. <p> For this purpose, we have extended the most popular model for generating random graphs without node weights, which is denoted by G N;p <ref> [Bol85] </ref>. According to this model, a graph has N given nodes, and for every pair of nodes in the graph, the probability that there is an edge between them is equal to p. If n is the desired average degree of the graph nodes, then p = n=(N 1). <p> Recall that Theorem 4.1 holds when the probability of edge existence between any two nodes is constant. This is the case closest to traditional random graphs <ref> [Bol85] </ref> with the addition of costs on the nodes. It is, therefore, interesting to observe that the above result follows the same trend that one sees on random graphs with respect to many other phenomena, where as edges are added to the graph, "things happen very fast". <p> There are also some additional observations that strengthen the above intuitive arguments. These concern the effect of n (and therefore the average node degree in the graph) and the overall node cost distribution. As n increases, the distance between two local minima decreases dramatically <ref> [Bol85] </ref> and the number of paths connecting them increases. Both these facts suggest that the connection cost of the two local minima should decrease as well. The intuition behind the above statement is based on formula (12).
Reference: [IK90] <author> Y. Ioannidis and Y. Kang. </author> <title> Randomized algorithms for optimizing large join queries. </title> <booktitle> In Proc. ACM-SIGMOD Conference on the Management of Data, </booktitle> <pages> pages 312-321, </pages> <address> Atlantic City, NJ, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Randomized algorithms have been successfully applied to various combinatorial optimization problems, e.g. the traveling salesman problem [AJMS84, MO97], neural networks and other machine learning approaches [AHS85], database query optimization <ref> [IK90, IK91] </ref>, etc. Most such algorithms operate by searching a graph whose nodes are all the potential solutions to the optimization problem. Each graph node S has a cost associated with it, which is given by some problem-specific cost function c (S). <p> Some examples are Simulated Annealing [KGV83], Iterative Improvement [NSS86], and Two Phase Optimization <ref> [IK90] </ref>, which have been the motivation for this work. Due to the randomness of the graph search, there is no guarantee for any of these algorithms that the global minimum will be identified in finite time. <p> This has been one of the major conclusions of our study of query optimization in relational databases <ref> [IK90, IK91] </ref>, which also motivated the work presented in this paper. By varying the characteristics of queries, databases, and the transformation rules that determined the neighborhood structure of nodes, the cost shapes of the corresponding search graphs changed as well. <p> We have already applied these results in the database query optimization problem and have verified that a `well' is formed based on the criteria discussed in this paper <ref> [IK90, IK91] </ref>. Accordingly, 2PO has been shown to be much more effective and efficient than other algorithms, e.g., II and SA. In the future we intend to investigate other areas where appropriate optimization problems arise and test the applicability of the obtained results in these cases as well.
Reference: [IK91] <author> Y. Ioannidis and Y. Kang. </author> <title> Left-deep vs. bushy trees: An analysis of strategy spaces and its implications for query optimization. </title> <booktitle> In Proc. ACM-SIGMOD Conference on the Management of Data, </booktitle> <pages> pages 168-177, </pages> <address> Denver, CO, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Randomized algorithms have been successfully applied to various combinatorial optimization problems, e.g. the traveling salesman problem [AJMS84, MO97], neural networks and other machine learning approaches [AHS85], database query optimization <ref> [IK90, IK91] </ref>, etc. Most such algorithms operate by searching a graph whose nodes are all the potential solutions to the optimization problem. Each graph node S has a cost associated with it, which is given by some problem-specific cost function c (S). <p> This has been one of the major conclusions of our study of query optimization in relational databases <ref> [IK90, IK91] </ref>, which also motivated the work presented in this paper. By varying the characteristics of queries, databases, and the transformation rules that determined the neighborhood structure of nodes, the cost shapes of the corresponding search graphs changed as well. <p> We have already applied these results in the database query optimization problem and have verified that a `well' is formed based on the criteria discussed in this paper <ref> [IK90, IK91] </ref>. Accordingly, 2PO has been shown to be much more effective and efficient than other algorithms, e.g., II and SA. In the future we intend to investigate other areas where appropriate optimization problems arise and test the applicability of the obtained results in these cases as well.
Reference: [KGV83] <author> S. Kirkpatrick, C. D. Gelatt, Jr., and M. P. Vecchi. </author> <title> Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> 220(4598) </volume> <pages> 671-680, </pages> <month> May </month> <year> 1983. </year>
Reference-contexts: Some examples are Simulated Annealing <ref> [KGV83] </ref>, Iterative Improvement [NSS86], and Two Phase Optimization [IK90], which have been the motivation for this work. Due to the randomness of the graph search, there is no guarantee for any of these algorithms that the global minimum will be identified in finite time.
Reference: [Leh59] <author> E. L. Lehmann. </author> <title> Testing Statistical Hypotheses. </title> <publisher> Wiley, </publisher> <address> New York, NY, </address> <year> 1959. </year>
Reference-contexts: Consider two random variables X and Y on the range [0,1) of possible values. Then, Y is stochastically smaller than X if F Y (x) F X (x) for all values of x <ref> [Leh59] </ref>. The ratio F Y (x)=F X (x) (for F X (x) &gt; 0) is the stochastic ratio of Y over X at point x.
Reference: [MO97] <author> O. C. Martin and S. W. Otto. </author> <title> Combining simulated annealing with local search heuristics. </title> <journal> Annals of Operations Research, </journal> <note> 1997. (To appear). </note>
Reference-contexts: 1 Introduction Randomized algorithms have been successfully applied to various combinatorial optimization problems, e.g. the traveling salesman problem <ref> [AJMS84, MO97] </ref>, neural networks and other machine learning approaches [AHS85], database query optimization [IK90, IK91], etc. Most such algorithms operate by searching a graph whose nodes are all the potential solutions to the optimization problem.
Reference: [NSS86] <author> S. Nahar, S. Sahni, and E. Shragowitz. </author> <title> Simulated annealing and combinatorial optimization. </title> <booktitle> In Proc. 23rd Design Automation Conference, </booktitle> <pages> pages 293-299, </pages> <year> 1986. </year>
Reference-contexts: Some examples are Simulated Annealing [KGV83], Iterative Improvement <ref> [NSS86] </ref>, and Two Phase Optimization [IK90], which have been the motivation for this work. Due to the randomness of the graph search, there is no guarantee for any of these algorithms that the global minimum will be identified in finite time.
Reference: [RL86] <author> V. Rothschild and N. Logothetis. </author> <title> Probability Distributions. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, NY, </address> <year> 1986. </year>
Reference-contexts: The choice of the Gamma distribution was motivated by the fact that by manipulating one of its two parameters, namely ff, we can modify the shape of the distribution <ref> [RL86] </ref>. Roughly, when ff = 1, is negative exponential, when ff = 3, is close to normal, and when ff = 2, is similar to a distribution in between. The value of the fi parameter controls the range of values in the distribution.
Reference: [RSV85] <author> F. Romeo and A. Sangiovanni-Vincentelli. </author> <title> Probabilistic hill climbing algorithms: Properties and applications. </title> <editor> In H. Fuchs, editor, </editor> <booktitle> Proc. 1985 Chapel Hill Conference on VLSI, </booktitle> <pages> pages 393-417, </pages> <address> Chapel Hill, N.C., 1985. </address> <publisher> Computer Science Press. </publisher>
Reference: [Rud64] <author> W. </author> <title> Rudin. Principles of Mathematical Analysis. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1964. </year>
Reference-contexts: (y) = R y lim N!1 x=0 p (x) dF X (x) R y R 1 : (9) In the above, we are able to interchange the order of limit and integration by the dominated convergence theorem and the fact that p (x) e nF X (x) for all N <ref> [Rud64] </ref>. It is well known that the limit of p (x) when N ! 1 is equal to lim N!1 p (x) = e nF X (x) ; where e is the Napierian number. <p> Similarly, for x x, (5) yields p (x) = 1 z=0 ffi (N 1) N1 n F X (x) ; which implies that lim N!1 p (x) = e nF X (x)=ffi . For this case, using the dominated conver gence theorem again <ref> [Rud64] </ref>, the limit of the denominator of (4) is equal to lim N!1 x=0 Z x e nF X (x)=ffi dF X (x) + x=x = n fi fi fi x = 0 fi fi fi x = x Therefore, for x x, due to the dominated convergence theorem [Rud64], the <p> again <ref> [Rud64] </ref>, the limit of the denominator of (4) is equal to lim N!1 x=0 Z x e nF X (x)=ffi dF X (x) + x=x = n fi fi fi x = 0 fi fi fi x = x Therefore, for x x, due to the dominated convergence theorem [Rud64], the appropriate substitutions to (4) yield lim N!1 F Y (y) = C x=0 Z y e n dF X (x) = C ffi (1 e n )=n + e n (F X (y) ffi) = 1 C e n F X (y) : Similarly, for x x, (4) yields
Reference: [SAC + 79] <author> P. G. Selinger, M. M. Astrahan, D. D. Chamberlin, R. A. Lorie, and T. G. Price. </author> <title> Access path selection in a relational database management system. </title> <booktitle> In Proc. ACM-SIGMOD Conf. on the Management of Data, </booktitle> <pages> pages 23-34, </pages> <address> Boston, MA, </address> <month> June </month> <year> 1979. </year>
Reference-contexts: Such problems include the traveling salesman problem (where each string represents the cities in the order they are visited) and database query optimization on left-deep trees (where each string represents the query relations in the order they are joined with the other relations) <ref> [SAC + 79] </ref>. One possible set of transformation rules that may define the edges of the search graph for such a problem is based on `switching any two consecutive letters in the string (node)'. Another, slightly more liberal one is based on `switching any two letters in the string (node)'.
Reference: [Sor91] <author> G. B. Sorkin. </author> <title> Efficient simulated annealing on fractal energy landscapes. </title> <journal> Algo-rithmica, </journal> <volume> 6 </volume> <pages> 367-418, </pages> <year> 1991. </year> <month> 23 </month>
Reference-contexts: The only other piece of work with which we are familiar that is similar to ours is by Sorkin <ref> [Sor91] </ref>. Using our terminology, he explores the relationship between cost function shapes over search graphs and the performance of SA.
References-found: 14

