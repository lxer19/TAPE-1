URL: http://cobar.cs.umass.edu/pubfiles/ir-103.ps.gz
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Title: Text Segmentation by Topic  
Author: Jay M. Ponte and W. Bruce Croft 
Address: Amherst, 01002, USA  
Affiliation: Computer Science Department, University of Massachusetts,  
Abstract: We investigate the problem of text segmentation by topic. Applications for this task include topic tracking of broadcast speech data and topic identification in full-text databases. Researchers have tackled similar problems before but with different goals. This study focuses on data with relatively small segment sizes and for which within-segment sentences have relatively few words in common making the problem challenging. We present a method for segmentation which makes use of a query expansion technique to find common features for the topic seg ments. Experiments with the technique show that it can be effective.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Callan J. P., </author> <title> "Passage-Level Evidence in Document Retrieval." </title> <booktitle> In Proceedings of the Seventeenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <address> Dublin, Ireland, </address> <month> July, </month> <pages> 1994 (pp. 302-310). </pages>
Reference-contexts: We will revisit this example to show how LCA helps to solve the problem, but we first discuss previous work on similar problems. 2 Previous Work The topic segmentation task is somewhat related to previous work in passage retrieval. Many passage retrieval techniques have, however, used fixed length passages <ref> [1] </ref> or other features such as paragraph boundaries [6]. For our task, paragraph and section information is not available and topic segments consist of a very small number of sentences, sometimes only one, so choosing an arbitrary block size as is often done for passage retrieval is not appropriate.
Reference: 2. <author> Croft, W. B. and D. J. Harper. </author> <title> "Using probabilistic models of document retrieval without relevance information." </title> <journal> Journal of Documentation, </journal> <volume> 35, </volume> <pages> 1979 (pp. 285-295). </pages>
Reference-contexts: Now that we have seen an overview of the process, we will look at some of the details. 3.1 LCA Xu and Croft [9] developed Local Context Analysis as the method of query expansion somewhat like a more robust version of local feedback (see <ref> [2] </ref> for a discussion of local feedback). For the purposes of the current work, LCA is being used as an association thesaurus. Each sentence in the test set is posed as a query to the LCA database. LCA works as follows, given a query: Retrieve the top N passages.
Reference: 3. <author> Hearst, M. </author> <title> "Multi-Paragraph Segmentation of Expository Text", </title> <booktitle> Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Las Cruces, NM, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: The segmenting process begins at paragraph level. Then, paragraphs are compared by computing cosine similarity in order to infer cohesive multi-paragraph segments. Hearst <ref> [3] </ref> and Hearst and Plaunt [4] discuss a method of segmenting expository texts into multi-paragraph subtopics which they call `tiles' using cosine similarity in conjunction with smoothing. One notable feature of this work is that formatting information is not used in the segmentation process. <p> This curve is then smoothed to get rid of local extrema. Finally, the resulting smoothed graph is used to identify potential topic boundaries. Hearst and Plaunt [4] performed experiments using these topic boundaries to enhance ad hoc retrieval, but the results were not significantly better than fixed-sized windows. In <ref> [3] </ref> the segmentation was compared to that of several human judges. These approaches are somewhat different from the one taken in our preliminary study. In the first place, we cannot assume paragraph boundaries are available. <p> This is a reasonable assumption for this study since each topic segment is a discussion of a different event. In other cases, one might have to determine the level of agreement between several human judges in order to estimate performance, see <ref> [3] </ref>. In order to score the segmentation generated by the algorithm, we first perform a least squares alignment with the correct segmentation. Then the distance between the two is measurable in terms of insertions, deletions and moves.
Reference: 4. <author> Hearst, M. and Plaunt, C. </author> <title> Subtopic Structuring for Full-Length Document Access, </title> <booktitle> Proceedings of the sixteenth Annual International ACM/SIGIR Conference, </booktitle> <address> Pittsburgh, PA. </address> <note> 1993 (pp. 59-68). </note>
Reference-contexts: The segmenting process begins at paragraph level. Then, paragraphs are compared by computing cosine similarity in order to infer cohesive multi-paragraph segments. Hearst [3] and Hearst and Plaunt <ref> [4] </ref> discuss a method of segmenting expository texts into multi-paragraph subtopics which they call `tiles' using cosine similarity in conjunction with smoothing. One notable feature of this work is that formatting information is not used in the segmentation process. <p> Next, a similarity curve of adjacent blocks is computed using cosine similarity. This curve is then smoothed to get rid of local extrema. Finally, the resulting smoothed graph is used to identify potential topic boundaries. Hearst and Plaunt <ref> [4] </ref> performed experiments using these topic boundaries to enhance ad hoc retrieval, but the results were not significantly better than fixed-sized windows. In [3] the segmentation was compared to that of several human judges. These approaches are somewhat different from the one taken in our preliminary study.
Reference: 5. <author> Mittendorf E. and P. Shauble, </author> <title> "Document and Passage Retrieval Based on Hidden Markov Models", </title> <booktitle> In Proceedings of the Seventeenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <address> Dublin, Ireland, </address> <month> July, </month> <pages> 1994 (pp. 318-327). </pages>
Reference-contexts: In that case, measuring similarity of within topic sentences does not provide enough information. As mentioned earlier, much of the work on passage retrieval has used passages of fixed length. An exception to this is Mittendorf and Shauble <ref> [5] </ref> in which Hidden Markov Models (HMMs) were used to retrieve relevant passages of variable length. This is an interesting approach and is somewhat related to our work in that in both cases the text is broken up using a sequential (Markov) decision process.
Reference: 6. <author> Salton, Gerard, J. Allan and C. Buckley, </author> <title> "Approaches to Passage Retrieval in Full Text Information Systems", </title> <booktitle> Proceedings of the sixteenth Annual International ACM/SIGIR Conference, </booktitle> <address> Pittsburgh, PA. </address> <note> 1993 (pp. 49-58). </note>
Reference-contexts: Many passage retrieval techniques have, however, used fixed length passages [1] or other features such as paragraph boundaries <ref> [6] </ref>. For our task, paragraph and section information is not available and topic segments consist of a very small number of sentences, sometimes only one, so choosing an arbitrary block size as is often done for passage retrieval is not appropriate.
Reference: 7. <author> Salton,Gerard, Amit Singhal, Chris Buckley and Mandar Mitra. </author> <title> "Automatic Text Decomposition Using Text Segments and Text Themes", </title> <booktitle> Proceedings of the Seventh ACM Conference on Hypertext, </booktitle> <address> Washington D.C., </address> <year> 1996. </year>
Reference-contexts: For our task, paragraph and section information is not available and topic segments consist of a very small number of sentences, sometimes only one, so choosing an arbitrary block size as is often done for passage retrieval is not appropriate. Salton and Singhal [8] and Salton et al <ref> [7] </ref>, discuss the decomposition of text into segments and themes where a segment is contiguous block of text discussing a single subtopic and a theme is a chain of such segments possibly interleaved with other themes. The segmenting process begins at paragraph level.
Reference: 8. <author> Salton,Gerard and Amit Singhal. </author> <title> "Automatic Text Theme Generation and the Analysis of Text Structure", </title> <institution> Cornell Computer Science Technical Report 94-1438, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: For our task, paragraph and section information is not available and topic segments consist of a very small number of sentences, sometimes only one, so choosing an arbitrary block size as is often done for passage retrieval is not appropriate. Salton and Singhal <ref> [8] </ref> and Salton et al [7], discuss the decomposition of text into segments and themes where a segment is contiguous block of text discussing a single subtopic and a theme is a chain of such segments possibly interleaved with other themes. The segmenting process begins at paragraph level.
Reference: 9. <author> Xu, Jinxi and W. Bruce Croft, </author> <title> "Query Expansion Using Local and Global Document Analysis", </title> <booktitle> In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <address> Zurich, Switzerland, </address> <month> August, </month> <pages> 1996 (pp. 4-11). </pages>
Reference-contexts: Note that in broadcast speech data, sentence boundary identification is not a trivial problem. For the current data, it can be approximated reasonably well. As a first step, we used the method of Local Context Analysis (LCA), as described by Xu and Croft <ref> [9] </ref>, in order to find words and phrases related to each sentence. The words and phrases returned by LCA were used in place of the original sentence and pairwise similarity of all sentences in the data set was 4 calculated. <p> There are exponentially many possible segmentations, but dynamic programming makes the calculation tractable. Now that we have seen an overview of the process, we will look at some of the details. 3.1 LCA Xu and Croft <ref> [9] </ref> developed Local Context Analysis as the method of query expansion somewhat like a more robust version of local feedback (see [2] for a discussion of local feedback). For the purposes of the current work, LCA is being used as an association thesaurus.
References-found: 9

