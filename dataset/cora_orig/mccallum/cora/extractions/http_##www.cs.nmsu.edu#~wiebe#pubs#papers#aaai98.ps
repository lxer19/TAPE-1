URL: http://www.cs.nmsu.edu/~wiebe/pubs/papers/aaai98.ps
Refering-URL: http://www.cs.nmsu.edu/~wiebe/pubs/index.html
Root-URL: http://www.cs.nmsu.edu
Email: fepontell,gupta,wiebeg@cs.nmsu.edu, david@crl.nmsu.edu  
Title: Natural Language Multiprocessing: A Case Study  
Author: Enrico Pontelli and Gopal Gupta and Janyce Wiebe and David Farwell 
Date: July 1998.  
Address: Madison, WI,  
Note: Proc. 15th National Conference on Artificial Intelligence (AAAI-98). American Association  
Affiliation: Dept. Computer Science and Computing Research Laboratory New Mexico State University  for Artificial Intelligence,  
Abstract: This paper presents two case studies of paralleliza-tion of large Natural Language Processing (NLP) applications using a parallel logic programming system (called "ACE") that automatically exploits implicit parallelism. The first system considered is Artwork, a system for semantic disambiguation, speech act resolution, and temporal reference resolution. The second system is ULTRA, a multilingual translation system. Both applications were originally developed in Prolog without any consideration for parallel processing. The results obtained confirm that NLP is a ripe area for exploitation of parallelism. Most previous work on parallelism in NLP focused primarily on parallelizing the parsing phase of language processing. The case studies presented here show that parallelism is also present in the semantic and discourse processing phases, which are often the most computationally intensive part of the application. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Adriaens, G., and Hahn, U. </author> <year> 1994. </year> <title> Parallel Natural Language Processing. </title> <publisher> Ablex Publishing. </publisher>
Reference: <author> Ali, K., and Karlsson, R. </author> <year> 1990. </year> <title> The Muse Or-parallel Prolog.. In NACLP. </title> <publisher> MIT Press. </publisher>
Reference-contexts: Given that parallelism can be exploited automatically, existing Prolog-based NLP applications can also be parallelized, by porting them with little or no effort to parallel systems. Fast parallel implementations of Prolog are currently available (e.g., <ref> (Ali & Karlsson 1990) </ref>) or about to be released into the public domain, including the ACE system (Gupta et al. 1994) used in this work. <p> The ACE System The ACE model (Gupta et al. 1994; Pontelli 1997) uses stack-copying <ref> (Ali & Karlsson 1990) </ref> and recomputation (Gupta et al. 1994) to efficiently support combined or- and independent and-parallel execution of logic programs. <p> This efficiency in execution is accomplished by introducing the concept of teams of processors and extending the stack-copying techniques to deal with this new processor organization. Or-Parallelism in ACE: ACE exploits or-parallelism by using a stack copying approach <ref> (Ali & Karlsson 1990) </ref>. In this approach, a set of processing agents (processors in the case of MUSE, teams of processors in the case of ACE|as explained later) working in or-parallel maintain a separate but identical address space (i.e. they allocate their data structures starting at the same logical addresses).
Reference: <author> M. Carlson and G. Gupta (eds.) </author> <year> 1996. </year> <journal> Journal of Logic Progr. </journal> <pages> 29(1-3). </pages>
Reference-contexts: This is mostly due to the increasing computational requirements of these applications, which were not satisfied by the older slow implementations of declarative languages. Even though implementations of these languages comparable in efficiency to imperative languages are available today (e.g., <ref> (Carlson & Gupta 1996) </ref>), past experience has discouraged designers of NLP systems from using them. The computational demands of today's NLP systems have reached the level where they are challenging for Copyright c fl1998, American Association for Artificial Intelligence (www.aaai.org).
Reference: <author> DeGroot, D. </author> <year> 1984. </year> <title> Restricted AND-Parallelism. </title> <booktitle> In Conf. on 5th Generation Computer Systems. </booktitle>
Reference: <author> Devos M. et al. </author> <year> 1988. </year> <title> The Parallel Expert Parser. </title> <booktitle> In Proceedings of COLING. </booktitle>
Reference-contexts: (1.99) 190115 (2.96) 128509 (4.38) 65283 (8.62) 46507 (12.1) 37768 (14.9) E-to-S 91519 45756 (2.0) 30505 (3.0) 18370 (4.98) 10057 (9.1) 6779 (13.5) 5684 (16.1) Table 4: Execution Times for ULTRA (Sequent Symmetry, times in ms.) There has been research in the past in paralleliz-ing the parsing phase of NLP <ref> (Devos et al. 1988) </ref>, including some that use a logic programming approach (Matsumoto 1986; Trehan & Wilk 1988). More recently, the Eu-PAGE systems (Manousopoulou et al. 1997) has been proposed, a parser generator capable of producing parallel parsers (based on PVM).
Reference: <author> Farwell, D., and Wilks, Y. </author> <year> 1991. </year> <title> ULTRA: A multilingual machine translator. In Mach. </title> <publisher> Transl. Summit. </publisher>
Reference-contexts: ULTRA: ULTRA (Universal Language TRAnslator) is a multilingual, interlingual machine translation system. It can currently translate between five languages (Chinese, English, German, Spanish, and Japanese) with vocabularies in each language based on about 10; 000 word senses. The multilingual system is based on a language-independent interlingual representation (IR) <ref> (Farwell & Wilks 1991) </ref> for representing expressions as elements of linguistic acts of communication (e.g., asking questions, describing the world, promising that things will get done, etc.). <p> Translation can be viewed as the use of the target language to express the same act as the one expressed in the source language. The IR is then used as the basis for analyzing or for generating expressions as elements of such acts in each of the languages <ref> (Farwell & Wilks 1991) </ref>. Each individual language system is independent and has its own rules to associate the appropriate IRs to each expression of the language. <p> Currently most of the language components are implemented as context-free grammars with complex categories. The system uses relaxation techniques (grammatical relaxation, semantic relaxation, and structure relaxation) to provide robustness by giving preferred or "near miss" translations <ref> (Farwell & Wilks 1991) </ref>. In addition, the adoption of language-independent seman tic and pragmatic procedures allows, given a context, the selection of the best IR from the set of possible IRs for a given expression. The use of Prolog allowed the design of a highly declarative and perfectly bidirectional application. <p> In the case of ULTRA the goal of parallelization was quickly achieved with limited effort, thanks to the clean and declarative programming style adopted by the programmers who developed the system, necessitated by the requirement that computations be reversible <ref> (Farwell & Wilks 1991) </ref>. In the case of Artwork the system had been developed following a more "imperative" approach in the code organization. We invested some effort in reorganizing some parts of the code and this proved effective in increasing the amount of and-parallelism.
Reference: <author> Gupta, G., Pontelli, E. et al. </author> <year> 1994. </year> <title> ACE: And/Or-parallel Copying-based Execution of Logic Programs. </title> <booktitle> In Proc. ICLP'94, </booktitle> <pages> 93-109. </pages> <publisher> MIT Press. </publisher>
Reference-contexts: Fast parallel implementations of Prolog are currently available (e.g., (Ali & Karlsson 1990)) or about to be released into the public domain, including the ACE system <ref> (Gupta et al. 1994) </ref> used in this work. In this work we present two case studies in which two large NLP applications, independently developed with no goal of parallelization in mind, have been studied and parallelized using the ACE parallel Prolog system. <p> The ACE System The ACE model (Gupta et al. 1994; Pontelli 1997) uses stack-copying (Ali & Karlsson 1990) and recomputation <ref> (Gupta et al. 1994) </ref> to efficiently support combined or- and independent and-parallel execution of logic programs. ACE represents an efficient combi nation of or- and independent and-parallelism in the sense that penalties for supporting either form of parallelism are paid only when that form of parallelism is actually exploited. <p> Thus, the the notion of or-agent is mapped to the notion of team of processors while the notion of and-agent is mapped to the notion of processors inside a team (i.e. each processor is an and-agent). Different approaches to incremental copying and heuristics have been developed <ref> (Gupta et al. 1994) </ref>. ACE has shown remarkable performance results on a large selection of programs (Figure 1 presents the speedup curves obtained on some benchmarks). Furthermore, the parallelization overhead is extremely low, on average 5 to 10% w.r.t. sequential SICStus Prolog, on which the ACE engine is based.
Reference: <author> Hermenegildo, M. et al. </author> <year> 1995. </year> <title> Incremental analysis of logic programs. In ICLP95. </title> <publisher> MIT Press. </publisher>
Reference-contexts: Dependencies are detected at run-time by executing some simple tests in troduced by the parallelizing compiler. ACE adopts the technique originally designed by DeGroot (DeG-root 1984) and refined by Hermenegildo <ref> (Hermenegildo et al. 1995) </ref> of annotating the program at compile time with Conditional Graph Expressions (CGEs): (h conditions i ) B 1 & & B n ) where h conditions i is a conjunction of simple tests on variables appearing in the clause that verifies whether the arguments share any variables <p> The automatic annotation performed by the ACE compiler was rather slow, due to the size and organization of the application|a single module of over 35; 000 lines of Prolog code. A modular reorganization of the code and the use of incremental analysis techniques <ref> (Hermenegildo et al. 1995) </ref> will improve the speed of annotation. The annotator is written in Prolog, so the annotation process itself can be parallelized. Comparison with Other Work Experience shows that NLP applications are highly parallel in nature.
Reference: <author> Hirschman L. et al. </author> <year> 1988. </year> <title> Or-parallel Speedup in Natural Language Processing. In ICLP88. </title> <publisher> MIT Press. </publisher>
Reference-contexts: More recently, the Eu-PAGE systems (Manousopoulou et al. 1997) has been proposed, a parser generator capable of producing parallel parsers (based on PVM). However, not much parallelism has been extracted from other phases of NLP systems. The main exception to this is the PUNDIT system <ref> (Hirschman et al. 1988) </ref> which exploits (only) or-parallelism from an NLP system coded in Prolog running on a simulated parallel environment. The PUNDIT system is about 3,000 lines long.
Reference: <author> Levin, L. et al. </author> <year> 1995. </year> <title> Using Context in the Machine Translation of Spoken Language. </title> <booktitle> In Proc. Theoretical and Methodological Issues in Machine Translation. </booktitle>
Reference-contexts: The input to the system is the output of a semantic parser developed as part of the Enthusiast speech-to-speech machine translation project at CMU <ref> (Levin 1995) </ref>; it determines, among other things, what type of event each utterance is about, and who the participants are. The output of the parser is ambiguous, so must be disambiguated by the Artwork system. <p> Wiebe et al. (1997) present the results of the system performing this task on unseen, held-out test data, taking as input the ambiguous output of the semantic parser (which itself takes as input the output of a speech recognition system <ref> (Levin 1995) </ref>). The system performs well, and comparable results on similar tasks have not been published elsewhere. The system parallelized in this work is an earlier version which performed speech-act and temporal reference resolution, but not semantic disambiguation.
Reference: <author> Manousopoulou A. et al. </author> <year> 1997. </year> <title> Automatic Generation of Portable Parallel Natural Language Parsers. In ICTAI. </title> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: More recently, the Eu-PAGE systems <ref> (Manousopoulou et al. 1997) </ref> has been proposed, a parser generator capable of producing parallel parsers (based on PVM). However, not much parallelism has been extracted from other phases of NLP systems.
Reference: <author> Matsumoto, Y. </author> <year> 1986. </year> <title> A Parallel Parsing System for Natural Language Analysis. </title> <booktitle> In Int. Conf. on Logic Programming. </booktitle> <publisher> Springer Verlag. </publisher>
Reference: <author> Pereira, F. and Shieber, S.M. </author> <year> 1987. </year> <title> Prolog and Natural-Language Analysis. </title> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Introduction Logic programming has been for a long time one of the programming paradigms of choice for the development of NLP systems. Logic programming languages (e.g., Prolog) offer features such as backtracking, unification, and symbolic data representation which greatly facilitate the development of NLP applications <ref> (Pereira 1987) </ref>. In recent years the use of declarative languages, such as Prolog and Lisp, for NLP applications has declined. This is mostly due to the increasing computational requirements of these applications, which were not satisfied by the older slow implementations of declarative languages.
Reference: <author> Pontelli, E. </author> <year> 1997. </year> <title> High-Performance Parallel Execution of Prolog Programs. </title> <type> Ph.D. Dissertation, </type> <institution> NMSU. </institution>
Reference-contexts: Experimental Results Parallelization of Artwork: The parallelization of Artwork was performed semi-automatically. The ACE compiler was used to identify potential sources of parallelism. Additionally, the rich output of the ACE static analyzer <ref> (Pontelli et al. 1997) </ref> (e.g., sharing information) allowed us to identify features of the program that were limiting the parallelism exploitable. Very few hand-modifications of the original code were needed to considerably improve the speedups achieved, as discussed in the next subsection. <p> The analyzer was quite successful in detecting parallelism in the program. At the highest level, IAP was exploited by allowing concurrent translation of successive phrases belonging to the source text. The translation of each phrase was marked as a potential source of DAP by the dependent and-parallel analyzer <ref> (Pontelli et al. 1997) </ref>, as illustrated below: ctrans (Src lg,Trg lg,In,Out) :- (dep ([I rep])-&gt; (analyse (Srg lg,In,I rep) & generate (Trg lg,I rep,Out)); Out String = "&lt; unable to translate &gt;"). where '&' denotes a parallel conjunction and the dep annotation identifies the source of dependency (shared variable).
Reference: <author> Pontelli, E., Gupta, G. et al. </author> <year> 1997. </year> <title> Automatic Compile-time Parallelization of Prolog Programs for DAP. In ICLP97. </title> <publisher> MIT Press. </publisher>
Reference-contexts: Experimental Results Parallelization of Artwork: The parallelization of Artwork was performed semi-automatically. The ACE compiler was used to identify potential sources of parallelism. Additionally, the rich output of the ACE static analyzer <ref> (Pontelli et al. 1997) </ref> (e.g., sharing information) allowed us to identify features of the program that were limiting the parallelism exploitable. Very few hand-modifications of the original code were needed to considerably improve the speedups achieved, as discussed in the next subsection. <p> The analyzer was quite successful in detecting parallelism in the program. At the highest level, IAP was exploited by allowing concurrent translation of successive phrases belonging to the source text. The translation of each phrase was marked as a potential source of DAP by the dependent and-parallel analyzer <ref> (Pontelli et al. 1997) </ref>, as illustrated below: ctrans (Src lg,Trg lg,In,Out) :- (dep ([I rep])-&gt; (analyse (Srg lg,In,I rep) & generate (Trg lg,I rep,Out)); Out String = "&lt; unable to translate &gt;"). where '&' denotes a parallel conjunction and the dep annotation identifies the source of dependency (shared variable).
Reference: <author> Reithinger, N. et al. </author> <year> 1995. </year> <title> Utilizing statistical dialogue act processing in verbmobil. </title> <booktitle> In ACL, </booktitle> <pages> 116-122. </pages>
Reference: <author> Rose, C. et al. </author> <year> 1995. </year> <title> Discourse processing of dialogues with multiple threads. </title> <booktitle> In Proceedings of ACL, </booktitle> <pages> 31-38. </pages>
Reference: <author> Trehan, R. et al. </author> <year> 1988. </year> <title> A Parallel Chart Parser for the CCND Languages. In ICLP88. </title> <publisher> MIT Press. </publisher>
Reference: <author> M. Walker and J. Moore (eds.) </author> <year> 1997. </year> <note> Computational Linguistics 23(1). </note>
Reference: <author> Wiebe J. et al. </author> <year> 1996. </year> <title> ARTWORK: Discourse Processing in Machine Translation of Dialog. </title> <type> Technical Report MCCS96294, </type> <institution> Computing Research Laboratory. </institution>
Reference-contexts: Very few hand-modifications of the original code were needed to considerably improve the speedups achieved, as discussed in the next subsection. Ambiguity in NLP gives rise to a "combinatorial explosion" of possible interpretations. Consequently, Artwork may take up to a couple of hours to process a dialog <ref> (Wiebe et al. 1996) </ref>. Artwork offers a great deal of inherent parallelism to exploit, including or-parallelism and both DAP and IAP. To process each utterance, the system applies all rules in its knowledge base. Each rule that matches the utterance fires, producing a partial representation.
Reference: <author> Wiebe J. et al. </author> <year> 1997. </year> <title> An Empirical Approach to Temporal Reference Resolution. </title> <booktitle> In Proceedings 2nd Conference on Empirical Methods in NLP. </booktitle>
Reference-contexts: The speaker might be suggesting that they meet from 2 to 4; they might be confirming that 2 to 4 is the time currently being discussed; they might, with the right intonation, be accepting 2 to 4; and so on. The other kind of discourse ambiguity addressed is temporal <ref> (Wiebe et al. 1997) </ref>. The Artwork system tracks the times being talked about, determining implicit contextual in formation. For example, when a speaker refers to "2 to 4 am", Artwork looks back at the previous utterances, and decides which day, date, and month are being referred to.
References-found: 21

