URL: http://www.maths.soton.ac.uk/staff/JJForster/Papers/MCMCloglin.ps.gz
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: SUMMARY  
Title: Markov Chain Monte Carlo Model Determination for Hierarchical and Graphical Log-linear Models  
Author: Petros Dellaportas and Jonathan J. Forster 
Keyword: Bayesian Analysis; Contingency table; Decomposable model; Hierarchical log-linear model; Graphical model; Markov chain Monte Carlo; Reversible jump  
Abstract: The Bayesian approach to comparing models involves calculating the posterior probability of each plausible model. For high-dimensional contingency tables, the set of plausible models is very large. We focus attention on reversible jump Markov chain Monte Carlo (Green, 1995) and develop strategies for calculating posterior probabilities of hierarchical, graphical or decomposable log-linear models. Even for tables of moderate size, these sets of models may be very large. The choice of suitable prior distributions for model parameters is also discussed in detail, and two examples are presented. For the first example, a 2 fi 3 fi 4 table, the model probabilities calculated using our reversible jump approach are compared with model probabilities calculated exactly or by using an alternative approximation. The second example is a 2 6 contingency table for which exact methods are infeasible, due to the large number of possible models. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Albert J. H. </author> <year> (1990). </year> <title> A Bayesian test for a two-way contingency table using independence priors. </title> <journal> The Canadian Journal of Statistics 18, </journal> <pages> 347-363. </pages>
Reference: <author> Albert J. H. </author> <year> (1995). </year> <title> Bayesian selection of log-linear models. </title> <type> Working Paper 95-15, </type> <institution> Duke University, Institute of Statistics and Decision Sciences. </institution>
Reference: <author> Darroch J. N., Lauritzen S. L. and Speed T. P. </author> <year> (1980). </year> <title> Markov fields and log-linear interaction models for contingency tables. </title> <journal> The Annals of Statistics 8, </journal> <pages> 522-539. </pages>
Reference-contexts: We propose Markov chain Monte Carlo methods as an efficient way of overcoming these difficulties. 2 2 The Log-linear Interaction Model A log-linear (interaction) model assumes that the N (i) are observations of independent Poisson random variables with E (N ) = = ((i); i 2 I). Then <ref> (again, following Darroch, Lauritzen and Speed, 1980) </ref> log (i) = aC where i a is the marginal cell i a = (i fl ; fl 2 a). Note that in practice, to ensure identifiability of the ~ a (i a ) terms, constraints are usually imposed.
Reference: <author> Dawid A. P. and Lauritzen S. L. </author> <year> (1993). </year> <title> Hyper Markov laws in the statistical analysis of decomposable graphical models. </title> <journal> The Annals of Statistics 21, </journal> <pages> 1272-1317. </pages>
Reference: <author> Dellaportas P. and Smith A. F. M. </author> <year> (1993). </year> <title> Bayesian inference for generalized linear and proportional hazards models via Gibbs sampling. </title> <journal> Applied Statistics 42, </journal> <pages> 443-459. </pages>
Reference: <author> Draper D. </author> <year> (1995). </year> <title> Assessment and propagation of model uncertainty (with discussion). </title> <journal> Journal of the Royal Statistical Society B 57, </journal> <pages> 45-97. </pages>
Reference-contexts: In principle, the approach outlined above overcomes these problems. Expression (1) allows the calculation of posterior probabilities of all competing models, regardless of their relative size or structure, and this model uncertainty can be incorporated into any decisions or predictions required <ref> (Draper, 1995, gives examples of this) </ref>. The problems with this approach are associated with the computation of f (mjn) using (1), which requires calculation of the marginal likelihood f (njm) = R fi m f (njm; m )f ( m jm)d m for each m 2 M .
Reference: <author> Edwards D. and Havranek T. </author> <year> (1985). </year> <title> A fast procedure for model search in multidimensional contingency tables. </title> <journal> Biometrika 72, </journal> <pages> 339-351. </pages>
Reference: <author> Epstein L. D. and Fienberg S. E. </author> <year> (1991). </year> <title> Using Gibbs sampling for Bayesian inference in multi-dimensional contingency tables. </title> <booktitle> In Proceedings of 23rd Symposium on the Interface of Computing Science and Statistics, </booktitle> <pages> pp. 215-223. </pages>
Reference: <author> Forster J. J. and Skene A. M. </author> <year> (1994). </year> <title> Calculation of marginal densities for parameters of multinomial distributions. </title> <journal> Statistics and Computing 4, </journal> <pages> 279-286. </pages>
Reference: <author> Geyer C. J. </author> <year> (1992). </year> <title> Practical Markov chain Monte Carlo (with discussion). </title> <booktitle> Statistical Science 7, </booktitle> <pages> 473-511. </pages>
Reference-contexts: The results displayed in the table are based on a sample of 500 000. The MCMC standard errors of the estimates of the model probabilities are calculated by splitting the MCMC output into 10 `batches' <ref> (see Geyer, 1992) </ref>. The model probabilities did not change substantially, even when the sample size was increased by a factor of ten. Only the model probabilities for the four most probable models are displayed.
Reference: <author> Gilks W. R. and Wild P. </author> <year> (1992). </year> <title> Adaptive rejection sampling for Gibbs sampling. </title> <journal> Applied Statistics 41, </journal> <pages> 337-348. </pages>
Reference-contexts: They showed that the univariate conditional distributions required for sampling are log-concave, and hence adaptive rejection sampling <ref> (Gilks and Wild, 1992) </ref> is straightforward to implement. Forster and Skene (1994) used a Gibbs sampler to generate from posterior distributions arising from multinomial likelihoods and logistic normal prior distributions, which corresponds to the situation in the present example.
Reference: <author> Good I. J. and Crook J. F. </author> <year> (1987). </year> <title> The robustness and sensitivity of the mixed-Dirichlet Bayesian test for "independence" in contingency tables. </title> <journal> The Annals of Statistics 15, </journal> <pages> 670-693. </pages>
Reference: <author> Green P. J. </author> <year> (1995). </year> <title> Reversible jump Markov chain Monte Carlo computation and Bayesian Model Determination. </title> <journal> Biometrika 82, </journal> <pages> 711-732. </pages> <note> 18 G^unel E. </note> <author> and Dickey J. </author> <year> (1995). </year> <title> Bayes factors for independence in contingency tables. </title> <journal> Biometrika 61, </journal> <pages> 545-557. </pages>
Reference: <author> Kass R. E. and Raftery A. E. </author> <year> (1995). </year> <title> Bayes factors. </title> <journal> Journal of the American Statistical Association 90, </journal> <pages> 773-795. </pages>
Reference: <author> Knuiman M. W. and Speed T. P. </author> <year> (1988). </year> <title> Incorporating prior information into the analysis of contingency tables. </title> <type> Biometrics 44, </type> <pages> 1061-1071. </pages>
Reference: <author> Madigan D., Anderson S. A., Perlman M. D. and Volinsky C. T. </author> <year> (1995). </year> <title> Bayesian model averaging and model selection for Markov equivalence classes of acyclic digraphs. </title> <type> Technical Report, </type> <institution> University of Washington, Department of Statistics. </institution>
Reference-contexts: Hence, in principle, all posterior model probabilities (1) are straightforward to calculate. However, for large tables, the number of models may prohibit this calculation. Occam's window (Madigan and Raftery, 1994) and Markov Chain Monte Carlo model composition <ref> (MC 3 , Madigan and York, 1995) </ref> are strategies for overcoming this problem. A comparison of the two approaches is provided by Madigan et al (1994). There are, however, interesting models which fall outside the class of decomposable models M D . <p> For large multiway contingency tables, one possible approach is MC 3 <ref> (Madigan and York, 1995) </ref>. For undirected graphical models MC 3 uses the Metropolis-Hastings algorithm to construct a Markov chain, for which the state space is the set of decomposable models, and the equilibrium distribution is f (mjn), the posterior model probabilities assuming that only decomposable models have non-zero prior probability.
Reference: <author> Madigan D. and Raftery A. E. </author> <year> (1994). </year> <title> Model selection and accounting for model uncertainty in graphical models using Occam's window. </title> <journal> Journal of the American Statistical Association 89, </journal> <pages> 1535-1546. </pages>
Reference-contexts: Hence, in principle, all posterior model probabilities (1) are straightforward to calculate. However, for large tables, the number of models may prohibit this calculation. Occam's window <ref> (Madigan and Raftery, 1994) </ref> and Markov Chain Monte Carlo model composition (MC 3 , Madigan and York, 1995) are strategies for overcoming this problem. A comparison of the two approaches is provided by Madigan et al (1994).
Reference: <author> Madigan D., Raftery A. E., York J., Bradshaw J. M. and Almond R. G. </author> <year> (1994). </year> <title> Strategies for graphical model selection. In Selecting Models from Data: AI and Statistics IV , eds. </title> <editor> P. Cheesman and R. W. Oldford, </editor> <address> New York: </address> <publisher> Springer-Verlag, </publisher> <pages> pp. 91-100. </pages>
Reference-contexts: Hence, in principle, all posterior model probabilities (1) are straightforward to calculate. However, for large tables, the number of models may prohibit this calculation. Occam's window <ref> (Madigan and Raftery, 1994) </ref> and Markov Chain Monte Carlo model composition (MC 3 , Madigan and York, 1995) are strategies for overcoming this problem. A comparison of the two approaches is provided by Madigan et al (1994).
Reference: <author> Madigan D. and York J. </author> <year> (1995). </year> <title> Bayesian graphical models for discrete data. </title> <journal> International Statistical Review 63, </journal> <pages> 215-232. </pages>
Reference-contexts: Hence, in principle, all posterior model probabilities (1) are straightforward to calculate. However, for large tables, the number of models may prohibit this calculation. Occam's window (Madigan and Raftery, 1994) and Markov Chain Monte Carlo model composition <ref> (MC 3 , Madigan and York, 1995) </ref> are strategies for overcoming this problem. A comparison of the two approaches is provided by Madigan et al (1994). There are, however, interesting models which fall outside the class of decomposable models M D . <p> For large multiway contingency tables, one possible approach is MC 3 <ref> (Madigan and York, 1995) </ref>. For undirected graphical models MC 3 uses the Metropolis-Hastings algorithm to construct a Markov chain, for which the state space is the set of decomposable models, and the equilibrium distribution is f (mjn), the posterior model probabilities assuming that only decomposable models have non-zero prior probability.
Reference: <author> O'Hagan A. </author> <year> (1995). </year> <title> Fractional Bayes factors for model comparison (with discussion). </title> <journal> Journal of the Royal Statistical Society B 57, </journal> <pages> 99-138. </pages>
Reference: <author> Perks W. </author> <year> (1947). </year> <title> Some observations on inverse probability including a new indifference rule. </title> <journal> Journal of the Institute of Actuaries 73, </journal> <pages> 285-334. </pages>
Reference: <author> Raftery A. E. </author> <year> (1993). </year> <title> Approximate Bayes factors and accounting for model uncertainty in generalized linear models. </title> <type> Technical Report 255, </type> <institution> University of Washington, Department of Statistics. </institution>
Reference: <author> Raftery A. E. </author> <year> (1995). </year> <title> Hypothesis testing and model selection. In Markov Chain Monte Carlo in Practice eds. </title> <editor> W. R. Gilks, S. Richardson and D. J. Spiegelhalter, </editor> <publisher> London: Chapman and Hall, </publisher> <pages> pp. 163-188. </pages>
Reference: <author> Spiegelhalter D. J. and Smith A. F. M. </author> <year> (1982). </year> <title> Bayes factors for linear and log-linear models with vague prior information. </title> <journal> Journal of the Royal Statistical Society B 44, </journal> <pages> 377-387. </pages>

References-found: 24

