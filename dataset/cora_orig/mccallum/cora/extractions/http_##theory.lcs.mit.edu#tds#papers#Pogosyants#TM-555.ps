URL: http://theory.lcs.mit.edu/tds/papers/Pogosyants/TM-555.ps
Refering-URL: http://theory.lcs.mit.edu/tds/papers/Pogosyants/WDAG97.html
Root-URL: 
Email: lynch@theory.lcs.mit.edu  segala@cs.unibo.it  
Title: Verification of the Randomized Consensus Algorithm of Aspnes and Herlihy: a Case Study  
Author: Anna Pogosyants Roberto Segala Nancy Lynch 
Address: Cambridge, MA 02139 USA,  Porta San Donato 5, 40127 Bologna Italy,  
Affiliation: Laboratory for Computer Science, Massachusetts Institute of Technology,  Dipartimento di Scienze dell'Informazione, Universita di Bologna, Piazza di  
Note: 1995 while working on this project for her Ph.D. dissertation. Supported by AFOSR-ONR contract F49620-94-1-0199, by ARPA contracts N00014-92-J-4033 and F19628 95-C-0118, and by NSF grant 9225124-CCR.  
Abstract: The Aspnes-Herlihy algorithm is a rather complex algorithm. Processes move through a succession of asynchronous rounds, attempting to agree at each round. At each round, the agreement attempt involves a distributed random walk. The algorithm is hard to analyze because of its use of nontrivial results of probability theory (specifically, random walk theory), because of its complex setting, including asynchrony and both nondeterministic and probabilistic choice, and because of the interplay among several different sub-protocols. We formalize the Aspnes-Herlihy algorithm using probabilistic I/O automata. In doing so, we decompose it formally into three subprotocols: one to carry out the agreement attempts, one to conduct the random walks, and one to implement a shared counter needed by the random walks. Properties of all three subprotocols are proved separately, and combined using general results about automaton composition. It turns out that most of the work involves proving non-probabilistic properties (invariants, simulation mappings, non-probabilistic progress properties, etc.). The probabilistic reasoning is isolated to a few small sections of the proof. The task of carrying out this proof has led us to develop several general proof techniques for probabilistic I/O automata. These include ways to combine expectations for different complexity measures, to compose expected complexity properties, to convert probabilistic claims to deterministic claims, to use abstraction mappings to prove probabilistic properties, and to apply random walk theory in a distributed computational setting. We apply all of these techniques to analyze the expected complexity of the algorithm. This paper is written in memory of Anna Pogosyants, who died in a car crash in December 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Abrahamson. </author> <title> On achieving consensus using a shared memory. </title> <booktitle> In Proceedings of the 7 th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1988. </year>
Reference-contexts: Other work is based on probabilistic model checking (e.g, [21, 11]). Prior to the algorithm of Aspnes and Herlihy, the best known randomized algorithm for consensus with shared memory was due to Abrahamson <ref> [1] </ref>. The algorithm has exponential expected running time. The algorithm of Aspnes and Herlihy was improved by Attiya, Dolev, and Shavit [6] by eliminating the use of unbounded counters needed for the random walk. Further improvements were proposed by Aspnes [4], and by Dwork, Herlihy, Plotkin, and Waarts [7]. <p> F is a collection of subsets of that is closed under complement and countable union and such that 2 F , also called a field, and 3. P is a function from F to <ref> [0; 1] </ref> such that P [] = 1 and such that for any collection fC i g i of at most countably many pairwise disjoint elements of F , P [[ i C i ] = P The pair (; F ) is called a measurable space, and the measure P
Reference: [2] <author> S. Aggarwal. </author> <title> Time optimal self-stabilizing spanning tree algorithms. </title> <type> Technical Report MIT/LCS/TR-632, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1994. </year> <type> Master's thesis. </type>
Reference-contexts: Previous work on verification of randomized distributed algorithms includes [18], where the randomized dining philosophers algorithm of [13] is shown to guarantee progress with probability 1, [15, 19], where the algorithm of [13] is shown to guarantee progress within expected constant time, and <ref> [2] </ref>, where the randomized self-stabilizing minimum spanning tree algorithm of [3] is shown to guarantee stabilization within an expected time proportional to the diameter of a network. <p> The analysis of [18] is based on converting a probabilistic property into a property of some of the computations of an algorithm (extreme fair computations); the 2 analysis of <ref> [15, 19, 2] </ref> is based on part of the methodology used in this paper. Other work is based on probabilistic model checking (e.g, [21, 11]). Prior to the algorithm of Aspnes and Herlihy, the best known randomized algorithm for consensus with shared memory was due to Abrahamson [1].
Reference: [3] <author> S. Aggarwal and S. Kutten. </author> <title> Time optimal self stabilizing spanning tree algorithms. In R.K. Shyamasundar, editor, </title> <booktitle> 13th International Conference on Foundations of Software Technology and Theoretical Computer Science, volume 761 of Lecture Notes in Computer Science, </booktitle> <pages> pages 400-410, </pages> <address> Bombay, India., </address> <month> December </month> <year> 1993. </year> <note> Springer-Verlag. 67 </note>
Reference-contexts: verification of randomized distributed algorithms includes [18], where the randomized dining philosophers algorithm of [13] is shown to guarantee progress with probability 1, [15, 19], where the algorithm of [13] is shown to guarantee progress within expected constant time, and [2], where the randomized self-stabilizing minimum spanning tree algorithm of <ref> [3] </ref> is shown to guarantee stabilization within an expected time proportional to the diameter of a network.
Reference: [4] <author> J. Aspnes. </author> <title> Time- and space-efficient randomized consensus. </title> <journal> Journal of Algorithms, </journal> <volume> 14(3) </volume> <pages> 414-431, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The algorithm has exponential expected running time. The algorithm of Aspnes and Herlihy was improved by Attiya, Dolev, and Shavit [6] by eliminating the use of unbounded counters needed for the random walk. Further improvements were proposed by Aspnes <ref> [4] </ref>, and by Dwork, Herlihy, Plotkin, and Waarts [7]. The best known algorithm [7] runs in an expected O (n (p 2 + n)) total atomic register operations, where n is the number of processes and p is the number of processes that participate in the consensus protocol.
Reference: [5] <author> J. Aspnes and M.P. Herlihy. </author> <title> Fast randomized consensus using shared memory. </title> <journal> Journal of Algorithms, </journal> <volume> 15(1) </volume> <pages> 441-460, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The types of modularity we are looking for include parallel composition and abstraction mappings, but also anything else that decomposes the math analysis. We develop our tools by analyzing complex algorithms of independent interest. In this paper we analyze the randomized consensus algorithm of Aspnes and Herlihy <ref> [5] </ref>, which guarantees termination within expected polynomial time. The Aspnes-Herlihy algorithm is a rather complex algorithm. Processes move through a succession of asynchronous rounds, attempting to agree at each round. At each round, the agreement attempt involves a distributed random walk. <p> However, the problem becomes solvable using randomization if we relax the termination condition and we replace it with the following condition. Probabilistic wait-free termination: With probability 1, all initialized and non-failed processes eventually decide. The algorithm that we analyze in this paper is due to Aspnes and Herlihy <ref> [5] </ref> and relies on the theory of random walks. It terminates within expected polynomial time. We have chosen this algorithm because it is frequently cited in the literature and because it is among the most complicated randomized algorithms so far proposed. <p> Then the process reads the current value of the shared counter, and if the value read is beyond the barriers Kn, where K is a fixed constant, then the process returns. The protocol described in Table 4 is slightly different from the protocol described in <ref> [5] </ref>: once a coin flip is requested, our protocol checks counter before flipping a coin, while the protocol of [5] starts immediately by flipping a coin. Our protocol improves the protocol of [5] in that properties C1 and C2 are satisfied even in the presence of multiple requests on the same <p> The protocol described in Table 4 is slightly different from the protocol described in <ref> [5] </ref>: once a coin flip is requested, our protocol checks counter before flipping a coin, while the protocol of [5] starts immediately by flipping a coin. Our protocol improves the protocol of [5] in that properties C1 and C2 are satisfied even in the presence of multiple requests on the same port. This improvement is not essential for the correctness of the protocol of [5], since the protocol guarantees that <p> The protocol described in Table 4 is slightly different from the protocol described in <ref> [5] </ref>: once a coin flip is requested, our protocol checks counter before flipping a coin, while the protocol of [5] starts immediately by flipping a coin. Our protocol improves the protocol of [5] in that properties C1 and C2 are satisfied even in the presence of multiple requests on the same port. This improvement is not essential for the correctness of the protocol of [5], since the protocol guarantees that there is at most one request at each port; however, our improvement simplifies <p> coin, while the protocol of <ref> [5] </ref> starts immediately by flipping a coin. Our protocol improves the protocol of [5] in that properties C1 and C2 are satisfied even in the presence of multiple requests on the same port. This improvement is not essential for the correctness of the protocol of [5], since the protocol guarantees that there is at most one request at each port; however, our improvement simplifies the proof slightly in that we do not have to prove explicitly that there is at most one request at each port. 49 Table 5 gives the state variables of the shared <p> If we compare the length of our analysis with the length of the original paper of Aspnes and Herlihy, we observe that the two lengths are similar. The length of our analysis is double the length of the analysis in <ref> [5] </ref>; however, our analysis includes a timing analysis of the protocol, which was not present in [5], and it includes all the details, many of which were not considered in the analysis of [5]. <p> The length of our analysis is double the length of the analysis in <ref> [5] </ref>; however, our analysis includes a timing analysis of the protocol, which was not present in [5], and it includes all the details, many of which were not considered in the analysis of [5]. Also, our proof would be considerably shorter if we had not included the detailed invariants and their proofs. These details are usually not included in algorithm papers. <p> The length of our analysis is double the length of the analysis in <ref> [5] </ref>; however, our analysis includes a timing analysis of the protocol, which was not present in [5], and it includes all the details, many of which were not considered in the analysis of [5]. Also, our proof would be considerably shorter if we had not included the detailed invariants and their proofs. These details are usually not included in algorithm papers.
Reference: [6] <author> Hagit Attiya, Danny Dolev, and Nir Shavit. </author> <title> Bounded polynomial randomised consensus. </title> <editor> In Piotr Rudnicki, editor, </editor> <booktitle> Proceedings of the 8th Annual Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 281-294, </pages> <address> Edmonton, AB, Canada, </address> <month> August </month> <year> 1989. </year> <note> ACM Press. </note>
Reference-contexts: Prior to the algorithm of Aspnes and Herlihy, the best known randomized algorithm for consensus with shared memory was due to Abrahamson [1]. The algorithm has exponential expected running time. The algorithm of Aspnes and Herlihy was improved by Attiya, Dolev, and Shavit <ref> [6] </ref> by eliminating the use of unbounded counters needed for the random walk. Further improvements were proposed by Aspnes [4], and by Dwork, Herlihy, Plotkin, and Waarts [7].
Reference: [7] <author> C. Dwork, M. Herlihy, S. Plotkin, and O. Waarts. </author> <title> Time-lapse snapshots. </title> <type> Unpublished manuscript. </type>
Reference-contexts: The algorithm has exponential expected running time. The algorithm of Aspnes and Herlihy was improved by Attiya, Dolev, and Shavit [6] by eliminating the use of unbounded counters needed for the random walk. Further improvements were proposed by Aspnes [4], and by Dwork, Herlihy, Plotkin, and Waarts <ref> [7] </ref>. The best known algorithm [7] runs in an expected O (n (p 2 + n)) total atomic register operations, where n is the number of processes and p is the number of processes that participate in the consensus protocol. The rest of the paper is organized as follows. <p> The algorithm of Aspnes and Herlihy was improved by Attiya, Dolev, and Shavit [6] by eliminating the use of unbounded counters needed for the random walk. Further improvements were proposed by Aspnes [4], and by Dwork, Herlihy, Plotkin, and Waarts <ref> [7] </ref>. The best known algorithm [7] runs in an expected O (n (p 2 + n)) total atomic register operations, where n is the number of processes and p is the number of processes that participate in the consensus protocol. The rest of the paper is organized as follows.
Reference: [8] <author> W. Feller. </author> <title> An Introduction to Probability Theory and its Applications. Volume 1. </title> <publisher> Jokn Wiley & Sons, Inc., </publisher> <year> 1950. </year>
Reference-contexts: Then, we can define the expected complexity to reach fi in H as follows: E [H; fi] = q2fi (q)P H [C q ] if P H [fi] = 1 1 otherwise. Complexity functions on full cuts enjoy several properties that are typical of random variables <ref> [8] </ref>. That is, if fi is a full cut, then H induces a probability distribution P fi over the states of fi. <p> Then, from [20], tdistr (H 1 ) = tdistr (H 2 ). 19 3 Symmetric Random Walks for Probabilistic Automata The correctness of the protocol of Aspnes and Herlihy is based on the theory of random walks <ref> [8] </ref>. That is, some parts of the protocol behave like a probabilistic process known in the literature as a random walk. <p> The following results are known from random walk theory <ref> [8] </ref>. Theorem 3.1 Let p = q = 1=2. Then 1. P [Top RW [B; T; z]] = (T z)=(T B); 3. P [Either RW [B; T; z]] = 1. <p> For a finitely satisfiable event fi that has probability 1 it is possible to study the average number of moves that are needed to satisfy fi as follows: E RW [fi] = x2fi length (x)P RW [C x ]: From random walk theory <ref> [8] </ref> we know the following result. Theorem 3.2 Let p = q = 1=2.
Reference: [9] <author> M. Fischer, N. Lynch, and M. Paterson. </author> <title> Impossibility of distributed consensus with a family of faulty process. </title> <journal> Journal of the ACM, </journal> <volume> 32(2) </volume> <pages> 374-382, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: Agreement: Any two processes that decide within an execution of the algorithm decide on the same value. Wait-free termination: All initialized and non-failed processes eventually decide. It is known from <ref> [9] </ref> that there is no deterministic algorithm for asynchronous processes that solves consensus and guarantees termination even in the presence of at most one single faulty process. However, the problem becomes solvable using randomization if we relax the termination condition and we replace it with the following condition.
Reference: [10] <author> R. Gawlick, R. Segala, J.F. Stgaard-Andersen, and N.A. Lynch. </author> <title> Liveness in timed and untimed systems. </title> <type> Technical Report MIT/LCS/TR-587, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: Specifically, it is possible to use refinements to derive fair trace inclusion and fair trace distribution inclusion. Our main 18 technique is based on the execution correspondence theorem <ref> [10] </ref>, which allows us to establish close relationships between the executions of two automata. We use refinements in the analysis of the shared counter in the algorithm of Aspnes and Herlihy. Our analysis is carried out mainly on an abstract specification of the counters. <p> For this purpose we augment the I/O automata of the previous sections paper so that time can be observed. Our augmentation resembles the patient construction of <ref> [10] </ref> and produces another probabilistic I/O automaton. Note that we cannot regard the augmentation we present in this paper as the definition of a general timed probabilistic model.
Reference: [11] <author> H. Hansson. </author> <title> Time and Probability in Formal Design of Distributed Systems, volume 1 of Real-Time Safety Critical Systems. </title> <publisher> Elsevier, </publisher> <year> 1994. </year>
Reference-contexts: Other work is based on probabilistic model checking (e.g, <ref> [21, 11] </ref>). Prior to the algorithm of Aspnes and Herlihy, the best known randomized algorithm for consensus with shared memory was due to Abrahamson [1]. The algorithm has exponential expected running time.
Reference: [12] <author> L. Lamport. </author> <title> Concurrent reading and writing. </title> <journal> Communications of the ACM, </journal> 20(11) 806-811, 1977. 
Reference-contexts: In this way, using the coin flipping protocol with the new counter, we obtain a protocol for consensus that uses only single-writer multiple-reader shared variables. The implementation of CT , which we denote by DCT (Distributed CounTer), is an adaptation of an algorithm proposed by Lamport <ref> [12] </ref> for read/write registers.
Reference: [13] <author> D. Lehmann and M. Rabin. </author> <title> On the advantage of free choice: a symmetric and fully distributed solution to the dining philosophers problem. </title> <booktitle> In Proceedings of the 8 th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 133-138, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: We apply all of these techniques to analyze the expected complexity of the algorithm. Previous work on verification of randomized distributed algorithms includes [18], where the randomized dining philosophers algorithm of <ref> [13] </ref> is shown to guarantee progress with probability 1, [15, 19], where the algorithm of [13] is shown to guarantee progress within expected constant time, and [2], where the randomized self-stabilizing minimum spanning tree algorithm of [3] is shown to guarantee stabilization within an expected time proportional to the diameter of <p> We apply all of these techniques to analyze the expected complexity of the algorithm. Previous work on verification of randomized distributed algorithms includes [18], where the randomized dining philosophers algorithm of <ref> [13] </ref> is shown to guarantee progress with probability 1, [15, 19], where the algorithm of [13] is shown to guarantee progress within expected constant time, and [2], where the randomized self-stabilizing minimum spanning tree algorithm of [3] is shown to guarantee stabilization within an expected time proportional to the diameter of a network.
Reference: [14] <author> N.A. Lynch. </author> <title> Distributed Algorithms. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1996. </year>
Reference-contexts: We start with ordinary I/O automata following the style of <ref> [16, 14] </ref>; then we move to probabilistic I/O automata by adding the input/output structure to the probabilistic automata of [20]. We describe methods to handle complexity measures within probabilistic automata, and we present progress statements as a basic tool for the complexity analysis of a probabilistic system.
Reference: [15] <author> N.A. Lynch, I. Saias, and R. Segala. </author> <title> Proving time bounds for randomized distributed algorithms. </title> <booktitle> In Proceedings of the 13 th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Los Angeles, CA, </address> <pages> pages 314-323, </pages> <year> 1994. </year>
Reference-contexts: We apply all of these techniques to analyze the expected complexity of the algorithm. Previous work on verification of randomized distributed algorithms includes [18], where the randomized dining philosophers algorithm of [13] is shown to guarantee progress with probability 1, <ref> [15, 19] </ref>, where the algorithm of [13] is shown to guarantee progress within expected constant time, and [2], where the randomized self-stabilizing minimum spanning tree algorithm of [3] is shown to guarantee stabilization within an expected time proportional to the diameter of a network. <p> The analysis of [18] is based on converting a probabilistic property into a property of some of the computations of an algorithm (extreme fair computations); the 2 analysis of <ref> [15, 19, 2] </ref> is based on part of the methodology used in this paper. Other work is based on probabilistic model checking (e.g, [21, 11]). Prior to the algorithm of Aspnes and Herlihy, the best known randomized algorithm for consensus with shared memory was due to Abrahamson [1]. <p> Probabilistic complexity statements can also be decomposed into simpler statements, thus splitting the progress properties of a randomized system into progress properties that either are simpler to analyze or can be derived by analyzing a smaller subcomponent of the system. Progress statements are introduced in <ref> [15, 19, 20] </ref>.
Reference: [16] <author> N.A. Lynch and M.R. Tuttle. </author> <title> Hierarchical correctness proofs for distributed algorithms. </title> <booktitle> In Proceedings of the 6 th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 137-151, </pages> <address> Vancouver, Canada, </address> <month> August </month> <year> 1987. </year> <note> A full version is available as MIT Technical Report MIT/LCS/TR-387. </note>
Reference-contexts: We start with ordinary I/O automata following the style of <ref> [16, 14] </ref>; then we move to probabilistic I/O automata by adding the input/output structure to the probabilistic automata of [20]. We describe methods to handle complexity measures within probabilistic automata, and we present progress statements as a basic tool for the complexity analysis of a probabilistic system. <p> In this section we provide the pieces of the technique that we use for the analysis of the algorithm of Aspnes and Herlihy. More details can be found in <ref> [16, 17, 20] </ref>. 2.6.1 Traces and Trace Distributions Trace and trace distributions are abstractions of the behavior of automata and probabilistic automata, respectively, that are based only on the sequences of external actions that the automata can provide.
Reference: [17] <author> N.A. Lynch and F.W. Vaandrager. </author> <title> Forward and backward simulations part I: Untimed systems. </title> <type> Technical Report MIT/LCS/TM-486, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> May </month> <year> 1993. </year> <note> Also appears as CWI technical report CS-R9313. 68 </note>
Reference-contexts: In this section we provide the pieces of the technique that we use for the analysis of the algorithm of Aspnes and Herlihy. More details can be found in <ref> [16, 17, 20] </ref>. 2.6.1 Traces and Trace Distributions Trace and trace distributions are abstractions of the behavior of automata and probabilistic automata, respectively, that are based only on the sequences of external actions that the automata can provide.
Reference: [18] <author> A. Pnueli and L. Zuck. </author> <title> Verification of multiprocess probabilistic protocols. </title> <journal> Distributed Computing, </journal> <volume> 1(1) </volume> <pages> 53-72, </pages> <year> 1986. </year>
Reference-contexts: We apply all of these techniques to analyze the expected complexity of the algorithm. Previous work on verification of randomized distributed algorithms includes <ref> [18] </ref>, where the randomized dining philosophers algorithm of [13] is shown to guarantee progress with probability 1, [15, 19], where the algorithm of [13] is shown to guarantee progress within expected constant time, and [2], where the randomized self-stabilizing minimum spanning tree algorithm of [3] is shown to guarantee stabilization within <p> The analysis of <ref> [18] </ref> is based on converting a probabilistic property into a property of some of the computations of an algorithm (extreme fair computations); the 2 analysis of [15, 19, 2] is based on part of the methodology used in this paper.
Reference: [19] <author> A. Pogosyants and R. Segala. </author> <title> Formal verification of timed properties of randomized distributed algorithms. </title> <booktitle> In Proceedings of the 14 th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Ottawa, Ontario, Canada, </address> <pages> pages 174-183, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: We apply all of these techniques to analyze the expected complexity of the algorithm. Previous work on verification of randomized distributed algorithms includes [18], where the randomized dining philosophers algorithm of [13] is shown to guarantee progress with probability 1, <ref> [15, 19] </ref>, where the algorithm of [13] is shown to guarantee progress within expected constant time, and [2], where the randomized self-stabilizing minimum spanning tree algorithm of [3] is shown to guarantee stabilization within an expected time proportional to the diameter of a network. <p> The analysis of [18] is based on converting a probabilistic property into a property of some of the computations of an algorithm (extreme fair computations); the 2 analysis of <ref> [15, 19, 2] </ref> is based on part of the methodology used in this paper. Other work is based on probabilistic model checking (e.g, [21, 11]). Prior to the algorithm of Aspnes and Herlihy, the best known randomized algorithm for consensus with shared memory was due to Abrahamson [1]. <p> Probabilistic complexity statements can also be decomposed into simpler statements, thus splitting the progress properties of a randomized system into progress properties that either are simpler to analyze or can be derived by analyzing a smaller subcomponent of the system. Progress statements are introduced in <ref> [15, 19, 20] </ref>.
Reference: [20] <author> R. Segala. </author> <title> Modeling and Verification of Randomized Distributed Real-Time Systems. </title> <type> PhD thesis, </type> <institution> MIT, Dept. of Electrical Engineering and Computer Science, </institution> <year> 1995. </year> <note> Also appears as technical report MIT/LCS/TR-676. </note>
Reference-contexts: We formalize the Aspnes-Herlihy algorithm using probabilistic I/O automata <ref> [20] </ref>. In doing so, we decompose it formally into three subprotocols: one to carry out the agreement attempts, one to conduct the random walks, and one to implement a shared counter needed by the random walks. <p> We start with ordinary I/O automata following the style of [16, 14]; then we move to probabilistic I/O automata by adding the input/output structure to the probabilistic automata of <ref> [20] </ref>. We describe methods to handle complexity measures within probabilistic automata, and we present progress statements as a basic tool for the complexity analysis of a probabilistic system. <p> It is possible to show that there is a unique probability measure having the property above, and thus ( H ; F H ; P H ) is a well defined probability space. The proof is analogous to the proof given in <ref> [20] </ref> for a similar probability space. An event E of H is an element of F H . An event E is called finitely satisfiable if it can be expressed as a union of cones. <p> It is the case that ffdM i is an execution fragment of M i . The notion of projection can be extended to probabilistic executions (cf. Section 4.3 of <ref> [20] </ref>). Here we do not present the formal definition of projection; rather, we present some properties of a projection that are needed for our analysis, and we refer the reader to [20] for a more detailed description. <p> The notion of projection can be extended to probabilistic executions (cf. Section 4.3 of <ref> [20] </ref>). Here we do not present the formal definition of projection; rather, we present some properties of a projection that are needed for our analysis, and we refer the reader to [20] for a more detailed description. Given a probabilistic execution fragment H of M , it is possible to define an object HdM i , which is a probabilistic execution fragment of M i that informally represents the contribution of M i to H. <p> We prove first that the probability space P i is a fringe of H i as defined in <ref> [20] </ref>, where a fringe of H i is a probability distribution P over the states of H i such that, for each state q of H i , P Consider a state q of H i . <p> Probabilistic complexity statements can also be decomposed into simpler statements, thus splitting the progress properties of a randomized system into progress properties that either are simpler to analyze or can be derived by analyzing a smaller subcomponent of the system. Progress statements are introduced in <ref> [15, 19, 20] </ref>. <p> Progress statements are introduced in [15, 19, 20]. In this section we specialize the theory of <ref> [20] </ref> to fair schedulers. 2.5.1 Probabilistic Complexity Statements A probabilistic complexity statement is a predicate of the form U c p U 0 , where U and U 0 are sets of states, is a complexity measure, and c is a nonnegative real number. <p> The fair probabilistic execution fragments of a probabilistic automaton enjoy a property that in <ref> [20] </ref> is called finite history insensitivity. Thus, using a result of [20], the following holds, which permits us to decompose a progress property into simpler progress properties. Proposition 2.8 Let M be a probabilistic automaton, and let U; U 0 ; U 00 States (M ). <p> The fair probabilistic execution fragments of a probabilistic automaton enjoy a property that in <ref> [20] </ref> is called finite history insensitivity. Thus, using a result of [20], the following holds, which permits us to decompose a progress property into simpler progress properties. Proposition 2.8 Let M be a probabilistic automaton, and let U; U 0 ; U 00 States (M ). Let be a complexity measure. <p> That is, fi U 0 (H) represents the event that contains all those executions of H where a state from U 0 is reached. The following theorem, which is an instantiation of a more general result of <ref> [20] </ref>, provides a way of computing the expected complexity for satisfying fi U 0 (H). Theorem 2.9 ([20]) Let M be a probabilistic automaton and be a complexity measure for M . <p> For the fully detailed proof and for a more general result the reader is referred to <ref> [20] </ref>. 15 2.5.3 How to Verify Probabilistic Complexity Statements A useful technique to prove the validity of a probabilistic complexity statement U c p a probabilistic automaton M is the following. 1. <p> This technique corresponds to the informal arguments of correctness that appear in the literature. Usually the intuition behind an algorithm is exactly that success is guaranteed whenever some specific random draws give some specific results. The first two steps can be carried out using the so-called coin lemmas <ref> [20] </ref>, which provide rules to map a stochastic process onto a probabilistic execution and lower bounds on the probability of the mapped events based on the properties of the given stochastic process; the third step concerns non-probabilistic properties and can be carried out by means of any known technique for non-probabilistic <p> In this section we provide the pieces of the technique that we use for the analysis of the algorithm of Aspnes and Herlihy. More details can be found in <ref> [16, 17, 20] </ref>. 2.6.1 Traces and Trace Distributions Trace and trace distributions are abstractions of the behavior of automata and probabilistic automata, respectively, that are based only on the sequences of external actions that the automata can provide. <p> In this case we also say that h preserves the fair executions of A 1 . The execution correspondence theorem can be extended to the probabilistic case as well <ref> [20] </ref>. We do not write the formal definitions in this paper; however, the following proposition can be proved easily from the results about execution correspondence of [20]. <p> The execution correspondence theorem can be extended to the probabilistic case as well <ref> [20] </ref>. We do not write the formal definitions in this paper; however, the following proposition can be proved easily from the results about execution correspondence of [20]. Proposition 2.14 Let A 1 ; A 2 be two I/O automata, and let M be a probabilistic I/O automaton compatible with A 1 and A 2 . Let h be a refinement from A 1 to A 2 that preserves the fair executions of A 1 . <p> Then ftdistrs (A 1 k M ) ftdistrs (A 2 k M ). Proof outline. Since h is a refinement from A 1 to A 2 , we can conclude from <ref> [20] </ref> that the following function is a probabilistic refinement from A 1 k M to A 2 k M : h 0 (s A 1 ; s M ) = (h (s A 1 ); s M ). <p> That is, h 0 coincides with h on the states of A 1 and A 2 and is the identity function on the states of M . Let H 1 be a fair probabilistic execution of A 1 k M . From the definition of h 0 -relation of <ref> [20] </ref>, and from the definition of h 0 , it is possible to build a fair probabilistic execution H 2 of A 2 k M such that (H 1 ; H 2 ) 2 h 0 . Then, from [20], tdistr (H 1 ) = tdistr (H 2 ). 19 3 <p> From the definition of h 0 -relation of <ref> [20] </ref>, and from the definition of h 0 , it is possible to build a fair probabilistic execution H 2 of A 2 k M such that (H 1 ; H 2 ) 2 h 0 . Then, from [20], tdistr (H 1 ) = tdistr (H 2 ). 19 3 Symmetric Random Walks for Probabilistic Automata The correctness of the protocol of Aspnes and Herlihy is based on the theory of random walks [8].
Reference: [21] <author> M.Y. Vardi. </author> <title> Automatic verification of probabilistic concurrent finite-state programs. </title> <booktitle> In Proceedings of 26th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 327-338, </pages> <address> Portland, OR, </address> <year> 1985. </year> <month> 69 </month>
Reference-contexts: Other work is based on probabilistic model checking (e.g, <ref> [21, 11] </ref>). Prior to the algorithm of Aspnes and Herlihy, the best known randomized algorithm for consensus with shared memory was due to Abrahamson [1]. The algorithm has exponential expected running time.
References-found: 21

