URL: http://www.cs.jhu.edu/~brill/acl-wkshp.ps
Refering-URL: http://www.cs.jhu.edu/~brill/acadpubs.html
Root-URL: 
Email: brill@cs.jhu.edu  
Title: Unsupervised Learning of Disambiguation Rules for Part of Speech Tagging  
Author: Eric Brill 
Affiliation: Department of Computer Science Johns Hopkins University  
Abstract: In this paper we describe an unsupervised learning algorithm for automatically training a rule-based part of speech tagger without using a manually tagged corpus. We compare this algorithm to the Baum-Welch algorithm, used for unsupervised training of stochastic taggers. Next, we show a method for combining unsupervised and supervised rule-based training algorithms to create a highly accurate tagger using only a small amount of manually tagged text.
Abstract-found: 1
Intro-found: 1
Reference: [ Baum, 1972 ] <author> Baum, L. </author> <year> 1972. </year> <title> An inequality and associated maximization technique in statistical estimation for probabilistic functions of a Markov process. </title> <booktitle> Inequalities 3 </booktitle> <pages> 1-8. </pages>
Reference: [ Black et al., 1992 ] <author> Black, E.; Jelinek, F.; Lafferty, J.; Mercer, R.; and Roukos, S. </author> <year> 1992. </year> <title> Decision tree models applied to the labeling of text with parts-of-speech. </title> <booktitle> In Darpa Workshop on Speech and Natural Language. </booktitle> <address> Harriman, N.Y. </address>
Reference-contexts: Therefore, if tagged text is needed in training, this would require manually tagging 1 This work was funded in part by NSF grant IRI-9502312. 2 Some other approaches to tagging are described in <ref> [ Hindle, 1989; Black et al., 1992 ] </ref> . text each time the tagger is to be applied to a new language, and even when being applied to a new type of text.
Reference: [ Brill and Resnik, 1994 ] <author> Brill, E. and Resnik, P. </author> <year> 1994. </year> <title> A transformation-based approach to prepositional phrase attachment disambiguation. </title> <booktitle> In Proceedings of the Fifteenth International Conference on Computational Linguistics (COLING-1994), </booktitle> <address> Kyoto, Japan. </address>
Reference: [ Brill, 1992 ] <author> Brill, E. </author> <year> 1992. </year> <title> A simple rule-based part of speech tagger. </title> <booktitle> In Proceedings of the Third Conference on Applied Natural Language Processing, ACL, </booktitle> <address> Trento, Italy. </address>
Reference-contexts: In <ref> [ Brill, 1992; Brill, 1994 ] </ref> , a rule-based part of speech tagger is described which achieves highly competitive performance compared to stochastic taggers, and captures the learned knowledge in a set of simple deterministic rules instead of a large table of statistics.
Reference: [ Brill, 1993a ] <author> Brill, E. </author> <year> 1993a. </year> <title> Automatic grammar induction and parsing free text: A transformation-based approach. </title> <booktitle> In Proceedings of the 31st Meeting of the Association of Computational Linguistics, </booktitle> <address> Columbus, Oh. </address>
Reference: [ Brill, 1993b ] <author> Brill, E. </author> <year> 1993b. </year> <title> Transformation-based error-driven parsing. </title> <booktitle> In Proceedings of the Third International Workshop on Parsing Technologies, </booktitle> <address> Tilburg, The Netherlands. </address>
Reference: [ Brill, 1994 ] <author> Brill, E. </author> <year> 1994. </year> <title> Some advances in rule-based part of speech tagging. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <address> Seattle, Wa. </address>
Reference-contexts: In <ref> [ Brill, 1992; Brill, 1994 ] </ref> , a rule-based part of speech tagger is described which achieves highly competitive performance compared to stochastic taggers, and captures the learned knowledge in a set of simple deterministic rules instead of a large table of statistics. <p> In each learning iteration, the system learns that transformation whose application results in the greatest reduction of error. 5 Because the learning algorithm is data-driven, it only needs to consider a small 3 For a more detailed description of supervised transformation-based part of speech tagging, see <ref> [ Brill, 1994 ] </ref> . 4 In [ Brill, 1994 ] , a total of 21 templates are used. 5 Note an important difference between Markov-model based taggers and the transformation-based tagger: the former attempts to maximize the probability of a string, whereas the latter attempts to minimize the number of <p> iteration, the system learns that transformation whose application results in the greatest reduction of error. 5 Because the learning algorithm is data-driven, it only needs to consider a small 3 For a more detailed description of supervised transformation-based part of speech tagging, see <ref> [ Brill, 1994 ] </ref> . 4 In [ Brill, 1994 ] , a total of 21 templates are used. 5 Note an important difference between Markov-model based taggers and the transformation-based tagger: the former attempts to maximize the probability of a string, whereas the latter attempts to minimize the number of errors. percentage of all possible transformations when <p> If the word race occurs more frequently as a verb than as a noun in the training corpus, the initial state annotator will mistag this word as a verb in the sentence: The race was very exciting. The above transformation will correct this tagging error. It was shown in <ref> [ Brill, 1994 ] </ref> that the transformation-based tagger achieves a high rate of tagging accuracy. <p> We plan to explore ways of processing unknown words in future work, either by initially assigning them all open-class tags, or devising an unsupervised version of the rule-based unknown word tagger described in <ref> [ Brill, 1994 ] </ref> . To fully define the learner, we must specify the three components of the learner: the initial state annotator, the set of transformation templates, and the scoring criterion. <p> A transformation-based system is a processor and not a classifier. Being a processor, it can be applied to the output of any initial state annotator. As mentioned above, in the supervised transformation-based tagger described in <ref> [ Brill, 1994 ] </ref> , each word is initially tagged with its most likely tag. Here, we use the trained unsupervised part of speech tagger as the initial state annotator for a supervised learner. Transformations will then be learned to fix errors made by the unsupervised learner. <p> This table also gives results from supervised training using the annotated corpus, without any prior unsupervised training. 12 In all cases, the combined training outperformed the purely supervised training at no added cost in terms of annotated 12 The purely supervised learning algorithm is the same as that described in <ref> [ Brill, 1994 ] </ref> , except there the most likely tag for every word in the dictionary is provided to the learner. % Correct % Correct Supervised Training Using Unsupervised Not Using Unsup.
Reference: [ Charniak et al., 1993 ] <author> Charniak, E.; Hendrickson, C.; Jacobson, N.; and Perkowitz, M. </author> <year> 1993. </year> <title> Equations for part of speech tagging. </title> <booktitle> In Proceedings of the Conference of the American Association for Artificial Intelligence (AAAI-93). </booktitle>
Reference-contexts: Once trained, a sentence can be tagged by searching for the tag sequence that maximizes the product of lexical and contextual probabilities. The most accurate stochastic taggers use estimates of lexical and contextual probabilities extracted from large manually annotated corpora (eg. <ref> [ Weischedel et al., 1993; Charniak et al., 1993 ] </ref> ).
Reference: [ Church, 1988 ] <author> Church, K. </author> <year> 1988. </year> <title> A stochastic parts program and noun phrase parser for unrestricted text. </title> <booktitle> In Proceedings of the Second Conference on Applied Natural Language Processing, ACL. </booktitle>
Reference: [ Cutting et al., 1992 ] <author> Cutting, D.; Kupiec, J.; Pedersen, J.; and Sibun, P. </author> <year> 1992. </year> <title> A practical part-of-speech tagger. </title> <booktitle> In Proceedings of the Third Conference on Applied Natural Language Processing, ACL, </booktitle> <address> Trento, Italy. </address>
Reference-contexts: With Markov-model based taggers, there have been two different methods proposed for adding knowledge to a tagger trained using the Baum-Welch algorithm. One method is to manually alter the tagging model, based on human error analysis. This method is employed in <ref> [ Kupiec, 1992; Cutting et al., 1992 ] </ref> . Another approach is to obtain the initial probabilities for the model directly from a manually tagged corpus instead of using random or evenly distributed initial probabilities, and then adjust these probabilities using the Baum-Welch algorithm and an untagged corpus.
Reference: [ DeMarcken, 1990 ] <author> DeMarcken, C. </author> <year> 1990. </year> <title> Parsing the lob corpus. </title> <booktitle> In Proceedings of the 1990 Conference of the Association for Computational Linguistics. </booktitle>
Reference: [ Derose, 1988 ] <author> Derose, S. </author> <year> 1988. </year> <title> Grammatical category disambiguation by statistical optimization. </title> <note> Computational Linguistics 14. </note>
Reference: [ Elworthy, 1994 ] <author> Elworthy, D. </author> <year> 1994. </year> <title> Does Baum-Welch re-estimation help taggers. </title> <booktitle> In Proceedings of the Fourth Conference on Applied Natural Language Processing, ACL. </booktitle>
Reference-contexts: Overtraining did not occur when using the original Brown Corpus either. When training a stochastic tagger using the Baum-Welch algorithm, overtraining often does occur <ref> [ Merialdo, 1995; Elworthy, 1994 ] </ref> , requiring an additional held-out training corpus for determining an appropriate number of training iterations. 10 The graphs are choppy because after each transformation is applied, correctness for words not yet fully disambiguated is judged after randomly selecting from the possible tags for that word. <p> Experiments were run on Associated Press articles which were manually tagged at the University of Lancaster. When training on one million words of text, test set accuracy peaks at 86.6%. In <ref> [ Elworthy, 1994 ] </ref> , similar experiments were run. There, a peak accuracy of 92.0% was attained using the LOB corpus. 11 Using the Penn Treebank corpus, a peak accuracy of 83.6% resulted. These results are significantly lower than the results achieved using unsupervised transformation-based learning. <p> Another approach is to obtain the initial probabilities for the model directly from a manually tagged corpus instead of using random or evenly distributed initial probabilities, and then adjust these probabilities using the Baum-Welch algorithm and an untagged corpus. This approach is described in <ref> [ Merialdo, 1995; Elworthy, 1994 ] </ref> . A tagged corpus can also be used to improve the accuracy of unsupervised transformation-based learning. A transformation-based system is a processor and not a classifier. Being a processor, it can be applied to the output of any initial state annotator. <p> The advantage of combining unsupervised and supervised learning over using supervised 11 <ref> [ Elworthy, 1994 ] </ref> quotes accuracy on ambiguous words, which we have converted to overall accuracy. learning alone is that the combined approach allows us to utilize both tagged and untagged text in training.
Reference: [ Francis and Kucera, 1982 ] <author> Francis, W. and Kucera, H. </author> <year> 1982. </year> <title> Frequency analysis of English usage: Lexicon and grammar. </title> <publisher> Houghton Mi*in, </publisher> <address> Boston. </address>
Reference-contexts: Although a number of manually tagged corpora are available (eg. <ref> [ Francis and Kucera, 1982; Marcus et al., 1993 ] </ref> ), training on a corpus of one type and then applying the tagger to a corpus of a different type usually results in a tagger with low accuracy [ Weischedel et al., 1993 ] . <p> Unsupervised Learning: Results To test the effectiveness of the above unsupervised learning algorithm, we ran a number of experiments using two different corpora and part of speech tag sets: the Penn Treebank Wall Street Journal Corpus [ Marcus et al., 1993 ] and the original Brown Corpus <ref> [ Francis and Kucera, 1982 ] </ref> . First, a dictionary was created listing all possible tags for each word in the corpus. This means that the test set contains no unknown words.
Reference: [ Harris, 1962 ] <author> Harris, Z. </author> <year> 1962. </year> <title> String Analysis of Language Structure. </title> <publisher> Mouton and Co., </publisher> <address> The Hague. </address>
Reference-contexts: Introduction There has recently been a great deal of work exploring methods for automatically training part of speech taggers, as an alternative to laboriously hand-crafting rules for tagging, as was done in the past <ref> [ Klein and Simmons, 1963; Harris, 1962 ] </ref> .
Reference: [ Hindle, 1989 ] <author> Hindle, D. </author> <year> 1989. </year> <title> Acquiring disambiguation rules from text. </title> <booktitle> In Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics. </booktitle>
Reference-contexts: Therefore, if tagged text is needed in training, this would require manually tagging 1 This work was funded in part by NSF grant IRI-9502312. 2 Some other approaches to tagging are described in <ref> [ Hindle, 1989; Black et al., 1992 ] </ref> . text each time the tagger is to be applied to a new language, and even when being applied to a new type of text.
Reference: [ Huang et al., 1994 ] <author> Huang, C.; Son-Bell, M.; and Baggett, D. </author> <year> 1994. </year> <title> Generation of pronunciations from orthographies using transformation-based error-driven learning. </title> <booktitle> In International Conference on Speech and Language Processing (ICSLP), </booktitle> <address> Yokohama, Japan. </address>
Reference: [ Jelinek, 1985 ] <author> Jelinek, F. </author> <year> 1985. </year> <title> Self-Organized Language Modelling for Speech Recognition. Dordrecht. In Impact of Processing Techniques on Communication, </title> <editor> J. Skwirzinski, </editor> <publisher> ed. </publisher>
Reference: [ Klein and Simmons, 1963 ] <author> Klein, S. and Simmons, R. </author> <year> 1963. </year> <title> A computational approach to grammatical coding of English words. </title> <type> JACM 10. </type>
Reference-contexts: Introduction There has recently been a great deal of work exploring methods for automatically training part of speech taggers, as an alternative to laboriously hand-crafting rules for tagging, as was done in the past <ref> [ Klein and Simmons, 1963; Harris, 1962 ] </ref> .
Reference: [ Kupiec, 1992 ] <author> Kupiec, J. </author> <year> 1992. </year> <title> Robust part-of-speech tagging using a hidden Markov model. </title> <booktitle> Computer speech and language 6. </booktitle>
Reference-contexts: In [ Elworthy, 1994 ] , similar experiments were run. There, a peak accuracy of 92.0% was attained using the LOB corpus. 11 Using the Penn Treebank corpus, a peak accuracy of 83.6% resulted. These results are significantly lower than the results achieved using unsupervised transformation-based learning. In <ref> [ Kupiec, 1992 ] </ref> a novel twist to the Baum-Welch algorithm is presented, where instead of having contextual probabilities for a tag following one or more previous tags, words are pooled into equivalence classes, where all words in an equivalence class have the same set of allowable part of speech assignments. <p> With Markov-model based taggers, there have been two different methods proposed for adding knowledge to a tagger trained using the Baum-Welch algorithm. One method is to manually alter the tagging model, based on human error analysis. This method is employed in <ref> [ Kupiec, 1992; Cutting et al., 1992 ] </ref> . Another approach is to obtain the initial probabilities for the model directly from a manually tagged corpus instead of using random or evenly distributed initial probabilities, and then adjust these probabilities using the Baum-Welch algorithm and an untagged corpus.
Reference: [ Lin et al., 1994 ] <author> Lin, Y.; Chiang, T.; and Su, K. </author> <year> 1994. </year> <title> Automatic model refinement with an application to tagging. </title> <booktitle> In Proceedings of the 15th International Conference on Computational Linguistics. </booktitle>
Reference: [ Marcus et al., 1993 ] <author> Marcus, M.; Santorini, B.; and Marcinkiewicz, M. </author> <year> 1993. </year> <title> Building a large annotated corpus of English: the Penn Treebank. </title> <note> Computational Linguistics 19(2). </note>
Reference-contexts: Although a number of manually tagged corpora are available (eg. <ref> [ Francis and Kucera, 1982; Marcus et al., 1993 ] </ref> ), training on a corpus of one type and then applying the tagger to a corpus of a different type usually results in a tagger with low accuracy [ Weischedel et al., 1993 ] . <p> The tags are not listed in any particular order. The initial state annotator tags each word in the corpus with a list of all allowable tags. Below is an example of the initial-state tagging of a sentence from the Penn Treebank <ref> [ Marcus et al., 1993 ] </ref> , where an underscore is to be read as or. 8 Rival/JJ NNP gangs/NNS have/VB VBP turned/VBD VBN cities/NNS into/IN combat/NN VB zones/NNS ./. Transformation Templates The learner currently has four transformation templates. <p> Learning stops when no positive scoring transformations can be found. Unsupervised Learning: Results To test the effectiveness of the above unsupervised learning algorithm, we ran a number of experiments using two different corpora and part of speech tag sets: the Penn Treebank Wall Street Journal Corpus <ref> [ Marcus et al., 1993 ] </ref> and the original Brown Corpus [ Francis and Kucera, 1982 ] . First, a dictionary was created listing all possible tags for each word in the corpus. This means that the test set contains no unknown words.
Reference: [ Merialdo, 1995 ] <author> Merialdo, B. </author> <year> 1995. </year> <title> Tagging english text with a probabilistic model. </title> <note> Computational Linguistics: To Appear. </note>
Reference-contexts: Overtraining did not occur when using the original Brown Corpus either. When training a stochastic tagger using the Baum-Welch algorithm, overtraining often does occur <ref> [ Merialdo, 1995; Elworthy, 1994 ] </ref> , requiring an additional held-out training corpus for determining an appropriate number of training iterations. 10 The graphs are choppy because after each transformation is applied, correctness for words not yet fully disambiguated is judged after randomly selecting from the possible tags for that word. <p> Expanding the training set to 350,000 words and testing on the same test set, accuracy increases to 96.0%. All unsupervised learning results are summarized in table 1. Comparison With Other Results In <ref> [ Merialdo, 1995 ] </ref> , tagging experiments are described training a tagger using the Baum-Welch algorithm with a dictionary constructed as described above and an untagged corpus. Experiments were run on Associated Press articles which were manually tagged at the University of Lancaster. <p> Another approach is to obtain the initial probabilities for the model directly from a manually tagged corpus instead of using random or evenly distributed initial probabilities, and then adjust these probabilities using the Baum-Welch algorithm and an untagged corpus. This approach is described in <ref> [ Merialdo, 1995; Elworthy, 1994 ] </ref> . A tagged corpus can also be used to improve the accuracy of unsupervised transformation-based learning. A transformation-based system is a processor and not a classifier. Being a processor, it can be applied to the output of any initial state annotator. <p> The latter approach has the potential weakness of unsupervised training erasing what was learned from the manually annotated corpus. For example, in <ref> [ Merialdo, 1995 ] </ref> , extracting probability estimates from a 50,000 word manually tagged corpus gave a test set accuracy of 95.4%. After applying ten iterations of the Baum-Welch algorithm, accuracy dropped to 94.4%.
Reference: [ Ramshaw and Marcus, 1994 ] <author> Ramshaw, L. and Marcus, M. </author> <year> 1994. </year> <title> Exploring the statistical derivation of transformational rule sequences for part-of-speech tagging. In The Balancing Act: </title> <booktitle> Proceedings of the ACL Workshop on Combining Symbolic and Statistical Approaches to Language, </booktitle> <institution> New Mexico State University. </institution>
Reference: [ Roche and Schabes, 1995 ] <author> Roche, E. and Schabes, Y. </author> <year> 1995. </year> <title> Deterministic part of speech tagging with finite state transducers. </title> <note> Computational Linguistics: To Appear. </note>
Reference-contexts: Tagging with this finite state transducer requires n steps to tag a sequence of length n, independent of the number of rules, and results in a part of speech tagger ten times faster than the fastest stochastic tagger <ref> [ Roche and Schabes, 1995 ] </ref> . One weakness of this rule-based tagger is that no unsupervised training algorithm has been presented for learning rules automatically without a manually annotated corpus. In this paper we present such an algorithm.
Reference: [ Schutze and Singer, 1994 ] <author> Schutze, H. and Singer, Y. </author> <year> 1994. </year> <title> Part of speech tagging using a variable memory Markov model. </title> <booktitle> In Proceedings of the Association for Computational Linguistics. </booktitle>
Reference: [ Weischedel et al., 1993 ] <author> Weischedel, R.; Meteer, M.; Schwartz, R.; Ramshaw, L.; and Pal-mucci, J. </author> <year> 1993. </year> <title> Coping with ambiguity and unknown words through probabilistic models. </title> <note> Computational Linguistics. </note>
Reference-contexts: Once trained, a sentence can be tagged by searching for the tag sequence that maximizes the product of lexical and contextual probabilities. The most accurate stochastic taggers use estimates of lexical and contextual probabilities extracted from large manually annotated corpora (eg. <ref> [ Weischedel et al., 1993; Charniak et al., 1993 ] </ref> ). <p> Although a number of manually tagged corpora are available (eg. [ Francis and Kucera, 1982; Marcus et al., 1993 ] ), training on a corpus of one type and then applying the tagger to a corpus of a different type usually results in a tagger with low accuracy <ref> [ Weischedel et al., 1993 ] </ref> .
References-found: 27

