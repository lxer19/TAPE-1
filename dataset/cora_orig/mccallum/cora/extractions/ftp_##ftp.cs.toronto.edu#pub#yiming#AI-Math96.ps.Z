URL: ftp://ftp.cs.toronto.edu/pub/yiming/AI-Math96.ps.Z
Refering-URL: http://www.cs.toronto.edu/~yiming/Research.html
Root-URL: http://www.cs.toronto.edu
Email: yiming@vis.toronto.edu tsotsos@vis.toronto.edu  
Title: Sensor Planning in 3D Object Search: its Formulation and Complexity  
Author: Yiming Ye and John K. Tsotsos 
Address: Toronto, Ontario, Canada M5S 1A4  
Affiliation: Department of Computer Science University of Toronto  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Connel. </author> <title> An Artificial Creature. </title> <type> PhD thesis, </type> <institution> AI Lab, MIT, </institution> <year> 1989. </year>
Reference-contexts: Sensor planning for object search refers to the task of how to select the sensing parameters so as to bring the target into the field of view of the sensor. This task is very important if a robot wants to interact intelligently and effectively with its environment. Connell <ref> [1] </ref> constructs a robot that roams an area searching for and collecting soda cans. The planning is very simple since the robot just follows the walls of the room and the sensor only searches the area immediately in front of the robot. <p> The initial probability distribution is denoted as p [0] (c 1 ); p [0] (c 2 ); : : : ; p [0] (c n ); p [0] (c o ). After the application of the operation f 1 , the 4 distribution is denoted by p <ref> [1] </ref> (c 1 ); p [1] (c 2 ); : : : ; p [1] (c n ); p [1] (c o ). <p> After the application of the operation f 1 , the 4 distribution is denoted by p <ref> [1] </ref> (c 1 ); p [1] (c 2 ); : : : ; p [1] (c n ); p [1] (c o ). <p> After the application of the operation f 1 , the 4 distribution is denoted by p <ref> [1] </ref> (c 1 ); p [1] (c 2 ); : : : ; p [1] (c n ); p [1] (c o ). <p> After the application of the operation f 1 , the 4 distribution is denoted by p <ref> [1] </ref> (c 1 ); p [1] (c 2 ); : : : ; p [1] (c n ); p [1] (c o ). Generally, after the application of the operation f i , the distribution is denoted by p [i] (c 1 ); p [i] (c 2 ); : : : ; p [i] (c n ); p [i] (c o ), where 1 i q.
Reference: [2] <author> T. D. Garvey. </author> <title> Perceptual strategies for purposive vision. </title> <type> Technical Report Technical Note 117, </type> <institution> SRI International, </institution> <year> 1976. </year>
Reference-contexts: Rimey and Brown [7] use composite Bayes net and utility decision rule to plan the sensor in their task-oriented system TEA. The indirect search mechanism proposed by Garvey <ref> [2] </ref> is to first 1 direct the sensor to search for an "intermediate" object that commonly participates in a spatial relationship with the target and then direct the sensor to examine the restricted region specified by this relationship.
Reference: [3] <author> W. </author> <title> Grimson. The combinatorics of local constraints in model-based recognition and localization from sparse data. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 33(4) </volume> <pages> 658-686, </pages> <year> 1986. </year>
Reference: [4] <author> L. Kirousis and C. Papadimitriou. </author> <title> The complexity of recognizing polyhedral scenes. </title> <booktitle> In 26 Annual Symposium on Foundations of Computer Science, </booktitle> <address> Portland, Ore., </address> <year> 1985. </year>
Reference-contexts: He [9] also ties the concept of active perception to attentive processing in general and to his complexity level analysis of visual search and proves that active unbounded visual search is NP-Complete. Kirousis and Papadimitriou <ref> [4] </ref> show that the problem of polyhedral scene labeling is inherently NP-Complete. Many other vision researchers ([3],[6], etc.) routinely provide an analysis of the complexity of their proposed algorithms.
Reference: [5] <author> B. O. Koopman. </author> <title> Search and Screen: general principles with historical applications. </title> <publisher> Pergaman Press, </publisher> <address> Elmsford, N.Y, </address> <year> 1980. </year>
Reference-contexts: Wixson and Ballard [10] present a mathematical model of search efficiency and predict that indirect search can improve efficiency in many situations. It is interesting to note that the operational research community has done a lot of research on optimal search <ref> [5] </ref>. Their purpose is to determine how to allocate effort to search for a target, such as a lost submarine in the ocean or an oil field within a certain region.
Reference: [6] <author> W. H. Plantinga and C. R. Dyer. </author> <title> An algorithm for constructing the aspect graph. </title> <booktitle> In 27 Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 123-131, </pages> <address> Toronto, Ontario, </address> <year> 1986. </year>
Reference: [7] <author> R. Rimey and C. Brown. </author> <title> Where to look next using a bayes net: Incorporating geometric relations. </title> <booktitle> In Second European Conference on Computer Vision, </booktitle> <pages> pages 542-550, </pages> <address> Santa Margherita Ligure, Italy, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Connell [1] constructs a robot that roams an area searching for and collecting soda cans. The planning is very simple since the robot just follows the walls of the room and the sensor only searches the area immediately in front of the robot. Rimey and Brown <ref> [7] </ref> use composite Bayes net and utility decision rule to plan the sensor in their task-oriented system TEA.
Reference: [8] <author> J. Tsotsos. </author> <title> Analyzing vision at the complexity level. </title> <journal> The behavioral and brain science, </journal> <volume> 13 </volume> <pages> 423-469, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction The research described in this paper conforms to the complexity level analysis of the sensor planning task for object search. Complexity considerations are commonplace in the biological and computational vision literature. For example, Tsotsos <ref> [8] </ref> shows that the general problem of visual search (search for a target within an image) is computationally intractable in a formal, complexity-theoretic sense.
Reference: [9] <author> J. Tsotsos. </author> <title> Active verses passive perception, which is more efficient? International Journal of Computer Vision, </title> <type> 7(2), </type> <year> 1992. </year>
Reference-contexts: Complexity considerations are commonplace in the biological and computational vision literature. For example, Tsotsos [8] shows that the general problem of visual search (search for a target within an image) is computationally intractable in a formal, complexity-theoretic sense. He <ref> [9] </ref> also ties the concept of active perception to attentive processing in general and to his complexity level analysis of visual search and proves that active unbounded visual search is NP-Complete. Kirousis and Papadimitriou [4] show that the problem of polyhedral scene labeling is inherently NP-Complete. <p> t f 1 )b (c i ; f 1 )] fi [ i=1 + : : : + f j=1 n X p (c i ; t f j )b (c i ; f j )] g fi [ i=1 and the total time for applying this allocation is (following <ref> [9] </ref>): T [F] = 1iq Suppose K is the total time that can be allowed in the search, then the task of sensor planning for object search can be defined as finding an allocation F ae O , which satisfies T (F) K and maximizes P [F]. 3 Some properties of
Reference: [10] <author> L. Wixson and D. Ballard. </author> <title> Using intermediate objects to improve the efficiency of visual search. </title> <journal> IJCV, </journal> <volume> 18(3) </volume> <pages> 209-230, </pages> <year> 1994. </year>
Reference-contexts: The indirect search mechanism proposed by Garvey [2] is to first 1 direct the sensor to search for an "intermediate" object that commonly participates in a spatial relationship with the target and then direct the sensor to examine the restricted region specified by this relationship. Wixson and Ballard <ref> [10] </ref> present a mathematical model of search efficiency and predict that indirect search can improve efficiency in many situations. It is interesting to note that the operational research community has done a lot of research on optimal search [5].
Reference: [11] <author> Y. Ye and J. K. Tsotsos. </author> <title> Where to look next in 3d object search. </title> <booktitle> In Proceedings of the IEEE International Symposium on Computer Vision, </booktitle> <address> Florida, USA, </address> <month> November </month> <year> 1995. </year> <month> 10 </month>
Reference-contexts: The theoretical result provided in this paper has been used as a guideline in designing the practical sensing strategies (see <ref> [11] </ref> for detail). 2 Problem Formulation Although it is important to examine different aspects of object search individually and in some degree of isolation, it is even more important to study their relationship and how to integrate them into a whole search system. <p> The number of total different operations is big, but is not infinite. This number is determined by hardware properties of the mobile platform, the robotics head, the zoom camera, and the available recognition algorithms <ref> [11] </ref>. The target distribution can be specified by a probability distribution function p. p (c i ; t) gives the probability that the center of the target is within cube c i at time t. <p> In general <ref> [11] </ref>, b (c i ; f ) is determined by various factors, such as intensity, occlusion, and orientation etc.. <p> This paper formalized the sensor planning problem, pointed out several properties of this task and analyzed the complexity of this task. The result presented in this paper has been used as a guideline in designing the practical sensor planning system (see <ref> [11] </ref> for detail). According to the properties of the image formation process, we decompose the huge space of all possible sensing actions into a small number of actions that must be tried.
References-found: 11

