URL: http://www.cs.wisc.edu/~talluri/thesis/thesis.tr.ps
Refering-URL: http://www.cs.wisc.edu/~talluri/talluri.html
Root-URL: 
Title: USE OF SUPERPAGES AND SUBBLOCKING IN THE ADDRESS TRANSLATION HIERARCHY  
Degree: by Madhusudhan Talluri A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Science) at the  
Date: 1995  
Address: WISCONSIN MADISON  
Affiliation: UNIVERSITY OF  
Abstract-found: 0
Intro-found: 0
Reference: [Abra81] <author> D. Abramson. </author> <title> Hardware Management of a Large Virtual Memory. </title> <booktitle> In Proc. of the 4th Australian Computer Science Conference, </booktitle> <year> 1981. </year>
Reference-contexts: Many forwar d-mapped page table implementations and guar ded page tables [Lied95] support certain superpage sizes at their intermediate nodes. Hashed page tables ar e being increasingly used to support sparse 64-bit addr ess <ref> [Houd68, Abra81, Thak86, Rose92, Huck93, May94] </ref> but none support superpage mappings.
Reference: [Acce86] <author> M. Accetta, Robert V. Baron, William Bolosky, David B. Golub, and Richard F. Rashid. </author> <title> Mach: A New Kernel Foundation for UNIX Development. </title> <booktitle> In Proc. of the Summer USENIX Conference, </booktitle> <address> Atlanta, </address> <month> Summer </month> <year> 1986. </year>
Reference-contexts: Operating system support for paged virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX [Thom74, Bach86, Lef f90], VMS [Levy82], NT [Cust93], MACH <ref> [Acce86, Rash88] </ref>, OS/2 [Koga88]). Most facets of paged virtual memory operating system policies and mechanisms r equire modif ications to support superpages ef fec-tively. A new policy pagesize assignment and upto six new mechanisms may also be required. <p> Operating system support for virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX [Thom74, Bach86, Leff90, Ging87b], VMS [Levy82], NT [Cust93], MACH <ref> [Acce86, Rash88] </ref>, OS/2 [Koga88]).
Reference: [Adva93] <institution> Advanced RISC Machines. ARM610 RISC Processor, </institution> <year> 1993. </year> <note> Document #: ARM DDI 0004C. </note>
Reference-contexts: For example, MIPS R4x000 supports seven page sizes from 4KB to 16MB [Kane92], UltraSPARC [Yung95] and Alpha [Bann95] support four pages sizes of 8KB, 64KB, 512KB, and 4MB. Others include ET A-10 [ETA 86], ARM6 <ref> [Adva93] </ref>, and SPARC Reference MMU [SPAR91]. Many also include a default TLB miss handler (in hardware or software) that can load superpage mappings in the TLB.
Reference: [Agar88] <author> A. Agarwal, M. Horowitz, and J. Hennessy. </author> <title> Cache Performance of Operating Systems and Multiprogramming Workloads. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 6(4):393431, </volume> <month> November </month> <year> 1988. </year>
Reference-contexts: There are two other limitations of my workloadsmultipr ogramming and working set size. I do not study the ef fects of multipr ogramming several lar ge programs. Multiprogramming can incr ease the number of TLB misses and make TLB miss handling mor e significant <ref> [Agar88] </ref>. Another ef fect of multipr ogramming is the use of mor e physical memory. This can affect the pr oper placement of pages in physical memory for superpage and partialsubblock TLBs (Chapter 6). <p> Rehash schemes: The TLB can first index assuming a base page and on a miss can r epeat the access, next cycle, using the superpage index. Similar schemes have been used to impr ove the performance of set-associative CPU caches <ref> [Agar88, Kess89, Agarwal93] </ref> and page tables [Thak86, May94]. The TLB access takes a variable number of cycles and can complicate pipeline design. If TLB access is in the critical path, increasing the TLB hit time for superpage mappings decreases their usefulness. <p> Software TLBs (e.g., swTLB [Huck93], TSB [Y ung94], STLB [Bala94], PowerPCs page table [May94]) eliminate a hashed page tables next pointers by pre-allocating few PTEs per bucket. be viewed as memory-r esident level-two TLBs with overf low handled in many ways, e.g., hash-rehash schemes <ref> [Agar88, Thak86] </ref> or set r eplacement [May94]. While softwar e TLBs can be the native page table str ucture, e.g., page tables for the PowerPC, they ar e more popular and effective alsoas a cache of r ecently used translations.
Reference: [Alex85] <author> C. A. Alexander, W. M. Keshlear, and F. Briggs. </author> <title> Translation Buffer Performance in a UNIX Environment. </title> <booktitle> Computer Architecture News, </booktitle> <pages> pages 214, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: I list some literatur e relating to TLBs that may be useful for futur e reference. A survey paper on cache memories by Smith also describes TLBs and r elated design parameters [Smit82]. The TLB in the V AX 11/780 system is the focus of some studies <ref> [Saty81, Clar85, Alex85, Alex86] </ref>. Their studies show that time spent in TLB miss handling is less than 5%, for the workloads (including multipr ogrammed 5 work-loads) used in early 1980s. W orkload changes have made TLBs mor e important, as shown in later studies [Chen92, T all92].
Reference: [Alex86] <author> C. Alexander, W. Keshlear, F. Cooper, and F. Briggs. </author> <title> Cache Memory Performance in a UNIX Environment. Computer Architecture News, </title> <address> 14(3):1470, </address> <month> June </month> <year> 1986. </year>
Reference-contexts: I list some literatur e relating to TLBs that may be useful for futur e reference. A survey paper on cache memories by Smith also describes TLBs and r elated design parameters [Smit82]. The TLB in the V AX 11/780 system is the focus of some studies <ref> [Saty81, Clar85, Alex85, Alex86] </ref>. Their studies show that time spent in TLB miss handling is less than 5%, for the workloads (including multipr ogrammed 5 work-loads) used in early 1980s. W orkload changes have made TLBs mor e important, as shown in later studies [Chen92, T all92].
Reference: [Ande92] <author> Thomas E. Anderson, Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy. </author> <title> Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(1), </volume> <month> February </month> <year> 1992. </year>
Reference-contexts: This allows implementation of custom user defined pagesize assignment policies that exploit pr ograms knowledge of their access pattern. Some operating systems have similarly exported mechanisms such as page r eplacement [Youn89, Hart92], scheduling <ref> [Ande92] </ref>, and cache coher ence [Rein94]. In summary, operating systems have a choice of a variety of page-assignment policies and different workloads may pr efer dif ferent policies. The key to operating system design is to identify and implement the mechanisms that can support many alternate policies.
Reference: [Appe91a] <author> Andrew W. Appel and Kai Li. </author> <title> Virtual Memory Primitives for User Programs. </title> <booktitle> In Proc. of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 96106, </pages> <address> Palo Alto, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: TLBs have traditionally been a second-or der performance concern, as pr ograms often incur a higher over head in cache miss handling. W ith the use of lar ge multi-megabyte caches [Kess91] and innovative uses of virtual addr ess spaces <ref> [Appe91a, Blum94] </ref>, some applications now incur mor e TLB misses than cache misses. Fortunately , there is a lar ge body of r esearch in cache design [ e.g., Smit86, Smit91] that is lar gely applicable to TLBs alsoTLBs have a structure similar to caches (Section 1.5).
Reference: [Appe91b] <author> Andrew W. Appel and David B. McQueen. </author> <title> Standard ML of New Jersey. </title> <booktitle> In Proc. Third International Symposium on Programming Language Implementation and Logic Programming, </booktitle> <pages> pages 1 13, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Nasa7, compress, wave5, spice, and gcc are from the SPEC92 suite [SPEC91]; fftpde is a NAS benchmark [Bail91] operating on a 64X64X64 matrix; mp3d and pthor are uniprocessor versions from the SPLASH benchmark suite [Sing92]; coral [Rama93] is a deductive database executing a nested loop join; ML <ref> [Appe91b] </ref> is executing a str ess test on the garbage collector [Repp94]. I use a Sun SPARCstation with a 40 MHz SuperSPARC processor for all the simulations.
Reference: [Aspr93] <author> Tom Asprey, Gregory S. Averill, Eric DeLano, Russ Mason, Bill Weiner, and Jeff Yetter. </author> <title> Performance Features of the PA7100 Microprocessor. </title> <journal> IEEE Micro, </journal> <volume> 13(3):2235, </volume> <month> June </month> <year> 1993. </year>
Reference-contexts: This incr eases cache pollution and r educes the likelihood of completing page table traversal within the CPU caches. Thir d, many pr ocessors support TLB miss handling in software, e.g., ZS-1 [Smit87], AMD29000 [John87], MIPS [Kane92], Alpha [Site93], UltraSP ARC [Yung95], PA7100 <ref> [Aspr93] </ref>, that incurs higher over head than har dware state machines. A small f ive cycle over head to drain the pr ocessor pipeline befor e trapping to softwar e has an opportunity cost of twenty instr uctions in a four way superscalar pr ocessor. <p> Many processors now support TLB miss handling in softwar e with some har dware assist, e.g., MIPS [Kane92], Alpha [Site93], Ul-traSPARC [Yung95], PA7100 <ref> [Aspr93] </ref>. This makes page table design an operating system issue and gives operating system designers mor e exibility than traditional har dware-defined page tables. Section 7.3 introduces the main contribution of this chapter: a clustered page table.
Reference: [Aust95] <author> T. M. Austin, D. N. Pnevmatikatos, and G. S. Sohi. </author> <title> Streamlining Data Cache Access with Fast Address Calculation. </title> <booktitle> In Proc. of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 369380, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: W orkload changes have made TLBs mor e important, as shown in later studies [Chen92, T all92]. Some innovative designs that attempt to r educe TLB access time include the TLB-slice [T ayl90], micr o-TLB [Chen92], lazy addr ess translation [Chiu92], and fast addr ess calculation <ref> [Aust95] </ref>. TLB misses ar e often handled by har dware that traverses page tables. Some processors support TLB miss handling in softwar e and Nagle et al discuss issues in softwar e TLB miss handling using MIPS pr ocessors as examples [Nagl94b].
Reference: [Bach86] <author> Maurice J. Bach. </author> <title> The Design of the UNIX Operating System. </title> <publisher> Prentice Hall, </publisher> <year> 1986. </year>
Reference-contexts: Operating system support for paged virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX <ref> [Thom74, Bach86, Lef f90] </ref>, VMS [Levy82], NT [Cust93], MACH [Acce86, Rash88], OS/2 [Koga88]). Most facets of paged virtual memory operating system policies and mechanisms r equire modif ications to support superpages ef fec-tively. A new policy pagesize assignment and upto six new mechanisms may also be required. <p> Operating system support for virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX <ref> [Thom74, Bach86, Leff90, Ging87b] </ref>, VMS [Levy82], NT [Cust93], MACH [Acce86, Rash88], OS/2 [Koga88]).
Reference: [Baer88] <author> Jean-Loup Baer and Wen-Hann Wang. </author> <title> On the Inclusion Properties for Multi-Level Cache Hierarchies. </title> <booktitle> In Proc. of the 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 73 80, </pages> <address> Honolulu Hawaii, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: I do not use this technique as I did not have access to an instrumentation system for Solaris that worked on dynamically linked libraries, operating system references, and supported multipr ogramming. Finally, Foxtrot supports simulation of two-level TLBs, with or without multilevel inclusion <ref> [Baer88] </ref>. 18 2.2 Area Model The number of TLB misses incurr ed by a TLB can often be made arbitrarily small by increasing the number of TLB blocks to map the complete working set of a workload.
Reference: [Bail91] <author> David Bailey, John Barton, Thomas Lasinski, and Horst Simon. </author> <title> The NAS Parallel Benchmarks. </title> <journal> Intl. Journal of Supercomputer Applications, </journal> <volume> 5(3):6373, </volume> <month> Fall </month> <year> 1991. </year>
Reference-contexts: I first describe the workloads and then discuss the consequences of concentrating on these workloads. Nasa7, compress, wave5, spice, and gcc are from the SPEC92 suite [SPEC91]; fftpde is a NAS benchmark <ref> [Bail91] </ref> operating on a 64X64X64 matrix; mp3d and pthor are uniprocessor versions from the SPLASH benchmark suite [Sing92]; coral [Rama93] is a deductive database executing a nested loop join; ML [Appe91b] is executing a str ess test on the garbage collector [Repp94].
Reference: [Bala92] <author> Ramesh Balan and Kurt Gollhardt. </author> <title> A Scalable Implementation of Virtual Memory HAT layer for Shared Memory Multiprocessor. </title> <booktitle> In Proc. of the Summer USENIX Conference, </booktitle> <pages> pages 107116, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Hashed page tables ar e being increasingly used to support sparse 64-bit addr ess [Houd68, Abra81, Thak86, Rose92, Huck93, May94] but none support superpage mappings. Page table management algorithms in a multi-thr eaded multiprocessor operating system <ref> [Bala92, Khal94] </ref> also af fect system performance, however, they execute infr equently compared to TLB misses. 1.4 My Previous Work A paper titled Tradeoffs in Supporting Two Page Sizes by Talluri et al. [Tall92] first addresses the costs and benefits of using lar ge page sizes. <p> loads/unloads mappings from a page table; one or more file systems that manage and maintain str ucture/coherence of objects on disk/network; a physical memory manager that manages/allocates physical pages; and a page table manager that isolates page table and TLB details in a machinedependent module, e.g., SYSV UNIX hat layer <ref> [Mora88, Bala92] </ref> and Mach pmap layer [Rash88]. To be ef fective, however, superpage and partialsubblock TLBs r equire operating system support in ar eas other than TLB and page table management (Chapter 7 discusses page tables). <p> The operating system uses a locking pr otocol to synchronize concurrent accesses (e.g., <ref> [Bala92, May94] </ref>) and has a significant impact on performance [Khal94]. Some results in the study of concurrent access to database index data str uctures may be applicable to page tables [Come79, Baye77, Litw93, Elli87, Fagi79, Hsu86, Kuma90, Gutt84].
Reference: [Bala94] <author> Kavita Bala, M. Frans Kaashoek, and William E. Weihl. </author> <title> Software prefetching and caching for translation lookaside buffers. </title> <booktitle> In Proc. First Symposium on Operating System Design and Implementation (OSDI), </booktitle> <pages> pages 243253, </pages> <address> Monterey, CA, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Memory system designers ar e addr essing the incr easing TLB miss penalty with mor e levels in the addr ess translation hierar chy by using a second-level software TLB , e.g., swTLB [Huck93], TSB [Yung94], STLB <ref> [Bala94] </ref>. My thesis looks at incr easing TLB r each through use of variable block size and subblock-ing techniques to map mor e addr ess space per TLB block. <p> An inverted page table easily incorporates this optimization by maintaining the hash buckets as circular lists and updating the head pointer after every page table lookup. Software TLBs (e.g., swTLB [Huck93], TSB [Y ung94], STLB <ref> [Bala94] </ref>, PowerPCs page table [May94]) eliminate a hashed page tables next pointers by pre-allocating few PTEs per bucket. be viewed as memory-r esident level-two TLBs with overf low handled in many ways, e.g., hash-rehash schemes [Agar88, Thak86] or set r eplacement [May94]. <p> They may r eside between the TLB and a native page table to r educe average access time for a slow native page table, e.g., a forward-mapped page table <ref> [Huck93, Bala94, Yung95] </ref>. The extensions I develop for hashed page table, described next, are applicable to inverted page tables and softwar e TLBs also, as I show in Section 7.4.7. <p> The separate miss handler r equires hardware to recognize that a subblock miss has occurred. 4. It is not sufficient for hardware to demap the TLB block when the TLB miss occurs, if the software can preload mappings that are not from the same page block <ref> [Bala94] </ref>. 00 PPN 0 ATTR 0 PPN 1 ATTR 1 PPN 3 ATTR 3 3 3 00 PPN 0 ATTR 0 PPN 1 ATTR 1 PPN 3 ATTR 3 State 1 - After TLB miss on page 001 ATTR 2 State 2 - After TLB miss on page 002 3 3
Reference: [Bann95] <author> Peter Bannon and Jim Keller. </author> <title> Internal Architecture of Alpha 21164 Microprocessor. </title> <booktitle> Compcon Digest of Papers, </booktitle> <pages> pages 7987, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Superpages have sizes that ar e power of-two multiples of the base page size and must be aligned in both virtual and physical memory (Chapter 3). Many pr ocessors now support su-perpages, e.g., MIPS [Kane92], UltraSPARC [Yung95], Alpha <ref> [Bann95] </ref>, PowerPC [Silh93], HP-PA RISC [Hunt95]. A fully-associative TLB can easily include support for superpages. An example is the MIPS R4000, which supports a 4KB base page size and superpages of 16KB, 64KB, 256KB, 1MB, 4MB, and 16MB with a fully-associative TLB. <p> The partialsubblock design optimizes a subblock design using specific knowledge about the str ucture and content of the data stor ed in a TLB. A key motivation for my thesis was the intr oduction of superpage support in many microprocessor TLBs, e.g., MIPS [Kane92], UltraSP ARC [Yung95], Alpha <ref> [Bann95] </ref>, PowerPC [Silh93], HP-PA RISC [Hunt95]. Commer cial operating systems I am awar e of, however , do not support general use of superpage mappings. Many operating systems include special mechanisms to use lar ge superpages for unpageable memory and devices. <p> Thus, the key to using superpage TLBs is an operating system that uses superpages wher e appropriate and base pages elsewhere. Nearly every current microprocessor supports superpages, e.g., MIPS [Kane92], UltraS-PARC [Yung95], Alpha <ref> [Bann95] </ref>, PowerPC [Silh93], HP-P A RISC [Hunt95]. The MIPS R4000 [Kane92], for example, supports a 4KB base page size and superpages of 16KB, 64KB, 256KB, 1MB, 4MB, and 16MB. However, I am not aware of any operating system that uses superpages in a general manner. <p> These TLBs ar e usually fully-associative due to the dif ficulty of building set-associative TLBs that support multiple page sizes (Section 3.2.2). For example, MIPS R4x000 supports seven page sizes from 4KB to 16MB [Kane92], UltraSPARC [Yung95] and Alpha <ref> [Bann95] </ref> support four pages sizes of 8KB, 64KB, 512KB, and 4MB. Others include ET A-10 [ETA 86], ARM6 [Adva93], and SPARC Reference MMU [SPAR91]. Many also include a default TLB miss handler (in hardware or software) that can load superpage mappings in the TLB.
Reference: [Bark89] <author> R. E. Barkley and T. Paul Lee. </author> <title> A Lazy Buddy System Bounded by Two Coalescing Delays per Class. </title> <booktitle> In Proc. of the 12th Symposium on Operating System Principles, </booktitle> <pages> pages 167176, </pages> <month> December </month> <year> 1989. </year> <month> 177 </month>
Reference-contexts: Variablesized freelist management has been studied in the context of segments and memory allocators [Know65, Hirs73, Barr93]. The pr oblem is simpler her e than general memory allocators as systems support only a few superpage sizes that ar e powers of two. A buddy-block allocator <ref> [Knut68a, Pete77, T ayl81, Purd70, Bark89, Lee89c] </ref> or ganizes free pages into multiple fr eelists, one per supported allocation size and has a policy and a mechanism to coalesce fr ee pages into a fr ee superpage and vice versa.
Reference: [Barr93] <author> David A. Barrett and Benjamin G. Zorn. </author> <title> Using Lifetime Predictors to Improve Memory Allocation Performance. </title> <booktitle> In Proc. of the SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 187196, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Variablesized freelist management has been studied in the context of segments and memory allocators <ref> [Know65, Hirs73, Barr93] </ref>. The pr oblem is simpler her e than general memory allocators as systems support only a few superpage sizes that ar e powers of two.
Reference: [Baye77] <author> R. Bayer and M. </author> <title> Schkolnick. </title> <journal> Concurrency of Operations on Btrees. Acta Informatica, </journal> <volume> 9(1), </volume> <year> 1977. </year> <note> Also published as IBM, </note> <institution> San Jose Research Lab, </institution> <note> Research Report RJ 1791, </note> <month> May </month> <year> 1976. </year>
Reference-contexts: The operating system uses a locking pr otocol to synchronize concurrent accesses (e.g., [Bala92, May94]) and has a significant impact on performance [Khal94]. Some results in the study of concurrent access to database index data str uctures may be applicable to page tables <ref> [Come79, Baye77, Litw93, Elli87, Fagi79, Hsu86, Kuma90, Gutt84] </ref>. A page table synchr onization protocol has to addr ess at least three issues. First, both the page table and the synonym table must be updated atomically (e.g., with two-phase locking).
Reference: [Beck93] <author> Michael C. Becker, Michael S. Allen, Charles R. Moore, John S. Muhich, and David P. Tuttle. </author> <title> The PowerPC 601 Microprocessor. </title> <journal> IEEE Micro, </journal> <volume> 13(5):5468, </volume> <month> October </month> <year> 1993. </year>
Reference-contexts: The traversal can be done by har dware, e.g., SPARC Reference MMU [SPAR91], some PowerPC implementations <ref> [May94, Levi95, Beck93] </ref>, or by softwar e, e.g., MIPS R4x00 [Kane92], UltraSP ARC [Yung95], Alpha [Site92]. W ith softwar e TLB miss handling, there is typically some har dware assist to speed up page table traversal.
Reference: [Bela66] <author> L. A. Belady. </author> <title> A Study of Replacement Algorithms for a Virtual Storage Computer. </title> <journal> IBM Systems Journal, </journal> <volume> 5(2):78101, </volume> <year> 1966. </year>
Reference-contexts: For set-associative and fully-associative TLBs, har dware or softwar e must implement a r eplacement policy. The TLB r eplacement policy impacts TLB performance because nonoptimal r eplacement decisions would cause additional TLB misses. It is impossible to implement the optimal r eplace-ment policy (OPT) <ref> [Bela66, Matt70, Prie76] </ref>, and it is impractical to maintain information for 8. Alternatively, the modified bit can be updated in the TLB, postponing the page table update till the next TLB replacement and leaves the page table in a stale state.
Reference: [Bell74] <author> J. Bell, D. Casasent, and C. G. Bell. </author> <title> An investigation of Alternative Cache Organizations. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-23(4):346351, </volume> <month> April </month> <year> 1974. </year>
Reference-contexts: In particular, my thesis applies to TLBs and page tables thr ee techniques borr owed fr om cache designvariable block size [Dubn92], subblocking <ref> [Lipt68, Bell74, Good83, Hill84] </ref>, and subblock pr efetching [Smit78b, Hill87]. Superpage TLBs implement a variable block size design with the policy decisions on when to use superpages made by the operating system.
Reference: [Blac89] <author> David L. Black, Richard F. Rashid, David B. Golub, Charles R. Hill, and Robert V. Baron. </author> <title> Translation Lookaside Buffer Consistency: A Software Approach. </title> <booktitle> In Proc. of the Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 113122, </pages> <address> Boston, </address> <month> April </month> <year> 1989. </year>
Reference-contexts: In multiprocessor systems TLB coher ence becomes an issue. T eller describes many strategies for maintaining TLB coher ence [Tell90]. Many operating systems use a conservative TLB shootdown algorithm, e.g., <ref> [Blac89] </ref>. The SPUR [W ood86] and Fugu [Mack94] machines combine TLB coher ence with existing cache coher ence mechanisms. Systems that support paged-segmentation typically include two translation buf fers, a TLB and a SLB (segment lookaside buffer), that ar e accessed one after another . <p> TLB miss handlers both r ead (load translation info) and write the page table (update r efer-ence/modified bits). Third, all the TLBs in a multiprocessor must be kept consistent with page table updates, requiring a TLB consistency algorithm ( e.g., TLB shootdown <ref> [Blac89, Tell90] </ref>) as part of the synchr onization protocol. Addition of superpage and partialsubblock PTEs complicates the synchr onization protocol. In practice, certain kinds of TLB-TLB and TLB-PTE inconsistencies are not fatal to the operation of the system and can be allowed.
Reference: [Blan92] <author> Greg Blanck and Steve Krueger. </author> <title> The SuperSPARC Microprocessor. </title> <booktitle> Compcon Digest of Papers, </booktitle> <pages> pages 136141, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: Foxtrot hides these page table changes from the rest of the operating system with wrapper functions for the read_pte and write_pte routines in So-laris. Foxtrot implements this for superSP ARC processors <ref> [Blan92] </ref> with SP ARC Reference MMU [SPAR91] and har dware TLB miss handling. This technique is also applicable for other processors or page table structures. Tapeworm II [Uhli94], for example, implements trap-driven simulation for a MIPS RX000 pr ocessor with linear page tables. <p> Ther e are techniques to short-circuit some levels. Guarded page tables [Lied95] are sometimes effective but would still require three to four levels. An intermediate node cache can accelerate page table access, e.g., PTP cache in SuperSPARC <ref> [Blan92] </ref>, Region Lookaside buffer in HaL [Chan95]. Large addr ess space systems often use hashed (inverted) page tables [Lee89b, Chan88, Huck93, May94] as they use memory pr oportional to the number of active virtual pages 1 .
Reference: [Blum94] <author> Matthias A. Blumrich, Kai Li, Richard Alpert, Cezary Dubnicki, Edward W. Felten, and Jonathon Sandberg. </author> <title> Virtual Memory Mapped Network Interface for the SHRIMP Multicomputer. </title> <booktitle> In Proc. 21st Annual Symposium on Computer Architecture, Computer Architecture N ews, </booktitle> <pages> pages 142 153, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: TLBs have traditionally been a second-or der performance concern, as pr ograms often incur a higher over head in cache miss handling. W ith the use of lar ge multi-megabyte caches [Kess91] and innovative uses of virtual addr ess spaces <ref> [Appe91a, Blum94] </ref>, some applications now incur mor e TLB misses than cache misses. Fortunately , there is a lar ge body of r esearch in cache design [ e.g., Smit86, Smit91] that is lar gely applicable to TLBs alsoTLBs have a structure similar to caches (Section 1.5).
Reference: [Bur61] <institution> A definition of the B5000 Information Processing System. Burrough Corp, </institution> <year> 1961. </year>
Reference-contexts: Pure segmented systems allow allocation of arbitrary sized r egions of memory and wer e popular in early computer systems, e.g., Multics [Or ga72] and Burr oughs B5000 <ref> [Bur61] </ref>. Segments use a two-dimensional addr ess space, may be arbitrarily long, and may start at arbitrary physical addr esses. Supporting superpages is easier than supporting segments because superpages have alignment r estrictions that allow har dware to use bit steering instead of adders that segments r equire.
Reference: [Camp91] <author> M. Campbell and et al. </author> <title> The Parallelization of UNIX System V Release 4.0. </title> <booktitle> In Proceedings of the Winter 1991 USENIX Conference, </booktitle> <year> 1991. </year>
Reference-contexts: Most code and data str uctures assume a constant PAGESIZE. Many internal and external interfaces assume a single fixed page size as an implicit parameter ( e.g., vnode interface [Klei86]). A multiprocessor multi-threaded operating system <ref> [Camp91, Eykh92, Khal94] </ref> has to synchr onize concurr ent operations and using superpages r equires a r edesign of the synchronization protocols. Some file systems assume that the page size is smaller than the file block size, and so on.
Reference: [Cao94] <author> Pei Cao, Edward W. Felten, and Kai Li. </author> <title> Implementation and performance of application-controlled file caching. </title> <booktitle> In Proc. First Symposium on Operating System Design and Implementation (OSDI), </booktitle> <pages> page 165 177, </pages> <address> Monterey, CA, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: A competitive algorithm makes decisions that r esult in performance within a constant factor of an optimal policy and competitive algorithms have been used in other contexts, e.g., <ref> [Karl88, Karl91, Slea85, Cao94] </ref>. Romer et al. r ecently pr oposed a competitive pagesize assignment policy that accounts for the cost of TLB misses and captur es reference patterns by updating counters for every base page and superpage on TLB misses [Rome95].
Reference: [Cart94] <author> Nicholas P. Carter, Stephen W. Keckler, and William J. Dally. </author> <title> Hardware Support for Fast Capability-Based Addressing. </title> <booktitle> In Proc. of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 328337, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: The exact index method, described later , is practical to implement if the page size corr esponding to the virtual address is known when starting the TLB access, e.g., the virtual addr ess includes the page size <ref> [Cart94] </ref>. Which bits from the virtual address should the TLB use to index the tag array? There are at least three options to consider: the VPN of the base page; the VPN of the superpage; or the exact VPN with apriori knowledge of the page size. <p> Indexing the TLB by the exact VPN. If the TLB knew the page size before starting the TLB access or can magically guess the corr ect page size, e.g., the virtual addr ess may include the page size <ref> [Cart94] </ref>, the TLB can be indexed by the superpage VPN (bits &lt;17..15&gt;) for superpag-es and by the base page VPN (bits &lt;14..12&gt;) for base pages. This solution would use a single TLB block for superpages without increasing the collision costs for using base pages.
Reference: [Chan88] <author> Albert Chang and Mark F. Mergen. </author> <title> 801 Storage: Architecture and Programming. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 6(1):2850, </volume> <month> February </month> <year> 1988. </year>
Reference-contexts: Foxtrot, my operating system pr ototype, implements a functional set of policies and mechanisms to support two page sizes and partial subblocking. 92 Chapter 7 Page Table Structures 7.1 Introduction A page table stores translation, pr otection, attribute, and status information for virtual addresses <ref> [Huck93, Chan88, Levy82, Silh93, Lee89b] </ref>. A page table entry (PTE) stores the information for one page. The TLB miss handler accesses the page table on a TLB miss to load the appropriate PTE into the TLB. <p> Guarded page tables [Lied95] are sometimes effective but would still require three to four levels. An intermediate node cache can accelerate page table access, e.g., PTP cache in SuperSPARC [Blan92], Region Lookaside buffer in HaL [Chan95]. Large addr ess space systems often use hashed (inverted) page tables <ref> [Lee89b, Chan88, Huck93, May94] </ref> as they use memory pr oportional to the number of active virtual pages 1 . A simple implementation uses an open hash table and a hash function that maps a VPN to a bucket, e.g., . <p> A synonym table is trivial in a global addr ess space model as it disallows aliases and each physical page descriptor stor es the corr esponding virtual addr ess <ref> [Chan88] </ref>. In implementations that support aliases, the synonym table builds a one-to-many r elation with a physical page descriptor storing either multiple alias descriptors or a pointer to a list of alias descriptors. An alias descriptor has a pointer to the PTE or a copy of the PTE itself.
Reference: [Chan90] <author> A. Chang, M. F. Mergen, R. K. Rader, J. A. Roberts, and S. L. Porter. </author> <title> Evolution of storage facilities in AIX Version 3 for RISC System/6000 processors. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 34(1):105110, </volume> <month> January </month> <year> 1990. </year>
Reference-contexts: In a paged-segmentation model, pr ograms generate a &lt;segment identifier, segment of fset&gt; tuple that f irst translates to a global ef fective virtual addr ess befor e translating to a physical addr ess [Knig81, Dall92]. Examples include Honeywell 645 [Glas65], SPUR, [Hill86], HP-P A RISC [Lee89b], IBM RS/6000 <ref> [Chan90] </ref>, and PowerPC [May94]. TLBs and page tables translate the virtual addr ess to physical addr ess, and superpages or sub-blocking ar e equally applicable as described in this thesis. <p> The same mapping at V A 0x40000 allows the use of one 4MB super-page. Virtual address allocation is more important than proper physical memory allocation as virtual addresses once allocated cannot be changedgather operations can corr ect erroneous physical memory allocations. Paged-segmented ar chitectures <ref> [Radi82, Chan90, Lee89b] </ref> can reassign virtual addr esses by modifying the segment table but cannot avoid the pr oblem completely as the segment of fset cannot be changed.
Reference: [Chan95] <author> David Chih-Wei Chang and et al. </author> <title> Microarchitecture of HaLs Memory Management Unit. </title> <booktitle> Comp-con Digest of Papers, </booktitle> <pages> pages 272279, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Ther e are techniques to short-circuit some levels. Guarded page tables [Lied95] are sometimes effective but would still require three to four levels. An intermediate node cache can accelerate page table access, e.g., PTP cache in SuperSPARC [Blan92], Region Lookaside buffer in HaL <ref> [Chan95] </ref>. Large addr ess space systems often use hashed (inverted) page tables [Lee89b, Chan88, Huck93, May94] as they use memory pr oportional to the number of active virtual pages 1 .
Reference: [Chas94] <author> J. S. Chase, H. M. Levy, M. J. Feeley, and E. D. Lazowska. </author> <title> Sharing and Protection in a Single-Address-Space Operating System. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 12(4):271307, </volume> <month> No-vember </month> <year> 1994. </year>
Reference-contexts: An operating system data structure, which I call the synonym table, keeps track of these aliases. Section 7.5 explores ways to incorporate superpage and partialsubblock PTEs in a synonym table. The page table techniques described in this chapter are equally applicable to single address space systems, e.g., Opal <ref> [Chas94] </ref> or MONADS [Rose85], and segmented systems that use global effective virtual addresses, e.g, HP [Lee89b]. Hashed and clustered page tables are especially attractive in these systems as they have a very sparse address space.
Reference: [Chen92] <author> J. Bradley Chen, Anita Borg, and Norman P. Jouppi. </author> <title> A Simulation Based Study of TLB Performance. </title> <booktitle> In Proc. of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 114123, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Their studies show that time spent in TLB miss handling is less than 5%, for the workloads (including multipr ogrammed 5 work-loads) used in early 1980s. W orkload changes have made TLBs mor e important, as shown in later studies <ref> [Chen92, T all92] </ref>. Some innovative designs that attempt to r educe TLB access time include the TLB-slice [T ayl90], micr o-TLB [Chen92], lazy addr ess translation [Chiu92], and fast addr ess calculation [Aust95]. TLB misses ar e often handled by har dware that traverses page tables. <p> W orkload changes have made TLBs mor e important, as shown in later studies [Chen92, T all92]. Some innovative designs that attempt to r educe TLB access time include the TLB-slice [T ayl90], micr o-TLB <ref> [Chen92] </ref>, lazy addr ess translation [Chiu92], and fast addr ess calculation [Aust95]. TLB misses ar e often handled by har dware that traverses page tables. <p> Commer cial operating systems I am awar e of, however , do not support general use of superpage mappings. Many operating systems include special mechanisms to use lar ge superpages for unpageable memory and devices. While some have suggested uses for superpages <ref> [Chen92, Mogu93] </ref>, I believe my thesis (and my pr evious work) is the f irst to study the issues involved in building superpages TLBs and supporting them.
Reference: [Chen93a] <author> J. Bradley Chen. </author> <title> Software Methods for System Address Tracing. </title> <booktitle> In Proc. of the Fourth Workshop on Workstation Operating Systems, </booktitle> <pages> pages 178185, </pages> <address> Napa CA, </address> <month> October </month> <year> 1993. </year> <month> 178 </month>
Reference-contexts: Trap-driven simulation is a very fast simulation technique when the miss ratio is very low [Uhli94, Lebe95], as it often is for TLBs. Other r esearchers instrument executables and operating systems to perform memory system simulations, e.g., Active Memory [Lebe95], Epoxie <ref> [Chen93b, Chen93a] </ref>, and ATOM [Sriv94]. I do not use this technique as I did not have access to an instrumentation system for Solaris that worked on dynamically linked libraries, operating system references, and supported multipr ogramming.
Reference: [Chen93b] <author> J. Bradley Chen and Brian N. Bershad. </author> <title> The Impact of Operating System Structure on Memory System Performance. </title> <booktitle> In Proc. of the 14th Symposium on Operating System Principles, </booktitle> <pages> pages 120133, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Trap-driven simulation is a very fast simulation technique when the miss ratio is very low [Uhli94, Lebe95], as it often is for TLBs. Other r esearchers instrument executables and operating systems to perform memory system simulations, e.g., Active Memory [Lebe95], Epoxie <ref> [Chen93b, Chen93a] </ref>, and ATOM [Sriv94]. I do not use this technique as I did not have access to an instrumentation system for Solaris that worked on dynamically linked libraries, operating system references, and supported multipr ogramming.
Reference: [Chiu92] <author> Tzicker Chiueh and Randy H. Katz. </author> <title> Eliminating the Address Translation Bottleneck for Physical Address Cache. </title> <booktitle> In Proc. of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 137148, </pages> <address> Boston MA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: W orkload changes have made TLBs mor e important, as shown in later studies [Chen92, T all92]. Some innovative designs that attempt to r educe TLB access time include the TLB-slice [T ayl90], micr o-TLB [Chen92], lazy addr ess translation <ref> [Chiu92] </ref>, and fast addr ess calculation [Aust95]. TLB misses ar e often handled by har dware that traverses page tables. Some processors support TLB miss handling in softwar e and Nagle et al discuss issues in softwar e TLB miss handling using MIPS pr ocessors as examples [Nagl94b]. <p> I have not explor ed this interaction or its ef fect on system performance. 6.3.6 Page Coloring Page coloring <ref> [Tayl90, Kess92, Chiu92] </ref> also car efully selects physical pages for virtual addresses but for a dif ferent purpose and in a dif ferent way than page r eservation.
Reference: [Clar85] <author> Douglas W. Clark and Joel S. Emer. </author> <title> Performance of the VAX-11/780 Translation Buffer: Simulation and Measurement. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(1):3162, </volume> <month> February </month> <year> 1985. </year>
Reference-contexts: In the early 1980s, TLB miss handling was a small fraction of the pr ocessor s cycles-per-instruction (CPI) <ref> [Clar85, W ood86] </ref>. Many workload, technology , and ar chitecture tr ends have combined to incr ease both the number of TLB misses and the TLB miss penalty , increasing the amount of time spent in TLB miss handling. <p> I list some literatur e relating to TLBs that may be useful for futur e reference. A survey paper on cache memories by Smith also describes TLBs and r elated design parameters [Smit82]. The TLB in the V AX 11/780 system is the focus of some studies <ref> [Saty81, Clar85, Alex85, Alex86] </ref>. Their studies show that time spent in TLB miss handling is less than 5%, for the workloads (including multipr ogrammed 5 work-loads) used in early 1980s. W orkload changes have made TLBs mor e important, as shown in later studies [Chen92, T all92].
Reference: [Clar95] <author> Ron Clark, Jack O Quinn, and Tom Weaver. </author> <title> Symmetric Multiprocessing for the AIX Operating System. </title> <booktitle> Compcon Digest of Papers, </booktitle> <pages> pages 110115, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: It has two drawbacks. First, it does not allow use of superpages to make page tables smaller . Second, the r eplicated PTEs make adding a superpage PTE or atomic PTE update more complex, especially in multi-threaded, multiprocessor operating systems <ref> [Eykh92, Clar95, May94] </ref>. Multiple Page Tables. This solution creates separate page tables for each page size in use. On a TLB miss, the handler accesses and sear ches the page tables in some pr edetermined order.
Reference: [Come79] <author> D. Comer. </author> <title> The Ubiquitous Btree. </title> <journal> ACM Surveys, </journal> <volume> 11(2), </volume> <month> June </month> <year> 1979. </year>
Reference-contexts: In Figure 7-9, for example, the branching factor for level 7 can be either four or sixty-four depending on whether a 256KB r egion uses 64KB PTEs or 4KB PTEs. Implementing the forwar d-mapped page table as a B-tr ee <ref> [Come79] </ref> allows each intermediate node to map a variable amount of memory and can result in fewer levels. However, a B-tree requires a binary sear ch at each level of the tr ee instead of indexing with fields fr om the virtual address. I have not explored the tradeoff further. <p> The operating system uses a locking pr otocol to synchronize concurrent accesses (e.g., [Bala92, May94]) and has a significant impact on performance [Khal94]. Some results in the study of concurrent access to database index data str uctures may be applicable to page tables <ref> [Come79, Baye77, Litw93, Elli87, Fagi79, Hsu86, Kuma90, Gutt84] </ref>. A page table synchr onization protocol has to addr ess at least three issues. First, both the page table and the synonym table must be updated atomically (e.g., with two-phase locking).
Reference: [Cust93] <author> Helen Custer. </author> <title> Inside Windows NT. </title> <publisher> Microsoft Press, </publisher> <year> 1993. </year>
Reference-contexts: Operating system support for paged virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX [Thom74, Bach86, Lef f90], VMS [Levy82], NT <ref> [Cust93] </ref>, MACH [Acce86, Rash88], OS/2 [Koga88]). Most facets of paged virtual memory operating system policies and mechanisms r equire modif ications to support superpages ef fec-tively. A new policy pagesize assignment and upto six new mechanisms may also be required. <p> Operating system support for virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX [Thom74, Bach86, Leff90, Ging87b], VMS [Levy82], NT <ref> [Cust93] </ref>, MACH [Acce86, Rash88], OS/2 [Koga88]).
Reference: [Dall92] <author> William J. Dally. </author> <title> A Fast Translation Method for Paging on top of Segmentation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 41(2), </volume> <month> February </month> <year> 1992. </year>
Reference-contexts: In a paged-segmentation model, pr ograms generate a &lt;segment identifier, segment of fset&gt; tuple that f irst translates to a global ef fective virtual addr ess befor e translating to a physical addr ess <ref> [Knig81, Dall92] </ref>. Examples include Honeywell 645 [Glas65], SPUR, [Hill86], HP-P A RISC [Lee89b], IBM RS/6000 [Chan90], and PowerPC [May94]. TLBs and page tables translate the virtual addr ess to physical addr ess, and superpages or sub-blocking ar e equally applicable as described in this thesis. <p> Systems that support paged-segmentation typically include two translation buf fers, a TLB and a SLB (segment lookaside buffer), that ar e accessed one after another . Dally shows a scheme that combines the segment and page translation <ref> [Dall92] </ref>. TLBs have traditionally been a second-or der performance concern, as pr ograms often incur a higher over head in cache miss handling.
Reference: [Dekk87] <author> G. J. Dekker and A. J. van de Goor. AMORE, </author> <title> Address Mapping with Overlapped Rotating Entries. </title> <journal> IEEE Micro, </journal> <volume> 7(3):2234, </volume> <month> June </month> <year> 1987. </year>
Reference-contexts: Figur e 1-2 shows a sample TLB block for 64-bit virtual addr esses with the length of the f ields in bitsthe VPN includes a 12-bit pr o-cess identifier (PID) <ref> [Dekk87] </ref>. Note that the TLB tag has mor e bits than the data. This is a significant difference fr om cache designs wher e tags, e.g., four to eight bytes, ar e much smaller than a cache block size, e.g., 32-256 bytes.
Reference: [DeMo86] <author> M. DeMoney, J. Moore, and J. Mashey. </author> <title> Operating System Support on a RISC. </title> <booktitle> In Proceedings 1986 COMPCON, </booktitle> <address> San Francisco, CA, March 4-6 1986. </address> <publisher> IEEE. </publisher>
Reference-contexts: Mod-bit updates occur fr equently as pr ograms often r ead data fr om a page befor e writing to it. Software TLB miss handlers allow operating systems to implement optimizations in setting these bits <ref> [DeMo86] </ref>. A TLB r eplacement policy, like a cache r eplacement policy [Puza85], decides wher e to place a new translation by choosing a victim TLB block. In a dir ect-mapped TLB replacement is trivialthere is only a single TLB block that can stor e the new translation.
Reference: [Denn68] <author> Peter J. Denning. </author> <title> The Working Set Model for Program Behavior. </title> <journal> Communications of the ACM, </journal> <volume> 11(5):323333, </volume> <month> May </month> <year> 1968. </year>
Reference-contexts: One longstanding computer tr end is that pr ograms memory usage doubles each year or two [Henn90]. To support the lar ger program working set sizes <ref> [Denn68] </ref>, workstations with more than 100MB of physical memory ar e becoming common. This places pr essure on the TLB to map an incr easingly larger amount of memory .
Reference: [Denn70] <author> Peter J. Denning. </author> <title> Virtual Memory. </title> <journal> Computing Surveys, </journal> <volume> 2(3):153189, </volume> <month> September </month> <year> 1970. </year>
Reference-contexts: On every memory access the system translates a virtual addr ess to a physical addr ess. This indir ection allows access to mor e memory than physically pr esent, transpar ent r elocation of pr ogram text and data, and pr otection between pr ocesses <ref> [Denn70] </ref>. A page table stores the translation and pr otection information and a translation lookaside buffer 1 (TLB) caches r ecently used translations to accelerate the translation pr ocess [Lee69, Smit82, Mile90]. <p> One way to incr ease the addr ess space mapped by a TLB block is to incr ease the page size. Doubling the page size, for example, doubles TLB r each. Large page sizes, however , increase physical memory usage due to internal fragmentation <ref> [Denn70] </ref> because the page size is lar ger than what the pr ogram needs. <p> In the next two chapters, I discuss the operating system mechanisms needed to support partialsubblock TLBs (and superpage TLBs) and page tables to store partialsubblock (and su-perpage) mappings. 78 Chapter 6 Operating System Support Virtual memory <ref> [Denn70] </ref> computer systems r equire a close interaction between the har d-ware ar chitecture and the operating system. Operating system support for virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX [Thom74, Bach86, Leff90, Ging87b], VMS [Levy82], NT [Cust93], MACH [Acce86, Rash88], OS/2 [Koga88]).
Reference: [Denn75] <author> Peter J. Denning and Kevin Kahn. </author> <title> A Study of Program Locality & Lifetime Functions. </title> <booktitle> In Proc. of the 5th Symposium on Operating System Principles, </booktitle> <pages> pages 207216, </pages> <month> November </month> <year> 1975. </year>
Reference-contexts: These TLBs can hold mappings to mor e base pages than a monolithic single-page-size of comparable implementation cost. Pr efetching mappings for neighboring base pages on a single TLB miss further r educes the number of TLB misses. These techniques ar e effective when spatial locality <ref> [Denn75] </ref> makes it likely that consecutive base pages ar e in contemporaneous use. The three TLB ar chitectures differ in the conditions under which mappings to base pages within a page block can shar e a single TLB block (T able 1-2).
Reference: [Devi92] <author> Yannick Deville and Jean Gobert. </author> <title> A class of replacement policies for medium and high associativity structures. Computer Architecture News, </title> <address> 20(1):5564, </address> <month> March </month> <year> 1992. </year>
Reference-contexts: The operating system often consults page table modified bits to ush dirty pages to disk and must instead use TLB probes to get the correct state. 15 true LRU (least r ecently used) replacement policy for lar ge set sizes. Pseudo-LRU algorithms, that approximate LRU with limited information <ref> [Kess89, So88, Devi92] </ref>, ar e often used. Policies that do not use reference information, e.g., RANDOM [Kane89], are cheaper to implement but incur more TLB misses. Section 2.6 describes the pseudo-LRU r eplacement policy I use in my TLB simulations.
Reference: [Dubn92] <author> Czarek Dubnicki and Thomas J. LeBlanc. </author> <title> Adjustable Block Size Coherent Caches. </title> <booktitle> In Proc. 19th Annual International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: In particular, my thesis applies to TLBs and page tables thr ee techniques borr owed fr om cache designvariable block size <ref> [Dubn92] </ref>, subblocking [Lipt68, Bell74, Good83, Hill84], and subblock pr efetching [Smit78b, Hill87]. Superpage TLBs implement a variable block size design with the policy decisions on when to use superpages made by the operating system.
Reference: [East79] <author> M. C. Easton and P. A. Franasek. </author> <title> Use of Bit Scanning in Replacement Decisions. </title> <journal> IEEE Transactions on Computing, </journal> <volume> 28(2):133141, </volume> <month> February </month> <year> 1979. </year>
Reference-contexts: In the rest of the thesis, I only include r esults using the above r eplacement policy. Simulation results show that using this replacement policy often results in fewer TLB misses than others. For illustration, I consider thr ee alternate TLB r eplacement policies. Clock <ref> [East79] </ref> implements a second-chance r eplacement algorithm often used in operating system page r e-placement, with the additional optimization that invalid TLB blocks ar e replaced first. Random [Kane89] replaces an arbitrary TLB block that may or may not be valid. FIFO implements a straightforward first-in-first-out algorithm. <p> Foxtr ot prevents such read-ahead. Other options include doing page r eservation on demand or allocating random base pages followed by a gather operation during page pr omotion. 6.3.5 Page replacement LRU-based replacement policies, e.g., Clock <ref> [East79] </ref>, work as in a single-page-size system if superpage mappings duplicate the r eference and modified bits in all the base physical page descriptors. Thus, base pages with superpage mappings ar e treated similarlyall replaced or none replaced.
Reference: [Eden90] <author> Robin W. Edenfield, Michael G. Gallup, William B. Ledbetter, Jr., Ralph C. McGarity, Eric E. Quintana, and Russell A. Reininger. </author> <title> The 68040 Processor: Part 2, Memory Design & Chip Verification. </title> <journal> IEEE Micro, </journal> <volume> 10(3):2235, </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: Examples of this category include Motor ola 68040, which has a mode bit to select between 4KB and 8KB page size <ref> [Eden90] </ref>, Motor ola 68020 using MC68851 contr oller can select a page size fr om 256 bytes to 2KB [Moto86], the SGI R8000 pr ocessor allows two page sizesone for instr uctions and another for datathat ar e selectable per process [MIPS93], AMD29000 [John87] supports a per-process pagesize. 31 Many single-page-size
Reference: [Elli87] <author> Carla S. Ellis. </author> <title> Concurrency in Linear Hashing. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 12(2), </volume> <month> June </month> <year> 1987. </year> <note> Also published as ACM SIGACT-SIGMOD Symposium on Principles of Database Systems 4, Mar.1985. </note>
Reference-contexts: The operating system uses a locking pr otocol to synchronize concurrent accesses (e.g., [Bala92, May94]) and has a significant impact on performance [Khal94]. Some results in the study of concurrent access to database index data str uctures may be applicable to page tables <ref> [Come79, Baye77, Litw93, Elli87, Fagi79, Hsu86, Kuma90, Gutt84] </ref>. A page table synchr onization protocol has to addr ess at least three issues. First, both the page table and the synonym table must be updated atomically (e.g., with two-phase locking).
Reference: [ETA 86] <author> ETA Systems, Inc. </author> <title> Mainframe Subsystem Instruction Specification for the ETA10, </title> <journal> Rev: B, </journal> <month> March </month> <year> 1986. </year>
Reference-contexts: For example, MIPS R4x000 supports seven page sizes from 4KB to 16MB [Kane92], UltraSPARC [Yung95] and Alpha [Bann95] support four pages sizes of 8KB, 64KB, 512KB, and 4MB. Others include ET A-10 <ref> [ETA 86] </ref>, ARM6 [Adva93], and SPARC Reference MMU [SPAR91]. Many also include a default TLB miss handler (in hardware or software) that can load superpage mappings in the TLB.
Reference: [Eykh92] <author> J. R. Eykholt, S. R. Kleiman, S. Barton, R. Faulkner, A. Shivalingiah, M. Smith, D. Stein, J. Voll, M. Weeks, and D. Williams. </author> <title> Beyond Multiprocessing: Multithreading the SunOS Kernel. </title> <booktitle> In Proc. of the Summer USENIX Conference, </booktitle> <pages> pages 1118, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Most code and data str uctures assume a constant PAGESIZE. Many internal and external interfaces assume a single fixed page size as an implicit parameter ( e.g., vnode interface [Klei86]). A multiprocessor multi-threaded operating system <ref> [Camp91, Eykh92, Khal94] </ref> has to synchr onize concurr ent operations and using superpages r equires a r edesign of the synchronization protocols. Some file systems assume that the page size is smaller than the file block size, and so on. <p> It has two drawbacks. First, it does not allow use of superpages to make page tables smaller . Second, the r eplicated PTEs make adding a superpage PTE or atomic PTE update more complex, especially in multi-threaded, multiprocessor operating systems <ref> [Eykh92, Clar95, May94] </ref>. Multiple Page Tables. This solution creates separate page tables for each page size in use. On a TLB miss, the handler accesses and sear ches the page tables in some pr edetermined order. <p> I also show thr ee ways to structure a synonym table such that superpage and partialsubblock PTEs require a single alias pointer, saving memory but complicating the synonym table management. 7.5.3 Concurrent access to a page table In a multi-thr eaded, multiprocessor operating system ( e.g., <ref> [Eykh92] </ref>) it is important that the page table and synonym table support concurr ent accesses in parallel. The operating system uses a locking pr otocol to synchronize concurrent accesses (e.g., [Bala92, May94]) and has a significant impact on performance [Khal94].
Reference: [Fabr74] <author> R. Fabry. </author> <title> Capability-based addressing. </title> <journal> Communications of the ACM, </journal> <volume> 17(7):403412, </volume> <month> July </month> <year> 1974. </year>
Reference-contexts: If segmentation is visible to the hardware, base page protection and attributes may be enhanced thr ough support for segment protections, pr otection lookaside buf fers [Kold92], page-gr oups [Wilk92], or capabilities 9 <ref> [Fabr74] </ref>. Various researchers have studied TLB design and extensions to impr ove TLB performance that may complement use of superpages or subblocking. I list some literatur e relating to TLBs that may be useful for futur e reference.
Reference: [Fagi79] <author> R. Fagin, J. Nievergelt, N. Pippenger, and H. R. </author> <title> Strong. Extendible Hashing A Fast Access Method for Dynamic Files. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 4(3), </volume> <month> September </month> <year> 1979. </year> <note> Also published as IBM Research Report RJ2305, </note> <month> July </month> <year> 1978. </year> <month> 179 </month>
Reference-contexts: The operating system uses a locking pr otocol to synchronize concurrent accesses (e.g., [Bala92, May94]) and has a significant impact on performance [Khal94]. Some results in the study of concurrent access to database index data str uctures may be applicable to page tables <ref> [Come79, Baye77, Litw93, Elli87, Fagi79, Hsu86, Kuma90, Gutt84] </ref>. A page table synchr onization protocol has to addr ess at least three issues. First, both the page table and the synonym table must be updated atomically (e.g., with two-phase locking).
Reference: [Fran74] <author> Mark A. Franklin, G. Scott Graham, and R. K. Gupta. </author> <title> Anomalies with Variable Partition Paging Algorithms. </title> <journal> Communications of the ACM, </journal> <volume> 21(3):232236, </volume> <month> March </month> <year> 1974. </year>
Reference-contexts: Further, simpler versions of the algorithms used in segmented operating systems may be applicable in superpage operating systems, e.g., memory allocation [Knut68a], segmentsize assignment [Redd75], and variablesized segment and page r eplace-ment <ref> [Prie76, Fran74, T urn81] </ref>. Smith compiled a bibliography of early virtual memory r e-search that includes r esearch on segmented systems [Smit78c].
Reference: [Gels89] <author> P. P. Gelsinger, P. A. Gargini, G. H. Parker, and A. Y. C. Yu. </author> <title> Microprocessors circa 2000. </title> <journal> IEEE Spectrum, </journal> <volume> 26(10):4347, </volume> <month> October </month> <year> 1989. </year>
Reference-contexts: First, access time constraints limit TLB designers fr om using the lar ger number of transistors and chip ar ea available today <ref> [Gels89] </ref> to incr ease the number of TLB blocks. Lar ger TLBs ar e slower to access and af fect cycle time. TLB access time is an important metric as TLBs are often in the cache-access critical path.
Reference: [Ging87a] <author> Robert A. Gingell, Meng Lee, Xuong T. Dang, and Mary S. Weeks. </author> <title> Shared Libraries in SunOS. </title> <booktitle> In Proc. of the Summer USENIX Conference, </booktitle> <pages> pages 8194, </pages> <address> Phoenix, </address> <month> Summer </month> <year> 1987. </year>
Reference-contexts: Operating systems using a private addr ess space model must support mappings for 93 shared objects, e.g., shared libraries <ref> [Ging87a] </ref>. When two dif ferent virtual pages map to a physical page, the two virtual pages ar e known as synonyms (or aliases). An operating system data structure, which I call the synonym table, keeps track of these aliases.
Reference: [Ging87b] <author> Robert A. Gingell, Joseph P. Moran, and William A. Shannon. </author> <title> Virtual Memory Architecture in SunOS. </title> <booktitle> In Proc. of the Summer USENIX Conference, </booktitle> <pages> pages 131146, </pages> <address> Phoenix, </address> <month> Summer </month> <year> 1987. </year>
Reference-contexts: Operating system support for virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX <ref> [Thom74, Bach86, Leff90, Ging87b] </ref>, VMS [Levy82], NT [Cust93], MACH [Acce86, Rash88], OS/2 [Koga88]).
Reference: [Glas65] <author> E. L. Glaser, J. F. Couleur, and G. A. Oliver. </author> <title> System Design of a computer for time sharing applications. </title> <booktitle> In Proc. of AFIPS, </booktitle> <volume> volume 27, </volume> <pages> pages 197202, </pages> <year> 1965. </year>
Reference-contexts: In a paged-segmentation model, pr ograms generate a &lt;segment identifier, segment of fset&gt; tuple that f irst translates to a global ef fective virtual addr ess befor e translating to a physical addr ess [Knig81, Dall92]. Examples include Honeywell 645 <ref> [Glas65] </ref>, SPUR, [Hill86], HP-P A RISC [Lee89b], IBM RS/6000 [Chan90], and PowerPC [May94]. TLBs and page tables translate the virtual addr ess to physical addr ess, and superpages or sub-blocking ar e equally applicable as described in this thesis.
Reference: [Good83] <author> James R. Goodman. </author> <title> Using Cache Memory to Reduce Processor-Memory Traffic. </title> <booktitle> In Proc. of the Tenth Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 124131, </pages> <address> Stockholm Sweden, </address> <month> June </month> <year> 1983. </year>
Reference-contexts: In particular, my thesis applies to TLBs and page tables thr ee techniques borr owed fr om cache designvariable block size [Dubn92], subblocking <ref> [Lipt68, Bell74, Good83, Hill84] </ref>, and subblock pr efetching [Smit78b, Hill87]. Superpage TLBs implement a variable block size design with the policy decisions on when to use superpages made by the operating system. <p> If the program has bad localityi.e., references only a small fraction of the pages within a page blockthe TLB performance is worse. This is the tradeoff in using subblock TLBs or caches. 1. Subblocking [Hill84] has also been called sectoring [Lipt68] and address/transfer blocks <ref> [Good83] </ref>. 2. This chapter concentrates on subblock TLBs as an alternative to medium-sized superpages. Appendix E illustrates how subblock TLBs support large superpages. 41 from a virtual address space to a physical address space. A completesubblock TLBs fields are as shown in the TLB block format in Figur e 4-1.
Reference: [Gutt84] <author> A. Guttman. R-Trees: </author> <title> A Dynamic Index Structure for Spatial Searching. </title> <booktitle> In Proceedings of ACM SIGMOD Conference, </booktitle> <pages> page 47, </pages> <address> Boston, MA, </address> <month> June </month> <year> 1984. </year> <note> Reprinted in M. </note> <author> Stonebraker, </author> <title> Readings in Database Systems, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: The operating system uses a locking pr otocol to synchronize concurrent accesses (e.g., [Bala92, May94]) and has a significant impact on performance [Khal94]. Some results in the study of concurrent access to database index data str uctures may be applicable to page tables <ref> [Come79, Baye77, Litw93, Elli87, Fagi79, Hsu86, Kuma90, Gutt84] </ref>. A page table synchr onization protocol has to addr ess at least three issues. First, both the page table and the synonym table must be updated atomically (e.g., with two-phase locking).
Reference: [Hart92] <author> Kieran Harty and David R. Cheriton. </author> <title> Application-Controlled Physical Memory using Extern Page-Cache Management. </title> <booktitle> In Proc. of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 187197, </pages> <address> Boston MA Boston MA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: This allows implementation of custom user defined pagesize assignment policies that exploit pr ograms knowledge of their access pattern. Some operating systems have similarly exported mechanisms such as page r eplacement <ref> [Youn89, Hart92] </ref>, scheduling [Ande92], and cache coher ence [Rein94]. In summary, operating systems have a choice of a variety of page-assignment policies and different workloads may pr efer dif ferent policies. The key to operating system design is to identify and implement the mechanisms that can support many alternate policies.
Reference: [Henn90] <author> John L Hennessy and David A Patterson. </author> <title> Computer Architecture A Quantitative Approach. </title> <publisher> Mor-gan Kaufmann Publishers Inc., </publisher> <year> 1990. </year>
Reference-contexts: One longstanding computer tr end is that pr ograms memory usage doubles each year or two <ref> [Henn90] </ref>. To support the lar ger program working set sizes [Denn68], workstations with more than 100MB of physical memory ar e becoming common. This places pr essure on the TLB to map an incr easingly larger amount of memory . <p> On the other hand, cache line size is an implementation parameter mor e easily changed. TLB miss penalty is also incr easing due to many r easons. First, as pr ocessors become faster relative to main memory accesses <ref> [Henn90] </ref>, page table traversalthe main component of TLB miss penaltybecomes r elatively slower. Second, page table size has been incr easing due to lar ger addr ess spaces and lar ger page table entry (PTE) size, e.g., four bytes to eight bytes.
Reference: [Hewl93] <author> Hewlett Packard. </author> <title> Hewlett-Packards 7100: A High-speed Superscalar PA-RISC Processor, </title> <note> 1993. White paper. </note>
Reference-contexts: This allows the operating system to use lar ge superpages for special cases such as kernel text, database buf fer caches, and frame buf fers. Examples of this category include HP-PA RISC <ref> [Hewl93, Hunt95] </ref>, Motor ola 88x00 [Mile90], Intel i860XP [Inte91], and PowerPC [Silh93, May94]. Such a superpage TLB is also known as a Block TLB or a Block Address Translation Cache (BATC).
Reference: [Hill84] <author> Mark D. Hill and Alan Jay Smith. </author> <title> Experimental Evaluation of On-Chip Microprocessor Cache Memories. </title> <booktitle> In Proc. of the 11th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 158166, </pages> <address> Ann Arbor MI, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: In particular, my thesis applies to TLBs and page tables thr ee techniques borr owed fr om cache designvariable block size [Dubn92], subblocking <ref> [Lipt68, Bell74, Good83, Hill84] </ref>, and subblock pr efetching [Smit78b, Hill87]. Superpage TLBs implement a variable block size design with the policy decisions on when to use superpages made by the operating system. <p> If the program has bad localityi.e., references only a small fraction of the pages within a page blockthe TLB performance is worse. This is the tradeoff in using subblock TLBs or caches. 1. Subblocking <ref> [Hill84] </ref> has also been called sectoring [Lipt68] and address/transfer blocks [Good83]. 2. This chapter concentrates on subblock TLBs as an alternative to medium-sized superpages. Appendix E illustrates how subblock TLBs support large superpages. 41 from a virtual address space to a physical address space.
Reference: [Hill86] <author> Mark D. Hill, Susan J. Eggers, James R. Larus, George S. Taylor, G. Adams, B. K. Bose, Garth A. Gibson, P. M. Hansen, J. Keller, Shing I. Kong, C. G. Lee, D. Lee, J. M. Pendleton, S. A. Ritchie, David A. Wood, B. G. Zorn, P. N. Hilfinger, D. Hodges, Randy H. Katz, John Ousterhout, and David A. Patterson. </author> <title> Design Decisions in SPUR. </title> <journal> IEEE Computer, </journal> <volume> 19(11):822, </volume> <month> November </month> <year> 1986. </year>
Reference-contexts: In a paged-segmentation model, pr ograms generate a &lt;segment identifier, segment of fset&gt; tuple that f irst translates to a global ef fective virtual addr ess befor e translating to a physical addr ess [Knig81, Dall92]. Examples include Honeywell 645 [Glas65], SPUR, <ref> [Hill86] </ref>, HP-P A RISC [Lee89b], IBM RS/6000 [Chan90], and PowerPC [May94]. TLBs and page tables translate the virtual addr ess to physical addr ess, and superpages or sub-blocking ar e equally applicable as described in this thesis. <p> Subblock TLBs can result in a better overall execution time. Subblock caches allow a portion of a cache line to be accessed befor e completely fetching the full cache line fr om memory <ref> [Hill86, Hill87] </ref>. Instr uction caches use this featur e to r educe hit time, often combined with a fetch policy that brings the r eferenced wor d first fr om memory.
Reference: [Hill87] <author> Mark D. Hill. </author> <title> Aspects of Cache Memory and Instruction Buffer Performance. </title> <type> Ph.D. thesis, </type> <institution> University of California, Berkeley, </institution> <month> November </month> <year> 1987. </year>
Reference-contexts: In particular, my thesis applies to TLBs and page tables thr ee techniques borr owed fr om cache designvariable block size [Dubn92], subblocking [Lipt68, Bell74, Good83, Hill84], and subblock pr efetching <ref> [Smit78b, Hill87] </ref>. Superpage TLBs implement a variable block size design with the policy decisions on when to use superpages made by the operating system. A subblock-cache associates with each addr ess tag several data subblocks that each have their own valid bits so that they can be loaded independently . <p> Subblock TLBs can result in a better overall execution time. Subblock caches allow a portion of a cache line to be accessed befor e completely fetching the full cache line fr om memory <ref> [Hill86, Hill87] </ref>. Instr uction caches use this featur e to r educe hit time, often combined with a fetch policy that brings the r eferenced wor d first fr om memory. <p> Subblock misses can be eliminated, however , if each block miss pr eloads all mappings associated with its tag, as the MIPS R4000 does for two PTEs [Kane92]. Subblock pr eloading never pollutes a TLB by replacing more useful mappings, because it never causes extra replacements <ref> [Hill87] </ref>, but reduces the number of TLB misses significantly (Chapter 4). A drawback of subblock preloading is the increased time to service TLB block misses. This penalty is large for hashed page tables, as it requires multiple hash probes.
Reference: [Hill88] <author> Mark D. Hill. </author> <title> A Case for Direct-Mapped Caches. </title> <journal> IEEE Computer, </journal> <volume> 21(12):2540, </volume> <month> December </month> <year> 1988. </year> <note> Also available as Computer Sciences Technical Report #778, </note> <institution> Univ. of Wisconsin, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: VPN Tag Offset VA VPNIndex 14 As in a fully-associative TLB, the valid bits can be part of the associative compar e or can combine with the comparator output as part of the multiplexor driver logic (Appendix A). Direct-mapped TLBs do not r equire the multiplexors <ref> [Hill88] </ref> and the data can be used befor e the tag array access is complete. If tag comparison fails subsequently , the processor can undo the instr uction (s) and cause a pr ecise interr upt [Smit88, W ang93]. Figur e 1-5 shows column multiplexors associated with the RAMs.
Reference: [Hill89] <author> Mark D. Hill and Alan Jay Smith. </author> <title> Evaluating Associativity in CPU Caches. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-38(12):16121630, </volume> <month> December </month> <year> 1989. </year>
Reference-contexts: Second, trap-driven simulation r equires separate runs for simulating multiple TLBs. It is possible to use techniques for simultaneous simulation of multiple TLBs <ref> [Matt70, Hill89, Kim91] </ref> in trap-driven simulators for TLBs that satisfy the inclusion property [Matt70]. Foxtr ot does not implement these techniques and I use separate runs for each TLB simulation. The operating system intr oduces variation in physical memory allocation between multiple r uns of a workload.
Reference: [Hirs73] <author> Daniel S. Hirschberg. </author> <title> A Class of dynamic Memory Allocation Algorithms. </title> <journal> Communications of the ACM, </journal> <volume> 16(10):615618, </volume> <month> October </month> <year> 1973. </year>
Reference-contexts: Variablesized freelist management has been studied in the context of segments and memory allocators <ref> [Know65, Hirs73, Barr93] </ref>. The pr oblem is simpler her e than general memory allocators as systems support only a few superpage sizes that ar e powers of two.
Reference: [Houd68] <author> M. E. Houdek and G. R. Mitchell. </author> <title> Translating a large virtual address. IBM System/38 Tech. </title> <booktitle> Developments, </booktitle> <pages> pages 2224, </pages> <year> 1968. </year>
Reference-contexts: Many forwar d-mapped page table implementations and guar ded page tables [Lied95] support certain superpage sizes at their intermediate nodes. Hashed page tables ar e being increasingly used to support sparse 64-bit addr ess <ref> [Houd68, Abra81, Thak86, Rose92, Huck93, May94] </ref> but none support superpage mappings.
Reference: [Hsu86] <author> M-C. Hsu and M-P. Yang. </author> <title> Concurrent Operations in Extendible Hashing. </title> <booktitle> In Proceedings of the 12th Conference on Very Large Databases, </booktitle> <month> August </month> <year> 1986. </year> <month> 180 </month>
Reference-contexts: The operating system uses a locking pr otocol to synchronize concurrent accesses (e.g., [Bala92, May94]) and has a significant impact on performance [Khal94]. Some results in the study of concurrent access to database index data str uctures may be applicable to page tables <ref> [Come79, Baye77, Litw93, Elli87, Fagi79, Hsu86, Kuma90, Gutt84] </ref>. A page table synchr onization protocol has to addr ess at least three issues. First, both the page table and the synonym table must be updated atomically (e.g., with two-phase locking).
Reference: [Huck93] <author> Jerry Huck and Jim Hays. </author> <title> Architectural Support for Translation Table Management in Large Address Space Machines. </title> <booktitle> In Proc. of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 3950, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Memory system designers ar e addr essing the incr easing TLB miss penalty with mor e levels in the addr ess translation hierar chy by using a second-level software TLB , e.g., swTLB <ref> [Huck93] </ref>, TSB [Yung94], STLB [Bala94]. My thesis looks at incr easing TLB r each through use of variable block size and subblock-ing techniques to map mor e addr ess space per TLB block. <p> Many forwar d-mapped page table implementations and guar ded page tables [Lied95] support certain superpage sizes at their intermediate nodes. Hashed page tables ar e being increasingly used to support sparse 64-bit addr ess <ref> [Houd68, Abra81, Thak86, Rose92, Huck93, May94] </ref> but none support superpage mappings. <p> A paper titled Virtual Memory Support for Multiple Page Sizes by Khalidi et al. [Khal93b] explains the importance of operating system support for superpage TLBs and lists the issues 6. For lack of a standard page table terminology in literature, I use the same terminology as Huck and Hays <ref> [Huck93] </ref> 11 that need to be addr essed in operating system implementation or design to support super-page TLBs. Chapter 6 identifies the mechanisms and policies that need to be implemented in an operating system to support superpage or partialsubblock TLBs. <p> Foxtrot, my operating system pr ototype, implements a functional set of policies and mechanisms to support two page sizes and partial subblocking. 92 Chapter 7 Page Table Structures 7.1 Introduction A page table stores translation, pr otection, attribute, and status information for virtual addresses <ref> [Huck93, Chan88, Levy82, Silh93, Lee89b] </ref>. A page table entry (PTE) stores the information for one page. The TLB miss handler accesses the page table on a TLB miss to load the appropriate PTE into the TLB. <p> Section 7.7 reiterates the contributions. 7.2 Conventional Page Tables for 64-bit Address Spaces This section reviews commonly-used page tableslinear, forward-mapped, and hashed and discusses extending them to support 64-bit virtual addr esses. A detailed description can be found in Huck and Hays <ref> [Huck93] </ref>. For all page table designs, 64-bit addr ess mapping information will r equire eight bytes, e.g., PowerPC [May94], Alpha [Site92], UltraSP ARC [Yung95]. <p> Guarded page tables [Lied95] are sometimes effective but would still require three to four levels. An intermediate node cache can accelerate page table access, e.g., PTP cache in SuperSPARC [Blan92], Region Lookaside buffer in HaL [Chan95]. Large addr ess space systems often use hashed (inverted) page tables <ref> [Lee89b, Chan88, Huck93, May94] </ref> as they use memory pr oportional to the number of active virtual pages 1 . A simple implementation uses an open hash table and a hash function that maps a VPN to a bucket, e.g., . <p> One optimization is to pack both into eight bytes by using a shorter next pointer and not storing tag bits that can be inferr ed from indexing the table <ref> [Huck93] </ref>. This optimization restricts page table placement and can slow software TLB miss handling. I do not consider it further, because clustered page tablesproposed in Section 7.3 offer more effective ways to reduce overhead. Two variations of hashed page tables include inverted page tables and softwar e TLBs. <p> Inverted page tables, e.g., in IBM System/38 [IBM78], hash to an array of pointers that when deref-erenced obtain the first element of the hash bucket (Figur e 7-4). The extra level of indir ection slows TLB miss handling as it often r esults in one additional cache miss <ref> [Huck93] </ref>. Ther e are two advantages of the indir ection [Rama81]. Inverted page tables usually use the physical page descriptors as the hash nodes. <p> Also, page table access time improves by dynamically moving the most r ecently accessed element to the head of the hash bucket list <ref> [Rama81, Huck93] </ref>. An inverted page table easily incorporates this optimization by maintaining the hash buckets as circular lists and updating the head pointer after every page table lookup. <p> An inverted page table easily incorporates this optimization by maintaining the hash buckets as circular lists and updating the head pointer after every page table lookup. Software TLBs (e.g., swTLB <ref> [Huck93] </ref>, TSB [Y ung94], STLB [Bala94], PowerPCs page table [May94]) eliminate a hashed page tables next pointers by pre-allocating few PTEs per bucket. be viewed as memory-r esident level-two TLBs with overf low handled in many ways, e.g., hash-rehash schemes [Agar88, Thak86] or set r eplacement [May94]. <p> They may r eside between the TLB and a native page table to r educe average access time for a slow native page table, e.g., a forward-mapped page table <ref> [Huck93, Bala94, Yung95] </ref>. The extensions I develop for hashed page table, described next, are applicable to inverted page tables and softwar e TLBs also, as I show in Section 7.4.7.
Reference: [Hunt95] <author> Doug Hunt. </author> <title> Advanced Performance Features of the 64-bit PA-8000. </title> <booktitle> Compcon Digest of Papers, </booktitle> <pages> pages 123115, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Superpages have sizes that ar e power of-two multiples of the base page size and must be aligned in both virtual and physical memory (Chapter 3). Many pr ocessors now support su-perpages, e.g., MIPS [Kane92], UltraSPARC [Yung95], Alpha [Bann95], PowerPC [Silh93], HP-PA RISC <ref> [Hunt95] </ref>. A fully-associative TLB can easily include support for superpages. An example is the MIPS R4000, which supports a 4KB base page size and superpages of 16KB, 64KB, 256KB, 1MB, 4MB, and 16MB with a fully-associative TLB. <p> A key motivation for my thesis was the intr oduction of superpage support in many microprocessor TLBs, e.g., MIPS [Kane92], UltraSP ARC [Yung95], Alpha [Bann95], PowerPC [Silh93], HP-PA RISC <ref> [Hunt95] </ref>. Commer cial operating systems I am awar e of, however , do not support general use of superpage mappings. Many operating systems include special mechanisms to use lar ge superpages for unpageable memory and devices. <p> Thus, the key to using superpage TLBs is an operating system that uses superpages wher e appropriate and base pages elsewhere. Nearly every current microprocessor supports superpages, e.g., MIPS [Kane92], UltraS-PARC [Yung95], Alpha [Bann95], PowerPC [Silh93], HP-P A RISC <ref> [Hunt95] </ref>. The MIPS R4000 [Kane92], for example, supports a 4KB base page size and superpages of 16KB, 64KB, 256KB, 1MB, 4MB, and 16MB. However, I am not aware of any operating system that uses superpages in a general manner. I discuss the operating system issues in Chapter 6. <p> This allows the operating system to use lar ge superpages for special cases such as kernel text, database buf fer caches, and frame buf fers. Examples of this category include HP-PA RISC <ref> [Hewl93, Hunt95] </ref>, Motor ola 88x00 [Mile90], Intel i860XP [Inte91], and PowerPC [Silh93, May94]. Such a superpage TLB is also known as a Block TLB or a Block Address Translation Cache (BATC).
Reference: [IBM78] <institution> IBM System/38 technical developments. IBM, </institution> <year> 1978. </year> <title> Order no G580-0237. </title>
Reference-contexts: I use workingset based pagesize assignment (described in Section 6.1) in my work [T all92, Tall94a]. Three styles of page tables ar e popular 6 linear ( e.g., VAX [Levy82]), forwar d-mapped (e.g., SPARC [SPAR91]), and hashed/inverted ( e.g., PowerPC [May94], IBM System/38 <ref> [IBM78] </ref>). Many forwar d-mapped page table implementations and guar ded page tables [Lied95] support certain superpage sizes at their intermediate nodes. Hashed page tables ar e being increasingly used to support sparse 64-bit addr ess [Houd68, Abra81, Thak86, Rose92, Huck93, May94] but none support superpage mappings. <p> I do not consider it further, because clustered page tablesproposed in Section 7.3 offer more effective ways to reduce overhead. Two variations of hashed page tables include inverted page tables and softwar e TLBs. Inverted page tables, e.g., in IBM System/38 <ref> [IBM78] </ref>, hash to an array of pointers that when deref-erenced obtain the first element of the hash bucket (Figur e 7-4). The extra level of indir ection slows TLB miss handling as it often r esults in one additional cache miss [Huck93].
Reference: [Inte91] <author> Intel Corporation. </author> <title> i860 Microprocessor Family Programmers Reference Manual, </title> <year> 1991. </year>
Reference-contexts: This allows the operating system to use lar ge superpages for special cases such as kernel text, database buf fer caches, and frame buf fers. Examples of this category include HP-PA RISC [Hewl93, Hunt95], Motor ola 88x00 [Mile90], Intel i860XP <ref> [Inte91] </ref>, and PowerPC [Silh93, May94]. Such a superpage TLB is also known as a Block TLB or a Block Address Translation Cache (BATC). Most implementations of separate superpage TLBs require special TLB miss handling for superpages as the default TLB miss handler does not handle superpage mappings.
Reference: [John61] <author> L. R. Johnson. </author> <title> Indirect chaining method for addressing on secondary keys. </title> <journal> Communications of the ACM, </journal> <pages> pages 218222, </pages> <month> May </month> <year> 1961. </year>
Reference-contexts: This results in shorter hash table lists, a hash table with fewer buckets, or both. Shorter hash table lists r educe hash table sear ch time on TLB misses <ref> [Knut68b, Morr68, John61] </ref>. Third, clustered page tables amortize the overhead of allocating memory for a PTE and inserting in the hash list over multiple PTE insertions. Hashed page tables incur a fixed overhead of memory allocation, list insertion and tag initialization for each PTE added to the page table.
Reference: [John87] <author> Mike Johnson. </author> <title> System Consideration in the Design of the Am29000. </title> <journal> IEEE Micro, </journal> <volume> 7(4):2841, </volume> <month> August </month> <year> 1987. </year>
Reference-contexts: This incr eases cache pollution and r educes the likelihood of completing page table traversal within the CPU caches. Thir d, many pr ocessors support TLB miss handling in software, e.g., ZS-1 [Smit87], AMD29000 <ref> [John87] </ref>, MIPS [Kane92], Alpha [Site93], UltraSP ARC [Yung95], PA7100 [Aspr93], that incurs higher over head than har dware state machines. <p> select between 4KB and 8KB page size [Eden90], Motor ola 68020 using MC68851 contr oller can select a page size fr om 256 bytes to 2KB [Moto86], the SGI R8000 pr ocessor allows two page sizesone for instr uctions and another for datathat ar e selectable per process [MIPS93], AMD29000 <ref> [John87] </ref> supports a per-process pagesize. 31 Many single-page-size operating systems use a configurable systemwide P AGESIZE constant. Solaris, for example, uses 8KB pages on V7 or V9 machines and 4KB pages for V8 machines; IRIX uses 4KB pages for R4X00 machines and 16KB pages for R6000 machines.
Reference: [Joup89] <author> Norman P. Jouppi and David W. Wall. </author> <title> Available Instruction-Level Parallelism for Superscalar and Superpipelined Machines. </title> <booktitle> In Proc. of the Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Boston, </address> <month> April </month> <year> 1989. </year>
Reference-contexts: Cache consistency management by the operating system has complicated ef forts to remove the TLB fr om the critical path using virtually-tagged caches [Whee92]. Physically-tagged caches continue to be common. Second, the tr end toward wider superscalar pr ocessor implementations <ref> [Joup89] </ref> r equires TLBs to support multiple translations per cycle thr ough multi-porting or r eplication. TLBs that support multiple transactions per cycle are slower to access and occupy lar ger chip area.
Reference: [Joup94] <author> Norman P. Jouppi and Steven J. E. Wilson. </author> <title> Tradeoffs in Two-Level On-Chip Caching. </title> <booktitle> In Proc. of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 3445, </pages> <month> April </month> <year> 1994. </year> <note> (Also as) WRL Research Report 93/3. </note>
Reference-contexts: However , most microprocessor designs include a TLB on-chip and chip ar ea constraints limit the design options available to processor designers <ref> [Joup94, Nagl94a] </ref>. In later chapters, I show the ef fec-tiveness of the new TLB ar chitectures by comparing execution time speedups for dif ferent TLBs that occupy comparable chip ar ea.
Reference: [Kagi91] <author> Toyohiko Kagimasa, Kikuo Takahashi, and Toshiaki Mori. </author> <title> Adaptive Storage Management for Very Large Virtual/Real Storage Systems. </title> <booktitle> In Proc. of the 18th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 372379, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: The dif ferent algorithms differ in the rate at which memory gets fragmented but all eventually r equire some form of addr ess space compaction. Another solution is to permanently partition physical memory into pools for each page size <ref> [Kagi91] </ref>. This is a feasible option in systems that use static pagesize assignment but may incr ease page fault rate if the system does not use the different page sizes in anticipated pr oportions.
Reference: [Kane89] <author> Gerry Kane. </author> <title> MIPS RISC Architecture. </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: This segmentation can be either invisible to har dware using a linear addr ess space model, e.g., VAX [Leon82] and MIPS <ref> [Kane89] </ref>, or visible to har dware using a paged-segmentation model. In a paged-segmentation model, pr ograms generate a &lt;segment identifier, segment of fset&gt; tuple that f irst translates to a global ef fective virtual addr ess befor e translating to a physical addr ess [Knig81, Dall92]. <p> Pseudo-LRU algorithms, that approximate LRU with limited information [Kess89, So88, Devi92], ar e often used. Policies that do not use reference information, e.g., RANDOM <ref> [Kane89] </ref>, are cheaper to implement but incur more TLB misses. Section 2.6 describes the pseudo-LRU r eplacement policy I use in my TLB simulations. Finally, the new translation dir ectly overwrites the victim TLB block by writing into the tag and data arrays. <p> For illustration, I consider thr ee alternate TLB r eplacement policies. Clock [East79] implements a second-chance r eplacement algorithm often used in operating system page r e-placement, with the additional optimization that invalid TLB blocks ar e replaced first. Random <ref> [Kane89] </ref> replaces an arbitrary TLB block that may or may not be valid. FIFO implements a straightforward first-in-first-out algorithm. Table 2-5 shows the sensitivity to r eplacement policy for a 64-block fully-associative single-page-size TLB.
Reference: [Kane92] <author> Gerry Kane and Joe Heinrich. </author> <title> MIPS RISC Architecture. </title> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: This incr eases cache pollution and r educes the likelihood of completing page table traversal within the CPU caches. Thir d, many pr ocessors support TLB miss handling in software, e.g., ZS-1 [Smit87], AMD29000 [John87], MIPS <ref> [Kane92] </ref>, Alpha [Site93], UltraSP ARC [Yung95], PA7100 [Aspr93], that incurs higher over head than har dware state machines. <p> Superpages have sizes that ar e power of-two multiples of the base page size and must be aligned in both virtual and physical memory (Chapter 3). Many pr ocessors now support su-perpages, e.g., MIPS <ref> [Kane92] </ref>, UltraSPARC [Yung95], Alpha [Bann95], PowerPC [Silh93], HP-PA RISC [Hunt95]. A fully-associative TLB can easily include support for superpages. An example is the MIPS R4000, which supports a 4KB base page size and superpages of 16KB, 64KB, 256KB, 1MB, 4MB, and 16MB with a fully-associative TLB. <p> The partialsubblock design optimizes a subblock design using specific knowledge about the str ucture and content of the data stor ed in a TLB. A key motivation for my thesis was the intr oduction of superpage support in many microprocessor TLBs, e.g., MIPS <ref> [Kane92] </ref>, UltraSP ARC [Yung95], Alpha [Bann95], PowerPC [Silh93], HP-PA RISC [Hunt95]. Commer cial operating systems I am awar e of, however , do not support general use of superpage mappings. Many operating systems include special mechanisms to use lar ge superpages for unpageable memory and devices. <p> The traversal can be done by har dware, e.g., SPARC Reference MMU [SPAR91], some PowerPC implementations [May94, Levi95, Beck93], or by softwar e, e.g., MIPS R4x00 <ref> [Kane92] </ref>, UltraSP ARC [Yung95], Alpha [Site92]. W ith softwar e TLB miss handling, there is typically some har dware assist to speed up page table traversal. Some pr o-cessors generate specialized TLB exceptions and har dware generated page table hint pointers as in MIPS R4x00 [Kane92], UltraSP ARC [Yung95], and PowerPC <p> softwar e, e.g., MIPS R4x00 <ref> [Kane92] </ref>, UltraSP ARC [Yung95], Alpha [Site92]. W ith softwar e TLB miss handling, there is typically some har dware assist to speed up page table traversal. Some pr o-cessors generate specialized TLB exceptions and har dware generated page table hint pointers as in MIPS R4x00 [Kane92], UltraSP ARC [Yung95], and PowerPC [Ogde95]. Further , software TLB miss handlers incur trap entry/exit costs not shown her e. Chapter 7 describes popular page table data str uctures and their access times. <p> Superpages decr ease the number of TLB misses but increase memory demand 1 due to internal fragmentation. Thus, the key to using superpage TLBs is an operating system that uses superpages wher e appropriate and base pages elsewhere. Nearly every current microprocessor supports superpages, e.g., MIPS <ref> [Kane92] </ref>, UltraS-PARC [Yung95], Alpha [Bann95], PowerPC [Silh93], HP-P A RISC [Hunt95]. The MIPS R4000 [Kane92], for example, supports a 4KB base page size and superpages of 16KB, 64KB, 256KB, 1MB, 4MB, and 16MB. However, I am not aware of any operating system that uses superpages in a general manner. <p> Thus, the key to using superpage TLBs is an operating system that uses superpages wher e appropriate and base pages elsewhere. Nearly every current microprocessor supports superpages, e.g., MIPS <ref> [Kane92] </ref>, UltraS-PARC [Yung95], Alpha [Bann95], PowerPC [Silh93], HP-P A RISC [Hunt95]. The MIPS R4000 [Kane92], for example, supports a 4KB base page size and superpages of 16KB, 64KB, 256KB, 1MB, 4MB, and 16MB. However, I am not aware of any operating system that uses superpages in a general manner. I discuss the operating system issues in Chapter 6. <p> These TLBs ar e usually fully-associative due to the dif ficulty of building set-associative TLBs that support multiple page sizes (Section 3.2.2). For example, MIPS R4x000 supports seven page sizes from 4KB to 16MB <ref> [Kane92] </ref>, UltraSPARC [Yung95] and Alpha [Bann95] support four pages sizes of 8KB, 64KB, 512KB, and 4MB. Others include ET A-10 [ETA 86], ARM6 [Adva93], and SPARC Reference MMU [SPAR91]. Many also include a default TLB miss handler (in hardware or software) that can load superpage mappings in the TLB. <p> When loading a mapping into the TLB, the PTE format can include the MASK field, the TLB miss handler can r ead the MASK from a special register, e.g., MIPS R4000 <ref> [Kane92] </ref>, or har dware can decode the size attribute in the PTE, e.g., UltraSPARC [Yung95]. PID/VPBN Offset TLB Protection Attr PPBN Offset VA Violation Soff. Soff =&gt; Superpage Offset TLB Miss Soff. <p> It explains why both linear and hashed page tables are viable, and why forward-mapped page tables are probably impractical as each TLB miss requires about seven memory references. Many processors now support TLB miss handling in softwar e with some har dware assist, e.g., MIPS <ref> [Kane92] </ref>, Alpha [Site93], Ul-traSPARC [Yung95], PA7100 [Aspr93]. This makes page table design an operating system issue and gives operating system designers mor e exibility than traditional har dware-defined page tables. Section 7.3 introduces the main contribution of this chapter: a clustered page table. <p> The virtual page number (VPN) indexes the array, as shown in Figur e 7-1. Complete linear page tables ar e very large and are only partially populated. Consequently, they reside in virtual address space, using page faults to populate the table dynamically ( e.g., VAX-11 [Levy82], MIPS R4000 <ref> [Kane92] </ref>, Alpha [Site92]). As PTEs ar e allocated a page at a time, space over head is high if an address space usage is sparse. A separate data str ucture stores mappings to the page table itself, e.g., a multilevel tr ee of linear page tables. <p> Subblock misses add a new PPN and attribute information to an existing TLB block, without causing a replacement. Subblock misses can be eliminated, however , if each block miss pr eloads all mappings associated with its tag, as the MIPS R4000 does for two PTEs <ref> [Kane92] </ref>. Subblock pr eloading never pollutes a TLB by replacing more useful mappings, because it never causes extra replacements [Hill87], but reduces the number of TLB misses significantly (Chapter 4). A drawback of subblock preloading is the increased time to service TLB block misses.
Reference: [Karl88] <author> A. Karlin, M. Manasse, L. Rudolph, and D. Sleator. </author> <title> Competitive Snoop Caching. </title> <journal> Algorithmica, </journal> <volume> 3(1):70119, </volume> <year> 1988. </year>
Reference-contexts: A competitive algorithm makes decisions that r esult in performance within a constant factor of an optimal policy and competitive algorithms have been used in other contexts, e.g., <ref> [Karl88, Karl91, Slea85, Cao94] </ref>. Romer et al. r ecently pr oposed a competitive pagesize assignment policy that accounts for the cost of TLB misses and captur es reference patterns by updating counters for every base page and superpage on TLB misses [Rome95].
Reference: [Karl91] <author> A. Karlin, K. Li, M. Manasse, and S. Owicki. </author> <title> Empirical Studies of Competitive Spinning for Shared Memory Multiprocessors. </title> <booktitle> In Proc. of the Thirteenth ACM Symposium on Operating System Principles, </booktitle> <year> 1991. </year>
Reference-contexts: A competitive algorithm makes decisions that r esult in performance within a constant factor of an optimal policy and competitive algorithms have been used in other contexts, e.g., <ref> [Karl88, Karl91, Slea85, Cao94] </ref>. Romer et al. r ecently pr oposed a competitive pagesize assignment policy that accounts for the cost of TLB misses and captur es reference patterns by updating counters for every base page and superpage on TLB misses [Rome95].
Reference: [Kess89] <author> R. E. Kessler and Miron Livny. </author> <title> An Analysis of Distributed Shared Memory Algorithms. </title> <type> Computer Sciences Technical Report #825, </type> <institution> Univ. of Wisconsin, </institution> <month> February </month> <year> 1989. </year>
Reference-contexts: The operating system often consults page table modified bits to ush dirty pages to disk and must instead use TLB probes to get the correct state. 15 true LRU (least r ecently used) replacement policy for lar ge set sizes. Pseudo-LRU algorithms, that approximate LRU with limited information <ref> [Kess89, So88, Devi92] </ref>, ar e often used. Policies that do not use reference information, e.g., RANDOM [Kane89], are cheaper to implement but incur more TLB misses. Section 2.6 describes the pseudo-LRU r eplacement policy I use in my TLB simulations. <p> Rehash schemes: The TLB can first index assuming a base page and on a miss can r epeat the access, next cycle, using the superpage index. Similar schemes have been used to impr ove the performance of set-associative CPU caches <ref> [Agar88, Kess89, Agarwal93] </ref> and page tables [Thak86, May94]. The TLB access takes a variable number of cycles and can complicate pipeline design. If TLB access is in the critical path, increasing the TLB hit time for superpage mappings decreases their usefulness.
Reference: [Kess91] <author> Richard Eugene Kessler. </author> <title> Analysis of Multi-Megabyte Secondary CPU Cache Memories. </title> <type> Computer Sciences Technical Report #1032, </type> <institution> Univ. of Wisconsin, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: Dally shows a scheme that combines the segment and page translation [Dall92]. TLBs have traditionally been a second-or der performance concern, as pr ograms often incur a higher over head in cache miss handling. W ith the use of lar ge multi-megabyte caches <ref> [Kess91] </ref> and innovative uses of virtual addr ess spaces [Appe91a, Blum94], some applications now incur mor e TLB misses than cache misses.
Reference: [Kess92] <author> R. E. Kessler and Mark D. Hill. </author> <title> Page Placement Algorithms for Large Real-Index Caches. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(4):338359, </volume> <month> November </month> <year> 1992. </year>
Reference-contexts: I have not explor ed this interaction or its ef fect on system performance. 6.3.6 Page Coloring Page coloring <ref> [Tayl90, Kess92, Chiu92] </ref> also car efully selects physical pages for virtual addresses but for a dif ferent purpose and in a dif ferent way than page r eservation.
Reference: [Khal93a] <author> Yousef A. Khalidi, Glen R. Anderson, Stephen A. Chessin, Shing Ip Kong, Charles E. Narad, and Madhusudhan Talluri. </author> <title> Virtual Address To Physical Address Translation Cache that Supports Multiple Page Sizes. Patent application filed, Serial No. 08/118,398, Sun Microsystems, </title> <note> Septem-ber 1993. (Accepted March 1995). </note>
Reference-contexts: Chapter 7 is an expanded version of this paper . Solaris 2.5, a commercial operating system, implements clustered page tables as explained by Khalidi et al. [Khal95a] and in patent applications <ref> [T all93, Khal93a] </ref>. <p> This approach maybe attractive for storing superpage PTEs in software TLBs where a superscalar processor can execute a TLB miss handler for two page sizes in comparable time to a single page size TLB miss handler <ref> [Kong92, Yung95, Khal93a] </ref>. There are also some superpage strategies that only work for specific page tables. Linear Intermediate Nodes. Linear page tables that use a multilevel tr ee structure can store superpage PTEs at intermediate tree nodes.
Reference: [Khal93b] <author> Yousef A. Khalidi, Madhusudhan Talluri, Michael N. Nelson, and Dock Williams. </author> <title> Virtual Memory Support for Multiple Page Sizes. </title> <booktitle> In Proc. of the Fourth Workshop on Workstation Operating Systems, </booktitle> <pages> pages 104109, </pages> <address> Napa CA, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: For the workloads used in the paper, superpage TLBs incur fewer TLB misses than partialsubblock TLBs without pr e-loading but mor e TLB misses than partialsubblock TLBs with pr eloading. A paper titled Virtual Memory Support for Multiple Page Sizes by Khalidi et al. <ref> [Khal93b] </ref> explains the importance of operating system support for superpage TLBs and lists the issues 6.
Reference: [Khal94] <author> Yousef A. Khalidi, Vikram P. Joshi, and Dock Williams. </author> <title> A Study of the Structure and Performance of MMU Handling Software. </title> <type> Technical Report TR-94-28, </type> <institution> Sun Microsystems Laboratories, </institution> <year> 1994. </year>
Reference-contexts: Hashed page tables ar e being increasingly used to support sparse 64-bit addr ess [Houd68, Abra81, Thak86, Rose92, Huck93, May94] but none support superpage mappings. Page table management algorithms in a multi-thr eaded multiprocessor operating system <ref> [Bala92, Khal94] </ref> also af fect system performance, however, they execute infr equently compared to TLB misses. 1.4 My Previous Work A paper titled Tradeoffs in Supporting Two Page Sizes by Talluri et al. [Tall92] first addresses the costs and benefits of using lar ge page sizes. <p> Most code and data str uctures assume a constant PAGESIZE. Many internal and external interfaces assume a single fixed page size as an implicit parameter ( e.g., vnode interface [Klei86]). A multiprocessor multi-threaded operating system <ref> [Camp91, Eykh92, Khal94] </ref> has to synchr onize concurr ent operations and using superpages r equires a r edesign of the synchronization protocols. Some file systems assume that the page size is smaller than the file block size, and so on. <p> A clustered PTE amortizes this overhead over multiple base page mappings that belong to the same page block. This is a significant benefit as page table manipulations ar e expensive, especially in multi-threaded operating systems where multiple locks must be acquired <ref> [Khal94] </ref>. Fourth, operations on a virtual addr ess range ar e more efficient. The operating system often updates PTEs for a contiguous range of addr esses, e.g., unmapping an object or changing protections for a segment. <p> The operating system uses a locking pr otocol to synchronize concurrent accesses (e.g., [Bala92, May94]) and has a significant impact on performance <ref> [Khal94] </ref>. Some results in the study of concurrent access to database index data str uctures may be applicable to page tables [Come79, Baye77, Litw93, Elli87, Fagi79, Hsu86, Kuma90, Gutt84]. A page table synchr onization protocol has to addr ess at least three issues.
Reference: [Khal95a] <author> Yousef Khalidi, Vikram Joshi, Madhusudhan Talluri, Adrian Caceras, and Dock Williams. </author> <title> De 181 sign Rationale of the UltraSPARC Hardware Address Translation Layer. </title> <booktitle> In SunSoft Technical Conference, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Chapter 7 is an expanded version of this paper . Solaris 2.5, a commercial operating system, implements clustered page tables as explained by Khalidi et al. <ref> [Khal95a] </ref> and in patent applications [T all93, Khal93a]. <p> Clustered page tables will be included in an upcoming r elease of Solaris, a commer cial operating system fr om Sun Microsystems <ref> [Khal95a] </ref>. Chapters 3, 4, and 5 described use of superpages and subblocking in TLBs. These techniques are very effective at improving TLB performance.
Reference: [Khal95b] <author> Yousef A. Khalidi and Madhusudhan Talluri. </author> <title> Improving the Address Translation Performance of Widely Shared Pages. </title> <type> Technical Report TR-95-38, </type> <institution> Sun Microsystems Laboratories, </institution> <month> February </month> <year> 1995. </year>
Reference-contexts: Solaris 2.5, a commercial operating system, implements clustered page tables as explained by Khalidi et al. [Khal95a] and in patent applications [T all93, Khal93a]. A technical r eport titled Improving the Addr ess Translation Performance of W idely Shar ed Pages by Khalidi and T alluri <ref> [Khal95b, T all94b] </ref> addr esses TLB performance and page table size in the pr esence of large number of aliases for physical pages, e.g., shared libraries.
Reference: [Kim91] <author> Yul H. Kim, Mark D. Hill, and David A. Wood. </author> <title> Implementing Stack Simulation for Highly-Associative Memories. </title> <booktitle> In Proc. ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 212213, </pages> <month> May </month> <year> 1991. </year> <note> Also available as University of Wisconsin-Mad-sion, Computer Sciences Technical Report #997. </note>
Reference-contexts: Second, trap-driven simulation r equires separate runs for simulating multiple TLBs. It is possible to use techniques for simultaneous simulation of multiple TLBs <ref> [Matt70, Hill89, Kim91] </ref> in trap-driven simulators for TLBs that satisfy the inclusion property [Matt70]. Foxtr ot does not implement these techniques and I use separate runs for each TLB simulation. The operating system intr oduces variation in physical memory allocation between multiple r uns of a workload.
Reference: [Klei86] <author> Steve R. Kleiman. Vnodes: </author> <title> An Architecture for Multiple File System Types in Sun UNIX. </title> <booktitle> In Proc. of the Summer USENIX Conference, </booktitle> <address> Atlanta, </address> <month> Summer </month> <year> 1986. </year>
Reference-contexts: First, the operating system has the idea of a single page size ingrained at all levels. Most code and data str uctures assume a constant PAGESIZE. Many internal and external interfaces assume a single fixed page size as an implicit parameter ( e.g., vnode interface <ref> [Klei86] </ref>). A multiprocessor multi-threaded operating system [Camp91, Eykh92, Khal94] has to synchr onize concurr ent operations and using superpages r equires a r edesign of the synchronization protocols. Some file systems assume that the page size is smaller than the file block size, and so on.
Reference: [Knig81] <author> J. Knight and P. </author> <title> Rosenfield. Segmented Virtual to Real Translation Assist. </title> <journal> IBM Technical Disclosure Bulletin, </journal> <volume> 23(11):51865187, </volume> <month> April </month> <year> 1981. </year>
Reference-contexts: In a paged-segmentation model, pr ograms generate a &lt;segment identifier, segment of fset&gt; tuple that f irst translates to a global ef fective virtual addr ess befor e translating to a physical addr ess <ref> [Knig81, Dall92] </ref>. Examples include Honeywell 645 [Glas65], SPUR, [Hill86], HP-P A RISC [Lee89b], IBM RS/6000 [Chan90], and PowerPC [May94]. TLBs and page tables translate the virtual addr ess to physical addr ess, and superpages or sub-blocking ar e equally applicable as described in this thesis.
Reference: [Know65] <author> Kenneth C. Knowlton. </author> <title> A Fast Storage Allocator. </title> <journal> Communications of the ACM, </journal> <volume> 8(10):623625, </volume> <month> October </month> <year> 1965. </year>
Reference-contexts: Variablesized freelist management has been studied in the context of segments and memory allocators <ref> [Know65, Hirs73, Barr93] </ref>. The pr oblem is simpler her e than general memory allocators as systems support only a few superpage sizes that ar e powers of two.
Reference: [Knut68a] <author> Donald E. Knuth. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> Volume 1. </volume> <publisher> Addison Wesley, </publisher> <year> 1968. </year> <note> Second Printing. </note>
Reference-contexts: Supporting superpages is easier than supporting segments because superpages have alignment r estrictions that allow har dware to use bit steering instead of adders that segments r equire. Further, simpler versions of the algorithms used in segmented operating systems may be applicable in superpage operating systems, e.g., memory allocation <ref> [Knut68a] </ref>, segmentsize assignment [Redd75], and variablesized segment and page r eplace-ment [Prie76, Fran74, T urn81]. Smith compiled a bibliography of early virtual memory r e-search that includes r esearch on segmented systems [Smit78c]. <p> By multiprogramming, I mean execution of multiple concurrently active processes. 10 Operating system support for superpages involves implementing some mechanisms (described in Section 6.2), e.g., variablesize memory allocation <ref> [Knut68a] </ref>, and a pagesize assignment policy (described in Section 6.1). Romer et al. [Rome95] study the use of competitive algorithms for pagesize assignment among multiple superpage sizes. I use workingset based pagesize assignment (described in Section 6.1) in my work [T all92, Tall94a]. <p> Variablesized freelist management has been studied in the context of segments and memory allocators [Know65, Hirs73, Barr93]. The pr oblem is simpler her e than general memory allocators as systems support only a few superpage sizes that ar e powers of two. A buddy-block allocator <ref> [Knut68a, Pete77, T ayl81, Purd70, Bark89, Lee89c] </ref> or ganizes free pages into multiple fr eelists, one per supported allocation size and has a policy and a mechanism to coalesce fr ee pages into a fr ee superpage and vice versa.
Reference: [Knut68b] <author> Donald E. Knuth. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> Volume 3. </volume> <publisher> Addison Wesley, </publisher> <year> 1968. </year> <note> Second Printing. </note>
Reference-contexts: This results in shorter hash table lists, a hash table with fewer buckets, or both. Shorter hash table lists r educe hash table sear ch time on TLB misses <ref> [Knut68b, Morr68, John61] </ref>. Third, clustered page tables amortize the overhead of allocating memory for a PTE and inserting in the hash list over multiple PTE insertions. Hashed page tables incur a fixed overhead of memory allocation, list insertion and tag initialization for each PTE added to the page table.
Reference: [Koga88] <author> M. S. Kogan and F. L. Rawson, III. </author> <title> The design of Operating System/2. </title> <journal> IBM Systems Journal, </journal> <volume> 27(2):90104, </volume> <year> 1988. </year>
Reference-contexts: Operating system support for paged virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX [Thom74, Bach86, Lef f90], VMS [Levy82], NT [Cust93], MACH [Acce86, Rash88], OS/2 <ref> [Koga88] </ref>). Most facets of paged virtual memory operating system policies and mechanisms r equire modif ications to support superpages ef fec-tively. A new policy pagesize assignment and upto six new mechanisms may also be required. <p> Operating system support for virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX [Thom74, Bach86, Leff90, Ging87b], VMS [Levy82], NT [Cust93], MACH [Acce86, Rash88], OS/2 <ref> [Koga88] </ref>).
Reference: [Kold92] <author> Eric J. Koldinger, Jeffrey S. Chase, and Susan J. Eggers. </author> <title> Architectural Support for Single Address Space Operating Systems. </title> <booktitle> In Proc. of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 175186, </pages> <address> Boston MA, </address> <month> Octo-ber </month> <year> 1992. </year>
Reference-contexts: If segmentation is visible to the hardware, base page protection and attributes may be enhanced thr ough support for segment protections, pr otection lookaside buf fers <ref> [Kold92] </ref>, page-gr oups [Wilk92], or capabilities 9 [Fabr74]. Various researchers have studied TLB design and extensions to impr ove TLB performance that may complement use of superpages or subblocking. I list some literatur e relating to TLBs that may be useful for futur e reference.
Reference: [Kong92] <author> Shing Kong. </author> <title> Sparc V9 Memory Management Unit Design Rationale. </title> <publisher> Sun Microsystems Inc., </publisher> <month> Oc-tober </month> <year> 1992. </year>
Reference-contexts: This approach maybe attractive for storing superpage PTEs in software TLBs where a superscalar processor can execute a TLB miss handler for two page sizes in comparable time to a single page size TLB miss handler <ref> [Kong92, Yung95, Khal93a] </ref>. There are also some superpage strategies that only work for specific page tables. Linear Intermediate Nodes. Linear page tables that use a multilevel tr ee structure can store superpage PTEs at intermediate tree nodes.
Reference: [Kuma90] <author> Vijay Kumar. </author> <title> Concurrent Operations on Extendible Hashing and its Performance. </title> <journal> Communications of the ACM, ; ACM CR 9012-0959, </journal> <volume> 33(6), </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: The operating system uses a locking pr otocol to synchronize concurrent accesses (e.g., [Bala92, May94]) and has a significant impact on performance [Khal94]. Some results in the study of concurrent access to database index data str uctures may be applicable to page tables <ref> [Come79, Baye77, Litw93, Elli87, Fagi79, Hsu86, Kuma90, Gutt84] </ref>. A page table synchr onization protocol has to addr ess at least three issues. First, both the page table and the synonym table must be updated atomically (e.g., with two-phase locking).
Reference: [Lebe95] <author> Alvin R. Lebeck and David A. Wood. </author> <title> Active Memory: A New Abstraction for Memory-System Simulation. </title> <booktitle> In Proc. of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: Thus, Foxtr ot is unable to simulate kernel TLB misses. It simulates only user TLB misses and kernel TLB misses incurr ed due to data copying during file I/O. Trap-driven simulation is a very fast simulation technique when the miss ratio is very low <ref> [Uhli94, Lebe95] </ref>, as it often is for TLBs. Other r esearchers instrument executables and operating systems to perform memory system simulations, e.g., Active Memory [Lebe95], Epoxie [Chen93b, Chen93a], and ATOM [Sriv94]. <p> Trap-driven simulation is a very fast simulation technique when the miss ratio is very low [Uhli94, Lebe95], as it often is for TLBs. Other r esearchers instrument executables and operating systems to perform memory system simulations, e.g., Active Memory <ref> [Lebe95] </ref>, Epoxie [Chen93b, Chen93a], and ATOM [Sriv94]. I do not use this technique as I did not have access to an instrumentation system for Solaris that worked on dynamically linked libraries, operating system references, and supported multipr ogramming.
Reference: [Lee69] <author> Francis F. Lee. </author> <title> Study of "Look-Aside" Memory. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 18(11):1062 1064, </volume> <month> November </month> <year> 1969. </year>
Reference-contexts: A page table stores the translation and pr otection information and a translation lookaside buffer 1 (TLB) caches r ecently used translations to accelerate the translation pr ocess <ref> [Lee69, Smit82, Mile90] </ref>. The TLB and page table make up the address translation hierarchy that is the focus of my study .
Reference: [Lee89a] <author> David D. Lee, Shing I. Kong, Mark D. Hill, George S. Taylor, David A. Hodges, Randy H. Katz, and David A. Patterson. </author> <title> VLSI chip set for a multiprocessor workstation - Part I: An RISC microprocessor with coprocessor interface and support for symbolic processing. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <pages> pages 16881698, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Simpler implementations are possible by storing the valid bits in a separate RAM or r egisters, as the next two options illustrate. The middle of Figur e A-2 illustrates the use of a pass gate contr olled by the valid bit stor ed separately <ref> [Lee89a] </ref>. Pass gates, however , degrade signals passing thr ough them and require more powerful drivers or pr echarge circuitry. The bottom of Figur e A-2 shows a third alternative that combines the valid bit as part of a standar d multistage wor dline driver circuit.
Reference: [Lee89b] <author> Ruby B. Lee. </author> <title> Precision Architecture. </title> <journal> IEEE Computer, </journal> <volume> 22(1):7891, </volume> <month> January </month> <year> 1989. </year>
Reference-contexts: In a paged-segmentation model, pr ograms generate a &lt;segment identifier, segment of fset&gt; tuple that f irst translates to a global ef fective virtual addr ess befor e translating to a physical addr ess [Knig81, Dall92]. Examples include Honeywell 645 [Glas65], SPUR, [Hill86], HP-P A RISC <ref> [Lee89b] </ref>, IBM RS/6000 [Chan90], and PowerPC [May94]. TLBs and page tables translate the virtual addr ess to physical addr ess, and superpages or sub-blocking ar e equally applicable as described in this thesis. <p> Indexing with the exact VPN r equires either a) too many ports, b) many r eprobes, or c) many separate TLBs. A compr omise solution uses a set-associative single-page-size TLB for base pages and a separate fully-associative TLB for multiple superpage sizes, e.g., HP PARISC <ref> [Lee89b] </ref>, PowerPC [May94]. This allows a much larger single-page-size TLB to be built but r estricts the number of superpage mappings and requires separate TLB miss handlers. In summary, set-associative superpage TLBs can use either the base page index, superpage index, or exact index. <p> The same mapping at V A 0x40000 allows the use of one 4MB super-page. Virtual address allocation is more important than proper physical memory allocation as virtual addresses once allocated cannot be changedgather operations can corr ect erroneous physical memory allocations. Paged-segmented ar chitectures <ref> [Radi82, Chan90, Lee89b] </ref> can reassign virtual addr esses by modifying the segment table but cannot avoid the pr oblem completely as the segment of fset cannot be changed. <p> Foxtrot, my operating system pr ototype, implements a functional set of policies and mechanisms to support two page sizes and partial subblocking. 92 Chapter 7 Page Table Structures 7.1 Introduction A page table stores translation, pr otection, attribute, and status information for virtual addresses <ref> [Huck93, Chan88, Levy82, Silh93, Lee89b] </ref>. A page table entry (PTE) stores the information for one page. The TLB miss handler accesses the page table on a TLB miss to load the appropriate PTE into the TLB. <p> Section 7.5 explores ways to incorporate superpage and partialsubblock PTEs in a synonym table. The page table techniques described in this chapter are equally applicable to single address space systems, e.g., Opal [Chas94] or MONADS [Rose85], and segmented systems that use global effective virtual addresses, e.g, HP <ref> [Lee89b] </ref>. Hashed and clustered page tables are especially attractive in these systems as they have a very sparse address space. <p> Guarded page tables [Lied95] are sometimes effective but would still require three to four levels. An intermediate node cache can accelerate page table access, e.g., PTP cache in SuperSPARC [Blan92], Region Lookaside buffer in HaL [Chan95]. Large addr ess space systems often use hashed (inverted) page tables <ref> [Lee89b, Chan88, Huck93, May94] </ref> as they use memory pr oportional to the number of active virtual pages 1 . A simple implementation uses an open hash table and a hash function that maps a VPN to a bucket, e.g., .
Reference: [Lee89c] <author> T. Paul Lee and Ronald E. Barkley. </author> <title> A Watermark-Based Lazy Buddy System for Kernel Memory Allocation. </title> <booktitle> In Proc. Summer 89 USENIX Conference, </booktitle> <pages> pages 114, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Variablesized freelist management has been studied in the context of segments and memory allocators [Know65, Hirs73, Barr93]. The pr oblem is simpler her e than general memory allocators as systems support only a few superpage sizes that ar e powers of two. A buddy-block allocator <ref> [Knut68a, Pete77, T ayl81, Purd70, Bark89, Lee89c] </ref> or ganizes free pages into multiple fr eelists, one per supported allocation size and has a policy and a mechanism to coalesce fr ee pages into a fr ee superpage and vice versa.
Reference: [Leff90] <author> Samuel J. Leffler, Marshall Kirk McKusick, Michael J. Karels, and John S. Quarterman. </author> <title> The Design and Implementation of the 4.3BSD UNIX Operating System. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: Operating system support for virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX <ref> [Thom74, Bach86, Leff90, Ging87b] </ref>, VMS [Levy82], NT [Cust93], MACH [Acce86, Rash88], OS/2 [Koga88]).
Reference: [Leon82] <author> T. Leonard, </author> <title> editor. VAX-11 Architecture Reference Manual. </title> <publisher> Digital Press, </publisher> <month> May </month> <year> 1982. </year> <title> Revision 6.1. </title> <type> 182 </type>
Reference-contexts: This segmentation can be either invisible to har dware using a linear addr ess space model, e.g., VAX <ref> [Leon82] </ref> and MIPS [Kane89], or visible to har dware using a paged-segmentation model. In a paged-segmentation model, pr ograms generate a &lt;segment identifier, segment of fset&gt; tuple that f irst translates to a global ef fective virtual addr ess befor e translating to a physical addr ess [Knig81, Dall92].
Reference: [Levi95] <author> David Levitan, Thomas Thomas, and Paul Tu. </author> <title> The PowerPC 620 Microprocessor: A High-Performance Superscalar RISC Processor. </title> <booktitle> Compcon Digest of Papers, </booktitle> <pages> pages 285291, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: The traversal can be done by har dware, e.g., SPARC Reference MMU [SPAR91], some PowerPC implementations <ref> [May94, Levi95, Beck93] </ref>, or by softwar e, e.g., MIPS R4x00 [Kane92], UltraSP ARC [Yung95], Alpha [Site92]. W ith softwar e TLB miss handling, there is typically some har dware assist to speed up page table traversal.
Reference: [Levy82] <author> H. M. Levy and P. H. Lipman. </author> <title> Virtual Memory Management in the VAX/VMS Operating System. </title> <journal> IEEE Computer, </journal> <volume> 15(3):3541, </volume> <month> March </month> <year> 1982. </year>
Reference-contexts: Second, the page size is an ar chitectural feature that changes only during major transitions in pr ocessor ar chitecture, such as fr om VAX <ref> [Levy82] </ref> to Alpha [Site93] or from SPARC V8 [SPAR91] to SPARC V9 [SPAR94]. On the other hand, cache line size is an implementation parameter mor e easily changed. TLB miss penalty is also incr easing due to many r easons. <p> Operating system support for paged virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX [Thom74, Bach86, Lef f90], VMS <ref> [Levy82] </ref>, NT [Cust93], MACH [Acce86, Rash88], OS/2 [Koga88]). Most facets of paged virtual memory operating system policies and mechanisms r equire modif ications to support superpages ef fec-tively. A new policy pagesize assignment and upto six new mechanisms may also be required. <p> Romer et al. [Rome95] study the use of competitive algorithms for pagesize assignment among multiple superpage sizes. I use workingset based pagesize assignment (described in Section 6.1) in my work [T all92, Tall94a]. Three styles of page tables ar e popular 6 linear ( e.g., VAX <ref> [Levy82] </ref>), forwar d-mapped (e.g., SPARC [SPAR91]), and hashed/inverted ( e.g., PowerPC [May94], IBM System/38 [IBM78]). Many forwar d-mapped page table implementations and guar ded page tables [Lied95] support certain superpage sizes at their intermediate nodes. <p> Operating system support for virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX [Thom74, Bach86, Leff90, Ging87b], VMS <ref> [Levy82] </ref>, NT [Cust93], MACH [Acce86, Rash88], OS/2 [Koga88]). <p> Foxtrot, my operating system pr ototype, implements a functional set of policies and mechanisms to support two page sizes and partial subblocking. 92 Chapter 7 Page Table Structures 7.1 Introduction A page table stores translation, pr otection, attribute, and status information for virtual addresses <ref> [Huck93, Chan88, Levy82, Silh93, Lee89b] </ref>. A page table entry (PTE) stores the information for one page. The TLB miss handler accesses the page table on a TLB miss to load the appropriate PTE into the TLB. <p> The virtual page number (VPN) indexes the array, as shown in Figur e 7-1. Complete linear page tables ar e very large and are only partially populated. Consequently, they reside in virtual address space, using page faults to populate the table dynamically ( e.g., VAX-11 <ref> [Levy82] </ref>, MIPS R4000 [Kane92], Alpha [Site92]). As PTEs ar e allocated a page at a time, space over head is high if an address space usage is sparse. A separate data str ucture stores mappings to the page table itself, e.g., a multilevel tr ee of linear page tables.
Reference: [Lied95] <author> Jochen Liedtke. </author> <title> Address Space Sparsity and Fine Granularity. Operating Systems Review, </title> <address> 29(1):8790, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: Three styles of page tables ar e popular 6 linear ( e.g., VAX [Levy82]), forwar d-mapped (e.g., SPARC [SPAR91]), and hashed/inverted ( e.g., PowerPC [May94], IBM System/38 [IBM78]). Many forwar d-mapped page table implementations and guar ded page tables <ref> [Lied95] </ref> support certain superpage sizes at their intermediate nodes. Hashed page tables ar e being increasingly used to support sparse 64-bit addr ess [Houd68, Abra81, Thak86, Rose92, Huck93, May94] but none support superpage mappings. <p> Forward-mapped page tables are impractical for 64-bit address spaces, as an overhead of seven memory accesses for every TLB miss is not acceptable. Ther e are techniques to short-circuit some levels. Guarded page tables <ref> [Lied95] </ref> are sometimes effective but would still require three to four levels. An intermediate node cache can accelerate page table access, e.g., PTP cache in SuperSPARC [Blan92], Region Lookaside buffer in HaL [Chan95].
Reference: [Lipt68] <author> J. S. Liptay. </author> <title> Structural aspects of the System/360 Model 85, Part II: the cache. </title> <journal> IBM Systems Journal, </journal> <volume> 7(1):1521, </volume> <year> 1968. </year>
Reference-contexts: In particular, my thesis applies to TLBs and page tables thr ee techniques borr owed fr om cache designvariable block size [Dubn92], subblocking <ref> [Lipt68, Bell74, Good83, Hill84] </ref>, and subblock pr efetching [Smit78b, Hill87]. Superpage TLBs implement a variable block size design with the policy decisions on when to use superpages made by the operating system. <p> If the program has bad localityi.e., references only a small fraction of the pages within a page blockthe TLB performance is worse. This is the tradeoff in using subblock TLBs or caches. 1. Subblocking [Hill84] has also been called sectoring <ref> [Lipt68] </ref> and address/transfer blocks [Good83]. 2. This chapter concentrates on subblock TLBs as an alternative to medium-sized superpages. Appendix E illustrates how subblock TLBs support large superpages. 41 from a virtual address space to a physical address space.
Reference: [Litw93] <author> W. Litwin, M. Neimat, and D. Schneider. </author> <title> LH -Linear Hashing for Distributed Files. </title> <booktitle> 19 ACM SIG-MOD Conf. on the Management of Data, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: The operating system uses a locking pr otocol to synchronize concurrent accesses (e.g., [Bala92, May94]) and has a significant impact on performance [Khal94]. Some results in the study of concurrent access to database index data str uctures may be applicable to page tables <ref> [Come79, Baye77, Litw93, Elli87, Fagi79, Hsu86, Kuma90, Gutt84] </ref>. A page table synchr onization protocol has to addr ess at least three issues. First, both the page table and the synonym table must be updated atomically (e.g., with two-phase locking).
Reference: [Mack94] <author> Kenneth Mackenzie, John Kubiatowicz, Anant Agarwal, and Frans Kaashoek. FUGU: </author> <title> Implementing Translation and Protection in a Multiuser, Multimodel Multiprocessor. </title> <note> Technical Memo MIT/LCS/TM-503, </note> <month> October </month> <year> 1994. </year>
Reference-contexts: In multiprocessor systems TLB coher ence becomes an issue. T eller describes many strategies for maintaining TLB coher ence [Tell90]. Many operating systems use a conservative TLB shootdown algorithm, e.g., [Blac89]. The SPUR [W ood86] and Fugu <ref> [Mack94] </ref> machines combine TLB coher ence with existing cache coher ence mechanisms. Systems that support paged-segmentation typically include two translation buf fers, a TLB and a SLB (segment lookaside buffer), that ar e accessed one after another . Dally shows a scheme that combines the segment and page translation [Dall92].
Reference: [Matt70] <author> R. L. Mattson, J. Gecsei, D. R. Slutz, and I. L. Traiger. </author> <title> Evaluation Techniques for Storage Hierarchies. </title> <journal> IBM Systems Journal, </journal> <volume> 9(2):78117, </volume> <year> 1970. </year>
Reference-contexts: For set-associative and fully-associative TLBs, har dware or softwar e must implement a r eplacement policy. The TLB r eplacement policy impacts TLB performance because nonoptimal r eplacement decisions would cause additional TLB misses. It is impossible to implement the optimal r eplace-ment policy (OPT) <ref> [Bela66, Matt70, Prie76] </ref>, and it is impractical to maintain information for 8. Alternatively, the modified bit can be updated in the TLB, postponing the page table update till the next TLB replacement and leaves the page table in a stale state. <p> Second, trap-driven simulation r equires separate runs for simulating multiple TLBs. It is possible to use techniques for simultaneous simulation of multiple TLBs <ref> [Matt70, Hill89, Kim91] </ref> in trap-driven simulators for TLBs that satisfy the inclusion property [Matt70]. Foxtr ot does not implement these techniques and I use separate runs for each TLB simulation. The operating system intr oduces variation in physical memory allocation between multiple r uns of a workload. <p> Second, trap-driven simulation r equires separate runs for simulating multiple TLBs. It is possible to use techniques for simultaneous simulation of multiple TLBs [Matt70, Hill89, Kim91] in trap-driven simulators for TLBs that satisfy the inclusion property <ref> [Matt70] </ref>. Foxtr ot does not implement these techniques and I use separate runs for each TLB simulation. The operating system intr oduces variation in physical memory allocation between multiple r uns of a workload.
Reference: [May94] <editor> Cathay May, Ed Silha, Rick Simpson, and Hank Warren. </editor> <title> The PowerPC Architecture. </title> <publisher> Morgan Kaufman Publishers, </publisher> <month> May </month> <year> 1994. </year>
Reference-contexts: Examples include Honeywell 645 [Glas65], SPUR, [Hill86], HP-P A RISC [Lee89b], IBM RS/6000 [Chan90], and PowerPC <ref> [May94] </ref>. TLBs and page tables translate the virtual addr ess to physical addr ess, and superpages or sub-blocking ar e equally applicable as described in this thesis. <p> I use workingset based pagesize assignment (described in Section 6.1) in my work [T all92, Tall94a]. Three styles of page tables ar e popular 6 linear ( e.g., VAX [Levy82]), forwar d-mapped (e.g., SPARC [SPAR91]), and hashed/inverted ( e.g., PowerPC <ref> [May94] </ref>, IBM System/38 [IBM78]). Many forwar d-mapped page table implementations and guar ded page tables [Lied95] support certain superpage sizes at their intermediate nodes. Hashed page tables ar e being increasingly used to support sparse 64-bit addr ess [Houd68, Abra81, Thak86, Rose92, Huck93, May94] but none support superpage mappings. <p> Many forwar d-mapped page table implementations and guar ded page tables [Lied95] support certain superpage sizes at their intermediate nodes. Hashed page tables ar e being increasingly used to support sparse 64-bit addr ess <ref> [Houd68, Abra81, Thak86, Rose92, Huck93, May94] </ref> but none support superpage mappings. <p> The traversal can be done by har dware, e.g., SPARC Reference MMU [SPAR91], some PowerPC implementations <ref> [May94, Levi95, Beck93] </ref>, or by softwar e, e.g., MIPS R4x00 [Kane92], UltraSP ARC [Yung95], Alpha [Site92]. W ith softwar e TLB miss handling, there is typically some har dware assist to speed up page table traversal. <p> This allows the operating system to use lar ge superpages for special cases such as kernel text, database buf fer caches, and frame buf fers. Examples of this category include HP-PA RISC [Hewl93, Hunt95], Motor ola 88x00 [Mile90], Intel i860XP [Inte91], and PowerPC <ref> [Silh93, May94] </ref>. Such a superpage TLB is also known as a Block TLB or a Block Address Translation Cache (BATC). Most implementations of separate superpage TLBs require special TLB miss handling for superpages as the default TLB miss handler does not handle superpage mappings. <p> Rehash schemes: The TLB can first index assuming a base page and on a miss can r epeat the access, next cycle, using the superpage index. Similar schemes have been used to impr ove the performance of set-associative CPU caches [Agar88, Kess89, Agarwal93] and page tables <ref> [Thak86, May94] </ref>. The TLB access takes a variable number of cycles and can complicate pipeline design. If TLB access is in the critical path, increasing the TLB hit time for superpage mappings decreases their usefulness. <p> Indexing with the exact VPN r equires either a) too many ports, b) many r eprobes, or c) many separate TLBs. A compr omise solution uses a set-associative single-page-size TLB for base pages and a separate fully-associative TLB for multiple superpage sizes, e.g., HP PARISC [Lee89b], PowerPC <ref> [May94] </ref>. This allows a much larger single-page-size TLB to be built but r estricts the number of superpage mappings and requires separate TLB miss handlers. In summary, set-associative superpage TLBs can use either the base page index, superpage index, or exact index. <p> On base page table misses, the operating system page fault handler traverses other data str uctures to find and load superpage mappings into the TLB, e.g., block TLB miss handling in PowerPC <ref> [May94] </ref>. 3.4 Sample design given area constraint A fully-associative single-page-size TLB can support superpages with little area and access time overhead (Section 3.2.1). <p> A detailed description can be found in Huck and Hays [Huck93]. For all page table designs, 64-bit addr ess mapping information will r equire eight bytes, e.g., PowerPC <ref> [May94] </ref>, Alpha [Site92], UltraSP ARC [Yung95]. The upper right corner of Figur e 7-1 illustrates example mapping information that contains one valid bit, a 28-bit PPN (40-bit physical addr ess with 4KB pages), 12 bits of software or hardware attributes, and PAD bits for future use. <p> Guarded page tables [Lied95] are sometimes effective but would still require three to four levels. An intermediate node cache can accelerate page table access, e.g., PTP cache in SuperSPARC [Blan92], Region Lookaside buffer in HaL [Chan95]. Large addr ess space systems often use hashed (inverted) page tables <ref> [Lee89b, Chan88, Huck93, May94] </ref> as they use memory pr oportional to the number of active virtual pages 1 . A simple implementation uses an open hash table and a hash function that maps a VPN to a bucket, e.g., . <p> An inverted page table easily incorporates this optimization by maintaining the hash buckets as circular lists and updating the head pointer after every page table lookup. Software TLBs (e.g., swTLB [Huck93], TSB [Y ung94], STLB [Bala94], PowerPCs page table <ref> [May94] </ref>) eliminate a hashed page tables next pointers by pre-allocating few PTEs per bucket. be viewed as memory-r esident level-two TLBs with overf low handled in many ways, e.g., hash-rehash schemes [Agar88, Thak86] or set r eplacement [May94]. <p> Software TLBs (e.g., swTLB [Huck93], TSB [Y ung94], STLB [Bala94], PowerPCs page table <ref> [May94] </ref>) eliminate a hashed page tables next pointers by pre-allocating few PTEs per bucket. be viewed as memory-r esident level-two TLBs with overf low handled in many ways, e.g., hash-rehash schemes [Agar88, Thak86] or set r eplacement [May94]. While softwar e TLBs can be the native page table str ucture, e.g., page tables for the PowerPC, they ar e more popular and effective alsoas a cache of r ecently used translations. <p> It has two drawbacks. First, it does not allow use of superpages to make page tables smaller . Second, the r eplicated PTEs make adding a superpage PTE or atomic PTE update more complex, especially in multi-threaded, multiprocessor operating systems <ref> [Eykh92, Clar95, May94] </ref>. Multiple Page Tables. This solution creates separate page tables for each page size in use. On a TLB miss, the handler accesses and sear ches the page tables in some pr edetermined order. <p> The operating system uses a locking pr otocol to synchronize concurrent accesses (e.g., <ref> [Bala92, May94] </ref>) and has a significant impact on performance [Khal94]. Some results in the study of concurrent access to database index data str uctures may be applicable to page tables [Come79, Baye77, Litw93, Elli87, Fagi79, Hsu86, Kuma90, Gutt84]. <p> First, both the page table and the synonym table must be updated atomically (e.g., with two-phase locking). Second, TLB miss handlers access the page table asynchronously without acquiring any locks, r equiring more elaborate page table algorithms <ref> [May94] </ref>. TLB miss handlers both r ead (load translation info) and write the page table (update r efer-ence/modified bits).
Reference: [McKu84] <author> M. K. McKusick, W. N. Joy, S. J. Leffler, and R. S. Fabry. </author> <title> A Fast File System for UNIX. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(3):191197, </volume> <month> August </month> <year> 1984. </year>
Reference-contexts: Thus page r eservation always places the physical pages at the corr ect location. Figure 6-1 shows a sample sequence of page faults and pages allocated using page r eser-vation. Some file systems also use similar techniques to r eserve disk space <ref> [McKu84] </ref>. If the physical memory manager cannot find a free physical page block, Foxtr ot resorts to using random base physical pages. The operating system can use a gather operation to correct these random allocations later when ther e are free page blocks.
Reference: [Mile90] <author> Milan Milenkovic. </author> <title> Microprocessor Memory Management Units. </title> <journal> IEEE Micro, </journal> <volume> 10(2):7085, </volume> <month> April </month> <year> 1990. </year>
Reference-contexts: A page table stores the translation and pr otection information and a translation lookaside buffer 1 (TLB) caches r ecently used translations to accelerate the translation pr ocess <ref> [Lee69, Smit82, Mile90] </ref>. The TLB and page table make up the address translation hierarchy that is the focus of my study . <p> This allows the operating system to use lar ge superpages for special cases such as kernel text, database buf fer caches, and frame buf fers. Examples of this category include HP-PA RISC [Hewl93, Hunt95], Motor ola 88x00 <ref> [Mile90] </ref>, Intel i860XP [Inte91], and PowerPC [Silh93, May94]. Such a superpage TLB is also known as a Block TLB or a Block Address Translation Cache (BATC). Most implementations of separate superpage TLBs require special TLB miss handling for superpages as the default TLB miss handler does not handle superpage mappings.
Reference: [MIPS93] <author> MIPS Technologies, Inc. </author> <title> TFP Microprocessor Chip Set: Preliminary Product Information, </title> <month> Octo-ber </month> <year> 1993. </year>
Reference-contexts: bit to select between 4KB and 8KB page size [Eden90], Motor ola 68020 using MC68851 contr oller can select a page size fr om 256 bytes to 2KB [Moto86], the SGI R8000 pr ocessor allows two page sizesone for instr uctions and another for datathat ar e selectable per process <ref> [MIPS93] </ref>, AMD29000 [John87] supports a per-process pagesize. 31 Many single-page-size operating systems use a configurable systemwide P AGESIZE constant. Solaris, for example, uses 8KB pages on V7 or V9 machines and 4KB pages for V8 machines; IRIX uses 4KB pages for R4X00 machines and 16KB pages for R6000 machines.
Reference: [Mogu93] <author> Jeffrey C. Mogul. </author> <title> Big Memories on the Desktop. </title> <booktitle> In Proc. of the Fourth Workshop on Workstation Operating Systems, </booktitle> <pages> pages 110115, </pages> <address> Napa CA, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: I identify the operating system policies and mechanisms r equired to support superpage and partialsubblock TLBs. Further, I have implemented some policies and mechanisms in So 2. I use the term first suggested by Mogul <ref> [Mogu93] </ref>. 3 laris 2.1, a commer cial operating system (Chapter 6). I propose a new page table str ucture, clustered page table, that has a lower page table access time, occupies less memory, and stores superpage (and partialsubblock) mappings mor e efficiently than conventional page tables (Chapter 7). <p> Commer cial operating systems I am awar e of, however , do not support general use of superpage mappings. Many operating systems include special mechanisms to use lar ge superpages for unpageable memory and devices. While some have suggested uses for superpages <ref> [Chen92, Mogu93] </ref>, I believe my thesis (and my pr evious work) is the f irst to study the issues involved in building superpages TLBs and supporting them. <p> Foxtrot uses page reservation, described in Section 6.2.5, to allocate physical memory such that base pages are often properly placed. 28 Chapter 3 Superpage TLBs This chapter evaluates the use of superpages <ref> [Tall92, Mogu93, Tall94a] </ref> to increase TLB reach. Superpages use the same linear addr ess space as conventional paging, have sizes that must be power-of-two multiples of the base page size, and must be aligned in both virtual and physical memory [Tall94a].
Reference: [Mogu95] <author> Jeffrey Mogul, Joel Bartlett, Robert Mayo, and Amitabh Srivastava. </author> <title> Performance Implications of Multiple Pointer Sizes. </title> <booktitle> USENIX, </booktitle> <year> 1995. </year>
Reference-contexts: Such workloads would make TLB and page table effects more important. For example, Mogul et al report that modifying some 32-bit pr ograms to use 64-bit pointers incr eases address space usage about 30% <ref> [Mogu95] </ref>. I am not awar e of any published r esults about the effect on time spent in TLB miss handling. By emphasizing on workloads for which TLB miss handling time is important, however , my results overestimate the potential speedup for workloads that include processes with small address spaces.
Reference: [Mora88] <author> Joseph P. Moran. </author> <title> SunOS Virtual Memory Implementation. </title> <booktitle> In Proc. of Europoean UNIX Users Group Conference, </booktitle> <month> Spring </month> <year> 1988. </year>
Reference-contexts: loads/unloads mappings from a page table; one or more file systems that manage and maintain str ucture/coherence of objects on disk/network; a physical memory manager that manages/allocates physical pages; and a page table manager that isolates page table and TLB details in a machinedependent module, e.g., SYSV UNIX hat layer <ref> [Mora88, Bala92] </ref> and Mach pmap layer [Rash88]. To be ef fective, however, superpage and partialsubblock TLBs r equire operating system support in ar eas other than TLB and page table management (Chapter 7 discusses page tables).
Reference: [Morr68] <author> R. Morris. </author> <title> Scatter Storage Techniques. </title> <journal> Communications of the ACM, </journal> <volume> 11(1):3843, </volume> <month> January </month> <year> 1968. </year>
Reference-contexts: This results in shorter hash table lists, a hash table with fewer buckets, or both. Shorter hash table lists r educe hash table sear ch time on TLB misses <ref> [Knut68b, Morr68, John61] </ref>. Third, clustered page tables amortize the overhead of allocating memory for a PTE and inserting in the hash list over multiple PTE insertions. Hashed page tables incur a fixed overhead of memory allocation, list insertion and tag initialization for each PTE added to the page table.
Reference: [Moto86] <author> Motorola Inc. </author> <title> MC68851 Paged Memory Management Unit Users Manual, </title> <year> 1986. </year>
Reference-contexts: Examples of this category include Motor ola 68040, which has a mode bit to select between 4KB and 8KB page size [Eden90], Motor ola 68020 using MC68851 contr oller can select a page size fr om 256 bytes to 2KB <ref> [Moto86] </ref>, the SGI R8000 pr ocessor allows two page sizesone for instr uctions and another for datathat ar e selectable per process [MIPS93], AMD29000 [John87] supports a per-process pagesize. 31 Many single-page-size operating systems use a configurable systemwide P AGESIZE constant.
Reference: [Muld91] <author> Johannes M. Mulder, Nhon T. Quach, and Michael J. Flynn. </author> <title> An Area Model for On-Chip Memories and its Applications. </title> <journal> IEEE Journal of Solid State Circuits, </journal> <volume> 26(2):98106, </volume> <month> February </month> <year> 1991. </year>
Reference-contexts: I estimate TLB access time and chip ar ea cost using analytical models adapted fr om similar models developed for caches. Section 2.2 describes the ar ea model adapted fr om Mul-der s model <ref> [Muld91] </ref> and Section 2.3 describes the access time model adapted fr om Jouppi and Wiltons model [Wilt93]. <p> I include a chip ar ea model and an access time model in my study to compar e the costs of building dif ferent TLBs. The chip ar ea model extends Mulder s model <ref> [Muld91] </ref> to accommodate superpage and subblock TLBs (Section 2.2) and the access time model extends Wilton and Jouppis model [Wilt93] (Section 2.3). Section 2.4 describes ten workloads I use thr oughout the thesis. I use execution time speedup as the performance metric as explained in Section 2.5. <p> The primary component of a TLB is the data pathtag and data arrays, drivers, multiplexors, and sense amps. I estimate the ar ea cost using the model pr oposed by Mulder et al. <ref> [Muld91] </ref> for fully-associative and set-associative caches. The model calculates the area in units of register bit equivalents ( rbe)the number of r egister cells that can be implemented in the same area. Figures 2-1 and 2-2 illustrate how the model estimates chip ar ea for TLBs.
Reference: [Nagl92] <author> David Nagle, Richard Uhlig, and Trevor Mudge. </author> <title> Monster: A Tool for Analyzing the Interaction Between Operating Systems and Computer Architecture. </title> <institution> University of michigan technical report, University of Michigan, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: Trap driven simulation has two disadvantages. First, it only calculates the number of target TLB misses and r equires other techniques to measur e the number of TLB hits, e.g., profiling counters [Site93], external pr obes <ref> [Nagl92] </ref>. Second, trap-driven simulation r equires separate runs for simulating multiple TLBs. It is possible to use techniques for simultaneous simulation of multiple TLBs [Matt70, Hill89, Kim91] in trap-driven simulators for TLBs that satisfy the inclusion property [Matt70].
Reference: [Nagl94a] <author> David Nagle, Richard Uhlig, Trevor Mudge, and Stuart Sechrest. </author> <title> Optimal Allocation of On-Chip Memory for Multiple-API Operating Systems. </title> <booktitle> In Proc. of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 358369, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: However , most microprocessor designs include a TLB on-chip and chip ar ea constraints limit the design options available to processor designers <ref> [Joup94, Nagl94a] </ref>. In later chapters, I show the ef fec-tiveness of the new TLB ar chitectures by comparing execution time speedups for dif ferent TLBs that occupy comparable chip ar ea.
Reference: [Nagl94b] <author> David Nagle, Richard Uhlig, Tim Stanley, Stuart Sechrest, Trevor Mudge, and Richard Brown. </author> <title> Design Tradeoffs for Software-Managed TLBs. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 12(3):175 205, </volume> <month> August </month> <year> 1994. </year>
Reference-contexts: TLB misses ar e often handled by har dware that traverses page tables. Some processors support TLB miss handling in softwar e and Nagle et al discuss issues in softwar e TLB miss handling using MIPS pr ocessors as examples <ref> [Nagl94b] </ref>. In multiprocessor systems TLB coher ence becomes an issue. T eller describes many strategies for maintaining TLB coher ence [Tell90]. Many operating systems use a conservative TLB shootdown algorithm, e.g., [Blac89]. The SPUR [W ood86] and Fugu [Mack94] machines combine TLB coher ence with existing cache coher ence mechanisms. <p> A separate data str ucture stores mappings to the page table itself, e.g., a multilevel tr ee of linear page tables. Ultrix uses a two-level tr ee and OSF/1 uses a three-level tree on the MIPS R3000 <ref> [Nagl94b] </ref>. A straightforwar d extension of linear page tables to 64-bit addr esses uses a virtual array with 4 x 10 15 entries and a six-level tr ee. This design is practical, as a portion of the TLB is r eserved for mappings to the page tables [Nagl94b] and the tree <p> the MIPS R3000 <ref> [Nagl94b] </ref>. A straightforwar d extension of linear page tables to 64-bit addr esses uses a virtual array with 4 x 10 15 entries and a six-level tr ee. This design is practical, as a portion of the TLB is r eserved for mappings to the page tables [Nagl94b] and the tree is rarely traversed. Alternatively, a linear page table could be backed by other data structures, e.g., a hashed page table or a forward-mapped page table [Site92], described next. Offset VPN 000 Base VPN Array of PTEs (8 bytes each) Virtual Address Page Table . .
Reference: [Ogde95] <author> Deene Ogden, Belli Kuttanna, Albert J. Loper, Soummya Mallick, and Michael Putrino. </author> <title> A New PowerPC Microprocessor for Low Power Computing Systems. </title> <booktitle> Compcon Digest of Papers, </booktitle> <pages> pages 183 281284, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: W ith softwar e TLB miss handling, there is typically some har dware assist to speed up page table traversal. Some pr o-cessors generate specialized TLB exceptions and har dware generated page table hint pointers as in MIPS R4x00 [Kane92], UltraSP ARC [Yung95], and PowerPC <ref> [Ogde95] </ref>. Further , software TLB miss handlers incur trap entry/exit costs not shown her e. Chapter 7 describes popular page table data str uctures and their access times. Many operating systems r equire the TLB miss handler to set r eference and modified bits in the page table.
Reference: [Orga72] <author> E.J. Organick. </author> <title> The Multics System: An Examination of Its Structure. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1972. </year>
Reference: [Pete77] <author> J. L. Peterson and N. Theodore. </author> <title> Buddy Systems. </title> <journal> Communications of the ACM, </journal> <volume> 20(6):421431, </volume> <month> June </month> <year> 1977. </year>
Reference-contexts: Variablesized freelist management has been studied in the context of segments and memory allocators [Know65, Hirs73, Barr93]. The pr oblem is simpler her e than general memory allocators as systems support only a few superpage sizes that ar e powers of two. A buddy-block allocator <ref> [Knut68a, Pete77, T ayl81, Purd70, Bark89, Lee89c] </ref> or ganizes free pages into multiple fr eelists, one per supported allocation size and has a policy and a mechanism to coalesce fr ee pages into a fr ee superpage and vice versa.
Reference: [Prie76] <author> B. G. Prieve and R. S. Fabry. </author> <title> VMIN- AN Optimal Variable Space Page Replacement algorithm. </title> <journal> Communications of the ACM, </journal> <volume> 19(6):295297, </volume> <month> May </month> <year> 1976. </year>
Reference-contexts: Further, simpler versions of the algorithms used in segmented operating systems may be applicable in superpage operating systems, e.g., memory allocation [Knut68a], segmentsize assignment [Redd75], and variablesized segment and page r eplace-ment <ref> [Prie76, Fran74, T urn81] </ref>. Smith compiled a bibliography of early virtual memory r e-search that includes r esearch on segmented systems [Smit78c]. <p> For set-associative and fully-associative TLBs, har dware or softwar e must implement a r eplacement policy. The TLB r eplacement policy impacts TLB performance because nonoptimal r eplacement decisions would cause additional TLB misses. It is impossible to implement the optimal r eplace-ment policy (OPT) <ref> [Bela66, Matt70, Prie76] </ref>, and it is impractical to maintain information for 8. Alternatively, the modified bit can be updated in the TLB, postponing the page table update till the next TLB replacement and leaves the page table in a stale state.
Reference: [Purd70] <author> P. W. Purdom and S. M. </author> <title> Stigler. Statistical Properties of the Buddy System. </title> <journal> JACM, </journal> <volume> 17(4):683 697, </volume> <month> October </month> <year> 1970. </year>
Reference-contexts: Variablesized freelist management has been studied in the context of segments and memory allocators [Know65, Hirs73, Barr93]. The pr oblem is simpler her e than general memory allocators as systems support only a few superpage sizes that ar e powers of two. A buddy-block allocator <ref> [Knut68a, Pete77, T ayl81, Purd70, Bark89, Lee89c] </ref> or ganizes free pages into multiple fr eelists, one per supported allocation size and has a policy and a mechanism to coalesce fr ee pages into a fr ee superpage and vice versa.
Reference: [Puza85] <author> T. R. Puzak. </author> <title> Analysis of Cache Replacement Algorithms. </title> <type> Ph.D. dissertation, </type> <institution> Dept. of Electrical and Computer Engineering, University of Massachusetts, </institution> <month> February </month> <year> 1985. </year>
Reference-contexts: Mod-bit updates occur fr equently as pr ograms often r ead data fr om a page befor e writing to it. Software TLB miss handlers allow operating systems to implement optimizations in setting these bits [DeMo86]. A TLB r eplacement policy, like a cache r eplacement policy <ref> [Puza85] </ref>, decides wher e to place a new translation by choosing a victim TLB block. In a dir ect-mapped TLB replacement is trivialthere is only a single TLB block that can stor e the new translation.
Reference: [Radi82] <author> G. Radin. </author> <title> The 801 Minicomputer. </title> <booktitle> In Proc. of the Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 3947, </pages> <address> Palo Alto CA, </address> <month> March </month> <year> 1982. </year>
Reference-contexts: The same mapping at V A 0x40000 allows the use of one 4MB super-page. Virtual address allocation is more important than proper physical memory allocation as virtual addresses once allocated cannot be changedgather operations can corr ect erroneous physical memory allocations. Paged-segmented ar chitectures <ref> [Radi82, Chan90, Lee89b] </ref> can reassign virtual addr esses by modifying the segment table but cannot avoid the pr oblem completely as the segment of fset cannot be changed.
Reference: [Rama81] <author> K. Ramamohanarao and R. Sacks-Davis. </author> <title> Hardware address translation for machines with a large virtual memory. </title> <journal> Information Processing Letters, </journal> <volume> 13(1):2329, </volume> <year> 1981. </year>
Reference-contexts: The extra level of indir ection slows TLB miss handling as it often r esults in one additional cache miss [Huck93]. Ther e are two advantages of the indir ection <ref> [Rama81] </ref>. Inverted page tables usually use the physical page descriptors as the hash nodes. They can save memory by not storing the PPN in a PTE as it can be inferr ed from the position of the page descriptor in the array . <p> Also, page table access time improves by dynamically moving the most r ecently accessed element to the head of the hash bucket list <ref> [Rama81, Huck93] </ref>. An inverted page table easily incorporates this optimization by maintaining the hash buckets as circular lists and updating the head pointer after every page table lookup. <p> Second, two-level tables allow easy movement of the most r ecently referenced PTE to the head of a hash bucket using cir cular lists <ref> [Rama81] </ref>. This optimization is important for cluster ed page tables with single-page-size TLBs wher e spatial locality makes it likely that mappings for neighboring base pages in the same PTE will be referenced soon.
Reference: [Rama93] <author> Raghu Ramakrishnan, Divesh Srivastava, S. Sudarshan, and Praveen Seshadri. </author> <title> Implementation of the CORAL Deductive Database System. </title> <booktitle> In Proceedings of ACM SIGMOD International Conference on Management of Data, </booktitle> <year> 1993. </year>
Reference-contexts: Nasa7, compress, wave5, spice, and gcc are from the SPEC92 suite [SPEC91]; fftpde is a NAS benchmark [Bail91] operating on a 64X64X64 matrix; mp3d and pthor are uniprocessor versions from the SPLASH benchmark suite [Sing92]; coral <ref> [Rama93] </ref> is a deductive database executing a nested loop join; ML [Appe91b] is executing a str ess test on the garbage collector [Repp94]. I use a Sun SPARCstation with a 40 MHz SuperSPARC processor for all the simulations.
Reference: [Rash88] <author> Richard F. Rashid, Avadis Tevanian, Michael Young, David B. Golub, Robert V. Baron, David L. Black, William Bolosky, and Jonathan Chew. </author> <title> Machine-Independent Virtual Memory Management for Paged Uniprocessor and Multiprocessor Architectures. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(8):896908, </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: Operating system support for paged virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX [Thom74, Bach86, Lef f90], VMS [Levy82], NT [Cust93], MACH <ref> [Acce86, Rash88] </ref>, OS/2 [Koga88]). Most facets of paged virtual memory operating system policies and mechanisms r equire modif ications to support superpages ef fec-tively. A new policy pagesize assignment and upto six new mechanisms may also be required. <p> Such a situation frequently occurs in operating systems that use the copy-on-write optimization <ref> [Rash88] </ref>. Third, a partialsubblock TLB block can be incrementally populated, e.g., the mapping from page block y uses a TLB block that also could store another properly placed mapping (if established) from page block y to page block b. <p> Operating system support for virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX [Thom74, Bach86, Leff90, Ging87b], VMS [Levy82], NT [Cust93], MACH <ref> [Acce86, Rash88] </ref>, OS/2 [Koga88]). <p> one or more file systems that manage and maintain str ucture/coherence of objects on disk/network; a physical memory manager that manages/allocates physical pages; and a page table manager that isolates page table and TLB details in a machinedependent module, e.g., SYSV UNIX hat layer [Mora88, Bala92] and Mach pmap layer <ref> [Rash88] </ref>. To be ef fective, however, superpage and partialsubblock TLBs r equire operating system support in ar eas other than TLB and page table management (Chapter 7 discusses page tables). The primary contribution of this chapter is that I identify the operating system support required and discuss alternate solutions. <p> This situation occurs quite fr equently but it is not practical to coor dinate the virtual addr esses and physical addr esses u sed by two non-contemporaneous programs. 6.3.3 Copy-on-write Many operating systems use the copy-on-write optimization <ref> [Rash88] </ref> to r educe memory demand by sharing r ead-only pages until written ( e.g., pr ogram data segment). A copy-on-write operation r emaps a virtual page to a copy of the original physical page adding r ead-write permissions.
Reference: [Redd75] <author> Y. V. Reddy. </author> <title> Optimal Segment Size for Storage Allocation in a Multiprogrammed Computer System. </title> <booktitle> In Proc. of IEEE Computer Society Conference, </booktitle> <pages> pages 303305, </pages> <month> September </month> <year> 1975. </year>
Reference-contexts: Further, simpler versions of the algorithms used in segmented operating systems may be applicable in superpage operating systems, e.g., memory allocation [Knut68a], segmentsize assignment <ref> [Redd75] </ref>, and variablesized segment and page r eplace-ment [Prie76, Fran74, T urn81]. Smith compiled a bibliography of early virtual memory r e-search that includes r esearch on segmented systems [Smit78c].
Reference: [Rein93] <author> Steven K. Reinhardt, Mark D. Hill, James R. Larus, Alvin R. Lebeck, James C. Lewis, and David A. Wood. </author> <title> The Wisconsin Wind Tunnel: Virtual Prototyping of Parallel Computers. </title> <booktitle> In Proc. ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 4860, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Trap-driven simulation can be faster than tracedriven simulation, as it does not have to pr o-cess references that are target TLB hits, but cannot measure the number of TLB hits. Wisconsin Wind Tunnel <ref> [Rein93] </ref> and Tapeworm II [Uhli94] ar e examples of other systems that use trap-driven simulation for memory system simulations.
Reference: [Rein94] <author> Steven K. Reinhardt, James R. Larus, and David A. Wood. Tempest and Typhoon: </author> <title> User-Level Shared Memory. </title> <booktitle> In Proc. of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 325337, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: This allows implementation of custom user defined pagesize assignment policies that exploit pr ograms knowledge of their access pattern. Some operating systems have similarly exported mechanisms such as page r eplacement [Youn89, Hart92], scheduling [Ande92], and cache coher ence <ref> [Rein94] </ref>. In summary, operating systems have a choice of a variety of page-assignment policies and different workloads may pr efer dif ferent policies. The key to operating system design is to identify and implement the mechanisms that can support many alternate policies.
Reference: [Repp94] <author> John H. Reppy. </author> <title> A High-performance Garbage Collector for Standard ML, 1994. </title> <institution> AT&T Bell Labs Technical Memo. </institution>
Reference-contexts: the SPEC92 suite [SPEC91]; fftpde is a NAS benchmark [Bail91] operating on a 64X64X64 matrix; mp3d and pthor are uniprocessor versions from the SPLASH benchmark suite [Sing92]; coral [Rama93] is a deductive database executing a nested loop join; ML [Appe91b] is executing a str ess test on the garbage collector <ref> [Repp94] </ref>. I use a Sun SPARCstation with a 40 MHz SuperSPARC processor for all the simulations. Table 2-1 displays workload data, with the workloads sorted fr om most to least per cent of user time spent on TLB miss handling for a SuperSP ARC processor.
Reference: [Rome95] <author> Ted Romer, Wayne Ohlrich, Anna Karlin, and Brian Bershad. </author> <title> Reducing TLB and Memory Overhead Using Online Superpage Promotion. </title> <booktitle> In Proc. of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 176187, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: By multiprogramming, I mean execution of multiple concurrently active processes. 10 Operating system support for superpages involves implementing some mechanisms (described in Section 6.2), e.g., variablesize memory allocation [Knut68a], and a pagesize assignment policy (described in Section 6.1). Romer et al. <ref> [Rome95] </ref> study the use of competitive algorithms for pagesize assignment among multiple superpage sizes. I use workingset based pagesize assignment (described in Section 6.1) in my work [T all92, Tall94a]. <p> Pagesize assignment can be either static or dynamic and this section describes two classes of dynamic policiesworking set thr eshold [Tall92, Tall94a] and competitive <ref> [Rome95] </ref>. A static pagesize assignment policy makes the decision once and fixes the page size over the life of the mapping. Device pages and non-pageable memory can use a static policy of using the largest superpage size that maps the object ( e.g., kernel text, frame buf fers, database buffers). <p> Romer et al. characterize such policies as ASAP (as-soon-as-possible) policies <ref> [Rome95] </ref>. Foxtrot implements a workingset thr eshold policy and makes policy decisions between two page sizes [T all94a]. Superpage TLBs and page tables do not gather r eference information at base page granularity for superpage mappingsther e is only a single r eferenced attribute bit per superpage PTE. <p> Romer et al. r ecently pr oposed a competitive pagesize assignment policy that accounts for the cost of TLB misses and captur es reference patterns by updating counters for every base page and superpage on TLB misses <ref> [Rome95] </ref>. The policy promotes pages when TLB miss costs exceed a thr eshold based on page pr omotion costs. <p> The disadvantage of competitive poli 81 cies is the incr ease in TLB miss penalty, e.g., from 30 to 130 cycles, and memory over head and cache pollution due to the extra counters, e.g., 3.125 counters per base page <ref> [Rome95] </ref>. By using superpages, these costs ar e offset by the decr ease in the number of TLB misses and pr o-grams show a net decr ease in execution time. Page demotions occur , if at all, when the superpage is selected for page r eplacement. <p> Competitive policies that tradeoff TLB miss costs against page pr omotion costs require information about which pages ar e incurring a lar ge number of TLB misses. The TLB miss handler could maintain such statistics, e.g., as pr oposed by Romer et al. <ref> [Rome95] </ref>.
Reference: [Rose85] <author> J. Rosenberg and D. A. Abramson. </author> <title> MONAD PC: A Capability Based Workstation to Support Software Engineering. </title> <booktitle> In Proc. of the 18th Hawaii International Conference on System Sciences, </booktitle> <pages> pages 222231, </pages> <year> 1985. </year>
Reference-contexts: Section 7.5 explores ways to incorporate superpage and partialsubblock PTEs in a synonym table. The page table techniques described in this chapter are equally applicable to single address space systems, e.g., Opal [Chas94] or MONADS <ref> [Rose85] </ref>, and segmented systems that use global effective virtual addresses, e.g, HP [Lee89b]. Hashed and clustered page tables are especially attractive in these systems as they have a very sparse address space.
Reference: [Rose92] <author> J. Rosenberg, J. L. Keedy, and D. Abramson. </author> <title> Addressing Large Virtual Memories. </title> <journal> The Computer Journal, </journal> <volume> 35(4):369376, </volume> <year> 1992. </year>
Reference-contexts: Many forwar d-mapped page table implementations and guar ded page tables [Lied95] support certain superpage sizes at their intermediate nodes. Hashed page tables ar e being increasingly used to support sparse 64-bit addr ess <ref> [Houd68, Abra81, Thak86, Rose92, Huck93, May94] </ref> but none support superpage mappings.
Reference: [Saty81] <author> M. Satyanarayanan and D. Bhandarkar. </author> <title> Design Trade-offs in VAX-11 Translation Buffer Organization. </title> <journal> IEEE Computer, </journal> <volume> 14(12):103111, </volume> <month> December </month> <year> 1981. </year>
Reference-contexts: I list some literatur e relating to TLBs that may be useful for futur e reference. A survey paper on cache memories by Smith also describes TLBs and r elated design parameters [Smit82]. The TLB in the V AX 11/780 system is the focus of some studies <ref> [Saty81, Clar85, Alex85, Alex86] </ref>. Their studies show that time spent in TLB miss handling is less than 5%, for the workloads (including multipr ogrammed 5 work-loads) used in early 1980s. W orkload changes have made TLBs mor e important, as shown in later studies [Chen92, T all92].
Reference: [Silh93] <author> Ed Silha. </author> <title> The PowerPC Architecture, IBM RISC System/6000 Technology, Volume II. </title> <institution> IBM Corp., </institution> <year> 1993. </year> <month> 184 </month>
Reference-contexts: Superpages have sizes that ar e power of-two multiples of the base page size and must be aligned in both virtual and physical memory (Chapter 3). Many pr ocessors now support su-perpages, e.g., MIPS [Kane92], UltraSPARC [Yung95], Alpha [Bann95], PowerPC <ref> [Silh93] </ref>, HP-PA RISC [Hunt95]. A fully-associative TLB can easily include support for superpages. An example is the MIPS R4000, which supports a 4KB base page size and superpages of 16KB, 64KB, 256KB, 1MB, 4MB, and 16MB with a fully-associative TLB. <p> A key motivation for my thesis was the intr oduction of superpage support in many microprocessor TLBs, e.g., MIPS [Kane92], UltraSP ARC [Yung95], Alpha [Bann95], PowerPC <ref> [Silh93] </ref>, HP-PA RISC [Hunt95]. Commer cial operating systems I am awar e of, however , do not support general use of superpage mappings. Many operating systems include special mechanisms to use lar ge superpages for unpageable memory and devices. <p> Thus, the key to using superpage TLBs is an operating system that uses superpages wher e appropriate and base pages elsewhere. Nearly every current microprocessor supports superpages, e.g., MIPS [Kane92], UltraS-PARC [Yung95], Alpha [Bann95], PowerPC <ref> [Silh93] </ref>, HP-P A RISC [Hunt95]. The MIPS R4000 [Kane92], for example, supports a 4KB base page size and superpages of 16KB, 64KB, 256KB, 1MB, 4MB, and 16MB. However, I am not aware of any operating system that uses superpages in a general manner. <p> This allows the operating system to use lar ge superpages for special cases such as kernel text, database buf fer caches, and frame buf fers. Examples of this category include HP-PA RISC [Hewl93, Hunt95], Motor ola 88x00 [Mile90], Intel i860XP [Inte91], and PowerPC <ref> [Silh93, May94] </ref>. Such a superpage TLB is also known as a Block TLB or a Block Address Translation Cache (BATC). Most implementations of separate superpage TLBs require special TLB miss handling for superpages as the default TLB miss handler does not handle superpage mappings. <p> Foxtrot, my operating system pr ototype, implements a functional set of policies and mechanisms to support two page sizes and partial subblocking. 92 Chapter 7 Page Table Structures 7.1 Introduction A page table stores translation, pr otection, attribute, and status information for virtual addresses <ref> [Huck93, Chan88, Levy82, Silh93, Lee89b] </ref>. A page table entry (PTE) stores the information for one page. The TLB miss handler accesses the page table on a TLB miss to load the appropriate PTE into the TLB.
Reference: [Sing92] <author> Jaswinder Pal Singh, Wolf-Dietrich Weber, and Anoop Gupta. </author> <title> SPLASH: Stanford Parallel Applications for Shared Memory. Computer Architecture News, </title> <address> 20(1):544, </address> <month> March </month> <year> 1992. </year>
Reference-contexts: I first describe the workloads and then discuss the consequences of concentrating on these workloads. Nasa7, compress, wave5, spice, and gcc are from the SPEC92 suite [SPEC91]; fftpde is a NAS benchmark [Bail91] operating on a 64X64X64 matrix; mp3d and pthor are uniprocessor versions from the SPLASH benchmark suite <ref> [Sing92] </ref>; coral [Rama93] is a deductive database executing a nested loop join; ML [Appe91b] is executing a str ess test on the garbage collector [Repp94]. I use a Sun SPARCstation with a 40 MHz SuperSPARC processor for all the simulations.
Reference: [Site92] <author> Richard L. </author> <title> Sites. Alpha Architecture Reference Manual. </title> <publisher> Digital Press, </publisher> <year> 1992. </year>
Reference-contexts: The traversal can be done by har dware, e.g., SPARC Reference MMU [SPAR91], some PowerPC implementations [May94, Levi95, Beck93], or by softwar e, e.g., MIPS R4x00 [Kane92], UltraSP ARC [Yung95], Alpha <ref> [Site92] </ref>. W ith softwar e TLB miss handling, there is typically some har dware assist to speed up page table traversal. Some pr o-cessors generate specialized TLB exceptions and har dware generated page table hint pointers as in MIPS R4x00 [Kane92], UltraSP ARC [Yung95], and PowerPC [Ogde95]. <p> A detailed description can be found in Huck and Hays [Huck93]. For all page table designs, 64-bit addr ess mapping information will r equire eight bytes, e.g., PowerPC [May94], Alpha <ref> [Site92] </ref>, UltraSP ARC [Yung95]. The upper right corner of Figur e 7-1 illustrates example mapping information that contains one valid bit, a 28-bit PPN (40-bit physical addr ess with 4KB pages), 12 bits of software or hardware attributes, and PAD bits for future use. <p> Complete linear page tables ar e very large and are only partially populated. Consequently, they reside in virtual address space, using page faults to populate the table dynamically ( e.g., VAX-11 [Levy82], MIPS R4000 [Kane92], Alpha <ref> [Site92] </ref>). As PTEs ar e allocated a page at a time, space over head is high if an address space usage is sparse. A separate data str ucture stores mappings to the page table itself, e.g., a multilevel tr ee of linear page tables. <p> This design is practical, as a portion of the TLB is r eserved for mappings to the page tables [Nagl94b] and the tree is rarely traversed. Alternatively, a linear page table could be backed by other data structures, e.g., a hashed page table or a forward-mapped page table <ref> [Site92] </ref>, described next. Offset VPN 000 Base VPN Array of PTEs (8 bytes each) Virtual Address Page Table . .
Reference: [Site93] <author> Richard L. </author> <title> Sites. Alpha AXP Architecture. </title> <journal> Communications of the ACM, </journal> <volume> 36(2):3344, </volume> <month> February </month> <year> 1993. </year>
Reference-contexts: Second, the page size is an ar chitectural feature that changes only during major transitions in pr ocessor ar chitecture, such as fr om VAX [Levy82] to Alpha <ref> [Site93] </ref> or from SPARC V8 [SPAR91] to SPARC V9 [SPAR94]. On the other hand, cache line size is an implementation parameter mor e easily changed. TLB miss penalty is also incr easing due to many r easons. <p> This incr eases cache pollution and r educes the likelihood of completing page table traversal within the CPU caches. Thir d, many pr ocessors support TLB miss handling in software, e.g., ZS-1 [Smit87], AMD29000 [John87], MIPS [Kane92], Alpha <ref> [Site93] </ref>, UltraSP ARC [Yung95], PA7100 [Aspr93], that incurs higher over head than har dware state machines. A small f ive cycle over head to drain the pr ocessor pipeline befor e trapping to softwar e has an opportunity cost of twenty instr uctions in a four way superscalar pr ocessor. <p> Trap driven simulation has two disadvantages. First, it only calculates the number of target TLB misses and r equires other techniques to measur e the number of TLB hits, e.g., profiling counters <ref> [Site93] </ref>, external pr obes [Nagl92]. Second, trap-driven simulation r equires separate runs for simulating multiple TLBs. It is possible to use techniques for simultaneous simulation of multiple TLBs [Matt70, Hill89, Kim91] in trap-driven simulators for TLBs that satisfy the inclusion property [Matt70]. <p> It explains why both linear and hashed page tables are viable, and why forward-mapped page tables are probably impractical as each TLB miss requires about seven memory references. Many processors now support TLB miss handling in softwar e with some har dware assist, e.g., MIPS [Kane92], Alpha <ref> [Site93] </ref>, Ul-traSPARC [Yung95], PA7100 [Aspr93]. This makes page table design an operating system issue and gives operating system designers mor e exibility than traditional har dware-defined page tables. Section 7.3 introduces the main contribution of this chapter: a clustered page table.
Reference: [Slea85] <author> D. D. Sleator and R. E. Tarjan. </author> <title> Amortized Efficiency of List Update and Paging Rules. </title> <journal> Communications of the ACM, </journal> <pages> pages 202208, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: A competitive algorithm makes decisions that r esult in performance within a constant factor of an optimal policy and competitive algorithms have been used in other contexts, e.g., <ref> [Karl88, Karl91, Slea85, Cao94] </ref>. Romer et al. r ecently pr oposed a competitive pagesize assignment policy that accounts for the cost of TLB misses and captur es reference patterns by updating counters for every base page and superpage on TLB misses [Rome95].
Reference: [Smit78a] <author> A. Smith. </author> <title> A Comparative Study of Set Associative Memory Mapping Algorithms and Their Use for Cache and Main Memory. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-4(2):121130, </volume> <month> March </month> <year> 1978. </year>
Reference-contexts: PID/VPN Offset TLB Protection Attr PPN Offset VA Violation TLB Miss Access Mode 13 1.5.2 Set-associative TLB In a set-associative TLB, as in a set-associative cache <ref> [Smit78a] </ref>, both tag and data arrays use RAMs [Wilt93]. In a typical implementation of an away set-associative TLB, a single r ow of the data RAM stor es a data words and a single r ow of the tag RAM stor es a tag words.
Reference: [Smit78b] <author> Alan J. Smith. </author> <title> Sequential Program Prefetching in Memory Hierarchies. </title> <journal> IEEE Computer, </journal> <volume> 11(12):721, </volume> <month> December </month> <year> 1978. </year>
Reference-contexts: In particular, my thesis applies to TLBs and page tables thr ee techniques borr owed fr om cache designvariable block size [Dubn92], subblocking [Lipt68, Bell74, Good83, Hill84], and subblock pr efetching <ref> [Smit78b, Hill87] </ref>. Superpage TLBs implement a variable block size design with the policy decisions on when to use superpages made by the operating system. A subblock-cache associates with each addr ess tag several data subblocks that each have their own valid bits so that they can be loaded independently .
Reference: [Smit78c] <author> Alan Jay Smith. </author> <title> Bibliography on Paging and Related Topics. </title> <booktitle> Operating Systems Review, </booktitle> <month> October </month> <year> 1978. </year>
Reference-contexts: Smith compiled a bibliography of early virtual memory r e-search that includes r esearch on segmented systems <ref> [Smit78c] </ref>. Operating systems still use segments to r epresent objects in addr ess spaces, but most curr ent operating systems tr eat all physical memory as f ixed-size frames or pages, allowing portions of segments to be pr esent in memory.
Reference: [Smit82] <author> Alan Jay Smith. </author> <title> Cache Memories. </title> <journal> Computing Surveys, </journal> <volume> 14(3):473530, </volume> <month> September </month> <year> 1982. </year>
Reference-contexts: A page table stores the translation and pr otection information and a translation lookaside buffer 1 (TLB) caches r ecently used translations to accelerate the translation pr ocess <ref> [Lee69, Smit82, Mile90] </ref>. The TLB and page table make up the address translation hierarchy that is the focus of my study . <p> I list some literatur e relating to TLBs that may be useful for futur e reference. A survey paper on cache memories by Smith also describes TLBs and r elated design parameters <ref> [Smit82] </ref>. The TLB in the V AX 11/780 system is the focus of some studies [Saty81, Clar85, Alex85, Alex86]. Their studies show that time spent in TLB miss handling is less than 5%, for the workloads (including multipr ogrammed 5 work-loads) used in early 1980s. <p> I do not describe this work further . 1.5 Mechanics of a single-page-size TLB A TLB, being a cache of virtual-to-physical addr ess translations, is constr ucted similar to a CPU data or instr uction cache <ref> [Smit82] </ref>. A pr ocessor or the memory system accesses a TLB with a virtual addr ess (VA) to translate it to a physical addr ess (PA)typically befor e or in parallel to accessing a physically-tagged cache or main memory . <p> In particular , rehash schemes are attractive for operating systems to traverse hashed page tables that stor e superpage mappings (Section 7.4.2). Split TLBs: A pr ocessor can include separate TLBs accessed in parallel for the two page sizes, similar to split instruction and data caches <ref> [Smit82] </ref>. The two TLBs can be either both set-associative, both fully-associative or one set-associative and one fully-associative. This has the disadvantage of unused har dware if pages ar e not appropriately distributed between the two page sizes. Supporting more than two page sizes in set-associative TLBs makes them further unattractive.
Reference: [Smit86] <author> Alan Jay Smith. </author> <title> Bibliography and Readings on Cache Memories. Computer Architecture News, </title> <address> 11(1):2242, </address> <month> January </month> <year> 1986. </year>
Reference-contexts: W ith the use of lar ge multi-megabyte caches [Kess91] and innovative uses of virtual addr ess spaces [Appe91a, Blum94], some applications now incur mor e TLB misses than cache misses. Fortunately , there is a lar ge body of r esearch in cache design <ref> [ e.g., Smit86, Smit91] </ref> that is lar gely applicable to TLBs alsoTLBs have a structure similar to caches (Section 1.5).
Reference: [Smit87] <author> J. E. Smith, G. E. Dermer, B. D. Vanderwarn, S. D. Klinger, C. M. Rozewski, D. L. Fowler, K. R. Scidmore, and J. P. Laudon. </author> <title> The ZS-1 Central Processor, </title> <year> 1987. </year>
Reference-contexts: This incr eases cache pollution and r educes the likelihood of completing page table traversal within the CPU caches. Thir d, many pr ocessors support TLB miss handling in software, e.g., ZS-1 <ref> [Smit87] </ref>, AMD29000 [John87], MIPS [Kane92], Alpha [Site93], UltraSP ARC [Yung95], PA7100 [Aspr93], that incurs higher over head than har dware state machines.
Reference: [Smit88] <author> J. E. Smith and A. R. Pleszkun. </author> <title> Implementing Precise Interrupts in Pipelined Processors. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-37(5):562573, </volume> <month> May </month> <year> 1988. </year>
Reference-contexts: Direct-mapped TLBs do not r equire the multiplexors [Hill88] and the data can be used befor e the tag array access is complete. If tag comparison fails subsequently , the processor can undo the instr uction (s) and cause a pr ecise interr upt <ref> [Smit88, W ang93] </ref>. Figur e 1-5 shows column multiplexors associated with the RAMs.
Reference: [Smit91] <author> Alan Jay Smith. </author> <title> Second Bibliography on Cache Memories. Computer Architecture News, </title> <address> 19(4):154182, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: W ith the use of lar ge multi-megabyte caches [Kess91] and innovative uses of virtual addr ess spaces [Appe91a, Blum94], some applications now incur mor e TLB misses than cache misses. Fortunately , there is a lar ge body of r esearch in cache design <ref> [ e.g., Smit86, Smit91] </ref> that is lar gely applicable to TLBs alsoTLBs have a structure similar to caches (Section 1.5).
Reference: [So88] <author> Kimming So and Rudolph N. Rechtschaffen. </author> <title> Cache Operations by MRU Change. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-37(6), </volume> <month> June </month> <year> 1988. </year>
Reference-contexts: The operating system often consults page table modified bits to ush dirty pages to disk and must instead use TLB probes to get the correct state. 15 true LRU (least r ecently used) replacement policy for lar ge set sizes. Pseudo-LRU algorithms, that approximate LRU with limited information <ref> [Kess89, So88, Devi92] </ref>, ar e often used. Policies that do not use reference information, e.g., RANDOM [Kane89], are cheaper to implement but incur more TLB misses. Section 2.6 describes the pseudo-LRU r eplacement policy I use in my TLB simulations.
Reference: [SPAR91] <author> SPARC International Inc. </author> <title> The SPARC Architecture Manual, </title> <type> Version 8, </type> <year> 1991. </year>
Reference-contexts: Second, the page size is an ar chitectural feature that changes only during major transitions in pr ocessor ar chitecture, such as fr om VAX [Levy82] to Alpha [Site93] or from SPARC V8 <ref> [SPAR91] </ref> to SPARC V9 [SPAR94]. On the other hand, cache line size is an implementation parameter mor e easily changed. TLB miss penalty is also incr easing due to many r easons. <p> I use workingset based pagesize assignment (described in Section 6.1) in my work [T all92, Tall94a]. Three styles of page tables ar e popular 6 linear ( e.g., VAX [Levy82]), forwar d-mapped (e.g., SPARC <ref> [SPAR91] </ref>), and hashed/inverted ( e.g., PowerPC [May94], IBM System/38 [IBM78]). Many forwar d-mapped page table implementations and guar ded page tables [Lied95] support certain superpage sizes at their intermediate nodes. <p> The traversal can be done by har dware, e.g., SPARC Reference MMU <ref> [SPAR91] </ref>, some PowerPC implementations [May94, Levi95, Beck93], or by softwar e, e.g., MIPS R4x00 [Kane92], UltraSP ARC [Yung95], Alpha [Site92]. W ith softwar e TLB miss handling, there is typically some har dware assist to speed up page table traversal. <p> Foxtrot hides these page table changes from the rest of the operating system with wrapper functions for the read_pte and write_pte routines in So-laris. Foxtrot implements this for superSP ARC processors [Blan92] with SP ARC Reference MMU <ref> [SPAR91] </ref> and har dware TLB miss handling. This technique is also applicable for other processors or page table structures. Tapeworm II [Uhli94], for example, implements trap-driven simulation for a MIPS RX000 pr ocessor with linear page tables. <p> For example, MIPS R4x000 supports seven page sizes from 4KB to 16MB [Kane92], UltraSPARC [Yung95] and Alpha [Bann95] support four pages sizes of 8KB, 64KB, 512KB, and 4MB. Others include ET A-10 [ETA 86], ARM6 [Adva93], and SPARC Reference MMU <ref> [SPAR91] </ref>. Many also include a default TLB miss handler (in hardware or software) that can load superpage mappings in the TLB. <p> An alternate solution, used by many curr ent microprocessors, is to stor e explicitly superpage mappings in the page table ( e.g., SPARC reference MMU <ref> [SPAR91] </ref>) that the TLB miss handler can load into the TLB without further checking. Storing superpage mappings in the page table has two advantages. First, it is mor e efficient as the operating system does compatibility checks only during page faults, which ar e less fr e-quent than TLB misses. <p> The leaf nodes stor e PTEs while intermediate nodes store pointers to the next level, page table pointers (PTPs) ( e.g., SPARC Reference MMU <ref> [SPAR91] </ref>). A 64-bit address space extends the number of levels to seven (a 32-bit address space uses three). Forward-mapped page tables are impractical for 64-bit address spaces, as an overhead of seven memory accesses for every TLB miss is not acceptable. Ther e are techniques to short-circuit some levels.
Reference: [SPAR94] <author> SPARC International Inc. </author> <title> The SPARC Architecture Manual, </title> <type> Version 9, </type> <year> 1994. </year>
Reference-contexts: Second, the page size is an ar chitectural feature that changes only during major transitions in pr ocessor ar chitecture, such as fr om VAX [Levy82] to Alpha [Site93] or from SPARC V8 [SPAR91] to SPARC V9 <ref> [SPAR94] </ref>. On the other hand, cache line size is an implementation parameter mor e easily changed. TLB miss penalty is also incr easing due to many r easons.
Reference: [SPEC91] <institution> SPEC. </institution> <note> (entire issue). SPEC Newsletter, 3(4), </note> <month> December </month> <year> 1991. </year>
Reference-contexts: I first describe the workloads and then discuss the consequences of concentrating on these workloads. Nasa7, compress, wave5, spice, and gcc are from the SPEC92 suite <ref> [SPEC91] </ref>; fftpde is a NAS benchmark [Bail91] operating on a 64X64X64 matrix; mp3d and pthor are uniprocessor versions from the SPLASH benchmark suite [Sing92]; coral [Rama93] is a deductive database executing a nested loop join; ML [Appe91b] is executing a str ess test on the garbage collector [Repp94].
Reference: [Sriv94] <author> Amitabh Srivastava and Alan Eustace. </author> <title> ATOM A System for Building Customized Program Analysis Tools. </title> <booktitle> In Proc. of the SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 196205, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Trap-driven simulation is a very fast simulation technique when the miss ratio is very low [Uhli94, Lebe95], as it often is for TLBs. Other r esearchers instrument executables and operating systems to perform memory system simulations, e.g., Active Memory [Lebe95], Epoxie [Chen93b, Chen93a], and ATOM <ref> [Sriv94] </ref>. I do not use this technique as I did not have access to an instrumentation system for Solaris that worked on dynamically linked libraries, operating system references, and supported multipr ogramming.
Reference: [Tall92] <author> Madhusudhan Talluri, Shing Kong, Mark D. Hill, and David A. Patterson. </author> <title> Tradeoffs in Supporting Two Page Sizes. </title> <booktitle> In Proc. of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 415424, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Extra paging in small-memory machines fr om use of lar ger pages makes the lar ge pages unattractive. Incr easing the page size from 4KB to 64KB, for example, doubles the working set size for some pr ograms <ref> [Tall92] </ref> and can increase paging. Second, the page size is an ar chitectural feature that changes only during major transitions in pr ocessor ar chitecture, such as fr om VAX [Levy82] to Alpha [Site93] or from SPARC V8 [SPAR91] to SPARC V9 [SPAR94]. <p> Page table management algorithms in a multi-thr eaded multiprocessor operating system [Bala92, Khal94] also af fect system performance, however, they execute infr equently compared to TLB misses. 1.4 My Previous Work A paper titled Tradeoffs in Supporting Two Page Sizes by Talluri et al. <ref> [Tall92] </ref> first addresses the costs and benefits of using lar ge page sizes. Using lar ger page sizes increases the working set size but r educes the number of TLB misses. <p> The simulator has access to such information from the operating system page table. T racedriven simulation techniques can simulate approximate pagesize assignment and physical memory allocation, e.g., as I did for a prior paper <ref> [Tall92] </ref>. Trap driven simulation has two disadvantages. First, it only calculates the number of target TLB misses and r equires other techniques to measur e the number of TLB hits, e.g., profiling counters [Site93], external pr obes [Nagl92]. Second, trap-driven simulation r equires separate runs for simulating multiple TLBs. <p> Foxtrot uses page reservation, described in Section 6.2.5, to allocate physical memory such that base pages are often properly placed. 28 Chapter 3 Superpage TLBs This chapter evaluates the use of superpages <ref> [Tall92, Mogu93, Tall94a] </ref> to increase TLB reach. Superpages use the same linear addr ess space as conventional paging, have sizes that must be power-of-two multiples of the base page size, and must be aligned in both virtual and physical memory [Tall94a]. <p> The costs of using superpages include a) over head in monitoring the r eference pattern of the workload, b) increased internal fragmentation, i.e., lar ger working set size and incr eased page initialization costs <ref> [Tall92] </ref>, c) page pr omotion costs (Section 6.2.3), and d) incr ease in TLB miss penalty (Chapter 7). Pagesize assignment can be either static or dynamic and this section describes two classes of dynamic policiesworking set thr eshold [Tall92, Tall94a] and competitive [Rome95]. <p> Pagesize assignment can be either static or dynamic and this section describes two classes of dynamic policiesworking set thr eshold <ref> [Tall92, Tall94a] </ref> and competitive [Rome95]. A static pagesize assignment policy makes the decision once and fixes the page size over the life of the mapping.
Reference: [Tall93] <author> Madhusudhan Talluri, Yousef A. Khalidi, Dock Williams, and Vikram Joshi. </author> <title> Virtual Memory Computer System Address Translation Mechanism that Supports Multiple Page Sizes. Patent application filed, Serial No. </title> <institution> 08/139,549, Sun Microsystems, </institution> <month> October </month> <year> 1993. </year> <note> (Accepted 1995). </note>
Reference: [Tall94a] <author> Madhusudhan Talluri and Mark D. Hill. </author> <title> Surpassing the TLB performance of Superpages with Less Operating System Support. </title> <booktitle> In Proc. of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 171182, </pages> <address> San Jose, CA, </address> <month> Oc-tober </month> <year> 1994. </year>
Reference-contexts: Romer et al. [Rome95] study the use of competitive algorithms for pagesize assignment among multiple superpage sizes. I use workingset based pagesize assignment (described in Section 6.1) in my work <ref> [T all92, Tall94a] </ref>. Three styles of page tables ar e popular 6 linear ( e.g., VAX [Levy82]), forwar d-mapped (e.g., SPARC [SPAR91]), and hashed/inverted ( e.g., PowerPC [May94], IBM System/38 [IBM78]). <p> Foxtrot uses page reservation, described in Section 6.2.5, to allocate physical memory such that base pages are often properly placed. 28 Chapter 3 Superpage TLBs This chapter evaluates the use of superpages <ref> [Tall92, Mogu93, Tall94a] </ref> to increase TLB reach. Superpages use the same linear addr ess space as conventional paging, have sizes that must be power-of-two multiples of the base page size, and must be aligned in both virtual and physical memory [Tall94a]. <p> Superpages use the same linear addr ess space as conventional paging, have sizes that must be power-of-two multiples of the base page size, and must be aligned in both virtual and physical memory <ref> [Tall94a] </ref>. Superpages, however, are not universally useful and ther e is an inher ent tradeoff in using superpages [T all92]. Superpages decr ease the number of TLB misses but increase memory demand 1 due to internal fragmentation. <p> Pagesize assignment can be either static or dynamic and this section describes two classes of dynamic policiesworking set thr eshold <ref> [Tall92, Tall94a] </ref> and competitive [Rome95]. A static pagesize assignment policy makes the decision once and fixes the page size over the life of the mapping.
Reference: [Tall94b] <author> Madhusudhan Talluri and Yousef A. Khalidi. </author> <title> Apparatus and Method for Efficient Sharing of Virtual Memory Translations. Patent application filed, Serial No. </title> <institution> 08/333,487, Sun Microsystems, </institution> <month> November </month> <year> 1994. </year> <month> 185 </month>
Reference: [Tall95] <author> Madhusudhan Talluri, Mark D. Hill, and Yousef A. Khalidi. </author> <title> A New Page Table for 64-bit Address Spaces. </title> <booktitle> In (To appear) Proceedings of 15th ACM Symposium on Operating System Principles, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: While I suggest some pagesize assignment policies and algorithms for the various mechanisms, this ar ea merits further operating system r esearch. A paper titled A New Page Table for 64-bit Addr ess Spaces by Talluri et al. <ref> [Tall95] </ref> reviews the suitability of conventional page tableslinear , forwar d-mapped and hashedfor 64-bit address spaces and superpage mappings.
Reference: [Tayl81] <author> Mitchell B. Taylor. </author> <title> Efficient Memory allocation with the buddy algorithm. </title> <institution> Motorola, </institution> <month> November </month> <year> 1981. </year>
Reference: [Tayl90] <author> George Taylor, Peter Davies, and Michael Farmwald. </author> <title> The TLB Slice - A Low-Cost HighSpeed Address Translation Mechanism. </title> <booktitle> In Proc. of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 355363, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: I have not explor ed this interaction or its ef fect on system performance. 6.3.6 Page Coloring Page coloring <ref> [Tayl90, Kess92, Chiu92] </ref> also car efully selects physical pages for virtual addresses but for a dif ferent purpose and in a dif ferent way than page r eservation.
Reference: [Tell90] <author> Patricia J. Teller. </author> <title> Translation-Lookaside Buffer Consistency. </title> <journal> IEEE Computer, </journal> <volume> 23(6):2636, </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: Some processors support TLB miss handling in softwar e and Nagle et al discuss issues in softwar e TLB miss handling using MIPS pr ocessors as examples [Nagl94b]. In multiprocessor systems TLB coher ence becomes an issue. T eller describes many strategies for maintaining TLB coher ence <ref> [Tell90] </ref>. Many operating systems use a conservative TLB shootdown algorithm, e.g., [Blac89]. The SPUR [W ood86] and Fugu [Mack94] machines combine TLB coher ence with existing cache coher ence mechanisms. <p> TLB miss handlers both r ead (load translation info) and write the page table (update r efer-ence/modified bits). Third, all the TLBs in a multiprocessor must be kept consistent with page table updates, requiring a TLB consistency algorithm ( e.g., TLB shootdown <ref> [Blac89, Tell90] </ref>) as part of the synchr onization protocol. Addition of superpage and partialsubblock PTEs complicates the synchr onization protocol. In practice, certain kinds of TLB-TLB and TLB-PTE inconsistencies are not fatal to the operation of the system and can be allowed.
Reference: [Thak86] <author> Shreekant S. Thakkar and Alan E. Knowles. </author> <title> A High-Performance Memory Management Scheme. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 822, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: Many forwar d-mapped page table implementations and guar ded page tables [Lied95] support certain superpage sizes at their intermediate nodes. Hashed page tables ar e being increasingly used to support sparse 64-bit addr ess <ref> [Houd68, Abra81, Thak86, Rose92, Huck93, May94] </ref> but none support superpage mappings. <p> Rehash schemes: The TLB can first index assuming a base page and on a miss can r epeat the access, next cycle, using the superpage index. Similar schemes have been used to impr ove the performance of set-associative CPU caches [Agar88, Kess89, Agarwal93] and page tables <ref> [Thak86, May94] </ref>. The TLB access takes a variable number of cycles and can complicate pipeline design. If TLB access is in the critical path, increasing the TLB hit time for superpage mappings decreases their usefulness. <p> Software TLBs (e.g., swTLB [Huck93], TSB [Y ung94], STLB [Bala94], PowerPCs page table [May94]) eliminate a hashed page tables next pointers by pre-allocating few PTEs per bucket. be viewed as memory-r esident level-two TLBs with overf low handled in many ways, e.g., hash-rehash schemes <ref> [Agar88, Thak86] </ref> or set r eplacement [May94]. While softwar e TLBs can be the native page table str ucture, e.g., page tables for the PowerPC, they ar e more popular and effective alsoas a cache of r ecently used translations.
Reference: [Thom74] <author> K. Thompson and D. M. Ritchie. </author> <title> The UNIX Time-Sharing System. </title> <journal> Communications of the ACM, </journal> <volume> 17(7):365375, </volume> <month> July </month> <year> 1974. </year>
Reference-contexts: Operating system support for paged virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX <ref> [Thom74, Bach86, Lef f90] </ref>, VMS [Levy82], NT [Cust93], MACH [Acce86, Rash88], OS/2 [Koga88]). Most facets of paged virtual memory operating system policies and mechanisms r equire modif ications to support superpages ef fec-tively. A new policy pagesize assignment and upto six new mechanisms may also be required. <p> Operating system support for virtual memory with a single fixed page size is substantial but well-understood ( e.g., UNIX <ref> [Thom74, Bach86, Leff90, Ging87b] </ref>, VMS [Levy82], NT [Cust93], MACH [Acce86, Rash88], OS/2 [Koga88]). <p> When TLBs do not support superpages or subblocking, page tables can use superpage or partialsubblock techniques to r educe page table size by an order of magnitude (Table 7-6) Operating systems using a private addr ess space model, e.g., UNIX <ref> [Thom74] </ref>, maintain one page table per pr ocess or associate a pr ocess identifier with each PTE in a shar ed page table. Operating systems using a private addr ess space model must support mappings for 93 shared objects, e.g., shared libraries [Ging87a].
Reference: [Turn81] <author> R. Turner and H. Levy. </author> <title> Segmented FIFO Page Replacement. </title> <booktitle> In Proc. of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 4851, </pages> <year> 1981. </year>
Reference: [Uhli94] <author> Richard Uhlig, David Nagle, Trevor Mudge, and Stuart Sechrest. Tapeworm II: </author> <title> A New Method for Measuring OS Effects on Memory Architecture Performance. </title> <booktitle> In Proc. of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 132144, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Trap-driven simulation can be faster than tracedriven simulation, as it does not have to pr o-cess references that are target TLB hits, but cannot measure the number of TLB hits. Wisconsin Wind Tunnel [Rein93] and Tapeworm II <ref> [Uhli94] </ref> ar e examples of other systems that use trap-driven simulation for memory system simulations. <p> Foxtrot implements this for superSP ARC processors [Blan92] with SP ARC Reference MMU [SPAR91] and har dware TLB miss handling. This technique is also applicable for other processors or page table structures. Tapeworm II <ref> [Uhli94] </ref>, for example, implements trap-driven simulation for a MIPS RX000 pr ocessor with linear page tables. Further , the technique extends to support multipr ocessor TLB simulationsby maintaining per processor page tables. Foxtrot implements the uniprocessor version only. Trap-driven simulation for TLBs has thr ee advantages over tracedriven simulation. <p> Thus, Foxtr ot is unable to simulate kernel TLB misses. It simulates only user TLB misses and kernel TLB misses incurr ed due to data copying during file I/O. Trap-driven simulation is a very fast simulation technique when the miss ratio is very low <ref> [Uhli94, Lebe95] </ref>, as it often is for TLBs. Other r esearchers instrument executables and operating systems to perform memory system simulations, e.g., Active Memory [Lebe95], Epoxie [Chen93b, Chen93a], and ATOM [Sriv94].
Reference: [Wada92] <author> Tomohisa Wada, Suresh Rajan, and Steven A. Przyblski. </author> <title> An Analytical Access Time Model for On-Chip Cache Memories. </title> <journal> IEEE Journal of Solid State Circuits, </journal> <volume> 27(8):11471156, </volume> <month> August </month> <year> 1992. </year>
Reference-contexts: I assume valid bits to have the same area as a CAM cell as I use CAM cells in partial-subblock TLBs (Section 5.1.2). In practice, valid bits are smaller and my model overestimates the area. 20 is an extension of the analytical model pr oposed by Wada et al. <ref> [Wada92] </ref>. The model derives simple equations that pr edict access and cycle times as a function of various cache and VLSI process parameters. I extend the model in several ways: I assume the number of tag and data bits as described in Section 2.2 for a 64-bit addr ess space. <p> RAM designers commonly divide a lar ge RAM array into smaller blocks to improve cycle time and layout aspect ratio. Similar techniques ar e applicable here but this thesis does not discuss details of these or other optimizations <ref> [Wada92, Wilt93] </ref>. One simple optimization for fully-associative subblock TLBs is to split the RAM array into two halves and place the two halves on either side of the tag array. While this requires additional drivers, it reduces access time. In my model, I assume a monolithic RAM array.
Reference: [Wang93] <author> Chia-Jiu Wang and Frank Emnett. </author> <title> Implementing Precise Interruptions in Pipelines RISC Processors. </title> <journal> IEEE Micro, </journal> <volume> 13(4):3643, </volume> <month> August </month> <year> 1993. </year>
Reference: [West88] <author> Neil Weste and Kamran Eshraghian. </author> <title> Principles of CMOS VLSI Design. </title> <publisher> Addison Wesley, </publisher> <year> 1988. </year>
Reference-contexts: I illustrate only static designs thr oughout the thesis. Dynamic designs ar e mor e popular. They primarily dif fer by adding pr echarge and dischar ge transistors <ref> [West88] </ref>. Figure A-1 shows a conventional CAM cell that implements the XNOR function [W est88], a 6-transistor RAM cell, and a CAM cell wor d composed of x CAM cells. Multiple such CAM words combine to form a CAM arraybitlines pass thr ough all the CAM wor ds.
Reference: [Whee92] <author> Bob Wheeler and Brian N. Bershad. </author> <title> Consistency Management for Virtually Indexed Caches. </title> <booktitle> In Proc. of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 124136, </pages> <address> Boston MA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: TLB access time is an important metric as TLBs are often in the cache-access critical path. Cache consistency management by the operating system has complicated ef forts to remove the TLB fr om the critical path using virtually-tagged caches <ref> [Whee92] </ref>. Physically-tagged caches continue to be common. Second, the tr end toward wider superscalar pr ocessor implementations [Joup89] r equires TLBs to support multiple translations per cycle thr ough multi-porting or r eplication. TLBs that support multiple transactions per cycle are slower to access and occupy lar ger chip area. <p> A synonym table accesses PTEs using a physical address as the key, e.g., during page replacement to collect reference and modified information or during PTE insertion to determine cacheability of aliases in virtually-indexed caches <ref> [Whee92] </ref>. This section f irst describes the basic str ucture used for synonym tables and then addr esses how to store superpage and partialsubblock PTEs in the synonym table.
Reference: [Wilk92] <author> J. Wilkes and B. Sears. </author> <title> A comparison of protection lookaside buffers and the PA-RISC protection architecture. </title> <type> Technical Report HPL-92-55, </type> <institution> Hewlett-Packard Laboratories, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: If segmentation is visible to the hardware, base page protection and attributes may be enhanced thr ough support for segment protections, pr otection lookaside buf fers [Kold92], page-gr oups <ref> [Wilk92] </ref>, or capabilities 9 [Fabr74]. Various researchers have studied TLB design and extensions to impr ove TLB performance that may complement use of superpages or subblocking. I list some literatur e relating to TLBs that may be useful for futur e reference.
Reference: [Wilt93] <author> Steven J. E. Wilton and Norman P. Jouppi. </author> <title> An Enhanced Access and Cycle Time Model for On-Chip Caches. </title> <note> WRL Research Report 93/5, </note> <institution> DEC Western Research Lab, </institution> <year> 1993. </year>
Reference-contexts: Section 2.2 describes the ar ea model adapted fr om Mul-der s model [Muld91] and Section 2.3 describes the access time model adapted fr om Jouppi and Wiltons model <ref> [Wilt93] </ref>. In Chapters 3 to 5, I compar e TLB configurations of comparable chip area to show that the new TLB ar chitectures not only impr ove execution time but often result in a TLB with faster access time 3 . <p> PID/VPN Offset TLB Protection Attr PPN Offset VA Violation TLB Miss Access Mode 13 1.5.2 Set-associative TLB In a set-associative TLB, as in a set-associative cache [Smit78a], both tag and data arrays use RAMs <ref> [Wilt93] </ref>. In a typical implementation of an away set-associative TLB, a single r ow of the data RAM stor es a data words and a single r ow of the tag RAM stor es a tag words. <p> The chip ar ea model extends Mulder s model [Muld91] to accommodate superpage and subblock TLBs (Section 2.2) and the access time model extends Wilton and Jouppis model <ref> [Wilt93] </ref> (Section 2.3). Section 2.4 describes ten workloads I use thr oughout the thesis. I use execution time speedup as the performance metric as explained in Section 2.5. Section 2.6 describes the TLB replacement policy I assume. <p> In r eal implementations cir cuit analysis tools, such as spice, pr edict TLB access time accurately. Due to lack of detailed cir cuit implementations and the lar ge number of TLB configurations studied, I use an analytical model pr oposed by Wilton and Jouppi <ref> [Wilt93] </ref>, which 1. The original model assumes tag valid bits to occupy a smaller area than CAM cells (2 x 1) vs. (2 x 2) times a RAM cell. <p> The model does not include in fully-associative TLBs an output multiplexor needed to implement MMU bypass mode or superpage and partialsubblock TLB physical addr ess generation. 21 Most importantly, the model has not been validated against any spice simulations. Many parts of the original model wer e validated <ref> [Wilt93] </ref> for gr eater than 100 r ows. I, however, use the same RAM model even when the number of rows is less than 100. <p> RAM designers commonly divide a lar ge RAM array into smaller blocks to improve cycle time and layout aspect ratio. Similar techniques ar e applicable here but this thesis does not discuss details of these or other optimizations <ref> [Wada92, Wilt93] </ref>. One simple optimization for fully-associative subblock TLBs is to split the RAM array into two halves and place the two halves on either side of the tag array. While this requires additional drivers, it reduces access time. In my model, I assume a monolithic RAM array. <p> The block offset bits may be predecoded in the preceding CPU pipeline stage by combining a decoder with pipeline latches or logic as suggested to me by Robert Yung, Sun Microsystems Laboratories. 3. This is not true for caches where the data RAM is often on the critical path <ref> [Wilt93] </ref>. Subblock-cache typically store the subblock valid bits along with the tag.
Reference: [Wood86] <author> David A. Wood, S. J. Eggers, G. Gibson, Mark D. Hill, J. Pendleton, S. A. Ritchie, Randy H. Katz, and David A. Patterson. </author> <title> An In-Cache Address Translation Mechanism. </title> <booktitle> In Proc. of the 13th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 158166, </pages> <address> Tokyo Japan, </address> <month> June </month> <year> 1986. </year>
Reference: [Yoo93] <author> Hyuck Yoo and Tom Rogers. </author> <title> UNIX Kernel Support for OLTP Performance. </title> <booktitle> In 1993 Winter US-ENIX Conference, </booktitle> <pages> pages 241247, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Ther e are at least thr ee drawbacks to this metric. First, and most important, it ignor es that some page table data may still be in cache, particularly for page tables that ar e smaller and stor e PTEs to exploit spatial locality. Yoo and Rogers <ref> [Yoo93] </ref>, for example, observed a 10% impr ovement in execution time mostly due to cache/TLB ef fects of r educing the page table size for a commer cial database workload.
Reference: [Youn89] <author> Michael W. Young. </author> <title> Exporting a User Interface to Memory Management from a Communication-Oriented Operating System. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, Carnegie Mellon University, </institution> <month> November </month> <year> 1989. </year>
Reference-contexts: This allows implementation of custom user defined pagesize assignment policies that exploit pr ograms knowledge of their access pattern. Some operating systems have similarly exported mechanisms such as page r eplacement <ref> [Youn89, Hart92] </ref>, scheduling [Ande92], and cache coher ence [Rein94]. In summary, operating systems have a choice of a variety of page-assignment policies and different workloads may pr efer dif ferent policies. The key to operating system design is to identify and implement the mechanisms that can support many alternate policies.
Reference: [Yung94] <author> Robert Yung and Leslie Kohn. </author> <title> UltraSPARC Programmers Reference Manual. </title> <publisher> Sun Microsys-tems Inc., </publisher> <year> 1994. </year>
Reference-contexts: Memory system designers ar e addr essing the incr easing TLB miss penalty with mor e levels in the addr ess translation hierar chy by using a second-level software TLB , e.g., swTLB [Huck93], TSB <ref> [Yung94] </ref>, STLB [Bala94]. My thesis looks at incr easing TLB r each through use of variable block size and subblock-ing techniques to map mor e addr ess space per TLB block. <p> Readers can choose different weights for the workloads if the desired workload mix is different from my assumptions. 2.6 TLB Replacement Policy All my TLB simulations use a pseudo-LRU r eplacement algorithmGo-Down-Stack (GODS) policy [Devi92]that some commer cial pr ocessors also use, e.g., UltraSPARC <ref> [Yung94] </ref>. Each TLB block includes one extra bit, the used bit that is set on TLB hits. <p> The cost of each sub-operation depends on operating system str ucture, e.g., a page table manager could batch multiple TLB shootdowns, and available har dware support, e.g., hardware support for ef ficient copying <ref> [Yung94] </ref>. 2.
Reference: [Yung95] <author> Robert Yung. </author> <title> UltraSPARC-I (Spitfire) Architecture. </title> <type> Technical report, </type> <institution> Sun Microsystems, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: This incr eases cache pollution and r educes the likelihood of completing page table traversal within the CPU caches. Thir d, many pr ocessors support TLB miss handling in software, e.g., ZS-1 [Smit87], AMD29000 [John87], MIPS [Kane92], Alpha [Site93], UltraSP ARC <ref> [Yung95] </ref>, PA7100 [Aspr93], that incurs higher over head than har dware state machines. A small f ive cycle over head to drain the pr ocessor pipeline befor e trapping to softwar e has an opportunity cost of twenty instr uctions in a four way superscalar pr ocessor. <p> Superpages have sizes that ar e power of-two multiples of the base page size and must be aligned in both virtual and physical memory (Chapter 3). Many pr ocessors now support su-perpages, e.g., MIPS [Kane92], UltraSPARC <ref> [Yung95] </ref>, Alpha [Bann95], PowerPC [Silh93], HP-PA RISC [Hunt95]. A fully-associative TLB can easily include support for superpages. An example is the MIPS R4000, which supports a 4KB base page size and superpages of 16KB, 64KB, 256KB, 1MB, 4MB, and 16MB with a fully-associative TLB. <p> The partialsubblock design optimizes a subblock design using specific knowledge about the str ucture and content of the data stor ed in a TLB. A key motivation for my thesis was the intr oduction of superpage support in many microprocessor TLBs, e.g., MIPS [Kane92], UltraSP ARC <ref> [Yung95] </ref>, Alpha [Bann95], PowerPC [Silh93], HP-PA RISC [Hunt95]. Commer cial operating systems I am awar e of, however , do not support general use of superpage mappings. Many operating systems include special mechanisms to use lar ge superpages for unpageable memory and devices. <p> The traversal can be done by har dware, e.g., SPARC Reference MMU [SPAR91], some PowerPC implementations [May94, Levi95, Beck93], or by softwar e, e.g., MIPS R4x00 [Kane92], UltraSP ARC <ref> [Yung95] </ref>, Alpha [Site92]. W ith softwar e TLB miss handling, there is typically some har dware assist to speed up page table traversal. Some pr o-cessors generate specialized TLB exceptions and har dware generated page table hint pointers as in MIPS R4x00 [Kane92], UltraSP ARC [Yung95], and PowerPC [Ogde95]. <p> MIPS R4x00 [Kane92], UltraSP ARC <ref> [Yung95] </ref>, Alpha [Site92]. W ith softwar e TLB miss handling, there is typically some har dware assist to speed up page table traversal. Some pr o-cessors generate specialized TLB exceptions and har dware generated page table hint pointers as in MIPS R4x00 [Kane92], UltraSP ARC [Yung95], and PowerPC [Ogde95]. Further , software TLB miss handlers incur trap entry/exit costs not shown her e. Chapter 7 describes popular page table data str uctures and their access times. <p> Superpages decr ease the number of TLB misses but increase memory demand 1 due to internal fragmentation. Thus, the key to using superpage TLBs is an operating system that uses superpages wher e appropriate and base pages elsewhere. Nearly every current microprocessor supports superpages, e.g., MIPS [Kane92], UltraS-PARC <ref> [Yung95] </ref>, Alpha [Bann95], PowerPC [Silh93], HP-P A RISC [Hunt95]. The MIPS R4000 [Kane92], for example, supports a 4KB base page size and superpages of 16KB, 64KB, 256KB, 1MB, 4MB, and 16MB. However, I am not aware of any operating system that uses superpages in a general manner. <p> These TLBs ar e usually fully-associative due to the dif ficulty of building set-associative TLBs that support multiple page sizes (Section 3.2.2). For example, MIPS R4x000 supports seven page sizes from 4KB to 16MB [Kane92], UltraSPARC <ref> [Yung95] </ref> and Alpha [Bann95] support four pages sizes of 8KB, 64KB, 512KB, and 4MB. Others include ET A-10 [ETA 86], ARM6 [Adva93], and SPARC Reference MMU [SPAR91]. Many also include a default TLB miss handler (in hardware or software) that can load superpage mappings in the TLB. <p> When loading a mapping into the TLB, the PTE format can include the MASK field, the TLB miss handler can r ead the MASK from a special register, e.g., MIPS R4000 [Kane92], or har dware can decode the size attribute in the PTE, e.g., UltraSPARC <ref> [Yung95] </ref>. PID/VPBN Offset TLB Protection Attr PPBN Offset VA Violation Soff. Soff =&gt; Superpage Offset TLB Miss Soff. Size 33 The size field (SZ), read from the data array along with the attributes, controls physical address generation. <p> It explains why both linear and hashed page tables are viable, and why forward-mapped page tables are probably impractical as each TLB miss requires about seven memory references. Many processors now support TLB miss handling in softwar e with some har dware assist, e.g., MIPS [Kane92], Alpha [Site93], Ul-traSPARC <ref> [Yung95] </ref>, PA7100 [Aspr93]. This makes page table design an operating system issue and gives operating system designers mor e exibility than traditional har dware-defined page tables. Section 7.3 introduces the main contribution of this chapter: a clustered page table. <p> A detailed description can be found in Huck and Hays [Huck93]. For all page table designs, 64-bit addr ess mapping information will r equire eight bytes, e.g., PowerPC [May94], Alpha [Site92], UltraSP ARC <ref> [Yung95] </ref>. The upper right corner of Figur e 7-1 illustrates example mapping information that contains one valid bit, a 28-bit PPN (40-bit physical addr ess with 4KB pages), 12 bits of software or hardware attributes, and PAD bits for future use. <p> They may r eside between the TLB and a native page table to r educe average access time for a slow native page table, e.g., a forward-mapped page table <ref> [Huck93, Bala94, Yung95] </ref>. The extensions I develop for hashed page table, described next, are applicable to inverted page tables and softwar e TLBs also, as I show in Section 7.4.7. <p> This approach maybe attractive for storing superpage PTEs in software TLBs where a superscalar processor can execute a TLB miss handler for two page sizes in comparable time to a single page size TLB miss handler <ref> [Kong92, Yung95, Khal93a] </ref>. There are also some superpage strategies that only work for specific page tables. Linear Intermediate Nodes. Linear page tables that use a multilevel tr ee structure can store superpage PTEs at intermediate tree nodes.
References-found: 192

