URL: ftp://ftp.ics.uci.edu/pub/CSP-repository/papers/top-param-time-space-tradeoff.ps
Refering-URL: http://www.ics.uci.edu/~mlearn/MLPapers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: dechter@ics.uci.edu  
Title: Topological Parameters for time-space tradeoff  
Author: Rina Dechter 
Address: Irvine  
Affiliation: Information and Computer Science University of California,  
Abstract: In this paper we propose a family of algorithms combining tree-clustering with conditioning that trade space for time. Such algorithms are useful for reasoning in probabilistic and deterministic networks as well as for accomplishing optimization tasks. By analyzing the problem structure it will be possible to select from a spectrum the algorithm that best meets a given time-space specifica tion.
Abstract-found: 1
Intro-found: 1
Reference: [ Arnborg et al., 1987 ] <author> S.A. Arnborg, D.G. Corneil, and A. Proskurowski. </author> <title> Complexity of finding embed-dings in a k-tree. </title> <journal> SIAM Journal of Discrete Mathematics., </journal> <volume> 8 </volume> <pages> 277-284, </pages> <year> 1987. </year>
Reference-contexts: computation can be accomplished using any one of the following time and space bounds b i , where b i = (O (n exp (r i )) time; and O (n exp (s i )) space). 2 We know that finding the smallest tree width of a graph is NP-hard <ref> [ Arnborg, 1985; Arnborg et al., 1987 ] </ref> ; nevertheless, many greedy ordering algorithms provide useful upper bounds that can be inspected in linear time. We denote by wfl s the smallest tree width among all the tree embeddings of G whose separators are of size s or less.
Reference: [ Arnborg, 1985 ] <author> S.A. Arnborg. </author> <title> Efficient algorithms for combinatorial problems on graphs with bounded decomposability a survey. </title> <journal> BIT, </journal> <volume> 25 </volume> <pages> 2-23, </pages> <year> 1985. </year>
Reference-contexts: computation can be accomplished using any one of the following time and space bounds b i , where b i = (O (n exp (r i )) time; and O (n exp (s i )) space). 2 We know that finding the smallest tree width of a graph is NP-hard <ref> [ Arnborg, 1985; Arnborg et al., 1987 ] </ref> ; nevertheless, many greedy ordering algorithms provide useful upper bounds that can be inspected in linear time. We denote by wfl s the smallest tree width among all the tree embeddings of G whose separators are of size s or less.
Reference: [ Bacchus and Grove, 1995 ] <author> F Bacchus and A. Grove. </author> <title> Graphical models for preference and utility. </title> <booktitle> In Uncertainty in Artificial Intelligence (UAI-95), </booktitle> <pages> pages 3-10, </pages> <year> 1995. </year> [ <editor> D. H. Krantz and Tversky, 1976 ] P. Suppes D. H. Krantz, R.D. Luce and A. Tver-sky. </editor> <booktitle> Foundations of measurements, </booktitle> <publisher> academic press. </publisher> <year> 1976. </year>
Reference: [ Darwiche, 1995 ] <author> A Darwiche. </author> <title> Conditioning algorithms for exact and approximate inference in causal networks. </title> <booktitle> In Uncertainty in Artificial Intelligence (UAI-95), </booktitle> <pages> pages 99-107, </pages> <year> 1995. </year>
Reference-contexts: When the moral graph can be decomposed to nonsep-arable components, the conditioning method can be modified to be time exponential in the maximal cut-set in each component only <ref> [ Peot and Shachter, 1991; Darwiche, 1995 ] </ref> . 2.4 EXAMPLE We conclude this section by demonstrating in details the mechanics of processing a subnetwork by tree-clustering, by a brute-force methods and by conditioning applied to our example in Figure 1. <p> Various algorithms that combine tree-clustering with conditioning were proposed in the past in the context of constraint networks [ Jegou, 1990 ] and belief networks <ref> [ Darwiche, 1995; Peot and Shachter, 1991 ] </ref> . These algorithms are normally space linear (a point that is not always appreciated), and they seem to fall in the first tradeoff class, as they exploit singleton separators only.
Reference: [ Dechter and Pearl, 1987 ] <author> R. Dechter and J. Pearl. </author> <title> Network-based heuristics for constraint satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <volume> 34 </volume> <pages> 1-38, </pages> <year> 1987. </year>
Reference-contexts: Specifically, one way to decide the consistency of a join-tree is to perform directional arc-consistency (also called pair-wise consistency) along some directed rooted tree. If the empty relation is not generated, finding one solution can be done in a backtrack-free manner from root to leaves <ref> [ Dechter and Pearl, 1987 ] </ref> . The operation of solving each subproblem in the clique-tree and the operation of pair-wise consistency can be interleaved. In this case, constraints may be recorded only on the intersection subsets of neighboring cliques. <p> A special case of Theorem 6, observed before in <ref> [ Dechter and Pearl, 1987; Freuder, 1985 ] </ref> , is when the graph is decomposed into nonseparable components (i.e., when the separator size equals 1).
Reference: [ Dechter and Pearl, 1989 ] <author> R. Dechter and J. Pearl. </author> <title> Tree clustering for constraint networks. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> pages 353-366, </pages> <year> 1989. </year>
Reference-contexts: In this case, constraints may be recorded only on the intersection subsets of neighboring cliques. The time complexity of this modification is exponential in the tree width, while its space complexity is exponentially bounded only by the maximal separator between subproblems. We conclude: Theorem 4: [Time-space of tree-clustering] <ref> [ Dechter and Pearl, 1989 ] </ref> : Given a constraint problem whose constraint graph can be embedded in a clique-tree having tree width r and separator width s, the time complexity of tree-clustering for deciding consistency and for finding one solution is O (n exp (r)) and its space complexity is <p> The two approaches that extend this propagation algorithm to multiply-connected networks, cycle-cutset and conditioning, are applicable here as well [ Pearl, 1988; Lauritzen and Spiegelhalter, 1988; Shachter, 1986 ] . It has also been shown that elimination algorithms are similar to tree-clustering methods <ref> [ Dechter and Pearl, 1989 ] </ref> .
Reference: [ Dechter et al., 1990 ] <author> R. Dechter, A. Dechter, and J. Pearl. </author> <title> Optimization in constraint networks. In Influence Diagrams, </title> <booktitle> Belief Nets and Decision Analysis, </booktitle> <pages> pages 411-425. </pages> <publisher> John Wiley & Sons, </publisher> <address> Sussex, England, </address> <year> 1990. </year>
Reference-contexts: Since constraint optimization can be performed in linear time when the augmented constraint graph is a tree, both tree-clustering and conditioning can extend the method to non-tree structures <ref> [ Dechter et al., 1990 ] </ref> .
Reference: [ Dechter, 1990 ] <author> R. Dechter. </author> <title> Enhancement schems for constraint processing incorporating, backjumping, learning and cutset decomposition. </title> <journal> Artificial Intelligence, </journal> <year> 1990. </year>
Reference-contexts: Thus, the overall time complexity is exponential in the size of the cycle-cutset [ Dechter, 1992 ] . More precisely, the cycle-cutset method is bounded by O (nk c+2 ), where c is the cutset size, k is the domain size, and n is the number of variables <ref> [ Dechter, 1990 ] </ref> . Fortunately, enumerating all the cutset's assignments can be accomplished in linear space using backtracking. Theorem 6: Let G be a constraint graph and let T be a primary join-tree with separator size s or less.
Reference: [ Dechter, 1992 ] <author> R. Dechter. </author> <title> Constraint networks. </title> <editor> In S. Shapiro, editor, </editor> <booktitle> Encyclopedia of Artificial Intelligence, </booktitle> <pages> pages 276-285. </pages> <publisher> John Wiley & Sons, </publisher> <year> 1992. </year>
Reference-contexts: A typical cycle-cutset method enumerates the possible assignments to a set of cutset variables and, for each cutset assignment, solves (or reasons about) a tree-like problem in polynomial time. The overall time complexity is exponential in the size of the cycle-cutset <ref> [ Dechter, 1992 ] </ref> . Fortunately, enumerating all the cutset's assignments can be accomplished in linear space. Since the space complexity of tree-clustering can severely limit its usefulness, we investigate the extent to which its space complexity can be reduced, while reasonable time complexity guarantees are maintained. <p> Thus, the overall time complexity is exponential in the size of the cycle-cutset <ref> [ Dechter, 1992 ] </ref> . More precisely, the cycle-cutset method is bounded by O (nk c+2 ), where c is the cutset size, k is the domain size, and n is the number of variables [ Dechter, 1990 ] .
Reference: [ Dechter, 1996 ] <author> R. Dechter. </author> <title> Bucket elimination: A unifying framework for probabilistic inference. </title> <booktitle> In Uncertainty for Artificial Intelligence (UAI-96), </booktitle> <year> 1996. </year>
Reference-contexts: marginal distribution over the separator B, namely (we annotate constant by primes): P (b 0 ) = d;g;e;c;f;h P (fjg)P (ejd; f )P (hjg; f; e): Migrating the components as far to the left as possible to exploit a variable elimination scheme which is similar to clustering (for details see <ref> [ Dechter, 1996 ] </ref> ), we get: X X P (gjb 0 ; d) e c X P (f jg)P (ejd; f ) h Clustering. Summing on the variables one by one from right to left, while recording intermediate tables is equivalent to tree-clustering.
Reference: [ Fattah and Dechter, 1996 ] <author> Y.El. Fattah and R. Dechter. </author> <title> An evaluation of structural parameters for probabilistic reasoning: results on benchmark circuits. </title> <note> In Submitted to Uncertainty in Artificial Intelligence (UAI-96), </note> <year> 1996. </year>
Reference: [ Freuder, 1985 ] <author> E. C. Freuder. </author> <title> A sufficient condition for backtrack-bounded search. </title> <journal> Journal of the ACM, </journal> <volume> 34(4) </volume> <pages> 755-761, </pages> <year> 1985. </year>
Reference-contexts: A special case of Theorem 6, observed before in <ref> [ Dechter and Pearl, 1987; Freuder, 1985 ] </ref> , is when the graph is decomposed into nonseparable components (i.e., when the separator size equals 1).
Reference: [ Jegou, 1990 ] <author> P Jegou. </author> <title> Cyclic clustering: a compromise between tree-clustering and the cycle-cutset method for improving search efficiency. </title> <booktitle> In Euro-pean Conference on AI (ECAI-90), </booktitle> <pages> pages 369-371, </pages> <address> Stockholm, </address> <year> 1990. </year>
Reference-contexts: The same kind of tradeoff is obeyed by optimization problems when using the problem's graph augmented with arcs reflecting the structure of the criterion function. Various algorithms that combine tree-clustering with conditioning were proposed in the past in the context of constraint networks <ref> [ Jegou, 1990 ] </ref> and belief networks [ Darwiche, 1995; Peot and Shachter, 1991 ] . These algorithms are normally space linear (a point that is not always appreciated), and they seem to fall in the first tradeoff class, as they exploit singleton separators only.
Reference: [ Jennsen and Jennsen, 1994 ] <author> F. Jennsen and F. Jennsen. </author> <title> Optimal junction trees. </title> <booktitle> In Uncertainty in Artificial Intelligence (UAI-95), </booktitle> <pages> pages 360-366, </pages> <year> 1994. </year>
Reference-contexts: A linear-time propagation algorithm exists for the MEU task whenever the utility-augmented moral graph of the network is a tree <ref> [ Jennsen and Jennsen, 1994 ] </ref> . Consequently, by exploiting the augmented moral graph, we can extend this propagation algorithm to general influence diagrams.
Reference: [ Lauritzen and Spiegelhalter, 1988 ] <author> S.L. Lau-ritzen and D.J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their applications to expert systems. </title> <journal> J. R. Stat. Soc., </journal> <volume> B 50:127- 224, </volume> <year> 1988. </year>
Reference-contexts: The conditional probabilities between neighboring cliques can then be computed [ Pearl, 1988 ] . Alternatively, the marginal probability distributions for each clique can be computed <ref> [ Lauritzen and Spiegelhalter, 1988 ] </ref> . In both cases, the computation is exponential in the clique's size, so clustering is time and space exponential in the moral graph's induced-width [ Pearl, 1988; Lauritzen and Spiegelhalter, 1988 ] . <p> Alternatively, the marginal probability distributions for each clique can be computed [ Lauritzen and Spiegelhalter, 1988 ] . In both cases, the computation is exponential in the clique's size, so clustering is time and space exponential in the moral graph's induced-width <ref> [ Pearl, 1988; Lauritzen and Spiegelhalter, 1988 ] </ref> . Example 1: Since the moral graph in Figure 1 (b) is chordal no arc is added in the first step of clustering. <p> First, the constraint graph is embedded in a clique-tree, then the solution set for each clique is computed. This latter computation is exponential in the clique's size. Therefore, clustering has time and space complexities that are exponential in the induced width of its constraint graph <ref> [ Pearl, 1988; Lauritzen and Spiegelhalter, 1988 ] </ref> . Example 4: Since the graph in Figure 3 (a) is identical to the graph in Figure 1 (b), it possesses the same clique-tree embeddings. <p> Consequently, by exploiting the augmented moral graph, we can extend this propagation algorithm to general influence diagrams. The two approaches that extend this propagation algorithm to multiply-connected networks, cycle-cutset and conditioning, are applicable here as well <ref> [ Pearl, 1988; Lauritzen and Spiegelhalter, 1988; Shachter, 1986 ] </ref> . It has also been shown that elimination algorithms are similar to tree-clustering methods [ Dechter and Pearl, 1989 ] .
Reference: [ Mackworth and Freuder, 1985 ] <author> A. K. Mackworth and E. C. Freuder. </author> <title> The complexity of some polynomial network consistency algorithms for constraint satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <volume> 25(1), </volume> <year> 1985. </year>
Reference-contexts: 1 INTRODUCTION Topology-based algorithms for constraint satisfaction and probabilistic reasoning fall into two distinct classes. One class is centered on tree-clustering, the other on cycle-cutset decomposition. Tree-clustering involves transforming the original problem into a treelike problem that can then be solved by a specialized tree-solving algorithm <ref> [ Mackworth and Freuder, 1985; Pearl, 1986 ] </ref> . The tree-clustering algorithm is time and space exponential in the induced width (also called tree width) of the problem's graph.
Reference: [ Pearl, 1986 ] <author> J. Pearl. </author> <title> Fusion propagation and structuring in belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 29(3) </volume> <pages> 241-248, </pages> <year> 1986. </year>
Reference-contexts: 1 INTRODUCTION Topology-based algorithms for constraint satisfaction and probabilistic reasoning fall into two distinct classes. One class is centered on tree-clustering, the other on cycle-cutset decomposition. Tree-clustering involves transforming the original problem into a treelike problem that can then be solved by a specialized tree-solving algorithm <ref> [ Mackworth and Freuder, 1985; Pearl, 1986 ] </ref> . The tree-clustering algorithm is time and space exponential in the induced width (also called tree width) of the problem's graph.
Reference: [ Pearl, 1988 ] <author> J. Pearl. </author> <title> Probabilistic Reasoning Intelligent Systems. </title> <publisher> Morgan Kaoufmann, </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference-contexts: Once the tree structure is determined, each subprob-lem is viewd as a metavariable whose values are all the value combinations of the original variables in the cluster. The conditional probabilities between neighboring cliques can then be computed <ref> [ Pearl, 1988 ] </ref> . Alternatively, the marginal probability distributions for each clique can be computed [ Lauritzen and Spiegelhalter, 1988 ] . <p> Alternatively, the marginal probability distributions for each clique can be computed [ Lauritzen and Spiegelhalter, 1988 ] . In both cases, the computation is exponential in the clique's size, so clustering is time and space exponential in the moral graph's induced-width <ref> [ Pearl, 1988; Lauritzen and Spiegelhalter, 1988 ] </ref> . Example 1: Since the moral graph in Figure 1 (b) is chordal no arc is added in the first step of clustering. <p> There are, however, many cases where the separator width is much smaller than the tree width. 2.2 CUTSET CONDITIONING Alternatively, belief networks may be processed by cutset conditioning <ref> [ Pearl, 1988 ] </ref> . Conditioning computes conditioned beliefs and MPE for each assignment to a cycle-cutset, using a tree algorithms applied to the tree resulting from deleting the conditioning variables, and then computes the overall belief by taking a weighted sum or performing a maximization. <p> First, the constraint graph is embedded in a clique-tree, then the solution set for each clique is computed. This latter computation is exponential in the clique's size. Therefore, clustering has time and space complexities that are exponential in the induced width of its constraint graph <ref> [ Pearl, 1988; Lauritzen and Spiegelhalter, 1988 ] </ref> . Example 4: Since the graph in Figure 3 (a) is identical to the graph in Figure 1 (b), it possesses the same clique-tree embeddings. <p> Consequently, by exploiting the augmented moral graph, we can extend this propagation algorithm to general influence diagrams. The two approaches that extend this propagation algorithm to multiply-connected networks, cycle-cutset and conditioning, are applicable here as well <ref> [ Pearl, 1988; Lauritzen and Spiegelhalter, 1988; Shachter, 1986 ] </ref> . It has also been shown that elimination algorithms are similar to tree-clustering methods [ Dechter and Pearl, 1989 ] .
Reference: [ Peot and Shachter, 1991 ] <author> M.A. Peot and R.D. Shachter. </author> <title> Fusion and propagation with multiple observations in belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 48 </volume> <pages> 299-318, </pages> <year> 1991. </year>
Reference-contexts: When the moral graph can be decomposed to nonsep-arable components, the conditioning method can be modified to be time exponential in the maximal cut-set in each component only <ref> [ Peot and Shachter, 1991; Darwiche, 1995 ] </ref> . 2.4 EXAMPLE We conclude this section by demonstrating in details the mechanics of processing a subnetwork by tree-clustering, by a brute-force methods and by conditioning applied to our example in Figure 1. <p> Various algorithms that combine tree-clustering with conditioning were proposed in the past in the context of constraint networks [ Jegou, 1990 ] and belief networks <ref> [ Darwiche, 1995; Peot and Shachter, 1991 ] </ref> . These algorithms are normally space linear (a point that is not always appreciated), and they seem to fall in the first tradeoff class, as they exploit singleton separators only.
Reference: [ Shachter et al., 1991 ] <author> R.D. Shachter, S.K. Anderson, and P. Solovitz. </author> <title> Global conditioning for probabilistic inference in belief networks. </title> <booktitle> In Uncertainty in Artificial Intelligence (UAI-91), </booktitle> <pages> pages 514-522, </pages> <year> 1991. </year>
Reference-contexts: This can be partially attributed to <ref> [ Shachter et al., 1991 ] </ref> , where it is argued that conditioning is a special case of clustering.
Reference: [ Shachter, 1986 ] <author> R.D. Shachter. </author> <title> Evaluating influence diagrams. </title> <journal> Operations Research, </journal> <volume> 34(6), </volume> <year> 1986. </year>
Reference-contexts: for finding a consistent optimal solution using conditioning is O (n exp (c)) while its space complexity is linear. 2 In a similar manner, the structure of the criterion function can augment the moral graph when computing the maximum expected utility (MEU) of some decisions in a general influence diagram <ref> [ Shachter, 1986 ] </ref> . An influence diagram is a belief network having decision variables as well as an additively decomposable utility function. <p> Consequently, by exploiting the augmented moral graph, we can extend this propagation algorithm to general influence diagrams. The two approaches that extend this propagation algorithm to multiply-connected networks, cycle-cutset and conditioning, are applicable here as well <ref> [ Pearl, 1988; Lauritzen and Spiegelhalter, 1988; Shachter, 1986 ] </ref> . It has also been shown that elimination algorithms are similar to tree-clustering methods [ Dechter and Pearl, 1989 ] .
References-found: 21

