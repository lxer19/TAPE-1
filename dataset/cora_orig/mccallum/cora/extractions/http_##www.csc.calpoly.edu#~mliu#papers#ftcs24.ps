URL: http://www.csc.calpoly.edu/~mliu/papers/ftcs24.ps
Refering-URL: http://www.csc.calpoly.edu/~mliu/papers.html
Root-URL: http://www.csc.calpoly.edu
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Deborah A. Agarwal. </author> <title> Personal Communication on Ethernet Performance Measurements. </title> <institution> Department of Electrical and Computer Engineering, University of California, Santa Barbara, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Our choice of parameters for the database and transactions are chosen so as to be comparable to the existing simulation studies such as [4]. The choice of message propagation time is in keeping with [15] and with a recent study <ref> [1] </ref> conducted on Sun workstations interconnected via ethernet and employing Unix UDP protocol. The scale of disk access time relative to message propagation time is in accordance with [9].
Reference: [2] <author> R. Agrawal, M. Carey, and M. Livny. </author> <title> The Performance of Alternative Strategies for Dealing with Deadlocks in Database Management Systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-13(12):1348-1363, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: For our model, the strict two-phase locking algorithm [6, 3] is used. Deadlocks avoidance is implemented by using a timeout interval based on the following heuristic <ref> [2] </ref> : T imeoutInterval = (G) + k fl (G) where (G) is the average lock request response time, (G) is the standard deviation of the response time, and k is a weighting factor. Hence T imeoutInterval is dynamically adjusted to reflect on-line estimation of lock request time.
Reference: [3] <author> P. A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1987. </year>
Reference-contexts: At each server site, this component is responsible for accepting transaction requests from the coordinator site. (b) Concurrency Control Manager: At each server site, this component provides concurrency control for transactions that have been submitted to the site. For our model, the strict two-phase locking algorithm <ref> [6, 3] </ref> is used.
Reference: [4] <author> M. Carey and M. Livny. </author> <title> Conflict Detection Tradeoffs for Replicated Data. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 16(4) </volume> <pages> 703-746, </pages> <year> 1991. </year>
Reference-contexts: For our experiments, the key parameter settings are described in Table 7. Our choice of parameters for the database and transactions are chosen so as to be comparable to the existing simulation studies such as <ref> [4] </ref>. The choice of message propagation time is in keeping with [15] and with a recent study [1] conducted on Sun workstations interconnected via ethernet and employing Unix UDP protocol. The scale of disk access time relative to message propagation time is in accordance with [9].
Reference: [5] <author> CACI Products Company. </author> <title> MODSIM II Reference Manual. </title> <address> CACI, La Jolla, CA, </address> <year> 1993. </year>
Reference-contexts: The simulation model described in this paper was implemented using the general-purpose simulation programming language MODSIM II from CACI Products Co., La Jolla, California <ref> [5] </ref>. MODSIM II is a high-level language which supports object-oriented programming and discrete-event simulation. The model is a large, process-based simulation model. Each site is an object, as is each transaction. Methods are defined for these objects to implement the functional modules of the model.
Reference: [6] <author> K. P. Eswaran, J. N. Gray, R. A. Lorie, and I. L. Traiger. </author> <title> The Notions of Consistency and Predicate Locks in a Database System. </title> <journal> Communications of the ACM, </journal> 19(11) 624-633, November 1976. 
Reference-contexts: At each server site, this component is responsible for accepting transaction requests from the coordinator site. (b) Concurrency Control Manager: At each server site, this component provides concurrency control for transactions that have been submitted to the site. For our model, the strict two-phase locking algorithm <ref> [6, 3] </ref> is used.
Reference: [7] <author> Domenico Ferrari. </author> <title> Computer Systems Performance Evaluation. </title> <publisher> Prentice Hall, </publisher> <year> 1978. </year>
Reference-contexts: Statistics for individual transactions are carried in the data fields of the objects for the transactions, and are accumulated using statistic procedures provided by MODSIM II. In our experiments, the means of the desired measurements are obtained by using the method of batch means <ref> [12, 7, 11] </ref>. The results reported in the paper are within the 90 percent confidence intervals for the 4 quantities measured: the size of the confidence intervals of those measurements was within a few percent of the mean in almost all cases.
Reference: [8] <author> A. Citron G. Samaras, K. Britton and C. Mohan. </author> <title> Two-Phase Commit Optimizations and Tradeoffs in the Commercial Environment. </title> <booktitle> In Proceedings Ninth International Conference on Data Engineering, </booktitle> <pages> pages 520-529, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Although the two phase commit protocol has been studied extensively for a long time, the topic is of sufficient significance that several refinements of the protocol have continued to emerge <ref> [10, 8] </ref>. Furthermore, much of the existing literature on this protocol is restricted to discussing and analyzing the protocol (and its variants) in the absence of failures. Very little, especially in quantitative terms, is available about its performance in the presence of site failures.
Reference: [9] <author> J. Gray and A. Reuter. </author> <title> Transaction Processing: Concepts and Techniques. </title> <publisher> Morgan Kaufman, </publisher> <year> 1993. </year>
Reference-contexts: In particular, the protocol must ensure that all sites involved in the execution of a transaction either all commit or all abort the transaction. Much has been written about atomic commitment protocols. In practice, the commonly used protocol of this genre is the two phase commit (2PC) protocol <ref> [9] </ref> and a host of its variants, such as the presumed commit [13], presumed abort [13], and the early prepare [19] protocols. In general, these protocols attempt to minimize execution overhead, in terms of message traffic and log writes, to optimize performance and costs. <p> The choice of message propagation time is in keeping with [15] and with a recent study [1] conducted on Sun workstations interconnected via ethernet and employing Unix UDP protocol. The scale of disk access time relative to message propagation time is in accordance with <ref> [9] </ref>. For the tractability of the simulation, the number of sites and the database size are set to smaller values than systems in practice.
Reference: [10] <author> B. Lampson and D. Lomet. </author> <title> A New Presumed Commit Optimization for Two Phase Commit. </title> <type> Technical report, </type> <institution> Digital Equipment Corp., </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: Although the two phase commit protocol has been studied extensively for a long time, the topic is of sufficient significance that several refinements of the protocol have continued to emerge <ref> [10, 8] </ref>. Furthermore, much of the existing literature on this protocol is restricted to discussing and analyzing the protocol (and its variants) in the absence of failures. Very little, especially in quantitative terms, is available about its performance in the presence of site failures.
Reference: [11] <author> S. Lavenberg. </author> <title> Computer Performance Modeling Handbook. </title> <publisher> Academic Press, </publisher> <year> 1983. </year>
Reference-contexts: Statistics for individual transactions are carried in the data fields of the objects for the transactions, and are accumulated using statistic procedures provided by MODSIM II. In our experiments, the means of the desired measurements are obtained by using the method of batch means <ref> [12, 7, 11] </ref>. The results reported in the paper are within the 90 percent confidence intervals for the 4 quantities measured: the size of the confidence intervals of those measurements was within a few percent of the mean in almost all cases.
Reference: [12] <author> Averill M. Law and David Kelton. </author> <title> Simulation Modeling and Analysis. </title> <publisher> McGraw Hill, </publisher> <year> 1991. </year>
Reference-contexts: Statistics for individual transactions are carried in the data fields of the objects for the transactions, and are accumulated using statistic procedures provided by MODSIM II. In our experiments, the means of the desired measurements are obtained by using the method of batch means <ref> [12, 7, 11] </ref>. The results reported in the paper are within the 90 percent confidence intervals for the 4 quantities measured: the size of the confidence intervals of those measurements was within a few percent of the mean in almost all cases.
Reference: [13] <author> C. Mohan, B. Lindsay, and R. Obermarck. </author> <title> Transaction Management in the R fl Distributed Database Management System. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 11(4) </volume> <pages> 378-396, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: Much has been written about atomic commitment protocols. In practice, the commonly used protocol of this genre is the two phase commit (2PC) protocol [9] and a host of its variants, such as the presumed commit <ref> [13] </ref>, presumed abort [13], and the early prepare [19] protocols. In general, these protocols attempt to minimize execution overhead, in terms of message traffic and log writes, to optimize performance and costs. <p> Much has been written about atomic commitment protocols. In practice, the commonly used protocol of this genre is the two phase commit (2PC) protocol [9] and a host of its variants, such as the presumed commit <ref> [13] </ref>, presumed abort [13], and the early prepare [19] protocols. In general, these protocols attempt to minimize execution overhead, in terms of message traffic and log writes, to optimize performance and costs. <p> Since message and log-write overheads delay the completion of a transaction, many modifications to the two phase commit protocol have been proposed. We review the three main variants: the presumed commit, the presumed abort, and the early prepare protocols. 2.1 Two Phase Commit Two phase commit (2PC) <ref> [13] </ref> is the simplest atomic commitment protocol, and is the most widely used in practice. A transaction T originates at a site, called the coordinator, which forwards the operations contained in T to the appropriate database sites, called the participants, where the data is stored. <p> To ascertain that all participants have been informed of the decision (abort or commit), the protocol requires that the participants acknowledge the coordinator's abort/commit message in the second phase. These acknowledgements accounts for C of the 4C messages. The Presumed Commit (PC) protocol <ref> [13] </ref> eliminates the need for these acknowledgements. At the point when a participant casts its vote to commit, it updates the data (however, it does not release the locks on the data; locks will be discussed later in this paper). <p> As a result, the number of log forces is also reduced to C + 2. In the case of an aborted transaction, the protocol requires the same overhead as with the generic 2PC: 2C messages and C + 1 log forces. 2.3 Presumed Abort Presumed Abort (PA) <ref> [13] </ref> is the counterpart of PC. The coordinator assumes that the participant sites are prepared to abort at the point when they cast their votes. That is, the participant sites make no update to the data until they receive a commit message from the coordinator.
Reference: [14] <author> R. Schlichting and F. B. Schneider. </author> <title> Fail-Stop Processors: An Approach to Designing Fault-Tolerant Computing Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 1(3) </volume> <pages> 222-238, </pages> <month> August </month> <year> 1982. </year>
Reference-contexts: For our study, the client sites never fail. Failures do not overlap at one server site; that is, a site will not be subject to more than one failure at a time. Failures are uniformly distributed among the server sites. Failures are fail-stop <ref> [14] </ref>: all activities at the failed site cease upon a failure. Key information needed for the recovery of the site is assumed to be retained in stable storage. Site failures are implemented by interrupting all activities occurring at the failed site.
Reference: [15] <author> M. Scott and A. Cox. </author> <title> An Empirical Study of Message-Passing Overhead. </title> <booktitle> In ICCC 7th International Conference on Distriubted Computing Systems, </booktitle> <pages> pages 536-543, </pages> <year> 1987. </year>
Reference-contexts: For our experiments, the key parameter settings are described in Table 7. Our choice of parameters for the database and transactions are chosen so as to be comparable to the existing simulation studies such as [4]. The choice of message propagation time is in keeping with <ref> [15] </ref> and with a recent study [1] conducted on Sun workstations interconnected via ethernet and employing Unix UDP protocol. The scale of disk access time relative to message propagation time is in accordance with [9].
Reference: [16] <author> D. Skeen. </author> <title> Crash Recovery in a Distributed Database Systems. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, University of California at Berkeley, </institution> <year> 1982. </year>
Reference-contexts: The three-phase commit protocol <ref> [17, 16, 18] </ref> (another type of atomic commitment protocol) overcomes this problem in the case of site failures, but may still block when network partitions occur. In this paper, we concentrate on site failures and the 2PC protocols and its variants.
Reference: [17] <author> D. Skeen. </author> <title> Non-blocking commit protocols. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 133-147, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: The three-phase commit protocol <ref> [17, 16, 18] </ref> (another type of atomic commitment protocol) overcomes this problem in the case of site failures, but may still block when network partitions occur. In this paper, we concentrate on site failures and the 2PC protocols and its variants.
Reference: [18] <author> D. Skeen. </author> <title> A quorum based commit protocol. </title> <booktitle> In Proceedings of the 6th Berkeley Workshop on Distributed Data Management and Computer Networks, </booktitle> <pages> pages 69-80, </pages> <month> February </month> <year> 1982. </year>
Reference-contexts: The three-phase commit protocol <ref> [17, 16, 18] </ref> (another type of atomic commitment protocol) overcomes this problem in the case of site failures, but may still block when network partitions occur. In this paper, we concentrate on site failures and the 2PC protocols and its variants.
Reference: [19] <author> J. Stamos and F. Cristian. </author> <title> A Low-Cost Atomic Commit Protocol. </title> <booktitle> In Proceedings of Ninth Synposium on Reliable Distributed Systems, </booktitle> <month> October </month> <year> 1990. </year> <month> 21 </month>
Reference-contexts: Much has been written about atomic commitment protocols. In practice, the commonly used protocol of this genre is the two phase commit (2PC) protocol [9] and a host of its variants, such as the presumed commit [13], presumed abort [13], and the early prepare <ref> [19] </ref> protocols. In general, these protocols attempt to minimize execution overhead, in terms of message traffic and log writes, to optimize performance and costs. <p> On the other hand, if the decision is to commit, the coordinator must gather acknowledgements from the participants, in which case its message and log force overhead is the same as that for 2PC. 2.4 Early Prepare The Early Prepare (EP) protocol <ref> [19] </ref> goes one step beyond PC: the coordinator assumes that each participant site is prepared to commit after it receives an acknowledgement for each operation. That is, each participant site immediately updates the data written by the transaction before it acknowledges a write operation.
References-found: 19

