URL: http://www.cam.sri.com/tr/crc044/paper.ps.Z
Refering-URL: http://www.cam.sri.com/tr/ABSTRACTS.html
Root-URL: 
Title: Combining Knowledge Sources to Reorder N-Best Speech Hypothesis Lists  
Author: Manny Rayner David Carter Vassilios Digalakis Patti Price 
Keyword: ATIS data.  
Address: Suite 23, Millers Yard, Cambridge CB2 1RQ, UK  333 Ravenswood Ave., Menlo Park, CA 94025, USA  
Affiliation: (1) SRI International,  SRI International,  
Note: (HLT) Proceedings, Princeton,  
Phone: (2)  
Web: URL: http://www.cam.sri.com/tr/crc044/paper.ps.ZARPA  
Date: 1994  November 29, 1994  
Abstract: A simple and general method is described that can combine different knowledge sources to reorder N-best lists of hypotheses produced by a speech recognizer. The method is automatically trainable, acquiring information from both positive and negative examples. Experiments are described in which it was tested on a 1000-utterance sample of unseen 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Agnas, M-S., Alshawi, H., Bretan, I., Carter, D.M. Ceder, K., Collins, M., Crouch, R., Digalakis, V., Ekholm, B., Gamback, B., Kaja, J., Karlgren, J., Ly-berg, B., Price, P., Pulman, S., Rayner, M., Samuelsson, C. and Svensson, T., </author> <title> Spoken Language Translator: First Year Report, </title> <type> joint SRI/SICS technical report, </type> <year> 1994. </year>
Reference-contexts: Linguistic processing was performed using a version of the Core Language Engine customized to the ATIS domain, which was developed under the SRI-SICS-Telia Research Spoken Language Translator project <ref> [1, 11, 12] </ref>. The CLE normally assigns a hypothesis several different possible linguistic analyses, scoring each one with a plausibility measure. The plausibility measure is highly optimized [3], and for the ATIS domain has an error rate of about 5%. Only the most plausible linguistic analysis was used.
Reference: 2. <author> Alshawi, H., </author> <title> The Core Language Engine, </title> <address> Cambridge, Massachusetts: </address> <publisher> The MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: The methods described here were tested on a 1001-utterance unseen subset of the ATIS corpus; speech recognition was performed using the DECIPHER (TM) recognizer [7, 5], and linguistic analysis by a version of the Core Language Engine (CLE; <ref> [2] </ref>). For 10-best hypothesis lists, the best method yielded proportional reductions of 22% in sentence error rate and 21% in word error rate. In contrast, the highest-in-coverage method gave a 4.5% reduction in sentence error rate and a 6.7% reduction in word error rate.
Reference: 3. <author> Alshawi, H. and Carter, </author> <title> D.M., Training and Scaling Preference Functions for Disambiguation, </title> <type> SRI Technical Report, </type> <year> 1993. </year>
Reference-contexts: The final requirement is to use the training corpus a second time to compute optimal weights for the different KSs. This is an optimization problem which can be approximately solved using the method described in <ref> [3] </ref> 1 . The most interesting role in the above is played by the discrimination functions. <p> The CLE normally assigns a hypothesis several different possible linguistic analyses, scoring each one with a plausibility measure. The plausibility measure is highly optimized <ref> [3] </ref>, and for the ATIS domain has an error rate of about 5%. Only the most plausible linguistic analysis was used. <p> Typical values for Rel are "subject" or "object", when Head 1 is a verb and Head 2 the head-word of one of its arguments; alternatively, Rel can be a preposition, if the relation is a PP modification of an NP or VP. There are also some other possibilities, cf. <ref> [3] </ref>. The knowledge sources naturally fall into three groups. The first is the singleton consisting of the "recognizer score" KS; the second contains the four class N-gram discriminant KSs; the third consists of the remaining "linguistic" 5 Strengths Knowledge Source Av. <p> The method of <ref> [3] </ref> was used to calculate near-optimal weights for three combinations of KSs: 1. Recognizer score + class N-gram discriminant KSs 2. Recognizer score + linguistic KSs 3. <p> The second surprise was that the semantic triple discriminant KS essentially received a weight of zero. We had not anticipated this at all, in view of the fact that it is an extremely strong KS when selecting among different semantic interpretations of a single utterance <ref> [3, 4] </ref>. The picture becomes clearer, however, when the KS strengths are calculated for the combination "recognizer score + linguistic KSs" (Table 2). Here, the strength of the semantic triples KS has climbed to a respectable value.
Reference: 4. <author> Collins, M.J. </author> <title> The Use of Semantic Collocations in Preference Metrics and Word Similarity Measures, </title> <type> M Phil Thesis, </type> <institution> Cambridge University, </institution> <address> Cambridge, England, </address> <year> 1993. </year>
Reference-contexts: (H) for a hypothesis H to be P d T (L), where the sum is over all the linguistic items L of type T associated with H. d T (L) for a given linguistic item L is computed as follows. (This is a slight generalization of the method given in <ref> [4] </ref>). The training corpus is analyzed, and each hypothesis is tagged with its set of associated linguistic items. <p> The second surprise was that the semantic triple discriminant KS essentially received a weight of zero. We had not anticipated this at all, in view of the fact that it is an extremely strong KS when selecting among different semantic interpretations of a single utterance <ref> [3, 4] </ref>. The picture becomes clearer, however, when the KS strengths are calculated for the combination "recognizer score + linguistic KSs" (Table 2). Here, the strength of the semantic triples KS has climbed to a respectable value.
Reference: 5. <author> Digalakis, V. and Murveit, H., "Genones: </author> <title> Optimizing the Degree of Tying in a Large Vocabulary HMM Speech Recognizer", </title> <booktitle> Proc. of the Inter. Conf. on Acoust., Speech and Signal Proc., </booktitle> <year> 1994. </year>
Reference-contexts: The methods described here were tested on a 1001-utterance unseen subset of the ATIS corpus; speech recognition was performed using the DECIPHER (TM) recognizer <ref> [7, 5] </ref>, and linguistic analysis by a version of the Core Language Engine (CLE; [2]). For 10-best hypothesis lists, the best method yielded proportional reductions of 22% in sentence error rate and 21% in word error rate.
Reference: 6. <author> Kubala F., Barry, C., Bates, M., Bobrow, R., Fung, P., Ingria, R., Makhoul, J., Nguyen, L., Schwartz, R. and Stallard, D., </author> <title> "BBN Byblos and Harc February 1992 ATIS Benchmark Results", </title> <booktitle> Proc. DARPA Workshop on Speech and Natural Language, </booktitle> <year> 1992. </year>
Reference-contexts: Two variants of the "highest-in-coverage" method were used: the "straight" method, and one in which the hypotheses were first rescored using the optimized combination of recognizer score and N-gram discriminant KSs. This is marked in the tables as "N-gram/highest-in-coverage", and is roughly the strategy described in <ref> [6] </ref>.
Reference: 7. <author> Murveit, H., Butzberger, J., Digalakis, V. and Weintraub, M., </author> <title> "Large Vocabulary Dictation using SRI's DECIPHER(TM) Speech Recognition System: Progressive Search Techniques", </title> <booktitle> Proc. of the Inter. Conf. on Acoust., Speech and Signal Proc., </booktitle> <address> Minneapolis, Minnesota, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: The methods described here were tested on a 1001-utterance unseen subset of the ATIS corpus; speech recognition was performed using the DECIPHER (TM) recognizer <ref> [7, 5] </ref>, and linguistic analysis by a version of the Core Language Engine (CLE; [2]). For 10-best hypothesis lists, the best method yielded proportional reductions of 22% in sentence error rate and 21% in word error rate.
Reference: 8. <author> Norton, L.M., Dahl, D.A. and Linebarger, </author> <title> M.C., "Recent Improvements and Benchmark Results for the Paramax ATIS System". </title> <booktitle> Proc. DARPA Workshop on Speech and Natural Language, </booktitle> <year> 1992. </year>
Reference-contexts: We will refer to this as the "highest-in-coverage" method. Intuitively, highest-in-coverage seems a promising idea. However, practical experience shows that it is surprisingly hard to use it to extract concrete gains. For example, a recent paper <ref> [8] </ref> concluded that the highest-in-coverage candidate was in terms of the word error rate only very marginally better than the one the recognizer considered best.
Reference: 9. <author> Ostendorf, M., et al, </author> <title> "Integration of Diverse Recognition Methodologies Through Reevaluation of N-best Sentence Hypotheses," </title> <booktitle> Proc. DARPA Workshop on Speech and Natural Language, </booktitle> <year> 1991. </year>
Reference-contexts: An immediate problem is the nature of the interface between the two. A popular solution has been the N-best list e.g. <ref> [9] </ref>; for some N, the speech recognizer hands the language processor the N utterance hypotheses it considers most plausible. The recognizer chooses the hypotheses on the basis of the acoustic information in the input signal and, usually, a simple language model such as a bigram grammar.
Reference: 10. <author> Powell, F.C., </author> <title> Cambridge Mathematical and Statistical Tables, </title> <publisher> Cambridge Univer sity Press, </publisher> <address> Cambridge, England, </address> <year> 1976. </year>
Reference-contexts: length is increased from 8 to infinity; also that the linguistic KSs still make a useful contribution to lowering the sentence error rate. (The difference in the sentence-error results between the combinations "recognizer+N-gram KSs" and "all available KSs" is significant at the 1% level according to the McNemar sign test <ref> [10] </ref>). Both versions of the "highest-in-coverage" method are clearly outperformed by the optimized combination of all KSs. Table 3 appears to show that the N-gram KSs are considerably better than the linguistic ones.
Reference: 11. <author> Rayner, M., Alshawi, H., Bretan, I., Carter, D.M., Digalakis, V., Gamback, B., Kaja, J., Karlgren, J., Lyberg, B., Price, P., Pulman, S. and Samuelsson, C., </author> <title> "A Speech to Speech Translation System Built From Standard Components". </title> <booktitle> Proc. ARPA workshop on Human Language Technology, </booktitle> <year> 1993 </year>
Reference-contexts: It seems sensible to demand that d (g,b) has the following properties: * d (g,b) &gt; 0 if g &gt; b * d (g,b) = -d (b,g) (and hence d (g,b) = 0 if g = b). 1 A summary can also be found in <ref> [11] </ref>. 3 * d (g 1 ; b) &gt; d (g 2 ; b) if g 1 &gt;g 2 We have experimented with a number of possible such functions, the best one appearing to be the following. d (g; b) = &gt; &lt; log 2 (2 (g + 1)=(g + b <p> Linguistic processing was performed using a version of the Core Language Engine customized to the ATIS domain, which was developed under the SRI-SICS-Telia Research Spoken Language Translator project <ref> [1, 11, 12] </ref>. The CLE normally assigns a hypothesis several different possible linguistic analyses, scoring each one with a plausibility measure. The plausibility measure is highly optimized [3], and for the ATIS domain has an error rate of about 5%. Only the most plausible linguistic analysis was used.
Reference: 12. <author> Rayner, M., Bretan, I., Carter, D., Collins, M., Digalakis, V., Gamback, B., Kaja, J., Karlgren, J., Lyberg, B., Price, P., Pulman S. and Samuelsson, C., </author> <title> "Spo-ken Language Translation with Mid-90's Technology: A Case Study". </title> <booktitle> Proceedings of Eurospeech '93, </booktitle> <address> Berlin, </address> <year> 1993. </year>
Reference-contexts: Linguistic processing was performed using a version of the Core Language Engine customized to the ATIS domain, which was developed under the SRI-SICS-Telia Research Spoken Language Translator project <ref> [1, 11, 12] </ref>. The CLE normally assigns a hypothesis several different possible linguistic analyses, scoring each one with a plausibility measure. The plausibility measure is highly optimized [3], and for the ATIS domain has an error rate of about 5%. Only the most plausible linguistic analysis was used.
Reference: 13. <author> Samuelsson, C. and Rayner, M., </author> <title> "Quantitative Evaluation of Explanation-Based Learning as a Tuning Tool for a Large-Scale Natural Language System". </title> <booktitle> Proc. 12th International Joint Conference on Artificial Intelligence. </booktitle> <address> Sydney, Australia, </address> <year> 1991. </year>
Reference-contexts: The plausibility measure is highly optimized [3], and for the ATIS domain has an error rate of about 5%. Only the most plausible linguistic analysis was used. The general CLE grammar was specialized to the domain using the Explanation-Based Learning (EBL) algorithm <ref> [13] </ref> and the resulting grammar parsed using an LR parser [14], giving a decrease in analysis time, compared to the normal CLE left-corner parser, of about an order of magnitude.
Reference: 14. <author> Samuelsson, C., </author> <title> Fast Natural Language Parsing Using Explanation-Based Learn ing, </title> <type> PhD thesis, </type> <institution> Royal Institute of Technology, Stockholm, Sweden, </institution> <year> 1994. </year> <month> 12 </month>
Reference-contexts: Only the most plausible linguistic analysis was used. The general CLE grammar was specialized to the domain using the Explanation-Based Learning (EBL) algorithm [13] and the resulting grammar parsed using an LR parser <ref> [14] </ref>, giving a decrease in analysis time, compared to the normal CLE left-corner parser, of about an order of magnitude.
References-found: 14

