URL: http://www.neci.nj.nec.com/homepages/eric/bayes2.ps
Refering-URL: http://www.neci.nj.nec.com/homepages/eric/
Root-URL: 
Email: Email: fwds, ericg@research.NJ.NEC.COM; garrett@cs.washington.edu  Email: rico@math.nwu.edu  
Title: Experiments with a Bayesian game player  
Author: Warren D. Smith Eric B. Baum Charles Garrett 
Keyword: Rico Tudor Pattern recognition systems,  
Date: November 27, 1996  
Note: 1890 maple  
Address: 4 Independence Way Princeton NJ 08540  av, suite 115, Evanston IL 60201  
Affiliation: NEC Research Institute  
Abstract: In [7] we proposed a Bayesian algorithm for game playing that we will call BP. BP maintains a probabilistic model of its uncertainty and uses it to grow its search tree in the most relevant directions, and to value the tree's nodes. Here we describe the first implementations of this algorithm and report on experiments comparing it with the standard (alpha-beta, or AB) approach, and the "probability product" (PP) approach, in several popular games. BP is seen to evaluate a fixed tree more accurately than either AB or PP in a large variety of games. BP is seen to beat strong alpha-beta programs in Othello and Warri even when the alpha-beta programs are given substantially greater computational resources. We elucidate which conditions favor BP and which favor AB. We have invented several important BP-gameplayer engineering tricks in the course of this research, such as the "multispike trick" and new methods of evaluation function design. More such tricks undoubtably remain to be discovered. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Foreman S. Acton: </author> <title> Numerical methods that work, </title> <note> MAA 1990 (updated from 1970 edition). </note>
Reference-contexts: This quantity was truncated to lie in <ref> [0; 1] </ref> and 14 if 16 stones remained in play the exact game value (from an endgame table) was used instead. Gamestarts are all 190 positions reachable in 3 ply. Players are identical at depth 1.
Reference: [2] <author> Alan Agresti: </author> <title> Categorical data analysis, </title> <publisher> Wiley 1990 </publisher>
Reference: [3] <author> Louis Victor Allis: </author> <title> Searching for solutions in games and artificial intelligence, </title> <journal> CIP-Gegevens Koninklijke Bibliotheek, </journal> <note> Den Haag 1994; ISBN=90-9007488-0 </note>
Reference-contexts: The only feature Lithidion has that w1 does not, is the use of "proof number search" <ref> [3] </ref> on the opponent's thinking time in an attempt to solve certain moves. 6 Neither our BP nor our AB players utilized transposition tables 7 or "multilevel" or "lazy" evaluators 8 . <p> This game is similar to the game sold by Milton-Bradley and played on a 6 fi 7 noncylindrical board, but that game has been solved (win for the first player by moving into the center column) by James Allen and L.V. Allis in 1989 <ref> [3, 55] </ref>. The present game was intentionally made larger and the columns were given an odd height (Allis's solver utilized various theorems about connect-4 variants with even-height columns), in an effort to make the game intractable. 8 Discussion In our experiments, BP performed well.
Reference: [4] <author> T. Anantharaman, M. Campbell, F. Hsu: </author> <title> Singular extensions; adding selectivity to brute force searching, </title> <booktitle> Artificial Intelligence 43 (1990) 99-109 </booktitle>
Reference-contexts: BP player will adjust its utility meter to spend more time thinking. 5 Engineering tricks Soon after the first alpha-beta chess players appeared, so did various engineering improvements upon them, including "quiescence" and [52] "iterative deepening." Although the rate has slowed, such improvements continue to appear even 40 years later <ref> [4, 11] </ref>. We similarly conjecture that there are many engineering tricks to be had in BP search. 5.1 The multispike trick There is a tradeoff in BP between using staircase CDF's with many steps, which can approximate well arbitrary density functions, and using few steps, saving memory and time.
Reference: [5] <author> Thomas S. Anantharaman: </author> <title> A Statistical Study of Selective Min-Max Search in Computer Chess, </title> <type> (PhD thesis, </type> <institution> Carnegie Mellon University, Computer Science Dept.) </institution> <month> May </month> <year> 1990, </year> <month> CMU-CS-90-173 </month>
Reference: [6] <author> Thomas S. Anantharaman: </author> <title> Extension heuristics, </title> <note> ICCA Journal 14,2 (June 1991) 47-65. </note>
Reference-contexts: In trees with random leaf values [35], negascout is known to be asymptotically equivalent to plain AB. 5 The best combination of search extensions found for the Deep Thought chess machine (after a huge amount of experimentation <ref> [6] </ref>) was estimated to be worth only 86 USCF rating points. 59 of these were due to threat extensions, 7 to singular extensions, and 5 to PV extensions.
Reference: [7] <author> Eric B. Baum and Warren D. Smith: </author> <title> Best Play for Imperfect Players and Game Tree Search; part I - theory. </title>
Reference-contexts: 1 Introduction 1.1 Three ways to valuate a tree: BP, AB, and PP In a companion paper <ref> [7] </ref> , we proposed a Bayesian procedure for making computers play games such as chess. We call this procedure "BP". <p> We played games against AB where each algorithm evaluated the same number of nodes per game, but the shapes of the trees were now not identical since BP was using utility-guided growth to shape its tree. Specifically we had proposed in <ref> [7] </ref> a procedure for computing an "expansion importance" measure called "Q step size" for each leaf, and proposed iteratively expanding the fraction f most important leaves, where f is the "gulp size." Meanwhile, AB was using full-width (but fffi-pruned, according to a good move ordering) trees. <p> Experiments (omitted) showed that training using game positions or positions a few random moves from games (wrong sample space), or using alpha-beta opinion changes or perfect play values (wrong data) resulted in significantly worse evaluation functions. 3 In footnote 11 of <ref> [7] </ref> we showed how this logarithmic factor may be gotten rid of at the cost of making the BP valuation less "exact." We have not experimented with that idea. 3 1.6 Experimental philosophy Our goal in this research has been to understand the capabilities of BP, rather than to produce the <p> Re-examination of their node count data with the aid of hindsight suggests that, if their AB implementation had used the same move ordering heuristics that ours did, then their MGSS* performance would, instead, merely have been comparable to AB. For more discussion of previous work, see <ref> [7] </ref>. Our results are the first of which we are aware where a non-minimaxing alternative approach was able to beat alpha-beta programs under realistic conditions. 2 Experimental methods, general discussion 2.1 Tournaments Most of our experiments consisted of multigame matches between two gameplaying entities. <p> various weighted averages of the AB values at depths 1-d of the moves, beat plain AB at depth d (d = 4-9), although remaining inferior to depth-d PP. 10 At k 10 the players are perfect. 11 This is related to an idea of Palay's, which we had reviewed in <ref> [7] </ref>, x7.3 8 player depth = 1 2 3 4 5 6 wins for AB 29 44 33 45 39 52 " " PP 29 14 25 13 19 6 For calibration, we played alpha-beta vs alpha-beta at increased depth, this time using 4-ply gamestarts. player depth = 1 2 3 <p> in time pressure). 22 But later experiments (x4.1.7) suggest "6" should be closer to 20. 23 Buro suggested switching to sub-single precision real numbers, in place of double precision, to save time and memory; another speedup might be to employ distribution compression within the search as in footnote 11 of <ref> [7] </ref>. On the other hand, Buro points out that 1. <p> In neither case have we tried the suggestion made in x3.1 of <ref> [7] </ref>, that the parameters in the time control be made explicitly dependent on the game stage. <p> That idea might have allowed us to cure an annoying sickness in our present time control algorithms: they tend to consume substantially less than their allotted time in long games (x4.1.7). 4.5.1 Othello Our Othello time control was based on "Szabo" version of a formula derived in x8 of <ref> [7] </ref>. <p> Thus the saving caused by better selectivity, can grow exponentially. This analysis and experience suggests that an engineering improvement along the lines suggested in x6.2 of <ref> [7] </ref> might pay substantial dividends. The idea there was to achieve greater selectivity by using a nontrivial notion of "expansion" of a leaf.
Reference: [8] <author> D.F. Beal: </author> <title> A generalized quiescence search algorithm, </title> <booktitle> Artificial Intelligence 43 (1990) 85-98 </booktitle>
Reference: [9] <author> H.J.Berliner & C.McConnell: </author> <title> B* probability-based search, </title> <booktitle> Artificial Intelligence 86,1 (1996) 97-156 </booktitle>
Reference-contexts: Palay compared his algorithm to Belle on tactical positions in chess [34]; further investigation was by Berliner and McConnell <ref> [9] </ref>. Russell and Wefald [42] reported that their "MGSS*" algorithm (incorporating utility ideas) beat alpha-beta at Othello by heavy margins, but their implementation of alpha-beta used no move ordering heuristics [43].
Reference: [10] <author> Leo Breiman, J.H. Friedman, R.A.Olshen, C.J. Stone: </author> <title> Classification and regression trees, </title> <publisher> Wadsworth 1984 </publisher>
Reference: [11] <author> Michael Buro: </author> <title> Techniken fur die Bewertung von Spielsituationen anhand von Beispielen, </title> <type> Ph.D thesis, </type> <institution> at University of Paderborn, Germany, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: Springer , and Bugs by J-C. Weill. The main weaknesses of our Othello programs as tournament players are: 1. Speed: Evaluation function slow ( 20fi) compared to Logistello. No transposition table. No thinking on opponent's time. 2. No opening book. 3. No top-quality endgame solver (the best programs <ref> [11, 57] </ref> find game theoretic value with 24 empty squares.) We intentionally neglected the opening book and endgame solver since they don't matter much to our research although they are important for tournament strength. <p> been consumed. (The AB player's time control was adjusted too, to equalize time used.) As table 4 shows, this lowered the performance of the BP player by about 1 disc per game, although it was still much stronger than the AB player 18 . 4.1.5 AB with "probcut" Michael Buro <ref> [11] </ref> invented a simple but (at least in Othello) effective heuristic for selective extension in AB. Buro's Othello program Logistello, at 30 minutes/side/game would normally search to about 11-12 ply doing a nonselective iterated deepening alpha-beta search. <p> BP player will adjust its utility meter to spend more time thinking. 5 Engineering tricks Soon after the first alpha-beta chess players appeared, so did various engineering improvements upon them, including "quiescence" and [52] "iterative deepening." Although the rate has slowed, such improvements continue to appear even 40 years later <ref> [4, 11] </ref>. We similarly conjecture that there are many engineering tricks to be had in BP search. 5.1 The multispike trick There is a tradeoff in BP between using staircase CDF's with many steps, which can approximate well arbitrary density functions, and using few steps, saving memory and time. <p> Our experience was that one needs 1000-3000 games per feature in order to get decent fits. Our Othello and checkers evaluators involve 30-60 features and are based on over 80000 games each. Our mod-9-connect-4 evaluator uses only 10 features. M. Buro <ref> [11] </ref> presented evidence that logistic regression works better than plain linear regression for Othello evaluators. Our experiments (omitted) in chess have entirely supported that. Also in chess we found that fitting only "quiescent" positions was a superior procedure.
Reference: [12] <author> Michael Buro: ProbCut: </author> <title> an effective selective extension of the fffi algorithm, </title> <note> ICCA Journal 18,2 (1995) 71-76. </note>
Reference-contexts: In some cases we tried enhancing AB with "quiescence" and "probcut" <ref> [12] </ref>. <p> The depths "8", and "4" and the optimum value X = 1:50 were found empirically. Probcut allows Logistello to search deeper in the selected lines. Its winning percentage against the nonselective version was 64:7% even in a tournament with 2:1 time odds. Also, Buro found <ref> [12] </ref> that 12 ply searches with selectivity turned on would make the same move, 93% of the time, as full width 12-ply searches, but run 4-6 times faster. Probcut is easy to implement. We implemented a probcut version of our AB Othello player.
Reference: [13] <author> David B. Chamberlin: </author> <title> How to play Warri, privately printed 1984. (Available from author, </title> <address> 2101 Birch-wood Road, Lancaster PA 17603, </address> <note> for $7.) </note>
Reference-contexts: requirement for the two sides to be the same, * and in other cases, simply every position reachable from gamestart in a certain number of ply. 2.2 Games, languages, hardware We have studied the abilities of full game playing programs on three games, Slagle kalah [50], Othello [26], and warri <ref> [13] </ref>. Kalah was chosen as a simple game to begin on; Othello as a more complex game on which alpha-beta performs well; and then warri was chosen as a more complex relative of Kalah. For rules, see x7. <p> The most important of the rule variants, and the one that is adopted in Antiguan league play (and in the annual tournaments held there in Decembers and televised in recent years) is called Warri. These are extracted from pages 15-17 of [41] and from <ref> [13] </ref>. 1. Warri is played on a 2fi6 board. 2. Four seeds per hole at gamestart (i.e. 48 total). South moves first. 3.
Reference: [14] <author> I. Chernev: </author> <title> The compleat Draughts player, </title> <publisher> Oxford University Press 1981. </publisher>
Reference: [15] <author> P-C. Chi & D. S. Nau: </author> <title> Comparison of the Minimax and Product Back-up Rules in a Variety of Games, </title> <booktitle> in Search in Artificial Intelligence, </booktitle> <editor> eds. L. Kanal and V. Kumar, </editor> <publisher> Springer Verlag, </publisher> <address> New York,(1989) pp 451-471. </address>
Reference-contexts: PP does this well because Slagle Kalah exhibits few recognizable features which last for longer than a few ply (and even these are invisible to the crude evaluation function we are using here), so that all positions are fairly "independent" of all other positions. Chi and Nau <ref> [15] </ref> showed that PP was superior to AB at certain search depths in a reduced version of Slagle Kalah. They argued that PP tends to do better against AB, if the evaluator used has a large "rate of heuristic flaw" as do all known evaluators in Slagle kalah. <p> seeds evenly between the players, so that whoever was ahead before the cycle started, wins. 30 7.3 Slagle Kalah Slagle kalah was introduced in papers by Slagle et al. [50, 51], who used it as a vehicle for studying game tree search, and studied by other AI researchers (see eg <ref> [15] </ref>). See [50, 51] for the rules. We call this game "Slagle Kalah" because, as far as we are able to determine, the particular Mancala rule variant used here was invented by Slagle.
Reference: [16] <author> A. Delcher, S. Kasif: </author> <title> Improved Decision Making in Game Trees: Recovering from Pathology, </title> <booktitle> Proceedings of the National Conference on Artificial Intelligence (July 1992) 513-518. </booktitle>
Reference: [17] <editor> A.Deledicq and A.Popova: Wari et Solo, le jeu de calculs Africain, </editor> <address> CEDIC (93 avenue d'Italie 75013 Paris) 1977 </address>
Reference-contexts: Many of them are listed in [41] and <ref> [17] </ref>. The most important of the rule variants, and the one that is adopted in Antiguan league play (and in the annual tournaments held there in Decembers and televised in recent years) is called Warri. These are extracted from pages 15-17 of [41] and from [13]. 1.
Reference: [18] <author> G.Goetsch & M.S&gt; Campbell: </author> <title> Experiments with the null-move heuristic, </title> <editor> in T.A.Marsland & J.Schaeffer eds., </editor> <booktitle> Computers, chess and cognitions, </booktitle> <publisher> Springer 1990. </publisher>
Reference-contexts: In general, however, we have stuck to simple versions of alpha-beta. We believe that fancy modifications of alpha-beta, e.g. negascout [37], buy little advantage in practice 4 . Although the "null-move heuristic" <ref> [18] </ref> can be very effective in chess, it would have had an extremely negative impact in checkers, warri and Othello, because "zugzwang" situations are rare in chess, common in checkers, and extremely common (in fact the norm) in warri and Othello.
Reference: [19] <author> R.M.Goodman and P. Smyth: </author> <title> Decision tree design from a communication theory standpoint, </title> <journal> IEEE Trans. Info. </journal> <note> Theory 34,5 (1988) 979-994. </note>
Reference: [20] <author> G.H. Golub and J.H. Welsch: </author> <title> Calculation of Gauss quadrature rules, </title> <journal> Math. </journal> <note> of Computation 23 (1969) 221-230 and microfiche. </note>
Reference-contexts: We have relied on the following method. We choose the locations and heights of the k spikes so that the first 2k nontrivial moments of the two distributions agree. Such a compression exists and is unique, and may be found using a slick numerical method of Golub and Welsch <ref> [20] </ref>. This compression method suffers from at least two flaws.
Reference: [21] <author> R. Floyd and R. Rivest: </author> <title> Expected time bounds for selection, </title> <journal> Commun. </journal> <note> ACM 18,3 (March 1975) 165-173 33 </note>
Reference: [22] <author> Louis C. Ginsberg: </author> <title> Principles of strategy in the game of checkers, privately printed 1931. Reprinted by Don Goodwin, </title> <address> 51 Tefly Road, Willowdale, Ontario Canada M2M-1C5. </address>
Reference: [23] <author> E.T.Jaynes: </author> <title> Concentration of distributions, pp 315-336 in E.T. Jaynes: papers on probability, </title> <journal> statistics, and statistical physics, </journal> <note> Kluwer 1989. </note>
Reference: [24] <author> Robert L. Jennrich: </author> <title> Stepwise regression, pp. 58-75 in: Statistical Methods for Digital Computers, </title> <editor> (Editors: Kurt Enslein, Anthony Ralston, Herbert S. </editor> <publisher> Wilf) Wiley 1977 </publisher>
Reference: [25] <author> Alexander Kotov: </author> <title> Think like a grandmaster, </title> <month> Batsford </month> <year> 1971 </year>
Reference: [26] <author> Ted Landau: </author> <title> Othello, brief and basic (1984), sold by US Othello Association, </title> <address> 920 Northgate Ave. Waynesboro VA 22980-3425. </address>
Reference-contexts: we remove the requirement for the two sides to be the same, * and in other cases, simply every position reachable from gamestart in a certain number of ply. 2.2 Games, languages, hardware We have studied the abilities of full game playing programs on three games, Slagle kalah [50], Othello <ref> [26] </ref>, and warri [13]. Kalah was chosen as a simple game to begin on; Othello as a more complex game on which alpha-beta performs well; and then warri was chosen as a more complex relative of Kalah. For rules, see x7. <p> feel we have made in the study of that particular game, and a discussion of "the hall of fame" of the strongest gameplaying entities for each game and estimates of how our programs compare to them, see our lengthy Tech Report [54]. 7.1 Othello For the rules of Othello, see <ref> [26] </ref> or [40]. An important rule not mentioned by these sources is the scoring of games that terminate before the board is filled. In these games, the winner gets the empties.
Reference: [27] <author> Han La Poutre and Warren D. Smith: </author> <title> Approximation of staircases by staircases, </title> <type> Technical report, </type> <address> NECI, 4 Independence Way, Princeton NJ 08540. </address>
Reference: [28] <author> Kai-Fu Lee and Sanjoy Mahajan: </author> <title> The development of a world class Othello program, </title> <booktitle> Artificial Intelligence 43 (1990) 21-36 </booktitle>
Reference-contexts: AB and BP are using the same evaluation function (AB is using the mean of the BP function, since AB requires a scalar) and AB is using response killer history tables and iterative deepening to do move ordering (similar to BILL <ref> [28] </ref>). The evaluator used a combination of linear regression and KS-trees (x6.1.1). In the timed games, AB did iterative deepening until cumulative time consumption exceeded a fixed fraction of the time budgeted for that move (except that on forced moves, which are rare, it plays instantly). <p> Slate's program is based on a comparatively fancy, full width alpha-beta type search with transposition table and quiescence, and it has a node rate 5fi higher than our programs. On the other hand, its evaluation function is comparatively simple. Slate's program had lost an earlier match with BILL <ref> [28] </ref> by a small margin. program wins mean discs sec/game consumed AB 94 36.35 217.22 (19) Slate 44 27.65 227.78 (18) (4 draws) (stddev 7.58) (disc conf. 6.83) program wins mean discs sec/game consumed BP 131 41.88 226.99 (23) Slate 10 22.12 239.26 (41) (1 draw) (stddev 6.51) (disc conf. 18.09)
Reference: [29] <author> R. Levinson & R. Snyder: </author> <title> DISTANCE: Toward the unification of chess knowledge, </title> <journal> ICCA (Int'l Computer Chess Assoc.) </journal> <note> Journal 16,3 (Sept. </note> <year> 1993) </year> <month> 123-136. </month>
Reference: [30] <author> T.A. Marsland: </author> <title> A review of game tree pruning, </title> <note> ICCA Journal 9,1 (March 1986) 3-19 </note>
Reference: [31] <author> F.J. Massey: </author> <title> Distribution table for the deviation between two sample cumulatives, </title> <journal> Ann. Math. Statist. </journal> <month> 23 </month> <year> (1952) </year> <month> 435-441. </month>
Reference-contexts: We regard each such subset as a (large sample from a) univariate probability density on . Choose that question maximizing the confidence that its two induced probability distributions are different. This confidence is computed by means of the "Kolmogorov-Smirnov two sample test," <ref> [53, 31] </ref> applied to uniquified 28 data. We cease to split further when (1 c)=s becomes smaller than some constant (we often used 0:001). Here c is the KS confidence that the two distributions really are different, and s is the number of candidate split-questions.
Reference: [32] <author> D.A. McAllester: </author> <title> Conspiracy numbers for min max search, </title> <booktitle> Artificial Intelligence 35 (1988) 287-310. </booktitle>
Reference-contexts: Rivest compared an algorithm of his devising to alpha-beta on the game of Connect 4, finding that he could beat it at equal nodes, but lost at equal time [39]. Schaeffer [46] implemented the conspiracy number algorithm of McAllester <ref> [32] </ref> and compared it to alpha-beta in chess, finding that it worked well in tactical middlegame situations, but was not competitive overall. Palay compared his algorithm to Belle on tactical positions in chess [34]; further investigation was by Berliner and McConnell [9].
Reference: [33] <author> Dana S. Nau: </author> <title> Pathology on game trees revisited, and an alternative to minimaxing, </title> <address> AI 21 (1983) 224-244. </address>
Reference-contexts: We would like to see experiments on chess, but have abandoned these for the present paper as requiring too much programming work. In addition to the above games, we have studied different evaluation methods on fixed sized trees on the games "mod-9 connect-4," and Pearl's P-game [35] <ref> [33] </ref>. Pearl's P-game was included in this list because it was crafted to be "pathological" and thus seemed likely to lead to insight. For a description of the games except the P-game, see x7. The P-game is described in x3.1. <p> The result would be both fast and smart. This idea has been quite unexplored, historically. 7 3.1 Pearl's "P-game" This game was designed by Pearl [35] and studied by Nau <ref> [33] </ref> as an example of a theoretically "pathological" game 9 , i.e. a game where searching deeper can be shown to give smaller probability of making the correct move for some depth pairs. <p> The results were as follows. player depth 2 3 4 5 6 7 8 9 wins for AB 196178 196763 184547 186982 172071 180741 172815 187157 " " PP 199926 197412 203727 202399 211349 207292 211538 203939 This confirms Nau's <ref> [33] </ref> results that PP is a superior decision procedure to minimax, searching to fixed depth in the P-game. BP is found to be superior to PP with 4-9 standard deviations of confidence, depending on which depth. The advantages are small in an absolute sense.
Reference: [34] <author> A.J. Palay: </author> <title> Searching with probabilities, </title> <publisher> Pitman 1985 </publisher>
Reference-contexts: Schaeffer [46] implemented the conspiracy number algorithm of McAllester [32] and compared it to alpha-beta in chess, finding that it worked well in tactical middlegame situations, but was not competitive overall. Palay compared his algorithm to Belle on tactical positions in chess <ref> [34] </ref>; further investigation was by Berliner and McConnell [9]. Russell and Wefald [42] reported that their "MGSS*" algorithm (incorporating utility ideas) beat alpha-beta at Othello by heavy margins, but their implementation of alpha-beta used no move ordering heuristics [43].
Reference: [35] <author> Judea Pearl: </author> <title> Heuristics, </title> <publisher> Addison-Wesley 1985. </publisher>
Reference-contexts: We also compared both alpha-beta and BP to a previously proposed probablistic scheme that we call Probability Product or PP. By PP we mean the proposal <ref> [35] </ref> to use an evaluation function estimating probability of winning, and to compute the value of a node as the probability it is a win, given the (assumed independent) estimates for its children. 1.2 Underlying assumptions and approximations One of the approximations and assumptions that underlies BP is that the probability <p> We would like to see experiments on chess, but have abandoned these for the present paper as requiring too much programming work. In addition to the above games, we have studied different evaluation methods on fixed sized trees on the games "mod-9 connect-4," and Pearl's P-game <ref> [35] </ref> [33]. Pearl's P-game was included in this list because it was crafted to be "pathological" and thus seemed likely to lead to insight. For a description of the games except the P-game, see x7. The P-game is described in x3.1. <p> These things are difficult to program well, and often do not buy very much improvement 5 . 4 See [48] for a comparative study of such modifications in chess; negascout caused a speedup of &lt; 10%. In trees with random leaf values <ref> [35] </ref>, negascout is known to be asymptotically equivalent to plain AB. 5 The best combination of search extensions found for the Deep Thought chess machine (after a huge amount of experimentation [6]) was estimated to be worth only 86 USCF rating points. 59 of these were due to threat extensions, 7 <p> The result would be both fast and smart. This idea has been quite unexplored, historically. 7 3.1 Pearl's "P-game" This game was designed by Pearl <ref> [35] </ref> and studied by Nau [33] as an example of a theoretically "pathological" game 9 , i.e. a game where searching deeper can be shown to give smaller probability of making the correct move for some depth pairs.
Reference: [36] <author> J. Ross Quinlan and R. L. Rivest: </author> <title> Inferring Decision Trees Using the Minimum Description Length Principle, </title> <booktitle> Information and Computation 80,3 (March 1989), </booktitle> <pages> 227-248. </pages>
Reference: [37] <author> A. Reinefeld: </author> <title> An improvement of the scout tree search algorithm, </title> <note> ICCA Journal 6,4 (Dec 1983) 4-14 </note>
Reference-contexts: We also implemented and report results against an alpha beta Othello program incorporating Buro's Probcut tree shaping heuristic. In general, however, we have stuck to simple versions of alpha-beta. We believe that fancy modifications of alpha-beta, e.g. negascout <ref> [37] </ref>, buy little advantage in practice 4 . <p> Our evaluator tables in total constituted 708588 bytes. Because this evaluator is so simple, we obtained rates of 70000 evaluations/second during searches enormous rates. Starting from a set of tables with all entries zero, we conducted learning negascout <ref> [37] </ref> searches with transposition table. After a few hours of learning, the program would make feeble attempts to avoid giving up a corner, but was still beaten soundly by a human beginner.
Reference: [38] <author> Arthur Reisman: </author> <title> Checkers made easy, Key publ. </title> <publisher> co. </publisher> <year> 1959 </year>
Reference: [39] <author> R.L. Rivest: </author> <title> Game tree searching by min max approximation, </title> <booktitle> Artificial Intelligence 34 (1988) 77-96 </booktitle>
Reference-contexts: A number of authors have previously compared tree growth algorithms to alpha-beta. Rivest compared an algorithm of his devising to alpha-beta on the game of Connect 4, finding that he could beat it at equal nodes, but lost at equal time <ref> [39] </ref>. Schaeffer [46] implemented the conspiracy number algorithm of McAllester [32] and compared it to alpha-beta in chess, finding that it worked well in tactical middlegame situations, but was not competitive overall.
Reference: [40] <author> Paul S. Rosenbloom: </author> <title> A world-championship level Othello program, </title> <booktitle> Artificial Intelligence 19 (1982) 279-320 </booktitle>
Reference-contexts: have made in the study of that particular game, and a discussion of "the hall of fame" of the strongest gameplaying entities for each game and estimates of how our programs compare to them, see our lengthy Tech Report [54]. 7.1 Othello For the rules of Othello, see [26] or <ref> [40] </ref>. An important rule not mentioned by these sources is the scoring of games that terminate before the board is filled. In these games, the winner gets the empties.
Reference: [41] <author> Laurence Russ: </author> <title> Mancala Games, </title> <publisher> Reference Publications Inc (218 St. </publisher> <address> Clair River Drive, Box 344, Algonac MI 48001) 1984 </address>
Reference-contexts: Many of them are listed in <ref> [41] </ref> and [17]. The most important of the rule variants, and the one that is adopted in Antiguan league play (and in the annual tournaments held there in Decembers and televised in recent years) is called Warri. These are extracted from pages 15-17 of [41] and from [13]. 1. <p> Many of them are listed in <ref> [41] </ref> and [17]. The most important of the rule variants, and the one that is adopted in Antiguan league play (and in the annual tournaments held there in Decembers and televised in recent years) is called Warri. These are extracted from pages 15-17 of [41] and from [13]. 1. Warri is played on a 2fi6 board. 2. Four seeds per hole at gamestart (i.e. 48 total). South moves first. 3.
Reference: [42] <author> S. Russell and E. Wefald: </author> <title> Do the Right Thing, </title> <note> MIT Press 1991 (see especially chapter 4) </note>
Reference-contexts: Palay compared his algorithm to Belle on tactical positions in chess [34]; further investigation was by Berliner and McConnell [9]. Russell and Wefald <ref> [42] </ref> reported that their "MGSS*" algorithm (incorporating utility ideas) beat alpha-beta at Othello by heavy margins, but their implementation of alpha-beta used no move ordering heuristics [43].
Reference: [43] <author> S. Russell, </author> <type> personal communication. </type>
Reference-contexts: Palay compared his algorithm to Belle on tactical positions in chess [34]; further investigation was by Berliner and McConnell [9]. Russell and Wefald [42] reported that their "MGSS*" algorithm (incorporating utility ideas) beat alpha-beta at Othello by heavy margins, but their implementation of alpha-beta used no move ordering heuristics <ref> [43] </ref>. Re-examination of their node count data with the aid of hindsight suggests that, if their AB implementation had used the same move ordering heuristics that ours did, then their MGSS* performance would, instead, merely have been comparable to AB. For more discussion of previous work, see [7].
Reference: [44] <author> A.L. Samuel: </author> <title> Some studies in machine learning using the game of checkers, </title> <institution> IBM J. Res. & Devel. </institution> <month> 3,3 </month> <year> (1959) </year> <month> 210-229. </month>
Reference: [45] <author> A.L. Samuel: </author> <title> Some studies in machine learning using the game of checkers II recent progress, </title> <institution> IBM J. Res. & Devel. </institution> <month> 11,6 </month> <year> (1967) </year> <month> 601-617. </month>
Reference: [46] <author> J. Schaeffer: </author> <title> Conspiracy numbers, </title> <booktitle> Artificial Intelligence 43 (1990) 67-84 </booktitle>
Reference-contexts: A number of authors have previously compared tree growth algorithms to alpha-beta. Rivest compared an algorithm of his devising to alpha-beta on the game of Connect 4, finding that he could beat it at equal nodes, but lost at equal time [39]. Schaeffer <ref> [46] </ref> implemented the conspiracy number algorithm of McAllester [32] and compared it to alpha-beta in chess, finding that it worked well in tactical middlegame situations, but was not competitive overall. Palay compared his algorithm to Belle on tactical positions in chess [34]; further investigation was by Berliner and McConnell [9].
Reference: [47] <author> J. Schaeffer, J. Culberson, N. Treloar, B. Knight, P. Lu, D. Szafron: </author> <title> A world championship calibre checkers program, </title> <booktitle> Artificial Intelligence 53 (1992) 273-289. </booktitle>
Reference: [48] <author> J. Schaeffer: </author> <title> Experiments in search and knowledge, </title> <type> TR 86-12, </type> <institution> Department of Computer Science, University of Alberta, Edmonton, Alberta, Canada. </institution> <type> (His PhD thesis from U. </type> <institution> Waterloo, </institution> <month> May </month> <year> 1986.) </year> <note> See also his later summary in IEEE Transactions on pattern analysis and machine intelligence 11,11 (1989) 1203-1212. </note>
Reference-contexts: Our AB players did not use heuristic tree shaping methods, including "singular extensions," and various other kinds of heuristic search extensions and retractions (except, where discussed, for Probcut and Quiescence). These things are difficult to program well, and often do not buy very much improvement 5 . 4 See <ref> [48] </ref> for a comparative study of such modifications in chess; negascout caused a speedup of &lt; 10%. <p> Brutelog and Eclipse have transposition tables. Transposition tables are well known to be more important at deeper search, because of combinatorial effects on the numbers of transpositions [52]. Schaeffer <ref> [48] </ref> found that in chess as search depth increased from 3 to 9, transposition tables caused a speedup factor that increased roughly from 2 to 10. Negascout's benefit over plain AB also was an increasing (although small) function of depth in Schaeffer's experiments.
Reference: [49] <author> C.E. Shannon: </author> <title> Programming a computer for playing chess, </title> <journal> Philos. </journal> <note> Magazine 41,7 (1950) 256-275 </note>
Reference-contexts: Shannon <ref> [49] </ref> proposed that computers select their move according to the minimax value of a full width subtree, with numerical leaf values assigned by some readily computed, heuristic evaluation function. The alpha-beta (AB) procedure speeds up the minimaxing.
Reference: [50] <author> J.R. Slagle and J.K. Dixon: </author> <title> Experiments with some programs that search game trees, </title> <journal> Commun. </journal> <note> ACM 16,2 (1969) 189-207 </note>
Reference-contexts: above, except we remove the requirement for the two sides to be the same, * and in other cases, simply every position reachable from gamestart in a certain number of ply. 2.2 Games, languages, hardware We have studied the abilities of full game playing programs on three games, Slagle kalah <ref> [50] </ref>, Othello [26], and warri [13]. Kalah was chosen as a simple game to begin on; Othello as a more complex game on which alpha-beta performs well; and then warri was chosen as a more complex relative of Kalah. For rules, see x7. <p> It is unclear how to evaluate the results of such a tournament. Totaling depths 2-7: BP won 218, PP won 156, with 23 draws. 12 This evaluation is the exact probability of winning given the current score difference (what <ref> [50] </ref> called Kalah difference) under the assumption that you will win the seeds on your side with probability G and those on your opponent's side with probability 1 G, the probabilities for each seed being assumed to be independent. 13 BP used an older evaluation function not based on K-S trees. <p> In this case (detected by a 3-time repetition) the simplest scoring method is to divide the cycling seeds evenly between the players, so that whoever was ahead before the cycle started, wins. 30 7.3 Slagle Kalah Slagle kalah was introduced in papers by Slagle et al. <ref> [50, 51] </ref>, who used it as a vehicle for studying game tree search, and studied by other AI researchers (see eg [15]). See [50, 51] for the rules. <p> between the players, so that whoever was ahead before the cycle started, wins. 30 7.3 Slagle Kalah Slagle kalah was introduced in papers by Slagle et al. <ref> [50, 51] </ref>, who used it as a vehicle for studying game tree search, and studied by other AI researchers (see eg [15]). See [50, 51] for the rules. We call this game "Slagle Kalah" because, as far as we are able to determine, the particular Mancala rule variant used here was invented by Slagle.
Reference: [51] <author> J.R. Slagle and J.K. Dixon: </author> <title> Experiments with the M & N tree searching program, </title> <journal> Commun. </journal> <note> ACM 13,3 (March 1970) 147-153 </note>
Reference-contexts: In this case (detected by a 3-time repetition) the simplest scoring method is to divide the cycling seeds evenly between the players, so that whoever was ahead before the cycle started, wins. 30 7.3 Slagle Kalah Slagle kalah was introduced in papers by Slagle et al. <ref> [50, 51] </ref>, who used it as a vehicle for studying game tree search, and studied by other AI researchers (see eg [15]). See [50, 51] for the rules. <p> between the players, so that whoever was ahead before the cycle started, wins. 30 7.3 Slagle Kalah Slagle kalah was introduced in papers by Slagle et al. <ref> [50, 51] </ref>, who used it as a vehicle for studying game tree search, and studied by other AI researchers (see eg [15]). See [50, 51] for the rules. We call this game "Slagle Kalah" because, as far as we are able to determine, the particular Mancala rule variant used here was invented by Slagle.
Reference: [52] <author> D.J. Slate & L.R.Atkin: </author> <title> Chess 4.5: The Northwestern University chess program, </title> <editor> in P.Frey (ed.) </editor> <booktitle> Chess skill in man and machine, </booktitle> <publisher> Springer-Verlag 1983 </publisher>
Reference-contexts: Brutelog and Eclipse have transposition tables. Transposition tables are well known to be more important at deeper search, because of combinatorial effects on the numbers of transpositions <ref> [52] </ref>. Schaeffer [48] found that in chess as search depth increased from 3 to 9, transposition tables caused a speedup factor that increased roughly from 2 to 10. Negascout's benefit over plain AB also was an increasing (although small) function of depth in Schaeffer's experiments. <p> Thus if the utility drops for several moves in a row, U final will drop and the BP player will adjust its utility meter to spend more time thinking. 5 Engineering tricks Soon after the first alpha-beta chess players appeared, so did various engineering improvements upon them, including "quiescence" and <ref> [52] </ref> "iterative deepening." Although the rate has slowed, such improvements continue to appear even 40 years later [4, 11].
Reference: [53] <author> N. Smirnov: </author> <title> Tables for estimating the goodness of fit of empirical distributions, </title> <journal> Annals Math. Statist. </journal> <month> 19 </month> <year> (1948) </year> <month> 280-281 </month>
Reference-contexts: We regard each such subset as a (large sample from a) univariate probability density on . Choose that question maximizing the confidence that its two induced probability distributions are different. This confidence is computed by means of the "Kolmogorov-Smirnov two sample test," <ref> [53, 31] </ref> applied to uniquified 28 data. We cease to split further when (1 c)=s becomes smaller than some constant (we often used 0:001). Here c is the KS confidence that the two distributions really are different, and s is the number of candidate split-questions.
Reference: [54] <author> Smith, W. D., E. B. Baum, C. Garrett, R. Tudor: </author> <title> Best Play for Imperfect Players and Game Tree Search; part II- experiments; Monster Unedited Version; http://www.neci.nj.nec.com:80/homepages/eric/monster.ps. </title>
Reference-contexts: Our engineering tricks are described in x5 and our learning methods are described in x6. The reader interested in replicating or extending our results will find gritty details of our experiments in our (completely unpolished) Technical report <ref> [54] </ref>. 1.5 Other findings It seems to be important, during evaluation function learning, to learn from positions drawn from BP searches (the "correct" sample space), and using BP opinion changes (the "correct" values). <p> See x6.1.3. For details about our features and evaluation functions, see our long TR <ref> [54] </ref>. 6.1.1 Kolmogorov-Smirnov decision trees Once one has a good-quality scalar evaluator, one can semi-automatically construct an evaluator which returns a probability distribution. We call the method we invented "Kolmogorov-Smirnov trees." First we acquire a large set of positions arising during BP searches. <p> The second was to use lookahead during play to gain data used to adjust the parameters in the scalar evaluator, in a Temporal-Difference like fashion. Details of both methods can be found in our TR <ref> [54] </ref>. We also used lookahead to learn scalar evaluators from scratch in Othello and Warri. <p> Presumably due to these factors, the 29 resulting table-based evaluation function was very successful and was the one we chose for w1. (See TR <ref> [54] </ref> for details.) 7 Descriptions of the games For a history of each game, a detailed description of features used in our evaluation functions, any new contributions we feel we have made in the study of that particular game, and a discussion of "the hall of fame" of the strongest gameplaying <p> used in our evaluation functions, any new contributions we feel we have made in the study of that particular game, and a discussion of "the hall of fame" of the strongest gameplaying entities for each game and estimates of how our programs compare to them, see our lengthy Tech Report <ref> [54] </ref>. 7.1 Othello For the rules of Othello, see [26] or [40]. An important rule not mentioned by these sources is the scoring of games that terminate before the board is filled. In these games, the winner gets the empties. <p> In BP you can focus on developing the evaluator. Obvious things to try next might include: * Transposition tables how should they best be implemented in BP, how should one best handle the issues related to BP in DAGs (cf. <ref> [54] </ref>), and how does all this affect performance? * 2-stage BP search to reduce memory consumption (cf [54]). * Distribution compression within the BP search to reduce time and space needs at the sacrifice of some accuracy. * Variants of BP with partial node expansion, or anyway different kinds of "expansion," <p> Obvious things to try next might include: * Transposition tables how should they best be implemented in BP, how should one best handle the issues related to BP in DAGs (cf. <ref> [54] </ref>), and how does all this affect performance? * 2-stage BP search to reduce memory consumption (cf [54]). * Distribution compression within the BP search to reduce time and space needs at the sacrifice of some accuracy. * Variants of BP with partial node expansion, or anyway different kinds of "expansion," for example deeper, guided expansion of very high utility nodes. * Further investigation of automated statistical methods
Reference: [55] <editor> J.W. Uiterwijk, J.J. van den Herik, L.V. Allis: </editor> <title> A knowledge-based approach to connect-four, </title> <booktitle> in: Heuristic programming and artificial intelligence, the first computer olympiad, </booktitle> <publisher> Ellis Horwood Ltd 1989 </publisher>
Reference-contexts: This game is similar to the game sold by Milton-Bradley and played on a 6 fi 7 noncylindrical board, but that game has been solved (win for the first player by moving into the center column) by James Allen and L.V. Allis in 1989 <ref> [3, 55] </ref>. The present game was intentionally made larger and the columns were given an odd height (Allis's solver utilized various theorems about connect-4 variants with even-height columns), in an effort to make the game intractable. 8 Discussion In our experiments, BP performed well.
Reference: [56] <author> S.H. Walker & D.B. Duncan: </author> <title> Estimation of the probability of an event as a function of several independent variables, </title> <note> Biometrika 54 (1967) 167-179. </note>
Reference: [57] <author> J-C. Weill: </author> <title> The NegaC* search, </title> <note> ICCA Journal 15,1 (March 1992) 3-7 </note>
Reference-contexts: Springer , and Bugs by J-C. Weill. The main weaknesses of our Othello programs as tournament players are: 1. Speed: Evaluation function slow ( 20fi) compared to Logistello. No transposition table. No thinking on opponent's time. 2. No opening book. 3. No top-quality endgame solver (the best programs <ref> [11, 57] </ref> find game theoretic value with 24 empty squares.) We intentionally neglected the opening book and endgame solver since they don't matter much to our research although they are important for tournament strength.
Reference: [58] <author> Tom Wiswell: </author> <title> The science of checkers and draughts, </title> <note> A.S. Barnes 1973. </note>
Reference: [59] <author> Tom Wiswell: </author> <title> The complete guide to checkers, </title> <publisher> Macmillan 1970 </publisher>
Reference: [60] <author> Tom Wiswell and Jules Leopold: </author> <title> The wonderful world of checkers and draughts, </title> <note> A.S. Barnes 1980. </note> *********************** 
Reference: [61] <author> Brian W. Kernighan, Rob Pike: </author> <title> The UNIX programming environment, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs NJ 1984 </address>
Reference-contexts: For a description of the games except the P-game, see x7. The P-game is described in x3.1. The guts of all our programs are written in C and C++,although we have also used the following languages in various places: UNIX (TM) shell, sed, and awk <ref> [61] </ref>, TCL [63], perl [64], and matlab [62]. All our timed experiments were run on a SGI machine based on a 150 MHz IP19 processor (MIPS R4400 processor with R4010 floating point chip) with data and instruction cache sizes of 16 Kbytes each, and a secondary unified 1 Mbyte cache.
Reference: [62] <author> Cleve B. Moler: </author> <title> MATLAB User's Guide, The MathWorks, </title> <publisher> Inc. </publisher> <address> Cochituate Place 24 Prime Park Way Natick, MA 01760. </address>
Reference-contexts: The P-game is described in x3.1. The guts of all our programs are written in C and C++,although we have also used the following languages in various places: UNIX (TM) shell, sed, and awk [61], TCL [63], perl [64], and matlab <ref> [62] </ref>. All our timed experiments were run on a SGI machine based on a 150 MHz IP19 processor (MIPS R4400 processor with R4010 floating point chip) with data and instruction cache sizes of 16 Kbytes each, and a secondary unified 1 Mbyte cache.
Reference: [63] <author> John K. Ousterhout: </author> <title> Tcl and the Tk toolkit, </title> <publisher> Addison-Wesley, </publisher> <address> Reading MA 1994 </address>
Reference-contexts: For a description of the games except the P-game, see x7. The P-game is described in x3.1. The guts of all our programs are written in C and C++,although we have also used the following languages in various places: UNIX (TM) shell, sed, and awk [61], TCL <ref> [63] </ref>, perl [64], and matlab [62]. All our timed experiments were run on a SGI machine based on a 150 MHz IP19 processor (MIPS R4400 processor with R4010 floating point chip) with data and instruction cache sizes of 16 Kbytes each, and a secondary unified 1 Mbyte cache.
Reference: [64] <author> Larry Wall and Randal L. Schwartz: </author> <title> Programming perl, O'Reilly & Associates, Sebastopol CA 1990 35 based on time odds tourney table 3 ; readers may conjure up their own error bars...) in Othello, versus BP thinking time allowance per game (seconds; BP evaluated 1350 nodes/sec as compared with AB's 2300). 36 compression of opinion change data at depth 5-6. </title> <type> 37 </type>
Reference-contexts: For a description of the games except the P-game, see x7. The P-game is described in x3.1. The guts of all our programs are written in C and C++,although we have also used the following languages in various places: UNIX (TM) shell, sed, and awk [61], TCL [63], perl <ref> [64] </ref>, and matlab [62]. All our timed experiments were run on a SGI machine based on a 150 MHz IP19 processor (MIPS R4400 processor with R4010 floating point chip) with data and instruction cache sizes of 16 Kbytes each, and a secondary unified 1 Mbyte cache.
References-found: 64

