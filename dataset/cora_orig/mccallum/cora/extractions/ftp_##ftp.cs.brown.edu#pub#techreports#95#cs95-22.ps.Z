URL: ftp://ftp.cs.brown.edu/pub/techreports/95/cs95-22.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-95-22.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. Atkinson et al. </author> <title> The Persistent Object Management System. </title> <type> Technical Report PRRR-1, </type> <institution> The Universities of Glasgow and St. Andrews, </institution> <year> 1983. </year>
Reference-contexts: Another approach is to augment the runtime structures of a high-level programming language to provide persistence and transaction semantics. This is the approach taken by the Persistent Object Management System (POMS) <ref> [1] </ref>. POMS extends the runtime virtual memory heap into stable storage. Because the database is an extension of a language, the database objects parallel the runtime objects. The objects are structured and typed, unlike ObServer's untyped, unstructured objects.
Reference: [2] <author> Fran~cois Bancilhon, C. Delobel, and Paris Kanellakis, </author> <title> editors. Building an Object-Oriented Database System: The Story of O2. </title> <publisher> Morgan-Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: The Exodus project [7, 39, 5] offers a persistent programming language, E, built on top of the Exodus Storage Manager (ESM), a standalone object store [6]. Several other OODBs use ESM for persistent storage <ref> [47, 2] </ref>. ESM provides applications with the abstraction of objects, but the unit of transfer between the client and server is the page. For this reason, ESM is a page server rather than an object server, which moves objects or segments between the client and server.
Reference: [3] <author> P. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: Traditional database systems provide a competitive transaction abstraction to group primitive database operations. Transactions compete for resources and the job of the database is to keep a transaction from observing the intermediate results of other transactions <ref> [3, 29, 36] </ref>. Design environments have a different set of criteria. Two designers should be able to cooperate interactively as they work: the designer of a support structure for an aircraft wing should be able to interact with another designer working on the control surfaces. <p> Intentions lists are used to eliminate the undo phase of recovery <ref> [3] </ref>.
Reference: [4] <author> Peter Buneman and Malcolm Atkinson. </author> <title> Inheritance and persistence in database programming languages. </title> <booktitle> In ACM SIGMOD Proceedings, </booktitle> <pages> pages 4-15, </pages> <year> 1986. </year>
Reference-contexts: In addition, we describe algorithms for two BOSS subsystems, cache coherency and recovery. 2.1 ObServer ObServer was the first object server our group developed [9, 13, 21]. The project had two main objectives: to support efficient traversal of an object space that supports identity <ref> [4] </ref> and to provide the primitives to support cooperative transaction synchronization for design environments [34, 24]. An object in ObServer consists of a unique object identifier (OID) coupled with a variable-size block of bytes. The OID labels the object's data and provides clients with a handle to the object.
Reference: [5] <author> M. Carey et al. </author> <title> The architecture of the EXODUS extensible DBMS. </title> <booktitle> In Proceedings of 1986 International Workshop on Object-Oriented Database Systems, </booktitle> <pages> pages 52-65, </pages> <booktitle> Asilomar Conference Center, </booktitle> <address> Pacific Grove, CA, </address> <month> September </month> <year> 1986. </year>
Reference-contexts: POMS transactions provide atomicity and recoverability for a single user, but do not confront the issues of multiuser concurrent access. 2.3 The Exodus Storage Manager The two systems previously described are persistent programming languages with specialized object stores. The Exodus project <ref> [7, 39, 5] </ref> offers a persistent programming language, E, built on top of the Exodus Storage Manager (ESM), a standalone object store [6]. Several other OODBs use ESM for persistent storage [47, 2].
Reference: [6] <author> M. Carey et al. </author> <title> Object and file management in the EXODUS extensible database system. </title> <booktitle> In Proceedings of the Twelfth International Conference on Very Large Data Bases, </booktitle> <pages> pages 91-100, </pages> <address> Kyoto, Japan, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: The Exodus project [7, 39, 5] offers a persistent programming language, E, built on top of the Exodus Storage Manager (ESM), a standalone object store <ref> [6] </ref>. Several other OODBs use ESM for persistent storage [47, 2]. ESM provides applications with the abstraction of objects, but the unit of transfer between the client and server is the page. <p> A number of other systems serve objects or pages: for example, Mneme [33], ESM <ref> [6] </ref>, and the original ObServer [21]. Postgres [45] and Starburst [42] are two extensible relational database systems. <p> Much of the functionality that ObServer offered is encapsulated in the segment storage class in BOSS. In addition, the ability to add new storage structures allows BOSS to be specialized for high performance for specific applications. The Exodus Storage Manager (ESM) <ref> [6] </ref>, a page server developed at the University of Wisconsin, provides support for values and indices. It generalizes the Aries transaction recovery system [32] to operate in the client-server model. Aries uses the concept of a log sequence number to reduce the time that a lock must be held 8.1.
Reference: [7] <author> M. Carey et al. </author> <title> The EXODUS extensible DBMS project: An overview. </title> <type> Technical Report 808, </type> <institution> Computer Science Department, University of Wisconsin - Madison, </institution> <year> 1988. </year> <note> 100 BIBLIOGRAPHY </note>
Reference-contexts: An object store provides persistence and distribution as a substrate of an object-oriented database (OODB). Developing the first generation of object stores was a challenge because OODBs extend the traditional notion of a database with an integrated, computationally complete data definition and programming language <ref> [43, 7, 33] </ref>. The demands these extensions place on the object store required entirely new architectures. Research into the architecture of object stores yielded the important results covered in Chapter 2, but this work needs to be reevaluated in light of three factors. <p> POMS transactions provide atomicity and recoverability for a single user, but do not confront the issues of multiuser concurrent access. 2.3 The Exodus Storage Manager The two systems previously described are persistent programming languages with specialized object stores. The Exodus project <ref> [7, 39, 5] </ref> offers a persistent programming language, E, built on top of the Exodus Storage Manager (ESM), a standalone object store [6]. Several other OODBs use ESM for persistent storage [47, 2].
Reference: [8] <author> David Clark. </author> <note> as quoted in Chapter 9 of J. </note> <author> Hennesy and D. Patterson, </author> <title> Computer Architecture a Quantitative Approach, 1990, </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: HIGH-LEVEL ARCHITECTURE 3.3 Asynchrony In a distributed system, communication overhead can become a bottleneck. Increasing network bandwidth alleviates the problem to a certain extent; however, network latency is not improving in proportion to bandwidth <ref> [8] </ref>. The cost per unit of information is significantly greater for a small message than for a larger message. Another important cost measure is the round-trip latency for synchronous communication, which is the basis of many concurrency-control and cache-coherency algorithms.
Reference: [9] <author> G. Delott. </author> <title> Performance improvements in the ObServer Object Server. </title> <type> Masters thesis, </type> <institution> Department of Computer Science, Brown University, </institution> <year> 1989. </year>
Reference-contexts: In addition, we describe algorithms for two BOSS subsystems, cache coherency and recovery. 2.1 ObServer ObServer was the first object server our group developed <ref> [9, 13, 21] </ref>. The project had two main objectives: to support efficient traversal of an object space that supports identity [4] and to provide the primitives to support cooperative transaction synchronization for design environments [34, 24]. <p> A performance-critical operation in an OODB is the mapping of logical OID s to physical data locations, and this mapping can occur many ways <ref> [33, 9] </ref>. Previous MOM designs did not include this mapping, on the rationale that a storage class should implement whatever logical-to-physical mapping best suits its semantics. For instance, a storage class that implements pages might compute the physical location from the logical identifier and save a table lookup.
Reference: [10] <author> EXODUS Project Document. </author> <title> EXODUS storage manager v3.0 architecture overview. </title> <institution> Computer Sciences Department, University of Wisconsin-Maddison, </institution> <note> (available by ftp from ftp.cs.wisc.edu), </note> <month> April </month> <year> 1993. </year>
Reference-contexts: When a page is initially fetched from the server, a shared lock is implicitly granted, and, at the end of a transaction, all locks are released <ref> [10] </ref>. ESM generalizes the ARIES recovery system for a client-server environment [15]. 10 CHAPTER 2. BACKGROUND 2.4 Concurrency Control These next three sections present algorithms rather than specific systems. This section discusses the optimistic, user-defined concurrency-control protocol used in BOSS.
Reference: [11] <editor> J. Eppinger, L. Mummert, and A. Spector, editors. Camelot and Avalon. </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: It does not provide recovery. Mneme semantics could possibly be provided by a storage class in a BOSS configuration. This would provide the benefits of a Mneme system and in addition recovery and the availability of other storage classes for specialized purposes. Camelot <ref> [11] </ref> is another system that could be classified as a page server, but it has a slightly different computation model. Camelot provides the abstraction of persistent virtual memory to data servers that run on the same node storing the persistent data. <p> The Camelot grid is an index structure stored in volatile memory and must be reconstructed after a failure. The 8.2. OBJECT-ORIENTED DATABASES 93 update and intentions lists in BOSS are stored persistently in the log and do not need to be recovered after a failure. The Avalon <ref> [11] </ref> language uses Camelot to provide a persistent C++. Because Camelot provides only persistent virtual memory, the semantics of the objects implemented in Avalon are lost at the persistence layer.
Reference: [12] <author> M. Carey et al. </author> <title> Shoring up persistent applications. </title> <booktitle> In ACM SIGMOD Proceedings, </booktitle> <year> 1994. </year>
Reference-contexts: This feature becomes more advantageous as clients perform more optimizing transformations, such as pointer swizzling or compression on data in the cache, and as architectures become heterogeneous, requiring translations between different caches. SHORE (Scalable Heterogeneous Object REpository) is a second-generation descendent of ESM and Exodus from Wisconsin <ref> [12] </ref>. SHORE shares BOSS's goal of increased extensibility but realizes it in a different manner. The means to extend SHORE is the Value-Added Server (VAS), which allows sophisticated users to implement new abstractions directly on SHORE servers, bypassing the type system and standard communication overhead.
Reference: [13] <author> M. Fernandez, S. Zdonik, and A. Ewald. </author> <title> ObServer: A storage system for object-oriented applications. </title> <type> Technical Report CS-90-27, </type> <institution> Brown University, Department of Computer Science, </institution> <year> 1990. </year>
Reference-contexts: In addition, we describe algorithms for two BOSS subsystems, cache coherency and recovery. 2.1 ObServer ObServer was the first object server our group developed <ref> [9, 13, 21] </ref>. The project had two main objectives: to support efficient traversal of an object space that supports identity [4] and to provide the primitives to support cooperative transaction synchronization for design environments [34, 24].
Reference: [14] <author> M. Franklin and M. Carey. </author> <title> Client-server caching revisited. </title> <booktitle> In International Workshop on Distributed Object Management, </booktitle> <address> Edmonton, Canada, </address> <year> 1992. </year>
Reference-contexts: Further, there is less dependence among modules, which facilitates the integration of new storage structures. High performance in a distributed system requires strict control of I/O costs. Cache coherency in a traditional client/server database architecture is based upon many small synchronous operations <ref> [14] </ref>. In a centralized system, communication is not an issue, but in a distributed system, these synchronous operations result in numerous small blocking messages. <p> The following examples illustrate the messages required to update an object X that is already cached at several clients. The first example (Figure 2.1) follows the callback locking protocol with invalidations <ref> [22, 14] </ref>. This protocol is synchronous in that all of the copies of an object have exactly the same state. <p> BOSS introduces a new protocol "invalidate on abort" that relaxes cache coherency to improve network utilization. In many systems, cache coherency is required for correctness, and the synchronous communication required becomes a bottleneck <ref> [14] </ref>. BOSS informs client caches of updates asynchronously. This approach allows BOSS to construct larger messages containing more updates and to make more efficient use of the network than even the best of the synchronous call back locking protocols. <p> The database and workloads are modeled after those used in simulations conducted by Franklin <ref> [14] </ref>, through because Franklin's simulations make different hardware assumptions the results are not directly comparable. The database consists of 40,000 objects, each 128 bytes long, clustered into 1,250 segments of 32 objects each. The resulting database is 6.5M including overhead. The workload is divided into hot and cold regions. <p> Data can be cached on a client's local disk for extended periods of time. However, cache coherency becomes a problem when caching data for long periods of time. AFS introduced call back locking which caches locks as well as data at clients. Franklin <ref> [14] </ref> shows that this protocol is desirable for database systems as well. Failures cause problems with consistency when locks are cached. AFS solves this problem by using locks that expire after a well-known period of time.
Reference: [15] <author> M. Franklin, M. Zwilling, C. Tan, M. Carey, and D. Dewitt. </author> <title> Crash recovery in client-server EXODUS. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <year> 1992. </year>
Reference-contexts: When a page is initially fetched from the server, a shared lock is implicitly granted, and, at the end of a transaction, all locks are released [10]. ESM generalizes the ARIES recovery system for a client-server environment <ref> [15] </ref>. 10 CHAPTER 2. BACKGROUND 2.4 Concurrency Control These next three sections present algorithms rather than specific systems. This section discusses the optimistic, user-defined concurrency-control protocol used in BOSS. The next section describes the difference between a synchronous and asynchronous cache-coherency protocol (BOSS actually has the ability to use either).
Reference: [16] <author> Michael T. Goodrich, Jyh-Jong Tsay, Darren E. Vengroff, and Jeffrey Scott Vit-ter. </author> <title> External-memory computational geometry. </title> <booktitle> In Proceedings of the 34th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 714-723, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: Third, applications such as hypermedia, geographic information systems, and the human genome project require new storage structures that cannot be supported efficiently by existing object stores. For example, geographic information systems require efficient multidimensional dynamic search structures for secondary storage, an area of active research <ref> [18, 16] </ref>. <p> The ability to add new functionality at the storage level allows BOSS, and therefore applications built using BOSS, to take advantage of new developments in storage technology and move into new domains. New developments have also occurred in multidimensional range searching in secondary storage <ref> [16] </ref>. Any of these new structures could be tested as a storage class within BOSS. In addition, the storage class has already allowed BOSS to be used in application domains beyond those for which it was designed (See 4.5).
Reference: [17] <author> J. </author> <title> Grey. Notes on database operating systems. </title> <editor> In R. Bayer, editor, </editor> <booktitle> Lecture Notes in Computer Science. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1978. </year> <note> BIBLIOGRAPHY 101 </note>
Reference-contexts: In addition, allowing the caches to drift temporarily means that communication failure can be tolerated and may eventually allow support for disconnected, mobile operation. 2. Efficient Recovery Technique BOSS's recovery algorithm improves on the popular and efficient write-ahead-logging <ref> [17] </ref>. BOSS's no-undo, no-redo write-ahead-logging does not require any updates to the database partition during recovery, reducing recovery to a single analysis scan of the log. The redos are applied on demand as the objects are read or asynchronously after recovery. 3. <p> Traditional write-ahead logging (WAL) is a synchronous protocol <ref> [17] </ref> that synchronizes all copies of every object before normal operation begins. BOSS introduces an asynchronous algorithm that does not have to modify any objects to achieve synchronization (See Chapter 5). <p> ALGORITHMS 61 endif End Apply 5.8.2 Prepare and Commit This section describes what happens in the prepare and commit phases at the server. The general flow of information during a transaction is presented in Section 4.2, and we use the two-phase commit protocol defined in Grey <ref> [17] </ref>. BOSS executes the following pseudocode during the prepare phase. This implementation is not reentrant, so only one transaction can prepare at a time.
Reference: [18] <author> A. Guttman. R-trees: </author> <title> A dynamic index structure for spatial searching. </title> <editor> In B. Yormack, editor, </editor> <booktitle> ACM SIGMOD Proceedings, </booktitle> <pages> pages 47-57, </pages> <address> Boston, MA, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: Third, applications such as hypermedia, geographic information systems, and the human genome project require new storage structures that cannot be supported efficiently by existing object stores. For example, geographic information systems require efficient multidimensional dynamic search structures for secondary storage, an area of active research <ref> [18, 16] </ref>.
Reference: [19] <author> L. Haas et al. </author> <title> Starburst mid-flight: As the dust clears. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 143-160, </pages> <month> March </month> <year> 1990. </year> <note> Also IBM Almaden Research Center Research Report RJ 7278 (68535). </note>
Reference-contexts: Each Gem process has its own virtual copy of the entire database. A true copy of any part of the database is made only when that part is modified. Upon successful termination of a transaction, changes are made permanent atomically by careful pointer manipulation. 8.3 Extended Relational Databases Starburst <ref> [42, 19, 26] </ref> extends relational databases in five areas: external data storage, storage management, access methods, abstract types, and complex objects. Many of the issues Starburst addresses are at the data-model level and thus should be compared to an OODB, not to an object store.
Reference: [20] <author> M. Herlihy. </author> <title> Apologizing versus asking permission: Optimistic concurrency control for abstract datatypes. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 15(1) </volume> <pages> 96-124, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Of the several global criteria discussed in [29], we chose dynamic atomicity because it covers both two-phase locking and the optimistic protocol that makes asynchrony possible in BOSS. BOSS uses conflict-based backward validation to maintain global correctness <ref> [20] </ref>. This protocol checks committing operations against previously committed operations. The alternative, forward validation, checks committing operations against operations that intend to commit. <p> THE STORAGE CLASS performance with specialized storage structures tuned to a particular application's needs. This goal requires a set of interfaces that allow a great deal of flexibility without undue overhead. The goal is met in large part through an efficient implementation of user-defined atomic datatypes <ref> [46, 20] </ref>. The storage class cooperates with the transaction manager for correctness. The storage class implements a local policy suited to its semantics for which the storage class designer guarantees correctness. <p> An LSN is a tuple in which the low order bits encode a memory address in the log. Interpreted as an integer, this number strictly increases as the log is written until the log wraps around. Our concurrency-control algorithm <ref> [20] </ref> requires a timestamp that increases strictly over all time, not in a piecemeal fashion. To correct this problem, the memory address is augmented with a count of the number of times the log has wrapped around.
Reference: [21] <author> M. Hornick and S. Zdonik. </author> <title> A shared, segmented-memory system for an object-oriented database. </title> <journal> ACM Transactions on Office Information Systems, </journal> <volume> 5(1) </volume> <pages> 70-85, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: In addition, we describe algorithms for two BOSS subsystems, cache coherency and recovery. 2.1 ObServer ObServer was the first object server our group developed <ref> [9, 13, 21] </ref>. The project had two main objectives: to support efficient traversal of an object space that supports identity [4] and to provide the primitives to support cooperative transaction synchronization for design environments [34, 24]. <p> It provides objects clustered into segments. Neither the objects nor the segments can change size after creation, thus the name Fixed. The functionality and implementation of these segments are similar to those provided by the original ObServer system <ref> [21] </ref>. A segment is a collection of variable-length byte streams. A byte stream is what is typically meant by an object in an object store, although in BOSS the meaning of object is more general. <p> A number of other systems serve objects or pages: for example, Mneme [33], ESM [6], and the original ObServer <ref> [21] </ref>. Postgres [45] and Starburst [42] are two extensible relational database systems. <p> In an object store, the identity of an object is fully independent of its value, size, or location, so that an object can expand and move easily. However, this flexibility comes at the cost of added complexity in dereferencing an object. ObServer <ref> [21] </ref>, the precursor to BOSS, introduced several features: semantic clustering of related objects, a novel lock set for cooperative work, and a notification system that also supports cooperative work. BOSS improves on ObServer in the areas of distribution, extensibility, and performance. ObServer offered only multi-client, single-server distribution.
Reference: [22] <author> J. H. Howard et al. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM TOCS, </journal> <volume> 6, </volume> <year> 1988. </year>
Reference-contexts: The following examples illustrate the messages required to update an object X that is already cached at several clients. The first example (Figure 2.1) follows the callback locking protocol with invalidations <ref> [22, 14] </ref>. This protocol is synchronous in that all of the copies of an object have exactly the same state. <p> Postgres [45] and Starburst [42] are two extensible relational database systems. Object servers draw from file system technology for persistent storage and cache coherency; this chapter closes with a comparison between BOSS and the Andrew File System <ref> [22] </ref> and the Sprite Log-Structured File System [40]. 8.1 Ob ject and Page Servers The basic service BOSS provides is transaction support for persistent objects in a distributed client-server environment. Page servers and object servers both provide this service. <p> In an object store, the problem would be even worse because of the finer granularity of naming. Also, garbage collection in a distributed persistent heap is much more complex than segment compaction [23]. AFS is interesting for its distribution properties. AFS 3.x <ref> [22] </ref> is a distributed file system that serves a purpose similar to Sun's NFS. However, the scale of the distributed system within which AFS operates is much larger than that of Sun's NFS: NFS was meant to operate within a single organization, whereas AFS can handle global distribution.
Reference: [23] <author> E. Kolodner, B. Liskov, and W. Weihl. </author> <title> Atomic garbage collection: Managing a stable heap. </title> <booktitle> In ACM SIGMOD Proceedings, </booktitle> <year> 1989. </year>
Reference-contexts: In an object store, the problem would be even worse because of the finer granularity of naming. Also, garbage collection in a distributed persistent heap is much more complex than segment compaction <ref> [23] </ref>. AFS is interesting for its distribution properties. AFS 3.x [22] is a distributed file system that serves a purpose similar to Sun's NFS.
Reference: [24] <author> H. Korth and G. Speegle. </author> <title> Formal model of correctness without serializability. </title> <booktitle> In ACM SIGMOD Proceedings, </booktitle> <year> 1988. </year>
Reference-contexts: The project had two main objectives: to support efficient traversal of an object space that supports identity [4] and to provide the primitives to support cooperative transaction synchronization for design environments <ref> [34, 24] </ref>. An object in ObServer consists of a unique object identifier (OID) coupled with a variable-size block of bytes. The OID labels the object's data and provides clients with a handle to the object. <p> The BOSS architecture assumes that a layer outside of the system maps the semantics of design transactions down to a series of short atomic transactions <ref> [34, 24] </ref>. This layer coordinates the activities of the designers to provide the desired semantics, but it has several other effects as well.
Reference: [25] <author> S. Le*er, M. McKusick, M. Karels, and J. Quaterman. </author> <title> The Design and Implementation of the 4.3BSD UNIX Operating System. </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Section 6.5 describes a policy that exploits this invariant. MOM provides a general-purpose memory-management policy that storage classes can specialize to suit their needs. The least-recently-used (LRU) replacement policy, with fetching on demand, is the most common general-purpose memory-management-policy <ref> [25] </ref>. MOM uses a variant of LRU as its general-purpose policy and provides the storage class with high-level control to change the behavior of the default policy. If contention occurs, a default global replacement policy based on a two-handed clock algorithm [25] arbitrates, as illustrated in Figure 6.3. <p> fetching on demand, is the most common general-purpose memory-management-policy <ref> [25] </ref>. MOM uses a variant of LRU as its general-purpose policy and provides the storage class with high-level control to change the behavior of the default policy. If contention occurs, a default global replacement policy based on a two-handed clock algorithm [25] arbitrates, as illustrated in Figure 6.3. A cleaning hand moves through the cached objects marking the objects unread; this hand is kept some fixed distance ahead of the allocation hand.
Reference: [26] <author> T. Lehman and B. Lindsay. </author> <title> The Starburst long field manager. </title> <booktitle> In Proceedings of the Fifteenth International Conference on Very Large Data Bases, </booktitle> <pages> pages 375-383, </pages> <address> Amsterdam, The Netherlands, </address> <month> August </month> <year> 1989. </year> <note> Also IBM Almaden Research Center Research Report RJ 6899 (65725). </note>
Reference-contexts: Each Gem process has its own virtual copy of the entire database. A true copy of any part of the database is made only when that part is modified. Upon successful termination of a transaction, changes are made permanent atomically by careful pointer manipulation. 8.3 Extended Relational Databases Starburst <ref> [42, 19, 26] </ref> extends relational databases in five areas: external data storage, storage management, access methods, abstract types, and complex objects. Many of the issues Starburst addresses are at the data-model level and thus should be compared to an OODB, not to an object store.
Reference: [27] <author> B. Liskov et al. </author> <title> Replication in the HARP file system. </title> <booktitle> In 13th ACM SOSP, </booktitle> <year> 1991. </year> <note> 102 BIBLIOGRAPHY </note>
Reference-contexts: A group of designers working against a deadline will not tolerate long downtimes for their CAD system. The problem of availability is even more acute in a computer-integrated manufacturing system where the database must respond to hard real-time constraints. High availability can be achieved through redundancy <ref> [27, 37] </ref>, but the cost quickly becomes prohibitive. Highly available systems will not become widely used unless the resource requirements are reduced. Third, applications such as hypermedia, geographic information systems, and the human genome project require new storage structures that cannot be supported efficiently by existing object stores. <p> THOR's designers plan to offer highly available, replicated servers using a primary copy replication scheme [35]. The group has implemented this algorithm in the HARP 94 CHAPTER 8. RELATED RESEARCH replicated file system, which provides near-UNIX semantics in a highly available file system <ref> [27] </ref>. A critical issue in a primary copy replicated system is the time required for the secondary machine after the primary fails. Techniques from BOSS's NR-WAL might prove useful in reducing the fail-over time.
Reference: [28] <author> C. Lynch and M. Stonebraker. </author> <title> Extended user-defined indexing with application to textual databases. </title> <booktitle> In Proceedings of the Fourteenth International Conference on Very Large Data Bases, </booktitle> <pages> pages 306-317, </pages> <address> Los Angeles, CA, </address> <year> 1988. </year>
Reference-contexts: The storage class implementor has exact control over whether parts of the abstraction are built at the client or the server. The goals of the Postgres Storage Manager are instantaneous recovery, historical access, and utilization of new technology <ref> [45, 28] </ref>. Postgres provides a linear history and allows more than one version of an object to be viewed in a transaction. Because Postgres keeps the entire history of all its data, the recovery system differs from conventional systems.
Reference: [29] <author> N. Lynch, M. Merritt, W. Weihl, and A. Fekete. </author> <title> Atomic Transactions. </title> <publisher> Morgan Kaufman, </publisher> <year> 1994. </year>
Reference-contexts: Traditional database systems provide a competitive transaction abstraction to group primitive database operations. Transactions compete for resources and the job of the database is to keep a transaction from observing the intermediate results of other transactions <ref> [3, 29, 36] </ref>. Design environments have a different set of criteria. Two designers should be able to cooperate interactively as they work: the designer of a support structure for an aircraft wing should be able to interact with another designer working on the control surfaces. <p> The basic requirement of atomic datatypes is that all types must serialize transactions in the same order. The criteria used in BOSS, dynamic atomicity, serializes transactions in the order in which they commit. Of the several global criteria discussed in <ref> [29] </ref>, we chose dynamic atomicity because it covers both two-phase locking and the optimistic protocol that makes asynchrony possible in BOSS. BOSS uses conflict-based backward validation to maintain global correctness [20]. This protocol checks committing operations against previously committed operations.
Reference: [30] <author> D. Maier and J. Stein. </author> <title> Indexing in an object-oriented DBMS. </title> <booktitle> In Proceedings of 1986 International Workshop on Object-Oriented Database Systems, </booktitle> <pages> pages 171-182, </pages> <booktitle> Asilomar Conference Center, </booktitle> <address> Pacific Grove, CA, </address> <month> September </month> <year> 1986. </year>
Reference-contexts: Techniques from BOSS's NR-WAL might prove useful in reducing the fail-over time. Of specific relevance is BOSS's use of log sequence numbers rather than clocked timestamps or operations counts. GemStone operates in a distributed client-server system and extends SmallTalk with persistence, concurrent access, transactions, and indexing over large collections <ref> [30, 31, 38] </ref>. The original clients were PCs and the original servers were VAXs running VMS; the system is still in existence and now supports a wide variety of clients and servers as well as the C++ language. GemStone is built on a query shipping model.
Reference: [31] <author> D. Maier and J. Stein. </author> <title> Development and inplementation of an object-oriented DBMS. </title> <editor> In B. Shriver and P. Wegner, editors, </editor> <booktitle> Research Directions in Object-Oriented Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: Techniques from BOSS's NR-WAL might prove useful in reducing the fail-over time. Of specific relevance is BOSS's use of log sequence numbers rather than clocked timestamps or operations counts. GemStone operates in a distributed client-server system and extends SmallTalk with persistence, concurrent access, transactions, and indexing over large collections <ref> [30, 31, 38] </ref>. The original clients were PCs and the original servers were VAXs running VMS; the system is still in existence and now supports a wide variety of clients and servers as well as the C++ language. GemStone is built on a query shipping model.
Reference: [32] <author> C. Mohan et al. </author> <title> Aries: A transaction recovery method supporting fine-granularity locking and partial rollbacks using write-ahead logging. </title> <journal> ACM TODS, </journal> <volume> 17(1), </volume> <year> 1992. </year>
Reference-contexts: All three of these passes require scanning the log and the last pass requires updates to both the log and the database. ARIES (Algorithm for Recovery and Isolation Exploiting Semantics), a variant of a write-ahead logging protocol, developed at IBM Almaden Research Center <ref> [32] </ref> supports faster recovery in a pessimistic system using a log sequence number (LSN). An LSN is the index of a log record that is used to efficiently determine the state of a page with respect to the stable state, the net effect of all committed transactions. <p> In addition, the ability to add new storage structures allows BOSS to be specialized for high performance for specific applications. The Exodus Storage Manager (ESM) [6], a page server developed at the University of Wisconsin, provides support for values and indices. It generalizes the Aries transaction recovery system <ref> [32] </ref> to operate in the client-server model. Aries uses the concept of a log sequence number to reduce the time that a lock must be held 8.1. OBJECT AND PAGE SERVERS 91 and facilitate recovery in a pessimistic system.
Reference: [33] <author> J. Eliot B. Moss. </author> <title> Design of the Mneme persistent object store. </title> <journal> ACM Trans. Inf. Syst., </journal> <volume> 8(2) </volume> <pages> 103-139, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: An object store provides persistence and distribution as a substrate of an object-oriented database (OODB). Developing the first generation of object stores was a challenge because OODBs extend the traditional notion of a database with an integrated, computationally complete data definition and programming language <ref> [43, 7, 33] </ref>. The demands these extensions place on the object store required entirely new architectures. Research into the architecture of object stores yielded the important results covered in Chapter 2, but this work needs to be reevaluated in light of three factors. <p> A performance-critical operation in an OODB is the mapping of logical OID s to physical data locations, and this mapping can occur many ways <ref> [33, 9] </ref>. Previous MOM designs did not include this mapping, on the rationale that a storage class should implement whatever logical-to-physical mapping best suits its semantics. For instance, a storage class that implements pages might compute the physical location from the logical identifier and save a table lookup. <p> A number of other systems serve objects or pages: for example, Mneme <ref> [33] </ref>, ESM [6], and the original ObServer [21]. Postgres [45] and Starburst [42] are two extensible relational database systems. <p> A VAS could potentially implement a relational database server, but VAS does not have the ability to define the concurrent semantics for the abstractions it creates as the BOSS storage class does. Concurrency control is performed on the underlying physical structures using read/write locking. The Mneme Persistent Object Store <ref> [33] </ref> explores the integration of an object store with a persistent programming language. It provides a persistent heap of objects that are available in a distributed system. The object model for Mneme is fixed, but it does offer some support for specialized buffering policies.
Reference: [34] <author> M. Nodine. </author> <title> A cooperative transaction model for design databases. </title> <editor> In A. Elma-garmid, editor, </editor> <title> Database Transaction Models for Advanced Applications. </title> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: The project had two main objectives: to support efficient traversal of an object space that supports identity [4] and to provide the primitives to support cooperative transaction synchronization for design environments <ref> [34, 24] </ref>. An object in ObServer consists of a unique object identifier (OID) coupled with a variable-size block of bytes. The OID labels the object's data and provides clients with a handle to the object. <p> CACHE COHERENCY EXPERIMENTS 7.1 Assumptions About Contention One characteristic of optimistic protocols is increased aborts. This feature is of particular concern in a design environment because engineers are not particularly tolerant of lost work. Concurrency-control semantics for engineers are studied in <ref> [34] </ref>. A se-rializable or atomic transaction is meant to be a single indivisible unit of work, such as a bank deposit or a flight reservation, and thus the work done by the transaction must be isolated from other concurrent transactions. <p> The BOSS architecture assumes that a layer outside of the system maps the semantics of design transactions down to a series of short atomic transactions <ref> [34, 24] </ref>. This layer coordinates the activities of the designers to provide the desired semantics, but it has several other effects as well.
Reference: [35] <author> B. Oki and B. Liskov. </author> <title> Viewstamped replication: A new primary copy method to support highly-available distributed systems. </title> <booktitle> In Proceedings of the 7th ACM Symposium on Principles of Distributed Systems, </booktitle> <year> 1988. </year>
Reference-contexts: THOR's designers plan to offer highly available, replicated servers using a primary copy replication scheme <ref> [35] </ref>. The group has implemented this algorithm in the HARP 94 CHAPTER 8. RELATED RESEARCH replicated file system, which provides near-UNIX semantics in a highly available file system [27]. A critical issue in a primary copy replicated system is the time required for the secondary machine after the primary fails.
Reference: [36] <author> C. Papadimitriou. </author> <title> The Theory of Database Concurrency Control. </title> <publisher> Computer Science Press, </publisher> <year> 1986. </year> <note> BIBLIOGRAPHY 103 </note>
Reference-contexts: Traditional database systems provide a competitive transaction abstraction to group primitive database operations. Transactions compete for resources and the job of the database is to keep a transaction from observing the intermediate results of other transactions <ref> [3, 29, 36] </ref>. Design environments have a different set of criteria. Two designers should be able to cooperate interactively as they work: the designer of a support structure for an aircraft wing should be able to interact with another designer working on the control surfaces.
Reference: [37] <author> D. Patterson, G. Gibson, and R. Katz. </author> <title> A case for redundant arrays of inexpensive disks. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <month> June </month> <year> 1988. </year>
Reference-contexts: A group of designers working against a deadline will not tolerate long downtimes for their CAD system. The problem of availability is even more acute in a computer-integrated manufacturing system where the database must respond to hard real-time constraints. High availability can be achieved through redundancy <ref> [27, 37] </ref>, but the cost quickly becomes prohibitive. Highly available systems will not become widely used unless the resource requirements are reduced. Third, applications such as hypermedia, geographic information systems, and the human genome project require new storage structures that cannot be supported efficiently by existing object stores.
Reference: [38] <author> A. Purdy, B. Schuchardt, and D. Maier. </author> <title> Integrating an object server with other worlds. </title> <journal> ACM Transactions on Office Information Systems, </journal> <volume> 5(1) </volume> <pages> 27-47, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: Techniques from BOSS's NR-WAL might prove useful in reducing the fail-over time. Of specific relevance is BOSS's use of log sequence numbers rather than clocked timestamps or operations counts. GemStone operates in a distributed client-server system and extends SmallTalk with persistence, concurrent access, transactions, and indexing over large collections <ref> [30, 31, 38] </ref>. The original clients were PCs and the original servers were VAXs running VMS; the system is still in existence and now supports a wide variety of clients and servers as well as the C++ language. GemStone is built on a query shipping model.
Reference: [39] <author> J. Richardson and M. Carey. </author> <title> Programming constructs for database system implementation in EXODUS. </title> <booktitle> In Proceedings of the 1987 ACM SIGMOD International Conference, </booktitle> <address> San Francisco, CA, </address> <month> May </month> <year> 1987. </year> <institution> Also University of Wisconsin - Madison Computer Science Department Techreport 680. </institution>
Reference-contexts: POMS transactions provide atomicity and recoverability for a single user, but do not confront the issues of multiuser concurrent access. 2.3 The Exodus Storage Manager The two systems previously described are persistent programming languages with specialized object stores. The Exodus project <ref> [7, 39, 5] </ref> offers a persistent programming language, E, built on top of the Exodus Storage Manager (ESM), a standalone object store [6]. Several other OODBs use ESM for persistent storage [47, 2].
Reference: [40] <author> M. Rosenblum and J. K. Ousterhout. </author> <title> The design and implementation of a log-structured file system. </title> <booktitle> In 13th SOSP, </booktitle> <year> 1991. </year>
Reference-contexts: Postgres [45] and Starburst [42] are two extensible relational database systems. Object servers draw from file system technology for persistent storage and cache coherency; this chapter closes with a comparison between BOSS and the Andrew File System [22] and the Sprite Log-Structured File System <ref> [40] </ref>. 8.1 Ob ject and Page Servers The basic service BOSS provides is transaction support for persistent objects in a distributed client-server environment. Page servers and object servers both provide this service. <p> RELATED RESEARCH File System (LFS) and the Andrew File System (AFS). LFS is interesting because it shows the feasibility of reading from a log given a reasonable cache. BOSS uses this facility to accelerate recovery and simplify transaction management data structures. LFS <ref> [40] </ref> keeps all data in a log, significantly reducing the cost of a write. The disadvantage of a log is that it does not support random access. The file location information must be kept stable, resulting in a major overhead cost because this information is constantly changing.
Reference: [41] <author> M. Satyanarayanan, Henry H. Mashburn, Puneet Kumar, David C. Steere, and James J. Kistler. </author> <title> Lightweight recoverable virtual memory. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 12(1) </volume> <pages> 33-57, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: One major difference is that it is expensive to look at the object when making decisions. There is a location operation to determine whether or not an object is resident before accessing it. MOM memory objects are actually memory-mapped portions of a container file or raw partition <ref> [41] </ref>. Memory mapping has numerous advantages. Using memory mapping completely avoids the problem of double buffering (writing an object to a second stable storage location for temporary storage). The operating system keeps track of modifications to memory objects. When an MO is pinned it is assigned a virtual-memory address.
Reference: [42] <author> P. Schwaarz et al. </author> <title> Extensibility in the Starburst Datbase System. </title> <booktitle> In International Workshop on Object-Oriented Database Systems, </booktitle> <year> 1986. </year>
Reference-contexts: A number of other systems serve objects or pages: for example, Mneme [33], ESM [6], and the original ObServer [21]. Postgres [45] and Starburst <ref> [42] </ref> are two extensible relational database systems. <p> Each Gem process has its own virtual copy of the entire database. A true copy of any part of the database is made only when that part is modified. Upon successful termination of a transaction, changes are made permanent atomically by careful pointer manipulation. 8.3 Extended Relational Databases Starburst <ref> [42, 19, 26] </ref> extends relational databases in five areas: external data storage, storage management, access methods, abstract types, and complex objects. Many of the issues Starburst addresses are at the data-model level and thus should be compared to an OODB, not to an object store.
Reference: [43] <author> G. Shaw and S. Zdonik. </author> <title> A query algebra for object-oriented databases. </title> <booktitle> In Proceedings of the Sixth International Conference on Data Engineering, </booktitle> <address> Los Angeles, CA, </address> <month> February </month> <year> 1990. </year>
Reference-contexts: An object store provides persistence and distribution as a substrate of an object-oriented database (OODB). Developing the first generation of object stores was a challenge because OODBs extend the traditional notion of a database with an integrated, computationally complete data definition and programming language <ref> [43, 7, 33] </ref>. The demands these extensions place on the object store required entirely new architectures. Research into the architecture of object stores yielded the important results covered in Chapter 2, but this work needs to be reevaluated in light of three factors.
Reference: [44] <author> K. Smith and S. Zdonik. </author> <title> Intermedia: A case study of the difference between relational and object-oriented database systems. </title> <booktitle> In Proceedings of the ACM Object-Oriented Programming Systems, Languages and Applications Conference, </booktitle> <year> 1987. </year> <note> 104 BIBLIOGRAPHY </note>
Reference-contexts: Because ObServer was intended to support different types of systems and object formats, ObServer has no knowledge of the structure of an object. Only client applications can interpret the semantics of an object. Efficient traversal of a highly connected object space is a serious problem in a relational database <ref> [44] </ref>. ObServer minimizes the cost of navigating a complex graph by clustering related objects together on disk so they can be retrieved as a group. 8 CHAPTER 2. BACKGROUND Because it does not know the semantics of its objects, ObServer cannot determine the best groupings.
Reference: [45] <author> M. Stonebraker. </author> <title> The design of the Postgres storage system. </title> <booktitle> In Proc. 13th VLDB, </booktitle> <year> 1987. </year>
Reference-contexts: If the LSN on the page is greater than or equal to the operation's LSN, the operation is reflected in the state of the page; otherwise, the operation is not yet reflected in the state of the page. The POSTGRES Storage Manager <ref> [45] </ref> supports transaction management without using a conventional WAL. POSTGRES uses an update log with a large amount of non-volatile RAM to avoid synchronous writes at commit and attain instantaneous recovery. <p> A number of other systems serve objects or pages: for example, Mneme [33], ESM [6], and the original ObServer [21]. Postgres <ref> [45] </ref> and Starburst [42] are two extensible relational database systems. <p> The storage class implementor has exact control over whether parts of the abstraction are built at the client or the server. The goals of the Postgres Storage Manager are instantaneous recovery, historical access, and utilization of new technology <ref> [45, 28] </ref>. Postgres provides a linear history and allows more than one version of an object to be viewed in a transaction. Because Postgres keeps the entire history of all its data, the recovery system differs from conventional systems.
Reference: [46] <author> W. Weihl and B. Liskov. </author> <title> Implementation of resilient atomic data types. </title> <booktitle> In ACM Transactions on Programing Languages and Systems, </booktitle> <month> April </month> <year> 1985. </year>
Reference-contexts: The redos are applied on demand as the objects are read or asynchronously after recovery. 3. Local Concurrency Control BOSS applies the theory of local concurrency control to separate concurrency control and storage management concerns <ref> [46] </ref>. Objects in BOSS are fully abstract with respect to the transaction manager, a model that supports all existing database access methods as well as any that may be invented in the future. No other database system has applied this theory in this way. <p> The final section presents a standard means of crash recovery. Traditional database concurrency control provides correct concurrent operation for only one or a small set of system defined datatypes, record, page, file, B-tree, etc. User-defined atomic datatypes allow implementors to design their applications using the best suited datatypes <ref> [46] </ref>, the advantage being that higher levels of concurrency can be achieved than by using only system-defined datatypes. The correctness of transactions is a global property because it is a constraint across all operations on all objects. <p> This novel feature has implications for concurrency control and recovery. 24 CHAPTER 4. THE STORAGE CLASS Each storage class defines its own local type-specific correctness criterion that is mediated by a global timestamp-based optimistic protocol. The advantages of type-specific concurrency control are discussed at length in <ref> [46] </ref>. In short, higher potential concurrency can be achieved by taking advantage of the semantics of the various operations that can be performed on an object. Concurrency control and recovery are performed on a per object basis within a class. <p> THE STORAGE CLASS performance with specialized storage structures tuned to a particular application's needs. This goal requires a set of interfaces that allow a great deal of flexibility without undue overhead. The goal is met in large part through an efficient implementation of user-defined atomic datatypes <ref> [46, 20] </ref>. The storage class cooperates with the transaction manager for correctness. The storage class implements a local policy suited to its semantics for which the storage class designer guarantees correctness. <p> A modifier that does not observe the state of the underlying object is called a blind operator <ref> [46] </ref>. Signal is such an operator. Blind operators never cause semantic conflicts, but can cause physical conflicts. BOSS recovery has a physical requirement that modifiers be linearly linked. In Weihl's terminology [46], modifiers cannot commute. For Note, this means that Signal can cause an abort. <p> A modifier that does not observe the state of the underlying object is called a blind operator <ref> [46] </ref>. Signal is such an operator. Blind operators never cause semantic conflicts, but can cause physical conflicts. BOSS recovery has a physical requirement that modifiers be linearly linked. In Weihl's terminology [46], modifiers cannot commute. For Note, this means that Signal can cause an abort. This constraint is not as bad as it might seem at first.
Reference: [47] <author> D. Wells, J. A. Blakeley, and C. W. Thompson. </author> <title> Architecture of an open object-oriented database management system. </title> <journal> IEEE Computer, </journal> <volume> 25(10):74, </volume> <month> October </month> <year> 1992. </year>
Reference-contexts: The Exodus project [7, 39, 5] offers a persistent programming language, E, built on top of the Exodus Storage Manager (ESM), a standalone object store [6]. Several other OODBs use ESM for persistent storage <ref> [47, 2] </ref>. ESM provides applications with the abstraction of objects, but the unit of transfer between the client and server is the page. For this reason, ESM is a page server rather than an object server, which moves objects or segments between the client and server.
References-found: 47

