URL: http://www.eecs.umich.edu/~qstout/pap/SIAMJSC99.ps
Refering-URL: http://www.eecs.umich.edu/~qstout/papers.html
Root-URL: http://www.eecs.umich.edu
Title: Using Path Induction to Evaluate Sequential Allocation Procedures  
Author: Janis P. Hardwick Quentin F. Stout 
Keyword: backward induction, adaptive allocation, stage, group sampling, path counting, forward induction, Bayesian, bandit problems, stochastic optimization  
Date: 14 Dec 1997.  
Address: Ann Arbor, MI 48109  
Affiliation: Statistics Department EECS Department University of Michigan,  
Note: To appear in SIAM Journal on Scientific Computing  AMS Classifications: 62L10, 90C35, 68Q25, 62A15 Copyright c fl1997. Last modified:  Research supported in part by National Science Foundation grants DMS-9157715 and DMS-9504980.  
Abstract: Path induction is a technique to speed the process of making multiple exact evaluations of a sequential allocation procedure, where the options are discrete and their outcomes follow a discrete distribution. Multiple evaluations are needed for determining criteria such as maxima or minima over parameter regions (where the location of the extremal value is unknown in advance), for visualizing characteristics such as robustness, or for obtaining the distribution of a statistic rather than just its mean. By using an initial phase to determine the number of paths reaching each terminal state, the subsequent evaluations are far faster than repeated use of standard evaluation techniques. Algorithms are given for fully sequential and staged sequential procedures, and the procedures can be either deterministic or random. The procedures can be generated by any technique (including dynamic programming or ad hoc approaches), and the evaluations performed can be quite flexible and need not be related to the method of obtaining the procedure. While the emphasis is on path induction, the techniques used to speed up the analyses of staged allocation procedures can also be used to improve backward induction for such procedures. If multiple evaluations need to be carried out, however, path induction will still be far superior. For each parameter configuration to be evaluated, one reduces the time by a factor of n, where n is the size of the experiment, by using path induction rather than the standard technique of backward induction. In some settings the savings is significantly greater than n. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Agrawal, R., Hegde, M.V., and Teneketzis, D. </author> <year> (1988), </year> <title> "Asymptotically efficient adaptive allocation rules for the multiarmed bandit problem with switching costs", </title> <journal> IEEE Trans. Auto. Control 33, </journal> <pages> pp. 899-906. </pages>
Reference-contexts: However, if the natural states are used, then there are criteria such as switching costs which cannot be evaluated. In a basic switching cost model <ref> [1, 12] </ref>, there is a fixed cost every time the experiment switches from one arm to another. For example, in a two-armed Bernoulli experiment, one might reach state (2,0,2,0) via 1, 2, or 3 switches, and the costs would vary correspondingly.
Reference: [2] <author> Bather, J. </author> <year> (1995), </year> <title> "Response adaptive allocation and selection bias", Adaptive Designs, </title> <editor> N. Flournoy and W.F. Rosenberger, eds., </editor> <booktitle> IMS Lecture Notes-Monograph Series 25, </booktitle> <pages> pp. 23-35. </pages>
Reference-contexts: For example, they require knowing the outcomes of previous allocations before the next allocation can be decided, and this prohibits the use of concurrent observations. Also, they are often difficult to randomize, which introduces possibilities such as selection bias <ref> [2] </ref>. Due to these concerns, investigators often prefer to use procedures that proceed in stages, where outcomes from previous stages are used to decide the number of observations from each arm for the next stage. Within a stage, however, one can incorporate concurrency and constrained randomization.
Reference: [3] <author> Bechhofer, R.E., Kiefer, J., and Sobel, M. </author> <year> (1968), </year> <title> Sequential Identification and Ranking Procedures, </title> <publisher> Univ. Chicago Press. </publisher>
Reference-contexts: The P (CS) is based on having observed a total of n responses and the assumption that the probabilities differ by at least ffi; see <ref> [3] </ref> for more details on these problems. In this best choice problem, it is known that one is least likely to make a correct selection when the success probabilities differ by exactly ffi. However, in general, it is not known which pair of probabilities achieve the minimum. <p> For example, suppose one is evaluating Vector-at-a-Time allocation (taking one observation from each arm at each step) and a stopping rule that halts if the number of successes on one arm is r more than on the other arm, or if level n is reached (see <ref> [3, 7] </ref>).
Reference: [4] <author> Bellman, R. </author> <year> (1961), </year> <title> Adaptive Control Processes: A Guided Tour, </title> <publisher> Princeton Univ. Press. </publisher>
Reference-contexts: This problem combines the goals of two well known design problems as well as both frequentist and Bayesian viewpoints. The first problem is the finite horizon, Bernoulli two-armed bandit problem, (2-AB), an allocation procedure of considerable vintage <ref> [4, 6] </ref>. In this problem one samples sequentially from either of two dichotomous populations ("arms") in an attempt to maximize the number of successes garnered after having taken a total of n observations.
Reference: [5] <author> Berry, D.A. and Eick, S.G. </author> <year> (1995), </year> <title> "Adaptive assignment versus balanced randomization in clinical trials| a decision-analysis", Stat. </title> <booktitle> in Medicine 14, </booktitle> <pages> pp. 231-246. </pages>
Reference-contexts: For example, for several years now, we have been able to use path induction on workstations [9] to perform calculations that had previously been done using backward induction on supercomputers <ref> [5] </ref>. This speed encourages more extensive analysis and visualization of designs, helping users achieve better optimizations and tradeoffs among multiple criteria. As another example of the restrictiveness of the computational space and time constraints, Jones, 1992, computed results for the 2-AB problem that we described in Section 1.
Reference: [6] <author> Bradt, R.N., Johnson, S.M. and Karlin, S. </author> <year> (1956), </year> <title> "On sequential designs for maximizing the sum of n observations", </title> <journal> Ann. Math. Stat. </journal> <volume> 27, </volume> <pages> pp. 1060-1074. </pages>
Reference-contexts: This problem combines the goals of two well known design problems as well as both frequentist and Bayesian viewpoints. The first problem is the finite horizon, Bernoulli two-armed bandit problem, (2-AB), an allocation procedure of considerable vintage <ref> [4, 6] </ref>. In this problem one samples sequentially from either of two dichotomous populations ("arms") in an attempt to maximize the number of successes garnered after having taken a total of n observations.
Reference: [7] <author> Buringer, H., Martin, H. and Schriever, K.H. </author> <year> (1980), </year> <title> Nonparametric Sequential Selection Procedures, </title> <publisher> Birkhauser. </publisher>
Reference-contexts: For example, suppose one is evaluating Vector-at-a-Time allocation (taking one observation from each arm at each step) and a stopping rule that halts if the number of successes on one arm is r more than on the other arm, or if level n is reached (see <ref> [3, 7] </ref>).
Reference: [8] <author> Gittins, </author> <title> J.C. (1979) "Bandit processes and dynamic allocation indices", </title> <journal> J. Roy. Statist. Soc. Ser. </journal> <volume> B 41, </volume> <pages> pp. 148-177. </pages>
Reference-contexts: There are a number of scenarios that call for forward algorithmic procedures, any of which may reasonably be called forward induction. For example, Gittins' procedure for solving certain multi-armed bandit problems has also been termed forward induction <ref> [8] </ref>. This is a procedure in which a dynamic allocation index for each arm is calculated at each stage and the next experiment chosen is the one corresponding to the highest allocation index.
Reference: [9] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1991), </year> <title> "Bandit strategies for ethical sequential allocation", </title> <booktitle> Computing Science and Statistics 23, </booktitle> <pages> pp. 421-424. </pages>
Reference-contexts: Depending on the procedure and sample size, path induction can be orders of magnitude faster than previous exact computational approaches for performing multiple evaluations of a procedure. For example, for several years now, we have been able to use path induction on workstations <ref> [9] </ref> to perform calculations that had previously been done using backward induction on supercomputers [5]. This speed encourages more extensive analysis and visualization of designs, helping users achieve better optimizations and tradeoffs among multiple criteria. <p> In this paper [11], the author acknowledges that his calculations could only be carried out for a sample of size n = 25 and he explicitly noted that this was due to computational constraints. Working contemporaneously, the present authors obtained the results in <ref> [9] </ref> for n = 150. These results were for a sequential model nearly identical to the one used by Jones, although the calculations for [9] included criteria that required approximately 100 evaluations per procedure, while the former required only a couple of evaluations per procedure. <p> Working contemporaneously, the present authors obtained the results in <ref> [9] </ref> for n = 150. These results were for a sequential model nearly identical to the one used by Jones, although the calculations for [9] included criteria that required approximately 100 evaluations per procedure, while the former required only a couple of evaluations per procedure. Thus, in terms of the algorithms used in [11], the work in [9] solved problems approximately (150=25) 4 100 100; 000 times harder. 1 While a factor of 10 or <p> were for a sequential model nearly identical to the one used by Jones, although the calculations for <ref> [9] </ref> included criteria that required approximately 100 evaluations per procedure, while the former required only a couple of evaluations per procedure. Thus, in terms of the algorithms used in [11], the work in [9] solved problems approximately (150=25) 4 100 100; 000 times harder. 1 While a factor of 10 or so advantage was obtained by using a workstation (a modest Sun 3/60) as opposed to a (presumed) personal computer, and some advantage was obtained by having an implementation that tried to maximize processor
Reference: [10] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1995), </year> <title> "Determining optimal few-stage allocation rules", </title> <booktitle> Computing Science and Statistics 27 (1995), </booktitle> <pages> pp. 342-346. </pages>
Reference-contexts: Despite the basic simplicity of such procedures, their optimization and analysis is surprisingly complicated. Some design optimization issues were addressed in <ref> [10] </ref>, and analysis is addressed here. To simplify analyses, the total sample size n will be fixed, and it is assumed that there are k stages, with k o n.
Reference: [11] <author> Jones, P.W. </author> <year> (1992), </year> <title> "Multiobjective Bayesian bandits", Bayesian Statistics 4, </title> <editor> J.M. Bernardo, J.O. Berger, A.P. Dawid, and A.F.M. Smith, eds., </editor> <publisher> Oxford Univ. Press. </publisher>
Reference-contexts: As another example of the restrictiveness of the computational space and time constraints, Jones, 1992, computed results for the 2-AB problem that we described in Section 1. In this paper <ref> [11] </ref>, the author acknowledges that his calculations could only be carried out for a sample of size n = 25 and he explicitly noted that this was due to computational constraints. Working contemporaneously, the present authors obtained the results in [9] for n = 150. <p> These results were for a sequential model nearly identical to the one used by Jones, although the calculations for [9] included criteria that required approximately 100 evaluations per procedure, while the former required only a couple of evaluations per procedure. Thus, in terms of the algorithms used in <ref> [11] </ref>, the work in [9] solved problems approximately (150=25) 4 100 100; 000 times harder. 1 While a factor of 10 or so advantage was obtained by using a workstation (a modest Sun 3/60) as opposed to a (presumed) personal computer, and some advantage was obtained by having an implementation that <p> However, it will still be true that one should use path induction, instead of the improved backward induction, if multiple evaluations are required. 1 Note that the algorithms used in <ref> [11] </ref> were essentially the same as those used by all other researchers, and our only reasons for singling out this paper are the fact that the results can be directly compared, and the paper explicitly noted that the sample size was limited by computational constraints. 20
Reference: [12] <author> Kolonko, M. and Benzing, H. </author> <year> (1985), </year> <title> "The sequential design of Bernoulli experiments including switching costs", </title> <journal> Operations Research 33, </journal> <pages> pp. 412-426. </pages>
Reference-contexts: However, if the natural states are used, then there are criteria such as switching costs which cannot be evaluated. In a basic switching cost model <ref> [1, 12] </ref>, there is a fixed cost every time the experiment switches from one arm to another. For example, in a two-armed Bernoulli experiment, one might reach state (2,0,2,0) via 1, 2, or 3 switches, and the costs would vary correspondingly.
Reference: [13] <author> Mehta, C. and Patel, N. </author> <title> (1983) "A network algorithm for performing Fisher's exact test in r fi c contingency tables", </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 78, </volume> <pages> pp. 427-434. </pages>
Reference-contexts: Similarly, there are a variety of other algorithmic techniques that utilize path computation and state indexing. For example, the network algorithms used for computing exact distributions in the statistical package StatXact use paths and states <ref> [13] </ref>. However, these algorithms are quite different than those discussed here.
Reference: [14] <author> Robbins, H. </author> <year> (1952), </year> <title> "Some aspects of the sequential design of experiments", </title> <journal> Bull. Amer. Math. Soc. </journal> <volume> 58, </volume> <pages> pp. 527-535. </pages>
Reference-contexts: In this section, a few of the more important ones will be considered. 6.1 State Reduction In practice, one of the most useful refinements is the elimination of unreachable states. For example, for the fully sequential strategy known as "Play the Winner" <ref> [14, 17] </ref> (or, more accurately, "Play the Winner/Switch on a Loser") for two Bernoulli arms, if a success occurs on one arm then the arm is repeated, while if a failure occurs then the other arm is tried.
Reference: [15] <author> Thompson, W.R. </author> <year> (1933), </year> <title> "On the likelihood that one unknown probability exceeds another in view of the evidence of two samples", </title> <journal> Biometrika 25, </journal> <pages> pp. 275-294. </pages>
Reference-contexts: Fortunately, many ad hoc sequential allocation rules, such as Alternating Allocation, Play the Winner (Section 6.1), Randomized Play the Winner (Section 6.4), Vector-at-a-Time (Section 6.2), Thompson's rule <ref> [15] </ref>, and most myopic rules, have the property that the allocation decision at a given state is independent of the sample size.
Reference: [16] <author> Wei, L.J. and Durham, S. </author> <year> (1978), </year> <title> "The randomized play the winner rule in medical trials", </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 73, </volume> <pages> pp. 840-843. </pages>
Reference-contexts: This requires some adjustments, because the paths to a given state need not all have the same probability, and the number of successors of a given state may be greatly enlarged. To illustrate the former effect, in a simple version of Randomized Play the Winner <ref> [16] </ref>, there is an urn with balls marked "arm 1" and "arm 2". A ball is randomly selected and returned to the urn, and that arm is tried.
Reference: [17] <author> Zelen, M. </author> <year> (1969), </year> <title> "Play-the-winner rule and the controlled clinical trial", </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 64, </volume> <pages> pp. 131-146. 21 </pages>
Reference-contexts: In this section, a few of the more important ones will be considered. 6.1 State Reduction In practice, one of the most useful refinements is the elimination of unreachable states. For example, for the fully sequential strategy known as "Play the Winner" <ref> [14, 17] </ref> (or, more accurately, "Play the Winner/Switch on a Loser") for two Bernoulli arms, if a success occurs on one arm then the arm is repeated, while if a failure occurs then the other arm is tried.
References-found: 17

