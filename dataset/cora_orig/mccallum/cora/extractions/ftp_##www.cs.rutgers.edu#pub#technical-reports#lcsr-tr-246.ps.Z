URL: ftp://www.cs.rutgers.edu/pub/technical-reports/lcsr-tr-246.ps.Z
Refering-URL: http://www.cs.rutgers.edu/pub/technical-reports/
Root-URL: 
Title: Recognition by Functional Parts  
Author: Ehud Rivlin Sven J. Dickinson Azriel Rosenfeld 
Date: September 1995.  
Note: To appear in Computer Vision and Image Understanding, special issue on function-based object recognition,  
Address: Haifa, Israel  P.O. Box 1179 Piscataway, NJ 08855  College Park, MD, USA 20742  
Affiliation: Department of Computer Science Technion-Israel Institute of Technology  Center for Cognitive Science and Department of Computer Science Rutgers University  Center for Automation Research University of Maryland  
Abstract: We present an approach to function-based object recognition that reasons about the functionality of an object's intuitive parts. We extend the popular "recognition by parts" shape recognition framework to support "recognition by functional parts", by combining a set of functional primitives and their relations with a set of abstract volumetric shape primitives and their relations. Previous approaches have relied on more global object features, often ignoring the problem of object segmentation and thereby restricting themselves to range images of unoccluded scenes. We show how these shape primitives and relations can be easily recovered from superquadric ellipsoids which, in turn, can be recovered from either range or intensity images of occluded scenes. Furthermore, the proposed framework supports both unexpected (bottom-up) object recognition and expected (top-down) object recognition. We demonstrate the approach on a simple domain by recognizing a restricted class of hand-tools from 2-D images. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Barr. </author> <title> Superquadrics and angle-preserving transformations. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 1 </volume> <pages> 11-23, </pages> <year> 1981. </year>
Reference-contexts: Based on the shapes we want to recover (sticks, strips, plates, and blobs with possible tapering and bending global deformations), we first consider the case of superquadric ellipsoids <ref> [1] </ref>, which are given by the following formula: e = a B a 1 C u * 2 * 1 S v a 3 S u 1 A ; (8) where =2 u =2 and v &lt; , and where S w * = sgn (sin w)j sin wj * ,
Reference: [2] <author> I. Biederman. </author> <title> Human image understanding: Recent research and a theory. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 32 </volume> <pages> 29-73, </pages> <year> 1985. </year>
Reference-contexts: For example, we can attach two shapes end to end, end to side, or side to side, as proposed by Biederman when building objects out of geons <ref> [2] </ref>. To further specify these attachments, we adopt the convention of labeling each volumetric primitive's attachment surfaces [9]. For example, a square plate has six attachment surfaces, while a cylindrical stick has three attachment surfaces. <p> For example, we may decide to distinguish among curved-axis vs. straight-axis shapes or tapering vs. constant cross-sectional sweep rules <ref> [2] </ref>. Recently, several researchers have proposed various segmentation techniques to partition image or range data, in order to automate the process of fitting superquadric volumetric primitives to the data.
Reference: [3] <author> M. Brady, P. Agre, D. Braunegg, and J. Connell. </author> <title> The mechanics mate. </title> <editor> In T. O'Shea, editor, </editor> <booktitle> Advances in Artificial Intelligence, </booktitle> <pages> pages 79-94. </pages> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1985. </year>
Reference-contexts: In Vaina and Jaulent's compatibility model [36], shape attributes of an object, e.g., length, relative part orientation, etc., were provided as input; neither a shape description nor a recovery scheme was presented. In Brady et al.'s Mechanics Mate <ref> [3] </ref>, a mapping from Curvature Primal Sketch (CPS) and Smoothed Local Symmetries (SLS) features in a 2-D image to a set of higher-order geometrical structures was proposed. These higher-order structures were then mapped to a set of functional parts belonging to a set of handtools.
Reference: [4] <author> R. Brooks. </author> <title> Model-based 3-D interpretations of 2-D images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5(2) </volume> <pages> 140-150, </pages> <year> 1983. </year>
Reference-contexts: How can we avoid having to provide the system with detailed CAD specifications of each object that the system is to recognize? One way of making object models more flexible is to parameterize geometric models, as proposed by Brooks in his ACRONYM system <ref> [4] </ref>. For example, the legs of a chair model could have lengths that fall in some specified range, or the number of chair legs could be variable. Object recognition systems using parameterized models have also been proposed by Huttenlocher [14] and by Lowe [17].
Reference: [5] <author> S. Dickinson, H. Christensen, J. Tsotsos, and G. Olofsson. </author> <title> Active object recognition integrating attention and viewpoint control. </title> <booktitle> In Proceedings, </booktitle> <address> ECCV '94, Stockholm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: In this section, we will describe both these strategies. 4.1 Unexpected Object Recognition In an unexpected object recognition task, we first first segment an input image into a set of homogeneous regions from which we recover a set of qualitative 3-D parts using local part-based aspect matching techniques <ref> [9, 8, 5] </ref>. Next, using the techniques of Dickinson and Metaxas [6], we use the recovered qualitative shape to constrain the fitting of a set of deformable superquadrics to the qualitative parts. <p> From a candidate search position, the next step is to recover a superquadric from which the 3-D part dimensions and orientation can be recovered. This consists of first recovering the qualitative shape of the part <ref> [9, 8, 5] </ref>, which is then used to constrain the fitting of a superquadric to the image data.
Reference: [6] <author> S. Dickinson and D. Metaxas. </author> <title> Integrating qualitative and quantitative shape recovery. </title> <journal> International Journal of Computer Vision, </journal> <volume> 13(3) </volume> <pages> 1-20, </pages> <year> 1994. </year>
Reference-contexts: In a related approach, Narayan and Jain [23] recover geons from range imagery, and use superquad fitting to determine the axis of the geon. The approach we take, due to Dickinson and Metaxas <ref> [6] </ref>, is to use a qualitative segmentation of a 2-D image to provide strong constraints on the deformable model fitting procedure described in [33]. In addition, the technique has been recently extended to deformable model recovery from range data [7]. <p> In addition, the technique has been recently extended to deformable model recovery from range data [7]. The result is a technique which allows us to recover certain classes of superquadrics from image or range data, under orthographic, perspective, and stereo projection <ref> [6] </ref>. Furthermore, the technique supports the recovery of occluded parts, allowing us to reason about the functionalities of objects that are only partially visible. We will not describe the above recovery methods in this paper; details can be found in [6, 7]. <p> Furthermore, the technique supports the recovery of occluded parts, allowing us to reason about the functionalities of objects that are only partially visible. We will not describe the above recovery methods in this paper; details can be found in <ref> [6, 7] </ref>. <p> Next, using the techniques of Dickinson and Metaxas <ref> [6] </ref>, we use the recovered qualitative shape to constrain the fitting of a set of deformable superquadrics to the qualitative parts. From the resulting quantitative parts, we compare the dimensions of the parts to abstract a set of sticks, strips, plates, and blobs. <p> Since only a monocular image was used (a stereo pair was unavailable), depth or scale must specified as a constraint; in this case, an arbitrary depth was chosen. When a stereo pair is available, true depth and scale can be recovered using the methods specified in <ref> [6] </ref>. <p> The method that we propose for shape recovery, i.e., the use of qualitative shape to constrain the recovery of quanitative shape, relies on a good region segmentation of an intensity image <ref> [6] </ref> or a range image [7], although a certain degree of both undersegmentation (as shown in the results) and oversegmentation can be tolerated. Furthermore, our region segmentation techniques rely on object surfaces being opaque and devoid of surface markings.
Reference: [7] <author> S. Dickinson, D. Metaxas, and A. Pentland. </author> <title> Constrained recovery of deformable models from range data. </title> <booktitle> In Proceedings, 2nd International Workshop on Visual Form, </booktitle> <address> Capri, Italy, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: The approach we take, due to Dickinson and Metaxas [6], is to use a qualitative segmentation of a 2-D image to provide strong constraints on the deformable model fitting procedure described in [33]. In addition, the technique has been recently extended to deformable model recovery from range data <ref> [7] </ref>. The result is a technique which allows us to recover certain classes of superquadrics from image or range data, under orthographic, perspective, and stereo projection [6]. Furthermore, the technique supports the recovery of occluded parts, allowing us to reason about the functionalities of objects that are only partially visible. <p> Furthermore, the technique supports the recovery of occluded parts, allowing us to reason about the functionalities of objects that are only partially visible. We will not describe the above recovery methods in this paper; details can be found in <ref> [6, 7] </ref>. <p> Only two qualitative volumes are recovered in which the conditional probability mapping the recovered aspect to the recovered volume is high (see <ref> [9, 8, 7] </ref>, corresponding to the block and the cylinder. 6 The fitted models for the two recovered qualitative volumes are shown in 6 All regions in the scene which do not touch the border of the image are examined by the algorithm in terms of their possible grouings with adjacent <p> The method that we propose for shape recovery, i.e., the use of qualitative shape to constrain the recovery of quanitative shape, relies on a good region segmentation of an intensity image [6] or a range image <ref> [7] </ref>, although a certain degree of both undersegmentation (as shown in the results) and oversegmentation can be tolerated. Furthermore, our region segmentation techniques rely on object surfaces being opaque and devoid of surface markings.
Reference: [8] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> From volumes to views: An approach to 3-D object recognition. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 55(2) </volume> <pages> 130-154, </pages> <year> 1992. </year>
Reference-contexts: In this section, we will describe both these strategies. 4.1 Unexpected Object Recognition In an unexpected object recognition task, we first first segment an input image into a set of homogeneous regions from which we recover a set of qualitative 3-D parts using local part-based aspect matching techniques <ref> [9, 8, 5] </ref>. Next, using the techniques of Dickinson and Metaxas [6], we use the recovered qualitative shape to constrain the fitting of a set of deformable superquadrics to the qualitative parts. <p> From a candidate search position, the next step is to recover a superquadric from which the 3-D part dimensions and orientation can be recovered. This consists of first recovering the qualitative shape of the part <ref> [9, 8, 5] </ref>, which is then used to constrain the fitting of a superquadric to the image data. <p> Only two qualitative volumes are recovered in which the conditional probability mapping the recovered aspect to the recovered volume is high (see <ref> [9, 8, 7] </ref>, corresponding to the block and the cylinder. 6 The fitted models for the two recovered qualitative volumes are shown in 6 All regions in the scene which do not touch the border of the image are examined by the algorithm in terms of their possible grouings with adjacent
Reference: [9] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> 3-D shape recovery using distributed aspect matching. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(2) </volume> <pages> 174-198, </pages> <year> 1992. </year>
Reference-contexts: For example, we can attach two shapes end to end, end to side, or side to side, as proposed by Biederman when building objects out of geons [2]. To further specify these attachments, we adopt the convention of labeling each volumetric primitive's attachment surfaces <ref> [9] </ref>. For example, a square plate has six attachment surfaces, while a cylindrical stick has three attachment surfaces. For simplicity, we shall require any junction of two primitives to involve exactly one attachment surface from each primitive. <p> The approach is based on the qualitative shape recovery work of Dickinson, Pentland, and Rosenfeld <ref> [9] </ref> and relies only on a region segmentation of the input image. In that approach, a fixed set of volumes was analyzed over the viewing sphere, giving rise to a set of aspects. <p> In this section, we will describe both these strategies. 4.1 Unexpected Object Recognition In an unexpected object recognition task, we first first segment an input image into a set of homogeneous regions from which we recover a set of qualitative 3-D parts using local part-based aspect matching techniques <ref> [9, 8, 5] </ref>. Next, using the techniques of Dickinson and Metaxas [6], we use the recovered qualitative shape to constrain the fitting of a set of deformable superquadrics to the qualitative parts. <p> From a candidate search position, the next step is to recover a superquadric from which the 3-D part dimensions and orientation can be recovered. This consists of first recovering the qualitative shape of the part <ref> [9, 8, 5] </ref>, which is then used to constrain the fitting of a superquadric to the image data. <p> Using Equations 1, 2, 3, and 4, defining two di 5 For a stronger heuristic that examines the nature of the parts' intersection in the image to determine intersection in the world, see <ref> [9] </ref>. 15 Superquad Part Parameter Head Handle a 37.19 37.19 a 2 0.45 0.22 t x -4.40 4.97 t z -50.0 -50.0 r 12 -0.22 0.07 r 21 -0.14 0.78 r 23 -0.33 -0.53 r 32 0.28 0.96 * 1 0.0 0.0 bend z 0.0 0.0 taper z 0.0 0.0 Table <p> Only two qualitative volumes are recovered in which the conditional probability mapping the recovered aspect to the recovered volume is high (see <ref> [9, 8, 7] </ref>, corresponding to the block and the cylinder. 6 The fitted models for the two recovered qualitative volumes are shown in 6 All regions in the scene which do not touch the border of the image are examined by the algorithm in terms of their possible grouings with adjacent
Reference: [10] <editor> F. Ferrie, J. Lagarde, and P. Whaite. Darboux frames, snakes, and superquadrics. </editor> <booktitle> In Proceedings, IEEE Workshop on Interpretation of 3D Scenes, </booktitle> <pages> pages 170-176, </pages> <year> 1989. </year>
Reference-contexts: Recently, several researchers have proposed various segmentation techniques to partition image or range data, in order to automate the process of fitting superquadric volumetric primitives to the data. Most of those approaches are applied to range data only <ref> [25, 10, 11, 13] </ref>, while Pentland [21] describes a two-stage algorithm to fit superquadrics to image data.
Reference: [11] <author> F. Ferrie, J. Lagarde, and P. Whaite. </author> <title> Recovery of volumetric descriptions from laser rangefinder images. </title> <booktitle> In Proceedings, </booktitle> <volume> ECCV '90, </volume> <pages> pages 387-396, </pages> <address> Antibes, France, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: Recently, several researchers have proposed various segmentation techniques to partition image or range data, in order to automate the process of fitting superquadric volumetric primitives to the data. Most of those approaches are applied to range data only <ref> [25, 10, 11, 13] </ref>, while Pentland [21] describes a two-stage algorithm to fit superquadrics to image data.
Reference: [12] <author> J. Gibson. </author> <title> The Ecological Approach to Visual Perception. </title> <publisher> Houghton Mi*in, </publisher> <address> Boston, </address> <year> 1979. </year>
Reference-contexts: Recognition is equivalent to the process that checks if an object suits a particular purpose. If an object is perceived to fulfill a function necessary to carry out a certain behavior or action, then it is recognized. Gibson's theory of affordances <ref> [12] </ref>, i.e., properties that are defined with reference to an observer, was a major step in this direction. Winston et al. [37] emphasized how much easier it is to describe what objects are used for, rather than to describe what objects look like.
Reference: [13] <author> A. Gupta. </author> <title> Surface and volumetric segmentation of 3D objects using parametric shape models. </title> <type> Technical Report MS-CIS-91-45, </type> <institution> GRASP LAB 128, University of Pennsylvania, </institution> <address> Philadelphia, PA, </address> <year> 1991. </year>
Reference-contexts: Recently, several researchers have proposed various segmentation techniques to partition image or range data, in order to automate the process of fitting superquadric volumetric primitives to the data. Most of those approaches are applied to range data only <ref> [25, 10, 11, 13] </ref>, while Pentland [21] describes a two-stage algorithm to fit superquadrics to image data.
Reference: [14] <author> D. Huttenlocher. </author> <title> Three-dimensional recognition of solid objects from a two-dimensional image. </title> <type> Technical Report 1045, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: For example, the legs of a chair model could have lengths that fall in some specified range, or the number of chair legs could be variable. Object recognition systems using parameterized models have also been proposed by Huttenlocher <ref> [14] </ref> and by Lowe [17]. However, all three of the above systems are very top-down, requiring not only knowledge of what object is in the image, but in some cases a good initial guess as to the orientation of the object.
Reference: [15] <author> D. Huttenlocher and S. Ullman. </author> <title> Recognizing solid objects by alignment with an image. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5(2) </volume> <pages> 195-212, </pages> <year> 1990. </year>
Reference-contexts: Full recovery has been difficult to achieve while matching suffers from combinatorial explosion. Model-based recognition has been suggested as a remedy to these problems. Many such 3-D object recognition systems take a single object model and attempt to locate it in the image, e.g., <ref> [16, 15, 35] </ref>. Furthermore, the object models are commonly CAD-like, capturing the exact geometry of the object.
Reference: [16] <author> D. Lowe. </author> <title> Perceptual Organization and Visual Recognition. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1985. </year>
Reference-contexts: Full recovery has been difficult to achieve while matching suffers from combinatorial explosion. Model-based recognition has been suggested as a remedy to these problems. Many such 3-D object recognition systems take a single object model and attempt to locate it in the image, e.g., <ref> [16, 15, 35] </ref>. Furthermore, the object models are commonly CAD-like, capturing the exact geometry of the object.
Reference: [17] <author> D. Lowe. </author> <title> Fitting parameterized three-dimensional models to images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(5) </volume> <pages> 441-450, </pages> <year> 1991. </year>
Reference-contexts: For example, the legs of a chair model could have lengths that fall in some specified range, or the number of chair legs could be variable. Object recognition systems using parameterized models have also been proposed by Huttenlocher [14] and by Lowe <ref> [17] </ref>. However, all three of the above systems are very top-down, requiring not only knowledge of what object is in the image, but in some cases a good initial guess as to the orientation of the object.
Reference: [18] <author> D. Marr. </author> <title> Vision. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco, CA, </address> <year> 1982. </year>
Reference-contexts: In the absence of distinguishing properties such as color, texture, or motion, object recognition first requires the visual recovery of shape, followed by the matching of the recovered shape to a database of known objects <ref> [18] </ref>. Although much research on the topic has been published, the community still lacks vision systems that can recognize in real time a large number of objects (natural or man-made). Full recovery has been difficult to achieve while matching suffers from combinatorial explosion.
Reference: [19] <author> P. Mulgaonkar, L. Shapiro, and R. Haralick. </author> <title> Matching "sticks, plates and blobs" objects using geometric and relational constraints. </title> <journal> Image and Vision Computing, </journal> <volume> 2(2) </volume> <pages> 85-98, </pages> <year> 1984. </year>
Reference-contexts: The representation is an extension to the generalized blob models (sticks, plates, and blobs) proposed by Mulgaonkar, Shapiro, and Haralick <ref> [19] </ref>. Our four classes are distinguished by their relative dimensions.
Reference: [20] <author> A. Pentland. </author> <title> Perceptual organization and the representation of natural form. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 293-331, </pages> <year> 1986. </year>
Reference-contexts: Moreover, those parts are the same parts that we recover from the image for shape recognition. Thus, instead of reasoning about the functionality of a collection of 3-D points or planar surfaces, we propose to reason about a more intuitive notion of an object's parts (Pentland <ref> [20] </ref>). Although we will not index using part shape, we can use knowledge of part shape to help segment the image into parts. Given a set of recovered volumetric parts, we can then reason both about the functionalities of individual parts and the interactions between the parts. <p> The approach consists of recovering a superquadric from the image, providing explicit dimensions which we can then use to classify our shape. Superquadrics offer a compact, coarse, volumetric description of an object's parts <ref> [20] </ref>. If finer shape modeling is required, deformable superquadrics can be used to capture both global part shape (using a superquadric) and local shape (using a deformable mesh) [33].
Reference: [21] <author> A. Pentland. </author> <title> Automatic extraction of deformable part models. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4 </volume> <pages> 107-126, </pages> <year> 1990. </year>
Reference-contexts: Recently, several researchers have proposed various segmentation techniques to partition image or range data, in order to automate the process of fitting superquadric volumetric primitives to the data. Most of those approaches are applied to range data only [25, 10, 11, 13], while Pentland <ref> [21] </ref> describes a two-stage algorithm to fit superquadrics to image data.
Reference: [22] <author> A. Pentland and S. Sclaroff. </author> <title> Closed-form solutions for physically based shape modeling and recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(7) </volume> <pages> 715-729, </pages> <year> 1991. </year>
Reference-contexts: Pentland's approach is only applicable in case of occluding boundary data under simple orthographic projection, as is true of earlier work of Terzopolous et al. [34], Terzopolous and Metaxas [33], and Pentland and Sclaroff <ref> [22] </ref>, which address only the problem of model fitting. In a related approach, Narayan and Jain [23] recover geons from range imagery, and use superquad fitting to determine the axis of the geon.
Reference: [23] <author> N. Raja and A. Jain. </author> <title> Recognizing geons from superquadrics fitted to range data. </title> <journal> Image and Vision Computing, </journal> <volume> 10(3) </volume> <pages> 179-190, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: In a related approach, Narayan and Jain <ref> [23] </ref> recover geons from range imagery, and use superquad fitting to determine the axis of the geon. The approach we take, due to Dickinson and Metaxas [6], is to use a qualitative segmentation of a 2-D image to provide strong constraints on the deformable model fitting procedure described in [33].
Reference: [24] <author> E. Rivlin, Y. Aloimonos, and A. Rosenfeld. </author> <title> Purposive recognition: A framework. </title> <type> Technical Report CAR-TR-2811, </type> <institution> Center for Automation Research, University of Maryland, College Park, MD, </institution> <month> December </month> <year> 1991. </year> <month> 22 </month>
Reference-contexts: A different approach to the problem is to consider the recognition process in the context of an agent interacting with its environment <ref> [24] </ref>. The recognition process is subordinate to the agent's intentions and behavior in its environment. Recognition is equivalent to the process that checks if an object suits a particular purpose.
Reference: [25] <author> F. Solina. </author> <title> Shape recovery and segmentation with deformable part models. </title> <type> Technical Report MS-CIS-87-111, </type> <institution> GRASP LAB 128, University of Pennsylvania, </institution> <address> Philadelphia, PA, </address> <year> 1987. </year>
Reference-contexts: Recently, several researchers have proposed various segmentation techniques to partition image or range data, in order to automate the process of fitting superquadric volumetric primitives to the data. Most of those approaches are applied to range data only <ref> [25, 10, 11, 13] </ref>, while Pentland [21] describes a two-stage algorithm to fit superquadrics to image data.
Reference: [26] <author> L. Stark and K. Bowyer. </author> <title> Achieving generalized object recognition through reasoning about association of function to structure. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(10) </volume> <pages> 1097-1104, </pages> <year> 1991. </year>
Reference-contexts: Alternatively, recognition based on functionality would enable our agent to possess knowledge of the needed function of a chair without explicitly specifying the possible shapes of a chair. The seminal work of Stark and Bowyer et al. <ref> [27, 26, 28, 29, 30, 31, 32] </ref> has addressed function-based object recognition, focusing on domains including chairs and dishes. In their work, they define a set of functional primitives specific to each object class. <p> For example, the functional primitives defining a coffee cup would include a handle and a container; a chair would include a seat, a base, and a back <ref> [27, 26] </ref>. In the remainder of this paper, we will illustrate our approach to functional object recognition by focusing on a class of manipulation tasks. <p> In this case, the chair could be thought of as having a single chair leg consisting of the box (minus the top which serves as the seat). The most general specification of the base of a chair, as articulated by Stark and Bowyer <ref> [26] </ref>, would specify only that the seat was supported at the proper height and that the structure was stable. The exact number, type, and orientation of the shape primitives making up the base need not be specified.
Reference: [27] <author> L. Stark and K. Bowyer. </author> <title> Generic recognition through qualitative reasoning about 3-D shape and object function. </title> <booktitle> In Proceedings, IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 251-256, </pages> <address> Maui, HI, </address> <year> 1991. </year>
Reference-contexts: Alternatively, recognition based on functionality would enable our agent to possess knowledge of the needed function of a chair without explicitly specifying the possible shapes of a chair. The seminal work of Stark and Bowyer et al. <ref> [27, 26, 28, 29, 30, 31, 32] </ref> has addressed function-based object recognition, focusing on domains including chairs and dishes. In their work, they define a set of functional primitives specific to each object class. <p> For example, the functional primitives defining a coffee cup would include a handle and a container; a chair would include a seat, a base, and a back <ref> [27, 26] </ref>. In the remainder of this paper, we will illustrate our approach to functional object recognition by focusing on a class of manipulation tasks.
Reference: [28] <author> L. Stark and K. Bowyer. </author> <title> Indexing function-based categories for generic object recognition. </title> <booktitle> In Proceedings, IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 795-797, </pages> <address> Champaign, IL, </address> <year> 1992. </year>
Reference-contexts: Alternatively, recognition based on functionality would enable our agent to possess knowledge of the needed function of a chair without explicitly specifying the possible shapes of a chair. The seminal work of Stark and Bowyer et al. <ref> [27, 26, 28, 29, 30, 31, 32] </ref> has addressed function-based object recognition, focusing on domains including chairs and dishes. In their work, they define a set of functional primitives specific to each object class.
Reference: [29] <author> L. Stark and K. Bowyer. </author> <title> Indexing function-based categories for generic object recognition. CVGIP: Image Understanding, </title> <note> to appear. </note>
Reference-contexts: Alternatively, recognition based on functionality would enable our agent to possess knowledge of the needed function of a chair without explicitly specifying the possible shapes of a chair. The seminal work of Stark and Bowyer et al. <ref> [27, 26, 28, 29, 30, 31, 32] </ref> has addressed function-based object recognition, focusing on domains including chairs and dishes. In their work, they define a set of functional primitives specific to each object class. <p> We will outline an approach which first segments an image containing multiple objects into a set of volumetric parts, supporting part recovery from incomplete views of the object and supporting object occlusion. Following part grouping by object, 1 In recent work, Stark and Bowyer <ref> [29] </ref> reason about the functionality of objects that are partially visible in range images. 3 the approach will infer the possible functionalities of individual parts and collections of parts. The robot can check if the needed functionality for a certain action is consistent with the recovered functionality.
Reference: [30] <author> L. Stark, L. Hall, and K. Bowyer. </author> <title> An investigation of methods of combining functional evidence for 3-D object recognition. </title> <journal> International Journal of Pattern Recognition and Artificial Intelligence, </journal> <note> to appear. </note>
Reference-contexts: Alternatively, recognition based on functionality would enable our agent to possess knowledge of the needed function of a chair without explicitly specifying the possible shapes of a chair. The seminal work of Stark and Bowyer et al. <ref> [27, 26, 28, 29, 30, 31, 32] </ref> has addressed function-based object recognition, focusing on domains including chairs and dishes. In their work, they define a set of functional primitives specific to each object class.
Reference: [31] <author> L. Stark, A. Hoover, D. Goldgof, and K. Bowyer. </author> <title> Function based recognition from incomplete knowledge of shape. </title> <editor> In P. Kahn, Y. Aloimonos, and D. Weinshall, editors, </editor> <booktitle> Proceedings, IEEE Workshop on Qualitative Vision, </booktitle> <pages> pages 11-22, </pages> <year> 1993. </year>
Reference-contexts: Alternatively, recognition based on functionality would enable our agent to possess knowledge of the needed function of a chair without explicitly specifying the possible shapes of a chair. The seminal work of Stark and Bowyer et al. <ref> [27, 26, 28, 29, 30, 31, 32] </ref> has addressed function-based object recognition, focusing on domains including chairs and dishes. In their work, they define a set of functional primitives specific to each object class.
Reference: [32] <author> M. Sutton, L. Stark, and K. Bowyer. </author> <title> Function-based generic recognition for multiple object categories. </title> <editor> In A. Jain and P. Flynn, editors, </editor> <title> Three-Dimensional Object Recognition Systems, Advances in Image Communication and Machine Vision Series. </title> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1993. </year>
Reference-contexts: Alternatively, recognition based on functionality would enable our agent to possess knowledge of the needed function of a chair without explicitly specifying the possible shapes of a chair. The seminal work of Stark and Bowyer et al. <ref> [27, 26, 28, 29, 30, 31, 32] </ref> has addressed function-based object recognition, focusing on domains including chairs and dishes. In their work, they define a set of functional primitives specific to each object class.
Reference: [33] <author> D. Terzopoulos and D. Metaxas. </author> <title> Dynamic 3D models with local and global deformations: Deformable superquadrics. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(7) </volume> <pages> 703-714, </pages> <year> 1991. </year>
Reference-contexts: Superquadrics offer a compact, coarse, volumetric description of an object's parts [20]. If finer shape modeling is required, deformable superquadrics can be used to capture both global part shape (using a superquadric) and local shape (using a deformable mesh) <ref> [33] </ref>. Since superquadrics capture more shape attributes than just the x, y, and z dimensions of a part, they provide us with a foundation from which to recover a richer vocabulary of qualitative shapes with which to reason about function. <p> In the second stage, he fits superquadrics to the segmented data using a least squares algorithm. Pentland's approach is only applicable in case of occluding boundary data under simple orthographic projection, as is true of earlier work of Terzopolous et al. [34], Terzopolous and Metaxas <ref> [33] </ref>, and Pentland and Sclaroff [22], which address only the problem of model fitting. In a related approach, Narayan and Jain [23] recover geons from range imagery, and use superquad fitting to determine the axis of the geon. <p> The approach we take, due to Dickinson and Metaxas [6], is to use a qualitative segmentation of a 2-D image to provide strong constraints on the deformable model fitting procedure described in <ref> [33] </ref>. In addition, the technique has been recently extended to deformable model recovery from range data [7]. The result is a technique which allows us to recover certain classes of superquadrics from image or range data, under orthographic, perspective, and stereo projection [6].
Reference: [34] <author> D. Terzopoulos, A. Witkin, and M. Kass. </author> <title> Constraints on deformable models: Recovering 3d shape and nonrigid motion. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 91-123, </pages> <year> 1988. </year>
Reference-contexts: In the second stage, he fits superquadrics to the segmented data using a least squares algorithm. Pentland's approach is only applicable in case of occluding boundary data under simple orthographic projection, as is true of earlier work of Terzopolous et al. <ref> [34] </ref>, Terzopolous and Metaxas [33], and Pentland and Sclaroff [22], which address only the problem of model fitting. In a related approach, Narayan and Jain [23] recover geons from range imagery, and use superquad fitting to determine the axis of the geon.
Reference: [35] <author> D. Thompson and J. Mundy. </author> <title> Model-directed object recognition on the connection machine. </title> <booktitle> In Proceedings, DARPA Image Understanding Workshop, </booktitle> <pages> pages 93-106, </pages> <address> Los Angeles, CA, </address> <year> 1987. </year>
Reference-contexts: Full recovery has been difficult to achieve while matching suffers from combinatorial explosion. Model-based recognition has been suggested as a remedy to these problems. Many such 3-D object recognition systems take a single object model and attempt to locate it in the image, e.g., <ref> [16, 15, 35] </ref>. Furthermore, the object models are commonly CAD-like, capturing the exact geometry of the object.
Reference: [36] <author> L. Vaina and M Jaulent. </author> <title> Object structure and action requirements: A compatibility model for functional recognition. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 6 </volume> <pages> 313-336, </pages> <year> 1991. </year>
Reference-contexts: In Winston et al. [37], the vision component was replaced by a linguistic interface which provided English descriptions of scene content. In Vaina and Jaulent's compatibility model <ref> [36] </ref>, shape attributes of an object, e.g., length, relative part orientation, etc., were provided as input; neither a shape description nor a recovery scheme was presented.
Reference: [37] <author> P. Winston, T. Binford, B. Katz, and M. Lowry. </author> <title> Learning physical description from functional descriptions, examples, and precedents. </title> <booktitle> In Proceedings, AAAI, </booktitle> <pages> pages 433-439, </pages> <address> Palo Alto, CA, </address> <month> August </month> <year> 1983. </year> <month> 24 </month>
Reference-contexts: If an object is perceived to fulfill a function necessary to carry out a certain behavior or action, then it is recognized. Gibson's theory of affordances [12], i.e., properties that are defined with reference to an observer, was a major step in this direction. Winston et al. <ref> [37] </ref> emphasized how much easier it is to describe what objects are used for, rather than to describe what objects look like. They tried to show how recognition could be performed using functional definitions, and how physical models could be learned using functional definitions and specific acts of identification. <p> Such interactions can include relative orientation, size, shape, or even motion! Although the idea of reasoning about the function of an object's parts has been proposed by other researchers, there has been little concerabout in dealing with real image data. In Winston et al. <ref> [37] </ref>, the vision component was replaced by a linguistic interface which provided English descriptions of scene content. In Vaina and Jaulent's compatibility model [36], shape attributes of an object, e.g., length, relative part orientation, etc., were provided as input; neither a shape description nor a recovery scheme was presented.
References-found: 37

