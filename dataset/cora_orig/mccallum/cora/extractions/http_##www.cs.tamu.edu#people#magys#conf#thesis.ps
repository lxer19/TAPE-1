URL: http://www.cs.tamu.edu/people/magys/conf/thesis.ps
Refering-URL: http://www.cs.tamu.edu/people/magys/conf/publication.html
Root-URL: http://www.cs.tamu.edu
Title: MODELING EMOTION DYNAMICS IN INTELLIGENT AGENTS  
Degree: A Thesis by MAGY SEIF EL-NASR Submitted to the Office of Graduate Studies of Texas A&M University in partial fulfillment of the requirements for the degree of MASTER OF SCIENCE  
Note: Major Subject: Computer Science  
Date: May 1998  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. Armony, J. Cohen, D. Servan-Schreiber, and J. LeDoux, </author> <title> An Anatomically Constrained Neural Network Model of Fear Conditioning, </title> <journal> Behavioral Neuroscience, </journal> <volume> vol. 109, no. 2, </volume> <pages> pp. 240-257, </pages> <year> 1995. </year>
Reference: [2] <author> R. M. Baecker, J. Grudin, W. A. S. Buxlon, and S. Greenberg, Eds. </author> <title> Readings in Human-Computer Interaction: </title> <booktitle> Toward the Year 2000, 2 nd. </booktitle> <publisher> Ed. </publisher> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1995. </year>
Reference-contexts: We have this feature as an option in case the user wants to start over after really torturing the pet. 2. EVALUATION METHOD AND VALIDITY A. EVALUATION PROTOCOL AND VALIDITY Evaluation methods were explored in Baeckers book <ref> [2] </ref>. Evaluation techniques were summarized as heuristic evaluation, cognitive walkthroughs, usability testing, usability 65 engineering, and controlled experiments. For more information on these evaluation techniques the reader is referred back to [2]. All these techniques involve users or experts evaluating the usability of the system. <p> EVALUATION METHOD AND VALIDITY A. EVALUATION PROTOCOL AND VALIDITY Evaluation methods were explored in Baeckers book <ref> [2] </ref>. Evaluation techniques were summarized as heuristic evaluation, cognitive walkthroughs, usability testing, usability 65 engineering, and controlled experiments. For more information on these evaluation techniques the reader is referred back to [2]. All these techniques involve users or experts evaluating the usability of the system. Nevertheless, there were other techniques discussed as: think aloud - work aloud, videos, questionnaires, etc. From all of these methods we chose to use questionnaires with scenario walkthroughs.
Reference: [3] <author> J. Bates, </author> <title> The Role of Emotion in Believable Agents, </title> <journal> Communications of the ACM, </journal> <volume> vol. 37, no. 7, </volume> <pages> pp. 122-125, </pages> <year> 1992. </year>
Reference-contexts: This particular application will be discussed in more detail in Chapter II. Believable agents heavily rely on emotions to create believable responses. Believable agents were defined to be agents that create the illusion of life <ref> [3, 36] </ref>. The concept of believability is often used in theater. In theater, a character is created by completing a character study, which is formulated into a manifestation of the real characters behaviors. This manifestation is not necessarily real. <p> Due to the emergence of the believable agents, a number of models simulating the emotional process have been proposed. Two major models evolved out of this area, the OZ project <ref> [3, 4, 5, 36, 38] </ref> at CMU and Simon [51] at MIT. These models follow different agent architectures. These architectures will be detailed along with other models in Chapter II. <p> These agents are typically used in entertainment products or theatrics animation. We will concentrate on the later type of agents in this section, because it is almost the only type that has made an extensive use of emotions in its architecture <ref> [3] </ref>. There are two different architectures for intelligent agents: the broad agent architecture and the distributed agent architecture. The broad agent architecture has three important properties: it has a broad set of capabilities, each capability is typically somewhat shallow, and all the capabilities are tightly integrated [38]. <p> These factors can be summarized as follows: (1) emotional exaggeration. One of the important aspects of believability is the idea of emotional expression. Some times these emotions and expressions have to be exaggerated to create the desired effect <ref> [3] </ref>. (2) staging. Creating the right emotion, the right movements at the right time and in the right situation are one of the elements that lead to a successful performance. In the pet example, we created a scene that is more or less within the users expectations. <p> Thus, essentially the developers will have to write different scripts and different storyboards according to the combination of the different paths that the user can take. The limitation of this method is that the characters tend to be unconvincing. The OZ project <ref> [3] </ref> introduced another approach to simulating characters. By the use of believable agents, the characters are promoted from a collection of scripts that are triggered by some constant number of sentences to an intelligent being that can express and trigger emotions according to the different situations that it faces.
Reference: [4] <author> J. Bates, A. Bryan Loyall, and W. Scott Reilly, </author> <title> An Architecture for Action, Emotion, and Social Behavior, </title> <institution> School of Computer Science, Pittsburgh, PA: Carnegie Mellon University, </institution> <type> Technical Rep. </type> <institution> CMU-CS-92-144, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: Due to the emergence of the believable agents, a number of models simulating the emotional process have been proposed. Two major models evolved out of this area, the OZ project <ref> [3, 4, 5, 36, 38] </ref> at CMU and Simon [51] at MIT. These models follow different agent architectures. These architectures will be detailed along with other models in Chapter II. <p> Although these models use internal variables, such as expectations and the level of effort exerted, to produce emotions, the computational models that evolved out of these models (e.g. OZ <ref> [4] </ref>) did not use experience to trigger these internal variables. As Figure 1 shows, we propose an agent architecture that uses past experiences to guide its emotional process. The experience model uses reinforcement learning to calculate the maximum reward that the agent can get given the situation. <p> Sixteen emotions were formalized in this form, including relief, distress, disappointment, love, hate and satisfaction [30]. In fact, the model was 25 employed as a computational model by the OZ group, a group working on believable agents at CMU (Carnegie Mellon University) <ref> [4, 5, 38, 36, 37] </ref>. Nevertheless, the model is not complete. As stated earlier the equations are intuitive and seem to capture the process of triggering one emotion really well, but often emotions are triggered in a mixture. <p> This 33 architecture consists of a set of distributed agents with no internal states. These agents interact with each other in a way that achieves global intelligence. i. BROAD AGENTS & BELIEVABLE AGENTS J. Bates is building a believable agent (OZ project) <ref> [38, 4, 5] </ref> using the model that was described in The Structure of Emotions by Ortony, Clore and Collins [30]. The aim of the OZ project was to provide the users with the experience of living in dramatically interesting microworlds that include moderately competent emotional agents. <p> Models of believable agents were developed using two main architectures. One of which, is the broad agent architecture that constitutes a big model, which includes several internal states <ref> [4] </ref>. These internal states are evaluated and an action evolves according to the resulting emotional state. The other architecture is closer to Brooks subsumption architecture, which consists of a set of different distributed agents with no internal states [51].
Reference: [5] <author> J. Bates, A. Bryan Loyall, and W. Scott Reilly, </author> <title> Integerating Reactivity, Goals and Emotion in a Broad Agent, </title> <institution> School of Computer Science, Pittsburgh, PA: Carnegie Mellon University, </institution> <type> Technical Rep. </type> <institution> CMU-CS-92-142, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: Due to the emergence of the believable agents, a number of models simulating the emotional process have been proposed. Two major models evolved out of this area, the OZ project <ref> [3, 4, 5, 36, 38] </ref> at CMU and Simon [51] at MIT. These models follow different agent architectures. These architectures will be detailed along with other models in Chapter II. <p> Sixteen emotions were formalized in this form, including relief, distress, disappointment, love, hate and satisfaction [30]. In fact, the model was 25 employed as a computational model by the OZ group, a group working on believable agents at CMU (Carnegie Mellon University) <ref> [4, 5, 38, 36, 37] </ref>. Nevertheless, the model is not complete. As stated earlier the equations are intuitive and seem to capture the process of triggering one emotion really well, but often emotions are triggered in a mixture. <p> This 33 architecture consists of a set of distributed agents with no internal states. These agents interact with each other in a way that achieves global intelligence. i. BROAD AGENTS & BELIEVABLE AGENTS J. Bates is building a believable agent (OZ project) <ref> [38, 4, 5] </ref> using the model that was described in The Structure of Emotions by Ortony, Clore and Collins [30]. The aim of the OZ project was to provide the users with the experience of living in dramatically interesting microworlds that include moderately competent emotional agents.
Reference: [6] <author> R. C. Bolles and Fanselow, M. S. </author> <title> A Perceptual Defensive Recuperative Model of Fear and Pain, </title> <journal> Behavioral and Brain Sciences, </journal> <volume> vol. 3, </volume> <pages> pp. 291-301, </pages> <year> 1980. </year>
Reference-contexts: Emotion was defined as a feeling [46]. Not all feelings are emotions. For example, you can feel hunger, you can feel pain, but hunger and pain are not emotions. They are called motivational states <ref> [6] </ref>. Motivational states are feelings that might drive the brain to interrupt its normal activity to concentrate on a higher need. <p> If we are going to simulate emotions in a computer, we need to know how to compute these internal states. Other models, like the Bolles and Fanselows <ref> [6] </ref> model, tend to take a few emotions or motivational states like fear and pain and determine how they affect each other. They found that fear might inhibit pain and vice versa. <p> Such mixed emotions can occur at various times and situations. To model emotions and emotional behavior, a model will have to take into account these mixtures and explore the effect of different emotions and motivational states on each other. We essentially combined different models, including Bolles and Fanslows model <ref> [6] </ref> and Bower and Cohens model [7] to provide a more believable behavior. (3) The mappings from emotions to behaviors are not gradual. Most of the previous models use a threshold-based mapping technique. <p> Schumacher and M. Velden [42]. However, most of these models tend to formulate the motivational states into a pure physiological reaction, and thus the impact that these motivational states have on other states such as the emotional states was not conceived. A model was proposed by Bolles and Fanselow <ref> [6] </ref> to explore the relation between the motivational states and the emotional states, more specifically the relation between fear and pain. Their idea was that the motivational states such as fear and pain sometimes inhibit or enhance each other. <p> In phase three, the recuperative phase, the intensity of fear would typically drop as a result of the disappearance of the cause of fear. Pain would then take over if there was any damage, and thus pain would inhibit fear <ref> [6] </ref>. The model emphasized the role of inhibition and how the brain or essentially the human body could inhibit or enhance some motivational states or emotions over others. This model was simulated and added as a part of our model. <p> Its expressive component is used to modify the agents expression and its experiential component is evaluated in order to update all appropriate motivations [51]. However, there are other motivational states that can affect the emotional life and sometimes inhibit some emotions, as in the case of pain <ref> [6] </ref>. This factor is discussed in more detail in Chapter III. Moreover, the model did not represent the learning factor in modeling emotions. Experience and learning has been proven to change and shape the emotional process [12]. Our model further expands this concept in Chapter III. <p> An emotion or a mixture of emotions will be triggered using the event desirability measure. The mixture will then be filtered to produce an emotional state. The filtering process uses a variation of Bolles and Fanslows <ref> [6] </ref> model to produce a coherent mixture of emotions. In essence, the emotional state will be a list of emotions that apply at a specific time given a certain situation. The emotional state is passed to the behavior selection phase. <p> For example, the feeling of sadness is often mixed with shame, anger or fear. However, what distinguishes one emotion from another is the intensity value. Furthermore, emotions are sometimes inhibited or triggered by other states such as the motivational states. Bolles and Fanslows <ref> [6] </ref> work gave an insight on the impact that motivational states have on other emotions. In their work the highest 51 intensity state takes over [6]. <p> Furthermore, emotions are sometimes inhibited or triggered by other states such as the motivational states. Bolles and Fanslows <ref> [6] </ref> work gave an insight on the impact that motivational states have on other emotions. In their work the highest 51 intensity state takes over [6]. Nevertheless, with emotional states it may not be the case, for example a certain mixture of emotions may produce different actions or behaviors as shown by the fuzzy rules in Section 2. <p> The cognitive process always looks for the best emotion to enhance or inhibit in various situations. In some situations, it might be best if fear inhibits pain, but in some others it might be the opposite <ref> [6] </ref>. Thus, before inhibiting emotions, we 52 make a situation assessment and an emotional versus motivational states assessment, whichever is best for the agent to act on, in the given situation, will take precedence while the others will be inhibited. TABLE 5.
Reference: [7] <author> G. H. Bower and P. R. Cohen, </author> <title> Emotional Influences in Memory and Thinking: Data and Theory, Affect and Cognition. </title> <editor> M. Clark and S. Fiske. London, Eds.: </editor> <publisher> Lawrence Erlbaum Associated Publishers, </publisher> <pages> pp. 291-331, </pages> <year> 1982. </year>
Reference-contexts: INTRODUCTION 1. WHAT IF What if a computer can learn and further predict the users emotional state at any given moment? It has been shown that the users emotional states affect perception, thinking and learning <ref> [7, 17] </ref>. However, many training and tutoring systems did not incorporate these factors in their systems architecture [22]. For a training system to understand the users learning status it may be useful to represent and predict his/her emotional state at any given time. <p> To model emotions and emotional behavior, a model will have to take into account these mixtures and explore the effect of different emotions and motivational states on each other. We essentially combined different models, including Bolles and Fanslows model [6] and Bower and Cohens model <ref> [7] </ref> to provide a more believable behavior. (3) The mappings from emotions to behaviors are not gradual. Most of the previous models use a threshold-based mapping technique. For example, they may have a rule that says if the agent is feeling 90% of sadness, then make him act aggressively. <p> Likewise, if joy was more intense than anger or sadness then joy will inhibit both. Nevertheless, we found that negative and positive emotions will tend to influence each other only when the mood is on the boundary between states <ref> [7] </ref>. The mood is simulated as either positive or negative depending on the number of positive and negative emotions in the last five time periods. <p> Since we are trying to simulate a believable agent, we looked at how humans make decisions. We found that emotions and moods have a great impact on their decisions <ref> [7, 8, 11, 12] </ref>. Thus, we used moods to guide the expectation values of the next state, s , given that the agent is in state s. <p> Instead of calculating the value of a state by maximizing the reward we are using the mood as a determining or averaging factor for the different new states. As noted in <ref> [7] </ref> when the agent is in a good mood it will tend to look at the good side, and otherwise it will look at the bad side. Thus, we refined the expectation mechanism to capture this phenomenon.
Reference: [8] <author> Antonio R. Damasio, </author> <title> Descartes Error: Emotion, Reason, and the Human Brain. </title> <address> New York: G.P. Putnam, </address> <year> 1994. </year>
Reference-contexts: By 1994, emotions were further shown to have a clear and important role in the decision-making process. Evidence was uncovered to further emphasize the existence of emotional intelligence. A. Demasio <ref> [8] </ref>, a neurologist and philosopher, reviled new neurological evidence that emphasized the importance of emotions in the design-making process. <p> Through his work with patients suffering a myriad of disorders, including brain damage, problems with memory, language, and reasoning, he was led to believe that mental activities need both the mind and the body <ref> [8] </ref>. A patient named Elliot was referred to Demasio after others had failed. Elliot had been diagnosed with a brain tumor. The tumor grew in his brain and it put enormous pressure on both frontal lobes. <p> some respects Elliot was new Phineas Gage [another case like Elliot, who was found at the time 1848], fallen from social grace, unable to reason and decide in ways conductive to the maintenance and betterment of himself and his family, no longer capable of succeeding as an independent human being <ref> [8] </ref>. After observing him talking about his situation, Demasio said, I never saw a tinge of emotion in my many hours of conversation with him: no sadness, no impatience, no frustration with my incessant and repetitious questioning [8]. Elliot was given tests, including IQ tests, memory tests and decision-making tests. <p> and his family, no longer capable of succeeding as an independent human being <ref> [8] </ref>. After observing him talking about his situation, Demasio said, I never saw a tinge of emotion in my many hours of conversation with him: no sadness, no impatience, no frustration with my incessant and repetitious questioning [8]. Elliot was given tests, including IQ tests, memory tests and decision-making tests. He passed every test that they could give him, even morality tests. His IQ was above average. However, Demasio argued that real-world decisions are far more complex than the tests which were given to him. <p> Since we are trying to simulate a believable agent, we looked at how humans make decisions. We found that emotions and moods have a great impact on their decisions <ref> [7, 8, 11, 12] </ref>. Thus, we used moods to guide the expectation values of the next state, s , given that the agent is in state s.
Reference: [9] <author> R. </author> <title> Descartes, The Passions of the Soul. Trans. </title> <editor> Stephen Voss. </editor> <publisher> Cambridge: Hackett Publishing Company, </publisher> <year> 1989. </year>
Reference-contexts: The Greek philosophers established a theory on emotions. Plato, for example, said that passions and desires and fears make it impossible for us to think [18]. Thus, emotions were viewed as obstacles to the human rational thinking. Centuries later, by the sixteenth century, Descartes <ref> [9] </ref> reinforced this theory by yet another theory. With his famous statement I think therefore I am, he formulated a theory of the emotional process that separates the mind from the body. In his book, The Passions of the Soul, he outlined the differences between passions and rational thinking. <p> He regarded emotions as passions of the soul, which were defined as urges and needs that the body creates. In his view, the body holds all the needs and urges, while the mind is the heart of the rational thinking process <ref> [9] </ref>. After three centuries, new theories of emotions were established. By 1884, William James [15] published his article What is Emotion? At that time, there were no psychology journals. <p> All the states that affect the survival goal of an agent are called motivational states, such as hunger, thirst, pain, exhaustion and sometimes fear. 8 Descartes defined emotions as passions <ref> [9] </ref>. He gave some examples of emotions, including anger, joy and fear. He further identified different facial expressions for each of these emotions. Emotions, among other feelings, can change the facial expressions. Feelings and emotions are part of the same process. <p> Izard [14], using some tests on various subjects, formulated a list of innate emotions, i.e. emotions that are common through various cultures and social groups. The list he produced is similar to Descartes list produced ages earlier <ref> [9] </ref>. Ortony et al. [30] produced a model of emotions where they defined emotions to be clusters or chunks. For example, there might be five or six different levels of anger, but these levels are all classified under the emotion anger. Rosman et al. [39] produced another model of emotions.
Reference: [10] <author> P. Ekman, </author> <title> An Argument for Basic Emotions, Cognition and Emotion, </title> <publisher> London, Lawrence Erlbaum Associated Publishers, </publisher> <pages> pp. 169-200, </pages> <year> 1992. </year>
Reference-contexts: Rosman et al. [39] produced another model of emotions. The model was used to trigger emotions according to events, which were divided into categories according to the cause. These categories include (1) self-caused, (2) other-caused and (3) uncertain-cause events. Ekman <ref> [10] </ref>, one of the leading psychologists in the area of emotions, listed six basic emotions: anger, fear, sadness, enjoyment, disgust, and surprise. He composed this list by looking at the various facial expressions among cultures and ethnic groups.
Reference: [11] <author> Howard Gardner, </author> <title> Frames of Mind. </title> <address> New York: </address> <publisher> Basic Books, </publisher> <year> 1983. </year>
Reference-contexts: EMOTIONAL INTELLIGENCE: A MYTH OR REALITY? Searching for a complete definition for the emotional process, some psychologists tried to further explore its role in human intelligence. Howard Gardner <ref> [11] </ref> was one of the pioneer researchers in this field. In 1973 Howard Gardner wrote his book, Frames of Mind, to explain the concept of Multiple Intelligence [11]. The idea of Multiple Intelligence originated long before Gardners time; however the theory was not well accepted at the time. <p> Howard Gardner <ref> [11] </ref> was one of the pioneer researchers in this field. In 1973 Howard Gardner wrote his book, Frames of Mind, to explain the concept of Multiple Intelligence [11]. The idea of Multiple Intelligence originated long before Gardners time; however the theory was not well accepted at the time. He was formulating a new theory of intelligence. <p> He was formulating a new theory of intelligence. The idea of a single IQ test that could determine a persons intelligence and therefore speculate on the future of a persons life was rejected. Gardner divided intelligence into six types: linguistic, musical, logical-mathematical, spatial, bodily kinesthetic and personal intelligence <ref> [11] </ref>. 5 The importance of Gardners work became apparent a few years later. By the 1990s, many theories were formulated to describe a phenomenon that was later called emotional intelligence. <p> Since we are trying to simulate a believable agent, we looked at how humans make decisions. We found that emotions and moods have a great impact on their decisions <ref> [7, 8, 11, 12] </ref>. Thus, we used moods to guide the expectation values of the next state, s , given that the agent is in state s.
Reference: [12] <author> Daniel Goleman, </author> <title> Emotional Intelligence. </title> <address> New York: </address> <publisher> Bantam Books, </publisher> <year> 1995. </year> <month> 90 </month>
Reference-contexts: Interpersonal intelligence is a correlative ability, turned inward. It is a capacity to form an accurate, veridical model of oneself and to be able to use that model to operate effectively in life <ref> [12] </ref>. By 1994, emotions were further shown to have a clear and important role in the decision-making process. Evidence was uncovered to further emphasize the existence of emotional intelligence. A. Demasio [8], a neurologist and philosopher, reviled new neurological evidence that emphasized the importance of emotions in the design-making process. <p> Pure reason is what Elliot was bound to, and that did not lead him to a successful life. 7 Demasios findings proved the existence of emotional intelligence. Emotional intelligence was further explored and formulated by D. Goleman <ref> [12] </ref>. In his book, Emotional Intelligence: why it can matter more than IQ [12], he said: what career to pursue, whether to stay with a secure job or switch to one that is riskier but more interesting, whom to date or marry, where to live, which apartment to rent or house <p> Emotional intelligence was further explored and formulated by D. Goleman <ref> [12] </ref>. In his book, Emotional Intelligence: why it can matter more than IQ [12], he said: what career to pursue, whether to stay with a secure job or switch to one that is riskier but more interesting, whom to date or marry, where to live, which apartment to rent or house to buy and on and on through life. <p> Formal logic alone can never work as the basis for deciding whom to marry or trust or even what job to take; these are realms where reason without feeling is blind <ref> [12] </ref>. 4. FOUNDATION OF EMOTION AND EI Emotion. Science has been and still is looking for a complete definition of the term emotion. Even though there is no complete definition, there are some theories established to formalize the concept of emotion. <p> The idea of emotional intelligence became the groundwork of much of the research work done on the theory of emotions. Thus, the focus went from the definition of the concept of emotion and the emotional expression to the definition and modeling of the emotional intelligence phenomenon. Goleman <ref> [12] </ref> stated, one aspect of emotional intelligence, social intelligence [is] the ability to understand others and act wisely in human relations [12]. Thus, he formulated and defined emotional intelligence to include the following: 9 1. Knowing ones emotions. Self-awareness - recognizing the emotion as it happens. 2. Managing emotions. <p> Thus, the focus went from the definition of the concept of emotion and the emotional expression to the definition and modeling of the emotional intelligence phenomenon. Goleman <ref> [12] </ref> stated, one aspect of emotional intelligence, social intelligence [is] the ability to understand others and act wisely in human relations [12]. Thus, he formulated and defined emotional intelligence to include the following: 9 1. Knowing ones emotions. Self-awareness - recognizing the emotion as it happens. 2. Managing emotions. The ability to handle the feelings and emotions when they happen. This ability builds on the self-awareness step. 3. Motivating oneself. <p> Recognizing Emotions in Others. The ability to recognize the others emotions, for example Empathy, is considered a fundamental people skill. 5. Handling relationships. Handling relationships is the ability to manage emotions in others through leadership, popularity and interpersonal effectiveness <ref> [12] </ref>. Moreover, experience plays an important role in the simulation of emotional intelligence. Experience helps in shaping the personality and emotional behavior. As Goleman says: Such decisions cannot be made well through sheer rationality; they require gut feeling, and the emotional wisdom garnered through past experiences. <p> Formal logic alone can never work as the basis for deciding whom to marry or trust or even what job to take; these are realms where reason without feeling is blind <ref> [12] </ref>. Therefore, to provide a good model of the emotional concept we have to simulate experience. 5. PROBLEMS IN EMOTIONAL MODELING By the 1980s, several appraisal models of emotions had been formulated. <p> This factor is discussed in more detail in Chapter III. Moreover, the model did not represent the learning factor in modeling emotions. Experience and learning has been proven to change and shape the emotional process <ref> [12] </ref>. Our model further expands this concept in Chapter III. Furthermore, the idea of mapping emotions to behavior and emotional intensity is still simulated in a sharp edged fashion. Thus the introduction of fuzzy logic for the purpose of smoothing the transition will probably enhance the model. <p> Since we are trying to simulate a believable agent, we looked at how humans make decisions. We found that emotions and moods have a great impact on their decisions <ref> [7, 8, 11, 12] </ref>. Thus, we used moods to guide the expectation values of the next state, s , given that the agent is in state s. <p> The processes of self-realization, self-perception and self-awareness form the identity that can later shape the personality. These concepts provide yet another dimension to the model that we did not incorporate. Moreover, the idea of self-esteem can also be added to the model. It had been documented <ref> [12] </ref> that the process of self-esteem heavily depends on the experience process, and thus we can further extend the model to incorporate the link between emotions, experience and self-esteem. The idea of opinion formation about other objects and other people around us may also be added to the model.
Reference: [13] <author> K. Inoue, K. Kawabata, and H. Kobayashi, </author> <title> On a Decision Making System with Emotion, </title> <booktitle> IEEE Int. Workshop on Robot and Human Communication, </booktitle> <address> Tokyo, Japan, </address> <pages> pp. 461-465, </pages> <year> 1996. </year>
Reference-contexts: As we will show in Chapter III, experience plays an important role in modeling emotions and further developing the emotional process. In essence, this is one of the major contributions of the thesis. Another system was developed that made use of yet another learning algorithm, namely Neural Networks <ref> [13] </ref>. Neural Networks were discussed in [26]. The system simulated a virtual environment where some herbivorous animals and carnivorous animals lived. Of course, the carnivorous animals were considered natural enemies of the herbivorous animals. <p> We consider this action is caused by Fear. Fear is the most simple and primitive mental software that determines the best action for escaping from danger <ref> [13] </ref>. To achieve believability in simple actions is very trivial. Actually these animals can pass as believable for very simple behavior animals. However, when we look at more complex animals such as, pets or humans or even birds, achieving believability turns out to be a completely different story.
Reference: [14] <author> Carroll E. Izard, </author> <title> Human Emotions. </title> <address> New York & London: </address> <publisher> Plenum Press, </publisher> <year> 1977. </year>
Reference-contexts: In fact, feelings, emotions and reasons are all intermingled [25]. While there has been questions about what an emotion is and how an emotion can be formulated into a feeling, there exist a few other attempts to define the concept of emotion. Izard <ref> [14] </ref>, using some tests on various subjects, formulated a list of innate emotions, i.e. emotions that are common through various cultures and social groups. The list he produced is similar to Descartes list produced ages earlier [9].
Reference: [15] <author> W. James, </author> <title> What is an Emotion? Mind, </title> <journal> vol. </journal> <volume> 9, </volume> <pages> pp. 188-205, 1884. </pages>
Reference-contexts: In his view, the body holds all the needs and urges, while the mind is the heart of the rational thinking process [9]. After three centuries, new theories of emotions were established. By 1884, William James <ref> [15] </ref> published his article What is Emotion? At that time, there were no psychology journals. <p> He said, my thesis on the contrary is that the bodily changes follow directly the perception of the exciting fact, and that our feeling of the same changes as they occur is the emotion <ref> [15] </ref>. His idea was that emotions are often accompanied by some bodily responses (e.g. tight stomach, tense muscles, etc.), and that different bodily responses trigger different emotions. Our reaction to these responses makes us feel an emotion. Years later, different views and theories were formulated [18].
Reference: [16] <author> L. P. Kaelbling, M. L. Littman, and A. W. Moore, </author> <title> Reinforcement Learning: A Survey, </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> vol. 4, </volume> <pages> pp. 237-285, </pages> <year> 1996. </year>
Reference-contexts: Thus, identifying the link between an event and the corresponding goals was noted to be a very complex task to accomplish [38]. The agent can potentially learn this by using a reinforcement learning algorithm <ref> [16, 26] </ref>; we will briefly outline one of the reinforcement algorithms, namely the Q-learning algorithm. The reader is referred back to [16, 26] for more detail. <p> The agent can potentially learn this by using a reinforcement learning algorithm <ref> [16, 26] </ref>; we will briefly outline one of the reinforcement algorithms, namely the Q-learning algorithm. The reader is referred back to [16, 26] for more detail. It is often the case that an agent does not know the consequences of a given action until a complete sequence of actions is finished.
Reference: [17] <author> A. Konev, E. Sinisyn, and V. Kim, </author> <title> Information Theory of Emotions in Heuristic Learning, </title> <journal> Zhurnal Vysshei Nervnoi Deyatelnosti imani, </journal> <volume> vol. 37, no. 5, </volume> <pages> pp. 875-879, </pages> <year> 1987. </year>
Reference-contexts: INTRODUCTION 1. WHAT IF What if a computer can learn and further predict the users emotional state at any given moment? It has been shown that the users emotional states affect perception, thinking and learning <ref> [7, 17] </ref>. However, many training and tutoring systems did not incorporate these factors in their systems architecture [22]. For a training system to understand the users learning status it may be useful to represent and predict his/her emotional state at any given time. <p> To simulate these personalities we did not need all the emotional states that were simulated in the pet. In fact we simulated only four emotions: joy, sad, depression and fear. We added some other states, including boredom and motivation. Students learning processes depend on their attention span and motivations <ref> [17] </ref>. We found that these states were enough to simulate classroom agents. However, how much is enough is still an open question. The answer heavily depends on the application and the domain studied.
Reference: [18] <author> Joseph LeDoux, </author> <title> The Emotional Brain, </title> <address> New York: </address> <publisher> Simon & Schuster,1996. </publisher>
Reference-contexts: HISTORICAL PERSPECTIVE Research on emotions started out with theories and views. The Greek philosophers established a theory on emotions. Plato, for example, said that passions and desires and fears make it impossible for us to think <ref> [18] </ref>. Thus, emotions were viewed as obstacles to the human rational thinking. Centuries later, by the sixteenth century, Descartes [9] reinforced this theory by yet another theory. <p> His idea was that emotions are often accompanied by some bodily responses (e.g. tight stomach, tense muscles, etc.), and that different bodily responses trigger different emotions. Our reaction to these responses makes us feel an emotion. Years later, different views and theories were formulated <ref> [18] </ref>. Cannon refuted James theory about emotions, which had dominated the psychology field for about thirty-six years. According to Cannon, James theory would not hold because almost all emotions have the same bodily responses. Thus, the idea that different bodily responses trigger different emotions was proven wrong. <p> However, by the mid-90s LeDoux opposed this rejection by stating that some cognitive processes occur in the subconscious level. Thus, it is premature to reject emotion from the field of cognition just because it includes subconscious level process <ref> [18] </ref>. Nevertheless, Zajoncs findings contributed to another view of the emotional process that was not yet explored. The idea of subconscious level emotional activities was new. <p> Some events or objects may trigger a conditioned behavior, and thus these events will not pass through the normal paths of the emotional process, but rather an emotion and a behavior is automatically triggered by the conditioning process <ref> [18] </ref>. A further discussion of this process will be given in Section 4. FIGURE 4. EMOTIONAL PROCESS Instead of discussing the emotional process step by step in terms of the order of execution, different steps will be reviewed from the various contribution viewpoints. <p> B. OVERVIEW OF THE LEARNING PROCESS In the early stages of this research, we expected that the only type of learning associated with the emotional process would be conditioning, which forms the emotional memory <ref> [18] </ref>. However, we found that there are other types of learning that directly relate emotions to the emotional intelligence process. These include learning about the subjects moods, and learning the actions that pleases or displeases the subject. <p> The intensities of these emotions are calculated as a function of the value, v, of the learnt rule. D. CLASSICAL LEARNING OR CONDITIONING Associating objects to emotions or to a motivational state, forms yet another type of learning which is closely integrated with the reinforcement learning discussed above <ref> [18] </ref>. For example, if the agent experienced pain when an object, g, touches it, then the motivational state of pain will be associated with the object g. This kind of learning does not depend on the situation per se, but it depends on the object-emotion/motivational state association.
Reference: [19] <author> A. Bryan Loyall and Joseph Bates, </author> <title> Personality-Based Believable Agents That Use Language, </title> <booktitle> Proc. of the First Autonomous Agents Conference, </booktitle> <address> Marina del Rey, CA, </address> <year> 1997. </year>
Reference-contexts: Looking for answers they sometimes turn to friends, but it might help if the system can sense the users level of frustration and try to offer help accordingly. Some agents have been built to learn and adapt to the users needs <ref> [19] </ref>. Learning users preferences can be predicted solely by the emotional state of the user. These agents may learn what news you like to read or what excites you and add a bookmark to it automatically.
Reference: [20] <author> P. Maes, </author> <title> Agents that Reduce Work and Information Overload, </title> <journal> Communications of ACM, </journal> <volume> vol. 37, no. 7, </volume> <pages> pp. 37-45, </pages> <year> 1997. </year>
Reference: [21] <author> P. Maes, </author> <title> Artificial Life Meets Entertainment: Lifelike Autonomous Agents, </title> <journal> Communications of the ACM Special Issue on Novel Applications of AI, </journal> <volume> vol. 38, no. 11, </volume> <pages> pp. 108-114, </pages> <year> 1995. </year>
Reference: [22] <author> Mark, M.A. </author> <title> The VCR Tutor: Design and Evaluation of an Intelligent Tutoring System. </title> <type> Masters Thesis, </type> <institution> University of Saskatchewan, Saskatoon, Saskatchewan, </institution> <year> 1991. </year>
Reference-contexts: However, many training and tutoring systems did not incorporate these factors in their systems architecture <ref> [22] </ref>. For a training system to understand the users learning status it may be useful to represent and predict his/her emotional state at any given time.
Reference: [23] <author> E. Masuyama, </author> <title> A Number of Fundamental Emotions and Their Definitions, </title> <booktitle> IEEE International Workshop on Robot and Human Communication, </booktitle> <address> Tokyo, Japan, </address> <pages> pp. 156-161, </pages> <year> 1994. </year>
Reference: [24] <author> G. A. Miller, </author> <title> The Magical Number Seven, Plus or Minus Two: Some Limits On Our Capacity for Processing Information, </title> <journal> Psychological Review, </journal> <volume> Vol. 63, </volume> <pages> pp. 81-97, </pages> <year> 1994. </year>
Reference-contexts: On the other hand, an upper bound of seven plus or minus two was made under the assumption that the short-term memory can hold only seven plus or minus two chunks <ref> [24] </ref>; i.e. the agents mind may not handle more than a length of 7-2 consecutive action comparisons. Considering a pets mind, we think that handling a pattern of three consecutive actions is more suitable.
Reference: [25] <author> M. Minsky, </author> <booktitle> The Society of the Mind. </booktitle> <address> New York: </address> <publisher> Simon and Schuster, </publisher> <year> 1986. </year> <month> 91 </month>
Reference-contexts: He gave some examples of emotions, including anger, joy and fear. He further identified different facial expressions for each of these emotions. Emotions, among other feelings, can change the facial expressions. Feelings and emotions are part of the same process. In fact, feelings, emotions and reasons are all intermingled <ref> [25] </ref>. While there has been questions about what an emotion is and how an emotion can be formulated into a feeling, there exist a few other attempts to define the concept of emotion.
Reference: [26] <author> Tom. M. Mitchell, </author> <title> Machine Learning, </title> <address> New York: </address> <publisher> McGraw-Hill Co., </publisher> <year> 1996. </year>
Reference-contexts: At any given time, the robot would test the situation and then it would choose a strategy that represented a best fit to the given situation. The selection of a strategy was based on a Q-learning algorithm. For more information on the Q-learning algorithm the reader is referred to <ref> [26] </ref>. The Q value was modified using an evaluation function that depended on the level of cooperation. The strategy with the best Q value would then be followed. A frustration function was introduced. The function served as a conflict resolution factor. <p> In essence, this is one of the major contributions of the thesis. Another system was developed that made use of yet another learning algorithm, namely Neural Networks [13]. Neural Networks were discussed in <ref> [26] </ref>. The system simulated a virtual environment where some herbivorous animals and carnivorous animals lived. Of course, the carnivorous animals were considered natural enemies of the herbivorous animals. The herbivorous animals selected their next actions by their own decision making process, while the carnivorous animals acted randomly. <p> Thus, identifying the link between an event and the corresponding goals was noted to be a very complex task to accomplish [38]. The agent can potentially learn this by using a reinforcement learning algorithm <ref> [16, 26] </ref>; we will briefly outline one of the reinforcement algorithms, namely the Q-learning algorithm. The reader is referred back to [16, 26] for more detail. <p> The agent can potentially learn this by using a reinforcement learning algorithm <ref> [16, 26] </ref>; we will briefly outline one of the reinforcement algorithms, namely the Q-learning algorithm. The reader is referred back to [16, 26] for more detail. It is often the case that an agent does not know the consequences of a given action until a complete sequence of actions is finished. <p> The table can be initially filled with default initial values (we used 0). The agent will begin from a state s. He will take an action, a, which takes him to a new state s'. The agent may obtain a reward r for his action <ref> [26] </ref>. If it receives a reward it updates the table above using the following formula: Q (s,a) r Q (s ,a ) + g max [26] 55 where r is the immediate reward, g is a discount factor, s'is the new state, and a'is an action from the new state s'. <p> He will take an action, a, which takes him to a new state s'. The agent may obtain a reward r for his action <ref> [26] </ref>. If it receives a reward it updates the table above using the following formula: Q (s,a) r Q (s ,a ) + g max [26] 55 where r is the immediate reward, g is a discount factor, s'is the new state, and a'is an action from the new state s'. Thus, the Q value of the previous state-action pair depends on the Q value of the new state-action pair.
Reference: [27] <author> H. Mizogouhi, T. Sato, and K. Takagi, </author> <title> Realization of Expressive Mobil Robot, </title> <booktitle> Proc. IEEE Int. Conf. of Robotics and Automation, </booktitle> <address> Albuquerque, NM, </address> <pages> pp. 581-586, </pages> <year> 1997. </year>
Reference: [28] <author> H. S. Nwana, </author> <title> Software Agents: An Overview, </title> <journal> Knowledge Engineering Review, </journal> <volume> vol. 11, no. 3, </volume> <pages> pp. 205-224, </pages> <year> 1996. </year>
Reference-contexts: if an agent can simulate certain emotional states and emotional behavior? Moreover, what if an agent can simulate emotional intelligence? Agents have been This thesis follows the style of IEEE Transactions on Robotics and Automation. 2 divided into several types, including interface agents, information agents, software agents and autonomous agents <ref> [28] </ref>. Modeling emotions will probably improve and further enhance the performance of several of these agent types.
Reference: [29] <author> Ane Ohman, </author> <title> The Psychophysiology of Emotion; Evolutionary and Nonconscious Origins, </title> <address> London, England: </address> <publisher> Lawrence Erlbaum Accociates, Inc., </publisher> <year> 1994. </year>
Reference-contexts: The idea of subconscious level emotional activities was new. Thus, the earlier view that regarded the emotional process as just a need or an urge was automatically refuted by the foundation of subconscious emotions, which was further expanded by Ohman <ref> [29] </ref>. 3. EMOTIONAL INTELLIGENCE: A MYTH OR REALITY? Searching for a complete definition for the emotional process, some psychologists tried to further explore its role in human intelligence. Howard Gardner [11] was one of the pioneer researchers in this field.
Reference: [30] <author> A. Ortony, G. Clore, and A. Collins, </author> <title> The Cognitive Structure of Emotions, </title> <publisher> Cambridge: Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: Izard [14], using some tests on various subjects, formulated a list of innate emotions, i.e. emotions that are common through various cultures and social groups. The list he produced is similar to Descartes list produced ages earlier [9]. Ortony et al. <ref> [30] </ref> produced a model of emotions where they defined emotions to be clusters or chunks. For example, there might be five or six different levels of anger, but these levels are all classified under the emotion anger. Rosman et al. [39] produced another model of emotions. <p> Therefore, to provide a good model of the emotional concept we have to simulate experience. 5. PROBLEMS IN EMOTIONAL MODELING By the 1980s, several appraisal models of emotions had been formulated. Ortony <ref> [30] </ref> and Rosman [39] tried to solve the problem of the synthesis of the emotional process given the occurrence of certain events. <p> Both of these models formalized some variables that might affect the synthesis of emotions, including expectations, predictions of the 10 occurrence of an event and effort of achieving a goal. In Ortonys <ref> [30] </ref> model, emotions were defined in terms of rules. For example, joy was defined as the occurrence of a desirable event [30]. In contrast, Rosmans model formalized emotions according to event categories [39]. <p> In Ortonys <ref> [30] </ref> model, emotions were defined in terms of rules. For example, joy was defined as the occurrence of a desirable event [30]. In contrast, Rosmans model formalized emotions according to event categories [39]. These categories depend on many factors, including the likelihood of the event to occur and the consistency measure of an event in terms of the goals. In addition, he further refined the synthesis process to include self-perception. <p> As soon as an event is perceived it is passed to the experience model for assessment. The experience model is one of the major contributions of the thesis. Most computational models of emotions have been built using the appraisal models such as Ortony & Collins <ref> [30] </ref>, or Rosman [39]. Although these models use internal variables, such as expectations and the level of effort exerted, to produce emotions, the computational models that evolved out of these models (e.g. OZ [4]) did not use experience to trigger these internal variables. <p> Clearly, this model presents only one spectrum of the filtering process. In our attempt to find better solutions, we reviewed other models. 22 B. APPRAISAL MODELS OF EMOTIONS Appraisal models had been developed by the 80s and the early 90s to model emotions in terms of event occurrence <ref> [30, 39] </ref>. In the next couple of sections, we will detail two models that evolved around the 1980s. i. ROSMANS MODEL Rosmans model [39] is illustrated in Table 1. In this model, an emotion is generated according to an event assessment procedure [39]. <p> Moreover, the emotional process is rather deeply immersed in the thinking process and thus, not all emotions are triggered by external events. This fact uncovered an important limitation in the emotion event appraisal models. ii. ORTONY, COLLINS AND CLORES MODEL Ortony et al. <ref> [30] </ref> developed another model that was quite similar to Rosmans model [39]. <p> For example: joy = the occurrence of a desirable event, relief = occurrence of a disconfirmed undesirable event. Sixteen emotions were formalized in this form, including relief, distress, disappointment, love, hate and satisfaction <ref> [30] </ref>. In fact, the model was 25 employed as a computational model by the OZ group, a group working on believable agents at CMU (Carnegie Mellon University) [4, 5, 38, 36, 37]. Nevertheless, the model is not complete. <p> These agents interact with each other in a way that achieves global intelligence. i. BROAD AGENTS & BELIEVABLE AGENTS J. Bates is building a believable agent (OZ project) [38, 4, 5] using the model that was described in The Structure of Emotions by Ortony, Clore and Collins <ref> [30] </ref>. The aim of the OZ project was to provide the users with the experience of living in dramatically interesting microworlds that include moderately competent emotional agents. They formalized emotions into types or clusters, where emotions within a cluster share similar causes. <p> For example, the distress type describes all emotions caused by displeasing events. The appraisal of the displeasingness of events is based on the agents goals. They also linked some emotions to some actions. They actually deviated a little from the OCC <ref> [30] </ref> model. They did not model hope or fear. Joy and distress were modeled according to goal success and failure, respectively. The agent architecture is presented in Figure 2. As the figure shows there are three major models. <p> EM produces the emotional state of the agent according to different factors, including the goal success/failure, attitudes, standards and events. The emotional state is determined according to the rules given by Ortonys model <ref> [30] </ref>. These emotions are then passed to HAP, which determines the behavior according to the emotion and its plan. Sometimes emotions override the plan and vice versa. <p> Fuzzy-logic can provide smoother transitions as it will be explained in more detail in the next chapter. Even though this model employed Ortonys emotional synthesis process <ref> [30] </ref>, which emphasized the importance of expectation values, the model did not simulate any expectation values. Emotions were changing only according to the change of situations in time. There was no learning employed. <p> Fuzzy implication rules are used to determine a desirability measure of the event according to these two criteria. The desirability measure, once calculated, will be passed to an appraisal model to further determine the emotional state of the agent. The model uses a combination of Ortony <ref> [30] </ref> and Rosmans [39] models to trigger emotions. An emotion or a mixture of emotions will be triggered using the event desirability measure. The mixture will then be filtered to produce an emotional state. <p> A desirable event was defined as an event that causes goal success, while an undesirable event was defined as an event that causes goal failure. The desirability of an event was measured as a true or false concept [36]. Ortonys <ref> [30] </ref> model was used to trigger emotions such as joy, sadness, etc. Emotions were triggered at different intensities. Intensities are degrees, say a number between 1 and 10, that measure the degree of an emotion. The intensity degree was used to map the emotional state to a behavior. <p> EMOTIONAL STATES SIMULATION Once an event desirability measure is calculated, rules can be fired to identify an emotional state. The rules used for firing the emotions are formulated from Ortonys model <ref> [30] </ref>; an example is shown below: Joy = the occurrence of a desirable event. Some emotions, including hope, fear and relief need more than just the measure of desirability discussed above; expectations and likelihood play an important role in simulating these emotions. <p> The expectation value is taken from the learning model, which is detailed in a later section. A variation of Ortonys <ref> [30] </ref> model is used to define the rules used. These rules are documented in Table 3. Fourteen emotions are simulated using these rules.
Reference: [31] <author> R. Pfeifer, </author> <booktitle> Artificial Intelligence Models of Emotions, Cognitive Perspectives on Emotion and Motivation, </booktitle> <pages> pp. 287-320, </pages> <year> 1988. </year>
Reference-contexts: He simulated these states as interrupts, thus whenever, for example, the hunger level goes beyond a certain limit the brain will be interrupted. Models of emotions from early 1960s till the 1980s were summarized by R. Pfeifer <ref> [31] </ref>. However, since the psychology of emotions was not yet complete at that time, it was not easy to find a computational model that described the whole emotional process. Instead of looking through these models, we will look at the more recent models.
Reference: [32] <author> R. W. Picard and J. Healy, </author> <title> Affective Wearables, </title> <booktitle> Proc. of IEEE Conf. on Wearables, </booktitle> <address> Cambridge, MA: </address> <pages> pp. 90-97, </pages> <year> 1997. </year>
Reference-contexts: In these cases, a complete model for simulating the emotional process is needed. C. AFFECTIVE WEARABLES Affective wearables were developed at the MIT media lab <ref> [33, 34, 32] </ref>. As Picard said, one of the distinguishing features of wearable computers, as opposed to merely portable computers, is that they can be in physical contact with you in a long-term intimate way [32]. <p> C. AFFECTIVE WEARABLES Affective wearables were developed at the MIT media lab [33, 34, 32]. As Picard said, one of the distinguishing features of wearable computers, as opposed to merely portable computers, is that they can be in physical contact with you in a long-term intimate way <ref> [32] </ref>. A wearable can potentially learn to recognize different physical and physiological patterns and then predict your mood, your emotional states, etc. Since it can stay with you for a long term, it can potentially learn some essential elements of your personality, your preferences, your friends, and your opinions.
Reference: [33] <author> R. W. </author> <title> Picard, Affective Computing, </title> <address> Cambridge, MA: </address> <institution> MIT Media Lab, </institution> <type> Technical Rep. No. 221, </type> <year> 1995. </year>
Reference-contexts: In these cases, a complete model for simulating the emotional process is needed. C. AFFECTIVE WEARABLES Affective wearables were developed at the MIT media lab <ref> [33, 34, 32] </ref>. As Picard said, one of the distinguishing features of wearable computers, as opposed to merely portable computers, is that they can be in physical contact with you in a long-term intimate way [32].
Reference: [34] <author> R. W. </author> <title> Picard, Affective Computing, </title> <address> Cambridge, MA: </address> <publisher> MIT press, </publisher> <year> 1997. </year>
Reference-contexts: Moreover, for a computer to understand or predict an emotional state of a subject, a quantitative measure of the emotional state must be calculated. Since we lack the experience and the equipment to measure emotion <ref> [34] </ref>, we felt obliged to purse other avenues. Thus, we chose to concentrate on simulating emotions rather than understanding emotions. <p> In these cases, a complete model for simulating the emotional process is needed. C. AFFECTIVE WEARABLES Affective wearables were developed at the MIT media lab <ref> [33, 34, 32] </ref>. As Picard said, one of the distinguishing features of wearable computers, as opposed to merely portable computers, is that they can be in physical contact with you in a long-term intimate way [32]. <p> Moreover, events are judged as desirable or undesirable events according to the degree by which an event affects a goal or a set of goals. The question of how the agent knows that a particular event causes a particular goal to fail or succeed was previously unsolved <ref> [34] </ref>. However, our model demonstrates that the knowledge about the causal effects of events can be a product of the learning process. 41 2. <p> Emotions and emotional expression is what differentiates good actors from bad ones. Therefore, if we are to create the illusion of life we need to simulate the emotional process. As Ian Maitlan, Emmy Award winning director and editor said, quoted by Picard <ref> [34] </ref>, A film is simply a series of emotions strung together with a plot. Though flippant, this thought is not far from the truth. <p> Though flippant, this thought is not far from the truth. It is the filmmakers job to create moods in such a realistic manner that the audience will experience those same emotions enacted on the screen, and thus feel part of the experience <ref> [34] </ref>. 78 There are important factors that should be taken into consideration when creating a believable agent. These factors can be summarized as follows: (1) emotional exaggeration. One of the important aspects of believability is the idea of emotional expression. <p> By using wearable computers, more 82 specifically affective wearable computers, information can be gathered about the amount of excitement and stress among other emotional states. Many applications were discussed in Picards book, Affective Computing <ref> [34] </ref>. She provided some other aspects of the use of affective computing. For more details on the various applications that can benefit from modeling emotions the reader is referred to [34]. D. MODELING EMOTIONS AND CONTRIBUTIONS Even though some applications may benefit from modeling emotions, some others may not. <p> Many applications were discussed in Picards book, Affective Computing <ref> [34] </ref>. She provided some other aspects of the use of affective computing. For more details on the various applications that can benefit from modeling emotions the reader is referred to [34]. D. MODELING EMOTIONS AND CONTRIBUTIONS Even though some applications may benefit from modeling emotions, some others may not. For example, modeling emotions may not affect applications like search engines. <p> Important emphasis on the concept of emotional intelligence has led researchers to look into the idea of emotion simulations and synthesis, and to further understand its impact on the many areas within the computer science field. Effective wearables <ref> [34] </ref> are being developed at MIT to measure the emotional state of a user. This research can then produce a model that can be used as a catalyst in many other systems. By the use of this model, systems can measure the users reaction to provide better services accordingly.
Reference: [35] <author> Donald D. Price, James E. Barrell, and James J. Barrell, </author> <title> A Quantitative-Experiential Analysis of Human Emotions, </title> <journal> Motivation and Emotion, </journal> <volume> vol. 9, No. 1, </volume> <year> 1985. </year>
Reference-contexts: Nevertheless, it outlines a very important point that the other models did not take into consideration; emotions and motivational states do affect each other in various situations. Thus, for example pain might inhibit other emotional states such as pride, shame, and fear. D. Price et al. <ref> [35] </ref> showed that internal states such as desire and expectation can affect or even predict the emotional state of various subjects [35]. <p> Thus, for example pain might inhibit other emotional states such as pride, shame, and fear. D. Price et al. <ref> [35] </ref> showed that internal states such as desire and expectation can affect or even predict the emotional state of various subjects [35]. They based this conclusion on the data obtained by asking various subjects to quantify their experience of a certain emotion by answering some questions on a score from one to ten. <p> Some others were built to model emotions according to the occurrence of events; these models are called event appraisals. In contrast, some other models were produced to tackle different questions and directions in modeling emotions. For example, D. Price and J. Barrell <ref> [35] </ref> developed a model that describes emotions in terms of desires and expectations. Unlike the appraisal models, they did not limit an emotion to an event. They linked an emotion to the internal thinking process, which were reflected in expectations and desires. <p> They gathered some participants and asked them questions about their experience with some emotions, including anger and depression. One of their questions was formalized as: rate your experience of this emotion in a number from one to ten <ref> [35] </ref>. They took a number of answers from different participants and quantified them to fit a mathematical curve that showed the relation between expectation, desire and emotional intensity. However, the model did not provide a method for calculating expectations and desires. <p> It should be noted that the hope intensity is not proportional to the expectation value, as is the case with other emotions. On the contrary, the higher the certainty, the less the hope, as is noted in <ref> [35] </ref>. Thus, the hope intensity is defined as : Hope expectation desirability expectation desirability ( , ) ( . ) ( . ) . 0 5 The formulas calculating the intensity of emotions were taken from a study done by Price et al. [35]. These are illustrated in Table 4. <p> less the hope, as is noted in <ref> [35] </ref>. Thus, the hope intensity is defined as : Hope expectation desirability expectation desirability ( , ) ( . ) ( . ) . 0 5 The formulas calculating the intensity of emotions were taken from a study done by Price et al. [35]. These are illustrated in Table 4. The table shows the method by which intensities are calculated for various emotions given an expectation value and an event desirability measure. 50 TABLE 4.
Reference: [36] <author> W. Scott Reilly, </author> <title> Believable Social and Emotional Agents, </title> <institution> School of Computer Science, Pittsburgh, PA: Carnegie Mellon University, </institution> <type> Ph.D. Thesis CMU-CS-96-138, </type> <year> 1996. </year>
Reference-contexts: This particular application will be discussed in more detail in Chapter II. Believable agents heavily rely on emotions to create believable responses. Believable agents were defined to be agents that create the illusion of life <ref> [3, 36] </ref>. The concept of believability is often used in theater. In theater, a character is created by completing a character study, which is formulated into a manifestation of the real characters behaviors. This manifestation is not necessarily real. <p> Due to the emergence of the believable agents, a number of models simulating the emotional process have been proposed. Two major models evolved out of this area, the OZ project <ref> [3, 4, 5, 36, 38] </ref> at CMU and Simon [51] at MIT. These models follow different agent architectures. These architectures will be detailed along with other models in Chapter II. <p> The OZ project uses Ortonys model as a basis for these rules. The emotions triggered are then mapped according to their intensity to a specific behavior. This behavior is then expressed in the form of text or animation <ref> [36] </ref>. One of the problems of this model is its mapping function. A specific emotion with a specific intensity is mapped to a behavior. The researchers rely on interval-based mapping. <p> Sixteen emotions were formalized in this form, including relief, distress, disappointment, love, hate and satisfaction [30]. In fact, the model was 25 employed as a computational model by the OZ group, a group working on believable agents at CMU (Carnegie Mellon University) <ref> [4, 5, 38, 36, 37] </ref>. Nevertheless, the model is not complete. As stated earlier the equations are intuitive and seem to capture the process of triggering one emotion really well, but often emotions are triggered in a mixture. <p> Thus, we will take one of the previous models and follow it through to point out some of these problems. We have chosen Reillys <ref> [36] </ref> Ph.D. thesis on believable social and emotional agents, which is the part of the OZ project that concentrated on the emotional and social side of intelligent agents. The model first assessed the event as being desirable or undesirable with respect to the agents goals. <p> A desirable event was defined as an event that causes goal success, while an undesirable event was defined as an event that causes goal failure. The desirability of an event was measured as a true or false concept <ref> [36] </ref>. Ortonys [30] model was used to trigger emotions such as joy, sadness, etc. Emotions were triggered at different intensities. Intensities are degrees, say a number between 1 and 10, that measure the degree of an emotion. The intensity degree was used to map the emotional state to a behavior. <p> The statement implies that if the anger level of the agent a is greater than 0 and the fear value of the agent a is greater than five then the aggressiveness will be a function of both anger and fear <ref> [36] </ref>. However, if anger is greater than 0 and fear is less than 5 then the aggressive value will be a function of anger.
Reference: [37] <author> W. Scott Reilly, </author> <title> A Methodology for Building Believable Social Agents, </title> <booktitle> The First Autonomous Agents Conference, </booktitle> <address> Marina del Rey, CA, </address> <year> 1997 </year>
Reference-contexts: Sixteen emotions were formalized in this form, including relief, distress, disappointment, love, hate and satisfaction [30]. In fact, the model was 25 employed as a computational model by the OZ group, a group working on believable agents at CMU (Carnegie Mellon University) <ref> [4, 5, 38, 36, 37] </ref>. Nevertheless, the model is not complete. As stated earlier the equations are intuitive and seem to capture the process of triggering one emotion really well, but often emotions are triggered in a mixture.
Reference: [38] <author> W. Reilly and Joseph Bates, </author> <title> Building Emotional Agents, </title> <institution> Pittsburgh, PA: Carnegie Mellon University, </institution> <type> Technical Rep. </type> <institution> CMU-CS-92-143, </institution> <year> 1992. </year> <month> 92 </month>
Reference-contexts: Due to the emergence of the believable agents, a number of models simulating the emotional process have been proposed. Two major models evolved out of this area, the OZ project <ref> [3, 4, 5, 36, 38] </ref> at CMU and Simon [51] at MIT. These models follow different agent architectures. These architectures will be detailed along with other models in Chapter II. <p> Sixteen emotions were formalized in this form, including relief, distress, disappointment, love, hate and satisfaction [30]. In fact, the model was 25 employed as a computational model by the OZ group, a group working on believable agents at CMU (Carnegie Mellon University) <ref> [4, 5, 38, 36, 37] </ref>. Nevertheless, the model is not complete. As stated earlier the equations are intuitive and seem to capture the process of triggering one emotion really well, but often emotions are triggered in a mixture. <p> There are two different architectures for intelligent agents: the broad agent architecture and the distributed agent architecture. The broad agent architecture has three important properties: it has a broad set of capabilities, each capability is typically somewhat shallow, and all the capabilities are tightly integrated <ref> [38] </ref>. Thus, we will have an architecture that integrates all the internal states of the agent within it. The other type was based on Brooks subsumption architecture. This 33 architecture consists of a set of distributed agents with no internal states. <p> This 33 architecture consists of a set of distributed agents with no internal states. These agents interact with each other in a way that achieves global intelligence. i. BROAD AGENTS & BELIEVABLE AGENTS J. Bates is building a believable agent (OZ project) <ref> [38, 4, 5] </ref> using the model that was described in The Structure of Emotions by Ortony, Clore and Collins [30]. The aim of the OZ project was to provide the users with the experience of living in dramatically interesting microworlds that include moderately competent emotional agents. <p> Sometimes emotions override the plan and vice versa. The outcome of the plan will then be fed back to the EM model that will then recreate and reevaluate its emotions and actions. This process will then iterate through the lifetime of the agent <ref> [38] </ref>. 34 FIGURE 2. OZ PROJECT ARCHITECTURE Many interesting points were considered in this project; however, there still are some problems. The emotional-behavior mapping process was designed as an interval-based mapping. <p> Thus, identifying the link between an event and the corresponding goals was noted to be a very complex task to accomplish <ref> [38] </ref>. The agent can potentially learn this by using a reinforcement learning algorithm [16, 26]; we will briefly outline one of the reinforcement algorithms, namely the Q-learning algorithm. The reader is referred back to [16, 26] for more detail.
Reference: [39] <author> I. J. Rosman, P. E. Jose, and M. S. Spindel, </author> <title> Appraisals of Emotion-Eliciting Events: Testing a Theory of Discrete Emotions, </title> <journal> Journal of Personality and Social Psychology, </journal> <volume> vol. 59, no. 5, </volume> <pages> pp. 899-915, </pages> <year> 1990. </year>
Reference-contexts: Ortony et al. [30] produced a model of emotions where they defined emotions to be clusters or chunks. For example, there might be five or six different levels of anger, but these levels are all classified under the emotion anger. Rosman et al. <ref> [39] </ref> produced another model of emotions. The model was used to trigger emotions according to events, which were divided into categories according to the cause. These categories include (1) self-caused, (2) other-caused and (3) uncertain-cause events. <p> Therefore, to provide a good model of the emotional concept we have to simulate experience. 5. PROBLEMS IN EMOTIONAL MODELING By the 1980s, several appraisal models of emotions had been formulated. Ortony [30] and Rosman <ref> [39] </ref> tried to solve the problem of the synthesis of the emotional process given the occurrence of certain events. Both of these models formalized some variables that might affect the synthesis of emotions, including expectations, predictions of the 10 occurrence of an event and effort of achieving a goal. <p> In Ortonys [30] model, emotions were defined in terms of rules. For example, joy was defined as the occurrence of a desirable event [30]. In contrast, Rosmans model formalized emotions according to event categories <ref> [39] </ref>. These categories depend on many factors, including the likelihood of the event to occur and the consistency measure of an event in terms of the goals. In addition, he further refined the synthesis process to include self-perception. <p> The researchers used Rosmans <ref> [39] </ref> model to build the event appraisal and emotion triggering process. Essentially, the model monitors the internal states and the environment. The emotional state is periodically updated according to Rosemans rules. <p> As soon as an event is perceived it is passed to the experience model for assessment. The experience model is one of the major contributions of the thesis. Most computational models of emotions have been built using the appraisal models such as Ortony & Collins [30], or Rosman <ref> [39] </ref>. Although these models use internal variables, such as expectations and the level of effort exerted, to produce emotions, the computational models that evolved out of these models (e.g. OZ [4]) did not use experience to trigger these internal variables. <p> Clearly, this model presents only one spectrum of the filtering process. In our attempt to find better solutions, we reviewed other models. 22 B. APPRAISAL MODELS OF EMOTIONS Appraisal models had been developed by the 80s and the early 90s to model emotions in terms of event occurrence <ref> [30, 39] </ref>. In the next couple of sections, we will detail two models that evolved around the 1980s. i. ROSMANS MODEL Rosmans model [39] is illustrated in Table 1. In this model, an emotion is generated according to an event assessment procedure [39]. <p> APPRAISAL MODELS OF EMOTIONS Appraisal models had been developed by the 80s and the early 90s to model emotions in terms of event occurrence [30, 39]. In the next couple of sections, we will detail two models that evolved around the 1980s. i. ROSMANS MODEL Rosmans model <ref> [39] </ref> is illustrated in Table 1. In this model, an emotion is generated according to an event assessment procedure [39]. Events were divided into motive-consistent and motive-inconsistent events. Motive-consistent events were defined as events that are consistent with one of the subjects goals. <p> In the next couple of sections, we will detail two models that evolved around the 1980s. i. ROSMANS MODEL Rosmans model <ref> [39] </ref> is illustrated in Table 1. In this model, an emotion is generated according to an event assessment procedure [39]. Events were divided into motive-consistent and motive-inconsistent events. Motive-consistent events were defined as events that are consistent with one of the subjects goals. On the other hand, a motive inconsistent event denoted an event that threatens one of the subjects goals. <p> However, if the same situation occurred and the subject regarded him/herself as strong, then frustration would be the emotion triggered (as shown in the table) <ref> [39] </ref>. This model, like most of the event appraisal models of emotion, is still not complete. The model did not formulate a method by which the categorization processes of events are calculated or measured. Calculating a probability factor of the occurrence of certain events still represents a big challenge. <p> This fact uncovered an important limitation in the emotion event appraisal models. ii. ORTONY, COLLINS AND CLORES MODEL Ortony et al. [30] developed another model that was quite similar to Rosmans model <ref> [39] </ref>. They divided goals into three types: Agoals, which were defined as implicit goals or preconditions to a higher-level I-goal; I-goals, which were defined as implicit goals such as life preservation, well being, etc.; and R-goals, which were defined as explicit and short-term goals such as food, sleep, water, etc. <p> Fuzzy implication rules are used to determine a desirability measure of the event according to these two criteria. The desirability measure, once calculated, will be passed to an appraisal model to further determine the emotional state of the agent. The model uses a combination of Ortony [30] and Rosmans <ref> [39] </ref> models to trigger emotions. An emotion or a mixture of emotions will be triggered using the event desirability measure. The mixture will then be filtered to produce an emotional state. The filtering process uses a variation of Bolles and Fanslows [6] model to produce a coherent mixture of emotions.
Reference: [40] <author> Stuart Russel and Peter Norvig, </author> <title> Artificial Intelligence A Modern Approach, Upper Saddle River, </title> <address> NJ: </address> <publisher> Prentice-Hall Inc., </publisher> <year> 1995. </year>
Reference: [41] <author> K. R. Scherer, </author> <title> Studying the Emotion Antecedent Appraisal Process: An Expert System Approach, </title> <journal> Cognition and Emotion, </journal> <volume> vol. 7, </volume> <pages> pp. 325-55, </pages> <year> 1993. </year>
Reference-contexts: It should be noted that these models simulate fourteen or fewer emotions. Thus, more variables might be required if totally different or new emotions are added to the model. An implementation of an expert system followed these models to further extend the number of variables involved <ref> [41] </ref>. The list of variables include goal significance (concern relevance, outcome probability, expectation, conductiveness, urgency), novelty (suddenness, familiarity, predictability) and intrinsic pleasantness [41]. However, questions about the quantity and identity of the variables involved in the emotional process are still open. <p> An implementation of an expert system followed these models to further extend the number of variables involved <ref> [41] </ref>. The list of variables include goal significance (concern relevance, outcome probability, expectation, conductiveness, urgency), novelty (suddenness, familiarity, predictability) and intrinsic pleasantness [41]. However, questions about the quantity and identity of the variables involved in the emotional process are still open. These models consider only a subset of the emotional process. For example, it is clear that at a given moment different emotions may be triggered with different intensities. <p> They did not show how the level of frustration was actually measured or calculated. Nevertheless, the system, as we understand it, illustrates a use of emotions in a multi-robot application. 28 B. MACHINE LEARNING IN EMOTIONS An expert system was developed by K. Scherer <ref> [41] </ref> to develop a computer program that would allow a user to enter information on a situation in which a strong emotion had been experienced and have the program predict or diagnose the nature of that emotional state [41]. According to Scherer, the emotional appraisal occurred in an invariant sequence. <p> Scherer <ref> [41] </ref> to develop a computer program that would allow a user to enter information on a situation in which a strong emotion had been experienced and have the program predict or diagnose the nature of that emotional state [41]. According to Scherer, the emotional appraisal occurred in an invariant sequence. Thus, the appraisal process was constantly operative with evaluations being continuously performed to update the subjects information on an event. Scherer developed a predictive vector for 14 different emotions. <p> The table shows, over ten variables that can elicit different emotions. Actually the table only provides some of the features that were selected for emotion prediction. For more information about the model and about the predictive vector used the reader is referred to <ref> [41] </ref>. <p> for the future? (0) not pertinent (1) the event had happened a long time ago (2) it happened in the recent past (3) it had just happened at that moment (4) it was to be expected for the near future (5) it was to be expected in the long run <ref> [41] </ref>. 29 TABLE 2.
Reference: [42] <author> R. Schumacher and M. Velden, Anxiety, </author> <title> Pain Experience and Pain Report: A Signal-detection Study, Perceptual and Motor Skills, </title> <journal> vol. </journal> <volume> 58, </volume> <pages> pp. 339-349, </pages> <year> 1984. </year>
Reference-contexts: MOTIVATIONAL STATES Models of motivational states, including pain, hunger and thirst were explored in varies areas in psychology and neurology. A model of pain was developed by R. Schumacher and M. Velden <ref> [42] </ref>. However, most of these models tend to formulate the motivational states into a pure physiological reaction, and thus the impact that these motivational states have on other states such as the emotional states was not conceived.
Reference: [43] <author> T. Shibata, K. Inoue, and Robert Irie, </author> <title> Emotional Robot for Intelligent System - Artificial Emotional Creature Project, </title> <booktitle> IEEE Int. Workshop on Robot and Human Communication, </booktitle> <address> Tokyo, Japan, </address> <pages> pp. 466-471, </pages> <year> 1996. </year>
Reference: [44] <author> T. Shibata, K. Ohkawa, and K. Tanie, </author> <title> Spontaneous Behavior of Robots for Cooperation Emotionally Intelligent Robot System, </title> <booktitle> Proc. of IEEE Int. Conf. on Robotics and Automation, </booktitle> <address> Tokyo, Japan, </address> <pages> pp. 2426-2431, </pages> <year> 1996. </year>
Reference-contexts: Software agents may use an emotion as a fitness function or an evaluation criterion for cooperation and coordination of certain tasks between multiple agents. In fact, emotion was used to help in the communication process of robots that collaborate on a certain task <ref> [44] </ref>. This particular application will be discussed in more detail in Chapter II. Believable agents heavily rely on emotions to create believable responses. Believable agents were defined to be agents that create the illusion of life [3, 36]. The concept of believability is often used in theater. <p> This concept is true in some cases. However, the emotional process is a much more complex concept than what was presented in the paper. Another system was developed not to model emotions, but rather it was developed to use some emotions for robot cooperation and collaboration <ref> [44] </ref>. A certain task was divided among a set of robots. Each robot initially had a set of strategies that it could employ. At any given time, the robot would test the situation and then it would choose a strategy that represented a best fit to the given situation. <p> In agent research, simulating emotions was proven to lead an important role in believable agents, interface agents and software agents. In software agents and robotics, models of emotions were developed to enhance the cooperation and collaboration between agents to carry out specific tasks <ref> [44] </ref>. Models of believable agents were developed using two main architectures. One of which, is the broad agent architecture that constitutes a big model, which includes several internal states [4]. These internal states are evaluated and an action evolves according to the resulting emotional state.
Reference: [45] <author> T. Shiida, </author> <title> An Attempt to Model Emotions on a Machine, Emotion and Behavior: </title>
References-found: 45

