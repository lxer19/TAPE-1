URL: ftp://ftp.cs.washington.edu/tr/1995/08/UW-CSE-95-08-02.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-title.html
Root-URL: 
Author: Rakesh Kumar Sinha 
Date: 1995  
Note: c Copyright  
Abstract-found: 0
Intro-found: 1
Reference: [Abr90] <author> Karl R. Abrahamson. </author> <title> A time-space tradeoff for Boolean matrix multiplication. </title> <booktitle> In Proceedings 31st Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 412-419, </pages> <address> St. Louis, MO, </address> <month> October </month> <year> 1990. </year> <note> IEEE. </note>
Reference-contexts: If each input variable comes from a domain of size R, then in the ensuing model each non-sink node has R outgoing edges. The model was introduced by Borodin and Cook [BC82] and has been subject to extensive studies ( for example, <ref> [Abr91, Abr90, Bea91] </ref>). 18 2.2 Some Basic Results 2.2.1 Time-Space Trade-off Results Because of their ability to model both space and time, branching programs and their many variants have been particularly useful in proving many time-space trade-off results.
Reference: [Abr91] <author> Karl R. Abrahamson. </author> <title> Time-space tradeoffs for algebraic problems on general sequential models. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 43(2) </volume> <pages> 269-289, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: If each input variable comes from a domain of size R, then in the ensuing model each non-sink node has R outgoing edges. The model was introduced by Borodin and Cook [BC82] and has been subject to extensive studies ( for example, <ref> [Abr91, Abr90, Bea91] </ref>). 18 2.2 Some Basic Results 2.2.1 Time-Space Trade-off Results Because of their ability to model both space and time, branching programs and their many variants have been particularly useful in proving many time-space trade-off results.
Reference: [Ajt83] <author> Miklos Ajtai. </author> <title> 1 1 -formulae on finite structures. </title> <journal> Annals of Pure and Applied Logic, </journal> <volume> 24 </volume> <pages> 1-48, </pages> <year> 1983. </year>
Reference-contexts: Using the known lower bounds on parity <ref> [H-as87, FSS81, Yao85, Ajt83] </ref>, they managed to prove a non-constant time lower bound for the problem of computing parity on PRAMs with polynomial number of processors.
Reference: [AM88] <author> Noga Alon and Wolfgang Maass. </author> <title> Meanders and their applications in lower bounds arguments. </title> <journal> Journal of Computer and System Sci ences, </journal> <volume> 37 </volume> <pages> 118-129, </pages> <year> 1988. </year>
Reference-contexts: For the class of non-constant threshold functions, Barrington and Straubing [BS91], using algebraic techniques, improved this bound to (n log log n). Alon and Maass <ref> [AM88] </ref> and Babai et al. [BPRS90] independently proved that any oblivious branching program of width w p for majority has length ( n log n log w ). <p> We will give some 23 intuition on this result in the next subsection. 3.1.2 Communication Complexity Technique Some of the best known lower bound results on branching programs (including <ref> [AM88] </ref> and [BPRS90]) are based on communication complexity. Informally, communication complexity measures the amount of communication needed to compute the given function when two parties are each given half of the input. <p> The heart of <ref> [AM88, BPRS90] </ref> is a Ramsey like theorem which states that given any oblivious branching program, there is a restriction that leaves a significant portion of the variables unset and results in a branching program with a structure similar to what we have described above. 25 Theorem 3.4 [AM88, BPRS90] For any <p> The heart of <ref> [AM88, BPRS90] </ref> is a Ramsey like theorem which states that given any oblivious branching program, there is a restriction that leaves a significant portion of the variables unset and results in a branching program with a structure similar to what we have described above. 25 Theorem 3.4 [AM88, BPRS90] For any function f , and any m n, let C f (m) denote the maximum worst-partition communication complexity of f under a restriction that leaves m variables unset (the maximum is taken over the set of restrictions). <p> For width log n w n, the length of the resulting branching program is O n log 2 n , which is within O log log log n of the length lower bound of <ref> [AM88, BPRS90] </ref> (see Corollary 3.6). Our constructions are a generalization of Lupanov's construction for computing majority [Lup65]. Both of our constructions have other nice properties. <p> To complete the proof of the theorem, notice that the integers reaching the input node specified in Claim 3 are going to reach different output nodes of the p k -box. 2 Constant width branching programs present an interesting challenge. The length lower bound on oblivious branching programs in <ref> [AM88, BPRS90] </ref> (Corollary 3.6) also applies to the function E n=2 and is tight for width w 2 (log n) (by choosing primes of size fi (w) in the proof of Proposition 3.13), but there is a relatively large gap between lower and upper bounds for width w 2 o (log <p> Open problem: Construct a simple branching program of polynomial size and width o (log n) for computing majority. Open problem: Can the length lower bound in <ref> [AM88, BPRS90] </ref> be improved for width w 2 o (log n)? Chapter 4 CREW PRAMS VERSUS EREW PRAMS 4.1 Introduction Parallel random access machines (PRAMs) have been the model of choice for de scribing parallel algorithms on shared memory machines.
Reference: [Aza92] <author> Yossi Azar. </author> <title> Lower bounds for threshold and symmetric functions in parallel computation. </title> <journal> SIAM Journal on Computing, </journal> <volume> 21(2):329 338, </volume> <month> April </month> <year> 1992. </year>
Reference-contexts: Beame [Bea86], by considering a different measure, granularity, proved a stronger ( q m ) lower bound on the OR function. Azar <ref> [Aza92] </ref> analyzed the threshold function Th k on priority CRCW PRAM (m) with a polynomial number of processors. He proved a lower bound of m for the case k n 1=2* and a lower bound of m for k n 1=2* , where * is any number greater than zero.
Reference: [Bar89] <author> David A. </author> <title> Mix Barrington. Bounded-width polynomial-size branching programs recognize exactly those languages in NC 1 . Journal of Computer and System Sciences, </title> <booktitle> 38 </booktitle> <pages> 150-164, </pages> <year> 1989. </year>
Reference-contexts: The lower bound results of Borodin et al. [BDFP86] and Yao [Yao83], described earlier, were seen as steps leading to a proof of super-polynomial lower bound on the length of constant width branching programs computing majority. Barrington <ref> [Bar89] </ref>, in a very surprising result, proved that there are polynomial size branching programs of width five for computing majority. In fact, his result is much more general and applies to all functions computable by fan-in two Boolean circuits of logarithmic depth (which includes all symmetric functions). Theorem 3.7 [Bar89] For <p> Barrington <ref> [Bar89] </ref>, in a very surprising result, proved that there are polynomial size branching programs of width five for computing majority. In fact, his result is much more general and applies to all functions computable by fan-in two Boolean circuits of logarithmic depth (which includes all symmetric functions). Theorem 3.7 [Bar89] For any function s (n) which is at least polynomial, constant width branching programs of size s (n) O (1) compute exactly the same class of functions as fan-in 2 Boolean circuits of depth O (log s (n)). An efficient simulation of branching programs by circuits was already known. <p> An efficient simulation of branching programs by circuits was already known. Bar-rington <ref> [Bar89] </ref> proved that a Boolean circuit of depth d can be simulated by a branching program of width five and size d4 d . He considered a restricted class of branching programs which can be thought of as computing permutations. <p> It is quite possible that the most efficient constructions for symmetric functions do not follow this pattern. We already know of constructions (for example, Barrington <ref> [Bar89] </ref>; also see the discussion following Corollary 3.41) that can not be translated to MA-programs. For computing majority, E n=2 , or mod 0;b p nc . the best size lower bound is n log n [BPRS90], which translates to a size lower bound of log log n on MA-programs. <p> Concentrating on constant width branching programs will force us to look beyond MA-programs, hopefully resulting in yet another general technique for computing symmetric functions. We already know of polynomial size constant width branching programs for computing majority. But all such constructions are based on Barrington's construction <ref> [Bar89] </ref>, which is indirect in nature as it starts from a Boolean formula and constructs an equivalent branching program. To the best of my knowledge, the resulting branching programs for specific functions (like majority) have no easy description.
Reference: [Bat80] <author> K.E. Batcher. </author> <title> Design of a massively parallel processor. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-29:836-840, </volume> <year> 1980. </year>
Reference-contexts: The MPP of Goodyear and NASA is an example of a full-bus two-dimensional mesh computer <ref> [Bat80] </ref>. Full-bus meshes are generally less powerful than sub-bus meshes: Both PARITY and finding the minimum of input vales requires (p ff ) time for some ff &gt; 0 on full-bus meshes [BNP91, PKR87].
Reference: [BC82] <author> Allan Borodin and Stephen A. Cook. </author> <title> A time-space tradeoff for sorting on a general sequential model of computation. </title> <journal> SIAM Journal on Computing, </journal> <volume> 11(2) </volume> <pages> 287-297, </pages> <month> May </month> <year> 1982. </year> <month> 114 </month>
Reference-contexts: All reasonable definitions of space on the logarithmic cost RAM model satisfy this property. Proposition 2.3 (Borodin and Cook <ref> [BC82] </ref>) The time and space complexity of any Boolean function on the branching program model is at most (up to a constant multiplicative factor) its time and space complexity on the logarithmic cost RAM model. <p> If each input variable comes from a domain of size R, then in the ensuing model each non-sink node has R outgoing edges. The model was introduced by Borodin and Cook <ref> [BC82] </ref> and has been subject to extensive studies ( for example, [Abr91, Abr90, Bea91]). 18 2.2 Some Basic Results 2.2.1 Time-Space Trade-off Results Because of their ability to model both space and time, branching programs and their many variants have been particularly useful in proving many time-space trade-off results.
Reference: [BC94] <author> R. E. Bryant and Y. Chen. </author> <title> Verification of arithmetic functions with binary moment diagrams. </title> <type> Technical Report CS-94-160, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <year> 1994. </year>
Reference-contexts: For many functions, no efficient representation with OBDDs is possible. Building on the success of OBDDs, researchers have tried either to define other models which are similar to OBDDs (see e.g. Bryant and Chen <ref> [BC94] </ref>) or to relax some of the restrictions of the OBDDs to allow more efficient representations while still retaining the ease of manipulation (see the discussion at the end of [Bry92]). 2.1.3 Restrictions and Extensions of the Branching Program Model We now discuss some variants of the branching program model.
Reference: [BCL + 94] <author> Jerry R. Burch, Edmund M. Clarke, David E. Long, Kenneth L. McMillan, and David L. Dill. </author> <title> Symbolic model checking for sequential circuit verification. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits, </journal> <volume> 13(4) </volume> <pages> 401-424, </pages> <year> 1994. </year>
Reference-contexts: OBDDs seem to have a good balance: they provide compact representation for many functions arising in practice and at the same time, they can be manipulated very efficiently. They have been extensively used in the design, verification, and testing of digital systems (see e.g. Bryant [Bry92], Burch et al. <ref> [BCL + 94] </ref>). In order to make these systems efficient, the size of the representation has to be minimized. For many functions, no efficient representation with OBDDs is possible. Building on the success of OBDDs, researchers have tried either to define other models which are similar to OBDDs (see e.g.
Reference: [BDFP86] <author> A. Borodin, D. Dolev, F. Fich, and W. Paul. </author> <title> Bounds for width two branching programs. </title> <journal> SIAM Journal on Computing, </journal> <volume> 15 </volume> <pages> 549-560, </pages> <year> 1986. </year>
Reference-contexts: The hope is that the insight gained might eventually be of use in attacking the general model. 3.1.1 Constant Width Branching Programs For the case of width two branching programs, Borodin et al. <ref> [BDFP86] </ref> proved an n 2 length lower bound for computing the majority function. Yao [Yao83] improved this to a super-polynomial lower bound. Shearer (unpublished) proved an exponential lower bound for the problem of checking whether the number of 1's in the input is a multiple of three. <p> For a long time it was widely believed that any constant width branching program for computing majority must have super-polynomial length. The lower bound results of Borodin et al. <ref> [BDFP86] </ref> and Yao [Yao83], described earlier, were seen as steps leading to a proof of super-polynomial lower bound on the length of constant width branching programs computing majority. Barrington [Bar89], in a very surprising result, proved that there are polynomial size branching programs of width five for computing majority.
Reference: [Bea86] <author> Paul W. Beame. </author> <title> Lower Bounds in Parallel Machine Computation. </title> <type> PhD thesis, </type> <institution> University of Toronto, 1986. Department of Computer Science Technical Report 198/87. </institution>
Reference-contexts: Their results imply an ( q n=m) lower bound on the problem of computing the PARITY of n bits and an m lower bound on the complexity of the OR function. Beame <ref> [Bea86] </ref>, by considering a different measure, granularity, proved a stronger ( q m ) lower bound on the OR function. Azar [Aza92] analyzed the threshold function Th k on priority CRCW PRAM (m) with a polynomial number of processors. <p> Our hope is that some of the techniques developed for small communication widths will turn out to be useful even for the general case. For example, the technique in the lower bound result for the OR function on CREW (1) PRAMs <ref> [VW85, Bea86] </ref> is very similar to the technique that Kuty lowski [Kut91] eventually used in his optimal bound for the OR on general CREW PRAMs. Our lower bound proof consists of three parts. <p> Since shared memory is the only means of communication, we can assume that for any PRAM running for t steps, only the processors that 65 write by time t are involved in the computation. The bounds in <ref> [Bea86] </ref> (see also [VW85]) show that for any CREW (1) PRAM at time t and for any given input vector e, at least a 2 O (t 2 ) fraction of all inputs vectors are indistinguishable from e, from the point of view of any individual processor. <p> There is at least some precedence for this: Kuty lowski's [Kut91] optimal lower bound for general CREW PRAMs, computing the OR function, uses techniques similar to the lower bound result, for the OR function, on CREW (1) PRAMs <ref> [VW85, Bea86] </ref>.
Reference: [Bea91] <author> Paul W. Beame. </author> <title> A general time-space tradeoff for finding unique elements. </title> <journal> SIAM Journal on Computing, </journal> <volume> 20(2) </volume> <pages> 270-277, </pages> <year> 1991. </year>
Reference-contexts: If each input variable comes from a domain of size R, then in the ensuing model each non-sink node has R outgoing edges. The model was introduced by Borodin and Cook [BC82] and has been subject to extensive studies ( for example, <ref> [Abr91, Abr90, Bea91] </ref>). 18 2.2 Some Basic Results 2.2.1 Time-Space Trade-off Results Because of their ability to model both space and time, branching programs and their many variants have been particularly useful in proving many time-space trade-off results.
Reference: [Bel91] <author> S. Bellantoni. </author> <title> Parallel random access machines with bounded memory wordsize. </title> <journal> Information and Computation, </journal> <volume> 91 </volume> <pages> 259-273, </pages> <year> 1991. </year>
Reference-contexts: Bellantoni <ref> [Bel91] </ref> showed a simulation of restricted word-sized PRIORITY CRCW PRAMs by unbounded fan-in circuits. We extend his result and the techniques are very similar although there are some significant differences in the details required to handle multiprefix operations. <p> For the case of limited word-size, Bellantoni gave a simulation of PRAMs by unbounded fan-in circuits, without any restriction on the computational power of individual processors of PRAMs. Theorem 5.7 (Bellantoni <ref> [Bel91] </ref>) A priority CRCW PRAM with word-size and p processors running in time T can be simulated by an unbounded fan-in circuits of depth O (T ) and size 2 O (T ) p O (1) . <p> Following the model of Bellantoni <ref> [Bel91] </ref> in our simulation, we initially assume that we do not have to worry about simulating memory. This motivates the following definition. <p> Proof: The essential idea of this proof follows that of Bellantoni <ref> [Bel91] </ref> but there are some additional complications due to the multiprefix phase.
Reference: [BFK + 81] <author> Allan Borodin, Michael J. Fischer, David G. Kirkpatrick, Nancy A. Lynch, and Martin Tompa. </author> <title> A time-space tradeoff for sorting on non-oblivious machines. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 22(3) </volume> <pages> 351-364, </pages> <month> June </month> <year> 1981. </year>
Reference-contexts: Pippenger has shown an easy way of converting any such general branching program of size s and length ` into a leveled branching program of size (` + 1)s and the same length ` (details are given in Borodin et al. <ref> [BFK + 81] </ref>). Pippenger's transformation makes ` + 1 copies of each node in the original branching program and connects them in a way such that the ith node on any semantic path is the ith copy of some node in the original branching program.
Reference: [BFMadH + 87] <author> Allan Borodin, Faith E. Fich, Friedhelm Meyer auf der Heide, Eli Upfal, and Avi Wigderson. </author> <title> A time-space tradeoff for element distinctness. </title> <journal> SIAM Journal on Computing, </journal> <volume> 16(1) </volume> <pages> 97-99, </pages> <month> February </month> <year> 1987. </year>
Reference: [BFS] <author> P. Beame, F. Fich, and R. Sinha. </author> <title> Separating the power of EREW and CREW PRAMs with small communication width. </title> <journal> Information and Computation. </journal> <note> To appear. 115 </note>
Reference: [BGS75] <author> T. P. Baker, J. Gill, and R. Solovay. </author> <title> Relativizations of the P =?NP question. </title> <journal> SIAM Journal on Computing, </journal> <volume> 4 </volume> <pages> 431-442, </pages> <year> 1975. </year>
Reference-contexts: We first outline the difficulties with the Turing machine model. A series of relativization results have shown that most of the known lower bound techniques on Turing machines are not powerful enough to prove strong lower bounds (see e.g. Baker, Gill, and Solovay <ref> [BGS75] </ref>). An even more serious concern is that Turing machines access their memory in sequential order. Because all real machines have random access, a lower bound proved on Turing machines that relies crucially on the sequential access feature may not say anything meaningful about resource requirements on real machines.
Reference: [BH89] <author> Paul W. Beame and J. H-astad. </author> <title> Optimal bounds for decision problems on the CRCW PRAM. </title> <journal> Journal of the ACM, </journal> <volume> 36(3) </volume> <pages> 643-670, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Nisan [Nis91] gave several characterizations of complexity of any function on 59 CREW PRAMs in terms of these measures. Beame and H-astad <ref> [BH89] </ref>, in a very important breakthrough, proved optimal log n bounds for computing the parity of n bits on a priority CRCW PRAM for the case when either the number of processors or the number of shared memory cells is bounded by a polynomial. <p> The 80 danger of having very powerful primitives is that for certain problems, this two step simulation process may be lot more expensive than a direct simulation in hardware. For example, Beame and H-astad <ref> [BH89] </ref> have shown that the parity function, which can be solved on realistic machines in essentially the same time as a multiprocessor read or write, requires (log n= log log n) time on a PRIORITY CRCW PRAM. <p> Using the known lower bounds on parity [H-as87, FSS81, Yao85, Ajt83], they managed to prove a non-constant time lower bound for the problem of computing parity on PRAMs with polynomial number of processors. By completely different techniques, Beame and H-astad <ref> [BH89] </ref> proved an optimal lower bound without placing restriction on the instruction set of individual processors of CRCW PRAMs. For the case of limited word-size, Bellantoni gave a simulation of PRAMs by unbounded fan-in circuits, without any restriction on the computational power of individual processors of PRAMs. <p> In the case of PRIORITY CRCW PRAMs, lower bounds for unbounded fan-in circuits [H-as87] provided the pattern for PRAM lower bounds <ref> [BH89] </ref>. What we demonstrate is that for natural restrictions of multiprefix PRAM word-length, bounds for circuits with prefix operations directly translate into bounds for the multiprefix PRAM. <p> Proof: It was shown in [CLLS] that a priority CRCW PRAM can simulate a sub-bus mesh computer to within a constant factor of the time and within a polynomial number of processors. Since Beame and H-astad <ref> [BH89] </ref> have proved a lower bound of time log log p on the time to compute SUM on a priority CRCW PRAM with a polynomial number of processors, a similar lower bound follows for the case of sub-bus mesh. 2 There is a trivial algorithm (Proposition 6.4) to compute any associative
Reference: [BIS90] <author> David A. Mix Barrington, Neil Immerman, and Howard Straub-ing. </author> <title> On uniformity within NC 1 . Journal of Computer and System Sciences, </title> <booktitle> 41(3) </booktitle> <pages> 274-306, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: If preprocessing is not allowed, q-parity can be computed in uniform NC 1 <ref> [BIS90] </ref> (details are given in [CLLS]). A parallel instruction issued by the front-end has the form "if &lt;condition&gt; then &lt;statement&gt;." Each processor evaluates the condition, which can be any sequence of non-branching operations which evaluates to a Boolean value.
Reference: [Bla90] <author> T. Blank. </author> <title> The MasPar MP-1 architecture. </title> <booktitle> In COMPCON Spring 90 The Thirty-Fifth IEEE Computer Society International Conference, </booktitle> <pages> pages 20-24, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: The model has several variants which have all been the subject of extensive study [HS86, Lei92, LS91, MS89, MPKRS93, RPK88, Sto86]. We will focus on the sub-bus mesh model, which has been implemented on the commercially available MasPar MP-1 <ref> [Bla90] </ref>. A sub-bus mesh is a single-instruction multiple-data (SIMD) two-dimensional array of processors. An m 1 fi m 2 sub-bus mesh has a processor placed at every grid point of a mesh with m 1 rows and m 2 columns. <p> length in constant time, then using the technique of Theorem 6.2, the sum of p integers of length 2 O ( p log p= log log p) can be computed in time O log log p . 6.3 Conclusion Because machines based on the sub-bus mesh model are commercially available <ref> [Bla90] </ref>, this model deserves further study. We gave an optimal algorithm for computing the SUM function, but it is unsatisfactory on two counts: First, the algorithm is complicated and the speed-up by a factor of fi (log log p) has too large a constant factor to be significant.
Reference: [Ble89] <author> Guy E. Blelloch. </author> <title> Scans as primitive parallel operations. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(11) </volume> <pages> 1526-1538, </pages> <year> 1989. </year>
Reference-contexts: Some practical and theoretical works for parallel machines <ref> [Ble89, Ble90, CBZ90, KRS86, RBJ88, PS88, KRS88] </ref> have suggested that multiprefix operations for certain multiary operators be allowed at unit cost. We will call all such models multiprefix PRAMs. Later we will give a precise definition of multiprefix operations and multiprefix PRAMs. <p> In the implementation of the CRCW PRAM on the NYU Ultracomputer, a number of additional operations such as Fetch-and-add were included [GGKR83]. These operations used the combining network to perform computation during a concurrent memory access and were used as synchronization primitives. Blelloch <ref> [Ble89] </ref> considered scan operations, where all processors are restricted to be in the same group. He also considered segmented scans where every group consists of processors with consecutive processor indices, and all processors perform multiprefix operation based on the same multiary operator. Blel-loch [Ble89] showed that scan primitives for integer-add, integer-max, <p> Blelloch <ref> [Ble89] </ref> considered scan operations, where all processors are restricted to be in the same group. He also considered segmented scans where every group consists of processors with consecutive processor indices, and all processors perform multiprefix operation based on the same multiary operator. Blel-loch [Ble89] showed that scan primitives for integer-add, integer-max, integer-min, 81 OR, and AND can be implemented as efficiently as reads and writes on a connection machine [Hil85]. He gives many examples where these primitives reduce the running time, sometimes by as much as a factor of fi (log n).
Reference: [Ble90] <author> Guy E. Blelloch. </author> <title> Vector Models for Data-Parallel Computing. </title> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Some practical and theoretical works for parallel machines <ref> [Ble89, Ble90, CBZ90, KRS86, RBJ88, PS88, KRS88] </ref> have suggested that multiprefix operations for certain multiary operators be allowed at unit cost. We will call all such models multiprefix PRAMs. Later we will give a precise definition of multiprefix operations and multiprefix PRAMs. <p> Chatterjee et al. [CBZ90] discuss implementation of scan operations on a CRAY Y-MP [Cra88]. Again the scan primitives turn out to be very powerful, even for the normally hard case of manipulating irregular and dynamically changing structures. The appendix in Blelloch's Ph.D. thesis <ref> [Ble90] </ref> gives a brief history of the scan operation. Ranade et al. [RBJ88] consider a generalization of the scan operation, where arbitrary partitioning of processors is allowed. The authors give strong justification for an architecture providing these primitives.
Reference: [Blu84] <author> N. Blum. </author> <title> A Boolean function requiring 3n network size. </title> <journal> Theoretical Computer Science, </journal> <volume> 28 </volume> <pages> 337-345, </pages> <year> 1984. </year>
Reference-contexts: Since there is no natural association of nodes and input variables in circuits, this technique has not yet been extended to the case of circuits. We remind the reader that the best unconditional size lower bound for circuits computing a function in NP is less than 3n <ref> [Blu84] </ref>; a circuit size lower bound of log 2 n would amount to a complexity breakthrough. Chapter 3 SYMMETRIC FUNCTIONS ON BRANCHING PROGRAMS Symmetric functions are a class of Boolean functions that depend only on the number of 1's in the input.
Reference: [BNP91] <author> A. Bar-Noy and D. Peleg. </author> <title> Square meshes are not always optimal. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40 </volume> <pages> 138-147, </pages> <year> 1991. </year>
Reference-contexts: The MPP of Goodyear and NASA is an example of a full-bus two-dimensional mesh computer [Bat80]. Full-bus meshes are generally less powerful than sub-bus meshes: Both PARITY and finding the minimum of input vales requires (p ff ) time for some ff &gt; 0 on full-bus meshes <ref> [BNP91, PKR87] </ref>. Second, there is the reconfigurable mesh, in which every processor connects to the busses by 4 ports (N, S, E, W) - 3 for processors on the sides; 2 for processors in the corners.
Reference: [Bop89] <author> Ravi B. Boppana. </author> <title> Optimal separations between concurrent-write parallel machines. </title> <booktitle> In Proceedings of the Twenty-First Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 320-326, </pages> <address> Seattle, WA, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: On the other hand, a separation result gives at least a partial justification for providing the set of primitives available on the stronger model because certain problems are provably more efficient in the presence of those primitives. 61 Boppana <ref> [Bop89] </ref> proved that given n integers, determining whether they are all distinct requires at least A (n; p) time on a common CRCW PRAM with p n processors, where A (n; p) = p log n log n : Because this problem has an O (1) time algorithm on a priority
Reference: [Bor93] <author> Allan Borodin. </author> <title> Time space tradeoffs (getting closer to the barrier?). </title> <booktitle> In 4th International Symposium on Algorithms and Computation, </booktitle> <pages> pages 209-229, </pages> <address> Hong Kong, </address> <month> December </month> <year> 1993. </year> <month> 116 </month>
Reference-contexts: That is, for solving certain problems, it has been shown that both time and space can not be limited at the same time [Abr91, Abr90, Bea91, BC82, BFK + 81, Yao88, BFMadH + 87, MNT90, PSP93] (also see Borodin's excellent survey article <ref> [Bor93] </ref>). Unlike Turing machines, branching programs allow random access of inputs, so that lower bounds proved on the branching program model provide a strong guarantee of the difficulty of problems on real machines. The general proof technique is to define some notion of "progress" towards computing a given function.
Reference: [BPRS90] <author> Laszlo Babai, Pavel Pudlak, V. Rodl, and Endre Szemeredi. </author> <title> Lower bounds to the complexity of symmetric Boolean functions. </title> <journal> Theoretical Computer Science, </journal> <volume> 74 </volume> <pages> 313-324, </pages> <year> 1990. </year>
Reference-contexts: For the class of non-constant threshold functions, Barrington and Straubing [BS91], using algebraic techniques, improved this bound to (n log log n). Alon and Maass [AM88] and Babai et al. <ref> [BPRS90] </ref> independently proved that any oblivious branching program of width w p for majority has length ( n log n log w ). <p> We will give some 23 intuition on this result in the next subsection. 3.1.2 Communication Complexity Technique Some of the best known lower bound results on branching programs (including [AM88] and <ref> [BPRS90] </ref>) are based on communication complexity. Informally, communication complexity measures the amount of communication needed to compute the given function when two parties are each given half of the input. <p> This protocol exchanges only log m bits where P has m nodes. Because C &gt; log m, P has at least 2 C nodes. 2 To give some intuition on the length lower bound on the oblivious branching program ([AM88] and <ref> [BPRS90] </ref>), consider the simpler case of proving lower bound on an oblivious branching program P with the following restriction: If the length of P is nfl then the levels can be divided into fl groups of consecutive levels such that all the odd numbered groups of levels (first, third, fifth etc.) <p> The heart of <ref> [AM88, BPRS90] </ref> is a Ramsey like theorem which states that given any oblivious branching program, there is a restriction that leaves a significant portion of the variables unset and results in a branching program with a structure similar to what we have described above. 25 Theorem 3.4 [AM88, BPRS90] For any <p> The heart of <ref> [AM88, BPRS90] </ref> is a Ramsey like theorem which states that given any oblivious branching program, there is a restriction that leaves a significant portion of the variables unset and results in a branching program with a structure similar to what we have described above. 25 Theorem 3.4 [AM88, BPRS90] For any function f , and any m n, let C f (m) denote the maximum worst-partition communication complexity of f under a restriction that leaves m variables unset (the maximum is taken over the set of restrictions). <p> For the case of arbitrary branching programs, Pudlak [Pud84] used a Ramsey theoretic argument to prove an unconditional size lower bound of log log log n for computing most threshold functions (including majority). Babai et al. <ref> [BPRS90] </ref> improved this to an unconditional size lower bound of log log n for computing majority. This bound is a generalization of Theorem 3.4 and also applies to almost all symmetric functions. Theorem 3.5 [BPRS90] For any function f , and any m n, let C f (m) denote the maximum <p> Babai et al. <ref> [BPRS90] </ref> improved this to an unconditional size lower bound of log log n for computing majority. This bound is a generalization of Theorem 3.4 and also applies to almost all symmetric functions. Theorem 3.5 [BPRS90] For any function f , and any m n, let C f (m) denote the maximum worst-partition communication complexity of f under a restriction that sets exactly n m variables to zero (the maximum is taken over the set of restrictions). <p> Theorem 3.24 There is an oblivious branching program of size O n log 4 n ! for computing any mod function on n inputs. For the case of threshold functions, the size bound is within O log log log n of the size lower bound of Babai et al. <ref> [BPRS90] </ref> (see Corollary 3.6). Our method also yields a spectrum of branching programs, one for each width greater than log n. <p> For width log n w n, the length of the resulting branching program is O n log 2 n , which is within O log log log n of the length lower bound of <ref> [AM88, BPRS90] </ref> (see Corollary 3.6). Our constructions are a generalization of Lupanov's construction for computing majority [Lup65]. Both of our constructions have other nice properties. <p> We already know of constructions (for example, Barrington [Bar89]; also see the discussion following Corollary 3.41) that can not be translated to MA-programs. For computing majority, E n=2 , or mod 0;b p nc . the best size lower bound is n log n <ref> [BPRS90] </ref>, which translates to a size lower bound of log log n on MA-programs. The proof is non-trivial and uses a very nice Ramsey theoretic lemma (Theorem 3.5). <p> To complete the proof of the theorem, notice that the integers reaching the input node specified in Claim 3 are going to reach different output nodes of the p k -box. 2 Constant width branching programs present an interesting challenge. The length lower bound on oblivious branching programs in <ref> [AM88, BPRS90] </ref> (Corollary 3.6) also applies to the function E n=2 and is tight for width w 2 (log n) (by choosing primes of size fi (w) in the proof of Proposition 3.13), but there is a relatively large gap between lower and upper bounds for width w 2 o (log <p> Open problem: Construct a simple branching program of polynomial size and width o (log n) for computing majority. Open problem: Can the length lower bound in <ref> [AM88, BPRS90] </ref> be improved for width w 2 o (log n)? Chapter 4 CREW PRAMS VERSUS EREW PRAMS 4.1 Introduction Parallel random access machines (PRAMs) have been the model of choice for de scribing parallel algorithms on shared memory machines.
Reference: [BRS93] <author> Allan Borodin, A. A. Razborov, and Roman Smolensky. </author> <title> On lower bounds for read-k times branching programs. </title> <journal> Computational Complexity, </journal> <volume> 3 </volume> <pages> 1-18, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Then k = O log w and each level of the recursion contributes a branching program of length kn = O log w . 2 In a syntactic read-k branching program, every input variable is read at most k times on any root to leaf path (see Borodin et al. <ref> [BRS93] </ref> for definitions, motiva tions, and a survey of results).
Reference: [Bry92] <author> R. E. Bryant. </author> <title> Symbolic Boolean manipulation with ordered binary decision diagram. </title> <journal> ACM Computing Surveys, </journal> <volume> 24(3) </volume> <pages> 283-316, </pages> <year> 1992. </year>
Reference-contexts: OBDDs seem to have a good balance: they provide compact representation for many functions arising in practice and at the same time, they can be manipulated very efficiently. They have been extensively used in the design, verification, and testing of digital systems (see e.g. Bryant <ref> [Bry92] </ref>, Burch et al. [BCL + 94]). In order to make these systems efficient, the size of the representation has to be minimized. For many functions, no efficient representation with OBDDs is possible. <p> Bryant and Chen [BC94]) or to relax some of the restrictions of the OBDDs to allow more efficient representations while still retaining the ease of manipulation (see the discussion at the end of <ref> [Bry92] </ref>). 2.1.3 Restrictions and Extensions of the Branching Program Model We now discuss some variants of the branching program model.
Reference: [BS91] <author> David A. Mix Barrington and Howard Straubing. </author> <title> Superlinear lower bounds for bounded-width branching programs. </title> <booktitle> In Proceedings, Structure in Complexity Theory, Sixth Annual Conference, </booktitle> <pages> pages 305-313, </pages> <address> Chicago, IL, </address> <month> June </month> <year> 1991. </year> <note> IEEE. </note>
Reference-contexts: For the class of non-constant threshold functions, Barrington and Straubing <ref> [BS91] </ref>, using algebraic techniques, improved this bound to (n log log n). Alon and Maass [AM88] and Babai et al. [BPRS90] independently proved that any oblivious branching program of width w p for majority has length ( n log n log w ).
Reference: [CBZ90] <author> S. Chatterjee, Guy E. Blelloch, and M. Zagha. </author> <title> Scan primitives for vector computers. </title> <booktitle> In Supercomputing '90, </booktitle> <pages> pages 666-675. </pages> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference-contexts: Some practical and theoretical works for parallel machines <ref> [Ble89, Ble90, CBZ90, KRS86, RBJ88, PS88, KRS88] </ref> have suggested that multiprefix operations for certain multiary operators be allowed at unit cost. We will call all such models multiprefix PRAMs. Later we will give a precise definition of multiprefix operations and multiprefix PRAMs. <p> He gives many examples where these primitives reduce the running time, sometimes by as much as a factor of fi (log n). In many cases, this also simplifies the program. Chatterjee et al. <ref> [CBZ90] </ref> discuss implementation of scan operations on a CRAY Y-MP [Cra88]. Again the scan primitives turn out to be very powerful, even for the normally hard case of manipulating irregular and dynamically changing structures. The appendix in Blelloch's Ph.D. thesis [Ble90] gives a brief history of the scan operation.
Reference: [CDHR88] <author> B. S. Chlebus, K. Diks, T. Hagerup, and T. Radzik. </author> <title> Efficient simulations between concurrent-read concurrent-write pram models. </title> <booktitle> In 13th Symposium on Mathematical Foundations of Computer Science, volume 324 of Lecture Notes in Computer Science, </booktitle> <pages> pages 231-239. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: Boppana, generalizing the results of Kucera [Kuc82] and Chlebus et al. <ref> [CDHR88] </ref>, also showed that one step of any n-processor priority CRCW PRAM can be simulated in O (A (n; p)) steps by a common CRCW PRAM with p processors.
Reference: [CDR86] <author> Steven A. Cook, Cynthia Dwork, and Rudiger Reischuk. </author> <title> Upper and lower time bounds for parallel random access machines without simultaneous writes. </title> <journal> SIAM Journal on Computing, </journal> <volume> 15(1) </volume> <pages> 87-97, </pages> <month> February </month> <year> 1986. </year>
Reference-contexts: A large body of algorithms has been discovered for a variety of problems (see, for example, [JaJ92]). Unfortunately, we have not had the same kind of success in proving lower bounds. We will survey some of the known lower bound results. Cook, Dwork, and Reischuk <ref> [CDR86] </ref>, by an elegant argument, showed that any CREW PRAM takes (log n) time to compute the OR of n bits. The result was improved by Kuty lowski [Kut91] and Dietzfelbinger et al. [DKR94] who determined the exact complexity of OR. <p> Cook, Dwork, and Reischuk [CDR86], by an elegant argument, showed that any CREW PRAM takes (log n) time to compute the OR of n bits. The result was improved by Kuty lowski [Kut91] and Dietzfelbinger et al. [DKR94] who determined the exact complexity of OR. The results in <ref> [CDR86, Kut91, DKR94] </ref> (as well as many other lower bound results on PRAMs) all have a similar flavor: they prove that a CREW PRAM running for a small number of steps can distinguish very few inputs. <p> So lower bounds are more of a communication lower bound. That is, they show the intrinsic limitation of global memory as a medium of communication. The results of <ref> [CDR86, Kut91, DKR94] </ref> do not put any restrictions on the number of processors either. 4.2 Communication Width The PRAM model provides a very high level abstraction of real parallel machines. <p> Because the OR of n bits can be computed easily in constant time on a CRCW PRAM, the (log n) lower bound results of <ref> [CDR86, Kut91, DKR94] </ref> prove a separation between the powers of CRCW and CREW PRAMs. <p> There is another issue here: for an exclusive write machine, information can be communicated by the fact that no processor writes into a cell at a given time step. This is not allowed in the case of owner write machines. A close examination of the proofs in <ref> [CDR86, Kut91, DKR94] </ref> reveals that bounding the amount of information communicated in this way is usually the hardest part of the lower bound argument. <p> This is not allowed in the case of owner write machines. A close examination of the proofs in [CDR86, Kut91, DKR94] reveals that bounding the amount of information communicated in this way is usually the hardest part of the lower bound argument. For example, in <ref> [CDR86] </ref>, the proof for the CROW PRAM model is presented as a warm up step and the bulk of the proof is devoted to proving a slightly weaker lower bound for the case of CREW PRAMs. <p> We define general PRAMs as PRAMs with unlimited communication width. The separation result of <ref> [CDR86, Kut91, DKR94] </ref> applies to general CRCW and CREW PRAMs and it would be nice to prove a similar result about CREW and EREW PRAMs. We hope that our lower bound argument gives some insight even for the general case.
Reference: [CFL83] <author> Ashok K. Chandra, M. L. Furst, and Richard J. Lipton. </author> <title> Multi-party protocols. </title> <booktitle> In Proceedings of the Fifteenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 94-99, </pages> <address> Boston, MA, </address> <month> April </month> <year> 1983. </year> <month> 117 </month>
Reference-contexts: Shearer (unpublished) proved an exponential lower bound for the problem of checking whether the number of 1's in the input is a multiple of three. For width three or more, the best lower bound for a symmetric function is much smaller. Chandra et al. <ref> [CFL83] </ref> were the first to prove a super-linear (nW (n)) length lower bound on arbitrary constant-width branching programs. (W (n) is the inverse of the Van der Waerden function and is less than 10 for all practical values of n.) They used Ramsey theoretic arguments and as we noted, their bound
Reference: [CL89] <author> Jin-Yi Cai and Richard J. Lipton. </author> <title> Subquadratic simulations of circuits by branching programs. </title> <booktitle> In 30th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 568-573, </pages> <address> Research Triangle Park, NC, </address> <month> October </month> <year> 1989. </year> <note> IEEE. </note>
Reference-contexts: The width five comes from the fact that the smallest unsolvable permutation group has order five. The size blow-up in the simulation of circuits by branching programs was later improved by Cai and Lipton <ref> [CL89] </ref>, and Cleve [Cle91]. Cleve showed that any formula of size t 27 can be simulated by a branching program of width w and length t 1+1=O (w) .
Reference: [Cle91] <author> R. Cleve. </author> <title> Towards optimal simulations of formulas by bounded-width programs. </title> <journal> Computational Complexity, </journal> <volume> 1 </volume> <pages> 91-105, </pages> <year> 1991. </year>
Reference-contexts: The width five comes from the fact that the smallest unsolvable permutation group has order five. The size blow-up in the simulation of circuits by branching programs was later improved by Cai and Lipton [CL89], and Cleve <ref> [Cle91] </ref>. Cleve showed that any formula of size t 27 can be simulated by a branching program of width w and length t 1+1=O (w) .
Reference: [CLLS] <author> A. Condon, R. Ladner, J. Lampe, and R. Sinha. </author> <title> Complexity of sub-bus computation. </title> <journal> SIAM Journal on Computing. </journal> <note> To appear. </note>
Reference-contexts: If preprocessing is not allowed, q-parity can be computed in uniform NC 1 [BIS90] (details are given in <ref> [CLLS] </ref>). A parallel instruction issued by the front-end has the form "if &lt;condition&gt; then &lt;statement&gt;." Each processor evaluates the condition, which can be any sequence of non-branching operations which evaluates to a Boolean value. <p> We consider the problem of summing the input bits on a p p p mesh when each processor starts with an input integer of length O (log p). It is a very basic operation and is used as a subroutine in many important algorithms. Theorem 6.1 <ref> [CLLS] </ref> Any algorithm for computing SUM on the p p bus must run for at least log log p steps. Proof: It was shown in [CLLS] that a priority CRCW PRAM can simulate a sub-bus mesh computer to within a constant factor of the time and within a polynomial number of <p> It is a very basic operation and is used as a subroutine in many important algorithms. Theorem 6.1 <ref> [CLLS] </ref> Any algorithm for computing SUM on the p p bus must run for at least log log p steps. Proof: It was shown in [CLLS] that a priority CRCW PRAM can simulate a sub-bus mesh computer to within a constant factor of the time and within a polynomial number of processors. <p> The running time is dlog m 2 e + dlog m 1 e = O (log p). 2 For the case of the 1 fi p sub-bus mesh, Condon et al. <ref> [CLLS] </ref> proved a lower bound of log p on the PARITY function and a lower bound of log 3 (2 min (k; p k)) on the kth threshold function. That paper also contains Theorem 6.2 and an efficient simulation of sub-bus meshes by CRCW PRAMs.
Reference: [Cob66] <author> Alan Cobham. </author> <title> The recognition problem for the set of perfect squares. </title> <institution> Research Paper RC-1704, IBM Watson Research Center, </institution> <year> 1966. </year>
Reference-contexts: We will give two examples. As our first example, consider the problem of checking whether two halves of a given input string of length 2n are equal. Cobham's classical result <ref> [Cob66] </ref> states that for any Turing machine solving this problem, the product of its time and space requirement is at least (n 2 ). <p> An s (n) space bounded nonuniform Turing machine is allowed to hardwire 2 O (s (n)) bits of advice. (See page 279 of Wegner [Weg87] for a definition of nonuniform Turing machines.) 14 Proposition 2.2 (Cobham <ref> [Cob66] </ref>, Pudlak and Zak [PZ83]) For any s = (log n), branching programs using space O (log s) compute exactly the same class of functions as nonuniform Turing machines using space O (log s).
Reference: [Cra88] <institution> Cray Research Inc., Mendota Heights, Minnesota. </institution> <note> Symbolic Machine Instructions Reference Manual. </note> <year> 1988. </year>
Reference-contexts: He gives many examples where these primitives reduce the running time, sometimes by as much as a factor of fi (log n). In many cases, this also simplifies the program. Chatterjee et al. [CBZ90] discuss implementation of scan operations on a CRAY Y-MP <ref> [Cra88] </ref>. Again the scan primitives turn out to be very powerful, even for the normally hard case of manipulating irregular and dynamically changing structures. The appendix in Blelloch's Ph.D. thesis [Ble90] gives a brief history of the scan operation.
Reference: [DKR94] <author> Martin Dietzfelbinger, Mirek Kuty lowski, and Rudiger Reischuk. </author> <title> Exact time bounds for computing Boolean functions on PRAMs without simultaneous writes. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 48(2) </volume> <pages> 231-254, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: We will survey some of the known lower bound results. Cook, Dwork, and Reischuk [CDR86], by an elegant argument, showed that any CREW PRAM takes (log n) time to compute the OR of n bits. The result was improved by Kuty lowski [Kut91] and Dietzfelbinger et al. <ref> [DKR94] </ref> who determined the exact complexity of OR. The results in [CDR86, Kut91, DKR94] (as well as many other lower bound results on PRAMs) all have a similar flavor: they prove that a CREW PRAM running for a small number of steps can distinguish very few inputs. <p> Cook, Dwork, and Reischuk [CDR86], by an elegant argument, showed that any CREW PRAM takes (log n) time to compute the OR of n bits. The result was improved by Kuty lowski [Kut91] and Dietzfelbinger et al. [DKR94] who determined the exact complexity of OR. The results in <ref> [CDR86, Kut91, DKR94] </ref> (as well as many other lower bound results on PRAMs) all have a similar flavor: they prove that a CREW PRAM running for a small number of steps can distinguish very few inputs. <p> So lower bounds are more of a communication lower bound. That is, they show the intrinsic limitation of global memory as a medium of communication. The results of <ref> [CDR86, Kut91, DKR94] </ref> do not put any restrictions on the number of processors either. 4.2 Communication Width The PRAM model provides a very high level abstraction of real parallel machines. <p> Because the OR of n bits can be computed easily in constant time on a CRCW PRAM, the (log n) lower bound results of <ref> [CDR86, Kut91, DKR94] </ref> prove a separation between the powers of CRCW and CREW PRAMs. <p> There is another issue here: for an exclusive write machine, information can be communicated by the fact that no processor writes into a cell at a given time step. This is not allowed in the case of owner write machines. A close examination of the proofs in <ref> [CDR86, Kut91, DKR94] </ref> reveals that bounding the amount of information communicated in this way is usually the hardest part of the lower bound argument. <p> We define general PRAMs as PRAMs with unlimited communication width. The separation result of <ref> [CDR86, Kut91, DKR94] </ref> applies to general CRCW and CREW PRAMs and it would be nice to prove a similar result about CREW and EREW PRAMs. We hope that our lower bound argument gives some insight even for the general case. <p> Proof sketch: The lower bound on CREW PRAMs follows from a degree argument <ref> [DKR94] </ref>; the upper bound follows from the following algorithm: for each node of D h , assign a processor and a common cell. In the first step, every processor reads the value of the corresponding input variable.
Reference: [DR86] <author> Patrick W. Dymond and Walter L. Ruzzo. </author> <title> Parallel random access machines with owned global memory and deterministic context-free language recognition. </title> <editor> In Laurent Kott, editor, </editor> <booktitle> Automata, Languages, and Programming: 13th International Colloquium, volume 226 of Lecture Notes in Computer Science, </booktitle> <pages> pages 95-104, </pages> <publisher> Rennes, </publisher> <address> France, July 1986. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The EROW PRAM is an EREW PRAM in which each processor is said to "own" one shared memory cell and that is the only cell to which it is allowed to write. Processors are still allowed to read from any cell. The CROW PRAM <ref> [DR86] </ref> is the CREW PRAM restricted in the same manner. Fich and Wigderson proved that the EROW PRAM requires ( p log n) time to compute a 63 Boolean function that requires only O (log log n) time on the CROW PRAM.
Reference: [Edm91] <author> Jeff Edmonds. </author> <title> Lower bounds with small domain size on concurrent write parallel machines. </title> <booktitle> In Proceedings, Structure in Complexity Theory, Sixth Annual Conference, </booktitle> <pages> pages 322-332, </pages> <address> Chicago, IL, </address> <month> June </month> <year> 1991. </year> <journal> IEEE. </journal> <volume> 118 </volume>
Reference-contexts: Boppana's result uses Ramsey's theorem and his lower bound argument does not work if the input integers are restricted to come from a small domain. Ed-monds <ref> [Edm91] </ref> improved Boppana's result to prove the same lower bound even if the input integers are restricted to come from a domain of size 2 (n) .
Reference: [Fic93] <author> Faith E. Fich. </author> <title> The complexity of computation on the parallel random access machine. </title> <editor> In John H. Reif, editor, </editor> <booktitle> Synthesis of Parallel Algorithms, chapter 20, </booktitle> <pages> pages 843-899. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: The three most popular models are the CRCW (concurrent read, concurrent write), CREW (concurrent read, exclusive write), and EREW (exclusive read, exclusive write) PRAMs (see <ref> [JaJ92, Fic93] </ref>.) In the case of concurrent write, we need some 58 way to arbitrate write conflicts. There are several variations; we will describe two of them.
Reference: [FMadHRW85] <author> Faith Fich, Friedhelm Meyer auf der Heide, Prabhakar Ragde, and Avi Wigderson. </author> <title> One, two, three ... infinity: Lower bounds for parallel computation. </title> <booktitle> In Proceedings of the Seventeenth Annual ACM Symposium on Theory of Computing, </booktitle> <address> Providence, RI, </address> <month> May </month> <year> 1985. </year>
Reference-contexts: As an example, consider the problem of finding the largest element from a set of n integers on an n-processor CRCW PRAM. With no restrictions on the size of the inputs, Fich et al. <ref> [FMadHRW85] </ref> have shown a lower bound of (log log n), but if the input integers are restricted to be at most O (n k ) in value, an algorithm running in time O (k) is known [FRW88]. Gafni, Naor, and Ragde [GNR89] extended Snir's result to a full domain.
Reference: [FRW88] <author> Faith E. Fich, Prabhakar Ragde, and Avi Wigderson. </author> <title> Relations between concurrent-write models of parallel computation. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17 </volume> <pages> 606-627, </pages> <year> 1988. </year>
Reference-contexts: With no restrictions on the size of the inputs, Fich et al. [FMadHRW85] have shown a lower bound of (log log n), but if the input integers are restricted to be at most O (n k ) in value, an algorithm running in time O (k) is known <ref> [FRW88] </ref>. Gafni, Naor, and Ragde [GNR89] extended Snir's result to a full domain. This takes care of our first objection but their result still uses Ramsey theory and requires a very large domain for input integers.
Reference: [FSS81] <author> M. Furst, J. B. Saxe, and Michael Sipser. </author> <title> Parity, circuits, and the polynomial-time hierarchy. </title> <booktitle> In 22nd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 260-270, </pages> <address> Nashville, TN, </address> <month> October </month> <year> 1981. </year> <note> IEEE. </note>
Reference-contexts: Their proof combines the restriction technique (used to prove size lower bounds on constant depth circuits <ref> [H-as87, FSS81] </ref>) with a degree argument and also applies to many other functions such as computing the sum of the bits. The results we have described so far are very appealing because they place absolutely no restrictions on the instruction set of individual processors or the word-size of the machine. <p> Using the known lower bounds on parity <ref> [H-as87, FSS81, Yao85, Ajt83] </ref>, they managed to prove a non-constant time lower bound for the problem of computing parity on PRAMs with polynomial number of processors.
Reference: [FW90] <author> Faith E. Fich and Avi Wigderson. </author> <title> Towards understanding exclusive read. </title> <journal> SIAM Journal on Computing, </journal> <volume> 19(4) </volume> <pages> 717-727, </pages> <year> 1990. </year>
Reference-contexts: The other extreme, when each of the n inputs is a single bit, is open. Open problem: Is there a function f : f0; 1g n ! f0; 1g that can be computed faster by a CREW PRAM than by an EREW PRAM. Fich and Wigderson <ref> [FW90] </ref> have made some progress by resolving this question in a special case when there is a restriction imposed on where processors can write in shared memory. <p> We can use a standard EREW PRAM pointer doubling algorithm to evaluate F h in log h + O (1) steps. 2 However a generalization of this function, considered in Fich and Wigder-son <ref> [FW90] </ref>, seems like a good candidate function. Definition 4.17 [FW90] Given any m (2 h 1) + 2 m bits of input, they can be interpreted as a Boolean decision tree of height h1, where each node is labeled with one of fx 1 ; x 2 ; : : : <p> We can use a standard EREW PRAM pointer doubling algorithm to evaluate F h in log h + O (1) steps. 2 However a generalization of this function, considered in Fich and Wigder-son <ref> [FW90] </ref>, seems like a good candidate function. Definition 4.17 [FW90] Given any m (2 h 1) + 2 m bits of input, they can be interpreted as a Boolean decision tree of height h1, where each node is labeled with one of fx 1 ; x 2 ; : : : ; x m g. <p> F m;h : f0; 1g m (2 h 1)+2 m ! f0; 1g is defined as the value of this decision tree. Proposition 4.18 <ref> [FW90] </ref> The complexity of F m;h on CREW PRAMs is fi (log m + log h), and it can be solved on an EROW PRAM in O (2 m + log h) steps. Open problem: Determine the exact complexity of F m;h on general EREW PRAMs.
Reference: [GGKR83] <author> A. Gottlieb, R. Grishman, Clyde P. Kruskal, and L. Rudolph. </author> <title> The NYU Ultracomputer | designing an MIMD parallel machine. </title> <journal> IEEE Transactions on Computers, </journal> <volume> TC-32:175-189, </volume> <year> 1983. </year>
Reference-contexts: There are several models which differ in the kinds of partitioning (of processors) they allow. Multiprefix operations have a basis in many existing parallel machines and proposed architectures. In the implementation of the CRCW PRAM on the NYU Ultracomputer, a number of additional operations such as Fetch-and-add were included <ref> [GGKR83] </ref>. These operations used the combining network to perform computation during a concurrent memory access and were used as synchronization primitives. Blelloch [Ble89] considered scan operations, where all processors are restricted to be in the same group.
Reference: [GLR83] <author> A. Gottlieb, B. D. Lubachevsky, and Larry Rudolph. </author> <title> Basic techniques for the efficient co-ordination of very large number of cooperating sequential processes. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <month> April </month> <year> 1983. </year>
Reference-contexts: The authors give strong justification for an architecture providing these primitives. Because we will be giving a simulation of multiprefix PRAMs, we adopt this (strongest) definition of multiprefix operations. The fetch-and-op of Gottlieb et al. <ref> [GLR83] </ref> is an indeterminate version of the mutiprefix operation. The effect of fetch-and-op is also to compute a set of prefixes, but the order of inputs is undetermined. In this regard, the multiprefix operation can be considered a particular implementation of fetch-and-op. We begin by defining a multiprefix (MP) operation.
Reference: [GNR89] <author> E. Gafni, Joseph Naor, and Prabhakar Ragde. </author> <title> On separating the EREW and CREW PRAM models. </title> <journal> Theoretical Computer Science, </journal> <volume> 68(3) </volume> <pages> 343-346, </pages> <year> 1989. </year> <month> 119 </month>
Reference-contexts: Gafni, Naor, and Ragde <ref> [GNR89] </ref> extended Snir's result to a full domain. This takes care of our first objection but their result still uses Ramsey theory and requires a very large domain for input integers. The other extreme, when each of the n inputs is a single bit, is open.
Reference: [H-as87] <author> Johan H-astad. </author> <title> Computational Limitations of Small-Depth Circuits. </title> <publisher> MIT Press, </publisher> <year> 1987. </year> <note> ACM Doctoral Dissertation Award Series (1986). </note>
Reference-contexts: Their proof combines the restriction technique (used to prove size lower bounds on constant depth circuits <ref> [H-as87, FSS81] </ref>) with a degree argument and also applies to many other functions such as computing the sum of the bits. The results we have described so far are very appealing because they place absolutely no restrictions on the instruction set of individual processors or the word-size of the machine. <p> Using the known lower bounds on parity <ref> [H-as87, FSS81, Yao85, Ajt83] </ref>, they managed to prove a non-constant time lower bound for the problem of computing parity on PRAMs with polynomial number of processors. <p> In the case of PRIORITY CRCW PRAMs, lower bounds for unbounded fan-in circuits <ref> [H-as87] </ref> provided the pattern for PRAM lower bounds [BH89]. What we demonstrate is that for natural restrictions of multiprefix PRAM word-length, bounds for circuits with prefix operations directly translate into bounds for the multiprefix PRAM.
Reference: [Hil85] <author> W. D. Hillis. </author> <title> The Connection Machine. </title> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference-contexts: Blel-loch [Ble89] showed that scan primitives for integer-add, integer-max, integer-min, 81 OR, and AND can be implemented as efficiently as reads and writes on a connection machine <ref> [Hil85] </ref>. He gives many examples where these primitives reduce the running time, sometimes by as much as a factor of fi (log n). In many cases, this also simplifies the program. Chatterjee et al. [CBZ90] discuss implementation of scan operations on a CRAY Y-MP [Cra88].
Reference: [HMP + 93] <author> Andras Hajnal, Wolfgang Maass, Pavel Pudlak, Mario Szegedy, and Gyorgy Turan. </author> <title> Threshold circuits of bounded depth. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 46(2) </volume> <pages> 129-154, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: In the case of lower bounds, it still remains to extend the results for unbounded fan-in circuits with more powerful gates as primitives such as those described in [Raz87], [Smo87] and <ref> [HMP + 93] </ref>. Parberry and Schnitger [PS88] defined and analyzed TRAMs (Threshold RAMs) that are CRCW PRAMs whose write resolution rule corresponds to computing a threshold function of the values that processors are attempting to write.
Reference: [HS86] <author> W.D. Hillis and G.L. Steele, Jr. </author> <title> Data parallel algorithms. </title> <journal> Communications of the ACM, </journal> <volume> 29 </volume> <pages> 1170-1183, </pages> <year> 1986. </year>
Reference-contexts: Their simple and regular design has also made them an attractive model with theoreticians interested in designing parallel algorithms. The model has several variants which have all been the subject of extensive study <ref> [HS86, Lei92, LS91, MS89, MPKRS93, RPK88, Sto86] </ref>. We will focus on the sub-bus mesh model, which has been implemented on the commercially available MasPar MP-1 [Bla90]. A sub-bus mesh is a single-instruction multiple-data (SIMD) two-dimensional array of processors.
Reference: [HW79] <author> G. H. Hardy and E. M. Wright. </author> <title> An Introduction to the Theory of Numbers. </title> <publisher> Oxford University Press, </publisher> <address> fifth edition, </address> <year> 1979. </year>
Reference-contexts: ) 1 j k 28 has a unique solution for x between 0 and Q p j 1 given by x = 4 j=1 3 Y where m j = Q p j A proof can be found in any standard textbook on Number Theory (for example, Hardy and Wright <ref> [HW79] </ref>). We will illustrate this approach by an example. Definition 3.9 For any k n, the exact-k function, E k , accepts an input ~x if and only if k~xk = k.
Reference: [JaJ92] <author> Joseph JaJa. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference-contexts: The three most popular models are the CRCW (concurrent read, concurrent write), CREW (concurrent read, exclusive write), and EREW (exclusive read, exclusive write) PRAMs (see <ref> [JaJ92, Fic93] </ref>.) In the case of concurrent write, we need some 58 way to arbitrate write conflicts. There are several variations; we will describe two of them. <p> The PRAM model has been very successful for developing algorithms. A large body of algorithms has been discovered for a variety of problems (see, for example, <ref> [JaJ92] </ref>). Unfortunately, we have not had the same kind of success in proving lower bounds. We will survey some of the known lower bound results. Cook, Dwork, and Reischuk [CDR86], by an elegant argument, showed that any CREW PRAM takes (log n) time to compute the OR of n bits.
Reference: [Kar89] <author> Mauricio Karchmer. </author> <title> Communication Complexity: A New Approach to Circuit Depth. </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: The communication complexity measure was first introduced by Yao [Yao79] and has turned out to be very useful in a number of contexts (e.g., circuit depth lower bound, VLSI time area trade-off). There are several papers containing detailed and precise treatment (see, for example, Karchmer's thesis <ref> [Kar89] </ref>). As a warm up, we will outline a very simple lower bound argument on the size of OBDDs. Proposition 3.3 Any OBDD computing a function with optimal-partition communication complexity C has at least 2 C nodes.
Reference: [KRS86] <author> Clyde P. Kruskal, L. Rudolph, and Marc Snir. </author> <title> Efficient synchronization in multiprocessors with shared memory. </title> <booktitle> In Proceedings of the Fifth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 218-228, </pages> <address> Calgary, Alberta, Canada, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: Some practical and theoretical works for parallel machines <ref> [Ble89, Ble90, CBZ90, KRS86, RBJ88, PS88, KRS88] </ref> have suggested that multiprefix operations for certain multiary operators be allowed at unit cost. We will call all such models multiprefix PRAMs. Later we will give a precise definition of multiprefix operations and multiprefix PRAMs.
Reference: [KRS88] <author> Clyde P. Kruskal, L. Rudolph, and Marc Snir. </author> <title> A complexity theory of efficient parallel algorithms. </title> <type> Technical Report RC 13572, </type> <institution> IBM, </institution> <month> March </month> <year> 1988. </year>
Reference-contexts: Some practical and theoretical works for parallel machines <ref> [Ble89, Ble90, CBZ90, KRS86, RBJ88, PS88, KRS88] </ref> have suggested that multiprefix operations for certain multiary operators be allowed at unit cost. We will call all such models multiprefix PRAMs. Later we will give a precise definition of multiprefix operations and multiprefix PRAMs.
Reference: [Kuc82] <author> L. Kucera. </author> <title> Parallel computation and conflicts in memory access. </title> <journal> Information Processing Letters, </journal> <volume> 14(2) </volume> <pages> 93-96, </pages> <month> April </month> <year> 1982. </year>
Reference-contexts: Boppana, generalizing the results of Kucera <ref> [Kuc82] </ref> and Chlebus et al. [CDHR88], also showed that one step of any n-processor priority CRCW PRAM can be simulated in O (A (n; p)) steps by a common CRCW PRAM with p processors.
Reference: [Kut91] <author> Mirek Kuty lowski. </author> <title> The complexity of Boolean functions on CREW PRAMs. </title> <journal> SIAM Journal on Computing, </journal> <volume> 20(5) </volume> <pages> 824-833, </pages> <year> 1991. </year> <month> 120 </month>
Reference-contexts: We will survey some of the known lower bound results. Cook, Dwork, and Reischuk [CDR86], by an elegant argument, showed that any CREW PRAM takes (log n) time to compute the OR of n bits. The result was improved by Kuty lowski <ref> [Kut91] </ref> and Dietzfelbinger et al. [DKR94] who determined the exact complexity of OR. <p> Cook, Dwork, and Reischuk [CDR86], by an elegant argument, showed that any CREW PRAM takes (log n) time to compute the OR of n bits. The result was improved by Kuty lowski [Kut91] and Dietzfelbinger et al. [DKR94] who determined the exact complexity of OR. The results in <ref> [CDR86, Kut91, DKR94] </ref> (as well as many other lower bound results on PRAMs) all have a similar flavor: they prove that a CREW PRAM running for a small number of steps can distinguish very few inputs. <p> So lower bounds are more of a communication lower bound. That is, they show the intrinsic limitation of global memory as a medium of communication. The results of <ref> [CDR86, Kut91, DKR94] </ref> do not put any restrictions on the number of processors either. 4.2 Communication Width The PRAM model provides a very high level abstraction of real parallel machines. <p> Because the OR of n bits can be computed easily in constant time on a CRCW PRAM, the (log n) lower bound results of <ref> [CDR86, Kut91, DKR94] </ref> prove a separation between the powers of CRCW and CREW PRAMs. <p> There is another issue here: for an exclusive write machine, information can be communicated by the fact that no processor writes into a cell at a given time step. This is not allowed in the case of owner write machines. A close examination of the proofs in <ref> [CDR86, Kut91, DKR94] </ref> reveals that bounding the amount of information communicated in this way is usually the hardest part of the lower bound argument. <p> For example, the technique in the lower bound result for the OR function on CREW (1) PRAMs [VW85, Bea86] is very similar to the technique that Kuty lowski <ref> [Kut91] </ref> eventually used in his optimal bound for the OR on general CREW PRAMs. Our lower bound proof consists of three parts. First we show that any EREW (1) PRAM running for a short time can only have a small number of processors doing useful work. <p> We define general PRAMs as PRAMs with unlimited communication width. The separation result of <ref> [CDR86, Kut91, DKR94] </ref> applies to general CRCW and CREW PRAMs and it would be nice to prove a similar result about CREW and EREW PRAMs. We hope that our lower bound argument gives some insight even for the general case. <p> We hope that our lower bound argument gives some insight even for the general case. There is at least some precedence for this: Kuty lowski's <ref> [Kut91] </ref> optimal lower bound for general CREW PRAMs, computing the OR function, uses techniques similar to the lower bound result, for the OR function, on CREW (1) PRAMs [VW85, Bea86].
Reference: [KW93] <author> Mauricio Karchmer and Avi Wigderson. </author> <title> On span programs. </title> <booktitle> In Proceedings, Structure in Complexity Theory, Eighth Annual Conference, </booktitle> <pages> pages 102-111, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <note> IEEE. </note>
Reference-contexts: Corollary 3.6 For the problem of computing majority or mod a;b p every branching program has size log log n and every oblivious branching program of width w p n has length log w . Razborov [Raz90], and Karchmer and Wigderson <ref> [KW93] </ref> proved unconditional size lower bounds of (n log log log ? n) for computing majority on nondeterministic extensions of the branching program model. Razborov proved it for rectifier-switching networks; Karchmer and Wigderson proved it for span programs.
Reference: [Lei92] <author> F. Thomson Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: Their simple and regular design has also made them an attractive model with theoreticians interested in designing parallel algorithms. The model has several variants which have all been the subject of extensive study <ref> [HS86, Lei92, LS91, MS89, MPKRS93, RPK88, Sto86] </ref>. We will focus on the sub-bus mesh model, which has been implemented on the commercially available MasPar MP-1 [Bla90]. A sub-bus mesh is a single-instruction multiple-data (SIMD) two-dimensional array of processors.
Reference: [LMR88] <author> F. Thomson Leighton, B. Maggs, and S. Rao. </author> <title> Universal packet routing algorithms. </title> <booktitle> In 29th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 256-271, </pages> <address> White Plains, NY, </address> <month> October </month> <year> 1988. </year> <note> IEEE. </note>
Reference-contexts: Such a simulation of a PRIORITY CRCW PRAM by an FFT Network was shown by Ranade [Ran87] and this was extended to a variety of other networks by Leighton, Maggs, and Rao <ref> [LMR88] </ref> among others. Currently there is no practical solution for implementing an n-processor read or write that does better than O (log 2 n) for deterministic schemes or O (log n) for probabilistic schemes.
Reference: [LS91] <author> H. Li and Q.F. Stout. </author> <title> Reconfigurable Massively Parallel Computers. </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1991. </year>
Reference-contexts: Their simple and regular design has also made them an attractive model with theoreticians interested in designing parallel algorithms. The model has several variants which have all been the subject of extensive study <ref> [HS86, Lei92, LS91, MS89, MPKRS93, RPK88, Sto86] </ref>. We will focus on the sub-bus mesh model, which has been implemented on the commercially available MasPar MP-1 [Bla90]. A sub-bus mesh is a single-instruction multiple-data (SIMD) two-dimensional array of processors. <p> By internally connecting some subsets of these ports to each other, the executing program is allowed to change the topology of the mesh <ref> [LS91] </ref>. Several prototype of reconfigurable mesh computers, though non-commercial, have been built. The model comes in two flavors: In the cross-over model, processors are allowed to independently connect their N-S ports together and their E-W ports together; such connections are not allowed in the non-cross-over model. <p> It is well known that PARITY can be computed in constant time on the crossover m 1 fi m 2 mesh if m 1 ; m 2 3. The basic idea of the algorithm is the same as in the branching program for computing parity in Proposition 3.10 (see <ref> [LS91] </ref> for details). Thus the fi (log p) bound for PARITY on the sub-bus mesh demonstrate that the sub-bus mesh computer architecture is strictly more powerful than the full-bus mesh computer architecture, but strictly less powerful than the reconfigurable cross-over mesh computer.
Reference: [Lup65] <author> O. B. Lupanov. </author> <title> On the problem of realization of symmetric Boolean functions by contact schemes. Probl. </title> <journal> Kibernet, </journal> <volume> 15 </volume> <pages> 85-99, </pages> <year> 1965. </year> <note> In Russian. </note>
Reference-contexts: All previously known constructions for these two classes of functions had size (n 3=2 ) <ref> [Lup65] </ref>. Our constructions are better described in terms of a new model Modular Arithmetic 22 Branching Programs (MA-programs) that we introduce in Subsection 3.2.3. <p> log log n e primes of size fi (log n) each such that their product is greater than n, then the summation of all the primes is O log log n and therefore the resulting branching program is of size O nlog 2 n log log n . 2 Lupanov <ref> [Lup65] </ref> used the idea of receiving partial information by computing modulo small primes, combined with a trick of identifying common subcomputa-tions, to beat the trivial O (n 2 ) bound for computing any symmetric function. <p> This result follows as a corollary of the next theorem. Theorem 3.21 <ref> [Lup65] </ref> For every partition of Z n+1 into two disjoint sets, there is an MA-program of size O log n separating these two sets. <p> This reduces the number of q-boxes by a factor of q but does not improve the asymptotic size bound. 2 Applying Lemma 3.16, we get Lupanov's result for computing arbitrary symmetric functions. Corollary 3.22 <ref> [Lup65] </ref> There is an oblivious branching program of size O n 2 for computing any symmetric function on n inputs. 3.3 Branching Programs for Threshold and Mod functions We would like to improve the O (n 2 = log n) upper bound (Corollary 3.22) on the size of branching programs computing <p> In Proposition 3.13, we already saw an easy way to compute exact functions more efficiently. Unfortunately, there is no easy way to replicate this technique to other important classes of symmetric functions, for example, threshold and mod functions. Lupanov <ref> [Lup65] </ref> constructed a branching program of size O (n 3=2 ) for computing any threshold function. No progress had been made on Lupanov's construction in nearly thirty years. <p> Our constructions are a generalization of Lupanov's construction for computing majority <ref> [Lup65] </ref>. Both of our constructions have other nice properties. For example, for any `, between levels `n and (`+1)n1, the variables are accessed in the order x 1 ; x 2 ; : : : ; x n . <p> We refer to this as "division" because the MA-program is computing (or approximating) bx=M 0 c on input x. We have the exact division for the case k = 2 which forms the basis of Lupanov's construction of branching programs of size O (n 3=2 ) for computing majority <ref> [Lup65] </ref>. In Theorem 3.43, we give some evidence of the difficulty of computing exact division for the case k 3. 43 Proof: We will first describe the construction of D. <p> We presented our constructions in terms of MA-programs, which helped us highlight the key ideas of our constructions. Many of the previously known constructions are also more easily understood in terms of MA-programs (for example, <ref> [Lup65] </ref>). But even for computing symmetric functions, MA-programs do not capture the full generality of branching programs. They correspond to the subset of branching programs for which computation can be broken into blocks such that within any block, a function of the sum of the input bits is computed.
Reference: [Mac93] <author> P. D. MacKenzie. </author> <title> A separation between reconfigurable mesh models. </title> <booktitle> In 7th International Parallel Processing Symposium, </booktitle> <year> 1993. </year>
Reference-contexts: That paper also contains Theorem 6.2 and an efficient simulation of sub-bus meshes by CRCW PRAMs. The lower bound on PARITY on the 1 fi p sub-bus mesh was (earlier) independently obtained by MacKen-zie <ref> [Mac93] </ref>. This lower bound is tight because of Proposition 6.4. Two variants of the mesh computer are closely related to the sub-bus mesh. <p> Thus the fi (log p) bound for PARITY on the sub-bus mesh demonstrate that the sub-bus mesh computer architecture is strictly more powerful than the full-bus mesh computer architecture, but strictly less powerful than the reconfigurable cross-over mesh computer. In another work on the PARITY function, MacKenzie <ref> [Mac93] </ref> proved a lower bound of ((log m 1 )=m 2 ) for computing PARITY on an m 1 fi m 2 non-cross-over reconfigurable mesh model, thereby showing a separation between the powers of the two flavors of the reconfigurable mesh model.
Reference: [MNT90] <author> Yishay Mansour, Noam Nisan, and Prasoon Tiwari. </author> <title> The computational complexity of universal hashing. </title> <booktitle> In Proceedings of the Twenty-Second Annual ACM Symposium on Theory of Computing, </booktitle> <address> Baltimore, MD, </address> <month> May </month> <year> 1990. </year>
Reference: [MNV94] <author> Y. Mansour, N. Nisan, and U. Vishkin. </author> <title> Trade-offs between communication throughput and parallel time. </title> <booktitle> In Proceedings of the Twenty-Sixthh Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 372-381, </pages> <address> Montreal, Quebec, Canada, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: He proved a lower bound of m for the case k n 1=2* and a lower bound of m for k n 1=2* , where * is any number greater than zero. Mansour et al. <ref> [MNV94] </ref> consider a CRCW (m) model with n &gt;> p &gt;> m (where p is the number of processors) and determine the exact complexity of the list reversal problem.
Reference: [MPKRS93] <author> R. Miller, V. K. Prasanna Kumar, D. I. Reisis, and Q. F. Stout. </author> <title> Parallel computations on reconfigurable meshes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 42 </volume> <pages> 678-692, </pages> <year> 1993. </year> <month> 121 </month>
Reference-contexts: Their simple and regular design has also made them an attractive model with theoreticians interested in designing parallel algorithms. The model has several variants which have all been the subject of extensive study <ref> [HS86, Lei92, LS91, MS89, MPKRS93, RPK88, Sto86] </ref>. We will focus on the sub-bus mesh model, which has been implemented on the commercially available MasPar MP-1 [Bla90]. A sub-bus mesh is a single-instruction multiple-data (SIMD) two-dimensional array of processors.
Reference: [MS89] <author> R. Miller and Q. Stout. </author> <title> Mesh computer algorithms for computational geometry. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38 </volume> <pages> 321-340, </pages> <year> 1989. </year>
Reference-contexts: Their simple and regular design has also made them an attractive model with theoreticians interested in designing parallel algorithms. The model has several variants which have all been the subject of extensive study <ref> [HS86, Lei92, LS91, MS89, MPKRS93, RPK88, Sto86] </ref>. We will focus on the sub-bus mesh model, which has been implemented on the commercially available MasPar MP-1 [Bla90]. A sub-bus mesh is a single-instruction multiple-data (SIMD) two-dimensional array of processors.
Reference: [Nak93] <author> K. Nakano. </author> <title> An efficient algorithm for summing up binary values on a reconfigurable mesh. </title> <type> Research Report 93-003, </type> <institution> Advanced Research Laboratory, </institution> <address> Hatoyama, Saitama 350-03, Japan, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: The SUM function has also been previously studied on the reconfigurable mesh. Nakano <ref> [Nak93] </ref>, improving a result of Nakano, Masuzawa and Tokura [NMT91], developed algorithms for summing n binary values on an n fi m reconfigurable mesh in time O (log n= q m= log n).
Reference: [Nec66] <author> E. Neciporuk. </author> <title> On a Boolean function. </title> <journal> Soviet Math. Doklady, </journal> <volume> 7 </volume> <pages> 999-1000, </pages> <year> 1966. </year>
Reference-contexts: By a counting argument we know that almost all functions have size complexity fi ( 2 n n ) on branching programs, but the best lower bound for a function in N P is only log 2 n . This bound was first proved by Neciporuk <ref> [Nec66] </ref> for a somewhat contrived function. Beame and Cook (unpublished) noticed that Neciporuk's technique can be applied to prove the same lower bound for the element distinctness problem. Neciporuk's technique is essentially a counting argument and applies to the stronger switching network model (see [Raz91] for definition). Theorem 2.5 [Nec66] Let <p> Neciporuk <ref> [Nec66] </ref> for a somewhat contrived function. Beame and Cook (unpublished) noticed that Neciporuk's technique can be applied to prove the same lower bound for the element distinctness problem. Neciporuk's technique is essentially a counting argument and applies to the stronger switching network model (see [Raz91] for definition). Theorem 2.5 [Nec66] Let b 1 ; b 2 ; : : : ; b m be any partition of input variables into m groups. Then setting all variables outside b i gives a sub-function of f on the 19 variables in b i .
Reference: [Nis91] <author> Noam Nisan. </author> <title> CREW PRAMs and decision trees. </title> <journal> SIAM Journal on Computing, </journal> <volume> 20(6) </volume> <pages> 999-1007, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: As the computation progresses, the partitioning of equivalence classes gets finer and finer. There are several measures (for example, sensitivity, certificate complexity, polynomial degree, granularity; see Nisan <ref> [Nis91] </ref> for definitions) to estimate how fine the partitioning of inputs is and therefore to measure the "progress" of the computation. <p> A lower bound proof consists of choosing one of these measures and then showing that any algorithm running for a short time makes less progress than what is needed to compute the given function. Nisan <ref> [Nis91] </ref> gave several characterizations of complexity of any function on 59 CREW PRAMs in terms of these measures. <p> It is known that the problem of computing the OR of n bits, when at most one of the bits is 1, is more efficiently solvable on a CREW PRAM than on any CROW PRAM, but Nisan <ref> [Nis91] </ref> has proved that CROW and CREW 62 PRAMs take the same time (up to a constant) for problems defined over their full domains. (2) The result uses Ramsey theory and relies crucially on the fact that the input integers come from an extremely large domain relative to the number of <p> The CROW PRAM never requires more than a constant factor more time than the CREW PRAM to compute any function defined on a complete domain (although the simulation may require a substantial increase in the number of processors) <ref> [Nis91] </ref>. However, the restriction to the owner write model with a single memory cell per processor seems more drastic for exclusive read machines. A fast simulation of EREW PRAMs by EROW PRAMs seems unlikely.
Reference: [NMT91] <author> K. Nakano, T. Masuzawa, and N. Tokura. </author> <title> A sub-logarithmic time sorting algorithm on a reconfigurable array. </title> <journal> IEICE Transactions, </journal> <volume> E74(11):3894-3901, </volume> <year> 1991. </year>
Reference-contexts: The SUM function has also been previously studied on the reconfigurable mesh. Nakano [Nak93], improving a result of Nakano, Masuzawa and Tokura <ref> [NMT91] </ref>, developed algorithms for summing n binary values on an n fi m reconfigurable mesh in time O (log n= q m= log n).
Reference: [PKR87] <author> V.K. Prasanna Kumar and C.S. Raghavendra. </author> <title> Array processor with multiple broadcasting. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 4 </volume> <pages> 173-190, </pages> <year> 1987. </year>
Reference-contexts: The MPP of Goodyear and NASA is an example of a full-bus two-dimensional mesh computer [Bat80]. Full-bus meshes are generally less powerful than sub-bus meshes: Both PARITY and finding the minimum of input vales requires (p ff ) time for some ff &gt; 0 on full-bus meshes <ref> [BNP91, PKR87] </ref>. Second, there is the reconfigurable mesh, in which every processor connects to the busses by 4 ports (N, S, E, W) - 3 for processors on the sides; 2 for processors in the corners.
Reference: [PS88] <author> Ian Parberry and George Schnitger. </author> <title> Parallel computation with threshold functions. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 36(3) </volume> <pages> 278-302, </pages> <year> 1988. </year>
Reference-contexts: Some practical and theoretical works for parallel machines <ref> [Ble89, Ble90, CBZ90, KRS86, RBJ88, PS88, KRS88] </ref> have suggested that multiprefix operations for certain multiary operators be allowed at unit cost. We will call all such models multiprefix PRAMs. Later we will give a precise definition of multiprefix operations and multiprefix PRAMs. <p> In the case of lower bounds, it still remains to extend the results for unbounded fan-in circuits with more powerful gates as primitives such as those described in [Raz87], [Smo87] and [HMP + 93]. Parberry and Schnitger <ref> [PS88] </ref> defined and analyzed TRAMs (Threshold RAMs) that are CRCW PRAMs whose write resolution rule corresponds to computing a threshold function of the values that processors are attempting to write.
Reference: [PSP93] <author> B. Patt-Shamir and D. Peleg. </author> <title> Time-space tradeoffs for set operations. </title> <journal> Theoretical Computer Science, </journal> <volume> 110 </volume> <pages> 99-129, </pages> <year> 1993. </year>
Reference: [Pud84] <author> Pavel Pudlak. </author> <title> A lower bound on the complexity of branching programs. </title> <editor> In Michal P. Chytil and V. Koubek, editors, </editor> <booktitle> Mathematical Foundations of Computer Science 1984: Proceedings, 11th Symposium, volume 176 of Lecture Notes in Computer Science, </booktitle> <pages> pages 480-485, </pages> <address> Praha, Czechoslovakia, </address> <month> September </month> <year> 1984. </year> <note> Springer-Verlag. 122 </note>
Reference-contexts: For the case of arbitrary branching programs, Pudlak <ref> [Pud84] </ref> used a Ramsey theoretic argument to prove an unconditional size lower bound of log log log n for computing most threshold functions (including majority). Babai et al. [BPRS90] improved this to an unconditional size lower bound of log log n for computing majority.
Reference: [PZ83] <author> Pavel Pudlak and S. Zak. </author> <title> Space complexity of computations. </title> <type> Technical report, </type> <institution> University of Prague, </institution> <year> 1983. </year>
Reference-contexts: An s (n) space bounded nonuniform Turing machine is allowed to hardwire 2 O (s (n)) bits of advice. (See page 279 of Wegner [Weg87] for a definition of nonuniform Turing machines.) 14 Proposition 2.2 (Cobham [Cob66], Pudlak and Zak <ref> [PZ83] </ref>) For any s = (log n), branching programs using space O (log s) compute exactly the same class of functions as nonuniform Turing machines using space O (log s).
Reference: [Ran87] <author> A. G. Ranade. </author> <title> How to emulate shared memory. </title> <booktitle> In 28th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 185-194, </pages> <address> Los Angeles, CA, </address> <month> October </month> <year> 1987. </year> <note> IEEE. </note>
Reference-contexts: The usual solution in this case is to combine messages destined for the same memory location in a single read or write cycle. Such a simulation of a PRIORITY CRCW PRAM by an FFT Network was shown by Ranade <ref> [Ran87] </ref> and this was extended to a variety of other networks by Leighton, Maggs, and Rao [LMR88] among others. Currently there is no practical solution for implementing an n-processor read or write that does better than O (log 2 n) for deterministic schemes or O (log n) for probabilistic schemes.
Reference: [Raz87] <author> A. A. Razborov. </author> <title> Lower bounds for the size of circuits with bounded depth with basis f^; g. </title> <journal> Mat. </journal> <volume> Zametki, </volume> <year> 1987. </year>
Reference-contexts: In the case of lower bounds, it still remains to extend the results for unbounded fan-in circuits with more powerful gates as primitives such as those described in <ref> [Raz87] </ref>, [Smo87] and [HMP + 93]. Parberry and Schnitger [PS88] defined and analyzed TRAMs (Threshold RAMs) that are CRCW PRAMs whose write resolution rule corresponds to computing a threshold function of the values that processors are attempting to write.
Reference: [Raz90] <author> A. A. Razborov. </author> <title> Lower bounds on the size of switching-and-rectifier networks for symmetric boolean functions. </title> <journal> Mathematical Notes of the Academy of Sciences of the USSR, </journal> <volume> 48(6) </volume> <pages> 79-91, </pages> <year> 1990. </year>
Reference-contexts: Corollary 3.6 For the problem of computing majority or mod a;b p every branching program has size log log n and every oblivious branching program of width w p n has length log w . Razborov <ref> [Raz90] </ref>, and Karchmer and Wigderson [KW93] proved unconditional size lower bounds of (n log log log ? n) for computing majority on nondeterministic extensions of the branching program model. Razborov proved it for rectifier-switching networks; Karchmer and Wigderson proved it for span programs.
Reference: [Raz91] <author> A. A. Razborov. </author> <title> Lower bounds for deterministic and nondeterministic branching programs. </title> <editor> In Lothar Budach, editor, </editor> <booktitle> Eighth International Conference on Fundamentals of Computation Theory, volume 529 of Lecture Notes in Computer Science, </booktitle> <pages> pages 47-60, </pages> <address> Gosen, Germany, </address> <month> September </month> <year> 1991. </year> <note> Springer-Verlag. </note>
Reference-contexts: The branching program model seems to fulfill both these requirements. Its many variants have long been popular for studying complexity of functions (see, for example, the survey paper of Razborov <ref> [Raz91] </ref>). It is a simple model which is amenable to combinatorial analysis and at the same time is powerful enough to simulate many other computational models. In particular, it redresses the input addressing mechanism of the Turing machine model by providing random access to inputs. <p> There are several nondeterministic variants of the branching program model where any setting of input corresponds to zero or more paths in the underlying graph. The nondeterministic variants differ in their acceptance criteria as well as on the types of underlying graphs they allow (see Razborov's survey paper <ref> [Raz91] </ref>). (2) It is also possible to define branching programs to compute function over non-Boolean domains. If each input variable comes from a domain of size R, then in the ensuing model each non-sink node has R outgoing edges. <p> Beame and Cook (unpublished) noticed that Neciporuk's technique can be applied to prove the same lower bound for the element distinctness problem. Neciporuk's technique is essentially a counting argument and applies to the stronger switching network model (see <ref> [Raz91] </ref> for definition). Theorem 2.5 [Nec66] Let b 1 ; b 2 ; : : : ; b m be any partition of input variables into m groups. Then setting all variables outside b i gives a sub-function of f on the 19 variables in b i . <p> to a modulo d, for fixed a and d), when d is a prime power close to p n, all previously known constructions for computing mod functions had size (n 3=2 ). (In Section 3.3.4, we outline an obvious construction of size O (n 3=2 log n).) This led Razborov <ref> [Raz91] </ref> to pose the following open problem: Open Problem (Razborov [Raz91]) Does every rectifier-switching network computing the majority of n bits have size n 1+(1) ? 37 We settle this problem in a strong negative way. <p> d is a prime power close to p n, all previously known constructions for computing mod functions had size (n 3=2 ). (In Section 3.3.4, we outline an obvious construction of size O (n 3=2 log n).) This led Razborov <ref> [Raz91] </ref> to pose the following open problem: Open Problem (Razborov [Raz91]) Does every rectifier-switching network computing the majority of n bits have size n 1+(1) ? 37 We settle this problem in a strong negative way.
Reference: [RBJ88] <author> A. G. Ranade, Sandeep Bhatt, and S. L. Johnsson. </author> <title> The Fluent abstract machine. </title> <booktitle> In Proc. 5th M.I.T. Conference on Advanced Research in VLSI, </booktitle> <pages> pages 71-94, </pages> <year> 1988. </year>
Reference-contexts: Some practical and theoretical works for parallel machines <ref> [Ble89, Ble90, CBZ90, KRS86, RBJ88, PS88, KRS88] </ref> have suggested that multiprefix operations for certain multiary operators be allowed at unit cost. We will call all such models multiprefix PRAMs. Later we will give a precise definition of multiprefix operations and multiprefix PRAMs. <p> Again the scan primitives turn out to be very powerful, even for the normally hard case of manipulating irregular and dynamically changing structures. The appendix in Blelloch's Ph.D. thesis [Ble90] gives a brief history of the scan operation. Ranade et al. <ref> [RBJ88] </ref> consider a generalization of the scan operation, where arbitrary partitioning of processors is allowed. The authors give strong justification for an architecture providing these primitives. Because we will be giving a simulation of multiprefix PRAMs, we adopt this (strongest) definition of multiprefix operations.
Reference: [RPK88] <author> D. Reisis and V.K. Prasanna Kumar. </author> <title> VLSI arrays with reconfigurable buses. </title> <booktitle> In Supercomputing 1987, volume 297 of Lecture Notes in Computer Science, </booktitle> <pages> pages 732-743. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: Their simple and regular design has also made them an attractive model with theoreticians interested in designing parallel algorithms. The model has several variants which have all been the subject of extensive study <ref> [HS86, Lei92, LS91, MS89, MPKRS93, RPK88, Sto86] </ref>. We will focus on the sub-bus mesh model, which has been implemented on the commercially available MasPar MP-1 [Bla90]. A sub-bus mesh is a single-instruction multiple-data (SIMD) two-dimensional array of processors. <p> The sub-bus mesh architecture was first investigated by Reisis and Prasanna Kumar <ref> [RPK88] </ref>. We will restate their observations about computing several basic 97 functions. These will be used as subroutines in our optimal algorithm for computing SUM. Proposition 6.3 The OR or AND of input bits can be computed in constant time on any sub-bus mesh.
Reference: [RS62] <author> J. B. Rosser and L. Schoenfeld. </author> <title> Approximate formulas for some functions of prime numbers. </title> <journal> Illinois Journal of Mathematics, </journal> <volume> 6 </volume> <pages> 64-94, </pages> <year> 1962. </year>
Reference-contexts: We can build more complex branching programs by interconnecting many such routers. We will be repeatedly using the following corollary of the prime number theorem. (A proof can be derived from <ref> [RS62, Corollary 1 and 2] </ref>.) 30 Theorem 3.12 For any constant c &gt; 0, there exist constants N; c 0 &gt; 0 such that for all n N , there are at least log log n primes between log n and c 0 log n. <p> See, for example, <ref> [RS62, Equation 3.9] </ref>.) We will describe the construction informally. Start with a p-box and designate its input node 0 as the source node. For 0 i &lt; p, define S i to be the subset of integers from S that reach the output node i of the p-box. <p> Define M = Q (A) p 1 + p 2 + + p k = O log 2 L (C) (2k 2)M 0 &lt; 8L Proof: From <ref> [RS62, Theorem 4] </ref> we know that there is a constant C 0 such that for L C 0 , the product of all primes between log L and 4 log L is at least L 4 log L . <p> It is known that the least common multiple of all integers between 1 and x is at most (2:83) x <ref> [RS62, Theorem 12] </ref>. Thus the least common multiple of all numbers in SMALL is at most (2:83) * log n * log n 4 = n *=2 . <p> Because of Proposition 3.19 and the fact that the product of all primes less than x is 2 O (x) ( <ref> [RS62, Equation 3:15] </ref>), any MA-program computing a function with non-constant discriminator (we define discriminator in Theorem 3.40) has at least one box with non-constant modulus. In other words, for computing functions with non-constant discriminators, MA-programs can not be used to construct constant 56 width branching programs. <p> Because each of the p input integers is an O (log p) bit integer, from <ref> [RS62, Equation 3:16, page 70] </ref>, we get t = O (log p). Now apply the algorithm in the previous lemma on a p p p mesh, for this choice of t, and m = & log p ' .
Reference: [Smo87] <author> Roman Smolensky. </author> <title> Algebraic methods in the theory of lower bounds for Boolean circuit complexity. </title> <booktitle> In Proceedings of the Nineteenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 77-82, </pages> <address> New York, NY, </address> <month> May </month> <year> 1987. </year> <month> 123 </month>
Reference-contexts: Then by Corollary 5.13, there is an unbounded fan-in circuit with AND, OR, NOT, M OD m gates of depth O (T ) and size p O (T ) which computes M OD r . However, Smolensky <ref> [Smo87] </ref> proved that any such circuit has size (2 n 1=2T ). <p> In the case of lower bounds, it still remains to extend the results for unbounded fan-in circuits with more powerful gates as primitives such as those described in [Raz87], <ref> [Smo87] </ref> and [HMP + 93]. Parberry and Schnitger [PS88] defined and analyzed TRAMs (Threshold RAMs) that are CRCW PRAMs whose write resolution rule corresponds to computing a threshold function of the values that processors are attempting to write.
Reference: [Sni85] <author> Marc Snir. </author> <title> On parallel searching. </title> <journal> SIAM Journal on Computing, </journal> <volume> 14 </volume> <pages> 688-708, </pages> <year> 1985. </year>
Reference-contexts: most popular variants of the PRAM model and separations between variants of the CRCW, and between the CRCW and CREW models have already been shown, the big open problem is to determine the relative power of CREW and EREW PRAMs. 4.4 Previous Attempts at Separating CREW and EREW PRAMs Snir <ref> [Sni85] </ref> proved that the problem of searching a sorted list is more difficult on the EREW PRAM than on the CREW PRAM.
Reference: [ST94] <author> R. Sinha and J. Thathachar. </author> <title> Efficient oblivious branching programs for threshold functions. </title> <booktitle> In Proceedings 35th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 309-317, </pages> <address> Santa Fe, NM, </address> <month> November </month> <year> 1994. </year> <note> IEEE. </note>
Reference: [Sto86] <author> Q. F. Stout. </author> <title> Meshes with multiple buses. </title> <booktitle> In 27th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 264-273, </pages> <address> Toronto, Ontario, </address> <month> October </month> <year> 1986. </year> <note> IEEE. </note>
Reference-contexts: Their simple and regular design has also made them an attractive model with theoreticians interested in designing parallel algorithms. The model has several variants which have all been the subject of extensive study <ref> [HS86, Lei92, LS91, MS89, MPKRS93, RPK88, Sto86] </ref>. We will focus on the sub-bus mesh model, which has been implemented on the commercially available MasPar MP-1 [Bla90]. A sub-bus mesh is a single-instruction multiple-data (SIMD) two-dimensional array of processors.
Reference: [SV84] <author> Larry J. Stockmeyer and Uzi Vishkin. </author> <title> Simulation of parallel random access machines by circuits. </title> <journal> SIAM Journal on Computing, </journal> <volume> 13(2) </volume> <pages> 409-422, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: The simulation is straightforward: the PRAM has a cell for each gate of the circuit and a processor for each edge and values are propagated from the input of the circuit towards its output node. Stockmeyer and Vishkin <ref> [SV84] </ref> showed a simulation of CRCW PRAMs by unbounded fan-in circuits. Their result is somewhat unsatisfactory because, for their simulation, they have to severely restrict the instruction set of processors in CRCW PRAMs, disallowing even natural operations like multiplication. Theorem 5.6 (Stockmeyer and Vishkin [SV84]) A priority PRAM with p processors <p> Stockmeyer and Vishkin <ref> [SV84] </ref> showed a simulation of CRCW PRAMs by unbounded fan-in circuits. Their result is somewhat unsatisfactory because, for their simulation, they have to severely restrict the instruction set of processors in CRCW PRAMs, disallowing even natural operations like multiplication. Theorem 5.6 (Stockmeyer and Vishkin [SV84]) A priority PRAM with p processors running in time T , where each processor has a limited instruction set and the input is given in n blocks of n bits each, can be simulated by an unbounded fan-in circuit of depth O (T ) and size bounded by a polynomial <p> Parberry and Schnitger [PS88] defined and analyzed TRAMs (Threshold RAMs) that are CRCW PRAMs whose write resolution rule corresponds to computing a threshold function of the values that processors are attempting to write. Parberry and Schnitger, by using techniques of Stockmeyer and Vishkin <ref> [SV84] </ref>, were able to show an efficient simulation of TRAMs by threshold circuits which are unbounded fan-in circuits with gates computing AND, OR, NOT, and threshold functions. Our techniques can be employed to give an alternate proof of their result.
Reference: [Tom78] <author> Martin Tompa. </author> <title> Time-Space Tradeoffs for Straight-Line and Branching Programs. </title> <type> PhD thesis, </type> <institution> University of Toronto, </institution> <month> July </month> <year> 1978. </year> <note> Department of Computer Science Technical Report 122/78. </note>
Reference-contexts: As another example, the Turing machine model can not differentiate between the complexity of sorting n integers and merging two sorted lists of n integers each <ref> [Tom78] </ref>; even though merging seems an easier problem to compute on real machines. RAMs are an attractive model because of their closeness to real machines.
Reference: [vEB90] <author> Peter van Emde Boas. </author> <title> Machine models and simulations. </title> <editor> In Jan Van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume A: Algorithms and Complexity, chapter 1, </booktitle> <pages> pages 1-66. </pages> <publisher> M.I.T. </publisher> <address> Press/Elsevier, </address> <year> 1990. </year>
Reference-contexts: The time and space requirements of branching programs give a lower bound on the (respective) time and space requirements of logarithmic cost RAMs. (See page 23 of van Emde Boas <ref> [vEB90] </ref> for a definition of the logarithmic cost RAM model.) There are several possible ways of defining space on logarithmic cost RAMs (see the discussion on page 27 of [vEB90]). <p> a lower bound on the (respective) time and space requirements of logarithmic cost RAMs. (See page 23 of van Emde Boas <ref> [vEB90] </ref> for a definition of the logarithmic cost RAM model.) There are several possible ways of defining space on logarithmic cost RAMs (see the discussion on page 27 of [vEB90]). The following proposition holds for any definition of space which ensures that the space requirement of any particular computation is greater than or equal to the number of bits needed to describe configurations of the machine during this computation.
Reference: [VW85] <author> Uzi Vishkin and Avi Wigderson. </author> <title> Trade-offs between depth and width in parallel computation. </title> <journal> SIAM Journal on Computing, </journal> <volume> 14(2) </volume> <pages> 303-314, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: We define communication width of a PRAM to be the number of common cells, that is cells that are available for reading as well as writing. We denote by EREW (m), CREW (m), and CRCW (m) the respective PRAM models with communication width m. Vishkin and Wigderson <ref> [VW85] </ref> initiated the study of PRAMs with bounded communication width. Their paper gives several motivations for studying such models. For example, the "Ethernet" can be thought of 60 as a PRAM with one common cell. <p> Our hope is that some of the techniques developed for small communication widths will turn out to be useful even for the general case. For example, the technique in the lower bound result for the OR function on CREW (1) PRAMs <ref> [VW85, Bea86] </ref> is very similar to the technique that Kuty lowski [Kut91] eventually used in his optimal bound for the OR on general CREW PRAMs. Our lower bound proof consists of three parts. <p> Since shared memory is the only means of communication, we can assume that for any PRAM running for t steps, only the processors that 65 write by time t are involved in the computation. The bounds in [Bea86] (see also <ref> [VW85] </ref>) show that for any CREW (1) PRAM at time t and for any given input vector e, at least a 2 O (t 2 ) fraction of all inputs vectors are indistinguishable from e, from the point of view of any individual processor. <p> Our lower bound proofs proceed by fixing the history of the common cells. We use the following result of Vishkin and Wigderson <ref> [VW85] </ref>. Lemma 4.6 [VW85] For any CRCW (m) PRAM computing any function F and running for t steps, there is a restriction r of F which sets at most m 2 variables such that the history of the common cells for the first t steps is the same for all inputs <p> Our lower bound proofs proceed by fixing the history of the common cells. We use the following result of Vishkin and Wigderson <ref> [VW85] </ref>. Lemma 4.6 [VW85] For any CRCW (m) PRAM computing any function F and running for t steps, there is a restriction r of F which sets at most m 2 variables such that the history of the common cells for the first t steps is the same for all inputs consistent with r. <p> There is at least some precedence for this: Kuty lowski's [Kut91] optimal lower bound for general CREW PRAMs, computing the OR function, uses techniques similar to the lower bound result, for the OR function, on CREW (1) PRAMs <ref> [VW85, Bea86] </ref>.
Reference: [Weg87] <author> Ingo Wegner. </author> <title> The Complexity of Boolean Functions. </title> <publisher> John Wiley & Sons, </publisher> <year> 1987. </year>
Reference-contexts: To relate their power to those of Turing machines, we also need to define nonuniform versions of Turing machines. An s (n) space bounded nonuniform Turing machine is allowed to hardwire 2 O (s (n)) bits of advice. (See page 279 of Wegner <ref> [Weg87] </ref> for a definition of nonuniform Turing machines.) 14 Proposition 2.2 (Cobham [Cob66], Pudlak and Zak [PZ83]) For any s = (log n), branching programs using space O (log s) compute exactly the same class of functions as nonuniform Turing machines using space O (log s). <p> Proof sketch: We will state the basic intuition of the proof; a complete proof appears on page 415 of Wegner <ref> [Weg87] </ref>. Given a branching program, a Turing machine can compute the same function by simulating the path from source to the sink node that is consistent with the given input. <p> The following theorem relates the size complexity of branching programs to size complexities of circuits and formulas (see Wegner <ref> [Weg87] </ref> for definitions of circuits and formulas). Proposition 2.4 The size complexity of any Boolean function in the branching program model is at least one third of its circuit size and at most one more than its formula size. <p> Proof sketch: The proof is not very hard (and can be found, for example, on page 416 of <ref> [Weg87] </ref>). Given a branching program, we will define a transformation to obtain an equivalent circuit. First, we reverse all the edges and make the source node the output node of the circuit. <p> Then the size of any branching program computing f is i=1 log log s i (f ) Proof sketch: We will state the basic intuition behind the proof; a complete proof is given on page 422 of <ref> [Weg87] </ref>. Start with a branching program for computing f . Partition the nodes of the branching program based on the input variable they are reading. Let t i be the number of nodes reading a variable in b i .
Reference: [Yao79] <author> A. C. Yao. </author> <title> Some complexity questions related to distributive computing. </title> <booktitle> In Conference Record of the Eleventh Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 209-213, </pages> <address> Atlanta, GA, </address> <month> April-May </month> <year> 1979. </year> <month> 124 </month>
Reference-contexts: We will consider two variations: (1) worst-partition communication complexity measures the maximum amount of communication needed, over all possible partitions. (2) optimal-partition communication complexity measures the minimum amount of communication needed, over all possible partitions. The communication complexity measure was first introduced by Yao <ref> [Yao79] </ref> and has turned out to be very useful in a number of contexts (e.g., circuit depth lower bound, VLSI time area trade-off). There are several papers containing detailed and precise treatment (see, for example, Karchmer's thesis [Kar89]).
Reference: [Yao83] <author> A. C. Yao. </author> <title> Lower bounds by probabilistic arguments. </title> <booktitle> In 24th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 420-428, </pages> <address> Tucson, AZ, </address> <month> November </month> <year> 1983. </year> <note> IEEE. </note>
Reference-contexts: The hope is that the insight gained might eventually be of use in attacking the general model. 3.1.1 Constant Width Branching Programs For the case of width two branching programs, Borodin et al. [BDFP86] proved an n 2 length lower bound for computing the majority function. Yao <ref> [Yao83] </ref> improved this to a super-polynomial lower bound. Shearer (unpublished) proved an exponential lower bound for the problem of checking whether the number of 1's in the input is a multiple of three. For width three or more, the best lower bound for a symmetric function is much smaller. <p> For a long time it was widely believed that any constant width branching program for computing majority must have super-polynomial length. The lower bound results of Borodin et al. [BDFP86] and Yao <ref> [Yao83] </ref>, described earlier, were seen as steps leading to a proof of super-polynomial lower bound on the length of constant width branching programs computing majority. Barrington [Bar89], in a very surprising result, proved that there are polynomial size branching programs of width five for computing majority.
Reference: [Yao85] <author> A. C. Yao. </author> <title> Separating the polynomial hierarchy by oracles: Part I. </title> <booktitle> In 26th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 1-10, </pages> <address> Portland, OR, </address> <month> October </month> <year> 1985. </year> <note> IEEE. </note>
Reference-contexts: Using the known lower bounds on parity <ref> [H-as87, FSS81, Yao85, Ajt83] </ref>, they managed to prove a non-constant time lower bound for the problem of computing parity on PRAMs with polynomial number of processors.
Reference: [Yao88] <author> A. C. Yao. </author> <title> Near-optimal time-space tradeoff for element distinctness. </title> <booktitle> In 29th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 91-97, </pages> <address> White Plains, NY, </address> <month> October </month> <year> 1988. </year> <note> IEEE. To appear in SIAM Journal on Computing. </note>
References-found: 101

