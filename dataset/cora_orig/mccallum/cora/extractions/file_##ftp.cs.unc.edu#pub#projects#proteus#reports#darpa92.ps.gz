URL: file://ftp.cs.unc.edu/pub/projects/proteus/reports/darpa92.ps.gz
Refering-URL: http://www.cs.unc.edu/Research/proteus/proteus-publications.html
Root-URL: http://www.cs.unc.edu
Title: Prototyping High-Performance Parallel Computing Applications in Proteus  
Author: Peter H. Mills Lars S. Nyland Jan F. Prins John H. Reif 
Note: In Proceedings of the 1992 DARPA Software Technology Conference, (Los Angeles, California, April 27-30), pp. 433-442, Meridian, 1992. Abstract  
Address: Durham, N.C. 27706 Chapel Hill, N.C. 27599-3175 USA  
Affiliation: Department of Computer Science, Department of Computer Science, Duke University, University of North Carolina,  
Abstract: This paper explores the use of Proteus, an architecture-independent language suitable for prototyp-ing time-sensitive parallel and distributed programs. Pro-teus is a high-level imperative notation based on sets and sequences with succinct yet powerful constructs for the parallel composition of processes communicating through shared memory. Several different parallel algorithms for N-body simulation in molecular dynamics are presented in Proteus, illustrating how Proteus provides a common foundation for expressing the various parallel programming models. This common foundation supports the construction of high-performance computing applications across a wide range of parallel machines through a development methodology in which prototype parallel programs can be tested and evolved without the use of machine-specific languages. To transform prototypes to implementations on specific architectures, program refinement techniques are utilized. Refinement strategies are illustrated that target broad-spectrum parallel intermediate languages, and their viability is demonstrated by refining an N-body algorithm to data-parallel intermediate code. Time-sensitive variants of a parallel N-body algorithm are also described to illustrate how Proteus allows the expression of resource requirements through real-time constraints as well as progress constraints which abstractly specify the distribution of computational resources. 
Abstract-found: 1
Intro-found: 1
Reference: [Agh90] <author> G. Agha, </author> <title> "Concurrent object-oriented programming," </title> <journal> Comm. ACM, </journal> <volume> vol. 33, </volume> <pages> pp. 125-141, </pages> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: It follows that await [true ! S] is equivalent to atomic execution of S, which we abbreviate as t S . 2.2. Concurrent objects Proteus also provides high-level constructs for controlling process parallelism based on the notion of concurrent objects <ref> [Agh90] </ref>. These features are built upon an extension of the ML-style type system which supports parametric polymorphism as well as object-oriented notions of subtyping and inheritance [MMM+91, BG90]. <p> A corresponding explicit receive construct waits for data computed by the asynchronous method to become available. These constructs correspond to an object-based view of fork/join, and behave analogously to the definition variables in PCN, futures in MultiLisp, and actors <ref> [Agh90] </ref>. Proteus also provides for active objects which have running reactive processes associated with them, as well as object constraints which enforce required exclusion among concurrently executing methods.
Reference: [App85] <author> A. W. Appel, </author> <title> "An efficient program for many-body simulation," </title> <journal> Siam J. Sci. Stat. Comput., </journal> <volume> vol. 6, </volume> <pages> pp. 85-103, </pages> <month> Jan. </month> <year> 1985. </year>
Reference-contexts: The N-body problem characterizes physical phenomena that arise in many important applications in fields such as astrophysics, plasma physics, and fluid mechanics as well as molecular dynamics <ref> [App85, Gre90] </ref>. While numerical solutions for the N-body problem are thus critically needed, they unfortunately require large amounts of computation due to the typically large number of particles and nature of the N 2 pairwise interaction. Many algorithmic refinements have been proposed to render N-body simulation more tractable. <p> Many algorithmic refinements have been proposed to render N-body simulation more tractable. These include methods which approximate interaction of a particle with a cluster of particles that are far away by modeling the cluster as a single particle (so-called far-field interactions) <ref> [App85] </ref>, and tree-code methods which compute far-field interactions by recursively decomposing the spatial domain [BH86]. A further optimization is obtained by the Fast Multipole Method [Gre90], which uses multigrid techniques and multi-pole approximations for far clusters to yield a faster and more accurate algorithm.
Reference: [BC90] <author> G. Blelloch and S. Chatterjee, </author> <title> "VCODE: a data-parallel intermediate language," </title> <booktitle> in Proc. Frontiers 90, IEEE, </booktitle> <year> 1990. </year>
Reference-contexts: For example, we intend initially to reduce data-parallelism to the set of parallel vector operations provided by the CVL library [BCSZ90], developed by Guy Blel-loch and colleagues at Carnegie-Mellon as a machine-independent library used in the interpretation of the data-parallel intermediate code VCODE <ref> [BC90] </ref>. Likewise, we intend to reduce process parallelism to the set of procedures provided with the threads facility of Mach [BRS + 85]. 3.3. Refinement to SIMD We now apply these strategies to our N-body program to yield execution on an SIMD architecture.
Reference: [BCSZ90] <author> G. Blelloch, S. Chatterjee, J. Sipelstein, and M. Zahga, "CVL: </author> <title> A C vector library," </title> <type> Draft Technical Note, </type> <institution> Carnegie Mellon University, </institution> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: For example, we intend initially to reduce data-parallelism to the set of parallel vector operations provided by the CVL library <ref> [BCSZ90] </ref>, developed by Guy Blel-loch and colleagues at Carnegie-Mellon as a machine-independent library used in the interpretation of the data-parallel intermediate code VCODE [BC90]. Likewise, we intend to reduce process parallelism to the set of procedures provided with the threads facility of Mach [BRS + 85]. 3.3.
Reference: [BG90] <author> L. Blaine and A. Goldberg, </author> <title> "Modules and types for a common prototyping language," </title> <type> Technical Report, </type> <institution> Kestrel Institute, Palo Alto, California, </institution> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: Concurrent objects Proteus also provides high-level constructs for controlling process parallelism based on the notion of concurrent objects [Agh90]. These features are built upon an extension of the ML-style type system which supports parametric polymorphism as well as object-oriented notions of subtyping and inheritance <ref> [MMM+91, BG90] </ref>. The type system permits algebraic specification in the familiar form of modules, while providing separation of module specifications from implementations, analogous to Ada packages. Other distinguishing features of the type system include an identification of types with modules and the ability to specify parameterized modules. <p> The KIDS system (Kestrel Interactive Development System) [Smi90] has been used to develop programs from specifications, and includes a number of algorithm design tactics and data refinement transformations <ref> [BG90] </ref>. Providing refinement techniques to target many specific architectures is likely to be prohibitive, hence our strategy is to refine to existing or proposed intermediate languages which permit reasonably efficient execution on a class of parallel platforms.
Reference: [BH86] <author> J. Barnes and P. Hut, </author> <title> "A hierarchical O(N log N) force-calculation algorithm," </title> <journal> Nature, </journal> <volume> vol. 324, </volume> <pages> pp. 446-449, </pages> <year> 1986. </year>
Reference-contexts: These include methods which approximate interaction of a particle with a cluster of particles that are far away by modeling the cluster as a single particle (so-called far-field interactions) [App85], and tree-code methods which compute far-field interactions by recursively decomposing the spatial domain <ref> [BH86] </ref>. A further optimization is obtained by the Fast Multipole Method [Gre90], which uses multigrid techniques and multi-pole approximations for far clusters to yield a faster and more accurate algorithm. <p> Note that, although the entire cluster array CL is declared as private, Proteus implementations need only copy on demand referenced boundary elements. The same technique of state isolation can be applied to parallelize further optimizations of the N-body simulation, specifically for Barnes-Hut tree-codes <ref> [BH86] </ref> and the Fast Multipole Method [Gre90]. Both employ a hierarchical decomposition of cluster space, such as quad-trees for 2D or oct-trees for 3D, which can be used to recursively partition areas of otherwise near-body interaction so as to treat them as far-body effects.
Reference: [BRS + 85] <author> R. Baron, R. Rashid, E. Siegel, A. Tevanian, and M. Young, "Mach-1: </author> <title> An operating environment for large-scale multiprocessor applications," </title> <journal> IEEE Software, </journal> <month> July </month> <year> 1985. </year>
Reference-contexts: Languages for these asynchronous distributed-state systems include CSP [Hoa85] and Strand [FT90]. Shared-memory multiprocessors, like the Multimax or the Sequent, are typically programmed using languages that support shared variables with access-exclusion and synchronization mechanisms like monitors, such as found in Concurrent Pascal, or threads such as found in Mach <ref> [BRS + 85] </ref>. Highly-parallel processors such as the TMC CM-2 or the MasPar MP-1 are programmed using data-parallel operations and barrier synchronization. Families of abstract computational models for these classes of synchronous and asynchronous shared-memory machines may be found in the PRAM and APRAM respectively [CZ89]. <p> Likewise, we intend to reduce process parallelism to the set of procedures provided with the threads facility of Mach <ref> [BRS + 85] </ref>. 3.3. Refinement to SIMD We now apply these strategies to our N-body program to yield execution on an SIMD architecture. <p> To execute this prototype, the control-parallelism of the group of parallel cluster processes can be straightforwardly implemented, if needed, in terms of threads (for example in Mach <ref> [BRS + 85] </ref>). A key point is that each cluster process can be vectorized since it uses the same techniques as the simple Proteus program for pairwise interaction.
Reference: [BS90] <author> G. Blelloch and G. Sabot, </author> <title> "Compiling collection-oriented languages into massively parallel computers," </title> <journal> Journal of Par. and Distr. Computing, </journal> <volume> vol. 8, </volume> <pages> pp. 119-134, </pages> <year> 1990. </year>
Reference-contexts: In order to target SIMD execution, we must refine the program to separate the reduction operation from the nested sequence generators, and combine the nested sequence generators into one. We do this by following techniques outlined in <ref> [BS90] </ref>, yielding a form of the program that can be translated to vector operations. In this case we performed the refinement and translation manually, but based on insights gained from this experiment we are developing tools in the Refine system to perform these steps semi-automatically. <p> Transform elwise (f ,...) operations into applications of the vector extension of f derived by converting scalar operations in f to vector operations. This corresponds to compiling Paralation "elwise" forms into vector operations, a topic ad dressed in detail in <ref> [BS90] </ref>. 3. Transform segmented reduction (using g) into vector operations, either by deriving from the scalar operations of g a sequence of segmented reductions, or by using the vector extension of g to implement the reduction using well-known techniques such as doubling.
Reference: [CG91] <author> M. Carriero and D. Gelernter, </author> <title> "Coordination Languages and Their Significance," </title> <journal> Comm. ACM, </journal> <volume> vol. 35, </volume> <pages> pp. 96-107, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Often called coordination languages, these form a harness in which programs in different sequential computation languages can cooperate in parallel <ref> [CG91] </ref>. * Languages which incorporate a large variety of par allel primitives, such as Ease [Zen90]. * Wide-spectrum parallel languages that rely on refinement from architecture-independent specification. Notable wide-spectrum parallel language efforts include Crystal [Che86] and variants of the Bird-Meertens functional formalism [Ski90].
Reference: [CGL86] <author> N. Carriero, D. Gelernter, and J. Leichter, </author> <title> "Dis--tributed data structures in Linda," </title> <booktitle> in Proc. 13th ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pp. 236-242, </pages> <publisher> ACM, </publisher> <year> 1986. </year>
Reference-contexts: Related work A variety of parallel languages are cited as being useful for programming broad classes of concurrent systems. These languages might be roughly divided into the following categories. * Languages with widely translatable logical models, such as Linda's distributed data structures <ref> [CGL86] </ref>, the synchronization-variable methods of Strand [FT90] and PCN [CT92], or the data-parallel abstraction of the Paralation model [Sab88].
Reference: [Che86] <author> M. Chen, </author> <title> "Very-high-level parallel programming in Crystal," </title> <booktitle> in Proc. 1986 Hypercube Conference, </booktitle> <address> (Knoxville,Tn.), </address> <year> 1986. </year>
Reference-contexts: Notable wide-spectrum parallel language efforts include Crystal <ref> [Che86] </ref> and variants of the Bird-Meertens functional formalism [Ski90]. UNITY [CM88], although not a wide-spectrum notation, is, as its name suggests, a particularly elegant notation for describing a large range of parallel and distributed computations. We see Proteus as falling into the last category.
Reference: [CM88] <author> K. Chandy and J. Misra, </author> <title> Parallel Program Design, A Foundation. </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: Notable wide-spectrum parallel language efforts include Crystal [Che86] and variants of the Bird-Meertens functional formalism [Ski90]. UNITY <ref> [CM88] </ref>, although not a wide-spectrum notation, is, as its name suggests, a particularly elegant notation for describing a large range of parallel and distributed computations. We see Proteus as falling into the last category.
Reference: [CT92] <author> K. Chandy and S. Taylor, </author> <title> An Introduction to Parallel Programming. </title> <publisher> Jones & Bartlett, </publisher> <year> 1992. </year>
Reference-contexts: These languages might be roughly divided into the following categories. * Languages with widely translatable logical models, such as Linda's distributed data structures [CGL86], the synchronization-variable methods of Strand [FT90] and PCN <ref> [CT92] </ref>, or the data-parallel abstraction of the Paralation model [Sab88].
Reference: [CZ89] <author> R. Cole and O. Zajicek, </author> <title> "The APRAM: Incorporating asynchrony into the PRAM model," </title> <booktitle> in Proc. 1st ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 169-178, </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: Highly-parallel processors such as the TMC CM-2 or the MasPar MP-1 are programmed using data-parallel operations and barrier synchronization. Families of abstract computational models for these classes of synchronous and asynchronous shared-memory machines may be found in the PRAM and APRAM respectively <ref> [CZ89] </ref>. The proliferation of languages following different concurrent programming paradigms targeting different architectures, together with the emergence of heterogeneous systems and mixed-mode architectures, pose problems for software development by increasing the complexity of programming and by reducing software portability, reuse, and reliability. <p> The semantics then associates, for each admissible execution history, a probability in a manner analogous to that for variable-speed APRAM's <ref> [CZ89] </ref>. The rate construct proves advantageous in several ways. The specification of expected rate of progress is interpreted as a scheduling directive that, when simulating execution of prototypes, allows experimentation to predict real-time behavior.
Reference: [Dij78] <author> E. Dijkstra, </author> <title> "Guarded commands, nondetermi-nacy and the formal derivation of programs," </title> <journal> Comm. ACM, </journal> <volume> vol. 18, </volume> <pages> pp. 453-457, </pages> <year> 1978. </year>
Reference-contexts: Figure 1 summarizes a number of control operators over sequences of statements and the familiar syntax that may be used when all of the statement values are explicit rather than generated. While the guarded command constructs behave similarly to those of Dijkstra and Hoare <ref> [Dij78, Hoa85] </ref> | for example, the rep operator repeatedly executes one command selected arbitrarily from those with true guards until all guards are false | Proteus provides greater expressive power by permitting operands to be dynamically generated by sequence construction. 2.1.
Reference: [F + 88] <author> G. Fox et al., </author> <title> Solving problems on concurrent processors. </title> <publisher> Prentice-Hall, </publisher> <year> 1988. </year>
Reference-contexts: At the end of the simulation step the private clusters are merged: this effects exchange of boundary cells between clusters since they are effectively recopied as privates in the next par cycle. This corresponds to exchanging guard strips in other multigrid simulations <ref> [F + 88] </ref>. Note that, although the entire cluster array CL is declared as private, Proteus implementations need only copy on demand referenced boundary elements.
Reference: [FT90] <author> I. Foster and S. Taylor, Strand: </author> <title> New Concepts in Parallel Programming. </title> <publisher> Prentice-Hall, </publisher> <year> 1990. </year>
Reference-contexts: Languages for these asynchronous distributed-state systems include CSP [Hoa85] and Strand <ref> [FT90] </ref>. Shared-memory multiprocessors, like the Multimax or the Sequent, are typically programmed using languages that support shared variables with access-exclusion and synchronization mechanisms like monitors, such as found in Concurrent Pascal, or threads such as found in Mach [BRS + 85]. <p> Related work A variety of parallel languages are cited as being useful for programming broad classes of concurrent systems. These languages might be roughly divided into the following categories. * Languages with widely translatable logical models, such as Linda's distributed data structures [CGL86], the synchronization-variable methods of Strand <ref> [FT90] </ref> and PCN [CT92], or the data-parallel abstraction of the Paralation model [Sab88].
Reference: [GG89] <author> L. Greengard and W. Gropp, </author> <title> "A parallel version of the fast multipole method," in Parallel Processing for Scientific Computing (G. </title> <editor> Ro-drigue, ed.), p. </editor> <volume> 213, </volume> <publisher> SIAM, </publisher> <year> 1989. </year>
Reference-contexts: A further optimization is obtained by the Fast Multipole Method [Gre90], which uses multigrid techniques and multi-pole approximations for far clusters to yield a faster and more accurate algorithm. To further decrease computational complexity, parallel implementations of these algorithms have also been explored <ref> [GG89] </ref>, in particular on data-parallel architectures such as the Connection Machine [ZJ89]. In following sections we consider two parallel algorithms for N-body simulation. We first present a simple N 2 interaction per step simulation, and refine this algorithm toward a highly-parallel SIMD architecture.
Reference: [GL91] <author> R. Gerber and I. Lee, </author> <title> "Specification and Analysis of Resource-Bound Real-Time Systems," </title> <type> Techical Report MS-CIS-91-96, </type> <institution> University of Pennsylvania, </institution> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: Among the Proteus primitives are: wait t [delay] await G: wait t ! (stmt) [guarded timeouts] every t (stmt) [periodicity] within t (stmt) on timeout (stmt) [response time] S1 on E F1 () [exception handlers] These primitives encompass conventional real-time constructs such as those found in <ref> [GL91] </ref>. An alternative form under consideration is that of the Flex language, in which conditions specifying inequalities on start, finish, interval and duration times can be attached to timing blocks [KL91]. Our measurement of time relies fundamentally on viewing clocks as modules. <p> configuration Real-time behavior will depend not only on synchronization and time constraints, but also on resource requests such as demands for computation, on the resource configuration which maps requesting agents such as processes to resources such as processors, and on scheduling which attempts to resolve resource contention and satisfy requests <ref> [GL91] </ref>. It is often critical to make the resource configuration explicit in order to ensure precise real-time behavior. For example, concurrent processes which are configured to run on one processor using interleaving may not satisfy the same time constraints as processes running truly concurrently.
Reference: [Gre90] <author> L. Greengard, </author> <title> "The numerical solution of the N-body problem," </title> <booktitle> Computers in Physics, </booktitle> <pages> pp. 142-152, </pages> <month> Mar. </month> <year> 1990. </year>
Reference-contexts: The N-body problem characterizes physical phenomena that arise in many important applications in fields such as astrophysics, plasma physics, and fluid mechanics as well as molecular dynamics <ref> [App85, Gre90] </ref>. While numerical solutions for the N-body problem are thus critically needed, they unfortunately require large amounts of computation due to the typically large number of particles and nature of the N 2 pairwise interaction. Many algorithmic refinements have been proposed to render N-body simulation more tractable. <p> A further optimization is obtained by the Fast Multipole Method <ref> [Gre90] </ref>, which uses multigrid techniques and multi-pole approximations for far clusters to yield a faster and more accurate algorithm. To further decrease computational complexity, parallel implementations of these algorithms have also been explored [GG89], in particular on data-parallel architectures such as the Connection Machine [ZJ89]. <p> Note that, although the entire cluster array CL is declared as private, Proteus implementations need only copy on demand referenced boundary elements. The same technique of state isolation can be applied to parallelize further optimizations of the N-body simulation, specifically for Barnes-Hut tree-codes [BH86] and the Fast Multipole Method <ref> [Gre90] </ref>. Both employ a hierarchical decomposition of cluster space, such as quad-trees for 2D or oct-trees for 3D, which can be used to recursively partition areas of otherwise near-body interaction so as to treat them as far-body effects.
Reference: [GSL90] <author> A. Grimshaw, A. Silberman, and J. Liu, </author> <title> "Real-Time Mentat Programming Language and Architecture," </title> <booktitle> in Proc. 7th IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <address> (Charlottesville, Virginia, May.1990), </address> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference-contexts: These declarative assertions appear in the specification side of the module, whereas directives appear in the implementation or body of the module. This is similar in style to [LVB+91], and differs from Mentat <ref> [GSL90] </ref> in which declarative assertions appear in the object while directives appear in the method. 6. Summary and future work In this paper we explored the use of Proteus, a prototyping language whose constructs for parallelism can serve as a foundation for expressing many concurrent programming models.
Reference: [Hoa85] <author> C. Hoare, </author> <title> Communicating Sequential Processes. </title> <publisher> Addison-Wesley, </publisher> <year> 1985. </year>
Reference-contexts: Languages for these asynchronous distributed-state systems include CSP <ref> [Hoa85] </ref> and Strand [FT90]. Shared-memory multiprocessors, like the Multimax or the Sequent, are typically programmed using languages that support shared variables with access-exclusion and synchronization mechanisms like monitors, such as found in Concurrent Pascal, or threads such as found in Mach [BRS + 85]. <p> Figure 1 summarizes a number of control operators over sequences of statements and the familiar syntax that may be used when all of the statement values are explicit rather than generated. While the guarded command constructs behave similarly to those of Dijkstra and Hoare <ref> [Dij78, Hoa85] </ref> | for example, the rep operator repeatedly executes one command selected arbitrarily from those with true guards until all guards are false | Proteus provides greater expressive power by permitting operands to be dynamically generated by sequence construction. 2.1.
Reference: [HGS90] <author> H. Heller, H. Grubmuller, and K. Schulten, </author> <title> "Molecular Dynamics Simulation on a Parallel Computer," </title> <journal> Molecular Simulation, </journal> <volume> vol. 5, </volume> <pages> pp 133-165, </pages> <year> 1990. </year>
Reference-contexts: Such simulations are critical in molecular biology in order to understand the function and properties of biological polymers such as proteins and nucleic acids on the atomic level, and might help to guide the synthesis of new materials and predict the properties of materials such as drug specificities <ref> [HGS90] </ref>. The energy and forces acting on each molecule have contributions from different sources, which may be divided into internal energies and forces connected with chemical bonds and their angles and torsional motion, and non-bonding energy and force contributions arising from pairwise electrostatic interaction of atomic charges. <p> The forces connected with chemical bonds may be determined fairly rapidly; by far the most time-consuming task in molecular dynamics simulations is the evaluation of pairwise particle interactions to determine non-bonding forces <ref> [MTB+91, HGS90] </ref>. The computational core of molecular dynamics simulation is thus the task of N-body simulation | that is, given a collection of N particles (or bodies) dis-tributed in space, to simulate the motion of the particles over time due to gravitational or electrostatic interaction.
Reference: [KL91] <author> K. Kenny and K. Lin, </author> <title> "Building Flexible Real-Time Systems Using the Flex Language," </title> <journal> IEEE Computer, </journal> <volume> vol. 24, </volume> <pages> pp. 70-78, </pages> <month> May. </month> <year> 1991. </year>
Reference-contexts: An alternative form under consideration is that of the Flex language, in which conditions specifying inequalities on start, finish, interval and duration times can be attached to timing blocks <ref> [KL91] </ref>. Our measurement of time relies fundamentally on viewing clocks as modules. Time parameters represent ticks on some named virtual clock, which is updated according to an underlying model of time and computation related to that found in [LVB+91].
Reference: [LVB+91] <author> D. Luckham, J. Vera, D. Bryan, L. Augustin, and F. Belz, </author> <title> "Partial Orderings of Event Sets and Their Application to Prototyping Concurrent Timed Systems," </title> <type> Draft Technical Report, </type> <institution> Computing Systems Laboratory, Stanford University, </institution> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: Our measurement of time relies fundamentally on viewing clocks as modules. Time parameters represent ticks on some named virtual clock, which is updated according to an underlying model of time and computation related to that found in <ref> [LVB+91] </ref>. A "clock" is just a module with an active process responsible for updating the clock and distributing its values to a set of processes which it is said to "time". A clock times those processes which are visible from its module as determined by standard scoping rules. <p> These declarative assertions appear in the specification side of the module, whereas directives appear in the implementation or body of the module. This is similar in style to <ref> [LVB+91] </ref>, and differs from Mentat [GSL90] in which declarative assertions appear in the object while directives appear in the method. 6.
Reference: [MMM+91] <author> J. Mitchell, S. Meldal, N. Madhav, and D.Katiyar, </author> <title> "An extension of standard ML modules with subtyping and inheritance," </title> <booktitle> in Proc. 17th ACM Symp. on Principles of Programming Languages, ACM, </booktitle> <year> 1991. </year>
Reference-contexts: Concurrent objects Proteus also provides high-level constructs for controlling process parallelism based on the notion of concurrent objects [Agh90]. These features are built upon an extension of the ML-style type system which supports parametric polymorphism as well as object-oriented notions of subtyping and inheritance <ref> [MMM+91, BG90] </ref>. The type system permits algebraic specification in the familiar form of modules, while providing separation of module specifications from implementations, analogous to Ada packages. Other distinguishing features of the type system include an identification of types with modules and the ability to specify parameterized modules.
Reference: [MNP + 91] <author> P. H. Mills, L. S. Nyland, J. F. Prins, J. H. Reif, and R. W. Wagner, </author> <title> "Prototyping parallel and distributed programs in proteus," </title> <booktitle> in Proc. 3rd IEEE Symp. on Parallel and Distributed Processing, IEEE, </booktitle> <year> 1991. </year>
Reference-contexts: The remainder of this paper begins in Section 2 with an overview of Proteus: a more detailed description of the language can be found in <ref> [Nyl91, MNP + 91] </ref>. In Section 3 one variant of an N-body algorithm is expressed in Proteus and then targeted to a data-parallel SIMD execution model, while another variant is evolved towards an MIMD execution model in Section 4.
Reference: [MTB+91] <author> J. Mertz, D. Toblas, C. Brooks III, and U. Singh, </author> <title> "Vector and Parallel Algorithms for the Molecular Dynamics Simulation of Macromolecules on Shared-Memory Computers," </title> <journal> Journal of Computational Chemistry, </journal> <volume> vol. 12, </volume> <pages> pp 1270-1277, </pages> <year> 1991. </year>
Reference-contexts: The forces connected with chemical bonds may be determined fairly rapidly; by far the most time-consuming task in molecular dynamics simulations is the evaluation of pairwise particle interactions to determine non-bonding forces <ref> [MTB+91, HGS90] </ref>. The computational core of molecular dynamics simulation is thus the task of N-body simulation | that is, given a collection of N particles (or bodies) dis-tributed in space, to simulate the motion of the particles over time due to gravitational or electrostatic interaction.
Reference: [Nyl91] <author> L. S. Nyland, </author> <title> The Design of A Prototyping Programming Language for Parallel and Sequential Algorithms. </title> <type> Ph.D. dissertation, </type> <institution> Duke University, </institution> <month> Feb. 3 </month> <year> 1991. </year>
Reference-contexts: The remainder of this paper begins in Section 2 with an overview of Proteus: a more detailed description of the language can be found in <ref> [Nyl91, MNP + 91] </ref>. In Section 3 one variant of an N-body algorithm is expressed in Proteus and then targeted to a data-parallel SIMD execution model, while another variant is evolved towards an MIMD execution model in Section 4.
Reference: [Ref88] <institution> Reasoning Systems, Inc., Palo Alto, California, Refine 2.0 Language Summary, </institution> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: We conclude the paper with a discussion of ongoing research. 2. Basic features of Proteus Our language starts with rich data models and operators along the lines of SETL [SDDS86] and REFINE <ref> [Ref88] </ref>, which employ the high-level mathematical notions of sets, sequences, and maps. The core of our language is a conventional imperative notation to the degree that it is assignment-based and block-structured; program state is maintained in typed, lexically-scoped variables, and assignment statements or procedure calls modify this state.
Reference: [Sab88] <author> G. Sabot, </author> <title> The Paralation Model: Architecture-Independent Parallel Programming. </title> <publisher> MIT, </publisher> <year> 1988. </year>
Reference-contexts: Each private variable has its values in all processes combined using a specified merge function f , and the result updates the corresponding variable in the enclosing scope. This combining action is similar to that used to resolve conflict in message collisions <ref> [Sab88] </ref>, although Proteus applies the reduction of f only across the changed values from all processes. <p> These languages might be roughly divided into the following categories. * Languages with widely translatable logical models, such as Linda's distributed data structures [CGL86], the synchronization-variable methods of Strand [FT90] and PCN [CT92], or the data-parallel abstraction of the Paralation model <ref> [Sab88] </ref>. Often called coordination languages, these form a harness in which programs in different sequential computation languages can cooperate in parallel [CG91]. * Languages which incorporate a large variety of par allel primitives, such as Ease [Zen90]. * Wide-spectrum parallel languages that rely on refinement from architecture-independent specification.
Reference: [SDDS86] <author> J. Schwartz, R. Dewar, E. Dubinsky, and E. Schonberg, </author> <title> Programming with Sets, An Introduction to SETL. </title> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: We conclude the paper with a discussion of ongoing research. 2. Basic features of Proteus Our language starts with rich data models and operators along the lines of SETL <ref> [SDDS86] </ref> and REFINE [Ref88], which employ the high-level mathematical notions of sets, sequences, and maps.
Reference: [Ski90] <author> D. Skillicorn, </author> <title> "Architecture-independent parallel computation," </title> <journal> IEEE Computer, </journal> <volume> vol. 23, </volume> <pages> pp. 38-50, </pages> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: Notable wide-spectrum parallel language efforts include Crystal [Che86] and variants of the Bird-Meertens functional formalism <ref> [Ski90] </ref>. UNITY [CM88], although not a wide-spectrum notation, is, as its name suggests, a particularly elegant notation for describing a large range of parallel and distributed computations. We see Proteus as falling into the last category. <p> One promising avenue for data type and algorithmic refinement relies on techniques to recognize the presense of CVL patterns such as elwise and product operations, as well as transformational strategies based on algebraic laws for functional languages <ref> [Ski90] </ref>. 4. Far-field approximation We now consider an evolution of the original Pro-teus N-body simulation program that yields a parallel algorithm suitable for targeting asynchronous collections of SIMD processors. We take advantage of the far-field approximation mentioned earlier.
Reference: [Smi90] <author> D. R. Smith, </author> <title> "KIDS a semi-automatic program development system," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 16, </volume> <pages> pp. 1024-1043, </pages> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: The KIDS system (Kestrel Interactive Development System) <ref> [Smi90] </ref> has been used to develop programs from specifications, and includes a number of algorithm design tactics and data refinement transformations [BG90].
Reference: [Zen90] <author> S. Zenith, </author> <title> "Programming with Ease: a semiotic definition of the language," </title> <institution> Research Report RR809, Yale University, </institution> <month> July </month> <year> 1990. </year>
Reference-contexts: Often called coordination languages, these form a harness in which programs in different sequential computation languages can cooperate in parallel [CG91]. * Languages which incorporate a large variety of par allel primitives, such as Ease <ref> [Zen90] </ref>. * Wide-spectrum parallel languages that rely on refinement from architecture-independent specification. Notable wide-spectrum parallel language efforts include Crystal [Che86] and variants of the Bird-Meertens functional formalism [Ski90].
Reference: [ZJ89] <author> F. Zhao and S. L. Johnsson, </author> <title> "The Parallel Mul-tipole Method on the Connection Machine," </title> <institution> Research Report CS89-6, Massachusetts Institute of Technology, </institution> <month> Oct. </month> <year> 1989. </year>
Reference-contexts: To further decrease computational complexity, parallel implementations of these algorithms have also been explored [GG89], in particular on data-parallel architectures such as the Connection Machine <ref> [ZJ89] </ref>. In following sections we consider two parallel algorithms for N-body simulation. We first present a simple N 2 interaction per step simulation, and refine this algorithm toward a highly-parallel SIMD architecture. Next a variant of the algorithm is considered that utilizes far-field interactions. <p> We are examining prototypes of parallel Fast Multipole algorithms in Proteus which isolate boundary cell communication while at the lowest level are vectorizable | how these can be efficiently implemented on asynchronous collections of SIMD processors, or can be refined into existing data-parallel Mul-tipole methods <ref> [ZJ89] </ref> is still being investigated. 5. Time and progress constraints Lastly we examine mechanisms in Proteus for specifying time and progress-constrained computation, and illustrate their utility on a variation of the N-body algorithm.
References-found: 36

