URL: ftp://mesquite.cs.panam.edu/pub/MENG/reno92.ps
Refering-URL: http://www.cs.panam.edu/meng/pub.html
Root-URL: http://www.cs.panam.edu
Email: dfinkel@cs.wpi.edu  meng@bucknell.edu  
Title: A Simulation Study of an Integrated Fault Tolerant and Load Sharing Distributed Computing System  
Author: David Finkel Xiannong Meng Sanjay Parikh 
Address: Worcester, MA 01609  Lewisburg, PA 17837  Worcester, MA 01609  
Affiliation: Department of Computer Science Worcester Polytechnic Institute  Department of Computer Science Bucknell University  Department of Computer Science Worcester Polytechnic Institute  
Abstract: A scheme for combining fault tolerance and load sharing in a distributed computing system is proposed. A simulation model is constructed, using the SIMAN simulation language, to determine the performance characteristics of this integrated scheme. The overall performance results show that a distributed system using this integrated scheme has better performance than a system without fault tolerance or load sharing, showing that the costs of implementing the fault tolerance are outweighed by the performance advantages of the load sharing. 
Abstract-found: 1
Intro-found: 1
Reference: [EAG86] <author> D.L. Eager, E.D. Lazowska, and J. Za-horjan, </author> <title> "Adaptive Load Sharing in Homogeneous Distributed Systems," </title> <journal> IEEE Trans. Soft. Eng. </journal> <volume> SE-12 (1986), </volume> <pages> 662-675. </pages>
Reference-contexts: Status information on all nodes is immediately available through the use of global variables. This is justified by the observation that the messages being exchanged are very small, and that network congestion is not typically a significant source of delay <ref> [EAG86] </ref>. 2.2 Experimental Settings All times in the model are exponentially distributed, although models were tested with non-exponential service times. The service time distribution is fixed with a mean of 1, and the arrival rate is varied to produce the desired system load. <p> The most interesting observation from these Tables, however, is that the smaller threshold values give the best performance. Smaller thresholds mean that the system is more likely to attempt load sharing. That lower thresholds lead to better performance is in agreement with the results obtained by other researchers <ref> [EAG86] </ref> [SHI89]. Finally, Table 5 shows a comparison of our integrated scheme with a system which does not implement load sharing or fault tolerance, as measured by average job response time. This system without load sharing or fault tolerance is just modeled as an M/M/1 queue.
Reference: [GRA91] <author> J. Gray and D.P. </author> <title> Siewiorek, </title> <journal> "High-Availability Computer Systems", IEEE Computer, </journal> <volume> vol. 24, no. </volume> <month> 9 (Sept. </month> <year> 1991), </year> <pages> 39 - 48. </pages>
Reference-contexts: In this way, a failure at a single node can be masked by invoking that node's backup. Several methods for achieving this have been proposed. In this paper we use a method similar to [FIN90], a process pair approach <ref> [GRA91] </ref> in which each process started at any node has a backup process on another node, which can be started in case of failure at the pri-mary node.
Reference: [FIN90] <author> D. Finkel, and S.K. Tripathi, </author> <title> "A Performance Analysis of a Buddy System for Fault Tolerance", Performance Evaluation 11, </title> <month> 177 - 185 </month> <year> (1990). </year>
Reference-contexts: In case of failure of a node, its jobs can be executed on the nodes where they are backed fl This research was supported by the National Science Foundation under grant CCR-8802584. up. These two services are based on approaches in [SHI89] and <ref> [FIN90] </ref>, respectively. The distributed system we consider consists of identical computers (nodes), which are able to communicate with each other directly via a network. Each node receives its own input stream of jobs, and is able to complete its jobs independently. <p> In this way, a failure at a single node can be masked by invoking that node's backup. Several methods for achieving this have been proposed. In this paper we use a method similar to <ref> [FIN90] </ref>, a process pair approach [GRA91] in which each process started at any node has a backup process on another node, which can be started in case of failure at the pri-mary node. <p> In this way each node is the backup to exactly one other node. When a node completes a job, it informs the backup node, so that the backup copy of this job can be discarded. This scheme is described in greater detail in <ref> [FIN90] </ref>. 1.3 Integrated System Several modifications are made to the above schemes to incorporate them into an integrated system. If a node transfers a job as part of the load sharing scheme, it keeps a copy of the job as the backup.
Reference: [LIV82] <author> M. Livny and M. Melman, </author> <title> "Load Balancing in Homogeneous Broadcast Distributed Systems", </title> <booktitle> Proceedings of the Computer Network Symposium, </booktitle> <address> College Park, Maryland, </address> <note> April 1982; Performance Evaluation Review, 11 (1982), 47 - 55. </note>
Reference-contexts: The impetus for load sharing is the observation that even in a heavily loaded system, there is a high probability that one or more nodes is idle <ref> [LIV82] </ref>, and the observation that in many real systems, there are many idle workstations [OUS87]. Many schemes for load sharing have been proposed; in this paper we will consider a sender-initiated threshold scheme similar to that proposed by Shin and Chang [SHI89].
Reference: [OUS87] <author> J. Ousterhout and F. Douglis, </author> <title> "Process Migration in the Sprite Operating System", </title> <booktitle> IEEE Proceedings of 7th Conference on Distributed Computing (1987), </booktitle> <volume> 18 - 25. </volume>
Reference-contexts: The impetus for load sharing is the observation that even in a heavily loaded system, there is a high probability that one or more nodes is idle [LIV82], and the observation that in many real systems, there are many idle workstations <ref> [OUS87] </ref>. Many schemes for load sharing have been proposed; in this paper we will consider a sender-initiated threshold scheme similar to that proposed by Shin and Chang [SHI89].
Reference: [PEG90] <author> C.D. Pegden, R.E. Shannon, and R.P. Sadowski, </author> <title> Introduction to Simulation Using SIMAN, </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: The rest of the data was divided into batches, and confidence intervals were then built based on the batch means. The results are presented in the next section. 2.3 Model Implementation This model was implemented in the SIMAN simulation language <ref> [PEG90] </ref>. SIMAN was chosen because its many advanced modeling features greatly simplified the construction and analysis of our simulation model. One of the key features of the SIMAN language we employed was the STATION construct.

References-found: 6

