URL: ftp://archive.cis.ohio-state.edu/pub/neuroprose/maass.third-generation.ps.Z
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00105.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: maass@igi.tu-graz.ac.at  
Title: Networks of Spiking Neurons: The Third Generation of Neural Network Models  
Author: Wolfgang Maass 
Date: April 18, 1996  
Address: Klosterwiesgasse 32/2 A-8010 Graz, Austria  
Affiliation: Institute for Theoretical Computer Science Technische Universitaet Graz  
Abstract: The computational power of formal models for networks of spiking neurons is compared with that of other neural network models based on McCulloch Pitts neurons (i.e. threshold gates) respectively sigmoidal gates. In particular it is shown that networks of spiking neurons are computationally more powerful than these other neural network models. A concrete biologically relevant function is exhibited which can be computed by a single spiking neuron (for biologically reasonable values of its parameters), but which requires hundreds of hidden units on a sigmoidal neural net. This article does not assume prior knowledge about spiking neurons, and it contains an extensive list of references to the currently available literature on computations in networks of spiking neurons and relevant results from neuro biology.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Abeles, Corticonics: </author> <title> Neural Circuits of the Cerebral Cortex, </title> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: There exist a number of variations of this model, which are described and compared in the recent survey (see [15]). With regard to the relationship of these mathematical models to the known behaviour of biological neurons we refer to <ref> [1] </ref>, [3], [4], [8], [9], [20], [24], [56], [57], and [63]. These mathematical models for spiking neurons do not provide a complete description of the extremely complex computational function of a biological neuron. <p> time t when P v (t) fi v (t t 0 ) &lt; 0 . 6 The previously described noisy version of the SNN model is basically identical with the spike response model in [15], [16], and with the other common mathematical models for networks of spiking neurons (see e.g. <ref> [1] </ref>, [4], [63]). Subtle differences exist between these models with regard to their treatment of the refractory effects and the "reset" of the membrane potential after a firing. But these differences will be irrelevant for the results that are considered in this article. <p> But these differences will be irrelevant for the results that are considered in this article. For theoretical results about stable states, synfire chains, associative memory etc. in networks of spiking neurons we refer to [10], <ref> [1] </ref>, [14], [16], [17], [51], [7], [19], [21]. Results about computations with stochastic spiking neurons in firing rate coding can be found in [28], [55], and results about the information transmitted by spiking neurons in [61]. <p> However neural nets from all three generations are also able to process numerical inputs from R n or <ref> [0; 1] </ref> n , instead of just boolean inputs from f0; 1g n . <p> Consider a threshold circuit that outputs 1 for inputs x 1 ; x 2 ; x 3 2 <ref> [0; 1] </ref> if x 1 +x 2 = x 3 , and 0 else. Obviously this can be achieved by a circuit with just 3 threshold gates: the circuit outputs 1 if (x 1 + x 2 x 3 AND x 1 + x 2 x 3 ) . <p> Obviously this can be achieved by a circuit with just 3 threshold gates: the circuit outputs 1 if (x 1 + x 2 x 3 AND x 1 + x 2 x 3 ) . However it has been shown that this function from <ref> [0; 1] </ref> 3 into f0; 1g (as well as any restriction to [0; fl] 3 for some fl &gt; 0) cannot be computed by any network of spiking neurons of type A, no matter how many neurons and how much computation time it employs. <p> Theorem 4 Any threshold circuit with s gates can be simulated for real valued inputs from <ref> [0; 1] </ref> n by a network of O (s) spiking neurons of type B. Proof: Consider first an arbitrary threshold gate G with inputs hx 1 ; : : : ; x n i from [0; 1] n that outputs 1 if P n i=1 ff i x i ff 0 <p> 4 Any threshold circuit with s gates can be simulated for real valued inputs from <ref> [0; 1] </ref> n by a network of O (s) spiking neurons of type B. Proof: Consider first an arbitrary threshold gate G with inputs hx 1 ; : : : ; x n i from [0; 1] n that outputs 1 if P n i=1 ff i x i ff 0 , and 0 else. We show that G can be simulated by a network of a fixed number (i.e.
Reference: [2] <author> M. Abeles, H. Bergman, E. Margalit, E. and Vaadia, </author> <title> "Spatiotemporal firing patterns in the frontal cortex of behaving monkeys", </title> <journal> J. of Neurophysiology, </journal> <volume> vol. 70, </volume> <pages> pp 1629-1638, </pages> <year> 1993. </year>
Reference-contexts: This time span is known to suffice for the completion of some complex multilayer cortical computations. On the other hand experimental evidence has accumulated during the last few years which indicates that many biological neural systems use the timing of single action potentials (or "spikes") to encode information ([1], <ref> [2] </ref>, [6], [3], [4], [5], [13], [20], [27], [33], [54], [58], [59], [62]). These experimental results from neurobiology have lead to the investigation of a third generation of neural network models wich employ spiking neurons (or "integrate and fire neurons") as computational units.
Reference: [3] <author> A. Aertsen, ed., </author> <title> Brain Theory: Spatio-Temporal Aspects of Brain Function, </title> <address> El-sevier, </address> <year> 1993. </year>
Reference-contexts: On the other hand experimental evidence has accumulated during the last few years which indicates that many biological neural systems use the timing of single action potentials (or "spikes") to encode information ([1], [2], [6], <ref> [3] </ref>, [4], [5], [13], [20], [27], [33], [54], [58], [59], [62]). These experimental results from neurobiology have lead to the investigation of a third generation of neural network models wich employ spiking neurons (or "integrate and fire neurons") as computational units. <p> There exist a number of variations of this model, which are described and compared in the recent survey (see [15]). With regard to the relationship of these mathematical models to the known behaviour of biological neurons we refer to [1], <ref> [3] </ref>, [4], [8], [9], [20], [24], [56], [57], and [63]. These mathematical models for spiking neurons do not provide a complete description of the extremely complex computational function of a biological neuron.
Reference: [4] <author> M. A. Arbib, ed., </author> <title> The Handbook of Brain Theory and Neural Networks, </title> <publisher> MIT-Press, </publisher> <address> Cambridge, </address> <year> 1995. </year>
Reference-contexts: On the other hand experimental evidence has accumulated during the last few years which indicates that many biological neural systems use the timing of single action potentials (or "spikes") to encode information ([1], [2], [6], [3], <ref> [4] </ref>, [5], [13], [20], [27], [33], [54], [58], [59], [62]). These experimental results from neurobiology have lead to the investigation of a third generation of neural network models wich employ spiking neurons (or "integrate and fire neurons") as computational units. <p> There exist a number of variations of this model, which are described and compared in the recent survey (see [15]). With regard to the relationship of these mathematical models to the known behaviour of biological neurons we refer to [1], [3], <ref> [4] </ref>, [8], [9], [20], [24], [56], [57], and [63]. These mathematical models for spiking neurons do not provide a complete description of the extremely complex computational function of a biological neuron. <p> t when P v (t) fi v (t t 0 ) &lt; 0 . 6 The previously described noisy version of the SNN model is basically identical with the spike response model in [15], [16], and with the other common mathematical models for networks of spiking neurons (see e.g. [1], <ref> [4] </ref>, [63]). Subtle differences exist between these models with regard to their treatment of the refractory effects and the "reset" of the membrane potential after a firing. But these differences will be irrelevant for the results that are considered in this article.
Reference: [5] <author> W. Bair, C. Koch, W. Newsome, K. and Britten, </author> <title> "Reliable temporal modulation in cortical spike trains in the awake monkey", </title> <booktitle> Proc. of the Symposium on Dynamics of Neural Processing, </booktitle> <address> Washington, USA, </address> <year> 1994. </year>
Reference-contexts: On the other hand experimental evidence has accumulated during the last few years which indicates that many biological neural systems use the timing of single action potentials (or "spikes") to encode information ([1], [2], [6], [3], [4], <ref> [5] </ref>, [13], [20], [27], [33], [54], [58], [59], [62]). These experimental results from neurobiology have lead to the investigation of a third generation of neural network models wich employ spiking neurons (or "integrate and fire neurons") as computational units.
Reference: [6] <author> W. Bialek, and F. Rieke, </author> <title> "Reliability and information transmission in spiking neurons", </title> <journal> Trends in Neuroscience, </journal> <volume> vol. 15, </volume> <pages> pp 428-434, </pages> <year> 1992. </year>
Reference-contexts: On the other hand experimental evidence has accumulated during the last few years which indicates that many biological neural systems use the timing of single action potentials (or "spikes") to encode information ([1], [2], <ref> [6] </ref>, [3], [4], [5], [13], [20], [27], [33], [54], [58], [59], [62]). These experimental results from neurobiology have lead to the investigation of a third generation of neural network models wich employ spiking neurons (or "integrate and fire neurons") as computational units.
Reference: [7] <author> E. </author> <title> Bienenstock, "A model of neocortex", Network: </title> <booktitle> Computation in Neural Systems, </booktitle> <volume> vol. 6, </volume> <pages> pp 179-224, </pages> <year> 1995. </year> <month> 18 </month>
Reference-contexts: But these differences will be irrelevant for the results that are considered in this article. For theoretical results about stable states, synfire chains, associative memory etc. in networks of spiking neurons we refer to [10], [1], [14], [16], [17], [51], <ref> [7] </ref>, [19], [21]. Results about computations with stochastic spiking neurons in firing rate coding can be found in [28], [55], and results about the information transmitted by spiking neurons in [61].
Reference: [8] <author> J. M. Bower, and D. Beeman, </author> <title> The Book of GENESIS: Exploring Realistic Neural Models with the GEneral NEural SImulation System, </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: There exist a number of variations of this model, which are described and compared in the recent survey (see [15]). With regard to the relationship of these mathematical models to the known behaviour of biological neurons we refer to [1], [3], [4], <ref> [8] </ref>, [9], [20], [24], [56], [57], and [63]. These mathematical models for spiking neurons do not provide a complete description of the extremely complex computational function of a biological neuron.
Reference: [9] <author> P. S. Churchland, and T. J. Sejnowski, </author> <title> The Computational Brain, </title> <publisher> MIT-Press, </publisher> <year> 1993. </year>
Reference-contexts: There exist a number of variations of this model, which are described and compared in the recent survey (see [15]). With regard to the relationship of these mathematical models to the known behaviour of biological neurons we refer to [1], [3], [4], [8], <ref> [9] </ref>, [20], [24], [56], [57], and [63]. These mathematical models for spiking neurons do not provide a complete description of the extremely complex computational function of a biological neuron.
Reference: [10] <author> M. C. Crair, and W. Bialek, </author> <title> "Non-Boltzmann dynamics in networks of spiking neurons", </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> vol. 2, </volume> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <pages> pp 109-116, </pages> <year> 1990. </year>
Reference-contexts: But these differences will be irrelevant for the results that are considered in this article. For theoretical results about stable states, synfire chains, associative memory etc. in networks of spiking neurons we refer to <ref> [10] </ref>, [1], [14], [16], [17], [51], [7], [19], [21]. Results about computations with stochastic spiking neurons in firing rate coding can be found in [28], [55], and results about the information transmitted by spiking neurons in [61].
Reference: [11] <author> B. DasGypta, G. Schnitger, </author> <title> "Analog versus discrete neural networks", </title> <type> preprint, </type> <year> (1996). </year>
Reference-contexts: These nets are also able to compute (with the help of rounding at the network output) arbitrary boolean functions. Actually it has been shown that neural nets from the second generation can compute certain boolean functions with fewer gates than neural nets from the first generation ([41], <ref> [11] </ref>). In addition, neural nets from the second generation are able to compute functions with analog input and output.
Reference: [12] <author> R. J. Douglas, C. Koch, M. Mahowald, K. A. C. Martin, and H. H. </author> <title> Suarez, "Recurrent excitation in neocortical circuits", </title> <journal> Science, </journal> <volume> vol. 269, </volume> <pages> pp 981-985, </pages> <year> 1995. </year>
Reference-contexts: Recently, one has also started to carry out experiments with related new types of electronic hardware such as pulse stream VLSI (see e.g. [46], [50], [22], [43], [44], [48], [47], <ref> [12] </ref>, [23]). In these new chips one 3 can encode analog variables by time differences between pulses, which has practical advantages over other encoding methods. <p> Obviously these constraints have basically no impact on theoretical complexity investigations (just consider pairs of excitatory and inhibitory neurons instead of single neurons), unless one cares about small constant factors in the size of networks, or one wants to model the actual architecture of cortical circuits (see <ref> [12] </ref>, [57]). It is mathematically more convenient to assume that the potential P v has value 0 in the absence of postsynaptic potentials, and that the threshold value fi v is always &gt; 0 .
Reference: [13] <author> D. Ferster, and N. Spruston, N., </author> " <title> Cracking the neuronal code", </title> <journal> Science, </journal> <volume> vol. 270, </volume> <pages> p 756-757, </pages> <year> 1995. </year>
Reference-contexts: On the other hand experimental evidence has accumulated during the last few years which indicates that many biological neural systems use the timing of single action potentials (or "spikes") to encode information ([1], [2], [6], [3], [4], [5], <ref> [13] </ref>, [20], [27], [33], [54], [58], [59], [62]). These experimental results from neurobiology have lead to the investigation of a third generation of neural network models wich employ spiking neurons (or "integrate and fire neurons") as computational units.
Reference: [14] <author> W. Gerstner, </author> <title> "Associative memory in a network of 'biological' neurons", </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> vol. 3, </volume> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <pages> pp 84-90, </pages> <year> 1991 </year>
Reference-contexts: But these differences will be irrelevant for the results that are considered in this article. For theoretical results about stable states, synfire chains, associative memory etc. in networks of spiking neurons we refer to [10], [1], <ref> [14] </ref>, [16], [17], [51], [7], [19], [21]. Results about computations with stochastic spiking neurons in firing rate coding can be found in [28], [55], and results about the information transmitted by spiking neurons in [61].
Reference: [15] <author> W. Gerstner, </author> <title> "Time structure of the activity in neural network models", </title> <journal> Phys. Rev. </journal> <volume> E vol. 51, </volume> <pages> pp 738-758, </pages> <year> 1995. </year>
Reference-contexts: Mathematical models for "integrate and fire neurons" (or "spiking neurons" as they have been called more recently) can be traced back to [31] (see [63]). There exist a number of variations of this model, which are described and compared in the recent survey (see <ref> [15] </ref>). With regard to the relationship of these mathematical models to the known behaviour of biological neurons we refer to [1], [3], [4], [8], [9], [20], [24], [56], [57], and [63]. <p> v (t)fi v (tt 0 ) &gt; 0 , or that v fires "spontaneously" at a time t when P v (t) fi v (t t 0 ) &lt; 0 . 6 The previously described noisy version of the SNN model is basically identical with the spike response model in <ref> [15] </ref>, [16], and with the other common mathematical models for networks of spiking neurons (see e.g. [1], [4], [63]). Subtle differences exist between these models with regard to their treatment of the refractory effects and the "reset" of the membrane potential after a firing.
Reference: [16] <author> W. Gerstner, and J. L. van Hemmen, </author> <title> "How to describe neuronal activity: spikes, rates, or assemblies?", </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> vol. 6, </volume> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <pages> pp 463-470, </pages> <year> 1994. </year>
Reference-contexts: (t)fi v (tt 0 ) &gt; 0 , or that v fires "spontaneously" at a time t when P v (t) fi v (t t 0 ) &lt; 0 . 6 The previously described noisy version of the SNN model is basically identical with the spike response model in [15], <ref> [16] </ref>, and with the other common mathematical models for networks of spiking neurons (see e.g. [1], [4], [63]). Subtle differences exist between these models with regard to their treatment of the refractory effects and the "reset" of the membrane potential after a firing. <p> But these differences will be irrelevant for the results that are considered in this article. For theoretical results about stable states, synfire chains, associative memory etc. in networks of spiking neurons we refer to [10], [1], [14], <ref> [16] </ref>, [17], [51], [7], [19], [21]. Results about computations with stochastic spiking neurons in firing rate coding can be found in [28], [55], and results about the information transmitted by spiking neurons in [61].
Reference: [17] <author> W. Gerstner, R. Ritz, and J. L. van Hemmen, </author> <title> "A biologically motivated and analytically soluble model of collective oscillations in the cortex: I. Theory of weak locking", </title> <journal> Biol. Cybern., </journal> <volume> vol. 68, </volume> <pages> pp 363-374, </pages> <year> 1993. </year>
Reference-contexts: But these differences will be irrelevant for the results that are considered in this article. For theoretical results about stable states, synfire chains, associative memory etc. in networks of spiking neurons we refer to [10], [1], [14], [16], <ref> [17] </ref>, [51], [7], [19], [21]. Results about computations with stochastic spiking neurons in firing rate coding can be found in [28], [55], and results about the information transmitted by spiking neurons in [61].
Reference: [18] <author> P. W. Goldberg, and M. R. Jerrum, </author> <title> "Bounding the Vapnik-Chervonenkis dimension of concept classes parameterized by real numbers", </title> <journal> Machine Learning, </journal> <volume> vol. 18, </volume> <pages> pp 131-148, </pages> <year> 1995. </year>
Reference-contexts: The fact that N computes CD n implies that N 0 shatters S (with regard to different assignments to these s programmable parameters). Thus N 0 has a VC-dimension of at least n . On the other hand the results of Goldberg and Jerrum <ref> [18] </ref> and Karpinski and Macintyre [26] imply that in this case the number s of programmable parameters in N satisfies n = O (s 2 ) in the case of piecewise polynomial activation functions, respectively n = O (s 4 ) in the case of piecewise exponential activation functions. 2.2 Computation
Reference: [19] <author> M. Herrmann, J. A. Hertz, and A. Prugel-Bennett, </author> <title> "Analysis of synfire chains", </title> <type> Nordita preprint, 95/5 S. </type>
Reference-contexts: But these differences will be irrelevant for the results that are considered in this article. For theoretical results about stable states, synfire chains, associative memory etc. in networks of spiking neurons we refer to [10], [1], [14], [16], [17], [51], [7], <ref> [19] </ref>, [21]. Results about computations with stochastic spiking neurons in firing rate coding can be found in [28], [55], and results about the information transmitted by spiking neurons in [61].
Reference: [20] <author> J. J. </author> <title> Hopfield, "Pattern recognition computation using action potential timing for stimulus representations", </title> <journal> Nature, </journal> <volume> vol. 376, </volume> <pages> pp 33-36, </pages> <year> 1995. </year> <month> 19 </month>
Reference-contexts: On the other hand experimental evidence has accumulated during the last few years which indicates that many biological neural systems use the timing of single action potentials (or "spikes") to encode information ([1], [2], [6], [3], [4], [5], [13], <ref> [20] </ref>, [27], [33], [54], [58], [59], [62]). These experimental results from neurobiology have lead to the investigation of a third generation of neural network models wich employ spiking neurons (or "integrate and fire neurons") as computational units. <p> There exist a number of variations of this model, which are described and compared in the recent survey (see [15]). With regard to the relationship of these mathematical models to the known behaviour of biological neurons we refer to [1], [3], [4], [8], [9], <ref> [20] </ref>, [24], [56], [57], and [63]. These mathematical models for spiking neurons do not provide a complete description of the extremely complex computational function of a biological neuron. <p> For networks of spiking neurons it is natural to encode a numerical input variable x i 2 R by the firing time T in x i c of input neuron a i (see also <ref> [20] </ref>), where c &gt; 0 is some constant.
Reference: [21] <author> J. J. Hopfield, and A. V. M. Herz, </author> <title> "Rapid local synchronization of action po-tentials: Towards computation with coupled integrate-and-fire neurons", </title> <journal> Proc. Natl. Acad. Sci., </journal> <volume> vol. 92, </volume> <pages> pp 6655-6662, </pages> <year> 1995. </year>
Reference-contexts: But these differences will be irrelevant for the results that are considered in this article. For theoretical results about stable states, synfire chains, associative memory etc. in networks of spiking neurons we refer to [10], [1], [14], [16], [17], [51], [7], [19], <ref> [21] </ref>. Results about computations with stochastic spiking neurons in firing rate coding can be found in [28], [55], and results about the information transmitted by spiking neurons in [61].
Reference: [22] <author> T. Horinchi, J. Lazzaro, A. Moore, and C. Koch, </author> <title> "A delay-line based motion detection chip",Advances in Neural Information Processing Systems, </title> <journal> vol. </journal> <volume> 3, </volume> <publisher> Mor-gan Kaufmann, </publisher> <address> San Mateo, </address> <pages> pp 406-412, </pages> <year> 1991. </year>
Reference-contexts: Recently, one has also started to carry out experiments with related new types of electronic hardware such as pulse stream VLSI (see e.g. [46], [50], <ref> [22] </ref>, [43], [44], [48], [47], [12], [23]). In these new chips one 3 can encode analog variables by time differences between pulses, which has practical advantages over other encoding methods.
Reference: [23] <author> A. Jahnke, U. Roth, and H. Klar, </author> <title> "Towards efficient hardware for spike-processing neural networks", </title> <booktitle> Proc. of the World Congress on Neural Networks, </booktitle> <address> Washington, </address> <year> 1995. </year>
Reference-contexts: Recently, one has also started to carry out experiments with related new types of electronic hardware such as pulse stream VLSI (see e.g. [46], [50], [22], [43], [44], [48], [47], [12], <ref> [23] </ref>). In these new chips one 3 can encode analog variables by time differences between pulses, which has practical advantages over other encoding methods.
Reference: [24] <author> D. Johnston, and S. M. Wu, </author> <title> Foundations of Cellular Neurophysiology, </title> <publisher> MIT-Press, </publisher> <address> Cambridge, </address> <year> 1995. </year>
Reference-contexts: There exist a number of variations of this model, which are described and compared in the recent survey (see [15]). With regard to the relationship of these mathematical models to the known behaviour of biological neurons we refer to [1], [3], [4], [8], [9], [20], <ref> [24] </ref>, [56], [57], and [63]. These mathematical models for spiking neurons do not provide a complete description of the extremely complex computational function of a biological neuron.
Reference: [25] <author> K. T. Judd, and K. Aihara, </author> <title> "Pulse propagation networks: A neural network model that uses temporal coding by action potentials", </title> <booktitle> Neural Networks, </booktitle> <volume> vol. 6, </volume> <pages> pp 203-215, </pages> <year> 1993. </year>
Reference-contexts: Results about computations with stochastic spiking neurons in firing rate coding can be found in [28], [55], and results about the information transmitted by spiking neurons in [61]. Computations with a somewhat different model of a stochastic spiking neuron are studied in <ref> [25] </ref> (see also the discussion in [36]), and in [55], [65]. We use in this article the terms analog, numerical and real-valued interchangeably to denote variables that range over R or an interval of R .
Reference: [26] <author> M. Karpinski, and A. Macintyre, </author> <title> "Polynomial bounds for VC-dimension of sig-moidal and general Pfaffian neural networks", </title> <note> to appear in the J. of Comp. and System Sciences. </note>
Reference-contexts: The fact that N computes CD n implies that N 0 shatters S (with regard to different assignments to these s programmable parameters). Thus N 0 has a VC-dimension of at least n . On the other hand the results of Goldberg and Jerrum [18] and Karpinski and Macintyre <ref> [26] </ref> imply that in this case the number s of programmable parameters in N satisfies n = O (s 2 ) in the case of piecewise polynomial activation functions, respectively n = O (s 4 ) in the case of piecewise exponential activation functions. 2.2 Computation of Functions with Analog Input
Reference: [27] <author> R. Kempter, W. Gerstner, J. L. van Hemmen, H. and Wagner, </author> <title> "Temporal coding in the sub-millisecond range: model of barn owl auditory pathway", </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> vol. 8, </volume> <publisher> MIT-Press, </publisher> <address> Cambridge, </address> <year> 1996, </year> <note> to appear. </note>
Reference-contexts: On the other hand experimental evidence has accumulated during the last few years which indicates that many biological neural systems use the timing of single action potentials (or "spikes") to encode information ([1], [2], [6], [3], [4], [5], [13], [20], <ref> [27] </ref>, [33], [54], [58], [59], [62]). These experimental results from neurobiology have lead to the investigation of a third generation of neural network models wich employ spiking neurons (or "integrate and fire neurons") as computational units.
Reference: [28] <author> C. Koch, and T. Poggio, </author> <title> "Multiplying with synapses and neurons", in: Single Neuron Computation, </title> <editor> T. McKenna, J. Davis, and S. F. Zornetzer, eds., </editor> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1992. </year>
Reference-contexts: For theoretical results about stable states, synfire chains, associative memory etc. in networks of spiking neurons we refer to [10], [1], [14], [16], [17], [51], [7], [19], [21]. Results about computations with stochastic spiking neurons in firing rate coding can be found in <ref> [28] </ref>, [55], and results about the information transmitted by spiking neurons in [61]. Computations with a somewhat different model of a stochastic spiking neuron are studied in [25] (see also the discussion in [36]), and in [55], [65].
Reference: [29] <author> P. Koiran, </author> <title> "VC-dimension in circuit complexity", </title> <note> preprint (1995). </note>
Reference-contexts: The proof of part b) is very similar to an argument in Koiran <ref> [29] </ref>.
Reference: [30] <author> J. Kruger, and F. Aiple, </author> <title> "Multielectrode investigation of monkey striate cortex: spike train correlations in the infragranular layers, </title> <journal> J. Neurophysiology, </journal> <volume> vol. 60, </volume> <pages> pp 798-828, </pages> <year> 1988. </year>
Reference-contexts: Thus a coding of analog variables by firing rates is quite dubious in the context of fast cortical computations. from monkey striate cortex by Kruger and Aiple <ref> [30] </ref>. Each firing is denoted by a short vertical bar, with a separate row for each neuron. For comparison we have marked the length of an interval of 100 msec by two vertical lines. This time span is known to suffice for the completion of some complex multilayer cortical computations.
Reference: [31] <editor> L. Lapique, "Recherches quantitatives sur l'excitation electrique des nerfs traitee comme une polarization", J. Physiol. Pathol. Gen., </editor> <volume> vol. 9, </volume> <pages> pp 620-635, </pages> <year> 1907. </year>
Reference-contexts: Mathematical models for "integrate and fire neurons" (or "spiking neurons" as they have been called more recently) can be traced back to <ref> [31] </ref> (see [63]). There exist a number of variations of this model, which are described and compared in the recent survey (see [15]).
Reference: [32] <author> M. Leshno, V. Y. Lin, A. Pinkus, and S. Schocken, </author> <title> "Multilayer feedforward networks with a nonpolynomial activation function can approximate any function", </title> <booktitle> Neural Networks, </booktitle> <volume> vol. 6, </volume> <pages> pp 861-867, </pages> <year> 1993. </year>
Reference-contexts: The result of <ref> [32] </ref> implies that any continuous function F : [0; fl] n ! [0; fl] k can be approximated by such net.
Reference: [33] <author> R. Lestienne, </author> <title> "Determination of the precision of spike timing in the visual cortex of anaesthetised cats", </title> <journal> Biol Cybernetics, </journal> <volume> vol. 74, </volume> <pages> pp 55-61, </pages> <year> 1996. </year> <month> 20 </month>
Reference-contexts: On the other hand experimental evidence has accumulated during the last few years which indicates that many biological neural systems use the timing of single action potentials (or "spikes") to encode information ([1], [2], [6], [3], [4], [5], [13], [20], [27], <ref> [33] </ref>, [54], [58], [59], [62]). These experimental results from neurobiology have lead to the investigation of a third generation of neural network models wich employ spiking neurons (or "integrate and fire neurons") as computational units.
Reference: [34] <author> W. Maass, </author> <title> "Vapnik-Chervonenkis dimension of neural nets", in: The Handbook of Brain Theory and Neural Networks, </title> <editor> M. A. Arbib, ed., </editor> <publisher> MIT Press (Cambridge, </publisher> <year> 1995), </year> <pages> pp 1000-1003. </pages>
Reference-contexts: N where the input nodes b 1 ; : : : ; b n are deleted, and the thresholds of the abovementioned s gates in N are viewed as the only "programmable parameters" (or "weights") in the usual sense of VC-dimension theory for neural networks (for a brief survey see <ref> [34] </ref>). The fact that N computes CD n implies that N 0 shatters S (with regard to different assignments to these s programmable parameters). Thus N 0 has a VC-dimension of at least n .
Reference: [35] <author> W. Maass, </author> <title> "On the computational complexity of networks of spiking neurons", </title> <booktitle> Proc. of the 1994 Conference on Neural Information Processing Systems 7, NIPS '94, </booktitle> <editor> G. Tesauro, D. S. Touretzky, and T. K. Leen, eds., </editor> <publisher> MIT Press (Cambridge), </publisher> <pages> pp 183-190, </pages> <year> 1995. </year>
Reference: [36] <author> W. Maass, </author> <title> "Lower bounds for the computational power of networks of spiking neurons", </title> <journal> Neural Computation, </journal> <volume> vol. 8(1), </volume> <pages> pp 1-40, </pages> <year> 1996. </year>
Reference-contexts: Results about computations with stochastic spiking neurons in firing rate coding can be found in [28], [55], and results about the information transmitted by spiking neurons in [61]. Computations with a somewhat different model of a stochastic spiking neuron are studied in [25] (see also the discussion in <ref> [36] </ref>), and in [55], [65]. We use in this article the terms analog, numerical and real-valued interchangeably to denote variables that range over R or an interval of R . <p> In order to simulate the subsequent layers of C with spiking neurons of type B one can employ the construction from <ref> [36] </ref>. The previously described spiking neurons v 0 represent the outputs of gates on the first layer of C by firing if and only if the corresponding gate in C outputs 1 . <p> Hence before one can use the "boolean" outputs of these gates v 0 as inputs for other spiking neurons of type B which simulate the subsequent layers of C according to the construction in <ref> [36] </ref>, one has to employ a synchronization module as constructed in the proof of Theorem 2.1 in [36]. Thus in contrast to SNN's of type A, networks of spiking neurons of type B can simulate neural nets from the first generation even for the case of real-valued network input. <p> before one can use the "boolean" outputs of these gates v 0 as inputs for other spiking neurons of type B which simulate the subsequent layers of C according to the construction in <ref> [36] </ref>, one has to employ a synchronization module as constructed in the proof of Theorem 2.1 in [36]. Thus in contrast to SNN's of type A, networks of spiking neurons of type B can simulate neural nets from the first generation even for the case of real-valued network input. <p> two generations: in order to achieve separation results between SNN's of type B and neural nets from the first two generations it just remains to verify that a single spiking neuron of type B can compute CD n ; ED n and g ED n . 17 We refer to <ref> [36] </ref> and [39] for details of the proofs of several of the abovementioned simulation results.
Reference: [37] <author> W. Maass, </author> <title> "Analog computations on networks of spiking neurons", </title> <booktitle> Proc. of the 7th Italian Workshop on Neural Nets, </booktitle> <publisher> World Scientific Press, </publisher> <year> 1995. </year>
Reference-contexts: Rather it suffices to assume that they just have a small linearly increasing respectively decreasing segment, a property which is approximately satisfied by EPSP's and IPSP's of biological neurons (see Figure 2). In [48], <ref> [37] </ref> a complete characterization of the computational power of SNN's of type B is given in terms of a restriction (called N-RAM) of the familiar model of a random access machine.
Reference: [38] <author> W. Maass, </author> <title> "On the computational power of noisy spiking neurons", </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> vol. 8, </volume> <publisher> MIT-Press (Cambridge), </publisher> <year> 1996, </year> <note> to appear. </note>
Reference-contexts: It is also easy to see that the here considered functions CD n , ED n and g ED n can be computed by a single noisy spiking neuron. Furthermore it is shown in <ref> [38] </ref> that even with very noisy spiking neurons one can in principle carry out arbitrary digital computations with any desired degree of reliability.
Reference: [39] <author> W. Maass, </author> <title> "An efficient implementation of sigmoidal neural nets in temporal coding with noisy spiking neurons", </title> <note> 1996, submitted for publication. </note>
Reference-contexts: One employs here the same construction as for the simulation of a linear (respectively sigmoidal) gate in <ref> [39] </ref>, which yields a spiking neuron v whose firing time represents the weighted sum P n i=1 ff i x i in temporal coding. <p> Hence the question arises whether networks of spiking neurons of type B can also simulate (respectively approximate) neural nets from the second generation which have real-valued input and output. This question is answered affirmatively in <ref> [39] </ref>, by showing that with regard to temporal coding of real-valued variables x from a sufficiently small range [0; fl] any continuous function F : [0; fl] n ! [0; fl] k can be approximated arbitrary closely (with regard to uniform convergence, i.e. <p> in order to achieve separation results between SNN's of type B and neural nets from the first two generations it just remains to verify that a single spiking neuron of type B can compute CD n ; ED n and g ED n . 17 We refer to [36] and <ref> [39] </ref> for details of the proofs of several of the abovementioned simulation results. <p> In [48], [37] a complete characterization of the computational power of SNN's of type B is given in terms of a restriction (called N-RAM) of the familiar model of a random access machine. In addition it is shown in <ref> [39] </ref> that the simulation of sigmoidal neural nets by SNN's can also be carried out with the biologically more realistic model of a stochastic or noisy spiking neuron.
Reference: [40] <author> W. Maass, and B. Ruf, </author> <title> "On the relevance of the shape of postsynaptic potentials for the computational power of Spiking Neurons", </title> <booktitle> Proc. of the International Conference on Artificial Neural Networks, ICANN'95, EC2&Cie, Paris, </booktitle> <pages> pp 515-520, </pages> <year> 1995. </year>
Reference-contexts: This follows from a general characterization of the computational power of networks of spiking neurons of type A for numerical inputs in terms of the computational power of a restriction called N -RAM of the common model of a random access machine (RAM) that is given in <ref> [40] </ref>. Thus we have arrived here at a limit for the computational power of spiking neurons of type A for numerical inputs.
Reference: [41] <author> W. Maass, G. Schnitger, and E. Sontag, </author> <title> "On the computational power of sigmoid versus boolean threshold circuits", </title> <booktitle> Proc. of the 32nd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp 767-776, </pages> <year> 1991. </year> <note> extended version appeared in: Theoretical Advances in Neural Computation and Learning, </note> <editor> V. P. Roychowdhury, K. Y. Siu, A. Orlitsky, editors, </editor> <publisher> Kluwer Academic Publishers (Boston), </publisher> <pages> pp 127-151, </pages> <year> 1994. </year>
Reference: [42] <author> W. Maass, and P. Orponen, </author> <title> "The computational power of noisy and probabilistic analog neural nets", </title> <type> preprint, </type> <year> 1996. </year>
Reference-contexts: Furthermore it is shown in [38] that even with very noisy spiking neurons one can in principle carry out arbitrary digital computations with any desired degree of reliability. However noise certainly affects the computational power of networks of spiking neurons, and we refer to <ref> [42] </ref> with regard to methods for proving lower bounds for networks of noisy spiking neurons.
Reference: [43] <author> M. Mahowald, </author> <title> VLSI Analogs of Neuronal Visual Processing: A Synthesis of Form and Function, </title> <institution> Phd-dissertation at the Cal. Inst. of Technology, </institution> <year> 1992. </year>
Reference-contexts: Recently, one has also started to carry out experiments with related new types of electronic hardware such as pulse stream VLSI (see e.g. [46], [50], [22], <ref> [43] </ref>, [44], [48], [47], [12], [23]). In these new chips one 3 can encode analog variables by time differences between pulses, which has practical advantages over other encoding methods.
Reference: [44] <author> M. Mahowald, </author> <title> "An Analog VLSI System for Stereoscopic Vision", </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1994. </year>
Reference-contexts: Recently, one has also started to carry out experiments with related new types of electronic hardware such as pulse stream VLSI (see e.g. [46], [50], [22], [43], <ref> [44] </ref>, [48], [47], [12], [23]). In these new chips one 3 can encode analog variables by time differences between pulses, which has practical advantages over other encoding methods.
Reference: [45] <author> Z. F. Mainen, and T. J. Sejnowski, </author> <title> "Reliability of spike timing in neocortical neurons", </title> <journal> Science, </journal> <volume> vol. 268, </volume> <pages> pp 1503-1506, </pages> <year> 1995. </year>
Reference: [46] <author> C. Mead, </author> <title> "Analog VLSI and Neural Systems", </title> <publisher> Addison-Wesley (Reading), </publisher> <year> 1989. </year> <month> 21 </month>
Reference-contexts: Recently, one has also started to carry out experiments with related new types of electronic hardware such as pulse stream VLSI (see e.g. <ref> [46] </ref>, [50], [22], [43], [44], [48], [47], [12], [23]). In these new chips one 3 can encode analog variables by time differences between pulses, which has practical advantages over other encoding methods.
Reference: [47] <author> J. L. Meador, A. Wu, C. Cole, N. Nintunze, and P. Chintrakulchai, </author> <title> "Pro--grammable impulse neural circuits", </title> <journal> IEEE Trans. on Neural Networks, </journal> <volume> vol. 2, </volume> <pages> pp 101-109, </pages> <year> 1991. </year>
Reference-contexts: Recently, one has also started to carry out experiments with related new types of electronic hardware such as pulse stream VLSI (see e.g. [46], [50], [22], [43], [44], [48], <ref> [47] </ref>, [12], [23]). In these new chips one 3 can encode analog variables by time differences between pulses, which has practical advantages over other encoding methods.
Reference: [48] <author> A. Murray, and L. Tarassenko, </author> <title> Analogue Neural VLSI: A Pulse Stream Approach, </title> <publisher> Chapman & Hall, </publisher> <year> 1994. </year>
Reference-contexts: Recently, one has also started to carry out experiments with related new types of electronic hardware such as pulse stream VLSI (see e.g. [46], [50], [22], [43], [44], <ref> [48] </ref>, [47], [12], [23]). In these new chips one 3 can encode analog variables by time differences between pulses, which has practical advantages over other encoding methods. <p> Rather it suffices to assume that they just have a small linearly increasing respectively decreasing segment, a property which is approximately satisfied by EPSP's and IPSP's of biological neurons (see Figure 2). In <ref> [48] </ref>, [37] a complete characterization of the computational power of SNN's of type B is given in terms of a restriction (called N-RAM) of the familiar model of a random access machine.
Reference: [49] <author> D. I. Perrett, E. T. Rolls, and W. C. Caan, </author> <title> "Visual neurons responsive to faces in the monkey temporal cortex", </title> <journal> Experimental Brain Research, </journal> <volume> vol. 47, </volume> <pages> pp 329-342, </pages> <year> 1982. </year>
Reference: [50] <author> G. A. Pratt, </author> <title> Pulse Computation, </title> <institution> Phd-thesis in the Dept. of Elec. Eng. and Comp. Sci., MIT, </institution> <address> Cambridge, USA, </address> <year> 1989. </year>
Reference-contexts: Recently, one has also started to carry out experiments with related new types of electronic hardware such as pulse stream VLSI (see e.g. [46], <ref> [50] </ref>, [22], [43], [44], [48], [47], [12], [23]). In these new chips one 3 can encode analog variables by time differences between pulses, which has practical advantages over other encoding methods.
Reference: [51] <author> R. Ritz, W. Gerstner, U. Fuentes, and L. van Hemmen, </author> <title> "A biologically motivated and analytically soluble model of collective ascillations in the cortex: II. Applications to binding and pattern segmentation", </title> <journal> Biol. Cybernetics, </journal> <volume> vol. 71, </volume> <pages> pp 349-358, </pages> <year> 1994. </year>
Reference-contexts: But these differences will be irrelevant for the results that are considered in this article. For theoretical results about stable states, synfire chains, associative memory etc. in networks of spiking neurons we refer to [10], [1], [14], [16], [17], <ref> [51] </ref>, [7], [19], [21]. Results about computations with stochastic spiking neurons in firing rate coding can be found in [28], [55], and results about the information transmitted by spiking neurons in [61].
Reference: [52] <author> E. T. </author> <title> Rolls, "Brain mechanisms for invariant visual recognition and learning", </title> <journal> Behavioural Processe, </journal> <volume> vol. 33, </volume> <pages> pp 113-138, </pages> <year> 1994. </year>
Reference: [53] <author> E. T. Rolls, and M. J. Tovee, </author> <title> "Processing speed in the cerebral cortex, and the neurophysiology of visual backward masking", </title> <journal> Proc. Roy. Soc. B., </journal> <volume> vol. 257, </volume> <pages> pp 9-15, </pages> <year> 1994. </year>
Reference-contexts: The same speed of visual processing has been measured by Rolls et al. (<ref> [53] </ref>) in macaque monkeys. Furthermore they have shown that a single cortical area involved in visual processing can complete its computation in just 20-30 msec ([52], [53]). On the other hand the firing rates of neurons involved in these computations 2 are usually below 100 Hz, and hence at least 20-30 msec would be needed just to sample the current firing rate of a neuron.
Reference: [54] <author> T. J. Sejnowski, </author> <title> "Time for a new neural code?", </title> <journal> Nature, </journal> <volume> vol. 376, </volume> <pages> pp 21-22, </pages> <year> 1995. </year>
Reference-contexts: On the other hand experimental evidence has accumulated during the last few years which indicates that many biological neural systems use the timing of single action potentials (or "spikes") to encode information ([1], [2], [6], [3], [4], [5], [13], [20], [27], [33], <ref> [54] </ref>, [58], [59], [62]). These experimental results from neurobiology have lead to the investigation of a third generation of neural network models wich employ spiking neurons (or "integrate and fire neurons") as computational units.
Reference: [55] <author> J. Shawe-Taylor, P. Jeavons, and M. Van Daalen, </author> <title> "Probabilistic bit stream neural chip: theory.", </title> <type> preprint, </type> <year> 1995. </year>
Reference-contexts: For theoretical results about stable states, synfire chains, associative memory etc. in networks of spiking neurons we refer to [10], [1], [14], [16], [17], [51], [7], [19], [21]. Results about computations with stochastic spiking neurons in firing rate coding can be found in [28], <ref> [55] </ref>, and results about the information transmitted by spiking neurons in [61]. Computations with a somewhat different model of a stochastic spiking neuron are studied in [25] (see also the discussion in [36]), and in [55], [65]. <p> about computations with stochastic spiking neurons in firing rate coding can be found in [28], <ref> [55] </ref>, and results about the information transmitted by spiking neurons in [61]. Computations with a somewhat different model of a stochastic spiking neuron are studied in [25] (see also the discussion in [36]), and in [55], [65]. We use in this article the terms analog, numerical and real-valued interchangeably to denote variables that range over R or an interval of R .
Reference: [56] <author> G. M. Shepherd, </author> <title> Neurobiology, </title> <publisher> 3rd ed., Oxford University Press, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: There exist a number of variations of this model, which are described and compared in the recent survey (see [15]). With regard to the relationship of these mathematical models to the known behaviour of biological neurons we refer to [1], [3], [4], [8], [9], [20], [24], <ref> [56] </ref>, [57], and [63]. These mathematical models for spiking neurons do not provide a complete description of the extremely complex computational function of a biological neuron. <p> On the other hand EPSP's that arrive synchronously at adjacent synapses are "boosted" at "hot spots" of the dendritic tree, and hence may have a significant impact on the membrane potential P v (t) at the trigger zone <ref> [56] </ref>. We have defined g ED n in such a way that in spite of these nonlinear effects in the integration of EPSP's it is quite plausible that a biological neuron can compute g ED n in temporal coding for a fairly large value of n .
Reference: [57] <author> G. M. Shepherd, ed., </author> <title> The Synaptic Organization of the Brain, </title> <publisher> 3rd ed., Oxford University Press, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: There exist a number of variations of this model, which are described and compared in the recent survey (see [15]). With regard to the relationship of these mathematical models to the known behaviour of biological neurons we refer to [1], [3], [4], [8], [9], [20], [24], [56], <ref> [57] </ref>, and [63]. These mathematical models for spiking neurons do not provide a complete description of the extremely complex computational function of a biological neuron. <p> Obviously these constraints have basically no impact on theoretical complexity investigations (just consider pairs of excitatory and inhibitory neurons instead of single neurons), unless one cares about small constant factors in the size of networks, or one wants to model the actual architecture of cortical circuits (see [12], <ref> [57] </ref>). It is mathematically more convenient to assume that the potential P v has value 0 in the absence of postsynaptic potentials, and that the threshold value fi v is always &gt; 0 .
Reference: [58] <author> W. Singer, </author> <title> "Synchronization of Neuronal Responses as a Putative Binding Mechanism", In: The Handbook of Brain Theory and Neural Networks, </title> <editor> M. A. Arbib, ed., </editor> <publisher> MIT-Press, Cambridge, </publisher> <pages> pp 960-964, </pages> <year> 1995. 1995. </year>
Reference-contexts: On the other hand experimental evidence has accumulated during the last few years which indicates that many biological neural systems use the timing of single action potentials (or "spikes") to encode information ([1], [2], [6], [3], [4], [5], [13], [20], [27], [33], [54], <ref> [58] </ref>, [59], [62]). These experimental results from neurobiology have lead to the investigation of a third generation of neural network models wich employ spiking neurons (or "integrate and fire neurons") as computational units.
Reference: [59] <author> W. Softky, </author> <title> "Sub-millisecond coincidence detection in active dendritic tree", </title> <journal> Neu-roscience, </journal> <volume> vol. 58, </volume> <pages> pp 13-41, </pages> <year> 1994. </year>
Reference-contexts: On the other hand experimental evidence has accumulated during the last few years which indicates that many biological neural systems use the timing of single action potentials (or "spikes") to encode information ([1], [2], [6], [3], [4], [5], [13], [20], [27], [33], [54], [58], <ref> [59] </ref>, [62]). These experimental results from neurobiology have lead to the investigation of a third generation of neural network models wich employ spiking neurons (or "integrate and fire neurons") as computational units.
Reference: [60] <author> E. D. Sontag, </author> <title> "Shattering all sets of k points in 'general position' requires (k 1)=2 parameters", </title> <type> preprint, </type> <month> (Feb. </month> <year> 1996). </year> <month> 22 </month>
Reference-contexts: This lower bound will be 11 improved to (n 1)=4 in the following theorem. The proof of this stronger separation result exploits instead of a bound for the VC-dimension Sontag's better upper bound of 2w + 1 <ref> [60] </ref> for the maximal number d such that every set of d different inputs can be shattered by a sigmoidal neural net with w programmable parameters. <p> Since S R + of size n 1 was chosen arbitrarily, we can now apply the result from Sontag <ref> [60] </ref>, which implies that n 1 2 (k + 1) + 1 , hence k (n 4)=2 . Thus N has at least (n 4)=2 computation nodes, and therefore at least (n 4)=2 1 hidden units. Remark: The result of section 4 in Sontag [60] implies that his upper bound , <p> now apply the result from Sontag <ref> [60] </ref>, which implies that n 1 2 (k + 1) + 1 , hence k (n 4)=2 . Thus N has at least (n 4)=2 computation nodes, and therefore at least (n 4)=2 1 hidden units. Remark: The result of section 4 in Sontag [60] implies that his upper bound , and hence the lower bound of the preceding Theorem 3, remain valid if the neural net N that computes ED n employs besides sigmoidal gates also threshold gates. <p> Since N computes g ED n , the network N with k computation nodes shatters S with the help of k + 1 programmable parameters. Hence Sontag's result <ref> [60] </ref> yields b (n 3)=3c 2 (k + 1) + 1 , i.e. k (n 14)=6 .
Reference: [61] <author> C. F. Stevens, and A. Zador, </author> <title> "Information through a spiking neuron", </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> vol. 8, </volume> <publisher> MIT Press (Cambridge), </publisher> <year> 1996, </year> <note> to appear. </note>
Reference-contexts: Results about computations with stochastic spiking neurons in firing rate coding can be found in [28], [55], and results about the information transmitted by spiking neurons in <ref> [61] </ref>. Computations with a somewhat different model of a stochastic spiking neuron are studied in [25] (see also the discussion in [36]), and in [55], [65].
Reference: [62] <author> S. T. Thorpe, and M. Imbert, </author> <title> "Biological constraints on connectionist mod-elling", In: Connectionism in Perspective, </title> <editor> R. Pfeifer, Z. Schreter, F. Fogelman-Soulie, and L. Steels, eds., </editor> <publisher> Elsevier, North-Holland, </publisher> <year> 1989. </year>
Reference-contexts: On the other hand experimental evidence has accumulated during the last few years which indicates that many biological neural systems use the timing of single action potentials (or "spikes") to encode information ([1], [2], [6], [3], [4], [5], [13], [20], [27], [33], [54], [58], [59], <ref> [62] </ref>). These experimental results from neurobiology have lead to the investigation of a third generation of neural network models wich employ spiking neurons (or "integrate and fire neurons") as computational units.
Reference: [63] <author> H. C. Tuckwell, </author> <title> "Introduction to Theoretical Neurobiology", </title> <booktitle> vol. 1 and 2, </booktitle> <publisher> Cam-bridge University Press, </publisher> <address> Cambridge, </address> <year> 1988. </year>
Reference-contexts: Mathematical models for "integrate and fire neurons" (or "spiking neurons" as they have been called more recently) can be traced back to [31] (see <ref> [63] </ref>). There exist a number of variations of this model, which are described and compared in the recent survey (see [15]). With regard to the relationship of these mathematical models to the known behaviour of biological neurons we refer to [1], [3], [4], [8], [9], [20], [24], [56], [57], and [63]. <p> <ref> [63] </ref>). There exist a number of variations of this model, which are described and compared in the recent survey (see [15]). With regard to the relationship of these mathematical models to the known behaviour of biological neurons we refer to [1], [3], [4], [8], [9], [20], [24], [56], [57], and [63]. These mathematical models for spiking neurons do not provide a complete description of the extremely complex computational function of a biological neuron. <p> when P v (t) fi v (t t 0 ) &lt; 0 . 6 The previously described noisy version of the SNN model is basically identical with the spike response model in [15], [16], and with the other common mathematical models for networks of spiking neurons (see e.g. [1], [4], <ref> [63] </ref>). Subtle differences exist between these models with regard to their treatment of the refractory effects and the "reset" of the membrane potential after a firing. But these differences will be irrelevant for the results that are considered in this article.
Reference: [64] <author> L. G. Valiant, </author> <title> "Circuits of the Mind", </title> <publisher> Oxford University Press, </publisher> <year> 1994. </year>
Reference-contexts: In that regard the common mathematical model for a spiking neuron "overestimates" the computational capabilities of a biological neuron. It is more realistic to assume that 6 simultaneously arriving EPSP's can cause a neuron to fire (see the discussion in <ref> [64] </ref>).
Reference: [65] <author> J. Zhao, </author> <title> "Stochastic Bit Stream Neural Networks: Theory, Simulations and Applications", </title> <type> Phd. </type> <institution> Thesis in the Dept. of Comp. Sci., Royal Holloway, University of London, </institution> <year> 1995. </year> <month> 23 </month>
Reference-contexts: Computations with a somewhat different model of a stochastic spiking neuron are studied in [25] (see also the discussion in [36]), and in [55], <ref> [65] </ref>. We use in this article the terms analog, numerical and real-valued interchangeably to denote variables that range over R or an interval of R .
References-found: 65

