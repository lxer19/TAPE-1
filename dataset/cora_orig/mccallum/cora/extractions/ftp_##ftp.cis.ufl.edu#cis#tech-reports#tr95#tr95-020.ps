URL: ftp://ftp.cis.ufl.edu/cis/tech-reports/tr95/tr95-020.ps
Refering-URL: http://www.cis.ufl.edu/tech-reports/tech-reports/tr95-abstracts.html
Root-URL: http://www.cis.ufl.edu
Title: A COMBINED UNIFRONTAL/MULTIFRONTAL METHOD FOR UNSYMMETRIC SPARSE MATRICES  
Author: TIMOTHY A. DAVIS AND IAIN S. DUFF 
Keyword: Categories and Subject Descriptors: G.1.3 [Numerical Analysis]: Numerical Linear Algebra linear systems (direct methods), sparse and very large systems; G.4 [Mathematics of Computing]: Mathematical Software algorithm analysis, efficiency. General Terms: Algorithms, Experimentation, Performance. Additional Key Words and Phrases: sparse matrices, linear equations, multifrontal methods, frontal methods.  
Date: September, 1995.  
Address: Florida.  
Affiliation: Computer and Information Science and Engineering Department, University of  
Pubnum: Technical Report TR-95-020,  
Abstract: We discuss the organization of frontal matrices in multifrontal methods for the solution of large sparse sets of linear equations. In the multifrontal method, several frontal matrices are used. Each is used for one or more pivot steps, and the resulting Schur complement is summed with other Schur complements to generate another frontal matrix. Although this means that arbitrary sparsity patterns can be handled efficiently, extra work is required to add the Schur complements together and can be costly because indirect addressing is required. The (uni-)frontal method avoids this extra work by factorizing the matrix with a single frontal matrix. Rows and columns are added to the frontal matrix, and pivot rows and columns are removed. Data movement is simpler, but higher fill-in can result if the matrix cannot be permuted into a variable-band form with small profile. We consider a combined unifrontal/multifrontal algorithm to enable general fill-in reduction orderings to be applied without the data movement of previous multifrontal approaches. 1. Introduction. We consider the direct solution of sets of linear equations 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Amestoy, T. A. Davis, and I. S. Duff, </author> <title> An approximate minimum degree ordering algorithm, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <note> (to appear). (Also University of Florida technical report TR-94-039). </note>
Reference-contexts: To reduce the profile, the frontal method is typically preceded by an ordering method such as reverse Cuthill-McKee (RCM) [5, 7, 29], which is typically faster than the sparsity-preserving orderings required by a more general technique like a multifrontal method (such as nested dissection [24] and minimum degree <ref> [1, 25] </ref>). A degree update phase, which is typically the most costly part of a minimum degree algorithm, is not required in the RCM algorithm. However, for matrices with large profile, the frontal matrix can be large, and an unacceptable level of fill-in can occur. 3. Multifrontal methods. <p> UMFPACK does not use actual degrees but keeps track of upper bounds on the degree of each row and column. The symmetric analogue of the approximate degree update in UMFPACK has been incorporated into an approximate minimum degree algorithm (AMD) as discussed in <ref> [1] </ref>, where the accuracy of our degree bounds is demonstrated. Our new algorithm consists of several major steps, each of which comprises several pivot selection and elimination operations.
Reference: [2] <author> P. R. Amestoy and I. S. Duff, </author> <title> Vectorization of a multiprocessor multifrontal code, </title> <journal> Int. J. Supercomputer Appl., </journal> <volume> 3 (1989), </volume> <pages> pp. 41-59. </pages>
Reference-contexts: Many recent algorithms and software for direct solution of sparse systems are based on a multifrontal approach <ref> [17, 2, 10, 27] </ref>. In this paper, we will examine a frontal matrix strategy to be used within a multifrontal approach. <p> However, for matrices with large profile, the frontal matrix can be large, and an unacceptable level of fill-in can occur. 3. Multifrontal methods. In a multifrontal scheme for a symmetric matrix <ref> [2, 8, 9, 10, 17, 18, 28] </ref>, it is normal to use an ordering such as minimum degree to reduce the fill-in. Such an ordering tends to reduce fill-in much more than profile reduction orderings. <p> A. DAVIS AND I. S. DUFF method (UMFPACK Version 1.1 [8, 10]), a general sparse matrix factorization algorithm that is not based on frontal matrices (MA48, [19, 20]), the frontal method (MA42, [15, 22]), and the symmetric-pattern multifrontal method (MUPS <ref> [2] </ref>). All methods can factorize general unsymmetric matrices and all use dense matrix kernels to some extent [12]. We tested each method on a single processor of a CRAY C-98, although MUPS is a parallel code. Version 6.0.4.1 of the Fortran compiler (CF77) was used.
Reference: [3] <author> Anon, </author> <title> Harwell Subroutine Library. A Catalogue of Subroutines (Release 11), </title> <institution> Theoretical Studies Department, AEA Industrial Technology, </institution> <year> 1993. </year>
Reference-contexts: A. DAVIS AND I. S. DUFF Subroutine Library <ref> [3] </ref>. 2 8. Acknowledgements. We would like to thank Nick Gould, John Reid, and Jennifer Scott from the Rutherford Appleton Laboratory for their helpful comments on a draft of this report.
Reference: [4] <author> M. Arioli, J. W. Demmel, and I. S. Duff, </author> <title> Solving sparse linear systems with sparse backward error, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 10 (1989), </volume> <pages> pp. 165-190. </pages>
Reference-contexts: between UMFPACK Version 1.1 and the new code (MA38, or UMFPACK Version 2.0) include an option of overwriting the matrix A with its LU factors, printing of input and output parameters, a removal of the extra copy of the numerical values of A, iterative refinement with sparse backward error analysis <ref> [4] </ref>, more use of Level 3 BLAS within the numerical factorization routine, and a simpler calling interface. These features improve the robustness of the code and result a modest decrease in memory usage.
Reference: [5] <author> W. M. Chan and A. George, </author> <title> A linear time implementation of the reverse Cuthill-Mckee algorithm, </title> <journal> BIT, </journal> <volume> 20 (1980), </volume> <pages> pp. 8-14. </pages>
Reference-contexts: If numerical pivoting is not required, fill-in does not increase the profile (L + U has the same profile as A). To reduce the profile, the frontal method is typically preceded by an ordering method such as reverse Cuthill-McKee (RCM) <ref> [5, 7, 29] </ref>, which is typically faster than the sparsity-preserving orderings required by a more general technique like a multifrontal method (such as nested dissection [24] and minimum degree [1, 25]).
Reference: [6] <author> A. R. Curtis and J. K. Reid, </author> <title> On the automatic scaling of matrices for Gaussian elimination, </title> <journal> Journal of the Institute of Mathematics and its Applications, </journal> <volume> 10 (1972), </volume> <pages> pp. 118-124. </pages>
Reference-contexts: This can reduce the work for unsymmetric matrices. We did not perform the preordering, since MA42 and MUPS do not provide these options. One matrix (lhr71) was so ill-conditioned that it required scaling prior to its factorization. The scale factors were computed by the Harwell Subroutine Library routine MC19A <ref> [6] </ref>. Each row was then subsequently divided by the maximum absolute value in the row (or column, depending on how the method implements threshold partial pivoting). No scaling was performed on the other matrices.
Reference: [7] <author> E. Cuthill and J. McKee, </author> <title> Reducing the bandwidth of sparse symmetric matrices, </title> <booktitle> in Proceedings 24th National Conference of the Association for Computing Machinery, </booktitle> <address> New Jersey, 1969, </address> <publisher> Brandon Press, </publisher> <pages> pp. 157-172. </pages>
Reference-contexts: If numerical pivoting is not required, fill-in does not increase the profile (L + U has the same profile as A). To reduce the profile, the frontal method is typically preceded by an ordering method such as reverse Cuthill-McKee (RCM) <ref> [5, 7, 29] </ref>, which is typically faster than the sparsity-preserving orderings required by a more general technique like a multifrontal method (such as nested dissection [24] and minimum degree [1, 25]).
Reference: [8] <author> T. A. Davis, </author> <title> Users' guide to the unsymmetric-pattern multifrontal package (UMFPACK, version 1.1), </title> <type> Tech. Report TR-95-004, </type> <institution> CIS Dept., Univ. of Florida, </institution> <address> Gainesville, FL, </address> <year> 1995. </year> <note> For a copy of UMFPACK Version 1.1, send e-mail to netlib@ornl.gov with the one-line message send umfpack.shar from linalg. </note>
Reference-contexts: However, for matrices with large profile, the frontal matrix can be large, and an unacceptable level of fill-in can occur. 3. Multifrontal methods. In a multifrontal scheme for a symmetric matrix <ref> [2, 8, 9, 10, 17, 18, 28] </ref>, it is normal to use an ordering such as minimum degree to reduce the fill-in. Such an ordering tends to reduce fill-in much more than profile reduction orderings. <p> The cost of this degree update is clearly a penalty we pay to avoid the poor fill-in properties of conventional unifrontal orderings. We now describe how this new frontal matrix strategy is applied in UMFPACK Version 1.1 <ref> [8, 10] </ref>, in order to obtain a new combined method. However, the new frontal strategy can be applied to any multifrontal algorithm. UMFPACK does not use actual degrees but keeps track of upper bounds on the degree of each row and column. <p> Performance. In this section, we compare the performance of the combined unifrontal/multifrontal method (MA38) with the unsymmetric-pattern multifrontal 8 T. A. DAVIS AND I. S. DUFF method (UMFPACK Version 1.1 <ref> [8, 10] </ref>), a general sparse matrix factorization algorithm that is not based on frontal matrices (MA48, [19, 20]), the frontal method (MA42, [15, 22]), and the symmetric-pattern multifrontal method (MUPS [2]). All methods can factorize general unsymmetric matrices and all use dense matrix kernels to some extent [12].
Reference: [9] <author> T. A. Davis and I. S. Duff, </author> <title> Unsymmetric-pattern multifrontal methods for parallel sparse LU factorization, </title> <type> Tech. Report TR-91-023, </type> <institution> CIS Dept., Univ. of Florida, </institution> <address> Gainesville, FL, </address> <year> 1991. </year> <title> [10] , An unsymmetric-pattern multifrontal method for sparse LU factorization, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <note> (to appear). (Also University of Florida technical report TR-94-038). </note>
Reference-contexts: However, for matrices with large profile, the frontal matrix can be large, and an unacceptable level of fill-in can occur. 3. Multifrontal methods. In a multifrontal scheme for a symmetric matrix <ref> [2, 8, 9, 10, 17, 18, 28] </ref>, it is normal to use an ordering such as minimum degree to reduce the fill-in. Such an ordering tends to reduce fill-in much more than profile reduction orderings. <p> In the unsymmetric-pattern multifrontal method, the tree is replaced by a directed acyclic graph (dag) <ref> [9] </ref>, and a contribution block may be assembled into more than one subsequent frontal matrix. 4. Combining the two methods. Let us now consider an approach that combines some of the best features of the two methods.
Reference: [11] <author> M. J. Dayd e and I. S. Duff, </author> <title> A block implementation of Level 3 BLAS for RISC processors, </title> <type> Tech. </type> <note> Report To appear, </note> <institution> CERFACS, Toulouse, France, </institution> <year> 1995. </year>
Reference-contexts: We have performed our experiments on the effect of the value of G on a SUN SPARCstation 20 Model 41, using the Fortran compiler (f77 version 1.4, with -O4 and -libmil options), and the BLAS from <ref> [11] </ref> and show the results in Table 5.2.
Reference: [12] <author> J. J. Dongarra, J. J. Du Croz, I. S. Duff, and S. Hammarling, </author> <title> A set of Level 3 Basic Linear Algebra Subprograms., </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 16 (1990), </volume> <pages> pp. 1-17. </pages>
Reference-contexts: All methods can factorize general unsymmetric matrices and all use dense matrix kernels to some extent <ref> [12] </ref>. We tested each method on a single processor of a CRAY C-98, although MUPS is a parallel code. Version 6.0.4.1 of the Fortran compiler (CF77) was used. Each method (except MA42, which we discuss later) was given 95 Mw of memory to factorize the matrices listed in Table 5.1.
Reference: [13] <author> J. J. Dongarra and E. Grosse, </author> <title> Distribution of mathematical software via electronic mail, </title> <journal> Comm. ACM, </journal> <volume> 30 (1987), </volume> <pages> pp. 403-407. </pages>
Reference-contexts: These features improve the robustness of the code and result a modest decrease in memory usage. The combined unifrontal/multifrontal method is available as the Fortran 77 codes, UMFPACK Version 2.0 in Netlib <ref> [13] </ref>, 1 and MA38 in Release 12 of the Harwell 1 UMFPACK Version 2.0, in Netlib, may only be used for research, education, or benchmarking 10 T. A. DAVIS AND I. S. DUFF Subroutine Library [3]. 2 8. Acknowledgements.
Reference: [14] <author> I. S. Duff, </author> <title> On algorithms for obtaining a maximum transversal, </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 7 (1981), </volume> <pages> pp. </pages> <month> 315-330. </month> <title> [15] , Design features of a frontal code for solving sparse unsymmetric linear systems out-of-core, </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 5 (1984), </volume> <pages> pp. 270-280. </pages>
Reference-contexts: We used the recommended defaults for most of these, with a few exceptions that we now indicate. By default, three of the five methods (MA38, UMFPACK V1.1, and MA48) preorder a matrix to block triangular form (always preceded by finding a maximum transversal <ref> [14] </ref>), and then factorize each block on the diagonal [16]. This can reduce the work for unsymmetric matrices. We did not perform the preordering, since MA42 and MUPS do not provide these options. One matrix (lhr71) was so ill-conditioned that it required scaling prior to its factorization.

References-found: 13

