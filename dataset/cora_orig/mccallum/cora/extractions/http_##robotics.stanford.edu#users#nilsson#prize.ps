URL: http://robotics.stanford.edu/users/nilsson/prize.ps
Refering-URL: http://www.cs.toronto.edu/~mes/ai/reading.html
Root-URL: 
Email: e-mail: nilsson@cs.stanford.edu  
Title: EYE ON THE PRIZE  
Author: Nils J. Nilsson Nils J. Nilsson 
Keyword: autonomous agents, general problem solving, habile systems  
Note: Copyright c fl1995  
Date: January 30, 1995  
Address: Stanford, CA 94305  
Affiliation: Robotics Laboratory Department of Computer Science Stanford University  
Abstract: In its early stages, the field of artificial intelligence (AI) had as its main goal the invention of computer programs having the general problem solving abilities of humans. Along the way, there developed a major shift of emphasis from general-purpose programs toward "performance programs"|ones whose competence was highly specialized and limited to particular areas of expertise. In this paper I claim that AI is now at the beginning of another transition|one that will re-invigorate efforts to build programs of general, human-like competence. These programs will use specialized performance programs as tools, much like humans do. [This paper is being submitted to the AI Magazine.] 
Abstract-found: 1
Intro-found: 1
Reference: [Ball & Ling, 1993] <author> Ball, J. E., and Ling, D., </author> <title> "Natural Language Processing for a Conversational Assistant," </title> <institution> Microsoft Research Technical Report MSR-TR-93-13, </institution> <month> October, </month> <year> 1993. </year>
Reference-contexts: Several people are working on prototypes that aim toward such 9 agents <ref> [Etzioni & Weld, 1994, Ball & Ling, 1993, Maes, 1994] </ref>.
Reference: [Bates, 1994] <author> Bates, J., </author> <title> "The Role of Emotion in Believable Agents," </title> <journal> Communications of the ACM, </journal> <volume> 37(7): </volume> <pages> 122-125, </pages> <month> July, </month> <year> 1994. </year>
Reference-contexts: Demand for habile personal assistants will be unceasing and growing as services available on the Internet continue to expand. 6.2 Entertainment, Education, and Simulation Interactive, multi-media video art and entertainment require characters that are "believable" in their emotions and actions <ref> [Bates, 1994] </ref>. The human participants in these interactions want characters that act and think very much like humans do. So long as such characters are perceived to be "simply mechanical" and easily predictable, there will be competitive pressure to do better.
Reference: [Benson & Nilsson, 1995] <author> Benson, S., and Nilsson, N., </author> <title> "Reacting, Planning and Learning in an Autonomous Agent," </title> <booktitle> in Machine Intelligence 14, </booktitle> <editor> (eds. K. Furukawa, D. Michie, and S. Muggleton), </editor> <publisher> Oxford: the Clarendon Press, </publisher> <year> 1995. </year> <month> 16 </month>
Reference-contexts: There are several such general-purpose robot architectures being explored|including one I am currently working on <ref> [Benson & Nilsson, 1995] </ref>. These factors will combine with those that have existed for quite some time.
Reference: [Brooks, 1991] <author> Brooks, R. A., </author> <title> "Intelligence Without Representation," </title> <booktitle> Arti--ficial Intelligence, </booktitle> <pages> 47(1-3), pp. 139-159, </pages> <month> January, </month> <year> 1991. </year> <title> [Business Week, 1992] "Smart Programs Go to Work," </title> <booktitle> Business Week, </booktitle> <pages> pp. </pages> <address> 97ff, March 2, </address> <year> 1992. </year>
Reference-contexts: There is what might be called the animat approach [Wilson, 1991], which holds that AI should concern itself first with building simple, insect-like, artifacts and gradually work its way up the evolutionary scale <ref> [Brooks, 1991] </ref>. Whatever one might believe about the long-range potential for this work, it is contributing significantly to our understanding of building autonomous systems that must function in a variety of complex, real environments and thus reinforces the trend toward habile systems.
Reference: [Chapman, 1987] <author> Chapman, D., </author> <title> "Planning for Conjunctive Goals," </title> <journal> Artificial Intelligence, </journal> <volume> 32: </volume> <pages> 333-377, </pages> <year> 1987. </year>
Reference-contexts: Some of the deficiencies were ameliorated by subsequent research [Waldinger, 1977, Sacerdoti 1977, Tate, 1977, Sussman, 1975]. Recent work by <ref> [Wilkins, 1988, Currie & Tate, 1991, Chapman, 1987] </ref> led to quite complex and useful planning and scheduling systems. Somewhere along this spectrum, however, we began to develop specialized planning capabilities that I think are not required of a general, intelligent system.
Reference: [Currie & Tate, 1991] <author> Currie, K. W., and Tate, A., "O-Plan: </author> <title> The Open Planning Architecture," </title> <journal> Artificial Intelligence, </journal> <volume> 51(1), </volume> <year> 1991. </year>
Reference-contexts: Some of the deficiencies were ameliorated by subsequent research [Waldinger, 1977, Sacerdoti 1977, Tate, 1977, Sussman, 1975]. Recent work by <ref> [Wilkins, 1988, Currie & Tate, 1991, Chapman, 1987] </ref> led to quite complex and useful planning and scheduling systems. Somewhere along this spectrum, however, we began to develop specialized planning capabilities that I think are not required of a general, intelligent system.
Reference: [Deale et al., 1994] <author> Deale, M., et al., </author> <title> "The Space Shuttle Ground Processing Scheduling System," in Zweben, </title> <editor> M, and Fox, M., </editor> <title> Intelligent Scheduling, </title> <address> San Francisco: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1994 </year>
Reference-contexts: After all, even the smartest human cannot (without the aid of special tools) plan NASA missions or lay out a factory schedule, but automatic planning programs can now do those things <ref> [Deale et al., 1994, Fox, 1984] </ref>. Other examples of refinement occur in the research area dealing with reasoning under uncertainty. Elaborate probabilistic reasoning schemes have been developed, and perhaps some of these computational processes are needed by intelligent systems.
Reference: [Drescher, 1991] <author> Drescher, G., </author> <title> Made-Up Minds: A Constructivist Approach to Artificial Intelligence, </title> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: At a similarly high level is an attempt to duplicate in computer agents some of the stages of Piagetian learning <ref> [Drescher, 1991] </ref>. All of these efforts are directed at understanding the common mechanisms in naturally occurring, biological individuals. The scientific quest to understand them will never cease, and will thus always exert a pull on the development of habile systems.
Reference: [Dreyfus & Dreyfus, 1985] <author> Dreyfus, H., and Dreyfus, S., </author> <title> Mind Over Machine, </title> <address> New York: </address> <publisher> MacMillan/The Free Press, </publisher> <year> 1985. </year>
Reference-contexts: Finally, the arguments of those who say "it can't be done" might have had some effect. People who know insufficient computer science, but yet consider themselves qualified to pronounce on what is possible and what is not, have been free with their opinions <ref> [Penrose, 1989, Penrose, 1994, Dreyfus & Dreyfus, 1985, Searle, 1980] </ref>.
Reference: [Etzioni & Weld, 1994] <author> Etzioni, O., and Weld, D., </author> <title> "A Softbot-Based Interface to the Internet," </title> <journal> Communications of the ACM, </journal> <volume> 37(7): </volume> <pages> 72-76, </pages> <month> July, </month> <year> 1994. </year>
Reference-contexts: Several people are working on prototypes that aim toward such 9 agents <ref> [Etzioni & Weld, 1994, Ball & Ling, 1993, Maes, 1994] </ref>.
Reference: [Feigenbaum, et al., 1971] <editor> Feigenbaum, E., et al., </editor> <title> "On Generality and Problem Solving: A Case Study Using the DENDRAL Program," </title> <editor> in Meltzer, B., and Michie, D., (eds.), </editor> <booktitle> Machine Intelligence 6, </booktitle> <pages> pp. 165-190, </pages> <publisher> Edinburgh: Edinburgh University Press, </publisher> <year> 1971. </year>
Reference-contexts: A representative performance program was DENDRAL <ref> [Feigenbaum, et al., 1971] </ref>). <p> A representative performance program was DENDRAL [Feigenbaum, et al., 1971]). Edward Feigenbaum and colleagues <ref> [Feigenbaum, et al., 1971, p. 187] </ref>, who are credited with having led the way toward the development of expert systems, put it this way: ": : : general problem-solvers are too weak to be used as the basis for building high performance systems. <p> Curiously, this view that "general intelligence" needs to be regarded as something separate from "specialist intelligence" was mentioned in the same 4 paper that helped to move the field toward concentrating on special intelli- gence. <ref> [Feigenbaum, et al., 1971, page 187] </ref> said: "The `big switch' hypothesis holds that generality in problem solving is achieved by arraying specialists at the terminals of a big switch.
Reference: [Fikes & Nilsson, 1971] <author> Fikes, R. E. and Nilsson, N. J., </author> <title> "STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving," </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 2(3-4): 189-208, </pages> <year> 1971. </year>
Reference: [Fox, 1984] <author> Fox, M., and Smith, S., </author> <title> "ISIS|A Knowledge-Based System for Factory Scheduling," </title> <journal> Expert Systems, </journal> <volume> 1(1), </volume> <year> 1984. </year>
Reference-contexts: After all, even the smartest human cannot (without the aid of special tools) plan NASA missions or lay out a factory schedule, but automatic planning programs can now do those things <ref> [Deale et al., 1994, Fox, 1984] </ref>. Other examples of refinement occur in the research area dealing with reasoning under uncertainty. Elaborate probabilistic reasoning schemes have been developed, and perhaps some of these computational processes are needed by intelligent systems.
Reference: [Genesereth, 1989] <author> Genesereth, M., </author> <title> "A Proposal for Research on Informable Agents," </title> <institution> Logic-89-9, Stanford University Computer Science Logic Group Report, </institution> <month> June </month> <year> 1989. </year> <month> 17 </month>
Reference-contexts: Agents having a continuous existence can learn from experience. New demands will create new applications, and agents must be able to learn how to solve new problems. All of the learning methods of AI will be needed here. Habile agents must be "informable" <ref> [Genesereth, 1989] </ref>. Humans will want to give advice to them that varies in precision from detailed instructions to vague hints. Since so much human knowledge exists in written form, we will want our agents to be able to get appropriate information from documents. These abilities also presuppose natural language skills.
Reference: [Genesereth, 1992] <author> Genesereth, M., </author> <title> "An Agent-Based Approach to Soft--ware Interoperability," </title> <booktitle> in Proceedings of the DARPA Software Technology Conference, </booktitle> <year> 1992. </year>
Reference-contexts: Such a personal assistant should have many of the features of habile agents: general common-sense knowledge, wide-ranging natural language ability, and continuous existence. As a step in that direction, the architecture being explored for CommerceNet uses an agent called a "facilitator" that has quite general capabilities <ref> [Genesereth, 1992] </ref>. Demand for habile personal assistants will be unceasing and growing as services available on the Internet continue to expand. 6.2 Entertainment, Education, and Simulation Interactive, multi-media video art and entertainment require characters that are "believable" in their emotions and actions [Bates, 1994].
Reference: [Genesereth & Fikes, et al., 1992] <author> Genesereth, M., and Fikes, R., et al., </author> <title> Knowledge Interchange Format Version 3 Reference Manual, </title> <institution> Logic-92-1, Stanford University Computer Science Logic Group Report, </institution> <year> 1992. </year>
Reference-contexts: Another project of general importance is the attempt to build an "inter-lingua" for knowledge representation such as the Knowledge Interchange Format (KIF) <ref> [Genesereth & Fikes, et al., 1992] </ref>. For efficiency, niche applications will want their specialized knowledge in customized formats, but some 13 of this knowledge, at least, will be the same as the knowledge needed by other niche systems.
Reference: [Green, 1969] <author> Green, C., </author> <title> "Application of Theorem Proving to Problem Solving," </title> <booktitle> Proceedings of the First International Joint Conference on Artificial Intelligence, </booktitle> <address> Washington, DC, </address> <year> 1969. </year>
Reference: [Grosz & Davis, 1994] <editor> Grosz, B., and Davis, R. (eds.), </editor> <title> "A Report to ARPA on Twenty-First Century Intelligent Systems," </title> <journal> AI Magazine, </journal> <pages> pp. 10-20, </pages> <month> Fall </month> <year> 1994. </year>
Reference-contexts: networks to help pinpoint oil and gas de posits deep below the earth's surface 1 Vic Reis, a former Director of the Advanced Research Projects Agency (ARPA), was quoted as saying that the DART system, used in deployment planning of operation Desert Shield, justified ARPA's entire investment in AI technology <ref> [Grosz & Davis, 1994, note 4, page 20] </ref>. 2 * The Internal Revenue Service is testing software designed to read tax returns and spot fraud * Spiegel uses neural networks to determine who on a vast mailing list are the most likely buyers of its products * American Airlines has an
Reference: [Guha & Lenat, 1990] <author> Guha, R., and Lenat, D., </author> <title> "Cyc: A Mid-Term Report," </title> <journal> The AI Magazine, </journal> <volume> Vol. 11, no. 3, </volume> <pages> pp. 32-59, </pages> <month> Fall, </month> <year> 1990. </year>
Reference-contexts: I'll remark on just three of the ones I know the most about. One is the CYC project led by Douglas Lenat <ref> [Guha & Lenat, 1990] </ref>. It has as its goal the building of a commonsense knowledge base containing millions of facts and their interrelationships.
Reference: [Hill, 1994] <author> Hill, G., </author> <title> "Cyber Servants," </title> <journal> The Wall Street Journal, </journal> <pages> page 1, </pages> <month> September 27, </month> <year> 1994. </year>
Reference-contexts: In the words of a Wall Street Journal article about electronic agents <ref> [Hill, 1994] </ref>: "The bigger the network and the more services on it, the greater the potential power of agents." All kinds of special "softbot" agents (sometimes called "spiders" when they inhabit the World Wide Web) have been proposed| personal assistants, database browsers, e-mail handlers, purchasing agents, and so forth.
Reference: [Holusha, 1994] <author> Holusha, J., </author> <title> "Industrial Robots Make the Grade," </title> <address> The New York Times, </address> <month> September 7, </month> <year> 1994. </year>
Reference-contexts: This need for realistic simulated agents exerts continuing pressure to develop ones with wide-ranging, human-like capabilities. 6.3 The Requirement for More Flexible Robots A recent article in The New York Times <ref> [Holusha, 1994] </ref> said " : : : sales are booming for robots, which are cheaper, stronger, faster and smarter than their predecessors." One reason for the sales increase is that robots are gradually becoming more flexible|in action and in perception.
Reference: [Iwasaki & Low, 1993] <author> Iwasaki, Y., and Low, C. M., </author> <title> "Model Generation and Simulation of Device Behavior with Continuous and Discrete Change," </title> <journal> Intelligent Systems Engineering, </journal> <volume> 1(2), </volume> <year> 1993. </year>
Reference-contexts: Several projects have as their goal making expert systems more flexible. One that is attempting to do so by giving such systems more general knowledge surrounding their specialized area is the "How Things Work" project at Stan-ford <ref> [Iwasaki & Low, 1993] </ref>, which is producing a knowledge base of general physical and electro-mechanical laws that would be useful to a wide variety of different expert systems. 6.6 The Scientific Interest to Understand How the Brain Works One of the motivations for AI research all along has been to gain
Reference: [Laird, et al., 1987] <author> Laird, J., et al., </author> <title> "Soar: An Architecture for General Intelligence," </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 1-64, </pages> <year> 1987. </year>
Reference-contexts: Such work also provides a base that arguably may be necessary to support higher cognitive functions. At a distinctly higher level is the work on Soar <ref> [Laird, et al., 1987] </ref>, an 12 architecture for general intelligence, which is aimed at modeling various cog-nitive and learning abilities of humans.
Reference: [McCarthy & Hayes, 1969] <author> McCarthy, J., and Hayes, P. J., </author> <title> "Some Philosophical Problems from the Standpoint of Artificial Intelligence," </title> <editor> in Meltzer, B., and Michie, D. (Eds.), </editor> <booktitle> Machine Intelligence 4, </booktitle> <pages> pp. 463-502, </pages> <publisher> Edinburgh: Edinburgh University Press, </publisher> <year> 1969. </year> <month> 18 </month>
Reference: [McCarthy, 1990] <author> McCarthy, J., </author> <title> "Some Expert Systems Need Common--sense," </title> <editor> in Lifschitz, V. (ed.), </editor> <title> Formalizing Common Sense: </title> <booktitle> Papers by John McCarthy, </booktitle> <pages> pp. 189-197, </pages> <address> Norwood, NJ: </address> <publisher> Ablex, </publisher> <year> 1990. </year>
Reference-contexts: Worse, they don't even know when they are off their mesa. These expert systems need what John 11 McCarthy <ref> [McCarthy, 1990] </ref> calls commonsense|without it they are idiot savants. There is growing insistence that these programs be less brittle. Making their "knowledge cliff" less steep means extending their competence at least to semi-hability in the areas surrounding their field of expertise.
Reference: [McCarthy, 1958] <author> McCarthy, J., </author> <title> "Programs with Common Sense," </title> <booktitle> Mechani-sation of Thought Processes, Proceedings of the Symposium of the National Physics Laboratory, </booktitle> <volume> Vol. I, </volume> <pages> pp. 77-84, </pages> <address> Lon-don, UK: Her Majesty's Stationary Office, </address> <year> 1958. </year>
Reference-contexts: McCarthy's work on commonsense reasoning <ref> [McCarthy, 1958, McCarthy, 1986] </ref> has been directly aimed at general, intelligent systems. The same can be said for Minsky's work on structuring knowledge in"frames" [Minsky, 1975] and on his "society of mind" [Minsky, 1986]. Newell's work on production systems and Soar [Newell, 1990] focussed on the same prize.
Reference: [McCarthy, 1986] <author> McCarthy, J., </author> <title> "Applications of Circumscription to Formalizing Commonsense Knowledge," </title> <journal> Artificial Intelligence, </journal> <volume> 28(1): </volume> <pages> 89-116, </pages> <year> 1986. </year>
Reference-contexts: McCarthy's work on commonsense reasoning <ref> [McCarthy, 1958, McCarthy, 1986] </ref> has been directly aimed at general, intelligent systems. The same can be said for Minsky's work on structuring knowledge in"frames" [Minsky, 1975] and on his "society of mind" [Minsky, 1986]. Newell's work on production systems and Soar [Newell, 1990] focussed on the same prize.
Reference: [Maes, 1994] <author> Maes, P., </author> <title> "Agents that Reduce Work and Information Overload," </title> <journal> Communications of the ACM, </journal> <volume> 37(7): </volume> <pages> 31-40, </pages> <month> July, </month> <year> 1994. </year>
Reference-contexts: Several people are working on prototypes that aim toward such 9 agents <ref> [Etzioni & Weld, 1994, Ball & Ling, 1993, Maes, 1994] </ref>.
Reference: [Miller et al., 1982] <author> Miller, R. et al., "INTERNIST-1: </author> <title> An Experimental Computer-Based Diagnostic Consultant for General Internal Medicine," </title> <journal> New England Journal of Medicine, </journal> <volume> 307 </volume> <pages> 468-476, </pages> <year> 1982. </year>
Reference-contexts: The components and knowledge needed for extreme specialization are not necessarily those that will be needed for general intelligence. Some medical diagnosis programs, for example, have expert medical knowledge comparable to that of human physicians who have had years of training and practice <ref> [Miller et al., 1982] </ref>. Yet, these doctors were already far more intelligent, generally, before attending medical school than are the best of our AI systems.
Reference: [Minsky, 1975] <author> Minsky, M., </author> <title> "A Framework for Representing Knowledge," </title> <editor> in Winston, P. H. (ed.), </editor> <booktitle> The Psychology of Computer Vision, </booktitle> <pages> pp. 211-277, </pages> <address> New York: </address> <publisher> McGraw-Hill, </publisher> <year> 1975. </year>
Reference-contexts: McCarthy's work on commonsense reasoning [McCarthy, 1958, McCarthy, 1986] has been directly aimed at general, intelligent systems. The same can be said for Minsky's work on structuring knowledge in"frames" <ref> [Minsky, 1975] </ref> and on his "society of mind" [Minsky, 1986]. Newell's work on production systems and Soar [Newell, 1990] focussed on the same prize.
Reference: [Minsky, 1986] <author> Minsky, M., </author> <booktitle> The Society of Mind, </booktitle> <address> New York: </address> <publisher> Simon and Schuster, </publisher> <year> 1986. </year>
Reference-contexts: McCarthy's work on commonsense reasoning [McCarthy, 1958, McCarthy, 1986] has been directly aimed at general, intelligent systems. The same can be said for Minsky's work on structuring knowledge in"frames" [Minsky, 1975] and on his "society of mind" <ref> [Minsky, 1986] </ref>. Newell's work on production systems and Soar [Newell, 1990] focussed on the same prize. Now it appears that there are strong and insistent reasons for many others also to resume work on AI's original goal of building systems with humanlike capabilities.
Reference: [Newell, 1990] <author> Newell, A., </author> <title> Unified Theories of Cognition, </title> <address> Cambridge, MA: </address> <publisher> Harvard University Press, </publisher> <year> 1990. </year>
Reference-contexts: McCarthy's work on commonsense reasoning [McCarthy, 1958, McCarthy, 1986] has been directly aimed at general, intelligent systems. The same can be said for Minsky's work on structuring knowledge in"frames" [Minsky, 1975] and on his "society of mind" [Minsky, 1986]. Newell's work on production systems and Soar <ref> [Newell, 1990] </ref> focussed on the same prize. Now it appears that there are strong and insistent reasons for many others also to resume work on AI's original goal of building systems with humanlike capabilities.
Reference: [Newell, 1992] <author> Newell, A., </author> <title> "Fairy Tales," </title> <journal> The AI Magazine, </journal> <volume> vol. 13, no. 4, </volume> <pages> pp. 46-48, </pages> <month> Winter, </month> <year> 1992. </year>
Reference-contexts: With the right sort of research support, AI will now proceed along two parallel paths|specialized systems and habile systems. Niche systems will continue to be developed because there are so many niches where computation is cost-effective. Newell foresaw this path when he charmingly predicted <ref> [Newell, 1992] </ref> that there would someday be "brakes that know how to stop on wet pavement, instruments that can converse with their users, bridges that watch out for the safety of those who cross them, streetlights that care about those who stand under them|who know the way, so no one need
Reference: [Newell, Shaw & Simon, 1960] <author> Newell, A., Shaw, J. C., and Simon, H. A., </author> <title> "Report on a General Problem-Solving Program for a Computer," </title> <booktitle> Information Processing: Proc. of the Int. Conf. on Information Processing, UNESCO, Paris, </booktitle> <pages> pp. 256-264, </pages> <year> 1960. </year> <month> 19 </month>
Reference-contexts: In its early stages, the field of artificial intelligence (AI) had as its main goal the invention of computer programs having the general problem-solving abilities of humans. One such program was the General Problem Solver, GPS <ref> [Newell, Shaw & Simon, 1960] </ref>, which used what have come to be called weak methods to search for solutions to simple problems. Many of the early AI programs dealt with toy problems|puzzles and games that humans sometimes find challenging but that they can usually solve without special training.
Reference: [Newell & Simon, 1976] <author> Newell, A. and Simon, H. A., </author> <title> "Computer Science as Empirical Inquiry: Symbols and Search," </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 19(3): </volume> <pages> 113-126, </pages> <year> 1976. </year>
Reference-contexts: Alan Turing [Turing, 1950] was among the first to speculate that " : : : machines will eventually compete with men in all purely intellectual fields." Allen Newell and Herb Simon <ref> [Newell & Simon, 1976] </ref> made this speculation more crisp in their physical symbol system hypothesis: "A physical symbol system [such as a digital computer] has the necessary and sufficient means for general intelligent action" (emphasis mine).
Reference: [Pearson, et al., 1993] <author> Pearson, D., et al., </author> <title> "Intelligent Multi-Level Control in a Highly Reactive Domain," </title> <editor> in Groen, F., Hirose, S., and Thorpe, C., </editor> <booktitle> Intelligent Autonomous Systems, IAS-3, </booktitle> <pages> pp. 449-458, </pages> <address> Washington: </address> <publisher> IOS Press, </publisher> <year> 1993. </year>
Reference-contexts: It is interesting to note that even with these general goals, the Soar architecture can be specialized to function as an expert system for configuring computer systems as well as for a number of other specialized tasks <ref> [Rosenbloom, et al., 1985, Pearson, et al., 1993] </ref>. At a similarly high level is an attempt to duplicate in computer agents some of the stages of Piagetian learning [Drescher, 1991]. All of these efforts are directed at understanding the common mechanisms in naturally occurring, biological individuals.
Reference: [Penrose, 1989] <author> Penrose, R., </author> <title> The Emperor's New Mind: Concerning Computers, Minds, and the Laws of Physics, </title> <publisher> Oxford: The Oxford University Press, </publisher> <year> 1989. </year>
Reference-contexts: Finally, the arguments of those who say "it can't be done" might have had some effect. People who know insufficient computer science, but yet consider themselves qualified to pronounce on what is possible and what is not, have been free with their opinions <ref> [Penrose, 1989, Penrose, 1994, Dreyfus & Dreyfus, 1985, Searle, 1980] </ref>.
Reference: [Penrose, 1994] <author> Penrose, R., </author> <title> Shadows of the Mind: Search for the Missing Science of Consciousness, </title> <publisher> Oxford: The Oxford University Press, </publisher> <year> 1994. </year>
Reference-contexts: Finally, the arguments of those who say "it can't be done" might have had some effect. People who know insufficient computer science, but yet consider themselves qualified to pronounce on what is possible and what is not, have been free with their opinions <ref> [Penrose, 1989, Penrose, 1994, Dreyfus & Dreyfus, 1985, Searle, 1980] </ref>.
Reference: [Riecken & Minsky, 1994] <author> Riecken, D., and Minsky, M., </author> <title> "A Conversation wilth Marvin Minsky About Agents," </title> <journal> Communications of the ACM, </journal> <volume> 37(7): </volume> <pages> 23-29, </pages> <month> July, </month> <year> 1994. </year>
Reference-contexts: I think projects of this sort are very important to AI's long-range goals, and I agree with Marvin Minsky who said "I find it heartbreaking [that] there still are not a dozen other such projects [like CYC] in the world, : : : " <ref> [Riecken & Minsky, 1994] </ref>. Another project of general importance is the attempt to build an "inter-lingua" for knowledge representation such as the Knowledge Interchange Format (KIF) [Genesereth & Fikes, et al., 1992].
Reference: [Rosenbloom, et al., 1985] <author> Rosenbloom, P., "R1-Soar: </author> <title> An Experiment in Knowledge-Intensive Programming in a Problem-Solving Architecture," </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 7 </volume> <pages> 561-569, </pages> <year> 1985. </year>
Reference-contexts: It is interesting to note that even with these general goals, the Soar architecture can be specialized to function as an expert system for configuring computer systems as well as for a number of other specialized tasks <ref> [Rosenbloom, et al., 1985, Pearson, et al., 1993] </ref>. At a similarly high level is an attempt to duplicate in computer agents some of the stages of Piagetian learning [Drescher, 1991]. All of these efforts are directed at understanding the common mechanisms in naturally occurring, biological individuals.
Reference: [Sacerdoti 1977] <author> Sacerdoti, E. D., </author> <title> A Structure for Plans and Behavior, </title> <address> New York: </address> <publisher> Elsevier, </publisher> <year> 1977. </year>
Reference-contexts: Some of the deficiencies were ameliorated by subsequent research <ref> [Waldinger, 1977, Sacerdoti 1977, Tate, 1977, Sussman, 1975] </ref>. Recent work by [Wilkins, 1988, Currie & Tate, 1991, Chapman, 1987] led to quite complex and useful planning and scheduling systems.
Reference: [Searle, 1980] <author> Searle, J., </author> <title> "Minds, Brains, and Programs," </title> <journal> Behavioral and Brain Sciences, </journal> <volume> vol 3, </volume> <year> 1980. </year>
Reference-contexts: Finally, the arguments of those who say "it can't be done" might have had some effect. People who know insufficient computer science, but yet consider themselves qualified to pronounce on what is possible and what is not, have been free with their opinions <ref> [Penrose, 1989, Penrose, 1994, Dreyfus & Dreyfus, 1985, Searle, 1980] </ref>. <p> Out of these pronouncements has come the distinction between "strong AI" and "weak AI." In the words of <ref> [Searle, 1980] </ref>: "According to weak AI, the principal value of the computer in the study of the mind is that it gives us a very powerful tool. For example, it enables us to formulate and test hypotheses in a more rigorous and precise fashion.
Reference: [Shoham, 1993] <author> Shoham, Y., </author> <title> "Agent Oriented Programming," </title> <journal> Artificial Intelligence, </journal> <volume> 60, 1 </volume> <pages> 51-92, </pages> <year> 1993. </year>
Reference-contexts: Agents that are part of communities of agents will need knowledge of each other's "cognitive structure" and how to affect the beliefs and goals in such structures through communication. Yoav Shoham's Agent-Oriented Programming (AOP) formalism <ref> [Shoham, 1993] </ref> is one attempt to facilitate the construction of communicating agents. 8 Summary and Conclusions AI's founding fathers, Marvin Minsky, John McCarthy, and Allen Newell, always kept their eyes on the prize|even though they pursued different paths toward it.
Reference: [Stroustrup, 1994] <author> Stroustrup, B., </author> <title> The Design and Evolution of C++, </title> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1994. </year> <month> 20 </month>
Reference-contexts: Of course, what we gain in breadth, we will probably have to give up in depth. This trade-off (applied to programming languages) was nicely expressed by <ref> [Stroustrup, 1994, page 201] </ref> 2 : For every single specific question, you can construct a language or system that is a better answer than C++.
Reference: [Sussman, 1975] <author> Sussman, G. J., </author> <title> A Computer Model of Skill Acquisition, </title> <address> New York: </address> <publisher> American Elsevier, </publisher> <year> 1975. </year>
Reference-contexts: Some of the deficiencies were ameliorated by subsequent research <ref> [Waldinger, 1977, Sacerdoti 1977, Tate, 1977, Sussman, 1975] </ref>. Recent work by [Wilkins, 1988, Currie & Tate, 1991, Chapman, 1987] led to quite complex and useful planning and scheduling systems.
Reference: [Tate, 1977] <author> Tate, A., </author> <title> "Generating Project Networks," </title> <booktitle> Proceedings of the Fifth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 888-893, </pages> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1977. </year>
Reference-contexts: Some of the deficiencies were ameliorated by subsequent research <ref> [Waldinger, 1977, Sacerdoti 1977, Tate, 1977, Sussman, 1975] </ref>. Recent work by [Wilkins, 1988, Currie & Tate, 1991, Chapman, 1987] led to quite complex and useful planning and scheduling systems.
Reference: [Turing, 1950] <author> Turing, </author> <title> A., </title> <journal> "Computing Machinery and Intelligence," Mind, </journal> <volume> 59 </volume> <pages> 433-460, </pages> <month> October, </month> <year> 1950. </year>
Reference-contexts: 1 Diversions from the Main Goal Over forty years ago, soon after the birth of electronic computers, people began to think that human levels of intelligence might someday be realized in computer programs. Alan Turing <ref> [Turing, 1950] </ref> was among the first to speculate that " : : : machines will eventually compete with men in all purely intellectual fields." Allen Newell and Herb Simon [Newell & Simon, 1976] made this speculation more crisp in their physical symbol system hypothesis: "A physical symbol system [such as a
Reference: [Waldinger, 1977] <author> Waldinger, R. J., </author> <title> "Achieving Several Goals Simultaneously," </title> <editor> in Elcock, E. and Michie, D. (eds.), </editor> <booktitle> Machine Intelligence 8: Machine Representations of Knowledge, </booktitle> <pages> pp. 94-136, </pages> <address> Chichester, UK: </address> <publisher> Ellis Horwood, </publisher> <year> 1977. </year>
Reference-contexts: Some of the deficiencies were ameliorated by subsequent research <ref> [Waldinger, 1977, Sacerdoti 1977, Tate, 1977, Sussman, 1975] </ref>. Recent work by [Wilkins, 1988, Currie & Tate, 1991, Chapman, 1987] led to quite complex and useful planning and scheduling systems.
Reference: [Wilkins, 1988] <author> Wilkins, D. E., </author> <title> Practical Planning: Extending the Classical AI Planning Paradigm, </title> <address> San Francisco: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: Some of the deficiencies were ameliorated by subsequent research [Waldinger, 1977, Sacerdoti 1977, Tate, 1977, Sussman, 1975]. Recent work by <ref> [Wilkins, 1988, Currie & Tate, 1991, Chapman, 1987] </ref> led to quite complex and useful planning and scheduling systems. Somewhere along this spectrum, however, we began to develop specialized planning capabilities that I think are not required of a general, intelligent system.
Reference: [Wilson, 1991] <author> Wilson, S., </author> <title> "The Animat Path to AI," </title> <editor> in Meyer, J. A., and Wilson, S. (eds.), </editor> <booktitle> From Animals to Animats; Proceedings of the First International Conference on the Simulation of Adaptive Behavior, </booktitle> <publisher> The MIT Press/Bradford Books, </publisher> <address> Cam-bridge, MA, </address> <year> 1991. </year> <month> 21 </month>
Reference-contexts: Even within AI, there are several approaches being followed by people whose main interest is the scientific study of mental functioning. There is what might be called the animat approach <ref> [Wilson, 1991] </ref>, which holds that AI should concern itself first with building simple, insect-like, artifacts and gradually work its way up the evolutionary scale [Brooks, 1991].
References-found: 50

