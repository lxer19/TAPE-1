URL: http://www.ai.sri.com/~luong/research/publications/RR-2014.ps.Z
Refering-URL: http://www.ai.sri.com/~luong/research/publications/publications.html
Root-URL: 
Title: Self-calibration of a stereo rig from unknown camera motions and point correspondences  
Author: Quang-Tuan LUONG Olivier FAUGERAS 
Date: 2014 Juillet 1993  
Note: N  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> H. Asada and M. Brady. </author> <title> The curvature primal sketch. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8 </volume> <pages> 2-14, </pages> <year> 1986. </year> <note> 32 Quang-Tuan LUONG Olivier FAUGERAS </note>
Reference-contexts: The features that we found to be the most useful are corners, as some vertexes (triple junctions) result from occlusion. There are three main approaches to the problem of corner detection: * The first one is to extract features such as edges chains <ref> [1] </ref> [30] or polygonal approximations [35] , and then to search for corners using these data. Apart from the com-putationnal cost, these methods suffer from the possible difference of the intermediate features extracted in the various images.
Reference: [2] <author> P.R. Beaudet. </author> <title> Rotational invariant image operators. </title> <booktitle> In Proc. International Conference on Pattern Recognition, </booktitle> <pages> pages 579-583, </pages> <year> 1978. </year>
Reference-contexts: Apart from the com-putationnal cost, these methods suffer from the possible difference of the intermediate features extracted in the various images. Self-calibration of a stereo rig from unknown camera motions and point correspondences 5 * The second one <ref> [2, 8, 22, 48, 33, 40, 17] </ref> is to first apply a differential operator measuring gradients and curvatures of image intensity surface, and then to select points that are corners by a second operator that is often a thresholding scheme.
Reference: [3] <author> H.H. Chen. </author> <title> A screw motion approach to uniqueness analysis of head-eye geometry. </title> <booktitle> In Proc. of the conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 145-151, </pages> <year> 1991. </year>
Reference-contexts: The first equation has been much studied in the framework of hand-eye calibration [4] [42], [46], <ref> [3] </ref>. Thus the reader is refered to those references for a more detailed analysis of unicity 22 Quang-Tuan LUONG Olivier FAUGERAS and sensitivity. We just show below that if we do two displacements of the stereo rig, we can solve the two resulting matrix equations (26) to compute R.
Reference: [4] <author> J.C.K. Chou and M. Kamel. </author> <title> Quaternions approach to solve the kinematic equation of rotation, A a A x = A x A a , of a sensor-mounted robotic manipulator. </title> <booktitle> In Proc. International Conference on Robotics and Automation, </booktitle> <pages> pages 656-662, </pages> <year> 1988. </year>
Reference-contexts: Equation (25) can be decomposed in the following two matrix equations: RR 1 = R 2 R (26) where 1 and 2 are unknown scale factors associated to D 1 and D 2 , respectively. The first equation has been much studied in the framework of hand-eye calibration <ref> [4] </ref> [42], [46], [3]. Thus the reader is refered to those references for a more detailed analysis of unicity 22 Quang-Tuan LUONG Olivier FAUGERAS and sensitivity. <p> Since s 1 = s 2 and s 0 2 , we finally obtain the equation: u 1 :u 0 2 (35) We have then shown that this equation is equivalent to the constraint (34). A linear method to take into account multiple motions We can also as <ref> [4] </ref> use the quaternion representation of rotations to obtain a linear solution. We can notice that (28) has the same form than (19).
Reference: [5] <author> R. Deriche and T. Blaszka. </author> <title> Recovering and characterizing image features using an efficient model based approach. </title> <booktitle> In Proc. International Conference on Computer Vision and Pattern Recognition, </booktitle> <year> 1993. </year> <note> Submitted. </note>
Reference-contexts: It is a global and quite efficient approach, however it has been shown [7] that the most notorious algorithms of this family yield a precision in the positionning of only a few pixels. * The third one <ref> [16, 38, 5] </ref> is to use an explicit model of the local image structure in the neighborhood of the target corner, and to search the numerical parameters of such a model by a non-linear minimization. <p> We use between 20 and 30 corners, which are extracted with a sub-pixel accuracy, semiautomatically, by the program of Blaszka and Deriche <ref> [5] </ref>. Correspondence is, in this experiment, performed manually, and followed by an automatic elimination of false matches. It should be noted that the corresponding points between pairs of images are different, that is, points need not be seen in the three views.
Reference: [6] <author> R. Deriche and O.D. Faugeras. </author> <title> Tracking line segments. </title> <journal> Image and Vision Computing, </journal> <volume> 8(4) </volume> <pages> 261-270, </pages> <month> November </month> <year> 1990. </year> <note> A shorter version appeared in the Proceedings of the 1st ECCV. </note>
Reference-contexts: Correspondences: Once the corners have been obtained independently in each image, the correspondences can be obtained using standard correlation techniques [21, 14] [15] in the general discrete case, or by a tracking technique, such as the one presented in <ref> [6] </ref>, in the case a long sequence of images is available. Note that an initial estimate of the epipolar geometry, obtained with at least seven point matches can be used to further refine the correspondence process.
Reference: [7] <author> R. Deriche and G. Giraudon. </author> <title> A computational approach for corner and vertex detection. </title> <journal> The International Journal of Computer Vision, </journal> <note> 1993. Accepted for Publication. </note>
Reference-contexts: It is a global and quite efficient approach, however it has been shown <ref> [7] </ref> that the most notorious algorithms of this family yield a precision in the positionning of only a few pixels. * The third one [16, 38, 5] is to use an explicit model of the local image structure in the neighborhood of the target corner, and to search the numerical parameters
Reference: [8] <author> L. Dreschler and H.H. Nagel. </author> <title> On the selection of critical points and local curvature extrema of region boundaries for interframe matching. </title> <booktitle> In Proc. International Conference on Pattern Recognition, </booktitle> <pages> pages 542-544, </pages> <year> 1982. </year>
Reference-contexts: Apart from the com-putationnal cost, these methods suffer from the possible difference of the intermediate features extracted in the various images. Self-calibration of a stereo rig from unknown camera motions and point correspondences 5 * The second one <ref> [2, 8, 22, 48, 33, 40, 17] </ref> is to first apply a differential operator measuring gradients and curvatures of image intensity surface, and then to select points that are corners by a second operator that is often a thresholding scheme.
Reference: [9] <author> O.D. Faugeras. </author> <title> What can be seen in three dimensions with an uncalibrated stereo rig. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 563-578, </pages> <year> 1992. </year>
Reference-contexts: A variant of the method allows to compute the relative displacements between three cameras. 2 Computing the fundamental matrix Almost all the point-based algorithms which start from multiple, uncalibrated images <ref> [9] </ref> [18] [36] [41] require, as the basic information, the fundamental matrix, which is the only alternative to projection matrices, in order to relate two views of the same scene. It is also the case for the self-calibration algorithm.
Reference: [10] <author> O.D. Faugeras, Q.-T. Luong, and S.J. Maybank. </author> <title> Camera self-calibration: theory and experiments. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 321-334, </pages> <address> Santa-Margerita, Italy, </address> <year> 1992. </year>
Reference-contexts: The first one <ref> [10] </ref> takes advantage of the fact that these equations are polynomial, of degree two in the Kruppa coefficients. Thus, having done three displacements, we can use semi-analytical methods to solve the resulting polynomial system of six equations in six homogeneous unk-nows.
Reference: [11] <author> O.D. Faugeras and S.J. Maybank. </author> <title> Motion from point matches: multiplicity of solutions. </title> <journal> The International Journal of Computer Vision, </journal> <volume> 4(3) </volume> <pages> 225-246, </pages> <year> 1990. </year> <note> also INRIA Tech. Report 1157. </note>
Reference-contexts: Several equivalent formulations are possible. The most interesting formulation is to use the Kruppa equations [23], first introduced in the field of computer vision by Faugeras and Maybank for the study of motion <ref> [11] </ref> , and then to develop a theory of self-calibration [29]. The Kruppa equations are obtained from a geometric interpretation of the rigidity constraints: the tangents to the image ! of the absolute conic 1 in two views taken by the same camera correspond under the epipolar transformation.
Reference: [12] <author> O.D. Faugeras and G. Toscani. </author> <title> The calibration problem for stereo. </title> <booktitle> In Proceedings of CVPR'86, </booktitle> <pages> pages 15-20, </pages> <year> 1986. </year>
Reference-contexts: the coordinate system of the first camera In the case of a trinocular stereo rig, we have of course 5 more intrinsic parameters represented by A 3 and 6 more extrinsic parameters represented D 0 to determine. 1.2 What do we mean by self-calibration In the usual method of calibration <ref> [12] </ref> [44] a special object (calibration grid) is put in the field of view of the cameras. It is assumed that we have a 3D model of this object, that is we know the 3D coordinates of some of its reference points, in a coordinate system attached to the object. <p> Figure 11 shows the points of interest matched between image 1 and image 2. The standard calibration is performed on each image, using the algorithm of Robert [36], which is a much improved version of the linear method of Fau-geras and Toscani <ref> [12] </ref>. From the projection matrices obtained by this algorithm, the three fundamental matrices F 12 , F 23 , F 13 are computed and used as a reference for the comparisons with our algorithm which computes the fundamental matrices from the point matches. The resulting epipoles are shown table 1.
Reference: [13] <author> Olivier D. Faugeras, Francis Lustman, and Giorgio Toscani. </author> <title> Motion and Structure from point and line matches. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 25-34, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: Our next goal is to compute the three-dimensionnal motion from pairs of images. This computation can be done quite robustly even with imprecise camera parameters. 4.1 Two approaches based on the computation of the fundamen tal matrix The motion determination problem from point correspondences is is very classical. See <ref> [13] </ref> [43] [47] [20] for solutions similar to ours. We present two different solutions, both based on the computation of the fundamental matrix. <p> direct factorization We have seen that during the course of intrinsic parameters estimation, we had to compute the fundamental matrix F, from which the essential matrix is immediately obtained: E = A T FA (17) The problem of finding the rotation R and the translation t from E is classical <ref> [25, 45, 13] </ref>. As we have, by construction, found a F-matrix of rank two, the direction of translation is just obtained by solving: E T t = 0. <p> As we have, by construction, found a F-matrix of rank two, the direction of translation is just obtained by solving: E T t = 0. To find the rotation, we use a method introduced by <ref> [13] </ref>: in the presence of noise, we minimize with respect to the rotation matrix R the criterion: C = i=1 where E i and T i are the 3 lines of the matrices E and T, respectively.
Reference: [14] <author> W. Forstner and A. Pertl. </author> <title> Photogrammetric standard methods and digital image matching techniques for high precision surface measurements. </title> <editor> In Gelsema, E.S. and Kanal, L.N., editor, </editor> <booktitle> Pattern Recognition in Practice II, </booktitle> <pages> pages 57-72. </pages> <publisher> Elsevier Science Publishers, </publisher> <year> 1986. </year> <title> Self-calibration of a stereo rig from unknown camera motions and point correspondences 33 </title>
Reference-contexts: The main drawback is the high computationnal cost, and the difficulty to perform the method in a purely automatic manner. Correspondences: Once the corners have been obtained independently in each image, the correspondences can be obtained using standard correlation techniques <ref> [21, 14] </ref> [15] in the general discrete case, or by a tracking technique, such as the one presented in [6], in the case a long sequence of images is available.
Reference: [15] <author> D.B. Gennery. </author> <title> Modelling the Environment of an Exploring Vehicle by means of Stereo Vision. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> June </month> <year> 1980. </year>
Reference-contexts: The main drawback is the high computationnal cost, and the difficulty to perform the method in a purely automatic manner. Correspondences: Once the corners have been obtained independently in each image, the correspondences can be obtained using standard correlation techniques [21, 14] <ref> [15] </ref> in the general discrete case, or by a tracking technique, such as the one presented in [6], in the case a long sequence of images is available.
Reference: [16] <author> A. Guiducci. </author> <title> Corner characterization by differential geometry techniques. </title> <journal> Pattern Recognition Letters, </journal> <volume> 8 </volume> <pages> 311-318, </pages> <year> 1988. </year>
Reference-contexts: It is a global and quite efficient approach, however it has been shown [7] that the most notorious algorithms of this family yield a precision in the positionning of only a few pixels. * The third one <ref> [16, 38, 5] </ref> is to use an explicit model of the local image structure in the neighborhood of the target corner, and to search the numerical parameters of such a model by a non-linear minimization.
Reference: [17] <author> C. Harris and M. Stephens. </author> <title> A combined corner and edge detector. </title> <booktitle> In Proc. Alvey Vision Conference, </booktitle> <pages> pages 189-192, </pages> <year> 1988. </year>
Reference-contexts: Apart from the com-putationnal cost, these methods suffer from the possible difference of the intermediate features extracted in the various images. Self-calibration of a stereo rig from unknown camera motions and point correspondences 5 * The second one <ref> [2, 8, 22, 48, 33, 40, 17] </ref> is to first apply a differential operator measuring gradients and curvatures of image intensity surface, and then to select points that are corners by a second operator that is often a thresholding scheme.
Reference: [18] <author> R. Hartley, R. Gupta, and T. Chang. </author> <title> Stereo from uncalibrated cameras. </title> <booktitle> In Proc. of the conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 761-764, </pages> <address> Urbana, </address> <year> 1992. </year>
Reference-contexts: A variant of the method allows to compute the relative displacements between three cameras. 2 Computing the fundamental matrix Almost all the point-based algorithms which start from multiple, uncalibrated images [9] <ref> [18] </ref> [36] [41] require, as the basic information, the fundamental matrix, which is the only alternative to projection matrices, in order to relate two views of the same scene. It is also the case for the self-calibration algorithm.
Reference: [19] <author> R.I. </author> <title> Hartley. Estimation of relative camera positions for uncalibrated cameras. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 579-587, </pages> <year> 1992. </year>
Reference-contexts: It can be noted that this solution is entirely equivalent to the well-known method of Tsai and Huang [45] , which has been recently proved to be optimal by Hartley <ref> [19] </ref> . We denote this algorithm by FACTOR. 14 Quang-Tuan LUONG Olivier FAUGERAS An iterative solution An alternative method is to use directly the criterion that has been used to determine the fundamental matrix.
Reference: [20] <author> B.K.P. Horn. </author> <title> Relative orientation. </title> <journal> The International Journal of Computer Vision, </journal> <volume> 4(1) </volume> <pages> 59-78, </pages> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: This computation can be done quite robustly even with imprecise camera parameters. 4.1 Two approaches based on the computation of the fundamen tal matrix The motion determination problem from point correspondences is is very classical. See [13] [43] [47] <ref> [20] </ref> for solutions similar to ours. We present two different solutions, both based on the computation of the fundamental matrix.
Reference: [21] <author> R.E. Kelly, P.R.H. McConnell, and S.J. Mildenberger. </author> <title> The gestalt photomapper. </title> <journal> Pho-togrammetric Engineering and Remote Sensing, </journal> <volume> 43 </volume> <pages> 1407-1417, </pages> <year> 1977. </year>
Reference-contexts: The main drawback is the high computationnal cost, and the difficulty to perform the method in a purely automatic manner. Correspondences: Once the corners have been obtained independently in each image, the correspondences can be obtained using standard correlation techniques <ref> [21, 14] </ref> [15] in the general discrete case, or by a tracking technique, such as the one presented in [6], in the case a long sequence of images is available.
Reference: [22] <author> L. Kitchen and A. Rosenfeld. </author> <title> Gray-level corner detection. </title> <journal> Pattern Recognition Letters, </journal> <pages> pages 95-102, </pages> <year> 1982. </year>
Reference-contexts: Apart from the com-putationnal cost, these methods suffer from the possible difference of the intermediate features extracted in the various images. Self-calibration of a stereo rig from unknown camera motions and point correspondences 5 * The second one <ref> [2, 8, 22, 48, 33, 40, 17] </ref> is to first apply a differential operator measuring gradients and curvatures of image intensity surface, and then to select points that are corners by a second operator that is often a thresholding scheme.
Reference: [23] <author> E. Kruppa. </author> <title> Zur Ermittlung eines Objektes aus zwei Perspektiven mit innerer Orien-tierung. </title> <journal> Sitz.-Ber. Akad. Wiss., Wien, math. naturw. Kl., Abt. IIa., </journal> <volume> 122 </volume> <pages> 1939-1948, </pages> <year> 1913. </year>
Reference-contexts: Several equivalent formulations are possible. The most interesting formulation is to use the Kruppa equations <ref> [23] </ref>, first introduced in the field of computer vision by Faugeras and Maybank for the study of motion [11] , and then to develop a theory of self-calibration [29].
Reference: [24] <author> R. Kumar and A. Hanson. </author> <title> Sensibility of the pose refinement problem to accurate estimation of camera parameters. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 365-369, </pages> <address> Osaka, Japan, </address> <year> 1990. </year>
Reference-contexts: Sensitivity to imprecision on intrinsic parameters Very few results are available concerning the sensitivity of motion and structure computations to imprecision on the intrinsic parameters <ref> [24] </ref>. It is nevertheless an important issue, as it determines the precision of calibration that it is necessary to achieve to obtain a given precision on the threedimen sionnal reconstruction, which is the final objective. We give here some experimental results which give an idea of the numerical values.
Reference: [25] <author> H.C. Longuet-Higgins. </author> <title> A Computer Algorithm for Reconstructing a Scene from Two Projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: In that case, the fundamental matrix reduces to an essential matrix <ref> [25] </ref>. But if one wants to proceed only from image measurements, the fundamental matrix is the key concept, since it contains all the geometrical information relating two different images. <p> If we restrict ourselves to the realistic case of an orthogonal pixel grid, two displacements are sufficient. 3.1 The principle of the method The Longuet-Higgins equation <ref> [25] </ref>, applies when using normalized coordinates, and thus calibrated cameras. <p> direct factorization We have seen that during the course of intrinsic parameters estimation, we had to compute the fundamental matrix F, from which the essential matrix is immediately obtained: E = A T FA (17) The problem of finding the rotation R and the translation t from E is classical <ref> [25, 45, 13] </ref>. As we have, by construction, found a F-matrix of rank two, the direction of translation is just obtained by solving: E T t = 0.
Reference: [26] <institution> Q.-T. Luong. Matrice fondamentale et calibration visuelle sur l'environnement: vers une plus grande autonomie des systemes robotiques. </institution> <type> PhD thesis, </type> <institution> Universite de Paris-Sud., </institution> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: following criterion give good results: min X ( k 11 k 12 00 ) 2 + ( k 22 k 12 00 ) 2 + ( k 22 k 11 00 ) 2 (16) For more details on solving the Kruppa equations, and numerous simulations the reader is refered to <ref> [26] </ref>. Self-calibration of a stereo rig from unknown camera motions and point correspondences 13 4 Computing the motion of the camera We suppose now that we have obtained the intrinsic parameters A of a camera. Our next goal is to compute the three-dimensionnal motion from pairs of images.
Reference: [27] <author> Q.-T. Luong, R. Deriche, O.D. Faugeras, and T. Papadopoulo. </author> <title> On determining the Fundamental matrix: analysis of different methods and experimental results. </title> <type> Technical Report RR-1894, </type> <institution> INRIA, </institution> <year> 1993. </year>
Reference-contexts: This second method for computing the fundamental matrix is more complicated, as it involves non-quadratic minimizations. However, it yields more precise results. We use the quadratic method to obtain a starting point. For a far more detailed analysis of different methods to compute the fundamental matrix, see <ref> [27] </ref>. 3 Computing the intrinsic parameters of the cameras Once a camera has performed at least three displacements it is possible to solve for all its intrinsic parameters, using the fundamental matrices.
Reference: [28] <author> Q.-T. Luong and O.D. Faugeras. </author> <title> Self-calibration of a camera using multiples images. </title> <booktitle> In Proc. International Conference on Pattern Recognition, </booktitle> <pages> pages 9-12, </pages> <address> Den Hag, The Netherlands, </address> <year> 1992. </year>
Reference-contexts: They allow us to discard spurious solutions. The main advantage of this approach is that no initial guess is needed at all, thus it can be used even with no a priori knowledge of the intrinsic parameters, which is important. The second approach is to use iterative methods <ref> [28] </ref>, which have some practical advantages: * it is easy to use long sequences, * uncertainty and a priori knowledge can be easily taken into account, * they are computationnaly efficient and ensure the existence of a real solution.
Reference: [29] <author> S.J. Maybank and O.D. Faugeras. </author> <title> A Theory of Self-Calibration of a Moving Camera. </title> <journal> The International Journal of Computer Vision, </journal> <volume> 8(2) </volume> <pages> 123-151, </pages> <year> 1992. </year> <note> 34 Quang-Tuan LUONG Olivier FAUGERAS </note>
Reference-contexts: Several equivalent formulations are possible. The most interesting formulation is to use the Kruppa equations [23], first introduced in the field of computer vision by Faugeras and Maybank for the study of motion [11] , and then to develop a theory of self-calibration <ref> [29] </ref>. The Kruppa equations are obtained from a geometric interpretation of the rigidity constraints: the tangents to the image ! of the absolute conic 1 in two views taken by the same camera correspond under the epipolar transformation.
Reference: [30] <author> G. Medioni and Y. Yasumuto. </author> <title> Corner detection and curve representation using cubic b-spline. </title> <booktitle> In Proc. International Conference on Robotics and Automation, </booktitle> <pages> pages 764-769, </pages> <year> 1986. </year>
Reference-contexts: The features that we found to be the most useful are corners, as some vertexes (triple junctions) result from occlusion. There are three main approaches to the problem of corner detection: * The first one is to extract features such as edges chains [1] <ref> [30] </ref> or polygonal approximations [35] , and then to search for corners using these data. Apart from the com-putationnal cost, these methods suffer from the possible difference of the intermediate features extracted in the various images.
Reference: [31] <author> A. Morgan. </author> <title> Solving polynomial systems using continuation for engineering and science problems. </title> <publisher> Prentice-Hall, </publisher> <year> 1987. </year>
Reference-contexts: Thus, having done three displacements, we can use semi-analytical methods to solve the resulting polynomial system of six equations in six homogeneous unk-nows. This is done by a numerical continuation method <ref> [31] </ref>: the idea is to intersect the six sets of 32 = 2 5 solutions obtained by solving five equations only. A set of algebraic constraints must be verified by the Kruppa coefficients to ensure the existence of a real solution.
Reference: [32] <author> J. L. Mundy and A. Zisserman, </author> <title> editors. Geometric invariance in computer vision. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: The basic assumption behind this model is that the relationship between the world coordinates and the pixel coordinates is linear projective. Thus no camera distortion is considered which allows us to use the powerful tools of projective geometry, which is emerging as an attractive framework for computer vision <ref> [32] </ref>. In this chapter, we assume that the reader is familiar with the elementary projective geometry described in [39] for example.
Reference: [33] <author> H.H. Nagel. </author> <title> Constraints for the estimation of displacement vector fields from image sequences. </title> <booktitle> In Proc. International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 156-160, </pages> <year> 1983. </year>
Reference-contexts: Apart from the com-putationnal cost, these methods suffer from the possible difference of the intermediate features extracted in the various images. Self-calibration of a stereo rig from unknown camera motions and point correspondences 5 * The second one <ref> [2, 8, 22, 48, 33, 40, 17] </ref> is to first apply a differential operator measuring gradients and curvatures of image intensity surface, and then to select points that are corners by a second operator that is often a thresholding scheme.
Reference: [34] <author> E. Pervin and J.A. Webb. </author> <booktitle> Quaternions in computer vision and robotics. In Proc. International Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 382-383, </pages> <year> 1983. </year>
Reference-contexts: On the opposite, finding directly stereo matches can be difficult if the baseline of the stereo rig is large, since at this stage the stereo rig is not yet calibrated. Recovering the rotation To solve equation (26), we use a quaternion representation of the rotations <ref> [34] </ref> q R = (s; v) q R 2 = (s 2 ; v 2 ) Writing equation (26) with this representation yields: q R fi q R 1 q R 2 fi q R = 0 (28) which gives the two equations: s (s 1 s 2 ) = v:(v
Reference: [35] <author> F.Veillon R.Horaud and T.Skordas. </author> <title> Finding geometric and relational structures in an image. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 374-384, </pages> <year> 1990. </year>
Reference-contexts: The features that we found to be the most useful are corners, as some vertexes (triple junctions) result from occlusion. There are three main approaches to the problem of corner detection: * The first one is to extract features such as edges chains [1] [30] or polygonal approximations <ref> [35] </ref> , and then to search for corners using these data. Apart from the com-putationnal cost, these methods suffer from the possible difference of the intermediate features extracted in the various images.
Reference: [36] <author> L. Robert. </author> <title> Reconstruction de courbes et de surfaces par vision stereoscopique. Applications a la robotique mobile. </title> <type> PhD thesis, </type> <institution> Ecole Polytechnique, </institution> <year> 1993. </year>
Reference-contexts: A variant of the method allows to compute the relative displacements between three cameras. 2 Computing the fundamental matrix Almost all the point-based algorithms which start from multiple, uncalibrated images [9] [18] <ref> [36] </ref> [41] require, as the basic information, the fundamental matrix, which is the only alternative to projection matrices, in order to relate two views of the same scene. It is also the case for the self-calibration algorithm. <p> Figure 11 shows the points of interest matched between image 1 and image 2. The standard calibration is performed on each image, using the algorithm of Robert <ref> [36] </ref>, which is a much improved version of the linear method of Fau-geras and Toscani [12]. <p> We use only three uncalibrated views taken by the same camera, shown figure 14. Edge detection is performed. Then the edge chains are approximated by B-splines, which are given as input to the trinocular stereovision algorithm of Luc Robert <ref> [37, 36] </ref>. The matching phase of this algorithm uses only the epipolar geometry obtained from the fundamental matrices F 12 , F 13 , and F 23 , which are computed from the point correspondences.
Reference: [37] <author> L. Robert and O.D. Faugeras. </author> <title> Curve-Based Stereo: Figural Continuity And Curvature. </title> <booktitle> In Proc. International Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 57-62, </pages> <address> Maui, Hawai, </address> <month> June </month> <year> 1991. </year> <note> IEEE. </note>
Reference-contexts: We use only three uncalibrated views taken by the same camera, shown figure 14. Edge detection is performed. Then the edge chains are approximated by B-splines, which are given as input to the trinocular stereovision algorithm of Luc Robert <ref> [37, 36] </ref>. The matching phase of this algorithm uses only the epipolar geometry obtained from the fundamental matrices F 12 , F 13 , and F 23 , which are computed from the point correspondences.
Reference: [38] <author> K. Rohr. </author> <title> Modelling and identification of characteristic intensity variations. </title> <journal> Image and Vision Computing, </journal> <volume> 10(2) </volume> <pages> 66-76, </pages> <year> 1992. </year>
Reference-contexts: It is a global and quite efficient approach, however it has been shown [7] that the most notorious algorithms of this family yield a precision in the positionning of only a few pixels. * The third one <ref> [16, 38, 5] </ref> is to use an explicit model of the local image structure in the neighborhood of the target corner, and to search the numerical parameters of such a model by a non-linear minimization.
Reference: [39] <author> J.G. Semple and G.T. Kneebone. </author> <title> Algebraic projective geometry. </title> <publisher> Oxford science publication, </publisher> <year> 1952. </year>
Reference-contexts: Thus no camera distortion is considered which allows us to use the powerful tools of projective geometry, which is emerging as an attractive framework for computer vision [32]. In this chapter, we assume that the reader is familiar with the elementary projective geometry described in <ref> [39] </ref> for example.
Reference: [40] <author> M.A. Shah and R. Jain. </author> <title> Detecting time-varying corners. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 28 </volume> <pages> 345-355, </pages> <year> 1984. </year>
Reference-contexts: Apart from the com-putationnal cost, these methods suffer from the possible difference of the intermediate features extracted in the various images. Self-calibration of a stereo rig from unknown camera motions and point correspondences 5 * The second one <ref> [2, 8, 22, 48, 33, 40, 17] </ref> is to first apply a differential operator measuring gradients and curvatures of image intensity surface, and then to select points that are corners by a second operator that is often a thresholding scheme.
Reference: [41] <author> A. Shashua. </author> <title> Projective structure from two uncalibrated images: structure from motion and recognition. </title> <journal> Technical Report A.I. </journal> <volume> Memo No. 1363, </volume> <publisher> MIT, </publisher> <month> Sept </month> <year> 1992. </year>
Reference-contexts: A variant of the method allows to compute the relative displacements between three cameras. 2 Computing the fundamental matrix Almost all the point-based algorithms which start from multiple, uncalibrated images [9] [18] [36] <ref> [41] </ref> require, as the basic information, the fundamental matrix, which is the only alternative to projection matrices, in order to relate two views of the same scene. It is also the case for the self-calibration algorithm.
Reference: [42] <author> Y.S. Shiu and S. Ahmad. </author> <title> Calibration of wrist-mounted robotic sensors by solving homogeneous transform equations of the form AX = XB. </title> <journal> IEEE Transactions on robotics and automation, </journal> <volume> 5(1) </volume> <pages> 16-29, </pages> <year> 1989. </year>
Reference-contexts: Equation (25) can be decomposed in the following two matrix equations: RR 1 = R 2 R (26) where 1 and 2 are unknown scale factors associated to D 1 and D 2 , respectively. The first equation has been much studied in the framework of hand-eye calibration [4] <ref> [42] </ref>, [46], [3]. Thus the reader is refered to those references for a more detailed analysis of unicity 22 Quang-Tuan LUONG Olivier FAUGERAS and sensitivity.
Reference: [43] <author> M.E. Spetsakis and J. Aloimonos. </author> <title> Optimal computing of structure from motion using point correspondances in two frames. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 449-453, </pages> <year> 1988. </year> <title> Self-calibration of a stereo rig from unknown camera motions and point correspondences 35 </title>
Reference-contexts: This computation can be done quite robustly even with imprecise camera parameters. 4.1 Two approaches based on the computation of the fundamen tal matrix The motion determination problem from point correspondences is is very classical. See [13] <ref> [43] </ref> [47] [20] for solutions similar to ours. We present two different solutions, both based on the computation of the fundamental matrix.
Reference: [44] <author> R.Y. Tsai. </author> <title> An Efficient and Accurate Camera Calibration Technique for 3D Machine Vision. </title> <booktitle> In Proceedings CVPR '86, </booktitle> <address> Miami Beach, Florida, </address> <pages> pages 364-374. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1986. </year>
Reference-contexts: coordinate system of the first camera In the case of a trinocular stereo rig, we have of course 5 more intrinsic parameters represented by A 3 and 6 more extrinsic parameters represented D 0 to determine. 1.2 What do we mean by self-calibration In the usual method of calibration [12] <ref> [44] </ref> a special object (calibration grid) is put in the field of view of the cameras. It is assumed that we have a 3D model of this object, that is we know the 3D coordinates of some of its reference points, in a coordinate system attached to the object.
Reference: [45] <author> R.Y. Tsai and T.S. Huang. </author> <title> Uniqueness and estimation of three-dimensional motion parameters of rigid objects wirth curved surfaces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 13-27, </pages> <year> 1984. </year>
Reference-contexts: direct factorization We have seen that during the course of intrinsic parameters estimation, we had to compute the fundamental matrix F, from which the essential matrix is immediately obtained: E = A T FA (17) The problem of finding the rotation R and the translation t from E is classical <ref> [25, 45, 13] </ref>. As we have, by construction, found a F-matrix of rank two, the direction of translation is just obtained by solving: E T t = 0. <p> It can be noted that this solution is entirely equivalent to the well-known method of Tsai and Huang <ref> [45] </ref> , which has been recently proved to be optimal by Hartley [19] . We denote this algorithm by FACTOR. 14 Quang-Tuan LUONG Olivier FAUGERAS An iterative solution An alternative method is to use directly the criterion that has been used to determine the fundamental matrix.
Reference: [46] <author> R.Y. Tsai and R.K. Lenz. </author> <title> Real time versatile robotics hamd/eye calibration using 3D machine vision. </title> <booktitle> In Proc. International Conference on Robotics and Automation, </booktitle> <pages> pages 554-561, </pages> <year> 1988. </year>
Reference-contexts: The first equation has been much studied in the framework of hand-eye calibration [4] [42], <ref> [46] </ref>, [3]. Thus the reader is refered to those references for a more detailed analysis of unicity 22 Quang-Tuan LUONG Olivier FAUGERAS and sensitivity. We just show below that if we do two displacements of the stereo rig, we can solve the two resulting matrix equations (26) to compute R.
Reference: [47] <author> J. Weng, N. Ahuja, and T.S. Huang. </author> <title> Optimal motion and structure estimation. </title> <booktitle> In Proc. International Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 144-152, </pages> <year> 1989. </year>
Reference-contexts: This computation can be done quite robustly even with imprecise camera parameters. 4.1 Two approaches based on the computation of the fundamen tal matrix The motion determination problem from point correspondences is is very classical. See [13] [43] <ref> [47] </ref> [20] for solutions similar to ours. We present two different solutions, both based on the computation of the fundamental matrix.

References-found: 47

