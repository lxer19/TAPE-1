URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3159/3159.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Email: E-mail: min@cs.umd.edu, nick@cs.umd.edu  
Title: The Implementation and Performance Evaluation of the ADMS Query Optimizer: Integrating  
Address: College Park  
Affiliation: Institute for Advanced Computer Studies and Department of Computer Science University of Maryland,  
Date: October 1993  
Pubnum: UMIACS-TR-93-106  CS-TR-3159  
Abstract: Query Result Caching and Matching fl Abstract In this paper, we describe the design and the evaluation of the ADMS optimizer. Cap- italizing on a structure called Logical Access Path Schema to model the derivation relationship among cached query results, the optimizer is able to perform query matching coincidently with the optimization and generate more efficient query plans using cached results. The optimizer also features data caching and pointer caching, different cache replacement strategies, and different cache update strategies. An extensive set of experiments were conducted and the results showed that pointer caching and dynamic cache update strategies substantially speedup query computations and, thus, increase query throughput under situations with fair query correlation and update load. The requirement of the cache space is relatively small and the extra computation overhead introduced by the caching and matching mechanism is more than offset by the time saved in query processing.
Abstract-found: 1
Intro-found: 1
Reference: [AL80] <author> M.E. Adiba and B. G. Lindsay. </author> <title> Database snapshots. </title> <booktitle> In Procs. of 6th VLDB, </booktitle> <year> 1980. </year>
Reference-contexts: The benefit of this technique is obtained from saving (part of) the subsequent query computations by utilizing the previous cached (intermediate) results. Applications of this technique can be found in <ref> [Fin82, LY85, DR92, Sel87, Rou91, Jhi88, HS93, AL80] </ref>. In [Fin82, LY85, Rou91], cached query results were used in relational database systems to avoid repeated computations. [Sel87, Jhi88] addressed the problem fl This research was sponsored partially by NSF under grant IRI-9057573 and GDR-85-00108 and by NASA/USRA under contract FCPO-550-81. <p> Recently, this technique was also suggested to support query computations in extensible or object-oriented database systems where expensive computations are more likely to happen [HS93]. Different issues concerning the caching technique have also been studied. <ref> [AL80, Rou82b, Val87, Rou91] </ref> proposed alternative methods for storing the cached data, [Sel88, Jhi88] discussed the problem of selective caching and cache replacement, and in [RK86, Han87, BLT86], different strategies for updating cached data are explored. <p> Cached temporaries are collected and maintained by the cache manager. Several key issues regarding cache management and the corresponding alternative approaches are discussed in the following: How to store the cached temporaries ? Temporaries can be stored as actual data in relations <ref> [AL80, BLT86] </ref>, which are called materialized views. Another approach is to store for each resulting tuple of the temporary, a number of Tuple Identifiers (TID), instead of materialized values, which point to the corresponding tuples in the base relations, possibly through several levels, that constitute the resulting tuple.
Reference: [BDT83] <author> D. Bitton, D.J. DeWitt, and C. Turbyfill. </author> <title> Benchmarking database systems, a sys-tematic approach. </title> <booktitle> In Procs. of 9th VLDB, </booktitle> <year> 1983. </year>
Reference-contexts: Different databases and query loads were used throughout the experiments so that the impact from the CMO parameters as well as from the system's environment can be observed. Databases Synthetic relations are generated according to the characteristics of the Wisconsin Benchmark <ref> [BDT83] </ref>. Table 1 outlines the cardinalities and sizes of each relation used in the experiments. The set of shorter version is obtained from the regular one by eliminating the last two string attributes, which are 104 bytes in length.
Reference: [BLT86] <author> J.A. Blakeley, P. Larson, and F.W. Tompa. </author> <title> Efficiently updating materialized views. </title> <booktitle> In Procs. of ACM-SIGMOD, </booktitle> <year> 1986. </year> <month> 19 </month>
Reference-contexts: Different issues concerning the caching technique have also been studied. [AL80, Rou82b, Val87, Rou91] proposed alternative methods for storing the cached data, [Sel88, Jhi88] discussed the problem of selective caching and cache replacement, and in <ref> [RK86, Han87, BLT86] </ref>, different strategies for updating cached data are explored. Aside from the above work which focused on the problem of cache maintenance and management, the problem of how to identify the useful cached data for computing queries, referred as query matching problem, was addressed in [Fin82, LY85]. <p> Cached temporaries are collected and maintained by the cache manager. Several key issues regarding cache management and the corresponding alternative approaches are discussed in the following: How to store the cached temporaries ? Temporaries can be stored as actual data in relations <ref> [AL80, BLT86] </ref>, which are called materialized views. Another approach is to store for each resulting tuple of the temporary, a number of Tuple Identifiers (TID), instead of materialized values, which point to the corresponding tuples in the base relations, possibly through several levels, that constitute the resulting tuple. <p> As for the cache update method, aside from updating via re-execution, the technique of incremental update (or differential computation) <ref> [LHM86, BLT86, Rou91] </ref> can efficiently update a temporary if only a little part of it is changed. For the second update method, logs must be maintained to support differential computations.
Reference: [CL73] <author> C. L. Chang and C. T. Lee. </author> <title> Symbolic Logic and Mechanical Theorem Proving. </title> <publisher> Academic Press, </publisher> <year> 1973. </year>
Reference-contexts: We say e is a k-connector if it connects k nodes, i.e. jN (e)j = k. An edge is a join edge if k 2, it is a selection edge if k = 1. Since any formula can be transformed into a conjunction of sub-formulas <ref> [CL73] </ref>, the initial query can always be represented by a query graph 2 . A state is reduced by assigning an access path to the sub-query induced by one of its join edges. <p> A clause is a disjunction of atoms, denoted as C = A 1 _ A 2 _ : : : A n . From elementary logic <ref> [CL73] </ref>, we can transform each formula into a conjunctive form as f = C 1 ^ C 2 ^ : : : C m . The following lemma gives sufficient conditions and a constructive way for the satisfiability check.
Reference: [DR92] <author> A. Delis and N. Roussopoulos. </author> <title> Evaluation of an enhanced workstation-server DBMS architecture. </title> <booktitle> In Procs. of 18th VLDB, </booktitle> <year> 1992. </year>
Reference-contexts: The benefit of this technique is obtained from saving (part of) the subsequent query computations by utilizing the previous cached (intermediate) results. Applications of this technique can be found in <ref> [Fin82, LY85, DR92, Sel87, Rou91, Jhi88, HS93, AL80] </ref>. In [Fin82, LY85, Rou91], cached query results were used in relational database systems to avoid repeated computations. [Sel87, Jhi88] addressed the problem fl This research was sponsored partially by NSF under grant IRI-9057573 and GDR-85-00108 and by NASA/USRA under contract FCPO-550-81. <p> In a client-- server environment, caching query results on local workstation can not only parallelize query processing among clients, but also reduce the bus contention and the server request bottleneck <ref> [DR92] </ref>. Recently, this technique was also suggested to support query computations in extensible or object-oriented database systems where expensive computations are more likely to happen [HS93].
Reference: [Fin82] <author> S. Finkelstein. </author> <title> Common expression analysis in database applications. </title> <booktitle> In Procs. of ACM-SIGMOD, </booktitle> <pages> pages 235-245, </pages> <year> 1982. </year>
Reference-contexts: The benefit of this technique is obtained from saving (part of) the subsequent query computations by utilizing the previous cached (intermediate) results. Applications of this technique can be found in <ref> [Fin82, LY85, DR92, Sel87, Rou91, Jhi88, HS93, AL80] </ref>. In [Fin82, LY85, Rou91], cached query results were used in relational database systems to avoid repeated computations. [Sel87, Jhi88] addressed the problem fl This research was sponsored partially by NSF under grant IRI-9057573 and GDR-85-00108 and by NASA/USRA under contract FCPO-550-81. <p> The benefit of this technique is obtained from saving (part of) the subsequent query computations by utilizing the previous cached (intermediate) results. Applications of this technique can be found in [Fin82, LY85, DR92, Sel87, Rou91, Jhi88, HS93, AL80]. In <ref> [Fin82, LY85, Rou91] </ref>, cached query results were used in relational database systems to avoid repeated computations. [Sel87, Jhi88] addressed the problem fl This research was sponsored partially by NSF under grant IRI-9057573 and GDR-85-00108 and by NASA/USRA under contract FCPO-550-81. <p> Aside from the above work which focused on the problem of cache maintenance and management, the problem of how to identify the useful cached data for computing queries, referred as query matching problem, was addressed in <ref> [Fin82, LY85] </ref>. In their work, however, query optimization was not considered inclusively. This is not satisfactory because blindly using cached data in query computations without optimization may result in a query plan even worse than the one optimized from the original query without utilizing any cached results. <p> Matching The problem of detecting if a cached temporary is useful for the computation of a query has been investigated in <ref> [Fin82, LY85] </ref>. The solution usually involves a theorem proving algorithm whose computation complexity, in general, is exponential. However, restrictive algorithms were 4 proposed in [Fin82, LY85] for formulas that contain only attributes, constants, comparison operators (&lt;; &gt;; =), and logical connectives (and, or, not). <p> Matching The problem of detecting if a cached temporary is useful for the computation of a query has been investigated in <ref> [Fin82, LY85] </ref>. The solution usually involves a theorem proving algorithm whose computation complexity, in general, is exponential. However, restrictive algorithms were 4 proposed in [Fin82, LY85] for formulas that contain only attributes, constants, comparison operators (&lt;; &gt;; =), and logical connectives (and, or, not). We have extended the method from [Fin82] for more general use in the CMO optimizer. <p> The solution usually involves a theorem proving algorithm whose computation complexity, in general, is exponential. However, restrictive algorithms were 4 proposed in [Fin82, LY85] for formulas that contain only attributes, constants, comparison operators (&lt;; &gt;; =), and logical connectives (and, or, not). We have extended the method from <ref> [Fin82] </ref> for more general use in the CMO optimizer. Besides, rather than using only one matched cache in a query, the CMO optimizer is capable of using multiple matched temporaries to answer the query more efficiently. More detail is described in the next section. <p> More detail is described in the next section. Optimization Optimization is required not only because there may be different combinations of matched caches from which the query can be computed, but also because it is not always beneficial to use caches. A possible solution, as mentioned in <ref> [Fin82] </ref>, is a two phase approach; during the first phase, the query is transformed into a number of equivalent queries using different cached temporaries, and during the second phase, all the revised queries are fed to a regular optimizer to generate an optimal plan. <p> However, restrictive algorithms have been proposed for formulas involving only attribute variables, constants, comparison operators and logical connectives <ref> [Fin82, LY85] </ref>. We have extended the method from [Fin82] to a more general one used in our implementation, detail is given in the Appendix. Condition 3 (Attribute Coverability) a v (a q [ ff (f r )), where ff (f r ) are attributes appearing in f r . <p> However, restrictive algorithms have been proposed for formulas involving only attribute variables, constants, comparison operators and logical connectives [Fin82, LY85]. We have extended the method from <ref> [Fin82] </ref> to a more general one used in our implementation, detail is given in the Appendix. Condition 3 (Attribute Coverability) a v (a q [ ff (f r )), where ff (f r ) are attributes appearing in f r . <p> The same problem has been addressed in [LY85], who transformed it into a directed graph problem. However, it was not clear how the restricting formula can be constructed and how efficient the algorithm is. Therefore, we used a more efficient but restrictive algorithm extended from <ref> [Fin82] </ref>. An atom is a predicate of the form x y, where x is an attribute, y is either an attribute or a constant, and is a comparison operator.
Reference: [Han87] <author> E.N. Hanson. </author> <title> A performance analysis of view materialization strategies. </title> <booktitle> In Procs. of ACM-SIGMOD, </booktitle> <pages> pages 440-453, </pages> <year> 1987. </year>
Reference-contexts: Different issues concerning the caching technique have also been studied. [AL80, Rou82b, Val87, Rou91] proposed alternative methods for storing the cached data, [Sel88, Jhi88] discussed the problem of selective caching and cache replacement, and in <ref> [RK86, Han87, BLT86] </ref>, different strategies for updating cached data are explored. Aside from the above work which focused on the problem of cache maintenance and management, the problem of how to identify the useful cached data for computing queries, referred as query matching problem, was addressed in [Fin82, LY85]. <p> For the second update method, logs must be maintained to support differential computations. It was analyzed in <ref> [Han87] </ref> that none of the combinations of update strategy and update method is superior to all the others under all situations.
Reference: [HS93] <author> J.M. Hellerstein and M. Stonebraker. </author> <title> Predicate migration: Optimizing queries with expensive predicates. </title> <booktitle> In Procs. of ACM-SIGMOD, </booktitle> <year> 1993. </year>
Reference-contexts: The benefit of this technique is obtained from saving (part of) the subsequent query computations by utilizing the previous cached (intermediate) results. Applications of this technique can be found in <ref> [Fin82, LY85, DR92, Sel87, Rou91, Jhi88, HS93, AL80] </ref>. In [Fin82, LY85, Rou91], cached query results were used in relational database systems to avoid repeated computations. [Sel87, Jhi88] addressed the problem fl This research was sponsored partially by NSF under grant IRI-9057573 and GDR-85-00108 and by NASA/USRA under contract FCPO-550-81. <p> Recently, this technique was also suggested to support query computations in extensible or object-oriented database systems where expensive computations are more likely to happen <ref> [HS93] </ref>. Different issues concerning the caching technique have also been studied. [AL80, Rou82b, Val87, Rou91] proposed alternative methods for storing the cached data, [Sel88, Jhi88] discussed the problem of selective caching and cache replacement, and in [RK86, Han87, BLT86], different strategies for updating cached data are explored.
Reference: [J + 93] <author> C. S. Jensen et al. </author> <title> Using differential techniques to efficiently support transaction time. </title> <journal> VLDB Journal, </journal> <volume> 2(1) </volume> <pages> 75-111, </pages> <year> 1993. </year>
Reference-contexts: Therefore, it is necessary to consider optimization at the same time of query matching. The first time where query matching and optimization are integrated was in <ref> [J + 93] </ref>. However, since their work emphasized on supporting transaction time using differential techniques, the matching and optimization problem was not addressed sufficiently, and no performance evaluation was reported. <p> A better approach is to integrate the matching steps with the optimization and thus, unify the search spaces and avoid duplicate effort. <ref> [J + 93] </ref> first described this approach and used a state transition network to model the space, along with some pruning heuristics. The CMO optimizer we implemented here is also one phase. <p> A graph search based algorithm [Nil80] (referred as state transition network in <ref> [J + 93, LW86] </ref>) is used to find the optimal plan. The input to the optimizer is an initial query graph (or state) which represents the uncomputed query, and a LAPS which models the cached temporaries.
Reference: [Jhi88] <author> A. Jhingran. </author> <title> A performance study of query optimization algorithms on a database system supporting procedures. </title> <booktitle> In Procs. of 14th VLDB, </booktitle> <year> 1988. </year>
Reference-contexts: The benefit of this technique is obtained from saving (part of) the subsequent query computations by utilizing the previous cached (intermediate) results. Applications of this technique can be found in <ref> [Fin82, LY85, DR92, Sel87, Rou91, Jhi88, HS93, AL80] </ref>. In [Fin82, LY85, Rou91], cached query results were used in relational database systems to avoid repeated computations. [Sel87, Jhi88] addressed the problem fl This research was sponsored partially by NSF under grant IRI-9057573 and GDR-85-00108 and by NASA/USRA under contract FCPO-550-81. <p> Applications of this technique can be found in [Fin82, LY85, DR92, Sel87, Rou91, Jhi88, HS93, AL80]. In [Fin82, LY85, Rou91], cached query results were used in relational database systems to avoid repeated computations. <ref> [Sel87, Jhi88] </ref> addressed the problem fl This research was sponsored partially by NSF under grant IRI-9057573 and GDR-85-00108 and by NASA/USRA under contract FCPO-550-81. <p> Recently, this technique was also suggested to support query computations in extensible or object-oriented database systems where expensive computations are more likely to happen [HS93]. Different issues concerning the caching technique have also been studied. [AL80, Rou82b, Val87, Rou91] proposed alternative methods for storing the cached data, <ref> [Sel88, Jhi88] </ref> discussed the problem of selective caching and cache replacement, and in [RK86, Han87, BLT86], different strategies for updating cached data are explored.
Reference: [LHM86] <author> B. Lindsay, L. Haas, and C. Mohan. </author> <title> A snapshot differential refresh algorithm. </title> <booktitle> In Procs. of ACM-SIGMOD, </booktitle> <pages> pages 53-60, </pages> <year> 1986. </year>
Reference-contexts: As for the cache update method, aside from updating via re-execution, the technique of incremental update (or differential computation) <ref> [LHM86, BLT86, Rou91] </ref> can efficiently update a temporary if only a little part of it is changed. For the second update method, logs must be maintained to support differential computations.
Reference: [LW86] <author> S. Lafortune and E. Wong. </author> <title> A state transition model for distributed query processing. </title> <journal> ACM TODS, </journal> <volume> 11(3) </volume> <pages> 294-322, </pages> <year> 1986. </year>
Reference-contexts: A graph search based algorithm [Nil80] (referred as state transition network in <ref> [J + 93, LW86] </ref>) is used to find the optimal plan. The input to the optimizer is an initial query graph (or state) which represents the uncomputed query, and a LAPS which models the cached temporaries.
Reference: [LY85] <author> P. A. Larson and H. Z. Yang. </author> <title> Computing queries from derived relations. </title> <booktitle> In Procs. of 11th VLDB, </booktitle> <pages> pages 259-269, </pages> <year> 1985. </year>
Reference-contexts: The benefit of this technique is obtained from saving (part of) the subsequent query computations by utilizing the previous cached (intermediate) results. Applications of this technique can be found in <ref> [Fin82, LY85, DR92, Sel87, Rou91, Jhi88, HS93, AL80] </ref>. In [Fin82, LY85, Rou91], cached query results were used in relational database systems to avoid repeated computations. [Sel87, Jhi88] addressed the problem fl This research was sponsored partially by NSF under grant IRI-9057573 and GDR-85-00108 and by NASA/USRA under contract FCPO-550-81. <p> The benefit of this technique is obtained from saving (part of) the subsequent query computations by utilizing the previous cached (intermediate) results. Applications of this technique can be found in [Fin82, LY85, DR92, Sel87, Rou91, Jhi88, HS93, AL80]. In <ref> [Fin82, LY85, Rou91] </ref>, cached query results were used in relational database systems to avoid repeated computations. [Sel87, Jhi88] addressed the problem fl This research was sponsored partially by NSF under grant IRI-9057573 and GDR-85-00108 and by NASA/USRA under contract FCPO-550-81. <p> Aside from the above work which focused on the problem of cache maintenance and management, the problem of how to identify the useful cached data for computing queries, referred as query matching problem, was addressed in <ref> [Fin82, LY85] </ref>. In their work, however, query optimization was not considered inclusively. This is not satisfactory because blindly using cached data in query computations without optimization may result in a query plan even worse than the one optimized from the original query without utilizing any cached results. <p> Matching The problem of detecting if a cached temporary is useful for the computation of a query has been investigated in <ref> [Fin82, LY85] </ref>. The solution usually involves a theorem proving algorithm whose computation complexity, in general, is exponential. However, restrictive algorithms were 4 proposed in [Fin82, LY85] for formulas that contain only attributes, constants, comparison operators (&lt;; &gt;; =), and logical connectives (and, or, not). <p> Matching The problem of detecting if a cached temporary is useful for the computation of a query has been investigated in <ref> [Fin82, LY85] </ref>. The solution usually involves a theorem proving algorithm whose computation complexity, in general, is exponential. However, restrictive algorithms were 4 proposed in [Fin82, LY85] for formulas that contain only attributes, constants, comparison operators (&lt;; &gt;; =), and logical connectives (and, or, not). We have extended the method from [Fin82] for more general use in the CMO optimizer. <p> However, restrictive algorithms have been proposed for formulas involving only attribute variables, constants, comparison operators and logical connectives <ref> [Fin82, LY85] </ref>. We have extended the method from [Fin82] to a more general one used in our implementation, detail is given in the Appendix. Condition 3 (Attribute Coverability) a v (a q [ ff (f r )), where ff (f r ) are attributes appearing in f r . <p> We will consider query qualifications constructed from attributes, constants, comparison operators (&gt;; =; &lt;), and logical connectives (^, _). The same problem has been addressed in <ref> [LY85] </ref>, who transformed it into a directed graph problem. However, it was not clear how the restricting formula can be constructed and how efficient the algorithm is. Therefore, we used a more efficient but restrictive algorithm extended from [Fin82].
Reference: [Nil80] <author> N.J. Nilsson. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga Pub. Co., </publisher> <year> 1980. </year>
Reference-contexts: A graph search based algorithm <ref> [Nil80] </ref> (referred as state transition network in [J + 93, LW86]) is used to find the optimal plan. The input to the optimizer is an initial query graph (or state) which represents the uncomputed query, and a LAPS which models the cached temporaries.
Reference: [RES93] <author> N. Roussopoulos, N. Economou, and A. Stamenas. ADMS: </author> <title> A testbed for incremental access methods. </title> <journal> To appear in IEEE Trans. on Knowledge and Data Engineering, </journal> <year> 1993. </year>
Reference-contexts: Incoming queries are optimized through the matching optimizer, 1 ADMS, the Advanced Database Management System, is a DBMS developed at the Department of Computer Science, University of Maryland, College Park <ref> [RES93] </ref>. 2 which capitalizes on the LAPS in finding pertinent cached results, in order to generate more efficient plan.
Reference: [RH80] <author> D.J. Rosenkrantz and H.B. Hunt. </author> <title> Processing conjunctive predicates and queries. </title> <booktitle> In Procs. of 6th VLDB, </booktitle> <year> 1980. </year>
Reference-contexts: The problem of testing 8x 1 ; x 2 ; : : : ; x n (f q ! f v ), known as the satisfiability problem, is in general NP-hard <ref> [RH80] </ref>. However, restrictive algorithms have been proposed for formulas involving only attribute variables, constants, comparison operators and logical connectives [Fin82, LY85]. We have extended the method from [Fin82] to a more general one used in our implementation, detail is given in the Appendix.
Reference: [RK86] <author> N. Roussopoulos and H. Kang. </author> <booktitle> Principles and techniques in the design of ADMS+. Computer, </booktitle> 19(12) 19-25, 1986. 
Reference-contexts: Different issues concerning the caching technique have also been studied. [AL80, Rou82b, Val87, Rou91] proposed alternative methods for storing the cached data, [Sel88, Jhi88] discussed the problem of selective caching and cache replacement, and in <ref> [RK86, Han87, BLT86] </ref>, different strategies for updating cached data are explored. Aside from the above work which focused on the problem of cache maintenance and management, the problem of how to identify the useful cached data for computing queries, referred as query matching problem, was addressed in [Fin82, LY85].
Reference: [Rou82a] <author> N. Roussopoulos. </author> <title> The logical access path schema of a database. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> SE-8(6):563-573, </volume> <year> 1982. </year>
Reference-contexts: In this paper, we describe the design of the Cache&Match Optimizer (CMO) on the ADMS 1 database management system, and present a comprehensive performance evaluation. We model the cached query results with a structure called Logical Access Path Schema (LAPS) <ref> [Rou82a] </ref>, and based on this, the CMO is able to perform the matching coincidently with the optimization, and generate an optimal plan using cached results. <p> The performance of the CMO mechanism under different levels of relation update loads is evaluated in detail in the experiments. How to keep track of the cached temporaries ? To facilitate the searching and matching against the cache pool, the LAPS <ref> [Rou82a] </ref> is used to keep track of all the cached temporaries efficiently. Instead of recording each cached temporary independently, the LAPS integrates the cached temporaries along with their logical access paths which captures the logical and derivation relationships among them. <p> Instead of recording each cached temporary independently, the LAPS integrates the cached temporaries along with their logical access paths which captures the logical and derivation relationships among them. The integration of new cached temporaries and logical access paths into the LAPS is fairly direct and has been developed in <ref> [Rou82a] </ref>. <p> Initially, the LAPS contains base relations only. When subsequent queries are processed, it is augmented by integrating the cached temporaries along with their logical access paths. The integration steps are straight forward and were described in <ref> [Rou82a] </ref>. 3.2 Query Matching Given a query, the optimizer must be able to identify the cached temporaries that can be used to compute the query. A temporary is useful if it can be used alone to compute the results of a sub-query of the given query.
Reference: [Rou82b] <author> N. Roussopoulos. </author> <title> View indexing in relational databases. </title> <journal> ACM TODS, </journal> <volume> 7(2) </volume> <pages> 258-290, </pages> <year> 1982. </year>
Reference-contexts: Recently, this technique was also suggested to support query computations in extensible or object-oriented database systems where expensive computations are more likely to happen [HS93]. Different issues concerning the caching technique have also been studied. <ref> [AL80, Rou82b, Val87, Rou91] </ref> proposed alternative methods for storing the cached data, [Sel88, Jhi88] discussed the problem of selective caching and cache replacement, and in [RK86, Han87, BLT86], different strategies for updating cached data are explored. <p> This is a pointer based approach for caching, variations of this approach have been proposed in <ref> [Rou82b, Val87] </ref> and called ViewCache in [Rou91]. While limited disk space prohibits unlimited data caching, pointer caching is more space- effective since each tuple is represented by a small number of fixed length pointers.
Reference: [Rou91] <author> N. Roussopoulos. </author> <title> An incremental access method for ViewCache: Concept, algo-rithms, and cost analysis. </title> <journal> ACM TODS, </journal> <volume> 16(3) </volume> <pages> 535-563, </pages> <year> 1991. </year>
Reference-contexts: The benefit of this technique is obtained from saving (part of) the subsequent query computations by utilizing the previous cached (intermediate) results. Applications of this technique can be found in <ref> [Fin82, LY85, DR92, Sel87, Rou91, Jhi88, HS93, AL80] </ref>. In [Fin82, LY85, Rou91], cached query results were used in relational database systems to avoid repeated computations. [Sel87, Jhi88] addressed the problem fl This research was sponsored partially by NSF under grant IRI-9057573 and GDR-85-00108 and by NASA/USRA under contract FCPO-550-81. <p> The benefit of this technique is obtained from saving (part of) the subsequent query computations by utilizing the previous cached (intermediate) results. Applications of this technique can be found in [Fin82, LY85, DR92, Sel87, Rou91, Jhi88, HS93, AL80]. In <ref> [Fin82, LY85, Rou91] </ref>, cached query results were used in relational database systems to avoid repeated computations. [Sel87, Jhi88] addressed the problem fl This research was sponsored partially by NSF under grant IRI-9057573 and GDR-85-00108 and by NASA/USRA under contract FCPO-550-81. <p> Recently, this technique was also suggested to support query computations in extensible or object-oriented database systems where expensive computations are more likely to happen [HS93]. Different issues concerning the caching technique have also been studied. <ref> [AL80, Rou82b, Val87, Rou91] </ref> proposed alternative methods for storing the cached data, [Sel88, Jhi88] discussed the problem of selective caching and cache replacement, and in [RK86, Han87, BLT86], different strategies for updating cached data are explored. <p> This is a pointer based approach for caching, variations of this approach have been proposed in [Rou82b, Val87] and called ViewCache in <ref> [Rou91] </ref>. While limited disk space prohibits unlimited data caching, pointer caching is more space- effective since each tuple is represented by a small number of fixed length pointers. <p> As for the cache update method, aside from updating via re-execution, the technique of incremental update (or differential computation) <ref> [LHM86, BLT86, Rou91] </ref> can efficiently update a temporary if only a little part of it is changed. For the second update method, logs must be maintained to support differential computations.
Reference: [S + 79] <author> P. G. Selinger et al. </author> <title> Access path selection in a relational database management system. </title> <booktitle> In Procs. of ACM-SIGMOD, </booktitle> <pages> pages 23-34, </pages> <year> 1979. </year> <month> 20 </month>
Reference-contexts: In the following, we discuss the concerned design issues for both modules, review the related work, and describe the approaches we adopted in the implementation. 2.1 Cache Management Conventional relational database query languages always allow users to save the final query results in relations <ref> [S + 79, SWK76] </ref>. Under certain conditions, for example, when sorting is performed or nested queries are present, query intermediate results must also be produced to facilitate the query computations.
Reference: [Sel87] <author> T. Sellis. </author> <title> Efficiently supporting procedures in relational database systems. </title> <booktitle> In Procs. of ACM-SIGMOD, </booktitle> <year> 1987. </year>
Reference-contexts: The benefit of this technique is obtained from saving (part of) the subsequent query computations by utilizing the previous cached (intermediate) results. Applications of this technique can be found in <ref> [Fin82, LY85, DR92, Sel87, Rou91, Jhi88, HS93, AL80] </ref>. In [Fin82, LY85, Rou91], cached query results were used in relational database systems to avoid repeated computations. [Sel87, Jhi88] addressed the problem fl This research was sponsored partially by NSF under grant IRI-9057573 and GDR-85-00108 and by NASA/USRA under contract FCPO-550-81. <p> Applications of this technique can be found in [Fin82, LY85, DR92, Sel87, Rou91, Jhi88, HS93, AL80]. In [Fin82, LY85, Rou91], cached query results were used in relational database systems to avoid repeated computations. <ref> [Sel87, Jhi88] </ref> addressed the problem fl This research was sponsored partially by NSF under grant IRI-9057573 and GDR-85-00108 and by NASA/USRA under contract FCPO-550-81.
Reference: [Sel88] <author> T. K. Sellis. </author> <title> Intelligent caching and indexing techniques for relational database systems. </title> <journal> Inform. Systems, </journal> <volume> 13(2), </volume> <year> 1988. </year>
Reference-contexts: Recently, this technique was also suggested to support query computations in extensible or object-oriented database systems where expensive computations are more likely to happen [HS93]. Different issues concerning the caching technique have also been studied. [AL80, Rou82b, Val87, Rou91] proposed alternative methods for storing the cached data, <ref> [Sel88, Jhi88] </ref> discussed the problem of selective caching and cache replacement, and in [RK86, Han87, BLT86], different strategies for updating cached data are explored. <p> In this situation, a cache replacement strategy must be employed to decide which temporaries to replace when the cache space is full. The problem of choosing a good replacement strategy so that the most profitable results can always be cached was addressed in <ref> [Sel88] </ref>. We incorporated the suggested 3 heuristic cache replacement strategies in the cache manager and experimented with them under a bounded cache space environment.
Reference: [SWK76] <author> M. Stonebraker, E. Wong, and P. Kreps. </author> <title> The design and implementation of INGRES. </title> <journal> ACM TODS, </journal> <volume> 1(3) </volume> <pages> 189-222, </pages> <year> 1976. </year>
Reference-contexts: In the following, we discuss the concerned design issues for both modules, review the related work, and describe the approaches we adopted in the implementation. 2.1 Cache Management Conventional relational database query languages always allow users to save the final query results in relations <ref> [S + 79, SWK76] </ref>. Under certain conditions, for example, when sorting is performed or nested queries are present, query intermediate results must also be produced to facilitate the query computations.
Reference: [Val87] <author> P. Valduriez. </author> <title> Join indices. </title> <journal> ACM TODS, </journal> <volume> 12(2) </volume> <pages> 218-246, </pages> <year> 1987. </year> <month> 21 </month>
Reference-contexts: Recently, this technique was also suggested to support query computations in extensible or object-oriented database systems where expensive computations are more likely to happen [HS93]. Different issues concerning the caching technique have also been studied. <ref> [AL80, Rou82b, Val87, Rou91] </ref> proposed alternative methods for storing the cached data, [Sel88, Jhi88] discussed the problem of selective caching and cache replacement, and in [RK86, Han87, BLT86], different strategies for updating cached data are explored. <p> This is a pointer based approach for caching, variations of this approach have been proposed in <ref> [Rou82b, Val87] </ref> and called ViewCache in [Rou91]. While limited disk space prohibits unlimited data caching, pointer caching is more space- effective since each tuple is represented by a small number of fixed length pointers.
References-found: 25

