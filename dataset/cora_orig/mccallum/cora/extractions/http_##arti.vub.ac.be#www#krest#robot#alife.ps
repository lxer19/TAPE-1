URL: http://arti.vub.ac.be/www/krest/robot/alife.ps
Refering-URL: http://www.cs.brandeis.edu/~zippy/alife-library.html
Root-URL: 
Email: E-mail: steels@arti.vub.ac.be  
Title: The artificial life roots of artificial intelligence  
Author: Luc Steels 
Date: November 4, 1993  
Address: Pleinlaan 2, B-1050 Brussels, Belgium  
Affiliation: Artificial Intelligence Laboratory Vrije Universiteit Brussel  
Abstract: Behavior-oriented AI is a scientific discipline that studies how behavior of agents emerges and becomes intelligent and adaptive. Success of the field is defined in terms of success in building physical agents that are capable of maximising their own self-preservation in interaction with a dynamically changing environment. The paper addresses this artificial life route towards artificial intelligence and reviews some of the results obtained so far. 
Abstract-found: 1
Intro-found: 1
Reference: <institution> References </institution>
Reference: [1] <author> Abraham, R.H. and C. D. </author> <title> Shaw (1992) Dynamics. The Geometry of Behavior. 2nd Edition. </title> <publisher> Addison-Wesley Pub. </publisher> <address> Cy., Reading, Ma. </address>
Reference-contexts: Several researchers have proposed a state-space approach for defining the dynamics of the observed behavior and the internal operation of the agent (e.g., [77], [54], [37], [119]). Once a state-space description is available, the concepts of dynamical systems theory (attractors, transients, recurrent trajectories, etc.) <ref> [1] </ref> can be used to characterise qualitatively and quantitatively behaviors and internal structures like perceptions, representations, and actions. Within this framework concepts like emergent functionality can be formalised and the results of emergent functionality better understood.
Reference: [2] <author> Agre, P. and D. </author> <title> Chapman (1987) Pengi: an implementation of a theory of activity. </title> <booktitle> Proceedings of the Sixth National Conference on Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann. </publisher> <address> San Mateo, Ca. p. </address> <pages> 268-272. </pages>
Reference-contexts: Circuit approaches A third approach stays closer to electrical engineering by assuming that behavior programs, in order to be as efficient as possible, should take the form of combinatorial circuits <ref> [2] </ref>, [100]. This approach potentially leads to direct hardware implementation using VLSI. A combinatorial circuit consists of a set of components which perform a transformation from inputs to outputs. The outputs of one component may be inputs to one or more other components, thus forming a network.
Reference: [3] <author> Alexander, </author> <title> R.M. (1968) Animal Mechanics. Sidgewick and Jackson, </title> <publisher> London. </publisher>
Reference-contexts: Many more biological examples how physics may `solve' problems, so that additional processing can be minimised, can be found in <ref> [3] </ref> and [127]. Guideline 3: Do not think of sensing and acting in terms of symbol processing. The classical AI approach has been criticised because the symbols and symbol structures on which planning and decision making are based are not grounded in the real world [43].
Reference: [4] <institution> Alife (1994) Journal of Artificial Life. MIT Press, </institution> <address> Cambridge Ma. </address>
Reference-contexts: Good sources for tracking the field are the conferences on the Simulation of Adaptive Behavior ([80], [79]) and the associated journal [102], the conferences on Artificial Life ([59], [60], [124], [30]), and the associated journal <ref> [4] </ref>. There are also occasional contributions to international conferences on AI (such as IJCAI, AAAI, or ECAI), neural networks (NIPS), or robotics (IEEE). Reports of some milestone workshops have been published ([65], [123], [112], [113]). Section 2 of the paper delineates the artificial life approach to artificial intelligence.
Reference: [5] <author> Arbib, M.A. and A.R. Hanson (eds.) </author> <title> (1987) Vision, Brain, and Cooperative Computation. </title> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. </address> <month> 67 </month>
Reference-contexts: This is the reason why it is so difficult to bridge the gap between neurology and psychology. There is a growing consensus in behavior-oriented AI research that behavior systems be considered as the basic units [19]. Other terms for the basic behavioral unit are task-achieving module [68], or schema <ref> [5] </ref>. 13 To define the notion of a behavior system we have to make a distinction between a functionality, a behavior, a mechanism, and a component: * Functionalities: A functionality is something that the agent needs to achieve, for example locomotion, recharging, avoiding obstacles, finding the charging station, performing a measurement,
Reference: [6] <author> Arbib, M. A. and D.H. </author> <title> House (1987) Depth and Detours: An essay on visually guided behavior. In: Arbib, M.A. </title> <editor> and A.R. Hanson (eds.) </editor> <title> (1987) Vision, Brain, and Cooperative Computation. </title> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 129-163. </pages>
Reference-contexts: Emergent temporary structures have also been used in individual agents. For example, several researchers have explored the creation of gradient fields over analogical representations of the environment. The best known example are potential fields [7], <ref> [6] </ref>. A potential field is a dynamical temporary structure created over an analogical representation of the environment by various repulsion and attraction forces. 45 that breaks it down, and an autocatalytic process so that the temporary structure builds upon itself.
Reference: [7] <author> Arkin, R. </author> <title> (1989) Motor Schema based mobile robot navigation. </title> <journal> Int. Journal of Robotics Research. </journal> <volume> Vol 8, 4 p. </volume> <pages> 92-112. </pages>
Reference-contexts: A review of the field can be organised along several lines. One way would be to look at the progress towards the achievement of specific competences, for example, the different approaches for `navigation towards a target': using potential fields <ref> [7] </ref>, cognitive maps with landmarks [70], phonotaxis [129], global reference frames [86], pheromone trails or agent chains [41], and so on. <p> More structure is needed in which different neural networks can be hierarchically combined. Several architectures and associated programming languages have been proposed. One of the best worked out examples is reported by Lyons and Arbib [62]. It centers around 25 the schema concept <ref> [7] </ref>. An advantage of neural network approaches is that they immediately incorporate a mechanism for learning. A disadvantage is that the global search space for an agent is too big to start from zero with neural network techniques. <p> These forces are recognised as the essential ingredients for emergent temporary structures in general [111],[59]. Emergent temporary structures have also been used in individual agents. For example, several researchers have explored the creation of gradient fields over analogical representations of the environment. The best known example are potential fields <ref> [7] </ref>, [6]. A potential field is a dynamical temporary structure created over an analogical representation of the environment by various repulsion and attraction forces. 45 that breaks it down, and an autocatalytic process so that the temporary structure builds upon itself. <p> The attraction force may come from the location of the desired goal towards which the agent wants to move. Repulsion may be generated by processes that are linked to the sensing of obstacles. Locomotion is influenced by the combined impact of attraction and repulsion forces (Fig. 12 from <ref> [7] </ref>, p.99).
Reference: [8] <author> Assad, A. and N. </author> <title> Packard (1991) Emergent Colonization in an Artificial Ecology. </title> <editor> In: F.J. Varela and P. Bourgine (eds.) </editor> <booktitle> Toward a Practice of Autonomous Systems. Proceedings of the First European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 143-152. </pages>
Reference-contexts: Many researchers in the Alife community have attempted to define emergence (see for example [36], [59], [24], [111], <ref> [8] </ref>). For the present purposes, we will define emergence from two viewpoints: that of the observer and that of the components of the system. From the viewpoint of an observer, we call a sequence of events a behavior if a certain regularity becomes apparent.
Reference: [9] <author> Baas, N. </author> <title> (1993) Second order emergence. </title> <booktitle> Oral communication at the second European Conference on Artificial Life, </booktitle> <address> ULB Brussels. </address>
Reference-contexts: of the components is directly sensitive to the regularities exhibited by the behavior and that no component is able to control its appearance directly. 37 A further distinction can be made between emergent behavior upon which the system does not build further, and semantic emergence [24] or second order emergence <ref> [9] </ref>, in which the system is able to detect, amplify, and build upon emergent behavior. The latter can only happen by operating on the behavior programs which causally influence behavior, similar to the way genetic evolution operates on the genes. The remainder of this section discusses first order emergence.
Reference: [10] <author> Babloyantz, A. </author> <title> (1986) Molecules, Dynamics, and Life. An Introduction to the Self-organisation of Matter. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: The classical example for multi-agent systems is the formation of paths. It has been well studied empirically not only in ant societies [91] but also in many other biological multi-element systems <ref> [10] </ref>. It is also well understood theoretically in terms of the more general theory of self-organisation [89]. The phenomenon has been shown in simulation studies [108], [29], [32] and recently on physical robots [14].
Reference: [11] <editor> Baeck, T., H-P. </editor> <title> Schwefel (1993) An Overview of Evolutionary Algorithms for Parameter Optimization. </title> <journal> Evolutionary Computation. </journal> <volume> Vol 1,1. </volume> <pages> p. 1-23. </pages>
Reference: [12] <author> Barto, </author> <title> A.G. and R.S. Sutton (1991) Landmark learning: An illustration of associative search. </title> <journal> Biological Cybernetics Vol. </journal> <volume> 42. </volume> <pages> p. 1-8. 68 </pages>
Reference-contexts: This introduces a credit assignment problem [82]. Early proposals ranked the possible situation-action associations, selected the best one (possibly with some variation to avoid local minima), and increased or decreased the probability of future choice depending on the effect of the chosen action ([132], <ref> [12] </ref>). More recent mechanisms go in the direction of having the agent develop a more sophisticated representation of the result of an action. For example, a prediction of reward is introduced, or a prediction of (long-term) cumulative reward, i.e. return [118].
Reference: [13] <author> Barto, </author> <title> A.G. (1990) Connectionist Learning for Control. </title> <editor> In Miller, T.W., R.S. Sutton, and P.J. Werbos (eds.) </editor> <title> Neural Networks for Control. </title> <publisher> MIT Press/Bradford Books. </publisher> <address> Cambridge Ma. p. </address> <pages> 5-58. </pages>
Reference: [14] <author> Beckers, R. </author> <booktitle> (1993) Demonstration at the Alife Meeting, </booktitle> <institution> Technical University of Delft. </institution>
Reference-contexts: It is also well understood theoretically in terms of the more general theory of self-organisation [89]. The phenomenon has been shown in simulation studies [108], [29], [32] and recently on physical robots <ref> [14] </ref>. The temporary structure in the case of path formation in ant societies is a chemical pheromone gradient deposited in the environment. Ants are attracted to the pheromone and therefore have a tendency to aggregate along the path.
Reference: [15] <author> Beer, R.D. </author> <title> (1990) Intelligence as Adaptive Behavior: An Experiment in Computational Neuroethology. </title> <publisher> Academic Press, </publisher> <address> Cambridge Ma. </address>
Reference-contexts: Particularly if sensori-motor competences are studied. This is why behavior-oriented AI researchers insist so strongly on the construction of physical agents [21], [130]. 6 Performing simulations of agents (as in <ref> [15] </ref>) is of course an extremely valuable aid in exploring and testing out certain mechanisms, the way simulation is heavily used in the design of airplanes. But a simulation of an airplane should not be confused with the airplane itself. 2.3 Behavior-oriented AI is strongly influenced by biology. <p> They fall roughly in four groups: neural network approaches, algorithmic approaches, circuit approaches, and dynamics approaches. Neural networks approaches Several researchers use artificial neural networks, in order to stay close to plausible biological structures ([5], [27], [94]). This approach is strongly related to biological cybernetics, and neuroethology <ref> [15] </ref>. A neural network consists of a set of nodes linked together in a network. Each node receives input from a set of nodes and sends activation as output to another set of nodes. Some inputs could come immediately from sensors. Some outputs are linked with actuators.
Reference: [16] <author> Bonner, J.T. </author> <title> (1988) The Evolution of Complexity by Means of Natural Selection. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, N.J. </address>
Reference-contexts: The biological orientation also shows up in a focus on the problem how complexity can emerge. The origin of order and complexity is a central theme in biology [53] and is usually studied within the context of self-organisation [95], or natural selection <ref> [16] </ref>. Behavior-oriented AI research is focusing on the concepts of emergent behavior and emergent functionality as a possible explanation for the emergence of functional complexity in agents. These concepts will be discussed in more detail later.
Reference: [17] <editor> Brady, J.M. and R. </editor> <booktitle> Paul (1984) Robotics Research: The First International Symposium. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge Ma. </address>
Reference-contexts: But the two fields should not be equated. The goal of robotics is to identify, design, and engineer the most reliable and most cost-effective solution for a sensori-motor task in a particular, usually fixed and known, environment <ref> [17] </ref>. Behavior-oriented AI uses the tools of roboticists to study biological issues, but very different criteria for success apply. 11 2.5 The rest of the paper focuses on emergence. A review of the field can be organised along several lines.
Reference: [18] <author> Braitenberg, V. </author> <title> (1984) Vehicles: Experiments in Synthetic Psychology. </title> <publisher> MIT Press, </publisher> <address> Cambridge MA. </address>
Reference-contexts: This technical work is in some way a revival of earlier cybernetics work by Walter [128] and Braitenberg <ref> [18] </ref> but now with better hardware and more advanced software. Yet another way is to look at progress on the theoretical questions outlined earlier, for example the definition and use of optimality criteria [76], or the development of quantitative behavioral descriptions using techniques from complex systems theory [89]. <p> It has additional light sensors and microphones. There is a translational motor for forward/backward movement and a rotational motor for turning left or right. The agent has a central PC-like processor and dedicated hardware for signal processing and interdevice communication. 19 enberg <ref> [18] </ref>, obstacle avoidance can be achieved by a direct coupling between infrared reflection and rotational motor speed. If the amount of reflection increases on one side, then the rotational motor speed going in the same direction increases.
Reference: [19] <author> Brooks, R. </author> <title> (1986) A Robust Layered Control System for a Mobile Robot. </title> <journal> IEEE Journal of Robotics and Automation. </journal> <volume> 2(1). </volume> <pages> p. 14-23. </pages>
Reference-contexts: Recently, a subgroup within the AI community has started to stress embodied intelligence and made strong alliances with biology and research on artificial life [59]. This is opening up an `artificial life route to artificial intelligence' [112], which has been characterised as Bottom-Up AI <ref> [19] </ref>, the Animat approach [133], Behavior-based AI [108], or Animal Robotics [75]. These terms identify a loose network of engineers and biologists who share the common goal of understanding intelligent behavior through the construction of artificial systems. <p> This is the reason why it is so difficult to bridge the gap between neurology and psychology. There is a growing consensus in behavior-oriented AI research that behavior systems be considered as the basic units <ref> [19] </ref>. <p> The reason why we need to be careful in mixing functional and behavior terminology is because the same behavior system may contribute to different functionalities. Behavior systems may be very simple, implementing direct reflexes between sensing and action (as in <ref> [19] </ref>. They may also be more complex, building up and using cognitive world maps (as in [70]. When enough complexity is reached, a large collection of interacting behavior systems may resemble a society of interacting agents [84]. Each behavior system is most adapted to a particular class of environments. <p> Algorithmic approaches Other researchers have stayed closer to the methods traditionally used in computer programming so that powerful abstraction mechanisms can be used to cope with the complexity of programming complete robotic agents. One of the best known examples is the subsumption architecture <ref> [19] </ref>. The subsumption architecture makes two fundamental assumptions: (1) behavior programs are defined algorithmically, (2) there is a hierarchical but distributed control between different behavior systems based on subsumption relations. <p> However one behavior system may inhibit that input values flow into the automaton or that action parameters are sent to the actuators. Inhibition is done by an explicit subsumption link which is under the control of the behavior system 27 (Fig. 4, Adapted from <ref> [19] </ref>). boxes are state variables. Boxes with a line in the bottom right corner are finite state automata. Alpha balance is another network. Nodes marked s establish a subsumption relation. For example activation of `up leg trigger' inhibits the inflow of `leg down' to the `beta pos' automaton.
Reference: [20] <author> Brooks, R. </author> <title> (1990) The Behavior Language; User's Guide. </title> <institution> MIT AI Lab. </institution> <note> Memo 1127. </note>
Reference-contexts: For example activation of `up leg trigger' inhibits the inflow of `leg down' to the `beta pos' automaton. In a concrete agent, the number and complexity of the finite state automata quickly grows to hundreds of states and registers. A higher level language, known as the behavior language <ref> [20] </ref>, has therefore been designed to make the definition of large collections of behavior systems possible. Many of the low-level details of programming finite-state automata are thus removed and consequently more complex applications can be tackled.
Reference: [21] <author> Brooks, R. </author> <title> (1991) Intelligence without reason. </title> <booktitle> Proceedings of IJCAI-91. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo Ca. p. </address> <pages> 569-595. 69 </pages>
Reference-contexts: This makes the construction of robotic agents that must sense the environment and can physically act upon the environment, unavoidable. Particularly if sensori-motor competences are studied. This is why behavior-oriented AI researchers insist so strongly on the construction of physical agents <ref> [21] </ref>, [130]. 6 Performing simulations of agents (as in [15]) is of course an extremely valuable aid in exploring and testing out certain mechanisms, the way simulation is heavily used in the design of airplanes. <p> Specialisation and the pressure to act in real time suggests a horizontal organisation, as opposed to a vertical or hierarchical organisation, typical for more classical ap 21 proaches <ref> [21] </ref>. In a vertical organisation, the different modules perform specific func-tions like vision, learning, world representation, communication or planning. This leads to a sense-think-act cycle which does not guarantee real-time response when needed. <p> Guideline 2: Exploit the physics. Surprisingly, it is sometimes easier to achieve a particular behavior when the physics of the world, the morphology of the body, and the physics of the sensors and the actuators of the agent are properly exploited <ref> [21] </ref>. This is already the case for obstacle avoidance. A robot may be equiped with bumpers which cause a (sudden) slow down and an immediate retraction in a random direction. This may get the robot out of situations which appear to be dead end situations in simulations.
Reference: [22] <author> Brooks, R. </author> <title> (1991b) Challenges for Complete Creature Architectures. </title> <editor> In: Meyer, J-A., and S.W. </editor> <booktitle> Wilson (1991) From Animals to Animats. Proceedings of the First International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books. </publisher> <address> Cambridge Ma. p. </address> <pages> 434-443. </pages>
Reference-contexts: This theme underlies other work in Artificial Life as well, and is related to the topic of emergence which is discussed more extensively in section 4 and 5. This tendency to search for simple mechanisms is particularly strong in the dislike of complex `objective' world models <ref> [22] </ref>. The de-emphasis of complex representations is shared by researchers criticising cognitivism [125], and is related to the trend for situated cognition [115], which hypothesises that intelligence is the result of simple situation-specific agent/environment mechanisms that are strongly adapted to moment-to-moment decision making. <p> It can be expected that many more design guidelines will become explicated as experience in building robotic agents continues. Some more extensive overviews can be found in [69], <ref> [22] </ref>, [94], [66], a.o. 24 3.3 Different approaches are explored for designing the be- havior programs. Although there seems to be a consensus in the field that behavior systems are appropriate units, different avenues are explored regarding the best way to design the underlying behavior programs.
Reference: [23] <author> Brooks, R. </author> <title> (1992) Artificial life and real robots. </title> <editor> In: F.J. Varela and P. Bourgine (eds.) </editor> <booktitle> Toward a Practice of Autonomous Systems. Proceedings of the First European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 3-10. </pages>
Reference-contexts: The primitive building blocks of the behavior programs are in this case the sensory inputs and action parameter outputs, Boolean connectives, conditionals, and the subsumption primitives. Brooks <ref> [23] </ref> has however criticised these results, mostly because the primitive building blocks were well chosen (based on an analysis of a known solution) and simplifying assumptions were made concerning the Boolean nature of certain conditionals. <p> Koza [57] uses a very simple virtual world. Cliff, Husbands and Harvey [26] use a much more sophisticated simulation to test out the fitness of a solution. But, as Brooks <ref> [23] </ref> points out, the gap between simulated and real world will always remain quite large. One possible way out is to use the real robot as soon as reasonable solutions have been discovered. An example application of this technique is discussed in [105].
Reference: [24] <author> Cariani, P. </author> <title> (1991) Emergence and Artificial Life. </title> <editor> In: Langton, C.G., C. Taylor, J.D. Farmer, and S. </editor> <booktitle> Rasmussen (1992) Artificial Life II. Proceedings of the Workshop on Artificial Life Held February, </booktitle> <address> 1990 in Santa Fe, New Mexico. </address> <publisher> Addison-Wesley, </publisher> <address> Reading Ma. p. </address> <pages> 775-797. </pages>
Reference-contexts: It is also the research theme that has the most connections to other areas of Artificial Life. 35 4.1 Emergence can be defined in terms of the need for new descriptive categories. Many researchers in the Alife community have attempted to define emergence (see for example [36], [59], <ref> [24] </ref>, [111], [8]). For the present purposes, we will define emergence from two viewpoints: that of the observer and that of the components of the system. From the viewpoint of an observer, we call a sequence of events a behavior if a certain regularity becomes apparent. <p> we should find that none of the components is directly sensitive to the regularities exhibited by the behavior and that no component is able to control its appearance directly. 37 A further distinction can be made between emergent behavior upon which the system does not build further, and semantic emergence <ref> [24] </ref> or second order emergence [9], in which the system is able to detect, amplify, and build upon emergent behavior. The latter can only happen by operating on the behavior programs which causally influence behavior, similar to the way genetic evolution operates on the genes. <p> But this introduces an important role for the designer. In the context of emergent functionality, we expect that the fitness function should be subject to evolution and should be local to the organism that evolves (as is indeed the case in [96]. Cariani <ref> [24] </ref> calls this pragmatic emergence. 5.2 A selectionist approach may be the key for generating emergent functionality. Although convincing examples of emergent functionality on physical robots operating in the real world do not exist, we are beginning to see the glimpses of it and breakthroughs can be expected soon.
Reference: [25] <author> Changeux, J-P. </author> <title> (1986) Neuronal Man: The Biology of Mind. </title> <publisher> Oxford University Press, Oxford. </publisher>
Reference-contexts: It has also been proposed by some neurobiologists to be the major mechanism underlying the formation of new structure (and therefore functionality) in the brain [33], <ref> [25] </ref>. Evolutionary algorithms have been worked out in great detail and studied from a mathematical point of view (see the review in ([11]). The major variants are genetic algorithms [40] usually operating on classifier systems [45] and evolution strategies [103]. Applications have focused mostly on parameter optimization [63].
Reference: [26] <author> Cliff, D., P. Husbands, and I. </author> <title> Harvey (1993) Evolving Visually Guided Robots. </title> <editor> In: Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wilson (1993) From Animals to Animats2. Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 374-383. </pages>
Reference-contexts: Off-line evolution creates a new problem, which is the gap between the virtual world of the simulator and the real world. Koza [57] uses a very simple virtual world. Cliff, Husbands and Harvey <ref> [26] </ref> use a much more sophisticated simulation to test out the fitness of a solution. But, as Brooks [23] points out, the gap between simulated and real world will always remain quite large.
Reference: [27] <author> Cruse, H., U. Muller-Wilm, and J. </author> <title> Dean (1993) Artificial Neural Nets for controlling a 6-legged walking system. </title> <editor> In: Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wilson (1993) From Animals to Animats2. Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 52-60. </pages>
Reference-contexts: They fall roughly in four groups: neural network approaches, algorithmic approaches, circuit approaches, and dynamics approaches. Neural networks approaches Several researchers use artificial neural networks, in order to stay close to plausible biological structures ([5], <ref> [27] </ref>, [94]). This approach is strongly related to biological cybernetics, and neuroethology [15]. A neural network consists of a set of nodes linked together in a network. Each node receives input from a set of nodes and sends activation as output to another set of nodes.
Reference: [28] <author> Decuyper, J. and D. </author> <title> Keymeulen (1991) A Reactive Robot Navigation System Based on a Fluid Dynamics Metaphor. </title> <editor> In: Varela, F.J. and P. Bourgine (eds.) </editor> <booktitle> (1992) Toward a Practice of Autonomous Systems. Proceedings of the First European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 348-355. </pages>
Reference-contexts: Other types of dynamics have been explored to generate and maintain emergent temporary structures to aid in navigation, for example fluid mechanics so that a fluid flow between the agent's location in an analogical map and the goal location emerges <ref> [28] </ref>, or reaction-diffusion dynamics to generate concentration gradients that can be exploited in navigation or movement control [109]. The creation of temporary structures through a self-organising mechanism that combines build-up, break-down, and feedback giving rise to autocatalysis, has been used also for other aspects of intelligent behavior.
Reference: [29] <author> Deneubourg, J-L. and S. </author> <title> Goss (1990) Collective patterns and decision making. </title> <journal> Ecology, Ethology and Evolution. </journal> <volume> Vol 1. </volume> <pages> p. 295-311. </pages>
Reference-contexts: It has been well studied empirically not only in ant societies [91] but also in many other biological multi-element systems [10]. It is also well understood theoretically in terms of the more general theory of self-organisation [89]. The phenomenon has been shown in simulation studies [108], <ref> [29] </ref>, [32] and recently on physical robots [14]. The temporary structure in the case of path formation in ant societies is a chemical pheromone gradient deposited in the environment. Ants are attracted to the pheromone and therefore have a tendency to aggregate along the path.
Reference: [30] <author> Deneubourg, J-L, et.al. </author> <title> (1993) Self-organisation and life: from simple rules to global complexity. </title> <booktitle> Proceedings of the Second European Conference on Artificial Life. </booktitle> <address> ULB, Brussels. </address>
Reference-contexts: Good sources for tracking the field are the conferences on the Simulation of Adaptive Behavior ([80], [79]) and the associated journal [102], the conferences on Artificial Life ([59], [60], [124], <ref> [30] </ref>), and the associated journal [4]. There are also occasional contributions to international conferences on AI (such as IJCAI, AAAI, or ECAI), neural networks (NIPS), or robotics (IEEE). Reports of some milestone workshops have been published ([65], [123], [112], [113]).
Reference: [31] <author> Donnett, J. and T. </author> <title> Smithers (1990) Lego Vehicles: A Technology for studying intelligent systems. </title> <editor> In: Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wilson (1993) From Animals to Animats2. Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 540-569. 71 </pages>
Reference-contexts: Another approach would be to review the large amount of work on building technical hardware and software platforms which now make it possible to execute experiments easily and at low cost [35], <ref> [31] </ref>, [50]. This technical work is in some way a revival of earlier cybernetics work by Walter [128] and Braitenberg [18] but now with better hardware and more advanced software.
Reference: [32] <author> Drogoul, A. and J. </author> <title> Ferber (1993) From Tom Thumb to the Dockers: Some Experiments with Foraging Robots. </title> <editor> In: Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wilson (1993) From Animals to Animats2. Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 451-459. </pages>
Reference-contexts: It has been well studied empirically not only in ant societies [91] but also in many other biological multi-element systems [10]. It is also well understood theoretically in terms of the more general theory of self-organisation [89]. The phenomenon has been shown in simulation studies [108], [29], <ref> [32] </ref> and recently on physical robots [14]. The temporary structure in the case of path formation in ant societies is a chemical pheromone gradient deposited in the environment. Ants are attracted to the pheromone and therefore have a tendency to aggregate along the path.
Reference: [33] <author> Edelman, G. </author> <title> (1987) Neural Darwinism: The Theory of Neuronal Group Selection. </title> <publisher> Basic Books, </publisher> <address> New York. </address>
Reference-contexts: Evolutionary development has been shown in other areas of Artificial Life to be an extremely powerful source for generating more complexity (see e.g. [96]). It has also been proposed by some neurobiologists to be the major mechanism underlying the formation of new structure (and therefore functionality) in the brain <ref> [33] </ref>, [25]. Evolutionary algorithms have been worked out in great detail and studied from a mathematical point of view (see the review in ([11]). The major variants are genetic algorithms [40] usually operating on classifier systems [45] and evolution strategies [103]. Applications have focused mostly on parameter optimization [63].
Reference: [34] <author> Edelman, G. </author> <title> (1992) Bright Air, Brilliant Fire. On the Matter of the Mind. </title> <publisher> Basic Books, </publisher> <address> New York. </address>
Reference-contexts: The distinction between the two fields is of course a matter of degree. Behavior-oriented researchers heavily make use of neural network techniques to implement certain aspects of an overall design and some neural network researchers are beginning to consider the problem of building complete agents (cf. Edelman's NOMAD <ref> [34] </ref>). There are obviously strong ties between behavior-oriented AI and robotics, because the construction of physical agents is seen as a conditio sine qua non for applying the method of the artificial properly. But the two fields should not be equated.
Reference: [35] <author> Flynn, A. and R. </author> <title> Brooks (1989) Building Robots: Expectations and Experiences. </title> <booktitle> IEEE Workshop on Intelligent Robots and Systems. IROS '89. Tsukuba. p. </booktitle> <pages> 236-243. </pages>
Reference-contexts: Another approach would be to review the large amount of work on building technical hardware and software platforms which now make it possible to execute experiments easily and at low cost <ref> [35] </ref>, [31], [50]. This technical work is in some way a revival of earlier cybernetics work by Walter [128] and Braitenberg [18] but now with better hardware and more advanced software.
Reference: [36] <author> Forrest, S. </author> <title> (1989) Emergent computation: self-organizing, collective, </title> <booktitle> and cooperative phenomena in natural and artificial computing networks. </booktitle> <publisher> North-Holland Pub. Co, Amsterdam. </publisher>
Reference-contexts: It is also the research theme that has the most connections to other areas of Artificial Life. 35 4.1 Emergence can be defined in terms of the need for new descriptive categories. Many researchers in the Alife community have attempted to define emergence (see for example <ref> [36] </ref>, [59], [24], [111], [8]). For the present purposes, we will define emergence from two viewpoints: that of the observer and that of the components of the system. From the viewpoint of an observer, we call a sequence of events a behavior if a certain regularity becomes apparent.
Reference: [37] <author> Gallagher, J. and R. </author> <title> Beer (1993) A Qualitative Dynamical Analysis of Evolved Locomotion Controllers. </title> <editor> In: Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wilson (1993) From Animals to Animats2. Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 71-80. 72 </pages>
Reference-contexts: Several researchers have proposed a state-space approach for defining the dynamics of the observed behavior and the internal operation of the agent (e.g., [77], [54], <ref> [37] </ref>, [119]). Once a state-space description is available, the concepts of dynamical systems theory (attractors, transients, recurrent trajectories, etc.) [1] can be used to characterise qualitatively and quantitatively behaviors and internal structures like perceptions, representations, and actions.
Reference: [38] <author> Genesereth, M. and N. </author> <booktitle> Nilsson (1987) Logical Foundations of Artificial In--telligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos. </address>
Reference-contexts: The behavior-oriented approach is complementary to the currently dominating trend in AI (also known as the classical approach) which is almost exclusively concentrated on the problems of identifying, formalising, and representing knowledge <ref> [38] </ref>. The emphasis on knowledge leads almost automatically to a focus on disembodied intelligence. Classical AI systems therefore do not include a physical body nor sensing or acting.
Reference: [39] <author> Giszter, S. </author> <title> (1993) Behavior networks and force fields for simulating spinal reflex behaviors of the frog. </title> <editor> In: Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wilson (1993) From Animals to Animats2. Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 172-181. </pages>
Reference-contexts: The temporary strength differences can be used by a decision module to determine which action will be selected next. 47 A particularly fascinating application of this mechanism for modeling spinal reflex behaviors of the frog is reported by Giszter <ref> [39] </ref>. The behaviors include limb withdrawal, aversive turns, and wiping away of noiceptive stimuli. The latter requires for example different simpler component behaviors: optional flexion, then place motion and then whisk motion. Each of these has certain conditions that need to be satisfied and each will make certain conditions true.
Reference: [40] <author> Goldberg, D.E. </author> <title> (1989) Genetic Algorithms in Search, Optimization and Machine Learning. </title> <address> Addison-Wesely, Reading Ma. </address>
Reference-contexts: Evolutionary algorithms have been worked out in great detail and studied from a mathematical point of view (see the review in ([11]). The major variants are genetic algorithms <ref> [40] </ref> usually operating on classifier systems [45] and evolution strategies [103]. Applications have focused mostly on parameter optimization [63].
Reference: [41] <author> Goss, S. and J-L. </author> <title> Deneubourg (1992) Harvesting by a group of robots. </title> <editor> In: Varela, F.J. and P. Bourgine (eds.) </editor> <booktitle> (1992) Toward a Practice of Autonomous Systems. Proceedings of the First European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 195-204. </pages>
Reference-contexts: One way would be to look at the progress towards the achievement of specific competences, for example, the different approaches for `navigation towards a target': using potential fields [7], cognitive maps with landmarks [70], phonotaxis [129], global reference frames [86], pheromone trails or agent chains <ref> [41] </ref>, and so on. Another approach would be to review the large amount of work on building technical hardware and software platforms which now make it possible to execute experiments easily and at low cost [35], [31], [50].
Reference: [42] <author> Hallam, J. </author> <title> (1993) Playing with toy cars. </title> <editor> In: Steels, L. and R. Brooks (eds.) </editor> <booktitle> (1993) The `artificial life' route to `artificial intelligence'. Building situated embodied agents. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <address> New Haven. </address>
Reference-contexts: This dynamics approach has been put forward by a number of researchers (see e.g. [107], [114]). It is more in line with standard control theory, which is also based on dynamical systems <ref> [42] </ref>. Artificial neural networks are a special case of dynamical systems and can therefore be incorporated easily in this paradigm. An example of a worked out dynamics architecture is described in [114]. It supports the formulation of processes and their combination in the design of complete behavior systems.
Reference: [43] <author> Harnad, S. </author> <title> (1990) The symbol grounding problem. </title> <journal> Physica D, </journal> <volume> 42 (1-3). </volume> <pages> p. 335-346. </pages>
Reference-contexts: Guideline 3: Do not think of sensing and acting in terms of symbol processing. The classical AI approach has been criticised because the symbols and symbol structures on which planning and decision making are based are not grounded in the real world <ref> [43] </ref>. The problem is that unequivocally decoding sensory data into a symbol and turning a command without error into its intended action may be unsolvable; not in principle but in practice. Behavior-oriented AI cannot escape the grounding problem. But a novel solution is proposed.
Reference: [44] <author> Hebb, </author> <title> D.O. (1949) The Organization of Behaviour. </title> <publisher> Wiley, </publisher> <address> New York. </address> <month> 73 </month>
Reference-contexts: They use associative or Hebbian learning. In Hebbian learning, an association between two elements (for example sensors and actuators) is made stronger based on co-occurrence <ref> [44] </ref>. It is also made weaker, for example due to a constant forgetting rate. Associative learning has been extensively studied in the artificial neural network field 59 (reviewed in [56], chap 4)).
Reference: [45] <author> Holland, J.H. </author> <booktitle> (1975) Adaptation in Natural and Artificial Systems. </booktitle> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, Michigan. </address>
Reference-contexts: Evolutionary algorithms have been worked out in great detail and studied from a mathematical point of view (see the review in ([11]). The major variants are genetic algorithms [40] usually operating on classifier systems <ref> [45] </ref> and evolution strategies [103]. Applications have focused mostly on parameter optimization [63]. More recently, higher level descriptions as opposed to bitstrings have been used for the representation of the algorithm that needs to be derived and as a result more complex algorithms have been generated [58].
Reference: [46] <author> Holland, J.H. </author> <title> (1985) Properties of the bucket brigade algorithm. </title> <editor> In J. J. Grefenstette (ed.) </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms and their appliations. </booktitle> <publisher> Lawrence Erlbaum, </publisher> <address> Pittsburgh, Pa. p. </address> <pages> 1-7. </pages>
Reference-contexts: A technique useful for learning temporal chains is to hand out reinforcement to the last action and from there back to previous associations which played a role. This technique is known as the bucket brigade algorithm and 51 originally due to <ref> [46] </ref>. Reinforcement learning methods have been shown to be capable of impressive learning behavior in simulations or engineering contexts [81], but there are again serious difficulties in the application to physical autonomous agents. The first major difficulty lies in the determination of the reinforcement signal.
Reference: [47] <author> Hoogeweg, P. </author> <title> (1989) Mirror Beyond Mirror: </title> <booktitle> Puddles of Life. In: Langton, C.G. (1989) Artificial Life. Santa Fe Institute Studies in the Sciences of Complexity. Proc. Vol VI. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading Ma. p. </address> <pages> 297-316. </pages>
Reference-contexts: Some biologists have called this the TODO principle: do whatever there is to do at a particular moment, instead of making complex representations and following elaborated plans <ref> [47] </ref>. It can be expected that many more design guidelines will become explicated as experience in building robotic agents continues. Some more extensive overviews can be found in [69], [22], [94], [66], a.o. 24 3.3 Different approaches are explored for designing the be- havior programs.
Reference: [48] <author> Horswill, I. </author> <title> (1992) Characterizing Adaptation by Constraint. </title> <editor> In: Varela, F.J. and P. Bourgine (eds.) </editor> <booktitle> (1992) Toward a Practice of Autonomous Systems. Proceedings of the First European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 58-63. </pages>
Reference-contexts: When enough complexity is reached, a large collection of interacting behavior systems may resemble a society of interacting agents [84]. Each behavior system is most adapted to a particular class of environments. This environment can be characterised in terms of a set of constraints <ref> [48] </ref> or cost functions [75]. Note that a behavior system is a theoretical unit. There is not a simple one-to-one 15 relation between a functionality, a behavior, and a set of mechanisms achieving the behavior. The only thing which has physical existence are the components.
Reference: [49] <author> Horswill, I. </author> <title> (1993) A simple, cheap, and robust visual navigation system. </title> <editor> In: Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wilson (1993) From Animals to Ani-mats2. Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p.129-136. </address>
Reference-contexts: Of course such a solution will not work outside its `niche'. But it will perform well and in a very cost effective way, as long as the conditions are appropriate. A good illustration of this design guideline is a visual navigation system developed by Horswill <ref> [49] </ref>. He has shown that by making a set of strong assumptions about the environment, the complexity of visual interpretation can be drastically reduced.
Reference: [50] <author> Jones, J.L. </author> <title> and A.M. Flynn (1993) Mobile Robots. Inspiration to implementation. A.K. </title> <publisher> Peters, </publisher> <address> Wellesley Ma. </address> <month> 74 </month>
Reference-contexts: Another approach would be to review the large amount of work on building technical hardware and software platforms which now make it possible to execute experiments easily and at low cost [35], [31], <ref> [50] </ref>. This technical work is in some way a revival of earlier cybernetics work by Walter [128] and Braitenberg [18] but now with better hardware and more advanced software.
Reference: [51] <author> Kaelbling, L. and S. </author> <title> Rosenschein (1990) Action and planning in embedded agents. </title> <journal> Journal of Robotics and Autonomous Systems, </journal> <volume> 6, </volume> <pages> 35-48. </pages>
Reference: [52] <author> Kaelbling, L. </author> <title> (1992) An Adaptable Mobile Robot. </title> <editor> In: Varela, F.J. and P. Bourgine (eds.) </editor> <booktitle> (1992) Toward a Practice of Autonomous Systems. Proceedings of the First European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 41-47. </pages>
Reference-contexts: The second difficulty is that reinforcement learning assumes a trial-and-error search to find a viable association. Unless the agent is already close to the desired behavior, it may take quite a while before such an association is discovered <ref> [52] </ref>. The third difficulty is the credit assignment problem. Proposed solutions all go in the direction of new complexity (in the form of models of return, or in more recent cases world models predicting return [118], [61]). <p> Despite these difficulties, there are some preliminary experiments on physical mobile robots ([67], <ref> [52] </ref>). The general conclusion seems to be that "current reinforcement-learning algorithms can be made to work robustly on simple problems, but there are a variety of dimensions in which they must be improved before it will 52 be possible to construct artificial agents that adapt to complex domains" ([52], p. 46).
Reference: [53] <author> Kauffman, S.A. </author> <title> (1993) The origins of order: self organization and selection in evolution. </title> <publisher> Oxford University Press, Oxford. </publisher>
Reference-contexts: The biological orientation also shows up in a focus on the problem how complexity can emerge. The origin of order and complexity is a central theme in biology <ref> [53] </ref> and is usually studied within the context of self-organisation [95], or natural selection [16]. Behavior-oriented AI research is focusing on the concepts of emergent behavior and emergent functionality as a possible explanation for the emergence of functional complexity in agents. These concepts will be discussed in more detail later.
Reference: [54] <author> Kiss, G. </author> <title> (1991) Autonomous Agents, AI and Chaos Theory. </title> <editor> In: Meyer, J-A., and S.W. </editor> <booktitle> Wilson (1991) From Animals to Animats. Proceedings of the First International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books. </publisher> <address> Cambridge Ma. p. </address> <pages> 518-524. </pages>
Reference-contexts: Several researchers have proposed a state-space approach for defining the dynamics of the observed behavior and the internal operation of the agent (e.g., [77], <ref> [54] </ref>, [37], [119]). Once a state-space description is available, the concepts of dynamical systems theory (attractors, transients, recurrent trajectories, etc.) [1] can be used to characterise qualitatively and quantitatively behaviors and internal structures like perceptions, representations, and actions.
Reference: [55] <author> Kohonen, T. </author> <title> (1988) Self-Organization and Associative Memory. </title> <booktitle> Springer Series in Information Sciences. </booktitle> <volume> Vol 8. </volume> <publisher> Springer Verlag, </publisher> <address> Berlin. </address>
Reference: [56] <author> Kosko, B. </author> <title> (1992) Neural Networks and Fuzzy Systems. A Dynamical Systems Approach to Machine Intelligence. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ. </address>
Reference-contexts: The behavior-oriented approach is also complementary to the artificial neural network approach, which is based on an even more radical bottom-up attitude because it focuses on the physical basis of behavior and hopes that this is sufficient to explain or synthesise intelligence <ref> [56] </ref>, i.e., that no separate behavioral level is necessary. The distinction between the two fields is of course a matter of degree. <p> The links between nodes are weighted. When the sum of the weighted inputs to a node exceeds a threshold, activation propagates to the output nodes. There are many variants of neural networks, depending on the type of propagation and the adaptation mechanism that is used for changing the weights <ref> [56] </ref>. Usually a single neural network (even with multiple layers) is not enough to build a complete robotic agent. More structure is needed in which different neural networks can be hierarchically combined. Several architectures and associated programming languages have been proposed. <p> The weights in multi-layered networks can still be learned if the error is back-propagated through nodes at successive layers based on the relative contribution of each node to the derived outcome [101]. See <ref> [56] </ref> (chap 5) for a review of these and other supervised learning methods. Although supervised learning methods have been demonstrated to be successful in simulation experiments, their application to autonomous agents runs into several problems. <p> In Hebbian learning, an association between two elements (for example sensors and actuators) is made stronger based on co-occurrence [44]. It is also made weaker, for example due to a constant forgetting rate. Associative learning has been extensively studied in the artificial neural network field 59 (reviewed in <ref> [56] </ref>, chap 4)). In the present case, there will be a progressively stronger association between particular states of the infrared sensors (determined by the environment) and particular action parameters of the rotational motor (determined by the turn away left and turn away right behavior systems).
Reference: [57] <author> Koza, J. </author> <title> (1991) Evolving Emergent Wall Following Robotic Behavior sing the Genetic Programming Paradigm. </title> <editor> In: Varela, F.J. and P. Bourgine (eds.) </editor> <booktitle> (1992) Toward a Practice of Autonomous Systems. Proceedings of the First 75 European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cam--bridge Ma. p. </address> <pages> 110-119. </pages>
Reference-contexts: This is a problem for a robot which has to remain viable, and thus maintain real-time responses within limited resource constraints. Consequently most researchers so far follow an off-line approach ([26], <ref> [57] </ref>). The genetic algorithm runs on a computer external to the robot. When a valid solution is found, it is loaded and integrated in the other behavior systems. Thus Koza [57] has shown how to derive the behavior programs for wall following and obstacle avoidance which were earlier demonstrated to function <p> Consequently most researchers so far follow an off-line approach ([26], <ref> [57] </ref>). The genetic algorithm runs on a computer external to the robot. When a valid solution is found, it is loaded and integrated in the other behavior systems. Thus Koza [57] has shown how to derive the behavior programs for wall following and obstacle avoidance which were earlier demonstrated to function on a real robot programmed 54 in the subsumption architecture [70]. <p> Off-line evolution creates a new problem, which is the gap between the virtual world of the simulator and the real world. Koza <ref> [57] </ref> uses a very simple virtual world. Cliff, Husbands and Harvey [26] use a much more sophisticated simulation to test out the fitness of a solution. But, as Brooks [23] points out, the gap between simulated and real world will always remain quite large.
Reference: [58] <editor> Koza, J. </editor> <booktitle> (1992) Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge Ma. </address>
Reference-contexts: Some of the disadvantages are: (1) algorithmic descriptions are more difficult to acquire or adapt (although see the work on genetic programming by Koza <ref> [58] </ref> discussed in section 5.), (2) an algorithmic specification makes it more difficult to get smooth behavior because conditions are expressed in terms of discrete thresholds, (3) the subsumption relation works well for basic sensori-motor competence, like 6-legged locomotion, but seems weak to regulate the interaction of more complex behavior systems <p> Applications have focused mostly on parameter optimization [63]. More recently, higher level descriptions as opposed to bitstrings have been used for the representation of the algorithm that needs to be derived and as a result more complex algorithms have been generated <ref> [58] </ref>. Evolutionary techniques start from a population of individuals (which in the present case would be equal to behavior systems) which each derive a different solution in 53 the space of possible solutions. The population is initialized in an arbitrary fash-ion.
Reference: [59] <author> Langton, </author> <title> C.G. </title> <booktitle> (1989) Artificial Life. Santa Fe Institute Studies in the Sciences of Complexity. Proc. Vol VI. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading Ma. </address>
Reference-contexts: The inspiration for AI theories has mostly come from logic and the cognitive sciences, particularly cognitive psychology and linguistics. Recently, a subgroup within the AI community has started to stress embodied intelligence and made strong alliances with biology and research on artificial life <ref> [59] </ref>. This is opening up an `artificial life route to artificial intelligence' [112], which has been characterised as Bottom-Up AI [19], the Animat approach [133], Behavior-based AI [108], or Animal Robotics [75]. <p> Different behavior systems cooperate and compete inside the agent. Different components cooperate and compete to form coherent behavior systems. So the ingredients of cooperation, competition, selection, hierarchy, and reinforcement, which have been identified as crucial for the emergence of complexity in other areas of biology <ref> [59] </ref>, are found at the behavioral level, making it possible to carry over results from other biological disciplines to behavior-oriented AI and vice versa. All of the elements of the above definitions for intelligence, adaptivity, and emergence can be quantitatively and objectively established. <p> It is also the research theme that has the most connections to other areas of Artificial Life. 35 4.1 Emergence can be defined in terms of the need for new descriptive categories. Many researchers in the Alife community have attempted to define emergence (see for example [36], <ref> [59] </ref>, [24], [111], [8]). For the present purposes, we will define emergence from two viewpoints: that of the observer and that of the components of the system. From the viewpoint of an observer, we call a sequence of events a behavior if a certain regularity becomes apparent.
Reference: [60] <editor> Langton, C.G., C. Taylor, J.D. Farmer, and S. </editor> <booktitle> Rasmussen (1992) Artificial Life II. Proceedings of the Workshop on Artificial Life Held February, </booktitle> <address> 1990 in Santa Fe, New Mexico. </address> <publisher> Addison-Wesley, </publisher> <address> Reading Ma. </address>
Reference-contexts: Good sources for tracking the field are the conferences on the Simulation of Adaptive Behavior ([80], [79]) and the associated journal [102], the conferences on Artificial Life ([59], <ref> [60] </ref>, [124], [30]), and the associated journal [4]. There are also occasional contributions to international conferences on AI (such as IJCAI, AAAI, or ECAI), neural networks (NIPS), or robotics (IEEE). Reports of some milestone workshops have been published ([65], [123], [112], [113]).
Reference: [61] <author> Lin, L-J, </author> <title> and T.M. Mitchell (1993) Reinforcement Learning with Hidden States. </title> <editor> In: In: Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wilson (1993) From Animals to Animats2. Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 271-280. </pages>
Reference-contexts: The third difficulty is the credit assignment problem. Proposed solutions all go in the direction of new complexity (in the form of models of return, or in more recent cases world models predicting return [118], <ref> [61] </ref>). Often many simplifying assumptions are made about the nature of sensory interpretations or actions. For example, most methods assume that it is possible to select each time the `best' action.
Reference: [62] <author> Lyons, </author> <title> D.M., and M.A. Arbib (1989) A Formal Model of Computation for Sensory-Based Robotics. </title> <journal> IEEE Trans. on Robotics and Automation. </journal> <volume> 5. </volume> <pages> p. 280-293. </pages>
Reference-contexts: More structure is needed in which different neural networks can be hierarchically combined. Several architectures and associated programming languages have been proposed. One of the best worked out examples is reported by Lyons and Arbib <ref> [62] </ref>. It centers around 25 the schema concept [7]. An advantage of neural network approaches is that they immediately incorporate a mechanism for learning. A disadvantage is that the global search space for an agent is too big to start from zero with neural network techniques.
Reference: [63] <author> Maenner, R. and B. </author> <title> Manderick (1992) Parallel Problem Solving from Nature, 2. </title> <publisher> North-Holland Pub. Co, </publisher> <address> Amsterdam. </address> <month> 76 </month>
Reference-contexts: Evolutionary algorithms have been worked out in great detail and studied from a mathematical point of view (see the review in ([11]). The major variants are genetic algorithms [40] usually operating on classifier systems [45] and evolution strategies [103]. Applications have focused mostly on parameter optimization <ref> [63] </ref>. More recently, higher level descriptions as opposed to bitstrings have been used for the representation of the algorithm that needs to be derived and as a result more complex algorithms have been generated [58].
Reference: [64] <author> Maes, P. </author> <title> (1989) The Dynamics of Action Selection. </title> <booktitle> In: Proceedings of the 11th International Joint Conference on AI (IJCAI 89) Morgan Kaufmann, </booktitle> <publisher> Pub. </publisher> <address> Los Altos. p. </address> <pages> 991-997. </pages>
Reference-contexts: The creation of temporary structures through a self-organising mechanism that combines build-up, break-down, and feedback giving rise to autocatalysis, has been used also for other aspects of intelligent behavior. For example, Maes <ref> [64] </ref> describes an action selection system (which maybe should be better called a motivational system) 46 the world. The structure consists of vector fields which can either attract or repell robot movement. The sum of all the fields generates a path which the robot can follow.
Reference: [65] <author> Maes, P. </author> <title> (1990) Designing Autonomous Agents: Theory and Practice from Biology to Engineering and Back. </title> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. </address>
Reference: [66] <editor> Maes, P. </editor> <booktitle> (1993) Behavior-Based Artificial Intelligence. In: </booktitle> <editor> Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wilson (1993) From Animals to Animats2. Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books. </publisher> <address> Cambridge Ma. p. </address> <pages> 2-10. </pages>
Reference-contexts: Moreover knowledge-oriented theories do not include environmental pressures on the self-preservation of the agent, and the role of adaptivity and emergence is taken over by the programmer. However, the claim (made for example in <ref> [66] </ref> that the classical, knowledge-oriented approach works only for "simulated toy problems" and makes too many simplifying assumptions (e.g., static environments, single tasks, etc.) is simply not true. <p> It can be expected that many more design guidelines will become explicated as experience in building robotic agents continues. Some more extensive overviews can be found in [69], [22], [94], <ref> [66] </ref>, a.o. 24 3.3 Different approaches are explored for designing the be- havior programs. Although there seems to be a consensus in the field that behavior systems are appropriate units, different avenues are explored regarding the best way to design the underlying behavior programs.
Reference: [67] <author> Maes, P. and R. </author> <title> Brooks (1990) Learning to coordinate behaviors. </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, Ca. p. </address> <pages> 796-802. </pages>
Reference: [68] <author> Malcolm, C. and T. </author> <title> Smithers (1988) Programming Assembly Robots in Terms of Task Achieving Behavioural Modules: First Experimental Results. </title> <booktitle> In: Proceedings International Advanced Robotics Programme, </booktitle> <address> Manchester. p. 15.1-15.6. </address>
Reference-contexts: This is the reason why it is so difficult to bridge the gap between neurology and psychology. There is a growing consensus in behavior-oriented AI research that behavior systems be considered as the basic units [19]. Other terms for the basic behavioral unit are task-achieving module <ref> [68] </ref>, or schema [5]. 13 To define the notion of a behavior system we have to make a distinction between a functionality, a behavior, a mechanism, and a component: * Functionalities: A functionality is something that the agent needs to achieve, for example locomotion, recharging, avoiding obstacles, finding the charging station,
Reference: [69] <author> Malcolm, C.A., T. Smithers and J. </author> <title> Hallam (1989) An emerging paradigm in robot architecture. </title> <editor> In: T. Kanade, F. Groen and L. Herzberger (eds.) </editor> <booktitle> (1989) Intelligent Autonomous Systems 2. </booktitle> <address> Amsterdam. p. </address> <pages> 546-564. 77 </pages>
Reference-contexts: It can be expected that many more design guidelines will become explicated as experience in building robotic agents continues. Some more extensive overviews can be found in <ref> [69] </ref>, [22], [94], [66], a.o. 24 3.3 Different approaches are explored for designing the be- havior programs. Although there seems to be a consensus in the field that behavior systems are appropriate units, different avenues are explored regarding the best way to design the underlying behavior programs.
Reference: [70] <author> Mataric, M. </author> <title> (1990) Environment Learning Using A Distributed Represen--tation. </title> <booktitle> In: Proceedings of 1990 IEEE International Conference on Robotics and Automation. p. </booktitle> <pages> 402-406. </pages>
Reference-contexts: A review of the field can be organised along several lines. One way would be to look at the progress towards the achievement of specific competences, for example, the different approaches for `navigation towards a target': using potential fields [7], cognitive maps with landmarks <ref> [70] </ref>, phonotaxis [129], global reference frames [86], pheromone trails or agent chains [41], and so on. Another approach would be to review the large amount of work on building technical hardware and software platforms which now make it possible to execute experiments easily and at low cost [35], [31], [50]. <p> Behavior systems may be very simple, implementing direct reflexes between sensing and action (as in [19]. They may also be more complex, building up and using cognitive world maps (as in <ref> [70] </ref>. When enough complexity is reached, a large collection of interacting behavior systems may resemble a society of interacting agents [84]. Each behavior system is most adapted to a particular class of environments. This environment can be characterised in terms of a set of constraints [48] or cost functions [75]. <p> When a valid solution is found, it is loaded and integrated in the other behavior systems. Thus Koza [57] has shown how to derive the behavior programs for wall following and obstacle avoidance which were earlier demonstrated to function on a real robot programmed 54 in the subsumption architecture <ref> [70] </ref>. The primitive building blocks of the behavior programs are in this case the sensory inputs and action parameter outputs, Boolean connectives, conditionals, and the subsumption primitives.
Reference: [71] <author> Maturana, H.R. and F.J. </author> <title> Varela (1987) The Tree of Knowledge: The Biological roots of Human Understanding. </title> <publisher> Shamhala Press, </publisher> <address> Boston. </address>
Reference-contexts: Newell's principle of rationality [87]). The behavior-oriented approach defines intelligence in terms of observed behavior and self-preservation (or autonomy) (see e.g. [124], [76]). It is based on the idea that the essence of biological systems is their capacity to continuously preserve and adapt themselves <ref> [71] </ref>: The behavior of a system is intelligent to the extent that it maximises the chances for self-preservation of that system in a particular environment. 7 The drive towards self-preservation applies to all levels of complexity: genes, cells, multi-cellular structures, plants, animals, groups of animals, societies, species. <p> When behavior systems are not orthogonal or not temporally ordered by the interaction dynamics, (partial) control of the actuators must take into account the fact that other behavior systems will have an impact at the same time. In these cases the interaction must be regulated by structural coupling <ref> [71] </ref> or co-adaptation: Behavior systems develop in the context of other behavior systems and their internal structure and functioning hence reflects this context. More complex control situations require the introduction of motivational variables which causally influence behavior systems and which have a dynamics on their own.
Reference: [72] <author> Maynard-Smith, J. </author> <title> (1982) Evolution and the theory of games. </title> <publisher> Cambridge Univ. Press, </publisher> <address> Cambridge UK. </address>
Reference-contexts: Another example is a study of how certain behavioral strategies (such as retreat when attacked) and their associated morphological characteristics are evolutionary stable <ref> [72] </ref>. Given this emphasis on behavior, the term behavior-oriented seems appropriate to distinguish the field, particularly from the more knowledge-oriented approach of classical AI. It will be used in the rest of the paper. 2.2 The methodology is based on building artificial systems.
Reference: [73] <editor> McClelland, J.L. and D.E. Rumelhart (eds.) </editor> <booktitle> (1986) Explorations in Parallel Distributed Processing. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. </address>
Reference: [74] <author> McDermott, J. </author> <title> (1982) R1: A Rule-Based Configurator of Computer systems. In: </title> <journal> AI Journal, </journal> <volume> Vol 19,1. </volume> <pages> p. 39-88. </pages>
Reference-contexts: It took several decades to turn these results into a solid engineering methodology and develop a number of well established industrial achievements, like XCON for configuring computer installations <ref> [74] </ref>. Some open issues. There are also many open problems beyond increasing the complexity of current systems. One of them, that has hardly been addressed, concerns the relation between the mechanisms used in behavior-oriented AI and those used in knowledge-oriented AI.
Reference: [75] <author> McFarland, D. </author> <title> (1992) Animals as cost-based Robots. </title> <booktitle> International Studies in the Philosophy of Science, </booktitle> <volume> Vol 6, 2. </volume> <pages> p. 133-153. </pages>
Reference-contexts: This is opening up an `artificial life route to artificial intelligence' [112], which has been characterised as Bottom-Up AI [19], the Animat approach [133], Behavior-based AI [108], or Animal Robotics <ref> [75] </ref>. These terms identify a loose network of engineers and biologists who share the common goal of understanding intelligent behavior through the construction of artificial systems. The researchers also share a growing number of assumptions and hypotheses about the nature of intelligence. <p> When enough complexity is reached, a large collection of interacting behavior systems may resemble a society of interacting agents [84]. Each behavior system is most adapted to a particular class of environments. This environment can be characterised in terms of a set of constraints [48] or cost functions <ref> [75] </ref>. Note that a behavior system is a theoretical unit. There is not a simple one-to-one 15 relation between a functionality, a behavior, and a set of mechanisms achieving the behavior. The only thing which has physical existence are the components.
Reference: [76] <author> McFarland, D. and T. </author> <booktitle> Boesser (1994) Intelligent Behavior in Animals and Robots. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. </address>
Reference-contexts: The `classical' AI approach defines intelligence in terms of knowledge: A system is intelligent if it maximally applies the knowledge that it has (cf. Newell's principle of rationality [87]). The behavior-oriented approach defines intelligence in terms of observed behavior and self-preservation (or autonomy) (see e.g. [124], <ref> [76] </ref>). <p> All this has already been illustrated by McFarland and Boesser <ref> [76] </ref>. We can also quantitatively identify the onset of emergence once a suitable mathematical 9 framework exists for defining the notion of a minimal description. <p> Yet another way is to look at progress on the theoretical questions outlined earlier, for example the definition and use of optimality criteria <ref> [76] </ref>, or the development of quantitative behavioral descriptions using techniques from complex systems theory [89]. These overviews would all be valuable but require much more space than available here. <p> Within this framework concepts like emergent functionality can be formalised and the results of emergent functionality better understood. At the same time work must proceed on developing formal theories to characterise the challenges in ecosystems, the optimality of behavior, and thus the chances of self-preservation of the agent <ref> [76] </ref>. The field of behavior-oriented AI research shows enormous signs of vitality. This paper focused only on a few aspects, ignoring other topics such as multi-agent systems, communication and cooperation, the formation of new sensory modalities, and so on.
Reference: [77] <author> McFarland, D. and A. </author> <title> Houston (1981) Quantitative Ethology: the state-space approach. </title> <publisher> Pitman Books, London. </publisher>
Reference-contexts: Several researchers have proposed a state-space approach for defining the dynamics of the observed behavior and the internal operation of the agent (e.g., <ref> [77] </ref>, [54], [37], [119]). Once a state-space description is available, the concepts of dynamical systems theory (attractors, transients, recurrent trajectories, etc.) [1] can be used to characterise qualitatively and quantitatively behaviors and internal structures like perceptions, representations, and actions.
Reference: [78] <author> Meyer, J-A. and A. </author> <title> Guillot (1991) Simulation of Adaptive Behavior in Ani-mats: Review and Prospect. </title> <editor> In: Meyer, J-A., and S.W. </editor> <booktitle> Wilson (1991) From 78 Animals to Animats. Proceedings of the First International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/ Bradford Books. </publisher> <address> Cambridge Ma. p. </address> <pages> 2-14. </pages>
Reference: [79] <author> Meyer, J-A., H.L. Roitblatt, </author> <title> and S.W. Wilson (1993) From Animals to Ani-mats2. </title> <booktitle> Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p.129-136. </address>
Reference-contexts: Given that substantial engineering efforts and non-trivial experimentation is required, the first solid experimental and technical results have only recently begun to appear. Good sources for tracking the field are the conferences on the Simulation of Adaptive Behavior ([80], <ref> [79] </ref>) and the associated journal [102], the conferences on Artificial Life ([59], [60], [124], [30]), and the associated journal [4]. There are also occasional contributions to international conferences on AI (such as IJCAI, AAAI, or ECAI), neural networks (NIPS), or robotics (IEEE).
Reference: [80] <author> Meyer, J-A., </author> <title> and S.W. Wilson (1991) From Animals to Animats. </title> <booktitle> Proceedings of the First International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/ Bradford Books. </publisher> <address> Cambridge Ma. </address>
Reference: [81] <author> Miller, W.T., R.S. Sutton and P.J. Werbos (eds.) </author> <title> (1990) Neural Networks for Control. </title> <publisher> MIT Press/Bradford Books. MIT Press, </publisher> <address> Cambridge, Ma </address>
Reference-contexts: This technique is known as the bucket brigade algorithm and 51 originally due to [46]. Reinforcement learning methods have been shown to be capable of impressive learning behavior in simulations or engineering contexts <ref> [81] </ref>, but there are again serious difficulties in the application to physical autonomous agents. The first major difficulty lies in the determination of the reinforcement signal. It is unrealistic to assume that the agent gets a clear scalar reinforcement signal after each action or series of actions.
Reference: [82] <author> Minsky, M. </author> <title> (1961) Steps towards artificial intelligence. </title> <editor> In: Feigenbaum, E. and J. Feldman (eds.) </editor> <booktitle> Computers and Thought. </booktitle> <publisher> McGraw-Hill, </publisher> <address> New York. p. </address> <pages> 406-450. </pages>
Reference-contexts: The reinforcement signal is produced as a direct or indirect consequence of the use of the association. Many different associations may play a role in a particular behavior, and there may be a delay between a behavior and its (positive or negative) consequences. This introduces a credit assignment problem <ref> [82] </ref>. Early proposals ranked the possible situation-action associations, selected the best one (possibly with some variation to avoid local minima), and increased or decreased the probability of future choice depending on the effect of the chosen action ([132], [12]).
Reference: [83] <author> Minsky, M. and S. </author> <title> Papert (1988) Perceptrons. </title> <publisher> MIT Press, </publisher> <address> Cambridge Ma. </address>
Reference-contexts: Con 49 vergence means that, given a consistent set of sense-act pairs, the learning method will settle on a stable set of weights that `correctly' relates X with Y. It can be shown that certain functions (such as the XOR function) require a multi-layered network <ref> [83] </ref>. The weights in multi-layered networks can still be learned if the error is back-propagated through nodes at successive layers based on the relative contribution of each node to the derived outcome [101]. See [56] (chap 5) for a review of these and other supervised learning methods.
Reference: [84] <author> Minsky, M. </author> <booktitle> (1985) The Society of Mind. </booktitle> <publisher> Simon and Schuster, </publisher> <address> New York. </address>
Reference-contexts: They may also be more complex, building up and using cognitive world maps (as in [70]. When enough complexity is reached, a large collection of interacting behavior systems may resemble a society of interacting agents <ref> [84] </ref>. Each behavior system is most adapted to a particular class of environments. This environment can be characterised in terms of a set of constraints [48] or cost functions [75]. Note that a behavior system is a theoretical unit.
Reference: [85] <author> Nehmzow, U., T. Smithers and B. </author> <title> McGonigle (1993) Increasing Behavioural Repertoire in a Mobile Robot. </title> <editor> In: Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wilson (1993) From Animals to Animats2. Proceedings of the Sec 79 ond International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 291-297. </pages>
Reference-contexts: Maintaining a distance from the wall can be achieved in an emergent way by the simultaneous operation of two behavior systems (as demonstrated by Nehmzow and Smithers <ref> [85] </ref>). The first one achieves regular obstacle avoidance, for example in 38 and the environment. New descriptive categories are needed to describe it. Right.
Reference: [86] <author> Nehmzow, U, and B. </author> <title> McGonigle (1993) Robot Navigation by Light. In: Deneubourg, J-L, et.al. (1993) Self-organisation and life: from simple rules to global complexity. </title> <booktitle> Proceedings of the Second European Conference on Artificial Life. </booktitle> <address> ULB, Brussels. p. </address> <pages> 835-844. </pages>
Reference-contexts: One way would be to look at the progress towards the achievement of specific competences, for example, the different approaches for `navigation towards a target': using potential fields [7], cognitive maps with landmarks [70], phonotaxis [129], global reference frames <ref> [86] </ref>, pheromone trails or agent chains [41], and so on. Another approach would be to review the large amount of work on building technical hardware and software platforms which now make it possible to execute experiments easily and at low cost [35], [31], [50]. <p> There may also be behavior systems that specialise in monitoring internal and external environmental conditions and act as a `reaper' [96], weakening or eliminating other behavior systems. An example of this is already shown in <ref> [86] </ref>. Large-scale experiments incorporating this approach do not exist yet. But reason for the optimism that emergent functionality may be demonstrated soon, comes from some initial experiments which show how new behavior systems may bootstrap themselves in the context of other behavior systems.
Reference: [87] <author> Newell, A. </author> <title> (1982) The Knowledge Level. </title> <journal> Artificial Intelligence Journal. </journal> <volume> Vol 18. </volume> <pages> p. 87-127. </pages>
Reference-contexts: The biological orientation clearly shows up in the way intelligence is defined. The `classical' AI approach defines intelligence in terms of knowledge: A system is intelligent if it maximally applies the knowledge that it has (cf. Newell's principle of rationality <ref> [87] </ref>). The behavior-oriented approach defines intelligence in terms of observed behavior and self-preservation (or autonomy) (see e.g. [124], [76]).
Reference: [88] <author> Nicolis, G. </author> <title> (1989) Physics of far-from-equilibrium systems and self-organisation. </title> <editor> In: Davis, P. </editor> <publisher> (ed) The New Physics. Cambridge University Press, </publisher> <address> Cambridge UK. p. </address> <pages> 316-347. </pages>
Reference-contexts: A behavior is emergent if new categories are needed to describe this underlying regularity which are not needed to describe the behaviors (i.e. the regularities) generated by the underlying behavior systems on their own. This definition is compatible with the one used in chemistry and physics (see for example <ref> [88] </ref>). Thus the regularities observed in the collective behavior of many molecules requires new categories like temperature and pressure over and above those needed to describe the motion of individual molecules.
Reference: [89] <author> Nicolis, G. and I. </author> <title> Prigogine (1985) Exploring Complexity. </title> <type> Piper, </type> <institution> Munchen. </institution>
Reference-contexts: We can also quantitatively identify the onset of emergence once a suitable mathematical 9 framework exists for defining the notion of a minimal description. An example of such a framework can be found in Chaitin's work on algorithmic complexity (see the discussion in <ref> [89] </ref> The objective nature of these definitions makes them preferable to those relying on the subjective assignment of knowledge or on subjective criteria of similarity to human intelligence as in the Turing test. 2.4 Behavior-oriented AI is complementary to other ap proaches to artificial intelligence. <p> Yet another way is to look at progress on the theoretical questions outlined earlier, for example the definition and use of optimality criteria [76], or the development of quantitative behavioral descriptions using techniques from complex systems theory <ref> [89] </ref>. These overviews would all be valuable but require much more space than available here. Instead, we will focus on how behavior-oriented AI may contribute to the field of Artificial Life as a whole, and more specifically to its central research theme, which is the origin of complexity. <p> The classical example for multi-agent systems is the formation of paths. It has been well studied empirically not only in ant societies [91] but also in many other biological multi-element systems [10]. It is also well understood theoretically in terms of the more general theory of self-organisation <ref> [89] </ref>. The phenomenon has been shown in simulation studies [108], [29], [32] and recently on physical robots [14]. The temporary structure in the case of path formation in ant societies is a chemical pheromone gradient deposited in the environment.
Reference: [90] <author> Nilsson, N. (ed.) </author> <title> (1984) Shakey the Robot. </title> <institution> SRI AI center. </institution> <note> Technical Note 323. </note>
Reference-contexts: The emphasis on knowledge leads almost automatically to a focus on disembodied intelligence. Classical AI systems therefore do not include a physical body nor sensing or acting. If intelligent robots have been considered (as in <ref> [90] </ref>, sensing and action has been delegated to subsystems which are assumed to deliver symbolic descriptions to the central planning and decision making modules.
Reference: [91] <author> Pasteels, J.M. </author> <title> and J-L Deneubourg (1987) From Individual to Collective Behaviour in Social Insects. </title> <publisher> Birkhauser, Basel. </publisher>
Reference-contexts: An example of a theory at the behavioral level is one which explains the formation of paths in an ant society in terms of a set of behavioral rules without reference to how they are neurophysiologically implemented <ref> [91] </ref>. Another example is a study of how certain behavioral strategies (such as retreat when attacked) and their associated morphological characteristics are evolutionary stable [72]. Given this emphasis on behavior, the term behavior-oriented seems appropriate to distinguish the field, particularly from the more knowledge-oriented approach of classical AI. <p> The classical example for multi-agent systems is the formation of paths. It has been well studied empirically not only in ant societies <ref> [91] </ref> but also in many other biological multi-element systems [10]. It is also well understood theoretically in terms of the more general theory of self-organisation [89]. The phenomenon has been shown in simulation studies [108], [29], [32] and recently on physical robots [14].
Reference: [92] <author> Pattee, H. </author> <year> (1989) </year> <month> Simluations, </month> <title> realizations, and theories of life. </title> <editor> In: Langton, C. (ed.) </editor> <booktitle> (1989) Artificial Life. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Redwood City, Ca. p. </address> <pages> 63-77. 80 </pages>
Reference-contexts: The device will have components with a particular structure and functioning which have been put together in a particular way. The design and implementation of these components and their mode of combination constitutes another possible way to theorise about the phenomena. Computational models and artificial models, or, what Pattee <ref> [92] </ref> calls simulations and realisations must be clearly distinguished.
Reference: [93] <author> Peters, T. </author> <title> (1990) Liberation Management. Necessary Disorganization for the Nanosecond Nineties. </title> <publisher> MacMillan, London. </publisher>
Reference-contexts: In a horizontal organisation, every module combines all these functions but specialised and optimised with respect to a particular behavior in a particular environment. This is reminiscent of horizontal organisations now becoming more common in corporations <ref> [93] </ref>. Guideline 2: Exploit the physics. Surprisingly, it is sometimes easier to achieve a particular behavior when the physics of the world, the morphology of the body, and the physics of the sensors and the actuators of the agent are properly exploited [21].
Reference: [94] <author> Pfeifer, R. and P. </author> <title> Verschure (1992) Distributed Adaptive Control: A Paradigm for Designing Autonomous Agents. </title> <editor> In: Varela, F.J. and P. Bourgine (eds.) </editor> <booktitle> (1992) Toward a Practice of Autonomous Systems. Proceedings of the First European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 21-30. </pages>
Reference-contexts: It can be expected that many more design guidelines will become explicated as experience in building robotic agents continues. Some more extensive overviews can be found in [69], [22], <ref> [94] </ref>, [66], a.o. 24 3.3 Different approaches are explored for designing the be- havior programs. Although there seems to be a consensus in the field that behavior systems are appropriate units, different avenues are explored regarding the best way to design the underlying behavior programs. <p> They fall roughly in four groups: neural network approaches, algorithmic approaches, circuit approaches, and dynamics approaches. Neural networks approaches Several researchers use artificial neural networks, in order to stay close to plausible biological structures ([5], [27], <ref> [94] </ref>). This approach is strongly related to biological cybernetics, and neuroethology [15]. A neural network consists of a set of nodes linked together in a network. Each node receives input from a set of nodes and sends activation as output to another set of nodes. <p> Let us look at one concrete example in the context of obstacle avoidance. This example was first suggested and tested in simulation by Pfeifer and Verschuere <ref> [94] </ref>. We have since done similar 58 experiments on a real robot and with different sensory modalities in Brussels.
Reference: [95] <author> Prigogine, I. and I. </author> <title> Stengers (1984) Order Out of Chaos. </title> <publisher> Bantam Books, </publisher> <address> New York. </address>
Reference-contexts: The biological orientation also shows up in a focus on the problem how complexity can emerge. The origin of order and complexity is a central theme in biology [53] and is usually studied within the context of self-organisation <ref> [95] </ref>, or natural selection [16]. Behavior-oriented AI research is focusing on the concepts of emergent behavior and emergent functionality as a possible explanation for the emergence of functional complexity in agents. These concepts will be discussed in more detail later.
Reference: [96] <author> Ray, T. </author> <title> (1992) An Approach to the Synthesis of Life. </title> <editor> In: Langton, C.G., C. Taylor, J.D. Farmer, and S. </editor> <booktitle> Rasmussen (1992) Artificial Life II. Proceedings of the Workshop on Artificial Life Held February, </booktitle> <address> 1990 in Santa Fe, New Mexico. p. </address> <pages> 325-371. </pages>
Reference-contexts: This mechanism is similar to evolution by natural selection as operating on the genes. Evolutionary development has been shown in other areas of Artificial Life to be an extremely powerful source for generating more complexity (see e.g. <ref> [96] </ref>). It has also been proposed by some neurobiologists to be the major mechanism underlying the formation of new structure (and therefore functionality) in the brain [33], [25]. Evolutionary algorithms have been worked out in great detail and studied from a mathematical point of view (see the review in ([11]). <p> But this introduces an important role for the designer. In the context of emergent functionality, we expect that the fitness function should be subject to evolution and should be local to the organism that evolves (as is indeed the case in <ref> [96] </ref>. Cariani [24] calls this pragmatic emergence. 5.2 A selectionist approach may be the key for generating emergent functionality. <p> These examples build further on the techniques discussed in the previous paragraphs but combine them in a novel way. When we study synthetic examples of emerging complexity, like that of Ray <ref> [96] </ref>, we see that they are based on selectionist mechanisms and that they have in addition two crucial features: 1. There is enough initial complexity to make a viable organism and there are many diverse organisms. <p> There may also be behavior systems that specialise in monitoring internal and external environmental conditions and act as a `reaper' <ref> [96] </ref>, weakening or eliminating other behavior systems. An example of this is already shown in [86]. Large-scale experiments incorporating this approach do not exist yet.
Reference: [97] <author> Rose, S. and S. </author> <booktitle> Bullock (1991) The Chemistry of Life. Third Edition. </booktitle> <publisher> Penguin Books, London. </publisher>
Reference-contexts: The processes take place in interaction with material outside the cell which is passing through the cell membrane in both directions. Cells may change their internal structure and functioning, to a certain limit, and thus adapt to the surrounding environment <ref> [97] </ref>. A behavior system consists also of a set of dynamic and static structures. The structures include physical components like sensors and body parts, as well as net 16 whereas behavior systems are guided in part by a behavior program. works, temporary states and electrical signals propagating in these networks.
Reference: [98] <author> Rosenblatt, F. </author> <booktitle> (1962) Principles of Neurodynamics. </booktitle> <publisher> Spartan Books, </publisher> <address> New York. </address>
Reference-contexts: There exist methods for adapting the weights w, which will lead to convergence <ref> [98] </ref>. Con 49 vergence means that, given a consistent set of sense-act pairs, the learning method will settle on a stable set of weights that `correctly' relates X with Y. It can be shown that certain functions (such as the XOR function) require a multi-layered network [83].
Reference: [99] <author> Rosenblatt, K.J. and D. </author> <title> Payton (1989) A Fine-Grained Alternative to the Subsumption Architecture for Mobile Robot Control. </title> <booktitle> In: Proceedings of the IEEE/INNS International Joint Conference on Neural Networks. </booktitle> <pages> 81 </pages>
Reference-contexts: There is still quite some work needed on additive control structures, particularly for hierarchical behavior systems, i.e. behavior systems that control a set of other behavior systems which are possibly internally temporally ordered. Work by Rosen-blatt and Payton <ref> [99] </ref> and Tyrrell [?] shows the direction in which this is being explored. These four different approaches to the design and implementation of behavior programs (neural networks, algorithms, circuits, dynamical systems) will undoubtly be explored further in the near future, and new approaches may come up.
Reference: [100] <author> Rosenschein, S. and L. Kaelbling. </author> <title> (1986) The synthesis of digital machines with provable epistemic properties. </title> <editor> In: Halpern, J. (ed.) </editor> <booktitle> (1986) Theoretical Aspects of Reasoning about Knowledge. </booktitle> <publisher> Morgan Kaufmann, Pub. </publisher> <address> San Mateo. p. </address> <pages> 83-98. </pages>
Reference-contexts: Circuit approaches A third approach stays closer to electrical engineering by assuming that behavior programs, in order to be as efficient as possible, should take the form of combinatorial circuits [2], <ref> [100] </ref>. This approach potentially leads to direct hardware implementation using VLSI. A combinatorial circuit consists of a set of components which perform a transformation from inputs to outputs. The outputs of one component may be inputs to one or more other components, thus forming a network. <p> Signals propagate through the network thus relating sensing to action. A language (called REX) has been developed to describe circuits. Compilers and interpreters exist which allow REX-defined circuits to run on physical robots. 29 To make programming circuits more tractable, Rosenschein and Kaelbling <ref> [100] </ref> have developed a higher level language which is based on a logical formalism known as situated automata. A translator has also been developed that transforms expressions expressed in this logical formalism into circuits. A circuit approach has a number of advantages from an engineering point of view.
Reference: [101] <editor> Rumelhart, J., J. </editor> <booktitle> McClelland and the PDP Research Group (1986) Parallel Distributed Processing. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge Ma. </address>
Reference-contexts: This is however not the case. Let us first look at supervised learning, i.e. learning with the aid of examples or counterexamples. One of the best known supervised learning algorithms is back propagation <ref> [101] </ref>. Behavior programs could be represented as artificial neural networks associating sensory signals to actuator outputs. Changes in behavior programs could then be based on the error between the desired outcome and the outcome derived from using the association. <p> It can be shown that certain functions (such as the XOR function) require a multi-layered network [83]. The weights in multi-layered networks can still be learned if the error is back-propagated through nodes at successive layers based on the relative contribution of each node to the derived outcome <ref> [101] </ref>. See [56] (chap 5) for a review of these and other supervised learning methods. Although supervised learning methods have been demonstrated to be successful in simulation experiments, their application to autonomous agents runs into several problems.
Reference: [102] <author> SAB. </author> <title> Simulation of Adaptive Behavior Journal. </title> <publisher> MIT Press, </publisher> <address> Cambridge Ma. </address>
Reference-contexts: Given that substantial engineering efforts and non-trivial experimentation is required, the first solid experimental and technical results have only recently begun to appear. Good sources for tracking the field are the conferences on the Simulation of Adaptive Behavior ([80], [79]) and the associated journal <ref> [102] </ref>, the conferences on Artificial Life ([59], [60], [124], [30]), and the associated journal [4]. There are also occasional contributions to international conferences on AI (such as IJCAI, AAAI, or ECAI), neural networks (NIPS), or robotics (IEEE). Reports of some milestone workshops have been published ([65], [123], [112], [113]).
Reference: [103] <author> Schwefel, </author> <title> H-P (1981) Numerical Optimization of Computer Models. </title> <publisher> Wiley, </publisher> <address> Chichester. </address>
Reference-contexts: Evolutionary algorithms have been worked out in great detail and studied from a mathematical point of view (see the review in ([11]). The major variants are genetic algorithms [40] usually operating on classifier systems [45] and evolution strategies <ref> [103] </ref>. Applications have focused mostly on parameter optimization [63]. More recently, higher level descriptions as opposed to bitstrings have been used for the representation of the algorithm that needs to be derived and as a result more complex algorithms have been generated [58].
Reference: [104] <author> Shapiro, </author> <title> S.C. </title> <booktitle> (1992) Encyclopedia of Artificial Intelligence. Second Edition. </booktitle> <publisher> John Wiley and Sons, Inc. </publisher> <address> New York. </address>
Reference-contexts: 1 Introduction For several decades, the field of Artificial Intelligence has been pursuing the study of intelligent behavior using the methodology of the artificial <ref> [104] </ref>. But the focus of this field, and hence the successes, have mostly been on higher order cognitive activities such as expert problem solving. The inspiration for AI theories has mostly come from logic and the cognitive sciences, particularly cognitive psychology and linguistics.
Reference: [105] <author> Shibata, T. and T. </author> <title> Fukuda (1993) Coordinative balancing in evolutionary multi-agent robot systems. </title> <editor> In Varela, F.J. and P. Bourgine (eds.) </editor> <booktitle> (1992) Toward a Practice of Autonomous Systems. Proceedings of the First European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 990-1003. </pages>
Reference-contexts: But, as Brooks [23] points out, the gap between simulated and real world will always remain quite large. One possible way out is to use the real robot as soon as reasonable solutions have been discovered. An example application of this technique is discussed in <ref> [105] </ref>. The application concerns the optimisation of path planning. Each robot is assumed to have a (static) map of the world that contains the obstacles and the goal towards which the robot needs to navigate. The genetic algorithm is used to search for a path towards the goal.
Reference: [106] <author> Smithers, T. </author> <title> (1992) Taking Eliminative Materialism Seriously: A Methodology for Autonomous Systems Research. </title> <editor> In Varela, F.J. and P. Bourgine (eds.) </editor> <booktitle> (1992) Toward a Practice of Autonomous Systems. Proceedings of the 82 First European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 31-40. </pages>
Reference-contexts: Behavior is defined 3 as a regularity observed in the interaction dynamics between the characteristics and processes of a system and the characteristics and processes of an environment <ref> [106] </ref>. Behavior is intelligent if it maximises preservation of the system in its environment. The main emphasis is not on the physical basis of behavior, as in the case of neural network research, but on the principles that can be formulated at the behavioral level itself.
Reference: [107] <author> Smithers, T. </author> <title> (1993) Are autonomous agents information processing systems? In: </title> <editor> Steels, L. and R. Brooks (eds.) </editor> <booktitle> (1993) The `artificial life' route to `artificial intelligence'. Building situated embodied agents. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <address> New Haven. </address>
Reference-contexts: are extreme functionalist tendencies in AI (and also in Alife) that equate intelligence or living with 17 disembodied abstractions, but this is not intended here. (2) The behavior programs and the transformation processes can be interpreted in information processing terms, but that is not necessary and may occasionally be harmful <ref> [107] </ref>. (3) The transformation processes can be implemented as computational processes but then only if we remind ourselves that computational processes are physical processes, that happen to be instantiated in a physical system of a certain organisation that we call a computer. The comparison also emphasises the dynamical aspects. <p> Rather than trying hard to establish a better correspondence between symbols (like distance or turn with a given angle) and the physical properties of the robot in the environment, it is also possible to dispense altogether with the idea that a symbolic interpretation is necessary <ref> [107] </ref>. For example, rather than having a rule of the sort "if the distance is greater than n, then turn away at a certain angle a", a dynamical coupling between infrared reflection and path deflection, implemented for example as differences between left and right motor speed, can be set up. <p> Dynamics approaches. Yet another approach is based on the hypothesis that behavior systems should be viewed as continuous dynamical systems instead of discrete computational systems as in the algorithmic approach. This dynamics approach has been put forward by a number of researchers (see e.g. <ref> [107] </ref>, [114]). It is more in line with standard control theory, which is also based on dynamical systems [42]. Artificial neural networks are a special case of dynamical systems and can therefore be incorporated easily in this paradigm. An example of a worked out dynamics architecture is described in [114].
Reference: [108] <author> Steels, L. </author> <title> (1990a) Cooperation between distributed agents through self-organisation. </title> <editor> In: Demazeau, Y. and J-P Muller (ed.) </editor> <booktitle> (1990) Decentralized A.I.. </booktitle> <publisher> North-Holland, Pub. Co., </publisher> <address> Amsterdam. p. </address> <pages> 175-196. </pages>
Reference-contexts: This is opening up an `artificial life route to artificial intelligence' [112], which has been characterised as Bottom-Up AI [19], the Animat approach [133], Behavior-based AI <ref> [108] </ref>, or Animal Robotics [75]. These terms identify a loose network of engineers and biologists who share the common goal of understanding intelligent behavior through the construction of artificial systems. The researchers also share a growing number of assumptions and hypotheses about the nature of intelligence. <p> It has been well studied empirically not only in ant societies [91] but also in many other biological multi-element systems [10]. It is also well understood theoretically in terms of the more general theory of self-organisation [89]. The phenomenon has been shown in simulation studies <ref> [108] </ref>, [29], [32] and recently on physical robots [14]. The temporary structure in the case of path formation in ant societies is a chemical pheromone gradient deposited in the environment. Ants are attracted to the pheromone and therefore have a tendency to aggregate along the path.
Reference: [109] <author> Steels, L. </author> <title> (1990b) Exploiting Analogical Representations. </title> <editor> In: Maes, P. </editor> <title> (1990) Designing Autonomous Agents: Theory and Practice from Biology to Engineering and Back. </title> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 71-88. </pages>
Reference-contexts: to generate and maintain emergent temporary structures to aid in navigation, for example fluid mechanics so that a fluid flow between the agent's location in an analogical map and the goal location emerges [28], or reaction-diffusion dynamics to generate concentration gradients that can be exploited in navigation or movement control <ref> [109] </ref>. The creation of temporary structures through a self-organising mechanism that combines build-up, break-down, and feedback giving rise to autocatalysis, has been used also for other aspects of intelligent behavior.
Reference: [110] <author> Steels, L. </author> <title> (1991) Emergent frame recognition and its use in artificial creatures. </title> <booktitle> Proceedings of the 10th IJCAI. </booktitle> <publisher> Morgan Kaufmann, Pub. </publisher> <address> San Mateo. </address>
Reference-contexts: When flexion executes it will establish conditions that make `place motion' executable, and so on. Another example of the creation of temporary emergent structures for a frame recognition system is reported in <ref> [110] </ref>. Each frame has a particular strength which corresponds to the applicability of the frame in a particular situation.
Reference: [111] <author> Steels, L. </author> <title> (1991b) Towards a theory of emergent functionality. </title> <editor> In: Meyer, J-A., and S.W. </editor> <booktitle> Wilson (1991) From Animals to Animats. Proceedings of the First International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/ Bradford Books. </publisher> <address> Cambridge Ma. p. p. </address> <pages> 451-461. 83 </pages>
Reference-contexts: It is also the research theme that has the most connections to other areas of Artificial Life. 35 4.1 Emergence can be defined in terms of the need for new descriptive categories. Many researchers in the Alife community have attempted to define emergence (see for example [36], [59], [24], <ref> [111] </ref>, [8]). For the present purposes, we will define emergence from two viewpoints: that of the observer and that of the components of the system. From the viewpoint of an observer, we call a sequence of events a behavior if a certain regularity becomes apparent. <p> Moreover it is not necessary that the two descriptions (the emergent behavior and the behavior of the individual components) are at different levels, although that is not excluded. Emergence can also be defined from the viewpoint of the components implicated 36 in the emergent behavior <ref> [111] </ref>. We can make a distinction between controlled and uncontrolled variables. A controlled variable can be directly influenced by a system. For example, a robot can directly control its forward speed, although maybe not with full accuracy.
Reference: [112] <editor> Steels, L. and R. Brooks (eds.) </editor> <booktitle> (1993) The `artificial life' route to `artificial intelligence'. Building situated embodied agents. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <address> New Haven. </address>
Reference-contexts: Recently, a subgroup within the AI community has started to stress embodied intelligence and made strong alliances with biology and research on artificial life [59]. This is opening up an `artificial life route to artificial intelligence' <ref> [112] </ref>, which has been characterised as Bottom-Up AI [19], the Animat approach [133], Behavior-based AI [108], or Animal Robotics [75]. These terms identify a loose network of engineers and biologists who share the common goal of understanding intelligent behavior through the construction of artificial systems. <p> There are also occasional contributions to international conferences on AI (such as IJCAI, AAAI, or ECAI), neural networks (NIPS), or robotics (IEEE). Reports of some milestone workshops have been published ([65], [123], <ref> [112] </ref>, [113]). Section 2 of the paper delineates the artificial life approach to artificial intelligence. Section 3 identifies the fundamental units of this approach, which are behavior systems.
Reference: [113] <editor> Steels, L. (ed.) </editor> <booktitle> (1993) The Biology and Technology of Intelligent Autonomous Agents. NATO ASI Series. </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin. </address>
Reference-contexts: There are also occasional contributions to international conferences on AI (such as IJCAI, AAAI, or ECAI), neural networks (NIPS), or robotics (IEEE). Reports of some milestone workshops have been published ([65], [123], [112], <ref> [113] </ref>). Section 2 of the paper delineates the artificial life approach to artificial intelligence. Section 3 identifies the fundamental units of this approach, which are behavior systems.
Reference: [114] <author> Steels, L. </author> <title> (1993b) Building Agents with Autonomous Behavior Systems. </title> <editor> In: Steels, L. and R. Brooks (eds.) </editor> <booktitle> (1993) The `artificial life' route to `artificial intelligence'. Building situated embodied agents. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <address> New Haven. </address>
Reference-contexts: Dynamics approaches. Yet another approach is based on the hypothesis that behavior systems should be viewed as continuous dynamical systems instead of discrete computational systems as in the algorithmic approach. This dynamics approach has been put forward by a number of researchers (see e.g. [107], <ref> [114] </ref>). It is more in line with standard control theory, which is also based on dynamical systems [42]. Artificial neural networks are a special case of dynamical systems and can therefore be incorporated easily in this paradigm. An example of a worked out dynamics architecture is described in [114]. <p> e.g. [107], <ref> [114] </ref>). It is more in line with standard control theory, which is also based on dynamical systems [42]. Artificial neural networks are a special case of dynamical systems and can therefore be incorporated easily in this paradigm. An example of a worked out dynamics architecture is described in [114]. It supports the formulation of processes and their combination in the design of complete behavior systems. Each process establishes a continuous relationship between a set of quantities. The quantities are either sensory signals, action parameters, or internal states. A process is always active.
Reference: [115] <author> Suchman, L. </author> <title> (1987) Plans and Situated Action. The problem of human machine interaction. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge UK. </address>
Reference-contexts: This tendency to search for simple mechanisms is particularly strong in the dislike of complex `objective' world models [22]. The de-emphasis of complex representations is shared by researchers criticising cognitivism [125], and is related to the trend for situated cognition <ref> [115] </ref>, which hypothesises that intelligence is the result of simple situation-specific agent/environment mechanisms that are strongly adapted to moment-to-moment decision making. Some biologists have called this the TODO principle: do whatever there is to do at a particular moment, instead of making complex representations and following elaborated plans [47].
Reference: [116] <author> Sutton, </author> <title> R.S. (1988) Learning to Predict by the Methods of Temporal Differences. </title> <journal> Machine Learning, </journal> <volume> vol 3, </volume> <month> p.9-44. </month>
Reference: [117] <author> Sutton, </author> <title> R.S. (1991) Reinforcement Learning Architectures for Animats. </title> <editor> In: Meyer, J-A., and S.W. </editor> <booktitle> Wilson (1991) From Animals to Animats. Proceedings of the First International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books. </publisher> <address> Cambridge Ma. p. </address> <pages> 288-296. </pages>
Reference: [118] <author> Sutton, </author> <title> R.S. </title> <journal> (1992) Special Issue on Reinforcement learning. Machine Learning, </journal> <volume> vol 8, </volume> <pages> p. 3-4. 84 </pages>
Reference-contexts: These difficulties explain why no one has as yet been able to convincingly use supervised learning methods on autonomous physical robots. Another major neural network mechanism is known as reinforcement learning <ref> [118] </ref>. Reinforcement learning methods increase (and decrease) the probability that a particular association between sensing and acting will be used, based on a reward or reinforcement signal. The reinforcement signal is produced as a direct or indirect consequence of the use of the association. <p> More recent mechanisms go in the direction of having the agent develop a more sophisticated representation of the result of an action. For example, a prediction of reward is introduced, or a prediction of (long-term) cumulative reward, i.e. return <ref> [118] </ref>. A technique useful for learning temporal chains is to hand out reinforcement to the last action and from there back to previous associations which played a role. This technique is known as the bucket brigade algorithm and 51 originally due to [46]. <p> The third difficulty is the credit assignment problem. Proposed solutions all go in the direction of new complexity (in the form of models of return, or in more recent cases world models predicting return <ref> [118] </ref>, [61]). Often many simplifying assumptions are made about the nature of sensory interpretations or actions. For example, most methods assume that it is possible to select each time the `best' action.
Reference: [119] <author> Todd, P.M. and S. </author> <title> Wilson (1993) Environment Structure and Adaptive Be--havior From the Ground up. </title> <editor> In: Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wil-son (1993) From Animals to Animats2. Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 11-20. </pages>
Reference-contexts: Several researchers have proposed a state-space approach for defining the dynamics of the observed behavior and the internal operation of the agent (e.g., [77], [54], [37], <ref> [119] </ref>). Once a state-space description is available, the concepts of dynamical systems theory (attractors, transients, recurrent trajectories, etc.) [1] can be used to characterise qualitatively and quantitatively behaviors and internal structures like perceptions, representations, and actions.
Reference: [120] <author> Toffoli, T. and N. </author> <title> Margolus (1977) Cellular Automata Machines. </title> <publisher> MIT Press, </publisher> <address> Cambridge Ma. </address>
Reference-contexts: A collection of processes can be described in 30 terms of a set of differential equations. Because of the implementation on digital computers, the differential equations are turned into difference equations which can be directly implemented, similar to the way cellular automata are discretised versions of continuous systems <ref> [120] </ref>. Each process partially determines the change to a quantity enacted at the next time step, as a function of current values of the same or other quantities. At each computation cycle, all the changes are summed and the values of all the quantities take on their new values.
Reference: [121] <author> Tyrrell, T. </author> <title> (1993) The Use of Hierarchies for Action Selection. </title> <editor> In: Meyer, J-A., H.L. Roitblatt, and S.W. </editor> <booktitle> Wilson (1993) From Animals to Animats2. Proceedings of the Second International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/Bradford Books. </publisher> <address> Cambridge Ma. p.138-147. </address>
Reference: [122] <author> Ullman, S. </author> <title> (1984) Visual routines. </title> <journal> Cognition, </journal> <volume> vol 18, </volume> <pages> p. 97-159. </pages>
Reference-contexts: For example, although in general edge detection is complex and computationally intensive, a simple algorithm based on a gradient threshold will do, if the edges are strong and straight. This work goes in the direction of the theory of visual routines <ref> [122] </ref>, which has abandoned the idea that there is a general purpose vision system and proposes instead a large collection of special purpose mechanisms which can be exploited in particular behavior systems.
Reference: [123] <author> Van de Velde, W. </author> <title> (1992) Learning Robots. </title> <publisher> MIT Press/ Bradford books, </publisher> <address> Cambridge Ma. </address>
Reference-contexts: There are also occasional contributions to international conferences on AI (such as IJCAI, AAAI, or ECAI), neural networks (NIPS), or robotics (IEEE). Reports of some milestone workshops have been published ([65], <ref> [123] </ref>, [112], [113]). Section 2 of the paper delineates the artificial life approach to artificial intelligence. Section 3 identifies the fundamental units of this approach, which are behavior systems.
Reference: [124] <editor> Varela, F.J. and P. Bourgine (eds.) </editor> <booktitle> (1992) Toward a Practice of Autonomous Systems. Proceedings of the First European Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. </address>
Reference-contexts: Good sources for tracking the field are the conferences on the Simulation of Adaptive Behavior ([80], [79]) and the associated journal [102], the conferences on Artificial Life ([59], [60], <ref> [124] </ref>, [30]), and the associated journal [4]. There are also occasional contributions to international conferences on AI (such as IJCAI, AAAI, or ECAI), neural networks (NIPS), or robotics (IEEE). Reports of some milestone workshops have been published ([65], [123], [112], [113]). <p> The `classical' AI approach defines intelligence in terms of knowledge: A system is intelligent if it maximally applies the knowledge that it has (cf. Newell's principle of rationality [87]). The behavior-oriented approach defines intelligence in terms of observed behavior and self-preservation (or autonomy) (see e.g. <ref> [124] </ref>, [76]).
Reference: [125] <author> Varela, F.J., E. Thompson and E. </author> <title> Rosch (1992) Embodied Mind. </title> <publisher> MIT Press, </publisher> <address> Cambridge Ma. </address> <month> 85 </month>
Reference-contexts: This tendency to search for simple mechanisms is particularly strong in the dislike of complex `objective' world models [22]. The de-emphasis of complex representations is shared by researchers criticising cognitivism <ref> [125] </ref>, and is related to the trend for situated cognition [115], which hypothesises that intelligence is the result of simple situation-specific agent/environment mechanisms that are strongly adapted to moment-to-moment decision making.
Reference: [126] <author> Verschure, P., B. Krose, and R. </author> <title> Pfeifer (1992) Distributed Adaptive Control: The Self-organization of Structured Behavior. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> vol 9, </volume> <pages> p. 181-196. </pages>
Reference: [127] <author> Vogel, F. </author> <title> (1989) How Life Learned to Live. </title> <publisher> MIT Press, </publisher> <address> Cambridge Ma. </address>
Reference-contexts: Many more biological examples how physics may `solve' problems, so that additional processing can be minimised, can be found in [3] and <ref> [127] </ref>. Guideline 3: Do not think of sensing and acting in terms of symbol processing. The classical AI approach has been criticised because the symbols and symbol structures on which planning and decision making are based are not grounded in the real world [43].
Reference: [128] <author> Walter, </author> <title> W.G. (1950) An imitation of life. </title> <publisher> Scientific American, </publisher> <address> p. </address> <pages> 42-45. </pages>
Reference-contexts: Another approach would be to review the large amount of work on building technical hardware and software platforms which now make it possible to execute experiments easily and at low cost [35], [31], [50]. This technical work is in some way a revival of earlier cybernetics work by Walter <ref> [128] </ref> and Braitenberg [18] but now with better hardware and more advanced software.
Reference: [129] <author> Webb, B. </author> <title> (1993) Modeling Biological Behaviour or `Dumb Animals and Stupid Robots'. In: Deneubourg, J-L, et.al. (1993) Self-organisation and life: from simple rules to global complexity. </title> <booktitle> Proceedings of the Second Eu-ropean Conference on Artificial Life. </booktitle> <address> ULB, Brussels. p. </address> <pages> 1090-1103. </pages>
Reference-contexts: A review of the field can be organised along several lines. One way would be to look at the progress towards the achievement of specific competences, for example, the different approaches for `navigation towards a target': using potential fields [7], cognitive maps with landmarks [70], phonotaxis <ref> [129] </ref>, global reference frames [86], pheromone trails or agent chains [41], and so on. Another approach would be to review the large amount of work on building technical hardware and software platforms which now make it possible to execute experiments easily and at low cost [35], [31], [50]. <p> A robot may be equiped with bumpers which cause a (sudden) slow down and an immediate retraction in a random direction. This may get the robot out of situations which appear to be dead end situations in simulations. Another good illustration of this design principle can be found in <ref> [129] </ref>. She has developed a model in the form of an artificial system for navigation based on the phonotaxis behavior of crickets.
Reference: [130] <author> Webb, B. and T. </author> <title> Smithers (1992) The Connection between AI and Biology in the Study of Behaviour. </title> <editor> In: Varela, F.J. and P. Bourgine (eds.) </editor> <booktitle> (1992) Toward a Practice of Autonomous Systems. Proceedings of the First Euro-pean Conference on Artificial Life. </booktitle> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge Ma. p. </address> <pages> 421-428. </pages>
Reference-contexts: This makes the construction of robotic agents that must sense the environment and can physically act upon the environment, unavoidable. Particularly if sensori-motor competences are studied. This is why behavior-oriented AI researchers insist so strongly on the construction of physical agents [21], <ref> [130] </ref>. 6 Performing simulations of agents (as in [15]) is of course an extremely valuable aid in exploring and testing out certain mechanisms, the way simulation is heavily used in the design of airplanes.
Reference: [131] <author> Weisbuch, G. </author> <title> (1991) Complex Systems Dynamics. An Introduction to Automata Networks. </title> <booktitle> Lecture Notes Volume II. Santa Fe Institute Studies in the Sciences of Complexity. </booktitle> <publisher> Addison-Wesley Pub. </publisher> <address> Cy. Reading Ma. </address>
Reference: [132] <author> Widrow, B., N. Gupta and S. </author> <month> Maitra </month> <year> (1973) </year> <month> Punish/reward: </month> <title> Learning with a critic in adaptive threshold systems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics. </journal> <volume> 5, </volume> <pages> p. 455-465. 86 </pages>
Reference: [133] <author> Wilson, </author> <title> S.W. (1991) The Animat Path to AI. </title> <editor> In: Meyer, J-A., and S.W. </editor> <booktitle> Wilson (1991) From Animals to Animats. Proceedings of the First International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press/ Bradford Books. </publisher> <address> Cambridge Ma. p. </address> <pages> 15-22. 87 </pages>
Reference-contexts: Recently, a subgroup within the AI community has started to stress embodied intelligence and made strong alliances with biology and research on artificial life [59]. This is opening up an `artificial life route to artificial intelligence' [112], which has been characterised as Bottom-Up AI [19], the Animat approach <ref> [133] </ref>, Behavior-based AI [108], or Animal Robotics [75]. These terms identify a loose network of engineers and biologists who share the common goal of understanding intelligent behavior through the construction of artificial systems. The researchers also share a growing number of assumptions and hypotheses about the nature of intelligence.
References-found: 134

