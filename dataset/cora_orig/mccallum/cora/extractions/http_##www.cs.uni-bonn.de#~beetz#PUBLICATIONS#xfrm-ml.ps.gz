URL: http://www.cs.uni-bonn.de/~beetz/PUBLICATIONS/xfrm-ml.ps.gz
Refering-URL: http://www.cs.uni-bonn.de/~beetz/publications.html
Root-URL: http://cs.uni-bonn.de
Email: beetz@cs.uni-bonn.de  mcdermott@cs.yale.edu  
Phone: 2  
Title: Expressing Transformations of Structured Reactive Plans  
Author: Michael Beetz and Drew McDermott 
Address: Roemerstr. 164, D-53117 Bonn, Germany,  P.O. Box 208285, Yale Station, New Haven, CT 06520-8285, USA,  
Affiliation: 1 University of Bonn, Dept. of Computer Science III,  Yale University, Dept. of Computer Science,  
Abstract: We describe xfrml, the transformation language of the planning system xfrm. xfrm is embedded in a simulated robot that performs jobs in a changing and partly unknown environment. xfrml allows xfrm to anticipate and forestall many common flaws in autonomous robot behavior that cannot be dealt with by other planning representations. In order to diagnose execution failures in projected execution scenarios, xfrm has to infer whether or not particular parts of the plan were projected to be executed and why. The use of xfrml makes such inferences possible because xfrml not only represents the physical effects of plan execution, but also the process of plan interpretation, as well as temporal, causal, and teleological relationships among plan interpretation, the world, and the physical behavior of the robot. 
Abstract-found: 1
Intro-found: 1
Reference: [AHT90] <editor> J. Allen, J. Hendler, and A. Tate, editors. </editor> <booktitle> Readings in Planning. </booktitle> <publisher> Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: The last condition tests the existence of a variable in the srp that has a description of the object OB as its value. Most planning systems use representations that are simpler than xfrml. They either reason about how the world changes while the plan gets executed <ref> [AHT90] </ref> or about the process of plan interpretation [Dav92, McD85]. In the first case, the planning systems have to assume that the critical decisions about the course of actions are made during planning because they cannot represent and rationalize decisions made during plan execution.
Reference: [Bee96] <author> M. Beetz. </author> <title> Anticipating and Forestalling Execution Failures in Structured Reactive Plans. </title> <type> Technical report, </type> <institution> Yale University, </institution> <year> 1996. </year>
Reference-contexts: that the robot has a faulty or ambiguous object description, that the object changed its appearance without the robot noticing, and so on. xfrml can express all the common-sense plan revisions listed in section 3; we formalized many more types of flaws and common-sense revision methods for avoiding them in <ref> [Bee96, BM94] </ref>. We can also express planning operations performed by classical planning systems such as means-end analysis [NS61] or the operations of the snlp planning algorithm can [MR91]. We have implemented models for about twenty five types of behavior flaws and about forty transformation rules. <p> Finally, we have conducted experiments in a simulated changing world using a simulated robot with limited and noisy sensing and imperfect control <ref> [Bee96] </ref>. These experiments have shown that controllers that forestall flaws in robot behavior using xfrml are in situations that do not require foresight as efficient as fixed robot controllers and in situations that require foresight more reliable.
Reference: [BM92] <author> M. Beetz and D. McDermott. </author> <title> Declarative goals in reactive plans. </title> <editor> In J. Hendler, editor, </editor> <booktitle> AIPS-92, </booktitle> <pages> pages 3-12, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: To support this kind of reasoning, rpl provides declarative commands for goals, perceptions, and beliefs that can be used to make the structure of srps and the functions of subplans explicit and thereby provide xfrm with a (partial) model of its plan <ref> [BM92] </ref>. 4 Plan Revision Rules While revising srps is more difficult than revising partial-order plans it also enables planners to forestall additional types of plan failures. Let's illustrate this by looking at some of xfrm's plan revision rules that are implemented in xfrml and performed on srps: 1. <p> Teleological Relations. The purpose of many subplans can be described in terms of the world states they are intended to achieve, maintain, or perceive. In rpl, the tasks of these subplans are annotated with declarative commands such as (ACHIEVE (LOC des h0,10i)) (see <ref> [BM92] </ref>) which are viewed by the planner as annotations that indicate the purpose of a task/subplan and can be queried in xfrml using the (TASK-GOAL t g) predicate.
Reference: [BM94] <author> M. Beetz and D. McDermott. </author> <title> Improving robot plans during their execution. </title> <editor> In Kris Hammond, editor, </editor> <booktitle> AIPS-94, </booktitle> <pages> pages 3-12, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: that the robot has a faulty or ambiguous object description, that the object changed its appearance without the robot noticing, and so on. xfrml can express all the common-sense plan revisions listed in section 3; we formalized many more types of flaws and common-sense revision methods for avoiding them in <ref> [Bee96, BM94] </ref>. We can also express planning operations performed by classical planning systems such as means-end analysis [NS61] or the operations of the snlp planning algorithm can [MR91]. We have implemented models for about twenty five types of behavior flaws and about forty transformation rules.
Reference: [Dav92] <author> E. Davis. </author> <title> Semantics for tasks that can be interrupted or abandoned. </title> <editor> In J. Hendler, editor, </editor> <booktitle> AIPS-92, </booktitle> <pages> pages 37-44, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: Most planning systems use representations that are simpler than xfrml. They either reason about how the world changes while the plan gets executed [AHT90] or about the process of plan interpretation <ref> [Dav92, McD85] </ref>. In the first case, the planning systems have to assume that the critical decisions about the course of actions are made during planning because they cannot represent and rationalize decisions made during plan execution.
Reference: [Fir89] <author> J. Firby. </author> <title> Adaptive Execution in Complex Dynamic Worlds. </title> <type> Technical report 672, </type> <institution> Yale University, Department of Computer Science, </institution> <year> 1989. </year>
Reference-contexts: Plans can explicitly fail if they detect situations they cannot handle. rpl provides several high-level concepts (interrupts, monitors) to synchronize parallel actions, to make plans reactive, etc. Other reactive plan languages such as RAP <ref> [Fir89] </ref> or ESL [Gat96] are easily provided as macro languages on top of rpl. [McD91] (pg. 20), for instance, shows a straightforward implementation of RAP using rpl control structures. One might argue in favor of simpler, more uniform plan representations, which are better suited for plan synthesis and learning. <p> Autonomous robots acting in changing and partly unknown environments need a notation for plan revision methods because such robots exhibit many kinds of behavior flaws that cannot be prevented by existing plan revision methods. xfrml can be also applied to other reactive plan languages such as RAP <ref> [Fir89] </ref> and ESL [Gat96]. The easiest way to do this is to define the constructs provided by these languages as rpl macros and then use xfrm's tools for projecting reactive plans and representing code trees. You might have the impression that xfrml makes simple plan revisions complicated.
Reference: [Gat96] <author> E. Gat. Esl: </author> <title> A language for supporting robust plan execution in embedded autonomous agents. </title> <booktitle> In AAAI Fall Symposium: Issues in Plan Execution, </booktitle> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: Plans can explicitly fail if they detect situations they cannot handle. rpl provides several high-level concepts (interrupts, monitors) to synchronize parallel actions, to make plans reactive, etc. Other reactive plan languages such as RAP [Fir89] or ESL <ref> [Gat96] </ref> are easily provided as macro languages on top of rpl. [McD91] (pg. 20), for instance, shows a straightforward implementation of RAP using rpl control structures. One might argue in favor of simpler, more uniform plan representations, which are better suited for plan synthesis and learning. <p> Autonomous robots acting in changing and partly unknown environments need a notation for plan revision methods because such robots exhibit many kinds of behavior flaws that cannot be prevented by existing plan revision methods. xfrml can be also applied to other reactive plan languages such as RAP [Fir89] and ESL <ref> [Gat96] </ref>. The easiest way to do this is to define the constructs provided by these languages as rpl macros and then use xfrm's tools for projecting reactive plans and representing code trees. You might have the impression that xfrml makes simple plan revisions complicated.
Reference: [Ham89] <author> K. Hammond. </author> <title> Case-Based Planning. </title> <publisher> Academic Press, Inc., </publisher> <year> 1989. </year>
Reference-contexts: We have implemented models for about twenty five types of behavior flaws and about forty transformation rules. Most of which cannot be expressed in other planning representations. xfrml can easily express the rules used by other transformational planners, such as those described in <ref> [Sus77, Ham89] </ref>. To implement gordius-like plan transformations, xfrm's projector would have to construct a dependency structure that justifies the executability of plan steps and their effects.
Reference: [McD85] <author> D. McDermott. </author> <title> Reasoning about plans. </title> <editor> In J. R. Hobbs and R. C. Moore, editors, </editor> <booktitle> Formal Theories of the Commonsense World, </booktitle> <pages> pages 269-317. </pages> <publisher> Ablex, </publisher> <address> Norwood, NJ, </address> <year> 1985. </year>
Reference-contexts: Most planning systems use representations that are simpler than xfrml. They either reason about how the world changes while the plan gets executed [AHT90] or about the process of plan interpretation <ref> [Dav92, McD85] </ref>. In the first case, the planning systems have to assume that the critical decisions about the course of actions are made during planning because they cannot represent and rationalize decisions made during plan execution.
Reference: [McD91] <author> D. McDermott. </author> <title> A reactive plan language. </title> <institution> Research Report YALEU/DCS/RR-864, Yale University, </institution> <year> 1991. </year>
Reference-contexts: If a marked ball is missing the robot looks for it at a neighbor location. 3 Structured Reactive Plans (SRPs) xfrml reasons about structured reactive plans (SRPs) written in rpl (Reactive Plan Language) <ref> [McD91] </ref>, a Lisp-like robot control language with conditionals, loops, local variables, processes, and subroutines. Plans can explicitly fail if they detect situations they cannot handle. rpl provides several high-level concepts (interrupts, monitors) to synchronize parallel actions, to make plans reactive, etc. <p> Plans can explicitly fail if they detect situations they cannot handle. rpl provides several high-level concepts (interrupts, monitors) to synchronize parallel actions, to make plans reactive, etc. Other reactive plan languages such as RAP [Fir89] or ESL [Gat96] are easily provided as macro languages on top of rpl. <ref> [McD91] </ref> (pg. 20), for instance, shows a straightforward implementation of RAP using rpl control structures. One might argue in favor of simpler, more uniform plan representations, which are better suited for plan synthesis and learning.
Reference: [McD92] <author> D. McDermott. </author> <title> Transformational planning of reactive behavior. </title> <institution> Research Report YALEU/DCS/RR-941, Yale University, </institution> <year> 1992. </year>
Reference-contexts: In a complex, structured plan, it is a complex editing operation that must respect the semantics of the plan language. In the past such trans-formations were represented as Lisp procedures, but the resulting codes were unintelligible and error-prone <ref> [McD92] </ref>. This paper describes xfrml (xfrm Plan Revision Language), a declarative notation for implementing general, common-sense plan revision methods. <p> Therefore, in an execution scenario, the projected plan is represented as a structure, called a code tree, which essentially duplicates the structure of the plan text, augmented with some further syntactic information. (For details, see <ref> [McD92] </ref>.) xfrm handles uncertainty implicitly: it randomly projects execution scenario from the given evidences and probabilistic action and exogenous event models and prior information. xfrm estimates the utility of a plan by taking the average utility over the projected scenarios and estimates the probability of a particular behavior flaw based on <p> the plan variable var and var has the value val at the start or end of tsk. 6.3 Predicates on Timelines The purpose of plans is to change the world. xfrm represents how the world changes during the execution of a plan in terms of time instants, occasions, and events <ref> [McD92] </ref>. Time instants are points in time at which the world changes due to an action or an exogenous event.
Reference: [MR91] <author> D. McAllester and D. Rosenblitt. </author> <title> Systematic nonlinear planning. </title> <booktitle> In Proc. of AAAI-91, </booktitle> <pages> pages 634-639, </pages> <year> 1991. </year>
Reference-contexts: We can also express planning operations performed by classical planning systems such as means-end analysis [NS61] or the operations of the snlp planning algorithm can <ref> [MR91] </ref>. We have implemented models for about twenty five types of behavior flaws and about forty transformation rules. Most of which cannot be expressed in other planning representations. xfrml can easily express the rules used by other transformational planners, such as those described in [Sus77, Ham89].
Reference: [NS61] <author> A. Newell and H. Simon. </author> <title> GPS, a program that simulates human thought. </title> <editor> In Heinz Billing, editor, </editor> <booktitle> Lernende Automaten, </booktitle> <pages> pages 109-124. </pages> <editor> R. </editor> <publisher> Oldenbourg, </publisher> <address> Munich, Germany, </address> <year> 1961. </year>
Reference-contexts: We can also express planning operations performed by classical planning systems such as means-end analysis <ref> [NS61] </ref> or the operations of the snlp planning algorithm can [MR91]. We have implemented models for about twenty five types of behavior flaws and about forty transformation rules.
Reference: [RK86] <author> S. Rosenschein and L. Kaelbling. </author> <title> The synthesis of digital machines with provable epistemic properties. </title> <booktitle> In Proc. of the 1986 Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 83-98, </pages> <address> Monterey, CA, </address> <year> 1986. </year>
Reference-contexts: In this case we say that at any time the robot believes it is at location hX,Yi if in this state, the value of X-POS* is X and the value of Y-POS* is Y. (see <ref> [RK86] </ref>) We take the relation (BELIEF-AT state ti) to mean that the robot believes that state holds in the world. The programmer has to provide axioms that define under which conditions the robot believes in state | usually in terms of constraints that the values of global variables must satisfy.
Reference: [Sim92] <author> R. Simmons. </author> <title> The roles of associational and causal reasoning in problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 53 </volume> <pages> 159-207, </pages> <year> 1992. </year>
Reference: [Sus77] <author> G. Sussman. </author> <title> A Computer Model of Skill Acquisition, </title> <booktitle> volume 1 of Aritficial Intelligence Series. </booktitle> <publisher> American Elsevier, </publisher> <address> New York, NY, </address> <year> 1977. </year>
Reference-contexts: Over and above the difficult substantive issues about what plan transformations should be carried out, we must deal with formal issues about how to specify the transformations. For example, the "protection-violation avoidance" transformation <ref> [Sus77] </ref> is, in the classical framework, a matter of inserting a link. In a complex, structured plan, it is a complex editing operation that must respect the semantics of the plan language. <p> We have implemented models for about twenty five types of behavior flaws and about forty transformation rules. Most of which cannot be expressed in other planning representations. xfrml can easily express the rules used by other transformational planners, such as those described in <ref> [Sus77, Ham89] </ref>. To implement gordius-like plan transformations, xfrm's projector would have to construct a dependency structure that justifies the executability of plan steps and their effects.
References-found: 16

