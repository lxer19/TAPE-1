URL: ftp://iamftp.unibe.ch/pub/TechReports/1996/iam-96-016.ps.gz
Refering-URL: 
Root-URL: 
Title: Robust Edge Detection in Range Images Based on Scan Line Approximation  
Author: Xiaoyi Jiang, Horst Bunke 
Keyword: CR Categories and Subject Descriptors: I.4.6 [Segmentation]: edge and feature detection, pixel classification; I.4.8 [Scene Analysis]: range data. General Terms: Algorithms. Additional Key Words: edge detection, scan line approximation, optimality analysis.  
Address: Bern, Switzerland  
Affiliation: Institut fur Informatik und angewandte Mathemathik Universitat  
Abstract: In this paper we present a novel edge detection algorithm for range images based on a scan line approximation technique. Compared to the known methods in the literature, our algorithm has a number of advantages. It provides edge strength measures that have a straightforward geometric interpretation and supports a classification of edge points into several subtypes. We give a definition of optimal edge detectors and compare our algorithm to this theoretical model. By simulations we show that our algorithm has a near-optimal performance. We have carried out extensive tests using real range images acquired by three range scanners with quite different characteristics. The good results that were achieved demonstrate the robustness of our edge detection algorithm.
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> F. Ade et al., Grasping unknown objects, in H. Bunke et al. (Eds.), </editor> <title> Modelling and Planning for Sensor Based Intelligent Robot Systems, </title> <address> 445-459, </address> <publisher> World Scientific, </publisher> <year> 1995. </year>
Reference-contexts: In the range image domain, vision tasks such as object recognition [3, 11], model construction [15], configuration analysis [25], motion analysis [21, 30], automated visual inspection [26], and robotic grasping operations <ref> [1, 2] </ref> have been build in most cases upon scene representations of surface patches. This has led to the general agreement of defining the range image segmentation task as one of dividing range images into closed regions with application domain specific surface properties [16].
Reference: [2] <author> E. Al-Hujazi, A. Sood, </author> <title> Range image segmentation with applications to robot bin-picking using vacuum gripper, </title> <journal> IEEE. Trans. on SMC, </journal> <volume> 20(6), </volume> <pages> 1313-1325, </pages> <year> 1990. </year>
Reference-contexts: In the range image domain, vision tasks such as object recognition [3, 11], model construction [15], configuration analysis [25], motion analysis [21, 30], automated visual inspection [26], and robotic grasping operations <ref> [1, 2] </ref> have been build in most cases upon scene representations of surface patches. This has led to the general agreement of defining the range image segmentation task as one of dividing range images into closed regions with application domain specific surface properties [16]. <p> Due to the nature of edge-based approaches, the region boundaries tend to be located precisely. The usefulness of edge detection is actually twofold. Edge detection has the potential of a complete segmentation. For this purpose heuristic criteria <ref> [2, 20] </ref> have been shown to be effective to close gaps in edge maps of range images. Alternatively, we can make use of edge detection to support region-based segmentation. An edge map may provide an initial segmentation that is further refined by region-based techniques. <p> strength, 1 This comparison is based on a number of objective performance metrics and two large range image sets acquired by a time-of-flight laser range finder and a structured light scanner, respectively, that have manually specified ground truth. 2 source real images shown scanners (real images evaluated) Al-Hujazi & Sood <ref> [2] </ref> 4 (several) 1 Berkman & Caelli [4] 0 (0) 0 Ghosal & Mehrotra [12] 3 (several) 1 Ghosal & Mehrotra [13] 2 (2) 1 Gunsel et al. [14] 0 (0) 0 Kaveti et al. [20] 6 (MSU) 1 Krishnapuram & Gupta [22] 7 (?) 2 Mintz [24] 2 (2) 1 <p> The works [7, 19] belong to this category of edge detection methods and are based on a morphological edge detector and the Canny operator, respectively. Another approach to edge detection is residual analysis. Al-Hujazi and Sood <ref> [2] </ref> considered the absolute difference (residue) between the input image and its smoothed version, which possesses maxima at the locations of jump and crease edges. Edge detection is done by locating such maxima. <p> Then, the boundary detection was done by maximizing this probability function using the Bayesian approach. In [12, 13] operators based on orthogonal Zernike moments were used to recover the parameters of a general 2-D edge model at each pixel. Similar to <ref> [2] </ref>, this method provides an edge strength that is proportional to jk 1 k 2 j and thus suffers from the same non-uniformity problem. 2 Any edge strength definition that is a monotonic function of (1) corresponds to an optimal edge detector, too.
Reference: [3] <author> F. Arman, J.K. Aggarwal, </author> <title> Model-based object recognition in dense-range images A review, </title> <journal> ACM Computing Surveys, </journal> <volume> 25(1), </volume> <pages> 5-43, </pages> <year> 1993. </year>
Reference-contexts: Thus, a segmentation step is usually carried out to group the range data into high-level features suitable for the subsequent image analysis and interpretation. In the range image domain, vision tasks such as object recognition <ref> [3, 11] </ref>, model construction [15], configuration analysis [25], motion analysis [21, 30], automated visual inspection [26], and robotic grasping operations [1, 2] have been build in most cases upon scene representations of surface patches.
Reference: [4] <author> J. Berkman, T. Caelli, </author> <title> Computation of surface geometry and segmentation using co-variance techniques, </title> <journal> IEEE Trans. on PAMI, </journal> <volume> 16(11), </volume> <pages> 1114-1116, </pages> <year> 1994. </year>
Reference-contexts: a number of objective performance metrics and two large range image sets acquired by a time-of-flight laser range finder and a structured light scanner, respectively, that have manually specified ground truth. 2 source real images shown scanners (real images evaluated) Al-Hujazi & Sood [2] 4 (several) 1 Berkman & Caelli <ref> [4] </ref> 0 (0) 0 Ghosal & Mehrotra [12] 3 (several) 1 Ghosal & Mehrotra [13] 2 (2) 1 Gunsel et al. [14] 0 (0) 0 Kaveti et al. [20] 6 (MSU) 1 Krishnapuram & Gupta [22] 7 (?) 2 Mintz [24] 2 (2) 1 Wani & Batchelor [34] 3 (3) 1 <p> Similar to [2], this method provides an edge strength that is proportional to jk 1 k 2 j and thus suffers from the same non-uniformity problem. 2 Any edge strength definition that is a monotonic function of (1) corresponds to an optimal edge detector, too. Berkman and Caelli <ref> [4] </ref> explored the application of covariance techniques to surface repre-sentation of 3-D objects. It was shown that the covariance approach provides shape descriptors invariant to rigid motions via the eigenvalues of covariance matrices of different orders, without explicitly using surface parameterizations or derivatives as in the case of curvatures.
Reference: [5] <author> P.J. Besl, </author> <title> Active, optical range imaging sensors, </title> <journal> Machine Vision and Applications, </journal> <volume> Vol. 1, </volume> <pages> 127-152, </pages> <year> 1988. </year>
Reference-contexts: Finally, not only theoretical performance characterization but also experimental evaluation is essential to demonstrate the robustness of an edge detection algorithm. Today, a large number of range scanners with different characteristics (working principle, sensor geometry, noise, etc.) are available <ref> [5, 18] </ref>. Therefore, the ease of adaptation to range images acquired by different range sensors should belong to the efforts to characterize the performance of an edge detection method. For example, some algorithms are limited to range images sampled on a regular grid. <p> These three types of range scanners are among the most important active ranging methods <ref> [5, 18] </ref> and thus represent quite well the spectrum of the range scanners available today. The first image source ist the popular image set from the PRIP Lab of Michigan State University and another 38 registered range/intensity image pairs 3 from the same Lab [23].
Reference: [6] <author> P.J. Besl, </author> <title> Surface in range image understanding, </title> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: So, we turn to bivariate polynomials: z = f (x; y) = i+jk To make the scan line approximation as simple as possible, we have chosen k = 2. In <ref> [6] </ref> it has been shown that the implicit surface function (2) can only be approximated well by a 7 (a) (b) bivariate polynomial using k = 4, implying that our use of quadratic bivariate polynomials may produce some oversegmentation of scan lines.
Reference: [7] <author> P. Boulanger, F. Blais, P. Cohen, </author> <title> Detection of depth and orientation discontinuities in range images using morphology, </title> <booktitle> Proc. of 10th Int. Conf. on Pattern Recognition, </booktitle> <volume> Vol. B, </volume> <pages> 729-732, </pages> <year> 1990. </year>
Reference-contexts: For crease edges we can apply the same edge detector independently to the three components of the normals of the imaged surfaces and then combine the results to locate edges, say by taking the maximum of the three channels. The works <ref> [7, 19] </ref> belong to this category of edge detection methods and are based on a morphological edge detector and the Canny operator, respectively. Another approach to edge detection is residual analysis. <p> This non-uniformity is certainly an undesired property. Mathematical morphology is attractive due to the fact that it involves simple logical operations and can be implemented in parallel, thus making real-time application possible. An application of mathematical morphology to edge detection in range images has been described in <ref> [7] </ref>. Cheng and Don [8] proposed another morphological approach to detect convex roof edges only. Such edges are found by looking for the leaf nodes of the skeletal tree of a range image constructed by morphological skeleton operations. Krishnapuram and Gupta [22] have developed two other morphological methods.
Reference: [8] <author> J.-C. Cheng, H.-S.Don, </author> <title> Roof edge detection: A morphological skeleton approach, </title> <editor> in C. Archibald et al. (Eds.), </editor> <booktitle> Advances in Machine Vision: Strategies and Applications, </booktitle> <pages> 171-191, </pages> <publisher> World Scientific, </publisher> <year> 1992. </year> <month> 23 </month>
Reference-contexts: Mathematical morphology is attractive due to the fact that it involves simple logical operations and can be implemented in parallel, thus making real-time application possible. An application of mathematical morphology to edge detection in range images has been described in [7]. Cheng and Don <ref> [8] </ref> proposed another morphological approach to detect convex roof edges only. Such edges are found by looking for the leaf nodes of the skeletal tree of a range image constructed by morphological skeleton operations. Krishnapuram and Gupta [22] have developed two other morphological methods.
Reference: [9] <author> R.O. Duda, P.E. Hart, </author> <title> Pattern Classification and Scene Analysis, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: For quadratic bivariate polynomials we need to partition scan lines into curve segments of the form: z = ax 2 + bx + c: We have used the classical splitting algorithm described by Duda and Hart <ref> [9] </ref>. A quadratic approximation function is first determined for a whole scan line based on the midpoint and the two endpoints.
Reference: [10] <author> J.G. Dunham, </author> <title> Optimum uniform piecewise linear approximation of planar curves, </title> <journal> IEEE Trans. on PAMI, </journal> <volume> 8(1), </volume> <pages> 67-75, </pages> <year> 1986. </year>
Reference-contexts: It is well known that the simple splitting method of Duda and Hart produces sometimes spurious segments. For the problem of piecewise linear approximation of curves, Pavlidis and Horowitz [27] tried to solve this problem by introducing a merge step. As stated in <ref> [10] </ref>, however, this algorithm is computationally rather expensive. For complex curves, it produces sometimes worse results than the simple splitting method. For the partitioning into quadratic curve segments, the usefulness of a merge operation is even more questionable.
Reference: [11] <author> P.J. Flynn, A.K. Jain, </author> <title> Three-dimensional object recognition, in T.Y. </title> <editor> Young (Ed.), </editor> <booktitle> Handbook of Pattern Recognition and Image Processing: Computer Vision, </booktitle> <pages> 497-541, </pages> <publisher> Academic Press, </publisher> <year> 1994. </year>
Reference-contexts: Thus, a segmentation step is usually carried out to group the range data into high-level features suitable for the subsequent image analysis and interpretation. In the range image domain, vision tasks such as object recognition <ref> [3, 11] </ref>, model construction [15], configuration analysis [25], motion analysis [21, 30], automated visual inspection [26], and robotic grasping operations [1, 2] have been build in most cases upon scene representations of surface patches.
Reference: [12] <author> S. Ghosal, R. Mehrotra, </author> <title> Segmentation of range images: An orthogonal moment-based integrated approach, </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> 9(4), </volume> <pages> 385-399, </pages> <year> 1993. </year>
Reference-contexts: two large range image sets acquired by a time-of-flight laser range finder and a structured light scanner, respectively, that have manually specified ground truth. 2 source real images shown scanners (real images evaluated) Al-Hujazi & Sood [2] 4 (several) 1 Berkman & Caelli [4] 0 (0) 0 Ghosal & Mehrotra <ref> [12] </ref> 3 (several) 1 Ghosal & Mehrotra [13] 2 (2) 1 Gunsel et al. [14] 0 (0) 0 Kaveti et al. [20] 6 (MSU) 1 Krishnapuram & Gupta [22] 7 (?) 2 Mintz [24] 2 (2) 1 Wani & Batchelor [34] 3 (3) 1 Table 1: Summary of recent journal-published edge <p> The output of each module was modeled to be dependent on all other outputs by being part of a joint a posteriori probability distribution. Then, the boundary detection was done by maximizing this probability function using the Bayesian approach. In <ref> [12, 13] </ref> operators based on orthogonal Zernike moments were used to recover the parameters of a general 2-D edge model at each pixel.
Reference: [13] <author> S. Ghosal, R. Mehrotra, </author> <title> Detection of composite edges, </title> <journal> IEEE Trans. on Image Processing, </journal> <volume> 3(1), </volume> <pages> 14-22, </pages> <year> 1994. </year>
Reference-contexts: a time-of-flight laser range finder and a structured light scanner, respectively, that have manually specified ground truth. 2 source real images shown scanners (real images evaluated) Al-Hujazi & Sood [2] 4 (several) 1 Berkman & Caelli [4] 0 (0) 0 Ghosal & Mehrotra [12] 3 (several) 1 Ghosal & Mehrotra <ref> [13] </ref> 2 (2) 1 Gunsel et al. [14] 0 (0) 0 Kaveti et al. [20] 6 (MSU) 1 Krishnapuram & Gupta [22] 7 (?) 2 Mintz [24] 2 (2) 1 Wani & Batchelor [34] 3 (3) 1 Table 1: Summary of recent journal-published edge detection algorithms for range images. "Real images <p> The output of each module was modeled to be dependent on all other outputs by being part of a joint a posteriori probability distribution. Then, the boundary detection was done by maximizing this probability function using the Bayesian approach. In <ref> [12, 13] </ref> operators based on orthogonal Zernike moments were used to recover the parameters of a general 2-D edge model at each pixel.
Reference: [14] <author> B. Gunsel, A.K. Jain, E. Panayirci, </author> <title> Reconstruction and boundary detection of range and intensity images using multiscale MRF representations, </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <volume> 63(2), </volume> <pages> 353-366, </pages> <year> 1996. </year>
Reference-contexts: structured light scanner, respectively, that have manually specified ground truth. 2 source real images shown scanners (real images evaluated) Al-Hujazi & Sood [2] 4 (several) 1 Berkman & Caelli [4] 0 (0) 0 Ghosal & Mehrotra [12] 3 (several) 1 Ghosal & Mehrotra [13] 2 (2) 1 Gunsel et al. <ref> [14] </ref> 0 (0) 0 Kaveti et al. [20] 6 (MSU) 1 Krishnapuram & Gupta [22] 7 (?) 2 Mintz [24] 2 (2) 1 Wani & Batchelor [34] 3 (3) 1 Table 1: Summary of recent journal-published edge detection algorithms for range images. "Real images shown" is counted from figures in the <p> However, these two methods don't provide a quantitative characterization of edge strengths. Multiscale boundary detection has proven to be effective for dealing with discontinuities occurring at a variety of spatial scales. Gunsel et al. <ref> [14] </ref> followed this approach by considering the boundary detection process as a fusion of n different sensory processing modules, each corresponding to a specific scale. The output of each module was modeled to be dependent on all other outputs by being part of a joint a posteriori probability distribution.
Reference: [15] <author> K.K. Gupta, X.M. Zhu, </author> <title> Extracting polyhedral models from a range image: A hybrid approach, </title> <type> Technical report CSS-IS-TR 91-10, </type> <institution> Centre for System Science, Simon Fraser University, </institution> <year> 1991. </year>
Reference-contexts: Thus, a segmentation step is usually carried out to group the range data into high-level features suitable for the subsequent image analysis and interpretation. In the range image domain, vision tasks such as object recognition [3, 11], model construction <ref> [15] </ref>, configuration analysis [25], motion analysis [21, 30], automated visual inspection [26], and robotic grasping operations [1, 2] have been build in most cases upon scene representations of surface patches.
Reference: [16] <author> A. Hoover et al., </author> <title> An experimental comparison of range image segmentation algorithms, </title> <journal> IEEE Trans. on PAMI, </journal> <volume> 18(7), </volume> <pages> 673-689, </pages> <year> 1996. </year>
Reference-contexts: This has led to the general agreement of defining the range image segmentation task as one of dividing range images into closed regions with application domain specific surface properties <ref> [16] </ref>. Range image segmentation algorithms can be broadly classified into two categories: edge-based and region-based segmentation. Region-based approaches group pixels into connected regions based on homogeneity measures, while boundaries between regions are located by edge detection methods. Both techniques have their strengths and drawbacks. <p> In clustering-based methods it is difficult to adaptively determine the actual number of clusters in range images. Often, an oversegmentation is achieved and a subsequent merge step is needed to provide the final segmentation. As a matter of fact, a recent experimental comparison 1 <ref> [16] </ref> reveals that even the seemingly simple task of segmenting range images into planar surface patches cannot be regarded as solved. There is still considerable room for improvement with respect to both segmentation quality and computation time. <p> The images of polyhedral objects only can also be downloaded from http://marathon.csee.usf.edu/range/seg comp/SegComp.html. 5 Available from http://marathon.csee.usf.edu/range/seg-comp/SegComp.html. 6 Forty images of the ABW image set and the entire Perceptron image set constitute the test data in a recent experimental comparison of region-based range image segmentation algorithms <ref> [16] </ref>. 14 (a) (b) (e) (f) text). 15 (g) (h) (k) (l) (see text). 16 (m) (n) (see text). 17 18 images and 120 for the other two image sets, corresponding to 20 o and 30 o , respectively, in the case of crease edges.
Reference: [17] <author> B.K.P. Horn, </author> <title> Robot Vision, </title> <publisher> The MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: For this representation we need a uniform tessellation of the unit sphere so that only a finite number of surface normals have to be dealt with. In our simulations we apply a tessellation method based on the well-known geodesic dome constructions <ref> [17] </ref>. Starting with a regular icosahedron, each of its edges is divided into f equal sections, where f is called the frequency of the geodesic division. This results in f 2 triangles for each face and totally 20f 2 triangles.
Reference: [18] <author> R.A. Jarvis, </author> <title> Range sensing for computer vision, in A.K. </title> <editor> Jain, P.J. Flynn (Eds.), </editor> <title> Three-dimensional object recognition systems, </title> <address> 17-56, </address> <publisher> Elsevier Science Publishers, </publisher> <year> 1993. </year>
Reference-contexts: Finally, not only theoretical performance characterization but also experimental evaluation is essential to demonstrate the robustness of an edge detection algorithm. Today, a large number of range scanners with different characteristics (working principle, sensor geometry, noise, etc.) are available <ref> [5, 18] </ref>. Therefore, the ease of adaptation to range images acquired by different range sensors should belong to the efforts to characterize the performance of an edge detection method. For example, some algorithms are limited to range images sampled on a regular grid. <p> These three types of range scanners are among the most important active ranging methods <ref> [5, 18] </ref> and thus represent quite well the spectrum of the range scanners available today. The first image source ist the popular image set from the PRIP Lab of Michigan State University and another 38 registered range/intensity image pairs 3 from the same Lab [23].
Reference: [19] <author> X.Y. Jiang et al., </author> <title> A methodology for evaluating edge detection techniques for range images, </title> <booktitle> Proc. of 2nd Asian Conf. on Computer Vision, Singapore, Vol.II, </booktitle> <pages> 415-419, </pages> <year> 1995. </year>
Reference-contexts: For crease edges we can apply the same edge detector independently to the three components of the normals of the imaged surfaces and then combine the results to locate edges, say by taking the maximum of the three channels. The works <ref> [7, 19] </ref> belong to this category of edge detection methods and are based on a morphological edge detector and the Canny operator, respectively. Another approach to edge detection is residual analysis. <p> In the present paper the results of our edge detection algorithm have been judged by human observation. Recently, a methodology <ref> [19] </ref> for experimentally evaluating edge detection methods for range images based on image sets with manually specified ground truth and a set of objective performance metrics was proposed.
Reference: [20] <author> S. Kaveti, E.K. Teoh, H. Wang, </author> <title> Second-order implicit polynomials for segmentation of range images, </title> <journal> Pattern Recognition, </journal> <volume> 29(6), </volume> <pages> 937-949, </pages> <year> 1996. </year>
Reference-contexts: Due to the nature of edge-based approaches, the region boundaries tend to be located precisely. The usefulness of edge detection is actually twofold. Edge detection has the potential of a complete segmentation. For this purpose heuristic criteria <ref> [2, 20] </ref> have been shown to be effective to close gaps in edge maps of range images. Alternatively, we can make use of edge detection to support region-based segmentation. An edge map may provide an initial segmentation that is further refined by region-based techniques. <p> specified ground truth. 2 source real images shown scanners (real images evaluated) Al-Hujazi & Sood [2] 4 (several) 1 Berkman & Caelli [4] 0 (0) 0 Ghosal & Mehrotra [12] 3 (several) 1 Ghosal & Mehrotra [13] 2 (2) 1 Gunsel et al. [14] 0 (0) 0 Kaveti et al. <ref> [20] </ref> 6 (MSU) 1 Krishnapuram & Gupta [22] 7 (?) 2 Mintz [24] 2 (2) 1 Wani & Batchelor [34] 3 (3) 1 Table 1: Summary of recent journal-published edge detection algorithms for range images. "Real images shown" is counted from figures in the paper, while "real images evaluated" is drawn
Reference: [21] <author> N. Kehtarnavaz, S. Mohan, </author> <title> A framework of estimation of motion parameters from range images, Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 45, </volume> <pages> 88-105, </pages> <year> 1989. </year>
Reference-contexts: Thus, a segmentation step is usually carried out to group the range data into high-level features suitable for the subsequent image analysis and interpretation. In the range image domain, vision tasks such as object recognition [3, 11], model construction [15], configuration analysis [25], motion analysis <ref> [21, 30] </ref>, automated visual inspection [26], and robotic grasping operations [1, 2] have been build in most cases upon scene representations of surface patches.
Reference: [22] <author> R. Krishnapuram, S. Gupta, </author> <title> Morphological methods for detection and classification for edges in range images, </title> <journal> Journal of Mathematical Imaging and Vision, </journal> <volume> 2, </volume> <pages> 351-375, </pages> <year> 1992. </year>
Reference-contexts: shown scanners (real images evaluated) Al-Hujazi & Sood [2] 4 (several) 1 Berkman & Caelli [4] 0 (0) 0 Ghosal & Mehrotra [12] 3 (several) 1 Ghosal & Mehrotra [13] 2 (2) 1 Gunsel et al. [14] 0 (0) 0 Kaveti et al. [20] 6 (MSU) 1 Krishnapuram & Gupta <ref> [22] </ref> 7 (?) 2 Mintz [24] 2 (2) 1 Wani & Batchelor [34] 3 (3) 1 Table 1: Summary of recent journal-published edge detection algorithms for range images. "Real images shown" is counted from figures in the paper, while "real images evaluated" is drawn from the text. <p> Note that experiments using synthetic images are not included. In our opinion, work that stops short of using real images inspires little confidence in its relevance. From Table 1 we can see that only one paper, namely <ref> [22] </ref>, has reported experiments using two different range cameras. The rest of this paper is organized as follows. We begin with the formulation of the edge detection problem. <p> Because of this problem and the fact that smooth edges relatively seldom occur in range images, their detection has been widely ignored in the literature. In this paper we concentrate our attention to jump and crease edges, too. Crease edges can be further divided into roof and non-roof edges <ref> [22] </ref>. Roof edges correspond to local extrema and have either higher or lower depth values on both sides, while non-roof edges are characterized by discontinuities in surface normals with lower values on one and higher values on the other side. <p> Cheng and Don [8] proposed another morphological approach to detect convex roof edges only. Such edges are found by looking for the leaf nodes of the skeletal tree of a range image constructed by morphological skeleton operations. Krishnapuram and Gupta <ref> [22] </ref> have developed two other morphological methods. Essentially, they are a morphological implementation of residual analysis techniques and the first-derivative operator, respectively. The results of morphological operations are used to classify pixels into non-edges and edges of several types by rules.
Reference: [23] <author> G.C. Lee, </author> <title> G.C. Stockman, Obtaining registered range and intensity images using the Technical Arts Scanner, </title> <type> Technical Report CPS-91-08, </type> <institution> Dept. of Computer Science, Michigan State University, East Lansing, </institution> <year> 1991. </year>
Reference-contexts: The first image source ist the popular image set from the PRIP Lab of Michigan State University and another 38 registered range/intensity image pairs 3 from the same Lab <ref> [23] </ref>. The second image set acquired by the ABW scanner consists of about 50 images of both polyhedral and curved objects 4 . By contrast, all 40 images taken by the Perceptron scanner 5 contain only polyhedral objects 6 . The three image sets have quite different characteristics. <p> The next two scenes contain surfaces such as cylinders, spheres and cones that are common in range images. Objects of more complicated shape can be seen in the remaining three scenes. The last scene contains two overlapping objects. For the image set described in <ref> [23] </ref>, the results of two scenes are shown in 9, containing an adaptor and a funnel, respectively. The other two image sets are more noisy than the Michigan images. In particular, we have observed that for ABW images the basic version of our algorithm cannot provide a precise edge localization.
Reference: [24] <author> D. Mintz, </author> <title> Robust consensus based edge detection, CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 59(2), </volume> <pages> 137-153, </pages> <year> 1994. </year>
Reference-contexts: Al-Hujazi & Sood [2] 4 (several) 1 Berkman & Caelli [4] 0 (0) 0 Ghosal & Mehrotra [12] 3 (several) 1 Ghosal & Mehrotra [13] 2 (2) 1 Gunsel et al. [14] 0 (0) 0 Kaveti et al. [20] 6 (MSU) 1 Krishnapuram & Gupta [22] 7 (?) 2 Mintz <ref> [24] </ref> 2 (2) 1 Wani & Batchelor [34] 3 (3) 1 Table 1: Summary of recent journal-published edge detection algorithms for range images. "Real images shown" is counted from figures in the paper, while "real images evaluated" is drawn from the text. <p> These eigenvalues were directly geometrically interpreted and thresholded to detect jump and crease edges. In <ref> [24] </ref> Mintz made use of robust estimators to transform local image windows into binary (inlier/outlier) windows. In case of discontinuities, the binary window resembles an inlier/outlier step edge and its location corresponds to the location of the discontinuity in the original image.
Reference: [25] <editor> P.G. Mulgaonkar et al., </editor> <title> Understanding object configurations using range images, </title> <journal> IEEE Trans. on PAMI, </journal> <volume> 14(2), </volume> <pages> 303-307, </pages> <year> 1992. </year>
Reference-contexts: Thus, a segmentation step is usually carried out to group the range data into high-level features suitable for the subsequent image analysis and interpretation. In the range image domain, vision tasks such as object recognition [3, 11], model construction [15], configuration analysis <ref> [25] </ref>, motion analysis [21, 30], automated visual inspection [26], and robotic grasping operations [1, 2] have been build in most cases upon scene representations of surface patches.
Reference: [26] <author> T.S. Newman, A.K. Jain, </author> <title> A system for 3D CAD-based inspection using range images, </title> <journal> Pattern Recognitiuon, </journal> <volume> 28(10), </volume> <pages> 1555-1574, </pages> <year> 1995. </year>
Reference-contexts: In the range image domain, vision tasks such as object recognition [3, 11], model construction [15], configuration analysis [25], motion analysis [21, 30], automated visual inspection <ref> [26] </ref>, and robotic grasping operations [1, 2] have been build in most cases upon scene representations of surface patches. This has led to the general agreement of defining the range image segmentation task as one of dividing range images into closed regions with application domain specific surface properties [16].
Reference: [27] <author> T. Pavlidis, S.L. Horowitz, </author> <title> Segmentation of plane curves, </title> <journal> IEEE Trans. on Computers, </journal> <volume> C23, </volume> <pages> 860-870, </pages> <year> 1974. </year>
Reference-contexts: The splitting algorithm proceeds recursively until the approximation error e max doesn't exceed the threshold *. It is well known that the simple splitting method of Duda and Hart produces sometimes spurious segments. For the problem of piecewise linear approximation of curves, Pavlidis and Horowitz <ref> [27] </ref> tried to solve this problem by introducing a merge step. As stated in [10], however, this algorithm is computationally rather expensive. For complex curves, it produces sometimes worse results than the simple splitting method.
Reference: [28] <author> Perceptron Inc., </author> <title> LASAR Hardware Manual, 23855 Research Drive, </title> <address> Farmington Hills, Michigan, </address> <year> 1993. </year>
Reference-contexts: we have used a large number (about 280) of real range images acquired by three range scanners with quite different characteristics: * a Technical Arts scanner [32] operating on the triangulation principal using laser plane projection, * an ABW structured light scanner [31], and * a Perceptron time-of-flight laser scanner <ref> [28] </ref>. These three types of range scanners are among the most important active ranging methods [5, 18] and thus represent quite well the spectrum of the range scanners available today.
Reference: [29] <author> P.L. Rosin, G.A.W. West, </author> <title> Salience distance transforms, Graphical Models and Image Processing, </title> <booktitle> 57(6), </booktitle> <pages> 483-521, </pages> <year> 1995. </year>
Reference-contexts: Figure 12 (a) shows the distance transform of the edge map in transform is taken into account during the seed region extraction, it is more likely to find 22 reliable seed regions. Instead of using a binary edge map, we can also apply the so-called salience distance transform <ref> [29] </ref> to an edge strength map. In the salience distance transform all edge candidates are involved in the computation of a distance map. But their contribution is weighted by a salience value (the edge strength in our case). This way we can eliminate the need for the binarization threshold.
Reference: [30] <author> B. Sabata, J.K. Aggarwal, </author> <title> Surface correspondnece and motion computation from a pair of range images, </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <volume> 63(2), </volume> <pages> 232-250, </pages> <year> 1996. </year>
Reference-contexts: Thus, a segmentation step is usually carried out to group the range data into high-level features suitable for the subsequent image analysis and interpretation. In the range image domain, vision tasks such as object recognition [3, 11], model construction [15], configuration analysis [25], motion analysis <ref> [21, 30] </ref>, automated visual inspection [26], and robotic grasping operations [1, 2] have been build in most cases upon scene representations of surface patches.
Reference: [31] <author> T.G. Stahs, </author> <title> F.M. Wahl, Fast and robust range data acquisition in a low-cost environment, </title> <booktitle> Proc. of SPIE#1395: Close-Range Photogrammetry Meets Machine Vision, </booktitle> <pages> 496-503, </pages> <year> 1990. </year>
Reference-contexts: Notice that this condition is satisfied by a much wider range of scanners than those of regular sampling in both coordinate directions, thus substantially extending the applicability of our edge detection algorithm. For instance, structured light scanners like that described in <ref> [31] </ref> typically don't have the property of regular sampling. However, the measured points of a scan line in 3D space lie in a plane spanned by the scan line in the image plane and the focal point of the camera. <p> For tests we have used a large number (about 280) of real range images acquired by three range scanners with quite different characteristics: * a Technical Arts scanner [32] operating on the triangulation principal using laser plane projection, * an ABW structured light scanner <ref> [31] </ref>, and * a Perceptron time-of-flight laser scanner [28]. These three types of range scanners are among the most important active ranging methods [5, 18] and thus represent quite well the spectrum of the range scanners available today.
Reference: [32] <author> Tech. </author> <title> Arts Corp., 100x 3-dimensional scanner: User's manual and application programming guide, </title> <address> Redmond, WA. </address>
Reference-contexts: For tests we have used a large number (about 280) of real range images acquired by three range scanners with quite different characteristics: * a Technical Arts scanner <ref> [32] </ref> operating on the triangulation principal using laser plane projection, * an ABW structured light scanner [31], and * a Perceptron time-of-flight laser scanner [28].
Reference: [33] <author> S. Venkatesh, </author> <title> P.L. Rosin, Dynamic threshold determination by local and global edge evaluation, Graphical Models and Image Processing, </title> <booktitle> 57(2), </booktitle> <pages> 146-160, </pages> <year> 1995. </year>
Reference-contexts: Note that more elaborate thresholding methods are known in the literature. The approach in <ref> [33] </ref>, for instance, takes both edge strength and edge curve length into account and is very effective to delete isolated spurious edge points. We use the range image in Figure 7 (a) acquired by the Technical Arts scanner to illustrate the behavior of our edge detection algorithm. <p> In contrast to the Michigan images, many spurious edge points were reported due to the high noisy level in these images. In this case more elaborate thresholding methods like that described in <ref> [33] </ref> may be effective to delete the spurious edge points while retaining true edge points. 21 transform of the edge strength map in Figure 7 (b). The computation time for the Michigan images of a typical resolution of 200 fi 200 pixels is about 1.5 seconds.
Reference: [34] <author> M.A. Wani, B.G. Batchelor, </author> <title> Edge-region-based segmentation of range images, </title> <journal> IEEE Trans. on PAMI, </journal> <volume> 16(3), </volume> <pages> 314-319, </pages> <year> 1994. </year> <month> 25 </month>
Reference-contexts: Berkman & Caelli [4] 0 (0) 0 Ghosal & Mehrotra [12] 3 (several) 1 Ghosal & Mehrotra [13] 2 (2) 1 Gunsel et al. [14] 0 (0) 0 Kaveti et al. [20] 6 (MSU) 1 Krishnapuram & Gupta [22] 7 (?) 2 Mintz [24] 2 (2) 1 Wani & Batchelor <ref> [34] </ref> 3 (3) 1 Table 1: Summary of recent journal-published edge detection algorithms for range images. "Real images shown" is counted from figures in the paper, while "real images evaluated" is drawn from the text.
References-found: 34

