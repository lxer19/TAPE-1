URL: ftp://ftp.cs.washington.edu/tr/1992/08/UW-CSE-92-08-03.PS.Z
Refering-URL: http://www.cs.washington.edu/homes/pardo/papers.d/thread.html
Root-URL: 
Title: Adding Scheduler Activations to Mach 3.0  
Author: Paul Barton-Davis, Dylan McNamee, Raj Vaswani, and Edward D. Lazowska 
Address: Seattle, Washington 98195  
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract: Technical Report 92-08-03 August 1992 Revised March 1993 Abstract When user-level threads are built on top of traditional kernel threads, they can exhibit poor performance or even incorrect behavior in the face of blocking kernel operations such as I/O, page faults, and processor preemption. This problem can be solved by building user-level threads on top of a new kernel entity, the scheduler activation. The goal of the effort described in this paper was to implement scheduler activations in the Mach 3.0 operating system. We describe the design decisions made, the kernel modifications required, and our additions to the CThreads thread library to take advantage of the new kernel structure. We also isolate the performance costs incurred due to scheduler activations support, and empirically demonstrate that these costs are outweighed by the benefits of this approach.
Abstract-found: 1
Intro-found: 1
Reference: [ABLL92] <author> Thomas E. Anderson, Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy. </author> <title> Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(1) </volume> <pages> 53-79, </pages> <month> February </month> <year> 1992. </year> <booktitle> Also appeared in Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <month> October </month> <year> 1991. </year>
Reference-contexts: This has presented the application programmer with a dilemma: use either kernel threads, which are well integrated with system services but have expensive common-case operations, or user-level threads, which have efficient common-case operations but are poorly integrated with system services. To resolve this dilemma, Anderson et al. <ref> [ABLL92] </ref> designed a new kernel entity, the scheduler activation, which provides proper support for user-level thread management. User-level threads built on top of scheduler activations combine the functionality of kernel threads with the performance and flexibility of user-level threads. <p> Multiprocessor operating systems such as Mach and Topaz [TSS88] attempted to address this problem by providing kernel threads. But kernel threads have also proven to be too expensive, and Mach and Topaz now provide user-level thread systems built on top of their kernel threads. Anderson et al. <ref> [ABLL92] </ref> argue that the cost of kernel threads relative to user-level threads is not an artifact of existing implementations, but rather is inherent, arising from two factors: * The cost of kernel services. Trapping into the kernel is more expensive than a simple procedure call. <p> Scheduler activations present a unified solution. 1.2 Scheduler Activations Scheduler activations are an alternative to kernel threads for supporting the user-level management of parallelism. As presented in <ref> [ABLL92] </ref>, a scheduler activations environment has the following key characteristics: * Processors are allocated to jobs by the kernel. Processor allocation is managed by the kernel, based on information communicated from user-level. <p> This is because event management is encapsulated within the user-level thread system, the interface to which remains unchanged. Readers unfamiliar with this system structure are strongly encouraged to review <ref> [ABLL92] </ref> before proceeding. 1.3 Scheduler Activations in Mach Anderson's prototype implementation involved modifying the Topaz operating system on the DEC SRC Firefly multiprocessor workstation [TSS88]. This provided an excellent prototyping environment, but the implementation was inaccessible to others, and experience was limited to systems with at most six processors.
Reference: [ALBL91] <author> Thomas E. Anderson, Henry M. Levy, Brian N. Bershad, and Edward D. Lazowska. </author> <title> The Interaction of Architecture and Operating System Design. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: Trapping into the kernel is more expensive than a simple procedure call. Architectural trends are making kernel traps relatively more expensive <ref> [ALBL91] </ref>. In addition, to protect itself from misbehaving user-level programs, the kernel must check each argument for bad values that could cause the system to crash. A user-level thread package uses procedure calls to provide thread management operations, avoiding the overhead of kernel traps.
Reference: [ALL89] <author> Thomas E. Anderson, Edward D. Lazowska, and Henry M. Levy. </author> <title> The Performance Implications of Thread Management Alternatives for Shared Memory Multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(12) </volume> <pages> 1631-1644, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: This can be of considerable benefit when there are multiple nested sets of blocked/unblocked notifications, and is simple to implement. 4.5.3 Per-Processor Run Queues Per-processor queues of ready threads are a commonly suggested optimization technique <ref> [ALL89] </ref> [FL89]. This could fairly easily be implemented on top of our system, but with mitigated benefits. In a non-preemptive threads package, per-processor ready queues can allow queue operations to proceed without synchronization, significantly improving performance.
Reference: [And91] <author> Thomas E. Anderson. </author> <title> Operating System Support for High Performance Multiprocessing. </title> <type> PhD thesis, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: The problem arises because preemption can occur while a thread is in a critical section, and this can impede the progress of other threads that wish to enter the critical section. Various solutions to this problem have been proposed <ref> [And91] </ref> [BRE92] [Her91]. Each of these solutions makes certain assumptions regarding the prevalence and characteristics of critical sections, and each requires a certain degree of system support, entailing a certain amount of implementation complexity.
Reference: [BH86] <author> J. Barnes and P. Hut. </author> <title> A Hierarchical O(n log n) Force-Calculation Algorithm. </title> <journal> Nature, </journal> <volume> 24 </volume> <pages> 446-449, </pages> <year> 1986. </year>
Reference-contexts: The application we use, called Gravity, is an implementation of the Barnes and Hut clustering algorithm for simulating the gravitational interaction of a large number of stars over time <ref> [BH86] </ref>. The program contains five phases of execution; these phases are repeated for each timestep in the simulation. The first phase is sequential, 18 while the last four are parallel. Between each of the parallel phases is a barrier synchronization at which the parallelism decreases briefly to one.
Reference: [Bla90] <author> David L. Black. </author> <title> Scheduling Support for Concurrency and Parallelism in the Mach Operating System. </title> <journal> IEEE Computer, </journal> <volume> 23(5) </volume> <pages> 35-43, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: The primary requirement of such a policy is the ability to manage processor allocation on a per-task basis, something difficult to do under the basic Mach policy. However, Mach's processor sets <ref> [Bla90] </ref> provided us with a mechanism to circumvent the standard thread-based policy (which is inappropriate for our purposes), and to replace it with our own task-based one.
Reference: [BLL88] <author> Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy. </author> <title> PRESTO: A System for Object-oriented Parallel Programming. </title> <journal> Software Practice and Experience, </journal> <volume> 18(8) </volume> <pages> 713-732, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Kernel threads must be all things to all people. Even if a particular program has no need for some specific facility (e.g., round-robin scheduling), it still must pay the price for the existence of that facility. A user-level thread package can be customized and optimized for each application's needs <ref> [BLL88] </ref>. User-level threads have proven useful for expressing relatively fine-grain parallelism. Unfortunately, implementing user-level threads on top of existing operating system mechanisms (such as kernel threads) causes difficulties.
Reference: [BRE92] <author> Brian N. Bershad, David D. Redell, and John R. Ellis. </author> <title> Fast Mutual Exclusion for Uniprocessors. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1992. </year>
Reference-contexts: The problem arises because preemption can occur while a thread is in a critical section, and this can impede the progress of other threads that wish to enter the critical section. Various solutions to this problem have been proposed [And91] <ref> [BRE92] </ref> [Her91]. Each of these solutions makes certain assumptions regarding the prevalence and characteristics of critical sections, and each requires a certain degree of system support, entailing a certain amount of implementation complexity.
Reference: [CD88] <author> Eric C. Cooper and Richard P. Draves. </author> <title> C Threads. </title> <type> Technical Report CMU-CS-88-154, </type> <institution> Department of Computer Science, Carnegie-Mellon University, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: We have in fact implemented several policies in addition to the one just described; we expect that still others will be implemented and evaluated as our work in this area continues. 4 User-Level Threads CThreads <ref> [CD88] </ref> forms the basis of our user-level thread package. We chose CThreads because it already works with the Mach kernel and has been widely used in the Mach community. CThreads is implemented as a library of functions with which the application program is linked. <p> The following sections describe how we have changed the CThreads package to take advantage of the new kernel and present some details of the implementation. 4.1 CThreads with Scheduler Activations The Mach Thread implementation of CThreads <ref> [CD88] </ref> runs user-level threads on top of Mach kernel threads when a program's parallelism increases, it asks the kernel for more kernel threads, which are used to run user-level threads.
Reference: [DBRD91] <author> Richard P. Draves, Brian N. Bershad, Richard F. Rashid, and Randall W. Dean. </author> <title> Using Continuations to Implement Thread Management and Communication in Operating Systems. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <month> October </month> <year> 1991. </year>
Reference-contexts: Be forewarned that the remainder of Section 2.2 is fairly detailed. A crucial component of a scheduler activation's state is its user-level continuation, which is similar to a kernel continuation (as described in <ref> [DBRD91] </ref>), but specifies a kernel routine to be run instead of returning to the user-level. We set this when we wish to gain control of the activation's execution in order to force an upcall to user-level (see Section 2.2.1).
Reference: [Dea93] <author> Randall W. Dean. </author> <title> Using Continuations to Build a User-Level Threads Library. </title> <booktitle> In Proceedings of the Third USENIX Mach Symposium, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: In particular, although our package differs (internally) from standard CThreads, it might benefit from the improvements to the latter that have been recently suggested <ref> [Dea93] </ref>. As described in section 4.4, our package already includes one of these optimizations, that of having idle threads spin (rather than block) waiting for work. We are currently experimenting with the other ideas proposed in [Dea93]. 4.5.1 Trap State Restores The low overhead of context switching at user-level is one <p> it might benefit from the improvements to the latter that have been recently suggested <ref> [Dea93] </ref>. As described in section 4.4, our package already includes one of these optimizations, that of having idle threads spin (rather than block) waiting for work. We are currently experimenting with the other ideas proposed in [Dea93]. 4.5.1 Trap State Restores The low overhead of context switching at user-level is one of the principal attractions of user-level thread systems. In the common case (a thread switching due to user-level synchronization or termination), our CThreads retains this low overhead.
Reference: [FL89] <author> John Faust and Henry M. Levy. </author> <title> The Performance of an Object-Oriented Thread Package. </title> <booktitle> In Proceedings of the 4th ACM Conference on Object-Oriented Programming Systems, Languages, and Applications, </booktitle> <month> October </month> <year> 1989. </year>
Reference-contexts: This can be of considerable benefit when there are multiple nested sets of blocked/unblocked notifications, and is simple to implement. 4.5.3 Per-Processor Run Queues Per-processor queues of ready threads are a commonly suggested optimization technique [ALL89] <ref> [FL89] </ref>. This could fairly easily be implemented on top of our system, but with mitigated benefits. In a non-preemptive threads package, per-processor ready queues can allow queue operations to proceed without synchronization, significantly improving performance.
Reference: [GDFR90] <author> David Golub, Randell W. Dean, Alessandro Forin, and Richard F. Rashid. </author> <title> Unix As An Application Program. </title> <booktitle> In Proceedings of the Summer USENIX Conference, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: stack (which is simple, because CThreads stacks are aligned on multiples of power-of-2 addresses), and then offset to find a pointer to the thread control block, thus identifying the thread. 13 Although the stack-based identification scheme appears simple, it is complicated by the existence of the Unix system call emulator <ref> [GDFR90] </ref>. This is a body of code mapped into the address space of each task created by the Unix server. When a task makes a Unix system call, a trap instruction carries it into kernel space.
Reference: [Her91] <author> Maurice Herlihy. </author> <title> Wait-Free Synchronization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(1) </volume> <pages> 124-149, </pages> <month> January </month> <year> 1991. </year> <month> 21 </month>
Reference-contexts: The second problem is that blocking kernel events such as I/O, page faults, and processor preemption are invisible to the user-level. Various mechanisms have been suggested to address specific instances of these problems [MSLM91] [TG89] <ref> [Her91] </ref>, but none of this work addresses all of the difficulties. Scheduler activations present a unified solution. 1.2 Scheduler Activations Scheduler activations are an alternative to kernel threads for supporting the user-level management of parallelism. <p> The problem arises because preemption can occur while a thread is in a critical section, and this can impede the progress of other threads that wish to enter the critical section. Various solutions to this problem have been proposed [And91] [BRE92] <ref> [Her91] </ref>. Each of these solutions makes certain assumptions regarding the prevalence and characteristics of critical sections, and each requires a certain degree of system support, entailing a certain amount of implementation complexity.
Reference: [Int87] <author> Intel Corporation. </author> <title> i386 Microprocessor Programmer's Reference Manual, </title> <year> 1987. </year>
Reference-contexts: On the Sequent, some of the register restores are probably redundant, given Mach's use of the 80386's flat address mode <ref> [Int87] </ref>; in particular, it seems likely that the segment registers do not need to be restored by y Threads that aren't being continued by an upcall continue to spin until they acquire the lock. z As previously explained, complete register state does not necessarily include the floating-point registers, which are passed
Reference: [LT88] <author> Tom Lovett and Shreekant Thakkar. </author> <title> The Symmetry Multiprocessor System. </title> <booktitle> In Proceedings of the 1988 International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: Our goal was to integrate scheduler activations into a kernel that was widely used and that ran on a variety of platforms. We chose Mach 3.0, and conducted our work on a 20-processor Sequent Symmetry <ref> [LT88] </ref>. We envision that our implementation will fulfill several roles. First, it will allow final validation of the scheduler activations concept with a reasonable number of processors.
Reference: [MSLM91] <author> Brian D. Marsh, Michael L. Scott, Thomas J. LeBlanc, and Evangelos P. Markatos. </author> <title> First-Class User-Level Threads. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <month> October </month> <year> 1991. </year>
Reference-contexts: The second problem is that blocking kernel events such as I/O, page faults, and processor preemption are invisible to the user-level. Various mechanisms have been suggested to address specific instances of these problems <ref> [MSLM91] </ref> [TG89] [Her91], but none of this work addresses all of the difficulties. Scheduler activations present a unified solution. 1.2 Scheduler Activations Scheduler activations are an alternative to kernel threads for supporting the user-level management of parallelism.
Reference: [MVZ90] <author> Cathy McCann, Raj Vaswani, and John Zahorjan. </author> <title> A Dynamic Processor Allocation Policy for Multipro-grammed, Shared Memory Multiprocessors. </title> <type> Technical Report 90-03-02, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> March </month> <year> 1990. </year> <note> To appear in ACM Transactions on Computer Systems. </note>
Reference-contexts: Each task has its own processor set, to which all of its activations belong and to which processors are assigned by the processor allocation server. This allocator assigns processors to tasks according to the Dynamic policy of McCann et al. <ref> [MVZ90] </ref>. The Dynamic policy is an adaptive, space sharing policy that attempts to maintain an equal allocation of processors to tasks. z In a system with P processors and T tasks, each task is initially assigned its desired allocation, up to P=T . <p> For example, while testing upcall handlers, it may be useful to prevent them from generating additional upcalls. z Policies based on spatial equipartition have been shown to outperform time-sharing policies in this environment [TG89] <ref> [MVZ90] </ref>. 10 We implement this processor allocation policy using the following per-task information (maintained in a page of memory shared between the task and the allocator): * desired stores the number of processors each task has requested * count stores the number of processors a task has at any moment * <p> Next, we used our processor allocator to provide a simple space-sharing policy, of the sort previously shown to provide good performance for this type of workload on this class of machine <ref> [TG89, MVZ90] </ref>. This allocator simply divides the available processors equally amongst the jobs: given P processors and J competing jobs, each job is allocated P/J processors. On each job arrival, the allocator computes a new equipartition allocation, and processors are preempted from active jobs for reassignment to the new arrival. <p> Preemptions are coordinated by using scheduler activations to notify active jobs of processor loss. The jobs' thread schedulers therefore have immediate access to interrupted threads, and the kernel ensures that the jobs always have exactly as many activations as processors (avoiding oblivious kernel scheduling). Note that, as described in <ref> [MVZ90] </ref>, better performance can be achieved by having the processor allocator respond to dynamic changes in the jobs' parallelism (i.e., processor demand) by reallocating processors from jobs that cannot currently use them to jobs that can.
Reference: [RBF + 89] <author> Richard Rashid, Robert Baron, Alessandro Forin, David Golub, Michael Jones, Daniel Julin, Doug Orr, and Richard Sanzi. </author> <title> Mach: A Foundation for Open Systems. </title> <booktitle> In Proceedings of the Second IEEE Workshop on Workstation Operating Systems, </booktitle> <month> September </month> <year> 1989. </year>
Reference-contexts: In the past few years a consensus has emerged that scheduler activations are the right kernel mechanism for supporting the user-level management of parallelism. The goal of the effort described in this paper was to implement scheduler activations in the Mach 3.0 operating system <ref> [RBF + 89] </ref>. This paper places emphasis on the implementation rather than the concepts involved.
Reference: [TG89] <author> Andrew Tucker and Anoop Gupta. </author> <title> Process Control and Scheduling Issues for Multiprogrammed Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1989. </year>
Reference-contexts: The second problem is that blocking kernel events such as I/O, page faults, and processor preemption are invisible to the user-level. Various mechanisms have been suggested to address specific instances of these problems [MSLM91] <ref> [TG89] </ref> [Her91], but none of this work addresses all of the difficulties. Scheduler activations present a unified solution. 1.2 Scheduler Activations Scheduler activations are an alternative to kernel threads for supporting the user-level management of parallelism. <p> For example, while testing upcall handlers, it may be useful to prevent them from generating additional upcalls. z Policies based on spatial equipartition have been shown to outperform time-sharing policies in this environment <ref> [TG89] </ref> [MVZ90]. 10 We implement this processor allocation policy using the following per-task information (maintained in a page of memory shared between the task and the allocator): * desired stores the number of processors each task has requested * count stores the number of processors a task has at any moment <p> Next, we used our processor allocator to provide a simple space-sharing policy, of the sort previously shown to provide good performance for this type of workload on this class of machine <ref> [TG89, MVZ90] </ref>. This allocator simply divides the available processors equally amongst the jobs: given P processors and J competing jobs, each job is allocated P/J processors. On each job arrival, the allocator computes a new equipartition allocation, and processors are preempted from active jobs for reassignment to the new arrival.
Reference: [TSS88] <author> Charles P. Thacker, Lawrence Stewart, and Edward Satterthwaite, Jr. Firefly: </author> <title> A Multiprocessor Workstation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(8) </volume> <pages> 909-920, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: It has long been accepted that kernel processes (e.g., as in Unix) are too expensive to support any but the most coarse grain parallel applications. Multiprocessor operating systems such as Mach and Topaz <ref> [TSS88] </ref> attempted to address this problem by providing kernel threads. But kernel threads have also proven to be too expensive, and Mach and Topaz now provide user-level thread systems built on top of their kernel threads. <p> Readers unfamiliar with this system structure are strongly encouraged to review [ABLL92] before proceeding. 1.3 Scheduler Activations in Mach Anderson's prototype implementation involved modifying the Topaz operating system on the DEC SRC Firefly multiprocessor workstation <ref> [TSS88] </ref>. This provided an excellent prototyping environment, but the implementation was inaccessible to others, and experience was limited to systems with at most six processors. Our goal was to integrate scheduler activations into a kernel that was widely used and that ran on a variety of platforms.
References-found: 21

