URL: ftp://ftp.cs.columbia.edu/reports/reports-1993/cucs-025-93.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1993.html
Root-URL: http://www.cs.columbia.edu
Title: DFLOPS:A Data Flow Machine for Production Systems  
Author: Fu-Chiung Cheng 
Keyword: Parallel processing, Data flow machine, Production systems, Pipeline processor, and Compilation.  
Date: November 15, 1993  
Address: NY, NY 10027  New York University NY, NY 10003  
Affiliation: Department of Computer Science Columbia University  Department of Computer Science  
Abstract: Many production system machines have been proposed to speed up the execution of production system programs. Most of them are implemented based on conventional control flow model of execution which is limited by the "von Neumann bottleneck." In this paper we propose DFLOPS, a new multiprocessor data flow machine, for parallel processing of production systems. Rule programs are compiled into data flow graphs and then mapped into DFLOPS processing elements. Three levels of parallelism: Rule Level Parallelism, RHS Level Parallelism and LHS Parallelism are fully exploited to achieve high performance. The design and implementation of DFLOPS is presented in detail. The distinguishing characteristics of this proposed machine lies in its simplicity, fully-pipelined processing and fine grain parallelism. The initial results reveal that the performance of production systems is greatly improved. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Arvind and Rishiyur S. Nikhil. </author> <title> Executing a program on the mit tagged-token data flow architecture. </title> <journal> IEEE Transactions on Computer, </journal> <volume> 39:3, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: Among them, the most significant parallelism are the rule level parallelism and the LHS level parallelism. The latter reduces the matching time and the former reduces the total number of recognize-act cycles. 2.3 Data Flow Computations Most data flow machines such as MIT Tagged-Token Dataflow Architecture <ref> [1] </ref>, Monsoon [23, 24], EM-4 [26], were designed for general-purpose parallel numerical computations. As for data flow symbolic computations, GAMMA [6], AGM [2], KARDAMOM [4] have demonstrated that the data flow principle can be applied in database applications. <p> This token is flowed to MWTQ because the the LR memory flag, f 1 , of node 1 is "L". Token matcher works as follows: first it fetches this token from MWTQ and stores the time tag of this token (i.e. 4) into LM <ref> [1] </ref> specified by f 1 and p 1 ; second, it matches this token against the time tag list stored in RM [1]; three time tags are matched and three new tokens ,&lt; 3; +; 4; 1 &gt;, &lt; 3; +; 4; 2 &gt; and &lt; 3; +; 4; 3 &gt;, <p> Token matcher works as follows: first it fetches this token from MWTQ and stores the time tag of this token (i.e. 4) into LM <ref> [1] </ref> specified by f 1 and p 1 ; second, it matches this token against the time tag list stored in RM [1]; three time tags are matched and three new tokens ,&lt; 3; +; 4; 1 &gt;, &lt; 3; +; 4; 2 &gt; and &lt; 3; +; 4; 3 &gt;, are generated; finally, it flows the generated tokens to ETQ. 11 ? 1. TEQA 1,0,0,0,+2,-,L,1,N,0 3.
Reference: [2] <author> L. Bic and R. Hartmann. Agm: </author> <title> The irvine dataflow database machine. </title> <booktitle> In Data Flow Computing, </booktitle> <pages> pages 387-412, </pages> <year> 1987. </year>
Reference-contexts: As for data flow symbolic computations, GAMMA [6], AGM <ref> [2] </ref>, KARDAMOM [4] have demonstrated that the data flow principle can be applied in database applications. We will demonstrate that data flow principle can also be applied in expert systems. 3 2.3.1 Data-driven Numerical Computations Information items in a data flow computer appear as operation packages and data tokens [13].
Reference: [3] <author> L. Brownston, R. Farrell, E. Kant, and N. Martin. </author> <title> Programming Expert Systems in OPS5: An Introduction to Rule-Based Programming. </title> <publisher> Addison Wesley, </publisher> <address> Reading, Mass., </address> <year> 1985. </year>
Reference-contexts: The design and implementation of DFLOPS is presented in detail in section 4. Section 5 gives an example showing how this machine works. The results evaluation is discussed in section 6. Finally, the conclusion and remarks are given. 1 2 Production Systems A production system <ref> [3, 7] </ref> is defined by a set of rules, or productions, which form the production memory (PM), together with a database of assertions, called working memory (WM), and an inference engine which executes the rules with a cycle consisting of three action states: 1. <p> Select: the interpreter applies some conflict resolution strategies to determine one dom inant rule for execution. 3. Execute: the interpreter executes the rule selected and the working memory is modified by the action part of the selected rule. OPS5 <ref> [3, 7] </ref> supports forward chaining mechanism and LEX or MEA conflict resolution strategies to select the "best" rule to fire. Each unit of WM, consisting of a class name and several attribute-value pairs, is called working memory elements (WMEs). Each WME is associated with an integer called time tag.
Reference: [4] <author> G. Bultzingloewsn and Cirano Iochpe. </author> <title> Design and implementation of kardamom a set-oriented data flow database machine. </title> <booktitle> In International Workshop on Database Machines, </booktitle> <pages> pages 18-33, </pages> <year> 1989. </year>
Reference-contexts: As for data flow symbolic computations, GAMMA [6], AGM [2], KARDAMOM <ref> [4] </ref> have demonstrated that the data flow principle can be applied in database applications. We will demonstrate that data flow principle can also be applied in expert systems. 3 2.3.1 Data-driven Numerical Computations Information items in a data flow computer appear as operation packages and data tokens [13].
Reference: [5] <author> Fu-Chiung Cheng, Huei-Huang Chen, and Jing-Hwi Perng. </author> <title> Parallel execution on production systems. </title> <booktitle> In Proceedings of the Second IEEE Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 463-470, </pages> <year> 1990. </year>
Reference-contexts: Rules dependency (i.e. which rules can be fired in parallel and which rule cannot) can be analyzed by the dependency propagation algorithm at compiled time <ref> [5] </ref>, so a rule dependency matrix is constructed and kept in the coordinator to decide which rules can be fired in parallel without changing the semantics of production systems. This model works as follows: All PEs perform LHS match and report the matched rules to the coordinator.
Reference: [6] <author> D. J. DeWitt, S. Ghandeharizadeh, D. Schneider, R. Jauhari, M. Muralikrishna, and Anoop Sharma. </author> <title> A single user evaluation of the gamma database machine. </title> <booktitle> In Database Machine and Knowledge Base Machines, </booktitle> <pages> pages 370-386, </pages> <year> 1987. </year> <month> 19 </month>
Reference-contexts: As for data flow symbolic computations, GAMMA <ref> [6] </ref>, AGM [2], KARDAMOM [4] have demonstrated that the data flow principle can be applied in database applications.
Reference: [7] <author> C. L. Forgy. </author> <title> OPS5 user's manual. </title> <type> Technical Report CMU-CS-81-135, </type> <institution> Department of Computer Science, Carnegie-Mellon University, </institution> <month> July </month> <year> 1981. </year>
Reference-contexts: The design and implementation of DFLOPS is presented in detail in section 4. Section 5 gives an example showing how this machine works. The results evaluation is discussed in section 6. Finally, the conclusion and remarks are given. 1 2 Production Systems A production system <ref> [3, 7] </ref> is defined by a set of rules, or productions, which form the production memory (PM), together with a database of assertions, called working memory (WM), and an inference engine which executes the rules with a cycle consisting of three action states: 1. <p> Select: the interpreter applies some conflict resolution strategies to determine one dom inant rule for execution. 3. Execute: the interpreter executes the rule selected and the working memory is modified by the action part of the selected rule. OPS5 <ref> [3, 7] </ref> supports forward chaining mechanism and LEX or MEA conflict resolution strategies to select the "best" rule to fire. Each unit of WM, consisting of a class name and several attribute-value pairs, is called working memory elements (WMEs). Each WME is associated with an integer called time tag.
Reference: [8] <author> C.L. Forgy. </author> <title> Rete: A fast algorithm for the many pattern/many object pattern matching problem. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> pages 17-37, </pages> <year> 1982. </year>
Reference-contexts: DFLOPS fully exploits both techniques. Many efforts have been proposed to speedup the performance of production system programs. In software approaches Forgy presented the RETE match algorithm, developed for the OPS5 production system interpreter, to reduce redundant pattern matching <ref> [8] </ref>. Schor et al. modified the operations of RETE network to achieve improvement in efficiency and rule clarity [19]. Miranker proposed the TREAT matching algorithm [21] and lazy matching to improve the matching time [20]. <p> there is a manager with name &lt;mn&gt; of department &lt;d&gt; and there is an employee &lt;en&gt; of department &lt;d&gt; but there is no fact like "&lt;mn&gt; is the boss of &lt;en&gt;" then create a new fact and insert it into the WM. 2.1 RETE Matching Algorithm The RETE matching algorithm <ref> [8] </ref> is a very efficient approach for matching many objects against many rules. It compiles the LHS of the production rules into an augmented data flow network, called RETE network.
Reference: [9] <author> Jean-Luc Gaudiot and Andrew Sohn. </author> <title> Data-driven parallel production systems. </title> <journal> IEEE trans. on Software Engineering, </journal> <volume> 16:3, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: However, in those parallel approaches, most of the production system machines are implemented in conventional control flow model of execution which is limited by the "von Neumann bottleneck." Gaudiot illustrated that production systems can be mapped on data-driven architecture <ref> [9, 17] </ref> and pointed out that the data-driven model of execution has been proposed as a solution to solve the "von Neumann bottleneck." Instead of designing a new architecture for data-driven production systems, a RETE network was compiled into a data flow graph which was then mapped into the MIT Tagged
Reference: [10] <author> A. Gupta. </author> <title> Implementing ops5 production systems on dado. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <pages> pages 83-91, </pages> <year> 1984. </year>
Reference-contexts: In hardware approaches Stolfo gave four parallel matching algorithms and a parallel execution algorithm based on DADO machine, a tree-structured parallel machine for large rule-based expert systems [31, 30, 15, 28, 27]. Gupta implemented OPS5 production system on DADO to perform parallel matching <ref> [10] </ref>. Oflazer proposed partitioning algorithms for production systems to maximize the effect of parallel matching [22]. <p> The software approaches [14, 21, 19, 12] can be classified as changing representation of important data structure and/or implementation of important operations, reducing processing by handling common cases efficiently, matching rules against working memory on demand, compiling and optimizing [21, 20]. In hardware approaches, some production system machines <ref> [25, 16, 11, 28, 30, 10] </ref> have been constructed. There are three applicable parallelism in production systems. 1. Rule level Parallelism: At each match state, the interpreter identifies all the rules whose LHS are satisfied by current contents of the working memory.
Reference: [11] <author> A. Gupta. </author> <booktitle> Parallel ops5 on the encore multimax. In Proceedings of International Conference on Parallel Processing, </booktitle> <pages> pages 271-280, </pages> <year> 1988. </year>
Reference-contexts: The software approaches [14, 21, 19, 12] can be classified as changing representation of important data structure and/or implementation of important operations, reducing processing by handling common cases efficiently, matching rules against working memory on demand, compiling and optimizing [21, 20]. In hardware approaches, some production system machines <ref> [25, 16, 11, 28, 30, 10] </ref> have been constructed. There are three applicable parallelism in production systems. 1. Rule level Parallelism: At each match state, the interpreter identifies all the rules whose LHS are satisfied by current contents of the working memory.
Reference: [12] <author> B.K. Hillyer and D.E. Shaw. </author> <title> Execution of ops5 production systems on a massively parallel machine. </title> <journal> Journal of parallel and distributed computing, </journal> <volume> 3:1:236-268, </volume> <year> 1986. </year>
Reference-contexts: The software approaches <ref> [14, 21, 19, 12] </ref> can be classified as changing representation of important data structure and/or implementation of important operations, reducing processing by handling common cases efficiently, matching rules against working memory on demand, compiling and optimizing [21, 20].
Reference: [13] <author> Kai Hwang and Faye A Briggs. </author> <booktitle> Computer Architecture and Parallel Processing. </booktitle> <address> MaGraw Hill, </address> <year> 1984. </year>
Reference-contexts: We will demonstrate that data flow principle can also be applied in expert systems. 3 2.3.1 Data-driven Numerical Computations Information items in a data flow computer appear as operation packages and data tokens <ref> [13] </ref>. Each operation package or instruction consists of an operator, operands, and the destinations to which the result (a new data token) will be sent. Instructions are activated by the availability of the data tokens and the enabled instructions can be executed simultaneously.
Reference: [14] <author> Toru Ishida and S.J. Stolfo. </author> <title> Optimizing rules in production system programs. </title> <booktitle> In Proceedings of the National Conference of the American Association for Artificial Intelligence, </booktitle> <pages> pages 699-704, </pages> <year> 1988. </year>
Reference-contexts: The software approaches <ref> [14, 21, 19, 12] </ref> can be classified as changing representation of important data structure and/or implementation of important operations, reducing processing by handling common cases efficiently, matching rules against working memory on demand, compiling and optimizing [21, 20].
Reference: [15] <author> Stolfo S. J. </author> <title> Five parallel algorithms for production system execution on the DADO machine. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence 1984, </booktitle> <pages> pages 300-307. </pages> <publisher> AAAI, </publisher> <year> 1984. </year>
Reference-contexts: Miranker proposed the TREAT matching algorithm [21] and lazy matching to improve the matching time [20]. In hardware approaches Stolfo gave four parallel matching algorithms and a parallel execution algorithm based on DADO machine, a tree-structured parallel machine for large rule-based expert systems <ref> [31, 30, 15, 28, 27] </ref>. Gupta implemented OPS5 production system on DADO to perform parallel matching [10]. Oflazer proposed partitioning algorithms for production systems to maximize the effect of parallel matching [22].
Reference: [16] <author> M.A. Kelly and R.E. Seviora. </author> <title> A multiprocessor architecture for production system matching. </title> <booktitle> In Proceedings of the National Conference of the American Association for Artificial Intelligence, </booktitle> <pages> pages 36-41, </pages> <year> 1987. </year>
Reference-contexts: The software approaches [14, 21, 19, 12] can be classified as changing representation of important data structure and/or implementation of important operations, reducing processing by handling common cases efficiently, matching rules against working memory on demand, compiling and optimizing [21, 20]. In hardware approaches, some production system machines <ref> [25, 16, 11, 28, 30, 10] </ref> have been constructed. There are three applicable parallelism in production systems. 1. Rule level Parallelism: At each match state, the interpreter identifies all the rules whose LHS are satisfied by current contents of the working memory.
Reference: [17] <author> Jean-Luc Gaudiot S. Lee and Andrew Sohn. </author> <title> Data-driven multiprocessor implementation of the rete match algorithm. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <pages> pages 256-260, </pages> <year> 1988. </year>
Reference-contexts: However, in those parallel approaches, most of the production system machines are implemented in conventional control flow model of execution which is limited by the "von Neumann bottleneck." Gaudiot illustrated that production systems can be mapped on data-driven architecture <ref> [9, 17] </ref> and pointed out that the data-driven model of execution has been proposed as a solution to solve the "von Neumann bottleneck." Instead of designing a new architecture for data-driven production systems, a RETE network was compiled into a data flow graph which was then mapped into the MIT Tagged <p> An example executing a fl b + c fl d is shown in Figure 2 (a). 2.3.2 Data-driven symbolic operations in production systems The suitability of the data-driven execution model for production systems was discussed in <ref> [17] </ref>. Here we discuss some differences between data-driven numerical computations and symbolic computations of productions systems. 1. Data grain: Data grain is the unit of data to be processed in a token.
Reference: [18] <author> J. McDermott. </author> <title> R1: A rule-based configurer of computer system. </title> <booktitle> Artificail Intelligence, </booktitle> <year> 1982. </year>
Reference-contexts: 1 Introduction Although production systems have been widely applied in the implementation of a number of knowledge-based expert systems <ref> [18, 32] </ref>, the major problem faced by expert system technology is efficiency. The main technique to increase the processing speed of a production system is through parallelism and compilation. DFLOPS fully exploits both techniques. Many efforts have been proposed to speedup the performance of production system programs.
Reference: [19] <author> H.S.L M.I. Schor, T.P Daly and B.R. Tibbitts. </author> <title> Advanced rete matching algorithm. </title> <booktitle> In Proceedings of National conference of Artificial Intelligence, </booktitle> <pages> pages 226-232, </pages> <year> 1986. </year>
Reference-contexts: In software approaches Forgy presented the RETE match algorithm, developed for the OPS5 production system interpreter, to reduce redundant pattern matching [8]. Schor et al. modified the operations of RETE network to achieve improvement in efficiency and rule clarity <ref> [19] </ref>. Miranker proposed the TREAT matching algorithm [21] and lazy matching to improve the matching time [20]. In hardware approaches Stolfo gave four parallel matching algorithms and a parallel execution algorithm based on DADO machine, a tree-structured parallel machine for large rule-based expert systems [31, 30, 15, 28, 27]. <p> The software approaches <ref> [14, 21, 19, 12] </ref> can be classified as changing representation of important data structure and/or implementation of important operations, reducing processing by handling common cases efficiently, matching rules against working memory on demand, compiling and optimizing [21, 20].
Reference: [20] <author> D. P. Miranker, D. A. Brant, B. Lofaso, and D. Gadbois. </author> <title> On the performance of lazy matching in production systems. </title> <booktitle> In Proceedings of AAAI-90, </booktitle> <pages> pages 685-692, </pages> <year> 1990. </year>
Reference-contexts: Schor et al. modified the operations of RETE network to achieve improvement in efficiency and rule clarity [19]. Miranker proposed the TREAT matching algorithm [21] and lazy matching to improve the matching time <ref> [20] </ref>. In hardware approaches Stolfo gave four parallel matching algorithms and a parallel execution algorithm based on DADO machine, a tree-structured parallel machine for large rule-based expert systems [31, 30, 15, 28, 27]. Gupta implemented OPS5 production system on DADO to perform parallel matching [10]. <p> The software approaches [14, 21, 19, 12] can be classified as changing representation of important data structure and/or implementation of important operations, reducing processing by handling common cases efficiently, matching rules against working memory on demand, compiling and optimizing <ref> [21, 20] </ref>. In hardware approaches, some production system machines [25, 16, 11, 28, 30, 10] have been constructed. There are three applicable parallelism in production systems. 1.
Reference: [21] <author> D.P. Miranker. </author> <title> Treat: A better match algorithm for ai production systems. </title> <booktitle> In Proceedings of National conference of Artificial Intelligence, </booktitle> <pages> pages 36-41, </pages> <year> 1987. </year>
Reference-contexts: In software approaches Forgy presented the RETE match algorithm, developed for the OPS5 production system interpreter, to reduce redundant pattern matching [8]. Schor et al. modified the operations of RETE network to achieve improvement in efficiency and rule clarity [19]. Miranker proposed the TREAT matching algorithm <ref> [21] </ref> and lazy matching to improve the matching time [20]. In hardware approaches Stolfo gave four parallel matching algorithms and a parallel execution algorithm based on DADO machine, a tree-structured parallel machine for large rule-based expert systems [31, 30, 15, 28, 27]. <p> The software approaches <ref> [14, 21, 19, 12] </ref> can be classified as changing representation of important data structure and/or implementation of important operations, reducing processing by handling common cases efficiently, matching rules against working memory on demand, compiling and optimizing [21, 20]. <p> The software approaches [14, 21, 19, 12] can be classified as changing representation of important data structure and/or implementation of important operations, reducing processing by handling common cases efficiently, matching rules against working memory on demand, compiling and optimizing <ref> [21, 20] </ref>. In hardware approaches, some production system machines [25, 16, 11, 28, 30, 10] have been constructed. There are three applicable parallelism in production systems. 1.
Reference: [22] <author> K. Oflazer. </author> <title> Partitioning in parallel processing of production systems. </title> <booktitle> In Proceedings of the IEEE International Conference on Parallel Processing, </booktitle> <pages> pages 92-100. </pages> <publisher> IEEE, </publisher> <year> 1984. </year>
Reference-contexts: Gupta implemented OPS5 production system on DADO to perform parallel matching [10]. Oflazer proposed partitioning algorithms for production systems to maximize the effect of parallel matching <ref> [22] </ref>. <p> Since the original RETE network in a single processor is divided into several SUBRETE networks, the time required for the matching phase can be considerably reduced. Performance evaluation of LHS parallelism can be found in <ref> [22] </ref>. 3. RHS level Parallelism: The actions of a rule being fired can be assigned to different processors so that several differernt actions of the RHS can be processed simultaneously. Among them, the most significant parallelism are the rule level parallelism and the LHS level parallelism.
Reference: [23] <author> Gregory M. Papadopoulos. </author> <title> Implementation of a General-Purpose Dataflow Multiprocessor. </title> <publisher> MIT Press, </publisher> <year> 1991. </year> <month> 20 </month>
Reference-contexts: Among them, the most significant parallelism are the rule level parallelism and the LHS level parallelism. The latter reduces the matching time and the former reduces the total number of recognize-act cycles. 2.3 Data Flow Computations Most data flow machines such as MIT Tagged-Token Dataflow Architecture [1], Monsoon <ref> [23, 24] </ref>, EM-4 [26], were designed for general-purpose parallel numerical computations. As for data flow symbolic computations, GAMMA [6], AGM [2], KARDAMOM [4] have demonstrated that the data flow principle can be applied in database applications.
Reference: [24] <author> Gregory M. Papadopoulos and David E. Culler. Monsoon: </author> <title> an explicit token-store archi-tecture. </title> <booktitle> In Proceedings of IEEE Symp. on Computer Architectures, </booktitle> <pages> pages 82-91, </pages> <year> 1990. </year>
Reference-contexts: Among them, the most significant parallelism are the rule level parallelism and the LHS level parallelism. The latter reduces the matching time and the former reduces the total number of recognize-act cycles. 2.3 Data Flow Computations Most data flow machines such as MIT Tagged-Token Dataflow Architecture [1], Monsoon <ref> [23, 24] </ref>, EM-4 [26], were designed for general-purpose parallel numerical computations. As for data flow symbolic computations, GAMMA [6], AGM [2], KARDAMOM [4] have demonstrated that the data flow principle can be applied in database applications.
Reference: [25] <author> F. Schreiner and G. Zimmermann. </author> <title> Pesa i- a parallel architecture for production systems. </title> <booktitle> In Proceedings of the IEEE International Conference on Parallel Processing, </booktitle> <pages> pages 166-169, </pages> <year> 1987. </year>
Reference-contexts: The software approaches [14, 21, 19, 12] can be classified as changing representation of important data structure and/or implementation of important operations, reducing processing by handling common cases efficiently, matching rules against working memory on demand, compiling and optimizing [21, 20]. In hardware approaches, some production system machines <ref> [25, 16, 11, 28, 30, 10] </ref> have been constructed. There are three applicable parallelism in production systems. 1. Rule level Parallelism: At each match state, the interpreter identifies all the rules whose LHS are satisfied by current contents of the working memory.
Reference: [26] <author> Yoshinori Yamaguchi Shuichi Sakai and Kei Kiraki. </author> <title> An architecture of a dataflow single chip processor. </title> <booktitle> In Proceedings of IEEE Symp. on Computer Architectures, </booktitle> <pages> pages 46-53, </pages> <year> 1989. </year>
Reference-contexts: The latter reduces the matching time and the former reduces the total number of recognize-act cycles. 2.3 Data Flow Computations Most data flow machines such as MIT Tagged-Token Dataflow Architecture [1], Monsoon [23, 24], EM-4 <ref> [26] </ref>, were designed for general-purpose parallel numerical computations. As for data flow symbolic computations, GAMMA [6], AGM [2], KARDAMOM [4] have demonstrated that the data flow principle can be applied in database applications.
Reference: [27] <author> S. J. Stolfo. </author> <title> Initial performance of the DADO2 prototype. </title> <journal> IEEE Computer Special Issue on AI Machines, </journal> <volume> 20 </volume> <pages> 75-83, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: Miranker proposed the TREAT matching algorithm [21] and lazy matching to improve the matching time [20]. In hardware approaches Stolfo gave four parallel matching algorithms and a parallel execution algorithm based on DADO machine, a tree-structured parallel machine for large rule-based expert systems <ref> [31, 30, 15, 28, 27] </ref>. Gupta implemented OPS5 production system on DADO to perform parallel matching [10]. Oflazer proposed partitioning algorithms for production systems to maximize the effect of parallel matching [22].
Reference: [28] <author> S. J. Stolfo and Miranker D. </author> <title> The DADO poduction system machine. </title> <journal> Journal of Parallel and Distributed Systems, </journal> <month> August </month> <year> 1986. </year>
Reference-contexts: Miranker proposed the TREAT matching algorithm [21] and lazy matching to improve the matching time [20]. In hardware approaches Stolfo gave four parallel matching algorithms and a parallel execution algorithm based on DADO machine, a tree-structured parallel machine for large rule-based expert systems <ref> [31, 30, 15, 28, 27] </ref>. Gupta implemented OPS5 production system on DADO to perform parallel matching [10]. Oflazer proposed partitioning algorithms for production systems to maximize the effect of parallel matching [22]. <p> The software approaches [14, 21, 19, 12] can be classified as changing representation of important data structure and/or implementation of important operations, reducing processing by handling common cases efficiently, matching rules against working memory on demand, compiling and optimizing [21, 20]. In hardware approaches, some production system machines <ref> [25, 16, 11, 28, 30, 10] </ref> have been constructed. There are three applicable parallelism in production systems. 1. Rule level Parallelism: At each match state, the interpreter identifies all the rules whose LHS are satisfied by current contents of the working memory.
Reference: [29] <author> S. J. Stolfo, H.M. Dewan, and O. Wolfson. </author> <title> The PARULEL parallel rule language. </title> <booktitle> In Proceedings of the IEEE International Conference on Parallel Processing, pages II:36-45. IEEE, </booktitle> <year> 1991. </year>
Reference-contexts: The PEs executes the RHS actions and broadcasts the changed WMEs to other PEs. * Model D: Meta rules. Meta rules are a set of rules to decide which instantiations in a conflict set shall be synchronized <ref> [29] </ref>. Meta rules can be compiled into token instructions as the production rules described in section 3. The compiled meta rule instructions are then stored in the coordinator. This model works as follows: All the PEs perform LHS match and report the matched rules to the coordinator. <p> To execute MISD mode, Rules are partitioned into the sets and then load one set and the same WMEs to a PE. MISD is similar to Copy and Constraint technique <ref> [29] </ref>. 6.2 Simulation Environment The DFLOPS simulator is implemented with execution models A, B and C. The software environment is shown in Figure 7.
Reference: [30] <author> S. J. Stolfo and D. P. Miranker. DADO: </author> <title> A parallel processor for expert systems. </title> <booktitle> In Proceedings of the 1984 International Parallel Processing Conference, </booktitle> <pages> pages 74-82. </pages> <publisher> IEEE, </publisher> <year> 1984. </year>
Reference-contexts: Miranker proposed the TREAT matching algorithm [21] and lazy matching to improve the matching time [20]. In hardware approaches Stolfo gave four parallel matching algorithms and a parallel execution algorithm based on DADO machine, a tree-structured parallel machine for large rule-based expert systems <ref> [31, 30, 15, 28, 27] </ref>. Gupta implemented OPS5 production system on DADO to perform parallel matching [10]. Oflazer proposed partitioning algorithms for production systems to maximize the effect of parallel matching [22]. <p> The software approaches [14, 21, 19, 12] can be classified as changing representation of important data structure and/or implementation of important operations, reducing processing by handling common cases efficiently, matching rules against working memory on demand, compiling and optimizing [21, 20]. In hardware approaches, some production system machines <ref> [25, 16, 11, 28, 30, 10] </ref> have been constructed. There are three applicable parallelism in production systems. 1. Rule level Parallelism: At each match state, the interpreter identifies all the rules whose LHS are satisfied by current contents of the working memory.
Reference: [31] <author> S. J. Stolfo and D.E. Shaw. DADO: </author> <title> A tree-structured machine architecture for production systems. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 242-246, </pages> <year> 1982. </year>
Reference-contexts: Miranker proposed the TREAT matching algorithm [21] and lazy matching to improve the matching time [20]. In hardware approaches Stolfo gave four parallel matching algorithms and a parallel execution algorithm based on DADO machine, a tree-structured parallel machine for large rule-based expert systems <ref> [31, 30, 15, 28, 27] </ref>. Gupta implemented OPS5 production system on DADO to perform parallel matching [10]. Oflazer proposed partitioning algorithms for production systems to maximize the effect of parallel matching [22].
Reference: [32] <author> G.T. Vesonder and S. J. Stolfo. </author> <title> The ace system. </title> <booktitle> In Proceedings of the Workshop on Expert Systems, </booktitle> <address> Australia, </address> <month> August </month> <year> 1984. </year> <month> 21 </month>
Reference-contexts: 1 Introduction Although production systems have been widely applied in the implementation of a number of knowledge-based expert systems <ref> [18, 32] </ref>, the major problem faced by expert system technology is efficiency. The main technique to increase the processing speed of a production system is through parallelism and compilation. DFLOPS fully exploits both techniques. Many efforts have been proposed to speedup the performance of production system programs.
References-found: 32

