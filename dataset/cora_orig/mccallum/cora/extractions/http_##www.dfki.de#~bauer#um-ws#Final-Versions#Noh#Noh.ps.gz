URL: http://www.dfki.de/~bauer/um-ws/Final-Versions/Noh/Noh.ps.gz
Refering-URL: http://www.dfki.de/~bauer/um-ws/
Root-URL: 
Title: Bayesian Belief Update in Antiair Defense  
Author: Sanguk Noh and Piotr J. Gmytrasiewicz 
Affiliation: Department of Computer Science and Engineering University of Texas at Arlington  
Abstract: This research applies Bayesian learning for belief update to the antiair defense domain, in which an automated defense unit is to defend a specified territory from a number of attacking missiles. Bayesian learning enables an agent to adjust his beliefs about the possible models of the other agents, given the observation of their behaviors. Through the Recursive Modeling Method (RMM), agent can select his rational action by examining the expected utility of his alternative behaviors and coordinate with other agent by modeling their decision making in a distributed multiagent environment. Bayesian learning is used in conjunction with RMM for belief update. As a result, an agent can predict which models of the other agents are correct, and keep his knowledge up to date. We describe how Bayesian learning can be used in conjunction with RMM for decision making and coordination in the antiair defense domain and show experimental results. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. J. Gmytrasiewicz. </author> <title> On reasoning about other agents. </title> <editor> In M. Wooldridge, J. P. Muller, and M. Tambe, editors, </editor> <title> Intelligent Agents II: Agent Theories, Architectures, </title> <booktitle> and Languages, </booktitle> <pages> pages 143-155, </pages> <address> Berlin, 1996. </address> <publisher> Springer. </publisher>
Reference-contexts: For the purpose of coordinated decision making in a multiagent environment, our research uses the Recursive Modeling Method (RMM), previously reported in <ref> [1, 2] </ref>. RMM enables an agent to model the other agents and to rationally coordinate with them even if no protocol or overall plan can be established explicitly in advance. <p> We elaborate on the solution procedure in more detail in <ref> [1] </ref> and have also outlined a numerical method of dealing with the No-info models at [2]. The dynamic programming bottom-up solution starts at Level 2.
Reference: [2] <author> S. Noh and P. J. Gmytrasiewicz. </author> <title> Agent modeling in antiair defense. </title> <booktitle> To Appear in Proceedings of the Sixth International Conference on User Modeling, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: For the purpose of coordinated decision making in a multiagent environment, our research uses the Recursive Modeling Method (RMM), previously reported in <ref> [1, 2] </ref>. RMM enables an agent to model the other agents and to rationally coordinate with them even if no protocol or overall plan can be established explicitly in advance. <p> We elaborate on the solution procedure in more detail in [1] and have also outlined a numerical method of dealing with the No-info models at <ref> [2] </ref>. The dynamic programming bottom-up solution starts at Level 2.
Reference: [3] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year> <month> 6 </month>
Reference-contexts: Specifically, Bayesian learning <ref> [3] </ref> can be used to update agent's belief about the other agent by revising the probability associated with the other agent's model based on their observed behavior.
References-found: 3

