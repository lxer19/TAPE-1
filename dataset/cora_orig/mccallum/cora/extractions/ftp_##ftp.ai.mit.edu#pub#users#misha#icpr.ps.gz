URL: ftp://ftp.ai.mit.edu/pub/users/misha/icpr.ps.gz
Refering-URL: http://www.ai.mit.edu/people/misha/misha.html
Root-URL: 
Title: Abacus: A High-Performance Architecture for Vision  
Author: Michael Bolotski Rajeevan Amirtharajah Weip Chen Timothy Kutscha Thomas Simon Thomas F. Knight, Jr. 
Address: Cambridge, MA 02139  
Affiliation: MIT Artificial Intelligence Laboratory  
Abstract: Abacus is a second generation distributed bit-parallel (DBP) architecture based on a reconfigurable mesh. A DPB organization distributes each bit of a data item to a different processor to exploit bit-level parallelism. This paper describes details of the VLSI-oriented architecture, the implementation of several arithmetic operations, and performance figures for various early vision tasks. A single IC in a non-aggressive technology is capable of 1-5 billion 16-bit operations per second (GOPS). A prototype machine currently under construction, with a completion date of October 1994, is expected to deliver approximately 250 GOPS.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. A. Barman, M. Bolotski, D. Camporese, and J. J. Little. Silt: </author> <title> The Bit-Parallel Approach. </title> <booktitle> In International Conference on Pattern Recognition. IEEE, </booktitle> <year> 1990. </year>
Reference-contexts: As in the polymorphic torus, network switches were locally controlled, but groups of processors could be electrically connected. This feature allowed efficient connected components and global statistics algorithms. We introduced the DBP architecture in <ref> [1] </ref>. As discussed in that work, none of the earlier architectures are suitable for DPB operation which requires very fast reconfiguration, very low ALU and network circuitry area overhead, as well as sub-cycle communication time.
Reference: [2] <author> D. W. Blevins, E. W. Davis, R. A. Heaton, and J. H. Reif. Blitzen: </author> <title> A Highly Integrated Massively Parallel Machine. </title> <booktitle> In Frontiers of Parallel Computation '88, </booktitle> <year> 1988. </year>
Reference-contexts: There are also several research designs which have not been put into commercial production. These designs explored different aspects of SIMD architectures. For example, IBM's polymorphic torus concentrated on adding connection autonomy by the addition of locally reconfigurable network switches. The MCNC Blitzen project <ref> [2] </ref> updated the original MPP design for VLSI technology by adding on-chip RAM, local modification of addresses, and an X-grid 8-neighbor interconnect. A unique Some/None network intended for associative processing was stressed in the CAAAP architecture developed at the University of Massachusetts at Amherst.
Reference: [3] <author> M. Bolotski. </author> <title> Distributed Bit-Parallel Architecture and Algorithms for Early Vision. </title> <type> Master's thesis, </type> <institution> University of British Columbia, </institution> <month> Aug </month> <year> 1990. </year>
Reference-contexts: In an earlier paper, we introduced the idea of a distributed bit-parallel (DBP) architecture, in which a simple processing element is allocated to each bit of a data word <ref> [3] </ref>. In this work Acknowledgments: This research is supported in part by the Advanced Research Projects Agency under contract DABT63-92-C-0039. we describe the Abacus machine, a high-performance implementation of a DBP architecture. <p> For example, the polymorphic torus and the CAAPP use one-bit PEs and therefore require multiple cycles to change their network configuration. An implementation of the Silt DBP architecture was described in <ref> [3] </ref>. Like the actual implementation of the polymorphic torus, Silt only had horizontal and vertical bypass switches rather than a full crossbar. As a result, connection patterns that turned corners had to be handled by the software stepping through all four directions at every corner.
Reference: [4] <author> M. Bolotski, R. Barman, J. J. Little, and D. Camporese. Silt: </author> <title> A Distributed Bit-Parallel Architecture for Early Vision. </title> <journal> International Journal of Computer Vision, </journal> <volume> 11(1) </volume> <pages> 63-74, </pages> <month> Oct </month> <year> 1993. </year> <month> 13 </month>
Reference-contexts: Thus, a shift by 9 can be accomplished by two vertical shifts by 4, followed by a conventional snake shift by 1. Addition Fast addition relies on quick computation of the carry bit. A DBP algorithm based on the the well-known logarithmic-time technique was described in <ref> [4] </ref>. The algorithm "looks-ahead" at the carry by computing the eventual carry into each one-bit adder. <p> Since each stage of a logarithmic scan doubles propagation time, an entire scan operation requires between approximately 500 cycles, or 4 microseconds. This can be optimized further by pipelining bit transmission. 4.3 Vision Performance We described a number of vision algorithms on the Silt architecture in <ref> [4] </ref>. The Abacus machine alters implementation details of only the arithmetic operations; the vision algorithms remained unchanged.
Reference: [5] <author> E. L. </author> <title> Cloud. The Geometric Arithmetic Parallel Processor. </title> <booktitle> In Frontiers of Parallel Computation '88, </booktitle> <year> 1988. </year>
Reference-contexts: We then examine the performance on several early vision algorithms. 2 2 Previous Work Massively parallel architectures, especially mesh-based one-bit SIMD machines, have been the topic of significant research. Early examples include Goodyear's MPP [11], NCR's GAPP <ref> [5] </ref> , and ICL's DAP [6]. Subsequent commercial vendors such as Thinking Machines and Maspar augmented the simple one-bit mesh with hypercube-style communication networks, and floating-point support. There are also several research designs which have not been put into commercial production. These designs explored different aspects of SIMD architectures.
Reference: [6] <author> T. Fountain. </author> <title> Processor Arrays: Architectures and Applications. </title> <publisher> Harcourt Brace Jo-vanovich, </publisher> <year> 1987. </year>
Reference-contexts: We then examine the performance on several early vision algorithms. 2 2 Previous Work Massively parallel architectures, especially mesh-based one-bit SIMD machines, have been the topic of significant research. Early examples include Goodyear's MPP [11], NCR's GAPP [5] , and ICL's DAP <ref> [6] </ref>. Subsequent commercial vendors such as Thinking Machines and Maspar augmented the simple one-bit mesh with hypercube-style communication networks, and floating-point support. There are also several research designs which have not been put into commercial production. These designs explored different aspects of SIMD architectures.
Reference: [7] <author> J. G. Harris. </author> <title> The Coupled Depth/Slope Approach To Surface Reconstruction. </title> <type> Master's thesis, </type> <institution> MIT, </institution> <month> May </month> <year> 1986. </year>
Reference-contexts: Surface Reconstruction Surface reconstruction consists of determining the surface shape (height and slope) from a set of potentially sparse and noisy measurements. Harris <ref> [7] </ref> introduced the coupled depth/slope model for surface reconstruction and developed an iterative solution technique suitable for a mesh-based massively parallel computer.
Reference: [8] <author> B. K. P. Horn. </author> <title> Robot Vision. </title> <publisher> MIT Electrical Engineering and Computer Science Series. The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1986. </year>
Reference-contexts: The Abacus machine alters implementation details of only the arithmetic operations; the vision algorithms remained unchanged. Edge Detection The widely used Marr-Hildreth edge detection algorithm consists of filtering the image with a Gaussian filter, computing the Laplacian of the filtered image, and locating the zero crossings of the result <ref> [8] </ref>. Convolution with a Gaussian can be approximated by repeated convolution with a triangular filter, with weights 1 4 , 1 4 , requiring only arithmetic shifts and accumulates. Since the Gaussian filter is separable, it can be implemented by two one-dimensional convolutions.
Reference: [9] <author> J. J. Little and H. H. Bulthoff. </author> <title> Parallel Optical Flow Using Local Voting. AI Memo 929, </title> <publisher> MIT, </publisher> <month> July </month> <year> 1988. </year>
Reference-contexts: This algorithm only requires division by a constant, which can be implemented by a special purpose sequence of shifts and adds. A single iteration of the algorithm requires approximately 250 cycles. Optical Flow In correlation-based optical flow <ref> [9] </ref> the original image is displaced in a variety of directions, and at each displacement the difference between the two images is computed, and summed over a window.
Reference: [10] <author> O. L. MacSorley. </author> <title> High speed Arithmetic in Binary Computers. </title> <booktitle> Proceedings of the IRE, </booktitle> <volume> 49 </volume> <pages> 67-91, </pages> <year> 1961. </year>
Reference-contexts: It is interesting to note that accumulation is an inherently simpler and faster operation than addition, and yet conventional processors do not make the distinction. Multiplication A fast integer multiplication algorithm known as the modified Booth algorithm <ref> [10] </ref> is suitable for bit-parallel implementation. It uses a recoding technique to cut in half the number of required additions. A single iteration examines three adjacent bits of the multiplier and adds 0, 1, or 2 times the multiplicand to the sum.
Reference: [11] <author> Jerry L. Potter, </author> <title> editor. The Massively Parallel Processor. </title> <publisher> MIT Press Series in Scientific Computation. The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1985. </year> <month> 14 </month>
Reference-contexts: We then examine the performance on several early vision algorithms. 2 2 Previous Work Massively parallel architectures, especially mesh-based one-bit SIMD machines, have been the topic of significant research. Early examples include Goodyear's MPP <ref> [11] </ref>, NCR's GAPP [5] , and ICL's DAP [6]. Subsequent commercial vendors such as Thinking Machines and Maspar augmented the simple one-bit mesh with hypercube-style communication networks, and floating-point support. There are also several research designs which have not been put into commercial production.
References-found: 11

