URL: http://www.cs.utah.edu/~stenger/PAPERS/stenger-sinc-matrices.ps
Refering-URL: http://www.cs.utah.edu/~stenger/papers.html
Root-URL: 
Title: MATRICES OF SINC METHODS  
Author: Frank Stenger 
Note: Dedicated to W.B. Gragg on his 60 th Birthday  
Address: Salt Lake City, Utah 84112  
Affiliation: Department of Computer Science University of Utah  
Abstract: This paper gives a brief review of Sinc methods, with emphasis on the matrices of Sinc methods. A novel procedure is presented, based on Sinc convolution, for solving a Poisson problem over a rectangular region. Although some of the work of Gragg and Reichel may already be applied to the solution of Sinc-matrix problems, this paper also points to new directions of matrix research.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. AMMAR, and P. GADER, </author> <title> A Variant of the Gohberg-Semencul Formula Involving Circulant Matrices, </title> <note> SIAM J. Matrix Anal. Appl. </note> <author> v. </author> <month> 12 </month> <year> (1991) </year> <month> 534-540. </month>
Reference-contexts: Fox example, one could use Chebyshev polynomials (as interpolating polynomials) for approximating indefinite convolutions over <ref> [1; 1] </ref>, or a basis such as fe x L n (x)g 1 n=0 , with L n the Laguerre polynomial for approx imating indefinite convolutions over (0; 1). 4.
Reference: [2] <author> G.S. AMMAR and W.B. GRAGG, </author> <title> Implementation and Use of the Generalized Schur Algorithm. </title> <editor> In C.I. Byrnes and A.Lindquist, editors, </editor> <booktitle> "Computational and Combinatorial Methods in Systems Theory", </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> (1986) </year> <month> 265-280. </month>
Reference: [3] <author> G.S. AMMAR and W.B. GRAGG, </author> <title> The Generalized Schur Algorithm for the Superfast Solution of Toeplitz Systems. </title> <editor> In J. Gilewicz, M. Pindor, and W. Siemaszko, editors, </editor> <title> "Rational Approximation and its Applications in Mathematics and Physics", </title> # <booktitle> 1237 in Lecture Notes in Mathematics, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> (1987) </year> <month> 315-330. </month>
Reference-contexts: 1 Introduction and Summary Much of W.B. Gragg's mathematically beautiful work investigates the connection of Toeplitz matrices and rational approximation <ref> [3] </ref>. My area of research - Sinc methods is a family of approximation formulas that require matrix methods for their practical implementation [14,15,18,22]. <p> Indeed, the matrix stemming from the Sinc approximation of the first derivative, and the Sinc matrices stemming from Hilbert transforms are, in fact a Cauchy matries, and the methods of Boros, Kalath and Olshevski <ref> [3] </ref>, and Calvetti and Reichel [8,9] may be applied to the solution of such matrix problems. We also mention here that some of the work of Pereyra (see e.g., [11]) has connections with Stenger's work [17].
Reference: [4] <author> G.S. AMMAR and W.B. GRAGG, </author> <title> Superfast Solution of Real Positive Definite Toeplitz Systems, </title> <note> SIAM J. Matrix Anal. Appl., v.9 (1988) 61-76. </note>
Reference-contexts: For example, the leading Sinc matrices that approximate derivatives are always Toeplitz matrices, and the even order ones are, in fact negative definite. The work of Ammar and Gragg <ref> [4] </ref>, Gragg [12], and Heinig and Rost [13] applies to these.
Reference: [5] <author> G.S. AMMAR and W.B. GRAGG, </author> <title> Numerical Experience with a Superfast real Toeplitz Solver. "Linear Algebra and its Applications", </title> <publisher> v. </publisher> <month> 121 </month> <year> (1989) </year> <month> 185-206. </month>
Reference: [6] <author> T. BOROS, T. KAILATH, and V. OLSHEVSKI, </author> <title> Predictive Partial Pivoting and Backward Stability of Fast Algorithms for Solving Cauchy Linear Equations, </title> <note> submitted. </note>
Reference: [7] <author> H.G. BURCHARD and K. H OLLIG, </author> <title> N -Width and Entropy of H p Classes in L q (1; 1), </title> <journal> SIAM J. Math. </journal> <note> Anal., </note> <author> v. </author> <month> 16 </month> <year> (1985) </year> <month> 405-421. </month>
Reference-contexts: Sinc methods are close to optimal approximation methods in Sinc spaces of functions [7,14,21], and in this setting, there is some intersection with Gragg's work, inasmuch as it has been shown <ref> [7] </ref> that Sinc and rational approximation converge at the same rate in these Sinc spaces [14, 21], and inasmuch as Sinc methods, which are intimately related to FFT yield systems of equations which are frequently conveniently converted to circulant matrix problems, fl Supported by NSF grant # CCR-9307602 1 and the
Reference: [8] <author> D. CALVETTI and L. REICHEL, </author> <title> On the Solution of Cauchy Systems of Equations, </title> <journal> Elec. Trans. Numer. </journal> <note> Anal., v.4 (1996) 125-136. </note>
Reference: [9] <author> D. CALVETTI and L. REICHEL, </author> <title> Factorizations of Cauchy Matrices, </title> <note> submitted. </note>
Reference: [10] <author> T.S. CARLSON, J. DOCKERY, AND J. LUND, </author> <title> A Sinc-Collocation Method for Initial Value Problems, </title> <note> to appear in Math. Comp. </note>
Reference-contexts: In particular, it would be nice to know this for the case of the even order matrix I (1) , which is useful for solving first order initial value problems for ordinary differential equations <ref> [10] </ref>. * Sinc Quadrature: This simple Sinc approximation is described as fol lows.
Reference: [11] <author> G. Galemberti and V. Pereyra, </author> <title> Numerical Differentiation and the Solution of Vandermonde Systems, </title> <journal> Math. </journal> <note> Comp., </note> <author> V. </author> <month> 24 </month> <year> (1970) </year> <month> 357-364. </month>
Reference-contexts: We also mention here that some of the work of Pereyra (see e.g., <ref> [11] </ref>) has connections with Stenger's work [17]. The solution of some elliptic PDE problems via Sinc methods (see [15; 18, x7.4]) can also be carried out via diagonalization of matrices.
Reference: [12] <author> W.B. GRAGG, </author> <title> Positive Definite Toeplitz Matrices, the Anoldi Process for Isometric Operators, and Gaussian Quadrature on the Unit Circle, in "Numerical Methods in Linear Algebra, ed. E.S. Nikolaev, </title> <publisher> Moscow University Press, </publisher> <address> Moscow, </address> <year> (1982) </year> <month> 16-32. 18 </month>
Reference-contexts: For example, the leading Sinc matrices that approximate derivatives are always Toeplitz matrices, and the even order ones are, in fact negative definite. The work of Ammar and Gragg [4], Gragg <ref> [12] </ref>, and Heinig and Rost [13] applies to these.
Reference: [13] <author> G. HEINIG, and K. ROST, </author> <title> Algebraic Methods for Toeplitz-like Matrices and Operators, Operator Theory, </title> <publisher> V. 13, Birkhauser Verlag, </publisher> <address> Basel (1984). </address>
Reference-contexts: For example, the leading Sinc matrices that approximate derivatives are always Toeplitz matrices, and the even order ones are, in fact negative definite. The work of Ammar and Gragg [4], Gragg [12], and Heinig and Rost <ref> [13] </ref> applies to these.
Reference: [14] <author> M. KOWALSKI, K. SIKORSKI and F. STENGER, </author> <title> Selected Topics in Approximation and Computation, </title> <publisher> Oxford University Press (1993). </publisher>
Reference-contexts: Sinc methods are close to optimal approximation methods in Sinc spaces of functions [7,14,21], and in this setting, there is some intersection with Gragg's work, inasmuch as it has been shown [7] that Sinc and rational approximation converge at the same rate in these Sinc spaces <ref> [14, 21] </ref>, and inasmuch as Sinc methods, which are intimately related to FFT yield systems of equations which are frequently conveniently converted to circulant matrix problems, fl Supported by NSF grant # CCR-9307602 1 and the work of G. Ammar and P. Gader hass applications to such prob-lems. <p> The most important properties of these spaces are, in essence, that if f 2 M ff;fi (D), then <ref> [14; 18, x4.1] </ref> f 0 = 0 2 L ff;fi (D); if f 2 M ff;fi (D), and if (1= 0 ) 0 is uniformly bounded in D then f (n) =( 0 ) n 2 L ff;fi (D), n = 1; 2; 3; . <p> For the case of Sinc convolution, we assume, in essence, that the convolution of f and g belongs to M ff;fi (D). * Sinc Interpolation: This basic procedure is described in the following theorem. Theorem 2.4: <ref> [14; 18, x4.1] </ref> If f 2 M ff;fi (D), then as N ! 1, kf w V f k = O (" N ): (2:15) For Sinc interpolation, we may thus associate the unit matrix, I of order m, i.e., V f = I V f: (2:16) * Sinc Collocation: While <p> This is the point of the theorem of this section, which enables us to reduce 9 all Sinc computations to the solution of (linear or nonlinear) algebraic equations. Theorem 2.5: <ref> [14] </ref> If the conditions of Thm. 2.4 are satisfied, and if c = (c M ; ; c N ) T is a vector of complex numbers, such that 0 N X jf (z j ) c j j 2 A &lt; ffi N ; (2:17) where ffi N is a <p> Theorem 2.6: <ref> [14; 18, x4.4] </ref> If f 2 M ff;fi (D), and if (1=' 0 ) 0 is uni formly bounded in D, then, for k = 1; 2; ,as N ! 1, fl fl fl (' 0 ) k wD (h k =(' 0 ) k ) [w j (z i )] <p> In particular, it would be nice to know this for the case of the even order matrix I (1) , which is useful for solving first order initial value problems for ordinary differential equations [10]. * Sinc Quadrature: This simple Sinc approximation is described as fol lows. Theorem 2.7: <ref> [14; 18, x4.2] </ref> If f =' 0 2 L ff;fi (D), then, as N ! 1, fi fi Z f (x) dx (V (h=' 0 )) T V f fi fi = O (" N ): (2:23) Notice the linear algebraic "inner product" form of Sinc quadrature. <p> Theorem 2.8: <ref> [14; 18, x4.5] </ref> If f =' 0 2 L ff;fi (D), then, as N ! 1, k a f (t) dt (w A V f )(x)k = O (" N ) fl R b fl fl = O (" N ): In matrix notation, indefinite integration thus takes the form V <p> For Sinc collocation of p and q, we assume that: 1. The "Laplace transform" (2.26) exists for all s such that &lt;s &gt; 0; and (roughly see [19] for more precise assumptions) that 13 2. p and q belong to M ff;fi (D). Theorem 2.9: <ref> [14; 18, x4.6] </ref> If the above conditions are satisfied, and if A and B are defined as in (2.24) above, then, as N ! 1, kp w F (A) V gk = O (" N ); (2:28) The matrix equivalents of these two expressions are V p F (A) V g
Reference: [15] <author> J. LUND and K.L. BOWERS, </author> <title> Sinc Methods for Quadrature and Differential Equations, </title> <note> SIAM (1992). </note>
Reference-contexts: We also mention here that some of the work of Pereyra (see e.g., [11]) has connections with Stenger's work [17]. The solution of some elliptic PDE problems via Sinc methods (see <ref> [15; 18, x7.4] </ref>) can also be carried out via diagonalization of matrices. The contributions of Ammar and Gragg [2,3] can most definitely be used to speed up the algorithms for solving such problems.
Reference: [16] <author> A. NAGHSH-NILCHI, </author> <title> Sinc Convolution Method of Solving the Electric Field Integral Equations on R 2 fi R fi [0; T ], Ph.D. </title> <type> thesis, </type> <institution> University of Utah (1966). </institution>
Reference-contexts: It is easily seen that this is the case for an interval on R if and only if each eigenvalue of the matrix I (1) defined as for Thm. 2.8 above lies in the open right half plane (see [18, p.228]). Recently Naghsh-Nilchi (see e.g., <ref> [16] </ref>) numerically evaluated all of the eigenvalues of each matrix I (1) of orders 2 to 513, to find that the eigenvalues of all of these matrices do indeed lie in the open right half plane.
Reference: [17] <author> F. STENGER, </author> <title> Kronecker Product Extension of Linear Operators, </title> <note> SIAM J. Numer. Anal. </note> <author> V. </author> <month> 5 </month> <year> (1964) </year> <month> 422-435. </month>
Reference-contexts: We also mention here that some of the work of Pereyra (see e.g., [11]) has connections with Stenger's work <ref> [17] </ref>. The solution of some elliptic PDE problems via Sinc methods (see [15; 18, x7.4]) can also be carried out via diagonalization of matrices. The contributions of Ammar and Gragg [2,3] can most definitely be used to speed up the algorithms for solving such problems.
Reference: [18] <author> F. STENGER, </author> <title> Numerical Methods Based on Sinc and Analytic Functions, </title> <publisher> Springer-Verlag, </publisher> <address> N.Y. </address> <year> (1993). </year>
Reference-contexts: Ammar and P. Gader hass applications to such prob-lems. The Fourier transforms of Sinc series yield DFT formulas, and the approximation of Hilbert transforms via Sinc methods <ref> [18, Secs. 5.2, 3.4, 6.7] </ref> can involve Vandermonde matrices and Cauchy systems. For example, the leading Sinc matrices that approximate derivatives are always Toeplitz matrices, and the even order ones are, in fact negative definite. <p> We also mention here that some of the work of Pereyra (see e.g., [11]) has connections with Stenger's work [17]. The solution of some elliptic PDE problems via Sinc methods (see <ref> [15; 18, x7.4] </ref>) can also be carried out via diagonalization of matrices. The contributions of Ammar and Gragg [2,3] can most definitely be used to speed up the algorithms for solving such problems. <p> We set sinc (z) = sin (z) S (k; h) ffi (z) = sinc z with k 2 Z, the set of integers. Theorem 2.1: <ref> [18, x1.11] </ref> Under the above conditions, the identity f (z) = k=1 3 is valid for all z 2 C. <p> Theorem 2.2: <ref> [18, Ch. 3] </ref> If f 2 H 1 (D d ), if h &gt; 0, j is any fixed non-negative integer, and if ` 2 Z, then, as h ! 0: 4 fl fl fl f (x) k=1 fl fl fl = O e d sup h ; fi fi fi <p> If we can furthermore select ' such that: (i) With f 2 H 1 (D) , ' provides a conformal map of D to D d with D d defined as in (2.4); (ii) We have D; '() = R Theorem 2.3: <ref> [18, Ch. 4] </ref> If these conditions are satisfied, then, letting k 2 Z, j a positive integer, and denoting the Sinc points z k by z k = ' 1 (kh) (2:7) we have, as h ! 0, that: fl fl fl f (x) k=1 f (z k ) fl fl <p> We can usually remove the ambiguity in the above multiple choice cases, by considering a problem in view of the Sinc spaces which are described in Section 2.5. Many such considerations are illustrated in <ref> [18] </ref>. We illustrate this point below, for the case of Sinc quadrature. 2.5 Sinc Spaces Although the approximations (2.5) and (2.8) are very accurate, they still have one undesirable feature, namely, that we require the evaluation of an infinite series. <p> The notation L ff;fi (D) will be used for that subset of functions f 2 M ff;fi (D) for which f (a) = f (b) = 0. These Sinc spaces (and their appropriate extension to more than one dimension, as described in e.g. <ref> [18, Secs. 6.5 or 6.6] </ref>) house nearly all solutions to differential and integral equations in applications. <p> The most important properties of these spaces are, in essence, that if f 2 M ff;fi (D), then <ref> [14; 18, x4.1] </ref> f 0 = 0 2 L ff;fi (D); if f 2 M ff;fi (D), and if (1= 0 ) 0 is uniformly bounded in D then f (n) =( 0 ) n 2 L ff;fi (D), n = 1; 2; 3; . <p> For the case of Sinc convolution, we assume, in essence, that the convolution of f and g belongs to M ff;fi (D). * Sinc Interpolation: This basic procedure is described in the following theorem. Theorem 2.4: <ref> [14; 18, x4.1] </ref> If f 2 M ff;fi (D), then as N ! 1, kf w V f k = O (" N ): (2:15) For Sinc interpolation, we may thus associate the unit matrix, I of order m, i.e., V f = I V f: (2:16) * Sinc Collocation: While <p> Theorem 2.6: <ref> [14; 18, x4.4] </ref> If f 2 M ff;fi (D), and if (1=' 0 ) 0 is uni formly bounded in D, then, for k = 1; 2; ,as N ! 1, fl fl fl (' 0 ) k wD (h k =(' 0 ) k ) [w j (z i )] <p> We remark here that the Toeplitz matrices 10 I (k) = ffi ij (2:21) with ffi (k) j defined as in (2.6) arise repeatedly in the expression (2.19). Relatively little is known about these matrices. It may be shown, for example (see <ref> [18, pp. 477-478] </ref>), that every eigenvalue of the matrix I (2) of order m satisfies the inequality 2 &lt; &lt; (m + 1) 2 ; (2:22) and this fact enables us to easily deduce that the systems of equations arising when solving PDEs by Sinc methods are generally well conditioned. <p> In particular, it would be nice to know this for the case of the even order matrix I (1) , which is useful for solving first order initial value problems for ordinary differential equations [10]. * Sinc Quadrature: This simple Sinc approximation is described as fol lows. Theorem 2.7: <ref> [14; 18, x4.2] </ref> If f =' 0 2 L ff;fi (D), then, as N ! 1, fi fi Z f (x) dx (V (h=' 0 )) T V f fi fi = O (" N ): (2:23) Notice the linear algebraic "inner product" form of Sinc quadrature. <p> Theorem 2.8: <ref> [14; 18, x4.5] </ref> If f =' 0 2 L ff;fi (D), then, as N ! 1, k a f (t) dt (w A V f )(x)k = O (" N ) fl R b fl fl = O (" N ): In matrix notation, indefinite integration thus takes the form V <p> For Sinc collocation of p and q, we assume that: 1. The "Laplace transform" (2.26) exists for all s such that &lt;s &gt; 0; and (roughly see [19] for more precise assumptions) that 13 2. p and q belong to M ff;fi (D). Theorem 2.9: <ref> [14; 18, x4.6] </ref> If the above conditions are satisfied, and if A and B are defined as in (2.24) above, then, as N ! 1, kp w F (A) V gk = O (" N ); (2:28) The matrix equivalents of these two expressions are V p F (A) V g <p> It is easily seen that this is the case for an interval on R if and only if each eigenvalue of the matrix I (1) defined as for Thm. 2.8 above lies in the open right half plane (see <ref> [18, p.228] </ref>). Recently Naghsh-Nilchi (see e.g., [16]) numerically evaluated all of the eigenvalues of each matrix I (1) of orders 2 to 513, to find that the eigenvalues of all of these matrices do indeed lie in the open right half plane.
Reference: [19] <author> F. STENGER, </author> <title> Collocating Convolutions, </title> <journal> Math. Comp., </journal> <month> 64 </month> <year> (1995) </year> <month> 211-235. </month>
Reference-contexts: In presenting these convolution results, we shall assume that = (a; b) R. For Sinc collocation of p and q, we assume that: 1. The "Laplace transform" (2.26) exists for all s such that &lt;s &gt; 0; and (roughly see <ref> [19] </ref> for more precise assumptions) that 13 2. p and q belong to M ff;fi (D).
Reference: [20] <author> F. STENGER, SINC-PACK, I. </author> <title> Summary of Sinc Methods, </title> <note> See http://www.cs.utah.edu/~stenger/SINC.html. </note>
Reference: [21] <author> F. STENGER, </author> <title> Explicit, Nearly Optimal, Linear Rational Approximations with Preassigned Poles, </title> <journal> Math. </journal> <note> Comp., </note> <author> v. </author> <month> 47 </month> <year> (1986) </year> <month> 225-252. </month>
Reference-contexts: Sinc methods are close to optimal approximation methods in Sinc spaces of functions [7,14,21], and in this setting, there is some intersection with Gragg's work, inasmuch as it has been shown [7] that Sinc and rational approximation converge at the same rate in these Sinc spaces <ref> [14, 21] </ref>, and inasmuch as Sinc methods, which are intimately related to FFT yield systems of equations which are frequently conveniently converted to circulant matrix problems, fl Supported by NSF grant # CCR-9307602 1 and the work of G. Ammar and P. Gader hass applications to such prob-lems.
Reference: [22] <author> F. STENGER, B. BARKEY and R. VAKILI, </author> <title> Sinc Convolution Method of Solution of Burgers' Equation, pp. 341-354 of "Proceedings of Computation and Control III", edited by K. </title> <editor> Bowers and J. Lund, </editor> <publisher> Birkhauser, </publisher> <address> Basel (1993). </address>
Reference: [23] <author> F. STENGER, B. KEYES, M. O'REILLY, and K. PARKER, ODE-IVP|PACK, </author> <title> via Sinc Indefinite Integration and Newton Iteration, </title> <note> to appear in "Numerical Algorithms". </note>
Reference-contexts: N ) fl R b fl fl = O (" N ): In matrix notation, indefinite integration thus takes the form V a f (t) dt A V f R b (2:25) These equations have been used to develop a computer package for solving ordinary differential equation initial value problems <ref> [23] </ref>. * Sinc Convolution: For the case of Sinc convolution, we define matrices A and B as for Sinc indefinite integration above, and in addition we shall also require the "Laplace transform", F (s) = E where the quotes indicate that we have replaced the s in the usual Laplace transform
Reference: [24] <author> R.S. VARGA, </author> <title> Matrix Iterative Analysis, </title> <booktitle> Prentice-Hall (1962). </booktitle> <pages> 19 </pages>
Reference-contexts: The little that has been done to date on this subject suggests that these matrices have properties similar to the matrices of finite difference methods. A thorough study of these matrices, such as that of the beautiful work of Varga <ref> [24] </ref> would greatly enhance the use of Sinc methods of solving partial differential and integral equations. In the present paper we present the simple equations of Sinc approximations in both symbolic and linear algebraic forms, and we also state some unsolved matrix problems for these approximations.
References-found: 24

