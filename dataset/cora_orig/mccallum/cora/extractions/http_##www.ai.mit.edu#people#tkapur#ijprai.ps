URL: http://www.ai.mit.edu/people/tkapur/ijprai.ps
Refering-URL: http://www.ai.mit.edu/people/tkapur/publications.html
Root-URL: 
Title: Utilizing Segmented MRI Data in Image-Guided Surgery  
Author: W.E.L. Grimson G.J. Ettinger T. Kapur M.E. Leventon W.M. Wells III ; R. Kikinis 
Date: November 3, 1997  
Abstract: While the role and utility of Magnetic Resonance Images as a diagnostic tool is well established in current clinical practice, there are a number of emerging medical arenas in which MRI can play an equally important role. In this article, we consider the problem of image-guided surgery, and provide an overview of a series of techniques that we have recently developed in order to automatically utilize MRI-based anatomical reconstructions for surgical guidance and navigation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Axel, J. Costantini, and J. Listerud. </author> <title> Intensity Correction in Surface-Coil MR Imaging. </title> <journal> AJR, </journal> <volume> 148(4) </volume> <pages> 418-420, </pages> <year> 1987. </year>
Reference-contexts: We have also collected the following TMS data: * C t o | position and orientation of TMS coil at time t, t 2 <ref> [1; T ] </ref>, in Flashpoint coordi nates. * R t j | measured response j to stimulation t. Multiple responses are usually collected such as from several different hand, arm, and leg muscles.
Reference: [2] <author> N. Ayache. </author> <title> "Medical Computer Vision, Virtual Reality and Robotics". </title> <journal> Image and Vision Computing, </journal> <volume> 13 </volume> <pages> 295-313, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction In recent years, Magnetic Resonance Imaging (MRI) has become a commonplace medical diagnostic tool <ref> [2] </ref>, especially for cases involving soft tissue, such as in the brain.
Reference: [3] <author> G. Barnett, D. Kormos, C. </author> <title> Steiner. "Frameless Stereotaxy Using a Sonic Digitizing Wand: Development and Adaptation to the Picker ViStar Medical Imaging System". R.J. </title> <editor> Maciunas, ed., </editor> <title> Interactive Image-Guided Neurosurgery, </title> <journal> American Association of Neurological Surgeons, </journal> <year> 1993. </year>
Reference-contexts: Image-guided surgery is a quickly growing field-other researchers are developing related capabilities. Of note is the VISLAN system [6] which is also designed to be an end-to-end image-guided surgery system with many automated procedures. Other related image-guidance capabilities include <ref> [3, 4, 10, 16, 32, 38] </ref>.
Reference: [4] <author> D.R. Bucholtz, K.R. Smith. </author> <title> "A Comparison of Sonic Digitizers Versus Light Emitting Diode-Based Localization". R.J. </title> <editor> Maciunas, ed., </editor> <title> Interactive Image-Guided Neurosurgery, </title> <journal> American Association of Neurological Surgeons, </journal> <year> 1993. </year>
Reference-contexts: Image-guided surgery is a quickly growing field-other researchers are developing related capabilities. Of note is the VISLAN system [6] which is also designed to be an end-to-end image-guided surgery system with many automated procedures. Other related image-guidance capabilities include <ref> [3, 4, 10, 16, 32, 38] </ref>.
Reference: [5] <author> H. Cline, W. Lorensen, R. Kikinis, F. Jolesz, </author> <title> "3D Segmentation of MR Images of the Head Using Probability and Connectivity." </title> <booktitle> JCAT 14(6) </booktitle> <pages> 1037-1045, </pages> <year> 1990. </year> <month> 37 </month>
Reference-contexts: Similar to other approaches to intensity-based segmentation of MRI [12] <ref> [5] </ref>, the distribution for observed values is modeled as a normal distribution: p (Y i j i ; fi i ) = G (Y i ( i ) fi i ) ; (1) where G (x) p exp ( 2 x ) 2 ) is the scalar Gaussian distribution, with variance
Reference: [6] <author> A.C.F. Colchester, J. Zhao, K.S. Holton-Tainter, C.J. Henri, N. Maitland, P.T.E. Roberts, C.G. Harris, R.J. Evans, </author> <title> "Development and Preliminary Evaluation of VISLAN, a Surgical Planning and Guidance System Using Intra-Operative Video Imaging". </title> <journal> Medical Image Analysis, </journal> <volume> 1(1) </volume> <pages> 73-90, </pages> <year> 1996. </year>
Reference-contexts: This technology will be an important factor in accelerating the trend towards minimally-invasive surgeries. Image-guided surgery is a quickly growing field-other researchers are developing related capabilities. Of note is the VISLAN system <ref> [6] </ref> which is also designed to be an end-to-end image-guided surgery system with many automated procedures. Other related image-guidance capabilities include [3, 4, 10, 16, 32, 38].
Reference: [7] <author> A. Collignon, D. Verndermeulen, P. Suetens, and G. Marchal. </author> <title> "3D multi-modality medical image registration using feature space clustering". </title> <booktitle> In Proceedings of the First Conference on Computer Vision, Virtual Reality and Robotics in Medicine. </booktitle> <publisher> Springer, </publisher> <year> 1995. </year>
Reference-contexts: the intensities in the images rather than particular features and does not require an a priori model of the relationships between the intensities of the different images, it has proven to be a general approach applicable to a wide range of multi-modality fusion applications (in addition to [42], see also <ref> [7, 28] </ref>). The use of these techniques is illustrated in the following surgical example. The patient had a skull base meningioma which consisted of both intra- and extra-cranial parts. The 3D models were made from CT images and two sequences of MR images (see Figure 11).
Reference: [8] <author> A.P. Dempster, N.M. Laird, and D.B. Rubin. </author> <title> Maximum Likelihood from Incomplete Data via the EM Algorithm. </title> <journal> J. Roy. Statist. Soc., </journal> <volume> 39:1 - 38, </volume> <year> 1977. </year>
Reference-contexts: The EM algorithm was originally described in its general form by A.P. Dempster, N.M. Laird and D.B. Rubin in 1977 <ref> [8] </ref>. It is often used in estimation problems where some of the data is "missing". In this application the missing data is knowledge of the tissue classes if the tissue classes were known, then estimating the bias field would be straightforward. <p> The iteration may be started on either expression. Initial values for the weights will be needed to start with Equation 9, and initial values for the bias field will be needed to start with Equation 10. It is shown in <ref> [8] </ref> that in many cases the EM algorithm enjoys pleasant convergence properties namely that iterations will never worsen the value of the objective function. Provided that the bias estimates are bounded, our model satisfies the necessary conditions for guaranteed convergence.
Reference: [9] <author> J. Feldmar, N. Ayache. </author> <title> "Locally Affine Registration of Free-Form Surfaces". </title> <booktitle> Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Seattle WA, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: We then apply a 3D surface registration algorithm to match the laser data to the MRI data, as depicted in Figure 14 and described below. Further details are in [14]. Related surface-based registration approaches include <ref> [9, 15, 30, 36, 37, 44] </ref>. 5.1 Initial Match Before commencing the matching process we preprocess the laser data to separate data of the subject's head from background data.
Reference: [10] <author> R.L. Galloway. </author> <title> "Interactive Image Guided Neurosurgery". </title> <journal> IEEE Trans. Biomedical Engineering, </journal> <volume> 39 </volume> <pages> 1226-1231, </pages> <year> 1992. </year>
Reference-contexts: Image-guided surgery is a quickly growing field-other researchers are developing related capabilities. Of note is the VISLAN system [6] which is also designed to be an end-to-end image-guided surgery system with many automated procedures. Other related image-guidance capabilities include <ref> [3, 4, 10, 16, 32, 38] </ref>.
Reference: [11] <author> G. Gerig, O. Kubler, and F. Jolesz. </author> <title> Nonlinear Anisotropic Filtering of MRI data. </title> <journal> IEEE Trans. Med. Imaging, </journal> <volume> 11 </volume> <pages> 221-232, </pages> <year> 1992. </year>
Reference-contexts: The method has also been applied to spine phased-array and surface-coil images. All of the MR images shown in this section were obtained using a General Electric Signa 1.5 Tesla clinical MR imager. An anisotropic diffusion filter developed by Gerig et al. <ref> [11] </ref> was used as a pre-processing step to reduce noise. 2.2.1 Gradient Echo Brain This example describes white matter / gray matter segmentation in a coronal gradient echo acquisition. Figure 1 shows the input (gradient echo) image, acquired using a conventional "birdcage" head coil.
Reference: [12] <author> G. Gerig, W. Kuoni, R. Kikinis, and O. Kubler. </author> <title> Medical Imaging and Computer Vision: an Integrated Approach for Diagnosis and Planning. </title> <booktitle> Proc. 11'th DAGM Symposium, </booktitle> <pages> pages 425-443. </pages> <publisher> Springer, </publisher> <year> 1989. </year>
Reference-contexts: Similar to other approaches to intensity-based segmentation of MRI <ref> [12] </ref> [5], the distribution for observed values is modeled as a normal distribution: p (Y i j i ; fi i ) = G (Y i ( i ) fi i ) ; (1) where G (x) p exp ( 2 x ) 2 ) is the scalar Gaussian distribution, with
Reference: [13] <author> W.E.L. Grimson, G.J. Ettinger, S.J. White, P.L. Gleason, T. Lozano-Perez, W.M. Wells III, R. Kikinis. </author> <title> "Evaluating and Validating an Automated Registration System for Enhanced Reality Visualization in Surgery". </title> <booktitle> Proceedings of First International Conference on Computer Vision, Virtual Reality and Robotics in Medicine, </booktitle> <address> Nice France, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: Similarly, during the surgical procedure itself, this registered visualization allows the surgeon to view nearby structures as well as the position of the tumor relative to his current working area, thus providing navigation guidance to the surgeon. Initial computational experiments on the registration method <ref> [13] </ref> show that RMS errors of the registered points are on the order of the resolution of the MR images-generally 1.5 mm.
Reference: [14] <author> W.E.L. Grimson, G.J. Ettinger, S.J. White, T. Lozano-Perez, W.M. Wells III, and R. Kikinis. </author> <title> "An Automatic Registration Method for Frameless Stereotaxy, Image Guided Surgery, and Enhanced Reality Visualization". </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 15(2) </volume> <pages> 129-140, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: We then apply a 3D surface registration algorithm to match the laser data to the MRI data, as depicted in Figure 14 and described below. Further details are in <ref> [14] </ref>. Related surface-based registration approaches include [9, 15, 30, 36, 37, 44]. 5.1 Initial Match Before commencing the matching process we preprocess the laser data to separate data of the subject's head from background data.
Reference: [15] <author> A. Gueziec, N. Ayache. </author> <title> "Smoothing and Matching of 3-D Space Curves". </title> <booktitle> Proceedings of European Conference on Computer Vision, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: We then apply a 3D surface registration algorithm to match the laser data to the MRI data, as depicted in Figure 14 and described below. Further details are in [14]. Related surface-based registration approaches include <ref> [9, 15, 30, 36, 37, 44] </ref>. 5.1 Initial Match Before commencing the matching process we preprocess the laser data to separate data of the subject's head from background data.
Reference: [16] <author> B.L. Guthrie, R. Kaplan, P.J. Kelly. </author> <title> "Neurosurgical Stereotactic Operating Arm". </title> <journal> Stereotactic and Functional Neurosurgery, </journal> <volume> 54 </volume> <pages> 497-500, </pages> <year> 1995. </year>
Reference-contexts: Image-guided surgery is a quickly growing field-other researchers are developing related capabilities. Of note is the VISLAN system [6] which is also designed to be an end-to-end image-guided surgery system with many automated procedures. Other related image-guidance capabilities include <ref> [3, 4, 10, 16, 32, 38] </ref>.
Reference: [17] <author> R. Haralick, S. Sternberg, and X. Zhuang. </author> <title> "Image Analysis Using Mathematical Morphology". </title> <journal> IEEE Transactions PAMI, </journal> <volume> 9 </volume> <pages> 532-550, </pages> <year> 1987. </year>
Reference-contexts: We say "roughly" since there are other non-brain tissues in the scan that naturally overlap in intensity with the four classes mentioned above, and as a result are incorrectly classified into one of the four classes. We reduce these misclassifications by using mathematical morphology operations <ref> [17, 19, 33, 34] </ref> such as erosion and dilation, as well as connectivity analysis. The procedure we use to extract the brain from the labelled scan uses anatomical information about the relation of the brain to other non-brain tissue in the scan.
Reference: [18] <author> B.K.P. Horn, </author> <title> "Closed-Form Solution of Absolute Orientation Using Unit Quaternions", </title> <journal> Journal of the Optical Society of America A, </journal> <volume> 4, </volume> <month> April </month> <year> 1987, </year> <pages> pp. 629-642. </pages>
Reference-contexts: This transform is applied to the position/orientation of the surgical probe in order to then apply the laser data/MRI transformation described in Section 5. Since we may use more than three LEDs to track we use Horn's closed form least-squares solution based on quaternions <ref> [18] </ref> for the tracking transform.
Reference: [19] <author> K.H. Hohne and W. Hanson. </author> <title> "Interactive 3D Segmentation of MRI and CT Volumes Using Morphological Operations". </title> <journal> Journal of Computer Assisted Tomography, </journal> <volume> 16 </volume> <pages> 285-294, </pages> <year> 1992. </year> <month> 38 </month>
Reference-contexts: We say "roughly" since there are other non-brain tissues in the scan that naturally overlap in intensity with the four classes mentioned above, and as a result are incorrectly classified into one of the four classes. We reduce these misclassifications by using mathematical morphology operations <ref> [17, 19, 33, 34] </ref> such as erosion and dilation, as well as connectivity analysis. The procedure we use to extract the brain from the labelled scan uses anatomical information about the relation of the brain to other non-brain tissue in the scan.
Reference: [20] <editor> K. Hohne et al. </editor> <title> A framework for the Generation of 3D Anatomical Atlases. </title> <booktitle> In SPIE Vol. 1808, Visualization in Biomedical Computing 1992, </booktitle> <year> 1992. </year>
Reference: [21] <author> H. Jiang, R. Robb, K. Holton, </author> <title> "A New Approach to 3D Registration of Multimodality Medical Images by Surface Matching", </title> <booktitle> Proceedings of Visualization in Biomedical Computing, </booktitle> <year> 1992. </year>
Reference-contexts: This objective function acts much like a robust chamfer matching scheme (e.g. <ref> [21] </ref>). The expectation is that this second objective function is more accurate locally, since it is composed of saturated quadratic forms. We observe that while this refinement method gets very close to the best solution, it can get trapped into local minima in the minimization of E 2 .
Reference: [22] <author> R. Kikinis, C. Guttmann, D. Metcalf, W. Wells, G. Ettinger, H. Weiner, and F. Jolesz, </author> <title> Quantitative Follow-up of Patients with Multiple Sclerosis using MRI SPL Technical Report 39, </title> <month> October </month> <year> 1996. </year> <note> (http://splweb.bwh.harvard.edu:8000/pages/papers/ms/) </note>
Reference-contexts: Each subject was scanned every few weeks over a period of many months, and each scan was segmented both by the EM algorithm and by a supervised segmentation method employed by an expert radiologist. The results are shown in <ref> [22] </ref>.
Reference: [23] <author> R. Kikinis, F.A. Jolesz, W.E. Lorensen, H.E. Cline, P.E Stieg, and P. McL. Black. </author> <title> 3D Reconstruction of Skull Base Tumors from MRI Data for Neurosurgical Planning. </title> <booktitle> Proceedings of the Society of Magnetic Resonance in Medicine Conference, </booktitle> <year> 1991. </year>
Reference: [24] <author> R. Kikinis, M. Shenton, F. Jolesz, G. Gerig, J. Martin, M. Anderson, D. Metcalf, C. Guttmann, R.W. McCarley, W. Lorensen, and H. Cline. </author> <title> "Quantitative Analysis of Brain and Cerebrospinal Fluid Spaces with MR Imaging". </title> <journal> JMRI, </journal> <volume> 2 </volume> <pages> 619-629, </pages> <year> 1992. </year>
Reference-contexts: Two comparisons were performed. The method was compared to manual segmentation performed by experienced raters, and to a method of supervised multivariate classification. The images, manual segmentations, and supervised segmentations are described in <ref> [24] </ref>. An ROI was obtained by selecting those pixels that were labelled as brain tissue by four of the five raters in the manual segmentations. <p> The middle column shows the number of pixels that were classified differently by our 3-class (white matter, grey matter, csf) segmentation method as compared with manual segmentation for each of 20 cases of size 256x256x124 voxels. dealing <ref> [24] </ref>. In terms of the actual errors, we note from the tables that the bulk of the deviations between our boundaries and manually segmented boundaries are only 1 or 2 pixels.
Reference: [25] <author> K.O. Lim and A. Pfferbaum. </author> <title> Segmentation of MR Brain Images into Cerebrospinal Fluid Spaces, White and Gray Matter. </title> <journal> JCAT, </journal> <volume> 13(4) </volume> <pages> 588-593, </pages> <year> 1989. </year>
Reference: [26] <author> W.E. Lorensen, H.E. Cline, </author> <title> "Marching Cube: A High Resolution 3-D Surface Construction Algorithm", </title> <booktitle> Computer Graphics 21(3), </booktitle> <year> 1987, </year> <pages> pp. 163-169. </pages>
Reference-contexts: We use surface rendering techniques to display the segmented MRI structures. This procedure consists of first extracting bounding surfaces from the segmented MRI volume using the marching cubes algorithm <ref> [26] </ref>. This algorithm generates a set of connected triangles to represent the 3D surface for each segmented structure.
Reference: [27] <author> R.B. Lufkin, T. Sharpless, B. Flannigan, and W. Hanafee. </author> <title> Dynamic-Range Compression in Surface-Coil MRI. </title> <journal> AJR, </journal> <volume> 147(379) </volume> <pages> 379-382, </pages> <year> 1986. </year>
Reference: [28] <author> F. Maes, A. Collignon, D. Vandermeulen, G. Marchal, and P. Suetens. </author> <title> "Multi-modality image registration by maximization of mutual information", </title> <booktitle> in Proceedings of workshop on Mathematical Methods in Biomedical Image Analysis. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1996. </year>
Reference-contexts: the intensities in the images rather than particular features and does not require an a priori model of the relationships between the intensities of the different images, it has proven to be a general approach applicable to a wide range of multi-modality fusion applications (in addition to [42], see also <ref> [7, 28] </ref>). The use of these techniques is illustrated in the following surgical example. The patient had a skull base meningioma which consisted of both intra- and extra-cranial parts. The 3D models were made from CT images and two sequences of MR images (see Figure 11).
Reference: [29] <author> J.P. Mellor, </author> <title> "Realtime Camera Calibration for Enhanced Reality Visualization", </title> <booktitle> Proceedings of First International Conference on Computer Vision, Virtual Reality and Robotics in Medicine, </booktitle> <address> Nice France, </address> <month> April </month> <year> 1995, </year> <pages> pp. 471-475. </pages>
Reference-contexts: Figure 19 shows the position of the minimum latency response for all muscles that were mapped. 6.3 Alternative tracking methods We are also currently investigating the possibility of using a more passive system to track both head position and probe position and orientation. This method <ref> [29] </ref> utilizes some simple visual markers placed on the objects of interest, which are then tracked reliably and rapidly by observation in a single video camera.
Reference: [30] <author> C. Pelizzari, G. Chen, D. Spelbring, R. Weichselbaum, and C. Chen. </author> <title> "Accurate Three Dimensional Registration of CT, PET and/or MR Images of the Brain". </title> <journal> J. Comp. Assis. Tomogr., </journal> <volume> 13 </volume> <pages> 20-26, </pages> <year> 1989. </year>
Reference-contexts: We then apply a 3D surface registration algorithm to match the laser data to the MRI data, as depicted in Figure 14 and described below. Further details are in [14]. Related surface-based registration approaches include <ref> [9, 15, 30, 36, 37, 44] </ref>. 5.1 Initial Match Before commencing the matching process we preprocess the laser data to separate data of the subject's head from background data.
Reference: [31] <author> W.H. Press, S.A. Teukolsky, S.T. Vetterling, </author> <title> B.P. Flannery, Numerical Recipes in C, The Art of Scientific Computing, Second Edition, </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: In order to minimize this evaluation function we use the Davidon-Fletcher-Powell (DFP) quasi-Newton method <ref> [31] </ref>. This method requires an estimate of the gradient of the objective function, which is easily obtained in closed form. Solving this minimization problem yields an estimate for the pose of the laser points in MRI coordinates. We execute this minimization stage with a multiresolution set of Gaussians.
Reference: [32] <author> H.F. Reinhardt, G.A. Hortsmann, O. Gratzl. </author> <title> "Sonic Stereometry in Microsurgical Procedures for Deep-Seated Brain Tumors and Vascular Malformations". </title> <journal> Neurosurgery, </journal> <volume> 32 </volume> <pages> 114-117, </pages> <year> 1993. </year> <month> 39 </month>
Reference-contexts: Image-guided surgery is a quickly growing field-other researchers are developing related capabilities. Of note is the VISLAN system [6] which is also designed to be an end-to-end image-guided surgery system with many automated procedures. Other related image-guidance capabilities include <ref> [3, 4, 10, 16, 32, 38] </ref>.
Reference: [33] <author> S. Sandor and R. Leahy. </author> <title> "A 3D Morphological Algorithm for Automated Labelling of the Cortex in Magnetic Resonance Brain Images. </title> <booktitle> AAAI Spring Symposium Applications of Computer Vision in Medical Image Processing, </booktitle> <address> Palo Alto, CA., </address> <month> March </month> <year> 1994. </year>
Reference-contexts: We say "roughly" since there are other non-brain tissues in the scan that naturally overlap in intensity with the four classes mentioned above, and as a result are incorrectly classified into one of the four classes. We reduce these misclassifications by using mathematical morphology operations <ref> [17, 19, 33, 34] </ref> such as erosion and dilation, as well as connectivity analysis. The procedure we use to extract the brain from the labelled scan uses anatomical information about the relation of the brain to other non-brain tissue in the scan.
Reference: [34] <author> J. Serra. </author> <title> Image Analysis and Mathematical Morphology. </title> <publisher> London Academic, </publisher> <year> 1982. </year>
Reference-contexts: We say "roughly" since there are other non-brain tissues in the scan that naturally overlap in intensity with the four classes mentioned above, and as a result are incorrectly classified into one of the four classes. We reduce these misclassifications by using mathematical morphology operations <ref> [17, 19, 33, 34] </ref> such as erosion and dilation, as well as connectivity analysis. The procedure we use to extract the brain from the labelled scan uses anatomical information about the relation of the brain to other non-brain tissue in the scan.
Reference: [35] <editor> M. Shenton, R. Kikinis, and et al. F. Jolesz. Left Temporal Lobe Abnormalities in Schizophrenia and Thought Disorder. N. Engl. J. Med., </editor> <volume> 327 </volume> <pages> 604-612, </pages> <year> 1992. </year>
Reference: [36] <author> R. Szeliski and S. Lavallee. </author> <title> "Matching 3D Anatomical Surfaces with Non-Rigid Deformations Using Octree-Splines". </title> <booktitle> Proceedings of IEEE Workshop on Biomedical Image Analysis, </booktitle> <address> Seattle WA, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: We then apply a 3D surface registration algorithm to match the laser data to the MRI data, as depicted in Figure 14 and described below. Further details are in [14]. Related surface-based registration approaches include <ref> [9, 15, 30, 36, 37, 44] </ref>. 5.1 Initial Match Before commencing the matching process we preprocess the laser data to separate data of the subject's head from background data.
Reference: [37] <author> J.P. Thirion. </author> <title> "Extremal Points: Definition and Application to 3D Image Registration". </title> <booktitle> Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Seattle WA, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: We then apply a 3D surface registration algorithm to match the laser data to the MRI data, as depicted in Figure 14 and described below. Further details are in [14]. Related surface-based registration approaches include <ref> [9, 15, 30, 36, 37, 44] </ref>. 5.1 Initial Match Before commencing the matching process we preprocess the laser data to separate data of the subject's head from background data.
Reference: [38] <author> E. Watanabe. </author> <title> "A Potentiometer-Based Localization Arm System". R.J. </title> <editor> Maciunas, ed., </editor> <title> Interactive Image-Guided Neurosurgery, </title> <journal> American Association of Neurological Surgeons, </journal> <year> 1993. </year>
Reference-contexts: Image-guided surgery is a quickly growing field-other researchers are developing related capabilities. Of note is the VISLAN system [6] which is also designed to be an end-to-end image-guided surgery system with many automated procedures. Other related image-guidance capabilities include <ref> [3, 4, 10, 16, 32, 38] </ref>.
Reference: [39] <author> W.M. Wells, </author> <title> Statistical Object Recognition, </title> <type> MIT AI Technical Report 1398, </type> <month> January </month> <year> 1993. </year>
Reference-contexts: In particular, we sum, for all transformed laser points, a term that is a sum of the distances from the transformed laser point to all nearby MRI points, where the distance is weighted by a Gaussian distribution <ref> [39] </ref>. This Gaussian weighting roughly interpolates between the sampled MRI points to estimate the nearest point on the underlying surface to the transformed laser point.
Reference: [40] <author> W. Wells, R. Kikinis, E. Grimson, and F. Jolesz. </author> <title> "Statistical Intensity Correction and Segmentation of Magnetic Resonance Image Data". </title> <booktitle> Proceedings of the First Conference on Computer Vision, Virtual Reality and Robotics in Medicine. </booktitle> <publisher> Springer, </publisher> <year> 1995. </year>
Reference: [41] <author> W. Wells, R. Kikinis, E. Grimson, and F. Jolesz. </author> <title> "Adaptive Segmentation of MRI Data". </title> <journal> IEEE Transactions on Medical Imaging, </journal> <note> To Appear, </note> <year> 1996. </year>
Reference-contexts: This section describes a statistical method that uses knowledge of tissue properties and gain inhomogeneities to correct the gain artifact of MRI. The result is a method that provides both more accurate segmentation of tissue types and better visualization of MRI data. Additional details may be found in <ref> [41] </ref>. 2.1 Description of Method If either the RF gain or the tissue type is known at an image location, then it is relatively easy to use models of the imaging process to infer the other parameter at that location, given the measured signal. <p> This single-channel implementation accommodates two tissue classes, and uses an input segmentation to limit the region of interest (ROI) to be classified and gain-corrected. Subsequent implementations accomodate multi-channel data and more general tissue models <ref> [41] </ref>. The algorithm of Section 2.1.2 is initiated on the "E step", Equation 10, with a flat initial bias field. A moving-average lowpass filter was used for the operator H in Equation 9.
Reference: [42] <author> W.M. Wells III, P. Viola, H. Atsumi, S. Nakajima, R. Kikinis. </author> <title> "Multi-Modal Volume Registration by Maximization of Mutual Information". </title> <journal> Medical Image Analysis, </journal> <volume> 1(1) </volume> <pages> 35-51, </pages> <year> 1996. </year>
Reference-contexts: Volume reg-istration is performed by using an information-theoretic approach which maximizes a mutual information metric <ref> [42] </ref>. <p> based solely on the intensities in the images rather than particular features and does not require an a priori model of the relationships between the intensities of the different images, it has proven to be a general approach applicable to a wide range of multi-modality fusion applications (in addition to <ref> [42] </ref>, see also [7, 28]). The use of these techniques is illustrated in the following surgical example. The patient had a skull base meningioma which consisted of both intra- and extra-cranial parts. The 3D models were made from CT images and two sequences of MR images (see Figure 11).
Reference: [43] <author> A. Witkin, M. Kass, and D. Terzopoulos. "Snakes: </author> <title> Active Contour Models". </title> <journal> International Journal of Computer Vision, </journal> <volume> 1(4) </volume> <pages> 321-331, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Such scenarios are currently detected by manual inspection, and are corrected by the use of deformable models, such as snakes <ref> [43] </ref>, customized to this application. For segmenting tissues which are not modeled for the automatic methods, such as tumors, an interactive segmentor is used by clinicians. This tool, developed by the Surgical Planning Lab at Brigham & Women's Hospital, uses real-time ray tracing running on a Thinking Machines Inc.
Reference: [44] <author> Z. Zhang. </author> <title> "Iterative Point Matching for Registration of Free-Form Curves and Surfaces". </title> <journal> IJCV, </journal> <volume> 13(2) </volume> <pages> 119-152, </pages> <year> 1994. </year>
Reference-contexts: We then apply a 3D surface registration algorithm to match the laser data to the MRI data, as depicted in Figure 14 and described below. Further details are in [14]. Related surface-based registration approaches include <ref> [9, 15, 30, 36, 37, 44] </ref>. 5.1 Initial Match Before commencing the matching process we preprocess the laser data to separate data of the subject's head from background data.
References-found: 44

