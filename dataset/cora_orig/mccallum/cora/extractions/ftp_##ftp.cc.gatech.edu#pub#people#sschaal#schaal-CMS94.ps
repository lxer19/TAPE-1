URL: ftp://ftp.cc.gatech.edu/pub/people/sschaal/schaal-CMS94.ps
Refering-URL: ftp://ftp.cc.gatech.edu/pub/people/sschaal/schaal-CMS94.html
Root-URL: 
Title: Control Systems Magazine, 14, 1, pp.57-71. Robot Juggling: An Implementation of Memory-based Learning  
Author: Stefan Schaal and Christopher G. Atkeson 
Abstract: This paper explores issues involved in implementing robot learning for a challenging dynamic task, using a case study from robot juggling. We use a memory-based local model - ing approach (locally weighted regression) to represent a learned model of the task to be performed. Statistical tests are given to examine the uncertainty of a model, to optimize its pre diction quality, and to deal with noisy and corrupted data. We develop an exploration algorithm that explicitly deals with prediction accuracy requirements dur ing explo - ration. Using all these ingredients in combination with methods from optimal control, our robot achieves fast real - time learning of the task within 40 to 100 trials. * Address of both authors: Massachusetts Institute of Technology, The Artificial Intelligence Laboratory & The Department of Brain and Cognitive Sciences, 545 Technology Square, Cambride, MA 02139, USA. Email: ss-chaal@ai.mit.edu, cga@ai.mit.edu. Support was provided by the Air Force Office of Sci entific Research and by Siemens Cor pora tion. Support for the first author was provided by the Ger man Scholar ship Foundation and the Alexander von Hum boldt Founda tion. Support for the second author was provided by a Na tional Sci ence Foundation Pre sidential Young Investigator Award. We thank Gideon Stein for im ple ment ing the first version of LWR on the i860 microprocessor, and Gerrie van Zyl for build ing the devil stick robot and implementing the first version of devil stick learning. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aboaf, E. W., Atkeson, C. G. ,Reinkensmeyer, D. J. </author> <year> (1988), </year> <title> Task-Level Robot Learning, </title> <booktitle> Proceedings of IEEE International Conference on Robotics and Automation, </booktitle> <address> April 24-29, Philadelphia, Pennsylvania (1988). </address>
Reference-contexts: Past work tested our ideas by imple - menting learning for oneshot or static tasks, such as throwing a ball at a target <ref> [1] </ref>, and also repetitive or dynamic tasks, such as bouncing a ball on a paddle [2] and hitting a stick back and forth (a form of juggling known as devil sticking) [40].
Reference: [2] <author> Aboaf, </author> <title> E.W., </title> <type> Drucker, S.M., Atkeson, C.G. </type> <year> (1989), </year> <title> Task-Level Robot Learing: Juggling a Tennis Ball More Accurately, </title> <booktitle> Proceedings of IEEE Interational Conference on Robotics and Automation , May 14-19, </booktitle> <address> Scottsdale, Arizona (1989). </address>
Reference-contexts: Past work tested our ideas by imple - menting learning for oneshot or static tasks, such as throwing a ball at a target [1], and also repetitive or dynamic tasks, such as bouncing a ball on a paddle <ref> [2] </ref> and hitting a stick back and forth (a form of juggling known as devil sticking) [40].
Reference: [3] <author> An, C.H., Atkeson, C.G., Hollerbach, J.M. </author> <year> (1988), </year> <title> Model-Based Control of A Robot Manipulator , Cambridge, </title> <address> MA: </address> <publisher> MIT Press (1988). </publisher> <address> [4] strm, K.J., Wittenmark, </address> <publisher> B. </publisher> <year> (1989), </year> <title> Adaptive Control, </title> <address> Reading, MA: </address> <publisher> Addison-Wesley (1989). </publisher>
Reference-contexts: Despite the computational complexity of these methods, we demonstrated the useful ness of our algorithms in a real-time implementation of robot learning. 23 Using models for control according to the certainty equivalence principle is nothing new and has been supported by many researchers in the last years (e.g., <ref> [3, 38, 22, 24] </ref>). Using memory-based or nonpara metric models, however, has only recently received in - creasing interest. One of the favor able advantages of memory-based modeling lies in the least commitment strategy which is associated with it.
Reference: [5] <author> Atkeson, C.G. </author> <year> (1990), </year> <title> Memory-Based Approaches to Approximating Continuous Functions, </title> <publisher> MIT, </publisher> <address> Cambridge, MA: </address> <institution> The AILab and the Brain and Cognitive Sciences Department (1990). </institution>
Reference: [6] <author> Atkeson, C.G. </author> <year> (1994), </year> <title> Using Local Trajectory Optimizers to Speed Up Global Optimization in Dynamic Programming, </title> <note> to appear in: </note> <editor> Moody, J.E., Hanson, S.J., and Lippmann, R.P. (eds.) </editor> <booktitle> Advances in Neural Information Processing Systems 6 , Morgan Kaufmann (1994). </booktitle>
Reference-contexts: 0 1 2 3 4 5 6 7 8 (c) 0 2 4 6 8 niques: (a) nearest neighbor; (b) weighted average; (c) locally weighted regression As the most generic approximator that satisfies many of these criteria, we explore a version of memory-based learning techniques called locally weighted regression (LWR). <ref> [15, 16, 11, 6, 24, 14, 27] </ref>. A memory-based learning (MBL) system is trained by storing the training data in a memory. This allows MBL systems to achieve real-time learning. MBL avoids interference between new and old data by retain ing and using all the data to answer each query. <p> One part of our future work will address these is - sues in more detail in that we search for good initial actions and strategies to approach a task <ref> [6] </ref>. Conclusions The paper demonstrated that a real robot can indeed learn a nontrivial task. As pointed out above, by taking input/output representations and good learning goals as given, a large portion of the task was already solved in advance.
Reference: [7] <author> BarShalom, Y. </author> <year> (1981), </year> <title> Stochastic Dynamic Programming: Caution and Probing, </title> <journal> IEEE Transactions on Automatic Control, vol.AC-26, </journal> <volume> no.5, </volume> <month> October </month> <year> 1981 (1981). </year>
Reference-contexts: Such situations were addressed by Feldbaum [17] as the dual control problem. In his formu la - tions, the optimal command tries to minimize the cost and the uncertainty at the same time. So far, only expensive numerical solutions based on dynamic programming have been found to this problem <ref> [4, 7] </ref>. As an inelegant but effec tive way out, we add some small amount of random noise to the com mand F * . The next section will demonstrate the importance of this measure. Exploration has many facets.
Reference: [8] <author> Bellman, R. </author> <year> (1957), </year> <title> Dynamic Programming. </title> <publisher> Princeton, </publisher> <address> N.J.: </address> <publisher> Princeton University Press (1957). </publisher>
Reference-contexts: Optimal Control Approaches Learning approaches that do not commit to a particular representational form generate nu - me rical repre sen tations, for which optimal control techniques provide natural methods to 5 design control systems for nonlinear tasks. Dynamic programming <ref> [8, 9, 13] </ref> lays the basis for a general paradigm of nonlinear controllers. In our formulation of the regulation prob - lem, a goal state x d is given, which is typically an equilibrium state, so x d = f x d , 0 ( ) .
Reference: [9] <author> Bertsekas, D.P. </author> <year> (1987), </year> <title> Dynamic Programming, </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall (1987). </publisher>
Reference-contexts: Optimal Control Approaches Learning approaches that do not commit to a particular representational form generate nu - me rical repre sen tations, for which optimal control techniques provide natural methods to 5 design control systems for nonlinear tasks. Dynamic programming <ref> [8, 9, 13] </ref> lays the basis for a general paradigm of nonlinear controllers. In our formulation of the regulation prob - lem, a goal state x d is given, which is typically an equilibrium state, so x d = f x d , 0 ( ) .
Reference: [10] <author> Bitmead, R. R., Gevers, M., Wertz, V. </author> <year> (1990), </year> <title> Adaptive Optimal Control , Englewood Cliffs NJ: </title> <publisher> Prentice Hall (1990). </publisher> <pages> 26 </pages>
Reference-contexts: Predictive control design techniques avoid using a value function, but are then merely locally optimal <ref> [10] </ref>. Value functions can also be approxi mated, e.g., with neural networks [42]. We are interested in exploring approxima tions to value func - tions that produce a locally quadratic model of V x ( ) in a lo cal neigh borhood of x .
Reference: [11] <author> Cleveland, W.S., Devlin, S.J., Grosse, E. </author> <year> (1988), </year> <title> Regression by Local Fitting: Methods, Properties, and Computational Algorithms. </title> <journal> Journal of Econometrics 37, </journal> <pages> 87-114, </pages> <publisher> North-Holland (1988). </publisher>
Reference-contexts: Weighted averaging and nearest neighbor methods are presumably the best known non parametric approaches. We are investigating a recently developed nonparametric (memory-based) statistical tech nique, lo cally weighted regression (LWR), to model the system we are trying to con - trol <ref> [11, 15, 16] </ref>. The LWR approach allows us to efficiently estimate local linear models for different points in the state space. <p> 0 1 2 3 4 5 6 7 8 (c) 0 2 4 6 8 niques: (a) nearest neighbor; (b) weighted average; (c) locally weighted regression As the most generic approximator that satisfies many of these criteria, we explore a version of memory-based learning techniques called locally weighted regression (LWR). <ref> [15, 16, 11, 6, 24, 14, 27] </ref>. A memory-based learning (MBL) system is trained by storing the training data in a memory. This allows MBL systems to achieve real-time learning. MBL avoids interference between new and old data by retain ing and using all the data to answer each query.
Reference: [12] <author> Duda, R.O., Hart, P.E. </author> <year> (1973), </year> <title> Pattern Classification and Scene Analysis , New York, </title> <publisher> NY: Wiley (1973). </publisher>
Reference-contexts: Common algorithms to choose the subset or the weighting are, for ex ample, n-near est neighbor methods (e.g., <ref> [12, 25] </ref>) or kernel re gression (e.g., [19, 28, 37]). Com mon functions are (hyper-)planes or (hyper-)qua dratic surfaces.
Reference: [13] <author> Dyer, P., McReynolds, S.R. </author> <year> (1970), </year> <title> The Computation and Theory of Opitmal Control, </title> <address> New York: </address> <publisher> Academic Press (1970). </publisher>
Reference-contexts: Optimal Control Approaches Learning approaches that do not commit to a particular representational form generate nu - me rical repre sen tations, for which optimal control techniques provide natural methods to 5 design control systems for nonlinear tasks. Dynamic programming <ref> [8, 9, 13] </ref> lays the basis for a general paradigm of nonlinear controllers. In our formulation of the regulation prob - lem, a goal state x d is given, which is typically an equilibrium state, so x d = f x d , 0 ( ) . <p> current T , F, x next T ) best T and its local linear model results from a corresponding LWR lookup: x S,out = f (x S,in , F S ) Ax S,in + BF S + c . (4.3) Based on this linear model, an optimal LQ controller (e.g., <ref> [13] </ref>) can be constructed by minimizing the cost: J = (x k - x S,in ) Q (x k - x S,in ) + r F k - F S ( ) ( ) of the regulator problem: x k +1 - x S,out = A x k - x S,in <p> By no means was the SSA algorithm intended to replace high-level controllers. Indeed, it remains to be explored in how far the chaining of individual LQ controllers is actually robust, and whether an approach from trajectory optimization <ref> [13] </ref> would not be more appropriate. In favor of the SSA al gorithm stands its easy implementation for real - time systems. Two crucial prerequisites entered our explanations on robot learning.
Reference: [14] <author> Fan, J., Gijbels, I. </author> <year> (1992), </year> <title> Variable Bandwidth And Local Linear Regression Smoothers, </title> <journal> The Annals of Statistics, vol.20, </journal> <volume> no.4, </volume> <year> pp.2008-2036 (1992). </year>
Reference-contexts: 0 1 2 3 4 5 6 7 8 (c) 0 2 4 6 8 niques: (a) nearest neighbor; (b) weighted average; (c) locally weighted regression As the most generic approximator that satisfies many of these criteria, we explore a version of memory-based learning techniques called locally weighted regression (LWR). <ref> [15, 16, 11, 6, 24, 14, 27] </ref>. A memory-based learning (MBL) system is trained by storing the training data in a memory. This allows MBL systems to achieve real-time learning. MBL avoids interference between new and old data by retain ing and using all the data to answer each query.
Reference: [15] <author> Farmer, J.D., Sidorowich, J.J. </author> <year> (1987), </year> <title> Predicting Chaotic Dynamics, </title> <editor> Kelso, J.A.S., Mandell, A.J., Shlesinger, M.F., (eds.): </editor> <title> Dynamic Patterns in Complex Systems, </title> <publisher> World Scientific Press (1987). </publisher>
Reference-contexts: Weighted averaging and nearest neighbor methods are presumably the best known non parametric approaches. We are investigating a recently developed nonparametric (memory-based) statistical tech nique, lo cally weighted regression (LWR), to model the system we are trying to con - trol <ref> [11, 15, 16] </ref>. The LWR approach allows us to efficiently estimate local linear models for different points in the state space. <p> 0 1 2 3 4 5 6 7 8 (c) 0 2 4 6 8 niques: (a) nearest neighbor; (b) weighted average; (c) locally weighted regression As the most generic approximator that satisfies many of these criteria, we explore a version of memory-based learning techniques called locally weighted regression (LWR). <ref> [15, 16, 11, 6, 24, 14, 27] </ref>. A memory-based learning (MBL) system is trained by storing the training data in a memory. This allows MBL systems to achieve real-time learning. MBL avoids interference between new and old data by retain ing and using all the data to answer each query.
Reference: [16] <author> Farmer, J.D., Sidorowich, J.J. </author> <year> (1988), </year> <title> Exploiting Chaos to Predict the Future and Reduce Noise, </title> <type> Technical Report LA-UR-88-901, </type> <institution> Los Alamos National Laboratory, </institution> <address> Los Alamos, NM (1988). </address>
Reference-contexts: Weighted averaging and nearest neighbor methods are presumably the best known non parametric approaches. We are investigating a recently developed nonparametric (memory-based) statistical tech nique, lo cally weighted regression (LWR), to model the system we are trying to con - trol <ref> [11, 15, 16] </ref>. The LWR approach allows us to efficiently estimate local linear models for different points in the state space. <p> 0 1 2 3 4 5 6 7 8 (c) 0 2 4 6 8 niques: (a) nearest neighbor; (b) weighted average; (c) locally weighted regression As the most generic approximator that satisfies many of these criteria, we explore a version of memory-based learning techniques called locally weighted regression (LWR). <ref> [15, 16, 11, 6, 24, 14, 27] </ref>. A memory-based learning (MBL) system is trained by storing the training data in a memory. This allows MBL systems to achieve real-time learning. MBL avoids interference between new and old data by retain ing and using all the data to answer each query.
Reference: [17] <author> Fel'dbaum, A.A. </author> <year> (1965), </year> <title> Optimal Control Systems , New York, </title> <publisher> NY: Academic Press (1965). </publisher>
Reference-contexts: In or der to identify the local model correctly, the stochastic process must provide data in all dimensions of the input and output space. If not, the regression problem (3.1a) may be ill-conditioned, resulting in bad estimates of the local model. Such situations were addressed by Feldbaum <ref> [17] </ref> as the dual control problem. In his formu la - tions, the optimal command tries to minimize the cost and the uncertainty at the same time. So far, only expensive numerical solutions based on dynamic programming have been found to this problem [4, 7].
Reference: [18] <author> Hampbell, F., Rousseeuw, P, Ronchetti, E, Stahel, W. </author> <year> (1985), </year> <title> Robust Statistics, </title> <publisher> Wiley International (1985). </publisher>
Reference-contexts: In Figure 3a we added three outliers to the test data of Figure 2 to demonstrate this effect; the charts in Figure 2 should be compared to Figure 2c. [27] applied the median absolute deviation procedure from robust statistics <ref> [18] </ref> to globally remove outliers in LWR. We would like to local ize our criterion for outlier re - moval. The PRESS statistic can be modified to serve as an outlier detector in LWR. For this, we need the standardized individual PRESS residual e i,cross (see Table 1, Appendix A).
Reference: [19] <author> Hrdle, W. </author> <year> (1991), </year> <title> Smoothing Techniques with Implementation in S, </title> <address> New York, NY: </address> <publisher> Springer (1991). </publisher>
Reference-contexts: Common algorithms to choose the subset or the weighting are, for ex ample, n-near est neighbor methods (e.g., [12, 25]) or kernel re gression (e.g., <ref> [19, 28, 37] </ref>). Com mon functions are (hyper-)planes or (hyper-)qua dratic surfaces.
Reference: [20] <author> Hertz, J., Krogh, A., Palmer, R.G. </author> <year> (1991), </year> <title> Introduction to the Theory of Neural Computation , Redwood City, </title> <address> CA: </address> <publisher> Addison Wesley (1991). </publisher>
Reference-contexts: Training a nonlinear parametric model typically requires an itera - tive search for the appropriate parameters. Examples of iterative search are the various gradient descent techniques used to train neural network models (e.g., <ref> [20] </ref>). Lookup or evaluating a memory based model is computationally expensive, as described in this paper. Lookup for a nonlinear parametric model is often rela tively inexpensive.
Reference: [21] <author> Isermann, R., Lachmann , K.-H., Matko, D. </author> <year> (1992), </year> <title> Adaptive Control Systems , New York, </title> <publisher> NY: Prentice Hall, </publisher> <year> (1992). </year>
Reference-contexts: A common formulation requires the plant be repre sentable accurately by a feedback linearizable model in which all unknown ele ments appear linearly as a parameter vector. A more black box approach to adaptive control <ref> [21] </ref> is to use a form of parametric Volterra series in the inputs and states. Single hidden layer perceptron-like neural network models essentially project the input data along a line given by the input weights, and then output a one di mensional function of the value of that projection.
Reference: [22] <author> Jordan, I.M. , Rumelhart, D.E.(1990), </author> <title> Forward Models: Supervised Learning with a Distal Teacher, </title> <institution> MIT Center for Cognitive Science Occasional Paper 40 , Cambridge, </institution> <address> MA: MIT(1990). </address>
Reference-contexts: Despite the computational complexity of these methods, we demonstrated the useful ness of our algorithms in a real-time implementation of robot learning. 23 Using models for control according to the certainty equivalence principle is nothing new and has been supported by many researchers in the last years (e.g., <ref> [3, 38, 22, 24] </ref>). Using memory-based or nonpara metric models, however, has only recently received in - creasing interest. One of the favor able advantages of memory-based modeling lies in the least commitment strategy which is associated with it. <p> The initial short - comings of our deadbeat inverse or inverse-forward model controllers are not due to the 24 LWR learning algorithm but rather to the inherent problems of this kind of control. As has been pointed out by Jordan and Rumelhart <ref> [22] </ref>, inverse models are not goal-directed and perform data sampling in action and not state space. They do not establish a connection be - tween a certain sensation and a certain action but rather a connection between two sensa - tions. Hence, they do not learn from bad actions.
Reference: [23] <author> Mallows, C.L. </author> <year> (1966), </year> <title> Choosing a Subset Regression, </title> <booktitle> unpublished paper presented at the annual meeting of the American Statistical Association, </booktitle> <address> Los Angles (1966). </address>
Reference: [24] <author> Moore, A. </author> <year> (1991), </year> <title> Fast, Robust Adaptive Control by Learning only Forward Models, </title> <editor> in: Moody, J.E., Hanson, S.J., and Lippmann, R.P. (eds.) </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <publisher> Morgan Kaufmann (1991). </publisher>
Reference-contexts: 0 1 2 3 4 5 6 7 8 (c) 0 2 4 6 8 niques: (a) nearest neighbor; (b) weighted average; (c) locally weighted regression As the most generic approximator that satisfies many of these criteria, we explore a version of memory-based learning techniques called locally weighted regression (LWR). <ref> [15, 16, 11, 6, 24, 14, 27] </ref>. A memory-based learning (MBL) system is trained by storing the training data in a memory. This allows MBL systems to achieve real-time learning. MBL avoids interference between new and old data by retain ing and using all the data to answer each query. <p> Despite the computational complexity of these methods, we demonstrated the useful ness of our algorithms in a real-time implementation of robot learning. 23 Using models for control according to the certainty equivalence principle is nothing new and has been supported by many researchers in the last years (e.g., <ref> [3, 38, 22, 24] </ref>). Using memory-based or nonpara metric models, however, has only recently received in - creasing interest. One of the favor able advantages of memory-based modeling lies in the least commitment strategy which is associated with it.
Reference: [25] <author> Moore, A.W. </author> <year> (1990), </year> <title> Efficient Memory-based Learning for Robot Control. </title> <type> PhD. Thesis, Technical Report No. 229, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <month> October </month> <year> 1990 (1990). </year>
Reference-contexts: Common algorithms to choose the subset or the weighting are, for ex ample, n-near est neighbor methods (e.g., <ref> [12, 25] </ref>) or kernel re gression (e.g., [19, 28, 37]). Com mon functions are (hyper-)planes or (hyper-)qua dratic surfaces.
Reference: [26] <author> Moore, A.W. </author> <year> (1991), </year> <title> Knowledge of Knowledge and Intelligent Experimenttion for Learning Control, </title> <booktitle> Proceedings of the 1991 International Joint Conference on Neural Networks, </booktitle> <address> Seattle (1991). </address>
Reference-contexts: This data can be used by more sophisticated control algo rithms for planning or further exploration. We want to graphically illustrate the algorithm in a simple example of a mountain car (Figure 4) <ref> [26] </ref>. The task of the car is to drive at a given constant horizontal speed x desired from the left to the right of the picture. x desired need not be met precisely; the car should also minimize its fuel consumption.
Reference: [27] <author> Moore, A.W., Atkeson, </author> <title> C.G (1993), An Investigation of Memory-based Function Approximators for Learning Control, </title> <note> submitted to Machine Learning (1993). </note>
Reference-contexts: 0 1 2 3 4 5 6 7 8 (c) 0 2 4 6 8 niques: (a) nearest neighbor; (b) weighted average; (c) locally weighted regression As the most generic approximator that satisfies many of these criteria, we explore a version of memory-based learning techniques called locally weighted regression (LWR). <ref> [15, 16, 11, 6, 24, 14, 27] </ref>. A memory-based learning (MBL) system is trained by storing the training data in a memory. This allows MBL systems to achieve real-time learning. MBL avoids interference between new and old data by retain ing and using all the data to answer each query. <p> In Figure 3a we added three outliers to the test data of Figure 2 to demonstrate this effect; the charts in Figure 2 should be compared to Figure 2c. <ref> [27] </ref> applied the median absolute deviation procedure from robust statistics [18] to globally remove outliers in LWR. We would like to local ize our criterion for outlier re - moval. The PRESS statistic can be modified to serve as an outlier detector in LWR.
Reference: [28] <author> Mller, H.-G. </author> <year> (1988), </year> <title> Nonparametric Regression Analysis of Longitudinal Data, </title> <booktitle> Lecture Notes in Statistics Series, </booktitle> <address> vol.46, Berlin: </address> <publisher> Springer (1988). </publisher>
Reference-contexts: Common algorithms to choose the subset or the weighting are, for ex ample, n-near est neighbor methods (e.g., [12, 25]) or kernel re gression (e.g., <ref> [19, 28, 37] </ref>). Com mon functions are (hyper-)planes or (hyper-)qua dratic surfaces.
Reference: [29] <author> Myers, R.H. </author> <year> (1990), </year> <title> Classical And Modern Regression With Applications, </title> <address> Boston, MA: </address> <month> PWS-KENT </month> <year> (1990). </year>
Reference-contexts: Standard linear regression analysis provides a series of well-defined statistical tools to assess the quality of fits, such as coefficients of determination, t-tests, F-test, the PRESS-statistic, Mallows C p test ([23], confidence intervals, prediction intervals, and many more (e.g., <ref> [29] </ref>). These tools can be adapted to locally weighted regression. <p> Table 1 gives the appropriate definition for LWR; its derivation can be found in most text books on regression analysis (e.g., <ref> [29] </ref>). Besides using the intervals to assess the con - fidence in the fit at a certain point, they provide another optimization measure.
Reference: [30] <editor> Narendra, K.S., Dorato, P. (eds.) </editor> <booktitle> (1991), Advances in Adaptive Control, </booktitle> <address> Piscataway, </address> <publisher> NJ : IEEE Press (1991). </publisher>
Reference-contexts: Any linear control design techniques may be used subsequently. Much of the recent work in adaptive controllers for nonlinear systems assumes some knowledge of the form of the nonlineari ties and the plants unknown pa - rameters <ref> [30] </ref>. A common formulation requires the plant be repre sentable accurately by a feedback linearizable model in which all unknown ele ments appear linearly as a parameter vector.
Reference: [31] <author> Press, W.P., Flannery, B.P., Teukolsky, S.A., Vetterling, W.T. </author> <year> (1989), </year> <title> Numerical Recipes in C The Art of Scientific Computing , Cambridge, </title> <address> MA: </address> <publisher> Press Syndiacate University of Cambridge (1989). </publisher>
Reference-contexts: respect to the command F S from a LWR lookup for x S,in T T err S,out = x S,out F S x S,out = -B, (4.7) and calculate a correction DF S from solving: -BDF S = a err S,out , (4.8) e.g., by sin gular value decomposi tion <ref> [31] </ref>; a 0,1 [ ] determines how much of the error should be compensated for in one step. 3) update F S : F S = F S - DF S and calculate the new x S,out with LWR (4.3). 4) assess the fit for the updated setpoint with prediction in
Reference: [32] <author> Rizzi, A.A., Whitcomb, L.L., Koditschek, D.E. </author> <year> (1992a), </year> <title> Distributed Real Time Control of a Spatial Robot Juggler, </title> <booktitle> IEEE Computer , 25 (5) (1992). </booktitle>
Reference-contexts: This as well as other ex - perimental work (e.g., <ref> [32] </ref>) has high lighted the importance of making sure the control paradigm used is robust to un certainty, that the robot is able to compute what is known about the task, and how well it is known, and that there is some process that generates ex - ploration, so that models
Reference: [33] <author> Schaal, S., Atkeson, C.G. </author> <year> (1993b), </year> <title> Open Loop Stable Control Strategies for Robot Juggling, </title> <booktitle> Proceedings IEEE International Conference on Robotics and Automation, vol.3, </booktitle> <address> pp.913-918, Georgia, Atlanta (1993). </address> <month> 27 </month>
Reference-contexts: First, we as - sumed we know the input/output representations of the task, and second, we were able to generate a goal state for the SSA exploration. A good choice of a representation is crucial in order to be able to accomplish the goal at all <ref> [33, 35] </ref>, and we have very limited insight so far how to automate this part of the learn ing process. Of equal importance is a good choice of a goal state.
Reference: [34] <author> Schaal, S., Atkeson, C.G., Botros, S. </author> <year> (1992b), </year> <title> What Should Be Learned?, </title> <booktitle> In: Proceedings of Seventh Yale Workshop on Adaptive and Learning Systems , pp.199-204, </booktitle> <address> New Haven (1992). </address>
Reference-contexts: In devil sticking, the goal state developed out of the necessity that the left and right hand have to cooperate. The initial action, however, which was given by the experimenter, clearly determined in which ballpark the juggling pattern would lie. Certain patterns of devil sticking are easier than others <ref> [34] </ref>, and we picked an initial action of which we knew that it was favorable. One part of our future work will address these is - sues in more detail in that we search for good initial actions and strategies to approach a task [6].
Reference: [35] <author> Schaal, S., Sternad, D., </author> <year> (1993), </year> <title> Learning Passive Motor Control Strategies with Genetic Algorithms, </title> <editor> in: Nadel, L. & Stein, D. (eds.): </editor> <booktitle> 1992 Lectures in Complex Systems 1992, </booktitle> <publisher> Addison-Wesley (1993). </publisher>
Reference-contexts: First, we as - sumed we know the input/output representations of the task, and second, we were able to generate a goal state for the SSA exploration. A good choice of a representation is crucial in order to be able to accomplish the goal at all <ref> [33, 35] </ref>, and we have very limited insight so far how to automate this part of the learn ing process. Of equal importance is a good choice of a goal state.
Reference: [36] <author> Slotine, J.-J.E., Li, W. </author> <year> (1991), </year> <title> Applied Nonlinear Control , Englewood Cliffs, </title> <address> NJ: </address> <publisher> Prentice Hall (1991). </publisher>
Reference-contexts: Representing the Forward Model Modeling approaches require model representations. If the nonlinear system has a particu - lar structure, it can be globally linearized using non linear coordinate transformations and state feedback (feedback linearization) <ref> [36] </ref>. Any linear control design techniques may be used subsequently. Much of the recent work in adaptive controllers for nonlinear systems assumes some knowledge of the form of the nonlineari ties and the plants unknown pa - rameters [30].
Reference: [37] <author> Specht, D.F. </author> <year> (1991), </year> <title> A General Regression Neural Network, </title> <journal> IEEE Transactions on Neural Networks, vol.2, </journal> <volume> no.6, </volume> <year> Nov.1991 (1991). </year>
Reference-contexts: Common algorithms to choose the subset or the weighting are, for ex ample, n-near est neighbor methods (e.g., [12, 25]) or kernel re gression (e.g., <ref> [19, 28, 37] </ref>). Com mon functions are (hyper-)planes or (hyper-)qua dratic surfaces.
Reference: [38] <author> Sutton, R.S. </author> <year> (1990), </year> <title> Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming, </title> <booktitle> Proceedings of the International Machine Learning Conference , pp.212-218 (1990). </booktitle>
Reference-contexts: Despite the computational complexity of these methods, we demonstrated the useful ness of our algorithms in a real-time implementation of robot learning. 23 Using models for control according to the certainty equivalence principle is nothing new and has been supported by many researchers in the last years (e.g., <ref> [3, 38, 22, 24] </ref>). Using memory-based or nonpara metric models, however, has only recently received in - creasing interest. One of the favor able advantages of memory-based modeling lies in the least commitment strategy which is associated with it.
Reference: [39] <author> Thrun, S.B. </author> <year> (1992a), </year> <title> Efficient Exploration in Reinforcement Learning, </title> <type> Technical report CMU-CS-92-102, </type> <institution> Pittsburgh, Pennsylvania: Carnegie-Mellon University (1992). </institution>
Reference-contexts: The next section will demonstrate the importance of this measure. Exploration has many facets. Depending on the task to be solved, random explora - tion, exploration towards unknown state space regions, and exploration towards reduction of uncertainty, etc., have been suggested <ref> [39] </ref>. The SSA exploration algorithm is goal di - rected and uncertainty driven under the premise not to dare any aggressive explo ration outside the cur rent data support.
Reference: [40] <author> Van Zyl, G. </author> <year> (1991), </year> <title> Design and control of a robotic platform for machine learning, </title> <type> MS thesis, </type> <institution> MIT Dept. of Mechanical Engineering. </institution>
Reference-contexts: ideas by imple - menting learning for oneshot or static tasks, such as throwing a ball at a target [1], and also repetitive or dynamic tasks, such as bouncing a ball on a paddle [2] and hitting a stick back and forth (a form of juggling known as devil sticking) <ref> [40] </ref>. <p> A System For Learning Experiments: Robot Juggling We have constructed a system for experiments in real-time motor learning <ref> [40] </ref>. The task is a juggling task known as devil sticking. A center stick is batted back and forth between two handsticks (Figure 5a). Figures 5b,c show a sketch and photograph of our devil stick - ing robot.
Reference: [41] <author> Wahba, G., Wold, S. </author> <year> (1975), </year> <title> A Completely Automatic French Curve: Fitting Spline Functions By Cross-Validation, </title> <booktitle> Communications in Statistics , 4(1) (1975). </booktitle>
Reference: [42] <author> White, D.A, Sofge, D.A. </author> <year> (1992), </year> <title> Handbook of Intelligent Control : Neural, Fuzzy, and Adaptive Approaches , New York, </title> <publisher> NY: Van Nostrand Reinhold (1992). </publisher>
Reference-contexts: Predictive control design techniques avoid using a value function, but are then merely locally optimal [10]. Value functions can also be approxi mated, e.g., with neural networks <ref> [42] </ref>. We are interested in exploring approxima tions to value func - tions that produce a locally quadratic model of V x ( ) in a lo cal neigh borhood of x . In this paper we are working within an optimal control framework.
References-found: 41

