URL: http://www.icsi.berkeley.edu/ftp/global/pub/techreports/1994/tr-94-009.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/ftp/global/pub/techreports/1994/
Root-URL: http://www.icsi.berkeley.edu
Title: A Performance Analysis of CNS-1 on Sparse Connectionist Networks  
Author: Silvia M. Muller and Benedict Gomes 
Note: The CNS-1 project is a collaboration of the  
Address: I 1947 Center St. Suite 600 Berkeley, California 94704-1198  Germany.  Berkeley.  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  University of California at Berkeley and the International Computer Science Institute ICSI and CS Department, University of Saarland,  ICSI and CS Division, U.C.  
Pubnum: TR-94-009  
Email: E-mail: smueller@cs.uni-sb.de  E-mail: gomes@icsi.berkeley.edu  
Phone: (510) 643-9153 FAX (510) 643-7684  
Date: February 1994  
Abstract: This report deals with the efficient mapping of sparse neural networks on CNS-1. We develop parallel vector code for an idealized sparse network and determine its performance under three memory systems. We use the code to evaluate the memory systems (one of which will be implemented in the prototype), and to pinpoint bottlenecks in the current CNS-1 design. 
Abstract-found: 1
Intro-found: 1
Reference: [ABC + 93] <author> K. Asanovic, J. Beck, T. Callahan, J. Feldman, B. Irissou, B. Kingsbury, P. Kohn, J. Lazzaro, N. Morgan, D. Stoutamire, and J. Wawrzynek. </author> <title> CNS-1 architecture specification. </title> <type> Technical Report TR-93-021, </type> <institution> International Computer Science Institute and UC Berkeley, </institution> <year> 1993. </year>
Reference-contexts: Introduction The Connectionist Network Supercomputer (CNS-1) <ref> [ABC + 93] </ref>, currently under development at ICSI, is a massively parallel multicomputer, with custom-designed fixed-point vector processor nodes. In [Mul93b], the performance of CNS-1 on densely connected multi-layer backpropagation networks has been analyzed in detail. <p> Though dense backpropagation networks are by far the most popular neural networks today, the field of connectionism is extremely diverse and models with sparse connectivity are gaining in popularity. In fact, the typical target problem <ref> [ABC + 93] </ref> for CNS is the simulation of a network of a million units, each with a thousand connections (a connectivity of 0.001). In this report, we will describe ways to represent such networks on the CNS-1 and analyze the resultant performance. <p> The actual processor speed will depend on the VLSI process available and on the memory structure, but should be in the neighborhood of 50-75 MHz. All scalar instructions are assumed to take a single cycle. <ref> [ABC + 93] </ref> contains details of the vector coprocessor architecture. We merely note that there are two vector arithmetic pipes, permitting an addition and a multiplication to proceed in parallel. In general, vector arithmetic operations take dVLR=8e cycles, and may be fully overlapped with memory operations. <p> most cases arithmetic may be completely hidden behind memory accesses, particularly with indexed memory accesses which take at least 32 cycles for a 32 element vector. 2.3 Network Performance The CNS-1 network design has not yet been finalized but it will be based on active messages [CSS + 91, vCGS92]. <ref> [ABC + 93, Mul93b, AC93] </ref> describe some basics of the network interface and give a timing model. <p> Each processor holds 4096 units, with an average of 512 input connections per unit. The problem size is chosen to fit in 16 MB of memory; the million unit problem mentioned in <ref> [ABC + 93] </ref> would not. If the node memory turns out to be 8MB, the reference problems must be further reduced in size. 3.2 Representation For each unit we need to represent its output activation and all its incoming connections. <p> The per-processor computation time therefore adds up to T comp basic = T weight + T index + 20:5u (5:93c + 20:5)u cycles or about 12.5 million cycles in the reference case. 3.8.2 Transfer Time The RDRAM version of the CNS-1 was originally <ref> [ABC + 93] </ref> expected to run at 125MHz, but 50 75 MHz seems to be more realistic. A network link then transfers b = 2 bytes per cycle, but with the faster clock only b = 1 byte per cycle is possible, assuming the same network bandwidth.
Reference: [AC93] <author> K. Asanovic and T. Callahan. </author> <title> Torrent Architecture Manual. </title> <institution> International Computer Science Institute and UC Berkeley, </institution> <year> 1993. </year> <title> Internal document, </title> <publisher> revisions 1.5/1.9. </publisher>
Reference-contexts: most cases arithmetic may be completely hidden behind memory accesses, particularly with indexed memory accesses which take at least 32 cycles for a 32 element vector. 2.3 Network Performance The CNS-1 network design has not yet been finalized but it will be based on active messages [CSS + 91, vCGS92]. <ref> [ABC + 93, Mul93b, AC93] </ref> describe some basics of the network interface and give a timing model.
Reference: [Asa93] <author> K. Asanovic. </author> <title> T0 Reference Manual. </title> <institution> International Computer Science Institute and UC Berkeley, </institution> <year> 1993. </year> <title> Internal document, revision 1.5. </title>
Reference-contexts: The scalar and the vector unit would both directly access the SRAM, and so the memory system would be similar to the T0 design <ref> [Asa93] </ref>. The instruction cache delivers one instruction per cycle but a cache miss takes 2 cycles. A busy memory (due to other cache traffic, for instance) causes an additional one cycle delay.
Reference: [Bre93] <author> Williams Brett. </author> <title> Synchronous DRAMs: Designing to theJEDEC standard. MICRON: Design Line, </title> <type> 2(2), </type> <year> 1993. </year>
Reference-contexts: The scalar unit would control the data cache but the vector unit could also access the cache. The SDRAM <ref> [SAM93, Bre93] </ref> itself would have a single active page of 8KB. A page break requires an extra t p = 2 cycle latency and there is a 2 to 4 cycle penalty for unaligned writes. An instruction cache miss takes 4 cycles.
Reference: [CSS + 91] <author> D. Culler, A. Sah, K. Schauser, T. von Eichen, and J. Wawrzynek. </author> <title> Fine-grain parallelism with minimal hardware support: A compiler-controlled threaded abstract machine. </title> <booktitle> In Proceedings of 4th Int. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 164-175, </pages> <year> 1991. </year>
Reference-contexts: In most cases arithmetic may be completely hidden behind memory accesses, particularly with indexed memory accesses which take at least 32 cycles for a 32 element vector. 2.3 Network Performance The CNS-1 network design has not yet been finalized but it will be based on active messages <ref> [CSS + 91, vCGS92] </ref>. [ABC + 93, Mul93b, AC93] describe some basics of the network interface and give a timing model.
Reference: [GH88] <author> Joydeep Ghosh and Kai Hwang. </author> <title> Mapping neural networks onto message passing multicomputers. </title> <journal> Journal of Parallel and Distributed Processing, </journal> <volume> 6 </volume> <pages> 291-330, </pages> <year> 1988. </year>
Reference: [LCDS90] <author> Y. Le Cun, J.S. Denker, and S.A. Solla. </author> <title> Optimal brain damage. </title> <editor> In D.S. Touret-zky, editor, </editor> <booktitle> Proceedings of NIPS 1989, </booktitle> <volume> volume 2, </volume> <pages> pages 598-605. </pages> <publisher> Morgan Kauf-mann, </publisher> <year> 1990. </year>
Reference: [Mul93a] <author> S. M. Muller. </author> <title> All-to-all Broadcast on the CNS-1. </title> <type> Technical Report TR-93-082, </type> <institution> International Computer Science Institute, Berkeley, </institution> <year> 1993. </year>
Reference-contexts: (k (n) 1) fl maxfT net (m (n)); T CP U (m (n))g +T net (m (n)) + T CP U (m (n)) ( T net (m (n)) + k (n) T CP U (m (n)) ; T net (m (n)) &lt; T CP U (m (n)): 2.3.2 Broadcast Paper <ref> [Mul93a] </ref> analyzes all-to-all broadcast on the CNS-1 in all detail. <p> Altogether, each node sends and receives xdu data bytes per 24 phase. Since du &gt; 128, this communication has the run time T trans (xdu) as shown in paper <ref> [Mul93a] </ref> and section 2.3. A whole iteration requires P=x of these communications. That takes T comm basic = P T trans (xdu) cycles. The CNS-1 can overlap additional computation with the transfer, if more time is spent in the network than in the communication handlers.
Reference: [Mul93b] <author> S. M. Muller. </author> <title> A performance analysis of the CNS-1 on large, dense backpropagation networks. </title> <type> Technical Report TR-93-046, </type> <institution> International Computer Science Institute, Berkeley, </institution> <year> 1993. </year>
Reference-contexts: Introduction The Connectionist Network Supercomputer (CNS-1) [ABC + 93], currently under development at ICSI, is a massively parallel multicomputer, with custom-designed fixed-point vector processor nodes. In <ref> [Mul93b] </ref>, the performance of CNS-1 on densely connected multi-layer backpropagation networks has been analyzed in detail. Though dense backpropagation networks are by far the most popular neural networks today, the field of connectionism is extremely diverse and models with sparse connectivity are gaining in popularity. <p> Three aspects of the CNS-1 machine are relevant to the performance analysis: vector-processor speed, memory speed, and inter-processor communication speed. The following subsections summarize the design and performance of these components, and may be omitted by those familiar with the design or with <ref> [Mul93b] </ref>. 2.1 Memory System As it turns out, the performance of sparse networks on CNS is largely determined by the performance of the memory system. Three different memory systems are currently under consideration: a Static RAM (SRAM) system, a Synchronous DRAM (SDRAM) system, and an RDRAM system. <p> most cases arithmetic may be completely hidden behind memory accesses, particularly with indexed memory accesses which take at least 32 cycles for a 32 element vector. 2.3 Network Performance The CNS-1 network design has not yet been finalized but it will be based on active messages [CSS + 91, vCGS92]. <ref> [ABC + 93, Mul93b, AC93] </ref> describe some basics of the network interface and give a timing model. <p> SDRAM is still quite easy to design for and yields good performance, at least on our idealized network model. Backpropagation on large dense layered networks is the second benchmark application of the CNS-1. The results of the report <ref> [Mul93b] </ref> showed, that a CNS-1 with RDRAM memory system could simulate a multi-layer backprop network at close to (ALU) peak performance. Using a SRAM or SDRAM system which runs at a slower system clock consequently results in a big performance loss.
Reference: [Ram92] <institution> Rambus Inc., Mountain View, California. </institution> <note> Rambus Technology Guide, 0.90 - preliminary edition, </note> <month> May </month> <year> 1992. </year>
Reference-contexts: Vector memory operations have an extra one cycle latency, but otherwise take dVLR=8e cycles to read or write byte or halfword contiguous vectors. Word accesses still take twice as long. Vector memory instructions with indexing only transfer two vector elements in three cycles. 2.1.3 RDRAM System The RDRAM <ref> [Ram92, Tos92] </ref> memory hierarchy would at least have three levels: separate instruction and data cache (4KB) on the processor chip, a second level cache of (2 fi 2KB) in each RDRAM chip, and the RDRAM itself. All the caches are direct mapped.
Reference: [SAM93] <institution> SAMSUNG Electronics. SAMSUNG Synchronous DRAM, </institution> <address> revision 1 edition, </address> <month> March </month> <year> 1993. </year> <month> 36 </month>
Reference-contexts: The scalar unit would control the data cache but the vector unit could also access the cache. The SDRAM <ref> [SAM93, Bre93] </ref> itself would have a single active page of 8KB. A page break requires an extra t p = 2 cycle latency and there is a 2 to 4 cycle penalty for unaligned writes. An instruction cache miss takes 4 cycles.
Reference: [Sha88] <author> Lokendra Shastri. </author> <title> Semantic Nets: Evidential Formalization and its Connection--ist Implementation. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: In our model, each unit just computes the dot product of the output. No thresholding function is considered. Connectivity structures vary from highly structured (sparse) networks with user defined weights (e.g. <ref> [Sha88] </ref>) to multi-layer backpropagation networks, which usually have complete connectivity between layers. Even in densely connected multi-layer networks, weight pruning techniques like Optimal Brain Damage ([LCDS90]) may be applied to yield multi-layered sparsely connected networks.
Reference: [Tos92] <editor> Toshiba. </editor> <booktitle> Advanced Information: </booktitle> <address> 2M fi 9 RDRAM, </address> <year> 1992. </year>
Reference-contexts: Vector memory operations have an extra one cycle latency, but otherwise take dVLR=8e cycles to read or write byte or halfword contiguous vectors. Word accesses still take twice as long. Vector memory instructions with indexing only transfer two vector elements in three cycles. 2.1.3 RDRAM System The RDRAM <ref> [Ram92, Tos92] </ref> memory hierarchy would at least have three levels: separate instruction and data cache (4KB) on the processor chip, a second level cache of (2 fi 2KB) in each RDRAM chip, and the RDRAM itself. All the caches are direct mapped.
Reference: [vCGS92] <author> T. von Eichen, D. Culler, S. Goldstein, and K. Schauser. </author> <title> Active messages: a mechanism for integrated communication and computation. </title> <booktitle> In Proceedings of 19th Int. Symposium on Computer Architecture. </booktitle> <publisher> ACM Press, </publisher> <year> 1992. </year> <month> 37 </month>
Reference-contexts: In most cases arithmetic may be completely hidden behind memory accesses, particularly with indexed memory accesses which take at least 32 cycles for a 32 element vector. 2.3 Network Performance The CNS-1 network design has not yet been finalized but it will be based on active messages <ref> [CSS + 91, vCGS92] </ref>. [ABC + 93, Mul93b, AC93] describe some basics of the network interface and give a timing model.
References-found: 14

