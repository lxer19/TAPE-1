URL: http://www.cs.brandeis.edu/~hugues/papers/ICGA_95.ps.gz
Refering-URL: http://www.cs.brandeis.edu/~hugues/sorting_networks.html
Root-URL: http://www.cs.brandeis.edu
Title: Evolution of Non-Deterministic Incremental Algorithms as a New Approach for Search in State Spaces  
Author: Hugues Juille 
Address: Waltham, MA 02254-9110  
Affiliation: Computer Science Department Volen Center for Complex Systems Brandeis University  
Abstract: Let us call a non-deterministic incremental algorithm one that is able to construct any solution to a combinatorial problem by selecting incrementally an ordered sequence of choices that defines this solution, each choice being made non-deterministically. In that case, the state space can be represented as a tree, and a solution is a path from the root of that tree to a leaf. This paper describes how the simulated evolution of a population of such non-deterministic incremental algorithms offers a new approach for the exploration of a state space, compared to other techniques like Genetic Algorithms (GA), Evolutionary Strategies (ES) or Hill Climbing. In particular, the efficiency of this method, implemented as the Evolving Non-Determinism (END) model, is presented for the sorting network problem, a reference problem that has challenged computer science. Then, we shall show that the END model remedies some drawbacks of these optimization techniques and even outperforms them for this problem. Indeed, some 16-input sorting networks as good as the best known have been built from scratch, and even a 25-year-old result for the 13-input problem has been improved by one comparator.
Abstract-found: 1
Intro-found: 1
Reference: [Back et al., 1991] <author> Back, T., Hoffmeister, F., & Schwefel, H.-P. </author> <year> (1991). </year> <title> A survey of evolution strategies. </title> <editor> In Belew, R. K. & Booker, L. B. (Eds.), </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pp. 2-9, </pages> <address> San Mateo, California. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [Belew & Kammayer, 1993] <author> Belew, R. K. & Kam-mayer, T. </author> <year> (1993). </year> <title> Evolving sthetic sorting networks using developmental grammars. </title> <editor> In Forrest, S. (Ed.), </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, California. </address> <publisher> Morgan Kauffmann. </publisher>
Reference: [Drescher, 1994] <author> Drescher, G. L. </author> <year> (1994). </year> <title> Evolution of 16-number sorting networks revisited. </title> <type> Personal communication. </type>
Reference-contexts: 1 2 3 4 5 6 7 8 Comparators 0 1 3 5 9 12 16 19 Inputs 9 10 11 12 13 14 15 16 Comparators 25 29 35 39 45 fl 51 56 60 4 Comparison of GA and END approaches 4.1 GA approach 4.1.1 Description As in <ref> [Drescher, 1994] </ref> and [Hillis, 1992], the intuitive representation of sorting networks is that each genome encodes a sorting network as a sequence of pairs, each pair representing a comparator. Then, crossover is performed by exchanging groups of comparators between two mating individuals. <p> Moreover, since there are only 151 remaining unsorted vectors after this initial construction, the fitness can be computed within reasonable time. Details of GA implementation are not relevant here and are described in <ref> [Drescher, 1994] </ref> and [Hillis, 1992]. Results along with population size and number of generations for Hillis and Drescher's experiments are presented in table 4. Drescher's GA evolved sorting networks as compact as the best known. However, in all experiments, a very large population size is used to reach these results.
Reference: [Green, 1969] <author> Green, M. W. (c.1969). </author> <title> Some improvements in nonadaptive sorting algorithms. </title> <type> Technical report, </type> <institution> Stanford Research Institute, Menlo Park, California. </institution>
Reference-contexts: W. Floyd and D. E. Knuth, and independently K. E. Batcher, found a new method and designed a sorting network using 63 comparisons. Then, a 62-comparator sorting network was found by G. Shapiro in 1969, soon to be followed by M. W. Green's 60 comparator network (see <ref> [Green, 1969] </ref> and [Knuth, 1973]). Table 2: Best upper bounds currently known for length of sorting networks. Previously, the best known upper bound for the 13-input problem was 46.
Reference: [Hillis, 1992] <author> Hillis, W. D. </author> <year> (1992). </year> <title> Co-evolving parasites improve simulated evolution as an optimization procedure. </title> <editor> In Langton, C. et al. (Eds.), </editor> <booktitle> Artificial Life II. </booktitle> <publisher> Addison Wesley. </publisher>
Reference-contexts: 4 5 6 7 8 Comparators 0 1 3 5 9 12 16 19 Inputs 9 10 11 12 13 14 15 16 Comparators 25 29 35 39 45 fl 51 56 60 4 Comparison of GA and END approaches 4.1 GA approach 4.1.1 Description As in [Drescher, 1994] and <ref> [Hillis, 1992] </ref>, the intuitive representation of sorting networks is that each genome encodes a sorting network as a sequence of pairs, each pair representing a comparator. Then, crossover is performed by exchanging groups of comparators between two mating individuals. <p> Moreover, since there are only 151 remaining unsorted vectors after this initial construction, the fitness can be computed within reasonable time. Details of GA implementation are not relevant here and are described in [Drescher, 1994] and <ref> [Hillis, 1992] </ref>. Results along with population size and number of generations for Hillis and Drescher's experiments are presented in table 4. Drescher's GA evolved sorting networks as compact as the best known. However, in all experiments, a very large population size is used to reach these results.
Reference: [Juille, 1994] <author> Juille, H. </author> <year> (1994). </year> <title> Evolving non-determinism: An inventive and efficient tool for optimization and discovery of strategies. </title> <type> Draft paper. </type>
Reference-contexts: Management of the commitment degree : As it is described in the previous section, this parameter also plays an important role in managing the balance between exploration and exploitation. The above description of the influence of these parameters on the search has been confirmed experimentally in <ref> [Juille, 1994] </ref>. 2.5 IDEA OF THE END APPROACH Another approach to describe how the END model works is to make the following analogy: Children of the root of the tree of solutions can be seen as a partition of the space of states, each child corresponding to a particular subset of
Reference: [Juille, 1995] <author> Juille, H. </author> <year> (1995). </year> <title> Incremental coevolution of organisms: A new approach for optimization and discovery of strategies. </title> <booktitle> To appear in the proceedings of the Third European Conference on Artificial Life. </booktitle>
Reference-contexts: This strategy will be inclined to find out a local optimum in the region of high average fitness. As it is shown in <ref> [Juille, 1995] </ref>, the landscape of the space of states for the sorting network problem is of this kind. <p> In another field, board games can also be considered as a subset of this class of "topologically" complex problems since rules of such games define valid configurations of the board and these valid configurations often represent only a very small subset of the whole set of possible configurations. In <ref> [Juille, 1995] </ref>, an example of a board game is presented to show how a strategy is evolved by the END model to play this game. Moreover, the END model is intrinsically highly paral-lelizable and scalable.
Reference: [Knuth, 1973] <author> Knuth, D. E. </author> <year> (1973). </year> <title> The Art of Computer Programming, volume 3: Sorting and Searching. </title> <publisher> Addison Wesley. </publisher>
Reference-contexts: This kind of algorithm has received much attention since it admits an implementation as circuits: comparison-swap can be hard-wired. Such an oblivious comparison-based algorithm for sorting n values is called an n-input sorting network (a survey of sorting network research is in <ref> [Knuth, 1973] </ref>). There is a convenient graphical representation of sorting networks as shown in figure 1, which is a 10-input sorting network (from [Knuth, 1973]). <p> Such an oblivious comparison-based algorithm for sorting n values is called an n-input sorting network (a survey of sorting network research is in <ref> [Knuth, 1973] </ref>). There is a convenient graphical representation of sorting networks as shown in figure 1, which is a 10-input sorting network (from [Knuth, 1973]). Each horizontal line represents an input of the sorting network and each connection between two lines represents a comparator which compares the two elements and exchanges them if the one on the upper line is larger than the one on the lower line. <p> Current upper and lower bounds are provided in [Parberry, 1991]. Table 1 presents these current bounds on depth for n 16. 2. Its length, that is the number of comparison-swap used. Optimal sorting networks for n 8 are known exactly and are presented in <ref> [Knuth, 1973] </ref> along with the most efficient sorting networks to date for 9 n 16. Table 2 presents these results. The 16-input sorting network has been the most challenging one. Knuth [Knuth, 1973] recounts its history as follows. <p> Optimal sorting networks for n 8 are known exactly and are presented in <ref> [Knuth, 1973] </ref> along with the most efficient sorting networks to date for 9 n 16. Table 2 presents these results. The 16-input sorting network has been the most challenging one. Knuth [Knuth, 1973] recounts its history as follows. First, in 1962, Bose and Nel-son discovered a method for constructing sorting networks that used 65 comparisons and conjectured that it was best possible. Two years later, R. W. Floyd and D. E. Knuth, and independently K. E. <p> Floyd and D. E. Knuth, and independently K. E. Batcher, found a new method and designed a sorting network using 63 comparisons. Then, a 62-comparator sorting network was found by G. Shapiro in 1969, soon to be followed by M. W. Green's 60 comparator network (see [Green, 1969] and <ref> [Knuth, 1973] </ref>). Table 2: Best upper bounds currently known for length of sorting networks. Previously, the best known upper bound for the 13-input problem was 46.
Reference: [Levy, 1992] <author> Levy, S. </author> <year> (1992). </year> <title> Artificial Life: the Quest for a New Creation. </title> <publisher> Pantheon Nooks. </publisher>
Reference: [Parberry, 1991] <author> Parberry, I. </author> <year> (1991). </year> <title> A computer-assisted optimal depth lower bound for nine-input sorting networks. </title> <journal> Mathematical Systems Theory, </journal> <volume> 24 </volume> <pages> 101-116. </pages>
Reference-contexts: Its depth which is defined as the number of parallel steps that it takes to sort any input, given that in one step disjoint comparison-swap operations can take place simultaneously. Current upper and lower bounds are provided in <ref> [Parberry, 1991] </ref>. Table 1 presents these current bounds on depth for n 16. 2. Its length, that is the number of comparison-swap used.
Reference: [Ruml et al., 1995] <author> Ruml, W., Ngo, J. T., Marks, J., & Shieber, S. </author> <year> (1995). </year> <title> Easily searched encodings for number partitioning. </title> <note> To appear in the Journal of Optimization Theory and Applications. </note>
Reference: [Schraudolph & Belew, 1992] <author> Schraudolph, N. N. & Belew, R. K. </author> <year> (1992). </year> <title> Dynamic parameter encoding for genetic algorithms. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 9-21. </pages>
Reference: [Tufts & Juille, 1994] <author> Tufts, P. & Juille, H. </author> <year> (1994). </year> <title> Evolving non-deterministic algorithms for efficient sorting networks. </title> <booktitle> Poster, Artificial Life IV Conference. First 60-comparator results. </booktitle>
Reference-contexts: This is the follow-up of an established problem for which several approaches have been used to try to improve some 25 years old results ([Belew & Kammayer, 1993, Drescher, 1994, Hillis, 1992, Levy, 1992, Parberry, 1991]). Actually, this problem was also the origin of an early paper <ref> [Tufts & Juille, 1994] </ref> in which GA were used to try to replicate Hillis' experiments ([Hillis, 1992]) for the 16-input problem and in which some ideas of the END model were presented.

References-found: 13

