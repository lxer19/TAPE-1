URL: http://www.robotics.stanford.edu/~koller/papers/uai94.ps
Refering-URL: http://www.robotics.stanford.edu/~koller/papers/uai94.html
Root-URL: http://www.robotics.stanford.edu
Email: fbacchus@logos.waterloo.edu  grove@research.nj.nec.com  halpern@almaden.ibm.com  daphne@cs.berkeley.edu  
Title: Generating New Beliefs From Old  
Author: Fahiem Bacchus Adam J. Grove Joseph Y. Halpern Daphne Koller 
Address: Waterloo, Ontario Canada, N2L 3G1  4 Independence Way Princeton, NJ 08540  650 Harry Road San Jose, CA 95120-6099  Berkeley, CA 94720  
Affiliation: Computer Science Dept. University of Waterloo  NEC Research Institute  IBM Almaden Research Center  Computer Science Division University of California, Berkeley  
Abstract: In previous work [BGHK92, BGHK93], we have studied the random-worlds approacha particular (and quite powerful) method for generating degrees of belief (i.e., subjective probabilities) from a knowledge base consisting of objective (first-order, statistical, and default) information. But allowing a knowledge base to contain only objective information is sometimes limiting. We occasionally wish to include information about degrees of belief in the knowledge base as well, because there are contexts in which old beliefs represent important information that should influence new beliefs. In this paper, we describe three quite general techniques for extending a method that generates degrees of belief from objective information to one that can make use of degrees of belief as well. All of our techniques are based on well-known approaches, such as cross-entropy. We discuss general connections between the techniques and in particular show that, although conceptually and technically quite different, all of the techniques give the same answer when applied to the random-worlds method.
Abstract-found: 1
Intro-found: 1
Reference: [BGHK92] <author> F. Bacchus, A. J. Grove, J. Y. Halpern, and D. Koller. </author> <title> From statistics to belief. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI '92), </booktitle> <pages> pages 602-608, </pages> <year> 1992. </year>
Reference-contexts: One way of guaranteeing this is to actually generate them from the objective information available to the agent. Several ways of doing this have been considered in the literature; for example, <ref> [BGHK92, PV92] </ref> each discuss several possibilities. The approaches in [BGHK92] are based in a very natural way on the semantics described above. Assume we have a (prior) probability distribution over some set of worlds. <p> One way of guaranteeing this is to actually generate them from the objective information available to the agent. Several ways of doing this have been considered in the literature; for example, [BGHK92, PV92] each discuss several possibilities. The approaches in <ref> [BGHK92] </ref> are based in a very natural way on the semantics described above. Assume we have a (prior) probability distribution over some set of worlds. <p> Assume we have a (prior) probability distribution over some set of worlds. We can then generate degrees of belief from an objective knowledge base KB by using standard Bayesian conditioning: to the formula ' we assign as its degree of belief the conditional probability of ' given KB. In <ref> [BGHK92] </ref> we considered three particular choices for a prior, and investigated the properties of the resulting inductive inference systems. In [BGHK93] we concentrated on the simplest of these methodsthe random-worlds methodwhose choice of prior is essentially the uniform prior over the set of possible worlds. <p> It is, however, the limit of world-based meth ods. (This is also true for the other methods considered in <ref> [BGHK92] </ref>.) We can easily extend CEW so that it applies to limits of world-based methods by taking limits in the obvious way. In particular, we define CEW (Pr 1 )('jKB) = lim lim CEW (Pr N )('jKB); provided the limit exists.
Reference: [BGHK93] <author> F. Bacchus, A. J. Grove, J. Y. Halpern, and D. Koller. </author> <title> Statistical foundations for default reasoning. </title> <booktitle> In Proc. Thirteenth International Joint Conference on Artificial Intelligence (IJ-CAI '93), </booktitle> <year> 1993. </year>
Reference-contexts: In [BGHK92] we considered three particular choices for a prior, and investigated the properties of the resulting inductive inference systems. In <ref> [BGHK93] </ref> we concentrated on the simplest of these methodsthe random-worlds methodwhose choice of prior is essentially the uniform prior over the set of possible worlds. <p> This limiting value (if it exists, which it may not) is denoted Pr 1 ('jKB), and it is what the random-world method takes to be the degree of belief in ' given KB. In <ref> [BGHK93] </ref>, we showed that this method possesses a number of attractive properties, such as a preference for more specific informa tion and the ability to ignore irrelevant information. The random-worlds method can generate degrees of belief from rich knowledge bases that may contain first-order, statistical, and default information. <p> The birdwatcher is trying to decide if b is a cardinal. By the results of <ref> [BGHK93] </ref>, if the birdwatcher assumes that the bird is not red, random-worlds gives Pr rw 1 (Cardinal (b)jKB bird ^ :Red (b)) = 0:1. On the other hand, if she assumes that the bird is red, we get Pr 1 (Cardinal (b)jKB bird ^ Red (b)) = 0:7. <p> The rest of this paper is organized as follows. In the next section we review the formal model of [Hal90] for degrees of belief and statistical information, and some material from <ref> [BGHK93] </ref> regarding the random-worlds method. We give the formal definitions of the three methods we consider in Section 3, and discuss their equivalence. In passing, we also discuss the connection to Jeffrey's rule, which is another very well known method of updating by uncertain information. <p> For example, complex formulas like Pr (8x (jjKnows (x; y)jj y 0:3)) 0:5 are in L. 4 We remark that in [Hal90] there was no use of approximate equality (). We use it here since, as argued in <ref> [BGHK93] </ref>, its use is crucial in our intended applications. On the other hand, in [BGHK93], we used a whole family of approximate equality functions of the form i , i = 1; 2; 3; : : :. To simplify the presentation, we use only one here. <p> We use it here since, as argued in <ref> [BGHK93] </ref>, its use is crucial in our intended applications. On the other hand, in [BGHK93], we used a whole family of approximate equality functions of the form i , i = 1; 2; 3; : : :. To simplify the presentation, we use only one here. We will also be interested in various sublanguages of L.
Reference: [Car50] <author> R. Carnap. </author> <title> Logical Foundations of Probability. </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, </address> <year> 1950. </year>
Reference-contexts: Yet the distinction can be a significant one if we want to use or interpret a probabilistic theory correctly. Carnap's work <ref> [Car50] </ref> is noteworthy for its careful distinction between, and study of, both statistical probabilities, which are objective, and degree of belief probabilities, which are subjective.
Reference: [GHK92] <author> A. J. Grove, J. Y. Halpern, and D. Koller. </author> <title> Random worlds and maximum entropy. </title> <booktitle> In Proc. 7th IEEE Symp. on Logic in Computer Science, </booktitle> <pages> pages 22-33, </pages> <year> 1992. </year>
Reference-contexts: The first applies it to the random-worlds method. The second applies it to a variant of the maximum-entropy approach used by Paris and Vencovska [PV89] (and similar in spirit to the method used by Jaeger [Jae94b]), which we henceforth call the ME (inference) process. Using results of <ref> [GHK92, PV89] </ref>, we prove that these two instantiations are equivalent. The third method we consider also applies only to certain types of inference processes. In particular, it takes as its basic intuition that all degrees of belief must ultimately be the result of some statistical process. <p> It was also defined (independently it seems) by Paris and Vencovska [PV92]; we follow their presentation here. Paris and Vencovska showed that the RS method and the CEF method agree when applied to their version of the ME process. Using results of <ref> [GHK92, PV89] </ref>, we can show that the methods also agree when applied to our version of the ME process and when applied to random worlds. <p> Atoms are always mutually exclusive and exhaustive; so, if we could find appropriate degrees of belief for these atoms, we could again define things so that Proposition 3.2 holds. A simple way of doing this 6 We remark that in <ref> [GHK92, PV89] </ref> a connection was established between random worlds and maximum entropy. Here maximum entropy is playing a different role. It is being used here to extend random worlds rather than to characterize properties of random worlds as in [GHK92, PV89]. would be to assume that, after conditioning, the assertions i <p> A simple way of doing this 6 We remark that in <ref> [GHK92, PV89] </ref> a connection was established between random worlds and maximum entropy. Here maximum entropy is playing a different role. It is being used here to extend random worlds rather than to characterize properties of random worlds as in [GHK92, PV89]. would be to assume that, after conditioning, the assertions i are independent. But, as we observed in the introduction, assuming independence is inappropriate in general. Our solution is to first employ cross-entropy to find appropriate probabilities for these atoms. We proceed as follows. <p> We can only apply CEF to ME if the knowledge base has the form KB ^ BB, where KB is a simple knowledge base about c and BB is a simple belief base about c. It follows from results of <ref> [GHK92, PV89] </ref> that random worlds and ME give the same results on their common domain. Hence, they are also equal after we apply the CEF transformation.
Reference: [Hal90] <author> J. Y. Halpern. </author> <title> An analysis of first-order logics of probability. </title> <journal> Artificial Intelligence, </journal> <volume> 46 </volume> <pages> 311-350, </pages> <year> 1990. </year>
Reference-contexts: In order to understand this distinction, it is useful to provide a formal semantics for degrees of belief that captures the difference between them and objective information. As demonstrated by Halpern <ref> [Hal90] </ref>, a natural, and very general, way to give a semantics to degrees of belief is by defining a probability distribution over a set of possible worlds. 1 The degree of belief in a formula ' is then the probability of the set of worlds where ' is true. <p> In addition, the resulting extension of random worlds agrees with the approach obtained when we apply CEF and RS to the ME process. The rest of this paper is organized as follows. In the next section we review the formal model of <ref> [Hal90] </ref> for degrees of belief and statistical information, and some material from [BGHK93] regarding the random-worlds method. We give the formal definitions of the three methods we consider in Section 3, and discuss their equivalence. <p> In passing, we also discuss the connection to Jeffrey's rule, which is another very well known method of updating by uncertain information. We conclude in Section 4 with some discussion of computational issues and possible generalizations of these approaches. 2 Technical preliminaries 2.1 A first-order logic of probability In <ref> [Hal90] </ref>, a logic is presented that allows us to represent and reason with both statistical information and degrees of belief. We briefly review the relevant material here. We start with a standard first-order language over a finite vocabulary F, and augment it with proportion expressions and belief expressions. <p> For example, complex formulas like Pr (8x (jjKnows (x; y)jj y 0:3)) 0:5 are in L. 4 We remark that in <ref> [Hal90] </ref> there was no use of approximate equality (). We use it here since, as argued in [BGHK93], its use is crucial in our intended applications. <p> To give semantics to both proportion formulas and belief formulas, we use a special case of what were called in <ref> [Hal90] </ref> type-3 structures.
Reference: [Jae94a] <author> M. Jaeger. </author> <title> A logic for default reasoning about probabilities. </title> <booktitle> In Proc. Tenth Annual Conference on Uncertainty Artificial Intelligence. </booktitle> <year> 1994. </year>
Reference-contexts: Our framework is slightly different from theirs, but we think this usage of the term is consistent with their intent. like to extend it so that it can also deal with subjective infor-mation. This is an issue that has received some attention recently <ref> [PV92, Jae94b, Jae94a] </ref>. We discuss three techniques here, and consider their application in the specific context of random worlds. As we shall see, all of our techniques are very closely based on well-known ideas in the literature.
Reference: [Jae94b] <author> M. Jaeger. </author> <title> Probabilistic reasoning in terminological logics. </title> <editor> In J. Doyle, E. Sandewall, and P. Torasso, editors, </editor> <booktitle> Principles of Knowledge Representation and Reasoning: Proc. Fourth International Conference (KR '94). </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, </address> <year> 1994. </year>
Reference-contexts: Our framework is slightly different from theirs, but we think this usage of the term is consistent with their intent. like to extend it so that it can also deal with subjective infor-mation. This is an issue that has received some attention recently <ref> [PV92, Jae94b, Jae94a] </ref>. We discuss three techniques here, and consider their application in the specific context of random worlds. As we shall see, all of our techniques are very closely based on well-known ideas in the literature. <p> In this paper, we focus on two instantiations of CEF. The first applies it to the random-worlds method. The second applies it to a variant of the maximum-entropy approach used by Paris and Vencovska [PV89] (and similar in spirit to the method used by Jaeger <ref> [Jae94b] </ref>), which we henceforth call the ME (inference) process. Using results of [GHK92, PV89], we prove that these two instantiations are equivalent. The third method we consider also applies only to certain types of inference processes.
Reference: [Jay78] <author> E. T. Jaynes. </author> <title> Where do we stand on maximum entropy? In R. </title> <editor> D. Levine and M. Tribus, editors, </editor> <booktitle> The Maximum Entropy Formalism, </booktitle> <pages> pages 15-118. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1978. </year>
Reference-contexts: Pr rw 1 ('jKB) is the degree of belief in ' given KB according to the random-worlds method. 2.3 Maximum entropy and cross-entropy The entropy of a probability distribution over a finite space W is !2W (!) ln ((!)). It has been argued <ref> [Jay78] </ref> that entropy measures the amount of information in a probability distribution, in the sense of information theory. The uniform distribution has the maximum possible entropy.
Reference: [Jef92] <author> R. C. Jeffrey. </author> <title> Probability and the Art of Judgement. </title> <publisher> Cambridge University Press, </publisher> <address> Cam-bridge, </address> <year> 1992. </year>
Reference-contexts: We simply use the prior generated by the method to assign relative weights to the worlds in the sets determined by Red (b) and :Red (b), and then scale these weights within each set so that the sets are assigned probability 0:8 and 0:2 respectively. (Readers familiar with Jeffrey's rule <ref> [Jef92] </ref> will realize that this is essentially an application of that rule.) Again, intuitively, we are considering the distribution closest to the original prior that gives the set of worlds satisfying Red (b) probability 0:8. Unfortunately, the knowledge base is rarely this simple. <p> We thus immediately get: Proposition 3.1: If KB is objective, then CEW (I)('jKB) = I ('jKB). Thus, CEW (I) is a true extension of I. Another important property of CEW follows from the well-known fact that cross-entropy generalizes Jeffrey's rule <ref> [Jef92] </ref>. Standard probability theory tells us that if we start with a probability function and observe that event E holds, we should update to the conditional probability function (jE).
Reference: [KL51] <author> S. Kullback and R. A. Leibler. </author> <title> On information and sufficiency. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 22 </volume> <pages> 76-86, </pages> <year> 1951. </year>
Reference-contexts: Nevertheless, we would like to maintain the intuition that we are considering the distribution closest to the original prior that satisfies the constraints imposed by the KB. But how do we determine the closest distribution? One way is by using cross-entropy <ref> [KL51] </ref>. Given two probability distributions and 0 , the cross-entropy of 0 relative to , denoted C ( 0 ; ), is a measure of how far 0 is from [SJ80, Sho86].
Reference: [Lan80] <author> L. D. </author> <title> Landau. </title> <journal> Statistical Physics, </journal> <volume> volume 1. </volume> <publisher> Pergamon Press, </publisher> <year> 1980. </year>
Reference-contexts: Once all degree of belief assertions have been converted into statistical assertions, we can then apply any method for inferring degrees of belief from statistical knowledge bases. We call this the RS method (for representative set). The general intuition for this method goes back to statistical mechanics <ref> [Lan80] </ref>. It was also defined (independently it seems) by Paris and Vencovska [PV92]; we follow their presentation here. Paris and Vencovska showed that the RS method and the CEF method agree when applied to their version of the ME process. <p> This general idea goes back to work in the field of statistical mechanics <ref> [Lan80] </ref>, where it has been applied to the problem of reasoning about the total energy of physical systems. If the system consists of many particles then what is, in essence, a random-worlds analysis can be appropriate.
Reference: [PV89] <author> J. B. Paris and A. Vencovska. </author> <title> On the applicability of maximum entropy to inexact reasoning. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 3 </volume> <pages> 1-34, </pages> <year> 1989. </year>
Reference-contexts: More generally, given any inference process 3 i.e., a method for generating degrees of belief from objective informationwe would worlds), this problem can be viewed as an instance of the general problem of conditioning a distribution on uncertain evidence. 3 The term inference process is taken from Paris and Vencov-ska <ref> [PV89] </ref>. Our framework is slightly different from theirs, but we think this usage of the term is consistent with their intent. like to extend it so that it can also deal with subjective infor-mation. This is an issue that has received some attention recently [PV92, Jae94b, Jae94a]. <p> In this paper, we focus on two instantiations of CEF. The first applies it to the random-worlds method. The second applies it to a variant of the maximum-entropy approach used by Paris and Vencovska <ref> [PV89] </ref> (and similar in spirit to the method used by Jaeger [Jae94b]), which we henceforth call the ME (inference) process. Using results of [GHK92, PV89], we prove that these two instantiations are equivalent. The third method we consider also applies only to certain types of inference processes. <p> The first applies it to the random-worlds method. The second applies it to a variant of the maximum-entropy approach used by Paris and Vencovska [PV89] (and similar in spirit to the method used by Jaeger [Jae94b]), which we henceforth call the ME (inference) process. Using results of <ref> [GHK92, PV89] </ref>, we prove that these two instantiations are equivalent. The third method we consider also applies only to certain types of inference processes. In particular, it takes as its basic intuition that all degrees of belief must ultimately be the result of some statistical process. <p> It was also defined (independently it seems) by Paris and Vencovska [PV92]; we follow their presentation here. Paris and Vencovska showed that the RS method and the CEF method agree when applied to their version of the ME process. Using results of <ref> [GHK92, PV89] </ref>, we can show that the methods also agree when applied to our version of the ME process and when applied to random worlds. <p> uniform distribution among those distributions satisfying some constraints S, is exactly the distribution of maximum entropy satisfying S. 6 This maximum-entropy characterization demonstrates that Pr CEW 1 extends random worlds by making the probabilities of the possible worlds as equal as possible given the constraints. 3.2 CEF Paris and Vencovska <ref> [PV89] </ref> consider inferences processes that are not world-based, so CEW cannot be applied to them. The method CEF we now define applies to arbitrary inference processes, but requires that the knowledge base be of a restricted form. <p> Atoms are always mutually exclusive and exhaustive; so, if we could find appropriate degrees of belief for these atoms, we could again define things so that Proposition 3.2 holds. A simple way of doing this 6 We remark that in <ref> [GHK92, PV89] </ref> a connection was established between random worlds and maximum entropy. Here maximum entropy is playing a different role. It is being used here to extend random worlds rather than to characterize properties of random worlds as in [GHK92, PV89]. would be to assume that, after conditioning, the assertions i <p> A simple way of doing this 6 We remark that in <ref> [GHK92, PV89] </ref> a connection was established between random worlds and maximum entropy. Here maximum entropy is playing a different role. It is being used here to extend random worlds rather than to characterize properties of random worlds as in [GHK92, PV89]. would be to assume that, after conditioning, the assertions i are independent. But, as we observed in the introduction, assuming independence is inappropriate in general. Our solution is to first employ cross-entropy to find appropriate probabilities for these atoms. We proceed as follows. <p> This means that CEF (Pr rw 1 )(Red (Tweety)jKB ^ BB) is undefined. We next consider what happens when we instantiate CEF with a particular inference process considered by Paris and Vencovska that uses maximum entropy <ref> [PV89] </ref>. Paris and Vencovska restrict attention to rather simple languages, corresponding to the notion of essentially propositional formulas defined below. When considering (our variant) of their method we shall make the same restriction. <p> We can only apply CEF to ME if the knowledge base has the form KB ^ BB, where KB is a simple knowledge base about c and BB is a simple belief base about c. It follows from results of <ref> [GHK92, PV89] </ref> that random worlds and ME give the same results on their common domain. Hence, they are also equal after we apply the CEF transformation.
Reference: [PV92] <author> J. B. Paris and A. Vencovska. </author> <title> A method for updating justifying minimum cross entropy. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 1-2:1-18, </volume> <year> 1992. </year>
Reference-contexts: One way of guaranteeing this is to actually generate them from the objective information available to the agent. Several ways of doing this have been considered in the literature; for example, <ref> [BGHK92, PV92] </ref> each discuss several possibilities. The approaches in [BGHK92] are based in a very natural way on the semantics described above. Assume we have a (prior) probability distribution over some set of worlds. <p> Our framework is slightly different from theirs, but we think this usage of the term is consistent with their intent. like to extend it so that it can also deal with subjective infor-mation. This is an issue that has received some attention recently <ref> [PV92, Jae94b, Jae94a] </ref>. We discuss three techniques here, and consider their application in the specific context of random worlds. As we shall see, all of our techniques are very closely based on well-known ideas in the literature. <p> As we shall see, all of our techniques are very closely based on well-known ideas in the literature. Two make use of cross-entropy, while the third is a generalization of a method considered by Paris and Vencov-ska <ref> [PV92] </ref>. They are conceptually and formally distinct, yet there are some interesting connections between them. In particular, in the context of random-worlds they generally yield the same answers (where the comparison makes sense; the various methods have different ranges of applicability). <p> We call this the RS method (for representative set). The general intuition for this method goes back to statistical mechanics [Lan80]. It was also defined (independently it seems) by Paris and Vencovska <ref> [PV92] </ref>; we follow their presentation here. Paris and Vencovska showed that the RS method and the CEF method agree when applied to their version of the ME process. <p> A more recent, and quite different, appearance of this intuition is in the work of Paris and Vencovska <ref> [PV92] </ref>. They defined their method so that it has the same restricted scope as the ME method. We present a more general version here, that can handle a somewhat richer set of knowledge bases, although its scope is still more restricted than CEF. <p> It is almost immediate from the definitions that if BB is a simple belief base about c, then RS (Pr rw 1 )('(c)jKB ^ t;rw N )('jKB). We abbreviate RS (Pr rw 1 . In general, RS and CEF are distinct. This observation follows from results of <ref> [PV92] </ref> concerning an infer ence process CM, showing that RS (CM) cannot be equal to CEF (CM). On the other hand, they show that, in the restricted setting in which ME applies, RS (ME) = CEF (ME).
Reference: [Sho86] <author> J. E. Shore. </author> <title> Relative entropy, probabilistic inference, and AI. </title> <editor> In L. N. Kanal and J. F. Lem-mer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence. </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1986. </year>
Reference-contexts: But how do we determine the closest distribution? One way is by using cross-entropy [KL51]. Given two probability distributions and 0 , the cross-entropy of 0 relative to , denoted C ( 0 ; ), is a measure of how far 0 is from <ref> [SJ80, Sho86] </ref>. Given an inference method that generates a prior and a set of constraints determined by the KB, we can then find the distribution on worlds satisfying the constraints that minimizes cross-entropy relative to the prior, and then use this new distribution to compute degrees of belief. <p> The related cross-entropy function measures the additional information gained by moving from one distribution to another distribution 0 : C ( 0 ; ) = !2W 0 (!) : Various arguments have been presented showing that cross-entropy measures how close one probability distribution is to another <ref> [SJ80, Sho86] </ref>. Thus, given a prior distribution and a set S of additional constraints, we are typically interested in the unique distribution 0 that satisfies S and minimizes C ( 0 ; ).
Reference: [SJ80] <author> J. E. Shore and R. W. Johnson. </author> <title> Axiomatic derivation of the principle of maximum entropy and the principle of minimimum cross-entropy. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-26(1):26-37, </volume> <year> 1980. </year>
Reference-contexts: But how do we determine the closest distribution? One way is by using cross-entropy [KL51]. Given two probability distributions and 0 , the cross-entropy of 0 relative to , denoted C ( 0 ; ), is a measure of how far 0 is from <ref> [SJ80, Sho86] </ref>. Given an inference method that generates a prior and a set of constraints determined by the KB, we can then find the distribution on worlds satisfying the constraints that minimizes cross-entropy relative to the prior, and then use this new distribution to compute degrees of belief. <p> The related cross-entropy function measures the additional information gained by moving from one distribution to another distribution 0 : C ( 0 ; ) = !2W 0 (!) : Various arguments have been presented showing that cross-entropy measures how close one probability distribution is to another <ref> [SJ80, Sho86] </ref>. Thus, given a prior distribution and a set S of additional constraints, we are typically interested in the unique distribution 0 that satisfies S and minimizes C ( 0 ; ).
References-found: 15

