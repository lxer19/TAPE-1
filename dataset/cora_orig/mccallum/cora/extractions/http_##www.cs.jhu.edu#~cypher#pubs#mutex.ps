URL: http://www.cs.jhu.edu/~cypher/pubs/mutex.ps
Refering-URL: http://www.cs.jhu.edu/~cypher/pubs/pubs.html
Root-URL: http://www.cs.jhu.edu
Email: cypher@cs.jhu.edu  
Title: The Communication Requirements of Mutual Exclusion  
Author: Robert Cypher 
Address: Baltimore, MD 21218  
Affiliation: Department of Computer Science Johns Hopkins University  
Abstract: This paper examines the amount of communication that is required for performing mutual exclusion. It is assumed that n processors communicate via accesses to a shared memory that is physically distributed among the processors. We consider the possibility of creating a scalable mutual exclusion protocol that requires only a constant amount of communication per access to a critical section. We present two main results. First, we show that there does not exist a scalable mutual exclusion protocol that uses only read and write operations. This result solves an open problem posed by Yang and Anderson. Second, we prove that the same result holds even if test-and-set, compare-and-swap, load-and-reserve and store-conditional operations are allowed in addition to read and write operations. Our results hold even if an amortized analysis of communication costs is used, an arbitrary amount of memory is available, and the processors have coherent caches. In contrast, a mutual exclusion protocol is known that uses only read, write and swap operations, performs a constant amount of communication per access to the critical section, uses a constant amount of memory per process, and does not require coherent caches. Our results suggest that many current generation microprocessors have instruction sets that are not well-suited to performing mutual exclusion in a shared memory environment. fl A preliminary version of this paper appeared in the Proceedings of the Seventh ACM Symposium on Parallel Algorithms and Architectures, 1995. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal, R. Simoni, J. Hennessy, and M. Horowitz, </author> <title> "An Evaluation of Directory Schemes for Cache Coherence", </title> <booktitle> in Proc. 15th Intl. Symp. on Computer Architecture, </booktitle> <pages> pp. 280-289, </pages> <year> 1988. </year>
Reference-contexts: Many different atomic operations, including test-and-set, compare-and-swap, read-and-increment, and swap have been proposed and/or implemented [16]. Second, the hardware can support coherent caching of shared memory locations, in which case processes can busy wait on locally cached data without generating communication <ref> [1, 4, 11, 18] </ref>. Third, part or all of the shared memory can be divided into regions, each of which is physically local to some processor [8, 18]. In this case, processes can busy wait on shared memory locations that are physically local without generating communication. <p> The communication cost captures the minimal amount of communication that would be generated by a sequentially consistent [17] cache coherence protocol running on a parallel computer in which the processors communicate over an interconnection network <ref> [1, 4, 11, 18] </ref>. (The issue of performing mutual exclusion on a bus-based parallel computer is examined in Section 5.) Note that the communication cost is conservative as it does not include the cost of updating or invalidating read-only copies of variables when they are modified.
Reference: [2] <author> T.E. Anderson, </author> <title> "The Performance of Spin Lock Alternatives for Shared Memory Multiprocessors", </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 6-16, </pages> <year> 1990. </year>
Reference-contexts: In a parallel or distributed computer, the use of busy waiting can generate an unbounded amount of communication, thus seriously degrading the performance of the system <ref> [2, 21, 26] </ref>. Several types of hardware features can reduce the communication costs of performing mutual exclusion. First, the hardware can support special atomic operations in addition to the standard read and write operations. Many different atomic operations, including test-and-set, compare-and-swap, read-and-increment, and swap have been proposed and/or implemented [16]. <p> Although this protocol only busy waits on locally cached variables, Anderson has shown that the communication that it generates can still be significant <ref> [2] </ref>. Anderson has also proposed a protocol that uses the read-and-increment primitive to reduce communication [2]. 1 In addition, several mutual exclusion protocols that use physically local shared memory have been created. <p> Although this protocol only busy waits on locally cached variables, Anderson has shown that the communication that it generates can still be significant <ref> [2] </ref>. Anderson has also proposed a protocol that uses the read-and-increment primitive to reduce communication [2]. 1 In addition, several mutual exclusion protocols that use physically local shared memory have been created.
Reference: [3] <author> H. Attiya and R. Friedman, </author> <title> "Programming DEC-Alpha Based Multiprocessors the Easy Way", </title> <booktitle> in Proc. ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 157-166, </pages> <year> 1994. </year>
Reference-contexts: Our results suggest that many current generation microprocessors have instruction sets that are not well-suited to performing mutual exclusion in a shared memory environment. For example, the DEC Alpha <ref> [3, 9] </ref> and the IBM-Motorola-Apple PowerPC [14] only support read, write, load-and-reserve, and store-conditional primitives. The remainder of the paper is organized as follows.
Reference: [4] <author> D. Chaiken, J. Kubiatowicz, and A. Agarwal, </author> <title> "LimitLESS Directories: A Scalable Cache Coherence Scheme", </title> <booktitle> in Proc. 4th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp. 224-234, </pages> <year> 1991. </year>
Reference-contexts: Many different atomic operations, including test-and-set, compare-and-swap, read-and-increment, and swap have been proposed and/or implemented [16]. Second, the hardware can support coherent caching of shared memory locations, in which case processes can busy wait on locally cached data without generating communication <ref> [1, 4, 11, 18] </ref>. Third, part or all of the shared memory can be divided into regions, each of which is physically local to some processor [8, 18]. In this case, processes can busy wait on shared memory locations that are physically local without generating communication. <p> The communication cost captures the minimal amount of communication that would be generated by a sequentially consistent [17] cache coherence protocol running on a parallel computer in which the processors communicate over an interconnection network <ref> [1, 4, 11, 18] </ref>. (The issue of performing mutual exclusion on a bus-based parallel computer is examined in Section 5.) Note that the communication cost is conservative as it does not include the cost of updating or invalidating read-only copies of variables when they are modified.
Reference: [5] <editor> G. Chartrand and L. Lesniak, </editor> <title> Graphs & Digraphs, Wadsworth & Brooks/Cole Advanced Books & Software, </title> <address> Monterey, CA, </address> <note> second edition, </note> <year> 1986. </year>
Reference-contexts: Note that the maximum degree of G is at most s j =2rm 1, so there must exist a vertex coloring of G that uses at most s j =2rm colors <ref> [5] </ref>. Let R be any subset of V consisting of at least jlight (j)j2rm=s j vertices that received the same color in this vertex coloring. Note that R S j and for each x; y 2 R where x 6= y, y 62 hits (x; j 1; S).
Reference: [6] <author> T.S. Craig, </author> <title> "Queuing Spin Lock Algorithms to Support Timing Predictability", </title> <booktitle> in Proc. Real-Time Systems Symp., </booktitle> <pages> pp. 148-157, </pages> <year> 1993. </year>
Reference-contexts: Furthermore, Craig created a protocol for strong mutual exclusion that uses only read, write and swap primitives <ref> [6, 7] </ref>. All three of these protocols perform only a constant amount of communication per critical section access, require only a constant amount of (physically local) memory per process, and do not require coherent caches. <p> These results are surprising, as Mellor-Crummey and Scott's algorithm for weak mutual exclusion [19] and Craig's algorithm for strong mutual exclusion <ref> [6, 7] </ref> use only read, write, and swap 1 operations, perform a constant amount of communication per access to the critical section, use a constant amount of memory per process, and do not require coherent caches. <p> As a result, the processes are able to create a distributed linked list of the processes that performed swap operations to the given memory location. Such linked lists are the basis for the communication-efficient mutual exclusion algorithms that use the swap primitive <ref> [6, 7, 19] </ref>. 5 Mutual Exclusion on Bus-Based Systems The metric for communication costs used in Sections 2 through 4 was designed for parallel computers in which the processors communicate via an interconnection network.
Reference: [7] <author> T.S. Craig, </author> <title> "Building FIFO and Priority-Queuing Spin Locks from Atomic Swap", </title> <type> Tech. Rep. </type> <institution> 93-02-02, Dept. of Comp. Sci. and Eng., U. of Washington, </institution> <year> 1993. </year>
Reference-contexts: Furthermore, Craig created a protocol for strong mutual exclusion that uses only read, write and swap primitives <ref> [6, 7] </ref>. All three of these protocols perform only a constant amount of communication per critical section access, require only a constant amount of (physically local) memory per process, and do not require coherent caches. <p> These results are surprising, as Mellor-Crummey and Scott's algorithm for weak mutual exclusion [19] and Craig's algorithm for strong mutual exclusion <ref> [6, 7] </ref> use only read, write, and swap 1 operations, perform a constant amount of communication per access to the critical section, use a constant amount of memory per process, and do not require coherent caches. <p> As a result, the processes are able to create a distributed linked list of the processes that performed swap operations to the given memory location. Such linked lists are the basis for the communication-efficient mutual exclusion algorithms that use the swap primitive <ref> [6, 7, 19] </ref>. 5 Mutual Exclusion on Bus-Based Systems The metric for communication costs used in Sections 2 through 4 was designed for parallel computers in which the processors communicate via an interconnection network.
Reference: [8] <author> Cray Research Inc., </author> <title> "SHMEM Technical Note for C", </title> <type> Tech. Rep., </type> <institution> Cray Research Inc., Eagan, MN, </institution> <month> October 25, </month> <year> 1994. </year>
Reference-contexts: Third, part or all of the shared memory can be divided into regions, each of which is physically local to some processor <ref> [8, 18] </ref>. In this case, processes can busy wait on shared memory locations that are physically local without generating communication. Other types of hardware features for mutual exclusion have also been considered [12, 13]. A number of mutual exclusion protocols have been based on the use of coherent caches.
Reference: [9] <institution> Digital Equipment Corporation, The Alpha Architecture Handbook, </institution> <year> 1992. </year>
Reference-contexts: Our results suggest that many current generation microprocessors have instruction sets that are not well-suited to performing mutual exclusion in a shared memory environment. For example, the DEC Alpha <ref> [3, 9] </ref> and the IBM-Motorola-Apple PowerPC [14] only support read, write, load-and-reserve, and store-conditional primitives. The remainder of the paper is organized as follows.
Reference: [10] <author> E.W. Dijkstra, </author> <title> "Solution of a Problem in Concurrent Programming Control", </title> <journal> Communications of the ACM, </journal> <volume> vol. 8, no. 9, </volume> <editor> p. </editor> <volume> 569, </volume> <year> 1965. </year>
Reference-contexts: In this paper we consider solutions to the mutual exclusion problem that are based on accesses to shared memory. In the paper that introduced the problem, Dijkstra presented a protocol for the weak mutual exclusion problem that uses only standard read and write primitives <ref> [10] </ref>. The problem of implementing strong mutual exclusion using only read and write operations was solved by Knuth [15].
Reference: [11] <author> M. Dubois, C. Scheurich, and F.A. Briggs, </author> <title> "Synchronization, Coherence, and Event Ordering in Multiprocessors", </title> <booktitle> IEEE Computer, </booktitle> <pages> pp. 9-21, </pages> <month> Feb. </month> <year> 1988. </year>
Reference-contexts: Many different atomic operations, including test-and-set, compare-and-swap, read-and-increment, and swap have been proposed and/or implemented [16]. Second, the hardware can support coherent caching of shared memory locations, in which case processes can busy wait on locally cached data without generating communication <ref> [1, 4, 11, 18] </ref>. Third, part or all of the shared memory can be divided into regions, each of which is physically local to some processor [8, 18]. In this case, processes can busy wait on shared memory locations that are physically local without generating communication. <p> The communication cost captures the minimal amount of communication that would be generated by a sequentially consistent [17] cache coherence protocol running on a parallel computer in which the processors communicate over an interconnection network <ref> [1, 4, 11, 18] </ref>. (The issue of performing mutual exclusion on a bus-based parallel computer is examined in Section 5.) Note that the communication cost is conservative as it does not include the cost of updating or invalidating read-only copies of variables when they are modified.
Reference: [12] <author> J.R. Goodman, M.K. Vernon, and P.J. Woest, </author> <title> "Efficient Synchronization Primitives for Large-Scale Cache-Coherent Multiprocessors", </title> <booktitle> in Proc. Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp. 64-75, </pages> <year> 1989. </year>
Reference-contexts: In this case, processes can busy wait on shared memory locations that are physically local without generating communication. Other types of hardware features for mutual exclusion have also been considered <ref> [12, 13] </ref>. A number of mutual exclusion protocols have been based on the use of coherent caches.
Reference: [13] <author> A. Gottlieb, R. Grishman, C.P. Kruskal, K.P. McAuliffe, L. Rudolph, and M. Snir, </author> <title> "The NYU Ultracomputer Designing an MIMD, Shared Memory Parallel Machine", </title> <journal> IEEE Trans. on Computers, </journal> <volume> vol. 32, </volume> <pages> pp. 175-189, </pages> <year> 1983. </year>
Reference-contexts: In this case, processes can busy wait on shared memory locations that are physically local without generating communication. Other types of hardware features for mutual exclusion have also been considered <ref> [12, 13] </ref>. A number of mutual exclusion protocols have been based on the use of coherent caches.
Reference: [14] <institution> International Business Machines Corp., </institution> <note> PowerPC Architecture (First Edition), </note> <month> May </month> <year> 1993. </year>
Reference-contexts: Our results suggest that many current generation microprocessors have instruction sets that are not well-suited to performing mutual exclusion in a shared memory environment. For example, the DEC Alpha [3, 9] and the IBM-Motorola-Apple PowerPC <ref> [14] </ref> only support read, write, load-and-reserve, and store-conditional primitives. The remainder of the paper is organized as follows.
Reference: [15] <author> D.E. Knuth, </author> <title> "Additional Comments on a Problem in Concurrent Programming Con--trol", </title> <journal> Communications of the ACM, </journal> <volume> vol. 9, no. 5, </volume> <pages> pp. 321-322, </pages> <year> 1966. </year>
Reference-contexts: In the paper that introduced the problem, Dijkstra presented a protocol for the weak mutual exclusion problem that uses only standard read and write primitives [10]. The problem of implementing strong mutual exclusion using only read and write operations was solved by Knuth <ref> [15] </ref>. A necessary feature of any shared memory solution to the mutual exclusion problem is the use of busy waiting, in which a process enters a loop and repeatedly accesses one or more memory locations.
Reference: [16] <author> C.P. Kruskal, L. Rudolph, and M. Snir, </author> <title> "Efficient Synchronization on Multiprocessors with Shared Memory", </title> <booktitle> in Proc. ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pp. 218-228, </pages> <year> 1986. </year>
Reference-contexts: Several types of hardware features can reduce the communication costs of performing mutual exclusion. First, the hardware can support special atomic operations in addition to the standard read and write operations. Many different atomic operations, including test-and-set, compare-and-swap, read-and-increment, and swap have been proposed and/or implemented <ref> [16] </ref>. Second, the hardware can support coherent caching of shared memory locations, in which case processes can busy wait on locally cached data without generating communication [1, 4, 11, 18].
Reference: [17] <author> L. Lamport, </author> <title> "How to Make a Multiprocessor Computer that Correctly Executes Mul-tiprocess Programs", </title> <journal> IEEE Trans. on Computers, </journal> <volume> vol. 28, no. 9, </volume> <pages> pp. 690-691, </pages> <year> 1979. </year>
Reference-contexts: Informally, only a remote write that overwrites a different process' value or the first remote read by a process that detects a value written by a different process causes communication. The communication cost captures the minimal amount of communication that would be generated by a sequentially consistent <ref> [17] </ref> cache coherence protocol running on a parallel computer in which the processors communicate over an interconnection network [1, 4, 11, 18]. (The issue of performing mutual exclusion on a bus-based parallel computer is examined in Section 5.) Note that the communication cost is conservative as it does not include the
Reference: [18] <author> D. Lenoski, J. Laudon, K. Gharachorloo, A. Gupta, and J. Hennessy, </author> <title> "The Directory-Based Cache Coherence Protocol for the DASH Multiprocessor", </title> <booktitle> in Proc. Intl. Symp. on Computer Architecture, </booktitle> <pages> pp. 148-159, </pages> <year> 1990. </year>
Reference-contexts: Many different atomic operations, including test-and-set, compare-and-swap, read-and-increment, and swap have been proposed and/or implemented [16]. Second, the hardware can support coherent caching of shared memory locations, in which case processes can busy wait on locally cached data without generating communication <ref> [1, 4, 11, 18] </ref>. Third, part or all of the shared memory can be divided into regions, each of which is physically local to some processor [8, 18]. In this case, processes can busy wait on shared memory locations that are physically local without generating communication. <p> Third, part or all of the shared memory can be divided into regions, each of which is physically local to some processor <ref> [8, 18] </ref>. In this case, processes can busy wait on shared memory locations that are physically local without generating communication. Other types of hardware features for mutual exclusion have also been considered [12, 13]. A number of mutual exclusion protocols have been based on the use of coherent caches. <p> The communication cost captures the minimal amount of communication that would be generated by a sequentially consistent [17] cache coherence protocol running on a parallel computer in which the processors communicate over an interconnection network <ref> [1, 4, 11, 18] </ref>. (The issue of performing mutual exclusion on a bus-based parallel computer is examined in Section 5.) Note that the communication cost is conservative as it does not include the cost of updating or invalidating read-only copies of variables when they are modified.
Reference: [19] <author> J.M. Mellor-Crummey and M.L. Scott, </author> <title> "Algorithms for Scalable Synchronization on Shared Memory Multiprocessors", </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> vol. 9, no. 1, </volume> <pages> pp. 21-65, </pages> <year> 1991. </year>
Reference-contexts: Mellor-Crummey and Scott presented a protocol for strong mutual exclusion that uses only read, write, compare-and-swap, and swap primitives, and a protocol for weak mutual exclusion that uses only read, write, and swap primitives <ref> [19] </ref>. Furthermore, Craig created a protocol for strong mutual exclusion that uses only read, write and swap primitives [6, 7]. <p> These results are surprising, as Mellor-Crummey and Scott's algorithm for weak mutual exclusion <ref> [19] </ref> and Craig's algorithm for strong mutual exclusion [6, 7] use only read, write, and swap 1 operations, perform a constant amount of communication per access to the critical section, use a constant amount of memory per process, and do not require coherent caches. <p> As a result, the processes are able to create a distributed linked list of the processes that performed swap operations to the given memory location. Such linked lists are the basis for the communication-efficient mutual exclusion algorithms that use the swap primitive <ref> [6, 7, 19] </ref>. 5 Mutual Exclusion on Bus-Based Systems The metric for communication costs used in Sections 2 through 4 was designed for parallel computers in which the processors communicate via an interconnection network.
Reference: [20] <author> M. Merritt and G. Taubenfeld, </author> <title> "Knowledge in Shared Memory Systems", </title> <booktitle> in Proc. ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pp. 189-200, </pages> <year> 1991. </year>
Reference-contexts: 5. 1 More precisely, these algorithms use a register-to-memory swap operation which atomically exchanges the contents of a register with the contents of a memory location. 2 2 Preliminaries 2.1 Formal Model Our model of an asynchronous shared memory protocol is based on the model given by Merritt and Taubenfeld <ref> [20] </ref>. In this section we will present a model that allows only atomic read and write operations. Other atomic primitives will be considered in Section 4.
Reference: [21] <author> G. Pfister and V.A. Norton, </author> <title> "Hot Spot Contention and Combining in Multistage Interconnection Networks", </title> <journal> IEEE Trans. on Computers, </journal> <volume> vol. 34, no. 10, </volume> <pages> pp. 943-948, </pages> <year> 1985. </year>
Reference-contexts: In a parallel or distributed computer, the use of busy waiting can generate an unbounded amount of communication, thus seriously degrading the performance of the system <ref> [2, 21, 26] </ref>. Several types of hardware features can reduce the communication costs of performing mutual exclusion. First, the hardware can support special atomic operations in addition to the standard read and write operations. Many different atomic operations, including test-and-set, compare-and-swap, read-and-increment, and swap have been proposed and/or implemented [16].
Reference: [22] <author> M. Raynal, </author> <title> Algorithms for Mutual Exclusion, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: 1 Introduction The mutual exclusion problem is a fundamental coordination problem in asynchronous systems <ref> [22] </ref>. In this problem, all accesses that a process makes to a shared resource are contained within a section of code called a critical section.
Reference: [23] <author> A. Segall and L. Rudolph, </author> <title> "Dynamic Decentralized Cache Schemes for an MIMD Parallel Processor", </title> <booktitle> in Proc. Intl. Symp. on Computer Architecture, </booktitle> <pages> pp. 340-347, </pages> <year> 1984. </year>
Reference-contexts: In particular, Segall and Rudolph proposed a mutual exclusion protocol for cache coherent shared memories that first busy waits on a lock variable until it becomes free, and then performs a test-and-set to the lock variable <ref> [23] </ref>. Although this protocol only busy waits on locally cached variables, Anderson has shown that the communication that it generates can still be significant [2].
Reference: [24] <author> J-H. Yang and J.H. Anderson, </author> <title> "Fast, Scalable Synchronization with Minimal Hardware Support", </title> <booktitle> in Proc. ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pp. 171-182, </pages> <year> 1993. </year>
Reference-contexts: Yang and Anderson developed a solution to the strong mutual exclusion problem for n processes that performs O (log n) communication per critical section access, and does not require coherent caches <ref> [24] </ref>.
Reference: [25] <author> J-H. Yang and J.H. Anderson, </author> <title> "Time Bounds for Mutual Exclusion and Related Problems", </title> <booktitle> in Proc. ACM Symp. on Theory of Computing, </booktitle> <pages> pp. 224-233, </pages> <year> 1994. </year>
Reference-contexts: between the amounts of contention and communication required for performing mutual exclusion, and they stated as an open problem the question of whether or not it is possible to create a scalable protocol that performs a constant amount of communication per critical section access using only read and write operations <ref> [25] </ref>. In this paper we present two main results. First, we show that there does not exist a scalable mutual exclusion protocol that uses only read and write operations, thus solving the open problem posed by Yang and Anderson [25]. <p> communication per critical section access using only read and write operations <ref> [25] </ref>. In this paper we present two main results. First, we show that there does not exist a scalable mutual exclusion protocol that uses only read and write operations, thus solving the open problem posed by Yang and Anderson [25]. Second, we prove that the same result holds even if test-and-set, compare-and-swap, load-and-reserve and store-conditional operations are allowed in addition to read and write operations.
Reference: [26] <author> P-C. Yew, N-F. Tzeng, and D.H. Lawrie, </author> <title> "Distributing Hot-Spot Addressing in Large-Scale Multiprocessors", </title> <journal> IEEE Trans. on Computers, </journal> <volume> vol. 36, no. 4, </volume> <pages> pp. 388-395, </pages> <year> 1987. </year> <month> 24 </month>
Reference-contexts: In a parallel or distributed computer, the use of busy waiting can generate an unbounded amount of communication, thus seriously degrading the performance of the system <ref> [2, 21, 26] </ref>. Several types of hardware features can reduce the communication costs of performing mutual exclusion. First, the hardware can support special atomic operations in addition to the standard read and write operations. Many different atomic operations, including test-and-set, compare-and-swap, read-and-increment, and swap have been proposed and/or implemented [16].
References-found: 26

