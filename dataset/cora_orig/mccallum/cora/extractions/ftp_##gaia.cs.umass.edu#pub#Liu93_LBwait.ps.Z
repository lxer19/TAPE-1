URL: ftp://gaia.cs.umass.edu/pub/Liu93:LBwait.ps.Z
Refering-URL: http://www-net.cs.umass.edu/papers/papers.html
Root-URL: 
Title: Burst Reduction Properties of Rate-Control Throttles: Downstream Queue Behavior  
Author: Zhen LIU Don TOWSLEY 
Keyword: ATM, leaky bucket, rate-based flow control, token bank.  
Note: The work of this author was supported in part by the CEC DG XIII under the ESPRIT BRA grant QMIPS. The work of this author was supported in part by the Natinal Science Foundation under grants ASC-8802764 and NCR-911618.  
Date: October 1993, Revised May 1994  
Address: 2004 Route des Lucioles 06560 Valbonne France  Amherst, MA 01003 U.S.A.  
Affiliation: INRIA Centre Sophia Antipolis  Dept. of Computer Science University of Massachusetts  
Abstract: In this paper we consider rate-based flow control throttles feeding a sequence of single server infinite capacity queues. Specifically, we consider two types of throttles, the token bank and the leaky bucket. We show that the cell waiting times at the downstream queues are increasing functions of the token buffer capacity. These results are established when the rate-based throttles have finite capacity data buffers as well as infinite capacity buffers. In the case that the data buffer has finite capacity, we require that the sum of the capacities of the data buffer and token buffer be a constant. Last, we establish similar results for the process of number of losses at the last downstream queue in the case that the waiting buffer has finite capacity. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Anantharam, P. Konstantopoulos, </author> <title> "Burst Reduction Properties of the Leaky Bucket Flow Control Scheme in ATM Networks", </title> <type> manuscript. </type>
Reference-contexts: Several papers have also studied the burst reduction properties of rate-control throttles. Results on the effects of different parameters on the departure process from the throttle can be found in [12, 13] for the case of the token bank, and [16] for both throttles. Anantharam and Konstantopoulos <ref> [1] </ref> studied the effect of varying the token buffer capacity on the buffer occupancy of the first queue on the path in the network. <p> In addition, similar results can be obtained for stationary cell delays and cell losses under appropriate assumptions on the cell arrival process. Examples of the types of assumptions required for the latter extension can be found in <ref> [1] </ref> and [16]. 7 Appendix: Proof of Lemma 5.1 In order to prove Lemma 5.1, we need the following lemma.
Reference: [2] <author> A. W. Berger, </author> <title> "Performance Analysis of a Rate-Control Throttle where Tokens and Jobs Queue", </title> <journal> IEEE J-SAC, </journal> <volume> Vol. 9, </volume> <pages> pp. 165-170, </pages> <year> 1991. </year>
Reference-contexts: One mechanism that has received considerable attention is the leaky bucket rate-based flow control throttle [20]. Numerous performance studies have evaluated the effectiveness of this mechanism through either simulation or analysis (see <ref> [19, 18, 2] </ref> for examples of such studies). The goal of this paper is to investigate qualitatively the burst reduction properties of two variations of this mechanism: the token bank and the leaky bucket.
Reference: [3] <author> A. W. Berger, W. Whitt, </author> <title> "The Impact of a Job Buffer in a Token-bank Rate-control Throttle" , Stochastic Models, </title> <booktitle> 8, </booktitle> <pages> pp. 685-717, </pages> <year> 1992. </year>
Reference-contexts: In a related study, Budka [7] examined monotonicity and convexity properties of the throughput of several rate-control throttles including the token bank and leaky bucket using sample path arguments. Our use of the terminology "token bank" and "leaky bucket" is taken from this study. Berger and Whitt <ref> [3] </ref> used similar arguments to study the effect of buffer allocation between the token bank data buffer and the buffer at the first downstream node. Although our analysis establishes the qualitative benefits of rate-control throttles, it does not quantify those benefits. <p> Berger and Whitt [3] used similar arguments to study the effect of buffer allocation between the token bank data buffer and the buffer at the first downstream node. Although our analysis establishes the qualitative benefits of rate-control throttles, it does not quantify those benefits. The reader is referred to <ref> [3, 6] </ref> for such studies. These studies conclude that the benefits of rate-control may not be all that great. The remainder of the paper is organized as follows. Section 2 defines and introduces a formal model for the two throttles feeding a tandem queueing system. <p> The result for two token banks, (3.1), was established in <ref> [3] </ref>. Similar arguments can be used to establish this result for two leaky buckets (see [15] for details). We next characterize the departure process of cells from the throttle.
Reference: [4] <author> A. W. Berger, W. Whitt, </author> <title> "The brownian approximation for rate-control throttles and the B/G/1/C queue", Discrete Event Dynamic Systems: </title> <journal> Theory and Applications, </journal> <volume> 2, 1, </volume> <pages> pp. 7 - 60, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Therefore, by induction, relation (3.10) holds for all n 1. Related results were established in [7] comparing the number of accepted packets under the two throttles and in <ref> [4] </ref> comparing the stationary packet rejection probabilities for both throttles under different token buffer capacities.
Reference: [5] <author> A. W. Berger, W. Whitt, </author> <title> "Comparisons of multi-server queues with finite waiting rooms", Stochastic Models, </title> <booktitle> 8, </booktitle> <pages> pp. 719-732, </pages> <year> 1992. </year>
Reference-contexts: It is usually more difficult to compare the behavior of finite capacity queueing server systems. An exception to this is <ref> [5] </ref> which compares the loss processes of two finite capacity systems which differ in that the arrival process at one system is a subsequence of the arrival process at the other system.
Reference: [6] <author> A. W. Berger, W. Whitt, </author> <title> "Traffic shaping by a job buffer in a token-bank rate-control throttle", </title> <type> preprint. </type>
Reference-contexts: Berger and Whitt [3] used similar arguments to study the effect of buffer allocation between the token bank data buffer and the buffer at the first downstream node. Although our analysis establishes the qualitative benefits of rate-control throttles, it does not quantify those benefits. The reader is referred to <ref> [3, 6] </ref> for such studies. These studies conclude that the benefits of rate-control may not be all that great. The remainder of the paper is organized as follows. Section 2 defines and introduces a formal model for the two throttles feeding a tandem queueing system.
Reference: [7] <author> K. C. Budka, </author> <title> Sample Path Analysis of Flow Control Schemes for Packet Networks. </title> <type> PhD thesis, </type> <institution> Harvard University, Division of Applied Sciences, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: However, using a fluid model does not allow them to distinguish between the token bank and leaky bucket; both reduce to the same model using their approach. In a related study, Budka <ref> [7] </ref> examined monotonicity and convexity properties of the throughput of several rate-control throttles including the token bank and leaky bucket using sample path arguments. Our use of the terminology "token bank" and "leaky bucket" is taken from this study. <p> Therefore, by induction, relation (3.10) holds for all n 1. Related results were established in <ref> [7] </ref> comparing the number of accepted packets under the two throttles and in [4] comparing the stationary packet rejection probabilities for both throttles under different token buffer capacities.
Reference: [8] <author> R.L. Cruz, H.-N. </author> <title> Liu "Non-recursive identities for tandem queueing networks", </title> <type> preprint. 23 </type>
Reference-contexts: This might be reasonable in a network in which 5 bandwidth is partitioned between different sessions as exemplified by hierarchical round robin [11], stop-and-go [10], weighted fair queueing [9]. A similar approach has been taken in <ref> [17, 8] </ref>. 3 Basic Sample Path Characteristics We now present several preliminary comparison relations which will be used to prove our main results.
Reference: [9] <author> A. Demers, S. Keshav, and S. Shenker, </author> <title> "Analysis and simulation of a fair queueing algo-rithm", </title> <journal> Internetworking:Research and Experience, </journal> <volume> 1, 3 - 26, </volume> <month> May </month> <year> 1990. </year>
Reference-contexts: Some of our results are based on the assumption that service times are deterministic whereas others are not. Such a model can be used to represent a system that partitions bandwidth between sources at each switching node (e.g., <ref> [10, 11, 9] </ref>). Using sample path arguments, we show that the cell delay at each switch increases as the token buffer capacity increases and/or the token generation rate increases when no losses occur. <p> This might be reasonable in a network in which 5 bandwidth is partitioned between different sessions as exemplified by hierarchical round robin [11], stop-and-go [10], weighted fair queueing <ref> [9] </ref>. A similar approach has been taken in [17, 8]. 3 Basic Sample Path Characteristics We now present several preliminary comparison relations which will be used to prove our main results.
Reference: [10] <author> S.J. Golestani, </author> <title> "A stop-and-go framework for congestion management", </title> <booktitle> Proc. 1990 SIG-COMM, </booktitle> <pages> 8-18, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Some of our results are based on the assumption that service times are deterministic whereas others are not. Such a model can be used to represent a system that partitions bandwidth between sources at each switching node (e.g., <ref> [10, 11, 9] </ref>). Using sample path arguments, we show that the cell delay at each switch increases as the token buffer capacity increases and/or the token generation rate increases when no losses occur. <p> The reader should note that the service times within the tandem network are not affected by changes in the parameters of the throttle. This might be reasonable in a network in which 5 bandwidth is partitioned between different sessions as exemplified by hierarchical round robin [11], stop-and-go <ref> [10] </ref>, weighted fair queueing [9]. A similar approach has been taken in [17, 8]. 3 Basic Sample Path Characteristics We now present several preliminary comparison relations which will be used to prove our main results.
Reference: [11] <author> C.R. Kalmanek, H. Kanakia, and S. Keshav, </author> <title> "Rate controlled servers for very high-speed networks", </title> <booktitle> Proc. </booktitle> <address> Globecom'90, </address> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: Some of our results are based on the assumption that service times are deterministic whereas others are not. Such a model can be used to represent a system that partitions bandwidth between sources at each switching node (e.g., <ref> [10, 11, 9] </ref>). Using sample path arguments, we show that the cell delay at each switch increases as the token buffer capacity increases and/or the token generation rate increases when no losses occur. <p> The reader should note that the service times within the tandem network are not affected by changes in the parameters of the throttle. This might be reasonable in a network in which 5 bandwidth is partitioned between different sessions as exemplified by hierarchical round robin <ref> [11] </ref>, stop-and-go [10], weighted fair queueing [9]. A similar approach has been taken in [17, 8]. 3 Basic Sample Path Characteristics We now present several preliminary comparison relations which will be used to prove our main results.
Reference: [12] <author> L. Kuang, </author> <title> "On the variance reduction property of buffered leaky bucket", </title> <type> SRC TR 91-90, </type> <institution> University of Maryland, USA, </institution> <year> 1991. </year>
Reference-contexts: We also establish comparisons between the token bank and leaky bucket. Several papers have also studied the burst reduction properties of rate-control throttles. Results on the effects of different parameters on the departure process from the throttle can be found in <ref> [12, 13] </ref> for the case of the token bank, and [16] for both throttles. Anantharam and Konstantopoulos [1] studied the effect of varying the token buffer capacity on the buffer occupancy of the first queue on the path in the network.
Reference: [13] <author> L. Kuang, </author> <title> "Monotonicity properties of the leaky bucket", </title> <type> SRC TR 92-27, </type> <institution> University of Maryland, USA, </institution> <year> 1992. </year>
Reference-contexts: We also establish comparisons between the token bank and leaky bucket. Several papers have also studied the burst reduction properties of rate-control throttles. Results on the effects of different parameters on the departure process from the throttle can be found in <ref> [12, 13] </ref> for the case of the token bank, and [16] for both throttles. Anantharam and Konstantopoulos [1] studied the effect of varying the token buffer capacity on the buffer occupancy of the first queue on the path in the network.
Reference: [14] <author> Z. Liu, D. Towsley, </author> <title> "Optimality of the round robin routing policy". </title> <type> COINS Technical Report, TR 92-55, </type> <year> 1992. </year> <note> To appear Journal of Applied Probability. </note>
Reference-contexts: Two random variables X and Y are comparable by st , say X st Y , if for all x 2 IR, P [X &gt; x] P [Y &gt; x]. The proofs of Lemmas 7.1 and 5.1 can be carried out using coupling arguments (see e.g. <ref> [14] </ref>). 17 6 Summary In this paper we studied the effect that a rate-control throttle has on delays incurred by cells belonging to the session being controlled.
Reference: [15] <author> Z. Liu, D. Towsley, </author> <title> "Burst reduction properties of rate-based flow control schemes: downstream queue behavior", </title> <type> CMPSCI TR 92-82, </type> <institution> University of Massachusetts, USA, </institution> <year> 1992. </year> <note> INRIA Research Report No. 2117, </note> <year> 1993. </year>
Reference-contexts: The result for two token banks, (3.1), was established in [3]. Similar arguments can be used to establish this result for two leaky buckets (see <ref> [15] </ref> for details). We next characterize the departure process of cells from the throttle. Theorem 3.2 Let C be a rate-control throttle with token generation period length T , token buffer size B T 1 and the arrival sequence of accepted cells b A. <p> We will prove inequality (3.10) by induction on n. The proofs of the remaining inequalities are similar. They are omitted here but can be found in <ref> [15] </ref>. Clearly, (3.10) is true for 1 n B T . Assume it holds for some n B T . <p> In all these states, we can show that L t L 0 t , so that the assertion of the lemma is true. The detailed proof is provided in <ref> [15] </ref>. Proof of Lemma 5.1. Assume first that k 0 = 1. In addition to the notation previously defined for Q (j) , we introduce U (j) t to be the remaining service time of the customer in service (if any) at time t 0. <p> We include the argument for the case n k+1 &gt; n k + 1. The argument for the case n k+1 = n k + 1 is similar though more straightforward and is found in <ref> [15] </ref>.
Reference: [16] <author> Z. Liu, D. Towsley, </author> <title> "Burst reduction properties of rate-based flow control schemes: departure process", </title> <journal> Annals of Operations Research, Special Issue on Methodologies for Performance Analysis of High Speed Networks, </journal> <volume> 49, </volume> <pages> pp. 51-78, </pages> <year> 1994. </year>
Reference-contexts: Several papers have also studied the burst reduction properties of rate-control throttles. Results on the effects of different parameters on the departure process from the throttle can be found in [12, 13] for the case of the token bank, and <ref> [16] </ref> for both throttles. Anantharam and Konstantopoulos [1] studied the effect of varying the token buffer capacity on the buffer occupancy of the first queue on the path in the network. <p> In addition, similar results can be obtained for stationary cell delays and cell losses under appropriate assumptions on the cell arrival process. Examples of the types of assumptions required for the latter extension can be found in [1] and <ref> [16] </ref>. 7 Appendix: Proof of Lemma 5.1 In order to prove Lemma 5.1, we need the following lemma. Lemma 7.1 Consider two single-server queues G=D=1=c with the same arrival sequence, the same deterministic service time, and the same finite capacity c of the waiting buffer (the server has no buffer).
Reference: [17] <author> S. Low, P. Varaiya, </author> <title> "Burstiness bounds for some burst reducing servers", </title> <booktitle> Proc. INFO-COM'93, </booktitle> <pages> 2-8, </pages> <year> 1993. </year>
Reference-contexts: They showed that the stationary buffer occupancy at this queue with deterministic service time is a stochastically increasing function of the token buffer size for the case of a token bank. Low and Varaiya <ref> [17] </ref>, using a fluid model, obtained several monotonicity properties in the case of a rate-based throttle feeding a tandem queueing network. However, using a fluid model does not allow them to distinguish between the token bank and leaky bucket; both reduce to the same model using their approach. <p> This might be reasonable in a network in which 5 bandwidth is partitioned between different sessions as exemplified by hierarchical round robin [11], stop-and-go [10], weighted fair queueing [9]. A similar approach has been taken in <ref> [17, 8] </ref>. 3 Basic Sample Path Characteristics We now present several preliminary comparison relations which will be used to prove our main results.
Reference: [18] <author> E.P. Rathgeb, </author> <title> "Modeling and performance comparison of policing mechanisms for ATM networks", </title> <journal> IEEE J. Sel. areas Comm., </journal> <volume> 9, 3, </volume> <pages> pp. 325-334, </pages> <year> 1991. </year>
Reference-contexts: One mechanism that has received considerable attention is the leaky bucket rate-based flow control throttle [20]. Numerous performance studies have evaluated the effectiveness of this mechanism through either simulation or analysis (see <ref> [19, 18, 2] </ref> for examples of such studies). The goal of this paper is to investigate qualitatively the burst reduction properties of two variations of this mechanism: the token bank and the leaky bucket.
Reference: [19] <author> M. Sidi, W. Liu, I. Cidon, I. Gopal, </author> <title> "Congestion control through input rate regulation", </title> <booktitle> Proc. </booktitle> <address> GLOBECOM'89, </address> <year> 1989. </year>
Reference-contexts: One mechanism that has received considerable attention is the leaky bucket rate-based flow control throttle [20]. Numerous performance studies have evaluated the effectiveness of this mechanism through either simulation or analysis (see <ref> [19, 18, 2] </ref> for examples of such studies). The goal of this paper is to investigate qualitatively the burst reduction properties of two variations of this mechanism: the token bank and the leaky bucket.
Reference: [20] <author> J. Turner, </author> <title> "New Directions in communications (or which way to the information age)", </title> <journal> 24, </journal> <volume> 8 -15, </volume> <year> 1986. </year>
Reference-contexts: 1 Introduction Rate-based flow control has been proposed as a mechanism for reducing the burstiness of traffic sources in high-speed networks (e.g., ATM). One mechanism that has received considerable attention is the leaky bucket rate-based flow control throttle <ref> [20] </ref>. Numerous performance studies have evaluated the effectiveness of this mechanism through either simulation or analysis (see [19, 18, 2] for examples of such studies).
Reference: [21] <author> W. Whitt, </author> <title> "Comparing counting processes and queues", </title> <journal> Adv. Appl. Prob., </journal> <volume> 13, </volume> <pages> pp. 207 - 220, </pages> <year> 1981. </year>
Reference-contexts: Although there are a number of results comparing the behavior of single server queues under different arrival processes (e.g., <ref> [21] </ref>), none of them apply to the two queues described above. Typical results are based on simpler relationships among the arrival processes. <p> Typical results are based on simpler relationships among the arrival processes. For example, the behaviors of two infinite capacity queueing systems that differ only in that the arrival process of one is a subsequence of the arrival process are compared in <ref> [21] </ref>. The assumptions behind this and other comparisons are too strong for our needs. Fortunately, Q (1) and Q (2) have sufficient structure to allow us to make the following comparison.
References-found: 21

