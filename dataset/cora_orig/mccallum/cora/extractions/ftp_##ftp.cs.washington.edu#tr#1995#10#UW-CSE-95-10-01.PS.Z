URL: ftp://ftp.cs.washington.edu/tr/1995/10/UW-CSE-95-10-01.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-title.html
Root-URL: 
Title: Using Runtime Measured Workload Characteristics in Parallel Processor Scheduling  
Author: Thu D. Nguyen, Raj Vaswani, and John Zahorjan 
Address: Box 352350  Seattle, WA 98195-2350 USA  
Affiliation: Department of Computer Science and Engineering,  University of Washington  
Pubnum: Technical Report UW-CSE-95-10-01  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. Berry, D. Chen, P. Koss, D. Kuck, S. Lo, Y. Pang, L. Pointer, R. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox, P. Messina, D. Walker, C. Hsiung, J. Scharzmeier, K. Lue, S. Orszag, F. Seidl, O. Johnson, R. Goodrum, and J. Martin. </author> <title> The PERFECT Club Benchmarks: Effective Performance Evaluation of Supercomputers. </title> <journal> The International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <year> 1989. </year>
Reference-contexts: Evaluation of the extent to which runtime measurements can be used to help the scheduler is done through the execution of benchmark programs on prototype implementations running on a KSR-2. The benchmarks we use are taken from the SPLASH [23] and Perfect <ref> [1] </ref> benchmark suites, the best benchmarks available to us for this work.
Reference: [2] <author> T. B. Brecht and K. Guha. </author> <title> Using Parallel Program Characteristics in Dynamic Processor Allocation Policies. </title> <type> Technical report, </type> <institution> Department of Computer Science, York University, </institution> <note> in preparation. </note>
Reference-contexts: There has been considerable work on this topic in the past. A great deal of this work has been involved with the interesting question of how best to schedule jobs 1 when given perfect information about speedup, a fundamental attribute of parallel workloads (e.g., <ref> [21, 8, 3, 2] </ref>, among many others).
Reference: [3] <author> S.-H. Chiang, R. Mansharamani, and M. Vernon. </author> <title> Use of Application Characteristics and Limited Preemption for Run-to-Completion Parallel Processor Scheduling Policies. </title> <booktitle> In Proceedings of ACM SIGMETRICS Conference, </booktitle> <pages> pages 33-44, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: There has been considerable work on this topic in the past. A great deal of this work has been involved with the interesting question of how best to schedule jobs 1 when given perfect information about speedup, a fundamental attribute of parallel workloads (e.g., <ref> [21, 8, 3, 2] </ref>, among many others). <p> Finding and determining how to exploit such long-term characterizations for production parallel workloads is an important topic, and has been an aspect of much work in this area (e.g., <ref> [8, 20, 22, 3] </ref>). <p> Many previous works have hypothesized the existence of such correlations, and have considered them when evaluating their policies (e.g., [11] and <ref> [3] </ref>, among other).
Reference: [4] <author> E. C. Cooper and R. P. Draves. </author> <title> C Threads. </title> <type> Technical Report CMU-CS-88-154, </type> <institution> Department of Computer Science, Carnegie-Mellon University, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: Thus, measuring system overhead and communication is simply a matter of reading these three registers periodically. Measuring idleness is only slightly more involved: we instrument the Cthreads synchronization code <ref> [4] </ref> to keep elapsed idle time using the wallclock hardware counter.
Reference: [5] <author> L. Dowdy. </author> <title> On the Partitioning of Multiprocessor Systems. </title> <type> Technical report, </type> <institution> Vanderbilt University, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: Rather, we have the presumably accurate value measured for the most recent allocation, as well as potentially out of date information obtained for previous allocations. To overcome this problem, we employ a simple analytic speedup function, taken from <ref> [5] </ref>, as a substitute for the jobs' actual speedups. We parameterize the speedup function for job j 12 so that it intersects the speedup estimate obtained in the most recent measurement interval. Our allocation scheme then walks along these speedup curves.
Reference: [6] <author> D. L. Eager and J. Zahorjan. Chores: </author> <title> Enhanced Run-Time Support for Shared-Memory Parallel Computing. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(1) </volume> <pages> 1-32, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: It is clearly possible to do much more dynamic scheduling (see, for example, <ref> [19, 6, 13] </ref>); we did not do so because of the very large incremental implementation cost relative to our more restrictive change, and because we anticipated that the additional benefits of this added flexibility at the application level would be quite modest. 3.2 Using Runtime Measurements: ST-EQUI The specific policy we
Reference: [7] <author> D. G. Feitelson and B. Nitzberg. </author> <title> Job Characteristics of a Production Parallel Scientific Workload on the NASA Ames iPSC/860. In Job Scheduling Strategies for Parallel Processing, </title> <booktitle> IPPS '95 Workshop, </booktitle> <pages> pages 337-360. </pages> <publisher> Springer, </publisher> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: Both kinds of computing already have significant roles on existing large scale parallel platforms <ref> [7] </ref>. For the interactive environment, we use measured efficiencies to guide adjustment of the number of processors given to each running job, attempting to maximize its speedup. For batch environments, our scheduler allocates processors in an attempt to maximize current system efficiency. <p> Many previous works have hypothesized the existence of such correlations, and have considered them when evaluating their policies (e.g., [11] and [3], among other). Feitelson and Nitzberg <ref> [7] </ref> present evidence that there is such a correlation for execution time consumed and number of nodes used, at least for one production installation. (Because they measured a message passing machine, in which processors and memory are allocated together, it is difficult to determine from their data whether a similar correlation <p> This decision is supported by the measurements in <ref> [7] </ref>, which indicate that a multiprogramming levels of 2, 3, and 4 are the three most common during daytime hours in their production environment. <p> However, we used a single multiprogramming level of 3 in all experiments (a reduction from the maximum of 4 considered for the interactive environment) to reflect the likely larger size of jobs submitted for batch execution. (This change is supported by the measurements in <ref> [7] </ref>.) Additionally, we present here results only for those workloads that include a Barnes job, the representative from the class of jobs having good speedup.
Reference: [8] <author> D. Ghosal, G. Serazzi, and S. Tripathi. </author> <title> The Processor Working Set and Its Use in Scheduling Multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(3) </volume> <pages> 408-423, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: There has been considerable work on this topic in the past. A great deal of this work has been involved with the interesting question of how best to schedule jobs 1 when given perfect information about speedup, a fundamental attribute of parallel workloads (e.g., <ref> [21, 8, 3, 2] </ref>, among many others). <p> Finding and determining how to exploit such long-term characterizations for production parallel workloads is an important topic, and has been an aspect of much work in this area (e.g., <ref> [8, 20, 22, 3] </ref>).
Reference: [9] <author> T. E. Jeremiassen and S. J. Eggers. </author> <title> Reducing False Sharing on Shared Memory Multiprocessors Through Compile-Time Analysis. </title> <booktitle> In Proceedings of the 7th SIGPLAN Symposium on Principles and Practice of Parallel Processing, </booktitle> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: For this study, we have inserted these calls into each application in our application suite by hand. In many instances, however, we believe that it would be possible for compilers to automatically detect iterative behavior and insert the calls to the runtime system appropriately. For example, Jeremiassen <ref> [9] </ref> has shown that it is possible to automatically detect phase behavior for many hand coded applications. 2.4 Use of Job Length Predictions in Scheduling Application characteristics other than speedup and efficiency certainly are also important in scheduling policy design.
Reference: [10] <institution> Kendall Square Research Inc., </institution> <address> 170 Tracer Lane, Waltham, MA 02154. </address> <booktitle> KSR/Series Principles of Operation, </booktitle> <year> 1994. </year>
Reference-contexts: Processor reallocations take place at job arrival and departure times. EQUI is representative of the space sharing approach to processor allocation that has been found to perform well for multiprogrammed shared-memory multiprocessors [25, 14], and exemplifies schemes actively used in such environments <ref> [10] </ref>. We have used the EQUI policy as our baseline despite two common objections to it (and other dynamic policies). The first is that the cost of periodic processor reallocations is too high. We do not find this to be the case in practice.
Reference: [11] <author> S. Majumdar, D. Eager, and R. Bunt. </author> <title> Scheduling in Multiprogrammed Parallel Systems. </title> <booktitle> In Proceedings of ACM SIGMETRICS Conference, </booktitle> <pages> pages 104-113, </pages> <month> May </month> <year> 1988. </year> <month> 16 </month>
Reference-contexts: Many previous works have hypothesized the existence of such correlations, and have considered them when evaluating their policies (e.g., <ref> [11] </ref> and [3], among other).
Reference: [12] <author> S. Majumdar, D. L. Eager, and R. B. Bunt. </author> <title> Scheduling in Multiprogrammed Parallel Systems. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference, </booktitle> <pages> pages 104-113, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Section 5 concludes our work. 2 Measuring Job Speedup and Efficiency at Runtime 2.1 What We Measure One approach to using measured job characteristics in formulating scheduling policies is to exploit general, long-term characteristizations of the workloads (e.g., <ref> [12] </ref>). An example of this from sequential systems is the use of feedback scheduling: the success of this approach is implied by the empirical validity of the assumption that a job that has run for a long time is likely to continue running for a proportionally long time.
Reference: [13] <author> E. Markatos and T. LeBlanc. </author> <title> Using Processor Affinity in Loop Scheduling on Shared-Memory Multiprocessors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(4) </volume> <pages> 379-400, </pages> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: It is clearly possible to do much more dynamic scheduling (see, for example, <ref> [19, 6, 13] </ref>); we did not do so because of the very large incremental implementation cost relative to our more restrictive change, and because we anticipated that the additional benefits of this added flexibility at the application level would be quite modest. 3.2 Using Runtime Measurements: ST-EQUI The specific policy we
Reference: [14] <author> C. McCann, R. Vaswani, and J. Zahorjan. </author> <title> A Dynamic Processor Allocation Strategy for Multipro-grammed, Shared Memory Multiprocessors. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 11(2) </volume> <pages> 146-178, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Under EQUI, each currently executing job is allocated an equal number of processors. Processor reallocations take place at job arrival and departure times. EQUI is representative of the space sharing approach to processor allocation that has been found to perform well for multiprogrammed shared-memory multiprocessors <ref> [25, 14] </ref>, and exemplifies schemes actively used in such environments [10]. We have used the EQUI policy as our baseline despite two common objections to it (and other dynamic policies). The first is that the cost of periodic processor reallocations is too high.
Reference: [15] <author> G. P. McCormick. </author> <title> Nonlinear Programming. </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1983. </year>
Reference-contexts: Comprehensive details can be found in [16], which examines the use of this technique in a static (essentially uniprogramming) environment. Self-tuning is based on a simple optimization technique, the method of golden sections <ref> [15] </ref>, which searches for the maximum of a unimodal function over a finite interval by iteratively computing function values and narrowing the interval in which the maximum must occur. In our case, the function to be maximized is job speedup.
Reference: [16] <author> T. D. Nguyen, R. Vaswani, and J. Zahorjan. </author> <title> Maximizing Speedup Through Self-Tuning of Processor Allocation. </title> <type> Technical Report UW-CSE-95-09-02, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: To understand better the source of that overhead, we next present the self-tuning procedure in somewhat more detail. 3.2.1 Self-Tuning We present here an overview of the self-tuning procedure we employ. Comprehensive details can be found in <ref> [16] </ref>, which examines the use of this technique in a static (essentially uniprogramming) environment. <p> The experiments in <ref> [16] </ref> show that this procedure works remarkably well, nearly always converging to a near optimal value. The second problem we face is one of efficiency. <p> This overhead is, as described in Section 3.2.1, the cost of running for some time at processor allocations that yield poor performance. (See also <ref> [16] </ref>.) Despite this, with few exceptions, ST-EQUI performs nearly as well as does AP-EQUI. We also observe that for each of the three jobs types, there are some workload mixes in which the jobs perform better than under AP-EQUI.
Reference: [17] <author> T. D. Nguyen, R. Vaswani, and J. Zahorjan. </author> <title> On Scheduling Implications of Application Characteristics. </title> <type> Technical report, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <note> in preparation. </note>
Reference-contexts: We next describe the workload used to exercise these policies. 3.3.1 Workload As explained in Section 1, we are interested in a diverse workload composed of both hand-coded (SPLASH) and compiler-parallelized (Perfect) applications. Our previous detailed study of these applications <ref> [17] </ref> made clear that these programs could be divided into three broad classes: * Good speedup. Most of the hand-coded applications fall into this class, which is characterized by fairly good speedup that rises monotonically as the job receives processors. <p> Most of these applications exhibit slowdown beyond a certain number of allocated processors. * Erratic speedup. This class consists of applications whose speedup is irregular, e.g., it varies over time, or its curve exhibits multiple local maxima. Such behavior can be observed in both hand-coded and compiler-parallelized applications <ref> [17] </ref>. Because it is clearly infeasible to run experiments with all possible combinations from our benchmark suites, we instead use our taxonomy to reduce the number of jobs that must be considered.
Reference: [18] <author> E. W. Parsons and K. C. Sevcik. </author> <title> Multiprocessor Scheduling for High-Variability Service Time Distributions. In Job Scheduling Strategies for Parallel Processing, </title> <booktitle> IPPS '95 Workshop, </booktitle> <pages> pages 127-145. </pages> <publisher> Springer, </publisher> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: Rather, we assume that some other mechanism, such as the feedback scheduling employed in sequential systems, is used for this purpose. (Parsons and Sevcik <ref> [18] </ref> present the design and evaluation of two such schemes, for example.) We consider the workload mixes we schedule to be the subset of a larger job mix chosen for current execution by such a mechanism. 5 3 Interactive Environments: Improving Response Time In this section, we describe and evaluate a
Reference: [19] <author> C. Polychronopoulos and D. Kuck. </author> <title> Guided Self-Scheduling: A Practical Scheduling Scheme for Parallel Supercomputers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(12):1425-1439, </volume> <month> Dec. </month> <year> 1987. </year>
Reference-contexts: It is clearly possible to do much more dynamic scheduling (see, for example, <ref> [19, 6, 13] </ref>); we did not do so because of the very large incremental implementation cost relative to our more restrictive change, and because we anticipated that the additional benefits of this added flexibility at the application level would be quite modest. 3.2 Using Runtime Measurements: ST-EQUI The specific policy we
Reference: [20] <author> S. Setia, M. Squillante, , and S. Tripathi. </author> <title> Processor Scheduling on Multiprogrammed, </title> <booktitle> Distributed Memory Parallel Systems. In Proceedings of ACM SIGMETRICS Conference, </booktitle> <pages> pages 158-170, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Finding and determining how to exploit such long-term characterizations for production parallel workloads is an important topic, and has been an aspect of much work in this area (e.g., <ref> [8, 20, 22, 3] </ref>).
Reference: [21] <author> K. Sevcik. </author> <title> Characterizations of Parallelism in Applications and Their Use in Scheduling. </title> <booktitle> In Proceedings of ACM SIGMETRICS Conference, </booktitle> <pages> pages 171-180, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: There has been considerable work on this topic in the past. A great deal of this work has been involved with the interesting question of how best to schedule jobs 1 when given perfect information about speedup, a fundamental attribute of parallel workloads (e.g., <ref> [21, 8, 3, 2] </ref>, among many others).
Reference: [22] <author> K. C. Sevcik. </author> <title> Application Scheduling and Processor Allocation in Multiprogrammed Parallel Processing Systems. Performance Evaluation, </title> <type> 19(2-3), </type> <year> 1994. </year>
Reference-contexts: Finding and determining how to exploit such long-term characterizations for production parallel workloads is an important topic, and has been an aspect of much work in this area (e.g., <ref> [8, 20, 22, 3] </ref>).
Reference: [23] <author> J. P. Singh, W.-D. Weber, and A. Gupta. </author> <title> SPLASH: Stanford Parallel Applications for Shared-Memory. </title> <journal> Computer Architecture News, </journal> <volume> 20(1) </volume> <pages> 5-44, </pages> <year> 1992. </year>
Reference-contexts: As an example, consider the MP3D application from the SPLASH <ref> [23] </ref> benchmark suite when run on the KSR-2 multiprocessor. The KSR-2 has an interconnection network that is a hierarchy of rings. The basic communication time between two rings is roughly six times that for communication within any one. <p> Evaluation of the extent to which runtime measurements can be used to help the scheduler is done through the execution of benchmark programs on prototype implementations running on a KSR-2. The benchmarks we use are taken from the SPLASH <ref> [23] </ref> and Perfect [1] benchmark suites, the best benchmarks available to us for this work.
Reference: [24] <author> P. G. Sobalvarro and W. E. Weihl. </author> <title> Demand-Based Coscheduling of Parallel Jobs on Multiprogrammed Multiprocessors. In Job Scheduling Strategies for Parallel Processing, </title> <booktitle> IPPS '95 Workshop, </booktitle> <pages> pages 106-126. </pages> <publisher> Springer, </publisher> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: In this paper we concentrate on a third approach, using the specific, recently measured characteristics of the currently running jobs to optimize performance for the specific workload in execution. (Sobalvarro and Weihl <ref> [24] </ref> take a similar approach in an attempt to relax the constraints of co-scheduling.) As we will show, this approach can offer substantial benefits.
Reference: [25] <author> A. Tucker and A. Gupta. </author> <title> Process Control and Scheduling Issues for Multiprogrammed Shared-Memory Multiprocessors. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating System Principles, </booktitle> <pages> pages 159-166, </pages> <month> December </month> <year> 1989. </year> <month> 17 </month>
Reference-contexts: This new policy is called ST-EQUI. Before presenting it, we first describe the baseline dynamic equipartition policy from which ST-EQUI is derived. 3.1 The Equipartition Policy: EQUI The basic scheduling policy on which we build is dynamic equipartition <ref> [25] </ref>, which we call EQUI. Under EQUI, each currently executing job is allocated an equal number of processors. Processor reallocations take place at job arrival and departure times. <p> Under EQUI, each currently executing job is allocated an equal number of processors. Processor reallocations take place at job arrival and departure times. EQUI is representative of the space sharing approach to processor allocation that has been found to perform well for multiprogrammed shared-memory multiprocessors <ref> [25, 14] </ref>, and exemplifies schemes actively used in such environments [10]. We have used the EQUI policy as our baseline despite two common objections to it (and other dynamic policies). The first is that the cost of periodic processor reallocations is too high.
References-found: 25

