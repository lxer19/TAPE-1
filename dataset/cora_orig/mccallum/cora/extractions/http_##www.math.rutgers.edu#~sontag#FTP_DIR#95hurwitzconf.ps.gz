URL: http://www.math.rutgers.edu/~sontag/FTP_DIR/95hurwitzconf.ps.gz
Refering-URL: http://www.math.rutgers.edu/~sontag/papers.html
Root-URL: 
Email: EMAIL: SONTAG@CONTROL.RUTGERS.EDU  EMAIL: SUSSMANN@HAMILTON.RUTGERS.EDU  
Title: GENERAL CLASSES OF CONTROL-LYAPUNOV FUNCTIONS  
Author: EDUARDO D. SONTAG H ECTOR J. SUSSMANN 
Address: NEW BRUNSWICK, NJ 08903  NEW BRUNSWICK, NJ 08903  
Affiliation: DEPARTMENT OF MATHEMATICS RUTGERS UNIVERSITY  DEPT. OF MATHEMATICS RUTGERS UNIVERSITY  
Abstract: The main result of this paper establishes the equivalence between null asymptotic controllability of nonlinear finite-dimensional control systems and the existence of continuous control-Lyapunov functions (clf's) defined by means of generalized derivatives. In this manner, one obtains a complete characterization of asymptotic controllability, applying in principle to a far wider class of systems than Artstein's Theorem (which relates closed-loop feedback stabilization to the existence of smooth clf's). The proof relies on viability theory and optimal control techniques. 1. Introduction. In this paper, we study systems of the general form 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Artstein, Z., </author> <title> "Stabilization with relaxed controls," Nonlinear Analysis, Theory, </title> <booktitle> Methods & Applications 7(1983): </booktitle> <pages> 1163-1173. </pages>
Reference: [2] <author> Aubin, J.-P., and A. Cellina, </author> <title> Differential Inclusions: Set-Valued Maps and Viability Theory, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1984. </year>
Reference-contexts: The proof follows easily by combining the main result in [12], which gave a necessary condition expressed in terms of Dini derivatives of trajectories, with results from <ref> [2] </ref>. Remark 1.1. Our result shows that asymptotic controllability implies the existence of a "Lyapunov function" in the strict sense that derivatives are negative for nonzero states. <p> Directional Derivatives. We now introduce an object widely studied in Set-Valued Analysis (cf., for instance, <ref> [2] </ref>, Def. 1 and Prop. 1 of Section 6.1, where it is called the "upper contingent derivative.") Definition 4.1. <p> such that F (~) &lt; +1, and a v 2 R n , the directional subderivative of V in the direction of v at ~ is v V (~) := lim inf w ! v t (The notations D + V (~)(v) and D " V (~)(v) are used in <ref> [2, 6] </ref> and [3] respectively, with the same meaning as our D v V (~).) For each fixed ~, the map v 7! D v V (~) is lower semicontinuous as an extended-real valued function (cf. [2], page 286); thus fvjD v V (~) ffg is a closed set for any <p> (The notations D + V (~)(v) and D " V (~)(v) are used in [2, 6] and [3] respectively, with the same meaning as our D v V (~).) For each fixed ~, the map v 7! D v V (~) is lower semicontinuous as an extended-real valued function (cf. <ref> [2] </ref>, page 286); thus fvjD v V (~) ffg is a closed set for any ff. Observe that if V is Lipschitz continuous then this definition coincides with that of the classical Dini derivative, that is, lim inf t!0+ [V (~ + tv) V (~)]=t. <p> If U is a compact topological space and f : X fi U ! Y is continuous, then the set valued map F (x) := F (x; U ) = ff (x; u); u 2 U g is USC (see for instance <ref> [2] </ref>, Prop. 1 in Section 1.2). We will henceforth use the abbreviations DI and USCMCC for "differential inclusion" and "upper semicontinuous multifunction with compact convex values," respectively. Let X be a subset of Y = R n . <p> The second ingredient needed to prove Theorem 4.1 is from the literature on differential inclusions and viability theory. The relevant results are as follows. (We give them in a slightly stronger form than needed, but still not in full generality: in <ref> [2] </ref>, the function "W " is allowed to depend convexly on derivatives _x (t), and in some implications less than continuity of V or W is required.) Theorem 1 in Section 6.3 of [2] shows that 2 implies 1 (with T = 1 if X is closed and F (X) is <p> (We give them in a slightly stronger form than needed, but still not in full generality: in <ref> [2] </ref>, the function "W " is allowed to depend convexly on derivatives _x (t), and in some implications less than continuity of V or W is required.) Theorem 1 in Section 6.3 of [2] shows that 2 implies 1 (with T = 1 if X is closed and F (X) is bounded), and Proposition 2 in Section 6.3 of [2] says that 1)2. (Another good reference is [6]; see in particular Theorem 14.1 there.) 7 Fact 6.1. <p> convexly on derivatives _x (t), and in some implications less than continuity of V or W is required.) Theorem 1 in Section 6.3 of <ref> [2] </ref> shows that 2 implies 1 (with T = 1 if X is closed and F (X) is bounded), and Proposition 2 in Section 6.3 of [2] says that 1)2. (Another good reference is [6]; see in particular Theorem 14.1 there.) 7 Fact 6.1. Let F be an USCMCC from X into subsets of R n , where X is a locally compact subset of R n . <p> Then D f (x;y) V (x; y) &lt; 0 if (x; y) =2 S. If r &gt; 0, then Fact 6.1 |with W 0| easily implies that the function <ref> [0; 2] </ref> 3 t 7! h r (t) = V (r cos t; r sin t) is nonincreasing on (0; 2). Since V is continuous, and h r (0) = h r (2), we conclude that h r is constant. So V is in fact a radial function, i.e.
Reference: [3] <author> Aubin, J.-P., </author> <title> Viability Theory, </title> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: (~) &lt; +1, and a v 2 R n , the directional subderivative of V in the direction of v at ~ is v V (~) := lim inf w ! v t (The notations D + V (~)(v) and D " V (~)(v) are used in [2, 6] and <ref> [3] </ref> respectively, with the same meaning as our D v V (~).) For each fixed ~, the map v 7! D v V (~) is lower semicontinuous as an extended-real valued function (cf. [2], page 286); thus fvjD v V (~) ffg is a closed set for any ff.
Reference: [4] <author> Bacciotti, A., </author> <title> Local Stabilizability of Nonlinear Control Systems, </title> <publisher> World Scientific, </publisher> <address> London, </address> <year> 1991. </year>
Reference-contexts: This is the content of Artstein's Theorem ([1]). More explicitely, and taking for simplicity the case m=1, one has the following "universal" formula for computing feedback laws (cf. [13] and also the recent textbooks <ref> [4, 9, 7] </ref> and the survey [5]): denote a (x) := rV (x):f 0 (x) and b (x) := rV (x):f 1 (x), for the given clf.
Reference: [5] <author> Coron, J.M., L. Praly, and A. Teel, </author> <title> "Feedback stabilization of nonlinear systems: sufficient conditions and Lyapunov and input-output techniques," in Trends in Control: A European Perspective (A. </title> <editor> Isidori, Ed.), </editor> <publisher> Springer, London, </publisher> <pages> 1995 (pp. 293-348). </pages>
Reference-contexts: This is the content of Artstein's Theorem ([1]). More explicitely, and taking for simplicity the case m=1, one has the following "universal" formula for computing feedback laws (cf. [13] and also the recent textbooks [4, 9, 7] and the survey <ref> [5] </ref>): denote a (x) := rV (x):f 0 (x) and b (x) := rV (x):f 1 (x), for the given clf. <p> But, for most systems, even affine in control and with m = 1, continuous feedback may fail to exist, even for very simple controllable systems (see e.g. [11], Section 4.8, and <ref> [5] </ref>). This means that unless one weakens the definition of clf, the converse implication "asymptotic controllability implies existence of clf" will be false. 2 The main result of this paper provides such a reformulation. The critical step is to relax the differentiability assumption on V to merely continuity .
Reference: [6] <author> Deimling, K., </author> <title> Multivalued Differential Equations, </title> <publisher> de Gruyter, </publisher> <address> Berlin, </address> <year> 1992. </year>
Reference-contexts: such that F (~) &lt; +1, and a v 2 R n , the directional subderivative of V in the direction of v at ~ is v V (~) := lim inf w ! v t (The notations D + V (~)(v) and D " V (~)(v) are used in <ref> [2, 6] </ref> and [3] respectively, with the same meaning as our D v V (~).) For each fixed ~, the map v 7! D v V (~) is lower semicontinuous as an extended-real valued function (cf. [2], page 286); thus fvjD v V (~) ffg is a closed set for any <p> implications less than continuity of V or W is required.) Theorem 1 in Section 6.3 of [2] shows that 2 implies 1 (with T = 1 if X is closed and F (X) is bounded), and Proposition 2 in Section 6.3 of [2] says that 1)2. (Another good reference is <ref> [6] </ref>; see in particular Theorem 14.1 there.) 7 Fact 6.1. Let F be an USCMCC from X into subsets of R n , where X is a locally compact subset of R n . Assume that V and W are two continuous functions X ! R 0 . <p> We now show that the converse implication can fail, that is, we provide an example of an AC system for which there is no clf. (It is proved in <ref> [6] </ref> that an AC DI arising from an USCMCC always has a lower semicontinuous "clf." Our definition requires the clf to be continuous.) We let f : R 2 ! R 2 be given by f (x; y) = (y; x). Let S = R 0 fi f0g.
Reference: [7] <author> Krstic, M., I. Kanellakopoulos, and P. Kokotovic, </author> <title> Nonlinear and adaptive control design, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: The idea underlies feedback control design (see the references in [12], and more recently the textbook <ref> [7] </ref>), the optimal control approach of Bellman, "artificial intelligence" techniques based on position evaluations in games and "critics" in learning programs, and can even be found in "neural-network" control design (see e.g. [8]). <p> This is the content of Artstein's Theorem ([1]). More explicitely, and taking for simplicity the case m=1, one has the following "universal" formula for computing feedback laws (cf. [13] and also the recent textbooks <ref> [4, 9, 7] </ref> and the survey [5]): denote a (x) := rV (x):f 0 (x) and b (x) := rV (x):f 1 (x), for the given clf.
Reference: [8] <author> Long, Y., and M. M. Bayoumi, </author> <title> "Feedback stabilization: Control Lyapunov functions modeled by neural networks," </title> <booktitle> in Proc. IEEE Conf. Decision and Control, </booktitle> <address> San Antonio, Dec. 1993, </address> <publisher> IEEE Publications, </publisher> <year> 1993, </year> <pages> pp. 2812-2814. </pages>
Reference-contexts: The idea underlies feedback control design (see the references in [12], and more recently the textbook [7]), the optimal control approach of Bellman, "artificial intelligence" techniques based on position evaluations in games and "critics" in learning programs, and can even be found in "neural-network" control design (see e.g. <ref> [8] </ref>).
Reference: [9] <author> Isidori, A., </author> <title> Nonlinear Control Systems: An Introduction, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, third ed., </address> <year> 1995. </year>
Reference-contexts: This is the content of Artstein's Theorem ([1]). More explicitely, and taking for simplicity the case m=1, one has the following "universal" formula for computing feedback laws (cf. [13] and also the recent textbooks <ref> [4, 9, 7] </ref> and the survey [5]): denote a (x) := rV (x):f 0 (x) and b (x) := rV (x):f 1 (x), for the given clf.
Reference: [10] <author> Lafferriere, G. A., </author> <title> "Discontinuous stabilizing feedback using partially defined Lyapunov functions," </title> <booktitle> in Proc. IEEE Conf. Decision and Control, </booktitle> <address> Lake Buena Vista, Dec. 1994, </address> <publisher> IEEE Publications, </publisher> <year> 1994, </year> <pages> pp. 3487-3491. </pages>
Reference-contexts: This general result helps in interpreting some of the constructions for particular classes of systems which involve nondif-ferentiable clf's; see for instance <ref> [10] </ref>. The proof follows easily by combining the main result in [12], which gave a necessary condition expressed in terms of Dini derivatives of trajectories, with results from [2]. Remark 1.1.
Reference: [11] <author> Sontag, E.D., </author> <title> Mathematical Control Theory: Deterministic Finite Dimensional Systems, </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: () such that, solving the initial-value problem (1) with x (0) = ~, the resulting trajectory satisfies x (t) ! 0 as t ! +1 ; 1 Supported in part by US Air Force Grant F49620-95-1-0101 2 Supported in part by NSF Grant DMS92-02554 1 see for instance the textbook <ref> [11] </ref>. A function V which is part of a Lyapunov pair is generically called a control-Lyapunov function, henceforth abbreviated "clf." Thus, existence of a clf implies null asymptotic controllability. <p> But, for most systems, even affine in control and with m = 1, continuous feedback may fail to exist, even for very simple controllable systems (see e.g. <ref> [11] </ref>, Section 4.8, and [5]). This means that unless one weakens the definition of clf, the converse implication "asymptotic controllability implies existence of clf" will be false. 2 The main result of this paper provides such a reformulation.
Reference: [12] <author> Sontag, E.D., </author> <title> "A Lyapunov-like characterization of asymptotic controllability," </title> <journal> SIAM J. Control & Opt. </journal> <volume> 21(1983): </volume> <month> 462-471. </month> <title> (See also "A characterization of asymptotic controllability," in Dynamical Systems II (A. </title> <editor> Bednarek and L. Cesari, eds.), </editor> <publisher> Academic Press, </publisher> <address> NY, </address> <year> 1982, </year> <pages> pp. 645-648.) </pages>
Reference-contexts: The idea underlies feedback control design (see the references in <ref> [12] </ref>, and more recently the textbook [7]), the optimal control approach of Bellman, "artificial intelligence" techniques based on position evaluations in games and "critics" in learning programs, and can even be found in "neural-network" control design (see e.g. [8]). <p> This general result helps in interpreting some of the constructions for particular classes of systems which involve nondif-ferentiable clf's; see for instance [10]. The proof follows easily by combining the main result in <ref> [12] </ref>, which gave a necessary condition expressed in terms of Dini derivatives of trajectories, with results from [2]. Remark 1.1. Our result shows that asymptotic controllability implies the existence of a "Lyapunov function" in the strict sense that derivatives are negative for nonzero states. <p> 0 is the origin.) The map f : Xfi U ! R n is assumed to be locally Lipschitz with respect to (x; u) and to satisfy f (0; 0) = 0. (The Lipschitz property with respect to u can be weakened, but we will need to quote results from <ref> [12] </ref>, where this was made as a blanket assumption.) A control is a bounded measurable map u : I u ! U , where I u 2 I. <p> initial value problem that obtains from initial state ~ and relaxed control u, and we denote kuk = inff j u (t) 2 P (U ) for almost all t 2 I u g : The first ingredient in the proof is the following restatement of the main result in <ref> [12] </ref>. Fact 5.1. <p> If there are such V , W , and -, then for each ~ we may pick a ! so that (4) holds; this implies the inequality lim inf t!0+ t 1 [V (x (t))V (~)] W (~), which is the sufficient condition for AC given in <ref> [12] </ref>. <p> is taken over the set of all relaxed controls ! : [0; 1) ! P (U -(j~j) ); and k is a constant which arises from the function in the definition of AC. (Here we take W (x) = N (jxj), where N : R 0 ! R 0 from <ref> [12] </ref> is a strictly increasing, continuous function satisfying also N (0) = 0 and lim r!+1 N (r) = +1, i.e. a function of class K 1 . <p> Remark 7.1. The proof actually shows that in the AC case one has trajectories, corresponding to relaxed controls, which are monotone with respect to V and W , and are defined on the entire [0; +1). (Observe that the cost function used in <ref> [12] </ref> is not additive, because of the term "maxfk!k k; 0g", so the dynamic programming principle does not apply, and hence we cannot conclude that optimal trajectories are monotone.
Reference: [13] <author> Sontag, E.D., </author> <title> "A `universal' construction of Artstein's theorem on nonlinear stabilization," </title> <journal> Systems and Control Letters, </journal> <volume> 13(1989): </volume> <pages> 117-123. </pages>
Reference-contexts: This is the content of Artstein's Theorem ([1]). More explicitely, and taking for simplicity the case m=1, one has the following "universal" formula for computing feedback laws (cf. <ref> [13] </ref> and also the recent textbooks [4, 9, 7] and the survey [5]): denote a (x) := rV (x):f 0 (x) and b (x) := rV (x):f 1 (x), for the given clf.
Reference: [14] <author> Sontag, E.D., and H.J. Sussmann, </author> <title> "Non-smooth control-Lyapunov functions," </title> <booktitle> Proc. IEEE Conf. Decision and Control, </booktitle> <address> New Orleans, Dec. 1995, </address> <publisher> IEEE Publications, </publisher> <year> 1995. </year> <month> 10 </month>
Reference-contexts: In analogy with ordinary differential equations, one may ask when the existence of a "weak CLF," for which W is only required to be non-negative, suffices for the converse. It is indeed possible to provide control theory versions of the LaSalle Invariance Principle; see <ref> [14] </ref> for details. 2. Asymptotic Controllability and CLF's. <p> Throughout the paper, systems of the form (1) are assumed to be in S, so we will use indistinctly the two forms of the definition of AC. However in Section 8 below, and in more detail in <ref> [14] </ref>, we compare systems in S with differential inclusions |which belong to S fl but not necessarily to S| and there one uses Definition 3.1 as stated rather than Conditions 1 and 2. 4. Directional Derivatives.
References-found: 14

