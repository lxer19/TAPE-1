URL: http://voronoi.sbp.ri.cmu.edu/~choset/papers/mfi96.ps
Refering-URL: http://voronoi.sbp.ri.cmu.edu/~choset/papers.html
Root-URL: 
Title: Mobile Robot Navigation: Issues in Implementating the Generalized Voronoi Graph in the Plane  
Author: Howie Choset* and Ilhan Konukseven** and Joel Burdick*** 
Abstract: This paper describes the procedures that are required to implement, on a conventional mobile robot, a sensor based motion planning algorithm based on the generalized Voronoi graph (GVG). The GVG is a roadmap of a static environment, and we describe how to incrementally construct this roadmap using only range information in an unknown environment. The GVG may then be used to guide future excursions into the explored environment. Experimental results validate the utility of this work. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Borenstein and J. Koren. </author> <title> Real-time Onstacle Avoid ance for Fast Mobile Robots in Cluttered Environments. </title> <booktitle> In IEEE Conference of Robotics and Automation, </booktitle> <pages> pages 572-577, </pages> <address> Cincinnati, Ohio, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: Another type of heuristic approach involves discretiz-ing the planar world into pixels of some resolution. Typically, this is used when approximating errors in sonar sensing readings, where each pixel is a assigned a value indicating the likelihood that it overlaps an obstacle <ref> [1] </ref>. This method lends itself very nicely to implementation with real sensors, but discretizing the world may require a large amount of computer memory and may lead to an inaccurate representation of the world.
Reference: [2] <author> R.A. Brooks. </author> <title> A Robust Layered Control System for a Mobile Robot. </title> <journal> IEEE Journal on Robotics and Automation, </journal> <volume> RA-2, </volume> <month> March </month> <year> 1986. </year>
Reference-contexts: One class of heuristic algorithms is a behavioral based approach in which the robot is armed with simple behaviors such as following a wall <ref> [2] </ref>. A hierarchy of cooperating behaviors forms more complicated behaviors such as exploration. An extension of this type of approach is called sequencing [7].
Reference: [3] <author> J.F. Canny and M.C. Lin. </author> <title> An Opportunistic Global Path Planner. </title> <journal> Algorithmica, </journal> <volume> 10 </volume> <pages> 102-120, </pages> <year> 1993. </year>
Reference-contexts: These methods are useful in higher dimensions because the bulk of the motion planning is done in a one-dimensional space. An example of a complete roadmap scheme is Canny and Lin's Opportunistic Path Planner <ref> [3] </ref>. Rimon adapted this motion planning scheme for sensor based use [12]. Unfortunately, connectivity of the roadmap in [12] cannot be guaranteed without active perception. Furthermore, from a practical point of view, there are two detractions to Rimon's method.
Reference: [4] <author> H. Choset and J.W. Burdick. </author> <title> Sensor Based Planning and Nonsmooth Analysis. </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 3034-3041, </pages> <address> San Diego, CA, </address> <year> 1994. </year>
Reference-contexts: In this paper, we show how a mobile robot effects sensor based planning using raw sensor readings from sonar sensors. We describe the experimental implementation of a sensor based planner that is based on the Generalized Voronoi Graph (GVG) whose definitions and properties are found in <ref> [4] </ref>, [5] and [6] (and are reviewed in Section 5). The computational aspects required to implement the GVG-based planning scheme was described in [6] (and is reviewed in Section 6) , where it was assumed that only information within line of sight of the robot can be detected.
Reference: [5] <author> H. Choset and J.W. Burdick. </author> <title> Sensor Based Planning, Part I: The Generalized Voronoi Graph. </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <address> Nagoya, Japan, </address> <year> 1995. </year>
Reference-contexts: In this paper, we show how a mobile robot effects sensor based planning using raw sensor readings from sonar sensors. We describe the experimental implementation of a sensor based planner that is based on the Generalized Voronoi Graph (GVG) whose definitions and properties are found in [4], <ref> [5] </ref> and [6] (and are reviewed in Section 5). The computational aspects required to implement the GVG-based planning scheme was described in [6] (and is reviewed in Section 6) , where it was assumed that only information within line of sight of the robot can be detected. <p> term this structure the two-equidistant face, F ij = fx 2 R m : 0 d i (x) = d j (x) d h (x) 8h 6= i; j A two-equidistant face has co-dimension one in the ambient space, and thus in the plane, a two-equidistant face is one dimensional <ref> [5] </ref>. The Pre-image Theorem asserts that the union of the two-equidistant faces, i.e., the GVD, is (m 1)-dimensional [5]. The GVD does reduce the motion planning problem by a dimension, but a one-dimensional roadmap is required. <p> = d j (x) d h (x) 8h 6= i; j A two-equidistant face has co-dimension one in the ambient space, and thus in the plane, a two-equidistant face is one dimensional <ref> [5] </ref>. The Pre-image Theorem asserts that the union of the two-equidistant faces, i.e., the GVD, is (m 1)-dimensional [5]. The GVD does reduce the motion planning problem by a dimension, but a one-dimensional roadmap is required. Observe that the two-equidistant faces, F ij , F ik , and F jk intersect to form an (m 2)-dimensional manifold that is equidistant to three obstacles. <p> Note that the GVD is m 1-dimensional whereas the GVG one-dimensional. Also, the GVD is the locus of points equidistant to two obstacles whereas the GVG is the locus of points equidistant to m obstacles. In the planar case, the GVG and GVD coincide. In <ref> [5] </ref>, it was shown that the GVG possesses the properties of accessibility and departability. Nevertheless, connectivity is only guaranteed in planar case. In higher dimensions, higher order generalized Voronoi graphs must be constructed to connect the GVG components [5]. <p> In the planar case, the GVG and GVD coincide. In <ref> [5] </ref>, it was shown that the GVG possesses the properties of accessibility and departability. Nevertheless, connectivity is only guaranteed in planar case. In higher dimensions, higher order generalized Voronoi graphs must be constructed to connect the GVG components [5]. <p> The incremental construction techniques described in this section provide a rigorous approach to constructing the GVG using only line of sight sensory information. Incremental Accessibility. As described in <ref> [5] </ref>, [10], gradient ascent applied to the distance function to the nearest object can be used to trace a path from any point in the free space to the planar GVG. See Fig. 2. Traceability. In an incremental context, the property of connectivity is interpreted as traceability. <p> The squares denote the location of meet points in the environment. 9 Conclusion This paper described the implementation of a general sensor based planning strategy, based on the generalized Voronoi graph, for the special case of a planar environment. We showed that using the algorithm of <ref> [5] </ref>, [6], a robot equipped with only a ring of sonar sensors can explore an a priori unknown environment and produce a one-dimensional representation (the GVG) of that static environment. With this one-dimensional representation, the robot can plan future excursions into the environment.
Reference: [6] <author> H. Choset and J.W. Burdick. </author> <title> Sensor Based Planning, Part II: Incremental Construction of the Generalized Voronoi Graph. </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <address> Nagoya, Japan, </address> <year> 1995. </year>
Reference-contexts: In this paper, we show how a mobile robot effects sensor based planning using raw sensor readings from sonar sensors. We describe the experimental implementation of a sensor based planner that is based on the Generalized Voronoi Graph (GVG) whose definitions and properties are found in [4], [5] and <ref> [6] </ref> (and are reviewed in Section 5). The computational aspects required to implement the GVG-based planning scheme was described in [6] (and is reviewed in Section 6) , where it was assumed that only information within line of sight of the robot can be detected. <p> We describe the experimental implementation of a sensor based planner that is based on the Generalized Voronoi Graph (GVG) whose definitions and properties are found in [4], [5] and <ref> [6] </ref> (and are reviewed in Section 5). The computational aspects required to implement the GVG-based planning scheme was described in [6] (and is reviewed in Section 6) , where it was assumed that only information within line of sight of the robot can be detected. We term this style of planning Incremental Path Planning. For the incremental construction of the GVG [6], the robot need only know the distance and direction <p> to implement the GVG-based planning scheme was described in <ref> [6] </ref> (and is reviewed in Section 6) , where it was assumed that only information within line of sight of the robot can be detected. We term this style of planning Incremental Path Planning. For the incremental construction of the GVG [6], the robot need only know the distance and direction to the m closest objects in m dimensions (in the planar case, m = 2). The implementation of the incremental technique using realistic sensors is described in this work. <p> The predictor step moves the robot for a small distance along the tangent of the GVG. This tangent is the vector orthogonal to the m closest points in the m closest obstacles <ref> [6] </ref>; this can be readily computed with line of sight information. Typically, the prediction step takes the robot off of a GVG edge, so a correction procedure is required to bring the robot back to the GVG. <p> It is shown in <ref> [6] </ref> that r y G is invertible and thus Equation (4) is well posed. Practically speaking, this result states that the numerical procedure defined by Equation (4) will be robust for reasonable errors in robot position, sensor errors, and numerical round off. Terminating Conditions. <p> Practically speaking, this result states that the numerical procedure defined by Equation (4) will be robust for reasonable errors in robot position, sensor errors, and numerical round off. Terminating Conditions. The explicit terminating conditions for edge tracing are described in <ref> [6] </ref>, but in the planar case there are two terminating conditions: a meet point, where three GVG edges join, and a boundary point, where a GVG edge intersects the boundary of the environment. Finding the meet points is essential to proper construction of the graph. <p> Each new tangent is determined from an m-wise combination of the m + 1 obstacles that define the meet point <ref> [6] </ref>. At a boundary point, the robot simply back tracks to a previous meet point that has unexplored GVG edges associated with it. See Figure 5. <p> Sensors provide the distance to the nearest point from the sensor, without knowing from which obstacle the nearest point came. Therefore, the incremental construction of the GVG described in Section 6 and in <ref> [6] </ref> has to be adapted for sensor based implementation on actual robots. 7.1 The Robot Experiments were performed on Nomadic Technologies mobile robot base, which is a circular platform that has a ring of sixteen sonar sensors radially pointing outward. (See Fig. 16) Dead reckoning for both systems is accomplished by <p> The squares denote the location of meet points in the environment. 9 Conclusion This paper described the implementation of a general sensor based planning strategy, based on the generalized Voronoi graph, for the special case of a planar environment. We showed that using the algorithm of [5], <ref> [6] </ref>, a robot equipped with only a ring of sonar sensors can explore an a priori unknown environment and produce a one-dimensional representation (the GVG) of that static environment. With this one-dimensional representation, the robot can plan future excursions into the environment.
Reference: [7] <author> E. Gat and G. Dorais. </author> <title> Robot Navigation by Conditional Sequencing. </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 1293-1299, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: One class of heuristic algorithms is a behavioral based approach in which the robot is armed with simple behaviors such as following a wall [2]. A hierarchy of cooperating behaviors forms more complicated behaviors such as exploration. An extension of this type of approach is called sequencing <ref> [7] </ref>. Since there are strong experimental results indicating the utility of these approaches (such as [7]), some of these algorithms may provide a future basis for provably correct sensor based planners. Another type of heuristic approach involves discretiz-ing the planar world into pixels of some resolution. <p> A hierarchy of cooperating behaviors forms more complicated behaviors such as exploration. An extension of this type of approach is called sequencing <ref> [7] </ref>. Since there are strong experimental results indicating the utility of these approaches (such as [7]), some of these algorithms may provide a future basis for provably correct sensor based planners. Another type of heuristic approach involves discretiz-ing the planar world into pixels of some resolution.
Reference: [8] <author> H.B. Keller. </author> <title> Lectures on Numerical Methods in Bifurcation Problems. </title> <institution> Tata Institute of Fundamental Research, Bombay, India, </institution> <year> 1987. </year>
Reference-contexts: More specifically, traceability implies that using only local data, the robot can: (1) "trace" the GVG edges; (2) determine when to terminate the edge tracing process, and (3) determine when to start new edge tracing procedures. The GVG incremental approach to edge construction borrows ideas from numerical continuation methods <ref> [8] </ref>. Continuation methods trace the roots of the expression G (y; ) = 0 as the parameter is varied. For the case of Fig. 2.
Reference: [9] <author> V. Lumelsky and A. Stepanov. </author> <title> Path Planning Strategies for Point Mobile Automaton Moving Amidst Unknown Obstacles of Arbitrary Shape. </title> <journal> Algorithmica, </journal> <volume> 2 </volume> <pages> 403-430, </pages> <year> 1987. </year>
Reference-contexts: There are many non-heuristic algorithms for which provably correct solutions exist in the plane (see [11] for an overview). For example, Lumelsky's "bug" algorithm <ref> [9] </ref> is an example of one of the first provably correct sensor based schemes to work in the plane. However, this algorithm (like many described in [11]) requires knowledge of the goal's location during the planning process. Furthermore, this algorithm simply returns a path from the start to the goal.
Reference: [10] <author> C. O'Dunlaing and C.K. Yap. </author> <title> A "Retraction" Method for Planning the Motion of a Disc. </title> <journal> Algorithmica, </journal> <volume> 6 </volume> <pages> 104-111, </pages> <year> 1985. </year>
Reference-contexts: However, this method requires landmarks in constructing its map and is limited to the planar case. 3 Contributions The generalized Voronoi graph (GVG) is a new type of roadmap-like structure that is a generalization of the generalized Voronoi diagram (GVD) <ref> [10] </ref> into higher dimensions. Recall that the GVD is the (m 1)-dimensional locus of points equidistant to two obstacles in m-dimensions, whereas the GVG is the one-dimensional locus of points equidistant to m obstacles in m dimensions. <p> The incremental construction techniques described in this section provide a rigorous approach to constructing the GVG using only line of sight sensory information. Incremental Accessibility. As described in [5], <ref> [10] </ref>, gradient ascent applied to the distance function to the nearest object can be used to trace a path from any point in the free space to the planar GVG. See Fig. 2. Traceability. In an incremental context, the property of connectivity is interpreted as traceability.
Reference: [11] <author> N.S.V. Rao, S. Kareti, W. Shi, and S.S. Iyenagar. </author> <title> Robot Navigation in Unknown Terrains: Introductory Survey of Non-Heuristic Algorithms. </title> <institution> Oak Ridge National Laboratory Technical Report, ORNL/TM-12410:1-58, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: This method lends itself very nicely to implementation with real sensors, but discretizing the world may require a large amount of computer memory and may lead to an inaccurate representation of the world. There are many non-heuristic algorithms for which provably correct solutions exist in the plane (see <ref> [11] </ref> for an overview). For example, Lumelsky's "bug" algorithm [9] is an example of one of the first provably correct sensor based schemes to work in the plane. However, this algorithm (like many described in [11]) requires knowledge of the goal's location during the planning process. <p> There are many non-heuristic algorithms for which provably correct solutions exist in the plane (see <ref> [11] </ref> for an overview). For example, Lumelsky's "bug" algorithm [9] is an example of one of the first provably correct sensor based schemes to work in the plane. However, this algorithm (like many described in [11]) requires knowledge of the goal's location during the planning process. Furthermore, this algorithm simply returns a path from the start to the goal. The resulting path does not reflect the topology of the free space and thus, it cannot be used to guide future robot excursions.
Reference: [12] <author> E. Rimon and J.F. Canny. </author> <title> Construction of C-space Roadmaps Using Local Sensory Data | What Should the Sensors Look For? In Proc. </title> <booktitle> IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 117-124, </pages> <address> San Diego, CA, </address> <year> 1994. </year>
Reference-contexts: These methods are useful in higher dimensions because the bulk of the motion planning is done in a one-dimensional space. An example of a complete roadmap scheme is Canny and Lin's Opportunistic Path Planner [3]. Rimon adapted this motion planning scheme for sensor based use <ref> [12] </ref>. Unfortunately, connectivity of the roadmap in [12] cannot be guaranteed without active perception. Furthermore, from a practical point of view, there are two detractions to Rimon's method. <p> An example of a complete roadmap scheme is Canny and Lin's Opportunistic Path Planner [3]. Rimon adapted this motion planning scheme for sensor based use <ref> [12] </ref>. Unfortunately, connectivity of the roadmap in [12] cannot be guaranteed without active perception. Furthermore, from a practical point of view, there are two detractions to Rimon's method. First, to construct the roadmap, the robot must contain "interesting critical point" and "interesting saddle point" sensors, whose implementation is not well described.
Reference: [13] <author> C.J. Taylor and D.J. Kriegman. </author> <title> Vision-Basied Motion Plan ning and Exploration Algorithms for Mobile Robots. </title> <booktitle> In Proc. of Workshop on the Algorithmic Foundations of Robotics, </booktitle> <address> San Francisco, CA, </address> <month> February </month> <year> 1994. </year>
Reference-contexts: Second, a robust and detailed procedure for constructing the roadmap fragments from sensor data is not presented. Finally, an example of a method that has a provably correct solution, uses realistic sensor assumptions, and need not require prior knowledge of the goal's location is described in <ref> [13] </ref>. In this method, the robot forms a graph of a bounded freespace by circumnavigating each of the obstacles, and then creating an adjacency relationship between obstacles within line of sight of each other.
References-found: 13

