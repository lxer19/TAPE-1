URL: http://www-unix.mcs.anl.gov/prism/lib/techsrc/wn23.ps.Z
Refering-URL: http://www-unix.mcs.anl.gov/prism/lib/tech.html
Root-URL: http://www.mcs.anl.gov
Title: Parallel Studies of the Invariant Subspace Decomposition Approach for Banded Symmetric Matrices*  
Author: Christian Bischof Steven Huss-Lederman Xiaobai Sun Anna Tsao Thomas Turnbull 
Abstract: We present an overview of the banded Invariant Subspace Decomposition Algorithm for symmetric matrices and describe a parallel implementation of this algorithm. The algorithm described here is a promising variant of the Invariant Subspace Decomposition Algorithm for dense symmetric matrices (SYISDA) that retains the property of using scalable primitives, while requiring significantly less overall computation than SYISDA. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Auslander, L. & A. Tsao, </author> <title> On parallelizable eigensolvers, </title> <journal> Adv. Appl. Math. </journal> <volume> 13 (1992), </volume> <pages> 253-261. </pages>
Reference-contexts: The goal of the PRISM project is the development of algorithms and software for solving large-scale eigenvalue problems based on the invariant subspace decomposition approach originally suggested by Auslander and Tsao <ref> [1] </ref>. The algorithm described here is an eigensolver for finding all or some of the eigenvalue-eigenvector pairs of a banded real symmetric matrix. <p> Recall that the SYISDA proceeds as follows: Scaling: Compute bounds on the spectrum (A) of A and use these bounds to compute ff and fi such that for B = ffA + fiI, (B) <ref> [0; 1] </ref>, with the mean eigenvalue of A being fl This work was partially supported by the Applied and Computational Mathematics Program, Advanced Research Projects Agency, under Contract DM28E04120, and by the Office of Scientific Computing, U.S.
Reference: [2] <author> Bischof, C. H., S. Huss-Lederman, X. Sun, & A. Tsao, </author> <title> The PRISM project: infrastructure and algorithms for parallel eigensolvers, </title> <booktitle> Proceedings, Scalable Parallel Libraries Conference (Starksville, </booktitle> <address> MS, </address> <month> Oct. </month> <pages> 6-8, </pages> <year> 1993), </year> <note> IEEE, </note> <year> 1993, </year> <pages> pp. 123-131, </pages> <note> (also PRISM Working Note #12). </note>
Reference-contexts: The algorithm described here is an eigensolver for finding all or some of the eigenvalue-eigenvector pairs of a banded real symmetric matrix. The algorithm is a variant of the Symmetric Invariant Subspace Decomposition Algorithm (SYISDA) <ref> [2] </ref> and like SYISDA, uses highly scalable primitives, while requiring significantly less overall computation than SYISDA. In the next section, we give an overview of the banded SYISDA. A parallel implementation of this algorithm is then presented in x3. <p> In contrast, for the matrix C 1 , the amount of work required is generally significantly reduced, because, as discussed in <ref> [4, 2] </ref>, one generally expects a substantial number of the transformations required to reduce a symmetric matrix to tridiagonal to be "skipped" due to the special structure of its eigenvalues.
Reference: [3] <author> Bischof, C., B. Lang, & X. Sun, </author> <title> Parallel tridiagonalization through two-step band reduction, </title> <booktitle> Proceedings: Scalable High Performance Computing Conference '94, </booktitle> <address> Knoxville, Tennessee, May 1994, </address> <publisher> IEEE Computer Society Press, </publisher> <year> 1994, </year> <note> (also PRISM Working Note #17). </note>
Reference-contexts: It turns out that each of these kernels can be performed almost entirely in block operations <ref> [6, 3] </ref>. To date, we have implemented the blocked reduction of a dense matrix to narrow band. We are currently developing a parallel realization of the blocked algorithms for reductions of a banded matrix to narrow band and of a narrow banded matrix to tridiagonal.
Reference: [4] <author> Bischof, C. & X. Sun, </author> <title> A divide-and-conquer method for tridiagonalizing symmetric matrices with repeated eigenvalues, </title> <type> Preprint MCS-P286-0192, </type> <institution> Argonne National Laboratory (1992), </institution> <note> (also PRISM Working Note #1). </note>
Reference-contexts: The periodic band reductions required are performed using successive band reduction [5]. As in dense SYISDA [9], the Invariant Subspace Computation step is performed using rank-revealing tridiagonalization <ref> [4, 9] </ref>. Sequential studies have demonstrated that banded SYISDA is quite promising [7]. 3 Parallel Algorithm In this section, we describe our parallel algorithm for banded SYISDA. <p> In contrast, for the matrix C 1 , the amount of work required is generally significantly reduced, because, as discussed in <ref> [4, 2] </ref>, one generally expects a substantial number of the transformations required to reduce a symmetric matrix to tridiagonal to be "skipped" due to the special structure of its eigenvalues.
Reference: [5] <author> Bischof, C. & X. Sun, </author> <title> A framework for symmetric band reduction and tridiagonaliza-tion, </title> <type> Preprint MCS-P298-0392, </type> <institution> Argonne National Laboratory (1992), </institution> <note> (also PRISM Working Note #3). </note>
Reference-contexts: The periodic band reductions required are performed using successive band reduction <ref> [5] </ref>. As in dense SYISDA [9], the Invariant Subspace Computation step is performed using rank-revealing tridiagonalization [4, 9]. Sequential studies have demonstrated that banded SYISDA is quite promising [7]. 3 Parallel Algorithm In this section, we describe our parallel algorithm for banded SYISDA. <p> The required band reductions will be performed using the so-called successive band reduction <ref> [5] </ref>.
Reference: [6] <author> Bischof, C. H. and X. Sun, </author> <title> On Orthogonal Block Elimination, </title> <type> Technical Report MCS-P441-0594, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory (1994), </institution> <note> (also PRISM Working Note #20). </note>
Reference-contexts: It turns out that each of these kernels can be performed almost entirely in block operations <ref> [6, 3] </ref>. To date, we have implemented the blocked reduction of a dense matrix to narrow band. We are currently developing a parallel realization of the blocked algorithms for reductions of a banded matrix to narrow band and of a narrow banded matrix to tridiagonal.
Reference: [7] <author> Bischof, C., X. Sun, A. Tsao, & T. Turnbull, </author> <title> A study of the Invariant Subspace De 6 Christian Bischof et al. composition Algorithm for banded symmetric matrices, </title> <booktitle> Proceedings: Fifth SIAM Conference on Applied Linear Algebra, </booktitle> <address> Snowbird, UT, </address> <month> June, </month> <editor> 1994 (John G. Lewis, eds.), </editor> <publisher> SIAM, </publisher> <year> 1994, </year> <pages> pp. 321-325, </pages> <note> (also PRISM Working Note #16). </note>
Reference-contexts: We can then apply the same approach in parallel to A 1 and A 2 until all subproblems have been solved. Banded SYISDA first reduces the original matrix to narrow band and then periodically reduces matrices in the Eigenvalue Smoothing step back to narrow band <ref> [7] </ref>. The dense matrix multiplications performed in dense SYISDA are replaced by banded matrix multiplications plus a small number of band reductions during the polynomial iteration process. <p> This fact, coupled with the slow band growth during the iteration process <ref> [7] </ref>, dramatically reduces the cost of performing matrix multiplications over that of SYISDA, at the expense of a small number of band reductions. <p> The periodic band reductions required are performed using successive band reduction [5]. As in dense SYISDA [9], the Invariant Subspace Computation step is performed using rank-revealing tridiagonalization [4, 9]. Sequential studies have demonstrated that banded SYISDA is quite promising <ref> [7] </ref>. 3 Parallel Algorithm In this section, we describe our parallel algorithm for banded SYISDA. <p> performance tradeoffs between the allowed band growth and computational efficiency. 3.2 Successive Band Reduction and Rank-revealing Tridiagonalization In banded SYISDA, symmetric band reductions play a pivotal role, since the band reductions performed during the Eigenvalue Smoothing step and rank-revealing tridiagonal-ization taken together account for the majority of the overall computation <ref> [7] </ref>. The required band reductions will be performed using the so-called successive band reduction [5].
Reference: [8] <author> Huss-Lederman, S., E. M. Jacobson, A. Tsao, & G. Zhang, </author> <title> Matrix multiplication on the Intel Touchstone Delta, </title> <journal> Concurrency: Practice & Experience, </journal> <note> (also PRISM Working Note #14) (to appear). </note>
Reference-contexts: For our parallel implementation of dense SYISDA, we developed a distributed dense matrix multiplication routine, BiM-MeR <ref> [8] </ref>. On square meshes, the same algorithm used in BiMMeR can be used to multiply banded matrices simply by replacing the dense matrix multiplication on each node by a banded matrix multiplication.
Reference: [9] <author> Huss-Lederman, S., A. Tsao, & G. Zhang, </author> <title> A parallel implementation of the Invariant Subspace Decomposition Algorithm for dense symmetric matrices, </title> <booktitle> Proceedings, Sixth SIAM Conference on Parallel Processing for Scientific Computing (Norfolk, </booktitle> <address> Virginia, </address> <month> March 22-24, </month> <editor> 1993) (R. F. Sincovec, eds.), </editor> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1993, </year> <pages> pp. 367-374, </pages> <note> (also PRISM Working Note #9, also appears as Technical Report SRC-TR-93-091, </note> <institution> Supercomputing Research Center, </institution> <year> 1993). </year>
Reference-contexts: The periodic band reductions required are performed using successive band reduction [5]. As in dense SYISDA <ref> [9] </ref>, the Invariant Subspace Computation step is performed using rank-revealing tridiagonalization [4, 9]. Sequential studies have demonstrated that banded SYISDA is quite promising [7]. 3 Parallel Algorithm In this section, we describe our parallel algorithm for banded SYISDA. <p> The periodic band reductions required are performed using successive band reduction [5]. As in dense SYISDA [9], the Invariant Subspace Computation step is performed using rank-revealing tridiagonalization <ref> [4, 9] </ref>. Sequential studies have demonstrated that banded SYISDA is quite promising [7]. 3 Parallel Algorithm In this section, we describe our parallel algorithm for banded SYISDA.
Reference: [10] <author> Huss-Lederman, S., A. Tsao, & G. Zhang, </author> <title> A parallel implementation of the Invariant Subspace Decomposition Algorithm for dense symmetric matrices, </title> <booktitle> Proceedings, Sixth SIAM Conference on Parallel Processing for Scientific Computing (Norfolk, </booktitle> <address> Virginia, </address> <month> March 22-24, </month> <editor> 1993) (R. F. Sincovec, eds.), </editor> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1993, </year> <pages> pp. 367-374, </pages> <note> (also PRISM Working Note #9). </note>
Reference-contexts: We briefly review the two stages of the divide and conquer strategy; more detail Parallel Banded Symmetric ISDA 5 can be found in <ref> [10] </ref>. The first stage encompasses the early divides, where large subproblems are solved sequentially and the overall performance depends on the scaling properties of the banded matrix multiplication, successive band reductions, and rank-revealing tridiagonalization. Each divide produces two independent dense symmetric eigenvalue problems. <p> Through the use of two-dimensional torus wrap, no data redistribution is required between divides. As in dense SYISDA, as the subproblem size decreases, the proportion of the total time required for communication during individual matrix multiplications increases and the granularity of local computation decreases. However, as discussed in <ref> [10] </ref>, this approach guarantees near-perfect load balancing in the costly early stages. As the subproblem size decreases, there is a point at which communications overhead makes it impractical to solve that subproblem over the entire mesh.
Reference: [11] <author> Quintana, G., X. Sun, A. Tsao, & T. Turnbull, </author> <title> A comparison of algorithms for banded matrix multiplication, </title> <note> in preparation. </note>
Reference-contexts: In our implementation, these uniprocessor banded matrix multiplications are performed using efficient, specialized routines for multiplying banded matrices stored in packed format <ref> [12, 11] </ref>. The use of packed storage translates into decreased communication costs over using full storage. Use of this strategy ensures that banded matrix multiplication will scale, provided that the matrix bandwidths grow proportionally to the matrix dimension and are large enough so that all processors have computation to do.
Reference: [12] <author> Tsao, A. & T. Turnbull, </author> <title> A comparison of algorithms for banded matrix multiplication, </title> <type> Technical Report SRC-TR-93-092, </type> <institution> Supercomputing Research Center (1993), </institution> <note> (also PRISM Working Note #6). </note>
Reference-contexts: In our implementation, these uniprocessor banded matrix multiplications are performed using efficient, specialized routines for multiplying banded matrices stored in packed format <ref> [12, 11] </ref>. The use of packed storage translates into decreased communication costs over using full storage. Use of this strategy ensures that banded matrix multiplication will scale, provided that the matrix bandwidths grow proportionally to the matrix dimension and are large enough so that all processors have computation to do.
References-found: 12

