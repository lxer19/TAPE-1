URL: http://polaris.cs.uiuc.edu/reports/1430.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: A MATLAB Compiler and Restructurer for the Development of Scientific Libraries and Applications  
Author: L. DeRose, K. Gallivan, E. Gallopoulos, B. Marsolf and D. Padua 
Address: 1308 West Main Street Urbana, Illinois 61801  
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  
Date: August 1995  May 1995  
Note: In the preliminary proceedings of the 8th International Workshop on Languages and Compilers for Parallel Computing. pp 18.1-18.18, Columbus, Ohio,  
Pubnum: CSRD Report No. 1430  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> AHO, A., SETHI, R., AND ULLMAN, J. </author> <booktitle> Compilers: Principles, Techniques and Tools. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1985. </year>
Reference-contexts: Although described separately here, shape and structure inference work in coordination with the coverage analysis discussed in the previous subsection. Variable properties are estimated using a forward/backward scheme <ref> [1] </ref>. For type inference, we use a type algebra similar to the one described in [27] for SETL. This algebra operates on the type of the MATLAB objects and is implemented using of tables for all operations.
Reference: [2] <author> AMARASINGHE, S. P., ANDERSON, J. M., LAM, M. S., AND LIM, A. W. </author> <title> An Overview of a Compiler for Scalable Parallel Machines. In Languages and Compilers for Parallel Computing (August 1993), </title> <editor> U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, Eds., </editor> <publisher> Springer-Verlag, </publisher> <pages> pp. 253-272. </pages> <booktitle> 6th International Workshop, </booktitle> <address> Portland, Oregon. </address>
Reference-contexts: This difficulty holds true even when the objective is to develop code for a single target machine. Several approaches to facilitate the development and maintenance of parallel code are currently under study. One approach is the automatic translation of conventional programming languages, notably Fortran, into parallel form. SUIF <ref> [2] </ref>, a compiler developed at Stanford, and Parafrase-2 [26] and Polaris [24], developed at Illinois, are examples of this first approach. Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions.
Reference: [3] <institution> APPLIED PARALLEL RESEARCH. </institution> <note> FORGE 90 Baseline System User's Guide. </note> <institution> Placerville, California. </institution> <note> Version 8.9. </note>
Reference-contexts: There has been some work on interactive program restructuring and there are some commercially available interactive Fortran restructurers, such as FORGE <ref> [3] </ref>. Also, restructuring of high-level operators has been discussed in the literature [4, 12], although there are no widely-used systems that apply these types of transformations. No system today includes capabilities for algebraic, control structure, and library selection transformations.
Reference: [4] <author> BACKUS, J. </author> <title> Can Programming Be Liberated from the Von Newmann Style? A Functional Style and Its Algebra of Programs. </title> <journal> Communications of the ACM 21, </journal> <month> 8 (August </month> <year> 1978), </year> <pages> 613-641. </pages>
Reference-contexts: There has been some work on interactive program restructuring and there are some commercially available interactive Fortran restructurers, such as FORGE [3]. Also, restructuring of high-level operators has been discussed in the literature <ref> [4, 12] </ref>, although there are no widely-used systems that apply these types of transformations. No system today includes capabilities for algebraic, control structure, and library selection transformations. We are planning on implementing several restructuring techniques for complex transformations on the code.
Reference: [5] <author> BARRETT, R., BERRY, M., CHAN, T., DEMMEL, J., DONATO, J., DONGARRA, J., EIJKHOUT, V., POZO, R., ROMINE, C., AND VAN DER VORST, H. </author> <title> Templates for the Solution of Linear Systems: Building Blocks for Iterative Methods. </title> <publisher> SIAM, </publisher> <year> 1993. </year>
Reference-contexts: Other libraries, such as a sparse library, can be supported. To test the performance of this initial version of the compiler, we used three MATLAB code segments provided in Netlib for the algorithms presented in <ref> [5] </ref>. These code segments correspond to the following algorithms for the iterative solution of linear systems: the Conjugate Gradient method (CG), the Quasi-Minimal Residual method (QMR), and the Successive Overrelaxation method (SOR). The programs were tested using a 420 fi 420 stiffness matrix from the Harwell-Boeing Test Set.
Reference: [6] <author> BLUME, W., AND EIGENMANN, R. </author> <title> The Range Test: A Dependence Test for Symbolic, Non-linear Expressions. </title> <booktitle> In Proceedings of Supercomputing '94 (November 1994), </booktitle> <pages> pp. 528-537. </pages>
Reference-contexts: It also makes use of a number of conventional analysis algorithms, including induction variable recognition [18] to compute upper and lower bounds of these variables, and propagation of the range of values of scalars and of those arrays used as subscripts <ref> [6, 13] </ref>. This analysis is performed interprocedurally whenever the modules referenced in the program are available to the system. In the case of intrinsic functions, information on the elements accessed are available in a database that is consulted during the computation of ranges.
Reference: [7] <author> BODIN, F., BECKMAN, P., GANNON, D., NARAYANA, S., AND YANG, S. </author> <title> Distributed pC++: Basic Ideas for an Object Parallel Language. </title> <booktitle> In OON-SKI'93 Proceedings of the First Annual Object-Oriented Numerics Conference (April 1993), </booktitle> <pages> pp. 1-24. </pages>
Reference-contexts: Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions. Examples include High Performance Fortran [19] and pC++ <ref> [7] </ref>. Finally, a third approach is to accept a very high-level description of the mathematical problem to be solved and automatically compute the solution fl Supported by the CSRD Affiliates under grant from the U.S. National Security Agency. y Supported by the National Science Foundation under Grant No.
Reference: [8] <author> BUDD, T. </author> <title> An APL Compiler. </title> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: Previous work on type inference has been done for several high-level languages. In particular, type inference techniques developed for SETL [27] and APL <ref> [8, 11] </ref> are most relevant to our work. These two languages are similar to MATLAB in that they can be executed interactively, are usually interpreted, and operate on aggregate data structures. <p> This last problem, which seems to be ignored by current APL compilers <ref> [8, 11] </ref>, is illustrated by the following pseudocode segment: A = ... if (cond) k = ... else k = ... ... In this case, the compiler needs to determine if the partial assignment to A is a subrange of the previous definitions of the variable.
Reference: [9] <author> CARR, S., AND KENNEDY, K. </author> <title> Compiler Blockability of Numerical Algorithms. </title> <booktitle> In Proceedings, Supercomputing '92 (November 1992), </booktitle> <pages> pp. 114-124. </pages>
Reference-contexts: These additional operations were generated by utilizing the definition of the transform; they would not have been apparent by just examining the code. This utilization of algebraic information is being performed not only by algorithm developers, but is also being explored by compiler writers <ref> [9] </ref>. The transformations will be based on patterns that the system can recognize in the code and on the replacements for these patterns. The developer will be able to select a segment of code and the system will indicate which patterns match the segment.
Reference: [10] <author> CHAR, B. W., GEDDES, K. O., GONNET, G. H., LEONG, B. L., MONAGAN, M. B., AND WATT, S. M. </author> <title> Maple V Language Reference Manual. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: To perform such manipulations, symbolic computation tools, such as Maple <ref> [10] </ref>, can be employed. In some cases, applying these rules may be similar to the standard loop-based restructuring strategies used by conventional restructuring compilers, such as loop blocking. However, we also want to be able to handle special matrix classes and more complex operators.
Reference: [11] <author> CHING, W.-M. </author> <title> Program Analysis and Code Generation in an APL/370 Compiler. </title> <journal> IBM Journal of Research and Development 30:6 (November 1986), </journal> <pages> 594-602. </pages>
Reference-contexts: Previous work on type inference has been done for several high-level languages. In particular, type inference techniques developed for SETL [27] and APL <ref> [8, 11] </ref> are most relevant to our work. These two languages are similar to MATLAB in that they can be executed interactively, are usually interpreted, and operate on aggregate data structures. <p> This last problem, which seems to be ignored by current APL compilers <ref> [8, 11] </ref>, is illustrated by the following pseudocode segment: A = ... if (cond) k = ... else k = ... ... In this case, the compiler needs to determine if the partial assignment to A is a subrange of the previous definitions of the variable.
Reference: [12] <author> COOK JR., G. O. </author> <title> ALPAL A Tool for the Development of Large-Scale Simulation Codes. </title> <type> Tech. rep., </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> August </month> <year> 1988. </year> <note> Technical Report UCID-21482. 17 </note>
Reference-contexts: US NSF CCR-9120105. x Supported in part by Army contract DABT63-92-C-0033. This work is not necessarily representative of the positions or policies of the Army or the Government. 1 in parallel. Examples of this approach are //ELLPACK [20], developed at Purdue, ALPAL <ref> [12] </ref>, developed at Lawrence Livermore Laboratories, and EXTENT [15], developed at Ohio State University. We are developing a programming environment that includes capabilities for interactive and automatic transformations at both the operation-level and the function- or algorithmic-level. <p> There has been some work on interactive program restructuring and there are some commercially available interactive Fortran restructurers, such as FORGE [3]. Also, restructuring of high-level operators has been discussed in the literature <ref> [4, 12] </ref>, although there are no widely-used systems that apply these types of transformations. No system today includes capabilities for algebraic, control structure, and library selection transformations. We are planning on implementing several restructuring techniques for complex transformations on the code.
Reference: [13] <author> COUSOT, P., AND HALBWACHS, N. </author> <title> Automatic Discovery of Linear Restraints Among Variables of a Program. </title> <booktitle> In Proceedings of the 5th Anual ACM Symposium on Principles of Programming Languages (1978), </booktitle> <pages> pp. 84-97. </pages>
Reference-contexts: It also makes use of a number of conventional analysis algorithms, including induction variable recognition [18] to compute upper and lower bounds of these variables, and propagation of the range of values of scalars and of those arrays used as subscripts <ref> [6, 13] </ref>. This analysis is performed interprocedurally whenever the modules referenced in the program are available to the system. In the case of intrinsic functions, information on the elements accessed are available in a database that is consulted during the computation of ranges.
Reference: [14] <author> CYTRON, R., FERRANTE, J., ROSEN, B. K., WEGMAN, M. N., AND ZADECK, F. K. </author> <title> Efficiently Computing Static Single Assignment Form and the Control Dependence Graph. </title> <journal> ACM Transactions on Programming Language and Systems 13, </journal> <month> 4 (October </month> <year> 1991), </year> <pages> 451-490. </pages>
Reference-contexts: During the compilation of the MATLAB program, M-files will be inlined into the main program. This approach is appealing because the variable properties can be easily propagated inside the functions. 2.1.1 Use-Definition Coverage The MATLAB program is internally represented in Static Single Assignment (SSA) form <ref> [14] </ref>. This is a convenient representation for many of the analysis algorithms that are implemented. In the SSA representation, it is evident which definitions affect (or cover) a particular use of a scalar variable. Using this information, it is easy to perform variable renaming and privatization.
Reference: [15] <author> DAI, D. L., GUPTA, S. K. S., KAUSHIK, S. D., LU, J. H., SINGH, R. V., HUANG, C.-H., SADAYAPPAN, P., AND JOHNSON, R. W. </author> <title> EXTENT: A Portable Programming Environment for Designing and Implementing High-Performance Block-Recursive Algorithms. </title> <booktitle> In Proceedings of Supercomputing '94 (November 1994), </booktitle> <pages> pp. 49-58. </pages>
Reference-contexts: This work is not necessarily representative of the positions or policies of the Army or the Government. 1 in parallel. Examples of this approach are //ELLPACK [20], developed at Purdue, ALPAL [12], developed at Lawrence Livermore Laboratories, and EXTENT <ref> [15] </ref>, developed at Ohio State University. We are developing a programming environment that includes capabilities for interactive and automatic transformations at both the operation-level and the function- or algorithmic-level.
Reference: [16] <author> DEROSE, L., GALLIVAN, K., GALLOPOULOS, E., MARSOLF, B., AND PADUA, D. </author> <title> An Environment for the Rapid Prototyping and Development of Numerical Programs and Libraries for Scientific Computation. </title> <booktitle> In Proc. of the DAGS'94 Symposium: Parallel Computation and Problem Solving Environments (Dartmouth College, </booktitle> <month> July </month> <year> 1994), </year> <editor> F. Makedon, </editor> <publisher> Ed., </publisher> <pages> pp. 11-25. </pages>
Reference-contexts: This environment supports the development of high-performance numerical programs and libraries, combining the transformation and analysis techniques used in restructuring compilers with the algebraic techniques used by developers to express and manipulate their algorithms in an intuitively useful manner <ref> [16] </ref>. As we envision it, the development process should start with a simple prototype of the algorithm and then continue with a sequence of automatic and interactive transformations until an effective program or routine is obtained.
Reference: [17] <author> GALLIVAN, K., AND MARSOLF, B. </author> <title> Practical Issues Related to Developing Object-Oriented Numerical Libraries. </title> <booktitle> In OON-SKI'94 Proceedings of the Second Annual Object-Oriented Numerics Conference (April 1994), </booktitle> <pages> pp. 93-106. </pages>
Reference-contexts: be interchanged only if the data dependences do not contain a direction vector of the form &lt;,&gt; [25]. 2.2.2 Primitive-set to Primitive-set Translation Primitive-set to primitive-set translation can also be used to translate the code to the level of numerical operations that work best for the target machine and application <ref> [17] </ref>. Instead of dealing with the code only at a matrix operation level, this phase will be able to decompose the algorithms to matrix-vector operations and vector-vector 11 operations; or, in some circumstances, it will form higher-level operations by combining multiple lower-level operations.
Reference: [18] <author> GERLEK, M. P., STOLTZ, E., AND WOLFE, M. </author> <title> Beyond Induction Variables: Detecting and Classifying Sequences Using a Demand-driven SSA Form. </title> <note> ACM TOPLAS (to appear). </note>
Reference-contexts: The strategy uses data flow analysis to determine which definitions cover the uses of array elements. It also makes use of a number of conventional analysis algorithms, including induction variable recognition <ref> [18] </ref> to compute upper and lower bounds of these variables, and propagation of the range of values of scalars and of those arrays used as subscripts [6, 13]. This analysis is performed interprocedurally whenever the modules referenced in the program are available to the system.
Reference: [19] <author> HIGH PERFORMANCE FORTRAN FORUM. </author> <title> High Performance Fortran Language Specification, </title> <month> May </month> <year> 1993. </year> <note> Version 1.0. </note>
Reference-contexts: Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions. Examples include High Performance Fortran <ref> [19] </ref> and pC++ [7]. Finally, a third approach is to accept a very high-level description of the mathematical problem to be solved and automatically compute the solution fl Supported by the CSRD Affiliates under grant from the U.S.
Reference: [20] <author> HOUSTIS, E. N., RICE, J. R., CHRISOCHOIDES, N. P., KARATHANASIS, H. C., PAPACHIOU, P. N., SAMARTIZS, M. K., VAVALIS, E. A., WANG, K. Y., AND WEERAWARANA, S. </author> <title> //ELLPACK: A Numerical Simulation Programming Environment for Parallel MIMD Machines. </title> <booktitle> In Proceedings 1990 International Conference on Supercomputing (1990), </booktitle> <pages> pp. 96-107. </pages>
Reference-contexts: ARPA/NIST 60NANB2D1272. z Supported by the National Science Foundation under Grant No. US NSF CCR-9120105. x Supported in part by Army contract DABT63-92-C-0033. This work is not necessarily representative of the positions or policies of the Army or the Government. 1 in parallel. Examples of this approach are //ELLPACK <ref> [20] </ref>, developed at Purdue, ALPAL [12], developed at Lawrence Livermore Laboratories, and EXTENT [15], developed at Ohio State University. We are developing a programming environment that includes capabilities for interactive and automatic transformations at both the operation-level and the function- or algorithmic-level.
Reference: [21] <author> KUCK AND ASSOCIATES, INC. </author> <title> KAP User's Guide, </title> <booktitle> 4th ed. </booktitle> <address> Savoy, IL 61874, </address> <year> 1987. </year>
Reference-contexts: Furthermore, the code generator will also produce a MATLAB program. The actual generation of parallel code will be done by a restructuring compiler, such as Polaris [24] or KAP <ref> [21] </ref>. Our system facilitates the translation into parallel form by annotating the target Fortran program and by using array operations whenever possible. Furthermore, the Fortran restructurer should be capable of applying transformations automatically, thereby saving the user of the interactive restructurer additional work.
Reference: [22] <author> THE MATH WORKS, INC. </author> <title> MATLAB, High-Performance Numeric Computation and Visualization Software. User's Guide, </title> <year> 1992. </year>
Reference-contexts: The ideal interactive array language should be easy to learn and capable of accessing powerful graphics and other I/O facilities. We are using an existing language in order to shorten the learning curve for our system and give us immediate access to existing support routines. APL and MATLAB <ref> [22] </ref> are the most widely used interactive array languages today. We have chosen MATLAB because it is the more popular of the two and has a conventional syntax that facilitates learning it. In MATLAB, as in any interactive array language, the type, rank and shape of variables are dynamically determined.
Reference: [23] <author> MURAOKA, Y., AND KUCK, D. J. </author> <title> On the Time Required for a Sequence of Matrix Products. </title> <journal> Communications of the ACM 16, </journal> <month> 1 (January </month> <year> 1973), </year> <pages> 22-26. </pages>
Reference-contexts: For example, A fl B may be possible whereas B fl A may not be possible. Furthermore, the order in which matrix operations are performed can have a significant effect on the number of operations to be performed <ref> [23] </ref>. Consider the multiplication of three vectors, v 1 fl v t 2 fl v 3 , where each vector contains n elements.
Reference: [24] <author> PADUA, D., EIGENMANN, R., HOEFLINGER, J., PETERSEN, P., TU, P., WEATHERFORD, S., AND FAIGIN, K. </author> <title> Polaris: A New-Generation Parallelizing Compiler for MPP's. </title> <type> Tech. rep., </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <month> June </month> <year> 1993. </year> <note> CSRD Report No. 1306. </note>
Reference-contexts: Several approaches to facilitate the development and maintenance of parallel code are currently under study. One approach is the automatic translation of conventional programming languages, notably Fortran, into parallel form. SUIF [2], a compiler developed at Stanford, and Parafrase-2 [26] and Polaris <ref> [24] </ref>, developed at Illinois, are examples of this first approach. Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions. Examples include High Performance Fortran [19] and pC++ [7]. <p> The code generator makes use of the information gathered by the program analysis phase to generate a Fortran 90 program or routine. Furthermore, the code generator will also produce a MATLAB program. The actual generation of parallel code will be done by a restructuring compiler, such as Polaris <ref> [24] </ref> or KAP [21]. Our system facilitates the translation into parallel form by annotating the target Fortran program and by using array operations whenever possible. Furthermore, the Fortran restructurer should be capable of applying transformations automatically, thereby saving the user of the interactive restructurer additional work.
Reference: [25] <author> PADUA, D., AND WOLFE, M. </author> <title> Advanced Compiler Optimizations for Supercomputers. </title> <journal> Communications of the ACM 29, </journal> <month> 12 (December </month> <year> 1986), </year> <pages> 1184-1201. </pages>
Reference-contexts: In Figure 6, a pattern for interchanging loops shows how certain dependence conditions can be placed on the matching of the loop body. In this example, the loops can be interchanged only if the data dependences do not contain a direction vector of the form &lt;,&gt; <ref> [25] </ref>. 2.2.2 Primitive-set to Primitive-set Translation Primitive-set to primitive-set translation can also be used to translate the code to the level of numerical operations that work best for the target machine and application [17].
Reference: [26] <author> POLYCHRONOPOULOS, C., GIRKAR, M., HAGHIGHAT, M. R., LEE, C.-L., LEUNG, B., AND SCHOUTEN, D. </author> <title> Parafrase-2: A New Generation Parallelizing Compiler. </title> <booktitle> In Proceedings of 1989 Int'l. Conference on Parallel Processing, </booktitle> <address> St. Charles, IL (August 1989), </address> <booktitle> vol. II, </booktitle> <pages> pp. 39-48. </pages>
Reference-contexts: Several approaches to facilitate the development and maintenance of parallel code are currently under study. One approach is the automatic translation of conventional programming languages, notably Fortran, into parallel form. SUIF [2], a compiler developed at Stanford, and Parafrase-2 <ref> [26] </ref> and Polaris [24], developed at Illinois, are examples of this first approach. Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions. Examples include High Performance Fortran [19] and pC++ [7].
Reference: [27] <author> SCHWARTZ, J. T. </author> <title> Automatic Data Structure Choice in a Language of a Very High Level. </title> <booktitle> Communications of the ACM 18 (1975), </booktitle> <pages> 722-728. </pages>
Reference-contexts: Previous work on type inference has been done for several high-level languages. In particular, type inference techniques developed for SETL <ref> [27] </ref> and APL [8, 11] are most relevant to our work. These two languages are similar to MATLAB in that they can be executed interactively, are usually interpreted, and operate on aggregate data structures. <p> Although described separately here, shape and structure inference work in coordination with the coverage analysis discussed in the previous subsection. Variable properties are estimated using a forward/backward scheme [1]. For type inference, we use a type algebra similar to the one described in <ref> [27] </ref> for SETL. This algebra operates on the type of the MATLAB objects and is implemented using of tables for all operations. Each node of the graph representing the program internally contains attribute fields to store inference information.
Reference: [28] <author> TU, P., AND PADUA, D. </author> <title> Automatic Array Privatization. In Languages and Compilers for Parallel Computing (August 1993), </title> <editor> U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, Eds., </editor> <publisher> Springer-Verlag, </publisher> <pages> pp. 500-521. </pages> <booktitle> 6th International Workshop, </booktitle> <address> Portland, Oregon. </address> <month> 18 </month>
Reference-contexts: We make use of some of the techniques developed for these two languages and extend them, with techniques originally developed for Fortran, to analyze array accesses and represent the information gathered in a compact form <ref> [28] </ref>. These techniques are necessary for MATLAB, since arrays are often built using Fortran-like loops and assignments that may be distributed across several sections of the code. In contrast, the techniques developed for APL assume that arrays are usually built by a single high-level array operation. <p> We plan to attack the problem of array memory allocation using the techniques described in <ref> [28] </ref>. These have proven quite effective in detecting privatizable arrays in Fortran programs and should be at least equally effective in this context. The strategy uses data flow analysis to determine which definitions cover the uses of array elements. <p> The analysis of ranges and induction variables is facilitated by the use of the SSA representation. These algorithms are applied on-demand. That is, only those values needed are estimated. Our experience is that on-demand analysis substantially improves performance over the conventional forward propagation algorithms <ref> [28] </ref>. 2.1.2 Type Inference To generate Fortran declarations and to support structure selection, the system infers variable properties. Although described separately here, shape and structure inference work in coordination with the coverage analysis discussed in the previous subsection. Variable properties are estimated using a forward/backward scheme [1].
References-found: 28

