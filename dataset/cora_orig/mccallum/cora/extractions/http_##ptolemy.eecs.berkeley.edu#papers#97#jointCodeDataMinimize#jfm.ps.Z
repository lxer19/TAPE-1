URL: http://ptolemy.eecs.berkeley.edu/papers/97/jointCodeDataMinimize/jfm.ps.Z
Refering-URL: http://ptolemy.eecs.berkeley.edu/papers/97/jointCodeDataMinimize/
Root-URL: 
Title: ABSTRACT  
Abstract: In this paper, we formally develop techniques that minimize the memory requirements of a target program when synthesizing software from dataow descriptions of multirate signal processing algorithms. The dataow programming model that we consider is the synchronous data-ow (SDF) model [21], which has been used heavily in DSP design environments over the past several years. We first focus on the restricted class of well-ordered SDF graphs. We show that while extremely efficient techniques exist for constructing minimum code size schedules for well-ordered graphs, the number of distinct minimum code size schedules increases combinatorially with the number of vertices in the input SDF graph, and these different schedules can have vastly different data memory requirements. We develop a dynamic programming algorithm that computes the schedule that minimizes the data memory requirement from among the schedules that minimize code size, and we show that the time complexity of this algorithm is cubic in the number of vertices in the given well-ordered SDF graph. We present several extensions to this dynamic programming technique to more general scheduling problems, and we present a heuristic that often computes near-optimal schedules with quadratic time complexity. We then show that finding optimal solutions for arbitrary acyclic graphs is NP-complete, and present heuristic techniques that jointly minimize code and data size requirements. We present a practical example and simulation data that demonstrate the effectiveness of these techniques. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. A. Abu-Sufah, D. J. Kuck, and D. H. Lawrie, </author> <title> On the Performance Enhancement of Paging Systems Through Program Analysis and Transformations, </title> <journal> IEEE Transactions on Computers, vol.C-30, </journal> <volume> (no.5):341-56, </volume> <month> May, </month> <year> 1981. </year>
Reference-contexts: Then (a). is a valid schedule for ; and (b). . The factoring transformation is closely related to the loop fusion transformation, which has been used for decades in compilers for procedural languages to reduce memory requirements and increase data locality <ref> [1, 26] </ref>. In compilers for procedural languages, tests for the validity of loop fusion include analysis of array subscripts to determine whether or not for each iteration of the (lexically) second loop, this iteration depends only on iterations of the first loop [27].
Reference: [2] <author> M. Ade, R. Lauwereins, and J. A. Peperstraete, </author> <title> Buffer Memory Requirements in DSP Applications, presented at IEEE Workshop on Rapid System Prototyping, </title> <address> Grenoble, </address> <month> June, </month> <year> 1994. </year>
Reference-contexts: We can also prove the following theorem about the lower bound on the buffering memory required by any valid schedule, not just a single appearance schedule. A less general version of this result was also derived independently in <ref> [2] </ref>. Theorem 1: [6] Given an SDF edge , the lower bound on the amount of memory required by any schedule on the edge is given by if , and by otherwise.
Reference: [3] <author> U. Banerjee, </author> <title> Dependence Analysis for Supercomputing, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: These tests are difficult to perform comprehensively due to the complexity of exact subscript analysis <ref> [3] </ref>, and due to complications such as data-dependent subscript values, conditional branches, and input/output statements.
Reference: [4] <author> S. S. Bhattacharyya, </author> <title> Compiling Dataow Programs for Digital Signal Processing, </title> <note> Memorandum No. </note> <institution> UCB/ERL M94/52, Electronics Research Laboratory, University of California at Berkeley, </institution> <month> July, </month> <year> 1994. </year>
Reference-contexts: To a good first approximation, any valid single appearance schedule gives the minimum code space cost for in-line code generation. This approximation neglects loop overhead and other second-order effects, such as the efficiency of data transfers between actors <ref> [4] </ref>. In general, a schedule of the form is called a at single appearance schedule. For the graph in figure 1, the schedule is a at single appearance schedule. 2.1 Buffering Costs The amount of memory required for buffering may vary greatly between different schedules. <p> Given a finite set , we denote the number of elements in by . Given a connected, consistent SDF graph , and a subset , we define . In <ref> [4] </ref>, we show that can be viewed as the number of times that a periodic schedule for invokes the subgraph associated with . When discussing the complexity of algorithms, we will use the standard , and notation. <p> Similarly, is if is bounded below by a positive real multiple of for sufficiently large , and is if it is both and . Also, we will use a number of facts that are proved in <ref> [4] </ref>. The first fact relates the repetitions vector of a connected SDF subgraph to that of an enclosing SDF graph. Fact 1: If is a connected, consistent SDF graph and is a connected subgraph of , then for each , . <p> Fact 1: If is a connected, consistent SDF graph and is a connected subgraph of , then for each , . The next fact is related to the factoring transformation for looped schedules that was introduced in <ref> [4] </ref>. <p> From our discussion of Fact 2, we know that non-coprime schedules or loops may result in significantly higher buffer memory requirements than their factored counterparts. It is shown in <ref> [4] </ref> that given a valid single appearance schedule, we can repeatedly apply the factoring transformation to derive from it a valid fully reduced schedule. As a consequence, we have the following fact. Fact 3: Suppose that is a consistent SDF graph and is a valid single appearance schedule for . <p> Thus, the following theorem guarantees that under our assumptions, the running time of is and . Theorem 3: The total number of iterations of the (for ) loop that are carried out in is and . Proof: This is straightforward; see <ref> [4] </ref> for the derivation. 5 Example: Sample Rate Conversion Digital audio tape (DAT) technology operates at a sampling rate of kHz, while compact disk (CD) players operate at a sampling rate of kHz. <p> For arbitrary graphs (not necessarily acyclic), necessary and sufficient conditions are given in <ref> [4] </ref> for single appearance schedules to exist, and efficient algorithms are given to find such schedules whenever they exist. <p> Furthermore, to attain the lowest buffering cost, it may be necessary to increase the extent of some strongly connected components by clustering neighboring actors together with actors in the strongly connected components before decomposing the components <ref> [4] </ref>. Hence, graphs with cycles are significantly more difficult to construct buffer-optimal single appearance schedules for than acyclic graphs. The number of topological sorts in an acyclic graph can be exponential in the size of the graph; for example, a complete bipartite graph with nodes has possible topological sorts.
Reference: [5] <author> S. S. Bhattacharyya and E. A. Lee, </author> <title> Scheduling Synchronous Dataow Graphs for Efficient Looping, </title> <journal> Journal of VLSI Signal Processing, vol.6, </journal> <volume> (no.3):271-88, </volume> <month> December, </month> <year> 1993. </year>
Reference-contexts: We also tested the heuristic against another heuristic described in detail in [8], outlined below. One of the earliest techniques for jointly optimizing both code and data requirements for SDF graphs was the PGAN (pairwise grouping of adjacent nodes) approach <ref> [5] </ref>. This approach, which was devised for general SDF graphs (not necessarily acyclic), involves constructing a cluster hierarchy by clustering two vertices at each clustering step. The cluster selection is based on frequency of occurrence the pair of adjacent actors is selected whose associated subgraph has the highest repetition count. <p> The cluster selection is based on frequency of occurrence the pair of adjacent actors is selected whose associated subgraph has the highest repetition count. In <ref> [5] </ref> it is shown that the approach naturally favors nested loops over at hierarchies, and thus reduces the buffer memory requirement over at schedules. We have evaluated the APGAN heuristic [8] (which is an efficient implementation of PGAN for acyclic graphs) against RPMC and randomly generated schedules.
Reference: [6] <author> S. S. Bhattacharyya, P. K. Murthy, and E. A. Lee, </author> <title> Software Synthesis from Dataow Graphs, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Norwell Ma, </address> <year> 1996. </year>
Reference-contexts: We can also prove the following theorem about the lower bound on the buffering memory required by any valid schedule, not just a single appearance schedule. A less general version of this result was also derived independently in [2]. Theorem 1: <ref> [6] </ref> Given an SDF edge , the lower bound on the amount of memory required by any schedule on the edge is given by if , and by otherwise. <p> A more extensive experimental survey can also be found in <ref> [6] </ref>. All of the algorithms developed in this paper have been implemented in the Ptolemy environment [10]. 8.5 An Example for Acyclic Graphs 3 (instead of the customary 1/2,1/2 for the octave QMF). Rate changes in the graph are annotated wherever the number produced or consumed is different from unity.
Reference: [7] <author> S. S. Bhattacharyya, P. K. Murthy, and E. A. Lee, </author> <title> Optimal Parenthesization of Lexical Orderings for DSP Block Diagrams, </title> <booktitle> Proceedings of the 1995 IEEE Workshop on VLSI Signal Processing, </booktitle> <address> Japan, </address> <month> October, </month> <year> 1995. </year>
Reference-contexts: Incorporating the techniques of this section with more general overlaying schemes is a topic for future work. Finally, the dynamic programming algorithm can be applied to arbitrary acyclic graphs with delays; we refer the reader to <ref> [7] </ref>. 8 Acyclic SDF Graphs Consistent acyclic SDF graphs are guaranteed to have single appearance schedules since a at schedule corresponding to any topological sort is a valid single appearance schedule.
Reference: [8] <author> S. S. Bhattacharyya, P. K. Murthy, and E. A. Lee, APGAN and RPMC: </author> <title> Complimentary Heuristics for Translating DSP Block Diagrams into Software Implementations, to appear, Design Automation for Embedded Systems Journal, </title> <year> 1996. </year>
Reference-contexts: Hence, a fair comparison is to pick the better of 2 random schedules and compare it to the heuristic answer. We also tested the heuristic against another heuristic described in detail in <ref> [8] </ref>, outlined below. One of the earliest techniques for jointly optimizing both code and data requirements for SDF graphs was the PGAN (pairwise grouping of adjacent nodes) approach [5]. <p> In [5] it is shown that the approach naturally favors nested loops over at hierarchies, and thus reduces the buffer memory requirement over at schedules. We have evaluated the APGAN heuristic <ref> [8] </ref> (which is an efficient implementation of PGAN for acyclic graphs) against RPMC and randomly generated schedules. In each case, the dynamic programming extension of Section 7 was applied as a post-processing step to optimally reparenthesize the APGAN schedule. <p> It should be noted that APGAN is optimal for a class of acyclic SDF graphs that includes many practical systems; this optimality result can be found in <ref> [8] </ref>. The study in [8] and the study done here allows us to conclude that APGAN and RPMC are complimentary heuristics; RPMC performs well when the graphs have irregular topologies and irregular rate changes, while APGAN performs well on graphs with more regular structures and rate changes. <p> It should be noted that APGAN is optimal for a class of acyclic SDF graphs that includes many practical systems; this optimality result can be found in <ref> [8] </ref>. The study in [8] and the study done here allows us to conclude that APGAN and RPMC are complimentary heuristics; RPMC performs well when the graphs have irregular topologies and irregular rate changes, while APGAN performs well on graphs with more regular structures and rate changes.
Reference: [9] <author> J. T. Buck, S. Ha, E. A. Lee, and D. G. Messerschmitt, </author> <title> Multirate Signal Processing in Ptolemy, </title> <booktitle> Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Toronto, p. 1245-8 vol.2, </address> <month> April, </month> <year> 1991. </year>
Reference-contexts: Multi-stage implementation of a CD to DAT sample rate system. CD DATFIR 160 147 C A D E F DATCD (b) 1 2 2 2 2 2 7 1 3 1 2 5 1 2:1 4 3: 4 7: 5 7: 23 eral polyphase filters <ref> [9] </ref>. Here ; the optimal looped schedule given by our dynamic programming approach is ; and the associated buffer memory requirement is .
Reference: [10] <author> J. T. Buck, S. Ha, E. A. Lee, and D. G. Messerschmitt, Ptolemy: </author> <title> A Framework for Simulating and Prototyping 42 Heterogeneous Systems, </title> <journal> International Journal of Computer Simulation, </journal> <volume> Vol. 4, </volume> <month> April, </month> <year> 1994. </year>
Reference-contexts: The synchronous dataow (SDF) model has been used widely as a foundation for block-diagram programming of digital signal processing (DSP) systems (see, for example, <ref> [10, 18, 20, 22, 24, 25] </ref>). In this model, as in other forms of dataow, a program is specified by a directed graph in which the vertices, called actors, represent computations, and the edges represent FIFO queues that store data values, called tokens, as they pass between computations. <p> Rapid prototyping environments such as those described in <ref> [10] </ref>, [18], [24], and [23] support code-generation for programmable digital signal processors (PDSP) used in embedded systems. Traditionally, PDSPs have been programmed manually, in assembly language, and this is a A B C D 3 tedious, error-prone process at best. Hence, generating code automatically is a desirable goal. <p> A more extensive experimental survey can also be found in [6]. All of the algorithms developed in this paper have been implemented in the Ptolemy environment <ref> [10] </ref>. 8.5 An Example for Acyclic Graphs 3 (instead of the customary 1/2,1/2 for the octave QMF). Rate changes in the graph are annotated wherever the number produced or consumed is different from unity.
Reference: [11] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest, </author> <title> Introduction to Algorithms, </title> <publisher> McGraw-Hill, </publisher> <year> 1990. </year>
Reference-contexts: k=( )( ) k 1= e k e n k ( ) n 1 e 1 1= n e n n 2n 2 = n 1 2 3 , , ,= 16 where , and it can be shown that the expression on the right hand side of (2) is <ref> [11] </ref>. For example, the chain-structured SDF graph in Figure 1 consists of four actors, so (2) indicates that this graph has R-schedules. The R-schedules for Figure 1 are , , ; and the corresponding buffer memory requirements are, respectively, , , , , and . <p> A familiar example of an optimal parenthesization problem is matrix chain multiplication <ref> [11, 13] </ref>. In matrix chain multiplication, we must compute the matrix product , assuming that the dimensions of the matrices are compatible with one another for the specified multiplication. There are several ways in which the product can be computed. <p> Kernighan and Lin [16] devised a heuristic procedure for computing cuts into bounded sets but they considered only undirected graphs. Methods based on network ows <ref> [11] </ref> do not work because the minimum cut given by the max-ow-min-cut theorem may not be legal and may not be bounded.
Reference: [12] <author> M. R. Garey, D. S. Johnson, </author> <title> Computers and Intractability-A guide to the theory of NP-completeness, </title> <publisher> Freeman, </publisher> <year> 1979. </year>
Reference-contexts: Question: Is there a subset , with , such that covers every edge; that is, for every edge , at least one of is in ? Remark: For an undirected graph, if is an edge, so is . Theorem 4: VC is NP-complete <ref> [12] </ref>. Theorem 5: AHSDF MIN BUFFER is NP-complete. <p> The problem then is to find the minimum weight legal cut into bounded sets for the graph with the weights defined as in (10). Since the related problem of finding a minimum cut (not necessarily legal) into bounded sets is NP-complete <ref> [12] </ref>, and the problem of finding an acyclic partition of a graph is NP-complete [12], we believe this problem to be NP-complete as well even though we have not discovered a proof. <p> Since the related problem of finding a minimum cut (not necessarily legal) into bounded sets is NP-complete <ref> [12] </ref>, and the problem of finding an acyclic partition of a graph is NP-complete [12], we believe this problem to be NP-complete as well even though we have not discovered a proof. Kernighan and Lin [16] devised a heuristic procedure for computing cuts into bounded sets but they considered only undirected graphs.
Reference: [13] <author> S. S. Godbole, </author> <title> On Efficient Computation of Matrix Chain Products, </title> <journal> IEEE Transactions on Computers, vol.C22, </journal> <volume> (no.9):864-7, </volume> <month> September, </month> <year> 1973. </year>
Reference-contexts: In Section 4, we show that the problem of finding a valid single appearance schedule that minimizes the buffer memory requirement for a chain-structured SDF graph is similar to the problem of most efficiently multiplying a chain of matrices, for which a cubic-time dynamic programming algorithm exists <ref> [13] </ref>. We show that this dynamic programming technique can be adapted to our problem to give an algorithm with time complexity , where is the number of actors in the input chain-structured SDF graph. <p> A familiar example of an optimal parenthesization problem is matrix chain multiplication <ref> [11, 13] </ref>. In matrix chain multiplication, we must compute the matrix product , assuming that the dimensions of the matrices are compatible with one another for the specified multiplication. There are several ways in which the product can be computed.
Reference: [14] <author> R. Govindarajan, G. R. Gao, and P. Desai, </author> <title> Minimizing Memory Requirements in Rate-Optimal Schedules, </title> <booktitle> Proceedings of the International Conference on Application Specific Array Processors, p. </booktitle> <pages> 75-86, </pages> <address> San Francisco, </address> <month> August, </month> <year> 1994. </year>
Reference-contexts: A linear programming framework for minimizing the memory requirement of a synchronous dataow graph in a parallel processing context is explored by Govindarajan and Gao in <ref> [14] </ref>. Here the goal is to minimize the buffer cost without sacrificing throughput just as the goal in this paper is to minimize buffering cost without sacrificing code compactness. Thus, the techniques of [14] address the problem of selecting a schedule that minimizes buffering cost from among the set of rate-optimal <p> of a synchronous dataow graph in a parallel processing context is explored by Govindarajan and Gao in <ref> [14] </ref>. Here the goal is to minimize the buffer cost without sacrificing throughput just as the goal in this paper is to minimize buffering cost without sacrificing code compactness. Thus, the techniques of [14] address the problem of selecting a schedule that minimizes buffering cost from among the set of rate-optimal schedules. This problem does not take code space constraints into account.
Reference: [15] <author> W. H. Ho, E. A. Lee, and D. G. Messerschmitt, </author> <title> High Level Dataow Programming for Digital Signal Processing, VLSI Signal Processing III, </title> <publisher> IEEE Press, </publisher> <year> 1988. </year>
Reference-contexts: In the model of buffering implied by our buffer memory requirement measure, each buffer is mapped to a contiguous and independent block of memory. This model is convenient and natural for code generation, and it is the model used, for example, in the SDF-based code generation environments described in <ref> [15, 23, 24] </ref>. However, perfectly valid target programs can be generated without these restrictions.
Reference: [16] <author> B. W. Kernighan and S. Lin, </author> <title> An Efficient Heuristic Procedure for Partitioning Graphs, </title> <journal> Bell System Technical Journal, vol.49, </journal> <volume> (no.2):291-308, </volume> <month> February </month> <year> 1970. </year>
Reference-contexts: Kernighan and Lin <ref> [16] </ref> devised a heuristic procedure for computing cuts into bounded sets but they considered only undirected graphs. Methods based on network ows [11] do not work because the minimum cut given by the max-ow-min-cut theorem may not be legal and may not be bounded. <p> Consider the set of independent, boundary nodes of in . A boundary node in is a node that is not the predecessor of any other node in . Following Kernighan and Lin <ref> [16] </ref>, for each of these s t B D 1 10 10 1 Minimum cut theorem is not equal to the min-legal cut for this graph. t 3 sBCt sADt sBDt V L s B C, , -= V R A D t, , -= 1 1 1+ + 3= A
Reference: [17] <author> R. Lauwereins, P. Wauters, M. Ade, and J. A. Peperstraete, </author> <title> Geometric Parallelism and Cyclo-Static Dataow in GRAPE-II, presented at IEEE Workshop on Rapid System Prototyping, </title> <address> Grenoble, </address> <month> June, </month> <year> 1994. </year>
Reference-contexts: The APGAN heuristic found a schedule of cost 117. This example clearly shows that, in practice, the performance of the new heuristic is likely to be better than that suggested by its performance on random graphs. 9 Related Work In <ref> [17] </ref>, Lauwereins, Wauters, Ade, and Peperstraete present a generalization of SDF, called cyclo-static dataow. In cyclo-static dataow, the number of tokens produced and consumed by an actor can vary between firings as long as the variations form a certain type of periodic pattern.
Reference: [18] <author> R. Lauwereins, M. Engels, J. A. Peperstraete, E. Steegmans, and J. Van Ginderdeuren, </author> <title> GRAPE: A CASE Tool for Digital Signal Parallel Processing, </title> <journal> IEEE ASSP Magazine, vol.7, </journal> <volume> (no.2):32-43, </volume> <month> April, </month> <year> 1990. </year>
Reference-contexts: The synchronous dataow (SDF) model has been used widely as a foundation for block-diagram programming of digital signal processing (DSP) systems (see, for example, <ref> [10, 18, 20, 22, 24, 25] </ref>). In this model, as in other forms of dataow, a program is specified by a directed graph in which the vertices, called actors, represent computations, and the edges represent FIFO queues that store data values, called tokens, as they pass between computations. <p> Rapid prototyping environments such as those described in [10], <ref> [18] </ref>, [24], and [23] support code-generation for programmable digital signal processors (PDSP) used in embedded systems. Traditionally, PDSPs have been programmed manually, in assembly language, and this is a A B C D 3 tedious, error-prone process at best. Hence, generating code automatically is a desirable goal.
Reference: [19] <author> E. A. Lee, T. M. Parks, </author> <title> Dataow Process Networks, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> Vol. 83, No. 5, </volume> <month> May, </month> <year> 1995. </year>
Reference-contexts: In addition, many models of computation (MoC) that have strong formal properties can be used as the underlying model on which the block diagram language is built; these MoCs include, for example, dataow, Petri Nets, and Kahn Process Networks <ref> [19] </ref>. These formal properties may include determinacy, guarantees on bounded memory execution policies, compile-time detection of deadlock, and static (i.e, compile-time) schedulability (thus obviating dynamic sequencing and the associated overheads).
Reference: [20] <author> E. A. Lee, W. H. Ho, E. Goei, J. Bier, and S. S. Bhattacharyya, Gabriel: </author> <title> A Design Environment for DSP, </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, vol.37, </journal> <volume> (no.11):1751-62, </volume> <month> November, </month> <year> 1989. </year>
Reference-contexts: The synchronous dataow (SDF) model has been used widely as a foundation for block-diagram programming of digital signal processing (DSP) systems (see, for example, <ref> [10, 18, 20, 22, 24, 25] </ref>). In this model, as in other forms of dataow, a program is specified by a directed graph in which the vertices, called actors, represent computations, and the edges represent FIFO queues that store data values, called tokens, as they pass between computations.
Reference: [21] <author> E. A. Lee and D. G. Messerschmitt, </author> <title> Static Scheduling of Synchronous Dataow Programs for Digital Signal Processing, </title> <journal> IEEE Transactions on Computers, vol.C-36, </journal> <volume> (no.1):24-35, </volume> <month> January, </month> <year> 1987. </year>
Reference-contexts: SDF graphs for which valid schedules exist are called consistent graphs. Systematic techniques exist to efficiently determine whether or not a given SDF graph is consistent <ref> [21] </ref>. Also, given a consistent SDF graph, the minimum number of times that each actor must execute in the body of a valid schedule can be computed efficiently [21]. <p> Systematic techniques exist to efficiently determine whether or not a given SDF graph is consistent <ref> [21] </ref>. Also, given a consistent SDF graph, the minimum number of times that each actor must execute in the body of a valid schedule can be computed efficiently [21]. We represent these minimum numbers of firings by a vector , indexed by the actors in , and we refer to as the repetitions vec tor of (we often suppress the subscript if is understood from context).
Reference: [22] <author> D. R. OHallaron, </author> <title> The Assign Parallel Program Generator, </title> <institution> Memorandum CMU-CS-91-141, School of Computer Science, Carnegie Mellon University, </institution> <month> May, </month> <year> 1991. </year>
Reference-contexts: The synchronous dataow (SDF) model has been used widely as a foundation for block-diagram programming of digital signal processing (DSP) systems (see, for example, <ref> [10, 18, 20, 22, 24, 25] </ref>). In this model, as in other forms of dataow, a program is specified by a directed graph in which the vertices, called actors, represent computations, and the edges represent FIFO queues that store data values, called tokens, as they pass between computations.
Reference: [23] <author> J. Pino, S. Ha, E. A. Lee, and J. T. Buck, </author> <title> Software Synthesis for DSP Using Ptolemy, invited paper in Journal of VLSI Signal Processing, </title> <month> January, </month> <year> 1995. </year>
Reference-contexts: Rapid prototyping environments such as those described in [10], [18], [24], and <ref> [23] </ref> support code-generation for programmable digital signal processors (PDSP) used in embedded systems. Traditionally, PDSPs have been programmed manually, in assembly language, and this is a A B C D 3 tedious, error-prone process at best. Hence, generating code automatically is a desirable goal. <p> In the model of buffering implied by our buffer memory requirement measure, each buffer is mapped to a contiguous and independent block of memory. This model is convenient and natural for code generation, and it is the model used, for example, in the SDF-based code generation environments described in <ref> [15, 23, 24] </ref>. However, perfectly valid target programs can be generated without these restrictions.
Reference: [24] <author> S. Ritz, S. Pankert, H. Meyr, </author> <title> High Level Software Synthesis for Signal Processing Systems, </title> <booktitle> Proceedings of the International Conference on Application Specific Array Processors, </booktitle> <address> Berkeley, p. 679-93, </address> <month> August, </month> <year> 1992. </year>
Reference-contexts: The synchronous dataow (SDF) model has been used widely as a foundation for block-diagram programming of digital signal processing (DSP) systems (see, for example, <ref> [10, 18, 20, 22, 24, 25] </ref>). In this model, as in other forms of dataow, a program is specified by a directed graph in which the vertices, called actors, represent computations, and the edges represent FIFO queues that store data values, called tokens, as they pass between computations. <p> Rapid prototyping environments such as those described in [10], [18], <ref> [24] </ref>, and [23] support code-generation for programmable digital signal processors (PDSP) used in embedded systems. Traditionally, PDSPs have been programmed manually, in assembly language, and this is a A B C D 3 tedious, error-prone process at best. Hence, generating code automatically is a desirable goal. <p> In the model of buffering implied by our buffer memory requirement measure, each buffer is mapped to a contiguous and independent block of memory. This model is convenient and natural for code generation, and it is the model used, for example, in the SDF-based code generation environments described in <ref> [15, 23, 24] </ref>. However, perfectly valid target programs can be generated without these restrictions.
Reference: [25] <author> M. Veiga, J. Parera, and J. Santos, </author> <title> Programming DSP Systems on Multiprocessor Architectures, </title> <booktitle> Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Albuquerque, p. 965-8 vol.2, </address> <month> April, </month> <year> 1990. </year>
Reference-contexts: The synchronous dataow (SDF) model has been used widely as a foundation for block-diagram programming of digital signal processing (DSP) systems (see, for example, <ref> [10, 18, 20, 22, 24, 25] </ref>). In this model, as in other forms of dataow, a program is specified by a directed graph in which the vertices, called actors, represent computations, and the edges represent FIFO queues that store data values, called tokens, as they pass between computations.
Reference: [26] <author> M. Wolfe, </author> <title> Optimizing Supercompilers for Supercomputers, </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: Then (a). is a valid schedule for ; and (b). . The factoring transformation is closely related to the loop fusion transformation, which has been used for decades in compilers for procedural languages to reduce memory requirements and increase data locality <ref> [1, 26] </ref>. In compilers for procedural languages, tests for the validity of loop fusion include analysis of array subscripts to determine whether or not for each iteration of the (lexically) second loop, this iteration depends only on iterations of the first loop [27].
Reference: [27] <author> H. Zima and B. Chapman, </author> <title> Supercompilers for Parallel and Vector Computers, </title> <publisher> ACM Press, </publisher> <year> 1990. </year>
Reference-contexts: In compilers for procedural languages, tests for the validity of loop fusion include analysis of array subscripts to determine whether or not for each iteration of the (lexically) second loop, this iteration depends only on iterations of the first loop <ref> [27] </ref>. These tests are difficult to perform comprehensively due to the complexity of exact subscript analysis [3], and due to complications such as data-dependent subscript values, conditional branches, and input/output statements.
Reference: [28] <author> V. Zivojnovic, H. Schraut, M. Willems, and R. Schoenen, </author> <title> DSPs, GPPs, and Multimedia Applications An Evaluation Using DSPStone, </title> <booktitle> Proceedings of ICSPAT, </booktitle> <month> November, </month> <year> 1995. </year>
Reference-contexts: One approach to automatic code generation is to specify the program in an imperative language such as C, C++, or FORTRAN and use a good compiler. However, even the best compilers today produce inefficient code <ref> [28] </ref>. In addition, specifications in imperative languages are difficult to parallelize, are difficult to change due to side effects, and offer few chances for any formal verification of program properties.
References-found: 28

