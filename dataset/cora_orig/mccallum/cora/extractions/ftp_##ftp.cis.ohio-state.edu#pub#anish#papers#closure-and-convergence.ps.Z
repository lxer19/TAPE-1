URL: ftp://ftp.cis.ohio-state.edu/pub/anish/papers/closure-and-convergence.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~anish/pub.html
Root-URL: 
Email: anish@cis.ohio-state.edu gouda@cs.utexas.edu  
Phone: 614-292-1836, Fax: 614-292-2911 512-471-9532, Fax: 512-471-8885  
Title: Closure and Convergence: A Foundation of Fault-Tolerant Computing  
Author: Anish ARORA Mohamed GOUDA 
Keyword: Fault-tolerance, Reliability, Algorithms, Verification, Design. Additional Keywords: Masking, Stabilizing, Closure, Convergence.  
Address: 2036 Neil Avenue Mall, OH 43210 2.128 Taylor Hall, TX 78712  
Affiliation: Department of Computer Science Department of Computer Sciences The Ohio State Univ. at Columbus The Univ. of Texas at Austin  
Abstract: We give a formal definition of what it means for a system to "tolerate" a class of "faults". The definition consists of two conditions: One, if a fault occurs when the system state is within a set of "legal" states, the resulting state is within some larger set and, if faults continue occurring, the system state remains within that larger set (Closure). And two, if faults stop occurring, the system eventually reaches a state within the legal set (Convergence). We demonstrate the applicability of our definition for specifying and verifying the fault-tolerance properties of a variety of digital and computer systems. Further, using the definition, we obtain a simple classification of fault-tolerant systems and discuss methods for their systematic design. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Anderson and P. Lee, </author> <title> "Fault tolerance terminology proposals", </title> <booktitle> Proceedings of FTCS-12, </booktitle> <pages> pp. 29-33, </pages> <year> 1982. </year>
Reference-contexts: One is based on a distinction between the notions of faults, errors, and failures: faults in a physical domain can cause errors in an information domain, whereas errors in an information domain can cause failures in an external domain <ref> [1, 6, 27] </ref>. (Unfortunately, these notions are subjective: "what one person calls a failure, a second person calls a fault, and a third person might call an error" [13].) The other is based on what type of fault is tolerated, for example, stuck-at, crash, fail-stop, omission, timing, or byzantine faults [19,
Reference: [2] <author> A. Arora, </author> <title> "A foundation of fault-tolerant computing", </title> <type> Ph.D. Dissertation, </type> <institution> The University of Texas at Austin, </institution> <year> 1992. </year>
Reference-contexts: A detailed report of these applications appears in <ref> [2] </ref>. We proceed as follows. In Section 2, we give a formal definition of what it means for a program to be fault-tolerant and present a formal classification of fault-tolerant programs. <p> The first example deals with faults whose effect is of a permanent nature; the second deals with faults whose effect is of a transient nature; and the third deals with faults whose effect is of an intermittent nature. We have presented several other examples in <ref> [2] </ref> and [3]. 3.1 Example: Atomic Commitment Protocol Specification [8] Each process casts one of two votes, Yes or No, then reaches one of two decisions, Commit or Abort, such that: 1. If no faults occur and all processes vote Yes, all processes reach a Commit decision. 2. <p> It can be shown that each computation of program Two-phase that starts at a state where S holds satisfies the atomic commitment specification. (Details appear in <ref> [2] </ref>.) Proof To show that program Two-phase is F -tolerant for S, we are required to exhibit a state predicate T that satisfies the three conditions in Definition 3. In this case, we let T to be S itself. <p> It is straightforward to show that each computation of program Sliding-window that starts at a state where S holds satisfies the data transfer specification. (Details appear in <ref> [2] </ref>.) Proof To show that program Sliding-window is F -tolerant for S, we are required to exhibit a state predicate T that satisfies the three conditions in Definition 3. <p> It is straightforward to show each computation of program Byzantine that starts at a state where S holds satisfies the byzantine agreement specification. (Details appear in <ref> [2] </ref>.) Proof To show that program Byzantine is F -tolerant for S, we are required to exhibit a state predicate T that satisfies the three conditions in Definition 3. In this case, we let T to be S itself.
Reference: [3] <author> A. Arora and M. Gouda, </author> <title> "Closure and convergence: A formulation of fault-tolerant computing", </title> <booktitle> preliminary version in Proceedings of the 22nd International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pp. 396-403, </pages> <year> 1992. </year>
Reference-contexts: The first example deals with faults whose effect is of a permanent nature; the second deals with faults whose effect is of a transient nature; and the third deals with faults whose effect is of an intermittent nature. We have presented several other examples in [2] and <ref> [3] </ref>. 3.1 Example: Atomic Commitment Protocol Specification [8] Each process casts one of two votes, Yes or No, then reaches one of two decisions, Commit or Abort, such that: 1. If no faults occur and all processes vote Yes, all processes reach a Commit decision. 2.
Reference: [4] <author> A. Arora and M. Gouda, </author> <title> "Distributed reset", </title> <booktitle> revised for IEEE Transactions on Computers ; extended abstract in Proceedings of the 10th Conference on Foundations of Software Technology and Theoretical Computer Science, Lecture Notes in Computer Science 472, </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pp. 316-331, </pages> <year> 1990. </year>
Reference-contexts: Even so, self-stabilizing systems are mainly being designed to tolerate arbi-trary transient faults, whereas they can be designed to tolerate a variety of fault types <ref> [4, 24, 40, 41] </ref>. <p> node j is one way of establishing R:j; hence, this action can be combined with the convergence action to yield the action :R:j _ c:j = green ^ c:(P:j) = red ^ sn:j 6 sn:(P:j) ! c:j ; sn:j := c:(P:j) ; sn:(P:j) Hence, our design yields the following program <ref> [4] </ref>. 30 program Diffusing-computation process j : 1::N ; var c:j : fgreen; redg ; sn:j : boolean ; begin c:j = green^P:j = j ! c:j ; sn:j := red ; :sn:j [] c:j = green ^ c:(P:j) = red ^ sn:j 6 sn:(P:j) ! c:j ; sn:j := c:(P:j)
Reference: [5] <author> A. Arora, M. Gouda, and G. Varghese, </author> <title> "Distributed constraint satisfaction", </title> <note> submitted for publication. </note>
Reference-contexts: Finally, design closure actions that preserve each of the constraints in S. The net result is that each computation of the closure and convergence actions eventually reaches a state where S holds. For more details on this approach, we refer the reader to <ref> [5] </ref>. 28 6.1 Example: Diffusing Computations Consider a finite, rooted tree. It is required to design a stabilizing program in which, starting from a state where all tree nodes are colored green, the root node initiates a diffusing computation.
Reference: [6] <author> A. Avizienis, </author> <title> "The four-universe information system model for the study of fault tolerance", </title> <booktitle> Proceedings of 12th International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pp. 6-13, </pages> <year> 1982. </year>
Reference-contexts: One is based on a distinction between the notions of faults, errors, and failures: faults in a physical domain can cause errors in an information domain, whereas errors in an information domain can cause failures in an external domain <ref> [1, 6, 27] </ref>. (Unfortunately, these notions are subjective: "what one person calls a failure, a second person calls a fault, and a third person might call an error" [13].) The other is based on what type of fault is tolerated, for example, stuck-at, crash, fail-stop, omission, timing, or byzantine faults [19,
Reference: [7] <author> F. Bastani, I.-L. Yen, and I. Chen, </author> <title> "A class of inherently fault-tolerant distributed programs", </title> <journal> IEEE Transactions on Software Engg., </journal> <volume> 14(10), </volume> <pages> pp. 1431-1442, </pages> <year> 1988. </year>
Reference-contexts: While self-stabilization was first studied in computing science in 1973 [15], and its application to fault-tolerance was strongly endorsed in 1983 [25], it is only in the last few years that concerted efforts have been made to relate self-stabilization to fault-tolerance 1 <ref> [7, 9, 11] </ref>. Even so, self-stabilizing systems are mainly being designed to tolerate arbi-trary transient faults, whereas they can be designed to tolerate a variety of fault types [4, 24, 40, 41].
Reference: [8] <author> P. Bernstein, V. Hadzilacos, and N. Goodman, </author> <title> Concurrency Control and Recovery in Database Systems, Chapter 7, </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: We have presented several other examples in [2] and [3]. 3.1 Example: Atomic Commitment Protocol Specification <ref> [8] </ref> Each process casts one of two votes, Yes or No, then reaches one of two decisions, Commit or Abort, such that: 1. If no faults occur and all processes vote Yes, all processes reach a Commit decision. 2.
Reference: [9] <author> G. Brown, and Y. Afek, </author> <title> "Self-stabilization of the Alternating-Bit protocol", </title> <booktitle> Proceedings of the 8th Symposium on Reliable Distributed Systems, </booktitle> <pages> pp. 80-83, </pages> <year> 1989. </year>
Reference-contexts: While self-stabilization was first studied in computing science in 1973 [15], and its application to fault-tolerance was strongly endorsed in 1983 [25], it is only in the last few years that concerted efforts have been made to relate self-stabilization to fault-tolerance 1 <ref> [7, 9, 11] </ref>. Even so, self-stabilizing systems are mainly being designed to tolerate arbi-trary transient faults, whereas they can be designed to tolerate a variety of fault types [4, 24, 40, 41].
Reference: [10] <author> M. Breuer and A. Friedman, </author> <title> Diagnosis and Reliable Design of Digital Systems, </title> <publisher> Computer Science Press, </publisher> <year> 1976. </year>
Reference-contexts: One consequence of this tradition is that several subdisciplines of fault-tolerant computing have emerged that are apparently unrelated to each other. These subdisciplines deal with specific classes of faults, employ distinct models and design methods, and have their own terminology and classification <ref> [10, 26, 39] </ref>. As a result, the discipline itself appears to be fragmented. Another consequence of this tradition is that verification of fault-tolerant systems is often based on implementation-specific artifacts|such as stable storage, timeouts, and shadow registers|without explicitly specifying what properties of these artifacts are necessary.
Reference: [11] <author> J. Burns and J. Pachl, </author> <title> "Uniform stabilizing rings," </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(2), </volume> <pages> pp. 330-344, </pages> <year> 1989. </year>
Reference-contexts: While self-stabilization was first studied in computing science in 1973 [15], and its application to fault-tolerance was strongly endorsed in 1983 [25], it is only in the last few years that concerted efforts have been made to relate self-stabilization to fault-tolerance 1 <ref> [7, 9, 11] </ref>. Even so, self-stabilizing systems are mainly being designed to tolerate arbi-trary transient faults, whereas they can be designed to tolerate a variety of fault types [4, 24, 40, 41].
Reference: [12] <author> K. Chandy and J. Misra, </author> <title> Parallel Program Design: A Foundation, </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: One process g is distinguished, and has associated with it a boolean value B. It is required that: 1. If g is Reliable, the decision value of each Reliable process is B. 2. All Reliable processes eventually reach the same decision. Faults may make Reliable processes Unreliable. Program <ref> [12, 37] </ref> We assume authenticated communication: messages sent by Reliable processes are correctly received by Reliable processes, and Unreliable processes cannot forge messages on behalf of Reliable processes. Agreement is reached within N +1 rounds of communication, where N is the maximum number of processes that can be Unreliable.
Reference: [13] <author> F. Cristian, </author> <title> "Understanding fault-tolerant distributed systems", </title> <journal> Communications of the ACM, </journal> <volume> 34(2), </volume> <pages> pp. 56-78, </pages> <year> 1991. </year>
Reference-contexts: physical domain can cause errors in an information domain, whereas errors in an information domain can cause failures in an external domain [1, 6, 27]. (Unfortunately, these notions are subjective: "what one person calls a failure, a second person calls a fault, and a third person might call an error" <ref> [13] </ref>.) The other is based on what type of fault is tolerated, for example, stuck-at, crash, fail-stop, omission, timing, or byzantine faults [19, 30, 32, 36]. A few efforts have also been made to formally define and verify system fault-tolerance [14, 29, 30, 32], albeit with limited scope.
Reference: [14] <author> F. Cristian, </author> <title> "A rigorous approach to fault-tolerant programming", </title> <journal> IEEE Transactions on Software Engg., </journal> <volume> 11(1), </volume> <year> 1985. </year>
Reference-contexts: A few efforts have also been made to formally define and verify system fault-tolerance <ref> [14, 29, 30, 32] </ref>, albeit with limited scope. More specifically, these efforts have considered systems that recover from the occurrence of faults and terminate properly. In other words, they have considered systems whose input-output relation masks faults. <p> Following this method, we require that for each fault-tolerant system there exists a predicate S that is invariant throughout fault-free system execution. Next, we observe that faults|be they stuck-at, crash, fail-stop, omission, timing, or byzantine|can be systematically represented as actions that upon execution perturb the system state <ref> [14] </ref>. In other words, even when the effect of a fault is not transient, but is permanent or intermittent, the fault can be represented as an action. For example, consider a wire that can be permanently stuck at low voltage. Such a wire can be represented by the following program.
Reference: [15] <author> E. Dijkstra, </author> <title> "Self-stabilizing systems in spite of distributed control", </title> <journal> Communications of the ACM, </journal> <volume> 17(11), </volume> <year> 1974. </year>
Reference-contexts: One form of fault-tolerance that does not always mask faults is self-stabilization [33]. While self-stabilization was first studied in computing science in 1973 <ref> [15] </ref>, and its application to fault-tolerance was strongly endorsed in 1983 [25], it is only in the last few years that concerted efforts have been made to relate self-stabilization to fault-tolerance 1 [7, 9, 11].
Reference: [16] <author> E. Dijkstra, </author> <title> A Discipline of Programming, </title> <publisher> Prentice-Hall, </publisher> <year> 1976. </year>
Reference-contexts: Our definition consists of two conditions: one of closure and another of convergence. To motivate the closure condition, let us observe that a well-established method for verifying fault-free systems is to exhibit a predicate that is true throughout system execution <ref> [16, 22] </ref>. Such an "invariant" predicate identifies the "legal" system states and asserts that the set of legal states is closed under system execution. Following this method, we require that for each fault-tolerant system there exists a predicate S that is invariant throughout fault-free system execution.
Reference: [17] <author> E. Dijkstra, </author> <title> "Solution of a problem in concurrent programming control", </title> <journal> Communications of the ACM, </journal> <volume> 17(11), </volume> <pages> pp. 569, </pages> <year> 1965. </year> <month> 34 </month>
Reference-contexts: Proof: Let p be an arbitrary read-write program for mutual exclusion, and let S be the intended domain of execution of p. That is, S is a closed state predicate of p such that all computations of p starting in S satisfy the following two properties <ref> [17] </ref>. * Safety : at most one process is "privileged" at each state in the computation, and 26 * Deadlock-Freedom : if the computation starts at a state where some process has requested the privilege, then there exists a subsequent state in the computation where some process that previously requested the
Reference: [18] <author> E. Dijkstra and C. Scholten, </author> <title> Predicate Calculus and Program Semantics, </title> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: ! st in F : (8T : T ) ) wp:(B ! st):(8T : T )) = f wp:(B ! st) is universally conjunctive if st always terminates g (8 B ! st in F : (8T : T ) ) (8T : wp:(B ! st):T )) ( f Leibniz <ref> [18] </ref> g 6 (8 B ! st in F : (8T : T ) wp:(B ! st):T )) = f T is closed in F , for all T g true T s converges to S in p since: (i) S is closed in p, (ii) T s is closed in <p> T ) = f there is at least one such T , predicate calculus g (9T : S ) T ) true (8 B ! st in F : executing st in a state where B ^ T w holds preserves T w ) = f definition of weakest preconditions <ref> [18] </ref> g (8 B ! st in F : T w ) wp:(B ! st):T w) ( f T ) T w for all T , wp:(B ! st) is monotonic [18], predicate calculus g (8 B ! st in F : T w ) (9T : wp:(B ! st):T )) <p> in a state where B ^ T w holds preserves T w ) = f definition of weakest preconditions <ref> [18] </ref> g (8 B ! st in F : T w ) wp:(B ! st):T w) ( f T ) T w for all T , wp:(B ! st) is monotonic [18], predicate calculus g (8 B ! st in F : T w ) (9T : wp:(B ! st):T )) = f definition of T w g (8 B ! st in F : (9T : T ) ) (9T : wp:(B ! st):T )) = f predicate calculus g (8
Reference: [19] <author> P. Ezhilchelvan and S. Shrivastava, </author> <title> "A characterization of faults in systems", </title> <booktitle> Proceedings of the 5th Symposium on Reliability in Distributed Software and Database Systems, </booktitle> <year> 1986. </year>
Reference-contexts: [1, 6, 27]. (Unfortunately, these notions are subjective: "what one person calls a failure, a second person calls a fault, and a third person might call an error" [13].) The other is based on what type of fault is tolerated, for example, stuck-at, crash, fail-stop, omission, timing, or byzantine faults <ref> [19, 30, 32, 36] </ref>. A few efforts have also been made to formally define and verify system fault-tolerance [14, 29, 30, 32], albeit with limited scope. More specifically, these efforts have considered systems that recover from the occurrence of faults and terminate properly.
Reference: [20] <author> M. Fischer, N. Lynch, and M. Paterson, </author> <title> "Impossibility of distributed consensus with one faulty process", </title> <journal> Journal of the ACM, </journal> <volume> 32(2), </volume> <pages> pp. 374-382, </pages> <year> 1985. </year>
Reference-contexts: in F , and * a computation of every program satisfying SP that starts at c and has no suffix satisfying SP. 25 Several results in the literature on impossibility of fault-tolerance [28] can be proven using this method, including the well-known impossibility of distributed consensus with one faulty process <ref> [20] </ref>. Some of these impossibility results involve special kinds of fault-tolerance such as masking or global stabilizing fault-tolerance. Observe that for proving impossibility of masking fault-tolerance, it suffices to exhibit the states b and c, and to show that c does not satisfy SP .
Reference: [21] <author> M. Gouda, and N. Multari, </author> <title> "Stabilizing communication protocols," </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40(4), </volume> <pages> pp. 448-458, </pages> <year> 1991. </year>
Reference: [22] <editor> D. Gries, </editor> <booktitle> The Science of Programming, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1981. </year>
Reference-contexts: Our definition consists of two conditions: one of closure and another of convergence. To motivate the closure condition, let us observe that a well-established method for verifying fault-free systems is to exhibit a predicate that is true throughout system execution <ref> [16, 22] </ref>. Such an "invariant" predicate identifies the "legal" system states and asserts that the set of legal states is closed under system execution. Following this method, we require that for each fault-tolerant system there exists a predicate S that is invariant throughout fault-free system execution.
Reference: [23] <author> B. Johnson, </author> <title> The Design and Analysis of Fault-Tolerant Digital Systems, </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference: [24] <author> S. Katz and K. Perry, </author> <title> "Self-stabilizing extensions for message-passing systems", </title> <booktitle> Proceedings of the 9th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 91-101, </pages> <year> 1990. </year>
Reference-contexts: Even so, self-stabilizing systems are mainly being designed to tolerate arbi-trary transient faults, whereas they can be designed to tolerate a variety of fault types <ref> [4, 24, 40, 41] </ref>.
Reference: [25] <author> L. Lamport, </author> <title> "Solved problems, unsolved problems and non-problems in concurrency", invited talk, </title> <booktitle> Proceedings of the 3rd Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 1-11, </pages> <year> 1984. </year>
Reference-contexts: One form of fault-tolerance that does not always mask faults is self-stabilization [33]. While self-stabilization was first studied in computing science in 1973 [15], and its application to fault-tolerance was strongly endorsed in 1983 <ref> [25] </ref>, it is only in the last few years that concerted efforts have been made to relate self-stabilization to fault-tolerance 1 [7, 9, 11].
Reference: [26] <author> B. Lampson and H. Sturgis, </author> <title> "Crash recovery in a distributed storage system", </title> <type> Xerox Park Tech. Report, </type> <institution> Xerox Palo Alto Research Center, </institution> <year> 1979. </year>
Reference-contexts: One consequence of this tradition is that several subdisciplines of fault-tolerant computing have emerged that are apparently unrelated to each other. These subdisciplines deal with specific classes of faults, employ distinct models and design methods, and have their own terminology and classification <ref> [10, 26, 39] </ref>. As a result, the discipline itself appears to be fragmented. Another consequence of this tradition is that verification of fault-tolerant systems is often based on implementation-specific artifacts|such as stable storage, timeouts, and shadow registers|without explicitly specifying what properties of these artifacts are necessary.
Reference: [27] <author> J.-C. Laprie, </author> <title> "Dependable computing and fault tolerance: Concepts and terminology", </title> <booktitle> Proceedings of the 15th International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pp. 2-11, </pages> <year> 1985. </year>
Reference-contexts: One is based on a distinction between the notions of faults, errors, and failures: faults in a physical domain can cause errors in an information domain, whereas errors in an information domain can cause failures in an external domain <ref> [1, 6, 27] </ref>. (Unfortunately, these notions are subjective: "what one person calls a failure, a second person calls a fault, and a third person might call an error" [13].) The other is based on what type of fault is tolerated, for example, stuck-at, crash, fail-stop, omission, timing, or byzantine faults [19,
Reference: [28] <author> N. Lynch, </author> <title> "A hundred impossibility proofs for distributed computing" invited talk, </title> <booktitle> Proceedings of the 8th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 1-29, </pages> <year> 1989. </year>
Reference-contexts: execution of all programs satisfying SP, * a state c that is reachable from b by executing actions in F , and * a computation of every program satisfying SP that starts at c and has no suffix satisfying SP. 25 Several results in the literature on impossibility of fault-tolerance <ref> [28] </ref> can be proven using this method, including the well-known impossibility of distributed consensus with one faulty process [20]. Some of these impossibility results involve special kinds of fault-tolerance such as masking or global stabilizing fault-tolerance.
Reference: [29] <author> A. Mili, </author> <title> An Introduction to Program Fault-Tolerance, </title> <publisher> Prentice-Hall, </publisher> <year> 1990. </year>
Reference-contexts: A few efforts have also been made to formally define and verify system fault-tolerance <ref> [14, 29, 30, 32] </ref>, albeit with limited scope. More specifically, these efforts have considered systems that recover from the occurrence of faults and terminate properly. In other words, they have considered systems whose input-output relation masks faults.
Reference: [30] <author> C. Mohan, R. Strong, and S. Finkelstein, </author> <title> "Methods for distributed transaction commit and recovery using byzantine agreement within clusters of processes", </title> <booktitle> Proceedings of the 2nd ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 29-43, </pages> <year> 1983. </year>
Reference-contexts: [1, 6, 27]. (Unfortunately, these notions are subjective: "what one person calls a failure, a second person calls a fault, and a third person might call an error" [13].) The other is based on what type of fault is tolerated, for example, stuck-at, crash, fail-stop, omission, timing, or byzantine faults <ref> [19, 30, 32, 36] </ref>. A few efforts have also been made to formally define and verify system fault-tolerance [14, 29, 30, 32], albeit with limited scope. More specifically, these efforts have considered systems that recover from the occurrence of faults and terminate properly. <p> A few efforts have also been made to formally define and verify system fault-tolerance <ref> [14, 29, 30, 32] </ref>, albeit with limited scope. More specifically, these efforts have considered systems that recover from the occurrence of faults and terminate properly. In other words, they have considered systems whose input-output relation masks faults.
Reference: [31] <author> J. von Neumann, </author> <title> "Probabilistic logics and the synthesis of reliable organisms from unreliable components," in Automata Studies, </title> <publisher> Princeton University Press, </publisher> <pages> pp. 43-98, </pages> <year> 1956. </year>
Reference: [32] <author> R. Schlichting and F. Schneider, </author> <title> "Fail-stop processors: An approach to designing fault-tolerant computing systems", </title> <journal> ACM Transactions on Computers, </journal> <pages> pp. 222-238, </pages> <year> 1983. </year>
Reference-contexts: [1, 6, 27]. (Unfortunately, these notions are subjective: "what one person calls a failure, a second person calls a fault, and a third person might call an error" [13].) The other is based on what type of fault is tolerated, for example, stuck-at, crash, fail-stop, omission, timing, or byzantine faults <ref> [19, 30, 32, 36] </ref>. A few efforts have also been made to formally define and verify system fault-tolerance [14, 29, 30, 32], albeit with limited scope. More specifically, these efforts have considered systems that recover from the occurrence of faults and terminate properly. <p> A few efforts have also been made to formally define and verify system fault-tolerance <ref> [14, 29, 30, 32] </ref>, albeit with limited scope. More specifically, these efforts have considered systems that recover from the occurrence of faults and terminate properly. In other words, they have considered systems whose input-output relation masks faults. <p> We then exhibit an implementation of the C-element that uses a 3-input majority function and verify the well-known fact that the implementation is masking fault-tolerant for one type of timing fault but not masking fault-tolerant for another type. Specification <ref> [32] </ref> A C-element with boolean inputs x and y and a boolean output z is specified as follows: (i) Input x (respectively, y) changes only if x z (respectively, y z) holds ; (ii) Output z becomes true only if x^y holds, and becomes f alse only if :x^:y holds ;
Reference: [33] <author> M. Schneider, </author> <title> "Self-Stabilization", </title> <journal> ACM Computing Surveys, </journal> <volume> 25(1), </volume> <pages> pp. 45-67, </pages> <year> 1993. </year>
Reference-contexts: Such forms of fault-tolerance ensure the continued availability of systems by repairing faulty system parts or by correctly restoring the system state whenever the system exhibits incorrect behavior due to the occurrence of faults. One form of fault-tolerance that does not always mask faults is self-stabilization <ref> [33] </ref>. While self-stabilization was first studied in computing science in 1973 [15], and its application to fault-tolerance was strongly endorsed in 1983 [25], it is only in the last few years that concerted efforts have been made to relate self-stabilization to fault-tolerance 1 [7, 9, 11].
Reference: [34] <author> C. Seitz, </author> <title> "System timing", in Introduction to VLSI Systems, </title> <publisher> Addison-Wesley, </publisher> <year> 1980. </year>
Reference-contexts: We first verify that a delay-insensitive circuit, the Muller C-element, tolerates timing faults in the arrival of its input signals <ref> [34] </ref>. We then exhibit an implementation of the C-element that uses a 3-input majority function and verify the well-known fact that the implementation is masking fault-tolerant for one type of timing fault but not masking fault-tolerant for another type. <p> In particular, it is both global stabilizing and masking fault-tolerant. Implementation Consider a majority circuit with three boolean inputs x, y, and u and one boolean output v. To implement the C-element using this majority circuit, it suffices to connect v to z and feedback v to u <ref> [34] </ref>.
Reference: [35] <author> D. Siewiorek, </author> <title> "Architecture of fault-tolerant computers", in Fault-Tolerant Computing: Volume II, </title> <publisher> Prentice-Hall, </publisher> <year> 1986. </year>
Reference: [36] <author> D. Skeen and M. Stonebraker, </author> <title> "A formal model of crash recovery in a distributed system", </title> <journal> IEEE Transactions on Software Engg., </journal> <pages> pp. 219-228, </pages> <year> 1983. </year> <month> 35 </month>
Reference-contexts: [1, 6, 27]. (Unfortunately, these notions are subjective: "what one person calls a failure, a second person calls a fault, and a third person might call an error" [13].) The other is based on what type of fault is tolerated, for example, stuck-at, crash, fail-stop, omission, timing, or byzantine faults <ref> [19, 30, 32, 36] </ref>. A few efforts have also been made to formally define and verify system fault-tolerance [14, 29, 30, 32], albeit with limited scope. More specifically, these efforts have considered systems that recover from the occurrence of faults and terminate properly.
Reference: [37] <author> T. Srikanth and S. Toeug, </author> <title> "Simulating authenticated broadcast to derive simple fault toler-ant algorithms", </title> <journal> Distributed Computing, </journal> <volume> 2(2), </volume> <pages> pp. 80-94, </pages> <year> 1987. </year>
Reference-contexts: One process g is distinguished, and has associated with it a boolean value B. It is required that: 1. If g is Reliable, the decision value of each Reliable process is B. 2. All Reliable processes eventually reach the same decision. Faults may make Reliable processes Unreliable. Program <ref> [12, 37] </ref> We assume authenticated communication: messages sent by Reliable processes are correctly received by Reliable processes, and Unreliable processes cannot forge messages on behalf of Reliable processes. Agreement is reached within N +1 rounds of communication, where N is the maximum number of processes that can be Unreliable.
Reference: [38] <author> B. Randell, </author> <title> "System structure for software fault tolerance", </title> <journal> IEEE Transactions on Software Engg., </journal> <pages> pp. 220-232, </pages> <year> 1975. </year>
Reference-contexts: How can we reason about the fault-tolerance of program interfaces? A program interface specifies the program behavior that is observable by some environment. This specification consists of a set of program variables and a set of constraints on how these variables may be updated <ref> [38] </ref>. In our approach, reasoning about interfaces is simple: Associated with each interface of a program p is some state predicate R that is closed under program execution. An interface is fault-tolerant with respect to some set of fault actions F iff p is F -tolerant for R.
Reference: [39] <author> A. Tanenbaum, </author> <title> Computer Networks, </title> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: One consequence of this tradition is that several subdisciplines of fault-tolerant computing have emerged that are apparently unrelated to each other. These subdisciplines deal with specific classes of faults, employ distinct models and design methods, and have their own terminology and classification <ref> [10, 26, 39] </ref>. As a result, the discipline itself appears to be fragmented. Another consequence of this tradition is that verification of fault-tolerant systems is often based on implementation-specific artifacts|such as stable storage, timeouts, and shadow registers|without explicitly specifying what properties of these artifacts are necessary.
Reference: [40] <author> I.-L. Yen, F. Bastani, and E. Leiss, </author> <title> "An inherently fault-tolerant sorting algorithm", </title> <booktitle> Proceedings of the 5th International Parallel Processing Symposium, </booktitle> <pages> pp. 37-42, </pages> <year> 1991. </year>
Reference-contexts: Even so, self-stabilizing systems are mainly being designed to tolerate arbi-trary transient faults, whereas they can be designed to tolerate a variety of fault types <ref> [4, 24, 40, 41] </ref>.
Reference: [41] <author> Y. Zhao and F. Bastani, </author> <title> "A self-stabilizing algorithm for byzantine agreement", </title> <institution> University of Houston Tech. </institution> <type> Rep. </type> <institution> UH-CS-87-6, </institution> <year> 1987. </year> <month> 36 </month>
Reference-contexts: Even so, self-stabilizing systems are mainly being designed to tolerate arbi-trary transient faults, whereas they can be designed to tolerate a variety of fault types <ref> [4, 24, 40, 41] </ref>.
References-found: 41

