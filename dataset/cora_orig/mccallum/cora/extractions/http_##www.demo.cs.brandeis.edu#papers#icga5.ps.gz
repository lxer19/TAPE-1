URL: http://www.demo.cs.brandeis.edu/papers/icga5.ps.gz
Refering-URL: http://www.demo.cs.brandeis.edu/papers/long.html
Root-URL: http://www.cs.brandeis.edu
Email: pja@cis.ohio-state.edu pollack@cis.ohio-state.edu  
Title: Competitive Environments Evolve Better Solutions for Complex Tasks  
Author: Peter J. Angeline and Jordan B. Pollack 
Note: Appears in: Genetic Algorithms: Proceedings of the Fifth International Conference (GA93) Edited by Stephanie Forrest  
Address: Columbus, Ohio 43210  
Affiliation: Laboratory for Artificial Intelligence Research Computer and Information Science Department The Ohio State University  
Abstract-found: 0
Intro-found: 1
Reference: <author> Angeline, P. and J. Pollack, </author> <title> (1993) Coevolving high-level representations. </title> <note> To Appear in Artificial Life III. </note>
Reference-contexts: These runs represent a range of independent fitness functions that might be used for this task. In fact, NEAR is very similar to the expert we used in earlier experiments with GLiB to induce a modular genetic program that could fork <ref> (Angeline and Pollack, 1993) </ref>. The final experiment uses the tournament fitness function as described in the previous section and is labeled POP in the results. Scoring a single competition between two programs was as described above. <p> For instance, in previous experiments with NEAR, we awarded a fitness bonus for evolved programs that successfully blocked a win <ref> (Angeline and Pollack, 1993) </ref>. With a competitive fitness function, this problem is removed since the population is its own measure. As the ability of the individual members of the population increases on the task, the difficulty of the fitness function evolves with them.
Reference: <author> Angeline, P. and J. Pollack, </author> <title> (1992) The evolutionary induction of subroutines. </title> <booktitle> The Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <address> Bloomington Indi-ana. </address>
Reference: <author> Axelrod, R., </author> <year> (1989), </year> <title> Evolution of strategies in the iterated prisoners dilemma. Genetic Algorithms and Simulated Annealing, </title> <editor> L. Davis editor, </editor> <publisher> Morgan Kaufman Axelrod, R., </publisher> <year> (1984), </year> <title> The Evolution of Cooperation, </title> <publisher> Basic Books. </publisher>
Reference: <author> Berliner, H., </author> <year> (1977), </year> <title> Experiences in evaluation with BKG- a program that plays backgammon, </title> <booktitle> Proceedings of IJCAI, </booktitle> <year> 1977. </year>
Reference: <author> DeJong, K., </author> <year> (1975), </year> <title> An Analysis of the Behavior of a Class of Genetic Adaptive Systems, </title> <type> Doctoral dissertation, </type> <institution> University of Michigan. </institution>
Reference: <author> Epstein, S., </author> <year> (1992), </year> <title> Learning expertise from the opposition: the role of the trainer in a competitive environment., </title> <booktitle> The Proceedings of AI 92, </booktitle> <pages> 236-243. </pages>
Reference: <author> Forrest, S., </author> <year> (1991), </year> <title> Emergent computation: self-organizing, collective, and cooperative phenomena in natural and artificial computing networks, In Emergent Computation, </title> <editor> S. Forrest editor, </editor> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Appropriate complex structures arising purely from the physics of the task environment would be the ultimate validation of machine learning capability. Such is the essence of emergent computation <ref> (Forrest, 1991) </ref>. A competitive learning process encourages an evolutionary development such that as new strategies are developed by one learner, its opponent adjusts its abilities and discovers new strategies of its own. This strategic arms race ideally increases the overall ability of the learners until they reach near optimal abilities.
Reference: <author> Goldberg, D., </author> <year> (1989), </year> <title> Genetic Algorithms in Search, Optimization, </title> <booktitle> and Machine Learning, </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley Publishing Company, Inc. </publisher>
Reference-contexts: As described in the last section, if the scores were equal the winner of the competition was chosen at random. Each of the experiments used a population size of 256 and ran for a total of 150 generations. All experiments used roulette wheel selection with linear scaling <ref> (Goldberg, 1989) </ref> and a scaled fitness maximum of two. Other than the method of training, all other factors were equal. The parameter settings used were as listed in Angeline and Pol-lack (1993).
Reference: <author> Hillis, D., </author> <year> (1992), </year> <title> Co-evolving parasites improves simulated evolution as an optimization procedure, In Artificial Life II, edited by C. </title> <editor> Langton, C. Taylor, J. </editor> <publisher> Farmer and S. </publisher>
Reference: <editor> Rasmussen. </editor> <address> Reading, MA: </address> <publisher> Addison-Wesley Publishing Company, Inc. </publisher>
Reference: <author> Holland, J., </author> <year> (1975), </year> <booktitle> Adaptation in Natural and Artificial Systems, </booktitle> <address> Ann Arbor, MI: </address> <publisher> The University of Michigan Press. </publisher>
Reference: <editor> Koza, J., </editor> <booktitle> (1992), Genetic Programming, </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Crossover in GPP simply swaps randomly selected subtrees between the expression trees. Koza has demonstrated the ability of GPP to evolve solutions for a significant number of engineering problems <ref> (Koza, 1992) </ref>. Our system, GLiB, is an extension to GPP that induces new language elements by non-deterministically creating subroutines that are protected from further alteration by recombination. New subroutines are formed with a muta tion operator called compression, as shown in Figure 2.
Reference: <author> Koza, J., </author> <year> (1992b), </year> <title> Genetic Evolution and Co-Evolution of Computer Programs. </title> <booktitle> In Artificial Life II, edited by C. </booktitle>
Reference: <editor> Langton, C. Taylor, J. Farmer and S. Rasmussen. </editor> <address> Reading, MA: </address> <publisher> Addison-Wesley Publishing Company, Inc. </publisher>
Reference: <author> Lindgren, K., </author> <year> (1992), </year> <title> Evolutionary Phenomena in Simple Dynamics, </title> <booktitle> In Artificial Life II, edited by C. Langton, </booktitle> <address> C. </address>
Reference: <editor> Taylor, J. Farmer and S. Rasmussen. </editor> <address> Reading, MA: </address> <publisher> Addi-son-Wesley Publishing Company, Inc. </publisher>
Reference: <author> Ray, T., </author> <year> (1992), </year> <title> An Approach to the Synthesis of Life. </title>
Reference: <editor> In Artificial Life II, edited by C. Langton, C. Taylor, </editor> <publisher> J. </publisher>
Reference: <editor> Farmer and S. Rasmussen. </editor> <address> Reading, MA: </address> <publisher> Addison-Wesley Publishing Company, Inc. </publisher>
Reference: <author> Rumelhart, D., Smolensky, J., McClelland, J., and Hinton, G., </author> <year> (1986), </year> <title> Schemata and sequential thought processes in PDP models. In Parallel Distributed Processing: Explorations into the Microstructure of Cognition, </title> <booktitle> Volume 2, </booktitle> <address> D. </address>
Reference: <editor> Rumelhart, J. McClelland and the PDP Research Group eds., </editor> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Samuel, A., </author> <year> (1966), </year> <title> Some studies in machine learning using the game of checkers, II - recent progress. </title> <journal> IBM Journal of Research and Development 11, </journal> <pages> 601-617. </pages>
Reference: <author> Samuel, A., </author> <year> (1959), </year> <title> Some studies in machine learning using the game of checkers., </title> <journal> IBM Journal of Research and Development 3, </journal> <pages> 210-229. </pages>
Reference: <author> Tesauro, G., </author> <year> (1992), </year> <title> Practical issues in temporal difference learning, </title> <booktitle> Machine Learning 8, </booktitle> <pages> 257-277. </pages>
Reference: <author> Tesauro, G., </author> <year> (1990),Neurogammon: </year> <title> a neural network backgammon program. </title> <booktitle> IJCNN Proceedings III, </booktitle> <pages> 33-39. </pages>
References-found: 25

