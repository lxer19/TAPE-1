URL: http://s2k-ftp.cs.berkeley.edu:8000/postgres/papers/unpubl-perf.ps.Z
Refering-URL: http://s2k-ftp.cs.berkeley.edu:8000/mariposa/papers.html
Root-URL: 
Title: Performance of Adaptive Query Processing in the Mariposa Distributed Database Management System  
Author: Jeff Sidell 
Address: Berkeley  
Affiliation: University of California,  
Abstract: jsidell@cs.berkeley.edu Abstract The Mariposa distributed database management system is based on an economic paradigm in which processing sites buy and sell resources such as CPU time, I/O capacity and network bandwidth [STO96]. In a Mariposa economy, a site assigns a price to perform a service and may adjust its prices as it sees fit. In designing Mariposa, it was our hope that market forces could be used to achieve good performance while maintaining the independence of each processing site. In this paper, we address the problem of distributed query processing in Mariposa and compare its performance to a traditional cost-based distributed query optimizer. We demonstrate the ability of a Mariposa system to adapt to a dynamic workload by using simple economic concepts such as the effect of supply and demand on prices. We investigate the benefits of adaptive distributed query processing in Mariposa and its interaction with multi-user workloads, network latencies and query size. We present performance results which show that in multi-user situations, when response time is used as a metric, the Mariposa system outperforms a static optimizer by causing work to be distributed more evenly among the available sites and that the overhead introduced by Mariposas bidding protocol is insignificant when used with large, expensive queries and is outweighed by the benefits of load balancing, even for relatively small queries. Our experiments demonstrate that the point at which our approach outperforms a static optimizer is affected by network latency and query size. Our performance comparisons are based on the TPC-D benchmark. 
Abstract-found: 1
Intro-found: 1
Reference: [BER81] <author> P. A. Bernstein, N. Goodman, E. Wong, C.L. Reeve, J. </author> <title> Rothnie Query Processing in a System for Distributed Databases (SDD-1), </title> <journal> ACM Transactions on database Systems, </journal> <volume> 6(4), </volume> <month> (December, </month> <year> 1981). </year>
Reference-contexts: We propose directions for future work in Section 6. 2. Previous Work Query optimization and query processing have been the subject of a great deal of research, starting with traditional single-site cost-based optimization [SEL79]. When distributed database management systems were first introduced [WDH81] <ref> [BER81] </ref> [STO86] the single-site cost-based optimizers were changed to take into account network costs. Conventional distributed (static) query optimizers consist of a cost function, which estimates resource usage such as network cost, CPU time and disk I/O, based on input parameters such as relation size and selectivity of join operations.
Reference: [BIT83] <author> D. Bitton, </author> <title> et al Benchmarking Database Systems: A Systematic Approach, </title> <booktitle> Proc. 1983 VLDB Conference, </booktitle> <address> Florence, Italy, </address> <month> Nov. </month> <year> 1983. </year>
Reference-contexts: It would be interesting to test Mariposa on other benchmarks with smaller queries, such as the Wisconsin Benchmark <ref> [BIT83] </ref>.
Reference: [CHM95] <author> C. Chekuri, W. Hasan, R. Motwani, </author> <title> Scheduling Problems in Parallel Query Optimization, </title> <booktitle> Proceedings of the Fourteenth ACM Symposium on Principles of Database Systems (PODS), </booktitle> <year> 1995, </year> <pages> pp. 255-265. </pages>
Reference-contexts: The XPRS parallel database management system [HON92] used a single-site optimizer during this phase and therefore ignored communication cost. [HM95] presents algorithms that incorporate communication costs. Dividing a plan into parts and scheduling the parts in an optimal way is itself an NP-complete problem. <ref> [CHM95] </ref> presents two approximation algorithms for dividing query plans into subplans for scheduling on a parallel machine. The original query plans must consist only of non-blocking operators such as sorts and hash table builds. <p> If each node were bid out individually to ten sites, there would be 10 60 possible solutions. To address this issue, we intend to pursue the work mentioned in Section 2 on optimal division of plan trees <ref> [CHM95] </ref>. <p> The bidder algorithm used for these performance studies is 17 quite primitive: load average is only a crude estimate of overall resource consumption. We intend to develop more sophisticated approaches to bidding which take into account individual resource availability. We also intend to expand on the work presented in <ref> [CHM95] </ref> to develop improved algorithms for dividing query plans up into units of work. As mentioned previously, the Mariposa model is general enough to support intra-operator parallelism. However, the Mariposa model is capable of a more intelligent approach to dividing work among machines in a shared-nothing environment.
Reference: [DAV95] <author> D. Davison, et al. </author> <title> Dynamic Resource Brokering for Multi-User Query Execution, </title> <booktitle> Proceedings of the 1995 ACM SIGMOD (May, </booktitle> <year> 1995), </year> <pages> pp. 281-92. </pages>
Reference-contexts: An approach closely related to that taken by Mariposa is presented in <ref> [DAV95] </ref>. The authors address the problem of multiple query management in a single-site database by utilizing a resource broker, which sells resources to competing operators. This work has many similarities to Mariposa, including a microeconomic model where the brokers goal is to maximize its profit.
Reference: [DNS91] <author> D.J. DeWitt, J.F. Naughton, D.A. Schneider, S. Seshadri, </author> <title> Parallel Sorting on a Shared-Nothing Architecture Using Probabilistic Splitting. </title> <booktitle> Proc. of the First International Conference on Parallel and Distributed Information Systems, </booktitle> <address> Miami, Florida (December 1991), </address> <pages> pp. 280-291. </pages>
Reference-contexts: For example, each Mariposa bidder can formulate its bid in any way it chooses. Much research in parallel query processing has focused on speeding up single queries, primarily by exploiting intra-operator parallelism [MD95]. An operation which can be performed in parallel by several processors at once, such as sorting <ref> [DNS91] </ref> or hash joins [ZG90] is divided among all available processors. Intra-operator parallelism is sensitive to data skew; since each processor is performing essentially the same task over different data, it is important that the division of data among the processors be as close to even as possible.
Reference: [DNS92] <author> D.J. DeWitt, J.F. Naughton, D.A. Schneider, S. Seshadri, </author> <title> Practical Skew Handling in Parallel Joins, </title> <booktitle> Proc. 18th VLDB Conf. </booktitle> <year> (1992), </year> <pages> pp. 27-40. </pages>
Reference-contexts: Overcoming data skew has been studied extensively and the various approaches are well-documented in the literature [WDJ91] [WDY91] <ref> [DNS92] </ref> [HLY93]. [RM95] proposes dynamic load balancing schemes for parallel join processing and compares them to static algorithms in a simulated multi-user environment. The dynamic load balancing techniques adjust the degree of join parallelism based on several factors, such as disk I/O, CPU usage and memory usage.
Reference: [GRA93] <author> J. Gray, G. Graefe, </author> <title> Transaction Processing: Concepts and Techniques, </title> <publisher> Morgan Kaufmann Publishers, Inc. </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: This work has many similarities to Mariposa, including a microeconomic model where the brokers goal is to maximize its profit. However, their work has not been expanded to distributed databases. 3 Transaction processing monitors <ref> [GRA93] </ref> also include distributed load balancing as part of a long list of services.
Reference: [HAS95] <author> W. Hasan, </author> <title> Optimizing Response Time of Relational Queries by Exploiting Parallel Execution, </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1995. </year> <note> In preparation. </note>
Reference-contexts: This is a generalization of the approach taken by some parallel database management systems [HON92] <ref> [HAS95] </ref> which perform join order query rewrite (JOQR) first, then divide the resulting plan among the available processors based on their current load, assigning the most work to the least-burdened processor. During JOQR, the query is optimized, producing a query plan, which is a tree of operation nodes.
Reference: [HLY93] <author> K.A. Hua, Y. Lo, H.C. Young, </author> <title> Considering Data Skew Factor in Multi-Way Join Query Optimization for Parallel Execution, </title> <booktitle> VLDB Journal 2(3) (1993), </booktitle> <pages> pp. 303-330. </pages>
Reference-contexts: Overcoming data skew has been studied extensively and the various approaches are well-documented in the literature [WDJ91] [WDY91] [DNS92] <ref> [HLY93] </ref>. [RM95] proposes dynamic load balancing schemes for parallel join processing and compares them to static algorithms in a simulated multi-user environment. The dynamic load balancing techniques adjust the degree of join parallelism based on several factors, such as disk I/O, CPU usage and memory usage.
Reference: [HM95] <author> W. Hasan, R. Motwani, </author> <title> Coloring Away Communication in Parallel Query Optimization, </title> <note> 1995. Submitted for publication. </note>
Reference-contexts: Each node represents a piece of work such as scanning a relation, sorting, or performing a join. The XPRS parallel database management system [HON92] used a single-site optimizer during this phase and therefore ignored communication cost. <ref> [HM95] </ref> presents algorithms that incorporate communication costs. Dividing a plan into parts and scheduling the parts in an optimal way is itself an NP-complete problem. [CHM95] presents two approximation algorithms for dividing query plans into subplans for scheduling on a parallel machine.
Reference: [HON92] <author> W. Hong. </author> <title> Parallel Query Processing Using Shared Memory Multiprocessors and Disk Arrays, </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: This is a generalization of the approach taken by some parallel database management systems <ref> [HON92] </ref> [HAS95] which perform join order query rewrite (JOQR) first, then divide the resulting plan among the available processors based on their current load, assigning the most work to the least-burdened processor. During JOQR, the query is optimized, producing a query plan, which is a tree of operation nodes. <p> During JOQR, the query is optimized, producing a query plan, which is a tree of operation nodes. Each node represents a piece of work such as scanning a relation, sorting, or performing a join. The XPRS parallel database management system <ref> [HON92] </ref> used a single-site optimizer during this phase and therefore ignored communication cost. [HM95] presents algorithms that incorporate communication costs.
Reference: [IOA92] <author> Y. Ioannidis, et al. </author> <title> Parametric Query Optimization, </title> <booktitle> Proceedings of the 18th International Conference on Very Large Databases (August, </booktitle> <year> 1992) </year>
Reference-contexts: The cost function used by a static optimizer is usually generated once when the system is installed, and reflects the hardware and network configuration of the system. The parameterized query optimizer presented in <ref> [IOA92] </ref> is an attempt to address the problem of adapting to dynamic resource allocation. In a parameterized query optimizer, many possible plans are generated and one is selected at run-time, depending on the values of parameters such as buffer size.
Reference: [MAR96] <institution> The Mariposa Users Guide, </institution> <note> http://mariposa.berkeley.edu (1996). </note>
Reference-contexts: The following example is illustrated in Figure 1, which shows the Mariposa modules and the communication among sites during query processing. For a detailed description of the Mariposa architecture, refer to [STO96] or <ref> [MAR96] </ref>. A front-end application submits a query such as SELECT O_ORDERPRIORITY, count (O_ORDERKEY) AS ORDER_COUNT FROM ORDERS, LINEITEM WHERE O_ORDERDATE &gt;= 01/01/1997 AND O_ORDERDATE &lt; 01/16/1997 AND L_ORDERKEY = O_ORDERKEY AND L_COMMITDATE &lt; L_RECEIPTDATE GROUP BY O_ORDERPRIORITY ORDER BY O_ORDERPRIORITY; and a bid curve at the home site.
Reference: [MD95] <author> M. Mehta, </author> <title> D.J. DeWitt, Managing Intra-Operator Parallelism in Parallel Database Systems, </title> <booktitle> Proc. 21st VLDB Conf., (1995) pp. </booktitle> <pages> 382-394. </pages>
Reference-contexts: In contrast, Mariposas brokering and bidding process is more expensive but also more flexible. For example, each Mariposa bidder can formulate its bid in any way it chooses. Much research in parallel query processing has focused on speeding up single queries, primarily by exploiting intra-operator parallelism <ref> [MD95] </ref>. An operation which can be performed in parallel by several processors at once, such as sorting [DNS91] or hash joins [ZG90] is divided among all available processors.
Reference: [OUS90] <author> J. Ousterhout. </author> <title> Tcl: An Embeddable Command Language, </title> <booktitle> Proceedings of the Winter 1990 USENIX Conference (January, </booktitle> <year> 1990), </year> <pages> pp. 133-46. </pages>
Reference-contexts: In Figure 1, the broker has asked two potential processing sites to bid on the plan chunk indicated, and gotten back two bids: ($5, 5 minutes) and ($10, 30 seconds) . The bidders response is determined completely by a script written in an enhanced Tcl <ref> [OUS90] </ref>. The broker selects the bid for each plan chunk which corresponds to the point which is farthest below the bid curve. Once the broker has determined the processing sites, the distributed plan is passed to a coordinator module, which contacts the processing sites to begin execution.
Reference: [RM95] <author> E. Rahm, R. Marek, </author> <title> Dynamic Multi-Resource Load Balancing in Parallel Database Systems, </title> <booktitle> Proceedings of the 21st VLDB Conf (1995), </booktitle> <pages> pp. 395-406. </pages>
Reference-contexts: Overcoming data skew has been studied extensively and the various approaches are well-documented in the literature [WDJ91] [WDY91] [DNS92] [HLY93]. <ref> [RM95] </ref> proposes dynamic load balancing schemes for parallel join processing and compares them to static algorithms in a simulated multi-user environment. The dynamic load balancing techniques adjust the degree of join parallelism based on several factors, such as disk I/O, CPU usage and memory usage.
Reference: [SEL79] <author> P. Selinger, et al. </author> <title> Access Path Selection in a Relational Database Management System, </title> <booktitle> Proceedings of the 1979 ACM SIGMOD Conference on Management of Data (June, </booktitle> <year> 1979). </year>
Reference-contexts: We describe the experimental setup in Section 4, and in Section 5 we present the results. We propose directions for future work in Section 6. 2. Previous Work Query optimization and query processing have been the subject of a great deal of research, starting with traditional single-site cost-based optimization <ref> [SEL79] </ref>. When distributed database management systems were first introduced [WDH81] [BER81] [STO86] the single-site cost-based optimizers were changed to take into account network costs.
Reference: [SID96] <editor> J. Sidell, et al. </editor> <booktitle> Data Replication in Mariposa, Proceedings of the 12th International Conference on Data Engineering (February, </booktitle> <year> 1996). </year>
Reference-contexts: The parser, optimizer and fragmenter (and, later, the query broker) use information from a Mariposa name server. Name servers provide system metadata including type information, data fragmentation and placement. Name service in Mariposa is described in <ref> [SID96] </ref>. In Mariposa, the optimizer is a single-site cost-based optimizer which minimizes single-site resources used to execute the query. The query plan produced by the optimizer is passed into the fragmenter. The fragmenter alters the single-site plan to reflect the underlying data fragmentation.
Reference: [STO86] <author> M. </author> <title> Stonebraker The Design and Implementation of Distributed INGRES, in The INGRES Papers, </title> <editor> M. Stonebraker (ed.), </editor> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: We propose directions for future work in Section 6. 2. Previous Work Query optimization and query processing have been the subject of a great deal of research, starting with traditional single-site cost-based optimization [SEL79]. When distributed database management systems were first introduced [WDH81] [BER81] <ref> [STO86] </ref> the single-site cost-based optimizers were changed to take into account network costs. Conventional distributed (static) query optimizers consist of a cost function, which estimates resource usage such as network cost, CPU time and disk I/O, based on input parameters such as relation size and selectivity of join operations.
Reference: [STO96] <author> M. Stonebraker, et al. Mariposa: </author> <title> A Wide-Area Distributed Database System, </title> <journal> VLDB Journal 5, </journal> <month> 1 (Jan. </month> <year> 1996), </year> <pages> pp. 48-63. </pages>
Reference-contexts: 1. Introduction The Mariposa distributed database management system is based on an economic paradigm in which processing sites buy and sell resources such as CPU time, I/O capacity and network bandwidth <ref> [STO96] </ref>. In a Mariposa economy, a site assigns a price to perform a service and may adjust its prices as it sees fit. In designing Mariposa, it was our hope that market forces could be used to achieve good performance while maintaining the independence of each processing site. <p> The next section describes previous work in the areas of distributed query optimization and parallel and distributed query processing. Section 3 describes the Mariposa architecture, paying particular attention to the query broker and bidder modules. A complete description of the Mariposa architecture can be found in <ref> [STO96] </ref>. We describe the experimental setup in Section 4, and in Section 5 we present the results. We propose directions for future work in Section 6. 2. <p> The following example is illustrated in Figure 1, which shows the Mariposa modules and the communication among sites during query processing. For a detailed description of the Mariposa architecture, refer to <ref> [STO96] </ref> or [MAR96]. A front-end application submits a query such as SELECT O_ORDERPRIORITY, count (O_ORDERKEY) AS ORDER_COUNT FROM ORDERS, LINEITEM WHERE O_ORDERDATE &gt;= 01/01/1997 AND O_ORDERDATE &lt; 01/16/1997 AND L_ORDERKEY = O_ORDERKEY AND L_COMMITDATE &lt; L_RECEIPTDATE GROUP BY O_ORDERPRIORITY ORDER BY O_ORDERPRIORITY; and a bid curve at the home site. <p> The fragmenter alters the single-site plan to reflect the underlying data fragmentation. The experiments in this paper were not performed over fragmented data so we will leave out a detailed explanation of the fragmenter. The interested reader can refer to <ref> [STO96] </ref>. The query plan is passed into the query broker, whose job it is to assign a processing site to each node in the plan tree. First, the query broker breaks up the plan into plan chunks. <p> The effects on query processing of breaking up plans in different ways is an area for future study. The query broker follows one of two protocols: long or short. The experiments in this paper all used the long protocol. For a description of the short protocol, refer to <ref> [STO96] </ref>. In the long protocol, illustrated in Figure 1, the query broker contacts bidder processes running at potential processing sites, passing along a plan chunk and soliciting a bid. <p> Data placement can have a profound impact on database performance. Mariposa supports lightweight data movement, copies and data fragmentation. The Mariposa data broker <ref> [STO96] </ref> buys and sells database tables or copies of tables in much the same way that the query broker buys and sells other computational resources. It is our belief that simple data broker algorithms, much like the ones presented in this paper, can lead to effective data placement.
Reference: [TPC] <institution> Transaction Processing Council, </institution> <address> 777 N. First St. Suite 600, San Jose, CA 95112-6311. URL: www.tpc.org 19 </address>
Reference-contexts: Our experiments demonstrate that the point at which our approach outperforms a static optimizer is affected by network latency and query size. Our performance comparisons are based on the TPC-D benchmark <ref> [TPC] </ref>. The next section describes previous work in the areas of distributed query optimization and parallel and distributed query processing. Section 3 describes the Mariposa architecture, paying particular attention to the query broker and bidder modules. A complete description of the Mariposa architecture can be found in [STO96]. <p> HOME SITE BLACK PROCESSING SITE Query Broker Bidder GRAY PROCESSING SITE Bidder ($2 10 seconds) JOIN SCAN SCAN AGG SCAN ORDERS Query Broker SCAN ORDERS Subcontract 4. Experimental Setup The performance studies are based on the Transaction Processing Councils benchmark D <ref> [TPC] </ref>. This benchmark is designed to model decision-support queries. There are seventeen queries over nine database tables (including one optional table). Several of the queries are multi-way joins and all of them include aggregates.
Reference: [WDH81] <author> R. Williams, D. Daniels, L. Haas, et al, </author> <title> R*: An Overview of the Architecture, </title> <institution> IBM Research, </institution> <address> San Jose, CA, RJ3325, </address> <month> Dec. </month> <year> 1981. </year>
Reference-contexts: Such an optimizer will produce the same plan for a query regardless of current conditions such as available buffer space or network traffic. For this reason, we call these types of optimizers static. A canonical example of a static optimizer is R* <ref> [WDH81] </ref>. Static optimizers are unable to react to fluctuating availability of resources by adjusting the relative values of those resources in their cost functions. <p> We propose directions for future work in Section 6. 2. Previous Work Query optimization and query processing have been the subject of a great deal of research, starting with traditional single-site cost-based optimization [SEL79]. When distributed database management systems were first introduced <ref> [WDH81] </ref> [BER81] [STO86] the single-site cost-based optimizers were changed to take into account network costs.
Reference: [WDJ91] <author> C.B. Walton, A.G. Dale, </author> <title> R.M. Jenevein, A Taxonomy and Performance Model of Data Skew Effects in Parallel Joins, </title> <booktitle> Proc. 17th VLDB Conf. (1991) pp. </booktitle> <pages> 537-548. </pages>
Reference-contexts: Overcoming data skew has been studied extensively and the various approaches are well-documented in the literature <ref> [WDJ91] </ref> [WDY91] [DNS92] [HLY93]. [RM95] proposes dynamic load balancing schemes for parallel join processing and compares them to static algorithms in a simulated multi-user environment. The dynamic load balancing techniques adjust the degree of join parallelism based on several factors, such as disk I/O, CPU usage and memory usage.
Reference: [WDY91] <author> J.L. Wolf, D.M. Dias, P.S. Yu, J. Turek, </author> <title> An Effective Algorithm for Parallelizing Hash Joins in the Presence of Data Skew, </title> <booktitle> Proc. 7th IEEE Data Engineering Conf. </booktitle> <year> (1991), </year> <pages> pp. 200-209. </pages>
Reference-contexts: Overcoming data skew has been studied extensively and the various approaches are well-documented in the literature [WDJ91] <ref> [WDY91] </ref> [DNS92] [HLY93]. [RM95] proposes dynamic load balancing schemes for parallel join processing and compares them to static algorithms in a simulated multi-user environment. The dynamic load balancing techniques adjust the degree of join parallelism based on several factors, such as disk I/O, CPU usage and memory usage.
Reference: [ZG90] <author> H. Zeller, J. Gray, </author> <title> An Adaptive hash Join Algorithm for Multiuser Environment, </title> <booktitle> Proc. 16th VLDB Conf. </booktitle> <volume> (199), </volume> <pages> pp. 186-197. </pages>
Reference-contexts: Much research in parallel query processing has focused on speeding up single queries, primarily by exploiting intra-operator parallelism [MD95]. An operation which can be performed in parallel by several processors at once, such as sorting [DNS91] or hash joins <ref> [ZG90] </ref> is divided among all available processors. Intra-operator parallelism is sensitive to data skew; since each processor is performing essentially the same task over different data, it is important that the division of data among the processors be as close to even as possible.
References-found: 25

