URL: http://www.cam.sri.com/people/milward/iicatgr.ps.gz
Refering-URL: http://www.cam.sri.com/people/milward/
Root-URL: 
Email: davidm@cogsci.ed.ac.uk  
Title: Incremental Interpretation of Categorial Grammar  
Author: David Milward 
Address: 2 Buccleuch Place, Edinburgh, EH8 9LW, U.K.  
Affiliation: Centre for Cognitive Science University of Edinburgh  
Note: In Proceedings of the 7th Conference of the European Chapter of the ACL, EACL 95, Dublin, Ireland.  
Abstract: The paper describes a parser for Catego-rial Grammar which provides fully word by word incremental interpretation. The parser does not require fragments of sentences to form constituents, and thereby avoids problems of spurious ambiguity. The paper includes a brief discussion of the relationship between basic Catego-rial Grammar and other formalisms such as HPSG, Dependency Grammar and the Lambek Calculus. It also includes a discussion of some of the issues which arise when parsing lexicalised grammars, and the possibilities for using statistical techniques for tuning to particular lan guages.
Abstract-found: 1
Intro-found: 1
Reference: <author> Ades, A. & Steedman, M.: </author> <year> 1972, </year> <title> `On the Order of Words', </title> <booktitle> Linguistics & Philosophy 4, </booktitle> <pages> 517-558. </pages>
Reference: <author> Bar-Hillel, Y.: </author> <year> 1953, </year> <title> `A Quasi-Arithmetical Notation for Syntactic Description', </title> <booktitle> Language 29, </booktitle> <pages> 47-58. </pages>
Reference: <author> Bar-Hillel, Y.: </author> <year> 1964, </year> <title> Language & Information: Selected Essays on Their Theory & Application, </title> <publisher> Addison-Wesley. </publisher>
Reference: <author> Bouma, G.: </author> <year> 1987, </year> <title> `A Unification-Based Analysis of Unbounded Dependencies', </title> <booktitle> in Proceedings of the 6th Amsterdam Colloquium, </booktitle> <institution> ITLI, University of Amsterdam. </institution>
Reference-contexts: of the composition rule were proposed in order to deal with non-peripheral extraction, 4 The reformulation is not entirely faithful here to Bar-Hillel, who used a slightly problematic `double slash' notation for functions of functions. 5 Lambek notation (Lambek 1958). but this led to unwanted effects elsewhere in the grammar <ref> (Bouma 1987) </ref>.
Reference: <author> Bouma, G. & van Noord, G.: </author> <year> 1994, </year> <title> `Constraint-Based Categorial Grammar', </title> <booktitle> in Proceedings of the 32nd ACL, </booktitle> <address> Las Cruces, U.S.A. </address>
Reference-contexts: It was first applied to linguistic description by Adjukiewicz and Bar-Hillel in the 1950s. Although it is still used for linguistic description <ref> (e.g. Bouma and van Noord, 1994) </ref>, it has been somewhat overshadowed in recent years by HPSG (Pollard and Sag 1994), and by Lambek Cate-gorial Grammars (Lambek 1958). It is therefore worth giving some brief indications of how it fits in with these developments.
Reference: <author> Earley, J.: </author> <year> 1970, </year> <title> `An Efficient Context-free Parsing Algorithm', </title> <journal> ACM Communications 13(2), </journal> <pages> 94-102. </pages>
Reference-contexts: lexical entries for a sentence is collected, they can, if required, then be converted back into a set of phrase structure rules (which should correspond to a small subset of the rule based formalism equivalent to the whole lexicalised grammar), before being parsing with a standard algorithm such as Earley's <ref> (Earley 1970) </ref>. In incremental parsing we cannot predict which words will appear in the sentence, so cannot use the same technique. However, if we are to base a parser on the rules given above, it would seem that we gain further.
Reference: <author> Gaifman, H.: </author> <year> 1965, </year> <title> `Dependency Systems & Phrase Structure Systems', </title> <booktitle> Information & Control 8: </booktitle> <pages> 304-337. </pages>
Reference: <author> Gazdar, G., Klein, E., Pullum, G.K., & Sag, I.A.: </author> <year> 1985, </year> <title> Generalized Phrase Structure Grammar, </title> <publisher> Blackwell, Oxford. </publisher>
Reference-contexts: This is very similar to the way in which wh-movement is dealt with in GPSG <ref> (Gazdar et al. 1985) </ref> and HPSG, where wh-arguments are treated using slash mechanisms or feature inheritance principles which correspond closely to function composition.
Reference: <author> Hays, D.G.: </author> <year> 1964, </year> <title> `Dependency Theory: A Formalism & Some Observations', </title> <booktitle> Language 40, </booktitle> <pages> 511-525. </pages>
Reference: <author> Joshi, A.K.: </author> <year> 1987, </year> <title> `An Introduction to Tree Adjoining Grammars', in Manaster-Ramer (ed.), Mathematics of Language, John Benjamins, Amsterdam. 15 Tugwell's approach does however differ in that the state transitions are not limited by the rules of State-Prediction and State-Application. This has advantages in allowing the grammar to learn phenomena such as heavy NP shift, but has the disadvantage of suffering from greater sparse data problems. A compromise system using the rules here, but allowing reordering of the r-lists might be preferable. </title>
Reference-contexts: Mary thinks John coming here was a mistake. s np vp Mary / " v s thinks / " np vp^ John M&C suggest various possibilities for packing the partial syntax trees, including using Tree Adjoining Grammar <ref> (Joshi 1987) </ref> or Description Theory (Marcus et al. 1983). One further possibility is to choose a single syntax tree, and to use destructive tree operations later in the parse 3 . The approach which we will adopt here is based on Milward (1992, 1994).
Reference: <author> Lambek, J.: </author> <year> 1958, </year> <title> `The Mathematics of Sentence Structure', </title> <journal> American Mathematical Monthly 65, </journal> <pages> 154-169. </pages>
Reference-contexts: For example, it gives a type to John thinks Mary, but not to John thinks each. In contrast the Lambek Calculus <ref> (Lambek 1958) </ref> provides an infinite number of types for any initial sentence fragment. word-by-word). M&C illustrate the problem by considering the fragment Mary thinks John. This has a small number of possible semantic representations (the exact number depending upon the grammar) e.g. P.thinks (mary,P (john)) P.Q. <p> It was first applied to linguistic description by Adjukiewicz and Bar-Hillel in the 1950s. Although it is still used for linguistic description (e.g. Bouma and van Noord, 1994), it has been somewhat overshadowed in recent years by HPSG (Pollard and Sag 1994), and by Lambek Cate-gorial Grammars <ref> (Lambek 1958) </ref>. It is therefore worth giving some brief indications of how it fits in with these developments. The first directed Applicative CG was proposed by Bar-Hillel (1953). Functional types included a list of arguments to the left, and a list of arguments to the right. <p> Variants of the composition rule were proposed in order to deal with non-peripheral extraction, 4 The reformulation is not entirely faithful here to Bar-Hillel, who used a slightly problematic `double slash' notation for functions of functions. 5 Lambek notation <ref> (Lambek 1958) </ref>. but this led to unwanted effects elsewhere in the grammar (Bouma 1987).
Reference: <author> Marcus, M., Hindle, D., & Fleck, M.: </author> <year> 1983, </year> <title> `D-Theory: Talking about Talking about Trees', </title> <booktitle> in Proceedings of the 21st ACL, </booktitle> <address> Cambridge, Mass. </address>
Reference-contexts: Mary thinks John coming here was a mistake. s np vp Mary / " v s thinks / " np vp^ John M&C suggest various possibilities for packing the partial syntax trees, including using Tree Adjoining Grammar (Joshi 1987) or Description Theory <ref> (Marcus et al. 1983) </ref>. One further possibility is to choose a single syntax tree, and to use destructive tree operations later in the parse 3 . The approach which we will adopt here is based on Milward (1992, 1994). Partial syntax trees can be regarded as performing two main roles.
Reference: <author> Marslen-Wilson, W.: </author> <year> 1973, </year> <title> `Linguistic Structure & Speech Shadowing at Very Short Latencies', </title> <booktitle> Nature 244, </booktitle> <pages> 522-523. </pages>
Reference: <author> Milward, D.: </author> <year> 1992, </year> <title> `Dynamics, Dependency Grammar & Incremental Interpretation', </title> <booktitle> in Proceedings of COLING 92, Nantes, </booktitle> <volume> vol 4, </volume> <pages> 1095-1099. </pages>
Reference: <author> Milward, D. & Cooper, R.: </author> <year> 1994, </year> <title> `Incremental Interpretation: Applications, Theory & Relationship to Dynamic Semantics', </title> <booktitle> in Proceedings of COLING 94, </booktitle> <address> Kyoto, Japan, </address> <pages> 748-754. </pages>
Reference: <author> Milward, D.: </author> <year> 1994, </year> <title> `Dynamic Dependency Grammar', </title> <note> to appear in Linguistics & Philosophy 17, 561-605. </note>
Reference: <author> Mitchell, D.C., Cuetos, F., & Corley, M.M.B.: </author> <year> 1992, </year> <title> `Statistical versus linguistic determinants of parsing bias: cross-linguistic evidence'. </title> <booktitle> Paper presented at the 5th Annual CUNY Conference on Human Sentence Processing, </booktitle> <address> New York. </address>
Reference-contexts: time complexity (Mil-ward 1994) and good practical performance, taking a couple of seconds on 30 word sentences. 14 The usage of the term language tuning is perhaps broader here than its use in the psycholinguistic literature to refer to different structural preferences between languages e.g. for high versus low attachment <ref> (Mitchell et al. 1992) </ref>. There has already been some early work done on providing statistically based parsing using transitions between recursively structured syntactic categories (Tugwell 1995) 15 . Unlike a simple Markov process, there are a potentially infinite number of states, so there is inevitably a problem of sparse data.
Reference: <author> Moore, R.C.: </author> <year> 1989, </year> <title> `Unification-Based Semantic Interpretation', </title> <booktitle> in Proceedings of the 27th ACL, </booktitle> <address> Van-couver. </address>
Reference: <author> Moortgat, M.: </author> <year> 1988, </year> <title> Categorial Investigations: Logical & Linguistic Aspects of the Lambek Calculus, </title> <publisher> Foris, Dordrecht. </publisher>
Reference-contexts: Subsequent treatments of non-peripheral extraction based on the Lambek Calculus (where standard composition is built in: it is a rule which can be proven from the calculus) have either introduced an alternative to the forward and backward slashes i.e. / and n for normal args, " for wh-args <ref> (Moortgat 1988) </ref>, or have introduced so called modal operators on the wh-argument (Morrill et al. 1990). Both techniques can be thought of as marking the wh-arguments as requiring special treatment, and therefore do not lead to unwanted effects elsewhere in the grammar.
Reference: <author> Morrill, G., Leslie, N., Hepple, M. & Barry,G.: </author> <year> 1990, </year> <title> `Categorial Deductions & Structural Operations', </title> <editor> in Barry, G. & Morrill, G. (eds.), </editor> <booktitle> Studies in Ca-tegorial Grammar, Edinburgh Working Papers in Cognitive Science, </booktitle> <pages> 5. </pages>
Reference-contexts: (where standard composition is built in: it is a rule which can be proven from the calculus) have either introduced an alternative to the forward and backward slashes i.e. / and n for normal args, " for wh-args (Moortgat 1988), or have introduced so called modal operators on the wh-argument <ref> (Morrill et al. 1990) </ref>. Both techniques can be thought of as marking the wh-arguments as requiring special treatment, and therefore do not lead to unwanted effects elsewhere in the grammar. However, there are problems with having just composition, the most basic of the non-applicative operations.
Reference: <author> Polanyi, L. & Scha, R.: </author> <year> 1984, </year> <title> `A Syntactic Approach to Discourse Semantics', </title> <booktitle> in Proceedings of CO-LING 84, Stanford, </booktitle> <pages> 413-419. </pages>
Reference-contexts: It is also closer to some methods for incremental adaptation of discourse structures, where additions are allowed to the right-frontier of a tree structure <ref> (e.g. Polanyi and Scha 1984) </ref>. There are however problems with this kind of approach when features are considered (see e.g. Vijay-Shanker 1992). This provides a state-transition or dynamic model of processing, with each state being a pair of a syntactic type and a semantic value.
Reference: <editor> Pollard, C. & Sag, </editor> <address> I.A.: </address> <year> 1994, </year> <title> Head-Driven Phrase Structure Grammar, </title> <publisher> University of Chicago Press & CSLI Publications, Chicago. </publisher>
Reference-contexts: It was first applied to linguistic description by Adjukiewicz and Bar-Hillel in the 1950s. Although it is still used for linguistic description (e.g. Bouma and van Noord, 1994), it has been somewhat overshadowed in recent years by HPSG <ref> (Pollard and Sag 1994) </ref>, and by Lambek Cate-gorial Grammars (Lambek 1958). It is therefore worth giving some brief indications of how it fits in with these developments. The first directed Applicative CG was proposed by Bar-Hillel (1953). <p> The first directed Applicative CG was proposed by Bar-Hillel (1953). Functional types included a list of arguments to the left, and a list of arguments to the right. Translating Bar-Hillel's notation into a feature based notation similar to that in HPSG <ref> (Pollard and Sag 1994) </ref>, we obtain the following category for a ditransitive verb such as put: 6 s lhnpi rhnp, ppi 3 5 The list of arguments to the left are gathered under the feature, l, and those to the right, an np and a pp in that order, under the
Reference: <author> Pulman, S.G.: </author> <year> 1986, </year> <title> `Grammars, Parsers, & Memory Limitations', </title> <booktitle> Language & Cognitive Processes 1(3), </booktitle> <pages> 197-225. </pages>
Reference-contexts: Incremental interpretation can then be achieved using a standard bottom-up shift reduce parser, working from left to right along the sentence. The alternative approach, exemplified by the work of Stabler on top-down parsing (Stabler 1991), and Pulman on left-corner parsing <ref> (Pulman 1986) </ref> is to associate a semantics directly with the partial structures formed during a top-down or left-corner parse.
Reference: <author> Spivey-Knowlton, M., Sedivy, J., Eberhard, K., & Ta-nenhaus, M.: </author> <year> 1994, </year> <title> `Psycholinguistic Study of the Interaction Between Language & Vision', </title> <booktitle> in Proceedings of the 12th National Conference on AI, AAAI-94. </booktitle>
Reference: <author> Stabler, E.P.: </author> <year> 1991, </year> <title> `Avoid the Pedestrian's Paradox', </title> <editor> in Berwick, R.C. et al. (eds.), </editor> <title> Principle-Based Parsing: Computation & Psycholinguistics, </title> <publisher> Kluwer, Netherlands, </publisher> <pages> 199-237. </pages>
Reference-contexts: Incremental interpretation can then be achieved using a standard bottom-up shift reduce parser, working from left to right along the sentence. The alternative approach, exemplified by the work of Stabler on top-down parsing <ref> (Stabler 1991) </ref>, and Pulman on left-corner parsing (Pulman 1986) is to associate a semantics directly with the partial structures formed during a top-down or left-corner parse.
Reference: <author> Steedman, M.J.: </author> <year> 1991, </year> <booktitle> `Type-Raising & Directiona-lity in Combinatory Grammar', in Proceedings of the 29th ACL, </booktitle> <address> Berkeley, U.S.A. </address>
Reference-contexts: Another showed on-line effects from adjectives and determiners during noun phrase processing. constituency, so that an initial fragment of a sentence, such as John likes, can be treated as a constituent, and hence be assigned a type and a semantics. This approach is exemplified by Com-binatory Categorial Grammar, CCG <ref> (Steedman 1991) </ref>, which takes a basic CG with just application, and adds various new ways of combining elements together 2 . Incremental interpretation can then be achieved using a standard bottom-up shift reduce parser, working from left to right along the sentence.
Reference: <editor> Tanenhaus, M.K., Garnsey, S., & Boland, J.: </editor> <year> 1990, </year> <title> `Combinatory Lexical Information & Language Comprehension', in Altmann, G.T.M. Cognitive Models of Speech Processing, </title> <publisher> MIT Press, </publisher> <address> Cam-bridge Ma. </address>
Reference: <author> Tugwell, D.: </author> <year> 1995, </year> <title> `A State-Transition Grammar for Data-Oriented Parsing', </title> <booktitle> in Proceedings of the 7th Conference of the European ACL, EACL-95, Dub-lin, this volume. </booktitle>
Reference-contexts: There has already been some early work done on providing statistically based parsing using transitions between recursively structured syntactic categories <ref> (Tugwell 1995) </ref> 15 . Unlike a simple Markov process, there are a potentially infinite number of states, so there is inevitably a problem of sparse data. It is therefore necessary to make various generalisations over the states, for example by ignoring the R 2 lists.
Reference: <author> Vijay-Shanker, K.: </author> <year> 1992, </year> <title> `Using Descriptions of Trees in a Tree Adjoining Grammar', </title> <booktitle> Computational Linguistics 18(4), </booktitle> <pages> 481-517. </pages>
References-found: 29

