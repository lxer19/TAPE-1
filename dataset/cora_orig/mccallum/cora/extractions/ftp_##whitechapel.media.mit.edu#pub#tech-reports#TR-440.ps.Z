URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-440.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: @media.mit.edu  
Title: Mixtures of Eigenfeatures for Real-Time Structure from Texture  
Author: Tony Jebara, Kenneth Russell and Alex Pentland f jebara, kbrussel, sandy g 
Address: 20 Ames Street, Cambridge, MA 02139  
Affiliation: Massachusetts Institute of Technology  
Pubnum: Perceptual Computing, M.I.T. Media Laboratory  
Abstract: MIT Media Laboratory, Perceptual Computing Technical Report #440 Appears in: Proceedings of ICCV'98, Bombay, India, January 4-7, 1998 Abstract We describe a face modeling system which estimates complete facial structure and texture from a real-time video stream. The system begins with a face tracking algorithm which detects and stabilizes live facial images into a canonical 3D pose. The resulting canonical texture is then processed by a statistical model to filter imperfections and estimate unknown components such as missing pixels and underlying 3D structure. This statistical model is a soft mixture of eigenfea-ture selectors which span the 3D deformations and texture changes across a training set of laser scanned faces. An iterative algorithm is introduced for determining the dimensional partitioning of the eigenfea-tures to maximize their generalization capability over a cross-validation set of data. The model's abilities to filter and estimate absent facial components are then demonstrated over incomplete 3D data. This ultimately allows the model to span known and regress unknown facial information from stabilized natural video sequences generated by a face tracking algorithm. The resulting continuous and dynamic estimation of the model's parameters over a video sequence generates a compact temporal description of the 3D deformations and texture changes of the face. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Atick, P. Griffin, and N. Redlich. </author> <title> Statistical approach to shape from shading: Reconstruction of three-dimensional face surfaces from single two-dimensional images. </title> <journal> Neural Computation, </journal> <volume> 8, </volume> <year> 1997. </year>
Reference-contexts: 1 Introduction Several approaches have been proposed for the recovery of 3D structure from 2D imagery. These methods include shape from shading <ref> [1] </ref>, structure from motion [2] [4], stereo techniques, geometric modeling and other variants. We investigate the use of an appearance based technique for the recovery process. This approach models the correlation between the texture of a face and its 3D structure from a training set of 3D laser scanned faces. <p> Thus, the modular eigenspace can be a superset of the single eigenspace. The mixture of eigenfeatures used is composed of "softly" modular eigen spaces. Dimensions are scaled for each module by a value between <ref> [0; 1] </ref> to artificially weight different features and rotate the eigenvectors in their favor. In our training set fxg we have N M -dimensional vectors, i.e. x i with i*[1; N ].
Reference: [2] <author> A. Azarbayejani and A. Pentland. </author> <title> Recursive estimation of motion, structure and focal length. </title> <journal> IEEE Pattern Analysis and Machine Intelligence, </journal> <month> June </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Several approaches have been proposed for the recovery of 3D structure from 2D imagery. These methods include shape from shading [1], structure from motion <ref> [2] </ref> [4], stereo techniques, geometric modeling and other variants. We investigate the use of an appearance based technique for the recovery process. This approach models the correlation between the texture of a face and its 3D structure from a training set of 3D laser scanned faces. <p> Structure from motion is computed online as the 2D feature trackers follow the face and is then fed back to constrain their individual behavior and avoid feature loss. 6.4 Structure from Motion In <ref> [2] </ref>, structure from motion has been reformulated into a stable recursive estimation problem and been shown to converge reliably. The SfM algorithm is implemented as an extended Kalman filter which recovers an internal state vector x.
Reference: [3] <author> M. Bolduc, G. Sela, and M. Levine. </author> <title> Fast computation of multiscalar symmetry in foveated images. </title> <booktitle> In Proceedings of the Conference on Computer Architectures for Machine Perception, </booktitle> <pages> pages 2-11, </pages> <year> 1995. </year>
Reference-contexts: Then, a connected component analysis is used to group skin pixels into a large skin region. Using the detected skin contour, a window can be defined which is expected to contain the eyes. We then use the dark symmetry transform <ref> [3] </ref> [9] [6] as an eye detector. This is an annular sampling region which detects perceptually significant edge configurations that enclose an object. Dark axial symmetry is computed from a phase and edge map by wave propagation and subsequently we compute dark radial symmetry.
Reference: [4] <author> D. DeCarlo and D. Metaxas. </author> <title> Deformable model-based face shape and motion estimation. </title> <booktitle> In International Conference on Automatic Face and Gesture Recognition, </booktitle> <pages> pages 146-160, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Several approaches have been proposed for the recovery of 3D structure from 2D imagery. These methods include shape from shading [1], structure from motion [2] <ref> [4] </ref>, stereo techniques, geometric modeling and other variants. We investigate the use of an appearance based technique for the recovery process. This approach models the correlation between the texture of a face and its 3D structure from a training set of 3D laser scanned faces.
Reference: [5] <author> G. Hager and P. Belhumeur. </author> <title> Real time tracking of image regions with changes in geometry and illumination. </title> <booktitle> In CVPR96, </booktitle> <pages> pages 403-410, </pages> <year> 1996. </year>
Reference-contexts: After having determined the locations of facial features in the image as explained above, it is now possible to define a number of windows on the face which will be used for template matching via SSD or normalizaed correlation <ref> [5] </ref>. Eight tracking windows are initialized on the nose, mouth corners and the eyes as shown in Figure 12.
Reference: [6] <author> T. Jebara. </author> <title> 3D Pose Estimation and Normalization for Face Recognition. </title> <institution> McGill Centre for Intelligent Machines. McGill University, </institution> <year> 1996. </year> <note> Bachelor's Thesis. </note>
Reference-contexts: Then, a connected component analysis is used to group skin pixels into a large skin region. Using the detected skin contour, a window can be defined which is expected to contain the eyes. We then use the dark symmetry transform [3] [9] <ref> [6] </ref> as an eye detector. This is an annular sampling region which detects perceptually significant edge configurations that enclose an object. Dark axial symmetry is computed from a phase and edge map by wave propagation and subsequently we compute dark radial symmetry.
Reference: [7] <author> T. Jebara and A. Pentland. </author> <title> Parameterized structure from motion for 3d adaptive feedback tracking of faces. </title> <booktitle> In CVPR97, </booktitle> <pages> pages 144-150, </pages> <year> 1997. </year>
Reference-contexts: The system switches between these two modes using eigen-face measurements. If the object being tracked is a face, tracking continues. However, if the object being tracked is not face-like, reliable face detection is used to search the whole image for a new face (see <ref> [7] </ref>). 6.1 Facial Feature Detection Human skin forms a dense manifold in RGB color space which makes it an easy feature to detect in images. We obtain multiple training samples of skin and compute a mixture of Gaussians on the RGB values (using EM). <p> The mug-shot with the minimal DFFS (# 10) corresponds to the best possible nose localization (Figure 11 (b)). 6.3 2D Feature Tracking We now describe the tracking algorithm which tracks the facial features as the face undergoes large 3D variations <ref> [7] </ref>. After having determined the locations of facial features in the image as explained above, it is now possible to define a number of windows on the face which will be used for template matching via SSD or normalizaed correlation [5]. <p> For each frame, we also compute an appropriate weighting of the tracked features which depends on the current orientation and scale of the correlation trackers, their residual values and the spatial sensitivity characteristics of their corresponding texture <ref> [7] </ref>. Thus, the Kalman filter is adaptive and dynamically changes its confidence in the 2D feature tracking (via the noise covariance matrix R). <p> In addition, the point-wise depth structure (ff i ) is constrained by an eigenspace of structure formed by analyzing Cyber-ware depth data over the points we are tracking. So, the SfM is specialized and constrained to estimate facial structure as in Figure 13 <ref> [7] </ref>. 6.5 System Integration and Feedback We now go over the implementation details of the system integration and the feedback process. The system begins with the face detection loop and repeats until a face is detected (i.e. satisfies a threshold on distance from face-space).
Reference: [8] <author> B. Moghaddam and A. Pentland. </author> <title> Probabilistic visual learning for object detection. </title> <booktitle> In ICCV95, </booktitle> <pages> pages 786-793, </pages> <year> 1995. </year>
Reference-contexts: Dimensional scaling helps reduce the impact of certain features or eliminates them altogether. This is often done manually as a pre-processing step to limit an eigenspace so that it only spans the interesting components of the data and to favor more significant dimensions. For instance, Moghaddam and Pentland <ref> [8] </ref> use modular eigenspaces to compute PCA only over small windows centered at the eyes, the nose and mouth instead of the whole face. This prevents the eigenvec-tors from wasting modeling resources to span irrelevant features such as hair.
Reference: [9] <author> D. Reisfeld and Y. Yeshurun. </author> <title> Robust detection of facial features by generalized symmetry. </title> <booktitle> In ICPR92, </booktitle> <pages> pages I:117-120, </pages> <year> 1992. </year>
Reference-contexts: Then, a connected component analysis is used to group skin pixels into a large skin region. Using the detected skin contour, a window can be defined which is expected to contain the eyes. We then use the dark symmetry transform [3] <ref> [9] </ref> [6] as an eye detector. This is an annular sampling region which detects perceptually significant edge configurations that enclose an object. Dark axial symmetry is computed from a phase and edge map by wave propagation and subsequently we compute dark radial symmetry.
References-found: 9

