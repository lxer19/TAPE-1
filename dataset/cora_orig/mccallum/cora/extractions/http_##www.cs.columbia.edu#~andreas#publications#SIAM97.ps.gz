URL: http://www.cs.columbia.edu/~andreas/publications/SIAM97.ps.gz
Refering-URL: http://www.cs.columbia.edu/~andreas/publications/publications.html
Root-URL: http://www.cs.columbia.edu
Title: Extensible Resource Scheduling for Parallel Scientific Applications  
Author: Nayeem Islam Andreas Prodromidis Mark S. Squillante Ajei S. Gopal Liana L. Fong 
Abstract: The resource requirements and processing characteristics of parallel scientific applications are quite diverse. In this paper, we present a new resource management approach for scheduling such parallel applications that combines multiple scheduling paradigms with a fault-tolerance paradigm into a coherent system. Results from a prototype implementation demonstrate that our system provides significant performance improvements over existing methods in a controllable and extensible manner.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. A. Fakhouri, L. L. Fong, A. S. Gopal, N. Islam, J. A. Pershing, and M. S. Squillante, </author> <title> Milliways scheduling and membership design, </title> <type> Tech. Rep., </type> <institution> IBM Research Division, </institution> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: few experimental results from our prototype implementation are provided in x3, and our concluding remarks are presented in x4. 2 Resource Scheduling System Design Our resource scheduling system, which is based on a design and implementation study that explored scheduling and fault-tolerance services for large-scale distributed and parallel computing environments <ref> [1] </ref>, has many diverse aspects and makes several important contributions. The system design is based on a hierarchical scheduling architecture that supports and integrates the dynamic co-existence of multiple resource management 3 paradigms into a coherent and efficient system.
Reference: [2] <author> N. Islam, A. Prodromidis, and M. S. Squillante, </author> <title> Dynamic partitioning in different distributed-memory environments, in Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <booktitle> Lecture Notes in Comp. Sci. </booktitle> <volume> Vol. </volume> <pages> 1162. </pages>
Reference-contexts: However, for other application workloads, the overheads associated with greedy dynamic partitioning in distributed environments can generally eliminate its potential performance benefits <ref> [7, 2] </ref>. In this section we describe a new approach for dynamically adjusting the partitioning of resources at any level of our resource scheduling system hierarchy in a controllable manner while reducing the overheads associated with dynamic partitioning in large-scale parallel environments.
Reference: [3] <author> N. Islam, A. Prodromidis, M. S. Squillante, A. S. Gopal, and L. L. Fong, </author> <title> Extensible resource management for cluster computing, </title> <type> Tech. Rep. </type> <institution> RC 20526, IBM Research Division, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: Many different approaches have been employed to allocate resources under this paradigm, each with varying and limited degrees of success. However, an optimal scheduling strategy for this parallel environment has been recently established, which has been shown to provide significant performance improvements over other methods for coarse-grained applications <ref> [8, 3] </ref>. We refer to this paradigm as load sharing. <p> In the interest of space, we focus here on certain elements of our resource management system design. Specifically, we first present a brief overview of the system architecture, and then we describe certain aspects of our dynamic partitioning and gang scheduling strategies. We refer the interested reader to <ref> [3] </ref> for more details on these elements of our resource management system, as well as a description of the other system components. 2.1 System Architecture Overview Our resource scheduling system architecture is hierarchical. <p> This DLS function can use a number of different weights and measures (which are monitored by the system) to trigger and perform the repartitioning process. As a specific example, in our current prototype implementation <ref> [3] </ref> the system administrator specifies a threshold T d i;j for the load differential d i;j kU P d i U P d j k between each pair of partitions P d i and P d j (or the same threshold can be used for all partitions, i.e., T d i;j <p> Several parallel scientific applications, and diverse workloads based on mixtures of these applications, were used to study a large number of scheduling performance issues on this experimental platform. In this section we briefly present a small subset of our experimental results. We refer the interested reader to <ref> [3] </ref> for the details on our prototype implementation and application workloads, as well as for a detailed description of the complete set of experimental results. A fundamental premise of our system design is that no single scheduling paradigm provides the best performance for all parallel application workloads.
Reference: [4] <author> C. McCann and J. Zahorjan, </author> <title> Processor allocation policies for message-passing parallel computers, </title> <booktitle> in Proc. ACM SIGMETRICS Conf. Meas. Mod. Comp. Sys., </booktitle> <month> May </month> <year> 1994, </year> <pages> pp. 19-32. </pages>
Reference-contexts: One dynamic partitioning strategy for decreasing these performance penalties consists of using the folding approach found in <ref> [4] </ref>, which reduces the number of reconfigurations performed under dynamic partitioning, at the expense of a less optimal allocation of the nodes among the competing jobs.
Reference: [5] <author> D. L. Mills, </author> <title> Improved algorithms for synchronizing computer network clocks, </title> <journal> IEEE Trans. Networks, </journal> <year> (1995), </year> <pages> pp. 245-254. </pages>
Reference-contexts: Our approach consists of a general, software-based mechanism that is used to provide coordinated context-switching across the system nodes. Specifically, each node independently time-slices among the jobs allocated to it according to its local logical "time", and synchronized clocks are used to maintain consistent time across the nodes <ref> [5] </ref>. Since each node switches independently based on its local clock, the actual overhead of a simultaneous multi-node context switch in our system is no more expensive than a local context switch.
Reference: [6] <author> J. K. Ousterhout, </author> <title> Scheduling techniques for concurrent systems, </title> <booktitle> in Proc. Third Int. Conf. Dist. Comp. Sys., </booktitle> <month> Oct. </month> <year> 1982, </year> <pages> pp. 22-30. </pages>
Reference-contexts: Our resource management system integrates the time-sharing and space-sharing paradigms in a very natural and efficient manner, which can be conceptually viewed as a generalization of the global matrix originally proposed by Ousterhout <ref> [6] </ref>. The number of columns in the matrix equals the number of nodes reserved for the gang scheduling partition, and these columns are divided into K GS disjoint subpartitions K GS k , 1 k K GS .
Reference: [7] <author> M. S. Squillante, </author> <title> On the benefits and limitations of dynamic partitioning in parallel computer systems, in Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1995, </year> <pages> pp. 219-238. </pages> <booktitle> Lecture Notes in Comp. Sci. </booktitle> <volume> Vol. </volume> <pages> 949. </pages>
Reference-contexts: However, for other application workloads, the overheads associated with greedy dynamic partitioning in distributed environments can generally eliminate its potential performance benefits <ref> [7, 2] </ref>. In this section we describe a new approach for dynamically adjusting the partitioning of resources at any level of our resource scheduling system hierarchy in a controllable manner while reducing the overheads associated with dynamic partitioning in large-scale parallel environments. <p> This approach reduces the number of reconfigurations, decreases the total costs of repartitioning by performing multiple reconfigurations together, and prevents a form of reconfiguration thrashing <ref> [7] </ref>. It also tends to reduce the adverse effects of highly variable job arrivals, and tends to result in better system performance by batching multiple allocation decisions.
Reference: [8] <author> M. S. Squillante and K. P. Tsoukatos, </author> <title> Optimal scheduling of coarse-grained parallel applications, </title> <booktitle> in Proc. Eighth SIAM Conf. Par. Processing Sci. Comp., </booktitle> <month> Mar. </month> <year> 1997. </year>
Reference-contexts: Many different approaches have been employed to allocate resources under this paradigm, each with varying and limited degrees of success. However, an optimal scheduling strategy for this parallel environment has been recently established, which has been shown to provide significant performance improvements over other methods for coarse-grained applications <ref> [8, 3] </ref>. We refer to this paradigm as load sharing.
Reference: [9] <author> M. S. Squillante, F. Wang, and M. Papaefthymiou, </author> <title> Stochastic analysis of gang scheduling in parallel and distributed systems, </title> <booktitle> Perf. Eval., 27&28 (1996), </booktitle> <pages> pp. 273-296. </pages>
Reference-contexts: quanta to smaller job classes for each quantum allocated to larger job classes (i.e., smaller jobs can be placed in multiple rows of a subpartition of the matrix) so that small jobs receive very efficient response times and the overall mean response times are reduced, both in a controllable manner <ref> [9] </ref>. This organization for the gang-scheduling matrix is due in part to our distributed gang-scheduling design, which is in stark contrast to previous methods that employ centralized, tightly-coupled and/or hardware-based control mechanisms.
References-found: 9

