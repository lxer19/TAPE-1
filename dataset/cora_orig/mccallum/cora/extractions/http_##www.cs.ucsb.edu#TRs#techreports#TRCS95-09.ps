URL: http://www.cs.ucsb.edu/TRs/techreports/TRCS95-09.ps
Refering-URL: http://www.cs.ucsb.edu/TRs/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fberto,mionescu,schauser,chrissg@cs.ucsb.edu  
Title: LogGP: Incorporating Long Messages into the LogP Model One step closer towards a realistic model
Author: Albert Alexandrov, Mihai F. Ionescu, Klaus E. Schauser, and Chris Scheiman 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California, Santa Barbara  
Abstract: We present a new model of parallel computationthe LogGP modeland use it to analyze a number of algorithms, most notably, the single node scatter (one-to-all personalized broadcast). The LogGP model is an extension of the LogP model for parallel computation [CKP + 93] which abstracts the communication of fixed-sized short messages through the use of four parameters: the communication latency (L), overhead (o), bandwidth (g), and the number of processors (P ). As evidenced by experimental data, the LogP model can accurately predict communication performance when only short messages are sent (as on the CM-5) [CKP + 93, CDMS94]. However, many existing parallel machines have special support for long messages and achieve a much higher bandwidth for long messages compared to short messages (e.g., IBM SP-2, Paragon, Meiko CS-2, Ncube/2). We extend the basic LogP model with a linear model for long messages. This combination, which we call the LogGP model of parallel computation, has one additional parameter, G, which captures the bandwidth obtained for long messages. Experimental data collected on the Meiko CS-2 shows that this simple extension of the LogP model can quite accurately predict communication performance for both short and long messages. This paper discusses algorithm design and analysis under the new model, examining the all-to-all remap, FFT, and radix sort. We also examine, in more detail, the single node scatter problem. We derive solutions for this problem and prove their optimality under the LogGP model. These solutions are qualitatively different from those obtained under the simpler LogP model, reflecting the importance of capturing long messages in a model.
Abstract-found: 1
Intro-found: 1
Reference: [AC94] <author> B. Alpern and L. Carter. </author> <title> Towards a Model for Portable Parallel Performance: Exposing the Memory Hierarchy. </title> <editor> In T. Hey and J. Ferrante, editors, </editor> <title> Portability and Performance for Parallel Processing. </title> <publisher> Wiley, </publisher> <year> 1994. </year> <month> 19 </month>
Reference-contexts: Others include network models for a variety of topologies [Lei92], sparse networks [Sny86], models which take the memory hierarchy into account <ref> [AC94] </ref>, or models based on communication primitives more powerful than simple point-to-point messages [Ble87]. There are also special models for shared memory computation, e.g., the CICO model [LCW94]. Some models address several of the above aspects.
Reference: [ACS89] <author> A. Aggarwal, A. K. Chandra, and M. Snir. </author> <title> On Communication Latency in PRAM Computation. </title> <booktitle> In Proceedings of the ACM Symposium on Parallel Algorithms and Architectures. ACM, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: As a consequence, a variety of alternative models have been developed, each capturing different aspects of real parallel machines, such as memory contention [MV84, KLMadH92], asynchronous execution [Gib89, CZ89], communication latency <ref> [PY88, ACS89] </ref>, or communication bandwidth [ACS90]. Others include network models for a variety of topologies [Lei92], sparse networks [Sny86], models which take the memory hierarchy into account [AC94], or models based on communication primitives more powerful than simple point-to-point messages [Ble87].
Reference: [ACS90] <author> A. Aggarwal, A. K. Chandra, and M. Snir. </author> <title> Communication Complexity of PRAMs. </title> <booktitle> In Theoretical Computer Science, </booktitle> <month> March </month> <year> 1990. </year>
Reference-contexts: As a consequence, a variety of alternative models have been developed, each capturing different aspects of real parallel machines, such as memory contention [MV84, KLMadH92], asynchronous execution [Gib89, CZ89], communication latency [PY88, ACS89], or communication bandwidth <ref> [ACS90] </ref>. Others include network models for a variety of topologies [Lei92], sparse networks [Sny86], models which take the memory hierarchy into account [AC94], or models based on communication primitives more powerful than simple point-to-point messages [Ble87]. There are also special models for shared memory computation, e.g., the CICO model [LCW94].
Reference: [BBB + 94] <author> V. Bala, J. Bruck, R. Bryant, R. Cypher, P. de Jong, P. Elustondo, D. Frye, A. Ho, C-T. Ho, G. Irwin, S. Kipnis, R. Lawrence, and M. Snir. </author> <title> The IBM external user interface for scalable parallel systems. </title> <journal> Parallel Computing, </journal> <volume> 20(4), </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: However, many existing parallel machines have special support for long messages which provide a much higher bandwidth than short messages (e.g., IBM SP-2 <ref> [BBB + 94] </ref>, Paragon [Pie94], Meiko CS-2 [BCM94], Ncube/2 [SV94]). Even low overhead communication architectures, such as the generic active message specification [CKL + 94], support bulk transfers. The LogP model only deals with short messages and does not adequately model machines with support for long messages.
Reference: [BBC + 94] <author> V. Bala, J. Bruck, R. Cypher, P. Elustondo, A. Ho, C-T. Ho, S. Kipnis, and M. Snir. </author> <title> CCL: a portable and tunable collective communication library for scalable parallel computers. </title> <booktitle> In 8th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: Then all the keys destined for a particular processor are sent at once. This intermediate local sorting step does not occur in the short message version. 4 The Scatter Problem Collective communication is frequently used in parallel computation and is often built out of point-to-point communication primitives <ref> [BBC + 94] </ref>. In this section we study a specific communication problem in more detail, the single node scatter problem [BT89], also known as the one-to-all personalized broadcast.
Reference: [BCM94] <author> E. Bartson, J. Cownie, and M. McLaren. </author> <title> Message passing on the Meiko CS-2. </title> <journal> Parallel Computing, </journal> <volume> 20(4), </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: However, many existing parallel machines have special support for long messages which provide a much higher bandwidth than short messages (e.g., IBM SP-2 [BBB + 94], Paragon [Pie94], Meiko CS-2 <ref> [BCM94] </ref>, Ncube/2 [SV94]). Even low overhead communication architectures, such as the generic active message specification [CKL + 94], support bulk transfers. The LogP model only deals with short messages and does not adequately model machines with support for long messages.
Reference: [Ble87] <author> G. E. Blelloch. </author> <title> Scans as Primitive Parallel Operations. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1987. </year>
Reference-contexts: Others include network models for a variety of topologies [Lei92], sparse networks [Sny86], models which take the memory hierarchy into account [AC94], or models based on communication primitives more powerful than simple point-to-point messages <ref> [Ble87] </ref>. There are also special models for shared memory computation, e.g., the CICO model [LCW94]. Some models address several of the above aspects.
Reference: [BNK92] <author> A. Bar-Noy and S. Kipnis. </author> <title> Designing broadcasting algorithms in the postal model for message-passing systems. </title> <booktitle> In Proceedings of the ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: There are also special models for shared memory computation, e.g., the CICO model [LCW94]. Some models address several of the above aspects. For example, the BSP [Val90], the Postal model <ref> [BNK92] </ref>, and LogP [CKP + 93] all capture both communication latency and bandwidth through parameters. 1 The LogP model, in addition, captures the communication overhead, i.e., the time it takes for a processor to send or receive a message. <p> For example, the single item and k-item (non-personalized) broadcast problem has been studied under the Postal <ref> [BNK92] </ref> and LogP model [KSSS93]. The scatter problem has received much less attention. It has been studied for specific topologies such as the mesh and hypercube assuming fixed size packets [JH89, SS89, BOS + 91]. 17 The Binomial Tree algorithm for the scatter problem is not new.
Reference: [BOS + 91] <author> D. P. Bertsekas, C. Ozveran, G. D. Stamoulis, P. Tseng, and J. N. Tsitsiklis. </author> <title> Optimal Communication Algorithms for Hypercubes. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 11, </volume> <year> 1991. </year>
Reference-contexts: For example, the single item and k-item (non-personalized) broadcast problem has been studied under the Postal [BNK92] and LogP model [KSSS93]. The scatter problem has received much less attention. It has been studied for specific topologies such as the mesh and hypercube assuming fixed size packets <ref> [JH89, SS89, BOS + 91] </ref>. 17 The Binomial Tree algorithm for the scatter problem is not new. In [JH89] the problem was studied assuming a hypercube network and a linear model for large message transfer (t + nt c ).
Reference: [BT89] <author> D. Bertsekas and J. Tsitsiklis. </author> <title> Parallel and Distributed Computation. </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: In this section we study a specific communication problem in more detail, the single node scatter problem <ref> [BT89] </ref>, also known as the one-to-all personalized broadcast. This problem is of special interest to us because it exhibits the essential difference between the LogGP 8 model and the simpler LogP model. The LogGP algorithms discussed so far are obvious extensions of the corresponding short-message (LogP) algorithms.
Reference: [CDG + 93] <author> D. E. Culler, A. Dusseau, S. C. Golstein, A. Krishnamurthy, S. Lumetta, T. von Eicken, and K. Yelick. </author> <title> Parallel Programming in Split-C. </title> <booktitle> In Proc. of Supercomputing, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: The LogGP parameters for the Meiko CS-2 are shown in Table 1. We show two sets of parameters, corresponding to two communication libraries. One is Meiko's own low-level Elan library [HM93], and the other is an implementation of Split-C <ref> [CDG + 93] </ref> (a parallel extension of C) based on active messages [vECGS92, SS95]. In both cases, we measured the parameters by timing a loop which repeats the relevant communication primitive many times to minimize timer overhead. To validate the model we focus on two questions.
Reference: [CDMS94] <author> D. E. Culler, A. Dusseau, R. Martin, and K. E. Schauser. </author> <title> Fast Parallel Sorting under LogP: from theory to practice. </title> <editor> In T. Hey and J. Ferrante, editors, </editor> <title> Portability and Performance for Parallel Processing. </title> <publisher> Wiley, </publisher> <year> 1994. </year>
Reference-contexts: Communication is modeled by point-to-point messages of some fixed short size. Thus, the model has implicitly a fifth parameter, the message size w. As evidenced by experimental data collected on the CM-5 [TM94], this model can accurately predict communication performance when only fixed-sized short messages are sent <ref> [CKP + 93, CDMS94, LC94] </ref>. However, many existing parallel machines have special support for long messages which provide a much higher bandwidth than short messages (e.g., IBM SP-2 [BBB + 94], Paragon [Pie94], Meiko CS-2 [BCM94], Ncube/2 [SV94]). <p> The LogP model would fail to explain this improvement. We now examine two applications: FFT and radix sort. For both applications, we have two versions of the algorithms: the original versions from <ref> [CKP + 93, CDMS94] </ref>, based on short messages, and the bulk versions which we restructured to use long messages for data transfer. A comparison of the two versions of the FFT algorithm is shown in Figure 5.
Reference: [CKL + 94] <author> D. E. Culler, K. Keeton, L. T. Liu, A. Mainwaring, R. Martin, S. Rodrigues, and K. Wright. </author> <title> Generic Active Message Interface Specification. </title> <institution> UC Berkeley, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: However, many existing parallel machines have special support for long messages which provide a much higher bandwidth than short messages (e.g., IBM SP-2 [BBB + 94], Paragon [Pie94], Meiko CS-2 [BCM94], Ncube/2 [SV94]). Even low overhead communication architectures, such as the generic active message specification <ref> [CKL + 94] </ref>, support bulk transfers. The LogP model only deals with short messages and does not adequately model machines with support for long messages. Our work addresses this shortcoming by extending the LogP model with a linear model for long messages.
Reference: [CKP + 93] <author> D. E. Culler, R. M. Karp, D. A. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a Realistic Model of Parallel Computation. </title> <booktitle> In Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: There are also special models for shared memory computation, e.g., the CICO model [LCW94]. Some models address several of the above aspects. For example, the BSP [Val90], the Postal model [BNK92], and LogP <ref> [CKP + 93] </ref> all capture both communication latency and bandwidth through parameters. 1 The LogP model, in addition, captures the communication overhead, i.e., the time it takes for a processor to send or receive a message. <p> The LogP model reflects the convergence of parallel machines towards systems formed by a collection of complete computers, each consisting of a microprocessor, cache and large DRAM memory, connected by a communication network <ref> [CKP + 93] </ref>. The LogP model for parallel computation models communication performance through the use of four parameters: the communication latency (L), overhead (o), bandwidth (g), and the number of processors (P ). Communication is modeled by point-to-point messages of some fixed short size. <p> Communication is modeled by point-to-point messages of some fixed short size. Thus, the model has implicitly a fifth parameter, the message size w. As evidenced by experimental data collected on the CM-5 [TM94], this model can accurately predict communication performance when only fixed-sized short messages are sent <ref> [CKP + 93, CDMS94, LC94] </ref>. However, many existing parallel machines have special support for long messages which provide a much higher bandwidth than short messages (e.g., IBM SP-2 [BBB + 94], Paragon [Pie94], Meiko CS-2 [BCM94], Ncube/2 [SV94]). <p> The results show a close match. Section 5 summarizes the work and concludes. 2 2 The LogGP model We use the LogP model <ref> [CKP + 93] </ref> as a basis for our work, and extend it with a simple linear model for long messages. The resulting model, which we call LogGP, can model both short and long messages. <p> The LogP model would fail to explain this improvement. We now examine two applications: FFT and radix sort. For both applications, we have two versions of the algorithms: the original versions from <ref> [CKP + 93, CDMS94] </ref>, based on short messages, and the bulk versions which we restructured to use long messages for data transfer. A comparison of the two versions of the FFT algorithm is shown in Figure 5.
Reference: [CZ89] <author> R. Cole and O. Zajicek. </author> <title> The APRAM: Incorporating asynchrony into the PRAM model. </title> <booktitle> In Proceedings of the Symposium on Parallel Architectures and Algorithms, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: As a consequence, a variety of alternative models have been developed, each capturing different aspects of real parallel machines, such as memory contention [MV84, KLMadH92], asynchronous execution <ref> [Gib89, CZ89] </ref>, communication latency [PY88, ACS89], or communication bandwidth [ACS90]. Others include network models for a variety of topologies [Lei92], sparse networks [Sny86], models which take the memory hierarchy into account [AC94], or models based on communication primitives more powerful than simple point-to-point messages [Ble87].
Reference: [FW78] <author> S. Fortune and J. Wyllie. </author> <title> Parallelism in Random Access Machines. </title> <booktitle> In Proceedings of the 10th Annual Symposium on Theory of Computing, </booktitle> <month> May </month> <year> 1978. </year>
Reference-contexts: 1 Introduction To guide parallel algorithm designers, a simple but accurate model of parallel computation is needed. The frequently used PRAM model <ref> [FW78, KR90] </ref> is useful for a gross classification of parallel algorithms, but unfortunately, it is not well suited for predicting performance on actual parallel machines.
Reference: [Gib89] <author> P. B. Gibbons. </author> <title> A More Practical PRAM Model. </title> <booktitle> In Proceedings of the ACM Symposium on Parallel Algorithms and Architectures. ACM, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: As a consequence, a variety of alternative models have been developed, each capturing different aspects of real parallel machines, such as memory contention [MV84, KLMadH92], asynchronous execution <ref> [Gib89, CZ89] </ref>, communication latency [PY88, ACS89], or communication bandwidth [ACS90]. Others include network models for a variety of topologies [Lei92], sparse networks [Sny86], models which take the memory hierarchy into account [AC94], or models based on communication primitives more powerful than simple point-to-point messages [Ble87].
Reference: [HM93] <author> M. Homewood and M. McLaren. </author> <title> Meiko CS-2 Interconnect Elan-Elite Design. </title> <booktitle> In Proc. of Hot Interconnects, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: Our experimental platform is a 64 node Meiko CS-2. The CS-2 consists of Sparc based nodes connected via a fat tree communication network <ref> [HM93] </ref>. Running a slightly enhanced version of the Solaris 2.3 operating system on every node, it closely resembles a cluster of workstations connected by a fast network. Each node contains a 40 MHz SuperSparc processor with 1 MB external cache and 32 MB of main memory. <p> The LogGP parameters for the Meiko CS-2 are shown in Table 1. We show two sets of parameters, corresponding to two communication libraries. One is Meiko's own low-level Elan library <ref> [HM93] </ref>, and the other is an implementation of Split-C [CDG + 93] (a parallel extension of C) based on active messages [vECGS92, SS95]. In both cases, we measured the parameters by timing a loop which repeats the relevant communication primitive many times to minimize timer overhead.
Reference: [Hoc94] <author> R. Hockney. </author> <title> Performance Parameters and Results for the Genesis Parallel Benchmarks. </title> <editor> In T. Hey and J. Ferrante, editors, </editor> <title> Portability and Performance for Parallel Processing. </title> <publisher> Wiley, </publisher> <year> 1994. </year>
Reference-contexts: Communication models for long messages usually model the time to send an n byte message by a linear model, t = t 0 + t B fl n, where t 0 is the startup time and t B is the time per byte <ref> [Hoc94, KGGK94] </ref>. The startup time t 0 lumps into a single parameter the overhead and latency differentiated in the LogP model. While combining these parameters may be appropriate for long messages, we believe that this is not sufficiently detailed for short fixed-size messages.
Reference: [JH89] <author> S. L. Johnsson and C. T. Ho. </author> <title> Optimum broadcasting and personalized communication in hypercubes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(9), </volume> <month> September </month> <year> 1989. </year>
Reference-contexts: For example, the single item and k-item (non-personalized) broadcast problem has been studied under the Postal [BNK92] and LogP model [KSSS93]. The scatter problem has received much less attention. It has been studied for specific topologies such as the mesh and hypercube assuming fixed size packets <ref> [JH89, SS89, BOS + 91] </ref>. 17 The Binomial Tree algorithm for the scatter problem is not new. In [JH89] the problem was studied assuming a hypercube network and a linear model for large message transfer (t + nt c ). <p> The scatter problem has received much less attention. It has been studied for specific topologies such as the mesh and hypercube assuming fixed size packets [JH89, SS89, BOS + 91]. 17 The Binomial Tree algorithm for the scatter problem is not new. In <ref> [JH89] </ref> the problem was studied assuming a hypercube network and a linear model for large message transfer (t + nt c ). Their binomial tree algorithm is identical to ours if they assume a sufficiently large packet size, and thus, has the same complexity.
Reference: [KGGK94] <author> V. Kumar, A. Grama, A. Gupta, and G. Karypis. </author> <title> Introduction to Parallel Computing. </title> <publisher> Benjamin Cummings, </publisher> <year> 1994. </year>
Reference-contexts: Communication models for long messages usually model the time to send an n byte message by a linear model, t = t 0 + t B fl n, where t 0 is the startup time and t B is the time per byte <ref> [Hoc94, KGGK94] </ref>. The startup time t 0 lumps into a single parameter the overhead and latency differentiated in the LogP model. While combining these parameters may be appropriate for long messages, we believe that this is not sufficiently detailed for short fixed-size messages.
Reference: [KLMadH92] <author> R. M. Karp, M. Luby, and F. Meyer auf der Heide. </author> <title> Efficient PRAM Simulation on a Distributed Memory Machine. </title> <booktitle> In Proceedings of the Twenty-Fourth Annual ACM Symposium of the Theory of Computing, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: As a consequence, a variety of alternative models have been developed, each capturing different aspects of real parallel machines, such as memory contention <ref> [MV84, KLMadH92] </ref>, asynchronous execution [Gib89, CZ89], communication latency [PY88, ACS89], or communication bandwidth [ACS90]. Others include network models for a variety of topologies [Lei92], sparse networks [Sny86], models which take the memory hierarchy into account [AC94], or models based on communication primitives more powerful than simple point-to-point messages [Ble87].
Reference: [KR90] <author> R. M. Karp and V. Ramachandran. </author> <title> Parallel Algorithms for Shared-Memory Machines. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science. </booktitle> <publisher> Elsevier Science Publishers, </publisher> <year> 1990. </year> <month> 20 </month>
Reference-contexts: 1 Introduction To guide parallel algorithm designers, a simple but accurate model of parallel computation is needed. The frequently used PRAM model <ref> [FW78, KR90] </ref> is useful for a gross classification of parallel algorithms, but unfortunately, it is not well suited for predicting performance on actual parallel machines.
Reference: [KSSS93] <author> R. Karp, A. Sahay, E. Santos, and K. E. Schauser. </author> <title> Optimal Broadcast and Summation in the LogP Model. </title> <booktitle> In 5th Symp. on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: For example, the single item and k-item (non-personalized) broadcast problem has been studied under the Postal [BNK92] and LogP model <ref> [KSSS93] </ref>. The scatter problem has received much less attention. It has been studied for specific topologies such as the mesh and hypercube assuming fixed size packets [JH89, SS89, BOS + 91]. 17 The Binomial Tree algorithm for the scatter problem is not new.
Reference: [LC94] <author> L. T. Liu and D. E. Culler. </author> <title> Measurements of Active Messages Performance on the CM-5. </title> <type> Technical Report UCB/CSD 94-807, </type> <institution> CS Div., UC Berkeley, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: Communication is modeled by point-to-point messages of some fixed short size. Thus, the model has implicitly a fifth parameter, the message size w. As evidenced by experimental data collected on the CM-5 [TM94], this model can accurately predict communication performance when only fixed-sized short messages are sent <ref> [CKP + 93, CDMS94, LC94] </ref>. However, many existing parallel machines have special support for long messages which provide a much higher bandwidth than short messages (e.g., IBM SP-2 [BBB + 94], Paragon [Pie94], Meiko CS-2 [BCM94], Ncube/2 [SV94]).
Reference: [LCW94] <author> J. R. Laurus, S. Chandra, and D. A. Wood. CICO: </author> <title> A Practical Shared-Memory Programming Performance Model. </title> <editor> In T. Hey and J. Ferrante, editors, </editor> <title> Portability and Performance for Parallel Processing. </title> <publisher> Wiley, </publisher> <year> 1994. </year>
Reference-contexts: Others include network models for a variety of topologies [Lei92], sparse networks [Sny86], models which take the memory hierarchy into account [AC94], or models based on communication primitives more powerful than simple point-to-point messages [Ble87]. There are also special models for shared memory computation, e.g., the CICO model <ref> [LCW94] </ref>. Some models address several of the above aspects.
Reference: [Lei92] <author> F. T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes. </title> <publisher> Morgan Kaufman, </publisher> <year> 1992. </year>
Reference-contexts: As a consequence, a variety of alternative models have been developed, each capturing different aspects of real parallel machines, such as memory contention [MV84, KLMadH92], asynchronous execution [Gib89, CZ89], communication latency [PY88, ACS89], or communication bandwidth [ACS90]. Others include network models for a variety of topologies <ref> [Lei92] </ref>, sparse networks [Sny86], models which take the memory hierarchy into account [AC94], or models based on communication primitives more powerful than simple point-to-point messages [Ble87]. There are also special models for shared memory computation, e.g., the CICO model [LCW94]. Some models address several of the above aspects.
Reference: [MV84] <author> K. Mehlhorn and U. Vishkin. </author> <title> Randomized and deterministic simulations of PRAMs by parallel machines with restricted granularity of parallel memories. </title> <journal> Acta Informatica, </journal> <volume> 21(4), </volume> <month> November </month> <year> 1984. </year>
Reference-contexts: As a consequence, a variety of alternative models have been developed, each capturing different aspects of real parallel machines, such as memory contention <ref> [MV84, KLMadH92] </ref>, asynchronous execution [Gib89, CZ89], communication latency [PY88, ACS89], or communication bandwidth [ACS90]. Others include network models for a variety of topologies [Lei92], sparse networks [Sny86], models which take the memory hierarchy into account [AC94], or models based on communication primitives more powerful than simple point-to-point messages [Ble87].
Reference: [Pie94] <author> P. Pierce. </author> <title> The NX message passing interface. </title> <journal> Parallel Computing, </journal> <volume> 20(4), </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: However, many existing parallel machines have special support for long messages which provide a much higher bandwidth than short messages (e.g., IBM SP-2 [BBB + 94], Paragon <ref> [Pie94] </ref>, Meiko CS-2 [BCM94], Ncube/2 [SV94]). Even low overhead communication architectures, such as the generic active message specification [CKL + 94], support bulk transfers. The LogP model only deals with short messages and does not adequately model machines with support for long messages.
Reference: [PY88] <author> C. H. Papadimitriou and M. Yannakakis. </author> <title> Towards an Architecture-Independent Analysis of Parallel Algorithms. </title> <booktitle> In Proceedings of the Twentieth Annual ACM Symposium of the Theory of Computing. ACM, </booktitle> <month> May </month> <year> 1988. </year>
Reference-contexts: As a consequence, a variety of alternative models have been developed, each capturing different aspects of real parallel machines, such as memory contention [MV84, KLMadH92], asynchronous execution [Gib89, CZ89], communication latency <ref> [PY88, ACS89] </ref>, or communication bandwidth [ACS90]. Others include network models for a variety of topologies [Lei92], sparse networks [Sny86], models which take the memory hierarchy into account [AC94], or models based on communication primitives more powerful than simple point-to-point messages [Ble87].
Reference: [Sny86] <author> L. Snyder. </author> <title> Type Architectures, Shared Memory, and the Corollary of Modest Potential. In Ann. Rev. </title> <publisher> Comput. Sci. Annual Reviews Inc., </publisher> <year> 1986. </year>
Reference-contexts: As a consequence, a variety of alternative models have been developed, each capturing different aspects of real parallel machines, such as memory contention [MV84, KLMadH92], asynchronous execution [Gib89, CZ89], communication latency [PY88, ACS89], or communication bandwidth [ACS90]. Others include network models for a variety of topologies [Lei92], sparse networks <ref> [Sny86] </ref>, models which take the memory hierarchy into account [AC94], or models based on communication primitives more powerful than simple point-to-point messages [Ble87]. There are also special models for shared memory computation, e.g., the CICO model [LCW94]. Some models address several of the above aspects.
Reference: [SS89] <author> Y. Saad and M. H. Schultz. </author> <title> Data communication in hypercubes. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 6(1), </volume> <month> February </month> <year> 1989. </year>
Reference-contexts: For example, the single item and k-item (non-personalized) broadcast problem has been studied under the Postal [BNK92] and LogP model [KSSS93]. The scatter problem has received much less attention. It has been studied for specific topologies such as the mesh and hypercube assuming fixed size packets <ref> [JH89, SS89, BOS + 91] </ref>. 17 The Binomial Tree algorithm for the scatter problem is not new. In [JH89] the problem was studied assuming a hypercube network and a linear model for large message transfer (t + nt c ).
Reference: [SS95] <author> K. E. Schauser and C. J. Scheiman. </author> <title> Experience with Active Messages on the Meiko CS-2. </title> <booktitle> In 9th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: We show two sets of parameters, corresponding to two communication libraries. One is Meiko's own low-level Elan library [HM93], and the other is an implementation of Split-C [CDG + 93] (a parallel extension of C) based on active messages <ref> [vECGS92, SS95] </ref>. In both cases, we measured the parameters by timing a loop which repeats the relevant communication primitive many times to minimize timer overhead. To validate the model we focus on two questions.
Reference: [SV94] <author> M. Schmidt-Voigt. </author> <title> Efficient parallel communication with the nCUBE 2S processor. </title> <journal> Parallel Computing, </journal> <volume> 20(4), </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: However, many existing parallel machines have special support for long messages which provide a much higher bandwidth than short messages (e.g., IBM SP-2 [BBB + 94], Paragon [Pie94], Meiko CS-2 [BCM94], Ncube/2 <ref> [SV94] </ref>). Even low overhead communication architectures, such as the generic active message specification [CKL + 94], support bulk transfers. The LogP model only deals with short messages and does not adequately model machines with support for long messages.
Reference: [TM94] <author> L. W. Tucker and A. Mainwaring. </author> <title> CMMD: Active messages on the CM-5. </title> <journal> Parallel Computing, </journal> <volume> 20(4), </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: Communication is modeled by point-to-point messages of some fixed short size. Thus, the model has implicitly a fifth parameter, the message size w. As evidenced by experimental data collected on the CM-5 <ref> [TM94] </ref>, this model can accurately predict communication performance when only fixed-sized short messages are sent [CKP + 93, CDMS94, LC94].
Reference: [Val90] <author> L. G. Valiant. </author> <title> A Bridging Model for Parallel Computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8), </volume> <month> August </month> <year> 1990. </year>
Reference-contexts: There are also special models for shared memory computation, e.g., the CICO model [LCW94]. Some models address several of the above aspects. For example, the BSP <ref> [Val90] </ref>, the Postal model [BNK92], and LogP [CKP + 93] all capture both communication latency and bandwidth through parameters. 1 The LogP model, in addition, captures the communication overhead, i.e., the time it takes for a processor to send or receive a message.
Reference: [vECGS92] <author> T. von Eicken, D. E. Culler, S. C. Goldstein, and K. E. Schauser. </author> <title> Active Messages: a Mechanism for Integrated Communication and Computation. </title> <booktitle> In Proc. of the 19th Int'l Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1992. </year> <month> 21 </month>
Reference-contexts: We show two sets of parameters, corresponding to two communication libraries. One is Meiko's own low-level Elan library [HM93], and the other is an implementation of Split-C [CDG + 93] (a parallel extension of C) based on active messages <ref> [vECGS92, SS95] </ref>. In both cases, we measured the parameters by timing a loop which repeats the relevant communication primitive many times to minimize timer overhead. To validate the model we focus on two questions.
References-found: 37

