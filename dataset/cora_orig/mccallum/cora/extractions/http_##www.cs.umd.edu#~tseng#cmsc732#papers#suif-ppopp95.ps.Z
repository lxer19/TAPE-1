URL: http://www.cs.umd.edu/~tseng/cmsc732/papers/suif-ppopp95.ps.Z
Refering-URL: http://www.cs.umd.edu/~tseng/cmsc732/papers.html
Root-URL: 
Title: Data and Computation Transformations for Multiprocessors  
Author: Jennifer M. Anderson, Saman P. Amarasinghe and Monica S. Lam 
Address: CA 94305  
Affiliation: Computer Systems Laboratory Stanford University,  
Abstract: Effective memory hierarchy utilization is critical to the performance of modern multiprocessor architectures. We have developed the first compiler system that fully automatically parallelizes sequential programs and changes the original array layouts to improve memory system performance. Our optimization algorithm consists of two steps. The first step chooses the parallelization and computation assignment such that synchronization and data sharing are minimized. The second step then restructures the layout of the data in the shared address space with an algorithm that is based on a new data transformation framework. We ran our compiler on a set of application programs and measured their performance on the Stanford DASH multiprocessor. Our results show that the compiler can effectively optimize parallelism in conjunction with memory subsystem performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal, D. Chaiken, G. D'Souza, K. Johnson, and D. Kranz et. al. </author> <title> The MIT Alewife machine: A large-scale distributed memory multiprocessor. In Scalable Shared Memory Multiprocessors. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: This is true for bus-based shared address space machines [11, 12], and even more so for scalable shared address space machines [8], such as the Stanford DASH multiprocessor [24], MIT ALEWIFE <ref> [1] </ref>, Kendall Square's KSR-1 [21], and the Convex This research was supported in part by ARPA contracts DABT63-91-K-0003 and DABT63-94-C-0054, an NSF Young Investigator Award and fellowships from Digital Equipment Corporation's Western Research Laboratory and Intel Corporation.
Reference: [2] <author> A. Agarwal, D. Kranz, and V. Natarajan. </author> <title> Automatic parition-ing of parallel loops for cache-coherent multiprocessors. </title> <booktitle> In Proceedings of the 1993 International Conference on Parallel Processing, </booktitle> <address> St. Charles, IL, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Recently a number of algorithms for finding data and/or computation decompositions automatically have been proposed <ref> [2, 4, 5, 7, 15, 25, 26] </ref>. In keeping with our observation that communication in efficient parallel programs is infrequent, our algorithm is unique in that it offers a simple procedure to find the largest available degree of parallelism that requires no major data communication [4].
Reference: [3] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <note> second edition, </note> <year> 1986. </year>
Reference-contexts: Simple extensions to standard compiler techniques such as loop invariant removal and induction variable recognition can move some of the division and modulo operators out of inner loops <ref> [3] </ref>. We have developed an additional set of optimizations that exploit the fundamental properties of these operations [14], as well as the specialized knowledge the compiler has about these address calculations. The optimizations, described below, have proved to be important and effective.
Reference: [4] <author> J. M. Anderson and M. S. Lam. </author> <title> Global optimizations for parallelism and locality on scalable parallel machines. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 112-125, </pages> <address> Albu-querque, NM, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Recently a number of algorithms for finding data and/or computation decompositions automatically have been proposed <ref> [2, 4, 5, 7, 15, 25, 26] </ref>. In keeping with our observation that communication in efficient parallel programs is infrequent, our algorithm is unique in that it offers a simple procedure to find the largest available degree of parallelism that requires no major data communication [4]. <p> In keeping with our observation that communication in efficient parallel programs is infrequent, our algorithm is unique in that it offers a simple procedure to find the largest available degree of parallelism that requires no major data communication <ref> [4] </ref>. We present a brief overview of the algorithm, and readers are referred to [4] for more details. 3.1 Representation Our algorithm represents loop nests and arrays as multi-dimensional spaces. <p> with our observation that communication in efficient parallel programs is infrequent, our algorithm is unique in that it offers a simple procedure to find the largest available degree of parallelism that requires no major data communication <ref> [4] </ref>. We present a brief overview of the algorithm, and readers are referred to [4] for more details. 3.1 Representation Our algorithm represents loop nests and arrays as multi-dimensional spaces. <p> This is a difficult problem since the compiler must map the decompositions across the procedure boundaries. The inter-procedural analysis must be able to handle array reshapes and array sections passed as parameters. Previously, our implementation was limited by procedure boundaries <ref> [4] </ref>. We have now implemented a prototype of an inter-procedural version of this algorithm that was used for the experiments described in Section 6. 3.3 Example We now use the code shown in Figure 1 (a) to illustrate our algorithm. <p> By analyzing across the loops in the program, the computation decomposition algorithm finds a static block column-wise distribution. This version of the program exploits doall parallelism in the first phase of ADI, switching to doall/pipeline parallelism the second half of the computation to minimize true-sharing communication <ref> [4, 18] </ref>. Loops enclosed within the doacross loop are tiled to increase the granularity of pipelining, thus reducing synchronization overhead. The optimized version of ADI achieves a speedup of 23 on 32 processors.
Reference: [5] <author> B. Appelbe and B. Lakshmanan. </author> <title> Optimizing parallel programs using affinity regions. </title> <booktitle> In Proceedings of the 1993 International Conference on Parallel Processing, </booktitle> <pages> pages 246-249, </pages> <address> St. Charles, IL, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Recently a number of algorithms for finding data and/or computation decompositions automatically have been proposed <ref> [2, 4, 5, 7, 15, 25, 26] </ref>. In keeping with our observation that communication in efficient parallel programs is infrequent, our algorithm is unique in that it offers a simple procedure to find the largest available degree of parallelism that requires no major data communication [4].
Reference: [6] <author> U. Banerjee, R. Eigenmann, A. Nicolau, and D. Padua. </author> <title> Automatic program parallelization. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 81(2) </volume> <pages> 211-243, </pages> <month> February </month> <year> 1993. </year> <month> 12 </month>
Reference-contexts: While loop transformation is relatively well understood, data transformation is not. In this paper, we show that various well-known data layouts can be derived as a combination of two simple primitives: strip-mining and permutation. Both of these transforms have a direct analog in the theory of loop transformations <ref> [6, 35] </ref>. The techniques described in this paper are all implemented in the SUIF compiler system [33]. Our compiler takes sequential C or FORTRAN programs as input and generates optimized SPMD (Single Program Multiple Data) C code fully automatically. <p> step restructures the arrays so that all the data accessed by the same processor are contiguous in the shared address space. 4.1 Data Transformation Model To facilitate the design of our data layout algorithm, we have developed a data transformation model that is analogous to the well-known loop transformation theory <ref> [6, 35] </ref>. We represent an n-dimensional array as an n-dimensional polytope whose boundaries are given by the array bounds, and the interior integer points represent all the elements in the array. As with sequential loops, the ordering of the axes is significant.
Reference: [7] <author> B. Bixby, K. Kennedy, and U. Kremer. </author> <title> Automatic data layout using 0-1 integer programming. </title> <booktitle> In Proceedings of the International Conference on Parallel Architectures and Compilation Techniques (PACT), </booktitle> <pages> pages 111-122, </pages> <address> Montreal, Canada, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: Recently a number of algorithms for finding data and/or computation decompositions automatically have been proposed <ref> [2, 4, 5, 7, 15, 25, 26] </ref>. In keeping with our observation that communication in efficient parallel programs is infrequent, our algorithm is unique in that it offers a simple procedure to find the largest available degree of parallelism that requires no major data communication [4].
Reference: [8] <author> W. J. Bolosky and M. L. Scott. </author> <title> False sharing and its effect on shared memory performance. </title> <booktitle> In Proceedings of the USENIX Symposium on Experiences with Distributed and Multiprocessor Systems (SEDMS IV), </booktitle> <pages> pages 57-71, </pages> <address> San Diego, CA, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: Making effective use of the memory hierarchy on multiprocessors is even more important to performance, but also more difficult. This is true for bus-based shared address space machines [11, 12], and even more so for scalable shared address space machines <ref> [8] </ref>, such as the Stanford DASH multiprocessor [24], MIT ALEWIFE [1], Kendall Square's KSR-1 [21], and the Convex This research was supported in part by ARPA contracts DABT63-91-K-0003 and DABT63-94-C-0054, an NSF Young Investigator Award and fellowships from Digital Equipment Corporation's Western Research Laboratory and Intel Corporation.
Reference: [9] <author> S. Carr, K. S. M c Kinley, and C.-W. Tseng. </author> <title> Compiler optimizations for improving data locality. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <pages> pages 252-262, </pages> <address> San Jose, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: Given that the processor-memory gap continues to widen, exploiting the memory hierarchy is critical to achieving high performance on modern architectures. Recent work on code transformations to improve cache performance has been shown to improve uniprocessor system performance significantly <ref> [9, 34] </ref>. Making effective use of the memory hierarchy on multiprocessors is even more important to performance, but also more difficult. <p> Here we address the memory hierarchy optimization problems that are specific to multiprocessors; the algorithm described in the paper can be followed with techniques that improve locality on uniprocessor code <ref> [9, 13, 34] </ref>. Uniprocessor cache optimization techniques are outside the scope of this paper. <p> IF (x.ge.64) THEN x = xst ENDIF 20 CONTINUE 5 Related Work and Comparison Previous work on compiler algorithms for optimizing memory hierarchy performance has focused primarily on loop transformations. Unimodular loop transformations, loop fusion and loop nest blocking restructure computation to increase uniprocessor cache re-use <ref> [9, 13, 34] </ref>. Copying data into contiguous regions has been studied as a means for reducing cache interference [23, 29]. Several researchers have proposed algorithms to transform computation and data layouts to improve memory system performance [10, 20].
Reference: [10] <author> M. Cierniak and W. Li. </author> <title> Unifying data and control transformations for distributed shared memory machines. </title> <type> Technical Report TR-542, </type> <institution> Department of Computer Science, University of Rochester, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: Copying data into contiguous regions has been studied as a means for reducing cache interference [23, 29]. Several researchers have proposed algorithms to transform computation and data layouts to improve memory system performance <ref> [10, 20] </ref>. The same optimizations are intended to change the data access patterns to improve locality on both unipro-cessors and shared address space multiprocessors. For the multiprocessor case, they assume that decision of which loops to parallelize has already been determined.
Reference: [11] <author> S. J. Eggers and T. E. Jeremiassen. </author> <title> Eliminating false sharing. </title> <booktitle> In Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <pages> pages 377-381, </pages> <address> St. Charles, IL, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: Recent work on code transformations to improve cache performance has been shown to improve uniprocessor system performance significantly [9, 34]. Making effective use of the memory hierarchy on multiprocessors is even more important to performance, but also more difficult. This is true for bus-based shared address space machines <ref> [11, 12] </ref>, and even more so for scalable shared address space machines [8], such as the Stanford DASH multiprocessor [24], MIT ALEWIFE [1], Kendall Square's KSR-1 [21], and the Convex This research was supported in part by ARPA contracts DABT63-91-K-0003 and DABT63-94-C-0054, an NSF Young Investigator Award and fellowships from Digital
Reference: [12] <author> S. J. Eggers and R. H. Katz. </author> <title> The effect of sharing on the cache and bus performance of parallel programs. </title> <booktitle> In Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-III), </booktitle> <pages> pages 257-270, </pages> <address> Boston, MA, </address> <month> April </month> <year> 1989. </year>
Reference-contexts: Recent work on code transformations to improve cache performance has been shown to improve uniprocessor system performance significantly [9, 34]. Making effective use of the memory hierarchy on multiprocessors is even more important to performance, but also more difficult. This is true for bus-based shared address space machines <ref> [11, 12] </ref>, and even more so for scalable shared address space machines [8], such as the Stanford DASH multiprocessor [24], MIT ALEWIFE [1], Kendall Square's KSR-1 [21], and the Convex This research was supported in part by ARPA contracts DABT63-91-K-0003 and DABT63-94-C-0054, an NSF Young Investigator Award and fellowships from Digital
Reference: [13] <author> D. Gannon, W. Jalby, and K. Gallivan. </author> <title> Strategies for cache and local memory management by global program transformation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5(5) </volume> <pages> 587-616, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Here we address the memory hierarchy optimization problems that are specific to multiprocessors; the algorithm described in the paper can be followed with techniques that improve locality on uniprocessor code <ref> [9, 13, 34] </ref>. Uniprocessor cache optimization techniques are outside the scope of this paper. <p> IF (x.ge.64) THEN x = xst ENDIF 20 CONTINUE 5 Related Work and Comparison Previous work on compiler algorithms for optimizing memory hierarchy performance has focused primarily on loop transformations. Unimodular loop transformations, loop fusion and loop nest blocking restructure computation to increase uniprocessor cache re-use <ref> [9, 13, 34] </ref>. Copying data into contiguous regions has been studied as a means for reducing cache interference [23, 29]. Several researchers have proposed algorithms to transform computation and data layouts to improve memory system performance [10, 20].
Reference: [14] <author> R. L. Graham, D. E. Knuth, and O. Patashnik. </author> <title> Concrete Mathematics. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: Simple extensions to standard compiler techniques such as loop invariant removal and induction variable recognition can move some of the division and modulo operators out of inner loops [3]. We have developed an additional set of optimizations that exploit the fundamental properties of these operations <ref> [14] </ref>, as well as the specialized knowledge the compiler has about these address calculations. The optimizations, described below, have proved to be important and effective. Our first optimization takes advantage of the fact that a processor often addresses only elements within a single strip-mined partition of the array.
Reference: [15] <author> M. Gupta and P. Banerjee. </author> <title> Demonstration of automatic data partitioning techniques for parallelizing compilers on multi-computers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(2) </volume> <pages> 179-193, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Recently a number of algorithms for finding data and/or computation decompositions automatically have been proposed <ref> [2, 4, 5, 7, 15, 25, 26] </ref>. In keeping with our observation that communication in efficient parallel programs is infrequent, our algorithm is unique in that it offers a simple procedure to find the largest available degree of parallelism that requires no major data communication [4].
Reference: [16] <author> J. L. Hennessy and D. A. Patterson. </author> <booktitle> Computer Architecture </booktitle>
Reference-contexts: 1 Introduction In the last decade, microprocessor speeds have been steadily improving at a rate of 50% to 100% every year <ref> [16] </ref>. Meanwhile, memory access times have been improving at the rate of only 7% per year [16]. A common technique used to bridge this gap between processor and memory speeds is to employ one or more levels of caches. <p> 1 Introduction In the last decade, microprocessor speeds have been steadily improving at a rate of 50% to 100% every year <ref> [16] </ref>. Meanwhile, memory access times have been improving at the rate of only 7% per year [16]. A common technique used to bridge this gap between processor and memory speeds is to employ one or more levels of caches. However, it has been notoriously difficult to use caches effectively for numeric applications. <p> In this way, no interprocessor communication or synchronization is necessary. Due to characteristics found in typical data caches, it is not sufficient to just minimize sharing between processors. First, data are transferred in fixed-size units known as cache lines, which are typically 4 to 128 bytes long <ref> [16] </ref>. A computation is said to have spatial locality if it uses multiple words in a cache line before the line is displaced from the cache. While spatial locality is a consideration for both uni- and multiprocessors, false sharing is unique to multiprocessors.
References-found: 16

