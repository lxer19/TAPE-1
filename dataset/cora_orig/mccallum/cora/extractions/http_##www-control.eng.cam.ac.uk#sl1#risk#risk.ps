URL: http://www-control.eng.cam.ac.uk/sl1/risk/risk.ps
Refering-URL: http://www-control.eng.cam.ac.uk/Homepage/Papers.html
Root-URL: 
Title: A game theoretic approach to moving horizon control  
Author: Sanjay Lall and Keith Glover 
Abstract: A control law is constructed for a linear time varying system by solving a two player zero sum differential game on a moving horizon, the game being that which is used to construct an H 1 controller on a finite horizon. Conditions are given under which this controller results in a stable system and satisfies an infinite horizon H 1 norm bound. A risk sensitive formulation is used to provide a state estimator in the observation feedback case.
Abstract-found: 1
Intro-found: 1
Reference: <author> Anderson, B. D. O. & Moore, J. B. </author> <year> (1989), </year> <title> Optimal Control Linear Quadratic Methods, </title> <publisher> Prentice Hall. </publisher>
Reference: <author> Basar, T. & Bernhard, P. </author> <year> (1991), </year> <title> H 1 Optimal Control and Related Minimax Design Problems. A Dynamic Game Approach, Systems and Control: Foundations and Applications, </title> <publisher> Birkhauser. </publisher>
Reference-contexts: and P satisfies _ P = A 0 P + P A P (B 2 B 0 1 )P + C 0 then, if both sides exist, P (t; 1 ; F ( 1 )) P (t; 2 ; F ( 2 )); t 1 2 Proof We know (see <ref> (Basar & Bernhard 1991) </ref>) x (t i ) 0 P (t i ; t f ; F (t f ))x (t i ) = (8) u w t i then (i) If ~ C 1 (t) 0 ~ C 1 (t) C 1 (t) 0 C 1 (t) 8t 2 [t <p> In recent years H 1 theory has been furnished with a certainty equivalence principle in several different formulations (Doyle et al. 1989, Whittle 1990, Basar & Bernhard 1991). For the finite horizon time varying H 1 problem Basar and Bernhard <ref> (Basar & Bernhard 1991, p. 119) </ref> give a derivation of the optimal estimator for output feedback. <p> (t i ) = ^x 0 x = (I fl 2 Y 1 X 1 ) 1 ^x Then the optimal risk sensitive feedback control law is given by u = B 0 10 This has exactly the form of an H 1 controller (see, for example, Basar and Bernhard <ref> (Basar & Bernhard 1991, pp. 124-126) </ref>) with unknown weighted initial state. However, it is important to note that the assumptions are very different, and that w is white noise. In the moving horizon case, we only need u (t) at t = t i .
Reference: <author> Basar, T. & Olsder, G. J. </author> <year> (1982), </year> <title> Dynamic Noncooperative Game Theory, </title> <booktitle> Mathematics in Science and Engineering, </booktitle> <publisher> Academic Press. </publisher>
Reference-contexts: saddle point solution u (t) = fl (t; x (t)), w (t) = -fl (t; x (t)) will satisfy J fl ( fl ; w) J fl ( fl ; -fl ) J fl (u; -fl ) 8u; w 2 L 2 [t i ; t f ]: Theorem 1 <ref> (Basar & Olsder 1982, Limebeer, Anderson, Khargonekar & Green 1992) </ref> J fl (u; w) = t i z (t) 0 z (t) fl 2 w (t) 0 w (t) dt + x (t f ) 0 F x (t f ) where F &gt; 0 is some weighting matrix.
Reference: <author> Bucy, R. S. </author> <year> (1967), </year> <title> `Global theory of the riccati equation', </title> <journal> Journal of Computer and System Sciences 1, </journal> <pages> 349-361. </pages>
Reference: <author> Chen, C. C. & Shaw, L. </author> <year> (1982), </year> <title> `On receding horizon feedback control', </title> <type> Automatica 18(3), </type> <pages> 349-352. </pages>
Reference: <author> Doyle, J. C., Glover, K., Khargonekar, P. P. & Francis, B. A. </author> <year> (1989), </year> <title> `State-space solutions to standard H 2 and H 1 control problems', </title> <journal> IEEE Transactions on Automatic Control 34(8), </journal> <pages> 831-847. </pages>
Reference-contexts: For the moving horizon controller we only need to know this strategy at time t = t i . In recent years H 1 theory has been furnished with a certainty equivalence principle in several different formulations <ref> (Doyle et al. 1989, Whittle 1990, Basar & Bernhard 1991) </ref>. For the finite horizon time varying H 1 problem Basar and Bernhard (Basar & Bernhard 1991, p. 119) give a derivation of the optimal estimator for output feedback.
Reference: <author> Glover, K. & Doyle, J. C. </author> <year> (1988), </year> <title> `State-space formulae for all stabilizing controllers that satisfy an H 1 -norm bound and relations to risk sensitivity', </title> <journal> Systems and Control Letters 11, </journal> <pages> 167-172. </pages>
Reference-contexts: In order to do this, we need a stochastic model for H 1 control. 5.1 Risk sensitive control There is a strong connection between the formulation of risk sensitive control developed by Whittle (Whittle 1990) and H 1 control. This is specified in <ref> (Glover & Doyle 1988) </ref>. We consider here the system described by equations (1 - 3). However, we now change our assumptions so that w is white noise with covariance function ffi (t)I, the identity matrix multiplied by a delta function. <p> Let where in this case (t; y (t)) is a policy, and E indicates the expectation when the input is u (t) = (t; y (t)). The risk sensitive control problem is min L fl where M is the space of all policy functions . Glover and Doyle <ref> (Glover & Doyle 1988) </ref> show that this is equivalent to an H 1 problem. However, in this case, a sufficient statistic for the initial conditions are the mean and variance of the initial state.
Reference: <author> Kalman, R. E. </author> <year> (1960), </year> <title> `Contributions to the theory of optimal control', </title> <institution> Boletin de la Sociedad Matematica Mexicana 5(1), </institution> <note> 102-119. 13 Khargonekar, </note> <author> P. P., Nagpal, K. M. & Poolla, K. R. </author> <year> (1991), </year> <title> `H 1 control with transients', </title> <journal> SIAM Journal on Control and Optimization 29(6), </journal> <pages> 1373-1393. </pages>
Reference-contexts: Bounds for Y 2 are given by Kalman <ref> (Kalman 1960) </ref>.
Reference: <author> Kleinman, D. L. </author> <year> (1970), </year> <title> `An easy way to stabilize a linear constant system', </title> <journal> IEEE Transactions on Automatic Control p. </journal> <volume> 692. </volume>
Reference-contexts: 1 Introduction The moving horizon control technique was developed in the 1970's, with one of the first papers being that by Kleinman <ref> (Kleinman 1970) </ref> in 1970. The techniques in his paper were later reformulated and generalized by various authors, see for example (Chen & Shaw 1982, Kwon & Pearson 1977, Kwon, Bruckstein & Kailath 1983).
Reference: <author> Kwon, W. H., Bruckstein, A. M. & Kailath, T. </author> <year> (1983), </year> <title> `Stabilizing state-feedback design via the moving horizon method', </title> <journal> International Journal of Control 37(3), </journal> <pages> 631-643. </pages>
Reference-contexts: The solution to this problem was given in terms of a Riccati differential equation, integrated backwards from time t + T at each time t. For time varying systems, this gives a practical method of stabilising the system. Kwon et. al. <ref> (Kwon et al. 1983) </ref> formulated a general procedure for the recursive update of such Riccati equations, which generalise easily to the indefinite Riccati equations in this paper. Further, this method allows stabilization of systems which are known only for the short term future. <p> The linear quadratic problem with a similar terminal weight was considered by Kwon, Bruckstein and Kailath <ref> (Kwon et al. 1983) </ref>. We use a modified form of their methods to handle the terminal weight. <p> The following results are derived in a slightly different way in <ref> (Kwon et al. 1983) </ref>, and various similar results can be found in (Anderson & Moore 1989, Reid 1970, Bucy 1967, Ran & Vreugdenhil 1988, Basar & Bernhard 1991). <p> This requires the solution of a Riccati differential equation over the interval [t; t + T ] for each time t, given boundary conditions P (t; t + T; F (t + T )) = F (t + T ) for all t &gt; 0. Kwon, Bruckstein and Kailath <ref> (Kwon et al. 1983) </ref> applied results from scattering theory in their solution to the quadratic problem, to give a forwards differential equation for P (t; t + T; F (t + T )). Here we state the same solution for the indefinite Riccati equation.
Reference: <author> Kwon, W. H. & Pearson, A. E. </author> <year> (1977), </year> <title> `A modified quadratic cost problem and feedback stabilization of a linear system', </title> <journal> IEEE Transactions on Automatic Control 22(5), </journal> <pages> 838-842. </pages>
Reference-contexts: The techniques in his paper were later reformulated and generalized by various authors, see for example (Chen & Shaw 1982, Kwon & Pearson 1977, Kwon, Bruckstein & Kailath 1983). Kwon and Pearson <ref> (Kwon & Pearson 1977) </ref> proved stability for linear time varying systems using a controller which optimised a quadratic cost function integrated over a time interval from the current time t to a fixed distance ahead t + T .
Reference: <author> Limebeer, D. J., Anderson, B. D. O., Khargonekar, P. P. & Green, M. </author> <year> (1992), </year> <title> `A game theoretic approach to H 1 control for time varying systems', </title> <journal> SIAM Journal on Control and Optimization 30(2), </journal> <pages> 262-283. </pages>
Reference: <author> Mayne, D. Q. & Michalska, H. </author> <year> (1990), </year> <title> `Receding horizon control of nonlinear systems', </title> <journal> IEEE Transactions on Automatic Control 35(7), </journal> <pages> 814-824. </pages>
Reference: <author> Ran, A. C. M. & Vreugdenhil, R. </author> <year> (1988), </year> <title> `Existence and comparison theorems for algebraic riccati equations for continuous and discrete time systems', Linear Algebra and its applications 99, </title> <type> 63-83. </type>
Reference: <author> Ravi, R., Nagpal, K. M. & Khargonekar, P. P. </author> <year> (1991), </year> <title> `H 1 control of linear time varying systems: A state space approach', </title> <journal> SIAM Journal on Control and Optimization 29(6), </journal> <pages> 1394-1413. </pages>
Reference: <author> Reid, W. T. </author> <year> (1970), </year> <title> Riccati Differential Equations, </title> <publisher> Academic Press. </publisher>
Reference: <author> Tadmor, G. </author> <year> (1992), </year> <title> `Receding horizon revisited: An easy way to robustly stabilize an ltv system', </title> <journal> Systems and Control Letters 18, </journal> <pages> 285-294. </pages>
Reference-contexts: The moving horizon method can be viewed as a compromise between these two methods. The aim of this present paper is to extend the work of Tadmor <ref> (Tadmor 1992) </ref>, in which a receding horizon controller is formulated with each finite horizon optimisation based upon an 1 H 1 optimisation. It is hoped that the practical advantages of receding horizon control might be combined with the robustness advantages of H 1 control. <p> (t) = B 2 (t) 0 P (t; t + T )x (t) In the case when all system matrices A; B 1 ; B 2 ; C 1 ; D 12 are time invariant, then P (t; t + T ) is independent of t also. 3.3 Stability Tadmor <ref> (Tadmor 1992) </ref> proves stability for the above controller when F = 1. In this case, we can consider the Riccati equation for P 1 and the interpretation on the finite horizon is that the controller is subject to the constraint x (t + T ) = 0. <p> Tadmor <ref> (Tadmor 1992) </ref> proves that P (t; t + T; 1) is bounded above and below. <p> 1 (t 0 ; t 1 ) is uniformly bounded for all t 1 t 0 T , then there exists fl &gt; 0 such that P (t; t + T; F (t + T )) is bounded above for all t &gt; 0. 3.4 Infinite horizon norm bounds Following <ref> (Tadmor 1992) </ref>, with the controller u (t) = B 2 (t) 0 P (t; t + T; F (t + T ))x (t) and w 2 L 2 [t 0 ; 1] we know Z 1 d n o Z 1 ( 1 P x fl 2 x 0 P B
Reference: <author> Tadmor, G. </author> <year> (1993), </year> <title> `The standard H 1 problem and the maximum principle: the general linear case', </title> <journal> SIAM Journal on Control and Optimization 31(4), </journal> <pages> 813-846. </pages>
Reference-contexts: The other is to design fully for time varying systems. In the case of both linear quadratic and H 1 controllers, this requires the backwards integration from infinity of a Riccati equation (see for example <ref> (Tadmor 1993, Ravi, Nagpal & Khargonekar 1991) </ref>), and somewhat optimistically assumes knowledge of the system throughout future time. The moving horizon method can be viewed as a compromise between these two methods.
Reference: <author> Uchida, K. & Fujita, M. </author> <year> (1992), </year> <title> `Finite horizon H 1 control problems with terminal penalties', </title> <journal> IEEE Transactions on Automatic Control 37(11), </journal> <pages> 1762-1767. </pages>
Reference-contexts: For the finite horizon problem, typically the assumptions made are that the initial state at the beginning of each optimization interval is completely known, or is completely unknown. In the latter case it is treated as part of the disturbance and subject to a quadratic weighting <ref> (Uchida & Fujita 1992) </ref> (Khargonekar, Nagpal & Poolla 1991). In the receding horizon problem, though, we have observations from before the optimization interval.
Reference: <author> Verghese, G., Friedlander, B. & Kailath, T. </author> <year> (1980), </year> <title> `Scattering theory and linear least squares estimation, part iii: The estimates', </title> <journal> IEEE Transactions on Automatic Control 25(4), </journal> <pages> 794-802. </pages>
Reference-contexts: Kwon, Bruckstein and Kailath (Kwon et al. 1983) applied results from scattering theory in their solution to the quadratic problem, to give a forwards differential equation for P (t; t + T; F (t + T )). Here we state the same solution for the indefinite Riccati equation. See <ref> (Verghese, Friedlander & Kailath 1980) </ref> for details on the derivation of these formulae. In this section, P (t; ) is used to mean P (t; ; 0).
Reference: <author> Whittle, P. </author> <year> (1990), </year> <title> Risk-sensitive optimal control, Wiley Interscience series in Systems and Optimization, </title> <publisher> Wiley. </publisher> <pages> 14 </pages>
Reference-contexts: In the receding horizon problem, though, we have observations from before the optimization interval. We attempt to make use of prior observations using the theory of risk sensitive control, as developed by Whittle <ref> (Whittle 1990) </ref>, which has been shown to be equivalent to H 1 control in many situations. 2 Preliminaries We consider the system _x (t) = A (t)x (t) + B 1 (t)w (t) + B 2 (t)u (t) (1) y (t) = C 2 (t)x (t) + D 21 (t)w (t) <p> In order to do this, we need a stochastic model for H 1 control. 5.1 Risk sensitive control There is a strong connection between the formulation of risk sensitive control developed by Whittle <ref> (Whittle 1990) </ref> and H 1 control. This is specified in (Glover & Doyle 1988). We consider here the system described by equations (1 - 3). However, we now change our assumptions so that w is white noise with covariance function ffi (t)I, the identity matrix multiplied by a delta function. <p> If the system has been running previous to the implementation of a risk sensitive controller, these can be provided by a Kalman filter. The solution to the risk sensitive control problem is given by Whittle <ref> (Whittle 1990) </ref>: Theorem 6 If there exists an X 1 0 satisfying _ X 1 = A 0 X 1 + X 1 A X 1 (B 0 1 )X 1 + C 0 and Y 1 satisfying _ Y 1 = AY 1 + Y 1 A 0 Y 1
References-found: 21

