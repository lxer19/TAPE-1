URL: ftp://ftp.eecs.umich.edu/people/marcush/spie92_vision.ps
Refering-URL: http://www.aic.nrl.navy.mil/~aswu/papers.html
Root-URL: 
Title: Computer vision for CARMEL  
Author: Marcus J. Huber, Clint Bidlack, David Kortenkamp, Kevin Mangis, Doug Baker, Annie Wu, Terry Weymouth 
Address: Ann Arbor, Michigan 48109-2110  
Affiliation: Artificial Intelligence Laboratory The University of Michigan  
Abstract: In this paper we discuss the implementation and uses of the object recognition system used for CARMEL, the University of Michigan's winning entry in the AAAI-92 Autonomous Robot Competition. Following the rules of the competition, the robot was required to navigate within a large, unstructured environment performing exploration, and then a directed search, for objects placed throughout the arena. CARMEL was completely autonomous and performed these tasks, in part, using computer vision techniques. The tasks required of the computer vision system consisted of actively searching for objects (four inch diameter tubes marked with black and white stripe patterns), detecting them in images, uniquely identifying each object based upon its distinguishing pattern, and determining each object's position from orientation and distance estimates measured from the image. We briefly describe the design of the various computer vision algorithms that were developed to perform these tasks. Because of the accuracy and robustness of the vision system, we were able to perform absolute positioning, where the robot accurately updated its position through backward triangulation from previously located objects. The success of CARMEL stemmed largely from the use and implementation of the vision system to perform the tasks listed above. Other teams chose to approach these same tasks using different sensory systems and/or techniques. We analyze the general approaches, looking at where they excelled and failed, in terms of their actual performance and in general, perhaps giving insight into how to build autonomous robots that can successfully operate in "natural" environments. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Johann Borenstein and Yoram Koren. </author> <title> The Vector Field Histogram for fast obstacle-avoidance for mobile robots. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 7(3), </volume> <year> 1991. </year>
Reference-contexts: To overcome these problems, Borenstein and Koren developed an obstacle avoidance method called the vector field histogram (see <ref> [1] </ref> for a thorough description of VFH). The VFH method uses a two dimensional Cartesian grid, called the histogram grid, to represent data from ultrasonic (or other) range sensors.
Reference: [2] <author> Johann Borenstein and Yoram Koren. </author> <title> Noise rejection for ultrasonic sensors in mobile robot applications. </title> <booktitle> In The Proceedings of the IEEE Conference on Robotics and Automation, </booktitle> <year> 1992. </year>
Reference-contexts: A separate processor manages the firing sequence of the sensors and the subsequent filtering of noise and crosstalk (see <ref> [2] </ref> for a detailed description of the design of EERUF, the error eliminating rapid ultrasonic firing system designed by Borenstein and Koren). This firing sequence and filtering process allows CARMEL to rapidly fire and sample the ultrasonic sensors for fast obstacle avoidance.
Reference: [3] <author> Charles Cohen and Frank Koss. </author> <title> A comprehensive study of three-object triangulation. </title> <booktitle> In SPIE Mobile Robots VII, </booktitle> <year> 1992. </year>
Reference-contexts: CARMEL uses an absolute positioning algorithm based on circle intersection (see <ref> [3] </ref> for an overview of three object absolute positioning algorithms).
Reference: [4] <author> Thomas Dean and R. Peter Bonasso. </author> <title> 1992 AAAI robot exhibition and competition. </title> <journal> AI Magazine, </journal> <month> Spring, </month> <year> 1993. </year>
Reference-contexts: Each of the teams were permitted the opportunity to design their own objects so as to not handicap any team by imposing perception characteristics, such as having to use a particular sensing modality. A complete description of the competition guidelines, competitors, and results can be found in <ref> [4] </ref>.
Reference: [5] <author> David Kortenkamp, Marcus Huber, Clare Bates Congdon, Scott Huffman, Clint Bidlack, Charles Cohen, , Frank Koss, Ulrich Raschke, and Terry Weymouth. </author> <title> Integrating obstacle avoidance, global path planning, visual cue detection and landmark triangulation in a mobile robot. </title> <booktitle> In Proceedings of SPIE Mobile Robots VII, </booktitle> <year> 1992. </year>
Reference-contexts: CARMEL was totally lacking any other sensing or high level planning system until work began on the robot competition in January of 1992. For a more thorough description of the design and architecture of CARMEL, see <ref> [5] </ref>. 2.1.1 Sensors CARMEL's current suite of sensors are: * Odometry Wheel encoders maintain the robot's position and orientation. Errors in the estimation of the distance traveled accumulates relatively slowly, and have a small impact on CARMEL's uncertainty in its position.
References-found: 5

