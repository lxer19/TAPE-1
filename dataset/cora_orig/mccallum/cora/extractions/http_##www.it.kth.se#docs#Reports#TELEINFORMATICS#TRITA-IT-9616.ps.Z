URL: http://www.it.kth.se/docs/Reports/TELEINFORMATICS/TRITA-IT-9616.ps.Z
Refering-URL: http://www.it.kth.se/docs/Reports/TELEINFORMATICS/
Root-URL: http://www.it.kth.se
Title: A Survey of Compiler Techniques for Adapting Programs to Memory Hierarchies and Distributed Execution  
Author: N. P. Drakenberg TRITA-IT R : 
Affiliation: Department of Teleinformatics  
Pubnum: ISSN 1103-534X ISRN KTH/IT/R|96/16|SE  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Walid Abu-Sufah, David J. Kuck, and Duncan H. Lawrie. </author> <title> On the performance enhancement of paging systems through program analysis and transformations. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-30(5):341-355, </volume> <month> May </month> <year> 1981. </year> <month> 33 </month>
Reference-contexts: Composing the iteration vector of a statement with a label uniquely identifying the statement, like in hS 4 ; <ref> [2; 1] </ref> T i, gives a label which identifies each run-time instance of a statement uniquely. Now that different run-time instances of statements can be distinguished, the definition of execution order must be extended to encompass statement instances. <p> As in previous sections loop transformations can be applied to improve reuse of data, this time data in physical memory. Abu-Sufah et al. is an early reference discussing the application of loop transformations to reduce paging <ref> [1] </ref>. They describe how loop distribution and loop fusion can be applied to reduce paging. Similarly [13] claim to improve paging behaviour even though their performance model, discussed in section 5.2.2, attempts to express cache behaviour.
Reference: [2] <author> Gagan Agrawal and Joel Saltz. </author> <title> Interprocedural compilation of irregular applications for distributed memory machines. </title> <type> Technical report, </type> <institution> UMIACS and Dept. of Computer Science, Univ. of Maryland, College Park, MD 20742, </institution> <year> 1995. </year>
Reference-contexts: Composing the iteration vector of a statement with a label uniquely identifying the statement, like in hS 4 ; <ref> [2; 1] </ref> T i, gives a label which identifies each run-time instance of a statement uniquely. Now that different run-time instances of statements can be distinguished, the definition of execution order must be extended to encompass statement instances. <p> Currently, compilers seem <ref> [20, 2] </ref> to rely on external libraries, such as PARTI [81], for communication preprocessing and dynamically optimized communication. Further optimization of inspector/executor code can be achieved by analyzing references (e.g., updates) to indirection arrays and how these influence the computations of communication sets. <p> Further optimization of inspector/executor code can be achieved by analyzing references (e.g., updates) to indirection arrays and how these influence the computations of communication sets. Optimizations of this type are discussed in <ref> [2, 39, 89] </ref>. 7 Discussion We have looked at a few compiler techniques for improved exploitation of data locality.
Reference: [3] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <title> Compilers | Priciples, Techniques, and Tools. </title> <publisher> Addison Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1986. </year>
Reference-contexts: Development of compiler code-generators and optimizers is an area where computational efficiency is the major concern, and where efficiency is ultimately measured using real programs 1 and real hardware. Nevertheless, work in this area has traditionally <ref> [3] </ref> focused on reducing the number of instructions 2 executed, and has traditionally ignored the effects of cache memory and other system components, on efficiency. <p> This information is also easily derived automatically, and it is techniques for solving such problems, at varying degrees of sophistication, which has formed the core of optimizing compilers for the last couple of decades <ref> [3] </ref>. It is also easily seen that the statements above must be performed in the order written, i.e., first statement S 1 then statement S 2 , or else the results will not be the same. <p> Traditionally, different run-time instances of statements and different array elements are not distinguished during program analysis <ref> [3] </ref>. Instead program analysis usually searches for facts which are invariant over all run-time instances of each statement, which usually means that array references are seen as referencing all or large parts of the array and doing so in an arbitrary way. <p> By introducing reaching decompositions [42] this problem becomes strikingly similar to the reaching definitions problem and can be solved in a manner similar to reaching definitions <ref> [3] </ref>. Once the possible alignments and distributions are known, this information is used to derive the sets of iterations to execute on each processor and the sets of indices of array elements that must be communicated between processors.
Reference: [4] <author> Corinne Ancourt and Francois Irigoin. </author> <title> Scanning polyhedra with DO loops. </title> <booktitle> In Proc. third SIGPLAN Symp. on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 39-50. </pages> <publisher> ACM Press, </publisher> <month> April </month> <year> 1991. </year>
Reference-contexts: The integer linear programming approach is not theoretically as restricted as the former approaches (anything linear can be handled), but scanning polyhedral index sets which may result from this approach is in general quite complicated <ref> [4] </ref>, and may often be inefficient.
Reference: [5] <author> David F. Bacon, Susan L. Graham, and Oliver J. Sharp. </author> <title> Compiler transformations for high-performance computing. </title> <journal> Computing Surveys, </journal> <volume> 26(4) </volume> <pages> 345-420, </pages> <year> 1994. </year>
Reference-contexts: An extensive set of program transformations is presented and discussed in <ref> [5] </ref>, also the already mentioned books by Wolfe [96] and Zima and Chapman [98] cover this type of transformations.
Reference: [6] <author> Utpal Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer Academic Publisher, </publisher> <address> Boston, MA, </address> <year> 1988. </year>
Reference-contexts: Examples of such methods are: the GCD-test [85] and Banerjee's inequalities <ref> [6] </ref>. Dependence testing, in its simplest form, gives only "yes" or "no" answers, revealing nothing about the nature of the dependence.
Reference: [7] <author> Utpal Banerjee. </author> <title> Unimodular transformations of double loops. </title> <editor> In A. Nicolau et al., editors, </editor> <booktitle> Advances in Languages and Compilers for Parallel Processing, Research Monographs in Parallel and Distributed Computing, chapter 10. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1991. </year>
Reference-contexts: An extensive set of program transformations is presented and discussed in [5], also the already mentioned books by Wolfe [96] and Zima and Chapman [98] cover this type of transformations. It has since been observed <ref> [7] </ref> that nearly all of the common reordering transformations can be expressed as linear mappings from the current loop control variables to a set of new loop control variables.
Reference: [8] <author> David Bau, Induprakas Kodukula, Vladimir Kotlyar, Keshav Pingali, and Paul Stodghill. </author> <title> Solving alignment using elementary linear algebra. </title> <booktitle> In Proc. 7th Annual Workshop on Languages and Compilers for Parallel Computing, </booktitle> <year> 1994. </year>
Reference-contexts: The general framework of alignment is as we see quite simple, generally agreed upon. The choice of objectives for alignment is much less obvious, however, which can also be seen from the literature: Bau et al. <ref> [8] </ref> derive communication free alignments, by showing that these correspond to the nullspace of a matrix constructed from the reference matrices F 1 ; : : : of involved variables, and refer to [60, 15, 18, 30, 51, 50] for determining the best choice of constraints to leave unsatisfied.
Reference: [9] <author> Francois Bodin, William Jalby, Daniel Windheiser, and Christine Eisenbeis. </author> <title> A quantitative algorithm for data locality optimization. In Code Generation | Concepts, </title> <booktitle> Tools, Techniques, </booktitle> <pages> pages 119-145. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Reference windows have been applied by Eisenbeis et al. in [25] for the management of local memory on CRAY-2 computers, and subsequently by the same authors in <ref> [9] </ref> to improve register allocation of array elements. In the latter case reference windows of small finite size are simply allocated in the set of registers, and the effected loops are unrolled to the extent required by the explicit and constant references to registers necessary in machine instructions. <p> The methods which do apply loop tiling, usually concentrate on that transformation. Of these methods, [34] assume cache memory to be under program control, and analyze uniformly generated references estimating reuse through reference windows (discussed in section 5.2.1). This work is a precursor to <ref> [9] </ref>: the latter reference also discusses cache management, by copying to elim 21 inate interference (essentially an adaption of the local memory management in the former). Wolf and Lam apply unimodular transformations and tiling in [93].
Reference: [10] <author> Pierre Boulet, Alain Darte, Tanguy Risset, and Yves Robert. </author> <type> (pen)- ultimate tiling ? Technical Report 93-36, </type> <institution> LIP, Ecole Normale Superieure du Lyon, </institution> <address> 69364 Lyon Cedex 07, France, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: A related field of study, and one which has received much more attention is that of blocking or tiling iteration spaces [46, 95, 12], which was discussed in section 4. Iteration space tiling for distributed memory MIMD-machines is addressed by Ramanujam and Sadayappan [75], and Boulet et al. <ref> [10] </ref>. Compared to automatic distribution, loop tiling derives clusters of iterations with greater freedom of shape than automatic distribution, but on the other hand a tiled loopnest does not include any information on processor mapping and scheduling, such as derived by automatic distribution.
Reference: [11] <author> David Callahan, Steve Carr, and Ken Kennedy. </author> <title> Improving register allocation for subscripted variables. </title> <booktitle> In Proc. ACM Conf. on Programming Language Design and Implementation, </booktitle> <pages> pages 53-65, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: In standard register allocation methods, such as the graph coloring methods surveyed in [70], only scalar variables are eligible for register placement. This limitation is particularly troublesome for floating-point register allocation, since most floating-point values originate from arrays. Callahan et al. <ref> [11] </ref> address the issue of register allocation for array elements. Their method is presented in terms of source-to-source transformations, called scalar replacement, in which temporary scalar variables are introduced, and additional code is generated to orchestrate the necessary transfers to and from the introduced scalar variables. <p> It has also been observed that tiling loops with respect to register 17 reuse may yield at least an additional factor of two in performance improvement, compared to tiling for cache reuse only [58]. In their paper mentioned above <ref> [11] </ref>, Callahan et al. also consider the application of program transformations to improve register allocation. In particular they apply loop permutation and a transformation called unroll-and-jam, in which an outer loop is unrolled a number of times followed by a fusing of the resulting multiple identical inner loops. <p> For loop permutation it is suggested that inwards movement of loops which carry more dependences will improve performance, unless this transformation will hurt "other critical performance areas". Apart from this rather vague advice, no performance models are suggested in <ref> [11] </ref>, in fact the unroll-and-jam transformation expects the unrolling factor to be externally supplied on a case by case basis. Gannon et al. [34] have developed the concept of reference windows in an attempt to quantify data locality. <p> The resulting code, when appropriate instructions have been added for transfers among registers and for transfers between memory and registers, and after dead-code elimination, is claimed to be identical to that presented by Callahan et al. in <ref> [11] </ref>. 5.2 Cache Memories The main differences between local memories, discussed in the preceeding subsection and cache memories is the explicit transfers required by the former, and the possibility of conflict misses in the latter.
Reference: [12] <author> Steve Carr and Ken Kennedy. </author> <title> Compiler blockability of numerical algorithms. </title> <booktitle> In Proceedings of Supercomputing '92, </booktitle> <pages> pages 114-124, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: The first group of methods do run-time selection of tile sizes, and are primarily concerned with cache interference in this process. All of these methods assume their input to be program fragments, symbolically tiled by hand or automatically <ref> [12, 95] </ref>, and use knowledge of the cache organization (e.g., size, associativity, etc.) to determine good tile sizes. A well known paper by Lam et al. [58] was the first to study the interac tion of cache interference and tile sizes. <p> Gupta [38] analyzes communication patterns similarly to [61] to determine if block or cyclic distributions are preferable and then proceeds to determine block sizes. A related field of study, and one which has received much more attention is that of blocking or tiling iteration spaces <ref> [46, 95, 12] </ref>, which was discussed in section 4. Iteration space tiling for distributed memory MIMD-machines is addressed by Ramanujam and Sadayappan [75], and Boulet et al. [10].
Reference: [13] <author> Steve Carr, Kathryn S. McKinley, and Chau-Wen Tseng. </author> <title> Compiler optimizations for improving data locality. </title> <booktitle> In Proceeding of the 6th Int. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 252-262, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Locality is typically evaluated by classifying array references into three different classes: references which are constant with respect to the loop in question, references which refer to the same array and differ by at most some small constant, and finally all other references. The method in <ref> [13] </ref> is one of few (the only?) also performing loop fusion and loop distribution, possibly of great benefit for large loop bodies common in certain application areas. The methods which do apply loop tiling, usually concentrate on that transformation. <p> Abu-Sufah et al. is an early reference discussing the application of loop transformations to reduce paging [1]. They describe how loop distribution and loop fusion can be applied to reduce paging. Similarly <ref> [13] </ref> claim to improve paging behaviour even though their performance model, discussed in section 5.2.2, attempts to express cache behaviour. Using the terminology of cache memories, virtual memory systems are usually fully associative, use a least-recently-used replacement policy, and thus do not suffer from the interference problems of cache memories.
Reference: [14] <author> Siddharta Chatterjee, John R. Gilbert, Fred J.E. Long, Robert Schreiber, and Shang-Hua Teng. </author> <title> Generating local addresses and communication sets for data-parallel programs. </title> <journal> J. Parallel Distrib Comput., </journal> <volume> 26(1) </volume> <pages> 72-84, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: The finite state machine approach is primarily aimed at cyclic distributions since these show repeating patterns in local index sets. The technique determines the basic pattern and produces a finite state machine capable of enumerating indices. The approach was first suggested by <ref> [14] </ref>, and further improvements have subsequently been suggested [49, 84].
Reference: [15] <author> Siddhartha Chatterjee, John Gilbert, Robert Schreiber, and Shang-Hua Teng. </author> <title> Optimal evaluation of array expressions on massively parallel machines. </title> <type> Technical report, </type> <note> XEROX PARC, </note> <month> December </month> <year> 1992. </year>
Reference-contexts: alignment is much less obvious, however, which can also be seen from the literature: Bau et al. [8] derive communication free alignments, by showing that these correspond to the nullspace of a matrix constructed from the reference matrices F 1 ; : : : of involved variables, and refer to <ref> [60, 15, 18, 30, 51, 50] </ref> for determining the best choice of constraints to leave unsatisfied. While Dion and Robert [24] derive alignments which minimize the amount of non-local communication, and show this problem to be N P-complete.
Reference: [16] <author> Siddhartha Chatterjee, John R. Gilbert, and Robert Schreiber. </author> <title> Mobile and replicated alignment of arrays in data-parallel programs. </title> <booktitle> In Proceedings of Supercomputing'93, </booktitle> <address> Portland, OR, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: Existing heuristics operate by determining each of axis, stride, and offset alignments in isolation and possibly using different cost metrics, as witnessed in [62](axis alignment), [92](axis alignment), [38](axis and stride alignment), and <ref> [19, 16] </ref>(axis, stride and offset alignment). 6.5 Automatic Distribution Automatic distribution is the automatic derivation of suitable distribution directives, for example of the type used in HPF.
Reference: [17] <author> Siddhartha Chatterjee, John R. Gilbert, Robert Schreiber, and Thomas J She*er. </author> <title> Array distribution in data-parallel programs. </title> <booktitle> In Proc. 7th Annual Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Ithaca, NY, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: This is not (as yet) a very actively researched topic, in fact the only paper known to us where compile-time derivation of HPF-like distribution directives was an explicitly stated goal is <ref> [17] </ref> by Chatterjee et al. It has been shown [54] that the dynamic distribution problem (i.e., redistributions are permitted) is N P-complete, so methods for this problem are likely to be heuristics, just as for automatic alignment. In [17], data parallel programs are targeted, and these are represented by alignment-distribution graphs <p> compile-time derivation of HPF-like distribution directives was an explicitly stated goal is <ref> [17] </ref> by Chatterjee et al. It has been shown [54] that the dynamic distribution problem (i.e., redistributions are permitted) is N P-complete, so methods for this problem are likely to be heuristics, just as for automatic alignment. In [17], data parallel programs are targeted, and these are represented by alignment-distribution graphs [18], and the distribution problem is viewed as a graph partitioning problem.
Reference: [18] <author> Siddhartha Chatterjee, John R. Gilbert, and Robert Schrieber. </author> <title> The alignment-distribution graph. </title> <editor> In A. Nicolau and D. Padua, editors, </editor> <booktitle> Proc. 6th Annual Workshop on Languages and Compilers for Parallel Computing. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: alignment is much less obvious, however, which can also be seen from the literature: Bau et al. [8] derive communication free alignments, by showing that these correspond to the nullspace of a matrix constructed from the reference matrices F 1 ; : : : of involved variables, and refer to <ref> [60, 15, 18, 30, 51, 50] </ref> for determining the best choice of constraints to leave unsatisfied. While Dion and Robert [24] derive alignments which minimize the amount of non-local communication, and show this problem to be N P-complete. <p> It has been shown [54] that the dynamic distribution problem (i.e., redistributions are permitted) is N P-complete, so methods for this problem are likely to be heuristics, just as for automatic alignment. In [17], data parallel programs are targeted, and these are represented by alignment-distribution graphs <ref> [18] </ref>, and the distribution problem is viewed as a graph partitioning problem.
Reference: [19] <author> Siddhartha Chatterjee, John R. Gilbert, Robert Shreiber, and Shang-Hua Teng. </author> <title> Automatic array alignment in data-parallel programs. </title> <booktitle> In Twentieth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1993. </year>
Reference-contexts: While Dion and Robert [24] derive alignments which minimize the amount of non-local communication, and show this problem to be N P-complete. In data-parallel languages alignment is often seen as relations, written 2 in the notation of Chatterjee et al. <ref> [19] </ref>, between the elements of array objects and those of a processor template. <p> With these constraints, alignments such as A (i; j)2T (i+j; j) are thus not legal. In some cases 30 <ref> [19] </ref> the constraint that the 2-relation must be 1-to-1 is added, and acts as a counter force to the tendency of mapping all elements to a single processor which is common in alignment for non data-parallel languages and which eliminates all available parallelism. <p> Existing heuristics operate by determining each of axis, stride, and offset alignments in isolation and possibly using different cost metrics, as witnessed in [62](axis alignment), [92](axis alignment), [38](axis and stride alignment), and <ref> [19, 16] </ref>(axis, stride and offset alignment). 6.5 Automatic Distribution Automatic distribution is the automatic derivation of suitable distribution directives, for example of the type used in HPF.
Reference: [20] <author> Fabien Coelho, Cecile Germain, and Jean-Louis Pazat. </author> <title> State of the Art in Compiling HPF. </title> <booktitle> In Proc. ParaDigme Spring School on Data Parallelism. </booktitle> <pages> Springer-Verlag, </pages> <note> To appear, </note> <month> March </month> <year> 1996. </year>
Reference-contexts: Of the existing communication optimization techniques, message vectorization, message pipelining, message coalescing, and message aggregation seem to be the most important. Message vectorization combines messages arising from a single array reference in a loop nest into one or a few large messages <ref> [42, 77, 20] </ref>. The optimization can be thought of as conventional vectorization [98, 96] applied to the array reference operations, and has exactly such legality conditions. Details on message vectorization can be found in [35]. <p> A discussion of the most significant alternatives is found in <ref> [20] </ref> which also considers the interactions with global to local address translations. 6.4 Automatic Alignment In this section we will consider methods for automatically deriving reasonable alignments of the type explicitly written in HPF programs. <p> The commonly used approach for compiling irregular applications <ref> [42, 97, 20] </ref> is the inspector/executor model [52]. <p> Currently, compilers seem <ref> [20, 2] </ref> to rely on external libraries, such as PARTI [81], for communication preprocessing and dynamically optimized communication. Further optimization of inspector/executor code can be achieved by analyzing references (e.g., updates) to indirection arrays and how these influence the computations of communication sets.
Reference: [21] <author> Stephanie Coleman and Kathryn S. McKinley. </author> <title> Tile size selection using cache organization and data layout. </title> <booktitle> In Proc. ACM Conf. on Programming Language Design and Implementation, </booktitle> <pages> pages 279-290, </pages> <address> La Jolla, </address> <year> 1995. </year>
Reference-contexts: Work on run-time determination of tile sizes has since continued [27]<ref> [21] </ref>. In these papers rectangular (possibly square) tiles are selected according to somewhat different strategies. The objective is to find the largest tile size without effective self-interference, as in [58], and in the case of [21], also to minimize expected cross interference. The run-time methods have several shortcomings in common. In particular, a single textual array reference (i.e., ...Y [j; l]...) is targeted to fit and stay in cache, which may be inappropriate for loopnests with large bodies. <p> Finally, deciding at compile time, which loops to tile, and which other transformations to apply is influenced by the methods described, and is not discussed in any of these papers. However, for the type of computational kernels which do fit the requirements, these methods show considerable improvements <ref> [21] </ref>. The second group of methods apply a more or less extensive set of program transformations in an effort to improve data locality.
Reference: [22] <author> Jean-Francois Collard, Denis Barthou, and Paul Feautrier. </author> <title> Fuzzy array dataflow analysis. </title> <booktitle> In ACM SIGPLAN Symp. on Principles and Practice of Parallel Programming, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Two primary directions of work can be identified: First studies of non-affine index expressions, represented by Maslov and Pugh [67]. Secondly, allowing if- and while-statements whose behavior is not statically decidable, as represented by Collard et al. <ref> [22] </ref>. Maslov and Pugh address the problem of analyzing polynomial index expressions. Polynomial constraints are transformed into conjunctions of affine constraints and a limited set of special forms, such as xy c or ax 2 +by 2 = c, which are subsequently affinized by way of specific rules.
Reference: [23] <institution> Cray Research, Mendota Heights, Minnesota. The CRAY X-MP series of computer systems Publication MP-2101. </institution>
Reference-contexts: Such designs belong to the MIMD category since each processor has its own instruction-and data-streams, and some examples of this type of machines are: Sequent Balance [83], VAX 8800 [59], IBM 3090 [88], CRAY X-MP <ref> [23] </ref>. The multiple processors of these machines were however most often used to increase throughput by working on different jobs simultaneously rather than cooperating to finish a single job faster. Another type of MIMD machines also made their commercial appearance in the mid 1980s.
Reference: [24] <author> Michele Dion and Yves Robert. </author> <title> Mapping affine loop nests: New results. </title> <type> Technical Report 94-30, </type> <institution> LIP, Ecole Normale Superieure de Lyon, </institution> <address> 69364 Lyon Cedex 07, France, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: While Dion and Robert <ref> [24] </ref> derive alignments which minimize the amount of non-local communication, and show this problem to be N P-complete. In data-parallel languages alignment is often seen as relations, written 2 in the notation of Chatterjee et al. [19], between the elements of array objects and those of a processor template.
Reference: [25] <author> Christine Eisenbeis, William Jalby, Daniel Windheiser, and Francois Bodin. </author> <title> A strategy for array management in local memory. </title> <editor> In A Nicolau et al., editors, </editor> <booktitle> Advances in Languages and Compilers for Parallel Processing, Research Monographs in Parallel and Distributed Computing. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1991. </year>
Reference-contexts: Linear functions with parametric constants are used to map the points of iteration spaces to points in time, and thus expressions for reference windows are somewhat parametricized with respect to evaluation order. Reference windows have been applied by Eisenbeis et al. in <ref> [25] </ref> for the management of local memory on CRAY-2 computers, and subsequently by the same authors in [9] to improve register allocation of array elements.
Reference: [26] <author> A. P. Ershov. </author> <title> ALPHA | an automatic programming system of high efficiency. </title> <journal> J. ACM, </journal> <volume> 13(1) </volume> <pages> 17-24, </pages> <month> January </month> <year> 1966. </year>
Reference-contexts: Unfortunately, a number of significant reordering transformations can not be expressed as linear mappings. The most important non-linear reordering transformations are loop tiling [46, 95], loop fission [71, 56] and loop fusion <ref> [26] </ref>.
Reference: [27] <author> K. Esseghir. </author> <title> Improving data locality for caches. </title> <type> Master's thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> September </month> <year> 1993. </year> <month> 35 </month>
Reference: [28] <author> Paul Feautrier. </author> <title> Parametric integer programming. </title> <journal> RAIRO Recherche Operationelle, </journal> <volume> 22 </volume> <pages> 243-268, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: from S i to S j at depth p is the maximal member of Q p S i S j (b) according to the o order: K S i S j (b) = max o Q S i S j (b): This maximum can be found using parametric integer programming <ref> [28] </ref>, and once the maxima for all values of p and for all possible source statements S i , have been found, we can determine the actual sources of values used by statement S j , parameterized by the iteration vector b of statement S j .
Reference: [29] <author> Paul Feautrier. </author> <title> Dataflow analysis of scalar and array references. </title> <journal> Int. J. of Parallel Programming, </journal> <volume> 20(1) </volume> <pages> 23-53, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: The relation OE is expressed in terms of lexicographic order which is the order in which the elements of iteration vectors assume values, and is denoted by o. We introduce the following notation (borrowed from Feautrier <ref> [29] </ref>), to formally express the o relation: Let The relation o can then be expressed as : a o b j p=0 where a and b are vectors of n elements, a l:m , b l:m denote the subvectors composed of elements l through m of a and b and are <p> With lexicographic order defined as above, and letting N (S i S j ) be the number of loops surrounding both statement S i and statement S j , it is easy to see <ref> [29] </ref> that the predicate OE may be defined as: hS i ; ai OE hS j ; bi j a 1:N (S i S j ) o b 1:N (S i S j ) _ (a 1:N (S i S j ) = b 1:N (S i S j ) ^ <p> In this presentation we have described the method developed by Feautrier <ref> [29] </ref>, who was the first to show exact dataflow analysis to be decidable for the restricted class of static control programs. Subsequently alternative approaches have been proposed. Maydan et al. [68] have identified a number of cases where faster techniques suffice, and fall back on [29] for more complicated cases only. <p> the method developed by Feautrier <ref> [29] </ref>, who was the first to show exact dataflow analysis to be decidable for the restricted class of static control programs. Subsequently alternative approaches have been proposed. Maydan et al. [68] have identified a number of cases where faster techniques suffice, and fall back on [29] for more complicated cases only. Pugh and Wonnacott [74] approach the problem in terms of simplifying formulas in Presburger arithmetic, using the previously developed Omega test [73] and some additional simplification rules. The maximization according to OE, is reformulated in Presburger arithmetic as a lack of intermediate conflicting writes. <p> Finally the approach described by Maslov [66] falls somewhere between that of <ref> [29] </ref> and [74]. All of the discussed techniques are complete over the restricted domain of programs with with structured, static control flow, and affine index expressions, guards and loop bounds.
Reference: [30] <author> Paul Feautrier. </author> <title> Toward automatic distribution. </title> <type> Technical Report 92.95, </type> <institution> IBP/MASI, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: alignment is much less obvious, however, which can also be seen from the literature: Bau et al. [8] derive communication free alignments, by showing that these correspond to the nullspace of a matrix constructed from the reference matrices F 1 ; : : : of involved variables, and refer to <ref> [60, 15, 18, 30, 51, 50] </ref> for determining the best choice of constraints to leave unsatisfied. While Dion and Robert [24] derive alignments which minimize the amount of non-local communication, and show this problem to be N P-complete.
Reference: [31] <author> M. J. Flynn. </author> <title> Very high-speed computing systems. </title> <journal> Proc. IEEE, </journal> <volume> 54(12) </volume> <pages> 1901-1909, </pages> <month> December </month> <year> 1966. </year>
Reference-contexts: However it had been argued for quite some time that parallel computers would eventually be the only way to achieve significant increases in performance As early as 1966 Flynn <ref> [31, 32] </ref> had proposed a simple model for categorizing computers, which is even today the most widely used scheme. Flynn's model establishes four categories of computers, using the number of instruction streams and data streams respectively: 1. Single instruction stream, single data stream (SISD, the uniprocessor) 2.
Reference: [32] <author> M. J. Flynn. </author> <title> Some computer organizations and their effectiveness. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-21:948-960, </volume> <year> 1972. </year>
Reference-contexts: However it had been argued for quite some time that parallel computers would eventually be the only way to achieve significant increases in performance As early as 1966 Flynn <ref> [31, 32] </ref> had proposed a simple model for categorizing computers, which is even today the most widely used scheme. Flynn's model establishes four categories of computers, using the number of instruction streams and data streams respectively: 1. Single instruction stream, single data stream (SISD, the uniprocessor) 2.
Reference: [33] <author> H.P.F. Forum. </author> <title> High Performance Fortran language specification, </title> <note> version 1.0. Technical Report CRC-TR-92225, Center for Research on Parallel Computations, </note> <month> May </month> <year> 1993. </year>
Reference-contexts: A recent event in compiler development for parallel distributed computers is the emergence of a standard, non-proprietary Fortran dialect named High Performance Fortran (HPF) <ref> [33] </ref>, and the appearance of compilers for this language. HPF is based on Fortran 90 [45] and extended with directives for decomposing arrays and mapping array-segments to processors. <p> Finally HPF also allows run-time changes of alignments and distributions. Support for this is provided by "executable" forms of alignment and distribution directives called REALIGN and REDISTRIBUTE respectively. Further information on data mapping in HPF can be found in [78, 53], and of course in the language definition <ref> [33] </ref>. 25 6.3 Compiling HPF Selecting suitable data decompositions is often claimed to be one of the most important intellectual steps in developing efficient parallel programs for scientific computations. In HPF data description directives are embedded in programs by their authors, and compiling may therefore seem straightforward.
Reference: [34] <author> Dennis Gannon, William Jalby, and Kyle Gallivan. </author> <title> Strategies for cache and local memory management by global program transformation. </title> <journal> J. Parallel Distrib Comput., </journal> <volume> 5 </volume> <pages> 587-616, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Apart from this rather vague advice, no performance models are suggested in [11], in fact the unroll-and-jam transformation expects the unrolling factor to be externally supplied on a case by case basis. Gannon et al. <ref> [34] </ref> have developed the concept of reference windows in an attempt to quantify data locality. <p> The method in [13] is one of few (the only?) also performing loop fusion and loop distribution, possibly of great benefit for large loop bodies common in certain application areas. The methods which do apply loop tiling, usually concentrate on that transformation. Of these methods, <ref> [34] </ref> assume cache memory to be under program control, and analyze uniformly generated references estimating reuse through reference windows (discussed in section 5.2.1). <p> This work is a precursor to [9]: the latter reference also discusses cache management, by copying to elim 21 inate interference (essentially an adaption of the local memory management in the former). Wolf and Lam apply unimodular transformations and tiling in [93]. Locality of reference is analysed as in <ref> [34] </ref> and is expressed in terms of vectors "connecting" iterations in which an arrray reference references the same location. Spatial locality is incorporated into the analysis by assuming column-major memory layout, and therefore ignoring the first indexing expression in these cases.
Reference: [35] <author> H.M. Gerndt. </author> <title> Updating distributed variables in local computations. </title> <journal> Con-currency: Practice & Experience, </journal> <volume> 2(3) </volume> <pages> 171-193, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The optimization can be thought of as conventional vectorization [98, 96] applied to the array reference operations, and has exactly such legality conditions. Details on message vectorization can be found in <ref> [35] </ref>. Message pipelining is performed by compile-time scheduling of send and receive operation with the purpose of overlapping message transmission times with useful 27 computation.
Reference: [36] <author> Matt Ginsberg. </author> <booktitle> Essentials of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufman Publishers, </publisher> <address> San Fransisco, CA, </address> <year> 1993. </year>
Reference-contexts: Finally, a slightly different approach is taken in [47, 48] where a much larger space of transformations is searched using a heuristic algorithm. A possible problem with this approach is the requirement for admissible heuristics <ref> [36] </ref>, and thereby possibly unrealistic performance estimates. 5.3 Virtual Memory Virtual memory is the lowest level of a memory hierarchy, and just like the levels above, exceeding the capacity of the upper layer, does bring a cost in terms of reduced performance.
Reference: [37] <author> Gina Goff, Ken Kennedy, and Chau-Wen Tseng. </author> <title> Practical dependence testing. </title> <booktitle> In Proc. ACM Conf. on Programming Language Design and Implementation, </booktitle> <pages> pages 15-29, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: The search for greater precision in dependence testing analysis led to a gradual movement towards general linear and integer programming techniques [91, 64, 94, 73]. The most recent developmental stage of dependence testing is represented by <ref> [37] </ref> and [69], which combine efficiency and precision by carefully selecting a set of fast tests for common cases, and falling back on general methods for cases not handled by the fast tests. 3.4 Array Dataflow Analysis As we have seen, dependence testing is not capable of eliciting true dataflow information
Reference: [38] <author> M. Gupta. </author> <title> Automatic Data Partitioning on Distributed Memory Multicom-puters. </title> <type> PhD thesis, </type> <institution> University of Illinios at Urbana-Champaign, Urbana, IL, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: Other work in automatic distribution is not explicitly targeted to the alignment and distribution model used by HPF. Wholey [92] allegedly determines the distributions for named variables using a hill-climbing procedure. Gupta <ref> [38] </ref> analyzes communication patterns similarly to [61] to determine if block or cyclic distributions are preferable and then proceeds to determine block sizes.
Reference: [39] <author> Manish Gupta, Edith Schonberg, and Harini Srinivasan. </author> <title> A unified data flow framework for optimizing communication. </title> <booktitle> In Proc. 7th Workshop on Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: Further optimization of inspector/executor code can be achieved by analyzing references (e.g., updates) to indirection arrays and how these influence the computations of communication sets. Optimizations of this type are discussed in <ref> [2, 39, 89] </ref>. 7 Discussion We have looked at a few compiler techniques for improved exploitation of data locality.
Reference: [40] <author> John L. Hennessy and David A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufman Publishers, </publisher> <address> San Mateo, Calif., </address> <year> 1990. </year>
Reference-contexts: In-depth coverage and discussion of memory hierarchy design can be found in any book on computer architecture, such as <ref> [40, 82] </ref>, and a shorter survey of cache memories is found in [79]. 2.3 Main Memory Main memory, also commonly called physical memory, and usually built from DRAM circuits, is generally seen as a natural bottommost level of memory hierarchies. <p> However, most general purpose computer systems of today use a technique called virtual memory, which allows currently unused parts of a 3 There may also be other reasons for wanting higher cache associativity, see <ref> [40] </ref> for an in-depth discussion. 5 Virtual Address Physical Address Page Table Pointer Physical Page NumberValid If false then Invalid running program to be moved to secondary storage (e.g., disks), and then moved back into physical memory when actually needed. <p> Good utilization of registers is known to be one of the most important optimizations in compilers and is sometimes claimed to be the single most important optimization <ref> [40] </ref>. In standard register allocation methods, such as the graph coloring methods surveyed in [70], only scalar variables are eligible for register placement. This limitation is particularly troublesome for floating-point register allocation, since most floating-point values originate from arrays.
Reference: [41] <author> W. Daniel Hillis and Jr. Guy L. Steele. </author> <title> Data parallel algorithms. </title> <journal> Comm. ACM, </journal> <volume> 29(12) </volume> <pages> 1170-1183, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: SIMD-machines also popularized a nearly forgotten programming model: data-parallelism, where operations are conceptually performed over all elements of a data aggregate, such as an array, at once <ref> [41] </ref>. The synchronous nature of SIMD-machines made implementations of data-parallel languages fairly straightforward which allowed the machines to be programmed at a higher level of abstraction, and also allowed the programming environments to be equipped with relatively easy-to-use debuggers and similar tools.
Reference: [42] <author> Seema Hiranandani, Kennedy, and Chau-Wen Tseng. </author> <title> Compiling Fortran D for MIMD distributed-memory machines. </title> <journal> Comm. ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: The possibility of executable realignment and redistribution directives means that program analysis is useful in determining the possible alignments and distributions of each variable at each point of reference in the program. By introducing reaching decompositions <ref> [42] </ref> this problem becomes strikingly similar to the reaching definitions problem and can be solved in a manner similar to reaching definitions [3]. <p> Of the existing communication optimization techniques, message vectorization, message pipelining, message coalescing, and message aggregation seem to be the most important. Message vectorization combines messages arising from a single array reference in a loop nest into one or a few large messages <ref> [42, 77, 20] </ref>. The optimization can be thought of as conventional vectorization [98, 96] applied to the array reference operations, and has exactly such legality conditions. Details on message vectorization can be found in [35]. <p> Further details, such as when non-blocking sends and receives can be used is found in <ref> [42] </ref>. When the sets V O and S O (p; p 0 ) can not be determined for some references to O, a scheme similar to run-time resolution must be used for these references. One remaining major responsibility of code-generation is to manage storage for all non-local array references. <p> The commonly used approach for compiling irregular applications <ref> [42, 97, 20] </ref> is the inspector/executor model [52].
Reference: [43] <author> R. W. Hockney and C. R. Jesshope. </author> <title> Parallel Computers-2, Architecture, Programming, and Algorithms. </title> <publisher> Adam Hilger Ltd, </publisher> <address> Bristol, England, and Philadelphia, USA, </address> <year> 1988. </year> <month> 36 </month>
Reference-contexts: In current computer architectures it is also very common to have a separate set of 8-32 registers for floating point values, operated on by a specific subset of the instructions. Some vector supercomputers (e.g., CRAY-2 <ref> [43, 76] </ref>, ETA-10 [43]) have introduced small fast local memories coupled to the CPU. <p> In current computer architectures it is also very common to have a separate set of 8-32 registers for floating point values, operated on by a specific subset of the instructions. Some vector supercomputers (e.g., CRAY-2 [43, 76], ETA-10 <ref> [43] </ref>) have introduced small fast local memories coupled to the CPU. From a compiler code-generator viewpoint small local memories are practically equivalent to registers, in that it is a noticably finite resource and that transfers to and from such memories must be explicitly managed and decided upon at code-generation time.
Reference: [44] <author> BBN Laboratories Inc. </author> <title> Butterfly parallel processor overview. </title> <type> Report 6148, </type> <institution> BBN, </institution> <month> March </month> <year> 1986. </year>
Reference-contexts: Early representatives of this class of distributed memory MIMDs are the Intel iPSC and the BBN Butterfly <ref> [44] </ref>. Throughout the late 1980s and early 1990s, the only programming style generally supported on MIMD-systems was explicit process parallelism.
Reference: [45] <institution> American National Standards Institute. </institution> <note> Fortran 90: X3J3 internal document S8.118, May 1991. Submitted as Text for ANSI X3.198-1991. </note>
Reference-contexts: A recent event in compiler development for parallel distributed computers is the emergence of a standard, non-proprietary Fortran dialect named High Performance Fortran (HPF) [33], and the appearance of compilers for this language. HPF is based on Fortran 90 <ref> [45] </ref> and extended with directives for decomposing arrays and mapping array-segments to processors. The compiler is responsible for decomposing the programs into processes and for generating statements for communication between processes, but does this with the guidance of the decomposition of data provided by directives.
Reference: [46] <author> F. Irigoin and R. Triolet. </author> <title> Supernode partitioning. </title> <booktitle> In Fifteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 319-329, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: Unfortunately, a number of significant reordering transformations can not be expressed as linear mappings. The most important non-linear reordering transformations are loop tiling <ref> [46, 95] </ref>, loop fission [71, 56] and loop fusion [26]. <p> = 1; : : : ; m: (11) When performing loop tiling we require that it be possible to execute each tile without interleaved or simultaneuos execution of other tiles, and this is the case if no tile boundary is crossed in both directions by the set of dependece vectors <ref> [46, 75] </ref>. <p> Gupta [38] analyzes communication patterns similarly to [61] to determine if block or cyclic distributions are preferable and then proceeds to determine block sizes. A related field of study, and one which has received much more attention is that of blocking or tiling iteration spaces <ref> [46, 95, 12] </ref>, which was discussed in section 4. Iteration space tiling for distributed memory MIMD-machines is addressed by Ramanujam and Sadayappan [75], and Boulet et al. [10].
Reference: [47] <author> Wayne Kelly and William Pugh. </author> <title> A framework for unifying reordering transformations. </title> <type> Technical Report UMIACS-CS-TR-93-134, </type> <institution> Dept. of Computer Science, Univ. of Maryland, College Park, MD 20742, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Spatial locality is incorporated into the analysis by assuming column-major memory layout, and therefore ignoring the first indexing expression in these cases. Finally, a slightly different approach is taken in <ref> [47, 48] </ref> where a much larger space of transformations is searched using a heuristic algorithm.
Reference: [48] <author> Wayne Kelly and William Pugh. </author> <title> Determining schedules based on performance estimation. </title> <type> Technical Report UMIACS-CS-TR-93-67, </type> <institution> Dept. of Computer Science, Univ. of Maryland, College Park, MD 20742, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: Spatial locality is incorporated into the analysis by assuming column-major memory layout, and therefore ignoring the first indexing expression in these cases. Finally, a slightly different approach is taken in <ref> [47, 48] </ref> where a much larger space of transformations is searched using a heuristic algorithm.
Reference: [49] <author> Ken Kennedy, Nenad Nedeljkovic, and Ajay Sethi. </author> <title> Efficient address generation for block-cyclic distributions. </title> <booktitle> In ACM International Conference on Supercomputing, </booktitle> <pages> pages 180-184, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The technique determines the basic pattern and produces a finite state machine capable of enumerating indices. The approach was first suggested by [14], and further improvements have subsequently been suggested <ref> [49, 84] </ref>. The integer linear programming approach is not theoretically as restricted as the former approaches (anything linear can be handled), but scanning polyhedral index sets which may result from this approach is in general quite complicated [4], and may often be inefficient.
Reference: [50] <author> Kathleen Knobe, Joan D. Lucas, and William J. Dally. </author> <title> Dynamic alignment on distributed memory systems. </title> <booktitle> In Proc. 3rd Workshop on Compilers for Parallel Computers, </booktitle> <pages> pages 394-404, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: alignment is much less obvious, however, which can also be seen from the literature: Bau et al. [8] derive communication free alignments, by showing that these correspond to the nullspace of a matrix constructed from the reference matrices F 1 ; : : : of involved variables, and refer to <ref> [60, 15, 18, 30, 51, 50] </ref> for determining the best choice of constraints to leave unsatisfied. While Dion and Robert [24] derive alignments which minimize the amount of non-local communication, and show this problem to be N P-complete.
Reference: [51] <author> Kathleen Knobe and Venkataraman Natarajan. </author> <title> Data optimization: Minimizing residual interprocess motion on SIMD machines. </title> <booktitle> In Proc. 3rd Symposium on the Frontiers of Massively Parallel Computation | Frontiers '90, </booktitle> <pages> pages 416-423, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: alignment is much less obvious, however, which can also be seen from the literature: Bau et al. [8] derive communication free alignments, by showing that these correspond to the nullspace of a matrix constructed from the reference matrices F 1 ; : : : of involved variables, and refer to <ref> [60, 15, 18, 30, 51, 50] </ref> for determining the best choice of constraints to leave unsatisfied. While Dion and Robert [24] derive alignments which minimize the amount of non-local communication, and show this problem to be N P-complete.
Reference: [52] <author> Charles Koelbel and Piyush Mehrotra. </author> <title> Compiling global name-space parallel loops for distributed execution. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 440-451, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The commonly used approach for compiling irregular applications [42, 97, 20] is the inspector/executor model <ref> [52] </ref>.
Reference: [53] <author> Charles E. Koelbel, David B. Loveman, Robert S. Schreiber, Guy L. Steele Jr., and Mary E. Zosel. </author> <title> The High Performance Fortran Handbook. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: Finally HPF also allows run-time changes of alignments and distributions. Support for this is provided by "executable" forms of alignment and distribution directives called REALIGN and REDISTRIBUTE respectively. Further information on data mapping in HPF can be found in <ref> [78, 53] </ref>, and of course in the language definition [33]. 25 6.3 Compiling HPF Selecting suitable data decompositions is often claimed to be one of the most important intellectual steps in developing efficient parallel programs for scientific computations.
Reference: [54] <author> Ulrich Kremer. </author> <title> Np-completeness of dynamic remapping. </title> <booktitle> In Proc. 4th Workshop on Compiler for Parallel Computers, </booktitle> <address> Delft, The Netherlands, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: This is not (as yet) a very actively researched topic, in fact the only paper known to us where compile-time derivation of HPF-like distribution directives was an explicitly stated goal is [17] by Chatterjee et al. It has been shown <ref> [54] </ref> that the dynamic distribution problem (i.e., redistributions are permitted) is N P-complete, so methods for this problem are likely to be heuristics, just as for automatic alignment.
Reference: [55] <author> D. Kuck, Y. Muraoka, and S. Chen. </author> <title> On the number of operations simultaneously executable in Fortran-like programs and their resulting speedup. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-21(12):1293-1310, </volume> <month> December </month> <year> 1972. </year>
Reference-contexts: In many cases, such as in the program fragment of figure 5, the difference between iteration vectors for which the dependence holds, is a constant vector. Under such circumstances, dependences can be represented by dependence distance vectors, first used by Kuck and Muraoka <ref> [55, 71] </ref>. The search for greater precision in dependence testing analysis led to a gradual movement towards general linear and integer programming techniques [91, 64, 94, 73].
Reference: [56] <author> David J. Kuck. </author> <title> A survey of parallel machine organization and programming. </title> <journal> Computing Surveys, </journal> <volume> 9(1) </volume> <pages> 29-59, </pages> <month> March </month> <year> 1977. </year>
Reference-contexts: Unfortunately, a number of significant reordering transformations can not be expressed as linear mappings. The most important non-linear reordering transformations are loop tiling [46, 95], loop fission <ref> [71, 56] </ref> and loop fusion [26].
Reference: [57] <author> David J. Kuck. </author> <title> The Structure of Computers and Computations. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1978. </year> <month> 37 </month>
Reference-contexts: Hence, our coverage of program analysis is geared towards the requirements of reordering transformations, which are themselves discussed in section 4. In order to identify relationships between statements which constrain reordering, Kuck <ref> [57] </ref> introduced the notion of dependence. A dependence is said to exist between two statements if there is a control flow path from the first to the second statement, and both statements reference the same memory location.
Reference: [58] <author> Monica S. Lam, Edward E. Rothberg, and Micheal E. Wolf. </author> <title> The cache performance and optimizations of blocked algorithms. </title> <booktitle> In Proc. 4th Int. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 63-74, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: It has also been observed that tiling loops with respect to register 17 reuse may yield at least an additional factor of two in performance improvement, compared to tiling for cache reuse only <ref> [58] </ref>. In their paper mentioned above [11], Callahan et al. also consider the application of program transformations to improve register allocation. <p> All of these methods assume their input to be program fragments, symbolically tiled by hand or automatically [12, 95], and use knowledge of the cache organization (e.g., size, associativity, etc.) to determine good tile sizes. A well known paper by Lam et al. <ref> [58] </ref> was the first to study the interac tion of cache interference and tile sizes. A program example (matrix-matrix 20 multiply) is used to illustrate a model for evaluating cache interference. <p> Work on run-time determination of tile sizes has since continued [27][21]. In these papers rectangular (possibly square) tiles are selected according to somewhat different strategies. The objective is to find the largest tile size without effective self-interference, as in <ref> [58] </ref>, and in the case of [21], also to minimize expected cross interference. The run-time methods have several shortcomings in common. In particular, a single textual array reference (i.e., ...Y [j; l]...) is targeted to fit and stay in cache, which may be inappropriate for loopnests with large bodies. <p> Furthermore, the decision on which reference to optimize for, and estimates of cross interference is based entirely on footprints and reuse factors <ref> [58] </ref> which are rather blunt instruments. Finally, deciding at compile time, which loops to tile, and which other transformations to apply is influenced by the methods described, and is not discussed in any of these papers. <p> Using the terminology of cache memories, virtual memory systems are usually fully associative, use a least-recently-used replacement policy, and thus do not suffer from the interference problems of cache memories. One might therefore expect <ref> [58] </ref> loop tiling methods similar to those of section 5.1 to be useful. Unfortunately, page sizes are usually fairly large leading to very large (square) tiles, which was precisely the problem tiling was supposed to avoid.
Reference: [59] <author> T. E. Leonard, </author> <title> editor. VAX Architecture Reference Manual. DEC books, </title> <institution> Maynard, Massachusetts, </institution> <year> 1987. </year>
Reference-contexts: Such designs belong to the MIMD category since each processor has its own instruction-and data-streams, and some examples of this type of machines are: Sequent Balance [83], VAX 8800 <ref> [59] </ref>, IBM 3090 [88], CRAY X-MP [23]. The multiple processors of these machines were however most often used to increase throughput by working on different jobs simultaneously rather than cooperating to finish a single job faster. Another type of MIMD machines also made their commercial appearance in the mid 1980s.
Reference: [60] <author> Jingke Li and Marina Chen. </author> <title> Index domain alignment: Minimizing cost of cross-referencing beween distributed arrays. </title> <type> Technical Report YALEU/DCS/TR-725, </type> <institution> Dept. of Computer Science, Yale University, </institution> <address> New Haven, CT 06520, </address> <month> September </month> <year> 1989. </year>
Reference-contexts: alignment is much less obvious, however, which can also be seen from the literature: Bau et al. [8] derive communication free alignments, by showing that these correspond to the nullspace of a matrix constructed from the reference matrices F 1 ; : : : of involved variables, and refer to <ref> [60, 15, 18, 30, 51, 50] </ref> for determining the best choice of constraints to leave unsatisfied. While Dion and Robert [24] derive alignments which minimize the amount of non-local communication, and show this problem to be N P-complete.
Reference: [61] <author> Jingke Li and Marina Chen. </author> <title> Compiling communication-efficient programs for massively parallel machines. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 361-376, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: This is usually done by matching reference patterns against communication functions as described by Li and Chen <ref> [61] </ref> Optimization of computation has focused on developing techniques for the efficient enumeration of local index values (i.e., enumerating the elements of C (p)). Three main approaches to this problem can be identified: closed forms, finite state machines, and integer linear programming. <p> Other work in automatic distribution is not explicitly targeted to the alignment and distribution model used by HPF. Wholey [92] allegedly determines the distributions for named variables using a hill-climbing procedure. Gupta [38] analyzes communication patterns similarly to <ref> [61] </ref> to determine if block or cyclic distributions are preferable and then proceeds to determine block sizes. A related field of study, and one which has received much more attention is that of blocking or tiling iteration spaces [46, 95, 12], which was discussed in section 4.
Reference: [62] <author> Jingke Li and Marina Chen. </author> <title> The data alignment phase in compiling programs for distributed memory machines. </title> <journal> J. Parallel Distrib Comput., </journal> <volume> 13 </volume> <pages> 213-221, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The parameters a k , s k and o k above, correspond to the three types of alignment: axis, stride and offset. The problem of optimal alignment is N P-complete <ref> [62] </ref>, and a range of different heuristics have been developed. Existing heuristics operate by determining each of axis, stride, and offset alignments in isolation and possibly using different cost metrics, as witnessed in [62](axis alignment), [92](axis alignment), [38](axis and stride alignment), and [19, 16](axis, stride and offset alignment). 6.5 Automatic Distribution
Reference: [63] <author> Wei Li and Keshav Pingali. </author> <title> A singular loop transformation framework based on non-singular matrices. </title> <type> Technical report, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, New York 14853, </address> <year> 1992. </year>
Reference-contexts: the transformation from program (a) to program (b) corresponds to the linear transformation: j 0 = 0 1 j : Linear transformation of loop control variables can express many well known transformations such as loop skewing, and a large number of transformations which have never been named in the litterature <ref> [72, 65, 63] </ref>.
Reference: [64] <author> L. Lu and M. Chen. </author> <title> Subdomain dependence test for massive parallelism. </title> <booktitle> In Proceedings of Supercomputing '90, </booktitle> <address> New York, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: Under such circumstances, dependences can be represented by dependence distance vectors, first used by Kuck and Muraoka [55, 71]. The search for greater precision in dependence testing analysis led to a gradual movement towards general linear and integer programming techniques <ref> [91, 64, 94, 73] </ref>.
Reference: [65] <author> Lee-Chung Lu. </author> <title> A unified framework for systematic loop transformations. </title> <booktitle> In 3rd ACM SIGPLAN Symp. on Principles and Practice of Parallel Programming, volume 26 of SIGPLAN Notices, </booktitle> <pages> pages 28-38, </pages> <year> 1991. </year>
Reference-contexts: the transformation from program (a) to program (b) corresponds to the linear transformation: j 0 = 0 1 j : Linear transformation of loop control variables can express many well known transformations such as loop skewing, and a large number of transformations which have never been named in the litterature <ref> [72, 65, 63] </ref>.
Reference: [66] <author> Vadim Maslov. </author> <title> Lazy array data-flow dependence analysis. </title> <booktitle> In 21st Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 311-325, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Finally the approach described by Maslov <ref> [66] </ref> falls somewhere between that of [29] and [74]. All of the discussed techniques are complete over the restricted domain of programs with with structured, static control flow, and affine index expressions, guards and loop bounds.
Reference: [67] <author> Vadim Maslov and William Pugh. </author> <title> Simplifying polynomial constraints over integers to make dependenca analysis more precise. </title> <type> Technical Report UMIACS-CS-TR-93-68.1, </type> <institution> Dept. of Computer Science, Univ. of Maryland, College Park, MD 20742, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: Two primary directions of work can be identified: First studies of non-affine index expressions, represented by Maslov and Pugh <ref> [67] </ref>. Secondly, allowing if- and while-statements whose behavior is not statically decidable, as represented by Collard et al. [22]. Maslov and Pugh address the problem of analyzing polynomial index expressions. <p> The proposed method is not capable of transforming arbitrary polynomials, and when affine constraints can not be derived, subsequent array dataflow analysis becomes inexact. It is shown in <ref> [67] </ref> that the set of special forms then used is sufficient for many common cases, such as linearized matrices and symbolic blocking. 13 Collard et al. have instead decided to consider the consequences of permit-ting if- and while-statements with arbitrary controlling expressions.
Reference: [68] <author> Dror E. Maydan, Saman P. Amarasinghe, and Monica S. Lam. </author> <title> Array data-flow analysis and its use in array privatization. </title> <booktitle> In ACM '93 Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1993. </year>
Reference-contexts: In this presentation we have described the method developed by Feautrier [29], who was the first to show exact dataflow analysis to be decidable for the restricted class of static control programs. Subsequently alternative approaches have been proposed. Maydan et al. <ref> [68] </ref> have identified a number of cases where faster techniques suffice, and fall back on [29] for more complicated cases only. Pugh and Wonnacott [74] approach the problem in terms of simplifying formulas in Presburger arithmetic, using the previously developed Omega test [73] and some additional simplification rules.
Reference: [69] <author> Dror E. Maydan, John L. Hennessy, and Monica S. Lam. </author> <title> Efficient and exact data dependence analysis. </title> <booktitle> In Proc. ACM Conf. on Programming Language Design and Implementation, </booktitle> <pages> pages 1-14, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: The search for greater precision in dependence testing analysis led to a gradual movement towards general linear and integer programming techniques [91, 64, 94, 73]. The most recent developmental stage of dependence testing is represented by [37] and <ref> [69] </ref>, which combine efficiency and precision by carefully selecting a set of fast tests for common cases, and falling back on general methods for cases not handled by the fast tests. 3.4 Array Dataflow Analysis As we have seen, dependence testing is not capable of eliciting true dataflow information such as
Reference: [70] <author> Frank Mueller. </author> <title> Register allocation by graph coloring: A review. </title> <type> Technical report, </type> <institution> Department of Computer Science, B-173, Florida State University, Tallahassee, </institution> <address> Florida 32306-4019, </address> <year> 1992. </year>
Reference-contexts: Good utilization of registers is known to be one of the most important optimizations in compilers and is sometimes claimed to be the single most important optimization [40]. In standard register allocation methods, such as the graph coloring methods surveyed in <ref> [70] </ref>, only scalar variables are eligible for register placement. This limitation is particularly troublesome for floating-point register allocation, since most floating-point values originate from arrays. Callahan et al. [11] address the issue of register allocation for array elements.
Reference: [71] <author> Y. Muraoka. </author> <title> Parallelism Exposure and Expliotation in Programs. </title> <type> PhD thesis, </type> <institution> University of Illinios at Urbana-Champaign, </institution> <month> February </month> <year> 1971. </year> <month> 38 </month>
Reference-contexts: In many cases, such as in the program fragment of figure 5, the difference between iteration vectors for which the dependence holds, is a constant vector. Under such circumstances, dependences can be represented by dependence distance vectors, first used by Kuck and Muraoka <ref> [55, 71] </ref>. The search for greater precision in dependence testing analysis led to a gradual movement towards general linear and integer programming techniques [91, 64, 94, 73]. <p> Unfortunately, a number of significant reordering transformations can not be expressed as linear mappings. The most important non-linear reordering transformations are loop tiling [46, 95], loop fission <ref> [71, 56] </ref> and loop fusion [26].
Reference: [72] <author> William Pugh. </author> <title> Uniform techniques for loop optimization. </title> <booktitle> In Proc. ACM Int. Conf. on Supercomputing, </booktitle> <address> Cologne, Germany, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: the transformation from program (a) to program (b) corresponds to the linear transformation: j 0 = 0 1 j : Linear transformation of loop control variables can express many well known transformations such as loop skewing, and a large number of transformations which have never been named in the litterature <ref> [72, 65, 63] </ref>.
Reference: [73] <author> William Pugh. </author> <title> A practical algorithm for exact array dependence analysis. </title> <journal> Comm. ACM, </journal> <volume> 35(8) </volume> <pages> 102-114, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Under such circumstances, dependences can be represented by dependence distance vectors, first used by Kuck and Muraoka [55, 71]. The search for greater precision in dependence testing analysis led to a gradual movement towards general linear and integer programming techniques <ref> [91, 64, 94, 73] </ref>. <p> Maydan et al. [68] have identified a number of cases where faster techniques suffice, and fall back on [29] for more complicated cases only. Pugh and Wonnacott [74] approach the problem in terms of simplifying formulas in Presburger arithmetic, using the previously developed Omega test <ref> [73] </ref> and some additional simplification rules. The maximization according to OE, is reformulated in Presburger arithmetic as a lack of intermediate conflicting writes. Traditional dependence information is assumed to have been derived through dependence testing [73], and dependence direction vectors or distance vectors are used to enforce the o order in <p> problem in terms of simplifying formulas in Presburger arithmetic, using the previously developed Omega test <ref> [73] </ref> and some additional simplification rules. The maximization according to OE, is reformulated in Presburger arithmetic as a lack of intermediate conflicting writes. Traditional dependence information is assumed to have been derived through dependence testing [73], and dependence direction vectors or distance vectors are used to enforce the o order in the set of constraints whenever possible, which makes it unnecessary to consider Q p S i S j (b) for all values of p.
Reference: [74] <author> William Pugh and David Wonnacott. </author> <title> An exact method for analysis of value-based array data dependeces. </title> <type> Technical Report UMIACS-CS-TR-93-137, </type> <institution> Dept. of Computer Science, Univ. of Maryland, College Park, MD 20742, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: Subsequently alternative approaches have been proposed. Maydan et al. [68] have identified a number of cases where faster techniques suffice, and fall back on [29] for more complicated cases only. Pugh and Wonnacott <ref> [74] </ref> approach the problem in terms of simplifying formulas in Presburger arithmetic, using the previously developed Omega test [73] and some additional simplification rules. The maximization according to OE, is reformulated in Presburger arithmetic as a lack of intermediate conflicting writes. <p> Finally the approach described by Maslov [66] falls somewhere between that of [29] and <ref> [74] </ref>. All of the discussed techniques are complete over the restricted domain of programs with with structured, static control flow, and affine index expressions, guards and loop bounds.
Reference: [75] <author> J. Ramanujam and P. Sadayappan. </author> <title> Tiling multidimensional iteration spaces for multicomputers. </title> <journal> J. Parallel Distrib. Comput., </journal> <volume> 16 </volume> <pages> 108-120, </pages> <year> 1992. </year>
Reference-contexts: = 1; : : : ; m: (11) When performing loop tiling we require that it be possible to execute each tile without interleaved or simultaneuos execution of other tiles, and this is the case if no tile boundary is crossed in both directions by the set of dependece vectors <ref> [46, 75] </ref>. <p> A related field of study, and one which has received much more attention is that of blocking or tiling iteration spaces [46, 95, 12], which was discussed in section 4. Iteration space tiling for distributed memory MIMD-machines is addressed by Ramanujam and Sadayappan <ref> [75] </ref>, and Boulet et al. [10]. Compared to automatic distribution, loop tiling derives clusters of iterations with greater freedom of shape than automatic distribution, but on the other hand a tiled loopnest does not include any information on processor mapping and scheduling, such as derived by automatic distribution.
Reference: [76] <author> Cray Research. </author> <title> Introducing the cray-2 computer system. Cray Channels, </title> <month> August </month> <year> 1985. </year>
Reference-contexts: In current computer architectures it is also very common to have a separate set of 8-32 registers for floating point values, operated on by a specific subset of the instructions. Some vector supercomputers (e.g., CRAY-2 <ref> [43, 76] </ref>, ETA-10 [43]) have introduced small fast local memories coupled to the CPU.
Reference: [77] <author> Anne Rogers and Keshav Pingali. </author> <title> Compiling for distributed memory architectures. </title> <journal> J. Parallel Distrib Comput., </journal> <volume> 5(3) </volume> <pages> 281-298, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Of the existing communication optimization techniques, message vectorization, message pipelining, message coalescing, and message aggregation seem to be the most important. Message vectorization combines messages arising from a single array reference in a loop nest into one or a few large messages <ref> [42, 77, 20] </ref>. The optimization can be thought of as conventional vectorization [98, 96] applied to the array reference operations, and has exactly such legality conditions. Details on message vectorization can be found in [35].
Reference: [78] <author> Robert S. Schreiber. </author> <title> An introduction to HPF. </title> <booktitle> In Proc. ParaDigme Spring School on Data Parallelism. </booktitle> <pages> Springer-Verlag, </pages> <note> To appear, </note> <month> March </month> <year> 1996. </year>
Reference-contexts: It remains to be seen if HPF will be successful in this venture, acceptance in the high performance computing community thus far seems to have been slow <ref> [78] </ref>. 24 6.2 Data Mapping in HPF The goal of the HPF developers was to define a dialect of Fortran, for programming distributed memory MIMDs at a reasonably high level of abstraction. <p> Finally HPF also allows run-time changes of alignments and distributions. Support for this is provided by "executable" forms of alignment and distribution directives called REALIGN and REDISTRIBUTE respectively. Further information on data mapping in HPF can be found in <ref> [78, 53] </ref>, and of course in the language definition [33]. 25 6.3 Compiling HPF Selecting suitable data decompositions is often claimed to be one of the most important intellectual steps in developing efficient parallel programs for scientific computations.
Reference: [79] <author> A. J. Smith. </author> <title> Cache memories. </title> <journal> Computing Surveys, </journal> <volume> 14(3) </volume> <pages> 473-530, </pages> <month> Septem-ber </month> <year> 1992. </year>
Reference-contexts: In-depth coverage and discussion of memory hierarchy design can be found in any book on computer architecture, such as [40, 82], and a shorter survey of cache memories is found in <ref> [79] </ref>. 2.3 Main Memory Main memory, also commonly called physical memory, and usually built from DRAM circuits, is generally seen as a natural bottommost level of memory hierarchies.
Reference: [80] <author> H. J. S. Smith. </author> <title> On systems of linear indeterminite equations and con-gruences. </title> <journal> Philosophical Transactions of the Royal Society of London, A(151):293-326, </journal> <volume> 1861. </volume>
Reference-contexts: single word size of cache lines, and we use &a to represent the address of a program entity a. 18 Under these conditions the set of locations in the iteration space related by possible self-interfering references are given by an easily derivable corollary, of the following theorem: Theorem 1 (Smith <ref> [80] </ref>, 1861) For any system Ax = b; A 2 Q mfin ; b 2 Q m with at least one integral solution x 0 , there exist integral vectors x 1 ; : : : ; x t such that fxjAx = b; x 2 Z n g = fx
Reference: [81] <author> Alan Sussman, Gagan Agrawal, and Joel Saltz. </author> <title> A manual for the multiblock PARTI runtime primitives. </title> <institution> Technical Report CS-TR-3070.1 and UMIACS-TR-93-36.1, University of Maryland, Department of Computer Science and UMIACS, College Park, MD 20742, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: Currently, compilers seem [20, 2] to rely on external libraries, such as PARTI <ref> [81] </ref>, for communication preprocessing and dynamically optimized communication. Further optimization of inspector/executor code can be achieved by analyzing references (e.g., updates) to indirection arrays and how these influence the computations of communication sets.
Reference: [82] <author> A. S. Tanenbaum. </author> <title> Structured Computer Organization. </title> <publisher> Prentice-Hall, </publisher> <address> En-glewood Cliffs, N.J., </address> <note> 3rd edition, </note> <year> 1990. </year>
Reference-contexts: In-depth coverage and discussion of memory hierarchy design can be found in any book on computer architecture, such as <ref> [40, 82] </ref>, and a shorter survey of cache memories is found in [79]. 2.3 Main Memory Main memory, also commonly called physical memory, and usually built from DRAM circuits, is generally seen as a natural bottommost level of memory hierarchies.
Reference: [83] <author> S. Thakkar, P. Gifford, and G. Fielland. Ballance: </author> <title> A shared memory multiprocessor. </title> <booktitle> In Proceedings of the Second International Conference on Supercomputing, </booktitle> <address> Santa Clara, CA, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: Such designs belong to the MIMD category since each processor has its own instruction-and data-streams, and some examples of this type of machines are: Sequent Balance <ref> [83] </ref>, VAX 8800 [59], IBM 3090 [88], CRAY X-MP [23]. The multiple processors of these machines were however most often used to increase throughput by working on different jobs simultaneously rather than cooperating to finish a single job faster.
Reference: [84] <author> Ashwath Thirumalai and J. Ramanujam. </author> <title> Fast address sequence generation for data-parallel programs using integer lattices. </title> <booktitle> In Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1995. </year>
Reference-contexts: The technique determines the basic pattern and produces a finite state machine capable of enumerating indices. The approach was first suggested by [14], and further improvements have subsequently been suggested <ref> [49, 84] </ref>. The integer linear programming approach is not theoretically as restricted as the former approaches (anything linear can be handled), but scanning polyhedral index sets which may result from this approach is in general quite complicated [4], and may often be inefficient.
Reference: [85] <author> R. A. Towle. </author> <title> Control and Data Dependence for Program Transformations. </title> <type> PhD thesis, </type> <institution> University of Illinios at Urbana-Champaign, </institution> <month> March </month> <year> 1976. </year>
Reference-contexts: Examples of such methods are: the GCD-test <ref> [85] </ref> and Banerjee's inequalities [6]. Dependence testing, in its simplest form, gives only "yes" or "no" answers, revealing nothing about the nature of the dependence.
Reference: [86] <author> Chau-Wen Tseng. </author> <title> An Optimizing Fortran D compiler for MIMD Distributed Memory Machines. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <year> 1993. </year>
Reference-contexts: Message coalescing combines messages resulting from different references to the same array into single messages, and message aggregation combines messages arising from references to different arrays. As shown in <ref> [86] </ref>, message vectorization is by far the most important of these optimizations. Most distributed memory MIMD-systems have a number of special purpose communication facilities which are more efficient than general communication for their specific purposes, and this in turn makes it necessary to select which communication facilities to use.
Reference: [87] <author> L. W. Tucker and G. G. Robertson. </author> <title> Architecture and applications of the connection machine. </title> <journal> Computer, </journal> <volume> 21(8) </volume> <pages> 26-39, </pages> <month> August </month> <year> 1988. </year> <month> 39 </month>
Reference-contexts: The year 1987 saw the commercial introduction of what was to become the world's most well-known model of SIMD-computer, Thinking Machines Corporation's Connection Machine-2 (CM-2) <ref> [87] </ref>. Typically, SIMD-machines are composed of a special control unit for decoding program instructions which is usually a conventional serial processor, and a large number of process elements connected in a communication network.
Reference: [88] <author> S. G. Tucker. </author> <title> The IBM 3090 system: An overview. </title> <journal> IBM Systems Journal, </journal> <volume> 25(1) </volume> <pages> 4-19, </pages> <year> 1986. </year>
Reference-contexts: Such designs belong to the MIMD category since each processor has its own instruction-and data-streams, and some examples of this type of machines are: Sequent Balance [83], VAX 8800 [59], IBM 3090 <ref> [88] </ref>, CRAY X-MP [23]. The multiple processors of these machines were however most often used to increase throughput by working on different jobs simultaneously rather than cooperating to finish a single job faster. Another type of MIMD machines also made their commercial appearance in the mid 1980s.
Reference: [89] <author> Reinhard von Hanxleden and Ken Kennedy. </author> <title> Give-n-take | a balanced code placement framework. </title> <booktitle> In Proc. ACM Conf. on Programming Language Design and Implementation, </booktitle> <pages> pages 107-120, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Further optimization of inspector/executor code can be achieved by analyzing references (e.g., updates) to indirection arrays and how these influence the computations of communication sets. Optimizations of this type are discussed in <ref> [2, 39, 89] </ref>. 7 Discussion We have looked at a few compiler techniques for improved exploitation of data locality.
Reference: [90] <author> Reinhard von Hanxleden and L. Ridgway Scott. </author> <title> Load balancing on message passign architectures. </title> <journal> Journal of Parallel and Distributed Vomputing, </journal> <volume> 13 </volume> <pages> 312-324, </pages> <year> 1991. </year>
Reference-contexts: There does of course exist many irregular problems which do not match the above description, for example recursive searching and branch-and-bound algorithms, which are often used for experimentation in dynamic load balancing <ref> [90] </ref>. However, indirection arrays would probably be used in Fortran implementations of such algorithms, but the functionality of dynamic load balancing would still be needed, and would have to be supplied by the compiler, which to our knowledge is not the case in current HPF compilers.
Reference: [91] <author> D. Wallace. </author> <title> Dependece of multi-dimensional array references. </title> <booktitle> In Proc. ACM Int. Conf. on Supercomputing, </booktitle> <address> St Malo, France, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: Under such circumstances, dependences can be represented by dependence distance vectors, first used by Kuck and Muraoka [55, 71]. The search for greater precision in dependence testing analysis led to a gradual movement towards general linear and integer programming techniques <ref> [91, 64, 94, 73] </ref>.
Reference: [92] <author> S. Wholey. </author> <title> Automatic Data Mapping for Distributed Memory Parallel Computers. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Other work in automatic distribution is not explicitly targeted to the alignment and distribution model used by HPF. Wholey <ref> [92] </ref> allegedly determines the distributions for named variables using a hill-climbing procedure. Gupta [38] analyzes communication patterns similarly to [61] to determine if block or cyclic distributions are preferable and then proceeds to determine block sizes.
Reference: [93] <author> Michael E. Wolf and Monica S. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proc. ACM Conf. on Programming Language Design and Implementation, </booktitle> <address> Toronto, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: This work is a precursor to [9]: the latter reference also discusses cache management, by copying to elim 21 inate interference (essentially an adaption of the local memory management in the former). Wolf and Lam apply unimodular transformations and tiling in <ref> [93] </ref>. Locality of reference is analysed as in [34] and is expressed in terms of vectors "connecting" iterations in which an arrray reference references the same location. Spatial locality is incorporated into the analysis by assuming column-major memory layout, and therefore ignoring the first indexing expression in these cases.
Reference: [94] <author> M. Wolfe and C. Tseng. </author> <title> The power test for data dependence. </title> <type> Technical Report CS/E 90-015, </type> <institution> Oregon Graduate Institute, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: Under such circumstances, dependences can be represented by dependence distance vectors, first used by Kuck and Muraoka [55, 71]. The search for greater precision in dependence testing analysis led to a gradual movement towards general linear and integer programming techniques <ref> [91, 64, 94, 73] </ref>.
Reference: [95] <author> Michael J. Wolfe. </author> <title> More iteration space tiling. </title> <booktitle> In Proceedings of Supercomputing '89, </booktitle> <pages> pages 655-664, </pages> <address> Reno, Nevada, </address> <month> November </month> <year> 1989. </year>
Reference-contexts: Unfortunately, a number of significant reordering transformations can not be expressed as linear mappings. The most important non-linear reordering transformations are loop tiling <ref> [46, 95] </ref>, loop fission [71, 56] and loop fusion [26]. <p> The first group of methods do run-time selection of tile sizes, and are primarily concerned with cache interference in this process. All of these methods assume their input to be program fragments, symbolically tiled by hand or automatically <ref> [12, 95] </ref>, and use knowledge of the cache organization (e.g., size, associativity, etc.) to determine good tile sizes. A well known paper by Lam et al. [58] was the first to study the interac tion of cache interference and tile sizes. <p> Gupta [38] analyzes communication patterns similarly to [61] to determine if block or cyclic distributions are preferable and then proceeds to determine block sizes. A related field of study, and one which has received much more attention is that of blocking or tiling iteration spaces <ref> [46, 95, 12] </ref>, which was discussed in section 4. Iteration space tiling for distributed memory MIMD-machines is addressed by Ramanujam and Sadayappan [75], and Boulet et al. [10].
Reference: [96] <author> Michael J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> Pitman Publishing, London, and MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference-contexts: Such a dependence representation is called dependence direction vectors and was introduced by Wolfe <ref> [96] </ref>. The dependence direction vector for the dependence from S 4 to S 4 in figure 5 due to references to the array A, is seen to be [&lt;; &gt;]. <p> An extensive set of program transformations is presented and discussed in [5], also the already mentioned books by Wolfe <ref> [96] </ref> and Zima and Chapman [98] cover this type of transformations. It has since been observed [7] that nearly all of the common reordering transformations can be expressed as linear mappings from the current loop control variables to a set of new loop control variables. <p> Message vectorization combines messages arising from a single array reference in a loop nest into one or a few large messages [42, 77, 20]. The optimization can be thought of as conventional vectorization <ref> [98, 96] </ref> applied to the array reference operations, and has exactly such legality conditions. Details on message vectorization can be found in [35]. Message pipelining is performed by compile-time scheduling of send and receive operation with the purpose of overlapping message transmission times with useful 27 computation.
Reference: [97] <author> Hans Zima and Barbara Chapman. </author> <title> Compiling for distributed-memory systems. </title> <booktitle> Proceedings of the IEEE, </booktitle> <pages> pages 139-174, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: The commonly used approach for compiling irregular applications <ref> [42, 97, 20] </ref> is the inspector/executor model [52].
Reference: [98] <author> Hans P. Zima and Barbara M. Chapman. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press Frontier Series, Addison-Wesley, </publisher> <year> 1990. </year> <month> 40 </month>
Reference-contexts: An extensive set of program transformations is presented and discussed in [5], also the already mentioned books by Wolfe [96] and Zima and Chapman <ref> [98] </ref> cover this type of transformations. It has since been observed [7] that nearly all of the common reordering transformations can be expressed as linear mappings from the current loop control variables to a set of new loop control variables. <p> Message vectorization combines messages arising from a single array reference in a loop nest into one or a few large messages [42, 77, 20]. The optimization can be thought of as conventional vectorization <ref> [98, 96] </ref> applied to the array reference operations, and has exactly such legality conditions. Details on message vectorization can be found in [35]. Message pipelining is performed by compile-time scheduling of send and receive operation with the purpose of overlapping message transmission times with useful 27 computation.
References-found: 98

