URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/tr.outbox/MIT-LCS-TR-666.ps.gz
Refering-URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/listings/tr600.html
Root-URL: 
Title: The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases  
Author: by Sanjay Ghemawat Barbara H. Liskov M. Frans Kaashoek 
Degree: (1990) Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Doctor of Philosophy at the  All rights reserved. Author  Certified by  Professor of Software Science and Engineering Thesis Supervisor Certified by  Assistant Professor of Computer Science and Engineering Thesis Supervisor Accepted by Frederic R. Morgenthaler Chairman, Departmental Committee on Graduate Students  
Date: September 1995  September 7, 1995  
Address: (1987)  
Affiliation: S.B., Cornell University  S.M. Massachusetts Institute of Technology  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  c Massachusetts Institute of Technology 1995.  Department of Electrical Engineering and Computer Science  NEC  Jamieson Career Development  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Adya. </author> <title> Transaction management for mobile objects using optimistic concurrency control. </title> <type> Technical Report MIT/LCS/TR-626, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1994. </year>
Reference-contexts: Therefore the system allows multiple transactions to execute concurrently, but adds extra concurrency control checks that prevent different transactions from interfering with each other. Techniques for performing these checks efficiently are well-known <ref> [1, 2, 19, 24, 27] </ref>. Since transactions can use objects that belong to multiple servers, special coordination is required at the servers to ensure the atomicity properties guaranteed by the transaction model. <p> Eviction of objects to make space in the client cache is discussed in [13]. Concurrency control issues for Thor are described in <ref> [1, 2, 27] </ref>. 2.5 Client-Server Protocol The clients send fetch requests and commit requests to the server as described in the previous section. The client-server communication protocol is illustrated in Figure 2-2. The server responds to a fetch request with a copy of the requested object. <p> Therefore, I implemented the single bit cache replacement policy and used extra client cache space when running the experiments described in this chapter. 6.1.3 Transaction Management Thor uses an optimistic concurrency control mechanism <ref> [1, 2, 27] </ref>. Concurrency control checks are performed at the server when a transaction commits. Therefore the client has to send the server the identifiers of all objects read and written by the transaction. <p> The optimistic concurrency control checks used in Thor do not require disk reads because only small volatile tables and data structures are used to validate incoming transactions. The details of these checks can be found in <ref> [1, 2, 27] </ref>.
Reference: [2] <author> A. Adya, R. Gruber, B. Liskov, and U. Maheshwari. </author> <title> Efficient optimistic concurrency control using loosely synchronized clocks. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 23-34, </pages> <address> San Jose, CA, </address> <year> 1995. </year>
Reference-contexts: Therefore the system allows multiple transactions to execute concurrently, but adds extra concurrency control checks that prevent different transactions from interfering with each other. Techniques for performing these checks efficiently are well-known <ref> [1, 2, 19, 24, 27] </ref>. Since transactions can use objects that belong to multiple servers, special coordination is required at the servers to ensure the atomicity properties guaranteed by the transaction model. <p> Eviction of objects to make space in the client cache is discussed in [13]. Concurrency control issues for Thor are described in <ref> [1, 2, 27] </ref>. 2.5 Client-Server Protocol The clients send fetch requests and commit requests to the server as described in the previous section. The client-server communication protocol is illustrated in Figure 2-2. The server responds to a fetch request with a copy of the requested object. <p> Transaction commits are more complicated when the committing transaction has read and written objects at more than one server. The well-known two-phase commit protocol can be used for such transactions [23]. Further details about the implementation of the two-phase commit protocol in Thor can be found in <ref> [2] </ref>. 2.6 Stable Transaction Log The storage management schemes discussed in this thesis use a stable write-ahead log to implement atomic transactions. Several techniques for implementing such a stable log are described in this section. Most database systems use an on-disk log [25]. <p> For example, Gruber studied concurrency control policies in a large client-server object oriented database. His results show that with an eighty megabits per second network, the network is not a bottleneck under most workloads <ref> [2, 27] </ref>; either the disk, or the server CPU, saturates first. 4.2.3 Disk The server has a disk that provides persistent storage for objects. We use the disk simulation algorithm from the Berkeley Raid Simulator [35] to model a Seagate ST18771FC (Barracuda 8) disk drive 1 . <p> Therefore, I implemented the single bit cache replacement policy and used extra client cache space when running the experiments described in this chapter. 6.1.3 Transaction Management Thor uses an optimistic concurrency control mechanism <ref> [1, 2, 27] </ref>. Concurrency control checks are performed at the server when a transaction commits. Therefore the client has to send the server the identifiers of all objects read and written by the transaction. <p> The optimistic concurrency control checks used in Thor do not require disk reads because only small volatile tables and data structures are used to validate incoming transactions. The details of these checks can be found in <ref> [1, 2, 27] </ref>.
Reference: [3] <author> M. Baker, S. Asami, E. Deprit, J. Ousterhout, and M. Seltzer. </author> <title> Non-volatile memory for fast reliable file systems. </title> <booktitle> In Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 10-22, </pages> <address> Boston, Massachusetts, </address> <year> 1992. </year>
Reference-contexts: The stable transaction log can be stored in non-volatile memory (NVRAM) instead of on a disk. NVRAM is much faster than disk storage, but is also much more expensive. Baker quotes NVRAM board costs ranging from $130-$630 dollars per megabyte <ref> [3] </ref>. (The higher 29 PrimaryPrimary BackupBackup Log Log Commit UPS UPS and a backup. <p> These false dependencies can create cycles in the dependency graph, and can also generate excessive disk writes. By storing modified metadata items separately instead of together in pages, the file system avoids introducing such false dependencies. Many file systems use non-volatile memory to speed up synchronous meta data updates <ref> [3, 43, 30] </ref>. If NVRAM is available to an object-oriented database, it can store the modified object buffer in this NVRAM and therefore avoid the necessity of having a separate stable transaction log. The Harp file system provides highly available storage for files [39].
Reference: [4] <author> M. Baker, J. Hartman, M. Kupfer, K. Shirriff, and J. Ousterhout. </author> <title> Measurements of a distributed file system. </title> <booktitle> In 13th Symposium on Operating System Principles, </booktitle> <pages> pages 198-212, </pages> <address> Pacific Grove, CA, </address> <year> 1991. </year>
Reference-contexts: The contents of a file tend to be read and written sequentially in their entirety <ref> [4] </ref>. Therefore it is easy to cluster the contents of a file efficiently by storing the file sequentially on disk [32, 41, 42].
Reference: [5] <author> V. Benzaken and C. Delobel. </author> <title> Enhancing performance in a persistent object store: Clustering strategies in O 2 . Technical Report 50-90, </title> <type> Altair, </type> <year> 1990. </year>
Reference-contexts: As mentioned earlier, objects are frequently accessed in detectable patterns. Many systems exploit this fact to group objects together on the disk in ways that match these access patterns reasonably well <ref> [5, 11, 18, 53, 54, 55] </ref>. When the server has to read an object from the disk, it can read an entire cluster of related objects from the disk into memory, under the expectation that other objects in this cluster will be needed soon. <p> We do not propose a particular clustering process. Instead, we assume that some unspecified clustering process has already partitioned the objects into various pages. The literature on object-oriented database systems describes a number of clustering policies that would fit into the organization described here <ref> [5, 11, 18, 53, 54, 55] </ref>. The page sizes used in our system are on the order of 32 to 64 KB. These sizes are much larger than the page sizes traditionally used in operating systems and file systems (usually around 4 or 8 KB).
Reference: [6] <author> P. A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison Wesley, </publisher> <year> 1987. </year>
Reference-contexts: We assume that the system uses a stable transaction log to implement atomic updates to stable storage. In particular, we assume that the log is managed as write-ahead log: modifications are written out to the log before they are written out the persistent database itself <ref> [6] </ref>. The server appends new objects and modified objects to the end of the the stable log. The transaction commits successfully if and only if all of the modified objects reach the log. If the server crashes in the middle of writing out the modified objects, the transaction is aborted.
Reference: [7] <author> T. Blackwell, J. Harris, and M. Seltzer. </author> <title> Heuristic cleaning algorithms in log-structured file systems. </title> <booktitle> In Winter Usenix Technical Conference, </booktitle> <pages> pages 277-288, </pages> <address> New Orleans, LA, </address> <year> 1995. </year>
Reference-contexts: Therefore these policies require a background cleaner that rearranges the contents of the database to create more free regions. Implementation of the cleaner can be complex, and the cleaner can often use a lot of available disk bandwidth and may therefore slow down client transactions <ref> [7, 48, 52] </ref>. 1.3 Results This thesis describes and evaluates a new storage management architecture built around a modified object buffer. <p> This compaction of data is called disk cleaning and various algorithms for performing such cleaning efficiently have been proposed in the literature <ref> [48, 7] </ref>. We assume that the disk cleaner runs as a background thread. The thread is activated when the number of free regions on disk falls below a certain threshold. It collects live data from a set of non-empty regions, combines the live data, and writes it to free regions. <p> Research on file systems has shown that the cleaning cost can vary widely depending on workload <ref> [7, 48, 51, 52] </ref>. We side-step the issue of cleaning costs in our simulation study by ignoring all cleaning costs. A magic zero-cost disk cleaner runs whenever the number of free regions falls below a certain threshold.
Reference: [8] <author> M. Carey, D. DeWitt, C. Kant, and J. Naughton. </author> <title> A status report on the OO7 OODBMS benchmarking effort. </title> <booktitle> In OOPSLA Proceedings, </booktitle> <pages> pages 414-426, </pages> <address> Portland, OR, </address> <year> 1994. </year>
Reference-contexts: The disk drive model is taken from the Berkeley Raid Simulator [35] and accurately models disk contention, seek times, rotational delays, and transfer delays. Finally, Chapter 6 backs up the simulation results with experiments on a real implementation running the widely accepted OO7 benchmark <ref> [9, 8] </ref>. 49 Parameter Default Value Range Studied Object size 128 bytes 128 bytes to 2 kilobytes Database size 100 megabytes 100 to 900 megabytes Table 4.1: Database parameters Parameter Default Value Range Studied Number of Clients 12 1 to 64 Objects fetched per transaction 128 128 or 512 Write Probability <p> Both the read-optimized and the write-optimized disk layout policies are supported as part of the Thor server. This chapter contains a detailed description of the implementation of the relevant parts of Thor. The chapter also describes the results of running the OO7 benchmark <ref> [8, 9] </ref> on Thor. <p> In configurations with tighter disk space, the performance of the write-optimized policy will drop because of higher cleaning overheads. 6.3.5 Client Workloads The experiments use the client traversals defined in the preliminary specification of the multiuser version of the OO7 benchmark <ref> [8] </ref>. All of these traversals start at the root of a module, follow a random path down to a leaf node of the hierarchy and then perform a depth-first traversal of a composite part pointed to by the leaf node. According to [8], the depth-first traversal can be either a read-only <p> of the multiuser version of the OO7 benchmark <ref> [8] </ref>. All of these traversals start at the root of a module, follow a random path down to a leaf node of the hierarchy and then perform a depth-first traversal of a composite part pointed to by the leaf node. According to [8], the depth-first traversal can be either a read-only traversal, or a write-traversal that modifies all of the atomic parts in the composite part. <p> As part of this depth-first search, each atomic part visited by the search is modified with probability p. The read and write traversals defined in <ref> [8] </ref> are equivalent to random traversals with p set to 0 and 1 respectively. This thesis uses two kinds of client workloads constructed out of read, write, and random traversals. Both workloads are characterized by a write probability w.
Reference: [9] <author> M. Carey, D. DeWitt, and J. Naughton. </author> <title> The OO7 benchmark. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 12-21, </pages> <address> Washington, DC, </address> <year> 1993. </year>
Reference-contexts: Disk management for object-oriented databases poses a hard problem because these systems store data as objects, most of which are quite small. For example, in the OO7 benchmark 16 database <ref> [9] </ref>, most objects are smaller than 100 bytes. Reading and writing individual objects from the disk is slow because of the performance characteristics of typical disk accesses. Each disk access has two parts. In the first phase, the disk head is moved to the right position on the disk surface. <p> The disk drive model is taken from the Berkeley Raid Simulator [35] and accurately models disk contention, seek times, rotational delays, and transfer delays. Finally, Chapter 6 backs up the simulation results with experiments on a real implementation running the widely accepted OO7 benchmark <ref> [9, 8] </ref>. 49 Parameter Default Value Range Studied Object size 128 bytes 128 bytes to 2 kilobytes Database size 100 megabytes 100 to 900 megabytes Table 4.1: Database parameters Parameter Default Value Range Studied Number of Clients 12 1 to 64 Objects fetched per transaction 128 128 or 512 Write Probability <p> Both the read-optimized and the write-optimized disk layout policies are supported as part of the Thor server. This chapter contains a detailed description of the implementation of the relevant parts of Thor. The chapter also describes the results of running the OO7 benchmark <ref> [8, 9] </ref> on Thor. <p> These measurements use overall system performance to make conclusions about the effectiveness of the MOB, and to compare the read-optimized and write-optimized disk layout policies. The experiments described in this chapter use the OO7 benchmark <ref> [9] </ref> to measure the performance of Thor. The OO7 benchmark is designed to model complex CAD/CAM/CASE applications built on top of an object-oriented database. The benchmark measures the speed of pointer traversals, object updates, and simple queries. <p> Each composite part is a randomly constructed graph with n nodes. These nodes are called atomic parts, and each atomic part has outgoing connections to e other atomic parts within the same composite part. The object-level representation of the assembly hierarchy and each composite part is described in <ref> [9] </ref>. <p> However, none of the traversals as defined in <ref> [9] </ref> test the performance of the MOB or the disk layout policies effectively. OO7's traversal 1 tests the speed of loading an entire module into the the client cache and also the speed of traversing a module that has already been loaded into the cache.
Reference: [10] <author> M. Carey, D. DeWitt, J. Richardson, and E. Shekita. </author> <title> Object and file management in the EXODUS database system. </title> <booktitle> In Proceedings of the Twelfth International Conference on Very Large Data Bases, </booktitle> <pages> pages 91-100, </pages> <address> Kyoto, Japan, </address> <year> 1986. </year> <month> 113 </month>
Reference-contexts: Chapter 3 contains a more detailed description of the object location process. Similar two-level object-location policies have been used in other object-oriented database systems <ref> [10, 16, 31] </ref>. <p> Therefore such systems can achieve extremely good clustering by ordering and grouping tuples on an appropriate set of pages. 7.2 Object-Oriented Databases Most distributed object-oriented databases use the PAGE organization described in Chapter 5 <ref> [16, 34, 10, 31] </ref>. As the results of this thesis show, the PAGE organization provides poor performance under typical object-oriented access patterns. The modified object buffer organization proposed in this thesis will provide a much better storage organizations for these object-oriented databases.
Reference: [11] <author> E. Chang and R. Katz. </author> <title> Exploiting inheritance and structure semantics for effective clustering and buffering in an object-oriented DBMS. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 348-357, </pages> <address> Portland, OR, </address> <year> 1989. </year>
Reference-contexts: As mentioned earlier, objects are frequently accessed in detectable patterns. Many systems exploit this fact to group objects together on the disk in ways that match these access patterns reasonably well <ref> [5, 11, 18, 53, 54, 55] </ref>. When the server has to read an object from the disk, it can read an entire cluster of related objects from the disk into memory, under the expectation that other objects in this cluster will be needed soon. <p> The results of this comparison are workload dependent. Research on clustering and application access patterns show that writes are less common than reads, and that clustering is often sub-optimal because of limitations in clustering algorithms and variances in application access patterns <ref> [11, 55] </ref>. Therefore, we expect typical applications to only modify small portions of a page a time. Simulation results show that under such workloads the MOB provides much better performance than PAGE. <p> We do not propose a particular clustering process. Instead, we assume that some unspecified clustering process has already partitioned the objects into various pages. The literature on object-oriented database systems describes a number of clustering policies that would fit into the organization described here <ref> [5, 11, 18, 53, 54, 55] </ref>. The page sizes used in our system are on the order of 32 to 64 KB. These sizes are much larger than the page sizes traditionally used in operating systems and file systems (usually around 4 or 8 KB). <p> Section 4.3.6 describes the impact of changing the write probability on the performance of the policies under study. Even though the write probability is varied from 0 to 100 percent in this simulation study, typically write probabilities are fairly small and do not exceed 15 to 20 percent <ref> [11] </ref>. 4.1.1 Clustering The simulator models a server that provides clustering of related objects. The database is modeled as an ordered list; objects close to each other on the ordered list are related to each other. <p> However perfect clustering is very hard, if not impossible, to achieve in practice. In a study of several object-oriented database applications for VLSI/CAD design, Chang and Katz found that access patterns for the same data varied widely depending on the application used to access the data <ref> [11] </ref>. Therefore any single clustering policy will not provide perfect clustering for all of these applications. In a study of clustering algorithms Tsangaris and Naughton found that most simple and practical clustering algorithms provide poor clustering [55]. <p> It is important to remember that write probabilities much higher than 20% are exceedingly rare. For example, in the applications studied by Chang and Katz, overall write probabilities of different applications did not exceed 25% <ref> [11] </ref>. The FREEMOB architecture out-performs PAGE for write probability under 50%. <p> We expect workloads that modify large portions of a page at a time to be rare. Chang and Katz point out several important characteristics of object-oriented database applications that support our claim <ref> [11] </ref>. They studied several VLSI/CAD applications layered on top of an object-oriented database and found that access patterns for the same data varied widely depending on which application was used to access the data. <p> A more complete study that takes all of the preceding factors into account will be very beneficial to system designers. The characteristics of object-oriented database applications reported by Chang and Katz in <ref> [11] </ref> were very helpful in devising some of the policies and client workloads used in this thesis. Reports from more real world applications would provide more guidance for such decisions. Other designers and implementors of object-oriented databases will also benefit from more information about object database applications.
Reference: [12] <author> S. Chutani, O. T. Anderson, M. L. Kazar, B. W. Leverett, W. A. Mason, and R. N. Sidebotham. </author> <title> The Episode file system. </title> <booktitle> In Winter Usenix Technical Conference, </booktitle> <pages> pages 43-60, </pages> <address> San Francisco, CA, 1992. </address> <publisher> USENIX. </publisher>
Reference-contexts: File system implementations improve write performance for metadata either by delaying metadata writes <ref> [12, 28, 21, 33] </ref>, or by using a write-optimized disk layout [48, 15, 30].
Reference: [13] <author> M. Day. </author> <title> Client cache management in a distributed object database. </title> <type> PhD thesis, </type> <institution> Mas-sachusetts Institute of Technology, </institution> <year> 1995. </year>
Reference-contexts: Eviction of objects to make space in the client cache is discussed in <ref> [13] </ref>. Concurrency control issues for Thor are described in [1, 2, 27]. 2.5 Client-Server Protocol The clients send fetch requests and commit requests to the server as described in the previous section. The client-server communication protocol is illustrated in Figure 2-2. <p> A description and analysis of policies for determining the related objects to be sent to the client can be found in <ref> [13] </ref>. A commit request to the server includes newly persistent objects, and the new values of all objects modified by the transaction. <p> There are other differences between object-shipping systems and page-shipping systems such as the effectiveness of client caching, and the use of network bandwidth. However these issues are not directly related to this thesis. The reader can find detailed comparisons of object-shipping and page-shipping in <ref> [13, 56] </ref>, The focus of this thesis is on object-shipping systems in which clients ship just the objects modified by the transaction, and not entire pages. <p> Day describes and compares a number of policies that can be used to control this prefetching of objects into the client cache <ref> [13] </ref>. Prefetching policies affect the number of network round trips and network utilization. Since the simulations described in this chapter are for a disk-bound system, the choice of prefetching policy will not have a significant impact on the results of these experiments. <p> However, network bandwidth is typically not an issue for a well-engineered object-oriented database system. Techniques such as smart prefetching of objects into the client cache <ref> [13] </ref>, and the shipping of individual modifications as opposed to entire modified pages [56], can be used to reduce the amount of network traffic generated by database activity. For example, Gruber studied concurrency control policies in a large client-server object oriented database. <p> In a page shipping architecture, object-level concur-rency control can require complicated merging of modified pages sent back by different clients [31]. More details on differences between object-shipping and page-shipping architectures can be found in the literature <ref> [13, 45, 56] </ref>. Given all of these differences, it is clear that MOB is a better storage management policy than PAGE unless the system is a page-shipping system and most modifications modify large portions of a page. <p> An empty handle is created when swizzling an object identifier that is not present in the global hash table. More efficient object management techniques such as node marking and edge marking have been described in the literature <ref> [13] </ref>. The indirection technique described here may not perform as well as these other techniques, but is easy to implement and does not require the cooperation of a garbage collector. 88 6.1.2 Cache Management The contents of the cache are not laid out explicitly by the client run-time system. <p> Therefore the cache replacement policy throws out all objects that have not been used since the last time the cache was scanned. Studies by Day show that a least-recently-used policy for evicting objects provides better performance than the simple one-bit scheme described here, but is hard to implement efficiently <ref> [13] </ref>. The single bit policy described here works quite well for hot-cold workloads if the cache space is made 50-60% bigger than the anticipated hot region size. <p> The size of the prefetch set is limited to about a thousand entries to limit the consumption of valuable server memory. The prefetch set is cleared whenever it reaches this threshold size. More discussion of prefetching of related objects into the client cache can be found in <ref> [13] </ref>. 6.2.2 Object Location Information Under the read-optimized disk layout, each page is stored at some fixed location on disk. The page map is itself stored in some special pages that are located at a well-known place on the disk.
Reference: [14] <author> M. Day, B. Liskov, U. Maheshwari, and A. Myers. </author> <title> References to remote mobile objects in Thor. </title> <journal> In ACM Letters on Programming Languages and Systems, </journal> <pages> pages 115-126, </pages> <year> 1994. </year>
Reference-contexts: Each object identifier has two parts: a page identifier, and an identifier that is unique within that page. The server maintains a two-level object-location map <ref> [14] </ref>. The first level of the map translates a page identifier into the location of the second level map entry for that page. The first level of the object location map is called the page map and each second level entry is called a page header.
Reference: [15] <author> W. deJonge, F. Kaashoek, and W. Hsieh. </author> <title> Logical disk: A simple new approach for improving file system performance. </title> <booktitle> In 14th Symposium on Operating System Principles, </booktitle> <pages> pages 15-28, </pages> <address> Asheville, NC, </address> <year> 1993. </year>
Reference-contexts: File system implementations improve write performance for metadata either by delaying metadata writes [12, 28, 21, 33], or by using a write-optimized disk layout <ref> [48, 15, 30] </ref>. A write-optimized disk layout works well for file systems for two reasons: * File contents remain clustered because most files are read and written sequentially. * Metadata is not clustered, but the amount of metadata is small enough to fit in a reasonably sized cache.
Reference: [16] <author> O. </author> <title> Deux et al. </title> <journal> The story of O 2 . IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 91-108, </pages> <year> 1990. </year>
Reference-contexts: Under such workloads the MOB may perform better because it stores just the modified portion of the page whereas PAGE has to store the entire dirty page. Furthermore, in many systems clients ship back just the objects modified by a transaction, not entire dirty pages <ref> [16, 31, 34, 38] </ref>. The focus of this thesis is on such object-shipping systems. In such systems, a PAGE organization requires expensive disk reads at transaction commit to fetch the old contents of the modified pages into server memory before the modified objects can be installed into the server cache. <p> This thesis does not concern itself with the implementation details of providing a seamless mapping of persistent objects into the heaps of non-persistent programming languages. That work has been covered elsewhere <ref> [16, 34, 38, 40] </ref>. The storage management policies described in this thesis are useful for building the lower levels of such a database system. At this low level, objects consist of a sequence of slots. <p> Chapter 3 contains a more detailed description of the object location process. Similar two-level object-location policies have been used in other object-oriented database systems <ref> [10, 16, 31] </ref>. <p> In an object-shipping system, client caches can be organized as object caches that store just the portions of the page that are currently being used by the application. Many object-oriented database systems use an object cache at the client for this reason <ref> [16, 34, 38, 40] </ref>. * Page-shipping architectures can have high network bandwidth requirements: if only part of a page is modified by a transaction, clients in an object-shipping architecture will send 85 just the modified portions of the page whereas clients in a page-shipping architecture will send the entire page. <p> Therefore such systems can achieve extremely good clustering by ordering and grouping tuples on an appropriate set of pages. 7.2 Object-Oriented Databases Most distributed object-oriented databases use the PAGE organization described in Chapter 5 <ref> [16, 34, 10, 31] </ref>. As the results of this thesis show, the PAGE organization provides poor performance under typical object-oriented access patterns. The modified object buffer organization proposed in this thesis will provide a much better storage organizations for these object-oriented databases.
Reference: [17] <author> D. DeWitt, R. Katz, F. Olken, L. Shapiro, M. Stonebraker, and D. Wood. </author> <title> Implementation techniques for main memory database systems. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 1-8, </pages> <address> Boston, MA, </address> <year> 1984. </year>
Reference-contexts: DeWitt and others propose using group commit to solve this problem <ref> [17] </ref>: transaction commits are delayed for a small period of time and then modifications from different transactions are grouped together on the same page and that page is written out to the stable transaction log.
Reference: [18] <author> P. Drew and R. King. </author> <title> The performance and utility of the Cactis implementation algorithms. </title> <booktitle> In Proceedings of the Sixteenth International Conference on Very Large Data Bases, </booktitle> <pages> pages 135-147, </pages> <address> Brisbane, Australia, </address> <year> 1990. </year>
Reference-contexts: As mentioned earlier, objects are frequently accessed in detectable patterns. Many systems exploit this fact to group objects together on the disk in ways that match these access patterns reasonably well <ref> [5, 11, 18, 53, 54, 55] </ref>. When the server has to read an object from the disk, it can read an entire cluster of related objects from the disk into memory, under the expectation that other objects in this cluster will be needed soon. <p> We do not propose a particular clustering process. Instead, we assume that some unspecified clustering process has already partitioned the objects into various pages. The literature on object-oriented database systems describes a number of clustering policies that would fit into the organization described here <ref> [5, 11, 18, 53, 54, 55] </ref>. The page sizes used in our system are on the order of 32 to 64 KB. These sizes are much larger than the page sizes traditionally used in operating systems and file systems (usually around 4 or 8 KB).
Reference: [19] <author> K. Eswaran, J. Gray, R. Lorie, and I. Traiger. </author> <title> The notion of consistency and predicate locks in a database system. </title> <journal> CACM, </journal> 19(11) 624-633, 1976. 
Reference-contexts: Therefore the system allows multiple transactions to execute concurrently, but adds extra concurrency control checks that prevent different transactions from interfering with each other. Techniques for performing these checks efficiently are well-known <ref> [1, 2, 19, 24, 27] </ref>. Since transactions can use objects that belong to multiple servers, special coordination is required at the servers to ensure the atomicity properties guaranteed by the transaction model.
Reference: [20] <author> M. Franklin, M. Carey, , and M. Livny. </author> <title> Global memory management in client-server DBMS architectures. </title> <booktitle> In Proceedings of the Eighteenth International Conference on Very Large Data Bases, </booktitle> <pages> pages 596-609, </pages> <address> Vancouver, Canada, </address> <year> 1992. </year>
Reference-contexts: This architecture will be called the free installation read variant of the MOB architecture (or the FREEMOB architecture for short). The FREEMOB architecture is actually feasible to implement by using a variant of the client-server cooperative caching scheme described by Franklin <ref> [20] </ref>. Instead of performing installation reads from the disk, the server can fetch the required pages from client caches. These fetches may sometimes fail because the client has evicted the corresponding page from its cache, and the fetches will also increase overall network traffic. <p> Installation reads form a significant component of the overall disk utilization in the MOB architecture. Some of these installation reads can be avoided by using a cooperative caching scheme that allows servers to fetch pages from client caches <ref> [20] </ref>. For example, in the simulated workload defined in Chapter 4, installation reads for hot and warm regions of the database can always be avoided by just fetching the appropriate page from one of the client caches.
Reference: [21] <author> G. Ganger and Y. Patt. </author> <title> Metadata update performance in file systems. </title> <booktitle> In Usenix Symposium on Operating System Design and Implementation, </booktitle> <pages> pages 49-60, </pages> <address> Monterey, CA, </address> <year> 1994. </year>
Reference-contexts: File system implementations improve write performance for metadata either by delaying metadata writes <ref> [12, 28, 21, 33] </ref>, or by using a write-optimized disk layout [48, 15, 30]. <p> Therefore the PAGE architecture will probably work just as well as the MOB architecture in a file system. The soft updates approach of Ganger and Patt uses a memory organization very similar to the MOB architecture <ref> [21, 22] </ref>. Instead of caching entire pages, part of the server memory holds individual modified metadata items. Unlike the MOB, this organization is not motivated by a desire to reduce memory usage. The soft updates approach does not use a stable log to ensure the recoverability of delayed writes.
Reference: [22] <author> G. Ganger and Y. Patt. </author> <title> Soft updates: A solution to the metadata update problem in file systems. </title> <type> Technical Report CSE-TR-254-95, </type> <institution> University of Michigan, </institution> <year> 1995. </year>
Reference-contexts: Therefore the PAGE architecture will probably work just as well as the MOB architecture in a file system. The soft updates approach of Ganger and Patt uses a memory organization very similar to the MOB architecture <ref> [21, 22] </ref>. Instead of caching entire pages, part of the server memory holds individual modified metadata items. Unlike the MOB, this organization is not motivated by a desire to reduce memory usage. The soft updates approach does not use a stable log to ensure the recoverability of delayed writes.
Reference: [23] <author> J. Gray. </author> <booktitle> Notes on database operating systems. In Operating Systems An Advanced Course, volume 60 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1978. </year>
Reference-contexts: These constraints have to be preserved in the presence of unexpected failures, as well as in the face of concurrent access by many applications. Therefore accesses to an object-oriented database are constrained to occur inside transactions <ref> [23] </ref>. Each application groups a set of object reads and writes within a transaction. The system provides atomic execution of these transactions: either the entire transaction succeeds as a unit (it commits), or the transaction fails (it aborts). <p> The servers provide persistent storage for objects. The applications run on the client machines and interact with the servers to access persistent objects. 2.3 Transactions Interaction with the object database is organized using atomic transactions <ref> [23] </ref>. Each client application groups a set of object reads and writes within a boundary of a transaction. The system provides atomic execution of these transactions: either the entire transaction succeeds as a unit (it commits), or the transaction fails (it aborts). <p> Since transactions can use objects that belong to multiple servers, special coordination is required at the servers to ensure the atomicity properties guaranteed by the transaction model. The well-known two-phase commit protocol can be used to allow a transaction to commit its modifications atomically at more than one server <ref> [23] </ref>. The storage management issues discussed in this thesis are independent of the implementation details required to manage multi-site transactions. Therefore the experiments described in this thesis all use single-site transactions that read and modify objects from just one server. <p> Transaction commits are more complicated when the committing transaction has read and written objects at more than one server. The well-known two-phase commit protocol can be used for such transactions <ref> [23] </ref>. Further details about the implementation of the two-phase commit protocol in Thor can be found in [2]. 2.6 Stable Transaction Log The storage management schemes discussed in this thesis use a stable write-ahead log to implement atomic transactions.
Reference: [24] <author> J. Gray, R. Lorie, G. Putzolu, and I. Traiger. </author> <title> Granularity of locks and degrees of consistency in a shared data base. </title> <editor> In G. M. Nijssen, editor, </editor> <booktitle> Modeling in Data Base Management Systems, </booktitle> <pages> pages 365-394. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1976. </year> <month> 114 </month>
Reference-contexts: Therefore the system allows multiple transactions to execute concurrently, but adds extra concurrency control checks that prevent different transactions from interfering with each other. Techniques for performing these checks efficiently are well-known <ref> [1, 2, 19, 24, 27] </ref>. Since transactions can use objects that belong to multiple servers, special coordination is required at the servers to ensure the atomicity properties guaranteed by the transaction model.
Reference: [25] <author> J. Gray, P. McJones, M. Blasgen, B. Lindsay, R. Lorie, T. Price, F. Putzoli, and I. Traiger. </author> <title> The recovery manager of the System R database manager. </title> <journal> ACM Computing Surveys, </journal> <volume> 13(2) </volume> <pages> 223-243, </pages> <year> 1981. </year>
Reference-contexts: Several techniques for implementing such a stable log are described in this section. Most database systems use an on-disk log <ref> [25] </ref>. This log can be stored either on the same disk as the rest of the database, or on a dedicated logging disk. A dedicated logging disk helps performance because it removes interference between logging and other system activity. <p> These databases typically maintain a large page cache similar to the one examined in Chapter 5 <ref> [25] </ref>. Entire pages are brought into the cache to satisfy read requests. Modifications are installed into the page cache. Dirty pages are written out to disk when they are evicted from the cache to make room for other pages.
Reference: [26] <author> J. Gray and A. Reuter. </author> <title> Transaction Processsing: Concepts and Techniques. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: If we switch to another policy, we will have to implement a more complicated scheme to perform log truncation before log space fills up. Some of the check-pointing algorithms used in databases can be adapted for this purpose <ref> [26] </ref>. Installation reads form a significant component of the overall disk utilization in the MOB architecture. Some of these installation reads can be avoided by using a cooperative caching scheme that allows servers to fetch pages from client caches [20].
Reference: [27] <author> R. Gruber. </author> <title> Concurrency control mechanisms for client-server object-oriented databases. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, forthcoming. </institution>
Reference-contexts: Therefore the system allows multiple transactions to execute concurrently, but adds extra concurrency control checks that prevent different transactions from interfering with each other. Techniques for performing these checks efficiently are well-known <ref> [1, 2, 19, 24, 27] </ref>. Since transactions can use objects that belong to multiple servers, special coordination is required at the servers to ensure the atomicity properties guaranteed by the transaction model. <p> Eviction of objects to make space in the client cache is discussed in [13]. Concurrency control issues for Thor are described in <ref> [1, 2, 27] </ref>. 2.5 Client-Server Protocol The clients send fetch requests and commit requests to the server as described in the previous section. The client-server communication protocol is illustrated in Figure 2-2. The server responds to a fetch request with a copy of the requested object. <p> For example, Gruber studied concurrency control policies in a large client-server object oriented database. His results show that with an eighty megabits per second network, the network is not a bottleneck under most workloads <ref> [2, 27] </ref>; either the disk, or the server CPU, saturates first. 4.2.3 Disk The server has a disk that provides persistent storage for objects. We use the disk simulation algorithm from the Berkeley Raid Simulator [35] to model a Seagate ST18771FC (Barracuda 8) disk drive 1 . <p> Therefore, I implemented the single bit cache replacement policy and used extra client cache space when running the experiments described in this chapter. 6.1.3 Transaction Management Thor uses an optimistic concurrency control mechanism <ref> [1, 2, 27] </ref>. Concurrency control checks are performed at the server when a transaction commits. Therefore the client has to send the server the identifiers of all objects read and written by the transaction. <p> The optimistic concurrency control checks used in Thor do not require disk reads because only small volatile tables and data structures are used to validate incoming transactions. The details of these checks can be found in <ref> [1, 2, 27] </ref>.
Reference: [28] <author> R. Hagmann. </author> <title> Reimplementing the Cedar file system using logging and group commit. </title> <booktitle> In 11th Symposium on Operating System Principles, </booktitle> <pages> pages 155-162, </pages> <address> Austin, TX, </address> <year> 1987. </year>
Reference-contexts: File system implementations improve write performance for metadata either by delaying metadata writes <ref> [12, 28, 21, 33] </ref>, or by using a write-optimized disk layout [48, 15, 30].
Reference: [29] <author> Hewlett-Packard. </author> <title> HP C2240 series 3.5-inch SCSI-2 disk drive: technical reference manual. Part number 5960-8346, </title> <type> edition 2, </type> <institution> Hewlett-Packard, </institution> <year> 1992. </year>
Reference-contexts: Therefore data transfer rates are higher near the edge of the disk. For example, on the HP C2240 disk, transfer rates can vary from 3.1 megabytes/second to 5.3 megabytes/second <ref> [29] </ref>. Disks include spare sectors to allow defective physical sectors to be dropped from the disk address space. Disk reads may have to be retried several times to cope with transient errors encountered while reading a disk block.
Reference: [30] <author> D. Hitz, J. Lau, and M. Malcolm. </author> <title> File system design for an NFS file server appliance. </title> <booktitle> In Winter Usenix Technical Conference, </booktitle> <pages> pages 235-246, </pages> <address> San Francisco, CA, </address> <year> 1994. </year>
Reference-contexts: File system implementations improve write performance for metadata either by delaying metadata writes [12, 28, 21, 33], or by using a write-optimized disk layout <ref> [48, 15, 30] </ref>. A write-optimized disk layout works well for file systems for two reasons: * File contents remain clustered because most files are read and written sequentially. * Metadata is not clustered, but the amount of metadata is small enough to fit in a reasonably sized cache. <p> These false dependencies can create cycles in the dependency graph, and can also generate excessive disk writes. By storing modified metadata items separately instead of together in pages, the file system avoids introducing such false dependencies. Many file systems use non-volatile memory to speed up synchronous meta data updates <ref> [3, 43, 30] </ref>. If NVRAM is available to an object-oriented database, it can store the modified object buffer in this NVRAM and therefore avoid the necessity of having a separate stable transaction log. The Harp file system provides highly available storage for files [39].
Reference: [31] <author> M. Hornick and S. Zdonik. </author> <title> A shared segmented memory system for an object-oriented database. </title> <journal> ACM Transactions on Office Information Systems, </journal> <volume> 5(1) </volume> <pages> 71-95, </pages> <year> 1987. </year>
Reference-contexts: Under such workloads the MOB may perform better because it stores just the modified portion of the page whereas PAGE has to store the entire dirty page. Furthermore, in many systems clients ship back just the objects modified by a transaction, not entire dirty pages <ref> [16, 31, 34, 38] </ref>. The focus of this thesis is on such object-shipping systems. In such systems, a PAGE organization requires expensive disk reads at transaction commit to fetch the old contents of the modified pages into server memory before the modified objects can be installed into the server cache. <p> Chapter 3 contains a more detailed description of the object location process. Similar two-level object-location policies have been used in other object-oriented database systems <ref> [10, 16, 31] </ref>. <p> In a page shipping architecture, object-level concur-rency control can require complicated merging of modified pages sent back by different clients <ref> [31] </ref>. More details on differences between object-shipping and page-shipping architectures can be found in the literature [13, 45, 56]. <p> Therefore such systems can achieve extremely good clustering by ordering and grouping tuples on an appropriate set of pages. 7.2 Object-Oriented Databases Most distributed object-oriented databases use the PAGE organization described in Chapter 5 <ref> [16, 34, 10, 31] </ref>. As the results of this thesis show, the PAGE organization provides poor performance under typical object-oriented access patterns. The modified object buffer organization proposed in this thesis will provide a much better storage organizations for these object-oriented databases.
Reference: [32] <institution> IBM. </institution> <note> MVS/XA JCL User's Guide. </note> <institution> International Business Machines Corporation. </institution>
Reference-contexts: The contents of a file tend to be read and written sequentially in their entirety [4]. Therefore it is easy to cluster the contents of a file efficiently by storing the file sequentially on disk <ref> [32, 41, 42] </ref>. Metadata information such as inodes and directory entries on the other hand are somewhat similar to objects in object-oriented databases: metadata items are typically small and therefore many such items are stored on each page.
Reference: [33] <author> M. Kazar, B. Leverett, O. Andersen, A. Vasilis, B. Bottos, S. Chutani, C. Everhart, A. Mason, S. Tu, and E. Zayas. </author> <title> DECorum file system architecture overview. </title> <booktitle> In Summer Usenix Technical Conference, </booktitle> <pages> pages 151-164, </pages> <address> Anaheim, CA, </address> <year> 1990. </year>
Reference-contexts: File system implementations improve write performance for metadata either by delaying metadata writes <ref> [12, 28, 21, 33] </ref>, or by using a write-optimized disk layout [48, 15, 30].
Reference: [34] <author> W. Kim, J. F. Garza, N. Ballou, and D. Woelk. </author> <title> Architecture of the ORION next-generation database system. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 109-124, </pages> <year> 1990. </year>
Reference-contexts: Under such workloads the MOB may perform better because it stores just the modified portion of the page whereas PAGE has to store the entire dirty page. Furthermore, in many systems clients ship back just the objects modified by a transaction, not entire dirty pages <ref> [16, 31, 34, 38] </ref>. The focus of this thesis is on such object-shipping systems. In such systems, a PAGE organization requires expensive disk reads at transaction commit to fetch the old contents of the modified pages into server memory before the modified objects can be installed into the server cache. <p> This thesis does not concern itself with the implementation details of providing a seamless mapping of persistent objects into the heaps of non-persistent programming languages. That work has been covered elsewhere <ref> [16, 34, 38, 40] </ref>. The storage management policies described in this thesis are useful for building the lower levels of such a database system. At this low level, objects consist of a sequence of slots. <p> In an object-shipping system, client caches can be organized as object caches that store just the portions of the page that are currently being used by the application. Many object-oriented database systems use an object cache at the client for this reason <ref> [16, 34, 38, 40] </ref>. * Page-shipping architectures can have high network bandwidth requirements: if only part of a page is modified by a transaction, clients in an object-shipping architecture will send 85 just the modified portions of the page whereas clients in a page-shipping architecture will send the entire page. <p> Therefore such systems can achieve extremely good clustering by ordering and grouping tuples on an appropriate set of pages. 7.2 Object-Oriented Databases Most distributed object-oriented databases use the PAGE organization described in Chapter 5 <ref> [16, 34, 10, 31] </ref>. As the results of this thesis show, the PAGE organization provides poor performance under typical object-oriented access patterns. The modified object buffer organization proposed in this thesis will provide a much better storage organizations for these object-oriented databases.
Reference: [35] <author> E. K. Lee. </author> <title> Software and performance issues in the implementation of a RAID prototype. </title> <type> Technical Report UCB/CSD 90/573, </type> <institution> University of California at Berkeley, </institution> <year> 1990. </year>
Reference-contexts: The server component of the simulator models the operation of a database server precisely. In fact, large portions of the simulated server were re-used in the implementation of the Thor server. The disk drive model is taken from the Berkeley Raid Simulator <ref> [35] </ref> and accurately models disk contention, seek times, rotational delays, and transfer delays. <p> We use the disk simulation algorithm from the Berkeley Raid Simulator <ref> [35] </ref> to model a Seagate ST18771FC (Barracuda 8) disk drive 1 . This simulator accurately models disk contention, seek times, rotational delays and transfer delays. However, the disk model does not include a read-ahead cache.
Reference: [36] <author> S. J. Leffler, M. K. McKusick, M. J. Karels, and J. S. Quarterman. </author> <title> The Design and Implementation of the 4.3BSD UNIX Operating System. </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: The 4.3 BSD file system partially solves this problem by dividing each page into 2, 4, 8, or 16 fragments and then allocating individual fragments to different files to reduce the amount of wasted space <ref> [36] </ref>. This optimization allowed the BSD fast file system implementation to increase the page size to 4 or 8 kilobytes without significantly increasing the amount of wasted space. Large pages do not cause fragmentation problems in our system because we treat small and large objects differently.
Reference: [37] <author> B. Liskov, D. Curtis, M. Day, S. Ghemawat, R. Gruber, P. Johnson, and A. C. Myers. </author> <title> Theta reference manual. Programming Methodology Group Memo 88, </title> <institution> MIT Laboratory for Computer Science, </institution> <year> 1995. </year>
Reference-contexts: confirm the important conclusions of the simulation study: the MOB improves system performance, and the read-optimized disk layout policy provides better performance than the write-optimized disk layout policy. 6.1 Client Implementation The client run-time system for Thor provides a number of useful properties such as the ability to run Theta <ref> [37] </ref> programs, garbage collected storage, interfaces to multiple languages, and isolation from unsafe languages such as C and C++ [38]. However, the implementation of this run-time system was unstable and incomplete at the time the experiments described in this chapter were run.
Reference: [38] <author> B. Liskov, M. Day, and L. Shrira. </author> <title> Distributed object management in Thor. </title> <editor> In M. T. Ozsu, U. Dayal, and P. Valduriez, editors, </editor> <booktitle> Distributed Object Management, </booktitle> <pages> pages 79-91. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Under such workloads the MOB may perform better because it stores just the modified portion of the page whereas PAGE has to store the entire dirty page. Furthermore, in many systems clients ship back just the objects modified by a transaction, not entire dirty pages <ref> [16, 31, 34, 38] </ref>. The focus of this thesis is on such object-shipping systems. In such systems, a PAGE organization requires expensive disk reads at transaction commit to fetch the old contents of the modified pages into server memory before the modified objects can be installed into the server cache. <p> The performance of the MOB and the effectiveness of different disk layout policies were evaluated using analytical models and by running two sets of experiments: simulations, and measurements of an implementation of the MOB in Thor, an object-oriented database system <ref> [38] </ref>. An simple analytical model shows that the MOB provides significant write absorption even under a workload that has no locality of access. <p> This thesis presents a storage architecture for such a system. This chapter describes the underlying assumptions about the system architecture. Our research has been done within the context of Thor <ref> [38] </ref>. <p> This thesis does not concern itself with the implementation details of providing a seamless mapping of persistent objects into the heaps of non-persistent programming languages. That work has been covered elsewhere <ref> [16, 34, 38, 40] </ref>. The storage management policies described in this thesis are useful for building the lower levels of such a database system. At this low level, objects consist of a sequence of slots. <p> In an object-shipping system, client caches can be organized as object caches that store just the portions of the page that are currently being used by the application. Many object-oriented database systems use an object cache at the client for this reason <ref> [16, 34, 38, 40] </ref>. * Page-shipping architectures can have high network bandwidth requirements: if only part of a page is modified by a transaction, clients in an object-shipping architecture will send 85 just the modified portions of the page whereas clients in a page-shipping architecture will send the entire page. <p> r=w) to convert from the read/write ratio (r=w) to the write probability metric used in this thesis. 86 Chapter 6 Implementation The results of the simulation study described in Chapter 4 were validated by implementing some of the proposed storage management techniques as part of the Thor object-oriented database system <ref> [38] </ref>. The implementation of Thor partitions server memory into a modified object buffer and a page cache as described in Chapter 2. Both the read-optimized and the write-optimized disk layout policies are supported as part of the Thor server. <p> provides better performance than the write-optimized disk layout policy. 6.1 Client Implementation The client run-time system for Thor provides a number of useful properties such as the ability to run Theta [37] programs, garbage collected storage, interfaces to multiple languages, and isolation from unsafe languages such as C and C++ <ref> [38] </ref>. However, the implementation of this run-time system was unstable and incomplete at the time the experiments described in this chapter were run. Therefore, I wrote my own simple implementation of the client run-time system for running these experiments. This section contains a description of this alternate run-time system.
Reference: [39] <author> B. Liskov, S. Ghemawat, R. Gruber, P. Johnson, L. Shrira, and M. Williams. </author> <title> Replication in the Harp file system. </title> <booktitle> In 13th Symposium on Operating System Principles, </booktitle> <pages> pages 226-238, </pages> <address> Pacific Grove, CA, </address> <year> 1991. </year> <month> 115 </month>
Reference-contexts: An alternative approach is to use replication to implement a stable transaction log (see a stable log <ref> [39] </ref>. As modifications reach the primary replica, they are recorded in the volatile memory of the primary and also sent over the network to a backup replica. The transaction is considered committed as soon as the modifications are stored in the memories of both the primary and the backup. <p> It suffices to replicate the contents of the MOB, because the MOB itself is cleaned in log order and the log management techniques used in the Harp file system can be used to coordinate the removal of objects from the memories of the two replicas <ref> [39] </ref>. Only the primary is simulated in detail. The backup is simulated by introducing delay at transaction commit that corresponds to the time required to send the modified objects to the backup and to receive an acknowledgment. The primary caches related groups of objects in main memory. <p> If NVRAM is available to an object-oriented database, it can store the modified object buffer in this NVRAM and therefore avoid the necessity of having a separate stable transaction log. The Harp file system provides highly available storage for files <ref> [39] </ref>. It is implemented with a primary-backup replication scheme in which the primary builds up in main-memory a log of modifications and continually streams the contents of this log to the backup.
Reference: [40] <author> D. Maier and J. Stein. </author> <title> Development and implementation of an object-oriented DBMS. </title> <editor> In B. Shriver and P. Wegner, editors, </editor> <booktitle> Research Directions in Object-Oriented Programming. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1987. </year>
Reference-contexts: This thesis does not concern itself with the implementation details of providing a seamless mapping of persistent objects into the heaps of non-persistent programming languages. That work has been covered elsewhere <ref> [16, 34, 38, 40] </ref>. The storage management policies described in this thesis are useful for building the lower levels of such a database system. At this low level, objects consist of a sequence of slots. <p> In an object-shipping system, client caches can be organized as object caches that store just the portions of the page that are currently being used by the application. Many object-oriented database systems use an object cache at the client for this reason <ref> [16, 34, 38, 40] </ref>. * Page-shipping architectures can have high network bandwidth requirements: if only part of a page is modified by a transaction, clients in an object-shipping architecture will send 85 just the modified portions of the page whereas clients in a page-shipping architecture will send the entire page.
Reference: [41] <author> M. K. McKusick, W. Joy, S. Leffler, and R. Fabry. </author> <title> A fast file system for UNIX. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(3):181, </volume> <year> 1984. </year>
Reference-contexts: The contents of a file tend to be read and written sequentially in their entirety [4]. Therefore it is easy to cluster the contents of a file efficiently by storing the file sequentially on disk <ref> [32, 41, 42] </ref>. Metadata information such as inodes and directory entries on the other hand are somewhat similar to objects in object-oriented databases: metadata items are typically small and therefore many such items are stored on each page. <p> For example, the BSD fast file system's clustering policies for inodes attempts to place the inodes for files from the same directory on the same cylinder of the disk <ref> [41] </ref>. This clustering policy reduces seek delays, but is much less efficient than a policy that places these inodes on the same page.
Reference: [42] <author> L. McVoy and S. Keiman. </author> <title> Extent-like performance from a UNIX file system. </title> <booktitle> In Winter Usenix Technical Conference, </booktitle> <pages> pages 33-43, </pages> <address> Dallas, TX, </address> <year> 1991. </year>
Reference-contexts: The contents of a file tend to be read and written sequentially in their entirety [4]. Therefore it is easy to cluster the contents of a file efficiently by storing the file sequentially on disk <ref> [32, 41, 42] </ref>. Metadata information such as inodes and directory entries on the other hand are somewhat similar to objects in object-oriented databases: metadata items are typically small and therefore many such items are stored on each page.
Reference: [43] <author> J. Moran, R. Sandberg, D. Coleman, J. Kepecs, and B. Lyon. </author> <title> Breaking through the NFS performance barrier. </title> <booktitle> In Proceedings of EUUG, </booktitle> <pages> pages 199-206, </pages> <address> Munich, Germany, </address> <year> 1990. </year>
Reference-contexts: These false dependencies can create cycles in the dependency graph, and can also generate excessive disk writes. By storing modified metadata items separately instead of together in pages, the file system avoids introducing such false dependencies. Many file systems use non-volatile memory to speed up synchronous meta data updates <ref> [3, 43, 30] </ref>. If NVRAM is available to an object-oriented database, it can store the modified object buffer in this NVRAM and therefore avoid the necessity of having a separate stable transaction log. The Harp file system provides highly available storage for files [39].
Reference: [44] <author> D. Muntz and P. Honeyman. </author> <title> Multi-level caching in distributed file systems -or- your cache ain't nuthin' but trash. </title> <booktitle> In Winter Usenix Technical Conference, </booktitle> <pages> pages 305-314, </pages> <address> San Francisco, CA, 1992. </address> <publisher> USENIX. </publisher>
Reference-contexts: The server cache is a second level cache, and in general it will not be very effective unless it is bigger than the combined cache size of all active clients <ref> [44] </ref>. <p> either of these schemes significantly because the server cache is a second level cache: requests coming into the server cache have already been filtered through a client cache and therefore do not exhibit much locality. (Muntz and Honeyman point out a similar phenomenon in the context of distributed file systems <ref> [44] </ref>.) The server cache only needs to be big enough to hold a page or a page fragment in memory long enough for the client to fetch all necessary objects into the client cache.
Reference: [45] <author> J. O'Toole and L. Shrira. </author> <title> Opportunistic log: Efficient installation reads in a reliable storage server. </title> <booktitle> In Usenix Symposium on Operating System Design and Implementation, </booktitle> <pages> pages 39-48, </pages> <address> Monterey, CA, </address> <year> 1994. </year>
Reference-contexts: Modified objects can be installed directly into the MOB without requiring immediate disk reads. O'Toole and Shrira report on the performance benefits of avoiding these immediate disk reads in <ref> [45] </ref>. The write-performance of a system that manages small objects can also be improved by changing the disk layout policy: instead of preserving the clustering of objects on disk, the server can efficiently stream a large number of modified objects to a previously empty space on the disk. <p> In the simulations described in Chapter 4, this situation arose only when the client cache size was increased to within 90% of the database size. 1.3.2 Page-Shipping Systems The PAGE architecture that dedicates the entire server memory to a page cache does not work well in object-shipping systems <ref> [45, 56] </ref>. This thesis also examines page-shipping systems in which clients ship back entire pages at transaction commit. In such systems, the PAGE architecture can provide reasonable performance and therefore this thesis compares the MOB architecture to the PAGE architecture in the context of a page-shipping system. <p> We use O'Toole and Shrira's terminology and call this disk read for installing modifications into a page an installation read <ref> [45] </ref>. In a MOB architecture these installation reads can be delayed until the contents of the MOB have to be flushed to disk. As experiments described in Chapter 4 show, and as O'Toole and Shrira 39 a b d Header demonstrated in [45], delaying these installation reads can reduce disk utilization <p> installing modifications into a page an installation read <ref> [45] </ref>. In a MOB architecture these installation reads can be delayed until the contents of the MOB have to be flushed to disk. As experiments described in Chapter 4 show, and as O'Toole and Shrira 39 a b d Header demonstrated in [45], delaying these installation reads can reduce disk utilization and improve system performance. Therefore, if the clients ship modified objects as opposed to modified pages at transaction commit, the MOB architecture will outperform the PAGE architecture. <p> When a page write has completed, the installed modifications are removed from both the MOB and the stable log. This read-modify-write cycle for flushing modifications is different from the disk scheduling used by O'Toole and Shrira <ref> [45] </ref>. In their system, a large number of pending modifications is treated as a source for disk operations for the disk scheduler. However treating the entire MOB as input to the disk scheduler has several drawbacks. <p> The server has to perform installation reads at transaction commit so that the incoming modified objects can be installed into pages before the pages are inserted into the cache. Results of various studies have shown that these immediate installation reads can significantly degrade system performance <ref> [45, 56] </ref>. The Quickstore study described in [56] used these results to conclude that page-shipping is better than object-shipping, but it did not consider a MOB architecture that can delay installation reads until modifications have to be flushed out of server memory. <p> In a page shipping architecture, object-level concur-rency control can require complicated merging of modified pages sent back by different clients [31]. More details on differences between object-shipping and page-shipping architectures can be found in the literature <ref> [13, 45, 56] </ref>. Given all of these differences, it is clear that MOB is a better storage management policy than PAGE unless the system is a page-shipping system and most modifications modify large portions of a page. <p> The MOB architecture is designed for databases that are too big to store completely in memory. Disk reads for handling partial block modifications (installation reads) in a system like Thor were studied by Shrira and O'Toole in <ref> [45] </ref>. Their study uses simulations to evaluate the effectiveness of clever scheduling techniques that reduce the impact of installation reads on server performance. These techniques depend on very good knowledge about the disk layout and performance characteristics. <p> Ruemmler's and Wilkes' description of disk characteristics and technology trends indicates that it will be very hard for software built above the disk interface to reliably discover and exploit this disk-specific information [49]. Therefore the scheduling techniques described in <ref> [45] </ref> will work reliably only if they are implemented inside the disk interface itself. Since the disk interface is block-oriented, such an implementation will not help with partial block modifications. <p> The thesis also compares the MOB architecture to the PAGE architecture that is used in most databases and file systems. Other research has shown that PAGE performs poorly in an 109 object-shipping system <ref> [45, 56] </ref>. The results of this thesis show that even in a page-shipping system, MOB provides better overall performance than PAGE under typical object database access patterns. <p> CPU overheads because the clients and the server can manage storage in terms of a small number of large pages instead of a large number of small objects. 110 Shrira and O'Toole have a preliminary study that examines the tradeoff between client cache performance and the cost of installation reads <ref> [45] </ref>. A more complete study that takes all of the preceding factors into account will be very beneficial to system designers. The characteristics of object-oriented database applications reported by Chang and Katz in [11] were very helpful in devising some of the policies and client workloads used in this thesis.
Reference: [46] <author> J. Ousterhout and F. Douglis. </author> <title> Beating the I/O bottleneck: A case for log-structured file systems. </title> <journal> ACM Operating Systems Review, </journal> <volume> 23(1) </volume> <pages> 11-28, </pages> <year> 1989. </year>
Reference-contexts: This technique was proposed as part of the log-structured file system by Rosenblum, Ousterhout, and Douglis <ref> [46, 48] </ref>. The MOB can be used in conjunction with the write-optimized disk layout policy to provide even better write performance than that offered by the write-optimized layout alone. However, the MOB will have only a small impact on the performance of a system that uses a write-optimized disk layout. <p> Each read-modify-write cycle on the other hand can be delayed until the MOB is almost full. Therefore using a read-modify-write policy will effectively increase the usable MOB size. 3.2.2 Write-Optimized Disk Layout The write-optimized disk layout policy is modeled after the implementation of the log-structured file system <ref> [46, 48] </ref>. The entire disk is divided up into large fixed-size regions (half a megabyte in the implementation described in this paper).
Reference: [47] <author> K. J. Richardson and M. J. Flynn. </author> <title> Attribute caches. </title> <type> Technical note TN-48, </type> <institution> Digital Equipment Corporation, Western Research Laboratory, </institution> <year> 1995. </year>
Reference-contexts: Part of the reason file systems do not pay much attention to clustering of metadata is because metadata forms only a small part of the total file 106 system data, and therefore with a reasonably sized metadata cache, most metadata accesses will not require disk reads <ref> [47] </ref>. File system implementations improve write performance for metadata either by delaying metadata writes [12, 28, 21, 33], or by using a write-optimized disk layout [48, 15, 30].
Reference: [48] <author> M. Rosenblum and J. K. Ousterhout. </author> <title> The design and implementation of a log-structured file system. </title> <booktitle> In 13th Symposium on Operating System Principles, </booktitle> <pages> pages 1-15, </pages> <address> Pacific Grove, CA, </address> <year> 1991. </year>
Reference-contexts: This technique was proposed as part of the log-structured file system by Rosenblum, Ousterhout, and Douglis <ref> [46, 48] </ref>. The MOB can be used in conjunction with the write-optimized disk layout policy to provide even better write performance than that offered by the write-optimized layout alone. However, the MOB will have only a small impact on the performance of a system that uses a write-optimized disk layout. <p> Therefore these policies require a background cleaner that rearranges the contents of the database to create more free regions. Implementation of the cleaner can be complex, and the cleaner can often use a lot of available disk bandwidth and may therefore slow down client transactions <ref> [7, 48, 52] </ref>. 1.3 Results This thesis describes and evaluates a new storage management architecture built around a modified object buffer. <p> Also, when individual objects are themselves big, cross-object clustering becomes less important and the performance gap between the two disk layout policies narrows. This is part of the reason write-optimized disk layouts provide good read performance for file systems <ref> [48] </ref>. File contents are typically read and written sequentially in their entirety, and therefore each file behaves like one big object. <p> Each read-modify-write cycle on the other hand can be delayed until the MOB is almost full. Therefore using a read-modify-write policy will effectively increase the usable MOB size. 3.2.2 Write-Optimized Disk Layout The write-optimized disk layout policy is modeled after the implementation of the log-structured file system <ref> [46, 48] </ref>. The entire disk is divided up into large fixed-size regions (half a megabyte in the implementation described in this paper). <p> A solution similar to the one used for the inode map in LFS <ref> [48] </ref> can be used by check-pointing the page map periodically. At recovery time the server can read the last check-pointed state of the page map and combine this check-pointed state with the object location information derived by scanning the regions updated since the checkpoint. Fetching occurs as follows. <p> This compaction of data is called disk cleaning and various algorithms for performing such cleaning efficiently have been proposed in the literature <ref> [48, 7] </ref>. We assume that the disk cleaner runs as a background thread. The thread is activated when the number of free regions on disk falls below a certain threshold. It collects live data from a set of non-empty regions, combines the live data, and writes it to free regions. <p> Such workloads are unlikely 47 in object database systems, but occur often in file systems because files are typically read and written sequentially in their entirety. The good performance of the write-optimized log-structured file system reported in <ref> [48] </ref> arises in part from this predominance of sequential reads and writes in typical file system workloads. <p> Research on file systems has shown that the cleaning cost can vary widely depending on workload <ref> [7, 48, 51, 52] </ref>. We side-step the issue of cleaning costs in our simulation study by ignoring all cleaning costs. A magic zero-cost disk cleaner runs whenever the number of free regions falls below a certain threshold. <p> This result is consistent with Rosenblum's predictions about the usefulness of a write-optimized disk layout in systems that have a large amount of memory <ref> [48] </ref>. It is important to realize that the write-optimized policy will out-perform the read-optimized policy only if clients have a large amount of memory, and the server do not. <p> This situation fits the assumption made in the log-structured file system that most reads hit in a cache <ref> [48] </ref>. <p> File system implementations improve write performance for metadata either by delaying metadata writes [12, 28, 21, 33], or by using a write-optimized disk layout <ref> [48, 15, 30] </ref>. A write-optimized disk layout works well for file systems for two reasons: * File contents remain clustered because most files are read and written sequentially. * Metadata is not clustered, but the amount of metadata is small enough to fit in a reasonably sized cache.
Reference: [49] <author> C. Ruemmler and J. Wilkes. </author> <title> An introduction to disk drive modeling. </title> <journal> Computer, </journal> <volume> 27(3) </volume> <pages> 17-28, </pages> <year> 1994. </year>
Reference-contexts: Ruemmler and Wilkes point out a number of complications in modeling the behavior of a modern disk drive <ref> [49] </ref>: seek times are hard to predict because each disk seek ends with a settle phase that can range from 1-3 milliseconds. <p> These techniques depend on very good knowledge about the disk layout and performance characteristics. Ruemmler's and Wilkes' description of disk characteristics and technology trends indicates that it will be very hard for software built above the disk interface to reliably discover and exploit this disk-specific information <ref> [49] </ref>. Therefore the scheduling techniques described in [45] will work reliably only if they are implemented inside the disk interface itself. Since the disk interface is block-oriented, such an implementation will not help with partial block modifications.
Reference: [50] <author> M. Satyanarayanan, H. Mashburn, P. Kumar, D. Steere, and J. Kistler. </author> <title> Lightweight recoverable virtual memory. </title> <booktitle> In 14th Symposium on Operating System Principles, </booktitle> <pages> pages 146-160, </pages> <address> Asheville, NC, </address> <year> 1993. </year>
Reference-contexts: The modified object buffer organization proposed in this thesis will provide a much better storage organizations for these object-oriented databases. The RVM storage manager is not an object-oriented database, but it has similar access characteristics because it allows applications to modify individual byte ranges of persistent 105 data <ref> [50] </ref>. The RVM storage manager uses a write-ahead transaction log to hold new values of modified objects. RVM is built on the assumption that the entire database fits in memory, and therefore these modifications are also installed immediately into the in-memory copies of the appropriate database pages.
Reference: [51] <author> M. Seltzer, K. Bostic, and M. K. McKusick. </author> <title> An implementation of a log-structured file system for UNIX. </title> <booktitle> In Winter Usenix Technical Conference, </booktitle> <pages> pages 307-326, </pages> <address> San Diego, CA, </address> <year> 1993. </year>
Reference-contexts: Research on file systems has shown that the cleaning cost can vary widely depending on workload <ref> [7, 48, 51, 52] </ref>. We side-step the issue of cleaning costs in our simulation study by ignoring all cleaning costs. A magic zero-cost disk cleaner runs whenever the number of free regions falls below a certain threshold.
Reference: [52] <author> M. Seltzer, K. Smith, H. Balakrishnan, J. Chang, S. McMains, and V. Padmanabhan. </author> <title> File system logging versus clustering: A performance comparison. </title> <booktitle> In Winter Usenix Technical Conference, </booktitle> <pages> pages 249-264, </pages> <address> New Orleans, LA, </address> <year> 1995. </year>
Reference-contexts: Therefore these policies require a background cleaner that rearranges the contents of the database to create more free regions. Implementation of the cleaner can be complex, and the cleaner can often use a lot of available disk bandwidth and may therefore slow down client transactions <ref> [7, 48, 52] </ref>. 1.3 Results This thesis describes and evaluates a new storage management architecture built around a modified object buffer. <p> Research on file systems has shown that the cleaning cost can vary widely depending on workload <ref> [7, 48, 51, 52] </ref>. We side-step the issue of cleaning costs in our simulation study by ignoring all cleaning costs. A magic zero-cost disk cleaner runs whenever the number of free regions falls below a certain threshold.
Reference: [53] <author> J. W. Stamos. </author> <title> Static grouping of small objects to enhance performance of a paged virtual memory. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(2) </volume> <pages> 155-180, </pages> <year> 1984. </year> <month> 116 </month>
Reference-contexts: As mentioned earlier, objects are frequently accessed in detectable patterns. Many systems exploit this fact to group objects together on the disk in ways that match these access patterns reasonably well <ref> [5, 11, 18, 53, 54, 55] </ref>. When the server has to read an object from the disk, it can read an entire cluster of related objects from the disk into memory, under the expectation that other objects in this cluster will be needed soon. <p> We do not propose a particular clustering process. Instead, we assume that some unspecified clustering process has already partitioned the objects into various pages. The literature on object-oriented database systems describes a number of clustering policies that would fit into the organization described here <ref> [5, 11, 18, 53, 54, 55] </ref>. The page sizes used in our system are on the order of 32 to 64 KB. These sizes are much larger than the page sizes traditionally used in operating systems and file systems (usually around 4 or 8 KB).
Reference: [54] <author> M. M. Tsangaris and J. F. Naughton. </author> <title> A stochastic approach to clustering. </title> <booktitle> In ACM SIG--MOD International Conference on Management of Data, </booktitle> <pages> pages 12-21, </pages> <address> Denver, Colorado, </address> <year> 1991. </year>
Reference-contexts: As mentioned earlier, objects are frequently accessed in detectable patterns. Many systems exploit this fact to group objects together on the disk in ways that match these access patterns reasonably well <ref> [5, 11, 18, 53, 54, 55] </ref>. When the server has to read an object from the disk, it can read an entire cluster of related objects from the disk into memory, under the expectation that other objects in this cluster will be needed soon. <p> We do not propose a particular clustering process. Instead, we assume that some unspecified clustering process has already partitioned the objects into various pages. The literature on object-oriented database systems describes a number of clustering policies that would fit into the organization described here <ref> [5, 11, 18, 53, 54, 55] </ref>. The page sizes used in our system are on the order of 32 to 64 KB. These sizes are much larger than the page sizes traditionally used in operating systems and file systems (usually around 4 or 8 KB).
Reference: [55] <author> M. M. Tsangaris and J. F. Naughton. </author> <title> On the performance of object clustering techniques. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 144-153, </pages> <address> California, </address> <year> 1992. </year>
Reference-contexts: As mentioned earlier, objects are frequently accessed in detectable patterns. Many systems exploit this fact to group objects together on the disk in ways that match these access patterns reasonably well <ref> [5, 11, 18, 53, 54, 55] </ref>. When the server has to read an object from the disk, it can read an entire cluster of related objects from the disk into memory, under the expectation that other objects in this cluster will be needed soon. <p> The results of this comparison are workload dependent. Research on clustering and application access patterns show that writes are less common than reads, and that clustering is often sub-optimal because of limitations in clustering algorithms and variances in application access patterns <ref> [11, 55] </ref>. Therefore, we expect typical applications to only modify small portions of a page a time. Simulation results show that under such workloads the MOB provides much better performance than PAGE. <p> We do not propose a particular clustering process. Instead, we assume that some unspecified clustering process has already partitioned the objects into various pages. The literature on object-oriented database systems describes a number of clustering policies that would fit into the organization described here <ref> [5, 11, 18, 53, 54, 55] </ref>. The page sizes used in our system are on the order of 32 to 64 KB. These sizes are much larger than the page sizes traditionally used in operating systems and file systems (usually around 4 or 8 KB). <p> Therefore any single clustering policy will not provide perfect clustering for all of these applications. In a study of clustering algorithms Tsangaris and Naughton found that most simple and practical clustering algorithms provide poor clustering <ref> [55] </ref>. Algorithms 52 Parameter Default Value Description Hot area size 6 megabytes About 50,000 objects. This is a small fraction of the database accessed heavily by a client. Half of this area is shared with other clients; the other half is private to this client.
Reference: [56] <author> S. J. White and D. J. DeWitt. </author> <title> Implementing crash recovery in Quickstore: A performance study. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 187-198, </pages> <address> San Jose, CA, </address> <year> 1995. </year> <month> 117 </month>
Reference-contexts: In the simulations described in Chapter 4, this situation arose only when the client cache size was increased to within 90% of the database size. 1.3.2 Page-Shipping Systems The PAGE architecture that dedicates the entire server memory to a page cache does not work well in object-shipping systems <ref> [45, 56] </ref>. This thesis also examines page-shipping systems in which clients ship back entire pages at transaction commit. In such systems, the PAGE architecture can provide reasonable performance and therefore this thesis compares the MOB architecture to the PAGE architecture in the context of a page-shipping system. <p> There are other differences between object-shipping systems and page-shipping systems such as the effectiveness of client caching, and the use of network bandwidth. However these issues are not directly related to this thesis. The reader can find detailed comparisons of object-shipping and page-shipping in <ref> [13, 56] </ref>, The focus of this thesis is on object-shipping systems in which clients ship just the objects modified by the transaction, and not entire pages. <p> However, network bandwidth is typically not an issue for a well-engineered object-oriented database system. Techniques such as smart prefetching of objects into the client cache [13], and the shipping of individual modifications as opposed to entire modified pages <ref> [56] </ref>, can be used to reduce the amount of network traffic generated by database activity. For example, Gruber studied concurrency control policies in a large client-server object oriented database. <p> The server has to perform installation reads at transaction commit so that the incoming modified objects can be installed into pages before the pages are inserted into the cache. Results of various studies have shown that these immediate installation reads can significantly degrade system performance <ref> [45, 56] </ref>. The Quickstore study described in [56] used these results to conclude that page-shipping is better than object-shipping, but it did not consider a MOB architecture that can delay installation reads until modifications have to be flushed out of server memory. <p> Results of various studies have shown that these immediate installation reads can significantly degrade system performance [45, 56]. The Quickstore study described in <ref> [56] </ref> used these results to conclude that page-shipping is better than object-shipping, but it did not consider a MOB architecture that can delay installation reads until modifications have to be flushed out of server memory. <p> In a page shipping architecture, object-level concur-rency control can require complicated merging of modified pages sent back by different clients [31]. More details on differences between object-shipping and page-shipping architectures can be found in the literature <ref> [13, 45, 56] </ref>. Given all of these differences, it is clear that MOB is a better storage management policy than PAGE unless the system is a page-shipping system and most modifications modify large portions of a page. <p> The thesis also compares the MOB architecture to the PAGE architecture that is used in most databases and file systems. Other research has shown that PAGE performs poorly in an 109 object-shipping system <ref> [45, 56] </ref>. The results of this thesis show that even in a page-shipping system, MOB provides better overall performance than PAGE under typical object database access patterns.
References-found: 56

