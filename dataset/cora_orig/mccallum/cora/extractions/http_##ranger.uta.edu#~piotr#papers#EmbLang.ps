URL: http://ranger.uta.edu/~piotr/papers/EmbLang.ps
Refering-URL: http://www-cse.uta.edu/~piotr/www/piotr.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: piotr@cse.uta.edu, durfee@engin.umich.edu, jeff@cs.huji.ac.il  
Title: Toward Rational Communicative Behavior  
Author: Piotr J. Gmytrasiewicz Edmund H. Durfee flfl and Jeffrey Rosenscheiny 
Address: TX 76013  Ann Arbor, Michigan 48109  Jerusalem, Israel  
Affiliation: Computer Science and Engineering University of Texas at Arlington,  flfl Department of Electrical Engineering and Computer Science University of Michigan,  Department of Computer Science Hebrew University,  
Abstract: We view communication as action aimed at increasing the efficiency of interaction among multiple agents. Thus, we postulate that a speaker design a speech act so as to maximally increase the benefit it obtains as the result of the interaction. This paper presents a theoretical framework which can be used by this kind of the design process. Our framework consists of a representation of an epistemic state of an agent engaged in an interaction, and includes the agent's preferences, abilities and beliefs about the world, as well as the beliefs the agent has about the other agents, the beliefs the other agents have, and so on. A pragmatic meaning of a speech act can be then defined as a transformation it induces on the epistemic state of an agent. This transformation leads to a change in the quality of the interaction, expressed in terms of the benefit to the agent. We propose that a rational communicative behavior results from a speaker choosing to perform the speech act that maximizes the expected increase in the quality of the interaction. In this paper we analyze questions, proposals and threats, imperatives, and statements of knowledge and belief. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aumann, R. J., and Brandenburger, A. </author> <year> 1994. </year> <title> Epistemic conditions for Nash equilibrium. </title> <type> Working paper, </type> <institution> Harvard Business School, Harverd. </institution>
Reference: <author> Austin, J. L. </author> <year> 1962. </year> <title> How to do Things with Words. </title> <publisher> Claren-don Press. </publisher>
Reference-contexts: Following the spirit of Grice (Grice 1957) and Austin <ref> (Austin 1962) </ref>, and working with our framework in RMM, we can model the pragmatic meaning of a message as the transformation it induces on the RMM's representation of the speaker's state of beliefs.
Reference: <author> Ballim, A., and Wilks, Y. </author> <year> 1991. </year> <title> Artificial Believers. </title> <publisher> Earl-baum Associates, Inc. </publisher>
Reference: <author> Clark, H. H. </author> <year> 1992. </year> <title> Arenas of Language Use. </title> <publisher> Chicago: The University of Chicago Press. </publisher>
Reference-contexts: In our future work we will undertake a more exhaustive testing of this correlation. We have not said much about the requirement of language and background knowledge commonality, so frequently required in other treatments (see, for example <ref> (Clark 1992) </ref> for interesting discussion) as a pre requisite for effective communication. We see these issues as included in our notion of the speaker's model of the messages' pragmatics, and thus directly entering into the utility considerations above.
Reference: <author> Cohen, P. R., and Levesque, H. J. </author> <year> 1990. </year> <title> Rational interaction as the basis for communication. </title> <editor> In Cohen, P. R.; Morgan, J.; and Pollack, M. E., eds., </editor> <title> Intentions in Communication. </title> <publisher> MIT Press. </publisher>
Reference: <author> Gmytrasiewicz, P. J., and Durfee, E. H. </author> <year> 1993, </year> <title> to appear. Toward a theory of honesty and trust among communicating autonomous agents. Group Decision and Negotiation. </title>
Reference: <author> Gmytrasiewicz, P. J., and Durfee, E. H. </author> <year> 1995. </year> <title> Formalization of recursive modeling. </title> <booktitle> In In Proceedings of the First International Conference on Multiagent Systems, </booktitle> <address> ICMAS'95. </address>
Reference-contexts: Introduction This paper describes an extension of the preliminary work on rational communication presented in (Gmy-trasiewicz, Durfee, & Wehe 1991). In this paper we present an application of a revised method of representing an agent's state of knowledge of a multiagent interaction recently presented in <ref> (Gmytrasiewicz & Dur-fee 1995) </ref>, we extend our previous approach to rational communication by formally defining the notion of a pragmatic meaning of a message, and expand the variations of the kinds of speech acts by considering acts we did not consider before. <p> The full exposition of the revised version of RMM is given in <ref> (Gmytrasiewicz & Durfee 1995) </ref>. The nested representation of the agents beliefs in RMM yields a solution, which is an optimal choice of action with a uniquely specified expected benefit (utility). <p> The example itself is similar to the one considered before (Gmytrasiewicz, Durfee, & Wehe 1991), and the formalism of the representation is discussed in detail in <ref> (Gmytrasiewicz & Durfee 1995) </ref>. Let us imagine an autonomous outdoor robotic vehicle, called R 1 (see Figure 1), that is attempting to coordinate its actions with another robotic vehicle, R 2 .
Reference: <author> Gmytrasiewicz, P. J., and Rosenschein, J. S. </author> <year> 1993. </year> <title> The utility of embedded knowledge-oriented actions. </title> <booktitle> In Proceedings of the Twelveth International Workshop on Distributed Artifcial Intelligence. </booktitle>
Reference: <author> Gmytrasiewicz, P. J.; Durfee, E. H.; and Wehe, D. K. </author> <year> 1991. </year> <title> The utility of communication in coordinating intelligent agents. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 166-172. </pages>
Reference-contexts: We then examine the pragmatic meaning that can be assigned to various speech acts. We concentrate on questions, proposals, threats, imperatives, and on statements expressing information about agents' beliefs, or their propositional attitudes, which complement the intentional, modeling and acknowledging messages considered in our earlier work <ref> (Gmytrasiewicz, Durfee, & Wehe 1991) </ref>. Value of Communication Basic Approach The value of communication stems from the changes in the beliefs of the agents, and from the improved coordination and overall quality of the interaction that results. <p> The example itself is similar to the one considered before <ref> (Gmytrasiewicz, Durfee, & Wehe 1991) </ref>, and the formalism of the representation is discussed in detail in (Gmytrasiewicz & Durfee 1995). Let us imagine an autonomous outdoor robotic vehicle, called R 1 (see Figure 1), that is attempting to coordinate its actions with another robotic vehicle, R 2 .
Reference: <author> Grice, H. P. </author> <year> 1957. </year> <title> Meaning. </title> <journal> Philosophical Review (LXVI):377-388. </journal>
Reference-contexts: Since the RMM representation contains the agent's beliefs about other agents' beliefs, and the speech act will alter these beliefs, it is natural to model the effect of the speech act as the transformation of the nested hierarchy of beliefs in RMM. Following the spirit of Grice <ref> (Grice 1957) </ref> and Austin (Austin 1962), and working with our framework in RMM, we can model the pragmatic meaning of a message as the transformation it induces on the RMM's representation of the speaker's state of beliefs.
Reference: <author> Halpern, J. Y., and Moses, Y. </author> <year> 1990. </year> <title> A guide to the modal logics of knowledge and belief. </title> <type> Technical Report 74007, </type> <institution> IBM Corporation, Almaden Research Center. </institution>
Reference: <author> Harsanyi, J. C. </author> <year> 1967. </year> <title> Games with incomplete information played by 'bayesian' players. </title> <booktitle> Management Science 14(3) </booktitle> <pages> 159-182. </pages>
Reference: <author> Konolige, K. </author> <year> 1986. </year> <title> A Deduction Model of Belief. </title> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Mayerson, R. </author> <year> 1988. </year> <title> Incentive constraints and optimal communication systems. </title> <booktitle> In Proceedings of the Conference on Theoretical Aspects of Reasoning about Knowl-adge, </booktitle> <pages> 179-193. </pages> <publisher> Morgan Kaufman. Mertens, and Zamir. </publisher> <year> 1985. </year> <title> Formulation of bayesian analysis for games with incomplete information. </title> <journal> International Journal of Game Theory 14 </journal> <pages> 1-29. </pages>
Reference: <author> Neapolitan, R. E. </author> <year> 1990. </year> <title> Probabilistic Reasoning in Expert Systems. </title> <publisher> John Wiley and Sons. </publisher>
Reference-contexts: These models represent the fact that, in this particular example, agent R 2 has no in formation whatsoever on which to base its own model of R 1 , and that R 1 knows that. Thus, according to the principle of indifference <ref> (Neapolitan 1990) </ref> R 2 would assign equal probabilities to alternative actions of R 1 in its model in every case. The hierarchy of nested payoff matrices, called the 2 These assumptions are only for the purpose of keeping our example simple.
Reference: <author> Pearl, J. </author> <year> 1988. </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: The mission is a version of a cooperative engagement and involves gathering information while minimizing 1 The notion of the utility of a message we use here is orthogonal to the notion of the value of information considered in decision theory <ref> (Pearl 1988) </ref>. The latter expresses the value of information to its recipient. We, on the other hand, consider the value of a message to its sender, since, of course, it is the sender that makes the decision of if, and what, to communicate. cost (fuel and/or time consumed).
Reference: <author> Perrault, C. R. </author> <year> 1990. </year> <title> An application of default logic to speech act theory. </title> <editor> In Cohen, P. R.; Morgan, J.; and Pollack, M. E., eds., </editor> <title> Intentions in Communication. </title> <publisher> MIT Press. </publisher>
Reference: <author> Russell, S., and Norvig, P. </author> <year> 1994. </year> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice Hall. </publisher>
Reference: <author> Schiffer, S. </author> <year> 1972. </year> <title> Meaning. </title> <publisher> Clarendon Press. </publisher>
Reference: <author> Zlotkin, G., and Rosenschein, J. S. </author> <year> 1991. </year> <title> Incomplete information and deception in multi-agent negotiation. </title> <booktitle> In IJCAI91. </booktitle>
Reference: <author> Zlotkin, G., and Rosenschein, J. S. </author> <year> 1993. </year> <title> A domain theory for task oriented negotiation. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 416-422. </pages>
References-found: 21

