URL: http://www.ai.mit.edu/people/max/webPub/aiMemo1629.ps.gz
Refering-URL: http://www.ai.mit.edu/people/max/pub.html
Root-URL: 
Title: Modeling Invariances in Inferotemporal Cell Tuning  
Author: Maximilian Riesenhuber and Tomaso Poggio 
Note: This publication can be retrieved by anonymous ftp to publications.ai.mit.edu. Copyright c Massachusetts Institute of Technology, 1998  
Date: 1629 March, 1998  160  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY and CENTER FOR BIOLOGICAL AND COMPUTATIONAL LEARNING DEPARTMENT OF BRAIN AND COGNITIVE SCIENCES  
Pubnum: A.I. Memo No.  C.B.C.L. Paper No.  
Abstract: In macaque inferotemporal cortex (IT), neurons have been found to respond selectively to complex shapes while showing broad tuning (invariance) with respect to stimulus transformations such as translation and scale changes and a limited tuning to rotation in depth. Training monkeys with novel, paperclip-like objects, Logothetis et al. 10 could investigate whether these invariance properties are due to experience with exhaustively many transformed instances of an object or if there are mechanisms that allow the cells to show response invariance also to previously unseen instances of that object. They found object-selective cells in anterior IT which exhibited limited invariance to various transformations after training with single object views. While previous models accounted for the tuning of the cells for rotations in depth and for their selectivity to a specific object relative to a population of distractor objects, 17,1 the model described here attempts to explain in a biologically plausible way the additional properties of translation and size invariance. Using the same stimuli as in the experiment, we find that model IT neurons exhibit invariance properties which closely parallel those of real neurons. Simulations show that the model is capable of unsupervised learning of view-tuned neurons. The model also allows to make experimentally testable predictions regarding novel stimulus transformations and combinations of stimuli. This report describes research done at the Center for Biological & Computational Learning and the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. This research was sponsored by the Office of Naval Research under contract No. N00014-93-1-0385 and the National Science Foundation under contract No. ASC-92-17041. Support was also provided by Daimler-Benz AG, Eastman Kodak Company, Siemens Corporate Research, Inc., and AT&T. Maximilian Riesenhuber is a Gerald J. and Marjorie J. Burnett Fellow in the Department of Brain & Cognitive Sciences. Part of this paper will appear in Advances in Neural Information Processing Systems 10, published by MIT Press (1998). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bricolo, E, Poggio, </author> <title> T & Logothetis, N (1997). 3D object recog nition: A model of view-tuned neurons. </title> <booktitle> In Advances In Neural Information Processing 9, </booktitle> <pages> 41-47. </pages> <publisher> MIT Press. </publisher>
Reference-contexts: It suggests a maximum-like response of intermediate cells as a key mechanism for explaining the properties of view-tuned IT cells, in addition to view-based representations (already described in <ref> [1, 10] </ref>). Neurons in the intermediate layer currently use a very simple set of features. While this appears to be adequate for the class of paperclip objects, more complex filters might be necessary for more complex stimulus classes like faces.
Reference: [2] <author> Bulthoff, H & Edelman, </author> <title> S (1992). Psychophysical support for a two-dimensional view interpolation theory of object recognition. </title> <booktitle> Proc. </booktitle> <institution> Nat. Acad. Sci. </institution> <address> USA 89, </address> <pages> 60-64. </pages>
Reference: [3] <author> Brunelli, R & Poggio, </author> <title> T (1993). Face Recognition: Features Versus Templates. </title> <journal> IEEE PAMI 15, </journal> <pages> 1042-1052. </pages>
Reference: [4] <author> Desimone, R & Schein, </author> <title> S (1987). Visual properties of neu rons in area V4 of the macaque: Sensitivity to stimulus form. </title> <journal> J. Neurophys. </journal> <volume> 57, </volume> <pages> 835-868. </pages>
Reference-contexts: Thus, a V4 cell receives inputs from V1 cells over a large area and different spatial scales ([9] reports an average receptive field size in V4 of 4.4 ffi of visual angle, as opposed to about 1 ffi in V1; for spatial frequency tuning, <ref> [4] </ref> report an average FWHM of 2.2 octaves, compared to 1.4 (foveally) to 1.8 octaves (parafoveally) in V1 6 ).
Reference: [5] <author> Foldiak, </author> <title> P (1991). Learning invariance from transformation sequences. </title> <booktitle> Neural Computation 3, </booktitle> <pages> 194-200. </pages>
Reference: [6] <author> Foster, KH, Gaska, JP, Nagler, M & Pollen, </author> <title> DA (1985). Spatial and temporal selectivity of neurones in visual cortical areas V1 and V2 of the macaque monkey. </title> <journal> J. Phy. </journal> <volume> 365, </volume> <pages> 331-363. </pages>
Reference: [7] <author> Fukushima, </author> <title> K (1980). Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. </title> <booktitle> Biological Cybernetics 36, </booktitle> <pages> 193-202. </pages>
Reference: [8] <author> Ito, M, Tamura, H, Fujita, I & Tanaka, </author> <title> K (1995). Size and posi tion invariance of neuronal responses in monkey inferotemporal cortex. </title> <journal> J. Neurophys. </journal> <volume> 73, </volume> <pages> 218-226. 5 </pages>
Reference: [9] <author> Kobatake, E & Tanaka, </author> <title> K (1995). Neuronal selectivities to complex object features in the ventral visual pathway of the macaque cerebral cortex J. </title> <journal> Neurophys., </journal> <volume> 71, </volume> <pages> 856-867. </pages>
Reference: [10] <author> Logothetis, NK, Pauls, J & Poggio, </author> <title> T (1995). Shape repre sentation in the inferior temporal cortex of monkeys. </title> <booktitle> Current Biology, </booktitle> <volume> 5, </volume> <pages> 552-563. </pages>
Reference-contexts: It suggests a maximum-like response of intermediate cells as a key mechanism for explaining the properties of view-tuned IT cells, in addition to view-based representations (already described in <ref> [1, 10] </ref>). Neurons in the intermediate layer currently use a very simple set of features. While this appears to be adequate for the class of paperclip objects, more complex filters might be necessary for more complex stimulus classes like faces.
Reference: [11] <author> Nikos Logothetis, </author> <type> personal communication. </type>
Reference: [12] <author> Mel, BW, Ruderman, DL & Archie, </author> <title> KA (1997). Translation invariant orientation tuning in visual `complex' cells could derive from intradendritic computations. </title> <note> Manuscript in preparation. </note>
Reference: [13] <author> Missal, M, Vogels, R & Orban, </author> <title> GA (1997). Responses of macaque inferior temporal neurons to overlapping shapes. </title> <type> Cerebral Cortex 7, </type> <pages> 758-767. </pages>
Reference-contexts: For tile sizes of 8, 16, 32, and 64 pixels, we obtain a recognition rate of 5%, 10%, 33%, and 57%, resp. Thus, as expected, recognizability of scrambled stimuli in the model decreases with decreasing tile size. 3.3 Superposition of Stimuli A very recent paper <ref> [13] </ref> describes changes in IT cell responses to overlapping shapes. The authors report that in general, neuronal responses change dramatically if a background (a polygon of different or same color or texture as the foreground stimulus) is added to the display (consisting of an isolated polygon). <p> We can easily perform the same experiment in our model, by looking at model neurons' responses to the superposition of two stimuli. For this, the stimuli were combinations of the cell's preferred stimulus and another object, either a circle or a square (similar to backgrounds used in <ref> [13] </ref>), as shown in Fig. 6. superimposed on a square. 3 to the superimposed stimuli of Fig. 6. <p> Hence, the superposition of a square interferes with recognition more than that of a circle for our set of features. In general, in qualitative agreement with the findings reported in <ref> [13] </ref>, we observe a strong decrease of model neurons' responses when background shapes are added to the preferred stimulus in the display. 3.4 Multiple Objects A crucial test for the model concerns the question of what happens if multiple stimuli are presented simultaneously in the neuron's receptive field.
Reference: [14] <author> Olshausen, BA, Anderson, CH & Van Essen, </author> <title> DC (1993). A neurobiological model of visual attention and invariant pattern recognition based on dynamic routing of information. </title> <journal> J. Neurosci. </journal> <volume> 13, </volume> <pages> 4700-4719. </pages>
Reference: [15] <author> Perret, D & Oram, </author> <title> M (1993). Neurophysiology of shape pro cessing. </title> <journal> Image Vision Comput. </journal> <volume> 11, </volume> <pages> 317-333. </pages>
Reference-contexts: inferotemporal cortex (IT) have been shown to respond to views of complex objects, 9 such as faces or body parts, even when the retinal image undergoes size changes over several octaves, is translated by several degrees of visual angle 8 or rotated in depth by a certain amount 10 (see <ref> [15] </ref> for a review). These findings have prompted researchers to investigate the physiological mechanisms underlying these tuning properties.
Reference: [16] <author> Poggio, T. </author> <title> Reflections on how the cortex works. </title> <note> In preparation. </note>
Reference-contexts: size and position invariance from one view by a brute force approach essentially scanning the image in x; y and scale and searching for a match with a set of templates. 3 Which mechanism in the brain could be equivalent to the biologically implausible scanning operation? One general hypothesis (see <ref> [16] </ref> for a discussion of computational motivation and of biophysical implementation) that we explore in the specific case studied in this paper is a mechanism of the Winner-Take-All type, implementing search over the inputs and selection of a subset of them (here at the level of each of the V4 cells).
Reference: [17] <author> Poggio, T & Edelman, </author> <title> S (1990). A Network that learns to recognize 3D objects. </title> <booktitle> Nature 343, </booktitle> <pages> 263-266. </pages>
Reference: [18] <author> Reynolds, JH & Desimone, </author> <title> R (1997). Attention and contrast have similar effects on competitive interactions in macaque area V4. </title> <journal> Soc. Neurosc. Abstr. </journal> <volume> 23, </volume> <pages> 302. </pages>
Reference: [19] <author> Riesenhuber, M & Dayan, </author> <title> P (1997). Neural models for part whole hierarchies. </title> <booktitle> In Advances In Neural Information Processing 9, </booktitle> <pages> 17-23. </pages> <publisher> MIT Press. </publisher>
Reference: [20] <author> Ullman, </author> <title> S (1996). High-level vision: Object recognition and visual cognition. </title> <publisher> MIT Press. </publisher> <pages> 6 </pages>
References-found: 20

