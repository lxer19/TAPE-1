URL: http://www-cse.uta.edu/~holder/pubs/pami97.ps
Refering-URL: http://www-cse.uta.edu/~holder/pubs.html
Root-URL: 
Email: Email: fcook, piotr, holderg@cse.uta.edu  
Title: Decision-Theoretic Cooperative Sensor Planning  
Author: Diane J. Cook, Piotr Gmytrasiewicz and Lawrence B. Holder 
Address: Arlington  
Affiliation: Department of Computer Science Engineering University of Texas at  
Abstract: This paper describes a decision-theoretic approach to cooperative sensor planning between multiple autonomous vehicles executing a military mission. For this autonomous vehicle application, intelligent cooperative reasoning must be used to select optimal vehicle viewing locations and select optimal camera pan and tilt angles throughout the mission. Decisions are made in such a way as to maximize the value of information gained by the sensors while maintaining vehicle stealth. Because the mission involves multiple vehicles, cooperation can be used to balance the work load and to increase information gain. This paper presents the theoretical foundations of our cooperative sensor planning research and describes the application of these techniques to ARPA's Unmanned Ground Vehicle program.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Aloimonos, I. Weiss, and A. Bandyopadhyay. </author> <title> Active vision. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1(4) </volume> <pages> 333-356, </pages> <year> 1988. </year>
Reference-contexts: Bajcsy notes that the role of active vision is to gain the most information while minimizing resulting cost. This approach lays the foundation for a decision-theoretic approach to sensor planning. Decision-theoretic approaches to measuring the utility of gathered knowledge have appeared in active vision research <ref> [1, 3, 16, 19] </ref>, but application to the type of military scenario described in this paper involving both static and dynamic decision making represents a new direction in active vision.
Reference: [2] <author> R. C. Arkin and D. MacKenzie. </author> <title> Temporal coordination of perceptual algorithms for mobile robot navigation. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 10(3) </volume> <pages> 276-286, </pages> <year> 1994. </year>
Reference-contexts: Multi-agent planning and negotiation techniques are common in the AI literature [7, 10, 11, 17, 20, 24], but have not been integrated into computer vision work. Some research <ref> [2, 14] </ref> has focused on developing centralized and distributed methods for multi-agent planning specifically in the context of the Unmanned Ground Vehicle project. Again, these projects focus on planning for navigation of the vehicles. Very little work has been investigated on multi-agent techniques for sensor planning and information gathering.
Reference: [3] <author> R. </author> <title> Bajcsy. Active perception. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 76(8) </volume> <pages> 996-1005, </pages> <year> 1988. </year>
Reference-contexts: The camera suite onboard the vehicles can be controlled in terms of pan, tilt, zoom, and focus. These parameters are controlled by our planning systems. 3 Related Work Work on active vision has been well established in the field. Bajcsy <ref> [3] </ref> introduced the idea of active perception as applied to controlling a sensor at any level of abstraction, from 4 5 controlling the focus of the physical device (as we are doing) to controlling the semantic interpretation of information returned from the sensor. <p> Bajcsy notes that the role of active vision is to gain the most information while minimizing resulting cost. This approach lays the foundation for a decision-theoretic approach to sensor planning. Decision-theoretic approaches to measuring the utility of gathered knowledge have appeared in active vision research <ref> [1, 3, 16, 19] </ref>, but application to the type of military scenario described in this paper involving both static and dynamic decision making represents a new direction in active vision.
Reference: [4] <author> R. Bajcsy and M. Campos. </author> <title> Active and exploratory perception. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 56(1) </volume> <pages> 31-40, </pages> <year> 1992. </year> <month> 30 </month>
Reference-contexts: This paper describes a project that uses ideas from multi-agent planning and from sensor planning to allow centralized allocation of major tasks, local control of individual sensor direction, and distributed cooperation between intelligent perceptual agents. Ballard and Brown [5] and Bajcsy and Campos <ref> [4] </ref> both emphasize that learning is an important part of active perception. To date, the probabilities use by our cooperative sensor planning algorithms are hard-coded based on information gathered about the mission and the battlefield area.
Reference: [5] <author> D. H. Ballard and C. M. Brown. </author> <title> Principles of animate vision. </title> <journal> CVGIP: Image Under--standing, </journal> <volume> 56(1) </volume> <pages> 3-21, </pages> <year> 1992. </year>
Reference-contexts: This paper describes a project that uses ideas from multi-agent planning and from sensor planning to allow centralized allocation of major tasks, local control of individual sensor direction, and distributed cooperation between intelligent perceptual agents. Ballard and Brown <ref> [5] </ref> and Bajcsy and Campos [4] both emphasize that learning is an important part of active perception. To date, the probabilities use by our cooperative sensor planning algorithms are hard-coded based on information gathered about the mission and the battlefield area.
Reference: [6] <author> K. R. Boff, L. Kaufman, and J. P. Thomas. </author> <title> Handbook of Perception and Human Performance, Volume 1. </title> <publisher> John Wiley and Sons, </publisher> <year> 1986. </year>
Reference-contexts: A decision-theoretic approach is also motivated by literature in the cognitive science community, which reports that a decision-theoretic approach to sensor planning is also demonstrated in human perception and information gathering <ref> [6, 22] </ref>. While a majority of reported active vision techniques have been applied to assembly, object recognition, and robot monitoring, Camus et al. [8] describe an application of active vision that is closely related to our UGV work.
Reference: [7] <author> W. Briggs and D. J. Cook. </author> <title> Flexible social laws. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (to appear), </booktitle> <year> 1995. </year>
Reference-contexts: While the need for multi-agent planning algorithms is apparent, the development of algorithms which meet each agent's goals in a timely fashion, avoid 6 deadlock, and do not incur heavy communication costs provides a challenging task. Multi-agent planning and negotiation techniques are common in the AI literature <ref> [7, 10, 11, 17, 20, 24] </ref>, but have not been integrated into computer vision work. Some research [2, 14] has focused on developing centralized and distributed methods for multi-agent planning specifically in the context of the Unmanned Ground Vehicle project.
Reference: [8] <author> T. Camus, J. Monsarrat, and T. Dean. </author> <title> Planning and selective perception for target retrieval. </title> <booktitle> In Proceedings of the Image Understanding Workshop, </booktitle> <pages> pages 593-597, </pages> <year> 1993. </year>
Reference-contexts: While a majority of reported active vision techniques have been applied to assembly, object recognition, and robot monitoring, Camus et al. <ref> [8] </ref> describe an application of active vision that is closely related to our UGV work. They have developed a system that employs active vision to perform target detection and retrieval.
Reference: [9] <author> D. Cook. </author> <title> Reconfiguration of multi-agent planning systems. </title> <booktitle> In Proceedings of Artificial Intelligence Planning Systems, </booktitle> <pages> pages 225-230. </pages> <address> AIPS, </address> <year> 1994. </year>
Reference-contexts: The use of multiple vehicles increases the chance of a successful mission because of the increased robustness, increased security, and increased number of observation points for scouting an area. Cook <ref> [9] </ref> describes three types of multi-agent control schemes: central control, distributed control, and local control (no communication). Central control is shown to be effective when communication is reliable, and local control is effective if no communication is needed; otherwise, distributed control is necessary.
Reference: [10] <author> E. H. Durfee and T. A. Montgomery. </author> <title> Coordination as distributed search in a hierarchical behavior space. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 21(6) </volume> <pages> 1363-1378, </pages> <month> Nov/Dec </month> <year> 1991. </year>
Reference-contexts: While the need for multi-agent planning algorithms is apparent, the development of algorithms which meet each agent's goals in a timely fashion, avoid 6 deadlock, and do not incur heavy communication costs provides a challenging task. Multi-agent planning and negotiation techniques are common in the AI literature <ref> [7, 10, 11, 17, 20, 24] </ref>, but have not been integrated into computer vision work. Some research [2, 14] has focused on developing centralized and distributed methods for multi-agent planning specifically in the context of the Unmanned Ground Vehicle project.
Reference: [11] <author> E. Ephrati, M. E. Pollack, and S. </author> <title> Ur. Deriving multi-agent coordination through filtering strategies. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (to appear), </booktitle> <year> 1995. </year>
Reference-contexts: While the need for multi-agent planning algorithms is apparent, the development of algorithms which meet each agent's goals in a timely fashion, avoid 6 deadlock, and do not incur heavy communication costs provides a challenging task. Multi-agent planning and negotiation techniques are common in the AI literature <ref> [7, 10, 11, 17, 20, 24] </ref>, but have not been integrated into computer vision work. Some research [2, 14] has focused on developing centralized and distributed methods for multi-agent planning specifically in the context of the Unmanned Ground Vehicle project.
Reference: [12] <author> J. A. Feldman and R. F. Sproull. </author> <booktitle> Decision theory and artificial intelligence ii: the hungry monkey. Cognitive Science, </booktitle> <volume> 1(2) </volume> <pages> 158-192, </pages> <month> April </month> <year> 1977. </year>
Reference-contexts: The calculation of the expected value of a sensing action has to include the likelihood that the interesting object is located within the area scanned, and that the sensor can successfully recognize the object at that location. Following Feldman and Sproull <ref> [12] </ref>, we propose that the general expression for the value of scanning the area A, using sensor S, from the position P , be: U Scan (A; S; P ) = Z X P 1 c (x; y)P 2 k (x; y)V I k dxdy; (2) where P 1 c (x;
Reference: [13] <author> D. E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: When a new field of view is requested, a biased roulette wheel is spun. Roulette wheel methods have proven to be effective in a variety of adaptive algorithm applications <ref> [13] </ref>. Using this selection method, potential fields of view are assigned a portion of the wheel corresponding to their fraction of the total possible weight. The probability of selecting a given FOV is proportional to the FOV's share of the roulette wheel.
Reference: [14] <author> M. J. Huber and P. G. Kenny. </author> <title> The problem with multiple robots. </title> <booktitle> In CIRFFSS, </booktitle> <year> 1994. </year> <month> 31 </month>
Reference-contexts: Multi-agent planning and negotiation techniques are common in the AI literature [7, 10, 11, 17, 20, 24], but have not been integrated into computer vision work. Some research <ref> [2, 14] </ref> has focused on developing centralized and distributed methods for multi-agent planning specifically in the context of the Unmanned Ground Vehicle project. Again, these projects focus on planning for navigation of the vehicles. Very little work has been investigated on multi-agent techniques for sensor planning and information gathering.
Reference: [15] <author> R. L. Keeney and H. Raiffa. </author> <title> Decisions with multiple objectives: preferences and value tradeoffs. </title> <publisher> John Wiley and Sons, </publisher> <year> 1976. </year>
Reference-contexts: One of the basic results in the multiattribute utility theory states that if the attributes are utility-independent then the global utility can be computed as a multiplicative function over the attributes considered <ref> [15] </ref>.
Reference: [16] <author> E. Krotkov. </author> <title> Active Computer Vision by Cooperative Focus and Stereio. </title> <address> Springer-Verlay, </address> <year> 1989. </year>
Reference-contexts: Bajcsy notes that the role of active vision is to gain the most information while minimizing resulting cost. This approach lays the foundation for a decision-theoretic approach to sensor planning. Decision-theoretic approaches to measuring the utility of gathered knowledge have appeared in active vision research <ref> [1, 3, 16, 19] </ref>, but application to the type of military scenario described in this paper involving both static and dynamic decision making represents a new direction in active vision.
Reference: [17] <author> Y. Moses and M. Tennenholtz. </author> <title> On formal aspects of artificial social systems. </title> <type> Technical Report CS91-01, </type> <institution> Weizmann Institute, </institution> <year> 1991. </year>
Reference-contexts: While the need for multi-agent planning algorithms is apparent, the development of algorithms which meet each agent's goals in a timely fashion, avoid 6 deadlock, and do not incur heavy communication costs provides a challenging task. Multi-agent planning and negotiation techniques are common in the AI literature <ref> [7, 10, 11, 17, 20, 24] </ref>, but have not been integrated into computer vision work. Some research [2, 14] has focused on developing centralized and distributed methods for multi-agent planning specifically in the context of the Unmanned Ground Vehicle project.
Reference: [18] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: One method of learning probability values is through the use of adaptive probabilistic networks, a subset of belief nets that can learn individual probability values and distributions using gradient descent <ref> [18, 21, 23] </ref>. 4 Decision-Theoretic Foundations Our approach to intelligent sensing behavior during a military scouting mission is based on the utility and decision theories.
Reference: [19] <author> R. D. Rimey and C. M. Brown. </author> <title> Control of selecctive perception using bayes nets and decision theory. </title> <journal> International Journal of Computer Vision, </journal> <volume> 12 </volume> <pages> 173-207, </pages> <year> 1994. </year>
Reference-contexts: Bajcsy notes that the role of active vision is to gain the most information while minimizing resulting cost. This approach lays the foundation for a decision-theoretic approach to sensor planning. Decision-theoretic approaches to measuring the utility of gathered knowledge have appeared in active vision research <ref> [1, 3, 16, 19] </ref>, but application to the type of military scenario described in this paper involving both static and dynamic decision making represents a new direction in active vision.
Reference: [20] <author> J. S. Rosenschein and G. Zlotkin. </author> <title> Designing conventions for automated negotiation. </title> <journal> AI Magazine, </journal> <volume> 15(3) </volume> <pages> 29-46, </pages> <month> Fall </month> <year> 1994. </year>
Reference-contexts: While the need for multi-agent planning algorithms is apparent, the development of algorithms which meet each agent's goals in a timely fashion, avoid 6 deadlock, and do not incur heavy communication costs provides a challenging task. Multi-agent planning and negotiation techniques are common in the AI literature <ref> [7, 10, 11, 17, 20, 24] </ref>, but have not been integrated into computer vision work. Some research [2, 14] has focused on developing centralized and distributed methods for multi-agent planning specifically in the context of the Unmanned Ground Vehicle project.
Reference: [21] <author> S. Russell and P. Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference-contexts: One method of learning probability values is through the use of adaptive probabilistic networks, a subset of belief nets that can learn individual probability values and distributions using gradient descent <ref> [18, 21, 23] </ref>. 4 Decision-Theoretic Foundations Our approach to intelligent sensing behavior during a military scouting mission is based on the utility and decision theories.
Reference: [22] <author> M. L. Shaw and P. Shaw. </author> <title> Optimal allocation of cognitive resources to spatial locations. </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 3(2) </volume> <pages> 201-211, </pages> <year> 1977. </year>
Reference-contexts: A decision-theoretic approach is also motivated by literature in the cognitive science community, which reports that a decision-theoretic approach to sensor planning is also demonstrated in human perception and information gathering <ref> [6, 22] </ref>. While a majority of reported active vision techniques have been applied to assembly, object recognition, and robot monitoring, Camus et al. [8] describe an application of active vision that is closely related to our UGV work.
Reference: [23] <author> D. Spiegelhalter, P. Dawid, S. Lauritzen, and R. Cowell. </author> <title> Bayesian analysis in expert systems. </title> <journal> Statistical Science, </journal> <volume> 8 </volume> <pages> 219-282, </pages> <year> 1993. </year>
Reference-contexts: One method of learning probability values is through the use of adaptive probabilistic networks, a subset of belief nets that can learn individual probability values and distributions using gradient descent <ref> [18, 21, 23] </ref>. 4 Decision-Theoretic Foundations Our approach to intelligent sensing behavior during a military scouting mission is based on the utility and decision theories.
Reference: [24] <author> F. von Martial. </author> <title> Coordinating Plans of Autonomous Agents. </title> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: While the need for multi-agent planning algorithms is apparent, the development of algorithms which meet each agent's goals in a timely fashion, avoid 6 deadlock, and do not incur heavy communication costs provides a challenging task. Multi-agent planning and negotiation techniques are common in the AI literature <ref> [7, 10, 11, 17, 20, 24] </ref>, but have not been integrated into computer vision work. Some research [2, 14] has focused on developing centralized and distributed methods for multi-agent planning specifically in the context of the Unmanned Ground Vehicle project.

References-found: 24

