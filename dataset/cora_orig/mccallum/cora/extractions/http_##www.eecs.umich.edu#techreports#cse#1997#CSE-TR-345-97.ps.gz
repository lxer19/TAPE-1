URL: http://www.eecs.umich.edu/techreports/cse/1997/CSE-TR-345-97.ps.gz
Refering-URL: http://www.eecs.umich.edu/home/techreports/cse97.html
Root-URL: http://www.cs.umich.edu
Title: INTERACTIVE DELAYED-SHARING OF COMPUTER-SUPPORTED WORKSPACES VIA THE STREAMING OF RE-EXECUTABLE CONTENT  
Author: by Nelson R. Manohar Professor Daniel E. Atkins, III 
Degree: A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Science and Engineering) in The  Doctoral Committee: Associate Professor Atul Prakash, Chair  Assistant Professor Elke A. Rundensteiner Professor Daniel Teichroew Professor  
Note: Toby J. Teorey  
Date: 1997  
Affiliation: University of Michigan  
Abstract-found: 0
Intro-found: 0
Reference: <institution> 152 BIBLIOGRAPHY </institution>
Reference: [1] <author> H.M. Abdel-Wahab, S. Guan, and J. Nievergelt. </author> <title> Shared workspaces for group collaboration: An experiment using Internet and Unix inter-process communication. </title> <journal> IEEE Comm. Magazine, </journal> <pages> pages 10-16, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: Public resources are assumed to be widely available across platforms. Private resources need to be made available to replay platforms. This is known as the resource mapping problem. This problem has partly been addressed in X pseudo servers, such as Xtv <ref> [1] </ref>, through the use of canonical mapping schemes. The canonical mapping scheme maps resource references made by a sharing-provider display (for example, window identification numbers, font sizes, etc.) into canonical resource references that are de-referenced into local resource references by sharing-subscriber displays. <p> The notion of session and workspaces is central to synchronous computer-supported collaborative work [92]. However, the notion has been absent so far from asynchronous computer-supported collaborative work. Our replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV <ref> [1, 17] </ref> TkReplay [25], DistView [83], SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis [20, 21], Quilt [33], Prep [78, 79], Active Mail [41], Object Lens [55, 64], etc.). <p> Editing and annotation now are performed over an active content artifact that represents an active log, a re-executable process description. 2.3 Delayed-Sharing of Workspaces Shared window systems such as XTV <ref> [1, 17] </ref> XMX [6], Shared-X [38], and window-stream oriented systems for record and replay such as CECED [24], XTRAP [49], TkReplay [25], SCOOT [23], as well as display-based screen camcorders such as Lotus Screen-Cam, and MS Camcorder, in principle, allow replay of unmodified applications.
Reference: [2] <author> D.P. Anderson and R. Kuivila. </author> <title> A system for music performance. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 8(1) </volume> <pages> 56-82, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: The scheduling of discrete events has also been addressed in computer-based musical systems by Anderson in <ref> [2] </ref>. However, there are two major differences. First, MIDI events undergo synchronous re-execution referred to as real-time synthesis. Second, the playback of integrated media is not supported. The playback of stored media requires addressing three basic overheads: (1) fetch, (2) scheduling, and (3) presentation. <p> The schedule compensation adjustment is variable and revised, (upgraded or downgraded, as needed), on every scheduling interval. However, asynchrony floats, under statistical control, during the scheduling interval. Our time deformations are different from temporal transformations, (as in <ref> [2, 39, 63, 89] </ref>). Temporal transformations scale the rate of execution of a global scheduler so as to support features such as fast forward or fast replay. <p> For brevity, we focus only on browsing features. Temporal access controls (TAC) allow the modeling of "VCR-like" (browsing) features as temporal transformations over a logical time system (LTS), as for example found in <ref> [2, 62, 85, 89] </ref>. Building on that model, I then show that the browsing support of the architecture are independent of both tool and media characteristics.
Reference: [3] <author> F. Arman, R. Depommier, A. Hsu, and M.Y. Chiu. </author> <title> Content-based browsing of video sequences. </title> <booktitle> In Proc. of ACM Multimedia '94, </booktitle> <pages> pages 173-180, </pages> <address> San Francisco, CA, USA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: For some streams, in particular the window stream, its contents may be easier to retrieve and classify, than for other streams such as the audio stream. For other streams, such as digital video, content retrieval techniques are being researched (as in <ref> [3, 37] </ref>). However, because the intended domain for markup languages is passive artifacts, as opposed to active artifacts such as session objects, some extensions might be needed. For example, consider the resource mapping problem.
Reference: [4] <author> R. Baker, A. Downing, K. Finn, E. Rennison, D.D. Kim, and Y.H. Lim. </author> <title> Multimedia processing model for a distributed multimedia I/O system. </title> <booktitle> In Proc. of the 3rd Int'l Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <pages> pages 164-175, </pages> <address> La Jolla, CA, USA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: This is a different problem than the playback presentation rate problems addressed in <ref> [4, 63] </ref>. Other important differences limit the suitability of continuous media servers to our requirements. First, there are differences in architectural constraints (for example, see Fig. 2.6) and focus.
Reference: [5] <author> P.C. Bates. </author> <title> Debugging heterogeneous distributed systems using event-based models of behavior. </title> <journal> Transactions on Computer Systems, </journal> <volume> 13(1) </volume> <pages> 1-31, </pages> <year> 1995. </year>
Reference-contexts: Ill choices of q affect scheduling fairness and must accounted for in the mechanisms for playback continuity and smoothness. Many systems enforce full temporal order of asynchronous events with tight synchronization but without continuity guarantees. Examples of these include schedulers used in distributed event simulations <ref> [5, 48, 73] </ref> and causality preserving protocols such as Birman's ISIS [8, 9]. Our research problem can be formulated as enforcing playback continuity over an asynchronous event simulation. Several systems enforce full temporal order of asynchronous events with synchronization and continuity but over coarse event grain.
Reference: [6] <author> John Bazik. XMX: </author> <month> Copyright </month> <year> 1988, 1989, 1990, </year> <institution> Brown University, Dept, Providence, RI, USA. </institution>
Reference-contexts: Editing and annotation now are performed over an active content artifact that represents an active log, a re-executable process description. 2.3 Delayed-Sharing of Workspaces Shared window systems such as XTV [1, 17] XMX <ref> [6] </ref>, Shared-X [38], and window-stream oriented systems for record and replay such as CECED [24], XTRAP [49], TkReplay [25], SCOOT [23], as well as display-based screen camcorders such as Lotus Screen-Cam, and MS Camcorder, in principle, allow replay of unmodified applications.
Reference: [7] <author> P.A. Bernstein. </author> <title> Middleware: A model for distributed system services. </title> <journal> Communications of the ACM, </journal> <volume> 39(2) </volume> <pages> 86-98, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: This is discussed on Chapter 8. This chapter focuses on middleware and its associated framework for extending and managing replay-awareness services on the workspace spanned by multiple applets. As also reported in <ref> [7] </ref>, the notions of tools, API transparency, platform/tool heterogeneity, and a shared data model are essential characteristics to described of middleware services. I examine these notions below (also described in [69]). 6.4 Overview of the Architecture A CSW is composed of multiple tools.
Reference: [8] <author> K. Birman et al. </author> <title> The ISIS System Manual, </title> <note> Version 2.0, </note> <month> April </month> <year> 1990. </year>
Reference-contexts: Many systems enforce full temporal order of asynchronous events with tight synchronization but without continuity guarantees. Examples of these include schedulers used in distributed event simulations [5, 48, 73] and causality preserving protocols such as Birman's ISIS <ref> [8, 9] </ref>. Our research problem can be formulated as enforcing playback continuity over an asynchronous event simulation. Several systems enforce full temporal order of asynchronous events with synchronization and continuity but over coarse event grain.
Reference: [9] <author> K.P. Birman and T.A. Joseph. </author> <title> Reliable communication in the presence of failures. </title> <journal> ACM Transactions on Computer Systems, </journal> <pages> pages 47-76, </pages> <month> February </month> <year> 1987. </year>
Reference-contexts: Many systems enforce full temporal order of asynchronous events with tight synchronization but without continuity guarantees. Examples of these include schedulers used in distributed event simulations [5, 48, 73] and causality preserving protocols such as Birman's ISIS <ref> [8, 9] </ref>. Our research problem can be formulated as enforcing playback continuity over an asynchronous event simulation. Several systems enforce full temporal order of asynchronous events with synchronization and continuity but over coarse event grain.
Reference: [10] <author> J. Birnbaum. </author> <title> How the coming digital utility may reshape computing and telecommunications. </title> <publisher> IEEE Media Briefing, </publisher> <month> October </month> <year> 1996. </year>
Reference-contexts: One such example is found in Birnbaum's pervasive computing, client-utility services <ref> [10, 11] </ref>, a vision of the next generation of internet on which the state of the services resides at the service providers far on the internet cloud.
Reference: [11] <author> J. </author> <title> Birnbaum. </title> <journal> Pervasive information systems. Communications of the ACM, </journal> <volume> 40(2) </volume> <pages> 40-41, </pages> <month> February </month> <year> 1997. </year>
Reference-contexts: In next generations of internet services, based on the notion of the streaming of downloadable content (for example, see Fig. 1.4), state capture, process mobility, and service/platform transparency represent fundamental building blocks of next generation architectures as found on visions of the future of the internet <ref> [11, 54, 56] </ref>. One such example is found in Birnbaum's pervasive computing, client-utility services [10, 11], a vision of the next generation of internet on which the state of the services resides at the service providers far on the internet cloud. <p> One such example is found in Birnbaum's pervasive computing, client-utility services <ref> [10, 11] </ref>, a vision of the next generation of internet on which the state of the services resides at the service providers far on the internet cloud.
Reference: [12] <author> L. Brothers, V. Sembugamoorthy, and M. Muller. ICICLE: </author> <title> Groupware for code inspection. </title> <booktitle> In Proc. of the Second Conference on Computer-Supported Cooperative Work, </booktitle> <pages> pages 169-181, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: Often, reviewers have different areas of expertise. In fact, most of the time, a synchronous collaboration of reviewers with disjoint areas of expertise is both unnecessary and, in some cases, impractical. The feasibility of a synchronous collaboration approach was shown in the ICICLE system <ref> [12] </ref>. Although, there are some benefits to holding such a meeting, providing an asynchronous collaboration mode also seems appropriate. Under our paradigm, the reader role becomes a baseline recording. Each reviewer independently walkthroughs over the code.
Reference: [13] <author> D.C.A. Bulterman and R. van Liere. </author> <title> Multimedia synchronization and UNIX. </title> <booktitle> In Proc. of the 3rd Int'l Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <pages> pages 108-119, </pages> <address> La Jolla, CA, USA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Other important differences limit the suitability of continuous media servers to our requirements. First, there are differences in architectural constraints (for example, see Fig. 2.6) and focus. Research on multimedia extensions for operating systems (see surveys <ref> [13, 97, 93] </ref>) and for file systems [51, 81, 87, 89, 101] address the support of stored continuous multimedia (e.g., predictive prefetching, batched processing, disk layout, optimal buffering, frame interleaving, etc.). On the 17 other hand, this dissertation focuses on best-effort playback on general-purpose platforms. <p> Our synchronization precision was originally targeted to support about 0:100 to :500ms for example, that of audio-annotated slide shows as quoted from <ref> [13] </ref>). Finer grain synchronization would have imposed demands requiring OS-level support [13], thus compromising our goal for high level support (R2). <p> Our synchronization precision was originally targeted to support about 0:100 to :500ms for example, that of audio-annotated slide shows as quoted from <ref> [13] </ref>). Finer grain synchronization would have imposed demands requiring OS-level support [13], thus compromising our goal for high level support (R2). <p> Our synchronization model is based on the notion of a master and multiple slave streams, (as in <ref> [13, 39, 96] </ref>). However, unlike these master/slave models, our approach differs in the following ways. First, synchronization is relative to the progress of the master stream (as opposed to the progress of logical time, as in the Tactus system [90]).
Reference: [14] <author> D.C.A. Bulterman, G. van Rossum, and R. van Liere. </author> <title> A structure for transportable, dynamic multimedia documents. </title> <booktitle> In Proc. of the Summer 1991 USENIX Conference, </booktitle> <pages> pages 137-154, </pages> <address> Nashville, TN, USA., </address> <month> June </month> <year> 1991. </year> <month> 153 </month>
Reference-contexts: This is very similar to our replay by re-execution approach. However, the SCOOT proposal does not address the synchronization of other media streams such as audio wrt the streaming of such re-executable content. 2.4 Authoring of Multimedia Sessions Our research has similarities to multimedia authoring <ref> [14, 15] </ref> (e.g., stored media integration, interactive browsing); however, the problems are significantly different. Authoring systems, such as MacroMind Director, allow specification of interactions over stored digital media such as video, audio, text, and animation. <p> Although our research then seems similar to interactive multimedia presentation research, I focus on fine-grain integration of heterogeneous media streams as opposed to orchestration of heterogeneous document parts. Issues in specification and presentation of multimedia documents have been addressed in Firefly system [15], CMIF <ref> [14] </ref>, and Isis's elastic time [52]. However, the focus of their work is on specification and enforcements of synchronization constraints among high-level parts of a multimedia document. Synchronization at internal points among media segments is not their focus. <p> The session object is thus copied and transported as any other directory. The workspace model addresses the representation of a workspace. Session objects are transportable objects (as the authored sessions from CMIF <ref> [14] </ref>). During playback, the relative temporal progress between its abstract streams must be preserved.
Reference: [15] <author> M. Cecelia-Buchanan and P.T. Zellweger. </author> <title> Scheduling multimedia documents using temporal constraints. </title> <booktitle> In Proc. of the 3rd Int'l Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <pages> pages 237-249, </pages> <address> La Jolla, CA, USA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: This is very similar to our replay by re-execution approach. However, the SCOOT proposal does not address the synchronization of other media streams such as audio wrt the streaming of such re-executable content. 2.4 Authoring of Multimedia Sessions Our research has similarities to multimedia authoring <ref> [14, 15] </ref> (e.g., stored media integration, interactive browsing); however, the problems are significantly different. Authoring systems, such as MacroMind Director, allow specification of interactions over stored digital media such as video, audio, text, and animation. <p> Although our research then seems similar to interactive multimedia presentation research, I focus on fine-grain integration of heterogeneous media streams as opposed to orchestration of heterogeneous document parts. Issues in specification and presentation of multimedia documents have been addressed in Firefly system <ref> [15] </ref>, CMIF [14], and Isis's elastic time [52]. However, the focus of their work is on specification and enforcements of synchronization constraints among high-level parts of a multimedia document. Synchronization at internal points among media segments is not their focus. <p> The mechanisms found in this dissertation can enhance authoring frameworks that are interested in supporting the streaming of re-executable content media parts. Replay of heterogeneous media is addressed in Isis [52] and Firefly <ref> [15] </ref> through online (i.e., run-time) optimization. Their run-time scheduling uses linear programming to merge a hard schedule (for time-invariant streams) with relative, auxiliary schedules (for each asynchronous streams). Their run-time schedule construction is input-size dependent. Thus, implicitly, this linear program relies on the coarseness of media parts. <p> Our research problem can be formulated as enforcing playback continuity over an asynchronous event simulation. Several systems enforce full temporal order of asynchronous events with synchronization and continuity but over coarse event grain. These include schedulers in multimedia authoring systems such as Cecelia-Buchanan/Zellweger's Firefly <ref> [15] </ref> and Kim/Song's Isis [52]. Abstractly, the main 21 difference comes from coarseness of the events they handle. These schedulers deal with high level asynchronous events, more correctly referred to as media parts (such programs and transitions). The coarseness of this grain allows the support of complex temporal relationships.
Reference: [16] <author> M.S. Chen, D.D. Kandlur, and P.S. Yu. </author> <title> Support for fully interactive playout in a disk-array-based video server. </title> <booktitle> In Proc. of ACM Multimedia '94, </booktitle> <pages> pages 391-398, </pages> <address> San Francisco, CA, USA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: However, such statefulness is well-structured (having a pre-determined dependecy structure, predictable length and expected duration). These properties facilitate scheduling and synchronization tasks. For example, consider the algorithms for fast forwarding of MPEG streams in a video server <ref> [16] </ref> which relies on I frames at variable rates since these lack stateful dependencies, possess deterministic playout time, and have inherent periodicity within the MPEG scheme. On the other hand, statefulness on re-executable content streams is arbitrary between streams as well as events within a stream.
Reference: [17] <author> G. Chung, K. Jeffay, and H. Adbel-Wahab. </author> <title> Dynamic participation in computer-based conferencing system. </title> <journal> Journal of Computer Communications, </journal> <volume> 17(1) </volume> <pages> 7-16, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: This way, the need for initial state capture is removed. The capture of state is related to the late join problem. The late join problem has been addressed in the implementation of the XTV system <ref> [17] </ref> by removing the need for state capture by recording all events processed from start-up and on. <p> The notion of session and workspaces is central to synchronous computer-supported collaborative work [92]. However, the notion has been absent so far from asynchronous computer-supported collaborative work. Our replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV <ref> [1, 17] </ref> TkReplay [25], DistView [83], SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis [20, 21], Quilt [33], Prep [78, 79], Active Mail [41], Object Lens [55, 64], etc.). <p> Editing and annotation now are performed over an active content artifact that represents an active log, a re-executable process description. 2.3 Delayed-Sharing of Workspaces Shared window systems such as XTV <ref> [1, 17] </ref> XMX [6], Shared-X [38], and window-stream oriented systems for record and replay such as CECED [24], XTRAP [49], TkReplay [25], SCOOT [23], as well as display-based screen camcorders such as Lotus Screen-Cam, and MS Camcorder, in principle, allow replay of unmodified applications. <p> Read access for the audio stream relies on a parametrized disk-prefetching of audio frames. The replay also introduces problems with the handling of resource references (e.g., fonts, files, devices, etc.) made during the recording of a session <ref> [17] </ref>. On the replay platform, referenced 29 resources may be unavailable and, even worse, if available, may not be in the same functional state. To address the unavailability problem, resource references are classified as being public or private. Public resources are assumed to be widely available across platforms.
Reference: [18] <author> C.R. Clauer, J.D. Kelly, T.J. Rosenberg, C.E. Rasmussen, P. Stauning, E. Friis-Christensen, R.J. Niciejewski, T.L. Killeen, S.B. Mende, Y. Zambre, T.E. Weymouth, A. Prakash, G.M. Ol-son S.E. McDaniel, T.A. Finholt, and D.E. Atkins. </author> <title> A new project to support scientific collaboration electronically. </title> <journal> EOS Transactions on American Geophysical Union, </journal> <volume> 75, </volume> <month> June 28 </month> <year> 1994. </year>
Reference-contexts: experience with various prototypes also made us aware of the potential for the following further uses of the paradigm. 24 3.2.1 The Support of Near-Synchronous Collaboration Our work was originally motivated by the UARC (The Upper Atmospheric Research Collabo-ratory) project, a collaboratory experiment among domain scientists in a wide-area network <ref> [18] </ref>. The domain of research among the scientists is space science. <p> In this chapter, I examine the notion that applications, their workspaces, and sessions on these workspaces in many cases should be temporally-aware. 5.2 Goals and Requirements Our research is partially motivated by the needs of two projects at the University of Michigan: UARC <ref> [18] </ref> and the Medical Collab. Specifically, in the Medical Collab, our goal is to support interactive delayed sharing of the workspace of a radiologist.
Reference: [19] <author> R. Clauer, J.D. Kelly, T.J. Rosenberg, C.E.P. Stauning, E. Friis-Christensen, R.J. Niciejewski, T.L. Killeen, S. Mende, T.E. Weymouth, A. Prakash, S.E. McDaniel, G.M. Olsen, T.A. Finholt, and D.E. Atkins. UARC: </author> <title> A Prototype Upper Atmostpheric Research Collaboratory. </title> <journal> EOS Trans. American Geophys. Union, </journal> <volume> 267(74), </volume> <year> 1993. </year>
Reference-contexts: The aspects of access and interaction with remote and shared facilities are the focus of the prototype Upper Atmospheric Research Collaboratory, or UARC <ref> [19] </ref> | a major collaboration testbed in the space science community funded since September 1992 by the Computer Information Science and Engineering Directorate in cooperation with the Atmospheric Sciences Directorate of the National Science Foundation. The motivation for our research comes from the needs and requirements of the UARC testbed. <p> any effort, perform all the operations of arithmethic, and may be relieved of the work which has often times fatigued your spirit." | Blaise Pascal, 1623-1662. 5.1 Introduction This research was originally motivated by the UARC project (see Fig. 5.1) a collaboratory experiment among space scientists in a wide-area network <ref> [19] </ref>. The domain of research among the scientists is space science. Because domain scientists often work from different time-zones and it is not known a-priori when interesting phenomena will be observed, providing support for session capture, annotation, replay, and exchange should facilitate collaborative work among scientists.
Reference: [20] <author> E.J. Conklin. gIBIS: </author> <title> A hypertext tool for exploratory policy discussion. </title> <booktitle> In Proc. </booktitle> <volume> Groupware '92, </volume> <pages> pages 133-137, </pages> <year> 1992. </year>
Reference-contexts: Our replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay [25], DistView [83], SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis <ref> [20, 21] </ref>, Quilt [33], Prep [78, 79], Active Mail [41], Object Lens [55, 64], etc.). Replayable workspaces provide an artifact that allows asynchronous sharing over the refinement and evolution of a shared workspace.
Reference: [21] <author> J. Conklin and M.L. Begeman. gIBIS: </author> <title> A hypertext tool for exploratory policy discussion. </title> <booktitle> In Proc. of the Second Conference on Computer-Supported Cooperative Work, </booktitle> <pages> pages 140-152, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Our replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay [25], DistView [83], SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis <ref> [20, 21] </ref>, Quilt [33], Prep [78, 79], Active Mail [41], Object Lens [55, 64], etc.). Replayable workspaces provide an artifact that allows asynchronous sharing over the refinement and evolution of a shared workspace.
Reference: [22] <author> J.J. Courant. </author> <title> Softbench message connector: Customizing software development tool interactions. </title> <journal> HP Journal, </journal> <volume> 45(4) </volume> <pages> 34-39, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: In general, the capture and replay of sessions on which interactions span multiple applications pose new challenges. One approach to the integration of heterogeneous applications is centered around extending my temporal-awareness to an intermediary representation or perhaps a software/message bus such as HP's Softbench <ref> [22] </ref>. Such approach requires addressing the following issues: * Intra-tool session capture and replay. First, the tools interfacing to the software bus must be made replay-aware (i.e., capable of capturing and replaying tool's sessions). * Inter-tool session capture and replay. <p> In this approach, the coordination of tool services is deferred to an intermediary process | in our case, referred to as the session manager. This example of tool coordination is typically found in "publish-and-subscribe"/"message-bus" <ref> [22] </ref> systems.
Reference: [23] <author> E. Craighill, M. Fong, K. Skinner, and et. al. SCOOT: </author> <title> An object-oriented toolkit for multimedia collaboration. </title> <booktitle> In Proc. of ACM Multimedia '94, </booktitle> <pages> pages 41-49, </pages> <address> San Francisco, CA, USA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: now are performed over an active content artifact that represents an active log, a re-executable process description. 2.3 Delayed-Sharing of Workspaces Shared window systems such as XTV [1, 17] XMX [6], Shared-X [38], and window-stream oriented systems for record and replay such as CECED [24], XTRAP [49], TkReplay [25], SCOOT <ref> [23] </ref>, as well as display-based screen camcorders such as Lotus Screen-Cam, and MS Camcorder, in principle, allow replay of unmodified applications. These X-based systems work, work coupled with the Window Server on an workstation in one of two ways (see Fig. 2.1). <p> Application-dependent record and replay of a workspace has recently been proposed in the CECED system [24] through its SCOOT project <ref> [23] </ref>. The SCOOT project proposes two approaches to replay of a session. The first approach centers around periodical recording of application state snapshots. The second approach logs invocations to object's methods. This is very similar to our replay by re-execution approach.
Reference: [24] <author> E. Craighill, R. Lang, M. Fong, and K. Skinner. CECED: </author> <title> A system for informal multimedia collaboration. </title> <booktitle> In Proc. of ACM Multimedia '93, </booktitle> <pages> pages 436-446, </pages> <address> CA, USA, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Editing and annotation now are performed over an active content artifact that represents an active log, a re-executable process description. 2.3 Delayed-Sharing of Workspaces Shared window systems such as XTV [1, 17] XMX [6], Shared-X [38], and window-stream oriented systems for record and replay such as CECED <ref> [24] </ref>, XTRAP [49], TkReplay [25], SCOOT [23], as well as display-based screen camcorders such as Lotus Screen-Cam, and MS Camcorder, in principle, allow replay of unmodified applications. These X-based systems work, work coupled with the Window Server on an workstation in one of two ways (see Fig. 2.1). <p> Application-dependent record and replay of a workspace has recently been proposed in the CECED system <ref> [24] </ref> through its SCOOT project [23]. The SCOOT project proposes two approaches to replay of a session. The first approach centers around periodical recording of application state snapshots. The second approach logs invocations to object's methods. This is very similar to our replay by re-execution approach.
Reference: [25] <author> C. Crowley. TkReplay: </author> <title> Record and Replay for Tk. </title> <booktitle> In USENIX Tcl/Tk Workshop, </booktitle> <pages> pages 131-140, </pages> <address> Toronto, Canada, </address> <month> July </month> <year> 1996. </year>
Reference-contexts: The notion of session and workspaces is central to synchronous computer-supported collaborative work [92]. However, the notion has been absent so far from asynchronous computer-supported collaborative work. Our replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay <ref> [25] </ref>, DistView [83], SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis [20, 21], Quilt [33], Prep [78, 79], Active Mail [41], Object Lens [55, 64], etc.). <p> and annotation now are performed over an active content artifact that represents an active log, a re-executable process description. 2.3 Delayed-Sharing of Workspaces Shared window systems such as XTV [1, 17] XMX [6], Shared-X [38], and window-stream oriented systems for record and replay such as CECED [24], XTRAP [49], TkReplay <ref> [25] </ref>, SCOOT [23], as well as display-based screen camcorders such as Lotus Screen-Cam, and MS Camcorder, in principle, allow replay of unmodified applications. These X-based systems work, work coupled with the Window Server on an workstation in one of two ways (see Fig. 2.1).
Reference: [26] <author> R.B. Dannenberg, T. Neuendorffer, J.M. Newcomer, D. Rubine, and D.B. Anderson. Tactus: </author> <title> toolkit-level support for synchronized interactive multimedia. </title> <journal> Multimedia Systems, </journal> <volume> 1(1) </volume> <pages> 77-86, </pages> <month> 1 </month> <year> 1993. </year>
Reference-contexts: Heterogeneity affects both scheduling and synchronization as shown in [66, 71, 85]. In this dissertation, I present mechanisms for the support of the playback of continuous (synchronous) and asynchronous (discrete) streams. 2.6 Scheduling and Synchronization Protocols The Tactus system <ref> [26, 90] </ref> supports the replay of integrated media. However, there are important differences. First, the Tactus system has no notion of relative time. Scheduling of asynchronous media is performed wrt progress of logical time.
Reference: [27] <author> P. Dewan. </author> <title> Flexible user interface coupling in collaborative systems. </title> <booktitle> In Proc. otf the ACM CHI'91 Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 41-48, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: This difference, in the context of synchronous sharing of workspaces, was first examined by Dewan <ref> [27, 28, 29] </ref> (see Fig. 2.2). In general, a complex computation can be associated to resources (say A and B) and data (say DB). Delayed-sharing requires preserving the statefulness on COMP on a different workspace, at a different time.
Reference: [28] <author> P. Dewan and R. Choudhary. </author> <title> Primitives for programming multi-user interfaces. </title> <booktitle> In Proc. of the Fourth ACM SIGGRAPH Symposium on User Interface Software and Technology, </booktitle> <pages> pages 69-78, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: This difference, in the context of synchronous sharing of workspaces, was first examined by Dewan <ref> [27, 28, 29] </ref> (see Fig. 2.2). In general, a complex computation can be associated to resources (say A and B) and data (say DB). Delayed-sharing requires preserving the statefulness on COMP on a different workspace, at a different time.
Reference: [29] <author> P. Dewan and R. Choudhary. </author> <title> A flexible and high-level framework for implementing multi-user user interfaces. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 10(4) </volume> <pages> 345-380, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: This difference, in the context of synchronous sharing of workspaces, was first examined by Dewan <ref> [27, 28, 29] </ref> (see Fig. 2.2). In general, a complex computation can be associated to resources (say A and B) and data (say DB). Delayed-sharing requires preserving the statefulness on COMP on a different workspace, at a different time.
Reference: [30] <author> M. Diaz and P Senac. </author> <title> Time stream petri nets: A model for multimedia streams synchronization. </title> <booktitle> In Proc. of the First Internation Conference on Multi Media Modeling, </booktitle> <pages> pages 257-274, </pages> <address> Singapore, </address> <month> November </month> <year> 1993. </year> <month> 154 </month>
Reference-contexts: There are systems for the enforcement of full temporal order of fine-grained synchronous or periodical tasks with tight synchronization and strong playback continuity. Some examples are schedulers used for continuous media in general purpose systems <ref> [30, 57, 61, 63, 89] </ref> and on real-time systems [34, 44, 46, 99]. However, these scheduling algorithms benefit (on one degree or another) from properties of continuous media not found in applet streams. <p> To specify the asynchronous nature of re-executable content, I use a timing departure model, which results in the modeling of imprecise interval-based relationships. The specification of rich and imprecise n-ary relationships between temporal intervals has been approached through timed petrinets, most markedly, in the object composition petrinets (OCPN) <ref> [30, 61] </ref> and time-flow graphs (TFG) [57, 58]. Asynchronous intermissions during playback are modeled in TFG through intermission nodes that buffer the asynchrony between concurrent relative temporal intervals. Gap filtering is used to remove playout gaps; by recomputing a run-time schedule for the media playout.
Reference: [31] <author> A. Eleftheriadis, S. Pejhan, and D. Anastassiou. </author> <title> Algorithms and Performance Evaluation of the Xphone Multimedia Communication System. </title> <booktitle> Proc. of ACM Multimedia'93, </booktitle> <pages> pages 311-320, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Second, the playback of integrated media is not supported. The playback of stored media requires addressing three basic overheads: (1) fetch, (2) scheduling, and (3) presentation. Unlike with network-based media streaming, in workstation-based streaming, playback overheads (1,2,3) are additive and inter-dependent. Research in network-based streaming, such as <ref> [31, 45, 74, 90, 103] </ref>, relies on adaptive scheduling protocols to manage (bounded) network variability. Their focus is on management of overheads up to the delivery of data to the presentation workstation. These approaches assume processing and presentation on the client workstation incur negligible overheads. <p> Because we are dealing with re-executable content, scheduling needs to be adjusted to compensate for trends during playback on workstations of unequal performance. For example, such compensations are found on the compression and/or expansion of resources such as: (1) idle schedule time [52, 66], (2) silence <ref> [31, 45] </ref>, and (3) presentation frame rate [76]. Let w i be the adaptation effort over a schedule time interval T , thus resulting in the compression (or expansion) of T i into a playback real-time duration w i T . <p> The resource is used as a degree of freedom to compensate for trends in inter-stream asynchrony. For the window stream, the selected resource was the inter-event delay times, for the audio stream a good choice is the duration of silence segments (as in <ref> [31, 74] </ref>), and for the video stream, our choice is the playback frame rate, as suggested in [76]. video stream. In this figure, a maximum video frame rate v max of 16f ps is assumed. <p> Because we are dealing with re-executable content, scheduling needs to be adjusted to compensate for trends during playback on workstations of unequal performance. For example, such compensations are found on the compression and/or expansion of resources such as: (1) idle schedule time [52, 66], (2) silence <ref> [31, 45] </ref>, and (3) presentation frame rate [76]. Let w i be the adaptation effort over a schedule time interval T , thus resulting in the compression (or expansion) of T i into a playback real-time duration w i T .
Reference: [32] <author> C. Ellis and J. </author> <title> Wainer. A conceptual model of groupware. </title> <booktitle> In Proc. of the Fifth Conference on Computer-Supported Cooperative Work, </booktitle> <pages> pages 79-88, </pages> <address> Raleigh, N.C., USA, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: However, since each module is only aware of its neighbor timing constraints, the data-directed approach lacks mechanisms for the compensation of long-term playback trends. Finally, because of its complexity, adding collaboration-awareness to applications usually requires their modification as argued by Ellis <ref> [32] </ref>. The approach taken in this dissertation fits within this classification. Our collaboration-aware features are delivered through an object class, referred to as the Replayable object class. 2.10 Concluding Remarks The contributions of this dissertation relate to two main areas of research: computer-supported collaborative work and multimedia systems.
Reference: [33] <author> R. Fish, R. Kraut, M. Leland, and M. Cohen. Quilt: </author> <title> A collaborative tool for cooperative writing. </title> <booktitle> In Proc. of ACM SIGOIS Conference, </booktitle> <pages> pages 30-37, </pages> <year> 1988. </year>
Reference-contexts: Our replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay [25], DistView [83], SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis [20, 21], Quilt <ref> [33] </ref>, Prep [78, 79], Active Mail [41], Object Lens [55, 64], etc.). Replayable workspaces provide an artifact that allows asynchronous sharing over the refinement and evolution of a shared workspace.
Reference: [34] <author> T. Fisher. </author> <title> Real-time scheduling support in ultrix-4.2 for multimedia communication. </title> <booktitle> In Proc. of the 3rd Int'l Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <pages> pages 321-327, </pages> <address> La Jolla, CA, USA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: There are systems for the enforcement of full temporal order of fine-grained synchronous or periodical tasks with tight synchronization and strong playback continuity. Some examples are schedulers used for continuous media in general purpose systems [30, 57, 61, 63, 89] and on real-time systems <ref> [34, 44, 46, 99] </ref>. However, these scheduling algorithms benefit (on one degree or another) from properties of continuous media not found in applet streams. <p> For example, continuous streams have well-defined events with predictable statefulness (if any); neither dropping nor inserting arbitrary events is possible during the streaming of re-executable content (see Fig. 2.4). Similarly, scheduling mechanisms for continuous streams <ref> [34, 44] </ref> often rely on the fact that the continuous media events (i.e., media frames) have predictable playout times (see Fig. 2.3). On the other hand, because of the asynchronous nature of re-executable content, event playout time is unpredictable.
Reference: [35] <author> S. Flinn. </author> <title> Coordinating heterogeneous time-based media between independent applications. </title> <booktitle> In Proc. of ACM Multimedia '95, </booktitle> <pages> pages 435-444, </pages> <address> San Francisco, CA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: There are modular streaming architectures for the support of interactive playback such as the one from the Interactive Multimedia Association (IMA). The orchestration of multiple applications in a workspace is also approached in <ref> [35] </ref>, through fine-grain synchronization that relies on exception handling. However, this approach lacks the notion and mechanisms to deal with playback continuity and smoothness. The VuSystem [60] uses a different approach; it uses a data-directed propagation of timing constraints between pipelined modules through back-pressure using a ready/not-ready protocol.
Reference: [36] <author> G.E. Fry, A. Jourdan, D.Y. Lee, A.S. Sawkar, N.J. Shah, and W.C. Wiberg. </author> <title> Next generation wireless networks. </title> <journal> Bell Labs Technical Journal, </journal> <volume> 1(2) </volume> <pages> 88-96, </pages> <month> Autumn </month> <year> 1996. </year>
Reference-contexts: The playback of re-executable content streams, together with continuous streams, arises during the streaming of inputs to multiple applets in a workspace. This problem is also of strong interest to next generation multimedia frameworks as found for ubiquitous computing [104], nomadic computing [53], and wireless ATMs <ref> [36] </ref>, with the introduction of time-dependent streaming of re-executable content. The media integration and streaming mechanisms on these frameworks face media heterogeneity. Streaming and integration require us to characterize stream requirements.
Reference: [37] <author> J.D. Gabbe, A. Ginsberg, and B.S. Robinson. </author> <title> Towards intelligent recognition of multimedia episodes in real-time applications. </title> <booktitle> In Proc. of ACM Multimedia '94, </booktitle> <pages> pages 227-236, </pages> <address> San Francisco, CA, USA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: For some streams, in particular the window stream, its contents may be easier to retrieve and classify, than for other streams such as the audio stream. For other streams, such as digital video, content retrieval techniques are being researched (as in <ref> [3, 37] </ref>). However, because the intended domain for markup languages is passive artifacts, as opposed to active artifacts such as session objects, some extensions might be needed. For example, consider the resource mapping problem.
Reference: [38] <author> D. Garfinkel, B.C. Welti, and T.W. Yip. </author> <title> HP SharedX: A tool for real-time collaboration. </title> <journal> HP Journal, </journal> <volume> 45(4) </volume> <pages> 26-33, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: However, the notion has been absent so far from asynchronous computer-supported collaborative work. Our replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay [25], DistView [83], SharedX <ref> [38] </ref>, XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis [20, 21], Quilt [33], Prep [78, 79], Active Mail [41], Object Lens [55, 64], etc.). <p> Editing and annotation now are performed over an active content artifact that represents an active log, a re-executable process description. 2.3 Delayed-Sharing of Workspaces Shared window systems such as XTV [1, 17] XMX [6], Shared-X <ref> [38] </ref>, and window-stream oriented systems for record and replay such as CECED [24], XTRAP [49], TkReplay [25], SCOOT [23], as well as display-based screen camcorders such as Lotus Screen-Cam, and MS Camcorder, in principle, allow replay of unmodified applications.
Reference: [39] <author> S. Gibbs. </author> <title> Composite multimedia and active objects. </title> <booktitle> In Proc. of OOPSLA'91, </booktitle> <pages> pages 97-112, </pages> <address> Phoenix, AZ, USA, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: To preserve temporal correspondence on the playback of asynchronous media, we need to rely on relative scheduling. Relative scheduling of stored media was also approached in [86]. To avoid frequent synchronization overheads, I rely on enforcement of temporal intervals through point synchronization. Synchronization points are discussed by Gibbs on <ref> [39, 40] </ref>. To enforce relationships between multiple streams, I use a modified master-slave model coupled with synchronization handshake. Differing from classical master-slave synchronization (see [40, 96]), I relied on a slave-initiated synchronization handshake. <p> Our synchronization model is based on the notion of a master and multiple slave streams, (as in <ref> [13, 39, 96] </ref>). However, unlike these master/slave models, our approach differs in the following ways. First, synchronization is relative to the progress of the master stream (as opposed to the progress of logical time, as in the Tactus system [90]). <p> The schedule compensation adjustment is variable and revised, (upgraded or downgraded, as needed), on every scheduling interval. However, asynchrony floats, under statistical control, during the scheduling interval. Our time deformations are different from temporal transformations, (as in <ref> [2, 39, 63, 89] </ref>). Temporal transformations scale the rate of execution of a global scheduler so as to support features such as fast forward or fast replay.
Reference: [40] <author> S. Gibbs, L. Dami, and D. Tsichritzis. </author> <title> An object-oriented framework for multimedia composition and synchronization. In Multimedia Systems, Interaction and Applications: </title> <booktitle> Proc. of the First Eurographics Workshop, </booktitle> <pages> pages 101-111. </pages> <publisher> Springer-Verlag, </publisher> <month> April </month> <year> 1991. </year>
Reference-contexts: To preserve temporal correspondence on the playback of asynchronous media, we need to rely on relative scheduling. Relative scheduling of stored media was also approached in [86]. To avoid frequent synchronization overheads, I rely on enforcement of temporal intervals through point synchronization. Synchronization points are discussed by Gibbs on <ref> [39, 40] </ref>. To enforce relationships between multiple streams, I use a modified master-slave model coupled with synchronization handshake. Differing from classical master-slave synchronization (see [40, 96]), I relied on a slave-initiated synchronization handshake. <p> To avoid frequent synchronization overheads, I rely on enforcement of temporal intervals through point synchronization. Synchronization points are discussed by Gibbs on [39, 40]. To enforce relationships between multiple streams, I use a modified master-slave model coupled with synchronization handshake. Differing from classical master-slave synchronization (see <ref> [40, 96] </ref>), I relied on a slave-initiated synchronization handshake. This policy-independent synchronization handshake results in a "publish-and-subscribe" model to point synchronization that facilitates relative synchronization across multiple streams. To specify relationships between multiple streams, I use n-ary relationships. These are enforced as multiple binary, point-based, relationships. <p> Appendix E specifies the various protocols considered in the experiments described through this dissertation in terms of their handling of these asynchrony cases. Protocol P1 and P2 relate to Gibbs' NoSync and InterruptSync synchronization modes between master and slaves found in <ref> [40] </ref>. Protocol P3 is our adaptive scheduling algorithm. Protocol P4 is a two-way, stop and wait, protocol for relative synchronization of discrete streams. 4.3.6 Adaptive Scheduling Mechanism The basic idea behind our adaptive mechanism was illustrated in Fig. 4.1. Next, we generalize and analyze this adaptive mechanism.
Reference: [41] <author> V. Goldberg, M. Safran, and E. Shapiro. </author> <title> Active Mail: A framework for implementing group-ware. </title> <booktitle> In Proc. of the Fourth Conference on Computer-Supported Cooperative Work, </booktitle> <pages> pages 75-83, </pages> <address> Toronto, Canada, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: However, the notion has been absent from asynchronous computer-supported collaborative work. Several systems for the support of asynchronous collaboration provide ways to model the interactions among users and the evolution of collaboration repositories <ref> [41, 55, 79] </ref>. Our work represents a complimentary paradigm for asynchronous collaboration that allows users to record and replay a session. <p> replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay [25], DistView [83], SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis [20, 21], Quilt [33], Prep [78, 79], Active Mail <ref> [41] </ref>, Object Lens [55, 64], etc.). Replayable workspaces provide an artifact that allows asynchronous sharing over the refinement and evolution of a shared workspace. <p> 23 CHAPTER 3 THE PARADIGM OF SESSION RECORD AND REPLAY FOR ASYNCHRONOUS COLLABORATION "... and all our knowledge is ourselves to keep." | Alexander Pope. 1688-1744. 3.1 Introduction Several systems for the support of asynchronous collaboration provide ways to model the interactions among users and the evolution of collaboration repositories <ref> [41, 55, 79] </ref>. In this chapter, we present a complimentary paradigm for asynchronous collaboration that allows users to record and replay an interactive session with an application.
Reference: [42] <author> J.L. Herlocker and J.A. Konstan. </author> <title> Commands as media: design and implementation of a command stream. </title> <booktitle> In Proc. of ACM Multimedia '95, </booktitle> <pages> pages 155-166, </pages> <address> San Francisco, CA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: On the other hand, we focus on fine-grained asynchronous events. These events are typically found inside a single media part (such as a program). Both approaches are needed and complementary. The streaming of re-executable content is also found, most evidently, in the TclCommand stream <ref> [42] </ref> extension to the CM/T system [89]. Because the CM/T is centered around continuous streams, it lacks the mechanisms for smoothing timing departures during the playback of asynchronous events. Unaccounted timing departures cause synchronization to introduce playback discontinuities to other continuous streams.
Reference: [43] <author> T.Y. Hou, A. Hsu, M.Y. Chiu, S.K. Chang, and H.J. Chang. </author> <title> An active multimedia system for delayed conferencing. </title> <booktitle> Proceedings of the SPIE, High-speed Networking and Multimedia Computing; SPIE, </booktitle> <volume> 2188 </volume> <pages> 97-104, </pages> <year> 1994. </year>
Reference-contexts: Inter-task content, on the other hand, refers to the decisions themselves. Annotating and editing provide a fundamental mechanism of collaboration between asynchronous collaborators: versioning of a shared artifact through iterative exchange and refinement. Delayed-time collaborative groupware systems (e.g., Siemens's <ref> [43] </ref>, GMD's Dolphin [100], Lotus's Notes, etc.) allow users to work asynchronously via annotations added to a shared object (a document composed of rich media parts).
Reference: [44] <author> K. Jeffay. </author> <title> On latency management in time-shared operating systems. </title> <booktitle> In Proc. of the 11th IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <pages> pages 86-90, </pages> <address> Seattle, WA, USA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: There are systems for the enforcement of full temporal order of fine-grained synchronous or periodical tasks with tight synchronization and strong playback continuity. Some examples are schedulers used for continuous media in general purpose systems [30, 57, 61, 63, 89] and on real-time systems <ref> [34, 44, 46, 99] </ref>. However, these scheduling algorithms benefit (on one degree or another) from properties of continuous media not found in applet streams. <p> For example, continuous streams have well-defined events with predictable statefulness (if any); neither dropping nor inserting arbitrary events is possible during the streaming of re-executable content (see Fig. 2.4). Similarly, scheduling mechanisms for continuous streams <ref> [34, 44] </ref> often rely on the fact that the continuous media events (i.e., media frames) have predictable playout times (see Fig. 2.3). On the other hand, because of the asynchronous nature of re-executable content, event playout time is unpredictable. <p> Such a-priori knowledge about the predictability and periodicity of event playback is an inherent assumption built-in on scheduling mechanisms for the playback of continuous media (both Schulzrinne [93] and Steinmetz [97] made similar observations). For example, this is particularly true for deadline-based of continuous media <ref> [47, 44, 75] </ref>. On the other hand, a re-executable content stream lacks periodicity. In this dissertation, I provide a playback characterization of re-executable content streams based on the relative inter-arrival distributions of sequences of discrete events on a re-executable content stream. <p> This characterization provides a foundation for the integration of heterogeneous media streams. A sporadic server [46] can be coupled with a deadline-based real-time scheduler [84] so as to handle the integration of asynchronous and continuous media by deadline-based schedulers <ref> [44, 97] </ref>. The sporadic server is used to handle all asynchronous events with unpredictable playout time. The sporadic server is given a CPU time allotment fraction q% to process asynchronous events. However, when we consider the streaming of re-executable content, two problems arise with this approach.
Reference: [45] <author> K. Jeffay, D. Stone, and F. Smith. </author> <title> Transport and display mechanisms for multimedia conferencing across packet switched networks. </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> 26(10) </volume> <pages> 1281-1304, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: Second, the playback of integrated media is not supported. The playback of stored media requires addressing three basic overheads: (1) fetch, (2) scheduling, and (3) presentation. Unlike with network-based media streaming, in workstation-based streaming, playback overheads (1,2,3) are additive and inter-dependent. Research in network-based streaming, such as <ref> [31, 45, 74, 90, 103] </ref>, relies on adaptive scheduling protocols to manage (bounded) network variability. Their focus is on management of overheads up to the delivery of data to the presentation workstation. These approaches assume processing and presentation on the client workstation incur negligible overheads. <p> Because we are dealing with re-executable content, scheduling needs to be adjusted to compensate for trends during playback on workstations of unequal performance. For example, such compensations are found on the compression and/or expansion of resources such as: (1) idle schedule time [52, 66], (2) silence <ref> [31, 45] </ref>, and (3) presentation frame rate [76]. Let w i be the adaptation effort over a schedule time interval T , thus resulting in the compression (or expansion) of T i into a playback real-time duration w i T . <p> Because we are dealing with re-executable content, scheduling needs to be adjusted to compensate for trends during playback on workstations of unequal performance. For example, such compensations are found on the compression and/or expansion of resources such as: (1) idle schedule time [52, 66], (2) silence <ref> [31, 45] </ref>, and (3) presentation frame rate [76]. Let w i be the adaptation effort over a schedule time interval T , thus resulting in the compression (or expansion) of T i into a playback real-time duration w i T .
Reference: [46] <author> K. Jeffay and D.L. Stone. </author> <title> Accounting for interrupt handling costs in dynamic priority task systems. </title> <booktitle> In Proc. of the 14th IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 212-221, </pages> <address> Raleigh-Durham, NC, USA, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: There are systems for the enforcement of full temporal order of fine-grained synchronous or periodical tasks with tight synchronization and strong playback continuity. Some examples are schedulers used for continuous media in general purpose systems [30, 57, 61, 63, 89] and on real-time systems <ref> [34, 44, 46, 99] </ref>. However, these scheduling algorithms benefit (on one degree or another) from properties of continuous media not found in applet streams. <p> In this dissertation, I provide a playback characterization of re-executable content streams based on the relative inter-arrival distributions of sequences of discrete events on a re-executable content stream. This characterization provides a foundation for the integration of heterogeneous media streams. A sporadic server <ref> [46] </ref> can be coupled with a deadline-based real-time scheduler [84] so as to handle the integration of asynchronous and continuous media by deadline-based schedulers [44, 97]. The sporadic server is used to handle all asynchronous events with unpredictable playout time.
Reference: [47] <author> K. Jeffay, D.L. Stone, and F. Donelson. </author> <title> Kernel support for live digital audio and video. </title> <journal> Computer Communications, </journal> <volume> 15(6) </volume> <pages> 388-395, </pages> <month> July </month> <year> 1992. </year> <month> 155 </month>
Reference-contexts: This dissertation contains mechanisms that address such timing variability at the client workstation. As a result, our workstation-based mechanisms could be coupled on top of existing network-based mechanisms. Research on management of fetch overheads [87, 89] and scheduling overheads <ref> [47, 75] </ref> focuses on (low-level) multimedia operating system enhancements for the support of continuous media. Kernel-level management of inter-dependent overheads between competing processes is approached by Mercer in [72]. <p> Such a-priori knowledge about the predictability and periodicity of event playback is an inherent assumption built-in on scheduling mechanisms for the playback of continuous media (both Schulzrinne [93] and Steinmetz [97] made similar observations). For example, this is particularly true for deadline-based of continuous media <ref> [47, 44, 75] </ref>. On the other hand, a re-executable content stream lacks periodicity. In this dissertation, I provide a playback characterization of re-executable content streams based on the relative inter-arrival distributions of sequences of discrete events on a re-executable content stream.
Reference: [48] <author> D.R. Jefferson. </author> <title> Synchronization in distributed simulation. </title> <booktitle> Proc. International Computers in Engineering 4-8 Aug. 1985, publ by ASME, </booktitle> <address> New York, NY, USA, </address> <pages> pages 407-413, </pages> <year> 1985. </year>
Reference-contexts: Ill choices of q affect scheduling fairness and must accounted for in the mechanisms for playback continuity and smoothness. Many systems enforce full temporal order of asynchronous events with tight synchronization but without continuity guarantees. Examples of these include schedulers used in distributed event simulations <ref> [5, 48, 73] </ref> and causality preserving protocols such as Birman's ISIS [8, 9]. Our research problem can be formulated as enforcing playback continuity over an asynchronous event simulation. Several systems enforce full temporal order of asynchronous events with synchronization and continuity but over coarse event grain.
Reference: [49] <author> O. Jones. </author> <title> Multidisplay software in x: A survey of architectures. The X Resource, </title> <publisher> O'Reilly & Associates, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: However, the notion has been absent so far from asynchronous computer-supported collaborative work. Our replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay [25], DistView [83], SharedX [38], XMX/XTRAP <ref> [49] </ref>, etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis [20, 21], Quilt [33], Prep [78, 79], Active Mail [41], Object Lens [55, 64], etc.). Replayable workspaces provide an artifact that allows asynchronous sharing over the refinement and evolution of a shared workspace. <p> Editing and annotation now are performed over an active content artifact that represents an active log, a re-executable process description. 2.3 Delayed-Sharing of Workspaces Shared window systems such as XTV [1, 17] XMX [6], Shared-X [38], and window-stream oriented systems for record and replay such as CECED [24], XTRAP <ref> [49] </ref>, TkReplay [25], SCOOT [23], as well as display-based screen camcorders such as Lotus Screen-Cam, and MS Camcorder, in principle, allow replay of unmodified applications. These X-based systems work, work coupled with the Window Server on an workstation in one of two ways (see Fig. 2.1).
Reference: [50] <author> S. Kaplan, W. Tolone, D. Bogia, and C. Bignoli. </author> <title> Flexible, active support for collaborative work with ConversationBuilder. </title> <booktitle> In Proc. of the Fourth Conference on Computer-Supported Cooperative Work, </booktitle> <pages> pages 378-385, </pages> <address> Toronto, Canada, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: Our replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay [25], DistView [83], SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder <ref> [50] </ref>, Strudel [95], gIbis [20, 21], Quilt [33], Prep [78, 79], Active Mail [41], Object Lens [55, 64], etc.). Replayable workspaces provide an artifact that allows asynchronous sharing over the refinement and evolution of a shared workspace.
Reference: [51] <author> H.P. Katseff and B.S. Robinson. </author> <title> Predictive prefetch in the Nemesis multimedia information service. </title> <booktitle> In Proc. of ACM Multimedia '94, </booktitle> <pages> pages 201-210, </pages> <address> San Francisco, CA, USA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: Other important differences limit the suitability of continuous media servers to our requirements. First, there are differences in architectural constraints (for example, see Fig. 2.6) and focus. Research on multimedia extensions for operating systems (see surveys [13, 97, 93]) and for file systems <ref> [51, 81, 87, 89, 101] </ref> address the support of stored continuous multimedia (e.g., predictive prefetching, batched processing, disk layout, optimal buffering, frame interleaving, etc.). On the 17 other hand, this dissertation focuses on best-effort playback on general-purpose platforms.
Reference: [52] <author> M.Y. Kim and J. Song. </author> <title> Multimedia documents with elastic time. </title> <booktitle> In Proc. of ACM Multimedia '95, </booktitle> <pages> pages 143-154, </pages> <address> San Francisco, CA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: Although our research then seems similar to interactive multimedia presentation research, I focus on fine-grain integration of heterogeneous media streams as opposed to orchestration of heterogeneous document parts. Issues in specification and presentation of multimedia documents have been addressed in Firefly system [15], CMIF [14], and Isis's elastic time <ref> [52] </ref>. However, the focus of their work is on specification and enforcements of synchronization constraints among high-level parts of a multimedia document. Synchronization at internal points among media segments is not their focus. <p> The mechanisms found in this dissertation can enhance authoring frameworks that are interested in supporting the streaming of re-executable content media parts. Replay of heterogeneous media is addressed in Isis <ref> [52] </ref> and Firefly [15] through online (i.e., run-time) optimization. Their run-time scheduling uses linear programming to merge a hard schedule (for time-invariant streams) with relative, auxiliary schedules (for each asynchronous streams). Their run-time schedule construction is input-size dependent. Thus, implicitly, this linear program relies on the coarseness of media parts. <p> Our research problem can be formulated as enforcing playback continuity over an asynchronous event simulation. Several systems enforce full temporal order of asynchronous events with synchronization and continuity but over coarse event grain. These include schedulers in multimedia authoring systems such as Cecelia-Buchanan/Zellweger's Firefly [15] and Kim/Song's Isis <ref> [52] </ref>. Abstractly, the main 21 difference comes from coarseness of the events they handle. These schedulers deal with high level asynchronous events, more correctly referred to as media parts (such programs and transitions). The coarseness of this grain allows the support of complex temporal relationships. <p> Because we are dealing with re-executable content, scheduling needs to be adjusted to compensate for trends during playback on workstations of unequal performance. For example, such compensations are found on the compression and/or expansion of resources such as: (1) idle schedule time <ref> [52, 66] </ref>, (2) silence [31, 45], and (3) presentation frame rate [76]. Let w i be the adaptation effort over a schedule time interval T , thus resulting in the compression (or expansion) of T i into a playback real-time duration w i T . <p> Because we are dealing with re-executable content, scheduling needs to be adjusted to compensate for trends during playback on workstations of unequal performance. For example, such compensations are found on the compression and/or expansion of resources such as: (1) idle schedule time <ref> [52, 66] </ref>, (2) silence [31, 45], and (3) presentation frame rate [76]. Let w i be the adaptation effort over a schedule time interval T , thus resulting in the compression (or expansion) of T i into a playback real-time duration w i T .
Reference: [53] <author> L. Kleinrock. Nomadicity: Anytime, </author> <title> anywhere in a disconnected world. Mobile Networks and Applications, </title> <type> 1(4), </type> <month> January </month> <year> 1996. </year>
Reference-contexts: The streaming of re-executable content is also found in next generation internet downloadable content technologies such as with the program capsules of Tennenhouse's proposed active networks [102] on in Kleinrock's notions of nomadicity <ref> [53] </ref>. In general, the streaming of re-executable content arises whenever a remote repository is used to store state and input behavior of one or more distributed computer appliances, for example in internet computers, in the next generation wireless (mobile/nomadic) computing appliances. <p> The playback of re-executable content streams, together with continuous streams, arises during the streaming of inputs to multiple applets in a workspace. This problem is also of strong interest to next generation multimedia frameworks as found for ubiquitous computing [104], nomadic computing <ref> [53] </ref>, and wireless ATMs [36], with the introduction of time-dependent streaming of re-executable content. The media integration and streaming mechanisms on these frameworks face media heterogeneity. Streaming and integration require us to characterize stream requirements.
Reference: [54] <author> H.F. Korth and A. Silbershatz. </author> <title> Database research faces the information explosion. </title> <journal> Communications of the ACM, </journal> <volume> 40(2) </volume> <pages> 139-142, </pages> <month> February </month> <year> 1997. </year>
Reference-contexts: In next generations of internet services, based on the notion of the streaming of downloadable content (for example, see Fig. 1.4), state capture, process mobility, and service/platform transparency represent fundamental building blocks of next generation architectures as found on visions of the future of the internet <ref> [11, 54, 56] </ref>. One such example is found in Birnbaum's pervasive computing, client-utility services [10, 11], a vision of the next generation of internet on which the state of the services resides at the service providers far on the internet cloud.
Reference: [55] <author> K.Y. Lai, T.W. Malone, and K.C. Yu. </author> <title> Object Lens: A "spreadsheet" for cooperative work. </title> <journal> ACM Transactions on Office and Information Systems, </journal> <volume> 6(4) </volume> <pages> 332-353, </pages> <year> 1988. </year>
Reference-contexts: However, the notion has been absent from asynchronous computer-supported collaborative work. Several systems for the support of asynchronous collaboration provide ways to model the interactions among users and the evolution of collaboration repositories <ref> [41, 55, 79] </ref>. Our work represents a complimentary paradigm for asynchronous collaboration that allows users to record and replay a session. <p> couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay [25], DistView [83], SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis [20, 21], Quilt [33], Prep [78, 79], Active Mail [41], Object Lens <ref> [55, 64] </ref>, etc.). Replayable workspaces provide an artifact that allows asynchronous sharing over the refinement and evolution of a shared workspace. <p> 23 CHAPTER 3 THE PARADIGM OF SESSION RECORD AND REPLAY FOR ASYNCHRONOUS COLLABORATION "... and all our knowledge is ourselves to keep." | Alexander Pope. 1688-1744. 3.1 Introduction Several systems for the support of asynchronous collaboration provide ways to model the interactions among users and the evolution of collaboration repositories <ref> [41, 55, 79] </ref>. In this chapter, we present a complimentary paradigm for asynchronous collaboration that allows users to record and replay an interactive session with an application.
Reference: [56] <author> B. Leiner, V. Cerf, D. Clark, R. Kahn, L. Kleinrock, D. Lynch, J. Postel, L. Roberts, and S. Wolf. </author> <title> The past and future history of the internet. </title> <journal> Communications of the ACM, </journal> <volume> 40(2) </volume> <pages> 102-108, </pages> <month> February </month> <year> 1997. </year>
Reference-contexts: In next generations of internet services, based on the notion of the streaming of downloadable content (for example, see Fig. 1.4), state capture, process mobility, and service/platform transparency represent fundamental building blocks of next generation architectures as found on visions of the future of the internet <ref> [11, 54, 56] </ref>. One such example is found in Birnbaum's pervasive computing, client-utility services [10, 11], a vision of the next generation of internet on which the state of the services resides at the service providers far on the internet cloud.
Reference: [57] <author> L. Li, A. Karmouch, </author> <title> and N.D. Georganas. Multimedia teleorchestra with independent sources: Part 2 | synchronization algorithms. </title> <journal> Multimedia Systems, </journal> <volume> 1(2) </volume> <pages> 154-165, </pages> <month> Spring </month> <year> 1994. </year>
Reference-contexts: There are systems for the enforcement of full temporal order of fine-grained synchronous or periodical tasks with tight synchronization and strong playback continuity. Some examples are schedulers used for continuous media in general purpose systems <ref> [30, 57, 61, 63, 89] </ref> and on real-time systems [34, 44, 46, 99]. However, these scheduling algorithms benefit (on one degree or another) from properties of continuous media not found in applet streams. <p> The specification of rich and imprecise n-ary relationships between temporal intervals has been approached through timed petrinets, most markedly, in the object composition petrinets (OCPN) [30, 61] and time-flow graphs (TFG) <ref> [57, 58] </ref>. Asynchronous intermissions during playback are modeled in TFG through intermission nodes that buffer the asynchrony between concurrent relative temporal intervals. Gap filtering is used to remove playout gaps; by recomputing a run-time schedule for the media playout. <p> Variability f o (A) present during replay is controlled through (1) prefetching of frames and (2) slave-initiated synchronization measures. timing between lhs and rhs streams involved in a synchronization dependency. In this notation, rhs streams synchronize to the lhs stream. In terms of temporal specification notations found in <ref> [57, 61] </ref>, our synchronization specifically preserves the relative synchronization relationship (e i same a j ) between window and audio streams. Figure 4.2 shows the use of a synchronization event s i (A W ), where A is the audio stream and W is the window stream.
Reference: [58] <author> L. Li, A. Karmouch, </author> <title> and N.D. Georganas. Multimedia teleorchestra with independent sources: Part 1 | temporal modeling of collaborative multimedia scenarios. </title> <journal> Multimedia Systems, </journal> <volume> 1(2) </volume> <pages> 143-153, </pages> <month> Spring </month> <year> 1994. </year>
Reference-contexts: To specify relationships between multiple streams, I use n-ary relationships. These are enforced as multiple binary, point-based, relationships. Work on n-ary relationships and their decomposition into binary relationships is also found in the TeleOrchestra <ref> [58] </ref>. To specify the asynchronous nature of re-executable content, I use a timing departure model, which results in the modeling of imprecise interval-based relationships. <p> The specification of rich and imprecise n-ary relationships between temporal intervals has been approached through timed petrinets, most markedly, in the object composition petrinets (OCPN) [30, 61] and time-flow graphs (TFG) <ref> [57, 58] </ref>. Asynchronous intermissions during playback are modeled in TFG through intermission nodes that buffer the asynchrony between concurrent relative temporal intervals. Gap filtering is used to remove playout gaps; by recomputing a run-time schedule for the media playout.
Reference: [59] <author> Y. Ligier, O. Ratib, M. Logean, and C. Girard. </author> <title> Osiris : A medical image manipulation system. M.D. </title> <journal> Computing Journal, </journal> <volume> 11(4) </volume> <pages> 212-218, </pages> <address> July-August 94. </address>
Reference-contexts: These components (application, streams, DSP, CPU, infrastructure services, disk, and data paths) are shown in Fig. 5.5 and 5.6. Fig. 5.5 shows the record-time view. Fig. 5.6 shows the replay-time view of the prototype. 5.4.2 Replayable Workspaces To explore our replayable workspace ideas, we used the Osiris II tool <ref> [59] </ref> from the University Hospital of Geneva, to provide the "look-and-feel" of the radiology domain.
Reference: [60] <author> C.J. Lindblad, </author> <title> D.J. Wetherall, and D.L. Tennenhouse. The VuSystem: A programming system for visual processing of digital video. </title> <booktitle> In Proc. of ACM Multimedia '94, </booktitle> <pages> pages 307-314, </pages> <address> San Francisco, CA, USA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: The orchestration of multiple applications in a workspace is also approached in [35], through fine-grain synchronization that relies on exception handling. However, this approach lacks the notion and mechanisms to deal with playback continuity and smoothness. The VuSystem <ref> [60] </ref> uses a different approach; it uses a data-directed propagation of timing constraints between pipelined modules through back-pressure using a ready/not-ready protocol. However, since each module is only aware of its neighbor timing constraints, the data-directed approach lacks mechanisms for the compensation of long-term playback trends.
Reference: [61] <author> T. Little and F. Ghafoor. </author> <title> Models for multimedia objects. </title> <journal> IEEE Journal of Selected Areas of Communication, </journal> <volume> 8(3), </volume> <month> April </month> <year> 1990. </year>
Reference-contexts: There are systems for the enforcement of full temporal order of fine-grained synchronous or periodical tasks with tight synchronization and strong playback continuity. Some examples are schedulers used for continuous media in general purpose systems <ref> [30, 57, 61, 63, 89] </ref> and on real-time systems [34, 44, 46, 99]. However, these scheduling algorithms benefit (on one degree or another) from properties of continuous media not found in applet streams. <p> To specify the asynchronous nature of re-executable content, I use a timing departure model, which results in the modeling of imprecise interval-based relationships. The specification of rich and imprecise n-ary relationships between temporal intervals has been approached through timed petrinets, most markedly, in the object composition petrinets (OCPN) <ref> [30, 61] </ref> and time-flow graphs (TFG) [57, 58]. Asynchronous intermissions during playback are modeled in TFG through intermission nodes that buffer the asynchrony between concurrent relative temporal intervals. Gap filtering is used to remove playout gaps; by recomputing a run-time schedule for the media playout. <p> Variability f o (A) present during replay is controlled through (1) prefetching of frames and (2) slave-initiated synchronization measures. timing between lhs and rhs streams involved in a synchronization dependency. In this notation, rhs streams synchronize to the lhs stream. In terms of temporal specification notations found in <ref> [57, 61] </ref>, our synchronization specifically preserves the relative synchronization relationship (e i same a j ) between window and audio streams. Figure 4.2 shows the use of a synchronization event s i (A W ), where A is the audio stream and W is the window stream.
Reference: [62] <author> T.D.C. Little. </author> <title> A framework for synchronous delivery of time-dependent multimedia systems. </title> <journal> Multimedia Systems, </journal> <volume> 1(1) </volume> <pages> 87-94, </pages> <year> 1993. </year>
Reference-contexts: Next, we generalize and analyze this adaptive mechanism. Our approach to per-stream scheduling intervals is different from the use of global (that is, across all streams) scheduling intervals (e.g., as in <ref> [62] </ref>). The scheduling interval of a stream contains all events between consecutive synchronization events s i and s i+1 . In general, because of the asymmetry of 1-Way protocols, a window synchronization event (A W ) can only preserve 37 window stream. Part (a) shows the original scheduling interval. <p> For brevity, we focus only on browsing features. Temporal access controls (TAC) allow the modeling of "VCR-like" (browsing) features as temporal transformations over a logical time system (LTS), as for example found in <ref> [2, 62, 85, 89] </ref>. Building on that model, I then show that the browsing support of the architecture are independent of both tool and media characteristics.
Reference: [63] <author> P. Lougher and D. Shepherd. </author> <title> The design of storage servers for continuous multimedia. </title> <journal> The Computer Journal, </journal> <volume> 63(1) </volume> <pages> 69-91, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: This is a different problem than the playback presentation rate problems addressed in <ref> [4, 63] </ref>. Other important differences limit the suitability of continuous media servers to our requirements. First, there are differences in architectural constraints (for example, see Fig. 2.6) and focus. <p> There are systems for the enforcement of full temporal order of fine-grained synchronous or periodical tasks with tight synchronization and strong playback continuity. Some examples are schedulers used for continuous media in general purpose systems <ref> [30, 57, 61, 63, 89] </ref> and on real-time systems [34, 44, 46, 99]. However, these scheduling algorithms benefit (on one degree or another) from properties of continuous media not found in applet streams. <p> The schedule compensation adjustment is variable and revised, (upgraded or downgraded, as needed), on every scheduling interval. However, asynchrony floats, under statistical control, during the scheduling interval. Our time deformations are different from temporal transformations, (as in <ref> [2, 39, 63, 89] </ref>). Temporal transformations scale the rate of execution of a global scheduler so as to support features such as fast forward or fast replay.
Reference: [64] <author> T. Malone, K.R. Grant, F.A. Turbak, S.A. Brobst, and M.D. Cohen. </author> <title> Intelligent information sharing systems. </title> <journal> Communications of the ACM, </journal> <volume> 30(5) </volume> <pages> 390-402, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay [25], DistView [83], SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis [20, 21], Quilt [33], Prep [78, 79], Active Mail [41], Object Lens <ref> [55, 64] </ref>, etc.). Replayable workspaces provide an artifact that allows asynchronous sharing over the refinement and evolution of a shared workspace.
Reference: [65] <author> N.R. Manohar and A. Prakash. </author> <title> Replay by re-execution: a paradigm for asynchronous collaboration via record and replay of interactive multimedia streams. </title> <journal> ACM SIGOIS Bulletin, </journal> <volume> 15(2) </volume> <pages> 32-34, </pages> <month> December </month> <year> 1994. </year> <month> 156 </month>
Reference-contexts: In this chapter, we present a complimentary paradigm for asynchronous collaboration that allows users to record and replay an interactive session with an application. Among us, we may want to refer to this paradigm as a sort of WYSNIWIST (What You See Now Is What I Saw Then) <ref> [65] </ref>. The paradigm introduces an associated data artifact, the session object, used to capture the collaborative session. Figure 3.1 shows a high level view of the capture and replay of an interactive session with an application.
Reference: [66] <author> N.R. Manohar and A. Prakash. </author> <title> Dealing with synchronization and timing variability in the playback of interactive session recordings. </title> <booktitle> In Proc. of ACM Multimedia '95, </booktitle> <pages> pages 45-56, </pages> <address> San Francisco, CA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: The mechanisms found in this dissertation remove awareness of media types from media integration so as to handle heterogeneous media. Steinmetz [96] provided early illustrations of the need for the integration of heterogeneous media. Heterogeneity affects both scheduling and synchronization as shown in <ref> [66, 71, 85] </ref>. In this dissertation, I present mechanisms for the support of the playback of continuous (synchronous) and asynchronous (discrete) streams. 2.6 Scheduling and Synchronization Protocols The Tactus system [26, 90] supports the replay of integrated media. However, there are important differences. <p> The variances due to CPU availability, DMA access, thread overheads, disk access, reliability of timing services, etc., affected the scheduling of both window and audio streams. Our results in <ref> [66] </ref> showed that an adaptive protocol that attempts to compensate for varying load generally performs better across all load conditions. The issues are explore in detail in Chapter 4. Streams execute as cooperating thread tasks in a single CPU. The infrastructure provides two generic thread models. <p> There are two basic approaches. In the first approach, services of multiple tools are integrated into a monolithic-application | using carefully orchestrated, cooperating threads. Our previous prototype followed this approach <ref> [66, 67] </ref>. This approach delivers complete control over tool coordination and media integration problems since, at the thread level, fine-grained scheduling and synchronization control is possible. Unfortunately, this low-level control it also limits the flexibility of the resulting infrastructure (see Fig. 5.4). <p> Because we are dealing with re-executable content, scheduling needs to be adjusted to compensate for trends during playback on workstations of unequal performance. For example, such compensations are found on the compression and/or expansion of resources such as: (1) idle schedule time <ref> [52, 66] </ref>, (2) silence [31, 45], and (3) presentation frame rate [76]. Let w i be the adaptation effort over a schedule time interval T , thus resulting in the compression (or expansion) of T i into a playback real-time duration w i T . <p> The mechanism is somewhat more forgiving of short-term timing departures. Through the characterization of long-term synchronization relationships between the streams in a workspace, the use of long-term policies such as P3 as shown in <ref> [66] </ref> or P5 can reduce asynchrony and still preserve continuity. 112 CHAPTER 9 ON DEVELOPING REPLAYABLE APPLETS "Please pay no attention to the man behind the curtains..." | from The Wizard of Oz by Frank Baum. 9.1 Introduction The integration of an applet into a replayable workspace is referred to as <p> Because we are dealing with re-executable content, scheduling needs to be adjusted to compensate for trends during playback on workstations of unequal performance. For example, such compensations are found on the compression and/or expansion of resources such as: (1) idle schedule time <ref> [52, 66] </ref>, (2) silence [31, 45], and (3) presentation frame rate [76]. Let w i be the adaptation effort over a schedule time interval T , thus resulting in the compression (or expansion) of T i into a playback real-time duration w i T .
Reference: [67] <author> N.R. Manohar and A. Prakash. </author> <title> The Session Capture and Replay Paradigm for Asynchronous Collaboration. </title> <booktitle> In Proc. of European Conference on Computer Supported Cooperative Work (ECSCW)'95, </booktitle> <pages> pages 161-177, </pages> <address> Stockholm, Sweden, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: There are two basic approaches. In the first approach, services of multiple tools are integrated into a monolithic-application | using carefully orchestrated, cooperating threads. Our previous prototype followed this approach <ref> [66, 67] </ref>. This approach delivers complete control over tool coordination and media integration problems since, at the thread level, fine-grained scheduling and synchronization control is possible. Unfortunately, this low-level control it also limits the flexibility of the resulting infrastructure (see Fig. 5.4). <p> Others capture these tasks with either analog or digital video. Both approaches are often inadequate for collaborative work due to the potential loss of collaboration content. The approach taken in this dissertation addresses the above problem by supporting the asynchronous sharing of an application workspace <ref> [67] </ref>. This is accomplished by extending an application object with our notions of replay-awareness (i.e., the replayable application object class and its associated session object (s) as described in Chapters 3 and 5). <p> an existing applet into a replayable workspace should result in limited and well-contained changes to the applet's implementation. 57 * collaborative-awareness: That is, the architecture should support the collaborative features (such as record, replay, annotation, and editing of session objects) found in the paradigm described in Chapter 3 and in <ref> [67] </ref>. In this chapter, I analyze the architectural support needed to achieve such flexible and modular replayable workspaces. The rest of this chapter is organized as follows. First, I state the motivation and requirements for my research on replayable workspaces. <p> The workspace model imposes session and workspace semantics over the media model of multiple applets on a workspace. The workspace model views the workspace as composed of abstract streams. Streams on a session object are rooted as a file hierarchy of media directories <ref> [67] </ref>. The data of a stream controller is represented using standard Unix filesystem support (i.e., byte-stream files and directories). The session object is thus copied and transported as any other directory. The workspace model addresses the representation of a workspace.
Reference: [68] <author> N.R. Manohar and A. Prakash. </author> <title> Design issues on heterogeneous replayable workspaces. </title> <type> Technical Report Technical Report CSE-, </type> <institution> Department of Eletrical Engineering and Computer Science, University of Michigan, </institution> <year> 1996. </year>
Reference-contexts: In this chapter, we desire to formulate a playback media integration model that supports the heterogeneity introduced by re-executable content streams and it is yet flexible enough to incorporate new and unknown stream types to be found in future replayable workspaces. 8.3 Synchronization and Continuity From our results in <ref> [68] </ref>, both playback smoothness and continuity estimators depend on the synchronization costs q as follows. * playback smoothness of asynchronous streams; We propose to relate playback smoothness to how schedule time departs from elapsed real-time. For a smooth playback, we want such departures to be small and stable. <p> The schedule compensation adjustment is variable and revised, (upgraded or downgraded, as needed), on every scheduling interval. However, asynchrony floats, under statistical control, during the scheduling interval. 135 APPENDIX C SYNCHRONIZATION AND CONTINUITY From our results in <ref> [68] </ref>, both playback smoothness and continuity estimators depend on the synchronization costs q as follows. * playback smoothness of asynchronous streams; We propose to relate playback smoothness to how schedule time departs from elapsed real-time. For a smooth playback, we want such departures to be small and stable.
Reference: [69] <author> N.R. Manohar and A. Prakash. </author> <title> A flexible architecture for heterogeneous media integration on replayable workspaces. </title> <booktitle> In Proc. Third IEEE Int'l Conf on Multimedia Computing and Systems, to appear, </booktitle> <address> Hiroshima, Japan, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: As also reported in [7], the notions of tools, API transparency, platform/tool heterogeneity, and a shared data model are essential characteristics to described of middleware services. I examine these notions below (also described in <ref> [69] </ref>). 6.4 Overview of the Architecture A CSW is composed of multiple tools. A tool is incorporated into a replayable workspace by means of a user-level process, referred to as a stream controller. A stream controller extends temporal-awareness to a particular tool service and its associated temporal media stream. <p> The session manager interfaces to and manipulates these stream controllers through simple "VCR-like" commands. These polymorphic commands are both tool and media independent, (i.e., are the same regardless of the services provided by individual tools). Fig. 6.1 illustrates the architecture of our replayable workspace <ref> [69] </ref>. The stream controller abstraction has three components: * temporal controller the glue logic to our replayable workspaces. Delivers temporal-awareness to its CSW tool. * temporal media stream herein, applet stream.
Reference: [70] <author> N.R. Manohar and A. Prakash. </author> <title> Flexible tool coordination and media integration on heterogeneous replayable workspaces. </title> <type> Technical Report Technical Report CSE-, </type> <institution> Department of Eletrical Engineering and Computer Science, University of Michigan, </institution> <year> 1996. </year>
Reference-contexts: This is the subject of this chapter, i.e., Chapter 6 (see also <ref> [70] </ref>). * temporal modeling of heterogeneous streams: We desire mechanisms to characterize and enforce heterogeneous relationships between re-executable content streams and other streams such as continuous streams of applets on a workspace.
Reference: [71] <author> A. Mathur and A. Prakash. </author> <title> Protocols for integrated audio and shared windows in collaborative systems. </title> <booktitle> In Proc. of ACM Multimedia '94, </booktitle> <pages> pages 381-390, </pages> <address> San Francisco, CA, USA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: The mechanisms found in this dissertation remove awareness of media types from media integration so as to handle heterogeneous media. Steinmetz [96] provided early illustrations of the need for the integration of heterogeneous media. Heterogeneity affects both scheduling and synchronization as shown in <ref> [66, 71, 85] </ref>. In this dissertation, I present mechanisms for the support of the playback of continuous (synchronous) and asynchronous (discrete) streams. 2.6 Scheduling and Synchronization Protocols The Tactus system [26, 90] supports the replay of integrated media. However, there are important differences.
Reference: [72] <author> C.W. Mercer, S. Savage, and H. Tokuda. </author> <title> Processor Capacity Reserves for Multimedia Operating Systems. </title> <booktitle> In Proceedings of the IEEE ICMCS, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: Research on management of fetch overheads [87, 89] and scheduling overheads [47, 75] focuses on (low-level) multimedia operating system enhancements for the support of continuous media. Kernel-level management of inter-dependent overheads between competing processes is approached by Mercer in <ref> [72] </ref>.
Reference: [73] <author> J. Misra. </author> <title> Distributed discrete-event simulation. </title> <journal> Computing Surveys, </journal> <volume> 18(1) </volume> <pages> 39-65, </pages> <year> 1986. </year>
Reference-contexts: Ill choices of q affect scheduling fairness and must accounted for in the mechanisms for playback continuity and smoothness. Many systems enforce full temporal order of asynchronous events with tight synchronization but without continuity guarantees. Examples of these include schedulers used in distributed event simulations <ref> [5, 48, 73] </ref> and causality preserving protocols such as Birman's ISIS [8, 9]. Our research problem can be formulated as enforcing playback continuity over an asynchronous event simulation. Several systems enforce full temporal order of asynchronous events with synchronization and continuity but over coarse event grain.
Reference: [74] <author> W.A. Montgomery. </author> <title> Techniques for packet voice synchronization. </title> <journal> IEEE Journal on Selected Areas In Communication, </journal> <volume> SAC-1(6):1022-1027, </volume> <month> December </month> <year> 1983. </year>
Reference-contexts: Second, the playback of integrated media is not supported. The playback of stored media requires addressing three basic overheads: (1) fetch, (2) scheduling, and (3) presentation. Unlike with network-based media streaming, in workstation-based streaming, playback overheads (1,2,3) are additive and inter-dependent. Research in network-based streaming, such as <ref> [31, 45, 74, 90, 103] </ref>, relies on adaptive scheduling protocols to manage (bounded) network variability. Their focus is on management of overheads up to the delivery of data to the presentation workstation. These approaches assume processing and presentation on the client workstation incur negligible overheads. <p> The resource is used as a degree of freedom to compensate for trends in inter-stream asynchrony. For the window stream, the selected resource was the inter-event delay times, for the audio stream a good choice is the duration of silence segments (as in <ref> [31, 74] </ref>), and for the video stream, our choice is the playback frame rate, as suggested in [76]. video stream. In this figure, a maximum video frame rate v max of 16f ps is assumed.
Reference: [75] <author> J. Nakajima, M. Yazaki, and H. Matsumoto. </author> <title> Multimedia/realtime extensions for the Mach operating system. </title> <booktitle> In Proc. of the Summer USENIX Conference, </booktitle> <pages> pages 183-196, </pages> <address> Nashville, TN, USA, </address> <month> Summer </month> <year> 1991. </year>
Reference-contexts: This dissertation contains mechanisms that address such timing variability at the client workstation. As a result, our workstation-based mechanisms could be coupled on top of existing network-based mechanisms. Research on management of fetch overheads [87, 89] and scheduling overheads <ref> [47, 75] </ref> focuses on (low-level) multimedia operating system enhancements for the support of continuous media. Kernel-level management of inter-dependent overheads between competing processes is approached by Mercer in [72]. <p> Such a-priori knowledge about the predictability and periodicity of event playback is an inherent assumption built-in on scheduling mechanisms for the playback of continuous media (both Schulzrinne [93] and Steinmetz [97] made similar observations). For example, this is particularly true for deadline-based of continuous media <ref> [47, 44, 75] </ref>. On the other hand, a re-executable content stream lacks periodicity. In this dissertation, I provide a playback characterization of re-executable content streams based on the relative inter-arrival distributions of sequences of discrete events on a re-executable content stream.
Reference: [76] <author> T. Nakajima and H. Tezuka. </author> <title> A Continuous Media Application supporting Dynamic QoS Control on Real Time Mach. </title> <booktitle> In Proc. of ACM Multimedia '94, </booktitle> <pages> pages 289-297, </pages> <address> San Francisco, CA, USA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: For example, such compensations are found on the compression and/or expansion of resources such as: (1) idle schedule time [52, 66], (2) silence [31, 45], and (3) presentation frame rate <ref> [76] </ref>. Let w i be the adaptation effort over a schedule time interval T , thus resulting in the compression (or expansion) of T i into a playback real-time duration w i T . At the end of T , synchronization is performed with associated costs q (a). <p> For the window stream, the selected resource was the inter-event delay times, for the audio stream a good choice is the duration of silence segments (as in [31, 74]), and for the video stream, our choice is the playback frame rate, as suggested in <ref> [76] </ref>. video stream. In this figure, a maximum video frame rate v max of 16f ps is assumed. Figure 9.10 (a) shows the current frame rate v f = 2 3 v max . One-third of all video frames in this interval are dropped. <p> For example, such compensations are found on the compression and/or expansion of resources such as: (1) idle schedule time [52, 66], (2) silence [31, 45], and (3) presentation frame rate <ref> [76] </ref>. Let w i be the adaptation effort over a schedule time interval T , thus resulting in the compression (or expansion) of T i into a playback real-time duration w i T . At the end of T , synchronization is performed with associated costs q (a).
Reference: [77] <author> A.D. Narasimhalu. </author> <title> Multimedia databases. </title> <journal> Multimedia Systems, </journal> <volume> 4(5) </volume> <pages> 226-249, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: The support of advanced collaborative features for asynchronous use of session objects introduces an interesting problem in their representation that naturally benefits from research on multimedia databases. Narasimhalu survey of research issues on multimedia databases <ref> [77] </ref>, presented the following considerations for research on the representation problem: data model, dimensions, real-time data, representation of complex objects, and transcoded objects. In this dissertation, I presented a data model for session objects that supports the heterogeneous multimedia dimensions through media-independent modeling of the underlying temporal media streams.
Reference: [78] <editor> C.M. Neuwirth, D.S. Kaufer, R. Chandhok, and J.H. Morris. </editor> <booktitle> Issues in the design of computer support for co-authoring and commenting. In Proc. of the Third Conference on Computer-Supported Cooperative Work, </booktitle> <pages> pages 183-195, </pages> <address> Los Angeles, CA, USA, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: Our replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay [25], DistView [83], SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis [20, 21], Quilt [33], Prep <ref> [78, 79] </ref>, Active Mail [41], Object Lens [55, 64], etc.). Replayable workspaces provide an artifact that allows asynchronous sharing over the refinement and evolution of a shared workspace.
Reference: [79] <author> C.M. Neuwirth, D.S. Kaufer, J. Morris, and R. Chandhok. </author> <title> Flexible diff-ing in a collaborative writing system. </title> <booktitle> In Proc. of the Fourth Conference on Computer-Supported Cooperative Work, </booktitle> <pages> pages 147-154, </pages> <address> Toronto, Canada, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: However, the notion has been absent from asynchronous computer-supported collaborative work. Several systems for the support of asynchronous collaboration provide ways to model the interactions among users and the evolution of collaboration repositories <ref> [41, 55, 79] </ref>. Our work represents a complimentary paradigm for asynchronous collaboration that allows users to record and replay a session. <p> Our replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay [25], DistView [83], SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis [20, 21], Quilt [33], Prep <ref> [78, 79] </ref>, Active Mail [41], Object Lens [55, 64], etc.). Replayable workspaces provide an artifact that allows asynchronous sharing over the refinement and evolution of a shared workspace. <p> 23 CHAPTER 3 THE PARADIGM OF SESSION RECORD AND REPLAY FOR ASYNCHRONOUS COLLABORATION "... and all our knowledge is ourselves to keep." | Alexander Pope. 1688-1744. 3.1 Introduction Several systems for the support of asynchronous collaboration provide ways to model the interactions among users and the evolution of collaboration repositories <ref> [41, 55, 79] </ref>. In this chapter, we present a complimentary paradigm for asynchronous collaboration that allows users to record and replay an interactive session with an application.
Reference: [80] <author> S.R. Newcomb, N.A. Kipp, </author> <title> and V.T. Newcomb. The Hytime hypermedia/time-based document structuring language. </title> <journal> Communications of the ACM, </journal> <volume> 34(11) </volume> <pages> 67-83, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: The use of textual descriptions or abstracts of a session have the inherent problem that there is no intrinsic relationship between the description and the content of the session. To address these difficulties, a markup language for time-dependent data, such as HyTime <ref> [80] </ref>, can be used. The use of a markup language allows standardized keyword and content querying of a stream contents. For some streams, in particular the window stream, its contents may be easier to retrieve and classify, than for other streams such as the audio stream.
Reference: [81] <author> B. Ozden, R. Rastogi, and A. Silverschatz. </author> <title> A framework for the storage and retrieval of continuous media data. </title> <booktitle> In Proc. of the IEEE Int'l Conference on Multimedia Computing and Systems, </booktitle> <pages> pages 580-589?, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Other important differences limit the suitability of continuous media servers to our requirements. First, there are differences in architectural constraints (for example, see Fig. 2.6) and focus. Research on multimedia extensions for operating systems (see surveys [13, 97, 93]) and for file systems <ref> [51, 81, 87, 89, 101] </ref> address the support of stored continuous multimedia (e.g., predictive prefetching, batched processing, disk layout, optimal buffering, frame interleaving, etc.). On the 17 other hand, this dissertation focuses on best-effort playback on general-purpose platforms. <p> Last, the aforementioned stored media servers do not currently address the integration of heterogeneous media. Media servers often rely on an implicit coupling of media and synchronization that assumes the playback of continuous media only <ref> [81] </ref> or that heterogeneous media has negligible requirements [93]. The mechanisms found in this dissertation remove awareness of media types from media integration so as to handle heterogeneous media. Steinmetz [96] provided early illustrations of the need for the integration of heterogeneous media. <p> Here the answer is interesting, media access operations need to be scheduled too (i.e., prefetching and buffered writes). Although research on batched access for real-time playback of continuous media is found in <ref> [87, 81] </ref>, the batching of heterogeneous streams, it is usually discarded as non-bandwidth critical. However, some re-executable content streams are bandwidth critical (for example, consider an incoming display stream from a remote instrument). Clearly, media access needs to be configurable to stream requirements 9.3.
Reference: [82] <author> D.L. Parnas and D.P. Siewiorek. </author> <title> Use of the concept of transparency in the design of hierarchically structured systems. </title> <journal> Communications of the ACM, </journal> <volume> 18(7) </volume> <pages> 401-408, </pages> <month> 7 </month> <year> 1975. </year> <month> 157 </month>
Reference-contexts: If the underlying workspace is to be shared, it is necessary to have access to the application's computation. In my approach, this access is found in the interfaces to the applet's abstract base machine. The notion of abstract base machines used here corresponds to Parnas <ref> [82] </ref>. However, this approach has other limitations. First, capturing the state of Window Server can be difficult. Second, replay is limited to only those events that go through Window Server. <p> To support later-time orchestration of a workspace, application objects need to provide access to their abstract base machines (as in Parnas <ref> [82] </ref>). In particular, two types of intra-application interfaces are required: (1) state capture, (2) event capture. To orchestrate application objects on a workspace, the workspace object needs to interface to them. <p> Typically, applets have a single-purpose, well-defined, abstract base machine. Abstract Base Machine The notion of an abstract base machine was defined by Parnas <ref> [82] </ref>. Let abm (A i ) be the abstract base machine of applet A i , where abm (A i ) is composed of abstract operations (f 1 (); f 2 (); ; f n ()). Tool Services Tool provide integrated services that spanned the workspace.
Reference: [83] <author> A. Prakash and H.S. Shim. Distview: </author> <title> Support for building efficient collaborative applications using replicated objects. </title> <booktitle> In Proceedings of the 1994 ACM Conference on Computer Supported Cooperative Work (CSCW'94), </booktitle> <pages> pages 153-164, </pages> <address> Chapel Hill, N.C., </address> <month> October </month> <year> 1994. </year>
Reference-contexts: The notion of session and workspaces is central to synchronous computer-supported collaborative work [92]. However, the notion has been absent so far from asynchronous computer-supported collaborative work. Our replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay [25], DistView <ref> [83] </ref>, SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel [95], gIbis [20, 21], Quilt [33], Prep [78, 79], Active Mail [41], Object Lens [55, 64], etc.).
Reference: [84] <author> R. Rajkumar. </author> <booktitle> Real-Time Synchronization in Uniprocessors, </booktitle> <pages> pages 15-58. </pages> <publisher> Kluwer Academic Publishing, </publisher> <year> 1991. </year>
Reference-contexts: This characterization provides a foundation for the integration of heterogeneous media streams. A sporadic server [46] can be coupled with a deadline-based real-time scheduler <ref> [84] </ref> so as to handle the integration of asynchronous and continuous media by deadline-based schedulers [44, 97]. The sporadic server is used to handle all asynchronous events with unpredictable playout time. The sporadic server is given a CPU time allotment fraction q% to process asynchronous events.
Reference: [85] <author> S. Ramanathan and P. Venkat Rangan. </author> <title> Continuous media synchronization in distributed multimedia systems. </title> <booktitle> In Proc. of the 3rd Int'l Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <pages> pages 328-335, </pages> <address> La Jolla, CA, USA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: The mechanisms found in this dissertation remove awareness of media types from media integration so as to handle heterogeneous media. Steinmetz [96] provided early illustrations of the need for the integration of heterogeneous media. Heterogeneity affects both scheduling and synchronization as shown in <ref> [66, 71, 85] </ref>. In this dissertation, I present mechanisms for the support of the playback of continuous (synchronous) and asynchronous (discrete) streams. 2.6 Scheduling and Synchronization Protocols The Tactus system [26, 90] supports the replay of integrated media. However, there are important differences. <p> However, SQC has been applied mostly to manufacturing lines | lines are sort of streams. My research introduces the use of statistical quality controls for achieving long-term controls over asynchrony and continuity on the playback of multimedia streams. The adaptive feedback mechanism proposed by Venkat-Rangan in <ref> [85] </ref> can be considered as compensating long 22 term playback asynchrony trends due to clock drift between record and playback workstations during the playback of stored media. The mechanism is complementary to our work. <p> For brevity, we focus only on browsing features. Temporal access controls (TAC) allow the modeling of "VCR-like" (browsing) features as temporal transformations over a logical time system (LTS), as for example found in <ref> [2, 62, 85, 89] </ref>. Building on that model, I then show that the browsing support of the architecture are independent of both tool and media characteristics.
Reference: [86] <author> S. Ramanathan and Venkat P. Rangan. </author> <title> Adaptive feedback techniques for synchronized multimedia retrieval over integrated networks. </title> <journal> ieanep, </journal> <volume> 1(2) </volume> <pages> 246-260, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: To preserve temporal correspondence on the playback of asynchronous media, we need to rely on relative scheduling. Relative scheduling of stored media was also approached in <ref> [86] </ref>. To avoid frequent synchronization overheads, I rely on enforcement of temporal intervals through point synchronization. Synchronization points are discussed by Gibbs on [39, 40]. To enforce relationships between multiple streams, I use a modified master-slave model coupled with synchronization handshake.
Reference: [87] <author> P. Venkat Rangan and Harrick M. Vin. </author> <title> Designing file systems for digital audio and video. </title> <booktitle> In Proceedings of 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 81-94. </pages> <institution> Association for Computing Machinery SIGOPS, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: Other important differences limit the suitability of continuous media servers to our requirements. First, there are differences in architectural constraints (for example, see Fig. 2.6) and focus. Research on multimedia extensions for operating systems (see surveys [13, 97, 93]) and for file systems <ref> [51, 81, 87, 89, 101] </ref> address the support of stored continuous multimedia (e.g., predictive prefetching, batched processing, disk layout, optimal buffering, frame interleaving, etc.). On the 17 other hand, this dissertation focuses on best-effort playback on general-purpose platforms. <p> This dissertation contains mechanisms that address such timing variability at the client workstation. As a result, our workstation-based mechanisms could be coupled on top of existing network-based mechanisms. Research on management of fetch overheads <ref> [87, 89] </ref> and scheduling overheads [47, 75] focuses on (low-level) multimedia operating system enhancements for the support of continuous media. Kernel-level management of inter-dependent overheads between competing processes is approached by Mercer in [72]. <p> Here the answer is interesting, media access operations need to be scheduled too (i.e., prefetching and buffered writes). Although research on batched access for real-time playback of continuous media is found in <ref> [87, 81] </ref>, the batching of heterogeneous streams, it is usually discarded as non-bandwidth critical. However, some re-executable content streams are bandwidth critical (for example, consider an incoming display stream from a remote instrument). Clearly, media access needs to be configurable to stream requirements 9.3.
Reference: [88] <author> M. Roseman and S. Greenberg. GroupKit: </author> <title> A groupware toolkit for building real-time conferencing applications. </title> <booktitle> In Proc. of the Fourth Conference on Computer-Supported Cooperative Work, </booktitle> <pages> pages 43-50, </pages> <address> Toronto, Canada, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: There are several approaches to the initial state capture problem. One approach is to assume that capture of application state is application-dependent and an application responsibility as for example, in GroupKit <ref> [88] </ref>. Another approach is to capture all inputs from the very start of the application launch. This way, the need for initial state capture is removed. The capture of state is related to the late join problem.
Reference: [89] <author> L.A. Rowe and B.C. Smith. </author> <title> A Continuous Media Player. </title> <booktitle> In "Proc. of the 3rd Int'l Workshop on Network and Operating System Support for Digital Audio and Video", </booktitle> <pages> pages 376-386, </pages> <address> La Jolla, CA, USA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Other important differences limit the suitability of continuous media servers to our requirements. First, there are differences in architectural constraints (for example, see Fig. 2.6) and focus. Research on multimedia extensions for operating systems (see surveys [13, 97, 93]) and for file systems <ref> [51, 81, 87, 89, 101] </ref> address the support of stored continuous multimedia (e.g., predictive prefetching, batched processing, disk layout, optimal buffering, frame interleaving, etc.). On the 17 other hand, this dissertation focuses on best-effort playback on general-purpose platforms. <p> On the 17 other hand, this dissertation focuses on best-effort playback on general-purpose platforms. Second, research such as <ref> [89, 90] </ref> focuses on network-centric access model to stored media, designed for the support of a multiple streams, multiple site model. On the other hand, in our domain, a workstation-centric access model is preferable, designed for the support of a multiple stream, single site model. <p> This dissertation contains mechanisms that address such timing variability at the client workstation. As a result, our workstation-based mechanisms could be coupled on top of existing network-based mechanisms. Research on management of fetch overheads <ref> [87, 89] </ref> and scheduling overheads [47, 75] focuses on (low-level) multimedia operating system enhancements for the support of continuous media. Kernel-level management of inter-dependent overheads between competing processes is approached by Mercer in [72]. <p> There are systems for the enforcement of full temporal order of fine-grained synchronous or periodical tasks with tight synchronization and strong playback continuity. Some examples are schedulers used for continuous media in general purpose systems <ref> [30, 57, 61, 63, 89] </ref> and on real-time systems [34, 44, 46, 99]. However, these scheduling algorithms benefit (on one degree or another) from properties of continuous media not found in applet streams. <p> These events are typically found inside a single media part (such as a program). Both approaches are needed and complementary. The streaming of re-executable content is also found, most evidently, in the TclCommand stream [42] extension to the CM/T system <ref> [89] </ref>. Because the CM/T is centered around continuous streams, it lacks the mechanisms for smoothing timing departures during the playback of asynchronous events. Unaccounted timing departures cause synchronization to introduce playback discontinuities to other continuous streams. <p> The schedule compensation adjustment is variable and revised, (upgraded or downgraded, as needed), on every scheduling interval. However, asynchrony floats, under statistical control, during the scheduling interval. Our time deformations are different from temporal transformations, (as in <ref> [2, 39, 63, 89] </ref>). Temporal transformations scale the rate of execution of a global scheduler so as to support features such as fast forward or fast replay. <p> For brevity, we focus only on browsing features. Temporal access controls (TAC) allow the modeling of "VCR-like" (browsing) features as temporal transformations over a logical time system (LTS), as for example found in <ref> [2, 62, 85, 89] </ref>. Building on that model, I then show that the browsing support of the architecture are independent of both tool and media characteristics. <p> The consumer thread gets events from the shared queue and dispatches them to the window system for replay. Optimizing Sampling and Prefetching I/O access of audio frames, buffered sampling and prefetching of multiple frames is used (i.e., block-based writing and prefetching, as also found in CMSS <ref> [89] </ref>). 120 execute asynchronously on the audio device. I baselined three important parameters that affect overheads f o (A1) during the record and replay of audio frames at the application layer: (1) the audio frame size, (2) the buffering effort for writes, and (3) the buffering effort for prefetches.
Reference: [90] <author> D. Rubine, R.B. Dannenberg, and D.B. Anderson. </author> <title> Low-latency interaction through choice-points, buffering and cuts in Tactus. </title> <booktitle> In Proc. of the Int'l Conference on Multimedia Computing and Systems, </booktitle> <pages> pages 224-233, </pages> <address> Los Alamitos, CA, USA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: On the 17 other hand, this dissertation focuses on best-effort playback on general-purpose platforms. Second, research such as <ref> [89, 90] </ref> focuses on network-centric access model to stored media, designed for the support of a multiple streams, multiple site model. On the other hand, in our domain, a workstation-centric access model is preferable, designed for the support of a multiple stream, single site model. <p> Heterogeneity affects both scheduling and synchronization as shown in [66, 71, 85]. In this dissertation, I present mechanisms for the support of the playback of continuous (synchronous) and asynchronous (discrete) streams. 2.6 Scheduling and Synchronization Protocols The Tactus system <ref> [26, 90] </ref> supports the replay of integrated media. However, there are important differences. First, the Tactus system has no notion of relative time. Scheduling of asynchronous media is performed wrt progress of logical time. <p> Second, the playback of integrated media is not supported. The playback of stored media requires addressing three basic overheads: (1) fetch, (2) scheduling, and (3) presentation. Unlike with network-based media streaming, in workstation-based streaming, playback overheads (1,2,3) are additive and inter-dependent. Research in network-based streaming, such as <ref> [31, 45, 74, 90, 103] </ref>, relies on adaptive scheduling protocols to manage (bounded) network variability. Their focus is on management of overheads up to the delivery of data to the presentation workstation. These approaches assume processing and presentation on the client workstation incur negligible overheads. <p> However, unlike these master/slave models, our approach differs in the following ways. First, synchronization is relative to the progress of the master stream (as opposed to the progress of logical time, as in the Tactus system <ref> [90] </ref>). In our prototype, the audio stream is used as the master 36 stream and the window stream is its synchronizing slave | the window stream schedule is adjusted to preserve synchronization wrt audio stream's schedule.
Reference: [91] <author> D.C. Schmidt, M. Fayad, and R.E. Johnson. </author> <title> Software patterns: Guest editor notes. </title> <journal> Communications of the ACM, </journal> <volume> 39(10) </volume> <pages> 36-39, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: researching mechanisms that address causal relationships between streams and the enforcement of n-ary relationships between richly heterogeneous streams be supported. 1.4.4 The Notion of Applications as Replayable Should applications be inherently replayable? We need investigate whether the notion of the application as a replayable object represents a new object pattern <ref> [91] </ref> that is yet to be found in other domains. An efficient way to deliver this replayable object pattern to an application is needed. One possible solution centers around object orientation. An object-oriented replayable class and its compliance protocols should allow an application to become replay-aware.
Reference: [92] <author> E.M. Schooler. </author> <title> Conferencing and collaborative computing. </title> <journal> Multimedia Systems, </journal> <volume> 4(5) </volume> <pages> 210-225, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Asynchronous collaboration represents a less imposing form of collaboration over the schedule of geographically distributed participants. The notion of session and workspaces is central to synchronous computer-supported collaborative work <ref> [92] </ref>. However, the notion has been absent so far from asynchronous computer-supported collaborative work.
Reference: [93] <author> H. Schulzrinne. </author> <title> Operating system issues for continuous media. </title> <journal> Multimedia Systems, </journal> <volume> 4(5) </volume> <pages> 269-280, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Other important differences limit the suitability of continuous media servers to our requirements. First, there are differences in architectural constraints (for example, see Fig. 2.6) and focus. Research on multimedia extensions for operating systems (see surveys <ref> [13, 97, 93] </ref>) and for file systems [51, 81, 87, 89, 101] address the support of stored continuous multimedia (e.g., predictive prefetching, batched processing, disk layout, optimal buffering, frame interleaving, etc.). On the 17 other hand, this dissertation focuses on best-effort playback on general-purpose platforms. <p> Last, the aforementioned stored media servers do not currently address the integration of heterogeneous media. Media servers often rely on an implicit coupling of media and synchronization that assumes the playback of continuous media only [81] or that heterogeneous media has negligible requirements <ref> [93] </ref>. The mechanisms found in this dissertation remove awareness of media types from media integration so as to handle heterogeneous media. Steinmetz [96] provided early illustrations of the need for the integration of heterogeneous media. Heterogeneity affects both scheduling and synchronization as shown in [66, 71, 85]. <p> Such a-priori knowledge about the predictability and periodicity of event playback is an inherent assumption built-in on scheduling mechanisms for the playback of continuous media (both Schulzrinne <ref> [93] </ref> and Steinmetz [97] made similar observations). For example, this is particularly true for deadline-based of continuous media [47, 44, 75]. On the other hand, a re-executable content stream lacks periodicity.
Reference: [94] <institution> National Research Council (Computer Science, Telecommunications Board Commission on Physical Sciences Mathematics, and Applications). National Collaboratories: Applying Information Technology for Scientific Research. National Academy Press, </institution> <year> 1993. </year>
Reference-contexts: A step in this direction has been the development of the concept of the national collaboratory <ref> [94] </ref>; described as: "...a center without walls in which the nation's researchers can perform research without regard to geographical location interacting with colleagues, accessing instrumentation, sharing data and computational resources, and accessing information from digital li braries." The collaboratory infrastructure is envisioned, therefore, to support distributed interaction between people, access to
Reference: [95] <author> A. Sheperd, N. Mayer, and A. Kuchinsky. Strudel: </author> <title> An extensible electronic conversation toolkit. </title> <booktitle> In Proc. of the Second Conference on Computer-Supported Cooperative Work, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: Our replayable workspace paradigm couples the notions of a shared workspace (found in synchronous groupware, e.g., XTV [1, 17] TkReplay [25], DistView [83], SharedX [38], XMX/XTRAP [49], etc.) and artifact-based collaboration (found in asynchronous groupware, e.g., Conversation Builder [50], Strudel <ref> [95] </ref>, gIbis [20, 21], Quilt [33], Prep [78, 79], Active Mail [41], Object Lens [55, 64], etc.). Replayable workspaces provide an artifact that allows asynchronous sharing over the refinement and evolution of a shared workspace.
Reference: [96] <author> R. Steinmetz. </author> <title> Synchronization properties in multimedia systems. </title> <journal> IEEE Journal of Selected Areas of Communication, </journal> <volume> 8(3) </volume> <pages> 401-411, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: The mechanisms found in this dissertation remove awareness of media types from media integration so as to handle heterogeneous media. Steinmetz <ref> [96] </ref> provided early illustrations of the need for the integration of heterogeneous media. Heterogeneity affects both scheduling and synchronization as shown in [66, 71, 85]. <p> To avoid frequent synchronization overheads, I rely on enforcement of temporal intervals through point synchronization. Synchronization points are discussed by Gibbs on [39, 40]. To enforce relationships between multiple streams, I use a modified master-slave model coupled with synchronization handshake. Differing from classical master-slave synchronization (see <ref> [40, 96] </ref>), I relied on a slave-initiated synchronization handshake. This policy-independent synchronization handshake results in a "publish-and-subscribe" model to point synchronization that facilitates relative synchronization across multiple streams. To specify relationships between multiple streams, I use n-ary relationships. These are enforced as multiple binary, point-based, relationships. <p> Synchronization is based on the use of synchronization events, widely accepted in the synchronization literature <ref> [96] </ref>. A synchronization event, s i (lhs rhs), preserves relative 35 Plots show the end-to-end duration t (a i ) of audio frames during record and replay of a 250sec test session. <p> Our synchronization model is based on the notion of a master and multiple slave streams, (as in <ref> [13, 39, 96] </ref>). However, unlike these master/slave models, our approach differs in the following ways. First, synchronization is relative to the progress of the master stream (as opposed to the progress of logical time, as in the Tactus system [90]). <p> Variability normally present on the master stream is reduced during replay since the master stream no longer initiates inter-stream synchronization protocols. Overall, we found this scheme to yield better audio continuity than a master-initiated synchronization scheme. 4.3.5 Synchronization Policies In <ref> [96] </ref>, synchronizing operations were characterized by: * the involved partner (s): that is, to which stream to synchronize.
Reference: [97] <author> R. Steinmetz. </author> <title> Analyzing the multimedia operating system. </title> <journal> IEEE MultiMedia, </journal> <volume> 2(1) </volume> <pages> 68-84, </pages> <month> Spring </month> <year> 1995. </year>
Reference-contexts: Other important differences limit the suitability of continuous media servers to our requirements. First, there are differences in architectural constraints (for example, see Fig. 2.6) and focus. Research on multimedia extensions for operating systems (see surveys <ref> [13, 97, 93] </ref>) and for file systems [51, 81, 87, 89, 101] address the support of stored continuous multimedia (e.g., predictive prefetching, batched processing, disk layout, optimal buffering, frame interleaving, etc.). On the 17 other hand, this dissertation focuses on best-effort playback on general-purpose platforms. <p> Such a-priori knowledge about the predictability and periodicity of event playback is an inherent assumption built-in on scheduling mechanisms for the playback of continuous media (both Schulzrinne [93] and Steinmetz <ref> [97] </ref> made similar observations). For example, this is particularly true for deadline-based of continuous media [47, 44, 75]. On the other hand, a re-executable content stream lacks periodicity. <p> This characterization provides a foundation for the integration of heterogeneous media streams. A sporadic server [46] can be coupled with a deadline-based real-time scheduler [84] so as to handle the integration of asynchronous and continuous media by deadline-based schedulers <ref> [44, 97] </ref>. The sporadic server is used to handle all asynchronous events with unpredictable playout time. The sporadic server is given a CPU time allotment fraction q% to process asynchronous events. However, when we consider the streaming of re-executable content, two problems arise with this approach.
Reference: [98] <author> R. Steinmetz and K. Nahrstedt. </author> <title> Chapter 15: </title> <booktitle> Synchronization, </booktitle> <pages> pages 585-595. </pages> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference-contexts: As a result, occasional lack of close synchronization is not disruptive whereas audio playback continuity is essential. Furthermore, a coarse grain synchronization (approximately close to that of audio annotated slide shows <ref> [98] </ref>) appeared satisfactory. * Availability on heterogeneous platforms is important because of the pervasiveness in hospital environments. In Chapters 6 and 7, I examine some issues on the support of the first two concerns. In Chapter 8, I describe mechanisms for achieving flexible tradeoffs on media integration.
Reference: [99] <author> D.L. Stone and K. Jeffay. </author> <title> An empirical study of delay jitter management policies. </title> <journal> ACM Multimedia Systems, </journal> <volume> 2(6) </volume> <pages> 267-279, </pages> <month> January </month> <year> 1995. </year> <month> 158 </month>
Reference-contexts: There are systems for the enforcement of full temporal order of fine-grained synchronous or periodical tasks with tight synchronization and strong playback continuity. Some examples are schedulers used for continuous media in general purpose systems [30, 57, 61, 63, 89] and on real-time systems <ref> [34, 44, 46, 99] </ref>. However, these scheduling algorithms benefit (on one degree or another) from properties of continuous media not found in applet streams.
Reference: [100] <author> N.A. Streitz, J. Geiler, J.M. Haake, and J. </author> <title> Hol. DOLPHIN: Integrated meeting support across liveboards, local and remote desktop environments. </title> <booktitle> In Proceedings of the 1994 ACM Conference on Computer Supported Cooperative Work (CSCW'94), </booktitle> <pages> pages 345-358., </pages> <address> Chapel Hill, N.C., </address> <month> October </month> <year> 1994. </year>
Reference-contexts: Inter-task content, on the other hand, refers to the decisions themselves. Annotating and editing provide a fundamental mechanism of collaboration between asynchronous collaborators: versioning of a shared artifact through iterative exchange and refinement. Delayed-time collaborative groupware systems (e.g., Siemens's [43], GMD's Dolphin <ref> [100] </ref>, Lotus's Notes, etc.) allow users to work asynchronously via annotations added to a shared object (a document composed of rich media parts). My approach builds on those ideas but, in our case, the annotations are over an active content artifact, a recording of interactions with a workspace.
Reference: [101] <author> B.I. Szabo and G.K. Wallace. </author> <title> Design considerations for JPEG video and synchronized audion in a Unix workstation environment. </title> <booktitle> In Proc. of the Summer USENIX Conference, </booktitle> <pages> pages 353-367, </pages> <address> Nashville, TN, USA, </address> <month> Summer </month> <year> 1991. </year>
Reference-contexts: Other important differences limit the suitability of continuous media servers to our requirements. First, there are differences in architectural constraints (for example, see Fig. 2.6) and focus. Research on multimedia extensions for operating systems (see surveys [13, 97, 93]) and for file systems <ref> [51, 81, 87, 89, 101] </ref> address the support of stored continuous multimedia (e.g., predictive prefetching, batched processing, disk layout, optimal buffering, frame interleaving, etc.). On the 17 other hand, this dissertation focuses on best-effort playback on general-purpose platforms.
Reference: [102] <author> D.L. Tennenhouse, J.M. Smith, W.D. Sincoskie, D.J. Wetherall, and G.J. Minden. </author> <title> A survey of active network research. </title> <journal> IEEE Communications Magazine, </journal> <volume> 35(1) </volume> <pages> 80-86, </pages> <month> January </month> <year> 1997. </year>
Reference-contexts: The streaming of re-executable content is also found in next generation internet downloadable content technologies such as with the program capsules of Tennenhouse's proposed active networks <ref> [102] </ref> on in Kleinrock's notions of nomadicity [53]. In general, the streaming of re-executable content arises whenever a remote repository is used to store state and input behavior of one or more distributed computer appliances, for example in internet computers, in the next generation wireless (mobile/nomadic) computing appliances. <p> The streaming of re-executable content is also found in next generation internet downloadable content technologies such as with the program capsules of Tennenhouse's proposed active networks <ref> [102] </ref>. In general, the streaming of re-executable content arises whenever a remote repository is used to store state and input behavior of one or more distributed digital appliances, for example in internet computers and next generation wireless personal computing devices.
Reference: [103] <author> H.M. Vin, P.T. Zellweger, D.C. Swinehart, and P. Venkat Rangan. </author> <title> Multimedia conferencing in the etherphone environment. </title> <journal> Computer, </journal> <volume> 24(10) </volume> <pages> 69-8, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Second, the playback of integrated media is not supported. The playback of stored media requires addressing three basic overheads: (1) fetch, (2) scheduling, and (3) presentation. Unlike with network-based media streaming, in workstation-based streaming, playback overheads (1,2,3) are additive and inter-dependent. Research in network-based streaming, such as <ref> [31, 45, 74, 90, 103] </ref>, relies on adaptive scheduling protocols to manage (bounded) network variability. Their focus is on management of overheads up to the delivery of data to the presentation workstation. These approaches assume processing and presentation on the client workstation incur negligible overheads.
Reference: [104] <author> Marc Weiser. </author> <title> Some computer science issues in ubiquitous computing. </title> <journal> CACM, </journal> <volume> 36(7) </volume> <pages> 74-84, </pages> <year> 1993. </year>
Reference-contexts: The playback of re-executable content streams, together with continuous streams, arises during the streaming of inputs to multiple applets in a workspace. This problem is also of strong interest to next generation multimedia frameworks as found for ubiquitous computing <ref> [104] </ref>, nomadic computing [53], and wireless ATMs [36], with the introduction of time-dependent streaming of re-executable content. The media integration and streaming mechanisms on these frameworks face media heterogeneity. Streaming and integration require us to characterize stream requirements.
References-found: 105

