URL: http://www.cs.msu.edu/~stockman/Papers/3D.freeform.object.representation.ps.Z
Refering-URL: http://www.cs.msu.edu/~stockman/pubs.html
Root-URL: http://www.cs.msu.edu
Title: Object Representation for Recognition-by-Alignment  
Author: George C. Stockman 
Address: East Lansing, MI 48824  
Affiliation: Department of Computer Science Michigan State University  
Abstract: We present an approach general enough to apply to recognition of complex rigid 3D objects from either a single intensity image or a single range image. Within the general paradigm of recognition by alignment, we address (1) definition and detection of primitives, (2) indexing to model hypotheses, (3) constructing view sphere models from sensed data, and (4) aligning model and sensed features for verification. The overall paradigm is not new, but rather fits within theory already espoused by Lowe and Ullman and many others: our position is therefore both a synthesis of and endorsement of much other work toward recognition of rigid free-form objects. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> R. Bajcsy and F. Solina, </editor> <title> Three-Dimensional Object representation Revisited, </title> <booktitle> Proceedings 1st Int. Conf. on Computer Vision, </booktitle> <address> pp.231-240, </address> <year> 1987. </year>
Reference-contexts: Another promising approach is through fitting 3D parametric models to 2D or 3D sensed data <ref> [1, 21] </ref>. The main advantage of this approach is that a global view-independent model of roughly a few dozen parameters is obtainable via fitting the model to 3D sensed data.
Reference: [2] <author> R. Basri and S. Ullman, </author> <title> The Alignment of Objects with Smooth Surfaces, </title> <booktitle> Proceedings 2nd Int. Conf. on Computer Vision, </booktitle> <address> pp.482-488, </address> <year> 1988. </year>
Reference-contexts: A model aspect is made from 5 images taken by rotating the viewpoint up,down,left and right of a central viewpoint <ref> [2] </ref>. Typically, we have used rotations of 20 degrees, but the size of the model aspect is dependent on the complexity of the object and the precision of image modeling and pose computation needed for the recognition task.
Reference: [3] <author> K. Bowyer, D. Eggert, J. Stewman, and L. Stark, </author> <title> Developing the Aspect Graph Representation for Use in Image Understanding, </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <address> Palo Alto, pp.831-849, </address> <year> 1989. </year>
Reference-contexts: Here, we advocate the view-based approach, where 3D objects are modeled by a collection of 2D views of the object, each view being fairly close in geometry and topology to a sensed image <ref> [3, 10, 12, 18] </ref>. The advantages are that learning can be used in a straightforward manner to build models and that matching can be done with a representation that is close to the sensed data.
Reference: [4] <author> T. Breuel, </author> <title> Adaptive Model-based Indexing, </title> <booktitle> In Proc. 1989 DARPA Image Understanding Workshop, </booktitle> <month> May </month> <year> 1989), </year> <month> pp.805-814. </month>
Reference-contexts: Our initial experience with these previously proposed techniques has been very encouraging. The parts resulting from the segmentation according to curvature extrema do have the properties prescribed above. Ideas and methods of indexing have been reported by Breuel <ref> [4] </ref> and Califano and Mohan [5]. In range images, surface information is usually available in the neighborhood of an "edge"; in fact, "edges" are extracted using the contrasting surface properties.
Reference: [5] <author> A. Califano and R. Mohan, </author> <title> Multidimensional Indexing for Recognizing Visual Shapes, </title> <journal> IEEE T-PAMI, </journal> <volume> Vol 16., No. 4, pp.373-392, </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: Our initial experience with these previously proposed techniques has been very encouraging. The parts resulting from the segmentation according to curvature extrema do have the properties prescribed above. Ideas and methods of indexing have been reported by Breuel [4] and Califano and Mohan <ref> [5] </ref>. In range images, surface information is usually available in the neighborhood of an "edge"; in fact, "edges" are extracted using the contrasting surface properties. In Section 4, we describe some experiments using primitives which we call "wings" that encode adjacent surface information along with an edge segment.
Reference: [6] <author> S.-W. Chen, </author> <title> Wing Representation for Rigid 3D Objects, </title> <booktitle> In Proc. 10th IAPR, </booktitle> <address> Atlantic City, NJ, </address> <month> June </month> <year> 1990, </year> <month> pp398-402. </month>
Reference-contexts: The average number of iterations (not shown in the table) ranged from 9 for Ellipsoid1 to 19 for the Squirrel. 4 Modeling and recognition using range images For range images, we proposed primitives which we called object wings <ref> [6] </ref> to represent meaningful object structure useful for both indexing and alignment. Wings are, however, small enough so that some of them are likely to survive significant occlusion and feature detection error. <p> The representation computed from the grouping process was called a Labelled Line Drawing Graph (LLDG); a representation simliar to that of Huffman and Clowes, but with geometrical attributes recorded. These results were unexciting since many other methods can handle polyhedra. Chen performed experiments <ref> [6] </ref> with sculptured objects and found that segmentation was difficult and that model aspects could be quite ambiguous. Improved range scanners which could produce fine silhouettes in the image would allow the part segmentation work described in Section 3 to be directly extended to range images. <p> Current work is focused on indexing and we are concentrating on intensity images rather than range images. There is still much to do. Acknowledgements Many ideas in the paper were developed jointly with Sei-Wang Chen, Greg Lee, and Jin-Long Chen <ref> [6, 16, 7] </ref>. Any implementations reported in Section III are due to Jin-Long Chen while those reported in Section IV are due to Sei-Wang Chen and Greg Lee. This work was supported in part by NSF Grant CDA-8806599 and by Texas Instruments.
Reference: [7] <author> J.-L. Chen, G. Stockman, and K. Rao, </author> <title> Recovering and Tracking Pose of Curved 3D Objects from 2D Images, </title> <booktitle> Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <address> New York, NY, pp.233-239, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Current work is focused on indexing and we are concentrating on intensity images rather than range images. There is still much to do. Acknowledgements Many ideas in the paper were developed jointly with Sei-Wang Chen, Greg Lee, and Jin-Long Chen <ref> [6, 16, 7] </ref>. Any implementations reported in Section III are due to Jin-Long Chen while those reported in Section IV are due to Sei-Wang Chen and Greg Lee. This work was supported in part by NSF Grant CDA-8806599 and by Texas Instruments.
Reference: [8] <author> J.-L. Chen and G. Stockman, </author> <title> Indexing to model aspects using invariant contour features, </title> <institution> Computer Science Dept. </institution> <type> Tech. Rep., </type> <institution> Michigan State Univ., </institution> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: The indexing scheme allows for added or missing parts due to occlusion, imperfect object extraction, or imperfect feature extraction. Work with 2D objects has been very successful; testing on the approximating silhou ettes of 3D objects is still in progress <ref> [8] </ref>. * aligning model aspects to images Using feature points from parts extracted in the previous step, approximate translation, scale, and rotation about the view axis (Z-axis) is available.
Reference: [9] <author> J. Ponce, D. Forsyth, L. Shapiro, R. Bajcsy, D. Metaxas, M. Hebert, K. Ikeuchi, S. Sclaroff, A. Pent-land, T. Binford, A. Kak, and G. Stockman, </author> <title> Object Representation for Object Recognition, </title> <booktitle> Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <address> Seattle, WA, pp.147-152, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Accepting this, one must then look for a catalog of representations and processes, each of which is applicable to certain tasks and domains. Having stated this position in <ref> [9] </ref> and mentioning it here, we proceed within just the alignment paradigm. We assume a domain of rigid objects and will primarily exploit shape information in recognition. Change of albedo ( surface marks) observable in an intensity image will also be used.
Reference: [10] <author> S. Edelman and D. Weinshall, </author> <title> A Self-organizing Mul--tiple View Representation of 3D Objects, </title> <journal> Biological Cybernetics, Vol.64, </journal> <volume> pp.209-219, </volume> <year> 1991. </year>
Reference-contexts: Here, we advocate the view-based approach, where 3D objects are modeled by a collection of 2D views of the object, each view being fairly close in geometry and topology to a sensed image <ref> [3, 10, 12, 18] </ref>. The advantages are that learning can be used in a straightforward manner to build models and that matching can be done with a representation that is close to the sensed data.
Reference: [11] <author> P. J. Flynn and A. K. Jain, </author> <title> BONSAI: 3D object recognition using constrained search, </title> <journal> T-PAMI, </journal> <volume> Vol. 13, No. 10, </volume> <month> Oct </month> <year> 1991, </year> <month> pp.1066-1075. </month>
Reference-contexts: Often, alignment is achieved by the ability to extract salient features from the observed data and make correspondences between those features and model features (e.g. <ref> [20, 14, 11] </ref>). Only one global model containing the aggregation of labeled geometric features is needed. Another significant advantage of this approach is that an alignment transformation can be computed in closed form from a small set of feature correspondences.
Reference: [12] <author> C. Goad, </author> <title> Special Purpose Automatic Programming for 3D Model-based Vision, </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <address> Arlington, VA, </address> <year> 1983. </year>
Reference-contexts: Here, we advocate the view-based approach, where 3D objects are modeled by a collection of 2D views of the object, each view being fairly close in geometry and topology to a sensed image <ref> [3, 10, 12, 18] </ref>. The advantages are that learning can be used in a straightforward manner to build models and that matching can be done with a representation that is close to the sensed data.
Reference: [13] <author> D. D. Hoffman and W. A. Richards, </author> <title> Representing smooth plane curves for recognition, </title> <booktitle> In Proc. AAAI, </booktitle> <pages> 1982 pp 5-8. </pages>
Reference-contexts: The indexing scheme must account for occlusion: it must work when characteristic primitives are missing or added due to an interposing object. For intensity images, we propose segmentation of object silhouettes based on an intermediate codon representation <ref> [13, 19] </ref>. Our initial experience with these previously proposed techniques has been very encouraging. The parts resulting from the segmentation according to curvature extrema do have the properties prescribed above. Ideas and methods of indexing have been reported by Breuel [4] and Califano and Mohan [5].
Reference: [14] <author> D. Huttenlocher and S. Ullman, </author> <title> Recognizing solid objects using alignment, </title> <booktitle> Proc. DARPA Image Understanding Workshop, </booktitle> <month> April </month> <year> 1988, </year> <month> pp1114-1122. </month>
Reference-contexts: Often, alignment is achieved by the ability to extract salient features from the observed data and make correspondences between those features and model features (e.g. <ref> [20, 14, 11] </ref>). Only one global model containing the aggregation of labeled geometric features is needed. Another significant advantage of this approach is that an alignment transformation can be computed in closed form from a small set of feature correspondences.
Reference: [15] <author> K. Higuchi, H. Delingette, M. Hebert, and K. </author> <title> Ikeuchi, Merging Multiple Views Using a Spherical Representation, </title> <booktitle> In Proc. IEEE 2nd CAD-Based Vision Workshop, Champion, </booktitle> <address> PA, pp.124-131, </address> <year> 1994. </year>
Reference: [16] <author> G. C. Lee, </author> <title> Scene Representation from Fused Imagery, </title> <type> PhD Dissertation, </type> <institution> Michigan State Univ., </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: in the wing primitive would not only be necessary for efficient indexing, but it would also be convenient for lower level grouping processes used in bottom-up extraction of an image representation. 4.1 Segmentation and indexing using wings Work with polyhedral and origami objects confirmed the utility of the wing-based approach <ref> [16] </ref>. Larger object parts could be derived from multiple wings and occluding parts could be identified using a bottom-up grouping algorithm. The representation computed from the grouping process was called a Labelled Line Drawing Graph (LLDG); a representation simliar to that of Huffman and Clowes, but with geometrical attributes recorded. <p> We need to return to explore this in future work. 4.2 Using specific surface hypotheses Lee explored using specialized fitting to extract wings from objects with quadric surface patches, as should be permissible with many industrial objects <ref> [16] </ref>. He used both 2D contour points and neighboring 3D surface points to fit small windows of a fused range and intensity image and found that the contour points had a significant focusing effect on the surface model fitting. <p> Current work is focused on indexing and we are concentrating on intensity images rather than range images. There is still much to do. Acknowledgements Many ideas in the paper were developed jointly with Sei-Wang Chen, Greg Lee, and Jin-Long Chen <ref> [6, 16, 7] </ref>. Any implementations reported in Section III are due to Jin-Long Chen while those reported in Section IV are due to Sei-Wang Chen and Greg Lee. This work was supported in part by NSF Grant CDA-8806599 and by Texas Instruments.
Reference: [17] <author> D. G. Lowe, </author> <title> Three-dimensional Object Recognition from Single Two-dimensional Images, </title> <journal> Artificial Intelligence, Vol.31 No.3, </journal> <volume> pp.355-395, </volume> <year> 1987. </year>
Reference-contexts: Change of albedo ( surface marks) observable in an intensity image will also be used. Our object domain is admittedly ill-defined; we would like our programs to incorporate as few assumptions as possible. Generally we follow the paradigm proposed by Lowe <ref> [17] </ref>: incomplete sets of image features are used to index into model space in order to activate top-down processes which attempt to verify the presence of an object in a certain pose. The task of model verification, although fairly well-defined, is complicated because objects are 3D and images are 2D.
Reference: [18] <author> A. Pentland, B. Moghaddam, and T. Starner, </author> <title> View-Based and Modular Eigenspaces for Face Recognition, </title> <booktitle> Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <address> Seattle, WA, pp.84-91, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Here, we advocate the view-based approach, where 3D objects are modeled by a collection of 2D views of the object, each view being fairly close in geometry and topology to a sensed image <ref> [3, 10, 12, 18] </ref>. The advantages are that learning can be used in a straightforward manner to build models and that matching can be done with a representation that is close to the sensed data.
Reference: [19] <author> P. L. Rosin, </author> <title> Multiscale Representation and Matching of Curves Using Codons, CVGIP: </title> <booktitle> Graphical Models and Image Proc., </booktitle> <volume> Vol. 55, No. 4, </volume> <year> 1993, </year> <month> pp.286-310. </month>
Reference-contexts: The indexing scheme must account for occlusion: it must work when characteristic primitives are missing or added due to an interposing object. For intensity images, we propose segmentation of object silhouettes based on an intermediate codon representation <ref> [13, 19] </ref>. Our initial experience with these previously proposed techniques has been very encouraging. The parts resulting from the segmentation according to curvature extrema do have the properties prescribed above. Ideas and methods of indexing have been reported by Breuel [4] and Califano and Mohan [5]. <p> Edges internal to the boundary are obtained using the Canny operator: small segments are discarded. We have only done minor work on this step. * indexing to model aspects The boundary is segmented into codon representation and then the codons are segmented into parts <ref> [19] </ref>. Parts may be convex or concave. For each part, several features are computed which are invariant to scaling, translation, and rotation. Also, for each part, at least three points are available to determine a model-to-object alignment for just this part.
Reference: [20] <author> G. Stockman, </author> <title> Object Recognition and Localization via Pose Clustering, </title> <journal> CVGIP, </journal> <volume> Vol. 40, </volume> <year> 1987, </year> <month> pp.361-387. </month>
Reference-contexts: Often, alignment is achieved by the ability to extract salient features from the observed data and make correspondences between those features and model features (e.g. <ref> [20, 14, 11] </ref>). Only one global model containing the aggregation of labeled geometric features is needed. Another significant advantage of this approach is that an alignment transformation can be computed in closed form from a small set of feature correspondences.
Reference: [21] <author> G. Taubin and F. Cukierman and S. Sullivan and J. Ponce and D. J. Kriegman, </author> <title> Parameterized Families of Polynomials for Bounded Algebraic Curve and Surface Fitting, </title> <journal> IEEE T-PAMI, vol.16 no.3, </journal> <volume> pp.287-303, </volume> <month> Mar </month> <year> 1994. </year>
Reference-contexts: Another promising approach is through fitting 3D parametric models to 2D or 3D sensed data <ref> [1, 21] </ref>. The main advantage of this approach is that a global view-independent model of roughly a few dozen parameters is obtainable via fitting the model to 3D sensed data.

References-found: 21

