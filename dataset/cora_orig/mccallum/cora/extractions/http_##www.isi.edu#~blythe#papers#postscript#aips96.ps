URL: http://www.isi.edu/~blythe/papers/postscript/aips96.ps
Refering-URL: http://www.isi.edu/~blythe/papers/aips96.html
Root-URL: http://www.isi.edu
Email: jblythe@cs.cmu.edu  
Title: Event-Based Decompositions for Reasoning about External Change in Planners  
Author: Jim Blythe 
Address: 5000 Forbes Avenue Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: An increasing number of planners can handle uncertainty in the domain or in action outcomes. However, less work has addressed building plans when the planner's world can change independently of the planning agent in an uncertain manner. In this paper, I model this change with external events that concisely represent some aspects of structure in the planner's domain. This event model is given a formal semantics in terms of a Markov chain, but probabilistic computations from this chain would be intractable in real-world domains. I describe a technique, based on a reachability analysis of a graph built from the events, that allows abstractions of the Markov chain to be built to answer specific queries efficiently. I prove that the technique is correct. I have implemented a planner that uses this technique, and I show an example from a large planning domain. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Blythe, J. </author> <year> 1994. </year> <title> Planning with external events. </title> <editor> In de Man-taras, R. L., and Poole, D., eds., </editor> <booktitle> Proc. Tenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> 94-101. </pages> <address> Seattle, WA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However relatively little work has addressed building plans when the world can change independently of the planning agent in an uncertain manner, although <ref> (Blythe 1994) </ref> and (Hanks, Madigan, & Gavrin 1995) are examples of work in this area. In this paper I describe a method for representing external change by events that can capture some aspects of structure in the possible changes in the planner's domain. <p> The events have a similar form to STRIPS actions, allowing a planner to create subgoals whose achievement will affect the probability of occurrence of events beyond its direct control. This is discussed further in <ref> (Blythe 1994) </ref>, while the main focus of this paper is to provide a formal description of the model and demonstrate a technique that allows probabilistic expressions to be computed efficiently. <p> Once the submodel induced by the literals in the plan is created, it is incorporated into a Bayesian belief net that Weaver builds to reason about the probability of plan success, described in <ref> (Blythe 1994) </ref>. Nodes in the belief net represent steps in the plan, and the values of fluents at time points that are relevant to the plan.
Reference: <author> Blythe, J. </author> <year> 1996. </year> <title> Planning under uncertainty. </title> <type> Technical report, </type> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference-contexts: Given a subset of literals of interest in the domain, I show how a reachability analysis of the event graph can be used to build abstractions of the full model that will answer queries about the subset efficiently. I sketch a proof, contained in full in <ref> (Blythe 1996) </ref>, that computations in the abstract chains will produce the same answers as in the full model. The event graph can be computed efficiently from the domain description before the planning problem is encountered. <p> Weaver is a backchaining planner built on top of Prodigy (Veloso et al. 1995) that includes a representation for actions and events similar to that described in the last section. The algorithm for Weaver is presented in <ref> (Blythe 1996) </ref> but for this section it is sufficient to know that Weaver decides whether a plan produced by Prodigy exceeds some threshold probability of success, taking events into account. Prodigy represents actions and events in schemas that contain predicates with typed variables. <p> This part of the proof is omitted here but can be found in <ref> (Blythe 1996) </ref>.
Reference: <author> Boutilier, C., and Dearden, R. </author> <year> 1994. </year> <title> Using abstractions for decision-theoretic planning with time constraints. </title> <booktitle> In Proc. Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> 1016-1022. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: Decompositions of Markov processes have been discussed in several places in the context of probabilistic planning. For example, (Boutilier, Dean, & Hanks 1995) and (Dean & Lin 1995) consider decompositions of Markov decision processes. Boutilier and Dearden <ref> (Boutilier & Dear-den 1994) </ref> use abstractions based on subsets of the domain literals to produce policies that come within a given bound of optimal for a Markov decision process (MDP).
Reference: <author> Boutilier, C.; Dean, T.; and Hanks, S. </author> <year> 1995. </year> <title> Planning under uncertainty: structural assumptions and computational leverage. </title> <booktitle> In Proc. European Workshop on Planning. </booktitle> <address> Assissi, Italy: </address> <publisher> IOS Press. </publisher>
Reference-contexts: A crucial issue is then to find ways to decompose the full model into small, abstract models that can be used to answer queries about these subsets of the domain. This problem has been discussed by several groups of researchers, including <ref> (Boutilier, Dean, & Hanks 1995) </ref> and (Dean & Lin 1995). <p> I have demonstrated a planner using the technique in a domain where reasoning about change in the full environment would be intractable. Decompositions of Markov processes have been discussed in several places in the context of probabilistic planning. For example, <ref> (Boutilier, Dean, & Hanks 1995) </ref> and (Dean & Lin 1995) consider decompositions of Markov decision processes. Boutilier and Dearden (Boutilier & Dear-den 1994) use abstractions based on subsets of the domain literals to produce policies that come within a given bound of optimal for a Markov decision process (MDP). <p> The commitment made in the algorithm to a specific plan is partly responsible for the small size of the abstraction produced. This focus of attention is not achieved in standard policy iteration algorithms, although it is used in structured policy iteration <ref> (Boutilier, Dearden, & Goldszmidt 1995) </ref>. There are also many instances in the literature where the operator dependency graph is analysed.
Reference: <author> Boutilier, C.; Dearden, R.; and Goldszmidt, M. </author> <year> 1995. </year> <title> Exploiting structure in policy construction. </title> <booktitle> In Proc. 14th International Joint Conference on Artificial Intelligence, </booktitle> <pages> 1104-1111. </pages> <address> Montreal, Quebec: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A crucial issue is then to find ways to decompose the full model into small, abstract models that can be used to answer queries about these subsets of the domain. This problem has been discussed by several groups of researchers, including <ref> (Boutilier, Dean, & Hanks 1995) </ref> and (Dean & Lin 1995). <p> I have demonstrated a planner using the technique in a domain where reasoning about change in the full environment would be intractable. Decompositions of Markov processes have been discussed in several places in the context of probabilistic planning. For example, <ref> (Boutilier, Dean, & Hanks 1995) </ref> and (Dean & Lin 1995) consider decompositions of Markov decision processes. Boutilier and Dearden (Boutilier & Dear-den 1994) use abstractions based on subsets of the domain literals to produce policies that come within a given bound of optimal for a Markov decision process (MDP). <p> The commitment made in the algorithm to a specific plan is partly responsible for the small size of the abstraction produced. This focus of attention is not achieved in standard policy iteration algorithms, although it is used in structured policy iteration <ref> (Boutilier, Dearden, & Goldszmidt 1995) </ref>. There are also many instances in the literature where the operator dependency graph is analysed.
Reference: <author> Dean, T., and Lin, S.-H. </author> <year> 1995. </year> <title> Decomposition techniques for planning in stochastic domains. </title> <booktitle> In Proc. 14th International Joint Conference on Artificial Intelligence, 1121 - 1127. </booktitle> <address> Montreal, Quebec: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A crucial issue is then to find ways to decompose the full model into small, abstract models that can be used to answer queries about these subsets of the domain. This problem has been discussed by several groups of researchers, including <ref> (Boutilier, Dean, & Hanks 1995) </ref> and (Dean & Lin 1995). <p> A crucial issue is then to find ways to decompose the full model into small, abstract models that can be used to answer queries about these subsets of the domain. This problem has been discussed by several groups of researchers, including (Boutilier, Dean, & Hanks 1995) and <ref> (Dean & Lin 1995) </ref>. In this paper I describe an algorithm that takes a subset of the domain literals and produces an abstraction of the full model that can provably be used to compute the same probabilities as the full model for queries involving the subset of literals. <p> I have demonstrated a planner using the technique in a domain where reasoning about change in the full environment would be intractable. Decompositions of Markov processes have been discussed in several places in the context of probabilistic planning. For example, <ref> (Boutilier, Dean, & Hanks 1995) </ref> and (Dean & Lin 1995) consider decompositions of Markov decision processes. Boutilier and Dearden (Boutilier & Dear-den 1994) use abstractions based on subsets of the domain literals to produce policies that come within a given bound of optimal for a Markov decision process (MDP). <p> I have demonstrated a planner using the technique in a domain where reasoning about change in the full environment would be intractable. Decompositions of Markov processes have been discussed in several places in the context of probabilistic planning. For example, (Boutilier, Dean, & Hanks 1995) and <ref> (Dean & Lin 1995) </ref> consider decompositions of Markov decision processes. Boutilier and Dearden (Boutilier & Dear-den 1994) use abstractions based on subsets of the domain literals to produce policies that come within a given bound of optimal for a Markov decision process (MDP). Dean and Lin (Dean & Lin 1995) partition <p> & Hanks 1995) and <ref> (Dean & Lin 1995) </ref> consider decompositions of Markov decision processes. Boutilier and Dearden (Boutilier & Dear-den 1994) use abstractions based on subsets of the domain literals to produce policies that come within a given bound of optimal for a Markov decision process (MDP). Dean and Lin (Dean & Lin 1995) partition the state space of an MDP and solve each partition using a different abstraction, combining the results to provide a solution to the original problem.
Reference: <author> Desimone, R. V., and Agosta, J. M. </author> <year> 1994. </year> <title> Oil spill response simulation: </title> <booktitle> the application of artificial intelligence planning technology. In Simulation Multiconference. </booktitle>
Reference-contexts: An example Weaver is an implemented planner that uses event graphs to reason about change in the environment. I present an example of Weaver reasoning about a plan constructed in the oil-spill domain, a large planning domain developed by SRI for the US Coast Guard 2 <ref> (Desimone & Agosta 1994) </ref>. 2 I am grateful to Roberto Desimone and John Mark Agosta of SRI for making this domain available.
Reference: <author> Etzioni, O. </author> <year> 1990. </year> <title> A Structural Theory of Explanation-Based Learning. </title> <type> Ph.D. Dissertation, </type> <institution> School of Computer Science, Carnegie Mellon University. </institution> <note> Available as techni-cal report CMU-CS-90-185. </note>
Reference-contexts: The event graph used here is similar to the operator graph used by Knoblock to create abstractions for classical planning (Knoblock 1993), as well as the problem space graph introduced by Etzioni for learning search control from action representations <ref> (Etzioni 1990) </ref>, and the directed cyclic graphical representations of Spirtes (Spirtes 1995). Although this paper has focussed on marginal independence, a commitment to a particular policy allows us to exploit conditional independence in the events to get a finer-grained abstraction.
Reference: <author> Haddawy, P.; Doan, A.; and Goodwin, R. </author> <year> 1995. </year> <title> Efficient decision-theoretic planning: Techniques and empirical analysis. </title> <editor> In Besnard, P., and Hanks, S., eds., </editor> <booktitle> Proc. Eleventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> 229-326. </pages> <address> Montreal, Quebec: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Introduction 1 An increasing number of subgoaling planners can handle uncertainty in the domain or in action outcomes, including (Kushmerick, Hanks, & Weld 1994) and <ref> (Haddawy, Doan, & Goodwin 1995) </ref>. However relatively little work has addressed building plans when the world can change independently of the planning agent in an uncertain manner, although (Blythe 1994) and (Hanks, Madigan, & Gavrin 1995) are examples of work in this area.
Reference: <author> Hanks, S.; Madigan, D.; and Gavrin, J. </author> <year> 1995. </year> <title> Probabilistic temporal reasoning with endogenous change. </title> <editor> In Besnard, P., and Hanks, S., eds., </editor> <booktitle> Proc. Eleventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> 245-254. </pages> <address> Montreal, Quebec: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However relatively little work has addressed building plans when the world can change independently of the planning agent in an uncertain manner, although (Blythe 1994) and <ref> (Hanks, Madigan, & Gavrin 1995) </ref> are examples of work in this area. In this paper I describe a method for representing external change by events that can capture some aspects of structure in the possible changes in the planner's domain. <p> A crucial issue is then to find ways to decompose the full model into small, abstract models that can be used to answer queries about these subsets of the domain. This problem has been discussed by several groups of researchers, including <ref> (Boutilier, Dean, & Hanks 1995) </ref> and (Dean & Lin 1995). <p> I have demonstrated a planner using the technique in a domain where reasoning about change in the full environment would be intractable. Decompositions of Markov processes have been discussed in several places in the context of probabilistic planning. For example, <ref> (Boutilier, Dean, & Hanks 1995) </ref> and (Dean & Lin 1995) consider decompositions of Markov decision processes. Boutilier and Dearden (Boutilier & Dear-den 1994) use abstractions based on subsets of the domain literals to produce policies that come within a given bound of optimal for a Markov decision process (MDP).
Reference: <author> Knoblock, C. A. </author> <year> 1993. </year> <title> Generating Abstraction Hierarchies: An Automated Approach to Reducing Search in Planning. </title> <address> Boston: </address> <publisher> Kluwer. </publisher>
Reference-contexts: There are also many instances in the literature where the operator dependency graph is analysed. The event graph used here is similar to the operator graph used by Knoblock to create abstractions for classical planning <ref> (Knoblock 1993) </ref>, as well as the problem space graph introduced by Etzioni for learning search control from action representations (Etzioni 1990), and the directed cyclic graphical representations of Spirtes (Spirtes 1995).
Reference: <author> Kushmerick, N.; Hanks, S.; and Weld, D. </author> <year> 1994. </year> <title> An algorithm for probabilistic least-commitment planning. </title> <booktitle> In Proc. Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> 1073-1078. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: Introduction 1 An increasing number of subgoaling planners can handle uncertainty in the domain or in action outcomes, including <ref> (Kushmerick, Hanks, & Weld 1994) </ref> and (Haddawy, Doan, & Goodwin 1995). However relatively little work has addressed building plans when the world can change independently of the planning agent in an uncertain manner, although (Blythe 1994) and (Hanks, Madigan, & Gavrin 1995) are examples of work in this area. <p> A formal model for actions and events In this section I give a formal description of a representation for actions and events, used to motivate and describe the event graph in the next section. The model is based on <ref> (Kushmerick, Hanks, & Weld 1994) </ref>.
Reference: <author> Spirtes, P. </author> <year> 1995. </year> <title> Directed cyclic graphical representations of feedback models. </title> <editor> In Besnard, P., and Hanks, S., eds., </editor> <booktitle> Proc. Eleventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> 491-498. </pages> <address> Montreal, Quebec: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The event graph used here is similar to the operator graph used by Knoblock to create abstractions for classical planning (Knoblock 1993), as well as the problem space graph introduced by Etzioni for learning search control from action representations (Etzioni 1990), and the directed cyclic graphical representations of Spirtes <ref> (Spirtes 1995) </ref>. Although this paper has focussed on marginal independence, a commitment to a particular policy allows us to exploit conditional independence in the events to get a finer-grained abstraction.
Reference: <author> Veloso, M.; Carbonell, J.; Perez, A.; Borrajo, D.; Fink, E.; and Blythe, J. </author> <year> 1995. </year> <title> Integrating planning and learning: The prodigy architecture. </title> <journal> Journal of Experimental and Theoretical AI 7 </journal> <pages> 81-120. </pages>
Reference-contexts: Weaver is a backchaining planner built on top of Prodigy <ref> (Veloso et al. 1995) </ref> that includes a representation for actions and events similar to that described in the last section.
References-found: 14

