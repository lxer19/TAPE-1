URL: ftp://dirleton.csres.utexas.edu/pub/reports/070.ps
Refering-URL: http://www.cli.com/reports/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Phone: (512) 322-9951  
Note: William D. Young  
Address: 1717 W. 6th St. Suite 290 Austin, Texas 78703  
Affiliation: Computational Logic Inc.  
Abstract: Technical Report 70 September, 1991 This work was sponsored in part at Computational Logic, Inc. by the Naval Research Laboratory, contract number N00014-90-C-2351 and is the final report on Task 1 of this contract. The views and conclusions contained in this document are those of the author(s) and should not be interpreted as representing the official policies, either expressed or implied, of Computational Logic, Inc., the Naval Research Laboratory, or the U.S. Government. Verifiable Computer Security and Hardware: Issues
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R.P. Abbott, et. al.. </author> <title> Security Analysis and Enhancements of Computer Operating Systems. </title> <type> Technical Report S-413558-740, </type> <institution> National Bureau of Standards, </institution> <year> 1974. </year>
Reference-contexts: Process isolation, then, is crucially relied upon by the security mechanisms and taken more or less for granted in the model. Yet, such underlying mechanisms have often been found to be the source of security flaws in implemented systems <ref> [1, 2, 62, 83, 135] </ref>. 9 Few serious attempts have been made to formally model and verify these crucial underlying facilities; 10 these facilities are obvious candidates for formal scrutiny at the hardware level.
Reference: [2] <institution> Air Force Studies Board. Committee on Multilevel Data Management Security. </institution> <address> Washington, D.C., </address> <year> 1983. </year>
Reference-contexts: Process isolation, then, is crucially relied upon by the security mechanisms and taken more or less for granted in the model. Yet, such underlying mechanisms have often been found to be the source of security flaws in implemented systems <ref> [1, 2, 62, 83, 135] </ref>. 9 Few serious attempts have been made to formally model and verify these crucial underlying facilities; 10 these facilities are obvious candidates for formal scrutiny at the hardware level.
Reference: [3] <author> S.R. Ames and D.R. Ostreicher. </author> <title> Design of a Message Processing System for a Multilevel Secure Environment. </title> <booktitle> In Proceedings of the National Computer Conference, </booktitle> <volume> Vol. 47, </volume> <pages> Pages 765-771. </pages> <publisher> AFIPS, </publisher> <year> 1978. </year>
Reference-contexts: Variants of the Bell and LaPadula model have been widely used in secure system development <ref> [3, 46, 55, 85, 102, 120] </ref> despite the fact that the model does not preclude some types of intuitively un-secure behavior (covert channels). Information flow models tend to be more abstract than access control models.
Reference: [4] <author> J.P. Anderson. </author> <title> Computer Security Technology Planning Study. </title> <type> Technical Report ESD-TR-73-51, </type> <institution> Volumes I and II, Electronic Systems Division, Bedford, </institution> <address> MA., </address> <month> October, </month> <year> 1972. </year>
Reference-contexts: Secure systems based on capabilities include the UCLA Secure Unix [107, 131], kernelized VM/370 [55], and PSOS [102]. 3.3-E (4)-d Reference Monitor. The most prevalent approach to implementing access control is the notion of a reference monitor <ref> [4] </ref>. A reference monitor is an access checking module that ideally: mediates all accesses by subjects to objects; can be verified to operate correctly; and, is tamperproof. Some believe that ``the reference monitor is inherent to the design of secure computers'' [119].
Reference: [5] <author> J.C. Barros and B.W. Johnson. </author> <title> Equivalence of the Arbiter, the Synchronizer, the Latch, and the Inertial Delay. </title> <journal> IEEE Transactions on Computers:603-614, </journal> <month> July, </month> <year> 1983. </year>
Reference-contexts: Researchers have considered verification of hardware at various levels of abstraction from circuit designs written in high-level hardware description languages such as VHDL [84, 117] down to low-level models of MOS circuits [25, 133]. Techniques have been developed that are adequate for handling small circuits <ref> [5] </ref> to handling entire microprocessors [66, 69]. There is a rapidly growing literature in this area [29, 79, 127, 136]. In many ways, verifying hardware is a more tractable problem than verifying software because hardware tends to be more regular.
Reference: [6] <author> D.E. Bell. </author> <title> Concerning `Modeling' of Computer Security. </title> <booktitle> In Symposium on Security and Privacy, </booktitle> <pages> Pages 8-13. </pages> <publisher> IEEE, </publisher> <year> 1988. </year>
Reference-contexts: Others construe models in the sense of a mathematical theory a collection of a formal structures and axioms about their manipulation. Some of the attempts to clarify this issue merely exacerbate the confusion. Bell <ref> [6] </ref>, for example, argues vehemently that the Bell and LaPadula model is an ``abstraction'' (but without once saying of what it is an abstraction).
Reference: [7] <author> D.E. Bell and L.J. LaPadula. </author> <title> Secure Computer System: Unified Exposition and Multics Interpretation. </title> <type> Technical Report MTR-2997, </type> <institution> MITRE Corp., Bedford, </institution> <address> Mass., </address> <month> July, </month> <year> 1975. </year>
Reference-contexts: The model may be very abstract (eg., the machine model used in the definition of noninterference [52]) or be fairly concrete and include specific security control mechanisms (eg., the Bell and LaPadula model <ref> [7] </ref>). At base, a security model is simply a specification of an information system (or class of systems) and its security properties. <p> The intent is to limit information flow by imposing certain operational constraints on subjects. The Bell and LaPadula model <ref> [7] </ref> is an access control model that incorporates a number of rules designed to restrict the flow of information.
Reference: [8] <author> H.K. Berg, W.E. Boebert, W.R. Franta, T.G. Moher. </author> <title> Formal Methods of Program Verification and Specification. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1982. </year>
Reference-contexts: This pattern of specification, illustrated in Figure 2, has become institutionalized by the promulgation of the A1 level requirements and is sometimes taken as illustrative of state-of-the-art formal methods in the security arena <ref> [8] </ref>. We continue to expect and accept this style and level of analysis for two major reasons. The common wisdom holds that this is the best we can do; code level verification of large systems is deemed beyond the current state of the verifier's art.
Reference: [9] <author> W.R. Bevier, W.A. Hunt, Jr., J S. Moore, W.D. Young. </author> <title> An Approach to Systems Verification. </title> <journal> Journal of Automated Reasoning5(4):411-428, </journal> <month> December, </month> <year> 1989. </year>
Reference-contexts: However, the formal analysis applied in secure system development to date has typically been carried out at rather high level of abstraction, leading some to question its usefulness and cost effectiveness in finding and eliminating security flaws in implemented systems. Some current work in verification <ref> [9] </ref> suggests that techniques and tools are becoming available for formal analysis at a level much closer to the actual implementation of a secure system. <p> There have been attempts to enforce security by permitting users to access a machine only through a high level language. [135] Such approaches are vulnerable to any means of directly accessing the machine at the assembly language level. 7 This is the style of proofs done on the CLI stack <ref> [9] </ref>. 8 benefits of abstraction as a tool for developing and honing intuitions about the secure system and its correctness properties, while gaining the benefits of ``completeness'' in the model. 2.2-C Modeling from the Top Down Our final point noted above is that it is usually futile to attempt to specify <p> The paradigm of secure system development illustrated in Figure 2 may be extended ``downward'' toward the hardware level as shown in Figure 3. There are significant research issues involved in relating levels of abstraction involving both verified hardware and verified software. The CLI ``stack'' effort <ref> [9] </ref> may offer some directions. However, as we indicated in Section 2.2, the correctness properties of a compiler or assembler are different than the security of a system; implements is simply the wrong relationship between the layers of the hierarchy in a secure system development.
Reference: [10] <author> W.R. Bevier. </author> <title> Kit and the Short Stack. </title> <journal> Journal of Automated Reasoning5(4):519-530, </journal> <month> December, </month> <year> 1989. </year>
Reference-contexts: Almost any hardware feature accessible to an end user could have potential use in some covert activity. This motivated our insistence in Section 2.2 that our formal system model be as inclusive as possible. We focus 9 Rushby [114] is the source of this list. 10 Bevier <ref> [10] </ref> is the only attempt of which we are aware to model and prove the correctness of a process isolation scheme down to the machine code level. 11 See [70] for some work on the generic specification of hardware. 13 on aspects of hardware that seem particularly relevant from a security
Reference: [11] <author> W.R. Bevier. </author> <title> Kit: A Study in Operating System Verification. </title> <journal> IEEE Transactions on Software Engineering15(11):1368-81, </journal> <month> November, </month> <year> 1989. </year> <note> Also published as CLI Technical Report 28. </note>
Reference-contexts: Both require a clear and unambiguous (formal) specification and a proof that an implementation meets this specification. Some proofs have been done on specific instances of this problem; Bevier <ref> [11] </ref>, for example, gives a specification for process isolation on a particular target machine. <p> Support for this basic concept 16 The scheme for protecting system mode is an obvious candidate for formal verification. The formal verification of the KIT operating system <ref> [11] </ref> included a proof that no user-mode program could enter system mode.
Reference: [12] <author> W.R. Bevier, W.D. Young. </author> <title> The Proof of Correctness of a Fault-Tolerant Circuit Design. </title> <booktitle> In Proceedings of the Second International Working Conference on Dependable Computing for Critical Applications, </booktitle> <pages> Pages 107-114. </pages> <publisher> IFIP, </publisher> <month> February, </month> <year> 1991. </year>
Reference-contexts: However, as we indicated in Section 2.2, the correctness properties of a compiler or assembler are different than the security of a system; implements is simply the wrong relationship between the layers of the hierarchy in a secure system development. We are aware of only a few efforts <ref> [12, 14] </ref>, other than the CLI stack, in which properties defined formally at a fairly high level of abstraction have been ``pushed down'' to the hardware level; none of these were explicitly security properties. 12 As an example of a significant and challenging research area where hardware modeling and verification could <p> Some schemes ensure the correct behavior of the system even in the presence of maliciously faulty units (Byzantine faults) [75]. Implementations of at least one such scheme have been modeled and formally verified to the hardware level. <ref> [12, 14] </ref> Despite an extensive literature on fault-tolerance, we are not aware of the use of fault tolerant hardware in secure system design, though the idea is an obvious one. An alternative to redundancy is provided by an approach called ``dynamic verification''.
Reference: [13] <author> K.J. Biba. </author> <title> Integrity Considerations for Secure Computer Systems. </title> <type> Technical Report ESD-TR-76-372, </type> <institution> USAF Electronic Systems Division, Bedford, </institution> <address> MA., </address> <month> April, </month> <year> 1977. </year>
Reference-contexts: Some have been general purpose and others designed for fairly specialized applications. Most have been concerned with preventing information disclosure; but others have been concerned with integrity of information in the system <ref> [13] </ref> or with preventing the denial of service to legitimate users [51]. In real secure system development efforts, most of these have given way to variants of the Bell and LaPadula model or to noninterference and restrictiveness.
Reference: [14] <author> M. Bickford and M. Srivas. </author> <title> Formal Verification of a Fault-Tolerant Microprocessor System Design. </title> <institution> NASA Contractor Report , Odyssey Research Associates, </institution> <month> February, </month> <year> 1991. </year> <month> 31 </month>
Reference-contexts: However, as we indicated in Section 2.2, the correctness properties of a compiler or assembler are different than the security of a system; implements is simply the wrong relationship between the layers of the hierarchy in a secure system development. We are aware of only a few efforts <ref> [12, 14] </ref>, other than the CLI stack, in which properties defined formally at a fairly high level of abstraction have been ``pushed down'' to the hardware level; none of these were explicitly security properties. 12 As an example of a significant and challenging research area where hardware modeling and verification could <p> Some schemes ensure the correct behavior of the system even in the presence of maliciously faulty units (Byzantine faults) [75]. Implementations of at least one such scheme have been modeled and formally verified to the hardware level. <ref> [12, 14] </ref> Despite an extensive literature on fault-tolerance, we are not aware of the use of fault tolerant hardware in secure system design, though the idea is an obvious one. An alternative to redundancy is provided by an approach called ``dynamic verification''.
Reference: [15] <author> W.E. Boebert. </author> <title> On the Inability of an Unmodified Capability Machine to Enforce the *-Property. </title> <booktitle> In Proceedings of the Seventh National Computer Security Conference, </booktitle> <month> September, </month> <year> 1984. </year>
Reference-contexts: They must be genuinely unforgeable. Schemes for enforcing this involve having a tagged architecture or separate designated segments for storing capabilities. Another problem is that capabilities allow control of access, but may not be well-matched for some types of security policies. <ref> [15] </ref> They do not support traceability of access since they do not answer the question ``who has access to this object?'' 17 Also, passing of capabilities among domains may violate the containment goals of lattice-style security policies.
Reference: [16] <author> W.E. Boebert. </author> <title> The LOCK Demostration. </title> <booktitle> In Proceedings of the 11th National Computer Security Conference, </booktitle> <institution> National Institute of Standards and Technology, </institution> <year> 1988. </year>
Reference-contexts: Noninterference is limited to deterministic systems. It has been used as the security model for at least one large system development effort <ref> [16, 119] </ref>. Non-deducibility [128] is a strengthening of noninterference suited to non-deterministic systems. The key idea is the following. Assume that subject a is prohibited by the policy from passing information to subject b. <p> Hardware has not been entirely neglected in secure systems specification and verification. Both the SCOMP [46] and LOCK <ref> [16, 119] </ref> specifications included protection mechanisms that were implemented in hardware as well as in software. However, these efforts considered features largely modeled at a level of abstraction where the distinction between hardware and software does not matter.
Reference: [17] <author> W.E. Boebert. </author> <title> Constructing and Infosec System using LOCK Technology. distributed at the LOCK Tutorial, </title> <booktitle> 11th National Computer Security Conference. </booktitle>
Reference-contexts: This reduces the need for physical security on the storage medium. ``In addition, cryptography is used to close covert channels 15 , protect security-critical data bases, and defend against attacks by subverted device controller hardware and firmware.'' <ref> [17] </ref> The use of cryptographic isolation may eliminate some of the verification requirements on I/O controllers and other portions of the system. However, it puts a correctness premium on the portions of the system that perform encryption and decryption. These units are often critical to system security.
Reference: [18] <author> W.E. Boebert and R.Y. </author> <note> Kain. </note>
Reference-contexts: The type-enforcement policy permits the construction of ``assured pipelines'' a mechanism of assuring that a data item passes through some series of transformations in a controlled manner without the possibility that the process may be subverted <ref> [18] </ref>. 18 Type-enforcement is orthogonal to the lattice-based mandatory access policy and to the discretionary access policy both also enforced by the SIDEARM. An access is permitted only if it passes the ``filter'' of all three policies.
References-found: 18

