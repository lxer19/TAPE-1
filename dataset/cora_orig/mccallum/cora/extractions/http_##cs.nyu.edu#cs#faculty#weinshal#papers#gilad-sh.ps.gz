URL: http://cs.nyu.edu/cs/faculty/weinshal/papers/gilad-sh.ps.gz
Refering-URL: http://cs.nyu.edu/cs/faculty/weinshal/papers.html
Root-URL: http://www.cs.nyu.edu
Title: Motion of Disturbances: Detection and Tracking of multi-Body non-Rigid Motion  
Author: Gilad Halevi and Daphna Weinshall 
Address: 91904 Jerusalem, Israel  
Affiliation: Institute of Computer Science, The Hebrew University,  
Abstract: We present a new approach to the tracking of very non rigid patterns of motion, such as water flowing down a stream. The algorithm is based on a disturbance map, which is obtained by linearly subtracting the temporal average of the previous frames from the new frame. Every local motion creates a disturbance having the form of a wave, with a head at the present position of the motion and a historical tail that indicates the previous locations of that motion. These disturbances serve as loci of attraction for tracking particles that are scattered throughout the image. The algorithm is very fast and can be performed in real time. We provide excellent tracking results on various complex sequences, using both stabilized and moving cameras, showing: a busy ant column, waterfalls, rapids and flowing streams, shoppers in a mall, and cars in a traffic intersection. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Halevi and D. Weinshall, </author> <title> Motion of Disturbances: Detection and Tracking of multi-Body non-Rigid Motion, </title> <journal> CVPR, </journal> <note> San-Juan, 1997; full version can be obtained from http://www.cs.huji.ac.il/ daphna/. </note>
Reference-contexts: We shall illustrate the algorithm in the difficult examples of an ant column, water flowing down streams and waterfalls, shoppers in a mall, and cars at a traffic intersection. A review of related literature can be found in the full version of this paper <ref> [1] </ref>. Proceedings: IEEE Conference on Computer Vision and Pattern Recognition, San-Juan, June 1997 2 2. Tracking in Stabilized Images We want to treat cases in which the objects to be tracked undergo significant changes in shape upon transition from frame to frame, e.g., water flowing down a waterfall. <p> There is a smooth monotonic path between the extremum at the tail of the disturbance to the extremum at its head (see detailed discussion in <ref> [1] </ref>). 2.2. Tracking Particles: Above we defined a disturbance field and showed how every moving object in an image creates a disturbance that includes a head and a historical tail. We shall now define tracking particles, which are attracted to these disturbances. <p> The third point, describing the relative shading of the object, is a feature which is maintained for a long period of time; therefore, it is sufficient to determine it at the beginning of the tracking (see discussion in <ref> [1] </ref>). After we set the relative shading of the object and place the particle on it during initialization, we move on to the tracking stage based on the disturbance field. W.l.o.g. we shall henceforth assume that the shading of the object is bright relative to the background. <p> Using the waterfalls sequences, the direction of the optical flow typically matched the actual motion, but the magnitude was far from the true speed, rendering tracking along a few frames impossible. These experiments, as well as comparisons to point matching algorithms, are described in <ref> [1] </ref>. In conclusion, in our experiments our algorithm was very reliable and performed better than other algorithms on sequences with many independently moving objects or complex patterns of motion.
Reference: [2] <author> H. H. Nagel, </author> <title> Formation of an Object Concept by Analysis of Systematic Time Variation in the Optically Perceptible Environment, </title> <journal> CVIP, </journal> <volume> 7 </volume> <pages> 149-194, </pages> <year> 1978. </year>
Reference-contexts: The basic structure of the disturbance does not depend on the changes in shading or shape that the object undergoes, but only on its motion. (Cf. to <ref> [2] </ref> where such changes were used for figure/ground segmentation.) A disturbance is an abrupt change in grey-levels that appears (and disappears) in a certain region and at a certain time.
Reference: [3] <author> A. Kass, A. Witkin and D. Terzopoulos, Snakes: </author> <title> Active Contour Modes, </title> <journal> IJCV, </journal> <volume> 1(3) </volume> <pages> 321-331, </pages> <year> 1988. </year>
Reference-contexts: Comparison with Other Methods Most of the published methods for tracking nonrigid objects are not suitable for handling the examples presented here. The basic assumption is almost always that the shape of the object changes slowly (small deformation), as in the methods based on the occluding contours of objects <ref> [3] </ref>, or methods based on extreme points in the object [4]. Clearly, these approaches are not suitable to handle flowing water (what are the objects in this case?), or camouflaged ants where occluding contours cannot be discerned reliably.
Reference: [4] <author> I. Cohen, N. Ayache and P. Sulger, </author> <title> Tracking Points on Deformable Objects, Using Curvature Information, </title> <booktitle> ECCV 92, </booktitle> <pages> pp. 458-465, </pages> <year> 1992. </year>
Reference-contexts: The basic assumption is almost always that the shape of the object changes slowly (small deformation), as in the methods based on the occluding contours of objects [3], or methods based on extreme points in the object <ref> [4] </ref>. Clearly, these approaches are not suitable to handle flowing water (what are the objects in this case?), or camouflaged ants where occluding contours cannot be discerned reliably.
Reference: [5] <author> J. P. Berroir, I. Herlin and I. Cohen,. </author> <title> Non-Rigid Motion Without Relying on Local Features: </title> ..., <journal> INRIA Repport, </journal> <volume> No. 2684, </volume> <year> 1995. </year>
Reference-contexts: The only methods that are not based on the assumption of slow changes, such as the method described in <ref> [5] </ref>, require a geometric model that is confined to very specific cases. Typically, however, we do not have a general geometric model for flowing water or the motion of ants.
Reference: [6] <author> D. P. Huttenlocher, J. J. Noh and W. J. Rucklidge, </author> <title> Tracking Non-Rigid Objects in Complex Scenes, </title> <booktitle> ICCV 93, </booktitle> <pages> pp. 93-101, </pages> <year> 1993. </year>
Reference-contexts: Clearly, these approaches are not suitable to handle flowing water (what are the objects in this case?), or camouflaged ants where occluding contours cannot be discerned reliably. Also, an approach like that described in <ref> [6] </ref>, in which the minimum of the Hausdorff distance between prominent points sampled from the frame is sought, requires that the shape of the object changes slowly between consecutive frames, and thus it does not meet our needs.
Reference: [7] <author> H. Applebaum, M. Werman, </author> <title> The detection of motion in noisy environments using a 3D f* algorithm, </title> <type> PhD thesis, </type> <institution> Hebrew University, </institution> <year> 1995. </year>
Reference: [8] <author> P. J. Burt, R. Hingorani and R. J. Kolezynski, </author> <title> Mechanism for isolating component patterns in the sequential analysis of multiple motion, </title> <booktitle> IEEE Workshop on Visual Motion, </booktitle> <pages> pp. 187-193, </pages> <year> 1991. </year>
Reference-contexts: In this way maximum overlap between the average and the new frame is always maintained, cf. [10]. The stabilization process is based on a search for affine correspondence between the frames. In <ref> [8] </ref> it was proved that this computation always converges to a result that correctly reflects the most dominant motion in the scene. In most cases it is the motion of the background.
Reference: [9] <author> B. K. P. Horn and B.G. Schunck, </author> <title> Determining Optical Flow, </title> <booktitle> Art. Intel. </booktitle> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference: [10] <author> M. Irani, B. Rousso and S. Peleg, </author> <title> Computing Occluding and Transparent Motion, </title> <journal> International Journal of Computer Visionq, </journal> <year> 1993. </year>
Reference-contexts: For this reason we employ the opposite approach of repeated registration of the background to the last frame. In this way maximum overlap between the average and the new frame is always maintained, cf. <ref> [10] </ref>. The stabilization process is based on a search for affine correspondence between the frames. In [8] it was proved that this computation always converges to a result that correctly reflects the most dominant motion in the scene. In most cases it is the motion of the background.
Reference: [11] <author> B. D. Lucas, T. Kanade. </author> <title> An Iterative Image Registration Technique with an Application to Stereo Vision, </title> <booktitle> IU workshop, </booktitle> <pages> pp. 121-130, </pages> <year> 1981. </year>
Reference-contexts: We performed extensive experiments with the algorithm of Lucas & Kanade <ref> [11] </ref>.
References-found: 11

