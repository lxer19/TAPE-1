URL: ftp://thales.cs.umd.edu/pub/reports/svdrqm.ps
Refering-URL: ftp://thales.cs.umd.edu/pub/reports/Contents.html
Root-URL: 
Title: On the Convergence of a New Rayleigh Quotient Method with Applications to Large Eigenproblems  
Author: D. P. O'Leary G. W. Stewart 
Date: October 1997  
Affiliation: University of Maryland College Park Institute for Advanced Computer Studies TR-97-74 Department of Computer Science  
Pubnum: TR-3839  
Abstract: In this paper we propose a variant of the Rayleigh quotient method to compute an eigenvalue and corresponding eigenvectors of a matrix. It is based on the observation that eigenvectors of a matrix with eigenvalue zero are also singular vectors corresponding to zero singular values. Instead of computing eigenvector approximations by the inverse power method, we take them to be the singular vectors corresponding to the smallest singular value of the shifted matrix. If these singular vectors are computed exactly the method is quadratically convergent. However, exact singular vectors are not required for convergence, and the resulting method combined with Golub-Kahan-Krylov bidiagonalization looks promising for enhancement/refinement meth ods for large eigenvalue problems. fl This report is available by anonymous ftp from thales.cs.umd.edu in the directory pub/reports or on the web at http://www.cs.umd.edu/ stewart/. y Computer Science Department and Institute for Advanced Computer Studies, University of Mary-land, College Park, MD 20742. This work was supported by the National Science Foundation under grant CCR-95-03126. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. R. Fokkema, G. L. G. Sleijpen, and H. A. Van der Vorst. </author> <title> Jacobi-Davidson style QR and QZ algorithms for the reduction of matrix pencils. </title> <type> Preprint 941, </type> <institution> Department of Mathematics, Universiteit Utrech, </institution> <year> 1996. </year>
Reference-contexts: Nonetheless, the method may be useful in finding eigenpairs of large matrices. Specifically, over the past decade new algorithms have been developed to solve large eigenvalue problems by building up approximations to the eigenspaces of eigenvalues lying in a neighborhood of the complex plane. These algorithms (e.g., see <ref> [3, 5, 1] </ref>) generally begin with subspaces V and W. The space V approximates a right eigenspace of A (the space W usually does not approximate a corresponding left eigenspace).
Reference: [2] <author> G. H. Golub and W. Kahan. </author> <title> Calculating the singular values and pseudo-inverse of a matrix. </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 2 </volume> <pages> 205-224, </pages> <year> 1965. </year>
Reference-contexts: Actually both methods are due to Golub and Kahan <ref> [2] </ref>. 4 The Singular Value Rayleigh Quotient Method where E = X H AX. Let A have the singular value decomposition 1 2 A (V 1 V 2 ) = 1 0 ! where 1 is nonsingular of order p and the singular values are in descending order.
Reference: [3] <author> R. B. Morgan. </author> <title> On restarting the Arnoldi method for large nonsymmetric eigenvalue problems. </title> <journal> Mathematics of Computation, </journal> <volume> 65 </volume> <pages> 1213-1230, </pages> <year> 1996. </year>
Reference-contexts: Nonetheless, the method may be useful in finding eigenpairs of large matrices. Specifically, over the past decade new algorithms have been developed to solve large eigenvalue problems by building up approximations to the eigenspaces of eigenvalues lying in a neighborhood of the complex plane. These algorithms (e.g., see <ref> [3, 5, 1] </ref>) generally begin with subspaces V and W. The space V approximates a right eigenspace of A (the space W usually does not approximate a corresponding left eigenspace).
Reference: [4] <author> A. M. Ostrowski. </author> <title> On the convergence of the Rayleigh quotient iteration for the computation of the characteristic roots and vectors. III (generalizd Rayleigh quotient and characteristic roots with linear elementary divisors). Arch. Rational Mech. </title> <journal> Anal., </journal> <volume> 3 </volume> <pages> 325-240, </pages> <year> 1959. </year>
Reference-contexts: The quantity ^t is called the generalized Rayleigh quotient of A at ^v and ^w H . Ostrowski <ref> [4] </ref> showed that under weak conditions on ^v and ^w H the shift t converges cubically to provided that the initial shift is sufficiently near . There are two reasons for the fast convergence. First, steps 1 and 2 in (1.1) improve earlier approximations to the right and left eigenvectors.
Reference: [5] <author> D. C. Sorensen. </author> <title> Implicit application of polynomial filters in a k-step arnoldi method. </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 13 </volume> <pages> 357-385, </pages> <year> 1992. </year>
Reference-contexts: Nonetheless, the method may be useful in finding eigenpairs of large matrices. Specifically, over the past decade new algorithms have been developed to solve large eigenvalue problems by building up approximations to the eigenspaces of eigenvalues lying in a neighborhood of the complex plane. These algorithms (e.g., see <ref> [3, 5, 1] </ref>) generally begin with subspaces V and W. The space V approximates a right eigenspace of A (the space W usually does not approximate a corresponding left eigenspace).
Reference: [6] <author> G. W. Stewart. </author> <title> Computable error bounds for aggregated Markov chains. </title> <journal> Journal of the ACM, </journal> <volume> 30 </volume> <pages> 271-285, </pages> <year> 1983. </year>
Reference-contexts: H (x X) = 1 0 ! y H ! 0 L ; where L = Y H AX = Y H AY: Moreover kxk = kY H k = 1 and ky H k = kXk : (2.3) The Singular Value Rayleigh Quotient Method 5 For a proof see <ref> [6] </ref>. The theorem states that the eigenvalue can be uncoupled from the rest of A by a similarity transformation and that the transformation has certain special properties, which we will use in the sequel.
Reference: [7] <author> G. W. Stewart and J.-G. Sun. </author> <title> Matrix Perturbation Theory. </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: The sines of the canonical angles between X and V 2 are the singular values of V H 1 X (see <ref> [7, xI.5.2] </ref>). Multiplying (2.1) by W H 1 and using the fact that W H 1 A = 1 V H we find that W H 1 AX = 1 V H The inequality (2.2) now follows on multiplying by 1 1 and taking norms. <p> Note that there are block versions of this theorem in which x and y H are replaced by matrices spanning left and right eigenspaces of A (see <ref> [7, xV.1] </ref>). The number in (2.3) is a condition number for the eigenvalue [7, xIV.2.2]. <p> Note that there are block versions of this theorem in which x and y H are replaced by matrices spanning left and right eigenspaces of A (see [7, xV.1]). The number in (2.3) is a condition number for the eigenvalue <ref> [7, xIV.2.2] </ref>. <p> In this case, the bound (3.4) also establishes the quadratic convergence of the sequence of vectors ~v to x. Specifically, the quantity kV H xk is the sine of the angle between x and ~v <ref> [7, xI.5] </ref>, which therefore goes to zero as fast as *. A similar result holds for the convergence of the vectors ~w H . We have established the local superlinear convergence of the SVRQ iteration to a simple eigenvalue, as long as the approximate singular vectors are accurate enough. <p> For it can be shown that when t = 1 = k 1 k k (L I) 1 k: The quantity k (L I) 1 k 1 is written sep (; L), and its reciprocal governs the sensitivity of the eigenvectors corresponding to <ref> [7, xV.2] </ref>. If is a nondefective multiple eigenvalue of A, then A I has a zero singular value of multiplicity at least two. It this case, must have a zero singular value, and our analysis fails because the required positive lower bound does not exist.
References-found: 7

