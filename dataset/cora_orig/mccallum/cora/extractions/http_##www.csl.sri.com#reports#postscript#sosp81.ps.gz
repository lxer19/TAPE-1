URL: http://www.csl.sri.com/reports/postscript/sosp81.ps.gz
Refering-URL: http://www.csl.sri.com/reports/postscript/
Root-URL: 
Title: Design and Verification of Secure Systems approach decouples verification of components which perform trusted functions
Author: John Rushby 
Address: Menlo Park CA 94025 USA  
Affiliation: Computer Science Laboratory SRI International  Computing Laboratory, University of Newcastle upon Tyne,  
Note: Reprint of a paper presented at the 8th ACM Symposium on Operating System Principles, Pacific Grove, California, 14-16 December 1981. (ACM Operating Systems Review Vol. 15 No. 5 pp. 12-21)  This  This work was performed while the author was with the  England, and was sponsored by (what was then) the Royal Signals Radar Establishment.  
Abstract: This paper reviews some of the difficulties that arise in the verification of kernelized secure systems and suggests new techniques for their resolution. It is proposed that secure systems should be conceived as distributed systems in which security is achieved partly through the physical separation of their individual components and partly through the mediation of trusted functions performed within some of those components. The purpose of a security kernel is simply to allow such a `distributed' system to actually run within a single processor; policy enforcement is not the concern of a security kernel. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. R. Ames Jr. </author> <title> Security kernels: </title> <booktitle> A solution or a problem? In Proceedings of the Symposium on Security and Privacy, </booktitle> <pages> pages 141-150, </pages> <address> Oakland, CA, April 1981. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: A number of kernelized systems have been constructed [12,19, 25] and various models of security have been formulated to serve as the basis for their verification [6, 9, 28]. Despite the enthusiasm for this approach, there remain certain difficulties and problems in its application (see, for example <ref> [1] </ref>).
Reference: [2] <author> S. R. Ames Jr. and J. G. Keeton-Williams. </author> <title> Demonstrating security for trusted applications on a security kernel base. </title> <booktitle> In Proceedings of the Symposium on Security and Privacy, </booktitle> <pages> pages 145-156, </pages> <address> Oakland, CA, April 1980. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: Attempts to support these applications on a conventional kernel have led to systems of considerable complexity whose verification presents difficulties that are quite at variance with the evident simplicity of the task which the system is intended to perform <ref> [2] </ref>. The purpose of this paper is to present a new approach (or, rather, a re-working of some old approaches [3,26,27]) to the design and verification of secure systems and to argue that the problems of conventional kernelized systems are thereby avoided or overcome.
Reference: [3] <author> J. P. Anderson. </author> <title> Systems architecture for security and protection. </title> <editor> In C. R. Renninger, editor, </editor> <booktitle> Approaches to Privacy and Security in Computer Systems, </booktitle> <pages> pages 49-50. </pages> <note> NBS Special Publication 404, </note> <institution> GPO SD Catalog No. </institution> <address> C13.10:404, Washington, D.C., </address> <year> 1974. </year>
Reference-contexts: Policy enforcement is not the concern of a security kernel. There is some similarity between these proposals and Popek's notion of `levels of kernels' [26, 27] while the idea that the management of shared resources can be handled by separate virtual machines can be traced back to Anderson <ref> [3] </ref>. This approach achieves a separation of concerns by completely decoupling the verification of the components which perform trusted functions from the verification of the security kernel.
Reference: [4] <author> K. </author> <title> Auerbach. Secure personal computing (technical correspondence). </title> <journal> Communications of the ACM, </journal> <volume> 23(1) </volume> <pages> 36-37, </pages> <month> January </month> <year> 1980. </year>
Reference-contexts: A SNFE is a device that is interposed between host machines and a network in order to provide end-to-end encryption around the network. Some of the general design issues for such a device are discussed by Auerbach <ref> [4] </ref> and a particular design is described by Barnes [5]. Basically, the issues are as follows.
Reference: [5] <author> D. H. Barnes. </author> <booktitle> Computer security in the RSRE PPSN. In Networks '80, </booktitle> <pages> pages 605-620. </pages> <note> Online Conferences, </note> <month> June </month> <year> 1980. </year>
Reference-contexts: Also, current approaches to kernel design and verification developed out of concern for the problem of providing multilevel secure operation on general-purpose multi-user systems|whereas many of the present-day applications which require some form of guaranteed security are special-purpose, single-function systems <ref> [5, 11, 13, 24, 33] </ref> whose security requirements are somewhat different to those enshrined in the multilevel models. <p> A SNFE is a device that is interposed between host machines and a network in order to provide end-to-end encryption around the network. Some of the general design issues for such a device are discussed by Auerbach [4] and a particular design is described by Barnes <ref> [5] </ref>. Basically, the issues are as follows. As well as a cryptographic device (a `crypto') the SNFE must certainly contain components for handling the protocols, message buffering and so on required at its interfaces with the communications lines to the host on one side and the network on the other. <p> One of the chief design aims of the SUE was that it should be minimally small and very simple <ref> [5] </ref>. (The SDC Communications Kernel [11] is a similar system, though rather more complex.) Because the SUE is only required to provide a fixed (and small) number of regimes, each of which executes a fixed (and small) program, there is no need for it to support paging or virtual memory management
Reference: [6] <author> D. E. Bell and L. J. La Padula. </author> <title> Secure computer system: Unified exposition and Multics interpretation. </title> <type> Technical Report ESD-TR-75-306, </type> <institution> Mitre Corporation, Bedford, </institution> <address> MA, </address> <month> March </month> <year> 1976. </year>
Reference-contexts: A number of kernelized systems have been constructed [12,19, 25] and various models of security have been formulated to serve as the basis for their verification <ref> [6, 9, 28] </ref>. Despite the enthusiasm for this approach, there remain certain difficulties and problems in its application (see, for example [1]). <p> But then the spooler cannot delete spool files after their contents have been printed|for such action conflicts with the (kernel enforced) *-property <ref> [6] </ref> of multilevel security. In order to provide an acceptable user interface, while avoiding the proliferation of used spool files, it seems necessary that the spooler should become a `trusted process' and be allowed to violate the *-property.
Reference: [7] <author> T. A. Berson and G. L. Barksdale Jr. </author> <title> KSOS|development methodology for a secure operating system. </title> <booktitle> In National Computer Conference, </booktitle> <volume> volume 48, </volume> <pages> pages 365-371. </pages> <booktitle> AFIPS Conference Proceedings, </booktitle> <year> 1979. </year>
Reference-contexts: In KSOS, for example, the trusted processes contain "support software to aid the day-to-day operation of the system (e.g., secure spoolers for line printer output, dump/restore programs, portions of the interface to a packet switched communications network etc.)." <ref> [7, page 365] </ref> Once trusted processes are admitted to the system, however, the kernel is no longer the sole arbiter of security; it is necessary to be sure that the special privileges granted to trusted processes are not abused by those processes and may not be usurped by other, untrusted, processes. <p> Rather: "to a large extent they [trusted processes] represent a mismatch between the idealizations of the multilevel security policy and the practical needs of a real user environment." <ref> [7, page 365] </ref> 4 The true roots of the difficulties caused by trusted processes are not to be found in those processes themselves, nor in the functions which they perform, but in the conception that a security kernel should act as a centralized agent for the enforcement of a uniform system-wide <p> The technique which has been used to verify secure information flow in kernels constructed by the Mitre Corporation [20] and in KSOS <ref> [7, 10] </ref>, and which seems to be widely accepted, is known as `information flow analysis' (IFA) [21]|sometimes also called `security flow analysis.' It might be thought that this will also provide a satisfactory technique for verifying a separation kernel. But this is not so. <p> The security of the implementation can then be established by showing it to be a correct implementation of the secure high-level specifications [23]. In conventional practice, however, this second stage is not performed. For KSOS, for example, only `illustrative' proofs of the implementation were provided <ref> [7] </ref>. Because the KSOS kernel contains, among other things, a mechanism to support a multilevel secure file system, verification of the security of its high-level specifications is a significant task. It would be vastly more difficult and hugely expensive to verify the correctness of its implementation as well.
Reference: [8] <author> D. E. Denning and P. J. Denning. </author> <title> Certification of programs for secure information flow. </title> <journal> Communications of the ACM, </journal> <volume> 20(7) </volume> <pages> 504-513, </pages> <month> July </month> <year> 1977. </year>
Reference-contexts: model developed at SRI [9] (which is more than can be said of a security kernel|a point I shall return to later) and this model therefore provides both a specification for the security requirements of the file-server and the justification for its verification by the method of `information flow analysis' <ref> [8, 20, 21] </ref>. We can add further shared resources to the system in just the same way as the file-server. A central printing facility, for example, can be provided by a self-contained printer-server connected to each single-user machine (and probably the file-server also) by additional, dedicated communication lines.
Reference: [9] <author> R. J. Feiertag, K. N. Levitt, and L. Robinson. </author> <title> Proving multilevel security of a system design. </title> <booktitle> In Sixth ACM Symposium on Operating System Principles, </booktitle> <pages> pages 57-65, </pages> <month> November </month> <year> 1977. </year>
Reference-contexts: A number of kernelized systems have been constructed [12,19, 25] and various models of security have been formulated to serve as the basis for their verification <ref> [6, 9, 28] </ref>. Despite the enthusiasm for this approach, there remain certain difficulties and problems in its application (see, for example [1]). <p> In order to guarantee the security of the whole system, all we need to do is to verify that single program with respect to an appropriate specification of its security requirements. It turns out that the role of a multilevel secure file-server matches the security model developed at SRI <ref> [9] </ref> (which is more than can be said of a security kernel|a point I shall return to later) and this model therefore provides both a specification for the security requirements of the file-server and the justification for its verification by the method of `information flow analysis' [8, 20, 21]. <p> Recall that the SUE kernel does very little except field interrupts and allow one regime to SWAP control to another|and IFA provides no basis for the verification of these important and tricky matters. Questions relating to control flow cannot even be formulated within the mathematical model <ref> [9] </ref> that justifies IFA as a verification technique. In fact, it is doubtful whether that model really provides a sound basis for the verification of any sort of security kernel|but then it was not formulated for that purpose.
Reference: [10] <author> Ford. </author> <title> KSOS verification plan. </title> <type> Technical Report WDL-TR-7809, </type> <institution> Ford Aerospace and Communications Corporation, </institution> <address> Palo Alto, CA, </address> <month> March </month> <year> 1978. </year>
Reference-contexts: The technique which has been used to verify secure information flow in kernels constructed by the Mitre Corporation [20] and in KSOS <ref> [7, 10] </ref>, and which seems to be widely accepted, is known as `information flow analysis' (IFA) [21]|sometimes also called `security flow analysis.' It might be thought that this will also provide a satisfactory technique for verifying a separation kernel. But this is not so.
Reference: [11] <author> D. L. Golber. </author> <title> The SDC communications kernel, </title> <month> August </month> <year> 1981. </year> <title> Presented at DoD Computer Security Industry Seminar. </title>
Reference-contexts: Also, current approaches to kernel design and verification developed out of concern for the problem of providing multilevel secure operation on general-purpose multi-user systems|whereas many of the present-day applications which require some form of guaranteed security are special-purpose, single-function systems <ref> [5, 11, 13, 24, 33] </ref> whose security requirements are somewhat different to those enshrined in the multilevel models. <p> One of the chief design aims of the SUE was that it should be minimally small and very simple [5]. (The SDC Communications Kernel <ref> [11] </ref> is a similar system, though rather more complex.) Because the SUE is only required to provide a fixed (and small) number of regimes, each of which executes a fixed (and small) program, there is no need for it to support paging or virtual memory management as found in the kernels
Reference: [12] <author> B. D. Gold et al. </author> <title> A security retrofit of VM/370. </title> <booktitle> In National Computer Conference, </booktitle> <volume> volume 48, </volume> <pages> pages 335-344. </pages> <booktitle> AFIPS Conference Proceedings, </booktitle> <year> 1979. </year> <month> 19 </month>
Reference-contexts: It is widely recognised that VMMs provide a suitable basis for the construction of secure systems and at least two systems have been constructed along these lines <ref> [12, 26] </ref>. <p> more complex.) Because the SUE is only required to provide a fixed (and small) number of regimes, each of which executes a fixed (and small) program, there is no need for it to support paging or virtual memory management as found in the kernels of general-purpose systems such as KVM/370 <ref> [12] </ref>. Instead, a much simpler memory-resident system is possible in which each regime is permanently allocated to a fixed partition of real memory while the SUE itself occupies another fixed partition.
Reference: [13] <author> A. Hathaway. </author> <title> LSI guard system specification (type A). </title> <type> Technical Report Draft, </type> <institution> MITRE Corporation, Bedford, </institution> <address> MA, </address> <month> July </month> <year> 1980. </year>
Reference-contexts: Also, current approaches to kernel design and verification developed out of concern for the problem of providing multilevel secure operation on general-purpose multi-user systems|whereas many of the present-day applications which require some form of guaranteed security are special-purpose, single-function systems <ref> [5, 11, 13, 24, 33] </ref> whose security requirements are somewhat different to those enshrined in the multilevel models.
Reference: [14] <author> C. A. R. Hoare. </author> <title> Proof of correctness of data representations. </title> <journal> Acta Informatica, </journal> <volume> 1 </volume> <pages> 271-281, </pages> <year> 1972. </year>
Reference-contexts: What we desire, for security, is that each regime's view of the concrete machine should exactly coincide with its own abstract machine. A similar requirement expresses the `correctness' criterion for implementations of abstract data types. This latter criterion may be formulated precisely in terms of an `abstraction function' <ref> [14] </ref>: that is, a function which maps from concrete to abstract states.
Reference: [15] <author> B. W. Lampson. </author> <title> A note on the confinement problem. </title> <journal> Communications of the ACM, </journal> <volume> 16(10) </volume> <pages> 613-615, </pages> <month> October </month> <year> 1973. </year>
Reference-contexts: The limitation of this approach is that it is concerned only to protect the physical representations of information, rather than information itself. Thus it does not control the `leakage' of information through covert signalling paths <ref> [15, 17] </ref>, nor is the notion of such `information flow' expressible in the model [28, 32] which underlies the verification of these kernels.
Reference: [16] <author> C. E. Landwehr. </author> <title> Assertions for verification of multilevel secure military message systems. </title> <journal> ACM Software Engineering Notes, </journal> <volume> 5(3) </volume> <pages> 46-47, </pages> <month> July </month> <year> 1980. </year>
Reference-contexts: What is not included in their exposition is a technique for establishing when a process may be trusted." <ref> [16, page 46] </ref> In the absence of any precise formulation of the role of trusted processes within a model of secure system behaviour, and in the absence of any formal understanding of how properties proved of trusted processes combine with those proved of a security kernel in order to establish the <p> It is not clear how the use of this kernel has contributed to the overall security or verifiability of the Guard and it is certainly no surprise to learn that: "Verification of the trusted processes to be used in the Guard has con sumed far more resources than originally planned." <ref> [16, page 46] </ref> 5 2 Security and Distributed Systems The combination of a security kernel and trusted processes is hard to understand and even harder to verify because it does not represent a separation of concerns but a confusion of the same: neither member of the combination is independent of the
Reference: [17] <author> S. B. Lipner. </author> <title> A comment on the confinement problem. </title> <booktitle> In Fifth ACM Symposium on Operating System Principles, </booktitle> <pages> pages 192-196. </pages> <publisher> ACM, </publisher> <year> 1975. </year>
Reference-contexts: The limitation of this approach is that it is concerned only to protect the physical representations of information, rather than information itself. Thus it does not control the `leakage' of information through covert signalling paths <ref> [15, 17] </ref>, nor is the notion of such `information flow' expressible in the model [28, 32] which underlies the verification of these kernels. <p> indirect leakage, is unacceptable and, in consequence, security kernels intended for these applications must not only enforce the security policy of the system on all non-kernel software, but must also adhere to it themselves, in order that their own internal variables may not become a channel for insecure information flow <ref> [17, 20] </ref>. This implies that the kernel must enforce and obey a single, system-wide security policy. But once this approach is adopted, it is soon discovered that certain system functions cannot be accommodated within its discipline.
Reference: [18] <author> A. F. Martin and J. K. Parks. </author> <title> Intelligent X25 level 2 line units for packet-switching. </title> <booktitle> In Networks '80, </booktitle> <pages> pages 371-384. </pages> <note> Online Conferences, </note> <year> 1980. </year>
Reference-contexts: The SUE adopts a far more ruthless approach: DMA is permanently excluded from the system. (The efficiency problems this might seem to cause are overcome by the use of special-purpose hardware <ref> [18] </ref>.) With DMA excluded from the system, almost all responsibility for I/O can be removed from the SUE since the memory management of a PDP-11 allows device registers to be protected just like ordinary memory locations.
Reference: [19] <author> E. J. McCauley and P. J. Drongowski. </author> <title> KSOS|the design of a secure operating system. </title> <booktitle> In National Computer Conference, </booktitle> <volume> volume 48, </volume> <pages> pages 345-353. </pages> <booktitle> AFIPS Conference Proceedings, </booktitle> <year> 1979. </year>
Reference: [20] <author> J. K. Millen. </author> <title> Security kernel validation in practice. </title> <journal> Communications of the ACM, </journal> <volume> 19(5) </volume> <pages> 243-250, </pages> <month> May </month> <year> 1976. </year>
Reference-contexts: indirect leakage, is unacceptable and, in consequence, security kernels intended for these applications must not only enforce the security policy of the system on all non-kernel software, but must also adhere to it themselves, in order that their own internal variables may not become a channel for insecure information flow <ref> [17, 20] </ref>. This implies that the kernel must enforce and obey a single, system-wide security policy. But once this approach is adopted, it is soon discovered that certain system functions cannot be accommodated within its discipline. <p> model developed at SRI [9] (which is more than can be said of a security kernel|a point I shall return to later) and this model therefore provides both a specification for the security requirements of the file-server and the justification for its verification by the method of `information flow analysis' <ref> [8, 20, 21] </ref>. We can add further shared resources to the system in just the same way as the file-server. A central printing facility, for example, can be provided by a self-contained printer-server connected to each single-user machine (and probably the file-server also) by additional, dedicated communication lines. <p> The technique which has been used to verify secure information flow in kernels constructed by the Mitre Corporation <ref> [20] </ref> and in KSOS [7, 10], and which seems to be widely accepted, is known as `information flow analysis' (IFA) [21]|sometimes also called `security flow analysis.' It might be thought that this will also provide a satisfactory technique for verifying a separation kernel. But this is not so.
Reference: [21] <author> J. K. Millen. </author> <title> Operating system security verification. </title> <type> Technical Report M79-223, </type> <institution> MITRE Corporation, Bedford, </institution> <address> MA, </address> <month> September </month> <year> 1979. </year>
Reference-contexts: model developed at SRI [9] (which is more than can be said of a security kernel|a point I shall return to later) and this model therefore provides both a specification for the security requirements of the file-server and the justification for its verification by the method of `information flow analysis' <ref> [8, 20, 21] </ref>. We can add further shared resources to the system in just the same way as the file-server. A central printing facility, for example, can be provided by a self-contained printer-server connected to each single-user machine (and probably the file-server also) by additional, dedicated communication lines.
Reference: [22] <author> P. G. Neumann, R. S. Boyer, R. J. Feiertag, K. N. Levitt, and L. Robinson. </author> <title> A provably secure operating system: The system, its applications, and proofs. </title> <type> Technical report, </type> <institution> SRI International, </institution> <month> May </month> <year> 1980. </year> <note> Second Edition, Report CSL-116. </note>
Reference: [23] <author> P. G. Neumann et al. </author> <title> Software development and proofs of multi-level security. </title> <booktitle> In Proc. 2nd International Conference on Software Engineering, </booktitle> <pages> pages 421-428, </pages> <address> San Francisco, CA, </address> <year> 1976. </year>
Reference-contexts: The security of the implementation can then be established by showing it to be a correct implementation of the secure high-level specifications <ref> [23] </ref>. In conventional practice, however, this second stage is not performed. For KSOS, for example, only `illustrative' proofs of the implementation were provided [7].
Reference: [24] <author> M. A. Padlipsky, K. J. Biba, and R. B. Neely. </author> <title> KSOS|computer network applications. </title> <booktitle> In National Computer Conference, </booktitle> <volume> volume 48, </volume> <pages> pages 373-381. </pages> <booktitle> AFIPS Conference Proceedings, </booktitle> <year> 1979. </year>
Reference-contexts: Also, current approaches to kernel design and verification developed out of concern for the problem of providing multilevel secure operation on general-purpose multi-user systems|whereas many of the present-day applications which require some form of guaranteed security are special-purpose, single-function systems <ref> [5, 11, 13, 24, 33] </ref> whose security requirements are somewhat different to those enshrined in the multilevel models.
Reference: [25] <author> G. J. Popek et al. </author> <title> UCLA secure UNIX. </title> <booktitle> In National Computer Conference, </booktitle> <volume> volume 48, </volume> <pages> pages 355-364. </pages> <booktitle> AFIPS Conference Proceedings, </booktitle> <year> 1979. </year>
Reference-contexts: Introduction A formally verified security kernel is widely considered to offer the most promising basis for the construction of truly secure computer systems, at least in the short term. A number of kernelized systems have been constructed <ref> [12,19, 25] </ref> and various models of security have been formulated to serve as the basis for their verification [6, 9, 28]. Despite the enthusiasm for this approach, there remain certain difficulties and problems in its application (see, for example [1]). <p> Security kernels differ in the extent to which they are cognizant of the overall security policy of the system. Some kernels (for example, that of UCLA Secure UNIX <ref> [25] </ref>) have the character of a sophisticated protection mechanism and guarantee that no object supported by the kernel may be accessed in any way unless its recorded `protection data' explicitly permits that type of access.
Reference: [26] <author> G. J. Popek and C. S. Kline. </author> <title> A verifiable protection system. </title> <booktitle> In Proc. International Conference on Reliable Software, </booktitle> <pages> pages 294-304, </pages> <address> Los Angeles, CA, </address> <year> 1975. </year>
Reference-contexts: It is widely recognised that VMMs provide a suitable basis for the construction of secure systems and at least two systems have been constructed along these lines <ref> [12, 26] </ref>. <p> Policy enforcement is not the concern of a security kernel. There is some similarity between these proposals and Popek's notion of `levels of kernels' <ref> [26, 27] </ref> while the idea that the management of shared resources can be handled by separate virtual machines can be traced back to Anderson [3].
Reference: [27] <author> G. J. Popek and C. S. Kline. </author> <title> Issues in kernel design. </title> <booktitle> In National Computer Conference, </booktitle> <volume> volume 47, </volume> <pages> pages 1079-1086. </pages> <booktitle> AFIPS Conference Proceedings, </booktitle> <year> 1978. </year>
Reference-contexts: Policy enforcement is not the concern of a security kernel. There is some similarity between these proposals and Popek's notion of `levels of kernels' <ref> [26, 27] </ref> while the idea that the management of shared resources can be handled by separate virtual machines can be traced back to Anderson [3].
Reference: [28] <author> Gerald J. Popek and David R. Farber. </author> <title> A model for verification of data security in operating systems. </title> <journal> Communications of the ACM, </journal> <volume> 21(9) </volume> <pages> 737-749, </pages> <month> September </month> <year> 1978. </year>
Reference-contexts: A number of kernelized systems have been constructed [12,19, 25] and various models of security have been formulated to serve as the basis for their verification <ref> [6, 9, 28] </ref>. Despite the enthusiasm for this approach, there remain certain difficulties and problems in its application (see, for example [1]). <p> The limitation of this approach is that it is concerned only to protect the physical representations of information, rather than information itself. Thus it does not control the `leakage' of information through covert signalling paths [15, 17], nor is the notion of such `information flow' expressible in the model <ref> [28, 32] </ref> which underlies the verification of these kernels.
Reference: [29] <author> L. Robinson. Quoted by P. </author> <title> zave in report of a panel session from specifications of reliable software conference, </title> <month> July </month> <year> 1979. </year>
Reference-contexts: The answer may be to add some explicit notion of interpretation to the state machine model. This extended model would make it possible to address such concerns as parallelism, language semantics, and interrupt handling." <ref> [29] </ref> A model with some of these characteristics is described in a companion paper to this [31] and is used to justify a new method for verifying kernels which enforce the policy of isolation. An informal explanation of this method is given in the next section.
Reference: [30] <author> John Rushby. </author> <title> Verification of secure systems. </title> <type> Technical Report 166, </type> <institution> Computing Laboratory, University of Newcastle upon Tyne, Newcastle upon Tyne, UK, </institution> <month> August </month> <year> 1981. </year>
Reference-contexts: of the very limited, controlled form that I have described (involving only the `aliasing' of certain names), so that the consequences of the differences between them may be understood completely, then, surely, the technique is sound. (For more extended discussion, and an example of the application of the technique, see <ref> [30] </ref>.) We now need a method for proving that a separation kernel (with its `wires cut') enforces isolation on its regimes: we must prove the total absence of any information flow from one regime to another. <p> Verification by IFA requires that 12 operations invoked by RED may only access RED values|but it is evident that the SWAP operation must access both RED and BLACK values. It follows that IFA cannot verify the security of a SWAP operation, even though it is manifestly secure (see <ref> [30] </ref> for more extended discussion and some worked examples). The cause of this failure is that IFA is a syntactic technique: it is concerned only with the security classifications (`colours') of variables, not their values. <p> A formal derivation of the six conditions, which attempts to demonstrate that they are exactly the right conditions, is given in [31], while the relationship between this method and verification by IFA is examined in <ref> [30] </ref>, which also contains a small example of the application of the method.
Reference: [31] <author> John Rushby. </author> <title> Proof of Separability|a verification technique for a class of security kernels. </title> <booktitle> In Proc. 5th International Symposium on Programming, volume 137 of Lecture Notes in Computer Science, </booktitle> <pages> pages 352-367, </pages> <address> Turin, Italy, April 1982. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Finally, in Section 4, I shall outline a precise specification of the role of a separation kernel and sketch an appropriate method of verification which I call `Proof of Separability' and which is developed formally in a companion paper to this <ref> [31] </ref>. <p> This extended model would make it possible to address such concerns as parallelism, language semantics, and interrupt handling." [29] A model with some of these characteristics is described in a companion paper to this <ref> [31] </ref> and is used to justify a new method for verifying kernels which enforce the policy of isolation. An informal explanation of this method is given in the next section. Proof of Separability The purpose of a separation kernel is to simulate a distributed environment. <p> A formal derivation of the six conditions, which attempts to demonstrate that they are exactly the right conditions, is given in <ref> [31] </ref>, while the relationship between this method and verification by IFA is examined in [30], which also contains a small example of the application of the method. <p> Space permits only a terse description of the model here; a more complete description, together with arguments for its suitability and justification for the particular choice of conditions defining Proof of Separability may be found in <ref> [31] </ref>. The model comprises a finite set S of states and a set OPS S ! S of operations on those states. The system interacts with its environment by consuming elements of a set I of inputs and producing elements of a set O of outputs.
Reference: [32] <author> B. J. Walker, R. A. Kemmerer, and G. J. Popek. </author> <title> Specification and verification of the UCLA Unix security kernel. </title> <journal> Communications of the ACM, </journal> <volume> 23(2) </volume> <pages> 118-131, </pages> <month> February </month> <year> 1980. </year>
Reference-contexts: The limitation of this approach is that it is concerned only to protect the physical representations of information, rather than information itself. Thus it does not control the `leakage' of information through covert signalling paths [15, 17], nor is the notion of such `information flow' expressible in the model <ref> [28, 32] </ref> which underlies the verification of these kernels.
Reference: [33] <author> J. P. L. Woodward. </author> <title> Applications for multilevel secure operating systems. </title> <booktitle> In National Computer Conference, </booktitle> <volume> volume 48, </volume> <pages> pages 319-328. </pages> <booktitle> AFIPS Conference Proceedings, </booktitle> <year> 1979. </year> <month> 21 </month>
Reference-contexts: Also, current approaches to kernel design and verification developed out of concern for the problem of providing multilevel secure operation on general-purpose multi-user systems|whereas many of the present-day applications which require some form of guaranteed security are special-purpose, single-function systems <ref> [5, 11, 13, 24, 33] </ref> whose security requirements are somewhat different to those enshrined in the multilevel models. <p> The truth of this proposition becomes self-evident when we consider some of the specialised applications of secure systems. The ACCAT Guard provides a good example <ref> [33] </ref>. The Guard is basically a facility for the exchange of messages between a highly classified system and a more lowly one.
References-found: 33

