URL: http://superbook.bellcore.com/~std/papers/CHI88.ps
Refering-URL: 
Root-URL: 
Title: USING LATENT SEMANTIC ANALYSIS TO IMPROVE ACCESS TO TEXTUAL INFORMATION  
Author: Susan T. Dumais George W. Furnas Thomas K. Landauer Scott Deerwester Richard Harshman 
Address: Ontario  
Affiliation: Bell Communications Research  University of Chicago University of Western  
Abstract: This paper describes a new approach for dealing with the vocabulary problem in human-computer interaction. Most approaches to retrieving textual materials depend on a lexical match between words in users' requests and those in or assigned to database objects. Because of the tremendous diversity in the words people use to describe the same object, lexical matching methods are necessarily incomplete and imprecise [5]. The latent semantic indexing approach tries to overcome these problems by automatically organizing text objects into a semantic structure more appropriate for matching user requests. This is done by taking advantage of implicit higher-order structure in the association of terms with text objects. The particular technique used is singular-value decomposition, in which a large term by text-object matrix is decomposed into a set of about 50 to 150 orthogonal factors from which the original matrix can be approximated by linear combination. Terms and objects are represented by 50 to 150 dimensional vectors and matched against user queries in this "semantic" space. Initial tests find this completely automatic method widely applicable and a promising way to improve users' access to many kinds of textual materials, or to objects and services for which textual descriptions are available. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Blair, </author> <title> D.C. and Maron, M.E. An evaluation of retrieval effectiveness for a full-text document-retrieval system. </title> <journal> Communications of the ACM, 1985, </journal> <volume> 28, </volume> <pages> 289-299. </pages>
Reference-contexts: Text objects that contain one or more words in common with those in the users' query are returned as relevant. Keyword or content-based retrieval systems like this are, however, far from ideal many objects relevant to a users' query are missed, and many unrelated or irrelevant materials are retrieved <ref> [1] </ref>, [12]. We believe that a principled attack on these problems depends on understanding human verbal behavior and its implications for human-computer interaction.
Reference: 2. <author> Borko, H. and Bernick, </author> <title> M.D. Automatic document classification. </title> <journal> Journal of the ACM, </journal> <month> April </month> <year> 1963, </year> <pages> 10(3), 151-162. </pages>
Reference-contexts: The idea of aiding information retrieval by discovering latent proximity structure has several lines of precedence in the information science literature. Hierarchical classification analyses have sometimes been used for term and document clustering [13], [15]. Factor analysis has also been explored previously for automatic indexing and retrieval <ref> [2] </ref>. Our latent structure method differs from these approaches in several important ways: (1) we use a high-dimensional representation which allows us to better represent semantic relations; (2) both terms and text objects are explicitly represented in the same space; and (3) objects can be retrieved directly from query terms.
Reference: 3. <author> Conklin, J. </author> <title> Hypertext: An introduction and survey. </title> <booktitle> Computer, </booktitle> <month> Sept </month> <year> 1987, </year> <pages> 17-41. </pages>
Reference-contexts: Methods for organizing and accessing textual information range from electronic analogs of familiar paper-based techniques, like tables of contents, hierarchies, or indices [11], [16] to richer associative connections that are feasible only with computers, like full-content addressability [12], hypertext <ref> [3] </ref>, or information lenses [10]. While these tools may provide some retrieval advantages over existing paper and pencil technology, many benefits of electronic storage and retrieval are unrealized.
Reference: 4. <author> Deerwester, S., Dumais, S.T., Furnas, G.W., Landauer, </author> <title> T.K., and Harshman, R.A. Indexing by latent semantic analysis. </title> <journal> Journal of the American Society for Information Science, </journal> <note> in press. </note>
Reference-contexts: As a result, terms that did not actually appear in an object may still end up close to it, if that is consistent with the major patterns of association in the data. Position in the space then serves as the new kind of "semantic indexing" <ref> [4] </ref>. The result can be represented geometrically with location of the terms and objects in k -space given by the vectors from the T and O matrices, respectively. In this space the cosine or dot product between vectors corresponds to their estimated similarity.
Reference: 5. <author> Furnas, G.W., Landauer, T.K., Gomez, L.M., and Dumais, S.T. </author> <title> Statistical semantics: Analysis of the potential performance of key-word information systems. </title> <journal> Bell System Technical Journal, 1983, </journal> <volume> 62(6), </volume> <pages> 1753-1806. </pages>
Reference-contexts: We believe that a principled attack on these problems depends on understanding human verbal behavior and its implications for human-computer interaction. In previous work <ref> [5] </ref>, [6], we showed that there is tremendous diversity in the words people use to describe the same object or concept (synonymy), and that this places strict, and low, limits on the expected performance of keyword systems.
Reference: 6. <author> Furnas, G.W., Landauer, T.K., Gomez, L.M., and Dumais, S. T. </author> <title> The vocabulary problem in human-system communication. </title> <journal> Communications of the ACM, 1987, </journal> <volume> 30(11), </volume> <pages> 964-971. </pages>
Reference-contexts: We believe that a principled attack on these problems depends on understanding human verbal behavior and its implications for human-computer interaction. In previous work [5], <ref> [6] </ref>, we showed that there is tremendous diversity in the words people use to describe the same object or concept (synonymy), and that this places strict, and low, limits on the expected performance of keyword systems.
Reference: 7. <author> Forsythe, G.E., Malcolm, M.A., and Moler, C.B. </author> <title> Computer Methods for Mathematical Computations (Chapter 9: Least squares and the singular value decomposition). </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1977. </year>
Reference-contexts: The particular latent semantic indexing analysis that we have tried uses singular-value decomposition, a technique closely related to eigenvector decomposition and factor analysis <ref> [7] </ref>. We take a large matrix, X , of term to text-object association data and decompose it into a set of, typically 50 to 150, orthogonal factors from which the original matrix can be approximated by linear combination.
Reference: 8. <author> Good, M.D., Whiteside, J.A. Wixon, D.R., and Jones, S.J. </author> <title> Building a user-derived interface. </title> <journal> Communications of the ACM, 1984, </journal> <volume> 27(10), </volume> <pages> 1032-1043. </pages>
Reference: 9. <author> Koll, M. </author> <title> An approach to concept-based information retrieval. </title> <journal> ACM SIGIR Forum, </journal> <volume> XIII, </volume> <year> 1979, </year> <pages> 32-50. </pages>
Reference-contexts: Koll <ref> [9] </ref> has discussed many of the same ideas we describe above regarding concept-based information retrieval. His system differs from ours in that it lacks the formal mathematical underpinnings provided by the singular value decomposition approach, and it has only been tested on very small datasets.
Reference: 10. <author> Malone, T.W., Grant, K.R., Turbak, F.A., Brobst, S.A., and Cohen, </author> <title> M.D. Intelligent information sharing systems. </title> <journal> Communications of the ACM, 1987, </journal> <volume> 30(5), </volume> <pages> 390-402. </pages>
Reference-contexts: Methods for organizing and accessing textual information range from electronic analogs of familiar paper-based techniques, like tables of contents, hierarchies, or indices [11], [16] to richer associative connections that are feasible only with computers, like full-content addressability [12], hypertext [3], or information lenses <ref> [10] </ref>. While these tools may provide some retrieval advantages over existing paper and pencil technology, many benefits of electronic storage and retrieval are unrealized.
Reference: 11. <author> Orwick, P., Jaynes, J.T., Barstow, T.R., and Bohn, </author> <title> L.S. DOMAIN/DELPHI: Retrieving documents online. </title> <booktitle> In Proceeding of CHI'86, </booktitle> <year> 1986, </year> <pages> 114-121. </pages>
Reference-contexts: While many of the technological barriers to information access and display have been removed, the psychological problem of being able to find what you want remains. Methods for organizing and accessing textual information range from electronic analogs of familiar paper-based techniques, like tables of contents, hierarchies, or indices <ref> [11] </ref>, [16] to richer associative connections that are feasible only with computers, like full-content addressability [12], hypertext [3], or information lenses [10]. While these tools may provide some retrieval advantages over existing paper and pencil technology, many benefits of electronic storage and retrieval are unrealized.
Reference: 12. <author> Salton, G. and McGill, M.J. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: Methods for organizing and accessing textual information range from electronic analogs of familiar paper-based techniques, like tables of contents, hierarchies, or indices [11], [16] to richer associative connections that are feasible only with computers, like full-content addressability <ref> [12] </ref>, hypertext [3], or information lenses [10]. While these tools may provide some retrieval advantages over existing paper and pencil technology, many benefits of electronic storage and retrieval are unrealized. <p> Keyword or content-based retrieval systems like this are, however, far from ideal many objects relevant to a users' query are missed, and many unrelated or irrelevant materials are retrieved [1], <ref> [12] </ref>. We believe that a principled attack on these problems depends on understanding human verbal behavior and its implications for human-computer interaction. <p> Not only are these methods expert-labor intensive, but they are often not very successful <ref> [12] </ref>. LATENT SEMANTIC INDEXING (LSI) The "latent semantic indexing" (LSI) approach we propose tries to overcome the problems of word-based access by treating the observed word to text-object association data as an unreliable estimate of the true, larger pool of words that could have been associated with each object.
Reference: 13. <author> Sparck Jones, K. </author> <title> Automatic keyword classification for information retrieval. </title> <address> Buttersworth, </address> <year> 1971. </year>
Reference-contexts: The idea of aiding information retrieval by discovering latent proximity structure has several lines of precedence in the information science literature. Hierarchical classification analyses have sometimes been used for term and document clustering <ref> [13] </ref>, [15]. Factor analysis has also been explored previously for automatic indexing and retrieval [2].
Reference: 14. <author> Streeter, L.A. and Lochbaum, K.E. </author> <title> An expert expert-locating system based on automatic representation of semantic structure. </title> <booktitle> In Proceedings of IEEE Conference on AI Applications. </booktitle> <address> San Diego, CA, </address> <month> March </month> <year> 1988. </year>
Reference-contexts: Bellcore Advisor Another test was conducted using an on-line service which provides information about Bellcore experts on topics of potential interest to other experts or clients <ref> [14] </ref>. The objects of interest in this case are people and not document abstracts as in our previous examples. For this database, 480 groups of people were characterized by descriptions of projects and work groups written for administrative purposes.
Reference: 15. <author> Voorhees, E. </author> <title> The cluster hypothesis revisited. </title> <booktitle> SIGIR, </booktitle> <year> 1985, </year> <pages> 188-196. </pages>
Reference-contexts: The idea of aiding information retrieval by discovering latent proximity structure has several lines of precedence in the information science literature. Hierarchical classification analyses have sometimes been used for term and document clustering [13], <ref> [15] </ref>. Factor analysis has also been explored previously for automatic indexing and retrieval [2].

References-found: 15

