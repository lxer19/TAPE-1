URL: ftp://ftp.cse.ogi.edu/pub/esr/reports/hpts-93.ps.gz
Refering-URL: http://www.cse.ogi.edu/~calton/publication.html
Root-URL: http://www.cse.ogi.edu
Email: Internet: calton@cse.ogi.edu 1  
Title: ACID Properties Need Fast Relief: Relaxing Consistency Using Epsilon Serializability  
Author: Calton Pu Shu-Wie F Chen 
Address: P.O. Box 91000 Portland, OR 97291-1000  500 W120th Street New York, NY 10027  
Affiliation: Dept. Computer Sci. and Eng. Oregon Grad. Inst. of Sci. Tech.  Department of Computer Science Columbia University  
Abstract: Epsilon Serializability (ESR) is a generalization of classic serializability (SR). ESR supports more concurrency and autonomy than SR by allowing a bounded amount of inconsistency in transactions that can tolerate it. ESR has three main advantages over previous "weak consistency" models: (1) ESR is a general framework, applicable to a wide range of application semantics; (2) ESR is upward-compatible, since it reduces to SR as * ! 0; and (3) ESR has number of efficient algorithms that support it. We briefly describe the concept of ESR, summarize the published work on ESR as well as ongoing research, outline an implementation on Transarc Encina, and sketch the current research efforts. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, M.J. Carey, and M. Livny. </author> <title> Concurrency control performance modeling: Alternatives and implications. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 12(4) </volume> <pages> 609-654, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: A group at Columbia is evaluating the performance of centralized divergence control algorithms (two-phase locking and optimistic validation) and divergence control algorithms using simulation. (The software is based on the CSIM package.) This model extends a traditional concurrency control evaluation <ref> [1] </ref>. In fact, the results from [1] are used for validation and as the baseline case when * = 0. The model allows a wide variation of system parameters such as the number of CPUs and disks, and TP parameters such as data access ratio, skew, length, and trans*-spec. <p> A group at Columbia is evaluating the performance of centralized divergence control algorithms (two-phase locking and optimistic validation) and divergence control algorithms using simulation. (The software is based on the CSIM package.) This model extends a traditional concurrency control evaluation <ref> [1] </ref>. In fact, the results from [1] are used for validation and as the baseline case when * = 0. The model allows a wide variation of system parameters such as the number of CPUs and disks, and TP parameters such as data access ratio, skew, length, and trans*-spec.
Reference: [2] <author> B.R. Badrinath and K. Ramamritham. </author> <title> Semantics-based concurrency control: Beyond commutativity. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 16, </volume> <month> September </month> <year> 1991. </year>
Reference-contexts: In ESR work, a bounded amount of inconsistency may be introduced into a transaction and we are interested in how this inconsistency is propagated within the transaction as well as in the database. This line of investigation [23, 4] benefits from previous work on operation semantics (e.g., <ref> [2] </ref>, cite UCSB work as a potential example). The results will help application designers in estimating the amount of inconsistency tolerated by the applications. Unlike the previous work on operation semantics, however, our algorithms do not depend on particular operation semantics.
Reference: [3] <author> D. Barbara and H. Garcia-Molina. </author> <title> The demarcation protocol: A technique for maintaining linear arithmetic constraints in distributed database systems. </title> <booktitle> In Proceedings of the International Conference in Extending Database Technology, </booktitle> <address> Vienna, </address> <month> March </month> <year> 1991. </year>
Reference-contexts: We have also applied it to design distributed divergence control algorithms [18]. The extension from centralized to distributed algorithms includes two additional steps. First, we need to distribute the trans*- spec from the global ET to sub-ETs running at each site. We use the demarcation protocol <ref> [3] </ref> to do this. The second step is the detection of global conflicts, an additional task due to serializability being a global property. We use the Superdatabase architecture [22] to do this. <p> control using simulation. * Performance evaluation of distributed divergence control (centralized divergence control plus demarcation protocol) using simulation. * Design of a general ESR system that includes both divergence control and consistency restora tion. * Combination of ESR to other optimization techniques such as Escrow Method [12], Demar cation Protocol <ref> [3] </ref>, and Transaction Chopping [24]
Reference: [4] <author> R. Barga and C. Pu. </author> <title> Handling inconsistency in scientific data management: An approach based on intervals. </title> <type> Technical Report OGI-CSE-93-005, </type> <institution> Department of Computer Science and Engineering, Oregon Graduate Institute, </institution> <year> 1993. </year>
Reference-contexts: In ESR work, a bounded amount of inconsistency may be introduced into a transaction and we are interested in how this inconsistency is propagated within the transaction as well as in the database. This line of investigation <ref> [23, 4] </ref> benefits from previous work on operation semantics (e.g., [2], cite UCSB work as a potential example). The results will help application designers in estimating the amount of inconsistency tolerated by the applications. <p> An epsilon-serializable history is a sequence of operations with an empty transitive closure of epsilon-transaction dependencies, which are the normal dependencies excluding the conflicts allowed under the trans*-spec. In the paper we also discuss the accumulation and transformation of inconsistency within ETs. 3.4 Applications A more recent work <ref> [4] </ref> at the Oregon Graduate Institute uses ESR techniques in scientific data management. Most of scientific data contain well-defined imprecision either due to the data source (e.g., from the physical world) or modeling limitations. This work applies methods from interval arithmetic to design an interval data model and algebra.
Reference: [5] <author> P.A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> first edition, </address> <year> 1987. </year>
Reference-contexts: In ACTA, an SR history is defined as a sequence of operations with an empty transitive closure of transaction dependencies. This is equivalent to the Serializability Theorem <ref> [5] </ref> that uses acyclic transaction dependency graphs. The definition of ESR in ACTA is an extension of the above. An epsilon-serializable history is a sequence of operations with an empty transitive closure of epsilon-transaction dependencies, which are the normal dependencies excluding the conflicts allowed under the trans*-spec.
Reference: [6] <author> S.W. Chen. </author> <title> Implementation and Design of a System Supporting Epsilon Serializability. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Columbia University, </institution> <note> Expected 1993. </note>
Reference-contexts: This implementation starts with the centralized two-phase locking divergence control, as part of an ongoing PhD dissertation work by Shu-Wie Chen <ref> [6] </ref>. The centralized divergence control 4 implementation changes two modules in Encina: the TP monitor is extended to accept trans*-spec and the lock manager is extended to accumulate potential inconsistency when R/W conflicts occur. We plan to extend this implementation to support distributed divergence control [18]. <p> Formal characterization of ESR using the ACTA framework. Current work: * Consistency restoration algorithms [7]. 9 * Implementation of centralized divergence control in Encina <ref> [6] </ref>. * Multiversion divergence control for time fuzziness. * Performance evaluation of divergence control using simulation. * Performance evaluation of distributed divergence control (centralized divergence control plus demarcation protocol) using simulation. * Design of a general ESR system that includes both divergence control and consistency restora tion. * Combination of ESR
Reference: [7] <author> P. Drew and C. Pu. </author> <title> Asynchronous consistency restoration under epsilon serializability. </title> <type> Technical Report OGI-CSE-93-004, </type> <institution> Department of Computer Science and Engineering, Oregon Graduate Institute, </institution> <year> 1993. </year> <note> Also available as tech. report HKUST-CS93-002, </note> <institution> Department of Computer Science, Hong Kong University of Science and Technology. </institution>
Reference-contexts: Consistency restoration algorithms are extensions of crash recovery algorithms. We have outlined some ideas for consistency restoration in an early paper [20] and described the problem and solutions in more detail in a recent paper <ref> [7] </ref>. Consistency restoration methods [7] can be divided into three families: undo/redo, compensation-based, and independent updates, in a decreasing ordering of both cost and applicability range. Undo/redo algorithms are similar to classic recovery algorithms, can be applied to most situations, and are the most expensive. <p> Consistency restoration algorithms are extensions of crash recovery algorithms. We have outlined some ideas for consistency restoration in an early paper [20] and described the problem and solutions in more detail in a recent paper <ref> [7] </ref>. Consistency restoration methods [7] can be divided into three families: undo/redo, compensation-based, and independent updates, in a decreasing ordering of both cost and applicability range. Undo/redo algorithms are similar to classic recovery algorithms, can be applied to most situations, and are the most expensive. <p> On the one hand, the figure shows the substantial similarity between SR and ESR systems. On the other hand, the figure also shows the differences between SR, rESR (with divergence control only), and gESR systems (which include consistency restoration <ref> [7] </ref>). The main difference between an rESR system and an SR system is the divergence control (DC) component. The DC component makes scheduling decisions based on ESR conflicts which can be defined with an SR-conflict relation and a set of rESR-safeness pre-conditions. <p> Formal characterization of ESR using the ACTA framework. Current work: * Consistency restoration algorithms <ref> [7] </ref>. 9 * Implementation of centralized divergence control in Encina [6]. * Multiversion divergence control for time fuzziness. * Performance evaluation of divergence control using simulation. * Performance evaluation of distributed divergence control (centralized divergence control plus demarcation protocol) using simulation. * Design of a general ESR system that includes both
Reference: [8] <author> H. Garcia-Molina and K. Salem. Sagas. </author> <booktitle> In Proceedings of ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 249-259, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: For new applications such as CAD/CAM, scientific data management, and long transactions, the ACID properties [10] of SR can really get in the way. For example, long transactions usually want to relax atomicity, since atomically aborting the entire transaction would mean significant loss of work. Similarly, in Sagas <ref> [8] </ref> compensation transactions were used to alleviate the durability problems when transactions commit, but later we wish to undo their effects. Applications that use level 2 consistency show that consistency is not always required.
Reference: [9] <author> Jim Gray and Andreas Reuter. </author> <title> Transaction Processing: Concepts and Techniques. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Guaranteeing SR requires preventing these anomalies from occurring <ref> [9] </ref>. ESR, however, explicitly allows these three types of concurrency anomalies, though it limits the extent and the effect of these inconsistencies through trans*-specs. We call a transaction that allows some non-SR inconsistent access an epsilon transaction (ET). An ET is a classic atomic transaction with the addition of trans*-specs. <p> Therefore, pre-condition testing only needs to be performed when locks are requested. Other possibilities and the trade-offs involved are described in [23]. In the remainder of this section, the classic TP system design and implementation presented in Gray and Reuter's transaction processing book <ref> [9] </ref> is used as a framework. Based on this framework we describe the modifications that must be made to an SR system to support rESR. In Gray and Reuter's system, transactions are initiated by a Begin Work call and terminated by either a Commit Work or a Abort Work call. <p> comparison with the original Encina SRjack and SRjill programs. 4.4 Evaluation of Implementation The implementation of the rESR system shows that: * From the functionality point of view, ESR is feasible and practical in a production TP system. * From the system point of view, the generic design of Gray <ref> [9] </ref> is effective and the modular structure of Encina extensible.
Reference: [10] <author> T. Haerder and A. Reuter. </author> <title> Principles of transaction-oriented database recovery. </title> <journal> ACM Computing Surveys, </journal> <volume> 15(4) </volume> <pages> 287-317, </pages> <month> December </month> <year> 1983. </year>
Reference-contexts: Many optimization techniques have been used to relax SR, for example, Escrow Method [12] and the many proposals for semantics-based concurrency control. For new applications such as CAD/CAM, scientific data management, and long transactions, the ACID properties <ref> [10] </ref> of SR can really get in the way. For example, long transactions usually want to relax atomicity, since atomically aborting the entire transaction would mean significant loss of work.
Reference: [11] <author> M. Kamath and K. Ramamritham. </author> <title> Performance characteristics of epsilon serializability with hierarchical inconsistency bounds. </title> <booktitle> In Proceedings of the Ninth International Conference on Data Engineering, </booktitle> <address> Vienna, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: Compensation-based algorithms depend on nice properties of compensations (such as commutativity), but are much cheaper. Independent updates are applicable only when an independent source of consistent data exists, and do not require any record keeping at the destination sites. 3.2 Algorithm Evaluation Kamath and Ramamrithan <ref> [11] </ref> have refined the specification of inconsistency into a hierarchy. Besides designing a timestamp-based divergence control algorithm to support such hierarchically specified inconsistency bounds, they also evaluated the performance of such an algorithm in a prototype implementation running on DECstations.
Reference: [12] <author> P. E. O'Neil. </author> <title> The escrow transactional method. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 11(4) </volume> <pages> 405-430, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: 1 Limitations of Serializability Serializability (SR) has been recognized as being too restrictive for even classic transaction processing. It is well known that many DB2 installations use level 2 consistency instead of level 3 (SR). Many optimization techniques have been used to relax SR, for example, Escrow Method <ref> [12] </ref> and the many proposals for semantics-based concurrency control. For new applications such as CAD/CAM, scientific data management, and long transactions, the ACID properties [10] of SR can really get in the way. <p> Performance evaluation of divergence control using simulation. * Performance evaluation of distributed divergence control (centralized divergence control plus demarcation protocol) using simulation. * Design of a general ESR system that includes both divergence control and consistency restora tion. * Combination of ESR to other optimization techniques such as Escrow Method <ref> [12] </ref>, Demar cation Protocol [3], and Transaction Chopping [24]
Reference: [13] <author> C. Pu. </author> <title> Generalized transaction processing with epsilon-serializability. </title> <booktitle> In Proceedings of Fourth International Workshop on High Performance Transaction Systems, Asilomar, </booktitle> <address> California, </address> <month> September </month> <year> 1991. </year> <month> 10 </month>
Reference-contexts: Fortunately, many of the real world database state spaces fulfill this requirement. For example, integers and real numbers in banking, airline, and scientific data are cartesian spaces that have a natural definition of distance function (the difference) and the regular geometry of a metric space <ref> [13] </ref>. Efficient algorithms that support ESR use these properties to preserve the inconsistency bounds. The management of inconsistency in database state spaces with irregular geometries remains an interesting area of research. Another dimension in the ESR research is the algebraic properties of transaction operators.
Reference: [14] <author> C. Pu. </author> <title> Asynchronous transaction execution with epsilon-serializability. </title> <booktitle> In Proceedings of 1992 Workshop on Heterogeneous Databases and Semantic Interoperability, </booktitle> <address> Boulder/CO, </address> <month> February </month> <year> 1992. </year>
Reference: [15] <author> C. Pu. </author> <title> Relaxing the limitations of serializable transactions in distributed systems. </title> <journal> Operating Systems Review, </journal> <volume> 27(2) </volume> <pages> 66-71, </pages> <month> April </month> <year> 1993. </year> <booktitle> Also appeared in the Proceedings of Fifth ACM SIGOPS European Workshop, 1992, </booktitle> <address> Le Mont Saint-Michel, France. </address>
Reference: [16] <author> C. Pu and S.W. Chen. </author> <title> Implementation of a prototype superdatabase. </title> <booktitle> In Proceedings of the Workshop on Experimental Distributed Systems, </booktitle> <address> Huntsville, Alabama, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: We plan to extend this implementation to support distributed divergence control [18]. The main components of distributed divergence control are: the centralized divergence control, an implementation of demarcation protocol done at Columbia, and modified Superdatabase global serializability testing routines <ref> [16] </ref>. 4.1 Generic Design Outline The concurrency problem in database systems is characterized by three anomalies- lost update, dirty read, and un-repeatable read. Guaranteeing SR requires preventing these anomalies from occurring [9].
Reference: [17] <author> C. Pu, D. Florissi, P. Soares, P. S. Yu, and K.L. Wu. </author> <title> Performance comparison of sender-active and receiver-active mutual data serving. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 5(4) </volume> <pages> 239-256, </pages> <month> June </month> <year> 1993. </year> <title> Special issue on High Performance Distributed Processing. </title>
Reference: [18] <author> C. Pu, W.W. Hseush, G.E. Kaiser, P. S. Yu, and K.L. Wu. </author> <title> Distributed divergence control algorithms for epsilon serializability. </title> <booktitle> In Proceedings of the Thirteenth International Conference on Distributed Computing Systems, </booktitle> <address> Pittsburgh, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Otherwise, the ET is blocked (in locking) or aborted (in serialization graph testing). This methodology [27] generates centralized divergence control algorithms directly. We have also applied it to design distributed divergence control algorithms <ref> [18] </ref>. The extension from centralized to distributed algorithms includes two additional steps. First, we need to distribute the trans*- spec from the global ET to sub-ETs running at each site. We use the demarcation protocol [3] to do this. <p> The centralized divergence control 4 implementation changes two modules in Encina: the TP monitor is extended to accept trans*-spec and the lock manager is extended to accumulate potential inconsistency when R/W conflicts occur. We plan to extend this implementation to support distributed divergence control <ref> [18] </ref>.
Reference: [19] <author> C. Pu and A. Leff. </author> <title> Replica control in distributed systems: An asynchronous approach. </title> <booktitle> In Proceedings of the 1991 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 377-386, </pages> <address> Denver, </address> <month> May </month> <year> 1991. </year>
Reference: [20] <author> C. Pu and A. Leff. </author> <title> Autonomous transaction execution with epsilon-serializability. </title> <booktitle> In Proceedings of 1992 RIDE Workshop on Transaction and Query Processing, Phoenix, </booktitle> <month> February </month> <year> 1992. </year> <journal> IEEE/Computer Society. </journal>
Reference-contexts: The main problem here is that the database state may become increasingly inconsistent due to the execution of G ET s. Consistency restoration algorithms are extensions of crash recovery algorithms. We have outlined some ideas for consistency restoration in an early paper <ref> [20] </ref> and described the problem and solutions in more detail in a recent paper [7]. Consistency restoration methods [7] can be divided into three families: undo/redo, compensation-based, and independent updates, in a decreasing ordering of both cost and applicability range.
Reference: [21] <author> C. Pu, A. Leff, and S.W. Chen. </author> <title> Heterogeneous and autonomous transaction processing. </title> <journal> IEEE Computer, </journal> <volume> 24(12) </volume> <pages> 64-72, </pages> <month> December </month> <year> 1991. </year> <note> Special issue on heterogeneous databases. </note>
Reference: [22] <author> Calton Pu. </author> <title> Superdatabases for composition of heterogeneous databases. </title> <editor> In Amar Gupta, editor, </editor> <booktitle> Integration of Information Systems: Bridging Heterogeneous Databases, </booktitle> <pages> pages 150-157. </pages> <publisher> IEEE Press, </publisher> <year> 1989. </year> <title> Also in IEEE Computer Society Tutorial, Multidatabase Systems: An Advanced Solution for Global Information Sharing. </title> <booktitle> The paper originally appeared in the Proceedings of Fourth International Conference on Data Engineering, 1988, </booktitle> <address> Los Angeles. </address>
Reference-contexts: We use the demarcation protocol [3] to do this. The second step is the detection of global conflicts, an additional task due to serializability being a global property. We use the Superdatabase architecture <ref> [22] </ref> to do this. The result is a family of distributed divergence control algorithms composed of three components: demarcation protocol, local divergence control, and global conflict detection.
Reference: [23] <author> K. Ramamrithan and C. Pu. </author> <title> A formal characterization of epsilon serializability. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <note> to appear 1993. </note>
Reference-contexts: In ESR work, a bounded amount of inconsistency may be introduced into a transaction and we are interested in how this inconsistency is propagated within the transaction as well as in the database. This line of investigation <ref> [23, 4] </ref> benefits from previous work on operation semantics (e.g., [2], cite UCSB work as a potential example). The results will help application designers in estimating the amount of inconsistency tolerated by the applications. <p> Preliminary data show that data contention is a significant bottleneck for high performance systems and also a limited trans*-spec can alleviate this bottleneck. 3.3 Formalization A formal characterization of ESR <ref> [23] </ref> has been done using the ACTA framework. In ACTA, an SR history is defined as a sequence of operations with an empty transitive closure of transaction dependencies. This is equivalent to the Serializability Theorem [5] that uses acyclic transaction dependency graphs. <p> In an SR system, the concurrency control (CC) mechanism schedules transaction operations based on the notion of SR conflicts. The analogous component in an ESR system is divergence control (DC) [27] which schedules ET operations based on the notion of ESR conflicts <ref> [23] </ref>. ESR conflicts are a subset of SR conflicts, occurring only when there is an SR conflict and a violation of trans*-spec at the same time. An ET is, in effect, allowed to arbitrarily interleave its execution with other ETs until it exceeds its trans*-spec. <p> In lock-based systems, SR conflicts are detected at lock request time. Therefore, pre-condition testing only needs to be performed when locks are requested. Other possibilities and the trade-offs involved are described in <ref> [23] </ref>. In the remainder of this section, the classic TP system design and implementation presented in Gray and Reuter's transaction processing book [9] is used as a framework. Based on this framework we describe the modifications that must be made to an SR system to support rESR.
Reference: [24] <author> D. Shasha, E. Simon, and P. Valduriez. </author> <title> Simple rational guidance for chopping up transactions. </title> <booktitle> In Proceedings of 1992 SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 298-307, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Performance evaluation of distributed divergence control (centralized divergence control plus demarcation protocol) using simulation. * Design of a general ESR system that includes both divergence control and consistency restora tion. * Combination of ESR to other optimization techniques such as Escrow Method [12], Demar cation Protocol [3], and Transaction Chopping <ref> [24] </ref>
Reference: [25] <author> S.H. Son and S. Koloumbis. </author> <title> Replication control for distributed real-time database systems. </title> <booktitle> In Proceedings of the Twelfth International Conference on Distributed Computing Systems, </booktitle> <pages> pages 144-151, </pages> <address> Yokohama, Japan, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: This work applies methods from interval arithmetic to design an interval data model and algebra. Operators on imprecise data give bounds on the result imprecision. ESR algorithms are then used to constrain the imprecision propagation. Son and Koloumbis <ref> [25, 26] </ref> have successfully used ESR in their approach to replication and concurrency control for real-time databases. Their token-based algorithm combines real-time constraints for resource scheduling with relaxation similar to divergence control methods based on ESR.
Reference: [26] <author> S.H. Son and S. Koloumbis. </author> <title> A token-based synchronization scheme using epsilon-serializability and its performance for real-time distributed databases. </title> <booktitle> In Proceedings of the Third International Symposium on Database Systems for Advanced Applications (DASFAA '93), </booktitle> <address> Taejon, Korea, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: This work applies methods from interval arithmetic to design an interval data model and algebra. Operators on imprecise data give bounds on the result imprecision. ESR algorithms are then used to constrain the imprecision propagation. Son and Koloumbis <ref> [25, 26] </ref> have successfully used ESR in their approach to replication and concurrency control for real-time databases. Their token-based algorithm combines real-time constraints for resource scheduling with relaxation similar to divergence control methods based on ESR.
Reference: [27] <author> K.L. Wu, P. S. Yu, and C. Pu. </author> <title> Divergence control for epsilon-serializability. </title> <booktitle> In Proceedings of Eighth International Conference on Data Engineering, </booktitle> <pages> pages 506-515, </pages> <address> Phoenix, </address> <month> February </month> <year> 1992. </year> <journal> IEEE/Computer Society. </journal> <volume> 11 </volume>
Reference-contexts: Algorithms that bring the database back to a consistent state are called consistency restoration. 2 3 Published and Ongoing ESR Work 3.1 Algorithm Design For the restricted model of ESR, consisting only of Q ET and U ET , Wu et al <ref> [27] </ref> have described a methodology to extend classic conflict-based concurrency control methods such as two-phase locking into a divergence control algorithm that guarantees ESR. The main idea of the methodology is that in every concurrency control algorithm, there is a place where all the potentially non-SR conflicts are detected. <p> If the accumulated inconsistency is less or equal than the amount specified by trans*-spec, then the conflict is allowed. Otherwise, the ET is blocked (in locking) or aborted (in serialization graph testing). This methodology <ref> [27] </ref> generates centralized divergence control algorithms directly. We have also applied it to design distributed divergence control algorithms [18]. The extension from centralized to distributed algorithms includes two additional steps. First, we need to distribute the trans*- spec from the global ET to sub-ETs running at each site. <p> Their results show consistent and significant increases in TP system concurrency (and decreases in abort rate) when the epsilon bound is increased. This work strengthened the preliminary evaluation done on the original divergence control 3 algorithms <ref> [27] </ref>. A group at Columbia is evaluating the performance of centralized divergence control algorithms (two-phase locking and optimistic validation) and divergence control algorithms using simulation. (The software is based on the CSIM package.) This model extends a traditional concurrency control evaluation [1]. <p> An ET is a classic atomic transaction with the addition of trans*-specs. In an SR system, the concurrency control (CC) mechanism schedules transaction operations based on the notion of SR conflicts. The analogous component in an ESR system is divergence control (DC) <ref> [27] </ref> which schedules ET operations based on the notion of ESR conflicts [23]. ESR conflicts are a subset of SR conflicts, occurring only when there is an SR conflict and a violation of trans*-spec at the same time.
References-found: 27

