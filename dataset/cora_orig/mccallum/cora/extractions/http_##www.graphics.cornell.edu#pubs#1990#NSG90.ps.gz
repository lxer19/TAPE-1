URL: http://www.graphics.cornell.edu/pubs/1990/NSG90.ps.gz
Refering-URL: http://www.graphics.cornell.edu/pubs/1990/NSG90.html
Root-URL: 
Title: An Efficient Method for Volume Rendering using Perspective Projection  
Author: Kevin L. Novins, Fran~cois X. Sillion and Donald P. Greenberg 
Keyword: CR Categories and Subject Descriptors: I.3.0 [Computer Graphics]: General; I.3.3 [Computer Graphics]: Picture/Image Genera tion; J.3 [Computer Applications]: Life and Medical Sciences Additional Keywords and Phrases: volume rendering, scientific visualization, ray tracing, perspective projection, depth of field  
Address: Ithaca, NY 14850.  
Affiliation: Program of Computer Graphics Cornell University,  
Abstract: Use of perspective projection adds important perceptual cues for image comprehension. However, it has not been widely usedin volume rendering because of the lack of efficient computational algorithms and concern over the nonuniform sampling rate imposed by perspective ray divergence. This paper introduces two new techniques to help make perspective projection more feasible in rendering volume data. First, a method is presented for efficient slice-by-slice processing of volume data, allowing high resolution data sets by eliminating typical memory constraints. Second, an adaptive "ray splitting" approach is described which ensures that the entire volume is sampled with user-specified limits. Additionally, we present results using distributed ray tracing to achieve depth of field effects. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Robert L. Cook, Thomas Porter, and Loren Carpenter. </author> <title> Distributed ray tracing. </title> <journal> Computer Graphics, </journal> <volume> 18(3) </volume> <pages> 137-145, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: The blurred remnants of distant objects help to maintain global perspective. If we use a perspective projection, a minor modification to the ray tracer allows the computation of images with depth of field <ref> [7, 1] </ref>. Rays are distributed over a finite aperture to blur the image outside the focal region. Because this effectively involves the jittering of the eyepoint, the slice processing order must be modified to take into account the minimum and maximum z extents of the eyepoint.
Reference: [2] <author> Robert A. Drebin, Loren Carpenter, and Pat Hanrahan. </author> <title> Volume rendering. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 65-74, </pages> <month> August </month> <year> 1988. </year> <title> extended eyepoint (lens surface) Z 22 Processing order order must be modified to account for the shifting ray origins. Slabs between the minimum and maximum z extents of the lens must be processed twice. </title>
Reference-contexts: In the orthographic view, lack of perspective depth cueing causes size and orientation ambiguity. 2 Previous Work A variety of techniques for volume rendering (rendering three dimensional grids of volume densities or scalar fields without the use of intermediate representations) have been introduced recently <ref> [4, 5, 2, 12] </ref>. The volume rendering engine described here follows most closely after the image space mapping technique of [5]. Voxel opacity and color arrays are computed independently via classifications and shading operations. <p> If the volume data has n voxels on a side, this approach requires O (n 3 ) storage space, which quickly outstrips RAM capacity for high resolution arrays. Random access to large virtual memory spaces causes an unacceptable amount of disk paging. In <ref> [2] </ref> and [3], a perspective view is realized by casting parallel rays into an appropriately transformed copy of the volume grid, however the transformation step is quite expensive. The cell-by-cell processing method of [10] assumes that the data can be accessed slice-at-a-time along any of the three coordinate axes.
Reference: [3] <author> Karl Heinz Hohne, Michael Bomans, Andreas Pommert, Martin Riemer, Carsten Schiers, Ulf Tiede, and Gunnar Wiebecke. </author> <title> 3D visualization of tomographic data using the generalized voxel model. </title> <booktitle> In Proceedings of the 1989 Chapel Hill Workshop on Volume Visualization, </booktitle> <pages> pages 51-57, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: If the volume data has n voxels on a side, this approach requires O (n 3 ) storage space, which quickly outstrips RAM capacity for high resolution arrays. Random access to large virtual memory spaces causes an unacceptable amount of disk paging. In [2] and <ref> [3] </ref>, a perspective view is realized by casting parallel rays into an appropriately transformed copy of the volume grid, however the transformation step is quite expensive. The cell-by-cell processing method of [10] assumes that the data can be accessed slice-at-a-time along any of the three coordinate axes.
Reference: [4] <author> James T. Kajiya and Brian P. Von Herzen. </author> <title> Ray tracing volume densities. </title> <journal> Computer Graphics, </journal> <volume> 18(3) </volume> <pages> 165-173, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: In the orthographic view, lack of perspective depth cueing causes size and orientation ambiguity. 2 Previous Work A variety of techniques for volume rendering (rendering three dimensional grids of volume densities or scalar fields without the use of intermediate representations) have been introduced recently <ref> [4, 5, 2, 12] </ref>. The volume rendering engine described here follows most closely after the image space mapping technique of [5]. Voxel opacity and color arrays are computed independently via classifications and shading operations.
Reference: [5] <author> Marc Levoy. </author> <title> Display of surfaces from volume data. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 8(3) </volume> <pages> 29-37, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: In the orthographic view, lack of perspective depth cueing causes size and orientation ambiguity. 2 Previous Work A variety of techniques for volume rendering (rendering three dimensional grids of volume densities or scalar fields without the use of intermediate representations) have been introduced recently <ref> [4, 5, 2, 12] </ref>. The volume rendering engine described here follows most closely after the image space mapping technique of [5]. Voxel opacity and color arrays are computed independently via classifications and shading operations. <p> The volume rendering engine described here follows most closely after the image space mapping technique of <ref> [5] </ref>. Voxel opacity and color arrays are computed independently via classifications and shading operations. Rays are then case into these arrays and opacities and colors are computed for equally spaced ample points along the ray using trilinear interpolation. <p> Later, the ray fragments are composited to yield a final pixel value [Figure 5]. In the current implementation, all ray fragments are averaged uniformly during composition, however any filter function could be used in its place. As in <ref> [5] </ref>, the sampling rate along the ray axis is maintained by taking samples at regular intervals along the ray. The sampling rate in the remaining two dimensions is maintained by considering the projected area of the screen pixel, which grows with distance from the eyepoint.
Reference: [6] <author> Marc Levoy. </author> <title> Efficient ray tracing of volume data. </title> <journal> Transactions on Graphics, </journal> <volume> 9(3) </volume> <pages> 245-261, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Unfortunately, this approach wastes computation by oversampling the parts of the dataset close to the eyepoint. An alternative approach to maintaining adequate sampling rates with perspective projection would be to use multiresolution filter-ings of the data as in the 3D-mipmap algorithms <ref> [13, 6] </ref>.
Reference: [7] <author> M. Potmesil and I. Chakravarty. </author> <title> Synthetic image generation with a lens and aperture camera model. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 1(2) </volume> <pages> 85-108, </pages> <month> April </month> <year> 1982. </year>
Reference-contexts: The blurred remnants of distant objects help to maintain global perspective. If we use a perspective projection, a minor modification to the ray tracer allows the computation of images with depth of field <ref> [7, 1] </ref>. Rays are distributed over a finite aperture to blur the image outside the focal region. Because this effectively involves the jittering of the eyepoint, the slice processing order must be modified to take into account the minimum and maximum z extents of the eyepoint.
Reference: [8] <author> Paolo Sabella. </author> <title> A rendering algorithm for visualizing 3D scalar fields. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 51-57, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Despite an emphasis on the use of orthographic projection, sev-eral researchers have explored the use of perspective in volume rendering. However, to date none have described efficient, single pass slice-by-slice processing techniques. Most ray casting implementations have assumed random access to the volume dataset <ref> [9, 10, 8, 11] </ref>. If the volume data has n voxels on a side, this approach requires O (n 3 ) storage space, which quickly outstrips RAM capacity for high resolution arrays. Random access to large virtual memory spaces causes an unacceptable amount of disk paging.
Reference: [9] <author> Daniel S. Schlusselberg, Wade K. Smith, and Donald J. Wood-ward. </author> <title> Three-dimensional display of medical image volumes. </title> <booktitle> In Proccedings of NCGA '86, </booktitle> <pages> pages 114-123. </pages> <institution> National Computer Graphics Association, </institution> <month> March </month> <year> 1986. </year>
Reference-contexts: Despite an emphasis on the use of orthographic projection, sev-eral researchers have explored the use of perspective in volume rendering. However, to date none have described efficient, single pass slice-by-slice processing techniques. Most ray casting implementations have assumed random access to the volume dataset <ref> [9, 10, 8, 11] </ref>. If the volume data has n voxels on a side, this approach requires O (n 3 ) storage space, which quickly outstrips RAM capacity for high resolution arrays. Random access to large virtual memory spaces causes an unacceptable amount of disk paging.
Reference: [10] <author> Craig Upson and Michael Keeler. V-buffer: </author> <title> Visible volume rendering. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 59-64, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Despite an emphasis on the use of orthographic projection, sev-eral researchers have explored the use of perspective in volume rendering. However, to date none have described efficient, single pass slice-by-slice processing techniques. Most ray casting implementations have assumed random access to the volume dataset <ref> [9, 10, 8, 11] </ref>. If the volume data has n voxels on a side, this approach requires O (n 3 ) storage space, which quickly outstrips RAM capacity for high resolution arrays. Random access to large virtual memory spaces causes an unacceptable amount of disk paging. <p> Random access to large virtual memory spaces causes an unacceptable amount of disk paging. In [2] and [3], a perspective view is realized by casting parallel rays into an appropriately transformed copy of the volume grid, however the transformation step is quite expensive. The cell-by-cell processing method of <ref> [10] </ref> assumes that the data can be accessed slice-at-a-time along any of the three coordinate axes.
Reference: [11] <author> Robert E. Webber. </author> <title> Ray tracing voxel data via biquadratic local surface interpolation. </title> <journal> The Visual Computer, </journal> <volume> 6(1) </volume> <pages> 8-15, </pages> <year> 1990. </year>
Reference-contexts: Despite an emphasis on the use of orthographic projection, sev-eral researchers have explored the use of perspective in volume rendering. However, to date none have described efficient, single pass slice-by-slice processing techniques. Most ray casting implementations have assumed random access to the volume dataset <ref> [9, 10, 8, 11] </ref>. If the volume data has n voxels on a side, this approach requires O (n 3 ) storage space, which quickly outstrips RAM capacity for high resolution arrays. Random access to large virtual memory spaces causes an unacceptable amount of disk paging.
Reference: [12] <author> Lee Westover. </author> <title> Interactive volume rendering. </title> <booktitle> In Proceedings of the Chapel Hill Workshop on Volume Visualization, </booktitle> <month> May </month> <year> 1989. </year>
Reference-contexts: In the orthographic view, lack of perspective depth cueing causes size and orientation ambiguity. 2 Previous Work A variety of techniques for volume rendering (rendering three dimensional grids of volume densities or scalar fields without the use of intermediate representations) have been introduced recently <ref> [4, 5, 2, 12] </ref>. The volume rendering engine described here follows most closely after the image space mapping technique of [5]. Voxel opacity and color arrays are computed independently via classifications and shading operations.

References-found: 12

