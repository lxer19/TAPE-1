URL: ftp://mancos.cs.utah.edu/papers/perobert_thesis.ps.gz
Refering-URL: ftp://mancos.cs.utah.edu/papers/perobert_abstract.html
Root-URL: 
Title: IMPLEMENTATION AND EVALUATION OF DATA BREAKPOINT SCHEMES IN AN INTERACTIVE DEBUGGER  
Author: by Paul E. Roberts 
Degree: A thesis submitted to the faculty of The University of Utah in partial fulfillment of the requirements for the degree of Master of Science  
Date: December 1996  
Affiliation: Department of Computer Science The University of Utah  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Bert Beander. </author> <title> Vax debug: an interactive, symbolic, multilingual debugger. </title> <booktitle> In Proceedings of the SIGSOFT/SIGPLAN Software Engineering Symposium on High-Level Debugging, </booktitle> <pages> pages 173-179, </pages> <month> August </month> <year> 1983. </year> <note> Appeared as SIGPLAN Notices 18(8). </note>
Reference-contexts: However if p ! q were to be watched while p points into a, then both pages would be protected and all writes to p, result, i and a would cause a page fault. VAX DEBUG uses the virtual memory system to do watchpoints <ref> [1] </ref> but performance information is not available for this implementation. I have been told of a 11 i result heap k debugger written for the Apple Macintosh that uses its MMU to do watchpoints [6], but have been unable to confirm this.
Reference: [2] <author> Robert Bedichek. </author> <title> A multi-space operating system debugger. </title> <institution> University of Washington, </institution> <note> Unpublished. </note>
Reference-contexts: of California, Berkeley, a company called Pure Software Inc. has also done extensive research into the uses of code patching including its use for detection of memory leaks and access errors. [14]. 9 Still others have modified GDB to provide kernel debugging support for Mach micro-kernels on the Motorola 88100/88200 <ref> [2] </ref>. Part of this work included a dynamic code generator to do code patching for conditional control breakpoints. Dynamic code patching improved the performance of some conditional control breakpoints by a factor of 1000. However, this implementation works only for debugging the kernel and not user programs.
Reference: [3] <author> Robert Bedichek. </author> <title> Some efficient architecture simulation techniques. </title> <booktitle> In Proceedings of the 1990 Winter Usenix Conference, </booktitle> <pages> pages 53-63, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: For example, interpreted ANSI C runs approximately 200 times slower than compiled code [16]. Likewise, machine simulators tend to run 5 to 50 times slower than native hardware <ref> [3, 7] </ref>. CHAPTER 3 IMPLEMENTATION DETAILS Many of the techniques proposed to provide efficient watchpoints rely on a service, either abstract or real, that informs the debugger when a particular address in memory is written.
Reference: [4] <author> J. Brown and R.Klamann. </author> <title> The application of code instrumentation technology in the Los Alamos Debugger. </title> <booktitle> In Proceedings of the Supercomputer Debugging Workshop, </booktitle> <month> October </month> <year> 1992. </year>
Reference-contexts: Also, watchpoints are a bit more difficult to implement than conditional breakpoints because one needs a way to identify the write instructions dynamically. Finally, the Los Alamos debugger ldb uses code patching to do fast conditional control breakpoints <ref> [4] </ref> 2.1.3 Checkpointing Another way to reduce the number of checks made is checkpointing [17]. This scheme is interesting, but has a major flaw in addition to the normal difficulties of doing checkpointing correctly [26] so I did not implement it.
Reference: [5] <author> Steve Burling. </author> <type> Personal communication. </type> <institution> MTS developer at University of Michigan. </institution>
Reference-contexts: I could only find one Unix debugger, the dynix/ptx version of USL's debug, that uses monitor registers, but it resorts to single stepping when it runs out of monitor registers [13, 23]. Another debugger, PER, which runs on the MTS operating system, also uses monitor registers <ref> [5] </ref>. GDB's developers plan to modify GDB to use them on those architectures that have them [22]. 2.1.9 Other Solutions Implementing watchpoints in interpreted code development environments is not difficult. The interpreter can be modified to do something special when it encounters an instruction that writes memory.
Reference: [6] <author> Peter Chang. </author> <type> Personal communication. </type> <institution> Stanford University. </institution>
Reference-contexts: VAX DEBUG uses the virtual memory system to do watchpoints [1] but performance information is not available for this implementation. I have been told of a 11 i result heap k debugger written for the Apple Macintosh that uses its MMU to do watchpoints <ref> [6] </ref>, but have been unable to confirm this. I am unaware of any other implementations that use the virtual memory system to do watchpoints.
Reference: [7] <author> Robert F. Cmelik and David Keppel. Shade: </author> <title> A fast instruction-set simulator for execution profiling. </title> <note> Technical Report (in preparation), </note> <institution> Sun Microsystems Laboratories and University of Washington, </institution> <year> 1993. </year>
Reference-contexts: For example, interpreted ANSI C runs approximately 200 times slower than compiled code [16]. Likewise, machine simulators tend to run 5 to 50 times slower than native hardware <ref> [3, 7] </ref>. CHAPTER 3 IMPLEMENTATION DETAILS Many of the techniques proposed to provide efficient watchpoints rely on a service, either abstract or real, that informs the debugger when a particular address in memory is written.
Reference: [8] <author> Hewlett Packard Company. </author> <title> Precision Architecture and Instruction Set Manual. Manual Part Number 09740-90014, </title> <booktitle> third edition, </booktitle> <month> April </month> <year> 1989. </year>
Reference-contexts: On the HP PA, the virtual memory scheme can be improved <ref> [8] </ref> because its virtual memory system has a special bit called the B-bit in its TLB.
Reference: [9] <author> Hewlett Packard Company. </author> <title> HP-UX Reference Guide|Vol 2: Section 2. HP Part Number B2355-90033, </title> <address> E0892 edition, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Surprisingly, HP debuggers do not take advantage of the break bit feature of the PA [10]. In fact, the HPUX operating system does not even provide the mechanism to set the bit <ref> [9] </ref>.
Reference: [10] <author> Hewlett Packard Company. </author> <title> HP-UX Symbolic Debugger User's Guide. HP Part Number B2355-90044, </title> <booktitle> first edition, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: Thus the major benefit of watchpoints is eliminated. Watchpoints in GDB are slow because they are implemented using single stepping. GDB is not the only debugger to use single stepping. Most UNIX debuggers and many others use this approach, for example SUN's dbx [19], HP's xdb <ref> [10] </ref>, and Hitachi's sdb [20]. Single stepping consists of stopping the program after each instruction, returning control to the debugger, and evaluating the expressions associated with any watchpoints to see if they have changed. If not, the debugger returns control to the program for one more instruction, and so on. <p> The Connection Machine CM-5 has even better debugging support, providing similar break bits associated with each word (32 bytes) of memory [21]. Surprisingly, HP debuggers do not take advantage of the break bit feature of the PA <ref> [10] </ref>. In fact, the HPUX operating system does not even provide the mechanism to set the bit [9].
Reference: [11] <author> Max Copperman and Jeff Thomas. </author> <title> Poor man's watchpoints. </title> <institution> Xerox Palo Alto Research Center and Kubota Pacific Computer, Inc, </institution> <note> Unpublished. </note>
Reference-contexts: This thesis shows that dramatic improvements in the performance of watchpoints can be made in a variety of ways. This thesis also compares these solutions for efficient watchpoints with each other. Having an efficient implementation of watchpoints would help programmers immensely in debugging programs <ref> [24, 17, 11] </ref>. Without watchpoints it is difficult to find problems with pointer uses that result in inadvertent modification of unrelated data. <p> As a result of the code patching research being done at the University of Cali-fornia, Berkeley, code patching is beginning to be implemented in some debugging environments to facilitate watchpoints. For example, Kubota Pacific Computer, Inc. has modified their debugger dbg <ref> [11] </ref>.
Reference: [12] <author> Intel Corporation. </author> <title> Intel 80386 Programmer's Reference Manual. </title> <address> Santa Clara, California, </address> <year> 1986. </year>
Reference-contexts: However, the designer of this system has told me that he has not yet implemented it, nor does he have time to do it in the immediate future. 2.1.8 Monitor Registers Some processors, including the Intel i386 and the MIPS R4000 <ref> [12, 15] </ref>, have special registers dedicated to monitoring writes. These registers hold address ranges for the memory they are monitoring and, when a write occurs to a monitored region, a trap occurs. Although this hardware solution is fast, it is limited by the number of registers dedicated to monitoring writes.
Reference: [13] <institution> Sequent Computer Corporation. </institution> <note> Dynix/ptx Unix System V.4 debug manual page. 85 </note>
Reference-contexts: I could only find one Unix debugger, the dynix/ptx version of USL's debug, that uses monitor registers, but it resorts to single stepping when it runs out of monitor registers <ref> [13, 23] </ref>. Another debugger, PER, which runs on the MTS operating system, also uses monitor registers [5]. GDB's developers plan to modify GDB to use them on those architectures that have them [22]. 2.1.9 Other Solutions Implementing watchpoints in interpreted code development environments is not difficult.
Reference: [14] <author> Reed Hastings and Bob Joyce. Purify: </author> <title> Fast detection of memory leaks and access errors. </title> <booktitle> In Proceedings of the 1992 Usenix Winter Conference, </booktitle> <pages> pages 125-136, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: Independent of the research at the University of California, Berkeley, a company called Pure Software Inc. has also done extensive research into the uses of code patching including its use for detection of memory leaks and access errors. <ref> [14] </ref>. 9 Still others have modified GDB to provide kernel debugging support for Mach micro-kernels on the Motorola 88100/88200 [2]. Part of this work included a dynamic code generator to do code patching for conditional control breakpoints.
Reference: [15] <author> Gerry Kane and Joe Heinrich. </author> <title> MIPS RISC Architecture. </title> <publisher> Prentice Hall, </publisher> <address> New Jersy, </address> <year> 1992. </year>
Reference-contexts: However, the designer of this system has told me that he has not yet implemented it, nor does he have time to do it in the immediate future. 2.1.8 Monitor Registers Some processors, including the Intel i386 and the MIPS R4000 <ref> [12, 15] </ref>, have special registers dedicated to monitoring writes. These registers hold address ranges for the memory they are monitoring and, when a write occurs to a monitored region, a trap occurs. Although this hardware solution is fast, it is limited by the number of registers dedicated to monitoring writes.
Reference: [16] <author> Stephen Kaufer, Russell Lopez, and Sesha Pratap. Saber-C: </author> <title> an interpreter-based programming environment for the C language. </title> <booktitle> In Proceedings of the 1988 Usenix Summer Conference, </booktitle> <pages> pages 161-171, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Using an interpreter to implement watchpoints would not be efficient because interpreted code runs slower than compiled code, but it would be faster than single 17 stepping. For example, interpreted ANSI C runs approximately 200 times slower than compiled code <ref> [16] </ref>. Likewise, machine simulators tend to run 5 to 50 times slower than native hardware [3, 7]. CHAPTER 3 IMPLEMENTATION DETAILS Many of the techniques proposed to provide efficient watchpoints rely on a service, either abstract or real, that informs the debugger when a particular address in memory is written.
Reference: [17] <author> David Keppel. </author> <title> Fast data breakpoints. </title> <type> Technical Report 93-04-06, </type> <institution> University of Washington, </institution> <year> 1993. </year>
Reference-contexts: This thesis shows that dramatic improvements in the performance of watchpoints can be made in a variety of ways. This thesis also compares these solutions for efficient watchpoints with each other. Having an efficient implementation of watchpoints would help programmers immensely in debugging programs <ref> [24, 17, 11] </ref>. Without watchpoints it is difficult to find problems with pointer uses that result in inadvertent modification of unrelated data. <p> The other is to make the check faster. There are three ways that have been proposed to reduce the number of checks. The first is to check only write instructions instead of all instructions <ref> [24, 17] </ref>; the second is to check only the write instructions that write to the same page as the watched memory [24, 17]; the third is to checkpoint [17], that is, periodically stop and check the condition with the ability to roll back 4 to a previous state if the stopping <p> There are three ways that have been proposed to reduce the number of checks. The first is to check only write instructions instead of all instructions <ref> [24, 17] </ref>; the second is to check only the write instructions that write to the same page as the watched memory [24, 17]; the third is to checkpoint [17], that is, periodically stop and check the condition with the ability to roll back 4 to a previous state if the stopping condition has been met. <p> The first is to check only write instructions instead of all instructions [24, 17]; the second is to check only the write instructions that write to the same page as the watched memory [24, 17]; the third is to checkpoint <ref> [17] </ref>, that is, periodically stop and check the condition with the ability to roll back 4 to a previous state if the stopping condition has been met. <p> There are many ways proposed to make the check faster, from moving the checks outside of the debugger and into the kernel or the debuggee itself <ref> [24, 17] </ref>, to using special hardware that may be available [18, 24, 17], to just using more efficient data structures and algorithms to do the checks [25], and various combinations of the above. <p> There are many ways proposed to make the check faster, from moving the checks outside of the debugger and into the kernel or the debuggee itself [24, 17], to using special hardware that may be available <ref> [18, 24, 17] </ref>, to just using more efficient data structures and algorithms to do the checks [25], and various combinations of the above. <p> A couple of papers describe trap patching as a possible solution for fast watch-points <ref> [24, 17] </ref> and its performance is analyzed in a simulation study [24], however these papers do not claim that trap patching is a good solution for watchpoints nor do they cite any implementations of this approach. 2.1.2 Code Patching Like trap patching, code patching checks every single write. <p> Finally, the Los Alamos debugger ldb uses code patching to do fast conditional control breakpoints [4] 2.1.3 Checkpointing Another way to reduce the number of checks made is checkpointing <ref> [17] </ref>. This scheme is interesting, but has a major flaw in addition to the normal difficulties of doing checkpointing correctly [26] so I did not implement it. The idea behind checkpointing is the debugger periodically stops the program, saves the state, and checks the condition for stopping. <p> It would assume that the value has not changed, even though it has changed many times, and continue from the new spot after saving all of the state. Although checkpointing is described as a possible solution for watchpoints <ref> [17] </ref>, it has not been implemented nor has its performance been analyzed. 2.1.4 Virtual Memory The number of checks can be further reduced by checking only those writes that write to pages that contain data involved in a watched expression. <p> This design saves two context switches, from kernel to debugger and from debugger back to kernel, on "false hits." In papers on fast data breakpoints, kernel checking is mentioned only in passing as a way of improving performance of virtual memory based implementations <ref> [24, 17] </ref>. No analysis of how much improvement kernel checking provides is attempted. 2.1.7 Patch on Trap Patch on trap is an attempt to take the best ideas from both code patching and virtual memory schemes [17]. <p> No analysis of how much improvement kernel checking provides is attempted. 2.1.7 Patch on Trap Patch on trap is an attempt to take the best ideas from both code patching and virtual memory schemes <ref> [17] </ref>. I did not implement patch on trap but it is an interesting proposal and deserves discussion of its merits. Patch on trap makes the assumption that if a single write instruction is repeated several times, then it is accessing the same page several times. <p> It has been proposed that the dynamic code generator, used to improve conditional control breakpoints for the kernel debugger that was described above also be used as the basis for the trap on patch scheme <ref> [17] </ref>.
Reference: [18] <author> Peter Kessler. </author> <title> Fast breakpoints: </title> <booktitle> Design and implementation. In Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 78-84, </pages> <month> June </month> <year> 1990. </year> <note> Appeared as SIGPLAN Notices 25(6). </note>
Reference-contexts: There are many ways proposed to make the check faster, from moving the checks outside of the debugger and into the kernel or the debuggee itself [24, 17], to using special hardware that may be available <ref> [18, 24, 17] </ref>, to just using more efficient data structures and algorithms to do the checks [25], and various combinations of the above. <p> There has been considerable research into uses of code patching. Code patching was first suggested as a means to implement fast control breakpoints in a noninteractive environment <ref> [18] </ref>. On a SPARC workstation, code patching improved breakpoint performance by a factor of 1000 compared to standard Unix debuggers.
Reference: [19] <institution> Sun Microsystems Laboratories. </institution> <note> SunOS Release 4.1 dbx manual page, </note> <year> 1989. </year>
Reference-contexts: Thus the major benefit of watchpoints is eliminated. Watchpoints in GDB are slow because they are implemented using single stepping. GDB is not the only debugger to use single stepping. Most UNIX debuggers and many others use this approach, for example SUN's dbx <ref> [19] </ref>, HP's xdb [10], and Hitachi's sdb [20]. Single stepping consists of stopping the program after each instruction, returning control to the debugger, and evaluating the expressions associated with any watchpoints to see if they have changed.
Reference: [20] <institution> Hitatchi Computer Products. </institution> <note> OSF/1 Unix sdb manual page. </note>
Reference-contexts: Watchpoints in GDB are slow because they are implemented using single stepping. GDB is not the only debugger to use single stepping. Most UNIX debuggers and many others use this approach, for example SUN's dbx [19], HP's xdb [10], and Hitachi's sdb <ref> [20] </ref>. Single stepping consists of stopping the program after each instruction, returning control to the debugger, and evaluating the expressions associated with any watchpoints to see if they have changed. If not, the debugger returns control to the program for one more instruction, and so on.
Reference: [21] <author> Steven K Reinhardt, Mark D. Hill, Alvin R. Lebeck James R Larus, James C. Lewis, and David A. Wood. </author> <title> Virtual prototyping of parallel computers. </title> <booktitle> In ACM SIGMETRICS, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: The Connection Machine CM-5 has even better debugging support, providing similar break bits associated with each word (32 bytes) of memory <ref> [21] </ref>. Surprisingly, HP debuggers do not take advantage of the break bit feature of the PA [10]. In fact, the HPUX operating system does not even provide the mechanism to set the bit [9].
Reference: [22] <author> Richard M. Stallman and Roland H. Pesch. </author> <title> Debugging with GDB: The GNU Source-Level Debugger. Free Software Foundation, </title> <type> 545 Tech Square, </type> <address> Cambridge, Ma 02139, 4.12 edition, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: INTRODUCTION Watchpoints <ref> [22] </ref> in GDB, the GNU source-level debugger, are a special kind of breakpoint, a data breakpoint. <p> Another debugger, PER, which runs on the MTS operating system, also uses monitor registers [5]. GDB's developers plan to modify GDB to use them on those architectures that have them <ref> [22] </ref>. 2.1.9 Other Solutions Implementing watchpoints in interpreted code development environments is not difficult. The interpreter can be modified to do something special when it encounters an instruction that writes memory.
Reference: [23] <author> S. Venkata Subramonyam. </author> <type> Personal communication. </type> <institution> Code developer for Sequent Computer Corporation. </institution>
Reference-contexts: I could only find one Unix debugger, the dynix/ptx version of USL's debug, that uses monitor registers, but it resorts to single stepping when it runs out of monitor registers <ref> [13, 23] </ref>. Another debugger, PER, which runs on the MTS operating system, also uses monitor registers [5]. GDB's developers plan to modify GDB to use them on those architectures that have them [22]. 2.1.9 Other Solutions Implementing watchpoints in interpreted code development environments is not difficult.
Reference: [24] <author> Robert Wahbe. </author> <title> Efficient data breakpoints. </title> <booktitle> In Proceedings of the Fifth International Symposium on Architectural Support for Programming Languages and Operating Systems (ASPLOS-V), </booktitle> <pages> pages 200-212, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: This thesis shows that dramatic improvements in the performance of watchpoints can be made in a variety of ways. This thesis also compares these solutions for efficient watchpoints with each other. Having an efficient implementation of watchpoints would help programmers immensely in debugging programs <ref> [24, 17, 11] </ref>. Without watchpoints it is difficult to find problems with pointer uses that result in inadvertent modification of unrelated data. <p> The other is to make the check faster. There are three ways that have been proposed to reduce the number of checks. The first is to check only write instructions instead of all instructions <ref> [24, 17] </ref>; the second is to check only the write instructions that write to the same page as the watched memory [24, 17]; the third is to checkpoint [17], that is, periodically stop and check the condition with the ability to roll back 4 to a previous state if the stopping <p> There are three ways that have been proposed to reduce the number of checks. The first is to check only write instructions instead of all instructions <ref> [24, 17] </ref>; the second is to check only the write instructions that write to the same page as the watched memory [24, 17]; the third is to checkpoint [17], that is, periodically stop and check the condition with the ability to roll back 4 to a previous state if the stopping condition has been met. <p> There are many ways proposed to make the check faster, from moving the checks outside of the debugger and into the kernel or the debuggee itself <ref> [24, 17] </ref>, to using special hardware that may be available [18, 24, 17], to just using more efficient data structures and algorithms to do the checks [25], and various combinations of the above. <p> There are many ways proposed to make the check faster, from moving the checks outside of the debugger and into the kernel or the debuggee itself [24, 17], to using special hardware that may be available <ref> [18, 24, 17] </ref>, to just using more efficient data structures and algorithms to do the checks [25], and various combinations of the above. <p> Trap patching involves replacing all write instructions with a trap instruction. When the trap instruction executes, control is given to the debugger which determines whether the user specified conditions are met and if it should trigger the debugging action or emulate the write instruction and continue <ref> [24] </ref>. In the sample program there are 10 instructions that write to memory (nine stw instructions and one stwm instruction). In trap patching all of these write instructions are replaced by trap instructions. <p> A couple of papers describe trap patching as a possible solution for fast watch-points <ref> [24, 17] </ref> and its performance is analyzed in a simulation study [24], however these papers do not claim that trap patching is a good solution for watchpoints nor do they cite any implementations of this approach. 2.1.2 Code Patching Like trap patching, code patching checks every single write. <p> A couple of papers describe trap patching as a possible solution for fast watch-points [24, 17] and its performance is analyzed in a simulation study <ref> [24] </ref>, however these papers do not claim that trap patching is a good solution for watchpoints nor do they cite any implementations of this approach. 2.1.2 Code Patching Like trap patching, code patching checks every single write. <p> Instead of trapping and returning control to the debugger, however, the check is done by the debuggee itself. This requires adding code to the executable to be debugged that checks the target of every write instruction <ref> [24] </ref>. To implement code patching, both the debugger and debuggee must be modified. The debuggee must have its code patched. The patching could be accomplished by the compiler, the assembler, the linker, the debugger, or a completely separate program. <p> Later, code patching was advocated as a good solution for watchpoints in a simulation study comparing four watchpoint schemes: monitor registers (special registers dedicated to facilitate watchpoints), simple virtual memory, trap patching, and code patching <ref> [24] </ref>. This study was motivated to justify supporting code 8 patching in the Ensemble software development environment being built at the University of California, Berkeley. <p> When a write to a protected page occurs, the debugger handles the fault. The debugger unprotects the page, allows the write to occur, and reprotects the page. It then checks to see if the specified conditions are met and triggers the debugging action or continues <ref> [24] </ref>. In the program sample, the variables a and i happen to be on the same page while p and result are on the next page. The variable k is on a third page associated with the stack and the malloc'd memory comes from another page associated with the heap. <p> I am unaware of any other implementations that use the virtual memory system to do watchpoints. Only the simulation study mentioned earlier provides performance data for this type of implementation <ref> [24] </ref>. 2.1.5 HP break bit A down side to using virtual memory to implement watchpoints is that every stop and check requires a page fault, two system calls to unprotect and then protect the page and a trap to single step the write instruction|a heavy overhead. <p> after hearing of my work, plans to provide such a mechanism are being made. 12 2.1.6 Kernel Checking The performance of the virtual memory based schemes and even the trap patching scheme could be improved by having the operating system kernel keep track of what memory locations are being watched <ref> [24] </ref>. The fault handler then could compare the address against its list of addresses involved in a watchpoint and return control to the debugger only after the program writes to a watched address instead of every time a write to the page occurs. <p> This design saves two context switches, from kernel to debugger and from debugger back to kernel, on "false hits." In papers on fast data breakpoints, kernel checking is mentioned only in passing as a way of improving performance of virtual memory based implementations <ref> [24, 17] </ref>. No analysis of how much improvement kernel checking provides is attempted. 2.1.7 Patch on Trap Patch on trap is an attempt to take the best ideas from both code patching and virtual memory schemes [17]. <p> cases of unnecessary overhead caused by stopping when the expression has not changed and protecting pages in which the user may not be interested. 4.7 Comparison Most of the watchpoint research and development being done lately use the results from a simulation study done at the University of California, Berkeley <ref> [24] </ref> as their basis. Table 4.4 is a comparison between the timings of the basic watchpoint operations as measured in the implementations discussed in this paper and the corresponding numbers put forth in the simulation study. <p> This thesis provides several contributions over previous work to the study of watchpoints. Most of the previous and concurrent work in watchpoint development is based on the simulation study done at the University of California, Berkeley <ref> [24] </ref> which concluded that code patching was the best overall solution. Since then most work has concentrated on how to improve code patching techniques and how to implement these techniques into a debugger while mostly ignoring the virtual memory based implementation.
Reference: [25] <author> Robert Wahbe, Steven Lucco, and Susan L. Graham. </author> <title> Practical data break-points: </title> <booktitle> Design and implementation. In Proceedings of the ACMSIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 1-12, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: many ways proposed to make the check faster, from moving the checks outside of the debugger and into the kernel or the debuggee itself [24, 17], to using special hardware that may be available [18, 24, 17], to just using more efficient data structures and algorithms to do the checks <ref> [25] </ref>, and various combinations of the above. <p> In my implementations these costs particularly worsen the performance of code patching when inserting and deleting watchpoints. Code patching has since been implemented at the University of California, Berkeley and further research has been done on possible improvements to the patched code speed <ref> [25] </ref>. The researchers concluded that the data structure used to store the watched addresses is of particular importance. They found that a bitmap was better than a hash table and a segmented bit map was even better.
Reference: [26] <author> Paul R. Wilson and Thomas G. Moher. </author> <title> Demonic memories for process histories. </title> <booktitle> In Proceedings of the ACM '89 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 330-343, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Finally, the Los Alamos debugger ldb uses code patching to do fast conditional control breakpoints [4] 2.1.3 Checkpointing Another way to reduce the number of checks made is checkpointing [17]. This scheme is interesting, but has a major flaw in addition to the normal difficulties of doing checkpointing correctly <ref> [26] </ref> so I did not implement it. The idea behind checkpointing is the debugger periodically stops the program, saves the state, and checks the condition for stopping.
References-found: 26

