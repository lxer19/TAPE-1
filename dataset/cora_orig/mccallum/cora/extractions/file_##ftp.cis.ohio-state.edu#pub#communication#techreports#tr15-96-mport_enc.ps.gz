URL: file://ftp.cis.ohio-state.edu/pub/communication/techreports/tr15-96-mport_enc.ps.gz
Refering-URL: http://www.cis.ohio-state.edu/~panda/wormhole_pub.html
Root-URL: 
Title: Efficient Broadcast and Multicast on Multistage Interconnection Networks using Multiport Encoding  
Author: RAJEEV SIVARAM, DHABALESWAR K. PANDA, AND CRAIG B. STUNKEL 
Note: A preliminary version of this manuscript has been accepted for presentation in the Eighth IEEE Symposium on Parallel and Distributed Processing (SPDP'96), October 1996. This manuscript is under review for publication in the IEEE Transactions on Parallel and Distributed Systems.  
Abstract: Technical Report OSU-CISRC-3/96-TR15 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Aydogan, C. B. Stunkel, C. Aykanat, and B. Abali. </author> <title> Adaptive Source Routing in Multistage Interconnection Networks. </title> <booktitle> In Proceedings of the International Parallel Processing Symposium, </booktitle> <pages> pages 258-267, </pages> <year> 1996. </year>
Reference-contexts: However, arbitrary multicast over output ports is not feasible by this scheme. Multiple broadcast/multicast using such a scheme also leads to deadlock. Recently, such a multiport encoding of worms has also been proposed for source-based adaptive routing on SP2-like MINs <ref> [1] </ref>. Since current MIN-based parallel systems, like the IBM SP1 and SP2 [34] use buffered wormhole or virtual cut-through techniques instead of wormhole routing, a worthwhile challenge is to devise a method to do multicast on such systems using multiport encoding. <p> It is to be noted that in such an encoding scheme, the bits corresponding to a stage can be discarded once a routing decision has been made. Recently, a new scheme called source based adaptive routing has been proposed in <ref> [1] </ref>. Here, the header of the unicast worm is organized as a sequence of k-bit strings similar to the example in Fig. 2 (d). However, each k-bit string may have more than one 1 bit. <p> Multiport encoding assumes greater importance in the light of the fact that unicast worms can always be encoded using a similar sequence of k-bit strings. As described in the previous section, such an approach is already being considered <ref> [1] </ref> to support adaptive routing in MINs with unicast worms. Thus such encoding can provide dual functionality, adaptivity for unicast worms and a mechanism for efficient multicast. <p> The worm may choose any link along its forward path that leads it to the last stage of switches. The choice of link may be made depending on local traffic conditions. This adaptivity can be captured using multiport encoding as described in <ref> [1] </ref> and as mentioned in Sec. 3. Each header flit has a bit to distinguish if it is to be interpreted for adaptive routing or multiport routing.
Reference: [2] <author> V. Bala, J. Bruck, R. Cypher, P. Elustondo, A. Ho, C.-T. Ho, S. Kipnis, and M. Snir. </author> <title> CCL: A Portable and Tunable Collective Communication Library for Scalable Parallel Computers. </title> <booktitle> In Proceedings of the International Parallel Processing Symposium, </booktitle> <year> 1994. </year>
Reference-contexts: All of these systems are being used to support either the distributed-memory or distributed-shared memory programming paradigms. For efficient support of either paradigm, these systems require fast collective communication <ref> [2, 21] </ref> support from the underlying communication subsystem, as for example is defined by the Message Passing Interface (MPI) Standard [23]. Among the set of collective communication operations, broadcast [15, 6] and multicast [11] are fundamental and are used in several other operations like barrier synchronization and reduction [26].
Reference: [3] <author> M. Barnett, D. G. Payne, and R. Van de Geijn. </author> <title> Optimal Broadcasting in Mesh-Connected Architectures. </title> <type> Technical Report TR91-38, </type> <institution> Dept. of Computer Science, Universityof Texas at Austin, </institution> <month> Dec </month> <year> 1991. </year>
Reference-contexts: Thus, it is advantageous to reduce latency of broadcast and multicast operations on these systems. Many software schemes have been recently proposed to efficiently implement broadcast and multicast in wormhole-routed k-ary n-cube networks <ref> [3, 22] </ref> and multistage interconnection networks [35]. All of these schemes use point-to-point (unicast) message passing and require multiple contention-free phases to achieve fast broadcast and multicast. For multicasting to d destinations, these schemes typically require dlog 2 (d + 1)e communication phases.
Reference: [4] <author> J. Beecroft, M. Homewood, and M. McLaren. </author> <title> Meiko CS-2 Interconnect Elan-Elite Design. </title> <journal> Parallel Computing, </journal> <volume> 20 </volume> <pages> 1627-1638, </pages> <month> Nov </month> <year> 1994. </year>
Reference-contexts: This switching technique is being used with a wide variety of topologies. Examples include k-ary n-cube networks (Cray T3D [9], Intel Paragon [14], Ncube [12]), fat-tree networks (CM-5 [18], Meiko CS2 <ref> [4] </ref>), and multistage interconnection networks (IBM SP1/SP2 [34, 32]). All of these systems are being used to support either the distributed-memory or distributed-shared memory programming paradigms. <p> Thus, a scheme using synchronous replication of multidestination worms that uses a deadlock avoidance scheme at each intermediate switch has been proposed. However, this scheme is very complex and requires considerable hardware support. Alternatively, multidestination worms with multiport encoding has been proposed <ref> [4] </ref> to support broadcast over a contiguous range of output ports at a given switch. However, arbitrary multicast over output ports is not feasible by this scheme. Multiple broadcast/multicast using such a scheme also leads to deadlock.
Reference: [5] <author> E. D. Brooks and J. E. Hoag. </author> <title> A Scalable Coherent Cache System with Incomplete Directory State. </title> <booktitle> In International Conference on Parallel Processing (ICPP), </booktitle> <volume> volume 1, </volume> <pages> pages 553-554, </pages> <year> 1990. </year>
Reference-contexts: A `1' in the ith position of the k-bit string (0 i k 1) denotes that output port i is one of the ports to which the worm should be forwarded <ref> [5] </ref>. The basic idea of multiport encoding is to use a sequence of such k-bit strings to encode the multidestination worm's path. The number of such k-bit strings in the worm header is equal to the number of stages in the network. <p> Siegel et al [30] describe a method of multicas-ting that is equivalant to multiport encoding based multicast for the special case of k = 2. Multiport encoding based multicast has also been introduced in the context of packet switched cache coherent systems <ref> [5] </ref>. Although [5] shows how multiport encoding can be used in a single switch, the paper does not extrapolate the use of multiport encoding for a MIN. <p> Siegel et al [30] describe a method of multicas-ting that is equivalant to multiport encoding based multicast for the special case of k = 2. Multiport encoding based multicast has also been introduced in the context of packet switched cache coherent systems <ref> [5] </ref>. Although [5] shows how multiport encoding can be used in a single switch, the paper does not extrapolate the use of multiport encoding for a MIN.
Reference: [6] <author> J. Bruck, R. Cypher, and C.-T. Ho. </author> <title> Multiple Message Broadcasting with Generalized Fibonacci Trees. </title> <booktitle> In Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 424-430, </pages> <year> 1992. </year> <month> 35 </month>
Reference-contexts: For efficient support of either paradigm, these systems require fast collective communication [2, 21] support from the underlying communication subsystem, as for example is defined by the Message Passing Interface (MPI) Standard [23]. Among the set of collective communication operations, broadcast <ref> [15, 6] </ref> and multicast [11] are fundamental and are used in several other operations like barrier synchronization and reduction [26]. Thus, it is advantageous to reduce latency of broadcast and multicast operations on these systems.
Reference: [7] <author> C.-M. Chiang and L. M. Ni. </author> <title> Deadlock-Free Multi-Head Wormhole Routing. </title> <booktitle> In Proceedings of the First High Performance Computing-Asia, </booktitle> <year> 1995. </year>
Reference-contexts: Since this mechanism and the associated schemes have been specifically developed for direct networks with k-ary n-cube topologies, they cannot be applied to switch-based indirect networks with multistage interconnects. Recently, an approach using multidestination worms has been proposed for MINs supporting strict wormhole-routing <ref> [7] </ref>. It has been shown that both asynchronous and synchronous replication of multidestination worms lead to deadlock. Thus, a scheme using synchronous replication of multidestination worms that uses a deadlock avoidance scheme at each intermediate switch has been proposed. However, this scheme is very complex and requires considerable hardware support. <p> The first criterion is the replication mechanism that is used at a switch. The second criterion is the flow control mechanism used. There are two main replication mechanisms that have been proposed in the literature <ref> [7, 28] </ref>. These mechanisms are known as synchronous replication and asynchronous replication, respectively. <p> Furthermore, all of a worm's copies at a stage must proceed together to the next stage of the network. Synchronous replication therefore requires some feedback mechanism from the switches to the originating nodes <ref> [7] </ref>. Under asynchronous replication, a multidestination worm arriving at a switch uses the available ports to forward copies of the flits, while remaining blocked on the unavailable ports. Asynchronous replication thus has the advantage of doing away with the feedback architecture required for synchronous replication. <p> One such mechanism is virtual cut-through [16]. Note that in both wormhole routing and virtual cut-through, in the absence of contention for output ports, worms continue to propagate on a flit by flit basis from one switch to the next. Chiang and Ni <ref> [7] </ref> have shown that both synchronous and asynchronous replication mechanisms can cause deadlock when used in conjunction with strict wormhole routing. Although a method to avoid deadlock in systems using synchronous replication is suggested in [7], the method is extremely restrictive and is inappropriate for variations of wormhole routing that provide <p> Chiang and Ni <ref> [7] </ref> have shown that both synchronous and asynchronous replication mechanisms can cause deadlock when used in conjunction with strict wormhole routing. Although a method to avoid deadlock in systems using synchronous replication is suggested in [7], the method is extremely restrictive and is inappropriate for variations of wormhole routing that provide more intermediate buffering. As shown in [7], the root of the deadlock problem is the dependence between the multiple output ports involved in a worm replication. <p> Although a method to avoid deadlock in systems using synchronous replication is suggested in <ref> [7] </ref>, the method is extremely restrictive and is inappropriate for variations of wormhole routing that provide more intermediate buffering. As shown in [7], the root of the deadlock problem is the dependence between the multiple output ports involved in a worm replication. This dependence results from blocked flits within the input buffer, which deny the entrance of the entire worm into this buffer.
Reference: [8] <author> C.-M. Chiang and L. M. Ni. </author> <title> Efficient Software Multicast in Wormhole-routed Unidirectional Multistage Networks. </title> <booktitle> In Symposium on Parallel and Distributed Processing, </booktitle> <year> 1995. </year>
Reference-contexts: Recently, a variant of the U-min algorithm (called C-min) has been proposed by Chiang and Ni <ref> [8] </ref>. Although this algorithm performs no better than U-min for a single multicast, it performs better than U-min for multiple multicasts. Both U-min and C-min require dlog 2 (d + 1)e phases to cover a destination set of size d. <p> These values are similar to those used in the IBM SP2 [34]. We assume a single read port model as discussed in Sec. 4.2. We performed experiments using the MTS, MTM and MTE algorithms and compared the results with the unicast based C-Min algorithm <ref> [8] </ref>. For the MTS algorithm we chose the least significant digit of the destination ID to group destinations. We studied the effect of startup time (t s ) on multicast latency using 3 different values for t s : 1.0, 5.0 and 10.0 microseconds.
Reference: [9] <author> Cray Research, Inc. </author> <title> Cray T3D System Architecture Overview, </title> <year> 1993. </year>
Reference-contexts: 1 Introduction The wormhole-routing switching technique is the current trend in building parallel systems due to inherent advantages such as low-latency communication and reduced communication hardware overhead [10, 17, 25]. This switching technique is being used with a wide variety of topologies. Examples include k-ary n-cube networks (Cray T3D <ref> [9] </ref>, Intel Paragon [14], Ncube [12]), fat-tree networks (CM-5 [18], Meiko CS2 [4]), and multistage interconnection networks (IBM SP1/SP2 [34, 32]). All of these systems are being used to support either the distributed-memory or distributed-shared memory programming paradigms. <p> For multicasting to d destinations, these schemes typically require dlog 2 (d + 1)e communication phases. Since the ratio of communication start-up time to propagation time is quite high on current parallel systems <ref> [9, 14, 34] </ref>, such a software based unicast message-passing approach leads to very high latency for broadcast and multicast operations. For example, with a 10.0 microsec communication start-up time, it takes at least 100.0 microsec (ignoring the data propagation time) to perform a broadcast operation on a 1024-processor system.
Reference: [10] <author> W. J. Dally and C. L. Seitz. </author> <title> Deadlock-Free Message Routing in Multiprocessor Interconnection Networks. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 547-553, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: 1 Introduction The wormhole-routing switching technique is the current trend in building parallel systems due to inherent advantages such as low-latency communication and reduced communication hardware overhead <ref> [10, 17, 25] </ref>. This switching technique is being used with a wide variety of topologies. Examples include k-ary n-cube networks (Cray T3D [9], Intel Paragon [14], Ncube [12]), fat-tree networks (CM-5 [18], Meiko CS2 [4]), and multistage interconnection networks (IBM SP1/SP2 [34, 32]).
Reference: [11] <author> J. Duato. </author> <title> A Theory of Deadlock-Free Adaptive Multicast Routing in Wormhole Networks. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <pages> pages 976-987, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: For efficient support of either paradigm, these systems require fast collective communication [2, 21] support from the underlying communication subsystem, as for example is defined by the Message Passing Interface (MPI) Standard [23]. Among the set of collective communication operations, broadcast [15, 6] and multicast <ref> [11] </ref> are fundamental and are used in several other operations like barrier synchronization and reduction [26]. Thus, it is advantageous to reduce latency of broadcast and multicast operations on these systems.
Reference: [12] <author> B. Duzett and R. Buck. </author> <title> An Overview of the Ncube-3 Supercomputer. </title> <booktitle> In Proceedings of the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 458-464, </pages> <year> 1992. </year>
Reference-contexts: This switching technique is being used with a wide variety of topologies. Examples include k-ary n-cube networks (Cray T3D [9], Intel Paragon [14], Ncube <ref> [12] </ref>), fat-tree networks (CM-5 [18], Meiko CS2 [4]), and multistage interconnection networks (IBM SP1/SP2 [34, 32]). All of these systems are being used to support either the distributed-memory or distributed-shared memory programming paradigms.
Reference: [13] <author> J. L. Hennessy and D. Patterson. </author> <title> Computer Organization and Design: The Hardware/Software Interface. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: The algorithm uses properties of the array by virtue of which some destinations may be covered by a single multiport tree. These properties are similar to the grouping properties of entries in a Karnaugh Map <ref> [13] </ref>. We therefore refer to the array as a Modified Karnaugh Map (MKM). Fig. 24 in Appendix A describes the procedure for forming the MKM more formally. This representation is shown in Fig. 16 (a) for the example multicast destination set presented above.
Reference: [14] <author> Intel Corporation. </author> <title> Paragon XP/S Product Overview, </title> <year> 1991. </year>
Reference-contexts: This switching technique is being used with a wide variety of topologies. Examples include k-ary n-cube networks (Cray T3D [9], Intel Paragon <ref> [14] </ref>, Ncube [12]), fat-tree networks (CM-5 [18], Meiko CS2 [4]), and multistage interconnection networks (IBM SP1/SP2 [34, 32]). All of these systems are being used to support either the distributed-memory or distributed-shared memory programming paradigms. <p> For multicasting to d destinations, these schemes typically require dlog 2 (d + 1)e communication phases. Since the ratio of communication start-up time to propagation time is quite high on current parallel systems <ref> [9, 14, 34] </ref>, such a software based unicast message-passing approach leads to very high latency for broadcast and multicast operations. For example, with a 10.0 microsec communication start-up time, it takes at least 100.0 microsec (ignoring the data propagation time) to perform a broadcast operation on a 1024-processor system.
Reference: [15] <author> S. L. Johnsson and C.-T. Ho. </author> <title> Optimum Broadcasting and Personalized Communication in Hypercubes. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 1249-1268, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: For efficient support of either paradigm, these systems require fast collective communication [2, 21] support from the underlying communication subsystem, as for example is defined by the Message Passing Interface (MPI) Standard [23]. Among the set of collective communication operations, broadcast <ref> [15, 6] </ref> and multicast [11] are fundamental and are used in several other operations like barrier synchronization and reduction [26]. Thus, it is advantageous to reduce latency of broadcast and multicast operations on these systems.
Reference: [16] <author> P. Kermani and L. Kleinrock. </author> <title> Virtual Cut-Through: A new Computer Communications Switching Technique. </title> <journal> Computer Networks, </journal> <volume> 3(4) </volume> <pages> 267-286, </pages> <month> Sept. </month> <year> 1979. </year>
Reference-contexts: A third approach is to guarantee that an arriving worm will have enough space for the worm to be fully buffered. One such mechanism is virtual cut-through <ref> [16] </ref>. Note that in both wormhole routing and virtual cut-through, in the absence of contention for output ports, worms continue to propagate on a flit by flit basis from one switch to the next.
Reference: [17] <author> S. Konstantinidou and L. Snyder. </author> <title> Chaos Router: Architecture and Performance. </title> <booktitle> In Proceedings of the International Symposium on Architecture, </booktitle> <pages> pages 212-221, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction The wormhole-routing switching technique is the current trend in building parallel systems due to inherent advantages such as low-latency communication and reduced communication hardware overhead <ref> [10, 17, 25] </ref>. This switching technique is being used with a wide variety of topologies. Examples include k-ary n-cube networks (Cray T3D [9], Intel Paragon [14], Ncube [12]), fat-tree networks (CM-5 [18], Meiko CS2 [4]), and multistage interconnection networks (IBM SP1/SP2 [34, 32]).
Reference: [18] <author> C. E. Leiserson et al. </author> <title> The Network Architecture of the Connection Machine CM-5. </title> <booktitle> In Proceedings of the ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 272-285, </pages> <year> 1992. </year>
Reference-contexts: This switching technique is being used with a wide variety of topologies. Examples include k-ary n-cube networks (Cray T3D [9], Intel Paragon [14], Ncube [12]), fat-tree networks (CM-5 <ref> [18] </ref>, Meiko CS2 [4]), and multistage interconnection networks (IBM SP1/SP2 [34, 32]). All of these systems are being used to support either the distributed-memory or distributed-shared memory programming paradigms.
Reference: [19] <author> X. Lin, P. K. McKinley, and L. M. Ni. </author> <title> Performance Evaluation of Multicast Wormhole Routing in 2D-Mesh Multicomputers. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages I:435-442, </pages> <year> 1991. </year>
Reference-contexts: This raises a fundamental question: can the latency of these operations be reduced by using a new and efficient mechanism at the hardware level? A new conceptmultidestination wormhole message passinghas been introduced recently <ref> [19, 27] </ref>. Unlike a unicast message which has a single destination, such a mechanism allows a message to have multiple destinations. A multidestination worm provides the flexibility to distribute data to multiple nodes or gather data from multiple nodes using a single message and a single communication start-up. <p> Using such worms it has been shown that broadcast and multicast operations on k-ary n-cube networks with different routing schemes (e-cube, adaptive, Hamiltonian, etc.) can be implemented with significantly reduced latency <ref> [19, 27] </ref> compared to unicast-based schemes. Since this mechanism and the associated schemes have been specifically developed for direct networks with k-ary n-cube topologies, they cannot be applied to switch-based indirect networks with multistage interconnects. Recently, an approach using multidestination worms has been proposed for MINs supporting strict wormhole-routing [7].
Reference: [20] <author> X. Lin and L. M. Ni. </author> <title> Deadlock-free Multicast Wormhole Routing in Multicomputer Networks. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 116-124, </pages> <year> 1991. </year>
Reference-contexts: We also develop a multicasting scheme to perform efficient multicast using multiport encoded worms. 3.1 Multiport Encoding A multidestination worm transfers a packet from a source to multiple destinations <ref> [20, 27] </ref>. A multidestination worm's header must carry information that helps the worm reach all its destinations.
Reference: [21] <author> P. K. McKinley and D. F. Robinson. </author> <title> Collective Communication in Wormhole-Routed Massively Parallel Computers. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 39-50, </pages> <month> Dec </month> <year> 1995. </year>
Reference-contexts: All of these systems are being used to support either the distributed-memory or distributed-shared memory programming paradigms. For efficient support of either paradigm, these systems require fast collective communication <ref> [2, 21] </ref> support from the underlying communication subsystem, as for example is defined by the Message Passing Interface (MPI) Standard [23]. Among the set of collective communication operations, broadcast [15, 6] and multicast [11] are fundamental and are used in several other operations like barrier synchronization and reduction [26].
Reference: [22] <author> P. K. McKinley, H. Xu, A.-H. Esfahanian, and L. M. Ni. </author> <title> Unicast-based Multicast Communication in Wormhole-routed Networks. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(12) </volume> <pages> 1252-1265, </pages> <month> Dec </month> <year> 1994. </year>
Reference-contexts: Thus, it is advantageous to reduce latency of broadcast and multicast operations on these systems. Many software schemes have been recently proposed to efficiently implement broadcast and multicast in wormhole-routed k-ary n-cube networks <ref> [3, 22] </ref> and multistage interconnection networks [35]. All of these schemes use point-to-point (unicast) message passing and require multiple contention-free phases to achieve fast broadcast and multicast. For multicasting to d destinations, these schemes typically require dlog 2 (d + 1)e communication phases.
Reference: [23] <author> Message Passing Interface Forum. </author> <title> MPI: A Message-Passing Interface Standard, </title> <month> Mar </month> <year> 1994. </year>
Reference-contexts: All of these systems are being used to support either the distributed-memory or distributed-shared memory programming paradigms. For efficient support of either paradigm, these systems require fast collective communication [2, 21] support from the underlying communication subsystem, as for example is defined by the Message Passing Interface (MPI) Standard <ref> [23] </ref>. Among the set of collective communication operations, broadcast [15, 6] and multicast [11] are fundamental and are used in several other operations like barrier synchronization and reduction [26]. Thus, it is advantageous to reduce latency of broadcast and multicast operations on these systems.
Reference: [24] <author> P. Mohapatra and C. R. Das. </author> <title> A Queuing Model for Finite-Buffered Multistage Interconnection Networks. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages I:210-213, </pages> <month> Aug </month> <year> 1993. </year>
Reference-contexts: In this paper we propose a new approach to implement fast broadcast and multicast on both unidirectional and bidirectional MINs using multiport encoded multidestination worms. For a MIN <ref> [24] </ref> with n stages and k fi k switches, our approach uses multidestination worms with n flit headers. One header flit is used for each stage. Each header flit carries information about the ports to which a message needs to be replicated at the associated switches of a given stage.
Reference: [25] <author> L. Ni and P. K. McKinley. </author> <title> A Survey of Wormhole Routing Techniques in Direct Networks. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 62-76, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: 1 Introduction The wormhole-routing switching technique is the current trend in building parallel systems due to inherent advantages such as low-latency communication and reduced communication hardware overhead <ref> [10, 17, 25] </ref>. This switching technique is being used with a wide variety of topologies. Examples include k-ary n-cube networks (Cray T3D [9], Intel Paragon [14], Ncube [12]), fat-tree networks (CM-5 [18], Meiko CS2 [4]), and multistage interconnection networks (IBM SP1/SP2 [34, 32]).
Reference: [26] <author> D. K. Panda. </author> <title> Issues in Designing Efficient and Practical Algorithms for Collective Communication in Wormhole-Routed Systems. </title> <booktitle> In 1995 Workshop on Challenges for Parallel Processing, </booktitle> <pages> pages 8-15, </pages> <year> 1995. </year>
Reference-contexts: Among the set of collective communication operations, broadcast [15, 6] and multicast [11] are fundamental and are used in several other operations like barrier synchronization and reduction <ref> [26] </ref>. Thus, it is advantageous to reduce latency of broadcast and multicast operations on these systems. Many software schemes have been recently proposed to efficiently implement broadcast and multicast in wormhole-routed k-ary n-cube networks [3, 22] and multistage interconnection networks [35].
Reference: [27] <author> D. K. Panda, S. Singal, and P. Prabhakaran. </author> <title> Multidestination Message Passing Mechanism Conforming to Base Wormhole Routing Scheme. </title> <booktitle> In Proceedings of the Parallel Computer Routing and Communication Workshop, </booktitle> <pages> pages 131-145, </pages> <year> 1994. </year> <month> 36 </month>
Reference-contexts: This raises a fundamental question: can the latency of these operations be reduced by using a new and efficient mechanism at the hardware level? A new conceptmultidestination wormhole message passinghas been introduced recently <ref> [19, 27] </ref>. Unlike a unicast message which has a single destination, such a mechanism allows a message to have multiple destinations. A multidestination worm provides the flexibility to distribute data to multiple nodes or gather data from multiple nodes using a single message and a single communication start-up. <p> Using such worms it has been shown that broadcast and multicast operations on k-ary n-cube networks with different routing schemes (e-cube, adaptive, Hamiltonian, etc.) can be implemented with significantly reduced latency <ref> [19, 27] </ref> compared to unicast-based schemes. Since this mechanism and the associated schemes have been specifically developed for direct networks with k-ary n-cube topologies, they cannot be applied to switch-based indirect networks with multistage interconnects. Recently, an approach using multidestination worms has been proposed for MINs supporting strict wormhole-routing [7]. <p> For a range of system sizes, message lengths, and communication start-up times, simulation studies indicate that a reduction in broadcast/multicast latency up to 4 times can be achieved by our approach. Similar to the results on k-ary n-cube networks <ref> [27] </ref>, this study also indicates that multiport encoded worms can reduce multicast latency in MINs as the number of destinations participating in a multicast increases beyond a certain number. <p> We also develop a multicasting scheme to perform efficient multicast using multiport encoded worms. 3.1 Multiport Encoding A multidestination worm transfers a packet from a source to multiple destinations <ref> [20, 27] </ref>. A multidestination worm's header must carry information that helps the worm reach all its destinations.
Reference: [28] <author> D. K. Panda and R. Sivaram. </author> <title> Fast Broadcast and Multicast in Wormhole Multistage Networks with Multidestina--tion Worms. </title> <type> Technical Report OSU-CISRC-4/95-TR21, </type> <institution> Dept. of Computer and Information Science, The Ohio State University, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: The first criterion is the replication mechanism that is used at a switch. The second criterion is the flow control mechanism used. There are two main replication mechanisms that have been proposed in the literature <ref> [7, 28] </ref>. These mechanisms are known as synchronous replication and asynchronous replication, respectively.
Reference: [29] <author> I. D. Scherson and C.-H. Chien. </author> <title> Least common ancestor networks. </title> <booktitle> In Proc. 7th Int. Parallel Processing Symp., </booktitle> <pages> pages 507-513, </pages> <year> 1993. </year>
Reference-contexts: It may be noted that a worm need not always travel up to the last stage of the bidi-MIN before turning around. Traveling up to a least common ancestor stage <ref> [29, 35] </ref> corresponding to the given set of destinations and the source, is sufficient. As described in [35], in the bidi-butterfly network the least common ancestor stage between a source and destination node is given by the position of the leftmost digit in which their IDs differ.
Reference: [30] <author> H. J. Siegel and R. McMillen. </author> <title> The Multistage Cube: a Versatile Interconnection Network. </title> <journal> IEEE Computer, </journal> <volume> 14(12) </volume> <pages> 65-76, </pages> <month> December </month> <year> 1981. </year>
Reference-contexts: As described in the previous section, such an approach is already being considered [1] to support adaptive routing in MINs with unicast worms. Thus such encoding can provide dual functionality, adaptivity for unicast worms and a mechanism for efficient multicast. Siegel et al <ref> [30] </ref> describe a method of multicas-ting that is equivalant to multiport encoding based multicast for the special case of k = 2. Multiport encoding based multicast has also been introduced in the context of packet switched cache coherent systems [5].
Reference: [31] <author> H. J. Siegel, W. G. Nation, C. P. Kruskal, and L. M. Napolitano. </author> <title> Using the Multistage Cube Network Topology in Parallel Supercomputers. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 77(12) </volume> <pages> 1932-1953, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: the multidestination mechanism are therefore few and can be easily incorporated into existing switch architectures. 15 5 Algorithms for Generating Multiport Encoded Worms In this section we present three algorithms of differing complexities that generate multiport encoded worms that cover a given destination set, using a unidirectional multistage cube network <ref> [31] </ref> as example. We first present some definitions and properties of the multistage cube network and introduce the notion of a multiport tree. <p> In the remaining part of this paper, we will concentrate mainly on achieving properties (i) and (ii) and present heuristics that produce a SM T of very low cardinality. To solve the problem stated above, we make use of the following source invariant properties of the cube network <ref> [31] </ref>. The following property shows that the path to a destination from any source can be determined using only the digits in the destination ID.
Reference: [32] <author> C. B. Stunkel, D. Shea, D. G. Grice, P. H. Hochschild, and M. Tsao. </author> <title> The SP1 High Performance Switch. </title> <booktitle> In Scalable High Performance Computing Conference, </booktitle> <pages> pages 150-157, </pages> <year> 1994. </year>
Reference-contexts: This switching technique is being used with a wide variety of topologies. Examples include k-ary n-cube networks (Cray T3D [9], Intel Paragon [14], Ncube [12]), fat-tree networks (CM-5 [18], Meiko CS2 [4]), and multistage interconnection networks (IBM SP1/SP2 <ref> [34, 32] </ref>). All of these systems are being used to support either the distributed-memory or distributed-shared memory programming paradigms. <p> Another form of header encoding is to store the entire path of the worm in the worm's header. The worm's path is determined a priori and known before the worm enters the network. Such a form of routing is called static routing. Systems like the IBM SP2 <ref> [33, 32, 34] </ref> use such an encoding. Assuming k fi k switches are used, Figs. 2 (c) and 2 (d) 6 show examples of such encoding using log 2 k and k bits per stage, respectively.
Reference: [33] <author> C. B. Stunkel, D. G. Shea, B. Abali, M. M. Denneau, P. H. Hochschild, D. J. Joseph, B. J. Nathanson, M. Tsao, and P. R. Varker. </author> <booktitle> Architecture and Implementation of Vulcan. In Proceedings of the International Parallel Processing Symposium, </booktitle> <pages> pages 268-274, </pages> <year> 1994. </year>
Reference-contexts: Another form of header encoding is to store the entire path of the worm in the worm's header. The worm's path is determined a priori and known before the worm enters the network. Such a form of routing is called static routing. Systems like the IBM SP2 <ref> [33, 32, 34] </ref> use such an encoding. Assuming k fi k switches are used, Figs. 2 (c) and 2 (d) 6 show examples of such encoding using log 2 k and k bits per stage, respectively.
Reference: [34] <author> C. B. Stunkel, D. G. Shea, B. Abali, et al. </author> <title> The SP2 High-Performance Switch. </title> <journal> IBM System Journal, </journal> <volume> 34(2) </volume> <pages> 185-204, </pages> <year> 1995. </year>
Reference-contexts: This switching technique is being used with a wide variety of topologies. Examples include k-ary n-cube networks (Cray T3D [9], Intel Paragon [14], Ncube [12]), fat-tree networks (CM-5 [18], Meiko CS2 [4]), and multistage interconnection networks (IBM SP1/SP2 <ref> [34, 32] </ref>). All of these systems are being used to support either the distributed-memory or distributed-shared memory programming paradigms. <p> For multicasting to d destinations, these schemes typically require dlog 2 (d + 1)e communication phases. Since the ratio of communication start-up time to propagation time is quite high on current parallel systems <ref> [9, 14, 34] </ref>, such a software based unicast message-passing approach leads to very high latency for broadcast and multicast operations. For example, with a 10.0 microsec communication start-up time, it takes at least 100.0 microsec (ignoring the data propagation time) to perform a broadcast operation on a 1024-processor system. <p> Multiple broadcast/multicast using such a scheme also leads to deadlock. Recently, such a multiport encoding of worms has also been proposed for source-based adaptive routing on SP2-like MINs [1]. Since current MIN-based parallel systems, like the IBM SP1 and SP2 <ref> [34] </ref> use buffered wormhole or virtual cut-through techniques instead of wormhole routing, a worthwhile challenge is to devise a method to do multicast on such systems using multiport encoding. <p> Another form of header encoding is to store the entire path of the worm in the worm's header. The worm's path is determined a priori and known before the worm enters the network. Such a form of routing is called static routing. Systems like the IBM SP2 <ref> [33, 32, 34] </ref> use such an encoding. Assuming k fi k switches are used, Figs. 2 (c) and 2 (d) 6 show examples of such encoding using log 2 k and k bits per stage, respectively. <p> The chunk size, described in Section 4, was assumed to be 4 flits for experiments performed with 4 fi 4 switches, and 8 flits for experiments performed with 8 fi 8 switches. These values are similar to those used in the IBM SP2 <ref> [34] </ref>. We assume a single read port model as discussed in Sec. 4.2. We performed experiments using the MTS, MTM and MTE algorithms and compared the results with the unicast based C-Min algorithm [8].
Reference: [35] <author> H. Xu, Y.-D. Gui, and L. M. Ni. </author> <title> Optimal Software Multicast in Wormhole-Routed Multistage Networks. </title> <booktitle> In Proceedings of the Supercomputing Conference, </booktitle> <pages> pages 703-712, </pages> <year> 1994. </year>
Reference-contexts: Thus, it is advantageous to reduce latency of broadcast and multicast operations on these systems. Many software schemes have been recently proposed to efficiently implement broadcast and multicast in wormhole-routed k-ary n-cube networks [3, 22] and multistage interconnection networks <ref> [35] </ref>. All of these schemes use point-to-point (unicast) message passing and require multiple contention-free phases to achieve fast broadcast and multicast. For multicasting to d destinations, these schemes typically require dlog 2 (d + 1)e communication phases. <p> With p destinations being covered by a single multiport encoded worm on the average, our scheme uses approximately dlog p+1 (d + 1)e communication start-ups to cover d destinations. This approach significantly reduces broadcast/multicast latency compared to schemes using unicast messages <ref> [35] </ref>. For a range of system sizes, message lengths, and communication start-up times, simulation studies indicate that a reduction in broadcast/multicast latency up to 4 times can be achieved by our approach. <p> The basic idea in these schemes is to derive contention free phases so that multiple communications can occur in parallel. A good algorithm for unicast-based multicast is the U-min algorithm proposed in <ref> [35] </ref>. This algorithm, proposed for fat-tree networks, uses a destination that receives a message in any phase to retransmit the message in succeeding phases. The coverage of the destinations therefore proceeds in the form of a binomial tree, with the number of sources doubling in every phase. <p> It may be noted that a worm need not always travel up to the last stage of the bidi-MIN before turning around. Traveling up to a least common ancestor stage <ref> [29, 35] </ref> corresponding to the given set of destinations and the source, is sufficient. As described in [35], in the bidi-butterfly network the least common ancestor stage between a source and destination node is given by the position of the leftmost digit in which their IDs differ. <p> It may be noted that a worm need not always travel up to the last stage of the bidi-MIN before turning around. Traveling up to a least common ancestor stage [29, 35] corresponding to the given set of destinations and the source, is sufficient. As described in <ref> [35] </ref>, in the bidi-butterfly network the least common ancestor stage between a source and destination node is given by the position of the leftmost digit in which their IDs differ. The least common ancestor stage between a source and a set of destinations may similarly be found. <p> Since we have already seen that the MTM algorithm is the best of the three algorithms, we only used multiport worms generated by the MTM algorithm for our experiments. For unicast based multicast, we used the U-Min algorithm proposed for bidirectional MIN networks in <ref> [35] </ref>. Note that the C-Min algorithm was proposed for unidirectional cube networks and is therefore not considered 32 values of message length, L=80, 160 and 240 flits, are considered for 64 node systems with 4 fi 4 and 8 fi 8 switches. in this section.
References-found: 35

