URL: http://www.cs.utexas.edu/users/raman/papers/iea-aie-94.ps
Refering-URL: http://www.cs.utexas.edu/users/raman/my-papers.html
Root-URL: 
Email: Email: raman@cs.utexas.edu, kuipers@cs.utexas.edu  
Title: THE FIGURE UNDERSTANDER: A SYSTEM FOR INTEGRATING TEXT AND DIAGRAM INPUT TO A KNOWLEDGE BASE  
Author: Raman Rajagopalan and Benjamin Kuipers 
Address: Austin, Texas, USA, 78712.  
Affiliation: Department of Computer Sciences, University of Texas at Austin,  
Note: In Proceedings of the Seventh International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems (IEA/AIE-94) Langhorne, PA: Gordon and Breech Science Publishers, 1994.  
Abstract: Figures, consisting of a diagram and an accompanying textual description, are heavily used in human communication. Diagrams carry static spatial information about the scene while text is used to describe semantic and dynamic information. The saying `a picture is worth a thousand words' exemplifies the great value of diagrams in describing a scenario. Since diagrams and text describe the same object in different ways, the primary task in automating the ability to use both text and diagram input in a modeling system is to find methods for coordinating the differing descriptions. This paper describes an implemented research tool, the Figure Understander, for accomplishing this task. 
Abstract-found: 1
Intro-found: 1
Reference: [AL90] <author> Angehrn, A. and H. Luthi. </author> <title> Intelligent Decision Support Systems: A Visual Interactive Approach. </title> <booktitle> Interfaces 20:6, </booktitle> <pages> 17-28. </pages>
Reference: [BB82] <author> Ballard, D.H. and C.M. Brown. </author> <title> Computer Vision. </title> <publisher> Prentice Hall, </publisher> <year> 1982. </year>
Reference-contexts: In their work, diagram input is treated as simulated visual input, consisting of interconnected lines, arc, and points. They demonstrated effective results on several nontrivial examples, but their approach requires address ing ambiguities in the interpretation of the diagram. They suffer from the classic visual scene analysis problem <ref> [BB82] </ref> of deciding which line segments belong together as parts of the same object, and which are only accidentally intersecting. PICTION [Sri91] is another example of a system for coordinating text and pictoral input given in visual form. <p> We stated previously that Novak and Bulko [NB90, NB93] assume that pictoral input is provided visually and therefore have to face the problems of visual scene interpretation <ref> [BB82] </ref>. In our work, we address diagrams for describing scenarios where the exact visual features are unimportant, and abstractions may be used to approximate the exact spatial extents of objects. Example of such scenarios include textbook diagrams, maps of college campuses, and flow charts. <p> They assumed that the pictoral input is provided visually, and had to address many of the problems associated with visual scene interpretation <ref> [BB82] </ref>, a difficult problem in its own right. We have reduced the scope of the problem, and therefore have produced a simpler solution, by assuming that the diagrams are input via a graphical editor, where each unique object is drawn as a distinguishable entity.
Reference: [Cra90] <author> Crawford, J. </author> <title> Access-Limited Logic A language for knowledge representation. </title> <type> Ph.D. dissertation, TR AI-90-141, </type> <institution> A.I. Lab, Dept. of Computer Sciences, Univ. of Texas at Austin, </institution> <year> 1990. </year>
Reference-contexts: Its output is a fragment of a knowledge base, which can be equivalently described as either a set of ground logical assertions or a set of frames, slots, and values. In the current implementation, the Algernon knowledge representation language <ref> [Cra90, CK92] </ref> is used to maintain the knowledge base. We are using the Figure Understander as the input processing module in a magnetic fields problem solving system [RK94].
Reference: [CK91] <author> Crawford, J. and B. Kuipers. </author> <title> Algernon A Tractable System for Knowledge-Representation. </title> <booktitle> In working notes: AAAI Spring Symposium on Implemented Knowledge Representation and Reasoning Systems, </booktitle> <address> Palo Alto, CA 1991. </address>
Reference: [Gri75] <author> Grice, </author> <title> H.P. Logic and Conversation. </title> <editor> In P. Cole & J. L. Morgan (Eds.), </editor> <title> Syntax and Semantics, v. 3: Speech Acts. </title> <address> New York: </address> <publisher> Academic Press, </publisher> <year> 1975. </year>
Reference-contexts: We are using the Figure Understander as the input processing module in a magnetic fields problem solving system [RK94]. Our approach is motivated by the observation that a figure is a communication act involving at least two agents <ref> [Gri75] </ref>. * The author of a figure has the goal of communicating a description of a situation to a human reader. * The reader of the figure has the goal of extracting the intended knowledge from the diagram and the text description.
Reference: [LS87] <author> Larkin, J. and H. Simon. </author> <title> Why a Diagram is (Sometimes) Worth 10,000 Words. </title> <booktitle> Cognitive Science 11, </booktitle> <pages> 65-99. </pages>
Reference-contexts: Diagrams illustrate objects and their spatial attributes and relationships, and text often describes the semantics and dynamics of those objects. The unique role of each form of input, diagram and text, has already been analyzed in great detail by such authors as Larkin and Simon <ref> [LS87] </ref>. As shown by the recent symposium on diagrammatic representations [SS92], there has been much interest in utilizing both text and diagram input in AI applications.
Reference: [NB90] <author> Novak, G. S., and W. Bulko. </author> <title> Understanding Natural Language with Diagrams. </title> <booktitle> In: Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI-90), </booktitle> <year> 1990, </year> <pages> pp. 465-470. </pages>
Reference-contexts: As shown by the recent symposium on diagrammatic representations [SS92], there has been much interest in utilizing both text and diagram input in AI applications. Novak and Bulko <ref> [NB90, NB93] </ref>, for example, have demonstrated a methodology using a blackboard architecture for utilizing both text and diagrams to solve textbook physics problems. In their work, diagram input is treated as simulated visual input, consisting of interconnected lines, arc, and points. <p> The problem of interpreting the object references in the diagram and text is complicated by fact that the text refers to the objects as `loop' and `ramp' while the diagram contains only two polygons, a directed line, and a circular object. We stated previously that Novak and Bulko <ref> [NB90, NB93] </ref> assume that pictoral input is provided visually and therefore have to face the problems of visual scene interpretation [BB82]. In our work, we address diagrams for describing scenarios where the exact visual features are unimportant, and abstractions may be used to approximate the exact spatial extents of objects. <p> Figure Understander includes a substantial spatial reasoning component and allows the use of spatial relations in the text to assist in isolating the relevant diagram objects. Although the problem of correlating text and diagram input has been addressed at length in previous work, such as Novak and Bulko's <ref> [NB90, NB93] </ref> physics problem solving system, and Srihari's [Sri91] PICTION system, a different set of assumptions were utilized. They assumed that the pictoral input is provided visually, and had to address many of the problems associated with visual scene interpretation [BB82], a difficult problem in its own right.
Reference: [NB93] <author> Novak, G. S., and W. Bulko. </author> <title> Diagrams and Text as Computer Input. </title> <booktitle> Journal of Visual Languages and Computing (1993) 4, </booktitle> <pages> 161-175. </pages>
Reference-contexts: As shown by the recent symposium on diagrammatic representations [SS92], there has been much interest in utilizing both text and diagram input in AI applications. Novak and Bulko <ref> [NB90, NB93] </ref>, for example, have demonstrated a methodology using a blackboard architecture for utilizing both text and diagrams to solve textbook physics problems. In their work, diagram input is treated as simulated visual input, consisting of interconnected lines, arc, and points. <p> The problem of interpreting the object references in the diagram and text is complicated by fact that the text refers to the objects as `loop' and `ramp' while the diagram contains only two polygons, a directed line, and a circular object. We stated previously that Novak and Bulko <ref> [NB90, NB93] </ref> assume that pictoral input is provided visually and therefore have to face the problems of visual scene interpretation [BB82]. In our work, we address diagrams for describing scenarios where the exact visual features are unimportant, and abstractions may be used to approximate the exact spatial extents of objects. <p> Figure Understander includes a substantial spatial reasoning component and allows the use of spatial relations in the text to assist in isolating the relevant diagram objects. Although the problem of correlating text and diagram input has been addressed at length in previous work, such as Novak and Bulko's <ref> [NB90, NB93] </ref> physics problem solving system, and Srihari's [Sri91] PICTION system, a different set of assumptions were utilized. They assumed that the pictoral input is provided visually, and had to address many of the problems associated with visual scene interpretation [BB82], a difficult problem in its own right.
Reference: [Raj93] <author> Rajagopalan, R. </author> <title> A Model of Spatial Position Based on Extremal Points. </title> <booktitle> In Proceedings, ACM Workshop on Advances in Geographic Information Systems, </booktitle> <address> Arlington, VA, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: In addition, we determine such things as the connectivity of the diagram object, the orientation of the object with respect to the global coordinate system, and the relative position of the object with respect to other objects in the diagram <ref> [Raj93, RK94] </ref>. The connectivity of a polygon is stored by creating knowledge base structures for all the edges and vectors, and storing the connections between the edges and vertices.
Reference: [RK94] <author> Rajagopalan R., and B. Kuipers. </author> <title> Qualitative Spatial Reasoning about Objects in Motion: Application to Physics Problem Solving. </title> <booktitle> In: Proceedings of the Tenth IEEE Conference on Artificial Intelligence for Applications (CAIA-94), </booktitle> <address> San Antonio, Texas, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: In the current implementation, the Algernon knowledge representation language [Cra90, CK92] is used to maintain the knowledge base. We are using the Figure Understander as the input processing module in a magnetic fields problem solving system <ref> [RK94] </ref>. <p> In addition, we determine such things as the connectivity of the diagram object, the orientation of the object with respect to the global coordinate system, and the relative position of the object with respect to other objects in the diagram <ref> [Raj93, RK94] </ref>. The connectivity of a polygon is stored by creating knowledge base structures for all the edges and vectors, and storing the connections between the edges and vertices.
Reference: [Sri91] <author> Srihari, R. PICTION: </author> <title> A System that Uses Captions to Label Human Faces in Newspaper Photographs. </title> <booktitle> In: Proceedings of the Ninth National Conference on Artificial Intelligence (AAAI-91), </booktitle> <year> 1991. </year>
Reference-contexts: They suffer from the classic visual scene analysis problem [BB82] of deciding which line segments belong together as parts of the same object, and which are only accidentally intersecting. PICTION <ref> [Sri91] </ref> is another example of a system for coordinating text and pictoral input given in visual form. <p> Although the problem of correlating text and diagram input has been addressed at length in previous work, such as Novak and Bulko's [NB90, NB93] physics problem solving system, and Srihari's <ref> [Sri91] </ref> PICTION system, a different set of assumptions were utilized. They assumed that the pictoral input is provided visually, and had to address many of the problems associated with visual scene interpretation [BB82], a difficult problem in its own right.
Reference: [SS92] <editor> Working Notes: </editor> <booktitle> AAAI Spring Symposium Series. Symposium: Reasoning with Diagrammatic Representations, </booktitle> <institution> Stanford University, </institution> <year> 1992. </year>
Reference-contexts: The unique role of each form of input, diagram and text, has already been analyzed in great detail by such authors as Larkin and Simon [LS87]. As shown by the recent symposium on diagrammatic representations <ref> [SS92] </ref>, there has been much interest in utilizing both text and diagram input in AI applications. Novak and Bulko [NB90, NB93], for example, have demonstrated a methodology using a blackboard architecture for utilizing both text and diagrams to solve textbook physics problems.
References-found: 12

